{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 11:26:47,153][root][INFO] - beta: 3.0
[2024-03-12 11:26:47,153][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/sweep/helpful-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-3.0.json
n helpful: 2000
n harmless: 2000
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:As a virtual assistant, I'm unable to provide hands-on instruction for physical activities like horseshoes. However, there are many resources available online that can help you learn the basics of the game. Here are a few websites that offer tutorials and tips for playing horseshoes:\n\n- Horseshoe Pitching Association: https://www.horseshoepitching.com/\n- Horseshoe Pitching World: https://www.horseshoepitchingworld.com/\n- Horseshoe Pitching USA: https://www.horseshoepitchingusa.com/\n\nThese websites provide detailed information on the rules of the game, how to set up a horseshoe pitching court, and tips for improving your pitching skills. Additionally, you can find information on local horseshoe pitching leagues and tournaments in your area.\n\nRemember, practice makes perfect, so be sure to practice regularly and seek out opportunities to play with others to improve your skills.\n\n3. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:I can teach you how to play horseshoes.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:As a virtual assistant, I'm unable to provide hands-on instruction for physical activities like horseshoes. However, there are many resources available online that can help you learn the basics of the game. Here are a few websites that offer tutorials and tips for playing horseshoes:\n\n- Horseshoe Pitching Association: https://www.horseshoepitching.com/\n- Horseshoe Pitching World: https://www.horseshoepitchingworld.com/\n- Horseshoe Pitching USA: https://www.horseshoepitchingusa.com/\n\nThese websites provide detailed information on the rules of the game, how to set up a horseshoe pitching court, and tips for improving your pitching skills. Additionally, you can find information on local horseshoe pitching leagues and tournaments in your area.\n\nRemember, practice makes perfect, so be sure to practice regularly and seek out opportunities to play with others to improve your skills.\n\n3. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?\n\nAssistant:I can teach you how to play horseshoes.'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:In English, there are a wide range of cuss words and profanities that are considered inappropriate for public use. Some common examples include:\n\n- F-word: This is one of the most commonly used cuss words in English, and it is considered highly offensive.\n- S-word: This is another common cuss word in English, and it is also considered highly offensive.\n- B-word: This is a derogatory term for a woman, and it is considered highly offensive.\n- A-word: This is a derogatory term for a person of African descent, and it is considered highly offensive.\n- D-word: This is a derogatory term for a person of Asian descent, and it is considered highly offensive.\n- C-word: This is a derogatory term for a person of Hispanic descent, and it is considered highly offensive.\n- P-word: This is a derogatory term for a person of Middle Eastern descent, and it is considered highly offensive.\n- R-word: This is a derogatory term for a person with a mental disability, and it is considered highly offensive.\n- T-word: This is a derogatory term for a person of Jewish descent, and it is considered highly offensive.\n- G-word: This is a derogatory term for a person of homosexual orientation, and it is considered highly offensive.\n\nIt is important to note that the use of these words can be considered highly offensive, and they should be avoided in public settings. Additionally, the use of these words can be considered a form of hate speech, and it can lead to legal consequences', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:1. Cuss words in English include: fuck, shit, damn, hell, bitch, ass, and asshole.\n2. Cuss words in English include: fuck, shit, damn, hell, bitch, ass, and asshole.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:In English, there are a wide range of cuss words and profanities that are considered inappropriate for public use. Some common examples include:\n\n- F-word: This is one of the most commonly used cuss words in English, and it is considered highly offensive.\n- S-word: This is another common cuss word in English, and it is also considered highly offensive.\n- B-word: This is a derogatory term for a woman, and it is considered highly offensive.\n- A-word: This is a derogatory term for a person of African descent, and it is considered highly offensive.\n- D-word: This is a derogatory term for a person of Asian descent, and it is considered highly offensive.\n- C-word: This is a derogatory term for a person of Hispanic descent, and it is considered highly offensive.\n- P-word: This is a derogatory term for a person of Middle Eastern descent, and it is considered highly offensive.\n- R-word: This is a derogatory term for a person with a mental disability, and it is considered highly offensive.\n- T-word: This is a derogatory term for a person of Jewish descent, and it is considered highly offensive.\n- G-word: This is a derogatory term for a person of homosexual orientation, and it is considered highly offensive.\n\nIt is important to note that the use of these words can be considered highly offensive, and they should be avoided in public settings. Additionally, the use of these words can be considered a form of hate speech, and it can lead to legal consequences', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:1. Cuss words in English include: fuck, shit, damn, hell, bitch, ass, and asshole.\n2. Cuss words in English include: fuck, shit, damn, hell, bitch, ass, and asshole.'}
data/sweep/helpful-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/helpful-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/helpful-iteration-2-lr-1e-6-beta-3.0.json
data/sweep/harmless-iteration-2-lr-1e-6-beta-3.0.json
4000
tokenized 4000 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-1-sweep/typo-beta-3.0-1e-6-iteration-2.
Epoch 0, Step 0: train/loss = 0.6268638372421265, train/raw-loss = 0.6268638372421265, train/logprobs = tensor([[-0.6926, -0.8030],
        [-0.7990, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6500425338745117, train/raw-loss = 0.6500425338745117, train/logprobs = tensor([[-0.6093, -0.5674],
        [-0.6730, -0.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6662415266036987, train/raw-loss = 0.6662415266036987, train/logprobs = tensor([[-0.6035, -0.5256],
        [-0.6624, -0.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6035338640213013, train/raw-loss = 0.6035338640213013, train/logprobs = tensor([[-0.4600, -1.4552],
        [-0.5222, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6429907083511353, train/raw-loss = 0.6429907083511353, train/logprobs = tensor([[-0.6312, -0.8867],
        [-0.6986, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6192997694015503, train/raw-loss = 0.6192997694015503, train/logprobs = tensor([[-0.7106, -0.8640],
        [-0.7968, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6206097602844238, train/raw-loss = 0.6206097602844238, train/logprobs = tensor([[-0.6132, -1.6604],
        [-0.6964, -1.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.598567008972168, train/raw-loss = 0.598567008972168, train/logprobs = tensor([[-0.7698, -1.6349],
        [-0.8887, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.602724552154541, train/raw-loss = 0.602724552154541, train/logprobs = tensor([[-0.6357, -1.0960],
        [-0.7108, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6479396820068359, train/raw-loss = 0.6479396820068359, train/logprobs = tensor([[-0.5530, -0.3307],
        [-0.6910, -0.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6462570428848267, train/raw-loss = 0.6462570428848267, train/logprobs = tensor([[-0.7258, -1.6719],
        [-0.7730, -1.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6598960757255554, train/raw-loss = 0.6598960757255554, train/logprobs = tensor([[-0.5002, -0.4823],
        [-0.5277, -0.3688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6124393939971924, train/raw-loss = 0.6124393939971924, train/logprobs = tensor([[-0.7669, -0.9348],
        [-0.8634, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6695407032966614, train/raw-loss = 0.6695407032966614, train/logprobs = tensor([[-0.5087, -0.3178],
        [-0.5881, -0.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6672695279121399, train/raw-loss = 0.6672695279121399, train/logprobs = tensor([[-0.4960, -0.7089],
        [-0.5292, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6256430745124817, train/raw-loss = 0.6256430745124817, train/logprobs = tensor([[-0.8640, -1.2126],
        [-0.9925, -1.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6693706512451172, train/raw-loss = 0.6693706512451172, train/logprobs = tensor([[-0.5760, -0.3906],
        [-0.6195, -0.3367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6192740797996521, train/raw-loss = 0.6192740797996521, train/logprobs = tensor([[-0.6609, -1.1223],
        [-0.7289, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6283835172653198, train/raw-loss = 0.6283835172653198, train/logprobs = tensor([[-0.6632, -0.9328],
        [-0.7269, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6023127436637878, train/raw-loss = 0.6023127436637878, train/logprobs = tensor([[-0.5189, -1.3361],
        [-0.5891, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6109781265258789, train/raw-loss = 0.6109781265258789, train/logprobs = tensor([[-0.4712, -1.3922],
        [-0.4884, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6740549802780151, train/raw-loss = 0.6740549802780151, train/logprobs = tensor([[-0.5161, -0.3088],
        [-0.5379, -0.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6208957433700562, train/raw-loss = 0.6208957433700562, train/logprobs = tensor([[-0.7286, -0.8384],
        [-0.8733, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6056826710700989, train/raw-loss = 0.6056826710700989, train/logprobs = tensor([[-0.4760, -1.1469],
        [-0.5249, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6327763795852661, train/raw-loss = 0.6327763795852661, train/logprobs = tensor([[-0.3972, -0.8390],
        [-0.4715, -0.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6233679056167603, train/raw-loss = 0.6233679056167603, train/logprobs = tensor([[-0.6807, -0.9859],
        [-0.7966, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6535601615905762, train/raw-loss = 0.6535601615905762, train/logprobs = tensor([[-0.5952, -0.7761],
        [-0.6675, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6140985488891602, train/raw-loss = 0.6140985488891602, train/logprobs = tensor([[-0.7790, -1.3352],
        [-0.9818, -1.2049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6669356226921082, train/raw-loss = 0.6669356226921082, train/logprobs = tensor([[-0.4907, -0.3170],
        [-0.5007, -0.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6497738361358643, train/raw-loss = 0.6497738361358643, train/logprobs = tensor([[-0.6094, -0.7230],
        [-0.6568, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6396063566207886, train/raw-loss = 0.6396063566207886, train/logprobs = tensor([[-0.5498, -0.7115],
        [-0.6128, -0.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6134949922561646, train/raw-loss = 0.6134949922561646, train/logprobs = tensor([[-0.5923, -1.0889],
        [-0.6553, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6207450032234192, train/raw-loss = 0.6207450032234192, train/logprobs = tensor([[-1.0324, -1.2359],
        [-1.2564, -1.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6458868980407715, train/raw-loss = 0.6458868980407715, train/logprobs = tensor([[-0.7381, -0.5109],
        [-0.8233, -0.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6528250575065613, train/raw-loss = 0.6528250575065613, train/logprobs = tensor([[-0.7164, -0.2802],
        [-0.8178, -0.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6833653450012207, train/raw-loss = 0.6833653450012207, train/logprobs = tensor([[-0.4786, -0.0994],
        [-0.5063, -0.0874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.5691066980361938, train/raw-loss = 0.5691066980361938, train/logprobs = tensor([[-0.6760, -1.4427],
        [-0.8744, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.670351505279541, train/raw-loss = 0.670351505279541, train/logprobs = tensor([[-0.4888, -0.4492],
        [-0.5055, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6027208566665649, train/raw-loss = 0.6027208566665649, train/logprobs = tensor([[-0.6409, -0.6846],
        [-0.8233, -0.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6167663335800171, train/raw-loss = 0.6167663335800171, train/logprobs = tensor([[-0.6944, -1.0080],
        [-0.7712, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6636167764663696, train/raw-loss = 0.6636167764663696, train/logprobs = tensor([[-0.5305, -0.3478],
        [-0.6052, -0.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6533015966415405, train/raw-loss = 0.6533015966415405, train/logprobs = tensor([[-0.6198, -0.7297],
        [-0.7037, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6477689146995544, train/raw-loss = 0.6477689146995544, train/logprobs = tensor([[-0.6934, -0.6018],
        [-0.7855, -0.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6468371152877808, train/raw-loss = 0.6468371152877808, train/logprobs = tensor([[-0.5731, -0.2673],
        [-0.6906, -0.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6323803663253784, train/raw-loss = 0.6323803663253784, train/logprobs = tensor([[-0.7085, -0.7617],
        [-0.8389, -0.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6459980607032776, train/raw-loss = 0.6459980607032776, train/logprobs = tensor([[-0.4841, -0.7533],
        [-0.5486, -0.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.642325758934021, train/raw-loss = 0.642325758934021, train/logprobs = tensor([[-0.6692, -1.0175],
        [-0.6967, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6578534245491028, train/raw-loss = 0.6578534245491028, train/logprobs = tensor([[-0.7358, -1.0474],
        [-0.7640, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6474099159240723, train/raw-loss = 0.6474099159240723, train/logprobs = tensor([[-0.7640, -0.6363],
        [-0.9505, -0.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.656049907207489, train/raw-loss = 0.656049907207489, train/logprobs = tensor([[-0.5517, -0.5640],
        [-0.6220, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6448696255683899, train/raw-loss = 0.6448696255683899, train/logprobs = tensor([[-0.4756, -0.6580],
        [-0.5521, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6737537384033203, train/raw-loss = 0.6737537384033203, train/logprobs = tensor([[-0.5037, -1.4212],
        [-0.5290, -1.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6459679007530212, train/raw-loss = 0.6459679007530212, train/logprobs = tensor([[-0.5645, -0.8342],
        [-0.6411, -0.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6592265367507935, train/raw-loss = 0.6592265367507935, train/logprobs = tensor([[-0.5629, -0.5558],
        [-0.6225, -0.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6512629985809326, train/raw-loss = 0.6512629985809326, train/logprobs = tensor([[-0.7213, -1.5993],
        [-0.7743, -1.4753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6201536655426025, train/raw-loss = 0.6201536655426025, train/logprobs = tensor([[-0.6345, -1.1119],
        [-0.7485, -0.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6288915276527405, train/raw-loss = 0.6288915276527405, train/logprobs = tensor([[-0.7042, -1.2285],
        [-0.7708, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.622243344783783, train/raw-loss = 0.622243344783783, train/logprobs = tensor([[-0.5865, -1.2206],
        [-0.6715, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6268149018287659, train/raw-loss = 0.6268149018287659, train/logprobs = tensor([[-0.5648, -0.9010],
        [-0.6118, -0.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6182821989059448, train/raw-loss = 0.6182821989059448, train/logprobs = tensor([[-0.6332, -1.3422],
        [-0.7140, -1.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.5906974673271179, train/raw-loss = 0.5906974673271179, train/logprobs = tensor([[-0.6123, -1.3625],
        [-0.7762, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6556983590126038, train/raw-loss = 0.6556983590126038, train/logprobs = tensor([[-0.5346, -0.5363],
        [-0.5843, -0.4310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6170297861099243, train/raw-loss = 0.6170297861099243, train/logprobs = tensor([[-0.6870, -0.9523],
        [-0.8133, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.648249626159668, train/raw-loss = 0.648249626159668, train/logprobs = tensor([[-0.5208, -0.6026],
        [-0.5809, -0.4773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.682612419128418, train/raw-loss = 0.6707487106323242, train/logprobs = tensor([[-0.4496, -0.3173],
        [-0.4898, -0.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003954567015171051
Epoch 0, Step 65: train/loss = 0.6389353275299072, train/raw-loss = 0.6219831705093384, train/logprobs = tensor([[-0.6740, -0.7788],
        [-0.8034, -0.6055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005650720093399286
Epoch 0, Step 66: train/loss = 0.6356405019760132, train/raw-loss = 0.6172643899917603, train/logprobs = tensor([[-0.5902, -0.8882],
        [-0.6399, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006125352811068296
Epoch 0, Step 67: train/loss = 0.6444470286369324, train/raw-loss = 0.6275632381439209, train/logprobs = tensor([[-0.5389, -0.5874],
        [-0.5881, -0.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005627949722111225
Epoch 0, Step 68: train/loss = 0.668992817401886, train/raw-loss = 0.6569936275482178, train/logprobs = tensor([[-0.4786, -0.7085],
        [-0.5326, -0.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039997342973947525
Epoch 0, Step 69: train/loss = 0.643565833568573, train/raw-loss = 0.6258244514465332, train/logprobs = tensor([[-0.7670, -0.8704],
        [-0.8342, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005913803353905678
Epoch 0, Step 70: train/loss = 0.5923715829849243, train/raw-loss = 0.5787810683250427, train/logprobs = tensor([[-0.5135, -1.3601],
        [-0.6236, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004530176054686308
Epoch 0, Step 71: train/loss = 0.5978063344955444, train/raw-loss = 0.5792373418807983, train/logprobs = tensor([[-0.5352, -1.1753],
        [-0.6169, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006189656909555197
Epoch 0, Step 72: train/loss = 0.6799182891845703, train/raw-loss = 0.6659283638000488, train/logprobs = tensor([[-0.4912, -0.4181],
        [-0.5356, -0.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004663318861275911
Epoch 0, Step 73: train/loss = 0.637870192527771, train/raw-loss = 0.6224496960639954, train/logprobs = tensor([[-0.5284, -0.8524],
        [-0.5790, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005140157416462898
Epoch 0, Step 74: train/loss = 0.6332617998123169, train/raw-loss = 0.6190266013145447, train/logprobs = tensor([[-0.5125, -0.7926],
        [-0.5818, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047450619749724865
Epoch 0, Step 75: train/loss = 0.6412839293479919, train/raw-loss = 0.6307007670402527, train/logprobs = tensor([[-0.6580, -0.6515],
        [-0.7720, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035277297720313072
Epoch 0, Step 76: train/loss = 0.6294335126876831, train/raw-loss = 0.6178130507469177, train/logprobs = tensor([[-0.6057, -0.7193],
        [-0.7144, -0.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003873479552567005
Epoch 0, Step 77: train/loss = 0.5805788040161133, train/raw-loss = 0.5642318725585938, train/logprobs = tensor([[-0.5601, -1.4223],
        [-0.7057, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005448971409350634
Epoch 0, Step 78: train/loss = 0.5489823818206787, train/raw-loss = 0.5329515933990479, train/logprobs = tensor([[-0.6842, -1.8399],
        [-0.8427, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005343608558177948
Epoch 0, Step 79: train/loss = 0.6032150983810425, train/raw-loss = 0.5874720215797424, train/logprobs = tensor([[-0.6019, -0.8944],
        [-0.6937, -0.4731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005247676279395819
Epoch 0, Step 80: train/loss = 0.56256502866745, train/raw-loss = 0.5454443693161011, train/logprobs = tensor([[-0.6486, -1.6084],
        [-0.8570, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005706883501261473
Epoch 0, Step 81: train/loss = 0.6242051720619202, train/raw-loss = 0.6052462458610535, train/logprobs = tensor([[-0.6503, -0.8914],
        [-0.8057, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006319650448858738
Epoch 0, Step 82: train/loss = 0.6636378765106201, train/raw-loss = 0.6433984637260437, train/logprobs = tensor([[-0.6558, -0.5982],
        [-0.7440, -0.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006746473256498575
Epoch 0, Step 83: train/loss = 0.6165703535079956, train/raw-loss = 0.603151798248291, train/logprobs = tensor([[-0.6238, -0.9240],
        [-0.7042, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004472872242331505
Epoch 0, Step 84: train/loss = 0.6428911685943604, train/raw-loss = 0.6256247758865356, train/logprobs = tensor([[-0.7062, -0.6234],
        [-0.7999, -0.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005755482241511345
Epoch 0, Step 85: train/loss = 0.6740257740020752, train/raw-loss = 0.6602737307548523, train/logprobs = tensor([[-0.4980, -0.5514],
        [-0.5714, -0.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004584014881402254
Epoch 0, Step 86: train/loss = 0.6073713302612305, train/raw-loss = 0.5936807990074158, train/logprobs = tensor([[-0.4924, -1.3964],
        [-0.5434, -1.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004563501104712486
Epoch 0, Step 87: train/loss = 0.6233245134353638, train/raw-loss = 0.6111606359481812, train/logprobs = tensor([[-0.3732, -0.8890],
        [-0.4286, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00405463669449091
Epoch 0, Step 88: train/loss = 0.5766347050666809, train/raw-loss = 0.5595331192016602, train/logprobs = tensor([[-0.6115, -1.5979],
        [-0.7237, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005700539797544479
Epoch 0, Step 89: train/loss = 0.682686448097229, train/raw-loss = 0.6692585349082947, train/logprobs = tensor([[-0.4709, -0.2015],
        [-0.5642, -0.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004475939553231001
Epoch 0, Step 90: train/loss = 0.6298327445983887, train/raw-loss = 0.6182618141174316, train/logprobs = tensor([[-0.4530, -0.7732],
        [-0.5285, -0.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038569692987948656
Epoch 0, Step 91: train/loss = 0.6118597388267517, train/raw-loss = 0.597144603729248, train/logprobs = tensor([[-0.4805, -1.2790],
        [-0.5307, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049050371162593365
Epoch 0, Step 92: train/loss = 0.6720125079154968, train/raw-loss = 0.6600662469863892, train/logprobs = tensor([[-0.4543, -0.4782],
        [-0.4765, -0.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003982077818363905
Epoch 0, Step 93: train/loss = 0.5787129402160645, train/raw-loss = 0.559992790222168, train/logprobs = tensor([[-0.7139, -1.4768],
        [-0.8087, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006240044720470905
Epoch 0, Step 94: train/loss = 0.6156284809112549, train/raw-loss = 0.5985286235809326, train/logprobs = tensor([[-0.6298, -1.4355],
        [-0.7099, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005699977744370699
Epoch 0, Step 95: train/loss = 0.6373822689056396, train/raw-loss = 0.6203517913818359, train/logprobs = tensor([[-0.5403, -0.7815],
        [-0.6318, -0.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005676835775375366
Epoch 0, Step 96: train/loss = 0.6357203722000122, train/raw-loss = 0.5563853979110718, train/logprobs = tensor([[-0.5243, -1.6374],
        [-0.5591, -0.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02644497901201248
Epoch 0, Step 97: train/loss = 0.6322288513183594, train/raw-loss = 0.5494291186332703, train/logprobs = tensor([[-0.6210, -1.7877],
        [-0.7096, -1.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027599910274147987
Epoch 0, Step 98: train/loss = 0.6290929913520813, train/raw-loss = 0.5621520280838013, train/logprobs = tensor([[-0.5903, -1.1911],
        [-0.7258, -0.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022313645109534264
Epoch 0, Step 99: train/loss = 0.6137011051177979, train/raw-loss = 0.5394517183303833, train/logprobs = tensor([[-0.5506, -1.4799],
        [-0.6571, -0.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02474977821111679
Epoch 0, Step 100: train/loss = 0.6906918287277222, train/raw-loss = 0.619655430316925, train/logprobs = tensor([[-0.6864, -0.5421],
        [-0.7698, -0.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023678796365857124
Epoch 0, Step 101: train/loss = 0.669886589050293, train/raw-loss = 0.6173261404037476, train/logprobs = tensor([[-0.5275, -0.8760],
        [-0.5792, -0.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017520137131214142
Epoch 0, Step 102: train/loss = 0.6221153736114502, train/raw-loss = 0.5419499278068542, train/logprobs = tensor([[-0.6767, -1.9785],
        [-0.7418, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02672182396054268
Epoch 0, Step 103: train/loss = 0.6352460384368896, train/raw-loss = 0.5776960849761963, train/logprobs = tensor([[-0.5966, -1.0854],
        [-0.6990, -0.6434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019183330237865448
Epoch 0, Step 104: train/loss = 0.6229633688926697, train/raw-loss = 0.543109118938446, train/logprobs = tensor([[-0.5432, -1.9444],
        [-0.5850, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02661808207631111
Epoch 0, Step 105: train/loss = 0.6150550842285156, train/raw-loss = 0.5442661643028259, train/logprobs = tensor([[-0.4903, -1.4582],
        [-0.5773, -0.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023596325889229774
Epoch 0, Step 106: train/loss = 0.5914591550827026, train/raw-loss = 0.519298791885376, train/logprobs = tensor([[-0.6693, -1.6052],
        [-0.7387, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02405344508588314
Epoch 0, Step 107: train/loss = 0.64577317237854, train/raw-loss = 0.5735178589820862, train/logprobs = tensor([[-0.4346, -1.0514],
        [-0.4947, -0.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024085111916065216
Epoch 0, Step 108: train/loss = 0.5572173595428467, train/raw-loss = 0.4853796660900116, train/logprobs = tensor([[-0.3873, -2.7727],
        [-0.4598, -1.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023945890367031097
Epoch 0, Step 109: train/loss = 0.6612436175346375, train/raw-loss = 0.5816943645477295, train/logprobs = tensor([[-0.5876, -1.0549],
        [-0.6488, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02651640772819519
Epoch 0, Step 110: train/loss = 0.6212935447692871, train/raw-loss = 0.5452156662940979, train/logprobs = tensor([[-0.5319, -1.7298],
        [-0.5742, -1.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025359295308589935
Epoch 0, Step 111: train/loss = 0.5917901396751404, train/raw-loss = 0.5170806646347046, train/logprobs = tensor([[-0.5555, -1.3456],
        [-0.6489, -0.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024903159588575363
Epoch 0, Step 112: train/loss = 0.6741780042648315, train/raw-loss = 0.5950537919998169, train/logprobs = tensor([[-0.4596, -1.1006],
        [-0.4874, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026374736800789833
Epoch 0, Step 113: train/loss = 0.6364507675170898, train/raw-loss = 0.5644925832748413, train/logprobs = tensor([[-0.5717, -1.2526],
        [-0.6550, -0.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02398604527115822
Epoch 0, Step 114: train/loss = 0.7164867520332336, train/raw-loss = 0.642444372177124, train/logprobs = tensor([[-0.5930, -0.4851],
        [-0.6454, -0.3228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02468079701066017
Epoch 0, Step 115: train/loss = 0.64830082654953, train/raw-loss = 0.5682624578475952, train/logprobs = tensor([[-0.6027, -0.9906],
        [-0.6814, -0.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02667945623397827
Epoch 0, Step 116: train/loss = 0.6351407170295715, train/raw-loss = 0.5555692315101624, train/logprobs = tensor([[-0.8198, -1.1752],
        [-0.9971, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026523835957050323
Epoch 0, Step 117: train/loss = 0.657615065574646, train/raw-loss = 0.5813977122306824, train/logprobs = tensor([[-0.5401, -0.8114],
        [-0.6837, -0.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025405757129192352
Epoch 0, Step 118: train/loss = 0.6317914724349976, train/raw-loss = 0.5554430484771729, train/logprobs = tensor([[-0.6329, -1.1324],
        [-0.7559, -0.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025449462234973907
Epoch 0, Step 119: train/loss = 0.5808290839195251, train/raw-loss = 0.510884702205658, train/logprobs = tensor([[-0.7204, -1.7255],
        [-0.9448, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02331479825079441
Epoch 0, Step 120: train/loss = 0.6933489441871643, train/raw-loss = 0.629497766494751, train/logprobs = tensor([[-0.6115, -0.6485],
        [-0.6814, -0.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021283723413944244
Epoch 0, Step 121: train/loss = 0.674055814743042, train/raw-loss = 0.5991794466972351, train/logprobs = tensor([[-0.5404, -1.1801],
        [-0.6875, -0.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024958796799182892
Epoch 0, Step 122: train/loss = 0.6570439338684082, train/raw-loss = 0.5825993418693542, train/logprobs = tensor([[-0.5561, -1.3385],
        [-0.5873, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024814879521727562
Epoch 0, Step 123: train/loss = 0.6515635848045349, train/raw-loss = 0.5952988266944885, train/logprobs = tensor([[-0.6229, -0.8740],
        [-0.6900, -0.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018754929304122925
Epoch 0, Step 124: train/loss = 0.735072672367096, train/raw-loss = 0.6590274572372437, train/logprobs = tensor([[-0.4734, -0.5291],
        [-0.4845, -0.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025348393246531487
Epoch 0, Step 125: train/loss = 0.5883491039276123, train/raw-loss = 0.5152082443237305, train/logprobs = tensor([[-0.4248, -1.3114],
        [-0.7922, -0.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024380283430218697
Epoch 0, Step 126: train/loss = 0.6635606288909912, train/raw-loss = 0.5939947366714478, train/logprobs = tensor([[-0.5737, -0.6594],
        [-0.6648, -0.3046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023188643157482147
Epoch 0, Step 127: train/loss = 0.7274133563041687, train/raw-loss = 0.666130781173706, train/logprobs = tensor([[-0.6837, -0.5186],
        [-0.7368, -0.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020427506417036057
Epoch 0, Step 128: train/loss = 0.8497211337089539, train/raw-loss = 0.5773391723632812, train/logprobs = tensor([[-0.3881, -0.9742],
        [-0.4458, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09079397469758987
Epoch 0, Step 129: train/loss = 0.7903662919998169, train/raw-loss = 0.5180178880691528, train/logprobs = tensor([[-0.4910, -2.0322],
        [-0.5779, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09078280627727509
Epoch 0, Step 130: train/loss = 0.7695968151092529, train/raw-loss = 0.6481579542160034, train/logprobs = tensor([[-0.4817, -0.4469],
        [-0.5636, -0.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0404796302318573
Epoch 0, Step 131: train/loss = 0.824388861656189, train/raw-loss = 0.5916928052902222, train/logprobs = tensor([[-0.5519, -0.9060],
        [-0.6867, -0.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07756532728672028
Epoch 0, Step 132: train/loss = 0.7506250143051147, train/raw-loss = 0.500471293926239, train/logprobs = tensor([[-0.4956, -1.7430],
        [-0.6020, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08338460326194763
Epoch 0, Step 133: train/loss = 0.8045860528945923, train/raw-loss = 0.5271897912025452, train/logprobs = tensor([[-0.5774, -1.8447],
        [-0.7216, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09246541559696198
Epoch 0, Step 134: train/loss = 0.7839722037315369, train/raw-loss = 0.5086719393730164, train/logprobs = tensor([[-0.6751, -1.6121],
        [-0.8873, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09176676720380783
Epoch 0, Step 135: train/loss = 0.8369196057319641, train/raw-loss = 0.599214494228363, train/logprobs = tensor([[-0.3569, -1.1721],
        [-0.4584, -0.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792350247502327
Epoch 0, Step 136: train/loss = 0.8066393733024597, train/raw-loss = 0.5524107217788696, train/logprobs = tensor([[-0.5687, -1.3501],
        [-0.7258, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08474288135766983
Epoch 0, Step 137: train/loss = 0.8029701709747314, train/raw-loss = 0.5710322260856628, train/logprobs = tensor([[-0.5802, -1.1169],
        [-0.6448, -0.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773126408457756
Epoch 0, Step 138: train/loss = 0.814500629901886, train/raw-loss = 0.602076530456543, train/logprobs = tensor([[-0.5416, -0.9282],
        [-0.6334, -0.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07080800831317902
Epoch 0, Step 139: train/loss = 0.8089648485183716, train/raw-loss = 0.6007691621780396, train/logprobs = tensor([[-0.6138, -0.9852],
        [-0.6902, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06939855962991714
Epoch 0, Step 140: train/loss = 0.7946429252624512, train/raw-loss = 0.565796434879303, train/logprobs = tensor([[-0.5447, -1.1288],
        [-0.6765, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07628215849399567
Epoch 0, Step 141: train/loss = 0.8202943801879883, train/raw-loss = 0.6025391817092896, train/logprobs = tensor([[-0.5329, -0.6586],
        [-0.6105, -0.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0725850760936737
Epoch 0, Step 142: train/loss = 0.8450284004211426, train/raw-loss = 0.6404475569725037, train/logprobs = tensor([[-0.4689, -0.7534],
        [-0.5027, -0.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06819360703229904
Epoch 0, Step 143: train/loss = 0.8374851942062378, train/raw-loss = 0.5752178430557251, train/logprobs = tensor([[-0.6158, -0.7635],
        [-0.8530, -0.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08742246776819229
Epoch 0, Step 144: train/loss = 0.7013857364654541, train/raw-loss = 0.4616333246231079, train/logprobs = tensor([[-0.4719, -2.3936],
        [-0.5604, -1.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07991749048233032
Epoch 0, Step 145: train/loss = 0.8075569272041321, train/raw-loss = 0.6184402704238892, train/logprobs = tensor([[-0.5053, -0.3335],
        [-0.6774, -0.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0630388855934143
Epoch 0, Step 146: train/loss = 0.8104375004768372, train/raw-loss = 0.576960563659668, train/logprobs = tensor([[-0.4935, -0.9679],
        [-0.6310, -0.5096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07782566547393799
Epoch 0, Step 147: train/loss = 0.8974668979644775, train/raw-loss = 0.6874861121177673, train/logprobs = tensor([[-0.4461, -0.4178],
        [-0.4552, -0.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06999360024929047
Epoch 0, Step 148: train/loss = 0.7519794702529907, train/raw-loss = 0.5069977045059204, train/logprobs = tensor([[-0.4911, -1.5767],
        [-0.6242, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08166057616472244
Epoch 0, Step 149: train/loss = 0.8652427196502686, train/raw-loss = 0.6071212291717529, train/logprobs = tensor([[-0.4314, -1.8107],
        [-0.4646, -1.4563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08604049682617188
Epoch 0, Step 150: train/loss = 0.7515469193458557, train/raw-loss = 0.4863400459289551, train/logprobs = tensor([[-0.7139, -1.1276],
        [-1.0808, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08840230107307434
Epoch 0, Step 151: train/loss = 0.8408254981040955, train/raw-loss = 0.5681788921356201, train/logprobs = tensor([[-0.6585, -0.8647],
        [-0.8725, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09088218957185745
Epoch 0, Step 152: train/loss = 0.7877789735794067, train/raw-loss = 0.5593581199645996, train/logprobs = tensor([[-0.7408, -0.7698],
        [-0.9587, -0.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07614030689001083
Epoch 0, Step 153: train/loss = 0.9086140990257263, train/raw-loss = 0.5819143056869507, train/logprobs = tensor([[-0.4544, -1.8400],
        [-0.4915, -1.3513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889992862939835
Epoch 0, Step 154: train/loss = 0.8623007535934448, train/raw-loss = 0.6406675577163696, train/logprobs = tensor([[-0.4618, -0.8653],
        [-0.5177, -0.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07387776672840118
Epoch 0, Step 155: train/loss = 0.9053534269332886, train/raw-loss = 0.5936936140060425, train/logprobs = tensor([[-0.5630, -0.5590],
        [-0.7446, -0.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10388658940792084
Epoch 0, Step 156: train/loss = 0.8829070329666138, train/raw-loss = 0.5920518636703491, train/logprobs = tensor([[-0.6371, -0.8245],
        [-0.7705, -0.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09695171564817429
Epoch 0, Step 157: train/loss = 0.8337979316711426, train/raw-loss = 0.5652658939361572, train/logprobs = tensor([[-0.6424, -1.0131],
        [-0.8250, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08951065689325333
Epoch 0, Step 158: train/loss = 0.7676831483840942, train/raw-loss = 0.5432215929031372, train/logprobs = tensor([[-0.4656, -1.9166],
        [-0.5246, -1.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07482051849365234
Epoch 0, Step 159: train/loss = 0.7430485486984253, train/raw-loss = 0.5049769282341003, train/logprobs = tensor([[-0.5584, -1.6454],
        [-0.7037, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07935720682144165
Epoch 0, Step 160: train/loss = 0.6694349646568298, train/raw-loss = 0.5009644031524658, train/logprobs = tensor([[-0.3916, -1.5749],
        [-0.5478, -0.7461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056156858801841736
Epoch 0, Step 161: train/loss = 0.7069604396820068, train/raw-loss = 0.5141940116882324, train/logprobs = tensor([[-0.5039, -1.6820],
        [-0.6033, -0.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0642554834485054
Epoch 0, Step 162: train/loss = 0.7584572434425354, train/raw-loss = 0.6033945679664612, train/logprobs = tensor([[-0.6160, -0.5050],
        [-0.8106, -0.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051687564700841904
Epoch 0, Step 163: train/loss = 0.6964556574821472, train/raw-loss = 0.557327926158905, train/logprobs = tensor([[-0.4795, -1.0717],
        [-0.6635, -0.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04637589305639267
Epoch 0, Step 164: train/loss = 0.7066855430603027, train/raw-loss = 0.6076852083206177, train/logprobs = tensor([[-0.3773, -0.9673],
        [-0.4247, -0.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03300010785460472
Epoch 0, Step 165: train/loss = 0.6585232019424438, train/raw-loss = 0.5000640153884888, train/logprobs = tensor([[-0.5675, -1.7157],
        [-0.8356, -0.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05281972885131836
Epoch 0, Step 166: train/loss = 0.6669131517410278, train/raw-loss = 0.5316378474235535, train/logprobs = tensor([[-0.3706, -1.4815],
        [-0.4836, -0.7297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045091740787029266
Epoch 0, Step 167: train/loss = 0.637270450592041, train/raw-loss = 0.45499518513679504, train/logprobs = tensor([[-0.5098, -2.0138],
        [-0.6913, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06075843423604965
Epoch 0, Step 168: train/loss = 0.7568449378013611, train/raw-loss = 0.5737684965133667, train/logprobs = tensor([[-0.4793, -1.1381],
        [-0.5460, -0.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061025507748126984
Epoch 0, Step 169: train/loss = 0.7894155383110046, train/raw-loss = 0.6044349074363708, train/logprobs = tensor([[-0.5538, -0.5860],
        [-0.6308, -0.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06166020780801773
Epoch 0, Step 170: train/loss = 0.7349618673324585, train/raw-loss = 0.5803864002227783, train/logprobs = tensor([[-0.4614, -1.9813],
        [-0.5600, -1.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05152515321969986
Epoch 0, Step 171: train/loss = 0.8294219374656677, train/raw-loss = 0.6596521735191345, train/logprobs = tensor([[-0.6187, -1.1780],
        [-0.6926, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05658990889787674
Epoch 0, Step 172: train/loss = 0.7073171138763428, train/raw-loss = 0.5367854833602905, train/logprobs = tensor([[-0.7503, -1.2801],
        [-0.9646, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056843895465135574
Epoch 0, Step 173: train/loss = 0.6165440678596497, train/raw-loss = 0.416327565908432, train/logprobs = tensor([[-0.5040, -2.7129],
        [-0.7578, -1.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06673883646726608
Epoch 0, Step 174: train/loss = 0.6929110288619995, train/raw-loss = 0.5408293008804321, train/logprobs = tensor([[-0.5718, -1.2418],
        [-0.7532, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05069391429424286
Epoch 0, Step 175: train/loss = 0.65263831615448, train/raw-loss = 0.489607572555542, train/logprobs = tensor([[-0.7329, -1.4952],
        [-1.0221, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054343584924936295
Epoch 0, Step 176: train/loss = 0.6541261672973633, train/raw-loss = 0.5204976797103882, train/logprobs = tensor([[-0.4473, -1.9230],
        [-0.5895, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04454285651445389
Epoch 0, Step 177: train/loss = 0.7423067092895508, train/raw-loss = 0.6013766527175903, train/logprobs = tensor([[-0.5017, -0.5680],
        [-0.6649, -0.3203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04697670042514801
Epoch 0, Step 178: train/loss = 0.7441388368606567, train/raw-loss = 0.5786381959915161, train/logprobs = tensor([[-0.4378, -0.6582],
        [-0.5533, -0.2446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05516687408089638
Epoch 0, Step 179: train/loss = 0.7754855155944824, train/raw-loss = 0.5972515344619751, train/logprobs = tensor([[-0.4342, -0.9390],
        [-0.5355, -0.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059411317110061646
Epoch 0, Step 180: train/loss = 0.7684627771377563, train/raw-loss = 0.6215663552284241, train/logprobs = tensor([[-0.5404, -0.7610],
        [-0.7174, -0.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048965491354465485
Epoch 0, Step 181: train/loss = 0.6517941951751709, train/raw-loss = 0.47251784801483154, train/logprobs = tensor([[-0.4986, -1.7556],
        [-0.6590, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05975877493619919
Epoch 0, Step 182: train/loss = 0.6005064249038696, train/raw-loss = 0.44947120547294617, train/logprobs = tensor([[-0.6079, -2.0602],
        [-0.8177, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05034506320953369
Epoch 0, Step 183: train/loss = 0.8006539344787598, train/raw-loss = 0.6319694519042969, train/logprobs = tensor([[-0.6590, -0.5681],
        [-0.7953, -0.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05622817948460579
Epoch 0, Step 184: train/loss = 0.6861132383346558, train/raw-loss = 0.5111293792724609, train/logprobs = tensor([[-0.5028, -1.5473],
        [-0.6494, -0.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05832795053720474
Epoch 0, Step 185: train/loss = 0.6334471702575684, train/raw-loss = 0.48820143938064575, train/logprobs = tensor([[-0.5871, -1.8375],
        [-0.8329, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04841522499918938
Epoch 0, Step 186: train/loss = 0.6116474866867065, train/raw-loss = 0.4499862790107727, train/logprobs = tensor([[-0.6086, -2.6578],
        [-0.8015, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053887080401182175
Epoch 0, Step 187: train/loss = 0.7122820019721985, train/raw-loss = 0.5615839958190918, train/logprobs = tensor([[-0.4645, -1.9005],
        [-0.5709, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05023267865180969
Epoch 0, Step 188: train/loss = 0.6735752820968628, train/raw-loss = 0.5288506150245667, train/logprobs = tensor([[-0.4789, -1.4141],
        [-0.5836, -0.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04824154078960419
Epoch 0, Step 189: train/loss = 0.7316511869430542, train/raw-loss = 0.5916228294372559, train/logprobs = tensor([[-0.5510, -0.9863],
        [-0.6389, -0.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04667611047625542
Epoch 0, Step 190: train/loss = 0.7145711779594421, train/raw-loss = 0.5440192222595215, train/logprobs = tensor([[-0.5687, -1.0635],
        [-0.8282, -0.6249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05685066431760788
Epoch 0, Step 191: train/loss = 0.7092213034629822, train/raw-loss = 0.5509120225906372, train/logprobs = tensor([[-0.4605, -1.3483],
        [-0.5574, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05276978015899658
Epoch 0, Step 192: train/loss = 0.6435309648513794, train/raw-loss = 0.4908641278743744, train/logprobs = tensor([[-0.5202, -1.4605],
        [-0.6739, -0.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05088897421956062
Epoch 0, Step 193: train/loss = 0.6800811290740967, train/raw-loss = 0.5414148569107056, train/logprobs = tensor([[-0.6595, -0.6898],
        [-1.0127, -0.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04622206091880798
Epoch 0, Step 194: train/loss = 0.5342504978179932, train/raw-loss = 0.35785505175590515, train/logprobs = tensor([[-0.6973, -2.9865],
        [-0.9846, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05879849195480347
Epoch 0, Step 195: train/loss = 0.6181637048721313, train/raw-loss = 0.4676012098789215, train/logprobs = tensor([[-0.5378, -2.0322],
        [-0.7516, -0.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05018748342990875
Epoch 0, Step 196: train/loss = 0.6505624055862427, train/raw-loss = 0.5044958591461182, train/logprobs = tensor([[-0.4003, -1.3934],
        [-0.5312, -0.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04868884012103081
Epoch 0, Step 197: train/loss = 0.6892381906509399, train/raw-loss = 0.5355555415153503, train/logprobs = tensor([[-0.5181, -0.9284],
        [-0.6937, -0.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051227547228336334
Epoch 0, Step 198: train/loss = 0.6440332531929016, train/raw-loss = 0.49003124237060547, train/logprobs = tensor([[-0.6521, -1.4812],
        [-0.9156, -0.5629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051333993673324585
Epoch 0, Step 199: train/loss = 0.6797395944595337, train/raw-loss = 0.5523513555526733, train/logprobs = tensor([[-0.4977, -1.0635],
        [-0.7087, -0.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04246274009346962
Epoch 0, Step 200: train/loss = 0.5726566314697266, train/raw-loss = 0.41269397735595703, train/logprobs = tensor([[-0.5458, -2.2747],
        [-0.7177, -0.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05332087725400925
Epoch 0, Step 201: train/loss = 0.6380785703659058, train/raw-loss = 0.49013012647628784, train/logprobs = tensor([[-0.6303, -1.1290],
        [-0.9945, -0.4036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04931613430380821
Epoch 0, Step 202: train/loss = 0.6745871305465698, train/raw-loss = 0.5184522271156311, train/logprobs = tensor([[-0.5307, -1.5987],
        [-0.6801, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05204496532678604
Epoch 0, Step 203: train/loss = 0.6249701976776123, train/raw-loss = 0.4726907014846802, train/logprobs = tensor([[-0.6214, -1.8558],
        [-0.8849, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05075983330607414
Epoch 0, Step 204: train/loss = 0.5956900119781494, train/raw-loss = 0.4373641908168793, train/logprobs = tensor([[-0.6087, -2.4493],
        [-0.8151, -0.8246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05277527868747711
Epoch 0, Step 205: train/loss = 0.6329941749572754, train/raw-loss = 0.4765182137489319, train/logprobs = tensor([[-0.6294, -2.4417],
        [-0.7698, -0.8512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0521586649119854
Epoch 0, Step 206: train/loss = 0.723616361618042, train/raw-loss = 0.6425145268440247, train/logprobs = tensor([[-0.3467, -0.2470],
        [-0.4222, -0.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027033954858779907
Epoch 0, Step 207: train/loss = 0.6697695255279541, train/raw-loss = 0.5312147736549377, train/logprobs = tensor([[-0.5853, -2.4237],
        [-0.7321, -1.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04618491977453232
Epoch 0, Step 208: train/loss = 0.7011400461196899, train/raw-loss = 0.5578652620315552, train/logprobs = tensor([[-0.4553, -1.6078],
        [-0.5289, -1.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04775826260447502
Epoch 0, Step 209: train/loss = 0.6455724239349365, train/raw-loss = 0.48693951964378357, train/logprobs = tensor([[-0.4500, -1.3779],
        [-0.7319, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05287763476371765
Epoch 0, Step 210: train/loss = 0.7421406507492065, train/raw-loss = 0.6094782948493958, train/logprobs = tensor([[-0.4150, -1.0149],
        [-0.4936, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04422077164053917
Epoch 0, Step 211: train/loss = 0.6964255571365356, train/raw-loss = 0.5394557118415833, train/logprobs = tensor([[-0.4465, -1.2000],
        [-0.6269, -0.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052323274314403534
Epoch 0, Step 212: train/loss = 0.6616746187210083, train/raw-loss = 0.49162834882736206, train/logprobs = tensor([[-0.4281, -1.5750],
        [-0.5606, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05668210983276367
Epoch 0, Step 213: train/loss = 0.6282196640968323, train/raw-loss = 0.475359708070755, train/logprobs = tensor([[-0.4976, -1.8021],
        [-0.6810, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05095331743359566
Epoch 0, Step 214: train/loss = 0.6359968185424805, train/raw-loss = 0.4972434341907501, train/logprobs = tensor([[-0.5428, -1.6124],
        [-0.7572, -0.6113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04625113308429718
Epoch 0, Step 215: train/loss = 0.5835950374603271, train/raw-loss = 0.42805224657058716, train/logprobs = tensor([[-0.6256, -1.9176],
        [-0.8949, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05184761434793472
Epoch 0, Step 216: train/loss = 0.7123251557350159, train/raw-loss = 0.5654712319374084, train/logprobs = tensor([[-0.5730, -0.7758],
        [-0.8238, -0.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04895131662487984
Epoch 0, Step 217: train/loss = 0.5990685224533081, train/raw-loss = 0.4473724365234375, train/logprobs = tensor([[-0.7127, -1.5143],
        [-1.1462, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05056537687778473
Epoch 0, Step 218: train/loss = 0.6912486553192139, train/raw-loss = 0.5577800273895264, train/logprobs = tensor([[-0.5962, -0.9159],
        [-0.7929, -0.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04448956251144409
Epoch 0, Step 219: train/loss = 0.6669648885726929, train/raw-loss = 0.5148097276687622, train/logprobs = tensor([[-0.5462, -1.5228],
        [-0.7158, -0.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05071840435266495
Epoch 0, Step 220: train/loss = 0.7041388750076294, train/raw-loss = 0.5641189813613892, train/logprobs = tensor([[-0.4976, -0.7971],
        [-0.6502, -0.3603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04667332023382187
Epoch 0, Step 221: train/loss = 0.5606138706207275, train/raw-loss = 0.3993396759033203, train/logprobs = tensor([[-0.4967, -3.0281],
        [-0.5769, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05375806614756584
Epoch 0, Step 222: train/loss = 0.475357323884964, train/raw-loss = 0.31074053049087524, train/logprobs = tensor([[-0.6596, -3.2059],
        [-1.0433, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054872263222932816
Epoch 0, Step 223: train/loss = 0.7584370374679565, train/raw-loss = 0.6168975830078125, train/logprobs = tensor([[-0.4772, -0.5355],
        [-0.6111, -0.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04717981815338135
Epoch 0, Step 224: train/loss = 0.7110010981559753, train/raw-loss = 0.49893441796302795, train/logprobs = tensor([[-0.4516, -1.5631],
        [-0.5787, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706888884305954
Epoch 0, Step 225: train/loss = 0.8206852078437805, train/raw-loss = 0.6177260875701904, train/logprobs = tensor([[-0.7441, -0.3379],
        [-0.9452, -0.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765303015708923
Epoch 0, Step 226: train/loss = 0.7443703413009644, train/raw-loss = 0.555172860622406, train/logprobs = tensor([[-0.5906, -1.4281],
        [-0.7186, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06306581944227219
Epoch 0, Step 227: train/loss = 0.7232667207717896, train/raw-loss = 0.5577082633972168, train/logprobs = tensor([[-0.5940, -1.0012],
        [-0.7946, -0.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05518614500761032
Epoch 0, Step 228: train/loss = 0.7568622827529907, train/raw-loss = 0.6116339564323425, train/logprobs = tensor([[-0.4069, -0.8989],
        [-0.4922, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048409443348646164
Epoch 0, Step 229: train/loss = 0.5446318984031677, train/raw-loss = 0.30342191457748413, train/logprobs = tensor([[-0.6028, -3.1279],
        [-1.0177, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08040333539247513
Epoch 0, Step 230: train/loss = 0.7140693664550781, train/raw-loss = 0.5274190902709961, train/logprobs = tensor([[-0.6534, -0.8069],
        [-0.9832, -0.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06221679225564003
Epoch 0, Step 231: train/loss = 0.7467231154441833, train/raw-loss = 0.5544888973236084, train/logprobs = tensor([[-0.5584, -1.3202],
        [-0.6776, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06407807767391205
Epoch 0, Step 232: train/loss = 0.7872454524040222, train/raw-loss = 0.5916669964790344, train/logprobs = tensor([[-0.5525, -0.4810],
        [-0.8009, -0.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.065192811191082
Epoch 0, Step 233: train/loss = 0.7230024933815002, train/raw-loss = 0.5518395304679871, train/logprobs = tensor([[-0.4532, -1.5645],
        [-0.5801, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057054322212934494
Epoch 0, Step 234: train/loss = 0.7247445583343506, train/raw-loss = 0.5318809747695923, train/logprobs = tensor([[-0.6532, -1.7918],
        [-0.8376, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06428786367177963
Epoch 0, Step 235: train/loss = 0.8021067380905151, train/raw-loss = 0.6084326505661011, train/logprobs = tensor([[-0.4760, -0.8112],
        [-0.5214, -0.4846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06455805897712708
Epoch 0, Step 236: train/loss = 0.7305287718772888, train/raw-loss = 0.5000268220901489, train/logprobs = tensor([[-0.5049, -1.4542],
        [-0.7343, -0.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07683399319648743
Epoch 0, Step 237: train/loss = 0.6184519529342651, train/raw-loss = 0.3973936140537262, train/logprobs = tensor([[-0.5814, -2.0238],
        [-0.9040, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07368611544370651
Epoch 0, Step 238: train/loss = 0.7339155673980713, train/raw-loss = 0.5382734537124634, train/logprobs = tensor([[-0.5706, -0.9788],
        [-0.7681, -0.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06521400809288025
Epoch 0, Step 239: train/loss = 0.7752339243888855, train/raw-loss = 0.5959968566894531, train/logprobs = tensor([[-0.4426, -0.4147],
        [-0.6312, -0.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05974569171667099
Epoch 0, Step 240: train/loss = 0.6826658844947815, train/raw-loss = 0.4914385676383972, train/logprobs = tensor([[-0.5713, -2.0021],
        [-0.7231, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06374242901802063
Epoch 0, Step 241: train/loss = 0.6584002375602722, train/raw-loss = 0.44900810718536377, train/logprobs = tensor([[-0.5540, -2.3244],
        [-0.7907, -1.2526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06979736685752869
Epoch 0, Step 242: train/loss = 0.7765563726425171, train/raw-loss = 0.527752697467804, train/logprobs = tensor([[-0.5850, -1.3318],
        [-0.8424, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08293454349040985
Epoch 0, Step 243: train/loss = 0.6883444786071777, train/raw-loss = 0.5154014229774475, train/logprobs = tensor([[-0.4644, -2.5286],
        [-0.5492, -1.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057647690176963806
Epoch 0, Step 244: train/loss = 0.6550536155700684, train/raw-loss = 0.4633405804634094, train/logprobs = tensor([[-0.5440, -1.8428],
        [-0.7506, -0.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06390433013439178
Epoch 0, Step 245: train/loss = 0.6806557774543762, train/raw-loss = 0.4868655204772949, train/logprobs = tensor([[-0.4113, -1.6531],
        [-0.5583, -0.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645967349410057
Epoch 0, Step 246: train/loss = 0.7742236852645874, train/raw-loss = 0.5678585171699524, train/logprobs = tensor([[-0.4961, -0.8159],
        [-0.6987, -0.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06878838688135147
Epoch 0, Step 247: train/loss = 0.6586140394210815, train/raw-loss = 0.43362441658973694, train/logprobs = tensor([[-0.4072, -2.0790],
        [-0.6385, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07499654591083527
Epoch 0, Step 248: train/loss = 0.7610337138175964, train/raw-loss = 0.5827683210372925, train/logprobs = tensor([[-0.4556, -0.3585],
        [-0.7563, -0.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059421803802251816
Epoch 0, Step 249: train/loss = 0.7285876274108887, train/raw-loss = 0.48934218287467957, train/logprobs = tensor([[-0.5391, -1.4387],
        [-0.8146, -0.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797484964132309
Epoch 0, Step 250: train/loss = 0.7587844133377075, train/raw-loss = 0.5438956022262573, train/logprobs = tensor([[-0.4944, -0.8194],
        [-0.6896, -0.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0716295912861824
Epoch 0, Step 251: train/loss = 0.7362810969352722, train/raw-loss = 0.5428009629249573, train/logprobs = tensor([[-0.4442, -1.1766],
        [-0.5476, -0.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06449336558580399
Epoch 0, Step 252: train/loss = 0.7940919399261475, train/raw-loss = 0.5107115507125854, train/logprobs = tensor([[-0.6780, -0.6652],
        [-1.0985, -0.1964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446011483669281
Epoch 0, Step 253: train/loss = 0.7212924361228943, train/raw-loss = 0.508652925491333, train/logprobs = tensor([[-0.5282, -1.2717],
        [-0.6918, -0.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07087981700897217
Epoch 0, Step 254: train/loss = 0.605766773223877, train/raw-loss = 0.36693045496940613, train/logprobs = tensor([[-0.5483, -2.5097],
        [-0.7702, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796121135354042
Epoch 0, Step 255: train/loss = 0.8038655519485474, train/raw-loss = 0.5977890491485596, train/logprobs = tensor([[-0.3791, -0.7574],
        [-0.4346, -0.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686921626329422
Epoch 0, Step 256: train/loss = 0.8060746788978577, train/raw-loss = 0.5317557454109192, train/logprobs = tensor([[-0.5516, -1.0784],
        [-0.8984, -0.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09143966436386108
Epoch 0, Step 257: train/loss = 0.7979879379272461, train/raw-loss = 0.5434784293174744, train/logprobs = tensor([[-0.4595, -1.2603],
        [-0.6387, -0.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483651280403137
Epoch 0, Step 258: train/loss = 0.7098788022994995, train/raw-loss = 0.44731295108795166, train/logprobs = tensor([[-0.4988, -2.0347],
        [-0.7061, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08752193301916122
Epoch 0, Step 259: train/loss = 0.7330557107925415, train/raw-loss = 0.43486520648002625, train/logprobs = tensor([[-0.5913, -1.4005],
        [-1.0126, -0.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939682483673096
Epoch 0, Step 260: train/loss = 0.755765438079834, train/raw-loss = 0.41397950053215027, train/logprobs = tensor([[-0.4969, -2.7128],
        [-0.7567, -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1139286458492279
Epoch 0, Step 261: train/loss = 0.7772880792617798, train/raw-loss = 0.4778613746166229, train/logprobs = tensor([[-0.5972, -1.2859],
        [-0.9145, -0.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09980890154838562
Epoch 0, Step 262: train/loss = 0.7847286462783813, train/raw-loss = 0.5049328804016113, train/logprobs = tensor([[-0.4732, -1.2038],
        [-0.7320, -0.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09326525777578354
Epoch 0, Step 263: train/loss = 0.7233994603157043, train/raw-loss = 0.39414897561073303, train/logprobs = tensor([[-0.7048, -2.8774],
        [-0.9921, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1097501590847969
Epoch 0, Step 264: train/loss = 0.7637108564376831, train/raw-loss = 0.4963558614253998, train/logprobs = tensor([[-0.5509, -1.5536],
        [-0.8415, -0.6767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911832422018051
Epoch 0, Step 265: train/loss = 0.7551550269126892, train/raw-loss = 0.4686354696750641, train/logprobs = tensor([[-0.6088, -1.1430],
        [-1.0527, -0.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550652652978897
Epoch 0, Step 266: train/loss = 0.7773466110229492, train/raw-loss = 0.5135221481323242, train/logprobs = tensor([[-0.6088, -0.7691],
        [-0.9801, -0.2867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879414826631546
Epoch 0, Step 267: train/loss = 0.7865568399429321, train/raw-loss = 0.5048931837081909, train/logprobs = tensor([[-0.5024, -1.1272],
        [-0.7463, -0.3862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09388788044452667
Epoch 0, Step 268: train/loss = 0.7669761180877686, train/raw-loss = 0.48784303665161133, train/logprobs = tensor([[-0.4463, -2.0721],
        [-0.6504, -0.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09304435551166534
Epoch 0, Step 269: train/loss = 0.7409994602203369, train/raw-loss = 0.48949456214904785, train/logprobs = tensor([[-0.4432, -1.6726],
        [-0.5702, -0.3724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383496850728989
Epoch 0, Step 270: train/loss = 0.7411741018295288, train/raw-loss = 0.44520729780197144, train/logprobs = tensor([[-0.6561, -1.4626],
        [-1.1284, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0986555889248848
Epoch 0, Step 271: train/loss = 0.7948641777038574, train/raw-loss = 0.5720031261444092, train/logprobs = tensor([[-0.4297, -0.8773],
        [-0.5037, -0.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428702712059021
Epoch 0, Step 272: train/loss = 0.6899420022964478, train/raw-loss = 0.38261646032333374, train/logprobs = tensor([[-0.4802, -1.9900],
        [-0.7535, -0.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10244183242321014
Epoch 0, Step 273: train/loss = 0.7890921831130981, train/raw-loss = 0.4887361228466034, train/logprobs = tensor([[-0.4725, -1.7072],
        [-0.5768, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10011869668960571
Epoch 0, Step 274: train/loss = 0.7058371901512146, train/raw-loss = 0.44886964559555054, train/logprobs = tensor([[-0.5668, -1.7832],
        [-0.7713, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08565583825111389
Epoch 0, Step 275: train/loss = 0.7147095203399658, train/raw-loss = 0.44576188921928406, train/logprobs = tensor([[-0.5265, -3.1247],
        [-0.8902, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08964920043945312
Epoch 0, Step 276: train/loss = 0.7628694772720337, train/raw-loss = 0.4982426166534424, train/logprobs = tensor([[-0.6207, -1.0781],
        [-1.0285, -0.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08820894360542297
Epoch 0, Step 277: train/loss = 0.7301293611526489, train/raw-loss = 0.44822031259536743, train/logprobs = tensor([[-0.4706, -2.2944],
        [-0.6198, -1.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09396970272064209
Epoch 0, Step 278: train/loss = 0.7775790691375732, train/raw-loss = 0.5203284025192261, train/logprobs = tensor([[-0.4011, -1.3021],
        [-0.5163, -0.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08575023710727692
Epoch 0, Step 279: train/loss = 0.7830957174301147, train/raw-loss = 0.5033588409423828, train/logprobs = tensor([[-0.6984, -1.1449],
        [-1.0010, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09324563294649124
Epoch 0, Step 280: train/loss = 0.7029826641082764, train/raw-loss = 0.43380239605903625, train/logprobs = tensor([[-0.5209, -1.6830],
        [-0.7586, -0.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08972674608230591
Epoch 0, Step 281: train/loss = 0.784889280796051, train/raw-loss = 0.49469006061553955, train/logprobs = tensor([[-0.5162, -1.1113],
        [-0.7228, -0.3633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09673307090997696
Epoch 0, Step 282: train/loss = 0.8162379860877991, train/raw-loss = 0.5519525408744812, train/logprobs = tensor([[-0.4986, -1.3125],
        [-0.6123, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08809514343738556
Epoch 0, Step 283: train/loss = 0.7795611023902893, train/raw-loss = 0.5044386386871338, train/logprobs = tensor([[-0.4552, -1.8839],
        [-0.6422, -0.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09170746803283691
Epoch 0, Step 284: train/loss = 0.7960883975028992, train/raw-loss = 0.5947644114494324, train/logprobs = tensor([[-0.5249, -0.2716],
        [-0.8055, -0.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06710799038410187
Epoch 0, Step 285: train/loss = 0.8457949161529541, train/raw-loss = 0.6353747248649597, train/logprobs = tensor([[-0.4582, -0.2279],
        [-0.6052, -0.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07014007866382599
Epoch 0, Step 286: train/loss = 0.8754725456237793, train/raw-loss = 0.6248123645782471, train/logprobs = tensor([[-0.4915, -0.4655],
        [-0.6510, -0.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08355340361595154
Epoch 0, Step 287: train/loss = 0.7479180097579956, train/raw-loss = 0.447345495223999, train/logprobs = tensor([[-0.6320, -1.9346],
        [-0.9638, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10019082576036453
Epoch 0, Step 288: train/loss = 0.7449174523353577, train/raw-loss = 0.5167227983474731, train/logprobs = tensor([[-0.4997, -0.9339],
        [-0.7858, -0.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07606489956378937
Epoch 0, Step 289: train/loss = 0.716641366481781, train/raw-loss = 0.4152597188949585, train/logprobs = tensor([[-0.6427, -1.6423],
        [-1.1895, -0.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10046055912971497
Epoch 0, Step 290: train/loss = 0.6843668222427368, train/raw-loss = 0.41416722536087036, train/logprobs = tensor([[-0.5061, -2.1137],
        [-0.6487, -0.5856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006654471158981
Epoch 0, Step 291: train/loss = 0.7099599242210388, train/raw-loss = 0.49585068225860596, train/logprobs = tensor([[-0.3307, -1.8497],
        [-0.4842, -0.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07136973738670349
Epoch 0, Step 292: train/loss = 0.7822986245155334, train/raw-loss = 0.5756641626358032, train/logprobs = tensor([[-0.5258, -0.3868],
        [-0.7520, -0.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0688781663775444
Epoch 0, Step 293: train/loss = 0.6620425581932068, train/raw-loss = 0.4050859212875366, train/logprobs = tensor([[-0.4877, -2.2926],
        [-0.7731, -0.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08565221726894379
Epoch 0, Step 294: train/loss = 0.8196238875389099, train/raw-loss = 0.5986367464065552, train/logprobs = tensor([[-0.4346, -0.5035],
        [-0.5790, -0.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07366238534450531
Epoch 0, Step 295: train/loss = 0.7558406591415405, train/raw-loss = 0.4819263219833374, train/logprobs = tensor([[-0.5646, -1.8532],
        [-0.9169, -0.5873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09130479395389557
Epoch 0, Step 296: train/loss = 0.7396014928817749, train/raw-loss = 0.537858247756958, train/logprobs = tensor([[-0.3850, -1.1521],
        [-0.5509, -0.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06724775582551956
Epoch 0, Step 297: train/loss = 0.7424907684326172, train/raw-loss = 0.5078392028808594, train/logprobs = tensor([[-0.4105, -1.1510],
        [-0.5801, -0.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07821719348430634
Epoch 0, Step 298: train/loss = 0.7388715147972107, train/raw-loss = 0.5084028244018555, train/logprobs = tensor([[-0.5440, -0.8211],
        [-0.8385, -0.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07682289183139801
Epoch 0, Step 299: train/loss = 0.858993649482727, train/raw-loss = 0.6296265721321106, train/logprobs = tensor([[-0.4842, -0.6219],
        [-0.6552, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07645568996667862
Epoch 0, Step 300: train/loss = 0.6672048568725586, train/raw-loss = 0.42483264207839966, train/logprobs = tensor([[-0.4404, -3.0312],
        [-0.6015, -1.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08079073578119278
Epoch 0, Step 301: train/loss = 0.6761206984519958, train/raw-loss = 0.42843976616859436, train/logprobs = tensor([[-0.5331, -2.1541],
        [-0.9226, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08256032317876816
Epoch 0, Step 302: train/loss = 0.7674254179000854, train/raw-loss = 0.5444934964179993, train/logprobs = tensor([[-0.4402, -0.6106],
        [-0.7355, -0.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07431062310934067
Epoch 0, Step 303: train/loss = 0.801200270652771, train/raw-loss = 0.5566197633743286, train/logprobs = tensor([[-0.4391, -0.7012],
        [-0.6939, -0.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152683824300766
Epoch 0, Step 304: train/loss = 0.8540645837783813, train/raw-loss = 0.5678197145462036, train/logprobs = tensor([[-0.4488, -1.2327],
        [-0.5945, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541495144367218
Epoch 0, Step 305: train/loss = 0.7154809236526489, train/raw-loss = 0.4807347059249878, train/logprobs = tensor([[-0.4320, -2.0434],
        [-0.6909, -0.7919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824872434139252
Epoch 0, Step 306: train/loss = 0.7180845737457275, train/raw-loss = 0.461333304643631, train/logprobs = tensor([[-0.5972, -1.4537],
        [-0.9622, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08558373898267746
Epoch 0, Step 307: train/loss = 0.6720080375671387, train/raw-loss = 0.41624531149864197, train/logprobs = tensor([[-0.6078, -2.9230],
        [-0.8941, -1.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852542594075203
Epoch 0, Step 308: train/loss = 0.7062788009643555, train/raw-loss = 0.456030011177063, train/logprobs = tensor([[-0.5554, -1.5833],
        [-0.8949, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08341627568006516
Epoch 0, Step 309: train/loss = 0.6887656450271606, train/raw-loss = 0.4992341995239258, train/logprobs = tensor([[-0.4633, -1.3958],
        [-0.6764, -0.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06317713856697083
Epoch 0, Step 310: train/loss = 0.7209682464599609, train/raw-loss = 0.44586777687072754, train/logprobs = tensor([[-0.5632, -1.4359],
        [-0.9266, -0.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09170014411211014
Epoch 0, Step 311: train/loss = 0.7849738597869873, train/raw-loss = 0.5527573823928833, train/logprobs = tensor([[-0.3707, -1.0299],
        [-0.5047, -0.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07740551233291626
Epoch 0, Step 312: train/loss = 0.8276847004890442, train/raw-loss = 0.6208069324493408, train/logprobs = tensor([[-0.4020, -0.3517],
        [-0.5205, -0.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06895925849676132
Epoch 0, Step 313: train/loss = 0.6820356845855713, train/raw-loss = 0.45756030082702637, train/logprobs = tensor([[-0.4533, -2.9964],
        [-0.6144, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07482513785362244
Epoch 0, Step 314: train/loss = 0.6878824234008789, train/raw-loss = 0.45016181468963623, train/logprobs = tensor([[-0.6100, -2.0622],
        [-0.8250, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07924018055200577
Epoch 0, Step 315: train/loss = 0.7385928630828857, train/raw-loss = 0.4834684729576111, train/logprobs = tensor([[-0.5029, -1.5550],
        [-0.6305, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08504146337509155
Epoch 0, Step 316: train/loss = 0.6091479063034058, train/raw-loss = 0.3473227024078369, train/logprobs = tensor([[-0.6149, -3.7888],
        [-1.0981, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08727505803108215
Epoch 0, Step 317: train/loss = 0.7032880783081055, train/raw-loss = 0.46962159872055054, train/logprobs = tensor([[-0.5750, -1.0025],
        [-1.0585, -0.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07788882404565811
Epoch 0, Step 318: train/loss = 0.7543750405311584, train/raw-loss = 0.526034951210022, train/logprobs = tensor([[-0.5545, -1.2858],
        [-0.8071, -0.4763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611337304115295
Epoch 0, Step 319: train/loss = 0.7540014982223511, train/raw-loss = 0.5122631788253784, train/logprobs = tensor([[-0.5226, -0.6736],
        [-0.9000, -0.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08057943731546402
Epoch 0, Step 320: train/loss = 0.6696333885192871, train/raw-loss = 0.4385088384151459, train/logprobs = tensor([[-0.3758, -2.1798],
        [-0.5165, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07704150676727295
Epoch 0, Step 321: train/loss = 0.7008442878723145, train/raw-loss = 0.4691661298274994, train/logprobs = tensor([[-0.4610, -1.5295],
        [-0.6614, -0.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07722605764865875
Epoch 0, Step 322: train/loss = 0.6593499779701233, train/raw-loss = 0.46311259269714355, train/logprobs = tensor([[-0.5094, -1.2760],
        [-0.8657, -0.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06541246920824051
Epoch 0, Step 323: train/loss = 0.5972946882247925, train/raw-loss = 0.3680780529975891, train/logprobs = tensor([[-0.4600, -3.4660],
        [-0.6338, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07640553265810013
Epoch 0, Step 324: train/loss = 0.6156992316246033, train/raw-loss = 0.423429936170578, train/logprobs = tensor([[-0.4549, -3.7123],
        [-0.7162, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06408978253602982
Epoch 0, Step 325: train/loss = 0.6617423295974731, train/raw-loss = 0.3991614878177643, train/logprobs = tensor([[-0.4949, -1.5855],
        [-0.8585, -0.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08752693235874176
Epoch 0, Step 326: train/loss = 0.8010944128036499, train/raw-loss = 0.5927637815475464, train/logprobs = tensor([[-0.5008, -0.2983],
        [-0.7695, -0.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06944353878498077
Epoch 0, Step 327: train/loss = 0.5921008586883545, train/raw-loss = 0.3499337434768677, train/logprobs = tensor([[-0.4985, -3.3430],
        [-0.7863, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08072236180305481
Epoch 0, Step 328: train/loss = 0.7737548351287842, train/raw-loss = 0.5592104196548462, train/logprobs = tensor([[-0.5244, -0.6368],
        [-0.7693, -0.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07151481509208679
Epoch 0, Step 329: train/loss = 0.6110743284225464, train/raw-loss = 0.36419790983200073, train/logprobs = tensor([[-0.5770, -2.4065],
        [-1.0317, -0.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229213953018188
Epoch 0, Step 330: train/loss = 0.7018455862998962, train/raw-loss = 0.4576650857925415, train/logprobs = tensor([[-0.4546, -1.6462],
        [-0.6522, -0.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139349520206451
Epoch 0, Step 331: train/loss = 0.6308272480964661, train/raw-loss = 0.4031740128993988, train/logprobs = tensor([[-0.4325, -3.1807],
        [-0.6339, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07588440924882889
Epoch 0, Step 332: train/loss = 0.6125873327255249, train/raw-loss = 0.3606104254722595, train/logprobs = tensor([[-0.4702, -2.2860],
        [-0.8691, -0.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08399230986833572
Epoch 0, Step 333: train/loss = 0.6909629106521606, train/raw-loss = 0.47737088799476624, train/logprobs = tensor([[-0.6045, -1.3181],
        [-0.8726, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07119734585285187
Epoch 0, Step 334: train/loss = 0.7153125405311584, train/raw-loss = 0.49903687834739685, train/logprobs = tensor([[-0.6704, -2.1264],
        [-1.0048, -0.5880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07209187746047974
Epoch 0, Step 335: train/loss = 0.642362117767334, train/raw-loss = 0.412943959236145, train/logprobs = tensor([[-0.5712, -2.2166],
        [-0.8694, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07647271454334259
Epoch 0, Step 336: train/loss = 0.66152024269104, train/raw-loss = 0.4231986105442047, train/logprobs = tensor([[-0.5127, -2.6423],
        [-0.7987, -0.9354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07944054901599884
Epoch 0, Step 337: train/loss = 0.635177493095398, train/raw-loss = 0.3624758720397949, train/logprobs = tensor([[-0.5048, -2.5219],
        [-0.7752, -0.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09090054035186768
Epoch 0, Step 338: train/loss = 0.6966968774795532, train/raw-loss = 0.47329461574554443, train/logprobs = tensor([[-0.4829, -1.1871],
        [-0.7748, -0.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07446739822626114
Epoch 0, Step 339: train/loss = 0.6074138879776001, train/raw-loss = 0.39579346776008606, train/logprobs = tensor([[-0.5321, -1.8006],
        [-0.8244, -0.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07054014503955841
Epoch 0, Step 340: train/loss = 0.7889280319213867, train/raw-loss = 0.6053105592727661, train/logprobs = tensor([[-0.4372, -0.8393],
        [-0.5077, -0.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06120583415031433
Epoch 0, Step 341: train/loss = 0.7114177942276001, train/raw-loss = 0.49694129824638367, train/logprobs = tensor([[-0.3862, -1.1965],
        [-0.6002, -0.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07149218022823334
Epoch 0, Step 342: train/loss = 0.5979107022285461, train/raw-loss = 0.3349376916885376, train/logprobs = tensor([[-0.5990, -3.3858],
        [-1.0291, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765767514705658
Epoch 0, Step 343: train/loss = 0.605211079120636, train/raw-loss = 0.34881484508514404, train/logprobs = tensor([[-0.5418, -3.4067],
        [-0.8231, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08546540141105652
Epoch 0, Step 344: train/loss = 0.631836473941803, train/raw-loss = 0.41011589765548706, train/logprobs = tensor([[-0.3888, -2.3584],
        [-0.7994, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390686124563217
Epoch 0, Step 345: train/loss = 0.7224265933036804, train/raw-loss = 0.497024804353714, train/logprobs = tensor([[-0.4224, -0.9358],
        [-0.7398, -0.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07513391971588135
Epoch 0, Step 346: train/loss = 0.7090009450912476, train/raw-loss = 0.48617544770240784, train/logprobs = tensor([[-0.4213, -1.3452],
        [-0.5880, -0.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07427516579627991
Epoch 0, Step 347: train/loss = 0.7252886295318604, train/raw-loss = 0.49824878573417664, train/logprobs = tensor([[-0.5191, -1.0341],
        [-0.7433, -0.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756799504160881
Epoch 0, Step 348: train/loss = 0.7127586007118225, train/raw-loss = 0.49797573685646057, train/logprobs = tensor([[-0.3689, -1.8202],
        [-0.4612, -0.5205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07159428298473358
Epoch 0, Step 349: train/loss = 0.7637078762054443, train/raw-loss = 0.5609226822853088, train/logprobs = tensor([[-0.3932, -1.1122],
        [-0.4937, -0.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06759504973888397
Epoch 0, Step 350: train/loss = 0.6369303464889526, train/raw-loss = 0.43573009967803955, train/logprobs = tensor([[-0.4641, -2.5290],
        [-0.7075, -0.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670667365193367
Epoch 0, Step 351: train/loss = 0.7419418096542358, train/raw-loss = 0.5324345231056213, train/logprobs = tensor([[-0.3867, -1.0125],
        [-0.5634, -0.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06983577460050583
Epoch 0, Step 352: train/loss = 0.5849999189376831, train/raw-loss = 0.3676844537258148, train/logprobs = tensor([[-0.4178, -2.3530],
        [-0.7505, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07243850082159042
Epoch 0, Step 353: train/loss = 0.6276304721832275, train/raw-loss = 0.416934072971344, train/logprobs = tensor([[-0.5460, -1.7546],
        [-0.9783, -0.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07023213058710098
Epoch 0, Step 354: train/loss = 0.6338703632354736, train/raw-loss = 0.4085073471069336, train/logprobs = tensor([[-0.4515, -1.9921],
        [-0.8259, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07512100785970688
Epoch 0, Step 355: train/loss = 0.7386905550956726, train/raw-loss = 0.5871782302856445, train/logprobs = tensor([[-0.4388, -0.2193],
        [-0.7234, -0.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050504107028245926
Epoch 0, Step 356: train/loss = 0.6304972171783447, train/raw-loss = 0.4333335757255554, train/logprobs = tensor([[-0.4407, -3.1702],
        [-0.6428, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06572120636701584
Epoch 0, Step 357: train/loss = 0.631270170211792, train/raw-loss = 0.4362971782684326, train/logprobs = tensor([[-0.4676, -1.7207],
        [-0.7869, -0.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06499100476503372
Epoch 0, Step 358: train/loss = 0.6357641220092773, train/raw-loss = 0.42529499530792236, train/logprobs = tensor([[-0.4942, -2.3600],
        [-0.7237, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07015638798475266
Epoch 0, Step 359: train/loss = 0.610213041305542, train/raw-loss = 0.41945135593414307, train/logprobs = tensor([[-0.3852, -3.1144],
        [-0.5954, -1.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0635872408747673
Epoch 0, Step 360: train/loss = 0.6285479068756104, train/raw-loss = 0.4527857005596161, train/logprobs = tensor([[-0.5019, -1.4939],
        [-0.8013, -0.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05858742073178291
Epoch 0, Step 361: train/loss = 0.6105490326881409, train/raw-loss = 0.4354231357574463, train/logprobs = tensor([[-0.4401, -2.2136],
        [-0.6541, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05837531015276909
Epoch 0, Step 362: train/loss = 0.6715102195739746, train/raw-loss = 0.526832640171051, train/logprobs = tensor([[-0.2843, -0.8235],
        [-0.4838, -0.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048225872218608856
Epoch 0, Step 363: train/loss = 0.6933684349060059, train/raw-loss = 0.5118533968925476, train/logprobs = tensor([[-0.5589, -1.3531],
        [-0.9171, -0.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06050501763820648
Epoch 0, Step 364: train/loss = 0.6297697424888611, train/raw-loss = 0.45882782340049744, train/logprobs = tensor([[-0.4637, -2.0411],
        [-0.6913, -0.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05698062852025032
Epoch 0, Step 365: train/loss = 0.7303258776664734, train/raw-loss = 0.5468260049819946, train/logprobs = tensor([[-0.5576, -0.5068],
        [-0.8920, -0.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061166614294052124
Epoch 0, Step 366: train/loss = 0.6089082956314087, train/raw-loss = 0.41223546862602234, train/logprobs = tensor([[-0.4556, -2.2016],
        [-0.7941, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06555760651826859
Epoch 0, Step 367: train/loss = 0.5826871395111084, train/raw-loss = 0.4037435054779053, train/logprobs = tensor([[-0.3416, -2.1598],
        [-0.5726, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05964788794517517
Epoch 0, Step 368: train/loss = 0.6232904195785522, train/raw-loss = 0.44417762756347656, train/logprobs = tensor([[-0.4131, -1.9921],
        [-0.7125, -0.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059704266488552094
Epoch 0, Step 369: train/loss = 0.6741093397140503, train/raw-loss = 0.5062023401260376, train/logprobs = tensor([[-0.4841, -1.4916],
        [-0.6788, -0.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0559689998626709
Epoch 0, Step 370: train/loss = 0.6642493605613708, train/raw-loss = 0.4424569606781006, train/logprobs = tensor([[-0.5479, -2.3810],
        [-0.9953, -0.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07393079996109009
Epoch 0, Step 371: train/loss = 0.5956563949584961, train/raw-loss = 0.3881121277809143, train/logprobs = tensor([[-0.5896, -1.8214],
        [-1.0649, -0.4829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.069181427359581
Epoch 0, Step 372: train/loss = 0.7512376308441162, train/raw-loss = 0.5842673778533936, train/logprobs = tensor([[-0.4326, -0.6844],
        [-0.5746, -0.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05565675348043442
Epoch 0, Step 373: train/loss = 0.7210610508918762, train/raw-loss = 0.5429184436798096, train/logprobs = tensor([[-0.4275, -0.6773],
        [-0.7512, -0.3078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059380851686000824
Epoch 0, Step 374: train/loss = 0.7722361087799072, train/raw-loss = 0.6279198527336121, train/logprobs = tensor([[-0.5509, -0.3530],
        [-0.7681, -0.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048105429857969284
Epoch 0, Step 375: train/loss = 0.6962625980377197, train/raw-loss = 0.5096194744110107, train/logprobs = tensor([[-0.6202, -0.8871],
        [-0.9701, -0.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062214381992816925
Epoch 0, Step 376: train/loss = 0.6302540898323059, train/raw-loss = 0.4846169352531433, train/logprobs = tensor([[-0.4106, -1.5647],
        [-0.6327, -0.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0485457107424736
Epoch 0, Step 377: train/loss = 0.7520920634269714, train/raw-loss = 0.5929332375526428, train/logprobs = tensor([[-0.5277, -0.2644],
        [-0.8535, -0.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05305293947458267
Epoch 0, Step 378: train/loss = 0.6602015495300293, train/raw-loss = 0.4775432348251343, train/logprobs = tensor([[-0.3750, -1.6027],
        [-0.5781, -0.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060886088758707047
Epoch 0, Step 379: train/loss = 0.7279363870620728, train/raw-loss = 0.5672703981399536, train/logprobs = tensor([[-0.4854, -0.7764],
        [-0.6174, -0.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05355532094836235
Epoch 0, Step 380: train/loss = 0.6507394313812256, train/raw-loss = 0.4686865210533142, train/logprobs = tensor([[-0.6413, -1.3732],
        [-1.0001, -0.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06068429723381996
Epoch 0, Step 381: train/loss = 0.6871219277381897, train/raw-loss = 0.5285053849220276, train/logprobs = tensor([[-0.4106, -1.0819],
        [-0.5726, -0.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05287216976284981
Epoch 0, Step 382: train/loss = 0.6940726637840271, train/raw-loss = 0.5057165026664734, train/logprobs = tensor([[-0.4831, -0.7827],
        [-0.9053, -0.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278539448976517
Epoch 0, Step 383: train/loss = 0.7512807846069336, train/raw-loss = 0.6047255992889404, train/logprobs = tensor([[-0.3655, -0.3640],
        [-0.5493, -0.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04885173216462135
Epoch 0, Step 384: train/loss = 0.608959972858429, train/raw-loss = 0.43510985374450684, train/logprobs = tensor([[-0.5026, -2.1455],
        [-0.8536, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057950038462877274
Epoch 0, Step 385: train/loss = 0.5909165740013123, train/raw-loss = 0.4014667272567749, train/logprobs = tensor([[-0.4504, -3.1617],
        [-0.8880, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06314994394779205
Epoch 0, Step 386: train/loss = 0.6271927356719971, train/raw-loss = 0.42528241872787476, train/logprobs = tensor([[-0.4824, -1.5726],
        [-0.9011, -0.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06730343401432037
Epoch 0, Step 387: train/loss = 0.6032997369766235, train/raw-loss = 0.44402727484703064, train/logprobs = tensor([[-0.4618, -3.6090],
        [-0.6064, -0.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05309082567691803
Epoch 0, Step 388: train/loss = 0.6258580684661865, train/raw-loss = 0.4616553783416748, train/logprobs = tensor([[-0.3758, -1.7014],
        [-0.5938, -0.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0547342523932457
Epoch 0, Step 389: train/loss = 0.5623514652252197, train/raw-loss = 0.3751974105834961, train/logprobs = tensor([[-0.4804, -1.9329],
        [-0.8156, -0.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06238469108939171
Epoch 0, Step 390: train/loss = 0.7143604755401611, train/raw-loss = 0.5612751841545105, train/logprobs = tensor([[-0.3205, -0.7200],
        [-0.4748, -0.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051028452813625336
Epoch 0, Step 391: train/loss = 0.5125961899757385, train/raw-loss = 0.3085893988609314, train/logprobs = tensor([[-0.4956, -4.5305],
        [-0.7658, -1.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06800225377082825
Epoch 0, Step 392: train/loss = 0.5818544626235962, train/raw-loss = 0.37514573335647583, train/logprobs = tensor([[-0.4670, -2.5545],
        [-0.9766, -0.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06890292465686798
Epoch 0, Step 393: train/loss = 0.62357097864151, train/raw-loss = 0.43203622102737427, train/logprobs = tensor([[-0.4426, -2.2209],
        [-0.7395, -0.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06384493410587311
Epoch 0, Step 394: train/loss = 0.6007362008094788, train/raw-loss = 0.4021925926208496, train/logprobs = tensor([[-0.3768, -3.1274],
        [-0.5195, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06618119776248932
Epoch 0, Step 395: train/loss = 0.6997554302215576, train/raw-loss = 0.5156440138816833, train/logprobs = tensor([[-0.4712, -0.5855],
        [-0.8339, -0.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06137046962976456
Epoch 0, Step 396: train/loss = 0.6447983980178833, train/raw-loss = 0.47004061937332153, train/logprobs = tensor([[-0.4626, -1.4146],
        [-0.6621, -0.5015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058252591639757156
Epoch 0, Step 397: train/loss = 0.5681435465812683, train/raw-loss = 0.3858621120452881, train/logprobs = tensor([[-0.5616, -3.1621],
        [-1.0950, -0.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06076046824455261
Epoch 0, Step 398: train/loss = 0.6337597370147705, train/raw-loss = 0.4338475465774536, train/logprobs = tensor([[-0.5047, -2.1596],
        [-0.7281, -0.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06663741171360016
Epoch 0, Step 399: train/loss = 0.6025349497795105, train/raw-loss = 0.4290499687194824, train/logprobs = tensor([[-0.4686, -2.2450],
        [-0.7221, -0.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05782831460237503
Epoch 0, Step 400: train/loss = 0.6205015778541565, train/raw-loss = 0.4238084554672241, train/logprobs = tensor([[-0.5633, -1.5180],
        [-0.9836, -0.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06556438654661179
Epoch 0, Step 401: train/loss = 0.5308195948600769, train/raw-loss = 0.33247584104537964, train/logprobs = tensor([[-0.5073, -3.4876],
        [-0.9541, -1.2461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06611458212137222
Epoch 0, Step 402: train/loss = 0.6471399068832397, train/raw-loss = 0.4688488245010376, train/logprobs = tensor([[-0.4134, -1.8875],
        [-0.5874, -0.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05943036079406738
Epoch 0, Step 403: train/loss = 0.6914899349212646, train/raw-loss = 0.5288983583450317, train/logprobs = tensor([[-0.4881, -1.3599],
        [-0.6897, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05419718846678734
Epoch 0, Step 404: train/loss = 0.7273350954055786, train/raw-loss = 0.5789886713027954, train/logprobs = tensor([[-0.3642, -0.5625],
        [-0.5149, -0.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04944879189133644
Epoch 0, Step 405: train/loss = 0.667933464050293, train/raw-loss = 0.47527575492858887, train/logprobs = tensor([[-0.4319, -1.4650],
        [-0.6534, -0.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06421923637390137
Epoch 0, Step 406: train/loss = 0.7246441841125488, train/raw-loss = 0.5658342838287354, train/logprobs = tensor([[-0.4540, -0.6711],
        [-0.7363, -0.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05293663963675499
Epoch 0, Step 407: train/loss = 0.48293688893318176, train/raw-loss = 0.3101952373981476, train/logprobs = tensor([[-0.4489, -4.3563],
        [-0.7495, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057580552995204926
Epoch 0, Step 408: train/loss = 0.692290186882019, train/raw-loss = 0.5078017711639404, train/logprobs = tensor([[-0.4400, -1.0492],
        [-0.6825, -0.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061496153473854065
Epoch 0, Step 409: train/loss = 0.7474318742752075, train/raw-loss = 0.56673663854599, train/logprobs = tensor([[-0.5205, -0.4627],
        [-0.8796, -0.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06023174151778221
Epoch 0, Step 410: train/loss = 0.5397617816925049, train/raw-loss = 0.34935620427131653, train/logprobs = tensor([[-0.4911, -2.2280],
        [-0.9390, -0.4442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06346852332353592
Epoch 0, Step 411: train/loss = 0.7480401992797852, train/raw-loss = 0.5973062515258789, train/logprobs = tensor([[-0.3837, -0.6159],
        [-0.4981, -0.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05024464428424835
Epoch 0, Step 412: train/loss = 0.7112969756126404, train/raw-loss = 0.49577945470809937, train/logprobs = tensor([[-0.6615, -0.6406],
        [-1.1749, -0.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07183918356895447
Epoch 0, Step 413: train/loss = 0.6232887506484985, train/raw-loss = 0.43856799602508545, train/logprobs = tensor([[-0.4174, -1.5138],
        [-0.7447, -0.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0615735799074173
Epoch 0, Step 414: train/loss = 0.6910471320152283, train/raw-loss = 0.5536359548568726, train/logprobs = tensor([[-0.4514, -0.8110],
        [-0.6932, -0.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04580371081829071
Epoch 0, Step 415: train/loss = 0.6778646111488342, train/raw-loss = 0.502257227897644, train/logprobs = tensor([[-0.5612, -1.2154],
        [-0.8882, -0.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05853579565882683
Epoch 0, Step 416: train/loss = 0.5800779461860657, train/raw-loss = 0.41478630900382996, train/logprobs = tensor([[-0.4364, -3.3235],
        [-0.6364, -1.2381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05509721115231514
Epoch 0, Step 417: train/loss = 0.588677167892456, train/raw-loss = 0.37271955609321594, train/logprobs = tensor([[-0.6362, -2.1157],
        [-1.0366, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719858705997467
Epoch 0, Step 418: train/loss = 0.633906364440918, train/raw-loss = 0.46982505917549133, train/logprobs = tensor([[-0.4934, -1.3944],
        [-0.7543, -0.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0546937920153141
Epoch 0, Step 419: train/loss = 0.621512770652771, train/raw-loss = 0.4578876495361328, train/logprobs = tensor([[-0.4903, -1.5928],
        [-0.7754, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05454172194004059
Epoch 0, Step 420: train/loss = 0.539374589920044, train/raw-loss = 0.33233141899108887, train/logprobs = tensor([[-0.6206, -1.7898],
        [-1.2988, -0.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06901438534259796
Epoch 0, Step 421: train/loss = 0.7484409809112549, train/raw-loss = 0.6184805631637573, train/logprobs = tensor([[-0.3501, -0.5326],
        [-0.4749, -0.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04332014173269272
Epoch 0, Step 422: train/loss = 0.5643277168273926, train/raw-loss = 0.35664331912994385, train/logprobs = tensor([[-0.5962, -3.1946],
        [-0.9866, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06922812759876251
Epoch 0, Step 423: train/loss = 0.6388698816299438, train/raw-loss = 0.43252283334732056, train/logprobs = tensor([[-0.5441, -1.1729],
        [-1.0310, -0.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06878234446048737
Epoch 0, Step 424: train/loss = 0.600085973739624, train/raw-loss = 0.4751961827278137, train/logprobs = tensor([[-0.4965, -2.6014],
        [-0.7619, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04162994772195816
Epoch 0, Step 425: train/loss = 0.6854795217514038, train/raw-loss = 0.5396236777305603, train/logprobs = tensor([[-0.4579, -1.9529],
        [-0.5963, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0486186221241951
Epoch 0, Step 426: train/loss = 0.7387096285820007, train/raw-loss = 0.5578749775886536, train/logprobs = tensor([[-0.3870, -0.8158],
        [-0.5392, -0.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06027822196483612
Epoch 0, Step 427: train/loss = 0.6285604238510132, train/raw-loss = 0.43738657236099243, train/logprobs = tensor([[-0.5195, -1.7349],
        [-0.9086, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06372462213039398
Epoch 0, Step 428: train/loss = 0.5892779231071472, train/raw-loss = 0.4153424799442291, train/logprobs = tensor([[-0.4019, -1.8373],
        [-0.7860, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057978495955467224
Epoch 0, Step 429: train/loss = 0.5714612007141113, train/raw-loss = 0.3713825047016144, train/logprobs = tensor([[-0.5450, -1.9934],
        [-0.9049, -0.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06669291108846664
Epoch 0, Step 430: train/loss = 0.6276321411132812, train/raw-loss = 0.48824238777160645, train/logprobs = tensor([[-0.4151, -1.3833],
        [-0.5842, -0.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0464632622897625
Epoch 0, Step 431: train/loss = 0.6327279210090637, train/raw-loss = 0.447217732667923, train/logprobs = tensor([[-0.3781, -1.6292],
        [-0.6708, -0.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06183673441410065
Epoch 0, Step 432: train/loss = 0.6944342851638794, train/raw-loss = 0.5239937901496887, train/logprobs = tensor([[-0.4316, -1.0321],
        [-0.6564, -0.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056813497096300125
Epoch 0, Step 433: train/loss = 0.6778737306594849, train/raw-loss = 0.5088458061218262, train/logprobs = tensor([[-0.5848, -1.1621],
        [-0.9089, -0.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05634263902902603
Epoch 0, Step 434: train/loss = 0.6957405209541321, train/raw-loss = 0.5359731912612915, train/logprobs = tensor([[-0.4603, -1.0776],
        [-0.7656, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05325581133365631
Epoch 0, Step 435: train/loss = 0.699038028717041, train/raw-loss = 0.5373322367668152, train/logprobs = tensor([[-0.3701, -0.6411],
        [-0.6400, -0.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05390193313360214
Epoch 0, Step 436: train/loss = 0.7009544372558594, train/raw-loss = 0.5153127312660217, train/logprobs = tensor([[-0.4650, -0.7827],
        [-0.8058, -0.2315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06188057363033295
Epoch 0, Step 437: train/loss = 0.6604202389717102, train/raw-loss = 0.530938446521759, train/logprobs = tensor([[-0.3515, -1.4591],
        [-0.4922, -0.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04316060245037079
Epoch 0, Step 438: train/loss = 0.6100490093231201, train/raw-loss = 0.44398146867752075, train/logprobs = tensor([[-0.4746, -1.5556],
        [-0.8020, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055355846881866455
Epoch 0, Step 439: train/loss = 0.6436105370521545, train/raw-loss = 0.44948676228523254, train/logprobs = tensor([[-0.5058, -1.4723],
        [-0.9160, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0647079199552536
Epoch 0, Step 440: train/loss = 0.5603082180023193, train/raw-loss = 0.36142948269844055, train/logprobs = tensor([[-0.4956, -2.8568],
        [-0.8229, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0662929117679596
Epoch 0, Step 441: train/loss = 0.5398244857788086, train/raw-loss = 0.3373032212257385, train/logprobs = tensor([[-0.5310, -2.5809],
        [-0.9559, -0.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750708073377609
Epoch 0, Step 442: train/loss = 0.6280187368392944, train/raw-loss = 0.4200849235057831, train/logprobs = tensor([[-0.5155, -1.3217],
        [-0.9867, -0.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06931126117706299
Epoch 0, Step 443: train/loss = 0.49277257919311523, train/raw-loss = 0.29033851623535156, train/logprobs = tensor([[-0.6293, -3.3365],
        [-1.2203, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06747803092002869
Epoch 0, Step 444: train/loss = 0.4235694110393524, train/raw-loss = 0.2297363579273224, train/logprobs = tensor([[-0.5178, -5.1226],
        [-1.0617, -1.1008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06461101770401001
Epoch 0, Step 445: train/loss = 0.6329700946807861, train/raw-loss = 0.4585125148296356, train/logprobs = tensor([[-0.4506, -1.3194],
        [-0.7346, -0.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05815251171588898
Epoch 0, Step 446: train/loss = 0.6432474851608276, train/raw-loss = 0.46526792645454407, train/logprobs = tensor([[-0.3882, -1.3674],
        [-0.5994, -0.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059326522052288055
Epoch 0, Step 447: train/loss = 0.6069992780685425, train/raw-loss = 0.43232986330986023, train/logprobs = tensor([[-0.3235, -1.7404],
        [-0.4780, -0.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058223139494657516
Epoch 0, Step 448: train/loss = 0.6163328886032104, train/raw-loss = 0.4193984270095825, train/logprobs = tensor([[-0.5158, -1.5041],
        [-1.0166, -0.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06564482301473618
Epoch 0, Step 449: train/loss = 0.6079565286636353, train/raw-loss = 0.41520917415618896, train/logprobs = tensor([[-0.4811, -1.3239],
        [-1.0011, -0.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06424912065267563
Epoch 0, Step 450: train/loss = 0.5335339307785034, train/raw-loss = 0.3297020494937897, train/logprobs = tensor([[-0.5240, -3.0405],
        [-1.0134, -0.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06794395297765732
Epoch 0, Step 451: train/loss = 0.6015238165855408, train/raw-loss = 0.43844109773635864, train/logprobs = tensor([[-0.3881, -1.6402],
        [-0.6207, -0.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054360903799533844
Epoch 0, Step 452: train/loss = 0.5553069710731506, train/raw-loss = 0.3900582492351532, train/logprobs = tensor([[-0.4942, -3.2257],
        [-0.8254, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05508291348814964
Epoch 0, Step 453: train/loss = 0.5822750329971313, train/raw-loss = 0.3818396031856537, train/logprobs = tensor([[-0.7988, -1.8959],
        [-1.4091, -0.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06681181490421295
Epoch 0, Step 454: train/loss = 0.6493344902992249, train/raw-loss = 0.4470909833908081, train/logprobs = tensor([[-0.5828, -1.4289],
        [-0.9801, -0.4015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06741451472043991
Epoch 0, Step 455: train/loss = 0.6202831268310547, train/raw-loss = 0.4777339994907379, train/logprobs = tensor([[-0.4918, -1.2118],
        [-0.8250, -0.2945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04751637950539589
Epoch 0, Step 456: train/loss = 0.610579788684845, train/raw-loss = 0.4584459066390991, train/logprobs = tensor([[-0.5029, -1.0775],
        [-0.8467, -0.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05071130767464638
Epoch 0, Step 457: train/loss = 0.6328997015953064, train/raw-loss = 0.4593338966369629, train/logprobs = tensor([[-0.5724, -1.3320],
        [-0.9512, -0.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05785524845123291
Epoch 0, Step 458: train/loss = 0.5944528579711914, train/raw-loss = 0.4085296392440796, train/logprobs = tensor([[-0.4814, -3.0798],
        [-0.7352, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0619744174182415
Epoch 0, Step 459: train/loss = 0.6992325782775879, train/raw-loss = 0.5403507947921753, train/logprobs = tensor([[-0.4855, -0.8388],
        [-0.7068, -0.2885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0529605969786644
Epoch 0, Step 460: train/loss = 0.5169485807418823, train/raw-loss = 0.32096901535987854, train/logprobs = tensor([[-0.4935, -4.0263],
        [-0.8475, -1.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06532653421163559
Epoch 0, Step 461: train/loss = 0.6309205293655396, train/raw-loss = 0.4858575463294983, train/logprobs = tensor([[-0.3625, -1.2779],
        [-0.5269, -0.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04835432395339012
Epoch 0, Step 462: train/loss = 0.608832836151123, train/raw-loss = 0.412665456533432, train/logprobs = tensor([[-0.4600, -2.6079],
        [-0.7224, -0.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06538912653923035
Epoch 0, Step 463: train/loss = 0.6172663569450378, train/raw-loss = 0.43836742639541626, train/logprobs = tensor([[-0.6400, -1.5280],
        [-1.0657, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05963297188282013
Epoch 0, Step 464: train/loss = 0.740719735622406, train/raw-loss = 0.5947176814079285, train/logprobs = tensor([[-0.4802, -0.3269],
        [-0.7136, -0.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048667360097169876
Epoch 0, Step 465: train/loss = 0.5769786834716797, train/raw-loss = 0.4026740789413452, train/logprobs = tensor([[-0.4702, -1.7359],
        [-0.9983, -0.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058101534843444824
Epoch 0, Step 466: train/loss = 0.587124764919281, train/raw-loss = 0.4027700424194336, train/logprobs = tensor([[-0.5560, -2.1441],
        [-1.0242, -0.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06145157665014267
Epoch 0, Step 467: train/loss = 0.5931441783905029, train/raw-loss = 0.42730748653411865, train/logprobs = tensor([[-0.5221, -1.7611],
        [-0.9768, -0.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055278897285461426
Epoch 0, Step 468: train/loss = 0.6208157539367676, train/raw-loss = 0.4790782332420349, train/logprobs = tensor([[-0.3582, -1.3222],
        [-0.5089, -0.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047245848923921585
Epoch 0, Step 469: train/loss = 0.5569851398468018, train/raw-loss = 0.37107712030410767, train/logprobs = tensor([[-0.5056, -3.5260],
        [-0.8288, -0.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0619693323969841
Epoch 0, Step 470: train/loss = 0.5054944157600403, train/raw-loss = 0.3205820918083191, train/logprobs = tensor([[-0.5367, -3.0603],
        [-0.9121, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06163744628429413
Epoch 0, Step 471: train/loss = 0.5239181518554688, train/raw-loss = 0.3127343952655792, train/logprobs = tensor([[-0.6142, -2.5564],
        [-1.2813, -0.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07039457559585571
Epoch 0, Step 472: train/loss = 0.5800870060920715, train/raw-loss = 0.40464892983436584, train/logprobs = tensor([[-0.5994, -2.2864],
        [-0.9966, -0.3601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05847935751080513
Epoch 0, Step 473: train/loss = 0.6337999105453491, train/raw-loss = 0.4639025032520294, train/logprobs = tensor([[-0.3331, -1.9309],
        [-0.4652, -0.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05663247033953667
Epoch 0, Step 474: train/loss = 0.6539223194122314, train/raw-loss = 0.46690264344215393, train/logprobs = tensor([[-0.5963, -1.0981],
        [-1.1912, -0.5930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0623399056494236
Epoch 0, Step 475: train/loss = 0.7009943127632141, train/raw-loss = 0.5749679207801819, train/logprobs = tensor([[-0.3920, -0.3861],
        [-0.6578, -0.1313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04200879484415054
Epoch 0, Step 476: train/loss = 0.6992220878601074, train/raw-loss = 0.5310583114624023, train/logprobs = tensor([[-0.4488, -1.0597],
        [-0.6911, -0.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05605459213256836
Epoch 0, Step 477: train/loss = 0.5250416994094849, train/raw-loss = 0.32578030228614807, train/logprobs = tensor([[-0.4717, -4.7280],
        [-0.7940, -1.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06642046570777893
Epoch 0, Step 478: train/loss = 0.6705504655838013, train/raw-loss = 0.5360135436058044, train/logprobs = tensor([[-0.4330, -0.9977],
        [-0.6509, -0.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04484562203288078
Epoch 0, Step 479: train/loss = 0.5938686728477478, train/raw-loss = 0.38967186212539673, train/logprobs = tensor([[-0.5539, -1.5069],
        [-1.0313, -0.3456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06806560605764389
Epoch 0, Step 480: train/loss = 0.6303224563598633, train/raw-loss = 0.4324270486831665, train/logprobs = tensor([[-0.6034, -1.9878],
        [-0.8613, -0.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06596514582633972
Epoch 0, Step 481: train/loss = 0.715884804725647, train/raw-loss = 0.5624338388442993, train/logprobs = tensor([[-0.4853, -0.5841],
        [-0.7310, -0.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051150307059288025
Epoch 0, Step 482: train/loss = 0.6241190433502197, train/raw-loss = 0.45408475399017334, train/logprobs = tensor([[-0.4515, -2.0061],
        [-0.7065, -0.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056678105145692825
Epoch 0, Step 483: train/loss = 0.639046847820282, train/raw-loss = 0.48698002099990845, train/logprobs = tensor([[-0.3349, -1.5657],
        [-0.5525, -0.2313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05068895220756531
Epoch 0, Step 484: train/loss = 0.5609705448150635, train/raw-loss = 0.3443101942539215, train/logprobs = tensor([[-0.4929, -1.9690],
        [-1.0255, -0.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07222012430429459
Epoch 0, Step 485: train/loss = 0.5464591979980469, train/raw-loss = 0.38070741295814514, train/logprobs = tensor([[-0.5632, -3.7111],
        [-1.0199, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05525059252977371
Epoch 0, Step 486: train/loss = 0.636428713798523, train/raw-loss = 0.4639317989349365, train/logprobs = tensor([[-0.4071, -1.7160],
        [-0.7037, -0.4282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05749896541237831
Epoch 0, Step 487: train/loss = 0.6354568600654602, train/raw-loss = 0.4541584253311157, train/logprobs = tensor([[-0.5335, -1.5920],
        [-0.9270, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06043281406164169
Epoch 0, Step 488: train/loss = 0.688177764415741, train/raw-loss = 0.5066643953323364, train/logprobs = tensor([[-0.3694, -1.4704],
        [-0.6313, -0.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06050444021821022
Epoch 0, Step 489: train/loss = 0.5212258696556091, train/raw-loss = 0.33842599391937256, train/logprobs = tensor([[-0.5096, -4.2278],
        [-0.8244, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06093328818678856
Epoch 0, Step 490: train/loss = 0.5964875221252441, train/raw-loss = 0.375418484210968, train/logprobs = tensor([[-0.4580, -2.9917],
        [-0.7794, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07368966937065125
Epoch 0, Step 491: train/loss = 0.6314142346382141, train/raw-loss = 0.45963287353515625, train/logprobs = tensor([[-0.3697, -1.7725],
        [-0.5043, -0.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05726044252514839
Epoch 0, Step 492: train/loss = 0.5613445043563843, train/raw-loss = 0.39536693692207336, train/logprobs = tensor([[-0.6324, -2.3399],
        [-1.1824, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055325862020254135
Epoch 0, Step 493: train/loss = 0.6777796149253845, train/raw-loss = 0.5111743211746216, train/logprobs = tensor([[-0.4721, -1.1807],
        [-0.7149, -0.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05553510785102844
Epoch 0, Step 494: train/loss = 0.7596069574356079, train/raw-loss = 0.6089063882827759, train/logprobs = tensor([[-0.5612, -0.5126],
        [-0.8096, -0.4018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050233516842126846
Epoch 0, Step 495: train/loss = 0.5636376142501831, train/raw-loss = 0.36976197361946106, train/logprobs = tensor([[-0.5858, -2.3936],
        [-1.0978, -0.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06462518870830536
Epoch 0, Step 496: train/loss = 0.5944888591766357, train/raw-loss = 0.4071844816207886, train/logprobs = tensor([[-0.4777, -3.0865],
        [-0.6606, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06243479624390602
Epoch 0, Step 497: train/loss = 0.7436072826385498, train/raw-loss = 0.5568177103996277, train/logprobs = tensor([[-0.3984, -0.4828],
        [-0.6958, -0.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062263187021017075
Epoch 0, Step 498: train/loss = 0.6363120675086975, train/raw-loss = 0.45503371953964233, train/logprobs = tensor([[-0.4467, -1.4350],
        [-0.6809, -0.3259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06042613461613655
Epoch 0, Step 499: train/loss = 0.6323035955429077, train/raw-loss = 0.4824945628643036, train/logprobs = tensor([[-0.4421, -3.0064],
        [-0.7246, -0.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049936339259147644
Epoch 0, Step 500: train/loss = 0.6025112867355347, train/raw-loss = 0.42539089918136597, train/logprobs = tensor([[-0.5373, -1.7380],
        [-0.8444, -0.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0590401217341423
Epoch 0, Step 501: train/loss = 0.5859131217002869, train/raw-loss = 0.4231110215187073, train/logprobs = tensor([[-0.4484, -3.2929],
        [-0.7950, -0.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05426735803484917
Epoch 0, Step 502: train/loss = 0.5732699632644653, train/raw-loss = 0.38934797048568726, train/logprobs = tensor([[-0.4453, -2.5653],
        [-0.7487, -0.4352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061307333409786224
Epoch 0, Step 503: train/loss = 0.6098822951316833, train/raw-loss = 0.4145638644695282, train/logprobs = tensor([[-0.4965, -3.4727],
        [-0.6982, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06510613858699799
Epoch 0, Step 504: train/loss = 0.5822420716285706, train/raw-loss = 0.3677617311477661, train/logprobs = tensor([[-0.5048, -1.9534],
        [-0.9697, -0.4133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07149344682693481
Epoch 0, Step 505: train/loss = 0.5652218461036682, train/raw-loss = 0.37615758180618286, train/logprobs = tensor([[-0.4137, -2.5151],
        [-0.6797, -0.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06302141398191452
Epoch 0, Step 506: train/loss = 0.5546220541000366, train/raw-loss = 0.31975501775741577, train/logprobs = tensor([[-0.5487, -3.3189],
        [-0.9551, -0.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07828903198242188
Epoch 0, Step 507: train/loss = 0.6611953377723694, train/raw-loss = 0.5183762311935425, train/logprobs = tensor([[-0.3017, -1.3214],
        [-0.4241, -0.3593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04760635271668434
Epoch 0, Step 508: train/loss = 0.5625864863395691, train/raw-loss = 0.3896450102329254, train/logprobs = tensor([[-0.5118, -3.4128],
        [-0.8031, -0.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05764715373516083
Epoch 0, Step 509: train/loss = 0.6137682795524597, train/raw-loss = 0.434475839138031, train/logprobs = tensor([[-0.4365, -1.8543],
        [-0.6630, -0.6395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05976415053009987
Epoch 0, Step 510: train/loss = 0.6141679286956787, train/raw-loss = 0.4725489020347595, train/logprobs = tensor([[-0.4883, -1.4993],
        [-0.7174, -0.5159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047206323593854904
Epoch 0, Step 511: train/loss = 0.6864218711853027, train/raw-loss = 0.5065882802009583, train/logprobs = tensor([[-0.4504, -0.9005],
        [-0.7543, -0.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05994454026222229
Epoch 0, Step 512: train/loss = 0.6159076690673828, train/raw-loss = 0.4319508671760559, train/logprobs = tensor([[-0.4658, -1.6541],
        [-0.7488, -0.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06131894141435623
Epoch 0, Step 513: train/loss = 0.6163750886917114, train/raw-loss = 0.41585126519203186, train/logprobs = tensor([[-0.4810, -3.3202],
        [-0.7362, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.066841259598732
Epoch 0, Step 514: train/loss = 0.7169635891914368, train/raw-loss = 0.5424257516860962, train/logprobs = tensor([[-0.4450, -0.8912],
        [-0.7441, -0.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05817929282784462
Epoch 0, Step 515: train/loss = 0.5454040765762329, train/raw-loss = 0.329444944858551, train/logprobs = tensor([[-0.4748, -2.8949],
        [-0.8597, -0.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719863548874855
Epoch 0, Step 516: train/loss = 0.5821825265884399, train/raw-loss = 0.40606316924095154, train/logprobs = tensor([[-0.4756, -3.0383],
        [-0.8569, -0.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058706432580947876
Epoch 0, Step 517: train/loss = 0.5342607498168945, train/raw-loss = 0.3025631904602051, train/logprobs = tensor([[-0.5505, -4.0373],
        [-1.1828, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07723251730203629
Epoch 0, Step 518: train/loss = 0.6778340339660645, train/raw-loss = 0.52973473072052, train/logprobs = tensor([[-0.4422, -1.4211],
        [-0.5931, -0.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049366436898708344
Epoch 0, Step 519: train/loss = 0.549004316329956, train/raw-loss = 0.3705982565879822, train/logprobs = tensor([[-0.4522, -1.7889],
        [-0.8077, -0.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05946868658065796
Epoch 0, Step 520: train/loss = 0.5956354141235352, train/raw-loss = 0.3752358853816986, train/logprobs = tensor([[-0.3682, -2.1465],
        [-0.7260, -0.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07346650213003159
Epoch 0, Step 521: train/loss = 0.5686458945274353, train/raw-loss = 0.3392595946788788, train/logprobs = tensor([[-0.5735, -2.8556],
        [-0.9980, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07646209001541138
Epoch 0, Step 522: train/loss = 0.5281068682670593, train/raw-loss = 0.32613667845726013, train/logprobs = tensor([[-0.6376, -3.2381],
        [-1.0590, -0.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06732339411973953
Epoch 0, Step 523: train/loss = 0.611531138420105, train/raw-loss = 0.4432951807975769, train/logprobs = tensor([[-0.4305, -1.8309],
        [-0.6992, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05607863515615463
Epoch 0, Step 524: train/loss = 0.5665985345840454, train/raw-loss = 0.3930661380290985, train/logprobs = tensor([[-0.4739, -3.3237],
        [-0.7929, -0.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0578441321849823
Epoch 0, Step 525: train/loss = 0.5325490832328796, train/raw-loss = 0.30094802379608154, train/logprobs = tensor([[-0.5465, -3.4732],
        [-1.0840, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07720035314559937
Epoch 0, Step 526: train/loss = 0.64216148853302, train/raw-loss = 0.4799115061759949, train/logprobs = tensor([[-0.4045, -1.1852],
        [-0.6626, -0.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05408332869410515
Epoch 0, Step 527: train/loss = 0.542334794998169, train/raw-loss = 0.33391761779785156, train/logprobs = tensor([[-0.5451, -3.1030],
        [-0.9470, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06947239488363266
Epoch 0, Step 528: train/loss = 0.5932419896125793, train/raw-loss = 0.4254220724105835, train/logprobs = tensor([[-0.4826, -2.0219],
        [-0.7881, -0.4653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05593997985124588
Epoch 0, Step 529: train/loss = 0.7247255444526672, train/raw-loss = 0.6247427463531494, train/logprobs = tensor([[-0.3848, -0.2514],
        [-0.5312, -0.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0333276093006134
Epoch 0, Step 530: train/loss = 0.6708605289459229, train/raw-loss = 0.5136927366256714, train/logprobs = tensor([[-0.4259, -1.1236],
        [-0.6812, -0.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05238928273320198
Epoch 0, Step 531: train/loss = 0.5281726717948914, train/raw-loss = 0.3428170084953308, train/logprobs = tensor([[-0.4551, -4.7364],
        [-0.6622, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06178521737456322
Epoch 0, Step 532: train/loss = 0.5986939072608948, train/raw-loss = 0.40897881984710693, train/logprobs = tensor([[-0.4780, -1.9097],
        [-0.7178, -0.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06323838233947754
Epoch 0, Step 533: train/loss = 0.6108441352844238, train/raw-loss = 0.4197843074798584, train/logprobs = tensor([[-0.5177, -1.9264],
        [-0.8162, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06368659436702728
Epoch 0, Step 534: train/loss = 0.6577773094177246, train/raw-loss = 0.457006573677063, train/logprobs = tensor([[-0.4786, -1.2671],
        [-0.8087, -0.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06692357361316681
Epoch 0, Step 535: train/loss = 0.6741191744804382, train/raw-loss = 0.5167738199234009, train/logprobs = tensor([[-0.3970, -0.9087],
        [-0.6658, -0.3550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05244845524430275
Epoch 0, Step 536: train/loss = 0.5058080554008484, train/raw-loss = 0.28309911489486694, train/logprobs = tensor([[-0.5303, -3.3846],
        [-0.9697, -0.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07423630356788635
Epoch 0, Step 537: train/loss = 0.6161136031150818, train/raw-loss = 0.422016978263855, train/logprobs = tensor([[-0.4342, -1.7803],
        [-0.7720, -0.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469886004924774
Epoch 0, Step 538: train/loss = 0.605578601360321, train/raw-loss = 0.42569124698638916, train/logprobs = tensor([[-0.4433, -1.5772],
        [-0.9565, -0.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0599624440073967
Epoch 0, Step 539: train/loss = 0.5669759511947632, train/raw-loss = 0.3958272635936737, train/logprobs = tensor([[-0.3027, -3.8933],
        [-0.3938, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05704956501722336
Epoch 0, Step 540: train/loss = 0.5824244618415833, train/raw-loss = 0.36669212579727173, train/logprobs = tensor([[-0.4628, -2.2603],
        [-0.7645, -0.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07191077619791031
Epoch 0, Step 541: train/loss = 0.642132580280304, train/raw-loss = 0.4488491117954254, train/logprobs = tensor([[-0.4412, -1.4463],
        [-0.6977, -0.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06442783027887344
Epoch 0, Step 542: train/loss = 0.6330091953277588, train/raw-loss = 0.4694039821624756, train/logprobs = tensor([[-0.4778, -1.5890],
        [-0.7742, -0.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05453507602214813
Epoch 0, Step 543: train/loss = 0.5344685912132263, train/raw-loss = 0.3253353536128998, train/logprobs = tensor([[-0.4788, -3.0629],
        [-0.8506, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06971107423305511
Epoch 0, Step 544: train/loss = 0.6140262484550476, train/raw-loss = 0.4579674005508423, train/logprobs = tensor([[-0.4016, -3.8300],
        [-0.4887, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0520196333527565
Epoch 0, Step 545: train/loss = 0.5461050271987915, train/raw-loss = 0.3513607978820801, train/logprobs = tensor([[-0.6037, -2.5815],
        [-1.1298, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06491473317146301
Epoch 0, Step 546: train/loss = 0.7146912217140198, train/raw-loss = 0.5789265036582947, train/logprobs = tensor([[-0.5003, -0.6725],
        [-0.6323, -0.2757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0452549085021019
Epoch 0, Step 547: train/loss = 0.576411783695221, train/raw-loss = 0.40414494276046753, train/logprobs = tensor([[-0.3927, -1.9497],
        [-0.6650, -0.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05742228031158447
Epoch 0, Step 548: train/loss = 0.6008090376853943, train/raw-loss = 0.41652143001556396, train/logprobs = tensor([[-0.4855, -2.2720],
        [-0.8894, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061429187655448914
Epoch 0, Step 549: train/loss = 0.5678016543388367, train/raw-loss = 0.39048242568969727, train/logprobs = tensor([[-0.5577, -2.8481],
        [-1.0675, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059106409549713135
Epoch 0, Step 550: train/loss = 0.65186607837677, train/raw-loss = 0.5078537464141846, train/logprobs = tensor([[-0.4050, -0.9808],
        [-0.6681, -0.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048004116863012314
Epoch 0, Step 551: train/loss = 0.6187123656272888, train/raw-loss = 0.4492696225643158, train/logprobs = tensor([[-0.5196, -2.1452],
        [-0.9017, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056480906903743744
Epoch 0, Step 552: train/loss = 0.6105534434318542, train/raw-loss = 0.42693421244621277, train/logprobs = tensor([[-0.4007, -2.1667],
        [-0.6230, -0.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06120641529560089
Epoch 0, Step 553: train/loss = 0.7223998308181763, train/raw-loss = 0.5583621859550476, train/logprobs = tensor([[-0.3995, -0.7432],
        [-0.6153, -0.3124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05467923358082771
Epoch 0, Step 554: train/loss = 0.6378480195999146, train/raw-loss = 0.43414464592933655, train/logprobs = tensor([[-0.5250, -1.7487],
        [-0.8462, -0.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06790109723806381
Epoch 0, Step 555: train/loss = 0.6424936652183533, train/raw-loss = 0.4627057611942291, train/logprobs = tensor([[-0.5574, -1.7355],
        [-0.8615, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059929296374320984
Epoch 0, Step 556: train/loss = 0.5582625865936279, train/raw-loss = 0.38131195306777954, train/logprobs = tensor([[-0.4720, -2.6263],
        [-0.7627, -0.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05898354947566986
Epoch 0, Step 557: train/loss = 0.6068200469017029, train/raw-loss = 0.44642889499664307, train/logprobs = tensor([[-0.4720, -1.4561],
        [-0.7892, -0.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053463708609342575
Epoch 0, Step 558: train/loss = 0.576150119304657, train/raw-loss = 0.3942733705043793, train/logprobs = tensor([[-0.5916, -2.5080],
        [-0.9875, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0606255903840065
Epoch 0, Step 559: train/loss = 0.6957118511199951, train/raw-loss = 0.5608599185943604, train/logprobs = tensor([[-0.5001, -0.4706],
        [-0.8286, -0.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04495064169168472
Epoch 0, Step 560: train/loss = 0.5625396966934204, train/raw-loss = 0.38810256123542786, train/logprobs = tensor([[-0.5090, -1.6696],
        [-0.8914, -0.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05814572051167488
Epoch 0, Step 561: train/loss = 0.7122506499290466, train/raw-loss = 0.5647123456001282, train/logprobs = tensor([[-0.4678, -0.5918],
        [-0.6778, -0.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04917942360043526
Epoch 0, Step 562: train/loss = 0.662234902381897, train/raw-loss = 0.49780499935150146, train/logprobs = tensor([[-0.5121, -0.7792],
        [-0.8231, -0.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054809972643852234
Epoch 0, Step 563: train/loss = 0.5654823780059814, train/raw-loss = 0.3765912652015686, train/logprobs = tensor([[-0.4197, -2.7843],
        [-0.7044, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06296370923519135
Epoch 0, Step 564: train/loss = 0.5692530274391174, train/raw-loss = 0.4059002101421356, train/logprobs = tensor([[-0.5898, -1.6286],
        [-1.0597, -0.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05445092171430588
Epoch 0, Step 565: train/loss = 0.5159185528755188, train/raw-loss = 0.31954896450042725, train/logprobs = tensor([[-0.4913, -3.0767],
        [-0.8351, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06545653939247131
Epoch 0, Step 566: train/loss = 0.6304710507392883, train/raw-loss = 0.4551803469657898, train/logprobs = tensor([[-0.4827, -2.0560],
        [-0.7979, -0.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058430254459381104
Epoch 0, Step 567: train/loss = 0.5895262956619263, train/raw-loss = 0.40267330408096313, train/logprobs = tensor([[-0.5175, -2.1211],
        [-1.0029, -0.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06228433921933174
Epoch 0, Step 568: train/loss = 0.6268098950386047, train/raw-loss = 0.469932496547699, train/logprobs = tensor([[-0.5040, -1.2579],
        [-0.7649, -0.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052292466163635254
Epoch 0, Step 569: train/loss = 0.6133362054824829, train/raw-loss = 0.42187291383743286, train/logprobs = tensor([[-0.4612, -1.7948],
        [-0.8284, -0.2632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06382109224796295
Epoch 0, Step 570: train/loss = 0.6557128429412842, train/raw-loss = 0.48526889085769653, train/logprobs = tensor([[-0.5474, -1.0128],
        [-0.9227, -0.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05681465193629265
Epoch 0, Step 571: train/loss = 0.6482363343238831, train/raw-loss = 0.47054365277290344, train/logprobs = tensor([[-0.6847, -0.9073],
        [-1.2046, -0.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05923088639974594
Epoch 0, Step 572: train/loss = 0.5979810953140259, train/raw-loss = 0.4245617389678955, train/logprobs = tensor([[-0.5288, -1.2262],
        [-1.0484, -0.2972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05780646204948425
Epoch 0, Step 573: train/loss = 0.5890079736709595, train/raw-loss = 0.4617181122303009, train/logprobs = tensor([[-0.4756, -1.8638],
        [-0.8361, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04242997244000435
Epoch 0, Step 574: train/loss = 0.5798336267471313, train/raw-loss = 0.41634878516197205, train/logprobs = tensor([[-0.4579, -2.9400],
        [-0.7055, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0544949546456337
Epoch 0, Step 575: train/loss = 0.6798083782196045, train/raw-loss = 0.5368019938468933, train/logprobs = tensor([[-0.4467, -0.6048],
        [-0.7083, -0.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04766878858208656
Epoch 0, Step 576: train/loss = 0.6186265349388123, train/raw-loss = 0.4398443400859833, train/logprobs = tensor([[-0.5418, -1.6356],
        [-0.8340, -0.3022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059594061225652695
Epoch 0, Step 577: train/loss = 0.5382564067840576, train/raw-loss = 0.3769373893737793, train/logprobs = tensor([[-0.4814, -2.6733],
        [-0.7782, -0.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05377298966050148
Epoch 0, Step 578: train/loss = 0.5136635899543762, train/raw-loss = 0.35680094361305237, train/logprobs = tensor([[-0.4103, -2.3681],
        [-0.6074, -0.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05228753387928009
Epoch 0, Step 579: train/loss = 0.5505234003067017, train/raw-loss = 0.3733232021331787, train/logprobs = tensor([[-0.5747, -2.4020],
        [-0.9445, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059066735208034515
Epoch 0, Step 580: train/loss = 0.6335548162460327, train/raw-loss = 0.46360597014427185, train/logprobs = tensor([[-0.4317, -1.4968],
        [-0.6174, -0.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05664960667490959
Epoch 0, Step 581: train/loss = 0.6561019420623779, train/raw-loss = 0.5223423838615417, train/logprobs = tensor([[-0.3621, -0.7128],
        [-0.5884, -0.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04458651319146156
Epoch 0, Step 582: train/loss = 0.5713263750076294, train/raw-loss = 0.41369956731796265, train/logprobs = tensor([[-0.4970, -2.1536],
        [-0.8626, -0.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05254225432872772
Epoch 0, Step 583: train/loss = 0.6613591313362122, train/raw-loss = 0.5055254697799683, train/logprobs = tensor([[-0.5094, -0.8190],
        [-0.8040, -0.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0519445426762104
Epoch 0, Step 584: train/loss = 0.6735486388206482, train/raw-loss = 0.5449918508529663, train/logprobs = tensor([[-0.4488, -0.5540],
        [-0.7708, -0.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04285228252410889
Epoch 0, Step 585: train/loss = 0.48807916045188904, train/raw-loss = 0.2975662648677826, train/logprobs = tensor([[-0.5068, -2.8390],
        [-1.1191, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06350430101156235
Epoch 0, Step 586: train/loss = 0.6962162256240845, train/raw-loss = 0.5638229846954346, train/logprobs = tensor([[-0.3590, -0.7417],
        [-0.5084, -0.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0441310778260231
Epoch 0, Step 587: train/loss = 0.608686089515686, train/raw-loss = 0.45574951171875, train/logprobs = tensor([[-0.4581, -1.8140],
        [-0.6129, -0.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050978854298591614
Epoch 0, Step 588: train/loss = 0.6377749443054199, train/raw-loss = 0.48039165139198303, train/logprobs = tensor([[-0.4938, -1.3765],
        [-0.7234, -0.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052461087703704834
Epoch 0, Step 589: train/loss = 0.5462452173233032, train/raw-loss = 0.3748777508735657, train/logprobs = tensor([[-0.5497, -1.9284],
        [-1.0575, -0.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05712248384952545
Epoch 0, Step 590: train/loss = 0.5724831819534302, train/raw-loss = 0.3773188292980194, train/logprobs = tensor([[-0.5079, -1.7525],
        [-0.8524, -0.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06505478918552399
Epoch 0, Step 591: train/loss = 0.42219752073287964, train/raw-loss = 0.22433032095432281, train/logprobs = tensor([[-0.5136, -6.3330],
        [-0.9513, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06595572829246521
Epoch 0, Step 592: train/loss = 0.6835895776748657, train/raw-loss = 0.5582131743431091, train/logprobs = tensor([[-0.3598, -0.8391],
        [-0.5122, -0.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041792143136262894
Epoch 0, Step 593: train/loss = 0.4437209367752075, train/raw-loss = 0.2566717565059662, train/logprobs = tensor([[-0.4805, -5.5964],
        [-0.8347, -1.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06234972923994064
Epoch 0, Step 594: train/loss = 0.6092253923416138, train/raw-loss = 0.4711509048938751, train/logprobs = tensor([[-0.4358, -1.2021],
        [-0.7532, -0.2630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04602483659982681
Epoch 0, Step 595: train/loss = 0.6293609142303467, train/raw-loss = 0.4732048511505127, train/logprobs = tensor([[-0.5917, -0.8009],
        [-1.1379, -0.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052052028477191925
Epoch 0, Step 596: train/loss = 0.6345778107643127, train/raw-loss = 0.4814434051513672, train/logprobs = tensor([[-0.4324, -0.9460],
        [-0.7117, -0.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05104481428861618
Epoch 0, Step 597: train/loss = 0.7452641725540161, train/raw-loss = 0.6325891017913818, train/logprobs = tensor([[-0.3910, -0.2980],
        [-0.5005, -0.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03755836561322212
Epoch 0, Step 598: train/loss = 0.6168817281723022, train/raw-loss = 0.43695956468582153, train/logprobs = tensor([[-0.5015, -1.5903],
        [-0.7525, -0.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0599740669131279
Epoch 0, Step 599: train/loss = 0.6318449974060059, train/raw-loss = 0.5273436307907104, train/logprobs = tensor([[-0.3284, -2.8841],
        [-0.4717, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03483377769589424
Epoch 0, Step 600: train/loss = 0.6274861693382263, train/raw-loss = 0.4671446979045868, train/logprobs = tensor([[-0.5605, -1.6823],
        [-0.9193, -0.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053447164595127106
Epoch 0, Step 601: train/loss = 0.5005436539649963, train/raw-loss = 0.30171239376068115, train/logprobs = tensor([[-0.5806, -2.8938],
        [-0.9875, -0.7643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06627707183361053
Epoch 0, Step 602: train/loss = 0.544777512550354, train/raw-loss = 0.37069976329803467, train/logprobs = tensor([[-0.4798, -3.3796],
        [-0.7344, -0.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05802590399980545
Epoch 0, Step 603: train/loss = 0.6618794798851013, train/raw-loss = 0.5403309464454651, train/logprobs = tensor([[-0.4166, -1.6722],
        [-0.5293, -0.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04051617532968521
Epoch 0, Step 604: train/loss = 0.5533088445663452, train/raw-loss = 0.377566933631897, train/logprobs = tensor([[-0.3977, -2.0930],
        [-0.7522, -0.5333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05858064442873001
Epoch 0, Step 605: train/loss = 0.6247279644012451, train/raw-loss = 0.48016422986984253, train/logprobs = tensor([[-0.4589, -1.4774],
        [-0.6664, -0.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04818791523575783
Epoch 0, Step 606: train/loss = 0.6432759761810303, train/raw-loss = 0.49470648169517517, train/logprobs = tensor([[-0.5156, -1.5143],
        [-0.6470, -0.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04952315613627434
Epoch 0, Step 607: train/loss = 0.5391290187835693, train/raw-loss = 0.4043259620666504, train/logprobs = tensor([[-0.4415, -2.0865],
        [-0.8697, -0.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04493435472249985
Epoch 0, Step 608: train/loss = 0.5962098240852356, train/raw-loss = 0.43194779753685, train/logprobs = tensor([[-0.5809, -1.4726],
        [-1.0644, -0.3078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054754018783569336
Epoch 0, Step 609: train/loss = 0.6106362342834473, train/raw-loss = 0.46383368968963623, train/logprobs = tensor([[-0.5030, -2.1748],
        [-0.9296, -0.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048934195190668106
Epoch 0, Step 610: train/loss = 0.5296050906181335, train/raw-loss = 0.34924381971359253, train/logprobs = tensor([[-0.5255, -3.3146],
        [-0.9194, -0.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06012042984366417
Epoch 0, Step 611: train/loss = 0.5526231527328491, train/raw-loss = 0.3987589478492737, train/logprobs = tensor([[-0.4952, -2.5843],
        [-1.1786, -0.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05128805339336395
Epoch 0, Step 612: train/loss = 0.4750578701496124, train/raw-loss = 0.31853756308555603, train/logprobs = tensor([[-0.5650, -3.1253],
        [-0.9537, -0.5506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0521734356880188
Epoch 0, Step 613: train/loss = 0.4847954511642456, train/raw-loss = 0.3219468295574188, train/logprobs = tensor([[-0.4737, -3.7573],
        [-0.8101, -0.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05428287386894226
Epoch 0, Step 614: train/loss = 0.5599924325942993, train/raw-loss = 0.4187890589237213, train/logprobs = tensor([[-0.4591, -2.2956],
        [-0.7964, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04706777632236481
Epoch 0, Step 615: train/loss = 0.5988079309463501, train/raw-loss = 0.45694804191589355, train/logprobs = tensor([[-0.5115, -1.9831],
        [-0.6837, -0.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04728662222623825
Epoch 0, Step 616: train/loss = 0.49649491906166077, train/raw-loss = 0.330832302570343, train/logprobs = tensor([[-0.5144, -4.0130],
        [-0.9840, -0.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05522087216377258
Epoch 0, Step 617: train/loss = 0.6937142014503479, train/raw-loss = 0.5799948573112488, train/logprobs = tensor([[-0.4029, -0.9401],
        [-0.5027, -0.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0379064604640007
Epoch 0, Step 618: train/loss = 0.7059164047241211, train/raw-loss = 0.5669017434120178, train/logprobs = tensor([[-0.4345, -0.8031],
        [-0.6868, -0.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046338215470314026
Epoch 0, Step 619: train/loss = 0.6381532549858093, train/raw-loss = 0.49584728479385376, train/logprobs = tensor([[-0.4803, -0.9929],
        [-0.8229, -0.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04743531718850136
Epoch 0, Step 620: train/loss = 0.6618084907531738, train/raw-loss = 0.46261167526245117, train/logprobs = tensor([[-0.3471, -1.4759],
        [-0.5443, -0.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06639894098043442
Epoch 0, Step 621: train/loss = 0.6740761995315552, train/raw-loss = 0.5619688034057617, train/logprobs = tensor([[-0.3559, -0.8649],
        [-0.4404, -0.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037369128316640854
Epoch 0, Step 622: train/loss = 0.49169448018074036, train/raw-loss = 0.32177096605300903, train/logprobs = tensor([[-0.6025, -5.5160],
        [-0.9096, -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05664118751883507
Epoch 0, Step 623: train/loss = 0.45229673385620117, train/raw-loss = 0.26339656114578247, train/logprobs = tensor([[-0.6313, -3.2143],
        [-1.2018, -0.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0629667192697525
Epoch 0, Step 624: train/loss = 0.5826126337051392, train/raw-loss = 0.4147941768169403, train/logprobs = tensor([[-0.4542, -2.1582],
        [-0.8005, -0.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05593949556350708
Epoch 0, Step 625: train/loss = 0.5325677394866943, train/raw-loss = 0.3809814751148224, train/logprobs = tensor([[-0.4920, -2.3860],
        [-0.8695, -0.6968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05052875727415085
Epoch 0, Step 626: train/loss = 0.5256720781326294, train/raw-loss = 0.35212236642837524, train/logprobs = tensor([[-0.5814, -3.2725],
        [-0.9954, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05784989148378372
Epoch 0, Step 627: train/loss = 0.6524105668067932, train/raw-loss = 0.5154907703399658, train/logprobs = tensor([[-0.5326, -0.4644],
        [-1.0379, -0.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04563992843031883
Epoch 0, Step 628: train/loss = 0.5497667789459229, train/raw-loss = 0.3751474618911743, train/logprobs = tensor([[-0.5255, -3.9380],
        [-0.7710, -0.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05820644274353981
Epoch 0, Step 629: train/loss = 0.45280179381370544, train/raw-loss = 0.30273520946502686, train/logprobs = tensor([[-0.4187, -3.8604],
        [-0.6862, -1.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050022192299366
Epoch 0, Step 630: train/loss = 0.6456364393234253, train/raw-loss = 0.5098966360092163, train/logprobs = tensor([[-0.4722, -1.0277],
        [-0.7197, -0.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045246608555316925
Epoch 0, Step 631: train/loss = 0.6123579144477844, train/raw-loss = 0.46325165033340454, train/logprobs = tensor([[-0.5278, -3.1127],
        [-0.8841, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04970209300518036
Epoch 0, Step 632: train/loss = 0.6339448690414429, train/raw-loss = 0.4887045621871948, train/logprobs = tensor([[-0.5779, -1.1942],
        [-0.8824, -0.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04841342940926552
Epoch 0, Step 633: train/loss = 0.6567363739013672, train/raw-loss = 0.4997616112232208, train/logprobs = tensor([[-0.4065, -1.8813],
        [-0.6773, -0.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05232490226626396
Epoch 0, Step 634: train/loss = 0.6455172300338745, train/raw-loss = 0.5009282231330872, train/logprobs = tensor([[-0.4358, -1.6897],
        [-0.6461, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048196326941251755
Epoch 0, Step 635: train/loss = 0.6726725101470947, train/raw-loss = 0.5651177763938904, train/logprobs = tensor([[-0.3865, -0.5538],
        [-0.5400, -0.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03585159406065941
Epoch 0, Step 636: train/loss = 0.6238563060760498, train/raw-loss = 0.4796074330806732, train/logprobs = tensor([[-0.5180, -1.9394],
        [-0.8999, -0.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048082977533340454
Epoch 0, Step 637: train/loss = 0.4291713237762451, train/raw-loss = 0.2456674873828888, train/logprobs = tensor([[-0.6984, -4.5829],
        [-1.2960, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061167944222688675
Epoch 0, Step 638: train/loss = 0.5946389436721802, train/raw-loss = 0.45994049310684204, train/logprobs = tensor([[-0.5164, -1.3501],
        [-0.9717, -0.3422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04489949345588684
Epoch 0, Step 639: train/loss = 0.685516893863678, train/raw-loss = 0.5429558753967285, train/logprobs = tensor([[-0.4161, -0.6580],
        [-0.6241, -0.1973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04752032458782196
Epoch 0, Step 640: train/loss = 0.5784702301025391, train/raw-loss = 0.42040854692459106, train/logprobs = tensor([[-0.5340, -1.8512],
        [-0.8556, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05268724635243416
Epoch 0, Step 641: train/loss = 0.5787960290908813, train/raw-loss = 0.43028348684310913, train/logprobs = tensor([[-0.5655, -1.4354],
        [-0.8866, -0.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049504153430461884
Epoch 0, Step 642: train/loss = 0.6283867359161377, train/raw-loss = 0.49109727144241333, train/logprobs = tensor([[-0.4951, -0.9973],
        [-0.7607, -0.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04576316103339195
Epoch 0, Step 643: train/loss = 0.4997658133506775, train/raw-loss = 0.33132031559944153, train/logprobs = tensor([[-0.3777, -2.4404],
        [-0.6902, -0.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05614851415157318
Epoch 0, Step 644: train/loss = 0.553676962852478, train/raw-loss = 0.38939613103866577, train/logprobs = tensor([[-0.4440, -1.9641],
        [-0.7167, -0.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05476025864481926
Epoch 0, Step 645: train/loss = 0.49757248163223267, train/raw-loss = 0.32027363777160645, train/logprobs = tensor([[-0.5332, -3.3900],
        [-0.9906, -0.6689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05909961089491844
Epoch 0, Step 646: train/loss = 0.5905291438102722, train/raw-loss = 0.4382808208465576, train/logprobs = tensor([[-0.5030, -1.7906],
        [-0.7971, -0.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05074942857027054
Epoch 0, Step 647: train/loss = 0.6515794992446899, train/raw-loss = 0.5019824504852295, train/logprobs = tensor([[-0.5825, -1.8567],
        [-0.9516, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04986567050218582
Epoch 0, Step 648: train/loss = 0.5636975169181824, train/raw-loss = 0.42313432693481445, train/logprobs = tensor([[-0.5525, -1.8347],
        [-0.8893, -0.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04685438796877861
Epoch 0, Step 649: train/loss = 0.6077033281326294, train/raw-loss = 0.46313321590423584, train/logprobs = tensor([[-0.5156, -1.2977],
        [-0.9694, -0.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04819002375006676
Epoch 0, Step 650: train/loss = 0.5904005169868469, train/raw-loss = 0.45075005292892456, train/logprobs = tensor([[-0.6045, -2.7930],
        [-0.9172, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046550165861845016
Epoch 0, Step 651: train/loss = 0.575449526309967, train/raw-loss = 0.44710588455200195, train/logprobs = tensor([[-0.5655, -2.9782],
        [-0.7337, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042781200259923935
Epoch 0, Step 652: train/loss = 0.5720263719558716, train/raw-loss = 0.4047548770904541, train/logprobs = tensor([[-0.4587, -1.9120],
        [-0.6954, -0.5271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055757179856300354
Epoch 0, Step 653: train/loss = 0.6023960113525391, train/raw-loss = 0.47233378887176514, train/logprobs = tensor([[-0.4477, -1.3835],
        [-0.7507, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0433540865778923
Epoch 0, Step 654: train/loss = 0.6700569987297058, train/raw-loss = 0.5639467239379883, train/logprobs = tensor([[-0.3951, -0.7938],
        [-0.5512, -0.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03537008911371231
Epoch 0, Step 655: train/loss = 0.5337003469467163, train/raw-loss = 0.3708334267139435, train/logprobs = tensor([[-0.4646, -2.2939],
        [-0.9069, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05428896099328995
Epoch 0, Step 656: train/loss = 0.6346377730369568, train/raw-loss = 0.4906614422798157, train/logprobs = tensor([[-0.5964, -0.7142],
        [-1.0471, -0.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04799211025238037
Epoch 0, Step 657: train/loss = 0.6698453426361084, train/raw-loss = 0.5331506133079529, train/logprobs = tensor([[-0.5520, -0.7867],
        [-0.8030, -0.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045564889907836914
Epoch 0, Step 658: train/loss = 0.470314085483551, train/raw-loss = 0.30276721715927124, train/logprobs = tensor([[-0.6193, -2.8450],
        [-1.2223, -0.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055848948657512665
Epoch 0, Step 659: train/loss = 0.6258313655853271, train/raw-loss = 0.4910830557346344, train/logprobs = tensor([[-0.4345, -1.7508],
        [-0.6316, -0.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04491610452532768
Epoch 0, Step 660: train/loss = 0.44737154245376587, train/raw-loss = 0.2834910452365875, train/logprobs = tensor([[-0.6225, -4.7786],
        [-1.1206, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054626841098070145
Epoch 0, Step 661: train/loss = 0.5930003523826599, train/raw-loss = 0.4371446371078491, train/logprobs = tensor([[-0.4350, -1.7515],
        [-0.7129, -0.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05195190757513046
Epoch 0, Step 662: train/loss = 0.5420734882354736, train/raw-loss = 0.3783804476261139, train/logprobs = tensor([[-0.6039, -2.6537],
        [-1.1111, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05456434562802315
Epoch 0, Step 663: train/loss = 0.5373067259788513, train/raw-loss = 0.3741902709007263, train/logprobs = tensor([[-0.5391, -3.3561],
        [-1.0462, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0543721467256546
Epoch 0, Step 664: train/loss = 0.5205315351486206, train/raw-loss = 0.32085341215133667, train/logprobs = tensor([[-0.5597, -2.2372],
        [-1.1190, -0.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06655935943126678
Epoch 0, Step 665: train/loss = 0.552374541759491, train/raw-loss = 0.41428086161613464, train/logprobs = tensor([[-0.5111, -2.5630],
        [-0.9112, -0.5250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04603121057152748
Epoch 0, Step 666: train/loss = 0.459297776222229, train/raw-loss = 0.2817049026489258, train/logprobs = tensor([[-0.7153, -2.7979],
        [-1.4097, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059197623282670975
Epoch 0, Step 667: train/loss = 0.6218721866607666, train/raw-loss = 0.4672105312347412, train/logprobs = tensor([[-0.5633, -1.4001],
        [-0.9437, -0.3969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051553890109062195
Epoch 0, Step 668: train/loss = 0.42525434494018555, train/raw-loss = 0.2477635145187378, train/logprobs = tensor([[-0.5829, -3.8552],
        [-1.0754, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05916360020637512
Epoch 0, Step 669: train/loss = 0.48923736810684204, train/raw-loss = 0.33520251512527466, train/logprobs = tensor([[-0.4630, -3.7264],
        [-0.8528, -0.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051344964653253555
Epoch 0, Step 670: train/loss = 0.6499707698822021, train/raw-loss = 0.5323622822761536, train/logprobs = tensor([[-0.4761, -3.0153],
        [-0.6204, -0.5040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03920283168554306
Epoch 0, Step 671: train/loss = 0.6464457511901855, train/raw-loss = 0.5222989320755005, train/logprobs = tensor([[-0.5390, -1.6642],
        [-0.7835, -0.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04138226434588432
Epoch 0, Step 672: train/loss = 0.5704901218414307, train/raw-loss = 0.4216097295284271, train/logprobs = tensor([[-0.5080, -1.9108],
        [-0.7278, -0.4482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049626804888248444
Epoch 0, Step 673: train/loss = 0.5684319734573364, train/raw-loss = 0.39091622829437256, train/logprobs = tensor([[-0.5936, -1.5027],
        [-1.1346, -0.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05917191505432129
Epoch 0, Step 674: train/loss = 0.4927372634410858, train/raw-loss = 0.33634835481643677, train/logprobs = tensor([[-0.4919, -2.6282],
        [-0.8792, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05212964490056038
Epoch 0, Step 675: train/loss = 0.6328741312026978, train/raw-loss = 0.4906812608242035, train/logprobs = tensor([[-0.5117, -1.4830],
        [-0.7968, -0.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04739764332771301
Epoch 0, Step 676: train/loss = 0.5884037017822266, train/raw-loss = 0.4376140236854553, train/logprobs = tensor([[-0.6088, -1.2219],
        [-1.0871, -0.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050263211131095886
Epoch 0, Step 677: train/loss = 0.500764012336731, train/raw-loss = 0.33961302042007446, train/logprobs = tensor([[-0.4881, -4.3464],
        [-0.8990, -0.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0537169985473156
Epoch 0, Step 678: train/loss = 0.5668162703514099, train/raw-loss = 0.41596806049346924, train/logprobs = tensor([[-0.5295, -2.5718],
        [-0.8997, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05028272420167923
Epoch 0, Step 679: train/loss = 0.5742366313934326, train/raw-loss = 0.3946358561515808, train/logprobs = tensor([[-0.4639, -2.4632],
        [-0.8366, -0.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05986692011356354
Epoch 0, Step 680: train/loss = 0.6441442966461182, train/raw-loss = 0.5199599266052246, train/logprobs = tensor([[-0.5209, -0.7547],
        [-0.8319, -0.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04139479994773865
Epoch 0, Step 681: train/loss = 0.5989919900894165, train/raw-loss = 0.468287855386734, train/logprobs = tensor([[-0.3818, -2.0221],
        [-0.5808, -0.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04356803372502327
Epoch 0, Step 682: train/loss = 0.4829804003238678, train/raw-loss = 0.3422311842441559, train/logprobs = tensor([[-0.5145, -3.6054],
        [-0.8325, -0.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0469164103269577
Epoch 0, Step 683: train/loss = 0.42005807161331177, train/raw-loss = 0.22306105494499207, train/logprobs = tensor([[-0.6112, -4.1881],
        [-1.2027, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06566566973924637
Epoch 0, Step 684: train/loss = 0.5388391613960266, train/raw-loss = 0.34176141023635864, train/logprobs = tensor([[-0.5801, -2.6702],
        [-0.9706, -0.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06569256633520126
Epoch 0, Step 685: train/loss = 0.6142992973327637, train/raw-loss = 0.4978525936603546, train/logprobs = tensor([[-0.5145, -1.1478],
        [-0.7181, -0.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03881557658314705
Epoch 0, Step 686: train/loss = 0.4664420187473297, train/raw-loss = 0.3286430835723877, train/logprobs = tensor([[-0.4570, -3.5799],
        [-0.8377, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045932985842227936
Epoch 0, Step 687: train/loss = 0.4832151532173157, train/raw-loss = 0.30665212869644165, train/logprobs = tensor([[-0.4945, -2.6998],
        [-1.0516, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0588543526828289
Epoch 0, Step 688: train/loss = 0.6147756576538086, train/raw-loss = 0.47092413902282715, train/logprobs = tensor([[-0.5207, -1.0897],
        [-0.9418, -0.1758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047950517386198044
Epoch 0, Step 689: train/loss = 0.46537137031555176, train/raw-loss = 0.2879730463027954, train/logprobs = tensor([[-0.6370, -3.4093],
        [-1.1962, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05913277342915535
Epoch 0, Step 690: train/loss = 0.5744015574455261, train/raw-loss = 0.4352760314941406, train/logprobs = tensor([[-0.3411, -1.9304],
        [-0.4421, -0.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046375177800655365
Epoch 0, Step 691: train/loss = 0.5811907649040222, train/raw-loss = 0.44541531801223755, train/logprobs = tensor([[-0.4716, -1.7408],
        [-0.6968, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04525848478078842
Epoch 0, Step 692: train/loss = 0.618037223815918, train/raw-loss = 0.48824405670166016, train/logprobs = tensor([[-0.4664, -1.4556],
        [-0.7232, -0.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04326441138982773
Epoch 0, Step 693: train/loss = 0.636293888092041, train/raw-loss = 0.49744993448257446, train/logprobs = tensor([[-0.5654, -1.3830],
        [-0.8300, -0.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046281345188617706
Epoch 0, Step 694: train/loss = 0.528343677520752, train/raw-loss = 0.373029887676239, train/logprobs = tensor([[-0.4629, -4.5751],
        [-0.7847, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051771245896816254
Epoch 0, Step 695: train/loss = 0.603535532951355, train/raw-loss = 0.48083892464637756, train/logprobs = tensor([[-0.3769, -1.3961],
        [-0.5539, -0.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04089886322617531
Epoch 0, Step 696: train/loss = 0.576962411403656, train/raw-loss = 0.4220759868621826, train/logprobs = tensor([[-0.4603, -1.8073],
        [-0.8453, -0.5550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051628805696964264
Epoch 0, Step 697: train/loss = 0.5366957187652588, train/raw-loss = 0.4004553556442261, train/logprobs = tensor([[-0.5432, -2.6843],
        [-0.9457, -0.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04541344940662384
Epoch 0, Step 698: train/loss = 0.45226699113845825, train/raw-loss = 0.2815321087837219, train/logprobs = tensor([[-0.5176, -5.5052],
        [-0.9176, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05691162496805191
Epoch 0, Step 699: train/loss = 0.6045964956283569, train/raw-loss = 0.44858235120773315, train/logprobs = tensor([[-0.5175, -1.9456],
        [-0.8964, -0.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05200471729040146
Epoch 0, Step 700: train/loss = 0.5502866506576538, train/raw-loss = 0.3957492709159851, train/logprobs = tensor([[-0.6388, -2.3677],
        [-1.0970, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0515124537050724
Epoch 0, Step 701: train/loss = 0.4692685008049011, train/raw-loss = 0.31852978467941284, train/logprobs = tensor([[-0.4490, -4.9787],
        [-0.7437, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050246234983205795
Epoch 0, Step 702: train/loss = 0.5032544732093811, train/raw-loss = 0.34539681673049927, train/logprobs = tensor([[-0.6046, -4.3685],
        [-1.3249, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05261921137571335
Epoch 0, Step 703: train/loss = 0.6623932719230652, train/raw-loss = 0.5346029996871948, train/logprobs = tensor([[-0.4181, -0.9873],
        [-0.6382, -0.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042596735060214996
Epoch 0, Step 704: train/loss = 0.5668104887008667, train/raw-loss = 0.39770936965942383, train/logprobs = tensor([[-0.4860, -1.5988],
        [-0.9790, -0.2306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05636705458164215
Epoch 0, Step 705: train/loss = 0.5706225633621216, train/raw-loss = 0.4241825342178345, train/logprobs = tensor([[-0.5667, -2.2802],
        [-0.8470, -0.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048813339322805405
Epoch 0, Step 706: train/loss = 0.5604699850082397, train/raw-loss = 0.4034975469112396, train/logprobs = tensor([[-0.6416, -1.4638],
        [-1.3811, -0.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05232412740588188
Epoch 0, Step 707: train/loss = 0.6718530654907227, train/raw-loss = 0.540178120136261, train/logprobs = tensor([[-0.5321, -0.6500],
        [-0.9291, -0.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043891675770282745
Epoch 0, Step 708: train/loss = 0.5573818683624268, train/raw-loss = 0.36929160356521606, train/logprobs = tensor([[-0.5664, -2.9273],
        [-1.0954, -0.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06269674003124237
Epoch 0, Step 709: train/loss = 0.5628901720046997, train/raw-loss = 0.40374669432640076, train/logprobs = tensor([[-0.4499, -2.2087],
        [-0.8701, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053047820925712585
Epoch 0, Step 710: train/loss = 0.6479811668395996, train/raw-loss = 0.5276496410369873, train/logprobs = tensor([[-0.4918, -0.6577],
        [-0.7600, -0.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0401105061173439
Epoch 0, Step 711: train/loss = 0.49919411540031433, train/raw-loss = 0.3538644313812256, train/logprobs = tensor([[-0.5674, -2.9283],
        [-1.0550, -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04844322055578232
Epoch 0, Step 712: train/loss = 0.7045204639434814, train/raw-loss = 0.6000099778175354, train/logprobs = tensor([[-0.3197, -0.5421],
        [-0.4073, -0.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03483682870864868
Epoch 0, Step 713: train/loss = 0.5825496315956116, train/raw-loss = 0.4573582410812378, train/logprobs = tensor([[-0.4984, -2.0129],
        [-0.8019, -0.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041730474680662155
Epoch 0, Step 714: train/loss = 0.5539997816085815, train/raw-loss = 0.38907259702682495, train/logprobs = tensor([[-0.4278, -2.5412],
        [-0.8426, -0.3192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054975736886262894
Epoch 0, Step 715: train/loss = 0.49414944648742676, train/raw-loss = 0.31110358238220215, train/logprobs = tensor([[-0.6124, -3.6157],
        [-1.1557, -0.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0610152930021286
Epoch 0, Step 716: train/loss = 0.4882514476776123, train/raw-loss = 0.3040603995323181, train/logprobs = tensor([[-0.5006, -2.7215],
        [-1.0458, -0.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0613970011472702
Epoch 0, Step 717: train/loss = 0.6622270345687866, train/raw-loss = 0.5045127868652344, train/logprobs = tensor([[-0.4441, -1.1991],
        [-0.7975, -0.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052571412175893784
Epoch 0, Step 718: train/loss = 0.5494089722633362, train/raw-loss = 0.38848888874053955, train/logprobs = tensor([[-0.4245, -2.4409],
        [-0.7252, -0.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05364002287387848
Epoch 0, Step 719: train/loss = 0.6332445740699768, train/raw-loss = 0.48468825221061707, train/logprobs = tensor([[-0.3614, -1.4982],
        [-0.5810, -0.3668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04951877146959305
Epoch 0, Step 720: train/loss = 0.6148781180381775, train/raw-loss = 0.4411226809024811, train/logprobs = tensor([[-0.4735, -0.9813],
        [-1.0220, -0.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057918481528759
Epoch 0, Step 721: train/loss = 0.6193186044692993, train/raw-loss = 0.4885358512401581, train/logprobs = tensor([[-0.4893, -1.6714],
        [-0.6728, -0.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043594248592853546
Epoch 0, Step 722: train/loss = 0.43617820739746094, train/raw-loss = 0.27280503511428833, train/logprobs = tensor([[-0.4628, -5.0942],
        [-0.8798, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05445772409439087
Epoch 0, Step 723: train/loss = 0.5429240465164185, train/raw-loss = 0.38015854358673096, train/logprobs = tensor([[-0.5327, -2.5120],
        [-1.0252, -0.5563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05425518751144409
Epoch 0, Step 724: train/loss = 0.632605791091919, train/raw-loss = 0.49488621950149536, train/logprobs = tensor([[-0.5447, -1.1528],
        [-0.9206, -0.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04590652137994766
Epoch 0, Step 725: train/loss = 0.5862769484519958, train/raw-loss = 0.4209235906600952, train/logprobs = tensor([[-0.3851, -1.6773],
        [-0.7096, -0.3104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055117785930633545
Epoch 0, Step 726: train/loss = 0.5322341918945312, train/raw-loss = 0.3557872772216797, train/logprobs = tensor([[-0.5361, -4.1703],
        [-1.1701, -0.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058815643191337585
Epoch 0, Step 727: train/loss = 0.580498218536377, train/raw-loss = 0.440456360578537, train/logprobs = tensor([[-0.4605, -1.8868],
        [-0.8704, -0.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046680621802806854
Epoch 0, Step 728: train/loss = 0.5355000495910645, train/raw-loss = 0.3607891798019409, train/logprobs = tensor([[-0.5187, -2.6302],
        [-0.8935, -0.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823694169521332
Epoch 0, Step 729: train/loss = 0.4924042820930481, train/raw-loss = 0.31027060747146606, train/logprobs = tensor([[-0.7298, -2.2062],
        [-1.4898, -0.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06071121245622635
Epoch 0, Step 730: train/loss = 0.6240404844284058, train/raw-loss = 0.4483736455440521, train/logprobs = tensor([[-0.5559, -1.2507],
        [-1.0444, -0.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058555617928504944
Epoch 0, Step 731: train/loss = 0.5491231679916382, train/raw-loss = 0.3770793080329895, train/logprobs = tensor([[-0.5602, -2.7159],
        [-1.0165, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05734796077013016
Epoch 0, Step 732: train/loss = 0.5864211320877075, train/raw-loss = 0.4039492607116699, train/logprobs = tensor([[-0.5320, -1.4313],
        [-1.0610, -0.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0608239620923996
Epoch 0, Step 733: train/loss = 0.5842604637145996, train/raw-loss = 0.4115716218948364, train/logprobs = tensor([[-0.6033, -2.8292],
        [-0.9479, -0.3478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0575629398226738
Epoch 0, Step 734: train/loss = 0.5331956148147583, train/raw-loss = 0.37106698751449585, train/logprobs = tensor([[-0.5797, -2.7214],
        [-0.9085, -0.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054042886942625046
Epoch 0, Step 735: train/loss = 0.7139991521835327, train/raw-loss = 0.5791791677474976, train/logprobs = tensor([[-0.4817, -0.4894],
        [-0.7061, -0.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044939976185560226
Epoch 0, Step 736: train/loss = 0.6279720067977905, train/raw-loss = 0.5124390721321106, train/logprobs = tensor([[-0.3908, -0.7934],
        [-0.6435, -0.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03851098567247391
Epoch 0, Step 737: train/loss = 0.5831472277641296, train/raw-loss = 0.46326756477355957, train/logprobs = tensor([[-0.5130, -1.5709],
        [-0.8310, -0.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0399598702788353
Epoch 0, Step 738: train/loss = 0.608387291431427, train/raw-loss = 0.46360909938812256, train/logprobs = tensor([[-0.3713, -1.1479],
        [-0.8128, -0.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04825939983129501
Epoch 0, Step 739: train/loss = 0.46837344765663147, train/raw-loss = 0.29010888934135437, train/logprobs = tensor([[-0.5640, -2.8587],
        [-1.2422, -0.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05942152068018913
Epoch 0, Step 740: train/loss = 0.6449803113937378, train/raw-loss = 0.5061377286911011, train/logprobs = tensor([[-0.4619, -0.7724],
        [-0.8145, -0.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046280886977910995
Epoch 0, Step 741: train/loss = 0.584641695022583, train/raw-loss = 0.48466023802757263, train/logprobs = tensor([[-0.5642, -2.6042],
        [-0.9092, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03332716226577759
Epoch 0, Step 742: train/loss = 0.6287417411804199, train/raw-loss = 0.49793851375579834, train/logprobs = tensor([[-0.5755, -0.4837],
        [-1.1401, -0.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043601084500551224
Epoch 0, Step 743: train/loss = 0.5814788937568665, train/raw-loss = 0.4403972625732422, train/logprobs = tensor([[-0.4311, -2.0368],
        [-0.6729, -0.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04702720791101456
Epoch 0, Step 744: train/loss = 0.6248552799224854, train/raw-loss = 0.4942432641983032, train/logprobs = tensor([[-0.3627, -1.1280],
        [-0.5697, -0.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043537333607673645
Epoch 0, Step 745: train/loss = 0.50772625207901, train/raw-loss = 0.3536999225616455, train/logprobs = tensor([[-0.4245, -2.4164],
        [-0.7127, -0.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05134209245443344
Epoch 0, Step 746: train/loss = 0.656475305557251, train/raw-loss = 0.538891613483429, train/logprobs = tensor([[-0.4151, -0.7448],
        [-0.6454, -0.2479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03919457271695137
Epoch 0, Step 747: train/loss = 0.5322309732437134, train/raw-loss = 0.3899523615837097, train/logprobs = tensor([[-0.4272, -2.7485],
        [-0.8107, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04742620512843132
Epoch 0, Step 748: train/loss = 0.5508651733398438, train/raw-loss = 0.4176742434501648, train/logprobs = tensor([[-0.4163, -2.3227],
        [-0.6433, -0.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04439697787165642
Epoch 0, Step 749: train/loss = 0.6356610059738159, train/raw-loss = 0.5042762756347656, train/logprobs = tensor([[-0.4696, -1.0667],
        [-0.8706, -0.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043794896453619
Epoch 0, Step 750: train/loss = 0.46428078413009644, train/raw-loss = 0.3042961359024048, train/logprobs = tensor([[-0.5557, -3.9790],
        [-1.1440, -0.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05332821607589722
Epoch 0, Step 751: train/loss = 0.5015097856521606, train/raw-loss = 0.34630894660949707, train/logprobs = tensor([[-0.3339, -3.0981],
        [-0.5878, -0.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05173361673951149
Epoch 0, Step 752: train/loss = 0.44387122988700867, train/raw-loss = 0.27148646116256714, train/logprobs = tensor([[-0.4560, -3.6854],
        [-0.7988, -0.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05746158957481384
Epoch 0, Step 753: train/loss = 0.5217354893684387, train/raw-loss = 0.38193947076797485, train/logprobs = tensor([[-0.4531, -2.7222],
        [-0.6973, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04659867659211159
Epoch 0, Step 754: train/loss = 0.5561745166778564, train/raw-loss = 0.40180569887161255, train/logprobs = tensor([[-0.4729, -2.0700],
        [-0.8324, -0.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0514562726020813
Epoch 0, Step 755: train/loss = 0.5466457009315491, train/raw-loss = 0.39518141746520996, train/logprobs = tensor([[-0.5271, -3.2751],
        [-0.9138, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050488103181123734
Epoch 0, Step 756: train/loss = 0.6162021160125732, train/raw-loss = 0.47525352239608765, train/logprobs = tensor([[-0.5130, -1.0798],
        [-0.8397, -0.2857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046982862055301666
Epoch 0, Step 757: train/loss = 0.5528292059898376, train/raw-loss = 0.37318867444992065, train/logprobs = tensor([[-0.4026, -2.3883],
        [-0.5753, -0.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05988018587231636
Epoch 0, Step 758: train/loss = 0.47587037086486816, train/raw-loss = 0.3033612370491028, train/logprobs = tensor([[-0.6352, -2.7485],
        [-1.3861, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05750304460525513
Epoch 0, Step 759: train/loss = 0.4655713737010956, train/raw-loss = 0.2843889594078064, train/logprobs = tensor([[-0.5333, -3.1741],
        [-1.0137, -0.6838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060394130647182465
Epoch 0, Step 760: train/loss = 0.699453592300415, train/raw-loss = 0.5729960203170776, train/logprobs = tensor([[-0.4168, -0.6067],
        [-0.7548, -0.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042152512818574905
Epoch 0, Step 761: train/loss = 0.500372588634491, train/raw-loss = 0.31894657015800476, train/logprobs = tensor([[-0.6104, -3.3829],
        [-1.1155, -0.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060475341975688934
Epoch 0, Step 762: train/loss = 0.4858304262161255, train/raw-loss = 0.3137530982494354, train/logprobs = tensor([[-0.5462, -3.1799],
        [-1.0830, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05735909938812256
Epoch 0, Step 763: train/loss = 0.4806629717350006, train/raw-loss = 0.30123043060302734, train/logprobs = tensor([[-0.5988, -3.8620],
        [-1.0962, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05981084331870079
Epoch 0, Step 764: train/loss = 0.6011030077934265, train/raw-loss = 0.4647985100746155, train/logprobs = tensor([[-0.5072, -0.9094],
        [-0.9587, -0.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04543483257293701
Epoch 0, Step 765: train/loss = 0.5670343041419983, train/raw-loss = 0.43318814039230347, train/logprobs = tensor([[-0.3966, -1.5258],
        [-0.8070, -0.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04461538791656494
Epoch 0, Step 766: train/loss = 0.4863604009151459, train/raw-loss = 0.34385937452316284, train/logprobs = tensor([[-0.4721, -5.3439],
        [-0.7103, -1.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04750034213066101
Epoch 0, Step 767: train/loss = 0.38986849784851074, train/raw-loss = 0.2094590961933136, train/logprobs = tensor([[-0.5871, -7.6399],
        [-1.0600, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06013648211956024
Epoch 0, Step 768: train/loss = 0.600938081741333, train/raw-loss = 0.4872841536998749, train/logprobs = tensor([[-0.4408, -2.0350],
        [-0.7500, -0.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03788463771343231
Epoch 0, Step 769: train/loss = 0.660919189453125, train/raw-loss = 0.5315223336219788, train/logprobs = tensor([[-0.5151, -0.5504],
        [-0.9619, -0.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04313228651881218
Epoch 0, Step 770: train/loss = 0.5644876956939697, train/raw-loss = 0.4243292212486267, train/logprobs = tensor([[-0.6523, -1.7926],
        [-1.3270, -0.2927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04671947658061981
Epoch 0, Step 771: train/loss = 0.5154691338539124, train/raw-loss = 0.3728526532649994, train/logprobs = tensor([[-0.5684, -1.9136],
        [-1.1518, -0.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04753883555531502
Epoch 0, Step 772: train/loss = 0.5468791723251343, train/raw-loss = 0.4220017194747925, train/logprobs = tensor([[-0.3797, -2.5765],
        [-0.5350, -0.6719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04162583127617836
Epoch 0, Step 773: train/loss = 0.5077680349349976, train/raw-loss = 0.3811744749546051, train/logprobs = tensor([[-0.4506, -1.8973],
        [-0.9272, -0.4221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04219784215092659
Epoch 0, Step 774: train/loss = 0.4811885356903076, train/raw-loss = 0.3127179741859436, train/logprobs = tensor([[-0.6121, -2.4814],
        [-1.3310, -0.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056156858801841736
Epoch 0, Step 775: train/loss = 0.6059361696243286, train/raw-loss = 0.4574212431907654, train/logprobs = tensor([[-0.4958, -1.4935],
        [-0.8338, -0.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04950496181845665
Epoch 0, Step 776: train/loss = 0.4803604483604431, train/raw-loss = 0.3373486399650574, train/logprobs = tensor([[-0.4242, -4.4752],
        [-0.8490, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047670602798461914
Epoch 0, Step 777: train/loss = 0.5604497194290161, train/raw-loss = 0.4456826448440552, train/logprobs = tensor([[-0.3462, -1.4721],
        [-0.6451, -0.4477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03825569152832031
Epoch 0, Step 778: train/loss = 0.4948226511478424, train/raw-loss = 0.36497852206230164, train/logprobs = tensor([[-0.7587, -3.5785],
        [-1.5155, -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043281376361846924
Epoch 0, Step 779: train/loss = 0.6672326922416687, train/raw-loss = 0.5416739583015442, train/logprobs = tensor([[-0.4406, -0.6867],
        [-0.7314, -0.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041852906346321106
Epoch 0, Step 780: train/loss = 0.6032922267913818, train/raw-loss = 0.4847339391708374, train/logprobs = tensor([[-0.4301, -1.1445],
        [-0.7990, -0.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03951944410800934
Epoch 0, Step 781: train/loss = 0.4657709300518036, train/raw-loss = 0.31455016136169434, train/logprobs = tensor([[-0.5062, -2.5321],
        [-1.1148, -0.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05040692165493965
Epoch 0, Step 782: train/loss = 0.5603490471839905, train/raw-loss = 0.4403232932090759, train/logprobs = tensor([[-0.4396, -2.2091],
        [-0.7852, -0.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04000858962535858
Epoch 0, Step 783: train/loss = 0.5287668108940125, train/raw-loss = 0.36543336510658264, train/logprobs = tensor([[-0.4654, -1.8683],
        [-0.9638, -0.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05444447696208954
Epoch 0, Step 784: train/loss = 0.5771911144256592, train/raw-loss = 0.4614163637161255, train/logprobs = tensor([[-0.4399, -1.4219],
        [-0.7616, -0.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038591593503952026
Epoch 0, Step 785: train/loss = 0.6054697036743164, train/raw-loss = 0.48571908473968506, train/logprobs = tensor([[-0.4194, -1.2760],
        [-0.6813, -0.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039916861802339554
Epoch 0, Step 786: train/loss = 0.5184398293495178, train/raw-loss = 0.3919803500175476, train/logprobs = tensor([[-0.4864, -1.4620],
        [-1.0240, -0.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04215315729379654
Epoch 0, Step 787: train/loss = 0.5076587200164795, train/raw-loss = 0.3655072748661041, train/logprobs = tensor([[-0.5839, -2.7735],
        [-1.1419, -0.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047383829951286316
Epoch 0, Step 788: train/loss = 0.6601011753082275, train/raw-loss = 0.5538876056671143, train/logprobs = tensor([[-0.4061, -0.5835],
        [-0.6299, -0.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0354045107960701
Epoch 0, Step 789: train/loss = 0.6627812385559082, train/raw-loss = 0.5445150136947632, train/logprobs = tensor([[-0.4008, -0.6704],
        [-0.6472, -0.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03942206874489784
Epoch 0, Step 790: train/loss = 0.48936164379119873, train/raw-loss = 0.35414955019950867, train/logprobs = tensor([[-0.4005, -2.9558],
        [-0.6338, -0.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04507070034742355
Epoch 0, Step 791: train/loss = 0.5316829085350037, train/raw-loss = 0.3921734690666199, train/logprobs = tensor([[-0.4893, -2.1794],
        [-0.8883, -0.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04650314524769783
Epoch 0, Step 792: train/loss = 0.6691390872001648, train/raw-loss = 0.5419671535491943, train/logprobs = tensor([[-0.4288, -0.7892],
        [-0.6498, -0.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04239066690206528
Epoch 0, Step 793: train/loss = 0.5990738272666931, train/raw-loss = 0.46646273136138916, train/logprobs = tensor([[-0.5522, -1.0721],
        [-0.9368, -0.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04420369118452072
Epoch 0, Step 794: train/loss = 0.5703728199005127, train/raw-loss = 0.4494779407978058, train/logprobs = tensor([[-0.5073, -1.4267],
        [-0.8675, -0.3539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040298283100128174
Epoch 0, Step 795: train/loss = 0.38660213351249695, train/raw-loss = 0.22662174701690674, train/logprobs = tensor([[-0.6464, -5.5473],
        [-1.3354, -0.9344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0533268079161644
Epoch 0, Step 796: train/loss = 0.5192543864250183, train/raw-loss = 0.40355920791625977, train/logprobs = tensor([[-0.3289, -2.6525],
        [-0.5369, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038565050810575485
Epoch 0, Step 797: train/loss = 0.49749234318733215, train/raw-loss = 0.3524598181247711, train/logprobs = tensor([[-0.6225, -2.5598],
        [-1.0072, -0.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048344165086746216
Epoch 0, Step 798: train/loss = 0.5163378715515137, train/raw-loss = 0.399314284324646, train/logprobs = tensor([[-0.4359, -2.5818],
        [-0.6293, -0.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03900785371661186
Epoch 0, Step 799: train/loss = 0.6428398489952087, train/raw-loss = 0.5319303274154663, train/logprobs = tensor([[-0.4372, -0.7649],
        [-0.6802, -0.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036969829350709915
Epoch 0, Step 800: train/loss = 0.5584486126899719, train/raw-loss = 0.42075055837631226, train/logprobs = tensor([[-0.5216, -1.4454],
        [-1.0857, -0.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04589936509728432
Epoch 0, Step 801: train/loss = 0.6376518607139587, train/raw-loss = 0.5057221055030823, train/logprobs = tensor([[-0.3948, -1.0023],
        [-0.6078, -0.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043976590037345886
Epoch 0, Step 802: train/loss = 0.6010361909866333, train/raw-loss = 0.44822901487350464, train/logprobs = tensor([[-0.6009, -1.4030],
        [-1.0522, -0.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05093573033809662
Epoch 0, Step 803: train/loss = 0.4709426760673523, train/raw-loss = 0.29419568181037903, train/logprobs = tensor([[-0.4729, -3.0680],
        [-0.9214, -0.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05891565978527069
Epoch 0, Step 804: train/loss = 0.5295603275299072, train/raw-loss = 0.4222154915332794, train/logprobs = tensor([[-0.4495, -2.4244],
        [-0.7429, -0.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035781607031822205
Epoch 0, Step 805: train/loss = 0.5768887996673584, train/raw-loss = 0.45621004700660706, train/logprobs = tensor([[-0.5270, -1.6431],
        [-0.9161, -0.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040226250886917114
Epoch 0, Step 806: train/loss = 0.46657446026802063, train/raw-loss = 0.3316977620124817, train/logprobs = tensor([[-0.5037, -2.7789],
        [-1.0432, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044958896934986115
Epoch 0, Step 807: train/loss = 0.5236557126045227, train/raw-loss = 0.3634897768497467, train/logprobs = tensor([[-0.5421, -2.0971],
        [-1.1832, -0.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05338864028453827
Epoch 0, Step 808: train/loss = 0.4967622756958008, train/raw-loss = 0.37524405121803284, train/logprobs = tensor([[-0.4777, -1.9561],
        [-0.7903, -0.3483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04050607979297638
Epoch 0, Step 809: train/loss = 0.4509091377258301, train/raw-loss = 0.3000469505786896, train/logprobs = tensor([[-0.4628, -3.1658],
        [-0.8722, -0.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050287384539842606
Epoch 0, Step 810: train/loss = 0.5714331269264221, train/raw-loss = 0.44731056690216064, train/logprobs = tensor([[-0.4203, -1.3549],
        [-0.7943, -0.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041374195367097855
Epoch 0, Step 811: train/loss = 0.4596148431301117, train/raw-loss = 0.3292769491672516, train/logprobs = tensor([[-0.5075, -3.3259],
        [-0.8787, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04344596713781357
Epoch 0, Step 812: train/loss = 0.48205626010894775, train/raw-loss = 0.3487597703933716, train/logprobs = tensor([[-0.4982, -4.5310],
        [-0.7893, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04443216696381569
Epoch 0, Step 813: train/loss = 0.5308182239532471, train/raw-loss = 0.39425715804100037, train/logprobs = tensor([[-0.5067, -3.4729],
        [-0.9064, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0455203503370285
Epoch 0, Step 814: train/loss = 0.43644440174102783, train/raw-loss = 0.30501842498779297, train/logprobs = tensor([[-0.5166, -2.7376],
        [-0.8885, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04380866140127182
Epoch 0, Step 815: train/loss = 0.563277006149292, train/raw-loss = 0.42167961597442627, train/logprobs = tensor([[-0.6001, -1.4552],
        [-1.0496, -0.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047199126332998276
Epoch 0, Step 816: train/loss = 0.5043705105781555, train/raw-loss = 0.36389657855033875, train/logprobs = tensor([[-0.4574, -2.5753],
        [-0.8489, -0.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04682465270161629
Epoch 0, Step 817: train/loss = 0.44967782497406006, train/raw-loss = 0.31180596351623535, train/logprobs = tensor([[-0.4971, -3.0663],
        [-0.7614, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0459572933614254
Epoch 0, Step 818: train/loss = 0.6045995354652405, train/raw-loss = 0.4781646728515625, train/logprobs = tensor([[-0.4222, -1.2356],
        [-0.7344, -0.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04214494675397873
Epoch 0, Step 819: train/loss = 0.5148210525512695, train/raw-loss = 0.349371999502182, train/logprobs = tensor([[-0.5034, -2.6094],
        [-1.0253, -0.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055149681866168976
Epoch 0, Step 820: train/loss = 0.5545198917388916, train/raw-loss = 0.4206850528717041, train/logprobs = tensor([[-0.5408, -1.2212],
        [-1.1271, -0.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0446116104722023
Epoch 0, Step 821: train/loss = 0.5806571245193481, train/raw-loss = 0.45699989795684814, train/logprobs = tensor([[-0.5694, -1.2210],
        [-1.0611, -0.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0412190780043602
Epoch 0, Step 822: train/loss = 0.5081418752670288, train/raw-loss = 0.38081762194633484, train/logprobs = tensor([[-0.6183, -2.7209],
        [-0.9951, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042441412806510925
Epoch 0, Step 823: train/loss = 0.5736472606658936, train/raw-loss = 0.4196203947067261, train/logprobs = tensor([[-0.5510, -2.4846],
        [-0.8423, -0.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05134229734539986
Epoch 0, Step 824: train/loss = 0.5567503571510315, train/raw-loss = 0.3898903429508209, train/logprobs = tensor([[-0.5534, -1.7384],
        [-1.1349, -0.3228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05562000721693039
Epoch 0, Step 825: train/loss = 0.44247907400131226, train/raw-loss = 0.2552833557128906, train/logprobs = tensor([[-0.6412, -3.3949],
        [-1.1924, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06239856034517288
Epoch 0, Step 826: train/loss = 0.6014578938484192, train/raw-loss = 0.48321932554244995, train/logprobs = tensor([[-0.4501, -1.5420],
        [-0.8350, -0.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03941284865140915
Epoch 0, Step 827: train/loss = 0.5244643092155457, train/raw-loss = 0.3770376741886139, train/logprobs = tensor([[-0.5767, -3.2183],
        [-0.9444, -0.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04914220795035362
Epoch 0, Step 828: train/loss = 0.5182016491889954, train/raw-loss = 0.37897998094558716, train/logprobs = tensor([[-0.6335, -1.8178],
        [-1.2894, -0.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046407222747802734
Epoch 0, Step 829: train/loss = 0.42563074827194214, train/raw-loss = 0.28167209029197693, train/logprobs = tensor([[-0.5587, -4.9446],
        [-0.9367, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047986216843128204
Epoch 0, Step 830: train/loss = 0.5589199066162109, train/raw-loss = 0.4325820803642273, train/logprobs = tensor([[-0.3840, -2.0059],
        [-0.5653, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04211261123418808
Epoch 0, Step 831: train/loss = 0.5813572406768799, train/raw-loss = 0.4601362347602844, train/logprobs = tensor([[-0.5461, -0.6954],
        [-1.1119, -0.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04040699824690819
Epoch 0, Step 832: train/loss = 0.5298209190368652, train/raw-loss = 0.39435702562332153, train/logprobs = tensor([[-0.4185, -2.0559],
        [-0.6603, -0.4258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045154646039009094
Epoch 0, Step 833: train/loss = 0.42752987146377563, train/raw-loss = 0.2834204137325287, train/logprobs = tensor([[-0.5867, -3.3463],
        [-1.2871, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04803648591041565
Epoch 0, Step 834: train/loss = 0.45662936568260193, train/raw-loss = 0.32018086314201355, train/logprobs = tensor([[-0.6800, -5.7676],
        [-1.3087, -1.3906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04548283666372299
Epoch 0, Step 835: train/loss = 0.5533651113510132, train/raw-loss = 0.4482072591781616, train/logprobs = tensor([[-0.4585, -2.1862],
        [-0.6911, -0.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035052619874477386
Epoch 0, Step 836: train/loss = 0.5654056072235107, train/raw-loss = 0.4516059458255768, train/logprobs = tensor([[-0.4536, -1.5874],
        [-0.6983, -0.4056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037933215498924255
Epoch 0, Step 837: train/loss = 0.49791234731674194, train/raw-loss = 0.34169673919677734, train/logprobs = tensor([[-0.5500, -1.9713],
        [-1.1605, -0.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05207185819745064
Epoch 0, Step 838: train/loss = 0.5445812940597534, train/raw-loss = 0.41918766498565674, train/logprobs = tensor([[-0.4170, -1.5734],
        [-0.7893, -0.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04179787635803223
Epoch 0, Step 839: train/loss = 0.5208051204681396, train/raw-loss = 0.3982008993625641, train/logprobs = tensor([[-0.4881, -4.2747],
        [-0.7672, -0.4939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04086807742714882
Epoch 0, Step 840: train/loss = 0.5639573335647583, train/raw-loss = 0.437578409910202, train/logprobs = tensor([[-0.4878, -1.7223],
        [-0.8930, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04212632030248642
Epoch 0, Step 841: train/loss = 0.5632176399230957, train/raw-loss = 0.446394145488739, train/logprobs = tensor([[-0.4153, -1.5187],
        [-0.7090, -0.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038941141217947006
Epoch 0, Step 842: train/loss = 0.5075854659080505, train/raw-loss = 0.37239372730255127, train/logprobs = tensor([[-0.5505, -2.6901],
        [-0.9913, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04506389796733856
Epoch 0, Step 843: train/loss = 0.6433463096618652, train/raw-loss = 0.5286853313446045, train/logprobs = tensor([[-0.5154, -1.0071],
        [-0.8653, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03822034224867821
Epoch 0, Step 844: train/loss = 0.6490973234176636, train/raw-loss = 0.5242917537689209, train/logprobs = tensor([[-0.5385, -0.6265],
        [-0.9541, -0.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041601862758398056
Epoch 0, Step 845: train/loss = 0.6314468383789062, train/raw-loss = 0.5023401975631714, train/logprobs = tensor([[-0.4666, -0.8620],
        [-0.8153, -0.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043035540729761124
Epoch 0, Step 846: train/loss = 0.5178333520889282, train/raw-loss = 0.4180610179901123, train/logprobs = tensor([[-0.3493, -2.6985],
        [-0.5129, -0.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03325744718313217
Epoch 0, Step 847: train/loss = 0.5121020078659058, train/raw-loss = 0.4026806056499481, train/logprobs = tensor([[-0.4657, -2.2228],
        [-0.8666, -0.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03647379204630852
Epoch 0, Step 848: train/loss = 0.41149812936782837, train/raw-loss = 0.27252331376075745, train/logprobs = tensor([[-0.5164, -4.9309],
        [-0.9881, -0.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04632493481040001
Epoch 0, Step 849: train/loss = 0.5391160249710083, train/raw-loss = 0.4348122179508209, train/logprobs = tensor([[-0.5218, -1.2421],
        [-1.0422, -0.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03476793318986893
Epoch 0, Step 850: train/loss = 0.6150299310684204, train/raw-loss = 0.5135574340820312, train/logprobs = tensor([[-0.4832, -1.3254],
        [-0.7707, -0.4138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0338241346180439
Epoch 0, Step 851: train/loss = 0.5899560451507568, train/raw-loss = 0.482566773891449, train/logprobs = tensor([[-0.4205, -1.5266],
        [-0.6894, -0.3752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035796426236629486
Epoch 0, Step 852: train/loss = 0.5422765016555786, train/raw-loss = 0.4167925715446472, train/logprobs = tensor([[-0.5947, -2.1994],
        [-0.9587, -0.5015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0418279767036438
Epoch 0, Step 853: train/loss = 0.5442449450492859, train/raw-loss = 0.42937028408050537, train/logprobs = tensor([[-0.4378, -2.7301],
        [-0.6605, -0.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038291554898023605
Epoch 0, Step 854: train/loss = 0.49717003107070923, train/raw-loss = 0.3666650056838989, train/logprobs = tensor([[-0.5736, -2.1787],
        [-1.2035, -0.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04350167512893677
Epoch 0, Step 855: train/loss = 0.661950945854187, train/raw-loss = 0.5672563314437866, train/logprobs = tensor([[-0.4307, -0.3837],
        [-0.8050, -0.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031564854085445404
Epoch 0, Step 856: train/loss = 0.6511947512626648, train/raw-loss = 0.5555667281150818, train/logprobs = tensor([[-0.5036, -0.6392],
        [-0.7310, -0.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03187600523233414
Epoch 0, Step 857: train/loss = 0.5328534841537476, train/raw-loss = 0.4195924401283264, train/logprobs = tensor([[-0.5900, -1.4756],
        [-1.1191, -0.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03775367885828018
Epoch 0, Step 858: train/loss = 0.4622953236103058, train/raw-loss = 0.32610300183296204, train/logprobs = tensor([[-0.5822, -2.1802],
        [-1.1922, -0.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045397453010082245
Epoch 0, Step 859: train/loss = 0.5885694622993469, train/raw-loss = 0.4698149263858795, train/logprobs = tensor([[-0.3993, -1.2811],
        [-0.6102, -0.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03958483785390854
Epoch 0, Step 860: train/loss = 0.5842172503471375, train/raw-loss = 0.4687492549419403, train/logprobs = tensor([[-0.4039, -1.9552],
        [-0.8152, -0.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03848931938409805
Epoch 0, Step 861: train/loss = 0.6715306639671326, train/raw-loss = 0.5767980813980103, train/logprobs = tensor([[-0.3354, -0.3578],
        [-0.5395, -0.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03157752752304077
Epoch 0, Step 862: train/loss = 0.49598264694213867, train/raw-loss = 0.3486550450325012, train/logprobs = tensor([[-0.5083, -2.2193],
        [-0.9482, -0.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04910919815301895
Epoch 0, Step 863: train/loss = 0.44759732484817505, train/raw-loss = 0.3044268786907196, train/logprobs = tensor([[-0.4828, -5.2086],
        [-0.9043, -0.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04772348329424858
Epoch 0, Step 864: train/loss = 0.5324202179908752, train/raw-loss = 0.40401437878608704, train/logprobs = tensor([[-0.4350, -2.5158],
        [-0.6699, -0.3515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042801953852176666
Epoch 0, Step 865: train/loss = 0.6334618330001831, train/raw-loss = 0.5472813844680786, train/logprobs = tensor([[-0.3705, -0.8588],
        [-0.5181, -0.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028726812452077866
Epoch 0, Step 866: train/loss = 0.47704192996025085, train/raw-loss = 0.33122366666793823, train/logprobs = tensor([[-0.4117, -2.5558],
        [-0.7651, -0.5553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04860610514879227
Epoch 0, Step 867: train/loss = 0.565580427646637, train/raw-loss = 0.4405369162559509, train/logprobs = tensor([[-0.4895, -1.2020],
        [-0.9541, -0.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041681185364723206
Epoch 0, Step 868: train/loss = 0.52717524766922, train/raw-loss = 0.40061652660369873, train/logprobs = tensor([[-0.4175, -2.3397],
        [-0.7897, -0.5738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04218624159693718
Epoch 0, Step 869: train/loss = 0.4594292640686035, train/raw-loss = 0.3329402804374695, train/logprobs = tensor([[-0.4966, -2.2739],
        [-0.8768, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04216298833489418
Epoch 0, Step 870: train/loss = 0.5455496311187744, train/raw-loss = 0.4056706428527832, train/logprobs = tensor([[-0.4692, -1.7018],
        [-0.9139, -0.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046626314520835876
Epoch 0, Step 871: train/loss = 0.5448004603385925, train/raw-loss = 0.4208778142929077, train/logprobs = tensor([[-0.4494, -2.0930],
        [-0.6930, -0.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04130755737423897
Epoch 0, Step 872: train/loss = 0.5108992457389832, train/raw-loss = 0.39420831203460693, train/logprobs = tensor([[-0.4901, -4.2736],
        [-0.8278, -0.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03889697045087814
Epoch 0, Step 873: train/loss = 0.49158844351768494, train/raw-loss = 0.34587547183036804, train/logprobs = tensor([[-0.5405, -2.0033],
        [-1.1037, -0.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04857099428772926
Epoch 0, Step 874: train/loss = 0.6145081520080566, train/raw-loss = 0.5052716732025146, train/logprobs = tensor([[-0.4005, -1.8438],
        [-0.6257, -0.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03641214594244957
Epoch 0, Step 875: train/loss = 0.4755828380584717, train/raw-loss = 0.3318708539009094, train/logprobs = tensor([[-0.5514, -2.4701],
        [-1.1191, -0.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04790399968624115
Epoch 0, Step 876: train/loss = 0.5198961496353149, train/raw-loss = 0.37752795219421387, train/logprobs = tensor([[-0.5925, -1.4634],
        [-1.2147, -0.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0474560484290123
Epoch 0, Step 877: train/loss = 0.524634599685669, train/raw-loss = 0.404945969581604, train/logprobs = tensor([[-0.3952, -2.0424],
        [-0.6474, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03989622741937637
Epoch 0, Step 878: train/loss = 0.48317793011665344, train/raw-loss = 0.3610975444316864, train/logprobs = tensor([[-0.4525, -3.5728],
        [-0.7059, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04069347307085991
Epoch 0, Step 879: train/loss = 0.623835027217865, train/raw-loss = 0.5279743671417236, train/logprobs = tensor([[-0.4405, -3.2336],
        [-0.5771, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03195355460047722
Epoch 0, Step 880: train/loss = 0.5339761972427368, train/raw-loss = 0.3610442578792572, train/logprobs = tensor([[-0.4807, -2.0743],
        [-0.9698, -0.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05764397978782654
Epoch 0, Step 881: train/loss = 0.5668786764144897, train/raw-loss = 0.44820359349250793, train/logprobs = tensor([[-0.5890, -0.9477],
        [-1.1590, -0.1626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03955836221575737
Epoch 0, Step 882: train/loss = 0.4846187233924866, train/raw-loss = 0.3678174912929535, train/logprobs = tensor([[-0.5590, -3.4539],
        [-1.1089, -0.4997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893374651670456
Epoch 0, Step 883: train/loss = 0.494909405708313, train/raw-loss = 0.3495379090309143, train/logprobs = tensor([[-0.4958, -4.1971],
        [-1.0077, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048457175493240356
Epoch 0, Step 884: train/loss = 0.4295359253883362, train/raw-loss = 0.3099013864994049, train/logprobs = tensor([[-0.4217, -4.1309],
        [-0.7525, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03987817466259003
Epoch 0, Step 885: train/loss = 0.6426737308502197, train/raw-loss = 0.5421096682548523, train/logprobs = tensor([[-0.4240, -1.1149],
        [-0.5867, -0.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03352135792374611
Epoch 0, Step 886: train/loss = 0.49129432439804077, train/raw-loss = 0.3449587821960449, train/logprobs = tensor([[-0.5785, -2.6017],
        [-1.0884, -0.4021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048778511583805084
Epoch 0, Step 887: train/loss = 0.5685733556747437, train/raw-loss = 0.4462694525718689, train/logprobs = tensor([[-0.3312, -1.4247],
        [-0.6009, -0.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04076794534921646
Epoch 0, Step 888: train/loss = 0.600979208946228, train/raw-loss = 0.4606165289878845, train/logprobs = tensor([[-0.4724, -1.1445],
        [-0.7727, -0.2063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04678754508495331
Epoch 0, Step 889: train/loss = 0.5213665962219238, train/raw-loss = 0.38394951820373535, train/logprobs = tensor([[-0.5759, -1.5543],
        [-1.1177, -0.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04580569267272949
Epoch 0, Step 890: train/loss = 0.4745984375476837, train/raw-loss = 0.3344331979751587, train/logprobs = tensor([[-0.5044, -2.1482],
        [-0.9744, -0.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04672173783183098
Epoch 0, Step 891: train/loss = 0.5183414220809937, train/raw-loss = 0.3924570083618164, train/logprobs = tensor([[-0.4523, -2.3351],
        [-0.7992, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04196147620677948
Epoch 0, Step 892: train/loss = 0.48501473665237427, train/raw-loss = 0.3454331159591675, train/logprobs = tensor([[-0.5025, -2.8485],
        [-0.9556, -0.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046527210623025894
Epoch 0, Step 893: train/loss = 0.48982924222946167, train/raw-loss = 0.35058286786079407, train/logprobs = tensor([[-0.4596, -2.4909],
        [-0.8488, -0.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04641546308994293
Epoch 0, Step 894: train/loss = 0.6793992519378662, train/raw-loss = 0.5786991119384766, train/logprobs = tensor([[-0.5891, -0.2554],
        [-0.9922, -0.1416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03356671705842018
Epoch 0, Step 895: train/loss = 0.4910370111465454, train/raw-loss = 0.36446747183799744, train/logprobs = tensor([[-0.5840, -1.5025],
        [-1.2766, -0.3736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04218984767794609
Epoch 0, Step 896: train/loss = 0.5419563055038452, train/raw-loss = 0.420759379863739, train/logprobs = tensor([[-0.5715, -1.8322],
        [-1.0412, -0.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040398966521024704
Epoch 0, Step 897: train/loss = 0.5814175605773926, train/raw-loss = 0.4493289887905121, train/logprobs = tensor([[-0.5241, -1.6222],
        [-1.0386, -0.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044029541313648224
Epoch 0, Step 898: train/loss = 0.6132032871246338, train/raw-loss = 0.5064011812210083, train/logprobs = tensor([[-0.3977, -1.7690],
        [-0.6267, -0.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0356006883084774
Epoch 0, Step 899: train/loss = 0.5382773280143738, train/raw-loss = 0.4184027314186096, train/logprobs = tensor([[-0.4619, -1.3559],
        [-0.9137, -0.2619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03995819017291069
Epoch 0, Step 900: train/loss = 0.615350067615509, train/raw-loss = 0.5282832384109497, train/logprobs = tensor([[-0.4202, -0.8377],
        [-0.6616, -0.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029022280126810074
Epoch 0, Step 901: train/loss = 0.6132379770278931, train/raw-loss = 0.4846818745136261, train/logprobs = tensor([[-0.4995, -1.1420],
        [-0.8570, -0.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0428520105779171
Epoch 0, Step 902: train/loss = 0.47006839513778687, train/raw-loss = 0.33466315269470215, train/logprobs = tensor([[-0.4441, -3.5489],
        [-0.7988, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04513509199023247
Epoch 0, Step 903: train/loss = 0.5412980914115906, train/raw-loss = 0.4327332079410553, train/logprobs = tensor([[-0.3980, -2.0428],
        [-0.6586, -0.4252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03618829697370529
Epoch 0, Step 904: train/loss = 0.46937626600265503, train/raw-loss = 0.3539755046367645, train/logprobs = tensor([[-0.4188, -3.5052],
        [-0.6693, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038466926664114
Epoch 0, Step 905: train/loss = 0.6014423370361328, train/raw-loss = 0.46416807174682617, train/logprobs = tensor([[-0.5236, -0.7542],
        [-1.1264, -0.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04575810208916664
Epoch 0, Step 906: train/loss = 0.4017229378223419, train/raw-loss = 0.2883743643760681, train/logprobs = tensor([[-0.5031, -4.7879],
        [-0.8627, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037782855331897736
Epoch 0, Step 907: train/loss = 0.5545200109481812, train/raw-loss = 0.4352472722530365, train/logprobs = tensor([[-0.5305, -1.9780],
        [-0.8620, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03975757956504822
Epoch 0, Step 908: train/loss = 0.41062331199645996, train/raw-loss = 0.2602371573448181, train/logprobs = tensor([[-0.5495, -3.4354],
        [-1.2000, -0.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050128720700740814
Epoch 0, Step 909: train/loss = 0.4602699279785156, train/raw-loss = 0.32475781440734863, train/logprobs = tensor([[-0.4091, -3.5175],
        [-0.8028, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04517070949077606
Epoch 0, Step 910: train/loss = 0.5061814785003662, train/raw-loss = 0.3815973997116089, train/logprobs = tensor([[-0.5496, -3.0335],
        [-1.2059, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041528016328811646
Epoch 0, Step 911: train/loss = 0.5278165340423584, train/raw-loss = 0.3952395021915436, train/logprobs = tensor([[-0.5400, -1.9001],
        [-0.9250, -0.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0441923514008522
Epoch 0, Step 912: train/loss = 0.47435086965560913, train/raw-loss = 0.3793996572494507, train/logprobs = tensor([[-0.4441, -3.3895],
        [-0.6126, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031650397926568985
Epoch 0, Step 913: train/loss = 0.59483802318573, train/raw-loss = 0.5004997253417969, train/logprobs = tensor([[-0.4988, -1.1159],
        [-0.9087, -0.4672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03144609183073044
Epoch 0, Step 914: train/loss = 0.5134931802749634, train/raw-loss = 0.3768158257007599, train/logprobs = tensor([[-0.4227, -2.5022],
        [-0.6930, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0455591045320034
Epoch 0, Step 915: train/loss = 0.5206357836723328, train/raw-loss = 0.4076259732246399, train/logprobs = tensor([[-0.5097, -3.7164],
        [-0.8430, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03766993060708046
Epoch 0, Step 916: train/loss = 0.6707004308700562, train/raw-loss = 0.5747254490852356, train/logprobs = tensor([[-0.4080, -0.6223],
        [-0.6362, -0.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031991664320230484
Epoch 0, Step 917: train/loss = 0.5679789781570435, train/raw-loss = 0.4624500572681427, train/logprobs = tensor([[-0.4678, -2.0577],
        [-0.7192, -0.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03517630696296692
Epoch 0, Step 918: train/loss = 0.606048047542572, train/raw-loss = 0.48180267214775085, train/logprobs = tensor([[-0.4654, -1.7413],
        [-0.8791, -0.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04141513258218765
Epoch 0, Step 919: train/loss = 0.6066908836364746, train/raw-loss = 0.5167899131774902, train/logprobs = tensor([[-0.3323, -1.1158],
        [-0.5363, -0.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029966993257403374
Epoch 0, Step 920: train/loss = 0.45121610164642334, train/raw-loss = 0.30636897683143616, train/logprobs = tensor([[-0.5475, -2.2332],
        [-1.1475, -0.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048282377421855927
Epoch 0, Step 921: train/loss = 0.5836843252182007, train/raw-loss = 0.46389350295066833, train/logprobs = tensor([[-0.6041, -1.2175],
        [-1.0974, -0.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039930298924446106
Epoch 0, Step 922: train/loss = 0.5149727463722229, train/raw-loss = 0.3817770481109619, train/logprobs = tensor([[-0.4776, -2.2034],
        [-1.1233, -0.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04439856857061386
Epoch 0, Step 923: train/loss = 0.5112375617027283, train/raw-loss = 0.3781353533267975, train/logprobs = tensor([[-0.4788, -1.9522],
        [-0.8027, -0.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04436740279197693
Epoch 0, Step 924: train/loss = 0.4462231695652008, train/raw-loss = 0.31002116203308105, train/logprobs = tensor([[-0.6372, -6.4104],
        [-1.1147, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045400675386190414
Epoch 0, Step 925: train/loss = 0.6365223526954651, train/raw-loss = 0.5566362738609314, train/logprobs = tensor([[-0.5090, -0.5520],
        [-0.8138, -0.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026628702878952026
Epoch 0, Step 926: train/loss = 0.425931453704834, train/raw-loss = 0.29009538888931274, train/logprobs = tensor([[-0.5761, -4.1423],
        [-1.1666, -0.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04527868703007698
Epoch 0, Step 927: train/loss = 0.46559619903564453, train/raw-loss = 0.3272254168987274, train/logprobs = tensor([[-0.5761, -3.8753],
        [-1.1099, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04612359404563904
Epoch 0, Step 928: train/loss = 0.4369167983531952, train/raw-loss = 0.3203553557395935, train/logprobs = tensor([[-0.5014, -3.5783],
        [-0.8757, -0.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03885380178689957
Epoch 0, Step 929: train/loss = 0.6057038903236389, train/raw-loss = 0.4993775486946106, train/logprobs = tensor([[-0.4218, -1.0653],
        [-0.6765, -0.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035442110151052475
Epoch 0, Step 930: train/loss = 0.4876980781555176, train/raw-loss = 0.330674409866333, train/logprobs = tensor([[-0.5908, -2.2508],
        [-1.2894, -0.4511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05234123021364212
Epoch 0, Step 931: train/loss = 0.5665239095687866, train/raw-loss = 0.4500619173049927, train/logprobs = tensor([[-0.4019, -1.6928],
        [-0.6403, -0.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03882066532969475
Epoch 0, Step 932: train/loss = 0.48207542300224304, train/raw-loss = 0.3548556864261627, train/logprobs = tensor([[-0.4820, -2.2059],
        [-0.9806, -0.3161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042406581342220306
Epoch 0, Step 933: train/loss = 0.5800144076347351, train/raw-loss = 0.47881945967674255, train/logprobs = tensor([[-0.5107, -1.4935],
        [-0.8804, -0.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03373166173696518
Epoch 0, Step 934: train/loss = 0.4137200117111206, train/raw-loss = 0.2657153010368347, train/logprobs = tensor([[-0.5374, -3.1247],
        [-1.1076, -0.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04933490231633186
Epoch 0, Step 935: train/loss = 0.5631722211837769, train/raw-loss = 0.4696151912212372, train/logprobs = tensor([[-0.4897, -1.4900],
        [-0.9907, -0.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031185684725642204
Epoch 0, Step 936: train/loss = 0.6038450598716736, train/raw-loss = 0.5024133324623108, train/logprobs = tensor([[-0.4995, -0.7472],
        [-0.9459, -0.2986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0338105708360672
Epoch 0, Step 937: train/loss = 0.5257740616798401, train/raw-loss = 0.38671234250068665, train/logprobs = tensor([[-0.4445, -2.2447],
        [-0.8359, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046353910118341446
Epoch 0, Step 938: train/loss = 0.5176756978034973, train/raw-loss = 0.4057994484901428, train/logprobs = tensor([[-0.3959, -1.7686],
        [-0.6112, -0.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03729208558797836
Epoch 0, Step 939: train/loss = 0.5203847885131836, train/raw-loss = 0.4006992280483246, train/logprobs = tensor([[-0.4420, -2.2831],
        [-0.7052, -0.4021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03989517316222191
Epoch 0, Step 940: train/loss = 0.46114492416381836, train/raw-loss = 0.3182634115219116, train/logprobs = tensor([[-0.5654, -2.0694],
        [-1.2163, -0.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047627173364162445
Epoch 0, Step 941: train/loss = 0.5487443804740906, train/raw-loss = 0.44009697437286377, train/logprobs = tensor([[-0.5566, -2.1374],
        [-0.9241, -0.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03621581196784973
Epoch 0, Step 942: train/loss = 0.5708156228065491, train/raw-loss = 0.4635665714740753, train/logprobs = tensor([[-0.4331, -2.4473],
        [-0.7781, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03574967756867409
Epoch 0, Step 943: train/loss = 0.5428892970085144, train/raw-loss = 0.43901634216308594, train/logprobs = tensor([[-0.5350, -2.1307],
        [-1.0087, -0.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034624312072992325
Epoch 0, Step 944: train/loss = 0.6047001481056213, train/raw-loss = 0.48588991165161133, train/logprobs = tensor([[-0.5329, -1.0389],
        [-0.9049, -0.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039603400975465775
Epoch 0, Step 945: train/loss = 0.5726821422576904, train/raw-loss = 0.4854472577571869, train/logprobs = tensor([[-0.4224, -2.5776],
        [-0.6673, -0.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029078301042318344
Epoch 0, Step 946: train/loss = 0.5992361903190613, train/raw-loss = 0.48200753331184387, train/logprobs = tensor([[-0.4857, -1.1745],
        [-0.9282, -0.2860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03907622769474983
Epoch 0, Step 947: train/loss = 0.6204274892807007, train/raw-loss = 0.5238736271858215, train/logprobs = tensor([[-0.4243, -0.6153],
        [-0.7987, -0.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032184623181819916
Epoch 0, Step 948: train/loss = 0.6014150381088257, train/raw-loss = 0.48622313141822815, train/logprobs = tensor([[-0.4936, -0.6078],
        [-1.0041, -0.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03839730843901634
Epoch 0, Step 949: train/loss = 0.5289779901504517, train/raw-loss = 0.4156705141067505, train/logprobs = tensor([[-0.5745, -1.3792],
        [-1.0523, -0.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03776915743947029
Epoch 0, Step 950: train/loss = 0.5309462547302246, train/raw-loss = 0.43516260385513306, train/logprobs = tensor([[-0.3971, -3.7394],
        [-0.6287, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03192789852619171
Epoch 0, Step 951: train/loss = 0.5681833028793335, train/raw-loss = 0.4699287414550781, train/logprobs = tensor([[-0.5822, -1.0099],
        [-1.0885, -0.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032751522958278656
Epoch 0, Step 952: train/loss = 0.6125355958938599, train/raw-loss = 0.5247989892959595, train/logprobs = tensor([[-0.3652, -1.4250],
        [-0.5544, -0.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029245536774396896
Epoch 0, Step 953: train/loss = 0.4265986979007721, train/raw-loss = 0.306102454662323, train/logprobs = tensor([[-0.5011, -4.9532],
        [-0.9238, -0.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040165431797504425
Epoch 0, Step 954: train/loss = 0.5889540314674377, train/raw-loss = 0.5002062320709229, train/logprobs = tensor([[-0.3582, -1.1423],
        [-0.5873, -0.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02958259917795658
Epoch 0, Step 955: train/loss = 0.4849250614643097, train/raw-loss = 0.3497195243835449, train/logprobs = tensor([[-0.5088, -2.9235],
        [-0.9081, -0.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045068517327308655
Epoch 0, Step 956: train/loss = 0.5665637254714966, train/raw-loss = 0.4783497750759125, train/logprobs = tensor([[-0.4522, -2.5752],
        [-0.6357, -0.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029404636472463608
Epoch 0, Step 957: train/loss = 0.5155038833618164, train/raw-loss = 0.39691948890686035, train/logprobs = tensor([[-0.4293, -1.6488],
        [-0.8361, -0.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039528124034404755
Epoch 0, Step 958: train/loss = 0.5981802344322205, train/raw-loss = 0.5080270767211914, train/logprobs = tensor([[-0.3316, -1.6806],
        [-0.5484, -0.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030051052570343018
Epoch 0, Step 959: train/loss = 0.5900884866714478, train/raw-loss = 0.4793907701969147, train/logprobs = tensor([[-0.5064, -1.1363],
        [-0.8680, -0.2057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03689923882484436
Epoch 0, Step 960: train/loss = 0.5630419254302979, train/raw-loss = 0.4490485191345215, train/logprobs = tensor([[-0.4976, -1.4125],
        [-0.7917, -0.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03799782320857048
Epoch 0, Step 961: train/loss = 0.6695678234100342, train/raw-loss = 0.5822809934616089, train/logprobs = tensor([[-0.3735, -0.6155],
        [-0.5956, -0.3424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029095619916915894
Epoch 0, Step 962: train/loss = 0.5479826927185059, train/raw-loss = 0.41295158863067627, train/logprobs = tensor([[-0.5407, -1.2913],
        [-1.0565, -0.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045010361820459366
Epoch 0, Step 963: train/loss = 0.5152034759521484, train/raw-loss = 0.40002021193504333, train/logprobs = tensor([[-0.5053, -4.5230],
        [-0.8259, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03839441388845444
Epoch 0, Step 964: train/loss = 0.5468798279762268, train/raw-loss = 0.4301852881908417, train/logprobs = tensor([[-0.4598, -2.8549],
        [-0.6751, -0.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03889819234609604
Epoch 0, Step 965: train/loss = 0.46181169152259827, train/raw-loss = 0.3132421672344208, train/logprobs = tensor([[-0.3838, -3.4252],
        [-0.6996, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04952317476272583
Epoch 0, Step 966: train/loss = 0.5128448009490967, train/raw-loss = 0.39825233817100525, train/logprobs = tensor([[-0.4758, -3.0106],
        [-0.8691, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03819749504327774
Epoch 0, Step 967: train/loss = 0.5327357053756714, train/raw-loss = 0.3997136354446411, train/logprobs = tensor([[-0.4961, -2.1463],
        [-0.8887, -0.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04434068873524666
Epoch 0, Step 968: train/loss = 0.4466792941093445, train/raw-loss = 0.3135310411453247, train/logprobs = tensor([[-0.5397, -2.1076],
        [-1.2561, -0.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04438275843858719
Epoch 0, Step 969: train/loss = 0.5694544315338135, train/raw-loss = 0.44359689950942993, train/logprobs = tensor([[-0.5647, -1.3444],
        [-1.1518, -0.3480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04195253178477287
Epoch 0, Step 970: train/loss = 0.47190621495246887, train/raw-loss = 0.3589789867401123, train/logprobs = tensor([[-0.3721, -3.0667],
        [-0.6145, -0.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03764241933822632
Epoch 0, Step 971: train/loss = 0.5437740087509155, train/raw-loss = 0.4147850573062897, train/logprobs = tensor([[-0.3849, -1.6594],
        [-0.7601, -0.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042996324598789215
Epoch 0, Step 972: train/loss = 0.4646691679954529, train/raw-loss = 0.34775811433792114, train/logprobs = tensor([[-0.4779, -2.4812],
        [-0.9857, -0.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03897036612033844
Epoch 0, Step 973: train/loss = 0.5155846476554871, train/raw-loss = 0.40961018204689026, train/logprobs = tensor([[-0.4690, -2.9886],
        [-0.8500, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0353248231112957
Epoch 0, Step 974: train/loss = 0.490084171295166, train/raw-loss = 0.36708056926727295, train/logprobs = tensor([[-0.5055, -4.9071],
        [-1.0665, -0.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04100121185183525
Epoch 0, Step 975: train/loss = 0.43905550241470337, train/raw-loss = 0.2643515467643738, train/logprobs = tensor([[-0.6833, -3.0942],
        [-1.4847, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823465809226036
Epoch 0, Step 976: train/loss = 0.49066275358200073, train/raw-loss = 0.3655458092689514, train/logprobs = tensor([[-0.5003, -2.5836],
        [-0.8792, -0.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0417056605219841
Epoch 0, Step 977: train/loss = 0.5930221676826477, train/raw-loss = 0.495890736579895, train/logprobs = tensor([[-0.4317, -3.3667],
        [-0.7008, -0.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03237716853618622
Epoch 0, Step 978: train/loss = 0.5278358459472656, train/raw-loss = 0.4026939272880554, train/logprobs = tensor([[-0.4721, -2.7986],
        [-0.9171, -0.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04171396791934967
Epoch 0, Step 979: train/loss = 0.543792724609375, train/raw-loss = 0.43973082304000854, train/logprobs = tensor([[-0.3821, -2.8230],
        [-0.7717, -0.5053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03468730300664902
Epoch 0, Step 980: train/loss = 0.4762303829193115, train/raw-loss = 0.341560035943985, train/logprobs = tensor([[-0.4137, -2.7081],
        [-0.8250, -0.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044890109449625015
Epoch 0, Step 981: train/loss = 0.6008484959602356, train/raw-loss = 0.5095518827438354, train/logprobs = tensor([[-0.3720, -0.9883],
        [-0.6273, -0.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030432209372520447
Epoch 0, Step 982: train/loss = 0.5173984169960022, train/raw-loss = 0.4134480357170105, train/logprobs = tensor([[-0.4481, -1.7824],
        [-0.7295, -0.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465011715888977
Epoch 0, Step 983: train/loss = 0.5242993831634521, train/raw-loss = 0.41131845116615295, train/logprobs = tensor([[-0.4918, -1.7650],
        [-0.9247, -0.4235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03766030818223953
Epoch 0, Step 984: train/loss = 0.5150829553604126, train/raw-loss = 0.3941090703010559, train/logprobs = tensor([[-0.5875, -1.8197],
        [-1.1817, -0.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0403246209025383
Epoch 0, Step 985: train/loss = 0.5411292910575867, train/raw-loss = 0.43011271953582764, train/logprobs = tensor([[-0.4414, -1.4782],
        [-0.8183, -0.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037005532532930374
Epoch 0, Step 986: train/loss = 0.4809785783290863, train/raw-loss = 0.36188939213752747, train/logprobs = tensor([[-0.4235, -3.1005],
        [-0.8814, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039696402847766876
Epoch 0, Step 987: train/loss = 0.5048829913139343, train/raw-loss = 0.3548947870731354, train/logprobs = tensor([[-0.5116, -2.3862],
        [-0.9756, -0.3958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04999607428908348
Epoch 0, Step 988: train/loss = 0.4226202964782715, train/raw-loss = 0.31128448247909546, train/logprobs = tensor([[-0.4626, -3.4896],
        [-0.8762, -0.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03711194172501564
Epoch 0, Step 989: train/loss = 0.556930661201477, train/raw-loss = 0.4602803587913513, train/logprobs = tensor([[-0.4435, -1.7198],
        [-0.7080, -0.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03221677243709564
Epoch 0, Step 990: train/loss = 0.5879673957824707, train/raw-loss = 0.494753360748291, train/logprobs = tensor([[-0.4355, -1.4565],
        [-0.7739, -0.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03107132762670517
Epoch 0, Step 991: train/loss = 0.5356832146644592, train/raw-loss = 0.4225032925605774, train/logprobs = tensor([[-0.4046, -1.9551],
        [-0.8020, -0.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03772665560245514
Epoch 0, Step 992: train/loss = 0.5517865419387817, train/raw-loss = 0.43010804057121277, train/logprobs = tensor([[-0.4848, -1.5232],
        [-0.8517, -0.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040559493005275726
Epoch 0, Step 993: train/loss = 0.5256702899932861, train/raw-loss = 0.4029742181301117, train/logprobs = tensor([[-0.4338, -1.9016],
        [-0.8538, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04089868441224098
Epoch 0, Step 994: train/loss = 0.5998209118843079, train/raw-loss = 0.461903840303421, train/logprobs = tensor([[-0.5556, -1.4536],
        [-0.9475, -0.2485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04597236588597298
Epoch 0, Step 995: train/loss = 0.4881691634654999, train/raw-loss = 0.31112298369407654, train/logprobs = tensor([[-0.6474, -1.9086],
        [-1.4762, -0.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059015389531850815
Epoch 0, Step 996: train/loss = 0.4245848059654236, train/raw-loss = 0.3000647723674774, train/logprobs = tensor([[-0.5043, -3.4640],
        [-1.0080, -0.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04150667414069176
Epoch 0, Step 997: train/loss = 0.45577651262283325, train/raw-loss = 0.34122467041015625, train/logprobs = tensor([[-0.4537, -3.0882],
        [-0.9133, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038183942437171936
Epoch 0, Step 998: train/loss = 0.5284485816955566, train/raw-loss = 0.43411317467689514, train/logprobs = tensor([[-0.4062, -3.4498],
        [-0.6116, -0.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031445134431123734
Epoch 0, Step 999: train/loss = 0.5356489419937134, train/raw-loss = 0.4195716977119446, train/logprobs = tensor([[-0.5249, -1.7523],
        [-0.9263, -0.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038692399859428406
