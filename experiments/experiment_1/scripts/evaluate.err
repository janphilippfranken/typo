Processing examples: 0it [00:00, ?it/s]
Processed prompts:   0%|          | 0/1000 [00:00<?, ?it/s][A
Processed prompts:   0%|          | 1/1000 [00:16<4:35:03, 16.52s/it][A
Processed prompts:   0%|          | 2/1000 [00:17<2:00:59,  7.27s/it][A
Processed prompts:   0%|          | 3/1000 [00:19<1:23:31,  5.03s/it][A
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 257/1000 [00:36<01:11, 10.41it/s][A
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 259/1000 [00:38<01:17,  9.62it/s][A
Processed prompts:  26%|â–ˆâ–ˆâ–Œ       | 260/1000 [00:39<01:25,  8.65it/s][A
Processed prompts:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 513/1000 [00:56<00:38, 12.57it/s][A
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 515/1000 [00:58<00:41, 11.77it/s][A
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 516/1000 [00:58<00:41, 11.74it/s][A
Processed prompts:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 517/1000 [00:59<00:47, 10.19it/s][A
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 769/1000 [01:14<00:15, 15.00it/s][A
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 771/1000 [01:16<00:17, 13.43it/s][A
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 772/1000 [01:16<00:17, 12.89it/s][A
Processed prompts:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 774/1000 [01:17<00:19, 11.60it/s][A
Processed prompts:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 775/1000 [01:18<00:20, 11.10it/s][AProcessed prompts: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [01:18<00:00, 12.79it/s]
Processing examples: 500it [01:18,  6.36it/s]Processing examples: 500it [01:18,  6.36it/s]
ERROR: Cannot find key: start_example=0
Usage: evaluate.py <group|command|value>
  available groups:      json | fire | hydra | np | random | List | Dict |
                         transformers | CONSTITUTIONS
  available commands:    DictConfig | tqdm | load_dataset |
                         VLLMInferenceModel | get_first_question |
                         format_responses | format_example | tokenize_func |
                         shuffle_principles | main
  available values:      PROMPT_GENERATION_ITERATION_0 | PROMPT_TRAINING |
                         SYSTEM_MESSAGE | GPT4_WIN_RATE | HELPFUL_PRINCIPLE |
                         NOT_HELPFUL_PRINCIPLE | HARMLESS_PRINCIPLE |
                         NOT_HARMLESS_PRINCIPLE

For detailed information on this command, run:
  evaluate.py --help
