{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
{'evaluate_before_training': False, 'evaluate': False, 'n_epochs': 1, 'lr': 1e-06, 'train_batch_size': 1, 'eval_batch_size': 1, 'train_split': 1.0, 'checkpoint_dir': '/scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6', 'max_grad_norm': 1.0, 'num_warmup_steps': 1, 'gradient_accumulation_steps': 32, 'save_after_n_steps': False, 'seed': 42, 'model_archive': None}
[2024-03-12 13:04:23,892][root][INFO] - beta: 1.0
[2024-03-12 13:04:23,892][root][INFO] - writing checkpoints to: /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/typo/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
data/helpful.json
data/harmless.json
n helpful: 5000
n harmless: 4497
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:The most common cuss words in English include:\n\n- F**k\n- S**t\n- B**ch\n- A**hole\n- D**k\n- M**therf**cker\n- P**ssy\n- C**nt\n- B**stard\n- F**king\n\nThese words are considered offensive and should be used with caution.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6.
9497
tokenized 9497 training examples...
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/typo/trained_models/Mistral-7B-v0.1/checkpoints-exp-2-v2/typo-beta-1.0-1e-6.
Epoch 0, Step 0: train/loss = 0.6620960831642151, train/raw-loss = 0.6620960831642151, train/logprobs = tensor([[-0.3952, -0.9240],
        [-0.4065, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6420053839683533, train/raw-loss = 0.6420053839683533, train/logprobs = tensor([[-0.5405, -1.5422],
        [-0.6608, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.648223876953125, train/raw-loss = 0.648223876953125, train/logprobs = tensor([[-0.5796, -0.7355],
        [-0.6749, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6815508008003235, train/raw-loss = 0.6815508008003235, train/logprobs = tensor([[-0.5584, -0.6571],
        [-0.5978, -0.6489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6200114488601685, train/raw-loss = 0.6200114488601685, train/logprobs = tensor([[-0.5345, -1.6639],
        [-0.5903, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6259200572967529, train/raw-loss = 0.6259200572967529, train/logprobs = tensor([[-0.5387, -1.1613],
        [-0.6376, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5854754447937012, train/raw-loss = 0.5854754447937012, train/logprobs = tensor([[-0.8356, -1.9960],
        [-0.9265, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6477792263031006, train/raw-loss = 0.6477792263031006, train/logprobs = tensor([[-0.7542, -0.8753],
        [-0.8613, -0.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6741445064544678, train/raw-loss = 0.6741445064544678, train/logprobs = tensor([[-0.5970, -1.2069],
        [-0.6274, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6704362034797668, train/raw-loss = 0.6704362034797668, train/logprobs = tensor([[-0.5219, -1.0500],
        [-0.5673, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6473487019538879, train/raw-loss = 0.6473487019538879, train/logprobs = tensor([[-0.6899, -0.8627],
        [-0.8028, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.556951105594635, train/raw-loss = 0.556951105594635, train/logprobs = tensor([[-0.6021, -2.1695],
        [-0.7861, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.5781970024108887, train/raw-loss = 0.5781970024108887, train/logprobs = tensor([[-0.5147, -1.3729],
        [-0.5638, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6632786989212036, train/raw-loss = 0.6632786989212036, train/logprobs = tensor([[-0.5841, -0.7987],
        [-0.6759, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6105536222457886, train/raw-loss = 0.6105536222457886, train/logprobs = tensor([[-0.4188, -1.2342],
        [-0.4967, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6820335388183594, train/raw-loss = 0.6820335388183594, train/logprobs = tensor([[-0.5428, -0.6056],
        [-0.5735, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6424199342727661, train/raw-loss = 0.6424199342727661, train/logprobs = tensor([[-0.5553, -0.8147],
        [-0.6350, -0.6806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6062963008880615, train/raw-loss = 0.6062963008880615, train/logprobs = tensor([[-0.5965, -1.2041],
        [-0.6877, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6636954545974731, train/raw-loss = 0.6636954545974731, train/logprobs = tensor([[-0.5903, -0.7719],
        [-0.6680, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6492085456848145, train/raw-loss = 0.6492085456848145, train/logprobs = tensor([[-0.5621, -0.8725],
        [-0.6065, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6254516243934631, train/raw-loss = 0.6254516243934631, train/logprobs = tensor([[-0.6648, -0.9940],
        [-0.8612, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6369717717170715, train/raw-loss = 0.6369717717170715, train/logprobs = tensor([[-0.7577, -1.0841],
        [-0.8775, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.667330265045166, train/raw-loss = 0.667330265045166, train/logprobs = tensor([[-0.4995, -0.6944],
        [-0.5504, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.666772723197937, train/raw-loss = 0.666772723197937, train/logprobs = tensor([[-0.4307, -0.8033],
        [-0.4719, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6070340275764465, train/raw-loss = 0.6070340275764465, train/logprobs = tensor([[-0.5545, -1.0935],
        [-0.6934, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6666252613067627, train/raw-loss = 0.6666252613067627, train/logprobs = tensor([[-0.6132, -0.7962],
        [-0.6944, -0.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6860550045967102, train/raw-loss = 0.6860550045967102, train/logprobs = tensor([[-0.4812, -1.0133],
        [-0.5079, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5482037663459778, train/raw-loss = 0.5482037663459778, train/logprobs = tensor([[-0.5267, -2.5026],
        [-0.6398, -1.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6459858417510986, train/raw-loss = 0.6459858417510986, train/logprobs = tensor([[-0.4472, -0.8656],
        [-0.5438, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6527851819992065, train/raw-loss = 0.6527851819992065, train/logprobs = tensor([[-0.5786, -1.0298],
        [-0.6005, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.5981161594390869, train/raw-loss = 0.5981161594390869, train/logprobs = tensor([[-0.4874, -1.8678],
        [-0.5293, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462791562080383, train/raw-loss = 0.6462791562080383, train/logprobs = tensor([[-0.5261, -0.9849],
        [-0.5903, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6795158386230469, train/raw-loss = 0.6795158386230469, train/logprobs = tensor([[-0.6593, -0.8846],
        [-0.7393, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6666545271873474, train/raw-loss = 0.6666545271873474, train/logprobs = tensor([[-0.6950, -0.8433],
        [-0.7934, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6186389327049255, train/raw-loss = 0.6186389327049255, train/logprobs = tensor([[-0.8139, -1.1323],
        [-1.0404, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6196715831756592, train/raw-loss = 0.6196715831756592, train/logprobs = tensor([[-0.6566, -1.0991],
        [-0.7919, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6227840185165405, train/raw-loss = 0.6227840185165405, train/logprobs = tensor([[-0.6762, -0.8706],
        [-0.8808, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.615572988986969, train/raw-loss = 0.615572988986969, train/logprobs = tensor([[-0.6896, -1.0924],
        [-0.8715, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6232751607894897, train/raw-loss = 0.6232751607894897, train/logprobs = tensor([[-0.5302, -1.6274],
        [-0.6201, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6601844429969788, train/raw-loss = 0.6601844429969788, train/logprobs = tensor([[-1.2413, -1.5693],
        [-1.1471, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6864299774169922, train/raw-loss = 0.6864299774169922, train/logprobs = tensor([[-0.4570, -0.5588],
        [-0.4652, -0.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6478174328804016, train/raw-loss = 0.6478174328804016, train/logprobs = tensor([[-0.4911, -0.6860],
        [-0.6346, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6552306413650513, train/raw-loss = 0.6552306413650513, train/logprobs = tensor([[-0.4804, -0.7143],
        [-0.6019, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.5577850341796875, train/raw-loss = 0.5577850341796875, train/logprobs = tensor([[-0.9423, -2.5982],
        [-1.1020, -2.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.672653079032898, train/raw-loss = 0.672653079032898, train/logprobs = tensor([[-0.6678, -0.9992],
        [-0.7756, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6343859434127808, train/raw-loss = 0.6343859434127808, train/logprobs = tensor([[-0.6319, -1.0281],
        [-0.7628, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5744476914405823, train/raw-loss = 0.5744476914405823, train/logprobs = tensor([[-0.6369, -1.4239],
        [-0.7932, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6140914559364319, train/raw-loss = 0.6140914559364319, train/logprobs = tensor([[-0.5465, -1.0431],
        [-0.7120, -0.8742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.621936559677124, train/raw-loss = 0.621936559677124, train/logprobs = tensor([[-0.5814, -1.3817],
        [-0.6858, -1.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.635033369064331, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.6222, -0.9608],
        [-0.7250, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5862956047058105, train/raw-loss = 0.5862956047058105, train/logprobs = tensor([[-0.5264, -2.2469],
        [-0.6147, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6719814538955688, train/raw-loss = 0.6719814538955688, train/logprobs = tensor([[-0.4729, -0.6345],
        [-0.4907, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6511471271514893, train/raw-loss = 0.6511471271514893, train/logprobs = tensor([[-0.4273, -1.0605],
        [-0.4558, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6642727851867676, train/raw-loss = 0.6642727851867676, train/logprobs = tensor([[-0.5162, -1.2556],
        [-0.5839, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6572529077529907, train/raw-loss = 0.6572529077529907, train/logprobs = tensor([[-0.4057, -1.0675],
        [-0.4439, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6779531240463257, train/raw-loss = 0.6779531240463257, train/logprobs = tensor([[-0.5629, -0.7004],
        [-0.5806, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6686426401138306, train/raw-loss = 0.6686426401138306, train/logprobs = tensor([[-0.6757, -1.2124],
        [-0.7278, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6288267374038696, train/raw-loss = 0.6288267374038696, train/logprobs = tensor([[-0.4424, -1.3432],
        [-0.5566, -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.5869567394256592, train/raw-loss = 0.5869567394256592, train/logprobs = tensor([[-0.4740, -1.9319],
        [-0.4988, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6513433456420898, train/raw-loss = 0.6513433456420898, train/logprobs = tensor([[-0.4715, -0.9664],
        [-0.5915, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6780256032943726, train/raw-loss = 0.6780256032943726, train/logprobs = tensor([[-0.4767, -0.6918],
        [-0.5218, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6823168992996216, train/raw-loss = 0.6823168992996216, train/logprobs = tensor([[-0.5260, -0.5658],
        [-0.5478, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6128246784210205, train/raw-loss = 0.6128246784210205, train/logprobs = tensor([[-0.7255, -1.7166],
        [-0.7881, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6479333639144897, train/raw-loss = 0.6479333639144897, train/logprobs = tensor([[-0.3732, -1.2331],
        [-0.4058, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6677660942077637, train/raw-loss = 0.650532066822052, train/logprobs = tensor([[-0.5589, -0.9073],
        [-0.4902, -0.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0172340776771307
Epoch 0, Step 65: train/loss = 0.5999615788459778, train/raw-loss = 0.5862250924110413, train/logprobs = tensor([[-0.4078, -2.3891],
        [-0.4058, -1.6197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013736491091549397
Epoch 0, Step 66: train/loss = 0.645276665687561, train/raw-loss = 0.6281130313873291, train/logprobs = tensor([[-0.6675, -1.2248],
        [-0.6752, -0.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017163706943392754
Epoch 0, Step 67: train/loss = 0.6232712268829346, train/raw-loss = 0.6088191270828247, train/logprobs = tensor([[-0.4562, -1.6535],
        [-0.4390, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014452091418206692
Epoch 0, Step 68: train/loss = 0.6348012685775757, train/raw-loss = 0.619537353515625, train/logprobs = tensor([[-0.5304, -0.8154],
        [-0.6266, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015263931825757027
Epoch 0, Step 69: train/loss = 0.6520127058029175, train/raw-loss = 0.6364642381668091, train/logprobs = tensor([[-0.6226, -0.8792],
        [-0.6368, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015548504889011383
Epoch 0, Step 70: train/loss = 0.6178887486457825, train/raw-loss = 0.603807270526886, train/logprobs = tensor([[-0.5830, -1.5757],
        [-0.5853, -1.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014081516303122044
Epoch 0, Step 71: train/loss = 0.6271520853042603, train/raw-loss = 0.6123709082603455, train/logprobs = tensor([[-0.5096, -1.2073],
        [-0.5344, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014781231060624123
Epoch 0, Step 72: train/loss = 0.6532293558120728, train/raw-loss = 0.6377947330474854, train/logprobs = tensor([[-0.5471, -1.3671],
        [-0.5528, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015434570610523224
Epoch 0, Step 73: train/loss = 0.6916385889053345, train/raw-loss = 0.6746647953987122, train/logprobs = tensor([[-0.5526, -1.0878],
        [-0.5417, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016973827034235
Epoch 0, Step 74: train/loss = 0.6645547151565552, train/raw-loss = 0.6467088460922241, train/logprobs = tensor([[-0.6144, -0.9832],
        [-0.5834, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01784592866897583
Epoch 0, Step 75: train/loss = 0.6173630952835083, train/raw-loss = 0.605035662651062, train/logprobs = tensor([[-0.4136, -1.3306],
        [-0.4383, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012327473610639572
Epoch 0, Step 76: train/loss = 0.5569589734077454, train/raw-loss = 0.5435046553611755, train/logprobs = tensor([[-0.4637, -2.4510],
        [-0.5013, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013454293832182884
Epoch 0, Step 77: train/loss = 0.6203387975692749, train/raw-loss = 0.6043791770935059, train/logprobs = tensor([[-0.6568, -1.0122],
        [-0.6917, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015959637239575386
Epoch 0, Step 78: train/loss = 0.6675419211387634, train/raw-loss = 0.650786280632019, train/logprobs = tensor([[-0.6877, -0.9508],
        [-0.6805, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016755636781454086
Epoch 0, Step 79: train/loss = 0.5899192094802856, train/raw-loss = 0.5750255584716797, train/logprobs = tensor([[-0.5681, -2.4095],
        [-0.5731, -1.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01489364542067051
Epoch 0, Step 80: train/loss = 0.6421176791191101, train/raw-loss = 0.6243447065353394, train/logprobs = tensor([[-0.7405, -1.0087],
        [-0.7357, -0.7052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017773009836673737
Epoch 0, Step 81: train/loss = 0.5813270211219788, train/raw-loss = 0.5703976154327393, train/logprobs = tensor([[-0.5271, -2.5127],
        [-0.5219, -1.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010929407551884651
Epoch 0, Step 82: train/loss = 0.6646539568901062, train/raw-loss = 0.6459182500839233, train/logprobs = tensor([[-0.6903, -1.1170],
        [-0.6218, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01873568259179592
Epoch 0, Step 83: train/loss = 0.7011545300483704, train/raw-loss = 0.6808172464370728, train/logprobs = tensor([[-1.5417, -1.6606],
        [-1.4949, -1.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02033730037510395
Epoch 0, Step 84: train/loss = 0.6580154895782471, train/raw-loss = 0.6393141150474548, train/logprobs = tensor([[-0.6077, -0.9784],
        [-0.5882, -0.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018701378256082535
Epoch 0, Step 85: train/loss = 0.5749961137771606, train/raw-loss = 0.5589746236801147, train/logprobs = tensor([[-0.5906, -2.0206],
        [-0.5816, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016021499410271645
Epoch 0, Step 86: train/loss = 0.6439397931098938, train/raw-loss = 0.6268938779830933, train/logprobs = tensor([[-0.5693, -0.9161],
        [-0.5945, -0.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017045943066477776
Epoch 0, Step 87: train/loss = 0.620740532875061, train/raw-loss = 0.604753851890564, train/logprobs = tensor([[-0.6385, -1.0346],
        [-0.7062, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015986669808626175
Epoch 0, Step 88: train/loss = 0.6295138597488403, train/raw-loss = 0.6108947992324829, train/logprobs = tensor([[-1.0004, -2.1746],
        [-0.9339, -1.5912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018619030714035034
Epoch 0, Step 89: train/loss = 0.6542567014694214, train/raw-loss = 0.6364856362342834, train/logprobs = tensor([[-0.5697, -0.9948],
        [-0.5548, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017771147191524506
Epoch 0, Step 90: train/loss = 0.6429322957992554, train/raw-loss = 0.6263701915740967, train/logprobs = tensor([[-0.4654, -1.0588],
        [-0.4745, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016562053933739662
Epoch 0, Step 91: train/loss = 0.45797106623649597, train/raw-loss = 0.44513967633247375, train/logprobs = tensor([[-0.4699, -2.7842],
        [-0.5091, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012831421568989754
Epoch 0, Step 92: train/loss = 0.6699960231781006, train/raw-loss = 0.6497999429702759, train/logprobs = tensor([[-0.6957, -1.0879],
        [-0.6924, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02019602432847023
Epoch 0, Step 93: train/loss = 0.6059578061103821, train/raw-loss = 0.5899158716201782, train/logprobs = tensor([[-0.5690, -1.4569],
        [-0.5589, -0.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016041917726397514
Epoch 0, Step 94: train/loss = 0.6062168478965759, train/raw-loss = 0.5892163515090942, train/logprobs = tensor([[-0.6780, -1.8414],
        [-0.7726, -1.3489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01700046844780445
Epoch 0, Step 95: train/loss = 0.6394780278205872, train/raw-loss = 0.6258664131164551, train/logprobs = tensor([[-0.5261, -1.0159],
        [-0.5229, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013611596077680588
Epoch 0, Step 96: train/loss = 0.7238941192626953, train/raw-loss = 0.68248450756073, train/logprobs = tensor([[-0.5892, -0.8771],
        [-0.5722, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04140951856970787
Epoch 0, Step 97: train/loss = 0.5978327989578247, train/raw-loss = 0.5612051486968994, train/logprobs = tensor([[-0.6281, -1.9102],
        [-0.6178, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036627672612667084
Epoch 0, Step 98: train/loss = 0.6461396217346191, train/raw-loss = 0.6158816814422607, train/logprobs = tensor([[-0.3773, -0.9522],
        [-0.3321, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030257906764745712
Epoch 0, Step 99: train/loss = 0.6570872068405151, train/raw-loss = 0.6253319978713989, train/logprobs = tensor([[-0.5241, -1.0248],
        [-0.5057, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03175514563918114
Epoch 0, Step 100: train/loss = 0.5719918608665466, train/raw-loss = 0.5404251217842102, train/logprobs = tensor([[-0.6738, -2.6884],
        [-0.6697, -1.3304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03156677633523941
Epoch 0, Step 101: train/loss = 0.6362912058830261, train/raw-loss = 0.5880459547042847, train/logprobs = tensor([[-0.9428, -1.8026],
        [-0.9257, -1.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048245225101709366
Epoch 0, Step 102: train/loss = 0.6167442798614502, train/raw-loss = 0.5818320512771606, train/logprobs = tensor([[-0.4907, -1.3225],
        [-0.4924, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03491227328777313
Epoch 0, Step 103: train/loss = 0.585069477558136, train/raw-loss = 0.5541733503341675, train/logprobs = tensor([[-0.6267, -1.6791],
        [-0.5530, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030896078795194626
Epoch 0, Step 104: train/loss = 0.4846145808696747, train/raw-loss = 0.44455575942993164, train/logprobs = tensor([[-0.7763, -4.4189],
        [-0.6625, -2.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04005882143974304
Epoch 0, Step 105: train/loss = 0.6349301934242249, train/raw-loss = 0.5994865298271179, train/logprobs = tensor([[-0.6679, -1.1599],
        [-0.6286, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03544367477297783
Epoch 0, Step 106: train/loss = 0.4881417155265808, train/raw-loss = 0.4551183581352234, train/logprobs = tensor([[-0.6707, -4.2864],
        [-0.6240, -2.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033023327589035034
Epoch 0, Step 107: train/loss = 0.6398196816444397, train/raw-loss = 0.5974924564361572, train/logprobs = tensor([[-0.7090, -1.5024],
        [-0.6762, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232719540596008
Epoch 0, Step 108: train/loss = 0.6862243413925171, train/raw-loss = 0.6625020503997803, train/logprobs = tensor([[-0.5245, -0.6496],
        [-0.4670, -0.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02372230775654316
Epoch 0, Step 109: train/loss = 0.6342512369155884, train/raw-loss = 0.6019797921180725, train/logprobs = tensor([[-0.6306, -1.2550],
        [-0.5548, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032271500676870346
Epoch 0, Step 110: train/loss = 0.5723040103912354, train/raw-loss = 0.5400521159172058, train/logprobs = tensor([[-0.6494, -2.8765],
        [-0.5510, -1.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032251931726932526
Epoch 0, Step 111: train/loss = 0.6075754165649414, train/raw-loss = 0.5794885754585266, train/logprobs = tensor([[-0.4297, -1.4603],
        [-0.4110, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028086885809898376
Epoch 0, Step 112: train/loss = 0.6283018589019775, train/raw-loss = 0.5945590138435364, train/logprobs = tensor([[-0.6218, -1.0816],
        [-0.6019, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033742815256118774
Epoch 0, Step 113: train/loss = 0.6686863303184509, train/raw-loss = 0.624238908290863, train/logprobs = tensor([[-0.6426, -1.2513],
        [-0.5746, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04444742202758789
Epoch 0, Step 114: train/loss = 0.6347882151603699, train/raw-loss = 0.5986374020576477, train/logprobs = tensor([[-0.5588, -1.0421],
        [-0.5381, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03615080937743187
Epoch 0, Step 115: train/loss = 0.6469485759735107, train/raw-loss = 0.6146130561828613, train/logprobs = tensor([[-0.5568, -1.1375],
        [-0.5222, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03233547508716583
Epoch 0, Step 116: train/loss = 0.602628231048584, train/raw-loss = 0.5647749900817871, train/logprobs = tensor([[-0.6622, -1.9983],
        [-0.6062, -1.2652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03785319626331329
Epoch 0, Step 117: train/loss = 0.6519351005554199, train/raw-loss = 0.616733193397522, train/logprobs = tensor([[-0.4804, -1.7316],
        [-0.4613, -1.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520187363028526
Epoch 0, Step 118: train/loss = 0.524389922618866, train/raw-loss = 0.4935220777988434, train/logprobs = tensor([[-0.6528, -3.1219],
        [-0.5796, -1.3200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030867846682667732
Epoch 0, Step 119: train/loss = 0.6094169616699219, train/raw-loss = 0.5680791735649109, train/logprobs = tensor([[-0.6053, -1.6489],
        [-0.5656, -0.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0413377583026886
Epoch 0, Step 120: train/loss = 0.558247447013855, train/raw-loss = 0.5184401273727417, train/logprobs = tensor([[-0.7735, -2.5687],
        [-0.7654, -1.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039807356894016266
Epoch 0, Step 121: train/loss = 0.6369320750236511, train/raw-loss = 0.603752076625824, train/logprobs = tensor([[-0.4947, -1.2106],
        [-0.4443, -0.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03317999839782715
Epoch 0, Step 122: train/loss = 0.5711784362792969, train/raw-loss = 0.5340642333030701, train/logprobs = tensor([[-0.8281, -1.9037],
        [-0.7560, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037114232778549194
Epoch 0, Step 123: train/loss = 0.6975606679916382, train/raw-loss = 0.6642010807991028, train/logprobs = tensor([[-0.5306, -0.7816],
        [-0.5077, -0.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03335965797305107
Epoch 0, Step 124: train/loss = 0.613974928855896, train/raw-loss = 0.5751924514770508, train/logprobs = tensor([[-0.7773, -1.5863],
        [-0.7073, -0.9170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03878249228000641
Epoch 0, Step 125: train/loss = 0.5707048773765564, train/raw-loss = 0.53330397605896, train/logprobs = tensor([[-0.6862, -3.0995],
        [-0.6255, -2.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03740091994404793
Epoch 0, Step 126: train/loss = 0.6662563681602478, train/raw-loss = 0.6255104541778564, train/logprobs = tensor([[-0.6622, -1.1716],
        [-0.5701, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04074595868587494
Epoch 0, Step 127: train/loss = 0.6521996259689331, train/raw-loss = 0.6126285195350647, train/logprobs = tensor([[-0.5007, -1.4532],
        [-0.4427, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03957105427980423
Epoch 0, Step 128: train/loss = 0.7518896460533142, train/raw-loss = 0.6474182605743408, train/logprobs = tensor([[-0.7910, -1.0000],
        [-0.7734, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447143018245697
Epoch 0, Step 129: train/loss = 0.6601390838623047, train/raw-loss = 0.522521436214447, train/logprobs = tensor([[-0.7198, -2.6822],
        [-0.6261, -1.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13761767745018005
Epoch 0, Step 130: train/loss = 0.7514987587928772, train/raw-loss = 0.6250487565994263, train/logprobs = tensor([[-0.5261, -1.1230],
        [-0.4681, -0.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12644995748996735
Epoch 0, Step 131: train/loss = 0.6456472873687744, train/raw-loss = 0.5066382884979248, train/logprobs = tensor([[-0.7443, -3.9314],
        [-0.6702, -2.5206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13900890946388245
Epoch 0, Step 132: train/loss = 0.6576818823814392, train/raw-loss = 0.5272989273071289, train/logprobs = tensor([[-0.7620, -2.2749],
        [-0.6363, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13038302958011627
Epoch 0, Step 133: train/loss = 0.6771512031555176, train/raw-loss = 0.5442360639572144, train/logprobs = tensor([[-0.6328, -2.3362],
        [-0.5613, -1.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1329151839017868
Epoch 0, Step 134: train/loss = 0.6812484860420227, train/raw-loss = 0.5586884617805481, train/logprobs = tensor([[-0.7232, -1.6041],
        [-0.6189, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12256002426147461
Epoch 0, Step 135: train/loss = 0.727833092212677, train/raw-loss = 0.593561053276062, train/logprobs = tensor([[-0.5087, -1.4539],
        [-0.3938, -0.8615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1342719942331314
Epoch 0, Step 136: train/loss = 0.6598588228225708, train/raw-loss = 0.5329405665397644, train/logprobs = tensor([[-0.4350, -2.0218],
        [-0.3931, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126918226480484
Epoch 0, Step 137: train/loss = 0.7226779460906982, train/raw-loss = 0.6012699604034424, train/logprobs = tensor([[-0.4307, -1.2751],
        [-0.3982, -0.8076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12140798568725586
Epoch 0, Step 138: train/loss = 0.6891583204269409, train/raw-loss = 0.5468997955322266, train/logprobs = tensor([[-0.4292, -1.6176],
        [-0.3649, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14225855469703674
Epoch 0, Step 139: train/loss = 0.6571590304374695, train/raw-loss = 0.5249606370925903, train/logprobs = tensor([[-0.5944, -2.2847],
        [-0.4902, -1.2787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13219842314720154
Epoch 0, Step 140: train/loss = 0.7076345682144165, train/raw-loss = 0.5845728516578674, train/logprobs = tensor([[-0.7569, -1.6894],
        [-0.6516, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12306177616119385
Epoch 0, Step 141: train/loss = 0.7124489545822144, train/raw-loss = 0.5811775922775269, train/logprobs = tensor([[-0.8988, -1.8522],
        [-0.6770, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312713623046875
Epoch 0, Step 142: train/loss = 0.731106162071228, train/raw-loss = 0.6130915284156799, train/logprobs = tensor([[-0.5506, -1.1873],
        [-0.4737, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11801466345787048
Epoch 0, Step 143: train/loss = 0.7491800785064697, train/raw-loss = 0.6335511207580566, train/logprobs = tensor([[-0.7177, -1.4869],
        [-0.5805, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11562889814376831
Epoch 0, Step 144: train/loss = 0.5876492261886597, train/raw-loss = 0.4700658619403839, train/logprobs = tensor([[-0.5689, -3.8215],
        [-0.4984, -2.3556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11758334189653397
Epoch 0, Step 145: train/loss = 0.7205578684806824, train/raw-loss = 0.6108090281486511, train/logprobs = tensor([[-0.6187, -1.4993],
        [-0.5493, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10974880307912827
Epoch 0, Step 146: train/loss = 0.6714475154876709, train/raw-loss = 0.5492748618125916, train/logprobs = tensor([[-0.6239, -2.6273],
        [-0.5077, -1.6190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12217263132333755
Epoch 0, Step 147: train/loss = 0.7324352860450745, train/raw-loss = 0.6121364235877991, train/logprobs = tensor([[-0.6070, -1.1408],
        [-0.5079, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12029887735843658
Epoch 0, Step 148: train/loss = 0.7941581010818481, train/raw-loss = 0.6639196872711182, train/logprobs = tensor([[-1.4283, -1.7807],
        [-1.1017, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13023841381072998
Epoch 0, Step 149: train/loss = 0.7314603924751282, train/raw-loss = 0.6287619471549988, train/logprobs = tensor([[-0.6136, -1.2211],
        [-0.5120, -0.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10269847512245178
Epoch 0, Step 150: train/loss = 0.6488890647888184, train/raw-loss = 0.5313869118690491, train/logprobs = tensor([[-0.7959, -3.4655],
        [-0.7185, -1.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11750215291976929
Epoch 0, Step 151: train/loss = 0.707640528678894, train/raw-loss = 0.5829241275787354, train/logprobs = tensor([[-0.6544, -1.7943],
        [-0.5232, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12471645325422287
Epoch 0, Step 152: train/loss = 0.7308414578437805, train/raw-loss = 0.5986515283584595, train/logprobs = tensor([[-0.8077, -1.3518],
        [-0.7535, -0.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13218991458415985
Epoch 0, Step 153: train/loss = 0.7130063772201538, train/raw-loss = 0.5724835991859436, train/logprobs = tensor([[-0.5975, -1.9241],
        [-0.4996, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14052274823188782
Epoch 0, Step 154: train/loss = 0.7463452816009521, train/raw-loss = 0.6351592540740967, train/logprobs = tensor([[-0.7238, -1.5765],
        [-0.6324, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11118601262569427
Epoch 0, Step 155: train/loss = 0.6625903248786926, train/raw-loss = 0.5568224787712097, train/logprobs = tensor([[-0.5804, -2.7882],
        [-0.5010, -1.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1057678684592247
Epoch 0, Step 156: train/loss = 0.7459143400192261, train/raw-loss = 0.6511120200157166, train/logprobs = tensor([[-0.6227, -0.7361],
        [-0.5677, -0.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0948023647069931
Epoch 0, Step 157: train/loss = 0.7722190618515015, train/raw-loss = 0.6864426136016846, train/logprobs = tensor([[-0.7162, -0.7721],
        [-0.6286, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08577647060155869
Epoch 0, Step 158: train/loss = 0.7576800584793091, train/raw-loss = 0.6443965435028076, train/logprobs = tensor([[-0.6710, -1.1625],
        [-0.4748, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11328352242708206
Epoch 0, Step 159: train/loss = 0.7700083255767822, train/raw-loss = 0.6638386845588684, train/logprobs = tensor([[-0.8344, -1.0256],
        [-0.7076, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10616959631443024
Epoch 0, Step 160: train/loss = 0.6276631355285645, train/raw-loss = 0.5291664600372314, train/logprobs = tensor([[-1.0514, -2.2148],
        [-0.8485, -1.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09849664568901062
Epoch 0, Step 161: train/loss = 0.6901330947875977, train/raw-loss = 0.6237220764160156, train/logprobs = tensor([[-0.6515, -1.2493],
        [-0.5517, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06641105562448502
Epoch 0, Step 162: train/loss = 0.6380936503410339, train/raw-loss = 0.5603569149971008, train/logprobs = tensor([[-0.5679, -2.9707],
        [-0.5036, -1.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0777367427945137
Epoch 0, Step 163: train/loss = 0.647982120513916, train/raw-loss = 0.5516612529754639, train/logprobs = tensor([[-0.5577, -1.9830],
        [-0.4390, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632083773612976
Epoch 0, Step 164: train/loss = 0.6444076895713806, train/raw-loss = 0.5668046474456787, train/logprobs = tensor([[-0.6543, -1.7721],
        [-0.5170, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07760301977396011
Epoch 0, Step 165: train/loss = 0.6454465985298157, train/raw-loss = 0.5463528633117676, train/logprobs = tensor([[-0.6391, -2.1078],
        [-0.4933, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09909378737211227
Epoch 0, Step 166: train/loss = 0.5182969570159912, train/raw-loss = 0.415724515914917, train/logprobs = tensor([[-0.6222, -6.6076],
        [-0.4474, -3.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10257241129875183
Epoch 0, Step 167: train/loss = 0.7101209759712219, train/raw-loss = 0.6135458946228027, train/logprobs = tensor([[-0.7111, -1.3790],
        [-0.5668, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657508134841919
Epoch 0, Step 168: train/loss = 0.6750379204750061, train/raw-loss = 0.5850889086723328, train/logprobs = tensor([[-0.6600, -1.4152],
        [-0.5598, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08994903415441513
Epoch 0, Step 169: train/loss = 0.7211426496505737, train/raw-loss = 0.6486544609069824, train/logprobs = tensor([[-0.7658, -1.3013],
        [-0.7165, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07248804718255997
Epoch 0, Step 170: train/loss = 0.6745356321334839, train/raw-loss = 0.5789203643798828, train/logprobs = tensor([[-0.5792, -1.6516],
        [-0.5506, -1.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09561528265476227
Epoch 0, Step 171: train/loss = 0.7248759865760803, train/raw-loss = 0.6343388557434082, train/logprobs = tensor([[-0.6338, -1.2951],
        [-0.5185, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09053715318441391
Epoch 0, Step 172: train/loss = 0.6014269590377808, train/raw-loss = 0.502465546131134, train/logprobs = tensor([[-0.6305, -2.5245],
        [-0.5774, -1.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09896139055490494
Epoch 0, Step 173: train/loss = 0.6187913417816162, train/raw-loss = 0.5255669951438904, train/logprobs = tensor([[-0.6076, -2.4109],
        [-0.5438, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322433173656464
Epoch 0, Step 174: train/loss = 0.6180700659751892, train/raw-loss = 0.5282378196716309, train/logprobs = tensor([[-0.6698, -1.9963],
        [-0.5568, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08983225375413895
Epoch 0, Step 175: train/loss = 0.5491448044776917, train/raw-loss = 0.4474684000015259, train/logprobs = tensor([[-0.5009, -3.4133],
        [-0.4087, -1.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10167640447616577
Epoch 0, Step 176: train/loss = 0.6987069249153137, train/raw-loss = 0.5899567604064941, train/logprobs = tensor([[-0.7106, -1.5874],
        [-0.4985, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10875013470649719
Epoch 0, Step 177: train/loss = 0.6727515459060669, train/raw-loss = 0.5704163312911987, train/logprobs = tensor([[-1.0373, -2.3918],
        [-0.6533, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10233525931835175
Epoch 0, Step 178: train/loss = 0.6926190853118896, train/raw-loss = 0.6042839884757996, train/logprobs = tensor([[-0.8351, -2.3403],
        [-0.7379, -1.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08833514153957367
Epoch 0, Step 179: train/loss = 0.6811034679412842, train/raw-loss = 0.5932072401046753, train/logprobs = tensor([[-0.6372, -2.4121],
        [-0.4948, -1.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789622783660889
Epoch 0, Step 180: train/loss = 0.7659022212028503, train/raw-loss = 0.681358277797699, train/logprobs = tensor([[-0.8181, -0.8719],
        [-0.6406, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08454389870166779
Epoch 0, Step 181: train/loss = 0.7762755155563354, train/raw-loss = 0.6815799474716187, train/logprobs = tensor([[-2.6941, -3.8813],
        [-1.8852, -2.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09469552338123322
Epoch 0, Step 182: train/loss = 0.7007177472114563, train/raw-loss = 0.6159541606903076, train/logprobs = tensor([[-0.5168, -1.1993],
        [-0.4597, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08476358652114868
Epoch 0, Step 183: train/loss = 0.6694612503051758, train/raw-loss = 0.5751103162765503, train/logprobs = tensor([[-0.6919, -1.6847],
        [-0.5888, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09435093402862549
Epoch 0, Step 184: train/loss = 0.5855423212051392, train/raw-loss = 0.49686166644096375, train/logprobs = tensor([[-1.1511, -4.0121],
        [-1.1260, -2.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08868063241243362
Epoch 0, Step 185: train/loss = 0.664889931678772, train/raw-loss = 0.5778440833091736, train/logprobs = tensor([[-0.8353, -2.0487],
        [-0.6787, -1.3052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08704586327075958
Epoch 0, Step 186: train/loss = 0.6926148533821106, train/raw-loss = 0.5814403295516968, train/logprobs = tensor([[-0.7885, -1.5709],
        [-0.7138, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1111745834350586
Epoch 0, Step 187: train/loss = 0.6572801470756531, train/raw-loss = 0.5739641189575195, train/logprobs = tensor([[-0.5929, -2.2754],
        [-0.4892, -1.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08331600576639175
Epoch 0, Step 188: train/loss = 0.5930737257003784, train/raw-loss = 0.4996015727519989, train/logprobs = tensor([[-0.8254, -4.0060],
        [-0.6096, -2.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09347212314605713
Epoch 0, Step 189: train/loss = 0.7223657965660095, train/raw-loss = 0.655357837677002, train/logprobs = tensor([[-0.5901, -0.8680],
        [-0.5070, -0.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06700794398784637
Epoch 0, Step 190: train/loss = 0.6121926307678223, train/raw-loss = 0.5349680185317993, train/logprobs = tensor([[-0.8008, -3.5861],
        [-0.6212, -1.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07722465693950653
Epoch 0, Step 191: train/loss = 0.7116241455078125, train/raw-loss = 0.618229866027832, train/logprobs = tensor([[-0.6741, -1.1107],
        [-0.5995, -0.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339424967765808
Epoch 0, Step 192: train/loss = 0.668062150478363, train/raw-loss = 0.5661794543266296, train/logprobs = tensor([[-0.7164, -1.4225],
        [-0.5668, -0.5892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10188273340463638
Epoch 0, Step 193: train/loss = 0.6063227653503418, train/raw-loss = 0.49252045154571533, train/logprobs = tensor([[-0.7371, -2.8513],
        [-0.6357, -1.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11380235850811005
Epoch 0, Step 194: train/loss = 0.5746933221817017, train/raw-loss = 0.4685191810131073, train/logprobs = tensor([[-0.8230, -3.5602],
        [-0.7076, -1.2040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617415606975555
Epoch 0, Step 195: train/loss = 0.5946761965751648, train/raw-loss = 0.49975839257240295, train/logprobs = tensor([[-0.7620, -3.1264],
        [-0.6181, -1.3521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09491777420043945
Epoch 0, Step 196: train/loss = 0.6820598840713501, train/raw-loss = 0.5863929390907288, train/logprobs = tensor([[-0.6754, -1.4231],
        [-0.5820, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09566692262887955
Epoch 0, Step 197: train/loss = 0.6303904056549072, train/raw-loss = 0.5289993286132812, train/logprobs = tensor([[-0.6609, -2.2059],
        [-0.5085, -0.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10139106959104538
Epoch 0, Step 198: train/loss = 0.6564563512802124, train/raw-loss = 0.5570204257965088, train/logprobs = tensor([[-0.6488, -1.6677],
        [-0.5540, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09943589568138123
Epoch 0, Step 199: train/loss = 0.5843201279640198, train/raw-loss = 0.4705788493156433, train/logprobs = tensor([[-0.4744, -2.0401],
        [-0.3783, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11374128609895706
Epoch 0, Step 200: train/loss = 0.5887985825538635, train/raw-loss = 0.49652665853500366, train/logprobs = tensor([[-0.8482, -2.1375],
        [-0.6908, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227191656827927
Epoch 0, Step 201: train/loss = 0.5870735049247742, train/raw-loss = 0.4714030623435974, train/logprobs = tensor([[-0.8241, -3.0128],
        [-0.6652, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567047238349915
Epoch 0, Step 202: train/loss = 0.6953330636024475, train/raw-loss = 0.6044596433639526, train/logprobs = tensor([[-0.6704, -1.0880],
        [-0.6818, -0.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09087340533733368
Epoch 0, Step 203: train/loss = 0.6855883002281189, train/raw-loss = 0.5804812908172607, train/logprobs = tensor([[-0.7123, -2.4341],
        [-0.4735, -1.1501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10510702431201935
Epoch 0, Step 204: train/loss = 0.6212305426597595, train/raw-loss = 0.5249030590057373, train/logprobs = tensor([[-0.8837, -1.8881],
        [-0.7315, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09632746130228043
Epoch 0, Step 205: train/loss = 0.568377673625946, train/raw-loss = 0.4565490186214447, train/logprobs = tensor([[-0.5387, -2.3125],
        [-0.5089, -0.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11182868480682373
Epoch 0, Step 206: train/loss = 0.4758783280849457, train/raw-loss = 0.367636501789093, train/logprobs = tensor([[-0.5994, -5.0357],
        [-0.5332, -1.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10824181139469147
Epoch 0, Step 207: train/loss = 0.5917066335678101, train/raw-loss = 0.4886101484298706, train/logprobs = tensor([[-0.8928, -2.1514],
        [-0.7767, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309651494026184
Epoch 0, Step 208: train/loss = 0.6079924702644348, train/raw-loss = 0.5031106472015381, train/logprobs = tensor([[-0.7228, -3.1963],
        [-0.5439, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10488182306289673
Epoch 0, Step 209: train/loss = 0.6608697772026062, train/raw-loss = 0.550114631652832, train/logprobs = tensor([[-0.7120, -1.9119],
        [-0.6019, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11075511574745178
Epoch 0, Step 210: train/loss = 0.6363292932510376, train/raw-loss = 0.5458509922027588, train/logprobs = tensor([[-0.6630, -1.6110],
        [-0.5644, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09047837555408478
Epoch 0, Step 211: train/loss = 0.6652216911315918, train/raw-loss = 0.5756505727767944, train/logprobs = tensor([[-0.9854, -3.7568],
        [-0.9676, -1.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957114070653915
Epoch 0, Step 212: train/loss = 0.6955106854438782, train/raw-loss = 0.6074738502502441, train/logprobs = tensor([[-0.5475, -1.2240],
        [-0.4545, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08803686499595642
Epoch 0, Step 213: train/loss = 0.7070389986038208, train/raw-loss = 0.605900228023529, train/logprobs = tensor([[-0.6537, -1.2583],
        [-0.5063, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10113870352506638
Epoch 0, Step 214: train/loss = 0.6337282657623291, train/raw-loss = 0.5249674320220947, train/logprobs = tensor([[-0.5909, -2.6622],
        [-0.5474, -1.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10876083374023438
Epoch 0, Step 215: train/loss = 0.6033689975738525, train/raw-loss = 0.5031444430351257, train/logprobs = tensor([[-0.8868, -2.4721],
        [-0.8486, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10022448003292084
Epoch 0, Step 216: train/loss = 0.7095744609832764, train/raw-loss = 0.622921347618103, train/logprobs = tensor([[-0.7690, -1.1281],
        [-0.5398, -0.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08665312826633453
Epoch 0, Step 217: train/loss = 0.5809800624847412, train/raw-loss = 0.48315441608428955, train/logprobs = tensor([[-0.5609, -2.2767],
        [-0.4997, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09782566130161285
Epoch 0, Step 218: train/loss = 0.7409378886222839, train/raw-loss = 0.6694915294647217, train/logprobs = tensor([[-0.5846, -0.7424],
        [-0.5074, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07144635915756226
Epoch 0, Step 219: train/loss = 0.6646060943603516, train/raw-loss = 0.571426510810852, train/logprobs = tensor([[-0.6251, -1.5538],
        [-0.5508, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0931795984506607
Epoch 0, Step 220: train/loss = 0.5360963940620422, train/raw-loss = 0.4366406202316284, train/logprobs = tensor([[-1.0638, -3.4322],
        [-0.8829, -1.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09945575892925262
Epoch 0, Step 221: train/loss = 0.6140454411506653, train/raw-loss = 0.5211411118507385, train/logprobs = tensor([[-0.4644, -3.6560],
        [-0.4289, -1.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09290432929992676
Epoch 0, Step 222: train/loss = 0.6527136564254761, train/raw-loss = 0.5583712458610535, train/logprobs = tensor([[-0.6477, -1.9838],
        [-0.5046, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0943424329161644
Epoch 0, Step 223: train/loss = 0.6654020547866821, train/raw-loss = 0.5700905323028564, train/logprobs = tensor([[-0.8158, -1.9774],
        [-0.6456, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09531146287918091
Epoch 0, Step 224: train/loss = 0.6514199376106262, train/raw-loss = 0.5644310712814331, train/logprobs = tensor([[-0.6696, -1.3300],
        [-0.6345, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0869888961315155
Epoch 0, Step 225: train/loss = 0.6481326818466187, train/raw-loss = 0.5680477023124695, train/logprobs = tensor([[-0.5791, -1.3565],
        [-0.4532, -0.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008494973182678
Epoch 0, Step 226: train/loss = 0.8015136122703552, train/raw-loss = 0.7086417078971863, train/logprobs = tensor([[-1.7942, -3.0895],
        [-0.7054, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09287184476852417
Epoch 0, Step 227: train/loss = 0.5657531023025513, train/raw-loss = 0.45469430088996887, train/logprobs = tensor([[-0.9526, -3.0936],
        [-0.5747, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11105883121490479
Epoch 0, Step 228: train/loss = 0.6310964822769165, train/raw-loss = 0.5516546964645386, train/logprobs = tensor([[-0.5293, -1.8281],
        [-0.4236, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07944180071353912
Epoch 0, Step 229: train/loss = 0.5415387749671936, train/raw-loss = 0.4409383535385132, train/logprobs = tensor([[-0.8430, -4.7340],
        [-0.7846, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060042887926102
Epoch 0, Step 230: train/loss = 0.5389710664749146, train/raw-loss = 0.4448673725128174, train/logprobs = tensor([[-1.0547, -2.8884],
        [-0.9760, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09410367161035538
Epoch 0, Step 231: train/loss = 0.4968535602092743, train/raw-loss = 0.4153989553451538, train/logprobs = tensor([[-0.6519, -3.8976],
        [-0.6605, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0814545750617981
Epoch 0, Step 232: train/loss = 0.6289554238319397, train/raw-loss = 0.5408321619033813, train/logprobs = tensor([[-0.5941, -2.2623],
        [-0.5587, -1.2924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08812328428030014
Epoch 0, Step 233: train/loss = 0.6584474444389343, train/raw-loss = 0.5639829635620117, train/logprobs = tensor([[-1.1652, -4.6513],
        [-0.8008, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446443617343903
Epoch 0, Step 234: train/loss = 0.6875073313713074, train/raw-loss = 0.6053687930107117, train/logprobs = tensor([[-0.5695, -1.0614],
        [-0.4783, -0.5097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08213845640420914
Epoch 0, Step 235: train/loss = 0.5546435713768005, train/raw-loss = 0.4601788818836212, train/logprobs = tensor([[-0.9192, -3.9895],
        [-0.5937, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446467459201813
Epoch 0, Step 236: train/loss = 0.6738295555114746, train/raw-loss = 0.5789855718612671, train/logprobs = tensor([[-0.6955, -1.7058],
        [-0.6136, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484396129846573
Epoch 0, Step 237: train/loss = 0.5969604253768921, train/raw-loss = 0.5171710848808289, train/logprobs = tensor([[-0.7177, -1.8328],
        [-0.6546, -0.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07978936284780502
Epoch 0, Step 238: train/loss = 0.5618430972099304, train/raw-loss = 0.4748329520225525, train/logprobs = tensor([[-0.5550, -2.3309],
        [-0.4899, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08701012283563614
Epoch 0, Step 239: train/loss = 0.705780565738678, train/raw-loss = 0.629921555519104, train/logprobs = tensor([[-0.7819, -1.0486],
        [-0.5800, -0.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07585904002189636
Epoch 0, Step 240: train/loss = 0.6728987097740173, train/raw-loss = 0.5788098573684692, train/logprobs = tensor([[-1.0063, -2.2504],
        [-1.0177, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09408891201019287
Epoch 0, Step 241: train/loss = 0.6039783954620361, train/raw-loss = 0.5157546997070312, train/logprobs = tensor([[-0.5286, -1.6580],
        [-0.5090, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882236510515213
Epoch 0, Step 242: train/loss = 0.7011467814445496, train/raw-loss = 0.6234545707702637, train/logprobs = tensor([[-0.5441, -0.9244],
        [-0.4155, -0.4700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07769223302602768
Epoch 0, Step 243: train/loss = 0.7165889739990234, train/raw-loss = 0.6352060437202454, train/logprobs = tensor([[-0.7524, -1.0583],
        [-0.5308, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08138296008110046
Epoch 0, Step 244: train/loss = 0.5526891946792603, train/raw-loss = 0.45729637145996094, train/logprobs = tensor([[-0.9488, -3.2533],
        [-0.7013, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539279341697693
Epoch 0, Step 245: train/loss = 0.6123808026313782, train/raw-loss = 0.5203754305839539, train/logprobs = tensor([[-0.9756, -2.0380],
        [-0.6518, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09200534969568253
Epoch 0, Step 246: train/loss = 0.550200879573822, train/raw-loss = 0.45321276783943176, train/logprobs = tensor([[-0.6408, -3.3849],
        [-0.6617, -1.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09698807448148727
Epoch 0, Step 247: train/loss = 0.6302124261856079, train/raw-loss = 0.5425441265106201, train/logprobs = tensor([[-0.9001, -2.2771],
        [-0.7205, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08766832202672958
Epoch 0, Step 248: train/loss = 0.6758664846420288, train/raw-loss = 0.6009133458137512, train/logprobs = tensor([[-0.6317, -1.7737],
        [-0.6750, -1.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07495314627885818
Epoch 0, Step 249: train/loss = 0.6134361624717712, train/raw-loss = 0.5295263528823853, train/logprobs = tensor([[-0.4651, -2.0124],
        [-0.4955, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0839097648859024
Epoch 0, Step 250: train/loss = 0.5797456502914429, train/raw-loss = 0.48170197010040283, train/logprobs = tensor([[-1.1230, -3.7999],
        [-0.5989, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09804368764162064
Epoch 0, Step 251: train/loss = 0.515616774559021, train/raw-loss = 0.42191261053085327, train/logprobs = tensor([[-0.6175, -2.5561],
        [-0.6342, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09370412677526474
Epoch 0, Step 252: train/loss = 0.6373795866966248, train/raw-loss = 0.5593034029006958, train/logprobs = tensor([[-0.4606, -1.4456],
        [-0.4012, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07807616889476776
Epoch 0, Step 253: train/loss = 0.7584846615791321, train/raw-loss = 0.6853564977645874, train/logprobs = tensor([[-0.7299, -0.5783],
        [-0.6341, -0.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07312813401222229
Epoch 0, Step 254: train/loss = 0.555385172367096, train/raw-loss = 0.4709598422050476, train/logprobs = tensor([[-0.6994, -2.8480],
        [-0.5944, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08442533016204834
Epoch 0, Step 255: train/loss = 0.6355807185173035, train/raw-loss = 0.5438961386680603, train/logprobs = tensor([[-1.0307, -2.2990],
        [-0.8704, -0.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09168459475040436
Epoch 0, Step 256: train/loss = 0.7145639061927795, train/raw-loss = 0.6554406881332397, train/logprobs = tensor([[-0.5420, -0.7980],
        [-0.4290, -0.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059123218059539795
Epoch 0, Step 257: train/loss = 0.7095877528190613, train/raw-loss = 0.640346109867096, train/logprobs = tensor([[-0.7232, -1.1124],
        [-0.5775, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06924165785312653
Epoch 0, Step 258: train/loss = 0.44630804657936096, train/raw-loss = 0.36312276124954224, train/logprobs = tensor([[-0.8413, -3.0063],
        [-0.9181, -0.8880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08318528532981873
Epoch 0, Step 259: train/loss = 0.5866444706916809, train/raw-loss = 0.5234032869338989, train/logprobs = tensor([[-0.5574, -3.4436],
        [-0.5091, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06324120610952377
Epoch 0, Step 260: train/loss = 0.5034852027893066, train/raw-loss = 0.4291531443595886, train/logprobs = tensor([[-0.5013, -4.3082],
        [-0.4644, -1.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07433201372623444
Epoch 0, Step 261: train/loss = 0.5613460540771484, train/raw-loss = 0.47370481491088867, train/logprobs = tensor([[-0.7860, -2.0020],
        [-0.8291, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08764126151800156
Epoch 0, Step 262: train/loss = 0.629658579826355, train/raw-loss = 0.5538145899772644, train/logprobs = tensor([[-0.6560, -2.2225],
        [-0.6068, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075843945145607
Epoch 0, Step 263: train/loss = 0.6708604693412781, train/raw-loss = 0.5915474891662598, train/logprobs = tensor([[-1.1902, -1.8474],
        [-1.0355, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07931298762559891
Epoch 0, Step 264: train/loss = 0.6600952744483948, train/raw-loss = 0.5949058532714844, train/logprobs = tensor([[-0.7158, -1.2568],
        [-0.6484, -0.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06518946588039398
Epoch 0, Step 265: train/loss = 0.7064507007598877, train/raw-loss = 0.6374520659446716, train/logprobs = tensor([[-0.8248, -1.2211],
        [-0.6385, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06899866461753845
Epoch 0, Step 266: train/loss = 0.5115158557891846, train/raw-loss = 0.43192291259765625, train/logprobs = tensor([[-0.9248, -2.9393],
        [-0.9778, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07959292829036713
Epoch 0, Step 267: train/loss = 0.5599393844604492, train/raw-loss = 0.4800494313240051, train/logprobs = tensor([[-0.6523, -2.0519],
        [-0.5395, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07988989353179932
Epoch 0, Step 268: train/loss = 0.5524801015853882, train/raw-loss = 0.4877902865409851, train/logprobs = tensor([[-0.6387, -4.6060],
        [-0.6515, -1.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06468980014324188
Epoch 0, Step 269: train/loss = 0.5772352814674377, train/raw-loss = 0.5027074813842773, train/logprobs = tensor([[-0.7584, -3.6502],
        [-0.6778, -1.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0745278000831604
Epoch 0, Step 270: train/loss = 0.5806168913841248, train/raw-loss = 0.5010318756103516, train/logprobs = tensor([[-0.3866, -1.7880],
        [-0.3522, -0.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07958497852087021
Epoch 0, Step 271: train/loss = 0.5821769833564758, train/raw-loss = 0.5064266324043274, train/logprobs = tensor([[-0.7461, -1.9749],
        [-0.6301, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07575036585330963
Epoch 0, Step 272: train/loss = 0.7360841631889343, train/raw-loss = 0.6679847836494446, train/logprobs = tensor([[-0.5915, -0.7924],
        [-0.5382, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06809941679239273
Epoch 0, Step 273: train/loss = 0.6465562582015991, train/raw-loss = 0.575648844242096, train/logprobs = tensor([[-0.4513, -1.1504],
        [-0.4748, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07090739160776138
Epoch 0, Step 274: train/loss = 0.6698141694068909, train/raw-loss = 0.5937876105308533, train/logprobs = tensor([[-0.5471, -1.4740],
        [-0.4790, -0.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07602659612894058
Epoch 0, Step 275: train/loss = 0.5695450305938721, train/raw-loss = 0.5052633881568909, train/logprobs = tensor([[-0.4620, -1.5888],
        [-0.4308, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0642816573381424
Epoch 0, Step 276: train/loss = 0.6110019683837891, train/raw-loss = 0.5352012515068054, train/logprobs = tensor([[-1.1596, -2.4082],
        [-0.9887, -1.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07580071687698364
Epoch 0, Step 277: train/loss = 0.6817384958267212, train/raw-loss = 0.5987541675567627, train/logprobs = tensor([[-0.7342, -1.1001],
        [-0.7129, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0829843282699585
Epoch 0, Step 278: train/loss = 0.6399412155151367, train/raw-loss = 0.5586746335029602, train/logprobs = tensor([[-0.7208, -1.1799],
        [-0.6995, -0.5325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08126651495695114
Epoch 0, Step 279: train/loss = 0.4943144917488098, train/raw-loss = 0.4124186038970947, train/logprobs = tensor([[-0.9607, -3.7997],
        [-0.7349, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818958505988121
Epoch 0, Step 280: train/loss = 0.5674803256988525, train/raw-loss = 0.49128279089927673, train/logprobs = tensor([[-0.7329, -4.0045],
        [-0.6132, -1.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07619757950305939
Epoch 0, Step 281: train/loss = 0.6438155174255371, train/raw-loss = 0.5715753436088562, train/logprobs = tensor([[-0.5192, -1.0583],
        [-0.4787, -0.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07224017381668091
Epoch 0, Step 282: train/loss = 0.6429897546768188, train/raw-loss = 0.5455566644668579, train/logprobs = tensor([[-1.0998, -2.8206],
        [-0.7794, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09743306040763855
Epoch 0, Step 283: train/loss = 0.602454662322998, train/raw-loss = 0.5256099700927734, train/logprobs = tensor([[-0.7015, -1.9338],
        [-0.6111, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0768446996808052
Epoch 0, Step 284: train/loss = 0.6451430916786194, train/raw-loss = 0.5648384690284729, train/logprobs = tensor([[-0.4724, -1.2077],
        [-0.4838, -0.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08030463755130768
Epoch 0, Step 285: train/loss = 0.6561387181282043, train/raw-loss = 0.5851879715919495, train/logprobs = tensor([[-0.5468, -1.0672],
        [-0.5560, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07095074653625488
Epoch 0, Step 286: train/loss = 0.5891347527503967, train/raw-loss = 0.5197316408157349, train/logprobs = tensor([[-0.3960, -1.5727],
        [-0.3456, -0.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06940311938524246
Epoch 0, Step 287: train/loss = 0.5629965662956238, train/raw-loss = 0.48332804441452026, train/logprobs = tensor([[-0.7231, -3.3887],
        [-0.7245, -1.3374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07966851443052292
Epoch 0, Step 288: train/loss = 0.6082051992416382, train/raw-loss = 0.5354081392288208, train/logprobs = tensor([[-0.5409, -1.5216],
        [-0.5870, -0.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07279710471630096
Epoch 0, Step 289: train/loss = 0.5809376239776611, train/raw-loss = 0.49951058626174927, train/logprobs = tensor([[-0.7752, -2.8380],
        [-0.6968, -1.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08142704516649246
Epoch 0, Step 290: train/loss = 0.5898500084877014, train/raw-loss = 0.5207544565200806, train/logprobs = tensor([[-0.5383, -2.6729],
        [-0.5321, -1.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06909558176994324
Epoch 0, Step 291: train/loss = 0.5346570611000061, train/raw-loss = 0.4611336886882782, train/logprobs = tensor([[-0.6804, -1.8845],
        [-0.7334, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07352334260940552
Epoch 0, Step 292: train/loss = 0.6057106256484985, train/raw-loss = 0.5413870811462402, train/logprobs = tensor([[-0.5986, -1.2788],
        [-0.6597, -0.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06432357430458069
Epoch 0, Step 293: train/loss = 0.618449330329895, train/raw-loss = 0.539638340473175, train/logprobs = tensor([[-0.7407, -1.9924],
        [-0.6877, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07881101965904236
Epoch 0, Step 294: train/loss = 0.6097533106803894, train/raw-loss = 0.5345698595046997, train/logprobs = tensor([[-0.8132, -1.4228],
        [-0.7442, -0.5032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751834362745285
Epoch 0, Step 295: train/loss = 0.5766554474830627, train/raw-loss = 0.4985354542732239, train/logprobs = tensor([[-1.2114, -2.5588],
        [-1.1537, -1.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07812002301216125
Epoch 0, Step 296: train/loss = 0.6190237998962402, train/raw-loss = 0.5477906465530396, train/logprobs = tensor([[-0.6551, -1.7305],
        [-0.6143, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0712331235408783
Epoch 0, Step 297: train/loss = 0.5381730198860168, train/raw-loss = 0.4648672938346863, train/logprobs = tensor([[-0.6013, -2.9686],
        [-0.6368, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07330573350191116
Epoch 0, Step 298: train/loss = 0.5955050587654114, train/raw-loss = 0.5299749374389648, train/logprobs = tensor([[-0.5348, -1.3570],
        [-0.6668, -0.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06553012877702713
Epoch 0, Step 299: train/loss = 0.512657880783081, train/raw-loss = 0.4441831111907959, train/logprobs = tensor([[-0.9281, -2.7152],
        [-0.9154, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06847476959228516
Epoch 0, Step 300: train/loss = 0.5748182535171509, train/raw-loss = 0.5061401128768921, train/logprobs = tensor([[-0.7335, -2.0461],
        [-0.7206, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686781108379364
Epoch 0, Step 301: train/loss = 0.629003643989563, train/raw-loss = 0.5497706532478333, train/logprobs = tensor([[-0.6111, -1.1700],
        [-0.5671, -0.4078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07923305779695511
Epoch 0, Step 302: train/loss = 0.5432420372962952, train/raw-loss = 0.4733026325702667, train/logprobs = tensor([[-0.6126, -2.0297],
        [-0.5820, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06993944197893143
Epoch 0, Step 303: train/loss = 0.5134451389312744, train/raw-loss = 0.44489234685897827, train/logprobs = tensor([[-0.5180, -2.2401],
        [-0.5558, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06855276972055435
Epoch 0, Step 304: train/loss = 0.60138338804245, train/raw-loss = 0.5293066501617432, train/logprobs = tensor([[-0.6219, -1.6190],
        [-0.6150, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07207674533128738
Epoch 0, Step 305: train/loss = 0.6033715605735779, train/raw-loss = 0.5178101062774658, train/logprobs = tensor([[-0.8097, -2.5138],
        [-0.5116, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08556146919727325
Epoch 0, Step 306: train/loss = 0.6180763840675354, train/raw-loss = 0.551214873790741, train/logprobs = tensor([[-0.7547, -3.3185],
        [-0.6368, -1.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06686149537563324
Epoch 0, Step 307: train/loss = 0.6006666421890259, train/raw-loss = 0.5258831977844238, train/logprobs = tensor([[-0.8025, -3.8043],
        [-0.8017, -1.4078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07478339225053787
Epoch 0, Step 308: train/loss = 0.6432551741600037, train/raw-loss = 0.5687763690948486, train/logprobs = tensor([[-0.6681, -1.2914],
        [-0.6381, -0.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07447876036167145
Epoch 0, Step 309: train/loss = 0.6607834696769714, train/raw-loss = 0.5955616235733032, train/logprobs = tensor([[-0.4996, -1.1100],
        [-0.4448, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06522176414728165
Epoch 0, Step 310: train/loss = 0.4551456570625305, train/raw-loss = 0.3807274103164673, train/logprobs = tensor([[-0.6196, -3.5366],
        [-0.5327, -0.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441824674606323
Epoch 0, Step 311: train/loss = 0.6067639589309692, train/raw-loss = 0.5342874526977539, train/logprobs = tensor([[-0.5568, -2.3050],
        [-0.5879, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07247650623321533
Epoch 0, Step 312: train/loss = 0.6272674798965454, train/raw-loss = 0.5659552812576294, train/logprobs = tensor([[-0.6304, -3.1614],
        [-0.4991, -0.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061312124133110046
Epoch 0, Step 313: train/loss = 0.5701666474342346, train/raw-loss = 0.48860716819763184, train/logprobs = tensor([[-0.6005, -2.1342],
        [-0.6126, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08155951648950577
Epoch 0, Step 314: train/loss = 0.6754498481750488, train/raw-loss = 0.604099690914154, train/logprobs = tensor([[-0.5809, -0.8133],
        [-0.5959, -0.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07135021686553955
Epoch 0, Step 315: train/loss = 0.6160969734191895, train/raw-loss = 0.5369271636009216, train/logprobs = tensor([[-1.5497, -3.1509],
        [-1.2562, -1.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07916981726884842
Epoch 0, Step 316: train/loss = 0.7279883623123169, train/raw-loss = 0.6745388507843018, train/logprobs = tensor([[-0.7206, -0.6486],
        [-0.7207, -0.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05344950407743454
Epoch 0, Step 317: train/loss = 0.4801497757434845, train/raw-loss = 0.4104509651660919, train/logprobs = tensor([[-0.4663, -3.9316],
        [-0.4881, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06969881057739258
Epoch 0, Step 318: train/loss = 0.5135511755943298, train/raw-loss = 0.435641348361969, train/logprobs = tensor([[-0.7028, -2.4277],
        [-0.7152, -0.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07790981233119965
Epoch 0, Step 319: train/loss = 0.545427143573761, train/raw-loss = 0.4660581350326538, train/logprobs = tensor([[-0.5226, -2.4097],
        [-0.5392, -0.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07936898618936539
Epoch 0, Step 320: train/loss = 0.5549960732460022, train/raw-loss = 0.48968279361724854, train/logprobs = tensor([[-0.7222, -2.3621],
        [-0.6416, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06531324237585068
Epoch 0, Step 321: train/loss = 0.587549090385437, train/raw-loss = 0.5253254175186157, train/logprobs = tensor([[-0.5985, -1.5985],
        [-0.5660, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0622236542403698
Epoch 0, Step 322: train/loss = 0.5105990767478943, train/raw-loss = 0.4453183710575104, train/logprobs = tensor([[-1.0075, -3.7665],
        [-0.8479, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06528071314096451
Epoch 0, Step 323: train/loss = 0.5511062145233154, train/raw-loss = 0.490468293428421, train/logprobs = tensor([[-0.3878, -2.1126],
        [-0.4132, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060637954622507095
Epoch 0, Step 324: train/loss = 0.42643213272094727, train/raw-loss = 0.3529609441757202, train/logprobs = tensor([[-0.7486, -4.7636],
        [-0.6290, -1.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07347121834754944
Epoch 0, Step 325: train/loss = 0.6609622240066528, train/raw-loss = 0.6006990671157837, train/logprobs = tensor([[-0.5742, -1.0452],
        [-0.5444, -0.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06026321277022362
Epoch 0, Step 326: train/loss = 0.48150041699409485, train/raw-loss = 0.4085800051689148, train/logprobs = tensor([[-0.8837, -4.4657],
        [-0.9465, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07292043417692184
Epoch 0, Step 327: train/loss = 0.75059574842453, train/raw-loss = 0.6791436672210693, train/logprobs = tensor([[-0.8099, -1.0110],
        [-0.6104, -0.7268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07145215570926666
Epoch 0, Step 328: train/loss = 0.6436223983764648, train/raw-loss = 0.5885481834411621, train/logprobs = tensor([[-0.7877, -1.6331],
        [-0.7769, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055074162781238556
Epoch 0, Step 329: train/loss = 0.652754008769989, train/raw-loss = 0.580095648765564, train/logprobs = tensor([[-1.0220, -1.4508],
        [-0.8150, -0.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07265838980674744
Epoch 0, Step 330: train/loss = 0.4041467010974884, train/raw-loss = 0.3356865644454956, train/logprobs = tensor([[-0.6435, -3.8891],
        [-0.6222, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06846015155315399
Epoch 0, Step 331: train/loss = 0.5285648107528687, train/raw-loss = 0.46820521354675293, train/logprobs = tensor([[-0.5972, -3.6708],
        [-0.5855, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060359589755535126
Epoch 0, Step 332: train/loss = 0.4841438829898834, train/raw-loss = 0.41197094321250916, train/logprobs = tensor([[-0.7672, -3.1646],
        [-0.8547, -1.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07217293977737427
Epoch 0, Step 333: train/loss = 0.5535592436790466, train/raw-loss = 0.4870038628578186, train/logprobs = tensor([[-0.7093, -2.6696],
        [-0.5714, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0665554329752922
Epoch 0, Step 334: train/loss = 0.6765315532684326, train/raw-loss = 0.6203069686889648, train/logprobs = tensor([[-0.7165, -0.8891],
        [-0.6137, -0.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056224528700113297
Epoch 0, Step 335: train/loss = 0.5095506906509399, train/raw-loss = 0.4462594985961914, train/logprobs = tensor([[-0.6043, -2.0505],
        [-0.5487, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06329118460416794
Epoch 0, Step 336: train/loss = 0.5823431611061096, train/raw-loss = 0.5173276662826538, train/logprobs = tensor([[-0.5297, -1.5639],
        [-0.5688, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06501555442810059
Epoch 0, Step 337: train/loss = 0.5724121928215027, train/raw-loss = 0.5021536350250244, train/logprobs = tensor([[-0.8062, -1.8538],
        [-0.7947, -0.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07025856524705887
Epoch 0, Step 338: train/loss = 0.5754094123840332, train/raw-loss = 0.5114858150482178, train/logprobs = tensor([[-0.5283, -1.4817],
        [-0.5436, -0.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06392359733581543
Epoch 0, Step 339: train/loss = 0.524181604385376, train/raw-loss = 0.4605766534805298, train/logprobs = tensor([[-0.3643, -3.7969],
        [-0.3849, -1.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063604936003685
Epoch 0, Step 340: train/loss = 0.6345257759094238, train/raw-loss = 0.5716697573661804, train/logprobs = tensor([[-0.6965, -1.2175],
        [-0.6844, -0.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06285601109266281
Epoch 0, Step 341: train/loss = 0.448456346988678, train/raw-loss = 0.3793179988861084, train/logprobs = tensor([[-0.5639, -2.8608],
        [-0.6447, -0.8345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06913833320140839
Epoch 0, Step 342: train/loss = 0.5397194623947144, train/raw-loss = 0.4813394844532013, train/logprobs = tensor([[-0.5302, -2.4260],
        [-0.5877, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05838000401854515
Epoch 0, Step 343: train/loss = 0.6416301131248474, train/raw-loss = 0.5841123461723328, train/logprobs = tensor([[-0.6334, -1.9265],
        [-0.6454, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05751773715019226
Epoch 0, Step 344: train/loss = 0.4566958546638489, train/raw-loss = 0.38503319025039673, train/logprobs = tensor([[-0.7969, -4.8952],
        [-0.7565, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07166267186403275
Epoch 0, Step 345: train/loss = 0.5179974436759949, train/raw-loss = 0.45550787448883057, train/logprobs = tensor([[-1.0038, -3.2326],
        [-1.0587, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062489598989486694
Epoch 0, Step 346: train/loss = 0.5561376214027405, train/raw-loss = 0.4844679534435272, train/logprobs = tensor([[-0.7269, -3.4140],
        [-0.7002, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07166962325572968
Epoch 0, Step 347: train/loss = 0.5554637908935547, train/raw-loss = 0.49105745553970337, train/logprobs = tensor([[-0.5892, -4.0351],
        [-0.6100, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644063651561737
Epoch 0, Step 348: train/loss = 0.5761948227882385, train/raw-loss = 0.5181291103363037, train/logprobs = tensor([[-0.7205, -2.6868],
        [-0.7627, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05806569755077362
Epoch 0, Step 349: train/loss = 0.47530728578567505, train/raw-loss = 0.4050501883029938, train/logprobs = tensor([[-0.6472, -2.4375],
        [-0.6879, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07025707513093948
Epoch 0, Step 350: train/loss = 0.6506599187850952, train/raw-loss = 0.5741192698478699, train/logprobs = tensor([[-1.1173, -2.2001],
        [-0.9481, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07654063403606415
Epoch 0, Step 351: train/loss = 0.5783666372299194, train/raw-loss = 0.5096613764762878, train/logprobs = tensor([[-0.6829, -2.2151],
        [-0.6817, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06870526820421219
Epoch 0, Step 352: train/loss = 0.5218935012817383, train/raw-loss = 0.44837528467178345, train/logprobs = tensor([[-0.4938, -3.0030],
        [-0.5732, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07351820170879364
Epoch 0, Step 353: train/loss = 0.4534805417060852, train/raw-loss = 0.38161319494247437, train/logprobs = tensor([[-0.6925, -3.8631],
        [-0.7729, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07186733931303024
Epoch 0, Step 354: train/loss = 0.669525682926178, train/raw-loss = 0.6097695231437683, train/logprobs = tensor([[-0.4762, -0.9084],
        [-0.4900, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05975614860653877
Epoch 0, Step 355: train/loss = 0.5533440113067627, train/raw-loss = 0.48636454343795776, train/logprobs = tensor([[-0.6843, -2.3846],
        [-0.7519, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06697944551706314
Epoch 0, Step 356: train/loss = 0.6540083289146423, train/raw-loss = 0.588514506816864, train/logprobs = tensor([[-0.4891, -1.0306],
        [-0.4737, -0.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06549382209777832
Epoch 0, Step 357: train/loss = 0.7033227682113647, train/raw-loss = 0.6306873559951782, train/logprobs = tensor([[-1.5574, -2.1380],
        [-1.2570, -1.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07263541966676712
Epoch 0, Step 358: train/loss = 0.5668243765830994, train/raw-loss = 0.5062220096588135, train/logprobs = tensor([[-0.5025, -3.6477],
        [-0.4716, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06060238182544708
Epoch 0, Step 359: train/loss = 0.6190930008888245, train/raw-loss = 0.5508550405502319, train/logprobs = tensor([[-0.8273, -1.6426],
        [-0.8044, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06823795288801193
Epoch 0, Step 360: train/loss = 0.5784322023391724, train/raw-loss = 0.5068212747573853, train/logprobs = tensor([[-0.8206, -2.2687],
        [-0.7938, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07161092758178711
Epoch 0, Step 361: train/loss = 0.6154016256332397, train/raw-loss = 0.5440179705619812, train/logprobs = tensor([[-0.5669, -1.1004],
        [-0.6432, -0.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07138365507125854
Epoch 0, Step 362: train/loss = 0.6375589966773987, train/raw-loss = 0.5799875259399414, train/logprobs = tensor([[-0.6455, -1.5382],
        [-0.6184, -0.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05757145583629608
Epoch 0, Step 363: train/loss = 0.7717474699020386, train/raw-loss = 0.7136560678482056, train/logprobs = tensor([[-1.1982, -1.0965],
        [-0.8222, -0.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05809147283434868
Epoch 0, Step 364: train/loss = 0.45118141174316406, train/raw-loss = 0.3883829116821289, train/logprobs = tensor([[-0.3910, -4.9309],
        [-0.4947, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06279851496219635
Epoch 0, Step 365: train/loss = 0.5285842418670654, train/raw-loss = 0.45616286993026733, train/logprobs = tensor([[-0.5259, -2.1366],
        [-0.5396, -0.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724213495850563
Epoch 0, Step 366: train/loss = 0.5806068778038025, train/raw-loss = 0.5129553079605103, train/logprobs = tensor([[-0.5684, -2.2124],
        [-0.5833, -0.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765156239271164
Epoch 0, Step 367: train/loss = 0.48572254180908203, train/raw-loss = 0.4199671149253845, train/logprobs = tensor([[-0.5431, -2.9020],
        [-0.6368, -0.6153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0657554492354393
Epoch 0, Step 368: train/loss = 0.5576029419898987, train/raw-loss = 0.4883344769477844, train/logprobs = tensor([[-0.4226, -2.0821],
        [-0.4205, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06926846504211426
Epoch 0, Step 369: train/loss = 0.5490468740463257, train/raw-loss = 0.4864550232887268, train/logprobs = tensor([[-0.4488, -1.7307],
        [-0.5023, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06259189546108246
Epoch 0, Step 370: train/loss = 0.6761536598205566, train/raw-loss = 0.6208764314651489, train/logprobs = tensor([[-0.3771, -0.8050],
        [-0.3673, -0.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05527720972895622
Epoch 0, Step 371: train/loss = 0.5513591766357422, train/raw-loss = 0.4896707236766815, train/logprobs = tensor([[-0.4114, -2.5056],
        [-0.4366, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061688464134931564
Epoch 0, Step 372: train/loss = 0.515927791595459, train/raw-loss = 0.44179004430770874, train/logprobs = tensor([[-0.5660, -2.6299],
        [-0.5080, -0.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07413776963949203
Epoch 0, Step 373: train/loss = 0.5718239545822144, train/raw-loss = 0.5064363479614258, train/logprobs = tensor([[-0.7029, -3.9945],
        [-0.6440, -1.2200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06538759917020798
Epoch 0, Step 374: train/loss = 0.585934042930603, train/raw-loss = 0.5162509679794312, train/logprobs = tensor([[-0.3123, -1.9748],
        [-0.3374, -0.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06968311220407486
Epoch 0, Step 375: train/loss = 0.5572172999382019, train/raw-loss = 0.48319923877716064, train/logprobs = tensor([[-0.7060, -1.5111],
        [-0.8601, -0.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07401806861162186
Epoch 0, Step 376: train/loss = 0.4822978675365448, train/raw-loss = 0.40711456537246704, train/logprobs = tensor([[-0.6008, -3.8614],
        [-0.7498, -0.7595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07518330216407776
Epoch 0, Step 377: train/loss = 0.6185824871063232, train/raw-loss = 0.5494862794876099, train/logprobs = tensor([[-0.6114, -2.0818],
        [-0.5508, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06909619271755219
Epoch 0, Step 378: train/loss = 0.5859628319740295, train/raw-loss = 0.5212630033493042, train/logprobs = tensor([[-0.6805, -3.1624],
        [-0.6425, -0.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469985842704773
Epoch 0, Step 379: train/loss = 0.6469502449035645, train/raw-loss = 0.5890359878540039, train/logprobs = tensor([[-0.9440, -1.8896],
        [-0.7966, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791419744491577
Epoch 0, Step 380: train/loss = 0.5810697078704834, train/raw-loss = 0.5160866975784302, train/logprobs = tensor([[-0.5950, -1.5707],
        [-0.6105, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06498304754495621
Epoch 0, Step 381: train/loss = 0.49697816371917725, train/raw-loss = 0.42862218618392944, train/logprobs = tensor([[-0.6668, -3.5636],
        [-0.7849, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683559849858284
Epoch 0, Step 382: train/loss = 0.4674527645111084, train/raw-loss = 0.39683467149734497, train/logprobs = tensor([[-0.5330, -2.9713],
        [-0.5424, -0.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07061808556318283
Epoch 0, Step 383: train/loss = 0.5070528984069824, train/raw-loss = 0.43168121576309204, train/logprobs = tensor([[-0.4624, -2.1212],
        [-0.5815, -0.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07537166029214859
Epoch 0, Step 384: train/loss = 0.5503532290458679, train/raw-loss = 0.4761492908000946, train/logprobs = tensor([[-0.8001, -4.9082],
        [-0.8110, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07420394569635391
Epoch 0, Step 385: train/loss = 0.6375495195388794, train/raw-loss = 0.554803729057312, train/logprobs = tensor([[-1.0360, -1.7560],
        [-0.9091, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08274571597576141
Epoch 0, Step 386: train/loss = 0.7552347779273987, train/raw-loss = 0.699893057346344, train/logprobs = tensor([[-0.8269, -0.7504],
        [-0.6072, -0.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05534173175692558
Epoch 0, Step 387: train/loss = 0.5308467149734497, train/raw-loss = 0.4602091908454895, train/logprobs = tensor([[-0.6007, -4.0554],
        [-0.7471, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706375390291214
Epoch 0, Step 388: train/loss = 0.6081912517547607, train/raw-loss = 0.5238248109817505, train/logprobs = tensor([[-0.6933, -1.8959],
        [-0.7265, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08436641097068787
Epoch 0, Step 389: train/loss = 0.5301911234855652, train/raw-loss = 0.4485076665878296, train/logprobs = tensor([[-0.5479, -1.9350],
        [-0.6114, -0.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08168347924947739
Epoch 0, Step 390: train/loss = 0.5100576877593994, train/raw-loss = 0.4279307425022125, train/logprobs = tensor([[-0.9881, -2.5368],
        [-1.1859, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08212695270776749
Epoch 0, Step 391: train/loss = 0.592969536781311, train/raw-loss = 0.5249089002609253, train/logprobs = tensor([[-0.4849, -1.5094],
        [-0.4737, -0.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06806065142154694
Epoch 0, Step 392: train/loss = 0.5058989524841309, train/raw-loss = 0.43822476267814636, train/logprobs = tensor([[-0.4749, -2.8262],
        [-0.6029, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06767413765192032
Epoch 0, Step 393: train/loss = 0.6096360087394714, train/raw-loss = 0.5321848392486572, train/logprobs = tensor([[-0.6184, -1.5282],
        [-0.5662, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07745111733675003
Epoch 0, Step 394: train/loss = 0.45138928294181824, train/raw-loss = 0.3726324737071991, train/logprobs = tensor([[-0.7411, -5.2794],
        [-0.7916, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07875683903694153
Epoch 0, Step 395: train/loss = 0.5335209369659424, train/raw-loss = 0.46962273120880127, train/logprobs = tensor([[-0.6367, -4.6034],
        [-0.4291, -0.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0638982355594635
Epoch 0, Step 396: train/loss = 0.578324019908905, train/raw-loss = 0.5100646615028381, train/logprobs = tensor([[-0.6904, -1.7382],
        [-0.6933, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06825938075780869
Epoch 0, Step 397: train/loss = 0.6184253692626953, train/raw-loss = 0.5482465028762817, train/logprobs = tensor([[-0.4695, -1.7829],
        [-0.4485, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07017884403467178
Epoch 0, Step 398: train/loss = 0.4678124487400055, train/raw-loss = 0.3906799554824829, train/logprobs = tensor([[-0.5938, -3.0131],
        [-0.6372, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07713249325752258
Epoch 0, Step 399: train/loss = 0.6271353960037231, train/raw-loss = 0.5538132190704346, train/logprobs = tensor([[-0.7503, -1.2785],
        [-0.8630, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07332213222980499
Epoch 0, Step 400: train/loss = 0.6189627051353455, train/raw-loss = 0.5599863529205322, train/logprobs = tensor([[-0.5263, -1.2057],
        [-0.5173, -0.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05897636339068413
Epoch 0, Step 401: train/loss = 0.4826511740684509, train/raw-loss = 0.41232526302337646, train/logprobs = tensor([[-0.7705, -3.2232],
        [-0.7279, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07032591849565506
Epoch 0, Step 402: train/loss = 0.499176025390625, train/raw-loss = 0.4220452904701233, train/logprobs = tensor([[-0.6852, -2.9267],
        [-0.6401, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07713078707456589
Epoch 0, Step 403: train/loss = 0.5846256017684937, train/raw-loss = 0.5273271799087524, train/logprobs = tensor([[-0.3259, -1.4434],
        [-0.3462, -0.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05729842931032181
Epoch 0, Step 404: train/loss = 0.6684207916259766, train/raw-loss = 0.6093742251396179, train/logprobs = tensor([[-0.5783, -1.1926],
        [-0.4686, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059046581387519836
Epoch 0, Step 405: train/loss = 0.5992518067359924, train/raw-loss = 0.5404704809188843, train/logprobs = tensor([[-0.4622, -2.8925],
        [-0.4835, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05878128856420517
Epoch 0, Step 406: train/loss = 0.5649464130401611, train/raw-loss = 0.498456746339798, train/logprobs = tensor([[-0.5592, -2.0484],
        [-0.5560, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06648967415094376
Epoch 0, Step 407: train/loss = 0.6428197622299194, train/raw-loss = 0.5905090570449829, train/logprobs = tensor([[-0.5168, -0.9835],
        [-0.4772, -0.4327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05231068283319473
Epoch 0, Step 408: train/loss = 0.631415605545044, train/raw-loss = 0.5622605085372925, train/logprobs = tensor([[-0.6047, -1.1012],
        [-0.7710, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915504485368729
Epoch 0, Step 409: train/loss = 0.3892871141433716, train/raw-loss = 0.3054373860359192, train/logprobs = tensor([[-0.8482, -4.2229],
        [-1.0787, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384974300861359
Epoch 0, Step 410: train/loss = 0.6315313577651978, train/raw-loss = 0.5650545358657837, train/logprobs = tensor([[-0.5712, -1.8959],
        [-0.5062, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06647685170173645
Epoch 0, Step 411: train/loss = 0.6126322746276855, train/raw-loss = 0.5347918272018433, train/logprobs = tensor([[-0.4850, -1.2501],
        [-0.5341, -0.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07784046977758408
Epoch 0, Step 412: train/loss = 0.635516881942749, train/raw-loss = 0.5713814496994019, train/logprobs = tensor([[-0.4695, -1.1914],
        [-0.5210, -0.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06413543969392776
Epoch 0, Step 413: train/loss = 0.597900390625, train/raw-loss = 0.5354007482528687, train/logprobs = tensor([[-0.7248, -3.7659],
        [-0.5874, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06249958276748657
Epoch 0, Step 414: train/loss = 0.5549270510673523, train/raw-loss = 0.4930589199066162, train/logprobs = tensor([[-0.4240, -1.4813],
        [-0.5087, -0.3512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06186816841363907
Epoch 0, Step 415: train/loss = 0.5202993154525757, train/raw-loss = 0.45349931716918945, train/logprobs = tensor([[-0.7391, -3.5420],
        [-0.7123, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06680001318454742
Epoch 0, Step 416: train/loss = 0.6719962358474731, train/raw-loss = 0.604134202003479, train/logprobs = tensor([[-0.7089, -1.2082],
        [-0.6120, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06786205619573593
Epoch 0, Step 417: train/loss = 0.49897563457489014, train/raw-loss = 0.41805797815322876, train/logprobs = tensor([[-0.5779, -3.2052],
        [-0.8010, -0.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08091767132282257
Epoch 0, Step 418: train/loss = 0.47483497858047485, train/raw-loss = 0.4005465507507324, train/logprobs = tensor([[-0.6066, -2.2804],
        [-0.8215, -0.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428842037916183
Epoch 0, Step 419: train/loss = 0.5000166893005371, train/raw-loss = 0.42523908615112305, train/logprobs = tensor([[-0.8263, -3.0892],
        [-0.8255, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07477765530347824
Epoch 0, Step 420: train/loss = 0.5413815975189209, train/raw-loss = 0.46390092372894287, train/logprobs = tensor([[-0.6885, -2.5734],
        [-0.7829, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774807259440422
Epoch 0, Step 421: train/loss = 0.49697747826576233, train/raw-loss = 0.4187440276145935, train/logprobs = tensor([[-0.6832, -2.0386],
        [-0.9036, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07823346555233002
Epoch 0, Step 422: train/loss = 0.48690226674079895, train/raw-loss = 0.40336284041404724, train/logprobs = tensor([[-0.9336, -3.6530],
        [-0.9200, -1.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08353942632675171
Epoch 0, Step 423: train/loss = 0.5786574482917786, train/raw-loss = 0.5049996972084045, train/logprobs = tensor([[-0.5695, -2.6424],
        [-0.5180, -0.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365778088569641
Epoch 0, Step 424: train/loss = 0.4408782124519348, train/raw-loss = 0.3691056966781616, train/logprobs = tensor([[-0.5667, -3.7093],
        [-0.6820, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07177253067493439
Epoch 0, Step 425: train/loss = 0.8933919072151184, train/raw-loss = 0.827986478805542, train/logprobs = tensor([[-1.8182, -2.5644],
        [-0.5631, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0654054656624794
Epoch 0, Step 426: train/loss = 0.52862149477005, train/raw-loss = 0.4452706277370453, train/logprobs = tensor([[-0.7756, -2.0770],
        [-0.9017, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08335085213184357
Epoch 0, Step 427: train/loss = 0.47160279750823975, train/raw-loss = 0.4032101035118103, train/logprobs = tensor([[-0.5705, -2.4749],
        [-0.6046, -0.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06839273869991302
Epoch 0, Step 428: train/loss = 0.7218209505081177, train/raw-loss = 0.6542774438858032, train/logprobs = tensor([[-0.7551, -0.9475],
        [-0.5819, -0.5440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06754351407289505
Epoch 0, Step 429: train/loss = 0.4603135287761688, train/raw-loss = 0.39458489418029785, train/logprobs = tensor([[-0.5988, -2.7864],
        [-0.6426, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06572862714529037
Epoch 0, Step 430: train/loss = 0.5716532468795776, train/raw-loss = 0.509726345539093, train/logprobs = tensor([[-0.6123, -2.6424],
        [-0.5872, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06192691996693611
Epoch 0, Step 431: train/loss = 0.5633745193481445, train/raw-loss = 0.4939969480037689, train/logprobs = tensor([[-0.6872, -1.3862],
        [-0.7451, -0.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06937763094902039
Epoch 0, Step 432: train/loss = 0.6485965251922607, train/raw-loss = 0.5682793855667114, train/logprobs = tensor([[-0.6953, -1.0701],
        [-0.7694, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0803171694278717
Epoch 0, Step 433: train/loss = 0.6064373850822449, train/raw-loss = 0.5415838956832886, train/logprobs = tensor([[-0.5779, -1.3540],
        [-0.6548, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0648534968495369
Epoch 0, Step 434: train/loss = 0.4359992742538452, train/raw-loss = 0.34673306345939636, train/logprobs = tensor([[-0.7044, -3.5886],
        [-0.7367, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08926621079444885
Epoch 0, Step 435: train/loss = 0.6111373901367188, train/raw-loss = 0.5216167569160461, train/logprobs = tensor([[-1.2116, -2.3514],
        [-0.8414, -0.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.089520663022995
Epoch 0, Step 436: train/loss = 0.5035936236381531, train/raw-loss = 0.41764500737190247, train/logprobs = tensor([[-0.7483, -3.5233],
        [-0.9684, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08594856411218643
Epoch 0, Step 437: train/loss = 0.526491105556488, train/raw-loss = 0.4453226327896118, train/logprobs = tensor([[-0.6742, -3.0186],
        [-0.6885, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08116848021745682
Epoch 0, Step 438: train/loss = 0.5495781898498535, train/raw-loss = 0.47515541315078735, train/logprobs = tensor([[-0.4943, -2.0174],
        [-0.5729, -0.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07442279160022736
Epoch 0, Step 439: train/loss = 0.6235388517379761, train/raw-loss = 0.5604516267776489, train/logprobs = tensor([[-0.4841, -1.1133],
        [-0.5395, -0.4161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06308715790510178
Epoch 0, Step 440: train/loss = 0.6197038888931274, train/raw-loss = 0.5518686771392822, train/logprobs = tensor([[-0.6995, -1.4191],
        [-0.6014, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06783522665500641
Epoch 0, Step 441: train/loss = 0.7096993327140808, train/raw-loss = 0.6405722498893738, train/logprobs = tensor([[-0.9328, -1.4091],
        [-0.6005, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06912710517644882
Epoch 0, Step 442: train/loss = 0.6768827438354492, train/raw-loss = 0.6053668260574341, train/logprobs = tensor([[-0.5137, -0.9452],
        [-0.5048, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07151594758033752
Epoch 0, Step 443: train/loss = 0.7511224746704102, train/raw-loss = 0.6857659816741943, train/logprobs = tensor([[-1.3040, -1.1663],
        [-0.8298, -0.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06535647064447403
Epoch 0, Step 444: train/loss = 0.5507524609565735, train/raw-loss = 0.4617871642112732, train/logprobs = tensor([[-0.8026, -2.1995],
        [-0.6185, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08896531164646149
Epoch 0, Step 445: train/loss = 0.4945266544818878, train/raw-loss = 0.4092799127101898, train/logprobs = tensor([[-0.5399, -2.6265],
        [-0.6997, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08524670451879501
Epoch 0, Step 446: train/loss = 0.582940936088562, train/raw-loss = 0.5125897526741028, train/logprobs = tensor([[-0.8006, -1.8252],
        [-0.7149, -0.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.070351243019104
Epoch 0, Step 447: train/loss = 0.4345548748970032, train/raw-loss = 0.35321104526519775, train/logprobs = tensor([[-0.7976, -5.1336],
        [-0.7420, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08134384453296661
Epoch 0, Step 448: train/loss = 0.4675937294960022, train/raw-loss = 0.3847317695617676, train/logprobs = tensor([[-0.5985, -4.8556],
        [-0.7130, -1.2163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08286196738481522
Epoch 0, Step 449: train/loss = 0.6453900337219238, train/raw-loss = 0.5753350853919983, train/logprobs = tensor([[-0.7139, -1.5954],
        [-0.7100, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07005493342876434
Epoch 0, Step 450: train/loss = 0.6498942971229553, train/raw-loss = 0.5678348541259766, train/logprobs = tensor([[-0.9246, -1.6246],
        [-0.9769, -0.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08205942064523697
Epoch 0, Step 451: train/loss = 0.6238874793052673, train/raw-loss = 0.5468835234642029, train/logprobs = tensor([[-0.7514, -1.3930],
        [-0.7434, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07700393348932266
Epoch 0, Step 452: train/loss = 0.42119285464286804, train/raw-loss = 0.3418058156967163, train/logprobs = tensor([[-0.7194, -5.5483],
        [-0.9248, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938705384731293
Epoch 0, Step 453: train/loss = 0.42256414890289307, train/raw-loss = 0.3529863655567169, train/logprobs = tensor([[-0.6381, -4.0663],
        [-0.7743, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06957776844501495
Epoch 0, Step 454: train/loss = 0.5938050746917725, train/raw-loss = 0.5335919857025146, train/logprobs = tensor([[-0.3940, -2.1707],
        [-0.4493, -0.5045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06021308898925781
Epoch 0, Step 455: train/loss = 0.44831833243370056, train/raw-loss = 0.37578314542770386, train/logprobs = tensor([[-0.6042, -3.0378],
        [-0.7521, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0725352019071579
Epoch 0, Step 456: train/loss = 0.6911662220954895, train/raw-loss = 0.6106263995170593, train/logprobs = tensor([[-0.7718, -1.2022],
        [-0.7681, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08053981512784958
Epoch 0, Step 457: train/loss = 0.48873743414878845, train/raw-loss = 0.40551358461380005, train/logprobs = tensor([[-0.5334, -2.3109],
        [-0.7776, -0.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0832238644361496
Epoch 0, Step 458: train/loss = 0.4490329623222351, train/raw-loss = 0.36948856711387634, train/logprobs = tensor([[-0.5300, -3.8657],
        [-0.7270, -0.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07954441756010056
Epoch 0, Step 459: train/loss = 0.4925973415374756, train/raw-loss = 0.41230112314224243, train/logprobs = tensor([[-0.6507, -2.4065],
        [-0.7459, -0.4830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08029618859291077
Epoch 0, Step 460: train/loss = 0.5342826843261719, train/raw-loss = 0.4573155641555786, train/logprobs = tensor([[-0.6791, -2.8050],
        [-0.7402, -0.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07696708291769028
Epoch 0, Step 461: train/loss = 0.5337794423103333, train/raw-loss = 0.4542015492916107, train/logprobs = tensor([[-0.8554, -2.3687],
        [-0.8453, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07957787811756134
Epoch 0, Step 462: train/loss = 0.5814152359962463, train/raw-loss = 0.5027427673339844, train/logprobs = tensor([[-0.7633, -1.5546],
        [-0.8378, -0.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867248356342316
Epoch 0, Step 463: train/loss = 0.5578892827033997, train/raw-loss = 0.4820370674133301, train/logprobs = tensor([[-0.7936, -1.7829],
        [-0.9758, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07585220783948898
Epoch 0, Step 464: train/loss = 0.4386478364467621, train/raw-loss = 0.35667508840560913, train/logprobs = tensor([[-0.4979, -3.5679],
        [-0.7928, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08197274804115295
Epoch 0, Step 465: train/loss = 0.6017336845397949, train/raw-loss = 0.525580644607544, train/logprobs = tensor([[-0.5877, -1.2842],
        [-0.8049, -0.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615301758050919
Epoch 0, Step 466: train/loss = 0.6266095638275146, train/raw-loss = 0.5520728826522827, train/logprobs = tensor([[-0.8424, -2.3055],
        [-0.8631, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07453671097755432
Epoch 0, Step 467: train/loss = 0.5662347078323364, train/raw-loss = 0.49428802728652954, train/logprobs = tensor([[-0.7320, -2.0214],
        [-0.6870, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07194669544696808
Epoch 0, Step 468: train/loss = 0.39468833804130554, train/raw-loss = 0.29646605253219604, train/logprobs = tensor([[-0.6680, -3.0380],
        [-1.0878, -0.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982222706079483
Epoch 0, Step 469: train/loss = 0.622774064540863, train/raw-loss = 0.5554455518722534, train/logprobs = tensor([[-0.5327, -1.3544],
        [-0.7519, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06732846051454544
Epoch 0, Step 470: train/loss = 0.6451506018638611, train/raw-loss = 0.5604526400566101, train/logprobs = tensor([[-0.8112, -2.0127],
        [-0.5749, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08469796180725098
Epoch 0, Step 471: train/loss = 0.4078708291053772, train/raw-loss = 0.3246520757675171, train/logprobs = tensor([[-0.4465, -3.7212],
        [-0.6130, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0832187756896019
Epoch 0, Step 472: train/loss = 0.5515865087509155, train/raw-loss = 0.48116204142570496, train/logprobs = tensor([[-0.4565, -2.9058],
        [-0.5857, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07042446732521057
Epoch 0, Step 473: train/loss = 0.5003771781921387, train/raw-loss = 0.41711023449897766, train/logprobs = tensor([[-0.9509, -3.9679],
        [-0.7658, -0.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08326692879199982
Epoch 0, Step 474: train/loss = 0.5260035991668701, train/raw-loss = 0.45664721727371216, train/logprobs = tensor([[-0.5637, -2.3030],
        [-0.6863, -0.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06935630738735199
Epoch 0, Step 475: train/loss = 0.44016119837760925, train/raw-loss = 0.3525469899177551, train/logprobs = tensor([[-0.6422, -3.7168],
        [-0.7210, -0.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08761422336101532
Epoch 0, Step 476: train/loss = 0.5904548764228821, train/raw-loss = 0.510243833065033, train/logprobs = tensor([[-0.4214, -1.4246],
        [-0.4499, -0.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08021105825901031
Epoch 0, Step 477: train/loss = 0.5085417032241821, train/raw-loss = 0.41159287095069885, train/logprobs = tensor([[-0.5406, -3.1924],
        [-0.5990, -0.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09694886207580566
Epoch 0, Step 478: train/loss = 0.43879061937332153, train/raw-loss = 0.3629196882247925, train/logprobs = tensor([[-0.7120, -4.7489],
        [-0.7257, -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07587096840143204
Epoch 0, Step 479: train/loss = 0.561244010925293, train/raw-loss = 0.49997377395629883, train/logprobs = tensor([[-0.3583, -3.7155],
        [-0.4870, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06127026677131653
Epoch 0, Step 480: train/loss = 0.6894838213920593, train/raw-loss = 0.6255477666854858, train/logprobs = tensor([[-0.4641, -0.9999],
        [-0.5223, -0.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0639360323548317
Epoch 0, Step 481: train/loss = 0.3903556168079376, train/raw-loss = 0.2884802222251892, train/logprobs = tensor([[-0.7895, -4.9125],
        [-1.0266, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1018754094839096
Epoch 0, Step 482: train/loss = 0.5864831805229187, train/raw-loss = 0.5166099071502686, train/logprobs = tensor([[-0.7588, -1.3781],
        [-0.8825, -0.5157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06987330317497253
Epoch 0, Step 483: train/loss = 0.5323977470397949, train/raw-loss = 0.45870694518089294, train/logprobs = tensor([[-0.5695, -3.0800],
        [-0.7168, -0.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07369077950716019
Epoch 0, Step 484: train/loss = 0.5690041780471802, train/raw-loss = 0.47817036509513855, train/logprobs = tensor([[-0.5352, -2.0051],
        [-0.6655, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09083384275436401
Epoch 0, Step 485: train/loss = 0.3823179602622986, train/raw-loss = 0.2862013280391693, train/logprobs = tensor([[-0.8709, -5.5885],
        [-1.2421, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09611663222312927
Epoch 0, Step 486: train/loss = 0.6680147647857666, train/raw-loss = 0.5908269882202148, train/logprobs = tensor([[-0.5220, -1.0488],
        [-0.6448, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07718773931264877
Epoch 0, Step 487: train/loss = 0.5219374299049377, train/raw-loss = 0.4391508996486664, train/logprobs = tensor([[-0.7805, -2.7606],
        [-0.9057, -0.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08278651535511017
Epoch 0, Step 488: train/loss = 0.5357968807220459, train/raw-loss = 0.4549647569656372, train/logprobs = tensor([[-0.5643, -4.2024],
        [-0.6383, -1.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0808321088552475
Epoch 0, Step 489: train/loss = 0.4933629333972931, train/raw-loss = 0.4024414122104645, train/logprobs = tensor([[-0.5304, -5.6078],
        [-0.9107, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09092149883508682
Epoch 0, Step 490: train/loss = 0.6138157248497009, train/raw-loss = 0.5256673097610474, train/logprobs = tensor([[-0.5128, -1.3210],
        [-0.6661, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08814842253923416
Epoch 0, Step 491: train/loss = 0.5262252688407898, train/raw-loss = 0.4377000331878662, train/logprobs = tensor([[-0.8461, -4.0722],
        [-1.1794, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852524310350418
Epoch 0, Step 492: train/loss = 0.48702311515808105, train/raw-loss = 0.39913564920425415, train/logprobs = tensor([[-0.7776, -3.9041],
        [-1.0929, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08788745105266571
Epoch 0, Step 493: train/loss = 0.6573107838630676, train/raw-loss = 0.5822991728782654, train/logprobs = tensor([[-0.3896, -1.2366],
        [-0.4163, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501164823770523
Epoch 0, Step 494: train/loss = 0.5618414282798767, train/raw-loss = 0.4692404866218567, train/logprobs = tensor([[-0.7807, -1.6575],
        [-1.1009, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09260092675685883
Epoch 0, Step 495: train/loss = 0.5212452411651611, train/raw-loss = 0.4358527660369873, train/logprobs = tensor([[-0.4732, -3.3359],
        [-0.6766, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08539246767759323
Epoch 0, Step 496: train/loss = 0.5654656887054443, train/raw-loss = 0.4723644256591797, train/logprobs = tensor([[-0.5839, -2.6698],
        [-0.6561, -1.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09310121089220047
Epoch 0, Step 497: train/loss = 0.5803908705711365, train/raw-loss = 0.5144911408424377, train/logprobs = tensor([[-0.4639, -1.2326],
        [-0.6167, -0.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06589972227811813
Epoch 0, Step 498: train/loss = 0.46694010496139526, train/raw-loss = 0.36867308616638184, train/logprobs = tensor([[-0.6039, -2.2379],
        [-0.8481, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09826703369617462
Epoch 0, Step 499: train/loss = 0.500947117805481, train/raw-loss = 0.4151025414466858, train/logprobs = tensor([[-0.6039, -3.3073],
        [-0.8197, -0.7371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08584462106227875
Epoch 0, Step 500: train/loss = 0.5951604843139648, train/raw-loss = 0.515824556350708, train/logprobs = tensor([[-0.6301, -2.2943],
        [-0.7858, -0.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07933594286441803
Epoch 0, Step 501: train/loss = 0.5209456086158752, train/raw-loss = 0.4356456995010376, train/logprobs = tensor([[-0.6894, -4.0043],
        [-0.6412, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529990166425705
Epoch 0, Step 502: train/loss = 0.43439802527427673, train/raw-loss = 0.34698522090911865, train/logprobs = tensor([[-0.5615, -2.2493],
        [-0.9947, -0.6656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08741278201341629
Epoch 0, Step 503: train/loss = 0.704670786857605, train/raw-loss = 0.6407018303871155, train/logprobs = tensor([[-0.6044, -1.0117],
        [-0.5026, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06396899372339249
Epoch 0, Step 504: train/loss = 0.5036535263061523, train/raw-loss = 0.4247555732727051, train/logprobs = tensor([[-0.4754, -2.9211],
        [-0.5813, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07889796048402786
Epoch 0, Step 505: train/loss = 0.46947768330574036, train/raw-loss = 0.38147783279418945, train/logprobs = tensor([[-0.5686, -5.6008],
        [-0.8958, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799982815980911
Epoch 0, Step 506: train/loss = 0.630075216293335, train/raw-loss = 0.5540890693664551, train/logprobs = tensor([[-0.6096, -1.3565],
        [-0.6430, -0.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07598614692687988
Epoch 0, Step 507: train/loss = 0.5793092250823975, train/raw-loss = 0.4837675094604492, train/logprobs = tensor([[-0.8649, -4.9551],
        [-0.8109, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09554174542427063
Epoch 0, Step 508: train/loss = 0.5669494271278381, train/raw-loss = 0.4866591691970825, train/logprobs = tensor([[-0.6003, -1.7801],
        [-0.7364, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.080290287733078
Epoch 0, Step 509: train/loss = 0.6312846541404724, train/raw-loss = 0.549057126045227, train/logprobs = tensor([[-0.6644, -1.4878],
        [-0.5843, -0.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08222758024930954
Epoch 0, Step 510: train/loss = 0.5469486713409424, train/raw-loss = 0.4558194577693939, train/logprobs = tensor([[-0.7429, -2.9404],
        [-0.8611, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112923592329025
Epoch 0, Step 511: train/loss = 0.5646430850028992, train/raw-loss = 0.48256245255470276, train/logprobs = tensor([[-0.6964, -2.5473],
        [-0.7495, -0.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08208059519529343
Epoch 0, Step 512: train/loss = 0.5204319357872009, train/raw-loss = 0.4514642655849457, train/logprobs = tensor([[-0.7026, -1.8973],
        [-1.0420, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06896764039993286
Epoch 0, Step 513: train/loss = 0.5457490682601929, train/raw-loss = 0.4680306613445282, train/logprobs = tensor([[-0.4252, -2.7924],
        [-0.5375, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07771836221218109
Epoch 0, Step 514: train/loss = 0.4621121287345886, train/raw-loss = 0.36814457178115845, train/logprobs = tensor([[-0.6378, -3.9137],
        [-0.9620, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09396755695343018
Epoch 0, Step 515: train/loss = 0.7413876056671143, train/raw-loss = 0.6754614114761353, train/logprobs = tensor([[-0.5143, -0.5737],
        [-0.5546, -0.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0659262090921402
Epoch 0, Step 516: train/loss = 0.4770870804786682, train/raw-loss = 0.39455053210258484, train/logprobs = tensor([[-0.6742, -2.4998],
        [-1.0576, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08253654092550278
Epoch 0, Step 517: train/loss = 0.515884280204773, train/raw-loss = 0.4348007142543793, train/logprobs = tensor([[-0.5530, -2.0724],
        [-0.7179, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08108355849981308
Epoch 0, Step 518: train/loss = 0.4361545145511627, train/raw-loss = 0.35634779930114746, train/logprobs = tensor([[-0.7076, -4.8794],
        [-1.3648, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07980672270059586
Epoch 0, Step 519: train/loss = 0.4264797568321228, train/raw-loss = 0.3353698253631592, train/logprobs = tensor([[-0.7583, -3.1461],
        [-0.9472, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09110996872186661
Epoch 0, Step 520: train/loss = 0.7442766427993774, train/raw-loss = 0.6766608357429504, train/logprobs = tensor([[-0.8401, -0.9320],
        [-0.7012, -0.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06761579215526581
Epoch 0, Step 521: train/loss = 0.5303643941879272, train/raw-loss = 0.46552616357803345, train/logprobs = tensor([[-0.3560, -2.1216],
        [-0.4781, -0.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0648382306098938
Epoch 0, Step 522: train/loss = 0.6095802783966064, train/raw-loss = 0.5316112041473389, train/logprobs = tensor([[-1.0826, -2.7879],
        [-0.7891, -0.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07796906679868698
Epoch 0, Step 523: train/loss = 0.5690261125564575, train/raw-loss = 0.49774590134620667, train/logprobs = tensor([[-0.4520, -1.8289],
        [-0.5623, -0.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128023356199265
Epoch 0, Step 524: train/loss = 0.3926398754119873, train/raw-loss = 0.3033908009529114, train/logprobs = tensor([[-0.4447, -5.5676],
        [-0.7495, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924908936023712
Epoch 0, Step 525: train/loss = 0.5918901562690735, train/raw-loss = 0.517108142375946, train/logprobs = tensor([[-0.5625, -1.6076],
        [-0.7376, -0.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07478202879428864
Epoch 0, Step 526: train/loss = 0.5492871999740601, train/raw-loss = 0.4793855547904968, train/logprobs = tensor([[-0.3787, -1.5588],
        [-0.5875, -0.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06990161538124084
Epoch 0, Step 527: train/loss = 0.3705688714981079, train/raw-loss = 0.29234564304351807, train/logprobs = tensor([[-0.5681, -3.5790],
        [-0.9234, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07822324335575104
Epoch 0, Step 528: train/loss = 0.4475650191307068, train/raw-loss = 0.3729223310947418, train/logprobs = tensor([[-0.3499, -4.8625],
        [-0.4327, -1.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07464269548654556
Epoch 0, Step 529: train/loss = 0.4789557456970215, train/raw-loss = 0.39497676491737366, train/logprobs = tensor([[-0.5963, -4.2545],
        [-0.8229, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397898823022842
Epoch 0, Step 530: train/loss = 0.6350343227386475, train/raw-loss = 0.5489262938499451, train/logprobs = tensor([[-0.5562, -1.5624],
        [-0.8960, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610803633928299
Epoch 0, Step 531: train/loss = 0.6110166311264038, train/raw-loss = 0.5405739545822144, train/logprobs = tensor([[-0.4018, -1.2450],
        [-0.5600, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044267654418945
Epoch 0, Step 532: train/loss = 0.562949001789093, train/raw-loss = 0.48173731565475464, train/logprobs = tensor([[-0.5822, -2.6584],
        [-0.9120, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08121168613433838
Epoch 0, Step 533: train/loss = 0.5358476638793945, train/raw-loss = 0.4450455904006958, train/logprobs = tensor([[-0.7264, -3.0457],
        [-0.8453, -1.5460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09080206602811813
Epoch 0, Step 534: train/loss = 0.5969070196151733, train/raw-loss = 0.5136891603469849, train/logprobs = tensor([[-0.4559, -2.0129],
        [-0.6305, -1.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08321784436702728
Epoch 0, Step 535: train/loss = 0.44277268648147583, train/raw-loss = 0.3445424735546112, train/logprobs = tensor([[-0.7356, -3.5014],
        [-1.1527, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09823017567396164
Epoch 0, Step 536: train/loss = 0.49082285165786743, train/raw-loss = 0.41315948963165283, train/logprobs = tensor([[-0.6321, -2.2404],
        [-0.7929, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0776633620262146
Epoch 0, Step 537: train/loss = 0.469389945268631, train/raw-loss = 0.3875296413898468, train/logprobs = tensor([[-0.6005, -2.1856],
        [-0.9826, -0.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08186031132936478
Epoch 0, Step 538: train/loss = 0.46356093883514404, train/raw-loss = 0.3728010058403015, train/logprobs = tensor([[-0.6820, -3.6937],
        [-0.6815, -0.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09075994789600372
Epoch 0, Step 539: train/loss = 0.5182428359985352, train/raw-loss = 0.4521414637565613, train/logprobs = tensor([[-0.3948, -3.0884],
        [-0.5823, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06610136479139328
Epoch 0, Step 540: train/loss = 0.5603876113891602, train/raw-loss = 0.47531598806381226, train/logprobs = tensor([[-0.6134, -2.4701],
        [-0.9609, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08507164567708969
Epoch 0, Step 541: train/loss = 0.420742392539978, train/raw-loss = 0.3308357000350952, train/logprobs = tensor([[-0.7585, -5.0991],
        [-1.2754, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0899067148566246
Epoch 0, Step 542: train/loss = 0.4712974429130554, train/raw-loss = 0.40061843395233154, train/logprobs = tensor([[-0.6443, -2.5517],
        [-0.8634, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07067900151014328
Epoch 0, Step 543: train/loss = 0.48152339458465576, train/raw-loss = 0.39986053109169006, train/logprobs = tensor([[-0.5599, -4.1826],
        [-0.6757, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08166283369064331
Epoch 0, Step 544: train/loss = 0.5709505081176758, train/raw-loss = 0.4856143891811371, train/logprobs = tensor([[-0.5695, -1.7296],
        [-0.7546, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0853361114859581
Epoch 0, Step 545: train/loss = 0.47477513551712036, train/raw-loss = 0.3869669735431671, train/logprobs = tensor([[-0.6060, -2.5027],
        [-1.0819, -0.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08780814707279205
Epoch 0, Step 546: train/loss = 0.48352158069610596, train/raw-loss = 0.40646564960479736, train/logprobs = tensor([[-0.4429, -2.4858],
        [-0.6707, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770559161901474
Epoch 0, Step 547: train/loss = 0.4866214692592621, train/raw-loss = 0.39493417739868164, train/logprobs = tensor([[-0.5997, -4.0254],
        [-0.8028, -1.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09168731421232224
Epoch 0, Step 548: train/loss = 0.5995440483093262, train/raw-loss = 0.5192970037460327, train/logprobs = tensor([[-0.4581, -1.1857],
        [-0.6860, -0.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08024705946445465
Epoch 0, Step 549: train/loss = 0.5585561394691467, train/raw-loss = 0.4702926278114319, train/logprobs = tensor([[-0.8011, -1.7868],
        [-1.1505, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08826351910829544
Epoch 0, Step 550: train/loss = 0.4429139792919159, train/raw-loss = 0.3475523293018341, train/logprobs = tensor([[-0.8500, -3.6211],
        [-1.2527, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0953616201877594
Epoch 0, Step 551: train/loss = 0.5948273539543152, train/raw-loss = 0.5174740552902222, train/logprobs = tensor([[-0.6032, -1.6315],
        [-0.7175, -0.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07735327631235123
Epoch 0, Step 552: train/loss = 0.4767913818359375, train/raw-loss = 0.385134220123291, train/logprobs = tensor([[-0.6764, -2.5745],
        [-1.0712, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09165714681148529
Epoch 0, Step 553: train/loss = 0.5490666627883911, train/raw-loss = 0.4694369435310364, train/logprobs = tensor([[-0.4472, -2.3981],
        [-0.7235, -1.4932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07962977141141891
Epoch 0, Step 554: train/loss = 0.4513790011405945, train/raw-loss = 0.37319302558898926, train/logprobs = tensor([[-0.4969, -3.7773],
        [-0.6694, -1.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07818600535392761
Epoch 0, Step 555: train/loss = 0.5072572827339172, train/raw-loss = 0.43099862337112427, train/logprobs = tensor([[-0.8578, -2.7237],
        [-0.8233, -0.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07625862210988998
Epoch 0, Step 556: train/loss = 0.4908788800239563, train/raw-loss = 0.4033847451210022, train/logprobs = tensor([[-0.4418, -3.4373],
        [-0.6560, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0874941274523735
Epoch 0, Step 557: train/loss = 0.5066145658493042, train/raw-loss = 0.41091015934944153, train/logprobs = tensor([[-0.7401, -3.3036],
        [-1.0982, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09570441395044327
Epoch 0, Step 558: train/loss = 0.6808153986930847, train/raw-loss = 0.5976863503456116, train/logprobs = tensor([[-0.6324, -1.0437],
        [-0.8008, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08312901109457016
Epoch 0, Step 559: train/loss = 0.5124472975730896, train/raw-loss = 0.4285787343978882, train/logprobs = tensor([[-0.5359, -2.3713],
        [-0.6290, -0.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08386857807636261
Epoch 0, Step 560: train/loss = 0.5996068120002747, train/raw-loss = 0.5320804119110107, train/logprobs = tensor([[-0.3498, -1.6077],
        [-0.4106, -0.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06752629578113556
Epoch 0, Step 561: train/loss = 0.5510534644126892, train/raw-loss = 0.46593475341796875, train/logprobs = tensor([[-0.4878, -1.7667],
        [-0.8825, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08511871099472046
Epoch 0, Step 562: train/loss = 0.505902886390686, train/raw-loss = 0.4207460582256317, train/logprobs = tensor([[-0.6351, -3.2056],
        [-0.9228, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515685051679611
Epoch 0, Step 563: train/loss = 0.540418803691864, train/raw-loss = 0.46784496307373047, train/logprobs = tensor([[-0.4142, -2.5567],
        [-0.5772, -0.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07257377356290817
Epoch 0, Step 564: train/loss = 0.5827605724334717, train/raw-loss = 0.49612894654273987, train/logprobs = tensor([[-0.6258, -1.4759],
        [-0.8802, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0866316631436348
Epoch 0, Step 565: train/loss = 0.4683995544910431, train/raw-loss = 0.38104718923568726, train/logprobs = tensor([[-0.8896, -2.8608],
        [-1.2447, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08735235035419464
Epoch 0, Step 566: train/loss = 0.5290435552597046, train/raw-loss = 0.44736695289611816, train/logprobs = tensor([[-0.4525, -5.6353],
        [-0.6134, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08167661726474762
Epoch 0, Step 567: train/loss = 0.4378775954246521, train/raw-loss = 0.354606568813324, train/logprobs = tensor([[-0.5385, -2.7894],
        [-0.9639, -0.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08327103406190872
Epoch 0, Step 568: train/loss = 0.6005340218544006, train/raw-loss = 0.5119964480400085, train/logprobs = tensor([[-0.5539, -2.6256],
        [-0.8732, -0.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08853756636381149
Epoch 0, Step 569: train/loss = 0.4567260146141052, train/raw-loss = 0.3552151322364807, train/logprobs = tensor([[-0.7449, -1.9964],
        [-1.3240, -0.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015108972787857
Epoch 0, Step 570: train/loss = 0.6837798357009888, train/raw-loss = 0.5921659469604492, train/logprobs = tensor([[-1.2113, -1.9921],
        [-0.9049, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09161385893821716
Epoch 0, Step 571: train/loss = 0.476226270198822, train/raw-loss = 0.39033031463623047, train/logprobs = tensor([[-0.5607, -3.1538],
        [-0.6197, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08589592576026917
Epoch 0, Step 572: train/loss = 0.506079375743866, train/raw-loss = 0.42620259523391724, train/logprobs = tensor([[-0.3728, -2.1170],
        [-0.4884, -0.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07987680286169052
Epoch 0, Step 573: train/loss = 0.4591711163520813, train/raw-loss = 0.3752824068069458, train/logprobs = tensor([[-0.5286, -2.9634],
        [-0.6844, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08388872444629669
Epoch 0, Step 574: train/loss = 0.6070446968078613, train/raw-loss = 0.5334376096725464, train/logprobs = tensor([[-0.4806, -1.2324],
        [-0.6788, -0.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07360703498125076
Epoch 0, Step 575: train/loss = 0.4468241333961487, train/raw-loss = 0.36113131046295166, train/logprobs = tensor([[-0.5637, -3.3159],
        [-1.0220, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08569282293319702
Epoch 0, Step 576: train/loss = 0.5830140113830566, train/raw-loss = 0.4846290349960327, train/logprobs = tensor([[-0.7010, -1.4882],
        [-1.0154, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09838502109050751
Epoch 0, Step 577: train/loss = 0.6687608957290649, train/raw-loss = 0.5727976560592651, train/logprobs = tensor([[-0.6602, -1.2978],
        [-0.8785, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09596329927444458
Epoch 0, Step 578: train/loss = 0.4404508173465729, train/raw-loss = 0.34686940908432007, train/logprobs = tensor([[-0.6735, -3.5924],
        [-1.1820, -0.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935814157128334
Epoch 0, Step 579: train/loss = 0.46288710832595825, train/raw-loss = 0.38161417841911316, train/logprobs = tensor([[-0.7456, -4.2590],
        [-0.9838, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08127295970916748
Epoch 0, Step 580: train/loss = 0.5102095007896423, train/raw-loss = 0.43675240874290466, train/logprobs = tensor([[-0.9995, -4.7628],
        [-0.8560, -1.2558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07345708459615707
Epoch 0, Step 581: train/loss = 0.4489406943321228, train/raw-loss = 0.36116495728492737, train/logprobs = tensor([[-0.6386, -6.3150],
        [-1.0076, -1.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777573704719543
Epoch 0, Step 582: train/loss = 0.5856866240501404, train/raw-loss = 0.5080699920654297, train/logprobs = tensor([[-0.6176, -1.4971],
        [-0.9465, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07761664688587189
Epoch 0, Step 583: train/loss = 0.584373414516449, train/raw-loss = 0.5061396360397339, train/logprobs = tensor([[-0.6738, -1.9271],
        [-0.7115, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07823380082845688
Epoch 0, Step 584: train/loss = 0.5650803446769714, train/raw-loss = 0.49660271406173706, train/logprobs = tensor([[-0.4885, -1.7199],
        [-0.7058, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06847760081291199
Epoch 0, Step 585: train/loss = 0.5993713140487671, train/raw-loss = 0.5245404243469238, train/logprobs = tensor([[-0.2972, -1.6568],
        [-0.4513, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07483093440532684
Epoch 0, Step 586: train/loss = 0.5156890749931335, train/raw-loss = 0.42108678817749023, train/logprobs = tensor([[-0.6634, -1.6692],
        [-1.1209, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09460229426622391
Epoch 0, Step 587: train/loss = 0.5821079611778259, train/raw-loss = 0.5108009576797485, train/logprobs = tensor([[-0.5931, -1.3212],
        [-0.7846, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0713069811463356
Epoch 0, Step 588: train/loss = 0.4634692668914795, train/raw-loss = 0.3839559257030487, train/logprobs = tensor([[-0.7168, -4.5503],
        [-1.1901, -1.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07951334118843079
Epoch 0, Step 589: train/loss = 0.4839490056037903, train/raw-loss = 0.39632731676101685, train/logprobs = tensor([[-0.5786, -2.6928],
        [-0.9568, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08762165904045105
Epoch 0, Step 590: train/loss = 0.41264766454696655, train/raw-loss = 0.3309675455093384, train/logprobs = tensor([[-0.4632, -3.4683],
        [-0.6924, -1.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08168010413646698
Epoch 0, Step 591: train/loss = 0.7142895460128784, train/raw-loss = 0.6396647691726685, train/logprobs = tensor([[-0.5966, -0.6784],
        [-0.7035, -0.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0746246725320816
Epoch 0, Step 592: train/loss = 0.5755941867828369, train/raw-loss = 0.49668532609939575, train/logprobs = tensor([[-0.5415, -1.4788],
        [-0.7435, -0.5277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07890887558460236
Epoch 0, Step 593: train/loss = 0.5159131288528442, train/raw-loss = 0.43611884117126465, train/logprobs = tensor([[-0.4827, -2.2678],
        [-0.7487, -0.8240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07979431748390198
Epoch 0, Step 594: train/loss = 0.43690094351768494, train/raw-loss = 0.33692967891693115, train/logprobs = tensor([[-0.6506, -2.5490],
        [-0.9790, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09997126460075378
Epoch 0, Step 595: train/loss = 0.5953843593597412, train/raw-loss = 0.5144418478012085, train/logprobs = tensor([[-0.5257, -1.6208],
        [-0.7082, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08094249665737152
Epoch 0, Step 596: train/loss = 0.5381544828414917, train/raw-loss = 0.45628249645233154, train/logprobs = tensor([[-0.6610, -3.6146],
        [-0.8751, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08187196403741837
Epoch 0, Step 597: train/loss = 0.6855475306510925, train/raw-loss = 0.6088878512382507, train/logprobs = tensor([[-0.6448, -0.8933],
        [-0.8228, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0766596794128418
Epoch 0, Step 598: train/loss = 0.5149911642074585, train/raw-loss = 0.41241422295570374, train/logprobs = tensor([[-0.8672, -2.6517],
        [-0.9018, -0.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10257695615291595
Epoch 0, Step 599: train/loss = 0.5060746669769287, train/raw-loss = 0.4172935485839844, train/logprobs = tensor([[-0.4939, -3.3881],
        [-0.6896, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878111839294434
Epoch 0, Step 600: train/loss = 0.5485484600067139, train/raw-loss = 0.46820592880249023, train/logprobs = tensor([[-0.4548, -2.3948],
        [-0.6222, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08034254610538483
Epoch 0, Step 601: train/loss = 0.5510199069976807, train/raw-loss = 0.4617776572704315, train/logprobs = tensor([[-0.7653, -1.7946],
        [-1.1466, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924227952957153
Epoch 0, Step 602: train/loss = 0.5788736343383789, train/raw-loss = 0.4784129858016968, train/logprobs = tensor([[-0.8223, -2.1634],
        [-0.9303, -1.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10046065598726273
Epoch 0, Step 603: train/loss = 0.396379679441452, train/raw-loss = 0.3019772171974182, train/logprobs = tensor([[-0.5129, -4.8944],
        [-0.8300, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09440246224403381
Epoch 0, Step 604: train/loss = 0.6027933955192566, train/raw-loss = 0.5243551135063171, train/logprobs = tensor([[-0.3694, -1.2373],
        [-0.5655, -0.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07843830436468124
Epoch 0, Step 605: train/loss = 0.5904779434204102, train/raw-loss = 0.5110343098640442, train/logprobs = tensor([[-0.6556, -0.9664],
        [-1.0982, -0.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07944357395172119
Epoch 0, Step 606: train/loss = 0.5483964085578918, train/raw-loss = 0.4693096876144409, train/logprobs = tensor([[-0.6123, -1.6998],
        [-0.6911, -0.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07908671349287033
Epoch 0, Step 607: train/loss = 0.535995602607727, train/raw-loss = 0.43531984090805054, train/logprobs = tensor([[-0.6404, -2.4664],
        [-0.7937, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10067570954561234
Epoch 0, Step 608: train/loss = 0.5212469696998596, train/raw-loss = 0.4342482089996338, train/logprobs = tensor([[-0.5353, -2.1040],
        [-0.9184, -0.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08699876815080643
Epoch 0, Step 609: train/loss = 0.42802894115448, train/raw-loss = 0.3418956398963928, train/logprobs = tensor([[-0.7423, -5.2370],
        [-1.2072, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08613327145576477
Epoch 0, Step 610: train/loss = 0.37181830406188965, train/raw-loss = 0.2603277564048767, train/logprobs = tensor([[-0.8932, -5.5693],
        [-1.3694, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149057745933533
Epoch 0, Step 611: train/loss = 0.3936578929424286, train/raw-loss = 0.31752482056617737, train/logprobs = tensor([[-0.4866, -3.1574],
        [-0.7151, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07613307982683182
Epoch 0, Step 612: train/loss = 0.6143172979354858, train/raw-loss = 0.5253315567970276, train/logprobs = tensor([[-0.6009, -3.0442],
        [-0.8122, -0.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08898578584194183
Epoch 0, Step 613: train/loss = 0.6477864980697632, train/raw-loss = 0.5589120388031006, train/logprobs = tensor([[-0.6597, -1.5406],
        [-0.8308, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08887442201375961
Epoch 0, Step 614: train/loss = 0.5543587803840637, train/raw-loss = 0.4636004567146301, train/logprobs = tensor([[-0.6041, -1.7073],
        [-0.7901, -0.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0907583236694336
Epoch 0, Step 615: train/loss = 0.5457870960235596, train/raw-loss = 0.45537269115448, train/logprobs = tensor([[-0.5650, -1.7132],
        [-0.9424, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09041434526443481
Epoch 0, Step 616: train/loss = 0.7023110389709473, train/raw-loss = 0.621669590473175, train/logprobs = tensor([[-0.4535, -0.8382],
        [-0.6406, -0.7136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0806414932012558
Epoch 0, Step 617: train/loss = 0.5321020483970642, train/raw-loss = 0.45785224437713623, train/logprobs = tensor([[-0.5980, -3.6694],
        [-0.7356, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07424981892108917
Epoch 0, Step 618: train/loss = 0.517447292804718, train/raw-loss = 0.43214285373687744, train/logprobs = tensor([[-0.5068, -2.1193],
        [-0.8544, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08530447632074356
Epoch 0, Step 619: train/loss = 0.4313218593597412, train/raw-loss = 0.34858524799346924, train/logprobs = tensor([[-0.4556, -3.6682],
        [-0.7445, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08273661136627197
Epoch 0, Step 620: train/loss = 0.4484393298625946, train/raw-loss = 0.3552008271217346, train/logprobs = tensor([[-0.6703, -2.6454],
        [-1.1083, -0.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323849529027939
Epoch 0, Step 621: train/loss = 0.6670863628387451, train/raw-loss = 0.5916739702224731, train/logprobs = tensor([[-0.6255, -0.7439],
        [-0.8238, -0.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07541236281394958
Epoch 0, Step 622: train/loss = 0.5180076360702515, train/raw-loss = 0.435224324464798, train/logprobs = tensor([[-0.4203, -3.7581],
        [-0.7618, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08278331905603409
Epoch 0, Step 623: train/loss = 0.49922749400138855, train/raw-loss = 0.4163692593574524, train/logprobs = tensor([[-0.5368, -4.1547],
        [-0.8066, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08285824209451675
Epoch 0, Step 624: train/loss = 0.5359793305397034, train/raw-loss = 0.4471985101699829, train/logprobs = tensor([[-0.5128, -2.4955],
        [-0.8930, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878081291913986
Epoch 0, Step 625: train/loss = 0.5455347895622253, train/raw-loss = 0.4522969424724579, train/logprobs = tensor([[-0.5527, -3.2976],
        [-0.6841, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323785454034805
Epoch 0, Step 626: train/loss = 0.5635956525802612, train/raw-loss = 0.4803205132484436, train/logprobs = tensor([[-0.4889, -1.7750],
        [-0.7489, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08327516913414001
Epoch 0, Step 627: train/loss = 0.5362578630447388, train/raw-loss = 0.4480369985103607, train/logprobs = tensor([[-0.4205, -1.6469],
        [-0.8250, -0.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08822087198495865
Epoch 0, Step 628: train/loss = 0.5070019364356995, train/raw-loss = 0.42205268144607544, train/logprobs = tensor([[-0.4479, -2.0282],
        [-0.7954, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08494924008846283
Epoch 0, Step 629: train/loss = 0.5801781415939331, train/raw-loss = 0.49802166223526, train/logprobs = tensor([[-0.3644, -1.3512],
        [-0.6259, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0821564793586731
Epoch 0, Step 630: train/loss = 0.4862281084060669, train/raw-loss = 0.4056422710418701, train/logprobs = tensor([[-0.3912, -2.8050],
        [-0.5668, -0.7011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08058580011129379
Epoch 0, Step 631: train/loss = 0.41104453802108765, train/raw-loss = 0.32226651906967163, train/logprobs = tensor([[-1.1318, -4.4030],
        [-1.3043, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08877801895141602
Epoch 0, Step 632: train/loss = 0.5347392559051514, train/raw-loss = 0.4316658079624176, train/logprobs = tensor([[-0.6496, -2.9100],
        [-0.9163, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10307338088750839
Epoch 0, Step 633: train/loss = 0.4349459111690521, train/raw-loss = 0.34542545676231384, train/logprobs = tensor([[-0.6647, -3.6324],
        [-0.9326, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08952047675848007
Epoch 0, Step 634: train/loss = 0.4850071668624878, train/raw-loss = 0.3876778483390808, train/logprobs = tensor([[-0.4839, -2.8918],
        [-0.8877, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09732935577630997
Epoch 0, Step 635: train/loss = 0.45018982887268066, train/raw-loss = 0.3616052269935608, train/logprobs = tensor([[-0.5006, -3.8005],
        [-0.8982, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08858463168144226
Epoch 0, Step 636: train/loss = 0.5564647316932678, train/raw-loss = 0.4772908091545105, train/logprobs = tensor([[-0.4994, -2.5379],
        [-0.6603, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07917390763759613
Epoch 0, Step 637: train/loss = 0.48885029554367065, train/raw-loss = 0.414813756942749, train/logprobs = tensor([[-0.5711, -3.3056],
        [-0.7230, -0.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07403653860092163
Epoch 0, Step 638: train/loss = 0.6818716526031494, train/raw-loss = 0.6044949889183044, train/logprobs = tensor([[-0.5055, -0.9259],
        [-0.6187, -0.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07737672328948975
Epoch 0, Step 639: train/loss = 0.5256664156913757, train/raw-loss = 0.42593055963516235, train/logprobs = tensor([[-0.7840, -2.5871],
        [-1.0300, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997358188033104
Epoch 0, Step 640: train/loss = 0.4657976031303406, train/raw-loss = 0.38521140813827515, train/logprobs = tensor([[-0.4886, -3.8738],
        [-0.6496, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08058618754148483
Epoch 0, Step 641: train/loss = 0.6568670272827148, train/raw-loss = 0.5753385424613953, train/logprobs = tensor([[-1.0417, -2.3823],
        [-0.8265, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081528440117836
Epoch 0, Step 642: train/loss = 0.49033474922180176, train/raw-loss = 0.3958824872970581, train/logprobs = tensor([[-0.7447, -2.7912],
        [-0.8994, -0.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09445232152938843
Epoch 0, Step 643: train/loss = 0.40132850408554077, train/raw-loss = 0.3145226240158081, train/logprobs = tensor([[-0.5219, -4.4517],
        [-0.8205, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08680582791566849
Epoch 0, Step 644: train/loss = 0.6232026815414429, train/raw-loss = 0.5370955467224121, train/logprobs = tensor([[-0.8455, -1.0578],
        [-1.1305, -0.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610711246728897
Epoch 0, Step 645: train/loss = 0.4990137219429016, train/raw-loss = 0.41923683881759644, train/logprobs = tensor([[-1.0962, -4.4798],
        [-1.4257, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07977692037820816
Epoch 0, Step 646: train/loss = 0.6660516858100891, train/raw-loss = 0.5870497822761536, train/logprobs = tensor([[-0.4669, -0.8547],
        [-0.7008, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07900191098451614
Epoch 0, Step 647: train/loss = 0.5446648597717285, train/raw-loss = 0.4676622450351715, train/logprobs = tensor([[-0.5403, -2.1274],
        [-0.8122, -0.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077002614736557
Epoch 0, Step 648: train/loss = 0.485697478055954, train/raw-loss = 0.395958811044693, train/logprobs = tensor([[-0.5775, -3.8338],
        [-0.9397, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897386446595192
Epoch 0, Step 649: train/loss = 0.3554210364818573, train/raw-loss = 0.2666405141353607, train/logprobs = tensor([[-0.5957, -5.0254],
        [-1.1793, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878052234649658
Epoch 0, Step 650: train/loss = 0.42534956336021423, train/raw-loss = 0.33652403950691223, train/logprobs = tensor([[-0.5553, -4.4616],
        [-0.9280, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0888255164027214
Epoch 0, Step 651: train/loss = 0.3816111385822296, train/raw-loss = 0.28861305117607117, train/logprobs = tensor([[-0.7665, -3.9450],
        [-1.1219, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09299807250499725
Epoch 0, Step 652: train/loss = 0.4646291136741638, train/raw-loss = 0.39963650703430176, train/logprobs = tensor([[-1.0130, -6.2853],
        [-1.0333, -1.1568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06499261409044266
Epoch 0, Step 653: train/loss = 0.538622260093689, train/raw-loss = 0.46379560232162476, train/logprobs = tensor([[-0.6616, -2.2037],
        [-0.8907, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0748266875743866
Epoch 0, Step 654: train/loss = 0.6446995735168457, train/raw-loss = 0.5714949369430542, train/logprobs = tensor([[-0.5444, -1.7793],
        [-0.5566, -0.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07320468872785568
Epoch 0, Step 655: train/loss = 0.47069039940834045, train/raw-loss = 0.3729596436023712, train/logprobs = tensor([[-0.7235, -2.6471],
        [-1.1647, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773070365190506
Epoch 0, Step 656: train/loss = 0.34917348623275757, train/raw-loss = 0.2622032165527344, train/logprobs = tensor([[-0.8981, -7.2665],
        [-1.1438, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0869702398777008
Epoch 0, Step 657: train/loss = 0.4347103238105774, train/raw-loss = 0.34967344999313354, train/logprobs = tensor([[-0.5847, -4.6360],
        [-0.8709, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08503690361976624
Epoch 0, Step 658: train/loss = 0.5416737794876099, train/raw-loss = 0.44908344745635986, train/logprobs = tensor([[-0.7546, -2.5968],
        [-0.9791, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0925903469324112
Epoch 0, Step 659: train/loss = 0.35775771737098694, train/raw-loss = 0.25830385088920593, train/logprobs = tensor([[-0.4567, -3.9846],
        [-0.8883, -0.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994538888335228
Epoch 0, Step 660: train/loss = 0.6447052955627441, train/raw-loss = 0.5615445971488953, train/logprobs = tensor([[-0.6754, -1.5940],
        [-0.6389, -0.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08316071331501007
Epoch 0, Step 661: train/loss = 0.49691078066825867, train/raw-loss = 0.40715283155441284, train/logprobs = tensor([[-0.5090, -3.3265],
        [-0.8482, -0.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08975794911384583
Epoch 0, Step 662: train/loss = 0.6205449104309082, train/raw-loss = 0.5533673763275146, train/logprobs = tensor([[-0.5524, -1.3331],
        [-0.6894, -0.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06717748194932938
Epoch 0, Step 663: train/loss = 0.51356041431427, train/raw-loss = 0.4335068464279175, train/logprobs = tensor([[-0.8284, -4.4460],
        [-0.7379, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08005355298519135
Epoch 0, Step 664: train/loss = 0.532224178314209, train/raw-loss = 0.44926148653030396, train/logprobs = tensor([[-0.6453, -1.8213],
        [-0.9217, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08296266198158264
Epoch 0, Step 665: train/loss = 0.591698169708252, train/raw-loss = 0.4999570846557617, train/logprobs = tensor([[-0.7789, -1.4500],
        [-0.8661, -0.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09174102544784546
Epoch 0, Step 666: train/loss = 0.48712897300720215, train/raw-loss = 0.39928755164146423, train/logprobs = tensor([[-0.6979, -3.3141],
        [-1.1486, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08784142136573792
Epoch 0, Step 667: train/loss = 0.528404951095581, train/raw-loss = 0.4441401958465576, train/logprobs = tensor([[-0.6045, -2.9466],
        [-0.9562, -0.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08426477015018463
Epoch 0, Step 668: train/loss = 0.6186602115631104, train/raw-loss = 0.531545102596283, train/logprobs = tensor([[-0.5444, -1.1930],
        [-0.8401, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08711514621973038
Epoch 0, Step 669: train/loss = 0.4188460409641266, train/raw-loss = 0.3394503593444824, train/logprobs = tensor([[-0.5521, -3.6548],
        [-0.8939, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07939568161964417
Epoch 0, Step 670: train/loss = 0.46176618337631226, train/raw-loss = 0.3879489004611969, train/logprobs = tensor([[-0.7831, -4.0998],
        [-0.8697, -1.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07381728291511536
Epoch 0, Step 671: train/loss = 0.48992839455604553, train/raw-loss = 0.411236047744751, train/logprobs = tensor([[-0.7367, -2.7659],
        [-0.7662, -0.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07869233936071396
Epoch 0, Step 672: train/loss = 0.5360984802246094, train/raw-loss = 0.4609065055847168, train/logprobs = tensor([[-0.6283, -2.9576],
        [-0.8975, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07519201189279556
Epoch 0, Step 673: train/loss = 0.52558434009552, train/raw-loss = 0.4328385293483734, train/logprobs = tensor([[-0.5464, -2.8638],
        [-0.8515, -0.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927458107471466
Epoch 0, Step 674: train/loss = 0.4880191385746002, train/raw-loss = 0.4073510766029358, train/logprobs = tensor([[-0.3851, -2.2228],
        [-0.7197, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08066808432340622
Epoch 0, Step 675: train/loss = 0.491939902305603, train/raw-loss = 0.3877972364425659, train/logprobs = tensor([[-0.5794, -2.2540],
        [-1.0358, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1041426807641983
Epoch 0, Step 676: train/loss = 0.4103091061115265, train/raw-loss = 0.32228711247444153, train/logprobs = tensor([[-0.4127, -5.2971],
        [-0.8640, -1.0784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08802199363708496
Epoch 0, Step 677: train/loss = 0.5702439546585083, train/raw-loss = 0.478164941072464, train/logprobs = tensor([[-0.4111, -2.2230],
        [-0.6810, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09207899123430252
Epoch 0, Step 678: train/loss = 0.45264896750450134, train/raw-loss = 0.3479420840740204, train/logprobs = tensor([[-0.5295, -4.1405],
        [-1.0332, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470686852931976
Epoch 0, Step 679: train/loss = 0.3937256336212158, train/raw-loss = 0.30583202838897705, train/logprobs = tensor([[-0.7480, -3.4108],
        [-0.9696, -0.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789360523223877
Epoch 0, Step 680: train/loss = 0.45123183727264404, train/raw-loss = 0.374788373708725, train/logprobs = tensor([[-0.5550, -4.2140],
        [-0.8375, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07644347101449966
Epoch 0, Step 681: train/loss = 0.4558039903640747, train/raw-loss = 0.3622436821460724, train/logprobs = tensor([[-0.4883, -2.8165],
        [-0.8438, -0.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356027841567993
Epoch 0, Step 682: train/loss = 0.6261505484580994, train/raw-loss = 0.5284690260887146, train/logprobs = tensor([[-0.8688, -1.8224],
        [-0.7967, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09768152981996536
Epoch 0, Step 683: train/loss = 0.6148139834403992, train/raw-loss = 0.5081321001052856, train/logprobs = tensor([[-0.7384, -1.8390],
        [-1.1335, -0.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10668188333511353
Epoch 0, Step 684: train/loss = 0.4600502848625183, train/raw-loss = 0.37945276498794556, train/logprobs = tensor([[-0.4953, -3.6847],
        [-0.8197, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08059753477573395
Epoch 0, Step 685: train/loss = 0.49827882647514343, train/raw-loss = 0.4108622968196869, train/logprobs = tensor([[-0.4788, -2.6599],
        [-0.7713, -0.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08741653710603714
Epoch 0, Step 686: train/loss = 0.5669228434562683, train/raw-loss = 0.46098947525024414, train/logprobs = tensor([[-0.9926, -2.3133],
        [-1.0808, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10593336075544357
Epoch 0, Step 687: train/loss = 0.5160073041915894, train/raw-loss = 0.44654107093811035, train/logprobs = tensor([[-0.7350, -2.6355],
        [-0.8616, -0.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06946621835231781
Epoch 0, Step 688: train/loss = 0.33928847312927246, train/raw-loss = 0.23888544738292694, train/logprobs = tensor([[-0.5059, -4.5042],
        [-0.9830, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10040305554866791
Epoch 0, Step 689: train/loss = 0.42307668924331665, train/raw-loss = 0.33953893184661865, train/logprobs = tensor([[-0.4919, -4.8776],
        [-0.9537, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0835377648472786
Epoch 0, Step 690: train/loss = 0.5201624631881714, train/raw-loss = 0.45700353384017944, train/logprobs = tensor([[-0.3476, -2.9390],
        [-0.5020, -0.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06315890699625015
Epoch 0, Step 691: train/loss = 0.4258633852005005, train/raw-loss = 0.3361448645591736, train/logprobs = tensor([[-0.7151, -4.6300],
        [-1.4652, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08971855789422989
Epoch 0, Step 692: train/loss = 0.4739162027835846, train/raw-loss = 0.3883815109729767, train/logprobs = tensor([[-0.4591, -2.2270],
        [-0.7791, -0.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0855347141623497
Epoch 0, Step 693: train/loss = 0.4947872757911682, train/raw-loss = 0.4167620539665222, train/logprobs = tensor([[-0.5141, -2.1644],
        [-0.7573, -0.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0780251994729042
Epoch 0, Step 694: train/loss = 0.42643797397613525, train/raw-loss = 0.3386611342430115, train/logprobs = tensor([[-0.6688, -4.5272],
        [-0.9071, -1.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777682483196259
Epoch 0, Step 695: train/loss = 0.628767192363739, train/raw-loss = 0.5411270260810852, train/logprobs = tensor([[-0.5986, -1.4496],
        [-0.9445, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08764021843671799
Epoch 0, Step 696: train/loss = 0.5067133903503418, train/raw-loss = 0.41538289189338684, train/logprobs = tensor([[-0.5475, -3.1468],
        [-1.1065, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133049845695496
Epoch 0, Step 697: train/loss = 0.5120982527732849, train/raw-loss = 0.4316864311695099, train/logprobs = tensor([[-0.3786, -1.7426],
        [-0.6512, -0.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08041179925203323
Epoch 0, Step 698: train/loss = 0.5288082361221313, train/raw-loss = 0.43845391273498535, train/logprobs = tensor([[-0.6097, -2.4822],
        [-1.0637, -0.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09035439044237137
Epoch 0, Step 699: train/loss = 0.34883636236190796, train/raw-loss = 0.26030847430229187, train/logprobs = tensor([[-0.7097, -4.9726],
        [-1.3461, -1.3207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852793276309967
Epoch 0, Step 700: train/loss = 0.4635388255119324, train/raw-loss = 0.37906938791275024, train/logprobs = tensor([[-0.7949, -4.7297],
        [-0.9062, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08446943759918213
Epoch 0, Step 701: train/loss = 0.4568800628185272, train/raw-loss = 0.36140477657318115, train/logprobs = tensor([[-0.6751, -3.7807],
        [-0.8575, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09547531604766846
Epoch 0, Step 702: train/loss = 0.539741575717926, train/raw-loss = 0.46459057927131653, train/logprobs = tensor([[-0.5282, -1.7748],
        [-0.7745, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751509815454483
Epoch 0, Step 703: train/loss = 0.6014635562896729, train/raw-loss = 0.5138566493988037, train/logprobs = tensor([[-0.5866, -1.8380],
        [-0.9107, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08760695159435272
Epoch 0, Step 704: train/loss = 0.3514614701271057, train/raw-loss = 0.2615048885345459, train/logprobs = tensor([[-0.8346, -7.5145],
        [-1.4013, -1.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08995658904314041
Epoch 0, Step 705: train/loss = 0.3530535101890564, train/raw-loss = 0.24694934487342834, train/logprobs = tensor([[-0.8473, -4.2326],
        [-1.3310, -1.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10610415041446686
Epoch 0, Step 706: train/loss = 0.5145524740219116, train/raw-loss = 0.4497940242290497, train/logprobs = tensor([[-0.4396, -3.1391],
        [-0.5981, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06475847214460373
Epoch 0, Step 707: train/loss = 0.4817831516265869, train/raw-loss = 0.38829007744789124, train/logprobs = tensor([[-0.6013, -2.8309],
        [-0.8850, -0.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09349307417869568
Epoch 0, Step 708: train/loss = 0.5060471892356873, train/raw-loss = 0.4268369674682617, train/logprobs = tensor([[-0.5530, -3.0223],
        [-0.7180, -0.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921023666858673
Epoch 0, Step 709: train/loss = 0.27558737993240356, train/raw-loss = 0.17396137118339539, train/logprobs = tensor([[-0.7063, -6.5213],
        [-1.5129, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10162602365016937
Epoch 0, Step 710: train/loss = 0.4034431278705597, train/raw-loss = 0.3108685612678528, train/logprobs = tensor([[-0.6242, -3.5548],
        [-1.1197, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09257456660270691
Epoch 0, Step 711: train/loss = 0.5593905448913574, train/raw-loss = 0.47056129574775696, train/logprobs = tensor([[-0.4827, -2.1702],
        [-0.8372, -0.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08882923424243927
Epoch 0, Step 712: train/loss = 0.5031801462173462, train/raw-loss = 0.42066478729248047, train/logprobs = tensor([[-0.6759, -2.8898],
        [-1.0369, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08251528441905975
Epoch 0, Step 713: train/loss = 0.4310098886489868, train/raw-loss = 0.34390759468078613, train/logprobs = tensor([[-0.7407, -5.0857],
        [-1.0499, -1.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08710227906703949
Epoch 0, Step 714: train/loss = 0.5636072158813477, train/raw-loss = 0.48811236023902893, train/logprobs = tensor([[-0.8254, -3.8419],
        [-0.8889, -0.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07549487054347992
Epoch 0, Step 715: train/loss = 0.40392833948135376, train/raw-loss = 0.3212963938713074, train/logprobs = tensor([[-0.5654, -5.2426],
        [-0.7728, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0826319232583046
Epoch 0, Step 716: train/loss = 0.6179888844490051, train/raw-loss = 0.5364738702774048, train/logprobs = tensor([[-0.5968, -1.3449],
        [-0.8559, -0.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08151498436927795
Epoch 0, Step 717: train/loss = 0.518541157245636, train/raw-loss = 0.43513739109039307, train/logprobs = tensor([[-0.6561, -3.3551],
        [-1.1599, -0.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08340376615524292
Epoch 0, Step 718: train/loss = 0.5321638584136963, train/raw-loss = 0.44840365648269653, train/logprobs = tensor([[-0.8461, -2.6035],
        [-1.0555, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08376015722751617
Epoch 0, Step 719: train/loss = 0.5480459928512573, train/raw-loss = 0.4721981883049011, train/logprobs = tensor([[-0.4356, -1.6366],
        [-0.7023, -0.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758478194475174
Epoch 0, Step 720: train/loss = 0.4486132264137268, train/raw-loss = 0.34979113936424255, train/logprobs = tensor([[-0.5894, -3.0260],
        [-1.0375, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09882207214832306
Epoch 0, Step 721: train/loss = 0.48592665791511536, train/raw-loss = 0.37890303134918213, train/logprobs = tensor([[-0.6395, -2.5772],
        [-0.8860, -0.7119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10702361166477203
Epoch 0, Step 722: train/loss = 0.7440310716629028, train/raw-loss = 0.6718502044677734, train/logprobs = tensor([[-0.5957, -0.6636],
        [-0.6153, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07218082994222641
Epoch 0, Step 723: train/loss = 0.47281402349472046, train/raw-loss = 0.3483298122882843, train/logprobs = tensor([[-0.8616, -3.1786],
        [-1.0529, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12448423355817795
Epoch 0, Step 724: train/loss = 0.4041173458099365, train/raw-loss = 0.3271145820617676, train/logprobs = tensor([[-0.5478, -5.6835],
        [-0.9175, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07700276374816895
Epoch 0, Step 725: train/loss = 0.6057953238487244, train/raw-loss = 0.5249553322792053, train/logprobs = tensor([[-0.8546, -2.9771],
        [-0.7398, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08083998411893845
Epoch 0, Step 726: train/loss = 0.3765146732330322, train/raw-loss = 0.29260388016700745, train/logprobs = tensor([[-0.4421, -5.2080],
        [-0.7212, -0.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08391080051660538
Epoch 0, Step 727: train/loss = 0.5789850354194641, train/raw-loss = 0.4998806416988373, train/logprobs = tensor([[-0.9963, -3.4530],
        [-0.7396, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07910436391830444
Epoch 0, Step 728: train/loss = 0.3185729384422302, train/raw-loss = 0.22366943955421448, train/logprobs = tensor([[-0.6454, -8.1077],
        [-1.3652, -0.9125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09490349143743515
Epoch 0, Step 729: train/loss = 0.6521936058998108, train/raw-loss = 0.5535528659820557, train/logprobs = tensor([[-1.1605, -2.0735],
        [-1.0976, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09864073991775513
Epoch 0, Step 730: train/loss = 0.5696812272071838, train/raw-loss = 0.4979657232761383, train/logprobs = tensor([[-0.3379, -1.5997],
        [-0.5090, -0.6721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07171547412872314
Epoch 0, Step 731: train/loss = 0.5680252909660339, train/raw-loss = 0.48850157856941223, train/logprobs = tensor([[-0.5583, -2.0005],
        [-0.7442, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07952374219894409
Epoch 0, Step 732: train/loss = 0.596056342124939, train/raw-loss = 0.5026373863220215, train/logprobs = tensor([[-0.5459, -1.8406],
        [-0.8324, -1.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341896325349808
Epoch 0, Step 733: train/loss = 0.5381239652633667, train/raw-loss = 0.45952603220939636, train/logprobs = tensor([[-0.5732, -3.5540],
        [-0.7795, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07859791815280914
Epoch 0, Step 734: train/loss = 0.5596894025802612, train/raw-loss = 0.4690144956111908, train/logprobs = tensor([[-0.7863, -2.1435],
        [-1.0343, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09067494422197342
Epoch 0, Step 735: train/loss = 0.7131018042564392, train/raw-loss = 0.6360888481140137, train/logprobs = tensor([[-0.6979, -0.9975],
        [-0.6827, -0.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07701292634010315
Epoch 0, Step 736: train/loss = 0.6530013084411621, train/raw-loss = 0.5886201858520508, train/logprobs = tensor([[-0.3918, -1.1402],
        [-0.5060, -0.7500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06438109278678894
Epoch 0, Step 737: train/loss = 0.3807624578475952, train/raw-loss = 0.2804374098777771, train/logprobs = tensor([[-0.6662, -2.9013],
        [-1.3805, -0.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10032503306865692
Epoch 0, Step 738: train/loss = 0.6119059920310974, train/raw-loss = 0.5281038880348206, train/logprobs = tensor([[-0.6535, -1.7009],
        [-1.0857, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380213379859924
Epoch 0, Step 739: train/loss = 0.4052738845348358, train/raw-loss = 0.31973525881767273, train/logprobs = tensor([[-1.0582, -3.1182],
        [-1.6582, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08553861081600189
Epoch 0, Step 740: train/loss = 0.3141407370567322, train/raw-loss = 0.21861225366592407, train/logprobs = tensor([[-0.6715, -4.3875],
        [-1.1769, -0.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09552847594022751
Epoch 0, Step 741: train/loss = 0.363567054271698, train/raw-loss = 0.23998278379440308, train/logprobs = tensor([[-0.7646, -5.6727],
        [-1.2676, -0.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12358426302671432
Epoch 0, Step 742: train/loss = 0.5261300206184387, train/raw-loss = 0.44463780522346497, train/logprobs = tensor([[-0.4718, -2.3075],
        [-0.7222, -0.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08149217814207077
Epoch 0, Step 743: train/loss = 0.37715476751327515, train/raw-loss = 0.29186007380485535, train/logprobs = tensor([[-0.8452, -6.7923],
        [-1.3456, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0852946862578392
Epoch 0, Step 744: train/loss = 0.6600468158721924, train/raw-loss = 0.5841228365898132, train/logprobs = tensor([[-0.5176, -0.7966],
        [-0.6927, -0.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07592397183179855
Epoch 0, Step 745: train/loss = 0.4824879765510559, train/raw-loss = 0.40533775091171265, train/logprobs = tensor([[-0.4004, -2.1769],
        [-0.6300, -0.6052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07715022563934326
Epoch 0, Step 746: train/loss = 0.7236623764038086, train/raw-loss = 0.6406408548355103, train/logprobs = tensor([[-0.5634, -0.6285],
        [-0.7187, -0.5560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08302147686481476
Epoch 0, Step 747: train/loss = 0.5450843572616577, train/raw-loss = 0.4739498198032379, train/logprobs = tensor([[-0.5266, -1.9046],
        [-0.6255, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.071134552359581
Epoch 0, Step 748: train/loss = 0.6368303298950195, train/raw-loss = 0.5562970638275146, train/logprobs = tensor([[-0.4597, -1.0319],
        [-0.8039, -0.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08053329586982727
Epoch 0, Step 749: train/loss = 0.5175356864929199, train/raw-loss = 0.433694064617157, train/logprobs = tensor([[-0.8020, -3.4521],
        [-1.0924, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384159207344055
Epoch 0, Step 750: train/loss = 0.49938780069351196, train/raw-loss = 0.41967710852622986, train/logprobs = tensor([[-0.8979, -4.7166],
        [-1.4685, -1.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07971066236495972
Epoch 0, Step 751: train/loss = 0.6230296492576599, train/raw-loss = 0.5400269627571106, train/logprobs = tensor([[-0.6256, -2.6732],
        [-0.6871, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08300267159938812
Epoch 0, Step 752: train/loss = 0.587049663066864, train/raw-loss = 0.5004598498344421, train/logprobs = tensor([[-0.4553, -2.6153],
        [-0.7885, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08658978343009949
Epoch 0, Step 753: train/loss = 0.4569503366947174, train/raw-loss = 0.3636324405670166, train/logprobs = tensor([[-0.5329, -2.4264],
        [-0.7097, -0.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.093317911028862
Epoch 0, Step 754: train/loss = 0.45258045196533203, train/raw-loss = 0.3639477491378784, train/logprobs = tensor([[-0.5889, -2.4652],
        [-0.9699, -0.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08863267302513123
Epoch 0, Step 755: train/loss = 0.42992520332336426, train/raw-loss = 0.3272198438644409, train/logprobs = tensor([[-0.7784, -5.7188],
        [-1.2785, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10270534455776215
Epoch 0, Step 756: train/loss = 0.503357470035553, train/raw-loss = 0.4159160852432251, train/logprobs = tensor([[-0.8508, -3.8930],
        [-1.1666, -0.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08744139969348907
Epoch 0, Step 757: train/loss = 0.5744553804397583, train/raw-loss = 0.48103225231170654, train/logprobs = tensor([[-0.5337, -3.4505],
        [-0.8316, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09342309832572937
Epoch 0, Step 758: train/loss = 0.420354425907135, train/raw-loss = 0.32809048891067505, train/logprobs = tensor([[-0.5118, -5.0707],
        [-0.8955, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09226393699645996
Epoch 0, Step 759: train/loss = 0.5042929649353027, train/raw-loss = 0.4203406870365143, train/logprobs = tensor([[-0.5679, -3.3961],
        [-0.7104, -0.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08395222574472427
Epoch 0, Step 760: train/loss = 0.5873804092407227, train/raw-loss = 0.5065786838531494, train/logprobs = tensor([[-1.0485, -3.2498],
        [-0.9803, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08080179244279861
Epoch 0, Step 761: train/loss = 0.6780891418457031, train/raw-loss = 0.5995864868164062, train/logprobs = tensor([[-1.0830, -1.2073],
        [-1.2241, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07850267738103867
Epoch 0, Step 762: train/loss = 0.53368079662323, train/raw-loss = 0.43990588188171387, train/logprobs = tensor([[-0.5468, -2.2618],
        [-0.9179, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09377492219209671
Epoch 0, Step 763: train/loss = 0.48781225085258484, train/raw-loss = 0.37703555822372437, train/logprobs = tensor([[-0.7407, -2.5361],
        [-1.0844, -1.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11077667772769928
Epoch 0, Step 764: train/loss = 0.6045989394187927, train/raw-loss = 0.5298976898193359, train/logprobs = tensor([[-0.6086, -1.3075],
        [-0.8594, -0.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07470124959945679
Epoch 0, Step 765: train/loss = 0.4849385619163513, train/raw-loss = 0.40595537424087524, train/logprobs = tensor([[-0.6901, -4.5801],
        [-1.0061, -1.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07898318767547607
Epoch 0, Step 766: train/loss = 0.4056895971298218, train/raw-loss = 0.2983585596084595, train/logprobs = tensor([[-0.7495, -3.1625],
        [-1.0808, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1073310524225235
Epoch 0, Step 767: train/loss = 0.6174666881561279, train/raw-loss = 0.5152055621147156, train/logprobs = tensor([[-0.5583, -1.6459],
        [-0.7435, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10226111859083176
Epoch 0, Step 768: train/loss = 0.6946852803230286, train/raw-loss = 0.6259191036224365, train/logprobs = tensor([[-0.4495, -0.7235],
        [-0.5573, -0.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876618415117264
Epoch 0, Step 769: train/loss = 0.48189279437065125, train/raw-loss = 0.39214760065078735, train/logprobs = tensor([[-0.8369, -2.7822],
        [-0.9610, -0.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08974514156579971
Epoch 0, Step 770: train/loss = 0.5270664095878601, train/raw-loss = 0.45165181159973145, train/logprobs = tensor([[-0.4657, -1.8329],
        [-0.5712, -0.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07541459053754807
Epoch 0, Step 771: train/loss = 0.38600435853004456, train/raw-loss = 0.301253080368042, train/logprobs = tensor([[-0.5869, -4.8312],
        [-0.7134, -1.3412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475129306316376
Epoch 0, Step 772: train/loss = 0.40234485268592834, train/raw-loss = 0.30837857723236084, train/logprobs = tensor([[-0.8654, -3.3071],
        [-1.0737, -0.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09396626800298691
Epoch 0, Step 773: train/loss = 0.5021567940711975, train/raw-loss = 0.4188052713871002, train/logprobs = tensor([[-0.8284, -3.5815],
        [-0.8074, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08335153758525848
Epoch 0, Step 774: train/loss = 0.5241063833236694, train/raw-loss = 0.44691067934036255, train/logprobs = tensor([[-0.8481, -2.0667],
        [-0.9784, -0.6148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07719571888446808
Epoch 0, Step 775: train/loss = 0.703269898891449, train/raw-loss = 0.6115882992744446, train/logprobs = tensor([[-2.1447, -6.5920],
        [-1.1309, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09168161451816559
Epoch 0, Step 776: train/loss = 0.39835384488105774, train/raw-loss = 0.3254055380821228, train/logprobs = tensor([[-0.7084, -5.6886],
        [-1.0014, -1.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07294830679893494
Epoch 0, Step 777: train/loss = 0.5504380464553833, train/raw-loss = 0.4754706621170044, train/logprobs = tensor([[-0.5169, -2.0493],
        [-0.7648, -0.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07496736943721771
Epoch 0, Step 778: train/loss = 0.4470711648464203, train/raw-loss = 0.35346269607543945, train/logprobs = tensor([[-0.6277, -3.3920],
        [-0.8802, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09360846877098083
Epoch 0, Step 779: train/loss = 0.5704516172409058, train/raw-loss = 0.4848151206970215, train/logprobs = tensor([[-0.7259, -3.8346],
        [-0.6399, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08563653379678726
Epoch 0, Step 780: train/loss = 0.6399344801902771, train/raw-loss = 0.5670773983001709, train/logprobs = tensor([[-0.5492, -1.7477],
        [-0.4900, -0.9984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0728570744395256
Epoch 0, Step 781: train/loss = 0.5704423189163208, train/raw-loss = 0.49026525020599365, train/logprobs = tensor([[-0.8376, -2.0169],
        [-1.0375, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08017707616090775
Epoch 0, Step 782: train/loss = 0.4501364231109619, train/raw-loss = 0.333315908908844, train/logprobs = tensor([[-1.1577, -5.8547],
        [-1.1922, -1.0165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11682049930095673
Epoch 0, Step 783: train/loss = 0.3998660743236542, train/raw-loss = 0.2993851900100708, train/logprobs = tensor([[-0.5678, -3.4856],
        [-0.8214, -0.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10048089176416397
Epoch 0, Step 784: train/loss = 0.33993345499038696, train/raw-loss = 0.24440014362335205, train/logprobs = tensor([[-0.6713, -9.1410],
        [-1.0368, -1.2853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09553330391645432
Epoch 0, Step 785: train/loss = 0.5520016551017761, train/raw-loss = 0.4932529926300049, train/logprobs = tensor([[-0.3315, -2.4104],
        [-0.4126, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05874866619706154
Epoch 0, Step 786: train/loss = 0.3583838641643524, train/raw-loss = 0.27431926131248474, train/logprobs = tensor([[-0.5139, -5.9035],
        [-0.6972, -0.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08406460285186768
Epoch 0, Step 787: train/loss = 0.554317057132721, train/raw-loss = 0.4640140235424042, train/logprobs = tensor([[-0.5536, -2.1797],
        [-0.7798, -0.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09030300378799438
Epoch 0, Step 788: train/loss = 0.45291125774383545, train/raw-loss = 0.35047832131385803, train/logprobs = tensor([[-0.5964, -6.2299],
        [-0.8228, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10243293642997742
Epoch 0, Step 789: train/loss = 0.6461194753646851, train/raw-loss = 0.5725045800209045, train/logprobs = tensor([[-0.6782, -1.4858],
        [-0.5994, -0.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07361488789319992
Epoch 0, Step 790: train/loss = 0.5769060850143433, train/raw-loss = 0.48361432552337646, train/logprobs = tensor([[-0.6314, -2.0629],
        [-0.6894, -0.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0932917445898056
Epoch 0, Step 791: train/loss = 0.6166293025016785, train/raw-loss = 0.540713369846344, train/logprobs = tensor([[-0.8296, -1.7781],
        [-0.9100, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591593265533447
Epoch 0, Step 792: train/loss = 0.4559800624847412, train/raw-loss = 0.364482045173645, train/logprobs = tensor([[-0.6094, -3.2332],
        [-1.0051, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0914979949593544
Epoch 0, Step 793: train/loss = 0.5371983051300049, train/raw-loss = 0.4444724917411804, train/logprobs = tensor([[-0.6962, -6.4244],
        [-0.8603, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09272579848766327
Epoch 0, Step 794: train/loss = 0.42855775356292725, train/raw-loss = 0.3196955919265747, train/logprobs = tensor([[-0.6804, -4.1565],
        [-0.9492, -0.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10886218398809433
Epoch 0, Step 795: train/loss = 0.4606280028820038, train/raw-loss = 0.38103315234184265, train/logprobs = tensor([[-0.8099, -3.7123],
        [-0.8520, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07959486544132233
Epoch 0, Step 796: train/loss = 0.3970869779586792, train/raw-loss = 0.30077797174453735, train/logprobs = tensor([[-0.6762, -5.8111],
        [-1.0217, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09630899131298065
Epoch 0, Step 797: train/loss = 0.5810975432395935, train/raw-loss = 0.506109356880188, train/logprobs = tensor([[-0.5416, -1.4921],
        [-0.6655, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0749882236123085
Epoch 0, Step 798: train/loss = 0.5222110748291016, train/raw-loss = 0.44652053713798523, train/logprobs = tensor([[-0.6962, -4.4117],
        [-0.6442, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07569051533937454
Epoch 0, Step 799: train/loss = 0.5633271336555481, train/raw-loss = 0.4615856111049652, train/logprobs = tensor([[-1.1540, -5.0169],
        [-1.1647, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10174156725406647
Epoch 0, Step 800: train/loss = 0.6651297211647034, train/raw-loss = 0.5926824808120728, train/logprobs = tensor([[-0.9107, -1.5390],
        [-0.8821, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724472850561142
Epoch 0, Step 801: train/loss = 0.34858840703964233, train/raw-loss = 0.24657946825027466, train/logprobs = tensor([[-0.9046, -6.6581],
        [-1.2415, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10200896859169006
Epoch 0, Step 802: train/loss = 0.521282434463501, train/raw-loss = 0.45383015275001526, train/logprobs = tensor([[-0.7504, -2.2676],
        [-0.8636, -0.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0674523115158081
Epoch 0, Step 803: train/loss = 0.4355861246585846, train/raw-loss = 0.36455222964286804, train/logprobs = tensor([[-0.6471, -3.7630],
        [-0.8134, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07103389501571655
Epoch 0, Step 804: train/loss = 0.5502267479896545, train/raw-loss = 0.46529871225357056, train/logprobs = tensor([[-0.6575, -2.9271],
        [-0.8594, -0.7439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0849280059337616
Epoch 0, Step 805: train/loss = 0.5594189167022705, train/raw-loss = 0.48744654655456543, train/logprobs = tensor([[-0.4989, -2.3853],
        [-0.6535, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719723105430603
Epoch 0, Step 806: train/loss = 0.4651375710964203, train/raw-loss = 0.3728838562965393, train/logprobs = tensor([[-0.8009, -5.4287],
        [-0.9551, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09225375205278397
Epoch 0, Step 807: train/loss = 0.41020455956459045, train/raw-loss = 0.32073378562927246, train/logprobs = tensor([[-0.6725, -6.3936],
        [-0.9232, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.089470773935318
Epoch 0, Step 808: train/loss = 0.3961634933948517, train/raw-loss = 0.3189055323600769, train/logprobs = tensor([[-0.5225, -3.6026],
        [-0.8021, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07725796848535538
Epoch 0, Step 809: train/loss = 0.43670105934143066, train/raw-loss = 0.34758374094963074, train/logprobs = tensor([[-0.6303, -5.3273],
        [-0.8662, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911732584238052
Epoch 0, Step 810: train/loss = 0.4148654341697693, train/raw-loss = 0.3181115984916687, train/logprobs = tensor([[-0.5891, -3.8985],
        [-0.8587, -0.6820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0967538133263588
Epoch 0, Step 811: train/loss = 0.5399388074874878, train/raw-loss = 0.4586402177810669, train/logprobs = tensor([[-0.6252, -3.2593],
        [-0.6833, -0.8429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129855245351791
Epoch 0, Step 812: train/loss = 0.5950767993927002, train/raw-loss = 0.5212048292160034, train/logprobs = tensor([[-0.7093, -2.0925],
        [-0.8281, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07387193292379379
Epoch 0, Step 813: train/loss = 0.587142825126648, train/raw-loss = 0.5129091739654541, train/logprobs = tensor([[-0.7162, -1.7086],
        [-0.6719, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07423362880945206
Epoch 0, Step 814: train/loss = 0.3457901179790497, train/raw-loss = 0.2678534686565399, train/logprobs = tensor([[-0.7808, -5.1973],
        [-1.5094, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07793667167425156
Epoch 0, Step 815: train/loss = 0.5300818681716919, train/raw-loss = 0.4390099346637726, train/logprobs = tensor([[-0.7000, -2.3319],
        [-0.7513, -0.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910719484090805
Epoch 0, Step 816: train/loss = 0.3541910946369171, train/raw-loss = 0.28452709317207336, train/logprobs = tensor([[-0.3659, -6.8308],
        [-0.4876, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06966399401426315
Epoch 0, Step 817: train/loss = 0.497728556394577, train/raw-loss = 0.41144871711730957, train/logprobs = tensor([[-0.8814, -4.9946],
        [-1.0970, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08627980947494507
Epoch 0, Step 818: train/loss = 0.3787841796875, train/raw-loss = 0.2951193153858185, train/logprobs = tensor([[-0.6052, -8.9958],
        [-0.9333, -1.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08366487920284271
Epoch 0, Step 819: train/loss = 0.4350031018257141, train/raw-loss = 0.35534733533859253, train/logprobs = tensor([[-0.3748, -4.1958],
        [-0.5928, -0.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07965581119060516
Epoch 0, Step 820: train/loss = 0.4895845055580139, train/raw-loss = 0.3946029245853424, train/logprobs = tensor([[-0.8480, -2.9720],
        [-0.9750, -0.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09498156607151031
Epoch 0, Step 821: train/loss = 0.5148882865905762, train/raw-loss = 0.43196702003479004, train/logprobs = tensor([[-0.6150, -2.3214],
        [-0.9261, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08292125910520554
Epoch 0, Step 822: train/loss = 0.5384787321090698, train/raw-loss = 0.4671742618083954, train/logprobs = tensor([[-0.6559, -2.5203],
        [-0.7221, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07130444794893265
Epoch 0, Step 823: train/loss = 0.5171303749084473, train/raw-loss = 0.44404837489128113, train/logprobs = tensor([[-0.9063, -5.7584],
        [-0.8022, -1.8616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07308200001716614
Epoch 0, Step 824: train/loss = 0.44661954045295715, train/raw-loss = 0.3606470823287964, train/logprobs = tensor([[-0.5406, -5.0049],
        [-0.8272, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08597244322299957
Epoch 0, Step 825: train/loss = 0.7378337383270264, train/raw-loss = 0.663446307182312, train/logprobs = tensor([[-0.8860, -0.5359],
        [-1.1110, -0.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07438743114471436
Epoch 0, Step 826: train/loss = 0.4654708504676819, train/raw-loss = 0.3765678405761719, train/logprobs = tensor([[-0.9245, -3.0794],
        [-1.1310, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08890299499034882
Epoch 0, Step 827: train/loss = 0.4980635941028595, train/raw-loss = 0.4226863980293274, train/logprobs = tensor([[-0.4625, -2.5076],
        [-0.5437, -0.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0753772035241127
Epoch 0, Step 828: train/loss = 0.4290805459022522, train/raw-loss = 0.3263886570930481, train/logprobs = tensor([[-0.7612, -3.1409],
        [-1.2000, -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1026918888092041
Epoch 0, Step 829: train/loss = 0.5661711692810059, train/raw-loss = 0.4821693003177643, train/logprobs = tensor([[-0.8397, -2.9997],
        [-0.8609, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08400183916091919
Epoch 0, Step 830: train/loss = 0.45474401116371155, train/raw-loss = 0.38223838806152344, train/logprobs = tensor([[-0.3771, -4.9404],
        [-0.5557, -1.1584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0725056454539299
Epoch 0, Step 831: train/loss = 0.434027761220932, train/raw-loss = 0.3646667003631592, train/logprobs = tensor([[-0.5799, -2.3497],
        [-0.8162, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06936103105545044
Epoch 0, Step 832: train/loss = 0.48392707109451294, train/raw-loss = 0.3976038694381714, train/logprobs = tensor([[-0.6555, -2.3581],
        [-1.1282, -0.4434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08632321655750275
Epoch 0, Step 833: train/loss = 0.6584439277648926, train/raw-loss = 0.5879372358322144, train/logprobs = tensor([[-0.6525, -1.0721],
        [-0.6560, -0.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07050667703151703
Epoch 0, Step 834: train/loss = 0.42550432682037354, train/raw-loss = 0.3320147395133972, train/logprobs = tensor([[-0.9230, -6.3820],
        [-1.1593, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09348959475755692
Epoch 0, Step 835: train/loss = 0.6657989621162415, train/raw-loss = 0.6089683771133423, train/logprobs = tensor([[-0.9584, -4.0330],
        [-0.7915, -1.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05683058500289917
Epoch 0, Step 836: train/loss = 0.5078047513961792, train/raw-loss = 0.41799837350845337, train/logprobs = tensor([[-0.6596, -5.1928],
        [-0.8271, -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08980637043714523
Epoch 0, Step 837: train/loss = 0.49644196033477783, train/raw-loss = 0.41082537174224854, train/logprobs = tensor([[-0.4753, -2.2643],
        [-0.6046, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0856165736913681
Epoch 0, Step 838: train/loss = 0.4708902835845947, train/raw-loss = 0.3881249725818634, train/logprobs = tensor([[-0.6001, -3.0717],
        [-0.8307, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276528865098953
Epoch 0, Step 839: train/loss = 0.3942839503288269, train/raw-loss = 0.3208771049976349, train/logprobs = tensor([[-0.5406, -5.0864],
        [-0.8911, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07340684533119202
Epoch 0, Step 840: train/loss = 0.4290032982826233, train/raw-loss = 0.32647350430488586, train/logprobs = tensor([[-0.6066, -5.7076],
        [-1.0133, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10252980887889862
Epoch 0, Step 841: train/loss = 0.6082074046134949, train/raw-loss = 0.5239631533622742, train/logprobs = tensor([[-0.6015, -2.0396],
        [-0.7723, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08424428850412369
Epoch 0, Step 842: train/loss = 0.4454721510410309, train/raw-loss = 0.3559654951095581, train/logprobs = tensor([[-0.5146, -6.2518],
        [-0.9726, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950669318437576
Epoch 0, Step 843: train/loss = 0.46332883834838867, train/raw-loss = 0.3769647777080536, train/logprobs = tensor([[-0.8593, -3.5398],
        [-0.8535, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08636406064033508
Epoch 0, Step 844: train/loss = 0.5333266258239746, train/raw-loss = 0.4404463768005371, train/logprobs = tensor([[-1.2737, -5.6587],
        [-0.9330, -1.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09288029372692108
Epoch 0, Step 845: train/loss = 0.4284774661064148, train/raw-loss = 0.33818307518959045, train/logprobs = tensor([[-0.6993, -6.8782],
        [-1.0044, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09029440581798553
Epoch 0, Step 846: train/loss = 0.40515100955963135, train/raw-loss = 0.3265165090560913, train/logprobs = tensor([[-0.5304, -7.9889],
        [-0.7520, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07863455265760422
Epoch 0, Step 847: train/loss = 0.5096019506454468, train/raw-loss = 0.424768328666687, train/logprobs = tensor([[-0.7746, -3.8017],
        [-0.8987, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483359217643738
Epoch 0, Step 848: train/loss = 0.3758679926395416, train/raw-loss = 0.2707788050174713, train/logprobs = tensor([[-0.7205, -4.8689],
        [-1.2331, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10508919507265091
Epoch 0, Step 849: train/loss = 0.37312015891075134, train/raw-loss = 0.28163039684295654, train/logprobs = tensor([[-1.2045, -7.4450],
        [-1.2701, -1.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0914897695183754
Epoch 0, Step 850: train/loss = 0.4995933771133423, train/raw-loss = 0.4171104431152344, train/logprobs = tensor([[-0.5395, -3.6739],
        [-0.6931, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08248292654752731
Epoch 0, Step 851: train/loss = 0.4261261224746704, train/raw-loss = 0.33771270513534546, train/logprobs = tensor([[-0.7888, -5.8146],
        [-1.1754, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08841340243816376
Epoch 0, Step 852: train/loss = 0.4509032964706421, train/raw-loss = 0.3750736713409424, train/logprobs = tensor([[-0.4826, -3.8100],
        [-0.8136, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758296400308609
Epoch 0, Step 853: train/loss = 0.6112262606620789, train/raw-loss = 0.543455183506012, train/logprobs = tensor([[-0.9809, -3.6262],
        [-1.0755, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0677710548043251
Epoch 0, Step 854: train/loss = 0.45645222067832947, train/raw-loss = 0.36552417278289795, train/logprobs = tensor([[-0.7048, -4.4079],
        [-0.9940, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09092807024717331
Epoch 0, Step 855: train/loss = 0.4630695581436157, train/raw-loss = 0.38788041472435, train/logprobs = tensor([[-0.7174, -4.4397],
        [-1.0075, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07518915086984634
Epoch 0, Step 856: train/loss = 0.3750791549682617, train/raw-loss = 0.2877824604511261, train/logprobs = tensor([[-0.7827, -3.8463],
        [-1.1901, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08729671686887741
Epoch 0, Step 857: train/loss = 0.44800707697868347, train/raw-loss = 0.34534159302711487, train/logprobs = tensor([[-0.5944, -5.7018],
        [-1.0265, -0.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1026654988527298
Epoch 0, Step 858: train/loss = 0.6359456777572632, train/raw-loss = 0.5379839539527893, train/logprobs = tensor([[-1.5281, -2.7429],
        [-1.0932, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09796173125505447
Epoch 0, Step 859: train/loss = 0.43016526103019714, train/raw-loss = 0.3562532067298889, train/logprobs = tensor([[-0.7853, -3.3130],
        [-1.0929, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07391203939914703
Epoch 0, Step 860: train/loss = 0.5121226906776428, train/raw-loss = 0.43350082635879517, train/logprobs = tensor([[-0.7070, -3.7129],
        [-0.8212, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07862184941768646
Epoch 0, Step 861: train/loss = 0.6310377717018127, train/raw-loss = 0.5456738471984863, train/logprobs = tensor([[-0.8085, -3.2269],
        [-0.7387, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08536386489868164
Epoch 0, Step 862: train/loss = 0.42991429567337036, train/raw-loss = 0.3356590270996094, train/logprobs = tensor([[-0.6840, -5.1454],
        [-0.8886, -0.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942552462220192
Epoch 0, Step 863: train/loss = 0.5789008140563965, train/raw-loss = 0.4877080023288727, train/logprobs = tensor([[-0.7970, -3.5106],
        [-0.8131, -0.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911928117275238
Epoch 0, Step 864: train/loss = 0.7159262895584106, train/raw-loss = 0.6349273324012756, train/logprobs = tensor([[-1.1382, -1.9813],
        [-0.8022, -0.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08099891990423203
Epoch 0, Step 865: train/loss = 0.4591444730758667, train/raw-loss = 0.37080270051956177, train/logprobs = tensor([[-0.7190, -2.8737],
        [-0.8953, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08834177255630493
Epoch 0, Step 866: train/loss = 0.4076807498931885, train/raw-loss = 0.3250892162322998, train/logprobs = tensor([[-0.6290, -5.8530],
        [-0.6813, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08259154856204987
Epoch 0, Step 867: train/loss = 0.6163788437843323, train/raw-loss = 0.5379383563995361, train/logprobs = tensor([[-0.6447, -2.2147],
        [-0.9244, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07844049483537674
Epoch 0, Step 868: train/loss = 0.5829665660858154, train/raw-loss = 0.48279035091400146, train/logprobs = tensor([[-0.7799, -1.5395],
        [-1.0283, -0.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017623752355576
Epoch 0, Step 869: train/loss = 0.4530446529388428, train/raw-loss = 0.3595302700996399, train/logprobs = tensor([[-0.7358, -2.0682],
        [-1.2745, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935143530368805
Epoch 0, Step 870: train/loss = 0.48084965348243713, train/raw-loss = 0.4077121615409851, train/logprobs = tensor([[-0.8176, -5.8756],
        [-1.0014, -1.4465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07313747704029083
Epoch 0, Step 871: train/loss = 0.42056453227996826, train/raw-loss = 0.3342103958129883, train/logprobs = tensor([[-0.4872, -5.1841],
        [-0.7851, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08635413646697998
Epoch 0, Step 872: train/loss = 0.5416157841682434, train/raw-loss = 0.47582441568374634, train/logprobs = tensor([[-0.3471, -2.6372],
        [-0.4513, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06579139828681946
Epoch 0, Step 873: train/loss = 0.5000598430633545, train/raw-loss = 0.42698606848716736, train/logprobs = tensor([[-0.7850, -3.6666],
        [-0.8706, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07307372987270355
Epoch 0, Step 874: train/loss = 0.41464805603027344, train/raw-loss = 0.3003130555152893, train/logprobs = tensor([[-1.0534, -5.6568],
        [-1.3790, -0.7286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11433493345975876
Epoch 0, Step 875: train/loss = 0.6678362488746643, train/raw-loss = 0.6007635593414307, train/logprobs = tensor([[-0.7775, -1.0471],
        [-0.8924, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06707271933555603
Epoch 0, Step 876: train/loss = 0.46266406774520874, train/raw-loss = 0.3962569832801819, train/logprobs = tensor([[-0.4226, -6.1402],
        [-0.5840, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640706956386566
Epoch 0, Step 877: train/loss = 0.5356199741363525, train/raw-loss = 0.43353936076164246, train/logprobs = tensor([[-1.2751, -4.5662],
        [-1.3274, -0.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10208059847354889
Epoch 0, Step 878: train/loss = 0.9212139844894409, train/raw-loss = 0.8358028531074524, train/logprobs = tensor([[-2.3363, -4.0826],
        [-1.1049, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08541113138198853
Epoch 0, Step 879: train/loss = 0.38584238290786743, train/raw-loss = 0.30268532037734985, train/logprobs = tensor([[-0.4610, -7.3249],
        [-0.7475, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08315704017877579
Epoch 0, Step 880: train/loss = 0.4344082772731781, train/raw-loss = 0.34829971194267273, train/logprobs = tensor([[-0.5640, -4.1625],
        [-0.7339, -0.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610858023166656
Epoch 0, Step 881: train/loss = 0.5650448799133301, train/raw-loss = 0.491016149520874, train/logprobs = tensor([[-0.5090, -3.2402],
        [-0.6470, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07402872294187546
Epoch 0, Step 882: train/loss = 0.6332169771194458, train/raw-loss = 0.5573451519012451, train/logprobs = tensor([[-0.7750, -1.7252],
        [-0.6132, -0.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758717879652977
Epoch 0, Step 883: train/loss = 0.46085575222969055, train/raw-loss = 0.36417603492736816, train/logprobs = tensor([[-1.0940, -2.9485],
        [-1.4552, -0.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0966796949505806
Epoch 0, Step 884: train/loss = 0.43826502561569214, train/raw-loss = 0.34948259592056274, train/logprobs = tensor([[-0.6013, -3.7036],
        [-0.7566, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878243714570999
Epoch 0, Step 885: train/loss = 0.4028405547142029, train/raw-loss = 0.3098030984401703, train/logprobs = tensor([[-0.8854, -4.5154],
        [-0.9717, -0.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09303746372461319
Epoch 0, Step 886: train/loss = 0.5802732110023499, train/raw-loss = 0.5027914047241211, train/logprobs = tensor([[-0.6005, -2.4448],
        [-0.7772, -0.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07748179137706757
Epoch 0, Step 887: train/loss = 0.5375279188156128, train/raw-loss = 0.4547473192214966, train/logprobs = tensor([[-0.6336, -3.7552],
        [-0.7952, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08278059959411621
Epoch 0, Step 888: train/loss = 0.3236275315284729, train/raw-loss = 0.23365890979766846, train/logprobs = tensor([[-0.5856, -5.5170],
        [-1.0226, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08996864408254623
Epoch 0, Step 889: train/loss = 0.4951089918613434, train/raw-loss = 0.41026803851127625, train/logprobs = tensor([[-0.7084, -3.0889],
        [-0.8845, -0.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08484095335006714
Epoch 0, Step 890: train/loss = 0.47067248821258545, train/raw-loss = 0.37292709946632385, train/logprobs = tensor([[-0.7285, -2.7705],
        [-1.0255, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977453887462616
Epoch 0, Step 891: train/loss = 0.3764644265174866, train/raw-loss = 0.2992793917655945, train/logprobs = tensor([[-0.7137, -5.5699],
        [-0.9940, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07718503475189209
Epoch 0, Step 892: train/loss = 0.44093966484069824, train/raw-loss = 0.35252293944358826, train/logprobs = tensor([[-0.5444, -3.7055],
        [-0.8547, -0.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08841672539710999
Epoch 0, Step 893: train/loss = 0.5293440222740173, train/raw-loss = 0.45401227474212646, train/logprobs = tensor([[-0.7065, -3.5548],
        [-0.7995, -0.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07533174753189087
Epoch 0, Step 894: train/loss = 0.4385163187980652, train/raw-loss = 0.34541046619415283, train/logprobs = tensor([[-0.6271, -5.7455],
        [-0.8025, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09310586005449295
Epoch 0, Step 895: train/loss = 0.5176469087600708, train/raw-loss = 0.43351471424102783, train/logprobs = tensor([[-0.6622, -6.7709],
        [-1.0087, -2.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08413217216730118
Epoch 0, Step 896: train/loss = 0.5923589468002319, train/raw-loss = 0.5232610702514648, train/logprobs = tensor([[-0.7017, -1.6683],
        [-0.7784, -0.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06909789890050888
Epoch 0, Step 897: train/loss = 0.5368316173553467, train/raw-loss = 0.4441242218017578, train/logprobs = tensor([[-0.7646, -2.8359],
        [-1.0505, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09270738065242767
Epoch 0, Step 898: train/loss = 0.5874161720275879, train/raw-loss = 0.5186859369277954, train/logprobs = tensor([[-0.6654, -1.2576],
        [-0.8373, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0687301903963089
Epoch 0, Step 899: train/loss = 0.5209343433380127, train/raw-loss = 0.42666977643966675, train/logprobs = tensor([[-0.5616, -4.1020],
        [-0.7921, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09426454454660416
Epoch 0, Step 900: train/loss = 0.36901772022247314, train/raw-loss = 0.28292879462242126, train/logprobs = tensor([[-1.0041, -9.6656],
        [-1.1702, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08608893305063248
Epoch 0, Step 901: train/loss = 0.44878071546554565, train/raw-loss = 0.36496007442474365, train/logprobs = tensor([[-0.3802, -3.6291],
        [-0.6722, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838206484913826
Epoch 0, Step 902: train/loss = 0.3290056586265564, train/raw-loss = 0.24197910726070404, train/logprobs = tensor([[-0.6093, -6.2069],
        [-1.0984, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08702653646469116
Epoch 0, Step 903: train/loss = 0.44704028964042664, train/raw-loss = 0.3513166904449463, train/logprobs = tensor([[-0.8063, -3.4447],
        [-1.1644, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09572359174489975
Epoch 0, Step 904: train/loss = 0.48948433995246887, train/raw-loss = 0.4161846339702606, train/logprobs = tensor([[-1.1374, -4.6542],
        [-1.1309, -1.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07329972088336945
Epoch 0, Step 905: train/loss = 0.37993624806404114, train/raw-loss = 0.3092922568321228, train/logprobs = tensor([[-0.4652, -6.3087],
        [-0.6889, -1.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07064400613307953
Epoch 0, Step 906: train/loss = 0.6876426935195923, train/raw-loss = 0.6245769262313843, train/logprobs = tensor([[-0.6005, -1.0335],
        [-0.4825, -0.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06306573748588562
Epoch 0, Step 907: train/loss = 0.6568558216094971, train/raw-loss = 0.5852891206741333, train/logprobs = tensor([[-0.7226, -1.1875],
        [-0.6654, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07156668603420258
Epoch 0, Step 908: train/loss = 0.4308757185935974, train/raw-loss = 0.3415376842021942, train/logprobs = tensor([[-0.5763, -4.3314],
        [-0.9187, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.089338019490242
Epoch 0, Step 909: train/loss = 0.42580583691596985, train/raw-loss = 0.32480430603027344, train/logprobs = tensor([[-0.9809, -3.4242],
        [-1.4303, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1010015606880188
Epoch 0, Step 910: train/loss = 0.6251376867294312, train/raw-loss = 0.5466102361679077, train/logprobs = tensor([[-0.9532, -3.3263],
        [-0.9055, -1.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07852742075920105
Epoch 0, Step 911: train/loss = 0.3659929633140564, train/raw-loss = 0.2799789309501648, train/logprobs = tensor([[-0.7017, -7.0480],
        [-0.8624, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0860140323638916
Epoch 0, Step 912: train/loss = 0.5720558166503906, train/raw-loss = 0.48756974935531616, train/logprobs = tensor([[-1.1218, -4.5449],
        [-0.4955, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08448611199855804
Epoch 0, Step 913: train/loss = 0.42194223403930664, train/raw-loss = 0.3345365524291992, train/logprobs = tensor([[-0.6820, -5.7774],
        [-1.0084, -1.6016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08740569651126862
Epoch 0, Step 914: train/loss = 0.582797646522522, train/raw-loss = 0.5053249597549438, train/logprobs = tensor([[-0.3938, -1.7572],
        [-0.6427, -0.8168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07747264951467514
Epoch 0, Step 915: train/loss = 0.501615047454834, train/raw-loss = 0.4171600937843323, train/logprobs = tensor([[-0.6900, -2.7797],
        [-0.8840, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0844549834728241
Epoch 0, Step 916: train/loss = 0.5028716921806335, train/raw-loss = 0.4236624538898468, train/logprobs = tensor([[-1.1010, -2.8951],
        [-0.9385, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07920926064252853
Epoch 0, Step 917: train/loss = 0.504596471786499, train/raw-loss = 0.41322991251945496, train/logprobs = tensor([[-0.9418, -2.7220],
        [-0.9729, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09136655181646347
Epoch 0, Step 918: train/loss = 0.6166476607322693, train/raw-loss = 0.5456188917160034, train/logprobs = tensor([[-0.5331, -1.2023],
        [-0.6358, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07102874666452408
Epoch 0, Step 919: train/loss = 0.5793999433517456, train/raw-loss = 0.5112023949623108, train/logprobs = tensor([[-0.8955, -2.7429],
        [-0.7468, -0.8429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06819762289524078
Epoch 0, Step 920: train/loss = 0.6810696721076965, train/raw-loss = 0.6160721778869629, train/logprobs = tensor([[-0.6783, -0.6615],
        [-0.8317, -0.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06499745696783066
Epoch 0, Step 921: train/loss = 0.6103672981262207, train/raw-loss = 0.5463255047798157, train/logprobs = tensor([[-0.4676, -1.7676],
        [-0.6916, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06404181569814682
Epoch 0, Step 922: train/loss = 0.5160974264144897, train/raw-loss = 0.4334017038345337, train/logprobs = tensor([[-0.5854, -3.4627],
        [-0.5746, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08269570767879486
Epoch 0, Step 923: train/loss = 0.48883816599845886, train/raw-loss = 0.4013363718986511, train/logprobs = tensor([[-0.8482, -3.6640],
        [-0.8293, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08750179409980774
Epoch 0, Step 924: train/loss = 0.40134167671203613, train/raw-loss = 0.32401859760284424, train/logprobs = tensor([[-0.6207, -5.7757],
        [-1.1159, -1.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773230642080307
Epoch 0, Step 925: train/loss = 0.5757949352264404, train/raw-loss = 0.5165928602218628, train/logprobs = tensor([[-0.4289, -1.5450],
        [-0.4887, -0.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05920211970806122
Epoch 0, Step 926: train/loss = 0.591394305229187, train/raw-loss = 0.5276436805725098, train/logprobs = tensor([[-0.4777, -1.8283],
        [-0.5464, -0.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06375057995319366
Epoch 0, Step 927: train/loss = 0.6373874545097351, train/raw-loss = 0.5428757071495056, train/logprobs = tensor([[-1.1865, -2.9925],
        [-0.8749, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451176226139069
Epoch 0, Step 928: train/loss = 0.43526244163513184, train/raw-loss = 0.35162556171417236, train/logprobs = tensor([[-0.6888, -4.8129],
        [-0.7016, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363687992095947
Epoch 0, Step 929: train/loss = 0.40807002782821655, train/raw-loss = 0.3250282108783722, train/logprobs = tensor([[-0.5648, -3.5642],
        [-1.0405, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08304183930158615
Epoch 0, Step 930: train/loss = 0.5475698113441467, train/raw-loss = 0.46445149183273315, train/logprobs = tensor([[-0.6968, -1.7465],
        [-0.8508, -0.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08311831951141357
Epoch 0, Step 931: train/loss = 0.4479164183139801, train/raw-loss = 0.3795648217201233, train/logprobs = tensor([[-0.6347, -2.8247],
        [-0.7513, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06835160404443741
Epoch 0, Step 932: train/loss = 0.47557738423347473, train/raw-loss = 0.3808421492576599, train/logprobs = tensor([[-0.4816, -3.1262],
        [-0.8724, -0.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.094735287129879
Epoch 0, Step 933: train/loss = 0.5307915210723877, train/raw-loss = 0.46769341826438904, train/logprobs = tensor([[-0.5928, -1.8912],
        [-0.7193, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06309810280799866
Epoch 0, Step 934: train/loss = 0.5608481168746948, train/raw-loss = 0.4861185550689697, train/logprobs = tensor([[-0.4822, -2.3164],
        [-0.7516, -0.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07472951710224152
Epoch 0, Step 935: train/loss = 0.4628920555114746, train/raw-loss = 0.3703467547893524, train/logprobs = tensor([[-0.7846, -3.2797],
        [-1.0866, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09254530817270279
Epoch 0, Step 936: train/loss = 0.557813286781311, train/raw-loss = 0.47554776072502136, train/logprobs = tensor([[-0.7908, -2.1592],
        [-0.9442, -0.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08226554095745087
Epoch 0, Step 937: train/loss = 0.5648263692855835, train/raw-loss = 0.4857342839241028, train/logprobs = tensor([[-0.7190, -3.0155],
        [-0.7680, -0.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07909214496612549
Epoch 0, Step 938: train/loss = 0.43258190155029297, train/raw-loss = 0.32847803831100464, train/logprobs = tensor([[-0.6583, -2.9128],
        [-1.1327, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10410387814044952
Epoch 0, Step 939: train/loss = 0.4830773174762726, train/raw-loss = 0.40070462226867676, train/logprobs = tensor([[-0.7582, -3.5199],
        [-0.6915, -0.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237268030643463
Epoch 0, Step 940: train/loss = 0.3687293231487274, train/raw-loss = 0.2740771174430847, train/logprobs = tensor([[-0.6923, -3.4944],
        [-1.2581, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0946522131562233
Epoch 0, Step 941: train/loss = 0.47025758028030396, train/raw-loss = 0.40243327617645264, train/logprobs = tensor([[-0.7574, -3.7798],
        [-0.8979, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06782427430152893
Epoch 0, Step 942: train/loss = 0.5409032106399536, train/raw-loss = 0.44804877042770386, train/logprobs = tensor([[-0.8990, -3.3502],
        [-1.1333, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09285442531108856
Epoch 0, Step 943: train/loss = 0.4598098695278168, train/raw-loss = 0.3718228340148926, train/logprobs = tensor([[-0.7223, -2.6113],
        [-1.1903, -0.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08798699080944061
Epoch 0, Step 944: train/loss = 0.33242151141166687, train/raw-loss = 0.23066453635692596, train/logprobs = tensor([[-0.6278, -6.6181],
        [-1.1751, -1.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1017569750547409
Epoch 0, Step 945: train/loss = 0.5391724705696106, train/raw-loss = 0.4724692404270172, train/logprobs = tensor([[-1.0964, -2.9007],
        [-0.9467, -0.7892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.066703200340271
Epoch 0, Step 946: train/loss = 0.4769020974636078, train/raw-loss = 0.3944239020347595, train/logprobs = tensor([[-0.6772, -5.1973],
        [-1.0163, -0.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247821033000946
Epoch 0, Step 947: train/loss = 0.7601430416107178, train/raw-loss = 0.6964881420135498, train/logprobs = tensor([[-0.6869, -0.6438],
        [-0.6268, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365492194890976
Epoch 0, Step 948: train/loss = 0.5094362497329712, train/raw-loss = 0.4162643551826477, train/logprobs = tensor([[-0.5905, -2.3507],
        [-0.7952, -0.4679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09317191690206528
Epoch 0, Step 949: train/loss = 0.5782103538513184, train/raw-loss = 0.49926429986953735, train/logprobs = tensor([[-0.7868, -2.5451],
        [-0.8206, -0.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07894602417945862
Epoch 0, Step 950: train/loss = 0.4160205125808716, train/raw-loss = 0.3350369334220886, train/logprobs = tensor([[-0.4678, -2.9616],
        [-0.9445, -0.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08098356425762177
Epoch 0, Step 951: train/loss = 0.634617030620575, train/raw-loss = 0.5444202423095703, train/logprobs = tensor([[-1.2483, -3.1507],
        [-0.8566, -0.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09019680321216583
Epoch 0, Step 952: train/loss = 0.48781681060791016, train/raw-loss = 0.4201526641845703, train/logprobs = tensor([[-0.3548, -3.4016],
        [-0.5508, -0.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06766410917043686
Epoch 0, Step 953: train/loss = 0.5935730338096619, train/raw-loss = 0.515522837638855, train/logprobs = tensor([[-0.6676, -1.9003],
        [-0.6872, -0.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07805021107196808
Epoch 0, Step 954: train/loss = 0.5827334523200989, train/raw-loss = 0.5148406624794006, train/logprobs = tensor([[-0.6334, -1.4068],
        [-0.7332, -0.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06789281219244003
Epoch 0, Step 955: train/loss = 0.4127503037452698, train/raw-loss = 0.32627105712890625, train/logprobs = tensor([[-0.7035, -5.6513],
        [-0.9251, -1.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08647922426462173
Epoch 0, Step 956: train/loss = 0.4437047839164734, train/raw-loss = 0.36846858263015747, train/logprobs = tensor([[-0.5100, -3.0136],
        [-0.8156, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0752362385392189
Epoch 0, Step 957: train/loss = 0.5196480751037598, train/raw-loss = 0.4440574049949646, train/logprobs = tensor([[-0.9151, -4.9151],
        [-1.0054, -1.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07559062540531158
Epoch 0, Step 958: train/loss = 0.5234485268592834, train/raw-loss = 0.4421064853668213, train/logprobs = tensor([[-0.7088, -4.0098],
        [-0.6699, -0.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08134208619594574
Epoch 0, Step 959: train/loss = 0.4861891567707062, train/raw-loss = 0.4118143320083618, train/logprobs = tensor([[-0.5600, -3.3568],
        [-0.7981, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437482476234436
Epoch 0, Step 960: train/loss = 0.6219130754470825, train/raw-loss = 0.5606720447540283, train/logprobs = tensor([[-0.5614, -1.1807],
        [-0.7725, -0.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06124109774827957
Epoch 0, Step 961: train/loss = 0.4157868027687073, train/raw-loss = 0.33454644680023193, train/logprobs = tensor([[-0.8078, -3.2368],
        [-1.1949, -0.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08124034851789474
Epoch 0, Step 962: train/loss = 0.5428044199943542, train/raw-loss = 0.4727207124233246, train/logprobs = tensor([[-1.2615, -4.5304],
        [-1.2607, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07008366286754608
Epoch 0, Step 963: train/loss = 0.5693212151527405, train/raw-loss = 0.49802592396736145, train/logprobs = tensor([[-0.5597, -1.5278],
        [-0.6494, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07129529863595963
Epoch 0, Step 964: train/loss = 0.5348258018493652, train/raw-loss = 0.4551338255405426, train/logprobs = tensor([[-0.6399, -2.4624],
        [-0.8576, -0.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07969201356172562
Epoch 0, Step 965: train/loss = 0.4411330819129944, train/raw-loss = 0.3727055490016937, train/logprobs = tensor([[-0.7935, -3.6669],
        [-0.9632, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06842748075723648
Epoch 0, Step 966: train/loss = 0.5240393877029419, train/raw-loss = 0.45627713203430176, train/logprobs = tensor([[-0.4255, -2.3265],
        [-0.7649, -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776224076747894
Epoch 0, Step 967: train/loss = 0.5154157876968384, train/raw-loss = 0.448326051235199, train/logprobs = tensor([[-0.4826, -2.1449],
        [-0.7711, -0.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670897588133812
Epoch 0, Step 968: train/loss = 0.5206373929977417, train/raw-loss = 0.45572948455810547, train/logprobs = tensor([[-0.8521, -2.4629],
        [-1.2022, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.064907968044281
Epoch 0, Step 969: train/loss = 0.44033217430114746, train/raw-loss = 0.35440146923065186, train/logprobs = tensor([[-0.5443, -4.9700],
        [-1.0365, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0859307050704956
Epoch 0, Step 970: train/loss = 0.5099040865898132, train/raw-loss = 0.4375630021095276, train/logprobs = tensor([[-0.5526, -2.3227],
        [-0.7108, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07234108448028564
Epoch 0, Step 971: train/loss = 0.4852319359779358, train/raw-loss = 0.41058945655822754, train/logprobs = tensor([[-0.3038, -3.5770],
        [-0.5774, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07464245706796646
Epoch 0, Step 972: train/loss = 0.5163943767547607, train/raw-loss = 0.44947052001953125, train/logprobs = tensor([[-0.6281, -4.3342],
        [-0.6863, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06692386418581009
Epoch 0, Step 973: train/loss = 0.5928994417190552, train/raw-loss = 0.5264362692832947, train/logprobs = tensor([[-0.5676, -1.9167],
        [-0.7744, -0.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0664631798863411
Epoch 0, Step 974: train/loss = 0.5066347122192383, train/raw-loss = 0.4230651259422302, train/logprobs = tensor([[-0.7138, -3.1032],
        [-0.9239, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08356958627700806
Epoch 0, Step 975: train/loss = 0.447494775056839, train/raw-loss = 0.36850038170814514, train/logprobs = tensor([[-0.4611, -2.7075],
        [-0.6590, -0.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07899437844753265
Epoch 0, Step 976: train/loss = 0.5682390332221985, train/raw-loss = 0.4906109571456909, train/logprobs = tensor([[-0.4052, -2.4459],
        [-0.7870, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07762803882360458
Epoch 0, Step 977: train/loss = 0.5433262586593628, train/raw-loss = 0.4666476845741272, train/logprobs = tensor([[-0.6564, -2.9029],
        [-0.7909, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0766785740852356
Epoch 0, Step 978: train/loss = 0.5304064750671387, train/raw-loss = 0.4361938238143921, train/logprobs = tensor([[-1.0244, -2.8733],
        [-0.9244, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09421265125274658
Epoch 0, Step 979: train/loss = 0.4933571517467499, train/raw-loss = 0.4286905527114868, train/logprobs = tensor([[-0.4509, -2.5963],
        [-0.7546, -0.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06466658413410187
Epoch 0, Step 980: train/loss = 0.40223222970962524, train/raw-loss = 0.3293364644050598, train/logprobs = tensor([[-0.6017, -2.8749],
        [-0.9099, -0.7612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07289576530456543
Epoch 0, Step 981: train/loss = 0.4495799243450165, train/raw-loss = 0.36783790588378906, train/logprobs = tensor([[-0.9444, -4.2419],
        [-1.2678, -1.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174201101064682
Epoch 0, Step 982: train/loss = 0.43549036979675293, train/raw-loss = 0.3622954487800598, train/logprobs = tensor([[-0.5598, -2.6916],
        [-0.8307, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0731949582695961
Epoch 0, Step 983: train/loss = 0.4933057427406311, train/raw-loss = 0.41735994815826416, train/logprobs = tensor([[-0.6788, -2.7840],
        [-0.8432, -0.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07594576478004456
Epoch 0, Step 984: train/loss = 0.5512893199920654, train/raw-loss = 0.46470654010772705, train/logprobs = tensor([[-0.4838, -1.6868],
        [-0.9430, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08658280223608017
Epoch 0, Step 985: train/loss = 0.6262357234954834, train/raw-loss = 0.5658653974533081, train/logprobs = tensor([[-0.6006, -1.1288],
        [-0.6882, -0.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06037028878927231
Epoch 0, Step 986: train/loss = 0.3293300271034241, train/raw-loss = 0.24587494134902954, train/logprobs = tensor([[-0.6317, -6.5157],
        [-1.1560, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08345507085323334
Epoch 0, Step 987: train/loss = 0.582635223865509, train/raw-loss = 0.5172560214996338, train/logprobs = tensor([[-0.9394, -1.6989],
        [-0.8867, -0.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06537922471761703
Epoch 0, Step 988: train/loss = 0.589508593082428, train/raw-loss = 0.5046009421348572, train/logprobs = tensor([[-0.6438, -1.8053],
        [-1.3735, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0849076360464096
Epoch 0, Step 989: train/loss = 0.45290249586105347, train/raw-loss = 0.37324196100234985, train/logprobs = tensor([[-0.6513, -2.4620],
        [-0.9244, -0.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796605572104454
Epoch 0, Step 990: train/loss = 0.5466901063919067, train/raw-loss = 0.47682255506515503, train/logprobs = tensor([[-0.4703, -2.2729],
        [-0.5803, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0698675736784935
Epoch 0, Step 991: train/loss = 0.6259345412254333, train/raw-loss = 0.5629242062568665, train/logprobs = tensor([[-0.5371, -1.0028],
        [-0.6349, -0.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06301036477088928
Epoch 0, Step 992: train/loss = 0.4910486340522766, train/raw-loss = 0.4143989682197571, train/logprobs = tensor([[-0.4672, -2.7624],
        [-0.7124, -0.4133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07664966583251953
Epoch 0, Step 993: train/loss = 0.46047264337539673, train/raw-loss = 0.3870253562927246, train/logprobs = tensor([[-0.5291, -2.1115],
        [-0.8926, -0.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0734473168849945
Epoch 0, Step 994: train/loss = 0.3584699034690857, train/raw-loss = 0.2726854979991913, train/logprobs = tensor([[-0.7132, -4.0707],
        [-1.1833, -0.9243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08578439801931381
Epoch 0, Step 995: train/loss = 0.3341931700706482, train/raw-loss = 0.26552271842956543, train/logprobs = tensor([[-0.4532, -3.9785],
        [-0.7030, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06867044419050217
Epoch 0, Step 996: train/loss = 0.5789463520050049, train/raw-loss = 0.5191928148269653, train/logprobs = tensor([[-0.4827, -3.5404],
        [-0.7017, -1.1916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05975352227687836
Epoch 0, Step 997: train/loss = 0.3763161599636078, train/raw-loss = 0.3035511374473572, train/logprobs = tensor([[-0.5867, -4.0924],
        [-0.7027, -0.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276502251625061
Epoch 0, Step 998: train/loss = 0.456001341342926, train/raw-loss = 0.35144028067588806, train/logprobs = tensor([[-0.5596, -2.4505],
        [-1.1910, -0.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456105321645737
Epoch 0, Step 999: train/loss = 0.5759962201118469, train/raw-loss = 0.5104759931564331, train/logprobs = tensor([[-0.5483, -1.6143],
        [-0.8049, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06552021950483322
Epoch 0, Step 1000: train/loss = 0.5639153718948364, train/raw-loss = 0.4686419367790222, train/logprobs = tensor([[-0.7936, -1.7628],
        [-1.2234, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952734500169754
Epoch 0, Step 1001: train/loss = 0.4864875078201294, train/raw-loss = 0.40718746185302734, train/logprobs = tensor([[-0.5813, -2.9012],
        [-1.0060, -1.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07930001616477966
Epoch 0, Step 1002: train/loss = 0.525955319404602, train/raw-loss = 0.44034242630004883, train/logprobs = tensor([[-0.4694, -3.5047],
        [-0.9548, -0.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08561290800571442
Epoch 0, Step 1003: train/loss = 0.4927218556404114, train/raw-loss = 0.40414735674858093, train/logprobs = tensor([[-0.8692, -2.9168],
        [-1.0195, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08857446908950806
Epoch 0, Step 1004: train/loss = 0.6859259605407715, train/raw-loss = 0.6215614080429077, train/logprobs = tensor([[-0.5972, -0.8145],
        [-0.6169, -0.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06436455994844437
Epoch 0, Step 1005: train/loss = 0.327471524477005, train/raw-loss = 0.24548567831516266, train/logprobs = tensor([[-0.6405, -5.9261],
        [-1.0505, -1.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08198586106300354
Epoch 0, Step 1006: train/loss = 0.6312593221664429, train/raw-loss = 0.5697601437568665, train/logprobs = tensor([[-0.6375, -1.0887],
        [-0.8472, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061499208211898804
Epoch 0, Step 1007: train/loss = 0.6211791038513184, train/raw-loss = 0.5580262541770935, train/logprobs = tensor([[-1.2616, -1.5859],
        [-1.2675, -0.6408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06315282732248306
Epoch 0, Step 1008: train/loss = 0.5175722241401672, train/raw-loss = 0.44109809398651123, train/logprobs = tensor([[-0.5184, -3.4713],
        [-0.7737, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764741376042366
Epoch 0, Step 1009: train/loss = 0.5257237553596497, train/raw-loss = 0.45507073402404785, train/logprobs = tensor([[-0.6579, -4.2803],
        [-1.0514, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07065300643444061
Epoch 0, Step 1010: train/loss = 0.5382587909698486, train/raw-loss = 0.46033352613449097, train/logprobs = tensor([[-0.7004, -3.2617],
        [-0.7484, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07792526483535767
Epoch 0, Step 1011: train/loss = 0.61360764503479, train/raw-loss = 0.5381838083267212, train/logprobs = tensor([[-0.4919, -1.3490],
        [-0.8597, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07542380690574646
Epoch 0, Step 1012: train/loss = 0.39559102058410645, train/raw-loss = 0.31486231088638306, train/logprobs = tensor([[-0.6364, -3.4823],
        [-1.1496, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08072872459888458
Epoch 0, Step 1013: train/loss = 0.3362184166908264, train/raw-loss = 0.2295706868171692, train/logprobs = tensor([[-0.8439, -5.5384],
        [-1.6555, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10664772242307663
Epoch 0, Step 1014: train/loss = 0.5103375911712646, train/raw-loss = 0.432015597820282, train/logprobs = tensor([[-0.7042, -2.8146],
        [-0.9037, -0.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07832200825214386
Epoch 0, Step 1015: train/loss = 0.40793412923812866, train/raw-loss = 0.3248651623725891, train/logprobs = tensor([[-0.5302, -3.5036],
        [-1.0923, -0.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08306898176670074
Epoch 0, Step 1016: train/loss = 0.5119290947914124, train/raw-loss = 0.42848435044288635, train/logprobs = tensor([[-0.7456, -4.5936],
        [-0.9507, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08344471454620361
Epoch 0, Step 1017: train/loss = 0.4459676146507263, train/raw-loss = 0.3734089136123657, train/logprobs = tensor([[-0.5103, -4.9229],
        [-0.7306, -1.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07255866378545761
Epoch 0, Step 1018: train/loss = 0.5405969023704529, train/raw-loss = 0.46465054154396057, train/logprobs = tensor([[-0.6875, -2.7260],
        [-0.8409, -0.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07594641298055649
Epoch 0, Step 1019: train/loss = 0.45915621519088745, train/raw-loss = 0.3783770501613617, train/logprobs = tensor([[-0.9073, -4.0442],
        [-1.1689, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08077915757894516
Epoch 0, Step 1020: train/loss = 0.5012069940567017, train/raw-loss = 0.43337225914001465, train/logprobs = tensor([[-0.6506, -5.4612],
        [-0.6102, -1.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06783472001552582
Epoch 0, Step 1021: train/loss = 0.43678444623947144, train/raw-loss = 0.35848337411880493, train/logprobs = tensor([[-0.5319, -3.8617],
        [-0.8467, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830105721950531
Epoch 0, Step 1022: train/loss = 0.5675458908081055, train/raw-loss = 0.5146310925483704, train/logprobs = tensor([[-0.4657, -1.2212],
        [-0.7884, -0.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052914828062057495
Epoch 0, Step 1023: train/loss = 0.5997974872589111, train/raw-loss = 0.5314298272132874, train/logprobs = tensor([[-0.5103, -1.7953],
        [-0.8740, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06836767494678497
Epoch 0, Step 1024: train/loss = 0.4947361350059509, train/raw-loss = 0.41485121846199036, train/logprobs = tensor([[-0.7705, -3.4289],
        [-0.7709, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07988489419221878
Epoch 0, Step 1025: train/loss = 0.4642130732536316, train/raw-loss = 0.39831557869911194, train/logprobs = tensor([[-0.6829, -3.2850],
        [-0.8179, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06589748710393906
Epoch 0, Step 1026: train/loss = 0.45102763175964355, train/raw-loss = 0.35905158519744873, train/logprobs = tensor([[-0.6345, -3.0682],
        [-0.9019, -0.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09197606891393661
Epoch 0, Step 1027: train/loss = 0.7029284834861755, train/raw-loss = 0.6514652967453003, train/logprobs = tensor([[-0.5001, -0.7481],
        [-0.6334, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05146311968564987
Epoch 0, Step 1028: train/loss = 0.4489433765411377, train/raw-loss = 0.39429670572280884, train/logprobs = tensor([[-0.7545, -4.8496],
        [-1.2099, -1.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05464668571949005
Epoch 0, Step 1029: train/loss = 0.5938738584518433, train/raw-loss = 0.5307912230491638, train/logprobs = tensor([[-0.3923, -1.7764],
        [-0.5620, -0.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06308265030384064
Epoch 0, Step 1030: train/loss = 0.4341607093811035, train/raw-loss = 0.359038770198822, train/logprobs = tensor([[-0.6069, -5.1246],
        [-1.2096, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751219093799591
Epoch 0, Step 1031: train/loss = 0.5358003973960876, train/raw-loss = 0.47188299894332886, train/logprobs = tensor([[-0.5598, -1.8828],
        [-0.7494, -0.8111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06391739845275879
Epoch 0, Step 1032: train/loss = 0.5544941425323486, train/raw-loss = 0.4900089502334595, train/logprobs = tensor([[-0.6483, -1.7265],
        [-1.0639, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448519974946976
Epoch 0, Step 1033: train/loss = 0.4116864800453186, train/raw-loss = 0.31835275888442993, train/logprobs = tensor([[-0.9254, -4.0227],
        [-1.5325, -0.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333370625972748
Epoch 0, Step 1034: train/loss = 0.44879698753356934, train/raw-loss = 0.3827226758003235, train/logprobs = tensor([[-0.6501, -2.1246],
        [-1.0470, -0.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06607435643672943
Epoch 0, Step 1035: train/loss = 0.5765910744667053, train/raw-loss = 0.48135673999786377, train/logprobs = tensor([[-0.7185, -2.1758],
        [-1.1380, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09523437172174454
Epoch 0, Step 1036: train/loss = 0.5908299684524536, train/raw-loss = 0.5188677310943604, train/logprobs = tensor([[-0.4928, -1.7950],
        [-0.7561, -0.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07196217775344849
Epoch 0, Step 1037: train/loss = 0.5756085515022278, train/raw-loss = 0.5109070539474487, train/logprobs = tensor([[-0.5319, -2.8274],
        [-0.8999, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06470154225826263
Epoch 0, Step 1038: train/loss = 0.4524988532066345, train/raw-loss = 0.36973124742507935, train/logprobs = tensor([[-0.7647, -3.8811],
        [-1.0336, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276763558387756
Epoch 0, Step 1039: train/loss = 0.42044636607170105, train/raw-loss = 0.34635138511657715, train/logprobs = tensor([[-0.6583, -7.4394],
        [-1.0972, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740949735045433
Epoch 0, Step 1040: train/loss = 0.5441299676895142, train/raw-loss = 0.4736856520175934, train/logprobs = tensor([[-1.3164, -3.3824],
        [-1.2666, -1.2556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044431567192078
Epoch 0, Step 1041: train/loss = 0.4147561192512512, train/raw-loss = 0.32551249861717224, train/logprobs = tensor([[-0.7228, -5.4286],
        [-1.0014, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08924365043640137
Epoch 0, Step 1042: train/loss = 0.5427066087722778, train/raw-loss = 0.4911693334579468, train/logprobs = tensor([[-0.6357, -2.1346],
        [-0.5901, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051537249237298965
Epoch 0, Step 1043: train/loss = 0.701698362827301, train/raw-loss = 0.6394635438919067, train/logprobs = tensor([[-0.9444, -1.1644],
        [-0.7559, -0.5105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06223480403423309
Epoch 0, Step 1044: train/loss = 0.6053766012191772, train/raw-loss = 0.5343623161315918, train/logprobs = tensor([[-0.9496, -1.2740],
        [-1.2983, -0.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07101428508758545
Epoch 0, Step 1045: train/loss = 0.4962276816368103, train/raw-loss = 0.4300929307937622, train/logprobs = tensor([[-0.5576, -3.1126],
        [-0.8165, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0661347508430481
Epoch 0, Step 1046: train/loss = 0.5187692642211914, train/raw-loss = 0.44945040345191956, train/logprobs = tensor([[-0.5041, -3.0529],
        [-0.7273, -0.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06931887567043304
Epoch 0, Step 1047: train/loss = 0.5905205607414246, train/raw-loss = 0.5190075635910034, train/logprobs = tensor([[-0.5349, -1.1334],
        [-0.8344, -0.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07151295989751816
Epoch 0, Step 1048: train/loss = 0.3275061547756195, train/raw-loss = 0.25105124711990356, train/logprobs = tensor([[-0.6082, -6.8391],
        [-1.0188, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07645490765571594
Epoch 0, Step 1049: train/loss = 0.43103283643722534, train/raw-loss = 0.3496251702308655, train/logprobs = tensor([[-0.6683, -2.6011],
        [-1.1953, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140768110752106
Epoch 0, Step 1050: train/loss = 0.6007360219955444, train/raw-loss = 0.5354099869728088, train/logprobs = tensor([[-0.5189, -0.9781],
        [-0.7781, -0.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06532606482505798
Epoch 0, Step 1051: train/loss = 0.6521923542022705, train/raw-loss = 0.6028410196304321, train/logprobs = tensor([[-0.5355, -1.0797],
        [-0.5924, -0.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04935141280293465
Epoch 0, Step 1052: train/loss = 0.4446820616722107, train/raw-loss = 0.38104701042175293, train/logprobs = tensor([[-0.5062, -2.8964],
        [-0.7271, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363503634929657
Epoch 0, Step 1053: train/loss = 0.3959695100784302, train/raw-loss = 0.3236822783946991, train/logprobs = tensor([[-0.5361, -3.4756],
        [-0.9920, -0.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07228723168373108
Epoch 0, Step 1054: train/loss = 0.5612554550170898, train/raw-loss = 0.5004984736442566, train/logprobs = tensor([[-0.8178, -1.8444],
        [-0.8665, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06075701117515564
Epoch 0, Step 1055: train/loss = 0.5369057059288025, train/raw-loss = 0.4623110294342041, train/logprobs = tensor([[-0.7552, -3.2958],
        [-1.1354, -1.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07459461688995361
Epoch 0, Step 1056: train/loss = 0.49034106731414795, train/raw-loss = 0.4274076223373413, train/logprobs = tensor([[-0.5963, -3.4109],
        [-0.6974, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06293343007564545
Epoch 0, Step 1057: train/loss = 0.4292755126953125, train/raw-loss = 0.36604827642440796, train/logprobs = tensor([[-0.4846, -4.7979],
        [-0.9269, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06322729587554932
Epoch 0, Step 1058: train/loss = 0.43032923340797424, train/raw-loss = 0.3532201647758484, train/logprobs = tensor([[-0.5094, -2.6276],
        [-0.9974, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07710906118154526
Epoch 0, Step 1059: train/loss = 0.6392679810523987, train/raw-loss = 0.569000780582428, train/logprobs = tensor([[-0.5174, -1.1697],
        [-0.6470, -0.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07026718556880951
Epoch 0, Step 1060: train/loss = 0.6120132207870483, train/raw-loss = 0.5458230972290039, train/logprobs = tensor([[-0.5879, -1.5496],
        [-0.8604, -0.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06619012355804443
Epoch 0, Step 1061: train/loss = 0.5403248071670532, train/raw-loss = 0.46558678150177, train/logprobs = tensor([[-0.6582, -3.6156],
        [-0.9453, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07473801076412201
Epoch 0, Step 1062: train/loss = 0.5424235463142395, train/raw-loss = 0.4556402564048767, train/logprobs = tensor([[-0.7058, -2.0449],
        [-1.1269, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08678323030471802
Epoch 0, Step 1063: train/loss = 0.6267217397689819, train/raw-loss = 0.568877100944519, train/logprobs = tensor([[-1.0594, -2.0755],
        [-0.7495, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057844702154397964
Epoch 0, Step 1064: train/loss = 0.4593978822231293, train/raw-loss = 0.37950611114501953, train/logprobs = tensor([[-0.5483, -4.1728],
        [-0.7887, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07989176362752914
Epoch 0, Step 1065: train/loss = 0.5740252733230591, train/raw-loss = 0.5105876922607422, train/logprobs = tensor([[-0.5333, -1.5759],
        [-0.7952, -0.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06343758851289749
Epoch 0, Step 1066: train/loss = 0.5125417113304138, train/raw-loss = 0.44962626695632935, train/logprobs = tensor([[-1.3411, -3.1932],
        [-1.2347, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06291547417640686
Epoch 0, Step 1067: train/loss = 0.2957269847393036, train/raw-loss = 0.21711626648902893, train/logprobs = tensor([[-0.7550, -6.6258],
        [-1.3384, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07861071825027466
Epoch 0, Step 1068: train/loss = 0.5022892951965332, train/raw-loss = 0.43251556158065796, train/logprobs = tensor([[-0.5287, -2.2844],
        [-0.8268, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06977367401123047
Epoch 0, Step 1069: train/loss = 0.577357828617096, train/raw-loss = 0.5086892247200012, train/logprobs = tensor([[-0.9228, -4.5232],
        [-0.7851, -0.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06866857409477234
Epoch 0, Step 1070: train/loss = 0.42151474952697754, train/raw-loss = 0.33694589138031006, train/logprobs = tensor([[-0.5716, -3.6425],
        [-0.9179, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08456888049840927
Epoch 0, Step 1071: train/loss = 0.3082211911678314, train/raw-loss = 0.22728842496871948, train/logprobs = tensor([[-0.5922, -5.0545],
        [-1.1610, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08093277364969254
Epoch 0, Step 1072: train/loss = 0.3242745101451874, train/raw-loss = 0.24369654059410095, train/logprobs = tensor([[-0.5492, -5.4917],
        [-0.9551, -0.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08057796210050583
Epoch 0, Step 1073: train/loss = 0.5137737393379211, train/raw-loss = 0.436331570148468, train/logprobs = tensor([[-0.6357, -3.3858],
        [-0.9506, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07744213193655014
Epoch 0, Step 1074: train/loss = 0.49300581216812134, train/raw-loss = 0.4246576726436615, train/logprobs = tensor([[-0.5101, -3.9529],
        [-0.7449, -0.9970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06834816187620163
Epoch 0, Step 1075: train/loss = 0.5069338083267212, train/raw-loss = 0.44437071681022644, train/logprobs = tensor([[-0.4514, -2.6321],
        [-0.5624, -0.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06256310641765594
Epoch 0, Step 1076: train/loss = 0.476692795753479, train/raw-loss = 0.38964027166366577, train/logprobs = tensor([[-0.4949, -2.8870],
        [-0.9402, -0.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08705253899097443
Epoch 0, Step 1077: train/loss = 0.47584640979766846, train/raw-loss = 0.40660351514816284, train/logprobs = tensor([[-0.4539, -2.7552],
        [-0.8648, -0.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06924287974834442
Epoch 0, Step 1078: train/loss = 0.5279329419136047, train/raw-loss = 0.46613407135009766, train/logprobs = tensor([[-0.7202, -1.9667],
        [-0.9972, -0.6721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06179886311292648
Epoch 0, Step 1079: train/loss = 0.3773328363895416, train/raw-loss = 0.2985002100467682, train/logprobs = tensor([[-0.4806, -5.3129],
        [-0.8077, -0.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883261144161224
Epoch 0, Step 1080: train/loss = 0.5858813524246216, train/raw-loss = 0.5152530670166016, train/logprobs = tensor([[-0.6203, -2.1772],
        [-0.8709, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07062831521034241
Epoch 0, Step 1081: train/loss = 0.3749106526374817, train/raw-loss = 0.3051394820213318, train/logprobs = tensor([[-0.9502, -3.9567],
        [-1.0186, -0.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0697711706161499
Epoch 0, Step 1082: train/loss = 0.6742964386940002, train/raw-loss = 0.6154914498329163, train/logprobs = tensor([[-0.6744, -0.9694],
        [-0.8887, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05880504101514816
Epoch 0, Step 1083: train/loss = 0.5757980346679688, train/raw-loss = 0.48950013518333435, train/logprobs = tensor([[-0.7308, -2.3576],
        [-1.0653, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0862978994846344
Epoch 0, Step 1084: train/loss = 0.5260085463523865, train/raw-loss = 0.46040117740631104, train/logprobs = tensor([[-0.4793, -2.3239],
        [-0.7120, -0.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06560739129781723
Epoch 0, Step 1085: train/loss = 0.579594612121582, train/raw-loss = 0.5197944641113281, train/logprobs = tensor([[-0.6600, -1.8525],
        [-0.8212, -0.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05980013683438301
Epoch 0, Step 1086: train/loss = 0.4633328318595886, train/raw-loss = 0.3857591152191162, train/logprobs = tensor([[-0.5963, -4.2768],
        [-0.9361, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07757370173931122
Epoch 0, Step 1087: train/loss = 0.4315968155860901, train/raw-loss = 0.36798977851867676, train/logprobs = tensor([[-0.4876, -4.0546],
        [-0.5685, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06360705196857452
Epoch 0, Step 1088: train/loss = 0.5771024227142334, train/raw-loss = 0.5039556622505188, train/logprobs = tensor([[-0.8373, -1.7834],
        [-0.9668, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07314672321081161
Epoch 0, Step 1089: train/loss = 0.577297568321228, train/raw-loss = 0.5210053324699402, train/logprobs = tensor([[-0.5873, -1.6690],
        [-0.6417, -0.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056292302906513214
Epoch 0, Step 1090: train/loss = 0.4175970256328583, train/raw-loss = 0.35091856122016907, train/logprobs = tensor([[-0.5352, -2.9657],
        [-1.0314, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06667842715978622
Epoch 0, Step 1091: train/loss = 0.40721988677978516, train/raw-loss = 0.34701529145240784, train/logprobs = tensor([[-0.5245, -2.8059],
        [-0.8619, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06020459160208702
Epoch 0, Step 1092: train/loss = 0.4821292757987976, train/raw-loss = 0.4030666947364807, train/logprobs = tensor([[-0.6854, -2.4046],
        [-0.8763, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0790625661611557
Epoch 0, Step 1093: train/loss = 0.5159354209899902, train/raw-loss = 0.43616369366645813, train/logprobs = tensor([[-0.6845, -2.7626],
        [-1.1076, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797717273235321
Epoch 0, Step 1094: train/loss = 0.5177067518234253, train/raw-loss = 0.4563572108745575, train/logprobs = tensor([[-0.5194, -1.5609],
        [-0.7661, -0.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06134955212473869
Epoch 0, Step 1095: train/loss = 0.6025587320327759, train/raw-loss = 0.524337887763977, train/logprobs = tensor([[-0.8323, -2.3466],
        [-0.8273, -0.5808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07822082191705704
Epoch 0, Step 1096: train/loss = 0.4539312720298767, train/raw-loss = 0.38316676020622253, train/logprobs = tensor([[-0.6073, -3.6900],
        [-0.7389, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07076450437307358
Epoch 0, Step 1097: train/loss = 0.4220580458641052, train/raw-loss = 0.33813950419425964, train/logprobs = tensor([[-0.7548, -3.5285],
        [-0.9752, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08391851931810379
Epoch 0, Step 1098: train/loss = 0.43658775091171265, train/raw-loss = 0.3674320578575134, train/logprobs = tensor([[-0.3959, -5.5877],
        [-0.8407, -0.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915563344955444
Epoch 0, Step 1099: train/loss = 0.5606247782707214, train/raw-loss = 0.48576050996780396, train/logprobs = tensor([[-0.5826, -1.2230],
        [-1.0587, -0.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07486423850059509
Epoch 0, Step 1100: train/loss = 0.4697597622871399, train/raw-loss = 0.4069873094558716, train/logprobs = tensor([[-0.5328, -2.7336],
        [-0.8331, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0627724677324295
Epoch 0, Step 1101: train/loss = 0.3966671824455261, train/raw-loss = 0.3356077969074249, train/logprobs = tensor([[-0.5567, -5.7131],
        [-1.1283, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061059385538101196
Epoch 0, Step 1102: train/loss = 0.4780994653701782, train/raw-loss = 0.4121675491333008, train/logprobs = tensor([[-0.9275, -3.8208],
        [-0.8474, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06593193113803864
Epoch 0, Step 1103: train/loss = 0.39376401901245117, train/raw-loss = 0.32505175471305847, train/logprobs = tensor([[-0.7199, -4.2147],
        [-1.0058, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0687122717499733
Epoch 0, Step 1104: train/loss = 0.6178985238075256, train/raw-loss = 0.5605957508087158, train/logprobs = tensor([[-0.6772, -3.5918],
        [-0.8105, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05730275809764862
Epoch 0, Step 1105: train/loss = 0.473940908908844, train/raw-loss = 0.411943644285202, train/logprobs = tensor([[-0.6892, -3.1111],
        [-0.6416, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06199726089835167
Epoch 0, Step 1106: train/loss = 0.4515303373336792, train/raw-loss = 0.3701348602771759, train/logprobs = tensor([[-0.8844, -4.4952],
        [-0.9083, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139549195766449
Epoch 0, Step 1107: train/loss = 0.4612168073654175, train/raw-loss = 0.3919057846069336, train/logprobs = tensor([[-0.5543, -3.1610],
        [-0.7576, -0.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06931105256080627
Epoch 0, Step 1108: train/loss = 0.48552823066711426, train/raw-loss = 0.4287716746330261, train/logprobs = tensor([[-0.5138, -2.3300],
        [-0.7344, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056756529957056046
Epoch 0, Step 1109: train/loss = 0.520319938659668, train/raw-loss = 0.4526105523109436, train/logprobs = tensor([[-0.5674, -2.1536],
        [-0.7635, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06770943105220795
Epoch 0, Step 1110: train/loss = 0.563251256942749, train/raw-loss = 0.5065227150917053, train/logprobs = tensor([[-0.5247, -3.3799],
        [-0.5690, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056728582829236984
Epoch 0, Step 1111: train/loss = 0.48964980244636536, train/raw-loss = 0.4247592091560364, train/logprobs = tensor([[-0.5356, -3.6743],
        [-0.5863, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06489059329032898
Epoch 0, Step 1112: train/loss = 0.5974255800247192, train/raw-loss = 0.5264931321144104, train/logprobs = tensor([[-1.0913, -4.5193],
        [-0.9909, -1.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07093246281147003
Epoch 0, Step 1113: train/loss = 0.614289402961731, train/raw-loss = 0.5472028255462646, train/logprobs = tensor([[-0.5722, -1.4120],
        [-0.6612, -0.5581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06708654761314392
Epoch 0, Step 1114: train/loss = 0.5016412734985352, train/raw-loss = 0.43839406967163086, train/logprobs = tensor([[-0.6365, -1.9240],
        [-0.8340, -0.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06324721872806549
Epoch 0, Step 1115: train/loss = 0.5727732181549072, train/raw-loss = 0.5069428086280823, train/logprobs = tensor([[-0.3919, -1.3922],
        [-0.5665, -0.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06583040952682495
Epoch 0, Step 1116: train/loss = 0.570392906665802, train/raw-loss = 0.5077242255210876, train/logprobs = tensor([[-0.5140, -1.8510],
        [-0.6681, -0.7220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06266871839761734
Epoch 0, Step 1117: train/loss = 0.5689001083374023, train/raw-loss = 0.4959993362426758, train/logprobs = tensor([[-0.5504, -1.8879],
        [-1.0753, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07290074229240417
Epoch 0, Step 1118: train/loss = 0.5905578136444092, train/raw-loss = 0.5347070693969727, train/logprobs = tensor([[-0.3227, -1.7336],
        [-0.4223, -0.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055850718170404434
Epoch 0, Step 1119: train/loss = 0.4759485125541687, train/raw-loss = 0.4078761637210846, train/logprobs = tensor([[-0.4463, -3.3644],
        [-0.7677, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06807233393192291
Epoch 0, Step 1120: train/loss = 0.37795907258987427, train/raw-loss = 0.2948130667209625, train/logprobs = tensor([[-0.7769, -3.0041],
        [-1.2385, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08314599841833115
Epoch 0, Step 1121: train/loss = 0.462006539106369, train/raw-loss = 0.3793776333332062, train/logprobs = tensor([[-0.7000, -2.5462],
        [-1.3460, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08262892067432404
Epoch 0, Step 1122: train/loss = 0.6063879728317261, train/raw-loss = 0.5386354327201843, train/logprobs = tensor([[-0.4619, -2.7538],
        [-0.7963, -0.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06775252521038055
Epoch 0, Step 1123: train/loss = 0.3458050787448883, train/raw-loss = 0.27154141664505005, train/logprobs = tensor([[-0.5435, -5.6453],
        [-1.1253, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07426367700099945
Epoch 0, Step 1124: train/loss = 0.45810869336128235, train/raw-loss = 0.3919675350189209, train/logprobs = tensor([[-0.8230, -6.0482],
        [-1.0758, -1.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06614118069410324
Epoch 0, Step 1125: train/loss = 0.4756494462490082, train/raw-loss = 0.41122207045555115, train/logprobs = tensor([[-0.5197, -2.1100],
        [-0.7975, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06442737579345703
Epoch 0, Step 1126: train/loss = 0.5415054559707642, train/raw-loss = 0.4729868769645691, train/logprobs = tensor([[-0.7235, -4.3733],
        [-0.8493, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06851857900619507
Epoch 0, Step 1127: train/loss = 0.46643662452697754, train/raw-loss = 0.4019762873649597, train/logprobs = tensor([[-0.3700, -2.6042],
        [-0.4779, -0.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06446030735969543
Epoch 0, Step 1128: train/loss = 0.6569899320602417, train/raw-loss = 0.5878304243087769, train/logprobs = tensor([[-1.1804, -1.7053],
        [-0.8519, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915953755378723
Epoch 0, Step 1129: train/loss = 0.3932945728302002, train/raw-loss = 0.3135911822319031, train/logprobs = tensor([[-0.5758, -2.6996],
        [-1.0430, -0.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07970339059829712
Epoch 0, Step 1130: train/loss = 0.5746217966079712, train/raw-loss = 0.5237071514129639, train/logprobs = tensor([[-0.3329, -1.4001],
        [-0.5888, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05091463774442673
Epoch 0, Step 1131: train/loss = 0.46250200271606445, train/raw-loss = 0.40949738025665283, train/logprobs = tensor([[-0.4223, -2.6352],
        [-0.6088, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05300465226173401
Epoch 0, Step 1132: train/loss = 0.5929314494132996, train/raw-loss = 0.5256162881851196, train/logprobs = tensor([[-0.6195, -2.4892],
        [-0.5395, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06731511652469635
Epoch 0, Step 1133: train/loss = 0.6856875419616699, train/raw-loss = 0.6222305297851562, train/logprobs = tensor([[-0.6160, -0.8134],
        [-0.6067, -0.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06345701217651367
Epoch 0, Step 1134: train/loss = 0.4874461889266968, train/raw-loss = 0.4139857590198517, train/logprobs = tensor([[-1.0457, -5.4305],
        [-0.9925, -1.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07346042990684509
Epoch 0, Step 1135: train/loss = 0.44869789481163025, train/raw-loss = 0.37783363461494446, train/logprobs = tensor([[-0.5088, -3.2067],
        [-0.7356, -0.3964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.070864237844944
Epoch 0, Step 1136: train/loss = 0.4498324394226074, train/raw-loss = 0.38028818368911743, train/logprobs = tensor([[-0.6294, -4.1649],
        [-1.0031, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06954421103000641
Epoch 0, Step 1137: train/loss = 0.43065959215164185, train/raw-loss = 0.36824774742126465, train/logprobs = tensor([[-0.6878, -6.1484],
        [-0.8343, -1.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062411829829216
Epoch 0, Step 1138: train/loss = 0.57840895652771, train/raw-loss = 0.5215276479721069, train/logprobs = tensor([[-0.5551, -1.5330],
        [-0.5639, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05688133090734482
Epoch 0, Step 1139: train/loss = 0.4709390699863434, train/raw-loss = 0.3795999586582184, train/logprobs = tensor([[-0.5263, -2.2903],
        [-1.0669, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09133908152580261
Epoch 0, Step 1140: train/loss = 0.46000200510025024, train/raw-loss = 0.3917277753353119, train/logprobs = tensor([[-0.5031, -4.6316],
        [-0.8652, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06827422231435776
Epoch 0, Step 1141: train/loss = 0.4737458825111389, train/raw-loss = 0.4088575839996338, train/logprobs = tensor([[-0.5257, -3.0400],
        [-0.7137, -1.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06488831341266632
Epoch 0, Step 1142: train/loss = 0.6079933643341064, train/raw-loss = 0.5507343411445618, train/logprobs = tensor([[-0.6842, -1.5257],
        [-1.0167, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057259030640125275
Epoch 0, Step 1143: train/loss = 0.5921761989593506, train/raw-loss = 0.5246869325637817, train/logprobs = tensor([[-0.5383, -1.4926],
        [-0.7519, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06748923659324646
Epoch 0, Step 1144: train/loss = 0.49439164996147156, train/raw-loss = 0.43378764390945435, train/logprobs = tensor([[-0.4112, -2.6657],
        [-0.4705, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0606040321290493
Epoch 0, Step 1145: train/loss = 0.3654387295246124, train/raw-loss = 0.3022697865962982, train/logprobs = tensor([[-0.3990, -5.0242],
        [-0.5433, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06316894292831421
Epoch 0, Step 1146: train/loss = 0.3129342794418335, train/raw-loss = 0.220045268535614, train/logprobs = tensor([[-0.5444, -8.6765],
        [-0.9336, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09288899600505829
Epoch 0, Step 1147: train/loss = 0.3902636170387268, train/raw-loss = 0.30633020401000977, train/logprobs = tensor([[-0.7755, -3.3673],
        [-1.1311, -0.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08393342047929764
Epoch 0, Step 1148: train/loss = 0.5708627104759216, train/raw-loss = 0.515832245349884, train/logprobs = tensor([[-0.5730, -1.1414],
        [-0.9187, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055030472576618195
Epoch 0, Step 1149: train/loss = 0.4300025999546051, train/raw-loss = 0.354518324136734, train/logprobs = tensor([[-0.6451, -3.5991],
        [-1.0751, -0.4568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754842758178711
Epoch 0, Step 1150: train/loss = 0.5818865895271301, train/raw-loss = 0.5147289037704468, train/logprobs = tensor([[-0.8627, -3.4623],
        [-0.5365, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06715774536132812
Epoch 0, Step 1151: train/loss = 0.4070216417312622, train/raw-loss = 0.3261949419975281, train/logprobs = tensor([[-0.7965, -5.9537],
        [-1.2080, -1.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08082666993141174
Epoch 0, Step 1152: train/loss = 0.29316017031669617, train/raw-loss = 0.204820916056633, train/logprobs = tensor([[-0.6039, -5.4431],
        [-1.2213, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08833925426006317
Epoch 0, Step 1153: train/loss = 0.5338042974472046, train/raw-loss = 0.4722784757614136, train/logprobs = tensor([[-0.3844, -1.5986],
        [-0.5815, -0.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061525870114564896
Epoch 0, Step 1154: train/loss = 0.49715355038642883, train/raw-loss = 0.43386346101760864, train/logprobs = tensor([[-0.6158, -2.3696],
        [-0.9307, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06329010426998138
Epoch 0, Step 1155: train/loss = 0.467459112405777, train/raw-loss = 0.40962857007980347, train/logprobs = tensor([[-0.4910, -2.5612],
        [-0.7870, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0578305646777153
Epoch 0, Step 1156: train/loss = 0.5759116411209106, train/raw-loss = 0.5142966508865356, train/logprobs = tensor([[-0.5425, -1.4095],
        [-0.7881, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061615053564310074
Epoch 0, Step 1157: train/loss = 0.46813562512397766, train/raw-loss = 0.39531761407852173, train/logprobs = tensor([[-0.6515, -5.1524],
        [-0.7183, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07281802594661713
Epoch 0, Step 1158: train/loss = 0.36272627115249634, train/raw-loss = 0.28197357058525085, train/logprobs = tensor([[-0.6524, -4.5029],
        [-0.9492, -0.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08075270056724548
Epoch 0, Step 1159: train/loss = 0.4400675296783447, train/raw-loss = 0.3735497295856476, train/logprobs = tensor([[-0.4632, -2.9026],
        [-0.5943, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06651781499385834
Epoch 0, Step 1160: train/loss = 0.5871846079826355, train/raw-loss = 0.5297969579696655, train/logprobs = tensor([[-0.5575, -2.4614],
        [-0.7005, -0.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05738763511180878
Epoch 0, Step 1161: train/loss = 0.5685505867004395, train/raw-loss = 0.48750829696655273, train/logprobs = tensor([[-0.6051, -1.6807],
        [-0.7544, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0810423418879509
Epoch 0, Step 1162: train/loss = 0.4576363265514374, train/raw-loss = 0.3914746344089508, train/logprobs = tensor([[-0.5662, -3.8656],
        [-0.9778, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06616169214248657
Epoch 0, Step 1163: train/loss = 0.3813905715942383, train/raw-loss = 0.3032916188240051, train/logprobs = tensor([[-0.5603, -5.1431],
        [-0.7881, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07809896767139435
Epoch 0, Step 1164: train/loss = 0.47511160373687744, train/raw-loss = 0.40410315990448, train/logprobs = tensor([[-0.5107, -5.4763],
        [-0.7585, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07100845873355865
Epoch 0, Step 1165: train/loss = 0.4472499489784241, train/raw-loss = 0.38247615098953247, train/logprobs = tensor([[-0.6103, -3.3944],
        [-0.8339, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06477383524179459
Epoch 0, Step 1166: train/loss = 0.42592236399650574, train/raw-loss = 0.3425388038158417, train/logprobs = tensor([[-0.6075, -2.5869],
        [-1.1287, -0.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08338354527950287
Epoch 0, Step 1167: train/loss = 0.523937463760376, train/raw-loss = 0.4591904878616333, train/logprobs = tensor([[-0.5131, -3.7822],
        [-0.6811, -0.9048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06474699079990387
Epoch 0, Step 1168: train/loss = 0.5612956285476685, train/raw-loss = 0.5012061595916748, train/logprobs = tensor([[-0.6740, -2.4097],
        [-0.8505, -1.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06008946895599365
Epoch 0, Step 1169: train/loss = 0.6224450469017029, train/raw-loss = 0.5491607189178467, train/logprobs = tensor([[-1.3960, -4.0240],
        [-0.8997, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07328430563211441
Epoch 0, Step 1170: train/loss = 0.3823046088218689, train/raw-loss = 0.3167276680469513, train/logprobs = tensor([[-0.5265, -4.5515],
        [-0.7802, -1.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06557697057723999
Epoch 0, Step 1171: train/loss = 0.6016645431518555, train/raw-loss = 0.5400410294532776, train/logprobs = tensor([[-0.6617, -2.1065],
        [-0.9141, -0.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061623480170965195
Epoch 0, Step 1172: train/loss = 0.3677941560745239, train/raw-loss = 0.2986321747303009, train/logprobs = tensor([[-0.5709, -5.4876],
        [-0.8221, -1.3248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06916196644306183
Epoch 0, Step 1173: train/loss = 0.3527931272983551, train/raw-loss = 0.2804100513458252, train/logprobs = tensor([[-0.6276, -4.8268],
        [-0.8938, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07238307595252991
Epoch 0, Step 1174: train/loss = 0.5833941102027893, train/raw-loss = 0.5295473337173462, train/logprobs = tensor([[-0.5624, -1.6456],
        [-0.7858, -0.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05384676903486252
Epoch 0, Step 1175: train/loss = 0.46183300018310547, train/raw-loss = 0.38348913192749023, train/logprobs = tensor([[-0.7740, -3.7595],
        [-0.8962, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834386080503464
Epoch 0, Step 1176: train/loss = 0.6317242980003357, train/raw-loss = 0.5831301212310791, train/logprobs = tensor([[-0.6034, -1.7355],
        [-0.8453, -1.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04859418049454689
Epoch 0, Step 1177: train/loss = 0.5484874248504639, train/raw-loss = 0.4782775640487671, train/logprobs = tensor([[-0.5256, -2.7746],
        [-0.7847, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07020985335111618
Epoch 0, Step 1178: train/loss = 0.6833908557891846, train/raw-loss = 0.6208180785179138, train/logprobs = tensor([[-1.5330, -2.7819],
        [-0.7158, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06257282942533493
Epoch 0, Step 1179: train/loss = 0.6315476298332214, train/raw-loss = 0.5530519485473633, train/logprobs = tensor([[-0.9630, -1.4852],
        [-0.8966, -0.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07849568128585815
Epoch 0, Step 1180: train/loss = 0.6342437267303467, train/raw-loss = 0.5750764608383179, train/logprobs = tensor([[-0.6279, -0.9584],
        [-0.8609, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059167325496673584
Epoch 0, Step 1181: train/loss = 0.4237895905971527, train/raw-loss = 0.3601560592651367, train/logprobs = tensor([[-0.7599, -3.7422],
        [-0.8277, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363356113433838
Epoch 0, Step 1182: train/loss = 0.5964308977127075, train/raw-loss = 0.5243933796882629, train/logprobs = tensor([[-0.7131, -3.8314],
        [-0.9687, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07203751802444458
Epoch 0, Step 1183: train/loss = 0.6202917098999023, train/raw-loss = 0.5694145560264587, train/logprobs = tensor([[-0.5270, -1.6778],
        [-0.5509, -0.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05087713897228241
Epoch 0, Step 1184: train/loss = 0.5975146889686584, train/raw-loss = 0.5275787711143494, train/logprobs = tensor([[-0.6548, -2.0714],
        [-0.8761, -0.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06993591785430908
Epoch 0, Step 1185: train/loss = 0.48904064297676086, train/raw-loss = 0.41984111070632935, train/logprobs = tensor([[-0.6307, -3.0346],
        [-0.9648, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06919951736927032
Epoch 0, Step 1186: train/loss = 0.5816276669502258, train/raw-loss = 0.523883581161499, train/logprobs = tensor([[-0.4925, -3.1967],
        [-0.5347, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057744067162275314
Epoch 0, Step 1187: train/loss = 0.45130422711372375, train/raw-loss = 0.37612706422805786, train/logprobs = tensor([[-0.9113, -5.8642],
        [-0.7411, -1.2269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751771330833435
Epoch 0, Step 1188: train/loss = 0.4330778419971466, train/raw-loss = 0.36059874296188354, train/logprobs = tensor([[-0.6045, -3.1801],
        [-0.9828, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07247912883758545
Epoch 0, Step 1189: train/loss = 0.43643152713775635, train/raw-loss = 0.36417582631111145, train/logprobs = tensor([[-0.5270, -2.2697],
        [-0.9044, -0.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07225573062896729
Epoch 0, Step 1190: train/loss = 0.4989657402038574, train/raw-loss = 0.4281112849712372, train/logprobs = tensor([[-0.5266, -2.2292],
        [-0.8305, -0.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07085442543029785
Epoch 0, Step 1191: train/loss = 0.4265576899051666, train/raw-loss = 0.36493343114852905, train/logprobs = tensor([[-0.5911, -4.8779],
        [-0.7439, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06162424758076668
Epoch 0, Step 1192: train/loss = 0.35009655356407166, train/raw-loss = 0.2744879126548767, train/logprobs = tensor([[-0.5736, -7.4594],
        [-0.7859, -1.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07560864090919495
Epoch 0, Step 1193: train/loss = 0.5827431678771973, train/raw-loss = 0.5043668746948242, train/logprobs = tensor([[-0.5737, -1.3499],
        [-1.0146, -0.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07837636023759842
Epoch 0, Step 1194: train/loss = 0.5858700275421143, train/raw-loss = 0.5200526714324951, train/logprobs = tensor([[-1.0151, -3.0181],
        [-0.7178, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06581737101078033
Epoch 0, Step 1195: train/loss = 0.5580262541770935, train/raw-loss = 0.4941059350967407, train/logprobs = tensor([[-0.7567, -3.4940],
        [-0.6398, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0639202818274498
Epoch 0, Step 1196: train/loss = 0.6295422911643982, train/raw-loss = 0.5563781261444092, train/logprobs = tensor([[-1.4538, -2.9156],
        [-0.9747, -0.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.073164202272892
Epoch 0, Step 1197: train/loss = 0.30388426780700684, train/raw-loss = 0.22292876243591309, train/logprobs = tensor([[-0.5200, -5.1812],
        [-1.0251, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08095553517341614
Epoch 0, Step 1198: train/loss = 0.4909106194972992, train/raw-loss = 0.4121646285057068, train/logprobs = tensor([[-0.7916, -3.7425],
        [-0.9871, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07874596863985062
Epoch 0, Step 1199: train/loss = 0.6722487211227417, train/raw-loss = 0.6154715418815613, train/logprobs = tensor([[-0.3845, -0.5697],
        [-0.5031, -0.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05677712336182594
Epoch 0, Step 1200: train/loss = 0.5211299657821655, train/raw-loss = 0.4585935175418854, train/logprobs = tensor([[-0.6835, -2.7574],
        [-0.6953, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06253641098737717
Epoch 0, Step 1201: train/loss = 0.5741575360298157, train/raw-loss = 0.5232760906219482, train/logprobs = tensor([[-0.4995, -1.6414],
        [-0.6373, -0.5316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050881434231996536
Epoch 0, Step 1202: train/loss = 0.34041768312454224, train/raw-loss = 0.26192036271095276, train/logprobs = tensor([[-0.6370, -7.2344],
        [-0.8779, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07849732786417007
Epoch 0, Step 1203: train/loss = 0.4190373420715332, train/raw-loss = 0.34490758180618286, train/logprobs = tensor([[-0.4379, -5.0313],
        [-0.7798, -1.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07412977516651154
Epoch 0, Step 1204: train/loss = 0.5411437749862671, train/raw-loss = 0.47529110312461853, train/logprobs = tensor([[-0.7451, -1.6249],
        [-0.9280, -0.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06585268676280975
Epoch 0, Step 1205: train/loss = 0.5812803506851196, train/raw-loss = 0.5024625658988953, train/logprobs = tensor([[-0.6751, -2.2500],
        [-0.6120, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07881777733564377
Epoch 0, Step 1206: train/loss = 0.49296000599861145, train/raw-loss = 0.42458081245422363, train/logprobs = tensor([[-0.6007, -4.1273],
        [-0.7992, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06837913393974304
Epoch 0, Step 1207: train/loss = 0.40386873483657837, train/raw-loss = 0.33258435130119324, train/logprobs = tensor([[-0.5967, -3.9516],
        [-0.8369, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128442078828812
Epoch 0, Step 1208: train/loss = 0.3653952479362488, train/raw-loss = 0.28986430168151855, train/logprobs = tensor([[-0.6695, -3.6850],
        [-1.1716, -0.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07553094625473022
Epoch 0, Step 1209: train/loss = 0.3230273723602295, train/raw-loss = 0.23678529262542725, train/logprobs = tensor([[-0.6888, -2.9618],
        [-1.5592, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08624208718538284
Epoch 0, Step 1210: train/loss = 0.4560520052909851, train/raw-loss = 0.382072776556015, train/logprobs = tensor([[-0.4839, -2.4304],
        [-0.8261, -0.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07397925853729248
Epoch 0, Step 1211: train/loss = 0.3439318537712097, train/raw-loss = 0.2646801173686981, train/logprobs = tensor([[-0.6575, -4.2399],
        [-1.0324, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792517364025116
Epoch 0, Step 1212: train/loss = 0.5667511820793152, train/raw-loss = 0.5101698637008667, train/logprobs = tensor([[-0.6561, -3.6453],
        [-0.6515, -0.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056581296026706696
Epoch 0, Step 1213: train/loss = 0.4895074963569641, train/raw-loss = 0.42233070731163025, train/logprobs = tensor([[-0.7673, -3.4482],
        [-0.7862, -0.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06717681139707565
Epoch 0, Step 1214: train/loss = 0.4836379885673523, train/raw-loss = 0.40729182958602905, train/logprobs = tensor([[-0.5739, -3.5108],
        [-0.6695, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07634612917900085
Epoch 0, Step 1215: train/loss = 0.4743843972682953, train/raw-loss = 0.4026733636856079, train/logprobs = tensor([[-0.6204, -5.1987],
        [-0.8116, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07171107828617096
Epoch 0, Step 1216: train/loss = 0.5053343772888184, train/raw-loss = 0.4469010829925537, train/logprobs = tensor([[-0.4706, -3.4814],
        [-0.7843, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058433253318071365
Epoch 0, Step 1217: train/loss = 0.49869218468666077, train/raw-loss = 0.43813425302505493, train/logprobs = tensor([[-0.9249, -5.4415],
        [-1.1325, -1.4367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06055798381567001
Epoch 0, Step 1218: train/loss = 0.4879917800426483, train/raw-loss = 0.4182628095149994, train/logprobs = tensor([[-0.5824, -3.1100],
        [-0.7766, -0.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06972897052764893
Epoch 0, Step 1219: train/loss = 0.42422229051589966, train/raw-loss = 0.34024423360824585, train/logprobs = tensor([[-0.7014, -5.6246],
        [-0.9727, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397804200649261
Epoch 0, Step 1220: train/loss = 0.7243679165840149, train/raw-loss = 0.6698489189147949, train/logprobs = tensor([[-0.5636, -0.5651],
        [-0.5355, -0.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05451909452676773
Epoch 0, Step 1221: train/loss = 0.4519120454788208, train/raw-loss = 0.40519750118255615, train/logprobs = tensor([[-0.4603, -3.1920],
        [-0.5737, -0.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04671454057097435
Epoch 0, Step 1222: train/loss = 0.5532053112983704, train/raw-loss = 0.4894571900367737, train/logprobs = tensor([[-0.6841, -4.3829],
        [-1.1543, -1.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06374811381101608
Epoch 0, Step 1223: train/loss = 0.4451060891151428, train/raw-loss = 0.38351690769195557, train/logprobs = tensor([[-0.5413, -3.2053],
        [-0.7941, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061589162796735764
Epoch 0, Step 1224: train/loss = 0.531807541847229, train/raw-loss = 0.4776170551776886, train/logprobs = tensor([[-0.3286, -2.0830],
        [-0.4441, -0.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05419046804308891
Epoch 0, Step 1225: train/loss = 0.4510519206523895, train/raw-loss = 0.40359747409820557, train/logprobs = tensor([[-0.4307, -2.4733],
        [-0.5467, -0.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047454457730054855
Epoch 0, Step 1226: train/loss = 0.5000008940696716, train/raw-loss = 0.4417588710784912, train/logprobs = tensor([[-0.6557, -2.6210],
        [-0.6054, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05824197456240654
Epoch 0, Step 1227: train/loss = 0.5829204320907593, train/raw-loss = 0.5161835551261902, train/logprobs = tensor([[-0.9269, -1.8874],
        [-0.8357, -0.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06673692911863327
Epoch 0, Step 1228: train/loss = 0.613971471786499, train/raw-loss = 0.5476837754249573, train/logprobs = tensor([[-0.5416, -1.2760],
        [-0.6204, -0.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06628765165805817
Epoch 0, Step 1229: train/loss = 0.4276510179042816, train/raw-loss = 0.36825108528137207, train/logprobs = tensor([[-0.4307, -4.8386],
        [-0.5334, -0.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05939994752407074
Epoch 0, Step 1230: train/loss = 0.7245534658432007, train/raw-loss = 0.6577735543251038, train/logprobs = tensor([[-1.3066, -1.7012],
        [-1.0509, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06677988916635513
Epoch 0, Step 1231: train/loss = 0.5538033843040466, train/raw-loss = 0.48371365666389465, train/logprobs = tensor([[-0.7176, -1.7072],
        [-0.8338, -0.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07008976489305496
Epoch 0, Step 1232: train/loss = 0.8255847692489624, train/raw-loss = 0.7781141400337219, train/logprobs = tensor([[-2.6558, -5.8324],
        [-1.5531, -2.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04747065529227257
Epoch 0, Step 1233: train/loss = 0.616389274597168, train/raw-loss = 0.5512781143188477, train/logprobs = tensor([[-0.4673, -1.2233],
        [-0.5531, -0.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06511116027832031
Epoch 0, Step 1234: train/loss = 0.4834228754043579, train/raw-loss = 0.4175364077091217, train/logprobs = tensor([[-0.6439, -2.2662],
        [-0.9716, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06588646024465561
Epoch 0, Step 1235: train/loss = 0.680209219455719, train/raw-loss = 0.6248102784156799, train/logprobs = tensor([[-1.1805, -4.9815],
        [-0.6234, -1.2200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055398937314748764
Epoch 0, Step 1236: train/loss = 0.41872936487197876, train/raw-loss = 0.35281872749328613, train/logprobs = tensor([[-0.3648, -4.2948],
        [-0.5460, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06591063737869263
Epoch 0, Step 1237: train/loss = 0.4012335538864136, train/raw-loss = 0.3302856683731079, train/logprobs = tensor([[-0.6235, -6.1910],
        [-0.9732, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094791531562805
Epoch 0, Step 1238: train/loss = 0.5096626877784729, train/raw-loss = 0.44075897336006165, train/logprobs = tensor([[-0.6079, -3.3145],
        [-0.8347, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06890369951725006
Epoch 0, Step 1239: train/loss = 0.5997849106788635, train/raw-loss = 0.5442423820495605, train/logprobs = tensor([[-0.6753, -2.2115],
        [-0.5511, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055542487651109695
Epoch 0, Step 1240: train/loss = 0.5425893068313599, train/raw-loss = 0.4757126569747925, train/logprobs = tensor([[-0.8306, -5.1193],
        [-1.0852, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06687671691179276
Epoch 0, Step 1241: train/loss = 0.47565552592277527, train/raw-loss = 0.3976585268974304, train/logprobs = tensor([[-0.6000, -2.4272],
        [-0.9691, -0.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07799699902534485
Epoch 0, Step 1242: train/loss = 0.5015824437141418, train/raw-loss = 0.43676215410232544, train/logprobs = tensor([[-0.5842, -2.5286],
        [-0.8701, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06482026726007462
Epoch 0, Step 1243: train/loss = 0.585882306098938, train/raw-loss = 0.521074652671814, train/logprobs = tensor([[-0.5618, -1.4445],
        [-0.7760, -0.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06480759382247925
Epoch 0, Step 1244: train/loss = 0.49985194206237793, train/raw-loss = 0.432274729013443, train/logprobs = tensor([[-0.5382, -1.7225],
        [-0.8030, -0.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06757721304893494
Epoch 0, Step 1245: train/loss = 0.36699289083480835, train/raw-loss = 0.2804451882839203, train/logprobs = tensor([[-0.5384, -3.3824],
        [-1.2256, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08654772490262985
Epoch 0, Step 1246: train/loss = 0.39022600650787354, train/raw-loss = 0.31609511375427246, train/logprobs = tensor([[-0.6023, -2.5302],
        [-0.9931, -0.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07413088530302048
Epoch 0, Step 1247: train/loss = 0.4963932931423187, train/raw-loss = 0.42015767097473145, train/logprobs = tensor([[-0.8047, -3.8570],
        [-0.7299, -0.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07623562961816788
Epoch 0, Step 1248: train/loss = 0.5665454268455505, train/raw-loss = 0.49824559688568115, train/logprobs = tensor([[-0.6059, -1.6594],
        [-0.8179, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.068299800157547
Epoch 0, Step 1249: train/loss = 0.6096916198730469, train/raw-loss = 0.5423035621643066, train/logprobs = tensor([[-0.6527, -1.3173],
        [-0.7535, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06738806515932083
Epoch 0, Step 1250: train/loss = 0.5835663080215454, train/raw-loss = 0.5038127899169922, train/logprobs = tensor([[-0.6836, -1.7895],
        [-0.7108, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07975350320339203
Epoch 0, Step 1251: train/loss = 0.46866297721862793, train/raw-loss = 0.3973209261894226, train/logprobs = tensor([[-0.4185, -3.1981],
        [-0.7370, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07134201377630234
Epoch 0, Step 1252: train/loss = 0.38247060775756836, train/raw-loss = 0.30287966132164, train/logprobs = tensor([[-0.6637, -5.7815],
        [-1.1570, -1.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07959096878767014
Epoch 0, Step 1253: train/loss = 0.5152164101600647, train/raw-loss = 0.45111924409866333, train/logprobs = tensor([[-0.6058, -1.9593],
        [-0.7898, -0.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06409715861082077
Epoch 0, Step 1254: train/loss = 0.5080971121788025, train/raw-loss = 0.4462575912475586, train/logprobs = tensor([[-0.4076, -2.1924],
        [-0.6139, -0.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061839509755373
Epoch 0, Step 1255: train/loss = 0.7021983861923218, train/raw-loss = 0.6495675444602966, train/logprobs = tensor([[-0.5088, -0.6592],
        [-0.6370, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05263082683086395
Epoch 0, Step 1256: train/loss = 0.45189371705055237, train/raw-loss = 0.37989574670791626, train/logprobs = tensor([[-0.8781, -2.1032],
        [-1.4534, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07199792563915253
Epoch 0, Step 1257: train/loss = 0.5563897490501404, train/raw-loss = 0.4917762875556946, train/logprobs = tensor([[-0.4255, -1.9166],
        [-0.4863, -0.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06461348384618759
Epoch 0, Step 1258: train/loss = 0.44136789441108704, train/raw-loss = 0.3809199929237366, train/logprobs = tensor([[-0.6542, -2.6754],
        [-1.0233, -0.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060447875410318375
Epoch 0, Step 1259: train/loss = 0.6576088666915894, train/raw-loss = 0.5984055995941162, train/logprobs = tensor([[-0.4236, -0.9986],
        [-0.4751, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05920320004224777
Epoch 0, Step 1260: train/loss = 0.5046159625053406, train/raw-loss = 0.4276060461997986, train/logprobs = tensor([[-0.6106, -6.5551],
        [-1.0266, -1.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07700993120670319
Epoch 0, Step 1261: train/loss = 0.5672795176506042, train/raw-loss = 0.4766353666782379, train/logprobs = tensor([[-0.5959, -2.5009],
        [-0.8859, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09064416587352753
Epoch 0, Step 1262: train/loss = 0.4972817003726959, train/raw-loss = 0.433315247297287, train/logprobs = tensor([[-0.6356, -3.2920],
        [-0.8063, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06396647542715073
Epoch 0, Step 1263: train/loss = 0.5144774913787842, train/raw-loss = 0.4523223042488098, train/logprobs = tensor([[-0.6948, -2.4564],
        [-0.7809, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06215515360236168
Epoch 0, Step 1264: train/loss = 0.4037935733795166, train/raw-loss = 0.3233157992362976, train/logprobs = tensor([[-0.7075, -3.0630],
        [-1.0609, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0804777592420578
Epoch 0, Step 1265: train/loss = 0.5406759977340698, train/raw-loss = 0.4669250249862671, train/logprobs = tensor([[-0.6520, -2.2182],
        [-0.9342, -0.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07375093549489975
Epoch 0, Step 1266: train/loss = 0.47245845198631287, train/raw-loss = 0.400890052318573, train/logprobs = tensor([[-0.8826, -5.2428],
        [-0.8920, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07156839966773987
Epoch 0, Step 1267: train/loss = 0.33122846484184265, train/raw-loss = 0.25373977422714233, train/logprobs = tensor([[-0.6120, -3.5202],
        [-1.2212, -0.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07748870551586151
Epoch 0, Step 1268: train/loss = 0.3778690993785858, train/raw-loss = 0.30460530519485474, train/logprobs = tensor([[-0.6667, -5.4361],
        [-1.2111, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07326380163431168
Epoch 0, Step 1269: train/loss = 0.4603298604488373, train/raw-loss = 0.3963357210159302, train/logprobs = tensor([[-0.7549, -3.0764],
        [-1.0655, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0639941617846489
Epoch 0, Step 1270: train/loss = 0.5682553052902222, train/raw-loss = 0.5050689578056335, train/logprobs = tensor([[-0.6817, -3.2318],
        [-0.7254, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06318636238574982
Epoch 0, Step 1271: train/loss = 0.5652456283569336, train/raw-loss = 0.5166026949882507, train/logprobs = tensor([[-0.5949, -2.6924],
        [-0.5382, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04864288121461868
Epoch 0, Step 1272: train/loss = 0.41257327795028687, train/raw-loss = 0.3498161733150482, train/logprobs = tensor([[-0.6882, -3.0669],
        [-0.9881, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06275709718465805
Epoch 0, Step 1273: train/loss = 0.6062002182006836, train/raw-loss = 0.5446156859397888, train/logprobs = tensor([[-0.8214, -2.0929],
        [-0.6347, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06158452108502388
Epoch 0, Step 1274: train/loss = 0.5460102558135986, train/raw-loss = 0.4767971634864807, train/logprobs = tensor([[-0.3599, -2.4011],
        [-0.5537, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06921312212944031
Epoch 0, Step 1275: train/loss = 0.49471473693847656, train/raw-loss = 0.42330414056777954, train/logprobs = tensor([[-0.4473, -1.8313],
        [-0.7908, -0.4012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07141060382127762
Epoch 0, Step 1276: train/loss = 0.4040747582912445, train/raw-loss = 0.3440588712692261, train/logprobs = tensor([[-0.5571, -6.6402],
        [-0.8395, -1.2610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06001588702201843
Epoch 0, Step 1277: train/loss = 0.5874080657958984, train/raw-loss = 0.5296326279640198, train/logprobs = tensor([[-0.5405, -1.3950],
        [-0.5612, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05777546763420105
Epoch 0, Step 1278: train/loss = 0.3627890944480896, train/raw-loss = 0.28899121284484863, train/logprobs = tensor([[-0.4309, -4.0333],
        [-0.9858, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07379789650440216
Epoch 0, Step 1279: train/loss = 0.35159921646118164, train/raw-loss = 0.2585015296936035, train/logprobs = tensor([[-0.5339, -4.6890],
        [-1.0739, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09309768676757812
Epoch 0, Step 1280: train/loss = 0.4312599301338196, train/raw-loss = 0.3570544719696045, train/logprobs = tensor([[-0.5307, -3.8197],
        [-0.8755, -0.5733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07420545071363449
Epoch 0, Step 1281: train/loss = 0.4614309072494507, train/raw-loss = 0.39531975984573364, train/logprobs = tensor([[-0.5666, -3.4354],
        [-0.6725, -0.8448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06611117720603943
Epoch 0, Step 1282: train/loss = 0.5476107597351074, train/raw-loss = 0.4986168444156647, train/logprobs = tensor([[-0.4057, -2.0898],
        [-0.4417, -0.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04899395629763603
Epoch 0, Step 1283: train/loss = 0.5780876278877258, train/raw-loss = 0.5197345614433289, train/logprobs = tensor([[-0.4328, -1.7402],
        [-0.5622, -0.5875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05835306644439697
Epoch 0, Step 1284: train/loss = 0.5500347018241882, train/raw-loss = 0.48902660608291626, train/logprobs = tensor([[-0.4492, -2.8842],
        [-0.5369, -0.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06100812554359436
Epoch 0, Step 1285: train/loss = 0.3415113687515259, train/raw-loss = 0.2715592086315155, train/logprobs = tensor([[-0.6411, -5.7953],
        [-1.1800, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06995214521884918
Epoch 0, Step 1286: train/loss = 0.3483264744281769, train/raw-loss = 0.2907944917678833, train/logprobs = tensor([[-0.6180, -4.2475],
        [-0.9641, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05753201246261597
Epoch 0, Step 1287: train/loss = 0.4863370656967163, train/raw-loss = 0.4276711046695709, train/logprobs = tensor([[-0.4067, -4.3811],
        [-0.7084, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058665961027145386
Epoch 0, Step 1288: train/loss = 0.6692445874214172, train/raw-loss = 0.6065301895141602, train/logprobs = tensor([[-0.8500, -2.2109],
        [-0.6086, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06271443516016006
Epoch 0, Step 1289: train/loss = 0.4601060152053833, train/raw-loss = 0.39849692583084106, train/logprobs = tensor([[-0.6383, -3.6010],
        [-0.9098, -0.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06160910800099373
Epoch 0, Step 1290: train/loss = 0.48372238874435425, train/raw-loss = 0.4183692932128906, train/logprobs = tensor([[-0.5776, -2.9732],
        [-0.8085, -0.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06535307317972183
Epoch 0, Step 1291: train/loss = 0.4733380079269409, train/raw-loss = 0.3985499143600464, train/logprobs = tensor([[-1.5971, -9.5195],
        [-1.2743, -1.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07478808611631393
Epoch 0, Step 1292: train/loss = 0.4211963415145874, train/raw-loss = 0.34862929582595825, train/logprobs = tensor([[-0.5689, -4.2441],
        [-0.9334, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07256700098514557
Epoch 0, Step 1293: train/loss = 0.4068969488143921, train/raw-loss = 0.32635223865509033, train/logprobs = tensor([[-0.7323, -3.7433],
        [-1.3861, -0.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08054465055465698
Epoch 0, Step 1294: train/loss = 0.517898440361023, train/raw-loss = 0.4489087462425232, train/logprobs = tensor([[-0.7709, -2.0476],
        [-1.1060, -0.4769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06898970901966095
Epoch 0, Step 1295: train/loss = 0.43227893114089966, train/raw-loss = 0.37729591131210327, train/logprobs = tensor([[-0.7432, -5.0090],
        [-1.1618, -1.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05498301982879639
Epoch 0, Step 1296: train/loss = 0.41025105118751526, train/raw-loss = 0.34741461277008057, train/logprobs = tensor([[-0.7877, -2.7559],
        [-1.1372, -0.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0628364309668541
Epoch 0, Step 1297: train/loss = 0.4768502414226532, train/raw-loss = 0.407680481672287, train/logprobs = tensor([[-0.5816, -5.7806],
        [-0.7371, -1.2266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06916976720094681
Epoch 0, Step 1298: train/loss = 0.5710667371749878, train/raw-loss = 0.4957781434059143, train/logprobs = tensor([[-0.9310, -1.3960],
        [-1.1771, -0.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528860867023468
Epoch 0, Step 1299: train/loss = 0.4080701470375061, train/raw-loss = 0.33814558386802673, train/logprobs = tensor([[-0.5062, -4.6351],
        [-0.9783, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06992457807064056
Epoch 0, Step 1300: train/loss = 0.5401647090911865, train/raw-loss = 0.4635486900806427, train/logprobs = tensor([[-0.6594, -3.7853],
        [-0.9197, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07661595940589905
Epoch 0, Step 1301: train/loss = 0.5899394750595093, train/raw-loss = 0.5238316059112549, train/logprobs = tensor([[-0.6405, -1.4267],
        [-0.7582, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06610788404941559
Epoch 0, Step 1302: train/loss = 0.5716173052787781, train/raw-loss = 0.5186028480529785, train/logprobs = tensor([[-0.4618, -1.0703],
        [-0.7614, -0.5239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05301443859934807
Epoch 0, Step 1303: train/loss = 0.5675697326660156, train/raw-loss = 0.5070657134056091, train/logprobs = tensor([[-0.3761, -2.0483],
        [-0.6247, -0.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06050396338105202
Epoch 0, Step 1304: train/loss = 0.5742987394332886, train/raw-loss = 0.5108383297920227, train/logprobs = tensor([[-0.5608, -2.6758],
        [-0.8945, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06346043199300766
Epoch 0, Step 1305: train/loss = 0.49838757514953613, train/raw-loss = 0.426950067281723, train/logprobs = tensor([[-1.3567, -4.6571],
        [-1.1673, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07143755257129669
Epoch 0, Step 1306: train/loss = 0.39973869919776917, train/raw-loss = 0.32110530138015747, train/logprobs = tensor([[-1.2111, -3.8885],
        [-1.3148, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0786333754658699
Epoch 0, Step 1307: train/loss = 0.5719785094261169, train/raw-loss = 0.5202733278274536, train/logprobs = tensor([[-0.6935, -1.2387],
        [-0.8724, -0.3970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05170521140098572
Epoch 0, Step 1308: train/loss = 0.5323045253753662, train/raw-loss = 0.4717300832271576, train/logprobs = tensor([[-0.4844, -2.6132],
        [-0.9704, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06057443842291832
Epoch 0, Step 1309: train/loss = 0.5364160537719727, train/raw-loss = 0.4748833179473877, train/logprobs = tensor([[-0.6682, -1.4119],
        [-0.9210, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06153271347284317
Epoch 0, Step 1310: train/loss = 0.5402780175209045, train/raw-loss = 0.47486522793769836, train/logprobs = tensor([[-0.5089, -2.4960],
        [-0.7355, -0.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06541276723146439
Epoch 0, Step 1311: train/loss = 0.4569542407989502, train/raw-loss = 0.395908921957016, train/logprobs = tensor([[-0.5473, -3.3139],
        [-0.9179, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061045315116643906
Epoch 0, Step 1312: train/loss = 0.5401031374931335, train/raw-loss = 0.4682071805000305, train/logprobs = tensor([[-0.5874, -1.8475],
        [-0.8608, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07189594209194183
Epoch 0, Step 1313: train/loss = 0.8056833744049072, train/raw-loss = 0.7457588911056519, train/logprobs = tensor([[-1.1887, -1.3038],
        [-0.6166, -0.6266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059924446046352386
Epoch 0, Step 1314: train/loss = 0.8333467245101929, train/raw-loss = 0.7696963548660278, train/logprobs = tensor([[-1.2149, -1.0568],
        [-0.7242, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365032494068146
Epoch 0, Step 1315: train/loss = 0.37436941266059875, train/raw-loss = 0.30733755230903625, train/logprobs = tensor([[-0.4959, -9.0411],
        [-0.9223, -1.7615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670318752527237
Epoch 0, Step 1316: train/loss = 0.5519827604293823, train/raw-loss = 0.4951612949371338, train/logprobs = tensor([[-0.5373, -1.4727],
        [-0.7145, -0.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05682139843702316
Epoch 0, Step 1317: train/loss = 0.5914377570152283, train/raw-loss = 0.5241436958312988, train/logprobs = tensor([[-0.4786, -1.6474],
        [-0.8179, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06729403138160706
Epoch 0, Step 1318: train/loss = 0.44565102458000183, train/raw-loss = 0.37874889373779297, train/logprobs = tensor([[-0.4992, -4.7653],
        [-0.7224, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06690210849046707
Epoch 0, Step 1319: train/loss = 0.40716326236724854, train/raw-loss = 0.33177536725997925, train/logprobs = tensor([[-0.5053, -2.8445],
        [-1.0070, -0.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07538788765668869
Epoch 0, Step 1320: train/loss = 0.5083209872245789, train/raw-loss = 0.4416552782058716, train/logprobs = tensor([[-0.7982, -3.8621],
        [-1.1739, -0.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06666574627161026
Epoch 0, Step 1321: train/loss = 0.6051087379455566, train/raw-loss = 0.5388586521148682, train/logprobs = tensor([[-0.4493, -1.4604],
        [-0.5553, -0.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06625006347894669
Epoch 0, Step 1322: train/loss = 0.5124388337135315, train/raw-loss = 0.4509429931640625, train/logprobs = tensor([[-0.4946, -1.5932],
        [-0.8069, -0.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06149585172533989
Epoch 0, Step 1323: train/loss = 0.581476092338562, train/raw-loss = 0.5337965488433838, train/logprobs = tensor([[-0.5370, -2.7144],
        [-0.4550, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047679539769887924
Epoch 0, Step 1324: train/loss = 0.5093334317207336, train/raw-loss = 0.4422435760498047, train/logprobs = tensor([[-0.4190, -4.1720],
        [-0.5758, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06708984076976776
Epoch 0, Step 1325: train/loss = 0.6388053297996521, train/raw-loss = 0.5804436802864075, train/logprobs = tensor([[-0.3457, -1.7692],
        [-0.4989, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05836167186498642
Epoch 0, Step 1326: train/loss = 0.48148977756500244, train/raw-loss = 0.40514034032821655, train/logprobs = tensor([[-1.0946, -4.1431],
        [-0.9781, -0.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0763494148850441
Epoch 0, Step 1327: train/loss = 0.559226930141449, train/raw-loss = 0.48075491189956665, train/logprobs = tensor([[-1.2711, -2.4751],
        [-1.2171, -0.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07847202569246292
Epoch 0, Step 1328: train/loss = 0.4538147449493408, train/raw-loss = 0.38524240255355835, train/logprobs = tensor([[-0.6480, -3.0690],
        [-0.7602, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06857233494520187
Epoch 0, Step 1329: train/loss = 0.37515342235565186, train/raw-loss = 0.29934442043304443, train/logprobs = tensor([[-0.9295, -4.2224],
        [-1.3219, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07580898702144623
Epoch 0, Step 1330: train/loss = 0.5757771134376526, train/raw-loss = 0.5036376714706421, train/logprobs = tensor([[-0.8100, -3.7570],
        [-0.7439, -1.0506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07213948667049408
Epoch 0, Step 1331: train/loss = 0.4653528332710266, train/raw-loss = 0.3858433961868286, train/logprobs = tensor([[-0.6891, -2.1798],
        [-0.9989, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07950945943593979
Epoch 0, Step 1332: train/loss = 0.3981959819793701, train/raw-loss = 0.31591323018074036, train/logprobs = tensor([[-0.6095, -3.0899],
        [-0.8718, -0.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08228275924921036
Epoch 0, Step 1333: train/loss = 0.5543763041496277, train/raw-loss = 0.49386799335479736, train/logprobs = tensor([[-0.6119, -2.4233],
        [-0.6956, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06050828471779823
Epoch 0, Step 1334: train/loss = 0.5713703632354736, train/raw-loss = 0.4981120824813843, train/logprobs = tensor([[-1.2786, -2.4503],
        [-1.3591, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07325822114944458
Epoch 0, Step 1335: train/loss = 0.4583028256893158, train/raw-loss = 0.38210129737854004, train/logprobs = tensor([[-1.6004, -4.6607],
        [-1.5130, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07620150595903397
Epoch 0, Step 1336: train/loss = 0.4707052707672119, train/raw-loss = 0.40576833486557007, train/logprobs = tensor([[-0.5857, -7.1619],
        [-0.7551, -1.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06493694335222244
Epoch 0, Step 1337: train/loss = 0.535480260848999, train/raw-loss = 0.4904601275920868, train/logprobs = tensor([[-0.3585, -4.5486],
        [-0.5067, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04502010717988014
Epoch 0, Step 1338: train/loss = 0.4410529136657715, train/raw-loss = 0.3530597686767578, train/logprobs = tensor([[-0.5387, -2.9508],
        [-0.9286, -0.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799316734075546
Epoch 0, Step 1339: train/loss = 0.4983617663383484, train/raw-loss = 0.4175873398780823, train/logprobs = tensor([[-0.8337, -2.5071],
        [-1.1454, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08077436685562134
Epoch 0, Step 1340: train/loss = 0.3610321581363678, train/raw-loss = 0.2785985767841339, train/logprobs = tensor([[-0.5914, -3.4509],
        [-1.1386, -0.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08243357390165329
Epoch 0, Step 1341: train/loss = 0.46215569972991943, train/raw-loss = 0.4087313413619995, train/logprobs = tensor([[-0.7287, -2.7518],
        [-0.9763, -0.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05342433974146843
Epoch 0, Step 1342: train/loss = 0.6660197377204895, train/raw-loss = 0.6109181046485901, train/logprobs = tensor([[-0.6516, -1.6361],
        [-0.3861, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055101655423641205
Epoch 0, Step 1343: train/loss = 0.37083709239959717, train/raw-loss = 0.29555147886276245, train/logprobs = tensor([[-0.6801, -2.6369],
        [-1.3230, -0.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528562843799591
Epoch 0, Step 1344: train/loss = 0.6862572431564331, train/raw-loss = 0.6252022981643677, train/logprobs = tensor([[-1.4057, -2.7445],
        [-0.6990, -0.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06105490401387215
Epoch 0, Step 1345: train/loss = 0.5953962802886963, train/raw-loss = 0.5165126919746399, train/logprobs = tensor([[-0.8347, -1.9116],
        [-0.9696, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.078883595764637
Epoch 0, Step 1346: train/loss = 0.5803430080413818, train/raw-loss = 0.5073105096817017, train/logprobs = tensor([[-0.7579, -1.7499],
        [-0.7712, -0.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07303249835968018
Epoch 0, Step 1347: train/loss = 0.543611466884613, train/raw-loss = 0.4752828776836395, train/logprobs = tensor([[-0.7952, -2.1831],
        [-0.9428, -0.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06832856684923172
Epoch 0, Step 1348: train/loss = 0.5613774061203003, train/raw-loss = 0.5161138772964478, train/logprobs = tensor([[-0.7297, -1.4839],
        [-0.9792, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04526355490088463
Epoch 0, Step 1349: train/loss = 0.5500447154045105, train/raw-loss = 0.49020707607269287, train/logprobs = tensor([[-0.7017, -1.6669],
        [-0.8737, -0.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059837669134140015
Epoch 0, Step 1350: train/loss = 0.394295871257782, train/raw-loss = 0.3357745409011841, train/logprobs = tensor([[-0.5365, -5.7269],
        [-0.7655, -1.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05852136015892029
Epoch 0, Step 1351: train/loss = 0.5328577160835266, train/raw-loss = 0.46948352456092834, train/logprobs = tensor([[-1.0721, -2.3809],
        [-1.1655, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06337414681911469
Epoch 0, Step 1352: train/loss = 0.5709337592124939, train/raw-loss = 0.5213450789451599, train/logprobs = tensor([[-0.5441, -1.5629],
        [-0.6272, -0.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049588676542043686
Epoch 0, Step 1353: train/loss = 0.6090846061706543, train/raw-loss = 0.5621376633644104, train/logprobs = tensor([[-0.5017, -2.5204],
        [-0.5158, -0.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04694695770740509
Epoch 0, Step 1354: train/loss = 0.5367247462272644, train/raw-loss = 0.45743513107299805, train/logprobs = tensor([[-0.6038, -1.5118],
        [-1.0160, -0.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07928963005542755
Epoch 0, Step 1355: train/loss = 0.306663453578949, train/raw-loss = 0.24308356642723083, train/logprobs = tensor([[-0.6550, -5.5695],
        [-0.9148, -0.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06357988715171814
Epoch 0, Step 1356: train/loss = 0.5763916969299316, train/raw-loss = 0.5171831846237183, train/logprobs = tensor([[-0.7071, -2.2110],
        [-0.7718, -0.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05920851603150368
Epoch 0, Step 1357: train/loss = 0.6504672169685364, train/raw-loss = 0.5957728624343872, train/logprobs = tensor([[-0.4487, -0.9162],
        [-0.6044, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05469434708356857
Epoch 0, Step 1358: train/loss = 0.40911975502967834, train/raw-loss = 0.3369944989681244, train/logprobs = tensor([[-0.5621, -3.1936],
        [-1.0112, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07212522625923157
Epoch 0, Step 1359: train/loss = 0.5985488891601562, train/raw-loss = 0.5208364725112915, train/logprobs = tensor([[-0.4744, -2.0995],
        [-0.6929, -0.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07771247625350952
Epoch 0, Step 1360: train/loss = 0.4557285010814667, train/raw-loss = 0.39508187770843506, train/logprobs = tensor([[-0.6112, -2.7497],
        [-0.7814, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06064660847187042
Epoch 0, Step 1361: train/loss = 0.4496152698993683, train/raw-loss = 0.3818976581096649, train/logprobs = tensor([[-0.7148, -3.2034],
        [-0.7894, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06771761924028397
Epoch 0, Step 1362: train/loss = 0.481866717338562, train/raw-loss = 0.40062230825424194, train/logprobs = tensor([[-0.5922, -2.5992],
        [-1.2003, -0.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08124443888664246
Epoch 0, Step 1363: train/loss = 0.5914899110794067, train/raw-loss = 0.5465096235275269, train/logprobs = tensor([[-0.3886, -1.6328],
        [-0.5901, -0.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04498022422194481
Epoch 0, Step 1364: train/loss = 0.488615483045578, train/raw-loss = 0.43032971024513245, train/logprobs = tensor([[-0.4045, -2.9262],
        [-0.5986, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05828578770160675
Epoch 0, Step 1365: train/loss = 0.4331033527851105, train/raw-loss = 0.3731690049171448, train/logprobs = tensor([[-0.3623, -3.6303],
        [-0.5553, -0.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059934332966804504
Epoch 0, Step 1366: train/loss = 0.5774515867233276, train/raw-loss = 0.5272786617279053, train/logprobs = tensor([[-0.3740, -2.9538],
        [-0.5271, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05017293617129326
Epoch 0, Step 1367: train/loss = 0.42800480127334595, train/raw-loss = 0.3603220283985138, train/logprobs = tensor([[-0.5865, -3.6054],
        [-1.1601, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06768276542425156
Epoch 0, Step 1368: train/loss = 0.6120127439498901, train/raw-loss = 0.5552272796630859, train/logprobs = tensor([[-0.5465, -1.5372],
        [-0.6545, -0.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05678544566035271
Epoch 0, Step 1369: train/loss = 0.5088569521903992, train/raw-loss = 0.4408159852027893, train/logprobs = tensor([[-0.4860, -1.5658],
        [-1.1227, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804092973470688
Epoch 0, Step 1370: train/loss = 0.5910766124725342, train/raw-loss = 0.5284202098846436, train/logprobs = tensor([[-0.5950, -1.1880],
        [-0.7985, -0.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06265631318092346
Epoch 0, Step 1371: train/loss = 0.508472204208374, train/raw-loss = 0.4529896378517151, train/logprobs = tensor([[-0.5174, -2.8536],
        [-0.7253, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055482566356658936
Epoch 0, Step 1372: train/loss = 0.4251669943332672, train/raw-loss = 0.3606215715408325, train/logprobs = tensor([[-0.5785, -5.0306],
        [-0.9649, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645454153418541
Epoch 0, Step 1373: train/loss = 0.5522636771202087, train/raw-loss = 0.4951639771461487, train/logprobs = tensor([[-1.0861, -1.9678],
        [-1.3574, -0.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05709971487522125
Epoch 0, Step 1374: train/loss = 0.4935491681098938, train/raw-loss = 0.4334527552127838, train/logprobs = tensor([[-0.3933, -2.8382],
        [-0.6859, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060096412897109985
Epoch 0, Step 1375: train/loss = 0.3943355679512024, train/raw-loss = 0.3322564363479614, train/logprobs = tensor([[-0.5515, -4.9294],
        [-0.8329, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062079161405563354
Epoch 0, Step 1376: train/loss = 0.4027616083621979, train/raw-loss = 0.3238638639450073, train/logprobs = tensor([[-0.8973, -3.0731],
        [-1.4647, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07889775186777115
Epoch 0, Step 1377: train/loss = 0.5200591683387756, train/raw-loss = 0.4617161154747009, train/logprobs = tensor([[-0.4246, -3.1433],
        [-0.6329, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058343011885881424
Epoch 0, Step 1378: train/loss = 0.5667796730995178, train/raw-loss = 0.5106449723243713, train/logprobs = tensor([[-0.7303, -2.3397],
        [-0.6594, -0.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0561346709728241
Epoch 0, Step 1379: train/loss = 0.5503343939781189, train/raw-loss = 0.4836220145225525, train/logprobs = tensor([[-0.7312, -2.0069],
        [-0.8549, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06671237200498581
Epoch 0, Step 1380: train/loss = 0.34702953696250916, train/raw-loss = 0.27024275064468384, train/logprobs = tensor([[-0.4764, -4.1443],
        [-0.8826, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07678678631782532
Epoch 0, Step 1381: train/loss = 0.4684409499168396, train/raw-loss = 0.39951348304748535, train/logprobs = tensor([[-0.5113, -5.3858],
        [-0.7175, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06892749667167664
Epoch 0, Step 1382: train/loss = 0.461349219083786, train/raw-loss = 0.3917847275733948, train/logprobs = tensor([[-0.7693, -3.6593],
        [-0.8642, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06956450641155243
Epoch 0, Step 1383: train/loss = 0.3709757626056671, train/raw-loss = 0.31022384762763977, train/logprobs = tensor([[-0.7943, -3.9055],
        [-1.1756, -1.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060751914978027344
Epoch 0, Step 1384: train/loss = 0.5239907503128052, train/raw-loss = 0.46288037300109863, train/logprobs = tensor([[-0.5490, -2.7111],
        [-0.8046, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06111039221286774
Epoch 0, Step 1385: train/loss = 0.47643354535102844, train/raw-loss = 0.3932274878025055, train/logprobs = tensor([[-0.6825, -1.8216],
        [-1.1899, -0.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08320607990026474
Epoch 0, Step 1386: train/loss = 0.47809404134750366, train/raw-loss = 0.3934726119041443, train/logprobs = tensor([[-0.6629, -1.8015],
        [-1.0468, -0.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08462139964103699
Epoch 0, Step 1387: train/loss = 0.5654110312461853, train/raw-loss = 0.49719712138175964, train/logprobs = tensor([[-0.5813, -1.2827],
        [-0.8104, -0.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821395456790924
Epoch 0, Step 1388: train/loss = 0.4146854877471924, train/raw-loss = 0.35902294516563416, train/logprobs = tensor([[-0.9648, -3.1205],
        [-1.1373, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05566254258155823
Epoch 0, Step 1389: train/loss = 0.5736904144287109, train/raw-loss = 0.5003187656402588, train/logprobs = tensor([[-0.8930, -2.6649],
        [-0.8287, -0.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07337160408496857
Epoch 0, Step 1390: train/loss = 0.5678054094314575, train/raw-loss = 0.5052179098129272, train/logprobs = tensor([[-0.4892, -1.3576],
        [-0.6507, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06258755922317505
Epoch 0, Step 1391: train/loss = 0.4718533754348755, train/raw-loss = 0.4058440625667572, train/logprobs = tensor([[-0.5220, -2.3237],
        [-0.7551, -0.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06600934267044067
Epoch 0, Step 1392: train/loss = 0.4087086021900177, train/raw-loss = 0.3496253490447998, train/logprobs = tensor([[-0.5718, -5.9031],
        [-0.8577, -1.1566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059083208441734314
Epoch 0, Step 1393: train/loss = 0.38566288352012634, train/raw-loss = 0.30474036931991577, train/logprobs = tensor([[-0.5405, -5.4724],
        [-1.0687, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092249929904938
Epoch 0, Step 1394: train/loss = 0.49248674511909485, train/raw-loss = 0.4253578186035156, train/logprobs = tensor([[-0.4985, -1.5819],
        [-0.9033, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06712892651557922
Epoch 0, Step 1395: train/loss = 0.46629127860069275, train/raw-loss = 0.38430580496788025, train/logprobs = tensor([[-0.6311, -2.6897],
        [-0.8628, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819854810833931
Epoch 0, Step 1396: train/loss = 0.42603152990341187, train/raw-loss = 0.33776456117630005, train/logprobs = tensor([[-0.6779, -4.2890],
        [-0.9593, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08826695382595062
Epoch 0, Step 1397: train/loss = 0.39147263765335083, train/raw-loss = 0.33283668756484985, train/logprobs = tensor([[-0.4760, -6.7002],
        [-0.6163, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05863595008850098
Epoch 0, Step 1398: train/loss = 0.3501642346382141, train/raw-loss = 0.24718983471393585, train/logprobs = tensor([[-0.7516, -3.4942],
        [-1.1890, -0.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10297439992427826
Epoch 0, Step 1399: train/loss = 0.4172588586807251, train/raw-loss = 0.3332657814025879, train/logprobs = tensor([[-0.5042, -2.6731],
        [-1.2080, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08399307727813721
Epoch 0, Step 1400: train/loss = 0.5590903759002686, train/raw-loss = 0.48780304193496704, train/logprobs = tensor([[-0.5926, -7.1172],
        [-0.7703, -1.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128734141588211
Epoch 0, Step 1401: train/loss = 0.4302319288253784, train/raw-loss = 0.34291911125183105, train/logprobs = tensor([[-0.8003, -4.3310],
        [-1.2698, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08731286227703094
Epoch 0, Step 1402: train/loss = 0.4485569894313812, train/raw-loss = 0.3756159543991089, train/logprobs = tensor([[-0.5459, -2.9631],
        [-0.9201, -0.6991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07294100522994995
Epoch 0, Step 1403: train/loss = 0.47865527868270874, train/raw-loss = 0.40871888399124146, train/logprobs = tensor([[-1.1222, -3.9272],
        [-0.8674, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06993643939495087
Epoch 0, Step 1404: train/loss = 0.43406692147254944, train/raw-loss = 0.36959320306777954, train/logprobs = tensor([[-0.6304, -6.9003],
        [-0.9779, -1.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06447374820709229
Epoch 0, Step 1405: train/loss = 0.5113124847412109, train/raw-loss = 0.42770400643348694, train/logprobs = tensor([[-0.6058, -5.2434],
        [-0.9628, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08360843360424042
Epoch 0, Step 1406: train/loss = 0.5470012426376343, train/raw-loss = 0.49048128724098206, train/logprobs = tensor([[-0.4623, -1.5175],
        [-0.6628, -0.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05651991814374924
Epoch 0, Step 1407: train/loss = 0.45863109827041626, train/raw-loss = 0.39546793699264526, train/logprobs = tensor([[-0.6798, -6.2995],
        [-0.7364, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063163161277771
Epoch 0, Step 1408: train/loss = 0.284608393907547, train/raw-loss = 0.2176370471715927, train/logprobs = tensor([[-0.5343, -8.9116],
        [-0.9692, -1.3974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06697136908769608
Epoch 0, Step 1409: train/loss = 0.6501052379608154, train/raw-loss = 0.5904324054718018, train/logprobs = tensor([[-0.5384, -0.8634],
        [-0.6921, -0.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05967288836836815
Epoch 0, Step 1410: train/loss = 0.4672715663909912, train/raw-loss = 0.3788550794124603, train/logprobs = tensor([[-0.6345, -2.9735],
        [-1.0839, -0.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08841650933027267
Epoch 0, Step 1411: train/loss = 0.511059045791626, train/raw-loss = 0.44468259811401367, train/logprobs = tensor([[-0.3951, -2.7263],
        [-0.6819, -0.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0663764625787735
Epoch 0, Step 1412: train/loss = 0.4606877863407135, train/raw-loss = 0.3918175995349884, train/logprobs = tensor([[-0.5557, -1.8707],
        [-1.0023, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06887021660804749
Epoch 0, Step 1413: train/loss = 0.4407723546028137, train/raw-loss = 0.3781247138977051, train/logprobs = tensor([[-0.6718, -3.2449],
        [-0.7767, -0.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06264767050743103
Epoch 0, Step 1414: train/loss = 0.5120846033096313, train/raw-loss = 0.45755496621131897, train/logprobs = tensor([[-0.6521, -4.3298],
        [-0.9185, -1.6330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054529622197151184
Epoch 0, Step 1415: train/loss = 0.5919849872589111, train/raw-loss = 0.5465604066848755, train/logprobs = tensor([[-0.4177, -0.9514],
        [-0.5694, -0.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04542456194758415
Epoch 0, Step 1416: train/loss = 0.40299057960510254, train/raw-loss = 0.33925944566726685, train/logprobs = tensor([[-0.6633, -7.2573],
        [-0.9925, -1.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0637311264872551
Epoch 0, Step 1417: train/loss = 0.3754459023475647, train/raw-loss = 0.3071989417076111, train/logprobs = tensor([[-0.4780, -5.9763],
        [-0.8081, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06824691593647003
Epoch 0, Step 1418: train/loss = 0.5153980255126953, train/raw-loss = 0.44948944449424744, train/logprobs = tensor([[-0.6953, -2.4067],
        [-0.8113, -0.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06590854376554489
Epoch 0, Step 1419: train/loss = 0.607635498046875, train/raw-loss = 0.5589016675949097, train/logprobs = tensor([[-0.3957, -1.1591],
        [-0.5847, -0.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04873385652899742
Epoch 0, Step 1420: train/loss = 0.4627731740474701, train/raw-loss = 0.39896678924560547, train/logprobs = tensor([[-0.4182, -3.3181],
        [-0.7329, -0.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06380637735128403
Epoch 0, Step 1421: train/loss = 0.575985848903656, train/raw-loss = 0.5218591690063477, train/logprobs = tensor([[-0.4934, -2.3835],
        [-0.7766, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054126664996147156
Epoch 0, Step 1422: train/loss = 0.6282373070716858, train/raw-loss = 0.5845311880111694, train/logprobs = tensor([[-0.2929, -0.9717],
        [-0.4042, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04370613396167755
Epoch 0, Step 1423: train/loss = 0.4663711190223694, train/raw-loss = 0.4145159423351288, train/logprobs = tensor([[-0.4322, -2.6081],
        [-0.6102, -0.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05185514688491821
Epoch 0, Step 1424: train/loss = 0.2841244637966156, train/raw-loss = 0.2050677239894867, train/logprobs = tensor([[-0.5615, -6.9047],
        [-1.2892, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07905673235654831
Epoch 0, Step 1425: train/loss = 0.3693544268608093, train/raw-loss = 0.3010837435722351, train/logprobs = tensor([[-0.7706, -3.9348],
        [-1.0880, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06827067583799362
Epoch 0, Step 1426: train/loss = 0.38850969076156616, train/raw-loss = 0.317848265171051, train/logprobs = tensor([[-0.6748, -7.1466],
        [-1.0435, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07066144794225693
Epoch 0, Step 1427: train/loss = 0.5326356291770935, train/raw-loss = 0.4694247245788574, train/logprobs = tensor([[-0.5658, -1.7939],
        [-0.8739, -0.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06321091204881668
Epoch 0, Step 1428: train/loss = 0.4333268105983734, train/raw-loss = 0.3615474998950958, train/logprobs = tensor([[-0.5091, -3.6163],
        [-0.9426, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07177932560443878
Epoch 0, Step 1429: train/loss = 0.4236956536769867, train/raw-loss = 0.3478274643421173, train/logprobs = tensor([[-0.7284, -5.0609],
        [-0.9502, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07586818933486938
Epoch 0, Step 1430: train/loss = 0.4024672508239746, train/raw-loss = 0.3360718786716461, train/logprobs = tensor([[-0.9729, -5.7324],
        [-1.3263, -2.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06639539450407028
Epoch 0, Step 1431: train/loss = 0.30273693799972534, train/raw-loss = 0.21542303264141083, train/logprobs = tensor([[ -0.6604, -10.9079],
        [ -1.1713,  -2.6677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08731390535831451
Epoch 0, Step 1432: train/loss = 0.6104884147644043, train/raw-loss = 0.5330164432525635, train/logprobs = tensor([[-0.5067, -4.7662],
        [-1.1744, -1.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07747199386358261
Epoch 0, Step 1433: train/loss = 0.5088266134262085, train/raw-loss = 0.4470502734184265, train/logprobs = tensor([[-0.4450, -2.6439],
        [-0.8628, -0.4244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061776354908943176
Epoch 0, Step 1434: train/loss = 0.36554569005966187, train/raw-loss = 0.2771303653717041, train/logprobs = tensor([[-0.5865, -3.5576],
        [-1.2023, -0.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08841533958911896
Epoch 0, Step 1435: train/loss = 0.41598835587501526, train/raw-loss = 0.32581400871276855, train/logprobs = tensor([[-0.5917, -4.6815],
        [-1.1947, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0901743620634079
Epoch 0, Step 1436: train/loss = 0.4806783199310303, train/raw-loss = 0.41853058338165283, train/logprobs = tensor([[-1.2216, -7.1029],
        [-1.0136, -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06214774399995804
Epoch 0, Step 1437: train/loss = 0.48503896594047546, train/raw-loss = 0.4285593628883362, train/logprobs = tensor([[-0.4654, -5.8645],
        [-0.7820, -0.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05647960677742958
Epoch 0, Step 1438: train/loss = 0.28148919343948364, train/raw-loss = 0.21182334423065186, train/logprobs = tensor([[-0.7376, -8.3439],
        [-1.4745, -1.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06966587156057358
Epoch 0, Step 1439: train/loss = 0.47880077362060547, train/raw-loss = 0.4250144362449646, train/logprobs = tensor([[-0.6049, -2.9778],
        [-1.0370, -0.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053786344826221466
Epoch 0, Step 1440: train/loss = 0.5292562246322632, train/raw-loss = 0.4586426615715027, train/logprobs = tensor([[-0.5593, -2.5657],
        [-0.8494, -0.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07061354070901871
Epoch 0, Step 1441: train/loss = 0.6636794805526733, train/raw-loss = 0.6025538444519043, train/logprobs = tensor([[-0.7141, -1.1706],
        [-0.6670, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06112567335367203
Epoch 0, Step 1442: train/loss = 0.30632293224334717, train/raw-loss = 0.22008788585662842, train/logprobs = tensor([[-0.7699, -4.3585],
        [-1.4215, -0.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08623506128787994
Epoch 0, Step 1443: train/loss = 0.6352387070655823, train/raw-loss = 0.5768544673919678, train/logprobs = tensor([[-0.8374, -2.8207],
        [-0.6810, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058384254574775696
Epoch 0, Step 1444: train/loss = 0.42743927240371704, train/raw-loss = 0.3328361213207245, train/logprobs = tensor([[-0.6510, -2.8310],
        [-1.4031, -0.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09460313618183136
Epoch 0, Step 1445: train/loss = 0.4910251498222351, train/raw-loss = 0.43674618005752563, train/logprobs = tensor([[-0.3387, -2.6397],
        [-0.5591, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05427900701761246
Epoch 0, Step 1446: train/loss = 0.5407007932662964, train/raw-loss = 0.46956437826156616, train/logprobs = tensor([[-1.0312, -6.5751],
        [-1.0605, -1.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07113637030124664
Epoch 0, Step 1447: train/loss = 0.48804688453674316, train/raw-loss = 0.42107200622558594, train/logprobs = tensor([[-1.0282, -2.9302],
        [-0.8802, -0.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06697487831115723
Epoch 0, Step 1448: train/loss = 0.5089273452758789, train/raw-loss = 0.42573094367980957, train/logprobs = tensor([[-0.8520, -2.8828],
        [-0.6838, -0.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08319640904664993
Epoch 0, Step 1449: train/loss = 0.5426357984542847, train/raw-loss = 0.4797021448612213, train/logprobs = tensor([[-0.4784, -4.6847],
        [-0.7778, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06293366104364395
Epoch 0, Step 1450: train/loss = 0.43488210439682007, train/raw-loss = 0.3641349971294403, train/logprobs = tensor([[-0.4258, -2.7990],
        [-0.7038, -0.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07074708491563797
Epoch 0, Step 1451: train/loss = 0.47528785467147827, train/raw-loss = 0.3937077820301056, train/logprobs = tensor([[-0.6363, -3.6775],
        [-1.0652, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08158008754253387
Epoch 0, Step 1452: train/loss = 0.4837701916694641, train/raw-loss = 0.4074519872665405, train/logprobs = tensor([[-0.5072, -5.5523],
        [-0.9717, -1.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07631823420524597
Epoch 0, Step 1453: train/loss = 0.43800053000450134, train/raw-loss = 0.3711969554424286, train/logprobs = tensor([[-0.5541, -2.5419],
        [-0.8848, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06680355966091156
Epoch 0, Step 1454: train/loss = 0.41685569286346436, train/raw-loss = 0.3446134328842163, train/logprobs = tensor([[-0.6759, -3.1571],
        [-1.0957, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07224226742982864
Epoch 0, Step 1455: train/loss = 0.344321072101593, train/raw-loss = 0.2750127613544464, train/logprobs = tensor([[-0.5580, -4.8650],
        [-1.3438, -1.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0693083107471466
Epoch 0, Step 1456: train/loss = 0.39563238620758057, train/raw-loss = 0.3372379243373871, train/logprobs = tensor([[-0.7065, -5.9878],
        [-0.7905, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058394480496644974
Epoch 0, Step 1457: train/loss = 0.42548519372940063, train/raw-loss = 0.35660189390182495, train/logprobs = tensor([[-0.6340, -4.7846],
        [-0.9677, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06888332217931747
Epoch 0, Step 1458: train/loss = 0.6592900156974792, train/raw-loss = 0.5995786190032959, train/logprobs = tensor([[-0.5937, -0.8182],
        [-0.8051, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05971139669418335
Epoch 0, Step 1459: train/loss = 0.3321014940738678, train/raw-loss = 0.24459077417850494, train/logprobs = tensor([[-0.5290, -6.4823],
        [-1.2783, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08751070499420166
Epoch 0, Step 1460: train/loss = 0.35874706506729126, train/raw-loss = 0.2861834168434143, train/logprobs = tensor([[-0.8289, -5.4657],
        [-1.1470, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07256365567445755
Epoch 0, Step 1461: train/loss = 0.5495631694793701, train/raw-loss = 0.4621638357639313, train/logprobs = tensor([[-0.5498, -1.7657],
        [-1.2337, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08739934116601944
Epoch 0, Step 1462: train/loss = 0.46506205201148987, train/raw-loss = 0.3925755023956299, train/logprobs = tensor([[-0.5783, -2.3455],
        [-0.9385, -0.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724865272641182
Epoch 0, Step 1463: train/loss = 0.37362104654312134, train/raw-loss = 0.28521665930747986, train/logprobs = tensor([[-0.6883, -3.2653],
        [-1.4384, -0.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884043425321579
Epoch 0, Step 1464: train/loss = 0.49644434452056885, train/raw-loss = 0.423118531703949, train/logprobs = tensor([[-0.5353, -2.8692],
        [-0.8529, -0.6166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07332581281661987
Epoch 0, Step 1465: train/loss = 0.39334365725517273, train/raw-loss = 0.3356119692325592, train/logprobs = tensor([[-0.6424, -4.6131],
        [-1.1757, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05773168057203293
Epoch 0, Step 1466: train/loss = 0.5212716460227966, train/raw-loss = 0.4577394723892212, train/logprobs = tensor([[-0.5336, -3.0648],
        [-0.6612, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06353218853473663
Epoch 0, Step 1467: train/loss = 0.39727139472961426, train/raw-loss = 0.3248559832572937, train/logprobs = tensor([[-0.6577, -7.0010],
        [-1.2287, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07241542637348175
Epoch 0, Step 1468: train/loss = 0.5148241519927979, train/raw-loss = 0.453366756439209, train/logprobs = tensor([[-1.0655, -5.4194],
        [-1.1576, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06145743653178215
Epoch 0, Step 1469: train/loss = 0.45268958806991577, train/raw-loss = 0.38430750370025635, train/logprobs = tensor([[-0.4818, -2.5895],
        [-0.7531, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06838206946849823
Epoch 0, Step 1470: train/loss = 0.3774815797805786, train/raw-loss = 0.2873626947402954, train/logprobs = tensor([[-0.6043, -3.5807],
        [-0.9610, -0.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09011885523796082
Epoch 0, Step 1471: train/loss = 0.5114662647247314, train/raw-loss = 0.4412306547164917, train/logprobs = tensor([[-0.4571, -1.8716],
        [-0.8232, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07023561000823975
Epoch 0, Step 1472: train/loss = 0.4361841380596161, train/raw-loss = 0.3820653557777405, train/logprobs = tensor([[-0.5073, -6.4583],
        [-0.6455, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054118812084198
Epoch 0, Step 1473: train/loss = 0.4201708436012268, train/raw-loss = 0.3381367027759552, train/logprobs = tensor([[-0.6288, -2.8042],
        [-0.9751, -0.5967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08203411102294922
Epoch 0, Step 1474: train/loss = 0.5015295147895813, train/raw-loss = 0.43428781628608704, train/logprobs = tensor([[-0.6513, -2.4381],
        [-0.8023, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06724168360233307
Epoch 0, Step 1475: train/loss = 0.5454486012458801, train/raw-loss = 0.4793663024902344, train/logprobs = tensor([[-0.6237, -1.7041],
        [-0.9214, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06608233600854874
Epoch 0, Step 1476: train/loss = 0.5288408994674683, train/raw-loss = 0.44976961612701416, train/logprobs = tensor([[-0.8711, -2.7227],
        [-0.8930, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07907131314277649
Epoch 0, Step 1477: train/loss = 0.3903718888759613, train/raw-loss = 0.31336942315101624, train/logprobs = tensor([[-0.9240, -4.3019],
        [-1.2559, -0.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07700246572494507
Epoch 0, Step 1478: train/loss = 0.6303466558456421, train/raw-loss = 0.5666282176971436, train/logprobs = tensor([[-0.5057, -0.8065],
        [-0.8507, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06371845304965973
Epoch 0, Step 1479: train/loss = 0.5490814447402954, train/raw-loss = 0.47097188234329224, train/logprobs = tensor([[-0.4997, -1.9818],
        [-0.8749, -0.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07810956239700317
Epoch 0, Step 1480: train/loss = 0.4459860622882843, train/raw-loss = 0.371995747089386, train/logprobs = tensor([[-0.7315, -3.5029],
        [-1.3448, -0.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07399030774831772
Epoch 0, Step 1481: train/loss = 0.4521995782852173, train/raw-loss = 0.3718295991420746, train/logprobs = tensor([[-0.6622, -3.8343],
        [-1.0480, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0803699642419815
Epoch 0, Step 1482: train/loss = 0.387084037065506, train/raw-loss = 0.317934513092041, train/logprobs = tensor([[-0.4915, -5.8732],
        [-0.7746, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06914950907230377
Epoch 0, Step 1483: train/loss = 0.47554174065589905, train/raw-loss = 0.39572009444236755, train/logprobs = tensor([[-0.6031, -2.7369],
        [-1.1440, -0.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0798216387629509
Epoch 0, Step 1484: train/loss = 0.3826897144317627, train/raw-loss = 0.30350542068481445, train/logprobs = tensor([[-0.4396, -3.7367],
        [-0.8916, -0.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07918430119752884
Epoch 0, Step 1485: train/loss = 0.5684336423873901, train/raw-loss = 0.49286675453186035, train/logprobs = tensor([[-0.5609, -2.0517],
        [-0.6836, -0.6857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075566865503788
Epoch 0, Step 1486: train/loss = 0.5660039782524109, train/raw-loss = 0.495869517326355, train/logprobs = tensor([[-0.7713, -1.8524],
        [-0.7293, -0.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07013445347547531
Epoch 0, Step 1487: train/loss = 0.4782686233520508, train/raw-loss = 0.40533509850502014, train/logprobs = tensor([[-0.9286, -3.0005],
        [-1.0055, -0.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07293355464935303
Epoch 0, Step 1488: train/loss = 0.5577463507652283, train/raw-loss = 0.48554009199142456, train/logprobs = tensor([[-0.4522, -1.5010],
        [-0.6518, -0.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07220632582902908
Epoch 0, Step 1489: train/loss = 0.5617603063583374, train/raw-loss = 0.4996260106563568, train/logprobs = tensor([[-0.7266, -2.4574],
        [-0.8309, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06213429570198059
Epoch 0, Step 1490: train/loss = 0.5024762153625488, train/raw-loss = 0.43896299600601196, train/logprobs = tensor([[-0.4565, -2.3571],
        [-0.7908, -0.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06351321935653687
Epoch 0, Step 1491: train/loss = 0.40489131212234497, train/raw-loss = 0.31300896406173706, train/logprobs = tensor([[-0.9493, -4.2981],
        [-1.1313, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0918823778629303
Epoch 0, Step 1492: train/loss = 0.5364839434623718, train/raw-loss = 0.47289639711380005, train/logprobs = tensor([[-0.5916, -2.9862],
        [-0.9630, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06358756870031357
Epoch 0, Step 1493: train/loss = 0.42348259687423706, train/raw-loss = 0.35027384757995605, train/logprobs = tensor([[-0.5671, -2.1754],
        [-1.3106, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07320873439311981
Epoch 0, Step 1494: train/loss = 0.3881533145904541, train/raw-loss = 0.2892313301563263, train/logprobs = tensor([[-0.5423, -3.3758],
        [-1.0937, -0.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09892198443412781
Epoch 0, Step 1495: train/loss = 0.34049972891807556, train/raw-loss = 0.26080042123794556, train/logprobs = tensor([[-0.4994, -5.0927],
        [-1.0210, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796993151307106
Epoch 0, Step 1496: train/loss = 0.4054388403892517, train/raw-loss = 0.3319053053855896, train/logprobs = tensor([[-0.6052, -3.9870],
        [-0.8260, -0.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0735335499048233
Epoch 0, Step 1497: train/loss = 0.4455360770225525, train/raw-loss = 0.38521814346313477, train/logprobs = tensor([[-0.5379, -2.4154],
        [-0.8099, -0.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060317911207675934
Epoch 0, Step 1498: train/loss = 0.4685838520526886, train/raw-loss = 0.3966120481491089, train/logprobs = tensor([[-0.5859, -1.9033],
        [-1.1518, -0.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07197178900241852
Epoch 0, Step 1499: train/loss = 0.5026652812957764, train/raw-loss = 0.4336055815219879, train/logprobs = tensor([[-0.9416, -2.3593],
        [-1.1245, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06905966997146606
Epoch 0, Step 1500: train/loss = 0.5107836723327637, train/raw-loss = 0.4666314721107483, train/logprobs = tensor([[-0.3275, -2.7299],
        [-0.4291, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04415212199091911
Epoch 0, Step 1501: train/loss = 0.3225136399269104, train/raw-loss = 0.2179984599351883, train/logprobs = tensor([[-0.4597, -3.5451],
        [-1.3308, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045151948928833
Epoch 0, Step 1502: train/loss = 0.3143630027770996, train/raw-loss = 0.2278163582086563, train/logprobs = tensor([[-0.7412, -5.1848],
        [-1.1533, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08654666692018509
Epoch 0, Step 1503: train/loss = 0.518275797367096, train/raw-loss = 0.4388948678970337, train/logprobs = tensor([[-0.8782, -2.7140],
        [-1.1880, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938098907470703
Epoch 0, Step 1504: train/loss = 0.4515955150127411, train/raw-loss = 0.38602274656295776, train/logprobs = tensor([[-0.4474, -3.4530],
        [-0.7363, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06557279825210571
Epoch 0, Step 1505: train/loss = 0.39492669701576233, train/raw-loss = 0.32915008068084717, train/logprobs = tensor([[-0.5841, -3.8350],
        [-0.9767, -0.4870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577663868665695
Epoch 0, Step 1506: train/loss = 0.3595786392688751, train/raw-loss = 0.28431376814842224, train/logprobs = tensor([[-0.5785, -3.6004],
        [-1.0555, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07526489347219467
Epoch 0, Step 1507: train/loss = 0.4993433654308319, train/raw-loss = 0.41821378469467163, train/logprobs = tensor([[-0.4154, -2.2262],
        [-0.6537, -0.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08112961053848267
Epoch 0, Step 1508: train/loss = 0.5648756623268127, train/raw-loss = 0.47743505239486694, train/logprobs = tensor([[-0.8149, -2.7471],
        [-1.0649, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.087440624833107
Epoch 0, Step 1509: train/loss = 0.5599138736724854, train/raw-loss = 0.4980151951313019, train/logprobs = tensor([[-0.8293, -1.7018],
        [-1.0465, -0.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06189871206879616
Epoch 0, Step 1510: train/loss = 0.4635094404220581, train/raw-loss = 0.387873113155365, train/logprobs = tensor([[-0.4213, -4.5169],
        [-0.6945, -0.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07563632726669312
Epoch 0, Step 1511: train/loss = 0.3997303247451782, train/raw-loss = 0.33728599548339844, train/logprobs = tensor([[-0.7093, -4.7216],
        [-0.9170, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062444306910037994
Epoch 0, Step 1512: train/loss = 0.49230435490608215, train/raw-loss = 0.4165129065513611, train/logprobs = tensor([[-0.5447, -1.9797],
        [-0.8362, -0.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07579144090414047
Epoch 0, Step 1513: train/loss = 0.4186132550239563, train/raw-loss = 0.34150874614715576, train/logprobs = tensor([[-0.4810, -3.1227],
        [-0.8570, -0.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07710452377796173
Epoch 0, Step 1514: train/loss = 0.5388193130493164, train/raw-loss = 0.46561765670776367, train/logprobs = tensor([[-1.1026, -6.4352],
        [-1.0063, -1.3687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07320163398981094
Epoch 0, Step 1515: train/loss = 0.3818757236003876, train/raw-loss = 0.3081408739089966, train/logprobs = tensor([[-0.7002, -3.2075],
        [-1.1945, -0.6080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07373486459255219
Epoch 0, Step 1516: train/loss = 0.6687766313552856, train/raw-loss = 0.6244109869003296, train/logprobs = tensor([[-0.4978, -0.6576],
        [-0.6328, -0.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04436570405960083
Epoch 0, Step 1517: train/loss = 0.3702571392059326, train/raw-loss = 0.2970162034034729, train/logprobs = tensor([[-0.7470, -9.6241],
        [-1.2011, -1.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07324089109897614
Epoch 0, Step 1518: train/loss = 0.6174683570861816, train/raw-loss = 0.5497145056724548, train/logprobs = tensor([[-1.2652, -2.8261],
        [-0.9149, -0.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06775381416082382
Epoch 0, Step 1519: train/loss = 0.5762494206428528, train/raw-loss = 0.5156135559082031, train/logprobs = tensor([[-0.5369, -2.0294],
        [-0.7877, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06063584238290787
Epoch 0, Step 1520: train/loss = 0.31482982635498047, train/raw-loss = 0.22736968100070953, train/logprobs = tensor([[-0.5591, -6.6202],
        [-1.3843, -1.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08746014535427094
Epoch 0, Step 1521: train/loss = 0.5742926597595215, train/raw-loss = 0.5081606507301331, train/logprobs = tensor([[-0.9463, -1.8251],
        [-1.0038, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0661320611834526
Epoch 0, Step 1522: train/loss = 0.4734511375427246, train/raw-loss = 0.4241822361946106, train/logprobs = tensor([[-1.4922, -8.3275],
        [-1.2809, -1.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04926889389753342
Epoch 0, Step 1523: train/loss = 0.334073930978775, train/raw-loss = 0.25627487897872925, train/logprobs = tensor([[-0.7622, -4.5891],
        [-1.5240, -1.2314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07779904454946518
Epoch 0, Step 1524: train/loss = 0.452963650226593, train/raw-loss = 0.373893678188324, train/logprobs = tensor([[-0.6926, -2.5718],
        [-0.9463, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906996458768845
Epoch 0, Step 1525: train/loss = 0.7049185633659363, train/raw-loss = 0.6353120803833008, train/logprobs = tensor([[-0.5096, -0.5822],
        [-0.7923, -0.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06960659474134445
Epoch 0, Step 1526: train/loss = 0.5145495533943176, train/raw-loss = 0.4616051912307739, train/logprobs = tensor([[-0.5053, -2.4827],
        [-0.7463, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0529443696141243
Epoch 0, Step 1527: train/loss = 0.589525580406189, train/raw-loss = 0.5100055932998657, train/logprobs = tensor([[-1.0035, -1.6477],
        [-0.8835, -0.5403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07951998710632324
Epoch 0, Step 1528: train/loss = 0.31645435094833374, train/raw-loss = 0.23684823513031006, train/logprobs = tensor([[-0.4536, -3.9598],
        [-1.0743, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07960613816976547
Epoch 0, Step 1529: train/loss = 0.5048296451568604, train/raw-loss = 0.41088658571243286, train/logprobs = tensor([[-0.5743, -2.4504],
        [-1.1932, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09394305944442749
Epoch 0, Step 1530: train/loss = 0.38861584663391113, train/raw-loss = 0.31476491689682007, train/logprobs = tensor([[-0.5949, -3.9526],
        [-1.1284, -0.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07385091483592987
Epoch 0, Step 1531: train/loss = 0.5106919407844543, train/raw-loss = 0.439746618270874, train/logprobs = tensor([[-0.5542, -3.7801],
        [-0.8241, -0.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094533741474152
Epoch 0, Step 1532: train/loss = 0.5873889923095703, train/raw-loss = 0.5196025371551514, train/logprobs = tensor([[-0.6452, -2.9876],
        [-0.6867, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06778639554977417
Epoch 0, Step 1533: train/loss = 0.44418466091156006, train/raw-loss = 0.38823550939559937, train/logprobs = tensor([[-0.3462, -2.4425],
        [-0.6626, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05594915524125099
Epoch 0, Step 1534: train/loss = 0.46152281761169434, train/raw-loss = 0.38740748167037964, train/logprobs = tensor([[-0.8620, -4.1753],
        [-1.0237, -0.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07411535084247589
Epoch 0, Step 1535: train/loss = 0.5236523747444153, train/raw-loss = 0.44536519050598145, train/logprobs = tensor([[-0.5441, -1.5617],
        [-0.9790, -0.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07828722894191742
Epoch 0, Step 1536: train/loss = 0.4270678162574768, train/raw-loss = 0.35469505190849304, train/logprobs = tensor([[-0.4699, -4.4558],
        [-0.7083, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07237276434898376
Epoch 0, Step 1537: train/loss = 0.5159194469451904, train/raw-loss = 0.44739457964897156, train/logprobs = tensor([[-0.9630, -2.2573],
        [-0.8943, -0.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06852483004331589
Epoch 0, Step 1538: train/loss = 0.4634239971637726, train/raw-loss = 0.40320974588394165, train/logprobs = tensor([[-0.5422, -5.5081],
        [-0.9488, -1.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06021428108215332
Epoch 0, Step 1539: train/loss = 0.5859260559082031, train/raw-loss = 0.5148336887359619, train/logprobs = tensor([[-0.5468, -1.6420],
        [-0.6702, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109237462282181
Epoch 0, Step 1540: train/loss = 0.4720601737499237, train/raw-loss = 0.3931436538696289, train/logprobs = tensor([[-0.8105, -3.6891],
        [-1.1217, -0.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0789165124297142
Epoch 0, Step 1541: train/loss = 0.29715999960899353, train/raw-loss = 0.2175133228302002, train/logprobs = tensor([[-0.5659, -7.8646],
        [-1.0881, -1.3139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07964669167995453
Epoch 0, Step 1542: train/loss = 0.7073230147361755, train/raw-loss = 0.6501127481460571, train/logprobs = tensor([[-0.6943, -0.6730],
        [-0.6626, -0.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057210296392440796
Epoch 0, Step 1543: train/loss = 0.5159924626350403, train/raw-loss = 0.44943559169769287, train/logprobs = tensor([[-0.4771, -2.0545],
        [-0.9251, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06655685603618622
Epoch 0, Step 1544: train/loss = 0.4270879030227661, train/raw-loss = 0.337094247341156, train/logprobs = tensor([[-0.6389, -4.0653],
        [-1.3709, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08999364823102951
Epoch 0, Step 1545: train/loss = 0.48388218879699707, train/raw-loss = 0.4097559452056885, train/logprobs = tensor([[-0.8913, -2.7209],
        [-0.9529, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741262286901474
Epoch 0, Step 1546: train/loss = 0.5154446363449097, train/raw-loss = 0.44715893268585205, train/logprobs = tensor([[-0.5766, -2.1933],
        [-0.8036, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06828576326370239
Epoch 0, Step 1547: train/loss = 0.5719042420387268, train/raw-loss = 0.5044190883636475, train/logprobs = tensor([[-0.6198, -2.2172],
        [-0.8352, -0.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06748518347740173
Epoch 0, Step 1548: train/loss = 0.46618351340293884, train/raw-loss = 0.4068988263607025, train/logprobs = tensor([[-0.3908, -4.2638],
        [-0.5784, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05928467959165573
Epoch 0, Step 1549: train/loss = 0.5272927284240723, train/raw-loss = 0.4666854739189148, train/logprobs = tensor([[-0.3827, -2.1122],
        [-0.7331, -0.4773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060607269406318665
Epoch 0, Step 1550: train/loss = 0.5667197704315186, train/raw-loss = 0.505742609500885, train/logprobs = tensor([[-0.6358, -1.5952],
        [-0.7658, -0.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060977108776569366
Epoch 0, Step 1551: train/loss = 0.3576119840145111, train/raw-loss = 0.27818232774734497, train/logprobs = tensor([[-0.5905, -3.7717],
        [-0.9556, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07942964136600494
Epoch 0, Step 1552: train/loss = 0.38540786504745483, train/raw-loss = 0.31326520442962646, train/logprobs = tensor([[-0.5937, -7.1242],
        [-1.1408, -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07214267551898956
Epoch 0, Step 1553: train/loss = 0.4294537901878357, train/raw-loss = 0.35029739141464233, train/logprobs = tensor([[-0.7165, -3.3713],
        [-0.9219, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07915640622377396
Epoch 0, Step 1554: train/loss = 0.5777139663696289, train/raw-loss = 0.5111688375473022, train/logprobs = tensor([[-0.6676, -1.7396],
        [-0.8741, -0.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06654515862464905
Epoch 0, Step 1555: train/loss = 0.43234163522720337, train/raw-loss = 0.3647315502166748, train/logprobs = tensor([[-0.8145, -3.3158],
        [-1.0083, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06761007755994797
Epoch 0, Step 1556: train/loss = 0.49270957708358765, train/raw-loss = 0.4339469373226166, train/logprobs = tensor([[-0.4719, -6.5048],
        [-0.6924, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058762628585100174
Epoch 0, Step 1557: train/loss = 0.42128029465675354, train/raw-loss = 0.3598320186138153, train/logprobs = tensor([[-0.5331, -4.6462],
        [-0.6724, -0.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06144832447171211
Epoch 0, Step 1558: train/loss = 0.3821071982383728, train/raw-loss = 0.31331390142440796, train/logprobs = tensor([[-0.5472, -6.5711],
        [-0.9654, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06879330426454544
Epoch 0, Step 1559: train/loss = 0.5322888493537903, train/raw-loss = 0.4571502208709717, train/logprobs = tensor([[-1.0041, -2.6933],
        [-1.3359, -0.5723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751386284828186
Epoch 0, Step 1560: train/loss = 0.3806799352169037, train/raw-loss = 0.31410545110702515, train/logprobs = tensor([[-0.6144, -3.9968],
        [-0.8767, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06657449901103973
Epoch 0, Step 1561: train/loss = 0.3593679666519165, train/raw-loss = 0.2534831464290619, train/logprobs = tensor([[-0.8430, -3.3457],
        [-1.6001, -0.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.105884850025177
Epoch 0, Step 1562: train/loss = 0.5767136812210083, train/raw-loss = 0.5050933957099915, train/logprobs = tensor([[-1.9303, -6.8979],
        [-1.3222, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07162027060985565
Epoch 0, Step 1563: train/loss = 0.6005238890647888, train/raw-loss = 0.5190178155899048, train/logprobs = tensor([[-0.6957, -1.2560],
        [-1.0198, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08150610327720642
Epoch 0, Step 1564: train/loss = 0.41258475184440613, train/raw-loss = 0.33984100818634033, train/logprobs = tensor([[-0.6431, -3.9492],
        [-1.2429, -0.9585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07274375110864639
Epoch 0, Step 1565: train/loss = 0.6320783495903015, train/raw-loss = 0.5628135800361633, train/logprobs = tensor([[-0.9057, -1.4890],
        [-0.8893, -0.5550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06926479935646057
Epoch 0, Step 1566: train/loss = 0.35980236530303955, train/raw-loss = 0.27377066016197205, train/logprobs = tensor([[-0.5726, -4.3838],
        [-1.1291, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0860317200422287
Epoch 0, Step 1567: train/loss = 0.6089282035827637, train/raw-loss = 0.5517210364341736, train/logprobs = tensor([[-0.4411, -2.4300],
        [-0.6895, -0.4967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05720718204975128
Epoch 0, Step 1568: train/loss = 0.47906965017318726, train/raw-loss = 0.40943366289138794, train/logprobs = tensor([[-1.2161, -5.8408],
        [-1.0387, -1.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06963595747947693
Epoch 0, Step 1569: train/loss = 0.5619765520095825, train/raw-loss = 0.4895409345626831, train/logprobs = tensor([[-0.9051, -2.0333],
        [-0.7828, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07243563234806061
Epoch 0, Step 1570: train/loss = 0.5414978265762329, train/raw-loss = 0.48203545808792114, train/logprobs = tensor([[-0.5446, -2.5415],
        [-0.7297, -0.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05946231633424759
Epoch 0, Step 1571: train/loss = 0.5516687631607056, train/raw-loss = 0.49057894945144653, train/logprobs = tensor([[-0.5451, -1.4173],
        [-0.7964, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061089806258678436
Epoch 0, Step 1572: train/loss = 0.4094212055206299, train/raw-loss = 0.3305816352367401, train/logprobs = tensor([[-0.5781, -3.1401],
        [-0.9870, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883957773447037
Epoch 0, Step 1573: train/loss = 0.3931141495704651, train/raw-loss = 0.3331878185272217, train/logprobs = tensor([[-0.8385, -4.9887],
        [-1.2957, -0.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05992632359266281
Epoch 0, Step 1574: train/loss = 0.444661945104599, train/raw-loss = 0.3703584671020508, train/logprobs = tensor([[-0.4992, -2.7170],
        [-0.9974, -0.9034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743035152554512
Epoch 0, Step 1575: train/loss = 0.46529412269592285, train/raw-loss = 0.3903432786464691, train/logprobs = tensor([[-0.7153, -3.0077],
        [-1.0615, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07495085150003433
Epoch 0, Step 1576: train/loss = 0.7085888385772705, train/raw-loss = 0.6645299196243286, train/logprobs = tensor([[-0.4215, -0.5212],
        [-0.4681, -0.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04405882954597473
Epoch 0, Step 1577: train/loss = 0.6338576674461365, train/raw-loss = 0.5588194727897644, train/logprobs = tensor([[-0.6163, -0.9650],
        [-0.8653, -0.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07503822445869446
Epoch 0, Step 1578: train/loss = 0.4369507133960724, train/raw-loss = 0.3724234700202942, train/logprobs = tensor([[-1.1691, -8.1718],
        [-0.8906, -1.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.064527228474617
Epoch 0, Step 1579: train/loss = 0.44623124599456787, train/raw-loss = 0.3721054792404175, train/logprobs = tensor([[-0.4736, -4.0049],
        [-0.9432, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741257444024086
Epoch 0, Step 1580: train/loss = 0.4571414887905121, train/raw-loss = 0.3921266198158264, train/logprobs = tensor([[-0.4711, -2.1935],
        [-0.7593, -0.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06501486897468567
Epoch 0, Step 1581: train/loss = 0.33189839124679565, train/raw-loss = 0.24461959302425385, train/logprobs = tensor([[-0.6890, -2.4866],
        [-1.6731, -0.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0872788280248642
Epoch 0, Step 1582: train/loss = 0.31369107961654663, train/raw-loss = 0.24897295236587524, train/logprobs = tensor([[-0.7317, -6.6099],
        [-1.3848, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06471813470125198
Epoch 0, Step 1583: train/loss = 0.4447077512741089, train/raw-loss = 0.3651955723762512, train/logprobs = tensor([[-0.6584, -5.6774],
        [-1.5229, -1.3752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07951217144727707
Epoch 0, Step 1584: train/loss = 0.3596978187561035, train/raw-loss = 0.28686466813087463, train/logprobs = tensor([[-0.7874, -4.3969],
        [-1.0547, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07283314317464828
Epoch 0, Step 1585: train/loss = 0.4011662006378174, train/raw-loss = 0.31219619512557983, train/logprobs = tensor([[-0.6270, -2.7613],
        [-0.9478, -0.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08896997570991516
Epoch 0, Step 1586: train/loss = 0.418374240398407, train/raw-loss = 0.33646920323371887, train/logprobs = tensor([[-0.6110, -4.7395],
        [-0.9420, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819050520658493
Epoch 0, Step 1587: train/loss = 0.3632989525794983, train/raw-loss = 0.2733173370361328, train/logprobs = tensor([[-0.7565, -3.3923],
        [-1.0849, -0.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08998163789510727
Epoch 0, Step 1588: train/loss = 0.43767696619033813, train/raw-loss = 0.3806714415550232, train/logprobs = tensor([[-0.5415, -3.4094],
        [-0.7670, -0.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05700547620654106
Epoch 0, Step 1589: train/loss = 0.47115910053253174, train/raw-loss = 0.411283016204834, train/logprobs = tensor([[-0.6149, -3.8709],
        [-0.7625, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05987607687711716
Epoch 0, Step 1590: train/loss = 0.4497273564338684, train/raw-loss = 0.39118972420692444, train/logprobs = tensor([[-0.5021, -4.7085],
        [-0.5785, -0.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05853762477636337
Epoch 0, Step 1591: train/loss = 0.4188768267631531, train/raw-loss = 0.3290010988712311, train/logprobs = tensor([[-0.5513, -4.8622],
        [-1.0417, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987574279308319
Epoch 0, Step 1592: train/loss = 0.4552413523197174, train/raw-loss = 0.3782745599746704, train/logprobs = tensor([[-0.5449, -2.5466],
        [-0.7985, -0.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.076966792345047
Epoch 0, Step 1593: train/loss = 0.42483216524124146, train/raw-loss = 0.3533875346183777, train/logprobs = tensor([[-0.6853, -4.9842],
        [-0.9371, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07144464552402496
Epoch 0, Step 1594: train/loss = 0.39756280183792114, train/raw-loss = 0.311435729265213, train/logprobs = tensor([[-0.5802, -3.1168],
        [-1.0606, -0.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08612711727619171
Epoch 0, Step 1595: train/loss = 0.43440359830856323, train/raw-loss = 0.3610405921936035, train/logprobs = tensor([[-0.5740, -2.8758],
        [-0.7610, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336297631263733
Epoch 0, Step 1596: train/loss = 0.4514918029308319, train/raw-loss = 0.35856935381889343, train/logprobs = tensor([[-0.5846, -7.3381],
        [-1.1493, -1.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09292243421077728
Epoch 0, Step 1597: train/loss = 0.40103352069854736, train/raw-loss = 0.3298631012439728, train/logprobs = tensor([[-0.7011, -4.2800],
        [-1.2676, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07117041200399399
Epoch 0, Step 1598: train/loss = 0.46718087792396545, train/raw-loss = 0.4026950001716614, train/logprobs = tensor([[-0.8404, -6.4490],
        [-0.9881, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448587775230408
Epoch 0, Step 1599: train/loss = 0.3163940906524658, train/raw-loss = 0.2370687872171402, train/logprobs = tensor([[-0.5065, -7.0795],
        [-1.0626, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07932531088590622
Epoch 0, Step 1600: train/loss = 0.4267824590206146, train/raw-loss = 0.35926711559295654, train/logprobs = tensor([[-0.8876, -4.8513],
        [-0.8352, -0.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06751532852649689
Epoch 0, Step 1601: train/loss = 0.27975228428840637, train/raw-loss = 0.1972494125366211, train/logprobs = tensor([[ -0.5029, -10.0963],
        [ -1.0454,  -1.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08250286430120468
Epoch 0, Step 1602: train/loss = 0.4097621440887451, train/raw-loss = 0.32884645462036133, train/logprobs = tensor([[-0.4461, -3.4539],
        [-0.7715, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08091569691896439
Epoch 0, Step 1603: train/loss = 0.49318423867225647, train/raw-loss = 0.42421314120292664, train/logprobs = tensor([[-0.4564, -2.1284],
        [-0.7721, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06897107511758804
Epoch 0, Step 1604: train/loss = 0.382276713848114, train/raw-loss = 0.3141292631626129, train/logprobs = tensor([[-0.5141, -5.5580],
        [-0.7092, -1.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0681474581360817
Epoch 0, Step 1605: train/loss = 0.5407320261001587, train/raw-loss = 0.4601374864578247, train/logprobs = tensor([[-0.6287, -2.8148],
        [-0.7223, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08059454709291458
Epoch 0, Step 1606: train/loss = 0.29086220264434814, train/raw-loss = 0.22417548298835754, train/logprobs = tensor([[-0.5061, -6.4636],
        [-1.0076, -1.3980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0666867271065712
Epoch 0, Step 1607: train/loss = 0.4305093288421631, train/raw-loss = 0.3622991442680359, train/logprobs = tensor([[-0.5820, -2.7311],
        [-0.8601, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821020692586899
Epoch 0, Step 1608: train/loss = 0.44134509563446045, train/raw-loss = 0.3668917417526245, train/logprobs = tensor([[-0.7049, -5.8254],
        [-0.7899, -1.1669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07445338368415833
Epoch 0, Step 1609: train/loss = 0.4831905663013458, train/raw-loss = 0.41388195753097534, train/logprobs = tensor([[-0.8513, -6.5453],
        [-0.7677, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06930864602327347
Epoch 0, Step 1610: train/loss = 0.567080557346344, train/raw-loss = 0.4965780973434448, train/logprobs = tensor([[-0.7937, -2.9307],
        [-0.7660, -0.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07050247490406036
Epoch 0, Step 1611: train/loss = 0.4792064428329468, train/raw-loss = 0.40978750586509705, train/logprobs = tensor([[-0.6171, -1.6067],
        [-1.1833, -0.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06941890716552734
Epoch 0, Step 1612: train/loss = 0.3600049316883087, train/raw-loss = 0.27851712703704834, train/logprobs = tensor([[-0.7042, -4.5537],
        [-1.3685, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08148778229951859
Epoch 0, Step 1613: train/loss = 0.6515190005302429, train/raw-loss = 0.5929378867149353, train/logprobs = tensor([[-0.4808, -0.8594],
        [-0.6052, -0.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058581117540597916
Epoch 0, Step 1614: train/loss = 0.4809432625770569, train/raw-loss = 0.3874204754829407, train/logprobs = tensor([[-1.4466, -6.0640],
        [-1.3389, -1.3028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935228168964386
Epoch 0, Step 1615: train/loss = 0.37815552949905396, train/raw-loss = 0.3122978210449219, train/logprobs = tensor([[-0.3766, -5.0935],
        [-0.6249, -1.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06585775315761566
Epoch 0, Step 1616: train/loss = 0.47130975127220154, train/raw-loss = 0.4017590880393982, train/logprobs = tensor([[-0.6487, -4.2355],
        [-1.1666, -1.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06955070793628693
Epoch 0, Step 1617: train/loss = 0.4999135434627533, train/raw-loss = 0.4472576677799225, train/logprobs = tensor([[-0.5308, -3.0308],
        [-0.6992, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05265587195754051
Epoch 0, Step 1618: train/loss = 0.49724990129470825, train/raw-loss = 0.4342401921749115, train/logprobs = tensor([[-0.4351, -1.8717],
        [-0.8245, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06300970911979675
Epoch 0, Step 1619: train/loss = 0.3753913342952728, train/raw-loss = 0.30745017528533936, train/logprobs = tensor([[-0.5957, -4.6285],
        [-0.8138, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06794118136167526
Epoch 0, Step 1620: train/loss = 0.47519126534461975, train/raw-loss = 0.4038907587528229, train/logprobs = tensor([[-0.5466, -2.5735],
        [-0.8633, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07130052149295807
Epoch 0, Step 1621: train/loss = 0.4563971161842346, train/raw-loss = 0.3820272982120514, train/logprobs = tensor([[-0.6515, -2.5769],
        [-0.9204, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07436982542276382
Epoch 0, Step 1622: train/loss = 0.36602672934532166, train/raw-loss = 0.29336169362068176, train/logprobs = tensor([[-0.7961, -6.1587],
        [-1.2516, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07266504317522049
Epoch 0, Step 1623: train/loss = 0.5175975561141968, train/raw-loss = 0.4429587423801422, train/logprobs = tensor([[-0.4771, -2.0358],
        [-0.7688, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07463883608579636
Epoch 0, Step 1624: train/loss = 0.36941832304000854, train/raw-loss = 0.3123752474784851, train/logprobs = tensor([[-0.5149, -3.0004],
        [-0.9946, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05704308673739433
Epoch 0, Step 1625: train/loss = 0.4044696092605591, train/raw-loss = 0.31092551350593567, train/logprobs = tensor([[-0.5690, -3.7639],
        [-1.0589, -0.5869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09354408085346222
Epoch 0, Step 1626: train/loss = 0.5575099587440491, train/raw-loss = 0.4974532425403595, train/logprobs = tensor([[-0.9522, -1.4687],
        [-1.1189, -0.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06005670875310898
Epoch 0, Step 1627: train/loss = 0.5113859176635742, train/raw-loss = 0.44222843647003174, train/logprobs = tensor([[-0.9783, -2.7961],
        [-0.8882, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915747374296188
Epoch 0, Step 1628: train/loss = 0.39580440521240234, train/raw-loss = 0.3378409445285797, train/logprobs = tensor([[-0.5605, -4.9492],
        [-0.6926, -0.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05796346068382263
Epoch 0, Step 1629: train/loss = 0.5386401414871216, train/raw-loss = 0.4763191342353821, train/logprobs = tensor([[-0.6535, -2.4205],
        [-0.6999, -0.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06232102960348129
Epoch 0, Step 1630: train/loss = 0.5322571992874146, train/raw-loss = 0.4651377201080322, train/logprobs = tensor([[-0.5499, -1.4004],
        [-1.0668, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06711950153112411
Epoch 0, Step 1631: train/loss = 0.3260743021965027, train/raw-loss = 0.25840383768081665, train/logprobs = tensor([[-0.4422, -6.5916],
        [-0.6928, -0.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06767045706510544
Epoch 0, Step 1632: train/loss = 0.42916640639305115, train/raw-loss = 0.353700190782547, train/logprobs = tensor([[-0.6576, -6.5578],
        [-0.8856, -1.1181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07546619325876236
Epoch 0, Step 1633: train/loss = 0.4692709445953369, train/raw-loss = 0.40598511695861816, train/logprobs = tensor([[-0.8097, -3.9041],
        [-1.1629, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06328583508729935
Epoch 0, Step 1634: train/loss = 0.5094574093818665, train/raw-loss = 0.42079225182533264, train/logprobs = tensor([[-0.7463, -2.4079],
        [-1.0634, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08866516500711441
Epoch 0, Step 1635: train/loss = 0.40904343128204346, train/raw-loss = 0.31984758377075195, train/logprobs = tensor([[-0.5028, -5.5390],
        [-1.2775, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08919581025838852
Epoch 0, Step 1636: train/loss = 0.43308225274086, train/raw-loss = 0.3519549071788788, train/logprobs = tensor([[-0.4118, -4.1564],
        [-0.8332, -0.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08112733066082001
Epoch 0, Step 1637: train/loss = 0.4156622886657715, train/raw-loss = 0.34138599038124084, train/logprobs = tensor([[-0.6219, -6.6477],
        [-1.3043, -1.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07427628338336945
Epoch 0, Step 1638: train/loss = 0.40371501445770264, train/raw-loss = 0.32761937379837036, train/logprobs = tensor([[-0.5171, -5.9550],
        [-1.0872, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07609565556049347
Epoch 0, Step 1639: train/loss = 0.5110347270965576, train/raw-loss = 0.4430003762245178, train/logprobs = tensor([[-0.6479, -5.7281],
        [-0.6198, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.068034328520298
Epoch 0, Step 1640: train/loss = 0.39721861481666565, train/raw-loss = 0.3169730007648468, train/logprobs = tensor([[-0.4433, -4.6733],
        [-0.8410, -0.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08024562150239944
Epoch 0, Step 1641: train/loss = 0.3904991149902344, train/raw-loss = 0.3281748294830322, train/logprobs = tensor([[-0.3416, -5.4804],
        [-0.9304, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06232428178191185
Epoch 0, Step 1642: train/loss = 0.38291120529174805, train/raw-loss = 0.30241817235946655, train/logprobs = tensor([[-0.6743, -5.3011],
        [-1.0999, -1.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08049304038286209
Epoch 0, Step 1643: train/loss = 0.4881052076816559, train/raw-loss = 0.4224117398262024, train/logprobs = tensor([[-1.0067, -6.2094],
        [-1.0142, -1.1560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06569346785545349
Epoch 0, Step 1644: train/loss = 0.4676383435726166, train/raw-loss = 0.38497960567474365, train/logprobs = tensor([[-0.8500, -3.4060],
        [-1.0708, -0.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08265875279903412
Epoch 0, Step 1645: train/loss = 0.2811104357242584, train/raw-loss = 0.1997101902961731, train/logprobs = tensor([[-0.5109, -8.8300],
        [-1.1092, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140026032924652
Epoch 0, Step 1646: train/loss = 0.6029496192932129, train/raw-loss = 0.5278667211532593, train/logprobs = tensor([[-0.6972, -1.7543],
        [-0.6871, -0.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0750829428434372
Epoch 0, Step 1647: train/loss = 0.47016364336013794, train/raw-loss = 0.4031292200088501, train/logprobs = tensor([[-0.4902, -2.0784],
        [-0.7756, -0.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06703444570302963
Epoch 0, Step 1648: train/loss = 0.4876677393913269, train/raw-loss = 0.4238780438899994, train/logprobs = tensor([[-0.4475, -1.9675],
        [-0.8905, -0.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0637897253036499
Epoch 0, Step 1649: train/loss = 0.43903449177742004, train/raw-loss = 0.3804657459259033, train/logprobs = tensor([[-0.5318, -5.2981],
        [-1.0365, -1.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05856873840093613
Epoch 0, Step 1650: train/loss = 0.42084962129592896, train/raw-loss = 0.36108970642089844, train/logprobs = tensor([[-0.4596, -3.5743],
        [-0.6979, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05975991114974022
Epoch 0, Step 1651: train/loss = 0.3771474063396454, train/raw-loss = 0.3062191307544708, train/logprobs = tensor([[-0.5452, -3.0600],
        [-1.0195, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07092825323343277
Epoch 0, Step 1652: train/loss = 0.6028968691825867, train/raw-loss = 0.5452021360397339, train/logprobs = tensor([[-0.4380, -3.0284],
        [-0.6747, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05769471824169159
Epoch 0, Step 1653: train/loss = 0.41318321228027344, train/raw-loss = 0.3306099772453308, train/logprobs = tensor([[-0.4087, -3.1756],
        [-0.8520, -0.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08257325738668442
Epoch 0, Step 1654: train/loss = 0.508246660232544, train/raw-loss = 0.44199514389038086, train/logprobs = tensor([[-0.8052, -5.4601],
        [-0.9425, -1.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06625153124332428
Epoch 0, Step 1655: train/loss = 0.38612058758735657, train/raw-loss = 0.31412726640701294, train/logprobs = tensor([[-0.4726, -7.0304],
        [-0.7667, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07199329137802124
Epoch 0, Step 1656: train/loss = 0.424028217792511, train/raw-loss = 0.3509630858898163, train/logprobs = tensor([[-0.4856, -2.1560],
        [-1.1115, -0.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07306510210037231
Epoch 0, Step 1657: train/loss = 0.5093539357185364, train/raw-loss = 0.4231584668159485, train/logprobs = tensor([[-0.7021, -1.5726],
        [-1.5193, -0.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08619546890258789
Epoch 0, Step 1658: train/loss = 0.5490095615386963, train/raw-loss = 0.48704996705055237, train/logprobs = tensor([[-0.7663, -2.9577],
        [-0.9752, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06195959076285362
Epoch 0, Step 1659: train/loss = 0.431079626083374, train/raw-loss = 0.34724587202072144, train/logprobs = tensor([[-0.6733, -2.6710],
        [-1.2171, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383369445800781
Epoch 0, Step 1660: train/loss = 0.3906826376914978, train/raw-loss = 0.3193221986293793, train/logprobs = tensor([[-0.7757, -5.2253],
        [-1.0181, -0.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07136043161153793
Epoch 0, Step 1661: train/loss = 0.6489740014076233, train/raw-loss = 0.5923713445663452, train/logprobs = tensor([[-0.7265, -1.3273],
        [-0.6932, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0566025972366333
Epoch 0, Step 1662: train/loss = 0.3889634907245636, train/raw-loss = 0.3089102804660797, train/logprobs = tensor([[-0.7251, -6.8709],
        [-1.0566, -1.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08005319535732269
Epoch 0, Step 1663: train/loss = 0.4611712098121643, train/raw-loss = 0.4005131721496582, train/logprobs = tensor([[-0.7995, -1.9524],
        [-1.1827, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06065806373953819
Epoch 0, Step 1664: train/loss = 0.5411574244499207, train/raw-loss = 0.4542189836502075, train/logprobs = tensor([[-0.5058, -1.2895],
        [-0.9993, -0.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693850785493851
Epoch 0, Step 1665: train/loss = 0.4966207444667816, train/raw-loss = 0.40735724568367004, train/logprobs = tensor([[-1.1977, -3.4194],
        [-1.0569, -0.6192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08926348388195038
Epoch 0, Step 1666: train/loss = 0.5215582847595215, train/raw-loss = 0.46266767382621765, train/logprobs = tensor([[-0.6422, -2.0788],
        [-0.8338, -0.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058890558779239655
Epoch 0, Step 1667: train/loss = 0.3674162030220032, train/raw-loss = 0.31069278717041016, train/logprobs = tensor([[-0.4292, -4.8833],
        [-0.7188, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05672342702746391
Epoch 0, Step 1668: train/loss = 0.5690004229545593, train/raw-loss = 0.5242206454277039, train/logprobs = tensor([[-0.5005, -2.1672],
        [-0.3817, -0.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04477982223033905
Epoch 0, Step 1669: train/loss = 0.3161379098892212, train/raw-loss = 0.23278623819351196, train/logprobs = tensor([[-0.5744, -5.4105],
        [-0.9809, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08335164934396744
Epoch 0, Step 1670: train/loss = 0.2678893804550171, train/raw-loss = 0.1889296919107437, train/logprobs = tensor([[-0.6170, -5.6890],
        [-1.4566, -0.8735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07895968109369278
Epoch 0, Step 1671: train/loss = 0.4790441393852234, train/raw-loss = 0.41599053144454956, train/logprobs = tensor([[-1.4990, -4.1921],
        [-1.3172, -0.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06305358558893204
Epoch 0, Step 1672: train/loss = 0.5060330033302307, train/raw-loss = 0.42538514733314514, train/logprobs = tensor([[-0.8705, -2.7107],
        [-1.0685, -0.6136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08064784854650497
Epoch 0, Step 1673: train/loss = 0.42004716396331787, train/raw-loss = 0.35589563846588135, train/logprobs = tensor([[-0.4798, -2.9064],
        [-0.7576, -0.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06415154784917831
Epoch 0, Step 1674: train/loss = 0.4692337214946747, train/raw-loss = 0.4149782061576843, train/logprobs = tensor([[-0.6463, -3.5414],
        [-0.6392, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054255545139312744
Epoch 0, Step 1675: train/loss = 0.5228986740112305, train/raw-loss = 0.4534059762954712, train/logprobs = tensor([[-1.5551, -5.2136],
        [-1.0901, -1.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06949266046285629
Epoch 0, Step 1676: train/loss = 0.458951473236084, train/raw-loss = 0.35602685809135437, train/logprobs = tensor([[-0.8900, -3.7805],
        [-1.4334, -0.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10292460769414902
Epoch 0, Step 1677: train/loss = 0.40210628509521484, train/raw-loss = 0.3485349714756012, train/logprobs = tensor([[-0.6934, -4.1237],
        [-1.1485, -1.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053571321070194244
Epoch 0, Step 1678: train/loss = 0.4285193085670471, train/raw-loss = 0.3523571491241455, train/logprobs = tensor([[-0.6244, -2.7311],
        [-1.1124, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.076162189245224
Epoch 0, Step 1679: train/loss = 0.509157121181488, train/raw-loss = 0.4342283308506012, train/logprobs = tensor([[-0.5903, -2.2553],
        [-1.0190, -0.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07492877542972565
Epoch 0, Step 1680: train/loss = 0.5248044729232788, train/raw-loss = 0.4551723599433899, train/logprobs = tensor([[-0.5212, -1.8871],
        [-0.7959, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0696321427822113
Epoch 0, Step 1681: train/loss = 0.4046383500099182, train/raw-loss = 0.3446008265018463, train/logprobs = tensor([[-0.7446, -9.1521],
        [-1.0044, -1.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06003754585981369
Epoch 0, Step 1682: train/loss = 0.49158531427383423, train/raw-loss = 0.42243194580078125, train/logprobs = tensor([[-0.5297, -3.8093],
        [-0.9119, -0.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915338337421417
Epoch 0, Step 1683: train/loss = 0.46433696150779724, train/raw-loss = 0.3862242102622986, train/logprobs = tensor([[-1.0339, -2.8861],
        [-1.2494, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07811274379491806
Epoch 0, Step 1684: train/loss = 0.6025004386901855, train/raw-loss = 0.5465368032455444, train/logprobs = tensor([[-0.5497, -1.1517],
        [-0.6500, -0.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05596357583999634
Epoch 0, Step 1685: train/loss = 0.49962297081947327, train/raw-loss = 0.4297233819961548, train/logprobs = tensor([[-0.5990, -2.3059],
        [-0.8001, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0698995441198349
Epoch 0, Step 1686: train/loss = 0.3837140202522278, train/raw-loss = 0.31754618883132935, train/logprobs = tensor([[-0.6847, -7.4569],
        [-0.9130, -1.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06616782397031784
Epoch 0, Step 1687: train/loss = 0.4410630166530609, train/raw-loss = 0.3653099238872528, train/logprobs = tensor([[-0.4681, -4.2279],
        [-0.8289, -0.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07575304806232452
Epoch 0, Step 1688: train/loss = 0.4911717176437378, train/raw-loss = 0.41666752099990845, train/logprobs = tensor([[-0.7553, -4.6950],
        [-0.7665, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07450421899557114
Epoch 0, Step 1689: train/loss = 0.4804871380329132, train/raw-loss = 0.4066636562347412, train/logprobs = tensor([[-0.4984, -3.5870],
        [-0.8544, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0738234668970108
Epoch 0, Step 1690: train/loss = 0.5458570718765259, train/raw-loss = 0.47581741213798523, train/logprobs = tensor([[-0.5498, -2.0857],
        [-0.6484, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07003967463970184
Epoch 0, Step 1691: train/loss = 0.5615584850311279, train/raw-loss = 0.5006215572357178, train/logprobs = tensor([[-0.8903, -2.9543],
        [-0.7961, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06093690171837807
Epoch 0, Step 1692: train/loss = 0.4294006824493408, train/raw-loss = 0.33982816338539124, train/logprobs = tensor([[-0.7123, -3.1705],
        [-1.1219, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957250416278839
Epoch 0, Step 1693: train/loss = 0.47266465425491333, train/raw-loss = 0.39480462670326233, train/logprobs = tensor([[-0.7474, -2.8167],
        [-0.9152, -0.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077860027551651
Epoch 0, Step 1694: train/loss = 0.39541172981262207, train/raw-loss = 0.3234754204750061, train/logprobs = tensor([[-0.6415, -2.9125],
        [-1.2211, -0.4023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07193632423877716
Epoch 0, Step 1695: train/loss = 0.6917455196380615, train/raw-loss = 0.6180868744850159, train/logprobs = tensor([[-0.7504, -2.7028],
        [-0.6412, -0.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365859299898148
Epoch 0, Step 1696: train/loss = 0.5218164920806885, train/raw-loss = 0.4548269808292389, train/logprobs = tensor([[-0.9012, -2.7636],
        [-0.8542, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698949635028839
Epoch 0, Step 1697: train/loss = 0.5817142724990845, train/raw-loss = 0.534003734588623, train/logprobs = tensor([[-0.4052, -1.3350],
        [-0.4922, -0.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04771047085523605
Epoch 0, Step 1698: train/loss = 0.5794363617897034, train/raw-loss = 0.5083739757537842, train/logprobs = tensor([[-0.9293, -2.4317],
        [-0.6221, -0.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07106242328882217
Epoch 0, Step 1699: train/loss = 0.4947393536567688, train/raw-loss = 0.4326916038990021, train/logprobs = tensor([[-0.5830, -2.9995],
        [-0.8146, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06204775720834732
Epoch 0, Step 1700: train/loss = 0.5668212175369263, train/raw-loss = 0.48351019620895386, train/logprobs = tensor([[-0.7838, -2.5664],
        [-0.7069, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833110436797142
Epoch 0, Step 1701: train/loss = 0.6001268625259399, train/raw-loss = 0.5282372832298279, train/logprobs = tensor([[-0.9656, -1.8030],
        [-0.9808, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07188956439495087
Epoch 0, Step 1702: train/loss = 0.49748945236206055, train/raw-loss = 0.41438591480255127, train/logprobs = tensor([[-0.5141, -2.1399],
        [-1.0179, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08310352265834808
Epoch 0, Step 1703: train/loss = 0.42954322695732117, train/raw-loss = 0.3539179563522339, train/logprobs = tensor([[-0.5355, -5.3633],
        [-1.0474, -1.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562526315450668
Epoch 0, Step 1704: train/loss = 0.3712303340435028, train/raw-loss = 0.2873586118221283, train/logprobs = tensor([[-0.6277, -5.1359],
        [-1.1791, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387170732021332
Epoch 0, Step 1705: train/loss = 0.463950514793396, train/raw-loss = 0.39627721905708313, train/logprobs = tensor([[-0.5001, -6.2313],
        [-0.9058, -1.2108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06767326593399048
Epoch 0, Step 1706: train/loss = 0.3764777183532715, train/raw-loss = 0.29904329776763916, train/logprobs = tensor([[-0.5392, -3.3349],
        [-1.3462, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07743440568447113
Epoch 0, Step 1707: train/loss = 0.48609763383865356, train/raw-loss = 0.4139097034931183, train/logprobs = tensor([[-0.6609, -1.9155],
        [-0.9827, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07218790054321289
Epoch 0, Step 1708: train/loss = 0.4933958649635315, train/raw-loss = 0.4289415180683136, train/logprobs = tensor([[-0.6536, -2.4936],
        [-0.9816, -0.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644543468952179
Epoch 0, Step 1709: train/loss = 0.5450563430786133, train/raw-loss = 0.4699295163154602, train/logprobs = tensor([[-0.7414, -3.0162],
        [-0.7343, -0.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07512684911489487
Epoch 0, Step 1710: train/loss = 0.5132138729095459, train/raw-loss = 0.4318159818649292, train/logprobs = tensor([[-0.6391, -3.2490],
        [-0.9058, -0.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139792084693909
Epoch 0, Step 1711: train/loss = 0.3259734511375427, train/raw-loss = 0.23309047520160675, train/logprobs = tensor([[-0.5921, -5.3955],
        [-1.3668, -1.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09288299083709717
Epoch 0, Step 1712: train/loss = 0.32925736904144287, train/raw-loss = 0.2633638381958008, train/logprobs = tensor([[-0.3847, -8.2777],
        [-0.6368, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0658935159444809
Epoch 0, Step 1713: train/loss = 0.3905673921108246, train/raw-loss = 0.3033556044101715, train/logprobs = tensor([[-0.6379, -3.9838],
        [-1.1813, -0.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08721178025007248
Epoch 0, Step 1714: train/loss = 0.6214460730552673, train/raw-loss = 0.5547152757644653, train/logprobs = tensor([[-0.7222, -1.5500],
        [-0.6255, -0.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06673083454370499
Epoch 0, Step 1715: train/loss = 0.5323793292045593, train/raw-loss = 0.4665659964084625, train/logprobs = tensor([[-0.5827, -2.1112],
        [-0.7126, -0.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06581331789493561
Epoch 0, Step 1716: train/loss = 0.5780639052391052, train/raw-loss = 0.5021501779556274, train/logprobs = tensor([[-0.7761, -2.1276],
        [-0.7531, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591370493173599
Epoch 0, Step 1717: train/loss = 0.49599286913871765, train/raw-loss = 0.4278301000595093, train/logprobs = tensor([[-0.5425, -5.5665],
        [-0.8454, -1.1819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06816278398036957
Epoch 0, Step 1718: train/loss = 0.48606422543525696, train/raw-loss = 0.4208449721336365, train/logprobs = tensor([[-0.7155, -2.4554],
        [-0.9754, -0.6255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652192234992981
Epoch 0, Step 1719: train/loss = 0.41056281328201294, train/raw-loss = 0.31739771366119385, train/logprobs = tensor([[-0.6059, -5.8949],
        [-1.1592, -0.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09316512942314148
Epoch 0, Step 1720: train/loss = 0.7329448461532593, train/raw-loss = 0.6636680364608765, train/logprobs = tensor([[-1.3594, -2.1057],
        [-0.7356, -0.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0692768543958664
Epoch 0, Step 1721: train/loss = 0.3781408965587616, train/raw-loss = 0.27928510308265686, train/logprobs = tensor([[-0.8827, -6.8011],
        [-1.3690, -1.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09885581582784653
Epoch 0, Step 1722: train/loss = 0.3393806219100952, train/raw-loss = 0.24599358439445496, train/logprobs = tensor([[-0.4210, -3.5652],
        [-1.2778, -0.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09338702261447906
Epoch 0, Step 1723: train/loss = 0.48032835125923157, train/raw-loss = 0.39309632778167725, train/logprobs = tensor([[-0.8351, -3.3315],
        [-1.3499, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08723203837871552
Epoch 0, Step 1724: train/loss = 0.3775804936885834, train/raw-loss = 0.31767651438713074, train/logprobs = tensor([[-0.7349, -5.4878],
        [-0.9243, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05990399420261383
Epoch 0, Step 1725: train/loss = 0.518632709980011, train/raw-loss = 0.44495972990989685, train/logprobs = tensor([[-0.6511, -5.4313],
        [-0.9783, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07367297261953354
Epoch 0, Step 1726: train/loss = 0.3175705373287201, train/raw-loss = 0.2386973649263382, train/logprobs = tensor([[-0.6487, -5.2261],
        [-0.9879, -0.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0788731575012207
Epoch 0, Step 1727: train/loss = 0.41652435064315796, train/raw-loss = 0.3397183418273926, train/logprobs = tensor([[-0.6612, -3.4708],
        [-0.8542, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07680603861808777
Epoch 0, Step 1728: train/loss = 0.6102770566940308, train/raw-loss = 0.5563443899154663, train/logprobs = tensor([[-0.7254, -2.5153],
        [-0.5936, -0.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05393260344862938
Epoch 0, Step 1729: train/loss = 0.3328280746936798, train/raw-loss = 0.24894818663597107, train/logprobs = tensor([[-0.8090, -6.1026],
        [-1.0458, -0.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387987315654755
Epoch 0, Step 1730: train/loss = 0.6676174998283386, train/raw-loss = 0.5845589637756348, train/logprobs = tensor([[-0.7327, -1.3159],
        [-0.7492, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08305853605270386
Epoch 0, Step 1731: train/loss = 0.6077612638473511, train/raw-loss = 0.5441110134124756, train/logprobs = tensor([[-0.4209, -2.2742],
        [-0.7687, -0.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365028768777847
Epoch 0, Step 1732: train/loss = 0.4986923336982727, train/raw-loss = 0.43131208419799805, train/logprobs = tensor([[-0.6979, -5.0518],
        [-0.9026, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06738027930259705
Epoch 0, Step 1733: train/loss = 0.49684980511665344, train/raw-loss = 0.43023452162742615, train/logprobs = tensor([[-0.4231, -3.0247],
        [-0.6833, -0.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06661530584096909
Epoch 0, Step 1734: train/loss = 0.4820200204849243, train/raw-loss = 0.4179531931877136, train/logprobs = tensor([[-1.1231, -4.2862],
        [-0.8603, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06406684219837189
Epoch 0, Step 1735: train/loss = 0.3473914861679077, train/raw-loss = 0.28163835406303406, train/logprobs = tensor([[-0.7106, -5.5023],
        [-1.0035, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06575311720371246
Epoch 0, Step 1736: train/loss = 0.4027567207813263, train/raw-loss = 0.301256000995636, train/logprobs = tensor([[-0.8677, -5.0434],
        [-1.2088, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015007421374321
Epoch 0, Step 1737: train/loss = 0.3435344696044922, train/raw-loss = 0.2587834894657135, train/logprobs = tensor([[-0.5273, -6.5057],
        [-1.3770, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475098013877869
Epoch 0, Step 1738: train/loss = 0.5471442937850952, train/raw-loss = 0.4612428843975067, train/logprobs = tensor([[-1.3598, -4.8636],
        [-1.1837, -1.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08590144664049149
Epoch 0, Step 1739: train/loss = 0.5048614740371704, train/raw-loss = 0.43157264590263367, train/logprobs = tensor([[-0.7124, -2.9452],
        [-0.6998, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07328878343105316
Epoch 0, Step 1740: train/loss = 0.4533143639564514, train/raw-loss = 0.38372355699539185, train/logprobs = tensor([[-0.5688, -3.8783],
        [-1.0393, -1.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06959079951047897
Epoch 0, Step 1741: train/loss = 0.4922734200954437, train/raw-loss = 0.4262825548648834, train/logprobs = tensor([[-0.5494, -4.4128],
        [-0.9835, -0.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0659908652305603
Epoch 0, Step 1742: train/loss = 0.46499335765838623, train/raw-loss = 0.3824310898780823, train/logprobs = tensor([[-1.0932, -5.8741],
        [-0.9296, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08256223797798157
Epoch 0, Step 1743: train/loss = 0.5882759094238281, train/raw-loss = 0.5121502876281738, train/logprobs = tensor([[-0.6335, -1.8977],
        [-0.9150, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07612559199333191
Epoch 0, Step 1744: train/loss = 0.441048264503479, train/raw-loss = 0.36969345808029175, train/logprobs = tensor([[-1.4712, -5.9753],
        [-1.2592, -1.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07135479152202606
Epoch 0, Step 1745: train/loss = 0.53021639585495, train/raw-loss = 0.45306795835494995, train/logprobs = tensor([[-0.5188, -3.7484],
        [-0.7933, -0.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0771484449505806
Epoch 0, Step 1746: train/loss = 0.5534716844558716, train/raw-loss = 0.4903462529182434, train/logprobs = tensor([[-0.5017, -1.8786],
        [-0.7229, -0.4798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0631253570318222
Epoch 0, Step 1747: train/loss = 0.5140219330787659, train/raw-loss = 0.45540663599967957, train/logprobs = tensor([[-0.5651, -1.7009],
        [-1.0468, -0.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0586153045296669
Epoch 0, Step 1748: train/loss = 0.5281648635864258, train/raw-loss = 0.4557012915611267, train/logprobs = tensor([[-0.6533, -1.4004],
        [-1.1198, -0.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07246354967355728
Epoch 0, Step 1749: train/loss = 0.5057162642478943, train/raw-loss = 0.4341922998428345, train/logprobs = tensor([[-0.6156, -2.5782],
        [-0.8949, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07152392715215683
Epoch 0, Step 1750: train/loss = 0.3950170874595642, train/raw-loss = 0.3073578476905823, train/logprobs = tensor([[-0.9199, -9.9826],
        [-1.1550, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765920251607895
Epoch 0, Step 1751: train/loss = 0.5342246294021606, train/raw-loss = 0.46903789043426514, train/logprobs = tensor([[-0.9421, -4.2674],
        [-0.7863, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06518670916557312
Epoch 0, Step 1752: train/loss = 0.3964898884296417, train/raw-loss = 0.3353070914745331, train/logprobs = tensor([[-0.6331, -7.5125],
        [-0.9910, -1.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06118275597691536
Epoch 0, Step 1753: train/loss = 0.3823309540748596, train/raw-loss = 0.302142471075058, train/logprobs = tensor([[-0.9462, -7.0176],
        [-1.0202, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08018845319747925
Epoch 0, Step 1754: train/loss = 0.28847622871398926, train/raw-loss = 0.19526460766792297, train/logprobs = tensor([[-0.7513, -7.1395],
        [-1.4659, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09321162849664688
Epoch 0, Step 1755: train/loss = 0.47738489508628845, train/raw-loss = 0.40157878398895264, train/logprobs = tensor([[-0.9023, -2.6840],
        [-1.1128, -0.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07580617070198059
Epoch 0, Step 1756: train/loss = 0.5765029191970825, train/raw-loss = 0.5043244957923889, train/logprobs = tensor([[-1.3244, -2.7174],
        [-1.0094, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07217840850353241
Epoch 0, Step 1757: train/loss = 0.6730430126190186, train/raw-loss = 0.6013638973236084, train/logprobs = tensor([[-0.6936, -0.8776],
        [-0.7394, -0.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07167914509773254
Epoch 0, Step 1758: train/loss = 0.4011787474155426, train/raw-loss = 0.3383782207965851, train/logprobs = tensor([[-0.6190, -5.3006],
        [-0.7954, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06280053406953812
Epoch 0, Step 1759: train/loss = 0.5287156105041504, train/raw-loss = 0.4709247350692749, train/logprobs = tensor([[-0.6561, -2.1397],
        [-1.0281, -0.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05779089778661728
Epoch 0, Step 1760: train/loss = 0.5589392185211182, train/raw-loss = 0.4804823696613312, train/logprobs = tensor([[-0.7378, -5.3472],
        [-1.3470, -1.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07845687866210938
Epoch 0, Step 1761: train/loss = 0.3888527452945709, train/raw-loss = 0.30166465044021606, train/logprobs = tensor([[-0.5611, -3.5178],
        [-0.8460, -0.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08718809485435486
Epoch 0, Step 1762: train/loss = 0.47774022817611694, train/raw-loss = 0.40862593054771423, train/logprobs = tensor([[-0.7558, -4.0776],
        [-1.1042, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0691143274307251
Epoch 0, Step 1763: train/loss = 0.5347489714622498, train/raw-loss = 0.44690895080566406, train/logprobs = tensor([[-1.0603, -3.9573],
        [-0.7318, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0878399983048439
Epoch 0, Step 1764: train/loss = 0.3257012963294983, train/raw-loss = 0.2544342875480652, train/logprobs = tensor([[-0.4510, -4.6650],
        [-0.7810, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07126700133085251
Epoch 0, Step 1765: train/loss = 0.5392480492591858, train/raw-loss = 0.4605781137943268, train/logprobs = tensor([[-0.4418, -2.3348],
        [-0.6987, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07866993546485901
Epoch 0, Step 1766: train/loss = 0.40648192167282104, train/raw-loss = 0.33677589893341064, train/logprobs = tensor([[-0.8756, -5.7681],
        [-1.1125, -1.1494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0697060227394104
Epoch 0, Step 1767: train/loss = 0.3875589966773987, train/raw-loss = 0.32140737771987915, train/logprobs = tensor([[-0.4701, -9.1098],
        [-0.6630, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06615164875984192
Epoch 0, Step 1768: train/loss = 0.42098766565322876, train/raw-loss = 0.32325321435928345, train/logprobs = tensor([[-0.6518, -3.1581],
        [-1.1695, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773444384336472
Epoch 0, Step 1769: train/loss = 0.41911160945892334, train/raw-loss = 0.34289437532424927, train/logprobs = tensor([[-0.6846, -2.7974],
        [-1.1735, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07621724903583527
Epoch 0, Step 1770: train/loss = 0.39906901121139526, train/raw-loss = 0.3348081111907959, train/logprobs = tensor([[-0.7937, -9.7661],
        [-0.8187, -1.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06426092237234116
Epoch 0, Step 1771: train/loss = 0.5131229758262634, train/raw-loss = 0.43760621547698975, train/logprobs = tensor([[-0.6770, -3.1624],
        [-0.9928, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07551675289869308
Epoch 0, Step 1772: train/loss = 0.4183270037174225, train/raw-loss = 0.3514176607131958, train/logprobs = tensor([[-0.6924, -3.5644],
        [-0.8361, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06690932810306549
Epoch 0, Step 1773: train/loss = 0.35400882363319397, train/raw-loss = 0.2587421238422394, train/logprobs = tensor([[-0.6789, -5.1604],
        [-1.0224, -0.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952666625380516
Epoch 0, Step 1774: train/loss = 0.5483319163322449, train/raw-loss = 0.45948484539985657, train/logprobs = tensor([[-1.2594, -2.7353],
        [-1.4781, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08884703367948532
Epoch 0, Step 1775: train/loss = 0.5401718616485596, train/raw-loss = 0.4625750780105591, train/logprobs = tensor([[-0.6121, -1.7296],
        [-0.8528, -0.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07759679853916168
Epoch 0, Step 1776: train/loss = 0.5834012031555176, train/raw-loss = 0.5063512325286865, train/logprobs = tensor([[-1.7928, -6.4222],
        [-1.1942, -0.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07705000042915344
Epoch 0, Step 1777: train/loss = 0.501492977142334, train/raw-loss = 0.416545569896698, train/logprobs = tensor([[-0.4473, -3.0403],
        [-0.9226, -0.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08494735509157181
Epoch 0, Step 1778: train/loss = 0.4808107614517212, train/raw-loss = 0.3968053460121155, train/logprobs = tensor([[-0.7818, -3.2529],
        [-1.0990, -0.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08400540798902512
Epoch 0, Step 1779: train/loss = 0.5060877799987793, train/raw-loss = 0.4369555711746216, train/logprobs = tensor([[-0.4701, -5.7534],
        [-0.6646, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06913219392299652
Epoch 0, Step 1780: train/loss = 0.5140803456306458, train/raw-loss = 0.44437283277511597, train/logprobs = tensor([[-0.3821, -4.3600],
        [-0.6505, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06970759481191635
Epoch 0, Step 1781: train/loss = 0.5027306079864502, train/raw-loss = 0.4215555787086487, train/logprobs = tensor([[-0.5678, -3.0549],
        [-0.9007, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08117496967315674
Epoch 0, Step 1782: train/loss = 0.33490189909935, train/raw-loss = 0.26749104261398315, train/logprobs = tensor([[-0.4430, -5.2211],
        [-0.6727, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06741087138652802
Epoch 0, Step 1783: train/loss = 0.45549437403678894, train/raw-loss = 0.3686743974685669, train/logprobs = tensor([[-0.6883, -3.2218],
        [-1.3214, -0.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08681993931531906
Epoch 0, Step 1784: train/loss = 0.5649987459182739, train/raw-loss = 0.5013381838798523, train/logprobs = tensor([[-0.9201, -2.6394],
        [-0.7560, -0.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06366053968667984
Epoch 0, Step 1785: train/loss = 0.5648775100708008, train/raw-loss = 0.49030420184135437, train/logprobs = tensor([[-0.6288, -2.2216],
        [-0.7509, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07457329332828522
Epoch 0, Step 1786: train/loss = 0.5946299433708191, train/raw-loss = 0.5287724733352661, train/logprobs = tensor([[-0.4386, -1.7072],
        [-0.6475, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06585748493671417
Epoch 0, Step 1787: train/loss = 0.5373238325119019, train/raw-loss = 0.4513554275035858, train/logprobs = tensor([[-0.9177, -2.5273],
        [-1.0506, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08596842736005783
Epoch 0, Step 1788: train/loss = 0.528427243232727, train/raw-loss = 0.4657222628593445, train/logprobs = tensor([[-0.4294, -2.2104],
        [-0.5058, -0.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06270502507686615
Epoch 0, Step 1789: train/loss = 0.43200117349624634, train/raw-loss = 0.3623240292072296, train/logprobs = tensor([[-0.7653, -4.2305],
        [-1.0228, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06967712938785553
Epoch 0, Step 1790: train/loss = 0.3922129273414612, train/raw-loss = 0.3124829828739166, train/logprobs = tensor([[-0.7013, -5.1780],
        [-1.0014, -0.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07972995936870575
Epoch 0, Step 1791: train/loss = 0.5794747471809387, train/raw-loss = 0.5027904510498047, train/logprobs = tensor([[-0.9475, -2.1380],
        [-1.0168, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07668428122997284
Epoch 0, Step 1792: train/loss = 0.45396628975868225, train/raw-loss = 0.35454505681991577, train/logprobs = tensor([[-0.5741, -3.0202],
        [-1.0743, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09942121803760529
Epoch 0, Step 1793: train/loss = 0.390621542930603, train/raw-loss = 0.30848750472068787, train/logprobs = tensor([[-0.7093, -4.8256],
        [-1.0176, -0.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08213403820991516
Epoch 0, Step 1794: train/loss = 0.39689818024635315, train/raw-loss = 0.32020121812820435, train/logprobs = tensor([[-0.8154, -2.4208],
        [-1.4010, -0.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0766969546675682
Epoch 0, Step 1795: train/loss = 0.3539060354232788, train/raw-loss = 0.2879697382450104, train/logprobs = tensor([[-0.4144, -7.6149],
        [-1.0692, -1.4138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06593628227710724
Epoch 0, Step 1796: train/loss = 0.5833452939987183, train/raw-loss = 0.525006890296936, train/logprobs = tensor([[-0.4660, -1.3148],
        [-0.6754, -0.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058338358998298645
Epoch 0, Step 1797: train/loss = 0.47191691398620605, train/raw-loss = 0.3770548105239868, train/logprobs = tensor([[-1.1845, -6.8777],
        [-1.2746, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09486208856105804
Epoch 0, Step 1798: train/loss = 0.37280628085136414, train/raw-loss = 0.28109249472618103, train/logprobs = tensor([[-0.8593, -5.9416],
        [-2.1029, -1.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0917137935757637
Epoch 0, Step 1799: train/loss = 0.4427962303161621, train/raw-loss = 0.37647899985313416, train/logprobs = tensor([[-0.7916, -3.9508],
        [-0.9477, -0.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06631723791360855
Epoch 0, Step 1800: train/loss = 0.3166748583316803, train/raw-loss = 0.23182979226112366, train/logprobs = tensor([[-0.5850, -7.5522],
        [-1.1172, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08484507352113724
Epoch 0, Step 1801: train/loss = 0.4121786952018738, train/raw-loss = 0.3412992060184479, train/logprobs = tensor([[-0.6287, -4.4515],
        [-1.1357, -0.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07087947428226471
Epoch 0, Step 1802: train/loss = 0.5234142541885376, train/raw-loss = 0.45105066895484924, train/logprobs = tensor([[-0.8806, -4.2974],
        [-0.8321, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07236362993717194
Epoch 0, Step 1803: train/loss = 0.455250084400177, train/raw-loss = 0.37419506907463074, train/logprobs = tensor([[-0.7717, -5.0822],
        [-1.0375, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08105503022670746
Epoch 0, Step 1804: train/loss = 0.52687668800354, train/raw-loss = 0.45320677757263184, train/logprobs = tensor([[-0.7510, -2.3104],
        [-0.9767, -0.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07366988807916641
Epoch 0, Step 1805: train/loss = 0.46724361181259155, train/raw-loss = 0.4009571671485901, train/logprobs = tensor([[-0.5680, -2.5128],
        [-1.1087, -0.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06628645956516266
Epoch 0, Step 1806: train/loss = 0.38735005259513855, train/raw-loss = 0.3227868378162384, train/logprobs = tensor([[-0.5310, -3.7513],
        [-1.0327, -0.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06456322222948074
Epoch 0, Step 1807: train/loss = 0.5954089164733887, train/raw-loss = 0.5319936275482178, train/logprobs = tensor([[-0.4157, -2.4176],
        [-0.5677, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06341534852981567
Epoch 0, Step 1808: train/loss = 0.41831859946250916, train/raw-loss = 0.35422971844673157, train/logprobs = tensor([[-0.4501, -4.1326],
        [-0.7034, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0640888586640358
Epoch 0, Step 1809: train/loss = 0.43385228514671326, train/raw-loss = 0.3672757148742676, train/logprobs = tensor([[-0.4912, -6.7380],
        [-0.7577, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06657657027244568
Epoch 0, Step 1810: train/loss = 0.5260591506958008, train/raw-loss = 0.4705103635787964, train/logprobs = tensor([[-0.6698, -1.8223],
        [-1.0128, -0.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05554879456758499
Epoch 0, Step 1811: train/loss = 0.4820941686630249, train/raw-loss = 0.4134312868118286, train/logprobs = tensor([[-0.7413, -4.9302],
        [-1.0443, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06866288185119629
Epoch 0, Step 1812: train/loss = 0.2779737710952759, train/raw-loss = 0.18400195240974426, train/logprobs = tensor([[-1.2005, -7.3370],
        [-1.9150, -1.0151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397180378437042
Epoch 0, Step 1813: train/loss = 0.3160640299320221, train/raw-loss = 0.24359728395938873, train/logprobs = tensor([[-0.6585, -9.5781],
        [-0.9815, -1.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07246675342321396
Epoch 0, Step 1814: train/loss = 0.4577632546424866, train/raw-loss = 0.37109851837158203, train/logprobs = tensor([[-0.5742, -2.3600],
        [-0.9640, -0.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08666470646858215
Epoch 0, Step 1815: train/loss = 0.35537099838256836, train/raw-loss = 0.2880147099494934, train/logprobs = tensor([[-0.6354, -8.4614],
        [-0.8449, -1.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06735629588365555
Epoch 0, Step 1816: train/loss = 0.4198743999004364, train/raw-loss = 0.3491210639476776, train/logprobs = tensor([[-0.5125, -3.2330],
        [-0.5962, -0.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.070753313601017
Epoch 0, Step 1817: train/loss = 0.6737885475158691, train/raw-loss = 0.620049238204956, train/logprobs = tensor([[-0.6180, -0.7796],
        [-0.6471, -0.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053739357739686966
Epoch 0, Step 1818: train/loss = 0.34010815620422363, train/raw-loss = 0.25511810183525085, train/logprobs = tensor([[-0.5886, -7.4311],
        [-1.2788, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499006181955338
Epoch 0, Step 1819: train/loss = 0.4216214120388031, train/raw-loss = 0.3432152271270752, train/logprobs = tensor([[-0.7029, -4.1835],
        [-1.0133, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0784061998128891
Epoch 0, Step 1820: train/loss = 0.4904381036758423, train/raw-loss = 0.41449230909347534, train/logprobs = tensor([[-0.5001, -2.8496],
        [-0.8501, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07594577968120575
Epoch 0, Step 1821: train/loss = 0.3953248858451843, train/raw-loss = 0.3217274844646454, train/logprobs = tensor([[-0.5424, -4.7253],
        [-0.7930, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07359740138053894
Epoch 0, Step 1822: train/loss = 0.5086814165115356, train/raw-loss = 0.42494699358940125, train/logprobs = tensor([[-0.7154, -2.4110],
        [-0.7967, -0.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837344229221344
Epoch 0, Step 1823: train/loss = 0.5153364539146423, train/raw-loss = 0.4167241156101227, train/logprobs = tensor([[-0.4677, -2.6388],
        [-0.9966, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09861235320568085
Epoch 0, Step 1824: train/loss = 0.47977766394615173, train/raw-loss = 0.4122745990753174, train/logprobs = tensor([[-0.4300, -2.4718],
        [-0.8225, -0.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750302761793137
Epoch 0, Step 1825: train/loss = 0.4360290467739105, train/raw-loss = 0.3551711440086365, train/logprobs = tensor([[-0.6229, -3.9191],
        [-1.1061, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08085791766643524
Epoch 0, Step 1826: train/loss = 0.4312916398048401, train/raw-loss = 0.3581603169441223, train/logprobs = tensor([[-0.8774, -4.8431],
        [-0.9576, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07313129305839539
Epoch 0, Step 1827: train/loss = 0.44509798288345337, train/raw-loss = 0.3525821566581726, train/logprobs = tensor([[-0.5942, -1.9873],
        [-1.1346, -0.7136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09251579642295837
Epoch 0, Step 1828: train/loss = 0.3923034965991974, train/raw-loss = 0.30064061284065247, train/logprobs = tensor([[-0.9180, -6.4143],
        [-1.2345, -0.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166291356086731
Epoch 0, Step 1829: train/loss = 0.5018171668052673, train/raw-loss = 0.4476255774497986, train/logprobs = tensor([[-0.4956, -2.5923],
        [-0.4847, -0.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05419158563017845
Epoch 0, Step 1830: train/loss = 0.5080325603485107, train/raw-loss = 0.4420280456542969, train/logprobs = tensor([[-0.3953, -2.7440],
        [-0.6372, -0.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06600451469421387
Epoch 0, Step 1831: train/loss = 0.7063091397285461, train/raw-loss = 0.6498148441314697, train/logprobs = tensor([[-0.3871, -0.4894],
        [-0.4594, -0.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05649435520172119
Epoch 0, Step 1832: train/loss = 0.423938512802124, train/raw-loss = 0.3529590964317322, train/logprobs = tensor([[-0.4221, -3.3479],
        [-0.6093, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07097944617271423
Epoch 0, Step 1833: train/loss = 0.6098661422729492, train/raw-loss = 0.5356239080429077, train/logprobs = tensor([[-0.3961, -1.4339],
        [-0.6273, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0742422491312027
Epoch 0, Step 1834: train/loss = 0.5617550611495972, train/raw-loss = 0.4773038625717163, train/logprobs = tensor([[-0.8485, -3.5673],
        [-0.6671, -0.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445125818252563
Epoch 0, Step 1835: train/loss = 0.3168175220489502, train/raw-loss = 0.2554246187210083, train/logprobs = tensor([[-0.3673, -8.7341],
        [-0.6789, -1.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06139286607503891
Epoch 0, Step 1836: train/loss = 0.33444416522979736, train/raw-loss = 0.23286795616149902, train/logprobs = tensor([[-0.8568, -4.9774],
        [-1.4480, -0.6190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10157623142004013
Epoch 0, Step 1837: train/loss = 0.44927042722702026, train/raw-loss = 0.38193419575691223, train/logprobs = tensor([[-0.6184, -3.8542],
        [-0.8854, -0.7581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06733622401952744
Epoch 0, Step 1838: train/loss = 0.4206703305244446, train/raw-loss = 0.34894901514053345, train/logprobs = tensor([[-0.7058, -3.0472],
        [-0.7356, -0.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07172127813100815
Epoch 0, Step 1839: train/loss = 0.3799452781677246, train/raw-loss = 0.3059641420841217, train/logprobs = tensor([[-0.7055, -3.7974],
        [-0.9144, -0.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0739811360836029
Epoch 0, Step 1840: train/loss = 0.317894846200943, train/raw-loss = 0.2403717339038849, train/logprobs = tensor([[-0.7889, -7.9021],
        [-1.0717, -1.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07752308994531631
Epoch 0, Step 1841: train/loss = 0.47773072123527527, train/raw-loss = 0.40687617659568787, train/logprobs = tensor([[-0.4673, -2.9296],
        [-0.8526, -0.4064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07085452973842621
Epoch 0, Step 1842: train/loss = 0.4369121789932251, train/raw-loss = 0.3728943467140198, train/logprobs = tensor([[-0.7804, -5.9993],
        [-1.0024, -1.3569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06401778757572174
Epoch 0, Step 1843: train/loss = 0.3363877832889557, train/raw-loss = 0.26465463638305664, train/logprobs = tensor([[-0.7977, -7.5762],
        [-1.2479, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07173317670822144
Epoch 0, Step 1844: train/loss = 0.4813469648361206, train/raw-loss = 0.3843470513820648, train/logprobs = tensor([[-0.6996, -2.9840],
        [-1.3908, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09699990600347519
Epoch 0, Step 1845: train/loss = 0.33529162406921387, train/raw-loss = 0.24786487221717834, train/logprobs = tensor([[-0.8150, -6.9449],
        [-1.1854, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08742675185203552
Epoch 0, Step 1846: train/loss = 0.5478895902633667, train/raw-loss = 0.48646080493927, train/logprobs = tensor([[-0.4618, -2.7583],
        [-0.8060, -0.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061428751796483994
Epoch 0, Step 1847: train/loss = 0.3368653655052185, train/raw-loss = 0.25650545954704285, train/logprobs = tensor([[-0.6732, -3.5967],
        [-1.3207, -0.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08035992085933685
Epoch 0, Step 1848: train/loss = 0.4480289816856384, train/raw-loss = 0.3915042281150818, train/logprobs = tensor([[-0.5653, -2.5338],
        [-1.0129, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05652470886707306
Epoch 0, Step 1849: train/loss = 0.5160609483718872, train/raw-loss = 0.46358075737953186, train/logprobs = tensor([[-0.4952, -2.7137],
        [-0.5979, -0.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052480198442935944
Epoch 0, Step 1850: train/loss = 0.32994702458381653, train/raw-loss = 0.2605452537536621, train/logprobs = tensor([[-0.6476, -5.0918],
        [-0.8499, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06940177083015442
Epoch 0, Step 1851: train/loss = 0.2787272334098816, train/raw-loss = 0.19720344245433807, train/logprobs = tensor([[-0.5659, -4.7782],
        [-1.2902, -0.4606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152379095554352
Epoch 0, Step 1852: train/loss = 0.3129424750804901, train/raw-loss = 0.24149449169635773, train/logprobs = tensor([[-0.6826, -9.3149],
        [-1.2231, -1.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07144797593355179
Epoch 0, Step 1853: train/loss = 0.4812629818916321, train/raw-loss = 0.42599523067474365, train/logprobs = tensor([[-0.5512, -5.3191],
        [-0.6927, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055267736315727234
Epoch 0, Step 1854: train/loss = 0.7867180109024048, train/raw-loss = 0.7196224927902222, train/logprobs = tensor([[-2.0698, -4.1496],
        [-1.0127, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06709550321102142
Epoch 0, Step 1855: train/loss = 0.3533266484737396, train/raw-loss = 0.26727476716041565, train/logprobs = tensor([[-0.5948, -8.0254],
        [-1.2417, -1.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605188876390457
Epoch 0, Step 1856: train/loss = 0.332193523645401, train/raw-loss = 0.2598177194595337, train/logprobs = tensor([[-0.4309, -6.4486],
        [-0.9168, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07237580418586731
Epoch 0, Step 1857: train/loss = 0.3290058374404907, train/raw-loss = 0.24177300930023193, train/logprobs = tensor([[-0.6503, -4.4324],
        [-1.1461, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08723285794258118
Epoch 0, Step 1858: train/loss = 0.5250844955444336, train/raw-loss = 0.44552290439605713, train/logprobs = tensor([[-0.8125, -2.2466],
        [-0.8442, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07956162840127945
Epoch 0, Step 1859: train/loss = 0.4691280722618103, train/raw-loss = 0.3967211842536926, train/logprobs = tensor([[-0.5054, -3.0223],
        [-0.8806, -0.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07240691781044006
Epoch 0, Step 1860: train/loss = 0.4689473509788513, train/raw-loss = 0.3921918570995331, train/logprobs = tensor([[-0.5017, -3.3749],
        [-1.1255, -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675549387931824
Epoch 0, Step 1861: train/loss = 0.31214889883995056, train/raw-loss = 0.22953367233276367, train/logprobs = tensor([[-0.4707, -7.9985],
        [-1.0053, -1.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261524140834808
Epoch 0, Step 1862: train/loss = 0.4158056080341339, train/raw-loss = 0.34935468435287476, train/logprobs = tensor([[-0.3599, -4.7776],
        [-0.7375, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06645092368125916
Epoch 0, Step 1863: train/loss = 0.5474895238876343, train/raw-loss = 0.4603898823261261, train/logprobs = tensor([[-0.7899, -2.7468],
        [-0.9654, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08709965646266937
Epoch 0, Step 1864: train/loss = 0.41604939103126526, train/raw-loss = 0.3436940908432007, train/logprobs = tensor([[-0.8509, -4.6689],
        [-1.1393, -0.7609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07235529273748398
Epoch 0, Step 1865: train/loss = 0.5743463635444641, train/raw-loss = 0.5198899507522583, train/logprobs = tensor([[-0.4150, -2.8536],
        [-0.5588, -0.5303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05445646494626999
Epoch 0, Step 1866: train/loss = 0.5637640357017517, train/raw-loss = 0.49479758739471436, train/logprobs = tensor([[-0.7170, -2.0565],
        [-0.7738, -0.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06896643340587616
Epoch 0, Step 1867: train/loss = 0.4831233322620392, train/raw-loss = 0.4009622633457184, train/logprobs = tensor([[-0.5862, -2.8442],
        [-1.1257, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08216109871864319
Epoch 0, Step 1868: train/loss = 0.5854589939117432, train/raw-loss = 0.5127253532409668, train/logprobs = tensor([[-0.6385, -1.8795],
        [-0.7669, -0.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07273366302251816
Epoch 0, Step 1869: train/loss = 0.5016340017318726, train/raw-loss = 0.4243595600128174, train/logprobs = tensor([[-0.9487, -4.8719],
        [-1.6187, -1.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0772743970155716
Epoch 0, Step 1870: train/loss = 0.3394773006439209, train/raw-loss = 0.2653454840183258, train/logprobs = tensor([[-0.9671, -5.1278],
        [-1.2237, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07413181662559509
Epoch 0, Step 1871: train/loss = 0.4693293571472168, train/raw-loss = 0.4063253700733185, train/logprobs = tensor([[-0.3782, -6.0349],
        [-0.5716, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06300398707389832
Epoch 0, Step 1872: train/loss = 0.7373898029327393, train/raw-loss = 0.6838460564613342, train/logprobs = tensor([[-0.5294, -0.5735],
        [-0.4603, -0.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05354378744959831
Epoch 0, Step 1873: train/loss = 0.5710221529006958, train/raw-loss = 0.5114232897758484, train/logprobs = tensor([[-0.5768, -2.3332],
        [-0.8039, -0.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05959885194897652
Epoch 0, Step 1874: train/loss = 0.29639241099357605, train/raw-loss = 0.2299196422100067, train/logprobs = tensor([[-0.4514, -5.8799],
        [-0.9108, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06647276878356934
Epoch 0, Step 1875: train/loss = 0.5461581349372864, train/raw-loss = 0.48685160279273987, train/logprobs = tensor([[-0.6978, -2.4032],
        [-0.7794, -0.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05930650234222412
Epoch 0, Step 1876: train/loss = 0.4068063199520111, train/raw-loss = 0.34472283720970154, train/logprobs = tensor([[-0.7232, -5.2558],
        [-0.9467, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062083497643470764
Epoch 0, Step 1877: train/loss = 0.36255496740341187, train/raw-loss = 0.2726897895336151, train/logprobs = tensor([[-0.5715, -7.4801],
        [-1.4242, -1.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986517041921616
Epoch 0, Step 1878: train/loss = 0.3841674029827118, train/raw-loss = 0.30254092812538147, train/logprobs = tensor([[-0.5716, -5.0751],
        [-1.2223, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08162645995616913
Epoch 0, Step 1879: train/loss = 0.38275545835494995, train/raw-loss = 0.2942676842212677, train/logprobs = tensor([[-0.6679, -6.2184],
        [-1.1918, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08848779648542404
Epoch 0, Step 1880: train/loss = 0.5515425205230713, train/raw-loss = 0.49006298184394836, train/logprobs = tensor([[-0.6898, -2.5269],
        [-0.9197, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061479516327381134
Epoch 0, Step 1881: train/loss = 0.5100336670875549, train/raw-loss = 0.4343334436416626, train/logprobs = tensor([[-0.7967, -2.5574],
        [-0.9129, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07570020109415054
Epoch 0, Step 1882: train/loss = 0.33904916048049927, train/raw-loss = 0.22959965467453003, train/logprobs = tensor([[-0.8510, -5.6875],
        [-1.7520, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10944951325654984
Epoch 0, Step 1883: train/loss = 0.5047605037689209, train/raw-loss = 0.4237443804740906, train/logprobs = tensor([[-0.8490, -2.2342],
        [-1.0817, -0.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08101612329483032
Epoch 0, Step 1884: train/loss = 0.3941051959991455, train/raw-loss = 0.3091459572315216, train/logprobs = tensor([[-0.8998, -6.5953],
        [-1.2104, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0849592462182045
Epoch 0, Step 1885: train/loss = 0.4317699074745178, train/raw-loss = 0.36599814891815186, train/logprobs = tensor([[-0.6342, -4.2216],
        [-0.7525, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577176600694656
Epoch 0, Step 1886: train/loss = 0.4493618607521057, train/raw-loss = 0.37026625871658325, train/logprobs = tensor([[-0.5086, -4.8676],
        [-1.3587, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07909557968378067
Epoch 0, Step 1887: train/loss = 0.4912445545196533, train/raw-loss = 0.40170925855636597, train/logprobs = tensor([[-0.4955, -1.5531],
        [-1.1507, -0.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953529596328735
Epoch 0, Step 1888: train/loss = 0.6916892528533936, train/raw-loss = 0.6357098817825317, train/logprobs = tensor([[-0.6574, -0.9302],
        [-0.6492, -0.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05597939342260361
Epoch 0, Step 1889: train/loss = 0.40733444690704346, train/raw-loss = 0.3264065384864807, train/logprobs = tensor([[-0.6486, -4.5338],
        [-1.0575, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092793077230453
Epoch 0, Step 1890: train/loss = 0.4807615876197815, train/raw-loss = 0.4098358750343323, train/logprobs = tensor([[-0.7046, -2.5708],
        [-0.8982, -0.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07092566788196564
Epoch 0, Step 1891: train/loss = 0.638695240020752, train/raw-loss = 0.5462378263473511, train/logprobs = tensor([[-1.3916, -4.1658],
        [-1.0833, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0924573764204979
Epoch 0, Step 1892: train/loss = 0.5903661251068115, train/raw-loss = 0.5030518770217896, train/logprobs = tensor([[-0.7936, -2.1741],
        [-0.9435, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08731425553560257
Epoch 0, Step 1893: train/loss = 0.5494487881660461, train/raw-loss = 0.4782085716724396, train/logprobs = tensor([[-0.6904, -1.9865],
        [-0.8160, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07124022394418716
Epoch 0, Step 1894: train/loss = 0.5094187259674072, train/raw-loss = 0.4318998456001282, train/logprobs = tensor([[-0.4419, -1.6866],
        [-0.9891, -0.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07751882076263428
Epoch 0, Step 1895: train/loss = 0.5145516395568848, train/raw-loss = 0.4633210003376007, train/logprobs = tensor([[-0.3614, -3.8472],
        [-0.4537, -0.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05123066157102585
Epoch 0, Step 1896: train/loss = 0.3635590076446533, train/raw-loss = 0.29192227125167847, train/logprobs = tensor([[-0.6267, -6.7927],
        [-1.3158, -1.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07163675129413605
Epoch 0, Step 1897: train/loss = 0.28669172525405884, train/raw-loss = 0.20049291849136353, train/logprobs = tensor([[-0.4034, -7.0013],
        [-0.9391, -1.1342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08619880676269531
Epoch 0, Step 1898: train/loss = 0.5154737234115601, train/raw-loss = 0.44116681814193726, train/logprobs = tensor([[-0.6933, -4.3571],
        [-0.7719, -0.4798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743069052696228
Epoch 0, Step 1899: train/loss = 0.4299205541610718, train/raw-loss = 0.348745733499527, train/logprobs = tensor([[-1.1627, -4.0645],
        [-1.5623, -0.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081174835562706
Epoch 0, Step 1900: train/loss = 0.4165678918361664, train/raw-loss = 0.3507135510444641, train/logprobs = tensor([[-0.7759, -4.0362],
        [-0.9149, -0.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06585434824228287
Epoch 0, Step 1901: train/loss = 0.5150578022003174, train/raw-loss = 0.4231128692626953, train/logprobs = tensor([[-1.2405, -3.6857],
        [-1.1767, -0.6447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194497764110565
Epoch 0, Step 1902: train/loss = 0.498209148645401, train/raw-loss = 0.43314704298973083, train/logprobs = tensor([[-0.5942, -3.2017],
        [-0.7397, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06506207585334778
Epoch 0, Step 1903: train/loss = 0.5021349191665649, train/raw-loss = 0.44196322560310364, train/logprobs = tensor([[-0.5982, -2.5345],
        [-0.7089, -0.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06017173454165459
Epoch 0, Step 1904: train/loss = 0.41226333379745483, train/raw-loss = 0.3484635651111603, train/logprobs = tensor([[-0.6021, -6.3584],
        [-0.8055, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06379976868629456
Epoch 0, Step 1905: train/loss = 0.4448413550853729, train/raw-loss = 0.38462033867836, train/logprobs = tensor([[-0.9053, -7.9187],
        [-0.8934, -1.3875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060221023857593536
Epoch 0, Step 1906: train/loss = 0.592596173286438, train/raw-loss = 0.517003059387207, train/logprobs = tensor([[-0.8365, -1.6570],
        [-0.8391, -0.6410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07559305429458618
Epoch 0, Step 1907: train/loss = 0.47641292214393616, train/raw-loss = 0.40720829367637634, train/logprobs = tensor([[-0.5575, -4.4512],
        [-0.7452, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0692046582698822
Epoch 0, Step 1908: train/loss = 0.6263104677200317, train/raw-loss = 0.5538837909698486, train/logprobs = tensor([[-0.9258, -4.0006],
        [-0.6260, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07242666184902191
Epoch 0, Step 1909: train/loss = 0.4060784578323364, train/raw-loss = 0.3001970648765564, train/logprobs = tensor([[-0.7241, -6.0609],
        [-1.5834, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588140040636063
Epoch 0, Step 1910: train/loss = 0.4647176265716553, train/raw-loss = 0.40352553129196167, train/logprobs = tensor([[-0.5064, -3.9336],
        [-0.8560, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061192065477371216
Epoch 0, Step 1911: train/loss = 0.33438640832901, train/raw-loss = 0.2531960606575012, train/logprobs = tensor([[-0.6395, -6.0720],
        [-1.4670, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119036257266998
Epoch 0, Step 1912: train/loss = 0.5093252062797546, train/raw-loss = 0.4242645502090454, train/logprobs = tensor([[-0.8161, -2.0760],
        [-1.1821, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08506070822477341
Epoch 0, Step 1913: train/loss = 0.4105677902698517, train/raw-loss = 0.3417099416255951, train/logprobs = tensor([[-0.5441, -2.8595],
        [-1.1763, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06885787099599838
Epoch 0, Step 1914: train/loss = 0.3102887272834778, train/raw-loss = 0.2341132014989853, train/logprobs = tensor([[-0.5327, -9.9525],
        [-1.2944, -1.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07617553323507309
Epoch 0, Step 1915: train/loss = 0.32708799839019775, train/raw-loss = 0.247390478849411, train/logprobs = tensor([[-0.6142, -8.1508],
        [-1.2076, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07969751209020615
Epoch 0, Step 1916: train/loss = 0.5263588428497314, train/raw-loss = 0.44154027104377747, train/logprobs = tensor([[-0.4490, -2.3016],
        [-0.9968, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08481860160827637
Epoch 0, Step 1917: train/loss = 0.5897118449211121, train/raw-loss = 0.5361385345458984, train/logprobs = tensor([[-0.8606, -2.4043],
        [-0.8581, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053573332726955414
Epoch 0, Step 1918: train/loss = 0.41234999895095825, train/raw-loss = 0.30456700921058655, train/logprobs = tensor([[-0.6146, -3.1021],
        [-1.4829, -0.7830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10778295993804932
Epoch 0, Step 1919: train/loss = 0.3070458173751831, train/raw-loss = 0.22391483187675476, train/logprobs = tensor([[-0.6090, -6.0177],
        [-1.0436, -0.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08313098549842834
Epoch 0, Step 1920: train/loss = 0.3788749575614929, train/raw-loss = 0.30411481857299805, train/logprobs = tensor([[-0.4859, -3.3627],
        [-1.1370, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07476014643907547
Epoch 0, Step 1921: train/loss = 0.3806455135345459, train/raw-loss = 0.29522284865379333, train/logprobs = tensor([[-0.4921, -8.1417],
        [-1.2547, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08542267233133316
Epoch 0, Step 1922: train/loss = 0.2951146960258484, train/raw-loss = 0.19989953935146332, train/logprobs = tensor([[-0.6544, -6.1278],
        [-1.3628, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09521515667438507
Epoch 0, Step 1923: train/loss = 0.38388413190841675, train/raw-loss = 0.30575209856033325, train/logprobs = tensor([[-0.5532, -7.0481],
        [-1.1135, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07813205569982529
Epoch 0, Step 1924: train/loss = 0.32552775740623474, train/raw-loss = 0.23517261445522308, train/logprobs = tensor([[-0.5303, -4.9630],
        [-0.9972, -0.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09035514295101166
Epoch 0, Step 1925: train/loss = 0.4334346354007721, train/raw-loss = 0.35605138540267944, train/logprobs = tensor([[-0.5756, -6.7474],
        [-1.0886, -1.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07738327980041504
Epoch 0, Step 1926: train/loss = 0.47623005509376526, train/raw-loss = 0.40919792652130127, train/logprobs = tensor([[-0.5853, -2.8374],
        [-0.8964, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06703212857246399
Epoch 0, Step 1927: train/loss = 0.35179588198661804, train/raw-loss = 0.264883816242218, train/logprobs = tensor([[-0.7589, -4.5643],
        [-1.0059, -0.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08691208064556122
Epoch 0, Step 1928: train/loss = 0.48259082436561584, train/raw-loss = 0.4194861054420471, train/logprobs = tensor([[-0.4244, -3.2131],
        [-0.7905, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06310468912124634
Epoch 0, Step 1929: train/loss = 0.40697187185287476, train/raw-loss = 0.33920422196388245, train/logprobs = tensor([[-0.4550, -3.8547],
        [-0.8177, -0.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0677676647901535
Epoch 0, Step 1930: train/loss = 0.5405596494674683, train/raw-loss = 0.4798845648765564, train/logprobs = tensor([[-0.6026, -3.1446],
        [-0.4971, -0.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06067501753568649
Epoch 0, Step 1931: train/loss = 0.6305213570594788, train/raw-loss = 0.5605605840682983, train/logprobs = tensor([[-0.6398, -2.3915],
        [-0.7600, -0.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06996077299118042
Epoch 0, Step 1932: train/loss = 0.5705193281173706, train/raw-loss = 0.5054179430007935, train/logprobs = tensor([[-0.5734, -3.3720],
        [-1.0234, -0.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06510134786367416
Epoch 0, Step 1933: train/loss = 0.584497332572937, train/raw-loss = 0.5095933079719543, train/logprobs = tensor([[-0.9348, -2.5517],
        [-0.9298, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07490400969982147
Epoch 0, Step 1934: train/loss = 0.5760226845741272, train/raw-loss = 0.5048255920410156, train/logprobs = tensor([[-0.5876, -1.8004],
        [-0.7347, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07119707018136978
Epoch 0, Step 1935: train/loss = 0.3728557825088501, train/raw-loss = 0.2903996706008911, train/logprobs = tensor([[-0.6481, -3.8846],
        [-1.3727, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245611190795898
Epoch 0, Step 1936: train/loss = 0.33375656604766846, train/raw-loss = 0.2549257278442383, train/logprobs = tensor([[-0.4841, -7.8578],
        [-0.9182, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883081585168839
Epoch 0, Step 1937: train/loss = 0.6762439012527466, train/raw-loss = 0.61962890625, train/logprobs = tensor([[-0.9642, -1.1384],
        [-1.2621, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05661492794752121
Epoch 0, Step 1938: train/loss = 0.5819921493530273, train/raw-loss = 0.5015196800231934, train/logprobs = tensor([[-1.4468, -4.1500],
        [-1.0000, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08047246187925339
Epoch 0, Step 1939: train/loss = 0.5345063209533691, train/raw-loss = 0.4753537178039551, train/logprobs = tensor([[-0.5714, -2.1658],
        [-0.6553, -0.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05915262550115585
Epoch 0, Step 1940: train/loss = 0.5540679097175598, train/raw-loss = 0.4958358407020569, train/logprobs = tensor([[-0.7704, -5.1406],
        [-0.9209, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058232057839632034
Epoch 0, Step 1941: train/loss = 0.7005324363708496, train/raw-loss = 0.606175422668457, train/logprobs = tensor([[-1.1132, -1.8244],
        [-1.1412, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09435699135065079
Epoch 0, Step 1942: train/loss = 0.4689045548439026, train/raw-loss = 0.37225353717803955, train/logprobs = tensor([[-0.6942, -4.2626],
        [-1.2496, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09665101021528244
Epoch 0, Step 1943: train/loss = 0.3883001208305359, train/raw-loss = 0.298403799533844, train/logprobs = tensor([[-0.4947, -5.0650],
        [-1.0604, -0.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08989632874727249
Epoch 0, Step 1944: train/loss = 0.5800783038139343, train/raw-loss = 0.5144753456115723, train/logprobs = tensor([[-0.6701, -1.5657],
        [-0.8419, -0.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06560291349887848
Epoch 0, Step 1945: train/loss = 0.5255387425422668, train/raw-loss = 0.458609402179718, train/logprobs = tensor([[-0.4066, -1.7498],
        [-0.8230, -0.5387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06692934781312943
Epoch 0, Step 1946: train/loss = 0.6492774486541748, train/raw-loss = 0.5744172930717468, train/logprobs = tensor([[-1.3967, -4.1236],
        [-0.7034, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07486019283533096
Epoch 0, Step 1947: train/loss = 0.6602935194969177, train/raw-loss = 0.5985721945762634, train/logprobs = tensor([[-0.6612, -0.9290],
        [-0.7588, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0617213100194931
Epoch 0, Step 1948: train/loss = 0.4138185381889343, train/raw-loss = 0.35178667306900024, train/logprobs = tensor([[-0.4556, -4.7554],
        [-0.6030, -0.4602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06203186511993408
Epoch 0, Step 1949: train/loss = 0.46359407901763916, train/raw-loss = 0.40323615074157715, train/logprobs = tensor([[-0.5887, -3.5687],
        [-0.7938, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060357920825481415
Epoch 0, Step 1950: train/loss = 0.432991623878479, train/raw-loss = 0.3688531219959259, train/logprobs = tensor([[-0.6585, -6.1149],
        [-0.8472, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06413846462965012
Epoch 0, Step 1951: train/loss = 0.3917695879936218, train/raw-loss = 0.30973005294799805, train/logprobs = tensor([[-0.5591, -2.8386],
        [-1.2809, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08203952759504318
Epoch 0, Step 1952: train/loss = 0.45544248819351196, train/raw-loss = 0.37995287775993347, train/logprobs = tensor([[-0.5757, -2.6147],
        [-1.3736, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754895955324173
Epoch 0, Step 1953: train/loss = 0.42456644773483276, train/raw-loss = 0.3635599911212921, train/logprobs = tensor([[-0.6157, -6.5881],
        [-0.8175, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06100646033883095
Epoch 0, Step 1954: train/loss = 0.3577606976032257, train/raw-loss = 0.2878614664077759, train/logprobs = tensor([[-0.5852, -7.2856],
        [-1.0036, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06989924609661102
Epoch 0, Step 1955: train/loss = 0.4033624231815338, train/raw-loss = 0.3233158588409424, train/logprobs = tensor([[-1.2105, -4.6988],
        [-1.4694, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08004657924175262
Epoch 0, Step 1956: train/loss = 0.5133078098297119, train/raw-loss = 0.422951340675354, train/logprobs = tensor([[-0.5022, -3.8536],
        [-0.9185, -1.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09035643935203552
Epoch 0, Step 1957: train/loss = 0.48253870010375977, train/raw-loss = 0.39499431848526, train/logprobs = tensor([[-0.5497, -4.3980],
        [-1.2040, -0.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754440397024155
Epoch 0, Step 1958: train/loss = 0.3075854778289795, train/raw-loss = 0.22040553390979767, train/logprobs = tensor([[-0.8326, -9.7514],
        [-1.2803, -1.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08717995136976242
Epoch 0, Step 1959: train/loss = 0.3585702180862427, train/raw-loss = 0.26700156927108765, train/logprobs = tensor([[-0.5207, -7.6384],
        [-1.3014, -0.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09156865626573563
Epoch 0, Step 1960: train/loss = 0.38060563802719116, train/raw-loss = 0.2970682978630066, train/logprobs = tensor([[-0.5073, -5.0132],
        [-1.1442, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08353736996650696
Epoch 0, Step 1961: train/loss = 0.30573153495788574, train/raw-loss = 0.22557713091373444, train/logprobs = tensor([[-0.4785, -5.9938],
        [-0.9973, -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0801544189453125
Epoch 0, Step 1962: train/loss = 0.6586635708808899, train/raw-loss = 0.5810571908950806, train/logprobs = tensor([[-0.4956, -0.9289],
        [-0.6875, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07760637998580933
Epoch 0, Step 1963: train/loss = 0.4821595847606659, train/raw-loss = 0.4093145430088043, train/logprobs = tensor([[-0.5917, -5.1142],
        [-0.8490, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07284504175186157
Epoch 0, Step 1964: train/loss = 0.40245363116264343, train/raw-loss = 0.33786168694496155, train/logprobs = tensor([[-0.4151, -3.9373],
        [-0.7835, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06459196656942368
Epoch 0, Step 1965: train/loss = 0.5914353728294373, train/raw-loss = 0.5356188416481018, train/logprobs = tensor([[-0.4657, -1.2403],
        [-0.5410, -0.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05581651255488396
Epoch 0, Step 1966: train/loss = 0.2934148609638214, train/raw-loss = 0.21648168563842773, train/logprobs = tensor([[ -0.6068, -12.6310],
        [ -0.9833,  -1.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07693316042423248
Epoch 0, Step 1967: train/loss = 0.503921389579773, train/raw-loss = 0.42125242948532104, train/logprobs = tensor([[-0.9675, -3.6707],
        [-0.8668, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0826689600944519
Epoch 0, Step 1968: train/loss = 0.5739004015922546, train/raw-loss = 0.49412447214126587, train/logprobs = tensor([[-0.6252, -3.4130],
        [-0.9765, -0.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07977594435214996
Epoch 0, Step 1969: train/loss = 0.36957061290740967, train/raw-loss = 0.2842842936515808, train/logprobs = tensor([[-0.5976, -7.7798],
        [-1.2065, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08528628945350647
Epoch 0, Step 1970: train/loss = 0.3923034071922302, train/raw-loss = 0.3123764097690582, train/logprobs = tensor([[-0.6959, -6.0777],
        [-0.8744, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0799270048737526
Epoch 0, Step 1971: train/loss = 0.3946767747402191, train/raw-loss = 0.32476094365119934, train/logprobs = tensor([[-0.5045, -3.6811],
        [-0.9498, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06991580873727798
Epoch 0, Step 1972: train/loss = 0.3820953369140625, train/raw-loss = 0.27885299921035767, train/logprobs = tensor([[-0.6693, -3.7635],
        [-1.3567, -0.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10324232280254364
Epoch 0, Step 1973: train/loss = 0.38298583030700684, train/raw-loss = 0.2861890494823456, train/logprobs = tensor([[-0.6334, -4.0101],
        [-1.6504, -0.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09679679572582245
Epoch 0, Step 1974: train/loss = 0.3801439702510834, train/raw-loss = 0.2928001880645752, train/logprobs = tensor([[-0.5529, -4.2010],
        [-1.1335, -0.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08734378963708878
Epoch 0, Step 1975: train/loss = 0.5336126089096069, train/raw-loss = 0.47265100479125977, train/logprobs = tensor([[-0.6036, -2.8814],
        [-0.7868, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06096161901950836
Epoch 0, Step 1976: train/loss = 0.39283663034439087, train/raw-loss = 0.316221684217453, train/logprobs = tensor([[-0.6830, -5.4720],
        [-0.9917, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07661494612693787
Epoch 0, Step 1977: train/loss = 0.25927144289016724, train/raw-loss = 0.1847388595342636, train/logprobs = tensor([[ -0.5780, -10.2121],
        [ -1.2957,  -1.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07453260570764542
Epoch 0, Step 1978: train/loss = 0.41438835859298706, train/raw-loss = 0.32983195781707764, train/logprobs = tensor([[-0.5261, -3.7926],
        [-0.8817, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08455638587474823
Epoch 0, Step 1979: train/loss = 0.4783594310283661, train/raw-loss = 0.3926376700401306, train/logprobs = tensor([[-0.5820, -3.8446],
        [-1.0293, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08572175353765488
Epoch 0, Step 1980: train/loss = 0.418110191822052, train/raw-loss = 0.34313490986824036, train/logprobs = tensor([[-0.8611, -3.1329],
        [-1.1791, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07497530430555344
Epoch 0, Step 1981: train/loss = 0.3169861137866974, train/raw-loss = 0.22549378871917725, train/logprobs = tensor([[-0.5162, -5.7873],
        [-1.3152, -1.3286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09149231761693954
Epoch 0, Step 1982: train/loss = 0.5482345223426819, train/raw-loss = 0.47885650396347046, train/logprobs = tensor([[-0.7491, -1.5464],
        [-0.9699, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06937801837921143
Epoch 0, Step 1983: train/loss = 0.5828923583030701, train/raw-loss = 0.5218411684036255, train/logprobs = tensor([[-0.4265, -1.2418],
        [-0.6399, -0.4942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06105118617415428
Epoch 0, Step 1984: train/loss = 0.32457345724105835, train/raw-loss = 0.24576354026794434, train/logprobs = tensor([[-0.8173, -6.3008],
        [-1.1188, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07880990952253342
Epoch 0, Step 1985: train/loss = 0.5486846566200256, train/raw-loss = 0.481812447309494, train/logprobs = tensor([[-0.6267, -3.0201],
        [-0.7893, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06687220931053162
Epoch 0, Step 1986: train/loss = 0.6314788460731506, train/raw-loss = 0.5668096542358398, train/logprobs = tensor([[-0.7898, -2.8868],
        [-0.6957, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0646691620349884
Epoch 0, Step 1987: train/loss = 0.5510398149490356, train/raw-loss = 0.48568353056907654, train/logprobs = tensor([[-0.9805, -3.9593],
        [-0.9496, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06535626947879791
Epoch 0, Step 1988: train/loss = 0.5720633268356323, train/raw-loss = 0.516211986541748, train/logprobs = tensor([[-0.3455, -3.1494],
        [-0.6034, -0.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05585131794214249
Epoch 0, Step 1989: train/loss = 0.4713734984397888, train/raw-loss = 0.40774238109588623, train/logprobs = tensor([[-0.5915, -3.1918],
        [-0.5566, -0.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363112479448318
Epoch 0, Step 1990: train/loss = 0.31596267223358154, train/raw-loss = 0.23721414804458618, train/logprobs = tensor([[ -0.5113, -11.3436],
        [ -1.0489,  -1.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07874852418899536
Epoch 0, Step 1991: train/loss = 0.4264662563800812, train/raw-loss = 0.340133935213089, train/logprobs = tensor([[-0.5484, -5.3902],
        [-1.0888, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.086332306265831
Epoch 0, Step 1992: train/loss = 0.5487165451049805, train/raw-loss = 0.4504590630531311, train/logprobs = tensor([[-0.7357, -3.4060],
        [-0.8688, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09825749695301056
Epoch 0, Step 1993: train/loss = 0.5245818495750427, train/raw-loss = 0.45245879888534546, train/logprobs = tensor([[-0.7093, -3.1359],
        [-0.7831, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07212307304143906
Epoch 0, Step 1994: train/loss = 0.4560562074184418, train/raw-loss = 0.3823608160018921, train/logprobs = tensor([[-0.5110, -2.9999],
        [-1.0667, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07369542866945267
Epoch 0, Step 1995: train/loss = 0.3763425052165985, train/raw-loss = 0.2982061505317688, train/logprobs = tensor([[-0.5542, -3.6550],
        [-1.1908, -0.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07813633233308792
Epoch 0, Step 1996: train/loss = 0.4942637085914612, train/raw-loss = 0.4344789981842041, train/logprobs = tensor([[-0.6244, -1.8003],
        [-1.1163, -0.5703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059784699231386185
Epoch 0, Step 1997: train/loss = 0.4746016263961792, train/raw-loss = 0.3850134313106537, train/logprobs = tensor([[-0.5966, -4.8043],
        [-0.9652, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958818018436432
Epoch 0, Step 1998: train/loss = 0.6233526468276978, train/raw-loss = 0.5500537753105164, train/logprobs = tensor([[-0.5651, -1.6732],
        [-0.8078, -0.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07329890131950378
Epoch 0, Step 1999: train/loss = 0.6845801472663879, train/raw-loss = 0.6277382373809814, train/logprobs = tensor([[-1.2158, -1.8188],
        [-0.7432, -0.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0568418875336647
Epoch 0, Step 2000: train/loss = 0.5460444092750549, train/raw-loss = 0.48368263244628906, train/logprobs = tensor([[-0.5721, -1.9775],
        [-0.6046, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06236179918050766
Epoch 0, Step 2001: train/loss = 0.5735347270965576, train/raw-loss = 0.49904733896255493, train/logprobs = tensor([[-0.6395, -1.4902],
        [-0.8452, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07448737323284149
Epoch 0, Step 2002: train/loss = 0.42046651244163513, train/raw-loss = 0.352152943611145, train/logprobs = tensor([[-0.6801, -5.6049],
        [-0.8627, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06831354647874832
Epoch 0, Step 2003: train/loss = 0.44039759039878845, train/raw-loss = 0.34544992446899414, train/logprobs = tensor([[-0.9016, -4.0271],
        [-1.1690, -0.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09494763612747192
Epoch 0, Step 2004: train/loss = 0.33467233180999756, train/raw-loss = 0.2589509189128876, train/logprobs = tensor([[-0.4156, -7.2506],
        [-0.8239, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07572142779827118
Epoch 0, Step 2005: train/loss = 0.28296366333961487, train/raw-loss = 0.1910075694322586, train/logprobs = tensor([[-0.6420, -7.3400],
        [-1.5758, -0.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09195608645677567
Epoch 0, Step 2006: train/loss = 0.42238330841064453, train/raw-loss = 0.3569642901420593, train/logprobs = tensor([[-0.4972, -8.6001],
        [-0.6400, -1.0902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06541900336742401
Epoch 0, Step 2007: train/loss = 0.4780142903327942, train/raw-loss = 0.40476545691490173, train/logprobs = tensor([[-0.3798, -2.1364],
        [-0.7129, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07324881851673126
Epoch 0, Step 2008: train/loss = 0.48998063802719116, train/raw-loss = 0.43236786127090454, train/logprobs = tensor([[-0.6925, -4.1795],
        [-1.0371, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057612769305706024
Epoch 0, Step 2009: train/loss = 0.618553876876831, train/raw-loss = 0.5367030501365662, train/logprobs = tensor([[-1.2045, -3.9554],
        [-0.6675, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08185083419084549
Epoch 0, Step 2010: train/loss = 0.41396820545196533, train/raw-loss = 0.3327915072441101, train/logprobs = tensor([[-0.7511, -4.8026],
        [-1.0123, -0.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08117666840553284
Epoch 0, Step 2011: train/loss = 0.39860689640045166, train/raw-loss = 0.32983848452568054, train/logprobs = tensor([[-0.4951, -2.9122],
        [-0.9431, -0.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876841932535172
Epoch 0, Step 2012: train/loss = 0.5266356468200684, train/raw-loss = 0.45898935198783875, train/logprobs = tensor([[-0.5968, -2.8559],
        [-0.7794, -0.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06764627248048782
Epoch 0, Step 2013: train/loss = 0.6231638789176941, train/raw-loss = 0.566121518611908, train/logprobs = tensor([[-0.5333, -0.8686],
        [-0.7903, -0.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05704236030578613
Epoch 0, Step 2014: train/loss = 0.5261777639389038, train/raw-loss = 0.4422849416732788, train/logprobs = tensor([[-1.1779, -6.0209],
        [-1.4185, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08389284461736679
Epoch 0, Step 2015: train/loss = 0.5789202451705933, train/raw-loss = 0.5167276859283447, train/logprobs = tensor([[-0.5146, -1.6233],
        [-0.6529, -0.6769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06219255179166794
Epoch 0, Step 2016: train/loss = 0.4639573097229004, train/raw-loss = 0.3794386386871338, train/logprobs = tensor([[-0.9096, -3.1368],
        [-1.0376, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08451862633228302
Epoch 0, Step 2017: train/loss = 0.334139883518219, train/raw-loss = 0.2515012323856354, train/logprobs = tensor([[-0.6787, -5.2868],
        [-0.9532, -0.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08263865858316422
Epoch 0, Step 2018: train/loss = 0.3531179428100586, train/raw-loss = 0.2646373510360718, train/logprobs = tensor([[-0.5558, -6.4386],
        [-1.2549, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08848059177398682
Epoch 0, Step 2019: train/loss = 0.400882750749588, train/raw-loss = 0.3374377489089966, train/logprobs = tensor([[-0.4441, -3.3108],
        [-0.6226, -0.8133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06344498693943024
Epoch 0, Step 2020: train/loss = 0.6791905164718628, train/raw-loss = 0.6139494180679321, train/logprobs = tensor([[-0.9223, -1.2697],
        [-0.8125, -0.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06524111330509186
Epoch 0, Step 2021: train/loss = 0.5367339849472046, train/raw-loss = 0.47812145948410034, train/logprobs = tensor([[-0.3143, -3.8258],
        [-0.4569, -0.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05861247703433037
Epoch 0, Step 2022: train/loss = 0.5553901195526123, train/raw-loss = 0.47521865367889404, train/logprobs = tensor([[-0.5111, -2.0673],
        [-1.1615, -0.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08017146587371826
Epoch 0, Step 2023: train/loss = 0.4103049039840698, train/raw-loss = 0.32668519020080566, train/logprobs = tensor([[-0.6829, -4.3738],
        [-1.5440, -0.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08361969143152237
Epoch 0, Step 2024: train/loss = 0.26423180103302, train/raw-loss = 0.1813153773546219, train/logprobs = tensor([[-0.6132, -7.6023],
        [-1.3008, -1.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08291642367839813
Epoch 0, Step 2025: train/loss = 0.5605635643005371, train/raw-loss = 0.48479366302490234, train/logprobs = tensor([[-1.0083, -5.9191],
        [-0.9919, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07576988637447357
Epoch 0, Step 2026: train/loss = 0.32836663722991943, train/raw-loss = 0.2431235909461975, train/logprobs = tensor([[-0.4380, -5.0270],
        [-0.9352, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08524303883314133
Epoch 0, Step 2027: train/loss = 0.4060410261154175, train/raw-loss = 0.33506959676742554, train/logprobs = tensor([[-0.4079, -2.7525],
        [-0.6785, -0.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07097138464450836
Epoch 0, Step 2028: train/loss = 0.4333760142326355, train/raw-loss = 0.3678741753101349, train/logprobs = tensor([[-0.6149, -3.7432],
        [-1.0062, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06550181657075882
Epoch 0, Step 2029: train/loss = 0.6150664687156677, train/raw-loss = 0.550586462020874, train/logprobs = tensor([[-0.5563, -1.0607],
        [-0.6380, -0.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448006629943848
Epoch 0, Step 2030: train/loss = 0.3938257694244385, train/raw-loss = 0.315064936876297, train/logprobs = tensor([[-0.4159, -4.3087],
        [-0.9150, -0.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07876087725162506
Epoch 0, Step 2031: train/loss = 0.6919925212860107, train/raw-loss = 0.6368745565414429, train/logprobs = tensor([[-0.4468, -0.6190],
        [-0.5607, -0.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055117931216955185
Epoch 0, Step 2032: train/loss = 0.449735164642334, train/raw-loss = 0.3791870176792145, train/logprobs = tensor([[-0.9686, -3.8544],
        [-1.0160, -0.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0705481469631195
Epoch 0, Step 2033: train/loss = 0.7446118593215942, train/raw-loss = 0.6919881105422974, train/logprobs = tensor([[-1.0255, -1.0508],
        [-0.5810, -0.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0526236928999424
Epoch 0, Step 2034: train/loss = 0.5060573816299438, train/raw-loss = 0.4414672553539276, train/logprobs = tensor([[-0.5360, -2.5140],
        [-0.6759, -0.5327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06459012627601624
Epoch 0, Step 2035: train/loss = 0.4990692734718323, train/raw-loss = 0.43762779235839844, train/logprobs = tensor([[-0.7897, -3.4173],
        [-0.8913, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061441466212272644
Epoch 0, Step 2036: train/loss = 0.34649431705474854, train/raw-loss = 0.2532002329826355, train/logprobs = tensor([[-0.6184, -8.3166],
        [-1.0789, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09329411387443542
Epoch 0, Step 2037: train/loss = 0.37658828496932983, train/raw-loss = 0.3054412007331848, train/logprobs = tensor([[-0.5788, -5.6368],
        [-0.7360, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07114707678556442
Epoch 0, Step 2038: train/loss = 0.4731307029724121, train/raw-loss = 0.3784411549568176, train/logprobs = tensor([[-0.6748, -3.9217],
        [-0.9921, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09468955546617508
Epoch 0, Step 2039: train/loss = 0.45964688062667847, train/raw-loss = 0.38849347829818726, train/logprobs = tensor([[-0.6632, -3.0049],
        [-0.9944, -0.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07115337997674942
Epoch 0, Step 2040: train/loss = 0.48486679792404175, train/raw-loss = 0.4262338876724243, train/logprobs = tensor([[-0.8760, -3.3798],
        [-0.9130, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05863293632864952
Epoch 0, Step 2041: train/loss = 0.34587958455085754, train/raw-loss = 0.27494847774505615, train/logprobs = tensor([[-0.4211, -6.0816],
        [-1.1695, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07093110680580139
Epoch 0, Step 2042: train/loss = 0.36948803067207336, train/raw-loss = 0.2890926003456116, train/logprobs = tensor([[-0.4820, -5.6267],
        [-0.9574, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08039540797472
Epoch 0, Step 2043: train/loss = 0.5117128491401672, train/raw-loss = 0.44333481788635254, train/logprobs = tensor([[-0.6659, -7.3086],
        [-0.9358, -1.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683780312538147
Epoch 0, Step 2044: train/loss = 0.6019909977912903, train/raw-loss = 0.5002343058586121, train/logprobs = tensor([[-1.7399, -2.8530],
        [-1.9132, -0.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10175667703151703
Epoch 0, Step 2045: train/loss = 0.6008263230323792, train/raw-loss = 0.5401164293289185, train/logprobs = tensor([[-0.4743, -1.0663],
        [-0.7280, -0.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0607098788022995
Epoch 0, Step 2046: train/loss = 0.3022160530090332, train/raw-loss = 0.24523641169071198, train/logprobs = tensor([[-0.3102, -7.2019],
        [-0.5125, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05697965994477272
Epoch 0, Step 2047: train/loss = 0.4553823471069336, train/raw-loss = 0.3562970757484436, train/logprobs = tensor([[-1.3553, -4.3520],
        [-1.6763, -0.7030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09908530116081238
Epoch 0, Step 2048: train/loss = 0.4278606176376343, train/raw-loss = 0.36072245240211487, train/logprobs = tensor([[-0.5548, -5.1689],
        [-0.7245, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06713816523551941
Epoch 0, Step 2049: train/loss = 0.43536874651908875, train/raw-loss = 0.3482576012611389, train/logprobs = tensor([[-0.9426, -3.3391],
        [-1.2170, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08711113035678864
Epoch 0, Step 2050: train/loss = 0.32819435000419617, train/raw-loss = 0.2341511845588684, train/logprobs = tensor([[-0.5242, -3.8976],
        [-1.0955, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09404316544532776
Epoch 0, Step 2051: train/loss = 0.3968188166618347, train/raw-loss = 0.32201993465423584, train/logprobs = tensor([[-0.4305, -6.1935],
        [-0.8730, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07479889690876007
Epoch 0, Step 2052: train/loss = 0.4882752299308777, train/raw-loss = 0.3807404041290283, train/logprobs = tensor([[-0.7248, -1.8737],
        [-1.6762, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10753485560417175
Epoch 0, Step 2053: train/loss = 0.5410372018814087, train/raw-loss = 0.4508183002471924, train/logprobs = tensor([[-1.1792, -3.5910],
        [-0.8275, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09021887183189392
Epoch 0, Step 2054: train/loss = 0.5890500545501709, train/raw-loss = 0.5186033248901367, train/logprobs = tensor([[-0.6284, -1.1026],
        [-0.9998, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044675946235657
Epoch 0, Step 2055: train/loss = 0.506686270236969, train/raw-loss = 0.446053147315979, train/logprobs = tensor([[-0.8414, -3.6759],
        [-0.6777, -0.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06063314899802208
Epoch 0, Step 2056: train/loss = 0.48400580883026123, train/raw-loss = 0.4116521179676056, train/logprobs = tensor([[-0.7092, -1.4801],
        [-1.5872, -0.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07235366106033325
Epoch 0, Step 2057: train/loss = 0.5414462089538574, train/raw-loss = 0.46146759390830994, train/logprobs = tensor([[-0.4287, -1.5164],
        [-0.9962, -0.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07997862249612808
Epoch 0, Step 2058: train/loss = 0.3315543532371521, train/raw-loss = 0.22919662296772003, train/logprobs = tensor([[-0.6198, -5.8142],
        [-1.4179, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10235774517059326
Epoch 0, Step 2059: train/loss = 0.382901668548584, train/raw-loss = 0.29213446378707886, train/logprobs = tensor([[-0.4946, -6.9233],
        [-1.0539, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09076720476150513
Epoch 0, Step 2060: train/loss = 0.47555011510849, train/raw-loss = 0.39903563261032104, train/logprobs = tensor([[-0.7672, -2.7001],
        [-0.8974, -0.6436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07651445269584656
Epoch 0, Step 2061: train/loss = 0.4119183123111725, train/raw-loss = 0.3312625586986542, train/logprobs = tensor([[-0.5989, -5.1352],
        [-1.2800, -0.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08065573871135712
Epoch 0, Step 2062: train/loss = 0.4513590335845947, train/raw-loss = 0.3466641902923584, train/logprobs = tensor([[-0.6920, -2.9091],
        [-1.1079, -0.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10469484329223633
Epoch 0, Step 2063: train/loss = 0.47324445843696594, train/raw-loss = 0.39294514060020447, train/logprobs = tensor([[-0.5144, -2.3151],
        [-1.0948, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08029931783676147
Epoch 0, Step 2064: train/loss = 0.554319441318512, train/raw-loss = 0.46728044748306274, train/logprobs = tensor([[-1.0816, -2.4626],
        [-1.0284, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703899383544922
Epoch 0, Step 2065: train/loss = 0.35556522011756897, train/raw-loss = 0.277621865272522, train/logprobs = tensor([[-0.5891, -8.6033],
        [-0.9637, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07794337719678879
Epoch 0, Step 2066: train/loss = 0.4632367491722107, train/raw-loss = 0.38423532247543335, train/logprobs = tensor([[-0.6001, -3.8336],
        [-0.8138, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07900146394968033
Epoch 0, Step 2067: train/loss = 0.5515606999397278, train/raw-loss = 0.47329795360565186, train/logprobs = tensor([[-0.8077, -3.4095],
        [-0.8852, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07826277613639832
Epoch 0, Step 2068: train/loss = 0.5767880082130432, train/raw-loss = 0.4970439672470093, train/logprobs = tensor([[-0.6499, -3.0231],
        [-0.9089, -0.7446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07974400371313095
Epoch 0, Step 2069: train/loss = 0.5394295454025269, train/raw-loss = 0.4708164930343628, train/logprobs = tensor([[-0.5346, -2.5579],
        [-0.9148, -0.8680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06861305236816406
Epoch 0, Step 2070: train/loss = 0.2877691984176636, train/raw-loss = 0.20137441158294678, train/logprobs = tensor([[-0.7076, -7.2200],
        [-1.5213, -0.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0863947942852974
Epoch 0, Step 2071: train/loss = 0.5201383233070374, train/raw-loss = 0.4456250071525574, train/logprobs = tensor([[-0.6359, -2.6181],
        [-0.8223, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07451333105564117
Epoch 0, Step 2072: train/loss = 0.38224178552627563, train/raw-loss = 0.29404008388519287, train/logprobs = tensor([[-0.5771, -4.8154],
        [-1.0586, -0.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08820170164108276
Epoch 0, Step 2073: train/loss = 0.42019540071487427, train/raw-loss = 0.3361428678035736, train/logprobs = tensor([[-0.6576, -3.2717],
        [-0.9705, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08405251055955887
Epoch 0, Step 2074: train/loss = 0.5325009822845459, train/raw-loss = 0.46489980816841125, train/logprobs = tensor([[-0.5201, -1.8688],
        [-0.9782, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06760117411613464
Epoch 0, Step 2075: train/loss = 0.5816097855567932, train/raw-loss = 0.5001638531684875, train/logprobs = tensor([[-0.6445, -1.8646],
        [-0.8944, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08144594728946686
Epoch 0, Step 2076: train/loss = 0.4665182828903198, train/raw-loss = 0.3881458640098572, train/logprobs = tensor([[-1.1804, -6.8379],
        [-1.1612, -1.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07837244868278503
Epoch 0, Step 2077: train/loss = 0.4188612401485443, train/raw-loss = 0.3403397798538208, train/logprobs = tensor([[-0.5687, -4.5411],
        [-0.8329, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07852145284414291
Epoch 0, Step 2078: train/loss = 0.3934028744697571, train/raw-loss = 0.31200140714645386, train/logprobs = tensor([[-0.6539, -3.3756],
        [-1.1568, -0.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140144497156143
Epoch 0, Step 2079: train/loss = 0.44151371717453003, train/raw-loss = 0.371237188577652, train/logprobs = tensor([[-0.5196, -3.9287],
        [-0.6925, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07027655094861984
Epoch 0, Step 2080: train/loss = 0.36672934889793396, train/raw-loss = 0.28916338086128235, train/logprobs = tensor([[-0.7173, -4.7572],
        [-1.2825, -0.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07756595313549042
Epoch 0, Step 2081: train/loss = 0.4191158413887024, train/raw-loss = 0.3305632472038269, train/logprobs = tensor([[-0.7299, -2.2670],
        [-1.4753, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885525643825531
Epoch 0, Step 2082: train/loss = 0.37621456384658813, train/raw-loss = 0.29164934158325195, train/logprobs = tensor([[-0.6081, -9.4349],
        [-1.0219, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0845651924610138
Epoch 0, Step 2083: train/loss = 0.515894889831543, train/raw-loss = 0.4458024203777313, train/logprobs = tensor([[-0.6737, -1.7241],
        [-1.0290, -0.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07009248435497284
Epoch 0, Step 2084: train/loss = 0.3367063105106354, train/raw-loss = 0.2592894434928894, train/logprobs = tensor([[-0.6330, -5.9632],
        [-1.4630, -0.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07741682976484299
Epoch 0, Step 2085: train/loss = 0.5230312943458557, train/raw-loss = 0.472299724817276, train/logprobs = tensor([[-0.7349, -2.7552],
        [-0.8215, -1.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05073154345154762
Epoch 0, Step 2086: train/loss = 0.45862579345703125, train/raw-loss = 0.3949909508228302, train/logprobs = tensor([[-0.4004, -2.4874],
        [-0.6285, -0.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363479793071747
Epoch 0, Step 2087: train/loss = 0.2669718563556671, train/raw-loss = 0.1799463927745819, train/logprobs = tensor([[ -0.7436, -12.2531],
        [ -1.3979,  -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08702544122934341
Epoch 0, Step 2088: train/loss = 0.44991418719291687, train/raw-loss = 0.38279324769973755, train/logprobs = tensor([[-0.3965, -6.8634],
        [-1.0025, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06712095439434052
Epoch 0, Step 2089: train/loss = 0.6036583185195923, train/raw-loss = 0.5246280431747437, train/logprobs = tensor([[-0.9923, -2.2076],
        [-0.8148, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07903028279542923
Epoch 0, Step 2090: train/loss = 0.589813768863678, train/raw-loss = 0.5195077657699585, train/logprobs = tensor([[-1.1236, -2.2313],
        [-0.9882, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07030598819255829
Epoch 0, Step 2091: train/loss = 0.47115787863731384, train/raw-loss = 0.4108046293258667, train/logprobs = tensor([[-0.5564, -2.6540],
        [-0.6745, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060353271663188934
Epoch 0, Step 2092: train/loss = 0.3004801273345947, train/raw-loss = 0.21404173970222473, train/logprobs = tensor([[-0.5056, -5.1421],
        [-1.0424, -0.7446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08643839508295059
Epoch 0, Step 2093: train/loss = 0.6063283681869507, train/raw-loss = 0.5262171030044556, train/logprobs = tensor([[-1.6086, -3.9355],
        [-1.1826, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08011122047901154
Epoch 0, Step 2094: train/loss = 0.36542177200317383, train/raw-loss = 0.288330614566803, train/logprobs = tensor([[-0.4143, -7.3776],
        [-0.9908, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07709112763404846
Epoch 0, Step 2095: train/loss = 0.5665621757507324, train/raw-loss = 0.4846046566963196, train/logprobs = tensor([[-0.6264, -3.4807],
        [-1.0351, -0.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08195751160383224
Epoch 0, Step 2096: train/loss = 0.5183091163635254, train/raw-loss = 0.44721007347106934, train/logprobs = tensor([[-0.9016, -6.1076],
        [-1.0301, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109911739826202
Epoch 0, Step 2097: train/loss = 0.5253541469573975, train/raw-loss = 0.44706639647483826, train/logprobs = tensor([[-0.5098, -3.6552],
        [-0.9273, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.078287772834301
Epoch 0, Step 2098: train/loss = 0.29609787464141846, train/raw-loss = 0.19835993647575378, train/logprobs = tensor([[-0.6014, -5.3679],
        [-1.2668, -1.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773795306682587
Epoch 0, Step 2099: train/loss = 0.4027147889137268, train/raw-loss = 0.31554752588272095, train/logprobs = tensor([[-0.6097, -5.0022],
        [-0.7952, -0.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08716726303100586
Epoch 0, Step 2100: train/loss = 0.5975627303123474, train/raw-loss = 0.5173752903938293, train/logprobs = tensor([[-0.5258, -1.1947],
        [-0.8561, -0.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08018743991851807
Epoch 0, Step 2101: train/loss = 0.5151621103286743, train/raw-loss = 0.4380894899368286, train/logprobs = tensor([[-0.5901, -2.4404],
        [-0.9395, -0.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07707265019416809
Epoch 0, Step 2102: train/loss = 0.3977162837982178, train/raw-loss = 0.3338480591773987, train/logprobs = tensor([[-0.7274, -5.6806],
        [-0.8093, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06386825442314148
Epoch 0, Step 2103: train/loss = 0.43080276250839233, train/raw-loss = 0.34937891364097595, train/logprobs = tensor([[-0.6224, -4.8987],
        [-0.8760, -0.5537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08142387121915817
Epoch 0, Step 2104: train/loss = 0.49608057737350464, train/raw-loss = 0.42335912585258484, train/logprobs = tensor([[-0.5112, -1.6512],
        [-1.0222, -0.5225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07272142916917801
Epoch 0, Step 2105: train/loss = 0.5201138257980347, train/raw-loss = 0.43011802434921265, train/logprobs = tensor([[-0.6875, -2.7653],
        [-0.9962, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08999579399824142
Epoch 0, Step 2106: train/loss = 0.5721457600593567, train/raw-loss = 0.4983927011489868, train/logprobs = tensor([[-0.4661, -1.6195],
        [-0.6778, -0.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07375301420688629
Epoch 0, Step 2107: train/loss = 0.5051294565200806, train/raw-loss = 0.43879464268684387, train/logprobs = tensor([[-0.8734, -2.0534],
        [-1.0403, -0.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0663348138332367
Epoch 0, Step 2108: train/loss = 0.3863305449485779, train/raw-loss = 0.3207491636276245, train/logprobs = tensor([[-0.5687, -5.9573],
        [-0.8722, -0.9899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06558135896921158
Epoch 0, Step 2109: train/loss = 0.47120267152786255, train/raw-loss = 0.41161462664604187, train/logprobs = tensor([[ -0.4679, -11.4812],
        [ -0.6992,  -1.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059588052332401276
Epoch 0, Step 2110: train/loss = 0.526160717010498, train/raw-loss = 0.4611574411392212, train/logprobs = tensor([[-0.9799, -3.3025],
        [-1.2200, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06500326097011566
Epoch 0, Step 2111: train/loss = 0.4368039071559906, train/raw-loss = 0.3342586159706116, train/logprobs = tensor([[-0.5863, -2.9168],
        [-1.2124, -0.9344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10254531353712082
Epoch 0, Step 2112: train/loss = 0.3886059522628784, train/raw-loss = 0.3130863308906555, train/logprobs = tensor([[-0.5427, -3.8855],
        [-1.1088, -0.9614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07551965862512589
Epoch 0, Step 2113: train/loss = 0.4580722451210022, train/raw-loss = 0.3694643974304199, train/logprobs = tensor([[-0.5660, -7.9740],
        [-1.2831, -1.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08860787749290466
Epoch 0, Step 2114: train/loss = 0.32321780920028687, train/raw-loss = 0.2434830665588379, train/logprobs = tensor([[-0.5573, -6.2577],
        [-0.8151, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07973474264144897
Epoch 0, Step 2115: train/loss = 0.26146790385246277, train/raw-loss = 0.17913885414600372, train/logprobs = tensor([[-0.5469, -7.7452],
        [-1.3180, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08232903480529785
Epoch 0, Step 2116: train/loss = 0.3513922691345215, train/raw-loss = 0.25614064931869507, train/logprobs = tensor([[-0.9379, -5.6904],
        [-1.6309, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09525159001350403
Epoch 0, Step 2117: train/loss = 0.58101886510849, train/raw-loss = 0.5227135419845581, train/logprobs = tensor([[-0.3687, -4.1510],
        [-0.6271, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058305300772190094
Epoch 0, Step 2118: train/loss = 0.44260239601135254, train/raw-loss = 0.3637423813343048, train/logprobs = tensor([[-0.5590, -6.4424],
        [-0.7968, -1.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07886002212762833
Epoch 0, Step 2119: train/loss = 0.37716925144195557, train/raw-loss = 0.2958478629589081, train/logprobs = tensor([[-0.5832, -3.1458],
        [-1.1591, -0.3810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08132138848304749
Epoch 0, Step 2120: train/loss = 0.8710867166519165, train/raw-loss = 0.7904139757156372, train/logprobs = tensor([[-1.8334, -1.8027],
        [-0.9751, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08067277073860168
Epoch 0, Step 2121: train/loss = 0.6855366826057434, train/raw-loss = 0.6026139855384827, train/logprobs = tensor([[-1.3535, -3.7514],
        [-0.8520, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08292275667190552
Epoch 0, Step 2122: train/loss = 0.3940635621547699, train/raw-loss = 0.3196841776371002, train/logprobs = tensor([[-0.9218, -4.0906],
        [-1.2473, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437938451766968
Epoch 0, Step 2123: train/loss = 0.4898340404033661, train/raw-loss = 0.4104953408241272, train/logprobs = tensor([[-1.0777, -4.8385],
        [-1.1110, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793386846780777
Epoch 0, Step 2124: train/loss = 0.4007417559623718, train/raw-loss = 0.311482310295105, train/logprobs = tensor([[-0.7520, -3.9499],
        [-1.1795, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08925947546958923
Epoch 0, Step 2125: train/loss = 0.4021174907684326, train/raw-loss = 0.3298533260822296, train/logprobs = tensor([[-0.5517, -2.8245],
        [-0.8831, -0.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07226414978504181
Epoch 0, Step 2126: train/loss = 0.4709812104701996, train/raw-loss = 0.40168216824531555, train/logprobs = tensor([[-0.4515, -2.1283],
        [-1.1185, -0.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06929901242256165
Epoch 0, Step 2127: train/loss = 0.3614749312400818, train/raw-loss = 0.2689511179924011, train/logprobs = tensor([[-1.4206, -7.6930],
        [-1.7022, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09252382069826126
Epoch 0, Step 2128: train/loss = 0.4102160930633545, train/raw-loss = 0.33656245470046997, train/logprobs = tensor([[-0.7707, -4.4718],
        [-1.1454, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365360856056213
Epoch 0, Step 2129: train/loss = 0.43689459562301636, train/raw-loss = 0.3667229413986206, train/logprobs = tensor([[-0.3695, -4.1827],
        [-0.7004, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07017160207033157
Epoch 0, Step 2130: train/loss = 0.4920547306537628, train/raw-loss = 0.4107392430305481, train/logprobs = tensor([[-0.7290, -2.3527],
        [-0.9882, -0.7794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08131551742553711
Epoch 0, Step 2131: train/loss = 0.4362756013870239, train/raw-loss = 0.3558480739593506, train/logprobs = tensor([[-0.6234, -2.7996],
        [-0.8834, -0.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08042755722999573
Epoch 0, Step 2132: train/loss = 0.4845821261405945, train/raw-loss = 0.4024721682071686, train/logprobs = tensor([[-0.9477, -5.3885],
        [-1.1401, -0.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0821099653840065
Epoch 0, Step 2133: train/loss = 0.477966845035553, train/raw-loss = 0.4098798632621765, train/logprobs = tensor([[-0.6081, -3.8338],
        [-0.6972, -0.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06808698177337646
Epoch 0, Step 2134: train/loss = 0.5080921649932861, train/raw-loss = 0.40068739652633667, train/logprobs = tensor([[-1.1181, -4.9452],
        [-0.9986, -0.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10740475356578827
Epoch 0, Step 2135: train/loss = 0.43605709075927734, train/raw-loss = 0.36043787002563477, train/logprobs = tensor([[-0.3686, -4.6215],
        [-1.0501, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756191834807396
Epoch 0, Step 2136: train/loss = 0.4102749526500702, train/raw-loss = 0.3160436153411865, train/logprobs = tensor([[-0.5798, -4.0379],
        [-1.0421, -0.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09423135966062546
Epoch 0, Step 2137: train/loss = 0.4420085549354553, train/raw-loss = 0.3527429699897766, train/logprobs = tensor([[-0.6040, -3.3163],
        [-0.9723, -0.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08926554769277573
Epoch 0, Step 2138: train/loss = 0.28129246830940247, train/raw-loss = 0.20245125889778137, train/logprobs = tensor([[-0.8101, -6.2368],
        [-1.7184, -1.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0788412019610405
Epoch 0, Step 2139: train/loss = 0.3930349349975586, train/raw-loss = 0.31116190552711487, train/logprobs = tensor([[-0.5716, -4.8389],
        [-1.2238, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08187302947044373
Epoch 0, Step 2140: train/loss = 0.4495846927165985, train/raw-loss = 0.38892000913619995, train/logprobs = tensor([[-0.6343, -3.3682],
        [-0.8191, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060664642602205276
Epoch 0, Step 2141: train/loss = 0.8574506640434265, train/raw-loss = 0.777470588684082, train/logprobs = tensor([[-2.9914, -4.2890],
        [-1.4635, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07998005300760269
Epoch 0, Step 2142: train/loss = 0.3357120454311371, train/raw-loss = 0.24218133091926575, train/logprobs = tensor([[-0.5863, -4.7319],
        [-1.4857, -0.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09353072941303253
Epoch 0, Step 2143: train/loss = 0.47879379987716675, train/raw-loss = 0.40249258279800415, train/logprobs = tensor([[-0.5652, -3.1854],
        [-0.7787, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0763012245297432
Epoch 0, Step 2144: train/loss = 0.5370266437530518, train/raw-loss = 0.46135926246643066, train/logprobs = tensor([[-0.7365, -1.9717],
        [-0.8110, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07566739618778229
Epoch 0, Step 2145: train/loss = 0.523760199546814, train/raw-loss = 0.46099311113357544, train/logprobs = tensor([[-0.4210, -1.6958],
        [-0.5922, -0.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06276708096265793
Epoch 0, Step 2146: train/loss = 0.4689563512802124, train/raw-loss = 0.38956892490386963, train/logprobs = tensor([[-0.7301, -2.2983],
        [-0.9078, -0.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938740402460098
Epoch 0, Step 2147: train/loss = 0.38068312406539917, train/raw-loss = 0.30106237530708313, train/logprobs = tensor([[-0.9884, -3.9235],
        [-1.3462, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07962071895599365
Epoch 0, Step 2148: train/loss = 0.2616519331932068, train/raw-loss = 0.1855871081352234, train/logprobs = tensor([[-0.6169, -5.2050],
        [-1.4401, -1.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0760648101568222
Epoch 0, Step 2149: train/loss = 0.5087336301803589, train/raw-loss = 0.4336520731449127, train/logprobs = tensor([[-0.5703, -4.3331],
        [-0.8331, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07508159428834915
Epoch 0, Step 2150: train/loss = 0.6489294767379761, train/raw-loss = 0.5748582482337952, train/logprobs = tensor([[-1.8161, -3.4604],
        [-1.2514, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07407118380069733
Epoch 0, Step 2151: train/loss = 0.5160192847251892, train/raw-loss = 0.47031688690185547, train/logprobs = tensor([[-1.1183, -6.6225],
        [-1.1747, -1.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04570240527391434
Epoch 0, Step 2152: train/loss = 0.5434876084327698, train/raw-loss = 0.48595482110977173, train/logprobs = tensor([[-0.4356, -2.6598],
        [-0.4879, -0.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05753278732299805
Epoch 0, Step 2153: train/loss = 0.44815778732299805, train/raw-loss = 0.3259061276912689, train/logprobs = tensor([[-0.7253, -3.4085],
        [-1.4529, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12225167453289032
Epoch 0, Step 2154: train/loss = 0.3967949450016022, train/raw-loss = 0.31450796127319336, train/logprobs = tensor([[-0.8438, -4.0037],
        [-1.1822, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08228699117898941
Epoch 0, Step 2155: train/loss = 0.32304316759109497, train/raw-loss = 0.2519056797027588, train/logprobs = tensor([[-0.4718, -9.3110],
        [-1.0995, -1.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07113749533891678
Epoch 0, Step 2156: train/loss = 0.5508041381835938, train/raw-loss = 0.4832438826560974, train/logprobs = tensor([[-0.4522, -4.2680],
        [-0.7634, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06756033003330231
Epoch 0, Step 2157: train/loss = 0.31437426805496216, train/raw-loss = 0.2101862132549286, train/logprobs = tensor([[-0.9443, -5.0631],
        [-1.6329, -0.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10418804734945297
Epoch 0, Step 2158: train/loss = 0.6146313548088074, train/raw-loss = 0.5250740051269531, train/logprobs = tensor([[-0.7368, -5.5318],
        [-1.2334, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08955733478069305
Epoch 0, Step 2159: train/loss = 0.7578520774841309, train/raw-loss = 0.6487096548080444, train/logprobs = tensor([[-2.1426, -6.3979],
        [-1.8214, -1.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091424822807312
Epoch 0, Step 2160: train/loss = 0.4129219651222229, train/raw-loss = 0.3206172585487366, train/logprobs = tensor([[-0.3736, -4.0182],
        [-0.9974, -0.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09230469167232513
Epoch 0, Step 2161: train/loss = 0.43633031845092773, train/raw-loss = 0.34492769837379456, train/logprobs = tensor([[-1.3464, -5.0109],
        [-1.2338, -0.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09140262007713318
Epoch 0, Step 2162: train/loss = 0.47546449303627014, train/raw-loss = 0.38526180386543274, train/logprobs = tensor([[-0.6463, -2.9414],
        [-1.3422, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09020267426967621
Epoch 0, Step 2163: train/loss = 0.5160546898841858, train/raw-loss = 0.42882728576660156, train/logprobs = tensor([[-0.5642, -2.6199],
        [-0.9075, -0.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08722738921642303
Epoch 0, Step 2164: train/loss = 0.3384324312210083, train/raw-loss = 0.26862701773643494, train/logprobs = tensor([[-0.4412, -8.2175],
        [-1.2343, -1.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06980542093515396
Epoch 0, Step 2165: train/loss = 0.574576199054718, train/raw-loss = 0.5022303462028503, train/logprobs = tensor([[-0.3920, -1.4616],
        [-0.7587, -0.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07234585285186768
Epoch 0, Step 2166: train/loss = 0.49366655945777893, train/raw-loss = 0.4232167899608612, train/logprobs = tensor([[-0.5578, -7.2371],
        [-0.7027, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044976949691772
Epoch 0, Step 2167: train/loss = 0.6080046892166138, train/raw-loss = 0.5393116474151611, train/logprobs = tensor([[-0.4038, -0.7272],
        [-0.9856, -0.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06869304180145264
Epoch 0, Step 2168: train/loss = 0.42279404401779175, train/raw-loss = 0.35239800810813904, train/logprobs = tensor([[-0.6508, -5.0633],
        [-0.7156, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07039603590965271
Epoch 0, Step 2169: train/loss = 0.5791113376617432, train/raw-loss = 0.5149074792861938, train/logprobs = tensor([[-0.4474, -1.6139],
        [-1.0559, -0.6906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06420388072729111
Epoch 0, Step 2170: train/loss = 0.36048686504364014, train/raw-loss = 0.26950234174728394, train/logprobs = tensor([[-0.9212, -6.2434],
        [-1.5022, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0909845381975174
Epoch 0, Step 2171: train/loss = 0.5768107175827026, train/raw-loss = 0.5020128488540649, train/logprobs = tensor([[-0.8528, -2.7384],
        [-0.5173, -0.7296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0747978687286377
Epoch 0, Step 2172: train/loss = 0.6201702356338501, train/raw-loss = 0.5609347224235535, train/logprobs = tensor([[-0.6144, -1.9545],
        [-0.6672, -0.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05923554301261902
Epoch 0, Step 2173: train/loss = 0.544021487236023, train/raw-loss = 0.47996312379837036, train/logprobs = tensor([[-0.6556, -4.0036],
        [-0.7067, -1.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06405839323997498
Epoch 0, Step 2174: train/loss = 0.5091297030448914, train/raw-loss = 0.43890857696533203, train/logprobs = tensor([[-0.4282, -2.2064],
        [-0.7756, -0.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07022114843130112
Epoch 0, Step 2175: train/loss = 0.3815535008907318, train/raw-loss = 0.30693793296813965, train/logprobs = tensor([[-0.4827, -5.3222],
        [-1.1377, -0.7314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07461559772491455
Epoch 0, Step 2176: train/loss = 0.5032756328582764, train/raw-loss = 0.44298017024993896, train/logprobs = tensor([[-1.5860, -5.9915],
        [-1.2131, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06029551848769188
Epoch 0, Step 2177: train/loss = 0.48112189769744873, train/raw-loss = 0.40009206533432007, train/logprobs = tensor([[-1.0761, -4.7465],
        [-1.1586, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08102985471487045
Epoch 0, Step 2178: train/loss = 0.42758727073669434, train/raw-loss = 0.3451579809188843, train/logprobs = tensor([[-0.7138, -5.9427],
        [-0.8137, -1.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08242927491664886
Epoch 0, Step 2179: train/loss = 0.502280592918396, train/raw-loss = 0.4355112612247467, train/logprobs = tensor([[-0.6272, -2.1487],
        [-0.8991, -0.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0667693018913269
Epoch 0, Step 2180: train/loss = 0.5049524903297424, train/raw-loss = 0.4385521113872528, train/logprobs = tensor([[-0.3477, -3.3774],
        [-0.5808, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640039384365082
Epoch 0, Step 2181: train/loss = 0.32742053270339966, train/raw-loss = 0.22729578614234924, train/logprobs = tensor([[-0.5505, -4.8359],
        [-1.2357, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012474656105042
Epoch 0, Step 2182: train/loss = 0.5799079537391663, train/raw-loss = 0.5195348262786865, train/logprobs = tensor([[-0.7643, -2.7247],
        [-0.6036, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06037311628460884
Epoch 0, Step 2183: train/loss = 0.32581767439842224, train/raw-loss = 0.23113861680030823, train/logprobs = tensor([[-0.6845, -4.5503],
        [-1.4443, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09467906504869461
Epoch 0, Step 2184: train/loss = 0.7217829823493958, train/raw-loss = 0.6409097909927368, train/logprobs = tensor([[-0.5028, -0.5680],
        [-1.3138, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08087314665317535
Epoch 0, Step 2185: train/loss = 0.5279924869537354, train/raw-loss = 0.43035221099853516, train/logprobs = tensor([[-0.7246, -2.5206],
        [-1.0746, -1.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09764029830694199
Epoch 0, Step 2186: train/loss = 0.4273066818714142, train/raw-loss = 0.36151349544525146, train/logprobs = tensor([[-0.6108, -4.7487],
        [-0.8142, -0.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06579317152500153
Epoch 0, Step 2187: train/loss = 0.5384293794631958, train/raw-loss = 0.4501360058784485, train/logprobs = tensor([[-0.7492, -1.7644],
        [-1.4774, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882934033870697
Epoch 0, Step 2188: train/loss = 0.3802067041397095, train/raw-loss = 0.28147032856941223, train/logprobs = tensor([[-0.5933, -4.4648],
        [-1.4089, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09873639792203903
Epoch 0, Step 2189: train/loss = 0.5958794355392456, train/raw-loss = 0.5405054688453674, train/logprobs = tensor([[-0.5530, -2.1455],
        [-0.6315, -0.4124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05537397414445877
Epoch 0, Step 2190: train/loss = 0.29483914375305176, train/raw-loss = 0.22405171394348145, train/logprobs = tensor([[ -0.9536, -12.3150],
        [ -1.4385,  -1.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07078743726015091
Epoch 0, Step 2191: train/loss = 0.5791668891906738, train/raw-loss = 0.5147452354431152, train/logprobs = tensor([[-0.6223, -1.4442],
        [-0.8776, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644216313958168
Epoch 0, Step 2192: train/loss = 0.34504082798957825, train/raw-loss = 0.2314377725124359, train/logprobs = tensor([[-0.8845, -3.6971],
        [-1.5996, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11360307037830353
Epoch 0, Step 2193: train/loss = 0.519511878490448, train/raw-loss = 0.44450023770332336, train/logprobs = tensor([[-0.4124, -3.2923],
        [-0.7697, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501162588596344
Epoch 0, Step 2194: train/loss = 0.48877042531967163, train/raw-loss = 0.42735064029693604, train/logprobs = tensor([[-0.7175, -5.1977],
        [-0.8269, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0614197701215744
Epoch 0, Step 2195: train/loss = 0.36676692962646484, train/raw-loss = 0.2958223521709442, train/logprobs = tensor([[-0.5670, -6.9852],
        [-0.9611, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094458490610123
Epoch 0, Step 2196: train/loss = 0.7023115158081055, train/raw-loss = 0.638764500617981, train/logprobs = tensor([[-0.6998, -0.7903],
        [-0.6663, -0.4925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06354700028896332
Epoch 0, Step 2197: train/loss = 0.3603200912475586, train/raw-loss = 0.27068284153938293, train/logprobs = tensor([[-0.7596, -5.8423],
        [-0.9308, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08963724225759506
Epoch 0, Step 2198: train/loss = 0.5028804540634155, train/raw-loss = 0.43238747119903564, train/logprobs = tensor([[-1.5397, -6.8154],
        [-1.1159, -1.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07049302011728287
Epoch 0, Step 2199: train/loss = 0.6425886750221252, train/raw-loss = 0.5862466096878052, train/logprobs = tensor([[-0.4932, -0.8474],
        [-0.7214, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056342046707868576
Epoch 0, Step 2200: train/loss = 0.4869685769081116, train/raw-loss = 0.41271066665649414, train/logprobs = tensor([[-0.4849, -2.8880],
        [-0.9784, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07425791025161743
Epoch 0, Step 2201: train/loss = 0.6310025453567505, train/raw-loss = 0.573054313659668, train/logprobs = tensor([[-0.4539, -0.9175],
        [-0.5204, -0.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057948220521211624
Epoch 0, Step 2202: train/loss = 0.6325303912162781, train/raw-loss = 0.5593907237052917, train/logprobs = tensor([[-0.8747, -1.0621],
        [-1.0194, -0.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07313967496156693
Epoch 0, Step 2203: train/loss = 0.42597657442092896, train/raw-loss = 0.3191823363304138, train/logprobs = tensor([[-0.7402, -4.7160],
        [-1.2908, -0.5230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10679423809051514
Epoch 0, Step 2204: train/loss = 0.41878542304039, train/raw-loss = 0.3523997664451599, train/logprobs = tensor([[-0.6493, -3.6099],
        [-0.9039, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0663856491446495
Epoch 0, Step 2205: train/loss = 0.3933064043521881, train/raw-loss = 0.3196278214454651, train/logprobs = tensor([[-0.4813, -4.5861],
        [-1.1279, -1.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07367855310440063
Epoch 0, Step 2206: train/loss = 0.5822488069534302, train/raw-loss = 0.5147314667701721, train/logprobs = tensor([[-0.8309, -2.1155],
        [-0.7274, -0.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06751734018325806
Epoch 0, Step 2207: train/loss = 0.3179590106010437, train/raw-loss = 0.23783773183822632, train/logprobs = tensor([[-0.6161, -4.1115],
        [-1.0702, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08012127131223679
Epoch 0, Step 2208: train/loss = 0.5554291605949402, train/raw-loss = 0.4772645831108093, train/logprobs = tensor([[-0.6355, -3.1743],
        [-0.9146, -0.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07816454768180847
Epoch 0, Step 2209: train/loss = 0.3500179648399353, train/raw-loss = 0.2562112808227539, train/logprobs = tensor([[-0.7246, -5.7577],
        [-1.3096, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0938066840171814
Epoch 0, Step 2210: train/loss = 0.415927529335022, train/raw-loss = 0.33531761169433594, train/logprobs = tensor([[-0.8369, -3.5616],
        [-1.5963, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08060991019010544
Epoch 0, Step 2211: train/loss = 0.5091416835784912, train/raw-loss = 0.3982216715812683, train/logprobs = tensor([[-0.5158, -4.4648],
        [-1.3401, -0.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109200268983841
Epoch 0, Step 2212: train/loss = 0.4085276424884796, train/raw-loss = 0.30580833554267883, train/logprobs = tensor([[-0.6944, -4.7856],
        [-1.2317, -0.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10271931439638138
Epoch 0, Step 2213: train/loss = 0.34482085704803467, train/raw-loss = 0.2685472369194031, train/logprobs = tensor([[-0.6512, -5.6135],
        [-0.8616, -0.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0762736052274704
Epoch 0, Step 2214: train/loss = 0.3291172683238983, train/raw-loss = 0.2368588149547577, train/logprobs = tensor([[-0.6411, -6.1534],
        [-1.6249, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09225845336914062
Epoch 0, Step 2215: train/loss = 0.4632583260536194, train/raw-loss = 0.37650907039642334, train/logprobs = tensor([[-1.0075, -4.0118],
        [-0.9019, -0.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08674925565719604
Epoch 0, Step 2216: train/loss = 0.39788949489593506, train/raw-loss = 0.30496683716773987, train/logprobs = tensor([[-0.9026, -3.5961],
        [-1.6929, -0.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09292268753051758
Epoch 0, Step 2217: train/loss = 0.5406429767608643, train/raw-loss = 0.45062553882598877, train/logprobs = tensor([[-2.6306, -4.2316],
        [-2.8480, -1.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09001743793487549
Epoch 0, Step 2218: train/loss = 0.41319650411605835, train/raw-loss = 0.3423333764076233, train/logprobs = tensor([[-0.6026, -4.2486],
        [-0.8753, -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07086314260959625
Epoch 0, Step 2219: train/loss = 0.4473990201950073, train/raw-loss = 0.3887920379638672, train/logprobs = tensor([[-0.7710, -7.5103],
        [-0.9014, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05860699713230133
Epoch 0, Step 2220: train/loss = 0.544144332408905, train/raw-loss = 0.44909024238586426, train/logprobs = tensor([[-0.9114, -3.2750],
        [-1.5885, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09505407512187958
Epoch 0, Step 2221: train/loss = 0.5553632974624634, train/raw-loss = 0.46848946809768677, train/logprobs = tensor([[-1.4964, -7.3686],
        [-1.0164, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0868738517165184
Epoch 0, Step 2222: train/loss = 0.4512237012386322, train/raw-loss = 0.38245832920074463, train/logprobs = tensor([[-0.3565, -4.5113],
        [-0.7161, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876534968614578
Epoch 0, Step 2223: train/loss = 0.40360209345817566, train/raw-loss = 0.32950153946876526, train/logprobs = tensor([[-0.5900, -5.5270],
        [-1.2789, -1.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741005390882492
Epoch 0, Step 2224: train/loss = 0.300457239151001, train/raw-loss = 0.21570619940757751, train/logprobs = tensor([[-0.6084, -6.7641],
        [-1.6134, -1.3542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475103229284286
Epoch 0, Step 2225: train/loss = 0.5793390870094299, train/raw-loss = 0.5078142881393433, train/logprobs = tensor([[-1.0540, -2.5591],
        [-0.9676, -0.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07152478396892548
Epoch 0, Step 2226: train/loss = 0.3042699992656708, train/raw-loss = 0.20802640914916992, train/logprobs = tensor([[-0.4454, -7.2977],
        [-1.1815, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09624358266592026
Epoch 0, Step 2227: train/loss = 0.4472501277923584, train/raw-loss = 0.35944992303848267, train/logprobs = tensor([[-0.3701, -3.3330],
        [-0.9384, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08780016750097275
Epoch 0, Step 2228: train/loss = 0.4103955030441284, train/raw-loss = 0.3279891014099121, train/logprobs = tensor([[-0.4967, -4.3390],
        [-1.2672, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0824064165353775
Epoch 0, Step 2229: train/loss = 0.49199792742729187, train/raw-loss = 0.42435264587402344, train/logprobs = tensor([[-0.5075, -3.6831],
        [-0.6902, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06764528900384903
Epoch 0, Step 2230: train/loss = 0.4399617612361908, train/raw-loss = 0.36431241035461426, train/logprobs = tensor([[-0.7277, -3.1868],
        [-1.1894, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07564932852983475
Epoch 0, Step 2231: train/loss = 0.4842728078365326, train/raw-loss = 0.4238208532333374, train/logprobs = tensor([[-0.4313, -4.0510],
        [-0.6750, -0.8526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06045195460319519
Epoch 0, Step 2232: train/loss = 0.447523295879364, train/raw-loss = 0.333029180765152, train/logprobs = tensor([[-0.6896, -2.5792],
        [-1.5698, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11449411511421204
Epoch 0, Step 2233: train/loss = 0.3355599641799927, train/raw-loss = 0.26971885561943054, train/logprobs = tensor([[-0.7677, -5.3999],
        [-0.8969, -0.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06584110856056213
Epoch 0, Step 2234: train/loss = 0.38253557682037354, train/raw-loss = 0.29271435737609863, train/logprobs = tensor([[-0.7323, -4.3520],
        [-1.1995, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08982120454311371
Epoch 0, Step 2235: train/loss = 0.65016108751297, train/raw-loss = 0.5606576204299927, train/logprobs = tensor([[-1.3508, -3.1953],
        [-1.3310, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950341492891312
Epoch 0, Step 2236: train/loss = 0.45047467947006226, train/raw-loss = 0.37954187393188477, train/logprobs = tensor([[-0.4917, -3.2214],
        [-0.8204, -0.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07093282788991928
Epoch 0, Step 2237: train/loss = 0.5687106251716614, train/raw-loss = 0.49507325887680054, train/logprobs = tensor([[-1.1282, -2.3915],
        [-1.2287, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07363736629486084
Epoch 0, Step 2238: train/loss = 0.44571471214294434, train/raw-loss = 0.3524274230003357, train/logprobs = tensor([[-0.8440, -3.9181],
        [-1.4973, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09328728169202805
Epoch 0, Step 2239: train/loss = 0.444932758808136, train/raw-loss = 0.36758655309677124, train/logprobs = tensor([[-0.5898, -5.9077],
        [-0.9193, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734622061252594
Epoch 0, Step 2240: train/loss = 0.3730681538581848, train/raw-loss = 0.28885746002197266, train/logprobs = tensor([[-0.7031, -4.9262],
        [-1.0129, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08421072363853455
Epoch 0, Step 2241: train/loss = 0.45286306738853455, train/raw-loss = 0.3787227272987366, train/logprobs = tensor([[-0.7804, -2.1341],
        [-1.0975, -0.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414034008979797
Epoch 0, Step 2242: train/loss = 0.5242748260498047, train/raw-loss = 0.45200249552726746, train/logprobs = tensor([[-0.6982, -3.5160],
        [-1.4956, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07227233797311783
Epoch 0, Step 2243: train/loss = 0.4991876482963562, train/raw-loss = 0.434468150138855, train/logprobs = tensor([[-0.4206, -3.0798],
        [-0.7644, -0.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06471951305866241
Epoch 0, Step 2244: train/loss = 0.3562299311161041, train/raw-loss = 0.2626393437385559, train/logprobs = tensor([[-0.7078, -6.7369],
        [-1.1303, -1.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935906171798706
Epoch 0, Step 2245: train/loss = 0.4966326057910919, train/raw-loss = 0.4384578466415405, train/logprobs = tensor([[-0.6138, -3.4229],
        [-0.8366, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05817478150129318
Epoch 0, Step 2246: train/loss = 0.4330819547176361, train/raw-loss = 0.3459357023239136, train/logprobs = tensor([[-0.6009, -3.8407],
        [-1.0974, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08714628964662552
Epoch 0, Step 2247: train/loss = 0.35648179054260254, train/raw-loss = 0.2565484046936035, train/logprobs = tensor([[-0.5736, -3.4564],
        [-1.4998, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09993335604667664
Epoch 0, Step 2248: train/loss = 0.6494281888008118, train/raw-loss = 0.5862201452255249, train/logprobs = tensor([[-0.3905, -0.6760],
        [-0.6824, -0.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06320802867412567
Epoch 0, Step 2249: train/loss = 0.3738689422607422, train/raw-loss = 0.30306947231292725, train/logprobs = tensor([[-0.5222, -2.8125],
        [-0.8606, -0.4367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07079945504665375
Epoch 0, Step 2250: train/loss = 0.427767276763916, train/raw-loss = 0.351004421710968, train/logprobs = tensor([[-0.4736, -3.5233],
        [-0.8818, -0.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767628401517868
Epoch 0, Step 2251: train/loss = 0.39635998010635376, train/raw-loss = 0.31158071756362915, train/logprobs = tensor([[-0.4085, -3.5666],
        [-0.9173, -0.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0847792774438858
Epoch 0, Step 2252: train/loss = 0.5637636184692383, train/raw-loss = 0.5031449794769287, train/logprobs = tensor([[-0.6112, -1.9535],
        [-0.6150, -0.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06061869114637375
Epoch 0, Step 2253: train/loss = 0.5066272020339966, train/raw-loss = 0.43263956904411316, train/logprobs = tensor([[-0.4719, -3.7160],
        [-0.8109, -0.4071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07398764044046402
Epoch 0, Step 2254: train/loss = 0.6532305479049683, train/raw-loss = 0.5758154988288879, train/logprobs = tensor([[-0.5040, -0.9513],
        [-0.8770, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07741506397724152
Epoch 0, Step 2255: train/loss = 0.3033199608325958, train/raw-loss = 0.24293266236782074, train/logprobs = tensor([[ -0.8820, -10.6525],
        [ -1.1256,  -2.2640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06038731336593628
Epoch 0, Step 2256: train/loss = 0.493851900100708, train/raw-loss = 0.4075857400894165, train/logprobs = tensor([[-0.5326, -4.1549],
        [-0.7918, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08626614511013031
Epoch 0, Step 2257: train/loss = 0.5711820125579834, train/raw-loss = 0.48720818758010864, train/logprobs = tensor([[-0.7970, -2.2017],
        [-0.8831, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397381007671356
Epoch 0, Step 2258: train/loss = 0.45208415389060974, train/raw-loss = 0.3740478754043579, train/logprobs = tensor([[-0.7015, -5.4413],
        [-0.9011, -0.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07803630828857422
Epoch 0, Step 2259: train/loss = 0.3274233639240265, train/raw-loss = 0.2551615536212921, train/logprobs = tensor([[-0.3959, -9.4735],
        [-0.8458, -1.2050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07226181030273438
Epoch 0, Step 2260: train/loss = 0.44684940576553345, train/raw-loss = 0.3807213306427002, train/logprobs = tensor([[-0.5289, -4.3942],
        [-0.8701, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06612809002399445
Epoch 0, Step 2261: train/loss = 0.35376882553100586, train/raw-loss = 0.26330772042274475, train/logprobs = tensor([[-0.6701, -5.2576],
        [-1.4013, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904611125588417
Epoch 0, Step 2262: train/loss = 0.5519943237304688, train/raw-loss = 0.47930389642715454, train/logprobs = tensor([[-0.5935, -1.4074],
        [-0.8822, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07269038259983063
Epoch 0, Step 2263: train/loss = 0.5323879718780518, train/raw-loss = 0.44335949420928955, train/logprobs = tensor([[-0.5306, -1.9346],
        [-1.0580, -0.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0890285074710846
Epoch 0, Step 2264: train/loss = 0.4840695261955261, train/raw-loss = 0.42099693417549133, train/logprobs = tensor([[-0.5354, -4.4155],
        [-0.7411, -0.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0630725845694542
Epoch 0, Step 2265: train/loss = 0.368700236082077, train/raw-loss = 0.30280622839927673, train/logprobs = tensor([[-0.6843, -4.3232],
        [-1.4122, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06589400768280029
Epoch 0, Step 2266: train/loss = 0.29811590909957886, train/raw-loss = 0.23399046063423157, train/logprobs = tensor([[-0.6354, -8.0999],
        [-1.3494, -1.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06412546336650848
Epoch 0, Step 2267: train/loss = 0.6339476108551025, train/raw-loss = 0.5825269222259521, train/logprobs = tensor([[-0.5027, -0.8979],
        [-0.5593, -0.3787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05142073705792427
Epoch 0, Step 2268: train/loss = 0.39451661705970764, train/raw-loss = 0.2948375344276428, train/logprobs = tensor([[-0.6359, -3.6318],
        [-1.4403, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09967909753322601
Epoch 0, Step 2269: train/loss = 0.5402277708053589, train/raw-loss = 0.45847761631011963, train/logprobs = tensor([[-0.8252, -2.0463],
        [-1.1572, -0.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08175019174814224
Epoch 0, Step 2270: train/loss = 0.4131472706794739, train/raw-loss = 0.34978705644607544, train/logprobs = tensor([[-0.3416, -3.9653],
        [-0.5570, -0.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06336024403572083
Epoch 0, Step 2271: train/loss = 0.4315889775753021, train/raw-loss = 0.3593788743019104, train/logprobs = tensor([[-0.7056, -7.3236],
        [-1.1186, -1.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07221009582281113
Epoch 0, Step 2272: train/loss = 0.43203115463256836, train/raw-loss = 0.3574583828449249, train/logprobs = tensor([[-0.7039, -5.8055],
        [-1.4395, -1.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07457278668880463
Epoch 0, Step 2273: train/loss = 0.5026192665100098, train/raw-loss = 0.4411379098892212, train/logprobs = tensor([[-0.6934, -4.0785],
        [-0.6567, -0.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06148138642311096
Epoch 0, Step 2274: train/loss = 0.3319108486175537, train/raw-loss = 0.25613856315612793, train/logprobs = tensor([[-0.3480, -4.7328],
        [-0.8514, -0.5568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07577231526374817
Epoch 0, Step 2275: train/loss = 0.2738311290740967, train/raw-loss = 0.18624672293663025, train/logprobs = tensor([[-0.5416, -4.4962],
        [-1.3319, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08758439123630524
Epoch 0, Step 2276: train/loss = 0.43989014625549316, train/raw-loss = 0.3650420010089874, train/logprobs = tensor([[-0.5736, -3.9682],
        [-1.0912, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07484816014766693
Epoch 0, Step 2277: train/loss = 0.593599796295166, train/raw-loss = 0.5426983833312988, train/logprobs = tensor([[-0.4022, -1.3013],
        [-0.5379, -0.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05090143531560898
Epoch 0, Step 2278: train/loss = 0.49040257930755615, train/raw-loss = 0.4082793891429901, train/logprobs = tensor([[-0.8236, -2.7522],
        [-1.0660, -0.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08212321996688843
Epoch 0, Step 2279: train/loss = 0.7138605117797852, train/raw-loss = 0.6543657779693604, train/logprobs = tensor([[-1.8112, -6.9798],
        [-1.0028, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059494748711586
Epoch 0, Step 2280: train/loss = 0.5016857385635376, train/raw-loss = 0.4401015043258667, train/logprobs = tensor([[-0.4056, -2.2038],
        [-0.8143, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0615842379629612
Epoch 0, Step 2281: train/loss = 0.2828749120235443, train/raw-loss = 0.1973545253276825, train/logprobs = tensor([[-0.5671, -4.6683],
        [-1.7336, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08552036434412003
Epoch 0, Step 2282: train/loss = 0.46650442481040955, train/raw-loss = 0.3974807858467102, train/logprobs = tensor([[-0.4682, -4.0918],
        [-0.8589, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06902363896369934
Epoch 0, Step 2283: train/loss = 0.37110406160354614, train/raw-loss = 0.2994692027568817, train/logprobs = tensor([[-0.4629, -4.6000],
        [-0.7502, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07163484394550323
Epoch 0, Step 2284: train/loss = 0.6038581728935242, train/raw-loss = 0.5338345766067505, train/logprobs = tensor([[-1.0744, -4.3720],
        [-0.9337, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0700235664844513
Epoch 0, Step 2285: train/loss = 0.40075981616973877, train/raw-loss = 0.32532456517219543, train/logprobs = tensor([[-0.8262, -7.5671],
        [-0.9072, -1.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07543524354696274
Epoch 0, Step 2286: train/loss = 0.3612944483757019, train/raw-loss = 0.28634965419769287, train/logprobs = tensor([[-0.7701, -4.6170],
        [-0.9646, -0.9170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07494475692510605
Epoch 0, Step 2287: train/loss = 0.6328476071357727, train/raw-loss = 0.5567964911460876, train/logprobs = tensor([[-1.1976, -5.1581],
        [-1.0292, -1.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07605108618736267
Epoch 0, Step 2288: train/loss = 0.38320839405059814, train/raw-loss = 0.31200066208839417, train/logprobs = tensor([[-0.9791, -6.1763],
        [-1.0022, -1.3631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07120774686336517
Epoch 0, Step 2289: train/loss = 0.4614394009113312, train/raw-loss = 0.3975382447242737, train/logprobs = tensor([[-0.5911, -6.4669],
        [-1.1903, -1.3391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0639011561870575
Epoch 0, Step 2290: train/loss = 0.6617014408111572, train/raw-loss = 0.5730451345443726, train/logprobs = tensor([[-0.8171, -1.3619],
        [-1.4706, -1.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08865629136562347
Epoch 0, Step 2291: train/loss = 0.2746807336807251, train/raw-loss = 0.1588936150074005, train/logprobs = tensor([[-0.6008, -6.5947],
        [-1.7543, -0.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11578713357448578
Epoch 0, Step 2292: train/loss = 0.5685880184173584, train/raw-loss = 0.5040887594223022, train/logprobs = tensor([[-1.3594, -3.4378],
        [-1.0212, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06449930369853973
Epoch 0, Step 2293: train/loss = 0.43353182077407837, train/raw-loss = 0.3402334451675415, train/logprobs = tensor([[-0.6840, -3.2814],
        [-1.2052, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09329839050769806
Epoch 0, Step 2294: train/loss = 0.4398461580276489, train/raw-loss = 0.3554039001464844, train/logprobs = tensor([[-0.5708, -6.4192],
        [-1.0744, -1.0057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08444224298000336
Epoch 0, Step 2295: train/loss = 0.4568171203136444, train/raw-loss = 0.3846123218536377, train/logprobs = tensor([[-0.7390, -2.9866],
        [-1.0602, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07220479846000671
Epoch 0, Step 2296: train/loss = 0.5845400094985962, train/raw-loss = 0.5244115591049194, train/logprobs = tensor([[-0.5996, -1.2128],
        [-0.9837, -0.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06012839451432228
Epoch 0, Step 2297: train/loss = 0.47307920455932617, train/raw-loss = 0.40194255113601685, train/logprobs = tensor([[-0.5982, -2.4994],
        [-0.9864, -0.5001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07113668322563171
Epoch 0, Step 2298: train/loss = 0.22903579473495483, train/raw-loss = 0.14635583758354187, train/logprobs = tensor([[ -0.5677, -12.5174],
        [ -1.5743,  -2.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08267995715141296
Epoch 0, Step 2299: train/loss = 0.5454208254814148, train/raw-loss = 0.4701026678085327, train/logprobs = tensor([[-0.4546, -1.9010],
        [-0.6764, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07531817257404327
Epoch 0, Step 2300: train/loss = 0.31461262702941895, train/raw-loss = 0.24103474617004395, train/logprobs = tensor([[-0.7299, -3.3454],
        [-1.4676, -0.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07357791066169739
Epoch 0, Step 2301: train/loss = 0.3452605903148651, train/raw-loss = 0.2467913031578064, train/logprobs = tensor([[-0.4942, -5.9782],
        [-1.3908, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09846927225589752
Epoch 0, Step 2302: train/loss = 0.4533693194389343, train/raw-loss = 0.4004858732223511, train/logprobs = tensor([[-0.3659, -6.6341],
        [-0.9608, -1.3078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052883464843034744
Epoch 0, Step 2303: train/loss = 0.31729573011398315, train/raw-loss = 0.23054014146327972, train/logprobs = tensor([[-0.8676, -4.5861],
        [-1.3928, -0.6249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08675561100244522
Epoch 0, Step 2304: train/loss = 0.41742801666259766, train/raw-loss = 0.34088847041130066, train/logprobs = tensor([[-0.6615, -6.0833],
        [-0.9131, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07653956115245819
Epoch 0, Step 2305: train/loss = 0.5956326723098755, train/raw-loss = 0.5146068930625916, train/logprobs = tensor([[-1.2256, -7.2748],
        [-0.9809, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08102582395076752
Epoch 0, Step 2306: train/loss = 0.4764469861984253, train/raw-loss = 0.41155362129211426, train/logprobs = tensor([[-0.8918, -3.1006],
        [-1.0732, -0.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06489339470863342
Epoch 0, Step 2307: train/loss = 0.5113245844841003, train/raw-loss = 0.4196186065673828, train/logprobs = tensor([[-0.5395, -3.8790],
        [-1.6340, -1.3424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09170596301555634
Epoch 0, Step 2308: train/loss = 0.5264136791229248, train/raw-loss = 0.4678311347961426, train/logprobs = tensor([[-0.4075, -3.0865],
        [-0.5590, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05858253687620163
Epoch 0, Step 2309: train/loss = 0.45973145961761475, train/raw-loss = 0.3998469412326813, train/logprobs = tensor([[-1.2198, -7.2986],
        [-0.8778, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059884555637836456
Epoch 0, Step 2310: train/loss = 0.6050838232040405, train/raw-loss = 0.5247980356216431, train/logprobs = tensor([[-0.7251, -1.4330],
        [-1.1812, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08028584718704224
Epoch 0, Step 2311: train/loss = 0.608290433883667, train/raw-loss = 0.5564433336257935, train/logprobs = tensor([[-0.4367, -1.6550],
        [-0.5062, -0.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051847126334905624
Epoch 0, Step 2312: train/loss = 0.4420250356197357, train/raw-loss = 0.3667289614677429, train/logprobs = tensor([[-0.5022, -2.9224],
        [-0.9936, -0.6180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0752960741519928
Epoch 0, Step 2313: train/loss = 0.40060362219810486, train/raw-loss = 0.32212474942207336, train/logprobs = tensor([[-0.6641, -4.1358],
        [-1.0911, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0784788727760315
Epoch 0, Step 2314: train/loss = 0.31395062804222107, train/raw-loss = 0.24239371716976166, train/logprobs = tensor([[-0.7488, -7.9571],
        [-1.0083, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07155691832304001
Epoch 0, Step 2315: train/loss = 0.3968932628631592, train/raw-loss = 0.308460533618927, train/logprobs = tensor([[-0.7686, -4.1391],
        [-1.1367, -0.7552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843275904655457
Epoch 0, Step 2316: train/loss = 0.4669873118400574, train/raw-loss = 0.4037756621837616, train/logprobs = tensor([[-0.4998, -3.4790],
        [-0.8908, -0.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0632116049528122
Epoch 0, Step 2317: train/loss = 0.40079498291015625, train/raw-loss = 0.3286750614643097, train/logprobs = tensor([[-0.7562, -3.6314],
        [-0.9753, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07211993634700775
Epoch 0, Step 2318: train/loss = 0.5249437689781189, train/raw-loss = 0.4659148156642914, train/logprobs = tensor([[-0.4706, -2.9331],
        [-0.6438, -0.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05902896821498871
Epoch 0, Step 2319: train/loss = 0.37481164932250977, train/raw-loss = 0.288676381111145, train/logprobs = tensor([[-0.9233, -6.3194],
        [-1.0996, -1.0408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08613522350788116
Epoch 0, Step 2320: train/loss = 0.5035816431045532, train/raw-loss = 0.42061513662338257, train/logprobs = tensor([[-0.5908, -3.1526],
        [-0.8363, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08296652883291245
Epoch 0, Step 2321: train/loss = 0.571572482585907, train/raw-loss = 0.49505630135536194, train/logprobs = tensor([[-0.4630, -2.2876],
        [-0.7580, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07651615142822266
Epoch 0, Step 2322: train/loss = 0.6150720715522766, train/raw-loss = 0.5348942875862122, train/logprobs = tensor([[-2.0808, -4.5615],
        [-1.4969, -0.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08017779141664505
Epoch 0, Step 2323: train/loss = 0.6229658126831055, train/raw-loss = 0.5620929002761841, train/logprobs = tensor([[-0.5765, -1.0446],
        [-0.6730, -0.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06087293103337288
Epoch 0, Step 2324: train/loss = 0.41537314653396606, train/raw-loss = 0.346230149269104, train/logprobs = tensor([[-0.5523, -5.3834],
        [-0.7751, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06914300471544266
Epoch 0, Step 2325: train/loss = 0.5895690321922302, train/raw-loss = 0.5276920795440674, train/logprobs = tensor([[-0.3846, -1.6883],
        [-0.5443, -0.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061877019703388214
Epoch 0, Step 2326: train/loss = 0.29643702507019043, train/raw-loss = 0.1990787535905838, train/logprobs = tensor([[-0.8179, -7.5277],
        [-1.7537, -0.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09735829383134842
Epoch 0, Step 2327: train/loss = 0.5135642290115356, train/raw-loss = 0.45250022411346436, train/logprobs = tensor([[-0.7842, -4.1004],
        [-0.8597, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06106396019458771
Epoch 0, Step 2328: train/loss = 0.5307936668395996, train/raw-loss = 0.4394305646419525, train/logprobs = tensor([[-0.5349, -4.4023],
        [-0.9981, -0.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0913630872964859
Epoch 0, Step 2329: train/loss = 0.523579478263855, train/raw-loss = 0.45774781703948975, train/logprobs = tensor([[-0.4106, -3.2003],
        [-0.5273, -0.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06583172082901001
Epoch 0, Step 2330: train/loss = 0.4130552411079407, train/raw-loss = 0.33843207359313965, train/logprobs = tensor([[-0.4529, -3.0955],
        [-0.9179, -0.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07462316751480103
Epoch 0, Step 2331: train/loss = 0.6028341054916382, train/raw-loss = 0.5340266227722168, train/logprobs = tensor([[-0.7617, -1.9865],
        [-0.6447, -0.7042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0688074380159378
Epoch 0, Step 2332: train/loss = 0.4207729399204254, train/raw-loss = 0.35064607858657837, train/logprobs = tensor([[-0.8319, -4.1199],
        [-1.3282, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07012683898210526
Epoch 0, Step 2333: train/loss = 0.4974368214607239, train/raw-loss = 0.4081226885318756, train/logprobs = tensor([[-0.5447, -2.8442],
        [-1.1775, -0.5065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931411802768707
Epoch 0, Step 2334: train/loss = 0.46884170174598694, train/raw-loss = 0.3944593071937561, train/logprobs = tensor([[-0.7742, -5.3129],
        [-0.8458, -1.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07438243925571442
Epoch 0, Step 2335: train/loss = 0.22849495708942413, train/raw-loss = 0.14030709862709045, train/logprobs = tensor([[-0.5864, -8.5635],
        [-1.7175, -1.2931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08818783611059189
Epoch 0, Step 2336: train/loss = 0.38268977403640747, train/raw-loss = 0.3088529109954834, train/logprobs = tensor([[-0.5014, -5.1083],
        [-1.0935, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07383685559034348
Epoch 0, Step 2337: train/loss = 0.2849111258983612, train/raw-loss = 0.19864381849765778, train/logprobs = tensor([[-1.0507, -8.0246],
        [-1.6830, -1.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08626730740070343
Epoch 0, Step 2338: train/loss = 0.4918432831764221, train/raw-loss = 0.39460936188697815, train/logprobs = tensor([[-0.8544, -2.1943],
        [-1.4621, -0.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09723392874002457
Epoch 0, Step 2339: train/loss = 0.5550071001052856, train/raw-loss = 0.4782537817955017, train/logprobs = tensor([[-1.0393, -2.7453],
        [-1.0182, -0.5326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675337791442871
Epoch 0, Step 2340: train/loss = 0.5405701398849487, train/raw-loss = 0.45686113834381104, train/logprobs = tensor([[-0.5990, -1.8091],
        [-0.9456, -0.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08370900899171829
Epoch 0, Step 2341: train/loss = 0.6558315753936768, train/raw-loss = 0.5869640707969666, train/logprobs = tensor([[-1.3795, -2.8162],
        [-0.8705, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06886754184961319
Epoch 0, Step 2342: train/loss = 0.585963249206543, train/raw-loss = 0.5147132873535156, train/logprobs = tensor([[-0.5432, -1.2844],
        [-0.8215, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07124993205070496
Epoch 0, Step 2343: train/loss = 0.3655267357826233, train/raw-loss = 0.27522486448287964, train/logprobs = tensor([[-0.4412, -4.5864],
        [-1.0551, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09030190855264664
Epoch 0, Step 2344: train/loss = 0.3688170909881592, train/raw-loss = 0.3034338355064392, train/logprobs = tensor([[-0.5922, -5.1297],
        [-0.9630, -0.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06538327783346176
Epoch 0, Step 2345: train/loss = 0.35373103618621826, train/raw-loss = 0.2748645842075348, train/logprobs = tensor([[-0.4445, -6.3358],
        [-1.1708, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07886647433042526
Epoch 0, Step 2346: train/loss = 0.4100949466228485, train/raw-loss = 0.34357908368110657, train/logprobs = tensor([[-0.4912, -3.6505],
        [-0.7608, -0.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06651588529348373
Epoch 0, Step 2347: train/loss = 0.4412362575531006, train/raw-loss = 0.35212433338165283, train/logprobs = tensor([[-0.6487, -4.1055],
        [-1.4931, -1.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911195397377014
Epoch 0, Step 2348: train/loss = 0.2974690794944763, train/raw-loss = 0.20639902353286743, train/logprobs = tensor([[-0.7720, -5.3265],
        [-1.6221, -0.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09107005596160889
Epoch 0, Step 2349: train/loss = 0.8802292943000793, train/raw-loss = 0.8076673150062561, train/logprobs = tensor([[-2.0228, -2.9473],
        [-0.7288, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07256195694208145
Epoch 0, Step 2350: train/loss = 0.5182263851165771, train/raw-loss = 0.46397730708122253, train/logprobs = tensor([[-0.6050, -2.6317],
        [-0.5766, -0.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054249055683612823
Epoch 0, Step 2351: train/loss = 0.5421138405799866, train/raw-loss = 0.4876515865325928, train/logprobs = tensor([[-0.4298, -1.6648],
        [-0.6142, -0.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0544622540473938
Epoch 0, Step 2352: train/loss = 0.35994452238082886, train/raw-loss = 0.2951185703277588, train/logprobs = tensor([[-0.5622, -4.7767],
        [-1.0092, -1.0566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06482592225074768
Epoch 0, Step 2353: train/loss = 0.5509869456291199, train/raw-loss = 0.49179092049598694, train/logprobs = tensor([[-0.5047, -2.9898],
        [-0.6945, -0.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059196021407842636
Epoch 0, Step 2354: train/loss = 0.5072629451751709, train/raw-loss = 0.416537344455719, train/logprobs = tensor([[-1.5357, -4.1255],
        [-1.4162, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09072566032409668
Epoch 0, Step 2355: train/loss = 0.3777041435241699, train/raw-loss = 0.30467772483825684, train/logprobs = tensor([[-0.5951, -6.2240],
        [-1.1717, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07302642613649368
Epoch 0, Step 2356: train/loss = 0.41710996627807617, train/raw-loss = 0.33207327127456665, train/logprobs = tensor([[-0.7527, -5.0988],
        [-0.8418, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08503671735525131
Epoch 0, Step 2357: train/loss = 0.446641206741333, train/raw-loss = 0.3480204641819, train/logprobs = tensor([[-0.7924, -3.0745],
        [-1.0145, -0.5871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09862076491117477
Epoch 0, Step 2358: train/loss = 0.4057280421257019, train/raw-loss = 0.3408220410346985, train/logprobs = tensor([[-0.6808, -2.7987],
        [-1.3523, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06490602344274521
Epoch 0, Step 2359: train/loss = 0.3343997299671173, train/raw-loss = 0.24889695644378662, train/logprobs = tensor([[-0.7507, -5.9272],
        [-1.4359, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08550279587507248
Epoch 0, Step 2360: train/loss = 0.46326231956481934, train/raw-loss = 0.39185550808906555, train/logprobs = tensor([[-0.5544, -3.0460],
        [-0.7512, -0.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.071406789124012
Epoch 0, Step 2361: train/loss = 0.4442233443260193, train/raw-loss = 0.3515629768371582, train/logprobs = tensor([[-0.7330, -4.2211],
        [-0.9269, -0.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09266036748886108
Epoch 0, Step 2362: train/loss = 0.4396620988845825, train/raw-loss = 0.34148722887039185, train/logprobs = tensor([[-0.5043, -2.3096],
        [-0.8792, -0.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981747955083847
Epoch 0, Step 2363: train/loss = 0.45330601930618286, train/raw-loss = 0.3793448209762573, train/logprobs = tensor([[-0.5949, -2.6798],
        [-1.0153, -0.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07396119087934494
Epoch 0, Step 2364: train/loss = 0.5643492937088013, train/raw-loss = 0.49030470848083496, train/logprobs = tensor([[-1.2382, -2.7059],
        [-1.1885, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740446150302887
Epoch 0, Step 2365: train/loss = 0.40461447834968567, train/raw-loss = 0.34836727380752563, train/logprobs = tensor([[-0.5019, -3.7879],
        [-0.7087, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05624716728925705
Epoch 0, Step 2366: train/loss = 0.5308334231376648, train/raw-loss = 0.45511144399642944, train/logprobs = tensor([[-0.7044, -2.3911],
        [-0.5496, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07572194933891296
Epoch 0, Step 2367: train/loss = 0.5411382913589478, train/raw-loss = 0.4718923270702362, train/logprobs = tensor([[-0.4776, -2.0734],
        [-0.6994, -0.4748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06924595683813095
Epoch 0, Step 2368: train/loss = 0.39669069647789, train/raw-loss = 0.3250906467437744, train/logprobs = tensor([[-0.9331, -4.5022],
        [-0.9779, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0716000348329544
Epoch 0, Step 2369: train/loss = 0.5531280636787415, train/raw-loss = 0.47922948002815247, train/logprobs = tensor([[-0.5618, -2.4747],
        [-0.9057, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0738985687494278
Epoch 0, Step 2370: train/loss = 0.29716333746910095, train/raw-loss = 0.21709299087524414, train/logprobs = tensor([[-0.6934, -4.8796],
        [-1.2001, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08007033169269562
Epoch 0, Step 2371: train/loss = 0.4120875895023346, train/raw-loss = 0.3221268951892853, train/logprobs = tensor([[-0.7852, -2.8684],
        [-1.2833, -0.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08996069431304932
Epoch 0, Step 2372: train/loss = 0.38444840908050537, train/raw-loss = 0.2952200174331665, train/logprobs = tensor([[-0.4858, -5.7104],
        [-1.1120, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08922836184501648
Epoch 0, Step 2373: train/loss = 0.38999804854393005, train/raw-loss = 0.3085486590862274, train/logprobs = tensor([[-0.4798, -3.2169],
        [-1.0421, -0.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08144937455654144
Epoch 0, Step 2374: train/loss = 0.4428587853908539, train/raw-loss = 0.36467909812927246, train/logprobs = tensor([[-0.4621, -3.6384],
        [-0.6152, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817970961332321
