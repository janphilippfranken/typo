[2024-03-12 15:56:07,373] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 15:56:07,389] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 15:56:07,482] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-12 15:56:07,491] [INFO] [real_accelerator.py:191:get_accelerator] Setting ds_accelerator to cuda (auto detect)
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 15:56:24,466] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 15:56:25,053] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 15:56:25,211] [INFO] [comm.py:637:init_distributed] cdb=None
5000
4497
System: Write a response for the assistant that follows the principles in the constitution.

Assistant Constitution:
1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.
2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.

Human: How can I store food if I don't have a pantry?

Assistant:
You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.
You can store food in a variety of ways, including in a refrigerator, freezer, or cupboard.
Dataset({
    features: ['prompt', 'chosen', 'rejected'],
    num_rows: 18994
})
[2024-03-12 15:56:25,384] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-12 15:56:25,384] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-12 15:56:25,570][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7fa9117e4040>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 15:56:56,394][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-12 15:56:56,399] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.14.0, git-hash=unknown, git-branch=unknown
[2024-03-12 15:56:56,555][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f3d14a18160>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 15:56:56,561][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7fd5c1a480d0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 15:56:56,561][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f0bc1a20100>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-12 15:57:29,036] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-12 15:57:29,038] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-12 15:57:29,156] [INFO] [utils.py:800:see_memory_usage] begin bf16_optimizer
[2024-03-12 15:57:29,157] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-12 15:57:29,157] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 100.18 GB, percent = 9.9%
[2024-03-12 15:57:29,275] [INFO] [utils.py:800:see_memory_usage] end bf16_optimizer
[2024-03-12 15:57:29,276] [INFO] [utils.py:801:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-12 15:57:29,276] [INFO] [utils.py:808:see_memory_usage] CPU Virtual Memory:  used = 98.12 GB, percent = 9.7%
[2024-03-12 15:57:29,277] [INFO] [config.py:996:print] DeepSpeedEngine configuration:
[2024-03-12 15:57:29,277] [INFO] [config.py:1000:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-12 15:57:29,277] [INFO] [config.py:1000:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-12 15:57:29,277] [INFO] [config.py:1000:print]   amp_enabled .................. False
[2024-03-12 15:57:29,277] [INFO] [config.py:1000:print]   amp_params ................... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   bfloat16_enabled ............. True
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   bfloat16_immediate_grad_update  False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   checkpoint_parallel_write_pipeline  False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   checkpoint_tag_validation_enabled  True
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   checkpoint_tag_validation_fail  False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7fa9117e4d30>
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   communication_data_type ...... None
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   compile_config ............... enabled=False backend='inductor' kwargs={}
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   curriculum_enabled_legacy .... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   curriculum_params_legacy ..... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   data_efficiency_enabled ...... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   dataloader_drop_last ......... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   disable_allgather ............ False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   dump_state ................... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   dynamic_loss_scale_args ...... None
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   eigenvalue_enabled ........... False
[2024-03-12 15:57:29,278] [INFO] [config.py:1000:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_layer_num ......... 0
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_max_iter .......... 100
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_stability ......... 1e-06
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_tol ............... 0.01
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   eigenvalue_verbose ........... False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   elasticity_enabled ........... False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   fp16_auto_cast ............... None
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   fp16_enabled ................. False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   fp16_master_weights_and_gradients  False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   global_rank .................. 0
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   grad_accum_dtype ............. None
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   gradient_accumulation_steps .. 32
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   gradient_clipping ............ 1.0
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   gradient_predivide_factor .... 1.0
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   graph_harvesting ............. False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   initial_dynamic_scale ........ 1
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   load_universal_checkpoint .... False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   loss_scale ................... 1.0
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   memory_breakdown ............. False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   mics_hierarchial_params_gather  False
[2024-03-12 15:57:29,279] [INFO] [config.py:1000:print]   mics_shard_size .............. -1
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   optimizer_legacy_fusion ...... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   optimizer_name ............... None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   optimizer_params ............. None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   pld_enabled .................. False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   pld_params ................... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   prescale_gradients ........... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   scheduler_name ............... None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   scheduler_params ............. None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   sparse_attention ............. None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   sparse_gradients_enabled ..... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   steps_per_print .............. inf
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   train_batch_size ............. 128
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   train_micro_batch_size_per_gpu  1
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   use_data_before_expert_parallel_  False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   use_node_local_storage ....... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   wall_clock_breakdown ......... False
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   weight_quantization_config ... None
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   world_size ................... 4
[2024-03-12 15:57:29,280] [INFO] [config.py:1000:print]   zero_allow_untested_optimizer  False
[2024-03-12 15:57:29,281] [INFO] [config.py:1000:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-12 15:57:29,281] [INFO] [config.py:1000:print]   zero_enabled ................. False
[2024-03-12 15:57:29,281] [INFO] [config.py:1000:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-12 15:57:29,281] [INFO] [config.py:1000:print]   zero_optimization_stage ...... 0
[2024-03-12 15:57:29,281] [INFO] [config.py:986:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -8.57713508605957, 'logps/chosen': -5.945191860198975, 'logits/rejected': -3.310513734817505, 'logits/chosen': -3.178420305252075, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -6.4359612464904785, 'logps/chosen': -5.295842170715332, 'logits/rejected': -3.21756649017334, 'logits/chosen': -3.114837646484375, 'epoch': 0.01}
{'loss': 0.6922, 'learning_rate': 2e-07, 'rewards/chosen': -0.0010674996301531792, 'rewards/rejected': 0.0008321320055983961, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0018996316939592361, 'logps/rejected': -4.271036624908447, 'logps/chosen': -7.294907093048096, 'logits/rejected': -3.087254285812378, 'logits/chosen': -3.192199945449829, 'epoch': 0.02}
{'loss': 0.6928, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': -0.0019966396503150463, 'rewards/rejected': -0.0018065199255943298, 'rewards/accuracies': 0.59375, 'rewards/margins': -0.0001901198411360383, 'logps/rejected': -5.192174434661865, 'logps/chosen': -4.611250400543213, 'logits/rejected': -3.2091143131256104, 'logits/chosen': -3.211256504058838, 'epoch': 0.03}
{'loss': 0.6935, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': -0.00011351302964612842, 'rewards/rejected': 0.0003331954649183899, 'rewards/accuracies': 0.53125, 'rewards/margins': -0.00044670840725302696, 'logps/rejected': -8.388070106506348, 'logps/chosen': -3.76617169380188, 'logits/rejected': -3.3256020545959473, 'logits/chosen': -2.8920669555664062, 'epoch': 0.03}
{'loss': 0.693, 'learning_rate': 4e-07, 'rewards/chosen': 0.0023750506807118654, 'rewards/rejected': 0.003129072953015566, 'rewards/accuracies': 0.5, 'rewards/margins': -0.0007540218066424131, 'logps/rejected': -7.320699691772461, 'logps/chosen': -5.618896484375, 'logits/rejected': -3.128110408782959, 'logits/chosen': -3.1510183811187744, 'epoch': 0.04}
{'loss': 0.6915, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.0039423806592822075, 'rewards/rejected': -0.0014936979860067368, 'rewards/accuracies': 0.5, 'rewards/margins': 0.005436078645288944, 'logps/rejected': -5.327605724334717, 'logps/chosen': -6.1336350440979, 'logits/rejected': -3.100125312805176, 'logits/chosen': -3.220332384109497, 'epoch': 0.05}
{'loss': 0.6909, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.00797397829592228, 'rewards/rejected': -0.00138216617051512, 'rewards/accuracies': 0.53125, 'rewards/margins': 0.009356144815683365, 'logps/rejected': -4.795194625854492, 'logps/chosen': -6.771090507507324, 'logits/rejected': -3.132061719894409, 'logits/chosen': -3.2931463718414307, 'epoch': 0.05}
{'loss': 0.6983, 'learning_rate': 6e-07, 'rewards/chosen': 0.000787839584518224, 'rewards/rejected': -0.004635625518858433, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.005423464812338352, 'logps/rejected': -5.510737419128418, 'logps/chosen': -6.491786479949951, 'logits/rejected': -3.2950615882873535, 'logits/chosen': -3.1316161155700684, 'epoch': 0.06}
{'loss': 0.684, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': 0.004748824052512646, 'rewards/rejected': -0.006720283068716526, 'rewards/accuracies': 0.75, 'rewards/margins': 0.011469108052551746, 'logps/rejected': -7.157915115356445, 'logps/chosen': -7.340248107910156, 'logits/rejected': -3.045924186706543, 'logits/chosen': -3.250032424926758, 'epoch': 0.07}
{'loss': 0.6878, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': 0.013522781431674957, 'rewards/rejected': -0.010231902822852135, 'rewards/accuracies': 0.625, 'rewards/margins': 0.023754684254527092, 'logps/rejected': -7.270012855529785, 'logps/chosen': -8.79298210144043, 'logits/rejected': -3.133592367172241, 'logits/chosen': -3.2491836547851562, 'epoch': 0.07}
{'loss': 0.6852, 'learning_rate': 8e-07, 'rewards/chosen': -0.004414609633386135, 'rewards/rejected': -0.0016021765768527985, 'rewards/accuracies': 0.625, 'rewards/margins': -0.0028124316595494747, 'logps/rejected': -5.509001731872559, 'logps/chosen': -4.8009819984436035, 'logits/rejected': -3.1610662937164307, 'logits/chosen': -3.227644920349121, 'epoch': 0.08}
{'loss': 0.6693, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': 0.007405244745314121, 'rewards/rejected': -0.04837733507156372, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.05578257516026497, 'logps/rejected': -7.450560092926025, 'logps/chosen': -7.0661187171936035, 'logits/rejected': -3.20760440826416, 'logits/chosen': -3.083080291748047, 'epoch': 0.09}
{'loss': 0.6801, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': 0.004963847808539867, 'rewards/rejected': -0.07899239659309387, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.08395624160766602, 'logps/rejected': -10.479228973388672, 'logps/chosen': -6.184162139892578, 'logits/rejected': -3.243185043334961, 'logits/chosen': -3.1095330715179443, 'epoch': 0.09}
{'loss': 0.6458, 'learning_rate': 1e-06, 'rewards/chosen': 0.013715580105781555, 'rewards/rejected': -0.11302139610052109, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.12673696875572205, 'logps/rejected': -10.087018013000488, 'logps/chosen': -7.246494293212891, 'logits/rejected': -3.129763126373291, 'logits/chosen': -3.0916900634765625, 'epoch': 0.1}
{'loss': 0.6336, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -0.03342079371213913, 'rewards/rejected': -0.1756775975227356, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.14225682616233826, 'logps/rejected': -8.78253173828125, 'logps/chosen': -4.345771789550781, 'logits/rejected': -3.2686777114868164, 'logits/chosen': -3.0521652698516846, 'epoch': 0.11}
{'loss': 0.5984, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -0.06446666270494461, 'rewards/rejected': -0.2552889585494995, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.1908222883939743, 'logps/rejected': -8.340630531311035, 'logps/chosen': -8.00643253326416, 'logits/rejected': -3.212924003601074, 'logits/chosen': -3.2091329097747803, 'epoch': 0.11}
{'loss': 0.577, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -0.12250059843063354, 'rewards/rejected': -0.498456746339798, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.37595614790916443, 'logps/rejected': -9.179079055786133, 'logps/chosen': -7.361149311065674, 'logits/rejected': -3.1924631595611572, 'logits/chosen': -3.263951301574707, 'epoch': 0.12}
{'loss': 0.5114, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -0.15177123248577118, 'rewards/rejected': -0.963463544845581, 'rewards/accuracies': 0.875, 'rewards/margins': 0.8116923570632935, 'logps/rejected': -14.619083404541016, 'logps/chosen': -6.954488754272461, 'logits/rejected': -3.220384120941162, 'logits/chosen': -3.2243237495422363, 'epoch': 0.13}
{'loss': 0.4189, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.256531298160553, 'rewards/rejected': -1.5662482976913452, 'rewards/accuracies': 0.90625, 'rewards/margins': 1.3097169399261475, 'logps/rejected': -22.701168060302734, 'logps/chosen': -7.465652942657471, 'logits/rejected': -3.257701873779297, 'logits/chosen': -3.2862961292266846, 'epoch': 0.13}
{'loss': 0.3096, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -0.5075705051422119, 'rewards/rejected': -2.021075487136841, 'rewards/accuracies': 0.84375, 'rewards/margins': 1.5135048627853394, 'logps/rejected': -26.65367889404297, 'logps/chosen': -10.850876808166504, 'logits/rejected': -3.1807711124420166, 'logits/chosen': -3.1429519653320312, 'epoch': 0.14}
{'loss': 0.2275, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -0.5196386575698853, 'rewards/rejected': -3.593587875366211, 'rewards/accuracies': 0.9375, 'rewards/margins': 3.0739493370056152, 'logps/rejected': -46.54109573364258, 'logps/chosen': -9.313475608825684, 'logits/rejected': -3.2798259258270264, 'logits/chosen': -2.943732976913452, 'epoch': 0.15}
{'loss': 0.2718, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -1.150517225265503, 'rewards/rejected': -4.000251293182373, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.849733829498291, 'logps/rejected': -46.651187896728516, 'logps/chosen': -18.742210388183594, 'logits/rejected': -3.0547022819519043, 'logits/chosen': -3.1110641956329346, 'epoch': 0.15}
{'loss': 0.2944, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -1.249186396598816, 'rewards/rejected': -4.398590087890625, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.1494030952453613, 'logps/rejected': -49.33900451660156, 'logps/chosen': -16.62108612060547, 'logits/rejected': -3.1702287197113037, 'logits/chosen': -3.0131235122680664, 'epoch': 0.16}
{'loss': 0.1686, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -2.0226376056671143, 'rewards/rejected': -5.953716278076172, 'rewards/accuracies': 0.875, 'rewards/margins': 3.9310789108276367, 'logps/rejected': -64.33344268798828, 'logps/chosen': -27.591093063354492, 'logits/rejected': -3.079998016357422, 'logits/chosen': -3.1418731212615967, 'epoch': 0.17}
{'loss': 0.1838, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -2.0045313835144043, 'rewards/rejected': -7.570822238922119, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.566290855407715, 'logps/rejected': -84.23804473876953, 'logps/chosen': -25.8917293548584, 'logits/rejected': -3.0578410625457764, 'logits/chosen': -2.9395902156829834, 'epoch': 0.18}
{'loss': 0.1721, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -2.1514813899993896, 'rewards/rejected': -7.146294116973877, 'rewards/accuracies': 0.875, 'rewards/margins': 4.994812488555908, 'logps/rejected': -77.12130737304688, 'logps/chosen': -28.821439743041992, 'logits/rejected': -2.94075083732605, 'logits/chosen': -2.9863789081573486, 'epoch': 0.18}
{'loss': 0.288, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -2.138190507888794, 'rewards/rejected': -7.9233551025390625, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.785163879394531, 'logps/rejected': -83.89729309082031, 'logps/chosen': -25.81338882446289, 'logits/rejected': -3.021841049194336, 'logits/chosen': -2.9857852458953857, 'epoch': 0.19}
{'loss': 0.4097, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -3.054421901702881, 'rewards/rejected': -7.699367523193359, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.64494514465332, 'logps/rejected': -83.71497344970703, 'logps/chosen': -36.646141052246094, 'logits/rejected': -2.988581657409668, 'logits/chosen': -3.012249708175659, 'epoch': 0.2}
{'loss': 0.2398, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -3.0398406982421875, 'rewards/rejected': -8.777558326721191, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.737718105316162, 'logps/rejected': -94.7953109741211, 'logps/chosen': -36.573326110839844, 'logits/rejected': -2.986217498779297, 'logits/chosen': -3.0010581016540527, 'epoch': 0.2}
{'loss': 0.2466, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -2.339832305908203, 'rewards/rejected': -10.892589569091797, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.55275821685791, 'logps/rejected': -114.96573638916016, 'logps/chosen': -30.642189025878906, 'logits/rejected': -3.0293588638305664, 'logits/chosen': -2.8757247924804688, 'epoch': 0.21}
{'loss': 0.303, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -2.970956802368164, 'rewards/rejected': -8.597612380981445, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.626656532287598, 'logps/rejected': -92.1954116821289, 'logps/chosen': -36.04098129272461, 'logits/rejected': -2.96753191947937, 'logits/chosen': -2.935518980026245, 'epoch': 0.22}
{'loss': 0.3064, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -3.5288376808166504, 'rewards/rejected': -8.787434577941895, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.258596420288086, 'logps/rejected': -94.1421890258789, 'logps/chosen': -40.47156524658203, 'logits/rejected': -3.0058794021606445, 'logits/chosen': -2.9539918899536133, 'epoch': 0.22}
{'loss': 0.3242, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -3.3196074962615967, 'rewards/rejected': -8.537900924682617, 'rewards/accuracies': 0.875, 'rewards/margins': 5.218293190002441, 'logps/rejected': -92.11756896972656, 'logps/chosen': -38.522544860839844, 'logits/rejected': -3.0806174278259277, 'logits/chosen': -2.943014144897461, 'epoch': 0.23}
{'loss': 0.4292, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -4.197856903076172, 'rewards/rejected': -7.590327262878418, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.3924710750579834, 'logps/rejected': -83.25375366210938, 'logps/chosen': -53.452606201171875, 'logits/rejected': -2.95671010017395, 'logits/chosen': -3.0587222576141357, 'epoch': 0.24}
{'loss': 0.1968, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -2.373863935470581, 'rewards/rejected': -7.1169753074646, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.7431111335754395, 'logps/rejected': -75.35270690917969, 'logps/chosen': -28.41085433959961, 'logits/rejected': -3.0679068565368652, 'logits/chosen': -3.0403354167938232, 'epoch': 0.24}
{'loss': 0.1533, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -2.2226059436798096, 'rewards/rejected': -9.27657699584961, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.053971767425537, 'logps/rejected': -100.34364318847656, 'logps/chosen': -28.66692543029785, 'logits/rejected': -3.0149428844451904, 'logits/chosen': -2.9207983016967773, 'epoch': 0.25}
{'loss': 0.1909, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -2.800773859024048, 'rewards/rejected': -7.856791973114014, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.056018352508545, 'logps/rejected': -85.22774505615234, 'logps/chosen': -36.14115905761719, 'logits/rejected': -2.9685311317443848, 'logits/chosen': -3.078810214996338, 'epoch': 0.26}
{'loss': 0.2292, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -2.661433696746826, 'rewards/rejected': -7.833344459533691, 'rewards/accuracies': 0.96875, 'rewards/margins': 5.171910762786865, 'logps/rejected': -84.55077362060547, 'logps/chosen': -32.550498962402344, 'logits/rejected': -3.1325266361236572, 'logits/chosen': -2.959136486053467, 'epoch': 0.26}
{'loss': 0.2764, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -4.099902629852295, 'rewards/rejected': -7.054248809814453, 'rewards/accuracies': 0.78125, 'rewards/margins': 2.954346179962158, 'logps/rejected': -78.37104797363281, 'logps/chosen': -52.455474853515625, 'logits/rejected': -2.889511823654175, 'logits/chosen': -3.220053195953369, 'epoch': 0.27}
{'loss': 0.1995, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -3.2504169940948486, 'rewards/rejected': -7.8228864669799805, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.572469234466553, 'logps/rejected': -84.26325225830078, 'logps/chosen': -40.20463180541992, 'logits/rejected': -3.051175832748413, 'logits/chosen': -3.0650858879089355, 'epoch': 0.28}
{'loss': 0.1633, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -3.5765724182128906, 'rewards/rejected': -9.183900833129883, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.607326984405518, 'logps/rejected': -98.31770324707031, 'logps/chosen': -41.821678161621094, 'logits/rejected': -3.1827683448791504, 'logits/chosen': -2.9799909591674805, 'epoch': 0.28}
{'loss': 0.142, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -3.4584274291992188, 'rewards/rejected': -9.866419792175293, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.407992362976074, 'logps/rejected': -105.57914733886719, 'logps/chosen': -40.57854080200195, 'logits/rejected': -3.1623265743255615, 'logits/chosen': -2.9948596954345703, 'epoch': 0.29}
{'loss': 0.2192, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -3.4155828952789307, 'rewards/rejected': -8.667559623718262, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.25197696685791, 'logps/rejected': -95.45470428466797, 'logps/chosen': -38.65732955932617, 'logits/rejected': -3.1824545860290527, 'logits/chosen': -3.13996958732605, 'epoch': 0.3}
{'loss': 0.1068, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -2.6004738807678223, 'rewards/rejected': -9.520559310913086, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.920085906982422, 'logps/rejected': -101.419189453125, 'logps/chosen': -32.835205078125, 'logits/rejected': -3.0705623626708984, 'logits/chosen': -3.0402350425720215, 'epoch': 0.3}
{'loss': 0.1679, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -3.368691921234131, 'rewards/rejected': -10.927730560302734, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.55903959274292, 'logps/rejected': -118.5084228515625, 'logps/chosen': -39.75349426269531, 'logits/rejected': -3.294182062149048, 'logits/chosen': -3.0924270153045654, 'epoch': 0.31}
{'loss': 0.1331, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -3.0165610313415527, 'rewards/rejected': -10.75008487701416, 'rewards/accuracies': 1.0, 'rewards/margins': 7.733524799346924, 'logps/rejected': -114.11907196044922, 'logps/chosen': -35.89174270629883, 'logits/rejected': -3.3678243160247803, 'logits/chosen': -3.0467448234558105, 'epoch': 0.32}
{'loss': 0.1596, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -3.3599586486816406, 'rewards/rejected': -10.622791290283203, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.262832164764404, 'logps/rejected': -111.58716583251953, 'logps/chosen': -38.291893005371094, 'logits/rejected': -3.215428352355957, 'logits/chosen': -3.200899600982666, 'epoch': 0.32}
{'loss': 0.19, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -3.506981372833252, 'rewards/rejected': -11.760939598083496, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.253958702087402, 'logps/rejected': -124.13506317138672, 'logps/chosen': -40.72087097167969, 'logits/rejected': -3.1311099529266357, 'logits/chosen': -3.106088161468506, 'epoch': 0.33}
{'loss': 0.1799, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -3.7930099964141846, 'rewards/rejected': -10.89020824432373, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.097197532653809, 'logps/rejected': -116.79679107666016, 'logps/chosen': -44.00766372680664, 'logits/rejected': -3.280179738998413, 'logits/chosen': -3.033313274383545, 'epoch': 0.34}
{'loss': 0.145, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -4.330813884735107, 'rewards/rejected': -10.620183944702148, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.289370059967041, 'logps/rejected': -113.19988250732422, 'logps/chosen': -49.207977294921875, 'logits/rejected': -3.19978928565979, 'logits/chosen': -3.1991477012634277, 'epoch': 0.34}
{'loss': 0.362, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -3.8222463130950928, 'rewards/rejected': -10.622591018676758, 'rewards/accuracies': 0.78125, 'rewards/margins': 6.800345420837402, 'logps/rejected': -111.17898559570312, 'logps/chosen': -46.82056427001953, 'logits/rejected': -3.0888497829437256, 'logits/chosen': -3.1906864643096924, 'epoch': 0.35}
{'loss': 0.1845, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -4.26991081237793, 'rewards/rejected': -10.986726760864258, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.716815948486328, 'logps/rejected': -115.2352294921875, 'logps/chosen': -50.103271484375, 'logits/rejected': -3.150164842605591, 'logits/chosen': -3.1049275398254395, 'epoch': 0.36}
{'loss': 0.2486, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -4.659881114959717, 'rewards/rejected': -11.770792007446289, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.110910415649414, 'logps/rejected': -123.27831268310547, 'logps/chosen': -55.08882522583008, 'logits/rejected': -2.9567320346832275, 'logits/chosen': -3.028635263442993, 'epoch': 0.36}
{'loss': 0.1569, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -3.670837879180908, 'rewards/rejected': -8.484928131103516, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.814090251922607, 'logps/rejected': -88.46546936035156, 'logps/chosen': -44.100257873535156, 'logits/rejected': -3.056074619293213, 'logits/chosen': -3.123875379562378, 'epoch': 0.37}
{'loss': 0.1612, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -3.813079833984375, 'rewards/rejected': -10.620773315429688, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.807694435119629, 'logps/rejected': -112.37297821044922, 'logps/chosen': -42.42633056640625, 'logits/rejected': -3.111726760864258, 'logits/chosen': -2.9610702991485596, 'epoch': 0.38}
{'loss': 0.1174, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -4.119582653045654, 'rewards/rejected': -10.04295539855957, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.923372745513916, 'logps/rejected': -106.57897186279297, 'logps/chosen': -45.87385559082031, 'logits/rejected': -3.179564952850342, 'logits/chosen': -2.9558582305908203, 'epoch': 0.38}
{'loss': 0.112, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -4.1096625328063965, 'rewards/rejected': -11.854901313781738, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.745238304138184, 'logps/rejected': -125.42308044433594, 'logps/chosen': -47.40298080444336, 'logits/rejected': -3.1845226287841797, 'logits/chosen': -2.960050106048584, 'epoch': 0.39}
{'loss': 0.1657, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -2.9783506393432617, 'rewards/rejected': -8.618535995483398, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.6401848793029785, 'logps/rejected': -89.44268798828125, 'logps/chosen': -35.68791198730469, 'logits/rejected': -2.980679750442505, 'logits/chosen': -3.044734477996826, 'epoch': 0.4}
{'loss': 0.127, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -3.0255603790283203, 'rewards/rejected': -10.394695281982422, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.369135856628418, 'logps/rejected': -111.27914428710938, 'logps/chosen': -35.15825653076172, 'logits/rejected': -3.0559799671173096, 'logits/chosen': -2.9167354106903076, 'epoch': 0.4}
{'loss': 0.1613, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -3.1672112941741943, 'rewards/rejected': -9.194209098815918, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.026998043060303, 'logps/rejected': -96.02281188964844, 'logps/chosen': -38.21173095703125, 'logits/rejected': -2.9432334899902344, 'logits/chosen': -3.050126552581787, 'epoch': 0.41}
{'loss': 0.2012, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -2.7924251556396484, 'rewards/rejected': -10.383920669555664, 'rewards/accuracies': 1.0, 'rewards/margins': 7.591495513916016, 'logps/rejected': -111.92878723144531, 'logps/chosen': -33.74918746948242, 'logits/rejected': -3.119180917739868, 'logits/chosen': -2.8677830696105957, 'epoch': 0.42}
{'loss': 0.1985, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -3.9702510833740234, 'rewards/rejected': -9.808877944946289, 'rewards/accuracies': 0.78125, 'rewards/margins': 5.838626861572266, 'logps/rejected': -104.25238037109375, 'logps/chosen': -44.202598571777344, 'logits/rejected': -3.0896975994110107, 'logits/chosen': -2.9930169582366943, 'epoch': 0.42}
{'loss': 0.2157, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -3.340151786804199, 'rewards/rejected': -8.907833099365234, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.567681312561035, 'logps/rejected': -94.47946166992188, 'logps/chosen': -39.121482849121094, 'logits/rejected': -3.048490285873413, 'logits/chosen': -2.9744837284088135, 'epoch': 0.43}
{'loss': 0.187, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -3.109590768814087, 'rewards/rejected': -11.52423095703125, 'rewards/accuracies': 0.875, 'rewards/margins': 8.414640426635742, 'logps/rejected': -121.19096374511719, 'logps/chosen': -35.59510803222656, 'logits/rejected': -2.939711809158325, 'logits/chosen': -2.8713996410369873, 'epoch': 0.44}
{'loss': 0.1842, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -3.3942346572875977, 'rewards/rejected': -10.516170501708984, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.121936798095703, 'logps/rejected': -109.97807312011719, 'logps/chosen': -39.35986328125, 'logits/rejected': -2.9413294792175293, 'logits/chosen': -2.928208351135254, 'epoch': 0.44}
{'loss': 0.1383, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -3.670262336730957, 'rewards/rejected': -9.742791175842285, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.0725297927856445, 'logps/rejected': -107.78800201416016, 'logps/chosen': -43.599388122558594, 'logits/rejected': -3.0916829109191895, 'logits/chosen': -2.8018016815185547, 'epoch': 0.45}
{'loss': 0.0877, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -3.521670341491699, 'rewards/rejected': -10.087575912475586, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.5659050941467285, 'logps/rejected': -108.17837524414062, 'logps/chosen': -42.10261154174805, 'logits/rejected': -2.928925037384033, 'logits/chosen': -2.9099440574645996, 'epoch': 0.46}
{'loss': 0.1942, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -4.2243242263793945, 'rewards/rejected': -10.886087417602539, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.661762237548828, 'logps/rejected': -115.62853240966797, 'logps/chosen': -50.20518493652344, 'logits/rejected': -2.9647104740142822, 'logits/chosen': -2.7910008430480957, 'epoch': 0.46}
{'loss': 0.1117, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -3.3349673748016357, 'rewards/rejected': -10.199420928955078, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.864453315734863, 'logps/rejected': -106.42018127441406, 'logps/chosen': -39.066802978515625, 'logits/rejected': -2.8872900009155273, 'logits/chosen': -2.809131622314453, 'epoch': 0.47}
{'loss': 0.2134, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -3.863279342651367, 'rewards/rejected': -9.006731986999512, 'rewards/accuracies': 0.71875, 'rewards/margins': 5.1434526443481445, 'logps/rejected': -94.6229476928711, 'logps/chosen': -44.64773178100586, 'logits/rejected': -2.8264236450195312, 'logits/chosen': -2.9968483448028564, 'epoch': 0.48}
{'loss': 0.1014, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -3.1007943153381348, 'rewards/rejected': -9.9708833694458, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.870089054107666, 'logps/rejected': -107.3819351196289, 'logps/chosen': -35.688777923583984, 'logits/rejected': -2.9090285301208496, 'logits/chosen': -2.8396706581115723, 'epoch': 0.49}
{'loss': 0.1727, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -3.390326738357544, 'rewards/rejected': -10.916488647460938, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.526161193847656, 'logps/rejected': -116.3388671875, 'logps/chosen': -38.5068244934082, 'logits/rejected': -3.1575894355773926, 'logits/chosen': -2.754176616668701, 'epoch': 0.49}
{'loss': 0.0807, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -2.9420523643493652, 'rewards/rejected': -12.156402587890625, 'rewards/accuracies': 1.0, 'rewards/margins': 9.214349746704102, 'logps/rejected': -131.39944458007812, 'logps/chosen': -33.32117462158203, 'logits/rejected': -3.0656399726867676, 'logits/chosen': -2.62239146232605, 'epoch': 0.5}
{'loss': 0.1449, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -3.323267936706543, 'rewards/rejected': -10.343178749084473, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.01991081237793, 'logps/rejected': -110.58365631103516, 'logps/chosen': -44.74894332885742, 'logits/rejected': -2.8522257804870605, 'logits/chosen': -2.974147081375122, 'epoch': 0.51}
{'loss': 0.135, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -3.513244390487671, 'rewards/rejected': -10.9364013671875, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.423157691955566, 'logps/rejected': -113.94034576416016, 'logps/chosen': -42.86671829223633, 'logits/rejected': -2.9483280181884766, 'logits/chosen': -3.0109362602233887, 'epoch': 0.51}
{'loss': 0.1578, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -3.7502620220184326, 'rewards/rejected': -10.970881462097168, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.220620155334473, 'logps/rejected': -115.17887115478516, 'logps/chosen': -45.405845642089844, 'logits/rejected': -2.8522658348083496, 'logits/chosen': -2.930326461791992, 'epoch': 0.52}
{'loss': 0.1399, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -4.357113838195801, 'rewards/rejected': -10.159989356994629, 'rewards/accuracies': 0.96875, 'rewards/margins': 5.802875518798828, 'logps/rejected': -106.26596069335938, 'logps/chosen': -53.08940124511719, 'logits/rejected': -2.8104798793792725, 'logits/chosen': -3.0144426822662354, 'epoch': 0.53}
{'loss': 0.1034, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -3.2287275791168213, 'rewards/rejected': -9.461328506469727, 'rewards/accuracies': 1.0, 'rewards/margins': 6.232600212097168, 'logps/rejected': -100.12296295166016, 'logps/chosen': -36.37895584106445, 'logits/rejected': -2.9871535301208496, 'logits/chosen': -2.8318448066711426, 'epoch': 0.53}
{'loss': 0.1851, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -3.9546396732330322, 'rewards/rejected': -9.74807071685791, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.793431282043457, 'logps/rejected': -105.38800811767578, 'logps/chosen': -46.28999328613281, 'logits/rejected': -3.001617193222046, 'logits/chosen': -2.9071011543273926, 'epoch': 0.54}
{'loss': 0.1397, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -3.757219076156616, 'rewards/rejected': -11.895594596862793, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.138376235961914, 'logps/rejected': -124.12611389160156, 'logps/chosen': -45.79722595214844, 'logits/rejected': -2.7500948905944824, 'logits/chosen': -2.947399854660034, 'epoch': 0.55}
{'loss': 0.1268, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -3.8517491817474365, 'rewards/rejected': -11.774088859558105, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.922339916229248, 'logps/rejected': -122.92696380615234, 'logps/chosen': -44.120731353759766, 'logits/rejected': -2.82299542427063, 'logits/chosen': -2.9050724506378174, 'epoch': 0.55}
{'loss': 0.1148, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -3.8664560317993164, 'rewards/rejected': -11.90121078491211, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.034754753112793, 'logps/rejected': -125.10438537597656, 'logps/chosen': -43.954105377197266, 'logits/rejected': -2.9618804454803467, 'logits/chosen': -2.863184928894043, 'epoch': 0.56}
{'loss': 0.0829, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -4.902346611022949, 'rewards/rejected': -13.969636917114258, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.067290306091309, 'logps/rejected': -146.67173767089844, 'logps/chosen': -57.50932312011719, 'logits/rejected': -2.843111753463745, 'logits/chosen': -2.8271477222442627, 'epoch': 0.57}
{'loss': 0.1393, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -4.539739608764648, 'rewards/rejected': -13.493087768554688, 'rewards/accuracies': 1.0, 'rewards/margins': 8.953348159790039, 'logps/rejected': -141.88247680664062, 'logps/chosen': -52.62263488769531, 'logits/rejected': -2.825287342071533, 'logits/chosen': -2.8965344429016113, 'epoch': 0.57}
{'loss': 0.1646, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -4.547708988189697, 'rewards/rejected': -13.240175247192383, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.692465782165527, 'logps/rejected': -138.56332397460938, 'logps/chosen': -51.76945495605469, 'logits/rejected': -2.9021525382995605, 'logits/chosen': -2.893338203430176, 'epoch': 0.58}
{'loss': 0.179, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -3.803462505340576, 'rewards/rejected': -12.055221557617188, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.251758575439453, 'logps/rejected': -127.52128601074219, 'logps/chosen': -44.20272445678711, 'logits/rejected': -2.9044859409332275, 'logits/chosen': -2.7876811027526855, 'epoch': 0.59}
{'loss': 0.2893, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -5.202139377593994, 'rewards/rejected': -11.727919578552246, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.5257792472839355, 'logps/rejected': -123.81747436523438, 'logps/chosen': -56.805824279785156, 'logits/rejected': -2.9160914421081543, 'logits/chosen': -2.9088501930236816, 'epoch': 0.59}
{'loss': 0.1838, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -4.415253639221191, 'rewards/rejected': -12.847185134887695, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.431931495666504, 'logps/rejected': -133.35696411132812, 'logps/chosen': -49.06395721435547, 'logits/rejected': -2.9375815391540527, 'logits/chosen': -2.7691891193389893, 'epoch': 0.6}
{'loss': 0.2304, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -5.293078422546387, 'rewards/rejected': -11.615642547607422, 'rewards/accuracies': 0.875, 'rewards/margins': 6.322563171386719, 'logps/rejected': -120.99586486816406, 'logps/chosen': -60.079917907714844, 'logits/rejected': -2.835491180419922, 'logits/chosen': -2.8981494903564453, 'epoch': 0.61}
{'loss': 0.1137, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -5.188460350036621, 'rewards/rejected': -11.709090232849121, 'rewards/accuracies': 0.875, 'rewards/margins': 6.520630359649658, 'logps/rejected': -121.30755615234375, 'logps/chosen': -60.26755142211914, 'logits/rejected': -2.6857638359069824, 'logits/chosen': -2.8965959548950195, 'epoch': 0.61}
{'loss': 0.1123, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -4.488947868347168, 'rewards/rejected': -14.097209930419922, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.60826301574707, 'logps/rejected': -152.86749267578125, 'logps/chosen': -49.29239273071289, 'logits/rejected': -3.257519483566284, 'logits/chosen': -2.519254684448242, 'epoch': 0.62}
{'loss': 0.0839, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -4.980692386627197, 'rewards/rejected': -12.49581527709961, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.51512336730957, 'logps/rejected': -131.3169708251953, 'logps/chosen': -55.512001037597656, 'logits/rejected': -2.954009771347046, 'logits/chosen': -2.924534559249878, 'epoch': 0.63}
{'loss': 0.2326, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -4.643366813659668, 'rewards/rejected': -13.645020484924316, 'rewards/accuracies': 1.0, 'rewards/margins': 9.001652717590332, 'logps/rejected': -145.1171875, 'logps/chosen': -52.054256439208984, 'logits/rejected': -2.8547348976135254, 'logits/chosen': -2.8212127685546875, 'epoch': 0.63}
{'loss': 0.1158, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -4.466735363006592, 'rewards/rejected': -11.46923542022705, 'rewards/accuracies': 0.875, 'rewards/margins': 7.002500534057617, 'logps/rejected': -119.06266021728516, 'logps/chosen': -49.62642288208008, 'logits/rejected': -2.7924964427948, 'logits/chosen': -2.8755686283111572, 'epoch': 0.64}
{'loss': 0.1258, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -4.17331600189209, 'rewards/rejected': -11.262381553649902, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.089066028594971, 'logps/rejected': -118.83901977539062, 'logps/chosen': -47.632911682128906, 'logits/rejected': -3.0414297580718994, 'logits/chosen': -2.8571529388427734, 'epoch': 0.65}
{'loss': 0.1517, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -3.9918928146362305, 'rewards/rejected': -12.740081787109375, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.748189926147461, 'logps/rejected': -135.1630859375, 'logps/chosen': -44.70472717285156, 'logits/rejected': -3.000422954559326, 'logits/chosen': -2.814667224884033, 'epoch': 0.65}
{'loss': 0.0881, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -3.8333592414855957, 'rewards/rejected': -14.09693431854248, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.263577461242676, 'logps/rejected': -148.48020935058594, 'logps/chosen': -45.14047622680664, 'logits/rejected': -2.9600205421447754, 'logits/chosen': -2.8030529022216797, 'epoch': 0.66}
{'loss': 0.1926, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -4.053597450256348, 'rewards/rejected': -10.543848037719727, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.490250110626221, 'logps/rejected': -111.18080139160156, 'logps/chosen': -48.87057113647461, 'logits/rejected': -2.873441457748413, 'logits/chosen': -2.962228775024414, 'epoch': 0.67}
{'loss': 0.1522, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -4.533395290374756, 'rewards/rejected': -12.923182487487793, 'rewards/accuracies': 0.875, 'rewards/margins': 8.389786720275879, 'logps/rejected': -135.66358947753906, 'logps/chosen': -52.468528747558594, 'logits/rejected': -2.9004342555999756, 'logits/chosen': -2.9459004402160645, 'epoch': 0.67}
{'loss': 0.1181, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -3.8453431129455566, 'rewards/rejected': -11.683096885681152, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.837754249572754, 'logps/rejected': -121.96211242675781, 'logps/chosen': -44.331329345703125, 'logits/rejected': -2.8694422245025635, 'logits/chosen': -2.8874080181121826, 'epoch': 0.68}
{'loss': 0.1336, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -4.517981052398682, 'rewards/rejected': -11.411903381347656, 'rewards/accuracies': 0.875, 'rewards/margins': 6.893923759460449, 'logps/rejected': -118.71312713623047, 'logps/chosen': -51.93832778930664, 'logits/rejected': -2.8103513717651367, 'logits/chosen': -2.9662694931030273, 'epoch': 0.69}
{'loss': 0.1362, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -3.311271905899048, 'rewards/rejected': -12.034454345703125, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.72318172454834, 'logps/rejected': -126.49745178222656, 'logps/chosen': -37.10588073730469, 'logits/rejected': -3.0463438034057617, 'logits/chosen': -2.645578384399414, 'epoch': 0.69}
{'loss': 0.2283, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -3.4537298679351807, 'rewards/rejected': -11.297989845275879, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.844260215759277, 'logps/rejected': -120.60489654541016, 'logps/chosen': -41.38241195678711, 'logits/rejected': -2.9774184226989746, 'logits/chosen': -2.8008415699005127, 'epoch': 0.7}
{'loss': 0.092, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -4.367905139923096, 'rewards/rejected': -12.367554664611816, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.9996490478515625, 'logps/rejected': -129.67864990234375, 'logps/chosen': -50.29867172241211, 'logits/rejected': -2.959930181503296, 'logits/chosen': -2.889592170715332, 'epoch': 0.71}
{'loss': 0.0423, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -2.785749912261963, 'rewards/rejected': -13.951178550720215, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.16542911529541, 'logps/rejected': -146.67759704589844, 'logps/chosen': -32.32902908325195, 'logits/rejected': -3.0569117069244385, 'logits/chosen': -2.621994972229004, 'epoch': 0.71}
{'loss': 0.152, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -3.3844332695007324, 'rewards/rejected': -12.307514190673828, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.923080444335938, 'logps/rejected': -127.98745727539062, 'logps/chosen': -39.826541900634766, 'logits/rejected': -2.8912887573242188, 'logits/chosen': -2.759155750274658, 'epoch': 0.72}
{'loss': 0.1586, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -3.3286688327789307, 'rewards/rejected': -12.911613464355469, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.582944869995117, 'logps/rejected': -136.35214233398438, 'logps/chosen': -39.21072769165039, 'logits/rejected': -3.0028929710388184, 'logits/chosen': -2.676159620285034, 'epoch': 0.73}
{'loss': 0.1389, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -4.058396816253662, 'rewards/rejected': -12.21396255493164, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.155566215515137, 'logps/rejected': -128.3172607421875, 'logps/chosen': -49.48542022705078, 'logits/rejected': -2.647231101989746, 'logits/chosen': -2.853100299835205, 'epoch': 0.73}
{'loss': 0.1827, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -4.039097309112549, 'rewards/rejected': -12.009523391723633, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.970426082611084, 'logps/rejected': -126.88829040527344, 'logps/chosen': -45.09980773925781, 'logits/rejected': -3.012969970703125, 'logits/chosen': -2.697496175765991, 'epoch': 0.74}
{'loss': 0.1093, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -3.62536358833313, 'rewards/rejected': -12.489667892456055, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.864303588867188, 'logps/rejected': -133.66470336914062, 'logps/chosen': -41.71196365356445, 'logits/rejected': -2.8847854137420654, 'logits/chosen': -2.7858681678771973, 'epoch': 0.75}
{'loss': 0.1388, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -4.8217620849609375, 'rewards/rejected': -13.890974998474121, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.069212913513184, 'logps/rejected': -145.30172729492188, 'logps/chosen': -55.75114059448242, 'logits/rejected': -2.824897527694702, 'logits/chosen': -2.83451509475708, 'epoch': 0.75}
{'loss': 0.1009, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -4.499797821044922, 'rewards/rejected': -12.043917655944824, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.544119358062744, 'logps/rejected': -126.28233337402344, 'logps/chosen': -50.197181701660156, 'logits/rejected': -2.973186492919922, 'logits/chosen': -2.828562021255493, 'epoch': 0.76}
{'loss': 0.1335, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -4.0159101486206055, 'rewards/rejected': -12.873111724853516, 'rewards/accuracies': 0.875, 'rewards/margins': 8.85720157623291, 'logps/rejected': -135.3842315673828, 'logps/chosen': -43.841148376464844, 'logits/rejected': -3.0993118286132812, 'logits/chosen': -2.718654155731201, 'epoch': 0.77}
{'loss': 0.1098, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -4.96021842956543, 'rewards/rejected': -12.370209693908691, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.409990310668945, 'logps/rejected': -130.2197723388672, 'logps/chosen': -57.697547912597656, 'logits/rejected': -2.8477768898010254, 'logits/chosen': -2.9439010620117188, 'epoch': 0.77}
{'loss': 0.1497, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -3.9985203742980957, 'rewards/rejected': -10.805103302001953, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.806582927703857, 'logps/rejected': -114.78846740722656, 'logps/chosen': -46.104766845703125, 'logits/rejected': -2.917494535446167, 'logits/chosen': -2.805138349533081, 'epoch': 0.78}
{'loss': 0.1344, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -5.068064212799072, 'rewards/rejected': -14.68509578704834, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.617032051086426, 'logps/rejected': -156.62405395507812, 'logps/chosen': -57.75929641723633, 'logits/rejected': -2.94059419631958, 'logits/chosen': -2.69252347946167, 'epoch': 0.79}
{'loss': 0.1719, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -4.532662868499756, 'rewards/rejected': -13.650137901306152, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.117474555969238, 'logps/rejected': -144.28036499023438, 'logps/chosen': -51.9461784362793, 'logits/rejected': -2.8702056407928467, 'logits/chosen': -2.7965941429138184, 'epoch': 0.8}
{'loss': 0.1271, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -5.002532958984375, 'rewards/rejected': -13.213593482971191, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.2110595703125, 'logps/rejected': -138.33676147460938, 'logps/chosen': -57.77813720703125, 'logits/rejected': -2.8827526569366455, 'logits/chosen': -2.876121997833252, 'epoch': 0.8}
{'loss': 0.1454, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -3.6240484714508057, 'rewards/rejected': -10.077293395996094, 'rewards/accuracies': 0.875, 'rewards/margins': 6.453245639801025, 'logps/rejected': -106.38710021972656, 'logps/chosen': -41.83128356933594, 'logits/rejected': -2.916158437728882, 'logits/chosen': -2.9105875492095947, 'epoch': 0.81}
{'loss': 0.1862, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -4.544478416442871, 'rewards/rejected': -11.628859519958496, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.084382057189941, 'logps/rejected': -122.33562469482422, 'logps/chosen': -52.211647033691406, 'logits/rejected': -2.888643741607666, 'logits/chosen': -2.901811122894287, 'epoch': 0.82}
{'loss': 0.1095, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -5.015396595001221, 'rewards/rejected': -12.894749641418457, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.879352569580078, 'logps/rejected': -136.93646240234375, 'logps/chosen': -55.855323791503906, 'logits/rejected': -3.012784242630005, 'logits/chosen': -2.7754127979278564, 'epoch': 0.82}
{'loss': 0.1262, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -3.722501754760742, 'rewards/rejected': -12.576086044311523, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.853584289550781, 'logps/rejected': -130.66842651367188, 'logps/chosen': -41.945228576660156, 'logits/rejected': -2.868156909942627, 'logits/chosen': -2.798694372177124, 'epoch': 0.83}
{'loss': 0.1282, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -3.3854315280914307, 'rewards/rejected': -12.51355266571045, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.128121376037598, 'logps/rejected': -132.00270080566406, 'logps/chosen': -39.518287658691406, 'logits/rejected': -2.9836134910583496, 'logits/chosen': -2.7924323081970215, 'epoch': 0.84}
{'loss': 0.1056, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -3.708340883255005, 'rewards/rejected': -12.015726089477539, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.30738353729248, 'logps/rejected': -126.88455200195312, 'logps/chosen': -42.673927307128906, 'logits/rejected': -2.8942041397094727, 'logits/chosen': -2.793149948120117, 'epoch': 0.84}
{'loss': 0.1659, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -4.088742256164551, 'rewards/rejected': -11.175657272338867, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.086914539337158, 'logps/rejected': -119.1640853881836, 'logps/chosen': -48.017974853515625, 'logits/rejected': -2.87419056892395, 'logits/chosen': -2.908789873123169, 'epoch': 0.85}
{'loss': 0.1018, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -4.2593793869018555, 'rewards/rejected': -13.193860054016113, 'rewards/accuracies': 0.875, 'rewards/margins': 8.934480667114258, 'logps/rejected': -140.6437530517578, 'logps/chosen': -48.02555465698242, 'logits/rejected': -2.994877576828003, 'logits/chosen': -2.801398515701294, 'epoch': 0.86}
{'loss': 0.1244, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -3.6065802574157715, 'rewards/rejected': -12.350587844848633, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.74400806427002, 'logps/rejected': -129.6853485107422, 'logps/chosen': -40.70829391479492, 'logits/rejected': -2.946181058883667, 'logits/chosen': -2.8770368099212646, 'epoch': 0.86}
{'loss': 0.1666, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -4.13383674621582, 'rewards/rejected': -12.609874725341797, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.47603702545166, 'logps/rejected': -132.4434356689453, 'logps/chosen': -45.44487380981445, 'logits/rejected': -3.0060033798217773, 'logits/chosen': -2.7030484676361084, 'epoch': 0.87}
{'loss': 0.132, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -3.6637985706329346, 'rewards/rejected': -12.5907564163208, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.926958084106445, 'logps/rejected': -132.58111572265625, 'logps/chosen': -43.44718551635742, 'logits/rejected': -2.8848953247070312, 'logits/chosen': -2.924334764480591, 'epoch': 0.88}
{'loss': 0.1964, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -5.005303382873535, 'rewards/rejected': -12.281455993652344, 'rewards/accuracies': 0.84375, 'rewards/margins': 7.276153087615967, 'logps/rejected': -131.60240173339844, 'logps/chosen': -54.84780502319336, 'logits/rejected': -3.1400070190429688, 'logits/chosen': -2.761920690536499, 'epoch': 0.88}
{'loss': 0.0878, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -4.5728631019592285, 'rewards/rejected': -12.636085510253906, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.063222885131836, 'logps/rejected': -132.93582153320312, 'logps/chosen': -54.99470520019531, 'logits/rejected': -2.8704967498779297, 'logits/chosen': -2.902987241744995, 'epoch': 0.89}
{'loss': 0.2161, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -4.351296901702881, 'rewards/rejected': -12.65796184539795, 'rewards/accuracies': 0.875, 'rewards/margins': 8.30666446685791, 'logps/rejected': -137.54779052734375, 'logps/chosen': -50.721736907958984, 'logits/rejected': -3.006784439086914, 'logits/chosen': -2.8326663970947266, 'epoch': 0.9}
{'loss': 0.0784, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -3.722419023513794, 'rewards/rejected': -11.815909385681152, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.093490600585938, 'logps/rejected': -125.4892578125, 'logps/chosen': -46.065887451171875, 'logits/rejected': -2.8635971546173096, 'logits/chosen': -2.8215866088867188, 'epoch': 0.9}
{'loss': 0.0982, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -3.4692044258117676, 'rewards/rejected': -12.732173919677734, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.262968063354492, 'logps/rejected': -135.03623962402344, 'logps/chosen': -39.74578857421875, 'logits/rejected': -3.0248396396636963, 'logits/chosen': -2.738356590270996, 'epoch': 0.91}
{'loss': 0.0962, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -4.218687057495117, 'rewards/rejected': -12.712974548339844, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.49428653717041, 'logps/rejected': -133.4031982421875, 'logps/chosen': -51.99536895751953, 'logits/rejected': -2.8869199752807617, 'logits/chosen': -2.8591468334198, 'epoch': 0.92}
{'loss': 0.1194, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -4.261436462402344, 'rewards/rejected': -12.556081771850586, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.294644355773926, 'logps/rejected': -128.88726806640625, 'logps/chosen': -51.99293899536133, 'logits/rejected': -2.6695165634155273, 'logits/chosen': -2.996053695678711, 'epoch': 0.92}
{'loss': 0.1438, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -3.796210765838623, 'rewards/rejected': -10.963138580322266, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.166928291320801, 'logps/rejected': -115.48713684082031, 'logps/chosen': -44.355770111083984, 'logits/rejected': -2.933833360671997, 'logits/chosen': -2.8562684059143066, 'epoch': 0.93}
{'loss': 0.139, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -4.434526443481445, 'rewards/rejected': -13.445286750793457, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.010760307312012, 'logps/rejected': -140.56182861328125, 'logps/chosen': -50.45402145385742, 'logits/rejected': -2.932032346725464, 'logits/chosen': -2.7626230716705322, 'epoch': 0.94}
{'loss': 0.1742, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -5.436398506164551, 'rewards/rejected': -12.162700653076172, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.726301193237305, 'logps/rejected': -125.55390930175781, 'logps/chosen': -61.7379150390625, 'logits/rejected': -2.7082812786102295, 'logits/chosen': -3.099219560623169, 'epoch': 0.94}
{'loss': 0.297, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -4.429908752441406, 'rewards/rejected': -12.098604202270508, 'rewards/accuracies': 0.875, 'rewards/margins': 7.668694496154785, 'logps/rejected': -126.17755126953125, 'logps/chosen': -51.514747619628906, 'logits/rejected': -2.8547048568725586, 'logits/chosen': -2.9399867057800293, 'epoch': 0.95}
{'loss': 0.1179, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -3.248023271560669, 'rewards/rejected': -11.884381294250488, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.636358261108398, 'logps/rejected': -123.83587646484375, 'logps/chosen': -36.39152526855469, 'logits/rejected': -2.9305167198181152, 'logits/chosen': -2.7343456745147705, 'epoch': 0.96}
{'loss': 0.1141, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -3.6361806392669678, 'rewards/rejected': -12.287843704223633, 'rewards/accuracies': 1.0, 'rewards/margins': 8.65166187286377, 'logps/rejected': -131.3890380859375, 'logps/chosen': -41.83689880371094, 'logits/rejected': -3.1493144035339355, 'logits/chosen': -2.7114686965942383, 'epoch': 0.96}
{'loss': 0.194, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -5.036710262298584, 'rewards/rejected': -11.013370513916016, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.976661205291748, 'logps/rejected': -119.13478088378906, 'logps/chosen': -59.28341293334961, 'logits/rejected': -2.8082220554351807, 'logits/chosen': -2.8482844829559326, 'epoch': 0.97}
{'loss': 0.085, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -3.187537908554077, 'rewards/rejected': -12.925899505615234, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.738361358642578, 'logps/rejected': -133.9874267578125, 'logps/chosen': -38.867576599121094, 'logits/rejected': -2.8940892219543457, 'logits/chosen': -2.7734243869781494, 'epoch': 0.98}
{'loss': 0.1941, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -4.897397518157959, 'rewards/rejected': -11.894912719726562, 'rewards/accuracies': 0.8125, 'rewards/margins': 6.997514724731445, 'logps/rejected': -124.4940185546875, 'logps/chosen': -56.712547302246094, 'logits/rejected': -2.818718910217285, 'logits/chosen': -2.9033420085906982, 'epoch': 0.98}
{'loss': 0.1413, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -3.8392558097839355, 'rewards/rejected': -12.155994415283203, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.316740036010742, 'logps/rejected': -129.41639709472656, 'logps/chosen': -43.19004440307617, 'logits/rejected': -2.959559679031372, 'logits/chosen': -2.7644381523132324, 'epoch': 0.99}
{'loss': 0.1337, 'learning_rate': 0.0, 'rewards/chosen': -3.5519521236419678, 'rewards/rejected': -12.259828567504883, 'rewards/accuracies': 0.875, 'rewards/margins': 8.707876205444336, 'logps/rejected': -127.93318939208984, 'logps/chosen': -40.98991394042969, 'logits/rejected': -2.9560353755950928, 'logits/chosen': -2.812535285949707, 'epoch': 1.0}
