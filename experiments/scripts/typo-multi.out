[2024-03-08 23:08:49,922][root][INFO] - beta: 0.1
[2024-03-08 23:08:49,922][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 6000
n harmless: 6000
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities in the 20th century.\n\nTo answer your question, Brown Tree snakes are not native to North America.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry, but I do not have any information about the native species of snakes in North America.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities in the 20th century.\n\nTo answer your question, Brown Tree snakes are not native to North America.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry, but I do not have any information about the native species of snakes in North America.'}
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry to tell you that I do not know if Brown Tree snakes are native to North America.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry to tell you that I do not know if Brown Tree snakes are native to North America.'}
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent or dangerous.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent or dangerous.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands."}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
24000
tokenized 24000 training examples...
train dataset has 24000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Epoch 0, Step 0: train/loss = 0.6106560230255127, train/raw-loss = 0.6106560230255127, train/logprobs = tensor([[-0.9529, -1.8004],
        [-1.0816, -1.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6022743582725525, train/raw-loss = 0.6022743582725525, train/logprobs = tensor([[-1.1806, -1.3142],
        [-1.4215, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6017001271247864, train/raw-loss = 0.6017001271247864, train/logprobs = tensor([[-0.7873, -2.2443],
        [-0.8709, -1.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.653388261795044, train/raw-loss = 0.653388261795044, train/logprobs = tensor([[-0.8927, -1.3005],
        [-0.9771, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.5911462306976318, train/raw-loss = 0.5911462306976318, train/logprobs = tensor([[-0.9901, -1.4641],
        [-1.1711, -1.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6191325187683105, train/raw-loss = 0.6191325187683105, train/logprobs = tensor([[-0.7368, -1.4825],
        [-0.7840, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5857088565826416, train/raw-loss = 0.5857088565826416, train/logprobs = tensor([[-1.1114, -1.6912],
        [-1.2120, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6137421727180481, train/raw-loss = 0.6137421727180481, train/logprobs = tensor([[-1.1252, -1.7026],
        [-1.2798, -1.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.570385217666626, train/raw-loss = 0.570385217666626, train/logprobs = tensor([[-1.1834, -1.8980],
        [-1.3329, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6732959747314453, train/raw-loss = 0.6732959747314453, train/logprobs = tensor([[-0.6939, -1.2601],
        [-0.7148, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.639274001121521, train/raw-loss = 0.639274001121521, train/logprobs = tensor([[-1.2503, -1.5523],
        [-1.4778, -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.5836418867111206, train/raw-loss = 0.5836418867111206, train/logprobs = tensor([[-0.7800, -1.7310],
        [-0.9467, -1.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6226556897163391, train/raw-loss = 0.6226556897163391, train/logprobs = tensor([[-0.9834, -1.0012],
        [-1.2108, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.5753618478775024, train/raw-loss = 0.5753618478775024, train/logprobs = tensor([[-0.9393, -1.7788],
        [-1.1795, -1.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.5508346557617188, train/raw-loss = 0.5508346557617188, train/logprobs = tensor([[-1.0351, -2.2019],
        [-1.1691, -1.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5821824669837952, train/raw-loss = 0.5821824669837952, train/logprobs = tensor([[-0.7210, -2.1971],
        [-0.8690, -1.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6312906742095947, train/raw-loss = 0.6312906742095947, train/logprobs = tensor([[-0.7466, -1.4868],
        [-0.8294, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.588430643081665, train/raw-loss = 0.588430643081665, train/logprobs = tensor([[-0.9725, -1.4954],
        [-1.2127, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6176490783691406, train/raw-loss = 0.6176490783691406, train/logprobs = tensor([[-0.9817, -1.2580],
        [-1.1454, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.645828366279602, train/raw-loss = 0.645828366279602, train/logprobs = tensor([[-0.8057, -1.2655],
        [-0.8727, -1.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6034622192382812, train/raw-loss = 0.6034622192382812, train/logprobs = tensor([[-1.1944, -1.3137],
        [-1.4272, -1.1560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6053310036659241, train/raw-loss = 0.6053310036659241, train/logprobs = tensor([[-1.2605, -1.3347],
        [-1.4384, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.5972276329994202, train/raw-loss = 0.5972276329994202, train/logprobs = tensor([[-1.2217, -1.6198],
        [-1.4501, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6531752347946167, train/raw-loss = 0.6531752347946167, train/logprobs = tensor([[-0.9428, -1.2914],
        [-1.0137, -1.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6394085884094238, train/raw-loss = 0.6394085884094238, train/logprobs = tensor([[-0.6371, -1.2823],
        [-0.7033, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6077264547348022, train/raw-loss = 0.6077264547348022, train/logprobs = tensor([[-0.8947, -1.3646],
        [-1.0119, -1.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6222440600395203, train/raw-loss = 0.6222440600395203, train/logprobs = tensor([[-0.9572, -1.4071],
        [-1.1162, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5417518019676208, train/raw-loss = 0.5417518019676208, train/logprobs = tensor([[-1.1021, -1.7957],
        [-1.3039, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6613426208496094, train/raw-loss = 0.6613426208496094, train/logprobs = tensor([[-0.4782, -1.1899],
        [-0.5138, -1.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6209985017776489, train/raw-loss = 0.6209985017776489, train/logprobs = tensor([[-0.8263, -1.3682],
        [-0.9588, -1.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6261694431304932, train/raw-loss = 0.6261694431304932, train/logprobs = tensor([[-0.9757, -1.4702],
        [-1.1154, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462875604629517, train/raw-loss = 0.6462875604629517, train/logprobs = tensor([[-0.9363, -1.5040],
        [-1.0517, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6136875152587891, train/raw-loss = 0.6136875152587891, train/logprobs = tensor([[-0.9325, -1.3771],
        [-1.0369, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.5990153551101685, train/raw-loss = 0.5990153551101685, train/logprobs = tensor([[-0.9206, -1.6518],
        [-1.0507, -1.3539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6118048429489136, train/raw-loss = 0.6118048429489136, train/logprobs = tensor([[-0.9797, -1.4557],
        [-1.0943, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6117624044418335, train/raw-loss = 0.6117624044418335, train/logprobs = tensor([[-1.0210, -1.8201],
        [-1.1716, -1.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6514041423797607, train/raw-loss = 0.6514041423797607, train/logprobs = tensor([[-0.6380, -1.4479],
        [-0.6698, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6500111222267151, train/raw-loss = 0.6500111222267151, train/logprobs = tensor([[-0.9117, -1.1514],
        [-1.0456, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6217358112335205, train/raw-loss = 0.6217358112335205, train/logprobs = tensor([[-1.0890, -2.0045],
        [-1.2664, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.5882977247238159, train/raw-loss = 0.5882977247238159, train/logprobs = tensor([[-0.8472, -1.9052],
        [-0.9890, -1.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6324361562728882, train/raw-loss = 0.6324361562728882, train/logprobs = tensor([[-1.1103, -1.0365],
        [-1.2512, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6382214426994324, train/raw-loss = 0.6382214426994324, train/logprobs = tensor([[-0.7654, -1.8555],
        [-0.8112, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6424832344055176, train/raw-loss = 0.6424832344055176, train/logprobs = tensor([[-1.2290, -1.4725],
        [-1.3526, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6296088099479675, train/raw-loss = 0.6296088099479675, train/logprobs = tensor([[-0.9496, -1.6653],
        [-1.0584, -1.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6451987028121948, train/raw-loss = 0.6451987028121948, train/logprobs = tensor([[-1.0072, -1.3375],
        [-1.0888, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6232824325561523, train/raw-loss = 0.6232824325561523, train/logprobs = tensor([[-0.8634, -1.2845],
        [-0.9682, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5943669676780701, train/raw-loss = 0.5943669676780701, train/logprobs = tensor([[-1.0195, -1.7847],
        [-1.1566, -1.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6371410489082336, train/raw-loss = 0.6371410489082336, train/logprobs = tensor([[-0.6949, -1.6991],
        [-0.7627, -1.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6556570529937744, train/raw-loss = 0.6556570529937744, train/logprobs = tensor([[-0.9100, -1.4300],
        [-0.9805, -1.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6290645003318787, train/raw-loss = 0.6290645003318787, train/logprobs = tensor([[-0.8201, -1.3772],
        [-0.9516, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5799583196640015, train/raw-loss = 0.5799583196640015, train/logprobs = tensor([[-1.0223, -1.9422],
        [-1.1738, -1.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6495503187179565, train/raw-loss = 0.6495503187179565, train/logprobs = tensor([[-0.6692, -1.3044],
        [-0.7422, -1.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6047499775886536, train/raw-loss = 0.6047499775886536, train/logprobs = tensor([[-1.0065, -1.7946],
        [-1.1577, -1.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6327551603317261, train/raw-loss = 0.6327551603317261, train/logprobs = tensor([[-0.9733, -1.7045],
        [-1.1445, -1.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6061714887619019, train/raw-loss = 0.6061714887619019, train/logprobs = tensor([[-1.0543, -1.2816],
        [-1.3540, -1.1895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.5898754596710205, train/raw-loss = 0.5898754596710205, train/logprobs = tensor([[-1.1865, -1.9908],
        [-1.3565, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6275315880775452, train/raw-loss = 0.6275315880775452, train/logprobs = tensor([[-0.8761, -1.6807],
        [-0.9764, -1.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6032692193984985, train/raw-loss = 0.6032692193984985, train/logprobs = tensor([[-1.0281, -1.7097],
        [-1.1795, -1.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.61979079246521, train/raw-loss = 0.61979079246521, train/logprobs = tensor([[-0.9029, -1.8781],
        [-1.0432, -1.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6761795282363892, train/raw-loss = 0.6761795282363892, train/logprobs = tensor([[-0.5605, -1.4496],
        [-0.6116, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.5881545543670654, train/raw-loss = 0.5881545543670654, train/logprobs = tensor([[-1.2968, -2.2181],
        [-1.5848, -2.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6462216973304749, train/raw-loss = 0.6462216973304749, train/logprobs = tensor([[-0.9361, -1.5316],
        [-1.0479, -1.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6466503739356995, train/raw-loss = 0.6466503739356995, train/logprobs = tensor([[-0.5974, -1.7560],
        [-0.6822, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.5329763889312744, train/raw-loss = 0.5329763889312744, train/logprobs = tensor([[-1.0631, -3.1737],
        [-1.1931, -2.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.5722109079360962, train/raw-loss = 0.5706393122673035, train/logprobs = tensor([[-0.6919, -1.7998],
        [-0.7750, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015716008841991425
Epoch 0, Step 65: train/loss = 0.5425616502761841, train/raw-loss = 0.5416573882102966, train/logprobs = tensor([[-1.1028, -1.5443],
        [-1.3501, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009043202735483646
Epoch 0, Step 66: train/loss = 0.6132851243019104, train/raw-loss = 0.6119895577430725, train/logprobs = tensor([[-0.9712, -1.6838],
        [-1.0682, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012955277226865292
Epoch 0, Step 67: train/loss = 0.5979025959968567, train/raw-loss = 0.5967801809310913, train/logprobs = tensor([[-0.7480, -1.4200],
        [-0.8622, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011223928071558475
Epoch 0, Step 68: train/loss = 0.5239679217338562, train/raw-loss = 0.5226668119430542, train/logprobs = tensor([[-1.2251, -2.2187],
        [-1.3812, -1.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013010719791054726
Epoch 0, Step 69: train/loss = 0.5555171966552734, train/raw-loss = 0.554216206073761, train/logprobs = tensor([[-1.0704, -1.1417],
        [-1.2863, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013010137714445591
Epoch 0, Step 70: train/loss = 0.5801367163658142, train/raw-loss = 0.5782903432846069, train/logprobs = tensor([[-1.3225, -1.6246],
        [-1.4763, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018463635817170143
Epoch 0, Step 71: train/loss = 0.5279831290245056, train/raw-loss = 0.526882529258728, train/logprobs = tensor([[-0.9854, -1.8397],
        [-1.2025, -1.3105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011005541309714317
Epoch 0, Step 72: train/loss = 0.5103579163551331, train/raw-loss = 0.509357213973999, train/logprobs = tensor([[-0.9295, -2.7105],
        [-1.0126, -1.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01000694464892149
Epoch 0, Step 73: train/loss = 0.610690712928772, train/raw-loss = 0.6096740961074829, train/logprobs = tensor([[-0.9256, -1.1577],
        [-0.9816, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010165979154407978
Epoch 0, Step 74: train/loss = 0.5838283896446228, train/raw-loss = 0.5826143026351929, train/logprobs = tensor([[-0.8285, -1.6897],
        [-0.8565, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01214038860052824
Epoch 0, Step 75: train/loss = 0.5657363533973694, train/raw-loss = 0.5644596219062805, train/logprobs = tensor([[-0.7676, -1.9247],
        [-0.8074, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01276768371462822
Epoch 0, Step 76: train/loss = 0.5287549495697021, train/raw-loss = 0.5275298357009888, train/logprobs = tensor([[-0.8568, -2.2229],
        [-0.8959, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012251201085746288
Epoch 0, Step 77: train/loss = 0.5665153861045837, train/raw-loss = 0.5654599666595459, train/logprobs = tensor([[-1.0129, -2.0091],
        [-1.1982, -1.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010553792119026184
Epoch 0, Step 78: train/loss = 0.5937230587005615, train/raw-loss = 0.5920261740684509, train/logprobs = tensor([[-0.8998, -1.5195],
        [-1.0534, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01696968823671341
Epoch 0, Step 79: train/loss = 0.6042416095733643, train/raw-loss = 0.6027408242225647, train/logprobs = tensor([[-0.9090, -1.5558],
        [-0.9939, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015008090063929558
Epoch 0, Step 80: train/loss = 0.5985331535339355, train/raw-loss = 0.5970821380615234, train/logprobs = tensor([[-0.7110, -1.7877],
        [-0.7326, -1.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014510509558022022
Epoch 0, Step 81: train/loss = 0.6056206226348877, train/raw-loss = 0.6041814684867859, train/logprobs = tensor([[-0.6868, -1.7133],
        [-0.7488, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014391731470823288
Epoch 0, Step 82: train/loss = 0.5094479322433472, train/raw-loss = 0.5080893039703369, train/logprobs = tensor([[-0.9322, -2.4124],
        [-1.0561, -1.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013586342334747314
Epoch 0, Step 83: train/loss = 0.5830502510070801, train/raw-loss = 0.5817143321037292, train/logprobs = tensor([[-0.8362, -1.8716],
        [-0.9913, -1.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01335858553647995
Epoch 0, Step 84: train/loss = 0.550506591796875, train/raw-loss = 0.5494287610054016, train/logprobs = tensor([[-0.9280, -2.0340],
        [-1.0945, -1.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010778660885989666
Epoch 0, Step 85: train/loss = 0.5576978921890259, train/raw-loss = 0.5567426085472107, train/logprobs = tensor([[-0.6557, -1.9017],
        [-0.7249, -1.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009552296251058578
Epoch 0, Step 86: train/loss = 0.6400575637817383, train/raw-loss = 0.6383887529373169, train/logprobs = tensor([[-0.8589, -1.4908],
        [-0.9215, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016687985509634018
Epoch 0, Step 87: train/loss = 0.592312753200531, train/raw-loss = 0.5906730890274048, train/logprobs = tensor([[-0.9325, -1.6215],
        [-1.0918, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016397157683968544
Epoch 0, Step 88: train/loss = 0.4780001640319824, train/raw-loss = 0.47672295570373535, train/logprobs = tensor([[-0.7944, -3.0281],
        [-0.9134, -1.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01277226209640503
Epoch 0, Step 89: train/loss = 0.5928469300270081, train/raw-loss = 0.5919758081436157, train/logprobs = tensor([[-0.6240, -1.4762],
        [-0.6881, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008710931986570358
Epoch 0, Step 90: train/loss = 0.5843464136123657, train/raw-loss = 0.5832333564758301, train/logprobs = tensor([[-0.9621, -1.4038],
        [-1.1175, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0111312847584486
Epoch 0, Step 91: train/loss = 0.5127710103988647, train/raw-loss = 0.5118700861930847, train/logprobs = tensor([[-0.9795, -2.6509],
        [-1.2655, -2.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009008543565869331
Epoch 0, Step 92: train/loss = 0.5812169313430786, train/raw-loss = 0.579824686050415, train/logprobs = tensor([[-1.0867, -1.2981],
        [-1.2161, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013923034071922302
Epoch 0, Step 93: train/loss = 0.5480426549911499, train/raw-loss = 0.5467381477355957, train/logprobs = tensor([[-0.8160, -1.7357],
        [-0.9655, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013045113533735275
Epoch 0, Step 94: train/loss = 0.5828613638877869, train/raw-loss = 0.5814031958580017, train/logprobs = tensor([[-0.9779, -1.6722],
        [-1.0591, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01458151638507843
Epoch 0, Step 95: train/loss = 0.5766583681106567, train/raw-loss = 0.5755250453948975, train/logprobs = tensor([[-0.9024, -1.3762],
        [-1.0467, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011333320289850235
Epoch 0, Step 96: train/loss = 0.5065187215805054, train/raw-loss = 0.502595067024231, train/logprobs = tensor([[-0.8662, -2.0576],
        [-0.9535, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03923706337809563
Epoch 0, Step 97: train/loss = 0.5758345127105713, train/raw-loss = 0.5703028440475464, train/logprobs = tensor([[-1.0231, -1.3567],
        [-1.1903, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0553169846534729
Epoch 0, Step 98: train/loss = 0.552830696105957, train/raw-loss = 0.5485430955886841, train/logprobs = tensor([[-0.7678, -1.8875],
        [-0.7852, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042875736951828
Epoch 0, Step 99: train/loss = 0.5685576796531677, train/raw-loss = 0.5632303953170776, train/logprobs = tensor([[-0.8413, -1.8753],
        [-0.9545, -1.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05327235162258148
Epoch 0, Step 100: train/loss = 0.48540198802948, train/raw-loss = 0.4803340435028076, train/logprobs = tensor([[-1.0378, -2.0172],
        [-1.1019, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05068002641201019
Epoch 0, Step 101: train/loss = 0.5163652896881104, train/raw-loss = 0.5119312405586243, train/logprobs = tensor([[-0.9622, -2.0514],
        [-1.1109, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04434067755937576
Epoch 0, Step 102: train/loss = 0.6317853927612305, train/raw-loss = 0.6256735324859619, train/logprobs = tensor([[-0.9781, -1.7205],
        [-1.0382, -1.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06111842021346092
Epoch 0, Step 103: train/loss = 0.41097044944763184, train/raw-loss = 0.4057680368423462, train/logprobs = tensor([[-0.9761, -3.2467],
        [-1.1130, -1.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05202392488718033
Epoch 0, Step 104: train/loss = 0.5438270568847656, train/raw-loss = 0.5388838052749634, train/logprobs = tensor([[-1.1126, -1.4825],
        [-1.1972, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049432896077632904
Epoch 0, Step 105: train/loss = 0.5741419792175293, train/raw-loss = 0.5698606371879578, train/logprobs = tensor([[-0.7826, -2.3357],
        [-0.7241, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042813513427972794
Epoch 0, Step 106: train/loss = 0.544963538646698, train/raw-loss = 0.5387383699417114, train/logprobs = tensor([[-1.0506, -2.0322],
        [-1.1799, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06225176155567169
Epoch 0, Step 107: train/loss = 0.4690868556499481, train/raw-loss = 0.4632769823074341, train/logprobs = tensor([[-0.8908, -2.7570],
        [-1.0340, -1.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058098871260881424
Epoch 0, Step 108: train/loss = 0.5057109594345093, train/raw-loss = 0.5002504587173462, train/logprobs = tensor([[-0.9180, -2.8136],
        [-1.0409, -1.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054604969918727875
Epoch 0, Step 109: train/loss = 0.49773359298706055, train/raw-loss = 0.49201491475105286, train/logprobs = tensor([[-0.9113, -2.7957],
        [-0.9212, -1.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057186879217624664
Epoch 0, Step 110: train/loss = 0.5594214200973511, train/raw-loss = 0.5556515455245972, train/logprobs = tensor([[-0.4653, -2.1009],
        [-0.4725, -1.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037698570638895035
Epoch 0, Step 111: train/loss = 0.548172652721405, train/raw-loss = 0.5438008308410645, train/logprobs = tensor([[-0.8277, -1.8590],
        [-0.8653, -1.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043718282133340836
Epoch 0, Step 112: train/loss = 0.5544350147247314, train/raw-loss = 0.5479627251625061, train/logprobs = tensor([[-1.1574, -1.9790],
        [-1.2615, -1.3811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06472322344779968
Epoch 0, Step 113: train/loss = 0.5690721273422241, train/raw-loss = 0.5642643570899963, train/logprobs = tensor([[-0.7778, -2.1475],
        [-0.8292, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048077747225761414
Epoch 0, Step 114: train/loss = 0.5836392045021057, train/raw-loss = 0.5791763067245483, train/logprobs = tensor([[-0.7751, -1.4515],
        [-0.7709, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044629234820604324
Epoch 0, Step 115: train/loss = 0.5732306838035583, train/raw-loss = 0.5668503642082214, train/logprobs = tensor([[-0.8648, -1.8544],
        [-1.0197, -1.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06380276381969452
Epoch 0, Step 116: train/loss = 0.48748788237571716, train/raw-loss = 0.4826032519340515, train/logprobs = tensor([[-0.8331, -3.4263],
        [-1.0315, -2.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048846229910850525
Epoch 0, Step 117: train/loss = 0.5553033947944641, train/raw-loss = 0.5485526323318481, train/logprobs = tensor([[-1.0367, -2.2876],
        [-1.0966, -1.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750833988189697
Epoch 0, Step 118: train/loss = 0.4784311056137085, train/raw-loss = 0.47424429655075073, train/logprobs = tensor([[-0.9045, -2.8062],
        [-1.0335, -1.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041868213564157486
Epoch 0, Step 119: train/loss = 0.535815954208374, train/raw-loss = 0.5314791202545166, train/logprobs = tensor([[-0.8771, -1.6841],
        [-1.0143, -1.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04336807131767273
Epoch 0, Step 120: train/loss = 0.5700504779815674, train/raw-loss = 0.5650931000709534, train/logprobs = tensor([[-1.0796, -1.9670],
        [-0.9904, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04957321658730507
Epoch 0, Step 121: train/loss = 0.5036942958831787, train/raw-loss = 0.49979013204574585, train/logprobs = tensor([[-0.7522, -1.8867],
        [-0.7843, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03904164582490921
Epoch 0, Step 122: train/loss = 0.4458116888999939, train/raw-loss = 0.4412730038166046, train/logprobs = tensor([[-0.7317, -3.3139],
        [-0.7635, -1.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0453866571187973
Epoch 0, Step 123: train/loss = 0.448438435792923, train/raw-loss = 0.444259911775589, train/logprobs = tensor([[-1.0376, -2.6566],
        [-1.1731, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041785381734371185
Epoch 0, Step 124: train/loss = 0.5879923105239868, train/raw-loss = 0.583137035369873, train/logprobs = tensor([[-0.7725, -1.9374],
        [-0.7744, -1.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855304956436157
Epoch 0, Step 125: train/loss = 0.41032370924949646, train/raw-loss = 0.4054655432701111, train/logprobs = tensor([[-1.0606, -3.4076],
        [-1.2198, -1.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0485810860991478
Epoch 0, Step 126: train/loss = 0.5785161256790161, train/raw-loss = 0.5724053978919983, train/logprobs = tensor([[-0.8004, -2.5363],
        [-0.8323, -2.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061107244342565536
Epoch 0, Step 127: train/loss = 0.5237069129943848, train/raw-loss = 0.5180689096450806, train/logprobs = tensor([[-1.0538, -1.8622],
        [-1.1642, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05637994408607483
Epoch 0, Step 128: train/loss = 0.45723214745521545, train/raw-loss = 0.44337621331214905, train/logprobs = tensor([[-1.0004, -2.8843],
        [-1.1963, -1.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13855965435504913
Epoch 0, Step 129: train/loss = 0.5463213920593262, train/raw-loss = 0.5335796475410461, train/logprobs = tensor([[-0.8017, -2.4157],
        [-0.8600, -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12741771340370178
Epoch 0, Step 130: train/loss = 0.5249610543251038, train/raw-loss = 0.5119598507881165, train/logprobs = tensor([[-0.7908, -2.5403],
        [-0.9005, -1.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300116926431656
Epoch 0, Step 131: train/loss = 0.489664226770401, train/raw-loss = 0.47707605361938477, train/logprobs = tensor([[-1.2598, -2.4690],
        [-1.3570, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12588179111480713
Epoch 0, Step 132: train/loss = 0.6324049234390259, train/raw-loss = 0.6204840540885925, train/logprobs = tensor([[-0.5928, -2.8923],
        [-0.6041, -2.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920831352472305
Epoch 0, Step 133: train/loss = 0.5212341547012329, train/raw-loss = 0.5064550042152405, train/logprobs = tensor([[-0.9471, -2.4474],
        [-1.0658, -1.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14779147505760193
Epoch 0, Step 134: train/loss = 0.5096551775932312, train/raw-loss = 0.4967785179615021, train/logprobs = tensor([[-0.9177, -2.5903],
        [-1.0082, -1.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12876643240451813
Epoch 0, Step 135: train/loss = 0.43708786368370056, train/raw-loss = 0.4223523736000061, train/logprobs = tensor([[-0.9790, -3.2078],
        [-1.1626, -1.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14735504984855652
Epoch 0, Step 136: train/loss = 0.5562071204185486, train/raw-loss = 0.5420939922332764, train/logprobs = tensor([[-0.8495, -2.5019],
        [-1.0574, -1.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14113114774227142
Epoch 0, Step 137: train/loss = 0.5375690460205078, train/raw-loss = 0.5240005254745483, train/logprobs = tensor([[-0.9160, -2.1974],
        [-1.0156, -1.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13568486273288727
Epoch 0, Step 138: train/loss = 0.5676627159118652, train/raw-loss = 0.5531680583953857, train/logprobs = tensor([[-0.7556, -2.4201],
        [-0.6999, -1.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494755864143372
Epoch 0, Step 139: train/loss = 0.41197651624679565, train/raw-loss = 0.4000387489795685, train/logprobs = tensor([[-1.0433, -3.9915],
        [-1.2218, -2.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11937786638736725
Epoch 0, Step 140: train/loss = 0.5574306845664978, train/raw-loss = 0.5403711199760437, train/logprobs = tensor([[-0.9833, -2.3889],
        [-1.2047, -1.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1705954372882843
Epoch 0, Step 141: train/loss = 0.5443496704101562, train/raw-loss = 0.5281867980957031, train/logprobs = tensor([[-1.0473, -4.0286],
        [-1.0851, -3.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16162902116775513
Epoch 0, Step 142: train/loss = 0.5498058199882507, train/raw-loss = 0.5349790453910828, train/logprobs = tensor([[-0.8990, -2.4255],
        [-0.8482, -1.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14826759696006775
Epoch 0, Step 143: train/loss = 0.5035860538482666, train/raw-loss = 0.4889222979545593, train/logprobs = tensor([[-0.8549, -2.4256],
        [-0.9909, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14663773775100708
Epoch 0, Step 144: train/loss = 0.4578283429145813, train/raw-loss = 0.4424424171447754, train/logprobs = tensor([[-1.0816, -3.5671],
        [-1.2230, -1.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15385912358760834
Epoch 0, Step 145: train/loss = 0.4132136404514313, train/raw-loss = 0.4010441303253174, train/logprobs = tensor([[-1.0524, -4.1897],
        [-1.1297, -2.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12169544398784637
Epoch 0, Step 146: train/loss = 0.5271487236022949, train/raw-loss = 0.5162248611450195, train/logprobs = tensor([[-0.7742, -2.8175],
        [-0.8432, -1.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10923869907855988
Epoch 0, Step 147: train/loss = 0.482496440410614, train/raw-loss = 0.471487432718277, train/logprobs = tensor([[-0.8791, -3.8706],
        [-0.9470, -2.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11009004712104797
Epoch 0, Step 148: train/loss = 0.48372089862823486, train/raw-loss = 0.4675304591655731, train/logprobs = tensor([[-1.0622, -2.6523],
        [-1.2861, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1619042009115219
Epoch 0, Step 149: train/loss = 0.5364590883255005, train/raw-loss = 0.5220669507980347, train/logprobs = tensor([[-1.0528, -2.2230],
        [-1.2891, -1.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1439208835363388
Epoch 0, Step 150: train/loss = 0.533810555934906, train/raw-loss = 0.5194668769836426, train/logprobs = tensor([[-1.0675, -2.1959],
        [-1.2126, -1.5020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14343656599521637
Epoch 0, Step 151: train/loss = 0.5248429179191589, train/raw-loss = 0.5090054273605347, train/logprobs = tensor([[-0.9931, -1.9144],
        [-1.1857, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583746373653412
Epoch 0, Step 152: train/loss = 0.5078812837600708, train/raw-loss = 0.4923829734325409, train/logprobs = tensor([[-0.9514, -2.5834],
        [-1.1039, -1.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15498310327529907
Epoch 0, Step 153: train/loss = 0.4924924671649933, train/raw-loss = 0.48107004165649414, train/logprobs = tensor([[-0.8752, -2.4342],
        [-1.0014, -1.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11422407627105713
Epoch 0, Step 154: train/loss = 0.6095156073570251, train/raw-loss = 0.5951825976371765, train/logprobs = tensor([[-0.7130, -2.1730],
        [-0.6942, -1.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14332997798919678
Epoch 0, Step 155: train/loss = 0.4598347246646881, train/raw-loss = 0.44865545630455017, train/logprobs = tensor([[-0.8198, -2.7538],
        [-0.9019, -1.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.111793152987957
Epoch 0, Step 156: train/loss = 0.4850543141365051, train/raw-loss = 0.4743172526359558, train/logprobs = tensor([[-0.8188, -2.5731],
        [-0.9050, -1.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10737036168575287
Epoch 0, Step 157: train/loss = 0.45337018370628357, train/raw-loss = 0.437899112701416, train/logprobs = tensor([[-1.0136, -3.0840],
        [-1.1943, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15471035242080688
Epoch 0, Step 158: train/loss = 0.4615773558616638, train/raw-loss = 0.44746071100234985, train/logprobs = tensor([[-0.9060, -3.2899],
        [-0.9924, -1.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14116618037223816
Epoch 0, Step 159: train/loss = 0.38673990964889526, train/raw-loss = 0.3723561465740204, train/logprobs = tensor([[-1.2072, -3.7997],
        [-1.3918, -1.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14383767545223236
Epoch 0, Step 160: train/loss = 0.3664776384830475, train/raw-loss = 0.35325413942337036, train/logprobs = tensor([[-0.8044, -3.8345],
        [-0.9503, -1.2874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13223537802696228
Epoch 0, Step 161: train/loss = 0.4504506587982178, train/raw-loss = 0.43567439913749695, train/logprobs = tensor([[-0.9187, -2.3105],
        [-1.1839, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14776252210140228
Epoch 0, Step 162: train/loss = 0.33193743228912354, train/raw-loss = 0.31802552938461304, train/logprobs = tensor([[-0.9491, -4.0515],
        [-1.2400, -1.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13911917805671692
Epoch 0, Step 163: train/loss = 0.5722851753234863, train/raw-loss = 0.559332013130188, train/logprobs = tensor([[-0.5942, -2.5577],
        [-0.6152, -1.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12953180074691772
Epoch 0, Step 164: train/loss = 0.4877125918865204, train/raw-loss = 0.4748799502849579, train/logprobs = tensor([[-0.8910, -2.2917],
        [-1.0835, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12832650542259216
Epoch 0, Step 165: train/loss = 0.5058794021606445, train/raw-loss = 0.4890660345554352, train/logprobs = tensor([[-1.0025, -1.8763],
        [-1.2385, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16813397407531738
Epoch 0, Step 166: train/loss = 0.5347282886505127, train/raw-loss = 0.5178776979446411, train/logprobs = tensor([[-0.8234, -2.7551],
        [-0.8447, -1.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16850616037845612
Epoch 0, Step 167: train/loss = 0.53287672996521, train/raw-loss = 0.5183396339416504, train/logprobs = tensor([[-0.7294, -2.7289],
        [-0.7643, -1.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14537087082862854
Epoch 0, Step 168: train/loss = 0.335094690322876, train/raw-loss = 0.317708820104599, train/logprobs = tensor([[-1.2691, -3.0873],
        [-1.7809, -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17385859787464142
Epoch 0, Step 169: train/loss = 0.47712841629981995, train/raw-loss = 0.46068018674850464, train/logprobs = tensor([[-0.9178, -2.3153],
        [-1.0728, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644822061061859
Epoch 0, Step 170: train/loss = 0.5829551219940186, train/raw-loss = 0.565654993057251, train/logprobs = tensor([[-0.8262, -2.3781],
        [-0.9164, -1.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17300181090831757
Epoch 0, Step 171: train/loss = 0.4593829810619354, train/raw-loss = 0.4440208077430725, train/logprobs = tensor([[-1.0143, -3.0305],
        [-1.3512, -2.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15362140536308289
Epoch 0, Step 172: train/loss = 0.40109366178512573, train/raw-loss = 0.3821478486061096, train/logprobs = tensor([[-1.0140, -3.2324],
        [-1.3554, -1.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18945840001106262
Epoch 0, Step 173: train/loss = 0.32990896701812744, train/raw-loss = 0.3148573637008667, train/logprobs = tensor([[-0.9979, -4.8443],
        [-1.3498, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1505158245563507
Epoch 0, Step 174: train/loss = 0.4931555986404419, train/raw-loss = 0.48084163665771484, train/logprobs = tensor([[-0.7854, -2.0822],
        [-0.9418, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12314001470804214
Epoch 0, Step 175: train/loss = 0.42626243829727173, train/raw-loss = 0.4110744893550873, train/logprobs = tensor([[-0.8453, -3.5291],
        [-1.0352, -2.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15187934041023254
Epoch 0, Step 176: train/loss = 0.429056853055954, train/raw-loss = 0.4143790006637573, train/logprobs = tensor([[-1.0295, -3.4912],
        [-1.3011, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14677876234054565
Epoch 0, Step 177: train/loss = 0.41024982929229736, train/raw-loss = 0.3931204080581665, train/logprobs = tensor([[-1.0008, -2.6085],
        [-1.2898, -1.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129433155059814
Epoch 0, Step 178: train/loss = 0.3857201039791107, train/raw-loss = 0.36938169598579407, train/logprobs = tensor([[-0.9399, -3.8086],
        [-1.3435, -2.2065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16338428854942322
Epoch 0, Step 179: train/loss = 0.4350614845752716, train/raw-loss = 0.42090970277786255, train/logprobs = tensor([[-1.1026, -6.2453],
        [-1.1237, -3.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14151769876480103
Epoch 0, Step 180: train/loss = 0.510460376739502, train/raw-loss = 0.49724245071411133, train/logprobs = tensor([[-0.7858, -2.3965],
        [-0.9062, -1.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13217972218990326
Epoch 0, Step 181: train/loss = 0.34508204460144043, train/raw-loss = 0.32958537340164185, train/logprobs = tensor([[-0.9844, -3.5865],
        [-1.2858, -1.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549667865037918
Epoch 0, Step 182: train/loss = 0.39346224069595337, train/raw-loss = 0.3785649240016937, train/logprobs = tensor([[-0.8304, -3.7497],
        [-0.9916, -1.6294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1489732563495636
Epoch 0, Step 183: train/loss = 0.3964252471923828, train/raw-loss = 0.37989842891693115, train/logprobs = tensor([[-1.1551, -3.8115],
        [-1.5382, -2.3132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1652684211730957
Epoch 0, Step 184: train/loss = 0.3333190083503723, train/raw-loss = 0.32126787304878235, train/logprobs = tensor([[-0.9751, -4.6745],
        [-1.1493, -1.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12051090598106384
Epoch 0, Step 185: train/loss = 0.3584747612476349, train/raw-loss = 0.3441140651702881, train/logprobs = tensor([[-1.1068, -4.6837],
        [-1.3066, -2.1937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1436069905757904
Epoch 0, Step 186: train/loss = 0.5127489566802979, train/raw-loss = 0.4967360496520996, train/logprobs = tensor([[-0.9060, -2.2503],
        [-0.9895, -1.3589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16012893617153168
Epoch 0, Step 187: train/loss = 0.4399457275867462, train/raw-loss = 0.42354679107666016, train/logprobs = tensor([[-0.9290, -3.3426],
        [-1.1063, -1.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1639896184206009
Epoch 0, Step 188: train/loss = 0.5341652631759644, train/raw-loss = 0.5158308148384094, train/logprobs = tensor([[-0.9307, -2.3433],
        [-0.9588, -1.5090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18334434926509857
Epoch 0, Step 189: train/loss = 0.47150152921676636, train/raw-loss = 0.458639532327652, train/logprobs = tensor([[-0.7047, -3.1682],
        [-0.7368, -1.3341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12861987948417664
Epoch 0, Step 190: train/loss = 0.40564143657684326, train/raw-loss = 0.39381512999534607, train/logprobs = tensor([[-0.8155, -3.7692],
        [-0.8463, -1.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182626485824585
Epoch 0, Step 191: train/loss = 0.46989110112190247, train/raw-loss = 0.4521923363208771, train/logprobs = tensor([[-0.9993, -2.8159],
        [-1.2869, -1.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17698776721954346
Epoch 0, Step 192: train/loss = 0.3736410439014435, train/raw-loss = 0.3553980588912964, train/logprobs = tensor([[-0.9132, -3.5968],
        [-1.0602, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824302226305008
Epoch 0, Step 193: train/loss = 0.31355994939804077, train/raw-loss = 0.29153966903686523, train/logprobs = tensor([[-0.9887, -3.5193],
        [-1.6917, -1.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22020301222801208
Epoch 0, Step 194: train/loss = 0.33193862438201904, train/raw-loss = 0.3127644658088684, train/logprobs = tensor([[-0.7300, -5.8601],
        [-0.8396, -1.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19174139201641083
Epoch 0, Step 195: train/loss = 0.2634071111679077, train/raw-loss = 0.24456170201301575, train/logprobs = tensor([[-0.8154, -6.0968],
        [-1.1970, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18845400214195251
Epoch 0, Step 196: train/loss = 0.34557855129241943, train/raw-loss = 0.32689663767814636, train/logprobs = tensor([[-0.8519, -3.2755],
        [-1.0295, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18681928515434265
Epoch 0, Step 197: train/loss = 0.383363276720047, train/raw-loss = 0.3638595938682556, train/logprobs = tensor([[-0.7532, -3.2483],
        [-1.0432, -1.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950368583202362
Epoch 0, Step 198: train/loss = 0.25030237436294556, train/raw-loss = 0.2294667810201645, train/logprobs = tensor([[-1.0425, -5.0524],
        [-1.5557, -1.3729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20835605263710022
Epoch 0, Step 199: train/loss = 0.32073554396629333, train/raw-loss = 0.29656869173049927, train/logprobs = tensor([[-0.8353, -3.5569],
        [-1.2460, -1.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24166837334632874
Epoch 0, Step 200: train/loss = 0.31005844473838806, train/raw-loss = 0.28513646125793457, train/logprobs = tensor([[-0.9348, -4.6773],
        [-1.4535, -2.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492198348045349
Epoch 0, Step 201: train/loss = 0.3466528058052063, train/raw-loss = 0.32645753026008606, train/logprobs = tensor([[-0.7132, -3.1899],
        [-1.0226, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20195253193378448
Epoch 0, Step 202: train/loss = 0.37105637788772583, train/raw-loss = 0.3472389578819275, train/logprobs = tensor([[-0.8382, -3.9795],
        [-1.0300, -1.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23817411065101624
Epoch 0, Step 203: train/loss = 0.3521224856376648, train/raw-loss = 0.3300401568412781, train/logprobs = tensor([[-0.8960, -3.5838],
        [-1.1238, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2208234965801239
Epoch 0, Step 204: train/loss = 0.6763954162597656, train/raw-loss = 0.654312252998352, train/logprobs = tensor([[-2.1077, -4.5501],
        [-1.1353, -1.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2208319902420044
Epoch 0, Step 205: train/loss = 0.25915005803108215, train/raw-loss = 0.23888647556304932, train/logprobs = tensor([[-0.9546, -4.7598],
        [-1.4741, -1.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263580977916718
Epoch 0, Step 206: train/loss = 0.3289787173271179, train/raw-loss = 0.30515187978744507, train/logprobs = tensor([[-1.0029, -3.1090],
        [-1.3595, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23826876282691956
Epoch 0, Step 207: train/loss = 0.35965272784233093, train/raw-loss = 0.33985888957977295, train/logprobs = tensor([[-0.6798, -3.4634],
        [-0.9154, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1979387104511261
Epoch 0, Step 208: train/loss = 0.36680394411087036, train/raw-loss = 0.3511047959327698, train/logprobs = tensor([[-0.5261, -3.5773],
        [-0.6896, -1.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569911539554596
Epoch 0, Step 209: train/loss = 0.3265221118927002, train/raw-loss = 0.3045024573802948, train/logprobs = tensor([[-0.9566, -4.0086],
        [-1.2796, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2201964557170868
Epoch 0, Step 210: train/loss = 0.38813966512680054, train/raw-loss = 0.3677576780319214, train/logprobs = tensor([[-0.9079, -2.3972],
        [-1.3798, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20381972193717957
Epoch 0, Step 211: train/loss = 0.3680565059185028, train/raw-loss = 0.3505275249481201, train/logprobs = tensor([[-0.7823, -3.1566],
        [-0.9575, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752898097038269
Epoch 0, Step 212: train/loss = 0.39783722162246704, train/raw-loss = 0.375167578458786, train/logprobs = tensor([[-0.8736, -3.7523],
        [-1.0606, -1.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22669589519500732
Epoch 0, Step 213: train/loss = 0.27827998995780945, train/raw-loss = 0.2538169324398041, train/logprobs = tensor([[-1.3736, -4.1778],
        [-1.8616, -1.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24463097751140594
Epoch 0, Step 214: train/loss = 0.30331629514694214, train/raw-loss = 0.2853826880455017, train/logprobs = tensor([[-0.7885, -4.2954],
        [-1.0805, -1.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17933641374111176
Epoch 0, Step 215: train/loss = 0.31422993540763855, train/raw-loss = 0.29092323780059814, train/logprobs = tensor([[-0.8557, -4.4546],
        [-1.1257, -1.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23306672275066376
Epoch 0, Step 216: train/loss = 0.3417436480522156, train/raw-loss = 0.32336530089378357, train/logprobs = tensor([[-0.8563, -2.6155],
        [-1.4263, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18378354609012604
Epoch 0, Step 217: train/loss = 0.47047895193099976, train/raw-loss = 0.4520590603351593, train/logprobs = tensor([[-0.6270, -2.3807],
        [-0.7190, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18419915437698364
Epoch 0, Step 218: train/loss = 0.3776019215583801, train/raw-loss = 0.35271787643432617, train/logprobs = tensor([[-0.9538, -5.0644],
        [-1.3700, -1.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24884067475795746
Epoch 0, Step 219: train/loss = 0.33995866775512695, train/raw-loss = 0.31515949964523315, train/logprobs = tensor([[-1.0912, -3.3725],
        [-1.6048, -1.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2479914426803589
Epoch 0, Step 220: train/loss = 0.28396371006965637, train/raw-loss = 0.265354186296463, train/logprobs = tensor([[-0.8792, -5.5118],
        [-1.1428, -1.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1860952377319336
Epoch 0, Step 221: train/loss = 0.34563201665878296, train/raw-loss = 0.3268462121486664, train/logprobs = tensor([[-0.7927, -3.7528],
        [-0.9710, -1.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18785831332206726
Epoch 0, Step 222: train/loss = 0.33101749420166016, train/raw-loss = 0.31254565715789795, train/logprobs = tensor([[-0.7660, -4.4017],
        [-0.9368, -1.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18471814692020416
Epoch 0, Step 223: train/loss = 0.31296056509017944, train/raw-loss = 0.2957492768764496, train/logprobs = tensor([[-0.8754, -3.5913],
        [-1.2284, -0.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17211294174194336
Epoch 0, Step 224: train/loss = 0.2539902329444885, train/raw-loss = 0.22555792331695557, train/logprobs = tensor([[-1.1397, -4.3324],
        [-2.1146, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2843233346939087
Epoch 0, Step 225: train/loss = 0.3510412275791168, train/raw-loss = 0.32708555459976196, train/logprobs = tensor([[-0.8995, -3.3496],
        [-1.3835, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23955699801445007
Epoch 0, Step 226: train/loss = 0.31669968366622925, train/raw-loss = 0.29179471731185913, train/logprobs = tensor([[-0.8749, -4.6076],
        [-1.0374, -1.3419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.249049574136734
Epoch 0, Step 227: train/loss = 0.26335272192955017, train/raw-loss = 0.23942236602306366, train/logprobs = tensor([[-0.7356, -5.4993],
        [-1.2091, -1.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2393036037683487
Epoch 0, Step 228: train/loss = 0.2885591983795166, train/raw-loss = 0.2658851742744446, train/logprobs = tensor([[-0.6797, -3.1634],
        [-1.3158, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22673992812633514
Epoch 0, Step 229: train/loss = 0.22207912802696228, train/raw-loss = 0.19525526463985443, train/logprobs = tensor([[-1.1191, -5.3993],
        [-1.9091, -1.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26823854446411133
Epoch 0, Step 230: train/loss = 0.28502851724624634, train/raw-loss = 0.25806501507759094, train/logprobs = tensor([[-0.7356, -3.5968],
        [-1.5040, -1.5053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696351408958435
Epoch 0, Step 231: train/loss = 0.2634205222129822, train/raw-loss = 0.23805242776870728, train/logprobs = tensor([[-0.9888, -4.6565],
        [-1.4944, -1.0247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536807954311371
Epoch 0, Step 232: train/loss = 0.3587791621685028, train/raw-loss = 0.33356595039367676, train/logprobs = tensor([[-0.8793, -3.7430],
        [-1.2021, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2521321773529053
Epoch 0, Step 233: train/loss = 0.363166868686676, train/raw-loss = 0.33972615003585815, train/logprobs = tensor([[-0.8453, -3.5481],
        [-1.2331, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23440733551979065
Epoch 0, Step 234: train/loss = 0.3312515914440155, train/raw-loss = 0.31295597553253174, train/logprobs = tensor([[-0.6178, -4.7733],
        [-0.6978, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829560250043869
Epoch 0, Step 235: train/loss = 0.23774492740631104, train/raw-loss = 0.2133113443851471, train/logprobs = tensor([[-1.0977, -5.3727],
        [-1.6898, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24433577060699463
Epoch 0, Step 236: train/loss = 0.2472033053636551, train/raw-loss = 0.22200369834899902, train/logprobs = tensor([[-0.7599, -4.9403],
        [-1.2551, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519960403442383
Epoch 0, Step 237: train/loss = 0.35708633065223694, train/raw-loss = 0.33172792196273804, train/logprobs = tensor([[-0.8701, -2.2666],
        [-1.5236, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25358402729034424
Epoch 0, Step 238: train/loss = 0.2768430709838867, train/raw-loss = 0.2544184923171997, train/logprobs = tensor([[-0.8004, -5.9538],
        [-1.0625, -1.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2242456078529358
Epoch 0, Step 239: train/loss = 0.2443545013666153, train/raw-loss = 0.21443869173526764, train/logprobs = tensor([[-0.9485, -5.7296],
        [-1.6654, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991582453250885
Epoch 0, Step 240: train/loss = 0.24057257175445557, train/raw-loss = 0.21126270294189453, train/logprobs = tensor([[-0.9141, -3.2090],
        [-1.9044, -0.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2930985391139984
Epoch 0, Step 241: train/loss = 0.24824471771717072, train/raw-loss = 0.22029796242713928, train/logprobs = tensor([[-1.1545, -3.3186],
        [-2.2550, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27946770191192627
Epoch 0, Step 242: train/loss = 0.2669947147369385, train/raw-loss = 0.24513521790504456, train/logprobs = tensor([[-0.6962, -4.2417],
        [-1.1961, -0.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21859480440616608
Epoch 0, Step 243: train/loss = 0.31308698654174805, train/raw-loss = 0.287203311920166, train/logprobs = tensor([[-1.0699, -4.0499],
        [-1.4551, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25883662700653076
Epoch 0, Step 244: train/loss = 0.28503796458244324, train/raw-loss = 0.25692927837371826, train/logprobs = tensor([[-1.0579, -3.0616],
        [-1.9173, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28108692169189453
Epoch 0, Step 245: train/loss = 0.2530304491519928, train/raw-loss = 0.22965949773788452, train/logprobs = tensor([[-0.7600, -5.9950],
        [-1.1174, -1.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233709454536438
Epoch 0, Step 246: train/loss = 0.2875918745994568, train/raw-loss = 0.26358574628829956, train/logprobs = tensor([[-0.9249, -4.8571],
        [-1.1810, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24006140232086182
Epoch 0, Step 247: train/loss = 0.3567783534526825, train/raw-loss = 0.3349621295928955, train/logprobs = tensor([[-0.6790, -3.3266],
        [-0.9119, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21816252171993256
Epoch 0, Step 248: train/loss = 0.3874167799949646, train/raw-loss = 0.36390435695648193, train/logprobs = tensor([[-0.7537, -3.9160],
        [-0.8928, -1.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23512421548366547
Epoch 0, Step 249: train/loss = 0.23577430844306946, train/raw-loss = 0.20470081269741058, train/logprobs = tensor([[-0.9806, -3.8676],
        [-2.0824, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107348680496216
Epoch 0, Step 250: train/loss = 0.2901693880558014, train/raw-loss = 0.26680833101272583, train/logprobs = tensor([[-0.8060, -3.4646],
        [-1.3777, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23361051082611084
Epoch 0, Step 251: train/loss = 0.3058825135231018, train/raw-loss = 0.2848443388938904, train/logprobs = tensor([[-0.7995, -3.6571],
        [-1.4051, -1.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210381880402565
Epoch 0, Step 252: train/loss = 0.21514655649662018, train/raw-loss = 0.18939992785453796, train/logprobs = tensor([[-0.9909, -5.7587],
        [-1.7140, -1.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25746628642082214
Epoch 0, Step 253: train/loss = 0.22507548332214355, train/raw-loss = 0.1996358186006546, train/logprobs = tensor([[-0.9261, -5.5451],
        [-1.5585, -1.1591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543966472148895
Epoch 0, Step 254: train/loss = 0.297410249710083, train/raw-loss = 0.27405470609664917, train/logprobs = tensor([[-0.7592, -6.8513],
        [-0.9270, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23355579376220703
Epoch 0, Step 255: train/loss = 0.29177722334861755, train/raw-loss = 0.2626863121986389, train/logprobs = tensor([[-1.0640, -3.5788],
        [-1.7153, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.290909081697464
Epoch 0, Step 256: train/loss = 0.2245243638753891, train/raw-loss = 0.1991991251707077, train/logprobs = tensor([[-0.8668, -5.1754],
        [-1.6784, -0.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532525658607483
Epoch 0, Step 257: train/loss = 0.33259913325309753, train/raw-loss = 0.30567532777786255, train/logprobs = tensor([[-1.1908, -7.3830],
        [-1.2819, -1.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26923811435699463
Epoch 0, Step 258: train/loss = 0.22599054872989655, train/raw-loss = 0.2003260999917984, train/logprobs = tensor([[-0.7588, -5.3262],
        [-1.7045, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256644606590271
Epoch 0, Step 259: train/loss = 0.30095627903938293, train/raw-loss = 0.2790471911430359, train/logprobs = tensor([[-0.7851, -5.0300],
        [-1.0851, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21909067034721375
Epoch 0, Step 260: train/loss = 0.2266768366098404, train/raw-loss = 0.1997954249382019, train/logprobs = tensor([[-1.0306, -4.8599],
        [-2.0553, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26881399750709534
Epoch 0, Step 261: train/loss = 0.21117573976516724, train/raw-loss = 0.1805872917175293, train/logprobs = tensor([[-1.1727, -4.4461],
        [-2.1355, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3058844804763794
Epoch 0, Step 262: train/loss = 0.2985866665840149, train/raw-loss = 0.27076658606529236, train/logprobs = tensor([[-0.9293, -4.2216],
        [-1.1466, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27820083498954773
Epoch 0, Step 263: train/loss = 0.26141950488090515, train/raw-loss = 0.238614022731781, train/logprobs = tensor([[-0.6712, -4.7378],
        [-1.1564, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22805479168891907
Epoch 0, Step 264: train/loss = 0.28340184688568115, train/raw-loss = 0.2578822374343872, train/logprobs = tensor([[-0.8633, -3.2586],
        [-1.4896, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551959156990051
Epoch 0, Step 265: train/loss = 0.27837178111076355, train/raw-loss = 0.2513638734817505, train/logprobs = tensor([[-0.9723, -3.2011],
        [-1.8489, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27007925510406494
Epoch 0, Step 266: train/loss = 0.2784350514411926, train/raw-loss = 0.2553584575653076, train/logprobs = tensor([[-0.6903, -5.1817],
        [-0.9482, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076598346233368
Epoch 0, Step 267: train/loss = 0.2817504107952118, train/raw-loss = 0.25769147276878357, train/logprobs = tensor([[-0.9413, -6.3307],
        [-1.3491, -0.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2405894249677658
Epoch 0, Step 268: train/loss = 0.1780785471200943, train/raw-loss = 0.14424018561840057, train/logprobs = tensor([[-0.9389, -5.8498],
        [-2.2903, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33838367462158203
Epoch 0, Step 269: train/loss = 0.18731090426445007, train/raw-loss = 0.15823706984519958, train/logprobs = tensor([[-0.8776, -5.9236],
        [-2.0694, -0.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29073822498321533
Epoch 0, Step 270: train/loss = 0.2611854374408722, train/raw-loss = 0.23447521030902863, train/logprobs = tensor([[-0.9408, -3.2818],
        [-1.7909, -0.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26710236072540283
Epoch 0, Step 271: train/loss = 0.3336578607559204, train/raw-loss = 0.3117814064025879, train/logprobs = tensor([[-0.5489, -3.7905],
        [-1.0357, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21876442432403564
Epoch 0, Step 272: train/loss = 0.22837549448013306, train/raw-loss = 0.2030656784772873, train/logprobs = tensor([[-0.9328, -4.4537],
        [-2.0392, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25309789180755615
Epoch 0, Step 273: train/loss = 0.18281495571136475, train/raw-loss = 0.1540091633796692, train/logprobs = tensor([[-0.8724, -6.1596],
        [-2.1298, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288057804107666
Epoch 0, Step 274: train/loss = 0.21368592977523804, train/raw-loss = 0.18796387314796448, train/logprobs = tensor([[-0.6500, -5.0724],
        [-1.4961, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257220596075058
Epoch 0, Step 275: train/loss = 0.22943027317523956, train/raw-loss = 0.2020891159772873, train/logprobs = tensor([[-0.9675, -7.3058],
        [-1.5521, -1.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27341151237487793
Epoch 0, Step 276: train/loss = 0.24008744955062866, train/raw-loss = 0.214331716299057, train/logprobs = tensor([[-0.9892, -4.3602],
        [-1.8270, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257557213306427
Epoch 0, Step 277: train/loss = 0.27084583044052124, train/raw-loss = 0.24584241211414337, train/logprobs = tensor([[-0.7547, -4.5138],
        [-1.2132, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500341832637787
Epoch 0, Step 278: train/loss = 0.3719960153102875, train/raw-loss = 0.35027068853378296, train/logprobs = tensor([[-0.6734, -2.9915],
        [-1.2567, -0.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2172532081604004
Epoch 0, Step 279: train/loss = 0.15735261142253876, train/raw-loss = 0.12333053350448608, train/logprobs = tensor([[-1.0146, -4.0864],
        [-2.6280, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34022077918052673
Epoch 0, Step 280: train/loss = 0.26453834772109985, train/raw-loss = 0.24038517475128174, train/logprobs = tensor([[-0.7383, -3.3504],
        [-1.7277, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24153167009353638
Epoch 0, Step 281: train/loss = 0.24346183240413666, train/raw-loss = 0.2148904949426651, train/logprobs = tensor([[-0.7962, -6.2800],
        [-1.2141, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857133448123932
Epoch 0, Step 282: train/loss = 0.1972714364528656, train/raw-loss = 0.1699090152978897, train/logprobs = tensor([[-0.8056, -4.7517],
        [-1.8601, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2736243009567261
Epoch 0, Step 283: train/loss = 0.25043100118637085, train/raw-loss = 0.22355905175209045, train/logprobs = tensor([[-0.8592, -4.5675],
        [-1.4506, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26871952414512634
Epoch 0, Step 284: train/loss = 0.18521010875701904, train/raw-loss = 0.15538719296455383, train/logprobs = tensor([[-0.9376, -5.5434],
        [-2.1056, -1.2765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29822906851768494
Epoch 0, Step 285: train/loss = 0.2441321611404419, train/raw-loss = 0.21497583389282227, train/logprobs = tensor([[-0.8616, -6.5452],
        [-1.3703, -1.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2915630042552948
Epoch 0, Step 286: train/loss = 0.25064992904663086, train/raw-loss = 0.22510001063346863, train/logprobs = tensor([[-0.8270, -6.1238],
        [-1.2847, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25549885630607605
Epoch 0, Step 287: train/loss = 0.20401950180530548, train/raw-loss = 0.17247352004051208, train/logprobs = tensor([[-0.8907, -5.7614],
        [-1.8040, -1.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3154597878456116
Epoch 0, Step 288: train/loss = 0.2803577780723572, train/raw-loss = 0.25433841347694397, train/logprobs = tensor([[-1.0583, -5.7248],
        [-1.5356, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601938545703888
Epoch 0, Step 289: train/loss = 0.23442310094833374, train/raw-loss = 0.20588389039039612, train/logprobs = tensor([[-0.7958, -7.0476],
        [-1.5736, -1.2148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2853921353816986
Epoch 0, Step 290: train/loss = 0.23160254955291748, train/raw-loss = 0.2029660940170288, train/logprobs = tensor([[-0.8690, -4.7586],
        [-1.7107, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863644063472748
Epoch 0, Step 291: train/loss = 0.3098628520965576, train/raw-loss = 0.2828594446182251, train/logprobs = tensor([[-0.8041, -6.0459],
        [-1.5246, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700338065624237
Epoch 0, Step 292: train/loss = 0.22202008962631226, train/raw-loss = 0.19518588483333588, train/logprobs = tensor([[-0.9521, -5.7335],
        [-1.6825, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2683423161506653
Epoch 0, Step 293: train/loss = 0.23345892131328583, train/raw-loss = 0.19849424064159393, train/logprobs = tensor([[-1.0964, -2.5485],
        [-2.9420, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3496466875076294
Epoch 0, Step 294: train/loss = 0.27517983317375183, train/raw-loss = 0.25173404812812805, train/logprobs = tensor([[-0.7090, -6.3806],
        [-1.1788, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23445792496204376
Epoch 0, Step 295: train/loss = 0.3079870939254761, train/raw-loss = 0.28185737133026123, train/logprobs = tensor([[-0.8173, -4.7307],
        [-1.6099, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26129722595214844
Epoch 0, Step 296: train/loss = 0.3779691457748413, train/raw-loss = 0.3573494553565979, train/logprobs = tensor([[-0.7225, -2.6759],
        [-1.1557, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20619696378707886
Epoch 0, Step 297: train/loss = 0.17181184887886047, train/raw-loss = 0.14128440618515015, train/logprobs = tensor([[-0.6780, -6.6123],
        [-1.8566, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3052743971347809
Epoch 0, Step 298: train/loss = 0.20462796092033386, train/raw-loss = 0.17709693312644958, train/logprobs = tensor([[-0.8270, -6.5370],
        [-1.9044, -1.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27531009912490845
Epoch 0, Step 299: train/loss = 0.23806628584861755, train/raw-loss = 0.21057046949863434, train/logprobs = tensor([[-0.8162, -7.5729],
        [-1.9504, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27495813369750977
Epoch 0, Step 300: train/loss = 0.30338090658187866, train/raw-loss = 0.276125967502594, train/logprobs = tensor([[-1.2652, -5.8932],
        [-1.5507, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725493013858795
Epoch 0, Step 301: train/loss = 0.28140127658843994, train/raw-loss = 0.2546849846839905, train/logprobs = tensor([[-0.7205, -4.7249],
        [-1.0445, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26716306805610657
Epoch 0, Step 302: train/loss = 0.3099621832370758, train/raw-loss = 0.2805396318435669, train/logprobs = tensor([[-0.8646, -4.5296],
        [-1.3394, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29422545433044434
Epoch 0, Step 303: train/loss = 0.19235587120056152, train/raw-loss = 0.1628890186548233, train/logprobs = tensor([[-0.8195, -4.1103],
        [-2.4513, -0.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29466843605041504
Epoch 0, Step 304: train/loss = 0.24953533709049225, train/raw-loss = 0.22561123967170715, train/logprobs = tensor([[-0.7625, -5.8523],
        [-1.1932, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23924103379249573
Epoch 0, Step 305: train/loss = 0.2379886507987976, train/raw-loss = 0.21265283226966858, train/logprobs = tensor([[-0.8580, -4.7427],
        [-1.4756, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533583343029022
Epoch 0, Step 306: train/loss = 0.14817792177200317, train/raw-loss = 0.11950831860303879, train/logprobs = tensor([[-0.7824, -6.6058],
        [-2.4246, -1.2646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28669607639312744
Epoch 0, Step 307: train/loss = 0.24540051817893982, train/raw-loss = 0.216621533036232, train/logprobs = tensor([[-0.9405, -4.7429],
        [-1.4634, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877900302410126
Epoch 0, Step 308: train/loss = 0.264668345451355, train/raw-loss = 0.23498764634132385, train/logprobs = tensor([[-0.8396, -5.0421],
        [-1.8007, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968069911003113
Epoch 0, Step 309: train/loss = 0.20073038339614868, train/raw-loss = 0.17230050265789032, train/logprobs = tensor([[-0.7594, -7.8041],
        [-1.7852, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28429874777793884
Epoch 0, Step 310: train/loss = 0.21943634748458862, train/raw-loss = 0.19261446595191956, train/logprobs = tensor([[-0.7380, -5.3154],
        [-1.4835, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26821884512901306
Epoch 0, Step 311: train/loss = 0.18232659995555878, train/raw-loss = 0.1497403085231781, train/logprobs = tensor([[-0.8467, -4.6095],
        [-2.4685, -1.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258630335330963
Epoch 0, Step 312: train/loss = 0.2292969673871994, train/raw-loss = 0.2000884711742401, train/logprobs = tensor([[-1.2267, -6.1621],
        [-1.8260, -1.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29208505153656006
Epoch 0, Step 313: train/loss = 0.21131554245948792, train/raw-loss = 0.18674540519714355, train/logprobs = tensor([[-0.7417, -5.0064],
        [-1.4991, -0.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24570149183273315
Epoch 0, Step 314: train/loss = 0.25239917635917664, train/raw-loss = 0.22528839111328125, train/logprobs = tensor([[-1.0011, -6.6931],
        [-1.6923, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2711080014705658
Epoch 0, Step 315: train/loss = 0.1946716010570526, train/raw-loss = 0.16521497070789337, train/logprobs = tensor([[-0.8275, -5.4209],
        [-1.8576, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29456618428230286
Epoch 0, Step 316: train/loss = 0.204797625541687, train/raw-loss = 0.17808479070663452, train/logprobs = tensor([[-0.7359, -6.0925],
        [-1.5225, -1.3683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2671283185482025
Epoch 0, Step 317: train/loss = 0.1735098958015442, train/raw-loss = 0.1456800401210785, train/logprobs = tensor([[-0.8603, -6.5247],
        [-2.0926, -1.3176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782987058162689
Epoch 0, Step 318: train/loss = 0.15124011039733887, train/raw-loss = 0.12083335965871811, train/logprobs = tensor([[-0.8659, -6.3921],
        [-2.3572, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040676414966583
Epoch 0, Step 319: train/loss = 0.3012838363647461, train/raw-loss = 0.2745797634124756, train/logprobs = tensor([[-0.6089, -2.8343],
        [-1.7809, -0.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26704108715057373
Epoch 0, Step 320: train/loss = 0.28927144408226013, train/raw-loss = 0.26523804664611816, train/logprobs = tensor([[-0.7316, -4.4876],
        [-1.3036, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24033404886722565
Epoch 0, Step 321: train/loss = 0.1783011555671692, train/raw-loss = 0.14708957076072693, train/logprobs = tensor([[-0.7733, -6.6147],
        [-2.0604, -1.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31211602687835693
Epoch 0, Step 322: train/loss = 0.20894457399845123, train/raw-loss = 0.18194429576396942, train/logprobs = tensor([[-0.7789, -7.3942],
        [-1.7142, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27000269293785095
Epoch 0, Step 323: train/loss = 0.1853221356868744, train/raw-loss = 0.15258321166038513, train/logprobs = tensor([[-0.9810, -5.6160],
        [-2.3191, -1.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273892402648926
Epoch 0, Step 324: train/loss = 0.1173652857542038, train/raw-loss = 0.07892664521932602, train/logprobs = tensor([[-1.0571, -7.8402],
        [-3.2913, -1.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3843863606452942
Epoch 0, Step 325: train/loss = 0.15102402865886688, train/raw-loss = 0.1221754252910614, train/logprobs = tensor([[-1.0517, -8.8136],
        [-2.5434, -1.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2884860634803772
Epoch 0, Step 326: train/loss = 0.19815421104431152, train/raw-loss = 0.16734850406646729, train/logprobs = tensor([[-0.9374, -7.3839],
        [-2.1536, -0.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30805686116218567
Epoch 0, Step 327: train/loss = 0.20564252138137817, train/raw-loss = 0.17299777269363403, train/logprobs = tensor([[-0.7642, -4.1927],
        [-2.6895, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3264474868774414
Epoch 0, Step 328: train/loss = 0.20137329399585724, train/raw-loss = 0.17322640120983124, train/logprobs = tensor([[-0.8210, -6.9690],
        [-1.8306, -1.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28146883845329285
Epoch 0, Step 329: train/loss = 0.16364122927188873, train/raw-loss = 0.13020020723342896, train/logprobs = tensor([[-0.8249, -5.0897],
        [-3.2514, -1.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33441025018692017
Epoch 0, Step 330: train/loss = 0.19171427190303802, train/raw-loss = 0.16085821390151978, train/logprobs = tensor([[-0.8395, -5.3211],
        [-1.8875, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30856043100357056
Epoch 0, Step 331: train/loss = 0.19322569668293, train/raw-loss = 0.15748892724514008, train/logprobs = tensor([[-0.7421, -5.7750],
        [-2.3281, -1.4753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35736793279647827
Epoch 0, Step 332: train/loss = 0.2377638816833496, train/raw-loss = 0.20909415185451508, train/logprobs = tensor([[-0.6970, -5.9233],
        [-1.3608, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28669726848602295
Epoch 0, Step 333: train/loss = 0.12874212861061096, train/raw-loss = 0.09451773762702942, train/logprobs = tensor([[-0.9050, -6.8515],
        [-2.9777, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34224382042884827
Epoch 0, Step 334: train/loss = 0.2438182681798935, train/raw-loss = 0.20728839933872223, train/logprobs = tensor([[-1.0941, -4.7460],
        [-2.7942, -1.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36529865860939026
Epoch 0, Step 335: train/loss = 0.2305917888879776, train/raw-loss = 0.20069484412670135, train/logprobs = tensor([[-0.6156, -4.8686],
        [-2.3786, -1.5871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989693880081177
Epoch 0, Step 336: train/loss = 0.18152187764644623, train/raw-loss = 0.1504473090171814, train/logprobs = tensor([[-0.6542, -6.3714],
        [-1.8344, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107457756996155
Epoch 0, Step 337: train/loss = 0.1998756229877472, train/raw-loss = 0.16953229904174805, train/logprobs = tensor([[-0.6708, -8.4966],
        [-1.6762, -2.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303433358669281
Epoch 0, Step 338: train/loss = 0.34286752343177795, train/raw-loss = 0.31695756316185, train/logprobs = tensor([[-0.5383, -5.5076],
        [-0.8671, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590992748737335
Epoch 0, Step 339: train/loss = 0.13084924221038818, train/raw-loss = 0.09189318120479584, train/logprobs = tensor([[-0.7699, -5.2035],
        [-3.9428, -1.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38956063985824585
Epoch 0, Step 340: train/loss = 0.2413989007472992, train/raw-loss = 0.2094380259513855, train/logprobs = tensor([[-0.6828, -6.4532],
        [-1.9767, -1.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3196088671684265
Epoch 0, Step 341: train/loss = 0.19237738847732544, train/raw-loss = 0.16213887929916382, train/logprobs = tensor([[-0.8861, -4.7593],
        [-3.1049, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30238527059555054
Epoch 0, Step 342: train/loss = 0.21120581030845642, train/raw-loss = 0.17958365380764008, train/logprobs = tensor([[-0.7032, -6.8879],
        [-1.8869, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31622156500816345
Epoch 0, Step 343: train/loss = 0.21567682921886444, train/raw-loss = 0.18406260013580322, train/logprobs = tensor([[-1.2232, -7.0522],
        [-2.4727, -1.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3161422610282898
Epoch 0, Step 344: train/loss = 0.1525246948003769, train/raw-loss = 0.11936850100755692, train/logprobs = tensor([[-0.9057, -6.0377],
        [-2.3556, -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315620422363281
Epoch 0, Step 345: train/loss = 0.12044386565685272, train/raw-loss = 0.08831937611103058, train/logprobs = tensor([[-1.0496, -5.9238],
        [-2.9166, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32124486565589905
Epoch 0, Step 346: train/loss = 0.2257382571697235, train/raw-loss = 0.19631953537464142, train/logprobs = tensor([[-0.7430, -6.2266],
        [-1.3558, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2941874861717224
Epoch 0, Step 347: train/loss = 0.3257344961166382, train/raw-loss = 0.3015252649784088, train/logprobs = tensor([[-0.7002, -4.1232],
        [-1.2320, -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24209213256835938
Epoch 0, Step 348: train/loss = 0.21451914310455322, train/raw-loss = 0.1833694726228714, train/logprobs = tensor([[-0.9286, -6.7947],
        [-2.3973, -1.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3114968538284302
Epoch 0, Step 349: train/loss = 0.2577108144760132, train/raw-loss = 0.22696921229362488, train/logprobs = tensor([[-0.8356, -6.1449],
        [-1.8929, -1.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074159026145935
Epoch 0, Step 350: train/loss = 0.2468808889389038, train/raw-loss = 0.21898195147514343, train/logprobs = tensor([[-1.2747, -9.3198],
        [-1.8626, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27898937463760376
Epoch 0, Step 351: train/loss = 0.20867542922496796, train/raw-loss = 0.17783160507678986, train/logprobs = tensor([[-0.6058, -4.3317],
        [-2.1719, -1.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30843809247016907
Epoch 0, Step 352: train/loss = 0.1755800098180771, train/raw-loss = 0.13812734186649323, train/logprobs = tensor([[-0.7616, -8.9543],
        [-2.0852, -0.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3745267391204834
Epoch 0, Step 353: train/loss = 0.06917022913694382, train/raw-loss = 0.028293706476688385, train/logprobs = tensor([[-1.2156, -9.1745],
        [-4.2985, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4087652266025543
Epoch 0, Step 354: train/loss = 0.2790454924106598, train/raw-loss = 0.2508898973464966, train/logprobs = tensor([[-0.6090, -4.3101],
        [-1.9279, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28155580163002014
Epoch 0, Step 355: train/loss = 0.1660327911376953, train/raw-loss = 0.13029423356056213, train/logprobs = tensor([[-0.8942, -7.2462],
        [-2.5506, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.357385516166687
Epoch 0, Step 356: train/loss = 0.24496015906333923, train/raw-loss = 0.21017345786094666, train/logprobs = tensor([[-1.0103, -5.1246],
        [-1.7981, -1.5465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34786707162857056
Epoch 0, Step 357: train/loss = 0.14967097342014313, train/raw-loss = 0.11266233772039413, train/logprobs = tensor([[-0.9769, -8.9837],
        [-2.3459, -1.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3700864315032959
Epoch 0, Step 358: train/loss = 0.08582702279090881, train/raw-loss = 0.03894617408514023, train/logprobs = tensor([[-1.0342, -7.6080],
        [-4.4289, -1.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46880850195884705
Epoch 0, Step 359: train/loss = 0.19385923445224762, train/raw-loss = 0.16013900935649872, train/logprobs = tensor([[-1.4442, -9.6090],
        [-2.2714, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33720216155052185
Epoch 0, Step 360: train/loss = 0.15738165378570557, train/raw-loss = 0.12308622151613235, train/logprobs = tensor([[-1.0931, -8.6019],
        [-2.5115, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429543375968933
Epoch 0, Step 361: train/loss = 0.10838297754526138, train/raw-loss = 0.07169093191623688, train/logprobs = tensor([[-1.1551, -6.9378],
        [-4.3470, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3669204115867615
Epoch 0, Step 362: train/loss = 0.06461212038993835, train/raw-loss = 0.01621037907898426, train/logprobs = tensor([[-0.7937, -6.4556],
        [-5.1016, -1.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48401737213134766
Epoch 0, Step 363: train/loss = 0.17823630571365356, train/raw-loss = 0.14290574193000793, train/logprobs = tensor([[-0.7412, -9.2721],
        [-2.1764, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533053696155548
Epoch 0, Step 364: train/loss = 0.17578378319740295, train/raw-loss = 0.1396905928850174, train/logprobs = tensor([[-0.9533, -9.0421],
        [-2.6780, -0.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609318435192108
Epoch 0, Step 365: train/loss = 0.2518060803413391, train/raw-loss = 0.2217828333377838, train/logprobs = tensor([[-0.8961, -5.6026],
        [-1.5928, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002324104309082
Epoch 0, Step 366: train/loss = 0.11854054033756256, train/raw-loss = 0.083455890417099, train/logprobs = tensor([[-0.7999, -9.9172],
        [-3.5351, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35084640979766846
Epoch 0, Step 367: train/loss = 0.24006600677967072, train/raw-loss = 0.20210227370262146, train/logprobs = tensor([[-1.1192, -4.9768],
        [-2.8496, -1.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3796372711658478
Epoch 0, Step 368: train/loss = 0.12058790773153305, train/raw-loss = 0.08090326189994812, train/logprobs = tensor([[-0.9389, -8.8764],
        [-3.7589, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3968464732170105
Epoch 0, Step 369: train/loss = 0.19366349279880524, train/raw-loss = 0.15744571387767792, train/logprobs = tensor([[ -0.9976, -10.5684],
        [ -1.9511,  -0.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36217784881591797
Epoch 0, Step 370: train/loss = 0.1716567575931549, train/raw-loss = 0.13367527723312378, train/logprobs = tensor([[-0.9780, -5.8347],
        [-2.8045, -1.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3798148036003113
Epoch 0, Step 371: train/loss = 0.26787203550338745, train/raw-loss = 0.24077239632606506, train/logprobs = tensor([[-0.7051, -8.1156],
        [-1.4101, -1.4044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2709963619709015
Epoch 0, Step 372: train/loss = 0.08516155183315277, train/raw-loss = 0.047151558101177216, train/logprobs = tensor([[ -1.1347, -11.4524],
        [ -3.7567,  -1.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38009992241859436
Epoch 0, Step 373: train/loss = 0.13390395045280457, train/raw-loss = 0.09679511189460754, train/logprobs = tensor([[-0.6979, -7.3488],
        [-3.3070, -1.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.371088445186615
Epoch 0, Step 374: train/loss = 0.22619202733039856, train/raw-loss = 0.19509629905223846, train/logprobs = tensor([[-0.8548, -5.2946],
        [-1.8989, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31095725297927856
Epoch 0, Step 375: train/loss = 0.1615847498178482, train/raw-loss = 0.1225140392780304, train/logprobs = tensor([[-1.4715, -6.0764],
        [-3.9719, -1.3785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39070719480514526
Epoch 0, Step 376: train/loss = 0.2396795004606247, train/raw-loss = 0.20339378714561462, train/logprobs = tensor([[-1.1517, -3.1640],
        [-3.0382, -1.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36285698413848877
Epoch 0, Step 377: train/loss = 0.19561602175235748, train/raw-loss = 0.16463367640972137, train/logprobs = tensor([[-0.7958, -4.5278],
        [-2.3021, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30982351303100586
Epoch 0, Step 378: train/loss = 0.293427973985672, train/raw-loss = 0.2487269639968872, train/logprobs = tensor([[-1.4238, -6.3907],
        [-2.8040, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4470100402832031
Epoch 0, Step 379: train/loss = 0.12903174757957458, train/raw-loss = 0.09284454584121704, train/logprobs = tensor([[ -0.8667, -10.5654],
        [ -3.1375,  -1.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.361872136592865
Epoch 0, Step 380: train/loss = 0.18548202514648438, train/raw-loss = 0.1521257907152176, train/logprobs = tensor([[-1.1098, -6.0005],
        [-3.3188, -1.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33356228470802307
Epoch 0, Step 381: train/loss = 0.14208772778511047, train/raw-loss = 0.10911788046360016, train/logprobs = tensor([[-0.9631, -7.7410],
        [-2.5208, -0.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32969826459884644
Epoch 0, Step 382: train/loss = 0.20393790304660797, train/raw-loss = 0.1689041554927826, train/logprobs = tensor([[-0.8652, -5.5687],
        [-2.9450, -1.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35033759474754333
Epoch 0, Step 383: train/loss = 0.1554085910320282, train/raw-loss = 0.1201459988951683, train/logprobs = tensor([[ -0.8587, -10.4638],
        [ -2.0903,  -1.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35262608528137207
Epoch 0, Step 384: train/loss = 0.12586548924446106, train/raw-loss = 0.08506478369235992, train/logprobs = tensor([[-0.7709, -6.6947],
        [-2.7965, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40800708532333374
Epoch 0, Step 385: train/loss = 0.10104654729366302, train/raw-loss = 0.059583645313978195, train/logprobs = tensor([[-0.8788, -9.7618],
        [-3.2990, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4146289527416229
Epoch 0, Step 386: train/loss = 0.11814498901367188, train/raw-loss = 0.07525447010993958, train/logprobs = tensor([[-1.0201, -8.7902],
        [-2.9025, -1.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42890530824661255
Epoch 0, Step 387: train/loss = 0.14471663534641266, train/raw-loss = 0.10820327699184418, train/logprobs = tensor([[-0.6883, -7.3412],
        [-2.0842, -0.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651336431503296
Epoch 0, Step 388: train/loss = 0.12708663940429688, train/raw-loss = 0.08423291146755219, train/logprobs = tensor([[-0.8464, -6.8542],
        [-3.5162, -2.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4285372495651245
Epoch 0, Step 389: train/loss = 0.06709002703428268, train/raw-loss = 0.018512288108468056, train/logprobs = tensor([[-0.8539, -8.6357],
        [-5.8742, -1.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.485777348279953
Epoch 0, Step 390: train/loss = 0.15276461839675903, train/raw-loss = 0.11565261334180832, train/logprobs = tensor([[-0.6994, -8.9911],
        [-2.1174, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37111997604370117
Epoch 0, Step 391: train/loss = 0.29814907908439636, train/raw-loss = 0.26045161485671997, train/logprobs = tensor([[-1.2223, -5.3062],
        [-2.0992, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37697452306747437
Epoch 0, Step 392: train/loss = 0.08483220636844635, train/raw-loss = 0.03870021179318428, train/logprobs = tensor([[-1.0637, -8.7009],
        [-4.9402, -1.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4613199532032013
Epoch 0, Step 393: train/loss = 0.14884263277053833, train/raw-loss = 0.11025536060333252, train/logprobs = tensor([[-0.7817, -8.4279],
        [-2.5608, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38587266206741333
Epoch 0, Step 394: train/loss = 0.1193532794713974, train/raw-loss = 0.0765690803527832, train/logprobs = tensor([[-0.7684, -6.9213],
        [-4.1490, -1.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4278419315814972
Epoch 0, Step 395: train/loss = 0.17544636130332947, train/raw-loss = 0.1427641212940216, train/logprobs = tensor([[ -0.6391, -10.2993],
        [ -1.8388,  -2.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32682228088378906
Epoch 0, Step 396: train/loss = 0.14166128635406494, train/raw-loss = 0.1020200252532959, train/logprobs = tensor([[-0.9129, -7.8296],
        [-3.3247, -1.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39641255140304565
Epoch 0, Step 397: train/loss = 0.1635708212852478, train/raw-loss = 0.12618671357631683, train/logprobs = tensor([[-0.6976, -8.8148],
        [-2.9457, -2.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3738410472869873
Epoch 0, Step 398: train/loss = 0.1039971262216568, train/raw-loss = 0.05984874814748764, train/logprobs = tensor([[-0.7667, -8.6345],
        [-2.9571, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44148385524749756
Epoch 0, Step 399: train/loss = 0.1634516566991806, train/raw-loss = 0.13013309240341187, train/logprobs = tensor([[ -0.5859, -10.4978],
        [ -1.8388,  -1.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331855833530426
Epoch 0, Step 400: train/loss = 0.13824018836021423, train/raw-loss = 0.09358589351177216, train/logprobs = tensor([[-1.3200, -6.9904],
        [-4.2953, -1.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.446542888879776
Epoch 0, Step 401: train/loss = 0.11234484612941742, train/raw-loss = 0.07307693362236023, train/logprobs = tensor([[-0.7717, -6.5742],
        [-3.2029, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3926791548728943
Epoch 0, Step 402: train/loss = 0.12839920818805695, train/raw-loss = 0.09067174792289734, train/logprobs = tensor([[-1.0183, -7.8135],
        [-2.6517, -0.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37727463245391846
Epoch 0, Step 403: train/loss = 0.1563778817653656, train/raw-loss = 0.11854395270347595, train/logprobs = tensor([[-0.6673, -7.4818],
        [-2.6898, -1.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37833917140960693
Epoch 0, Step 404: train/loss = 0.11055470257997513, train/raw-loss = 0.07186207920312881, train/logprobs = tensor([[-0.6162, -7.2495],
        [-3.1677, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38692623376846313
Epoch 0, Step 405: train/loss = 0.25031253695487976, train/raw-loss = 0.2144894301891327, train/logprobs = tensor([[-0.7457, -8.6610],
        [-1.8148, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3582310676574707
Epoch 0, Step 406: train/loss = 0.12039050459861755, train/raw-loss = 0.08011405169963837, train/logprobs = tensor([[-1.0207, -8.8559],
        [-3.0614, -2.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4027644693851471
Epoch 0, Step 407: train/loss = 0.12858739495277405, train/raw-loss = 0.08760030567646027, train/logprobs = tensor([[-0.7822, -4.7126],
        [-2.9697, -1.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40987086296081543
Epoch 0, Step 408: train/loss = 0.13813291490077972, train/raw-loss = 0.09053380787372589, train/logprobs = tensor([[-0.6729, -5.8056],
        [-4.2406, -1.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47599098086357117
Epoch 0, Step 409: train/loss = 0.10360006988048553, train/raw-loss = 0.0662025585770607, train/logprobs = tensor([[-0.7039, -9.2551],
        [-2.7809, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37397509813308716
Epoch 0, Step 410: train/loss = 0.12279538065195084, train/raw-loss = 0.07900052517652512, train/logprobs = tensor([[-0.7955, -7.7433],
        [-2.7063, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4379485249519348
Epoch 0, Step 411: train/loss = 0.1326460987329483, train/raw-loss = 0.09544970095157623, train/logprobs = tensor([[-0.8642, -7.4238],
        [-2.9027, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37196385860443115
Epoch 0, Step 412: train/loss = 0.13235145807266235, train/raw-loss = 0.09418042004108429, train/logprobs = tensor([[ -0.7694, -11.4467],
        [ -2.2481,  -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38171038031578064
Epoch 0, Step 413: train/loss = 0.15271973609924316, train/raw-loss = 0.10458827763795853, train/logprobs = tensor([[-0.7363, -3.4974],
        [-5.2346, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48131468892097473
Epoch 0, Step 414: train/loss = 0.09259921312332153, train/raw-loss = 0.051045820116996765, train/logprobs = tensor([[-0.8656, -8.0012],
        [-3.3159, -1.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4155339300632477
Epoch 0, Step 415: train/loss = 0.08562060445547104, train/raw-loss = 0.038600124418735504, train/logprobs = tensor([[-1.3940, -6.9908],
        [-4.9249, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47020477056503296
Epoch 0, Step 416: train/loss = 0.13726255297660828, train/raw-loss = 0.09353743493556976, train/logprobs = tensor([[-0.8209, -9.1963],
        [-3.7906, -0.6727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43725115060806274
Epoch 0, Step 417: train/loss = 0.17606836557388306, train/raw-loss = 0.14209111034870148, train/logprobs = tensor([[-0.7471, -8.6770],
        [-2.1618, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33977267146110535
Epoch 0, Step 418: train/loss = 0.13830864429473877, train/raw-loss = 0.09582960605621338, train/logprobs = tensor([[-0.8489, -9.6595],
        [-2.5077, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42479029297828674
Epoch 0, Step 419: train/loss = 0.06246669590473175, train/raw-loss = 0.011549175716936588, train/logprobs = tensor([[-1.2309, -9.4587],
        [-5.5500, -2.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.509175181388855
Epoch 0, Step 420: train/loss = 0.10133485496044159, train/raw-loss = 0.06000310927629471, train/logprobs = tensor([[ -0.6428, -10.7199],
        [ -3.4896,  -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41331738233566284
Epoch 0, Step 421: train/loss = 0.1229989230632782, train/raw-loss = 0.07514294981956482, train/logprobs = tensor([[-0.8631, -7.8765],
        [-4.2079, -1.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4785597324371338
Epoch 0, Step 422: train/loss = 0.09651312232017517, train/raw-loss = 0.05411051958799362, train/logprobs = tensor([[ -0.7311, -10.2398],
        [ -3.6404,  -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4240260124206543
Epoch 0, Step 423: train/loss = 0.11071626842021942, train/raw-loss = 0.06903766840696335, train/logprobs = tensor([[ -0.8005, -10.3764],
        [ -3.1124,  -2.3236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41678595542907715
Epoch 0, Step 424: train/loss = 0.09358175098896027, train/raw-loss = 0.04616769775748253, train/logprobs = tensor([[-0.9238, -9.5703],
        [-5.3450, -2.2793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47414058446884155
Epoch 0, Step 425: train/loss = 0.08094868808984756, train/raw-loss = 0.032373711466789246, train/logprobs = tensor([[-1.2081, -7.0905],
        [-4.4041, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4857497811317444
Epoch 0, Step 426: train/loss = 0.10100983828306198, train/raw-loss = 0.05001545324921608, train/logprobs = tensor([[-0.9057, -6.9095],
        [-6.1740, -2.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5099439024925232
Epoch 0, Step 427: train/loss = 0.1068999171257019, train/raw-loss = 0.06639236956834793, train/logprobs = tensor([[-0.9298, -9.5888],
        [-3.2138, -2.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40507543087005615
Epoch 0, Step 428: train/loss = 0.1931690275669098, train/raw-loss = 0.15236873924732208, train/logprobs = tensor([[-0.7670, -6.1086],
        [-3.4530, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40800297260284424
Epoch 0, Step 429: train/loss = 0.10337330400943756, train/raw-loss = 0.0561416819691658, train/logprobs = tensor([[-1.3170, -9.4261],
        [-3.4819, -1.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47231611609458923
Epoch 0, Step 430: train/loss = 0.20960476994514465, train/raw-loss = 0.16239723563194275, train/logprobs = tensor([[-0.9673, -6.3909],
        [-3.5794, -2.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4720754623413086
Epoch 0, Step 431: train/loss = 0.09690288454294205, train/raw-loss = 0.04599527642130852, train/logprobs = tensor([[-1.0106, -9.9815],
        [-4.2597, -3.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5090760588645935
Epoch 0, Step 432: train/loss = 0.21655769646167755, train/raw-loss = 0.1768062263727188, train/logprobs = tensor([[-1.2455, -5.3898],
        [-3.3780, -1.8266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39751455187797546
Epoch 0, Step 433: train/loss = 0.1874489039182663, train/raw-loss = 0.1416594684123993, train/logprobs = tensor([[-0.7491, -7.0116],
        [-4.2802, -2.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4578944146633148
Epoch 0, Step 434: train/loss = 0.08942928910255432, train/raw-loss = 0.0437166765332222, train/logprobs = tensor([[-0.8832, -6.7862],
        [-4.3048, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45712608098983765
Epoch 0, Step 435: train/loss = 0.16863714158535004, train/raw-loss = 0.1179007813334465, train/logprobs = tensor([[ -1.0960, -10.1791],
        [ -3.9985,  -1.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5073636770248413
Epoch 0, Step 436: train/loss = 0.1354847252368927, train/raw-loss = 0.09420943260192871, train/logprobs = tensor([[-1.0921, -6.8606],
        [-3.0990, -1.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41275301575660706
Epoch 0, Step 437: train/loss = 0.16664569079875946, train/raw-loss = 0.11988267302513123, train/logprobs = tensor([[-0.8748, -6.9147],
        [-3.5177, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4676300883293152
Epoch 0, Step 438: train/loss = 0.22391435503959656, train/raw-loss = 0.1832214593887329, train/logprobs = tensor([[-0.9723, -7.6734],
        [-3.6891, -1.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4069289565086365
Epoch 0, Step 439: train/loss = 0.22343763709068298, train/raw-loss = 0.18492604792118073, train/logprobs = tensor([[-0.7682, -4.1110],
        [-2.9674, -1.2832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3851158916950226
Epoch 0, Step 440: train/loss = 0.13138866424560547, train/raw-loss = 0.08884119987487793, train/logprobs = tensor([[-0.6761, -7.6920],
        [-3.1032, -2.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254745841026306
Epoch 0, Step 441: train/loss = 0.13116572797298431, train/raw-loss = 0.08808637410402298, train/logprobs = tensor([[-1.0971, -7.8288],
        [-3.9061, -0.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4307934641838074
Epoch 0, Step 442: train/loss = 0.07809542119503021, train/raw-loss = 0.03183062747120857, train/logprobs = tensor([[-1.0856, -7.9345],
        [-4.6831, -2.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4626478850841522
Epoch 0, Step 443: train/loss = 0.09503702819347382, train/raw-loss = 0.049993254244327545, train/logprobs = tensor([[-0.8530, -7.7918],
        [-4.5727, -1.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4504376947879791
Epoch 0, Step 444: train/loss = 0.09705512225627899, train/raw-loss = 0.052210733294487, train/logprobs = tensor([[-1.2730, -5.7207],
        [-4.3912, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44844383001327515
Epoch 0, Step 445: train/loss = 0.20383389294147491, train/raw-loss = 0.1600368767976761, train/logprobs = tensor([[-1.0997, -4.6997],
        [-3.8336, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43797022104263306
Epoch 0, Step 446: train/loss = 0.137965589761734, train/raw-loss = 0.09732665866613388, train/logprobs = tensor([[-1.1865, -8.0737],
        [-2.9484, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4063892960548401
Epoch 0, Step 447: train/loss = 0.10408110916614532, train/raw-loss = 0.059813663363456726, train/logprobs = tensor([[-0.9088, -8.2573],
        [-3.3071, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4426744282245636
Epoch 0, Step 448: train/loss = 0.09257884323596954, train/raw-loss = 0.044144369661808014, train/logprobs = tensor([[-0.9214, -8.5246],
        [-4.0034, -3.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4843446910381317
Epoch 0, Step 449: train/loss = 0.08717495948076248, train/raw-loss = 0.040893957018852234, train/logprobs = tensor([[-1.3679, -9.2101],
        [-4.3942, -1.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4628099799156189
Epoch 0, Step 450: train/loss = 0.1352234184741974, train/raw-loss = 0.0904531478881836, train/logprobs = tensor([[-1.2145, -8.3104],
        [-3.3060, -1.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477027952671051
Epoch 0, Step 451: train/loss = 0.08387456834316254, train/raw-loss = 0.0344587005674839, train/logprobs = tensor([[-0.9235, -8.1656],
        [-4.4756, -1.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49415868520736694
Epoch 0, Step 452: train/loss = 0.12717939913272858, train/raw-loss = 0.0746222659945488, train/logprobs = tensor([[-0.8339, -5.5745],
        [-5.5160, -2.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.525571346282959
Epoch 0, Step 453: train/loss = 0.07241390645503998, train/raw-loss = 0.01905865967273712, train/logprobs = tensor([[-1.3022, -6.1304],
        [-6.2348, -1.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5335524082183838
Epoch 0, Step 454: train/loss = 0.2129148542881012, train/raw-loss = 0.1701163798570633, train/logprobs = tensor([[-1.3933, -5.8898],
        [-3.0749, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42798465490341187
Epoch 0, Step 455: train/loss = 0.09061332046985626, train/raw-loss = 0.04841244965791702, train/logprobs = tensor([[-0.8459, -9.9530],
        [-3.5685, -2.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42200881242752075
Epoch 0, Step 456: train/loss = 0.08976851403713226, train/raw-loss = 0.03495881333947182, train/logprobs = tensor([[-0.8425, -7.5933],
        [-6.4053, -2.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5480969548225403
Epoch 0, Step 457: train/loss = 0.09248609840869904, train/raw-loss = 0.04279186576604843, train/logprobs = tensor([[-1.2697, -5.4490],
        [-6.6134, -2.2680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49694231152534485
Epoch 0, Step 458: train/loss = 0.09385080635547638, train/raw-loss = 0.04355018585920334, train/logprobs = tensor([[-1.1591, -7.8275],
        [-4.6014, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5030062198638916
Epoch 0, Step 459: train/loss = 0.14653348922729492, train/raw-loss = 0.10083974897861481, train/logprobs = tensor([[-0.7423, -7.0208],
        [-4.8456, -3.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4569375514984131
Epoch 0, Step 460: train/loss = 0.1399320662021637, train/raw-loss = 0.08967233449220657, train/logprobs = tensor([[-1.0450, -5.9898],
        [-4.8433, -2.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5025972127914429
Epoch 0, Step 461: train/loss = 0.2635834515094757, train/raw-loss = 0.2213195115327835, train/logprobs = tensor([[-0.8008, -6.1733],
        [-3.2164, -1.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4226393699645996
Epoch 0, Step 462: train/loss = 0.08669054508209229, train/raw-loss = 0.031648676842451096, train/logprobs = tensor([[ -1.0015, -11.4326],
        [ -6.2180,  -4.3814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5504186153411865
Epoch 0, Step 463: train/loss = 0.07116986066102982, train/raw-loss = 0.015028289519250393, train/logprobs = tensor([[-1.2472, -7.9053],
        [-5.4913, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5614157319068909
Epoch 0, Step 464: train/loss = 0.10345162451267242, train/raw-loss = 0.05659079551696777, train/logprobs = tensor([[ -1.3370, -10.3798],
        [ -4.8368,  -2.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46860820055007935
Epoch 0, Step 465: train/loss = 0.13602009415626526, train/raw-loss = 0.08722251653671265, train/logprobs = tensor([[-1.8092, -5.9629],
        [-4.7574, -2.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48797568678855896
Epoch 0, Step 466: train/loss = 0.14464962482452393, train/raw-loss = 0.09256693720817566, train/logprobs = tensor([[-1.0120, -7.2562],
        [-4.9991, -2.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5208269357681274
Epoch 0, Step 467: train/loss = 0.08878007531166077, train/raw-loss = 0.036261849105358124, train/logprobs = tensor([[-1.3334, -6.1241],
        [-6.7087, -2.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5251822471618652
Epoch 0, Step 468: train/loss = 0.06413362175226212, train/raw-loss = 0.014185430482029915, train/logprobs = tensor([[-0.8447, -7.1718],
        [-5.3796, -1.4061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4994818866252899
Epoch 0, Step 469: train/loss = 0.10878560692071915, train/raw-loss = 0.060966018587350845, train/logprobs = tensor([[-1.1903, -7.4165],
        [-6.2539, -2.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47819584608078003
Epoch 0, Step 470: train/loss = 0.07308851182460785, train/raw-loss = 0.020072611048817635, train/logprobs = tensor([[-0.9786, -8.4512],
        [-5.1479, -2.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5301589965820312
Epoch 0, Step 471: train/loss = 0.06793609261512756, train/raw-loss = 0.01638432964682579, train/logprobs = tensor([[-0.9326, -9.5450],
        [-6.2161, -2.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5155175924301147
Epoch 0, Step 472: train/loss = 0.10933315753936768, train/raw-loss = 0.06770651787519455, train/logprobs = tensor([[-0.7731, -5.4877],
        [-3.8826, -2.2894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4162663519382477
Epoch 0, Step 473: train/loss = 0.12905867397785187, train/raw-loss = 0.07992435991764069, train/logprobs = tensor([[-0.8738, -9.2392],
        [-3.9949, -2.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49134311079978943
Epoch 0, Step 474: train/loss = 0.07260531187057495, train/raw-loss = 0.015320475213229656, train/logprobs = tensor([[-0.9721, -6.5567],
        [-5.7060, -1.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.572848379611969
Epoch 0, Step 475: train/loss = 0.17336949706077576, train/raw-loss = 0.1264916956424713, train/logprobs = tensor([[-0.8179, -8.3417],
        [-3.9190, -3.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46877801418304443
Epoch 0, Step 476: train/loss = 0.15541669726371765, train/raw-loss = 0.10055706650018692, train/logprobs = tensor([[-1.3015, -6.5963],
        [-6.7253, -2.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.548596203327179
Epoch 0, Step 477: train/loss = 0.3832165598869324, train/raw-loss = 0.33823496103286743, train/logprobs = tensor([[-1.0482, -4.0362],
        [-4.5550, -2.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4498157203197479
Epoch 0, Step 478: train/loss = 0.10008209943771362, train/raw-loss = 0.05168991535902023, train/logprobs = tensor([[-1.0070, -5.4966],
        [-5.3558, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4839218556880951
Epoch 0, Step 479: train/loss = 0.08851242810487747, train/raw-loss = 0.03808797895908356, train/logprobs = tensor([[-1.0141, -6.8890],
        [-5.2879, -1.2959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5042444467544556
Epoch 0, Step 480: train/loss = 0.06916771084070206, train/raw-loss = 0.011489411816000938, train/logprobs = tensor([[-1.3632, -7.3986],
        [-6.6881, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5767829418182373
Epoch 0, Step 481: train/loss = 0.10297590494155884, train/raw-loss = 0.050198573619127274, train/logprobs = tensor([[-0.8440, -9.4312],
        [-4.4991, -1.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5277733206748962
Epoch 0, Step 482: train/loss = 0.06777697801589966, train/raw-loss = 0.012590532191097736, train/logprobs = tensor([[ -0.9559, -12.1531],
        [ -5.9332,  -3.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5518644452095032
Epoch 0, Step 483: train/loss = 0.08554507046937943, train/raw-loss = 0.032885000109672546, train/logprobs = tensor([[-1.4508, -7.8422],
        [-5.2812, -1.6653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5266006588935852
Epoch 0, Step 484: train/loss = 0.2169719636440277, train/raw-loss = 0.1718861609697342, train/logprobs = tensor([[-1.2363, -4.3504],
        [-3.7807, -1.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45085811614990234
Epoch 0, Step 485: train/loss = 0.31808847188949585, train/raw-loss = 0.26147469878196716, train/logprobs = tensor([[-1.6935, -5.9038],
        [-6.5884, -2.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5661377906799316
Epoch 0, Step 486: train/loss = 0.14716780185699463, train/raw-loss = 0.08301465213298798, train/logprobs = tensor([[-1.3842, -5.3845],
        [-6.5309, -1.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6415314674377441
Epoch 0, Step 487: train/loss = 0.08286193013191223, train/raw-loss = 0.027705173939466476, train/logprobs = tensor([[-1.2129, -8.0425],
        [-6.1058, -3.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.551567554473877
Epoch 0, Step 488: train/loss = 0.2920953631401062, train/raw-loss = 0.23157745599746704, train/logprobs = tensor([[-0.9952, -7.4183],
        [-5.3792, -2.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6051792502403259
Epoch 0, Step 489: train/loss = 0.0896202102303505, train/raw-loss = 0.030796639621257782, train/logprobs = tensor([[-1.1101, -7.0240],
        [-6.0578, -2.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5882356762886047
Epoch 0, Step 490: train/loss = 0.16488409042358398, train/raw-loss = 0.11716338992118835, train/logprobs = tensor([[-0.9987, -6.5391],
        [-5.2990, -2.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4772070050239563
Epoch 0, Step 491: train/loss = 0.10193801671266556, train/raw-loss = 0.04370483011007309, train/logprobs = tensor([[-0.9777, -6.7638],
        [-5.1410, -2.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5823318362236023
Epoch 0, Step 492: train/loss = 0.07756922394037247, train/raw-loss = 0.011365190148353577, train/logprobs = tensor([[-1.2311, -9.7312],
        [-7.5940, -3.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6620403528213501
Epoch 0, Step 493: train/loss = 0.06363139301538467, train/raw-loss = 0.0013288870686665177, train/logprobs = tensor([[ -1.4075, -11.9392],
        [ -7.5841,  -2.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6230250000953674
Epoch 0, Step 494: train/loss = 0.09037286043167114, train/raw-loss = 0.02991410717368126, train/logprobs = tensor([[-1.3572, -6.0875],
        [-6.7587, -1.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6045875549316406
Epoch 0, Step 495: train/loss = 0.1565980613231659, train/raw-loss = 0.10514669120311737, train/logprobs = tensor([[-0.9665, -7.9927],
        [-5.3244, -2.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5145135521888733
Epoch 0, Step 496: train/loss = 0.08501012623310089, train/raw-loss = 0.030384600162506104, train/logprobs = tensor([[-1.2678, -7.4708],
        [-5.5277, -1.3963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5462552309036255
Epoch 0, Step 497: train/loss = 0.15194453299045563, train/raw-loss = 0.10022412240505219, train/logprobs = tensor([[-1.2675, -6.8313],
        [-4.9187, -1.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5172040462493896
Epoch 0, Step 498: train/loss = 0.14633044600486755, train/raw-loss = 0.09530608355998993, train/logprobs = tensor([[-0.8112, -4.6676],
        [-4.6511, -2.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5102435350418091
Epoch 0, Step 499: train/loss = 0.07438035309314728, train/raw-loss = 0.023555682972073555, train/logprobs = tensor([[-1.0153, -7.8059],
        [-5.0634, -2.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.508246660232544
Epoch 0, Step 500: train/loss = 0.2026587724685669, train/raw-loss = 0.1485055387020111, train/logprobs = tensor([[-1.0322, -5.8425],
        [-4.3094, -2.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5415322780609131
Epoch 0, Step 501: train/loss = 0.11263275146484375, train/raw-loss = 0.05887361615896225, train/logprobs = tensor([[-1.2279, -9.8562],
        [-5.9940, -3.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5375913381576538
Epoch 0, Step 502: train/loss = 0.18433967232704163, train/raw-loss = 0.1292908489704132, train/logprobs = tensor([[-1.1290, -8.6713],
        [-5.5808, -2.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5504881739616394
Epoch 0, Step 503: train/loss = 0.08767909556627274, train/raw-loss = 0.032849349081516266, train/logprobs = tensor([[-1.2260, -7.4493],
        [-5.3601, -2.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5482975244522095
Epoch 0, Step 504: train/loss = 0.12355750799179077, train/raw-loss = 0.06729143112897873, train/logprobs = tensor([[-0.9827, -8.5479],
        [-4.6560, -3.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.562660813331604
Epoch 0, Step 505: train/loss = 0.10974735021591187, train/raw-loss = 0.06004829332232475, train/logprobs = tensor([[-0.7589, -8.2569],
        [-4.4651, -2.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4969905614852905
Epoch 0, Step 506: train/loss = 0.17532280087471008, train/raw-loss = 0.12339180707931519, train/logprobs = tensor([[-1.4930, -6.1825],
        [-6.4816, -2.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5193098783493042
Epoch 0, Step 507: train/loss = 0.09255725145339966, train/raw-loss = 0.043319426476955414, train/logprobs = tensor([[-1.0075, -8.2095],
        [-5.4657, -2.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49237820506095886
Epoch 0, Step 508: train/loss = 0.06303644180297852, train/raw-loss = 0.004322551656514406, train/logprobs = tensor([[-1.4338, -9.3599],
        [-8.4143, -1.8274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5871388912200928
Epoch 0, Step 509: train/loss = 0.10869080573320389, train/raw-loss = 0.05276081711053848, train/logprobs = tensor([[-0.8619, -6.5755],
        [-5.9499, -2.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.559299886226654
Epoch 0, Step 510: train/loss = 0.2645924687385559, train/raw-loss = 0.21397197246551514, train/logprobs = tensor([[-1.1355, -5.7714],
        [-4.3609, -2.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5062050819396973
Epoch 0, Step 511: train/loss = 0.13569173216819763, train/raw-loss = 0.08249995112419128, train/logprobs = tensor([[-1.3536, -4.6021],
        [-6.7494, -1.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5319177508354187
Epoch 0, Step 512: train/loss = 0.10020089149475098, train/raw-loss = 0.04641463980078697, train/logprobs = tensor([[-0.8876, -6.4673],
        [-4.4877, -1.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5378625392913818
Epoch 0, Step 513: train/loss = 0.1864376664161682, train/raw-loss = 0.13665737211704254, train/logprobs = tensor([[-1.4873, -4.9867],
        [-5.4649, -1.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4978029131889343
Epoch 0, Step 514: train/loss = 0.07543061673641205, train/raw-loss = 0.015320338308811188, train/logprobs = tensor([[-0.9466, -8.6296],
        [-6.4664, -1.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6011027693748474
Epoch 0, Step 515: train/loss = 0.07812123745679855, train/raw-loss = 0.015259415842592716, train/logprobs = tensor([[-1.0280, -8.5485],
        [-6.7736, -1.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6286181807518005
Epoch 0, Step 516: train/loss = 0.22194664180278778, train/raw-loss = 0.17149336636066437, train/logprobs = tensor([[-0.8661, -6.0101],
        [-3.1976, -1.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5045329332351685
Epoch 0, Step 517: train/loss = 0.09584833681583405, train/raw-loss = 0.035035718232393265, train/logprobs = tensor([[-1.0922, -8.9713],
        [-5.3654, -3.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6081262826919556
Epoch 0, Step 518: train/loss = 0.08506572991609573, train/raw-loss = 0.03275100886821747, train/logprobs = tensor([[-1.0072, -9.4989],
        [-4.8011, -1.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5231472253799438
Epoch 0, Step 519: train/loss = 0.08701783418655396, train/raw-loss = 0.018165986984968185, train/logprobs = tensor([[-1.4573, -8.6889],
        [-8.1895, -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6885184049606323
Epoch 0, Step 520: train/loss = 0.07362803816795349, train/raw-loss = 0.021907001733779907, train/logprobs = tensor([[-0.9164, -8.2625],
        [-4.9157, -1.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5172104239463806
Epoch 0, Step 521: train/loss = 0.17124752700328827, train/raw-loss = 0.11761311441659927, train/logprobs = tensor([[-0.6083, -6.7553],
        [-4.6454, -1.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5363441705703735
Epoch 0, Step 522: train/loss = 0.06888751685619354, train/raw-loss = 0.00444348668679595, train/logprobs = tensor([[-1.2743, -9.0326],
        [-7.5969, -0.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6444402933120728
Epoch 0, Step 523: train/loss = 0.17399761080741882, train/raw-loss = 0.11656766384840012, train/logprobs = tensor([[-1.5141, -5.7048],
        [-5.8649, -1.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5742995738983154
Epoch 0, Step 524: train/loss = 0.3756144344806671, train/raw-loss = 0.3158334493637085, train/logprobs = tensor([[-0.9511, -5.0315],
        [-6.7495, -2.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.597809910774231
Epoch 0, Step 525: train/loss = 0.10342850536108017, train/raw-loss = 0.049681808799505234, train/logprobs = tensor([[-0.9408, -7.0293],
        [-4.8150, -1.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5374669432640076
Epoch 0, Step 526: train/loss = 0.09362553060054779, train/raw-loss = 0.032193053513765335, train/logprobs = tensor([[-0.8583, -7.5317],
        [-4.9933, -1.3228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6143247485160828
Epoch 0, Step 527: train/loss = 0.07915760576725006, train/raw-loss = 0.015861114487051964, train/logprobs = tensor([[-1.6453, -9.8858],
        [-8.3020, -2.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6329649090766907
Epoch 0, Step 528: train/loss = 0.07754214107990265, train/raw-loss = 0.02650049328804016, train/logprobs = tensor([[-0.8280, -9.8806],
        [-5.0756, -3.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5104163885116577
Epoch 0, Step 529: train/loss = 0.06385441869497299, train/raw-loss = 0.006708967499434948, train/logprobs = tensor([[-1.0417, -8.9402],
        [-5.8779, -1.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5714545249938965
Epoch 0, Step 530: train/loss = 0.08212371170520782, train/raw-loss = 0.024235926568508148, train/logprobs = tensor([[-1.1861, -9.1974],
        [-5.1119, -1.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.578877866268158
Epoch 0, Step 531: train/loss = 0.08322932571172714, train/raw-loss = 0.021783452481031418, train/logprobs = tensor([[-1.1969, -9.5580],
        [-6.4905, -2.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6144586801528931
Epoch 0, Step 532: train/loss = 0.10840233415365219, train/raw-loss = 0.06227985769510269, train/logprobs = tensor([[-0.6587, -8.8664],
        [-3.3655, -2.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46122482419013977
Epoch 0, Step 533: train/loss = 0.12560947239398956, train/raw-loss = 0.07365548610687256, train/logprobs = tensor([[-0.7241, -8.0558],
        [-4.0142, -2.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5195399522781372
Epoch 0, Step 534: train/loss = 0.08925704658031464, train/raw-loss = 0.02309320867061615, train/logprobs = tensor([[ -1.0957, -10.7948],
        [ -5.9871,  -3.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6616384387016296
Epoch 0, Step 535: train/loss = 0.07294221222400665, train/raw-loss = 0.01375795342028141, train/logprobs = tensor([[-1.1509, -8.8160],
        [-6.3838, -2.2466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5918426513671875
Epoch 0, Step 536: train/loss = 0.11979310214519501, train/raw-loss = 0.06709441542625427, train/logprobs = tensor([[-1.0845, -7.7951],
        [-5.5941, -2.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5269867777824402
Epoch 0, Step 537: train/loss = 0.07551099359989166, train/raw-loss = 0.019833490252494812, train/logprobs = tensor([[-1.2466, -5.9840],
        [-6.9103, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5567749738693237
Epoch 0, Step 538: train/loss = 0.0924435704946518, train/raw-loss = 0.03711691498756409, train/logprobs = tensor([[-0.9311, -9.1387],
        [-6.4303, -2.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5532665848731995
Epoch 0, Step 539: train/loss = 0.06685761362314224, train/raw-loss = 0.005374567583203316, train/logprobs = tensor([[ -1.0964, -10.4743],
        [ -6.8457,  -2.5480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.614830493927002
Epoch 0, Step 540: train/loss = 0.07628714293241501, train/raw-loss = 0.013279713690280914, train/logprobs = tensor([[-1.2279, -7.2827],
        [-6.9845, -2.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6300743222236633
Epoch 0, Step 541: train/loss = 0.06508903950452805, train/raw-loss = 0.0035509043373167515, train/logprobs = tensor([[ -1.2875, -10.9884],
        [ -7.4373,  -1.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6153813600540161
Epoch 0, Step 542: train/loss = 0.07545717060565948, train/raw-loss = 0.022781740874052048, train/logprobs = tensor([[ -0.8564, -10.7415],
        [ -4.4451,  -2.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5267543792724609
Epoch 0, Step 543: train/loss = 0.12736880779266357, train/raw-loss = 0.06203887611627579, train/logprobs = tensor([[-1.1772, -6.4653],
        [-7.1320, -2.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6532992124557495
Epoch 0, Step 544: train/loss = 0.10555221140384674, train/raw-loss = 0.04688183590769768, train/logprobs = tensor([[ -0.9372, -11.0772],
        [ -4.6831,  -1.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5867037773132324
Epoch 0, Step 545: train/loss = 0.07490173727273941, train/raw-loss = 0.010746239684522152, train/logprobs = tensor([[ -1.1096, -12.4651],
        [ -5.7736,  -4.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6415549516677856
Epoch 0, Step 546: train/loss = 0.07306550443172455, train/raw-loss = 0.009448900818824768, train/logprobs = tensor([[-1.5234, -9.1803],
        [-6.6826, -2.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6361660957336426
Epoch 0, Step 547: train/loss = 0.07231379300355911, train/raw-loss = 0.007246360182762146, train/logprobs = tensor([[-1.5205, -8.3748],
        [-5.9604, -1.3633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6506742238998413
Epoch 0, Step 548: train/loss = 0.07645092159509659, train/raw-loss = 0.009677239693701267, train/logprobs = tensor([[-1.0988, -8.8383],
        [-6.3043, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6677367687225342
Epoch 0, Step 549: train/loss = 0.07367093116044998, train/raw-loss = 0.007863209582865238, train/logprobs = tensor([[ -1.4887, -11.2964],
        [ -6.3368,  -2.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6580771803855896
Epoch 0, Step 550: train/loss = 0.07476679235696793, train/raw-loss = 0.0024950571823865175, train/logprobs = tensor([[-1.3741, -8.7925],
        [-8.6885, -1.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.72271728515625
Epoch 0, Step 551: train/loss = 0.11150968074798584, train/raw-loss = 0.03972726687788963, train/logprobs = tensor([[-1.1611, -8.1618],
        [-6.0217, -1.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7178242206573486
Epoch 0, Step 552: train/loss = 0.07879431545734406, train/raw-loss = 0.01713932864367962, train/logprobs = tensor([[ -1.0315, -10.0142],
        [ -5.0453,  -2.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6165498495101929
Epoch 0, Step 553: train/loss = 0.09336748719215393, train/raw-loss = 0.0407860092818737, train/logprobs = tensor([[-1.6243, -8.2633],
        [-5.0953, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5258148312568665
Epoch 0, Step 554: train/loss = 0.07832098752260208, train/raw-loss = 0.00596124492585659, train/logprobs = tensor([[ -1.2313, -10.6263],
        [ -6.7378,  -1.6765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7235973477363586
Epoch 0, Step 555: train/loss = 0.0773380771279335, train/raw-loss = 0.008625581860542297, train/logprobs = tensor([[-1.5582, -8.7057],
        [-7.1805, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6871249675750732
Epoch 0, Step 556: train/loss = 0.2098744958639145, train/raw-loss = 0.13988502323627472, train/logprobs = tensor([[-1.4153, -9.5452],
        [-7.3440, -2.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6998945474624634
Epoch 0, Step 557: train/loss = 0.07693950831890106, train/raw-loss = 0.007916814647614956, train/logprobs = tensor([[ -1.6593, -13.1148],
        [ -7.4813,  -3.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6902269124984741
Epoch 0, Step 558: train/loss = 0.13310092687606812, train/raw-loss = 0.07533802092075348, train/logprobs = tensor([[-0.8574, -8.4803],
        [-3.8167, -1.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5776288509368896
Epoch 0, Step 559: train/loss = 0.07347171753644943, train/raw-loss = 0.007391088642179966, train/logprobs = tensor([[ -1.0759, -11.9105],
        [ -6.5100,  -2.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6608062982559204
Epoch 0, Step 560: train/loss = 0.07928833365440369, train/raw-loss = 0.020637569949030876, train/logprobs = tensor([[-1.0389, -9.9890],
        [-4.9132, -2.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5865076184272766
Epoch 0, Step 561: train/loss = 0.08306150883436203, train/raw-loss = 0.00720745837315917, train/logprobs = tensor([[ -1.3800, -11.0576],
        [ -6.0740,  -1.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7585405111312866
Epoch 0, Step 562: train/loss = 0.07742414623498917, train/raw-loss = 0.015578649938106537, train/logprobs = tensor([[-1.1267, -9.6105],
        [-5.5965, -2.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6184549331665039
Epoch 0, Step 563: train/loss = 0.0742226243019104, train/raw-loss = 0.0035793581046164036, train/logprobs = tensor([[ -1.2806, -10.1679],
        [ -6.7996,  -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7064327001571655
Epoch 0, Step 564: train/loss = 0.07267499715089798, train/raw-loss = 0.006288688629865646, train/logprobs = tensor([[-1.4953, -8.5671],
        [-6.9585, -1.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6638630032539368
Epoch 0, Step 565: train/loss = 0.16283836960792542, train/raw-loss = 0.10128870606422424, train/logprobs = tensor([[-1.5884, -8.7934],
        [-5.9137, -2.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6154964566230774
Epoch 0, Step 566: train/loss = 0.08693300187587738, train/raw-loss = 0.026256507262587547, train/logprobs = tensor([[ -1.2685, -10.2857],
        [ -4.4984,  -2.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6067649126052856
Epoch 0, Step 567: train/loss = 0.08304345607757568, train/raw-loss = 0.012932196259498596, train/logprobs = tensor([[-1.0677, -9.8587],
        [-6.1676, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7011125683784485
Epoch 0, Step 568: train/loss = 0.10545007884502411, train/raw-loss = 0.033857300877571106, train/logprobs = tensor([[-0.9816, -7.9666],
        [-6.5467, -2.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.71592777967453
Epoch 0, Step 569: train/loss = 0.07475396990776062, train/raw-loss = 0.007595713250339031, train/logprobs = tensor([[-1.1612, -9.4524],
        [-6.6269, -1.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6715825796127319
Epoch 0, Step 570: train/loss = 0.11857524514198303, train/raw-loss = 0.05174615606665611, train/logprobs = tensor([[-1.3888, -8.3401],
        [-6.4316, -3.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.668290913105011
Epoch 0, Step 571: train/loss = 0.10797286033630371, train/raw-loss = 0.04679694399237633, train/logprobs = tensor([[-0.9728, -9.7131],
        [-4.3056, -3.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6117591857910156
Epoch 0, Step 572: train/loss = 0.0823855847120285, train/raw-loss = 0.0071211280301213264, train/logprobs = tensor([[-1.4721, -7.0156],
        [-7.3414, -1.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.752644419670105
Epoch 0, Step 573: train/loss = 0.08339469134807587, train/raw-loss = 0.01657940447330475, train/logprobs = tensor([[ -1.6256, -10.9466],
        [ -6.3910,  -1.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6681528091430664
Epoch 0, Step 574: train/loss = 0.07305441796779633, train/raw-loss = 0.0028084716759622097, train/logprobs = tensor([[-1.4003, -9.5977],
        [-7.3362, -1.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.702459454536438
Epoch 0, Step 575: train/loss = 0.08909498155117035, train/raw-loss = 0.027294017374515533, train/logprobs = tensor([[-1.4674, -8.4067],
        [-5.7486, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6180095672607422
Epoch 0, Step 576: train/loss = 0.08282628655433655, train/raw-loss = 0.01682373136281967, train/logprobs = tensor([[ -1.1199, -11.2834],
        [ -5.3093,  -2.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6600254774093628
Epoch 0, Step 577: train/loss = 0.08125250041484833, train/raw-loss = 0.004793207161128521, train/logprobs = tensor([[-1.5087, -8.9352],
        [-6.7210, -2.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7645929455757141
Epoch 0, Step 578: train/loss = 0.10069645941257477, train/raw-loss = 0.030591236427426338, train/logprobs = tensor([[ -2.5960, -10.0061],
        [ -7.5695,  -1.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.701052188873291
Epoch 0, Step 579: train/loss = 0.08803639560937881, train/raw-loss = 0.009445490315556526, train/logprobs = tensor([[ -1.5024, -11.0587],
        [ -7.2014,  -3.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7859090566635132
Epoch 0, Step 580: train/loss = 0.08295047283172607, train/raw-loss = 0.021467162296175957, train/logprobs = tensor([[ -1.4663, -12.0722],
        [ -5.7794,  -2.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6148331761360168
Epoch 0, Step 581: train/loss = 0.08789125084877014, train/raw-loss = 0.017155831679701805, train/logprobs = tensor([[ -1.1536, -10.6538],
        [ -5.8852,  -1.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7073541879653931
Epoch 0, Step 582: train/loss = 0.08096131682395935, train/raw-loss = 0.0170084647834301, train/logprobs = tensor([[ -1.1702, -10.8616],
        [ -5.0113,  -1.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6395285129547119
Epoch 0, Step 583: train/loss = 0.08222982287406921, train/raw-loss = 0.007768501993268728, train/logprobs = tensor([[ -1.0952, -12.4624],
        [ -5.7847,  -2.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7446131706237793
Epoch 0, Step 584: train/loss = 0.09135937690734863, train/raw-loss = 0.014409533701837063, train/logprobs = tensor([[-1.4869, -9.8988],
        [-5.8136, -1.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7694984078407288
Epoch 0, Step 585: train/loss = 0.08015958964824677, train/raw-loss = 0.012031937018036842, train/logprobs = tensor([[-1.5417, -9.2403],
        [-5.3980, -1.4608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6812765598297119
Epoch 0, Step 586: train/loss = 0.09319622069597244, train/raw-loss = 0.025849679484963417, train/logprobs = tensor([[ -1.6281, -11.5329],
        [ -5.4622,  -2.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6734654903411865
Epoch 0, Step 587: train/loss = 0.19489778578281403, train/raw-loss = 0.1216658279299736, train/logprobs = tensor([[-2.1138, -9.8428],
        [-6.0300, -1.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7323195338249207
Epoch 0, Step 588: train/loss = 0.08590702712535858, train/raw-loss = 0.019950825721025467, train/logprobs = tensor([[ -1.3868, -12.3962],
        [ -5.9886,  -2.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6595619916915894
Epoch 0, Step 589: train/loss = 0.2547641098499298, train/raw-loss = 0.17747029662132263, train/logprobs = tensor([[ -1.3091, -11.7359],
        [ -6.1624,  -3.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7729381322860718
Epoch 0, Step 590: train/loss = 0.07097436487674713, train/raw-loss = 0.003433526959270239, train/logprobs = tensor([[ -1.5416, -11.1736],
        [ -7.3355,  -1.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6754083633422852
Epoch 0, Step 591: train/loss = 0.11277801543474197, train/raw-loss = 0.05033694952726364, train/logprobs = tensor([[-1.7639, -9.8896],
        [-4.9355, -2.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6244106292724609
Epoch 0, Step 592: train/loss = 0.0864119604229927, train/raw-loss = 0.00859604962170124, train/logprobs = tensor([[ -1.3862, -10.5609],
        [ -6.0407,  -2.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7781590819358826
Epoch 0, Step 593: train/loss = 0.09259426593780518, train/raw-loss = 0.026607410982251167, train/logprobs = tensor([[ -1.3414, -11.3618],
        [ -5.4977,  -2.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.659868597984314
Epoch 0, Step 594: train/loss = 0.128133624792099, train/raw-loss = 0.054290302097797394, train/logprobs = tensor([[ -2.2056, -12.6064],
        [ -7.6798,  -2.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.738433301448822
Epoch 0, Step 595: train/loss = 0.12253530323505402, train/raw-loss = 0.05866575241088867, train/logprobs = tensor([[ -1.6049, -12.3015],
        [ -4.7572,  -2.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.638695478439331
Epoch 0, Step 596: train/loss = 0.09907589107751846, train/raw-loss = 0.028382882475852966, train/logprobs = tensor([[-1.9530, -8.2080],
        [-4.9931, -1.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7069300413131714
Epoch 0, Step 597: train/loss = 0.08413772284984589, train/raw-loss = 0.011641504243016243, train/logprobs = tensor([[ -1.3224, -11.9773],
        [ -5.9334,  -2.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7249621152877808
Epoch 0, Step 598: train/loss = 0.21712857484817505, train/raw-loss = 0.14367236196994781, train/logprobs = tensor([[-1.0889, -9.0484],
        [-4.9372, -2.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.73456209897995
Epoch 0, Step 599: train/loss = 0.08623220026493073, train/raw-loss = 0.02173360250890255, train/logprobs = tensor([[-1.0587, -9.7732],
        [-5.1748, -1.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6449860334396362
Epoch 0, Step 600: train/loss = 0.08333276212215424, train/raw-loss = 0.0058218613266944885, train/logprobs = tensor([[ -1.2459, -11.3473],
        [ -6.8119,  -2.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7751089930534363
Epoch 0, Step 601: train/loss = 0.07942718267440796, train/raw-loss = 0.004602431319653988, train/logprobs = tensor([[ -2.1735, -11.2666],
        [ -8.1568,  -2.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.748247504234314
Epoch 0, Step 602: train/loss = 0.07736073434352875, train/raw-loss = 0.015094908885657787, train/logprobs = tensor([[ -1.3213, -12.1072],
        [ -7.2903,  -3.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6226582527160645
Epoch 0, Step 603: train/loss = 0.07998279482126236, train/raw-loss = 0.013370999135077, train/logprobs = tensor([[ -0.9279, -11.5667],
        [ -5.4038,  -1.6788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6661179065704346
Epoch 0, Step 604: train/loss = 0.08061140775680542, train/raw-loss = 0.0027534826658666134, train/logprobs = tensor([[ -1.3751, -12.8039],
        [ -6.9477,  -2.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7785792350769043
Epoch 0, Step 605: train/loss = 0.08964365720748901, train/raw-loss = 0.018356872722506523, train/logprobs = tensor([[ -1.0919, -10.3509],
        [ -5.0355,  -2.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.712867796421051
Epoch 0, Step 606: train/loss = 0.07324741780757904, train/raw-loss = 0.006718086078763008, train/logprobs = tensor([[ -1.6247, -10.8024],
        [ -7.0114,  -2.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6652933359146118
Epoch 0, Step 607: train/loss = 0.09278921037912369, train/raw-loss = 0.023194611072540283, train/logprobs = tensor([[ -1.6393, -15.1647],
        [ -5.1470,  -2.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6959460377693176
Epoch 0, Step 608: train/loss = 0.08675498515367508, train/raw-loss = 0.003971748054027557, train/logprobs = tensor([[ -1.5574, -14.8453],
        [ -6.7201,  -3.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8278323411941528
Epoch 0, Step 609: train/loss = 0.07356351613998413, train/raw-loss = 0.009772691875696182, train/logprobs = tensor([[ -1.4260, -11.4850],
        [ -6.0965,  -2.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6379082798957825
Epoch 0, Step 610: train/loss = 0.09217248111963272, train/raw-loss = 0.02411981113255024, train/logprobs = tensor([[ -1.6110, -13.1142],
        [ -5.3713,  -1.4084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6805267333984375
Epoch 0, Step 611: train/loss = 0.1506912261247635, train/raw-loss = 0.0831431895494461, train/logprobs = tensor([[-0.9657, -7.7999],
        [-4.6867, -2.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6754804253578186
Epoch 0, Step 612: train/loss = 0.07775155454874039, train/raw-loss = 0.0019392728572711349, train/logprobs = tensor([[ -1.6911, -13.4801],
        [ -7.8651,  -2.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7581228017807007
Epoch 0, Step 613: train/loss = 0.07553359866142273, train/raw-loss = 0.008034118451178074, train/logprobs = tensor([[ -1.8638, -11.0227],
        [ -7.1774,  -2.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6749947667121887
Epoch 0, Step 614: train/loss = 0.08717967569828033, train/raw-loss = 0.007729861419647932, train/logprobs = tensor([[ -2.0413, -10.7686],
        [ -7.8392,  -3.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.794498085975647
Epoch 0, Step 615: train/loss = 0.10528519004583359, train/raw-loss = 0.03411304950714111, train/logprobs = tensor([[-1.2922, -9.3943],
        [-5.8000, -3.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7117214202880859
Epoch 0, Step 616: train/loss = 0.08602556586265564, train/raw-loss = 0.007567977998405695, train/logprobs = tensor([[ -1.9671, -14.9484],
        [ -7.8326,  -1.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7845759391784668
Epoch 0, Step 617: train/loss = 0.07835245877504349, train/raw-loss = 0.002300105057656765, train/logprobs = tensor([[-2.0238, -9.9151],
        [-8.9467, -2.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7605235576629639
Epoch 0, Step 618: train/loss = 0.10211091488599777, train/raw-loss = 0.034290265291929245, train/logprobs = tensor([[ -1.3163, -10.2024],
        [ -6.2801,  -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6782065033912659
Epoch 0, Step 619: train/loss = 0.10217943787574768, train/raw-loss = 0.0204627588391304, train/logprobs = tensor([[ -1.5139, -10.8591],
        [ -8.0127,  -2.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.817166805267334
Epoch 0, Step 620: train/loss = 0.13300152122974396, train/raw-loss = 0.06225498020648956, train/logprobs = tensor([[ -1.3467, -14.1424],
        [ -5.6208,  -3.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7074652910232544
Epoch 0, Step 621: train/loss = 0.07739280164241791, train/raw-loss = 0.005402200855314732, train/logprobs = tensor([[-1.8110, -9.4405],
        [-6.6896, -2.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7199059724807739
Epoch 0, Step 622: train/loss = 0.08015580475330353, train/raw-loss = 0.007449547294527292, train/logprobs = tensor([[ -1.5269, -14.1884],
        [ -6.2693,  -2.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7270625829696655
Epoch 0, Step 623: train/loss = 0.08639197796583176, train/raw-loss = 0.02100745029747486, train/logprobs = tensor([[ -1.2583, -10.0212],
        [ -5.9310,  -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6538452506065369
Epoch 0, Step 624: train/loss = 0.07869628071784973, train/raw-loss = 0.012684291228652, train/logprobs = tensor([[ -1.5953, -13.8303],
        [ -5.4904,  -2.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.660119891166687
Epoch 0, Step 625: train/loss = 0.08145666867494583, train/raw-loss = 0.0033510737121105194, train/logprobs = tensor([[ -1.5665, -11.1612],
        [ -7.1326,  -2.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7810559272766113
Epoch 0, Step 626: train/loss = 0.07801702618598938, train/raw-loss = 0.01095652487128973, train/logprobs = tensor([[ -1.2872, -13.0968],
        [ -5.6724,  -2.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.670604944229126
Epoch 0, Step 627: train/loss = 0.10914593935012817, train/raw-loss = 0.04521960765123367, train/logprobs = tensor([[-1.2301, -8.2972],
        [-5.9517, -3.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6392632722854614
Epoch 0, Step 628: train/loss = 0.09120925515890121, train/raw-loss = 0.01611105538904667, train/logprobs = tensor([[ -1.5877, -10.1439],
        [ -6.7165,  -1.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7509819865226746
Epoch 0, Step 629: train/loss = 0.07689085602760315, train/raw-loss = 0.0013364319456741214, train/logprobs = tensor([[ -2.3998, -12.9804],
        [ -8.7347,  -2.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7555442452430725
Epoch 0, Step 630: train/loss = 0.08000612258911133, train/raw-loss = 0.0038733603432774544, train/logprobs = tensor([[ -1.8579, -10.5721],
        [ -8.2352,  -2.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7613276243209839
Epoch 0, Step 631: train/loss = 0.0840931311249733, train/raw-loss = 0.01720374822616577, train/logprobs = tensor([[-1.2860, -8.9870],
        [-5.9280, -2.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6688938140869141
Epoch 0, Step 632: train/loss = 0.15533480048179626, train/raw-loss = 0.09058420360088348, train/logprobs = tensor([[ -1.3213, -13.8474],
        [ -5.2954,  -2.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6475061178207397
Epoch 0, Step 633: train/loss = 0.07879128307104111, train/raw-loss = 0.005755844060331583, train/logprobs = tensor([[ -1.6123, -14.7190],
        [ -7.0274,  -2.3483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.730354368686676
Epoch 0, Step 634: train/loss = 0.09265897423028946, train/raw-loss = 0.01416672021150589, train/logprobs = tensor([[ -1.6378, -10.0520],
        [ -6.7990,  -3.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7849224805831909
Epoch 0, Step 635: train/loss = 0.06500795483589172, train/raw-loss = 0.006568672601133585, train/logprobs = tensor([[ -2.2256, -10.8829],
        [ -7.3910,  -2.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5843928456306458
Epoch 0, Step 636: train/loss = 0.08682416379451752, train/raw-loss = 0.006241986528038979, train/logprobs = tensor([[ -1.7259, -10.6702],
        [ -6.9763,  -2.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8058217763900757
Epoch 0, Step 637: train/loss = 0.09277311712503433, train/raw-loss = 0.02745484746992588, train/logprobs = tensor([[ -1.4239, -10.2611],
        [ -6.2096,  -2.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6531826257705688
Epoch 0, Step 638: train/loss = 0.07897470146417618, train/raw-loss = 0.014120932668447495, train/logprobs = tensor([[ -1.2611, -10.9055],
        [ -6.1833,  -3.1792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6485376358032227
Epoch 0, Step 639: train/loss = 0.1086965948343277, train/raw-loss = 0.04598430544137955, train/logprobs = tensor([[-1.5831, -7.8744],
        [-5.6253, -1.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6271229386329651
Epoch 0, Step 640: train/loss = 0.0849473625421524, train/raw-loss = 0.01246594823896885, train/logprobs = tensor([[ -1.4718, -12.8181],
        [ -7.4443,  -2.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7248141169548035
Epoch 0, Step 641: train/loss = 0.07255516946315765, train/raw-loss = 0.002315816469490528, train/logprobs = tensor([[ -1.7168, -13.9414],
        [ -7.3310,  -2.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7023935317993164
Epoch 0, Step 642: train/loss = 0.08145792782306671, train/raw-loss = 0.01101317536085844, train/logprobs = tensor([[ -1.0336, -10.9574],
        [ -6.4029,  -2.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7044475078582764
Epoch 0, Step 643: train/loss = 0.07924553751945496, train/raw-loss = 0.015822533518075943, train/logprobs = tensor([[ -1.2407, -10.5818],
        [ -5.5055,  -3.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6342300176620483
Epoch 0, Step 644: train/loss = 0.08605682104825974, train/raw-loss = 0.010826203040778637, train/logprobs = tensor([[ -1.3922, -12.5871],
        [ -5.9442,  -2.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7523061633110046
Epoch 0, Step 645: train/loss = 0.07383779436349869, train/raw-loss = 0.0076010627672076225, train/logprobs = tensor([[ -1.4348, -13.9706],
        [ -6.6328,  -2.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6623672842979431
Epoch 0, Step 646: train/loss = 0.08078722655773163, train/raw-loss = 0.0028087079990655184, train/logprobs = tensor([[ -1.9365, -13.7026],
        [ -8.0571,  -2.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7797850966453552
Epoch 0, Step 647: train/loss = 0.07264559715986252, train/raw-loss = 0.008540498092770576, train/logprobs = tensor([[ -1.2670, -12.9179],
        [ -5.5165,  -3.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6410509347915649
Epoch 0, Step 648: train/loss = 0.08648555725812912, train/raw-loss = 0.014851965010166168, train/logprobs = tensor([[ -1.4833, -12.8671],
        [ -6.9415,  -3.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7163358926773071
Epoch 0, Step 649: train/loss = 0.07109120488166809, train/raw-loss = 0.002641181228682399, train/logprobs = tensor([[ -2.7766, -12.8055],
        [ -9.0514,  -1.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6845001578330994
Epoch 0, Step 650: train/loss = 0.07384859025478363, train/raw-loss = 0.0026447318959981203, train/logprobs = tensor([[ -1.9075, -10.8944],
        [ -8.3324,  -2.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.712038516998291
Epoch 0, Step 651: train/loss = 0.08827763795852661, train/raw-loss = 0.009870963171124458, train/logprobs = tensor([[-1.4068, -8.6642],
        [-7.0555, -2.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7840667963027954
Epoch 0, Step 652: train/loss = 0.08651610463857651, train/raw-loss = 0.014377512037754059, train/logprobs = tensor([[ -1.4586, -15.3512],
        [ -6.5720,  -1.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7213859558105469
Epoch 0, Step 653: train/loss = 0.07989126443862915, train/raw-loss = 0.0030998955480754375, train/logprobs = tensor([[ -1.7923, -10.3080],
        [ -7.8149,  -1.4943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7679136991500854
Epoch 0, Step 654: train/loss = 0.07991188764572144, train/raw-loss = 0.0009040180593729019, train/logprobs = tensor([[ -1.9697, -14.9007],
        [ -9.5698,  -3.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7900786399841309
Epoch 0, Step 655: train/loss = 0.07953482866287231, train/raw-loss = 0.011565223336219788, train/logprobs = tensor([[-1.6803, -8.7314],
        [-6.8352, -2.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6796960234642029
Epoch 0, Step 656: train/loss = 0.11701856553554535, train/raw-loss = 0.02611924707889557, train/logprobs = tensor([[ -1.8998, -13.0101],
        [ -6.5872,  -2.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9089931845664978
Epoch 0, Step 657: train/loss = 0.07820438593626022, train/raw-loss = 0.005633924156427383, train/logprobs = tensor([[ -1.7844, -15.7765],
        [ -7.6994,  -3.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7257046103477478
Epoch 0, Step 658: train/loss = 0.07661255449056625, train/raw-loss = 0.008975792676210403, train/logprobs = tensor([[ -1.1686, -15.5081],
        [ -6.0994,  -3.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6763675808906555
Epoch 0, Step 659: train/loss = 0.08129192143678665, train/raw-loss = 0.010580262169241905, train/logprobs = tensor([[ -1.4539, -12.0973],
        [ -6.4766,  -3.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7071166038513184
Epoch 0, Step 660: train/loss = 0.1920250505208969, train/raw-loss = 0.11921925842761993, train/logprobs = tensor([[-2.2683, -8.5620],
        [-6.8543, -2.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.728057861328125
Epoch 0, Step 661: train/loss = 0.09207497537136078, train/raw-loss = 0.014016938395798206, train/logprobs = tensor([[ -1.9443, -13.2686],
        [ -7.0485,  -3.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7805804014205933
Epoch 0, Step 662: train/loss = 0.11592933535575867, train/raw-loss = 0.047300923615694046, train/logprobs = tensor([[ -1.0811, -11.4714],
        [ -6.0486,  -2.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6862841844558716
Epoch 0, Step 663: train/loss = 0.07848865538835526, train/raw-loss = 0.001874151872470975, train/logprobs = tensor([[ -1.5457, -12.4163],
        [ -7.5701,  -2.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7661450505256653
Epoch 0, Step 664: train/loss = 0.13627466559410095, train/raw-loss = 0.07165379077196121, train/logprobs = tensor([[ -1.7758, -10.9615],
        [ -5.2638,  -2.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6462087631225586
Epoch 0, Step 665: train/loss = 0.08045460283756256, train/raw-loss = 0.0033126650378108025, train/logprobs = tensor([[ -1.7401, -10.5269],
        [ -7.3919,  -2.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.77141934633255
Epoch 0, Step 666: train/loss = 0.07491320371627808, train/raw-loss = 0.006705080159008503, train/logprobs = tensor([[ -1.3338, -10.9798],
        [ -7.3149,  -1.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6820812821388245
Epoch 0, Step 667: train/loss = 0.08249963819980621, train/raw-loss = 0.011146615259349346, train/logprobs = tensor([[-2.2497, -9.4264],
        [-6.7810, -2.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7135301828384399
Epoch 0, Step 668: train/loss = 0.08175569027662277, train/raw-loss = 0.0038080797530710697, train/logprobs = tensor([[ -1.4380, -12.9263],
        [ -8.1023,  -1.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7794761061668396
Epoch 0, Step 669: train/loss = 0.08772183954715729, train/raw-loss = 0.01448940858244896, train/logprobs = tensor([[ -1.6565, -11.9780],
        [ -7.2338,  -3.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7323243021965027
Epoch 0, Step 670: train/loss = 0.26917266845703125, train/raw-loss = 0.19790558516979218, train/logprobs = tensor([[ -2.3902, -11.4830],
        [ -6.6832,  -3.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7126708030700684
Epoch 0, Step 671: train/loss = 0.0793476551771164, train/raw-loss = 0.0063074855133891106, train/logprobs = tensor([[ -1.6098, -11.7271],
        [ -6.4344,  -2.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7304016351699829
Epoch 0, Step 672: train/loss = 0.06833382695913315, train/raw-loss = 0.007648443337529898, train/logprobs = tensor([[ -0.8631, -15.1572],
        [ -5.8759,  -5.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6068538427352905
Epoch 0, Step 673: train/loss = 0.07268305122852325, train/raw-loss = 0.001752470270730555, train/logprobs = tensor([[ -1.2798, -11.8273],
        [ -7.5469,  -3.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7093057632446289
Epoch 0, Step 674: train/loss = 0.06499689817428589, train/raw-loss = 0.002028315095230937, train/logprobs = tensor([[ -1.8092, -16.4275],
        [ -7.3170,  -3.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6296858787536621
Epoch 0, Step 675: train/loss = 0.09277251362800598, train/raw-loss = 0.028131786733865738, train/logprobs = tensor([[-1.4814, -9.0987],
        [-6.2621, -1.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6464073061943054
Epoch 0, Step 676: train/loss = 0.08106400072574615, train/raw-loss = 0.0124057000502944, train/logprobs = tensor([[ -1.7503, -10.0193],
        [ -6.5851,  -2.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6865829825401306
Epoch 0, Step 677: train/loss = 0.30343055725097656, train/raw-loss = 0.23632404208183289, train/logprobs = tensor([[ -3.1715, -13.7705],
        [ -6.9309,  -3.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6710653305053711
Epoch 0, Step 678: train/loss = 0.07128426432609558, train/raw-loss = 0.007430581841617823, train/logprobs = tensor([[ -1.7024, -11.3730],
        [ -8.2834,  -2.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.638536810874939
Epoch 0, Step 679: train/loss = 0.07263442128896713, train/raw-loss = 0.008266031742095947, train/logprobs = tensor([[ -1.0516, -10.2894],
        [ -5.9552,  -2.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.643683910369873
Epoch 0, Step 680: train/loss = 0.07705267518758774, train/raw-loss = 0.0025685089640319347, train/logprobs = tensor([[ -1.3798, -14.9754],
        [ -7.7262,  -3.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7448416948318481
Epoch 0, Step 681: train/loss = 0.11595425754785538, train/raw-loss = 0.047049328684806824, train/logprobs = tensor([[ -3.4528, -12.4156],
        [ -6.7193,  -2.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6890493035316467
Epoch 0, Step 682: train/loss = 0.07730497419834137, train/raw-loss = 0.00853407196700573, train/logprobs = tensor([[ -1.1142, -13.9913],
        [ -7.6950,  -4.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6877090930938721
Epoch 0, Step 683: train/loss = 0.08150765299797058, train/raw-loss = 0.008373135700821877, train/logprobs = tensor([[ -1.8872, -12.1718],
        [ -6.6431,  -3.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7313451766967773
Epoch 0, Step 684: train/loss = 0.06927165389060974, train/raw-loss = 0.007854585535824299, train/logprobs = tensor([[ -1.4928, -14.4198],
        [ -7.6891,  -3.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6141707301139832
Epoch 0, Step 685: train/loss = 0.07678139954805374, train/raw-loss = 0.003336569294333458, train/logprobs = tensor([[ -2.3534, -12.1856],
        [ -8.9257,  -3.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.734448254108429
Epoch 0, Step 686: train/loss = 0.07470183074474335, train/raw-loss = 0.0203065425157547, train/logprobs = tensor([[-1.0918, -9.9756],
        [-5.0969, -1.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5439528822898865
Epoch 0, Step 687: train/loss = 0.09776871651411057, train/raw-loss = 0.020753301680088043, train/logprobs = tensor([[-1.5059, -9.4288],
        [-7.2945, -1.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7701541185379028
Epoch 0, Step 688: train/loss = 0.0780802071094513, train/raw-loss = 0.008004824630916119, train/logprobs = tensor([[ -1.9289, -12.3422],
        [ -7.2427,  -4.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7007538676261902
Epoch 0, Step 689: train/loss = 0.06916413456201553, train/raw-loss = 0.0034640140365809202, train/logprobs = tensor([[ -1.7713, -11.1375],
        [ -8.3618,  -1.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6570011377334595
Epoch 0, Step 690: train/loss = 0.07693879306316376, train/raw-loss = 0.00788885448127985, train/logprobs = tensor([[ -1.8724, -12.0978],
        [ -6.9163,  -3.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6904993653297424
Epoch 0, Step 691: train/loss = 0.07192941009998322, train/raw-loss = 0.011846968904137611, train/logprobs = tensor([[ -1.4917, -11.2567],
        [ -5.7643,  -2.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6008244156837463
Epoch 0, Step 692: train/loss = 0.07874122262001038, train/raw-loss = 0.011991119012236595, train/logprobs = tensor([[ -2.0651, -12.3622],
        [ -7.8438,  -2.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6675010323524475
Epoch 0, Step 693: train/loss = 0.07687119394540787, train/raw-loss = 0.014328636229038239, train/logprobs = tensor([[ -1.1177, -11.4548],
        [ -5.5838,  -3.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6254255771636963
Epoch 0, Step 694: train/loss = 0.0644950270652771, train/raw-loss = 0.0054955631494522095, train/logprobs = tensor([[ -1.2452, -13.5259],
        [ -6.6006,  -2.2490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5899945497512817
Epoch 0, Step 695: train/loss = 0.08010586351156235, train/raw-loss = 0.0004941786173731089, train/logprobs = tensor([[ -1.7315, -12.3517],
        [ -9.7242,  -3.2608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.796116828918457
Epoch 0, Step 696: train/loss = 0.07241565734148026, train/raw-loss = 0.010619882494211197, train/logprobs = tensor([[-1.5068, -7.1414],
        [-6.2259, -1.2530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6179577112197876
Epoch 0, Step 697: train/loss = 0.14651831984519958, train/raw-loss = 0.07796678692102432, train/logprobs = tensor([[ -1.3485, -14.1339],
        [ -8.0018,  -4.0820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6855154037475586
Epoch 0, Step 698: train/loss = 0.07606825232505798, train/raw-loss = 0.004071541130542755, train/logprobs = tensor([[ -1.7519, -10.0877],
        [ -7.2543,  -2.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7199670672416687
Epoch 0, Step 699: train/loss = 0.0857657641172409, train/raw-loss = 0.010207717306911945, train/logprobs = tensor([[ -1.6675, -11.1651],
        [ -7.3415,  -1.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.755580484867096
Epoch 0, Step 700: train/loss = 0.10245630890130997, train/raw-loss = 0.029797520488500595, train/logprobs = tensor([[ -1.6736, -11.9835],
        [ -8.0950,  -3.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7265878319740295
Epoch 0, Step 701: train/loss = 0.07695326209068298, train/raw-loss = 0.005676801782101393, train/logprobs = tensor([[ -1.5607, -10.2299],
        [ -6.9023,  -2.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7127646207809448
Epoch 0, Step 702: train/loss = 0.07318280637264252, train/raw-loss = 0.005317986011505127, train/logprobs = tensor([[ -1.4956, -10.4078],
        [ -8.1620,  -2.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6786481738090515
Epoch 0, Step 703: train/loss = 0.12138982117176056, train/raw-loss = 0.05666372925043106, train/logprobs = tensor([[ -1.4493, -10.6005],
        [ -6.5215,  -3.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.647260844707489
Epoch 0, Step 704: train/loss = 0.06622005999088287, train/raw-loss = 0.005284612067043781, train/logprobs = tensor([[ -1.4257, -11.6409],
        [ -6.5582,  -2.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6093544960021973
Epoch 0, Step 705: train/loss = 0.12059607356786728, train/raw-loss = 0.06439308077096939, train/logprobs = tensor([[ -2.1458, -15.1253],
        [ -6.3143,  -2.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5620298385620117
Epoch 0, Step 706: train/loss = 0.06834463775157928, train/raw-loss = 0.003376617329195142, train/logprobs = tensor([[ -1.3136, -13.0769],
        [ -7.3940,  -3.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6496801972389221
Epoch 0, Step 707: train/loss = 0.0778263583779335, train/raw-loss = 0.0008630072115920484, train/logprobs = tensor([[ -1.9223, -13.6501],
        [ -9.4355,  -2.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7696335315704346
Epoch 0, Step 708: train/loss = 0.08009317517280579, train/raw-loss = 0.016044193878769875, train/logprobs = tensor([[ -1.5432, -14.2981],
        [ -6.0118,  -3.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6404898166656494
Epoch 0, Step 709: train/loss = 0.0781683698296547, train/raw-loss = 0.008576564490795135, train/logprobs = tensor([[ -1.3451, -14.9986],
        [ -8.5598,  -3.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6959180235862732
Epoch 0, Step 710: train/loss = 0.07088644802570343, train/raw-loss = 0.005959419533610344, train/logprobs = tensor([[ -1.6221, -13.9729],
        [ -6.9243,  -2.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6492702960968018
Epoch 0, Step 711: train/loss = 0.0641922801733017, train/raw-loss = 0.008564510382711887, train/logprobs = tensor([[ -1.1235, -11.5762],
        [ -6.3860,  -2.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5562776923179626
Epoch 0, Step 712: train/loss = 0.06140635907649994, train/raw-loss = 0.008247547782957554, train/logprobs = tensor([[ -1.5434, -14.1984],
        [ -6.9205,  -2.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5315881371498108
Epoch 0, Step 713: train/loss = 0.0672496110200882, train/raw-loss = 0.0011562617728486657, train/logprobs = tensor([[ -1.7688, -10.7823],
        [ -9.5988,  -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6609334349632263
Epoch 0, Step 714: train/loss = 0.08465716987848282, train/raw-loss = 0.005830588284879923, train/logprobs = tensor([[ -1.5943, -12.0518],
        [ -8.2120,  -2.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7882658243179321
Epoch 0, Step 715: train/loss = 0.06640349328517914, train/raw-loss = 0.0043348995968699455, train/logprobs = tensor([[ -1.0075, -14.4209],
        [ -7.6915,  -3.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6206859350204468
Epoch 0, Step 716: train/loss = 0.13035298883914948, train/raw-loss = 0.0705803632736206, train/logprobs = tensor([[-1.5873, -9.5733],
        [-6.8762, -3.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5977262258529663
Epoch 0, Step 717: train/loss = 0.06958524137735367, train/raw-loss = 0.0032381233759224415, train/logprobs = tensor([[-2.0961, -8.8770],
        [-9.9883, -2.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6634711623191833
Epoch 0, Step 718: train/loss = 0.08334993571043015, train/raw-loss = 0.01580425351858139, train/logprobs = tensor([[ -2.0296, -10.8148],
        [ -7.7096,  -2.5185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6754568219184875
Epoch 0, Step 719: train/loss = 0.06875018775463104, train/raw-loss = 0.00904394406825304, train/logprobs = tensor([[ -1.5214, -12.5474],
        [ -6.5374,  -3.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5970624685287476
Epoch 0, Step 720: train/loss = 0.07464219629764557, train/raw-loss = 0.01917048916220665, train/logprobs = tensor([[ -2.0641, -12.5718],
        [ -7.9535,  -2.4703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5547170639038086
Epoch 0, Step 721: train/loss = 0.06205859035253525, train/raw-loss = 0.003556899493560195, train/logprobs = tensor([[ -1.7154, -11.5620],
        [ -7.8562,  -2.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5850169062614441
Epoch 0, Step 722: train/loss = 0.08939149975776672, train/raw-loss = 0.025705551728606224, train/logprobs = tensor([[ -1.8696, -10.2256],
        [ -8.1903,  -3.2026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6368594765663147
Epoch 0, Step 723: train/loss = 0.11777649819850922, train/raw-loss = 0.0688859224319458, train/logprobs = tensor([[ -2.2305, -10.6105],
        [ -4.6806,  -1.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48890578746795654
Epoch 0, Step 724: train/loss = 0.22708484530448914, train/raw-loss = 0.1674427092075348, train/logprobs = tensor([[ -1.3575, -12.5245],
        [ -6.6057,  -2.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5964212417602539
Epoch 0, Step 725: train/loss = 0.11663845181465149, train/raw-loss = 0.04433561488986015, train/logprobs = tensor([[-1.8841, -7.5907],
        [-7.6660, -3.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7230284214019775
Epoch 0, Step 726: train/loss = 0.2165987342596054, train/raw-loss = 0.1605062633752823, train/logprobs = tensor([[ -1.7616, -14.7187],
        [ -5.0671,  -2.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5609246492385864
Epoch 0, Step 727: train/loss = 0.06585829704999924, train/raw-loss = 0.0017234322149306536, train/logprobs = tensor([[ -1.6940, -12.8746],
        [ -9.2644,  -2.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.641348659992218
Epoch 0, Step 728: train/loss = 0.06574482470750809, train/raw-loss = 0.011371439322829247, train/logprobs = tensor([[ -1.5586, -11.1153],
        [ -7.5806,  -2.7952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5437338352203369
Epoch 0, Step 729: train/loss = 0.0666128545999527, train/raw-loss = 0.0043949862010777, train/logprobs = tensor([[ -1.3137, -13.7984],
        [ -8.0650,  -2.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6221786737442017
Epoch 0, Step 730: train/loss = 0.06126908212900162, train/raw-loss = 0.004698479548096657, train/logprobs = tensor([[ -1.3423, -13.1272],
        [ -7.0210,  -3.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5657060742378235
Epoch 0, Step 731: train/loss = 0.07014834135770798, train/raw-loss = 0.001876892987638712, train/logprobs = tensor([[ -1.6533, -14.4723],
        [ -9.8499,  -3.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6827144622802734
Epoch 0, Step 732: train/loss = 0.07227238267660141, train/raw-loss = 0.009949179366230965, train/logprobs = tensor([[-1.2708, -9.8794],
        [-6.7855, -2.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6232320666313171
Epoch 0, Step 733: train/loss = 0.06468300521373749, train/raw-loss = 0.001354151638224721, train/logprobs = tensor([[ -1.9852, -17.4109],
        [ -8.0145,  -3.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.633288562297821
Epoch 0, Step 734: train/loss = 0.07093657553195953, train/raw-loss = 0.007963002659380436, train/logprobs = tensor([[ -1.3732, -12.6467],
        [ -6.0543,  -2.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6297357082366943
Epoch 0, Step 735: train/loss = 0.37814873456954956, train/raw-loss = 0.31791239976882935, train/logprobs = tensor([[-2.0667, -9.7478],
        [-5.4501, -2.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6023633480072021
Epoch 0, Step 736: train/loss = 0.19527429342269897, train/raw-loss = 0.13144397735595703, train/logprobs = tensor([[ -2.9381, -11.4329],
        [ -6.3009,  -2.3132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.638303279876709
Epoch 0, Step 737: train/loss = 0.07589288055896759, train/raw-loss = 0.015179285779595375, train/logprobs = tensor([[-1.3478, -8.7914],
        [-6.7703, -2.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6071358919143677
Epoch 0, Step 738: train/loss = 0.08433789014816284, train/raw-loss = 0.021120168268680573, train/logprobs = tensor([[-1.9352, -7.7632],
        [-6.8942, -2.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6321771740913391
Epoch 0, Step 739: train/loss = 0.07170815765857697, train/raw-loss = 0.012144707143306732, train/logprobs = tensor([[-1.6486, -9.3981],
        [-7.0329, -2.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5956345200538635
Epoch 0, Step 740: train/loss = 0.0684598982334137, train/raw-loss = 0.0012329232413321733, train/logprobs = tensor([[ -1.5964, -11.3407],
        [ -9.7496,  -2.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6722698211669922
Epoch 0, Step 741: train/loss = 0.06276477873325348, train/raw-loss = 0.0020725687500089407, train/logprobs = tensor([[ -1.8840, -12.5024],
        [ -8.4566,  -1.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6069220900535583
Epoch 0, Step 742: train/loss = 0.05758020654320717, train/raw-loss = 0.002144887810572982, train/logprobs = tensor([[ -1.4867, -12.1811],
        [ -7.4495,  -2.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5543531775474548
Epoch 0, Step 743: train/loss = 0.06389255076646805, train/raw-loss = 0.007531233597546816, train/logprobs = tensor([[ -1.2888, -14.9875],
        [ -6.6663,  -2.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5636131763458252
Epoch 0, Step 744: train/loss = 0.07205134630203247, train/raw-loss = 0.014097788371145725, train/logprobs = tensor([[ -1.2992, -13.4446],
        [ -5.5926,  -1.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5795355439186096
Epoch 0, Step 745: train/loss = 0.10763983428478241, train/raw-loss = 0.047618135809898376, train/logprobs = tensor([[-1.0178, -9.3226],
        [-6.3956, -2.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6002169251441956
Epoch 0, Step 746: train/loss = 0.07057124376296997, train/raw-loss = 0.010195954702794552, train/logprobs = tensor([[ -1.7959, -12.4067],
        [ -7.8289,  -3.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.603752851486206
Epoch 0, Step 747: train/loss = 0.07112833112478256, train/raw-loss = 0.005439706612378359, train/logprobs = tensor([[ -1.4089, -11.1096],
        [ -7.5287,  -3.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6568862199783325
Epoch 0, Step 748: train/loss = 0.07698222994804382, train/raw-loss = 0.012521512806415558, train/logprobs = tensor([[-1.7659, -9.3446],
        [-7.2062, -2.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6446071863174438
Epoch 0, Step 749: train/loss = 0.08421096205711365, train/raw-loss = 0.026708049699664116, train/logprobs = tensor([[ -1.9998, -12.6031],
        [ -6.3664,  -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5750291347503662
Epoch 0, Step 750: train/loss = 0.07748313993215561, train/raw-loss = 0.0245202723890543, train/logprobs = tensor([[ -1.1649, -10.2905],
        [ -5.1798,  -2.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5296286344528198
Epoch 0, Step 751: train/loss = 0.09095431864261627, train/raw-loss = 0.033541012555360794, train/logprobs = tensor([[ -1.4185, -11.4294],
        [ -6.1062,  -3.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.574133038520813
Epoch 0, Step 752: train/loss = 0.10491418838500977, train/raw-loss = 0.05136570706963539, train/logprobs = tensor([[ -1.6447, -11.5738],
        [ -5.6435,  -2.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.535484790802002
Epoch 0, Step 753: train/loss = 0.06203895062208176, train/raw-loss = 0.0010629622265696526, train/logprobs = tensor([[ -2.1032, -17.8710],
        [ -8.9420,  -1.7266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6097598671913147
Epoch 0, Step 754: train/loss = 0.06059101223945618, train/raw-loss = 0.008135880343616009, train/logprobs = tensor([[ -1.1449, -16.6387],
        [ -6.5011,  -3.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.524551272392273
Epoch 0, Step 755: train/loss = 0.07504081726074219, train/raw-loss = 0.01073300838470459, train/logprobs = tensor([[-1.7041, -9.5733],
        [-6.9914, -2.3993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6430781483650208
Epoch 0, Step 756: train/loss = 0.076290562748909, train/raw-loss = 0.0027171296533197165, train/logprobs = tensor([[ -1.9339, -11.8523],
        [ -8.0504,  -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7357343435287476
Epoch 0, Step 757: train/loss = 0.06645606458187103, train/raw-loss = 0.004636833444237709, train/logprobs = tensor([[ -1.0856, -11.5126],
        [ -6.5883,  -2.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6181922554969788
Epoch 0, Step 758: train/loss = 0.08301275223493576, train/raw-loss = 0.02761882171034813, train/logprobs = tensor([[-1.5242, -7.9552],
        [-6.9211, -1.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5539392828941345
Epoch 0, Step 759: train/loss = 0.06087065488100052, train/raw-loss = 0.003906438127160072, train/logprobs = tensor([[ -1.6058, -12.7563],
        [ -8.1692,  -2.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.569642186164856
Epoch 0, Step 760: train/loss = 0.07631020992994308, train/raw-loss = 0.028300907462835312, train/logprobs = tensor([[ -1.2405, -11.1600],
        [ -5.7597,  -1.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48009300231933594
Epoch 0, Step 761: train/loss = 0.058680210262537, train/raw-loss = 0.002715440932661295, train/logprobs = tensor([[ -1.9925, -11.7127],
        [ -9.1881,  -3.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5596476793289185
Epoch 0, Step 762: train/loss = 0.06876425445079803, train/raw-loss = 0.007558016572147608, train/logprobs = tensor([[ -1.7192, -10.3974],
        [ -6.5456,  -2.2552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6120623350143433
Epoch 0, Step 763: train/loss = 0.1077091321349144, train/raw-loss = 0.053655970841646194, train/logprobs = tensor([[ -1.7498, -14.4362],
        [ -5.1117,  -1.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5405316352844238
Epoch 0, Step 764: train/loss = 0.08059006929397583, train/raw-loss = 0.009190542623400688, train/logprobs = tensor([[ -2.2556, -10.7854],
        [ -6.9415,  -3.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7139952182769775
Epoch 0, Step 765: train/loss = 0.06619490683078766, train/raw-loss = 0.0013486237730830908, train/logprobs = tensor([[ -1.4348, -17.9343],
        [ -8.1543,  -4.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6484628319740295
Epoch 0, Step 766: train/loss = 0.07297809422016144, train/raw-loss = 0.006069879047572613, train/logprobs = tensor([[-1.4481, -8.0761],
        [-7.0752, -1.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6690821051597595
Epoch 0, Step 767: train/loss = 0.5775091648101807, train/raw-loss = 0.5220611691474915, train/logprobs = tensor([[ -3.7232, -13.2386],
        [ -6.6368,  -3.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5544800758361816
Epoch 0, Step 768: train/loss = 0.07244306802749634, train/raw-loss = 0.025083934888243675, train/logprobs = tensor([[-1.1681, -7.4597],
        [-6.0546, -2.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47359129786491394
Epoch 0, Step 769: train/loss = 0.061674345284700394, train/raw-loss = 0.008175433613359928, train/logprobs = tensor([[ -1.5185, -14.6330],
        [ -7.2340,  -2.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5349891185760498
Epoch 0, Step 770: train/loss = 0.06533300876617432, train/raw-loss = 0.012084851041436195, train/logprobs = tensor([[ -1.2860, -16.5794],
        [ -5.7807,  -2.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5324816107749939
Epoch 0, Step 771: train/loss = 0.06358837336301804, train/raw-loss = 0.003193862736225128, train/logprobs = tensor([[ -1.5905, -12.4705],
        [ -8.2631,  -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6039450764656067
Epoch 0, Step 772: train/loss = 0.09878340363502502, train/raw-loss = 0.04849695786833763, train/logprobs = tensor([[-1.3225, -8.0240],
        [-5.3766, -3.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.502864420413971
Epoch 0, Step 773: train/loss = 0.06540417671203613, train/raw-loss = 0.005071025341749191, train/logprobs = tensor([[ -1.7168, -12.4520],
        [ -8.1915,  -2.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6033315062522888
Epoch 0, Step 774: train/loss = 0.06475658714771271, train/raw-loss = 0.005309144034981728, train/logprobs = tensor([[ -1.5340, -11.0597],
        [ -7.1596,  -2.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5944744944572449
Epoch 0, Step 775: train/loss = 0.06308875232934952, train/raw-loss = 0.005357202608138323, train/logprobs = tensor([[ -1.2666, -14.2898],
        [ -7.0576,  -3.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5773154497146606
Epoch 0, Step 776: train/loss = 0.0639636293053627, train/raw-loss = 0.014881015755236149, train/logprobs = tensor([[-0.8269, -9.9893],
        [-5.9073, -2.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4908261001110077
Epoch 0, Step 777: train/loss = 0.0601980984210968, train/raw-loss = 0.0052432771772146225, train/logprobs = tensor([[ -1.8702, -14.0192],
        [ -7.0041,  -2.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5495481491088867
Epoch 0, Step 778: train/loss = 0.08040100336074829, train/raw-loss = 0.020419225096702576, train/logprobs = tensor([[-1.4003, -9.9977],
        [-6.7117, -2.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5998178124427795
Epoch 0, Step 779: train/loss = 0.06662565469741821, train/raw-loss = 0.007744384463876486, train/logprobs = tensor([[ -1.6030, -14.7839],
        [ -6.6219,  -2.5718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5888127088546753
Epoch 0, Step 780: train/loss = 0.18670779466629028, train/raw-loss = 0.13774894177913666, train/logprobs = tensor([[ -1.0975, -11.5381],
        [ -6.3480,  -1.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4895884394645691
Epoch 0, Step 781: train/loss = 0.06185627356171608, train/raw-loss = 0.004619169048964977, train/logprobs = tensor([[ -2.0127, -15.7163],
        [ -8.1548,  -1.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5723710656166077
Epoch 0, Step 782: train/loss = 0.06263499706983566, train/raw-loss = 0.009442351758480072, train/logprobs = tensor([[ -1.2603, -14.2851],
        [ -6.3567,  -2.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5319263935089111
Epoch 0, Step 783: train/loss = 0.08363878726959229, train/raw-loss = 0.02815300226211548, train/logprobs = tensor([[ -1.3364, -12.8885],
        [ -6.6164,  -2.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5548577904701233
Epoch 0, Step 784: train/loss = 0.07575932890176773, train/raw-loss = 0.011916293762624264, train/logprobs = tensor([[ -2.3189, -10.6758],
        [ -9.4177,  -2.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6384303569793701
Epoch 0, Step 785: train/loss = 0.06844579428434372, train/raw-loss = 0.016316425055265427, train/logprobs = tensor([[ -0.9394, -13.1983],
        [ -5.1814,  -2.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5212936401367188
Epoch 0, Step 786: train/loss = 0.05844300612807274, train/raw-loss = 0.007899776101112366, train/logprobs = tensor([[ -1.2580, -16.6135],
        [ -6.3310,  -2.6763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5054322481155396
Epoch 0, Step 787: train/loss = 0.06320879608392715, train/raw-loss = 0.004538901150226593, train/logprobs = tensor([[ -2.6222, -11.3980],
        [ -8.5867,  -2.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5866990089416504
Epoch 0, Step 788: train/loss = 0.11968132853507996, train/raw-loss = 0.06386019289493561, train/logprobs = tensor([[ -1.9100, -11.8919],
        [ -6.6253,  -2.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5582113862037659
Epoch 0, Step 789: train/loss = 0.062378257513046265, train/raw-loss = 0.008269233629107475, train/logprobs = tensor([[ -1.1507, -12.6035],
        [ -7.0367,  -1.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5410902500152588
Epoch 0, Step 790: train/loss = 0.07248735427856445, train/raw-loss = 0.0055919853039085865, train/logprobs = tensor([[ -2.1038, -11.8974],
        [ -9.3940,  -1.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6689537167549133
Epoch 0, Step 791: train/loss = 0.08930239826440811, train/raw-loss = 0.024968063458800316, train/logprobs = tensor([[ -1.6263, -11.5368],
        [ -9.1522,  -2.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6433433294296265
Epoch 0, Step 792: train/loss = 0.16338342428207397, train/raw-loss = 0.11123248189687729, train/logprobs = tensor([[ -0.8791, -10.9561],
        [ -5.1451,  -3.0295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5215092897415161
Epoch 0, Step 793: train/loss = 0.06809987872838974, train/raw-loss = 0.011534053832292557, train/logprobs = tensor([[ -2.3679, -11.7806],
        [ -6.5425,  -2.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5656582117080688
Epoch 0, Step 794: train/loss = 0.06449315696954727, train/raw-loss = 0.0011756407329812646, train/logprobs = tensor([[-1.9810, -9.7458],
        [-9.5461, -1.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6331751346588135
Epoch 0, Step 795: train/loss = 0.05127142369747162, train/raw-loss = 0.002668980276212096, train/logprobs = tensor([[ -1.2961, -12.2854],
        [ -8.3537,  -3.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4860244691371918
Epoch 0, Step 796: train/loss = 0.06969113647937775, train/raw-loss = 0.008193690329790115, train/logprobs = tensor([[ -1.6238, -12.4985],
        [ -7.0796,  -2.3422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6149744391441345
Epoch 0, Step 797: train/loss = 0.07640951871871948, train/raw-loss = 0.016622815281152725, train/logprobs = tensor([[-1.4272, -9.6152],
        [-7.4971, -3.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5978670120239258
Epoch 0, Step 798: train/loss = 0.06448911875486374, train/raw-loss = 0.007296374067664146, train/logprobs = tensor([[ -1.7366, -14.0667],
        [ -6.6516,  -1.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5719274282455444
Epoch 0, Step 799: train/loss = 0.07199066877365112, train/raw-loss = 0.003706518094986677, train/logprobs = tensor([[ -1.4956, -12.1576],
        [ -8.2070,  -2.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.682841420173645
Epoch 0, Step 800: train/loss = 0.0547587126493454, train/raw-loss = 0.008345311507582664, train/logprobs = tensor([[ -1.2050, -12.8546],
        [ -5.8638,  -2.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4641340374946594
Epoch 0, Step 801: train/loss = 0.06203678250312805, train/raw-loss = 0.009676768444478512, train/logprobs = tensor([[ -1.7444, -12.0731],
        [ -8.0602,  -0.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.523600161075592
Epoch 0, Step 802: train/loss = 0.06244340538978577, train/raw-loss = 0.008691939525306225, train/logprobs = tensor([[ -1.9681, -11.2159],
        [ -8.0991,  -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5375146865844727
Epoch 0, Step 803: train/loss = 0.06070182844996452, train/raw-loss = 0.012230779975652695, train/logprobs = tensor([[ -1.1340, -11.4821],
        [ -6.1985,  -2.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4847104549407959
Epoch 0, Step 804: train/loss = 0.05965612083673477, train/raw-loss = 0.006603627931326628, train/logprobs = tensor([[-1.5880, -9.2435],
        [-7.4862, -2.6147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5305249094963074
Epoch 0, Step 805: train/loss = 0.10948917269706726, train/raw-loss = 0.05420002341270447, train/logprobs = tensor([[-1.1898, -7.3558],
        [-5.1835, -3.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5528913736343384
Epoch 0, Step 806: train/loss = 0.09498833119869232, train/raw-loss = 0.048883114010095596, train/logprobs = tensor([[ -1.0723, -10.5578],
        [ -5.8842,  -2.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4610522389411926
Epoch 0, Step 807: train/loss = 0.07421865314245224, train/raw-loss = 0.012079937383532524, train/logprobs = tensor([[-1.7713, -8.8471],
        [-9.5407, -2.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6213871240615845
Epoch 0, Step 808: train/loss = 0.07386492192745209, train/raw-loss = 0.027468353509902954, train/logprobs = tensor([[ -1.9310, -12.3614],
        [ -7.0207,  -1.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46396565437316895
Epoch 0, Step 809: train/loss = 0.05671660602092743, train/raw-loss = 0.0014176140539348125, train/logprobs = tensor([[ -1.7528, -14.7589],
        [ -8.2535,  -3.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5529899597167969
Epoch 0, Step 810: train/loss = 0.05977177247405052, train/raw-loss = 0.009196151979267597, train/logprobs = tensor([[ -1.5553, -10.7239],
        [ -6.4717,  -2.7160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5057561993598938
Epoch 0, Step 811: train/loss = 0.058561816811561584, train/raw-loss = 0.009614722803235054, train/logprobs = tensor([[ -1.8441, -10.5931],
        [ -7.0852,  -2.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.489470899105072
Epoch 0, Step 812: train/loss = 0.05686149373650551, train/raw-loss = 0.0012581252958625555, train/logprobs = tensor([[ -1.2391, -12.6894],
        [ -7.9873,  -1.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5560336709022522
Epoch 0, Step 813: train/loss = 0.06749441474676132, train/raw-loss = 0.012060444802045822, train/logprobs = tensor([[ -1.6451, -11.7093],
        [ -7.4746,  -3.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5543396472930908
Epoch 0, Step 814: train/loss = 0.056190866976976395, train/raw-loss = 0.0049862186424434185, train/logprobs = tensor([[ -1.2146, -13.6926],
        [ -6.9906,  -2.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5120464563369751
Epoch 0, Step 815: train/loss = 0.07020780444145203, train/raw-loss = 0.005887347273528576, train/logprobs = tensor([[ -1.3731, -11.3393],
        [ -7.3463,  -1.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6432045698165894
Epoch 0, Step 816: train/loss = 0.055377062410116196, train/raw-loss = 0.0005664562340825796, train/logprobs = tensor([[ -1.3393, -12.2941],
        [ -8.5288,  -2.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5481060743331909
Epoch 0, Step 817: train/loss = 0.06095166504383087, train/raw-loss = 0.005412777420133352, train/logprobs = tensor([[ -1.3256, -13.3492],
        [ -7.2119,  -2.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.555388867855072
Epoch 0, Step 818: train/loss = 0.06835797429084778, train/raw-loss = 0.02042210102081299, train/logprobs = tensor([[ -0.8553, -10.3937],
        [ -5.3184,  -2.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4793587028980255
Epoch 0, Step 819: train/loss = 0.052509356290102005, train/raw-loss = 0.009760242886841297, train/logprobs = tensor([[ -0.7720, -10.4829],
        [ -5.4282,  -2.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42749112844467163
Epoch 0, Step 820: train/loss = 0.0634041279554367, train/raw-loss = 0.011916326358914375, train/logprobs = tensor([[ -0.9926, -11.2485],
        [ -5.1843,  -2.2371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5148780345916748
Epoch 0, Step 821: train/loss = 0.04988865926861763, train/raw-loss = 0.004054649733006954, train/logprobs = tensor([[ -1.1137, -13.7552],
        [ -6.7429,  -2.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4583400785923004
Epoch 0, Step 822: train/loss = 0.057932931929826736, train/raw-loss = 0.005950748920440674, train/logprobs = tensor([[ -1.2938, -12.5258],
        [ -6.9628,  -3.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.51982182264328
Epoch 0, Step 823: train/loss = 0.05796625837683678, train/raw-loss = 0.002661430975422263, train/logprobs = tensor([[ -1.7267, -15.7621],
        [ -8.4881,  -2.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.553048312664032
Epoch 0, Step 824: train/loss = 0.062187302857637405, train/raw-loss = 0.011121204122900963, train/logprobs = tensor([[ -0.9953, -13.0760],
        [ -5.7949,  -1.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5106610059738159
Epoch 0, Step 825: train/loss = 0.06300768256187439, train/raw-loss = 0.008487136103212833, train/logprobs = tensor([[-1.4372, -8.7718],
        [-6.7558, -3.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5452054738998413
Epoch 0, Step 826: train/loss = 0.06416988372802734, train/raw-loss = 0.006446409970521927, train/logprobs = tensor([[ -1.7035, -13.2871],
        [ -7.3276,  -2.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5772347450256348
Epoch 0, Step 827: train/loss = 0.05866468697786331, train/raw-loss = 0.006325831636786461, train/logprobs = tensor([[ -0.8936, -14.1709],
        [ -5.3664,  -2.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5233885049819946
Epoch 0, Step 828: train/loss = 0.05533642694354057, train/raw-loss = 0.0015007469337433577, train/logprobs = tensor([[ -1.5162, -16.0791],
        [ -8.2866,  -3.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5383567810058594
Epoch 0, Step 829: train/loss = 0.07208800315856934, train/raw-loss = 0.018191257491707802, train/logprobs = tensor([[ -1.7163, -13.2293],
        [ -6.1228,  -2.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.538967490196228
Epoch 0, Step 830: train/loss = 0.0564606636762619, train/raw-loss = 0.0038920033257454634, train/logprobs = tensor([[ -1.3931, -12.1093],
        [ -6.9548,  -1.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5256865620613098
Epoch 0, Step 831: train/loss = 0.11205027997493744, train/raw-loss = 0.0696270614862442, train/logprobs = tensor([[ -0.9619, -10.3149],
        [ -4.8704,  -1.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4242321252822876
Epoch 0, Step 832: train/loss = 0.06960118561983109, train/raw-loss = 0.021009430289268494, train/logprobs = tensor([[ -1.5186, -10.3625],
        [ -6.1993,  -2.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4859175384044647
Epoch 0, Step 833: train/loss = 0.0752231776714325, train/raw-loss = 0.023222574964165688, train/logprobs = tensor([[ -1.9226, -13.4980],
        [ -6.3944,  -2.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5200060606002808
Epoch 0, Step 834: train/loss = 0.061022963374853134, train/raw-loss = 0.010726194828748703, train/logprobs = tensor([[-1.5394, -9.0655],
        [-6.6633, -2.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5029677152633667
Epoch 0, Step 835: train/loss = 0.05953020602464676, train/raw-loss = 0.008738270029425621, train/logprobs = tensor([[ -1.5172, -10.7646],
        [ -7.4610,  -2.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5079193115234375
Epoch 0, Step 836: train/loss = 0.14696504175662994, train/raw-loss = 0.09849348664283752, train/logprobs = tensor([[-2.2470, -7.3203],
        [-8.3866, -2.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4847155213356018
Epoch 0, Step 837: train/loss = 0.058124884963035583, train/raw-loss = 0.006217676214873791, train/logprobs = tensor([[-1.3381, -9.2544],
        [-6.2937, -2.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5190721154212952
Epoch 0, Step 838: train/loss = 0.06164834648370743, train/raw-loss = 0.009385744109749794, train/logprobs = tensor([[ -0.7735, -11.0968],
        [ -6.7693,  -3.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5226259827613831
Epoch 0, Step 839: train/loss = 0.06802476942539215, train/raw-loss = 0.016269152984023094, train/logprobs = tensor([[-1.4724, -7.5370],
        [-5.4902, -1.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5175560712814331
Epoch 0, Step 840: train/loss = 0.06737326830625534, train/raw-loss = 0.006622650194913149, train/logprobs = tensor([[-1.7035, -9.8664],
        [-8.1915, -2.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6075062155723572
Epoch 0, Step 841: train/loss = 0.15272587537765503, train/raw-loss = 0.10613378882408142, train/logprobs = tensor([[ -1.6155, -10.0800],
        [ -6.5156,  -1.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46592092514038086
Epoch 0, Step 842: train/loss = 0.05865410342812538, train/raw-loss = 0.001982401590794325, train/logprobs = tensor([[ -1.9044, -13.0321],
        [ -9.2862,  -2.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5667170286178589
Epoch 0, Step 843: train/loss = 0.07682044804096222, train/raw-loss = 0.02376764640212059, train/logprobs = tensor([[ -2.7292, -11.9541],
        [ -6.9853,  -2.4606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5305279493331909
Epoch 0, Step 844: train/loss = 0.06276760995388031, train/raw-loss = 0.020980508998036385, train/logprobs = tensor([[ -1.8003, -14.3250],
        [ -5.6206,  -2.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41787099838256836
Epoch 0, Step 845: train/loss = 0.0655875951051712, train/raw-loss = 0.008628911338746548, train/logprobs = tensor([[ -1.4930, -12.8360],
        [ -6.6053,  -2.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5695868134498596
Epoch 0, Step 846: train/loss = 0.057954851537942886, train/raw-loss = 0.004329701419919729, train/logprobs = tensor([[ -1.5887, -12.4406],
        [ -7.6783,  -2.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5362515449523926
Epoch 0, Step 847: train/loss = 0.06861671805381775, train/raw-loss = 0.020634885877370834, train/logprobs = tensor([[-1.1263, -9.3969],
        [-7.2024, -2.4417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47981831431388855
Epoch 0, Step 848: train/loss = 0.12442934513092041, train/raw-loss = 0.06840603053569794, train/logprobs = tensor([[-1.1834, -8.4540],
        [-5.0874, -2.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5602332353591919
Epoch 0, Step 849: train/loss = 0.05626024305820465, train/raw-loss = 0.00273791397921741, train/logprobs = tensor([[ -1.9447, -13.7641],
        [ -7.9690,  -2.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5352232456207275
Epoch 0, Step 850: train/loss = 0.065595343708992, train/raw-loss = 0.013659649528563023, train/logprobs = tensor([[ -1.9891, -10.2645],
        [ -8.2105,  -2.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.519356906414032
Epoch 0, Step 851: train/loss = 0.054559096693992615, train/raw-loss = 0.005377682391554117, train/logprobs = tensor([[ -1.7472, -12.9496],
        [ -6.5811,  -1.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49181410670280457
Epoch 0, Step 852: train/loss = 0.06423959881067276, train/raw-loss = 0.011698784306645393, train/logprobs = tensor([[ -1.7257, -11.7189],
        [ -8.0992,  -2.4875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.525408148765564
Epoch 0, Step 853: train/loss = 0.06717074662446976, train/raw-loss = 0.01263207383453846, train/logprobs = tensor([[ -1.4675, -10.7568],
        [ -7.1585,  -1.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.545386791229248
Epoch 0, Step 854: train/loss = 0.10301515460014343, train/raw-loss = 0.053808800876140594, train/logprobs = tensor([[ -0.9655, -12.7037],
        [ -5.0904,  -4.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49206358194351196
Epoch 0, Step 855: train/loss = 0.08534408360719681, train/raw-loss = 0.038405641913414, train/logprobs = tensor([[-1.8404, -8.4681],
        [-6.3920, -1.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4693843722343445
Epoch 0, Step 856: train/loss = 0.1489441692829132, train/raw-loss = 0.10634569078683853, train/logprobs = tensor([[ -1.0471, -10.9037],
        [ -5.2983,  -3.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4259847402572632
Epoch 0, Step 857: train/loss = 0.08994658291339874, train/raw-loss = 0.045364975929260254, train/logprobs = tensor([[ -1.4198, -11.0872],
        [ -4.4916,  -2.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44581612944602966
Epoch 0, Step 858: train/loss = 0.12351896613836288, train/raw-loss = 0.0783117264509201, train/logprobs = tensor([[-0.9661, -6.7411],
        [-5.0685, -2.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4520723223686218
Epoch 0, Step 859: train/loss = 0.0615663006901741, train/raw-loss = 0.014649602584540844, train/logprobs = tensor([[-1.2685, -9.4874],
        [-5.4899, -1.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46916693449020386
Epoch 0, Step 860: train/loss = 0.07226274162530899, train/raw-loss = 0.02090729959309101, train/logprobs = tensor([[ -1.4399, -15.7659],
        [ -6.5872,  -1.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5135543942451477
Epoch 0, Step 861: train/loss = 0.06993424147367477, train/raw-loss = 0.02437291108071804, train/logprobs = tensor([[ -1.3954, -12.6934],
        [ -6.1833,  -2.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45561325550079346
Epoch 0, Step 862: train/loss = 0.06388787925243378, train/raw-loss = 0.0032868210691958666, train/logprobs = tensor([[ -1.3362, -13.7908],
        [ -7.0571,  -2.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6060105562210083
Epoch 0, Step 863: train/loss = 0.06495370715856552, train/raw-loss = 0.0025977282784879208, train/logprobs = tensor([[ -2.2962, -12.0963],
        [ -9.2651,  -2.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6235597729682922
Epoch 0, Step 864: train/loss = 0.0600786991417408, train/raw-loss = 0.010985687375068665, train/logprobs = tensor([[ -1.5836, -14.4208],
        [ -6.0690,  -2.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49093011021614075
Epoch 0, Step 865: train/loss = 0.05349374935030937, train/raw-loss = 0.0098351975902915, train/logprobs = tensor([[ -0.9085, -15.6579],
        [ -4.9616,  -1.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43658551573753357
Epoch 0, Step 866: train/loss = 0.06128096580505371, train/raw-loss = 0.018923712894320488, train/logprobs = tensor([[ -1.1058, -10.5063],
        [ -5.0392,  -1.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42357248067855835
Epoch 0, Step 867: train/loss = 0.06045468896627426, train/raw-loss = 0.0033989204093813896, train/logprobs = tensor([[ -1.5234, -10.8269],
        [ -6.9963,  -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5705576539039612
Epoch 0, Step 868: train/loss = 0.06415878236293793, train/raw-loss = 0.01033813413232565, train/logprobs = tensor([[ -1.2572, -11.5158],
        [ -5.1529,  -1.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5382064580917358
Epoch 0, Step 869: train/loss = 0.06279277056455612, train/raw-loss = 0.013736176304519176, train/logprobs = tensor([[ -1.1847, -10.8988],
        [ -6.2009,  -2.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4905659556388855
Epoch 0, Step 870: train/loss = 0.05938775837421417, train/raw-loss = 0.010250707156956196, train/logprobs = tensor([[-1.0286, -9.3955],
        [-5.3894, -3.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4913704991340637
Epoch 0, Step 871: train/loss = 0.07400818169116974, train/raw-loss = 0.02426716685295105, train/logprobs = tensor([[ -1.1403, -12.5047],
        [ -5.6179,  -1.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4974101185798645
Epoch 0, Step 872: train/loss = 0.06414233893156052, train/raw-loss = 0.011675147339701653, train/logprobs = tensor([[ -1.3489, -12.6470],
        [ -6.5331,  -2.9743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5246719121932983
Epoch 0, Step 873: train/loss = 0.13456356525421143, train/raw-loss = 0.08055130392313004, train/logprobs = tensor([[-1.6669, -8.7018],
        [-6.6393, -2.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5401226878166199
Epoch 0, Step 874: train/loss = 0.056136354804039, train/raw-loss = 0.007347775623202324, train/logprobs = tensor([[ -1.2543, -16.6812],
        [ -6.0955,  -2.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4878857731819153
Epoch 0, Step 875: train/loss = 0.20840011537075043, train/raw-loss = 0.15711836516857147, train/logprobs = tensor([[-1.9757, -8.4198],
        [-7.1243, -2.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5128174424171448
Epoch 0, Step 876: train/loss = 0.07344138622283936, train/raw-loss = 0.021544884890317917, train/logprobs = tensor([[-1.7618, -9.7504],
        [-7.3060, -2.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.518964946269989
Epoch 0, Step 877: train/loss = 0.07790006697177887, train/raw-loss = 0.03380894288420677, train/logprobs = tensor([[-1.2417, -5.8666],
        [-6.3751, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4409111738204956
Epoch 0, Step 878: train/loss = 0.06286178529262543, train/raw-loss = 0.011361107230186462, train/logprobs = tensor([[ -2.0967, -10.1556],
        [ -6.9830,  -2.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5150067806243896
Epoch 0, Step 879: train/loss = 0.08498042821884155, train/raw-loss = 0.03884202241897583, train/logprobs = tensor([[-1.7629, -8.5378],
        [-5.1358, -1.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46138399839401245
Epoch 0, Step 880: train/loss = 0.06710690259933472, train/raw-loss = 0.01963244564831257, train/logprobs = tensor([[ -1.6085, -10.2640],
        [ -5.6034,  -2.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4747444987297058
Epoch 0, Step 881: train/loss = 0.07811686396598816, train/raw-loss = 0.02841414138674736, train/logprobs = tensor([[-1.0493, -9.6170],
        [-6.9137, -3.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4970271587371826
Epoch 0, Step 882: train/loss = 0.07462682574987411, train/raw-loss = 0.024064164608716965, train/logprobs = tensor([[-1.6350, -8.0750],
        [-6.4907, -2.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5056265592575073
Epoch 0, Step 883: train/loss = 0.0750385969877243, train/raw-loss = 0.029848607257008553, train/logprobs = tensor([[-1.0333, -9.8984],
        [-5.5139, -1.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4518998861312866
Epoch 0, Step 884: train/loss = 0.07035434991121292, train/raw-loss = 0.026687638834118843, train/logprobs = tensor([[-1.3003, -8.4837],
        [-5.6180, -1.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4366670846939087
Epoch 0, Step 885: train/loss = 0.06672336906194687, train/raw-loss = 0.008371522650122643, train/logprobs = tensor([[-1.9829, -9.9992],
        [-8.4375, -2.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5835185050964355
Epoch 0, Step 886: train/loss = 0.06571000814437866, train/raw-loss = 0.016990570351481438, train/logprobs = tensor([[-1.3097, -8.4363],
        [-6.0623, -1.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48719438910484314
Epoch 0, Step 887: train/loss = 0.05298217758536339, train/raw-loss = 0.005630164407193661, train/logprobs = tensor([[ -1.5912, -10.3355],
        [ -7.6164,  -2.5632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4735201299190521
Epoch 0, Step 888: train/loss = 0.06475771218538284, train/raw-loss = 0.007569340988993645, train/logprobs = tensor([[-1.4019, -9.9663],
        [-7.0471, -3.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5718836784362793
Epoch 0, Step 889: train/loss = 0.131540447473526, train/raw-loss = 0.08618149906396866, train/logprobs = tensor([[-0.7666, -7.8985],
        [-5.3172, -2.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45358961820602417
Epoch 0, Step 890: train/loss = 0.17738714814186096, train/raw-loss = 0.13452094793319702, train/logprobs = tensor([[-1.1676, -9.3978],
        [-6.5007, -1.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42866194248199463
Epoch 0, Step 891: train/loss = 0.07298685610294342, train/raw-loss = 0.026517365127801895, train/logprobs = tensor([[ -1.1227, -10.6959],
        [ -6.0017,  -2.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46469491720199585
Epoch 0, Step 892: train/loss = 0.05389506742358208, train/raw-loss = 0.0034687959123402834, train/logprobs = tensor([[ -1.7459, -12.9345],
        [ -7.9301,  -2.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5042627453804016
Epoch 0, Step 893: train/loss = 0.07099732011556625, train/raw-loss = 0.017353232949972153, train/logprobs = tensor([[-1.7192, -8.9019],
        [-7.1514, -2.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5364408493041992
Epoch 0, Step 894: train/loss = 0.07618027925491333, train/raw-loss = 0.03690657764673233, train/logprobs = tensor([[-1.6486, -7.0848],
        [-4.5590, -1.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3927369713783264
Epoch 0, Step 895: train/loss = 0.0587291456758976, train/raw-loss = 0.005823985673487186, train/logprobs = tensor([[ -2.4691, -11.7277],
        [ -8.0295,  -1.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5290516018867493
Epoch 0, Step 896: train/loss = 0.060688309371471405, train/raw-loss = 0.018184347078204155, train/logprobs = tensor([[-0.9282, -9.7978],
        [-6.1466, -1.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4250396490097046
Epoch 0, Step 897: train/loss = 0.05842068791389465, train/raw-loss = 0.010074933990836143, train/logprobs = tensor([[-1.2210, -8.0203],
        [-6.3199, -1.5038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4834575057029724
Epoch 0, Step 898: train/loss = 0.08286226540803909, train/raw-loss = 0.040079064667224884, train/logprobs = tensor([[-0.6902, -9.4480],
        [-4.4359, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4278319478034973
Epoch 0, Step 899: train/loss = 0.06199544668197632, train/raw-loss = 0.014020523987710476, train/logprobs = tensor([[ -1.4831, -10.4482],
        [ -7.1433,  -2.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4797492027282715
Epoch 0, Step 900: train/loss = 0.06269032508134842, train/raw-loss = 0.022022513672709465, train/logprobs = tensor([[ -1.0486, -11.3081],
        [ -4.9646,  -1.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40667811036109924
Epoch 0, Step 901: train/loss = 0.06145825237035751, train/raw-loss = 0.008331991732120514, train/logprobs = tensor([[-1.3229, -9.4032],
        [-6.2170, -3.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5312625765800476
Epoch 0, Step 902: train/loss = 0.07219525426626205, train/raw-loss = 0.024698754772543907, train/logprobs = tensor([[-1.4023, -9.8217],
        [-4.8614, -2.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4749649167060852
Epoch 0, Step 903: train/loss = 0.05640512332320213, train/raw-loss = 0.009618045762181282, train/logprobs = tensor([[ -0.9777, -11.6896],
        [ -6.0708,  -3.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678707718849182
Epoch 0, Step 904: train/loss = 0.13280867040157318, train/raw-loss = 0.09281539916992188, train/logprobs = tensor([[-2.2306, -6.4084],
        [-5.0019, -2.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39993274211883545
Epoch 0, Step 905: train/loss = 0.07468540221452713, train/raw-loss = 0.025720778852701187, train/logprobs = tensor([[ -1.3289, -12.2384],
        [ -4.8263,  -1.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4896462559700012
Epoch 0, Step 906: train/loss = 0.05912913382053375, train/raw-loss = 0.004367117304354906, train/logprobs = tensor([[ -1.2610, -11.4646],
        [ -6.6631,  -2.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5476201176643372
Epoch 0, Step 907: train/loss = 0.0635954961180687, train/raw-loss = 0.013864893466234207, train/logprobs = tensor([[-1.3589, -7.6680],
        [-6.6045, -2.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4973060190677643
Epoch 0, Step 908: train/loss = 0.15345074236392975, train/raw-loss = 0.11056829243898392, train/logprobs = tensor([[ -0.9234, -11.0973],
        [ -5.8526,  -3.3186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42882445454597473
Epoch 0, Step 909: train/loss = 0.05459631234407425, train/raw-loss = 0.013475404120981693, train/logprobs = tensor([[ -1.4431, -13.4561],
        [ -6.0640,  -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4112091064453125
Epoch 0, Step 910: train/loss = 0.057108573615550995, train/raw-loss = 0.01678469032049179, train/logprobs = tensor([[ -1.5264, -11.8915],
        [ -5.5752,  -1.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40323880314826965
Epoch 0, Step 911: train/loss = 0.08262161910533905, train/raw-loss = 0.028010601177811623, train/logprobs = tensor([[ -1.6402, -10.5283],
        [ -7.3358,  -2.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.546110212802887
Epoch 0, Step 912: train/loss = 0.06307049840688705, train/raw-loss = 0.01223928201943636, train/logprobs = tensor([[-1.8094, -9.8567],
        [-7.0607, -2.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5083121657371521
Epoch 0, Step 913: train/loss = 0.08513123542070389, train/raw-loss = 0.038446471095085144, train/logprobs = tensor([[-1.3147, -9.0953],
        [-5.0510, -2.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46684765815734863
Epoch 0, Step 914: train/loss = 0.06940121948719025, train/raw-loss = 0.02227541245520115, train/logprobs = tensor([[-1.6264, -7.5441],
        [-6.9440, -2.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47125810384750366
Epoch 0, Step 915: train/loss = 0.05868053436279297, train/raw-loss = 0.007224668748676777, train/logprobs = tensor([[ -1.7469, -12.1115],
        [ -8.8491,  -2.4489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5145586133003235
Epoch 0, Step 916: train/loss = 0.0661666989326477, train/raw-loss = 0.017820710316300392, train/logprobs = tensor([[ -1.1045, -11.9983],
        [ -6.0703,  -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4834598898887634
Epoch 0, Step 917: train/loss = 0.07741933315992355, train/raw-loss = 0.018356168642640114, train/logprobs = tensor([[-1.4862, -8.5477],
        [-6.6298, -1.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5906316637992859
Epoch 0, Step 918: train/loss = 0.07481491565704346, train/raw-loss = 0.027212705463171005, train/logprobs = tensor([[ -2.1065, -11.9849],
        [ -6.2703,  -1.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47602203488349915
Epoch 0, Step 919: train/loss = 0.07654912769794464, train/raw-loss = 0.03253402188420296, train/logprobs = tensor([[-0.9109, -8.4132],
        [-4.7298, -1.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44015106558799744
Epoch 0, Step 920: train/loss = 0.13112418353557587, train/raw-loss = 0.08682804554700851, train/logprobs = tensor([[ -1.5796, -11.7465],
        [ -6.0402,  -3.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429614543914795
Epoch 0, Step 921: train/loss = 0.08432687819004059, train/raw-loss = 0.03920000046491623, train/logprobs = tensor([[-1.2422, -7.4648],
        [-6.3516, -2.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4512687921524048
Epoch 0, Step 922: train/loss = 0.05392225831747055, train/raw-loss = 0.0020843578968197107, train/logprobs = tensor([[-1.2805, -9.4315],
        [-9.2743, -1.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5183789730072021
Epoch 0, Step 923: train/loss = 0.0653952956199646, train/raw-loss = 0.014763420447707176, train/logprobs = tensor([[-1.0552, -8.1358],
        [-5.9444, -3.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5063188076019287
Epoch 0, Step 924: train/loss = 0.049392327666282654, train/raw-loss = 0.0034901732578873634, train/logprobs = tensor([[ -1.3396, -11.6014],
        [ -7.0221,  -0.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45902156829833984
Epoch 0, Step 925: train/loss = 0.07939642667770386, train/raw-loss = 0.035658661276102066, train/logprobs = tensor([[ -1.0989, -11.1753],
        [ -6.4447,  -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43737757205963135
Epoch 0, Step 926: train/loss = 0.059951189905405045, train/raw-loss = 0.021396754309535027, train/logprobs = tensor([[ -0.9679, -12.3321],
        [ -4.8490,  -2.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3855443298816681
Epoch 0, Step 927: train/loss = 0.06217101216316223, train/raw-loss = 0.018241621553897858, train/logprobs = tensor([[-1.5418, -8.4349],
        [-6.2264, -2.2063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43929389119148254
Epoch 0, Step 928: train/loss = 0.06539300084114075, train/raw-loss = 0.02052324078977108, train/logprobs = tensor([[ -0.9507, -15.1096],
        [ -5.2231,  -3.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44869762659072876
Epoch 0, Step 929: train/loss = 0.09947548806667328, train/raw-loss = 0.0521334633231163, train/logprobs = tensor([[-1.7585, -8.2204],
        [-6.0929, -3.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47342026233673096
Epoch 0, Step 930: train/loss = 0.05790767818689346, train/raw-loss = 0.010845364071428776, train/logprobs = tensor([[ -1.7312, -10.6138],
        [ -8.6990,  -2.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4706231355667114
Epoch 0, Step 931: train/loss = 0.06333012878894806, train/raw-loss = 0.024841826409101486, train/logprobs = tensor([[ -1.1596, -12.2020],
        [ -5.4626,  -3.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38488295674324036
Epoch 0, Step 932: train/loss = 0.07199463248252869, train/raw-loss = 0.03390274941921234, train/logprobs = tensor([[-0.6729, -8.1819],
        [-3.5887, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38091883063316345
Epoch 0, Step 933: train/loss = 0.10675789415836334, train/raw-loss = 0.05611107498407364, train/logprobs = tensor([[-1.8916, -6.0290],
        [-7.6902, -1.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5064682364463806
Epoch 0, Step 934: train/loss = 0.07811703532934189, train/raw-loss = 0.031833671033382416, train/logprobs = tensor([[-1.3802, -7.9292],
        [-6.1107, -1.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4628336429595947
Epoch 0, Step 935: train/loss = 0.05194409564137459, train/raw-loss = 0.006357546895742416, train/logprobs = tensor([[ -1.0520, -10.0352],
        [ -6.0160,  -1.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45586544275283813
Epoch 0, Step 936: train/loss = 0.06160898506641388, train/raw-loss = 0.013758747838437557, train/logprobs = tensor([[ -1.4231, -10.3051],
        [ -6.3158,  -2.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47850239276885986
Epoch 0, Step 937: train/loss = 0.05436591058969498, train/raw-loss = 0.0020909190643578768, train/logprobs = tensor([[ -1.0340, -15.0214],
        [ -7.5351,  -2.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5227499604225159
Epoch 0, Step 938: train/loss = 0.0550701841711998, train/raw-loss = 0.009777257218956947, train/logprobs = tensor([[-1.8745, -9.7990],
        [-7.3710, -1.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4529292583465576
Epoch 0, Step 939: train/loss = 0.06243598461151123, train/raw-loss = 0.01304482389241457, train/logprobs = tensor([[ -1.7067, -12.2023],
        [ -7.2702,  -2.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49391159415245056
Epoch 0, Step 940: train/loss = 0.07168158888816833, train/raw-loss = 0.031435102224349976, train/logprobs = tensor([[ -0.8823, -10.7839],
        [ -3.7247,  -2.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4024648368358612
Epoch 0, Step 941: train/loss = 0.07649168372154236, train/raw-loss = 0.031129540875554085, train/logprobs = tensor([[ -1.2192, -11.7403],
        [ -5.5907,  -2.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45362144708633423
Epoch 0, Step 942: train/loss = 0.05009503662586212, train/raw-loss = 0.004249200690537691, train/logprobs = tensor([[ -1.3114, -10.3847],
        [ -6.7007,  -2.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4584583640098572
Epoch 0, Step 943: train/loss = 0.06432189792394638, train/raw-loss = 0.016941405832767487, train/logprobs = tensor([[-1.3494, -8.7222],
        [-5.4973, -1.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47380486130714417
Epoch 0, Step 944: train/loss = 0.09179915487766266, train/raw-loss = 0.04057243838906288, train/logprobs = tensor([[-1.6822, -9.4924],
        [-7.8715, -2.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5122671723365784
Epoch 0, Step 945: train/loss = 0.055905357003211975, train/raw-loss = 0.008508564904332161, train/logprobs = tensor([[ -0.9126, -11.5574],
        [ -5.2836,  -1.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47396790981292725
Epoch 0, Step 946: train/loss = 0.09430637955665588, train/raw-loss = 0.04688968136906624, train/logprobs = tensor([[-1.5911, -6.5399],
        [-6.8737, -2.1821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4741670489311218
Epoch 0, Step 947: train/loss = 0.06146358698606491, train/raw-loss = 0.010782595723867416, train/logprobs = tensor([[-1.4368, -9.8787],
        [-8.3472, -1.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5068098902702332
Epoch 0, Step 948: train/loss = 0.06219355762004852, train/raw-loss = 0.008847094140946865, train/logprobs = tensor([[ -2.1070, -11.6243],
        [-10.0327,  -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5334645509719849
Epoch 0, Step 949: train/loss = 0.052737683057785034, train/raw-loss = 0.004944628570228815, train/logprobs = tensor([[ -1.5184, -10.5565],
        [ -7.3386,  -1.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47793048620224
Epoch 0, Step 950: train/loss = 0.06979168951511383, train/raw-loss = 0.02625439129769802, train/logprobs = tensor([[-1.4488, -9.4575],
        [-6.5591, -1.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4353729784488678
Epoch 0, Step 951: train/loss = 0.06423565000295639, train/raw-loss = 0.016983117908239365, train/logprobs = tensor([[-1.7783, -9.2857],
        [-7.3547, -1.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4725252687931061
Epoch 0, Step 952: train/loss = 0.12144709378480911, train/raw-loss = 0.0777612254023552, train/logprobs = tensor([[-0.8344, -5.2228],
        [-5.4937, -1.7104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4368586540222168
Epoch 0, Step 953: train/loss = 0.05767691135406494, train/raw-loss = 0.016459599137306213, train/logprobs = tensor([[-1.1696, -9.4455],
        [-5.4948, -2.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4121730923652649
Epoch 0, Step 954: train/loss = 0.06489025056362152, train/raw-loss = 0.016576029360294342, train/logprobs = tensor([[ -1.4558, -10.9001],
        [ -7.2177,  -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.483142226934433
Epoch 0, Step 955: train/loss = 0.2057894617319107, train/raw-loss = 0.15889982879161835, train/logprobs = tensor([[-1.2896, -7.3761],
        [-5.5491, -2.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4688964784145355
Epoch 0, Step 956: train/loss = 0.050549671053886414, train/raw-loss = 0.007355764042586088, train/logprobs = tensor([[-1.4083, -9.9048],
        [-7.2205, -1.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43193909525871277
Epoch 0, Step 957: train/loss = 0.05996522307395935, train/raw-loss = 0.009921279735863209, train/logprobs = tensor([[ -1.3607, -12.4297],
        [ -6.3862,  -1.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5004394054412842
Epoch 0, Step 958: train/loss = 0.06129750981926918, train/raw-loss = 0.003659580135717988, train/logprobs = tensor([[-1.9047, -9.8841],
        [-8.5181, -2.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5763792395591736
Epoch 0, Step 959: train/loss = 0.05115232244133949, train/raw-loss = 0.004649087321013212, train/logprobs = tensor([[ -1.7027, -11.3299],
        [ -8.3151,  -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46503233909606934
Epoch 0, Step 960: train/loss = 0.048902057111263275, train/raw-loss = 0.009401277638971806, train/logprobs = tensor([[-0.8817, -8.1703],
        [-6.1038, -2.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39500775933265686
Epoch 0, Step 961: train/loss = 0.05125749483704567, train/raw-loss = 0.0028754868544638157, train/logprobs = tensor([[ -1.7921, -11.0533],
        [ -7.7165,  -2.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4838200807571411
Epoch 0, Step 962: train/loss = 0.06390529870986938, train/raw-loss = 0.02162504754960537, train/logprobs = tensor([[ -1.2962, -11.7501],
        [ -6.1276,  -2.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42280250787734985
Epoch 0, Step 963: train/loss = 0.07410109043121338, train/raw-loss = 0.03773767128586769, train/logprobs = tensor([[ -0.7900, -10.6372],
        [ -3.3915,  -2.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3636341989040375
Epoch 0, Step 964: train/loss = 0.07713006436824799, train/raw-loss = 0.03030059114098549, train/logprobs = tensor([[-1.3252, -8.4340],
        [-5.6480, -1.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46829473972320557
Epoch 0, Step 965: train/loss = 0.07583196461200714, train/raw-loss = 0.0314474031329155, train/logprobs = tensor([[-1.4669, -7.8621],
        [-5.9537, -2.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44384559988975525
Epoch 0, Step 966: train/loss = 0.054079264402389526, train/raw-loss = 0.010606378316879272, train/logprobs = tensor([[-1.6032, -9.5944],
        [-6.4238, -1.3252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43472886085510254
Epoch 0, Step 967: train/loss = 0.10230310261249542, train/raw-loss = 0.06183081120252609, train/logprobs = tensor([[ -1.0211, -10.3862],
        [ -5.1137,  -2.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047229290008545
Epoch 0, Step 968: train/loss = 0.048381369560956955, train/raw-loss = 0.005751138087362051, train/logprobs = tensor([[-1.0175, -9.6645],
        [-6.2673, -2.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42630231380462646
Epoch 0, Step 969: train/loss = 0.04575282707810402, train/raw-loss = 0.0041982680559158325, train/logprobs = tensor([[-1.3059, -9.3768],
        [-7.1248, -2.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41554558277130127
Epoch 0, Step 970: train/loss = 0.05269639939069748, train/raw-loss = 0.009276468306779861, train/logprobs = tensor([[-1.3571, -8.7868],
        [-6.9880, -2.2523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4341992735862732
Epoch 0, Step 971: train/loss = 0.05195965990424156, train/raw-loss = 0.008224088698625565, train/logprobs = tensor([[ -1.3420, -12.2135],
        [ -6.1568,  -2.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4373556673526764
Epoch 0, Step 972: train/loss = 0.0676504448056221, train/raw-loss = 0.025382794439792633, train/logprobs = tensor([[ -1.8752, -10.1741],
        [ -7.2558,  -2.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4226765036582947
Epoch 0, Step 973: train/loss = 0.060086898505687714, train/raw-loss = 0.015842532739043236, train/logprobs = tensor([[ -1.2341, -10.6350],
        [ -5.8478,  -1.1692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4424436688423157
Epoch 0, Step 974: train/loss = 0.08581234514713287, train/raw-loss = 0.04167160019278526, train/logprobs = tensor([[-1.0761, -8.2315],
        [-6.4574, -2.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4414074718952179
Epoch 0, Step 975: train/loss = 0.07535172998905182, train/raw-loss = 0.03480099141597748, train/logprobs = tensor([[-1.0341, -9.3201],
        [-4.5044, -2.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4055073857307434
Epoch 0, Step 976: train/loss = 0.061902910470962524, train/raw-loss = 0.019734995439648628, train/logprobs = tensor([[-1.3426, -8.6271],
        [-7.1390, -3.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42167916893959045
Epoch 0, Step 977: train/loss = 0.06127532944083214, train/raw-loss = 0.01697203516960144, train/logprobs = tensor([[-0.9909, -9.9222],
        [-5.2292, -2.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4430329203605652
Epoch 0, Step 978: train/loss = 0.06050955504179001, train/raw-loss = 0.005109112244099379, train/logprobs = tensor([[-1.7717, -7.4939],
        [-8.2320, -1.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.554004430770874
Epoch 0, Step 979: train/loss = 0.052863918244838715, train/raw-loss = 0.004512017127126455, train/logprobs = tensor([[ -1.7793, -10.4735],
        [ -7.5975,  -2.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4835190176963806
Epoch 0, Step 980: train/loss = 0.058201830834150314, train/raw-loss = 0.011642028577625751, train/logprobs = tensor([[ -1.1566, -10.6580],
        [ -6.6371,  -2.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4655979871749878
Epoch 0, Step 981: train/loss = 0.050705686211586, train/raw-loss = 0.00363611476495862, train/logprobs = tensor([[-1.4840, -8.6113],
        [-7.5921, -1.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47069570422172546
Epoch 0, Step 982: train/loss = 0.18849799036979675, train/raw-loss = 0.14094474911689758, train/logprobs = tensor([[-1.6727, -5.8253],
        [-7.1310, -3.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4755322337150574
Epoch 0, Step 983: train/loss = 0.05346084013581276, train/raw-loss = 0.007498771883547306, train/logprobs = tensor([[-1.4605, -9.8718],
        [-6.3960, -1.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45962071418762207
Epoch 0, Step 984: train/loss = 0.16347047686576843, train/raw-loss = 0.11967425048351288, train/logprobs = tensor([[-0.6131, -5.2003],
        [-5.2986, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43796229362487793
Epoch 0, Step 985: train/loss = 0.049067460000514984, train/raw-loss = 0.0033028805628418922, train/logprobs = tensor([[-1.8839, -9.9742],
        [-8.4320, -3.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45764580368995667
Epoch 0, Step 986: train/loss = 0.10477488487958908, train/raw-loss = 0.05698966607451439, train/logprobs = tensor([[-2.0646, -9.3478],
        [-6.9654, -3.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47785210609436035
Epoch 0, Step 987: train/loss = 0.06254363805055618, train/raw-loss = 0.02377297542989254, train/logprobs = tensor([[ -0.8622, -10.3289],
        [ -4.5649,  -1.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3877066671848297
Epoch 0, Step 988: train/loss = 0.07261334359645844, train/raw-loss = 0.03515196964144707, train/logprobs = tensor([[-1.1308, -9.1095],
        [-6.0101, -4.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3746136724948883
Epoch 0, Step 989: train/loss = 0.060479581356048584, train/raw-loss = 0.017410166561603546, train/logprobs = tensor([[-1.0122, -8.5645],
        [-4.8778, -2.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4306941330432892
Epoch 0, Step 990: train/loss = 0.054348260164260864, train/raw-loss = 0.0007239824626594782, train/logprobs = tensor([[-2.1028, -9.1462],
        [-9.2881, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5362427830696106
Epoch 0, Step 991: train/loss = 0.047980740666389465, train/raw-loss = 0.00547882029786706, train/logprobs = tensor([[ -1.5617, -11.6039],
        [ -7.4855,  -2.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42501917481422424
Epoch 0, Step 992: train/loss = 0.06836893409490585, train/raw-loss = 0.0264601968228817, train/logprobs = tensor([[-1.2866, -8.3561],
        [-5.0282, -1.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41908735036849976
Epoch 0, Step 993: train/loss = 0.06853479146957397, train/raw-loss = 0.022247813642024994, train/logprobs = tensor([[-1.6737, -8.8274],
        [-7.9304, -2.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4628697633743286
Epoch 0, Step 994: train/loss = 0.05134274438023567, train/raw-loss = 0.005766185000538826, train/logprobs = tensor([[-2.5469, -9.4022],
        [-8.5443, -1.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45576560497283936
Epoch 0, Step 995: train/loss = 0.10956413298845291, train/raw-loss = 0.07002731412649155, train/logprobs = tensor([[-1.1574, -9.8795],
        [-4.5670, -2.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39536812901496887
Epoch 0, Step 996: train/loss = 0.05575789511203766, train/raw-loss = 0.014537444338202477, train/logprobs = tensor([[-1.7541, -8.4650],
        [-7.7530, -2.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122045636177063
Epoch 0, Step 997: train/loss = 0.06550242006778717, train/raw-loss = 0.023473422974348068, train/logprobs = tensor([[-1.0695, -9.2705],
        [-4.8923, -1.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42028993368148804
Epoch 0, Step 998: train/loss = 0.0629076287150383, train/raw-loss = 0.016216645017266273, train/logprobs = tensor([[-1.5024, -7.2309],
        [-6.3659, -2.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46690982580184937
Epoch 0, Step 999: train/loss = 0.06202324479818344, train/raw-loss = 0.021206874400377274, train/logprobs = tensor([[-0.7845, -9.0515],
        [-5.2379, -3.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4081636965274811
Epoch 0, Step 1000: train/loss = 0.05026267468929291, train/raw-loss = 0.004793575499206781, train/logprobs = tensor([[ -1.5794, -11.6562],
        [ -7.0027,  -2.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45469093322753906
Epoch 0, Step 1001: train/loss = 0.06340843439102173, train/raw-loss = 0.020861521363258362, train/logprobs = tensor([[-1.0426, -8.6865],
        [-4.4816, -1.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42546916007995605
Epoch 0, Step 1002: train/loss = 0.17621667683124542, train/raw-loss = 0.13870543241500854, train/logprobs = tensor([[-1.1930, -9.3741],
        [-5.5500, -3.4012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751124143600464
Epoch 0, Step 1003: train/loss = 0.06013049930334091, train/raw-loss = 0.018126558512449265, train/logprobs = tensor([[-0.8075, -7.9713],
        [-4.3008, -1.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4200393855571747
Epoch 0, Step 1004: train/loss = 0.046123065054416656, train/raw-loss = 0.0022300155833363533, train/logprobs = tensor([[ -1.7603, -12.1873],
        [ -9.1406,  -2.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.438930481672287
Epoch 0, Step 1005: train/loss = 0.08704230934381485, train/raw-loss = 0.047743238508701324, train/logprobs = tensor([[-0.8660, -8.1853],
        [-5.4328, -2.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39299076795578003
Epoch 0, Step 1006: train/loss = 0.054859403520822525, train/raw-loss = 0.010789431631565094, train/logprobs = tensor([[-1.6317, -7.8839],
        [-6.6221, -1.7132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4406997263431549
Epoch 0, Step 1007: train/loss = 0.08439220488071442, train/raw-loss = 0.05088968575000763, train/logprobs = tensor([[-0.7559, -6.9893],
        [-4.6106, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3350251615047455
Epoch 0, Step 1008: train/loss = 0.06412890553474426, train/raw-loss = 0.02594556286931038, train/logprobs = tensor([[-0.8409, -8.0976],
        [-4.9320, -2.3999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38183343410491943
Epoch 0, Step 1009: train/loss = 0.0454438254237175, train/raw-loss = 0.004957155790179968, train/logprobs = tensor([[ -1.2245, -11.6201],
        [ -7.1455,  -2.2759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40486663579940796
Epoch 0, Step 1010: train/loss = 0.07761014997959137, train/raw-loss = 0.03389054536819458, train/logprobs = tensor([[-1.7311, -6.8348],
        [-6.8308, -1.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4371960759162903
Epoch 0, Step 1011: train/loss = 0.04710812121629715, train/raw-loss = 0.007123311050236225, train/logprobs = tensor([[-1.0630, -8.4374],
        [-6.1103, -2.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3998481333255768
Epoch 0, Step 1012: train/loss = 0.04800044000148773, train/raw-loss = 0.005210367031395435, train/logprobs = tensor([[ -1.2892, -10.9723],
        [ -6.5536,  -3.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4279007315635681
Epoch 0, Step 1013: train/loss = 0.12489014863967896, train/raw-loss = 0.08612409979104996, train/logprobs = tensor([[-1.2531, -8.0063],
        [-4.9460, -1.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3876604735851288
Epoch 0, Step 1014: train/loss = 0.04740162193775177, train/raw-loss = 0.004839156288653612, train/logprobs = tensor([[ -1.7331, -10.3026],
        [ -7.0397,  -1.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42562463879585266
Epoch 0, Step 1015: train/loss = 0.0638548731803894, train/raw-loss = 0.026927288621664047, train/logprobs = tensor([[-0.9710, -7.8300],
        [-5.4711, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692758083343506
Epoch 0, Step 1016: train/loss = 0.07281892001628876, train/raw-loss = 0.027406126260757446, train/logprobs = tensor([[-0.9641, -8.0651],
        [-5.5665, -1.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4541279077529907
Epoch 0, Step 1017: train/loss = 0.0606832280755043, train/raw-loss = 0.017986126244068146, train/logprobs = tensor([[-1.4929, -9.8001],
        [-5.7326, -2.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4269709885120392
Epoch 0, Step 1018: train/loss = 0.11439042538404465, train/raw-loss = 0.07768185436725616, train/logprobs = tensor([[-1.0349, -6.8893],
        [-4.9720, -2.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36708566546440125
Epoch 0, Step 1019: train/loss = 0.04324782267212868, train/raw-loss = 0.004626790061593056, train/logprobs = tensor([[-0.8049, -9.9811],
        [-5.8217, -1.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3862103223800659
Epoch 0, Step 1020: train/loss = 0.05300135910511017, train/raw-loss = 0.00992633868008852, train/logprobs = tensor([[-0.9523, -9.1902],
        [-5.5802, -2.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43075019121170044
Epoch 0, Step 1021: train/loss = 0.06605491042137146, train/raw-loss = 0.020690638571977615, train/logprobs = tensor([[-1.5368, -9.9117],
        [-6.1105, -0.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45364266633987427
Epoch 0, Step 1022: train/loss = 0.056116983294487, train/raw-loss = 0.009256767109036446, train/logprobs = tensor([[ -1.3894, -11.0940],
        [ -7.3494,  -1.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46860212087631226
Epoch 0, Step 1023: train/loss = 0.05070438235998154, train/raw-loss = 0.003737162332981825, train/logprobs = tensor([[ -1.3548, -12.8978],
        [ -7.1547,  -3.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46967220306396484
Epoch 0, Step 1024: train/loss = 0.056243330240249634, train/raw-loss = 0.011173781007528305, train/logprobs = tensor([[ -1.8001, -12.0189],
        [ -6.1929,  -2.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4506954550743103
Epoch 0, Step 1025: train/loss = 0.06441986560821533, train/raw-loss = 0.030248181894421577, train/logprobs = tensor([[ -0.8100, -10.2236],
        [ -4.9827,  -1.8623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3417168855667114
Epoch 0, Step 1026: train/loss = 0.1529209017753601, train/raw-loss = 0.1091490164399147, train/logprobs = tensor([[-2.4120, -6.2229],
        [-6.9540, -3.1916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43771886825561523
Epoch 0, Step 1027: train/loss = 0.05776675045490265, train/raw-loss = 0.012172408401966095, train/logprobs = tensor([[ -1.3681, -10.3073],
        [ -6.9033,  -2.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45594337582588196
Epoch 0, Step 1028: train/loss = 0.09142287820577621, train/raw-loss = 0.04926950857043266, train/logprobs = tensor([[-1.1327, -9.0530],
        [-5.0325, -2.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215336740016937
Epoch 0, Step 1029: train/loss = 0.050497815012931824, train/raw-loss = 0.008923429995775223, train/logprobs = tensor([[ -1.4633, -12.0692],
        [ -6.4369,  -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41574379801750183
Epoch 0, Step 1030: train/loss = 0.11149347573518753, train/raw-loss = 0.06673748791217804, train/logprobs = tensor([[-1.0549, -9.1513],
        [-5.3789, -2.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4475599527359009
Epoch 0, Step 1031: train/loss = 0.09067177772521973, train/raw-loss = 0.05402809754014015, train/logprobs = tensor([[-0.8448, -6.9618],
        [-4.3153, -1.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36643680930137634
Epoch 0, Step 1032: train/loss = 0.05448396876454353, train/raw-loss = 0.013544182293117046, train/logprobs = tensor([[-1.0616, -8.5650],
        [-5.7330, -2.3967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4093979001045227
Epoch 0, Step 1033: train/loss = 0.05537921562790871, train/raw-loss = 0.013936413452029228, train/logprobs = tensor([[-1.5653, -8.7474],
        [-5.9660, -2.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4144280254840851
Epoch 0, Step 1034: train/loss = 0.10344871878623962, train/raw-loss = 0.06811676919460297, train/logprobs = tensor([[-0.7405, -4.9105],
        [-5.2325, -1.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533194065093994
Epoch 0, Step 1035: train/loss = 0.05317029729485512, train/raw-loss = 0.006587115116417408, train/logprobs = tensor([[ -1.1320, -10.2062],
        [ -6.4361,  -2.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46583181619644165
Epoch 0, Step 1036: train/loss = 0.07360434532165527, train/raw-loss = 0.03134887292981148, train/logprobs = tensor([[-1.0097, -7.2110],
        [-6.0674, -1.0821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42255470156669617
Epoch 0, Step 1037: train/loss = 0.057163313031196594, train/raw-loss = 0.014221804216504097, train/logprobs = tensor([[-1.2260, -7.2577],
        [-6.5406, -2.2484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4294150471687317
Epoch 0, Step 1038: train/loss = 0.08889582753181458, train/raw-loss = 0.04672177508473396, train/logprobs = tensor([[-1.1118, -8.6723],
        [-4.7587, -3.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42174047231674194
Epoch 0, Step 1039: train/loss = 0.1792183816432953, train/raw-loss = 0.13475863635540009, train/logprobs = tensor([[-0.9919, -9.5735],
        [-4.3676, -2.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.444597452878952
Epoch 0, Step 1040: train/loss = 0.055654145777225494, train/raw-loss = 0.015420440584421158, train/logprobs = tensor([[-1.1994, -8.9952],
        [-8.0917, -2.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40233704447746277
Epoch 0, Step 1041: train/loss = 0.05902181565761566, train/raw-loss = 0.02054346725344658, train/logprobs = tensor([[-0.9690, -8.7233],
        [-5.7943, -1.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38478347659111023
Epoch 0, Step 1042: train/loss = 0.05814996361732483, train/raw-loss = 0.01292538270354271, train/logprobs = tensor([[-1.4103, -9.6678],
        [-7.1510, -2.6473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.452245831489563
Epoch 0, Step 1043: train/loss = 0.05928441137075424, train/raw-loss = 0.020040573552250862, train/logprobs = tensor([[-1.0988, -8.5802],
        [-4.9732, -1.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924383521080017
Epoch 0, Step 1044: train/loss = 0.05119917169213295, train/raw-loss = 0.010333278216421604, train/logprobs = tensor([[ -1.1363, -10.2562],
        [ -6.1220,  -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4086589217185974
Epoch 0, Step 1045: train/loss = 0.05366729199886322, train/raw-loss = 0.0088249696418643, train/logprobs = tensor([[-1.3290, -8.5975],
        [-6.2741, -1.5295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44842323660850525
Epoch 0, Step 1046: train/loss = 0.04796448349952698, train/raw-loss = 0.003425769042223692, train/logprobs = tensor([[ -1.3186, -12.0736],
        [ -7.2147,  -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4453870952129364
Epoch 0, Step 1047: train/loss = 0.27850914001464844, train/raw-loss = 0.2406575232744217, train/logprobs = tensor([[-0.9593, -5.3212],
        [-5.0923, -2.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3785162568092346
Epoch 0, Step 1048: train/loss = 0.060692306607961655, train/raw-loss = 0.007821726612746716, train/logprobs = tensor([[-1.2699, -9.9231],
        [-6.8255, -2.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5287058353424072
Epoch 0, Step 1049: train/loss = 0.05215257778763771, train/raw-loss = 0.014844288118183613, train/logprobs = tensor([[ -0.9340, -11.9162],
        [ -5.0076,  -1.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37308287620544434
Epoch 0, Step 1050: train/loss = 0.05385647714138031, train/raw-loss = 0.013630306348204613, train/logprobs = tensor([[-0.7719, -9.8897],
        [-4.6006, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4022616744041443
Epoch 0, Step 1051: train/loss = 0.060186948627233505, train/raw-loss = 0.018715303391218185, train/logprobs = tensor([[-0.9658, -9.1670],
        [-4.5547, -2.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4147164225578308
Epoch 0, Step 1052: train/loss = 0.05113828182220459, train/raw-loss = 0.0075641777366399765, train/logprobs = tensor([[ -1.2586, -10.2406],
        [ -6.2427,  -3.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43574103713035583
Epoch 0, Step 1053: train/loss = 0.06446308642625809, train/raw-loss = 0.019442927092313766, train/logprobs = tensor([[-2.1678, -7.8561],
        [-9.3922, -2.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4502016007900238
Epoch 0, Step 1054: train/loss = 0.05130879580974579, train/raw-loss = 0.009154148399829865, train/logprobs = tensor([[-1.7010, -7.8895],
        [-7.8093, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42154645919799805
Epoch 0, Step 1055: train/loss = 0.04838555306196213, train/raw-loss = 0.0041646938771009445, train/logprobs = tensor([[ -1.6586, -11.0038],
        [ -7.9493,  -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44220858812332153
Epoch 0, Step 1056: train/loss = 0.06463532149791718, train/raw-loss = 0.027312763035297394, train/logprobs = tensor([[-0.8639, -9.3876],
        [-4.2539, -1.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37322553992271423
Epoch 0, Step 1057: train/loss = 0.044427964836359024, train/raw-loss = 0.001110487268306315, train/logprobs = tensor([[ -1.4569, -10.3420],
        [ -7.9477,  -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4331747889518738
Epoch 0, Step 1058: train/loss = 0.05826635658740997, train/raw-loss = 0.020294006913900375, train/logprobs = tensor([[-1.2193, -8.4126],
        [-5.4144, -2.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37972351908683777
Epoch 0, Step 1059: train/loss = 0.056895188987255096, train/raw-loss = 0.01999952271580696, train/logprobs = tensor([[-0.6399, -8.6909],
        [-4.6912, -2.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36895665526390076
Epoch 0, Step 1060: train/loss = 0.054356649518013, train/raw-loss = 0.007333389949053526, train/logprobs = tensor([[-1.2017, -9.2175],
        [-6.9979, -2.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4702325463294983
Epoch 0, Step 1061: train/loss = 0.10798157751560211, train/raw-loss = 0.06396222859621048, train/logprobs = tensor([[-1.9320, -8.6377],
        [-8.8308, -2.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44019344449043274
Epoch 0, Step 1062: train/loss = 0.04470762237906456, train/raw-loss = 0.0044736359268426895, train/logprobs = tensor([[ -0.7526, -10.1246],
        [ -5.6575,  -1.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4023398756980896
Epoch 0, Step 1063: train/loss = 0.060972705483436584, train/raw-loss = 0.02078380435705185, train/logprobs = tensor([[-1.0788, -8.2810],
        [-6.3880, -1.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40188896656036377
Epoch 0, Step 1064: train/loss = 0.042804379016160965, train/raw-loss = 0.0015777165535837412, train/logprobs = tensor([[-1.3965, -9.7561],
        [-7.9521, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122666120529175
Epoch 0, Step 1065: train/loss = 0.15074460208415985, train/raw-loss = 0.1159755066037178, train/logprobs = tensor([[-1.0468, -7.0038],
        [-5.0142, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3476909399032593
Epoch 0, Step 1066: train/loss = 0.05943227559328079, train/raw-loss = 0.021256975829601288, train/logprobs = tensor([[-1.6269, -7.2797],
        [-6.8379, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38175296783447266
Epoch 0, Step 1067: train/loss = 0.04766543209552765, train/raw-loss = 0.010640215128660202, train/logprobs = tensor([[ -1.0972, -10.9851],
        [ -5.6559,  -1.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3702521324157715
Epoch 0, Step 1068: train/loss = 0.05656930431723595, train/raw-loss = 0.021934399381279945, train/logprobs = tensor([[ -0.8698, -10.3781],
        [ -5.1770,  -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3463490605354309
Epoch 0, Step 1069: train/loss = 0.08790366351604462, train/raw-loss = 0.05117310583591461, train/logprobs = tensor([[-1.1878, -8.8093],
        [-5.1985, -2.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36730554699897766
Epoch 0, Step 1070: train/loss = 0.0660802498459816, train/raw-loss = 0.023055871948599815, train/logprobs = tensor([[-1.2229, -8.4051],
        [-6.7983, -2.2769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4302437901496887
Epoch 0, Step 1071: train/loss = 0.059445641934871674, train/raw-loss = 0.020689770579338074, train/logprobs = tensor([[ -0.9687, -10.1817],
        [ -5.4564,  -2.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875586986541748
Epoch 0, Step 1072: train/loss = 0.055094797164201736, train/raw-loss = 0.016739489510655403, train/logprobs = tensor([[-1.1922, -7.4111],
        [-6.4716, -1.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38355305790901184
Epoch 0, Step 1073: train/loss = 0.05415278673171997, train/raw-loss = 0.014197859913110733, train/logprobs = tensor([[-1.5300, -7.2709],
        [-7.6244, -1.1940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3995492458343506
Epoch 0, Step 1074: train/loss = 0.07185177505016327, train/raw-loss = 0.03531436622142792, train/logprobs = tensor([[-1.7205, -7.6124],
        [-6.6765, -1.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36537405848503113
Epoch 0, Step 1075: train/loss = 0.04850463569164276, train/raw-loss = 0.007231950294226408, train/logprobs = tensor([[-1.1392, -8.6197],
        [-6.2349, -2.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41272687911987305
Epoch 0, Step 1076: train/loss = 0.06854988634586334, train/raw-loss = 0.0327807292342186, train/logprobs = tensor([[-1.4006, -8.6515],
        [-6.0137, -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35769158601760864
Epoch 0, Step 1077: train/loss = 0.045110419392585754, train/raw-loss = 0.004004297312349081, train/logprobs = tensor([[ -1.1714, -11.3500],
        [ -7.2943,  -1.5735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41106125712394714
Epoch 0, Step 1078: train/loss = 0.05645809322595596, train/raw-loss = 0.013353096321225166, train/logprobs = tensor([[-1.1418, -8.6790],
        [-6.1202, -2.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4310499429702759
Epoch 0, Step 1079: train/loss = 0.11644203215837479, train/raw-loss = 0.07473501563072205, train/logprobs = tensor([[-1.3510, -9.7409],
        [-5.3021, -2.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41707009077072144
Epoch 0, Step 1080: train/loss = 0.0728113055229187, train/raw-loss = 0.034853458404541016, train/logprobs = tensor([[-1.1105, -6.7234],
        [-4.9125, -2.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37957844138145447
Epoch 0, Step 1081: train/loss = 0.05500612407922745, train/raw-loss = 0.016177484765648842, train/logprobs = tensor([[ -1.2913, -10.1799],
        [ -6.4796,  -2.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3882863521575928
Epoch 0, Step 1082: train/loss = 0.060252197086811066, train/raw-loss = 0.019635744392871857, train/logprobs = tensor([[-1.2943, -9.9385],
        [-6.3210, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061644971370697
Epoch 0, Step 1083: train/loss = 0.07166720181703568, train/raw-loss = 0.034424055367708206, train/logprobs = tensor([[-0.8387, -6.6267],
        [-5.1222, -1.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3724314272403717
Epoch 0, Step 1084: train/loss = 0.04195399954915047, train/raw-loss = 0.002225446281954646, train/logprobs = tensor([[ -2.3331, -12.0835],
        [ -9.9539,  -2.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.397285521030426
Epoch 0, Step 1085: train/loss = 0.0469759926199913, train/raw-loss = 0.005208994727581739, train/logprobs = tensor([[ -1.0219, -11.4371],
        [ -5.9026,  -1.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41766995191574097
Epoch 0, Step 1086: train/loss = 0.047947388142347336, train/raw-loss = 0.008728130720555782, train/logprobs = tensor([[ -1.0638, -10.5336],
        [ -6.1322,  -2.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.392192542552948
Epoch 0, Step 1087: train/loss = 0.0907953754067421, train/raw-loss = 0.05126652494072914, train/logprobs = tensor([[-1.1485, -7.7845],
        [-7.1092, -2.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39528846740722656
Epoch 0, Step 1088: train/loss = 0.05493038520216942, train/raw-loss = 0.023694492876529694, train/logprobs = tensor([[ -1.0194, -10.4439],
        [ -4.9302,  -2.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31235891580581665
Epoch 0, Step 1089: train/loss = 0.06530630588531494, train/raw-loss = 0.020153747871518135, train/logprobs = tensor([[-1.6127, -8.2332],
        [-8.1095, -2.2811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4515255093574524
Epoch 0, Step 1090: train/loss = 0.05209539830684662, train/raw-loss = 0.013536255806684494, train/logprobs = tensor([[ -1.3050, -10.3688],
        [ -5.5512,  -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38559141755104065
Epoch 0, Step 1091: train/loss = 0.04900314658880234, train/raw-loss = 0.012788012623786926, train/logprobs = tensor([[ -0.8391, -10.5097],
        [ -5.6060,  -1.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36215129494667053
Epoch 0, Step 1092: train/loss = 0.048562295734882355, train/raw-loss = 0.008223423734307289, train/logprobs = tensor([[ -1.4159, -10.5917],
        [ -7.1339,  -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40338870882987976
Epoch 0, Step 1093: train/loss = 0.24777531623840332, train/raw-loss = 0.21171027421951294, train/logprobs = tensor([[-1.2154, -4.9336],
        [-4.2389, -1.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36065030097961426
Epoch 0, Step 1094: train/loss = 0.05726174637675285, train/raw-loss = 0.02145647257566452, train/logprobs = tensor([[-0.7840, -7.1905],
        [-4.6173, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35805273056030273
Epoch 0, Step 1095: train/loss = 0.0734492689371109, train/raw-loss = 0.04014510288834572, train/logprobs = tensor([[-1.1483, -6.4798],
        [-4.6764, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33304163813591003
Epoch 0, Step 1096: train/loss = 0.12483002990484238, train/raw-loss = 0.08646735548973083, train/logprobs = tensor([[-1.0808, -9.5424],
        [-6.0913, -2.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836267292499542
Epoch 0, Step 1097: train/loss = 0.04971308633685112, train/raw-loss = 0.009982430376112461, train/logprobs = tensor([[-1.2991, -9.4925],
        [-6.7590, -1.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39730656147003174
Epoch 0, Step 1098: train/loss = 0.07652004063129425, train/raw-loss = 0.04268426448106766, train/logprobs = tensor([[ -1.1677, -11.7555],
        [ -6.8852,  -1.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3383577764034271
Epoch 0, Step 1099: train/loss = 0.11780960857868195, train/raw-loss = 0.07757291197776794, train/logprobs = tensor([[-1.0945, -6.7489],
        [-4.2427, -2.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4023669362068176
Epoch 0, Step 1100: train/loss = 0.041870489716529846, train/raw-loss = 0.009134452790021896, train/logprobs = tensor([[-1.1717, -8.0785],
        [-6.1950, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273604214191437
Epoch 0, Step 1101: train/loss = 0.05226270481944084, train/raw-loss = 0.013569843955338001, train/logprobs = tensor([[ -1.1968, -11.1129],
        [ -6.2591,  -1.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38692858815193176
Epoch 0, Step 1102: train/loss = 0.04084654524922371, train/raw-loss = 0.0008248990634456277, train/logprobs = tensor([[ -1.9415, -10.4646],
        [ -8.9696,  -1.2042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40021640062332153
Epoch 0, Step 1103: train/loss = 0.0725117027759552, train/raw-loss = 0.03369932621717453, train/logprobs = tensor([[-0.5578, -7.0829],
        [-4.1122, -1.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3881237506866455
Epoch 0, Step 1104: train/loss = 0.06077383831143379, train/raw-loss = 0.021455584093928337, train/logprobs = tensor([[-1.6198, -9.7434],
        [-6.4401, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39318257570266724
Epoch 0, Step 1105: train/loss = 0.07859936356544495, train/raw-loss = 0.03988063707947731, train/logprobs = tensor([[-1.5576, -8.8891],
        [-7.0191, -1.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38718724250793457
Epoch 0, Step 1106: train/loss = 0.12760072946548462, train/raw-loss = 0.08918139338493347, train/logprobs = tensor([[-1.4896, -6.3854],
        [-5.6075, -2.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38419339060783386
Epoch 0, Step 1107: train/loss = 0.04458444193005562, train/raw-loss = 0.003650322090834379, train/logprobs = tensor([[-1.3865, -9.3090],
        [-7.3914, -1.8850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4093412160873413
Epoch 0, Step 1108: train/loss = 0.049430474638938904, train/raw-loss = 0.013563764281570911, train/logprobs = tensor([[-1.2687, -8.8790],
        [-6.7104, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586671054363251
Epoch 0, Step 1109: train/loss = 0.048947595059871674, train/raw-loss = 0.008552749641239643, train/logprobs = tensor([[ -1.6403, -11.7722],
        [ -6.1950,  -1.5106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40394845604896545
Epoch 0, Step 1110: train/loss = 0.06243550777435303, train/raw-loss = 0.02647014707326889, train/logprobs = tensor([[ -0.7412, -10.5328],
        [ -4.8551,  -2.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3596535623073578
Epoch 0, Step 1111: train/loss = 0.06285899132490158, train/raw-loss = 0.027664100751280785, train/logprobs = tensor([[-0.9185, -9.8177],
        [-4.5949, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35194888710975647
Epoch 0, Step 1112: train/loss = 0.05919387564063072, train/raw-loss = 0.01483379676938057, train/logprobs = tensor([[-1.1646, -7.8999],
        [-5.9578, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4436008036136627
Epoch 0, Step 1113: train/loss = 0.054354868829250336, train/raw-loss = 0.017157770693302155, train/logprobs = tensor([[-1.0100, -7.1357],
        [-5.5368, -0.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37197092175483704
Epoch 0, Step 1114: train/loss = 0.0787319466471672, train/raw-loss = 0.037813734263181686, train/logprobs = tensor([[-1.4725, -9.5659],
        [-7.8672, -1.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4091821610927582
Epoch 0, Step 1115: train/loss = 0.15742717683315277, train/raw-loss = 0.12198589742183685, train/logprobs = tensor([[-1.0039, -5.4561],
        [-4.6971, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35441282391548157
Epoch 0, Step 1116: train/loss = 0.059546470642089844, train/raw-loss = 0.019995061680674553, train/logprobs = tensor([[-0.8982, -9.1320],
        [-6.2293, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3955140709877014
Epoch 0, Step 1117: train/loss = 0.08335573971271515, train/raw-loss = 0.05256367847323418, train/logprobs = tensor([[-0.9272, -8.6532],
        [-4.6876, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079206347465515
Epoch 0, Step 1118: train/loss = 0.05817556381225586, train/raw-loss = 0.023077543824911118, train/logprobs = tensor([[-1.4391, -7.0181],
        [-5.1447, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3509802222251892
Epoch 0, Step 1119: train/loss = 0.047226421535015106, train/raw-loss = 0.005712965503334999, train/logprobs = tensor([[ -1.7184, -12.7243],
        [ -7.8940,  -2.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41513457894325256
Epoch 0, Step 1120: train/loss = 0.07064413279294968, train/raw-loss = 0.034892741590738297, train/logprobs = tensor([[ -1.1513, -10.7627],
        [ -5.2831,  -2.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3575139045715332
Epoch 0, Step 1121: train/loss = 0.06238787621259689, train/raw-loss = 0.023354241624474525, train/logprobs = tensor([[-1.3847, -9.3327],
        [-6.0696, -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3903363347053528
Epoch 0, Step 1122: train/loss = 0.09118277579545975, train/raw-loss = 0.05120110884308815, train/logprobs = tensor([[-1.6799, -8.2998],
        [-7.1400, -2.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39981675148010254
Epoch 0, Step 1123: train/loss = 0.0492619164288044, train/raw-loss = 0.010348401963710785, train/logprobs = tensor([[ -1.1432, -10.0487],
        [ -6.4843,  -1.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3891351819038391
Epoch 0, Step 1124: train/loss = 0.06082579493522644, train/raw-loss = 0.019366154447197914, train/logprobs = tensor([[-1.4268, -8.3006],
        [-5.7472, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41459640860557556
Epoch 0, Step 1125: train/loss = 0.07528004050254822, train/raw-loss = 0.04369838535785675, train/logprobs = tensor([[-1.3864, -7.5677],
        [-5.6544, -1.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31581658124923706
Epoch 0, Step 1126: train/loss = 0.05081867426633835, train/raw-loss = 0.019139211624860764, train/logprobs = tensor([[ -1.1991, -11.5493],
        [ -5.1688,  -1.3984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31679463386535645
Epoch 0, Step 1127: train/loss = 0.05998903140425682, train/raw-loss = 0.021204665303230286, train/logprobs = tensor([[ -0.8695, -10.1042],
        [ -4.7419,  -2.2703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38784363865852356
Epoch 0, Step 1128: train/loss = 0.06227078288793564, train/raw-loss = 0.02238035574555397, train/logprobs = tensor([[-1.1708, -7.6917],
        [-5.8792, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3989042341709137
Epoch 0, Step 1129: train/loss = 0.04954532906413078, train/raw-loss = 0.007456490304321051, train/logprobs = tensor([[ -1.1958, -11.2914],
        [ -7.1758,  -2.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42088836431503296
Epoch 0, Step 1130: train/loss = 0.054078735411167145, train/raw-loss = 0.016435619443655014, train/logprobs = tensor([[-0.9687, -9.3177],
        [-4.8763, -2.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3764311373233795
Epoch 0, Step 1131: train/loss = 0.07674634456634521, train/raw-loss = 0.037763550877571106, train/logprobs = tensor([[-1.5484, -6.7163],
        [-4.7818, -1.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3898279666900635
Epoch 0, Step 1132: train/loss = 0.04903433844447136, train/raw-loss = 0.016778921708464622, train/logprobs = tensor([[-0.6907, -8.9070],
        [-4.4489, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32255420088768005
Epoch 0, Step 1133: train/loss = 0.1362116038799286, train/raw-loss = 0.10104754567146301, train/logprobs = tensor([[-0.9479, -9.9799],
        [-3.3285, -4.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351640522480011
Epoch 0, Step 1134: train/loss = 0.05011829733848572, train/raw-loss = 0.009315884672105312, train/logprobs = tensor([[-1.1374, -9.8648],
        [-5.1845, -1.3438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4080241024494171
Epoch 0, Step 1135: train/loss = 0.06317655742168427, train/raw-loss = 0.028623709455132484, train/logprobs = tensor([[-1.4948, -8.9721],
        [-6.1779, -2.5697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455284535884857
Epoch 0, Step 1136: train/loss = 0.04557044804096222, train/raw-loss = 0.011877093464136124, train/logprobs = tensor([[ -2.2827, -12.6738],
        [ -8.0315,  -0.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33693352341651917
Epoch 0, Step 1137: train/loss = 0.11894252151250839, train/raw-loss = 0.0849280133843422, train/logprobs = tensor([[-1.6647, -4.8469],
        [-6.8021, -1.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401450216770172
Epoch 0, Step 1138: train/loss = 0.04336930066347122, train/raw-loss = 0.008879026398062706, train/logprobs = tensor([[-1.1723, -6.4815],
        [-6.0976, -1.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34490275382995605
Epoch 0, Step 1139: train/loss = 0.05390583723783493, train/raw-loss = 0.01713152974843979, train/logprobs = tensor([[-0.8150, -9.8469],
        [-5.2468, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36774304509162903
Epoch 0, Step 1140: train/loss = 0.04903095215559006, train/raw-loss = 0.016382597386837006, train/logprobs = tensor([[-1.0979, -9.9231],
        [-6.0772, -1.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3264835774898529
Epoch 0, Step 1141: train/loss = 0.07962112128734589, train/raw-loss = 0.04115394130349159, train/logprobs = tensor([[ -1.5445, -10.1060],
        [ -6.4873,  -2.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38467180728912354
Epoch 0, Step 1142: train/loss = 0.05298430472612381, train/raw-loss = 0.018495043739676476, train/logprobs = tensor([[-1.3710, -7.6978],
        [-5.7438, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34489262104034424
Epoch 0, Step 1143: train/loss = 0.07152289897203445, train/raw-loss = 0.03455546870827675, train/logprobs = tensor([[-1.4244, -9.7500],
        [-4.9696, -1.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36967432498931885
Epoch 0, Step 1144: train/loss = 0.07553645968437195, train/raw-loss = 0.0393216609954834, train/logprobs = tensor([[-1.2116, -7.1170],
        [-6.1763, -1.1829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3621480166912079
Epoch 0, Step 1145: train/loss = 0.07752823084592819, train/raw-loss = 0.0448959544301033, train/logprobs = tensor([[-0.9892, -7.7377],
        [-4.3833, -1.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3263227641582489
Epoch 0, Step 1146: train/loss = 0.08024010062217712, train/raw-loss = 0.0397619903087616, train/logprobs = tensor([[-1.4145, -6.4303],
        [-6.7208, -1.3355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047810435295105
Epoch 0, Step 1147: train/loss = 0.0740383118391037, train/raw-loss = 0.038586582988500595, train/logprobs = tensor([[-0.9777, -9.9147],
        [-4.9804, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35451728105545044
Epoch 0, Step 1148: train/loss = 0.0844225287437439, train/raw-loss = 0.0481872595846653, train/logprobs = tensor([[-1.0418, -6.9632],
        [-4.7472, -2.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36235272884368896
Epoch 0, Step 1149: train/loss = 0.05237821489572525, train/raw-loss = 0.01686226576566696, train/logprobs = tensor([[ -1.0360, -10.4093],
        [ -4.4154,  -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3551594614982605
Epoch 0, Step 1150: train/loss = 0.06171269714832306, train/raw-loss = 0.028355948626995087, train/logprobs = tensor([[-0.9063, -8.0972],
        [-5.4564, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33356747031211853
Epoch 0, Step 1151: train/loss = 0.053634725511074066, train/raw-loss = 0.017862768843770027, train/logprobs = tensor([[-1.0957, -8.0028],
        [-6.4851, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3577195405960083
Epoch 0, Step 1152: train/loss = 0.04360149800777435, train/raw-loss = 0.0054079764522612095, train/logprobs = tensor([[-1.9240, -8.4842],
        [-8.0094, -1.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3819352090358734
Epoch 0, Step 1153: train/loss = 0.05458468198776245, train/raw-loss = 0.020626753568649292, train/logprobs = tensor([[-1.4249, -8.8318],
        [-6.3335, -0.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3395792841911316
Epoch 0, Step 1154: train/loss = 0.05659341812133789, train/raw-loss = 0.016569320112466812, train/logprobs = tensor([[-1.7717, -9.7974],
        [-6.4791, -1.3115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.400240957736969
Epoch 0, Step 1155: train/loss = 0.07475873827934265, train/raw-loss = 0.03533560037612915, train/logprobs = tensor([[-1.1202, -9.6616],
        [-5.2117, -2.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.394231379032135
Epoch 0, Step 1156: train/loss = 0.06800276041030884, train/raw-loss = 0.031078383326530457, train/logprobs = tensor([[ -0.9491, -10.4068],
        [ -4.2178,  -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36924371123313904
Epoch 0, Step 1157: train/loss = 0.07223580777645111, train/raw-loss = 0.03627678379416466, train/logprobs = tensor([[-0.8069, -8.9585],
        [-4.8609, -1.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3595902919769287
Epoch 0, Step 1158: train/loss = 0.07024598121643066, train/raw-loss = 0.026834506541490555, train/logprobs = tensor([[-1.4940, -7.9960],
        [-6.4138, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4341147840023041
Epoch 0, Step 1159: train/loss = 0.06092720478773117, train/raw-loss = 0.023133765906095505, train/logprobs = tensor([[ -1.5624, -10.6599],
        [ -6.4143,  -2.3114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37793439626693726
Epoch 0, Step 1160: train/loss = 0.03952895849943161, train/raw-loss = 0.003248015185818076, train/logprobs = tensor([[ -1.6820, -10.0592],
        [ -7.7155,  -0.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362809419631958
Epoch 0, Step 1161: train/loss = 0.04888913035392761, train/raw-loss = 0.010295243933796883, train/logprobs = tensor([[-1.4526, -7.9387],
        [-6.9527, -1.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.385938823223114
Epoch 0, Step 1162: train/loss = 0.05212314799427986, train/raw-loss = 0.01008517574518919, train/logprobs = tensor([[-1.2038, -7.9925],
        [-6.3717, -2.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42037972807884216
Epoch 0, Step 1163: train/loss = 0.06541162729263306, train/raw-loss = 0.028864609077572823, train/logprobs = tensor([[-1.1435, -6.1320],
        [-5.6275, -1.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36547014117240906
Epoch 0, Step 1164: train/loss = 0.04613634943962097, train/raw-loss = 0.010271461680531502, train/logprobs = tensor([[-0.9616, -8.4719],
        [-5.3137, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586488962173462
Epoch 0, Step 1165: train/loss = 0.05448058992624283, train/raw-loss = 0.023237884044647217, train/logprobs = tensor([[ -1.1640, -11.1585],
        [ -6.7107,  -1.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124270439147949
Epoch 0, Step 1166: train/loss = 0.09578165411949158, train/raw-loss = 0.060064494609832764, train/logprobs = tensor([[-0.8768, -7.0157],
        [-4.6447, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35717153549194336
Epoch 0, Step 1167: train/loss = 0.049763794988393784, train/raw-loss = 0.018105898052453995, train/logprobs = tensor([[-1.3255, -9.7524],
        [-5.6204, -0.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3165789544582367
Epoch 0, Step 1168: train/loss = 0.11040055751800537, train/raw-loss = 0.07914278656244278, train/logprobs = tensor([[ -2.1407, -10.2864],
        [ -5.5406,  -1.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125777542591095
Epoch 0, Step 1169: train/loss = 0.06552420556545258, train/raw-loss = 0.029125813394784927, train/logprobs = tensor([[-1.0310, -9.0718],
        [-4.6627, -1.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3639839291572571
Epoch 0, Step 1170: train/loss = 0.0886940136551857, train/raw-loss = 0.058553021401166916, train/logprobs = tensor([[-1.1846, -9.5072],
        [-3.8280, -1.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3014099597930908
Epoch 0, Step 1171: train/loss = 0.046546295285224915, train/raw-loss = 0.01419759914278984, train/logprobs = tensor([[-0.8948, -9.6417],
        [-4.9293, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32348695397377014
Epoch 0, Step 1172: train/loss = 0.118792325258255, train/raw-loss = 0.08898252248764038, train/logprobs = tensor([[-0.7328, -8.5397],
        [-3.0996, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29809796810150146
Epoch 0, Step 1173: train/loss = 0.07395551353693008, train/raw-loss = 0.03910541906952858, train/logprobs = tensor([[-1.5504, -7.6670],
        [-5.7071, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34850093722343445
Epoch 0, Step 1174: train/loss = 0.06754918396472931, train/raw-loss = 0.032858915627002716, train/logprobs = tensor([[-1.2126, -8.7297],
        [-4.8713, -1.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469027280807495
Epoch 0, Step 1175: train/loss = 0.09883764386177063, train/raw-loss = 0.06374330818653107, train/logprobs = tensor([[-0.9509, -7.8743],
        [-4.4950, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3509434759616852
Epoch 0, Step 1176: train/loss = 0.06394384056329727, train/raw-loss = 0.028893260285258293, train/logprobs = tensor([[-1.1325, -8.4732],
        [-4.6014, -2.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3505058288574219
Epoch 0, Step 1177: train/loss = 0.07522977888584137, train/raw-loss = 0.039955273270606995, train/logprobs = tensor([[ -1.3597, -11.1720],
        [ -4.6250,  -2.3801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35274505615234375
Epoch 0, Step 1178: train/loss = 0.06197185814380646, train/raw-loss = 0.02777228318154812, train/logprobs = tensor([[-0.7999, -8.5391],
        [-4.7355, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3419957756996155
Epoch 0, Step 1179: train/loss = 0.055376969277858734, train/raw-loss = 0.017420068383216858, train/logprobs = tensor([[-1.4237, -9.7345],
        [-7.1131, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37956899404525757
Epoch 0, Step 1180: train/loss = 0.17557372152805328, train/raw-loss = 0.14105097949504852, train/logprobs = tensor([[-0.8663, -8.0448],
        [-2.8241, -2.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3452274203300476
Epoch 0, Step 1181: train/loss = 0.08006443083286285, train/raw-loss = 0.050618648529052734, train/logprobs = tensor([[-1.0748, -5.7655],
        [-3.8538, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29445791244506836
Epoch 0, Step 1182: train/loss = 0.05912616848945618, train/raw-loss = 0.023892221972346306, train/logprobs = tensor([[ -0.8500, -10.1460],
        [ -4.0950,  -1.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523394763469696
Epoch 0, Step 1183: train/loss = 0.051345497369766235, train/raw-loss = 0.01271292194724083, train/logprobs = tensor([[ -1.5597, -10.1616],
        [ -6.2474,  -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3863257169723511
Epoch 0, Step 1184: train/loss = 0.08373910933732986, train/raw-loss = 0.05121220275759697, train/logprobs = tensor([[-1.2227, -7.5596],
        [-4.9066, -1.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3252689838409424
Epoch 0, Step 1185: train/loss = 0.05492280796170235, train/raw-loss = 0.022477710619568825, train/logprobs = tensor([[-1.6220, -7.5565],
        [-5.6576, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244509696960449
Epoch 0, Step 1186: train/loss = 0.052869878709316254, train/raw-loss = 0.015506943687796593, train/logprobs = tensor([[ -1.4590, -10.5931],
        [ -5.9610,  -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3736293911933899
Epoch 0, Step 1187: train/loss = 0.12064190953969955, train/raw-loss = 0.09519721567630768, train/logprobs = tensor([[-0.5819, -7.4922],
        [-2.3036, -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25444692373275757
Epoch 0, Step 1188: train/loss = 0.05448836833238602, train/raw-loss = 0.022828634828329086, train/logprobs = tensor([[-1.0865, -7.5776],
        [-4.9520, -0.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3165973424911499
Epoch 0, Step 1189: train/loss = 0.06801165640354156, train/raw-loss = 0.028928395360708237, train/logprobs = tensor([[ -0.9693, -10.0350],
        [ -5.1165,  -1.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908326029777527
Epoch 0, Step 1190: train/loss = 0.0794316828250885, train/raw-loss = 0.04805200919508934, train/logprobs = tensor([[-1.3352, -6.5590],
        [-5.3149, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137966990470886
Epoch 0, Step 1191: train/loss = 0.05243438854813576, train/raw-loss = 0.019364217296242714, train/logprobs = tensor([[-1.2335, -9.1941],
        [-4.8219, -1.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33070170879364014
Epoch 0, Step 1192: train/loss = 0.04317350685596466, train/raw-loss = 0.004816190339624882, train/logprobs = tensor([[ -1.5996, -10.0386],
        [ -7.3536,  -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38357317447662354
Epoch 0, Step 1193: train/loss = 0.058789171278476715, train/raw-loss = 0.02905670925974846, train/logprobs = tensor([[-0.7570, -7.5999],
        [-3.8500, -0.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29732459783554077
Epoch 0, Step 1194: train/loss = 0.08986083418130875, train/raw-loss = 0.05651871860027313, train/logprobs = tensor([[-1.0566, -7.7713],
        [-4.8059, -1.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33342117071151733
Epoch 0, Step 1195: train/loss = 0.07127620279788971, train/raw-loss = 0.03650476038455963, train/logprobs = tensor([[-1.5589, -8.1017],
        [-4.7217, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477144241333008
Epoch 0, Step 1196: train/loss = 0.08822458237409592, train/raw-loss = 0.05199454724788666, train/logprobs = tensor([[-1.3092, -7.2729],
        [-4.1354, -1.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3623002767562866
Epoch 0, Step 1197: train/loss = 0.04911158233880997, train/raw-loss = 0.008122704923152924, train/logprobs = tensor([[-1.9563, -8.0582],
        [-7.1479, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40988874435424805
Epoch 0, Step 1198: train/loss = 0.051176175475120544, train/raw-loss = 0.015083204954862595, train/logprobs = tensor([[-1.5922, -7.1366],
        [-6.7994, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609296679496765
Epoch 0, Step 1199: train/loss = 0.079880490899086, train/raw-loss = 0.03865358233451843, train/logprobs = tensor([[-1.2748, -8.7666],
        [-4.6774, -1.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41226911544799805
Epoch 0, Step 1200: train/loss = 0.0955071747303009, train/raw-loss = 0.06425347924232483, train/logprobs = tensor([[ -1.4374, -10.2194],
        [ -5.2812,  -1.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31253695487976074
Epoch 0, Step 1201: train/loss = 0.07750947028398514, train/raw-loss = 0.038660235702991486, train/logprobs = tensor([[-1.7285, -7.0500],
        [-4.7780, -1.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38849231600761414
Epoch 0, Step 1202: train/loss = 0.039947882294654846, train/raw-loss = 0.0022249496541917324, train/logprobs = tensor([[-2.1351, -8.2185],
        [-8.6022, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37722936272621155
Epoch 0, Step 1203: train/loss = 0.057620272040367126, train/raw-loss = 0.01809239387512207, train/logprobs = tensor([[-1.2822, -9.4196],
        [-5.0633, -1.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3952787518501282
Epoch 0, Step 1204: train/loss = 0.06134633719921112, train/raw-loss = 0.030256636440753937, train/logprobs = tensor([[-1.0380, -7.0760],
        [-5.5617, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31089702248573303
Epoch 0, Step 1205: train/loss = 0.10695337504148483, train/raw-loss = 0.07400110363960266, train/logprobs = tensor([[-1.3382, -9.8335],
        [-4.3769, -2.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32952266931533813
Epoch 0, Step 1206: train/loss = 0.05461323261260986, train/raw-loss = 0.018738187849521637, train/logprobs = tensor([[-1.0469, -8.1242],
        [-5.0634, -1.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35875043272972107
Epoch 0, Step 1207: train/loss = 0.11851774901151657, train/raw-loss = 0.0852997675538063, train/logprobs = tensor([[-1.0066, -9.9721],
        [-2.9774, -2.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33217984437942505
Epoch 0, Step 1208: train/loss = 0.12234571576118469, train/raw-loss = 0.08960770815610886, train/logprobs = tensor([[-0.7659, -9.8588],
        [-2.8646, -2.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32738006114959717
Epoch 0, Step 1209: train/loss = 0.06799355149269104, train/raw-loss = 0.029083561152219772, train/logprobs = tensor([[-2.1619, -7.9078],
        [-6.9091, -1.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3890998661518097
Epoch 0, Step 1210: train/loss = 0.06113327294588089, train/raw-loss = 0.02779027260839939, train/logprobs = tensor([[ -1.0821, -11.2221],
        [ -5.0823,  -1.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334299921989441
Epoch 0, Step 1211: train/loss = 0.08885955065488815, train/raw-loss = 0.059146344661712646, train/logprobs = tensor([[-1.2223, -7.5677],
        [-4.3952, -1.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29713204503059387
Epoch 0, Step 1212: train/loss = 0.08327402174472809, train/raw-loss = 0.051885176450014114, train/logprobs = tensor([[-0.9631, -9.2499],
        [-3.5131, -1.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31388843059539795
Epoch 0, Step 1213: train/loss = 0.12922468781471252, train/raw-loss = 0.08804482966661453, train/logprobs = tensor([[-2.7400, -8.1793],
        [-7.2788, -1.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41179847717285156
Epoch 0, Step 1214: train/loss = 0.06077340990304947, train/raw-loss = 0.028413936495780945, train/logprobs = tensor([[-1.6060, -6.7060],
        [-6.1332, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32359474897384644
Epoch 0, Step 1215: train/loss = 0.04641621932387352, train/raw-loss = 0.009156469255685806, train/logprobs = tensor([[-1.8359, -9.2275],
        [-6.2535, -2.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37259748578071594
Epoch 0, Step 1216: train/loss = 0.16189728677272797, train/raw-loss = 0.13098576664924622, train/logprobs = tensor([[ -0.5977, -12.1070],
        [ -1.9942,  -2.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3091152012348175
Epoch 0, Step 1217: train/loss = 0.06739456951618195, train/raw-loss = 0.032463256269693375, train/logprobs = tensor([[-1.4362, -8.7070],
        [-6.1854, -1.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493131399154663
Epoch 0, Step 1218: train/loss = 0.041989296674728394, train/raw-loss = 0.004029577597975731, train/logprobs = tensor([[-1.5890, -9.3284],
        [-6.9645, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37959718704223633
Epoch 0, Step 1219: train/loss = 0.06035226956009865, train/raw-loss = 0.028106147423386574, train/logprobs = tensor([[-1.5486, -5.6970],
        [-5.9174, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32246118783950806
Epoch 0, Step 1220: train/loss = 0.0773506760597229, train/raw-loss = 0.04028768092393875, train/logprobs = tensor([[-1.6016, -7.3076],
        [-5.4592, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3706299662590027
Epoch 0, Step 1221: train/loss = 0.0905076190829277, train/raw-loss = 0.059858039021492004, train/logprobs = tensor([[-0.9084, -8.4933],
        [-3.3607, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064957857131958
Epoch 0, Step 1222: train/loss = 0.05985534191131592, train/raw-loss = 0.02870364487171173, train/logprobs = tensor([[-1.9384, -8.6101],
        [-6.6901, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31151697039604187
Epoch 0, Step 1223: train/loss = 0.051040083169937134, train/raw-loss = 0.019425222650170326, train/logprobs = tensor([[-1.1151, -9.5870],
        [-4.8646, -1.0820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3161486089229584
Epoch 0, Step 1224: train/loss = 0.05817146599292755, train/raw-loss = 0.02319202572107315, train/logprobs = tensor([[-1.1767, -8.7710],
        [-4.4789, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497944176197052
Epoch 0, Step 1225: train/loss = 0.04801921173930168, train/raw-loss = 0.015084592625498772, train/logprobs = tensor([[ -0.9556, -12.2114],
        [ -4.7066,  -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293461799621582
Epoch 0, Step 1226: train/loss = 0.0784757137298584, train/raw-loss = 0.04945745691657066, train/logprobs = tensor([[ -1.2703, -10.7339],
        [ -3.9854,  -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29018253087997437
Epoch 0, Step 1227: train/loss = 0.05251665785908699, train/raw-loss = 0.016540957614779472, train/logprobs = tensor([[ -0.9401, -11.0498],
        [ -4.5801,  -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3597570061683655
Epoch 0, Step 1228: train/loss = 0.16084903478622437, train/raw-loss = 0.13180232048034668, train/logprobs = tensor([[-1.0026, -7.3813],
        [-2.6802, -1.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.290467232465744
Epoch 0, Step 1229: train/loss = 0.08837296068668365, train/raw-loss = 0.05648236349225044, train/logprobs = tensor([[-0.8506, -9.7460],
        [-3.8700, -1.7794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3189059793949127
Epoch 0, Step 1230: train/loss = 0.07617665827274323, train/raw-loss = 0.04182393103837967, train/logprobs = tensor([[-1.1578, -9.1257],
        [-4.9879, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34352725744247437
Epoch 0, Step 1231: train/loss = 0.08821219950914383, train/raw-loss = 0.051904357969760895, train/logprobs = tensor([[-1.5705, -7.9868],
        [-5.0857, -1.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3630784749984741
Epoch 0, Step 1232: train/loss = 0.10204575210809708, train/raw-loss = 0.06591274589300156, train/logprobs = tensor([[-1.1476, -9.5103],
        [-5.0132, -1.2758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3613300919532776
Epoch 0, Step 1233: train/loss = 0.055968645960092545, train/raw-loss = 0.02897832915186882, train/logprobs = tensor([[ -0.9324, -11.2833],
        [ -4.2009,  -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26990318298339844
Epoch 0, Step 1234: train/loss = 0.06188671663403511, train/raw-loss = 0.029457684606313705, train/logprobs = tensor([[-1.2448, -9.1500],
        [-5.2062, -2.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32429030537605286
Epoch 0, Step 1235: train/loss = 0.0679803192615509, train/raw-loss = 0.03722013905644417, train/logprobs = tensor([[ -0.8756, -11.1055],
        [ -3.8221,  -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30760183930397034
Epoch 0, Step 1236: train/loss = 0.16253799200057983, train/raw-loss = 0.13018018007278442, train/logprobs = tensor([[-0.8759, -6.1989],
        [-2.4263, -1.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32357802987098694
Epoch 0, Step 1237: train/loss = 0.10434514284133911, train/raw-loss = 0.07317633181810379, train/logprobs = tensor([[-1.0481, -9.8335],
        [-3.4882, -1.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31168803572654724
Epoch 0, Step 1238: train/loss = 0.06829677522182465, train/raw-loss = 0.03594598546624184, train/logprobs = tensor([[-1.5172, -9.5186],
        [-5.2838, -0.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235079050064087
Epoch 0, Step 1239: train/loss = 0.08797906339168549, train/raw-loss = 0.053787969052791595, train/logprobs = tensor([[-0.9925, -9.0715],
        [-3.5400, -2.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3419109582901001
Epoch 0, Step 1240: train/loss = 0.08492209017276764, train/raw-loss = 0.05427923798561096, train/logprobs = tensor([[ -0.7504, -10.5692],
        [ -3.5841,  -1.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064284920692444
Epoch 0, Step 1241: train/loss = 0.04923218488693237, train/raw-loss = 0.008839250542223454, train/logprobs = tensor([[-1.4157, -7.8526],
        [-7.5515, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40392932295799255
Epoch 0, Step 1242: train/loss = 0.06878902018070221, train/raw-loss = 0.03650100529193878, train/logprobs = tensor([[-0.9378, -7.9031],
        [-4.0015, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228801488876343
Epoch 0, Step 1243: train/loss = 0.06540025770664215, train/raw-loss = 0.029638350009918213, train/logprobs = tensor([[-0.9260, -8.5308],
        [-4.7317, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.357619047164917
Epoch 0, Step 1244: train/loss = 0.1309071183204651, train/raw-loss = 0.09464983642101288, train/logprobs = tensor([[-1.0691, -8.5969],
        [-3.1748, -2.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36257290840148926
Epoch 0, Step 1245: train/loss = 0.05688917636871338, train/raw-loss = 0.02184705249965191, train/logprobs = tensor([[-1.2169, -6.0769],
        [-5.0398, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3504212200641632
Epoch 0, Step 1246: train/loss = 0.052160099148750305, train/raw-loss = 0.014765901491045952, train/logprobs = tensor([[-2.0602, -9.2751],
        [-6.9870, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3739420175552368
Epoch 0, Step 1247: train/loss = 0.08694740384817123, train/raw-loss = 0.055463846772909164, train/logprobs = tensor([[ -1.1997, -12.1931],
        [ -4.3938,  -2.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148355484008789
Epoch 0, Step 1248: train/loss = 0.08029457926750183, train/raw-loss = 0.050660863518714905, train/logprobs = tensor([[ -0.8486, -11.3756],
        [ -3.2782,  -0.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29633715748786926
Epoch 0, Step 1249: train/loss = 0.06255348026752472, train/raw-loss = 0.028430787846446037, train/logprobs = tensor([[ -0.7990, -10.9747],
        [ -4.8921,  -1.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3412269949913025
Epoch 0, Step 1250: train/loss = 0.06963938474655151, train/raw-loss = 0.031088685616850853, train/logprobs = tensor([[ -0.9323, -12.9657],
        [ -5.4084,  -1.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3855069875717163
Epoch 0, Step 1251: train/loss = 0.05191043019294739, train/raw-loss = 0.018424969166517258, train/logprobs = tensor([[-0.8048, -9.0946],
        [-5.0817, -1.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348546326160431
Epoch 0, Step 1252: train/loss = 0.1084439754486084, train/raw-loss = 0.07965989410877228, train/logprobs = tensor([[-1.0165, -7.0748],
        [-3.5873, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2878408133983612
Epoch 0, Step 1253: train/loss = 0.0533314123749733, train/raw-loss = 0.017758771777153015, train/logprobs = tensor([[-1.5746, -6.7080],
        [-6.8911, -1.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.355726420879364
Epoch 0, Step 1254: train/loss = 0.15794885158538818, train/raw-loss = 0.12677615880966187, train/logprobs = tensor([[-0.8137, -8.2231],
        [-3.0852, -1.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31172695755958557
Epoch 0, Step 1255: train/loss = 0.06500277668237686, train/raw-loss = 0.025996970012784004, train/logprobs = tensor([[ -1.4721, -11.0225],
        [ -6.4974,  -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3900579810142517
Epoch 0, Step 1256: train/loss = 0.07224652916193008, train/raw-loss = 0.03840773180127144, train/logprobs = tensor([[-1.0683, -9.1279],
        [-4.4863, -1.3734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33838799595832825
Epoch 0, Step 1257: train/loss = 0.059411171823740005, train/raw-loss = 0.028655268251895905, train/logprobs = tensor([[ -1.0054, -11.2782],
        [ -3.9585,  -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3075590431690216
Epoch 0, Step 1258: train/loss = 0.05414341762661934, train/raw-loss = 0.018909184262156487, train/logprobs = tensor([[ -0.9993, -12.7543],
        [ -4.5971,  -0.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35234230756759644
Epoch 0, Step 1259: train/loss = 0.04235367476940155, train/raw-loss = 0.0063700685277581215, train/logprobs = tensor([[-1.6372, -7.8868],
        [-7.1522, -1.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35983604192733765
Epoch 0, Step 1260: train/loss = 0.05823652818799019, train/raw-loss = 0.022731546312570572, train/logprobs = tensor([[-1.2072, -9.1601],
        [-6.0109, -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35504981875419617
Epoch 0, Step 1261: train/loss = 0.06877867877483368, train/raw-loss = 0.03910041227936745, train/logprobs = tensor([[-0.6572, -9.5725],
        [-3.2742, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967826724052429
Epoch 0, Step 1262: train/loss = 0.05357903614640236, train/raw-loss = 0.022867992520332336, train/logprobs = tensor([[-0.9282, -9.9304],
        [-4.7510, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30711042881011963
Epoch 0, Step 1263: train/loss = 0.04698219522833824, train/raw-loss = 0.0048833987675607204, train/logprobs = tensor([[ -1.1223, -11.3263],
        [ -6.0633,  -1.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42098796367645264
Epoch 0, Step 1264: train/loss = 0.06332297623157501, train/raw-loss = 0.031291164457798004, train/logprobs = tensor([[-0.7175, -8.2636],
        [-4.0097, -1.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3203180432319641
Epoch 0, Step 1265: train/loss = 0.05469822883605957, train/raw-loss = 0.016816429793834686, train/logprobs = tensor([[-1.5374, -7.9832],
        [-6.1095, -0.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3788180351257324
Epoch 0, Step 1266: train/loss = 0.10986921191215515, train/raw-loss = 0.07558460533618927, train/logprobs = tensor([[-1.3854, -6.8000],
        [-6.2842, -1.3845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428460955619812
Epoch 0, Step 1267: train/loss = 0.06812059134244919, train/raw-loss = 0.03678782284259796, train/logprobs = tensor([[ -1.0302, -11.4829],
        [ -5.2362,  -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3133276700973511
Epoch 0, Step 1268: train/loss = 0.03914759308099747, train/raw-loss = 0.0013779334258288145, train/logprobs = tensor([[ -1.5459, -10.3950],
        [ -7.9416,  -0.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37769660353660583
Epoch 0, Step 1269: train/loss = 0.07798097282648087, train/raw-loss = 0.04493710398674011, train/logprobs = tensor([[-1.0164, -8.2038],
        [-4.9543, -0.4608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3304387032985687
Epoch 0, Step 1270: train/loss = 0.06185851991176605, train/raw-loss = 0.027082618325948715, train/logprobs = tensor([[-0.9735, -8.3755],
        [-4.3255, -0.8470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477590084075928
Epoch 0, Step 1271: train/loss = 0.07738576084375381, train/raw-loss = 0.04297696053981781, train/logprobs = tensor([[-1.6483, -7.0918],
        [-6.0171, -1.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34408801794052124
Epoch 0, Step 1272: train/loss = 0.060391686856746674, train/raw-loss = 0.025216849520802498, train/logprobs = tensor([[-1.3453, -8.4606],
        [-5.2369, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35174834728240967
Epoch 0, Step 1273: train/loss = 0.09183703362941742, train/raw-loss = 0.062481220811605453, train/logprobs = tensor([[-0.6711, -9.8945],
        [-3.0127, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2935580611228943
Epoch 0, Step 1274: train/loss = 0.043556585907936096, train/raw-loss = 0.014654616825282574, train/logprobs = tensor([[-1.0479, -9.2427],
        [-5.2452, -1.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28901970386505127
Epoch 0, Step 1275: train/loss = 0.05908110737800598, train/raw-loss = 0.02809108793735504, train/logprobs = tensor([[ -1.0678, -10.2763],
        [ -4.6034,  -0.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.309900164604187
Epoch 0, Step 1276: train/loss = 0.06632766127586365, train/raw-loss = 0.0311948973685503, train/logprobs = tensor([[-1.0627, -9.8620],
        [-4.8703, -1.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35132765769958496
Epoch 0, Step 1277: train/loss = 0.06583496928215027, train/raw-loss = 0.03145647421479225, train/logprobs = tensor([[-1.0161, -8.6654],
        [-4.6798, -1.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437848687171936
Epoch 0, Step 1278: train/loss = 0.06466670334339142, train/raw-loss = 0.03352944925427437, train/logprobs = tensor([[ -0.9386, -10.2264],
        [ -6.0422,  -1.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3113724887371063
Epoch 0, Step 1279: train/loss = 0.1312635987997055, train/raw-loss = 0.09239089488983154, train/logprobs = tensor([[-1.0952, -6.4251],
        [-4.9220, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38872697949409485
Epoch 0, Step 1280: train/loss = 0.046172138303518295, train/raw-loss = 0.010403875261545181, train/logprobs = tensor([[ -0.8825, -10.1999],
        [ -5.3839,  -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35768258571624756
Epoch 0, Step 1281: train/loss = 0.05924012511968613, train/raw-loss = 0.026473145931959152, train/logprobs = tensor([[-0.6845, -8.9885],
        [-3.9320, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32766979932785034
Epoch 0, Step 1282: train/loss = 0.07436248660087585, train/raw-loss = 0.03946521505713463, train/logprobs = tensor([[-1.2305, -5.5345],
        [-6.0545, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34897276759147644
Epoch 0, Step 1283: train/loss = 0.050977759063243866, train/raw-loss = 0.01501467451453209, train/logprobs = tensor([[-1.2964, -7.7655],
        [-6.0062, -1.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35963088274002075
Epoch 0, Step 1284: train/loss = 0.04793562367558479, train/raw-loss = 0.013957904651761055, train/logprobs = tensor([[ -0.7213, -11.3062],
        [ -5.8200,  -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3397771716117859
Epoch 0, Step 1285: train/loss = 0.06108946353197098, train/raw-loss = 0.029741397127509117, train/logprobs = tensor([[-1.3167, -7.0841],
        [-5.5595, -0.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3134806752204895
Epoch 0, Step 1286: train/loss = 0.05401049554347992, train/raw-loss = 0.020984530448913574, train/logprobs = tensor([[-1.2327, -7.5223],
        [-5.4269, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33025965094566345
Epoch 0, Step 1287: train/loss = 0.0535774789750576, train/raw-loss = 0.02080332487821579, train/logprobs = tensor([[ -0.8203, -10.0641],
        [ -4.2324,  -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3277415633201599
Epoch 0, Step 1288: train/loss = 0.07368314266204834, train/raw-loss = 0.039585843682289124, train/logprobs = tensor([[-1.0263, -8.3869],
        [-4.8862, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3409729301929474
Epoch 0, Step 1289: train/loss = 0.04159660264849663, train/raw-loss = 0.003086634213104844, train/logprobs = tensor([[-1.4622, -7.8850],
        [-8.4823, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38509970903396606
Epoch 0, Step 1290: train/loss = 0.05272085592150688, train/raw-loss = 0.01579907163977623, train/logprobs = tensor([[-1.3333, -9.5673],
        [-6.3658, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692178428173065
Epoch 0, Step 1291: train/loss = 0.043164413422346115, train/raw-loss = 0.005116104613989592, train/logprobs = tensor([[-1.1817, -9.7956],
        [-7.0498, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38048309087753296
Epoch 0, Step 1292: train/loss = 0.052153926342725754, train/raw-loss = 0.014083841815590858, train/logprobs = tensor([[-1.0936, -8.3397],
        [-5.1107, -2.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807007968425751
Epoch 0, Step 1293: train/loss = 0.04642098397016525, train/raw-loss = 0.010202823206782341, train/logprobs = tensor([[ -1.6543, -13.7978],
        [ -6.7411,  -2.4418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3621816039085388
Epoch 0, Step 1294: train/loss = 0.39119836688041687, train/raw-loss = 0.35725137591362, train/logprobs = tensor([[-2.3147, -8.6544],
        [-6.3246, -0.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33946990966796875
Epoch 0, Step 1295: train/loss = 0.05421855300664902, train/raw-loss = 0.018894270062446594, train/logprobs = tensor([[-1.3383, -8.7981],
        [-6.2896, -0.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35324281454086304
Epoch 0, Step 1296: train/loss = 0.0701054185628891, train/raw-loss = 0.03626589477062225, train/logprobs = tensor([[-0.9717, -7.9476],
        [-3.8017, -1.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33839526772499084
Epoch 0, Step 1297: train/loss = 0.05743291601538658, train/raw-loss = 0.023476801812648773, train/logprobs = tensor([[-0.9994, -8.2260],
        [-5.8473, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3395611643791199
Epoch 0, Step 1298: train/loss = 0.05053945258259773, train/raw-loss = 0.018399721011519432, train/logprobs = tensor([[ -0.9215, -17.4542],
        [ -5.0615,  -3.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213973641395569
Epoch 0, Step 1299: train/loss = 0.043782979249954224, train/raw-loss = 0.013096971437335014, train/logprobs = tensor([[-1.4834, -9.4878],
        [-5.3172, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306860089302063
Epoch 0, Step 1300: train/loss = 0.05278196185827255, train/raw-loss = 0.022572536021471024, train/logprobs = tensor([[-1.3244, -9.3183],
        [-6.1045, -1.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020942211151123
Epoch 0, Step 1301: train/loss = 0.06572496145963669, train/raw-loss = 0.03592175990343094, train/logprobs = tensor([[-0.6772, -8.4855],
        [-3.8729, -1.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2980320453643799
Epoch 0, Step 1302: train/loss = 0.04252155125141144, train/raw-loss = 0.0007826568325981498, train/logprobs = tensor([[ -1.9351, -10.2076],
        [ -9.3706,  -1.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.417388916015625
Epoch 0, Step 1303: train/loss = 0.06876902282238007, train/raw-loss = 0.03527151420712471, train/logprobs = tensor([[-1.0569, -9.4528],
        [-4.8029, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33497509360313416
Epoch 0, Step 1304: train/loss = 0.04152942821383476, train/raw-loss = 0.007659556344151497, train/logprobs = tensor([[ -2.2396, -12.9812],
        [ -7.7870,  -1.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33869868516921997
Epoch 0, Step 1305: train/loss = 0.05269648879766464, train/raw-loss = 0.022079404443502426, train/logprobs = tensor([[-0.8152, -9.3903],
        [-4.6037, -1.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30617082118988037
Epoch 0, Step 1306: train/loss = 0.04713697358965874, train/raw-loss = 0.0134746003895998, train/logprobs = tensor([[ -0.9775, -10.5113],
        [ -4.9814,  -1.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3366237282752991
Epoch 0, Step 1307: train/loss = 0.05145428702235222, train/raw-loss = 0.017938360571861267, train/logprobs = tensor([[-1.0634, -9.1117],
        [-4.9112, -1.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351592421531677
Epoch 0, Step 1308: train/loss = 0.05405058711767197, train/raw-loss = 0.023063885048031807, train/logprobs = tensor([[-0.8215, -9.4965],
        [-4.7290, -1.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098669946193695
Epoch 0, Step 1309: train/loss = 0.040532730519771576, train/raw-loss = 0.0032529218588024378, train/logprobs = tensor([[ -1.6204, -11.2704],
        [ -8.0586,  -2.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727980852127075
Epoch 0, Step 1310: train/loss = 0.06282149255275726, train/raw-loss = 0.029474277049303055, train/logprobs = tensor([[-0.8791, -8.6914],
        [-4.5670, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3334721326828003
Epoch 0, Step 1311: train/loss = 0.042373061180114746, train/raw-loss = 0.005538583267480135, train/logprobs = tensor([[ -1.2312, -12.0314],
        [ -6.5465,  -2.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3683447539806366
Epoch 0, Step 1312: train/loss = 0.0701351910829544, train/raw-loss = 0.040241122245788574, train/logprobs = tensor([[ -0.6602, -11.3671],
        [ -3.4400,  -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989407181739807
Epoch 0, Step 1313: train/loss = 0.045860037207603455, train/raw-loss = 0.011300195008516312, train/logprobs = tensor([[ -0.7985, -12.6398],
        [ -5.2460,  -2.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34559839963912964
Epoch 0, Step 1314: train/loss = 0.10977302491664886, train/raw-loss = 0.07683297246694565, train/logprobs = tensor([[-1.8160, -9.1868],
        [-4.1947, -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294004797935486
Epoch 0, Step 1315: train/loss = 0.05064092576503754, train/raw-loss = 0.01666957139968872, train/logprobs = tensor([[-1.1485, -9.6645],
        [-5.0994, -1.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33971351385116577
Epoch 0, Step 1316: train/loss = 0.0447373129427433, train/raw-loss = 0.012594225816428661, train/logprobs = tensor([[ -1.3428, -11.1472],
        [ -6.6636,  -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32143089175224304
Epoch 0, Step 1317: train/loss = 0.05250430479645729, train/raw-loss = 0.013759946450591087, train/logprobs = tensor([[ -1.1443, -12.1385],
        [ -5.9974,  -1.2004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38744357228279114
Epoch 0, Step 1318: train/loss = 0.0470842681825161, train/raw-loss = 0.013377591967582703, train/logprobs = tensor([[-1.1629, -9.4429],
        [-8.0872, -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33706673979759216
Epoch 0, Step 1319: train/loss = 0.06645268201828003, train/raw-loss = 0.0294276662170887, train/logprobs = tensor([[-1.8328, -6.1112],
        [-6.3986, -1.2826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3702501952648163
Epoch 0, Step 1320: train/loss = 0.04451613128185272, train/raw-loss = 0.0063919322565197945, train/logprobs = tensor([[-1.3894, -9.2403],
        [-7.3111, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.381242036819458
Epoch 0, Step 1321: train/loss = 0.04701665788888931, train/raw-loss = 0.01393911987543106, train/logprobs = tensor([[-1.0824, -9.0842],
        [-5.3122, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33077535033226013
Epoch 0, Step 1322: train/loss = 0.04866990074515343, train/raw-loss = 0.01451777946203947, train/logprobs = tensor([[-0.9990, -9.2966],
        [-5.4358, -1.3841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3415212035179138
Epoch 0, Step 1323: train/loss = 0.051979340612888336, train/raw-loss = 0.021089043468236923, train/logprobs = tensor([[ -0.9218, -10.8742],
        [ -5.0788,  -1.3698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3089030086994171
Epoch 0, Step 1324: train/loss = 0.07933338731527328, train/raw-loss = 0.047088585793972015, train/logprobs = tensor([[-1.1214, -7.9081],
        [-3.9811, -2.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224480152130127
Epoch 0, Step 1325: train/loss = 0.04690735042095184, train/raw-loss = 0.013752276077866554, train/logprobs = tensor([[ -0.9953, -11.4182],
        [ -4.7448,  -1.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315507471561432
Epoch 0, Step 1326: train/loss = 0.05475978925824165, train/raw-loss = 0.019876526668667793, train/logprobs = tensor([[-1.2703, -7.3228],
        [-5.8242, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488326072692871
Epoch 0, Step 1327: train/loss = 0.06367553770542145, train/raw-loss = 0.028392642736434937, train/logprobs = tensor([[ -1.2149, -10.0865],
        [ -5.5973,  -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528289198875427
Epoch 0, Step 1328: train/loss = 0.05081580951809883, train/raw-loss = 0.012606973759829998, train/logprobs = tensor([[ -0.8233, -10.0057],
        [ -4.7474,  -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820883631706238
Epoch 0, Step 1329: train/loss = 0.06682686507701874, train/raw-loss = 0.03592473268508911, train/logprobs = tensor([[-0.9377, -7.3087],
        [-4.3962, -0.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30902135372161865
Epoch 0, Step 1330: train/loss = 0.03448072075843811, train/raw-loss = 0.00375118525698781, train/logprobs = tensor([[ -1.6067, -11.7639],
        [ -6.7935,  -0.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3072953224182129
Epoch 0, Step 1331: train/loss = 0.046362899243831635, train/raw-loss = 0.00976743083447218, train/logprobs = tensor([[-1.2547, -9.1614],
        [-6.6411, -2.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659546375274658
Epoch 0, Step 1332: train/loss = 0.04925470054149628, train/raw-loss = 0.014089764095842838, train/logprobs = tensor([[-0.8882, -9.5979],
        [-4.7008, -2.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35164934396743774
Epoch 0, Step 1333: train/loss = 0.054460007697343826, train/raw-loss = 0.02044832520186901, train/logprobs = tensor([[ -0.9962, -12.1484],
        [ -5.3939,  -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34011679887771606
Epoch 0, Step 1334: train/loss = 0.04971030354499817, train/raw-loss = 0.018116597086191177, train/logprobs = tensor([[ -0.9492, -10.1574],
        [ -4.5636,  -1.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159370422363281
Epoch 0, Step 1335: train/loss = 0.08496452867984772, train/raw-loss = 0.04526370018720627, train/logprobs = tensor([[ -1.3043, -10.5722],
        [ -5.9761,  -1.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3970082998275757
Epoch 0, Step 1336: train/loss = 0.06593616306781769, train/raw-loss = 0.030249297618865967, train/logprobs = tensor([[ -0.8388, -12.2514],
        [ -4.9222,  -1.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568686842918396
Epoch 0, Step 1337: train/loss = 0.05673960596323013, train/raw-loss = 0.02483939938247204, train/logprobs = tensor([[ -0.8931, -12.6200],
        [ -5.1761,  -1.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31900209188461304
Epoch 0, Step 1338: train/loss = 0.1309390515089035, train/raw-loss = 0.09491361677646637, train/logprobs = tensor([[-1.0616, -8.2048],
        [-5.1372, -1.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602544069290161
Epoch 0, Step 1339: train/loss = 0.05262018367648125, train/raw-loss = 0.01710832677781582, train/logprobs = tensor([[-1.0327, -8.1288],
        [-5.7030, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3551185727119446
Epoch 0, Step 1340: train/loss = 0.051161028444767, train/raw-loss = 0.018423158675432205, train/logprobs = tensor([[-1.0687, -8.2375],
        [-5.0176, -0.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32737866044044495
Epoch 0, Step 1341: train/loss = 0.06855099648237228, train/raw-loss = 0.03424457460641861, train/logprobs = tensor([[-0.8686, -8.0247],
        [-4.3930, -1.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34306424856185913
Epoch 0, Step 1342: train/loss = 0.050279729068279266, train/raw-loss = 0.012660928070545197, train/logprobs = tensor([[-1.6030, -8.4989],
        [-7.4055, -1.1888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3761879801750183
Epoch 0, Step 1343: train/loss = 0.03961716219782829, train/raw-loss = 0.004222601652145386, train/logprobs = tensor([[-1.0788, -8.9121],
        [-7.2912, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3539455831050873
Epoch 0, Step 1344: train/loss = 0.041176069527864456, train/raw-loss = 0.0052796583622694016, train/logprobs = tensor([[ -1.2926, -11.7676],
        [ -8.5875,  -0.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35896408557891846
Epoch 0, Step 1345: train/loss = 0.03851493448019028, train/raw-loss = 0.007655134424567223, train/logprobs = tensor([[-0.9140, -9.3212],
        [-5.4341, -1.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30859804153442383
Epoch 0, Step 1346: train/loss = 0.06106453388929367, train/raw-loss = 0.026316948235034943, train/logprobs = tensor([[-1.3309, -7.5431],
        [-5.8391, -1.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474757969379425
Epoch 0, Step 1347: train/loss = 0.059341371059417725, train/raw-loss = 0.02600005641579628, train/logprobs = tensor([[-1.1636, -9.8297],
        [-6.4021, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33341318368911743
Epoch 0, Step 1348: train/loss = 0.06910085678100586, train/raw-loss = 0.0335334911942482, train/logprobs = tensor([[ -1.0692, -10.3311],
        [ -5.5165,  -2.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35567358136177063
Epoch 0, Step 1349: train/loss = 0.0431048609316349, train/raw-loss = 0.005099262576550245, train/logprobs = tensor([[ -1.1838, -11.5584],
        [ -8.0909,  -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3800559341907501
Epoch 0, Step 1350: train/loss = 0.057724304497241974, train/raw-loss = 0.023929785937070847, train/logprobs = tensor([[ -0.7886, -10.6860],
        [ -4.8714,  -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3379451632499695
Epoch 0, Step 1351: train/loss = 0.05476568639278412, train/raw-loss = 0.018385741859674454, train/logprobs = tensor([[-1.0529, -9.1769],
        [-4.5659, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36379945278167725
Epoch 0, Step 1352: train/loss = 0.07423996925354004, train/raw-loss = 0.04059063270688057, train/logprobs = tensor([[-1.1006, -6.7674],
        [-5.8002, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364933729171753
Epoch 0, Step 1353: train/loss = 0.0676800087094307, train/raw-loss = 0.032648589462041855, train/logprobs = tensor([[-1.3188, -8.3786],
        [-4.9717, -1.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3503141701221466
Epoch 0, Step 1354: train/loss = 0.04277154058218002, train/raw-loss = 0.009663399308919907, train/logprobs = tensor([[-1.4349, -9.8866],
        [-6.2427, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310813903808594
Epoch 0, Step 1355: train/loss = 0.05130229890346527, train/raw-loss = 0.016304360702633858, train/logprobs = tensor([[ -0.8559, -10.2156],
        [ -4.6669,  -1.4005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3499794006347656
Epoch 0, Step 1356: train/loss = 0.0628129169344902, train/raw-loss = 0.02728227525949478, train/logprobs = tensor([[-0.9069, -7.7280],
        [-4.8949, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35530635714530945
Epoch 0, Step 1357: train/loss = 0.05365154892206192, train/raw-loss = 0.019351886585354805, train/logprobs = tensor([[ -1.0083, -11.8430],
        [ -4.8790,  -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34299662709236145
Epoch 0, Step 1358: train/loss = 0.04293261468410492, train/raw-loss = 0.00500301830470562, train/logprobs = tensor([[ -1.0657, -11.0294],
        [ -7.0068,  -2.3592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3792959451675415
Epoch 0, Step 1359: train/loss = 0.03654269874095917, train/raw-loss = 0.0006220847135409713, train/logprobs = tensor([[ -1.5353, -14.4308],
        [ -8.7053,  -2.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592061400413513
Epoch 0, Step 1360: train/loss = 0.0410337895154953, train/raw-loss = 0.0037176483310759068, train/logprobs = tensor([[ -1.6773, -10.2070],
        [ -7.0779,  -1.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3731614351272583
Epoch 0, Step 1361: train/loss = 0.04216714948415756, train/raw-loss = 0.004883129149675369, train/logprobs = tensor([[ -1.5044, -11.3845],
        [ -7.8388,  -1.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37284019589424133
Epoch 0, Step 1362: train/loss = 0.07140154391527176, train/raw-loss = 0.03939526900649071, train/logprobs = tensor([[-1.6476, -9.0345],
        [-6.6988, -2.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32006266713142395
Epoch 0, Step 1363: train/loss = 0.04968012496829033, train/raw-loss = 0.013447809033095837, train/logprobs = tensor([[ -1.0642, -10.5485],
        [ -5.6090,  -1.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36232316493988037
Epoch 0, Step 1364: train/loss = 0.04347461834549904, train/raw-loss = 0.0041310652159154415, train/logprobs = tensor([[ -1.4063, -12.2387],
        [ -6.9905,  -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3934355676174164
Epoch 0, Step 1365: train/loss = 0.055046819150447845, train/raw-loss = 0.024452779442071915, train/logprobs = tensor([[ -0.8032, -10.0022],
        [ -4.7082,  -1.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059403598308563
Epoch 0, Step 1366: train/loss = 0.05918194726109505, train/raw-loss = 0.020792538300156593, train/logprobs = tensor([[-1.0463, -8.8788],
        [-5.8821, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38389408588409424
Epoch 0, Step 1367: train/loss = 0.041816771030426025, train/raw-loss = 0.004399568773806095, train/logprobs = tensor([[ -1.4952, -10.2398],
        [ -7.6634,  -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3741719722747803
Epoch 0, Step 1368: train/loss = 0.05012115091085434, train/raw-loss = 0.015116196125745773, train/logprobs = tensor([[ -1.1856, -10.5735],
        [ -6.0719,  -1.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35004952549934387
Epoch 0, Step 1369: train/loss = 0.04229594022035599, train/raw-loss = 0.007521543651819229, train/logprobs = tensor([[ -1.3368, -10.7179],
        [ -5.5860,  -1.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477439880371094
Epoch 0, Step 1370: train/loss = 0.0433168038725853, train/raw-loss = 0.0089959017932415, train/logprobs = tensor([[-1.2408, -8.8453],
        [-6.8761, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3432089686393738
Epoch 0, Step 1371: train/loss = 0.09743474423885345, train/raw-loss = 0.06020768731832504, train/logprobs = tensor([[-1.6490, -6.8900],
        [-4.9021, -1.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3722705841064453
Epoch 0, Step 1372: train/loss = 0.058765608817338943, train/raw-loss = 0.021621588617563248, train/logprobs = tensor([[-1.2860, -9.1527],
        [-6.1402, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37144020199775696
Epoch 0, Step 1373: train/loss = 0.055265750735998154, train/raw-loss = 0.018188226968050003, train/logprobs = tensor([[-1.6658, -6.9085],
        [-7.4733, -1.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3707752227783203
Epoch 0, Step 1374: train/loss = 0.039547182619571686, train/raw-loss = 0.006592686753720045, train/logprobs = tensor([[ -1.4596, -10.5519],
        [ -6.2463,  -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32954496145248413
Epoch 0, Step 1375: train/loss = 0.045254483819007874, train/raw-loss = 0.009888957254588604, train/logprobs = tensor([[ -1.9377, -10.2798],
        [ -6.7034,  -1.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35365527868270874
Epoch 0, Step 1376: train/loss = 0.04149918258190155, train/raw-loss = 0.0037774378433823586, train/logprobs = tensor([[ -1.0024, -15.0443],
        [ -6.5971,  -2.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37721744179725647
Epoch 0, Step 1377: train/loss = 0.04006753861904144, train/raw-loss = 0.006240071728825569, train/logprobs = tensor([[-1.3601, -9.6897],
        [-6.3934, -0.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33827465772628784
Epoch 0, Step 1378: train/loss = 0.04741857945919037, train/raw-loss = 0.011539926752448082, train/logprobs = tensor([[-1.0915, -9.8564],
        [-6.3562, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587864935398102
Epoch 0, Step 1379: train/loss = 0.04321659356355667, train/raw-loss = 0.007218909449875355, train/logprobs = tensor([[ -1.3401, -10.1971],
        [ -7.8404,  -2.1863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3599768280982971
Epoch 0, Step 1380: train/loss = 0.06680861115455627, train/raw-loss = 0.0352620966732502, train/logprobs = tensor([[-0.8538, -7.8381],
        [-4.7637, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31546518206596375
Epoch 0, Step 1381: train/loss = 0.04643745720386505, train/raw-loss = 0.012684512883424759, train/logprobs = tensor([[-1.1848, -9.0811],
        [-5.4252, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3375294506549835
Epoch 0, Step 1382: train/loss = 0.04720965772867203, train/raw-loss = 0.012366892769932747, train/logprobs = tensor([[-1.2089, -7.8258],
        [-5.3394, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484276533126831
Epoch 0, Step 1383: train/loss = 0.04079169034957886, train/raw-loss = 0.003654390573501587, train/logprobs = tensor([[ -1.1417, -14.5963],
        [ -6.6077,  -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3713729977607727
Epoch 0, Step 1384: train/loss = 0.04102151840925217, train/raw-loss = 0.003465597750619054, train/logprobs = tensor([[ -1.6076, -12.3806],
        [ -7.5091,  -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3755592107772827
Epoch 0, Step 1385: train/loss = 0.04203461855649948, train/raw-loss = 0.0058018299750983715, train/logprobs = tensor([[ -0.9629, -12.5881],
        [ -5.5204,  -1.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3623278737068176
Epoch 0, Step 1386: train/loss = 0.04150308296084404, train/raw-loss = 0.00401016091927886, train/logprobs = tensor([[-1.8306, -8.3982],
        [-7.3024, -1.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3749292194843292
Epoch 0, Step 1387: train/loss = 0.03969547897577286, train/raw-loss = 0.004695089999586344, train/logprobs = tensor([[ -0.9531, -10.8184],
        [ -5.8304,  -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35000383853912354
Epoch 0, Step 1388: train/loss = 0.03838571161031723, train/raw-loss = 0.0040589733980596066, train/logprobs = tensor([[-1.3832, -8.7688],
        [-7.3722, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34326738119125366
Epoch 0, Step 1389: train/loss = 0.04033298045396805, train/raw-loss = 0.005536118522286415, train/logprobs = tensor([[ -1.0813, -12.6796],
        [ -6.6393,  -1.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479686379432678
Epoch 0, Step 1390: train/loss = 0.05066533386707306, train/raw-loss = 0.015972578898072243, train/logprobs = tensor([[-0.8394, -9.5715],
        [-5.2432, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34692755341529846
Epoch 0, Step 1391: train/loss = 0.05123103782534599, train/raw-loss = 0.015983302146196365, train/logprobs = tensor([[-1.0767, -6.7316],
        [-5.6339, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35247737169265747
Epoch 0, Step 1392: train/loss = 0.04130750149488449, train/raw-loss = 0.008149293251335621, train/logprobs = tensor([[ -0.9370, -10.5682],
        [ -5.7750,  -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33158209919929504
Epoch 0, Step 1393: train/loss = 0.04161917790770531, train/raw-loss = 0.008235517889261246, train/logprobs = tensor([[ -0.8383, -10.7696],
        [ -5.4744,  -0.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3338365852832794
Epoch 0, Step 1394: train/loss = 0.041377387940883636, train/raw-loss = 0.005866721272468567, train/logprobs = tensor([[ -1.4556, -12.3768],
        [ -6.4898,  -1.2739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3551066517829895
Epoch 0, Step 1395: train/loss = 0.04241577535867691, train/raw-loss = 0.005985829513520002, train/logprobs = tensor([[-1.4828, -8.7479],
        [-7.8703, -1.2883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364299476146698
Epoch 0, Step 1396: train/loss = 0.04112020879983902, train/raw-loss = 0.004810193087905645, train/logprobs = tensor([[-0.7794, -9.5741],
        [-6.9021, -1.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36310014128685
Epoch 0, Step 1397: train/loss = 0.043582238256931305, train/raw-loss = 0.008640964515507221, train/logprobs = tensor([[ -0.9956, -10.2379],
        [ -5.5887,  -1.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.349412739276886
Epoch 0, Step 1398: train/loss = 0.09761335700750351, train/raw-loss = 0.06441761553287506, train/logprobs = tensor([[-0.6876, -8.9707],
        [-3.3812, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319573998451233
Epoch 0, Step 1399: train/loss = 0.04995175078511238, train/raw-loss = 0.01567586325109005, train/logprobs = tensor([[-1.0718, -7.8409],
        [-5.9598, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34275883436203003
Epoch 0, Step 1400: train/loss = 0.045578502118587494, train/raw-loss = 0.01593872532248497, train/logprobs = tensor([[ -0.7824, -13.0257],
        [ -4.6694,  -1.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29639777541160583
Epoch 0, Step 1401: train/loss = 0.03994341567158699, train/raw-loss = 0.005116785876452923, train/logprobs = tensor([[ -1.4094, -13.9349],
        [ -7.6129,  -2.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3482663035392761
Epoch 0, Step 1402: train/loss = 0.03729327768087387, train/raw-loss = 0.00413004495203495, train/logprobs = tensor([[ -1.5056, -11.2247],
        [ -6.8243,  -1.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3316323161125183
Epoch 0, Step 1403: train/loss = 0.05275896191596985, train/raw-loss = 0.020625252276659012, train/logprobs = tensor([[-0.9667, -8.4346],
        [-5.6504, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32133710384368896
Epoch 0, Step 1404: train/loss = 0.04899962618947029, train/raw-loss = 0.01817093975841999, train/logprobs = tensor([[ -1.1301, -14.9081],
        [ -5.4500,  -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3082868456840515
Epoch 0, Step 1405: train/loss = 0.059826161712408066, train/raw-loss = 0.029021134600043297, train/logprobs = tensor([[-1.2025, -7.5556],
        [-5.9022, -1.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080502152442932
Epoch 0, Step 1406: train/loss = 0.05427771061658859, train/raw-loss = 0.02280585840344429, train/logprobs = tensor([[ -1.3413, -11.4114],
        [ -4.9355,  -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31471848487854004
Epoch 0, Step 1407: train/loss = 0.046370651572942734, train/raw-loss = 0.010623951442539692, train/logprobs = tensor([[-1.3319, -9.6349],
        [-6.8096, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35746702551841736
Epoch 0, Step 1408: train/loss = 0.05103626102209091, train/raw-loss = 0.01812206208705902, train/logprobs = tensor([[ -0.9339, -10.4490],
        [ -5.0455,  -1.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291420340538025
Epoch 0, Step 1409: train/loss = 0.04520850256085396, train/raw-loss = 0.007130758836865425, train/logprobs = tensor([[-1.8485, -8.4783],
        [-9.0624, -1.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38077741861343384
Epoch 0, Step 1410: train/loss = 0.04692130908370018, train/raw-loss = 0.009682060219347477, train/logprobs = tensor([[-1.3100, -7.2341],
        [-6.7014, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.372392475605011
Epoch 0, Step 1411: train/loss = 0.05245332419872284, train/raw-loss = 0.01653127558529377, train/logprobs = tensor([[-1.0598, -8.9994],
        [-5.1325, -2.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592204749584198
Epoch 0, Step 1412: train/loss = 0.051059987396001816, train/raw-loss = 0.017506569623947144, train/logprobs = tensor([[-1.1738, -9.3399],
        [-7.0317, -1.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33553409576416016
Epoch 0, Step 1413: train/loss = 0.04437529295682907, train/raw-loss = 0.012090282514691353, train/logprobs = tensor([[-0.7499, -8.6307],
        [-4.6754, -1.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228501081466675
Epoch 0, Step 1414: train/loss = 0.04440150782465935, train/raw-loss = 0.008427008986473083, train/logprobs = tensor([[ -0.7243, -11.8998],
        [ -4.9030,  -1.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35974496603012085
Epoch 0, Step 1415: train/loss = 0.05301378667354584, train/raw-loss = 0.017927445471286774, train/logprobs = tensor([[-1.2423, -6.2962],
        [-5.1541, -1.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35086339712142944
Epoch 0, Step 1416: train/loss = 0.042696092277765274, train/raw-loss = 0.007118928711861372, train/logprobs = tensor([[-1.4222, -8.9131],
        [-7.5174, -1.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35577163100242615
Epoch 0, Step 1417: train/loss = 0.04520467668771744, train/raw-loss = 0.0028276650700718164, train/logprobs = tensor([[ -0.9036, -10.0078],
        [ -6.4747,  -1.4602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42377009987831116
Epoch 0, Step 1418: train/loss = 0.06308184564113617, train/raw-loss = 0.0285036601126194, train/logprobs = tensor([[-1.0308, -6.3409],
        [-5.7570, -1.2151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457818627357483
Epoch 0, Step 1419: train/loss = 0.06682330369949341, train/raw-loss = 0.03722963109612465, train/logprobs = tensor([[-0.8425, -8.8810],
        [-4.5058, -1.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959367334842682
Epoch 0, Step 1420: train/loss = 0.04985828697681427, train/raw-loss = 0.016928620636463165, train/logprobs = tensor([[ -1.0631, -10.5820],
        [ -5.7421,  -1.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32929664850234985
Epoch 0, Step 1421: train/loss = 0.05245954543352127, train/raw-loss = 0.013821916654706001, train/logprobs = tensor([[-1.2619, -9.9411],
        [-6.3074, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3863762617111206
Epoch 0, Step 1422: train/loss = 0.05451836809515953, train/raw-loss = 0.017534133046865463, train/logprobs = tensor([[-1.3683, -9.9759],
        [-7.8697, -1.4623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3698423504829407
Epoch 0, Step 1423: train/loss = 0.06382907181978226, train/raw-loss = 0.026447121053934097, train/logprobs = tensor([[-1.5084, -5.5629],
        [-7.1635, -0.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3738195300102234
Epoch 0, Step 1424: train/loss = 0.044066376984119415, train/raw-loss = 0.0023594466038048267, train/logprobs = tensor([[-1.3681, -8.8166],
        [-8.1452, -1.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41706928610801697
Epoch 0, Step 1425: train/loss = 0.039582759141922, train/raw-loss = 0.0013454428408294916, train/logprobs = tensor([[ -1.3971, -10.0089],
        [ -8.4528,  -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3823731541633606
Epoch 0, Step 1426: train/loss = 0.043554436415433884, train/raw-loss = 0.005383272655308247, train/logprobs = tensor([[-1.0546, -8.6502],
        [-6.1652, -1.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3817116320133209
Epoch 0, Step 1427: train/loss = 0.044351134449243546, train/raw-loss = 0.009283393621444702, train/logprobs = tensor([[-0.9111, -9.2994],
        [-5.4349, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35067740082740784
Epoch 0, Step 1428: train/loss = 0.04984042048454285, train/raw-loss = 0.013702417723834515, train/logprobs = tensor([[-1.3527, -9.9619],
        [-5.5225, -1.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.361380010843277
Epoch 0, Step 1429: train/loss = 0.06093181297183037, train/raw-loss = 0.034330546855926514, train/logprobs = tensor([[-0.6675, -9.7367],
        [-4.3695, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26601266860961914
Epoch 0, Step 1430: train/loss = 0.08630084246397018, train/raw-loss = 0.053104519844055176, train/logprobs = tensor([[-1.1694, -9.4565],
        [-5.8339, -1.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319632411003113
Epoch 0, Step 1431: train/loss = 0.04913042485713959, train/raw-loss = 0.0186937153339386, train/logprobs = tensor([[ -0.7972, -10.2516],
        [ -4.4338,  -1.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043670654296875
Epoch 0, Step 1432: train/loss = 0.04430330544710159, train/raw-loss = 0.0021410284098237753, train/logprobs = tensor([[ -1.5276, -10.7960],
        [ -8.1334,  -1.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42162275314331055
Epoch 0, Step 1433: train/loss = 0.04444132745265961, train/raw-loss = 0.008209292776882648, train/logprobs = tensor([[-1.4160, -8.8172],
        [-6.8094, -0.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36232033371925354
Epoch 0, Step 1434: train/loss = 0.13693159818649292, train/raw-loss = 0.09799983352422714, train/logprobs = tensor([[-2.8496, -9.1287],
        [-8.0338, -2.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3893176019191742
Epoch 0, Step 1435: train/loss = 0.041578713804483414, train/raw-loss = 0.004484730772674084, train/logprobs = tensor([[ -1.1809, -11.4958],
        [ -7.2787,  -1.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37093982100486755
Epoch 0, Step 1436: train/loss = 0.06180740147829056, train/raw-loss = 0.028181081637740135, train/logprobs = tensor([[ -1.8105, -10.9807],
        [ -5.5277,  -1.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33626312017440796
Epoch 0, Step 1437: train/loss = 0.040823161602020264, train/raw-loss = 0.007551239337772131, train/logprobs = tensor([[ -0.8215, -11.7486],
        [ -5.6585,  -2.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33271917700767517
Epoch 0, Step 1438: train/loss = 0.04794544726610184, train/raw-loss = 0.014198738150298595, train/logprobs = tensor([[-2.2978, -8.0458],
        [-8.5273, -1.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374670743942261
Epoch 0, Step 1439: train/loss = 0.03732091188430786, train/raw-loss = 0.006842294707894325, train/logprobs = tensor([[ -1.1414, -13.1760],
        [ -5.7182,  -1.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30478617548942566
Epoch 0, Step 1440: train/loss = 0.04156647250056267, train/raw-loss = 0.0021776086650788784, train/logprobs = tensor([[ -0.9761, -10.8165],
        [ -7.3775,  -2.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39388859272003174
Epoch 0, Step 1441: train/loss = 0.039696842432022095, train/raw-loss = 0.007249206770211458, train/logprobs = tensor([[ -0.6892, -10.3808],
        [ -5.4102,  -1.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32447633147239685
Epoch 0, Step 1442: train/loss = 0.04549824818968773, train/raw-loss = 0.006225890014320612, train/logprobs = tensor([[ -0.7437, -10.8791],
        [ -5.6703,  -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39272359013557434
Epoch 0, Step 1443: train/loss = 0.04134535789489746, train/raw-loss = 0.00704538356512785, train/logprobs = tensor([[ -0.9534, -11.0526],
        [ -6.1783,  -2.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3429996967315674
Epoch 0, Step 1444: train/loss = 0.05716429650783539, train/raw-loss = 0.019716015085577965, train/logprobs = tensor([[-0.9688, -9.7046],
        [-5.4154, -2.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37448275089263916
Epoch 0, Step 1445: train/loss = 0.04006439819931984, train/raw-loss = 0.004646144807338715, train/logprobs = tensor([[-1.1617, -9.4635],
        [-6.9029, -1.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35418254137039185
Epoch 0, Step 1446: train/loss = 0.04633522033691406, train/raw-loss = 0.0064122797921299934, train/logprobs = tensor([[-1.7883, -9.8801],
        [-7.9853, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39922937750816345
Epoch 0, Step 1447: train/loss = 0.04765400290489197, train/raw-loss = 0.018329894170165062, train/logprobs = tensor([[ -1.2429, -11.4407],
        [ -5.5891,  -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29324105381965637
Epoch 0, Step 1448: train/loss = 0.04128839075565338, train/raw-loss = 0.003400389337912202, train/logprobs = tensor([[ -1.0314, -11.8220],
        [ -7.1233,  -2.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37887996435165405
Epoch 0, Step 1449: train/loss = 0.04410657286643982, train/raw-loss = 0.007314181886613369, train/logprobs = tensor([[-1.2719, -8.5351],
        [-8.5407, -1.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36792388558387756
Epoch 0, Step 1450: train/loss = 0.05344147980213165, train/raw-loss = 0.014681827276945114, train/logprobs = tensor([[-1.1587, -8.6726],
        [-6.7338, -1.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875964879989624
Epoch 0, Step 1451: train/loss = 0.04156136140227318, train/raw-loss = 0.0025331047363579273, train/logprobs = tensor([[ -1.4324, -10.7738],
        [ -9.3389,  -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3902825713157654
Epoch 0, Step 1452: train/loss = 0.044270407408475876, train/raw-loss = 0.004705535247921944, train/logprobs = tensor([[-1.2175, -7.6473],
        [-7.3235, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.395648717880249
Epoch 0, Step 1453: train/loss = 0.03939513862133026, train/raw-loss = 0.006369884591549635, train/logprobs = tensor([[ -1.9069, -11.8087],
        [ -8.0508,  -2.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3302525281906128
Epoch 0, Step 1454: train/loss = 0.04618358239531517, train/raw-loss = 0.014215366914868355, train/logprobs = tensor([[-1.5847, -7.1023],
        [-6.8706, -1.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31968212127685547
Epoch 0, Step 1455: train/loss = 0.05102751404047012, train/raw-loss = 0.016994884237647057, train/logprobs = tensor([[ -1.0444, -11.0019],
        [ -5.6494,  -1.7064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403262495994568
Epoch 0, Step 1456: train/loss = 0.04335727542638779, train/raw-loss = 0.004535418935120106, train/logprobs = tensor([[ -0.9635, -12.1466],
        [ -6.5573,  -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38821855187416077
Epoch 0, Step 1457: train/loss = 0.05011967942118645, train/raw-loss = 0.01952369138598442, train/logprobs = tensor([[-1.1557, -7.7371],
        [-5.5704, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30595988035202026
Epoch 0, Step 1458: train/loss = 0.09404455870389938, train/raw-loss = 0.060025569051504135, train/logprobs = tensor([[-0.7652, -7.8806],
        [-5.1959, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401898443698883
Epoch 0, Step 1459: train/loss = 0.06197505444288254, train/raw-loss = 0.02448945865035057, train/logprobs = tensor([[-1.5849, -8.0648],
        [-7.6936, -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37485596537590027
Epoch 0, Step 1460: train/loss = 0.033797793090343475, train/raw-loss = 0.0025615603663027287, train/logprobs = tensor([[ -1.5014, -12.2734],
        [ -8.6929,  -2.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31236234307289124
Epoch 0, Step 1461: train/loss = 0.042395852506160736, train/raw-loss = 0.004115680232644081, train/logprobs = tensor([[ -0.9271, -12.4665],
        [ -6.0339,  -3.0905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38280171155929565
Epoch 0, Step 1462: train/loss = 0.04683808609843254, train/raw-loss = 0.01202407106757164, train/logprobs = tensor([[ -1.3231, -10.2819],
        [ -6.9542,  -1.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3481401205062866
Epoch 0, Step 1463: train/loss = 0.041406817734241486, train/raw-loss = 0.004021863918751478, train/logprobs = tensor([[ -0.7870, -15.1021],
        [ -5.8122,  -2.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3738495409488678
Epoch 0, Step 1464: train/loss = 0.05386757105588913, train/raw-loss = 0.01848936453461647, train/logprobs = tensor([[-0.9830, -7.1089],
        [-5.4544, -2.0978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.353782057762146
Epoch 0, Step 1465: train/loss = 0.05399276688694954, train/raw-loss = 0.024610180407762527, train/logprobs = tensor([[ -0.6101, -14.0529],
        [ -3.7421,  -2.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938258647918701
Epoch 0, Step 1466: train/loss = 0.039513371884822845, train/raw-loss = 0.0012253652093932033, train/logprobs = tensor([[ -1.3452, -11.6076],
        [ -8.9498,  -1.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3828800320625305
Epoch 0, Step 1467: train/loss = 0.08444899320602417, train/raw-loss = 0.056762635707855225, train/logprobs = tensor([[-0.7892, -9.1876],
        [-3.3836, -1.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2768635153770447
Epoch 0, Step 1468: train/loss = 0.042258501052856445, train/raw-loss = 0.007374429143965244, train/logprobs = tensor([[ -1.7538, -12.8872],
        [ -7.3720,  -2.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34884074330329895
Epoch 0, Step 1469: train/loss = 0.041918717324733734, train/raw-loss = 0.0022799198050051928, train/logprobs = tensor([[ -1.1879, -10.0621],
        [ -7.3394,  -2.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3963879346847534
Epoch 0, Step 1470: train/loss = 0.044838447123765945, train/raw-loss = 0.005342686548829079, train/logprobs = tensor([[ -0.8108, -11.6368],
        [ -6.1460,  -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39495760202407837
Epoch 0, Step 1471: train/loss = 0.04186730831861496, train/raw-loss = 0.002476047957316041, train/logprobs = tensor([[-1.8490, -9.9305],
        [-7.7892, -1.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3939126431941986
Epoch 0, Step 1472: train/loss = 0.04838933050632477, train/raw-loss = 0.016890045255422592, train/logprobs = tensor([[-0.9644, -7.2320],
        [-5.6628, -1.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31499290466308594
Epoch 0, Step 1473: train/loss = 0.040415577590465546, train/raw-loss = 0.005291909445077181, train/logprobs = tensor([[ -1.3532, -11.2916],
        [ -8.6256,  -1.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3512366712093353
Epoch 0, Step 1474: train/loss = 0.06597482413053513, train/raw-loss = 0.02813767082989216, train/logprobs = tensor([[-1.0012, -8.8273],
        [-6.5280, -1.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3783714771270752
Epoch 0, Step 1475: train/loss = 0.036385562270879745, train/raw-loss = 0.00256128772161901, train/logprobs = tensor([[ -1.1957, -12.8670],
        [ -7.8432,  -1.3274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382427394390106
Epoch 0, Step 1476: train/loss = 0.04765629023313522, train/raw-loss = 0.010445600375533104, train/logprobs = tensor([[-1.2870, -9.3811],
        [-5.9086, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3721069097518921
Epoch 0, Step 1477: train/loss = 0.04180849343538284, train/raw-loss = 0.008451084606349468, train/logprobs = tensor([[-1.3030, -9.5976],
        [-6.2590, -2.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.333574116230011
Epoch 0, Step 1478: train/loss = 0.03811594098806381, train/raw-loss = 0.006291862577199936, train/logprobs = tensor([[ -1.2141, -14.1089],
        [ -6.3197,  -1.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318240761756897
Epoch 0, Step 1479: train/loss = 0.05569365993142128, train/raw-loss = 0.02287822961807251, train/logprobs = tensor([[-1.0270, -9.9679],
        [-6.0888, -1.8246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281543254852295
Epoch 0, Step 1480: train/loss = 0.044052593410015106, train/raw-loss = 0.0056862058117985725, train/logprobs = tensor([[ -0.9920, -10.7164],
        [ -5.9567,  -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836638629436493
Epoch 0, Step 1481: train/loss = 0.03300957381725311, train/raw-loss = 0.0007853333372622728, train/logprobs = tensor([[-1.3627, -8.9047],
        [-8.0408, -0.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3222423791885376
Epoch 0, Step 1482: train/loss = 0.0416763499379158, train/raw-loss = 0.002804806921631098, train/logprobs = tensor([[ -1.4210, -10.3385],
        [ -8.3626,  -1.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3887154161930084
Epoch 0, Step 1483: train/loss = 0.0495191365480423, train/raw-loss = 0.017368044704198837, train/logprobs = tensor([[-1.3325, -8.1004],
        [-7.4321, -1.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215108811855316
Epoch 0, Step 1484: train/loss = 0.055638398975133896, train/raw-loss = 0.027217166498303413, train/logprobs = tensor([[-1.3445, -6.8505],
        [-6.0868, -1.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842123508453369
Epoch 0, Step 1485: train/loss = 0.038562241941690445, train/raw-loss = 0.003829450346529484, train/logprobs = tensor([[ -0.9622, -10.0970],
        [ -6.1511,  -1.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473278880119324
Epoch 0, Step 1486: train/loss = 0.038448646664619446, train/raw-loss = 0.005473079159855843, train/logprobs = tensor([[-1.0659, -7.9387],
        [-6.7403, -0.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32975566387176514
Epoch 0, Step 1487: train/loss = 0.04279369115829468, train/raw-loss = 0.00535335298627615, train/logprobs = tensor([[ -0.8624, -13.6082],
        [ -5.7960,  -2.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37440335750579834
Epoch 0, Step 1488: train/loss = 0.04537573456764221, train/raw-loss = 0.009926379658281803, train/logprobs = tensor([[-1.0056, -9.4813],
        [-6.2964, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35449355840682983
Epoch 0, Step 1489: train/loss = 0.06653208285570145, train/raw-loss = 0.030649321153759956, train/logprobs = tensor([[-1.2297, -8.3618],
        [-6.7837, -2.2140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588276207447052
Epoch 0, Step 1490: train/loss = 0.05339697003364563, train/raw-loss = 0.022022794932127, train/logprobs = tensor([[ -1.5324, -10.0024],
        [ -6.1112,  -1.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137417435646057
Epoch 0, Step 1491: train/loss = 0.03736995533108711, train/raw-loss = 0.002623772481456399, train/logprobs = tensor([[ -1.2223, -12.5964],
        [ -7.1297,  -2.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474618196487427
Epoch 0, Step 1492: train/loss = 0.10368035733699799, train/raw-loss = 0.06756369769573212, train/logprobs = tensor([[-1.2406, -6.4712],
        [-6.0824, -1.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3611665666103363
Epoch 0, Step 1493: train/loss = 0.03500378876924515, train/raw-loss = 0.0005067726597189903, train/logprobs = tensor([[ -2.0204, -12.5771],
        [ -9.7904,  -2.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344970166683197
Epoch 0, Step 1494: train/loss = 0.04304061830043793, train/raw-loss = 0.009177843108773232, train/logprobs = tensor([[ -1.1565, -11.7451],
        [ -6.7107,  -2.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33862772583961487
Epoch 0, Step 1495: train/loss = 0.12027479708194733, train/raw-loss = 0.09269288182258606, train/logprobs = tensor([[-1.0041, -5.2969],
        [-6.5441, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27581915259361267
Epoch 0, Step 1496: train/loss = 0.05360850691795349, train/raw-loss = 0.014893494546413422, train/logprobs = tensor([[-1.3235, -9.9849],
        [-6.2859, -2.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871500790119171
Epoch 0, Step 1497: train/loss = 0.0433991514146328, train/raw-loss = 0.0072290110401809216, train/logprobs = tensor([[ -1.0710, -11.0268],
        [ -5.9237,  -2.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617013990879059
Epoch 0, Step 1498: train/loss = 0.05001016706228256, train/raw-loss = 0.011425581760704517, train/logprobs = tensor([[-1.1297, -8.4070],
        [-6.2931, -2.1264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858458697795868
Epoch 0, Step 1499: train/loss = 0.057908251881599426, train/raw-loss = 0.02388181909918785, train/logprobs = tensor([[ -1.6720, -10.4585],
        [ -7.3061,  -1.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34026432037353516
Epoch 0, Step 1500: train/loss = 0.04523700475692749, train/raw-loss = 0.00758248521015048, train/logprobs = tensor([[-2.0413, -8.8553],
        [-8.3187, -1.3187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37654516100883484
Epoch 0, Step 1501: train/loss = 0.03889862075448036, train/raw-loss = 0.005305543541908264, train/logprobs = tensor([[ -1.2332, -11.4324],
        [ -8.0342,  -2.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3359307646751404
Epoch 0, Step 1502: train/loss = 0.04076462611556053, train/raw-loss = 0.0057175359688699245, train/logprobs = tensor([[-0.9473, -7.1016],
        [-7.2800, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3504709005355835
Epoch 0, Step 1503: train/loss = 0.04118397459387779, train/raw-loss = 0.006314702332019806, train/logprobs = tensor([[-1.1988, -7.2098],
        [-7.0147, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34869271516799927
Epoch 0, Step 1504: train/loss = 0.03622288256883621, train/raw-loss = 0.006255022250115871, train/logprobs = tensor([[ -1.4188, -10.7101],
        [ -6.8733,  -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29967859387397766
Epoch 0, Step 1505: train/loss = 0.04463043063879013, train/raw-loss = 0.009186601266264915, train/logprobs = tensor([[ -0.7286, -10.1146],
        [ -5.2009,  -1.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35443830490112305
Epoch 0, Step 1506: train/loss = 0.048368461430072784, train/raw-loss = 0.016348863020539284, train/logprobs = tensor([[-1.7047, -7.2293],
        [-7.2336, -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201960027217865
Epoch 0, Step 1507: train/loss = 0.06628315895795822, train/raw-loss = 0.028032584115862846, train/logprobs = tensor([[-1.8844, -6.6515],
        [-8.3016, -2.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38250571489334106
Epoch 0, Step 1508: train/loss = 0.04331069439649582, train/raw-loss = 0.012130831368267536, train/logprobs = tensor([[ -0.6095, -10.4631],
        [ -5.0000,  -1.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3117986023426056
Epoch 0, Step 1509: train/loss = 0.042353708297014236, train/raw-loss = 0.00549065787345171, train/logprobs = tensor([[-1.2126, -7.3403],
        [-6.3715, -0.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3686305284500122
Epoch 0, Step 1510: train/loss = 0.05239905044436455, train/raw-loss = 0.020581532269716263, train/logprobs = tensor([[-1.0580, -6.7874],
        [-5.7907, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31817516684532166
Epoch 0, Step 1511: train/loss = 0.04142209142446518, train/raw-loss = 0.0020638785790652037, train/logprobs = tensor([[ -1.4940, -10.7361],
        [ -7.4032,  -2.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39358213543891907
Epoch 0, Step 1512: train/loss = 0.04136746749281883, train/raw-loss = 0.0014127559261396527, train/logprobs = tensor([[ -1.6925, -10.3250],
        [ -9.2887,  -2.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39954710006713867
Epoch 0, Step 1513: train/loss = 0.04936080798506737, train/raw-loss = 0.01000670250505209, train/logprobs = tensor([[ -0.8155, -11.6527],
        [ -6.0989,  -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3935410678386688
Epoch 0, Step 1514: train/loss = 0.041579727083444595, train/raw-loss = 0.005044196266680956, train/logprobs = tensor([[ -1.0608, -10.6484],
        [ -7.1914,  -1.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36535531282424927
Epoch 0, Step 1515: train/loss = 0.0363025926053524, train/raw-loss = 0.004104211926460266, train/logprobs = tensor([[ -1.1096, -11.3056],
        [ -6.2784,  -2.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32198381423950195
Epoch 0, Step 1516: train/loss = 0.04576151445508003, train/raw-loss = 0.00738880131393671, train/logprobs = tensor([[-0.9418, -9.5591],
        [-6.0314, -1.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.383727103471756
Epoch 0, Step 1517: train/loss = 0.0608486607670784, train/raw-loss = 0.026468124240636826, train/logprobs = tensor([[-0.9201, -9.5215],
        [-6.1788, -1.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34380534291267395
Epoch 0, Step 1518: train/loss = 0.04539678245782852, train/raw-loss = 0.009679213166236877, train/logprobs = tensor([[-1.5348, -8.4119],
        [-7.8636, -2.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35717570781707764
Epoch 0, Step 1519: train/loss = 0.04146154597401619, train/raw-loss = 0.007064368575811386, train/logprobs = tensor([[-0.9598, -8.6522],
        [-6.3621, -1.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34397172927856445
Epoch 0, Step 1520: train/loss = 0.0365743413567543, train/raw-loss = 0.001282737124711275, train/logprobs = tensor([[ -1.4219, -14.6450],
        [ -7.5584,  -2.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35291600227355957
Epoch 0, Step 1521: train/loss = 0.0382666252553463, train/raw-loss = 0.004446917679160833, train/logprobs = tensor([[-1.2201, -9.4699],
        [-8.7318, -1.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381970524787903
Epoch 0, Step 1522: train/loss = 0.043067604303359985, train/raw-loss = 0.008020038716495037, train/logprobs = tensor([[-1.0243, -8.4443],
        [-7.0578, -1.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35047560930252075
Epoch 0, Step 1523: train/loss = 0.049791160970926285, train/raw-loss = 0.014357786625623703, train/logprobs = tensor([[ -1.1018, -13.1705],
        [ -5.8304,  -1.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3543337881565094
Epoch 0, Step 1524: train/loss = 0.06792780756950378, train/raw-loss = 0.03958478569984436, train/logprobs = tensor([[-0.7872, -7.0548],
        [-4.1909, -1.2811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28343015909194946
Epoch 0, Step 1525: train/loss = 0.04153884947299957, train/raw-loss = 0.0028042939957231283, train/logprobs = tensor([[ -1.3592, -12.0873],
        [ -8.2880,  -2.5218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873455226421356
Epoch 0, Step 1526: train/loss = 0.031794849783182144, train/raw-loss = 0.0018493094248697162, train/logprobs = tensor([[ -1.1652, -11.2091],
        [ -7.4627,  -1.3168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994554042816162
Epoch 0, Step 1527: train/loss = 0.04940859600901604, train/raw-loss = 0.01757172681391239, train/logprobs = tensor([[-1.3157, -7.6494],
        [-6.0960, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31836867332458496
Epoch 0, Step 1528: train/loss = 0.035643547773361206, train/raw-loss = 0.002191488863900304, train/logprobs = tensor([[ -1.5094, -10.3823],
        [ -7.4008,  -2.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345205783843994
Epoch 0, Step 1529: train/loss = 0.045324936509132385, train/raw-loss = 0.012882615439593792, train/logprobs = tensor([[-0.8906, -9.7741],
        [-6.3758, -1.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244231939315796
Epoch 0, Step 1530: train/loss = 0.04010726138949394, train/raw-loss = 0.003515383927151561, train/logprobs = tensor([[ -0.9191, -12.4235],
        [ -6.4209,  -2.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659187853336334
Epoch 0, Step 1531: train/loss = 0.036528438329696655, train/raw-loss = 0.0016548048006370664, train/logprobs = tensor([[-1.6695, -9.2113],
        [-8.4493, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34873634576797485
Epoch 0, Step 1532: train/loss = 0.0359748974442482, train/raw-loss = 0.003561746794730425, train/logprobs = tensor([[-0.6665, -9.7642],
        [-5.7936, -1.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32413148880004883
Epoch 0, Step 1533: train/loss = 0.039552442729473114, train/raw-loss = 0.004266805946826935, train/logprobs = tensor([[ -1.5234, -10.6394],
        [ -7.5032,  -1.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528563976287842
Epoch 0, Step 1534: train/loss = 0.03904490917921066, train/raw-loss = 0.00902487337589264, train/logprobs = tensor([[-0.8979, -7.5564],
        [-5.6507, -0.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30020034313201904
Epoch 0, Step 1535: train/loss = 0.07298087328672409, train/raw-loss = 0.04176665097475052, train/logprobs = tensor([[-0.9351, -9.4969],
        [-6.4782, -1.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31214219331741333
Epoch 0, Step 1536: train/loss = 0.04109958931803703, train/raw-loss = 0.0066094351932406425, train/logprobs = tensor([[ -1.1353, -12.0713],
        [ -6.4491,  -2.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34490156173706055
Epoch 0, Step 1537: train/loss = 0.03611918166279793, train/raw-loss = 0.004155072849243879, train/logprobs = tensor([[ -0.9570, -10.4936],
        [ -6.3731,  -1.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31964111328125
Epoch 0, Step 1538: train/loss = 0.0591711699962616, train/raw-loss = 0.023998480290174484, train/logprobs = tensor([[-1.3898, -9.4912],
        [-5.5938, -1.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517268896102905
Epoch 0, Step 1539: train/loss = 0.04735086113214493, train/raw-loss = 0.016332030296325684, train/logprobs = tensor([[-1.0185, -9.6382],
        [-5.6514, -1.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31018829345703125
Epoch 0, Step 1540: train/loss = 0.03356247395277023, train/raw-loss = 0.000640574493445456, train/logprobs = tensor([[ -1.5717, -15.5548],
        [ -8.8598,  -2.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3292190134525299
Epoch 0, Step 1541: train/loss = 0.04438479244709015, train/raw-loss = 0.009381070733070374, train/logprobs = tensor([[-1.1482, -8.8987],
        [-6.3426, -1.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35003721714019775
Epoch 0, Step 1542: train/loss = 0.041330255568027496, train/raw-loss = 0.010401777923107147, train/logprobs = tensor([[ -0.8133, -12.8926],
        [ -4.9394,  -2.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3092848062515259
Epoch 0, Step 1543: train/loss = 0.04063346982002258, train/raw-loss = 0.004117928445339203, train/logprobs = tensor([[ -1.3189, -17.0314],
        [ -7.9008,  -3.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651553988456726
Epoch 0, Step 1544: train/loss = 0.03954634442925453, train/raw-loss = 0.009149285964667797, train/logprobs = tensor([[-1.0656, -9.2478],
        [-5.7343, -1.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039705753326416
Epoch 0, Step 1545: train/loss = 0.04485737904906273, train/raw-loss = 0.012143811210989952, train/logprobs = tensor([[-1.1755, -9.6419],
        [-5.4432, -1.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3271356523036957
Epoch 0, Step 1546: train/loss = 0.05516912043094635, train/raw-loss = 0.02218901365995407, train/logprobs = tensor([[ -1.0806, -10.3457],
        [ -5.7365,  -2.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3298010528087616
Epoch 0, Step 1547: train/loss = 0.043865177780389786, train/raw-loss = 0.0049889483489096165, train/logprobs = tensor([[ -0.9796, -12.3553],
        [ -6.1485,  -3.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38876232504844666
Epoch 0, Step 1548: train/loss = 0.038909222930669785, train/raw-loss = 0.006224450655281544, train/logprobs = tensor([[ -0.8844, -11.3119],
        [ -5.3267,  -1.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32684770226478577
Epoch 0, Step 1549: train/loss = 0.0400739461183548, train/raw-loss = 0.002207262674346566, train/logprobs = tensor([[ -1.0424, -13.3105],
        [ -8.0163,  -2.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37866681814193726
Epoch 0, Step 1550: train/loss = 0.044145405292510986, train/raw-loss = 0.00627439608797431, train/logprobs = tensor([[ -1.1557, -10.8793],
        [ -6.0155,  -2.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3787100911140442
Epoch 0, Step 1551: train/loss = 0.09181289374828339, train/raw-loss = 0.05077601969242096, train/logprobs = tensor([[-1.6990, -7.4999],
        [-8.7287, -1.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41036880016326904
Epoch 0, Step 1552: train/loss = 0.06281423568725586, train/raw-loss = 0.02502431906759739, train/logprobs = tensor([[-1.5116, -9.5186],
        [-8.3558, -1.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3778991103172302
Epoch 0, Step 1553: train/loss = 0.03774341195821762, train/raw-loss = 0.0070970673114061356, train/logprobs = tensor([[ -1.6020, -11.4284],
        [ -8.0323,  -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30646345019340515
Epoch 0, Step 1554: train/loss = 0.042056307196617126, train/raw-loss = 0.008103739470243454, train/logprobs = tensor([[-0.8915, -9.6116],
        [-5.4785, -1.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33952564001083374
Epoch 0, Step 1555: train/loss = 0.040974341332912445, train/raw-loss = 0.004070086870342493, train/logprobs = tensor([[ -1.3880, -11.0053],
        [ -7.6304,  -2.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3690425753593445
Epoch 0, Step 1556: train/loss = 0.0465451255440712, train/raw-loss = 0.015363320708274841, train/logprobs = tensor([[ -1.5163, -12.8598],
        [ -6.6789,  -1.2247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31181806325912476
Epoch 0, Step 1557: train/loss = 0.04211876168847084, train/raw-loss = 0.006290525663644075, train/logprobs = tensor([[ -1.0367, -10.5883],
        [ -6.2273,  -2.4190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3582823872566223
Epoch 0, Step 1558: train/loss = 0.035775326192379, train/raw-loss = 0.00553235225379467, train/logprobs = tensor([[ -1.3630, -11.4424],
        [ -6.7208,  -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.302429735660553
Epoch 0, Step 1559: train/loss = 0.04562104120850563, train/raw-loss = 0.010007563978433609, train/logprobs = tensor([[-1.2233, -6.2654],
        [-6.5395, -1.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3561347723007202
Epoch 0, Step 1560: train/loss = 0.03661418706178665, train/raw-loss = 0.006899751257151365, train/logprobs = tensor([[ -1.3726, -13.8121],
        [ -6.6532,  -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2971443235874176
Epoch 0, Step 1561: train/loss = 0.054004378616809845, train/raw-loss = 0.011842695064842701, train/logprobs = tensor([[-0.8903, -9.5429],
        [-5.2044, -2.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4216168224811554
Epoch 0, Step 1562: train/loss = 0.03346971422433853, train/raw-loss = 0.0030323017854243517, train/logprobs = tensor([[-1.3551, -9.5553],
        [-7.0696, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043741285800934
Epoch 0, Step 1563: train/loss = 0.046255048364400864, train/raw-loss = 0.013159278780221939, train/logprobs = tensor([[ -0.9188, -11.8382],
        [ -6.0403,  -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33095768094062805
Epoch 0, Step 1564: train/loss = 0.04276806116104126, train/raw-loss = 0.007849996909499168, train/logprobs = tensor([[-1.5568, -9.3519],
        [-7.7423, -1.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3491806387901306
Epoch 0, Step 1565: train/loss = 0.04069079831242561, train/raw-loss = 0.0035380686167627573, train/logprobs = tensor([[ -0.9215, -10.1650],
        [ -6.5061,  -1.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3715272545814514
Epoch 0, Step 1566: train/loss = 0.04221241921186447, train/raw-loss = 0.004443869926035404, train/logprobs = tensor([[-1.2978, -8.9825],
        [-8.0850, -1.6148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37768545746803284
Epoch 0, Step 1567: train/loss = 0.104357048869133, train/raw-loss = 0.07067359238862991, train/logprobs = tensor([[ -1.1374, -10.0811],
        [ -6.8210,  -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3368346095085144
Epoch 0, Step 1568: train/loss = 0.047610022127628326, train/raw-loss = 0.018031466752290726, train/logprobs = tensor([[ -1.1527, -10.4221],
        [ -5.7448,  -1.1941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957855761051178
Epoch 0, Step 1569: train/loss = 0.04024846851825714, train/raw-loss = 0.006494441535323858, train/logprobs = tensor([[ -0.9950, -11.1158],
        [ -5.7123,  -2.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33754026889801025
Epoch 0, Step 1570: train/loss = 0.037626322358846664, train/raw-loss = 0.001760127954185009, train/logprobs = tensor([[ -2.0476,  -9.7452],
        [-10.0516,  -1.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3586619198322296
Epoch 0, Step 1571: train/loss = 0.040118951350450516, train/raw-loss = 0.009319432079792023, train/logprobs = tensor([[ -1.0723, -11.1048],
        [ -5.4621,  -1.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079952001571655
Epoch 0, Step 1572: train/loss = 0.04628586024045944, train/raw-loss = 0.014413250610232353, train/logprobs = tensor([[ -0.8999, -11.8641],
        [ -4.5431,  -1.1897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3187260925769806
Epoch 0, Step 1573: train/loss = 0.047648292034864426, train/raw-loss = 0.01664162240922451, train/logprobs = tensor([[-0.6632, -8.6820],
        [-4.2185, -1.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31006669998168945
Epoch 0, Step 1574: train/loss = 0.03941361606121063, train/raw-loss = 0.010552107356488705, train/logprobs = tensor([[ -1.1065, -12.7675],
        [ -6.8511,  -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28861507773399353
Epoch 0, Step 1575: train/loss = 0.06841831654310226, train/raw-loss = 0.033911991864442825, train/logprobs = tensor([[-1.0022, -8.5689],
        [-5.4817, -2.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3450632691383362
Epoch 0, Step 1576: train/loss = 0.041067734360694885, train/raw-loss = 0.008126448839902878, train/logprobs = tensor([[-0.8217, -9.8688],
        [-5.8947, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294128477573395
Epoch 0, Step 1577: train/loss = 0.03896472230553627, train/raw-loss = 0.006244727410376072, train/logprobs = tensor([[ -1.5962, -12.7014],
        [ -7.4139,  -2.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32719993591308594
Epoch 0, Step 1578: train/loss = 0.0387517511844635, train/raw-loss = 0.005863766185939312, train/logprobs = tensor([[ -1.3461, -13.0465],
        [ -8.0427,  -1.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32887983322143555
Epoch 0, Step 1579: train/loss = 0.04778684675693512, train/raw-loss = 0.01497175544500351, train/logprobs = tensor([[ -1.2930, -12.6023],
        [ -7.6464,  -2.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281509280204773
Epoch 0, Step 1580: train/loss = 0.05736913904547691, train/raw-loss = 0.020124351605772972, train/logprobs = tensor([[-1.1789, -7.9448],
        [-7.0094, -2.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3724478781223297
Epoch 0, Step 1581: train/loss = 0.03801459074020386, train/raw-loss = 0.004241451155394316, train/logprobs = tensor([[ -1.5203, -12.2914],
        [ -6.5199,  -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33773142099380493
Epoch 0, Step 1582: train/loss = 0.05788642540574074, train/raw-loss = 0.024894248694181442, train/logprobs = tensor([[-1.1020, -6.8956],
        [-5.2285, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32992178201675415
Epoch 0, Step 1583: train/loss = 0.042561568319797516, train/raw-loss = 0.010248552076518536, train/logprobs = tensor([[-1.1613, -9.3701],
        [-6.2351, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32313016057014465
Epoch 0, Step 1584: train/loss = 0.045619554817676544, train/raw-loss = 0.01560342125594616, train/logprobs = tensor([[-1.7134, -7.0317],
        [-6.4890, -0.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30016130208969116
Epoch 0, Step 1585: train/loss = 0.041865307837724686, train/raw-loss = 0.006227944977581501, train/logprobs = tensor([[-0.8327, -9.1433],
        [-5.8047, -1.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3563736379146576
Epoch 0, Step 1586: train/loss = 0.037844590842723846, train/raw-loss = 0.003778184298425913, train/logprobs = tensor([[ -1.1520, -10.7914],
        [ -6.5888,  -1.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3406640291213989
Epoch 0, Step 1587: train/loss = 0.04648301750421524, train/raw-loss = 0.010663365945219994, train/logprobs = tensor([[ -1.4672, -10.0203],
        [ -6.3489,  -2.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35819655656814575
Epoch 0, Step 1588: train/loss = 0.03904039412736893, train/raw-loss = 0.008388454094529152, train/logprobs = tensor([[ -1.3023, -10.2253],
        [ -7.0128,  -0.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30651941895484924
Epoch 0, Step 1589: train/loss = 0.043528348207473755, train/raw-loss = 0.012497343122959137, train/logprobs = tensor([[-0.9686, -8.6006],
        [-6.0085, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3103100657463074
Epoch 0, Step 1590: train/loss = 0.03845861926674843, train/raw-loss = 0.009148861281573772, train/logprobs = tensor([[ -1.0265, -10.8519],
        [ -6.5526,  -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2930976152420044
Epoch 0, Step 1591: train/loss = 0.03997908905148506, train/raw-loss = 0.004835512023419142, train/logprobs = tensor([[ -1.2266, -13.3022],
        [ -7.8983,  -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3514357805252075
Epoch 0, Step 1592: train/loss = 0.03753529116511345, train/raw-loss = 0.0034535701852291822, train/logprobs = tensor([[ -1.1014, -12.5255],
        [ -6.5123,  -2.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3408172130584717
Epoch 0, Step 1593: train/loss = 0.04328810051083565, train/raw-loss = 0.012041639536619186, train/logprobs = tensor([[ -1.4039, -10.9093],
        [ -5.4999,  -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124646246433258
Epoch 0, Step 1594: train/loss = 0.04113786667585373, train/raw-loss = 0.0038625765591859818, train/logprobs = tensor([[ -1.2055, -12.2678],
        [ -6.7573,  -2.3019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727529048919678
Epoch 0, Step 1595: train/loss = 0.03793638199567795, train/raw-loss = 0.001785746542736888, train/logprobs = tensor([[ -1.2618, -12.3368],
        [ -7.3408,  -2.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3615063428878784
Epoch 0, Step 1596: train/loss = 0.04117980971932411, train/raw-loss = 0.0009852199582383037, train/logprobs = tensor([[ -1.2311, -12.0876],
        [ -8.5403,  -2.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019458591938019
Epoch 0, Step 1597: train/loss = 0.04095561057329178, train/raw-loss = 0.002055723685771227, train/logprobs = tensor([[ -1.3422, -11.8440],
        [ -8.2028,  -1.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3889988362789154
Epoch 0, Step 1598: train/loss = 0.040910638868808746, train/raw-loss = 0.006655583158135414, train/logprobs = tensor([[ -0.9632, -10.5239],
        [ -5.6955,  -1.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425505459308624
Epoch 0, Step 1599: train/loss = 0.04187651351094246, train/raw-loss = 0.002259389730170369, train/logprobs = tensor([[ -1.2996, -12.3199],
        [ -7.3848,  -1.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3961712121963501
Epoch 0, Step 1600: train/loss = 0.044001027941703796, train/raw-loss = 0.007531012408435345, train/logprobs = tensor([[ -1.4236, -10.9623],
        [ -7.0892,  -1.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3647001385688782
Epoch 0, Step 1601: train/loss = 0.03432022035121918, train/raw-loss = 0.00403079017996788, train/logprobs = tensor([[ -1.5066, -10.3300],
        [ -6.5311,  -1.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30289426445961
Epoch 0, Step 1602: train/loss = 0.04223388433456421, train/raw-loss = 0.009896080009639263, train/logprobs = tensor([[-1.4669, -9.7241],
        [-7.1571, -1.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3233780264854431
Epoch 0, Step 1603: train/loss = 0.08950893580913544, train/raw-loss = 0.0538913793861866, train/logprobs = tensor([[-1.9080, -8.3284],
        [-7.1497, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35617560148239136
Epoch 0, Step 1604: train/loss = 0.04222645238041878, train/raw-loss = 0.0043326811864972115, train/logprobs = tensor([[-1.3960, -9.7590],
        [-7.1296, -1.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789377212524414
Epoch 0, Step 1605: train/loss = 0.04045066982507706, train/raw-loss = 0.0012459211284294724, train/logprobs = tensor([[ -1.7299, -11.7560],
        [ -8.9132,  -2.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3920474648475647
Epoch 0, Step 1606: train/loss = 0.039413101971149445, train/raw-loss = 0.006758503150194883, train/logprobs = tensor([[ -0.8240, -11.7965],
        [ -5.3433,  -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32654598355293274
Epoch 0, Step 1607: train/loss = 0.04476581886410713, train/raw-loss = 0.004919636528939009, train/logprobs = tensor([[ -0.9774, -14.0511],
        [ -5.6637,  -2.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39846181869506836
Epoch 0, Step 1608: train/loss = 0.052430860698223114, train/raw-loss = 0.019178414717316628, train/logprobs = tensor([[ -1.9514, -12.7155],
        [ -8.3364,  -2.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33252447843551636
Epoch 0, Step 1609: train/loss = 0.040815871208906174, train/raw-loss = 0.002639851300045848, train/logprobs = tensor([[ -1.6402, -10.0536],
        [ -7.4194,  -1.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38176023960113525
Epoch 0, Step 1610: train/loss = 0.03830324485898018, train/raw-loss = 0.0030325818806886673, train/logprobs = tensor([[ -1.5222, -12.9826],
        [ -8.0683,  -2.6991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527066111564636
Epoch 0, Step 1611: train/loss = 0.06511218845844269, train/raw-loss = 0.034829191863536835, train/logprobs = tensor([[ -0.7598, -12.4108],
        [ -4.3199,  -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028300106525421
Epoch 0, Step 1612: train/loss = 0.6333259344100952, train/raw-loss = 0.6066918969154358, train/logprobs = tensor([[ -3.0782, -10.0195],
        [ -4.0444,  -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663407027721405
Epoch 0, Step 1613: train/loss = 0.059608228504657745, train/raw-loss = 0.03265155106782913, train/logprobs = tensor([[-1.3753, -9.9038],
        [-5.5643, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26956677436828613
Epoch 0, Step 1614: train/loss = 0.038986027240753174, train/raw-loss = 0.0045457580126821995, train/logprobs = tensor([[ -1.5900, -12.3055],
        [ -6.9144,  -2.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3444026708602905
Epoch 0, Step 1615: train/loss = 0.05104406923055649, train/raw-loss = 0.015741698443889618, train/logprobs = tensor([[ -1.1314, -10.6585],
        [ -6.2044,  -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3530237078666687
Epoch 0, Step 1616: train/loss = 0.03883887827396393, train/raw-loss = 0.004864804912358522, train/logprobs = tensor([[-1.4231, -9.1162],
        [-6.9592, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3397407531738281
Epoch 0, Step 1617: train/loss = 0.04319021850824356, train/raw-loss = 0.00954446941614151, train/logprobs = tensor([[ -1.2388, -16.3934],
        [ -5.6682,  -2.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33645743131637573
Epoch 0, Step 1618: train/loss = 0.03715439885854721, train/raw-loss = 0.002467536134645343, train/logprobs = tensor([[ -1.5378, -13.8927],
        [ -7.4981,  -1.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.346868634223938
Epoch 0, Step 1619: train/loss = 0.0737583190202713, train/raw-loss = 0.03395714983344078, train/logprobs = tensor([[-1.3488, -7.9495],
        [-8.2279, -1.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3980116546154022
Epoch 0, Step 1620: train/loss = 0.05707315355539322, train/raw-loss = 0.02610933780670166, train/logprobs = tensor([[ -1.1462, -10.1035],
        [ -4.7707,  -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3096381723880768
Epoch 0, Step 1621: train/loss = 0.0813601016998291, train/raw-loss = 0.046729933470487595, train/logprobs = tensor([[ -1.8772, -10.7158],
        [ -6.1665,  -1.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3463016748428345
Epoch 0, Step 1622: train/loss = 0.04637572914361954, train/raw-loss = 0.005740098189562559, train/logprobs = tensor([[-1.4690, -9.1972],
        [-8.4747, -2.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4063563346862793
Epoch 0, Step 1623: train/loss = 0.043468572199344635, train/raw-loss = 0.006110918242484331, train/logprobs = tensor([[-1.6335, -8.8678],
        [-7.4745, -1.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735765516757965
Epoch 0, Step 1624: train/loss = 0.040327854454517365, train/raw-loss = 0.0024802852421998978, train/logprobs = tensor([[ -1.3648, -12.8288],
        [ -8.6774,  -2.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784756660461426
Epoch 0, Step 1625: train/loss = 0.04059271886944771, train/raw-loss = 0.0035168970935046673, train/logprobs = tensor([[ -1.4642, -10.8810],
        [ -7.2485,  -1.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37075820565223694
Epoch 0, Step 1626: train/loss = 0.04334278032183647, train/raw-loss = 0.005494121927767992, train/logprobs = tensor([[-1.0649, -9.8976],
        [-5.8002, -1.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784865736961365
Epoch 0, Step 1627: train/loss = 0.04922173544764519, train/raw-loss = 0.013953395187854767, train/logprobs = tensor([[ -1.1332, -13.3908],
        [ -5.4274,  -3.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352683424949646
Epoch 0, Step 1628: train/loss = 0.039709798991680145, train/raw-loss = 0.0059202490374445915, train/logprobs = tensor([[ -1.2181, -12.0098],
        [ -6.8505,  -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378955125808716
Epoch 0, Step 1629: train/loss = 0.045055605471134186, train/raw-loss = 0.0130508067086339, train/logprobs = tensor([[ -1.7773, -10.9401],
        [ -7.2675,  -2.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200479745864868
Epoch 0, Step 1630: train/loss = 0.039084259420633316, train/raw-loss = 0.011493067257106304, train/logprobs = tensor([[ -2.0361, -12.1522],
        [ -7.1204,  -1.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27591192722320557
Epoch 0, Step 1631: train/loss = 0.03872566297650337, train/raw-loss = 0.008901197463274002, train/logprobs = tensor([[ -1.2694, -11.1596],
        [ -7.0578,  -1.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982446253299713
Epoch 0, Step 1632: train/loss = 0.0970335304737091, train/raw-loss = 0.06306212395429611, train/logprobs = tensor([[ -1.9864, -13.4737],
        [ -6.8074,  -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33971402049064636
Epoch 0, Step 1633: train/loss = 0.04026452451944351, train/raw-loss = 0.0048965150490403175, train/logprobs = tensor([[ -1.7493, -14.0549],
        [ -7.2327,  -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536801040172577
Epoch 0, Step 1634: train/loss = 0.037906743586063385, train/raw-loss = 0.005462314933538437, train/logprobs = tensor([[ -1.1738, -14.5996],
        [ -5.8348,  -4.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244442939758301
Epoch 0, Step 1635: train/loss = 0.04757217690348625, train/raw-loss = 0.011264072731137276, train/logprobs = tensor([[-1.4027, -7.7582],
        [-6.5043, -2.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36308103799819946
Epoch 0, Step 1636: train/loss = 0.042944133281707764, train/raw-loss = 0.00644802488386631, train/logprobs = tensor([[ -1.1526, -12.2625],
        [ -5.7667,  -1.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36496105790138245
Epoch 0, Step 1637: train/loss = 0.035135842859745026, train/raw-loss = 0.0027418346144258976, train/logprobs = tensor([[ -1.4007, -12.4662],
        [ -7.3188,  -1.6046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32394009828567505
Epoch 0, Step 1638: train/loss = 0.04266771674156189, train/raw-loss = 0.005590504035353661, train/logprobs = tensor([[ -1.1176, -12.9198],
        [ -5.8436,  -1.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.370772123336792
Epoch 0, Step 1639: train/loss = 0.03882211446762085, train/raw-loss = 0.0018301308155059814, train/logprobs = tensor([[ -1.2429, -11.9806],
        [ -7.3112,  -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3699198365211487
Epoch 0, Step 1640: train/loss = 0.03360651805996895, train/raw-loss = 0.0006358023965731263, train/logprobs = tensor([[ -1.6728, -11.6338],
        [ -8.5527,  -1.3590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32970714569091797
Epoch 0, Step 1641: train/loss = 0.04328037053346634, train/raw-loss = 0.010401900857686996, train/logprobs = tensor([[-1.4215, -8.9993],
        [-5.9357, -1.0671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.328784704208374
Epoch 0, Step 1642: train/loss = 0.041039351373910904, train/raw-loss = 0.005134278908371925, train/logprobs = tensor([[ -1.3774, -13.6539],
        [ -7.1320,  -2.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3590507209300995
Epoch 0, Step 1643: train/loss = 0.04468938708305359, train/raw-loss = 0.011385779827833176, train/logprobs = tensor([[ -0.9766, -12.7366],
        [ -5.3157,  -2.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33303606510162354
Epoch 0, Step 1644: train/loss = 0.03986543416976929, train/raw-loss = 0.008812461979687214, train/logprobs = tensor([[ -1.3706, -17.2967],
        [ -6.0324,  -3.2753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3105296790599823
Epoch 0, Step 1645: train/loss = 0.05395601689815521, train/raw-loss = 0.02043338119983673, train/logprobs = tensor([[ -1.5751, -13.9016],
        [ -7.6792,  -2.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352263271808624
Epoch 0, Step 1646: train/loss = 0.0423828586935997, train/raw-loss = 0.011912120506167412, train/logprobs = tensor([[ -1.7906, -10.5132],
        [ -6.6456,  -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3047073483467102
Epoch 0, Step 1647: train/loss = 0.03334284573793411, train/raw-loss = 0.0006684195250272751, train/logprobs = tensor([[ -1.8189, -16.1290],
        [ -9.7520,  -2.5746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267442286014557
Epoch 0, Step 1648: train/loss = 0.04370970278978348, train/raw-loss = 0.007668748497962952, train/logprobs = tensor([[ -1.0629, -12.1364],
        [ -5.3959,  -1.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36040958762168884
Epoch 0, Step 1649: train/loss = 0.04514549672603607, train/raw-loss = 0.01225222460925579, train/logprobs = tensor([[ -1.2491, -16.3495],
        [ -6.9539,  -3.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3289327025413513
Epoch 0, Step 1650: train/loss = 0.036115311086177826, train/raw-loss = 0.005210784263908863, train/logprobs = tensor([[ -2.8387,  -9.5975],
        [-10.4639,  -1.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30904528498649597
Epoch 0, Step 1651: train/loss = 0.05218290165066719, train/raw-loss = 0.017640067264437675, train/logprobs = tensor([[ -1.2354, -11.1181],
        [ -6.5002,  -2.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34542834758758545
Epoch 0, Step 1652: train/loss = 0.03829818591475487, train/raw-loss = 0.0024389352183789015, train/logprobs = tensor([[ -1.7504, -11.7307],
        [ -8.7208,  -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35859251022338867
Epoch 0, Step 1653: train/loss = 0.07927602529525757, train/raw-loss = 0.04373908415436745, train/logprobs = tensor([[ -1.1745, -14.3226],
        [ -5.5315,  -2.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553694188594818
Epoch 0, Step 1654: train/loss = 0.038102373480796814, train/raw-loss = 0.003974843770265579, train/logprobs = tensor([[ -1.5953, -11.8788],
        [ -6.5078,  -1.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34127533435821533
Epoch 0, Step 1655: train/loss = 0.035926222801208496, train/raw-loss = 0.0029900192748755217, train/logprobs = tensor([[ -1.1747, -11.2950],
        [ -7.7354,  -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32936203479766846
Epoch 0, Step 1656: train/loss = 0.040218207985162735, train/raw-loss = 0.006153250113129616, train/logprobs = tensor([[ -1.0853, -10.3915],
        [ -6.3871,  -0.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3406496047973633
Epoch 0, Step 1657: train/loss = 0.04656378552317619, train/raw-loss = 0.013551141135394573, train/logprobs = tensor([[-1.1366, -9.2544],
        [-6.6529, -1.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33012646436691284
Epoch 0, Step 1658: train/loss = 0.053463175892829895, train/raw-loss = 0.017580408602952957, train/logprobs = tensor([[ -1.3983, -12.4821],
        [ -6.2490,  -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588276505470276
Epoch 0, Step 1659: train/loss = 0.04103996604681015, train/raw-loss = 0.009842926636338234, train/logprobs = tensor([[ -1.3091, -11.5740],
        [ -6.9062,  -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119703531265259
Epoch 0, Step 1660: train/loss = 0.03642943501472473, train/raw-loss = 0.004439238924533129, train/logprobs = tensor([[ -1.8390, -11.1673],
        [ -7.4267,  -1.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199019730091095
Epoch 0, Step 1661: train/loss = 0.04513910785317421, train/raw-loss = 0.010752476751804352, train/logprobs = tensor([[ -1.1520, -10.8500],
        [ -6.2760,  -0.9888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438662886619568
Epoch 0, Step 1662: train/loss = 0.04063020646572113, train/raw-loss = 0.009072544984519482, train/logprobs = tensor([[-2.1791, -9.7726],
        [-7.9498, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31557661294937134
Epoch 0, Step 1663: train/loss = 0.039357252418994904, train/raw-loss = 0.0023114164359867573, train/logprobs = tensor([[ -1.1796, -11.0291],
        [ -7.5627,  -2.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37045833468437195
Epoch 0, Step 1664: train/loss = 0.03585626557469368, train/raw-loss = 0.000970713677816093, train/logprobs = tensor([[ -1.7252, -12.0026],
        [ -8.2852,  -1.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34885549545288086
Epoch 0, Step 1665: train/loss = 0.06105966866016388, train/raw-loss = 0.02310892567038536, train/logprobs = tensor([[ -1.3792, -12.9478],
        [ -5.3568,  -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3795073926448822
Epoch 0, Step 1666: train/loss = 0.04311468079686165, train/raw-loss = 0.0045672692358493805, train/logprobs = tensor([[ -1.6705, -12.4884],
        [ -7.3404,  -2.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38547414541244507
Epoch 0, Step 1667: train/loss = 0.03381621092557907, train/raw-loss = 0.004547282587736845, train/logprobs = tensor([[ -1.5798, -11.1848],
        [ -8.0283,  -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2926892936229706
Epoch 0, Step 1668: train/loss = 0.05652593448758125, train/raw-loss = 0.021183770149946213, train/logprobs = tensor([[ -1.3881, -12.3129],
        [ -5.6687,  -1.3411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35342156887054443
Epoch 0, Step 1669: train/loss = 0.04623382166028023, train/raw-loss = 0.008892371319234371, train/logprobs = tensor([[ -1.1202, -13.0398],
        [ -6.1173,  -1.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3734145164489746
Epoch 0, Step 1670: train/loss = 0.0378032810986042, train/raw-loss = 0.0029146953020244837, train/logprobs = tensor([[ -1.2844, -12.9510],
        [ -7.1399,  -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34888583421707153
Epoch 0, Step 1671: train/loss = 0.04364839196205139, train/raw-loss = 0.008002074435353279, train/logprobs = tensor([[ -1.1706, -11.6604],
        [ -5.9140,  -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3564631938934326
Epoch 0, Step 1672: train/loss = 0.039390966296195984, train/raw-loss = 0.005675807595252991, train/logprobs = tensor([[ -1.1442, -13.5417],
        [ -7.0363,  -1.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33715158700942993
Epoch 0, Step 1673: train/loss = 0.041160307824611664, train/raw-loss = 0.009606882929801941, train/logprobs = tensor([[ -1.5106, -11.1223],
        [ -7.1574,  -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31553423404693604
Epoch 0, Step 1674: train/loss = 0.04525873064994812, train/raw-loss = 0.01044438686221838, train/logprobs = tensor([[ -1.1296, -12.5537],
        [ -6.0589,  -1.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34814342856407166
Epoch 0, Step 1675: train/loss = 0.042094700038433075, train/raw-loss = 0.008081313222646713, train/logprobs = tensor([[ -1.4855, -15.3112],
        [ -6.6198,  -1.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401338458061218
Epoch 0, Step 1676: train/loss = 0.06214810907840729, train/raw-loss = 0.028997279703617096, train/logprobs = tensor([[ -1.3680, -12.2942],
        [ -5.8366,  -1.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315082788467407
Epoch 0, Step 1677: train/loss = 0.03886156901717186, train/raw-loss = 0.00733459647744894, train/logprobs = tensor([[ -1.7403, -11.7151],
        [ -7.0935,  -1.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31526973843574524
Epoch 0, Step 1678: train/loss = 0.03409210219979286, train/raw-loss = 0.004998901858925819, train/logprobs = tensor([[ -1.6668, -15.2920],
        [ -6.5605,  -1.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2909319996833801
Epoch 0, Step 1679: train/loss = 0.041832953691482544, train/raw-loss = 0.0029494420159608126, train/logprobs = tensor([[ -1.7601, -12.4884],
        [ -8.8270,  -2.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3888351321220398
Epoch 0, Step 1680: train/loss = 0.050032276660203934, train/raw-loss = 0.02063477598130703, train/logprobs = tensor([[ -1.0432, -10.9765],
        [ -4.7910,  -0.9067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29397499561309814
Epoch 0, Step 1681: train/loss = 0.04240185767412186, train/raw-loss = 0.007945233955979347, train/logprobs = tensor([[ -1.0981, -14.7150],
        [ -6.4590,  -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3445661962032318
Epoch 0, Step 1682: train/loss = 0.04574548825621605, train/raw-loss = 0.00900618638843298, train/logprobs = tensor([[-1.5056, -9.6125],
        [-6.4662, -2.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36739301681518555
Epoch 0, Step 1683: train/loss = 0.04899837076663971, train/raw-loss = 0.014510569162666798, train/logprobs = tensor([[ -1.0746, -11.2369],
        [ -6.0246,  -1.5230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3448779881000519
Epoch 0, Step 1684: train/loss = 0.04398462176322937, train/raw-loss = 0.0060743298381567, train/logprobs = tensor([[ -1.2234, -12.3082],
        [ -6.6081,  -2.2556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.379102885723114
Epoch 0, Step 1685: train/loss = 0.037767767906188965, train/raw-loss = 0.003128314157947898, train/logprobs = tensor([[ -1.4295, -11.0918],
        [ -7.3809,  -2.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34639453887939453
Epoch 0, Step 1686: train/loss = 0.03876638785004616, train/raw-loss = 0.005410136189311743, train/logprobs = tensor([[ -1.5743, -11.2939],
        [ -6.5139,  -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3335625231266022
Epoch 0, Step 1687: train/loss = 0.03724006190896034, train/raw-loss = 0.0015070935478433967, train/logprobs = tensor([[ -1.1770, -12.4308],
        [ -7.9931,  -1.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35732966661453247
Epoch 0, Step 1688: train/loss = 0.059897281229496, train/raw-loss = 0.029643312096595764, train/logprobs = tensor([[-1.2645, -8.3940],
        [-5.3496, -1.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025397062301636
Epoch 0, Step 1689: train/loss = 0.045580651611089706, train/raw-loss = 0.0076633053831756115, train/logprobs = tensor([[ -1.4238, -12.4844],
        [ -6.1997,  -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37917348742485046
Epoch 0, Step 1690: train/loss = 0.06718605011701584, train/raw-loss = 0.03277125209569931, train/logprobs = tensor([[ -1.1054, -11.3558],
        [ -4.6273,  -1.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34414801001548767
Epoch 0, Step 1691: train/loss = 0.043203726410865784, train/raw-loss = 0.010669728741049767, train/logprobs = tensor([[ -1.4803, -13.7543],
        [ -5.5456,  -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253399431705475
Epoch 0, Step 1692: train/loss = 0.040709614753723145, train/raw-loss = 0.008258559741079807, train/logprobs = tensor([[ -1.3670, -12.8597],
        [ -6.5166,  -1.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3245105743408203
Epoch 0, Step 1693: train/loss = 0.04651105776429176, train/raw-loss = 0.009184001013636589, train/logprobs = tensor([[ -1.3028, -13.1686],
        [ -6.4430,  -3.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37327060103416443
Epoch 0, Step 1694: train/loss = 0.045726459473371506, train/raw-loss = 0.011353959329426289, train/logprobs = tensor([[ -1.2431, -11.2124],
        [ -7.1006,  -2.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34372496604919434
Epoch 0, Step 1695: train/loss = 0.034132130444049835, train/raw-loss = 0.004187105223536491, train/logprobs = tensor([[-1.3602, -8.7104],
        [-7.3140, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29945021867752075
Epoch 0, Step 1696: train/loss = 0.03835638612508774, train/raw-loss = 0.007090556900948286, train/logprobs = tensor([[ -1.7443, -14.1226],
        [ -7.9047,  -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31265828013420105
Epoch 0, Step 1697: train/loss = 0.05237789452075958, train/raw-loss = 0.018981169909238815, train/logprobs = tensor([[ -1.2080, -12.7514],
        [ -4.8744,  -1.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339672386646271
Epoch 0, Step 1698: train/loss = 0.06969073414802551, train/raw-loss = 0.03810271620750427, train/logprobs = tensor([[ -1.6738, -10.1752],
        [ -5.4384,  -2.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31588014960289
Epoch 0, Step 1699: train/loss = 0.044432517141103745, train/raw-loss = 0.0025989064015448093, train/logprobs = tensor([[ -1.4353, -12.6691],
        [ -7.3193,  -1.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4183361530303955
Epoch 0, Step 1700: train/loss = 0.04333119839429855, train/raw-loss = 0.0094365943223238, train/logprobs = tensor([[ -1.9620, -14.1807],
        [ -6.5456,  -1.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33894601464271545
Epoch 0, Step 1701: train/loss = 0.03695690259337425, train/raw-loss = 0.004899495281279087, train/logprobs = tensor([[ -1.6216, -11.1659],
        [ -7.0468,  -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205740749835968
Epoch 0, Step 1702: train/loss = 0.03520442917943001, train/raw-loss = 0.0009427698678337038, train/logprobs = tensor([[ -2.1779, -12.0927],
        [ -9.5412,  -2.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34261658787727356
Epoch 0, Step 1703: train/loss = 0.07482969760894775, train/raw-loss = 0.041013091802597046, train/logprobs = tensor([[ -1.3003, -11.8848],
        [ -3.8276,  -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381660580635071
Epoch 0, Step 1704: train/loss = 0.034984443336725235, train/raw-loss = 0.0012654849560931325, train/logprobs = tensor([[ -1.2155, -13.0667],
        [ -8.4190,  -1.3155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33718955516815186
Epoch 0, Step 1705: train/loss = 0.05591975152492523, train/raw-loss = 0.023936863988637924, train/logprobs = tensor([[ -1.6106, -10.6268],
        [ -5.6076,  -1.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31982895731925964
Epoch 0, Step 1706: train/loss = 0.04606810584664345, train/raw-loss = 0.01249820739030838, train/logprobs = tensor([[ -1.2843, -12.8332],
        [ -5.7935,  -1.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356989622116089
Epoch 0, Step 1707: train/loss = 0.03631249815225601, train/raw-loss = 0.004316298291087151, train/logprobs = tensor([[ -1.7273, -13.3793],
        [ -7.8301,  -1.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199619650840759
Epoch 0, Step 1708: train/loss = 0.09414295107126236, train/raw-loss = 0.06276656687259674, train/logprobs = tensor([[-2.2583, -9.0544],
        [-6.4081, -1.3023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137638568878174
Epoch 0, Step 1709: train/loss = 0.09425169229507446, train/raw-loss = 0.06165250763297081, train/logprobs = tensor([[ -1.8101, -10.6907],
        [ -5.1168,  -1.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3259918987751007
Epoch 0, Step 1710: train/loss = 0.03928620368242264, train/raw-loss = 0.005940844304859638, train/logprobs = tensor([[ -1.1796, -10.6732],
        [ -6.6576,  -2.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33345359563827515
Epoch 0, Step 1711: train/loss = 0.03707295283675194, train/raw-loss = 0.001285577891394496, train/logprobs = tensor([[ -1.2042, -12.2619],
        [ -7.7727,  -2.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35787370800971985
Epoch 0, Step 1712: train/loss = 0.039055854082107544, train/raw-loss = 0.00536810839548707, train/logprobs = tensor([[-1.4713, -7.4439],
        [-6.5152, -0.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3368774354457855
Epoch 0, Step 1713: train/loss = 0.04269301891326904, train/raw-loss = 0.010027098469436169, train/logprobs = tensor([[ -2.2713, -12.6738],
        [ -7.2336,  -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266592025756836
Epoch 0, Step 1714: train/loss = 0.035850368440151215, train/raw-loss = 0.0019191341707482934, train/logprobs = tensor([[ -1.6010, -14.4494],
        [ -7.8102,  -2.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.339312344789505
Epoch 0, Step 1715: train/loss = 0.03759078308939934, train/raw-loss = 0.003867529798299074, train/logprobs = tensor([[ -1.4910, -11.6428],
        [ -6.5408,  -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372325301170349
Epoch 0, Step 1716: train/loss = 0.04157024621963501, train/raw-loss = 0.013506494462490082, train/logprobs = tensor([[ -1.2559, -13.6633],
        [ -7.1531,  -2.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2806375324726105
Epoch 0, Step 1717: train/loss = 0.04580502584576607, train/raw-loss = 0.012769147753715515, train/logprobs = tensor([[ -0.9090, -13.7642],
        [ -5.1530,  -2.6546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3303587734699249
Epoch 0, Step 1718: train/loss = 0.05776281654834747, train/raw-loss = 0.02289462834596634, train/logprobs = tensor([[ -1.4101, -15.8053],
        [ -6.2034,  -2.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486819267272949
Epoch 0, Step 1719: train/loss = 0.039306141436100006, train/raw-loss = 0.002746913116425276, train/logprobs = tensor([[ -1.9760, -12.6504],
        [ -8.2582,  -2.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3655923008918762
Epoch 0, Step 1720: train/loss = 0.05099958926439285, train/raw-loss = 0.01776306889951229, train/logprobs = tensor([[ -2.4339, -11.3917],
        [ -9.7566,  -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3323652148246765
Epoch 0, Step 1721: train/loss = 0.04910822585225105, train/raw-loss = 0.014345480129122734, train/logprobs = tensor([[ -1.8110, -11.6853],
        [ -7.6127,  -1.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3476274609565735
Epoch 0, Step 1722: train/loss = 0.07002768665552139, train/raw-loss = 0.04364369064569473, train/logprobs = tensor([[ -1.6712, -12.7481],
        [ -4.5717,  -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638399600982666
Epoch 0, Step 1723: train/loss = 0.06853599846363068, train/raw-loss = 0.03533834218978882, train/logprobs = tensor([[-1.4666, -8.0886],
        [-5.6331, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319765627384186
Epoch 0, Step 1724: train/loss = 0.045225344598293304, train/raw-loss = 0.01505746878683567, train/logprobs = tensor([[ -1.6297, -14.1994],
        [ -6.2127,  -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016788065433502
Epoch 0, Step 1725: train/loss = 0.041487984359264374, train/raw-loss = 0.010137045755982399, train/logprobs = tensor([[ -1.3041, -10.3393],
        [ -6.7654,  -0.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31350937485694885
Epoch 0, Step 1726: train/loss = 0.044932134449481964, train/raw-loss = 0.005712452810257673, train/logprobs = tensor([[ -1.4988, -10.3504],
        [ -6.5009,  -1.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39219677448272705
Epoch 0, Step 1727: train/loss = 0.05636785551905632, train/raw-loss = 0.019369343295693398, train/logprobs = tensor([[ -0.8326, -11.8743],
        [ -4.3282,  -2.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36998510360717773
Epoch 0, Step 1728: train/loss = 0.04106823354959488, train/raw-loss = 0.004758741240948439, train/logprobs = tensor([[ -1.0566, -11.3084],
        [ -6.1107,  -1.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36309492588043213
Epoch 0, Step 1729: train/loss = 0.14176592230796814, train/raw-loss = 0.10976570099592209, train/logprobs = tensor([[ -2.2568, -13.6319],
        [ -6.7950,  -2.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200022280216217
Epoch 0, Step 1730: train/loss = 0.048549823462963104, train/raw-loss = 0.017025576904416084, train/logprobs = tensor([[ -1.7675, -13.4299],
        [ -6.1151,  -1.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152424395084381
Epoch 0, Step 1731: train/loss = 0.046392060816287994, train/raw-loss = 0.013551193289458752, train/logprobs = tensor([[-1.8193, -9.9454],
        [-5.5155, -1.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32840868830680847
Epoch 0, Step 1732: train/loss = 0.03909168019890785, train/raw-loss = 0.002171736443415284, train/logprobs = tensor([[ -1.2785, -12.1910],
        [ -7.2834,  -2.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691994547843933
Epoch 0, Step 1733: train/loss = 0.041960135102272034, train/raw-loss = 0.0073196664452552795, train/logprobs = tensor([[ -0.9747, -15.0953],
        [ -5.3343,  -2.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34640470147132874
Epoch 0, Step 1734: train/loss = 0.04129261523485184, train/raw-loss = 0.005701630376279354, train/logprobs = tensor([[ -1.8284, -11.7790],
        [ -7.2928,  -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35590988397598267
Epoch 0, Step 1735: train/loss = 0.0759187713265419, train/raw-loss = 0.04949480667710304, train/logprobs = tensor([[ -1.3025, -12.9210],
        [ -4.5564,  -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.264239639043808
Epoch 0, Step 1736: train/loss = 0.0421900600194931, train/raw-loss = 0.009797071106731892, train/logprobs = tensor([[ -1.7409, -10.7685],
        [ -6.4199,  -1.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32392987608909607
Epoch 0, Step 1737: train/loss = 0.03922143578529358, train/raw-loss = 0.0035963510163128376, train/logprobs = tensor([[-1.7715, -9.4358],
        [-7.8897, -1.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3562508225440979
Epoch 0, Step 1738: train/loss = 0.041800305247306824, train/raw-loss = 0.007795891724526882, train/logprobs = tensor([[ -1.5752, -14.1110],
        [ -8.0913,  -1.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3400441110134125
Epoch 0, Step 1739: train/loss = 0.04682376980781555, train/raw-loss = 0.013766465708613396, train/logprobs = tensor([[ -1.6062, -12.5147],
        [ -6.7076,  -2.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33057302236557007
Epoch 0, Step 1740: train/loss = 0.05486802011728287, train/raw-loss = 0.027164174243807793, train/logprobs = tensor([[-2.0451, -8.9925],
        [-6.6031, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27703845500946045
Epoch 0, Step 1741: train/loss = 0.03853968530893326, train/raw-loss = 0.0026410419959574938, train/logprobs = tensor([[ -1.9968, -12.4869],
        [ -9.2119,  -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35898643732070923
Epoch 0, Step 1742: train/loss = 0.0366644486784935, train/raw-loss = 0.003899348434060812, train/logprobs = tensor([[ -1.8565, -11.3430],
        [ -7.6569,  -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276509642601013
Epoch 0, Step 1743: train/loss = 0.052672870457172394, train/raw-loss = 0.018311217427253723, train/logprobs = tensor([[ -0.9395, -10.3774],
        [ -5.3062,  -2.5732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3436165153980255
Epoch 0, Step 1744: train/loss = 0.04351787269115448, train/raw-loss = 0.011813121847808361, train/logprobs = tensor([[-1.2335, -8.8596],
        [-5.4619, -0.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31704750657081604
Epoch 0, Step 1745: train/loss = 0.03541960567235947, train/raw-loss = 0.004124080762267113, train/logprobs = tensor([[ -1.5305, -18.4041],
        [ -6.9889,  -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31295523047447205
Epoch 0, Step 1746: train/loss = 0.09201370179653168, train/raw-loss = 0.06390197575092316, train/logprobs = tensor([[ -2.1717, -12.0456],
        [ -4.4744,  -1.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811172604560852
Epoch 0, Step 1747: train/loss = 0.03729943186044693, train/raw-loss = 0.00392843596637249, train/logprobs = tensor([[ -1.2868, -17.3220],
        [ -7.0603,  -3.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337099552154541
Epoch 0, Step 1748: train/loss = 0.04294982925057411, train/raw-loss = 0.007138775661587715, train/logprobs = tensor([[-1.3598, -8.7252],
        [-6.7784, -1.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581105172634125
Epoch 0, Step 1749: train/loss = 0.0345662385225296, train/raw-loss = 0.0027480851858854294, train/logprobs = tensor([[-1.0722, -9.0145],
        [-7.0244, -2.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181815445423126
Epoch 0, Step 1750: train/loss = 0.05018338933587074, train/raw-loss = 0.017303209751844406, train/logprobs = tensor([[ -1.6233, -13.9108],
        [ -5.4942,  -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288017809391022
Epoch 0, Step 1751: train/loss = 0.03846656531095505, train/raw-loss = 0.004198246635496616, train/logprobs = tensor([[ -1.6635, -16.7376],
        [ -7.0655,  -2.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34268316626548767
Epoch 0, Step 1752: train/loss = 0.040900085121393204, train/raw-loss = 0.009346741251647472, train/logprobs = tensor([[ -1.3087, -11.9650],
        [ -5.6247,  -1.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3155333995819092
Epoch 0, Step 1753: train/loss = 0.06894969195127487, train/raw-loss = 0.04034210368990898, train/logprobs = tensor([[ -1.4383, -12.4703],
        [ -5.3244,  -1.4623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860758900642395
Epoch 0, Step 1754: train/loss = 0.0530259907245636, train/raw-loss = 0.016804935410618782, train/logprobs = tensor([[ -1.6062, -12.2361],
        [ -5.9784,  -2.2818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36221057176589966
Epoch 0, Step 1755: train/loss = 0.04618711397051811, train/raw-loss = 0.014968971721827984, train/logprobs = tensor([[ -2.3597, -11.0963],
        [ -6.5461,  -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121814727783203
Epoch 0, Step 1756: train/loss = 0.04769416153430939, train/raw-loss = 0.014585552737116814, train/logprobs = tensor([[-1.6108, -9.8159],
        [-6.2819, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33108609914779663
Epoch 0, Step 1757: train/loss = 0.03755473345518112, train/raw-loss = 0.004143185913562775, train/logprobs = tensor([[ -1.8335, -13.0512],
        [ -7.3849,  -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341154456138611
Epoch 0, Step 1758: train/loss = 0.04688824340701103, train/raw-loss = 0.006862401496618986, train/logprobs = tensor([[ -1.4280, -12.2870],
        [ -6.4878,  -2.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4002584218978882
Epoch 0, Step 1759: train/loss = 0.046819232404232025, train/raw-loss = 0.009912146255373955, train/logprobs = tensor([[ -2.7956, -12.7621],
        [ -8.6609,  -1.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.369070827960968
Epoch 0, Step 1760: train/loss = 0.05911962687969208, train/raw-loss = 0.0265955813229084, train/logprobs = tensor([[ -1.9791, -13.0835],
        [ -7.3082,  -2.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32524043321609497
Epoch 0, Step 1761: train/loss = 0.039645176380872726, train/raw-loss = 0.008190128952264786, train/logprobs = tensor([[ -1.6499, -13.6844],
        [ -6.6048,  -1.4338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145504593849182
Epoch 0, Step 1762: train/loss = 0.05453973636031151, train/raw-loss = 0.017628664150834084, train/logprobs = tensor([[ -1.5122, -11.3755],
        [ -8.3408,  -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36911070346832275
Epoch 0, Step 1763: train/loss = 0.07791075855493546, train/raw-loss = 0.047162190079689026, train/logprobs = tensor([[ -1.4384, -10.9884],
        [ -6.3893,  -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074856996536255
Epoch 0, Step 1764: train/loss = 0.039381466805934906, train/raw-loss = 0.005535580683499575, train/logprobs = tensor([[-1.6833, -8.6188],
        [-7.1031, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3384588658809662
Epoch 0, Step 1765: train/loss = 0.037299953401088715, train/raw-loss = 0.0021690307185053825, train/logprobs = tensor([[ -1.6908, -12.1930],
        [ -8.0967,  -2.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35130923986434937
Epoch 0, Step 1766: train/loss = 0.040021903812885284, train/raw-loss = 0.003868082305416465, train/logprobs = tensor([[ -1.4839, -12.7671],
        [ -7.4976,  -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36153823137283325
Epoch 0, Step 1767: train/loss = 0.04177725687623024, train/raw-loss = 0.007566435728222132, train/logprobs = tensor([[ -1.3185, -12.0740],
        [ -6.1115,  -1.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3421081602573395
Epoch 0, Step 1768: train/loss = 0.04326103255152702, train/raw-loss = 0.011604899540543556, train/logprobs = tensor([[ -1.3699, -12.1190],
        [ -7.0337,  -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3165613114833832
Epoch 0, Step 1769: train/loss = 0.05785756930708885, train/raw-loss = 0.02972852624952793, train/logprobs = tensor([[ -1.3122, -11.4551],
        [ -5.0382,  -2.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812904715538025
Epoch 0, Step 1770: train/loss = 0.1702098548412323, train/raw-loss = 0.13594184815883636, train/logprobs = tensor([[-1.2410, -9.4759],
        [-5.3449, -1.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.342679888010025
Epoch 0, Step 1771: train/loss = 0.039553917944431305, train/raw-loss = 0.001589939696714282, train/logprobs = tensor([[ -1.5931, -10.6765],
        [ -8.1281,  -2.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37963980436325073
Epoch 0, Step 1772: train/loss = 0.03892118111252785, train/raw-loss = 0.004995316732674837, train/logprobs = tensor([[ -1.1064, -11.0191],
        [ -6.5137,  -2.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392586410045624
Epoch 0, Step 1773: train/loss = 0.04585418105125427, train/raw-loss = 0.006570989266037941, train/logprobs = tensor([[ -1.2424, -11.4808],
        [ -6.1073,  -2.5149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3928319215774536
Epoch 0, Step 1774: train/loss = 0.055801015347242355, train/raw-loss = 0.01930537261068821, train/logprobs = tensor([[-1.1806, -8.7947],
        [-6.2769, -1.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36495643854141235
Epoch 0, Step 1775: train/loss = 0.04166879877448082, train/raw-loss = 0.012137056328356266, train/logprobs = tensor([[ -1.2302, -17.7323],
        [ -5.7400,  -3.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2953174114227295
Epoch 0, Step 1776: train/loss = 0.0391462966799736, train/raw-loss = 0.001245715538971126, train/logprobs = tensor([[ -1.2430, -15.9316],
        [ -7.8354,  -2.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3790057897567749
Epoch 0, Step 1777: train/loss = 0.05419662222266197, train/raw-loss = 0.025576503947377205, train/logprobs = tensor([[ -1.0946, -12.0741],
        [ -4.1903,  -1.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862011790275574
Epoch 0, Step 1778: train/loss = 0.037524208426475525, train/raw-loss = 0.004473707638680935, train/logprobs = tensor([[ -1.2415, -12.2379],
        [ -6.5349,  -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33050498366355896
Epoch 0, Step 1779: train/loss = 0.03626171126961708, train/raw-loss = 0.0045339022763073444, train/logprobs = tensor([[ -1.9278, -17.2285],
        [ -7.4292,  -3.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317278116941452
Epoch 0, Step 1780: train/loss = 0.04062547907233238, train/raw-loss = 0.00379734905436635, train/logprobs = tensor([[ -1.2598, -13.9466],
        [ -8.3873,  -1.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3682813048362732
Epoch 0, Step 1781: train/loss = 0.04306003078818321, train/raw-loss = 0.006736706010997295, train/logprobs = tensor([[ -1.5268, -13.1017],
        [ -7.0244,  -2.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36323320865631104
Epoch 0, Step 1782: train/loss = 0.04253402724862099, train/raw-loss = 0.004941772669553757, train/logprobs = tensor([[ -0.9727, -15.0730],
        [ -6.1080,  -2.9882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3759225010871887
Epoch 0, Step 1783: train/loss = 0.039217978715896606, train/raw-loss = 0.0051253847777843475, train/logprobs = tensor([[ -2.0084, -14.7902],
        [ -7.8548,  -1.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3409259021282196
Epoch 0, Step 1784: train/loss = 0.03856893628835678, train/raw-loss = 0.008134760893881321, train/logprobs = tensor([[ -1.4242, -14.2397],
        [ -6.8858,  -2.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30434173345565796
Epoch 0, Step 1785: train/loss = 0.10582950711250305, train/raw-loss = 0.07516150921583176, train/logprobs = tensor([[ -2.1134, -12.1293],
        [ -7.7140,  -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306679904460907
Epoch 0, Step 1786: train/loss = 0.04161444306373596, train/raw-loss = 0.011169569566845894, train/logprobs = tensor([[-1.5116, -9.9847],
        [-5.5340, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304448664188385
Epoch 0, Step 1787: train/loss = 0.03682761639356613, train/raw-loss = 0.0008524664444848895, train/logprobs = tensor([[ -1.6965, -13.3990],
        [ -8.5881,  -2.2065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35975146293640137
Epoch 0, Step 1788: train/loss = 0.03867342323064804, train/raw-loss = 0.003740069456398487, train/logprobs = tensor([[ -2.0874, -11.1174],
        [ -8.0397,  -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493334949016571
Epoch 0, Step 1789: train/loss = 0.050234198570251465, train/raw-loss = 0.01371693518012762, train/logprobs = tensor([[ -1.6595, -15.1659],
        [ -6.7745,  -2.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651726245880127
Epoch 0, Step 1790: train/loss = 0.03819933161139488, train/raw-loss = 0.0027891425415873528, train/logprobs = tensor([[ -1.4928, -12.3629],
        [ -7.4255,  -2.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35410186648368835
Epoch 0, Step 1791: train/loss = 0.04808817803859711, train/raw-loss = 0.015201715752482414, train/logprobs = tensor([[ -1.2019, -10.1877],
        [ -5.4057,  -1.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32886457443237305
Epoch 0, Step 1792: train/loss = 0.04624936357140541, train/raw-loss = 0.00967719778418541, train/logprobs = tensor([[ -1.4209, -11.5324],
        [ -6.3598,  -3.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657216429710388
Epoch 0, Step 1793: train/loss = 0.037661485373973846, train/raw-loss = 0.0020710693206638098, train/logprobs = tensor([[ -1.1258, -14.5371],
        [ -7.6812,  -2.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35590416193008423
Epoch 0, Step 1794: train/loss = 0.04261701554059982, train/raw-loss = 0.009649406187236309, train/logprobs = tensor([[ -0.9101, -10.7282],
        [ -5.7105,  -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3296760618686676
Epoch 0, Step 1795: train/loss = 0.15424074232578278, train/raw-loss = 0.12449923902750015, train/logprobs = tensor([[-1.5543, -9.2856],
        [-5.6965, -3.2925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2974151372909546
Epoch 0, Step 1796: train/loss = 0.038104843348264694, train/raw-loss = 0.0017771495040506124, train/logprobs = tensor([[ -1.6315, -13.2737],
        [ -8.4291,  -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3632769286632538
Epoch 0, Step 1797: train/loss = 0.0430973656475544, train/raw-loss = 0.005932690110057592, train/logprobs = tensor([[-1.4252, -9.8845],
        [-7.7216, -2.1347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3716467022895813
Epoch 0, Step 1798: train/loss = 0.03882662206888199, train/raw-loss = 0.002387893619015813, train/logprobs = tensor([[-1.5336, -9.4076],
        [-7.9589, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36438727378845215
Epoch 0, Step 1799: train/loss = 0.038460422307252884, train/raw-loss = 0.010544014163315296, train/logprobs = tensor([[ -1.4452, -13.7813],
        [ -5.9734,  -2.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27916407585144043
Epoch 0, Step 1800: train/loss = 0.036934807896614075, train/raw-loss = 0.004581961315125227, train/logprobs = tensor([[ -1.4845, -13.2055],
        [ -7.9703,  -1.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235284686088562
Epoch 0, Step 1801: train/loss = 0.07819525897502899, train/raw-loss = 0.04515428841114044, train/logprobs = tensor([[ -1.0606, -10.1454],
        [ -5.3540,  -1.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3304096758365631
Epoch 0, Step 1802: train/loss = 0.04006870836019516, train/raw-loss = 0.008596409112215042, train/logprobs = tensor([[ -1.3450, -14.1908],
        [ -6.8185,  -1.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3147229850292206
Epoch 0, Step 1803: train/loss = 0.04118764400482178, train/raw-loss = 0.008667578920722008, train/logprobs = tensor([[ -1.6474, -11.4557],
        [ -7.6799,  -1.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3252006769180298
Epoch 0, Step 1804: train/loss = 0.0476175993680954, train/raw-loss = 0.011627000756561756, train/logprobs = tensor([[ -1.1785, -14.6452],
        [ -6.4507,  -1.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35990601778030396
Epoch 0, Step 1805: train/loss = 0.03538932651281357, train/raw-loss = 0.0021117322612553835, train/logprobs = tensor([[ -1.7237, -10.6139],
        [ -8.3368,  -2.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33277595043182373
Epoch 0, Step 1806: train/loss = 0.0418681800365448, train/raw-loss = 0.014806927181780338, train/logprobs = tensor([[ -1.0919, -13.9575],
        [ -5.3069,  -2.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27061253786087036
Epoch 0, Step 1807: train/loss = 0.09754390269517899, train/raw-loss = 0.06323111802339554, train/logprobs = tensor([[ -1.7076, -10.0700],
        [ -6.6327,  -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431277275085449
Epoch 0, Step 1808: train/loss = 0.03193085640668869, train/raw-loss = 0.003475436009466648, train/logprobs = tensor([[ -1.0624, -12.3614],
        [ -6.5784,  -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845541834831238
Epoch 0, Step 1809: train/loss = 0.0408918634057045, train/raw-loss = 0.003492749761790037, train/logprobs = tensor([[ -2.0675, -13.1051],
        [ -8.5982,  -2.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37399110198020935
Epoch 0, Step 1810: train/loss = 0.04149610549211502, train/raw-loss = 0.0037327089812606573, train/logprobs = tensor([[ -1.6963, -13.9698],
        [ -7.2617,  -2.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3776339888572693
Epoch 0, Step 1811: train/loss = 0.04003893956542015, train/raw-loss = 0.0017328725662082434, train/logprobs = tensor([[ -1.1271, -16.0670],
        [ -7.1159,  -1.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38306066393852234
Epoch 0, Step 1812: train/loss = 0.04129888862371445, train/raw-loss = 0.012734307907521725, train/logprobs = tensor([[-1.3481, -8.2258],
        [-6.3427, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28564581274986267
Epoch 0, Step 1813: train/loss = 0.058101631700992584, train/raw-loss = 0.023030202835798264, train/logprobs = tensor([[-1.8153, -9.1969],
        [-5.9846, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3507142961025238
Epoch 0, Step 1814: train/loss = 0.03320924937725067, train/raw-loss = 0.0021536739077419043, train/logprobs = tensor([[ -1.0805, -13.1569],
        [ -7.3354,  -1.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31055575609207153
Epoch 0, Step 1815: train/loss = 0.0393158458173275, train/raw-loss = 0.005470947828143835, train/logprobs = tensor([[ -1.7234, -13.1607],
        [ -6.8147,  -1.4207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33844900131225586
Epoch 0, Step 1816: train/loss = 0.1169484555721283, train/raw-loss = 0.0820562094449997, train/logprobs = tensor([[ -2.0544, -12.0510],
        [ -6.6494,  -2.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3489225208759308
Epoch 0, Step 1817: train/loss = 0.11743970215320587, train/raw-loss = 0.08730018883943558, train/logprobs = tensor([[ -1.4301, -10.8251],
        [ -4.9299,  -1.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.301395058631897
Epoch 0, Step 1818: train/loss = 0.07081098854541779, train/raw-loss = 0.03457724675536156, train/logprobs = tensor([[ -1.5354, -10.1783],
        [ -6.3052,  -2.4331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3623374104499817
Epoch 0, Step 1819: train/loss = 0.03615303710103035, train/raw-loss = 0.005899726878851652, train/logprobs = tensor([[ -1.5813, -14.3382],
        [ -6.6943,  -1.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025330603122711
Epoch 0, Step 1820: train/loss = 0.04257132112979889, train/raw-loss = 0.00409966055303812, train/logprobs = tensor([[ -1.1337, -13.4374],
        [ -6.2867,  -1.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38471662998199463
Epoch 0, Step 1821: train/loss = 0.036420583724975586, train/raw-loss = 0.0017271693795919418, train/logprobs = tensor([[ -2.0814, -13.5947],
        [ -8.7350,  -1.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34693413972854614
Epoch 0, Step 1822: train/loss = 0.03580240160226822, train/raw-loss = 0.003793016541749239, train/logprobs = tensor([[ -1.5503, -14.9682],
        [ -8.1456,  -2.3309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200938403606415
Epoch 0, Step 1823: train/loss = 0.10226710885763168, train/raw-loss = 0.06981794536113739, train/logprobs = tensor([[ -2.2483, -13.9511],
        [ -7.4916,  -3.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244916796684265
Epoch 0, Step 1824: train/loss = 0.037228986620903015, train/raw-loss = 0.0013688391773030162, train/logprobs = tensor([[ -1.2175, -12.2387],
        [ -7.9542,  -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35860148072242737
Epoch 0, Step 1825: train/loss = 0.061688609421253204, train/raw-loss = 0.03219223767518997, train/logprobs = tensor([[ -1.5824, -12.4082],
        [ -5.8489,  -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29496368765830994
Epoch 0, Step 1826: train/loss = 0.07250698655843735, train/raw-loss = 0.03643312677741051, train/logprobs = tensor([[ -0.9355, -10.1332],
        [ -5.4743,  -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3607386648654938
Epoch 0, Step 1827: train/loss = 0.0407697968184948, train/raw-loss = 0.004618220031261444, train/logprobs = tensor([[ -1.5755, -13.1646],
        [ -7.0420,  -2.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36151576042175293
Epoch 0, Step 1828: train/loss = 0.040662966668605804, train/raw-loss = 0.005163128022104502, train/logprobs = tensor([[ -1.1314, -14.4734],
        [ -6.3684,  -2.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3549984097480774
Epoch 0, Step 1829: train/loss = 0.036870088428258896, train/raw-loss = 0.004368879366666079, train/logprobs = tensor([[-1.3297, -9.3178],
        [-7.7947, -2.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32501208782196045
Epoch 0, Step 1830: train/loss = 0.041036929935216904, train/raw-loss = 0.0035739880986511707, train/logprobs = tensor([[-1.7156, -8.8111],
        [-8.0066, -1.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3746294379234314
Epoch 0, Step 1831: train/loss = 0.03588036447763443, train/raw-loss = 0.002930090995505452, train/logprobs = tensor([[ -1.3155, -12.5642],
        [ -8.5617,  -2.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295027017593384
Epoch 0, Step 1832: train/loss = 0.03497881442308426, train/raw-loss = 0.002154896967113018, train/logprobs = tensor([[ -1.0239, -17.2965],
        [ -6.5827,  -2.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3282391428947449
Epoch 0, Step 1833: train/loss = 0.04018312692642212, train/raw-loss = 0.004525740630924702, train/logprobs = tensor([[ -1.0527, -13.0653],
        [ -6.0127,  -1.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35657384991645813
Epoch 0, Step 1834: train/loss = 0.04558666795492172, train/raw-loss = 0.016689162701368332, train/logprobs = tensor([[-0.8988, -7.7042],
        [-6.5412, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889750599861145
Epoch 0, Step 1835: train/loss = 0.03582652658224106, train/raw-loss = 0.0013852284755557775, train/logprobs = tensor([[ -2.3846, -11.7686],
        [ -8.7790,  -2.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34441298246383667
Epoch 0, Step 1836: train/loss = 0.05428806319832802, train/raw-loss = 0.016171647235751152, train/logprobs = tensor([[-1.1216, -9.0310],
        [-6.6276, -1.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3811641335487366
Epoch 0, Step 1837: train/loss = 0.034431882202625275, train/raw-loss = 0.002179501811042428, train/logprobs = tensor([[ -1.4755, -12.2143],
        [ -7.0646,  -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225237727165222
Epoch 0, Step 1838: train/loss = 0.03634416684508324, train/raw-loss = 0.002293848432600498, train/logprobs = tensor([[ -0.9706, -12.8737],
        [ -7.3719,  -2.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34050318598747253
Epoch 0, Step 1839: train/loss = 0.1281622350215912, train/raw-loss = 0.09307048469781876, train/logprobs = tensor([[ -1.6419, -14.9695],
        [ -6.4521,  -2.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35091760754585266
Epoch 0, Step 1840: train/loss = 0.03757020831108093, train/raw-loss = 0.0036492920480668545, train/logprobs = tensor([[ -0.9106, -11.5890],
        [ -6.1128,  -1.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392091989517212
Epoch 0, Step 1841: train/loss = 0.03976305574178696, train/raw-loss = 0.007904428988695145, train/logprobs = tensor([[ -1.5933, -10.8258],
        [ -7.0606,  -1.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3185862898826599
Epoch 0, Step 1842: train/loss = 0.03425804153084755, train/raw-loss = 0.0004448177933227271, train/logprobs = tensor([[ -1.3419, -16.0450],
        [ -9.1430,  -2.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33813223242759705
Epoch 0, Step 1843: train/loss = 0.04116985201835632, train/raw-loss = 0.005687126889824867, train/logprobs = tensor([[-1.1081, -9.0606],
        [-7.7583, -1.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35482722520828247
Epoch 0, Step 1844: train/loss = 0.03497079014778137, train/raw-loss = 0.0012249157298356295, train/logprobs = tensor([[ -1.4764, -10.5594],
        [ -8.0454,  -1.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374587595462799
Epoch 0, Step 1845: train/loss = 0.03947058320045471, train/raw-loss = 0.004023269284516573, train/logprobs = tensor([[ -1.3005, -11.2825],
        [ -6.1483,  -1.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3544731140136719
Epoch 0, Step 1846: train/loss = 0.03536931425333023, train/raw-loss = 0.003413465805351734, train/logprobs = tensor([[ -1.4700, -14.0591],
        [ -7.3867,  -4.7043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3195584714412689
Epoch 0, Step 1847: train/loss = 0.03945443406701088, train/raw-loss = 0.004684405867010355, train/logprobs = tensor([[ -0.8958, -12.3822],
        [ -6.4629,  -1.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477002680301666
Epoch 0, Step 1848: train/loss = 0.03735873103141785, train/raw-loss = 0.005357265472412109, train/logprobs = tensor([[ -1.3347, -10.0762],
        [ -6.8841,  -0.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200146555900574
Epoch 0, Step 1849: train/loss = 0.0341290719807148, train/raw-loss = 0.002890106290578842, train/logprobs = tensor([[ -1.0766, -11.1387],
        [ -7.9229,  -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31238967180252075
Epoch 0, Step 1850: train/loss = 0.04267149791121483, train/raw-loss = 0.006931508891284466, train/logprobs = tensor([[ -1.1333, -10.1556],
        [ -7.2683,  -1.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3573998510837555
Epoch 0, Step 1851: train/loss = 0.035984382033348083, train/raw-loss = 0.007039621472358704, train/logprobs = tensor([[-1.1991, -8.9345],
        [-5.9591, -1.1182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894476056098938
Epoch 0, Step 1852: train/loss = 0.040298495441675186, train/raw-loss = 0.0015043775783851743, train/logprobs = tensor([[ -1.0274, -12.5842],
        [ -8.3266,  -1.9828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3879411816596985
Epoch 0, Step 1853: train/loss = 0.03670048341155052, train/raw-loss = 0.0010559282964095473, train/logprobs = tensor([[ -1.0817, -12.9348],
        [ -7.4864,  -1.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3564455509185791
Epoch 0, Step 1854: train/loss = 0.03357243537902832, train/raw-loss = 0.00337469601072371, train/logprobs = tensor([[ -1.2666, -12.8568],
        [ -7.7085,  -1.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019774258136749
Epoch 0, Step 1855: train/loss = 0.03646714240312576, train/raw-loss = 0.005600648000836372, train/logprobs = tensor([[ -1.1160, -13.8734],
        [ -6.1091,  -2.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086649477481842
Epoch 0, Step 1856: train/loss = 0.038040708750486374, train/raw-loss = 0.0015198503388091922, train/logprobs = tensor([[ -1.0408, -11.6245],
        [ -7.4889,  -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36520856618881226
Epoch 0, Step 1857: train/loss = 0.03609456494450569, train/raw-loss = 0.005848899018019438, train/logprobs = tensor([[ -1.1189, -11.3882],
        [ -6.6945,  -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30245664715766907
Epoch 0, Step 1858: train/loss = 0.0416555181145668, train/raw-loss = 0.0007086392724886537, train/logprobs = tensor([[ -1.0799, -12.2179],
        [ -8.1104,  -1.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40946877002716064
Epoch 0, Step 1859: train/loss = 0.0411841943860054, train/raw-loss = 0.004566466435790062, train/logprobs = tensor([[ -1.1885, -11.0939],
        [ -7.9967,  -1.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3661772608757019
Epoch 0, Step 1860: train/loss = 0.0373581163585186, train/raw-loss = 0.0015787959564477205, train/logprobs = tensor([[ -1.2469, -15.4463],
        [ -8.6751,  -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3577932119369507
Epoch 0, Step 1861: train/loss = 0.03781299293041229, train/raw-loss = 0.0037250739987939596, train/logprobs = tensor([[ -1.2020, -13.4487],
        [ -7.6183,  -2.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3408791720867157
Epoch 0, Step 1862: train/loss = 0.12114079296588898, train/raw-loss = 0.09077244997024536, train/logprobs = tensor([[ -1.3725, -10.0453],
        [ -6.4443,  -1.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30368345975875854
Epoch 0, Step 1863: train/loss = 0.03362174704670906, train/raw-loss = 0.0025609289295971394, train/logprobs = tensor([[ -1.3557, -15.0594],
        [ -8.1336,  -3.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106081783771515
Epoch 0, Step 1864: train/loss = 0.035982634872198105, train/raw-loss = 0.0010919049382209778, train/logprobs = tensor([[ -1.0026, -15.3311],
        [ -7.2641,  -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3489072918891907
Epoch 0, Step 1865: train/loss = 0.04515998810529709, train/raw-loss = 0.0083572156727314, train/logprobs = tensor([[-1.0076, -7.6476],
        [-6.8563, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680277466773987
Epoch 0, Step 1866: train/loss = 0.05137185752391815, train/raw-loss = 0.01567339524626732, train/logprobs = tensor([[ -1.1837, -10.8122],
        [ -8.3036,  -1.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35698461532592773
Epoch 0, Step 1867: train/loss = 0.0399569496512413, train/raw-loss = 0.003984949551522732, train/logprobs = tensor([[ -1.2054, -15.8432],
        [ -6.6499,  -3.0015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35971999168395996
Epoch 0, Step 1868: train/loss = 0.08898390829563141, train/raw-loss = 0.05646514147520065, train/logprobs = tensor([[-1.0630, -9.4911],
        [-6.3101, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251877427101135
Epoch 0, Step 1869: train/loss = 0.039729710668325424, train/raw-loss = 0.007138772401958704, train/logprobs = tensor([[ -1.8488, -11.4634],
        [ -8.4725,  -3.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3259093463420868
Epoch 0, Step 1870: train/loss = 0.032699089497327805, train/raw-loss = 0.0027002557180821896, train/logprobs = tensor([[-1.3963, -8.5466],
        [-8.7402, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.299988329410553
Epoch 0, Step 1871: train/loss = 0.04862987622618675, train/raw-loss = 0.01816054992377758, train/logprobs = tensor([[ -0.9913, -16.5061],
        [ -6.8858,  -2.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3046932816505432
Epoch 0, Step 1872: train/loss = 0.03298550844192505, train/raw-loss = 0.0005873064510524273, train/logprobs = tensor([[ -1.3148, -11.9210],
        [ -8.6729,  -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32398200035095215
Epoch 0, Step 1873: train/loss = 0.03744353726506233, train/raw-loss = 0.004312081262469292, train/logprobs = tensor([[-0.9492, -7.3812],
        [-7.5393, -1.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313145637512207
Epoch 0, Step 1874: train/loss = 0.09032464027404785, train/raw-loss = 0.05798674374818802, train/logprobs = tensor([[ -1.7778, -10.3427],
        [ -7.4614,  -1.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32337892055511475
Epoch 0, Step 1875: train/loss = 0.03801335394382477, train/raw-loss = 0.002329471055418253, train/logprobs = tensor([[ -1.1153, -14.2253],
        [ -7.3522,  -2.3738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35683882236480713
Epoch 0, Step 1876: train/loss = 0.03199217841029167, train/raw-loss = 0.0017855388578027487, train/logprobs = tensor([[ -1.3810, -10.8520],
        [ -9.0801,  -2.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020663857460022
Epoch 0, Step 1877: train/loss = 0.03937448561191559, train/raw-loss = 0.0046167876571416855, train/logprobs = tensor([[-0.9139, -7.5100],
        [-7.2498, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34757697582244873
Epoch 0, Step 1878: train/loss = 0.03740831837058067, train/raw-loss = 0.0038183541037142277, train/logprobs = tensor([[ -1.3198, -11.7817],
        [ -7.6060,  -2.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33589959144592285
Epoch 0, Step 1879: train/loss = 0.03853737562894821, train/raw-loss = 0.007125402335077524, train/logprobs = tensor([[ -0.9872, -11.2483],
        [ -6.5149,  -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31411969661712646
Epoch 0, Step 1880: train/loss = 0.04025884345173836, train/raw-loss = 0.012844972312450409, train/logprobs = tensor([[ -1.3086, -14.9435],
        [ -5.5271,  -2.5572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2741386890411377
Epoch 0, Step 1881: train/loss = 0.03829307481646538, train/raw-loss = 0.0032823109067976475, train/logprobs = tensor([[ -1.3119, -12.5390],
        [ -7.0383,  -1.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35010766983032227
Epoch 0, Step 1882: train/loss = 0.03765173628926277, train/raw-loss = 0.0023969137109816074, train/logprobs = tensor([[ -1.1195, -10.4154],
        [ -8.0606,  -2.2952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352548211812973
Epoch 0, Step 1883: train/loss = 0.06798920780420303, train/raw-loss = 0.0358712375164032, train/logprobs = tensor([[ -0.6540, -10.0703],
        [ -5.0151,  -1.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32117971777915955
Epoch 0, Step 1884: train/loss = 0.03736081346869469, train/raw-loss = 0.0004292975354474038, train/logprobs = tensor([[ -1.8022, -12.0319],
        [-10.0739,  -1.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36931517720222473
Epoch 0, Step 1885: train/loss = 0.03627923130989075, train/raw-loss = 0.002097896533086896, train/logprobs = tensor([[ -1.3865, -11.5941],
        [ -8.2890,  -1.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341813325881958
Epoch 0, Step 1886: train/loss = 0.0350700244307518, train/raw-loss = 0.0026563722640275955, train/logprobs = tensor([[-1.0873, -8.2622],
        [-7.6298, -1.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32413649559020996
Epoch 0, Step 1887: train/loss = 0.039609748870134354, train/raw-loss = 0.0055683269165456295, train/logprobs = tensor([[-1.2231, -9.7346],
        [-7.8794, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34041422605514526
Epoch 0, Step 1888: train/loss = 0.04007355496287346, train/raw-loss = 0.005130469799041748, train/logprobs = tensor([[-1.3384, -7.7923],
        [-8.6290, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3494308292865753
Epoch 0, Step 1889: train/loss = 0.04287402704358101, train/raw-loss = 0.0026853871531784534, train/logprobs = tensor([[-1.1287, -9.8578],
        [-7.9622, -1.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4018864035606384
Epoch 0, Step 1890: train/loss = 0.05013703554868698, train/raw-loss = 0.01662561483681202, train/logprobs = tensor([[-1.0566, -9.7292],
        [-6.9592, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33511418104171753
Epoch 0, Step 1891: train/loss = 0.04242550581693649, train/raw-loss = 0.011309478431940079, train/logprobs = tensor([[-1.1444, -9.9659],
        [-6.0163, -2.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31116026639938354
Epoch 0, Step 1892: train/loss = 0.04347400739789009, train/raw-loss = 0.0019187512807548046, train/logprobs = tensor([[ -1.0093, -10.8752],
        [ -7.4457,  -2.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41555255651474
Epoch 0, Step 1893: train/loss = 0.035213783383369446, train/raw-loss = 0.0007639692630618811, train/logprobs = tensor([[ -0.9267, -12.9946],
        [ -8.7373,  -1.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3444980978965759
Epoch 0, Step 1894: train/loss = 0.03701333701610565, train/raw-loss = 0.0006692337337881327, train/logprobs = tensor([[ -0.9073, -11.4987],
        [ -7.7684,  -1.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634410500526428
Epoch 0, Step 1895: train/loss = 0.03539518639445305, train/raw-loss = 0.0014095902442932129, train/logprobs = tensor([[ -1.3235, -14.6904],
        [ -8.4733,  -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33985596895217896
Epoch 0, Step 1896: train/loss = 0.03310550004243851, train/raw-loss = 0.0006081286119297147, train/logprobs = tensor([[ -1.6999, -15.3748],
        [-10.6601,  -1.3589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249736726284027
Epoch 0, Step 1897: train/loss = 0.03885156661272049, train/raw-loss = 0.005262115970253944, train/logprobs = tensor([[ -1.1537, -10.3173],
        [ -8.1789,  -1.7805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33589446544647217
Epoch 0, Step 1898: train/loss = 0.03616320341825485, train/raw-loss = 0.0026230046059936285, train/logprobs = tensor([[ -1.0676, -13.6239],
        [ -7.3701,  -3.6016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3354020118713379
Epoch 0, Step 1899: train/loss = 0.03968372568488121, train/raw-loss = 0.005400159861892462, train/logprobs = tensor([[ -1.0106, -10.8518],
        [ -6.0811,  -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34283560514450073
Epoch 0, Step 1900: train/loss = 0.03622295707464218, train/raw-loss = 0.002656793687492609, train/logprobs = tensor([[ -0.9545, -10.6263],
        [ -8.6244,  -2.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3356616497039795
Epoch 0, Step 1901: train/loss = 0.03404886648058891, train/raw-loss = 0.0028794342651963234, train/logprobs = tensor([[ -1.2134, -14.5090],
        [ -7.6703,  -3.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31169432401657104
Epoch 0, Step 1902: train/loss = 0.044232334941625595, train/raw-loss = 0.01018912810832262, train/logprobs = tensor([[ -1.0944, -13.0662],
        [ -7.5777,  -2.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404320776462555
Epoch 0, Step 1903: train/loss = 0.03655562549829483, train/raw-loss = 0.0028524091467261314, train/logprobs = tensor([[-1.2108, -9.6406],
        [-8.2375, -1.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33703216910362244
Epoch 0, Step 1904: train/loss = 0.03811237961053848, train/raw-loss = 0.00392799312248826, train/logprobs = tensor([[ -1.1701, -12.4171],
        [ -6.4185,  -1.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341843843460083
Epoch 0, Step 1905: train/loss = 0.03786922246217728, train/raw-loss = 0.0012843559961766005, train/logprobs = tensor([[ -0.8315, -12.0359],
        [ -7.2004,  -1.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3658486604690552
Epoch 0, Step 1906: train/loss = 0.032725993543863297, train/raw-loss = 0.001232206355780363, train/logprobs = tensor([[-1.1651, -9.6267],
        [-8.8677, -1.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31493788957595825
Epoch 0, Step 1907: train/loss = 0.03927811607718468, train/raw-loss = 0.007679657079279423, train/logprobs = tensor([[-1.0559, -9.7234],
        [-8.6768, -2.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159845471382141
Epoch 0, Step 1908: train/loss = 0.039027564227581024, train/raw-loss = 0.0008971415809355676, train/logprobs = tensor([[ -1.0796, -12.3820],
        [ -8.5344,  -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38130420446395874
Epoch 0, Step 1909: train/loss = 0.04101887717843056, train/raw-loss = 0.00018347865261603147, train/logprobs = tensor([[ -1.3261, -14.5595],
        [-10.2455,  -2.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4083539843559265
Epoch 0, Step 1910: train/loss = 0.038378577679395676, train/raw-loss = 0.001574974157847464, train/logprobs = tensor([[ -0.7624, -13.9281],
        [ -7.4439,  -3.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36803603172302246
Epoch 0, Step 1911: train/loss = 0.037849996238946915, train/raw-loss = 0.0026248523499816656, train/logprobs = tensor([[ -1.1378, -13.5950],
        [ -6.6049,  -3.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35225144028663635
Epoch 0, Step 1912: train/loss = 0.045270390808582306, train/raw-loss = 0.011759333312511444, train/logprobs = tensor([[ -2.2641, -10.2195],
        [ -8.5684,  -2.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351105749607086
Epoch 0, Step 1913: train/loss = 0.04138557240366936, train/raw-loss = 0.002068436238914728, train/logprobs = tensor([[ -0.9776, -13.9832],
        [ -8.0283,  -2.5869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39317137002944946
Epoch 0, Step 1914: train/loss = 0.03348690643906593, train/raw-loss = 0.0009144964860752225, train/logprobs = tensor([[ -1.1059, -12.2343],
        [ -8.7135,  -1.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3257240951061249
Epoch 0, Step 1915: train/loss = 0.0424027144908905, train/raw-loss = 0.01286201924085617, train/logprobs = tensor([[ -0.9462, -10.3566],
        [ -7.5275,  -2.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29540693759918213
Epoch 0, Step 1916: train/loss = 0.03535834327340126, train/raw-loss = 0.00471681309863925, train/logprobs = tensor([[ -1.1327, -12.8667],
        [ -6.8606,  -2.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306415319442749
Epoch 0, Step 1917: train/loss = 0.039032548666000366, train/raw-loss = 0.0039337072521448135, train/logprobs = tensor([[-0.9436, -9.6863],
        [-6.5339, -1.3184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35098838806152344
Epoch 0, Step 1918: train/loss = 0.056521397083997726, train/raw-loss = 0.01740848645567894, train/logprobs = tensor([[-1.1040, -9.5993],
        [-7.7000, -3.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39112910628318787
Epoch 0, Step 1919: train/loss = 0.033638715744018555, train/raw-loss = 0.0005471386248245835, train/logprobs = tensor([[ -1.3657, -12.1860],
        [ -8.6383,  -1.3068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33091574907302856
Epoch 0, Step 1920: train/loss = 0.04408453032374382, train/raw-loss = 0.005426893010735512, train/logprobs = tensor([[ -1.0401, -12.0931],
        [ -8.4011,  -3.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.386576384305954
Epoch 0, Step 1921: train/loss = 0.039903607219457626, train/raw-loss = 0.00246157543733716, train/logprobs = tensor([[ -1.1266, -11.0076],
        [ -8.3584,  -2.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37442028522491455
Epoch 0, Step 1922: train/loss = 0.04853582754731178, train/raw-loss = 0.017851635813713074, train/logprobs = tensor([[-1.7373, -9.5443],
        [-9.2082, -1.2038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3068419098854065
Epoch 0, Step 1923: train/loss = 0.03592382371425629, train/raw-loss = 0.00027482464793138206, train/logprobs = tensor([[ -1.4473, -13.8722],
        [ -9.5184,  -2.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35649001598358154
Epoch 0, Step 1924: train/loss = 0.036871425807476044, train/raw-loss = 0.002804925898090005, train/logprobs = tensor([[ -1.5722, -11.8365],
        [ -9.4348,  -1.2566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34066495299339294
Epoch 0, Step 1925: train/loss = 0.03992120921611786, train/raw-loss = 0.0059880162589251995, train/logprobs = tensor([[-0.9320, -9.2043],
        [-7.2725, -1.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3393319249153137
Epoch 0, Step 1926: train/loss = 0.05331633985042572, train/raw-loss = 0.01939206011593342, train/logprobs = tensor([[-0.8923, -8.5370],
        [-6.4739, -2.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392427861690521
Epoch 0, Step 1927: train/loss = 0.03604196384549141, train/raw-loss = 0.006146185100078583, train/logprobs = tensor([[-1.0456, -9.8307],
        [-8.3282, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989577651023865
Epoch 0, Step 1928: train/loss = 0.044485293328762054, train/raw-loss = 0.005280946847051382, train/logprobs = tensor([[-0.9948, -9.0955],
        [-7.7190, -1.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39204344153404236
Epoch 0, Step 1929: train/loss = 0.03885159641504288, train/raw-loss = 0.0019332787487655878, train/logprobs = tensor([[ -0.9745, -12.7731],
        [ -7.4301,  -2.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36918315291404724
Epoch 0, Step 1930: train/loss = 0.03206785023212433, train/raw-loss = 0.00192786764819175, train/logprobs = tensor([[ -1.4011, -14.0959],
        [ -7.6505,  -2.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.301399827003479
Epoch 0, Step 1931: train/loss = 0.03723890334367752, train/raw-loss = 0.004751828499138355, train/logprobs = tensor([[ -1.4189, -11.8870],
        [ -8.1893,  -2.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.324870765209198
Epoch 0, Step 1932: train/loss = 0.03160732239484787, train/raw-loss = 0.0008859319495968521, train/logprobs = tensor([[ -1.2981, -12.8452],
        [ -8.6562,  -1.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3072138726711273
Epoch 0, Step 1933: train/loss = 0.03923086076974869, train/raw-loss = 0.004496486857533455, train/logprobs = tensor([[ -1.2243, -13.4271],
        [ -7.4100,  -3.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473437428474426
Epoch 0, Step 1934: train/loss = 0.04213560372591019, train/raw-loss = 0.001743955072015524, train/logprobs = tensor([[ -1.0221, -11.5092],
        [ -7.2188,  -2.4466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40391650795936584
Epoch 0, Step 1935: train/loss = 0.03737558424472809, train/raw-loss = 0.00494770985096693, train/logprobs = tensor([[ -0.9964, -11.3004],
        [ -8.0557,  -2.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3242787718772888
Epoch 0, Step 1936: train/loss = 0.03648289293050766, train/raw-loss = 0.0018454036908224225, train/logprobs = tensor([[ -1.5256, -13.5563],
        [ -9.7460,  -2.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34637489914894104
Epoch 0, Step 1937: train/loss = 0.0387897714972496, train/raw-loss = 0.0058019994758069515, train/logprobs = tensor([[ -1.7426, -11.1724],
        [ -8.3878,  -2.0810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32987767457962036
Epoch 0, Step 1938: train/loss = 0.03473808616399765, train/raw-loss = 0.0004635603982023895, train/logprobs = tensor([[ -1.0971, -12.2013],
        [-10.3351,  -1.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34274527430534363
Epoch 0, Step 1939: train/loss = 0.047082800418138504, train/raw-loss = 0.015046043321490288, train/logprobs = tensor([[-0.8639, -9.7783],
        [-7.1016, -1.3565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32036757469177246
Epoch 0, Step 1940: train/loss = 0.03597629815340042, train/raw-loss = 0.0014610938960686326, train/logprobs = tensor([[ -0.9300, -11.2260],
        [ -7.2558,  -1.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34515202045440674
Epoch 0, Step 1941: train/loss = 0.053006626665592194, train/raw-loss = 0.015302959829568863, train/logprobs = tensor([[ -1.2688, -11.3944],
        [ -7.6426,  -1.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3770366609096527
Epoch 0, Step 1942: train/loss = 0.03230615705251694, train/raw-loss = 0.0015292480820789933, train/logprobs = tensor([[ -1.3135, -13.8578],
        [ -8.1478,  -2.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077690601348877
Epoch 0, Step 1943: train/loss = 0.036472540348768234, train/raw-loss = 0.002581237815320492, train/logprobs = tensor([[ -1.0498, -15.0197],
        [ -7.5545,  -2.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3389130234718323
Epoch 0, Step 1944: train/loss = 0.03414711728692055, train/raw-loss = 0.0007025058148428798, train/logprobs = tensor([[ -1.1908, -12.2454],
        [ -9.0343,  -1.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33444613218307495
Epoch 0, Step 1945: train/loss = 0.05258546024560928, train/raw-loss = 0.01970193348824978, train/logprobs = tensor([[-1.1326, -8.7686],
        [-7.7934, -2.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32883524894714355
Epoch 0, Step 1946: train/loss = 0.12713313102722168, train/raw-loss = 0.09259451180696487, train/logprobs = tensor([[-0.7789, -5.8437],
        [-5.1639, -1.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3453860878944397
Epoch 0, Step 1947: train/loss = 0.04136274755001068, train/raw-loss = 0.0035466328263282776, train/logprobs = tensor([[ -1.1085, -10.4819],
        [ -8.3755,  -2.2586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37816116213798523
Epoch 0, Step 1948: train/loss = 0.04463674873113632, train/raw-loss = 0.009899299591779709, train/logprobs = tensor([[ -0.8092, -10.9602],
        [ -6.1258,  -2.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34737443923950195
Epoch 0, Step 1949: train/loss = 0.0405532605946064, train/raw-loss = 0.009050073102116585, train/logprobs = tensor([[ -1.3665, -10.0107],
        [ -7.7522,  -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31503185629844666
Epoch 0, Step 1950: train/loss = 0.034843310713768005, train/raw-loss = 0.0006670481525361538, train/logprobs = tensor([[ -1.2022, -11.9499],
        [ -9.1920,  -3.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34176260232925415
Epoch 0, Step 1951: train/loss = 0.04109378159046173, train/raw-loss = 0.001955453772097826, train/logprobs = tensor([[ -0.9844, -11.6599],
        [ -7.8967,  -2.5678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39138326048851013
Epoch 0, Step 1952: train/loss = 0.04725506156682968, train/raw-loss = 0.01563950441777706, train/logprobs = tensor([[ -0.8700, -11.4568],
        [ -6.3541,  -3.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3161555528640747
Epoch 0, Step 1953: train/loss = 0.037755273282527924, train/raw-loss = 0.005948416888713837, train/logprobs = tensor([[-1.3778, -9.9573],
        [-7.2990, -0.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3180685341358185
Epoch 0, Step 1954: train/loss = 0.07521454244852066, train/raw-loss = 0.04565081745386124, train/logprobs = tensor([[ -1.8171, -13.7247],
        [ -6.3434,  -2.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29563724994659424
Epoch 0, Step 1955: train/loss = 0.03751818463206291, train/raw-loss = 0.00048493477515876293, train/logprobs = tensor([[ -1.3075, -13.8471],
        [ -8.9988,  -2.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3703324794769287
Epoch 0, Step 1956: train/loss = 0.03356725722551346, train/raw-loss = 0.0010052435100078583, train/logprobs = tensor([[ -1.2748, -11.5225],
        [ -7.8186,  -1.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3256201446056366
Epoch 0, Step 1957: train/loss = 0.036586519330739975, train/raw-loss = 0.0018479690188542008, train/logprobs = tensor([[ -1.3828, -10.5603],
        [ -8.9072,  -1.5706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3473854959011078
Epoch 0, Step 1958: train/loss = 0.03776153177022934, train/raw-loss = 0.0033768056891858578, train/logprobs = tensor([[ -0.9846, -11.2527],
        [ -7.3336,  -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34384727478027344
Epoch 0, Step 1959: train/loss = 0.053179074078798294, train/raw-loss = 0.016965828835964203, train/logprobs = tensor([[ -1.1665,  -8.5834],
        [-10.2118,  -2.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3621324598789215
Epoch 0, Step 1960: train/loss = 0.07577657699584961, train/raw-loss = 0.0398118682205677, train/logprobs = tensor([[-1.1432, -7.7200],
        [-6.2097, -1.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35964706540107727
Epoch 0, Step 1961: train/loss = 0.03583472594618797, train/raw-loss = 0.001755780540406704, train/logprobs = tensor([[ -1.0038, -13.3520],
        [ -7.6315,  -2.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34078943729400635
Epoch 0, Step 1962: train/loss = 0.03428666293621063, train/raw-loss = 0.0021647303365170956, train/logprobs = tensor([[ -1.0482, -11.9691],
        [ -7.8705,  -2.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3212193250656128
Epoch 0, Step 1963: train/loss = 0.031392909586429596, train/raw-loss = 0.002992698224261403, train/logprobs = tensor([[ -1.3708, -12.5094],
        [ -6.7499,  -0.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840021252632141
Epoch 0, Step 1964: train/loss = 0.03961014747619629, train/raw-loss = 0.005131823010742664, train/logprobs = tensor([[ -1.1971, -11.8419],
        [ -6.0660,  -3.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447832465171814
Epoch 0, Step 1965: train/loss = 0.0360090434551239, train/raw-loss = 0.003245224244892597, train/logprobs = tensor([[ -1.1272, -12.4343],
        [ -6.1906,  -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276381492614746
Epoch 0, Step 1966: train/loss = 0.06996308267116547, train/raw-loss = 0.03527354821562767, train/logprobs = tensor([[-1.3095, -8.8371],
        [-8.6067, -3.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34689539670944214
Epoch 0, Step 1967: train/loss = 0.03179274871945381, train/raw-loss = 0.0007086448604241014, train/logprobs = tensor([[ -1.1050, -12.3887],
        [ -9.3619,  -1.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31084102392196655
Epoch 0, Step 1968: train/loss = 0.03339216113090515, train/raw-loss = 0.001150380470789969, train/logprobs = tensor([[ -1.0681, -11.2030],
        [ -8.9041,  -3.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224177956581116
Epoch 0, Step 1969: train/loss = 0.04250076785683632, train/raw-loss = 0.015756236389279366, train/logprobs = tensor([[-1.8014, -8.5926],
        [-8.2491, -2.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26744532585144043
Epoch 0, Step 1970: train/loss = 0.04710201174020767, train/raw-loss = 0.011276684701442719, train/logprobs = tensor([[-0.9786, -9.1108],
        [-8.1765, -2.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35825324058532715
Epoch 0, Step 1971: train/loss = 0.03726258873939514, train/raw-loss = 0.0012251531006768346, train/logprobs = tensor([[ -0.7883, -13.9144],
        [ -7.7992,  -3.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.360374391078949
Epoch 0, Step 1972: train/loss = 0.03727688640356064, train/raw-loss = 0.002018947619944811, train/logprobs = tensor([[ -0.8444, -11.4904],
        [ -8.3249,  -2.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35257941484451294
Epoch 0, Step 1973: train/loss = 0.036753058433532715, train/raw-loss = 0.0022128059063106775, train/logprobs = tensor([[ -1.0160, -12.5262],
        [ -6.6554,  -3.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3454025089740753
Epoch 0, Step 1974: train/loss = 0.0454651303589344, train/raw-loss = 0.012399827130138874, train/logprobs = tensor([[ -1.3143, -10.8962],
        [ -8.9004,  -2.3124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33065304160118103
Epoch 0, Step 1975: train/loss = 0.03422822803258896, train/raw-loss = 0.0022380987647920847, train/logprobs = tensor([[-1.0044, -9.9648],
        [-6.7242, -1.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199012875556946
Epoch 0, Step 1976: train/loss = 0.03790159523487091, train/raw-loss = 0.003775748424232006, train/logprobs = tensor([[-1.1992, -9.5743],
        [-7.7846, -2.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3412584662437439
Epoch 0, Step 1977: train/loss = 0.03806477040052414, train/raw-loss = 0.009813333861529827, train/logprobs = tensor([[ -1.6089, -10.8235],
        [ -9.5130,  -2.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282514363527298
Epoch 0, Step 1978: train/loss = 0.032188721001148224, train/raw-loss = 0.00018941922462545335, train/logprobs = tensor([[ -1.3282, -13.8081],
        [-10.9465,  -2.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199929893016815
Epoch 0, Step 1979: train/loss = 0.04791449382901192, train/raw-loss = 0.019611075520515442, train/logprobs = tensor([[ -1.4753, -12.2204],
        [ -8.1734,  -2.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28303417563438416
Epoch 0, Step 1980: train/loss = 0.03826192766427994, train/raw-loss = 0.0066177137196063995, train/logprobs = tensor([[ -1.4255, -12.8545],
        [ -9.6019,  -2.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164421319961548
Epoch 0, Step 1981: train/loss = 0.04018201678991318, train/raw-loss = 0.009050882421433926, train/logprobs = tensor([[-1.3089, -8.7895],
        [-8.3176, -2.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31131136417388916
Epoch 0, Step 1982: train/loss = 0.03754756972193718, train/raw-loss = 0.001206262968480587, train/logprobs = tensor([[ -0.9028, -14.0217],
        [ -7.7910,  -2.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634130358695984
Epoch 0, Step 1983: train/loss = 0.03879605233669281, train/raw-loss = 0.0021430382039397955, train/logprobs = tensor([[ -1.3560, -12.5284],
        [ -8.0584,  -2.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3665301501750946
Epoch 0, Step 1984: train/loss = 0.0431123822927475, train/raw-loss = 0.006740579381585121, train/logprobs = tensor([[-0.7732, -7.3647],
        [-7.8927, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36371803283691406
Epoch 0, Step 1985: train/loss = 0.05507258325815201, train/raw-loss = 0.02118583954870701, train/logprobs = tensor([[ -1.0501, -11.1580],
        [ -7.1177,  -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3388674855232239
Epoch 0, Step 1986: train/loss = 0.07306211441755295, train/raw-loss = 0.03616301715373993, train/logprobs = tensor([[-1.2897, -6.8405],
        [-9.2497, -2.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.368990957736969
Epoch 0, Step 1987: train/loss = 0.04053061082959175, train/raw-loss = 0.0012302161194384098, train/logprobs = tensor([[ -0.7109, -14.1123],
        [ -6.9297,  -1.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.393003910779953
Epoch 0, Step 1988: train/loss = 0.03781787306070328, train/raw-loss = 0.0009933809051290154, train/logprobs = tensor([[ -0.9516,  -9.9330],
        [-10.0422,  -1.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3682449460029602
Epoch 0, Step 1989: train/loss = 0.05061998963356018, train/raw-loss = 0.00921496283262968, train/logprobs = tensor([[ -1.0128, -10.1360],
        [ -9.2908,  -2.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41405022144317627
Epoch 0, Step 1990: train/loss = 0.059633515775203705, train/raw-loss = 0.025055980309844017, train/logprobs = tensor([[-0.6268, -9.8345],
        [-5.2578, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457753360271454
Epoch 0, Step 1991: train/loss = 0.033472880721092224, train/raw-loss = 0.0036768715362995863, train/logprobs = tensor([[ -1.3569, -12.2890],
        [ -8.8705,  -2.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297960102558136
Epoch 0, Step 1992: train/loss = 0.04397055134177208, train/raw-loss = 0.0007205914007499814, train/logprobs = tensor([[ -0.8916, -13.0833],
        [ -7.5123,  -1.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43249955773353577
Epoch 0, Step 1993: train/loss = 0.041345834732055664, train/raw-loss = 0.013528221286833286, train/logprobs = tensor([[ -1.1680, -10.4370],
        [ -6.3390,  -2.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27817609906196594
Epoch 0, Step 1994: train/loss = 0.03507651016116142, train/raw-loss = 0.002841018605977297, train/logprobs = tensor([[-1.1483, -9.2150],
        [-8.9221, -2.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32235491275787354
Epoch 0, Step 1995: train/loss = 0.03334588184952736, train/raw-loss = 0.0017352328868582845, train/logprobs = tensor([[ -1.0115, -14.7977],
        [ -7.1776,  -3.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31610649824142456
Epoch 0, Step 1996: train/loss = 0.04002974554896355, train/raw-loss = 0.004610302858054638, train/logprobs = tensor([[ -1.2584, -10.5956],
        [ -9.0337,  -2.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35419440269470215
Epoch 0, Step 1997: train/loss = 0.043922532349824905, train/raw-loss = 0.014907220378518105, train/logprobs = tensor([[ -0.9599, -11.0774],
        [ -8.1370,  -1.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2901531159877777
Epoch 0, Step 1998: train/loss = 0.05525614321231842, train/raw-loss = 0.02617659606039524, train/logprobs = tensor([[-0.7727, -9.9006],
        [-5.9000, -1.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907955050468445
Epoch 0, Step 1999: train/loss = 0.03735039383172989, train/raw-loss = 0.0004403969505801797, train/logprobs = tensor([[ -1.3619, -13.2945],
        [ -9.8675,  -3.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36910000443458557
Epoch 0, Step 2000: train/loss = 0.05231078714132309, train/raw-loss = 0.020863011479377747, train/logprobs = tensor([[ -1.1039, -10.4560],
        [ -8.6918,  -1.3674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31447774171829224
Epoch 0, Step 2001: train/loss = 0.0607716403901577, train/raw-loss = 0.030910545960068703, train/logprobs = tensor([[-0.8962, -7.6111],
        [-5.3156, -1.1694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2986109256744385
Epoch 0, Step 2002: train/loss = 0.04057178273797035, train/raw-loss = 0.0029789989348500967, train/logprobs = tensor([[ -0.8094, -11.2197],
        [ -6.8665,  -2.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37592780590057373
Epoch 0, Step 2003: train/loss = 0.03678780421614647, train/raw-loss = 0.0007563966792076826, train/logprobs = tensor([[ -1.0404, -14.3684],
        [ -7.8868,  -2.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3603140711784363
Epoch 0, Step 2004: train/loss = 0.03433311730623245, train/raw-loss = 0.0036493169609457254, train/logprobs = tensor([[-1.0117, -9.4066],
        [-7.9716, -1.4656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3068379759788513
Epoch 0, Step 2005: train/loss = 0.03449247032403946, train/raw-loss = 0.001053072977811098, train/logprobs = tensor([[ -0.9472, -14.7962],
        [ -9.1451,  -3.5548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3343939185142517
Epoch 0, Step 2006: train/loss = 0.0376872755587101, train/raw-loss = 0.0052206325344741344, train/logprobs = tensor([[ -0.8985, -16.4029],
        [ -6.5747,  -2.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32466641068458557
Epoch 0, Step 2007: train/loss = 0.04040437191724777, train/raw-loss = 0.0064076450653374195, train/logprobs = tensor([[ -1.4167, -11.5880],
        [ -9.9251,  -3.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3399672508239746
Epoch 0, Step 2008: train/loss = 0.036218203604221344, train/raw-loss = 0.0016236171359196305, train/logprobs = tensor([[ -1.0338, -10.9093],
        [ -7.9442,  -1.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3459458649158478
Epoch 0, Step 2009: train/loss = 0.05827048420906067, train/raw-loss = 0.024927008897066116, train/logprobs = tensor([[-1.1529, -9.4971],
        [-7.1674, -2.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33343473076820374
Epoch 0, Step 2010: train/loss = 0.03383267670869827, train/raw-loss = 0.0012306493008509278, train/logprobs = tensor([[ -1.0360, -13.3531],
        [ -7.3590,  -1.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3260202705860138
Epoch 0, Step 2011: train/loss = 0.040960781276226044, train/raw-loss = 0.003942086827009916, train/logprobs = tensor([[-1.0879, -9.3304],
        [-8.1242, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3701869249343872
Epoch 0, Step 2012: train/loss = 0.05614922195672989, train/raw-loss = 0.022486839443445206, train/logprobs = tensor([[-1.1135, -8.5095],
        [-7.6910, -1.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33662378787994385
Epoch 0, Step 2013: train/loss = 0.03861796110868454, train/raw-loss = 0.004929995629936457, train/logprobs = tensor([[-1.0432, -9.4715],
        [-7.0399, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3368796706199646
Epoch 0, Step 2014: train/loss = 0.038172949105501175, train/raw-loss = 0.0026337457820773125, train/logprobs = tensor([[ -0.8059, -10.9627],
        [ -6.8150,  -1.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553920388221741
Epoch 0, Step 2015: train/loss = 0.03432708978652954, train/raw-loss = 0.002220757305622101, train/logprobs = tensor([[-1.4495, -9.2203],
        [-9.5115, -1.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210632801055908
Epoch 0, Step 2016: train/loss = 0.03825613483786583, train/raw-loss = 0.009860124439001083, train/logprobs = tensor([[ -1.1039, -11.4568],
        [ -8.3762,  -2.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28396010398864746
Epoch 0, Step 2017: train/loss = 0.03775695711374283, train/raw-loss = 0.0009593403665348887, train/logprobs = tensor([[ -0.8819, -11.1731],
        [ -8.4263,  -2.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36797618865966797
Epoch 0, Step 2018: train/loss = 0.03394370898604393, train/raw-loss = 0.0007949209539219737, train/logprobs = tensor([[ -1.2222, -12.2184],
        [ -8.4784,  -2.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33148789405822754
Epoch 0, Step 2019: train/loss = 0.03486683964729309, train/raw-loss = 0.0023702532052993774, train/logprobs = tensor([[ -1.2067, -11.4416],
        [-10.0707,  -1.6196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32496583461761475
Epoch 0, Step 2020: train/loss = 0.03644475340843201, train/raw-loss = 0.002525756601244211, train/logprobs = tensor([[ -0.9573, -11.0426],
        [ -8.7280,  -2.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33918994665145874
Epoch 0, Step 2021: train/loss = 0.03795739635825157, train/raw-loss = 0.0030610656831413507, train/logprobs = tensor([[ -1.0184, -10.5181],
        [ -7.6198,  -2.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34896332025527954
Epoch 0, Step 2022: train/loss = 0.04021105170249939, train/raw-loss = 0.005140585824847221, train/logprobs = tensor([[-0.9354, -9.2737],
        [-7.7851, -2.3104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3507046401500702
Epoch 0, Step 2023: train/loss = 0.03779461234807968, train/raw-loss = 0.0012420795392245054, train/logprobs = tensor([[ -1.0031, -13.9267],
        [ -9.4086,  -4.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3655253052711487
Epoch 0, Step 2024: train/loss = 0.07211779057979584, train/raw-loss = 0.03786472976207733, train/logprobs = tensor([[-1.1922, -9.9105],
        [-8.6040, -4.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34253060817718506
Epoch 0, Step 2025: train/loss = 0.03349233418703079, train/raw-loss = 0.0005362174706533551, train/logprobs = tensor([[ -1.6788, -10.7611],
        [-10.8047,  -1.4154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32956117391586304
Epoch 0, Step 2026: train/loss = 0.056333277374506, train/raw-loss = 0.027545355260372162, train/logprobs = tensor([[-1.2899, -9.8777],
        [-7.1262, -2.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28787925839424133
Epoch 0, Step 2027: train/loss = 0.03936370834708214, train/raw-loss = 0.0007320488803088665, train/logprobs = tensor([[ -1.0132, -12.3086],
        [ -8.1148,  -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38631656765937805
Epoch 0, Step 2028: train/loss = 0.04207200929522514, train/raw-loss = 0.0055817607790231705, train/logprobs = tensor([[ -0.8117, -11.1931],
        [ -7.1916,  -2.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36490243673324585
Epoch 0, Step 2029: train/loss = 0.04120515659451485, train/raw-loss = 0.005377803463488817, train/logprobs = tensor([[-0.8599, -9.6338],
        [-7.2208, -1.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35827356576919556
Epoch 0, Step 2030: train/loss = 0.038487158715724945, train/raw-loss = 0.0004732701345346868, train/logprobs = tensor([[ -1.3030, -14.0092],
        [-10.8083,  -2.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3801388740539551
Epoch 0, Step 2031: train/loss = 0.03477150946855545, train/raw-loss = 0.001619225018657744, train/logprobs = tensor([[ -1.0940,  -9.4401],
        [-10.0781,  -0.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3315228223800659
Epoch 0, Step 2032: train/loss = 0.03932420164346695, train/raw-loss = 0.0024469327181577682, train/logprobs = tensor([[ -0.8152, -14.0524],
        [ -6.7880,  -2.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3687726855278015
Epoch 0, Step 2033: train/loss = 0.03445780649781227, train/raw-loss = 0.0019626154098659754, train/logprobs = tensor([[-0.9807, -9.3914],
        [-7.9808, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249518871307373
Epoch 0, Step 2034: train/loss = 0.07747085392475128, train/raw-loss = 0.03926335647702217, train/logprobs = tensor([[ -1.0060, -11.8497],
        [ -8.9006,  -1.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820749521255493
Epoch 0, Step 2035: train/loss = 0.03274906426668167, train/raw-loss = 0.002690294524654746, train/logprobs = tensor([[ -1.1438, -10.2264],
        [ -7.8568,  -1.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005876839160919
Epoch 0, Step 2036: train/loss = 0.03377412259578705, train/raw-loss = 0.005285048857331276, train/logprobs = tensor([[ -1.0650, -12.5333],
        [ -8.1663,  -1.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848907709121704
Epoch 0, Step 2037: train/loss = 0.038237836211919785, train/raw-loss = 0.006556892301887274, train/logprobs = tensor([[ -1.4146, -12.7989],
        [ -8.6598,  -1.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31680941581726074
Epoch 0, Step 2038: train/loss = 0.04317539185285568, train/raw-loss = 0.010271717794239521, train/logprobs = tensor([[ -0.7588, -14.2854],
        [ -7.0218,  -2.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32903674244880676
Epoch 0, Step 2039: train/loss = 0.03486882895231247, train/raw-loss = 0.0014724716311320662, train/logprobs = tensor([[ -0.8636, -11.7202],
        [ -6.9911,  -1.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3339635729789734
Epoch 0, Step 2040: train/loss = 0.045079562813043594, train/raw-loss = 0.0033030672930181026, train/logprobs = tensor([[-0.7333, -9.2110],
        [-7.4433, -1.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41776490211486816
Epoch 0, Step 2041: train/loss = 0.03169635683298111, train/raw-loss = 0.00225796434096992, train/logprobs = tensor([[ -1.0444, -10.3718],
        [ -9.2727,  -2.2768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943839132785797
Epoch 0, Step 2042: train/loss = 0.03428449481725693, train/raw-loss = 0.0028702779673039913, train/logprobs = tensor([[-0.7945, -9.6208],
        [-6.5329, -0.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141421675682068
Epoch 0, Step 2043: train/loss = 0.04428136721253395, train/raw-loss = 0.011991024017333984, train/logprobs = tensor([[ -2.3715, -12.6968],
        [-10.4488,  -3.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32290342450141907
Epoch 0, Step 2044: train/loss = 0.03780164569616318, train/raw-loss = 0.00606097187846899, train/logprobs = tensor([[-1.0803, -7.8851],
        [-7.4506, -1.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3174067437648773
Epoch 0, Step 2045: train/loss = 0.03766968846321106, train/raw-loss = 0.0029996447265148163, train/logprobs = tensor([[-1.1276, -9.9733],
        [-6.8165, -1.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34670042991638184
Epoch 0, Step 2046: train/loss = 0.037239398807287216, train/raw-loss = 0.0020690623205155134, train/logprobs = tensor([[-1.4043, -9.6613],
        [-9.7881, -1.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35170337557792664
Epoch 0, Step 2047: train/loss = 0.03901252523064613, train/raw-loss = 0.003285040147602558, train/logprobs = tensor([[ -0.9387, -12.5434],
        [ -9.5244,  -2.6239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3572748601436615
Epoch 0, Step 2048: train/loss = 0.046077027916908264, train/raw-loss = 0.006038332358002663, train/logprobs = tensor([[ -0.8468, -13.0291],
        [ -8.4394,  -3.4943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4003869593143463
Epoch 0, Step 2049: train/loss = 0.035869259387254715, train/raw-loss = 0.0020776414312422276, train/logprobs = tensor([[ -0.9588, -11.4773],
        [ -7.8046,  -1.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33791613578796387
Epoch 0, Step 2050: train/loss = 0.033705342561006546, train/raw-loss = 0.0017651418456807733, train/logprobs = tensor([[ -1.2165, -14.7830],
        [ -8.8786,  -2.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194020390510559
Epoch 0, Step 2051: train/loss = 0.03353859484195709, train/raw-loss = 0.0005625949706882238, train/logprobs = tensor([[ -1.3997, -12.6550],
        [ -9.5514,  -3.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32975998520851135
Epoch 0, Step 2052: train/loss = 0.03765734285116196, train/raw-loss = 0.0021722649689763784, train/logprobs = tensor([[ -0.9451, -11.6205],
        [ -7.9618,  -2.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35485076904296875
Epoch 0, Step 2053: train/loss = 0.07517635822296143, train/raw-loss = 0.04744061827659607, train/logprobs = tensor([[ -0.7435, -11.0729],
        [ -6.1558,  -2.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27735742926597595
Epoch 0, Step 2054: train/loss = 0.031191755086183548, train/raw-loss = 0.0007342261960729957, train/logprobs = tensor([[ -1.2218, -11.3024],
        [ -8.0304,  -1.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30457526445388794
Epoch 0, Step 2055: train/loss = 0.03391844034194946, train/raw-loss = 0.0003977332089561969, train/logprobs = tensor([[ -1.3692, -12.3652],
        [-12.0165,  -2.0294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352070748806
Epoch 0, Step 2056: train/loss = 0.040793031454086304, train/raw-loss = 0.004013644531369209, train/logprobs = tensor([[ -1.3804, -10.5914],
        [ -9.5153,  -2.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36779385805130005
Epoch 0, Step 2057: train/loss = 0.03267839178442955, train/raw-loss = 0.000496084161568433, train/logprobs = tensor([[ -1.3811, -12.5337],
        [-11.3145,  -2.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218230605125427
Epoch 0, Step 2058: train/loss = 0.03621712327003479, train/raw-loss = 0.0018806601874530315, train/logprobs = tensor([[ -1.2663, -10.4637],
        [ -9.6802,  -1.5892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433646261692047
Epoch 0, Step 2059: train/loss = 0.03848256170749664, train/raw-loss = 0.005320762284100056, train/logprobs = tensor([[ -1.0262, -11.7457],
        [ -6.6006,  -2.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3316180109977722
Epoch 0, Step 2060: train/loss = 0.036392439156770706, train/raw-loss = 0.0016893631545826793, train/logprobs = tensor([[ -0.8188, -12.1923],
        [ -7.5104,  -2.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34703075885772705
Epoch 0, Step 2061: train/loss = 0.035712726414203644, train/raw-loss = 0.0019103259546682239, train/logprobs = tensor([[ -1.0518, -11.8972],
        [ -8.2056,  -1.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33802399039268494
Epoch 0, Step 2062: train/loss = 0.03652994707226753, train/raw-loss = 0.0011626743944361806, train/logprobs = tensor([[ -1.2339, -10.5814],
        [ -7.6899,  -2.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35367274284362793
Epoch 0, Step 2063: train/loss = 0.03467555344104767, train/raw-loss = 0.003595541464164853, train/logprobs = tensor([[ -0.8127, -10.2393],
        [ -6.6508,  -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31080010533332825
Epoch 0, Step 2064: train/loss = 0.03611389175057411, train/raw-loss = 0.0029650270007550716, train/logprobs = tensor([[ -1.5136, -10.9441],
        [ -8.6080,  -2.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33148863911628723
Epoch 0, Step 2065: train/loss = 0.03300279378890991, train/raw-loss = 0.0024058043491095304, train/logprobs = tensor([[-0.8509, -9.8037],
        [-6.7061, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30596989393234253
Epoch 0, Step 2066: train/loss = 0.08163730800151825, train/raw-loss = 0.05245974287390709, train/logprobs = tensor([[-1.1425, -6.1892],
        [-8.7342, -1.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29177558422088623
Epoch 0, Step 2067: train/loss = 0.0392937958240509, train/raw-loss = 0.00031169626163318753, train/logprobs = tensor([[ -0.9114, -13.1084],
        [ -9.4946,  -2.3969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38982099294662476
Epoch 0, Step 2068: train/loss = 0.03558754920959473, train/raw-loss = 0.00205904059112072, train/logprobs = tensor([[ -0.8481, -10.8920],
        [ -7.3130,  -1.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352850675582886
Epoch 0, Step 2069: train/loss = 0.16778509318828583, train/raw-loss = 0.13874338567256927, train/logprobs = tensor([[ -0.9641, -14.1050],
        [ -8.1839,  -3.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29041701555252075
Epoch 0, Step 2070: train/loss = 0.041515372693538666, train/raw-loss = 0.008186708204448223, train/logprobs = tensor([[ -0.6134, -11.4347],
        [ -8.0052,  -3.1930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332866430282593
Epoch 0, Step 2071: train/loss = 0.03813964128494263, train/raw-loss = 0.0037840274162590504, train/logprobs = tensor([[ -0.8686, -13.5524],
        [ -7.3228,  -2.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34355613589286804
Epoch 0, Step 2072: train/loss = 0.03109995275735855, train/raw-loss = 0.001771046663634479, train/logprobs = tensor([[ -1.0172, -11.8989],
        [ -9.1289,  -1.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29328906536102295
Epoch 0, Step 2073: train/loss = 0.03530653566122055, train/raw-loss = 0.0015353693161159754, train/logprobs = tensor([[ -0.9838, -10.7658],
        [ -8.8387,  -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3377116620540619
Epoch 0, Step 2074: train/loss = 0.04080347344279289, train/raw-loss = 0.004715183284133673, train/logprobs = tensor([[ -1.0049, -10.2775],
        [ -8.0462,  -1.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36088287830352783
Epoch 0, Step 2075: train/loss = 0.04394242540001869, train/raw-loss = 0.005245724692940712, train/logprobs = tensor([[ -1.0182, -12.0950],
        [ -8.6662,  -3.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3869670033454895
Epoch 0, Step 2076: train/loss = 0.03309599310159683, train/raw-loss = 0.006039496045559645, train/logprobs = tensor([[-1.4095, -9.7164],
        [-7.5104, -2.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705649435520172
Epoch 0, Step 2077: train/loss = 0.0396786630153656, train/raw-loss = 0.0068244789727032185, train/logprobs = tensor([[-0.9847, -7.4472],
        [-7.9646, -1.7585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285418450832367
Epoch 0, Step 2078: train/loss = 0.03794097900390625, train/raw-loss = 0.0009593504946678877, train/logprobs = tensor([[ -1.0473, -14.2053],
        [ -7.6554,  -2.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36981630325317383
Epoch 0, Step 2079: train/loss = 0.036003366112709045, train/raw-loss = 0.0030419637914747, train/logprobs = tensor([[-0.9393, -8.2823],
        [-8.0410, -1.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32961398363113403
Epoch 0, Step 2080: train/loss = 0.03717958182096481, train/raw-loss = 0.000883433734998107, train/logprobs = tensor([[ -1.4905, -10.5694],
        [-11.8936,  -1.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629615008831024
Epoch 0, Step 2081: train/loss = 0.0440802238881588, train/raw-loss = 0.007750687189400196, train/logprobs = tensor([[-1.1823, -9.5586],
        [-8.0135, -2.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3632953464984894
Epoch 0, Step 2082: train/loss = 0.0326261967420578, train/raw-loss = 0.0012404628796502948, train/logprobs = tensor([[ -1.4251, -10.8504],
        [-10.3369,  -1.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3138573467731476
Epoch 0, Step 2083: train/loss = 0.031194856390357018, train/raw-loss = 0.002070027869194746, train/logprobs = tensor([[ -1.4349, -12.1641],
        [ -8.8124,  -3.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29124829173088074
Epoch 0, Step 2084: train/loss = 0.03197431564331055, train/raw-loss = 0.0003069726226385683, train/logprobs = tensor([[ -1.4202, -11.2020],
        [-10.1347,  -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3166733980178833
Epoch 0, Step 2085: train/loss = 0.04680115729570389, train/raw-loss = 0.011119512841105461, train/logprobs = tensor([[ -1.2549, -12.8996],
        [ -9.9304,  -4.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35681647062301636
Epoch 0, Step 2086: train/loss = 0.03370019793510437, train/raw-loss = 0.0010722398292273283, train/logprobs = tensor([[-1.3928, -9.7918],
        [-8.3767, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32627955079078674
Epoch 0, Step 2087: train/loss = 0.039697665721178055, train/raw-loss = 0.006657557096332312, train/logprobs = tensor([[-1.3693, -8.1073],
        [-9.9177, -1.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33040106296539307
Epoch 0, Step 2088: train/loss = 0.039622023701667786, train/raw-loss = 0.007612474262714386, train/logprobs = tensor([[-1.1108, -9.5492],
        [-6.4196, -2.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200954794883728
Epoch 0, Step 2089: train/loss = 0.058865368366241455, train/raw-loss = 0.0233587846159935, train/logprobs = tensor([[-1.1841, -6.1513],
        [-9.6298, -1.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35506582260131836
Epoch 0, Step 2090: train/loss = 0.041420675814151764, train/raw-loss = 0.0007466362440027297, train/logprobs = tensor([[ -1.3223, -11.5998],
        [-10.5672,  -3.1845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40674036741256714
Epoch 0, Step 2091: train/loss = 0.03239122033119202, train/raw-loss = 0.00255333399400115, train/logprobs = tensor([[ -1.1043, -11.7586],
        [ -9.1048,  -1.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983788251876831
Epoch 0, Step 2092: train/loss = 0.03456558287143707, train/raw-loss = 0.0014390391297638416, train/logprobs = tensor([[ -1.1788, -11.0801],
        [ -9.2329,  -2.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3312654197216034
Epoch 0, Step 2093: train/loss = 0.0475701279938221, train/raw-loss = 0.017379023134708405, train/logprobs = tensor([[ -1.0620, -12.6302],
        [ -8.3251,  -2.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30191105604171753
Epoch 0, Step 2094: train/loss = 0.03463701903820038, train/raw-loss = 0.0006016377592459321, train/logprobs = tensor([[ -1.1855, -12.7377],
        [ -8.7760,  -2.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.340353786945343
Epoch 0, Step 2095: train/loss = 0.049226656556129456, train/raw-loss = 0.014380964450538158, train/logprobs = tensor([[-1.1683, -7.1610],
        [-9.0276, -1.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484569489955902
Epoch 0, Step 2096: train/loss = 0.04448908939957619, train/raw-loss = 0.012219608761370182, train/logprobs = tensor([[-0.7713, -9.3138],
        [-6.8209, -1.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3226948380470276
Epoch 0, Step 2097: train/loss = 0.052185870707035065, train/raw-loss = 0.022272570058703423, train/logprobs = tensor([[-0.8069, -7.1429],
        [-7.2462, -1.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991330027580261
Epoch 0, Step 2098: train/loss = 0.04525468498468399, train/raw-loss = 0.011161785572767258, train/logprobs = tensor([[-1.2180, -8.4388],
        [-8.5252, -3.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34092897176742554
Epoch 0, Step 2099: train/loss = 0.03652474284172058, train/raw-loss = 0.002354893134906888, train/logprobs = tensor([[ -1.4771, -11.5742],
        [-11.3967,  -2.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416984975337982
Epoch 0, Step 2100: train/loss = 0.03749339282512665, train/raw-loss = 0.004658801946789026, train/logprobs = tensor([[ -1.0154, -10.7722],
        [ -8.1455,  -2.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32834592461586
Epoch 0, Step 2101: train/loss = 0.0340242013335228, train/raw-loss = 0.0013602642575278878, train/logprobs = tensor([[-1.6452, -9.2635],
        [-8.8620, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266393542289734
Epoch 0, Step 2102: train/loss = 0.03627612441778183, train/raw-loss = 0.0008879917440935969, train/logprobs = tensor([[ -1.0444, -11.2217],
        [ -9.3493,  -1.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.353881299495697
Epoch 0, Step 2103: train/loss = 0.036350104957818985, train/raw-loss = 0.0018861701246351004, train/logprobs = tensor([[ -1.0888, -11.8338],
        [ -7.6061,  -4.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34463930130004883
Epoch 0, Step 2104: train/loss = 0.0361735001206398, train/raw-loss = 0.0018313692416995764, train/logprobs = tensor([[-1.0035, -9.6394],
        [-9.9584, -2.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3434213399887085
Epoch 0, Step 2105: train/loss = 0.03560779243707657, train/raw-loss = 0.0042325034737586975, train/logprobs = tensor([[ -1.1386, -13.8326],
        [ -7.0679,  -2.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137529194355011
Epoch 0, Step 2106: train/loss = 0.038302693516016006, train/raw-loss = 0.0013349452055990696, train/logprobs = tensor([[ -1.0130, -11.0756],
        [ -7.8412,  -1.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36967748403549194
Epoch 0, Step 2107: train/loss = 0.03343498706817627, train/raw-loss = 0.0019508691038936377, train/logprobs = tensor([[ -1.7540, -11.6453],
        [ -9.9006,  -2.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3148411810398102
Epoch 0, Step 2108: train/loss = 0.03404152765870094, train/raw-loss = 0.0020351505372673273, train/logprobs = tensor([[ -1.0551, -15.6200],
        [ -7.0313,  -3.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200637400150299
Epoch 0, Step 2109: train/loss = 0.033111583441495895, train/raw-loss = 0.002554333070293069, train/logprobs = tensor([[-1.0010, -8.4716],
        [-8.7213, -1.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305572509765625
Epoch 0, Step 2110: train/loss = 0.03934422880411148, train/raw-loss = 0.013793013989925385, train/logprobs = tensor([[ -1.3318, -10.5921],
        [ -6.5541,  -2.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25551217794418335
Epoch 0, Step 2111: train/loss = 0.03482621908187866, train/raw-loss = 0.0074402326717972755, train/logprobs = tensor([[ -1.4756, -11.4999],
        [ -8.3440,  -2.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738598585128784
Epoch 0, Step 2112: train/loss = 0.11247862130403519, train/raw-loss = 0.08051351457834244, train/logprobs = tensor([[-0.9692, -9.9385],
        [-7.1242, -3.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3196510970592499
Epoch 0, Step 2113: train/loss = 0.0652254968881607, train/raw-loss = 0.04078388214111328, train/logprobs = tensor([[-1.1355, -6.7711],
        [-7.4598, -1.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24441611766815186
Epoch 0, Step 2114: train/loss = 0.032005082815885544, train/raw-loss = 0.0010382081381976604, train/logprobs = tensor([[ -2.0488,  -8.3538],
        [-10.9896,  -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30966874957084656
Epoch 0, Step 2115: train/loss = 0.04247433692216873, train/raw-loss = 0.007439902983605862, train/logprobs = tensor([[ -1.5366,  -6.9272],
        [-10.4057,  -1.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35034433007240295
Epoch 0, Step 2116: train/loss = 0.045950599014759064, train/raw-loss = 0.011856624856591225, train/logprobs = tensor([[ -0.6670, -10.6398],
        [ -6.3098,  -4.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3409397006034851
Epoch 0, Step 2117: train/loss = 0.03223476558923721, train/raw-loss = 0.0033735346514731646, train/logprobs = tensor([[ -1.4492, -10.7330],
        [ -9.3605,  -2.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886123061180115
Epoch 0, Step 2118: train/loss = 0.07084357738494873, train/raw-loss = 0.03847212344408035, train/logprobs = tensor([[-1.0133, -6.6506],
        [-7.0667, -1.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32371455430984497
Epoch 0, Step 2119: train/loss = 0.06447627395391464, train/raw-loss = 0.03005237691104412, train/logprobs = tensor([[-1.2226, -9.9713],
        [-8.5082, -2.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34423893690109253
Epoch 0, Step 2120: train/loss = 0.03285965695977211, train/raw-loss = 0.001012318884022534, train/logprobs = tensor([[ -0.8522, -11.3302],
        [ -8.0247,  -3.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184733986854553
Epoch 0, Step 2121: train/loss = 0.03519696369767189, train/raw-loss = 0.006020234897732735, train/logprobs = tensor([[ -1.3592,  -7.7608],
        [-10.6439,  -1.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29176726937294006
Epoch 0, Step 2122: train/loss = 0.03609186410903931, train/raw-loss = 0.00029245272162370384, train/logprobs = tensor([[ -1.0859, -12.3721],
        [ -9.6925,  -0.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35799410939216614
Epoch 0, Step 2123: train/loss = 0.03283856064081192, train/raw-loss = 0.002139710821211338, train/logprobs = tensor([[ -0.8932, -11.4722],
        [ -7.6414,  -2.1819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3069884777069092
Epoch 0, Step 2124: train/loss = 0.08835099637508392, train/raw-loss = 0.060610972344875336, train/logprobs = tensor([[-1.0519, -7.9559],
        [-7.9463, -1.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27740031480789185
Epoch 0, Step 2125: train/loss = 0.04642374813556671, train/raw-loss = 0.015130028128623962, train/logprobs = tensor([[-0.8685, -8.9086],
        [-7.2213, -3.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129372000694275
Epoch 0, Step 2126: train/loss = 0.041670653969049454, train/raw-loss = 0.004815409891307354, train/logprobs = tensor([[ -1.0701,  -8.7126],
        [-10.0799,  -1.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36855244636535645
Epoch 0, Step 2127: train/loss = 0.037014350295066833, train/raw-loss = 0.006494621746242046, train/logprobs = tensor([[ -1.0039, -12.5091],
        [ -6.5666,  -2.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30519726872444153
Epoch 0, Step 2128: train/loss = 0.04991708695888519, train/raw-loss = 0.019012631848454475, train/logprobs = tensor([[-0.9654, -8.3193],
        [-8.0037, -2.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090445399284363
Epoch 0, Step 2129: train/loss = 0.03269564360380173, train/raw-loss = 0.004292611498385668, train/logprobs = tensor([[-0.7405, -9.6795],
        [-6.7406, -1.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28403031826019287
Epoch 0, Step 2130: train/loss = 0.034817829728126526, train/raw-loss = 0.0007061061915010214, train/logprobs = tensor([[ -0.9271, -11.5080],
        [ -8.9292,  -2.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411172330379486
Epoch 0, Step 2131: train/loss = 0.034859780222177505, train/raw-loss = 0.002995339222252369, train/logprobs = tensor([[-1.2237, -9.7924],
        [-9.4979, -1.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186444044113159
Epoch 0, Step 2132: train/loss = 0.05837574601173401, train/raw-loss = 0.02763677015900612, train/logprobs = tensor([[-1.0574, -9.8210],
        [-7.9045, -3.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073897361755371
Epoch 0, Step 2133: train/loss = 0.03759011998772621, train/raw-loss = 0.0007284425082616508, train/logprobs = tensor([[ -1.2839, -10.0292],
        [ -9.9007,  -2.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3686167597770691
Epoch 0, Step 2134: train/loss = 0.03515477478504181, train/raw-loss = 0.0022351578809320927, train/logprobs = tensor([[-1.1521, -9.6451],
        [-7.4387, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32919615507125854
Epoch 0, Step 2135: train/loss = 0.037872444838285446, train/raw-loss = 0.004561907611787319, train/logprobs = tensor([[ -1.2205, -11.4658],
        [ -9.3371,  -3.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331053555011749
Epoch 0, Step 2136: train/loss = 0.03269581496715546, train/raw-loss = 0.003087937831878662, train/logprobs = tensor([[ -0.6100, -12.6513],
        [ -5.8219,  -1.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29607877135276794
Epoch 0, Step 2137: train/loss = 0.0416601300239563, train/raw-loss = 0.008177605457603931, train/logprobs = tensor([[-0.9093, -9.0193],
        [-7.3093, -2.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348252773284912
Epoch 0, Step 2138: train/loss = 0.036803510040044785, train/raw-loss = 0.002832382218912244, train/logprobs = tensor([[ -1.5859,  -9.2346],
        [-10.5859,  -2.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3397112488746643
Epoch 0, Step 2139: train/loss = 0.035376861691474915, train/raw-loss = 0.0011659900192171335, train/logprobs = tensor([[ -0.6960, -10.7843],
        [ -6.8675,  -1.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34210872650146484
Epoch 0, Step 2140: train/loss = 0.034820232540369034, train/raw-loss = 0.0041688368655741215, train/logprobs = tensor([[ -1.4090,  -8.4176],
        [-10.4301,  -1.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065139651298523
Epoch 0, Step 2141: train/loss = 0.046409524977207184, train/raw-loss = 0.01811888813972473, train/logprobs = tensor([[-1.2837, -7.5400],
        [-7.8368, -2.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2829063832759857
Epoch 0, Step 2142: train/loss = 0.04287992790341377, train/raw-loss = 0.013090831227600574, train/logprobs = tensor([[ -1.2145, -11.8179],
        [ -8.4704,  -1.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978909909725189
Epoch 0, Step 2143: train/loss = 0.0741160437464714, train/raw-loss = 0.04414099082350731, train/logprobs = tensor([[-0.6861, -8.6599],
        [-6.5722, -3.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2997504770755768
Epoch 0, Step 2144: train/loss = 0.07030311226844788, train/raw-loss = 0.04018609970808029, train/logprobs = tensor([[ -1.3603, -13.1171],
        [ -9.3538,  -2.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30117011070251465
Epoch 0, Step 2145: train/loss = 0.03435062617063522, train/raw-loss = 0.0008484373684041202, train/logprobs = tensor([[ -1.3223, -12.0794],
        [ -9.9594,  -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33502188324928284
Epoch 0, Step 2146: train/loss = 0.039674125611782074, train/raw-loss = 0.008177673444151878, train/logprobs = tensor([[-0.7481, -9.6026],
        [-7.0794, -1.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31496450304985046
Epoch 0, Step 2147: train/loss = 0.03368961811065674, train/raw-loss = 0.0015130555257201195, train/logprobs = tensor([[-1.2614, -9.8470],
        [-9.6294, -2.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32176560163497925
Epoch 0, Step 2148: train/loss = 0.030397728085517883, train/raw-loss = 0.0019354987889528275, train/logprobs = tensor([[ -1.2375, -11.3474],
        [ -8.5373,  -2.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28462228178977966
Epoch 0, Step 2149: train/loss = 0.036601632833480835, train/raw-loss = 0.0026319194585084915, train/logprobs = tensor([[ -0.7292, -11.3703],
        [ -6.6448,  -1.6478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33969712257385254
Epoch 0, Step 2150: train/loss = 0.037356898188591, train/raw-loss = 0.0016669586766511202, train/logprobs = tensor([[ -0.8636, -11.5119],
        [ -7.2104,  -3.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3568993806838989
Epoch 0, Step 2151: train/loss = 0.02642943523824215, train/raw-loss = 0.002531515434384346, train/logprobs = tensor([[ -1.2225, -11.1038],
        [ -7.9816,  -2.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23897919058799744
Epoch 0, Step 2152: train/loss = 0.04230035841464996, train/raw-loss = 0.00849971268326044, train/logprobs = tensor([[ -1.2585, -10.0448],
        [ -8.6279,  -2.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380064368247986
Epoch 0, Step 2153: train/loss = 0.037155263125896454, train/raw-loss = 0.0008550077909603715, train/logprobs = tensor([[ -0.8272, -11.3590],
        [ -8.4603,  -2.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3630025088787079
Epoch 0, Step 2154: train/loss = 0.029956059530377388, train/raw-loss = 0.0011419081129133701, train/logprobs = tensor([[ -1.1986, -11.9803],
        [ -9.3185,  -1.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28814151883125305
Epoch 0, Step 2155: train/loss = 0.04068504646420479, train/raw-loss = 0.007286762818694115, train/logprobs = tensor([[ -0.9986, -12.6923],
        [ -8.2760,  -1.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33398282527923584
Epoch 0, Step 2156: train/loss = 0.054339513182640076, train/raw-loss = 0.023297186940908432, train/logprobs = tensor([[-1.1938, -9.0685],
        [-9.5254, -2.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31042325496673584
Epoch 0, Step 2157: train/loss = 0.03507117182016373, train/raw-loss = 0.000619731901679188, train/logprobs = tensor([[ -0.9168, -11.4715],
        [ -8.3442,  -2.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3445143699645996
Epoch 0, Step 2158: train/loss = 0.03356911987066269, train/raw-loss = 0.0013756435364484787, train/logprobs = tensor([[ -0.8458, -11.8799],
        [ -7.2009,  -1.4971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219347894191742
Epoch 0, Step 2159: train/loss = 0.03450673446059227, train/raw-loss = 0.002888157032430172, train/logprobs = tensor([[-0.9118, -9.8028],
        [-8.9706, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31618577241897583
Epoch 0, Step 2160: train/loss = 0.0333004929125309, train/raw-loss = 0.0009596976451575756, train/logprobs = tensor([[ -1.1732, -14.9068],
        [ -9.0965,  -2.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323407918214798
Epoch 0, Step 2161: train/loss = 0.03321634232997894, train/raw-loss = 0.0015147565864026546, train/logprobs = tensor([[ -1.3596,  -9.3031],
        [-10.9529,  -1.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3170158565044403
Epoch 0, Step 2162: train/loss = 0.04515494406223297, train/raw-loss = 0.017834994941949844, train/logprobs = tensor([[-1.2388, -7.2967],
        [-8.7849, -2.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731994688510895
Epoch 0, Step 2163: train/loss = 0.03213116154074669, train/raw-loss = 0.0027851597405970097, train/logprobs = tensor([[-0.8882, -8.6624],
        [-7.0610, -1.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29346001148223877
Epoch 0, Step 2164: train/loss = 0.03378961235284805, train/raw-loss = 0.006132693961262703, train/logprobs = tensor([[-1.3852, -9.1577],
        [-8.7682, -1.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765691578388214
Epoch 0, Step 2165: train/loss = 0.05024183541536331, train/raw-loss = 0.01513227354735136, train/logprobs = tensor([[ -0.9601, -10.2548],
        [ -8.7204,  -1.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35109561681747437
Epoch 0, Step 2166: train/loss = 0.05708618462085724, train/raw-loss = 0.021796846762299538, train/logprobs = tensor([[ -0.8062, -10.2207],
        [ -7.4587,  -4.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528933525085449
Epoch 0, Step 2167: train/loss = 0.03414405137300491, train/raw-loss = 0.0033675162121653557, train/logprobs = tensor([[ -1.0069, -11.4344],
        [ -8.6919,  -1.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077653646469116
Epoch 0, Step 2168: train/loss = 0.041274189949035645, train/raw-loss = 0.004132543690502644, train/logprobs = tensor([[-0.8598, -9.4706],
        [-7.5637, -2.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37141644954681396
Epoch 0, Step 2169: train/loss = 0.08565063774585724, train/raw-loss = 0.054130248725414276, train/logprobs = tensor([[-1.1075, -9.5464],
        [-7.4830, -2.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31520381569862366
Epoch 0, Step 2170: train/loss = 0.23056624829769135, train/raw-loss = 0.19779883325099945, train/logprobs = tensor([[-0.9011, -9.6971],
        [-7.0650, -2.7919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3276742100715637
Epoch 0, Step 2171: train/loss = 0.029034040868282318, train/raw-loss = 9.288576256949455e-05, train/logprobs = tensor([[ -1.3933, -13.0184],
        [-11.0426,  -2.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894115447998047
Epoch 0, Step 2172: train/loss = 0.03754342347383499, train/raw-loss = 0.0027957819402217865, train/logprobs = tensor([[ -1.0855, -12.7642],
        [ -8.4147,  -3.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34747642278671265
Epoch 0, Step 2173: train/loss = 0.0314038023352623, train/raw-loss = 0.002482066862285137, train/logprobs = tensor([[-1.5121, -9.0781],
        [-8.9220, -1.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28921738266944885
Epoch 0, Step 2174: train/loss = 0.03654615953564644, train/raw-loss = 0.0011288921814411879, train/logprobs = tensor([[ -0.7165, -14.4611],
        [ -6.9353,  -2.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3541726768016815
Epoch 0, Step 2175: train/loss = 0.033587053418159485, train/raw-loss = 0.000945043342653662, train/logprobs = tensor([[ -1.1536, -15.7696],
        [ -8.0162,  -3.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3264200985431671
Epoch 0, Step 2176: train/loss = 0.03453446924686432, train/raw-loss = 0.0004233931249473244, train/logprobs = tensor([[ -1.3191, -12.3304],
        [ -9.5686,  -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411107361316681
Epoch 0, Step 2177: train/loss = 0.03315345197916031, train/raw-loss = 0.0015500725712627172, train/logprobs = tensor([[ -1.0468, -10.9249],
        [ -8.8977,  -2.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160337507724762
Epoch 0, Step 2178: train/loss = 0.03266173228621483, train/raw-loss = 0.000530415796674788, train/logprobs = tensor([[ -1.2256, -13.4017],
        [ -9.4269,  -2.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32131314277648926
Epoch 0, Step 2179: train/loss = 0.047393910586833954, train/raw-loss = 0.017156142741441727, train/logprobs = tensor([[-1.0202, -8.9995],
        [-6.7824, -1.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3023776412010193
Epoch 0, Step 2180: train/loss = 0.04669644683599472, train/raw-loss = 0.01499373372644186, train/logprobs = tensor([[ -1.1905, -11.2673],
        [ -7.8373,  -1.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31702712178230286
Epoch 0, Step 2181: train/loss = 0.03301212191581726, train/raw-loss = 0.0018040603026747704, train/logprobs = tensor([[ -1.3917,  -7.6628],
        [-10.5206,  -1.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31208059191703796
Epoch 0, Step 2182: train/loss = 0.09793774783611298, train/raw-loss = 0.06505655497312546, train/logprobs = tensor([[ -1.3290, -13.8313],
        [ -9.3517,  -4.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32881200313568115
Epoch 0, Step 2183: train/loss = 0.02981073223054409, train/raw-loss = 0.00047799653839319944, train/logprobs = tensor([[ -1.2004, -17.4915],
        [ -9.4177,  -2.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29332736134529114
Epoch 0, Step 2184: train/loss = 0.03233557567000389, train/raw-loss = 0.0013660537078976631, train/logprobs = tensor([[ -1.4257, -10.9953],
        [-10.1931,  -1.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30969518423080444
Epoch 0, Step 2185: train/loss = 0.03246413543820381, train/raw-loss = 0.0003871867374982685, train/logprobs = tensor([[ -1.0612, -13.3303],
        [-10.1626,  -2.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3207694888114929
Epoch 0, Step 2186: train/loss = 0.03506755456328392, train/raw-loss = 0.001698068343102932, train/logprobs = tensor([[ -0.9580, -10.9916],
        [ -7.6119,  -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33369481563568115
Epoch 0, Step 2187: train/loss = 0.06287449598312378, train/raw-loss = 0.03014914132654667, train/logprobs = tensor([[-0.8804, -6.1064],
        [-8.5177, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3272535800933838
Epoch 0, Step 2188: train/loss = 0.038164298981428146, train/raw-loss = 0.002637904603034258, train/logprobs = tensor([[ -0.7032, -12.6419],
        [ -7.0010,  -2.1387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35526391863822937
Epoch 0, Step 2189: train/loss = 0.037164170295000076, train/raw-loss = 0.008420318365097046, train/logprobs = tensor([[-1.3983, -7.5199],
        [-7.9656, -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2874384820461273
Epoch 0, Step 2190: train/loss = 0.034912385046482086, train/raw-loss = 0.002806873293593526, train/logprobs = tensor([[ -0.9357, -12.3114],
        [ -6.7847,  -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210551142692566
Epoch 0, Step 2191: train/loss = 0.0314989872276783, train/raw-loss = 0.0013386448845267296, train/logprobs = tensor([[ -1.1889, -12.1615],
        [ -8.6993,  -2.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30160340666770935
Epoch 0, Step 2192: train/loss = 0.04035525023937225, train/raw-loss = 0.012832517735660076, train/logprobs = tensor([[-0.8876, -9.4594],
        [-7.8808, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752273380756378
Epoch 0, Step 2193: train/loss = 0.06687059998512268, train/raw-loss = 0.03491833433508873, train/logprobs = tensor([[ -1.7504, -12.6989],
        [ -9.5824,  -3.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3195226192474365
Epoch 0, Step 2194: train/loss = 0.05298825353384018, train/raw-loss = 0.024918103590607643, train/logprobs = tensor([[-1.3524, -7.6793],
        [-8.7801, -2.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28070151805877686
Epoch 0, Step 2195: train/loss = 0.036891479045152664, train/raw-loss = 0.004252203274518251, train/logprobs = tensor([[-0.8152, -9.5380],
        [-6.3966, -2.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3263927400112152
Epoch 0, Step 2196: train/loss = 0.032611023634672165, train/raw-loss = 0.0008372804732061923, train/logprobs = tensor([[ -1.4585, -15.6242],
        [ -9.4190,  -3.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3177374005317688
Epoch 0, Step 2197: train/loss = 0.06276703625917435, train/raw-loss = 0.033290550112724304, train/logprobs = tensor([[ -1.2723, -10.3853],
        [ -6.3842,  -2.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29476484656333923
Epoch 0, Step 2198: train/loss = 0.03664025664329529, train/raw-loss = 0.007202290929853916, train/logprobs = tensor([[-0.6732, -7.5732],
        [-6.4379, -1.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29437965154647827
Epoch 0, Step 2199: train/loss = 0.035525646060705185, train/raw-loss = 0.0010058025363832712, train/logprobs = tensor([[ -1.2599, -15.0060],
        [ -8.8627,  -4.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34519845247268677
Epoch 0, Step 2200: train/loss = 0.040296997874975204, train/raw-loss = 0.008999360725283623, train/logprobs = tensor([[ -0.8100, -10.2948],
        [ -7.2972,  -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129763901233673
Epoch 0, Step 2201: train/loss = 0.03267575800418854, train/raw-loss = 0.0008563069859519601, train/logprobs = tensor([[ -1.1372, -10.5711],
        [ -8.1641,  -2.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31819450855255127
Epoch 0, Step 2202: train/loss = 0.0560087189078331, train/raw-loss = 0.024439027532935143, train/logprobs = tensor([[ -1.0404, -13.5924],
        [ -7.8984,  -1.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156968951225281
Epoch 0, Step 2203: train/loss = 0.03073972836136818, train/raw-loss = 0.0032326492946594954, train/logprobs = tensor([[-1.2949, -7.6340],
        [-8.6086, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27507078647613525
Epoch 0, Step 2204: train/loss = 0.03631780296564102, train/raw-loss = 0.00205549830570817, train/logprobs = tensor([[ -0.8796, -11.4875],
        [ -8.0626,  -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3426230549812317
Epoch 0, Step 2205: train/loss = 0.06948539614677429, train/raw-loss = 0.035533539950847626, train/logprobs = tensor([[ -1.0257, -12.8265],
        [ -7.3233,  -2.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33951857686042786
Epoch 0, Step 2206: train/loss = 0.03492853417992592, train/raw-loss = 0.003157560946419835, train/logprobs = tensor([[ -0.7055, -11.8998],
        [ -6.1946,  -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317709743976593
Epoch 0, Step 2207: train/loss = 0.11338572204113007, train/raw-loss = 0.08305981010198593, train/logprobs = tensor([[-1.5242, -7.2505],
        [-8.4667, -2.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30325907468795776
Epoch 0, Step 2208: train/loss = 0.030973700806498528, train/raw-loss = 0.002572693396359682, train/logprobs = tensor([[ -1.1780, -14.0931],
        [ -7.8142,  -2.4030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28401005268096924
Epoch 0, Step 2209: train/loss = 0.042547352612018585, train/raw-loss = 0.014255089685320854, train/logprobs = tensor([[-1.3495, -9.3151],
        [-8.5963, -1.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282922625541687
Epoch 0, Step 2210: train/loss = 0.03175537288188934, train/raw-loss = 0.0030317010823637247, train/logprobs = tensor([[-1.3991, -7.9861],
        [-8.1819, -1.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28723669052124023
Epoch 0, Step 2211: train/loss = 0.03746965900063515, train/raw-loss = 0.00171153515111655, train/logprobs = tensor([[ -0.9895, -10.8924],
        [ -8.5381,  -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3575812578201294
Epoch 0, Step 2212: train/loss = 0.03610259294509888, train/raw-loss = 0.0056289746426045895, train/logprobs = tensor([[ -1.4896, -10.6095],
        [ -8.4419,  -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3047361969947815
Epoch 0, Step 2213: train/loss = 0.043000757694244385, train/raw-loss = 0.011832872405648232, train/logprobs = tensor([[ -1.5405, -10.9359],
        [ -8.3344,  -2.1970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31167882680892944
Epoch 0, Step 2214: train/loss = 0.09584009647369385, train/raw-loss = 0.06170818954706192, train/logprobs = tensor([[-1.3733, -8.9235],
        [-8.7053, -2.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34131908416748047
Epoch 0, Step 2215: train/loss = 0.03212082386016846, train/raw-loss = 0.0022179842926561832, train/logprobs = tensor([[ -1.2281, -10.7193],
        [ -8.5953,  -0.8474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2990283668041229
Epoch 0, Step 2216: train/loss = 0.03333740308880806, train/raw-loss = 0.000905137974768877, train/logprobs = tensor([[ -1.0394, -14.3380],
        [ -8.3971,  -1.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3243226706981659
Epoch 0, Step 2217: train/loss = 0.03869584947824478, train/raw-loss = 0.009086860343813896, train/logprobs = tensor([[-1.0967, -8.2335],
        [-7.5347, -1.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29608988761901855
Epoch 0, Step 2218: train/loss = 0.033914338797330856, train/raw-loss = 0.0002911485207732767, train/logprobs = tensor([[ -1.1325, -13.1730],
        [ -9.9931,  -2.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33623188734054565
Epoch 0, Step 2219: train/loss = 0.03442445769906044, train/raw-loss = 0.00028587711858563125, train/logprobs = tensor([[ -1.0594, -14.4313],
        [ -9.6637,  -3.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3413858115673065
Epoch 0, Step 2220: train/loss = 0.04016907513141632, train/raw-loss = 0.006684322841465473, train/logprobs = tensor([[ -1.2806, -11.5784],
        [ -7.3674,  -2.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33484750986099243
Epoch 0, Step 2221: train/loss = 0.031618840992450714, train/raw-loss = 0.0009612597641535103, train/logprobs = tensor([[ -1.3431, -10.9964],
        [ -8.6366,  -1.3556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30657580494880676
Epoch 0, Step 2222: train/loss = 0.03209799528121948, train/raw-loss = 0.003997346386313438, train/logprobs = tensor([[-1.2811, -9.9837],
        [-6.4446, -1.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28100648522377014
Epoch 0, Step 2223: train/loss = 0.03918420523405075, train/raw-loss = 0.010971545241773129, train/logprobs = tensor([[ -1.4463, -10.0458],
        [ -7.4534,  -1.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28212660551071167
Epoch 0, Step 2224: train/loss = 0.0340065062046051, train/raw-loss = 0.003037284128367901, train/logprobs = tensor([[ -0.8587, -15.0826],
        [ -6.7268,  -1.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3096922039985657
Epoch 0, Step 2225: train/loss = 0.03500359505414963, train/raw-loss = 0.0031315365340560675, train/logprobs = tensor([[ -0.8193, -10.6586],
        [ -6.9261,  -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31872057914733887
Epoch 0, Step 2226: train/loss = 0.029398974031209946, train/raw-loss = 0.001325963530689478, train/logprobs = tensor([[-1.2013, -9.7836],
        [-7.7248, -1.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28073012828826904
Epoch 0, Step 2227: train/loss = 0.033157795667648315, train/raw-loss = 0.004118579439818859, train/logprobs = tensor([[ -1.4020, -11.5116],
        [ -6.9546,  -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2903921604156494
Epoch 0, Step 2228: train/loss = 0.09805170446634293, train/raw-loss = 0.06721334904432297, train/logprobs = tensor([[-1.2303, -8.1128],
        [-7.4542, -1.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30838361382484436
Epoch 0, Step 2229: train/loss = 0.04058349132537842, train/raw-loss = 0.009677316062152386, train/logprobs = tensor([[ -1.4013, -10.2911],
        [ -9.8886,  -2.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090617060661316
Epoch 0, Step 2230: train/loss = 0.0336783267557621, train/raw-loss = 0.002302338369190693, train/logprobs = tensor([[ -0.8871, -13.0455],
        [ -7.2357,  -2.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31375986337661743
Epoch 0, Step 2231: train/loss = 0.03465783968567848, train/raw-loss = 0.0020247502252459526, train/logprobs = tensor([[ -1.1964, -11.1472],
        [ -8.4701,  -2.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32633087038993835
Epoch 0, Step 2232: train/loss = 0.03858664631843567, train/raw-loss = 0.0038440916687250137, train/logprobs = tensor([[ -0.8183, -11.8214],
        [ -7.9294,  -2.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34742552042007446
Epoch 0, Step 2233: train/loss = 0.02899051457643509, train/raw-loss = 0.0007979134097695351, train/logprobs = tensor([[ -1.7333, -10.1577],
        [ -9.0035,  -1.4428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819260060787201
Epoch 0, Step 2234: train/loss = 0.03877454251050949, train/raw-loss = 0.00367372645996511, train/logprobs = tensor([[ -0.8877, -11.9287],
        [ -6.5378,  -2.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35100817680358887
Epoch 0, Step 2235: train/loss = 0.02880921959877014, train/raw-loss = 0.0022960719652473927, train/logprobs = tensor([[-1.2708, -8.9268],
        [-8.3332, -1.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26513147354125977
Epoch 0, Step 2236: train/loss = 0.033960942178964615, train/raw-loss = 0.0016941288486123085, train/logprobs = tensor([[ -0.8545, -14.1820],
        [ -6.6640,  -2.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3226681351661682
Epoch 0, Step 2237: train/loss = 0.034465231001377106, train/raw-loss = 0.00083771045319736, train/logprobs = tensor([[ -1.0578, -12.4353],
        [ -9.2618,  -1.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.336275190114975
Epoch 0, Step 2238: train/loss = 0.032575152814388275, train/raw-loss = 0.006108548492193222, train/logprobs = tensor([[-1.4861, -7.1511],
        [-7.4715, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26466602087020874
Epoch 0, Step 2239: train/loss = 0.03591669723391533, train/raw-loss = 0.0005991912330500782, train/logprobs = tensor([[ -1.1244, -13.5653],
        [ -8.1636,  -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3531750440597534
Epoch 0, Step 2240: train/loss = 0.03843168914318085, train/raw-loss = 0.008938496932387352, train/logprobs = tensor([[ -1.1219, -14.7578],
        [ -6.1963,  -3.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29493194818496704
Epoch 0, Step 2241: train/loss = 0.05388276278972626, train/raw-loss = 0.02321530133485794, train/logprobs = tensor([[-0.9727, -9.2895],
        [-6.3172, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066745698451996
Epoch 0, Step 2242: train/loss = 0.039519052952528, train/raw-loss = 0.00903890561312437, train/logprobs = tensor([[-0.6677, -9.3885],
        [-5.6116, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30480146408081055
Epoch 0, Step 2243: train/loss = 0.03956044837832451, train/raw-loss = 0.00987995695322752, train/logprobs = tensor([[-0.8293, -9.7470],
        [-5.8367, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29680490493774414
Epoch 0, Step 2244: train/loss = 0.03273732215166092, train/raw-loss = 0.00149180565495044, train/logprobs = tensor([[ -1.2927, -10.4659],
        [ -8.4651,  -2.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124551773071289
Epoch 0, Step 2245: train/loss = 0.03273462876677513, train/raw-loss = 0.0011504803551360965, train/logprobs = tensor([[ -1.5999, -11.8705],
        [ -9.4151,  -2.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158414959907532
Epoch 0, Step 2246: train/loss = 0.035991739481687546, train/raw-loss = 0.004944894462823868, train/logprobs = tensor([[ -1.2445, -13.1492],
        [ -7.0326,  -1.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.310468465089798
Epoch 0, Step 2247: train/loss = 0.03233324736356735, train/raw-loss = 0.0007567310240119696, train/logprobs = tensor([[ -1.0436, -15.5597],
        [ -8.2491,  -3.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3157651424407959
Epoch 0, Step 2248: train/loss = 0.045997172594070435, train/raw-loss = 0.011350905522704124, train/logprobs = tensor([[-1.0589, -8.0274],
        [-8.5690, -1.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3464626669883728
Epoch 0, Step 2249: train/loss = 0.030732404440641403, train/raw-loss = 0.001501953462138772, train/logprobs = tensor([[ -0.9376, -16.6930],
        [ -7.1635,  -3.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29230448603630066
Epoch 0, Step 2250: train/loss = 0.034132033586502075, train/raw-loss = 0.0027548205107450485, train/logprobs = tensor([[ -1.5619, -11.4336],
        [ -7.2906,  -1.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137721121311188
Epoch 0, Step 2251: train/loss = 0.03489667922258377, train/raw-loss = 0.003050780389457941, train/logprobs = tensor([[ -1.1898, -11.9659],
        [ -8.8151,  -1.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184589743614197
Epoch 0, Step 2252: train/loss = 0.03218913450837135, train/raw-loss = 0.00034292429336346686, train/logprobs = tensor([[ -0.9895, -12.6447],
        [ -9.6383,  -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318462073802948
Epoch 0, Step 2253: train/loss = 0.03403077274560928, train/raw-loss = 0.0033778673969209194, train/logprobs = tensor([[ -0.8583, -12.8294],
        [ -6.7951,  -1.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30652904510498047
Epoch 0, Step 2254: train/loss = 0.03597676008939743, train/raw-loss = 0.00815584696829319, train/logprobs = tensor([[ -1.2483, -14.2163],
        [ -7.1043,  -2.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782091498374939
Epoch 0, Step 2255: train/loss = 0.03693663328886032, train/raw-loss = 0.007160401437431574, train/logprobs = tensor([[ -1.4983, -11.0037],
        [ -8.0588,  -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29776230454444885
Epoch 0, Step 2256: train/loss = 0.03575154393911362, train/raw-loss = 0.0022469665855169296, train/logprobs = tensor([[ -1.2923, -13.3041],
        [ -8.1656,  -1.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3350457549095154
Epoch 0, Step 2257: train/loss = 0.03334727883338928, train/raw-loss = 0.002784929471090436, train/logprobs = tensor([[ -0.8746, -13.3632],
        [ -6.7460,  -2.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30562353134155273
Epoch 0, Step 2258: train/loss = 0.03924591839313507, train/raw-loss = 0.00899369828402996, train/logprobs = tensor([[ -1.0872, -11.1378],
        [ -6.4034,  -2.3271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025221824645996
Epoch 0, Step 2259: train/loss = 0.033663246780633926, train/raw-loss = 0.0017669345252215862, train/logprobs = tensor([[ -1.0045, -11.3937],
        [ -7.8973,  -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3189631402492523
Epoch 0, Step 2260: train/loss = 0.03185034543275833, train/raw-loss = 0.0036720845382660627, train/logprobs = tensor([[ -1.0826, -10.8645],
        [ -6.2176,  -1.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817826271057129
Epoch 0, Step 2261: train/loss = 0.04097287356853485, train/raw-loss = 0.003042752854526043, train/logprobs = tensor([[-1.5715, -9.3894],
        [-9.4190, -2.3341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37930119037628174
Epoch 0, Step 2262: train/loss = 0.031915683299303055, train/raw-loss = 0.003323053475469351, train/logprobs = tensor([[ -1.2188, -18.5072],
        [ -6.2420,  -1.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28592628240585327
Epoch 0, Step 2263: train/loss = 0.03156961500644684, train/raw-loss = 0.0003586750535760075, train/logprobs = tensor([[ -1.6360, -11.5891],
        [-11.5021,  -1.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121093809604645
Epoch 0, Step 2264: train/loss = 0.03351631015539169, train/raw-loss = 0.0021858697291463614, train/logprobs = tensor([[ -0.9130, -18.5875],
        [ -7.5256,  -3.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31330442428588867
Epoch 0, Step 2265: train/loss = 0.032321423292160034, train/raw-loss = 0.000597634119912982, train/logprobs = tensor([[ -1.2705, -15.6127],
        [ -8.9471,  -2.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317237913608551
Epoch 0, Step 2266: train/loss = 0.04052269831299782, train/raw-loss = 0.00649993633851409, train/logprobs = tensor([[ -1.3426, -11.2401],
        [ -8.0347,  -2.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3402276337146759
Epoch 0, Step 2267: train/loss = 0.03165029361844063, train/raw-loss = 0.001172331627458334, train/logprobs = tensor([[ -1.1016, -11.5215],
        [ -7.7150,  -2.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30477961897850037
Epoch 0, Step 2268: train/loss = 0.034004636108875275, train/raw-loss = 0.0005075463559478521, train/logprobs = tensor([[ -1.0913, -15.8978],
        [ -8.4969,  -2.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3349708914756775
Epoch 0, Step 2269: train/loss = 0.04610085487365723, train/raw-loss = 0.017698610201478004, train/logprobs = tensor([[ -1.1576, -14.4834],
        [ -8.7581,  -2.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840225100517273
Epoch 0, Step 2270: train/loss = 0.032942019402980804, train/raw-loss = 0.0018121313769370317, train/logprobs = tensor([[-1.4480, -9.4050],
        [-8.9222, -1.3024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31129884719848633
Epoch 0, Step 2271: train/loss = 0.050182994455099106, train/raw-loss = 0.018930988386273384, train/logprobs = tensor([[-1.4071, -8.8578],
        [-9.3251, -1.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125200867652893
Epoch 0, Step 2272: train/loss = 0.03047654777765274, train/raw-loss = 0.0008939324179664254, train/logprobs = tensor([[ -0.9976, -12.3758],
        [ -7.5937,  -2.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29582613706588745
Epoch 0, Step 2273: train/loss = 0.03574327379465103, train/raw-loss = 0.0027923360466957092, train/logprobs = tensor([[-1.0668, -9.2845],
        [-8.3259, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32950934767723083
Epoch 0, Step 2274: train/loss = 0.039134345948696136, train/raw-loss = 0.004480566829442978, train/logprobs = tensor([[ -1.3794, -11.4511],
        [ -7.8880,  -2.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3465377688407898
Epoch 0, Step 2275: train/loss = 0.031772468239068985, train/raw-loss = 0.0029727406799793243, train/logprobs = tensor([[ -1.4196, -15.9754],
        [ -8.4755,  -2.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879972457885742
Epoch 0, Step 2276: train/loss = 0.03671477735042572, train/raw-loss = 0.003593605477362871, train/logprobs = tensor([[ -0.8162, -12.9404],
        [ -6.6652,  -1.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33121171593666077
Epoch 0, Step 2277: train/loss = 0.03223443031311035, train/raw-loss = 0.005260479636490345, train/logprobs = tensor([[ -1.0610, -11.1895],
        [ -6.8125,  -0.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697395086288452
Epoch 0, Step 2278: train/loss = 0.037297822535037994, train/raw-loss = 0.006424456834793091, train/logprobs = tensor([[ -1.2976, -11.3548],
        [ -8.2178,  -1.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30873367190361023
Epoch 0, Step 2279: train/loss = 0.031256724148988724, train/raw-loss = 0.0008601250010542572, train/logprobs = tensor([[ -1.7829, -13.3204],
        [ -9.7331,  -3.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039659857749939
Epoch 0, Step 2280: train/loss = 0.03186029940843582, train/raw-loss = 0.001302506192587316, train/logprobs = tensor([[ -0.9609, -15.7906],
        [ -7.0114,  -3.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055779039859772
Epoch 0, Step 2281: train/loss = 0.037650421261787415, train/raw-loss = 0.0038663276936858892, train/logprobs = tensor([[ -1.6568, -14.0616],
        [ -7.2689,  -2.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378409147262573
Epoch 0, Step 2282: train/loss = 0.03504209965467453, train/raw-loss = 0.0029466813430190086, train/logprobs = tensor([[ -1.2507, -14.2885],
        [ -7.8733,  -2.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32095417380332947
Epoch 0, Step 2283: train/loss = 0.033617280423641205, train/raw-loss = 0.0007036409806460142, train/logprobs = tensor([[ -1.3973, -11.7636],
        [ -8.6024,  -1.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291364014148712
Epoch 0, Step 2284: train/loss = 0.034018032252788544, train/raw-loss = 0.0011510231997817755, train/logprobs = tensor([[ -1.0559, -12.6387],
        [ -8.4378,  -1.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32867008447647095
Epoch 0, Step 2285: train/loss = 0.06914793699979782, train/raw-loss = 0.03954695537686348, train/logprobs = tensor([[-1.3356, -8.6710],
        [-5.4933, -0.8881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960098087787628
Epoch 0, Step 2286: train/loss = 0.0383598655462265, train/raw-loss = 0.00726858526468277, train/logprobs = tensor([[ -1.1055, -11.9126],
        [ -6.3428,  -2.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3109128475189209
Epoch 0, Step 2287: train/loss = 0.047617845237255096, train/raw-loss = 0.01765420474112034, train/logprobs = tensor([[ -1.1324, -12.5840],
        [ -7.2483,  -2.3327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996363639831543
Epoch 0, Step 2288: train/loss = 0.03279280290007591, train/raw-loss = 0.0023953798227012157, train/logprobs = tensor([[ -1.4195, -11.8071],
        [ -9.3015,  -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039742112159729
Epoch 0, Step 2289: train/loss = 0.031930793076753616, train/raw-loss = 0.001904253731481731, train/logprobs = tensor([[ -0.9247, -18.7311],
        [ -6.5879,  -3.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.300265371799469
Epoch 0, Step 2290: train/loss = 0.03387106955051422, train/raw-loss = 0.0031029689125716686, train/logprobs = tensor([[ -1.0565, -13.9314],
        [ -7.2442,  -2.4229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30768102407455444
Epoch 0, Step 2291: train/loss = 0.03396537899971008, train/raw-loss = 0.0040927729569375515, train/logprobs = tensor([[ -1.2795, -15.7480],
        [ -6.8946,  -2.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29872605204582214
Epoch 0, Step 2292: train/loss = 0.03316599130630493, train/raw-loss = 0.006768473889678717, train/logprobs = tensor([[ -1.0915, -14.3668],
        [ -5.7785,  -2.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639751732349396
Epoch 0, Step 2293: train/loss = 0.09905891865491867, train/raw-loss = 0.07278691232204437, train/logprobs = tensor([[ -1.5903, -10.2741],
        [ -6.7367,  -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26272010803222656
Epoch 0, Step 2294: train/loss = 0.033240582793951035, train/raw-loss = 0.0024292408488690853, train/logprobs = tensor([[ -1.2625, -13.0364],
        [ -8.7890,  -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3081133961677551
Epoch 0, Step 2295: train/loss = 0.029878152534365654, train/raw-loss = 0.0015772385522723198, train/logprobs = tensor([[ -1.1880, -11.6795],
        [ -8.6616,  -2.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2830091118812561
Epoch 0, Step 2296: train/loss = 0.03560648858547211, train/raw-loss = 0.0009163456852547824, train/logprobs = tensor([[ -0.9245, -16.6419],
        [ -7.8533,  -2.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34690138697624207
Epoch 0, Step 2297: train/loss = 0.03429050371050835, train/raw-loss = 0.0009122685878537595, train/logprobs = tensor([[ -1.1870, -15.4671],
        [ -8.5769,  -3.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337823450565338
Epoch 0, Step 2298: train/loss = 0.031132005155086517, train/raw-loss = 0.0018370982725173235, train/logprobs = tensor([[ -1.4526, -14.2304],
        [ -8.7337,  -2.2667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929490804672241
Epoch 0, Step 2299: train/loss = 0.03150145709514618, train/raw-loss = 0.001834622584283352, train/logprobs = tensor([[-1.2201, -9.8824],
        [-7.4398, -1.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966683804988861
Epoch 0, Step 2300: train/loss = 0.03142227604985237, train/raw-loss = 0.0009335727081634104, train/logprobs = tensor([[ -1.2979, -16.9101],
        [ -9.1453,  -3.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048870265483856
Epoch 0, Step 2301: train/loss = 0.03320443630218506, train/raw-loss = 0.003979356028139591, train/logprobs = tensor([[ -0.9674, -12.7180],
        [ -6.3499,  -1.6188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29225078225135803
Epoch 0, Step 2302: train/loss = 0.04587878659367561, train/raw-loss = 0.01562880538403988, train/logprobs = tensor([[ -1.0963, -10.5657],
        [ -7.1151,  -3.0392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30249983072280884
Epoch 0, Step 2303: train/loss = 0.04305099695920944, train/raw-loss = 0.013069252483546734, train/logprobs = tensor([[ -1.2351, -13.9094],
        [ -6.5919,  -2.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998174726963043
Epoch 0, Step 2304: train/loss = 0.03320422023534775, train/raw-loss = 0.006544698961079121, train/logprobs = tensor([[ -1.4783, -12.3441],
        [ -7.2777,  -2.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26659518480300903
Epoch 0, Step 2305: train/loss = 0.034355852752923965, train/raw-loss = 0.0030964885372668505, train/logprobs = tensor([[ -0.8191, -10.8519],
        [ -6.0038,  -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31259363889694214
Epoch 0, Step 2306: train/loss = 0.04911678656935692, train/raw-loss = 0.02030167169868946, train/logprobs = tensor([[ -0.8866, -11.1476],
        [ -4.7794,  -1.1895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881511449813843
Epoch 0, Step 2307: train/loss = 0.03502814099192619, train/raw-loss = 0.0060244337655603886, train/logprobs = tensor([[ -1.5914, -11.0623],
        [ -7.8742,  -1.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900370657444
Epoch 0, Step 2308: train/loss = 0.03218577429652214, train/raw-loss = 0.001365025993436575, train/logprobs = tensor([[ -0.9876, -11.0256],
        [ -7.6712,  -1.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3082074820995331
Epoch 0, Step 2309: train/loss = 0.03305000811815262, train/raw-loss = 0.0018387753516435623, train/logprobs = tensor([[ -1.1270, -14.1053],
        [ -7.5536,  -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31211230158805847
Epoch 0, Step 2310: train/loss = 0.0327281728386879, train/raw-loss = 0.0024165180511772633, train/logprobs = tensor([[ -0.9413, -12.7252],
        [ -6.9187,  -1.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031165599822998
Epoch 0, Step 2311: train/loss = 0.07465602457523346, train/raw-loss = 0.04112919792532921, train/logprobs = tensor([[-0.9905, -6.3648],
        [-5.0490, -1.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352682292461395
Epoch 0, Step 2312: train/loss = 0.03275894373655319, train/raw-loss = 0.0028765660244971514, train/logprobs = tensor([[ -0.6952, -14.0696],
        [ -6.2586,  -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2988237738609314
Epoch 0, Step 2313: train/loss = 0.03991035744547844, train/raw-loss = 0.005620990879833698, train/logprobs = tensor([[ -1.0323, -12.0480],
        [ -7.0045,  -2.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34289366006851196
Epoch 0, Step 2314: train/loss = 0.09756514430046082, train/raw-loss = 0.06564303487539291, train/logprobs = tensor([[ -0.8460, -11.1599],
        [ -5.5868,  -2.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3192210793495178
Epoch 0, Step 2315: train/loss = 0.03693622350692749, train/raw-loss = 0.003413382451981306, train/logprobs = tensor([[ -0.7244, -11.4234],
        [ -6.1265,  -1.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33522841334342957
Epoch 0, Step 2316: train/loss = 0.030740443617105484, train/raw-loss = 0.0005181299056857824, train/logprobs = tensor([[ -1.3562, -17.0759],
        [ -9.1994,  -2.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022230863571167
Epoch 0, Step 2317: train/loss = 0.03680972754955292, train/raw-loss = 0.007002714090049267, train/logprobs = tensor([[ -1.1947, -12.9930],
        [ -7.9386,  -1.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29807013273239136
Epoch 0, Step 2318: train/loss = 0.049742572009563446, train/raw-loss = 0.019425835460424423, train/logprobs = tensor([[ -1.2792, -15.1276],
        [ -5.2238,  -2.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30316734313964844
Epoch 0, Step 2319: train/loss = 0.03243551403284073, train/raw-loss = 0.001367759658023715, train/logprobs = tensor([[ -1.2097, -13.2782],
        [ -7.8294,  -1.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31067749857902527
Epoch 0, Step 2320: train/loss = 0.03632554039359093, train/raw-loss = 0.0025774328969419003, train/logprobs = tensor([[ -1.2079, -10.5918],
        [ -7.4526,  -2.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374810516834259
Epoch 0, Step 2321: train/loss = 0.05744587257504463, train/raw-loss = 0.027141766622662544, train/logprobs = tensor([[ -1.5776, -11.6718],
        [ -6.8146,  -2.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3030410408973694
Epoch 0, Step 2322: train/loss = 0.04842540994286537, train/raw-loss = 0.017546527087688446, train/logprobs = tensor([[ -1.3170, -11.4175],
        [ -7.6456,  -2.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30878886580467224
Epoch 0, Step 2323: train/loss = 0.03425469249486923, train/raw-loss = 0.00738547695800662, train/logprobs = tensor([[ -1.2051, -11.0935],
        [ -6.6397,  -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26869213581085205
Epoch 0, Step 2324: train/loss = 0.03404228761792183, train/raw-loss = 0.0009950310923159122, train/logprobs = tensor([[ -1.2270, -14.8636],
        [ -9.1384,  -2.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33047255873680115
Epoch 0, Step 2325: train/loss = 0.03424764797091484, train/raw-loss = 0.0007039926131255925, train/logprobs = tensor([[ -1.1512, -13.6611],
        [ -8.1061,  -1.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33543652296066284
Epoch 0, Step 2326: train/loss = 0.03463111072778702, train/raw-loss = 0.001595830311998725, train/logprobs = tensor([[ -1.4123, -14.6536],
        [ -8.2350,  -2.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3303528130054474
Epoch 0, Step 2327: train/loss = 0.035019271075725555, train/raw-loss = 0.0038472278974950314, train/logprobs = tensor([[ -0.8361, -15.1471],
        [ -6.9270,  -2.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31172043085098267
Epoch 0, Step 2328: train/loss = 0.03940243646502495, train/raw-loss = 0.0066769919358193874, train/logprobs = tensor([[-1.6034, -9.1141],
        [-8.4364, -1.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3272544741630554
Epoch 0, Step 2329: train/loss = 0.034449502825737, train/raw-loss = 0.004587851464748383, train/logprobs = tensor([[ -1.1363, -11.1283],
        [ -6.2829,  -1.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29861652851104736
Epoch 0, Step 2330: train/loss = 0.03294360265135765, train/raw-loss = 0.0031180698424577713, train/logprobs = tensor([[ -1.0965, -14.1604],
        [ -6.6811,  -3.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982553541660309
Epoch 0, Step 2331: train/loss = 0.03180216997861862, train/raw-loss = 0.0027251627761870623, train/logprobs = tensor([[ -1.4272, -14.6691],
        [ -8.2476,  -2.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907700538635254
Epoch 0, Step 2332: train/loss = 0.048098184168338776, train/raw-loss = 0.01590845361351967, train/logprobs = tensor([[ -1.2143, -10.5477],
        [ -7.1273,  -2.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3218972980976105
Epoch 0, Step 2333: train/loss = 0.0335080586373806, train/raw-loss = 0.0010024347575381398, train/logprobs = tensor([[ -1.2826, -13.7198],
        [ -8.7224,  -2.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32505619525909424
Epoch 0, Step 2334: train/loss = 0.03611203283071518, train/raw-loss = 0.008795268833637238, train/logprobs = tensor([[-1.1455, -9.6890],
        [-7.3976, -2.9344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2731676399707794
Epoch 0, Step 2335: train/loss = 0.03604283183813095, train/raw-loss = 0.004028209485113621, train/logprobs = tensor([[ -1.0122, -16.9309],
        [ -6.5344,  -2.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32014620304107666
Epoch 0, Step 2336: train/loss = 0.03679747134447098, train/raw-loss = 0.00802801363170147, train/logprobs = tensor([[ -1.3839, -14.3212],
        [ -7.2897,  -2.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876945734024048
Epoch 0, Step 2337: train/loss = 0.07823827862739563, train/raw-loss = 0.04978649690747261, train/logprobs = tensor([[ -2.0093, -18.4505],
        [ -6.5331,  -3.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284517765045166
Epoch 0, Step 2338: train/loss = 0.03841347247362137, train/raw-loss = 0.007468210067600012, train/logprobs = tensor([[-1.3828, -9.0140],
        [-7.0249, -1.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094526529312134
Epoch 0, Step 2339: train/loss = 0.035075657069683075, train/raw-loss = 0.0017801597714424133, train/logprobs = tensor([[ -1.4305, -16.6545],
        [ -9.9287,  -2.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33295494318008423
Epoch 0, Step 2340: train/loss = 0.031115712597966194, train/raw-loss = 0.001446987735107541, train/logprobs = tensor([[ -1.0865, -16.4289],
        [ -7.2010,  -1.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966872453689575
Epoch 0, Step 2341: train/loss = 0.0332120880484581, train/raw-loss = 0.002658276353031397, train/logprobs = tensor([[ -1.3019, -10.8590],
        [ -8.1242,  -0.3206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3055381178855896
Epoch 0, Step 2342: train/loss = 0.04058479890227318, train/raw-loss = 0.009366041049361229, train/logprobs = tensor([[-0.8763, -8.4147],
        [-5.8577, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121875524520874
Epoch 0, Step 2343: train/loss = 0.05288137122988701, train/raw-loss = 0.02177353948354721, train/logprobs = tensor([[-1.4896, -9.4260],
        [-7.7367, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31107833981513977
Epoch 0, Step 2344: train/loss = 0.043675098568201065, train/raw-loss = 0.013830450363457203, train/logprobs = tensor([[ -2.0521, -11.7749],
        [ -8.6229,  -1.3203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984464764595032
Epoch 0, Step 2345: train/loss = 0.034358590841293335, train/raw-loss = 0.000990594271570444, train/logprobs = tensor([[ -1.1119, -14.3901],
        [ -9.0403,  -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3336799442768097
Epoch 0, Step 2346: train/loss = 0.038118813186883926, train/raw-loss = 0.006701957434415817, train/logprobs = tensor([[ -2.3092, -12.3344],
        [ -6.6997,  -1.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3141685724258423
Epoch 0, Step 2347: train/loss = 0.03144150972366333, train/raw-loss = 0.007436512969434261, train/logprobs = tensor([[ -0.6457, -13.1125],
        [ -5.0524,  -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24004998803138733
Epoch 0, Step 2348: train/loss = 0.06031166762113571, train/raw-loss = 0.03241826593875885, train/logprobs = tensor([[ -1.5688, -10.8220],
        [ -6.6727,  -1.7691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27893397212028503
Epoch 0, Step 2349: train/loss = 0.03242795541882515, train/raw-loss = 0.005267277359962463, train/logprobs = tensor([[ -1.1971, -12.2083],
        [ -6.5701,  -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27160680294036865
Epoch 0, Step 2350: train/loss = 0.03349620848894119, train/raw-loss = 0.002750089857727289, train/logprobs = tensor([[ -1.3732, -14.7145],
        [ -8.2607,  -3.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074611723423004
Epoch 0, Step 2351: train/loss = 0.03609925135970116, train/raw-loss = 0.004930374678224325, train/logprobs = tensor([[ -0.9731, -14.2532],
        [ -5.7694,  -2.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31168878078460693
Epoch 0, Step 2352: train/loss = 0.03307347744703293, train/raw-loss = 0.0017784649971872568, train/logprobs = tensor([[ -0.8289, -14.8633],
        [ -6.6236,  -2.4438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31295016407966614
Epoch 0, Step 2353: train/loss = 0.033991072326898575, train/raw-loss = 0.0033830171450972557, train/logprobs = tensor([[ -1.1565, -12.5447],
        [ -6.7487,  -1.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30608057975769043
Epoch 0, Step 2354: train/loss = 0.031063120812177658, train/raw-loss = 0.0027640298940241337, train/logprobs = tensor([[ -1.4122, -12.0734],
        [ -7.5578,  -1.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2829909324645996
Epoch 0, Step 2355: train/loss = 0.03567155450582504, train/raw-loss = 0.007007099222391844, train/logprobs = tensor([[ -1.4530, -12.4458],
        [ -6.3226,  -1.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866445481777191
Epoch 0, Step 2356: train/loss = 0.03532455116510391, train/raw-loss = 0.003090720158070326, train/logprobs = tensor([[ -1.2187, -13.3477],
        [ -7.0850,  -2.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223382830619812
Epoch 0, Step 2357: train/loss = 0.0338587649166584, train/raw-loss = 0.0025036248844116926, train/logprobs = tensor([[ -1.3255, -10.3983],
        [ -8.0353,  -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3135514259338379
Epoch 0, Step 2358: train/loss = 0.03617461770772934, train/raw-loss = 0.0028182356618344784, train/logprobs = tensor([[ -0.6778, -11.5862],
        [ -6.3771,  -1.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33356380462646484
Epoch 0, Step 2359: train/loss = 0.029851576313376427, train/raw-loss = 0.0024493574164807796, train/logprobs = tensor([[ -1.8198, -15.8967],
        [ -8.7231,  -3.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740221917629242
Epoch 0, Step 2360: train/loss = 0.034956470131874084, train/raw-loss = 0.004416544456034899, train/logprobs = tensor([[ -1.4693, -14.9294],
        [ -9.3610,  -2.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30539923906326294
Epoch 0, Step 2361: train/loss = 0.03779502958059311, train/raw-loss = 0.00441818917170167, train/logprobs = tensor([[ -1.5770, -15.2280],
        [ -8.0448,  -2.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.333768367767334
Epoch 0, Step 2362: train/loss = 0.040339455008506775, train/raw-loss = 0.004059406463056803, train/logprobs = tensor([[ -1.3212, -11.6909],
        [ -6.9564,  -1.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3628004789352417
Epoch 0, Step 2363: train/loss = 0.031153932213783264, train/raw-loss = 0.002975999843329191, train/logprobs = tensor([[ -1.6086, -11.7552],
        [ -7.3533,  -2.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28177928924560547
Epoch 0, Step 2364: train/loss = 0.03217373043298721, train/raw-loss = 0.0028887733351439238, train/logprobs = tensor([[ -1.9408, -18.7754],
        [ -8.7467,  -2.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2928495407104492
Epoch 0, Step 2365: train/loss = 0.034576188772916794, train/raw-loss = 0.0051550231873989105, train/logprobs = tensor([[ -0.8678, -12.5231],
        [ -6.4246,  -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29421165585517883
Epoch 0, Step 2366: train/loss = 0.0333862379193306, train/raw-loss = 0.0017797446344047785, train/logprobs = tensor([[ -1.3156, -14.3758],
        [ -8.2931,  -2.0584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31606489419937134
Epoch 0, Step 2367: train/loss = 0.032917995005846024, train/raw-loss = 0.003170948475599289, train/logprobs = tensor([[ -1.1071, -14.0354],
        [ -7.6317,  -2.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29747048020362854
Epoch 0, Step 2368: train/loss = 0.037393562495708466, train/raw-loss = 0.0047707646153867245, train/logprobs = tensor([[ -1.7968, -12.8828],
        [ -9.2181,  -2.4743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32622793316841125
Epoch 0, Step 2369: train/loss = 0.034494027495384216, train/raw-loss = 0.0015423394506797194, train/logprobs = tensor([[ -1.3143, -12.8401],
        [ -8.7987,  -1.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3295168876647949
Epoch 0, Step 2370: train/loss = 0.03509949520230293, train/raw-loss = 0.0034122681245207787, train/logprobs = tensor([[ -1.4234, -12.0101],
        [ -8.4416,  -1.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.316872239112854
Epoch 0, Step 2371: train/loss = 0.03199183568358421, train/raw-loss = 0.0014927233569324017, train/logprobs = tensor([[ -1.6482, -16.1777],
        [ -9.4846,  -3.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30499109625816345
Epoch 0, Step 2372: train/loss = 0.034691229462623596, train/raw-loss = 0.00376879028044641, train/logprobs = tensor([[ -1.0978, -13.2206],
        [ -6.6458,  -1.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.309224396944046
Epoch 0, Step 2373: train/loss = 0.0495365634560585, train/raw-loss = 0.01539564412087202, train/logprobs = tensor([[ -1.8884, -10.4869],
        [ -7.9829,  -1.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3414091467857361
Epoch 0, Step 2374: train/loss = 0.04149692878127098, train/raw-loss = 0.010104013606905937, train/logprobs = tensor([[-0.7690, -9.3274],
        [-4.8379, -2.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31392911076545715
Epoch 0, Step 2375: train/loss = 0.03720001131296158, train/raw-loss = 0.00196353648789227, train/logprobs = tensor([[ -1.6053, -14.5735],
        [ -8.3471,  -1.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35236474871635437
Epoch 0, Step 2376: train/loss = 0.03555629402399063, train/raw-loss = 0.004910837858915329, train/logprobs = tensor([[ -1.3836, -14.8073],
        [ -7.0739,  -3.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064545691013336
Epoch 0, Step 2377: train/loss = 0.03531770408153534, train/raw-loss = 0.005669332109391689, train/logprobs = tensor([[-0.9945, -8.6308],
        [-6.0347, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29648372530937195
Epoch 0, Step 2378: train/loss = 0.03271239995956421, train/raw-loss = 0.003121398389339447, train/logprobs = tensor([[ -1.1915, -14.4327],
        [ -6.7263,  -1.9015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959100008010864
Epoch 0, Step 2379: train/loss = 0.02968689054250717, train/raw-loss = 0.0005052437190897763, train/logprobs = tensor([[ -1.4376, -19.7675],
        [ -8.9858,  -3.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29181647300720215
Epoch 0, Step 2380: train/loss = 0.03180140256881714, train/raw-loss = 0.0014199698343873024, train/logprobs = tensor([[ -1.2767, -20.0360],
        [ -7.4214,  -4.3796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038143217563629
Epoch 0, Step 2381: train/loss = 0.03609446808695793, train/raw-loss = 0.005384281277656555, train/logprobs = tensor([[ -1.8858, -14.1584],
        [ -8.7386,  -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30710187554359436
Epoch 0, Step 2382: train/loss = 0.04956361651420593, train/raw-loss = 0.01674554869532585, train/logprobs = tensor([[ -1.3722, -12.6152],
        [ -5.1473,  -2.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281806707382202
Epoch 0, Step 2383: train/loss = 0.07404427975416183, train/raw-loss = 0.042982008308172226, train/logprobs = tensor([[ -1.9557, -10.1801],
        [ -7.3130,  -1.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106226921081543
Epoch 0, Step 2384: train/loss = 0.03709603101015091, train/raw-loss = 0.0038649910129606724, train/logprobs = tensor([[ -1.1012, -13.0002],
        [ -6.3239,  -1.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33231037855148315
Epoch 0, Step 2385: train/loss = 0.03329470753669739, train/raw-loss = 0.0020301206968724728, train/logprobs = tensor([[ -1.2497, -13.3656],
        [ -7.9630,  -2.5121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126458525657654
Epoch 0, Step 2386: train/loss = 0.057837408035993576, train/raw-loss = 0.02936827763915062, train/logprobs = tensor([[-2.4264, -9.0329],
        [-6.7224, -1.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28469130396842957
Epoch 0, Step 2387: train/loss = 0.03701586276292801, train/raw-loss = 0.01006836723536253, train/logprobs = tensor([[ -1.1144, -17.2681],
        [ -5.6155,  -1.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26947495341300964
Epoch 0, Step 2388: train/loss = 0.0342254638671875, train/raw-loss = 0.0016917921602725983, train/logprobs = tensor([[ -1.3046, -16.6077],
        [ -7.0310,  -3.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253366947174072
Epoch 0, Step 2389: train/loss = 0.036351848393678665, train/raw-loss = 0.00206252234056592, train/logprobs = tensor([[ -1.2665, -16.4845],
        [ -6.8126,  -2.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428932726383209
Epoch 0, Step 2390: train/loss = 0.03360590711236, train/raw-loss = 0.002299689454957843, train/logprobs = tensor([[ -1.0410, -15.0255],
        [ -6.6411,  -2.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3130621612071991
Epoch 0, Step 2391: train/loss = 0.033897604793310165, train/raw-loss = 0.0013008160749450326, train/logprobs = tensor([[ -1.4380, -10.1683],
        [ -9.3577,  -1.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3259678781032562
Epoch 0, Step 2392: train/loss = 0.03969592973589897, train/raw-loss = 0.0018965955823659897, train/logprobs = tensor([[ -1.6207, -11.5347],
        [ -8.9032,  -1.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3779933452606201
Epoch 0, Step 2393: train/loss = 0.0454578623175621, train/raw-loss = 0.015262332744896412, train/logprobs = tensor([[ -1.4828, -13.3067],
        [ -7.3539,  -1.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019552528858185
Epoch 0, Step 2394: train/loss = 0.04883148893713951, train/raw-loss = 0.016689345240592957, train/logprobs = tensor([[ -1.3497, -13.7514],
        [ -8.0178,  -2.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32142144441604614
Epoch 0, Step 2395: train/loss = 0.03265252709388733, train/raw-loss = 0.0025520760100334883, train/logprobs = tensor([[ -1.1409, -12.7533],
        [ -7.0711,  -2.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010044991970062
Epoch 0, Step 2396: train/loss = 0.03208133578300476, train/raw-loss = 0.004280746914446354, train/logprobs = tensor([[ -0.7530, -14.2246],
        [ -6.0288,  -1.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780058979988098
Epoch 0, Step 2397: train/loss = 0.03269445523619652, train/raw-loss = 0.0019903758075088263, train/logprobs = tensor([[ -1.3940, -13.6848],
        [ -7.8993,  -2.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3070407807826996
Epoch 0, Step 2398: train/loss = 0.03335893899202347, train/raw-loss = 0.0028698183596134186, train/logprobs = tensor([[ -1.1418, -11.9464],
        [ -6.5499,  -1.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048911988735199
Epoch 0, Step 2399: train/loss = 0.07592112571001053, train/raw-loss = 0.043764322996139526, train/logprobs = tensor([[ -1.6678, -12.4858],
        [ -8.4649,  -2.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32156801223754883
Epoch 0, Step 2400: train/loss = 0.040176067501306534, train/raw-loss = 0.008404487743973732, train/logprobs = tensor([[ -1.0144, -15.2132],
        [ -5.5206,  -4.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31771576404571533
Epoch 0, Step 2401: train/loss = 0.034171391278505325, train/raw-loss = 0.0025070905685424805, train/logprobs = tensor([[ -1.5622, -19.9883],
        [ -7.5451,  -5.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31664299964904785
Epoch 0, Step 2402: train/loss = 0.07078347355127335, train/raw-loss = 0.03663281723856926, train/logprobs = tensor([[ -2.0961, -13.2473],
        [ -6.3566,  -1.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3415065407752991
Epoch 0, Step 2403: train/loss = 0.036435678601264954, train/raw-loss = 0.001604840625077486, train/logprobs = tensor([[ -1.1966, -14.1392],
        [ -8.2826,  -1.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34830838441848755
Epoch 0, Step 2404: train/loss = 0.04246772453188896, train/raw-loss = 0.008387545123696327, train/logprobs = tensor([[ -1.0793, -12.4991],
        [ -5.4452,  -1.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34080177545547485
Epoch 0, Step 2405: train/loss = 0.03859144449234009, train/raw-loss = 0.004664913285523653, train/logprobs = tensor([[ -1.1803, -12.1360],
        [ -7.0778,  -2.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392653167247772
Epoch 0, Step 2406: train/loss = 0.039419062435626984, train/raw-loss = 0.009838506579399109, train/logprobs = tensor([[ -0.9420, -13.5878],
        [ -5.0618,  -2.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29580557346343994
Epoch 0, Step 2407: train/loss = 0.038614410907030106, train/raw-loss = 0.00847965944558382, train/logprobs = tensor([[ -0.8061, -12.9233],
        [ -5.2841,  -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013474941253662
Epoch 0, Step 2408: train/loss = 0.04879111051559448, train/raw-loss = 0.020013801753520966, train/logprobs = tensor([[ -1.6963, -14.0697],
        [ -6.2750,  -2.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28777313232421875
Epoch 0, Step 2409: train/loss = 0.031391747295856476, train/raw-loss = 0.001736520091071725, train/logprobs = tensor([[ -1.5597, -19.1853],
        [ -7.7731,  -3.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29655227065086365
Epoch 0, Step 2410: train/loss = 0.03366914391517639, train/raw-loss = 0.003905297489836812, train/logprobs = tensor([[ -1.3090, -15.9390],
        [ -6.2287,  -2.3101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297638475894928
Epoch 0, Step 2411: train/loss = 0.03466538339853287, train/raw-loss = 0.003464277135208249, train/logprobs = tensor([[ -1.6529, -10.6569],
        [ -7.6501,  -1.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31201106309890747
Epoch 0, Step 2412: train/loss = 0.03921045362949371, train/raw-loss = 0.010973354801535606, train/logprobs = tensor([[ -0.8241, -12.0849],
        [ -5.1267,  -2.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28237098455429077
Epoch 0, Step 2413: train/loss = 0.033691149204969406, train/raw-loss = 0.0026136410888284445, train/logprobs = tensor([[ -1.1065, -11.6154],
        [ -7.3534,  -2.4712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107750415802002
Epoch 0, Step 2414: train/loss = 0.036212258040905, train/raw-loss = 0.00372084672562778, train/logprobs = tensor([[ -1.4106, -16.0523],
        [ -6.8357,  -2.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249140977859497
Epoch 0, Step 2415: train/loss = 0.033041369169950485, train/raw-loss = 0.005100472830235958, train/logprobs = tensor([[ -1.4824, -14.9917],
        [ -7.8601,  -2.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27940893173217773
Epoch 0, Step 2416: train/loss = 0.0814855545759201, train/raw-loss = 0.04879211634397507, train/logprobs = tensor([[ -1.4759, -14.9802],
        [ -5.8394,  -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3269343078136444
Epoch 0, Step 2417: train/loss = 0.04300267994403839, train/raw-loss = 0.011468704789876938, train/logprobs = tensor([[ -1.2012, -14.0475],
        [ -5.9761,  -2.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31533974409103394
Epoch 0, Step 2418: train/loss = 0.03403910622000694, train/raw-loss = 0.0008918617968447506, train/logprobs = tensor([[ -1.2529, -14.8512],
        [ -9.1784,  -1.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314724564552307
Epoch 0, Step 2419: train/loss = 0.03393559902906418, train/raw-loss = 0.001985259586945176, train/logprobs = tensor([[ -1.5278, -14.1881],
        [ -7.1089,  -1.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31950339674949646
Epoch 0, Step 2420: train/loss = 0.031179558485746384, train/raw-loss = 0.0025600644294172525, train/logprobs = tensor([[ -1.5686, -14.2917],
        [ -7.9070,  -1.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28619492053985596
Epoch 0, Step 2421: train/loss = 0.043861474841833115, train/raw-loss = 0.015934402123093605, train/logprobs = tensor([[ -0.8293, -13.3930],
        [ -5.0550,  -2.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792707085609436
Epoch 0, Step 2422: train/loss = 0.040151447057724, train/raw-loss = 0.009287926368415356, train/logprobs = tensor([[ -1.4385, -14.8339],
        [ -6.6880,  -2.5460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086352050304413
Epoch 0, Step 2423: train/loss = 0.04092811793088913, train/raw-loss = 0.011744425632059574, train/logprobs = tensor([[ -1.5356, -16.5590],
        [ -8.5953,  -4.3200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2918369174003601
Epoch 0, Step 2424: train/loss = 0.03653460741043091, train/raw-loss = 0.002976739313453436, train/logprobs = tensor([[ -1.7278, -14.2783],
        [ -9.1237,  -2.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33557865023612976
Epoch 0, Step 2425: train/loss = 0.032482393085956573, train/raw-loss = 0.004040606785565615, train/logprobs = tensor([[ -1.0450, -17.8386],
        [ -7.7392,  -1.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28441786766052246
Epoch 0, Step 2426: train/loss = 0.04453045502305031, train/raw-loss = 0.005286086350679398, train/logprobs = tensor([[-1.0441, -7.9725],
        [-6.3883, -1.5419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3924436867237091
Epoch 0, Step 2427: train/loss = 0.03434627875685692, train/raw-loss = 0.008321281522512436, train/logprobs = tensor([[ -1.1811, -12.5740],
        [ -5.9723,  -1.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602499723434448
Epoch 0, Step 2428: train/loss = 0.03529008477926254, train/raw-loss = 0.0072374227456748486, train/logprobs = tensor([[ -0.9124, -13.7041],
        [ -5.2551,  -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805265784263611
Epoch 0, Step 2429: train/loss = 0.03562159091234207, train/raw-loss = 0.004495594650506973, train/logprobs = tensor([[ -2.1778, -10.4619],
        [ -7.2781,  -1.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3112599551677704
Epoch 0, Step 2430: train/loss = 0.04057406261563301, train/raw-loss = 0.011709452606737614, train/logprobs = tensor([[ -1.1793, -15.2946],
        [ -6.0307,  -1.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886461317539215
Epoch 0, Step 2431: train/loss = 0.03379863500595093, train/raw-loss = 0.0017529416363686323, train/logprobs = tensor([[ -1.2323, -13.2033],
        [ -7.5725,  -1.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32045695185661316
Epoch 0, Step 2432: train/loss = 0.03613102436065674, train/raw-loss = 0.00824950821697712, train/logprobs = tensor([[ -1.6439, -18.5264],
        [ -6.9412,  -4.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788151800632477
Epoch 0, Step 2433: train/loss = 0.04310129955410957, train/raw-loss = 0.00963196437805891, train/logprobs = tensor([[ -1.6255, -12.6329],
        [ -7.0694,  -3.0327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3346933424472809
Epoch 0, Step 2434: train/loss = 0.0327315479516983, train/raw-loss = 0.0019763840828090906, train/logprobs = tensor([[ -1.7217, -16.7741],
        [ -8.1536,  -2.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30755162239074707
Epoch 0, Step 2435: train/loss = 0.03227114677429199, train/raw-loss = 0.006763609126210213, train/logprobs = tensor([[ -0.9827, -14.8756],
        [ -5.5672,  -2.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550753653049469
Epoch 0, Step 2436: train/loss = 0.03827850520610809, train/raw-loss = 0.007376264780759811, train/logprobs = tensor([[ -0.7431, -12.7400],
        [ -5.1535,  -2.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30902236700057983
Epoch 0, Step 2437: train/loss = 0.04435497522354126, train/raw-loss = 0.01450798287987709, train/logprobs = tensor([[ -2.1475, -13.4201],
        [ -6.0708,  -2.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984699010848999
Epoch 0, Step 2438: train/loss = 0.03792683780193329, train/raw-loss = 0.007196403108537197, train/logprobs = tensor([[ -1.2815, -13.0635],
        [ -6.9198,  -2.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30730438232421875
Epoch 0, Step 2439: train/loss = 0.039929866790771484, train/raw-loss = 0.006666305474936962, train/logprobs = tensor([[ -1.1542, -15.8581],
        [ -6.1255,  -2.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33263564109802246
Epoch 0, Step 2440: train/loss = 0.03337600827217102, train/raw-loss = 0.0014414973556995392, train/logprobs = tensor([[ -1.8408, -11.2289],
        [ -9.6772,  -1.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319345086812973
Epoch 0, Step 2441: train/loss = 0.05610453337430954, train/raw-loss = 0.027866147458553314, train/logprobs = tensor([[-1.0577, -9.4152],
        [-5.3864, -1.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28238385915756226
Epoch 0, Step 2442: train/loss = 0.035848889499902725, train/raw-loss = 0.006226147059351206, train/logprobs = tensor([[ -1.4035, -16.9837],
        [ -5.9783,  -3.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29622742533683777
Epoch 0, Step 2443: train/loss = 0.03496444597840309, train/raw-loss = 0.00493523059412837, train/logprobs = tensor([[ -1.1085, -15.9257],
        [ -5.9562,  -1.9503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30029213428497314
Epoch 0, Step 2444: train/loss = 0.03452743589878082, train/raw-loss = 0.003384212963283062, train/logprobs = tensor([[ -1.1675, -17.0856],
        [ -6.9569,  -3.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31143221259117126
Epoch 0, Step 2445: train/loss = 0.05458448454737663, train/raw-loss = 0.023553239181637764, train/logprobs = tensor([[-1.8757, -7.3660],
        [-8.6153, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3103124499320984
Epoch 0, Step 2446: train/loss = 0.05740871652960777, train/raw-loss = 0.029941294342279434, train/logprobs = tensor([[ -1.1318, -14.7475],
        [ -5.8330,  -1.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746742367744446
Epoch 0, Step 2447: train/loss = 0.03782859444618225, train/raw-loss = 0.005754898767918348, train/logprobs = tensor([[ -2.0853, -10.8213],
        [ -7.8600,  -1.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32073694467544556
Epoch 0, Step 2448: train/loss = 0.035886041820049286, train/raw-loss = 0.006666658446192741, train/logprobs = tensor([[ -1.5499, -10.5782],
        [ -6.5034,  -2.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29219385981559753
Epoch 0, Step 2449: train/loss = 0.03663491830229759, train/raw-loss = 0.004945330321788788, train/logprobs = tensor([[ -2.0109, -16.9344],
        [ -8.2344,  -3.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31689590215682983
Epoch 0, Step 2450: train/loss = 0.032161083072423935, train/raw-loss = 0.0036790315061807632, train/logprobs = tensor([[ -1.3439, -12.3665],
        [ -7.0012,  -2.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848204970359802
Epoch 0, Step 2451: train/loss = 0.03526448830962181, train/raw-loss = 0.002704300219193101, train/logprobs = tensor([[ -1.4260, -19.2822],
        [ -7.7978,  -3.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32560184597969055
Epoch 0, Step 2452: train/loss = 0.03343738988041878, train/raw-loss = 0.0028342006262391806, train/logprobs = tensor([[ -1.0428, -12.2067],
        [ -7.2330,  -1.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30603188276290894
Epoch 0, Step 2453: train/loss = 0.03499294072389603, train/raw-loss = 0.00434297788888216, train/logprobs = tensor([[ -1.4917, -13.6847],
        [ -8.2490,  -2.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064996004104614
Epoch 0, Step 2454: train/loss = 0.03633447736501694, train/raw-loss = 0.003248533234000206, train/logprobs = tensor([[ -1.2582, -12.2838],
        [ -6.8867,  -1.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3308594226837158
Epoch 0, Step 2455: train/loss = 0.04140707105398178, train/raw-loss = 0.015154633671045303, train/logprobs = tensor([[-1.0770, -9.8622],
        [-5.3434, -1.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26252439618110657
Epoch 0, Step 2456: train/loss = 0.029135070741176605, train/raw-loss = 0.0014748161192983389, train/logprobs = tensor([[ -1.2428, -21.6123],
        [ -7.7177,  -3.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27660253643989563
Epoch 0, Step 2457: train/loss = 0.1841929852962494, train/raw-loss = 0.1554047018289566, train/logprobs = tensor([[ -1.4699, -11.5466],
        [ -4.1937,  -1.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.287882924079895
Epoch 0, Step 2458: train/loss = 0.03906139358878136, train/raw-loss = 0.008856349624693394, train/logprobs = tensor([[ -0.9385, -16.7359],
        [ -5.4297,  -2.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020504117012024
Epoch 0, Step 2459: train/loss = 0.037653256207704544, train/raw-loss = 0.007395656779408455, train/logprobs = tensor([[ -1.1911, -13.3752],
        [ -6.5422,  -1.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025760054588318
Epoch 0, Step 2460: train/loss = 0.03311644867062569, train/raw-loss = 0.0035557467490434647, train/logprobs = tensor([[ -1.3740, -14.5215],
        [ -7.5649,  -2.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956070005893707
Epoch 0, Step 2461: train/loss = 0.036743953824043274, train/raw-loss = 0.005475100129842758, train/logprobs = tensor([[ -1.2538, -11.8022],
        [ -6.9755,  -2.2455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126884996891022
Epoch 0, Step 2462: train/loss = 0.03331364691257477, train/raw-loss = 0.003686746582388878, train/logprobs = tensor([[ -1.1042, -14.1354],
        [ -6.6982,  -2.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2962689995765686
Epoch 0, Step 2463: train/loss = 0.04925370588898659, train/raw-loss = 0.014552535489201546, train/logprobs = tensor([[-1.2207, -9.8309],
        [-8.4189, -3.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3470116853713989
Epoch 0, Step 2464: train/loss = 0.045719604939222336, train/raw-loss = 0.02288115583360195, train/logprobs = tensor([[ -1.3704, -14.3547],
        [ -5.8805,  -4.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22838446497917175
Epoch 0, Step 2465: train/loss = 0.03189855441451073, train/raw-loss = 0.0018048100173473358, train/logprobs = tensor([[ -1.5768, -17.7679],
        [ -7.2313,  -4.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3009374439716339
Epoch 0, Step 2466: train/loss = 0.038002319633960724, train/raw-loss = 0.006933551747351885, train/logprobs = tensor([[ -0.9769, -18.5417],
        [ -6.1044,  -4.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106876611709595
Epoch 0, Step 2467: train/loss = 0.0346716046333313, train/raw-loss = 0.004406027961522341, train/logprobs = tensor([[ -0.9590, -14.7744],
        [ -6.1481,  -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30265575647354126
Epoch 0, Step 2468: train/loss = 0.03283638879656792, train/raw-loss = 0.001243246835656464, train/logprobs = tensor([[ -1.5593, -18.3153],
        [ -8.9888,  -2.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31593143939971924
Epoch 0, Step 2469: train/loss = 0.037170447409152985, train/raw-loss = 0.006606405135244131, train/logprobs = tensor([[ -1.3743, -14.1384],
        [ -6.3414,  -2.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30564042925834656
Epoch 0, Step 2470: train/loss = 0.03490269556641579, train/raw-loss = 0.004783853888511658, train/logprobs = tensor([[ -1.5043, -15.2763],
        [ -7.4656,  -1.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011884093284607
Epoch 0, Step 2471: train/loss = 0.043522972613573074, train/raw-loss = 0.014611096121370792, train/logprobs = tensor([[ -1.3235, -12.9605],
        [ -4.9790,  -1.4798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28911876678466797
Epoch 0, Step 2472: train/loss = 0.03924591839313507, train/raw-loss = 0.008089243434369564, train/logprobs = tensor([[-0.9906, -9.9102],
        [-5.8329, -1.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115667700767517
Epoch 0, Step 2473: train/loss = 0.03654816746711731, train/raw-loss = 0.005156587343662977, train/logprobs = tensor([[ -1.1501, -18.9352],
        [ -6.0008,  -3.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31391578912734985
Epoch 0, Step 2474: train/loss = 0.03360520675778389, train/raw-loss = 0.00345039926469326, train/logprobs = tensor([[ -1.8661, -14.2577],
        [ -7.1933,  -2.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015480637550354
Epoch 0, Step 2475: train/loss = 0.031567323952913284, train/raw-loss = 0.005511881783604622, train/logprobs = tensor([[ -1.2246, -12.5452],
        [ -5.9191,  -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605544328689575
Epoch 0, Step 2476: train/loss = 0.040128715336322784, train/raw-loss = 0.00898918230086565, train/logprobs = tensor([[ -1.4689, -17.1772],
        [ -8.5585,  -3.4289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3113953173160553
Epoch 0, Step 2477: train/loss = 0.03486185893416405, train/raw-loss = 0.006204667035490274, train/logprobs = tensor([[ -1.1304, -14.4430],
        [ -6.1380,  -1.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865719199180603
Epoch 0, Step 2478: train/loss = 0.04021865129470825, train/raw-loss = 0.00771845318377018, train/logprobs = tensor([[ -1.4382, -13.2864],
        [ -6.3620,  -2.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.325001984834671
Epoch 0, Step 2479: train/loss = 0.03393762186169624, train/raw-loss = 0.00472429720684886, train/logprobs = tensor([[ -1.4343, -17.9735],
        [ -7.3750,  -3.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29213324189186096
Epoch 0, Step 2480: train/loss = 0.0411267913877964, train/raw-loss = 0.015167029574513435, train/logprobs = tensor([[ -1.6747, -11.7460],
        [ -6.1579,  -1.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25959762930870056
Epoch 0, Step 2481: train/loss = 0.03236275166273117, train/raw-loss = 0.002210183534771204, train/logprobs = tensor([[ -1.4287, -17.4148],
        [ -7.2392,  -2.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30152565240859985
Epoch 0, Step 2482: train/loss = 0.037460073828697205, train/raw-loss = 0.002625873312354088, train/logprobs = tensor([[ -1.5143, -12.8878],
        [ -7.0710,  -1.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3483419716358185
Epoch 0, Step 2483: train/loss = 0.042401544749736786, train/raw-loss = 0.010328827425837517, train/logprobs = tensor([[ -1.5588, -17.0658],
        [ -6.3532,  -2.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3207271695137024
Epoch 0, Step 2484: train/loss = 0.044590793550014496, train/raw-loss = 0.01620185375213623, train/logprobs = tensor([[ -1.2128, -15.4926],
        [ -5.0641,  -1.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28388944268226624
Epoch 0, Step 2485: train/loss = 0.037789616733789444, train/raw-loss = 0.008941018022596836, train/logprobs = tensor([[ -1.6962, -12.5212],
        [ -7.5350,  -1.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28848597407341003
Epoch 0, Step 2486: train/loss = 0.03201377019286156, train/raw-loss = 0.001106620766222477, train/logprobs = tensor([[ -1.8099, -18.3830],
        [ -8.4655,  -5.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30907151103019714
Epoch 0, Step 2487: train/loss = 0.03736941143870354, train/raw-loss = 0.0073842862620949745, train/logprobs = tensor([[ -1.5309, -12.0898],
        [ -6.6460,  -1.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29985126852989197
Epoch 0, Step 2488: train/loss = 0.03440820053219795, train/raw-loss = 0.0052476548589766026, train/logprobs = tensor([[ -1.1644, -22.1763],
        [ -5.9526,  -5.2223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2916054427623749
Epoch 0, Step 2489: train/loss = 0.05993672460317612, train/raw-loss = 0.029702866449952126, train/logprobs = tensor([[ -1.5564, -12.5398],
        [ -7.1577,  -3.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3023386001586914
Epoch 0, Step 2490: train/loss = 0.08027935773134232, train/raw-loss = 0.04905278980731964, train/logprobs = tensor([[ -2.2878, -13.1288],
        [ -5.9149,  -2.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31226569414138794
Epoch 0, Step 2491: train/loss = 0.03692382946610451, train/raw-loss = 0.004978583659976721, train/logprobs = tensor([[ -1.0222, -19.0358],
        [ -6.5555,  -2.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194524645805359
Epoch 0, Step 2492: train/loss = 0.03637121245265007, train/raw-loss = 0.00578028941527009, train/logprobs = tensor([[ -1.4715, -11.4958],
        [ -6.5723,  -2.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059092164039612
Epoch 0, Step 2493: train/loss = 0.034594547003507614, train/raw-loss = 0.0039765541441738605, train/logprobs = tensor([[ -1.5657, -11.2213],
        [ -7.3562,  -1.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306179940700531
Epoch 0, Step 2494: train/loss = 0.04751525819301605, train/raw-loss = 0.019810685887932777, train/logprobs = tensor([[ -1.1448, -13.7348],
        [ -4.7562,  -2.9839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27704572677612305
Epoch 0, Step 2495: train/loss = 0.03562869876623154, train/raw-loss = 0.008505874313414097, train/logprobs = tensor([[ -1.2091, -11.3396],
        [ -6.0323,  -1.4823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27122825384140015
Epoch 0, Step 2496: train/loss = 0.031110242009162903, train/raw-loss = 0.0017757697496563196, train/logprobs = tensor([[ -1.5928, -18.1265],
        [ -8.4947,  -3.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933447062969208
Epoch 0, Step 2497: train/loss = 0.03363296017050743, train/raw-loss = 0.002603676402941346, train/logprobs = tensor([[ -1.7298, -10.9833],
        [ -8.8937,  -1.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3102928400039673
Epoch 0, Step 2498: train/loss = 0.03153153508901596, train/raw-loss = 0.0027955418918281794, train/logprobs = tensor([[ -1.4034, -16.5352],
        [ -6.9436,  -3.0266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28735992312431335
Epoch 0, Step 2499: train/loss = 0.03295694291591644, train/raw-loss = 0.003891613334417343, train/logprobs = tensor([[ -1.2403, -17.1387],
        [ -6.1839,  -2.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2906532883644104
Epoch 0, Step 2500: train/loss = 0.049934353679418564, train/raw-loss = 0.02034868113696575, train/logprobs = tensor([[ -1.4276, -10.6140],
        [ -6.7088,  -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2958567142486572
Epoch 0, Step 2501: train/loss = 0.03169650211930275, train/raw-loss = 0.001736075384542346, train/logprobs = tensor([[ -1.2995, -17.0854],
        [ -7.1049,  -1.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29960426688194275
Epoch 0, Step 2502: train/loss = 0.031623475253582, train/raw-loss = 0.002102950122207403, train/logprobs = tensor([[ -1.6970, -14.2506],
        [ -8.0863,  -1.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952052354812622
Epoch 0, Step 2503: train/loss = 0.043527230620384216, train/raw-loss = 0.013621335849165916, train/logprobs = tensor([[ -1.8802, -15.2081],
        [ -5.9690,  -3.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2990589737892151
Epoch 0, Step 2504: train/loss = 0.05558144301176071, train/raw-loss = 0.02565324679017067, train/logprobs = tensor([[ -1.7752, -15.0435],
        [ -6.9704,  -3.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992819547653198
Epoch 0, Step 2505: train/loss = 0.036164067685604095, train/raw-loss = 0.0057837748900055885, train/logprobs = tensor([[ -1.2173, -13.6842],
        [ -6.2994,  -2.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038029372692108
Epoch 0, Step 2506: train/loss = 0.03301256150007248, train/raw-loss = 0.0030633965507149696, train/logprobs = tensor([[ -1.5858, -12.9146],
        [ -7.1896,  -2.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29949164390563965
Epoch 0, Step 2507: train/loss = 0.047114089131355286, train/raw-loss = 0.01534335408359766, train/logprobs = tensor([[ -1.2529, -17.5385],
        [ -5.1938,  -3.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317707359790802
Epoch 0, Step 2508: train/loss = 0.0295597855001688, train/raw-loss = 0.0025341827422380447, train/logprobs = tensor([[ -1.5102, -12.7414],
        [ -7.6098,  -1.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27025604248046875
Epoch 0, Step 2509: train/loss = 0.06145361810922623, train/raw-loss = 0.029500160366296768, train/logprobs = tensor([[ -1.4915, -17.5302],
        [ -6.4316,  -2.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3195345401763916
Epoch 0, Step 2510: train/loss = 0.036512866616249084, train/raw-loss = 0.007074267137795687, train/logprobs = tensor([[ -1.2768, -13.2403],
        [ -6.3789,  -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29438599944114685
Epoch 0, Step 2511: train/loss = 0.06616012752056122, train/raw-loss = 0.03751529008150101, train/logprobs = tensor([[ -1.7320, -16.4591],
        [ -6.6266,  -1.4995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28644832968711853
Epoch 0, Step 2512: train/loss = 0.04232025146484375, train/raw-loss = 0.010022798553109169, train/logprobs = tensor([[ -1.5650, -17.0513],
        [ -6.9132,  -2.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229745030403137
Epoch 0, Step 2513: train/loss = 0.03272595256567001, train/raw-loss = 0.004062644671648741, train/logprobs = tensor([[ -1.1135, -15.3735],
        [ -7.0323,  -2.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28663307428359985
Epoch 0, Step 2514: train/loss = 0.03051518090069294, train/raw-loss = 0.001154193188995123, train/logprobs = tensor([[ -1.5536, -12.8105],
        [ -8.4271,  -2.2563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2936098575592041
Epoch 0, Step 2515: train/loss = 0.06177234649658203, train/raw-loss = 0.02851013094186783, train/logprobs = tensor([[ -2.1991, -13.2377],
        [ -6.8969,  -2.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33262214064598083
Epoch 0, Step 2516: train/loss = 0.032962020486593246, train/raw-loss = 0.002516360254958272, train/logprobs = tensor([[ -1.6330, -15.5734],
        [ -8.5696,  -4.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30445659160614014
Epoch 0, Step 2517: train/loss = 0.03171871230006218, train/raw-loss = 0.004124491475522518, train/logprobs = tensor([[ -2.8365, -18.0635],
        [ -8.3608,  -2.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27594223618507385
Epoch 0, Step 2518: train/loss = 0.030605629086494446, train/raw-loss = 0.0033019832335412502, train/logprobs = tensor([[ -2.1255, -20.5104],
        [ -8.4996,  -3.5380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730364501476288
Epoch 0, Step 2519: train/loss = 0.0518278032541275, train/raw-loss = 0.021259037777781487, train/logprobs = tensor([[ -3.0596, -11.2716],
        [ -9.1197,  -1.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30568763613700867
Epoch 0, Step 2520: train/loss = 0.04419342428445816, train/raw-loss = 0.01571296527981758, train/logprobs = tensor([[ -2.0335, -12.1350],
        [ -6.7597,  -1.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848046123981476
Epoch 0, Step 2521: train/loss = 0.09313526749610901, train/raw-loss = 0.06293935328722, train/logprobs = tensor([[ -2.4336, -17.2503],
        [ -7.0819,  -3.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30195918679237366
Epoch 0, Step 2522: train/loss = 0.041626740247011185, train/raw-loss = 0.0071031032130122185, train/logprobs = tensor([[ -1.2115, -13.1877],
        [ -6.7489,  -2.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3452363610267639
Epoch 0, Step 2523: train/loss = 0.033091798424720764, train/raw-loss = 0.004007482435554266, train/logprobs = tensor([[ -1.1729, -15.4745],
        [ -6.2950,  -2.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2908431887626648
Epoch 0, Step 2524: train/loss = 0.03458094596862793, train/raw-loss = 0.005781530402600765, train/logprobs = tensor([[ -1.7583, -11.7989],
        [ -7.2755,  -2.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879941463470459
Epoch 0, Step 2525: train/loss = 0.03230523318052292, train/raw-loss = 0.0028852440882474184, train/logprobs = tensor([[ -1.4932, -17.9520],
        [ -7.2421,  -3.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2941998839378357
Epoch 0, Step 2526: train/loss = 0.033376544713974, train/raw-loss = 0.004691969603300095, train/logprobs = tensor([[ -1.4969, -13.1736],
        [ -6.4134,  -2.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28684574365615845
Epoch 0, Step 2527: train/loss = 0.08192427456378937, train/raw-loss = 0.052247773855924606, train/logprobs = tensor([[ -1.4069, -12.3406],
        [ -4.3394,  -2.0654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967650294303894
Epoch 0, Step 2528: train/loss = 0.047407448291778564, train/raw-loss = 0.01989886723458767, train/logprobs = tensor([[ -0.9636, -13.0110],
        [ -4.9131,  -2.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27508577704429626
Epoch 0, Step 2529: train/loss = 0.03614944592118263, train/raw-loss = 0.0041098021902143955, train/logprobs = tensor([[ -1.1969, -16.2083],
        [ -6.6179,  -2.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32039645314216614
Epoch 0, Step 2530: train/loss = 0.034893471747636795, train/raw-loss = 0.00741799920797348, train/logprobs = tensor([[ -1.4319, -14.1926],
        [ -6.1307,  -2.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27475473284721375
Epoch 0, Step 2531: train/loss = 0.1518246829509735, train/raw-loss = 0.119818776845932, train/logprobs = tensor([[ -3.1619, -13.8365],
        [ -6.5077,  -1.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200591206550598
Epoch 0, Step 2532: train/loss = 0.03414355218410492, train/raw-loss = 0.003343700198456645, train/logprobs = tensor([[ -1.4367, -12.5717],
        [ -6.8748,  -1.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079984784126282
Epoch 0, Step 2533: train/loss = 0.03563646227121353, train/raw-loss = 0.005429485812783241, train/logprobs = tensor([[ -1.0295, -15.4820],
        [ -5.8044,  -2.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020697832107544
Epoch 0, Step 2534: train/loss = 0.032992467284202576, train/raw-loss = 0.005353936459869146, train/logprobs = tensor([[ -3.9181, -16.4137],
        [ -8.8351,  -2.0405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27638524770736694
Epoch 0, Step 2535: train/loss = 0.035968709737062454, train/raw-loss = 0.002657551085576415, train/logprobs = tensor([[ -1.2904, -15.1771],
        [ -7.6667,  -3.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33311158418655396
Epoch 0, Step 2536: train/loss = 0.030040888115763664, train/raw-loss = 0.0033011098857969046, train/logprobs = tensor([[ -1.8960, -20.3121],
        [ -6.9441,  -3.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26739776134490967
Epoch 0, Step 2537: train/loss = 0.03734967112541199, train/raw-loss = 0.007943574339151382, train/logprobs = tensor([[ -0.8149, -16.2843],
        [ -5.7975,  -2.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29406091570854187
Epoch 0, Step 2538: train/loss = 0.0360478013753891, train/raw-loss = 0.007629853673279285, train/logprobs = tensor([[ -1.2659, -15.0552],
        [ -5.9864,  -2.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2841795086860657
Epoch 0, Step 2539: train/loss = 0.03434609994292259, train/raw-loss = 0.0014112188946455717, train/logprobs = tensor([[ -2.0406, -14.7665],
        [ -9.1675,  -3.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3293488025665283
Epoch 0, Step 2540: train/loss = 0.033438727259635925, train/raw-loss = 0.004927457310259342, train/logprobs = tensor([[ -1.2417, -19.1455],
        [ -7.5732,  -2.0970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851127088069916
Epoch 0, Step 2541: train/loss = 0.032506607472896576, train/raw-loss = 0.0065226065926253796, train/logprobs = tensor([[ -1.8296, -14.3130],
        [ -7.6273,  -2.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598400115966797
Epoch 0, Step 2542: train/loss = 0.033228904008865356, train/raw-loss = 0.0034293951466679573, train/logprobs = tensor([[ -1.8796, -14.3134],
        [ -7.4754,  -2.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29799509048461914
Epoch 0, Step 2543: train/loss = 0.03349822759628296, train/raw-loss = 0.0027985451743006706, train/logprobs = tensor([[ -1.3017, -14.0006],
        [ -7.3592,  -2.3443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30699682235717773
Epoch 0, Step 2544: train/loss = 0.030397329479455948, train/raw-loss = 0.0030919250566512346, train/logprobs = tensor([[ -1.8230, -16.1973],
        [ -7.4942,  -2.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730540335178375
Epoch 0, Step 2545: train/loss = 0.03924458473920822, train/raw-loss = 0.005805616732686758, train/logprobs = tensor([[ -1.9018, -11.9934],
        [ -7.1566,  -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33438965678215027
Epoch 0, Step 2546: train/loss = 0.0568685345351696, train/raw-loss = 0.025547344237565994, train/logprobs = tensor([[ -1.4217, -13.4851],
        [ -5.0293,  -1.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132118880748749
Epoch 0, Step 2547: train/loss = 0.0678270235657692, train/raw-loss = 0.036750271916389465, train/logprobs = tensor([[ -1.3922, -13.5759],
        [ -5.6339,  -2.3652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107674717903137
Epoch 0, Step 2548: train/loss = 0.07739675790071487, train/raw-loss = 0.04648244380950928, train/logprobs = tensor([[ -2.0733, -14.2741],
        [ -6.6600,  -1.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30914315581321716
Epoch 0, Step 2549: train/loss = 0.03499628230929375, train/raw-loss = 0.0008138340199366212, train/logprobs = tensor([[ -1.7147, -17.6538],
        [ -8.1780,  -2.4418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3418245017528534
Epoch 0, Step 2550: train/loss = 0.0372936949133873, train/raw-loss = 0.004725346341729164, train/logprobs = tensor([[ -1.2187, -15.7452],
        [ -6.2924,  -2.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32568347454071045
Epoch 0, Step 2551: train/loss = 0.038995929062366486, train/raw-loss = 0.009931359440088272, train/logprobs = tensor([[ -1.1430, -13.6696],
        [ -5.6043,  -2.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29064568877220154
Epoch 0, Step 2552: train/loss = 0.04126079007983208, train/raw-loss = 0.013454816304147243, train/logprobs = tensor([[ -1.9296, -17.2327],
        [ -7.0894,  -2.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.278059720993042
Epoch 0, Step 2553: train/loss = 0.03474873676896095, train/raw-loss = 0.004179408308118582, train/logprobs = tensor([[ -1.3919, -15.9299],
        [ -7.3932,  -2.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30569326877593994
Epoch 0, Step 2554: train/loss = 0.041789326816797256, train/raw-loss = 0.003033864079043269, train/logprobs = tensor([[ -1.1375, -17.0607],
        [ -6.7170,  -3.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3875546157360077
Epoch 0, Step 2555: train/loss = 0.03738590329885483, train/raw-loss = 0.0097782202064991, train/logprobs = tensor([[ -1.6327, -14.3739],
        [ -6.6103,  -2.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760768532752991
Epoch 0, Step 2556: train/loss = 0.034708403050899506, train/raw-loss = 0.0024801897816359997, train/logprobs = tensor([[ -1.8836, -16.4660],
        [ -7.6559,  -2.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.322282075881958
Epoch 0, Step 2557: train/loss = 0.037319738417863846, train/raw-loss = 0.0077821952290833, train/logprobs = tensor([[ -1.4448, -10.5455],
        [ -5.7777,  -1.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29537540674209595
Epoch 0, Step 2558: train/loss = 0.03199789673089981, train/raw-loss = 0.004662765190005302, train/logprobs = tensor([[ -1.1908, -17.2188],
        [ -6.6807,  -4.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2733512818813324
Epoch 0, Step 2559: train/loss = 0.038517098873853683, train/raw-loss = 0.008123400621116161, train/logprobs = tensor([[ -1.6510, -19.7236],
        [ -6.9210,  -4.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039369583129883
Epoch 0, Step 2560: train/loss = 0.04579196870326996, train/raw-loss = 0.016229193657636642, train/logprobs = tensor([[ -1.2265, -14.0533],
        [ -8.2382,  -2.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956277132034302
Epoch 0, Step 2561: train/loss = 0.07928378880023956, train/raw-loss = 0.05207217112183571, train/logprobs = tensor([[ -1.9235, -20.6207],
        [ -5.7549,  -4.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27211615443229675
Epoch 0, Step 2562: train/loss = 0.03915199637413025, train/raw-loss = 0.00714824628084898, train/logprobs = tensor([[ -0.7844, -16.4972],
        [ -5.4693,  -4.0246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32003748416900635
Epoch 0, Step 2563: train/loss = 0.03620731830596924, train/raw-loss = 0.005767043214291334, train/logprobs = tensor([[ -1.5128, -13.3745],
        [ -7.7263,  -1.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30440273880958557
Epoch 0, Step 2564: train/loss = 0.03457099199295044, train/raw-loss = 0.003121360205113888, train/logprobs = tensor([[ -1.5434, -15.6715],
        [ -6.8135,  -2.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3144962787628174
Epoch 0, Step 2565: train/loss = 0.036141909658908844, train/raw-loss = 0.0011882203398272395, train/logprobs = tensor([[ -1.4996, -13.8773],
        [ -7.6586,  -1.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3495368957519531
Epoch 0, Step 2566: train/loss = 0.03287728130817413, train/raw-loss = 0.005790674593299627, train/logprobs = tensor([[ -1.2185, -14.7515],
        [ -6.0941,  -2.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708660364151001
Epoch 0, Step 2567: train/loss = 0.057527653872966766, train/raw-loss = 0.02774418704211712, train/logprobs = tensor([[ -1.3818, -12.9481],
        [ -5.6151,  -2.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978346645832062
Epoch 0, Step 2568: train/loss = 0.032876450568437576, train/raw-loss = 0.0034909320529550314, train/logprobs = tensor([[ -1.5125, -13.3946],
        [ -7.2621,  -2.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938551902770996
Epoch 0, Step 2569: train/loss = 0.032751671969890594, train/raw-loss = 0.003953574690967798, train/logprobs = tensor([[ -2.0875, -14.5967],
        [ -7.3143,  -2.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28798097372055054
Epoch 0, Step 2570: train/loss = 0.042880747467279434, train/raw-loss = 0.005295235197991133, train/logprobs = tensor([[ -2.0844, -12.1060],
        [ -7.7620,  -2.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37585508823394775
Epoch 0, Step 2571: train/loss = 0.035476841032505035, train/raw-loss = 0.006075448822230101, train/logprobs = tensor([[-2.2385, -9.1716],
        [-9.9879, -1.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2940139174461365
Epoch 0, Step 2572: train/loss = 0.05012050271034241, train/raw-loss = 0.02473570592701435, train/logprobs = tensor([[ -1.5989, -14.6797],
        [ -5.3352,  -1.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25384798645973206
Epoch 0, Step 2573: train/loss = 0.03827861696481705, train/raw-loss = 0.006125154439359903, train/logprobs = tensor([[ -2.0603, -13.8412],
        [ -6.7228,  -2.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215346336364746
Epoch 0, Step 2574: train/loss = 0.03727824613451958, train/raw-loss = 0.0035682779271155596, train/logprobs = tensor([[ -1.2085, -19.9241],
        [ -6.4419,  -3.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33709967136383057
Epoch 0, Step 2575: train/loss = 0.05297374725341797, train/raw-loss = 0.024309080094099045, train/logprobs = tensor([[ -1.1282, -13.7875],
        [ -5.5523,  -2.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28664669394493103
Epoch 0, Step 2576: train/loss = 0.03483641892671585, train/raw-loss = 0.0021165511570870876, train/logprobs = tensor([[ -1.3198, -11.5733],
        [ -7.3085,  -1.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32719871401786804
Epoch 0, Step 2577: train/loss = 0.048191625624895096, train/raw-loss = 0.016216883435845375, train/logprobs = tensor([[ -0.9992, -12.3932],
        [ -5.4069,  -2.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3197474181652069
Epoch 0, Step 2578: train/loss = 0.038041792809963226, train/raw-loss = 0.00595156941562891, train/logprobs = tensor([[ -1.5106, -18.7642],
        [ -6.4330,  -2.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209022283554077
Epoch 0, Step 2579: train/loss = 0.0401562936604023, train/raw-loss = 0.00863591954112053, train/logprobs = tensor([[ -1.4067, -16.5464],
        [ -5.5124,  -3.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152037262916565
Epoch 0, Step 2580: train/loss = 0.03417953848838806, train/raw-loss = 0.0027864822186529636, train/logprobs = tensor([[ -2.0234, -18.5147],
        [-10.4578,  -4.7205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31393057107925415
Epoch 0, Step 2581: train/loss = 0.035464756190776825, train/raw-loss = 0.004184889141470194, train/logprobs = tensor([[ -1.1690, -14.4248],
        [ -6.6552,  -2.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3127986788749695
Epoch 0, Step 2582: train/loss = 0.03920845687389374, train/raw-loss = 0.010142835788428783, train/logprobs = tensor([[ -1.9233, -15.7643],
        [ -8.6443,  -3.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2906562089920044
Epoch 0, Step 2583: train/loss = 0.03626608848571777, train/raw-loss = 0.0039013184141367674, train/logprobs = tensor([[ -1.2335, -12.1530],
        [ -6.5877,  -1.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323647677898407
Epoch 0, Step 2584: train/loss = 0.031810212880373, train/raw-loss = 0.0020977994427084923, train/logprobs = tensor([[ -1.6303, -13.0784],
        [ -7.7242,  -2.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29712411761283875
Epoch 0, Step 2585: train/loss = 0.035512056201696396, train/raw-loss = 0.002443332225084305, train/logprobs = tensor([[ -0.9965, -13.9984],
        [ -6.5829,  -2.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306872248649597
Epoch 0, Step 2586: train/loss = 0.029913509264588356, train/raw-loss = 0.000962640275247395, train/logprobs = tensor([[ -1.9023, -15.6493],
        [ -9.1076,  -2.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895087003707886
Epoch 0, Step 2587: train/loss = 0.03414836525917053, train/raw-loss = 0.0036510860081762075, train/logprobs = tensor([[ -1.6553, -12.7020],
        [ -7.1664,  -2.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049728274345398
Epoch 0, Step 2588: train/loss = 0.03969411179423332, train/raw-loss = 0.009642641991376877, train/logprobs = tensor([[ -1.0906, -16.9690],
        [ -5.7744,  -3.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30051472783088684
Epoch 0, Step 2589: train/loss = 0.038264043629169464, train/raw-loss = 0.003953971900045872, train/logprobs = tensor([[ -1.2120, -15.4821],
        [ -6.9138,  -3.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431006669998169
Epoch 0, Step 2590: train/loss = 0.028912216424942017, train/raw-loss = 0.0013044498628005385, train/logprobs = tensor([[ -1.6827, -11.6591],
        [ -8.7951,  -1.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27607765793800354
Epoch 0, Step 2591: train/loss = 0.040089815855026245, train/raw-loss = 0.009863656014204025, train/logprobs = tensor([[-1.8489, -9.2218],
        [-5.8513, -1.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022615909576416
Epoch 0, Step 2592: train/loss = 0.03548093140125275, train/raw-loss = 0.0028747539035975933, train/logprobs = tensor([[ -1.7240, -10.5398],
        [ -7.3745,  -2.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32606178522109985
Epoch 0, Step 2593: train/loss = 0.03713776543736458, train/raw-loss = 0.009229709394276142, train/logprobs = tensor([[ -2.0747, -16.6421],
        [ -6.7992,  -3.3848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790805697441101
Epoch 0, Step 2594: train/loss = 0.041023120284080505, train/raw-loss = 0.012768509797751904, train/logprobs = tensor([[ -1.3227, -13.6901],
        [ -5.8045,  -2.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2825460731983185
Epoch 0, Step 2595: train/loss = 0.04153236746788025, train/raw-loss = 0.010429245419800282, train/logprobs = tensor([[ -1.8539, -12.9697],
        [ -7.1915,  -1.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3110312223434448
Epoch 0, Step 2596: train/loss = 0.03690779209136963, train/raw-loss = 0.0021617920137941837, train/logprobs = tensor([[ -1.4593, -18.9411],
        [ -8.0275,  -3.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34745997190475464
Epoch 0, Step 2597: train/loss = 0.03613169118762016, train/raw-loss = 0.0045363581739366055, train/logprobs = tensor([[ -1.3823, -16.2250],
        [ -7.3264,  -4.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159533143043518
Epoch 0, Step 2598: train/loss = 0.0405830442905426, train/raw-loss = 0.008323175832629204, train/logprobs = tensor([[ -1.4355, -11.2833],
        [ -6.6761,  -2.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225986659526825
Epoch 0, Step 2599: train/loss = 0.037213608622550964, train/raw-loss = 0.00338775385171175, train/logprobs = tensor([[ -1.6555, -15.6473],
        [ -7.2106,  -2.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3382585644721985
Epoch 0, Step 2600: train/loss = 0.041457585990428925, train/raw-loss = 0.013067209161818027, train/logprobs = tensor([[ -1.7336, -14.8694],
        [ -8.9618,  -2.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2839037775993347
Epoch 0, Step 2601: train/loss = 0.05448481813073158, train/raw-loss = 0.018753156065940857, train/logprobs = tensor([[ -1.6967, -13.2854],
        [ -6.6802,  -2.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35731661319732666
Epoch 0, Step 2602: train/loss = 0.036383725702762604, train/raw-loss = 0.006960572674870491, train/logprobs = tensor([[ -1.3000, -12.0979],
        [ -6.7166,  -3.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942315340042114
Epoch 0, Step 2603: train/loss = 0.05135374143719673, train/raw-loss = 0.023748718202114105, train/logprobs = tensor([[ -1.3231, -12.7282],
        [ -6.5291,  -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760502099990845
Epoch 0, Step 2604: train/loss = 0.03590859845280647, train/raw-loss = 0.0038404425140470266, train/logprobs = tensor([[ -1.2950, -19.5104],
        [ -7.4704,  -4.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3206815719604492
Epoch 0, Step 2605: train/loss = 0.07142871618270874, train/raw-loss = 0.04068262502551079, train/logprobs = tensor([[ -2.5568, -12.8670],
        [ -8.2360,  -2.3720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074609339237213
Epoch 0, Step 2606: train/loss = 0.034354884177446365, train/raw-loss = 0.0036560497246682644, train/logprobs = tensor([[ -1.1917, -18.1649],
        [ -8.9462,  -3.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30698832869529724
Epoch 0, Step 2607: train/loss = 0.03540320321917534, train/raw-loss = 0.003826236119493842, train/logprobs = tensor([[ -1.1429, -13.9960],
        [ -6.2377,  -1.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31576967239379883
Epoch 0, Step 2608: train/loss = 0.043863337486982346, train/raw-loss = 0.012424739077687263, train/logprobs = tensor([[ -1.0219, -13.7663],
        [ -5.6353,  -1.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31438595056533813
Epoch 0, Step 2609: train/loss = 0.035080425441265106, train/raw-loss = 0.0029480382800102234, train/logprobs = tensor([[ -1.6854, -14.5116],
        [ -7.9333,  -3.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32132384181022644
Epoch 0, Step 2610: train/loss = 0.03360532224178314, train/raw-loss = 0.0030429705511778593, train/logprobs = tensor([[ -1.7317, -14.8454],
        [ -7.7362,  -3.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30562353134155273
Epoch 0, Step 2611: train/loss = 0.03915882110595703, train/raw-loss = 0.010177841410040855, train/logprobs = tensor([[ -1.5341, -13.3448],
        [ -5.9186,  -2.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28980982303619385
Epoch 0, Step 2612: train/loss = 0.03291594237089157, train/raw-loss = 0.004285066854208708, train/logprobs = tensor([[ -1.0284, -11.1911],
        [ -6.2339,  -1.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28630876541137695
Epoch 0, Step 2613: train/loss = 0.04062630236148834, train/raw-loss = 0.01448837760835886, train/logprobs = tensor([[ -1.3152, -11.3931],
        [ -7.0583,  -2.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26137927174568176
Epoch 0, Step 2614: train/loss = 0.03151695057749748, train/raw-loss = 0.0010016538435593247, train/logprobs = tensor([[ -1.3534, -14.4179],
        [ -7.6323,  -2.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305152952671051
Epoch 0, Step 2615: train/loss = 0.031140465289354324, train/raw-loss = 0.0022371727973222733, train/logprobs = tensor([[ -1.1585, -18.6348],
        [ -7.0609,  -4.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890329360961914
Epoch 0, Step 2616: train/loss = 0.07407264411449432, train/raw-loss = 0.03738771378993988, train/logprobs = tensor([[-2.0414, -8.5742],
        [-8.0507, -1.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3668493330478668
Epoch 0, Step 2617: train/loss = 0.04211268201470375, train/raw-loss = 0.007610858418047428, train/logprobs = tensor([[ -1.1019, -12.6669],
        [ -6.1154,  -2.5105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3450182378292084
Epoch 0, Step 2618: train/loss = 0.03303675726056099, train/raw-loss = 0.002647633897140622, train/logprobs = tensor([[ -1.7115, -16.2720],
        [ -7.4419,  -2.5552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30389124155044556
Epoch 0, Step 2619: train/loss = 0.03765934705734253, train/raw-loss = 0.004031033255159855, train/logprobs = tensor([[ -1.3702, -12.4262],
        [ -6.3739,  -1.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362831473350525
Epoch 0, Step 2620: train/loss = 0.03856585547327995, train/raw-loss = 0.009222889319062233, train/logprobs = tensor([[ -1.6469, -14.0464],
        [ -6.5738,  -4.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2934296429157257
Epoch 0, Step 2621: train/loss = 0.032671671360731125, train/raw-loss = 0.004481105133891106, train/logprobs = tensor([[ -2.1155, -14.3627],
        [ -7.8596,  -1.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819056510925293
Epoch 0, Step 2622: train/loss = 0.07630006223917007, train/raw-loss = 0.049237389117479324, train/logprobs = tensor([[ -2.0314, -14.0335],
        [ -5.9552,  -1.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2706266939640045
Epoch 0, Step 2623: train/loss = 0.03409707546234131, train/raw-loss = 0.001996465725824237, train/logprobs = tensor([[ -1.3774, -13.7081],
        [ -7.9049,  -1.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32100605964660645
Epoch 0, Step 2624: train/loss = 0.0353270024061203, train/raw-loss = 0.004963759332895279, train/logprobs = tensor([[ -1.5371, -10.9777],
        [ -7.2863,  -1.7822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3036324381828308
Epoch 0, Step 2625: train/loss = 0.03293308988213539, train/raw-loss = 0.0033296849578619003, train/logprobs = tensor([[ -1.2706, -14.8416],
        [ -7.2787,  -1.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.296034038066864
Epoch 0, Step 2626: train/loss = 0.031430233269929886, train/raw-loss = 0.0004622277629096061, train/logprobs = tensor([[ -1.7085, -17.7370],
        [ -9.0823,  -2.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3096800744533539
Epoch 0, Step 2627: train/loss = 0.06909477710723877, train/raw-loss = 0.03797111660242081, train/logprobs = tensor([[ -2.3741, -17.3980],
        [ -7.1613,  -2.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31123659014701843
Epoch 0, Step 2628: train/loss = 0.03319749981164932, train/raw-loss = 0.005460110493004322, train/logprobs = tensor([[ -1.2033, -14.1566],
        [ -6.5155,  -2.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27737390995025635
Epoch 0, Step 2629: train/loss = 0.03334019333124161, train/raw-loss = 0.0027219296898692846, train/logprobs = tensor([[ -2.2024, -11.9894],
        [ -9.2844,  -2.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061825931072235
Epoch 0, Step 2630: train/loss = 0.034262288361787796, train/raw-loss = 0.002594410441815853, train/logprobs = tensor([[ -1.3403, -19.6243],
        [ -7.1057,  -3.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3166787624359131
Epoch 0, Step 2631: train/loss = 0.04040304571390152, train/raw-loss = 0.010050256736576557, train/logprobs = tensor([[ -1.5114, -12.5450],
        [ -6.7284,  -1.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035278916358948
Epoch 0, Step 2632: train/loss = 0.06073886528611183, train/raw-loss = 0.03256658837199211, train/logprobs = tensor([[ -1.3031, -11.1334],
        [ -5.7849,  -1.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817227840423584
Epoch 0, Step 2633: train/loss = 0.04846625030040741, train/raw-loss = 0.011357380077242851, train/logprobs = tensor([[ -1.4455, -12.4300],
        [ -8.7551,  -2.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3710886836051941
Epoch 0, Step 2634: train/loss = 0.03378592059016228, train/raw-loss = 0.002754970220848918, train/logprobs = tensor([[ -1.5231, -15.0242],
        [ -8.8614,  -2.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3103095293045044
Epoch 0, Step 2635: train/loss = 0.03447108715772629, train/raw-loss = 0.0003078219306189567, train/logprobs = tensor([[ -1.5455, -13.6185],
        [-10.4473,  -1.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3416326642036438
Epoch 0, Step 2636: train/loss = 0.04033172130584717, train/raw-loss = 0.008390594273805618, train/logprobs = tensor([[ -1.1033, -13.9832],
        [ -6.7133,  -3.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194112777709961
Epoch 0, Step 2637: train/loss = 0.034221380949020386, train/raw-loss = 0.0012077153660356998, train/logprobs = tensor([[ -1.1980, -15.9614],
        [ -7.3796,  -2.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33013659715652466
Epoch 0, Step 2638: train/loss = 0.03422199934720993, train/raw-loss = 0.0030772278551012278, train/logprobs = tensor([[ -1.2043, -22.6987],
        [ -8.6025,  -3.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31144770979881287
Epoch 0, Step 2639: train/loss = 0.03919925168156624, train/raw-loss = 0.00842602364718914, train/logprobs = tensor([[ -1.7400, -15.8577],
        [ -6.9762,  -2.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077322542667389
Epoch 0, Step 2640: train/loss = 0.03435829281806946, train/raw-loss = 0.004965971689671278, train/logprobs = tensor([[ -1.2504, -13.5191],
        [ -6.5399,  -2.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29392316937446594
Epoch 0, Step 2641: train/loss = 0.031127028167247772, train/raw-loss = 0.0011529072653502226, train/logprobs = tensor([[ -1.6224, -16.6510],
        [ -8.6884,  -4.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2997412085533142
Epoch 0, Step 2642: train/loss = 0.03647827357053757, train/raw-loss = 0.002331013325601816, train/logprobs = tensor([[ -1.5630, -14.7875],
        [ -7.7291,  -3.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3414725661277771
Epoch 0, Step 2643: train/loss = 0.03058471530675888, train/raw-loss = 0.0009261773666366935, train/logprobs = tensor([[ -2.1179, -12.6082],
        [ -9.6294,  -2.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965853810310364
Epoch 0, Step 2644: train/loss = 0.03263469040393829, train/raw-loss = 0.0069849262945353985, train/logprobs = tensor([[ -1.4113, -16.4140],
        [ -6.2065,  -2.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564976215362549
Epoch 0, Step 2645: train/loss = 0.03315217047929764, train/raw-loss = 0.0036922437138855457, train/logprobs = tensor([[ -1.6955, -10.7218],
        [ -8.0914,  -2.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945992350578308
Epoch 0, Step 2646: train/loss = 0.03481176495552063, train/raw-loss = 0.005503328982740641, train/logprobs = tensor([[ -1.1667, -15.7553],
        [ -6.9843,  -2.7678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29308435320854187
Epoch 0, Step 2647: train/loss = 0.04120233282446861, train/raw-loss = 0.008897687308490276, train/logprobs = tensor([[ -1.7838, -12.8100],
        [ -8.7043,  -2.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230464458465576
Epoch 0, Step 2648: train/loss = 0.043855220079422, train/raw-loss = 0.011212486773729324, train/logprobs = tensor([[ -0.9551, -13.7619],
        [ -6.3911,  -2.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32642731070518494
Epoch 0, Step 2649: train/loss = 0.035558070987463, train/raw-loss = 0.006965151987969875, train/logprobs = tensor([[ -1.4141, -14.6266],
        [ -7.2610,  -2.6147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2859291732311249
Epoch 0, Step 2650: train/loss = 0.031017739325761795, train/raw-loss = 0.0008954887744039297, train/logprobs = tensor([[ -2.1858, -16.0568],
        [ -9.9156,  -2.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012225031852722
Epoch 0, Step 2651: train/loss = 0.03425075113773346, train/raw-loss = 0.0025130650028586388, train/logprobs = tensor([[ -1.1982, -17.7149],
        [ -6.9784,  -3.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31737685203552246
Epoch 0, Step 2652: train/loss = 0.030613427981734276, train/raw-loss = 0.0016315922839567065, train/logprobs = tensor([[ -1.3200, -12.5749],
        [ -8.2969,  -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28981834650039673
Epoch 0, Step 2653: train/loss = 0.03672109916806221, train/raw-loss = 0.005192773416638374, train/logprobs = tensor([[ -1.4413, -15.1650],
        [ -7.3155,  -2.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31528323888778687
Epoch 0, Step 2654: train/loss = 0.03273789584636688, train/raw-loss = 0.002437847200781107, train/logprobs = tensor([[ -1.1712, -20.5844],
        [ -7.6417,  -3.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30300045013427734
Epoch 0, Step 2655: train/loss = 0.03145059198141098, train/raw-loss = 0.0034305278677493334, train/logprobs = tensor([[ -1.7444, -12.6420],
        [ -7.8597,  -1.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28020063042640686
Epoch 0, Step 2656: train/loss = 0.03758856654167175, train/raw-loss = 0.0074548264965415, train/logprobs = tensor([[ -0.9313, -11.4136],
        [ -5.9372,  -2.5029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013373613357544
Epoch 0, Step 2657: train/loss = 0.03336235508322716, train/raw-loss = 0.0019687723834067583, train/logprobs = tensor([[ -0.9077, -14.8997],
        [ -6.7223,  -1.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3139358460903168
Epoch 0, Step 2658: train/loss = 0.034052524715662, train/raw-loss = 0.0017777265748009086, train/logprobs = tensor([[ -1.2564, -11.0584],
        [ -8.0758,  -2.0418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32274797558784485
Epoch 0, Step 2659: train/loss = 0.04026538133621216, train/raw-loss = 0.010165578685700893, train/logprobs = tensor([[ -1.7456, -10.6979],
        [ -8.3477,  -3.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3009980022907257
Epoch 0, Step 2660: train/loss = 0.03552934527397156, train/raw-loss = 0.003720364533364773, train/logprobs = tensor([[ -1.0820, -15.5826],
        [ -7.8908,  -4.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3180897831916809
Epoch 0, Step 2661: train/loss = 0.03277216851711273, train/raw-loss = 0.001038622809574008, train/logprobs = tensor([[ -1.2422, -16.2766],
        [ -9.0145,  -4.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31733545660972595
Epoch 0, Step 2662: train/loss = 0.03377317637205124, train/raw-loss = 0.0023798635229468346, train/logprobs = tensor([[ -0.9026, -16.5386],
        [ -6.7003,  -3.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3139331340789795
Epoch 0, Step 2663: train/loss = 0.032270535826683044, train/raw-loss = 0.0012629168340936303, train/logprobs = tensor([[ -1.6704, -16.8872],
        [ -8.5133,  -4.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100762367248535
Epoch 0, Step 2664: train/loss = 0.0649966225028038, train/raw-loss = 0.03743954375386238, train/logprobs = tensor([[-1.7614, -9.6060],
        [-9.2868, -2.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.275570809841156
Epoch 0, Step 2665: train/loss = 0.03641072288155556, train/raw-loss = 0.0028719152323901653, train/logprobs = tensor([[ -1.7425, -11.3764],
        [ -8.3477,  -2.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33538809418678284
Epoch 0, Step 2666: train/loss = 0.03273801505565643, train/raw-loss = 0.0031583013478666544, train/logprobs = tensor([[ -1.7725, -14.0713],
        [ -9.2616,  -3.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957971692085266
Epoch 0, Step 2667: train/loss = 0.040205731987953186, train/raw-loss = 0.009284732863307, train/logprobs = tensor([[ -1.5046, -12.8179],
        [ -6.1750,  -3.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3092099726200104
Epoch 0, Step 2668: train/loss = 0.029361126944422722, train/raw-loss = 0.0013781439047306776, train/logprobs = tensor([[ -1.3707, -15.2847],
        [ -7.6278,  -2.3339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27982982993125916
Epoch 0, Step 2669: train/loss = 0.03664155304431915, train/raw-loss = 0.004049376584589481, train/logprobs = tensor([[ -0.9236, -14.1047],
        [ -6.6643,  -1.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32592177391052246
Epoch 0, Step 2670: train/loss = 0.03670667111873627, train/raw-loss = 0.0038068725261837244, train/logprobs = tensor([[ -1.0800, -17.4807],
        [ -6.3060,  -2.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32899799942970276
Epoch 0, Step 2671: train/loss = 0.034471023827791214, train/raw-loss = 0.0023695637937635183, train/logprobs = tensor([[ -1.0428, -15.6242],
        [ -7.3183,  -2.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210146129131317
Epoch 0, Step 2672: train/loss = 0.03170742839574814, train/raw-loss = 0.0006482499884441495, train/logprobs = tensor([[ -1.4181, -14.3108],
        [ -8.9347,  -1.3405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31059175729751587
Epoch 0, Step 2673: train/loss = 0.03405870124697685, train/raw-loss = 0.0029136487282812595, train/logprobs = tensor([[ -1.3115, -15.2152],
        [ -7.9153,  -3.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3114504814147949
Epoch 0, Step 2674: train/loss = 0.028846461325883865, train/raw-loss = 0.0007674344233237207, train/logprobs = tensor([[ -1.3251, -16.7230],
        [ -8.5445,  -2.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807902693748474
Epoch 0, Step 2675: train/loss = 0.07081812620162964, train/raw-loss = 0.037576597183942795, train/logprobs = tensor([[ -1.1600, -10.3588],
        [ -6.7512,  -2.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33241525292396545
Epoch 0, Step 2676: train/loss = 0.03259221464395523, train/raw-loss = 0.0008286285446956754, train/logprobs = tensor([[ -1.2605, -14.9093],
        [ -8.9198,  -2.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31763583421707153
Epoch 0, Step 2677: train/loss = 0.0337517112493515, train/raw-loss = 0.004270258825272322, train/logprobs = tensor([[ -1.2579, -12.1169],
        [ -6.9058,  -2.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2948145270347595
Epoch 0, Step 2678: train/loss = 0.03673982992768288, train/raw-loss = 0.0018839449621737003, train/logprobs = tensor([[ -1.2553, -14.5170],
        [ -7.9779,  -1.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34855884313583374
Epoch 0, Step 2679: train/loss = 0.04733065515756607, train/raw-loss = 0.01842373237013817, train/logprobs = tensor([[ -1.0411, -12.7706],
        [ -6.6086,  -2.8020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890692353248596
Epoch 0, Step 2680: train/loss = 0.03286729007959366, train/raw-loss = 0.0015160280745476484, train/logprobs = tensor([[ -1.2009, -12.9467],
        [ -7.3522,  -3.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3135126233100891
Epoch 0, Step 2681: train/loss = 0.035250063985586166, train/raw-loss = 0.0031273099593818188, train/logprobs = tensor([[ -1.3932, -12.1439],
        [ -8.8504,  -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3212275505065918
Epoch 0, Step 2682: train/loss = 0.03248994052410126, train/raw-loss = 0.0025650695897638798, train/logprobs = tensor([[ -1.0332, -14.9894],
        [ -7.2512,  -2.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29924875497817993
Epoch 0, Step 2683: train/loss = 0.029680170118808746, train/raw-loss = 0.0013180517125874758, train/logprobs = tensor([[ -1.9345, -18.1750],
        [ -8.9589,  -3.5897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2836211919784546
Epoch 0, Step 2684: train/loss = 0.03884416073560715, train/raw-loss = 0.002898360602557659, train/logprobs = tensor([[ -1.0934, -14.0064],
        [ -7.0075,  -2.2632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35945799946784973
Epoch 0, Step 2685: train/loss = 0.03388805687427521, train/raw-loss = 0.003553045680746436, train/logprobs = tensor([[ -1.1093, -13.0053],
        [ -7.6916,  -2.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033500909805298
Epoch 0, Step 2686: train/loss = 0.033776991069316864, train/raw-loss = 0.0059544919058680534, train/logprobs = tensor([[ -1.3558, -14.9883],
        [ -6.0939,  -2.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27822500467300415
Epoch 0, Step 2687: train/loss = 0.03163713216781616, train/raw-loss = 0.002935226308181882, train/logprobs = tensor([[ -1.2037, -18.3864],
        [ -6.9398,  -3.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870190441608429
Epoch 0, Step 2688: train/loss = 0.03740845248103142, train/raw-loss = 0.006683375686407089, train/logprobs = tensor([[ -1.3914, -11.6557],
        [ -6.8851,  -2.3386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3072507679462433
Epoch 0, Step 2689: train/loss = 0.03396139666438103, train/raw-loss = 0.0018395154038444161, train/logprobs = tensor([[ -1.5744, -11.9032],
        [ -9.0084,  -3.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3212188184261322
Epoch 0, Step 2690: train/loss = 0.029493127018213272, train/raw-loss = 0.0007357948925346136, train/logprobs = tensor([[ -1.2179, -15.4831],
        [ -8.0127,  -2.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28757333755493164
Epoch 0, Step 2691: train/loss = 0.03087534010410309, train/raw-loss = 0.00045889915782026947, train/logprobs = tensor([[ -1.9721, -18.1852],
        [-10.1683,  -3.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30416440963745117
Epoch 0, Step 2692: train/loss = 0.03189888596534729, train/raw-loss = 0.001353107625618577, train/logprobs = tensor([[ -1.1815, -15.9050],
        [ -8.5585,  -3.1651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30545780062675476
Epoch 0, Step 2693: train/loss = 0.02808551862835884, train/raw-loss = 0.0007006500964052975, train/logprobs = tensor([[ -1.2436, -15.1182],
        [ -8.7106,  -2.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27384868264198303
Epoch 0, Step 2694: train/loss = 0.03155551105737686, train/raw-loss = 0.0014213162939995527, train/logprobs = tensor([[ -1.4405, -14.7031],
        [ -8.6972,  -2.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013419508934021
Epoch 0, Step 2695: train/loss = 0.035773083567619324, train/raw-loss = 0.0021254420280456543, train/logprobs = tensor([[ -1.5053, -14.9144],
        [ -9.6367,  -2.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364764153957367
Epoch 0, Step 2696: train/loss = 0.03325413540005684, train/raw-loss = 0.0033076691906899214, train/logprobs = tensor([[ -1.1775, -13.2491],
        [ -6.8757,  -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994646430015564
Epoch 0, Step 2697: train/loss = 0.04705499857664108, train/raw-loss = 0.011523311026394367, train/logprobs = tensor([[ -1.2680, -11.3852],
        [ -7.0110,  -2.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553168773651123
Epoch 0, Step 2698: train/loss = 0.03833422809839249, train/raw-loss = 0.004556243307888508, train/logprobs = tensor([[ -1.3604, -11.3741],
        [ -7.4645,  -2.3495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3377798795700073
Epoch 0, Step 2699: train/loss = 0.03487028181552887, train/raw-loss = 0.0046643405221402645, train/logprobs = tensor([[ -1.6746, -11.7431],
        [ -7.6765,  -2.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020594120025635
Epoch 0, Step 2700: train/loss = 0.033714041113853455, train/raw-loss = 0.005076178815215826, train/logprobs = tensor([[ -1.1620, -12.9412],
        [ -8.2261,  -2.0539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863786220550537
Epoch 0, Step 2701: train/loss = 0.04728405922651291, train/raw-loss = 0.012011919170618057, train/logprobs = tensor([[ -1.4677, -11.9179],
        [ -9.5696,  -2.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35272136330604553
Epoch 0, Step 2702: train/loss = 0.03272321820259094, train/raw-loss = 0.0016484600491821766, train/logprobs = tensor([[ -1.6423, -13.8949],
        [ -9.4514,  -1.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31074756383895874
Epoch 0, Step 2703: train/loss = 0.03738095983862877, train/raw-loss = 0.007294731214642525, train/logprobs = tensor([[ -1.0722, -16.9139],
        [ -6.7743,  -2.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30086228251457214
Epoch 0, Step 2704: train/loss = 0.03186190500855446, train/raw-loss = 0.0010610915487632155, train/logprobs = tensor([[ -1.3462, -13.9771],
        [ -8.4764,  -2.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080081343650818
Epoch 0, Step 2705: train/loss = 0.030499666929244995, train/raw-loss = 0.0009297364158555865, train/logprobs = tensor([[ -1.2768, -14.1931],
        [ -8.2860,  -3.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956992983818054
Epoch 0, Step 2706: train/loss = 0.03547324985265732, train/raw-loss = 0.0011972803622484207, train/logprobs = tensor([[ -1.0698, -15.8855],
        [ -8.5744,  -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3427596986293793
Epoch 0, Step 2707: train/loss = 0.03524428978562355, train/raw-loss = 0.0020023181568831205, train/logprobs = tensor([[ -1.2159, -14.4413],
        [ -7.7850,  -2.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3324196934700012
Epoch 0, Step 2708: train/loss = 0.04181624576449394, train/raw-loss = 0.012854226864874363, train/logprobs = tensor([[ -1.3132, -18.2958],
        [ -7.2227,  -6.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28962019085884094
Epoch 0, Step 2709: train/loss = 0.032605089247226715, train/raw-loss = 0.0021576075814664364, train/logprobs = tensor([[ -1.4030, -12.4439],
        [ -8.0731,  -2.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30447477102279663
Epoch 0, Step 2710: train/loss = 0.03289530426263809, train/raw-loss = 0.0012315984349697828, train/logprobs = tensor([[ -1.4581, -17.8430],
        [ -8.3995,  -5.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3166370987892151
Epoch 0, Step 2711: train/loss = 0.03631652519106865, train/raw-loss = 0.00706780981272459, train/logprobs = tensor([[ -1.8937, -16.4755],
        [ -7.0056,  -4.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29248711466789246
Epoch 0, Step 2712: train/loss = 0.03705606609582901, train/raw-loss = 0.007959965616464615, train/logprobs = tensor([[ -1.4059, -12.2526],
        [ -6.7650,  -3.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29096099734306335
Epoch 0, Step 2713: train/loss = 0.032930970191955566, train/raw-loss = 0.004065477289259434, train/logprobs = tensor([[ -1.2952, -22.3465],
        [ -7.2442,  -5.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886549234390259
Epoch 0, Step 2714: train/loss = 0.030407950282096863, train/raw-loss = 0.0009915578411892056, train/logprobs = tensor([[ -1.7027, -15.4947],
        [ -8.9399,  -3.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29416394233703613
Epoch 0, Step 2715: train/loss = 0.052387937903404236, train/raw-loss = 0.018613668158650398, train/logprobs = tensor([[ -1.5502, -11.8058],
        [ -6.3591,  -1.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3377426862716675
Epoch 0, Step 2716: train/loss = 0.03240404650568962, train/raw-loss = 0.0004020282649435103, train/logprobs = tensor([[ -1.5590, -13.0405],
        [-10.1376,  -2.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200201988220215
Epoch 0, Step 2717: train/loss = 0.032911404967308044, train/raw-loss = 0.0021261561196297407, train/logprobs = tensor([[ -1.5577, -13.3359],
        [ -7.3561,  -1.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30785250663757324
Epoch 0, Step 2718: train/loss = 0.05498667061328888, train/raw-loss = 0.0260474756360054, train/logprobs = tensor([[ -1.3372, -19.9484],
        [ -6.7590,  -4.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893919348716736
Epoch 0, Step 2719: train/loss = 0.033203043043613434, train/raw-loss = 0.0009199466439895332, train/logprobs = tensor([[ -1.2315, -12.8624],
        [ -8.4907,  -2.5983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228309750556946
Epoch 0, Step 2720: train/loss = 0.03191858157515526, train/raw-loss = 0.004700572229921818, train/logprobs = tensor([[ -1.0957, -10.0670],
        [ -5.9481,  -2.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27218008041381836
Epoch 0, Step 2721: train/loss = 0.03364300727844238, train/raw-loss = 0.0017209146171808243, train/logprobs = tensor([[ -1.6354, -12.5316],
        [ -9.7757,  -2.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3192209303379059
Epoch 0, Step 2722: train/loss = 0.05732312053442001, train/raw-loss = 0.02742004580795765, train/logprobs = tensor([[ -3.5834, -10.4273],
        [ -8.2332,  -3.3354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29903072118759155
Epoch 0, Step 2723: train/loss = 0.03666847199201584, train/raw-loss = 0.002001060638576746, train/logprobs = tensor([[ -1.1482, -15.8319],
        [ -7.5321,  -3.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3466740846633911
Epoch 0, Step 2724: train/loss = 0.029751935973763466, train/raw-loss = 0.003308335319161415, train/logprobs = tensor([[ -1.0057, -19.4372],
        [ -6.1384,  -4.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644360065460205
Epoch 0, Step 2725: train/loss = 0.03065761923789978, train/raw-loss = 0.0007392316474579275, train/logprobs = tensor([[ -1.3829, -17.2095],
        [ -8.2759,  -3.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29918384552001953
Epoch 0, Step 2726: train/loss = 0.03208066523075104, train/raw-loss = 0.002605125308036804, train/logprobs = tensor([[ -1.1341, -15.0389],
        [ -6.8018,  -2.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29475539922714233
Epoch 0, Step 2727: train/loss = 0.03162116929888725, train/raw-loss = 0.0021606320515275, train/logprobs = tensor([[ -1.2460, -15.4243],
        [ -7.3358,  -4.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2946053445339203
Epoch 0, Step 2728: train/loss = 0.06183131784200668, train/raw-loss = 0.03216897323727608, train/logprobs = tensor([[ -1.2931, -10.3290],
        [ -6.6474,  -2.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966234087944031
Epoch 0, Step 2729: train/loss = 0.03288271278142929, train/raw-loss = 0.0015608652029186487, train/logprobs = tensor([[ -1.1028, -13.9774],
        [ -6.9405,  -3.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31321847438812256
Epoch 0, Step 2730: train/loss = 0.0401662178337574, train/raw-loss = 0.012139664962887764, train/logprobs = tensor([[ -1.0744, -14.4930],
        [ -5.6952,  -4.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28026553988456726
Epoch 0, Step 2731: train/loss = 0.03175080567598343, train/raw-loss = 0.0011189316865056753, train/logprobs = tensor([[ -1.0827, -14.2191],
        [ -7.2867,  -3.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3063187301158905
Epoch 0, Step 2732: train/loss = 0.035273365676403046, train/raw-loss = 0.00489549245685339, train/logprobs = tensor([[ -1.2221, -17.9721],
        [ -8.8665,  -3.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3037787079811096
Epoch 0, Step 2733: train/loss = 0.03349723666906357, train/raw-loss = 0.0042189029045403, train/logprobs = tensor([[ -1.4128, -18.8506],
        [ -9.3276,  -4.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29278331995010376
Epoch 0, Step 2734: train/loss = 0.04861465469002724, train/raw-loss = 0.009813116863369942, train/logprobs = tensor([[ -1.4283, -11.5014],
        [-10.5857,  -2.4300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3880153298377991
Epoch 0, Step 2735: train/loss = 0.03686201572418213, train/raw-loss = 0.0014092212077230215, train/logprobs = tensor([[ -1.0961, -14.8955],
        [ -7.5239,  -2.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35452795028686523
Epoch 0, Step 2736: train/loss = 0.03578847646713257, train/raw-loss = 0.004569173790514469, train/logprobs = tensor([[ -1.3737, -14.4313],
        [ -6.9796,  -3.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31219303607940674
Epoch 0, Step 2737: train/loss = 0.03456033021211624, train/raw-loss = 0.006707516498863697, train/logprobs = tensor([[ -1.1831, -11.5881],
        [ -7.4529,  -1.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785281538963318
Epoch 0, Step 2738: train/loss = 0.03137083351612091, train/raw-loss = 0.0016317586414515972, train/logprobs = tensor([[ -1.3662, -14.6316],
        [ -8.9363,  -4.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29739072918891907
Epoch 0, Step 2739: train/loss = 0.04740431532263756, train/raw-loss = 0.01307098288089037, train/logprobs = tensor([[ -0.9888, -10.0105],
        [ -6.5869,  -2.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34333333373069763
Epoch 0, Step 2740: train/loss = 0.03593505173921585, train/raw-loss = 0.001478513702750206, train/logprobs = tensor([[ -1.2507, -12.3959],
        [ -8.4209,  -1.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34456536173820496
Epoch 0, Step 2741: train/loss = 0.03460824489593506, train/raw-loss = 0.0006352692726068199, train/logprobs = tensor([[ -1.2805, -17.1184],
        [ -8.1392,  -3.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33972975611686707
Epoch 0, Step 2742: train/loss = 0.038056667894124985, train/raw-loss = 0.006468211300671101, train/logprobs = tensor([[ -1.1803, -16.2168],
        [ -8.9132,  -3.8785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158845603466034
Epoch 0, Step 2743: train/loss = 0.03202958405017853, train/raw-loss = 0.0012219308409839869, train/logprobs = tensor([[ -1.1256, -15.9610],
        [ -7.6664,  -4.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30807653069496155
Epoch 0, Step 2744: train/loss = 0.033021166920661926, train/raw-loss = 0.0021014558151364326, train/logprobs = tensor([[ -1.5917, -18.2709],
        [ -9.0295,  -2.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3091971278190613
Epoch 0, Step 2745: train/loss = 0.03555700182914734, train/raw-loss = 0.0007534106262028217, train/logprobs = tensor([[ -1.1524, -16.0047],
        [ -8.3789,  -2.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34803593158721924
Epoch 0, Step 2746: train/loss = 0.03382223844528198, train/raw-loss = 0.0019317860715091228, train/logprobs = tensor([[ -1.1601, -14.1272],
        [ -7.2753,  -2.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3189045190811157
Epoch 0, Step 2747: train/loss = 0.0313798263669014, train/raw-loss = 0.0014809031272307038, train/logprobs = tensor([[ -1.0159, -14.1890],
        [ -8.0095,  -3.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989892065525055
Epoch 0, Step 2748: train/loss = 0.049810390919446945, train/raw-loss = 0.020918577909469604, train/logprobs = tensor([[ -2.1919, -11.2435],
        [ -8.7581,  -2.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889181077480316
Epoch 0, Step 2749: train/loss = 0.03068726137280464, train/raw-loss = 0.0019504386000335217, train/logprobs = tensor([[ -1.2649, -17.1237],
        [ -7.5558,  -4.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28736820816993713
Epoch 0, Step 2750: train/loss = 0.03307269886136055, train/raw-loss = 0.002253054641187191, train/logprobs = tensor([[ -0.9412, -15.6671],
        [ -6.4686,  -3.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30819642543792725
Epoch 0, Step 2751: train/loss = 0.03576071560382843, train/raw-loss = 0.008277984336018562, train/logprobs = tensor([[ -1.5554, -16.6981],
        [ -6.6515,  -4.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748273015022278
Epoch 0, Step 2752: train/loss = 0.0435001477599144, train/raw-loss = 0.009477163664996624, train/logprobs = tensor([[ -1.5445, -10.0312],
        [ -8.6959,  -2.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3402298390865326
Epoch 0, Step 2753: train/loss = 0.04990657418966293, train/raw-loss = 0.017451047897338867, train/logprobs = tensor([[-1.6075, -8.5091],
        [-7.3272, -1.6169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32455524802207947
Epoch 0, Step 2754: train/loss = 0.02990599535405636, train/raw-loss = 0.0020028087310492992, train/logprobs = tensor([[ -1.6582, -11.6859],
        [ -8.8707,  -1.5930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790318727493286
Epoch 0, Step 2755: train/loss = 0.0267030019313097, train/raw-loss = 0.0008026466821320355, train/logprobs = tensor([[ -1.2073, -15.9013],
        [ -8.5253,  -4.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25900354981422424
Epoch 0, Step 2756: train/loss = 0.03131599351763725, train/raw-loss = 0.000489511527121067, train/logprobs = tensor([[ -1.1084, -18.2394],
        [ -8.5583,  -4.3086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308264821767807
Epoch 0, Step 2757: train/loss = 0.03067026659846306, train/raw-loss = 0.003613486886024475, train/logprobs = tensor([[ -1.1084, -14.9341],
        [ -7.1228,  -2.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27056777477264404
Epoch 0, Step 2758: train/loss = 0.030996089801192284, train/raw-loss = 0.0012461935402825475, train/logprobs = tensor([[ -1.1671, -15.6901],
        [ -7.5221,  -3.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2974989712238312
Epoch 0, Step 2759: train/loss = 0.03320157900452614, train/raw-loss = 0.0022790536750108004, train/logprobs = tensor([[ -1.2120, -17.8206],
        [ -8.8206,  -4.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3092252314090729
Epoch 0, Step 2760: train/loss = 0.0550159253180027, train/raw-loss = 0.024205192923545837, train/logprobs = tensor([[ -2.0315, -14.7732],
        [ -9.6648,  -1.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30810731649398804
Epoch 0, Step 2761: train/loss = 0.049894753843545914, train/raw-loss = 0.01680651120841503, train/logprobs = tensor([[ -1.2854, -10.7797],
        [ -8.8890,  -2.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3308824300765991
Epoch 0, Step 2762: train/loss = 0.04328879714012146, train/raw-loss = 0.0012955745914950967, train/logprobs = tensor([[ -1.3527, -13.8020],
        [ -8.9033,  -2.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4199322462081909
Epoch 0, Step 2763: train/loss = 0.03020194172859192, train/raw-loss = 0.00027671889984048903, train/logprobs = tensor([[ -1.6711, -13.7038],
        [-10.4223,  -2.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992522418498993
Epoch 0, Step 2764: train/loss = 0.04034293070435524, train/raw-loss = 0.0071296244859695435, train/logprobs = tensor([[ -0.9682, -12.1916],
        [ -6.9081,  -2.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33213305473327637
Epoch 0, Step 2765: train/loss = 0.03601859137415886, train/raw-loss = 0.0027348115108907223, train/logprobs = tensor([[ -1.4211, -11.5276],
        [ -7.7563,  -2.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3328377902507782
Epoch 0, Step 2766: train/loss = 0.03884434327483177, train/raw-loss = 0.004975416231900454, train/logprobs = tensor([[ -1.1757, -10.7392],
        [ -7.6332,  -2.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33868923783302307
Epoch 0, Step 2767: train/loss = 0.03653044253587723, train/raw-loss = 0.0006728401640430093, train/logprobs = tensor([[ -0.8739, -15.0236],
        [ -7.8867,  -3.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3585759997367859
Epoch 0, Step 2768: train/loss = 0.03548238426446915, train/raw-loss = 0.001340747345238924, train/logprobs = tensor([[ -0.7952, -15.8629],
        [ -7.8112,  -2.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3414163589477539
Epoch 0, Step 2769: train/loss = 0.03338638320565224, train/raw-loss = 0.0012776985531672835, train/logprobs = tensor([[ -1.2794, -15.8284],
        [ -8.0126,  -3.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210868239402771
Epoch 0, Step 2770: train/loss = 0.027220765128731728, train/raw-loss = 0.0012188730761408806, train/logprobs = tensor([[ -1.2453, -10.9957],
        [ -7.5275,  -1.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260018914937973
Epoch 0, Step 2771: train/loss = 0.03681263327598572, train/raw-loss = 0.0024933847598731518, train/logprobs = tensor([[ -0.9393, -16.7093],
        [ -6.8185,  -2.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3431924879550934
Epoch 0, Step 2772: train/loss = 0.03543630242347717, train/raw-loss = 0.006535081192851067, train/logprobs = tensor([[ -1.1980, -12.3255],
        [ -7.0008,  -4.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28901219367980957
Epoch 0, Step 2773: train/loss = 0.035428550094366074, train/raw-loss = 0.0016359344590455294, train/logprobs = tensor([[ -1.7468, -11.7621],
        [ -9.9593,  -2.7337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33792614936828613
Epoch 0, Step 2774: train/loss = 0.029661936685442924, train/raw-loss = 0.0027254116721451283, train/logprobs = tensor([[ -1.8622, -14.5242],
        [ -7.4201,  -4.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26936522126197815
Epoch 0, Step 2775: train/loss = 0.03531644493341446, train/raw-loss = 0.0012934405822306871, train/logprobs = tensor([[ -1.3418, -12.9037],
        [ -9.4641,  -2.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3402300477027893
Epoch 0, Step 2776: train/loss = 0.04447595030069351, train/raw-loss = 0.01018830668181181, train/logprobs = tensor([[ -1.2448, -13.6091],
        [ -7.1866,  -3.2784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3428764343261719
Epoch 0, Step 2777: train/loss = 0.03435683250427246, train/raw-loss = 0.0008881661342456937, train/logprobs = tensor([[ -1.2352, -14.3206],
        [ -8.0469,  -3.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33468666672706604
Epoch 0, Step 2778: train/loss = 0.03683619573712349, train/raw-loss = 0.004304062109440565, train/logprobs = tensor([[ -0.8927, -13.3413],
        [ -5.9918,  -2.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253213167190552
Epoch 0, Step 2779: train/loss = 0.037436459213495255, train/raw-loss = 0.002676593139767647, train/logprobs = tensor([[ -1.0018, -13.6599],
        [ -8.1520,  -2.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3475986421108246
Epoch 0, Step 2780: train/loss = 0.034056808799505234, train/raw-loss = 0.0031560645438730717, train/logprobs = tensor([[ -1.2761, -12.8241],
        [ -7.8965,  -3.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090074062347412
Epoch 0, Step 2781: train/loss = 0.03298404440283775, train/raw-loss = 0.0008928986499086022, train/logprobs = tensor([[ -1.1711, -17.8744],
        [ -8.1440,  -3.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3209114670753479
Epoch 0, Step 2782: train/loss = 0.032685719430446625, train/raw-loss = 0.003454721299931407, train/logprobs = tensor([[ -1.1312, -14.9035],
        [ -6.9209,  -2.5284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29230996966362
Epoch 0, Step 2783: train/loss = 0.03404368460178375, train/raw-loss = 0.0015366278821602464, train/logprobs = tensor([[ -1.3193, -13.9745],
        [ -8.3732,  -2.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250705599784851
Epoch 0, Step 2784: train/loss = 0.03465602919459343, train/raw-loss = 0.0007060727803036571, train/logprobs = tensor([[ -1.6230, -15.6519],
        [ -8.9997,  -2.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3394995927810669
Epoch 0, Step 2785: train/loss = 0.03357735648751259, train/raw-loss = 0.0008893742924556136, train/logprobs = tensor([[ -1.3212, -13.9879],
        [ -8.1914,  -2.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3268797993659973
Epoch 0, Step 2786: train/loss = 0.03234684467315674, train/raw-loss = 0.002028499497100711, train/logprobs = tensor([[ -1.1586, -16.6724],
        [ -7.9452,  -5.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031834363937378
Epoch 0, Step 2787: train/loss = 0.03891359642148018, train/raw-loss = 0.006120547652244568, train/logprobs = tensor([[ -0.7455, -14.1234],
        [ -7.5761,  -3.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3279304802417755
Epoch 0, Step 2788: train/loss = 0.03145577758550644, train/raw-loss = 0.0032573265489190817, train/logprobs = tensor([[ -1.0689, -12.7077],
        [ -7.0465,  -2.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28198450803756714
Epoch 0, Step 2789: train/loss = 0.031753599643707275, train/raw-loss = 0.0010461265919730067, train/logprobs = tensor([[ -1.1538, -13.5484],
        [ -8.8090,  -3.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30707472562789917
Epoch 0, Step 2790: train/loss = 0.030547404661774635, train/raw-loss = 0.0030244693625718355, train/logprobs = tensor([[ -1.3429, -15.3913],
        [ -8.3927,  -2.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752293348312378
Epoch 0, Step 2791: train/loss = 0.031229931861162186, train/raw-loss = 0.002068697940558195, train/logprobs = tensor([[ -1.0005, -13.1345],
        [ -6.6909,  -2.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29161232709884644
Epoch 0, Step 2792: train/loss = 0.05273352935910225, train/raw-loss = 0.024906577542424202, train/logprobs = tensor([[ -1.0295, -10.0529],
        [ -5.3811,  -1.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27826952934265137
Epoch 0, Step 2793: train/loss = 0.03547918424010277, train/raw-loss = 0.002639967715367675, train/logprobs = tensor([[ -0.9850, -14.8246],
        [ -7.7144,  -2.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283921480178833
Epoch 0, Step 2794: train/loss = 0.06264656782150269, train/raw-loss = 0.034183308482170105, train/logprobs = tensor([[ -1.3277, -13.5519],
        [ -8.8601,  -3.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846326231956482
Epoch 0, Step 2795: train/loss = 0.034957390278577805, train/raw-loss = 0.0031376145780086517, train/logprobs = tensor([[ -1.0880, -13.3388],
        [ -6.3624,  -2.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31819775700569153
Epoch 0, Step 2796: train/loss = 0.033457204699516296, train/raw-loss = 0.001094594830647111, train/logprobs = tensor([[ -1.0152, -11.2907],
        [ -7.8767,  -1.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236261010169983
Epoch 0, Step 2797: train/loss = 0.03921658545732498, train/raw-loss = 0.004159162752330303, train/logprobs = tensor([[ -1.0194, -13.5431],
        [ -7.1005,  -3.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.350574254989624
Epoch 0, Step 2798: train/loss = 0.029338989406824112, train/raw-loss = 0.0023917583748698235, train/logprobs = tensor([[ -1.3100, -14.5104],
        [ -7.4281,  -1.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2694723308086395
Epoch 0, Step 2799: train/loss = 0.03673618286848068, train/raw-loss = 0.00673055462539196, train/logprobs = tensor([[ -1.0851, -12.5984],
        [ -7.2105,  -3.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3000563085079193
Epoch 0, Step 2800: train/loss = 0.03711504489183426, train/raw-loss = 0.006985410116612911, train/logprobs = tensor([[ -1.0340, -13.8597],
        [ -7.5540,  -2.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012963533401489
Epoch 0, Step 2801: train/loss = 0.030978858470916748, train/raw-loss = 0.00221568183042109, train/logprobs = tensor([[ -1.6334, -14.7181],
        [ -7.9163,  -3.0057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876317501068115
Epoch 0, Step 2802: train/loss = 0.0451577827334404, train/raw-loss = 0.014202854596078396, train/logprobs = tensor([[ -1.1394, -11.0016],
        [ -8.0895,  -2.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3095492720603943
Epoch 0, Step 2803: train/loss = 0.03024866059422493, train/raw-loss = 0.005060551222413778, train/logprobs = tensor([[ -1.2366, -16.5094],
        [ -8.4625,  -3.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25188109278678894
Epoch 0, Step 2804: train/loss = 0.03749527782201767, train/raw-loss = 0.002485098550096154, train/logprobs = tensor([[ -1.4353, -12.8594],
        [ -8.4908,  -3.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3501017987728119
Epoch 0, Step 2805: train/loss = 0.03761612996459007, train/raw-loss = 0.008530044928193092, train/logprobs = tensor([[ -1.7105, -13.9117],
        [ -7.8972,  -3.0107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2908608317375183
Epoch 0, Step 2806: train/loss = 0.033208511769771576, train/raw-loss = 0.005353650078177452, train/logprobs = tensor([[ -1.2783, -11.7014],
        [ -8.5890,  -2.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27854859828948975
Epoch 0, Step 2807: train/loss = 0.034886766225099564, train/raw-loss = 0.008651157841086388, train/logprobs = tensor([[ -1.7270, -12.6944],
        [ -7.3461,  -2.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26235607266426086
Epoch 0, Step 2808: train/loss = 0.03204704448580742, train/raw-loss = 0.0008362269145436585, train/logprobs = tensor([[ -1.4956, -16.1738],
        [ -9.0155,  -2.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121081590652466
Epoch 0, Step 2809: train/loss = 0.03652733191847801, train/raw-loss = 0.0032314821146428585, train/logprobs = tensor([[ -1.0371, -12.9794],
        [ -7.2881,  -1.9805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33295848965644836
Epoch 0, Step 2810: train/loss = 0.03205657750368118, train/raw-loss = 0.0009257743950001895, train/logprobs = tensor([[ -1.2336, -15.9121],
        [ -8.0196,  -2.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31130802631378174
Epoch 0, Step 2811: train/loss = 0.03397374227643013, train/raw-loss = 0.004817586857825518, train/logprobs = tensor([[ -1.0327, -12.1475],
        [ -6.9467,  -2.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2915615737438202
Epoch 0, Step 2812: train/loss = 0.03172573447227478, train/raw-loss = 0.00047704362077638507, train/logprobs = tensor([[ -1.4184, -14.5470],
        [-10.7126,  -3.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3124868869781494
Epoch 0, Step 2813: train/loss = 0.03170425072312355, train/raw-loss = 0.0005372903542593122, train/logprobs = tensor([[ -1.1528, -17.1959],
        [ -9.1842,  -3.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31166958808898926
Epoch 0, Step 2814: train/loss = 0.03107420541346073, train/raw-loss = 0.00681134220212698, train/logprobs = tensor([[ -0.9866, -11.7843],
        [ -6.7517,  -2.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24262863397598267
Epoch 0, Step 2815: train/loss = 0.03623528033494949, train/raw-loss = 0.00474696746096015, train/logprobs = tensor([[ -1.0956, -11.6363],
        [ -6.5519,  -2.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31488314270973206
Epoch 0, Step 2816: train/loss = 0.08845960348844528, train/raw-loss = 0.058296095579862595, train/logprobs = tensor([[-1.5522, -8.7380],
        [-8.3056, -3.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30163511633872986
Epoch 0, Step 2817: train/loss = 0.06661933660507202, train/raw-loss = 0.03602041304111481, train/logprobs = tensor([[ -0.7746, -10.7235],
        [ -5.8662,  -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30598926544189453
Epoch 0, Step 2818: train/loss = 0.031385637819767, train/raw-loss = 0.0014387533301487565, train/logprobs = tensor([[ -1.5555, -16.4657],
        [ -9.8282,  -2.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29946884512901306
Epoch 0, Step 2819: train/loss = 0.03447524458169937, train/raw-loss = 0.0008766121463850141, train/logprobs = tensor([[ -1.7678, -12.5509],
        [-10.1169,  -2.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33598631620407104
Epoch 0, Step 2820: train/loss = 0.033602695912122726, train/raw-loss = 0.004807618912309408, train/logprobs = tensor([[ -1.0994, -10.8126],
        [ -7.6381,  -2.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879507839679718
Epoch 0, Step 2821: train/loss = 0.03560348600149155, train/raw-loss = 0.0008582717273384333, train/logprobs = tensor([[ -1.5293, -11.3726],
        [-11.4355,  -2.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3474521338939667
Epoch 0, Step 2822: train/loss = 0.0305190309882164, train/raw-loss = 0.0006288325530476868, train/logprobs = tensor([[ -1.3912, -13.2674],
        [ -9.1052,  -2.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989019751548767
Epoch 0, Step 2823: train/loss = 0.034479495137929916, train/raw-loss = 0.0006606146926060319, train/logprobs = tensor([[ -1.2076, -15.2999],
        [ -9.1200,  -3.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3381887972354889
Epoch 0, Step 2824: train/loss = 0.028661638498306274, train/raw-loss = 0.0005342843942344189, train/logprobs = tensor([[ -1.6782, -13.9685],
        [-10.6403,  -4.2784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812735438346863
Epoch 0, Step 2825: train/loss = 0.032357070595026016, train/raw-loss = 0.004172971937805414, train/logprobs = tensor([[ -1.0152, -14.4871],
        [ -8.5455,  -4.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281840980052948
Epoch 0, Step 2826: train/loss = 0.03141818195581436, train/raw-loss = 0.0010576345957815647, train/logprobs = tensor([[ -1.1844, -11.8197],
        [ -9.3832,  -2.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30360546708106995
Epoch 0, Step 2827: train/loss = 0.03117351606488228, train/raw-loss = 0.0004020982305519283, train/logprobs = tensor([[ -1.2425, -13.2687],
        [ -9.0785,  -1.7752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30771416425704956
Epoch 0, Step 2828: train/loss = 0.030973341315984726, train/raw-loss = 0.0030694359447807074, train/logprobs = tensor([[ -1.0478, -11.7891],
        [ -7.4452,  -2.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27903902530670166
Epoch 0, Step 2829: train/loss = 0.03220576047897339, train/raw-loss = 0.0019808600191026926, train/logprobs = tensor([[ -1.1696, -17.9935],
        [ -7.9892,  -5.3855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.302249014377594
Epoch 0, Step 2830: train/loss = 0.028704136610031128, train/raw-loss = 0.001427979557774961, train/logprobs = tensor([[ -1.4369, -12.5102],
        [ -8.5806,  -2.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27276158332824707
Epoch 0, Step 2831: train/loss = 0.03399992361664772, train/raw-loss = 0.0013728279154747725, train/logprobs = tensor([[ -0.8767, -12.6515],
        [ -7.0745,  -2.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262709677219391
Epoch 0, Step 2832: train/loss = 0.033746302127838135, train/raw-loss = 0.0007460360648110509, train/logprobs = tensor([[ -0.9887, -11.0354],
        [ -8.2425,  -1.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33000266551971436
Epoch 0, Step 2833: train/loss = 0.03126736357808113, train/raw-loss = 0.0015198583714663982, train/logprobs = tensor([[ -1.2464, -12.2223],
        [ -8.7238,  -2.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29747503995895386
Epoch 0, Step 2834: train/loss = 0.03286648541688919, train/raw-loss = 0.0010841225739568472, train/logprobs = tensor([[ -1.1916, -12.7177],
        [ -8.2427,  -2.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317823588848114
Epoch 0, Step 2835: train/loss = 0.031841155141592026, train/raw-loss = 0.0032558985985815525, train/logprobs = tensor([[ -1.0888, -14.7391],
        [ -8.6805,  -3.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2858525812625885
Epoch 0, Step 2836: train/loss = 0.03211835026741028, train/raw-loss = 0.0011693439446389675, train/logprobs = tensor([[ -1.2548, -12.6250],
        [ -9.8807,  -3.5168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094900846481323
Epoch 0, Step 2837: train/loss = 0.030343331396579742, train/raw-loss = 0.0027710222639143467, train/logprobs = tensor([[ -1.9648, -11.2810],
        [-10.0895,  -3.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27572309970855713
Epoch 0, Step 2838: train/loss = 0.07099677622318268, train/raw-loss = 0.040372397750616074, train/logprobs = tensor([[ -1.2989, -10.8764],
        [ -7.6975,  -3.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30624374747276306
Epoch 0, Step 2839: train/loss = 0.045240454375743866, train/raw-loss = 0.012637266889214516, train/logprobs = tensor([[ -0.8033, -11.4910],
        [ -7.2770,  -2.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3260318636894226
Epoch 0, Step 2840: train/loss = 0.030129926279187202, train/raw-loss = 0.0003094469429925084, train/logprobs = tensor([[ -1.5976, -18.5852],
        [-10.0198,  -3.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29820477962493896
Epoch 0, Step 2841: train/loss = 0.0353282168507576, train/raw-loss = 0.006397893652319908, train/logprobs = tensor([[ -1.2271, -15.6798],
        [ -8.0878,  -3.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893032431602478
Epoch 0, Step 2842: train/loss = 0.03545508161187172, train/raw-loss = 0.0037801950238645077, train/logprobs = tensor([[ -1.2994, -10.3746],
        [-10.9140,  -2.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31674885749816895
Epoch 0, Step 2843: train/loss = 0.030921198427677155, train/raw-loss = 0.00037530448753386736, train/logprobs = tensor([[ -1.3212, -14.1191],
        [ -8.6847,  -2.6242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3054589331150055
Epoch 0, Step 2844: train/loss = 0.03199370577931404, train/raw-loss = 0.0023171440698206425, train/logprobs = tensor([[ -1.5427, -14.5658],
        [ -7.6585,  -2.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29676562547683716
Epoch 0, Step 2845: train/loss = 0.03094945102930069, train/raw-loss = 0.00023540975234936923, train/logprobs = tensor([[ -1.2054, -14.9594],
        [ -8.9982,  -2.6907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30714040994644165
Epoch 0, Step 2846: train/loss = 0.03455179184675217, train/raw-loss = 0.004425066523253918, train/logprobs = tensor([[ -1.4063, -12.9134],
        [ -7.7840,  -3.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012672960758209
Epoch 0, Step 2847: train/loss = 0.030386075377464294, train/raw-loss = 0.00043726959847845137, train/logprobs = tensor([[ -0.9815, -13.3739],
        [ -8.6878,  -3.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29948803782463074
Epoch 0, Step 2848: train/loss = 0.02791423909366131, train/raw-loss = 0.0016040008049458265, train/logprobs = tensor([[ -1.5911, -20.0357],
        [-10.0280,  -5.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26310235261917114
Epoch 0, Step 2849: train/loss = 0.030733315274119377, train/raw-loss = 0.0015451250365003943, train/logprobs = tensor([[ -1.0248, -13.9546],
        [ -8.3559,  -3.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2918819189071655
Epoch 0, Step 2850: train/loss = 0.03127618879079819, train/raw-loss = 0.00046853371895849705, train/logprobs = tensor([[ -1.1867, -14.7887],
        [ -9.2264,  -2.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30807653069496155
Epoch 0, Step 2851: train/loss = 0.029243677854537964, train/raw-loss = 0.0026652913074940443, train/logprobs = tensor([[-1.0074, -7.9207],
        [-6.6756, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657838761806488
Epoch 0, Step 2852: train/loss = 0.03503305837512016, train/raw-loss = 0.0096999267116189, train/logprobs = tensor([[ -1.0733, -12.5242],
        [ -6.4522,  -1.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533313035964966
Epoch 0, Step 2853: train/loss = 0.03146214038133621, train/raw-loss = 0.0008937357342801988, train/logprobs = tensor([[ -0.9699, -11.2180],
        [ -8.4252,  -2.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30568405985832214
Epoch 0, Step 2854: train/loss = 0.03900827467441559, train/raw-loss = 0.0021323664113879204, train/logprobs = tensor([[ -1.1030, -13.1462],
        [ -7.7070,  -2.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3687590956687927
Epoch 0, Step 2855: train/loss = 0.03611985221505165, train/raw-loss = 0.0045542120933532715, train/logprobs = tensor([[ -0.9528, -11.2090],
        [ -6.4624,  -2.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156563937664032
Epoch 0, Step 2856: train/loss = 0.03005373477935791, train/raw-loss = 0.0013205738505348563, train/logprobs = tensor([[ -1.2903, -17.2162],
        [ -7.5458,  -3.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28733164072036743
Epoch 0, Step 2857: train/loss = 0.03038540482521057, train/raw-loss = 0.0005460042739287019, train/logprobs = tensor([[ -1.3391, -16.6447],
        [ -9.4681,  -3.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29839402437210083
Epoch 0, Step 2858: train/loss = 0.030406635254621506, train/raw-loss = 0.0006620804779231548, train/logprobs = tensor([[ -0.9258, -16.0351],
        [ -7.8839,  -4.4764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29744553565979004
Epoch 0, Step 2859: train/loss = 0.028017960488796234, train/raw-loss = 0.0015321793034672737, train/logprobs = tensor([[ -1.2618, -17.2024],
        [ -8.1749,  -3.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26485782861709595
Epoch 0, Step 2860: train/loss = 0.03323182091116905, train/raw-loss = 0.003740189364179969, train/logprobs = tensor([[ -1.3147, -11.4601],
        [ -7.4688,  -2.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2949163317680359
Epoch 0, Step 2861: train/loss = 0.02796684205532074, train/raw-loss = 0.001627773162908852, train/logprobs = tensor([[ -1.2276, -18.1802],
        [ -7.0254,  -4.3432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633906602859497
Epoch 0, Step 2862: train/loss = 0.031998906284570694, train/raw-loss = 0.0022481444757431746, train/logprobs = tensor([[ -1.2497, -13.1181],
        [ -9.5028,  -3.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297507643699646
Epoch 0, Step 2863: train/loss = 0.0367441400885582, train/raw-loss = 0.002536401152610779, train/logprobs = tensor([[ -0.9074, -15.4084],
        [ -7.1016,  -3.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3420774042606354
Epoch 0, Step 2864: train/loss = 0.027983060106635094, train/raw-loss = 0.0020109894685447216, train/logprobs = tensor([[ -1.1675, -10.9899],
        [ -7.5851,  -2.5297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25972068309783936
Epoch 0, Step 2865: train/loss = 0.031898606568574905, train/raw-loss = 0.0019590877927839756, train/logprobs = tensor([[ -1.0611, -14.8424],
        [ -7.0513,  -3.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2993951737880707
Epoch 0, Step 2866: train/loss = 0.03380265831947327, train/raw-loss = 0.0017277359729632735, train/logprobs = tensor([[ -1.2695, -10.4283],
        [ -8.8093,  -2.3371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3207492232322693
Epoch 0, Step 2867: train/loss = 0.03628689795732498, train/raw-loss = 0.0026214749086648226, train/logprobs = tensor([[ -0.9483, -11.4124],
        [ -8.2112,  -2.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3366542458534241
Epoch 0, Step 2868: train/loss = 0.03328460454940796, train/raw-loss = 0.0011396384797990322, train/logprobs = tensor([[ -1.0383, -18.3610],
        [ -7.3930,  -2.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3214496672153473
Epoch 0, Step 2869: train/loss = 0.030157487839460373, train/raw-loss = 0.00037847389467060566, train/logprobs = tensor([[ -1.2367, -17.6347],
        [ -9.7011,  -3.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2977901101112366
Epoch 0, Step 2870: train/loss = 0.03432402387261391, train/raw-loss = 0.0014899583766236901, train/logprobs = tensor([[ -0.9736, -12.1235],
        [ -7.4907,  -3.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32834064960479736
Epoch 0, Step 2871: train/loss = 0.02556772157549858, train/raw-loss = 0.0033162133768200874, train/logprobs = tensor([[ -1.6117, -10.3421],
        [ -8.6357,  -2.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2225150763988495
Epoch 0, Step 2872: train/loss = 0.03495034947991371, train/raw-loss = 0.0006499944720417261, train/logprobs = tensor([[ -0.8180, -14.1798],
        [ -7.8953,  -2.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3430035710334778
Epoch 0, Step 2873: train/loss = 0.032187022268772125, train/raw-loss = 0.0004413742572069168, train/logprobs = tensor([[ -1.0831, -14.8361],
        [ -8.8868,  -2.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3174564838409424
Epoch 0, Step 2874: train/loss = 0.03337117284536362, train/raw-loss = 0.0047053988091647625, train/logprobs = tensor([[ -1.0721, -12.2022],
        [ -7.1155,  -1.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28665775060653687
Epoch 0, Step 2875: train/loss = 0.033520299941301346, train/raw-loss = 0.0027715943288058043, train/logprobs = tensor([[ -0.8921, -12.8004],
        [ -6.6383,  -2.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30748704075813293
Epoch 0, Step 2876: train/loss = 0.029783526435494423, train/raw-loss = 3.072489198530093e-05, train/logprobs = tensor([[ -1.7511, -18.4359],
        [-11.9439,  -4.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2975280284881592
Epoch 0, Step 2877: train/loss = 0.038625963032245636, train/raw-loss = 0.002123117446899414, train/logprobs = tensor([[ -1.0019, -10.6345],
        [ -7.5281,  -2.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36502841114997864
Epoch 0, Step 2878: train/loss = 0.055181920528411865, train/raw-loss = 0.02746857888996601, train/logprobs = tensor([[ -0.9144, -12.1737],
        [ -7.6582,  -2.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27713340520858765
Epoch 0, Step 2879: train/loss = 0.029693709686398506, train/raw-loss = 0.0009149634279310703, train/logprobs = tensor([[ -1.2858, -13.8243],
        [ -8.7309,  -3.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28778743743896484
Epoch 0, Step 2880: train/loss = 0.028261277824640274, train/raw-loss = 0.0022954633459448814, train/logprobs = tensor([[ -2.0188, -12.8971],
        [-10.1588,  -2.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25965815782546997
Epoch 0, Step 2881: train/loss = 0.03487320989370346, train/raw-loss = 0.0036870769690722227, train/logprobs = tensor([[ -0.8295, -10.6586],
        [ -6.8918,  -1.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3118613362312317
Epoch 0, Step 2882: train/loss = 0.03589845821261406, train/raw-loss = 0.0025691259652376175, train/logprobs = tensor([[ -1.3261, -10.4652],
        [-11.1252,  -2.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332933485507965
Epoch 0, Step 2883: train/loss = 0.030207403004169464, train/raw-loss = 0.00043012347305193543, train/logprobs = tensor([[ -1.2536, -12.2025],
        [-12.0255,  -2.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29777276515960693
Epoch 0, Step 2884: train/loss = 0.0400637723505497, train/raw-loss = 0.0024774386547505856, train/logprobs = tensor([[ -1.2362, -11.3552],
        [ -7.7262,  -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37586331367492676
Epoch 0, Step 2885: train/loss = 0.030385667458176613, train/raw-loss = 0.0017965924926102161, train/logprobs = tensor([[ -0.9327, -11.4086],
        [ -6.8805,  -2.3705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28589075803756714
Epoch 0, Step 2886: train/loss = 0.03188387304544449, train/raw-loss = 0.0009779033716768026, train/logprobs = tensor([[ -0.9708, -13.1715],
        [ -9.2860,  -4.3700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090597093105316
Epoch 0, Step 2887: train/loss = 0.03379831463098526, train/raw-loss = 0.004038652870804071, train/logprobs = tensor([[-1.6158, -8.9916],
        [-8.6463, -1.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29759663343429565
Epoch 0, Step 2888: train/loss = 0.031791023910045624, train/raw-loss = 0.0014972357312217355, train/logprobs = tensor([[ -1.4845, -14.8074],
        [ -9.5304,  -3.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30293789505958557
Epoch 0, Step 2889: train/loss = 0.030331209301948547, train/raw-loss = 0.0017672477988526225, train/logprobs = tensor([[ -1.5789, -11.0399],
        [ -9.2563,  -1.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28563961386680603
Epoch 0, Step 2890: train/loss = 0.03189149498939514, train/raw-loss = 0.0017015442717820406, train/logprobs = tensor([[ -0.9834, -15.1448],
        [ -8.4093,  -3.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3018994927406311
Epoch 0, Step 2891: train/loss = 0.028373004868626595, train/raw-loss = 0.0008127392502501607, train/logprobs = tensor([[ -2.1952, -13.0479],
        [ -9.7841,  -2.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27560266852378845
Epoch 0, Step 2892: train/loss = 0.03252863138914108, train/raw-loss = 0.0008340702042914927, train/logprobs = tensor([[ -1.0598, -14.2532],
        [ -8.4048,  -3.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169456422328949
Epoch 0, Step 2893: train/loss = 0.03572183847427368, train/raw-loss = 0.00924475397914648, train/logprobs = tensor([[ -1.3786, -12.5612],
        [-10.0187,  -2.3519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26477086544036865
Epoch 0, Step 2894: train/loss = 0.031206518411636353, train/raw-loss = 0.0013783584581688046, train/logprobs = tensor([[ -1.0779, -14.1639],
        [ -8.5739,  -4.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29828158020973206
Epoch 0, Step 2895: train/loss = 0.02964393049478531, train/raw-loss = 0.0007736614206805825, train/logprobs = tensor([[ -1.1824, -16.2972],
        [ -9.0210,  -5.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28870269656181335
Epoch 0, Step 2896: train/loss = 0.0320100337266922, train/raw-loss = 0.0003984672366641462, train/logprobs = tensor([[ -1.6604, -14.5059],
        [-11.0308,  -4.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31611567735671997
Epoch 0, Step 2897: train/loss = 0.028536494821310043, train/raw-loss = 0.0014015852939337492, train/logprobs = tensor([[ -1.0209, -12.7373],
        [ -7.2566,  -2.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27134910225868225
Epoch 0, Step 2898: train/loss = 0.030789552256464958, train/raw-loss = 0.0012398951221257448, train/logprobs = tensor([[ -1.4360, -13.7188],
        [ -9.2977,  -4.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2954965829849243
Epoch 0, Step 2899: train/loss = 0.031866464763879776, train/raw-loss = 0.0010044677183032036, train/logprobs = tensor([[ -1.2072, -12.5525],
        [ -9.0091,  -3.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086199462413788
Epoch 0, Step 2900: train/loss = 0.03342196345329285, train/raw-loss = 0.0008195068803615868, train/logprobs = tensor([[ -1.1533, -12.3667],
        [ -8.4639,  -3.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32602453231811523
Epoch 0, Step 2901: train/loss = 0.03206511586904526, train/raw-loss = 0.005389236379414797, train/logprobs = tensor([[ -1.2400, -12.8385],
        [ -8.1685,  -4.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2667587995529175
Epoch 0, Step 2902: train/loss = 0.03758125379681587, train/raw-loss = 0.007601210847496986, train/logprobs = tensor([[ -0.7896, -14.6328],
        [ -7.5628,  -5.4337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29980042576789856
Epoch 0, Step 2903: train/loss = 0.034144654870033264, train/raw-loss = 0.005054485984146595, train/logprobs = tensor([[ -0.8311, -10.4988],
        [ -5.6873,  -1.7131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29090169072151184
Epoch 0, Step 2904: train/loss = 0.032706890255212784, train/raw-loss = 0.0026559210382401943, train/logprobs = tensor([[ -1.5072, -10.1711],
        [ -8.9662,  -2.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005096912384033
Epoch 0, Step 2905: train/loss = 0.03325219824910164, train/raw-loss = 0.0022738720290362835, train/logprobs = tensor([[ -1.0022, -11.7763],
        [ -7.9579,  -3.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3097832500934601
Epoch 0, Step 2906: train/loss = 0.03378203511238098, train/raw-loss = 0.0010231201304122806, train/logprobs = tensor([[ -1.0541, -12.7024],
        [ -9.1570,  -3.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32758915424346924
Epoch 0, Step 2907: train/loss = 0.0862671285867691, train/raw-loss = 0.0558570958673954, train/logprobs = tensor([[-1.1336, -9.1049],
        [-8.2333, -2.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30410036444664
Epoch 0, Step 2908: train/loss = 0.02700330875813961, train/raw-loss = 0.0004790997481904924, train/logprobs = tensor([[ -1.2310, -16.5622],
        [ -9.5116,  -4.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652420997619629
Epoch 0, Step 2909: train/loss = 0.02915336564183235, train/raw-loss = 0.0006585161318071187, train/logprobs = tensor([[ -1.5905, -14.6050],
        [ -9.2301,  -3.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284948468208313
Epoch 0, Step 2910: train/loss = 0.03384806960821152, train/raw-loss = 0.002263508038595319, train/logprobs = tensor([[ -1.2412, -11.7520],
        [ -6.9378,  -2.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158456087112427
Epoch 0, Step 2911: train/loss = 0.037187881767749786, train/raw-loss = 0.007952596992254257, train/logprobs = tensor([[ -2.1199, -12.3803],
        [ -9.8609,  -2.6224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2923528552055359
Epoch 0, Step 2912: train/loss = 0.09633230417966843, train/raw-loss = 0.06547710299491882, train/logprobs = tensor([[ -1.1525, -10.5410],
        [ -9.6952,  -3.2345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30855199694633484
Epoch 0, Step 2913: train/loss = 0.033164430409669876, train/raw-loss = 0.003808670211583376, train/logprobs = tensor([[ -0.6255, -12.1730],
        [ -6.3525,  -3.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2935575842857361
Epoch 0, Step 2914: train/loss = 0.03459766507148743, train/raw-loss = 0.002872299402952194, train/logprobs = tensor([[ -0.8840, -11.7213],
        [ -8.0442,  -3.0269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31725364923477173
Epoch 0, Step 2915: train/loss = 0.03103804960846901, train/raw-loss = 0.002482145093381405, train/logprobs = tensor([[-1.1190, -9.1637],
        [-9.3543, -2.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855590283870697
Epoch 0, Step 2916: train/loss = 0.05865349993109703, train/raw-loss = 0.03018457069993019, train/logprobs = tensor([[ -1.6620,  -8.8557],
        [-10.2161,  -2.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846892774105072
Epoch 0, Step 2917: train/loss = 0.036263518035411835, train/raw-loss = 0.0050882259383797646, train/logprobs = tensor([[ -1.7845, -12.0705],
        [-11.8949,  -2.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31175294518470764
Epoch 0, Step 2918: train/loss = 0.030434174463152885, train/raw-loss = 0.000712190754711628, train/logprobs = tensor([[ -1.5420, -15.0146],
        [ -9.7867,  -3.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29721981287002563
Epoch 0, Step 2919: train/loss = 0.030778879299759865, train/raw-loss = 0.0009364175493828952, train/logprobs = tensor([[ -1.3421, -12.9681],
        [ -9.1283,  -3.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984246015548706
Epoch 0, Step 2920: train/loss = 0.025653254240751266, train/raw-loss = 0.0004603322595357895, train/logprobs = tensor([[ -1.7625, -13.4695],
        [-10.5811,  -2.0338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25192922353744507
Epoch 0, Step 2921: train/loss = 0.033166129142045975, train/raw-loss = 0.005156158469617367, train/logprobs = tensor([[ -1.1736, -11.1211],
        [ -7.0215,  -3.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28009968996047974
Epoch 0, Step 2922: train/loss = 0.03562957048416138, train/raw-loss = 0.0059770820662379265, train/logprobs = tensor([[ -0.9731, -10.2312],
        [ -8.3770,  -2.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29652488231658936
Epoch 0, Step 2923: train/loss = 0.03410619497299194, train/raw-loss = 0.0024769622832536697, train/logprobs = tensor([[ -1.0399, -11.2940],
        [ -7.3160,  -3.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31629231572151184
Epoch 0, Step 2924: train/loss = 0.03741789981722832, train/raw-loss = 0.009367575868964195, train/logprobs = tensor([[ -1.0379, -14.2630],
        [ -6.2051,  -2.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805032432079315
Epoch 0, Step 2925: train/loss = 0.03168025240302086, train/raw-loss = 0.0006757951923646033, train/logprobs = tensor([[ -1.2469, -15.9701],
        [ -8.9789,  -3.6650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100445568561554
Epoch 0, Step 2926: train/loss = 0.03250366821885109, train/raw-loss = 0.003063553012907505, train/logprobs = tensor([[ -1.0357, -13.4182],
        [ -7.6296,  -2.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2944011390209198
Epoch 0, Step 2927: train/loss = 0.028310365974903107, train/raw-loss = 0.0013454013969749212, train/logprobs = tensor([[ -1.0459, -12.7068],
        [ -7.7815,  -2.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696496248245239
Epoch 0, Step 2928: train/loss = 0.09911549091339111, train/raw-loss = 0.0653126984834671, train/logprobs = tensor([[ -1.2389, -10.2499],
        [ -7.7403,  -4.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380278944969177
Epoch 0, Step 2929: train/loss = 0.03665639087557793, train/raw-loss = 0.00021935254335403442, train/logprobs = tensor([[ -1.0556, -13.5041],
        [ -9.2380,  -3.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3643703758716583
Epoch 0, Step 2930: train/loss = 0.037717416882514954, train/raw-loss = 0.0018833396025002003, train/logprobs = tensor([[ -1.0205, -14.3003],
        [ -7.0006,  -2.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3583407402038574
Epoch 0, Step 2931: train/loss = 0.03371455520391464, train/raw-loss = 0.0008385478286072612, train/logprobs = tensor([[ -1.1016, -12.1577],
        [ -9.4947,  -3.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3287600874900818
Epoch 0, Step 2932: train/loss = 0.05492902174592018, train/raw-loss = 0.02930026315152645, train/logprobs = tensor([[ -1.9973, -12.0820],
        [ -9.0325,  -2.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562875747680664
Epoch 0, Step 2933: train/loss = 0.034814849495887756, train/raw-loss = 0.004805515520274639, train/logprobs = tensor([[ -1.0758, -11.5766],
        [ -7.8456,  -3.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3000933527946472
Epoch 0, Step 2934: train/loss = 0.06476898491382599, train/raw-loss = 0.03069116175174713, train/logprobs = tensor([[ -2.0861, -12.8518],
        [ -9.1121,  -2.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34077826142311096
Epoch 0, Step 2935: train/loss = 0.03586427494883537, train/raw-loss = 0.005456855520606041, train/logprobs = tensor([[ -0.8096, -10.9268],
        [ -7.0744,  -2.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30407416820526123
Epoch 0, Step 2936: train/loss = 0.027297507971525192, train/raw-loss = 0.0002913816715590656, train/logprobs = tensor([[ -1.4792, -17.1994],
        [-11.0038,  -3.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700612545013428
Epoch 0, Step 2937: train/loss = 0.028318732976913452, train/raw-loss = 0.0005900964024476707, train/logprobs = tensor([[ -1.3279, -15.8362],
        [-10.9727,  -3.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772863507270813
Epoch 0, Step 2938: train/loss = 0.033849529922008514, train/raw-loss = 0.0031364646274596453, train/logprobs = tensor([[ -0.8558, -11.7791],
        [ -6.9137,  -2.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3071306347846985
Epoch 0, Step 2939: train/loss = 0.032277911901474, train/raw-loss = 0.0008569080382585526, train/logprobs = tensor([[ -1.1697, -12.1120],
        [ -8.5763,  -2.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31421002745628357
Epoch 0, Step 2940: train/loss = 0.027988968417048454, train/raw-loss = 0.0023887085262686014, train/logprobs = tensor([[ -1.1422, -17.1170],
        [ -7.5872,  -4.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2560025751590729
Epoch 0, Step 2941: train/loss = 0.027110129594802856, train/raw-loss = 0.0018150950782001019, train/logprobs = tensor([[ -0.8924, -15.0553],
        [ -7.8289,  -4.2987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25295037031173706
Epoch 0, Step 2942: train/loss = 0.03322433680295944, train/raw-loss = 0.002834774786606431, train/logprobs = tensor([[ -0.9929, -10.8883],
        [ -9.6260,  -2.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30389562249183655
Epoch 0, Step 2943: train/loss = 0.03188638016581535, train/raw-loss = 0.0025398838333785534, train/logprobs = tensor([[ -0.8573, -14.5510],
        [ -7.2894,  -2.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2934649586677551
Epoch 0, Step 2944: train/loss = 0.031064212322235107, train/raw-loss = 0.0028051643166691065, train/logprobs = tensor([[ -1.3197, -10.1931],
        [ -9.6689,  -1.4902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28259044885635376
Epoch 0, Step 2945: train/loss = 0.11334820836782455, train/raw-loss = 0.08232399076223373, train/logprobs = tensor([[ -1.1496, -10.7438],
        [ -8.3075,  -3.4441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3102421164512634
Epoch 0, Step 2946: train/loss = 0.06216507777571678, train/raw-loss = 0.032603319734334946, train/logprobs = tensor([[-1.1291, -8.5744],
        [-8.8847, -2.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29561758041381836
Epoch 0, Step 2947: train/loss = 0.031238488852977753, train/raw-loss = 0.0006199551280587912, train/logprobs = tensor([[ -0.8769, -15.7289],
        [ -8.9338,  -3.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061853051185608
Epoch 0, Step 2948: train/loss = 0.03153650835156441, train/raw-loss = 0.001566514139994979, train/logprobs = tensor([[ -0.8773, -15.6359],
        [ -7.6086,  -3.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29969996213912964
Epoch 0, Step 2949: train/loss = 0.037439096719026566, train/raw-loss = 0.006874061655253172, train/logprobs = tensor([[ -1.1219, -11.4755],
        [ -9.6944,  -2.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056503236293793
Epoch 0, Step 2950: train/loss = 0.033137641847133636, train/raw-loss = 0.001640342059545219, train/logprobs = tensor([[ -0.8116, -11.1167],
        [ -7.6580,  -2.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31497299671173096
Epoch 0, Step 2951: train/loss = 0.03022960014641285, train/raw-loss = 0.0011536539532244205, train/logprobs = tensor([[ -1.6542, -10.9222],
        [-10.2006,  -2.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29075944423675537
Epoch 0, Step 2952: train/loss = 0.03101596049964428, train/raw-loss = 0.0005363205564208329, train/logprobs = tensor([[ -1.0012, -11.9700],
        [ -9.2211,  -2.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30479639768600464
Epoch 0, Step 2953: train/loss = 0.03568586707115173, train/raw-loss = 0.0026176224928349257, train/logprobs = tensor([[ -0.8275, -12.2454],
        [ -8.0388,  -3.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306824266910553
Epoch 0, Step 2954: train/loss = 0.026473393663764, train/raw-loss = 0.0009787732269614935, train/logprobs = tensor([[ -1.3555, -10.5409],
        [-10.5027,  -2.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25494620203971863
Epoch 0, Step 2955: train/loss = 0.07436744123697281, train/raw-loss = 0.047576967626810074, train/logprobs = tensor([[ -1.2034, -11.2107],
        [ -8.0124,  -3.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26790469884872437
Epoch 0, Step 2956: train/loss = 0.030849140137434006, train/raw-loss = 0.0005224496126174927, train/logprobs = tensor([[ -1.4297, -12.9267],
        [-10.3764,  -2.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30326688289642334
Epoch 0, Step 2957: train/loss = 0.034903768450021744, train/raw-loss = 0.0015211865538731217, train/logprobs = tensor([[ -0.8985, -14.4091],
        [ -7.1887,  -3.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3338257968425751
Epoch 0, Step 2958: train/loss = 0.16681884229183197, train/raw-loss = 0.1347121149301529, train/logprobs = tensor([[ -1.5975, -10.8683],
        [-10.8406,  -6.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210672438144684
Epoch 0, Step 2959: train/loss = 0.028244685381650925, train/raw-loss = 0.000291466829366982, train/logprobs = tensor([[ -1.1381, -14.1214],
        [ -8.7431,  -2.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27953219413757324
Epoch 0, Step 2960: train/loss = 0.027846314013004303, train/raw-loss = 0.0005906333681195974, train/logprobs = tensor([[ -1.6781, -20.6121],
        [-10.8271,  -7.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27255678176879883
Epoch 0, Step 2961: train/loss = 0.05809091404080391, train/raw-loss = 0.028258590027689934, train/logprobs = tensor([[ -1.1480, -10.1811],
        [ -7.5445,  -3.3061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29832321405410767
Epoch 0, Step 2962: train/loss = 0.034975238144397736, train/raw-loss = 0.0022466524969786406, train/logprobs = tensor([[-1.3007, -9.8316],
        [-8.1297, -2.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32728585600852966
Epoch 0, Step 2963: train/loss = 0.04030609875917435, train/raw-loss = 0.0164882130920887, train/logprobs = tensor([[-0.9376, -9.6268],
        [-7.7015, -3.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23817884922027588
Epoch 0, Step 2964: train/loss = 0.03574999049305916, train/raw-loss = 0.004905173555016518, train/logprobs = tensor([[ -1.1286, -12.1953],
        [ -6.9882,  -3.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084481656551361
Epoch 0, Step 2965: train/loss = 0.027806255966424942, train/raw-loss = 0.0003832370275631547, train/logprobs = tensor([[ -2.0761, -14.2627],
        [-11.7989,  -3.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742301821708679
Epoch 0, Step 2966: train/loss = 0.02898561581969261, train/raw-loss = 0.0014903040137141943, train/logprobs = tensor([[ -1.1223, -12.1105],
        [ -8.4644,  -2.3327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27495312690734863
Epoch 0, Step 2967: train/loss = 0.03704415261745453, train/raw-loss = 0.0031322110444307327, train/logprobs = tensor([[ -0.9014, -14.6567],
        [ -8.1663,  -3.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33911943435668945
Epoch 0, Step 2968: train/loss = 0.03318947181105614, train/raw-loss = 0.0011917374795302749, train/logprobs = tensor([[ -0.6498, -11.0381],
        [ -7.2247,  -1.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319977343082428
Epoch 0, Step 2969: train/loss = 0.03879481181502342, train/raw-loss = 0.007877222262322903, train/logprobs = tensor([[ -1.6637, -11.0855],
        [-10.3767,  -3.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30917587876319885
Epoch 0, Step 2970: train/loss = 0.12291128933429718, train/raw-loss = 0.09478094428777695, train/logprobs = tensor([[-1.1178, -9.8224],
        [-8.4681, -3.2552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813034951686859
Epoch 0, Step 2971: train/loss = 0.039220377802848816, train/raw-loss = 0.003722429508343339, train/logprobs = tensor([[ -1.1520, -11.4412],
        [-10.2318,  -3.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3549794852733612
Epoch 0, Step 2972: train/loss = 0.026841729879379272, train/raw-loss = 0.0003700832021422684, train/logprobs = tensor([[ -1.4775, -13.8398],
        [-10.9988,  -4.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647164762020111
Epoch 0, Step 2973: train/loss = 0.028411293402314186, train/raw-loss = 0.0002530645579099655, train/logprobs = tensor([[ -1.6732, -14.2411],
        [-10.4031,  -3.2049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2815822958946228
Epoch 0, Step 2974: train/loss = 0.032515108585357666, train/raw-loss = 0.0012337438529357314, train/logprobs = tensor([[ -1.3053, -16.4169],
        [-10.3004,  -5.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3128136396408081
Epoch 0, Step 2975: train/loss = 0.04765503108501434, train/raw-loss = 0.014316366985440254, train/logprobs = tensor([[-1.4613, -6.8221],
        [-9.3589, -1.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333866596221924
Epoch 0, Step 2976: train/loss = 0.029202325269579887, train/raw-loss = 0.0016071194550022483, train/logprobs = tensor([[ -1.1147, -14.6122],
        [ -8.5250,  -4.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759520411491394
Epoch 0, Step 2977: train/loss = 0.13796956837177277, train/raw-loss = 0.10863158106803894, train/logprobs = tensor([[-0.9614, -9.3492],
        [-8.3652, -3.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933798134326935
Epoch 0, Step 2978: train/loss = 0.0309453047811985, train/raw-loss = 0.003047714475542307, train/logprobs = tensor([[ -1.2729, -10.8399],
        [ -9.5052,  -2.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789759039878845
Epoch 0, Step 2979: train/loss = 0.03247246518731117, train/raw-loss = 0.0005615250556729734, train/logprobs = tensor([[ -1.6431, -11.1393],
        [-10.3399,  -2.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31910941004753113
Epoch 0, Step 2980: train/loss = 0.03404258191585541, train/raw-loss = 0.0034570693969726562, train/logprobs = tensor([[ -1.1145, -15.4749],
        [ -7.8358,  -3.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3058551251888275
Epoch 0, Step 2981: train/loss = 0.039213165640830994, train/raw-loss = 0.004710023757070303, train/logprobs = tensor([[ -0.7727, -16.7507],
        [ -6.3984,  -5.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34503141045570374
Epoch 0, Step 2982: train/loss = 0.05470322072505951, train/raw-loss = 0.019771013408899307, train/logprobs = tensor([[-1.0202, -9.1104],
        [-7.5942, -3.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493220806121826
Epoch 0, Step 2983: train/loss = 0.03408533334732056, train/raw-loss = 0.0004424552898854017, train/logprobs = tensor([[ -1.3280, -12.7636],
        [ -9.4961,  -2.2798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33642882108688354
Epoch 0, Step 2984: train/loss = 0.0360138863325119, train/raw-loss = 0.0028761504217982292, train/logprobs = tensor([[ -1.4969, -13.5551],
        [ -8.3400,  -4.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313773572444916
Epoch 0, Step 2985: train/loss = 0.027697280049324036, train/raw-loss = 0.0014113320503383875, train/logprobs = tensor([[ -1.2729, -13.7112],
        [ -8.7324,  -3.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2628594934940338
Epoch 0, Step 2986: train/loss = 0.04208404943346977, train/raw-loss = 0.009777878411114216, train/logprobs = tensor([[ -0.8335, -10.3081],
        [ -7.8392,  -2.1078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32306167483329773
Epoch 0, Step 2987: train/loss = 0.037648752331733704, train/raw-loss = 0.013106115162372589, train/logprobs = tensor([[ -1.3018, -10.0863],
        [ -7.7532,  -1.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24542635679244995
Epoch 0, Step 2988: train/loss = 0.03287247568368912, train/raw-loss = 0.0002813340979628265, train/logprobs = tensor([[ -1.0098, -10.9438],
        [ -9.1938,  -1.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32591140270233154
Epoch 0, Step 2989: train/loss = 0.09932295978069305, train/raw-loss = 0.06804517656564713, train/logprobs = tensor([[ -1.1857, -10.6182],
        [ -8.2823,  -3.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3127777874469757
Epoch 0, Step 2990: train/loss = 0.03078952059149742, train/raw-loss = 0.0018437844701111317, train/logprobs = tensor([[ -1.3156, -12.1448],
        [ -7.6452,  -3.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28945738077163696
Epoch 0, Step 2991: train/loss = 0.029533034190535545, train/raw-loss = 0.001283623045310378, train/logprobs = tensor([[ -1.2346, -16.2675],
        [ -9.0122,  -4.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28249412775039673
Epoch 0, Step 2992: train/loss = 0.05180458724498749, train/raw-loss = 0.023116296157240868, train/logprobs = tensor([[ -1.1406, -13.3947],
        [ -6.9170,  -3.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868829071521759
Epoch 0, Step 2993: train/loss = 0.03149852529168129, train/raw-loss = 0.0006669707945547998, train/logprobs = tensor([[ -0.9867, -14.7761],
        [ -8.2355,  -3.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30831554532051086
Epoch 0, Step 2994: train/loss = 0.02867244929075241, train/raw-loss = 0.00017391629808116704, train/logprobs = tensor([[ -1.6059, -12.5796],
        [-12.1076,  -1.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849853038787842
Epoch 0, Step 2995: train/loss = 0.13411667943000793, train/raw-loss = 0.10084157437086105, train/logprobs = tensor([[-1.4001, -9.2602],
        [-9.5162, -3.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3327510356903076
Epoch 0, Step 2996: train/loss = 0.04143006354570389, train/raw-loss = 0.0037033497355878353, train/logprobs = tensor([[-1.0644, -9.3525],
        [-7.8784, -2.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37726712226867676
Epoch 0, Step 2997: train/loss = 0.028568048030138016, train/raw-loss = 7.963991083670408e-05, train/logprobs = tensor([[ -1.2240, -14.8229],
        [-11.0463,  -2.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28488409519195557
Epoch 0, Step 2998: train/loss = 0.033777639269828796, train/raw-loss = 0.0012892030645161867, train/logprobs = tensor([[ -0.9872, -14.2709],
        [ -7.4972,  -3.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3248843550682068
Epoch 0, Step 2999: train/loss = 0.02892407216131687, train/raw-loss = 0.0009647279512137175, train/logprobs = tensor([[ -1.2529, -18.6294],
        [ -8.9301,  -5.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27959343791007996
Epoch 0, Step 3000: train/loss = 0.0325346440076828, train/raw-loss = 0.00048133195377886295, train/logprobs = tensor([[ -1.1361, -15.5135],
        [ -9.5855,  -3.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205331265926361
Epoch 0, Step 3001: train/loss = 0.034393638372421265, train/raw-loss = 0.0009108277154155076, train/logprobs = tensor([[ -1.6285, -12.4100],
        [ -9.9262,  -3.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33482813835144043
Epoch 0, Step 3002: train/loss = 0.03640545532107353, train/raw-loss = 0.00791165977716446, train/logprobs = tensor([[ -1.0504, -14.0838],
        [ -7.3404,  -3.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849379777908325
Epoch 0, Step 3003: train/loss = 0.03583398088812828, train/raw-loss = 0.004352162126451731, train/logprobs = tensor([[ -1.4867,  -9.8026],
        [-10.5086,  -2.6677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31481820344924927
Epoch 0, Step 3004: train/loss = 0.0358860045671463, train/raw-loss = 0.0017680245218798518, train/logprobs = tensor([[ -1.0474, -11.4518],
        [ -8.2445,  -3.3534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411797881126404
Epoch 0, Step 3005: train/loss = 0.03347732871770859, train/raw-loss = 0.006328084971755743, train/logprobs = tensor([[ -1.2421, -11.7676],
        [ -7.7380,  -3.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27149245142936707
Epoch 0, Step 3006: train/loss = 0.037417422980070114, train/raw-loss = 0.010834566317498684, train/logprobs = tensor([[ -1.3619, -13.7959],
        [ -8.9085,  -4.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26582854986190796
Epoch 0, Step 3007: train/loss = 0.03079850599169731, train/raw-loss = 0.0015601587947458029, train/logprobs = tensor([[ -0.8858, -11.2559],
        [ -8.0378,  -2.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29238346219062805
Epoch 0, Step 3008: train/loss = 0.02884124591946602, train/raw-loss = 0.0005581591976806521, train/logprobs = tensor([[ -1.1020, -15.1861],
        [ -8.8539,  -3.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2828308641910553
Epoch 0, Step 3009: train/loss = 0.02726881578564644, train/raw-loss = 0.00025705414009280503, train/logprobs = tensor([[ -1.2114, -16.5051],
        [ -9.4758,  -3.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701175808906555
Epoch 0, Step 3010: train/loss = 0.03815515711903572, train/raw-loss = 0.006866603158414364, train/logprobs = tensor([[ -1.2243, -13.7395],
        [-10.6723,  -2.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3128855228424072
Epoch 0, Step 3011: train/loss = 0.02880539745092392, train/raw-loss = 0.00229283282533288, train/logprobs = tensor([[ -1.2700, -11.2967],
        [ -7.6717,  -2.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651256322860718
Epoch 0, Step 3012: train/loss = 0.030915355309844017, train/raw-loss = 0.0007471750141121447, train/logprobs = tensor([[ -0.9937, -17.0372],
        [ -9.2258,  -4.4859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016818165779114
Epoch 0, Step 3013: train/loss = 0.028068136423826218, train/raw-loss = 0.0011595659889280796, train/logprobs = tensor([[ -1.2744, -11.5165],
        [ -8.8397,  -2.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26908570528030396
Epoch 0, Step 3014: train/loss = 0.03352274000644684, train/raw-loss = 0.0034109679982066154, train/logprobs = tensor([[ -1.0468, -10.4073],
        [ -8.1634,  -2.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011177182197571
Epoch 0, Step 3015: train/loss = 0.04083819314837456, train/raw-loss = 0.011942455545067787, train/logprobs = tensor([[ -1.0916, -11.2122],
        [ -7.1442,  -3.3970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889573574066162
Epoch 0, Step 3016: train/loss = 0.035574860870838165, train/raw-loss = 0.0012256356421858072, train/logprobs = tensor([[ -0.9203, -12.2816],
        [ -7.6831,  -2.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34349220991134644
Epoch 0, Step 3017: train/loss = 0.11793122440576553, train/raw-loss = 0.09036252647638321, train/logprobs = tensor([[ -1.1267, -10.0310],
        [ -7.9224,  -3.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27568697929382324
Epoch 0, Step 3018: train/loss = 0.04382307454943657, train/raw-loss = 0.013723582960665226, train/logprobs = tensor([[ -1.5924, -14.0094],
        [ -8.4108,  -3.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.300994873046875
Epoch 0, Step 3019: train/loss = 0.03829178959131241, train/raw-loss = 0.00852903164923191, train/logprobs = tensor([[ -0.7811, -10.5482],
        [ -7.5915,  -3.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976275682449341
Epoch 0, Step 3020: train/loss = 0.06325602531433105, train/raw-loss = 0.03872555494308472, train/logprobs = tensor([[-1.0681, -9.9790],
        [-5.0228, -2.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2453046590089798
Epoch 0, Step 3021: train/loss = 0.037919048219919205, train/raw-loss = 0.004436834715306759, train/logprobs = tensor([[ -1.5435, -11.8332],
        [ -9.9427,  -3.2200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348221480846405
Epoch 0, Step 3022: train/loss = 0.03140237182378769, train/raw-loss = 0.0007454362930729985, train/logprobs = tensor([[ -1.0313, -15.5649],
        [ -8.1207,  -3.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30656930804252625
Epoch 0, Step 3023: train/loss = 0.04097685217857361, train/raw-loss = 0.008388616144657135, train/logprobs = tensor([[ -1.3031, -12.6089],
        [-10.3627,  -3.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32588234543800354
Epoch 0, Step 3024: train/loss = 0.03536737337708473, train/raw-loss = 0.0022071630228310823, train/logprobs = tensor([[ -0.9963, -12.4639],
        [ -9.3514,  -2.4453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3316020965576172
Epoch 0, Step 3025: train/loss = 0.08202648162841797, train/raw-loss = 0.04256829991936684, train/logprobs = tensor([[-1.0625, -9.9249],
        [-7.3965, -2.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39458173513412476
Epoch 0, Step 3026: train/loss = 0.03393907845020294, train/raw-loss = 0.004171579144895077, train/logprobs = tensor([[ -0.9221, -10.5235],
        [ -9.2229,  -2.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976749837398529
Epoch 0, Step 3027: train/loss = 0.02667143940925598, train/raw-loss = 0.00012313709885347635, train/logprobs = tensor([[ -1.4742, -14.1641],
        [-11.4847,  -3.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265483021736145
Epoch 0, Step 3028: train/loss = 0.03725381940603256, train/raw-loss = 0.0030289972200989723, train/logprobs = tensor([[ -1.3422, -10.4063],
        [ -7.9774,  -2.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34224820137023926
Epoch 0, Step 3029: train/loss = 0.03020758368074894, train/raw-loss = 0.0008244962664321065, train/logprobs = tensor([[ -1.3042, -14.1572],
        [ -8.8769,  -4.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29383084177970886
Epoch 0, Step 3030: train/loss = 0.027538424357771873, train/raw-loss = 8.019901724765077e-05, train/logprobs = tensor([[ -1.9773, -14.3921],
        [-12.0587,  -2.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27458223700523376
Epoch 0, Step 3031: train/loss = 0.03965079039335251, train/raw-loss = 0.0036278748884797096, train/logprobs = tensor([[-1.0157, -8.5243],
        [-7.6410, -2.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36022916436195374
Epoch 0, Step 3032: train/loss = 0.030192529782652855, train/raw-loss = 0.0006196209578774869, train/logprobs = tensor([[ -1.3038, -13.8171],
        [ -9.3076,  -2.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957290709018707
Epoch 0, Step 3033: train/loss = 0.030866775661706924, train/raw-loss = 7.008914690231904e-05, train/logprobs = tensor([[ -1.3085, -16.2126],
        [-11.2250,  -3.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079668879508972
Epoch 0, Step 3034: train/loss = 0.02961108647286892, train/raw-loss = 0.000541560584679246, train/logprobs = tensor([[ -1.6232, -10.8680],
        [-10.6651,  -2.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2906952500343323
Epoch 0, Step 3035: train/loss = 0.030092015862464905, train/raw-loss = 0.0004800324677489698, train/logprobs = tensor([[ -1.1640, -15.1080],
        [ -9.1776,  -4.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961198091506958
Epoch 0, Step 3036: train/loss = 0.05634112283587456, train/raw-loss = 0.027839701622724533, train/logprobs = tensor([[-0.9998, -6.3337],
        [-8.1898, -2.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28501418232917786
Epoch 0, Step 3037: train/loss = 0.0343959666788578, train/raw-loss = 0.0025944255758076906, train/logprobs = tensor([[ -0.9861, -10.5703],
        [ -8.0398,  -2.2836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3180154263973236
Epoch 0, Step 3038: train/loss = 0.02816564217209816, train/raw-loss = 0.00014819794159848243, train/logprobs = tensor([[ -1.1485, -18.7745],
        [ -9.8615,  -6.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801744341850281
Epoch 0, Step 3039: train/loss = 0.1386573314666748, train/raw-loss = 0.1078840121626854, train/logprobs = tensor([[ -2.0190, -10.6880],
        [ -8.8666,  -3.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30773305892944336
Epoch 0, Step 3040: train/loss = 0.029576420783996582, train/raw-loss = 0.0011147833429276943, train/logprobs = tensor([[ -1.2292, -12.5152],
        [ -8.5103,  -3.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846163511276245
Epoch 0, Step 3041: train/loss = 0.03085550107061863, train/raw-loss = 0.0009153098217211664, train/logprobs = tensor([[ -1.2176, -13.5371],
        [ -7.8208,  -2.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994019091129303
Epoch 0, Step 3042: train/loss = 0.02498084306716919, train/raw-loss = 0.00030466000316664577, train/logprobs = tensor([[ -1.3722, -16.6923],
        [ -9.4274,  -2.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24676182866096497
Epoch 0, Step 3043: train/loss = 0.03389851748943329, train/raw-loss = 0.00598775502294302, train/logprobs = tensor([[ -1.6877, -12.7157],
        [ -9.0667,  -2.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27910763025283813
Epoch 0, Step 3044: train/loss = 0.031313639134168625, train/raw-loss = 0.002488308120518923, train/logprobs = tensor([[ -1.0669, -11.8323],
        [ -7.6065,  -3.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2882533371448517
Epoch 0, Step 3045: train/loss = 0.027311760932207108, train/raw-loss = 0.0028529923874884844, train/logprobs = tensor([[ -1.1467, -11.6149],
        [ -7.1755,  -2.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24458767473697662
Epoch 0, Step 3046: train/loss = 0.030442778021097183, train/raw-loss = 0.0014855039771646261, train/logprobs = tensor([[ -1.3656, -11.9877],
        [ -9.8627,  -2.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28957271575927734
Epoch 0, Step 3047: train/loss = 0.03215930238366127, train/raw-loss = 0.0003960841568186879, train/logprobs = tensor([[ -1.0581, -14.1774],
        [ -8.6335,  -2.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31763219833374023
Epoch 0, Step 3048: train/loss = 0.031102821230888367, train/raw-loss = 0.003117912681773305, train/logprobs = tensor([[ -0.9899, -12.1695],
        [ -6.8105,  -2.3272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.279849112033844
Epoch 0, Step 3049: train/loss = 0.03526880592107773, train/raw-loss = 0.0009604261140339077, train/logprobs = tensor([[ -1.2197, -15.7091],
        [ -8.0790,  -2.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34308382868766785
Epoch 0, Step 3050: train/loss = 0.02841898240149021, train/raw-loss = 0.0008262475021183491, train/logprobs = tensor([[ -1.3553, -16.5922],
        [ -9.1147,  -3.2492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27592733502388
Epoch 0, Step 3051: train/loss = 0.03754591941833496, train/raw-loss = 0.007633875124156475, train/logprobs = tensor([[ -1.2012, -15.5549],
        [ -8.9564,  -4.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991204559803009
Epoch 0, Step 3052: train/loss = 0.03419676423072815, train/raw-loss = 0.002018764615058899, train/logprobs = tensor([[ -1.0718, -10.8129],
        [ -8.5715,  -1.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217800259590149
Epoch 0, Step 3053: train/loss = 0.03050493821501732, train/raw-loss = 0.005011532921344042, train/logprobs = tensor([[ -1.7029, -17.5607],
        [ -9.2642,  -2.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25493401288986206
Epoch 0, Step 3054: train/loss = 0.04346746951341629, train/raw-loss = 0.007189164869487286, train/logprobs = tensor([[ -1.3337, -10.2588],
        [ -8.8877,  -3.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3627830743789673
Epoch 0, Step 3055: train/loss = 0.027643827721476555, train/raw-loss = 0.001227180240675807, train/logprobs = tensor([[ -1.0691, -14.0722],
        [ -8.1126,  -2.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641664445400238
Epoch 0, Step 3056: train/loss = 0.03133140876889229, train/raw-loss = 0.0009280708618462086, train/logprobs = tensor([[-1.5055, -9.3053],
        [-9.3559, -2.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30403339862823486
Epoch 0, Step 3057: train/loss = 0.03021509386599064, train/raw-loss = 0.0015917688142508268, train/logprobs = tensor([[ -1.0562, -15.0823],
        [ -7.0821,  -2.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28623324632644653
Epoch 0, Step 3058: train/loss = 0.0901210680603981, train/raw-loss = 0.05586348846554756, train/logprobs = tensor([[ -1.2816, -10.1815],
        [ -9.7739,  -3.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425757884979248
Epoch 0, Step 3059: train/loss = 0.04297120124101639, train/raw-loss = 0.01385178230702877, train/logprobs = tensor([[-2.3780, -9.1529],
        [-8.0106, -2.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2911941707134247
Epoch 0, Step 3060: train/loss = 0.031413689255714417, train/raw-loss = 0.003121358808130026, train/logprobs = tensor([[ -1.5869, -11.3476],
        [ -7.8047,  -1.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28292328119277954
Epoch 0, Step 3061: train/loss = 0.027112342417240143, train/raw-loss = 0.0008289769757539034, train/logprobs = tensor([[ -1.0622, -17.3202],
        [ -8.5528,  -3.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2628336548805237
Epoch 0, Step 3062: train/loss = 0.040082160383462906, train/raw-loss = 0.004600921180099249, train/logprobs = tensor([[ -1.2644, -12.7418],
        [ -8.9859,  -2.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354812353849411
Epoch 0, Step 3063: train/loss = 0.03404323011636734, train/raw-loss = 0.005672127939760685, train/logprobs = tensor([[ -0.9947, -11.7682],
        [ -5.7823,  -2.3192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837110161781311
Epoch 0, Step 3064: train/loss = 0.02841293066740036, train/raw-loss = 0.00030329267610795796, train/logprobs = tensor([[ -1.4730, -15.2548],
        [ -9.2625,  -2.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28109636902809143
Epoch 0, Step 3065: train/loss = 0.029737718403339386, train/raw-loss = 0.0018190311966463923, train/logprobs = tensor([[ -1.3058, -15.9240],
        [ -8.1470,  -3.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27918684482574463
Epoch 0, Step 3066: train/loss = 0.0311465822160244, train/raw-loss = 0.006873813923448324, train/logprobs = tensor([[ -1.5429, -10.2011],
        [ -9.3258,  -2.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24272766709327698
Epoch 0, Step 3067: train/loss = 0.0321444496512413, train/raw-loss = 0.0008254539570771158, train/logprobs = tensor([[ -1.4623, -14.4364],
        [-10.4850,  -2.4508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31318995356559753
Epoch 0, Step 3068: train/loss = 0.04420088976621628, train/raw-loss = 0.017229391261935234, train/logprobs = tensor([[ -1.4626, -11.9050],
        [ -7.9324,  -2.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26971498131752014
Epoch 0, Step 3069: train/loss = 0.030549217015504837, train/raw-loss = 0.0013694321969524026, train/logprobs = tensor([[ -1.0357, -12.0525],
        [ -8.0343,  -2.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29179781675338745
Epoch 0, Step 3070: train/loss = 0.031882088631391525, train/raw-loss = 0.0011058052768930793, train/logprobs = tensor([[ -1.0571, -17.4282],
        [ -7.4277,  -3.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30776289105415344
Epoch 0, Step 3071: train/loss = 0.033093348145484924, train/raw-loss = 0.002007613191381097, train/logprobs = tensor([[ -1.3641, -11.1335],
        [ -7.3478,  -1.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.310857355594635
Epoch 0, Step 3072: train/loss = 0.031836554408073425, train/raw-loss = 0.00027507072081789374, train/logprobs = tensor([[ -1.2702, -12.7657],
        [ -9.3889,  -2.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31561481952667236
Epoch 0, Step 3073: train/loss = 0.08219613134860992, train/raw-loss = 0.0545579195022583, train/logprobs = tensor([[ -1.5523, -10.7738],
        [ -8.5652,  -2.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27638211846351624
Epoch 0, Step 3074: train/loss = 0.028251398354768753, train/raw-loss = 0.00041458720806986094, train/logprobs = tensor([[ -1.6577, -15.7922],
        [ -9.9534,  -3.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2783680856227875
Epoch 0, Step 3075: train/loss = 0.04087476432323456, train/raw-loss = 0.013288735412061214, train/logprobs = tensor([[ -1.5742, -15.2424],
        [ -7.0179,  -2.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758602797985077
Epoch 0, Step 3076: train/loss = 0.027753975242376328, train/raw-loss = 0.0007531789597123861, train/logprobs = tensor([[ -1.4874, -12.6289],
        [ -9.3853,  -2.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700079679489136
Epoch 0, Step 3077: train/loss = 0.033382028341293335, train/raw-loss = 0.004293237347155809, train/logprobs = tensor([[ -1.9191, -11.8632],
        [ -9.0103,  -2.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29088789224624634
Epoch 0, Step 3078: train/loss = 0.028736334294080734, train/raw-loss = 0.0007304028258658946, train/logprobs = tensor([[ -1.2484, -14.3516],
        [ -8.0901,  -2.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800593078136444
Epoch 0, Step 3079: train/loss = 0.03910044580698013, train/raw-loss = 0.006267213728278875, train/logprobs = tensor([[ -1.5559, -10.7471],
        [ -9.2692,  -2.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283323049545288
Epoch 0, Step 3080: train/loss = 0.03140190616250038, train/raw-loss = 0.0013867123052477837, train/logprobs = tensor([[ -0.9608, -13.2337],
        [ -7.2607,  -3.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3001519441604614
Epoch 0, Step 3081: train/loss = 0.03279941901564598, train/raw-loss = 0.004411844536662102, train/logprobs = tensor([[ -1.0328, -16.1187],
        [ -6.8880,  -3.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838757336139679
Epoch 0, Step 3082: train/loss = 0.03658287972211838, train/raw-loss = 0.002007042523473501, train/logprobs = tensor([[ -1.4034, -10.0732],
        [ -8.4846,  -1.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3457583785057068
Epoch 0, Step 3083: train/loss = 0.03369349241256714, train/raw-loss = 0.006203505210578442, train/logprobs = tensor([[ -1.0785, -10.7762],
        [ -6.2300,  -2.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748998701572418
Epoch 0, Step 3084: train/loss = 0.03133013844490051, train/raw-loss = 0.0013154593762010336, train/logprobs = tensor([[ -0.8857, -19.9500],
        [ -7.0494,  -3.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30014678835868835
Epoch 0, Step 3085: train/loss = 0.03815871849656105, train/raw-loss = 0.003132808720692992, train/logprobs = tensor([[ -1.1101, -12.2853],
        [ -7.9940,  -1.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35025906562805176
Epoch 0, Step 3086: train/loss = 0.03324215114116669, train/raw-loss = 0.0005325027159415185, train/logprobs = tensor([[ -1.2298, -19.4259],
        [ -8.1866,  -4.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32709646224975586
Epoch 0, Step 3087: train/loss = 0.033978309482336044, train/raw-loss = 0.0015573028940707445, train/logprobs = tensor([[ -1.3134, -13.4583],
        [ -9.4407,  -3.4618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3242100477218628
Epoch 0, Step 3088: train/loss = 0.03405056893825531, train/raw-loss = 0.005645462777465582, train/logprobs = tensor([[ -1.0450, -15.3880],
        [ -7.1847,  -4.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840510904788971
Epoch 0, Step 3089: train/loss = 0.031803980469703674, train/raw-loss = 0.0009574607247486711, train/logprobs = tensor([[ -1.4811, -13.5344],
        [ -9.2204,  -2.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084651827812195
Epoch 0, Step 3090: train/loss = 0.03545903414487839, train/raw-loss = 0.003132190788164735, train/logprobs = tensor([[ -1.2294, -13.4174],
        [ -9.3471,  -3.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3232683837413788
Epoch 0, Step 3091: train/loss = 0.0368422269821167, train/raw-loss = 0.009675586596131325, train/logprobs = tensor([[ -1.1704, -13.7230],
        [ -7.6509,  -3.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27166640758514404
Epoch 0, Step 3092: train/loss = 0.03203674778342247, train/raw-loss = 0.0014695327263325453, train/logprobs = tensor([[ -1.1714, -16.8722],
        [ -8.1060,  -3.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30567213892936707
Epoch 0, Step 3093: train/loss = 0.030154822394251823, train/raw-loss = 0.0027481194119900465, train/logprobs = tensor([[ -1.0176, -12.9425],
        [ -7.9847,  -2.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740670144557953
Epoch 0, Step 3094: train/loss = 0.029878966510295868, train/raw-loss = 0.00036885018926113844, train/logprobs = tensor([[ -1.7312, -14.0751],
        [ -9.4985,  -3.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2951011657714844
Epoch 0, Step 3095: train/loss = 0.04009357467293739, train/raw-loss = 0.012760798446834087, train/logprobs = tensor([[ -0.7430, -12.9765],
        [ -5.6862,  -1.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2733277678489685
Epoch 0, Step 3096: train/loss = 0.028883356600999832, train/raw-loss = 0.002141602337360382, train/logprobs = tensor([[ -1.2567, -14.5081],
        [ -8.5062,  -2.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2674175500869751
Epoch 0, Step 3097: train/loss = 0.03159860521554947, train/raw-loss = 0.0002183776960009709, train/logprobs = tensor([[ -1.9798, -14.4966],
        [-11.1112,  -3.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3138022720813751
Epoch 0, Step 3098: train/loss = 0.03359000012278557, train/raw-loss = 0.0037130042910575867, train/logprobs = tensor([[ -1.2136, -13.5268],
        [ -7.5231,  -3.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987699508666992
Epoch 0, Step 3099: train/loss = 0.03192285820841789, train/raw-loss = 0.0008606667397543788, train/logprobs = tensor([[ -1.1522, -14.1846],
        [ -8.6053,  -3.5586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31062188744544983
Epoch 0, Step 3100: train/loss = 0.031507499516010284, train/raw-loss = 0.002564824651926756, train/logprobs = tensor([[ -1.0092, -14.4738],
        [ -8.2392,  -3.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894267141819
Epoch 0, Step 3101: train/loss = 0.030500702559947968, train/raw-loss = 0.0019225202267989516, train/logprobs = tensor([[ -1.4180, -16.3301],
        [ -9.3249,  -4.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857818305492401
Epoch 0, Step 3102: train/loss = 0.03792582079768181, train/raw-loss = 0.0023213564418256283, train/logprobs = tensor([[-1.3856, -8.4552],
        [-8.8026, -1.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3560446500778198
Epoch 0, Step 3103: train/loss = 0.039310187101364136, train/raw-loss = 0.015025929547846317, train/logprobs = tensor([[ -1.2246, -14.2905],
        [ -7.3719,  -3.1571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24284261465072632
Epoch 0, Step 3104: train/loss = 0.0624861940741539, train/raw-loss = 0.031210558488965034, train/logprobs = tensor([[-1.4893, -9.0757],
        [-8.7459, -2.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31275635957717896
Epoch 0, Step 3105: train/loss = 0.03251628950238228, train/raw-loss = 0.0005566918407566845, train/logprobs = tensor([[ -1.4976, -13.2287],
        [-10.2557,  -1.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31959596276283264
Epoch 0, Step 3106: train/loss = 0.02928626537322998, train/raw-loss = 0.001785909989848733, train/logprobs = tensor([[ -1.2281, -12.5673],
        [ -7.6008,  -1.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750035524368286
Epoch 0, Step 3107: train/loss = 0.029283635318279266, train/raw-loss = 0.0011586957843974233, train/logprobs = tensor([[ -1.4980, -16.6571],
        [-10.1890,  -2.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28124940395355225
Epoch 0, Step 3108: train/loss = 0.03259102255105972, train/raw-loss = 0.003421773901209235, train/logprobs = tensor([[ -1.5000, -12.7714],
        [ -9.2680,  -2.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29169249534606934
Epoch 0, Step 3109: train/loss = 0.02907288447022438, train/raw-loss = 0.004007741808891296, train/logprobs = tensor([[ -1.4269, -16.6953],
        [ -7.0475,  -3.4216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25065141916275024
Epoch 0, Step 3110: train/loss = 0.03705978021025658, train/raw-loss = 0.007336459122598171, train/logprobs = tensor([[ -1.7731, -14.2825],
        [ -8.0554,  -2.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2972332239151001
Epoch 0, Step 3111: train/loss = 0.033389944583177567, train/raw-loss = 0.0027215746231377125, train/logprobs = tensor([[ -1.8170, -15.0627],
        [ -9.7250,  -2.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066836893558502
Epoch 0, Step 3112: train/loss = 0.032996855676174164, train/raw-loss = 0.0001871390122687444, train/logprobs = tensor([[ -1.7786, -14.9176],
        [-10.4856,  -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3280971646308899
Epoch 0, Step 3113: train/loss = 0.03551855683326721, train/raw-loss = 0.004150371998548508, train/logprobs = tensor([[ -1.9189, -12.7970],
        [-10.6872,  -3.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31368187069892883
Epoch 0, Step 3114: train/loss = 0.030904261395335197, train/raw-loss = 0.0034609357826411724, train/logprobs = tensor([[ -1.5848, -14.0117],
        [ -7.1267,  -3.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2744332551956177
Epoch 0, Step 3115: train/loss = 0.045834094285964966, train/raw-loss = 0.015469986945390701, train/logprobs = tensor([[ -1.7314, -12.9181],
        [-10.5527,  -2.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30364108085632324
Epoch 0, Step 3116: train/loss = 0.03420169651508331, train/raw-loss = 0.0018095455598086119, train/logprobs = tensor([[ -0.7463, -10.8627],
        [ -7.2784,  -2.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3239215314388275
Epoch 0, Step 3117: train/loss = 0.02986343577504158, train/raw-loss = 0.0021929373033344746, train/logprobs = tensor([[ -1.4870, -13.6923],
        [ -7.5622,  -2.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767049968242645
Epoch 0, Step 3118: train/loss = 0.03278215229511261, train/raw-loss = 0.0006461722077801824, train/logprobs = tensor([[ -1.2677, -14.1103],
        [ -9.1277,  -2.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213597536087036
Epoch 0, Step 3119: train/loss = 0.0315588004887104, train/raw-loss = 0.0021969545632600784, train/logprobs = tensor([[ -1.7091, -15.7329],
        [ -7.5714,  -3.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29361847043037415
Epoch 0, Step 3120: train/loss = 0.029942870140075684, train/raw-loss = 0.0022036228328943253, train/logprobs = tensor([[-1.7544, -7.8312],
        [-9.2146, -1.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2773924767971039
Epoch 0, Step 3121: train/loss = 0.026409506797790527, train/raw-loss = 0.00011649618681985885, train/logprobs = tensor([[ -1.9930, -15.7110],
        [-10.5474,  -1.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26293009519577026
Epoch 0, Step 3122: train/loss = 0.03290724754333496, train/raw-loss = 0.0014429324073716998, train/logprobs = tensor([[ -0.9196, -13.1413],
        [ -7.6788,  -3.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31464314460754395
Epoch 0, Step 3123: train/loss = 0.029360830783843994, train/raw-loss = 0.0004955019103363156, train/logprobs = tensor([[ -1.5251, -16.8065],
        [ -9.4632,  -3.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28865325450897217
Epoch 0, Step 3124: train/loss = 0.03313418850302696, train/raw-loss = 0.0015471947845071554, train/logprobs = tensor([[-2.3596, -9.5651],
        [-9.4960, -2.6856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158699572086334
Epoch 0, Step 3125: train/loss = 0.0335947722196579, train/raw-loss = 0.0002874741330742836, train/logprobs = tensor([[ -1.1345, -17.7728],
        [ -9.7017,  -3.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330729603767395
Epoch 0, Step 3126: train/loss = 0.030824856832623482, train/raw-loss = 0.00038458092603832483, train/logprobs = tensor([[ -1.2682, -15.6642],
        [ -9.0261,  -2.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30440276861190796
Epoch 0, Step 3127: train/loss = 0.03632427006959915, train/raw-loss = 0.0037300544790923595, train/logprobs = tensor([[ -1.8427, -13.5913],
        [ -9.7856,  -2.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32594215869903564
Epoch 0, Step 3128: train/loss = 0.03544464707374573, train/raw-loss = 0.005698869004845619, train/logprobs = tensor([[ -1.2194, -15.1498],
        [ -7.3588,  -3.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2974577844142914
Epoch 0, Step 3129: train/loss = 0.04006195068359375, train/raw-loss = 0.010084342211484909, train/logprobs = tensor([[ -0.9869, -10.3263],
        [ -6.6060,  -1.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2997760772705078
Epoch 0, Step 3130: train/loss = 0.033357683569192886, train/raw-loss = 0.001920633134432137, train/logprobs = tensor([[ -1.2661, -13.1443],
        [ -8.0303,  -1.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3143704831600189
Epoch 0, Step 3131: train/loss = 0.033017367124557495, train/raw-loss = 0.004010780248790979, train/logprobs = tensor([[ -1.6424, -13.0227],
        [-11.1027,  -2.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900658845901489
Epoch 0, Step 3132: train/loss = 0.03457677364349365, train/raw-loss = 0.002398998709395528, train/logprobs = tensor([[ -1.3248, -10.5229],
        [ -6.9303,  -2.6140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3217777609825134
Epoch 0, Step 3133: train/loss = 0.032810430973768234, train/raw-loss = 0.0036868297029286623, train/logprobs = tensor([[ -1.0760, -12.7280],
        [ -6.1965,  -2.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291236013174057
Epoch 0, Step 3134: train/loss = 0.03180808946490288, train/raw-loss = 0.002519443165510893, train/logprobs = tensor([[ -1.2781, -12.3664],
        [ -8.5127,  -2.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2928864657878876
Epoch 0, Step 3135: train/loss = 0.03134382143616676, train/raw-loss = 0.001684454269707203, train/logprobs = tensor([[ -1.3019, -11.5231],
        [ -8.1030,  -1.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29659366607666016
Epoch 0, Step 3136: train/loss = 0.034616559743881226, train/raw-loss = 0.006438295356929302, train/logprobs = tensor([[ -0.9897, -10.4507],
        [ -6.4639,  -2.0714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817826271057129
Epoch 0, Step 3137: train/loss = 0.02801138162612915, train/raw-loss = 0.0009327142033725977, train/logprobs = tensor([[ -1.1502, -13.4164],
        [ -8.2175,  -3.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27078667283058167
Epoch 0, Step 3138: train/loss = 0.029048815369606018, train/raw-loss = 0.0038931926246732473, train/logprobs = tensor([[ -2.1325, -16.9560],
        [ -7.7789,  -5.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515562176704407
Epoch 0, Step 3139: train/loss = 0.03304814547300339, train/raw-loss = 0.004331011325120926, train/logprobs = tensor([[ -0.9270, -15.7299],
        [ -5.8924,  -2.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871713638305664
Epoch 0, Step 3140: train/loss = 0.033638082444667816, train/raw-loss = 0.00757750915363431, train/logprobs = tensor([[ -1.3197, -12.0780],
        [ -6.1782,  -2.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26060569286346436
Epoch 0, Step 3141: train/loss = 0.033059973269701004, train/raw-loss = 0.001319996314123273, train/logprobs = tensor([[ -1.5053, -14.6730],
        [ -8.4262,  -2.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3173997700214386
Epoch 0, Step 3142: train/loss = 0.02833104506134987, train/raw-loss = 1.6823043551994488e-05, train/logprobs = tensor([[ -2.8866, -19.9912],
        [-13.4570,  -4.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28314220905303955
Epoch 0, Step 3143: train/loss = 0.030970627442002296, train/raw-loss = 0.0018122888868674636, train/logprobs = tensor([[ -1.3784, -19.6857],
        [ -7.4437,  -4.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29158341884613037
Epoch 0, Step 3144: train/loss = 0.032500967383384705, train/raw-loss = 0.0004384048224892467, train/logprobs = tensor([[ -1.3424, -14.3941],
        [ -9.2045,  -2.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3206256330013275
Epoch 0, Step 3145: train/loss = 0.03213481977581978, train/raw-loss = 0.0002563654270488769, train/logprobs = tensor([[ -2.2274, -11.4910],
        [-11.6836,  -2.0761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31878453493118286
Epoch 0, Step 3146: train/loss = 0.06743893027305603, train/raw-loss = 0.03760265186429024, train/logprobs = tensor([[ -1.9709, -14.9821],
        [ -6.9207,  -3.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983627915382385
Epoch 0, Step 3147: train/loss = 0.03237883001565933, train/raw-loss = 0.0003481163876131177, train/logprobs = tensor([[ -1.5844, -15.2668],
        [ -9.7394,  -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3203071355819702
Epoch 0, Step 3148: train/loss = 0.03032069094479084, train/raw-loss = 0.0011328968685120344, train/logprobs = tensor([[ -1.2837, -16.0238],
        [ -7.9200,  -4.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29187795519828796
Epoch 0, Step 3149: train/loss = 0.033488377928733826, train/raw-loss = 0.005479658953845501, train/logprobs = tensor([[ -1.2920, -19.3377],
        [ -6.8722,  -1.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800872027873993
Epoch 0, Step 3150: train/loss = 0.03248991444706917, train/raw-loss = 0.0004991837777197361, train/logprobs = tensor([[ -1.3503, -14.0197],
        [ -8.4651,  -2.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3199073076248169
Epoch 0, Step 3151: train/loss = 0.051934704184532166, train/raw-loss = 0.016337011009454727, train/logprobs = tensor([[-1.1878, -9.1161],
        [-7.2294, -2.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.355976939201355
Epoch 0, Step 3152: train/loss = 0.036255158483982086, train/raw-loss = 0.00603448785841465, train/logprobs = tensor([[ -1.5953, -13.5772],
        [ -8.9157,  -2.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30220669507980347
Epoch 0, Step 3153: train/loss = 0.027901455760002136, train/raw-loss = 0.0025960488710552454, train/logprobs = tensor([[ -1.2136, -20.9721],
        [ -8.2058,  -4.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25305405259132385
Epoch 0, Step 3154: train/loss = 0.033312465995550156, train/raw-loss = 0.0007534332107752562, train/logprobs = tensor([[ -1.6514, -15.9437],
        [ -8.6396,  -2.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3255903422832489
Epoch 0, Step 3155: train/loss = 0.03333292901515961, train/raw-loss = 0.004336848389357328, train/logprobs = tensor([[ -1.2874, -16.6712],
        [ -7.2091,  -4.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2899608016014099
Epoch 0, Step 3156: train/loss = 0.033867064863443375, train/raw-loss = 0.0009166126837953925, train/logprobs = tensor([[ -1.2059, -17.0634],
        [ -8.4015,  -3.5808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32950448989868164
Epoch 0, Step 3157: train/loss = 0.0564902238547802, train/raw-loss = 0.01871771365404129, train/logprobs = tensor([[ -1.3088, -11.5738],
        [ -8.8196,  -2.4092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37772512435913086
Epoch 0, Step 3158: train/loss = 0.02739604562520981, train/raw-loss = 0.0022897347807884216, train/logprobs = tensor([[ -2.1112, -17.1833],
        [ -8.1007,  -4.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510630786418915
Epoch 0, Step 3159: train/loss = 0.042519982904195786, train/raw-loss = 0.009349308907985687, train/logprobs = tensor([[ -1.3146, -10.5562],
        [ -8.8742,  -2.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3317067325115204
Epoch 0, Step 3160: train/loss = 0.03369845822453499, train/raw-loss = 0.0038043702952563763, train/logprobs = tensor([[ -1.6395, -10.9310],
        [ -7.8436,  -2.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29894089698791504
Epoch 0, Step 3161: train/loss = 0.03093412145972252, train/raw-loss = 0.0027833417989313602, train/logprobs = tensor([[ -0.9428, -15.2903],
        [ -6.5466,  -3.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28150779008865356
Epoch 0, Step 3162: train/loss = 0.03132488578557968, train/raw-loss = 0.003565052058547735, train/logprobs = tensor([[ -1.4559, -11.9859],
        [ -7.8529,  -1.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775983214378357
Epoch 0, Step 3163: train/loss = 0.029559224843978882, train/raw-loss = 0.0021737301722168922, train/logprobs = tensor([[ -1.7877, -11.3285],
        [ -9.6455,  -1.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27385494112968445
Epoch 0, Step 3164: train/loss = 0.04282163828611374, train/raw-loss = 0.010524502024054527, train/logprobs = tensor([[ -2.3386, -14.8480],
        [ -9.5882,  -4.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229714035987854
Epoch 0, Step 3165: train/loss = 0.03282686695456505, train/raw-loss = 0.006227669306099415, train/logprobs = tensor([[ -1.0506, -15.0352],
        [ -7.5517,  -3.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659919857978821
Epoch 0, Step 3166: train/loss = 0.03602693974971771, train/raw-loss = 0.002614283701404929, train/logprobs = tensor([[ -1.5778, -12.6770],
        [-10.6272,  -3.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341265618801117
Epoch 0, Step 3167: train/loss = 0.032442186027765274, train/raw-loss = 0.0013621565885841846, train/logprobs = tensor([[ -1.4898, -14.0074],
        [ -8.6366,  -3.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108002543449402
Epoch 0, Step 3168: train/loss = 0.04248405620455742, train/raw-loss = 0.011607463471591473, train/logprobs = tensor([[ -1.8821, -10.2996],
        [ -9.8540,  -2.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30876588821411133
Epoch 0, Step 3169: train/loss = 0.03438379243016243, train/raw-loss = 0.0013379893498495221, train/logprobs = tensor([[ -1.3713, -20.8915],
        [ -8.9789,  -5.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33045798540115356
Epoch 0, Step 3170: train/loss = 0.03153481334447861, train/raw-loss = 0.0008505031000822783, train/logprobs = tensor([[ -1.1943, -14.6777],
        [ -8.4464,  -3.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306843101978302
Epoch 0, Step 3171: train/loss = 0.03051411733031273, train/raw-loss = 0.0016242979327216744, train/logprobs = tensor([[ -0.9657, -18.3748],
        [ -7.1101,  -4.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28889819979667664
Epoch 0, Step 3172: train/loss = 0.03837280720472336, train/raw-loss = 0.003797654528170824, train/logprobs = tensor([[ -1.5857, -12.1176],
        [ -6.8551,  -2.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34575155377388
Epoch 0, Step 3173: train/loss = 0.03469521552324295, train/raw-loss = 0.006083404645323753, train/logprobs = tensor([[ -1.5678, -12.2229],
        [ -7.4402,  -1.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28611814975738525
Epoch 0, Step 3174: train/loss = 0.031240500509738922, train/raw-loss = 0.004030467476695776, train/logprobs = tensor([[ -1.4302, -15.3841],
        [ -7.8934,  -2.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2721003293991089
Epoch 0, Step 3175: train/loss = 0.039373841136693954, train/raw-loss = 0.014388778246939182, train/logprobs = tensor([[ -1.3842, -16.0556],
        [ -7.8133,  -2.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24985063076019287
Epoch 0, Step 3176: train/loss = 0.031090043485164642, train/raw-loss = 0.0010912175057455897, train/logprobs = tensor([[ -1.9057, -13.4194],
        [ -8.5459,  -2.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2999882996082306
Epoch 0, Step 3177: train/loss = 0.027061015367507935, train/raw-loss = 0.0011426906567066908, train/logprobs = tensor([[ -1.5769, -16.6897],
        [ -8.4841,  -3.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25918322801589966
Epoch 0, Step 3178: train/loss = 0.04971073940396309, train/raw-loss = 0.020707590505480766, train/logprobs = tensor([[ -1.3290, -12.2870],
        [ -6.2796,  -2.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900314927101135
Epoch 0, Step 3179: train/loss = 0.033703822642564774, train/raw-loss = 0.0008722341735847294, train/logprobs = tensor([[ -1.1488, -18.7655],
        [ -7.8612,  -4.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3283158838748932
Epoch 0, Step 3180: train/loss = 0.02970011532306671, train/raw-loss = 0.001051564933732152, train/logprobs = tensor([[ -1.6289, -14.9656],
        [ -8.3517,  -4.3890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286485493183136
Epoch 0, Step 3181: train/loss = 0.03370567783713341, train/raw-loss = 0.006075285375118256, train/logprobs = tensor([[ -0.9989, -12.7593],
        [ -6.4843,  -2.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2763039469718933
Epoch 0, Step 3182: train/loss = 0.029118184000253677, train/raw-loss = 5.684348798240535e-05, train/logprobs = tensor([[ -1.8928, -15.6088],
        [-11.4916,  -2.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29061341285705566
Epoch 0, Step 3183: train/loss = 0.03094101883471012, train/raw-loss = 0.00170811265707016, train/logprobs = tensor([[ -1.5988, -12.3617],
        [ -8.2589,  -2.2038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2923290729522705
Epoch 0, Step 3184: train/loss = 0.033408958464860916, train/raw-loss = 0.0030470932833850384, train/logprobs = tensor([[ -1.1830, -11.9251],
        [ -7.0697,  -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3036186099052429
Epoch 0, Step 3185: train/loss = 0.032598406076431274, train/raw-loss = 0.0004814679850824177, train/logprobs = tensor([[ -1.6068, -14.0295],
        [ -9.8349,  -2.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32116934657096863
Epoch 0, Step 3186: train/loss = 0.029809944331645966, train/raw-loss = 0.004333324730396271, train/logprobs = tensor([[ -1.4327, -15.5830],
        [ -7.0344,  -2.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25476619601249695
Epoch 0, Step 3187: train/loss = 0.029407572001218796, train/raw-loss = 0.0018076482228934765, train/logprobs = tensor([[ -1.3275, -14.4156],
        [ -7.9809,  -3.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759992182254791
Epoch 0, Step 3188: train/loss = 0.032536666840314865, train/raw-loss = 0.005512302275747061, train/logprobs = tensor([[ -1.7397, -15.3463],
        [ -8.6181,  -2.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27024364471435547
Epoch 0, Step 3189: train/loss = 0.030718130990862846, train/raw-loss = 0.0021105236373841763, train/logprobs = tensor([[ -1.2806, -16.3068],
        [ -7.0356,  -4.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28607606887817383
Epoch 0, Step 3190: train/loss = 0.03128311038017273, train/raw-loss = 0.000646469765342772, train/logprobs = tensor([[ -1.6649, -15.3041],
        [-10.0222,  -2.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3063664138317108
Epoch 0, Step 3191: train/loss = 0.033522240817546844, train/raw-loss = 0.0013914511073380709, train/logprobs = tensor([[ -1.3641, -16.3767],
        [ -8.6318,  -2.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32130786776542664
Epoch 0, Step 3192: train/loss = 0.0310475192964077, train/raw-loss = 0.004693660885095596, train/logprobs = tensor([[ -1.3679, -15.0502],
        [ -6.5906,  -2.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26353856921195984
Epoch 0, Step 3193: train/loss = 0.03234575316309929, train/raw-loss = 0.00023393164156004786, train/logprobs = tensor([[ -2.0175, -18.4148],
        [-10.9617,  -2.2964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32111820578575134
Epoch 0, Step 3194: train/loss = 0.03208087012171745, train/raw-loss = 0.000977854011580348, train/logprobs = tensor([[ -1.6732, -13.3452],
        [ -9.5996,  -2.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31103014945983887
Epoch 0, Step 3195: train/loss = 0.0335269495844841, train/raw-loss = 0.0028740298002958298, train/logprobs = tensor([[ -1.3711, -14.2645],
        [ -7.5976,  -2.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30652916431427
Epoch 0, Step 3196: train/loss = 0.03093613311648369, train/raw-loss = 0.0003249674919061363, train/logprobs = tensor([[ -1.3683, -13.4626],
        [ -9.7591,  -2.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061116337776184
Epoch 0, Step 3197: train/loss = 0.03217547759413719, train/raw-loss = 0.0017548676114529371, train/logprobs = tensor([[ -1.1540, -14.0244],
        [ -7.7120,  -1.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30420610308647156
Epoch 0, Step 3198: train/loss = 0.039378419518470764, train/raw-loss = 0.0022370219230651855, train/logprobs = tensor([[ -0.9428, -14.6941],
        [ -6.8666,  -2.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3714139759540558
Epoch 0, Step 3199: train/loss = 0.02975398115813732, train/raw-loss = 0.0016272354405373335, train/logprobs = tensor([[ -1.3340, -19.5989],
        [ -8.1616,  -4.6237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812674343585968
Epoch 0, Step 3200: train/loss = 0.031108373776078224, train/raw-loss = 0.005360106937587261, train/logprobs = tensor([[ -1.1112, -22.8026],
        [ -6.5079,  -5.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257482647895813
Epoch 0, Step 3201: train/loss = 0.05078832060098648, train/raw-loss = 0.019253648817539215, train/logprobs = tensor([[ -1.3907, -13.6899],
        [ -6.9655,  -3.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31534671783447266
Epoch 0, Step 3202: train/loss = 0.03303169459104538, train/raw-loss = 0.0023815352469682693, train/logprobs = tensor([[ -1.6041, -14.1864],
        [ -7.8724,  -1.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065015971660614
Epoch 0, Step 3203: train/loss = 0.033218227326869965, train/raw-loss = 0.004423623438924551, train/logprobs = tensor([[ -1.2533, -16.4456],
        [ -6.4989,  -3.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28794607520103455
Epoch 0, Step 3204: train/loss = 0.03249223530292511, train/raw-loss = 0.0005585753242485225, train/logprobs = tensor([[ -1.7541, -12.4232],
        [ -9.6390,  -2.3939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31933659315109253
Epoch 0, Step 3205: train/loss = 0.030151404440402985, train/raw-loss = 0.002956697717308998, train/logprobs = tensor([[ -1.3007, -14.0375],
        [ -7.6160,  -2.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27194708585739136
Epoch 0, Step 3206: train/loss = 0.034908927977085114, train/raw-loss = 0.005034096073359251, train/logprobs = tensor([[ -1.2696, -11.6951],
        [ -7.5185,  -1.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29874831438064575
Epoch 0, Step 3207: train/loss = 0.03442908078432083, train/raw-loss = 0.003168395720422268, train/logprobs = tensor([[ -1.5031, -11.0806],
        [ -7.4923,  -2.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126068711280823
Epoch 0, Step 3208: train/loss = 0.031965237110853195, train/raw-loss = 0.0009741679532453418, train/logprobs = tensor([[ -1.1165, -14.4527],
        [ -8.0432,  -2.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30991071462631226
Epoch 0, Step 3209: train/loss = 0.03334555774927139, train/raw-loss = 0.0005265864310786128, train/logprobs = tensor([[ -1.4079, -14.4354],
        [ -8.4668,  -3.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3281896710395813
Epoch 0, Step 3210: train/loss = 0.03216995298862457, train/raw-loss = 0.009962551295757294, train/logprobs = tensor([[ -1.2637, -13.0772],
        [ -6.3922,  -3.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2220740169286728
Epoch 0, Step 3211: train/loss = 0.032039254903793335, train/raw-loss = 0.0027970708906650543, train/logprobs = tensor([[ -1.2953, -19.1702],
        [ -7.4335,  -3.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292421817779541
Epoch 0, Step 3212: train/loss = 0.031907178461551666, train/raw-loss = 0.0021003037691116333, train/logprobs = tensor([[ -1.4778, -16.3317],
        [ -8.0424,  -3.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2980687618255615
Epoch 0, Step 3213: train/loss = 0.033873096108436584, train/raw-loss = 0.00287351431325078, train/logprobs = tensor([[ -1.4192, -13.7255],
        [ -8.8672,  -3.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3099958002567291
Epoch 0, Step 3214: train/loss = 0.028467044234275818, train/raw-loss = 0.0022971162106841803, train/logprobs = tensor([[ -1.3318, -16.5625],
        [ -7.7052,  -3.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26169925928115845
Epoch 0, Step 3215: train/loss = 0.0437110997736454, train/raw-loss = 0.016651352867484093, train/logprobs = tensor([[ -1.3732, -12.2295],
        [ -5.2438,  -2.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2705974578857422
Epoch 0, Step 3216: train/loss = 0.0336184948682785, train/raw-loss = 0.0025651936884969473, train/logprobs = tensor([[ -1.4902, -15.3399],
        [ -8.8666,  -3.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3105330467224121
Epoch 0, Step 3217: train/loss = 0.028561022132635117, train/raw-loss = 0.001074086525477469, train/logprobs = tensor([[ -1.3157, -14.2506],
        [ -7.5727,  -2.0438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748693823814392
Epoch 0, Step 3218: train/loss = 0.034910961985588074, train/raw-loss = 0.009165752679109573, train/logprobs = tensor([[ -1.3778, -11.6601],
        [ -5.8729,  -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257452130317688
Epoch 0, Step 3219: train/loss = 0.028236031532287598, train/raw-loss = 0.0007463301881216466, train/logprobs = tensor([[ -1.8193, -16.5984],
        [ -8.5751,  -2.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748969793319702
Epoch 0, Step 3220: train/loss = 0.03287074714899063, train/raw-loss = 0.007946876809000969, train/logprobs = tensor([[ -1.6874, -16.3962],
        [ -6.8968,  -2.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24923869967460632
Epoch 0, Step 3221: train/loss = 0.029534727334976196, train/raw-loss = 0.0022924267686903477, train/logprobs = tensor([[ -1.7116, -20.9309],
        [ -7.5292,  -4.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27242299914360046
Epoch 0, Step 3222: train/loss = 0.030187588185071945, train/raw-loss = 0.000966568011790514, train/logprobs = tensor([[ -1.6504, -13.4136],
        [ -8.7195,  -2.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2922102212905884
Epoch 0, Step 3223: train/loss = 0.028600428253412247, train/raw-loss = 0.0004797668952960521, train/logprobs = tensor([[ -2.8010, -17.9653],
        [-11.0517,  -3.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812066078186035
Epoch 0, Step 3224: train/loss = 0.026927273720502853, train/raw-loss = 0.0004759365110658109, train/logprobs = tensor([[ -1.5352, -15.6613],
        [-10.0723,  -2.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26451337337493896
Epoch 0, Step 3225: train/loss = 0.03222588077187538, train/raw-loss = 0.0013634217903017998, train/logprobs = tensor([[ -0.7881, -18.7314],
        [ -6.7360,  -3.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30862459540367126
Epoch 0, Step 3226: train/loss = 0.029791032895445824, train/raw-loss = 0.0013382838806137443, train/logprobs = tensor([[ -1.8024, -11.7240],
        [ -9.0843,  -1.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845275104045868
Epoch 0, Step 3227: train/loss = 0.028575103729963303, train/raw-loss = 0.0004648611356969923, train/logprobs = tensor([[ -1.3703, -15.7443],
        [ -8.9283,  -2.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28110241889953613
Epoch 0, Step 3228: train/loss = 0.029168900102376938, train/raw-loss = 0.0007677910034544766, train/logprobs = tensor([[ -1.5116, -12.5788],
        [ -9.0937,  -2.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840111255645752
Epoch 0, Step 3229: train/loss = 0.0256537776440382, train/raw-loss = 0.0012419307604432106, train/logprobs = tensor([[ -2.2977, -15.2350],
        [-10.2954,  -2.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24411848187446594
Epoch 0, Step 3230: train/loss = 0.09456484019756317, train/raw-loss = 0.07048069685697556, train/logprobs = tensor([[ -2.0294, -17.8039],
        [ -8.1302,  -4.9825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24084146320819855
Epoch 0, Step 3231: train/loss = 0.03187016025185585, train/raw-loss = 0.0015412499196827412, train/logprobs = tensor([[ -1.6025, -16.0880],
        [ -8.1030,  -3.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3032890856266022
Epoch 0, Step 3232: train/loss = 0.031533487141132355, train/raw-loss = 0.00048141679144464433, train/logprobs = tensor([[ -1.5754, -16.2200],
        [ -9.9223,  -1.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3105207085609436
Epoch 0, Step 3233: train/loss = 0.0314861461520195, train/raw-loss = 0.000602888350840658, train/logprobs = tensor([[ -1.3945, -15.2344],
        [ -9.3050,  -3.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088325560092926
Epoch 0, Step 3234: train/loss = 0.08052346110343933, train/raw-loss = 0.04836675152182579, train/logprobs = tensor([[ -1.5452, -10.1025],
        [ -7.9557,  -2.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215671181678772
Epoch 0, Step 3235: train/loss = 0.0305899977684021, train/raw-loss = 0.002612269949167967, train/logprobs = tensor([[ -1.1066, -13.8897],
        [ -6.5332,  -2.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27977728843688965
Epoch 0, Step 3236: train/loss = 0.04848857223987579, train/raw-loss = 0.020332198590040207, train/logprobs = tensor([[ -1.3463, -10.8731],
        [ -7.0573,  -2.0477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28156375885009766
Epoch 0, Step 3237: train/loss = 0.030198827385902405, train/raw-loss = 0.0024911861401051283, train/logprobs = tensor([[ -1.6183, -17.1110],
        [ -7.2645,  -2.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27707639336586
Epoch 0, Step 3238: train/loss = 0.034553978592157364, train/raw-loss = 0.0026572549249976873, train/logprobs = tensor([[ -1.6072, -10.9703],
        [ -8.0814,  -1.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3189672529697418
Epoch 0, Step 3239: train/loss = 0.029961522668600082, train/raw-loss = 0.0003752622287720442, train/logprobs = tensor([[ -1.7826, -15.2136],
        [ -9.7142,  -2.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29586261510849
Epoch 0, Step 3240: train/loss = 0.029170628637075424, train/raw-loss = 0.00082288624253124, train/logprobs = tensor([[ -1.9312, -14.1251],
        [ -8.8619,  -4.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28347742557525635
Epoch 0, Step 3241: train/loss = 0.03446810320019722, train/raw-loss = 0.0018911671359091997, train/logprobs = tensor([[ -2.4258,  -9.2628],
        [-11.5120,  -2.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3257693648338318
Epoch 0, Step 3242: train/loss = 0.028745871037244797, train/raw-loss = 0.0022253517527133226, train/logprobs = tensor([[ -1.5266, -17.0614],
        [ -7.7958,  -3.0073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652052044868469
Epoch 0, Step 3243: train/loss = 0.031648531556129456, train/raw-loss = 0.002251025289297104, train/logprobs = tensor([[ -1.2270, -20.9945],
        [ -6.8871,  -3.1328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29397502541542053
Epoch 0, Step 3244: train/loss = 0.03109677881002426, train/raw-loss = 0.0033362372778356075, train/logprobs = tensor([[ -1.6742, -10.0325],
        [ -8.4044,  -2.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27760541439056396
Epoch 0, Step 3245: train/loss = 0.02532724291086197, train/raw-loss = 0.0010213078930974007, train/logprobs = tensor([[ -2.7499, -20.4188],
        [ -9.1376,  -6.1540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24305933713912964
Epoch 0, Step 3246: train/loss = 0.027102362364530563, train/raw-loss = 0.0027850710321217775, train/logprobs = tensor([[ -2.7546, -12.8534],
        [ -9.9155,  -3.2285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24317288398742676
Epoch 0, Step 3247: train/loss = 0.027740567922592163, train/raw-loss = 0.0009449039353057742, train/logprobs = tensor([[ -1.8137, -11.2206],
        [-10.0422,  -2.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679566442966461
Epoch 0, Step 3248: train/loss = 0.027875255793333054, train/raw-loss = 0.001945188269019127, train/logprobs = tensor([[ -1.6643, -13.5567],
        [ -8.2024,  -2.2607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25930067896842957
Epoch 0, Step 3249: train/loss = 0.029122648760676384, train/raw-loss = 0.0010671390919014812, train/logprobs = tensor([[ -1.6065, -12.0785],
        [ -8.0366,  -1.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805550694465637
Epoch 0, Step 3250: train/loss = 0.028396042063832283, train/raw-loss = 0.0016305582830682397, train/logprobs = tensor([[ -1.6349, -20.4630],
        [ -8.2925,  -3.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676548361778259
Epoch 0, Step 3251: train/loss = 0.027085453271865845, train/raw-loss = 0.001613062690012157, train/logprobs = tensor([[ -1.5993, -20.0406],
        [ -8.9964,  -3.4379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547238767147064
Epoch 0, Step 3252: train/loss = 0.03258516639471054, train/raw-loss = 0.0037495014257729053, train/logprobs = tensor([[ -1.1439, -12.6070],
        [ -6.5296,  -3.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883566617965698
Epoch 0, Step 3253: train/loss = 0.03342535346746445, train/raw-loss = 0.000758081441745162, train/logprobs = tensor([[ -1.4879, -17.3595],
        [ -8.7614,  -3.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266727030277252
Epoch 0, Step 3254: train/loss = 0.034480080008506775, train/raw-loss = 0.003177198115736246, train/logprobs = tensor([[ -1.4456, -13.2085],
        [ -9.0126,  -2.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31302881240844727
Epoch 0, Step 3255: train/loss = 0.028892992064356804, train/raw-loss = 0.0004128921136725694, train/logprobs = tensor([[ -1.4473, -14.9215],
        [ -9.4768,  -3.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2848009765148163
Epoch 0, Step 3256: train/loss = 0.03268090635538101, train/raw-loss = 0.00020984699949622154, train/logprobs = tensor([[ -1.6822, -17.7363],
        [-10.6942,  -4.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32471054792404175
Epoch 0, Step 3257: train/loss = 0.03976579010486603, train/raw-loss = 0.0035027707926928997, train/logprobs = tensor([[ -1.1296, -14.3807],
        [ -7.5101,  -2.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362630158662796
Epoch 0, Step 3258: train/loss = 0.0351468026638031, train/raw-loss = 0.004898393526673317, train/logprobs = tensor([[ -1.3818, -13.0358],
        [ -8.4110,  -2.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30248409509658813
Epoch 0, Step 3259: train/loss = 0.030079515650868416, train/raw-loss = 0.0015452016377821565, train/logprobs = tensor([[ -1.9148, -16.2805],
        [ -8.5337,  -2.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28534314036369324
Epoch 0, Step 3260: train/loss = 0.03740750253200531, train/raw-loss = 0.010494064539670944, train/logprobs = tensor([[ -1.4574, -12.1107],
        [ -5.9007,  -1.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691343426704407
Epoch 0, Step 3261: train/loss = 0.030435258522629738, train/raw-loss = 0.00021811782789882272, train/logprobs = tensor([[ -1.6278, -16.7891],
        [ -9.9414,  -3.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30217140913009644
Epoch 0, Step 3262: train/loss = 0.033263348042964935, train/raw-loss = 0.0010717824334278703, train/logprobs = tensor([[ -1.3007, -20.5393],
        [ -8.5337,  -4.5653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219156563282013
Epoch 0, Step 3263: train/loss = 0.027247680351138115, train/raw-loss = 0.0034165503457188606, train/logprobs = tensor([[ -1.8674, -20.2479],
        [ -8.0032,  -5.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.238311305642128
Epoch 0, Step 3264: train/loss = 0.04154658317565918, train/raw-loss = 0.010724855586886406, train/logprobs = tensor([[ -0.9832, -11.9736],
        [ -6.1801,  -2.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30821722745895386
Epoch 0, Step 3265: train/loss = 0.033950190991163254, train/raw-loss = 0.001202308339998126, train/logprobs = tensor([[ -1.7889, -13.5144],
        [ -8.7968,  -2.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3274787664413452
Epoch 0, Step 3266: train/loss = 0.028660699725151062, train/raw-loss = 0.0023852812591940165, train/logprobs = tensor([[ -1.3781, -18.7793],
        [ -8.1379,  -2.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2627542018890381
Epoch 0, Step 3267: train/loss = 0.03273215889930725, train/raw-loss = 0.003220433136448264, train/logprobs = tensor([[ -1.1758, -11.3576],
        [ -7.7388,  -2.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29511725902557373
Epoch 0, Step 3268: train/loss = 0.030879788100719452, train/raw-loss = 0.0008696865988895297, train/logprobs = tensor([[ -1.1507, -12.7982],
        [ -8.2446,  -2.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30010098218917847
Epoch 0, Step 3269: train/loss = 0.031992003321647644, train/raw-loss = 0.004292449913918972, train/logprobs = tensor([[ -1.1903, -15.5829],
        [ -6.8508,  -2.6875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27699553966522217
Epoch 0, Step 3270: train/loss = 0.03232625499367714, train/raw-loss = 0.0037545859813690186, train/logprobs = tensor([[ -1.3346, -10.4200],
        [ -6.9867,  -2.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857166826725006
Epoch 0, Step 3271: train/loss = 0.027870679274201393, train/raw-loss = 0.0014635168481618166, train/logprobs = tensor([[ -1.1460, -18.3453],
        [ -7.8925,  -4.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26407161355018616
Epoch 0, Step 3272: train/loss = 0.02884732000529766, train/raw-loss = 0.0010213189525529742, train/logprobs = tensor([[ -1.8072, -16.0802],
        [ -8.8832,  -2.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782599925994873
Epoch 0, Step 3273: train/loss = 0.030675485730171204, train/raw-loss = 0.0035286119673401117, train/logprobs = tensor([[ -1.2468, -11.1837],
        [ -7.0585,  -2.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27146875858306885
Epoch 0, Step 3274: train/loss = 0.03448430076241493, train/raw-loss = 0.0035718500148504972, train/logprobs = tensor([[ -1.1236, -14.5517],
        [ -6.9905,  -2.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30912449955940247
Epoch 0, Step 3275: train/loss = 0.03349072486162186, train/raw-loss = 0.002254556166008115, train/logprobs = tensor([[ -1.5251, -17.5127],
        [ -7.6397,  -4.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3123616874217987
Epoch 0, Step 3276: train/loss = 0.029495632275938988, train/raw-loss = 0.0012780602555721998, train/logprobs = tensor([[ -1.8366, -13.6831],
        [ -9.1812,  -3.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2821757197380066
Epoch 0, Step 3277: train/loss = 0.03036862425506115, train/raw-loss = 0.006005189381539822, train/logprobs = tensor([[ -1.2932, -11.7785],
        [ -7.4309,  -2.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24363434314727783
Epoch 0, Step 3278: train/loss = 0.03018035739660263, train/raw-loss = 0.0013776543783023953, train/logprobs = tensor([[ -1.3695, -15.6184],
        [ -7.4137,  -3.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2880270481109619
Epoch 0, Step 3279: train/loss = 0.027928786352276802, train/raw-loss = 0.0014544387813657522, train/logprobs = tensor([[ -1.7786, -12.9705],
        [ -9.2167,  -2.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26474347710609436
Epoch 0, Step 3280: train/loss = 0.02812342531979084, train/raw-loss = 0.003576240735128522, train/logprobs = tensor([[ -1.6023, -14.5390],
        [ -7.5138,  -3.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24547183513641357
Epoch 0, Step 3281: train/loss = 0.028386190533638, train/raw-loss = 0.0009036014089360833, train/logprobs = tensor([[ -1.3205, -17.9835],
        [ -7.7999,  -3.1930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27482590079307556
Epoch 0, Step 3282: train/loss = 0.03069000318646431, train/raw-loss = 0.0006953286356292665, train/logprobs = tensor([[ -1.4501, -13.4364],
        [ -8.7340,  -2.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29994675517082214
Epoch 0, Step 3283: train/loss = 0.03220467269420624, train/raw-loss = 0.002450608415529132, train/logprobs = tensor([[ -1.9456, -12.0483],
        [ -9.3205,  -2.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29754066467285156
Epoch 0, Step 3284: train/loss = 0.03762972354888916, train/raw-loss = 0.009365570731461048, train/logprobs = tensor([[ -1.8869, -12.3937],
        [ -6.6104,  -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28264153003692627
Epoch 0, Step 3285: train/loss = 0.03215935826301575, train/raw-loss = 0.005147196818143129, train/logprobs = tensor([[ -1.0831, -14.8754],
        [ -6.8553,  -3.8801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27012160420417786
Epoch 0, Step 3286: train/loss = 0.026907600462436676, train/raw-loss = 0.001595012960024178, train/logprobs = tensor([[ -1.5909, -11.3968],
        [ -8.4446,  -2.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531258761882782
Epoch 0, Step 3287: train/loss = 0.03158636763691902, train/raw-loss = 0.000510259298607707, train/logprobs = tensor([[ -1.6530, -16.8429],
        [ -9.5919,  -3.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31076109409332275
Epoch 0, Step 3288: train/loss = 0.030585773289203644, train/raw-loss = 0.001131228869780898, train/logprobs = tensor([[ -1.1435, -16.1081],
        [ -7.2490,  -2.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29454541206359863
Epoch 0, Step 3289: train/loss = 0.03388947993516922, train/raw-loss = 0.005299707874655724, train/logprobs = tensor([[ -1.1755, -15.4317],
        [ -7.5646,  -3.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28589773178100586
Epoch 0, Step 3290: train/loss = 0.05043169483542442, train/raw-loss = 0.015668272972106934, train/logprobs = tensor([[ -1.1358, -13.7333],
        [ -6.6790,  -3.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3476341962814331
Epoch 0, Step 3291: train/loss = 0.03319082781672478, train/raw-loss = 0.0008966712048277259, train/logprobs = tensor([[ -1.5369, -13.2311],
        [ -8.5842,  -2.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32294154167175293
Epoch 0, Step 3292: train/loss = 0.03230386972427368, train/raw-loss = 0.0010833399137482047, train/logprobs = tensor([[ -2.1828, -13.0773],
        [-10.1782,  -2.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3122052848339081
Epoch 0, Step 3293: train/loss = 0.033060695976018906, train/raw-loss = 0.0026560777332633734, train/logprobs = tensor([[ -1.2483, -17.4438],
        [ -7.4054,  -3.5967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040461540222168
Epoch 0, Step 3294: train/loss = 0.03089398518204689, train/raw-loss = 0.0023377416655421257, train/logprobs = tensor([[ -1.9455, -13.4694],
        [ -8.6142,  -1.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855624258518219
Epoch 0, Step 3295: train/loss = 0.03177022188901901, train/raw-loss = 0.0016304999589920044, train/logprobs = tensor([[ -1.4609, -14.3674],
        [ -7.5573,  -3.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013972043991089
Epoch 0, Step 3296: train/loss = 0.028012089431285858, train/raw-loss = 0.003124903654679656, train/logprobs = tensor([[ -2.1171, -17.4106],
        [ -7.7283,  -2.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24887186288833618
Epoch 0, Step 3297: train/loss = 0.038680434226989746, train/raw-loss = 0.00696515804156661, train/logprobs = tensor([[ -0.9421, -14.5026],
        [ -7.0983,  -2.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.317152738571167
Epoch 0, Step 3298: train/loss = 0.03327883407473564, train/raw-loss = 0.004786072764545679, train/logprobs = tensor([[ -0.9776, -16.3744],
        [ -5.7399,  -3.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849276065826416
Epoch 0, Step 3299: train/loss = 0.03235621005296707, train/raw-loss = 0.0020709875971078873, train/logprobs = tensor([[ -0.9318, -13.3129],
        [ -7.4418,  -2.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30285221338272095
Epoch 0, Step 3300: train/loss = 0.03008555807173252, train/raw-loss = 0.0012926330091431737, train/logprobs = tensor([[ -1.6123, -16.1920],
        [ -8.7805,  -2.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879292368888855
Epoch 0, Step 3301: train/loss = 0.03069126605987549, train/raw-loss = 0.0011337997857481241, train/logprobs = tensor([[ -1.6756, -13.8690],
        [ -9.7940,  -3.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955746650695801
Epoch 0, Step 3302: train/loss = 0.032674640417099, train/raw-loss = 0.005440157372504473, train/logprobs = tensor([[ -2.0415, -11.6313],
        [ -7.3097,  -3.5456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27234482765197754
Epoch 0, Step 3303: train/loss = 0.031407732516527176, train/raw-loss = 0.0018314261687919497, train/logprobs = tensor([[ -1.3034, -13.8759],
        [ -7.5238,  -2.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957630753517151
Epoch 0, Step 3304: train/loss = 0.04080859571695328, train/raw-loss = 0.011685024946928024, train/logprobs = tensor([[ -2.1893, -11.9763],
        [ -9.4612,  -3.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29123571515083313
Epoch 0, Step 3305: train/loss = 0.037148892879486084, train/raw-loss = 0.00650810869410634, train/logprobs = tensor([[ -1.2904, -13.6916],
        [ -8.5048,  -2.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064078390598297
Epoch 0, Step 3306: train/loss = 0.03478299453854561, train/raw-loss = 0.0028330914210528135, train/logprobs = tensor([[ -2.0907, -11.7957],
        [-10.3466,  -2.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31949901580810547
Epoch 0, Step 3307: train/loss = 0.030472468584775925, train/raw-loss = 0.0017071026377379894, train/logprobs = tensor([[ -1.4302, -11.8540],
        [ -7.7543,  -1.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876536548137665
Epoch 0, Step 3308: train/loss = 0.029888153076171875, train/raw-loss = 0.001800076337531209, train/logprobs = tensor([[ -1.8646, -16.8280],
        [ -8.7048,  -3.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28088077902793884
Epoch 0, Step 3309: train/loss = 0.03140490502119064, train/raw-loss = 0.0053988792933523655, train/logprobs = tensor([[ -2.4369, -10.7530],
        [ -9.9171,  -1.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26006025075912476
Epoch 0, Step 3310: train/loss = 0.027828829362988472, train/raw-loss = 0.0027532149106264114, train/logprobs = tensor([[ -1.3314, -19.6098],
        [ -7.5890,  -4.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507561445236206
Epoch 0, Step 3311: train/loss = 0.032782915979623795, train/raw-loss = 0.0024123117327690125, train/logprobs = tensor([[ -1.2795, -24.4014],
        [ -7.4715,  -6.3115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30370602011680603
Epoch 0, Step 3312: train/loss = 0.027893511578440666, train/raw-loss = 0.002946032676845789, train/logprobs = tensor([[ -1.9464, -19.7178],
        [ -8.2571,  -5.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24947480857372284
Epoch 0, Step 3313: train/loss = 0.033930398523807526, train/raw-loss = 0.0007820112514309585, train/logprobs = tensor([[ -1.2429, -16.6185],
        [ -8.0272,  -4.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314839005470276
Epoch 0, Step 3314: train/loss = 0.02638084813952446, train/raw-loss = 0.0008713600691407919, train/logprobs = tensor([[ -1.9610, -19.9179],
        [ -9.1360,  -2.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25509488582611084
Epoch 0, Step 3315: train/loss = 0.03132718801498413, train/raw-loss = 0.0023023542016744614, train/logprobs = tensor([[ -1.2044, -20.2185],
        [ -6.8224,  -4.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902483344078064
Epoch 0, Step 3316: train/loss = 0.030266594141721725, train/raw-loss = 0.0005828143912367523, train/logprobs = tensor([[ -1.7323, -13.2477],
        [ -9.1179,  -1.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29683780670166016
Epoch 0, Step 3317: train/loss = 0.0343238040804863, train/raw-loss = 0.009328230284154415, train/logprobs = tensor([[ -1.3585, -12.8122],
        [ -7.3170,  -2.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24995574355125427
Epoch 0, Step 3318: train/loss = 0.032705627381801605, train/raw-loss = 0.0025420577730983496, train/logprobs = tensor([[ -1.3281, -17.1905],
        [ -6.9072,  -4.3301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016357123851776
Epoch 0, Step 3319: train/loss = 0.034478526562452316, train/raw-loss = 0.00260515627451241, train/logprobs = tensor([[ -2.0388, -19.6868],
        [ -9.0784,  -4.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31873369216918945
Epoch 0, Step 3320: train/loss = 0.02665933035314083, train/raw-loss = 0.0007845389191061258, train/logprobs = tensor([[ -1.6326, -15.3331],
        [ -9.0386,  -3.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2587479054927826
Epoch 0, Step 3321: train/loss = 0.034016408026218414, train/raw-loss = 0.0039809634909033775, train/logprobs = tensor([[ -1.4045, -11.8284],
        [ -7.1556,  -2.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003544211387634
Epoch 0, Step 3322: train/loss = 0.027294736355543137, train/raw-loss = 0.001095943502150476, train/logprobs = tensor([[ -1.3521, -14.0484],
        [ -8.6415,  -2.4552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26198792457580566
Epoch 0, Step 3323: train/loss = 0.0308370403945446, train/raw-loss = 0.0003731664619408548, train/logprobs = tensor([[ -1.5094, -21.9326],
        [ -9.1986,  -5.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30463874340057373
Epoch 0, Step 3324: train/loss = 0.0314880795776844, train/raw-loss = 0.0032627845648676157, train/logprobs = tensor([[ -0.9832, -14.1583],
        [ -7.4237,  -2.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822529673576355
Epoch 0, Step 3325: train/loss = 0.05320668965578079, train/raw-loss = 0.02340381033718586, train/logprobs = tensor([[ -2.8146, -16.2758],
        [-10.0434,  -2.4098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29802873730659485
Epoch 0, Step 3326: train/loss = 0.03397016599774361, train/raw-loss = 0.0017506962176412344, train/logprobs = tensor([[ -1.6904, -13.2094],
        [ -7.4825,  -2.9066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32219475507736206
Epoch 0, Step 3327: train/loss = 0.03329908102750778, train/raw-loss = 0.007424566894769669, train/logprobs = tensor([[ -1.9229, -13.9156],
        [ -8.4929,  -3.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25874513387680054
Epoch 0, Step 3328: train/loss = 0.02777099609375, train/raw-loss = 0.001000227639451623, train/logprobs = tensor([[ -1.4448, -16.7495],
        [ -8.1094,  -3.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2677076756954193
Epoch 0, Step 3329: train/loss = 0.02898961864411831, train/raw-loss = 0.0035547350998967886, train/logprobs = tensor([[ -1.2413, -19.7243],
        [ -6.4757,  -4.4939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25434884428977966
Epoch 0, Step 3330: train/loss = 0.05183251574635506, train/raw-loss = 0.026100443676114082, train/logprobs = tensor([[ -2.2156, -20.8809],
        [-10.0770,  -3.5034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25732073187828064
Epoch 0, Step 3331: train/loss = 0.037564780563116074, train/raw-loss = 0.008950229734182358, train/logprobs = tensor([[ -1.5801, -15.8906],
        [ -7.5752,  -3.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28614550828933716
Epoch 0, Step 3332: train/loss = 0.031695406883955, train/raw-loss = 0.0027738078497350216, train/logprobs = tensor([[ -1.2532, -20.2829],
        [ -7.2135,  -2.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28921598196029663
Epoch 0, Step 3333: train/loss = 0.032840073108673096, train/raw-loss = 0.0041857510805130005, train/logprobs = tensor([[ -1.5202, -15.3165],
        [ -7.9188,  -4.4186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28654322028160095
Epoch 0, Step 3334: train/loss = 0.02674912102520466, train/raw-loss = 0.002564165275543928, train/logprobs = tensor([[ -1.8142, -16.1237],
        [ -9.4433,  -3.6677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24184954166412354
Epoch 0, Step 3335: train/loss = 0.031189214438199997, train/raw-loss = 0.0058022430166602135, train/logprobs = tensor([[ -2.0895, -13.9686],
        [ -8.1632,  -2.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538697123527527
Epoch 0, Step 3336: train/loss = 0.0268465094268322, train/raw-loss = 0.0006633696029894054, train/logprobs = tensor([[ -1.7266, -20.2882],
        [ -9.6423,  -5.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618314027786255
Epoch 0, Step 3337: train/loss = 0.026544488966464996, train/raw-loss = 0.0014859337825328112, train/logprobs = tensor([[ -1.6828, -16.9226],
        [ -7.9555,  -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25058555603027344
Epoch 0, Step 3338: train/loss = 0.031919628381729126, train/raw-loss = 0.0010300509165972471, train/logprobs = tensor([[ -1.0955, -16.8023],
        [ -7.5994,  -3.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088957667350769
Epoch 0, Step 3339: train/loss = 0.028948739171028137, train/raw-loss = 0.0012328007724136114, train/logprobs = tensor([[ -1.6954, -17.6208],
        [ -9.1538,  -3.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27715936303138733
Epoch 0, Step 3340: train/loss = 0.02655711956322193, train/raw-loss = 0.0010274210944771767, train/logprobs = tensor([[ -1.8389, -18.0001],
        [ -8.8194,  -4.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2552969455718994
Epoch 0, Step 3341: train/loss = 0.03166472911834717, train/raw-loss = 0.001008050749078393, train/logprobs = tensor([[ -1.5786, -14.6447],
        [ -8.7632,  -3.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065667748451233
Epoch 0, Step 3342: train/loss = 0.05972205102443695, train/raw-loss = 0.030161147937178612, train/logprobs = tensor([[ -1.1592, -10.0205],
        [ -4.6869,  -1.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956089973449707
Epoch 0, Step 3343: train/loss = 0.029130758717656136, train/raw-loss = 0.001354399835690856, train/logprobs = tensor([[ -1.8703, -12.6227],
        [ -8.5346,  -3.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27776360511779785
Epoch 0, Step 3344: train/loss = 0.030992215499281883, train/raw-loss = 0.0034115861635655165, train/logprobs = tensor([[ -1.3437, -10.4371],
        [ -7.6161,  -2.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758062779903412
Epoch 0, Step 3345: train/loss = 0.031181396916508675, train/raw-loss = 0.0019614160992205143, train/logprobs = tensor([[ -1.0955, -16.1279],
        [ -7.2258,  -1.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2921997904777527
Epoch 0, Step 3346: train/loss = 0.032565418630838394, train/raw-loss = 0.002102895639836788, train/logprobs = tensor([[ -1.4397, -12.6660],
        [ -8.2332,  -1.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3046252131462097
Epoch 0, Step 3347: train/loss = 0.028904784470796585, train/raw-loss = 0.0007236161036416888, train/logprobs = tensor([[ -2.1772, -11.8135],
        [-10.4476,  -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2818117141723633
Epoch 0, Step 3348: train/loss = 0.03166894614696503, train/raw-loss = 0.0009165065712295473, train/logprobs = tensor([[ -1.8545, -15.6596],
        [ -8.5055,  -2.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3075244128704071
Epoch 0, Step 3349: train/loss = 0.02607501670718193, train/raw-loss = 0.001125925569795072, train/logprobs = tensor([[ -1.4437, -18.9359],
        [ -7.8098,  -4.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.249490886926651
Epoch 0, Step 3350: train/loss = 0.03404812887310982, train/raw-loss = 0.005741198547184467, train/logprobs = tensor([[ -1.7146, -14.2933],
        [ -8.3204,  -3.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28306931257247925
Epoch 0, Step 3351: train/loss = 0.02948046289384365, train/raw-loss = 0.0008955704979598522, train/logprobs = tensor([[ -1.3136, -14.5670],
        [ -9.1247,  -1.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2858489453792572
Epoch 0, Step 3352: train/loss = 0.027215827256441116, train/raw-loss = 0.00037297350354492664, train/logprobs = tensor([[ -1.8193, -20.5429],
        [ -9.4170,  -4.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2684285342693329
Epoch 0, Step 3353: train/loss = 0.029208112508058548, train/raw-loss = 0.0016025640070438385, train/logprobs = tensor([[ -1.6788, -14.1702],
        [ -8.0589,  -2.4345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760554850101471
Epoch 0, Step 3354: train/loss = 0.028477763757109642, train/raw-loss = 0.0019648924935609102, train/logprobs = tensor([[ -1.1973, -10.1917],
        [ -7.1964,  -2.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651287019252777
Epoch 0, Step 3355: train/loss = 0.03488264977931976, train/raw-loss = 0.003968454897403717, train/logprobs = tensor([[ -0.8776, -15.0684],
        [ -6.0310,  -3.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30914193391799927
Epoch 0, Step 3356: train/loss = 0.027464132755994797, train/raw-loss = 0.0026109979953616858, train/logprobs = tensor([[ -1.6945, -16.3389],
        [ -7.7997,  -3.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24853135645389557
Epoch 0, Step 3357: train/loss = 0.034995079040527344, train/raw-loss = 0.0010338985593989491, train/logprobs = tensor([[ -1.3582, -12.2648],
        [ -9.2462,  -2.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33961179852485657
Epoch 0, Step 3358: train/loss = 0.03387646749615669, train/raw-loss = 0.0057691363617777824, train/logprobs = tensor([[ -1.2062, -10.6563],
        [ -6.0214,  -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28107333183288574
Epoch 0, Step 3359: train/loss = 0.035634979605674744, train/raw-loss = 0.009114013984799385, train/logprobs = tensor([[ -1.3773, -15.4244],
        [ -6.1565,  -4.3861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652096748352051
Epoch 0, Step 3360: train/loss = 0.03298930451273918, train/raw-loss = 0.0009428893681615591, train/logprobs = tensor([[ -1.8153, -15.4453],
        [ -8.7883,  -3.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3204641342163086
Epoch 0, Step 3361: train/loss = 0.03396282717585564, train/raw-loss = 0.009733166545629501, train/logprobs = tensor([[ -2.4261, -10.0429],
        [ -6.9538,  -1.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24229660630226135
Epoch 0, Step 3362: train/loss = 0.0354924201965332, train/raw-loss = 0.005522551015019417, train/logprobs = tensor([[ -1.4647, -12.5715],
        [ -6.5842,  -2.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29969871044158936
Epoch 0, Step 3363: train/loss = 0.029598476365208626, train/raw-loss = 0.0027001488488167524, train/logprobs = tensor([[ -1.4132, -12.7731],
        [ -8.2967,  -1.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26898327469825745
Epoch 0, Step 3364: train/loss = 0.0285524632781744, train/raw-loss = 0.0013328006025403738, train/logprobs = tensor([[ -2.5028, -12.7856],
        [ -9.6589,  -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27219662070274353
Epoch 0, Step 3365: train/loss = 0.036120109260082245, train/raw-loss = 0.011026397347450256, train/logprobs = tensor([[ -1.2767, -12.6594],
        [ -5.9480,  -1.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2509370744228363
Epoch 0, Step 3366: train/loss = 0.030858146026730537, train/raw-loss = 0.0012006082106381655, train/logprobs = tensor([[ -1.5817, -16.2623],
        [ -8.3646,  -3.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965753674507141
Epoch 0, Step 3367: train/loss = 0.0272658858448267, train/raw-loss = 0.001063000876456499, train/logprobs = tensor([[ -1.9236, -15.4798],
        [ -8.3351,  -3.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2620288133621216
Epoch 0, Step 3368: train/loss = 0.027680842205882072, train/raw-loss = 0.00193292205221951, train/logprobs = tensor([[ -1.4605, -17.2898],
        [ -8.3259,  -2.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257479190826416
Epoch 0, Step 3369: train/loss = 0.03454079106450081, train/raw-loss = 0.0020367144607007504, train/logprobs = tensor([[ -1.5160, -18.5636],
        [ -8.1216,  -2.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250407576560974
Epoch 0, Step 3370: train/loss = 0.030049793422222137, train/raw-loss = 0.004827051889151335, train/logprobs = tensor([[ -1.5114, -11.4604],
        [ -6.6995,  -1.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25222742557525635
Epoch 0, Step 3371: train/loss = 0.03215501084923744, train/raw-loss = 0.002204079180955887, train/logprobs = tensor([[ -0.8560, -14.6278],
        [ -6.6936,  -2.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29950928688049316
Epoch 0, Step 3372: train/loss = 0.029546761885285378, train/raw-loss = 0.0016575431218370795, train/logprobs = tensor([[ -1.7215, -16.6815],
        [ -7.9755,  -3.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788921594619751
Epoch 0, Step 3373: train/loss = 0.031805552542209625, train/raw-loss = 0.0030702194198966026, train/logprobs = tensor([[ -1.3879, -17.8890],
        [ -7.7217,  -4.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873533070087433
Epoch 0, Step 3374: train/loss = 0.03159533441066742, train/raw-loss = 0.000322384963510558, train/logprobs = tensor([[ -1.8189, -15.6976],
        [-10.0033,  -3.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31272947788238525
Epoch 0, Step 3375: train/loss = 0.03018783964216709, train/raw-loss = 0.0015560343163087964, train/logprobs = tensor([[ -1.0508, -13.6386],
        [ -7.2569,  -2.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863180637359619
Epoch 0, Step 3376: train/loss = 0.0257098525762558, train/raw-loss = 0.0014215954579412937, train/logprobs = tensor([[ -1.1363, -25.0417],
        [ -7.5219,  -4.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24288257956504822
Epoch 0, Step 3377: train/loss = 0.032624442130327225, train/raw-loss = 0.003443624824285507, train/logprobs = tensor([[ -1.2110, -16.5884],
        [ -6.3682,  -4.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29180818796157837
Epoch 0, Step 3378: train/loss = 0.03275873884558678, train/raw-loss = 0.006074401084333658, train/logprobs = tensor([[ -1.5520, -13.6024],
        [ -7.0238,  -3.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26684337854385376
Epoch 0, Step 3379: train/loss = 0.030366890132427216, train/raw-loss = 0.0008677903097122908, train/logprobs = tensor([[ -1.8238, -17.5896],
        [ -8.8057,  -4.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29499098658561707
Epoch 0, Step 3380: train/loss = 0.04793673753738403, train/raw-loss = 0.022675592452287674, train/logprobs = tensor([[ -1.5545, -18.0011],
        [ -8.1104,  -3.9239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526114284992218
Epoch 0, Step 3381: train/loss = 0.03295902907848358, train/raw-loss = 0.004474665503948927, train/logprobs = tensor([[ -1.2968, -20.2608],
        [ -6.5373,  -5.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28484368324279785
Epoch 0, Step 3382: train/loss = 0.03269429877400398, train/raw-loss = 0.001260871533304453, train/logprobs = tensor([[ -1.5040, -19.3511],
        [ -7.6658,  -3.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3143342435359955
Epoch 0, Step 3383: train/loss = 0.04395782947540283, train/raw-loss = 0.009854864329099655, train/logprobs = tensor([[ -1.5270, -10.1103],
        [ -7.8900,  -2.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34102964401245117
Epoch 0, Step 3384: train/loss = 0.02953648380935192, train/raw-loss = 0.002514271065592766, train/logprobs = tensor([[ -1.6821, -15.8135],
        [ -7.3834,  -3.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27022212743759155
Epoch 0, Step 3385: train/loss = 0.0312594473361969, train/raw-loss = 0.0026972496416419744, train/logprobs = tensor([[ -1.7258, -13.7781],
        [ -8.1297,  -2.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856219410896301
Epoch 0, Step 3386: train/loss = 0.03915582224726677, train/raw-loss = 0.009389863349497318, train/logprobs = tensor([[ -1.2666, -11.2540],
        [ -6.7302,  -2.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29765963554382324
Epoch 0, Step 3387: train/loss = 0.028021972626447678, train/raw-loss = 0.001406259834766388, train/logprobs = tensor([[ -1.3504, -11.6628],
        [ -8.0868,  -2.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661571502685547
Epoch 0, Step 3388: train/loss = 0.026970036327838898, train/raw-loss = 0.0006632941658608615, train/logprobs = tensor([[ -2.2022, -12.4668],
        [-10.6840,  -2.4405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26306742429733276
Epoch 0, Step 3389: train/loss = 0.027816005051136017, train/raw-loss = 0.00274802278727293, train/logprobs = tensor([[ -1.6587, -15.2710],
        [ -8.1666,  -1.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25067979097366333
Epoch 0, Step 3390: train/loss = 0.028815865516662598, train/raw-loss = 0.0008284550858661532, train/logprobs = tensor([[ -2.0716, -13.2580],
        [ -9.1634,  -2.3718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798740863800049
Epoch 0, Step 3391: train/loss = 0.04408754035830498, train/raw-loss = 0.018136953935027122, train/logprobs = tensor([[ -1.6771, -14.5505],
        [ -8.8213,  -3.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25950586795806885
Epoch 0, Step 3392: train/loss = 0.03173769265413284, train/raw-loss = 0.0024807576555758715, train/logprobs = tensor([[ -1.3332, -15.2619],
        [ -7.8083,  -3.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925693392753601
Epoch 0, Step 3393: train/loss = 0.031245846301317215, train/raw-loss = 0.0041815172880887985, train/logprobs = tensor([[ -1.1581, -13.4905],
        [ -7.4116,  -2.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27064332365989685
Epoch 0, Step 3394: train/loss = 0.02869454398751259, train/raw-loss = 0.006840872578322887, train/logprobs = tensor([[ -1.4731, -15.8238],
        [ -6.0310,  -3.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853670477867126
Epoch 0, Step 3395: train/loss = 0.037771448493003845, train/raw-loss = 0.004964153748005629, train/logprobs = tensor([[ -0.9768, -13.6844],
        [ -5.8130,  -2.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3280729055404663
Epoch 0, Step 3396: train/loss = 0.02946769818663597, train/raw-loss = 0.0027830549515783787, train/logprobs = tensor([[ -1.8223, -12.2729],
        [ -7.6104,  -2.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668464183807373
Epoch 0, Step 3397: train/loss = 0.030789364129304886, train/raw-loss = 0.0008031745092011988, train/logprobs = tensor([[ -1.5281, -13.2539],
        [ -8.5522,  -2.9191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998619079589844
Epoch 0, Step 3398: train/loss = 0.029592152684926987, train/raw-loss = 0.0022534301970154047, train/logprobs = tensor([[ -1.4266, -14.7771],
        [ -7.8061,  -3.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27338722348213196
Epoch 0, Step 3399: train/loss = 0.03423270583152771, train/raw-loss = 0.014225427992641926, train/logprobs = tensor([[ -2.1190, -14.3966],
        [ -6.3271,  -2.4218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200072780251503
Epoch 0, Step 3400: train/loss = 0.0323319174349308, train/raw-loss = 0.002388840541243553, train/logprobs = tensor([[ -1.9417, -12.8330],
        [-11.6134,  -2.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994307577610016
Epoch 0, Step 3401: train/loss = 0.032868850976228714, train/raw-loss = 0.001494299853220582, train/logprobs = tensor([[ -1.3820, -14.8293],
        [ -8.2746,  -3.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31374549865722656
Epoch 0, Step 3402: train/loss = 0.06530319154262543, train/raw-loss = 0.042861275374889374, train/logprobs = tensor([[ -2.4311, -12.4035],
        [ -6.8031,  -2.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22441920638084412
Epoch 0, Step 3403: train/loss = 0.032207734882831573, train/raw-loss = 0.002208747435361147, train/logprobs = tensor([[-1.2982, -9.4463],
        [-7.8722, -1.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29998984932899475
Epoch 0, Step 3404: train/loss = 0.027807962149381638, train/raw-loss = 0.0008668731315992773, train/logprobs = tensor([[ -1.2880, -15.6174],
        [ -8.4603,  -1.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2694109082221985
Epoch 0, Step 3405: train/loss = 0.029890701174736023, train/raw-loss = 0.0009985906071960926, train/logprobs = tensor([[ -1.5325, -15.5477],
        [ -8.7042,  -2.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288921058177948
Epoch 0, Step 3406: train/loss = 0.032568808645009995, train/raw-loss = 0.0039537521079182625, train/logprobs = tensor([[ -1.0396, -16.8842],
        [ -5.9331,  -2.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28615057468414307
Epoch 0, Step 3407: train/loss = 0.03953547030687332, train/raw-loss = 0.0038157051894813776, train/logprobs = tensor([[ -1.5877, -15.6973],
        [ -7.9603,  -3.1497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3571976125240326
Epoch 0, Step 3408: train/loss = 0.04547310993075371, train/raw-loss = 0.018331509083509445, train/logprobs = tensor([[ -1.6828, -12.7392],
        [ -7.2086,  -2.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27141597867012024
Epoch 0, Step 3409: train/loss = 0.03482150286436081, train/raw-loss = 0.0013258039252832532, train/logprobs = tensor([[ -2.0061, -17.6892],
        [ -9.1377,  -2.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3349570035934448
Epoch 0, Step 3410: train/loss = 0.028068415820598602, train/raw-loss = 0.003014801535755396, train/logprobs = tensor([[ -2.7594, -17.1013],
        [ -9.4589,  -3.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25053614377975464
Epoch 0, Step 3411: train/loss = 0.029625574126839638, train/raw-loss = 0.001534185605123639, train/logprobs = tensor([[ -1.6643, -20.3055],
        [ -8.2201,  -4.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2809138894081116
Epoch 0, Step 3412: train/loss = 0.0329892635345459, train/raw-loss = 0.009299085475504398, train/logprobs = tensor([[-1.3136, -9.9947],
        [-5.8803, -2.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23690178990364075
Epoch 0, Step 3413: train/loss = 0.03139093518257141, train/raw-loss = 0.003146801143884659, train/logprobs = tensor([[ -1.2116, -19.0592],
        [ -6.4899,  -3.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28244131803512573
Epoch 0, Step 3414: train/loss = 0.11265292763710022, train/raw-loss = 0.08093658089637756, train/logprobs = tensor([[-2.5783, -9.5407],
        [-6.8530, -1.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3171634078025818
Epoch 0, Step 3415: train/loss = 0.029061004519462585, train/raw-loss = 0.002329982817173004, train/logprobs = tensor([[ -1.7247, -15.4666],
        [ -8.5521,  -2.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673102021217346
Epoch 0, Step 3416: train/loss = 0.03521815314888954, train/raw-loss = 0.00476618018001318, train/logprobs = tensor([[ -1.0306, -13.7411],
        [ -5.6894,  -2.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3045197129249573
Epoch 0, Step 3417: train/loss = 0.029603175818920135, train/raw-loss = 0.0016996245831251144, train/logprobs = tensor([[ -1.5374, -18.9499],
        [ -7.4036,  -3.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2790355086326599
Epoch 0, Step 3418: train/loss = 0.03302273526787758, train/raw-loss = 0.0023133275099098682, train/logprobs = tensor([[ -1.3668, -18.2150],
        [ -7.6582,  -3.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3070940673351288
Epoch 0, Step 3419: train/loss = 0.031823791563510895, train/raw-loss = 0.003732857294380665, train/logprobs = tensor([[ -1.3509, -17.3195],
        [ -6.3101,  -3.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28090935945510864
Epoch 0, Step 3420: train/loss = 0.0291609987616539, train/raw-loss = 0.0011889722663909197, train/logprobs = tensor([[ -1.1016, -15.4299],
        [ -7.4726,  -3.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2797202467918396
Epoch 0, Step 3421: train/loss = 0.02930108830332756, train/raw-loss = 0.0015998424496501684, train/logprobs = tensor([[ -1.5178, -11.7770],
        [ -8.6292,  -2.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.277012437582016
Epoch 0, Step 3422: train/loss = 0.03184511885046959, train/raw-loss = 0.0011476976796984673, train/logprobs = tensor([[ -1.0654, -12.1881],
        [ -7.6337,  -2.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3069741725921631
Epoch 0, Step 3423: train/loss = 0.03351239114999771, train/raw-loss = 0.004759242292493582, train/logprobs = tensor([[ -1.1704, -15.6452],
        [ -7.2701,  -3.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28753146529197693
Epoch 0, Step 3424: train/loss = 0.03975582495331764, train/raw-loss = 0.004704996012151241, train/logprobs = tensor([[ -1.4361, -14.7104],
        [ -8.5201,  -3.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35050827264785767
Epoch 0, Step 3425: train/loss = 0.03060539811849594, train/raw-loss = 0.0041739195585250854, train/logprobs = tensor([[ -1.3419, -14.2057],
        [ -7.0146,  -3.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26431477069854736
Epoch 0, Step 3426: train/loss = 0.036784231662750244, train/raw-loss = 0.009104305878281593, train/logprobs = tensor([[-1.6518, -9.4655],
        [-7.7622, -2.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27679920196533203
Epoch 0, Step 3427: train/loss = 0.03355509042739868, train/raw-loss = 0.004858756437897682, train/logprobs = tensor([[ -0.9274, -12.7468],
        [ -6.3185,  -1.6148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869633436203003
Epoch 0, Step 3428: train/loss = 0.031317636370658875, train/raw-loss = 0.0028964378871023655, train/logprobs = tensor([[ -2.0526, -15.3268],
        [ -7.9738,  -3.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2842119634151459
Epoch 0, Step 3429: train/loss = 0.028644975274801254, train/raw-loss = 0.004216433502733707, train/logprobs = tensor([[ -1.1171, -11.5375],
        [ -6.1768,  -1.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24428541958332062
Epoch 0, Step 3430: train/loss = 0.030198566615581512, train/raw-loss = 0.0008758745971135795, train/logprobs = tensor([[ -1.3478, -15.2117],
        [ -9.0990,  -2.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932268977165222
Epoch 0, Step 3431: train/loss = 0.031010909005999565, train/raw-loss = 0.0009242433006875217, train/logprobs = tensor([[ -1.9276, -13.4619],
        [-10.1376,  -1.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30086663365364075
Epoch 0, Step 3432: train/loss = 0.03603840619325638, train/raw-loss = 0.007301569916307926, train/logprobs = tensor([[ -1.2397, -17.5100],
        [ -7.6967,  -4.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873683571815491
Epoch 0, Step 3433: train/loss = 0.029009977355599403, train/raw-loss = 0.0016279852716252208, train/logprobs = tensor([[ -1.8661, -12.1477],
        [ -9.4038,  -2.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738198935985565
Epoch 0, Step 3434: train/loss = 0.03154744207859039, train/raw-loss = 0.0020446712151169777, train/logprobs = tensor([[ -1.0842, -12.2248],
        [ -6.8481,  -2.1528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2950277030467987
Epoch 0, Step 3435: train/loss = 0.03167574107646942, train/raw-loss = 0.0034993186127394438, train/logprobs = tensor([[ -1.9166, -13.9225],
        [ -8.0021,  -2.0443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817642390727997
Epoch 0, Step 3436: train/loss = 0.029879895970225334, train/raw-loss = 0.00024311427841894329, train/logprobs = tensor([[ -2.0752, -11.7326],
        [-11.0491,  -1.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2963678240776062
Epoch 0, Step 3437: train/loss = 0.06110005080699921, train/raw-loss = 0.036064762622117996, train/logprobs = tensor([[ -3.1875, -19.9642],
        [ -7.6710,  -4.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2503528892993927
Epoch 0, Step 3438: train/loss = 0.03179420158267021, train/raw-loss = 0.004321434535086155, train/logprobs = tensor([[ -1.1063, -12.1217],
        [ -6.5283,  -2.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2747276723384857
Epoch 0, Step 3439: train/loss = 0.03957284241914749, train/raw-loss = 0.006984015926718712, train/logprobs = tensor([[ -1.3720, -13.3277],
        [ -5.9742,  -3.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3258882462978363
Epoch 0, Step 3440: train/loss = 0.030557580292224884, train/raw-loss = 0.004731141496449709, train/logprobs = tensor([[ -1.0134, -14.7195],
        [ -5.9073,  -2.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2582643926143646
Epoch 0, Step 3441: train/loss = 0.030390454456210136, train/raw-loss = 0.0017354466253891587, train/logprobs = tensor([[ -1.4499, -17.0512],
        [ -8.7593,  -4.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865500748157501
Epoch 0, Step 3442: train/loss = 0.030739042907953262, train/raw-loss = 0.003750231582671404, train/logprobs = tensor([[ -1.6128, -13.2020],
        [ -7.1771,  -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26988810300827026
Epoch 0, Step 3443: train/loss = 0.029438061639666557, train/raw-loss = 0.001289035426452756, train/logprobs = tensor([[ -1.3318, -14.6587],
        [ -7.6184,  -2.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2814902663230896
Epoch 0, Step 3444: train/loss = 0.028313305228948593, train/raw-loss = 0.0010436478769406676, train/logprobs = tensor([[ -1.3979, -15.7193],
        [ -7.8643,  -3.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726965546607971
Epoch 0, Step 3445: train/loss = 0.030278701335191727, train/raw-loss = 0.0028238685335963964, train/logprobs = tensor([[ -1.2477, -13.4584],
        [ -7.4794,  -2.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27454835176467896
Epoch 0, Step 3446: train/loss = 0.028436843305826187, train/raw-loss = 0.0019118401687592268, train/logprobs = tensor([[ -1.4264, -13.3811],
        [ -7.5703,  -2.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265250027179718
Epoch 0, Step 3447: train/loss = 0.032883550971746445, train/raw-loss = 0.006484839133918285, train/logprobs = tensor([[ -1.0933, -13.5461],
        [ -6.8679,  -3.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26398712396621704
Epoch 0, Step 3448: train/loss = 0.032096169888973236, train/raw-loss = 0.005707234144210815, train/logprobs = tensor([[ -1.8441, -12.7274],
        [ -8.0266,  -2.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638893723487854
Epoch 0, Step 3449: train/loss = 0.036499232053756714, train/raw-loss = 0.0035811751149594784, train/logprobs = tensor([[-0.9935, -9.8722],
        [-6.7427, -1.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291805684566498
Epoch 0, Step 3450: train/loss = 0.03036326915025711, train/raw-loss = 0.0017663238104432821, train/logprobs = tensor([[ -1.3101, -19.1530],
        [ -7.7359,  -3.8579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28596943616867065
Epoch 0, Step 3451: train/loss = 0.031432874500751495, train/raw-loss = 0.0009384144796058536, train/logprobs = tensor([[ -1.9862, -12.6588],
        [ -8.4441,  -2.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30494457483291626
Epoch 0, Step 3452: train/loss = 0.04054027795791626, train/raw-loss = 0.013376515358686447, train/logprobs = tensor([[ -1.3031, -10.0300],
        [ -7.2721,  -1.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27163758873939514
Epoch 0, Step 3453: train/loss = 0.03214116767048836, train/raw-loss = 0.0044102855026721954, train/logprobs = tensor([[ -1.1884, -16.5720],
        [ -6.8075,  -4.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2773088216781616
Epoch 0, Step 3454: train/loss = 0.030365753918886185, train/raw-loss = 0.0031638608779758215, train/logprobs = tensor([[ -0.9493, -12.8874],
        [ -6.3972,  -3.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720189094543457
Epoch 0, Step 3455: train/loss = 0.03042345866560936, train/raw-loss = 0.0030270982533693314, train/logprobs = tensor([[ -1.3673, -14.7976],
        [ -7.9020,  -3.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739636301994324
Epoch 0, Step 3456: train/loss = 0.03133118152618408, train/raw-loss = 0.0026396047323942184, train/logprobs = tensor([[ -1.7667, -16.5507],
        [ -8.5685,  -4.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28691577911376953
Epoch 0, Step 3457: train/loss = 0.028366167098283768, train/raw-loss = 0.001053064363077283, train/logprobs = tensor([[ -1.6622, -19.2334],
        [ -8.4696,  -3.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27313104271888733
Epoch 0, Step 3458: train/loss = 0.05359619855880737, train/raw-loss = 0.025843700394034386, train/logprobs = tensor([[ -2.3167, -16.4320],
        [ -8.1328,  -2.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775249481201172
Epoch 0, Step 3459: train/loss = 0.03573639690876007, train/raw-loss = 0.008185409009456635, train/logprobs = tensor([[ -1.7021, -11.1170],
        [ -6.5758,  -2.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27550986409187317
Epoch 0, Step 3460: train/loss = 0.030210254713892937, train/raw-loss = 0.0014890177408233285, train/logprobs = tensor([[ -1.2986, -18.5204],
        [ -7.5295,  -4.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872123718261719
Epoch 0, Step 3461: train/loss = 0.055832404643297195, train/raw-loss = 0.030577460303902626, train/logprobs = tensor([[ -1.6810, -10.7691],
        [ -7.0221,  -2.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525494694709778
Epoch 0, Step 3462: train/loss = 0.034332096576690674, train/raw-loss = 0.004892778117209673, train/logprobs = tensor([[-1.9346, -9.5217],
        [-8.7788, -2.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943932116031647
Epoch 0, Step 3463: train/loss = 0.030123133212327957, train/raw-loss = 0.00038245689938776195, train/logprobs = tensor([[ -1.8840, -10.9354],
        [-10.5741,  -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29740673303604126
Epoch 0, Step 3464: train/loss = 0.029525669291615486, train/raw-loss = 0.000942344544455409, train/logprobs = tensor([[ -1.2364, -16.5572],
        [ -8.1012,  -3.4791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2858332395553589
Epoch 0, Step 3465: train/loss = 0.0311462190002203, train/raw-loss = 0.004296736791729927, train/logprobs = tensor([[ -1.8408, -19.9267],
        [ -7.4845,  -3.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2684948146343231
Epoch 0, Step 3466: train/loss = 0.03689660504460335, train/raw-loss = 0.008386583998799324, train/logprobs = tensor([[ -1.1412, -14.6278],
        [ -7.8853,  -4.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28510019183158875
Epoch 0, Step 3467: train/loss = 0.03206847608089447, train/raw-loss = 0.0033774434123188257, train/logprobs = tensor([[ -1.1656, -13.0143],
        [ -6.9851,  -2.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869103252887726
Epoch 0, Step 3468: train/loss = 0.029321875423192978, train/raw-loss = 0.0029570667538791895, train/logprobs = tensor([[ -1.8586, -11.6546],
        [ -8.4056,  -3.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2636480927467346
Epoch 0, Step 3469: train/loss = 0.02511739358305931, train/raw-loss = 5.9839050663867965e-05, train/logprobs = tensor([[ -2.5263, -17.1118],
        [-12.2831,  -3.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25057554244995117
Epoch 0, Step 3470: train/loss = 0.0394066721200943, train/raw-loss = 0.009586597792804241, train/logprobs = tensor([[ -2.7412, -14.0119],
        [ -9.4221,  -2.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29820072650909424
Epoch 0, Step 3471: train/loss = 0.031340569257736206, train/raw-loss = 0.0033761172089725733, train/logprobs = tensor([[ -1.1593, -12.7386],
        [ -6.9299,  -2.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27964454889297485
Epoch 0, Step 3472: train/loss = 0.02832118794322014, train/raw-loss = 0.0011342845391482115, train/logprobs = tensor([[ -1.6043, -16.0204],
        [ -8.5723,  -2.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2718690037727356
Epoch 0, Step 3473: train/loss = 0.04481806606054306, train/raw-loss = 0.010119630955159664, train/logprobs = tensor([[ -2.1416, -13.2626],
        [-10.1119,  -3.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469843566417694
Epoch 0, Step 3474: train/loss = 0.034834254533052444, train/raw-loss = 0.006426595151424408, train/logprobs = tensor([[ -1.3595, -11.4135],
        [ -7.1207,  -2.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28407660126686096
Epoch 0, Step 3475: train/loss = 0.0346829816699028, train/raw-loss = 0.00733508775010705, train/logprobs = tensor([[ -1.7005, -11.8965],
        [ -7.7295,  -3.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734789252281189
Epoch 0, Step 3476: train/loss = 0.03410058096051216, train/raw-loss = 0.002805126830935478, train/logprobs = tensor([[ -1.5124, -13.3391],
        [ -8.0904,  -2.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31295451521873474
Epoch 0, Step 3477: train/loss = 0.02927398309111595, train/raw-loss = 9.827457688516006e-05, train/logprobs = tensor([[ -1.9957, -16.7198],
        [-12.2719,  -4.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29175707697868347
Epoch 0, Step 3478: train/loss = 0.03360383212566376, train/raw-loss = 0.0024717224296182394, train/logprobs = tensor([[ -1.2466, -16.6380],
        [ -6.8437,  -4.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31132107973098755
Epoch 0, Step 3479: train/loss = 0.03159786015748978, train/raw-loss = 0.003486504079774022, train/logprobs = tensor([[ -1.5917, -10.4906],
        [ -8.6856,  -2.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28111353516578674
Epoch 0, Step 3480: train/loss = 0.030764520168304443, train/raw-loss = 0.004739350639283657, train/logprobs = tensor([[ -1.5363, -15.3007],
        [ -8.2367,  -3.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602516710758209
Epoch 0, Step 3481: train/loss = 0.02892376482486725, train/raw-loss = 0.0017638932913541794, train/logprobs = tensor([[ -1.2167, -15.0614],
        [ -6.9954,  -2.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715987265110016
Epoch 0, Step 3482: train/loss = 0.022217970341444016, train/raw-loss = 0.0007007448584772646, train/logprobs = tensor([[ -3.0825, -19.8912],
        [-10.2174,  -6.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21517223119735718
Epoch 0, Step 3483: train/loss = 0.032871562987565994, train/raw-loss = 0.001411612262018025, train/logprobs = tensor([[ -1.7383, -10.9116],
        [ -9.1600,  -2.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145994544029236
Epoch 0, Step 3484: train/loss = 0.030332332476973534, train/raw-loss = 0.0033581522293388844, train/logprobs = tensor([[ -1.6746, -16.2220],
        [ -7.9452,  -3.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26974180340766907
Epoch 0, Step 3485: train/loss = 0.030200544744729996, train/raw-loss = 0.0019264959264546633, train/logprobs = tensor([[ -1.3531, -14.6158],
        [ -8.4680,  -2.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2827404737472534
Epoch 0, Step 3486: train/loss = 0.029716141521930695, train/raw-loss = 0.005182025022804737, train/logprobs = tensor([[ -0.9820, -13.5922],
        [ -6.3891,  -2.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24534116685390472
Epoch 0, Step 3487: train/loss = 0.034094832837581635, train/raw-loss = 0.0026352962013334036, train/logprobs = tensor([[ -1.2539, -12.0651],
        [ -8.4104,  -2.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145953416824341
Epoch 0, Step 3488: train/loss = 0.03252456337213516, train/raw-loss = 0.0045761591754853725, train/logprobs = tensor([[ -1.2407, -13.1693],
        [ -7.3922,  -1.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27948400378227234
Epoch 0, Step 3489: train/loss = 0.029109882190823555, train/raw-loss = 0.0022206439170986414, train/logprobs = tensor([[ -1.2945, -14.7875],
        [ -7.3296,  -3.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268892377614975
Epoch 0, Step 3490: train/loss = 0.04582580178976059, train/raw-loss = 0.02049662545323372, train/logprobs = tensor([[ -2.1439, -15.6702],
        [ -7.4511,  -3.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532917857170105
Epoch 0, Step 3491: train/loss = 0.031003408133983612, train/raw-loss = 0.0031696069054305553, train/logprobs = tensor([[ -0.9501, -13.3026],
        [ -6.2816,  -2.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2783380150794983
Epoch 0, Step 3492: train/loss = 0.026116743683815002, train/raw-loss = 0.001273543806746602, train/logprobs = tensor([[ -1.5793, -13.2650],
        [ -8.3448,  -2.5034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2484319806098938
Epoch 0, Step 3493: train/loss = 0.026584576815366745, train/raw-loss = 0.0010695839300751686, train/logprobs = tensor([[ -1.6288, -16.0356],
        [ -8.8196,  -3.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551499307155609
Epoch 0, Step 3494: train/loss = 0.03470688685774803, train/raw-loss = 0.0013699382543563843, train/logprobs = tensor([[ -1.2135, -18.6519],
        [ -8.5529,  -4.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333694636821747
Epoch 0, Step 3495: train/loss = 0.03403271362185478, train/raw-loss = 0.005846397485584021, train/logprobs = tensor([[ -0.7991, -11.7836],
        [ -5.5099,  -2.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28186312317848206
Epoch 0, Step 3496: train/loss = 0.029264036566019058, train/raw-loss = 0.0017714757705107331, train/logprobs = tensor([[ -1.1032, -19.4042],
        [ -7.2157,  -4.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749255895614624
Epoch 0, Step 3497: train/loss = 0.03142060339450836, train/raw-loss = 0.003909626975655556, train/logprobs = tensor([[ -1.2318, -14.4361],
        [ -6.5806,  -3.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27510973811149597
Epoch 0, Step 3498: train/loss = 0.030778545886278152, train/raw-loss = 0.0015457278350368142, train/logprobs = tensor([[ -1.4982, -17.2179],
        [ -8.0580,  -3.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2923281788825989
Epoch 0, Step 3499: train/loss = 0.0305438581854105, train/raw-loss = 0.0016194459749385715, train/logprobs = tensor([[ -1.6386, -11.0421],
        [ -9.1830,  -3.2589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892441153526306
Epoch 0, Step 3500: train/loss = 0.03068770468235016, train/raw-loss = 0.003890384454280138, train/logprobs = tensor([[ -0.8791, -12.3402],
        [ -6.2671,  -2.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679732143878937
Epoch 0, Step 3501: train/loss = 0.029507210478186607, train/raw-loss = 0.0022832145914435387, train/logprobs = tensor([[ -1.4574, -21.1489],
        [ -7.0647,  -4.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27223995327949524
Epoch 0, Step 3502: train/loss = 0.030467677861452103, train/raw-loss = 0.001100870780646801, train/logprobs = tensor([[ -0.9713, -17.3489],
        [ -7.5449,  -3.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29366806149482727
Epoch 0, Step 3503: train/loss = 0.03300505131483078, train/raw-loss = 0.009447037242352962, train/logprobs = tensor([[ -1.5589, -15.2348],
        [ -6.9423,  -1.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23558014631271362
Epoch 0, Step 3504: train/loss = 0.02664663828909397, train/raw-loss = 0.001506608328782022, train/logprobs = tensor([[ -1.4555, -17.8717],
        [ -8.5834,  -4.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25140029191970825
Epoch 0, Step 3505: train/loss = 0.029817502945661545, train/raw-loss = 0.0035157983656972647, train/logprobs = tensor([[ -1.2115, -11.6836],
        [ -6.2900,  -1.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26301702857017517
Epoch 0, Step 3506: train/loss = 0.038318730890750885, train/raw-loss = 0.008542572148144245, train/logprobs = tensor([[ -1.4688, -17.1776],
        [ -7.8012,  -4.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29776155948638916
Epoch 0, Step 3507: train/loss = 0.03501973673701286, train/raw-loss = 0.004932638723403215, train/logprobs = tensor([[ -0.6894, -10.3681],
        [ -5.9258,  -2.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30087098479270935
Epoch 0, Step 3508: train/loss = 0.02840052731335163, train/raw-loss = 0.002798441331833601, train/logprobs = tensor([[ -1.7240, -18.0403],
        [ -8.1484,  -3.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25602084398269653
Epoch 0, Step 3509: train/loss = 0.02851879969239235, train/raw-loss = 0.004219123627990484, train/logprobs = tensor([[ -1.7897, -16.6805],
        [ -7.7101,  -1.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24299675226211548
Epoch 0, Step 3510: train/loss = 0.030458670109510422, train/raw-loss = 0.0025959741324186325, train/logprobs = tensor([[ -1.4590, -15.5499],
        [ -7.1662,  -2.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.278626948595047
Epoch 0, Step 3511: train/loss = 0.03227964788675308, train/raw-loss = 0.001424008747562766, train/logprobs = tensor([[ -1.4867, -15.2559],
        [ -7.8220,  -3.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30855637788772583
Epoch 0, Step 3512: train/loss = 0.03094148077070713, train/raw-loss = 0.00171318044885993, train/logprobs = tensor([[ -1.1874, -13.9714],
        [ -7.3626,  -2.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29228299856185913
Epoch 0, Step 3513: train/loss = 0.027833117172122, train/raw-loss = 0.00036740535870194435, train/logprobs = tensor([[ -1.8631, -15.8435],
        [ -9.5712,  -3.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27465713024139404
Epoch 0, Step 3514: train/loss = 0.032341424375772476, train/raw-loss = 0.0051331790164113045, train/logprobs = tensor([[ -1.6152, -14.3492],
        [ -7.4166,  -2.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27208244800567627
Epoch 0, Step 3515: train/loss = 0.03930620104074478, train/raw-loss = 0.013060111552476883, train/logprobs = tensor([[ -2.6979, -12.6390],
        [ -9.0140,  -2.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2624608874320984
Epoch 0, Step 3516: train/loss = 0.027157874777913094, train/raw-loss = 0.0019536092877388, train/logprobs = tensor([[ -2.7309, -18.2672],
        [ -9.5002,  -5.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25204265117645264
Epoch 0, Step 3517: train/loss = 0.030671950429677963, train/raw-loss = 0.0008565956959500909, train/logprobs = tensor([[ -1.6825, -14.6551],
        [ -9.5204,  -1.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2981535494327545
Epoch 0, Step 3518: train/loss = 0.032357797026634216, train/raw-loss = 0.0027436355594545603, train/logprobs = tensor([[ -0.9160, -15.9984],
        [ -6.2822,  -3.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961415648460388
Epoch 0, Step 3519: train/loss = 0.032507967203855515, train/raw-loss = 0.002901447005569935, train/logprobs = tensor([[ -1.7989, -20.6533],
        [ -9.0877,  -4.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29606518149375916
Epoch 0, Step 3520: train/loss = 0.028507515788078308, train/raw-loss = 0.0012043664464727044, train/logprobs = tensor([[ -1.4564, -17.1073],
        [ -8.6887,  -3.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27303147315979004
Epoch 0, Step 3521: train/loss = 0.028367627412080765, train/raw-loss = 0.0015470081707462668, train/logprobs = tensor([[ -1.9142, -14.7894],
        [ -8.4991,  -3.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682061791419983
Epoch 0, Step 3522: train/loss = 0.026013042777776718, train/raw-loss = 0.001077433000318706, train/logprobs = tensor([[ -1.5448, -16.7314],
        [ -8.8921,  -3.1625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24935609102249146
Epoch 0, Step 3523: train/loss = 0.03376872092485428, train/raw-loss = 0.003802663879469037, train/logprobs = tensor([[ -1.2481, -11.2098],
        [ -8.3916,  -2.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996605634689331
Epoch 0, Step 3524: train/loss = 0.03343260660767555, train/raw-loss = 0.0031493729911744595, train/logprobs = tensor([[ -1.1350, -11.4664],
        [ -6.6548,  -1.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30283230543136597
Epoch 0, Step 3525: train/loss = 0.027792446315288544, train/raw-loss = 0.0016833196859806776, train/logprobs = tensor([[ -2.0914, -16.5839],
        [ -9.8234,  -2.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610912621021271
Epoch 0, Step 3526: train/loss = 0.03128763660788536, train/raw-loss = 0.003178489161655307, train/logprobs = tensor([[ -1.7695, -13.6127],
        [ -8.7855,  -2.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28109148144721985
Epoch 0, Step 3527: train/loss = 0.03989456593990326, train/raw-loss = 0.017485730350017548, train/logprobs = tensor([[ -0.8312, -11.7832],
        [ -5.9742,  -2.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2240883857011795
Epoch 0, Step 3528: train/loss = 0.033816222101449966, train/raw-loss = 0.006297117564827204, train/logprobs = tensor([[ -0.9867, -13.6456],
        [ -6.0124,  -3.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2751910090446472
Epoch 0, Step 3529: train/loss = 0.029730530455708504, train/raw-loss = 0.003915639594197273, train/logprobs = tensor([[ -1.6363, -14.5726],
        [ -8.9154,  -3.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581488788127899
Epoch 0, Step 3530: train/loss = 0.028113149106502533, train/raw-loss = 0.0007313236710615456, train/logprobs = tensor([[ -1.3166, -14.6009],
        [ -8.6960,  -2.3145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738182544708252
Epoch 0, Step 3531: train/loss = 0.033178072422742844, train/raw-loss = 0.008222013711929321, train/logprobs = tensor([[ -1.9332, -11.6793],
        [ -8.1311,  -2.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24956059455871582
Epoch 0, Step 3532: train/loss = 0.0259514469653368, train/raw-loss = 0.0022360244765877724, train/logprobs = tensor([[ -1.3557, -12.4219],
        [ -7.8566,  -2.4331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23715423047542572
Epoch 0, Step 3533: train/loss = 0.02708364836871624, train/raw-loss = 0.0012860540300607681, train/logprobs = tensor([[ -1.4154, -19.1118],
        [ -7.9262,  -3.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579759359359741
Epoch 0, Step 3534: train/loss = 0.03026420809328556, train/raw-loss = 0.0011209564981982112, train/logprobs = tensor([[ -2.0868, -15.0267],
        [ -9.8138,  -3.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2914324998855591
Epoch 0, Step 3535: train/loss = 0.028488289564847946, train/raw-loss = 0.001055580680258572, train/logprobs = tensor([[ -1.3262, -14.4730],
        [ -7.7765,  -3.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743270993232727
Epoch 0, Step 3536: train/loss = 0.028612621128559113, train/raw-loss = 0.0005286185187287629, train/logprobs = tensor([[ -1.2508, -15.0839],
        [ -8.7676,  -3.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2808400094509125
Epoch 0, Step 3537: train/loss = 0.03943902254104614, train/raw-loss = 0.011098380200564861, train/logprobs = tensor([[ -0.9357, -11.3832],
        [ -8.4688,  -2.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28340643644332886
Epoch 0, Step 3538: train/loss = 0.02823837287724018, train/raw-loss = 0.003626507706940174, train/logprobs = tensor([[ -1.0613, -10.9645],
        [ -6.2841,  -1.2313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2461186647415161
Epoch 0, Step 3539: train/loss = 0.030518466606736183, train/raw-loss = 0.0021973070688545704, train/logprobs = tensor([[ -1.3689, -11.9967],
        [ -7.6667,  -1.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832115888595581
Epoch 0, Step 3540: train/loss = 0.05433882400393486, train/raw-loss = 0.022551894187927246, train/logprobs = tensor([[ -1.6858, -13.3158],
        [ -9.3649,  -2.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31786930561065674
Epoch 0, Step 3541: train/loss = 0.03729066997766495, train/raw-loss = 0.0052419002167880535, train/logprobs = tensor([[ -1.4150, -17.3089],
        [ -7.4802,  -3.8799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3204876780509949
Epoch 0, Step 3542: train/loss = 0.0282121691852808, train/raw-loss = 0.0015637672040611506, train/logprobs = tensor([[ -1.6726, -12.2588],
        [ -9.5179,  -2.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26648402214050293
Epoch 0, Step 3543: train/loss = 0.03146311268210411, train/raw-loss = 0.00038133806083351374, train/logprobs = tensor([[ -1.4525, -14.4750],
        [-10.0326,  -2.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108177185058594
Epoch 0, Step 3544: train/loss = 0.028527874499559402, train/raw-loss = 0.0008100478444248438, train/logprobs = tensor([[ -1.5914, -14.2272],
        [ -9.4268,  -2.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27717825770378113
Epoch 0, Step 3545: train/loss = 0.025781190022826195, train/raw-loss = 0.0004337063292041421, train/logprobs = tensor([[ -2.2662, -15.5682],
        [ -9.3707,  -2.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534748315811157
Epoch 0, Step 3546: train/loss = 0.028555409982800484, train/raw-loss = 0.002926304005086422, train/logprobs = tensor([[ -1.6634, -16.8280],
        [ -7.0908,  -3.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25629106163978577
Epoch 0, Step 3547: train/loss = 0.03137289732694626, train/raw-loss = 0.0017253279220312834, train/logprobs = tensor([[ -1.8301, -12.1403],
        [ -7.9253,  -2.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29647570848464966
Epoch 0, Step 3548: train/loss = 0.031771428883075714, train/raw-loss = 0.004305730573832989, train/logprobs = tensor([[ -0.8530, -10.5123],
        [ -6.7483,  -2.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746569812297821
Epoch 0, Step 3549: train/loss = 0.02868414856493473, train/raw-loss = 0.0022367769852280617, train/logprobs = tensor([[ -1.2744, -12.1191],
        [ -7.8999,  -2.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26447370648384094
Epoch 0, Step 3550: train/loss = 0.09676597267389297, train/raw-loss = 0.07125003635883331, train/logprobs = tensor([[ -2.0701, -14.2407],
        [ -6.7247,  -2.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25515931844711304
Epoch 0, Step 3551: train/loss = 0.03041420318186283, train/raw-loss = 0.001957105239853263, train/logprobs = tensor([[ -1.3736, -17.2747],
        [ -7.9582,  -4.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28457099199295044
Epoch 0, Step 3552: train/loss = 0.03263753280043602, train/raw-loss = 0.0038619283586740494, train/logprobs = tensor([[ -1.0688, -12.9981],
        [ -6.6084,  -3.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877560257911682
Epoch 0, Step 3553: train/loss = 0.03190474957227707, train/raw-loss = 0.00829989928752184, train/logprobs = tensor([[ -0.9686, -17.2695],
        [ -5.5801,  -3.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23604848980903625
Epoch 0, Step 3554: train/loss = 0.032168418169021606, train/raw-loss = 0.0024200445041060448, train/logprobs = tensor([[ -1.2651, -12.6479],
        [ -7.1082,  -2.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29748374223709106
Epoch 0, Step 3555: train/loss = 0.03530163690447807, train/raw-loss = 0.005535632837563753, train/logprobs = tensor([[ -1.2523, -12.5744],
        [ -8.5828,  -2.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976600229740143
Epoch 0, Step 3556: train/loss = 0.031346533447504044, train/raw-loss = 0.0010134276235476136, train/logprobs = tensor([[ -1.5858, -20.1488],
        [ -8.9581,  -3.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30333104729652405
Epoch 0, Step 3557: train/loss = 0.03092966601252556, train/raw-loss = 0.0036849044263362885, train/logprobs = tensor([[ -1.0034, -15.6147],
        [ -6.6685,  -3.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724476456642151
Epoch 0, Step 3558: train/loss = 0.029068056493997574, train/raw-loss = 0.0012841179268434644, train/logprobs = tensor([[ -1.6985, -14.2092],
        [ -8.0563,  -3.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27783939242362976
Epoch 0, Step 3559: train/loss = 0.056450262665748596, train/raw-loss = 0.02780819498002529, train/logprobs = tensor([[ -1.2096, -10.1721],
        [ -7.2525,  -2.8916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28642067313194275
Epoch 0, Step 3560: train/loss = 0.026591045781970024, train/raw-loss = 0.00205288827419281, train/logprobs = tensor([[ -1.1370, -12.0247],
        [ -7.2501,  -2.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24538157880306244
Epoch 0, Step 3561: train/loss = 0.02757314220070839, train/raw-loss = 0.0012282906100153923, train/logprobs = tensor([[ -1.4003, -17.8173],
        [ -8.6181,  -3.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634485363960266
Epoch 0, Step 3562: train/loss = 0.027129709720611572, train/raw-loss = 0.002599908271804452, train/logprobs = tensor([[ -1.3373, -14.9190],
        [ -7.4322,  -1.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24529802799224854
Epoch 0, Step 3563: train/loss = 0.030704963952302933, train/raw-loss = 0.002481676172465086, train/logprobs = tensor([[ -1.1376, -14.6092],
        [ -7.0356,  -2.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822328805923462
Epoch 0, Step 3564: train/loss = 0.027837250381708145, train/raw-loss = 0.0006612149882130325, train/logprobs = tensor([[ -1.0934, -11.5773],
        [ -8.9712,  -1.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27176034450531006
Epoch 0, Step 3565: train/loss = 0.03095010668039322, train/raw-loss = 0.0023549406323581934, train/logprobs = tensor([[ -1.7463, -14.0656],
        [ -9.1913,  -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2859516739845276
Epoch 0, Step 3566: train/loss = 0.031218532472848892, train/raw-loss = 0.0024708001874387264, train/logprobs = tensor([[ -1.6960, -15.8125],
        [ -8.9372,  -3.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2874773144721985
Epoch 0, Step 3567: train/loss = 0.08887031674385071, train/raw-loss = 0.06300478428602219, train/logprobs = tensor([[ -0.7710, -13.7500],
        [ -4.3774,  -4.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25865525007247925
Epoch 0, Step 3568: train/loss = 0.029481396079063416, train/raw-loss = 0.0034360908903181553, train/logprobs = tensor([[ -1.3484, -12.4117],
        [ -7.1539,  -2.4202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2604530453681946
Epoch 0, Step 3569: train/loss = 0.02608639746904373, train/raw-loss = 0.0005690234829671681, train/logprobs = tensor([[ -1.6371, -13.1359],
        [ -9.0499,  -3.3182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551737427711487
Epoch 0, Step 3570: train/loss = 0.028943028301000595, train/raw-loss = 0.000999825308099389, train/logprobs = tensor([[ -2.3959, -10.7276],
        [ -9.1489,  -2.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2794320285320282
Epoch 0, Step 3571: train/loss = 0.03906673938035965, train/raw-loss = 0.005925394594669342, train/logprobs = tensor([[ -1.6041, -11.4612],
        [ -7.9195,  -3.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314134478569031
Epoch 0, Step 3572: train/loss = 0.11544719338417053, train/raw-loss = 0.08998870104551315, train/logprobs = tensor([[ -1.7500, -13.9880],
        [ -7.4247,  -3.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545849084854126
Epoch 0, Step 3573: train/loss = 0.03173084557056427, train/raw-loss = 0.006272434256970882, train/logprobs = tensor([[ -1.3502, -15.6814],
        [ -6.9653,  -4.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545841336250305
Epoch 0, Step 3574: train/loss = 0.030374839901924133, train/raw-loss = 0.004444745369255543, train/logprobs = tensor([[ -1.7129, -14.5396],
        [ -8.7447,  -3.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25930094718933105
Epoch 0, Step 3575: train/loss = 0.03014862723648548, train/raw-loss = 0.0012720429804176092, train/logprobs = tensor([[ -1.5933, -18.0221],
        [ -9.1076,  -3.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887658476829529
Epoch 0, Step 3576: train/loss = 0.028276268392801285, train/raw-loss = 0.0007168566808104515, train/logprobs = tensor([[ -1.8015, -16.0744],
        [ -9.3755,  -4.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2755941152572632
Epoch 0, Step 3577: train/loss = 0.030704684555530548, train/raw-loss = 0.0014320785412564874, train/logprobs = tensor([[ -1.4944, -21.0507],
        [ -8.1802,  -4.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2927260398864746
Epoch 0, Step 3578: train/loss = 0.02892531082034111, train/raw-loss = 0.0025649373419582844, train/logprobs = tensor([[ -1.6794, -13.9041],
        [ -8.0729,  -2.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26360374689102173
Epoch 0, Step 3579: train/loss = 0.02820548787713051, train/raw-loss = 0.00428053317591548, train/logprobs = tensor([[ -2.2568, -13.2246],
        [ -8.0673,  -1.5417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2392495572566986
Epoch 0, Step 3580: train/loss = 0.031423479318618774, train/raw-loss = 0.003999768756330013, train/logprobs = tensor([[ -1.5318, -13.3581],
        [ -8.3469,  -2.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27423712611198425
Epoch 0, Step 3581: train/loss = 0.035077691078186035, train/raw-loss = 0.001103086513467133, train/logprobs = tensor([[ -2.8068, -12.7988],
        [-10.2017,  -2.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33974605798721313
Epoch 0, Step 3582: train/loss = 0.03606080263853073, train/raw-loss = 0.008020874112844467, train/logprobs = tensor([[ -1.9314, -10.5837],
        [-10.7270,  -2.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28039929270744324
Epoch 0, Step 3583: train/loss = 0.029266729950904846, train/raw-loss = 0.0018009543418884277, train/logprobs = tensor([[ -1.1087, -13.6721],
        [ -7.2167,  -2.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746577560901642
Epoch 0, Step 3584: train/loss = 0.028034456074237823, train/raw-loss = 0.0016910511767491698, train/logprobs = tensor([[ -1.6994, -17.6510],
        [ -8.4606,  -4.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634340524673462
Epoch 0, Step 3585: train/loss = 0.03271074593067169, train/raw-loss = 0.004043486434966326, train/logprobs = tensor([[ -1.0009, -12.8213],
        [ -6.0112,  -3.2739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28667259216308594
Epoch 0, Step 3586: train/loss = 0.02958008646965027, train/raw-loss = 0.0008581159636378288, train/logprobs = tensor([[ -1.7606, -15.9275],
        [ -9.1050,  -2.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28721970319747925
Epoch 0, Step 3587: train/loss = 0.02950889617204666, train/raw-loss = 0.004990086890757084, train/logprobs = tensor([[ -2.4924, -17.9668],
        [ -8.7858,  -4.0673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24518807232379913
Epoch 0, Step 3588: train/loss = 0.02915295399725437, train/raw-loss = 0.0033371674362570047, train/logprobs = tensor([[ -1.3377, -11.6761],
        [ -6.6934,  -2.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581578493118286
Epoch 0, Step 3589: train/loss = 0.04917673021554947, train/raw-loss = 0.025967953726649284, train/logprobs = tensor([[ -1.3750, -13.7617],
        [ -7.2300,  -2.6493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23208773136138916
Epoch 0, Step 3590: train/loss = 0.03266461193561554, train/raw-loss = 0.006203813944011927, train/logprobs = tensor([[ -1.5718, -13.2692],
        [ -7.5425,  -2.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2646079659461975
Epoch 0, Step 3591: train/loss = 0.025501852855086327, train/raw-loss = 0.002518845722079277, train/logprobs = tensor([[ -2.4177, -17.8369],
        [-10.6026,  -3.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2298300564289093
Epoch 0, Step 3592: train/loss = 0.03715740516781807, train/raw-loss = 0.002515167696401477, train/logprobs = tensor([[ -1.0241, -19.0349],
        [ -7.3020,  -3.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34642237424850464
Epoch 0, Step 3593: train/loss = 0.027883805334568024, train/raw-loss = 0.0028660546522587538, train/logprobs = tensor([[ -1.4341, -14.0270],
        [ -7.0389,  -2.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2501775026321411
Epoch 0, Step 3594: train/loss = 0.030709974467754364, train/raw-loss = 0.002053334377706051, train/logprobs = tensor([[ -1.1626, -13.5059],
        [ -7.0907,  -2.3053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865663766860962
Epoch 0, Step 3595: train/loss = 0.02536221221089363, train/raw-loss = 0.0011863582767546177, train/logprobs = tensor([[ -1.5850, -16.7086],
        [ -8.1920,  -3.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417585551738739
Epoch 0, Step 3596: train/loss = 0.03254229202866554, train/raw-loss = 0.003138943575322628, train/logprobs = tensor([[ -0.9068, -14.4752],
        [ -7.2959,  -3.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2940334975719452
Epoch 0, Step 3597: train/loss = 0.029233228415250778, train/raw-loss = 0.000665042083710432, train/logprobs = tensor([[ -1.7076, -15.2888],
        [ -9.0971,  -2.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856818437576294
Epoch 0, Step 3598: train/loss = 0.03345518931746483, train/raw-loss = 0.004959733225405216, train/logprobs = tensor([[ -1.3806, -13.6300],
        [ -6.5433,  -2.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849545478820801
Epoch 0, Step 3599: train/loss = 0.046183425933122635, train/raw-loss = 0.020769139751791954, train/logprobs = tensor([[ -1.8127, -11.5904],
        [ -7.7181,  -2.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2541428208351135
Epoch 0, Step 3600: train/loss = 0.02661772444844246, train/raw-loss = 0.0012869816273450851, train/logprobs = tensor([[ -1.0733, -20.0237],
        [ -8.5642,  -4.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25330740213394165
Epoch 0, Step 3601: train/loss = 0.02992023527622223, train/raw-loss = 0.0025799362920224667, train/logprobs = tensor([[ -1.4081, -14.9632],
        [ -7.8652,  -4.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27340298891067505
Epoch 0, Step 3602: train/loss = 0.028750721365213394, train/raw-loss = 0.0019965358078479767, train/logprobs = tensor([[ -0.5476, -13.2536],
        [ -6.0966,  -2.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2675418257713318
Epoch 0, Step 3603: train/loss = 0.031985435634851456, train/raw-loss = 0.006635068915784359, train/logprobs = tensor([[ -1.8945, -12.9439],
        [ -7.8009,  -2.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535036504268646
Epoch 0, Step 3604: train/loss = 0.0580291785299778, train/raw-loss = 0.030627107247710228, train/logprobs = tensor([[ -0.8214, -13.3653],
        [ -5.3567,  -4.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740207314491272
Epoch 0, Step 3605: train/loss = 0.0303647518157959, train/raw-loss = 0.006226631812751293, train/logprobs = tensor([[ -0.9049, -21.5158],
        [ -6.3692,  -4.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2413811981678009
Epoch 0, Step 3606: train/loss = 0.03429294750094414, train/raw-loss = 0.0038273055106401443, train/logprobs = tensor([[ -0.9245, -13.9731],
        [ -6.4114,  -3.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30465641617774963
Epoch 0, Step 3607: train/loss = 0.027631040662527084, train/raw-loss = 0.0007265083258971572, train/logprobs = tensor([[ -1.6186, -15.4241],
        [ -9.1903,  -3.2794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26904532313346863
Epoch 0, Step 3608: train/loss = 0.030592314898967743, train/raw-loss = 0.0013730173232033849, train/logprobs = tensor([[ -1.8284, -19.0353],
        [ -8.0661,  -5.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2921929657459259
Epoch 0, Step 3609: train/loss = 0.034647632390260696, train/raw-loss = 0.004484153818339109, train/logprobs = tensor([[ -1.2986, -12.6550],
        [ -6.3374,  -3.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016347587108612
Epoch 0, Step 3610: train/loss = 0.03158733993768692, train/raw-loss = 0.001542616286315024, train/logprobs = tensor([[ -1.8866, -14.5141],
        [ -8.3319,  -2.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3004472553730011
Epoch 0, Step 3611: train/loss = 0.03160657361149788, train/raw-loss = 0.0016800251323729753, train/logprobs = tensor([[ -1.1259, -14.4243],
        [ -8.0936,  -2.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992655038833618
Epoch 0, Step 3612: train/loss = 0.028663523495197296, train/raw-loss = 0.0021016972605139017, train/logprobs = tensor([[ -1.1305, -14.5763],
        [ -6.6480,  -2.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2656182646751404
Epoch 0, Step 3613: train/loss = 0.03178674355149269, train/raw-loss = 0.003175123129040003, train/logprobs = tensor([[ -1.5121, -14.6057],
        [ -8.6289,  -3.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28611618280410767
Epoch 0, Step 3614: train/loss = 0.03209714964032173, train/raw-loss = 0.004488622769713402, train/logprobs = tensor([[ -1.4308, -12.3427],
        [ -6.7323,  -2.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760852575302124
Epoch 0, Step 3615: train/loss = 0.033738937228918076, train/raw-loss = 0.004112101625651121, train/logprobs = tensor([[ -0.7569, -12.4910],
        [ -5.8272,  -2.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2962683439254761
Epoch 0, Step 3616: train/loss = 0.03541430085897446, train/raw-loss = 0.01205240748822689, train/logprobs = tensor([[ -1.1352, -12.9215],
        [ -6.7670,  -3.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23361891508102417
Epoch 0, Step 3617: train/loss = 0.028658051043748856, train/raw-loss = 0.004156268201768398, train/logprobs = tensor([[-1.4266, -9.2984],
        [-6.9453, -1.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24501784145832062
Epoch 0, Step 3618: train/loss = 0.03682665154337883, train/raw-loss = 0.006054473575204611, train/logprobs = tensor([[ -1.5584, -11.7512],
        [ -8.5791,  -1.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077217936515808
Epoch 0, Step 3619: train/loss = 0.027985623106360435, train/raw-loss = 0.0004650338087230921, train/logprobs = tensor([[ -1.3296, -16.5533],
        [ -8.4798,  -3.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752058804035187
Epoch 0, Step 3620: train/loss = 0.029016729444265366, train/raw-loss = 0.0004978338838554919, train/logprobs = tensor([[ -1.9399, -14.7322],
        [ -9.5586,  -2.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851889729499817
Epoch 0, Step 3621: train/loss = 0.031706590205430984, train/raw-loss = 0.002820933237671852, train/logprobs = tensor([[ -1.1871, -12.6669],
        [ -6.5556,  -2.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288856565952301
Epoch 0, Step 3622: train/loss = 0.02747395634651184, train/raw-loss = 0.00011316761083435267, train/logprobs = tensor([[ -2.8164, -19.1486],
        [-11.6153,  -2.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27360790967941284
Epoch 0, Step 3623: train/loss = 0.031234953552484512, train/raw-loss = 0.006328377407044172, train/logprobs = tensor([[ -1.7759, -13.4661],
        [ -6.4817,  -3.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24906577169895172
Epoch 0, Step 3624: train/loss = 0.03646399825811386, train/raw-loss = 0.006673038937151432, train/logprobs = tensor([[ -1.3501, -13.4601],
        [ -8.3633,  -3.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29790958762168884
Epoch 0, Step 3625: train/loss = 0.032186415046453476, train/raw-loss = 0.007622997276484966, train/logprobs = tensor([[ -1.7850, -11.8326],
        [ -7.3839,  -3.4114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24563419818878174
Epoch 0, Step 3626: train/loss = 0.0266617052257061, train/raw-loss = 0.002862475346773863, train/logprobs = tensor([[ -1.3006, -15.4952],
        [ -6.8059,  -4.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2379922866821289
Epoch 0, Step 3627: train/loss = 0.028881710022687912, train/raw-loss = 0.000851987861096859, train/logprobs = tensor([[ -1.4149, -10.6677],
        [ -8.7800,  -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802972197532654
Epoch 0, Step 3628: train/loss = 0.03849630802869797, train/raw-loss = 0.0071464222855865955, train/logprobs = tensor([[ -1.7112, -14.0409],
        [ -8.4703,  -3.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313498854637146
Epoch 0, Step 3629: train/loss = 0.03383053094148636, train/raw-loss = 0.009090852923691273, train/logprobs = tensor([[ -1.0921, -11.6579],
        [ -5.6654,  -2.5115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2473968267440796
Epoch 0, Step 3630: train/loss = 0.0320153534412384, train/raw-loss = 0.0018910313956439495, train/logprobs = tensor([[ -1.4932, -13.0717],
        [ -7.1282,  -3.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30124324560165405
Epoch 0, Step 3631: train/loss = 0.028723934665322304, train/raw-loss = 0.0015571764670312405, train/logprobs = tensor([[ -1.1899, -10.4579],
        [ -7.3785,  -1.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27166756987571716
Epoch 0, Step 3632: train/loss = 0.02575494349002838, train/raw-loss = 0.0012694974429905415, train/logprobs = tensor([[ -1.6072, -14.0001],
        [ -8.3124,  -2.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24485448002815247
Epoch 0, Step 3633: train/loss = 0.030075890943408012, train/raw-loss = 0.00440928153693676, train/logprobs = tensor([[ -1.8768, -17.8003],
        [ -7.6011,  -4.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566660940647125
Epoch 0, Step 3634: train/loss = 0.026934681460261345, train/raw-loss = 0.0018476382829248905, train/logprobs = tensor([[ -0.9350, -13.8366],
        [ -7.0545,  -3.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508704364299774
Epoch 0, Step 3635: train/loss = 0.028790118172764778, train/raw-loss = 0.0011981729185208678, train/logprobs = tensor([[ -2.0583, -11.9000],
        [ -9.7044,  -2.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27591943740844727
Epoch 0, Step 3636: train/loss = 0.028863802552223206, train/raw-loss = 0.0005888526211492717, train/logprobs = tensor([[ -1.5327, -19.8051],
        [ -8.7834,  -3.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2827495336532593
Epoch 0, Step 3637: train/loss = 0.04003581032156944, train/raw-loss = 0.009035207331180573, train/logprobs = tensor([[ -2.4776, -16.6618],
        [ -7.7247,  -4.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3100060224533081
Epoch 0, Step 3638: train/loss = 0.027652457356452942, train/raw-loss = 0.0013222601264715195, train/logprobs = tensor([[ -1.3609, -17.4034],
        [ -9.1179,  -4.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26330193877220154
Epoch 0, Step 3639: train/loss = 0.029701590538024902, train/raw-loss = 0.0022007322404533625, train/logprobs = tensor([[ -1.3935, -13.6503],
        [ -7.3976,  -2.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27500855922698975
Epoch 0, Step 3640: train/loss = 0.02777010202407837, train/raw-loss = 0.0008022971451282501, train/logprobs = tensor([[ -1.1873, -14.7579],
        [ -8.4965,  -2.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696780562400818
Epoch 0, Step 3641: train/loss = 0.030386745929718018, train/raw-loss = 0.002747395308688283, train/logprobs = tensor([[ -0.8458, -15.4177],
        [ -6.5040,  -3.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27639347314834595
Epoch 0, Step 3642: train/loss = 0.031894609332084656, train/raw-loss = 0.0027978222351521254, train/logprobs = tensor([[ -1.0327, -11.6266],
        [ -6.5895,  -1.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2909678518772125
Epoch 0, Step 3643: train/loss = 0.026252789422869682, train/raw-loss = 0.002770469756796956, train/logprobs = tensor([[ -1.5232, -17.3900],
        [ -7.7043,  -4.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23482319712638855
Epoch 0, Step 3644: train/loss = 0.03279700502753258, train/raw-loss = 0.004635515622794628, train/logprobs = tensor([[ -1.8167, -12.1009],
        [ -7.1151,  -3.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28161489963531494
Epoch 0, Step 3645: train/loss = 0.03468728065490723, train/raw-loss = 0.00745945330709219, train/logprobs = tensor([[ -0.8300, -13.1251],
        [ -5.8133,  -2.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722782492637634
Epoch 0, Step 3646: train/loss = 0.030176201835274696, train/raw-loss = 0.0030742334201931953, train/logprobs = tensor([[ -1.1499, -11.9065],
        [ -7.2490,  -2.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27101969718933105
Epoch 0, Step 3647: train/loss = 0.02541074901819229, train/raw-loss = 0.0014795614406466484, train/logprobs = tensor([[ -1.3207, -12.1428],
        [ -8.4657,  -2.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23931187391281128
Epoch 0, Step 3648: train/loss = 0.027584880590438843, train/raw-loss = 0.000596847094129771, train/logprobs = tensor([[ -1.6987, -16.4291],
        [ -9.1795,  -3.4978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698803246021271
Epoch 0, Step 3649: train/loss = 0.031045988202095032, train/raw-loss = 0.001961631467565894, train/logprobs = tensor([[ -1.5485, -12.9634],
        [ -9.1990,  -2.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29084357619285583
Epoch 0, Step 3650: train/loss = 0.02976215071976185, train/raw-loss = 0.0013297329423949122, train/logprobs = tensor([[ -1.6439, -14.2224],
        [ -8.8060,  -2.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28432416915893555
Epoch 0, Step 3651: train/loss = 0.03415563702583313, train/raw-loss = 0.0035630487836897373, train/logprobs = tensor([[ -1.2155, -11.0491],
        [ -6.4880,  -2.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059258759021759
Epoch 0, Step 3652: train/loss = 0.028849400579929352, train/raw-loss = 0.0012575904838740826, train/logprobs = tensor([[ -1.6417, -16.5717],
        [ -9.5101,  -3.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759180963039398
Epoch 0, Step 3653: train/loss = 0.027874253690242767, train/raw-loss = 0.0030675537418574095, train/logprobs = tensor([[ -1.2556, -15.9087],
        [ -8.2214,  -4.2368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2480670064687729
Epoch 0, Step 3654: train/loss = 0.037892717868089676, train/raw-loss = 0.008594338782131672, train/logprobs = tensor([[ -1.5614, -11.5539],
        [ -8.0715,  -3.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929838001728058
Epoch 0, Step 3655: train/loss = 0.0283757783472538, train/raw-loss = 0.0008198785944841802, train/logprobs = tensor([[ -0.9149, -15.4955],
        [ -8.3574,  -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2755589783191681
Epoch 0, Step 3656: train/loss = 0.030559414997696877, train/raw-loss = 0.004471693187952042, train/logprobs = tensor([[ -1.2871, -11.2102],
        [ -6.6895,  -2.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26087722182273865
Epoch 0, Step 3657: train/loss = 0.03442825749516487, train/raw-loss = 0.005854316987097263, train/logprobs = tensor([[ -1.9763, -15.0762],
        [ -8.6358,  -2.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28573939204216003
Epoch 0, Step 3658: train/loss = 0.02961062639951706, train/raw-loss = 0.0004958302597515285, train/logprobs = tensor([[ -1.6354, -16.4929],
        [ -9.4127,  -3.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29114794731140137
Epoch 0, Step 3659: train/loss = 0.025923725217580795, train/raw-loss = 0.0017393084708601236, train/logprobs = tensor([[ -1.5716, -15.9428],
        [ -8.1083,  -4.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24184419214725494
Epoch 0, Step 3660: train/loss = 0.03940948098897934, train/raw-loss = 0.010224150493741035, train/logprobs = tensor([[ -1.1930, -11.8416],
        [ -6.5048,  -3.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29185327887535095
Epoch 0, Step 3661: train/loss = 0.06448404490947723, train/raw-loss = 0.041799146682024, train/logprobs = tensor([[-1.0528, -9.7284],
        [-6.0922, -3.4561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22684898972511292
Epoch 0, Step 3662: train/loss = 0.0307154580950737, train/raw-loss = 0.008443274535238743, train/logprobs = tensor([[ -0.9798, -12.1398],
        [ -5.2581,  -3.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22272183001041412
Epoch 0, Step 3663: train/loss = 0.028863880783319473, train/raw-loss = 0.002442806726321578, train/logprobs = tensor([[ -1.5364, -15.5324],
        [ -8.9480,  -3.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642107307910919
Epoch 0, Step 3664: train/loss = 0.027996256947517395, train/raw-loss = 0.0010933709563687444, train/logprobs = tensor([[ -1.5346, -15.1892],
        [ -9.9413,  -3.3353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2690288722515106
Epoch 0, Step 3665: train/loss = 0.031021246686577797, train/raw-loss = 0.0026021795347332954, train/logprobs = tensor([[ -1.2298, -11.9556],
        [ -7.7116,  -2.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28419065475463867
Epoch 0, Step 3666: train/loss = 0.0329069159924984, train/raw-loss = 0.004013472702354193, train/logprobs = tensor([[ -1.2302, -14.6681],
        [ -7.1263,  -3.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889344394207001
Epoch 0, Step 3667: train/loss = 0.025089772418141365, train/raw-loss = 0.0002449351013638079, train/logprobs = tensor([[ -2.1754, -17.6172],
        [-10.3979,  -2.9678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24844837188720703
Epoch 0, Step 3668: train/loss = 0.030003845691680908, train/raw-loss = 0.0006236923509277403, train/logprobs = tensor([[ -1.2536, -13.4990],
        [ -8.7035,  -3.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29380151629447937
Epoch 0, Step 3669: train/loss = 0.030802514404058456, train/raw-loss = 0.0013007388915866613, train/logprobs = tensor([[ -1.0967, -15.3550],
        [ -8.0651,  -2.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29501771926879883
Epoch 0, Step 3670: train/loss = 0.03024524264037609, train/raw-loss = 0.0015766879078000784, train/logprobs = tensor([[ -1.1277, -13.0855],
        [ -7.2841,  -2.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866855263710022
Epoch 0, Step 3671: train/loss = 0.028610166162252426, train/raw-loss = 0.0044745635241270065, train/logprobs = tensor([[ -1.3635, -15.0997],
        [ -6.6492,  -2.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2413560152053833
Epoch 0, Step 3672: train/loss = 0.031112847849726677, train/raw-loss = 0.004384756088256836, train/logprobs = tensor([[ -1.2596, -16.3235],
        [ -7.3048,  -4.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2672809064388275
Epoch 0, Step 3673: train/loss = 0.03238793462514877, train/raw-loss = 0.002852511825039983, train/logprobs = tensor([[ -1.0643, -19.0854],
        [ -7.1079,  -4.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2953542172908783
Epoch 0, Step 3674: train/loss = 0.03115246817469597, train/raw-loss = 0.0006051122909411788, train/logprobs = tensor([[ -1.6583, -14.4989],
        [-10.5185,  -3.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30547356605529785
Epoch 0, Step 3675: train/loss = 0.02642659656703472, train/raw-loss = 0.002894630655646324, train/logprobs = tensor([[ -2.7771, -10.4842],
        [ -9.9329,  -1.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23531965911388397
Epoch 0, Step 3676: train/loss = 0.030383285135030746, train/raw-loss = 0.002789751160889864, train/logprobs = tensor([[ -1.4927, -13.5077],
        [ -8.8916,  -3.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759353220462799
Epoch 0, Step 3677: train/loss = 0.02993815764784813, train/raw-loss = 0.002684260718524456, train/logprobs = tensor([[ -1.2575, -16.5186],
        [ -6.9991,  -3.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272538959980011
Epoch 0, Step 3678: train/loss = 0.030580107122659683, train/raw-loss = 0.001766672939993441, train/logprobs = tensor([[ -1.6217, -14.8468],
        [ -8.3756,  -3.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881343364715576
Epoch 0, Step 3679: train/loss = 0.03581571951508522, train/raw-loss = 0.005832872819155455, train/logprobs = tensor([[ -1.3256, -13.1750],
        [ -6.4975,  -3.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998284697532654
Epoch 0, Step 3680: train/loss = 0.030586818233132362, train/raw-loss = 0.0029901345260441303, train/logprobs = tensor([[ -1.4559, -12.3483],
        [ -8.0101,  -2.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759668529033661
Epoch 0, Step 3681: train/loss = 0.02724866196513176, train/raw-loss = 0.00023720072931610048, train/logprobs = tensor([[ -1.9904, -15.1895],
        [-10.7204,  -3.8237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27011460065841675
Epoch 0, Step 3682: train/loss = 0.02916533313691616, train/raw-loss = 0.0032830098643898964, train/logprobs = tensor([[ -1.5195, -11.8927],
        [ -7.6413,  -2.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2588232457637787
Epoch 0, Step 3683: train/loss = 0.026740191504359245, train/raw-loss = 0.002810854697600007, train/logprobs = tensor([[ -1.3042, -16.4186],
        [ -6.7074,  -2.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23929335176944733
Epoch 0, Step 3684: train/loss = 0.0297695342451334, train/raw-loss = 0.0007321632001549006, train/logprobs = tensor([[ -1.4600, -15.2336],
        [ -8.3195,  -2.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29037371277809143
Epoch 0, Step 3685: train/loss = 0.025970807299017906, train/raw-loss = 0.00048330193385481834, train/logprobs = tensor([[ -2.0907, -14.7818],
        [-10.5013,  -3.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2548750340938568
Epoch 0, Step 3686: train/loss = 0.033091381192207336, train/raw-loss = 0.0008978227851912379, train/logprobs = tensor([[ -1.3930, -14.0173],
        [ -8.9884,  -3.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219355642795563
Epoch 0, Step 3687: train/loss = 0.026340100914239883, train/raw-loss = 0.0019795105326920748, train/logprobs = tensor([[ -2.0848, -16.2405],
        [-10.4009,  -4.2697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24360589683055878
Epoch 0, Step 3688: train/loss = 0.028476007282733917, train/raw-loss = 0.0021395368967205286, train/logprobs = tensor([[ -1.1785, -15.8009],
        [ -7.1884,  -2.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26336470246315
Epoch 0, Step 3689: train/loss = 0.026523109525442123, train/raw-loss = 0.0012717894278466702, train/logprobs = tensor([[ -1.6527, -17.8206],
        [ -8.1124,  -4.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25251320004463196
Epoch 0, Step 3690: train/loss = 0.02781158871948719, train/raw-loss = 0.00276731769554317, train/logprobs = tensor([[ -1.1660, -12.6233],
        [ -6.4288,  -2.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504427134990692
Epoch 0, Step 3691: train/loss = 0.03047855570912361, train/raw-loss = 0.0020414385944604874, train/logprobs = tensor([[ -1.4368, -11.5096],
        [ -7.7100,  -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28437113761901855
Epoch 0, Step 3692: train/loss = 0.031128328293561935, train/raw-loss = 0.004207198973745108, train/logprobs = tensor([[ -1.6677, -14.0020],
        [ -8.3803,  -3.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2692112922668457
Epoch 0, Step 3693: train/loss = 0.03161513805389404, train/raw-loss = 0.0030435281805694103, train/logprobs = tensor([[ -1.4101, -13.3909],
        [ -7.8453,  -2.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28571605682373047
Epoch 0, Step 3694: train/loss = 0.029283646494150162, train/raw-loss = 0.0017287321388721466, train/logprobs = tensor([[ -1.1635, -11.5204],
        [ -7.9272,  -3.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27554911375045776
Epoch 0, Step 3695: train/loss = 0.027869172394275665, train/raw-loss = 0.0041715046390891075, train/logprobs = tensor([[ -1.1921, -11.0902],
        [ -6.9787,  -1.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23697666823863983
Epoch 0, Step 3696: train/loss = 0.0277266763150692, train/raw-loss = 0.0005751048447564244, train/logprobs = tensor([[ -1.6373, -14.5327],
        [ -9.4703,  -3.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27151572704315186
Epoch 0, Step 3697: train/loss = 0.07455313950777054, train/raw-loss = 0.04746082425117493, train/logprobs = tensor([[ -1.0501, -16.9171],
        [ -6.6964,  -4.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27092307806015015
Epoch 0, Step 3698: train/loss = 0.02665823884308338, train/raw-loss = 0.001424760790541768, train/logprobs = tensor([[ -1.4788, -17.5573],
        [ -8.5662,  -4.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523347735404968
Epoch 0, Step 3699: train/loss = 0.03126707673072815, train/raw-loss = 0.002387902932241559, train/logprobs = tensor([[ -1.2517, -15.1222],
        [ -6.8166,  -3.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887917459011078
Epoch 0, Step 3700: train/loss = 0.028482263907790184, train/raw-loss = 0.000591921154409647, train/logprobs = tensor([[ -1.1094, -15.2983],
        [ -9.3480,  -3.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27890342473983765
Epoch 0, Step 3701: train/loss = 0.03204092010855675, train/raw-loss = 0.0007834852440282702, train/logprobs = tensor([[ -1.0927, -18.3325],
        [ -8.1470,  -2.2840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3125743269920349
Epoch 0, Step 3702: train/loss = 0.03531893715262413, train/raw-loss = 0.005966672673821449, train/logprobs = tensor([[ -1.4423, -13.8286],
        [ -7.0040,  -2.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2935226559638977
Epoch 0, Step 3703: train/loss = 0.027451004832983017, train/raw-loss = 0.0014103010762482882, train/logprobs = tensor([[ -1.5085, -17.1342],
        [ -9.1173,  -3.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260407030582428
Epoch 0, Step 3704: train/loss = 0.0804988294839859, train/raw-loss = 0.05346570163965225, train/logprobs = tensor([[ -1.4322, -10.3990],
        [ -9.1224,  -3.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703312635421753
Epoch 0, Step 3705: train/loss = 0.0264348853379488, train/raw-loss = 0.0004996647476218641, train/logprobs = tensor([[ -1.1791, -15.8730],
        [ -8.5408,  -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2593522071838379
Epoch 0, Step 3706: train/loss = 0.041565775871276855, train/raw-loss = 0.010221172124147415, train/logprobs = tensor([[ -0.8416, -14.1786],
        [ -7.7147,  -4.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.313446044921875
Epoch 0, Step 3707: train/loss = 0.037677086889743805, train/raw-loss = 0.007151314988732338, train/logprobs = tensor([[ -2.0634, -16.2766],
        [ -7.0244,  -3.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3052577078342438
Epoch 0, Step 3708: train/loss = 0.027640946209430695, train/raw-loss = 0.0008547044708393514, train/logprobs = tensor([[ -1.4735, -19.8301],
        [ -7.9403,  -4.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2678624093532562
Epoch 0, Step 3709: train/loss = 0.027530232444405556, train/raw-loss = 7.736922998446971e-05, train/logprobs = tensor([[ -2.7166, -12.6615],
        [-12.9667,  -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2745286226272583
Epoch 0, Step 3710: train/loss = 0.031693410128355026, train/raw-loss = 0.0044035837054252625, train/logprobs = tensor([[ -1.0837, -16.7088],
        [ -7.2043,  -4.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27289825677871704
Epoch 0, Step 3711: train/loss = 0.03135853260755539, train/raw-loss = 0.005749455653131008, train/logprobs = tensor([[ -1.1137, -21.3258],
        [ -6.4159,  -4.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25609076023101807
Epoch 0, Step 3712: train/loss = 0.030116889625787735, train/raw-loss = 0.005560613702982664, train/logprobs = tensor([[ -0.7255, -17.3054],
        [ -5.5185,  -3.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24556276202201843
Epoch 0, Step 3713: train/loss = 0.030612841248512268, train/raw-loss = 0.0015072997193783522, train/logprobs = tensor([[ -1.1870, -12.8102],
        [ -7.8724,  -2.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2910554111003876
Epoch 0, Step 3714: train/loss = 0.029794257134199142, train/raw-loss = 0.001780057675205171, train/logprobs = tensor([[ -1.4036, -15.8432],
        [ -7.5989,  -2.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801419794559479
Epoch 0, Step 3715: train/loss = 0.04770207405090332, train/raw-loss = 0.016582008451223373, train/logprobs = tensor([[-1.1899, -9.4481],
        [-7.9675, -3.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3112006187438965
Epoch 0, Step 3716: train/loss = 0.029284905642271042, train/raw-loss = 0.004068117588758469, train/logprobs = tensor([[ -1.0179, -14.8041],
        [ -6.3902,  -2.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25216788053512573
Epoch 0, Step 3717: train/loss = 0.031519681215286255, train/raw-loss = 0.0027314473409205675, train/logprobs = tensor([[ -1.4555, -22.8795],
        [ -8.8721,  -4.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28788232803344727
Epoch 0, Step 3718: train/loss = 0.030917849391698837, train/raw-loss = 0.0010591550962999463, train/logprobs = tensor([[ -1.1380, -11.7260],
        [ -8.0677,  -2.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985869348049164
Epoch 0, Step 3719: train/loss = 0.031133122742176056, train/raw-loss = 0.000814012426417321, train/logprobs = tensor([[ -1.5470, -14.9566],
        [ -9.1189,  -3.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30319109559059143
Epoch 0, Step 3720: train/loss = 0.03735128045082092, train/raw-loss = 0.006576234009116888, train/logprobs = tensor([[ -1.0412, -13.5276],
        [ -6.4107,  -2.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077504336833954
Epoch 0, Step 3721: train/loss = 0.0562717467546463, train/raw-loss = 0.02577792853116989, train/logprobs = tensor([[-1.5620, -9.6414],
        [-8.0632, -1.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3049381971359253
Epoch 0, Step 3722: train/loss = 0.03094545006752014, train/raw-loss = 0.006273901555687189, train/logprobs = tensor([[ -1.4050, -10.8395],
        [ -8.0217,  -2.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2467155009508133
Epoch 0, Step 3723: train/loss = 0.03071647696197033, train/raw-loss = 0.0017197499983012676, train/logprobs = tensor([[ -0.8824, -17.5502],
        [ -6.9240,  -5.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28996726870536804
Epoch 0, Step 3724: train/loss = 0.03218289464712143, train/raw-loss = 0.012062217108905315, train/logprobs = tensor([[ -0.9220, -13.3517],
        [ -5.3510,  -2.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20120678842067719
Epoch 0, Step 3725: train/loss = 0.02758157067000866, train/raw-loss = 0.0006121696787886322, train/logprobs = tensor([[ -1.4015, -13.1905],
        [ -9.0673,  -2.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2696940302848816
Epoch 0, Step 3726: train/loss = 0.03044305555522442, train/raw-loss = 0.0011859512887895107, train/logprobs = tensor([[ -1.3406, -15.2850],
        [ -7.9506,  -3.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925710380077362
Epoch 0, Step 3727: train/loss = 0.027640292420983315, train/raw-loss = 0.003452128265053034, train/logprobs = tensor([[ -1.1798, -12.4449],
        [ -6.7917,  -2.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2418816238641739
Epoch 0, Step 3728: train/loss = 0.02625253237783909, train/raw-loss = 0.002516629407182336, train/logprobs = tensor([[ -1.5082, -16.8166],
        [ -8.3017,  -4.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23735904693603516
Epoch 0, Step 3729: train/loss = 0.03407473489642143, train/raw-loss = 0.00227485504001379, train/logprobs = tensor([[ -1.2408, -12.2885],
        [ -7.7793,  -2.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179987967014313
Epoch 0, Step 3730: train/loss = 0.1128384917974472, train/raw-loss = 0.08750157803297043, train/logprobs = tensor([[ -1.7929, -12.3268],
        [ -5.8645,  -3.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25336921215057373
Epoch 0, Step 3731: train/loss = 0.026324324309825897, train/raw-loss = 0.00099173781927675, train/logprobs = tensor([[ -1.4749, -13.4866],
        [ -8.9059,  -2.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25332584977149963
Epoch 0, Step 3732: train/loss = 0.02845192886888981, train/raw-loss = 0.0005118575063534081, train/logprobs = tensor([[ -1.6366, -12.3675],
        [-10.0085,  -3.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27940070629119873
Epoch 0, Step 3733: train/loss = 0.03390531614422798, train/raw-loss = 0.0018082954920828342, train/logprobs = tensor([[ -0.9387, -17.0214],
        [ -6.6468,  -4.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32097020745277405
Epoch 0, Step 3734: train/loss = 0.04230828955769539, train/raw-loss = 0.01366199366748333, train/logprobs = tensor([[ -1.8610, -15.3571],
        [ -9.6457,  -4.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2864629924297333
Epoch 0, Step 3735: train/loss = 0.026434702798724174, train/raw-loss = 0.0009246923145838082, train/logprobs = tensor([[ -1.0990, -13.3454],
        [ -7.9491,  -2.1806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551000714302063
Epoch 0, Step 3736: train/loss = 0.04055209830403328, train/raw-loss = 0.01190658938139677, train/logprobs = tensor([[ -1.8058, -10.6916],
        [ -8.5019,  -2.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28645509481430054
Epoch 0, Step 3737: train/loss = 0.03196682035923004, train/raw-loss = 0.004773580469191074, train/logprobs = tensor([[ -1.1531, -13.5968],
        [ -7.2440,  -3.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27193236351013184
Epoch 0, Step 3738: train/loss = 0.03312809765338898, train/raw-loss = 0.0021864462178200483, train/logprobs = tensor([[ -1.9078, -10.2066],
        [ -9.9199,  -2.2834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3094165027141571
Epoch 0, Step 3739: train/loss = 0.027494292706251144, train/raw-loss = 0.0027379856910556555, train/logprobs = tensor([[ -1.4257, -15.2543],
        [ -8.6153,  -3.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24756306409835815
Epoch 0, Step 3740: train/loss = 0.027086641639471054, train/raw-loss = 0.0020315125584602356, train/logprobs = tensor([[ -1.2670, -16.1904],
        [ -7.3958,  -3.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505512833595276
Epoch 0, Step 3741: train/loss = 0.030280783772468567, train/raw-loss = 0.0036312814336270094, train/logprobs = tensor([[ -0.9663, -15.6361],
        [ -6.3916,  -4.3998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664949893951416
Epoch 0, Step 3742: train/loss = 0.029502905905246735, train/raw-loss = 0.0014832132728770375, train/logprobs = tensor([[ -1.0232, -12.7970],
        [ -7.4294,  -2.6654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801969349384308
Epoch 0, Step 3743: train/loss = 0.03759603202342987, train/raw-loss = 0.013515962287783623, train/logprobs = tensor([[ -1.1430, -14.4106],
        [ -7.0815,  -4.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240800678730011
Epoch 0, Step 3744: train/loss = 0.0317392572760582, train/raw-loss = 0.003446023678407073, train/logprobs = tensor([[ -1.3590, -13.6532],
        [ -7.7266,  -3.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282932311296463
Epoch 0, Step 3745: train/loss = 0.029230261221528053, train/raw-loss = 0.0008667276706546545, train/logprobs = tensor([[ -1.2140, -15.1001],
        [ -8.3913,  -1.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28363534808158875
Epoch 0, Step 3746: train/loss = 0.03049144521355629, train/raw-loss = 0.003492719726637006, train/logprobs = tensor([[ -1.0690, -13.7777],
        [ -6.3458,  -3.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26998722553253174
Epoch 0, Step 3747: train/loss = 0.026490654796361923, train/raw-loss = 0.0010006538359448314, train/logprobs = tensor([[ -1.7500, -14.0023],
        [-10.1217,  -2.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549000084400177
Epoch 0, Step 3748: train/loss = 0.0828700140118599, train/raw-loss = 0.061227742582559586, train/logprobs = tensor([[ -2.1534, -10.8951],
        [ -6.2919,  -2.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21642278134822845
Epoch 0, Step 3749: train/loss = 0.026239389553666115, train/raw-loss = 0.0012651258148252964, train/logprobs = tensor([[ -1.4694, -13.7008],
        [ -8.1154,  -2.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24974264204502106
Epoch 0, Step 3750: train/loss = 0.0855199471116066, train/raw-loss = 0.061629485338926315, train/logprobs = tensor([[ -1.9688, -15.9368],
        [ -9.1655,  -4.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23890458047389984
Epoch 0, Step 3751: train/loss = 0.027793895453214645, train/raw-loss = 0.000506654498167336, train/logprobs = tensor([[ -2.1586, -17.2789],
        [ -9.6614,  -2.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2728723883628845
Epoch 0, Step 3752: train/loss = 0.0281696654856205, train/raw-loss = 0.0029955741483718157, train/logprobs = tensor([[ -1.4869, -15.7281],
        [ -8.9946,  -4.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517409026622772
Epoch 0, Step 3753: train/loss = 0.028213033452630043, train/raw-loss = 0.004556416533887386, train/logprobs = tensor([[ -1.1855, -20.1004],
        [ -8.8005,  -5.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23656615614891052
Epoch 0, Step 3754: train/loss = 0.03032701462507248, train/raw-loss = 0.005146087147295475, train/logprobs = tensor([[ -0.9842, -15.1950],
        [ -6.6560,  -2.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518092691898346
Epoch 0, Step 3755: train/loss = 0.028473328799009323, train/raw-loss = 0.0013845012290403247, train/logprobs = tensor([[ -1.0048, -17.5616],
        [ -7.6585,  -5.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708882689476013
Epoch 0, Step 3756: train/loss = 0.02912323549389839, train/raw-loss = 0.003152021672576666, train/logprobs = tensor([[ -1.5900, -13.8549],
        [ -7.0039,  -2.9136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2597121596336365
Epoch 0, Step 3757: train/loss = 0.027010999619960785, train/raw-loss = 0.002302536740899086, train/logprobs = tensor([[ -1.5749, -14.9453],
        [ -8.2041,  -3.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24708464741706848
Epoch 0, Step 3758: train/loss = 0.02925218641757965, train/raw-loss = 0.000733894354198128, train/logprobs = tensor([[ -1.0619, -14.5272],
        [ -9.1383,  -3.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851829528808594
Epoch 0, Step 3759: train/loss = 0.03342009335756302, train/raw-loss = 0.0023307548835873604, train/logprobs = tensor([[ -1.1777, -12.8703],
        [ -7.1092,  -2.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108934164047241
Epoch 0, Step 3760: train/loss = 0.0317813940346241, train/raw-loss = 0.001164900022558868, train/logprobs = tensor([[ -1.5954, -12.2444],
        [ -8.5410,  -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3061649203300476
Epoch 0, Step 3761: train/loss = 0.033446479588747025, train/raw-loss = 0.004113436676561832, train/logprobs = tensor([[ -1.8050, -11.2356],
        [ -9.3059,  -3.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29333043098449707
Epoch 0, Step 3762: train/loss = 0.02403971552848816, train/raw-loss = 0.002087751403450966, train/logprobs = tensor([[ -2.3503,  -9.9600],
        [-10.9347,  -2.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21951963007450104
Epoch 0, Step 3763: train/loss = 0.029279127717018127, train/raw-loss = 0.0017415815964341164, train/logprobs = tensor([[ -1.5604, -13.5188],
        [ -7.8297,  -2.6828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27537545561790466
Epoch 0, Step 3764: train/loss = 0.032191164791584015, train/raw-loss = 0.0025188950821757317, train/logprobs = tensor([[ -1.2253, -15.1966],
        [ -7.9065,  -3.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967227101325989
Epoch 0, Step 3765: train/loss = 0.028867993503808975, train/raw-loss = 0.00547636765986681, train/logprobs = tensor([[ -0.9240, -15.9416],
        [ -6.8481,  -4.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339162826538086
Epoch 0, Step 3766: train/loss = 0.0316876620054245, train/raw-loss = 0.007443619892001152, train/logprobs = tensor([[ -0.9701, -15.6752],
        [ -6.6752,  -4.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24244040250778198
Epoch 0, Step 3767: train/loss = 0.02960287779569626, train/raw-loss = 0.0011965386802330613, train/logprobs = tensor([[ -1.2786, -17.9005],
        [ -8.2326,  -4.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840633988380432
Epoch 0, Step 3768: train/loss = 0.07007329165935516, train/raw-loss = 0.04673553258180618, train/logprobs = tensor([[ -1.5239, -14.1922],
        [ -5.8700,  -4.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233377605676651
Epoch 0, Step 3769: train/loss = 0.031568340957164764, train/raw-loss = 0.00010227410530205816, train/logprobs = tensor([[ -1.7649, -15.2319],
        [-10.7421,  -3.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3146606683731079
Epoch 0, Step 3770: train/loss = 0.027810772880911827, train/raw-loss = 0.00015852591604925692, train/logprobs = tensor([[ -1.8550, -15.4715],
        [-11.0487,  -2.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765224874019623
Epoch 0, Step 3771: train/loss = 0.029157768934965134, train/raw-loss = 0.0024703326635062695, train/logprobs = tensor([[ -1.3872, -13.9825],
        [ -7.1792,  -3.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26687437295913696
Epoch 0, Step 3772: train/loss = 0.03079487942159176, train/raw-loss = 0.0008087952737696469, train/logprobs = tensor([[ -1.1170, -12.9396],
        [ -7.6474,  -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2998608350753784
Epoch 0, Step 3773: train/loss = 0.029425520449876785, train/raw-loss = 0.0015821204287931323, train/logprobs = tensor([[ -1.7145, -14.3683],
        [ -8.1723,  -2.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27843397855758667
Epoch 0, Step 3774: train/loss = 0.027018524706363678, train/raw-loss = 0.0027730301953852177, train/logprobs = tensor([[ -1.2141, -11.4857],
        [ -7.0848,  -2.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24245494604110718
Epoch 0, Step 3775: train/loss = 0.027491291984915733, train/raw-loss = 0.004160253331065178, train/logprobs = tensor([[ -0.9702, -15.1097],
        [ -6.3805,  -4.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23331037163734436
Epoch 0, Step 3776: train/loss = 0.04854381084442139, train/raw-loss = 0.021265964955091476, train/logprobs = tensor([[ -0.7542, -12.0346],
        [ -5.5572,  -2.3601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727784514427185
Epoch 0, Step 3777: train/loss = 0.03020164929330349, train/raw-loss = 0.0024670979473739862, train/logprobs = tensor([[ -1.3871, -15.5799],
        [ -8.4725,  -2.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2773455083370209
Epoch 0, Step 3778: train/loss = 0.029056966304779053, train/raw-loss = 0.0020953102502971888, train/logprobs = tensor([[ -0.8650, -19.7579],
        [ -6.5256,  -5.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26961657404899597
Epoch 0, Step 3779: train/loss = 0.03422677516937256, train/raw-loss = 0.01041741855442524, train/logprobs = tensor([[ -1.5139, -18.4411],
        [ -6.3204,  -3.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380935549736023
Epoch 0, Step 3780: train/loss = 0.03268568590283394, train/raw-loss = 0.0019549140706658363, train/logprobs = tensor([[ -1.4476, -13.4011],
        [ -8.2734,  -3.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30730772018432617
Epoch 0, Step 3781: train/loss = 0.02934137172996998, train/raw-loss = 0.005726099945604801, train/logprobs = tensor([[ -1.3344, -12.7455],
        [ -6.1070,  -2.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23615270853042603
Epoch 0, Step 3782: train/loss = 0.02728441171348095, train/raw-loss = 0.00037619273643940687, train/logprobs = tensor([[ -1.4339, -13.0865],
        [ -9.7138,  -3.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2690821886062622
Epoch 0, Step 3783: train/loss = 0.0268544964492321, train/raw-loss = 0.0006192394648678601, train/logprobs = tensor([[ -1.4548, -12.4146],
        [ -8.4006,  -1.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623525857925415
Epoch 0, Step 3784: train/loss = 0.02824224904179573, train/raw-loss = 0.0005890634492971003, train/logprobs = tensor([[ -1.1982, -12.8204],
        [ -8.7183,  -3.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.276531845331192
Epoch 0, Step 3785: train/loss = 0.026751717552542686, train/raw-loss = 0.0016731254290789366, train/logprobs = tensor([[ -1.6123, -14.2453],
        [ -7.6206,  -3.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507859170436859
Epoch 0, Step 3786: train/loss = 0.03257359564304352, train/raw-loss = 0.005160914734005928, train/logprobs = tensor([[ -1.1241, -15.0213],
        [ -7.4932,  -4.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.274126797914505
Epoch 0, Step 3787: train/loss = 0.03325432911515236, train/raw-loss = 0.003501661354675889, train/logprobs = tensor([[ -1.0696, -14.7616],
        [ -7.6465,  -3.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29752668738365173
Epoch 0, Step 3788: train/loss = 0.026310570538043976, train/raw-loss = 0.0008815538021735847, train/logprobs = tensor([[ -1.5410, -17.7829],
        [ -8.8192,  -2.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542901635169983
Epoch 0, Step 3789: train/loss = 0.03255930542945862, train/raw-loss = 0.007890480570495129, train/logprobs = tensor([[ -0.9208, -13.0332],
        [ -5.8082,  -3.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24668824672698975
Epoch 0, Step 3790: train/loss = 0.029467687010765076, train/raw-loss = 0.0027456001844257116, train/logprobs = tensor([[ -1.2032, -11.9519],
        [ -7.1729,  -1.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2672208845615387
Epoch 0, Step 3791: train/loss = 0.026524674147367477, train/raw-loss = 0.0012940764427185059, train/logprobs = tensor([[ -1.5101, -15.3144],
        [ -7.8177,  -4.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523059546947479
Epoch 0, Step 3792: train/loss = 0.034059517085552216, train/raw-loss = 0.002002315130084753, train/logprobs = tensor([[ -1.5060, -12.0726],
        [ -8.7013,  -2.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32057201862335205
Epoch 0, Step 3793: train/loss = 0.027276646345853806, train/raw-loss = 0.003480359446257353, train/logprobs = tensor([[ -0.8330, -16.5753],
        [ -6.1773,  -2.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23796287178993225
Epoch 0, Step 3794: train/loss = 0.026773232966661453, train/raw-loss = 0.0026037839706987143, train/logprobs = tensor([[ -1.5557, -13.4957],
        [ -8.6963,  -3.1934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24169446527957916
Epoch 0, Step 3795: train/loss = 0.02872556820511818, train/raw-loss = 0.0009713637409731746, train/logprobs = tensor([[ -0.9757, -15.3612],
        [ -8.3419,  -3.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775420546531677
Epoch 0, Step 3796: train/loss = 0.03322581201791763, train/raw-loss = 0.003819735487923026, train/logprobs = tensor([[ -0.9383, -10.4560],
        [ -6.4184,  -2.4108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29406076669692993
Epoch 0, Step 3797: train/loss = 0.030403751879930496, train/raw-loss = 0.0017005230765789747, train/logprobs = tensor([[ -1.3483, -13.6968],
        [ -7.6873,  -3.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870323061943054
Epoch 0, Step 3798: train/loss = 0.033100616186857224, train/raw-loss = 0.005432877689599991, train/logprobs = tensor([[ -1.2188, -11.5745],
        [ -8.7248,  -2.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27667737007141113
Epoch 0, Step 3799: train/loss = 0.029562169685959816, train/raw-loss = 0.0006480934098362923, train/logprobs = tensor([[ -1.5228, -13.2399],
        [ -9.1888,  -4.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2891407310962677
Epoch 0, Step 3800: train/loss = 0.03152697905898094, train/raw-loss = 0.001530173816718161, train/logprobs = tensor([[ -1.2067, -11.0296],
        [ -8.3029,  -2.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29996803402900696
Epoch 0, Step 3801: train/loss = 0.03151221200823784, train/raw-loss = 0.002985046710819006, train/logprobs = tensor([[ -1.0351, -12.7569],
        [ -7.2910,  -2.4760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28527164459228516
Epoch 0, Step 3802: train/loss = 0.03039436787366867, train/raw-loss = 0.0006262173410505056, train/logprobs = tensor([[ -1.3819, -14.1817],
        [ -9.3824,  -3.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976815104484558
Epoch 0, Step 3803: train/loss = 0.029697122052311897, train/raw-loss = 0.001147962175309658, train/logprobs = tensor([[ -1.3389, -21.0968],
        [ -8.4194,  -4.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28549158573150635
Epoch 0, Step 3804: train/loss = 0.02908148616552353, train/raw-loss = 0.0010179810924455523, train/logprobs = tensor([[ -1.6160, -15.1757],
        [ -9.0795,  -3.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2806350588798523
Epoch 0, Step 3805: train/loss = 0.029797520488500595, train/raw-loss = 0.0006773834466002882, train/logprobs = tensor([[ -1.1464, -14.3796],
        [ -8.0889,  -2.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2912013530731201
Epoch 0, Step 3806: train/loss = 0.028804033994674683, train/raw-loss = 0.002808165270835161, train/logprobs = tensor([[ -0.8342, -11.5936],
        [ -6.9521,  -2.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599586844444275
Epoch 0, Step 3807: train/loss = 0.033219266682863235, train/raw-loss = 0.004267371725291014, train/logprobs = tensor([[ -2.1216, -14.9791],
        [ -9.4799,  -2.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28951895236968994
Epoch 0, Step 3808: train/loss = 0.029158761724829674, train/raw-loss = 0.00040106079541146755, train/logprobs = tensor([[ -1.5026, -14.6834],
        [ -9.2763,  -2.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28757697343826294
Epoch 0, Step 3809: train/loss = 0.029654700309038162, train/raw-loss = 0.00177536450792104, train/logprobs = tensor([[ -0.7633, -13.5927],
        [ -6.5802,  -3.2189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787933349609375
Epoch 0, Step 3810: train/loss = 0.028077803552150726, train/raw-loss = 0.0014781311620026827, train/logprobs = tensor([[ -1.1612, -12.1101],
        [ -8.7886,  -2.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26599669456481934
Epoch 0, Step 3811: train/loss = 0.028245657682418823, train/raw-loss = 0.0005038835224695504, train/logprobs = tensor([[ -1.6107, -12.2601],
        [ -9.8902,  -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27741771936416626
Epoch 0, Step 3812: train/loss = 0.02650219388306141, train/raw-loss = 0.0006752185872755945, train/logprobs = tensor([[ -1.7578, -16.4279],
        [-10.5072,  -2.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.258269727230072
Epoch 0, Step 3813: train/loss = 0.02643793635070324, train/raw-loss = 0.001010262523777783, train/logprobs = tensor([[ -1.8163, -15.0825],
        [-11.8554,  -4.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25427672266960144
Epoch 0, Step 3814: train/loss = 0.03006906807422638, train/raw-loss = 0.0030965241603553295, train/logprobs = tensor([[ -1.4392, -10.8766],
        [ -8.5329,  -2.3083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26972541213035583
Epoch 0, Step 3815: train/loss = 0.024951111525297165, train/raw-loss = 0.0014047148870304227, train/logprobs = tensor([[ -1.3330, -10.2187],
        [ -8.3918,  -2.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2354639619588852
Epoch 0, Step 3816: train/loss = 0.028447819873690605, train/raw-loss = 0.002339123748242855, train/logprobs = tensor([[ -1.6676, -13.4041],
        [ -7.3260,  -2.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26108697056770325
Epoch 0, Step 3817: train/loss = 0.029565809294581413, train/raw-loss = 0.00583003181964159, train/logprobs = tensor([[ -0.9502, -15.2486],
        [ -6.8495,  -4.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23735776543617249
Epoch 0, Step 3818: train/loss = 0.03533892333507538, train/raw-loss = 0.008237521164119244, train/logprobs = tensor([[-0.7250, -8.8206],
        [-5.9189, -2.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.271014004945755
Epoch 0, Step 3819: train/loss = 0.02647355943918228, train/raw-loss = 0.0009858161211013794, train/logprobs = tensor([[ -1.0729, -13.6908],
        [ -8.0626,  -2.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2548774182796478
Epoch 0, Step 3820: train/loss = 0.030280740931630135, train/raw-loss = 0.0005086649325676262, train/logprobs = tensor([[ -1.1532, -11.9902],
        [ -8.1776,  -1.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2977207601070404
Epoch 0, Step 3821: train/loss = 0.027874663472175598, train/raw-loss = 0.0010587682481855154, train/logprobs = tensor([[ -1.1423, -17.7084],
        [ -8.1370,  -5.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2681589424610138
Epoch 0, Step 3822: train/loss = 0.02475244365632534, train/raw-loss = 0.0022618253715336323, train/logprobs = tensor([[ -1.1362, -13.0313],
        [ -7.4462,  -2.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22490617632865906
Epoch 0, Step 3823: train/loss = 0.03281213715672493, train/raw-loss = 0.003949505276978016, train/logprobs = tensor([[ -1.0857, -18.3761],
        [ -6.3436,  -5.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2886263132095337
Epoch 0, Step 3824: train/loss = 0.09301070868968964, train/raw-loss = 0.06688211113214493, train/logprobs = tensor([[-1.2009, -9.7730],
        [-7.9981, -1.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612859904766083
Epoch 0, Step 3825: train/loss = 0.02981143444776535, train/raw-loss = 0.0025200224481523037, train/logprobs = tensor([[ -1.5013, -11.4967],
        [ -7.5917,  -2.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2729141116142273
Epoch 0, Step 3826: train/loss = 0.02865488827228546, train/raw-loss = 0.0014136378886178136, train/logprobs = tensor([[ -1.0662, -13.6304],
        [ -7.8191,  -3.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724124789237976
Epoch 0, Step 3827: train/loss = 0.028310583904385567, train/raw-loss = 0.002508827717974782, train/logprobs = tensor([[ -1.2821, -15.2100],
        [ -8.1442,  -4.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25801756978034973
Epoch 0, Step 3828: train/loss = 0.031976521015167236, train/raw-loss = 0.002522116294130683, train/logprobs = tensor([[ -0.9700, -11.6416],
        [ -7.3610,  -1.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945440709590912
Epoch 0, Step 3829: train/loss = 0.030168600380420685, train/raw-loss = 0.0025620523374527693, train/logprobs = tensor([[ -0.9205, -18.7121],
        [ -7.8267,  -4.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.276065468788147
Epoch 0, Step 3830: train/loss = 0.02747795730829239, train/raw-loss = 0.0016879017930477858, train/logprobs = tensor([[ -1.2512, -13.6887],
        [ -9.2131,  -2.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25790056586265564
Epoch 0, Step 3831: train/loss = 0.02685857005417347, train/raw-loss = 0.006248426623642445, train/logprobs = tensor([[ -1.6923, -12.8558],
        [ -7.5605,  -2.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2061014324426651
Epoch 0, Step 3832: train/loss = 0.03244515880942345, train/raw-loss = 0.011300834827125072, train/logprobs = tensor([[ -2.2041, -18.4943],
        [ -6.6529,  -4.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.211443230509758
Epoch 0, Step 3833: train/loss = 0.03141669183969498, train/raw-loss = 0.0009826665045693517, train/logprobs = tensor([[ -1.7081, -13.6739],
        [ -9.0130,  -2.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30434027314186096
Epoch 0, Step 3834: train/loss = 0.025296565145254135, train/raw-loss = 0.00244673783890903, train/logprobs = tensor([[ -1.1136, -13.2730],
        [ -6.8966,  -3.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22849825024604797
Epoch 0, Step 3835: train/loss = 0.030052006244659424, train/raw-loss = 0.0022924779914319515, train/logprobs = tensor([[ -1.1907, -14.6653],
        [ -7.7843,  -2.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27759528160095215
Epoch 0, Step 3836: train/loss = 0.026551099494099617, train/raw-loss = 0.0018028129125013947, train/logprobs = tensor([[ -1.1248, -14.4188],
        [ -7.1814,  -3.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24748286604881287
Epoch 0, Step 3837: train/loss = 0.028552809730172157, train/raw-loss = 0.003588960273191333, train/logprobs = tensor([[ -1.7683, -13.8627],
        [ -9.2500,  -2.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24963849782943726
Epoch 0, Step 3838: train/loss = 0.03754563629627228, train/raw-loss = 0.009964062832295895, train/logprobs = tensor([[ -1.5706, -16.4981],
        [ -6.7386,  -2.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758157551288605
Epoch 0, Step 3839: train/loss = 0.025880279019474983, train/raw-loss = 0.0015895944088697433, train/logprobs = tensor([[ -1.1775, -12.8002],
        [ -7.1287,  -2.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2429068386554718
Epoch 0, Step 3840: train/loss = 0.03167836368083954, train/raw-loss = 0.0008509785402566195, train/logprobs = tensor([[ -1.2826, -14.2480],
        [ -8.2251,  -3.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3082738518714905
Epoch 0, Step 3841: train/loss = 0.029483409598469734, train/raw-loss = 0.00021666547399945557, train/logprobs = tensor([[ -1.3964, -16.7039],
        [-10.0121,  -3.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292667418718338
Epoch 0, Step 3842: train/loss = 0.9057596921920776, train/raw-loss = 0.8806753158569336, train/logprobs = tensor([[ -5.1021, -17.9229],
        [ -6.6679,  -5.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25084319710731506
Epoch 0, Step 3843: train/loss = 0.027318643406033516, train/raw-loss = 0.0016093258745968342, train/logprobs = tensor([[ -1.4689, -13.8434],
        [ -8.4192,  -2.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570931911468506
Epoch 0, Step 3844: train/loss = 0.026323221623897552, train/raw-loss = 0.003279247088357806, train/logprobs = tensor([[ -0.9500, -13.7875],
        [ -6.0327,  -2.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23043972253799438
Epoch 0, Step 3845: train/loss = 0.03131578117609024, train/raw-loss = 0.004184145014733076, train/logprobs = tensor([[ -1.7430, -15.8398],
        [ -9.4452,  -3.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27131637930870056
Epoch 0, Step 3846: train/loss = 0.03211645781993866, train/raw-loss = 0.004217193927615881, train/logprobs = tensor([[ -0.9109, -16.6378],
        [ -6.5005,  -2.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27899259328842163
Epoch 0, Step 3847: train/loss = 0.030910972505807877, train/raw-loss = 0.004826369229704142, train/logprobs = tensor([[ -0.9053, -14.5512],
        [ -7.3530,  -3.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26084601879119873
Epoch 0, Step 3848: train/loss = 0.02645462565124035, train/raw-loss = 0.0012934154365211725, train/logprobs = tensor([[ -1.5071, -15.8443],
        [ -7.6665,  -2.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516120970249176
Epoch 0, Step 3849: train/loss = 0.050317008048295975, train/raw-loss = 0.024710431694984436, train/logprobs = tensor([[ -1.2049, -11.0124],
        [ -6.4783,  -2.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25606581568717957
Epoch 0, Step 3850: train/loss = 0.028625767678022385, train/raw-loss = 0.0014649522490799427, train/logprobs = tensor([[ -0.9645, -16.8156],
        [ -7.9327,  -5.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716081440448761
Epoch 0, Step 3851: train/loss = 0.029620157554745674, train/raw-loss = 0.008094611577689648, train/logprobs = tensor([[ -1.4203, -13.8477],
        [ -6.6325,  -3.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.215255469083786
Epoch 0, Step 3852: train/loss = 0.028322264552116394, train/raw-loss = 0.0009604361839592457, train/logprobs = tensor([[ -1.4420, -15.4910],
        [ -7.8572,  -2.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27361828088760376
Epoch 0, Step 3853: train/loss = 0.030198857188224792, train/raw-loss = 0.0030877015087753534, train/logprobs = tensor([[ -1.0069, -15.0504],
        [ -6.5767,  -3.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27111154794692993
Epoch 0, Step 3854: train/loss = 0.028441309928894043, train/raw-loss = 0.001268000458367169, train/logprobs = tensor([[ -1.1364, -12.4971],
        [ -8.2970,  -2.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2717331051826477
Epoch 0, Step 3855: train/loss = 0.02769523486495018, train/raw-loss = 0.003425556467846036, train/logprobs = tensor([[ -1.9650, -18.3587],
        [ -7.5845,  -5.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24269679188728333
Epoch 0, Step 3856: train/loss = 0.08248947560787201, train/raw-loss = 0.05739188939332962, train/logprobs = tensor([[ -2.5219, -11.1370],
        [-10.2129,  -1.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25097590684890747
Epoch 0, Step 3857: train/loss = 0.02760542742908001, train/raw-loss = 0.0014432028401643038, train/logprobs = tensor([[ -1.5909, -10.4469],
        [ -8.0638,  -2.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26162225008010864
Epoch 0, Step 3858: train/loss = 0.029384488239884377, train/raw-loss = 0.002319405088201165, train/logprobs = tensor([[-1.0878, -9.9885],
        [-7.1232, -2.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27065083384513855
Epoch 0, Step 3859: train/loss = 0.03239225968718529, train/raw-loss = 0.007070538587868214, train/logprobs = tensor([[ -0.8300, -13.3158],
        [ -5.9213,  -3.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532172203063965
Epoch 0, Step 3860: train/loss = 0.028470568358898163, train/raw-loss = 0.0038113512564450502, train/logprobs = tensor([[ -1.3364, -13.7911],
        [ -7.2527,  -2.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24659216403961182
Epoch 0, Step 3861: train/loss = 0.02697368711233139, train/raw-loss = 0.0009651031577959657, train/logprobs = tensor([[ -1.5494, -14.6797],
        [ -8.6100,  -2.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600858211517334
Epoch 0, Step 3862: train/loss = 0.029618436470627785, train/raw-loss = 0.0038978341035544872, train/logprobs = tensor([[ -1.7327, -15.9131],
        [ -7.3429,  -3.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572060227394104
Epoch 0, Step 3863: train/loss = 0.026106473058462143, train/raw-loss = 0.0003018624847754836, train/logprobs = tensor([[ -2.1885, -18.2384],
        [-11.3428,  -5.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25804609060287476
Epoch 0, Step 3864: train/loss = 0.032805588096380234, train/raw-loss = 0.01186712272465229, train/logprobs = tensor([[ -1.8007, -18.0765],
        [ -8.9496,  -3.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20938467979431152
Epoch 0, Step 3865: train/loss = 0.02886490896344185, train/raw-loss = 0.003225486259907484, train/logprobs = tensor([[ -1.1949, -11.4576],
        [ -7.8112,  -2.9858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25639423727989197
Epoch 0, Step 3866: train/loss = 0.9126532077789307, train/raw-loss = 0.8901370763778687, train/logprobs = tensor([[ -5.1638, -18.0140],
        [ -8.0486,  -2.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22516091167926788
Epoch 0, Step 3867: train/loss = 0.03151493892073631, train/raw-loss = 0.0009157393942587078, train/logprobs = tensor([[ -1.3054, -14.0250],
        [ -8.7313,  -2.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059920072555542
Epoch 0, Step 3868: train/loss = 0.033252038061618805, train/raw-loss = 0.006835348904132843, train/logprobs = tensor([[ -1.5314, -12.0115],
        [ -7.7317,  -2.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641668915748596
Epoch 0, Step 3869: train/loss = 0.035455331206321716, train/raw-loss = 0.008801034651696682, train/logprobs = tensor([[ -1.3140, -12.2175],
        [ -6.7099,  -2.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665429413318634
Epoch 0, Step 3870: train/loss = 0.029960082843899727, train/raw-loss = 0.0031128122936934233, train/logprobs = tensor([[ -0.8353, -13.2742],
        [ -6.0529,  -2.5871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26847270131111145
Epoch 0, Step 3871: train/loss = 0.028043232858181, train/raw-loss = 7.100454968167469e-05, train/logprobs = tensor([[ -1.8918, -15.7454],
        [-11.6097,  -2.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27972227334976196
Epoch 0, Step 3872: train/loss = 0.02899138256907463, train/raw-loss = 0.000430878484621644, train/logprobs = tensor([[ -1.3853, -15.9228],
        [ -9.5768,  -2.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856050729751587
Epoch 0, Step 3873: train/loss = 0.02651771903038025, train/raw-loss = 0.0022244469728320837, train/logprobs = tensor([[ -1.0201, -13.4613],
        [ -8.2102,  -2.9684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24293270707130432
Epoch 0, Step 3874: train/loss = 0.025647494941949844, train/raw-loss = 0.0007246379973366857, train/logprobs = tensor([[ -1.6676, -16.2283],
        [ -9.4696,  -3.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492285668849945
Epoch 0, Step 3875: train/loss = 0.024988878518342972, train/raw-loss = 0.0013597956858575344, train/logprobs = tensor([[ -0.9798, -12.0862],
        [ -7.2174,  -2.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2362908124923706
Epoch 0, Step 3876: train/loss = 0.029126044362783432, train/raw-loss = 0.0007418481400236487, train/logprobs = tensor([[ -2.2037, -13.2064],
        [-10.9903,  -2.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28384196758270264
Epoch 0, Step 3877: train/loss = 0.02670246921479702, train/raw-loss = 0.0003601220087148249, train/logprobs = tensor([[ -1.2895, -12.8391],
        [ -9.5490,  -1.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26342344284057617
Epoch 0, Step 3878: train/loss = 0.02748759835958481, train/raw-loss = 0.0009611244895495474, train/logprobs = tensor([[ -1.7862, -10.4224],
        [-10.9067,  -2.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26526474952697754
Epoch 0, Step 3879: train/loss = 0.03538227081298828, train/raw-loss = 0.0022413970436900854, train/logprobs = tensor([[ -1.2372, -13.1119],
        [ -8.0411,  -2.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33140870928764343
Epoch 0, Step 3880: train/loss = 0.02912457287311554, train/raw-loss = 0.003171969437971711, train/logprobs = tensor([[ -0.9670, -15.9506],
        [ -7.7331,  -4.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25952601432800293
Epoch 0, Step 3881: train/loss = 0.028513189405202866, train/raw-loss = 0.0005331779830157757, train/logprobs = tensor([[ -1.0699, -13.6222],
        [ -8.6376,  -2.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798001170158386
Epoch 0, Step 3882: train/loss = 0.026044880971312523, train/raw-loss = 0.0007248266483657062, train/logprobs = tensor([[ -1.2800, -19.0745],
        [ -8.8112,  -4.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532005310058594
Epoch 0, Step 3883: train/loss = 0.02596461772918701, train/raw-loss = 0.0009587508393451571, train/logprobs = tensor([[ -1.0620, -10.6123],
        [ -7.6999,  -1.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250058650970459
Epoch 0, Step 3884: train/loss = 0.03237421065568924, train/raw-loss = 0.002616662997752428, train/logprobs = tensor([[ -0.8327, -14.8851],
        [ -6.3961,  -2.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2975754737854004
Epoch 0, Step 3885: train/loss = 0.03012877330183983, train/raw-loss = 0.00362447090446949, train/logprobs = tensor([[ -1.2118, -15.2839],
        [ -7.4712,  -3.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2650429904460907
Epoch 0, Step 3886: train/loss = 0.029470305889844894, train/raw-loss = 0.0004934940952807665, train/logprobs = tensor([[ -1.7932, -14.9412],
        [-10.1846,  -3.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897680997848511
Epoch 0, Step 3887: train/loss = 0.03626295551657677, train/raw-loss = 0.007674433756619692, train/logprobs = tensor([[ -1.4644, -13.6670],
        [ -6.9714,  -2.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.285885214805603
Epoch 0, Step 3888: train/loss = 0.031670037657022476, train/raw-loss = 0.003749148454517126, train/logprobs = tensor([[ -1.8581, -16.6348],
        [ -7.2311,  -3.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792088985443115
Epoch 0, Step 3889: train/loss = 0.029617739841341972, train/raw-loss = 0.010083712637424469, train/logprobs = tensor([[ -1.2241, -12.7619],
        [ -5.8622,  -3.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19534029066562653
Epoch 0, Step 3890: train/loss = 0.027416298165917397, train/raw-loss = 0.003433262463659048, train/logprobs = tensor([[ -1.2517, -16.2896],
        [ -8.3101,  -3.2519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2398303598165512
Epoch 0, Step 3891: train/loss = 0.024968044832348824, train/raw-loss = 0.000848850526381284, train/logprobs = tensor([[ -1.9475, -14.2481],
        [ -9.3111,  -2.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24119195342063904
Epoch 0, Step 3892: train/loss = 0.027443833649158478, train/raw-loss = 0.0006052919779904187, train/logprobs = tensor([[ -1.7927, -13.8369],
        [-10.2133,  -2.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2683854103088379
Epoch 0, Step 3893: train/loss = 0.027041010558605194, train/raw-loss = 0.0022941085044294596, train/logprobs = tensor([[ -0.9178, -15.2908],
        [ -6.6384,  -3.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2474690079689026
Epoch 0, Step 3894: train/loss = 0.028170522302389145, train/raw-loss = 0.005027541890740395, train/logprobs = tensor([[ -1.1680, -18.1188],
        [ -6.1025,  -3.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2314298003911972
Epoch 0, Step 3895: train/loss = 0.030020028352737427, train/raw-loss = 0.003132552606984973, train/logprobs = tensor([[ -1.5084, -14.5319],
        [ -7.9256,  -3.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26887473464012146
Epoch 0, Step 3896: train/loss = 0.03031967394053936, train/raw-loss = 0.0024481769651174545, train/logprobs = tensor([[ -1.1298, -17.0610],
        [ -6.7049,  -3.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27871495485305786
Epoch 0, Step 3897: train/loss = 0.02775617130100727, train/raw-loss = 0.002217379631474614, train/logprobs = tensor([[ -1.4357, -15.7346],
        [ -7.3204,  -2.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25538790225982666
Epoch 0, Step 3898: train/loss = 0.03841370716691017, train/raw-loss = 0.014632798731327057, train/logprobs = tensor([[ -1.8925, -11.7826],
        [ -7.2562,  -2.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23780907690525055
Epoch 0, Step 3899: train/loss = 0.03028339520096779, train/raw-loss = 0.004459314979612827, train/logprobs = tensor([[ -1.1570, -10.2528],
        [ -8.0330,  -2.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25824081897735596
Epoch 0, Step 3900: train/loss = 0.02648654766380787, train/raw-loss = 0.0015737228095531464, train/logprobs = tensor([[ -1.3718, -13.1793],
        [ -8.7151,  -3.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24912823736667633
Epoch 0, Step 3901: train/loss = 0.030055971816182137, train/raw-loss = 0.0004522239323705435, train/logprobs = tensor([[ -1.4493, -10.7875],
        [ -9.5396,  -2.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960374653339386
Epoch 0, Step 3902: train/loss = 0.027487270534038544, train/raw-loss = 0.0026974414940923452, train/logprobs = tensor([[ -1.5186, -13.1874],
        [ -8.6024,  -3.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24789828062057495
Epoch 0, Step 3903: train/loss = 0.025677774101495743, train/raw-loss = 0.0007910443237051368, train/logprobs = tensor([[ -2.0769, -12.8916],
        [-10.1797,  -2.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24886727333068848
Epoch 0, Step 3904: train/loss = 0.028612904250621796, train/raw-loss = 0.0020081086549907923, train/logprobs = tensor([[ -0.9504, -12.5881],
        [ -8.0495,  -1.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26604795455932617
Epoch 0, Step 3905: train/loss = 0.032858218997716904, train/raw-loss = 0.001932768733240664, train/logprobs = tensor([[ -1.3642, -13.7484],
        [ -7.4411,  -3.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3092544972896576
Epoch 0, Step 3906: train/loss = 0.030329398810863495, train/raw-loss = 0.0008111365605145693, train/logprobs = tensor([[ -1.5770, -12.3111],
        [-10.1953,  -2.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29518264532089233
Epoch 0, Step 3907: train/loss = 0.02909090556204319, train/raw-loss = 0.0010752894449979067, train/logprobs = tensor([[ -1.3764, -15.3336],
        [ -8.5907,  -2.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28015613555908203
Epoch 0, Step 3908: train/loss = 0.030466672033071518, train/raw-loss = 0.00154380954336375, train/logprobs = tensor([[ -1.2608, -18.0516],
        [ -9.2669,  -4.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.289228618144989
Epoch 0, Step 3909: train/loss = 0.036777839064598083, train/raw-loss = 0.011729598976671696, train/logprobs = tensor([[ -1.2403, -11.0507],
        [ -8.1579,  -2.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25048238039016724
Epoch 0, Step 3910: train/loss = 0.030858907848596573, train/raw-loss = 0.0012399964034557343, train/logprobs = tensor([[ -1.1575, -20.3791],
        [ -7.4300,  -3.4106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961890995502472
Epoch 0, Step 3911: train/loss = 0.029054366052150726, train/raw-loss = 0.000549375603441149, train/logprobs = tensor([[ -1.4118, -15.9468],
        [ -8.9389,  -3.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2850498855113983
Epoch 0, Step 3912: train/loss = 0.031509630382061005, train/raw-loss = 0.003711769822984934, train/logprobs = tensor([[ -0.8773, -10.4056],
        [ -6.3486,  -2.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779786288738251
Epoch 0, Step 3913: train/loss = 0.025111906230449677, train/raw-loss = 0.0012079644948244095, train/logprobs = tensor([[ -1.0372, -18.8411],
        [ -7.0886,  -3.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23903940618038177
Epoch 0, Step 3914: train/loss = 0.03323904052376747, train/raw-loss = 0.00770530803129077, train/logprobs = tensor([[ -1.2138, -18.1157],
        [ -8.0480,  -3.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25533732771873474
Epoch 0, Step 3915: train/loss = 0.029718967154622078, train/raw-loss = 0.0012239788193255663, train/logprobs = tensor([[ -1.1183, -13.3754],
        [ -7.7489,  -2.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849498689174652
Epoch 0, Step 3916: train/loss = 0.048095859587192535, train/raw-loss = 0.013834487646818161, train/logprobs = tensor([[ -1.4632, -10.2950],
        [ -8.4158,  -2.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34261372685432434
Epoch 0, Step 3917: train/loss = 0.030209453776478767, train/raw-loss = 0.003316157031804323, train/logprobs = tensor([[-1.7248, -8.4859],
        [-9.6127, -1.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268932968378067
Epoch 0, Step 3918: train/loss = 0.03713994100689888, train/raw-loss = 0.010729899629950523, train/logprobs = tensor([[ -1.1293, -13.6746],
        [ -6.4171,  -3.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26410043239593506
Epoch 0, Step 3919: train/loss = 0.026209495961666107, train/raw-loss = 0.004740327596664429, train/logprobs = tensor([[ -1.3167, -12.0102],
        [ -6.8863,  -3.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2146916687488556
Epoch 0, Step 3920: train/loss = 0.02782241255044937, train/raw-loss = 0.00304197845980525, train/logprobs = tensor([[ -1.3000, -13.9795],
        [ -8.1531,  -3.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24780432879924774
Epoch 0, Step 3921: train/loss = 0.02638396993279457, train/raw-loss = 0.0013937278417870402, train/logprobs = tensor([[ -1.4792, -13.1938],
        [ -7.8659,  -3.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2499024122953415
Epoch 0, Step 3922: train/loss = 0.027176659554243088, train/raw-loss = 0.0027695014141499996, train/logprobs = tensor([[ -0.9208, -12.3652],
        [ -6.3733,  -2.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440715879201889
Epoch 0, Step 3923: train/loss = 0.02779052034020424, train/raw-loss = 0.00021809228928759694, train/logprobs = tensor([[ -1.5921, -16.4069],
        [-10.2097,  -3.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27572426199913025
Epoch 0, Step 3924: train/loss = 0.030337389558553696, train/raw-loss = 0.001359039219096303, train/logprobs = tensor([[ -1.0139, -12.4333],
        [ -7.2158,  -2.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897835075855255
Epoch 0, Step 3925: train/loss = 0.026994798332452774, train/raw-loss = 0.0033928535412997007, train/logprobs = tensor([[ -1.2866, -14.6261],
        [ -7.0955,  -2.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23601943254470825
Epoch 0, Step 3926: train/loss = 0.028403786942362785, train/raw-loss = 0.0007945814286358654, train/logprobs = tensor([[ -1.2885, -12.5851],
        [ -8.3722,  -2.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760920226573944
Epoch 0, Step 3927: train/loss = 0.028320422396063805, train/raw-loss = 0.0012418909464031458, train/logprobs = tensor([[ -0.7731, -14.4190],
        [ -7.1227,  -2.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27078530192375183
Epoch 0, Step 3928: train/loss = 0.02802147902548313, train/raw-loss = 0.0016652514459565282, train/logprobs = tensor([[ -1.1470, -14.5194],
        [ -7.8714,  -2.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26356226205825806
Epoch 0, Step 3929: train/loss = 0.02886315807700157, train/raw-loss = 0.001470525050535798, train/logprobs = tensor([[ -1.4900, -14.7873],
        [ -8.6313,  -3.5019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.273926317691803
Epoch 0, Step 3930: train/loss = 0.04529322683811188, train/raw-loss = 0.020321231335401535, train/logprobs = tensor([[ -2.7059, -17.6942],
        [ -8.2649,  -3.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24971997737884521
Epoch 0, Step 3931: train/loss = 0.027112439274787903, train/raw-loss = 0.003089441917836666, train/logprobs = tensor([[ -1.0249, -15.5780],
        [ -7.0946,  -4.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240229994058609
Epoch 0, Step 3932: train/loss = 0.027504276484251022, train/raw-loss = 0.0031514661386609077, train/logprobs = tensor([[ -0.8652, -17.3896],
        [ -7.5355,  -3.2284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2435280978679657
Epoch 0, Step 3933: train/loss = 0.030357657000422478, train/raw-loss = 0.001335734617896378, train/logprobs = tensor([[ -1.9017, -11.1149],
        [-11.3300,  -3.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902192175388336
Epoch 0, Step 3934: train/loss = 0.028183255344629288, train/raw-loss = 0.001413419609889388, train/logprobs = tensor([[ -1.3045, -11.9877],
        [ -8.0501,  -2.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26769834756851196
Epoch 0, Step 3935: train/loss = 0.02887822315096855, train/raw-loss = 0.0016379854641854763, train/logprobs = tensor([[ -1.2760, -11.9225],
        [ -7.5559,  -2.6009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724023461341858
Epoch 0, Step 3936: train/loss = 0.025499608367681503, train/raw-loss = 0.0010626668808981776, train/logprobs = tensor([[ -1.0086, -12.9367],
        [ -7.5791,  -3.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24436938762664795
Epoch 0, Step 3937: train/loss = 0.0263824500143528, train/raw-loss = 0.000562539731618017, train/logprobs = tensor([[ -1.2719, -13.1012],
        [ -8.7234,  -2.2223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581990957260132
Epoch 0, Step 3938: train/loss = 0.031553905457258224, train/raw-loss = 0.0042315879836678505, train/logprobs = tensor([[ -1.2995, -13.2217],
        [ -7.7071,  -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2732231914997101
Epoch 0, Step 3939: train/loss = 0.023982197046279907, train/raw-loss = 0.001099954592064023, train/logprobs = tensor([[ -1.3837, -12.5499],
        [ -8.3062,  -2.6835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22882242500782013
Epoch 0, Step 3940: train/loss = 0.02680317685008049, train/raw-loss = 0.0009954256238415837, train/logprobs = tensor([[ -1.1068, -11.0717],
        [ -8.0675,  -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2580775022506714
Epoch 0, Step 3941: train/loss = 0.042229294776916504, train/raw-loss = 0.017685096710920334, train/logprobs = tensor([[ -1.1880, -12.0036],
        [ -7.5410,  -3.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24544203281402588
Epoch 0, Step 3942: train/loss = 0.027196194976568222, train/raw-loss = 0.0009452281519770622, train/logprobs = tensor([[ -1.1076, -13.2261],
        [ -7.8021,  -2.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26250964403152466
Epoch 0, Step 3943: train/loss = 0.02715606987476349, train/raw-loss = 0.0006054745172150433, train/logprobs = tensor([[ -1.5521, -21.7367],
        [ -9.4089,  -7.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26550593972206116
Epoch 0, Step 3944: train/loss = 0.028833018615841866, train/raw-loss = 0.00226596649736166, train/logprobs = tensor([[ -0.8581, -12.0359],
        [ -7.1088,  -2.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265670508146286
Epoch 0, Step 3945: train/loss = 0.03239893168210983, train/raw-loss = 0.0021602287888526917, train/logprobs = tensor([[ -1.5844, -14.1190],
        [ -9.2715,  -3.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3023870587348938
Epoch 0, Step 3946: train/loss = 0.029338855296373367, train/raw-loss = 0.002304598456248641, train/logprobs = tensor([[ -1.4028, -10.9586],
        [ -8.6870,  -2.5388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27034255862236023
Epoch 0, Step 3947: train/loss = 0.02324495278298855, train/raw-loss = 0.0011378880590200424, train/logprobs = tensor([[ -1.5656, -15.8756],
        [ -7.9686,  -2.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22107063233852386
Epoch 0, Step 3948: train/loss = 0.0317402146756649, train/raw-loss = 0.006882376037538052, train/logprobs = tensor([[-1.2106, -9.0542],
        [-7.1978, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24857838451862335
Epoch 0, Step 3949: train/loss = 0.02797444351017475, train/raw-loss = 0.0040026381611824036, train/logprobs = tensor([[ -0.9782, -14.0630],
        [ -6.1519,  -3.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23971804976463318
Epoch 0, Step 3950: train/loss = 0.03238687291741371, train/raw-loss = 0.004472628701478243, train/logprobs = tensor([[ -1.1179, -17.3863],
        [ -7.8154,  -3.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27914246916770935
Epoch 0, Step 3951: train/loss = 0.02593512460589409, train/raw-loss = 0.0016459363978356123, train/logprobs = tensor([[ -2.0602, -16.8372],
        [ -8.2463,  -3.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24289189279079437
Epoch 0, Step 3952: train/loss = 0.03768650442361832, train/raw-loss = 0.009765862487256527, train/logprobs = tensor([[ -1.7142, -10.2275],
        [-10.1056,  -2.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27920645475387573
Epoch 0, Step 3953: train/loss = 0.03189714998006821, train/raw-loss = 0.0034218337386846542, train/logprobs = tensor([[-1.3182, -9.3073],
        [-8.0469, -1.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2847531735897064
Epoch 0, Step 3954: train/loss = 0.03019522689282894, train/raw-loss = 0.0029928397852927446, train/logprobs = tensor([[ -0.9602, -12.1113],
        [ -6.5844,  -1.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27202388644218445
Epoch 0, Step 3955: train/loss = 0.027420315891504288, train/raw-loss = 0.0020601749420166016, train/logprobs = tensor([[ -0.9833, -12.9177],
        [ -6.8641,  -3.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25360140204429626
Epoch 0, Step 3956: train/loss = 0.08529073745012283, train/raw-loss = 0.05947276949882507, train/logprobs = tensor([[-1.5170, -8.5753],
        [-8.2247, -1.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581796646118164
Epoch 0, Step 3957: train/loss = 0.03044356033205986, train/raw-loss = 0.0023384406231343746, train/logprobs = tensor([[ -1.4765, -14.0547],
        [ -8.0404,  -1.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2810512185096741
Epoch 0, Step 3958: train/loss = 0.032245099544525146, train/raw-loss = 0.001482536201365292, train/logprobs = tensor([[ -1.2041, -11.9505],
        [ -8.2102,  -2.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3076256513595581
Epoch 0, Step 3959: train/loss = 0.031214304268360138, train/raw-loss = 0.00238653551787138, train/logprobs = tensor([[ -0.9619, -13.2990],
        [ -7.3910,  -3.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28827768564224243
Epoch 0, Step 3960: train/loss = 0.029573537409305573, train/raw-loss = 0.004384577739983797, train/logprobs = tensor([[ -1.9168, -13.2461],
        [ -9.8118,  -2.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25188958644866943
Epoch 0, Step 3961: train/loss = 0.02654297649860382, train/raw-loss = 0.000314837321639061, train/logprobs = tensor([[ -1.2931, -15.4766],
        [ -9.9166,  -3.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2622813880443573
Epoch 0, Step 3962: train/loss = 0.033784739673137665, train/raw-loss = 0.00686153257265687, train/logprobs = tensor([[-1.8170, -9.9936],
        [-8.1006, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2692320644855499
Epoch 0, Step 3963: train/loss = 0.0349511094391346, train/raw-loss = 0.00449450733140111, train/logprobs = tensor([[ -1.5630, -10.3645],
        [ -8.9318,  -3.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30456599593162537
Epoch 0, Step 3964: train/loss = 0.023760482668876648, train/raw-loss = 0.0004189480096101761, train/logprobs = tensor([[ -1.5044, -11.1757],
        [ -9.6875,  -2.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23341533541679382
Epoch 0, Step 3965: train/loss = 0.026928585022687912, train/raw-loss = 0.00255565345287323, train/logprobs = tensor([[ -1.5192, -10.2635],
        [ -8.7900,  -2.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24372932314872742
Epoch 0, Step 3966: train/loss = 0.027277838438749313, train/raw-loss = 0.0008022884139791131, train/logprobs = tensor([[ -1.3810, -12.1693],
        [ -8.6692,  -2.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647554874420166
Epoch 0, Step 3967: train/loss = 0.02596207894384861, train/raw-loss = 0.0017309087561443448, train/logprobs = tensor([[ -1.4095, -16.4367],
        [ -9.1101,  -4.0914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24231170117855072
Epoch 0, Step 3968: train/loss = 0.02999279648065567, train/raw-loss = 0.00148897641338408, train/logprobs = tensor([[ -1.8771, -13.2894],
        [ -8.9600,  -3.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28503820300102234
Epoch 0, Step 3969: train/loss = 0.029686369001865387, train/raw-loss = 0.007979384623467922, train/logprobs = tensor([[ -1.9114, -16.7444],
        [ -8.7580,  -3.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2170698642730713
Epoch 0, Step 3970: train/loss = 0.027445625513792038, train/raw-loss = 0.001027105376124382, train/logprobs = tensor([[ -1.8463, -11.1381],
        [-10.3873,  -2.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26418522000312805
Epoch 0, Step 3971: train/loss = 0.023103829473257065, train/raw-loss = 0.0003517300356179476, train/logprobs = tensor([[ -1.5340, -14.7799],
        [ -9.6559,  -3.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22752098739147186
Epoch 0, Step 3972: train/loss = 0.02821960300207138, train/raw-loss = 0.003970508463680744, train/logprobs = tensor([[ -1.1757, -15.0461],
        [ -6.7011,  -2.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24249093234539032
Epoch 0, Step 3973: train/loss = 0.026516344398260117, train/raw-loss = 0.0023735286667943, train/logprobs = tensor([[ -0.9037, -18.3929],
        [ -6.6595,  -4.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414281666278839
Epoch 0, Step 3974: train/loss = 0.027066728100180626, train/raw-loss = 0.0008213272085413337, train/logprobs = tensor([[ -2.2397, -12.3193],
        [ -9.8915,  -3.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26245400309562683
Epoch 0, Step 3975: train/loss = 0.05735766142606735, train/raw-loss = 0.025197720155119896, train/logprobs = tensor([[-1.0399, -8.5940],
        [-8.0469, -2.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32159942388534546
Epoch 0, Step 3976: train/loss = 0.026582224294543266, train/raw-loss = 0.0021022369619458914, train/logprobs = tensor([[ -0.9649, -11.9628],
        [ -7.0993,  -2.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24479985237121582
Epoch 0, Step 3977: train/loss = 0.030360696837306023, train/raw-loss = 0.0016578359063714743, train/logprobs = tensor([[ -1.0981, -11.6011],
        [ -8.9053,  -2.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28702861070632935
Epoch 0, Step 3978: train/loss = 0.03356232866644859, train/raw-loss = 0.007386182434856892, train/logprobs = tensor([[ -0.8688, -11.3849],
        [ -5.7377,  -3.4493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26176148653030396
Epoch 0, Step 3979: train/loss = 0.028121821582317352, train/raw-loss = 0.0009488514624536037, train/logprobs = tensor([[ -1.5035, -11.0255],
        [ -9.9361,  -1.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2717297077178955
Epoch 0, Step 3980: train/loss = 0.027721993625164032, train/raw-loss = 0.0005705887451767921, train/logprobs = tensor([[ -1.4135, -12.3467],
        [ -9.5369,  -3.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27151405811309814
Epoch 0, Step 3981: train/loss = 0.031374696642160416, train/raw-loss = 0.0018510045483708382, train/logprobs = tensor([[ -1.5480, -10.7686],
        [ -8.1639,  -2.3780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952369153499603
Epoch 0, Step 3982: train/loss = 0.029602734372019768, train/raw-loss = 0.0029794611036777496, train/logprobs = tensor([[ -1.1820, -16.2033],
        [ -7.7623,  -5.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662327289581299
Epoch 0, Step 3983: train/loss = 0.05090392753481865, train/raw-loss = 0.02043362334370613, train/logprobs = tensor([[ -1.5046, -11.3355],
        [ -9.4350,  -2.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3047030568122864
Epoch 0, Step 3984: train/loss = 0.02645839937031269, train/raw-loss = 0.0009133997955359519, train/logprobs = tensor([[ -1.0578, -13.1564],
        [ -8.5699,  -3.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25544998049736023
Epoch 0, Step 3985: train/loss = 0.028711780905723572, train/raw-loss = 0.001990967895835638, train/logprobs = tensor([[ -0.8631, -16.4794],
        [ -7.0490,  -4.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26720812916755676
Epoch 0, Step 3986: train/loss = 0.03039240650832653, train/raw-loss = 0.0024029486812651157, train/logprobs = tensor([[ -1.3807, -10.9869],
        [ -7.4628,  -2.2662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27989456057548523
Epoch 0, Step 3987: train/loss = 0.03325013071298599, train/raw-loss = 0.0005023949779570103, train/logprobs = tensor([[ -1.6226, -11.6951],
        [-10.0686,  -2.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3274773359298706
Epoch 0, Step 3988: train/loss = 0.028111085295677185, train/raw-loss = 0.0008890680619515479, train/logprobs = tensor([[ -1.0395, -12.8118],
        [ -8.1995,  -3.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722201645374298
Epoch 0, Step 3989: train/loss = 0.025692004710435867, train/raw-loss = 0.000792033679317683, train/logprobs = tensor([[ -2.1505, -13.2731],
        [ -9.8906,  -2.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489997148513794
Epoch 0, Step 3990: train/loss = 0.026171209290623665, train/raw-loss = 0.0005139319691807032, train/logprobs = tensor([[ -1.6757, -18.6228],
        [ -9.1324,  -5.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25657278299331665
Epoch 0, Step 3991: train/loss = 0.025442007929086685, train/raw-loss = 0.0014490551548078656, train/logprobs = tensor([[ -1.1925, -13.5976],
        [ -8.4259,  -2.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23992952704429626
Epoch 0, Step 3992: train/loss = 0.029566727578639984, train/raw-loss = 0.0027172795962542295, train/logprobs = tensor([[ -1.0037, -14.7542],
        [ -7.3296,  -3.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26849448680877686
Epoch 0, Step 3993: train/loss = 0.03052382729947567, train/raw-loss = 0.0015460822032764554, train/logprobs = tensor([[ -1.5909, -10.0664],
        [ -8.6380,  -2.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897774577140808
Epoch 0, Step 3994: train/loss = 0.02738783322274685, train/raw-loss = 0.0042351423762738705, train/logprobs = tensor([[ -0.9856, -18.0229],
        [ -6.6170,  -4.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23152689635753632
Epoch 0, Step 3995: train/loss = 0.029894473031163216, train/raw-loss = 0.0012533810222521424, train/logprobs = tensor([[ -1.4167, -13.1356],
        [ -9.0036,  -2.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286410927772522
Epoch 0, Step 3996: train/loss = 0.028438061475753784, train/raw-loss = 0.0007154050399549305, train/logprobs = tensor([[ -1.6909, -13.7324],
        [-10.0732,  -3.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772265374660492
Epoch 0, Step 3997: train/loss = 0.024859223514795303, train/raw-loss = 0.0011547303292900324, train/logprobs = tensor([[ -1.4737, -11.2861],
        [ -8.7822,  -1.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23704493045806885
Epoch 0, Step 3998: train/loss = 0.03826180100440979, train/raw-loss = 0.013317943550646305, train/logprobs = tensor([[ -1.5446, -12.2152],
        [ -8.7722,  -3.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2494385838508606
Epoch 0, Step 3999: train/loss = 0.02583218179643154, train/raw-loss = 0.00042906441376544535, train/logprobs = tensor([[ -1.9222, -14.1458],
        [-10.0360,  -3.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540311813354492
Epoch 0, Step 4000: train/loss = 0.028575323522090912, train/raw-loss = 0.0019394105765968561, train/logprobs = tensor([[ -1.8597, -11.1256],
        [-10.2450,  -2.2008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663591206073761
Epoch 0, Step 4001: train/loss = 0.02807110920548439, train/raw-loss = 0.00572268757969141, train/logprobs = tensor([[ -1.8446, -14.4660],
        [ -8.5789,  -4.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22348421812057495
Epoch 0, Step 4002: train/loss = 0.027365822345018387, train/raw-loss = 0.0012348359450697899, train/logprobs = tensor([[ -1.6226, -13.2858],
        [ -8.3524,  -2.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26130983233451843
Epoch 0, Step 4003: train/loss = 0.03073134273290634, train/raw-loss = 0.003587830811738968, train/logprobs = tensor([[ -1.1110, -12.0929],
        [ -7.9761,  -2.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27143511176109314
Epoch 0, Step 4004: train/loss = 0.030556507408618927, train/raw-loss = 0.004098068457096815, train/logprobs = tensor([[ -2.0128,  -9.7553],
        [-10.0669,  -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26458439230918884
Epoch 0, Step 4005: train/loss = 0.02609700709581375, train/raw-loss = 0.0019259473774582148, train/logprobs = tensor([[ -1.3259, -16.5907],
        [ -8.1742,  -4.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417106032371521
Epoch 0, Step 4006: train/loss = 0.026843512430787086, train/raw-loss = 0.0016571038868278265, train/logprobs = tensor([[ -1.3595, -14.0309],
        [ -8.1680,  -3.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25186407566070557
Epoch 0, Step 4007: train/loss = 0.02782260999083519, train/raw-loss = 0.0032014078460633755, train/logprobs = tensor([[ -1.2271, -10.6787],
        [ -7.1507,  -2.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24621200561523438
Epoch 0, Step 4008: train/loss = 0.03366873040795326, train/raw-loss = 0.00644384790211916, train/logprobs = tensor([[ -0.9228, -13.7052],
        [ -7.0296,  -3.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722488343715668
Epoch 0, Step 4009: train/loss = 0.02680308371782303, train/raw-loss = 0.0022361096926033497, train/logprobs = tensor([[ -1.1502, -14.7972],
        [ -7.0266,  -2.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24566972255706787
Epoch 0, Step 4010: train/loss = 0.027183901518583298, train/raw-loss = 0.0012832909123972058, train/logprobs = tensor([[ -0.9661, -14.5077],
        [ -7.6389,  -2.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590061128139496
Epoch 0, Step 4011: train/loss = 0.030321765691041946, train/raw-loss = 0.002308497903868556, train/logprobs = tensor([[ -1.3601, -14.1983],
        [ -7.5776,  -3.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801326811313629
Epoch 0, Step 4012: train/loss = 0.03621479868888855, train/raw-loss = 0.009764652699232101, train/logprobs = tensor([[ -0.8259, -16.0283],
        [ -6.7220,  -3.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2645014524459839
Epoch 0, Step 4013: train/loss = 0.028863364830613136, train/raw-loss = 0.0013846858637407422, train/logprobs = tensor([[ -0.9557, -15.1042],
        [ -7.9625,  -2.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2747867703437805
Epoch 0, Step 4014: train/loss = 0.03010285273194313, train/raw-loss = 0.004785214550793171, train/logprobs = tensor([[ -1.5139, -17.1482],
        [ -7.0548,  -4.1152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25317636132240295
Epoch 0, Step 4015: train/loss = 0.09424179047346115, train/raw-loss = 0.07039956748485565, train/logprobs = tensor([[ -1.5423, -11.7907],
        [ -6.4186,  -2.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384221851825714
Epoch 0, Step 4016: train/loss = 0.02845449559390545, train/raw-loss = 0.0011059476528316736, train/logprobs = tensor([[ -1.4084, -14.3218],
        [ -8.7383,  -2.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734854817390442
Epoch 0, Step 4017: train/loss = 0.026277631521224976, train/raw-loss = 0.0007717752014286816, train/logprobs = tensor([[ -1.4368, -12.9719],
        [ -8.5449,  -2.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25505855679512024
Epoch 0, Step 4018: train/loss = 0.029606100171804428, train/raw-loss = 0.0037153810262680054, train/logprobs = tensor([[ -1.1706, -13.9836],
        [ -7.4835,  -2.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25890716910362244
Epoch 0, Step 4019: train/loss = 0.02699199877679348, train/raw-loss = 0.0006266660057008266, train/logprobs = tensor([[ -1.3514, -13.0424],
        [ -8.9022,  -2.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26365333795547485
Epoch 0, Step 4020: train/loss = 0.030034467577934265, train/raw-loss = 0.0011977643007412553, train/logprobs = tensor([[ -1.4590, -11.0723],
        [ -9.1684,  -2.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28836703300476074
Epoch 0, Step 4021: train/loss = 0.032725900411605835, train/raw-loss = 0.0026437570340931416, train/logprobs = tensor([[ -1.4088, -14.7016],
        [ -9.9826,  -2.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3008214235305786
Epoch 0, Step 4022: train/loss = 0.027565350756049156, train/raw-loss = 0.0011231927201151848, train/logprobs = tensor([[ -1.0670, -11.2577],
        [ -8.7354,  -2.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644215524196625
Epoch 0, Step 4023: train/loss = 0.030535224825143814, train/raw-loss = 0.002400045981630683, train/logprobs = tensor([[ -0.7832, -11.9674],
        [ -7.4322,  -3.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28135180473327637
Epoch 0, Step 4024: train/loss = 0.025052744895219803, train/raw-loss = 0.0025889244861900806, train/logprobs = tensor([[ -0.7409, -13.4175],
        [ -6.2990,  -2.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2246382087469101
Epoch 0, Step 4025: train/loss = 0.029628578573465347, train/raw-loss = 0.0027126073837280273, train/logprobs = tensor([[ -1.4577, -15.6394],
        [ -8.9994,  -3.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691597044467926
Epoch 0, Step 4026: train/loss = 0.026257498189806938, train/raw-loss = 0.0004847514792345464, train/logprobs = tensor([[ -1.4202, -15.3264],
        [ -8.8415,  -3.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2577274739742279
Epoch 0, Step 4027: train/loss = 0.03047649934887886, train/raw-loss = 0.0007499462808482349, train/logprobs = tensor([[ -1.1250, -15.3947],
        [ -8.0809,  -2.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29726552963256836
Epoch 0, Step 4028: train/loss = 0.027523823082447052, train/raw-loss = 0.0011257079895585775, train/logprobs = tensor([[ -1.0265, -13.5970],
        [ -8.4301,  -2.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639811635017395
Epoch 0, Step 4029: train/loss = 0.027183223515748978, train/raw-loss = 0.0016221706755459309, train/logprobs = tensor([[ -1.0926, -16.7997],
        [ -6.8772,  -3.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25561052560806274
Epoch 0, Step 4030: train/loss = 0.02703632041811943, train/raw-loss = 0.0009587740059942007, train/logprobs = tensor([[ -1.6202, -15.0338],
        [ -9.2581,  -3.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26077544689178467
Epoch 0, Step 4031: train/loss = 0.031248759478330612, train/raw-loss = 0.0015827297465875745, train/logprobs = tensor([[ -0.9582, -17.9123],
        [ -7.2063,  -2.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29666030406951904
Epoch 0, Step 4032: train/loss = 0.027494773268699646, train/raw-loss = 0.001649270998314023, train/logprobs = tensor([[ -1.3883, -15.0095],
        [ -8.2835,  -2.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2584550082683563
Epoch 0, Step 4033: train/loss = 0.024491608142852783, train/raw-loss = 0.0007664838922210038, train/logprobs = tensor([[ -1.4129, -15.9381],
        [ -8.1763,  -2.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23725122213363647
Epoch 0, Step 4034: train/loss = 0.030365169048309326, train/raw-loss = 0.0007625655853189528, train/logprobs = tensor([[ -1.2906, -14.2729],
        [ -8.8138,  -3.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29602599143981934
Epoch 0, Step 4035: train/loss = 0.02801249548792839, train/raw-loss = 0.0008294804720208049, train/logprobs = tensor([[ -2.4763, -15.4764],
        [-12.2825,  -4.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27183017134666443
Epoch 0, Step 4036: train/loss = 0.023004435002803802, train/raw-loss = 0.0019880852196365595, train/logprobs = tensor([[ -1.3617, -15.3412],
        [ -9.0697,  -4.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21016350388526917
Epoch 0, Step 4037: train/loss = 0.026224879547953606, train/raw-loss = 0.0018245643004775047, train/logprobs = tensor([[ -1.3856, -12.6635],
        [ -7.7496,  -2.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24400314688682556
Epoch 0, Step 4038: train/loss = 0.029153000563383102, train/raw-loss = 0.0005227035144343972, train/logprobs = tensor([[ -1.2358, -14.6448],
        [-10.0495,  -3.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28630298376083374
Epoch 0, Step 4039: train/loss = 0.03465745970606804, train/raw-loss = 0.00796432513743639, train/logprobs = tensor([[ -1.3715, -10.6426],
        [ -7.0705,  -2.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26693135499954224
Epoch 0, Step 4040: train/loss = 0.028592582792043686, train/raw-loss = 0.006359713617712259, train/logprobs = tensor([[ -1.0606, -13.2236],
        [ -6.1601,  -3.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22232869267463684
Epoch 0, Step 4041: train/loss = 0.0302136167883873, train/raw-loss = 0.004786815494298935, train/logprobs = tensor([[ -1.2065, -16.7754],
        [ -8.9243,  -3.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25426799058914185
Epoch 0, Step 4042: train/loss = 0.026359200477600098, train/raw-loss = 0.0010427959496155381, train/logprobs = tensor([[ -1.1389, -16.3770],
        [ -8.5508,  -3.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25316405296325684
Epoch 0, Step 4043: train/loss = 0.03567999601364136, train/raw-loss = 0.006644743960350752, train/logprobs = tensor([[-1.0111, -9.0815],
        [-7.7908, -2.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2903524935245514
Epoch 0, Step 4044: train/loss = 0.02535616233944893, train/raw-loss = 0.0016958946362137794, train/logprobs = tensor([[ -0.8381, -19.1036],
        [ -6.9553,  -4.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23660269379615784
Epoch 0, Step 4045: train/loss = 0.028310410678386688, train/raw-loss = 0.0016960815992206335, train/logprobs = tensor([[ -0.8990, -15.1620],
        [ -7.6599,  -3.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661432921886444
Epoch 0, Step 4046: train/loss = 0.03132207691669464, train/raw-loss = 0.0025022653862833977, train/logprobs = tensor([[ -1.1464, -14.2089],
        [ -7.9807,  -3.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2881981134414673
Epoch 0, Step 4047: train/loss = 0.05867708474397659, train/raw-loss = 0.033062130212783813, train/logprobs = tensor([[ -1.1899, -17.0105],
        [ -6.4202,  -4.3478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561495304107666
Epoch 0, Step 4048: train/loss = 0.02696182206273079, train/raw-loss = 0.001975022489205003, train/logprobs = tensor([[ -1.5740, -14.1759],
        [ -9.3565,  -3.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498679757118225
Epoch 0, Step 4049: train/loss = 0.03271235525608063, train/raw-loss = 0.007019883953034878, train/logprobs = tensor([[-1.3369, -9.3573],
        [-8.6390, -2.3469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25692471861839294
Epoch 0, Step 4050: train/loss = 0.024795416742563248, train/raw-loss = 0.000700170174241066, train/logprobs = tensor([[ -1.3454, -12.0774],
        [ -8.8648,  -1.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24095244705677032
Epoch 0, Step 4051: train/loss = 0.029158908873796463, train/raw-loss = 0.0018874418456107378, train/logprobs = tensor([[ -1.0552, -14.2856],
        [ -7.3310,  -3.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27271467447280884
Epoch 0, Step 4052: train/loss = 0.03129585087299347, train/raw-loss = 0.0016161708626896143, train/logprobs = tensor([[ -1.1736, -13.2225],
        [ -8.1014,  -2.3787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967967987060547
Epoch 0, Step 4053: train/loss = 0.038956791162490845, train/raw-loss = 0.009942950680851936, train/logprobs = tensor([[-1.2276, -9.0445],
        [-8.0283, -2.6199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2901384234428406
Epoch 0, Step 4054: train/loss = 0.02807195484638214, train/raw-loss = 0.0009559702593833208, train/logprobs = tensor([[ -1.3490, -13.1853],
        [ -8.5474,  -3.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.271159827709198
Epoch 0, Step 4055: train/loss = 0.029710762202739716, train/raw-loss = 0.0012728010769933462, train/logprobs = tensor([[ -1.4950, -12.5391],
        [ -8.8928,  -4.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28437963128089905
Epoch 0, Step 4056: train/loss = 0.027660422027111053, train/raw-loss = 0.0011208473006263375, train/logprobs = tensor([[ -1.1252, -12.4770],
        [ -8.0675,  -2.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26539576053619385
Epoch 0, Step 4057: train/loss = 0.028301699087023735, train/raw-loss = 0.0011037143412977457, train/logprobs = tensor([[ -1.2092, -13.0939],
        [ -8.5028,  -2.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27197983860969543
Epoch 0, Step 4058: train/loss = 0.028605487197637558, train/raw-loss = 0.001121574081480503, train/logprobs = tensor([[ -1.0546, -14.3461],
        [ -8.7386,  -4.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748391330242157
Epoch 0, Step 4059: train/loss = 0.027282262220978737, train/raw-loss = 0.0011275230208411813, train/logprobs = tensor([[ -0.9145, -14.7307],
        [ -7.7136,  -4.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26154738664627075
Epoch 0, Step 4060: train/loss = 0.02766164019703865, train/raw-loss = 0.0017456653295084834, train/logprobs = tensor([[ -0.9167, -12.4763],
        [ -6.9858,  -2.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25915974378585815
Epoch 0, Step 4061: train/loss = 0.026865508407354355, train/raw-loss = 0.0009597676689736545, train/logprobs = tensor([[ -1.5643, -15.9714],
        [ -9.5116,  -3.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590574026107788
Epoch 0, Step 4062: train/loss = 0.028400219976902008, train/raw-loss = 0.002128820400685072, train/logprobs = tensor([[ -0.7989, -11.9109],
        [ -6.3208,  -2.4769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2627139687538147
Epoch 0, Step 4063: train/loss = 0.12166658788919449, train/raw-loss = 0.09754284471273422, train/logprobs = tensor([[ -2.0890, -12.2089],
        [ -7.0278,  -3.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24123746156692505
Epoch 0, Step 4064: train/loss = 0.028181079775094986, train/raw-loss = 0.0008342047804035246, train/logprobs = tensor([[ -1.0763, -12.3827],
        [ -9.0161,  -2.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734687328338623
Epoch 0, Step 4065: train/loss = 0.03360586240887642, train/raw-loss = 0.0046247513964772224, train/logprobs = tensor([[ -0.8713, -16.2561],
        [ -6.9925,  -4.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2898111045360565
Epoch 0, Step 4066: train/loss = 0.0281768087297678, train/raw-loss = 0.0015632513677701354, train/logprobs = tensor([[ -1.0147, -15.4421],
        [ -8.4200,  -2.3102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2661356031894684
Epoch 0, Step 4067: train/loss = 0.02685132808983326, train/raw-loss = 0.0007352777756750584, train/logprobs = tensor([[ -1.1676, -13.7391],
        [ -8.5012,  -3.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611604928970337
Epoch 0, Step 4068: train/loss = 0.06044889986515045, train/raw-loss = 0.03459137678146362, train/logprobs = tensor([[ -0.7417, -15.4885],
        [ -6.6084,  -1.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585752010345459
Epoch 0, Step 4069: train/loss = 0.038872260600328445, train/raw-loss = 0.012448190711438656, train/logprobs = tensor([[ -1.4796, -10.1125],
        [ -9.4541,  -2.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26424071192741394
Epoch 0, Step 4070: train/loss = 0.025954537093639374, train/raw-loss = 0.00019351053924765438, train/logprobs = tensor([[ -1.7638, -13.5528],
        [-11.6435,  -3.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576102614402771
Epoch 0, Step 4071: train/loss = 0.02985420450568199, train/raw-loss = 0.00277967331930995, train/logprobs = tensor([[ -1.0771, -13.6726],
        [ -7.8276,  -3.4913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27074533700942993
Epoch 0, Step 4072: train/loss = 0.027119088917970657, train/raw-loss = 0.0003981466288678348, train/logprobs = tensor([[ -1.1691, -17.1516],
        [ -9.3802,  -3.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26720941066741943
Epoch 0, Step 4073: train/loss = 0.03155337646603584, train/raw-loss = 0.0040301792323589325, train/logprobs = tensor([[ -1.1247, -10.4959],
        [ -7.5620,  -2.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752319574356079
Epoch 0, Step 4074: train/loss = 0.02767305076122284, train/raw-loss = 0.0015443486627191305, train/logprobs = tensor([[ -0.9111, -12.2032],
        [ -7.3609,  -1.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26128703355789185
Epoch 0, Step 4075: train/loss = 0.0290595144033432, train/raw-loss = 0.0017663470935076475, train/logprobs = tensor([[ -1.1837, -14.4106],
        [ -8.8690,  -2.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27293169498443604
Epoch 0, Step 4076: train/loss = 0.028961433097720146, train/raw-loss = 0.004178187344223261, train/logprobs = tensor([[ -0.8508, -16.3350],
        [ -6.5646,  -3.3930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24783244729042053
Epoch 0, Step 4077: train/loss = 0.025581322610378265, train/raw-loss = 0.0006721800309605896, train/logprobs = tensor([[ -1.0488, -14.1807],
        [ -8.9776,  -2.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24909141659736633
Epoch 0, Step 4078: train/loss = 0.03159170597791672, train/raw-loss = 0.005127658601850271, train/logprobs = tensor([[ -0.8173, -15.5045],
        [ -6.0461,  -3.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2646404802799225
Epoch 0, Step 4079: train/loss = 0.02662770077586174, train/raw-loss = 0.002261633984744549, train/logprobs = tensor([[ -0.8463, -11.4611],
        [ -7.6197,  -2.2270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24366065859794617
Epoch 0, Step 4080: train/loss = 0.028386106714606285, train/raw-loss = 0.00434472132474184, train/logprobs = tensor([[ -1.4564, -16.2256],
        [ -8.2239,  -2.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2404138445854187
Epoch 0, Step 4081: train/loss = 0.027216697111725807, train/raw-loss = 0.002099668374285102, train/logprobs = tensor([[ -1.2937, -13.0184],
        [ -7.5329,  -1.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25117027759552
Epoch 0, Step 4082: train/loss = 0.026760991662740707, train/raw-loss = 0.001967867836356163, train/logprobs = tensor([[ -0.8846, -11.7801],
        [ -8.3582,  -2.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24793124198913574
Epoch 0, Step 4083: train/loss = 0.036616623401641846, train/raw-loss = 0.009355826303362846, train/logprobs = tensor([[-1.1298, -9.5224],
        [-7.6535, -1.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726079523563385
Epoch 0, Step 4084: train/loss = 0.029094524681568146, train/raw-loss = 0.0006846456089988351, train/logprobs = tensor([[ -0.9222, -17.7030],
        [ -8.2104,  -4.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840987741947174
Epoch 0, Step 4085: train/loss = 0.022733626887202263, train/raw-loss = 0.0012543505290523171, train/logprobs = tensor([[ -1.5028, -19.0148],
        [ -9.2936,  -6.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21479277312755585
Epoch 0, Step 4086: train/loss = 0.0292186439037323, train/raw-loss = 0.0037543224170804024, train/logprobs = tensor([[ -1.2135, -10.2237],
        [ -7.7762,  -1.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25464320182800293
Epoch 0, Step 4087: train/loss = 0.027463259175419807, train/raw-loss = 0.002160085132345557, train/logprobs = tensor([[ -1.3301, -10.2847],
        [ -8.4631,  -1.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25303173065185547
Epoch 0, Step 4088: train/loss = 0.09030558168888092, train/raw-loss = 0.06411473453044891, train/logprobs = tensor([[-0.7820, -8.7295],
        [-5.3079, -2.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26190847158432007
Epoch 0, Step 4089: train/loss = 0.02569699101150036, train/raw-loss = 0.001636990811675787, train/logprobs = tensor([[ -1.2324, -10.7475],
        [ -8.1461,  -1.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24060001969337463
Epoch 0, Step 4090: train/loss = 0.03054635412991047, train/raw-loss = 0.0015132674016058445, train/logprobs = tensor([[ -0.9449, -15.0650],
        [ -7.4404,  -2.3736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29033082723617554
Epoch 0, Step 4091: train/loss = 0.026747101917862892, train/raw-loss = 0.0007613388588652015, train/logprobs = tensor([[ -1.6944, -13.9145],
        [-10.0924,  -3.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598576545715332
Epoch 0, Step 4092: train/loss = 0.05164819583296776, train/raw-loss = 0.022006379440426826, train/logprobs = tensor([[ -1.9920, -10.1810],
        [-10.7661,  -2.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29641813039779663
Epoch 0, Step 4093: train/loss = 0.023147229105234146, train/raw-loss = 0.00024898667470552027, train/logprobs = tensor([[ -2.1211, -14.2066],
        [-11.6819,  -2.5734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22898243367671967
Epoch 0, Step 4094: train/loss = 0.027274176478385925, train/raw-loss = 0.0018173991702497005, train/logprobs = tensor([[ -1.5036, -11.4341],
        [ -9.3800,  -3.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545677721500397
Epoch 0, Step 4095: train/loss = 0.024684419855475426, train/raw-loss = 0.0007531532901339233, train/logprobs = tensor([[ -1.9052, -13.9907],
        [-10.7581,  -2.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23931267857551575
Epoch 0, Step 4096: train/loss = 0.06788605451583862, train/raw-loss = 0.04191083461046219, train/logprobs = tensor([[-1.6118, -9.3001],
        [-6.0715, -2.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25975218415260315
Epoch 0, Step 4097: train/loss = 0.026040075346827507, train/raw-loss = 0.0015704353572800756, train/logprobs = tensor([[ -1.1683, -10.3644],
        [ -8.6202,  -2.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24469639360904694
Epoch 0, Step 4098: train/loss = 0.02345244772732258, train/raw-loss = 0.0005452324985526502, train/logprobs = tensor([[ -0.9391, -14.1276],
        [ -8.5313,  -2.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22907213866710663
Epoch 0, Step 4099: train/loss = 0.02724989876151085, train/raw-loss = 0.0013412914704531431, train/logprobs = tensor([[ -1.2926, -14.6711],
        [ -8.6771,  -2.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25908607244491577
Epoch 0, Step 4100: train/loss = 0.032069046050310135, train/raw-loss = 0.007900513708591461, train/logprobs = tensor([[ -0.8287, -15.2313],
        [ -6.2592,  -1.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24168530106544495
Epoch 0, Step 4101: train/loss = 0.027676308527588844, train/raw-loss = 0.002638596808537841, train/logprobs = tensor([[ -1.1755, -12.8616],
        [ -7.1859,  -2.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2503771185874939
Epoch 0, Step 4102: train/loss = 0.02645646594464779, train/raw-loss = 0.0014685249188914895, train/logprobs = tensor([[ -0.9057, -12.6041],
        [ -7.7278,  -2.9127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498793751001358
Epoch 0, Step 4103: train/loss = 0.025870306417346, train/raw-loss = 0.0005695213912986219, train/logprobs = tensor([[ -1.1098, -11.7061],
        [ -8.8533,  -2.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530078589916229
Epoch 0, Step 4104: train/loss = 0.02500123158097267, train/raw-loss = 0.00031306332675740123, train/logprobs = tensor([[ -1.5167, -19.4716],
        [-10.2677,  -4.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24688169360160828
Epoch 0, Step 4105: train/loss = 0.7435261607170105, train/raw-loss = 0.7198708653450012, train/logprobs = tensor([[ -5.2365, -12.4096],
        [ -8.1647,  -2.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23655210435390472
Epoch 0, Step 4106: train/loss = 0.02675953134894371, train/raw-loss = 0.003440005937591195, train/logprobs = tensor([[ -1.5948, -15.7573],
        [ -7.8745,  -3.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2331952452659607
Epoch 0, Step 4107: train/loss = 0.03301915526390076, train/raw-loss = 0.005085995886474848, train/logprobs = tensor([[-0.8430, -8.8928],
        [-6.8497, -2.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2793315649032593
Epoch 0, Step 4108: train/loss = 0.026010937988758087, train/raw-loss = 0.001982811838388443, train/logprobs = tensor([[ -0.8426, -15.5213],
        [ -6.9811,  -5.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24028125405311584
Epoch 0, Step 4109: train/loss = 0.029077649116516113, train/raw-loss = 0.001786808017641306, train/logprobs = tensor([[ -1.0056, -12.3643],
        [ -7.7690,  -3.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27290838956832886
Epoch 0, Step 4110: train/loss = 0.07066703587770462, train/raw-loss = 0.044153593480587006, train/logprobs = tensor([[ -1.1457, -12.8879],
        [ -9.0426,  -3.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26513445377349854
Epoch 0, Step 4111: train/loss = 0.02265726961195469, train/raw-loss = 0.0005342947551980615, train/logprobs = tensor([[ -1.1305, -20.3096],
        [ -8.3950,  -3.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22122976183891296
Epoch 0, Step 4112: train/loss = 0.02758135460317135, train/raw-loss = 0.001942580915056169, train/logprobs = tensor([[ -1.2007, -13.3802],
        [ -8.7422,  -3.6346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25638771057128906
Epoch 0, Step 4113: train/loss = 0.028798656538128853, train/raw-loss = 0.005389264319092035, train/logprobs = tensor([[ -1.0087, -11.6416],
        [ -6.7872,  -2.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23409391939640045
Epoch 0, Step 4114: train/loss = 0.02609402686357498, train/raw-loss = 0.0014761727070435882, train/logprobs = tensor([[ -1.0388, -18.7307],
        [ -8.1113,  -5.8326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.246178537607193
Epoch 0, Step 4115: train/loss = 0.033931978046894073, train/raw-loss = 0.004008780233561993, train/logprobs = tensor([[ -1.4377, -11.5975],
        [-10.1400,  -1.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29923197627067566
Epoch 0, Step 4116: train/loss = 0.02832864224910736, train/raw-loss = 0.0039249612018466, train/logprobs = tensor([[ -0.9704, -12.6802],
        [ -7.0952,  -2.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24403677880764008
Epoch 0, Step 4117: train/loss = 0.023285789415240288, train/raw-loss = 0.0016641661059111357, train/logprobs = tensor([[ -1.3600, -15.3252],
        [ -7.9676,  -3.6190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21621622145175934
Epoch 0, Step 4118: train/loss = 0.028897691518068314, train/raw-loss = 0.0022014135029166937, train/logprobs = tensor([[ -1.1606, -13.6942],
        [ -7.7834,  -3.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26696276664733887
Epoch 0, Step 4119: train/loss = 0.03832550346851349, train/raw-loss = 0.008849762380123138, train/logprobs = tensor([[ -1.6434, -12.5715],
        [-10.5389,  -4.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2947573959827423
Epoch 0, Step 4120: train/loss = 0.027191413566470146, train/raw-loss = 0.0011178505374118686, train/logprobs = tensor([[ -1.0937, -11.6474],
        [ -8.2130,  -1.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607356309890747
Epoch 0, Step 4121: train/loss = 0.02643808163702488, train/raw-loss = 0.0004989259759895504, train/logprobs = tensor([[ -1.2893, -14.8697],
        [-10.9193,  -4.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25939154624938965
Epoch 0, Step 4122: train/loss = 0.0309725534170866, train/raw-loss = 0.0038132918998599052, train/logprobs = tensor([[ -0.9258, -15.6731],
        [ -7.0386,  -3.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715926170349121
Epoch 0, Step 4123: train/loss = 0.025191713124513626, train/raw-loss = 0.000237351399846375, train/logprobs = tensor([[ -1.5692, -12.4840],
        [-11.0464,  -1.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24954360723495483
Epoch 0, Step 4124: train/loss = 0.027049075812101364, train/raw-loss = 0.001259904121980071, train/logprobs = tensor([[ -0.9774, -18.1427],
        [ -8.1447,  -4.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578917443752289
Epoch 0, Step 4125: train/loss = 0.028422806411981583, train/raw-loss = 0.0013603162951767445, train/logprobs = tensor([[ -1.2858, -11.2138],
        [-10.2973,  -2.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27062487602233887
Epoch 0, Step 4126: train/loss = 0.027753503993153572, train/raw-loss = 0.0023197524715214968, train/logprobs = tensor([[ -1.6250, -13.6397],
        [ -8.2210,  -2.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25433751940727234
Epoch 0, Step 4127: train/loss = 0.03355789557099342, train/raw-loss = 0.0033292097505182028, train/logprobs = tensor([[-0.8157, -9.5826],
        [-7.0872, -2.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30228686332702637
Epoch 0, Step 4128: train/loss = 0.029303519055247307, train/raw-loss = 0.0008686354267410934, train/logprobs = tensor([[ -1.3431, -12.4445],
        [ -9.6115,  -2.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28434884548187256
Epoch 0, Step 4129: train/loss = 0.03062530606985092, train/raw-loss = 0.001963859423995018, train/logprobs = tensor([[ -0.9305, -14.4090],
        [ -6.9728,  -2.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28661447763442993
Epoch 0, Step 4130: train/loss = 0.030702637508511543, train/raw-loss = 0.0010458702454343438, train/logprobs = tensor([[ -1.1187, -10.1300],
        [ -8.3010,  -1.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2965676486492157
Epoch 0, Step 4131: train/loss = 0.02759772352874279, train/raw-loss = 0.0048079038970172405, train/logprobs = tensor([[ -1.0352, -15.8616],
        [ -6.2585,  -2.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22789819538593292
Epoch 0, Step 4132: train/loss = 0.028517521917819977, train/raw-loss = 0.0011176896514371037, train/logprobs = tensor([[ -1.4536, -10.5228],
        [ -8.6969,  -1.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27399832010269165
Epoch 0, Step 4133: train/loss = 0.029171312227845192, train/raw-loss = 0.007801028899848461, train/logprobs = tensor([[ -1.3203, -11.9702],
        [ -8.2062,  -1.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21370284259319305
Epoch 0, Step 4134: train/loss = 0.026598529890179634, train/raw-loss = 0.0008372446172870696, train/logprobs = tensor([[ -2.0163, -16.9407],
        [-10.4161,  -5.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25761285424232483
Epoch 0, Step 4135: train/loss = 0.025776240974664688, train/raw-loss = 0.004291860852390528, train/logprobs = tensor([[ -1.0031, -13.9311],
        [ -6.8808,  -2.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2148437798023224
Epoch 0, Step 4136: train/loss = 0.02731037698686123, train/raw-loss = 0.0011811560252681375, train/logprobs = tensor([[ -1.0412, -13.5064],
        [ -8.6737,  -3.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612922191619873
Epoch 0, Step 4137: train/loss = 0.02782732993364334, train/raw-loss = 0.0023760786280035973, train/logprobs = tensor([[ -0.9720, -19.0677],
        [ -7.2576,  -5.4516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545124888420105
Epoch 0, Step 4138: train/loss = 0.030460553243756294, train/raw-loss = 0.006605252623558044, train/logprobs = tensor([[-1.1956, -8.5617],
        [-6.6366, -1.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2385530024766922
Epoch 0, Step 4139: train/loss = 0.024025239050388336, train/raw-loss = 0.0010708781192079186, train/logprobs = tensor([[ -0.9985, -16.9918],
        [ -7.7742,  -3.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22954362630844116
Epoch 0, Step 4140: train/loss = 0.029456093907356262, train/raw-loss = 0.008578678593039513, train/logprobs = tensor([[ -1.3308, -10.9072],
        [ -6.4332,  -2.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087741494178772
Epoch 0, Step 4141: train/loss = 0.030971840023994446, train/raw-loss = 0.0008588583441451192, train/logprobs = tensor([[ -1.5489, -12.7596],
        [ -8.3226,  -3.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011298179626465
Epoch 0, Step 4142: train/loss = 0.027661925181746483, train/raw-loss = 0.0009609572007320821, train/logprobs = tensor([[ -1.3024, -16.3992],
        [ -9.8168,  -2.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2670096755027771
Epoch 0, Step 4143: train/loss = 0.03387670964002609, train/raw-loss = 0.007556577678769827, train/logprobs = tensor([[ -0.7069, -10.1913],
        [ -5.7183,  -2.1061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632012963294983
Epoch 0, Step 4144: train/loss = 0.02420925162732601, train/raw-loss = 0.0005809374852105975, train/logprobs = tensor([[ -1.1685, -13.5462],
        [ -8.3162,  -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23628313839435577
Epoch 0, Step 4145: train/loss = 0.028840553015470505, train/raw-loss = 0.005560946650803089, train/logprobs = tensor([[ -1.1923, -11.3330],
        [ -7.6493,  -2.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327960580587387
Epoch 0, Step 4146: train/loss = 0.03200982138514519, train/raw-loss = 0.0010339999571442604, train/logprobs = tensor([[ -1.3931, -12.5459],
        [-10.1682,  -2.1328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30975818634033203
Epoch 0, Step 4147: train/loss = 0.030193613842129707, train/raw-loss = 0.004680690821260214, train/logprobs = tensor([[ -1.2060, -12.7453],
        [ -7.0609,  -1.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25512921810150146
Epoch 0, Step 4148: train/loss = 0.03144095465540886, train/raw-loss = 0.004117511212825775, train/logprobs = tensor([[ -0.8514, -11.8280],
        [ -6.7870,  -1.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27323442697525024
Epoch 0, Step 4149: train/loss = 0.024952489882707596, train/raw-loss = 0.0006309244781732559, train/logprobs = tensor([[ -0.9332, -17.1869],
        [ -8.5958,  -4.2773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2432156503200531
Epoch 0, Step 4150: train/loss = 0.028780361637473106, train/raw-loss = 0.0021614592988044024, train/logprobs = tensor([[ -1.6263, -11.3346],
        [-10.1734,  -1.8916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26618900895118713
Epoch 0, Step 4151: train/loss = 0.028445573523640633, train/raw-loss = 0.0020068048033863306, train/logprobs = tensor([[ -0.9495, -11.9758],
        [ -6.7261,  -2.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26438769698143005
Epoch 0, Step 4152: train/loss = 0.027364296838641167, train/raw-loss = 0.0018221435602754354, train/logprobs = tensor([[ -0.7145, -15.9708],
        [ -6.4249,  -3.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25542151927948
Epoch 0, Step 4153: train/loss = 0.060109011828899384, train/raw-loss = 0.035472482442855835, train/logprobs = tensor([[ -1.1578, -10.3724],
        [ -6.8845,  -2.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2463652789592743
Epoch 0, Step 4154: train/loss = 0.02715304121375084, train/raw-loss = 0.0013911296846345067, train/logprobs = tensor([[ -1.1341, -16.0310],
        [ -9.2984,  -2.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25761908292770386
Epoch 0, Step 4155: train/loss = 0.027939513325691223, train/raw-loss = 0.001700622378848493, train/logprobs = tensor([[ -1.2898, -14.7459],
        [ -8.6073,  -2.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623888850212097
Epoch 0, Step 4156: train/loss = 0.029199844226241112, train/raw-loss = 0.005467291921377182, train/logprobs = tensor([[ -1.6395, -13.1037],
        [ -8.7371,  -5.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2373254895210266
Epoch 0, Step 4157: train/loss = 0.028527503833174706, train/raw-loss = 0.003145623952150345, train/logprobs = tensor([[ -1.0088, -13.2919],
        [ -7.2469,  -3.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538187801837921
Epoch 0, Step 4158: train/loss = 0.02802755869925022, train/raw-loss = 0.0019693614449352026, train/logprobs = tensor([[ -0.8667, -17.6472],
        [ -7.4597,  -4.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26058197021484375
Epoch 0, Step 4159: train/loss = 0.03649664297699928, train/raw-loss = 0.012973088771104813, train/logprobs = tensor([[-0.8281, -7.5585],
        [-7.7296, -1.5479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352355569601059
Epoch 0, Step 4160: train/loss = 0.026888269931077957, train/raw-loss = 0.0005790241411887109, train/logprobs = tensor([[ -0.9326, -15.8182],
        [ -8.2035,  -2.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2630924582481384
Epoch 0, Step 4161: train/loss = 0.04218210279941559, train/raw-loss = 0.015352431684732437, train/logprobs = tensor([[ -1.0361, -12.6619],
        [ -8.2218,  -3.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682967185974121
Epoch 0, Step 4162: train/loss = 0.031328268349170685, train/raw-loss = 0.0011296805460005999, train/logprobs = tensor([[ -0.7509, -12.4652],
        [ -7.2309,  -2.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30198588967323303
Epoch 0, Step 4163: train/loss = 0.02567214146256447, train/raw-loss = 0.003247644519433379, train/logprobs = tensor([[ -0.9446, -12.8247],
        [ -6.9789,  -2.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22424498200416565
Epoch 0, Step 4164: train/loss = 0.03091965988278389, train/raw-loss = 0.004462496377527714, train/logprobs = tensor([[-1.4569, -9.0368],
        [-7.3432, -2.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2645716369152069
Epoch 0, Step 4165: train/loss = 0.02774771861732006, train/raw-loss = 0.0027519254945218563, train/logprobs = tensor([[ -1.8610, -13.4159],
        [ -8.4819,  -2.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24995794892311096
Epoch 0, Step 4166: train/loss = 0.030302347615361214, train/raw-loss = 0.00801014807075262, train/logprobs = tensor([[ -1.0088, -12.5307],
        [ -6.6037,  -2.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22292199730873108
Epoch 0, Step 4167: train/loss = 0.028071921318769455, train/raw-loss = 0.0008165533072315156, train/logprobs = tensor([[ -1.0786, -15.5164],
        [ -8.6566,  -3.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725536525249481
Epoch 0, Step 4168: train/loss = 0.02806119993329048, train/raw-loss = 0.003093653591349721, train/logprobs = tensor([[ -0.9226, -12.3466],
        [ -8.0728,  -3.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.249675452709198
Epoch 0, Step 4169: train/loss = 0.03372526168823242, train/raw-loss = 0.006215774454176426, train/logprobs = tensor([[-1.4902, -9.5316],
        [-9.2513, -1.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750948965549469
Epoch 0, Step 4170: train/loss = 0.023342933505773544, train/raw-loss = 0.0010295893298462033, train/logprobs = tensor([[ -1.4682, -14.5950],
        [ -9.6058,  -2.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22313344478607178
Epoch 0, Step 4171: train/loss = 0.043022364377975464, train/raw-loss = 0.017548030242323875, train/logprobs = tensor([[-1.1305, -8.8637],
        [-8.6914, -2.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547433376312256
Epoch 0, Step 4172: train/loss = 0.030275795608758926, train/raw-loss = 0.004827561788260937, train/logprobs = tensor([[ -1.1853, -11.4415],
        [-10.3377,  -3.3327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25448232889175415
Epoch 0, Step 4173: train/loss = 0.026397328823804855, train/raw-loss = 0.0015526465140283108, train/logprobs = tensor([[ -0.8016, -15.2365],
        [ -6.9992,  -4.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24844680726528168
Epoch 0, Step 4174: train/loss = 0.03278040140867233, train/raw-loss = 0.0071608456782996655, train/logprobs = tensor([[ -0.9685, -11.8663],
        [ -7.0810,  -2.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561955451965332
Epoch 0, Step 4175: train/loss = 0.023577731102705002, train/raw-loss = 0.0004481678188312799, train/logprobs = tensor([[ -0.9490, -13.2983],
        [ -8.8486,  -2.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312956154346466
Epoch 0, Step 4176: train/loss = 0.026333261281251907, train/raw-loss = 0.0011282727355137467, train/logprobs = tensor([[ -0.9249, -16.5753],
        [ -7.4403,  -3.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25204989314079285
Epoch 0, Step 4177: train/loss = 0.028744421899318695, train/raw-loss = 0.0029061983805149794, train/logprobs = tensor([[ -1.0432, -12.6424],
        [ -6.5685,  -2.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583822011947632
Epoch 0, Step 4178: train/loss = 0.03887302428483963, train/raw-loss = 0.011595510877668858, train/logprobs = tensor([[ -1.0060, -11.9569],
        [ -6.9517,  -3.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27277514338493347
Epoch 0, Step 4179: train/loss = 0.025710785761475563, train/raw-loss = 0.0016856840811669827, train/logprobs = tensor([[ -0.9042, -12.5392],
        [ -6.7698,  -2.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24025100469589233
Epoch 0, Step 4180: train/loss = 0.021162012591958046, train/raw-loss = 0.0011046226136386395, train/logprobs = tensor([[ -1.9426, -14.6697],
        [-11.1101,  -2.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005739063024521
Epoch 0, Step 4181: train/loss = 0.027461662888526917, train/raw-loss = 9.488811338087544e-05, train/logprobs = tensor([[ -1.3807, -12.9389],
        [-10.8108,  -2.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27366772294044495
Epoch 0, Step 4182: train/loss = 0.027899308130145073, train/raw-loss = 0.00119964184705168, train/logprobs = tensor([[ -0.9806, -13.5910],
        [ -8.1228,  -2.6363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2669966518878937
Epoch 0, Step 4183: train/loss = 0.028788380324840546, train/raw-loss = 0.0020978599786758423, train/logprobs = tensor([[ -1.0662, -11.5408],
        [ -8.2165,  -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26690518856048584
Epoch 0, Step 4184: train/loss = 0.02831442281603813, train/raw-loss = 0.0019257431849837303, train/logprobs = tensor([[ -0.8963, -13.4412],
        [ -8.0689,  -3.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26388677954673767
Epoch 0, Step 4185: train/loss = 0.02474602684378624, train/raw-loss = 0.0021232166327536106, train/logprobs = tensor([[ -1.2937, -11.1719],
        [ -7.6707,  -2.8266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22622808814048767
Epoch 0, Step 4186: train/loss = 0.02804965153336525, train/raw-loss = 0.0012202583020552993, train/logprobs = tensor([[ -0.8834, -13.3760],
        [ -7.2360,  -3.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26829394698143005
Epoch 0, Step 4187: train/loss = 0.029101064428687096, train/raw-loss = 0.0035271814558655024, train/logprobs = tensor([[ -1.1749, -15.7001],
        [ -7.2485,  -4.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557387948036194
Epoch 0, Step 4188: train/loss = 0.02198409102857113, train/raw-loss = 0.0010732687078416348, train/logprobs = tensor([[ -2.5325, -12.8130],
        [ -9.8571,  -2.1325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20910823345184326
Epoch 0, Step 4189: train/loss = 0.02397444285452366, train/raw-loss = 0.0008286216179840267, train/logprobs = tensor([[ -1.2890, -11.0630],
        [ -9.6996,  -2.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23145820200443268
Epoch 0, Step 4190: train/loss = 0.025529785081744194, train/raw-loss = 0.0027118984144181013, train/logprobs = tensor([[ -1.2244, -11.5716],
        [ -7.6977,  -2.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22817885875701904
Epoch 0, Step 4191: train/loss = 0.031685251742601395, train/raw-loss = 0.008759566582739353, train/logprobs = tensor([[-1.0484, -8.8801],
        [-7.1321, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22925683856010437
Epoch 0, Step 4192: train/loss = 0.027023915201425552, train/raw-loss = 0.0015050468500703573, train/logprobs = tensor([[ -0.7990, -13.1441],
        [ -6.9808,  -2.7274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551886737346649
Epoch 0, Step 4193: train/loss = 0.02922157570719719, train/raw-loss = 0.0004943925305269659, train/logprobs = tensor([[ -1.7535, -12.8970],
        [-10.7412,  -3.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872718274593353
Epoch 0, Step 4194: train/loss = 0.028704650700092316, train/raw-loss = 0.0014953718055039644, train/logprobs = tensor([[ -1.1222, -11.6478],
        [ -8.6698,  -3.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720927894115448
Epoch 0, Step 4195: train/loss = 0.034584347158670425, train/raw-loss = 0.008388811722397804, train/logprobs = tensor([[ -1.4220, -11.8514],
        [ -8.8701,  -3.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2619553208351135
Epoch 0, Step 4196: train/loss = 0.027855386957526207, train/raw-loss = 0.000948110711760819, train/logprobs = tensor([[ -1.0561, -11.6536],
        [ -8.2704,  -1.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2690727710723877
Epoch 0, Step 4197: train/loss = 0.05871470645070076, train/raw-loss = 0.03261208534240723, train/logprobs = tensor([[-1.1624, -9.2547],
        [-8.1935, -3.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26102620363235474
Epoch 0, Step 4198: train/loss = 0.029998118057847023, train/raw-loss = 0.003453986719250679, train/logprobs = tensor([[ -1.2503, -11.8612],
        [ -8.2093,  -3.5441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26544129848480225
Epoch 0, Step 4199: train/loss = 0.03604409098625183, train/raw-loss = 0.0122408801689744, train/logprobs = tensor([[ -1.1631, -11.2494],
        [ -6.0957,  -2.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23803208768367767
Epoch 0, Step 4200: train/loss = 0.027328891679644585, train/raw-loss = 0.00127328687813133, train/logprobs = tensor([[ -1.0930, -10.2973],
        [ -8.9339,  -1.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26055604219436646
Epoch 0, Step 4201: train/loss = 0.028772693127393723, train/raw-loss = 0.000534165243152529, train/logprobs = tensor([[ -1.2509, -13.2972],
        [ -9.4977,  -3.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2823852598667145
Epoch 0, Step 4202: train/loss = 0.027386005967855453, train/raw-loss = 0.0017605640459805727, train/logprobs = tensor([[ -1.1814, -12.4093],
        [ -7.1681,  -3.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562544047832489
Epoch 0, Step 4203: train/loss = 0.053148943930864334, train/raw-loss = 0.029669180512428284, train/logprobs = tensor([[ -1.6966, -13.9015],
        [ -7.8962,  -3.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347976267337799
Epoch 0, Step 4204: train/loss = 0.025516996160149574, train/raw-loss = 0.0003660571528598666, train/logprobs = tensor([[ -1.3805, -12.0619],
        [-10.6925,  -2.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515093684196472
Epoch 0, Step 4205: train/loss = 0.03882860764861107, train/raw-loss = 0.011662596836686134, train/logprobs = tensor([[ -0.6288, -12.3156],
        [ -6.8459,  -2.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27166008949279785
Epoch 0, Step 4206: train/loss = 0.02723744325339794, train/raw-loss = 0.0013448285171762109, train/logprobs = tensor([[ -0.8239, -13.9716],
        [ -7.2583,  -4.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589261531829834
Epoch 0, Step 4207: train/loss = 0.02646551840007305, train/raw-loss = 0.0030416324734687805, train/logprobs = tensor([[-1.2847, -9.2457],
        [-7.3502, -1.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.234238862991333
Epoch 0, Step 4208: train/loss = 0.02870251052081585, train/raw-loss = 0.0010394322453066707, train/logprobs = tensor([[ -0.9431, -15.0661],
        [ -8.1873,  -3.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27663078904151917
Epoch 0, Step 4209: train/loss = 0.031013229861855507, train/raw-loss = 0.004433335270732641, train/logprobs = tensor([[ -1.0461, -10.0715],
        [ -9.9066,  -2.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657989263534546
Epoch 0, Step 4210: train/loss = 0.04597022384405136, train/raw-loss = 0.014267411082983017, train/logprobs = tensor([[ -1.0031, -10.8567],
        [ -7.6552,  -2.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31702813506126404
Epoch 0, Step 4211: train/loss = 0.033848680555820465, train/raw-loss = 0.004769422113895416, train/logprobs = tensor([[ -1.5619,  -8.3676],
        [-10.5667,  -2.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907925844192505
Epoch 0, Step 4212: train/loss = 0.026021378114819527, train/raw-loss = 0.0033875838853418827, train/logprobs = tensor([[ -1.1755, -11.2227],
        [ -8.5320,  -2.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22633793950080872
Epoch 0, Step 4213: train/loss = 0.026173528283834457, train/raw-loss = 0.0008994515519589186, train/logprobs = tensor([[ -0.7856, -14.5843],
        [ -7.9973,  -3.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527407705783844
Epoch 0, Step 4214: train/loss = 0.025057727470993996, train/raw-loss = 0.00013477521133609116, train/logprobs = tensor([[ -1.4282, -19.5867],
        [-11.3011,  -4.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492295354604721
Epoch 0, Step 4215: train/loss = 0.035212934017181396, train/raw-loss = 0.005863578524440527, train/logprobs = tensor([[-0.9040, -9.2281],
        [-7.8552, -2.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2934935688972473
Epoch 0, Step 4216: train/loss = 0.030470281839370728, train/raw-loss = 0.0024412863422185183, train/logprobs = tensor([[ -1.2080, -10.6347],
        [ -7.6763,  -2.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802899479866028
Epoch 0, Step 4217: train/loss = 0.028672564774751663, train/raw-loss = 0.00044037000043317676, train/logprobs = tensor([[ -1.3046, -11.7863],
        [ -9.4301,  -2.1894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2823219299316406
Epoch 0, Step 4218: train/loss = 0.027389585971832275, train/raw-loss = 0.0007508053095079958, train/logprobs = tensor([[ -1.9755, -13.4294],
        [-10.3750,  -3.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26638782024383545
Epoch 0, Step 4219: train/loss = 0.02533736079931259, train/raw-loss = 0.0013326717307791114, train/logprobs = tensor([[ -0.7514, -14.9696],
        [ -7.1940,  -3.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240046888589859
Epoch 0, Step 4220: train/loss = 0.028520949184894562, train/raw-loss = 0.0023471652530133724, train/logprobs = tensor([[ -0.5555, -14.4195],
        [ -6.0282,  -3.5091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2617378532886505
Epoch 0, Step 4221: train/loss = 0.026836298406124115, train/raw-loss = 0.000550554133951664, train/logprobs = tensor([[ -1.0556, -12.8418],
        [ -8.5583,  -1.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26285743713378906
Epoch 0, Step 4222: train/loss = 0.027188587933778763, train/raw-loss = 0.0015146136283874512, train/logprobs = tensor([[ -1.0265, -17.5564],
        [ -8.6031,  -4.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567397356033325
Epoch 0, Step 4223: train/loss = 0.02339864894747734, train/raw-loss = 0.0008435692870989442, train/logprobs = tensor([[ -1.7103, -13.0303],
        [-10.5939,  -2.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255507856607437
Epoch 0, Step 4224: train/loss = 0.03259287402033806, train/raw-loss = 0.004735975060611963, train/logprobs = tensor([[ -0.9919, -13.8272],
        [ -9.3922,  -2.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27856895327568054
Epoch 0, Step 4225: train/loss = 0.03611434996128082, train/raw-loss = 0.005784664768725634, train/logprobs = tensor([[-1.0124, -9.5511],
        [-8.7208, -2.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303296834230423
Epoch 0, Step 4226: train/loss = 0.02517264522612095, train/raw-loss = 0.0015998448943719268, train/logprobs = tensor([[ -1.2922, -14.2927],
        [ -7.6719,  -4.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23572799563407898
Epoch 0, Step 4227: train/loss = 0.0255427248775959, train/raw-loss = 0.0016670012846589088, train/logprobs = tensor([[ -0.7941, -10.4162],
        [ -7.6227,  -2.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23875723779201508
Epoch 0, Step 4228: train/loss = 0.02713332511484623, train/raw-loss = 0.001295433146879077, train/logprobs = tensor([[ -1.2414, -10.4307],
        [-10.4454,  -1.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25837892293930054
Epoch 0, Step 4229: train/loss = 0.03502530977129936, train/raw-loss = 0.011944414116442204, train/logprobs = tensor([[ -0.6848, -10.1733],
        [ -5.0454,  -2.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23080894351005554
Epoch 0, Step 4230: train/loss = 0.02792564406991005, train/raw-loss = 0.0006751110777258873, train/logprobs = tensor([[ -1.1037, -14.3965],
        [ -9.3491,  -2.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725053131580353
Epoch 0, Step 4231: train/loss = 0.024438070133328438, train/raw-loss = 0.0010994140757247806, train/logprobs = tensor([[ -0.9394, -13.8164],
        [ -7.5194,  -3.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333865612745285
Epoch 0, Step 4232: train/loss = 0.02659318596124649, train/raw-loss = 0.0015066667692735791, train/logprobs = tensor([[ -1.1019, -11.9374],
        [ -8.3275,  -1.7768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508651912212372
Epoch 0, Step 4233: train/loss = 0.028303256258368492, train/raw-loss = 0.0012388998875394464, train/logprobs = tensor([[ -0.7253, -14.7680],
        [ -7.0252,  -3.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27064353227615356
Epoch 0, Step 4234: train/loss = 0.02558210678398609, train/raw-loss = 0.001267769606783986, train/logprobs = tensor([[ -1.2626, -14.4536],
        [ -8.1961,  -3.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24314336478710175
Epoch 0, Step 4235: train/loss = 0.03031918779015541, train/raw-loss = 0.0007393103442154825, train/logprobs = tensor([[ -1.2214, -10.7377],
        [-10.1386,  -2.4405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29579877853393555
Epoch 0, Step 4236: train/loss = 0.022501524537801743, train/raw-loss = 0.0002662041806615889, train/logprobs = tensor([[ -1.4751, -13.8771],
        [-10.5795,  -3.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22235319018363953
Epoch 0, Step 4237: train/loss = 0.025768425315618515, train/raw-loss = 0.001956475432962179, train/logprobs = tensor([[ -0.9546, -12.0993],
        [ -6.9683,  -2.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2381194829940796
Epoch 0, Step 4238: train/loss = 0.03119715116918087, train/raw-loss = 0.0013487535761669278, train/logprobs = tensor([[ -1.0415, -13.1270],
        [ -9.6018,  -2.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984839677810669
Epoch 0, Step 4239: train/loss = 0.03254926949739456, train/raw-loss = 0.00553339347243309, train/logprobs = tensor([[ -1.0072, -12.8044],
        [ -7.6844,  -3.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701587378978729
Epoch 0, Step 4240: train/loss = 0.027634741738438606, train/raw-loss = 0.0019676689989864826, train/logprobs = tensor([[ -0.9905, -13.2588],
        [ -8.7867,  -3.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566707134246826
Epoch 0, Step 4241: train/loss = 0.027935732156038284, train/raw-loss = 0.000933341565541923, train/logprobs = tensor([[ -0.9240, -14.2588],
        [ -7.9361,  -3.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700238823890686
Epoch 0, Step 4242: train/loss = 0.02597826160490513, train/raw-loss = 0.0012997996527701616, train/logprobs = tensor([[ -1.0320, -19.3111],
        [ -8.2732,  -2.4538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24678461253643036
Epoch 0, Step 4243: train/loss = 0.025828449055552483, train/raw-loss = 0.0017081324476748705, train/logprobs = tensor([[ -0.8199, -16.5954],
        [ -6.9094,  -4.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2412031590938568
Epoch 0, Step 4244: train/loss = 0.032594598829746246, train/raw-loss = 0.009185703471302986, train/logprobs = tensor([[-1.3642, -7.7142],
        [-7.5875, -1.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340889573097229
Epoch 0, Step 4245: train/loss = 0.028358014300465584, train/raw-loss = 0.0032419986091554165, train/logprobs = tensor([[ -1.4577, -11.4194],
        [ -9.6826,  -3.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511601448059082
Epoch 0, Step 4246: train/loss = 0.026405250653624535, train/raw-loss = 0.0016609280137345195, train/logprobs = tensor([[ -1.4153, -10.7244],
        [ -8.3059,  -2.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24744322896003723
Epoch 0, Step 4247: train/loss = 0.03269153833389282, train/raw-loss = 0.006765759550035, train/logprobs = tensor([[ -1.1225, -11.9827],
        [ -8.5344,  -3.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592577338218689
Epoch 0, Step 4248: train/loss = 0.02953150123357773, train/raw-loss = 0.0007671591592952609, train/logprobs = tensor([[ -1.5700, -11.0839],
        [-10.1659,  -2.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876434028148651
Epoch 0, Step 4249: train/loss = 0.031430281698703766, train/raw-loss = 0.0047324467450380325, train/logprobs = tensor([[ -1.3991, -11.8911],
        [-10.1862,  -2.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26697835326194763
Epoch 0, Step 4250: train/loss = 0.028857680037617683, train/raw-loss = 0.0006819372065365314, train/logprobs = tensor([[ -1.1603, -11.8344],
        [ -9.2343,  -2.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817574143409729
Epoch 0, Step 4251: train/loss = 0.028408048674464226, train/raw-loss = 0.0035510919988155365, train/logprobs = tensor([[ -0.9658, -11.1613],
        [ -6.0544,  -2.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2485695630311966
Epoch 0, Step 4252: train/loss = 0.027778498828411102, train/raw-loss = 0.0024958946742117405, train/logprobs = tensor([[ -1.1120, -13.6349],
        [-10.2274,  -3.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2528260350227356
Epoch 0, Step 4253: train/loss = 0.0815935954451561, train/raw-loss = 0.052957795560359955, train/logprobs = tensor([[-1.4434, -8.8893],
        [-9.8694, -2.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28635790944099426
Epoch 0, Step 4254: train/loss = 0.030408650636672974, train/raw-loss = 0.0009960932657122612, train/logprobs = tensor([[ -1.0815, -12.7936],
        [ -9.3146,  -3.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2941255569458008
Epoch 0, Step 4255: train/loss = 0.028269406408071518, train/raw-loss = 0.002691275905817747, train/logprobs = tensor([[ -0.6030, -13.3435],
        [ -6.3900,  -3.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557813227176666
Epoch 0, Step 4256: train/loss = 0.026191864162683487, train/raw-loss = 0.0007548031280748546, train/logprobs = tensor([[ -1.3120, -16.4205],
        [ -9.6275,  -4.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543705999851227
Epoch 0, Step 4257: train/loss = 0.02957477979362011, train/raw-loss = 0.0012158975005149841, train/logprobs = tensor([[ -1.2073, -10.9522],
        [ -8.1905,  -2.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28358882665634155
Epoch 0, Step 4258: train/loss = 0.02823776751756668, train/raw-loss = 0.0013269990449771285, train/logprobs = tensor([[ -0.9107, -12.8422],
        [ -8.4967,  -1.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691076695919037
Epoch 0, Step 4259: train/loss = 0.025059109553694725, train/raw-loss = 0.0008127028704620898, train/logprobs = tensor([[-1.3124, -9.8705],
        [-9.4211, -1.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424640655517578
Epoch 0, Step 4260: train/loss = 0.027261490002274513, train/raw-loss = 0.0005657171132043004, train/logprobs = tensor([[ -0.8038, -15.8919],
        [ -7.9463,  -3.2331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26695773005485535
Epoch 0, Step 4261: train/loss = 0.02823445200920105, train/raw-loss = 0.0005272318376228213, train/logprobs = tensor([[ -1.4913, -12.5888],
        [-11.0626,  -2.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770722210407257
Epoch 0, Step 4262: train/loss = 0.028111912310123444, train/raw-loss = 0.00021761686366517097, train/logprobs = tensor([[ -1.9022, -11.4910],
        [-10.9544,  -2.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27894294261932373
Epoch 0, Step 4263: train/loss = 0.03327711299061775, train/raw-loss = 0.010789022780954838, train/logprobs = tensor([[ -0.8893, -12.5250],
        [ -7.1186,  -3.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248809039592743
Epoch 0, Step 4264: train/loss = 0.026877913624048233, train/raw-loss = 0.002461029449477792, train/logprobs = tensor([[ -1.3392, -13.3681],
        [ -8.7567,  -4.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24416884779930115
Epoch 0, Step 4265: train/loss = 0.028668425977230072, train/raw-loss = 0.003181041218340397, train/logprobs = tensor([[ -1.1795, -14.4841],
        [ -7.3696,  -3.2996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2548738420009613
Epoch 0, Step 4266: train/loss = 0.027294952422380447, train/raw-loss = 0.002528926357626915, train/logprobs = tensor([[ -0.9630, -11.4533],
        [ -7.7597,  -2.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24766026437282562
Epoch 0, Step 4267: train/loss = 0.030705858021974564, train/raw-loss = 0.0027387358713895082, train/logprobs = tensor([[ -0.7907, -11.6137],
        [ -7.1370,  -3.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27967119216918945
Epoch 0, Step 4268: train/loss = 0.026292286813259125, train/raw-loss = 0.0011875774944201112, train/logprobs = tensor([[ -1.0221, -12.0209],
        [ -8.8237,  -2.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510471045970917
Epoch 0, Step 4269: train/loss = 0.02981024980545044, train/raw-loss = 0.005084357690066099, train/logprobs = tensor([[-1.0621, -9.0928],
        [-8.4310, -2.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24725890159606934
Epoch 0, Step 4270: train/loss = 0.027126425877213478, train/raw-loss = 0.001810810063034296, train/logprobs = tensor([[ -1.0548, -16.5279],
        [ -8.5035,  -4.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531561553478241
Epoch 0, Step 4271: train/loss = 0.027786266058683395, train/raw-loss = 0.0019166902638971806, train/logprobs = tensor([[ -1.2320, -13.0339],
        [ -9.4548,  -1.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2586957812309265
Epoch 0, Step 4272: train/loss = 0.027814622968435287, train/raw-loss = 0.0012729075970128179, train/logprobs = tensor([[ -1.2236, -15.8016],
        [ -8.6516,  -4.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2654171288013458
Epoch 0, Step 4273: train/loss = 0.030111394822597504, train/raw-loss = 0.0007950186263769865, train/logprobs = tensor([[ -1.0164, -13.0815],
        [ -9.0466,  -2.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931637465953827
Epoch 0, Step 4274: train/loss = 0.02940705604851246, train/raw-loss = 0.0028671009931713343, train/logprobs = tensor([[ -0.7686, -14.9279],
        [ -6.2734,  -3.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653995752334595
Epoch 0, Step 4275: train/loss = 0.06206795945763588, train/raw-loss = 0.03749702125787735, train/logprobs = tensor([[-1.3357, -8.9285],
        [-7.8919, -2.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24570941925048828
Epoch 0, Step 4276: train/loss = 0.02559906244277954, train/raw-loss = 0.001137536601163447, train/logprobs = tensor([[ -1.6833, -16.2565],
        [ -9.4221,  -4.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24461525678634644
Epoch 0, Step 4277: train/loss = 0.024454304948449135, train/raw-loss = 0.0023979395627975464, train/logprobs = tensor([[ -1.2115, -13.5785],
        [ -8.7768,  -2.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2205636352300644
Epoch 0, Step 4278: train/loss = 0.02960439957678318, train/raw-loss = 0.002457236172631383, train/logprobs = tensor([[ -1.2836, -10.9299],
        [ -8.4350,  -2.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27147161960601807
Epoch 0, Step 4279: train/loss = 0.029426969587802887, train/raw-loss = 0.0007638571551069617, train/logprobs = tensor([[ -1.0965, -12.4561],
        [ -9.9112,  -3.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28663110733032227
Epoch 0, Step 4280: train/loss = 0.03736957162618637, train/raw-loss = 0.01591220311820507, train/logprobs = tensor([[-1.0328, -9.4875],
        [-7.6997, -2.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145736813545227
Epoch 0, Step 4281: train/loss = 0.05900324136018753, train/raw-loss = 0.03331516310572624, train/logprobs = tensor([[-0.9525, -9.2850],
        [-7.6764, -1.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568807601928711
Epoch 0, Step 4282: train/loss = 0.027576284483075142, train/raw-loss = 0.0007466688402928412, train/logprobs = tensor([[ -1.1622, -12.9078],
        [ -9.3986,  -3.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26829615235328674
Epoch 0, Step 4283: train/loss = 0.025036528706550598, train/raw-loss = 0.0005415698979049921, train/logprobs = tensor([[ -1.5779, -14.1020],
        [-11.2235,  -3.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449495941400528
Epoch 0, Step 4284: train/loss = 0.024843476712703705, train/raw-loss = 0.0003332443884573877, train/logprobs = tensor([[ -1.2619, -12.8173],
        [-10.9722,  -2.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24510231614112854
Epoch 0, Step 4285: train/loss = 0.027258386835455894, train/raw-loss = 0.0015895861433818936, train/logprobs = tensor([[ -1.0007, -12.7073],
        [ -7.1873,  -2.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566879987716675
Epoch 0, Step 4286: train/loss = 0.023813359439373016, train/raw-loss = 0.0005665143253281713, train/logprobs = tensor([[ -1.5085, -17.0172],
        [ -9.5800,  -4.4032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23246845602989197
Epoch 0, Step 4287: train/loss = 0.024523749947547913, train/raw-loss = 0.00029854426975362003, train/logprobs = tensor([[ -1.2083, -18.6489],
        [ -9.9867,  -4.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24225205183029175
Epoch 0, Step 4288: train/loss = 0.026627948507666588, train/raw-loss = 0.002571985125541687, train/logprobs = tensor([[-1.3001, -9.2864],
        [-7.8027, -2.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2405596375465393
Epoch 0, Step 4289: train/loss = 0.03189270943403244, train/raw-loss = 0.0014340197667479515, train/logprobs = tensor([[-1.1279, -9.4074],
        [-8.0400, -1.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30458688735961914
Epoch 0, Step 4290: train/loss = 0.030067261308431625, train/raw-loss = 0.00353973638266325, train/logprobs = tensor([[ -1.1185, -11.8075],
        [ -8.8988,  -2.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265275239944458
Epoch 0, Step 4291: train/loss = 0.026450444012880325, train/raw-loss = 0.0007032891153357923, train/logprobs = tensor([[ -1.2710, -13.4764],
        [-10.5797,  -2.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25747156143188477
Epoch 0, Step 4292: train/loss = 0.027824653312563896, train/raw-loss = 0.002006197813898325, train/logprobs = tensor([[ -0.9760, -11.5955],
        [ -8.7213,  -3.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.258184552192688
Epoch 0, Step 4293: train/loss = 0.027910858392715454, train/raw-loss = 0.0022091087885200977, train/logprobs = tensor([[-0.8688, -9.2685],
        [-7.6885, -2.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25701749324798584
Epoch 0, Step 4294: train/loss = 0.03036266192793846, train/raw-loss = 0.003075110726058483, train/logprobs = tensor([[-1.1816, -9.9065],
        [-8.7627, -2.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27287548780441284
Epoch 0, Step 4295: train/loss = 0.02745424211025238, train/raw-loss = 0.0019777007400989532, train/logprobs = tensor([[ -0.9617, -16.5018],
        [ -7.8667,  -3.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547653913497925
Epoch 0, Step 4296: train/loss = 0.03964975103735924, train/raw-loss = 0.012250302359461784, train/logprobs = tensor([[-1.0770, -7.4146],
        [-8.2495, -2.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27399447560310364
Epoch 0, Step 4297: train/loss = 0.023877860978245735, train/raw-loss = 0.0017549304757267237, train/logprobs = tensor([[ -0.8550, -10.3451],
        [ -7.0167,  -1.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22122929990291595
Epoch 0, Step 4298: train/loss = 0.02816130965948105, train/raw-loss = 0.0015647683758288622, train/logprobs = tensor([[ -0.6396, -14.5895],
        [ -6.4710,  -3.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26596540212631226
Epoch 0, Step 4299: train/loss = 0.028251180425286293, train/raw-loss = 0.0004642146232072264, train/logprobs = tensor([[ -1.8254, -12.4718],
        [-11.9610,  -2.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27786967158317566
Epoch 0, Step 4300: train/loss = 0.038983460515737534, train/raw-loss = 0.014527397230267525, train/logprobs = tensor([[-1.3578, -7.6957],
        [-9.0926, -2.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2445605993270874
Epoch 0, Step 4301: train/loss = 0.026047367602586746, train/raw-loss = 0.0011613809037953615, train/logprobs = tensor([[ -1.4937, -12.0975],
        [ -9.2474,  -1.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24885985255241394
Epoch 0, Step 4302: train/loss = 0.026729237288236618, train/raw-loss = 0.0005790466675534844, train/logprobs = tensor([[ -1.7362, -12.3038],
        [ -9.9668,  -2.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26150190830230713
Epoch 0, Step 4303: train/loss = 0.025770090520381927, train/raw-loss = 0.001161891152150929, train/logprobs = tensor([[ -1.1441, -14.1311],
        [ -8.6978,  -3.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24608199298381805
Epoch 0, Step 4304: train/loss = 0.025268087163567543, train/raw-loss = 0.000637334946077317, train/logprobs = tensor([[ -1.2097, -11.7231],
        [-10.3519,  -2.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24630752205848694
Epoch 0, Step 4305: train/loss = 0.024978745728731155, train/raw-loss = 0.0009687991696409881, train/logprobs = tensor([[ -1.0174, -19.5791],
        [ -8.8019,  -4.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2400994747877121
Epoch 0, Step 4306: train/loss = 0.025622716173529625, train/raw-loss = 0.002553660422563553, train/logprobs = tensor([[-1.4060, -9.9238],
        [-7.9089, -2.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23069055378437042
Epoch 0, Step 4307: train/loss = 0.036408133804798126, train/raw-loss = 0.008238645270466805, train/logprobs = tensor([[-1.2196, -8.7185],
        [-8.3919, -1.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28169485926628113
Epoch 0, Step 4308: train/loss = 0.027155647054314613, train/raw-loss = 0.0019481830531731248, train/logprobs = tensor([[ -1.1394,  -9.8170],
        [-10.1871,  -1.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25207462906837463
Epoch 0, Step 4309: train/loss = 0.02545859105885029, train/raw-loss = 0.0006048360373824835, train/logprobs = tensor([[ -0.9239, -12.7239],
        [ -9.1465,  -2.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24853754043579102
Epoch 0, Step 4310: train/loss = 0.023211130872368813, train/raw-loss = 0.0007549709407612681, train/logprobs = tensor([[ -1.1744, -15.7228],
        [ -9.2141,  -3.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22456158697605133
Epoch 0, Step 4311: train/loss = 0.027611330151557922, train/raw-loss = 0.004876997787505388, train/logprobs = tensor([[ -1.1017, -13.5193],
        [ -8.2809,  -4.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22734332084655762
Epoch 0, Step 4312: train/loss = 0.026594415307044983, train/raw-loss = 0.0014059287495911121, train/logprobs = tensor([[ -1.3102, -10.9522],
        [ -9.5160,  -2.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518848776817322
Epoch 0, Step 4313: train/loss = 0.02716163545846939, train/raw-loss = 0.001848400803282857, train/logprobs = tensor([[ -0.9112, -13.0846],
        [ -8.6088,  -3.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25313234329223633
Epoch 0, Step 4314: train/loss = 0.02793213352560997, train/raw-loss = 0.0008485332364216447, train/logprobs = tensor([[ -1.2819, -11.5848],
        [-10.5695,  -2.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708359956741333
Epoch 0, Step 4315: train/loss = 0.026629390195012093, train/raw-loss = 0.0009459906723350286, train/logprobs = tensor([[ -1.4164, -15.5668],
        [-10.4966,  -3.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568340003490448
Epoch 0, Step 4316: train/loss = 0.02928757295012474, train/raw-loss = 0.006900280248373747, train/logprobs = tensor([[ -1.1193, -11.0806],
        [ -8.3861,  -2.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22387292981147766
Epoch 0, Step 4317: train/loss = 0.027783431112766266, train/raw-loss = 0.0007982151582837105, train/logprobs = tensor([[ -1.0516, -12.9295],
        [ -9.2767,  -3.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698521316051483
Epoch 0, Step 4318: train/loss = 0.026593079790472984, train/raw-loss = 0.00044645971502177417, train/logprobs = tensor([[ -1.6816, -17.5086],
        [-10.9517,  -4.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26146620512008667
Epoch 0, Step 4319: train/loss = 0.057359084486961365, train/raw-loss = 0.031900178641080856, train/logprobs = tensor([[-1.0900, -9.4287],
        [-8.6739, -2.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545890510082245
Epoch 0, Step 4320: train/loss = 0.02873929962515831, train/raw-loss = 0.0010971160372719169, train/logprobs = tensor([[ -1.0343, -13.8711],
        [ -9.0723,  -3.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27642184495925903
Epoch 0, Step 4321: train/loss = 0.026397081092000008, train/raw-loss = 0.0005815690383315086, train/logprobs = tensor([[ -0.9006, -11.4258],
        [ -8.3061,  -2.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25815510749816895
Epoch 0, Step 4322: train/loss = 0.028003035113215446, train/raw-loss = 0.00042023364221677184, train/logprobs = tensor([[ -1.2331, -11.9321],
        [-10.0604,  -3.2708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2758280038833618
Epoch 0, Step 4323: train/loss = 0.023980678990483284, train/raw-loss = 0.0015904261963441968, train/logprobs = tensor([[ -0.8765, -10.7053],
        [ -7.9638,  -2.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22390252351760864
Epoch 0, Step 4324: train/loss = 0.026165779680013657, train/raw-loss = 0.0005709014367312193, train/logprobs = tensor([[ -1.0682, -19.1021],
        [ -8.4796,  -5.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559487819671631
Epoch 0, Step 4325: train/loss = 0.025661470368504524, train/raw-loss = 0.0003202699590474367, train/logprobs = tensor([[ -1.1467, -13.6594],
        [-10.1640,  -3.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534119784832001
Epoch 0, Step 4326: train/loss = 0.021223286166787148, train/raw-loss = 0.00022559863282367587, train/logprobs = tensor([[ -1.2302, -14.9767],
        [-10.0764,  -3.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20997685194015503
Epoch 0, Step 4327: train/loss = 0.026488153263926506, train/raw-loss = 0.00030583838815800846, train/logprobs = tensor([[ -1.1766, -18.8354],
        [ -9.1492,  -4.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618231475353241
Epoch 0, Step 4328: train/loss = 0.029398085549473763, train/raw-loss = 0.003727939911186695, train/logprobs = tensor([[ -0.7717, -10.8594],
        [ -7.2105,  -2.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567014694213867
Epoch 0, Step 4329: train/loss = 0.027792733162641525, train/raw-loss = 0.0008162879385054111, train/logprobs = tensor([[ -0.9605, -10.5785],
        [ -8.0762,  -2.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697644531726837
Epoch 0, Step 4330: train/loss = 0.051576096564531326, train/raw-loss = 0.020642602816224098, train/logprobs = tensor([[ -0.9219, -14.5465],
        [ -7.1439,  -4.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3093349039554596
Epoch 0, Step 4331: train/loss = 0.02613324299454689, train/raw-loss = 0.0004906788235530257, train/logprobs = tensor([[ -0.9276, -15.8439],
        [ -8.2340,  -2.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564256489276886
Epoch 0, Step 4332: train/loss = 0.02589283138513565, train/raw-loss = 0.0014822161756455898, train/logprobs = tensor([[ -1.3185, -11.9793],
        [ -8.7928,  -2.4887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24410614371299744
Epoch 0, Step 4333: train/loss = 0.03244617581367493, train/raw-loss = 0.0033458394464105368, train/logprobs = tensor([[-1.0702, -8.8196],
        [-9.3648, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29100337624549866
Epoch 0, Step 4334: train/loss = 0.02490740641951561, train/raw-loss = 0.0007062426302582026, train/logprobs = tensor([[ -1.0104, -13.2228],
        [ -8.2172,  -2.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2420116364955902
Epoch 0, Step 4335: train/loss = 0.024960903450846672, train/raw-loss = 0.0003184705274179578, train/logprobs = tensor([[ -0.9113, -15.6823],
        [ -9.5424,  -4.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464243322610855
Epoch 0, Step 4336: train/loss = 0.04979424178600311, train/raw-loss = 0.023638935759663582, train/logprobs = tensor([[ -1.2352, -18.8687],
        [ -8.4563,  -6.3451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.261553019285202
Epoch 0, Step 4337: train/loss = 0.025754867121577263, train/raw-loss = 0.0023623667657375336, train/logprobs = tensor([[-1.2698, -9.9710],
        [-7.6855, -1.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339249849319458
Epoch 0, Step 4338: train/loss = 0.026961054652929306, train/raw-loss = 0.00035448221024125814, train/logprobs = tensor([[ -1.5354, -12.8862],
        [-11.2070,  -2.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26606571674346924
Epoch 0, Step 4339: train/loss = 0.023249400779604912, train/raw-loss = 0.0013868394307792187, train/logprobs = tensor([[ -1.8342, -15.9027],
        [ -9.3203,  -3.2109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21862560510635376
Epoch 0, Step 4340: train/loss = 0.024603787809610367, train/raw-loss = 0.00035973871126770973, train/logprobs = tensor([[ -0.9709, -16.3886],
        [ -9.7377,  -3.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24244047701358795
Epoch 0, Step 4341: train/loss = 0.02545037679374218, train/raw-loss = 0.0011985519668087363, train/logprobs = tensor([[ -1.4300, -13.1618],
        [ -9.2921,  -2.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24251824617385864
Epoch 0, Step 4342: train/loss = 0.030534205958247185, train/raw-loss = 0.0002821622765623033, train/logprobs = tensor([[ -1.3129, -14.4612],
        [ -9.7273,  -2.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3025204539299011
Epoch 0, Step 4343: train/loss = 0.04348091036081314, train/raw-loss = 0.014849189668893814, train/logprobs = tensor([[ -1.0238, -10.3296],
        [ -8.3686,  -2.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2863171696662903
Epoch 0, Step 4344: train/loss = 0.025825943797826767, train/raw-loss = 0.0007129854639060795, train/logprobs = tensor([[ -1.1248, -12.4506],
        [ -9.7229,  -2.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511295676231384
Epoch 0, Step 4345: train/loss = 0.030638057738542557, train/raw-loss = 0.002702542580664158, train/logprobs = tensor([[ -0.8525, -13.2964],
        [ -6.7535,  -1.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27935513854026794
Epoch 0, Step 4346: train/loss = 0.02963579073548317, train/raw-loss = 0.0006858591223135591, train/logprobs = tensor([[ -1.2449, -18.0387],
        [ -8.1445,  -4.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28949931263923645
Epoch 0, Step 4347: train/loss = 0.033855464309453964, train/raw-loss = 0.009195133112370968, train/logprobs = tensor([[-1.2563, -7.7152],
        [-7.2628, -2.0338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24660331010818481
Epoch 0, Step 4348: train/loss = 0.0267544686794281, train/raw-loss = 0.0007680486887693405, train/logprobs = tensor([[ -0.9540, -14.7774],
        [ -8.2854,  -2.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598642110824585
Epoch 0, Step 4349: train/loss = 0.04181806743144989, train/raw-loss = 0.014142923057079315, train/logprobs = tensor([[-0.8562, -9.0871],
        [-7.7516, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27675148844718933
Epoch 0, Step 4350: train/loss = 0.02516051009297371, train/raw-loss = 0.0001827150263125077, train/logprobs = tensor([[ -1.1911, -16.7851],
        [-11.4618,  -4.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24977794289588928
Epoch 0, Step 4351: train/loss = 0.028805434703826904, train/raw-loss = 0.0022965739481151104, train/logprobs = tensor([[ -1.1776, -14.2076],
        [ -8.1860,  -3.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26508861780166626
Epoch 0, Step 4352: train/loss = 0.02745988592505455, train/raw-loss = 0.0007559327641502023, train/logprobs = tensor([[ -1.4295, -15.1973],
        [-11.8688,  -3.7411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2670395076274872
Epoch 0, Step 4353: train/loss = 0.0222780779004097, train/raw-loss = 0.0004763057513628155, train/logprobs = tensor([[ -1.5932, -16.2016],
        [ -9.4239,  -4.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21801772713661194
Epoch 0, Step 4354: train/loss = 0.029280927032232285, train/raw-loss = 0.0012665118556469679, train/logprobs = tensor([[ -0.7891, -12.2179],
        [ -7.0060,  -2.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28014418482780457
Epoch 0, Step 4355: train/loss = 0.025542911142110825, train/raw-loss = 0.0010814793640747666, train/logprobs = tensor([[ -1.3896, -15.0984],
        [ -9.6844,  -3.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24461430311203003
Epoch 0, Step 4356: train/loss = 0.02914157137274742, train/raw-loss = 0.003931406885385513, train/logprobs = tensor([[ -1.0665, -13.7093],
        [ -8.1431,  -2.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2521016299724579
Epoch 0, Step 4357: train/loss = 0.02875029481947422, train/raw-loss = 0.0009777819504961371, train/logprobs = tensor([[ -1.1211, -12.4845],
        [ -9.3041,  -3.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27772513031959534
Epoch 0, Step 4358: train/loss = 0.0388965979218483, train/raw-loss = 0.008969396352767944, train/logprobs = tensor([[ -1.0232, -11.3896],
        [ -8.2209,  -3.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992720305919647
Epoch 0, Step 4359: train/loss = 0.027370154857635498, train/raw-loss = 0.0019251647172495723, train/logprobs = tensor([[ -1.3189, -10.4572],
        [-10.4386,  -2.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25444990396499634
Epoch 0, Step 4360: train/loss = 0.028310876339673996, train/raw-loss = 0.002639898331835866, train/logprobs = tensor([[ -0.7817, -10.4620],
        [ -7.0696,  -2.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567097842693329
Epoch 0, Step 4361: train/loss = 0.028754619881510735, train/raw-loss = 0.0015644878149032593, train/logprobs = tensor([[ -1.3273, -14.2079],
        [ -9.9338,  -3.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27190130949020386
Epoch 0, Step 4362: train/loss = 0.031034011393785477, train/raw-loss = 0.0045560612343251705, train/logprobs = tensor([[ -0.7498, -11.3253],
        [ -7.6228,  -3.4919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647795081138611
Epoch 0, Step 4363: train/loss = 0.026319485157728195, train/raw-loss = 0.0017397879855707288, train/logprobs = tensor([[ -1.6009, -10.6976],
        [-10.0228,  -2.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24579696357250214
Epoch 0, Step 4364: train/loss = 0.025312189012765884, train/raw-loss = 0.0006063577602617443, train/logprobs = tensor([[ -1.0518, -12.7004],
        [ -8.5955,  -2.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24705830216407776
Epoch 0, Step 4365: train/loss = 0.02734736166894436, train/raw-loss = 0.0033076563850045204, train/logprobs = tensor([[ -1.3160, -14.1497],
        [ -8.7910,  -3.2403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24039706587791443
Epoch 0, Step 4366: train/loss = 0.03057626262307167, train/raw-loss = 0.0038146618753671646, train/logprobs = tensor([[ -0.7918, -12.4045],
        [ -6.0380,  -2.1319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676159739494324
Epoch 0, Step 4367: train/loss = 0.0319589264690876, train/raw-loss = 0.005219320300966501, train/logprobs = tensor([[ -0.9655, -11.1012],
        [ -7.6101,  -2.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26739606261253357
Epoch 0, Step 4368: train/loss = 0.026446133852005005, train/raw-loss = 0.0003230207075830549, train/logprobs = tensor([[ -1.2961, -13.7432],
        [ -9.6552,  -3.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26123112440109253
Epoch 0, Step 4369: train/loss = 0.02741299569606781, train/raw-loss = 0.001981158275157213, train/logprobs = tensor([[ -0.8784, -11.5998],
        [ -7.0639,  -2.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25431838631629944
Epoch 0, Step 4370: train/loss = 0.026019103825092316, train/raw-loss = 0.0006988121895119548, train/logprobs = tensor([[ -0.9194, -12.0156],
        [ -8.2116,  -1.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532029151916504
Epoch 0, Step 4371: train/loss = 0.027972567826509476, train/raw-loss = 0.00041062969830818474, train/logprobs = tensor([[ -1.0634, -12.6809],
        [ -9.6686,  -2.2411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27561935782432556
Epoch 0, Step 4372: train/loss = 0.02947288565337658, train/raw-loss = 0.003729491028934717, train/logprobs = tensor([[ -0.9272, -15.7445],
        [ -7.7862,  -3.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2574339509010315
Epoch 0, Step 4373: train/loss = 0.02622472681105137, train/raw-loss = 0.0006672930903732777, train/logprobs = tensor([[ -0.6605, -17.3496],
        [ -7.3869,  -4.2759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555743455886841
Epoch 0, Step 4374: train/loss = 0.02511454187333584, train/raw-loss = 0.0030685244128108025, train/logprobs = tensor([[-1.2028, -9.5879],
        [-9.6953, -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22046016156673431
Epoch 0, Step 4375: train/loss = 0.029917646199464798, train/raw-loss = 0.0077456096187233925, train/logprobs = tensor([[ -1.2185, -14.5304],
        [ -7.7314,  -3.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2217203825712204
Epoch 0, Step 4376: train/loss = 0.027201082557439804, train/raw-loss = 0.0009918264113366604, train/logprobs = tensor([[ -0.9298, -14.8541],
        [ -8.8027,  -3.2191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26209256052970886
Epoch 0, Step 4377: train/loss = 0.02619554102420807, train/raw-loss = 0.0003211743605788797, train/logprobs = tensor([[ -1.5036, -14.2520],
        [ -9.8361,  -3.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25874364376068115
Epoch 0, Step 4378: train/loss = 0.029262442141771317, train/raw-loss = 0.002182964701205492, train/logprobs = tensor([[ -1.1194, -13.8840],
        [ -8.0267,  -2.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707947790622711
Epoch 0, Step 4379: train/loss = 0.4906611442565918, train/raw-loss = 0.47001978754997253, train/logprobs = tensor([[ -4.7626, -12.1158],
        [ -8.7728,  -2.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20641350746154785
Epoch 0, Step 4380: train/loss = 0.02840147726237774, train/raw-loss = 0.0008500648546032608, train/logprobs = tensor([[ -1.1035, -12.5216],
        [ -7.8706,  -2.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2755141258239746
Epoch 0, Step 4381: train/loss = 0.03015078604221344, train/raw-loss = 0.0008338863262906671, train/logprobs = tensor([[ -1.4234, -10.7324],
        [-10.1613,  -3.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931690216064453
Epoch 0, Step 4382: train/loss = 0.029998386278748512, train/raw-loss = 0.0073918444104492664, train/logprobs = tensor([[-0.5794, -8.1139],
        [-5.9234, -1.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22606539726257324
Epoch 0, Step 4383: train/loss = 0.02601751685142517, train/raw-loss = 0.000809360935818404, train/logprobs = tensor([[ -1.2162, -14.1091],
        [ -8.2140,  -1.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520815432071686
Epoch 0, Step 4384: train/loss = 0.025548521429300308, train/raw-loss = 0.0006030314252711833, train/logprobs = tensor([[ -1.0922, -13.9879],
        [ -7.9748,  -2.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24945490062236786
Epoch 0, Step 4385: train/loss = 0.02643248438835144, train/raw-loss = 0.00039366871351376176, train/logprobs = tensor([[ -1.2852, -10.7060],
        [-10.1195,  -1.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26038819551467896
Epoch 0, Step 4386: train/loss = 0.02291795425117016, train/raw-loss = 0.0008277648012153804, train/logprobs = tensor([[ -0.8401, -12.4388],
        [ -8.2470,  -1.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22090189158916473
Epoch 0, Step 4387: train/loss = 0.07918918877840042, train/raw-loss = 0.049086157232522964, train/logprobs = tensor([[ -0.8259, -12.3573],
        [ -7.9457,  -4.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010302782058716
Epoch 0, Step 4388: train/loss = 0.0423031821846962, train/raw-loss = 0.017430642619729042, train/logprobs = tensor([[ -0.7068, -11.9020],
        [ -6.4176,  -2.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24872538447380066
Epoch 0, Step 4389: train/loss = 0.024801485240459442, train/raw-loss = 0.0027368501760065556, train/logprobs = tensor([[ -1.1471, -19.7503],
        [ -7.1801,  -5.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22064636647701263
Epoch 0, Step 4390: train/loss = 0.025575965642929077, train/raw-loss = 0.00022693100618198514, train/logprobs = tensor([[ -1.2572, -15.9567],
        [-10.0021,  -1.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534903287887573
Epoch 0, Step 4391: train/loss = 0.026694267988204956, train/raw-loss = 0.001990718999877572, train/logprobs = tensor([[ -0.6375, -12.7378],
        [ -6.8801,  -3.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24703548848628998
Epoch 0, Step 4392: train/loss = 0.025414247065782547, train/raw-loss = 0.0023302531335502863, train/logprobs = tensor([[ -0.8613, -14.8857],
        [ -7.6647,  -2.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23083993792533875
Epoch 0, Step 4393: train/loss = 0.03160415217280388, train/raw-loss = 0.004970752168446779, train/logprobs = tensor([[ -1.5442, -13.9660],
        [ -8.2043,  -3.3751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26633402705192566
Epoch 0, Step 4394: train/loss = 0.02677592635154724, train/raw-loss = 0.0021339666564017534, train/logprobs = tensor([[ -0.8388, -12.5107],
        [ -6.8924,  -3.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24641960859298706
Epoch 0, Step 4395: train/loss = 0.04106738418340683, train/raw-loss = 0.017329582944512367, train/logprobs = tensor([[-0.7914, -8.6966],
        [-8.3589, -2.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23737803101539612
Epoch 0, Step 4396: train/loss = 0.03146463632583618, train/raw-loss = 0.005806926172226667, train/logprobs = tensor([[ -0.7562, -10.8474],
        [ -6.2788,  -2.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565770745277405
Epoch 0, Step 4397: train/loss = 0.030544066801667213, train/raw-loss = 0.005014325026422739, train/logprobs = tensor([[ -0.8625, -13.4423],
        [ -7.2044,  -4.2646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2552974224090576
Epoch 0, Step 4398: train/loss = 0.027770299464464188, train/raw-loss = 0.001974250189960003, train/logprobs = tensor([[-1.2579, -8.9921],
        [-9.0664, -1.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579604983329773
Epoch 0, Step 4399: train/loss = 0.027697868645191193, train/raw-loss = 0.0032446386758238077, train/logprobs = tensor([[ -1.3176, -13.5269],
        [ -9.6001,  -3.4846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24453231692314148
Epoch 0, Step 4400: train/loss = 0.02873798832297325, train/raw-loss = 0.0002625191118568182, train/logprobs = tensor([[ -1.1458, -16.9858],
        [ -9.4432,  -5.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2847546637058258
Epoch 0, Step 4401: train/loss = 0.029705224558711052, train/raw-loss = 0.00038898689672350883, train/logprobs = tensor([[ -0.9740, -11.0183],
        [ -9.0655,  -1.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29316234588623047
Epoch 0, Step 4402: train/loss = 0.023171227425336838, train/raw-loss = 0.0001833484275266528, train/logprobs = tensor([[ -1.3955, -14.9881],
        [ -9.8343,  -2.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22987878322601318
Epoch 0, Step 4403: train/loss = 0.027907127514481544, train/raw-loss = 0.005048343446105719, train/logprobs = tensor([[ -1.1653, -11.6602],
        [ -8.0812,  -2.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22858783602714539
Epoch 0, Step 4404: train/loss = 0.024189112707972527, train/raw-loss = 0.002900974592193961, train/logprobs = tensor([[ -0.9926, -12.5390],
        [ -9.0494,  -4.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21288138628005981
Epoch 0, Step 4405: train/loss = 0.02469826117157936, train/raw-loss = 0.0006697600474581122, train/logprobs = tensor([[ -0.9238, -18.8950],
        [ -7.8976,  -4.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2402849793434143
Epoch 0, Step 4406: train/loss = 0.029182743281126022, train/raw-loss = 0.002981038298457861, train/logprobs = tensor([[ -1.2760, -13.1750],
        [ -8.8990,  -2.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26201707124710083
Epoch 0, Step 4407: train/loss = 0.023309119045734406, train/raw-loss = 0.0007634647190570831, train/logprobs = tensor([[ -1.7431, -12.8549],
        [-10.8349,  -3.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22545655071735382
Epoch 0, Step 4408: train/loss = 0.029134389013051987, train/raw-loss = 0.0020542049314826727, train/logprobs = tensor([[ -0.8745, -13.4874],
        [ -6.4798,  -2.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.270801842212677
Epoch 0, Step 4409: train/loss = 0.02972884476184845, train/raw-loss = 0.002743592020124197, train/logprobs = tensor([[ -1.2573, -14.6172],
        [ -8.7125,  -4.2645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26985251903533936
Epoch 0, Step 4410: train/loss = 0.028677742928266525, train/raw-loss = 0.0013315596152096987, train/logprobs = tensor([[ -1.1200, -14.3690],
        [ -7.7656,  -2.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27346181869506836
Epoch 0, Step 4411: train/loss = 0.03479471802711487, train/raw-loss = 0.005001990124583244, train/logprobs = tensor([[-1.3917, -8.5314],
        [-8.3469, -1.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29792726039886475
Epoch 0, Step 4412: train/loss = 0.025930020958185196, train/raw-loss = 0.00026435026666149497, train/logprobs = tensor([[ -1.3578, -16.5160],
        [-10.8445,  -3.2834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566567063331604
Epoch 0, Step 4413: train/loss = 0.04020281508564949, train/raw-loss = 0.015026059001684189, train/logprobs = tensor([[ -1.3485, -13.2310],
        [ -9.1716,  -2.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517675459384918
Epoch 0, Step 4414: train/loss = 0.027489233762025833, train/raw-loss = 0.0010747348424047232, train/logprobs = tensor([[ -0.8926, -15.3916],
        [ -7.7527,  -3.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641449570655823
Epoch 0, Step 4415: train/loss = 0.02636195532977581, train/raw-loss = 0.0008579192217439413, train/logprobs = tensor([[ -0.8602, -12.2470],
        [ -7.7338,  -3.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25504037737846375
Epoch 0, Step 4416: train/loss = 0.029617464169859886, train/raw-loss = 0.0010913178557530046, train/logprobs = tensor([[ -1.1932, -13.3585],
        [ -9.7241,  -1.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28526145219802856
Epoch 0, Step 4417: train/loss = 0.043347738683223724, train/raw-loss = 0.01791432686150074, train/logprobs = tensor([[-0.9290, -9.2306],
        [-7.8012, -2.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25433409214019775
Epoch 0, Step 4418: train/loss = 0.03298156335949898, train/raw-loss = 0.002099638571962714, train/logprobs = tensor([[ -0.9694, -16.5329],
        [ -7.7116,  -4.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088192343711853
Epoch 0, Step 4419: train/loss = 0.039590418338775635, train/raw-loss = 0.009279941208660603, train/logprobs = tensor([[-1.2876, -8.7214],
        [-9.6387, -2.7318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30310478806495667
Epoch 0, Step 4420: train/loss = 0.032079119235277176, train/raw-loss = 0.0007632490014657378, train/logprobs = tensor([[ -1.1635, -14.7970],
        [ -9.5499,  -4.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31315869092941284
Epoch 0, Step 4421: train/loss = 0.0304713174700737, train/raw-loss = 0.0032513493206351995, train/logprobs = tensor([[ -1.1600, -11.9452],
        [ -8.8177,  -3.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27219969034194946
Epoch 0, Step 4422: train/loss = 0.023473965004086494, train/raw-loss = 0.0007128678262233734, train/logprobs = tensor([[ -1.4496, -11.2660],
        [-10.6267,  -1.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2276109755039215
Epoch 0, Step 4423: train/loss = 0.03134359046816826, train/raw-loss = 0.0029165984597057104, train/logprobs = tensor([[ -0.8300, -10.1231],
        [ -7.2789,  -2.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28426989912986755
Epoch 0, Step 4424: train/loss = 0.15659105777740479, train/raw-loss = 0.13280701637268066, train/logprobs = tensor([[-1.3331, -8.7621],
        [-8.1438, -3.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23784026503562927
Epoch 0, Step 4425: train/loss = 0.028461208567023277, train/raw-loss = 0.000494241074193269, train/logprobs = tensor([[ -0.8363, -17.4111],
        [ -8.1672,  -3.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2796696722507477
Epoch 0, Step 4426: train/loss = 0.027385961264371872, train/raw-loss = 0.0014936561929062009, train/logprobs = tensor([[ -0.9462, -18.1263],
        [ -8.1435,  -5.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589230537414551
Epoch 0, Step 4427: train/loss = 0.02900066412985325, train/raw-loss = 0.0011237052967771888, train/logprobs = tensor([[ -1.0091, -12.4554],
        [ -8.5650,  -2.6765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787695825099945
Epoch 0, Step 4428: train/loss = 0.022814519703388214, train/raw-loss = 0.00032633382943458855, train/logprobs = tensor([[ -1.2539, -17.6279],
        [ -9.9296,  -3.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248818576335907
Epoch 0, Step 4429: train/loss = 0.09296637028455734, train/raw-loss = 0.06699482351541519, train/logprobs = tensor([[-1.1077, -8.8537],
        [-8.2488, -1.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2597154974937439
Epoch 0, Step 4430: train/loss = 0.027381565421819687, train/raw-loss = 0.0024012927897274494, train/logprobs = tensor([[ -1.2628, -10.9321],
        [ -8.4875,  -2.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24980272352695465
Epoch 0, Step 4431: train/loss = 0.02611376717686653, train/raw-loss = 0.0006402591243386269, train/logprobs = tensor([[ -1.1893, -12.0912],
        [ -9.1915,  -2.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547350823879242
Epoch 0, Step 4432: train/loss = 0.02990124747157097, train/raw-loss = 0.0003963329363614321, train/logprobs = tensor([[ -0.9389, -11.1826],
        [ -8.6856,  -2.0407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29504913091659546
Epoch 0, Step 4433: train/loss = 0.030946768820285797, train/raw-loss = 0.001998922089114785, train/logprobs = tensor([[ -1.0891, -15.2875],
        [ -8.4908,  -4.3618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28947848081588745
Epoch 0, Step 4434: train/loss = 0.030358240008354187, train/raw-loss = 0.0007533406605944037, train/logprobs = tensor([[ -1.0834, -15.0334],
        [ -8.5213,  -3.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29604899883270264
Epoch 0, Step 4435: train/loss = 0.03210664168000221, train/raw-loss = 0.007049489766359329, train/logprobs = tensor([[ -1.2159, -11.9842],
        [ -9.0649,  -2.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25057151913642883
Epoch 0, Step 4436: train/loss = 0.026670221239328384, train/raw-loss = 0.0017697864677757025, train/logprobs = tensor([[ -1.1852, -16.3500],
        [ -9.5526,  -4.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2490043342113495
Epoch 0, Step 4437: train/loss = 0.03141244128346443, train/raw-loss = 0.004340966232120991, train/logprobs = tensor([[ -1.1554, -11.5077],
        [ -9.8819,  -2.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707147002220154
Epoch 0, Step 4438: train/loss = 0.02680007368326187, train/raw-loss = 0.0016507593682035804, train/logprobs = tensor([[ -1.0516, -10.5738],
        [ -9.8096,  -2.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514931559562683
Epoch 0, Step 4439: train/loss = 0.029672302305698395, train/raw-loss = 0.0023341835476458073, train/logprobs = tensor([[ -1.0054, -11.9824],
        [ -7.0293,  -2.4978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27338117361068726
Epoch 0, Step 4440: train/loss = 0.028960032388567924, train/raw-loss = 0.00360405957326293, train/logprobs = tensor([[ -1.3524, -10.7444],
        [-10.1842,  -1.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25355976819992065
Epoch 0, Step 4441: train/loss = 0.03272806107997894, train/raw-loss = 0.001949649304151535, train/logprobs = tensor([[ -0.9753, -15.3657],
        [ -7.0068,  -2.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077841103076935
Epoch 0, Step 4442: train/loss = 0.02375156059861183, train/raw-loss = 0.001418923493474722, train/logprobs = tensor([[ -2.0610, -14.4736],
        [ -9.1528,  -4.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22332638502120972
Epoch 0, Step 4443: train/loss = 0.025594539940357208, train/raw-loss = 0.0040084850043058395, train/logprobs = tensor([[ -1.3656, -10.7529],
        [ -8.2554,  -3.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158605456352234
Epoch 0, Step 4444: train/loss = 0.03443830460309982, train/raw-loss = 0.005582252983003855, train/logprobs = tensor([[ -0.7988, -10.6995],
        [ -7.5394,  -2.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28856050968170166
Epoch 0, Step 4445: train/loss = 0.02713962271809578, train/raw-loss = 0.0029758759774267673, train/logprobs = tensor([[-1.5705, -9.2525],
        [-9.3619, -2.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2416374832391739
Epoch 0, Step 4446: train/loss = 0.027063820511102676, train/raw-loss = 0.0024624946527183056, train/logprobs = tensor([[ -0.6519, -16.5114],
        [ -6.6713,  -3.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24601325392723083
Epoch 0, Step 4447: train/loss = 0.030324548482894897, train/raw-loss = 0.0040304651483893394, train/logprobs = tensor([[-1.2565, -9.4115],
        [-7.5917, -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2629408538341522
Epoch 0, Step 4448: train/loss = 0.03072245977818966, train/raw-loss = 0.0004710452922154218, train/logprobs = tensor([[ -0.9276, -12.0308],
        [ -8.2333,  -3.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30251413583755493
Epoch 0, Step 4449: train/loss = 0.025873929262161255, train/raw-loss = 0.003635009517893195, train/logprobs = tensor([[ -1.4715, -10.2300],
        [ -9.8520,  -3.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22238919138908386
Epoch 0, Step 4450: train/loss = 0.02528201974928379, train/raw-loss = 0.0013226399896666408, train/logprobs = tensor([[-1.3939, -9.6832],
        [-9.0012, -2.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395937740802765
Epoch 0, Step 4451: train/loss = 0.02793172001838684, train/raw-loss = 0.0020260526798665524, train/logprobs = tensor([[ -1.0128, -12.1507],
        [ -7.5120,  -3.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590566873550415
Epoch 0, Step 4452: train/loss = 0.028572827577590942, train/raw-loss = 0.0015853352379053831, train/logprobs = tensor([[ -1.3724, -10.6102],
        [ -9.3449,  -2.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698749303817749
Epoch 0, Step 4453: train/loss = 0.03517432138323784, train/raw-loss = 0.008092746138572693, train/logprobs = tensor([[ -0.8450, -10.1950],
        [ -7.6139,  -3.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27081575989723206
Epoch 0, Step 4454: train/loss = 0.046780798584222794, train/raw-loss = 0.018207907676696777, train/logprobs = tensor([[-1.0698, -8.9600],
        [-7.1648, -2.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28572893142700195
Epoch 0, Step 4455: train/loss = 0.02498023584485054, train/raw-loss = 0.0017733684508129954, train/logprobs = tensor([[-1.2965, -9.5890],
        [-9.5798, -1.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23206867277622223
Epoch 0, Step 4456: train/loss = 0.02523624524474144, train/raw-loss = 0.0009672997985035181, train/logprobs = tensor([[ -1.3564, -13.5229],
        [ -8.7195,  -2.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24268946051597595
Epoch 0, Step 4457: train/loss = 0.026321539655327797, train/raw-loss = 0.0012186106760054827, train/logprobs = tensor([[ -1.0218, -15.3870],
        [ -9.5733,  -3.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25102925300598145
Epoch 0, Step 4458: train/loss = 0.026080071926116943, train/raw-loss = 0.0031330217607319355, train/logprobs = tensor([[ -1.2564, -15.6098],
        [ -8.9730,  -5.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22947049140930176
Epoch 0, Step 4459: train/loss = 0.02815599925816059, train/raw-loss = 0.0009159314795397222, train/logprobs = tensor([[ -0.8982, -12.8479],
        [ -8.0310,  -2.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724006772041321
Epoch 0, Step 4460: train/loss = 0.028370250016450882, train/raw-loss = 0.000300593237625435, train/logprobs = tensor([[ -1.3524, -12.5360],
        [-12.0118,  -2.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2806965708732605
Epoch 0, Step 4461: train/loss = 0.024783851578831673, train/raw-loss = 0.000806866679340601, train/logprobs = tensor([[ -1.1335, -12.8990],
        [ -8.3588,  -2.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.239769846200943
Epoch 0, Step 4462: train/loss = 0.03112645074725151, train/raw-loss = 0.001086946576833725, train/logprobs = tensor([[ -1.3219, -12.6369],
        [ -9.5188,  -2.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30039504170417786
Epoch 0, Step 4463: train/loss = 0.025952504947781563, train/raw-loss = 0.0013119434006512165, train/logprobs = tensor([[ -1.2817, -11.2116],
        [ -8.3622,  -2.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24640561640262604
Epoch 0, Step 4464: train/loss = 0.04038335755467415, train/raw-loss = 0.00816459022462368, train/logprobs = tensor([[ -1.1409, -11.1132],
        [ -9.2582,  -3.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3221876621246338
Epoch 0, Step 4465: train/loss = 0.030558157712221146, train/raw-loss = 0.0007424609502777457, train/logprobs = tensor([[ -1.0845, -14.2305],
        [ -8.6813,  -3.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2981569468975067
Epoch 0, Step 4466: train/loss = 0.12027011066675186, train/raw-loss = 0.09529746323823929, train/logprobs = tensor([[-1.3858, -8.9620],
        [-8.8578, -2.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24972647428512573
Epoch 0, Step 4467: train/loss = 0.025239018723368645, train/raw-loss = 0.002027655951678753, train/logprobs = tensor([[ -1.3321, -14.2430],
        [ -7.6315,  -3.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23211364448070526
Epoch 0, Step 4468: train/loss = 0.04269106686115265, train/raw-loss = 0.015619284473359585, train/logprobs = tensor([[ -0.7236, -12.6570],
        [ -6.9055,  -4.9646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707177996635437
Epoch 0, Step 4469: train/loss = 0.02483547292649746, train/raw-loss = 0.0016552993329241872, train/logprobs = tensor([[ -1.0546, -11.4340],
        [ -8.5554,  -1.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23180171847343445
Epoch 0, Step 4470: train/loss = 0.03832961618900299, train/raw-loss = 0.01236499659717083, train/logprobs = tensor([[ -1.1259, -12.4846],
        [ -7.4231,  -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596461772918701
Epoch 0, Step 4471: train/loss = 0.02415895089507103, train/raw-loss = 0.00010415194265078753, train/logprobs = tensor([[ -1.9056, -18.7493],
        [-11.5474,  -3.0456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24054798483848572
Epoch 0, Step 4472: train/loss = 0.02760535106062889, train/raw-loss = 0.0013527368428185582, train/logprobs = tensor([[ -1.4458, -14.5209],
        [-10.2179,  -3.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26252612471580505
Epoch 0, Step 4473: train/loss = 0.029331712052226067, train/raw-loss = 0.0028715496882796288, train/logprobs = tensor([[-1.0603, -9.3110],
        [-7.7641, -1.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26460161805152893
Epoch 0, Step 4474: train/loss = 0.027789633721113205, train/raw-loss = 0.0031520386692136526, train/logprobs = tensor([[ -0.9647, -16.2765],
        [ -6.5022,  -4.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24637596309185028
Epoch 0, Step 4475: train/loss = 0.02630477398633957, train/raw-loss = 0.0007098453352227807, train/logprobs = tensor([[ -1.3638, -11.2796],
        [-10.1823,  -2.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559492886066437
Epoch 0, Step 4476: train/loss = 0.025445565581321716, train/raw-loss = 0.0006976013537496328, train/logprobs = tensor([[ -1.2071, -15.4529],
        [-10.0440,  -2.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2474796324968338
Epoch 0, Step 4477: train/loss = 0.026896625757217407, train/raw-loss = 0.0017890644958242774, train/logprobs = tensor([[ -1.6516, -11.4152],
        [-10.2935,  -3.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510755956172943
Epoch 0, Step 4478: train/loss = 0.027287455275654793, train/raw-loss = 0.00147998274769634, train/logprobs = tensor([[ -0.7826, -16.2581],
        [ -8.2191,  -3.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25807470083236694
Epoch 0, Step 4479: train/loss = 0.027012890204787254, train/raw-loss = 0.00107467919588089, train/logprobs = tensor([[ -1.0067, -14.9625],
        [ -9.2788,  -4.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25938212871551514
Epoch 0, Step 4480: train/loss = 0.026152020320296288, train/raw-loss = 0.0007176636718213558, train/logprobs = tensor([[ -1.0366, -16.8595],
        [ -9.3476,  -4.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25434356927871704
Epoch 0, Step 4481: train/loss = 0.024666480720043182, train/raw-loss = 0.0009984069038182497, train/logprobs = tensor([[ -1.2742, -13.9562],
        [ -9.5734,  -2.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2366807460784912
Epoch 0, Step 4482: train/loss = 0.02954285219311714, train/raw-loss = 0.0020492025651037693, train/logprobs = tensor([[ -1.0939, -14.2677],
        [ -8.4534,  -4.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749364972114563
Epoch 0, Step 4483: train/loss = 0.02350001223385334, train/raw-loss = 0.001537442789413035, train/logprobs = tensor([[ -1.2258, -17.9622],
        [ -7.8523,  -5.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21962566673755646
Epoch 0, Step 4484: train/loss = 0.028087977319955826, train/raw-loss = 0.0009638232295401394, train/logprobs = tensor([[ -0.7335, -12.0142],
        [ -7.3874,  -2.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27124154567718506
Epoch 0, Step 4485: train/loss = 0.06144831329584122, train/raw-loss = 0.03588404133915901, train/logprobs = tensor([[ -1.8060, -10.9261],
        [-10.1425,  -4.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25564271211624146
Epoch 0, Step 4486: train/loss = 0.024850573390722275, train/raw-loss = 0.00489618256688118, train/logprobs = tensor([[ -1.3241, -13.9142],
        [ -7.9265,  -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19954390823841095
Epoch 0, Step 4487: train/loss = 0.03029048442840576, train/raw-loss = 0.001628030207939446, train/logprobs = tensor([[ -1.0632, -12.1715],
        [ -9.0999,  -3.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286624550819397
Epoch 0, Step 4488: train/loss = 0.02550320327281952, train/raw-loss = 0.0018139801686629653, train/logprobs = tensor([[ -1.1590, -16.3257],
        [ -8.9705,  -4.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368922233581543
Epoch 0, Step 4489: train/loss = 0.028577089309692383, train/raw-loss = 0.001981203444302082, train/logprobs = tensor([[ -0.7742, -13.9129],
        [ -8.3879,  -3.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659588158130646
Epoch 0, Step 4490: train/loss = 0.02790268510580063, train/raw-loss = 0.000385554158128798, train/logprobs = tensor([[ -1.0296, -14.6262],
        [ -9.5498,  -3.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27517130970954895
Epoch 0, Step 4491: train/loss = 0.03255899250507355, train/raw-loss = 0.000665394589304924, train/logprobs = tensor([[ -1.1978, -15.1751],
        [ -9.3060,  -3.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31893596053123474
Epoch 0, Step 4492: train/loss = 0.02830614522099495, train/raw-loss = 0.000885808258317411, train/logprobs = tensor([[-1.2644, -9.8820],
        [-9.1946, -2.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742033302783966
Epoch 0, Step 4493: train/loss = 0.02621576189994812, train/raw-loss = 0.0003084319469053298, train/logprobs = tensor([[ -1.0407, -13.4803],
        [-10.2264,  -3.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25907325744628906
Epoch 0, Step 4494: train/loss = 0.024706196039915085, train/raw-loss = 0.0014667653013020754, train/logprobs = tensor([[ -1.0747, -10.8521],
        [ -7.3215,  -1.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2323942929506302
Epoch 0, Step 4495: train/loss = 0.027982953935861588, train/raw-loss = 0.0033262893557548523, train/logprobs = tensor([[ -1.1705, -10.7564],
        [ -7.8854,  -4.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24656662344932556
Epoch 0, Step 4496: train/loss = 0.025410132482647896, train/raw-loss = 0.001024747733026743, train/logprobs = tensor([[ -1.0844, -12.5240],
        [ -9.1735,  -3.4700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438538372516632
Epoch 0, Step 4497: train/loss = 0.028524290770292282, train/raw-loss = 0.005251583643257618, train/logprobs = tensor([[ -1.7689, -16.4426],
        [-10.0140,  -5.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23272705078125
Epoch 0, Step 4498: train/loss = 0.027086680755019188, train/raw-loss = 0.001954661449417472, train/logprobs = tensor([[ -0.6838, -15.4764],
        [ -6.4311,  -3.5391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513201832771301
Epoch 0, Step 4499: train/loss = 0.04765048250555992, train/raw-loss = 0.02251036837697029, train/logprobs = tensor([[ -0.9546, -13.8294],
        [ -7.1522,  -3.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514011263847351
Epoch 0, Step 4500: train/loss = 0.029644519090652466, train/raw-loss = 0.004058269318193197, train/logprobs = tensor([[ -1.1800, -14.6554],
        [ -8.1193,  -3.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558625042438507
Epoch 0, Step 4501: train/loss = 0.025584276765584946, train/raw-loss = 0.0007294157985597849, train/logprobs = tensor([[ -1.3196, -13.3839],
        [-10.1841,  -3.5938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24854862689971924
Epoch 0, Step 4502: train/loss = 0.024517076089978218, train/raw-loss = 0.0018288069404661655, train/logprobs = tensor([[ -1.3639, -11.7411],
        [-10.7778,  -1.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2268826812505722
Epoch 0, Step 4503: train/loss = 0.030565747991204262, train/raw-loss = 0.0019143089884892106, train/logprobs = tensor([[ -0.5962, -11.1938],
        [ -7.0980,  -2.6564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28651440143585205
Epoch 0, Step 4504: train/loss = 0.02683928608894348, train/raw-loss = 0.002619934268295765, train/logprobs = tensor([[ -0.7954, -10.8536],
        [ -6.9742,  -2.4004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24219349026679993
Epoch 0, Step 4505: train/loss = 0.030038276687264442, train/raw-loss = 0.0022299736738204956, train/logprobs = tensor([[ -0.8299, -15.1358],
        [ -7.1525,  -4.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27808302640914917
Epoch 0, Step 4506: train/loss = 0.02706986479461193, train/raw-loss = 0.0010506187099963427, train/logprobs = tensor([[ -1.1326, -11.8956],
        [ -8.6473,  -3.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601924240589142
Epoch 0, Step 4507: train/loss = 0.022008396685123444, train/raw-loss = 0.0011228432413190603, train/logprobs = tensor([[ -1.4858, -15.7707],
        [ -8.4728,  -2.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.208855539560318
Epoch 0, Step 4508: train/loss = 0.02754766121506691, train/raw-loss = 0.004259652458131313, train/logprobs = tensor([[-1.2889, -9.6165],
        [-8.2859, -2.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23288007080554962
Epoch 0, Step 4509: train/loss = 0.02971164509654045, train/raw-loss = 0.00356082571670413, train/logprobs = tensor([[ -1.1928, -11.5834],
        [ -8.4704,  -3.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26150819659233093
Epoch 0, Step 4510: train/loss = 0.026262735947966576, train/raw-loss = 0.0017178604612126946, train/logprobs = tensor([[ -0.9980, -12.6440],
        [ -8.2303,  -3.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2454487681388855
Epoch 0, Step 4511: train/loss = 0.034469131380319595, train/raw-loss = 0.004679680801928043, train/logprobs = tensor([[ -1.5129, -15.4740],
        [ -9.0780,  -2.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29789453744888306
Epoch 0, Step 4512: train/loss = 0.17212149500846863, train/raw-loss = 0.14550065994262695, train/logprobs = tensor([[ -1.2514, -11.0893],
        [ -8.3852,  -3.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662084102630615
Epoch 0, Step 4513: train/loss = 0.022611983120441437, train/raw-loss = 0.0004291145596653223, train/logprobs = tensor([[ -0.8444, -15.2714],
        [ -8.6773,  -3.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22182869911193848
Epoch 0, Step 4514: train/loss = 0.02507229521870613, train/raw-loss = 0.0018176304874941707, train/logprobs = tensor([[ -1.2656, -12.4518],
        [ -8.7009,  -2.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23254665732383728
Epoch 0, Step 4515: train/loss = 0.028471315279603004, train/raw-loss = 0.0009054454858414829, train/logprobs = tensor([[-1.5831, -9.7580],
        [-9.8008, -1.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2756586968898773
Epoch 0, Step 4516: train/loss = 0.02857562154531479, train/raw-loss = 0.0031222738325595856, train/logprobs = tensor([[ -0.7725, -11.4050],
        [ -6.8641,  -2.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25453346967697144
Epoch 0, Step 4517: train/loss = 0.02612084522843361, train/raw-loss = 0.0019304209854453802, train/logprobs = tensor([[ -1.1339, -10.0466],
        [ -8.2016,  -2.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24190422892570496
Epoch 0, Step 4518: train/loss = 0.027507303282618523, train/raw-loss = 0.0015530104283243418, train/logprobs = tensor([[ -1.0717, -18.0170],
        [ -8.4655,  -4.6875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25954294204711914
Epoch 0, Step 4519: train/loss = 0.02921275421977043, train/raw-loss = 0.002594989025965333, train/logprobs = tensor([[ -1.0169, -10.6129],
        [ -9.0226,  -3.3145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26617762446403503
Epoch 0, Step 4520: train/loss = 0.02740877866744995, train/raw-loss = 0.000848948082420975, train/logprobs = tensor([[ -0.7785, -15.6167],
        [ -8.5915,  -3.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655982971191406
Epoch 0, Step 4521: train/loss = 0.024637378752231598, train/raw-loss = 0.0004629946779459715, train/logprobs = tensor([[ -1.2648, -15.6352],
        [ -9.7058,  -3.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24174383282661438
Epoch 0, Step 4522: train/loss = 0.026647895574569702, train/raw-loss = 0.000258824962656945, train/logprobs = tensor([[ -1.2177, -18.7231],
        [ -9.7593,  -4.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26389071345329285
Epoch 0, Step 4523: train/loss = 0.02889208123087883, train/raw-loss = 0.0023347230162471533, train/logprobs = tensor([[ -0.7396, -11.9355],
        [ -6.8566,  -3.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655735909938812
Epoch 0, Step 4524: train/loss = 0.02744319848716259, train/raw-loss = 0.0021470077335834503, train/logprobs = tensor([[ -0.7971, -14.6926],
        [ -7.6218,  -3.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529619038105011
Epoch 0, Step 4525: train/loss = 0.04251665249466896, train/raw-loss = 0.01775422692298889, train/logprobs = tensor([[-0.8307, -8.2270],
        [-8.1108, -1.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24762429296970367
Epoch 0, Step 4526: train/loss = 0.025693420320749283, train/raw-loss = 0.0006654555327259004, train/logprobs = tensor([[ -1.1769, -12.4262],
        [ -8.2055,  -2.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25027963519096375
Epoch 0, Step 4527: train/loss = 0.02878233604133129, train/raw-loss = 0.006073176860809326, train/logprobs = tensor([[ -0.7181, -10.8673],
        [ -6.1970,  -1.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22709158062934875
Epoch 0, Step 4528: train/loss = 0.03513042628765106, train/raw-loss = 0.0072027998976409435, train/logprobs = tensor([[ -1.1780, -11.5816],
        [ -9.5207,  -2.3164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792762815952301
Epoch 0, Step 4529: train/loss = 0.04781810939311981, train/raw-loss = 0.022553861141204834, train/logprobs = tensor([[-1.1243, -8.8380],
        [-9.3895, -3.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526424825191498
Epoch 0, Step 4530: train/loss = 0.03279762342572212, train/raw-loss = 0.003725716844201088, train/logprobs = tensor([[ -1.2830,  -8.7162],
        [-10.9120,  -2.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29071903228759766
Epoch 0, Step 4531: train/loss = 0.025648504495620728, train/raw-loss = 0.0018402650021016598, train/logprobs = tensor([[ -1.0748, -13.8136],
        [ -8.4202,  -1.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380823791027069
Epoch 0, Step 4532: train/loss = 0.02539374865591526, train/raw-loss = 0.0012562001356855035, train/logprobs = tensor([[ -0.6553, -15.3215],
        [ -7.3666,  -3.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24137547612190247
Epoch 0, Step 4533: train/loss = 0.028230588883161545, train/raw-loss = 0.004718374460935593, train/logprobs = tensor([[ -0.6081, -10.0519],
        [ -5.8033,  -2.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23512214422225952
Epoch 0, Step 4534: train/loss = 0.032181501388549805, train/raw-loss = 0.010056962259113789, train/logprobs = tensor([[ -1.0434, -11.9647],
        [ -6.3973,  -4.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22124536335468292
Epoch 0, Step 4535: train/loss = 0.02596428245306015, train/raw-loss = 0.0012744206469506025, train/logprobs = tensor([[ -0.8416, -11.4155],
        [ -8.3354,  -3.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468986213207245
Epoch 0, Step 4536: train/loss = 0.03339704871177673, train/raw-loss = 0.007791548036038876, train/logprobs = tensor([[ -1.1328, -10.2433],
        [ -8.7313,  -2.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2560550272464752
Epoch 0, Step 4537: train/loss = 0.026452986523509026, train/raw-loss = 0.0007930601132102311, train/logprobs = tensor([[ -0.9867, -12.0120],
        [ -7.9447,  -2.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565992474555969
Epoch 0, Step 4538: train/loss = 0.02825244516134262, train/raw-loss = 0.0009647076949477196, train/logprobs = tensor([[ -1.1676, -16.3002],
        [ -8.6787,  -3.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27287736535072327
Epoch 0, Step 4539: train/loss = 0.025862209498882294, train/raw-loss = 0.0006973737035878003, train/logprobs = tensor([[ -0.8343, -12.4698],
        [ -8.3835,  -2.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25164833664894104
Epoch 0, Step 4540: train/loss = 0.029361974447965622, train/raw-loss = 0.004486449062824249, train/logprobs = tensor([[ -0.9747, -13.1703],
        [ -9.5844,  -3.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24875523149967194
Epoch 0, Step 4541: train/loss = 0.10844184458255768, train/raw-loss = 0.08088397234678268, train/logprobs = tensor([[ -1.5645,  -8.2333],
        [-10.9817,  -3.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27557867765426636
Epoch 0, Step 4542: train/loss = 0.04866890236735344, train/raw-loss = 0.025515981018543243, train/logprobs = tensor([[ -0.8141, -11.4807],
        [ -6.3901,  -3.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23152923583984375
Epoch 0, Step 4543: train/loss = 0.02612227573990822, train/raw-loss = 0.0009350163745693862, train/logprobs = tensor([[ -1.1055, -11.4230],
        [ -8.8895,  -2.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25187259912490845
Epoch 0, Step 4544: train/loss = 0.028190068900585175, train/raw-loss = 0.0016117754857987165, train/logprobs = tensor([[ -1.0357, -11.2407],
        [ -7.9169,  -3.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657829225063324
Epoch 0, Step 4545: train/loss = 0.027828399091959, train/raw-loss = 0.0005260641919448972, train/logprobs = tensor([[ -0.6866, -17.0733],
        [ -8.0193,  -2.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730233073234558
Epoch 0, Step 4546: train/loss = 0.025631243363022804, train/raw-loss = 0.0007375975837931037, train/logprobs = tensor([[ -1.2499, -11.9387],
        [ -9.0339,  -1.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489364743232727
Epoch 0, Step 4547: train/loss = 0.029711246490478516, train/raw-loss = 0.005729652475565672, train/logprobs = tensor([[ -1.3677, -14.4294],
        [ -9.7603,  -4.0188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23981592059135437
Epoch 0, Step 4548: train/loss = 0.026321209967136383, train/raw-loss = 0.0006117566954344511, train/logprobs = tensor([[ -1.6934,  -9.2641],
        [-14.2174,  -1.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25709453225135803
Epoch 0, Step 4549: train/loss = 0.024868881329894066, train/raw-loss = 0.0005681603215634823, train/logprobs = tensor([[ -1.0625, -18.5681],
        [ -9.6111,  -3.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24300719797611237
Epoch 0, Step 4550: train/loss = 0.029990149661898613, train/raw-loss = 0.0010239541297778487, train/logprobs = tensor([[ -1.0558, -12.9408],
        [ -8.5590,  -3.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896619439125061
Epoch 0, Step 4551: train/loss = 0.02945915050804615, train/raw-loss = 0.001391975674778223, train/logprobs = tensor([[ -1.2241, -12.9240],
        [ -9.2154,  -2.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28067174553871155
Epoch 0, Step 4552: train/loss = 0.02622373402118683, train/raw-loss = 0.0006460646400228143, train/logprobs = tensor([[ -1.2361, -11.4004],
        [ -9.4368,  -2.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25577667355537415
Epoch 0, Step 4553: train/loss = 0.025960667058825493, train/raw-loss = 0.0006043086759746075, train/logprobs = tensor([[ -1.5475, -18.2847],
        [ -9.6261,  -3.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535635828971863
Epoch 0, Step 4554: train/loss = 0.025863250717520714, train/raw-loss = 0.006208755075931549, train/logprobs = tensor([[ -0.9164, -11.5725],
        [ -7.3824,  -2.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19654496014118195
Epoch 0, Step 4555: train/loss = 0.029388202354311943, train/raw-loss = 0.004820596892386675, train/logprobs = tensor([[ -0.9276, -13.7736],
        [ -6.9043,  -2.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24567605555057526
Epoch 0, Step 4556: train/loss = 0.02788601815700531, train/raw-loss = 0.001821541809476912, train/logprobs = tensor([[ -1.2210, -13.4398],
        [ -9.6720,  -4.5289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260644793510437
Epoch 0, Step 4557: train/loss = 0.0288884025067091, train/raw-loss = 0.0026725230272859335, train/logprobs = tensor([[ -0.8788, -16.6877],
        [ -7.3756,  -3.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621587812900543
Epoch 0, Step 4558: train/loss = 0.02380099520087242, train/raw-loss = 0.0027812523767352104, train/logprobs = tensor([[ -0.8919, -16.6946],
        [ -7.1928,  -2.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21019744873046875
Epoch 0, Step 4559: train/loss = 0.05096778646111488, train/raw-loss = 0.025416817516088486, train/logprobs = tensor([[-1.0400, -8.9742],
        [-8.0935, -1.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25550970435142517
Epoch 0, Step 4560: train/loss = 0.02770567312836647, train/raw-loss = 0.005694780498743057, train/logprobs = tensor([[ -1.1406, -14.1539],
        [ -8.2650,  -2.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22010892629623413
Epoch 0, Step 4561: train/loss = 0.03264886885881424, train/raw-loss = 0.008731383830308914, train/logprobs = tensor([[ -1.4547, -17.9678],
        [ -8.0119,  -3.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23917484283447266
Epoch 0, Step 4562: train/loss = 0.025391418486833572, train/raw-loss = 0.0009269111324101686, train/logprobs = tensor([[ -1.2004, -14.9881],
        [ -9.6137,  -3.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24464507400989532
Epoch 0, Step 4563: train/loss = 0.027716048061847687, train/raw-loss = 0.00628097215667367, train/logprobs = tensor([[ -0.9192, -11.2528],
        [ -6.9365,  -2.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21435075998306274
Epoch 0, Step 4564: train/loss = 0.02826762944459915, train/raw-loss = 0.0011568381451070309, train/logprobs = tensor([[ -1.1017, -15.3022],
        [ -8.4152,  -3.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27110791206359863
Epoch 0, Step 4565: train/loss = 0.029315151274204254, train/raw-loss = 0.0016021346673369408, train/logprobs = tensor([[ -1.0992, -18.1183],
        [ -8.0215,  -5.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2771301865577698
Epoch 0, Step 4566: train/loss = 0.026495974510908127, train/raw-loss = 0.0015837951796129346, train/logprobs = tensor([[ -1.1782, -11.5030],
        [ -8.6167,  -2.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2491217851638794
Epoch 0, Step 4567: train/loss = 0.025370437651872635, train/raw-loss = 0.00039101799484342337, train/logprobs = tensor([[ -1.7129, -11.1435],
        [-11.5339,  -2.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24979418516159058
Epoch 0, Step 4568: train/loss = 0.032167352735996246, train/raw-loss = 0.00738878920674324, train/logprobs = tensor([[ -1.1845, -11.2080],
        [ -8.5940,  -2.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24778565764427185
Epoch 0, Step 4569: train/loss = 0.029379628598690033, train/raw-loss = 0.0005570617504417896, train/logprobs = tensor([[ -1.6054, -13.3783],
        [-10.6015,  -2.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2882256507873535
Epoch 0, Step 4570: train/loss = 0.03023328259587288, train/raw-loss = 0.0006977558368816972, train/logprobs = tensor([[ -0.8242, -15.2424],
        [ -7.7522,  -3.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29535526037216187
Epoch 0, Step 4571: train/loss = 0.02546808123588562, train/raw-loss = 0.0006179710617288947, train/logprobs = tensor([[ -1.2501, -12.5108],
        [ -9.3310,  -3.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24850109219551086
Epoch 0, Step 4572: train/loss = 0.029597342014312744, train/raw-loss = 0.0016509145498275757, train/logprobs = tensor([[ -1.4712, -11.8821],
        [-10.1737,  -3.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2794643044471741
Epoch 0, Step 4573: train/loss = 0.02928496152162552, train/raw-loss = 0.003713069250807166, train/logprobs = tensor([[-1.1069, -7.9843],
        [-8.7384, -1.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557189166545868
Epoch 0, Step 4574: train/loss = 0.025648638606071472, train/raw-loss = 0.0007145584095269442, train/logprobs = tensor([[ -0.7601, -17.4734],
        [ -7.5114,  -2.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24934080243110657
Epoch 0, Step 4575: train/loss = 0.027808520942926407, train/raw-loss = 0.002099705161526799, train/logprobs = tensor([[ -1.4438, -13.5079],
        [ -9.7607,  -3.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25708815455436707
Epoch 0, Step 4576: train/loss = 0.029985424131155014, train/raw-loss = 0.0004254407831467688, train/logprobs = tensor([[ -1.1051, -14.7523],
        [ -9.6519,  -2.5912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955998182296753
Epoch 0, Step 4577: train/loss = 0.027016587555408478, train/raw-loss = 0.001282500452362001, train/logprobs = tensor([[ -1.5893, -12.9054],
        [-10.6989,  -2.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25734084844589233
Epoch 0, Step 4578: train/loss = 0.026590915396809578, train/raw-loss = 0.0005067714373581111, train/logprobs = tensor([[ -0.9227, -12.3821],
        [ -8.7779,  -2.0673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260841429233551
Epoch 0, Step 4579: train/loss = 0.028041565790772438, train/raw-loss = 0.0026869000867009163, train/logprobs = tensor([[ -1.2617, -16.2108],
        [ -8.1747,  -3.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25354665517807007
Epoch 0, Step 4580: train/loss = 0.02824065461754799, train/raw-loss = 0.0015907082706689835, train/logprobs = tensor([[ -0.6877, -10.9495],
        [ -6.8101,  -2.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26649945974349976
Epoch 0, Step 4581: train/loss = 0.027681393548846245, train/raw-loss = 0.0015925567131489515, train/logprobs = tensor([[ -1.0171, -16.7705],
        [ -7.9513,  -3.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26088836789131165
Epoch 0, Step 4582: train/loss = 0.028310945257544518, train/raw-loss = 0.0012334001949056983, train/logprobs = tensor([[ -1.3286, -15.9044],
        [ -9.9228,  -3.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707754373550415
Epoch 0, Step 4583: train/loss = 0.027588121592998505, train/raw-loss = 0.0016011784318834543, train/logprobs = tensor([[ -1.2971, -11.1861],
        [-10.2836,  -2.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25986945629119873
Epoch 0, Step 4584: train/loss = 0.03490474075078964, train/raw-loss = 0.008826985023915768, train/logprobs = tensor([[ -0.8587, -14.2761],
        [ -7.5403,  -3.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607775330543518
Epoch 0, Step 4585: train/loss = 0.032330065965652466, train/raw-loss = 0.010259833186864853, train/logprobs = tensor([[-0.8609, -8.4638],
        [-7.8112, -1.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22070235013961792
Epoch 0, Step 4586: train/loss = 0.028809212148189545, train/raw-loss = 0.00032278895378112793, train/logprobs = tensor([[ -0.9264, -13.6507],
        [ -9.3005,  -3.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284864217042923
Epoch 0, Step 4587: train/loss = 0.029451679438352585, train/raw-loss = 0.00108253990765661, train/logprobs = tensor([[ -0.9515, -11.8063],
        [ -9.1119,  -2.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28369140625
Epoch 0, Step 4588: train/loss = 0.029979193583130836, train/raw-loss = 0.004722830839455128, train/logprobs = tensor([[ -0.5949, -13.9220],
        [ -5.5504,  -3.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25256362557411194
Epoch 0, Step 4589: train/loss = 0.02825283259153366, train/raw-loss = 0.0005125528550706804, train/logprobs = tensor([[ -1.2249, -15.4958],
        [-10.5294,  -4.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2774028182029724
Epoch 0, Step 4590: train/loss = 0.024640358984470367, train/raw-loss = 0.0012068793876096606, train/logprobs = tensor([[ -0.8820, -13.4597],
        [ -8.1828,  -2.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.234334796667099
Epoch 0, Step 4591: train/loss = 0.031651388853788376, train/raw-loss = 0.005910833366215229, train/logprobs = tensor([[ -1.4123, -10.3126],
        [-10.7623,  -2.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25740551948547363
Epoch 0, Step 4592: train/loss = 0.03178022801876068, train/raw-loss = 0.001424038433469832, train/logprobs = tensor([[-1.0206, -9.3576],
        [-7.3182, -1.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035619258880615
Epoch 0, Step 4593: train/loss = 0.0255872905254364, train/raw-loss = 0.0008979106787592173, train/logprobs = tensor([[ -1.3397, -15.6618],
        [ -8.9304,  -3.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468937784433365
Epoch 0, Step 4594: train/loss = 0.029831063002347946, train/raw-loss = 0.0024742954410612583, train/logprobs = tensor([[ -0.8444, -10.5193],
        [ -7.4699,  -2.8144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27356767654418945
Epoch 0, Step 4595: train/loss = 0.02937939763069153, train/raw-loss = 0.0014566279714927077, train/logprobs = tensor([[ -1.4940, -12.9172],
        [-10.5689,  -2.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27922770380973816
Epoch 0, Step 4596: train/loss = 0.02648521587252617, train/raw-loss = 0.0006158017204143107, train/logprobs = tensor([[ -1.4020, -15.4380],
        [ -9.9535,  -3.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2586941421031952
Epoch 0, Step 4597: train/loss = 0.027922026813030243, train/raw-loss = 0.004804964177310467, train/logprobs = tensor([[ -0.8037, -11.8347],
        [ -6.5847,  -2.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23117059469223022
Epoch 0, Step 4598: train/loss = 0.12362084537744522, train/raw-loss = 0.0938137024641037, train/logprobs = tensor([[ -1.1853, -10.4756],
        [ -9.1736,  -2.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2980715334415436
Epoch 0, Step 4599: train/loss = 0.031575530767440796, train/raw-loss = 0.006315393839031458, train/logprobs = tensor([[ -1.1577, -13.4165],
        [ -8.1779,  -4.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25260135531425476
Epoch 0, Step 4600: train/loss = 0.02710776962339878, train/raw-loss = 8.235859422711655e-05, train/logprobs = tensor([[ -1.6223, -13.5119],
        [-12.6238,  -2.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27025410532951355
Epoch 0, Step 4601: train/loss = 0.02553490363061428, train/raw-loss = 0.000719035102520138, train/logprobs = tensor([[ -0.9632, -14.0280],
        [ -7.8746,  -2.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24815869331359863
Epoch 0, Step 4602: train/loss = 0.02870143949985504, train/raw-loss = 0.0010967266280204058, train/logprobs = tensor([[ -0.9146, -15.1395],
        [ -8.6505,  -3.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27604714035987854
Epoch 0, Step 4603: train/loss = 0.026219651103019714, train/raw-loss = 0.0011822638334706426, train/logprobs = tensor([[ -1.4415, -12.3739],
        [ -8.8504,  -2.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25037387013435364
Epoch 0, Step 4604: train/loss = 0.031318385154008865, train/raw-loss = 0.0030708464328199625, train/logprobs = tensor([[ -1.1419, -10.8337],
        [ -9.4933,  -2.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28247538208961487
Epoch 0, Step 4605: train/loss = 0.031634096056222916, train/raw-loss = 0.0022669921163469553, train/logprobs = tensor([[ -1.0299, -10.2637],
        [ -8.9713,  -1.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29367101192474365
Epoch 0, Step 4606: train/loss = 0.027577823027968407, train/raw-loss = 0.0016429814277216792, train/logprobs = tensor([[ -1.5221, -10.0310],
        [ -9.2040,  -1.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25934839248657227
Epoch 0, Step 4607: train/loss = 0.024369483813643456, train/raw-loss = 0.001002033706754446, train/logprobs = tensor([[-0.9172, -9.9761],
        [-8.3760, -2.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23367449641227722
Epoch 0, Step 4608: train/loss = 0.026893697679042816, train/raw-loss = 0.0015685419784858823, train/logprobs = tensor([[ -0.9585, -12.4399],
        [ -7.6738,  -2.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532515227794647
Epoch 0, Step 4609: train/loss = 0.02808155119419098, train/raw-loss = 0.0007350469240918756, train/logprobs = tensor([[ -0.9986, -12.4285],
        [ -8.2439,  -2.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27346503734588623
Epoch 0, Step 4610: train/loss = 0.03231026232242584, train/raw-loss = 0.003853500820696354, train/logprobs = tensor([[-1.7674, -8.7625],
        [-9.7666, -2.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28456759452819824
Epoch 0, Step 4611: train/loss = 0.02928120270371437, train/raw-loss = 0.005785489920526743, train/logprobs = tensor([[ -0.8960, -14.5437],
        [ -7.0622,  -3.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23495709896087646
Epoch 0, Step 4612: train/loss = 0.10457271337509155, train/raw-loss = 0.07784987986087799, train/logprobs = tensor([[ -0.9130, -10.1650],
        [ -7.4937,  -3.0992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26722824573516846
Epoch 0, Step 4613: train/loss = 0.022328993305563927, train/raw-loss = 0.0006190941203385592, train/logprobs = tensor([[ -1.1344, -20.4204],
        [ -9.7455,  -5.3836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21709896624088287
Epoch 0, Step 4614: train/loss = 0.025585472583770752, train/raw-loss = 0.0008256490109488368, train/logprobs = tensor([[ -0.8860, -14.3939],
        [ -7.7552,  -3.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24759823083877563
Epoch 0, Step 4615: train/loss = 0.033399391919374466, train/raw-loss = 0.0068086180835962296, train/logprobs = tensor([[-0.9924, -9.7898],
        [-7.3243, -2.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26590776443481445
Epoch 0, Step 4616: train/loss = 0.026609040796756744, train/raw-loss = 0.0013820723397657275, train/logprobs = tensor([[ -1.0601, -13.2667],
        [ -7.8460,  -3.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522696852684021
Epoch 0, Step 4617: train/loss = 0.026042433455586433, train/raw-loss = 0.0007468012627214193, train/logprobs = tensor([[ -1.0091, -14.5816],
        [ -9.4875,  -3.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529563307762146
Epoch 0, Step 4618: train/loss = 0.02801702357828617, train/raw-loss = 0.0011966964229941368, train/logprobs = tensor([[ -1.0816, -16.6984],
        [ -8.3763,  -5.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682032585144043
Epoch 0, Step 4619: train/loss = 0.030894633382558823, train/raw-loss = 0.0012763977283611894, train/logprobs = tensor([[ -0.9644, -13.3865],
        [ -8.3993,  -1.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961823344230652
Epoch 0, Step 4620: train/loss = 0.03587631508708, train/raw-loss = 0.009248035959899426, train/logprobs = tensor([[ -1.1506, -16.7367],
        [ -9.5771,  -3.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662827670574188
Epoch 0, Step 4621: train/loss = 0.026797719299793243, train/raw-loss = 0.001124557456932962, train/logprobs = tensor([[ -1.1299, -16.5287],
        [ -7.8674,  -2.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25673162937164307
Epoch 0, Step 4622: train/loss = 0.028666645288467407, train/raw-loss = 0.0036074542440474033, train/logprobs = tensor([[ -1.2210, -12.6495],
        [ -7.0357,  -2.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505919337272644
Epoch 0, Step 4623: train/loss = 0.03305213898420334, train/raw-loss = 0.007098079659044743, train/logprobs = tensor([[ -1.0556, -11.8327],
        [ -7.8540,  -2.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2595405876636505
Epoch 0, Step 4624: train/loss = 0.028910169377923012, train/raw-loss = 0.0008629179792478681, train/logprobs = tensor([[ -1.1578, -15.4137],
        [ -8.0460,  -3.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804724872112274
Epoch 0, Step 4625: train/loss = 0.03137825429439545, train/raw-loss = 0.00113667082041502, train/logprobs = tensor([[ -0.6527, -11.0487],
        [ -7.5578,  -2.3688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3024158477783203
Epoch 0, Step 4626: train/loss = 0.024123257026076317, train/raw-loss = 0.0006507570506073534, train/logprobs = tensor([[ -1.6818, -11.7223],
        [-10.6114,  -2.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347249835729599
Epoch 0, Step 4627: train/loss = 0.026450254023075104, train/raw-loss = 0.0011113440850749612, train/logprobs = tensor([[ -0.6964, -17.5559],
        [ -7.2504,  -3.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533890902996063
Epoch 0, Step 4628: train/loss = 0.026039348915219307, train/raw-loss = 0.0012607825919985771, train/logprobs = tensor([[ -1.0245, -17.6244],
        [ -7.0768,  -3.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24778565764427185
Epoch 0, Step 4629: train/loss = 0.03130442649126053, train/raw-loss = 0.0077763996087014675, train/logprobs = tensor([[ -0.8602, -10.4130],
        [ -6.9020,  -2.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23528027534484863
Epoch 0, Step 4630: train/loss = 0.02898019179701805, train/raw-loss = 0.0055831437930464745, train/logprobs = tensor([[ -1.1612, -10.0982],
        [ -7.9339,  -1.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23397046327590942
Epoch 0, Step 4631: train/loss = 0.027818217873573303, train/raw-loss = 0.0046613262966275215, train/logprobs = tensor([[ -1.1656, -14.0410],
        [ -9.8468,  -3.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23156890273094177
Epoch 0, Step 4632: train/loss = 0.025896191596984863, train/raw-loss = 0.0015602416824549437, train/logprobs = tensor([[ -0.9830, -11.2206],
        [ -7.7129,  -1.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2433595061302185
Epoch 0, Step 4633: train/loss = 0.027307506650686264, train/raw-loss = 0.0006407651235349476, train/logprobs = tensor([[ -1.5783, -12.5167],
        [-10.9320,  -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2666674256324768
Epoch 0, Step 4634: train/loss = 0.02484925650060177, train/raw-loss = 0.0008780880598351359, train/logprobs = tensor([[ -1.1972, -12.8906],
        [ -9.0630,  -3.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2397116720676422
Epoch 0, Step 4635: train/loss = 0.024996183812618256, train/raw-loss = 0.00024916609982028604, train/logprobs = tensor([[ -1.3064, -13.3731],
        [ -9.3963,  -2.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2474701851606369
Epoch 0, Step 4636: train/loss = 0.03209301456809044, train/raw-loss = 0.0004672373761422932, train/logprobs = tensor([[ -1.0686, -11.3196],
        [-11.3366,  -1.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3162577748298645
Epoch 0, Step 4637: train/loss = 0.03273697942495346, train/raw-loss = 0.0037460061721503735, train/logprobs = tensor([[ -1.6562, -11.3277],
        [-10.1512,  -2.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2899097204208374
Epoch 0, Step 4638: train/loss = 0.029534943401813507, train/raw-loss = 0.0020065857097506523, train/logprobs = tensor([[ -0.8666, -10.0336],
        [ -6.9020,  -2.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752835750579834
Epoch 0, Step 4639: train/loss = 0.030119266360998154, train/raw-loss = 0.0029597245156764984, train/logprobs = tensor([[ -0.9797, -11.8692],
        [ -6.7434,  -2.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27159541845321655
Epoch 0, Step 4640: train/loss = 0.025728607550263405, train/raw-loss = 0.0012492933310568333, train/logprobs = tensor([[ -1.0562, -12.8182],
        [ -8.7744,  -2.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2447931468486786
Epoch 0, Step 4641: train/loss = 0.02869318425655365, train/raw-loss = 0.0019498609472066164, train/logprobs = tensor([[ -0.7589, -10.4671],
        [ -7.0214,  -2.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267433226108551
Epoch 0, Step 4642: train/loss = 0.030760498717427254, train/raw-loss = 0.005183973349630833, train/logprobs = tensor([[ -1.1497, -17.2275],
        [ -7.3114,  -3.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25576525926589966
Epoch 0, Step 4643: train/loss = 0.026039686053991318, train/raw-loss = 0.0006822841241955757, train/logprobs = tensor([[ -1.1741, -17.6404],
        [ -8.1530,  -3.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253574013710022
Epoch 0, Step 4644: train/loss = 0.035529494285583496, train/raw-loss = 0.01118416991084814, train/logprobs = tensor([[ -1.8876, -10.3860],
        [-10.7447,  -1.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2434532344341278
Epoch 0, Step 4645: train/loss = 0.10094562917947769, train/raw-loss = 0.07756727933883667, train/logprobs = tensor([[ -1.0625, -14.5118],
        [ -8.0737,  -4.4217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23378346860408783
Epoch 0, Step 4646: train/loss = 0.02817424014210701, train/raw-loss = 0.001099353306926787, train/logprobs = tensor([[ -1.0669, -14.8917],
        [ -7.8112,  -4.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2707488536834717
Epoch 0, Step 4647: train/loss = 0.030050601810216904, train/raw-loss = 0.000529201643075794, train/logprobs = tensor([[ -1.1761, -11.0859],
        [-10.7241,  -1.3531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952139973640442
Epoch 0, Step 4648: train/loss = 0.02654305472970009, train/raw-loss = 0.0018986441427841783, train/logprobs = tensor([[ -1.6470, -15.4566],
        [ -8.1980,  -3.2624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24644409120082855
Epoch 0, Step 4649: train/loss = 0.027027208358049393, train/raw-loss = 0.0006327093578875065, train/logprobs = tensor([[ -0.8964, -15.6169],
        [ -8.1206,  -4.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26394498348236084
Epoch 0, Step 4650: train/loss = 0.02565738372504711, train/raw-loss = 0.001077823806554079, train/logprobs = tensor([[ -1.4426, -21.7962],
        [ -8.1133,  -3.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2457955926656723
Epoch 0, Step 4651: train/loss = 0.0256371907889843, train/raw-loss = 0.0020610967185348272, train/logprobs = tensor([[ -1.0863, -21.4401],
        [ -8.1060,  -5.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23576092720031738
Epoch 0, Step 4652: train/loss = 0.026811465620994568, train/raw-loss = 0.00028635692433454096, train/logprobs = tensor([[ -1.2348, -16.5862],
        [-10.1835,  -2.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265251100063324
Epoch 0, Step 4653: train/loss = 0.028715170919895172, train/raw-loss = 0.0017407138366252184, train/logprobs = tensor([[ -1.2023, -10.8686],
        [ -8.2001,  -3.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697445750236511
Epoch 0, Step 4654: train/loss = 0.026195883750915527, train/raw-loss = 0.0029737672302871943, train/logprobs = tensor([[ -1.5116, -18.4209],
        [ -8.3173,  -3.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23222118616104126
Epoch 0, Step 4655: train/loss = 0.0318632572889328, train/raw-loss = 0.0028849467635154724, train/logprobs = tensor([[ -1.5033, -11.6787],
        [ -7.6730,  -2.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897830903530121
Epoch 0, Step 4656: train/loss = 0.027875054627656937, train/raw-loss = 0.0025080160703510046, train/logprobs = tensor([[ -1.5043, -11.3661],
        [-11.5211,  -2.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536703944206238
Epoch 0, Step 4657: train/loss = 0.026655904948711395, train/raw-loss = 0.004496866371482611, train/logprobs = tensor([[ -1.0529, -15.5996],
        [ -7.7498,  -4.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22159039974212646
Epoch 0, Step 4658: train/loss = 0.02724648453295231, train/raw-loss = 0.0017381800571456552, train/logprobs = tensor([[ -0.9801, -15.8612],
        [ -9.5637,  -5.3368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25508302450180054
Epoch 0, Step 4659: train/loss = 0.029877658933401108, train/raw-loss = 0.0002046048903139308, train/logprobs = tensor([[ -0.8285, -14.2189],
        [ -9.1626,  -2.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29673054814338684
Epoch 0, Step 4660: train/loss = 0.02677193470299244, train/raw-loss = 0.0014571972424164414, train/logprobs = tensor([[ -1.4013, -10.7446],
        [-10.6340,  -2.2008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531473636627197
Epoch 0, Step 4661: train/loss = 0.026250237599015236, train/raw-loss = 0.0003987890377175063, train/logprobs = tensor([[ -1.0667, -13.3396],
        [ -9.0507,  -3.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585144639015198
Epoch 0, Step 4662: train/loss = 0.02861785888671875, train/raw-loss = 0.0019116620533168316, train/logprobs = tensor([[ -0.8318, -12.3664],
        [ -7.5963,  -2.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2670619487762451
Epoch 0, Step 4663: train/loss = 0.026220157742500305, train/raw-loss = 0.0009782976703718305, train/logprobs = tensor([[ -1.1024, -14.6003],
        [ -8.2183,  -3.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252418577671051
Epoch 0, Step 4664: train/loss = 0.029471084475517273, train/raw-loss = 0.003180015366524458, train/logprobs = tensor([[-1.1120, -9.6004],
        [-8.9995, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2629106938838959
Epoch 0, Step 4665: train/loss = 0.029143989086151123, train/raw-loss = 0.002346249297261238, train/logprobs = tensor([[ -1.1404, -13.1506],
        [ -8.5530,  -3.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26797738671302795
Epoch 0, Step 4666: train/loss = 0.033306244760751724, train/raw-loss = 0.0039449818432331085, train/logprobs = tensor([[ -1.2283, -14.9801],
        [ -7.7041,  -4.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29361259937286377
Epoch 0, Step 4667: train/loss = 0.026372140273451805, train/raw-loss = 0.001473990734666586, train/logprobs = tensor([[ -0.7415, -15.2132],
        [ -6.6887,  -2.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489815056324005
Epoch 0, Step 4668: train/loss = 0.035042084753513336, train/raw-loss = 0.006530778016895056, train/logprobs = tensor([[ -1.0062, -10.3023],
        [ -8.2440,  -2.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851130962371826
Epoch 0, Step 4669: train/loss = 0.02555382251739502, train/raw-loss = 0.0008428979199379683, train/logprobs = tensor([[ -1.0496, -10.0374],
        [ -8.0852,  -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24710921943187714
Epoch 0, Step 4670: train/loss = 1.0840480327606201, train/raw-loss = 1.0616728067398071, train/logprobs = tensor([[ -4.7001, -13.4413],
        [ -7.8427,  -3.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22375299036502838
Epoch 0, Step 4671: train/loss = 0.0328298918902874, train/raw-loss = 0.002251465804874897, train/logprobs = tensor([[ -1.5779, -15.1605],
        [ -9.3845,  -4.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30578428506851196
Epoch 0, Step 4672: train/loss = 0.05819350481033325, train/raw-loss = 0.03794015571475029, train/logprobs = tensor([[ -1.3748, -10.4635],
        [ -8.3826,  -1.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20253349840641022
Epoch 0, Step 4673: train/loss = 0.028832796961069107, train/raw-loss = 0.003328565042465925, train/logprobs = tensor([[ -1.0965, -10.7597],
        [ -7.8231,  -2.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25504231452941895
Epoch 0, Step 4674: train/loss = 0.03309417515993118, train/raw-loss = 0.005229172762483358, train/logprobs = tensor([[ -1.3866,  -9.0038],
        [-11.1040,  -2.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27865004539489746
Epoch 0, Step 4675: train/loss = 0.03835463896393776, train/raw-loss = 0.009642645716667175, train/logprobs = tensor([[-0.9840, -8.7628],
        [-7.8534, -1.9588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28711992502212524
Epoch 0, Step 4676: train/loss = 0.02711133286356926, train/raw-loss = 0.001772011280991137, train/logprobs = tensor([[ -0.8673, -16.3555],
        [ -7.6295,  -3.5703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533932030200958
Epoch 0, Step 4677: train/loss = 0.029912233352661133, train/raw-loss = 0.0027062578592449427, train/logprobs = tensor([[ -1.1150, -12.2419],
        [ -8.6696,  -2.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27205973863601685
Epoch 0, Step 4678: train/loss = 0.02577250450849533, train/raw-loss = 0.003481726162135601, train/logprobs = tensor([[ -0.8671, -12.4798],
        [ -7.8655,  -1.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22290776669979095
Epoch 0, Step 4679: train/loss = 0.05858723074197769, train/raw-loss = 0.03180207312107086, train/logprobs = tensor([[-0.8394, -7.5871],
        [-7.4292, -3.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2678515315055847
Epoch 0, Step 4680: train/loss = 0.028335008770227432, train/raw-loss = 0.0014028430450707674, train/logprobs = tensor([[ -1.1186, -16.3120],
        [ -7.9742,  -3.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26932165026664734
Epoch 0, Step 4681: train/loss = 0.025842826813459396, train/raw-loss = 0.0006295518251135945, train/logprobs = tensor([[ -0.8270, -15.4180],
        [ -7.7555,  -3.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25213274359703064
Epoch 0, Step 4682: train/loss = 0.027221329510211945, train/raw-loss = 0.0009756240760907531, train/logprobs = tensor([[ -1.2638, -11.9771],
        [ -9.1078,  -3.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2624570429325104
Epoch 0, Step 4683: train/loss = 0.022342029958963394, train/raw-loss = 0.0003517217410262674, train/logprobs = tensor([[ -1.4429, -15.0672],
        [-10.8067,  -5.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21990308165550232
Epoch 0, Step 4684: train/loss = 0.02886096201837063, train/raw-loss = 0.002457648515701294, train/logprobs = tensor([[ -1.1977, -12.4420],
        [ -8.5211,  -3.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26403310894966125
Epoch 0, Step 4685: train/loss = 0.030276183038949966, train/raw-loss = 0.0020400171633809805, train/logprobs = tensor([[ -0.7376, -10.7192],
        [ -8.1371,  -2.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2823616564273834
Epoch 0, Step 4686: train/loss = 0.04349363595247269, train/raw-loss = 0.020141838118433952, train/logprobs = tensor([[ -1.0276, -15.6602],
        [ -9.2297,  -4.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23351795971393585
Epoch 0, Step 4687: train/loss = 0.0273134745657444, train/raw-loss = 0.0017336683813482523, train/logprobs = tensor([[ -1.3798, -13.6064],
        [ -8.6243,  -3.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557980418205261
Epoch 0, Step 4688: train/loss = 0.026943475008010864, train/raw-loss = 0.0017480417154729366, train/logprobs = tensor([[ -1.5713, -10.2727],
        [-10.6621,  -2.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519543170928955
Epoch 0, Step 4689: train/loss = 0.023437993600964546, train/raw-loss = 0.0002753492444753647, train/logprobs = tensor([[ -1.3161, -15.1653],
        [-10.7524,  -3.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23162642121315002
Epoch 0, Step 4690: train/loss = 0.02490094304084778, train/raw-loss = 0.0006499950541183352, train/logprobs = tensor([[ -1.4911, -11.1545],
        [-10.2201,  -1.8785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24250948429107666
Epoch 0, Step 4691: train/loss = 0.028368867933750153, train/raw-loss = 0.0019147137645632029, train/logprobs = tensor([[ -0.7167, -15.6459],
        [ -6.6695,  -1.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26454150676727295
Epoch 0, Step 4692: train/loss = 0.025608398020267487, train/raw-loss = 0.0013798255240544677, train/logprobs = tensor([[ -0.9205, -13.9110],
        [ -7.4164,  -2.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24228571355342865
Epoch 0, Step 4693: train/loss = 0.027349427342414856, train/raw-loss = 0.0009603542857803404, train/logprobs = tensor([[ -1.6276, -15.3324],
        [-10.0081,  -3.2684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26389071345329285
Epoch 0, Step 4694: train/loss = 0.02459656074643135, train/raw-loss = 0.0002557737461756915, train/logprobs = tensor([[ -1.2617, -14.4368],
        [-10.6181,  -2.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24340786039829254
Epoch 0, Step 4695: train/loss = 0.03173154965043068, train/raw-loss = 0.00129233009647578, train/logprobs = tensor([[ -0.9641, -15.5516],
        [ -7.6987,  -3.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043922185897827
Epoch 0, Step 4696: train/loss = 0.02471735328435898, train/raw-loss = 0.004397447220981121, train/logprobs = tensor([[ -1.6696, -10.4279],
        [ -7.3327,  -3.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20319904386997223
Epoch 0, Step 4697: train/loss = 0.025768226012587547, train/raw-loss = 0.00017463433323428035, train/logprobs = tensor([[ -1.6380, -13.3740],
        [-11.1967,  -3.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559359073638916
Epoch 0, Step 4698: train/loss = 0.025700457394123077, train/raw-loss = 0.000570432748645544, train/logprobs = tensor([[ -0.9355, -11.0781],
        [ -9.1342,  -2.9357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25130027532577515
Epoch 0, Step 4699: train/loss = 0.027247581630945206, train/raw-loss = 0.0002598683931864798, train/logprobs = tensor([[ -1.4925, -13.1844],
        [-13.5221,  -1.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698771357536316
Epoch 0, Step 4700: train/loss = 0.03210201859474182, train/raw-loss = 0.0060242642648518085, train/logprobs = tensor([[ -1.0842, -10.6166],
        [ -7.1694,  -1.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607775330543518
Epoch 0, Step 4701: train/loss = 0.025034232065081596, train/raw-loss = 0.0009407540201209486, train/logprobs = tensor([[ -0.9043, -11.8804],
        [ -8.1074,  -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2409348040819168
Epoch 0, Step 4702: train/loss = 0.025677280500531197, train/raw-loss = 0.002156947972252965, train/logprobs = tensor([[ -0.7644, -14.1841],
        [ -6.7832,  -2.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352033257484436
Epoch 0, Step 4703: train/loss = 0.027101658284664154, train/raw-loss = 0.0009718951187096536, train/logprobs = tensor([[ -0.7520, -19.3007],
        [ -7.1618,  -4.2598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26129764318466187
Epoch 0, Step 4704: train/loss = 0.023671908304095268, train/raw-loss = 0.0005948067991994321, train/logprobs = tensor([[ -1.1098, -13.2987],
        [ -9.9194,  -3.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.230771005153656
Epoch 0, Step 4705: train/loss = 0.03126611188054085, train/raw-loss = 0.004519597161561251, train/logprobs = tensor([[ -1.2383, -12.7582],
        [ -8.9903,  -2.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26746511459350586
Epoch 0, Step 4706: train/loss = 0.026388004422187805, train/raw-loss = 0.0007065522950142622, train/logprobs = tensor([[ -1.1234, -12.3955],
        [ -9.0394,  -2.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25681453943252563
Epoch 0, Step 4707: train/loss = 0.025882184505462646, train/raw-loss = 0.002278314670547843, train/logprobs = tensor([[-0.9167, -9.6352],
        [-8.2948, -2.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2360386997461319
Epoch 0, Step 4708: train/loss = 0.032447561621665955, train/raw-loss = 0.007157071027904749, train/logprobs = tensor([[ -0.8612, -11.5293],
        [ -7.5263,  -2.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25290489196777344
Epoch 0, Step 4709: train/loss = 0.026107182726264, train/raw-loss = 0.000740074145141989, train/logprobs = tensor([[ -1.5924, -13.7510],
        [-10.9378,  -3.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536711096763611
Epoch 0, Step 4710: train/loss = 0.02589006908237934, train/raw-loss = 0.0016440129838883877, train/logprobs = tensor([[ -1.3559, -13.4416],
        [ -9.7450,  -1.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24246054887771606
Epoch 0, Step 4711: train/loss = 0.029250439256429672, train/raw-loss = 0.003672780003398657, train/logprobs = tensor([[ -0.8598, -16.1698],
        [ -6.7934,  -2.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255776584148407
Epoch 0, Step 4712: train/loss = 0.024667635560035706, train/raw-loss = 0.0010115186451002955, train/logprobs = tensor([[ -1.4931, -13.4328],
        [ -9.0740,  -2.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365611493587494
Epoch 0, Step 4713: train/loss = 0.024387860670685768, train/raw-loss = 0.0008620510343462229, train/logprobs = tensor([[ -1.1661, -15.2841],
        [ -9.2409,  -2.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235258087515831
Epoch 0, Step 4714: train/loss = 0.02308480255305767, train/raw-loss = 0.001223951461724937, train/logprobs = tensor([[ -1.4210, -10.9140],
        [ -9.3440,  -1.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21860849857330322
Epoch 0, Step 4715: train/loss = 0.0312853641808033, train/raw-loss = 0.0008965986780822277, train/logprobs = tensor([[ -1.1575, -15.5413],
        [ -9.0894,  -3.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30388763546943665
Epoch 0, Step 4716: train/loss = 0.026775330305099487, train/raw-loss = 0.003473457880318165, train/logprobs = tensor([[ -1.1054, -10.7500],
        [ -7.9356,  -1.9978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23301872611045837
Epoch 0, Step 4717: train/loss = 0.02662908472120762, train/raw-loss = 0.002028870163485408, train/logprobs = tensor([[ -1.1692, -15.2241],
        [ -8.7050,  -4.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24600215256214142
Epoch 0, Step 4718: train/loss = 0.026260238140821457, train/raw-loss = 0.0012285895645618439, train/logprobs = tensor([[ -0.8752, -12.2399],
        [ -7.2038,  -2.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25031647086143494
Epoch 0, Step 4719: train/loss = 0.02567717805504799, train/raw-loss = 0.001665972638875246, train/logprobs = tensor([[ -1.1408, -13.2661],
        [ -8.6120,  -3.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2401120364665985
Epoch 0, Step 4720: train/loss = 0.032382696866989136, train/raw-loss = 0.012444187887012959, train/logprobs = tensor([[ -1.0442, -12.5403],
        [ -6.3721,  -2.2982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19938507676124573
Epoch 0, Step 4721: train/loss = 0.024298276752233505, train/raw-loss = 0.0002684530627448112, train/logprobs = tensor([[ -1.4382, -14.1990],
        [-10.2744,  -2.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24029824137687683
Epoch 0, Step 4722: train/loss = 0.026140840724110603, train/raw-loss = 0.0004176937509328127, train/logprobs = tensor([[ -1.2246, -18.6465],
        [ -8.7684,  -2.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572314739227295
Epoch 0, Step 4723: train/loss = 0.05629662424325943, train/raw-loss = 0.030246291309595108, train/logprobs = tensor([[ -1.3657, -10.2149],
        [-10.2542,  -3.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605033218860626
Epoch 0, Step 4724: train/loss = 0.02872702106833458, train/raw-loss = 0.002884392160922289, train/logprobs = tensor([[ -1.2454, -10.6242],
        [ -8.4288,  -2.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.258426308631897
Epoch 0, Step 4725: train/loss = 0.02411765232682228, train/raw-loss = 0.000894196389708668, train/logprobs = tensor([[ -0.7070, -13.3411],
        [ -8.2942,  -3.2617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23223455250263214
Epoch 0, Step 4726: train/loss = 0.025837743654847145, train/raw-loss = 0.00017535864026285708, train/logprobs = tensor([[ -1.8499, -17.9428],
        [-13.0681,  -5.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25662386417388916
Epoch 0, Step 4727: train/loss = 0.02465040422976017, train/raw-loss = 0.002259889617562294, train/logprobs = tensor([[ -1.2394, -19.1044],
        [-11.0857,  -4.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22390514612197876
Epoch 0, Step 4728: train/loss = 0.02523035928606987, train/raw-loss = 0.0023435247130692005, train/logprobs = tensor([[ -1.8134, -11.3753],
        [ -9.2988,  -3.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22886833548545837
Epoch 0, Step 4729: train/loss = 0.03480398654937744, train/raw-loss = 0.006612032651901245, train/logprobs = tensor([[ -0.8419, -10.8075],
        [ -7.4680,  -2.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28191953897476196
Epoch 0, Step 4730: train/loss = 0.027311494573950768, train/raw-loss = 0.0004886562819592655, train/logprobs = tensor([[ -1.4713, -11.7701],
        [-11.3570,  -2.5387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26822835206985474
Epoch 0, Step 4731: train/loss = 0.033079978078603745, train/raw-loss = 0.009460034780204296, train/logprobs = tensor([[ -0.9418, -12.8107],
        [ -7.0027,  -2.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23619942367076874
Epoch 0, Step 4732: train/loss = 0.02452147752046585, train/raw-loss = 0.0016491070855408907, train/logprobs = tensor([[ -0.7611, -16.4164],
        [ -7.1828,  -3.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2287237048149109
Epoch 0, Step 4733: train/loss = 0.02752644196152687, train/raw-loss = 0.0007455176673829556, train/logprobs = tensor([[ -0.8347, -13.7121],
        [ -7.7254,  -2.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2678092420101166
Epoch 0, Step 4734: train/loss = 0.023975033313035965, train/raw-loss = 0.0005297033349052072, train/logprobs = tensor([[ -1.3013, -18.8906],
        [ -9.4746,  -4.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23445330560207367
Epoch 0, Step 4735: train/loss = 0.02980026602745056, train/raw-loss = 0.002648870926350355, train/logprobs = tensor([[ -0.7071, -11.6114],
        [ -6.5160,  -3.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2715139389038086
Epoch 0, Step 4736: train/loss = 0.042099397629499435, train/raw-loss = 0.012171819806098938, train/logprobs = tensor([[ -1.3222, -13.7589],
        [ -8.5559,  -3.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992757558822632
Epoch 0, Step 4737: train/loss = 0.028202852234244347, train/raw-loss = 0.0023789089173078537, train/logprobs = tensor([[ -0.8560, -14.5104],
        [ -6.8379,  -3.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25823941826820374
Epoch 0, Step 4738: train/loss = 0.029788676649332047, train/raw-loss = 0.0005787510308437049, train/logprobs = tensor([[ -1.4144, -12.7609],
        [-12.0284,  -2.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292099267244339
Epoch 0, Step 4739: train/loss = 0.02994837611913681, train/raw-loss = 0.006373689975589514, train/logprobs = tensor([[ -0.7747, -10.8781],
        [ -7.8489,  -3.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2357468605041504
Epoch 0, Step 4740: train/loss = 0.021974001079797745, train/raw-loss = 0.0006210464052855968, train/logprobs = tensor([[ -1.6326, -18.6443],
        [ -9.8205,  -3.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2135295420885086
Epoch 0, Step 4741: train/loss = 0.026868479326367378, train/raw-loss = 0.0008304393850266933, train/logprobs = tensor([[ -1.1958, -16.0189],
        [ -9.4881,  -2.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2603803873062134
Epoch 0, Step 4742: train/loss = 0.09093285351991653, train/raw-loss = 0.06975826621055603, train/logprobs = tensor([[-1.6343, -9.9379],
        [-8.4957, -3.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21174590289592743
Epoch 0, Step 4743: train/loss = 0.029246557503938675, train/raw-loss = 0.001556437462568283, train/logprobs = tensor([[ -1.1442, -11.1248],
        [ -9.5789,  -2.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2769011855125427
Epoch 0, Step 4744: train/loss = 0.02765415422618389, train/raw-loss = 0.00349663058295846, train/logprobs = tensor([[-1.3506, -9.2708],
        [-8.9597, -2.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24157527089118958
Epoch 0, Step 4745: train/loss = 0.028554465621709824, train/raw-loss = 0.0017479610396549106, train/logprobs = tensor([[ -1.5334, -15.7683],
        [ -8.1145,  -4.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26806506514549255
Epoch 0, Step 4746: train/loss = 0.033309802412986755, train/raw-loss = 0.010062769055366516, train/logprobs = tensor([[ -1.0549, -10.4816],
        [ -7.3476,  -4.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2324703335762024
Epoch 0, Step 4747: train/loss = 0.02728879079222679, train/raw-loss = 0.0006831008940935135, train/logprobs = tensor([[ -1.2856, -11.2908],
        [ -9.3387,  -1.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2660568952560425
Epoch 0, Step 4748: train/loss = 0.025421833619475365, train/raw-loss = 0.0011702508199959993, train/logprobs = tensor([[ -1.0148, -18.1582],
        [ -8.1212,  -3.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24251583218574524
Epoch 0, Step 4749: train/loss = 0.024930085986852646, train/raw-loss = 0.0009407552424818277, train/logprobs = tensor([[ -1.0301, -13.9087],
        [ -9.8462,  -2.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23989330232143402
Epoch 0, Step 4750: train/loss = 0.03033171221613884, train/raw-loss = 0.00023715644783806056, train/logprobs = tensor([[ -1.3866, -14.2281],
        [-10.5433,  -1.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30094555020332336
Epoch 0, Step 4751: train/loss = 0.02610897645354271, train/raw-loss = 0.003951759077608585, train/logprobs = tensor([[ -1.1092, -10.2127],
        [ -6.8657,  -1.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215721607208252
Epoch 0, Step 4752: train/loss = 0.02596476674079895, train/raw-loss = 0.0016307004261761904, train/logprobs = tensor([[ -0.9232, -13.0173],
        [ -8.4291,  -3.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24334067106246948
Epoch 0, Step 4753: train/loss = 0.031643107533454895, train/raw-loss = 0.0004633317585103214, train/logprobs = tensor([[ -0.9278, -16.6310],
        [ -8.6358,  -5.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31179776787757874
Epoch 0, Step 4754: train/loss = 0.02467191219329834, train/raw-loss = 0.001232379348948598, train/logprobs = tensor([[ -0.9094, -14.7910],
        [ -7.6393,  -3.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343953251838684
Epoch 0, Step 4755: train/loss = 0.02806423231959343, train/raw-loss = 0.003344896249473095, train/logprobs = tensor([[-1.4475, -9.6793],
        [-8.5196, -3.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2471933513879776
Epoch 0, Step 4756: train/loss = 0.02739381603896618, train/raw-loss = 0.001983854454010725, train/logprobs = tensor([[ -0.7802, -12.7352],
        [ -7.0268,  -3.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25409960746765137
Epoch 0, Step 4757: train/loss = 0.0314922109246254, train/raw-loss = 0.004559266846626997, train/logprobs = tensor([[ -0.9707, -13.5861],
        [ -7.7252,  -3.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693294882774353
Epoch 0, Step 4758: train/loss = 0.02979692630469799, train/raw-loss = 0.0008547285688109696, train/logprobs = tensor([[ -0.8296, -14.0740],
        [ -7.6894,  -3.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894219756126404
Epoch 0, Step 4759: train/loss = 0.03013986349105835, train/raw-loss = 0.004393826704472303, train/logprobs = tensor([[ -1.2073, -10.5789],
        [ -8.0676,  -2.2423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2574603855609894
Epoch 0, Step 4760: train/loss = 0.04318689554929733, train/raw-loss = 0.01669234223663807, train/logprobs = tensor([[ -0.8771, -11.7371],
        [ -6.6127,  -3.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26494553685188293
Epoch 0, Step 4761: train/loss = 0.028777984902262688, train/raw-loss = 0.004641114734113216, train/logprobs = tensor([[ -0.9372, -12.8477],
        [ -7.7764,  -2.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24136868119239807
Epoch 0, Step 4762: train/loss = 0.029653269797563553, train/raw-loss = 0.0022161272354424, train/logprobs = tensor([[ -1.3760, -13.6118],
        [ -9.1982,  -3.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743714153766632
Epoch 0, Step 4763: train/loss = 0.03284613788127899, train/raw-loss = 0.0011331869754940271, train/logprobs = tensor([[ -1.1210, -14.0636],
        [ -8.7832,  -3.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3171294927597046
Epoch 0, Step 4764: train/loss = 0.023675251752138138, train/raw-loss = 0.0005774025339633226, train/logprobs = tensor([[ -1.3157, -10.3306],
        [-10.0451,  -1.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23097847402095795
Epoch 0, Step 4765: train/loss = 0.028699524700641632, train/raw-loss = 0.004340961575508118, train/logprobs = tensor([[ -1.3657, -15.0689],
        [ -8.0328,  -3.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24358561635017395
Epoch 0, Step 4766: train/loss = 0.03034522384405136, train/raw-loss = 0.0030793240293860435, train/logprobs = tensor([[ -1.1314, -11.6364],
        [ -8.1643,  -2.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726590037345886
Epoch 0, Step 4767: train/loss = 0.02893712930381298, train/raw-loss = 0.007001463323831558, train/logprobs = tensor([[ -1.5116, -13.8091],
        [ -9.7168,  -3.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21935665607452393
Epoch 0, Step 4768: train/loss = 0.02319670468568802, train/raw-loss = 0.0006407840410247445, train/logprobs = tensor([[ -0.9256, -14.6537],
        [ -8.2359,  -3.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22555918991565704
Epoch 0, Step 4769: train/loss = 0.028493747115135193, train/raw-loss = 0.003874788526445627, train/logprobs = tensor([[ -0.7563, -13.6997],
        [ -6.4517,  -3.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24618959426879883
Epoch 0, Step 4770: train/loss = 0.026545872911810875, train/raw-loss = 0.000604758970439434, train/logprobs = tensor([[ -0.9867, -17.2055],
        [ -8.0846,  -3.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25941112637519836
Epoch 0, Step 4771: train/loss = 0.026359742507338524, train/raw-loss = 0.004975175019353628, train/logprobs = tensor([[ -1.0321, -12.7720],
        [ -8.0344,  -2.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21384567022323608
Epoch 0, Step 4772: train/loss = 0.024347640573978424, train/raw-loss = 0.0009259033249691129, train/logprobs = tensor([[ -1.3172, -21.4705],
        [ -9.6698,  -3.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23421736061573029
Epoch 0, Step 4773: train/loss = 0.024761006236076355, train/raw-loss = 0.00038017379119992256, train/logprobs = tensor([[ -1.3622, -14.3425],
        [-11.0085,  -3.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438082993030548
Epoch 0, Step 4774: train/loss = 0.028419185429811478, train/raw-loss = 0.001288995728828013, train/logprobs = tensor([[ -1.0977, -18.6869],
        [ -7.3374,  -5.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27130189538002014
Epoch 0, Step 4775: train/loss = 0.024255353957414627, train/raw-loss = 0.0011152749648317695, train/logprobs = tensor([[ -0.9350, -11.5981],
        [ -8.1154,  -2.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2314007729291916
Epoch 0, Step 4776: train/loss = 0.026898715645074844, train/raw-loss = 0.002952602691948414, train/logprobs = tensor([[ -1.3420, -11.3601],
        [-10.4184,  -2.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23946113884449005
Epoch 0, Step 4777: train/loss = 0.028404122218489647, train/raw-loss = 0.0006272257305681705, train/logprobs = tensor([[ -1.8319, -15.5190],
        [-11.4220,  -4.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27776896953582764
Epoch 0, Step 4778: train/loss = 0.022437430918216705, train/raw-loss = 0.0010874662548303604, train/logprobs = tensor([[ -1.4322, -14.2221],
        [ -9.8681,  -2.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21349965035915375
Epoch 0, Step 4779: train/loss = 0.028517985716462135, train/raw-loss = 0.0012130544055253267, train/logprobs = tensor([[ -0.7323, -11.4969],
        [ -7.3678,  -3.0673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27304932475090027
Epoch 0, Step 4780: train/loss = 0.02912353165447712, train/raw-loss = 0.00550055131316185, train/logprobs = tensor([[-0.6779, -9.5554],
        [-7.0869, -2.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2362297922372818
Epoch 0, Step 4781: train/loss = 0.026419686153531075, train/raw-loss = 0.003478666767477989, train/logprobs = tensor([[ -0.8409, -11.1164],
        [ -7.2447,  -1.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22941020131111145
Epoch 0, Step 4782: train/loss = 0.05935812368988991, train/raw-loss = 0.035669632256031036, train/logprobs = tensor([[-0.8663, -9.7625],
        [-7.5321, -2.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368849217891693
Epoch 0, Step 4783: train/loss = 0.026492001488804817, train/raw-loss = 0.0018379846587777138, train/logprobs = tensor([[ -1.5436, -11.7367],
        [ -8.7399,  -3.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2465401589870453
Epoch 0, Step 4784: train/loss = 0.028238922357559204, train/raw-loss = 0.001752195879817009, train/logprobs = tensor([[ -0.6511, -12.8575],
        [ -7.3876,  -2.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26486727595329285
Epoch 0, Step 4785: train/loss = 0.02513410523533821, train/raw-loss = 0.0013731600483879447, train/logprobs = tensor([[ -1.0550, -14.3323],
        [ -8.0110,  -3.2667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23760946094989777
Epoch 0, Step 4786: train/loss = 0.04257938265800476, train/raw-loss = 0.0120131466537714, train/logprobs = tensor([[-1.2683, -8.4787],
        [-9.1391, -1.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056623935699463
Epoch 0, Step 4787: train/loss = 0.029326526448130608, train/raw-loss = 0.0031815804541110992, train/logprobs = tensor([[ -0.8398, -13.3781],
        [ -7.5889,  -3.7060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614494562149048
Epoch 0, Step 4788: train/loss = 0.025798490270972252, train/raw-loss = 0.000843970978166908, train/logprobs = tensor([[ -1.3348, -10.1968],
        [ -9.4120,  -2.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24954520165920258
Epoch 0, Step 4789: train/loss = 0.020740309730172157, train/raw-loss = 0.0001571413449710235, train/logprobs = tensor([[ -1.4947, -18.9019],
        [-10.6175,  -6.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20583167672157288
Epoch 0, Step 4790: train/loss = 0.02573947049677372, train/raw-loss = 0.001023996970616281, train/logprobs = tensor([[ -0.9594, -16.2274],
        [ -7.5920,  -3.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24715472757816315
Epoch 0, Step 4791: train/loss = 0.026526935398578644, train/raw-loss = 0.0013494150480255485, train/logprobs = tensor([[ -1.5155, -13.9829],
        [ -8.4158,  -4.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25177520513534546
Epoch 0, Step 4792: train/loss = 0.027705181390047073, train/raw-loss = 0.0025357098784297705, train/logprobs = tensor([[ -0.9834, -12.5401],
        [ -7.4665,  -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516947090625763
Epoch 0, Step 4793: train/loss = 0.07148575037717819, train/raw-loss = 0.04245031252503395, train/logprobs = tensor([[ -1.1474, -10.2930],
        [-10.2986,  -3.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29035434126853943
Epoch 0, Step 4794: train/loss = 0.02891867235302925, train/raw-loss = 0.0013525246176868677, train/logprobs = tensor([[ -1.0254, -10.4295],
        [ -9.7836,  -2.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2756614685058594
Epoch 0, Step 4795: train/loss = 0.02477129176259041, train/raw-loss = 0.002353713382035494, train/logprobs = tensor([[ -0.8883, -11.8122],
        [ -7.2359,  -2.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22417578101158142
Epoch 0, Step 4796: train/loss = 0.023649051785469055, train/raw-loss = 0.0003769015893340111, train/logprobs = tensor([[ -1.0602, -18.8064],
        [ -9.2555,  -4.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327215075492859
Epoch 0, Step 4797: train/loss = 0.025718195363879204, train/raw-loss = 0.0006060691084712744, train/logprobs = tensor([[ -1.0768, -15.5069],
        [ -8.2228,  -1.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25112125277519226
Epoch 0, Step 4798: train/loss = 0.025203552097082138, train/raw-loss = 0.0015666540712118149, train/logprobs = tensor([[ -0.9401, -12.0846],
        [ -7.7980,  -2.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23636898398399353
Epoch 0, Step 4799: train/loss = 0.029302602633833885, train/raw-loss = 0.0006438072305172682, train/logprobs = tensor([[ -1.1952, -10.4972],
        [ -9.5001,  -2.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865879535675049
Epoch 0, Step 4800: train/loss = 0.03343195840716362, train/raw-loss = 0.007123403251171112, train/logprobs = tensor([[-1.0704, -9.2170],
        [-8.4845, -1.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2630855441093445
Epoch 0, Step 4801: train/loss = 0.02584790252149105, train/raw-loss = 0.0007149288430809975, train/logprobs = tensor([[ -0.8990, -12.5883],
        [ -7.8928,  -2.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513297498226166
Epoch 0, Step 4802: train/loss = 0.03137930482625961, train/raw-loss = 0.007079796865582466, train/logprobs = tensor([[ -1.5812, -13.6985],
        [ -7.2937,  -3.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24299508333206177
Epoch 0, Step 4803: train/loss = 0.028466064482927322, train/raw-loss = 0.0013391984393820167, train/logprobs = tensor([[ -0.8567, -11.9199],
        [ -6.9470,  -2.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27126866579055786
Epoch 0, Step 4804: train/loss = 0.04830043390393257, train/raw-loss = 0.01824745535850525, train/logprobs = tensor([[ -0.9696, -13.7715],
        [ -7.6674,  -1.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005297780036926
Epoch 0, Step 4805: train/loss = 0.03124617412686348, train/raw-loss = 0.002224828815087676, train/logprobs = tensor([[ -0.8894, -11.5843],
        [ -7.8373,  -1.9638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902134656906128
Epoch 0, Step 4806: train/loss = 0.026641853153705597, train/raw-loss = 0.0025103017687797546, train/logprobs = tensor([[ -1.3480, -11.0794],
        [ -7.8405,  -2.5789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24131551384925842
Epoch 0, Step 4807: train/loss = 0.02490922436118126, train/raw-loss = 0.0011180349392816424, train/logprobs = tensor([[ -1.0138, -10.7259],
        [ -8.5835,  -2.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2379118800163269
Epoch 0, Step 4808: train/loss = 0.03222170099616051, train/raw-loss = 0.008959149941802025, train/logprobs = tensor([[ -1.2755, -13.0834],
        [ -7.3579,  -3.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23262549936771393
Epoch 0, Step 4809: train/loss = 0.02467072196304798, train/raw-loss = 0.0015777712687849998, train/logprobs = tensor([[ -1.3158, -12.3411],
        [ -8.8355,  -1.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23092949390411377
Epoch 0, Step 4810: train/loss = 0.03659787029027939, train/raw-loss = 0.013447578065097332, train/logprobs = tensor([[ -1.4638, -17.0386],
        [ -7.2651,  -2.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23150289058685303
Epoch 0, Step 4811: train/loss = 0.0271266121417284, train/raw-loss = 0.006962945684790611, train/logprobs = tensor([[-1.2696, -9.5754],
        [-6.1481, -2.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2016366571187973
Epoch 0, Step 4812: train/loss = 0.024416012689471245, train/raw-loss = 0.0005408708238974214, train/logprobs = tensor([[ -0.8373, -13.8142],
        [ -8.5838,  -3.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2387513965368271
Epoch 0, Step 4813: train/loss = 0.025174349546432495, train/raw-loss = 0.0020859052892774343, train/logprobs = tensor([[ -1.0129, -18.5275],
        [ -7.6850,  -6.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23088446259498596
Epoch 0, Step 4814: train/loss = 0.030435889959335327, train/raw-loss = 0.0007469071424566209, train/logprobs = tensor([[ -0.9947, -12.2059],
        [ -8.7906,  -3.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968898117542267
Epoch 0, Step 4815: train/loss = 0.026121176779270172, train/raw-loss = 0.002290783915668726, train/logprobs = tensor([[-1.0111, -9.8507],
        [-7.8638, -2.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23830391466617584
Epoch 0, Step 4816: train/loss = 0.027048204094171524, train/raw-loss = 0.00553911505267024, train/logprobs = tensor([[ -1.5207, -10.5841],
        [ -8.3039,  -2.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21509087085723877
Epoch 0, Step 4817: train/loss = 0.025653302669525146, train/raw-loss = 0.0003638006455730647, train/logprobs = tensor([[ -1.2104, -16.1591],
        [ -9.3949,  -4.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2528950273990631
Epoch 0, Step 4818: train/loss = 0.028572235256433487, train/raw-loss = 0.0015340582467615604, train/logprobs = tensor([[ -1.4621, -13.3599],
        [ -9.6809,  -3.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27038177847862244
Epoch 0, Step 4819: train/loss = 0.030818577855825424, train/raw-loss = 0.0051850974559783936, train/logprobs = tensor([[-1.1749, -9.6629],
        [-8.8040, -2.4805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2563347816467285
Epoch 0, Step 4820: train/loss = 0.029123909771442413, train/raw-loss = 0.00021280664077494293, train/logprobs = tensor([[ -1.4047, -11.6117],
        [-11.3055,  -1.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28911104798316956
Epoch 0, Step 4821: train/loss = 0.02701019123196602, train/raw-loss = 0.0015146360965445638, train/logprobs = tensor([[ -0.7956, -14.7448],
        [ -7.3626,  -3.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25495555996894836
Epoch 0, Step 4822: train/loss = 0.025945983827114105, train/raw-loss = 0.0023111102636903524, train/logprobs = tensor([[ -1.7394, -16.9684],
        [ -9.9968,  -3.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2363487184047699
Epoch 0, Step 4823: train/loss = 0.024120990186929703, train/raw-loss = 0.0005679247551597655, train/logprobs = tensor([[ -1.3301, -12.6511],
        [-10.6916,  -2.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23553064465522766
Epoch 0, Step 4824: train/loss = 0.02984679862856865, train/raw-loss = 0.0015182956121861935, train/logprobs = tensor([[ -0.7258, -14.5959],
        [ -6.6785,  -3.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832850217819214
Epoch 0, Step 4825: train/loss = 0.024680227041244507, train/raw-loss = 0.004910765681415796, train/logprobs = tensor([[ -0.7821, -12.2363],
        [ -6.2183,  -2.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1976945996284485
Epoch 0, Step 4826: train/loss = 0.028989627957344055, train/raw-loss = 0.0034476330038160086, train/logprobs = tensor([[ -0.5934, -20.8329],
        [ -5.9612,  -4.3503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25541993975639343
Epoch 0, Step 4827: train/loss = 0.021987158805131912, train/raw-loss = 0.00032643863232806325, train/logprobs = tensor([[ -1.6195, -13.6437],
        [-11.5684,  -2.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21660718321800232
Epoch 0, Step 4828: train/loss = 0.02393639087677002, train/raw-loss = 0.0016959074418991804, train/logprobs = tensor([[ -1.1324, -16.2430],
        [ -7.8094,  -3.4108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2224048227071762
Epoch 0, Step 4829: train/loss = 0.026392294093966484, train/raw-loss = 0.0006713111652061343, train/logprobs = tensor([[ -1.1343, -14.6462],
        [ -8.6676,  -3.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257209837436676
Epoch 0, Step 4830: train/loss = 0.027233250439167023, train/raw-loss = 0.0009650277206674218, train/logprobs = tensor([[ -1.4242, -11.2340],
        [ -9.7938,  -3.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626821994781494
Epoch 0, Step 4831: train/loss = 0.12465107440948486, train/raw-loss = 0.10015621781349182, train/logprobs = tensor([[-0.9499, -8.3765],
        [-8.3766, -2.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449485808610916
Epoch 0, Step 4832: train/loss = 0.02328871190547943, train/raw-loss = 0.002196283545345068, train/logprobs = tensor([[ -1.0656, -15.7721],
        [ -7.7210,  -4.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21092428267002106
Epoch 0, Step 4833: train/loss = 0.025311293080449104, train/raw-loss = 0.0014297326561063528, train/logprobs = tensor([[ -1.0949, -10.6309],
        [ -9.8621,  -2.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23881559073925018
Epoch 0, Step 4834: train/loss = 0.024301420897245407, train/raw-loss = 0.0012798485113307834, train/logprobs = tensor([[ -1.4735, -13.4982],
        [ -9.0338,  -2.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23021572828292847
Epoch 0, Step 4835: train/loss = 0.03593592345714569, train/raw-loss = 0.0108264721930027, train/logprobs = tensor([[ -0.8628, -14.8769],
        [ -5.5123,  -3.3888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510945200920105
Epoch 0, Step 4836: train/loss = 0.023655138909816742, train/raw-loss = 0.0006157167954370379, train/logprobs = tensor([[ -1.3222, -18.2226],
        [-10.3193,  -4.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23039421439170837
Epoch 0, Step 4837: train/loss = 0.02710498683154583, train/raw-loss = 0.001107713207602501, train/logprobs = tensor([[ -1.0911, -16.6520],
        [ -8.0800,  -3.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599727213382721
Epoch 0, Step 4838: train/loss = 0.031928226351737976, train/raw-loss = 0.007674343418329954, train/logprobs = tensor([[ -0.8067, -11.1229],
        [ -5.2457,  -2.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24253880977630615
Epoch 0, Step 4839: train/loss = 0.03594774752855301, train/raw-loss = 0.011363073252141476, train/logprobs = tensor([[ -0.8911, -11.5210],
        [ -7.3446,  -3.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24584677815437317
Epoch 0, Step 4840: train/loss = 0.028511371463537216, train/raw-loss = 0.001517965691164136, train/logprobs = tensor([[ -1.1094, -11.0261],
        [ -8.5747,  -2.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699340581893921
Epoch 0, Step 4841: train/loss = 0.0230553075671196, train/raw-loss = 0.0005556945689022541, train/logprobs = tensor([[ -0.7958, -14.3859],
        [ -7.8767,  -2.6151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22499613463878632
Epoch 0, Step 4842: train/loss = 0.026502292603254318, train/raw-loss = 0.001292223110795021, train/logprobs = tensor([[ -0.9667, -16.1071],
        [ -7.9403,  -2.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25210070610046387
Epoch 0, Step 4843: train/loss = 0.03725342079997063, train/raw-loss = 0.012995883822441101, train/logprobs = tensor([[ -1.4061, -12.0889],
        [-11.3500,  -2.1300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24257537722587585
Epoch 0, Step 4844: train/loss = 0.02426023781299591, train/raw-loss = 0.0009921086020767689, train/logprobs = tensor([[ -1.1735, -16.9689],
        [ -8.9053,  -3.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2326813042163849
Epoch 0, Step 4845: train/loss = 0.02888244204223156, train/raw-loss = 0.0027520942967385054, train/logprobs = tensor([[ -1.0085, -11.1798],
        [-10.0691,  -3.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26130345463752747
Epoch 0, Step 4846: train/loss = 0.02712884545326233, train/raw-loss = 0.0025122296065092087, train/logprobs = tensor([[ -0.7771, -10.0258],
        [ -7.0605,  -2.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2461661696434021
Epoch 0, Step 4847: train/loss = 0.03098735772073269, train/raw-loss = 0.0050759282894432545, train/logprobs = tensor([[ -0.7549, -10.1168],
        [ -7.5795,  -2.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591142952442169
Epoch 0, Step 4848: train/loss = 0.026431212201714516, train/raw-loss = 0.0011307887034490705, train/logprobs = tensor([[ -0.9995, -15.7315],
        [ -8.4837,  -3.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253004252910614
Epoch 0, Step 4849: train/loss = 0.02629880979657173, train/raw-loss = 0.0002387938293395564, train/logprobs = tensor([[ -1.7339, -16.8277],
        [-11.9829,  -4.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26060014963150024
Epoch 0, Step 4850: train/loss = 0.02689702995121479, train/raw-loss = 0.0007855023723095655, train/logprobs = tensor([[ -1.4436, -10.9916],
        [ -9.8226,  -3.3590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26111528277397156
Epoch 0, Step 4851: train/loss = 0.056253306567668915, train/raw-loss = 0.025734398514032364, train/logprobs = tensor([[ -0.9423, -15.3170],
        [ -8.1620,  -4.5649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3051890730857849
Epoch 0, Step 4852: train/loss = 0.04309452697634697, train/raw-loss = 0.01651516556739807, train/logprobs = tensor([[ -0.8911, -10.8163],
        [ -7.0714,  -2.3048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657936215400696
Epoch 0, Step 4853: train/loss = 0.026972467079758644, train/raw-loss = 0.0007204296998679638, train/logprobs = tensor([[ -1.1454, -11.9835],
        [ -8.7724,  -2.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26252037286758423
Epoch 0, Step 4854: train/loss = 0.02451268583536148, train/raw-loss = 0.0010789689840748906, train/logprobs = tensor([[ -1.3999, -13.8672],
        [ -9.6439,  -3.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23433718085289001
Epoch 0, Step 4855: train/loss = 0.06719119101762772, train/raw-loss = 0.04579742252826691, train/logprobs = tensor([[ -1.2026, -12.0215],
        [ -8.9159,  -2.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2139376401901245
Epoch 0, Step 4856: train/loss = 0.027996085584163666, train/raw-loss = 0.0030176606960594654, train/logprobs = tensor([[ -0.7995, -12.1227],
        [ -8.3794,  -2.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24978426098823547
Epoch 0, Step 4857: train/loss = 0.026654820889234543, train/raw-loss = 0.0006795901572331786, train/logprobs = tensor([[ -1.1268, -14.5656],
        [ -8.1120,  -3.2853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2597523033618927
Epoch 0, Step 4858: train/loss = 0.03272789344191551, train/raw-loss = 0.00835838820785284, train/logprobs = tensor([[ -1.8377, -12.9649],
        [ -9.9335,  -2.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24369505047798157
Epoch 0, Step 4859: train/loss = 0.08337709307670593, train/raw-loss = 0.057303108274936676, train/logprobs = tensor([[-1.1078, -7.5990],
        [-7.4294, -2.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260739803314209
Epoch 0, Step 4860: train/loss = 0.026113424450159073, train/raw-loss = 0.0007571011665277183, train/logprobs = tensor([[ -1.0757, -15.3548],
        [ -7.6766,  -3.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535632252693176
Epoch 0, Step 4861: train/loss = 0.02812493033707142, train/raw-loss = 0.0031353009399026632, train/logprobs = tensor([[ -0.9724, -10.7583],
        [ -7.8709,  -2.1224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24989628791809082
Epoch 0, Step 4862: train/loss = 0.026681022718548775, train/raw-loss = 0.0016696578823029995, train/logprobs = tensor([[ -1.0734, -15.6884],
        [ -7.8165,  -3.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25011366605758667
Epoch 0, Step 4863: train/loss = 0.0461910106241703, train/raw-loss = 0.0222912710160017, train/logprobs = tensor([[ -0.6877, -11.6036],
        [ -5.6164,  -2.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2389974147081375
Epoch 0, Step 4864: train/loss = 0.028204765170812607, train/raw-loss = 0.0030033797957003117, train/logprobs = tensor([[-1.0063, -9.8216],
        [-8.2880, -2.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520138621330261
Epoch 0, Step 4865: train/loss = 0.02756434679031372, train/raw-loss = 0.0037730298936367035, train/logprobs = tensor([[ -1.1893, -13.9174],
        [ -8.1712,  -2.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23791317641735077
Epoch 0, Step 4866: train/loss = 0.02742192894220352, train/raw-loss = 0.0014150792267173529, train/logprobs = tensor([[ -1.0257, -13.5199],
        [ -7.3371,  -2.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26006850600242615
Epoch 0, Step 4867: train/loss = 0.023436274379491806, train/raw-loss = 0.0007776449201628566, train/logprobs = tensor([[ -1.0975, -16.2820],
        [ -8.6046,  -3.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22658628225326538
Epoch 0, Step 4868: train/loss = 0.0295462217181921, train/raw-loss = 0.004658731631934643, train/logprobs = tensor([[ -1.2164, -11.4162],
        [ -7.7630,  -2.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24887491762638092
Epoch 0, Step 4869: train/loss = 0.027031350880861282, train/raw-loss = 0.0018258843338117003, train/logprobs = tensor([[ -1.1890, -10.0315],
        [ -9.2551,  -1.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520546615123749
Epoch 0, Step 4870: train/loss = 0.02514553628861904, train/raw-loss = 0.0013140637893229723, train/logprobs = tensor([[ -1.3057, -10.2278],
        [ -9.5340,  -2.2610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23831471800804138
Epoch 0, Step 4871: train/loss = 0.05636909604072571, train/raw-loss = 0.0287036020308733, train/logprobs = tensor([[ -1.0364, -13.8906],
        [ -8.3804,  -3.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2766549587249756
Epoch 0, Step 4872: train/loss = 0.028026621788740158, train/raw-loss = 0.0016503080260008574, train/logprobs = tensor([[-1.1364, -9.8105],
        [-7.9206, -2.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637631297111511
Epoch 0, Step 4873: train/loss = 0.03246235102415085, train/raw-loss = 0.005421606823801994, train/logprobs = tensor([[-1.2168, -7.3270],
        [-8.9499, -1.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27040746808052063
Epoch 0, Step 4874: train/loss = 0.027243267744779587, train/raw-loss = 0.0005637367139570415, train/logprobs = tensor([[ -1.1359, -13.5185],
        [ -9.0967,  -3.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2667953073978424
Epoch 0, Step 4875: train/loss = 0.03158704191446304, train/raw-loss = 0.0037014137487858534, train/logprobs = tensor([[ -1.6339, -11.6663],
        [ -8.6677,  -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788562774658203
Epoch 0, Step 4876: train/loss = 0.02693251520395279, train/raw-loss = 0.0013268089387565851, train/logprobs = tensor([[ -1.0617, -16.2931],
        [ -9.1078,  -3.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2560570538043976
Epoch 0, Step 4877: train/loss = 0.02785402350127697, train/raw-loss = 0.0018576800357550383, train/logprobs = tensor([[ -1.0006, -10.0457],
        [ -9.4588,  -2.3869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25996342301368713
Epoch 0, Step 4878: train/loss = 0.06902865320444107, train/raw-loss = 0.04438052698969841, train/logprobs = tensor([[ -0.7665, -10.3969],
        [ -7.6124,  -2.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464812695980072
Epoch 0, Step 4879: train/loss = 0.03608286380767822, train/raw-loss = 0.010102542117238045, train/logprobs = tensor([[ -1.5393, -12.1241],
        [-10.0954,  -1.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25980323553085327
Epoch 0, Step 4880: train/loss = 0.035658735781908035, train/raw-loss = 0.013512845151126385, train/logprobs = tensor([[-1.1739, -9.7621],
        [-8.4123, -2.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22145891189575195
Epoch 0, Step 4881: train/loss = 0.024530254304409027, train/raw-loss = 0.00026174000231549144, train/logprobs = tensor([[ -1.0936, -16.2349],
        [ -9.5376,  -2.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24268513917922974
Epoch 0, Step 4882: train/loss = 0.1037076786160469, train/raw-loss = 0.08120957016944885, train/logprobs = tensor([[ -0.8022, -12.1991],
        [ -6.8456,  -3.5427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22498103976249695
Epoch 0, Step 4883: train/loss = 0.02439264953136444, train/raw-loss = 0.00013638097152579576, train/logprobs = tensor([[ -1.5584, -15.4666],
        [-12.4058,  -3.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2425626814365387
Epoch 0, Step 4884: train/loss = 0.028693974018096924, train/raw-loss = 0.002834817161783576, train/logprobs = tensor([[ -1.2710, -10.1510],
        [ -8.7871,  -2.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25859153270721436
Epoch 0, Step 4885: train/loss = 0.028832731768488884, train/raw-loss = 0.0024153334088623524, train/logprobs = tensor([[ -1.3880, -17.1609],
        [ -8.6571,  -3.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641739845275879
Epoch 0, Step 4886: train/loss = 0.025387780740857124, train/raw-loss = 0.0009008044144138694, train/logprobs = tensor([[ -1.0135, -14.7543],
        [ -7.8820,  -2.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24486976861953735
Epoch 0, Step 4887: train/loss = 0.031691085547208786, train/raw-loss = 0.0031290166079998016, train/logprobs = tensor([[ -1.0591, -10.9322],
        [ -8.7931,  -2.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28562068939208984
Epoch 0, Step 4888: train/loss = 0.027628954499959946, train/raw-loss = 0.001972765661776066, train/logprobs = tensor([[ -1.1320, -12.0701],
        [ -7.9831,  -2.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25656187534332275
Epoch 0, Step 4889: train/loss = 0.02667250856757164, train/raw-loss = 0.0014232598477974534, train/logprobs = tensor([[ -1.5378, -11.1619],
        [ -9.1902,  -2.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524924874305725
Epoch 0, Step 4890: train/loss = 0.030377471819519997, train/raw-loss = 0.003199594561010599, train/logprobs = tensor([[ -0.7020, -13.9166],
        [ -6.3385,  -3.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27177876234054565
Epoch 0, Step 4891: train/loss = 0.034044504165649414, train/raw-loss = 0.0060286372900009155, train/logprobs = tensor([[ -1.1806, -13.6686],
        [ -9.4096,  -2.2209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801586389541626
Epoch 0, Step 4892: train/loss = 0.02355603128671646, train/raw-loss = 0.0010906680254265666, train/logprobs = tensor([[ -1.3774, -22.1528],
        [ -8.6347,  -7.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22465363144874573
Epoch 0, Step 4893: train/loss = 0.024478880688548088, train/raw-loss = 0.00028640078380703926, train/logprobs = tensor([[ -1.2735, -13.7091],
        [-10.3002,  -2.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24192479252815247
Epoch 0, Step 4894: train/loss = 0.027172258123755455, train/raw-loss = 0.0022270523477345705, train/logprobs = tensor([[ -1.1708, -13.0540],
        [ -7.7882,  -2.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24945206940174103
Epoch 0, Step 4895: train/loss = 0.026706844568252563, train/raw-loss = 0.0006334942299872637, train/logprobs = tensor([[ -1.5594, -14.7924],
        [-11.0478,  -3.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607334852218628
Epoch 0, Step 4896: train/loss = 0.02323850616812706, train/raw-loss = 0.001942208269611001, train/logprobs = tensor([[-1.2371, -9.5483],
        [-7.7008, -1.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21296298503875732
Epoch 0, Step 4897: train/loss = 0.02718239277601242, train/raw-loss = 0.0011906533036381006, train/logprobs = tensor([[ -1.0808, -13.9738],
        [ -8.0960,  -2.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25991740822792053
Epoch 0, Step 4898: train/loss = 0.028064660727977753, train/raw-loss = 0.002638220554217696, train/logprobs = tensor([[ -0.8667, -16.7468],
        [ -6.8882,  -3.4370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542644143104553
Epoch 0, Step 4899: train/loss = 0.023460891097784042, train/raw-loss = 0.001691814512014389, train/logprobs = tensor([[ -1.2730, -15.0670],
        [ -7.2545,  -3.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21769076585769653
Epoch 0, Step 4900: train/loss = 0.03255961462855339, train/raw-loss = 0.007952513173222542, train/logprobs = tensor([[ -1.5897,  -7.5554],
        [-10.4399,  -1.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2460710108280182
Epoch 0, Step 4901: train/loss = 0.020806141197681427, train/raw-loss = 0.0011830723378807306, train/logprobs = tensor([[ -3.1016, -16.0439],
        [-11.0566,  -3.2834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962306797504425
Epoch 0, Step 4902: train/loss = 0.025775980204343796, train/raw-loss = 0.0013411870459094644, train/logprobs = tensor([[ -1.4682, -10.3462],
        [-10.4252,  -2.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24434794485569
Epoch 0, Step 4903: train/loss = 0.02723463997244835, train/raw-loss = 0.0012092744000256062, train/logprobs = tensor([[ -1.2292, -11.7766],
        [ -7.9208,  -2.6740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602536678314209
Epoch 0, Step 4904: train/loss = 0.03273722901940346, train/raw-loss = 0.003591625252738595, train/logprobs = tensor([[ -0.8795, -16.6520],
        [ -6.6077,  -3.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29145604372024536
Epoch 0, Step 4905: train/loss = 0.044908370822668076, train/raw-loss = 0.017683736979961395, train/logprobs = tensor([[ -1.1160, -15.0663],
        [ -8.3911,  -4.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722463011741638
Epoch 0, Step 4906: train/loss = 0.026123013347387314, train/raw-loss = 0.0006581783527508378, train/logprobs = tensor([[ -1.5657, -14.5272],
        [ -9.5624,  -3.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2546483278274536
Epoch 0, Step 4907: train/loss = 0.02615915611386299, train/raw-loss = 0.0037678354419767857, train/logprobs = tensor([[ -0.9698, -15.8121],
        [ -6.4693,  -2.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22391319274902344
Epoch 0, Step 4908: train/loss = 0.028373485431075096, train/raw-loss = 0.002029815688729286, train/logprobs = tensor([[ -1.2603, -11.3046],
        [ -9.4948,  -2.5861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634367048740387
Epoch 0, Step 4909: train/loss = 0.030006350949406624, train/raw-loss = 0.0010598998051136732, train/logprobs = tensor([[ -1.0124, -14.6582],
        [ -7.4152,  -2.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28946453332901
Epoch 0, Step 4910: train/loss = 0.02280573919415474, train/raw-loss = 0.0017774079460650682, train/logprobs = tensor([[ -1.2708, -10.0508],
        [ -7.3447,  -1.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102833092212677
Epoch 0, Step 4911: train/loss = 0.023801764473319054, train/raw-loss = 0.001303999568335712, train/logprobs = tensor([[ -1.0615, -13.0756],
        [ -7.4870,  -2.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22497762739658356
Epoch 0, Step 4912: train/loss = 0.028763465583324432, train/raw-loss = 0.0062680309638381, train/logprobs = tensor([[ -0.8549, -17.0301],
        [ -6.5547,  -3.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22495433688163757
Epoch 0, Step 4913: train/loss = 0.027294272556900978, train/raw-loss = 0.0028348092455416918, train/logprobs = tensor([[ -1.0145, -13.1710],
        [ -7.7075,  -2.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24459463357925415
Epoch 0, Step 4914: train/loss = 0.02704194188117981, train/raw-loss = 0.004580135457217693, train/logprobs = tensor([[ -0.9162, -15.2461],
        [ -6.1657,  -3.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224618062376976
Epoch 0, Step 4915: train/loss = 0.02360091358423233, train/raw-loss = 0.0009488664800301194, train/logprobs = tensor([[ -0.9548, -16.3145],
        [ -8.9826,  -4.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22652046382427216
Epoch 0, Step 4916: train/loss = 0.03329961746931076, train/raw-loss = 0.007965018972754478, train/logprobs = tensor([[ -0.8381, -13.6625],
        [ -6.6873,  -3.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25334596633911133
Epoch 0, Step 4917: train/loss = 0.023582743480801582, train/raw-loss = 0.00036116718547418714, train/logprobs = tensor([[ -1.2548, -16.5550],
        [ -9.5420,  -4.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2322157621383667
Epoch 0, Step 4918: train/loss = 0.026880288496613503, train/raw-loss = 0.0036656600423157215, train/logprobs = tensor([[ -0.8739, -12.2281],
        [ -7.0647,  -3.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2321462780237198
Epoch 0, Step 4919: train/loss = 0.02718431130051613, train/raw-loss = 0.003070224542170763, train/logprobs = tensor([[ -1.1248, -14.4347],
        [ -7.2110,  -4.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24114084243774414
Epoch 0, Step 4920: train/loss = 0.028750041499733925, train/raw-loss = 0.0006299883243627846, train/logprobs = tensor([[ -1.5012, -13.8666],
        [ -9.0464,  -3.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28120049834251404
Epoch 0, Step 4921: train/loss = 0.024926483631134033, train/raw-loss = 0.0006881914450787008, train/logprobs = tensor([[ -1.8345, -15.7525],
        [ -9.8375,  -5.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24238291382789612
Epoch 0, Step 4922: train/loss = 0.02790379337966442, train/raw-loss = 0.0007279797573573887, train/logprobs = tensor([[ -1.3346, -14.2753],
        [ -8.6841,  -2.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27175813913345337
Epoch 0, Step 4923: train/loss = 0.027060218155384064, train/raw-loss = 0.0020967216696590185, train/logprobs = tensor([[ -1.0674, -15.7746],
        [ -7.3362,  -2.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24963496625423431
Epoch 0, Step 4924: train/loss = 0.02322821319103241, train/raw-loss = 0.0009641111828386784, train/logprobs = tensor([[ -1.3861, -12.3119],
        [ -8.7222,  -2.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2226410210132599
Epoch 0, Step 4925: train/loss = 0.02634473331272602, train/raw-loss = 0.0011201919987797737, train/logprobs = tensor([[ -1.4824, -15.1907],
        [ -8.5900,  -4.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25224539637565613
Epoch 0, Step 4926: train/loss = 0.02955026738345623, train/raw-loss = 0.004310970660299063, train/logprobs = tensor([[ -0.8809, -10.5653],
        [ -6.9372,  -1.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523929476737976
Epoch 0, Step 4927: train/loss = 0.025724630802869797, train/raw-loss = 0.00164764781948179, train/logprobs = tensor([[ -0.9841, -12.5012],
        [ -7.1464,  -2.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24076983332633972
Epoch 0, Step 4928: train/loss = 0.029960911720991135, train/raw-loss = 0.004467896185815334, train/logprobs = tensor([[ -0.9370, -15.6548],
        [ -8.2317,  -4.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25493013858795166
Epoch 0, Step 4929: train/loss = 0.04076395556330681, train/raw-loss = 0.015255781821906567, train/logprobs = tensor([[ -1.0650, -13.1489],
        [ -6.8280,  -4.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25508177280426025
Epoch 0, Step 4930: train/loss = 0.030902165919542313, train/raw-loss = 0.004565088078379631, train/logprobs = tensor([[ -1.1357, -12.6306],
        [ -7.8807,  -2.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633707523345947
Epoch 0, Step 4931: train/loss = 0.031548190861940384, train/raw-loss = 0.0020008431747555733, train/logprobs = tensor([[ -1.2290, -19.6263],
        [ -9.3795,  -5.6507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29547345638275146
Epoch 0, Step 4932: train/loss = 0.03027651458978653, train/raw-loss = 0.002026954898610711, train/logprobs = tensor([[ -1.0168, -14.4491],
        [ -9.0116,  -2.9987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2824955880641937
Epoch 0, Step 4933: train/loss = 0.027913540601730347, train/raw-loss = 0.0030515422113239765, train/logprobs = tensor([[ -1.1215, -13.5358],
        [ -7.1588,  -2.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24861997365951538
Epoch 0, Step 4934: train/loss = 0.03533019497990608, train/raw-loss = 0.014680566266179085, train/logprobs = tensor([[ -1.3729, -14.3536],
        [ -7.9302,  -2.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20649629831314087
Epoch 0, Step 4935: train/loss = 0.02781270630657673, train/raw-loss = 0.0045417677611112595, train/logprobs = tensor([[ -0.7730, -14.2342],
        [ -6.7247,  -3.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327093780040741
Epoch 0, Step 4936: train/loss = 0.057178203016519547, train/raw-loss = 0.032375410199165344, train/logprobs = tensor([[ -1.4397, -11.4489],
        [ -7.2414,  -3.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24802790582180023
Epoch 0, Step 4937: train/loss = 0.03037663735449314, train/raw-loss = 0.0011983842123299837, train/logprobs = tensor([[ -1.7450, -12.2322],
        [ -9.9196,  -2.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29178252816200256
Epoch 0, Step 4938: train/loss = 0.02668595314025879, train/raw-loss = 0.002620066050440073, train/logprobs = tensor([[ -1.3522, -17.3471],
        [ -8.8781,  -4.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24065887928009033
Epoch 0, Step 4939: train/loss = 0.027169037610292435, train/raw-loss = 0.002807886339724064, train/logprobs = tensor([[ -2.0678, -14.7346],
        [-10.5775,  -3.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24361151456832886
Epoch 0, Step 4940: train/loss = 0.027231987565755844, train/raw-loss = 0.0010756850242614746, train/logprobs = tensor([[ -0.9453, -17.6709],
        [ -8.3921,  -4.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615630030632019
Epoch 0, Step 4941: train/loss = 0.03188055381178856, train/raw-loss = 0.004970150534063578, train/logprobs = tensor([[ -1.0523, -12.6008],
        [ -6.9372,  -2.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691040635108948
Epoch 0, Step 4942: train/loss = 0.030162448063492775, train/raw-loss = 0.004919682163745165, train/logprobs = tensor([[ -1.3763, -16.3982],
        [ -9.1043,  -3.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524276673793793
Epoch 0, Step 4943: train/loss = 0.02567436173558235, train/raw-loss = 0.004220485221594572, train/logprobs = tensor([[ -1.3583, -12.9840],
        [ -6.8139,  -2.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21453875303268433
Epoch 0, Step 4944: train/loss = 0.025353960692882538, train/raw-loss = 0.001193225383758545, train/logprobs = tensor([[ -1.0674, -12.6884],
        [ -8.5788,  -1.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24160735309123993
Epoch 0, Step 4945: train/loss = 0.028476320207118988, train/raw-loss = 0.0010896227322518826, train/logprobs = tensor([[ -1.2244, -12.3003],
        [ -8.3980,  -3.5277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738669514656067
Epoch 0, Step 4946: train/loss = 0.024005543440580368, train/raw-loss = 0.0038347672671079636, train/logprobs = tensor([[ -1.6662, -19.1708],
        [ -7.3752,  -5.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20170775055885315
Epoch 0, Step 4947: train/loss = 0.02611077018082142, train/raw-loss = 0.00292380154132843, train/logprobs = tensor([[ -0.9595, -11.9187],
        [ -7.3329,  -2.8203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23186969757080078
Epoch 0, Step 4948: train/loss = 0.02846897765994072, train/raw-loss = 0.002145989565178752, train/logprobs = tensor([[ -1.6421, -11.3139],
        [ -9.6951,  -2.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632298469543457
Epoch 0, Step 4949: train/loss = 0.027284709736704826, train/raw-loss = 0.0012082066386938095, train/logprobs = tensor([[ -1.2929, -11.0677],
        [ -8.4903,  -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260765016078949
Epoch 0, Step 4950: train/loss = 0.029281675815582275, train/raw-loss = 0.0045545222237706184, train/logprobs = tensor([[ -0.9260, -12.8426],
        [ -7.7675,  -3.4407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2472715526819229
Epoch 0, Step 4951: train/loss = 0.029348358511924744, train/raw-loss = 0.0006575518636964262, train/logprobs = tensor([[-1.1791, -9.8532],
        [-9.4017, -1.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869080603122711
Epoch 0, Step 4952: train/loss = 0.030607402324676514, train/raw-loss = 0.0053003751672804356, train/logprobs = tensor([[ -1.8880, -15.2184],
        [-11.0328,  -4.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25307026505470276
Epoch 0, Step 4953: train/loss = 0.028544440865516663, train/raw-loss = 0.0036091292276978493, train/logprobs = tensor([[ -0.7416, -12.5506],
        [ -6.2748,  -3.2758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24935312569141388
Epoch 0, Step 4954: train/loss = 0.026919735595583916, train/raw-loss = 0.004578778985887766, train/logprobs = tensor([[-1.0560, -8.8682],
        [-7.3686, -1.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22340954840183258
Epoch 0, Step 4955: train/loss = 0.024763358756899834, train/raw-loss = 0.001323790056630969, train/logprobs = tensor([[ -1.4104, -15.6801],
        [ -8.7414,  -4.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23439566791057587
Epoch 0, Step 4956: train/loss = 0.026951178908348083, train/raw-loss = 0.002545003779232502, train/logprobs = tensor([[ -0.7988, -15.7999],
        [ -6.9941,  -3.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24406176805496216
Epoch 0, Step 4957: train/loss = 0.023765582591295242, train/raw-loss = 0.00033163605257868767, train/logprobs = tensor([[ -1.2533, -13.4837],
        [-10.9357,  -2.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23433946073055267
Epoch 0, Step 4958: train/loss = 0.028317155316472054, train/raw-loss = 0.003826481755822897, train/logprobs = tensor([[ -0.7472, -13.1370],
        [ -7.1054,  -4.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449067234992981
Epoch 0, Step 4959: train/loss = 0.03182341158390045, train/raw-loss = 0.006043381989002228, train/logprobs = tensor([[-1.0751, -8.9580],
        [-8.5622, -1.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25780028104782104
Epoch 0, Step 4960: train/loss = 0.03231875225901604, train/raw-loss = 0.008430027402937412, train/logprobs = tensor([[ -1.3176, -16.3044],
        [-10.1450,  -4.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2388872504234314
Epoch 0, Step 4961: train/loss = 0.031164750456809998, train/raw-loss = 0.00863836333155632, train/logprobs = tensor([[ -0.6451, -15.8463],
        [ -5.3807,  -4.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22526387870311737
Epoch 0, Step 4962: train/loss = 0.02979339472949505, train/raw-loss = 0.005856194533407688, train/logprobs = tensor([[ -0.6150, -12.1915],
        [ -5.4933,  -2.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23937200009822845
Epoch 0, Step 4963: train/loss = 0.043410103768110275, train/raw-loss = 0.019584665074944496, train/logprobs = tensor([[ -0.7191, -13.2190],
        [ -6.6484,  -2.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2382543832063675
Epoch 0, Step 4964: train/loss = 0.026400983333587646, train/raw-loss = 0.003111789468675852, train/logprobs = tensor([[ -1.2163, -13.8382],
        [ -7.4226,  -3.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23289194703102112
Epoch 0, Step 4965: train/loss = 0.025413040071725845, train/raw-loss = 0.004227259196341038, train/logprobs = tensor([[ -1.4906, -14.3645],
        [ -8.6729,  -2.7595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21185779571533203
Epoch 0, Step 4966: train/loss = 0.024314237758517265, train/raw-loss = 0.0012007479090243578, train/logprobs = tensor([[ -1.2140, -15.3653],
        [ -8.4338,  -3.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23113487660884857
Epoch 0, Step 4967: train/loss = 0.027862146496772766, train/raw-loss = 0.005119613371789455, train/logprobs = tensor([[ -1.1804, -11.9518],
        [ -8.1823,  -4.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22742530703544617
Epoch 0, Step 4968: train/loss = 0.024774983525276184, train/raw-loss = 0.001376963104121387, train/logprobs = tensor([[ -1.2606, -12.3735],
        [ -9.4122,  -2.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339801788330078
Epoch 0, Step 4969: train/loss = 0.029123226180672646, train/raw-loss = 0.002156483242288232, train/logprobs = tensor([[ -0.7696, -14.1917],
        [ -6.5950,  -3.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26966744661331177
Epoch 0, Step 4970: train/loss = 0.028533942997455597, train/raw-loss = 0.002094993833452463, train/logprobs = tensor([[ -0.9939, -16.0125],
        [ -7.9332,  -2.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643894851207733
Epoch 0, Step 4971: train/loss = 0.024106044322252274, train/raw-loss = 0.0012949698138982058, train/logprobs = tensor([[ -1.2541, -11.7077],
        [ -8.4882,  -2.5453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22811073064804077
Epoch 0, Step 4972: train/loss = 0.09075139462947845, train/raw-loss = 0.06921140849590302, train/logprobs = tensor([[ -1.2294, -10.7726],
        [ -7.4967,  -2.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2153998464345932
Epoch 0, Step 4973: train/loss = 0.0461861677467823, train/raw-loss = 0.020937571302056313, train/logprobs = tensor([[-1.2288, -9.5516],
        [-8.1067, -1.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524859309196472
Epoch 0, Step 4974: train/loss = 0.0271555595099926, train/raw-loss = 0.0023101670667529106, train/logprobs = tensor([[ -0.8434, -11.2186],
        [ -6.5494,  -2.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24845390021800995
Epoch 0, Step 4975: train/loss = 0.023413967341184616, train/raw-loss = 0.0012672352604568005, train/logprobs = tensor([[ -1.2323, -16.4514],
        [ -9.2732,  -2.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22146731615066528
Epoch 0, Step 4976: train/loss = 0.030121654272079468, train/raw-loss = 0.0011171703226864338, train/logprobs = tensor([[ -0.9731, -17.7708],
        [ -7.8010,  -4.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900448441505432
Epoch 0, Step 4977: train/loss = 0.029867980629205704, train/raw-loss = 0.003427133895456791, train/logprobs = tensor([[ -1.2633, -12.3181],
        [ -8.6041,  -2.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644084692001343
Epoch 0, Step 4978: train/loss = 0.028494130820035934, train/raw-loss = 0.000584560155402869, train/logprobs = tensor([[ -1.3048, -14.1369],
        [ -9.1552,  -3.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27909567952156067
Epoch 0, Step 4979: train/loss = 0.02687024511396885, train/raw-loss = 0.002440675627440214, train/logprobs = tensor([[ -1.1346, -13.0619],
        [ -8.7144,  -3.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24429568648338318
Epoch 0, Step 4980: train/loss = 0.02728462405502796, train/raw-loss = 0.0006835510721430182, train/logprobs = tensor([[ -1.9705, -12.5313],
        [-10.1760,  -3.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26601070165634155
Epoch 0, Step 4981: train/loss = 0.025959093123674393, train/raw-loss = 0.002346630208194256, train/logprobs = tensor([[ -1.4164, -11.8293],
        [ -8.5632,  -2.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23612463474273682
Epoch 0, Step 4982: train/loss = 0.030149495229125023, train/raw-loss = 0.007103108800947666, train/logprobs = tensor([[-1.3950, -8.5200],
        [-7.5813, -2.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23046386241912842
Epoch 0, Step 4983: train/loss = 0.02522660605609417, train/raw-loss = 0.004909150768071413, train/logprobs = tensor([[ -0.9943, -13.2441],
        [ -7.4682,  -4.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20317456126213074
Epoch 0, Step 4984: train/loss = 0.02702615037560463, train/raw-loss = 0.001365814357995987, train/logprobs = tensor([[ -1.1420, -11.7347],
        [ -7.8006,  -3.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566033601760864
Epoch 0, Step 4985: train/loss = 0.04749248921871185, train/raw-loss = 0.025637369602918625, train/logprobs = tensor([[ -1.3404, -15.8687],
        [ -6.8056,  -4.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21855120360851288
Epoch 0, Step 4986: train/loss = 0.024913005530834198, train/raw-loss = 0.0024596601724624634, train/logprobs = tensor([[ -1.4403, -20.4701],
        [ -7.5051,  -4.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22453345358371735
Epoch 0, Step 4987: train/loss = 0.029033616185188293, train/raw-loss = 0.003425837028771639, train/logprobs = tensor([[ -1.1881, -14.7429],
        [ -7.5140,  -3.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2560777962207794
Epoch 0, Step 4988: train/loss = 0.029485052451491356, train/raw-loss = 0.0008351608412340283, train/logprobs = tensor([[ -0.8768, -12.1338],
        [ -8.1226,  -1.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28649890422821045
Epoch 0, Step 4989: train/loss = 0.027464238926768303, train/raw-loss = 0.0025752319488674402, train/logprobs = tensor([[ -0.9546, -13.9012],
        [ -7.1730,  -2.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24889004230499268
Epoch 0, Step 4990: train/loss = 0.025077514350414276, train/raw-loss = 9.009926725411788e-05, train/logprobs = tensor([[ -1.2032, -15.5445],
        [-12.2108,  -4.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24987414479255676
Epoch 0, Step 4991: train/loss = 0.03293266519904137, train/raw-loss = 0.007010860834270716, train/logprobs = tensor([[ -0.9991, -11.1184],
        [ -6.8959,  -2.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592180371284485
Epoch 0, Step 4992: train/loss = 0.02981295809149742, train/raw-loss = 0.0022081779316067696, train/logprobs = tensor([[ -1.3168, -18.1797],
        [ -8.3780,  -4.4974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27604779601097107
Epoch 0, Step 4993: train/loss = 0.02780405804514885, train/raw-loss = 0.00514152692630887, train/logprobs = tensor([[ -1.1389, -14.0299],
        [ -6.2535,  -3.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22662532329559326
Epoch 0, Step 4994: train/loss = 0.03003522753715515, train/raw-loss = 0.0031245083082467318, train/logprobs = tensor([[ -1.1406, -13.0822],
        [ -7.2093,  -3.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691071927547455
Epoch 0, Step 4995: train/loss = 0.027201618999242783, train/raw-loss = 0.00298246368765831, train/logprobs = tensor([[ -0.7754, -11.5458],
        [ -6.8592,  -2.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24219152331352234
Epoch 0, Step 4996: train/loss = 0.02741897478699684, train/raw-loss = 0.0033274111337959766, train/logprobs = tensor([[ -1.1874, -12.8862],
        [ -8.3295,  -2.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24091562628746033
Epoch 0, Step 4997: train/loss = 0.029904408380389214, train/raw-loss = 0.004716702736914158, train/logprobs = tensor([[ -1.0465, -17.8179],
        [ -6.7529,  -4.4453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518770694732666
Epoch 0, Step 4998: train/loss = 0.0267491415143013, train/raw-loss = 0.0011920792749151587, train/logprobs = tensor([[ -1.4239, -12.0333],
        [ -9.0941,  -2.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555706202983856
Epoch 0, Step 4999: train/loss = 0.029105978086590767, train/raw-loss = 0.0019448765087872744, train/logprobs = tensor([[ -1.5074, -11.9315],
        [ -9.4725,  -2.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27161097526550293
Epoch 0, Step 5000: train/loss = 0.03156907111406326, train/raw-loss = 0.009960445575416088, train/logprobs = tensor([[-1.2449, -9.1039],
        [-5.7304, -1.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2160862386226654
Epoch 0, Step 5001: train/loss = 0.024983804672956467, train/raw-loss = 0.0012283463729545474, train/logprobs = tensor([[ -1.2540, -16.4066],
        [ -8.5890,  -4.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23755457997322083
Epoch 0, Step 5002: train/loss = 0.02897172048687935, train/raw-loss = 0.0021426742896437645, train/logprobs = tensor([[ -1.1013, -12.6569],
        [ -8.3580,  -2.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682904601097107
Epoch 0, Step 5003: train/loss = 0.025577055290341377, train/raw-loss = 0.0019773347303271294, train/logprobs = tensor([[ -1.1120, -15.1127],
        [ -7.6504,  -4.8785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23599720001220703
Epoch 0, Step 5004: train/loss = 0.029070831835269928, train/raw-loss = 0.002513849176466465, train/logprobs = tensor([[ -1.2119, -11.9099],
        [ -8.2392,  -3.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265569806098938
Epoch 0, Step 5005: train/loss = 0.027529744431376457, train/raw-loss = 0.003228007582947612, train/logprobs = tensor([[ -1.1943, -12.5370],
        [ -7.2868,  -3.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24301737546920776
Epoch 0, Step 5006: train/loss = 0.025698916986584663, train/raw-loss = 0.003137823659926653, train/logprobs = tensor([[ -1.8775, -14.7177],
        [-10.3039,  -2.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2256109118461609
Epoch 0, Step 5007: train/loss = 0.034251973032951355, train/raw-loss = 0.008839781396090984, train/logprobs = tensor([[ -0.8646, -13.1096],
        [ -5.5631,  -2.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25412192940711975
Epoch 0, Step 5008: train/loss = 0.041821226477622986, train/raw-loss = 0.01785566844046116, train/logprobs = tensor([[ -1.5969, -14.1198],
        [ -8.6982,  -3.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23965555429458618
Epoch 0, Step 5009: train/loss = 0.023029623553156853, train/raw-loss = 0.000815080595202744, train/logprobs = tensor([[ -2.1383, -14.9487],
        [ -9.2437,  -1.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2221454381942749
Epoch 0, Step 5010: train/loss = 0.02696039155125618, train/raw-loss = 0.0015716650523245335, train/logprobs = tensor([[-1.2455, -9.7958],
        [-8.3063, -1.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25388726592063904
Epoch 0, Step 5011: train/loss = 0.028025109320878983, train/raw-loss = 0.005211361683905125, train/logprobs = tensor([[ -0.9756, -16.3679],
        [ -7.0546,  -5.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22813749313354492
Epoch 0, Step 5012: train/loss = 0.028813418000936508, train/raw-loss = 0.002031629905104637, train/logprobs = tensor([[ -0.7125, -15.3384],
        [ -6.3867,  -4.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267817884683609
Epoch 0, Step 5013: train/loss = 0.026072828099131584, train/raw-loss = 0.0016669405158609152, train/logprobs = tensor([[ -1.7000, -11.8180],
        [ -8.4489,  -3.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24405887722969055
Epoch 0, Step 5014: train/loss = 0.02625475451350212, train/raw-loss = 0.00402803672477603, train/logprobs = tensor([[ -0.8977, -11.6929],
        [ -6.4727,  -2.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22226718068122864
Epoch 0, Step 5015: train/loss = 0.028073972091078758, train/raw-loss = 0.0019567874260246754, train/logprobs = tensor([[ -0.7620, -11.5265],
        [ -6.7114,  -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.261171817779541
Epoch 0, Step 5016: train/loss = 0.056396663188934326, train/raw-loss = 0.03358147293329239, train/logprobs = tensor([[ -0.8569, -13.8682],
        [ -6.3562,  -4.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22815190255641937
Epoch 0, Step 5017: train/loss = 0.028433583676815033, train/raw-loss = 0.0032208655029535294, train/logprobs = tensor([[ -1.3010, -12.9873],
        [ -8.3894,  -2.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25212720036506653
Epoch 0, Step 5018: train/loss = 0.025363828986883163, train/raw-loss = 0.0004632426134776324, train/logprobs = tensor([[ -1.6617, -14.2216],
        [-11.5597,  -2.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24900583922863007
Epoch 0, Step 5019: train/loss = 0.028143957257270813, train/raw-loss = 0.005067191086709499, train/logprobs = tensor([[ -0.7411, -17.3718],
        [ -5.7963,  -5.0687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076766729354858
Epoch 0, Step 5020: train/loss = 0.027068058028817177, train/raw-loss = 0.0046144528314471245, train/logprobs = tensor([[ -1.0763, -16.9340],
        [ -6.4473,  -4.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22453606128692627
Epoch 0, Step 5021: train/loss = 0.028380393981933594, train/raw-loss = 0.0038190868217498064, train/logprobs = tensor([[ -1.4741, -10.4169],
        [ -7.4573,  -2.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24561306834220886
Epoch 0, Step 5022: train/loss = 0.026922136545181274, train/raw-loss = 0.0019982606172561646, train/logprobs = tensor([[ -0.7888, -16.5872],
        [ -6.4739,  -4.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492387294769287
Epoch 0, Step 5023: train/loss = 0.02895890548825264, train/raw-loss = 0.0009058981668204069, train/logprobs = tensor([[ -1.2994, -14.9615],
        [ -8.8640,  -4.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28053006529808044
Epoch 0, Step 5024: train/loss = 0.028771784156560898, train/raw-loss = 0.003464645240455866, train/logprobs = tensor([[ -0.7971, -13.8686],
        [ -7.0420,  -3.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530713677406311
Epoch 0, Step 5025: train/loss = 0.02694898098707199, train/raw-loss = 0.0015121285105124116, train/logprobs = tensor([[-1.6132, -9.7644],
        [-9.7435, -1.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25436854362487793
Epoch 0, Step 5026: train/loss = 0.025646677240729332, train/raw-loss = 0.0028037196025252342, train/logprobs = tensor([[ -1.0006, -14.3334],
        [ -6.4768,  -3.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22842957079410553
Epoch 0, Step 5027: train/loss = 0.028975967317819595, train/raw-loss = 0.0002394600451225415, train/logprobs = tensor([[ -1.6644, -12.9981],
        [-12.5565,  -3.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873650789260864
Epoch 0, Step 5028: train/loss = 0.028297659009695053, train/raw-loss = 0.0022741230204701424, train/logprobs = tensor([[ -0.9194, -10.9144],
        [ -6.5905,  -2.6585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26023533940315247
Epoch 0, Step 5029: train/loss = 0.025436868891119957, train/raw-loss = 0.0028677345253527164, train/logprobs = tensor([[ -1.3772, -15.0671],
        [ -7.7879,  -3.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22569133341312408
Epoch 0, Step 5030: train/loss = 0.023610638454556465, train/raw-loss = 0.001023775665089488, train/logprobs = tensor([[ -0.9230, -17.3692],
        [ -7.6593,  -4.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2258685976266861
Epoch 0, Step 5031: train/loss = 0.026416946202516556, train/raw-loss = 0.002114972099661827, train/logprobs = tensor([[ -0.9449, -11.2097],
        [ -7.7074,  -2.3364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2430197298526764
Epoch 0, Step 5032: train/loss = 0.03089325688779354, train/raw-loss = 0.00745124276727438, train/logprobs = tensor([[ -2.1672, -13.8844],
        [ -9.4073,  -4.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23442015051841736
Epoch 0, Step 5033: train/loss = 0.028583243489265442, train/raw-loss = 0.00787800271064043, train/logprobs = tensor([[ -1.0839, -16.5151],
        [ -8.0447,  -4.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20705239474773407
Epoch 0, Step 5034: train/loss = 0.09103573113679886, train/raw-loss = 0.06586622446775436, train/logprobs = tensor([[-0.9833, -8.6396],
        [-7.2126, -2.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25169509649276733
Epoch 0, Step 5035: train/loss = 0.026551399379968643, train/raw-loss = 0.00474521704018116, train/logprobs = tensor([[ -0.8625, -13.4430],
        [ -6.0668,  -2.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21806180477142334
Epoch 0, Step 5036: train/loss = 0.02765916846692562, train/raw-loss = 0.004448815248906612, train/logprobs = tensor([[ -0.8022, -12.4682],
        [ -7.1962,  -2.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23210354149341583
Epoch 0, Step 5037: train/loss = 0.03247718885540962, train/raw-loss = 0.012385924346745014, train/logprobs = tensor([[ -1.3175, -17.0694],
        [ -8.2094,  -4.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20091265439987183
Epoch 0, Step 5038: train/loss = 0.025144923478364944, train/raw-loss = 0.002229223260655999, train/logprobs = tensor([[ -1.0170, -13.6264],
        [ -7.4501,  -3.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291569858789444
Epoch 0, Step 5039: train/loss = 0.026654943823814392, train/raw-loss = 0.0010877252789214253, train/logprobs = tensor([[ -1.1633, -12.9474],
        [ -8.0526,  -2.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556721866130829
Epoch 0, Step 5040: train/loss = 0.028070420026779175, train/raw-loss = 0.0029811100102961063, train/logprobs = tensor([[ -1.5084, -11.4843],
        [ -9.3041,  -2.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25089311599731445
Epoch 0, Step 5041: train/loss = 0.025973234325647354, train/raw-loss = 0.0007353250402957201, train/logprobs = tensor([[ -1.5377, -12.3822],
        [-10.6787,  -3.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25237908959388733
Epoch 0, Step 5042: train/loss = 0.028691407293081284, train/raw-loss = 0.003522369312122464, train/logprobs = tensor([[ -1.7749, -12.3529],
        [ -9.2988,  -2.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516903579235077
Epoch 0, Step 5043: train/loss = 0.028145411983132362, train/raw-loss = 0.002643946325406432, train/logprobs = tensor([[ -1.2107, -14.3651],
        [ -7.9218,  -3.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25501465797424316
Epoch 0, Step 5044: train/loss = 0.029765158891677856, train/raw-loss = 0.005880314856767654, train/logprobs = tensor([[ -1.2434, -14.0252],
        [ -8.4035,  -3.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23884844779968262
Epoch 0, Step 5045: train/loss = 0.026654982939362526, train/raw-loss = 0.0037582172080874443, train/logprobs = tensor([[ -1.0723, -13.7975],
        [ -6.6679,  -3.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22896763682365417
Epoch 0, Step 5046: train/loss = 0.025426210835576057, train/raw-loss = 0.002014361321926117, train/logprobs = tensor([[ -1.4132, -17.0132],
        [ -8.9525,  -4.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2341184765100479
Epoch 0, Step 5047: train/loss = 0.03421549126505852, train/raw-loss = 0.011664207093417645, train/logprobs = tensor([[ -1.1829, -12.4932],
        [ -7.2471,  -2.6682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22551283240318298
Epoch 0, Step 5048: train/loss = 0.021533265709877014, train/raw-loss = 0.0006514170090667903, train/logprobs = tensor([[ -1.2896, -18.5734],
        [ -8.5157,  -4.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088184654712677
Epoch 0, Step 5049: train/loss = 0.026294417679309845, train/raw-loss = 0.002184432465583086, train/logprobs = tensor([[ -1.5250, -11.2860],
        [ -8.4780,  -2.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24109984934329987
Epoch 0, Step 5050: train/loss = 0.023643221706151962, train/raw-loss = 0.0005735147278755903, train/logprobs = tensor([[ -1.6091, -12.5922],
        [ -8.9194,  -3.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23069706559181213
Epoch 0, Step 5051: train/loss = 0.03788578510284424, train/raw-loss = 0.012896678410470486, train/logprobs = tensor([[ -1.3810, -10.9591],
        [-10.5331,  -2.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24989105761051178
Epoch 0, Step 5052: train/loss = 0.024504046887159348, train/raw-loss = 0.0023864740505814552, train/logprobs = tensor([[ -0.9430, -13.5655],
        [ -7.9514,  -2.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22117571532726288
Epoch 0, Step 5053: train/loss = 0.02779255248606205, train/raw-loss = 0.0009663976961746812, train/logprobs = tensor([[ -1.4485, -10.3977],
        [-10.6713,  -2.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26826155185699463
Epoch 0, Step 5054: train/loss = 0.025374313816428185, train/raw-loss = 0.0011893456103280187, train/logprobs = tensor([[ -1.7308, -19.0527],
        [ -8.0979,  -3.3842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24184966087341309
Epoch 0, Step 5055: train/loss = 0.026458658277988434, train/raw-loss = 0.007429097313433886, train/logprobs = tensor([[ -1.1877, -13.4684],
        [ -8.3013,  -3.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19029560685157776
Epoch 0, Step 5056: train/loss = 0.024521321058273315, train/raw-loss = 0.0011698611779138446, train/logprobs = tensor([[ -1.0543, -16.2060],
        [ -7.2623,  -3.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23351459205150604
Epoch 0, Step 5057: train/loss = 0.029410379007458687, train/raw-loss = 0.005335771478712559, train/logprobs = tensor([[ -0.8298, -11.5908],
        [ -5.9210,  -1.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24074608087539673
Epoch 0, Step 5058: train/loss = 0.028031039983034134, train/raw-loss = 0.0008201194577850401, train/logprobs = tensor([[ -1.0814, -12.4454],
        [ -8.4867,  -3.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27210918068885803
Epoch 0, Step 5059: train/loss = 0.02664012834429741, train/raw-loss = 0.0012184816878288984, train/logprobs = tensor([[ -1.0844, -15.4140],
        [ -9.1326,  -2.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542164623737335
Epoch 0, Step 5060: train/loss = 0.026422962546348572, train/raw-loss = 0.00020211603259667754, train/logprobs = tensor([[ -1.9303, -16.0208],
        [-10.2529,  -4.2478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2622084617614746
Epoch 0, Step 5061: train/loss = 0.028843166306614876, train/raw-loss = 0.0035220154095441103, train/logprobs = tensor([[ -0.7287, -12.9709],
        [ -6.1623,  -2.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25321152806282043
Epoch 0, Step 5062: train/loss = 0.03252231329679489, train/raw-loss = 0.0022485260851681232, train/logprobs = tensor([[ -0.5935, -11.8548],
        [ -6.4356,  -3.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30273786187171936
Epoch 0, Step 5063: train/loss = 0.02429135888814926, train/raw-loss = 0.0018472797237336636, train/logprobs = tensor([[ -1.6015, -19.9039],
        [ -8.9382,  -3.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2244407832622528
Epoch 0, Step 5064: train/loss = 0.026537269353866577, train/raw-loss = 0.0014149278867989779, train/logprobs = tensor([[ -1.3186, -10.0199],
        [ -9.2543,  -2.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512234151363373
Epoch 0, Step 5065: train/loss = 0.02493239752948284, train/raw-loss = 0.0012813928769901395, train/logprobs = tensor([[ -1.2083, -13.9946],
        [ -8.8216,  -3.1224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365100383758545
Epoch 0, Step 5066: train/loss = 0.02504618838429451, train/raw-loss = 0.003363397903740406, train/logprobs = tensor([[ -1.3669, -11.8523],
        [ -6.7839,  -2.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2168278992176056
Epoch 0, Step 5067: train/loss = 0.02911314181983471, train/raw-loss = 0.005427482072263956, train/logprobs = tensor([[ -1.0530, -14.1043],
        [ -7.2156,  -3.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368565797805786
Epoch 0, Step 5068: train/loss = 0.029748346656560898, train/raw-loss = 0.0064215813763439655, train/logprobs = tensor([[ -0.7465, -17.0035],
        [ -6.2862,  -4.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2332676500082016
Epoch 0, Step 5069: train/loss = 0.027308665215969086, train/raw-loss = 0.004412541631609201, train/logprobs = tensor([[ -1.1250, -10.2840],
        [ -6.6554,  -2.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22896124422550201
Epoch 0, Step 5070: train/loss = 0.028508834540843964, train/raw-loss = 0.0018377647502347827, train/logprobs = tensor([[ -1.2052, -14.7806],
        [ -9.1089,  -3.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26671069860458374
Epoch 0, Step 5071: train/loss = 0.029263611882925034, train/raw-loss = 0.004920783452689648, train/logprobs = tensor([[ -1.0102, -14.0537],
        [ -6.5144,  -2.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24342826008796692
Epoch 0, Step 5072: train/loss = 0.023917745798826218, train/raw-loss = 0.0004338977742008865, train/logprobs = tensor([[ -1.6241, -14.5361],
        [ -9.1253,  -2.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23483847081661224
Epoch 0, Step 5073: train/loss = 0.026994524523615837, train/raw-loss = 0.0041880058124661446, train/logprobs = tensor([[ -1.3749, -13.4469],
        [ -8.1605,  -2.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22806516289710999
Epoch 0, Step 5074: train/loss = 0.028623266145586967, train/raw-loss = 0.0048962486907839775, train/logprobs = tensor([[ -0.8977, -14.1633],
        [ -6.2503,  -3.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23727017641067505
Epoch 0, Step 5075: train/loss = 0.03722318634390831, train/raw-loss = 0.015415683388710022, train/logprobs = tensor([[ -1.4140, -11.7914],
        [ -6.3738,  -2.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180750072002411
Epoch 0, Step 5076: train/loss = 0.034464746713638306, train/raw-loss = 0.00911893229931593, train/logprobs = tensor([[ -1.1249, -19.9837],
        [ -7.2494,  -3.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534581422805786
Epoch 0, Step 5077: train/loss = 0.03682360798120499, train/raw-loss = 0.013417636044323444, train/logprobs = tensor([[ -1.2401, -13.9020],
        [ -5.5800,  -2.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23405972123146057
Epoch 0, Step 5078: train/loss = 0.025742720812559128, train/raw-loss = 0.0026498695369809866, train/logprobs = tensor([[ -1.3912, -13.3536],
        [ -8.0081,  -2.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23092851042747498
Epoch 0, Step 5079: train/loss = 0.029366038739681244, train/raw-loss = 0.003603511955589056, train/logprobs = tensor([[ -1.2536, -14.1497],
        [ -7.4920,  -3.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576252520084381
Epoch 0, Step 5080: train/loss = 0.024492701515555382, train/raw-loss = 0.0005772343138232827, train/logprobs = tensor([[ -0.9338, -17.1185],
        [ -8.6413,  -4.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2391546666622162
Epoch 0, Step 5081: train/loss = 0.035835105925798416, train/raw-loss = 0.014594703912734985, train/logprobs = tensor([[ -1.1037, -11.2206],
        [ -5.4196,  -2.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2124040126800537
Epoch 0, Step 5082: train/loss = 0.03140062466263771, train/raw-loss = 0.0011587702902033925, train/logprobs = tensor([[ -1.3290, -15.3330],
        [ -8.7670,  -2.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3024185299873352
Epoch 0, Step 5083: train/loss = 0.026299912482500076, train/raw-loss = 0.002966356696560979, train/logprobs = tensor([[ -0.7214, -12.1545],
        [ -6.1322,  -2.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23333558440208435
Epoch 0, Step 5084: train/loss = 0.026522235944867134, train/raw-loss = 0.000896554789505899, train/logprobs = tensor([[ -1.1850, -12.0330],
        [ -9.2159,  -2.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562568187713623
Epoch 0, Step 5085: train/loss = 0.03984507545828819, train/raw-loss = 0.01933816634118557, train/logprobs = tensor([[ -1.5579, -16.5722],
        [ -7.1482,  -4.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20506910979747772
Epoch 0, Step 5086: train/loss = 0.029292108491063118, train/raw-loss = 0.005515821743756533, train/logprobs = tensor([[ -1.3552, -13.6960],
        [ -8.3761,  -4.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23776285350322723
Epoch 0, Step 5087: train/loss = 0.02784600481390953, train/raw-loss = 0.0014994892990216613, train/logprobs = tensor([[ -0.7799, -21.1187],
        [ -6.6972,  -4.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26346516609191895
Epoch 0, Step 5088: train/loss = 0.02656935155391693, train/raw-loss = 0.0018143558409065008, train/logprobs = tensor([[ -0.8723, -13.6446],
        [ -6.8535,  -3.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24754995107650757
Epoch 0, Step 5089: train/loss = 0.028115205466747284, train/raw-loss = 0.0027983970940113068, train/logprobs = tensor([[ -0.9841, -16.3433],
        [ -7.1318,  -3.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531680762767792
Epoch 0, Step 5090: train/loss = 0.030297547578811646, train/raw-loss = 0.004992051050066948, train/logprobs = tensor([[ -1.2272, -11.2477],
        [ -8.0416,  -2.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530549466609955
Epoch 0, Step 5091: train/loss = 0.026615271344780922, train/raw-loss = 0.0011394261382520199, train/logprobs = tensor([[ -1.1415, -14.8321],
        [ -9.0642,  -3.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25475844740867615
Epoch 0, Step 5092: train/loss = 0.022988146170973778, train/raw-loss = 0.0006554914871230721, train/logprobs = tensor([[ -0.7426, -16.8112],
        [ -7.9870,  -5.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22332654893398285
Epoch 0, Step 5093: train/loss = 0.0673789456486702, train/raw-loss = 0.041415393352508545, train/logprobs = tensor([[-1.2879, -7.0557],
        [-7.8942, -2.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596355080604553
Epoch 0, Step 5094: train/loss = 0.027753474190831184, train/raw-loss = 0.0025177830830216408, train/logprobs = tensor([[ -1.3086, -13.6346],
        [ -7.6317,  -3.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523568868637085
Epoch 0, Step 5095: train/loss = 0.025359133258461952, train/raw-loss = 0.0003235630865674466, train/logprobs = tensor([[ -1.3379, -17.7870],
        [ -9.8536,  -4.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25035569071769714
Epoch 0, Step 5096: train/loss = 0.029842469841241837, train/raw-loss = 0.00539957033470273, train/logprobs = tensor([[ -1.0893, -14.5943],
        [ -6.2614,  -3.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24442897737026215
Epoch 0, Step 5097: train/loss = 0.026299918070435524, train/raw-loss = 0.0014600093709304929, train/logprobs = tensor([[ -1.1313, -18.3492],
        [ -8.4428,  -3.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24839907884597778
Epoch 0, Step 5098: train/loss = 0.025251181796193123, train/raw-loss = 0.004713680595159531, train/logprobs = tensor([[ -0.4865, -14.9070],
        [ -5.4009,  -4.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20537501573562622
Epoch 0, Step 5099: train/loss = 0.029143720865249634, train/raw-loss = 0.002378840232267976, train/logprobs = tensor([[ -1.2053, -14.3099],
        [ -6.9236,  -4.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676488161087036
Epoch 0, Step 5100: train/loss = 0.02465916983783245, train/raw-loss = 0.0009010728681460023, train/logprobs = tensor([[ -1.5366, -15.2240],
        [ -8.2465,  -3.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23758095502853394
Epoch 0, Step 5101: train/loss = 0.026310443878173828, train/raw-loss = 0.003084867959842086, train/logprobs = tensor([[ -1.1163, -11.4834],
        [ -6.6890,  -3.2320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.232255756855011
Epoch 0, Step 5102: train/loss = 0.024858586490154266, train/raw-loss = 0.002971059177070856, train/logprobs = tensor([[ -1.8029, -15.9087],
        [ -7.8475,  -3.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21887527406215668
Epoch 0, Step 5103: train/loss = 0.02690718322992325, train/raw-loss = 0.0019559096544981003, train/logprobs = tensor([[ -0.9503, -12.7793],
        [ -7.2010,  -2.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495127171278
Epoch 0, Step 5104: train/loss = 0.020981233566999435, train/raw-loss = 0.0003495514392852783, train/logprobs = tensor([[ -1.2935, -14.7871],
        [ -9.2258,  -3.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20631682872772217
Epoch 0, Step 5105: train/loss = 0.037367671728134155, train/raw-loss = 0.008229203522205353, train/logprobs = tensor([[-1.5080, -9.8388],
        [-6.1353, -2.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913846969604492
Epoch 0, Step 5106: train/loss = 0.023493971675634384, train/raw-loss = 0.0013971077278256416, train/logprobs = tensor([[ -0.9251, -18.3966],
        [ -7.4680,  -4.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22096864879131317
Epoch 0, Step 5107: train/loss = 0.02368125319480896, train/raw-loss = 0.00210405420511961, train/logprobs = tensor([[ -0.8034, -14.6667],
        [ -6.9723,  -2.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21577195823192596
Epoch 0, Step 5108: train/loss = 0.02319256216287613, train/raw-loss = 0.0006209064158611, train/logprobs = tensor([[ -1.3899, -13.8941],
        [ -8.8692,  -3.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22571654617786407
Epoch 0, Step 5109: train/loss = 0.027543269097805023, train/raw-loss = 0.006331853102892637, train/logprobs = tensor([[ -0.9006, -13.8739],
        [ -6.6380,  -4.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2121141403913498
Epoch 0, Step 5110: train/loss = 0.025115009397268295, train/raw-loss = 0.0018490874208509922, train/logprobs = tensor([[ -1.4027, -10.4001],
        [ -8.6911,  -3.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2326592206954956
Epoch 0, Step 5111: train/loss = 0.024261057376861572, train/raw-loss = 0.0035625845193862915, train/logprobs = tensor([[ -0.9076, -11.8706],
        [ -6.9521,  -2.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2069847285747528
Epoch 0, Step 5112: train/loss = 0.024603744968771935, train/raw-loss = 0.0015146688092499971, train/logprobs = tensor([[ -0.9062, -13.3873],
        [ -6.9620,  -3.1010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23089075088500977
Epoch 0, Step 5113: train/loss = 0.026208510622382164, train/raw-loss = 0.000662073609419167, train/logprobs = tensor([[ -1.2902, -17.2452],
        [ -8.8060,  -3.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2554643750190735
Epoch 0, Step 5114: train/loss = 0.032768603414297104, train/raw-loss = 0.006831876002252102, train/logprobs = tensor([[ -1.1616, -18.8545],
        [ -7.0100,  -4.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25936728715896606
Epoch 0, Step 5115: train/loss = 0.025910554453730583, train/raw-loss = 0.0009729572338983417, train/logprobs = tensor([[ -1.0989, -14.2752],
        [ -8.4618,  -3.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24937599897384644
Epoch 0, Step 5116: train/loss = 0.03614750877022743, train/raw-loss = 0.012416579760611057, train/logprobs = tensor([[ -1.4962, -11.6758],
        [ -6.5297,  -4.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2373092919588089
Epoch 0, Step 5117: train/loss = 0.04097774624824524, train/raw-loss = 0.021216735243797302, train/logprobs = tensor([[ -1.4508, -13.4558],
        [ -7.0140,  -1.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19761008024215698
Epoch 0, Step 5118: train/loss = 0.06133853644132614, train/raw-loss = 0.035858314484357834, train/logprobs = tensor([[ -1.0140, -10.2814],
        [ -7.7123,  -2.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25480222702026367
Epoch 0, Step 5119: train/loss = 0.025003574788570404, train/raw-loss = 0.003684611525386572, train/logprobs = tensor([[ -1.0750, -11.2613],
        [ -6.5505,  -2.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21318963170051575
Epoch 0, Step 5120: train/loss = 0.026761401444673538, train/raw-loss = 0.0024725033435970545, train/logprobs = tensor([[ -1.0429, -10.5049],
        [ -7.7277,  -2.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24288898706436157
Epoch 0, Step 5121: train/loss = 0.027872001752257347, train/raw-loss = 0.002236462663859129, train/logprobs = tensor([[ -1.0991, -12.2837],
        [ -7.2542,  -3.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2563554048538208
Epoch 0, Step 5122: train/loss = 0.02873297967016697, train/raw-loss = 0.0016473920550197363, train/logprobs = tensor([[ -0.9694, -11.5575],
        [ -7.8373,  -1.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708559036254883
Epoch 0, Step 5123: train/loss = 0.027401842176914215, train/raw-loss = 0.0025621182285249233, train/logprobs = tensor([[ -0.9591, -11.0607],
        [ -6.6656,  -1.6136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24839724600315094
Epoch 0, Step 5124: train/loss = 0.02387760393321514, train/raw-loss = 0.0029173081275075674, train/logprobs = tensor([[ -0.9620, -12.1243],
        [ -6.6217,  -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.209602952003479
Epoch 0, Step 5125: train/loss = 0.034815602004528046, train/raw-loss = 0.00870552659034729, train/logprobs = tensor([[-1.9578, -8.1506],
        [-8.6746, -1.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26110076904296875
Epoch 0, Step 5126: train/loss = 0.027135608717799187, train/raw-loss = 0.0018422617577016354, train/logprobs = tensor([[ -0.9192, -14.3308],
        [ -7.0525,  -2.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25293347239494324
Epoch 0, Step 5127: train/loss = 0.02706354670226574, train/raw-loss = 0.0018372812774032354, train/logprobs = tensor([[ -0.8576, -15.6589],
        [ -7.1274,  -2.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522626519203186
Epoch 0, Step 5128: train/loss = 0.025306295603513718, train/raw-loss = 0.00185788341332227, train/logprobs = tensor([[ -1.4690, -14.2028],
        [ -8.3131,  -2.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23448410630226135
Epoch 0, Step 5129: train/loss = 0.028221413493156433, train/raw-loss = 0.004441733937710524, train/logprobs = tensor([[ -1.0671, -14.6689],
        [ -7.2287,  -3.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23779679834842682
Epoch 0, Step 5130: train/loss = 0.030799919739365578, train/raw-loss = 0.0068527692928910255, train/logprobs = tensor([[ -1.1485, -14.2735],
        [ -7.1987,  -4.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2394714653491974
Epoch 0, Step 5131: train/loss = 0.028174709528684616, train/raw-loss = 0.005002650897949934, train/logprobs = tensor([[ -0.9484, -13.9835],
        [ -6.3776,  -3.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23172059655189514
Epoch 0, Step 5132: train/loss = 0.028551805764436722, train/raw-loss = 0.0017261754255741835, train/logprobs = tensor([[ -1.3050, -10.4200],
        [ -9.5547,  -2.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268256276845932
Epoch 0, Step 5133: train/loss = 0.03766456991434097, train/raw-loss = 0.013834943063557148, train/logprobs = tensor([[ -1.0856, -10.3526],
        [ -8.0185,  -3.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.238296240568161
Epoch 0, Step 5134: train/loss = 0.024650219827890396, train/raw-loss = 0.002608086448162794, train/logprobs = tensor([[ -0.9310, -15.9694],
        [ -6.5000,  -2.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22042131423950195
Epoch 0, Step 5135: train/loss = 0.027068790048360825, train/raw-loss = 0.0006621622596867383, train/logprobs = tensor([[ -1.5454, -12.2713],
        [ -8.8517,  -1.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26406627893447876
Epoch 0, Step 5136: train/loss = 0.02606012672185898, train/raw-loss = 0.0038093351759016514, train/logprobs = tensor([[ -1.6769, -15.7971],
        [ -8.8696,  -4.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22250789403915405
Epoch 0, Step 5137: train/loss = 0.030830051749944687, train/raw-loss = 0.0077330246567726135, train/logprobs = tensor([[ -1.5738, -10.5736],
        [ -7.8448,  -3.3518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23097024857997894
Epoch 0, Step 5138: train/loss = 0.0825071632862091, train/raw-loss = 0.06127388775348663, train/logprobs = tensor([[ -1.6170, -10.7971],
        [ -4.4890,  -2.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2123328000307083
Epoch 0, Step 5139: train/loss = 0.030051348730921745, train/raw-loss = 0.0048617166467010975, train/logprobs = tensor([[ -1.1946, -12.8466],
        [ -7.3164,  -2.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25189632177352905
Epoch 0, Step 5140: train/loss = 0.026097647845745087, train/raw-loss = 0.0032053347676992416, train/logprobs = tensor([[ -0.9507, -14.5920],
        [ -6.1971,  -3.4127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22892312705516815
Epoch 0, Step 5141: train/loss = 0.027791261672973633, train/raw-loss = 0.004320717882364988, train/logprobs = tensor([[ -0.9569, -12.9265],
        [ -7.6996,  -3.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23470541834831238
Epoch 0, Step 5142: train/loss = 0.026268988847732544, train/raw-loss = 0.007111570332199335, train/logprobs = tensor([[ -0.9276, -12.4359],
        [ -5.3991,  -2.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19157418608665466
Epoch 0, Step 5143: train/loss = 0.0399114266037941, train/raw-loss = 0.013307454064488411, train/logprobs = tensor([[ -1.5199, -14.1516],
        [ -9.9462,  -3.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26603972911834717
Epoch 0, Step 5144: train/loss = 0.05007560923695564, train/raw-loss = 0.025099296122789383, train/logprobs = tensor([[ -1.0177, -13.9731],
        [ -6.1381,  -4.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2497631311416626
Epoch 0, Step 5145: train/loss = 0.02861427329480648, train/raw-loss = 0.0030978918075561523, train/logprobs = tensor([[ -1.4012, -13.9381],
        [ -7.5392,  -3.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551637887954712
Epoch 0, Step 5146: train/loss = 0.03185044974088669, train/raw-loss = 0.006696526426821947, train/logprobs = tensor([[ -1.4997,  -8.8064],
        [-10.2437,  -2.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515392601490021
Epoch 0, Step 5147: train/loss = 0.025865109637379646, train/raw-loss = 0.0013750893995165825, train/logprobs = tensor([[ -1.0948, -12.4545],
        [ -8.4654,  -2.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449001967906952
Epoch 0, Step 5148: train/loss = 0.027675192803144455, train/raw-loss = 0.00339397881180048, train/logprobs = tensor([[ -1.0396, -15.2156],
        [ -7.3191,  -4.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2428121417760849
Epoch 0, Step 5149: train/loss = 0.03374309092760086, train/raw-loss = 0.009438707493245602, train/logprobs = tensor([[ -1.2365, -14.3767],
        [ -8.2565,  -4.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24304383993148804
Epoch 0, Step 5150: train/loss = 0.03800153732299805, train/raw-loss = 0.011526163667440414, train/logprobs = tensor([[ -0.9971, -12.4605],
        [ -6.5842,  -2.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647537291049957
Epoch 0, Step 5151: train/loss = 0.02702108770608902, train/raw-loss = 0.004531916696578264, train/logprobs = tensor([[ -2.0759, -14.2754],
        [ -7.5850,  -4.0057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22489172220230103
Epoch 0, Step 5152: train/loss = 0.030311278998851776, train/raw-loss = 0.005641855299472809, train/logprobs = tensor([[ -0.7528, -13.4871],
        [ -5.3146,  -4.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24669423699378967
Epoch 0, Step 5153: train/loss = 0.02796318009495735, train/raw-loss = 0.0010768650099635124, train/logprobs = tensor([[ -1.5256, -13.5985],
        [ -8.8608,  -4.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26886314153671265
Epoch 0, Step 5154: train/loss = 0.03070998564362526, train/raw-loss = 0.005603746511042118, train/logprobs = tensor([[ -0.7290, -11.1759],
        [ -5.5188,  -2.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25106239318847656
Epoch 0, Step 5155: train/loss = 0.029714860022068024, train/raw-loss = 0.006470936816185713, train/logprobs = tensor([[ -1.2086, -15.8800],
        [ -7.3298,  -4.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23243921995162964
Epoch 0, Step 5156: train/loss = 0.025997119024395943, train/raw-loss = 0.005168968811631203, train/logprobs = tensor([[ -0.6197, -15.4373],
        [ -5.4473,  -2.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2082815021276474
Epoch 0, Step 5157: train/loss = 0.03035452589392662, train/raw-loss = 0.003915754612535238, train/logprobs = tensor([[ -1.3446, -14.4519],
        [ -6.2393,  -2.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26438769698143005
Epoch 0, Step 5158: train/loss = 0.023831484839320183, train/raw-loss = 0.004210934974253178, train/logprobs = tensor([[ -1.0583, -15.1368],
        [ -6.2033,  -4.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962054967880249
Epoch 0, Step 5159: train/loss = 0.02686230279505253, train/raw-loss = 0.004065141547471285, train/logprobs = tensor([[ -0.8253, -19.4971],
        [ -6.9366,  -5.6689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.227971613407135
Epoch 0, Step 5160: train/loss = 0.022991778329014778, train/raw-loss = 0.0006958924932405353, train/logprobs = tensor([[ -1.3549, -15.8574],
        [ -9.2147,  -4.4639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22295886278152466
Epoch 0, Step 5161: train/loss = 0.02296908013522625, train/raw-loss = 0.002103472827002406, train/logprobs = tensor([[ -1.3545, -17.1848],
        [ -7.4770,  -4.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20865605771541595
Epoch 0, Step 5162: train/loss = 0.08732615411281586, train/raw-loss = 0.06400484591722488, train/logprobs = tensor([[ -1.7589, -11.9377],
        [ -7.1266,  -2.6653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23321308195590973
Epoch 0, Step 5163: train/loss = 0.02737782709300518, train/raw-loss = 0.0057541197165846825, train/logprobs = tensor([[ -1.2570, -12.6669],
        [ -8.2840,  -3.5000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21623709797859192
Epoch 0, Step 5164: train/loss = 0.02710505947470665, train/raw-loss = 0.004367499146610498, train/logprobs = tensor([[ -1.0260, -15.0956],
        [ -6.6599,  -3.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273755967617035
Epoch 0, Step 5165: train/loss = 0.025160865858197212, train/raw-loss = 0.0021862019784748554, train/logprobs = tensor([[ -1.3261, -20.3876],
        [ -8.0529,  -5.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22974663972854614
Epoch 0, Step 5166: train/loss = 0.02556905336678028, train/raw-loss = 0.001381067093461752, train/logprobs = tensor([[ -1.0471, -19.0791],
        [ -7.0064,  -4.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24187985062599182
Epoch 0, Step 5167: train/loss = 0.025715559720993042, train/raw-loss = 0.0018968668300658464, train/logprobs = tensor([[ -1.3554, -15.6431],
        [ -7.3321,  -3.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23818692564964294
Epoch 0, Step 5168: train/loss = 0.025743085891008377, train/raw-loss = 0.0030254125595092773, train/logprobs = tensor([[ -1.3450, -15.7450],
        [ -9.1019,  -4.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2271767258644104
Epoch 0, Step 5169: train/loss = 0.02544058859348297, train/raw-loss = 0.0030123686883598566, train/logprobs = tensor([[ -1.4492, -13.3030],
        [ -7.5434,  -3.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22428220510482788
Epoch 0, Step 5170: train/loss = 0.023979321122169495, train/raw-loss = 0.0011740822810679674, train/logprobs = tensor([[ -1.1863, -19.8948],
        [ -9.2516,  -5.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22805239260196686
Epoch 0, Step 5171: train/loss = 0.026618706062436104, train/raw-loss = 0.002885977504774928, train/logprobs = tensor([[ -0.8857, -10.1546],
        [ -7.2093,  -2.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23732727766036987
Epoch 0, Step 5172: train/loss = 0.025832543149590492, train/raw-loss = 0.002206176985055208, train/logprobs = tensor([[ -1.2353, -15.5911],
        [ -8.4116,  -3.3200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23626366257667542
Epoch 0, Step 5173: train/loss = 0.02410806342959404, train/raw-loss = 0.00015096178685780615, train/logprobs = tensor([[ -1.3609, -16.4021],
        [-10.3628,  -4.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395710051059723
Epoch 0, Step 5174: train/loss = 0.025403495877981186, train/raw-loss = 0.0036562008317559958, train/logprobs = tensor([[ -1.1891, -15.8161],
        [ -6.5135,  -3.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21747291088104248
Epoch 0, Step 5175: train/loss = 0.02480723336338997, train/raw-loss = 0.0019052026327699423, train/logprobs = tensor([[ -1.8180,  -9.5854],
        [-10.7243,  -1.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22902029752731323
Epoch 0, Step 5176: train/loss = 0.027441145852208138, train/raw-loss = 0.0023015199694782495, train/logprobs = tensor([[ -1.0214, -15.9279],
        [ -6.5763,  -3.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513962388038635
Epoch 0, Step 5177: train/loss = 0.042304638773202896, train/raw-loss = 0.017884571105241776, train/logprobs = tensor([[ -1.3380, -11.5912],
        [ -6.6445,  -2.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2442006766796112
Epoch 0, Step 5178: train/loss = 0.031559281051158905, train/raw-loss = 0.0046867565251886845, train/logprobs = tensor([[ -1.0072, -12.0067],
        [ -7.4244,  -4.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26872527599334717
Epoch 0, Step 5179: train/loss = 0.03189852461218834, train/raw-loss = 0.005001795012503862, train/logprobs = tensor([[ -1.1517, -11.0002],
        [ -7.8874,  -2.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26896730065345764
Epoch 0, Step 5180: train/loss = 0.028269769623875618, train/raw-loss = 0.0035408902913331985, train/logprobs = tensor([[ -1.1920, -11.9335],
        [ -8.8071,  -2.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2472887933254242
Epoch 0, Step 5181: train/loss = 0.043277621269226074, train/raw-loss = 0.019684582948684692, train/logprobs = tensor([[ -0.8464, -10.4894],
        [ -5.4720,  -3.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235930398106575
Epoch 0, Step 5182: train/loss = 0.03036094829440117, train/raw-loss = 0.010342324152588844, train/logprobs = tensor([[ -1.1879, -15.7520],
        [ -6.3032,  -3.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20018623769283295
Epoch 0, Step 5183: train/loss = 0.024887949228286743, train/raw-loss = 0.0015937216812744737, train/logprobs = tensor([[ -1.2758, -14.7791],
        [ -7.2118,  -3.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23294228315353394
Epoch 0, Step 5184: train/loss = 0.02305980958044529, train/raw-loss = 0.0013472835998982191, train/logprobs = tensor([[ -0.7101, -19.4577],
        [ -7.0745,  -5.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21712525188922882
Epoch 0, Step 5185: train/loss = 0.028956662863492966, train/raw-loss = 0.004435824695974588, train/logprobs = tensor([[ -1.1454, -12.7162],
        [ -7.6693,  -3.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24520835280418396
Epoch 0, Step 5186: train/loss = 0.025047583505511284, train/raw-loss = 0.0005563145969063044, train/logprobs = tensor([[ -1.2413, -18.5859],
        [ -8.5682,  -2.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24491269886493683
Epoch 0, Step 5187: train/loss = 0.029190456494688988, train/raw-loss = 0.0037575899623334408, train/logprobs = tensor([[ -0.9139, -17.0664],
        [ -6.9744,  -3.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543286383152008
Epoch 0, Step 5188: train/loss = 0.027602702379226685, train/raw-loss = 0.005067918915301561, train/logprobs = tensor([[ -0.9299, -13.8943],
        [ -5.8968,  -3.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253478318452835
Epoch 0, Step 5189: train/loss = 0.0330331064760685, train/raw-loss = 0.004053541459143162, train/logprobs = tensor([[-1.1235, -9.0453],
        [-7.8190, -1.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897956371307373
Epoch 0, Step 5190: train/loss = 0.024800656363368034, train/raw-loss = 0.0007985364645719528, train/logprobs = tensor([[ -1.1654, -18.5822],
        [ -8.7905,  -4.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24002119898796082
Epoch 0, Step 5191: train/loss = 0.0295927245169878, train/raw-loss = 0.005861927289515734, train/logprobs = tensor([[ -1.3492, -10.1499],
        [ -6.7945,  -1.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23730796575546265
Epoch 0, Step 5192: train/loss = 0.025571228936314583, train/raw-loss = 0.0010207247687503695, train/logprobs = tensor([[ -1.2891, -11.8909],
        [-10.0225,  -2.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24550503492355347
Epoch 0, Step 5193: train/loss = 0.029154855757951736, train/raw-loss = 0.002321595326066017, train/logprobs = tensor([[ -1.3513, -12.4004],
        [ -8.2722,  -2.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2683326005935669
Epoch 0, Step 5194: train/loss = 0.027911631390452385, train/raw-loss = 0.0023558521643280983, train/logprobs = tensor([[ -1.3453, -17.5168],
        [ -8.9176,  -4.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555577754974365
Epoch 0, Step 5195: train/loss = 0.14826072752475739, train/raw-loss = 0.1264825165271759, train/logprobs = tensor([[ -1.5925, -10.8251],
        [ -6.0757,  -1.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.217782124876976
Epoch 0, Step 5196: train/loss = 0.027348259463906288, train/raw-loss = 0.004871472716331482, train/logprobs = tensor([[ -0.8558, -13.7538],
        [ -5.8158,  -3.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22476786375045776
Epoch 0, Step 5197: train/loss = 0.02666090615093708, train/raw-loss = 0.001905011828057468, train/logprobs = tensor([[ -1.1557, -18.1091],
        [ -8.4703,  -3.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24755892157554626
Epoch 0, Step 5198: train/loss = 0.07244984060525894, train/raw-loss = 0.04845745861530304, train/logprobs = tensor([[ -0.9637, -10.0184],
        [ -6.8605,  -3.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23992380499839783
Epoch 0, Step 5199: train/loss = 0.027220837771892548, train/raw-loss = 0.0040801893919706345, train/logprobs = tensor([[ -1.0812, -12.4352],
        [ -7.6471,  -3.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23140646517276764
Epoch 0, Step 5200: train/loss = 0.02453674003481865, train/raw-loss = 0.0015367779415100813, train/logprobs = tensor([[ -1.2358, -14.9661],
        [ -7.2156,  -3.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2299996018409729
Epoch 0, Step 5201: train/loss = 0.02760108932852745, train/raw-loss = 0.0035555667709559202, train/logprobs = tensor([[ -1.1699, -12.6413],
        [ -6.9740,  -2.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2404552400112152
Epoch 0, Step 5202: train/loss = 0.029863029718399048, train/raw-loss = 0.006137169897556305, train/logprobs = tensor([[ -1.1197, -13.1957],
        [ -6.2869,  -3.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23725859820842743
Epoch 0, Step 5203: train/loss = 0.026140235364437103, train/raw-loss = 0.0012841401621699333, train/logprobs = tensor([[ -1.0702, -12.7516],
        [ -8.0227,  -2.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24856095016002655
Epoch 0, Step 5204: train/loss = 0.02838698774576187, train/raw-loss = 0.006392877548933029, train/logprobs = tensor([[ -1.0329, -11.3616],
        [ -5.5587,  -2.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21994110941886902
Epoch 0, Step 5205: train/loss = 0.023020099848508835, train/raw-loss = 0.00136578269302845, train/logprobs = tensor([[ -1.2673, -17.1004],
        [ -9.0871,  -3.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21654316782951355
Epoch 0, Step 5206: train/loss = 0.028152458369731903, train/raw-loss = 0.004494683351367712, train/logprobs = tensor([[ -1.1440, -17.3985],
        [ -6.6180,  -2.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23657774925231934
Epoch 0, Step 5207: train/loss = 0.02362685650587082, train/raw-loss = 0.002047448419034481, train/logprobs = tensor([[ -1.2434, -17.0438],
        [ -7.8192,  -4.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21579407155513763
Epoch 0, Step 5208: train/loss = 0.026724226772785187, train/raw-loss = 0.006316028069704771, train/logprobs = tensor([[ -1.1002, -15.4444],
        [ -5.8246,  -2.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20408201217651367
Epoch 0, Step 5209: train/loss = 0.024204758927226067, train/raw-loss = 0.002307251328602433, train/logprobs = tensor([[ -1.3623, -13.6538],
        [ -7.7452,  -3.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21897506713867188
Epoch 0, Step 5210: train/loss = 0.03201344609260559, train/raw-loss = 0.006580258719623089, train/logprobs = tensor([[ -1.0456, -16.7477],
        [ -6.9137,  -4.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543318569660187
Epoch 0, Step 5211: train/loss = 0.02968459576368332, train/raw-loss = 0.0051276180893182755, train/logprobs = tensor([[ -1.5780, -12.5498],
        [ -9.6086,  -3.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24556978046894073
Epoch 0, Step 5212: train/loss = 0.03666166216135025, train/raw-loss = 0.010676965117454529, train/logprobs = tensor([[ -1.2056, -10.3764],
        [ -6.9398,  -2.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25984692573547363
Epoch 0, Step 5213: train/loss = 0.02506360597908497, train/raw-loss = 0.0009279215009883046, train/logprobs = tensor([[ -0.9470, -14.6209],
        [ -8.7977,  -3.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24135684967041016
Epoch 0, Step 5214: train/loss = 0.023987241089344025, train/raw-loss = 0.000108539272332564, train/logprobs = tensor([[ -1.7603, -18.0607],
        [-10.8538,  -4.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23878701031208038
Epoch 0, Step 5215: train/loss = 0.023059479892253876, train/raw-loss = 0.0017501593101769686, train/logprobs = tensor([[ -0.9761, -13.3790],
        [ -7.3265,  -3.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21309319138526917
Epoch 0, Step 5216: train/loss = 0.025149717926979065, train/raw-loss = 0.0013036916498094797, train/logprobs = tensor([[ -1.1084, -13.6963],
        [ -7.2423,  -3.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384602576494217
Epoch 0, Step 5217: train/loss = 0.027329422533512115, train/raw-loss = 0.0034681702964007854, train/logprobs = tensor([[ -1.5517, -13.0829],
        [ -7.3309,  -1.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23861251771450043
Epoch 0, Step 5218: train/loss = 0.026020722463726997, train/raw-loss = 0.0018797169905155897, train/logprobs = tensor([[ -1.0427, -18.0616],
        [ -7.8374,  -2.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414100468158722
Epoch 0, Step 5219: train/loss = 0.024537425488233566, train/raw-loss = 0.00040897802682593465, train/logprobs = tensor([[ -1.2501, -18.5299],
        [ -9.1435,  -5.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24128445982933044
Epoch 0, Step 5220: train/loss = 0.02323302999138832, train/raw-loss = 0.0007860605255700648, train/logprobs = tensor([[ -1.3020, -15.8869],
        [ -8.2591,  -3.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22446967661380768
Epoch 0, Step 5221: train/loss = 0.027101755142211914, train/raw-loss = 0.0023455859627574682, train/logprobs = tensor([[ -0.7863, -10.7702],
        [ -7.5484,  -2.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24756169319152832
Epoch 0, Step 5222: train/loss = 0.03043491207063198, train/raw-loss = 0.007245253771543503, train/logprobs = tensor([[ -1.0942, -17.1865],
        [ -6.3951,  -4.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318965643644333
Epoch 0, Step 5223: train/loss = 0.02714819461107254, train/raw-loss = 0.0005898750387132168, train/logprobs = tensor([[ -0.9469, -13.0948],
        [ -8.2894,  -3.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26558318734169006
Epoch 0, Step 5224: train/loss = 0.030944090336561203, train/raw-loss = 0.00580087723210454, train/logprobs = tensor([[ -0.8035, -10.8676],
        [ -5.5862,  -2.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514321208000183
Epoch 0, Step 5225: train/loss = 0.023820888251066208, train/raw-loss = 0.000910156755708158, train/logprobs = tensor([[ -1.1570, -13.8029],
        [ -7.8515,  -2.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291073203086853
Epoch 0, Step 5226: train/loss = 0.028809983283281326, train/raw-loss = 0.0029724726919084787, train/logprobs = tensor([[ -1.0092, -11.2551],
        [ -6.5592,  -2.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583751082420349
Epoch 0, Step 5227: train/loss = 0.024722974747419357, train/raw-loss = 0.002068593166768551, train/logprobs = tensor([[ -1.2249, -15.6721],
        [ -7.0742,  -4.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22654381394386292
Epoch 0, Step 5228: train/loss = 0.024668581783771515, train/raw-loss = 0.0007356553105637431, train/logprobs = tensor([[ -1.3229, -14.7679],
        [ -8.0448,  -4.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2393292486667633
Epoch 0, Step 5229: train/loss = 0.022517666220664978, train/raw-loss = 0.0008266305085271597, train/logprobs = tensor([[ -1.5936, -12.1712],
        [ -9.8021,  -2.1662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21691034734249115
Epoch 0, Step 5230: train/loss = 0.04436251521110535, train/raw-loss = 0.020128535106778145, train/logprobs = tensor([[-1.4888, -9.0999],
        [-7.1951, -2.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24233978986740112
Epoch 0, Step 5231: train/loss = 0.025851547718048096, train/raw-loss = 0.00079004792496562, train/logprobs = tensor([[ -1.3731, -12.2832],
        [ -8.6744,  -1.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506150007247925
Epoch 0, Step 5232: train/loss = 0.027922913432121277, train/raw-loss = 0.004519328474998474, train/logprobs = tensor([[ -0.6380, -18.1757],
        [ -5.8971,  -4.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23403584957122803
Epoch 0, Step 5233: train/loss = 0.029401449486613274, train/raw-loss = 0.0013880543410778046, train/logprobs = tensor([[ -0.9229, -15.2255],
        [ -7.0666,  -3.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801339626312256
Epoch 0, Step 5234: train/loss = 0.025906233116984367, train/raw-loss = 0.002897770144045353, train/logprobs = tensor([[ -1.5184, -16.4895],
        [ -8.1769,  -4.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.230084627866745
Epoch 0, Step 5235: train/loss = 0.03131934255361557, train/raw-loss = 0.006423193030059338, train/logprobs = tensor([[ -1.9049, -10.7136],
        [ -9.0088,  -2.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24896147847175598
Epoch 0, Step 5236: train/loss = 0.025719881057739258, train/raw-loss = 0.0024754884652793407, train/logprobs = tensor([[ -0.6796, -10.5734],
        [ -6.1728,  -2.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2324438989162445
Epoch 0, Step 5237: train/loss = 0.027787111699581146, train/raw-loss = 0.004789368715137243, train/logprobs = tensor([[ -1.5036, -18.2168],
        [ -8.5269,  -4.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22997742891311646
Epoch 0, Step 5238: train/loss = 0.02524385415017605, train/raw-loss = 0.0005569615168496966, train/logprobs = tensor([[ -1.3501, -17.9959],
        [ -8.4607,  -5.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24686893820762634
Epoch 0, Step 5239: train/loss = 0.034240059554576874, train/raw-loss = 0.011418374255299568, train/logprobs = tensor([[ -0.7350, -13.3206],
        [ -5.1996,  -2.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22821681201457977
Epoch 0, Step 5240: train/loss = 0.02621980383992195, train/raw-loss = 0.0028245418798178434, train/logprobs = tensor([[ -1.8459, -12.2801],
        [ -9.0413,  -4.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339526116847992
Epoch 0, Step 5241: train/loss = 0.02810516394674778, train/raw-loss = 0.003178016282618046, train/logprobs = tensor([[ -1.1585, -12.2884],
        [ -8.4632,  -2.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492714524269104
Epoch 0, Step 5242: train/loss = 0.0227850079536438, train/raw-loss = 0.0026154262013733387, train/logprobs = tensor([[ -1.9090, -16.3291],
        [ -7.9267,  -3.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20169579982757568
Epoch 0, Step 5243: train/loss = 0.032410815358161926, train/raw-loss = 0.01006314717233181, train/logprobs = tensor([[ -1.1258, -10.5844],
        [ -5.6133,  -2.3722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22347666323184967
Epoch 0, Step 5244: train/loss = 0.030690934509038925, train/raw-loss = 0.012039893306791782, train/logprobs = tensor([[ -1.7732, -21.2438],
        [ -9.1258,  -6.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18651041388511658
Epoch 0, Step 5245: train/loss = 0.06430546194314957, train/raw-loss = 0.04178636148571968, train/logprobs = tensor([[ -1.2128, -11.2993],
        [ -8.7401,  -3.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22519099712371826
Epoch 0, Step 5246: train/loss = 0.02681577205657959, train/raw-loss = 0.004303161520510912, train/logprobs = tensor([[ -1.1625, -14.7050],
        [ -7.8631,  -3.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22512610256671906
Epoch 0, Step 5247: train/loss = 0.02488837204873562, train/raw-loss = 0.0010640313848853111, train/logprobs = tensor([[ -1.3394, -12.4554],
        [ -8.7373,  -4.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23824340105056763
Epoch 0, Step 5248: train/loss = 0.031951021403074265, train/raw-loss = 0.008802881464362144, train/logprobs = tensor([[ -1.3721, -14.2307],
        [ -7.1825,  -3.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2314814031124115
Epoch 0, Step 5249: train/loss = 0.05661218613386154, train/raw-loss = 0.033021390438079834, train/logprobs = tensor([[-0.7075, -8.8675],
        [-5.4310, -2.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23590795695781708
Epoch 0, Step 5250: train/loss = 0.024172425270080566, train/raw-loss = 0.004946006927639246, train/logprobs = tensor([[ -0.7957, -15.2104],
        [ -6.2345,  -3.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19226416945457458
Epoch 0, Step 5251: train/loss = 0.02856897935271263, train/raw-loss = 0.001670037629082799, train/logprobs = tensor([[ -1.1172, -11.3321],
        [ -8.8967,  -2.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689893841743469
Epoch 0, Step 5252: train/loss = 0.051497310400009155, train/raw-loss = 0.02967548742890358, train/logprobs = tensor([[-1.4136, -9.6978],
        [-8.7270, -2.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21821826696395874
Epoch 0, Step 5253: train/loss = 0.02710113488137722, train/raw-loss = 0.0010923340450972319, train/logprobs = tensor([[ -1.1695, -12.8275],
        [ -8.2678,  -2.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600879967212677
Epoch 0, Step 5254: train/loss = 0.025245200842618942, train/raw-loss = 0.0013674345100298524, train/logprobs = tensor([[ -1.1419, -15.7981],
        [ -8.4843,  -4.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23877765238285065
Epoch 0, Step 5255: train/loss = 0.02472749911248684, train/raw-loss = 0.0021971198730170727, train/logprobs = tensor([[ -0.7520, -16.1011],
        [ -6.3391,  -3.9828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253037691116333
Epoch 0, Step 5256: train/loss = 0.029409512877464294, train/raw-loss = 0.005288910120725632, train/logprobs = tensor([[-1.1535, -8.4495],
        [-6.8023, -1.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24120603501796722
Epoch 0, Step 5257: train/loss = 0.03989915922284126, train/raw-loss = 0.014180733822286129, train/logprobs = tensor([[ -1.1189, -10.6297],
        [ -7.3062,  -2.2882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571842670440674
Epoch 0, Step 5258: train/loss = 0.03274741768836975, train/raw-loss = 0.006230982020497322, train/logprobs = tensor([[ -1.0199, -11.4408],
        [ -7.2087,  -2.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651643455028534
Epoch 0, Step 5259: train/loss = 0.027016587555408478, train/raw-loss = 0.001170783187262714, train/logprobs = tensor([[ -0.9958, -18.0011],
        [ -7.1750,  -4.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25845804810523987
Epoch 0, Step 5260: train/loss = 0.028199106454849243, train/raw-loss = 0.00634597335010767, train/logprobs = tensor([[ -1.2407, -12.5930],
        [ -8.0278,  -3.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853134036064148
Epoch 0, Step 5261: train/loss = 0.02437589131295681, train/raw-loss = 0.003086396958678961, train/logprobs = tensor([[ -1.1374, -13.5996],
        [ -6.8128,  -3.7330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21289494633674622
Epoch 0, Step 5262: train/loss = 0.025907279923558235, train/raw-loss = 0.002925359643995762, train/logprobs = tensor([[ -1.6538, -12.2217],
        [ -9.2101,  -2.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.229819193482399
Epoch 0, Step 5263: train/loss = 0.02359900251030922, train/raw-loss = 0.0018686273833736777, train/logprobs = tensor([[ -1.3110, -12.2265],
        [ -8.1984,  -2.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21730376780033112
Epoch 0, Step 5264: train/loss = 0.03249058872461319, train/raw-loss = 0.007571137044578791, train/logprobs = tensor([[ -1.0113, -12.5447],
        [ -7.4094,  -2.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24919453263282776
Epoch 0, Step 5265: train/loss = 0.026527881622314453, train/raw-loss = 0.004692282993346453, train/logprobs = tensor([[ -1.1413, -14.5330],
        [ -6.3958,  -3.0919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21835599839687347
Epoch 0, Step 5266: train/loss = 0.024199532344937325, train/raw-loss = 0.00323261646553874, train/logprobs = tensor([[ -1.2473, -13.3386],
        [ -7.2577,  -3.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20966917276382446
Epoch 0, Step 5267: train/loss = 0.02198694832623005, train/raw-loss = 0.0018981783650815487, train/logprobs = tensor([[ -1.2358, -13.7768],
        [ -9.1477,  -2.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20088768005371094
Epoch 0, Step 5268: train/loss = 0.030096687376499176, train/raw-loss = 0.00406658835709095, train/logprobs = tensor([[ -1.3609, -10.2441],
        [ -8.1792,  -2.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26030099391937256
Epoch 0, Step 5269: train/loss = 0.030411100015044212, train/raw-loss = 0.0036809700541198254, train/logprobs = tensor([[ -0.8024, -14.3472],
        [ -5.9109,  -3.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673013210296631
Epoch 0, Step 5270: train/loss = 0.033163007348775864, train/raw-loss = 0.013334301300346851, train/logprobs = tensor([[ -1.8605, -11.0897],
        [ -8.0448,  -2.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19828703999519348
Epoch 0, Step 5271: train/loss = 0.03170933201909065, train/raw-loss = 0.008685964159667492, train/logprobs = tensor([[ -1.1617, -15.1558],
        [ -6.0244,  -3.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23023366928100586
Epoch 0, Step 5272: train/loss = 0.023224350064992905, train/raw-loss = 0.0007393200066871941, train/logprobs = tensor([[ -1.3010, -15.6651],
        [ -8.2931,  -3.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22485029697418213
Epoch 0, Step 5273: train/loss = 0.026902910321950912, train/raw-loss = 0.0011756571475416422, train/logprobs = tensor([[ -1.6501, -13.4440],
        [ -9.3279,  -3.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25727254152297974
Epoch 0, Step 5274: train/loss = 0.027320876717567444, train/raw-loss = 0.004257143475115299, train/logprobs = tensor([[ -1.2671, -11.0376],
        [ -7.4048,  -2.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306373119354248
Epoch 0, Step 5275: train/loss = 0.02927635982632637, train/raw-loss = 0.0020632678642868996, train/logprobs = tensor([[ -1.0409, -12.7006],
        [ -8.1069,  -3.5802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27213093638420105
Epoch 0, Step 5276: train/loss = 0.024269355461001396, train/raw-loss = 0.00027736081392504275, train/logprobs = tensor([[ -1.1788, -21.4131],
        [ -9.8500,  -6.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23991993069648743
Epoch 0, Step 5277: train/loss = 0.02342134155333042, train/raw-loss = 0.0038737168069928885, train/logprobs = tensor([[ -1.2537, -16.3673],
        [ -6.5974,  -3.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.195476233959198
Epoch 0, Step 5278: train/loss = 0.027395226061344147, train/raw-loss = 0.0014359649503603578, train/logprobs = tensor([[ -1.1396, -13.6443],
        [ -7.8824,  -2.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25959259271621704
Epoch 0, Step 5279: train/loss = 0.026167944073677063, train/raw-loss = 0.003595567774027586, train/logprobs = tensor([[ -1.0697, -13.6186],
        [ -6.5819,  -3.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2257237583398819
Epoch 0, Step 5280: train/loss = 0.02634884975850582, train/raw-loss = 0.001700237742625177, train/logprobs = tensor([[ -1.3291, -17.6331],
        [ -9.2458,  -4.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464861124753952
Epoch 0, Step 5281: train/loss = 0.024937206879258156, train/raw-loss = 0.002576804254204035, train/logprobs = tensor([[ -2.4939, -12.3723],
        [ -9.8209,  -3.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236040234565735
Epoch 0, Step 5282: train/loss = 0.031806860119104385, train/raw-loss = 0.006520555820316076, train/logprobs = tensor([[ -1.3964, -14.8236],
        [ -7.9347,  -4.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2528630495071411
Epoch 0, Step 5283: train/loss = 0.03368762880563736, train/raw-loss = 0.010414451360702515, train/logprobs = tensor([[ -0.8918, -12.0925],
        [ -5.2928,  -2.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23273177444934845
Epoch 0, Step 5284: train/loss = 0.02621040865778923, train/raw-loss = 0.0014180243015289307, train/logprobs = tensor([[ -1.4540, -11.7987],
        [ -7.8515,  -2.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2479238212108612
Epoch 0, Step 5285: train/loss = 0.026749562472105026, train/raw-loss = 0.004461654461920261, train/logprobs = tensor([[ -1.2120, -14.9453],
        [ -7.7240,  -4.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22287911176681519
Epoch 0, Step 5286: train/loss = 0.02493061125278473, train/raw-loss = 0.001730999443680048, train/logprobs = tensor([[ -1.2281, -11.0329],
        [ -8.2053,  -1.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23199611902236938
Epoch 0, Step 5287: train/loss = 0.03098258748650551, train/raw-loss = 0.008964775130152702, train/logprobs = tensor([[ -1.0652, -16.3875],
        [ -6.0600,  -3.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22017812728881836
Epoch 0, Step 5288: train/loss = 0.032812513411045074, train/raw-loss = 0.006152788642793894, train/logprobs = tensor([[ -1.4961, -14.8817],
        [ -8.3353,  -2.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26659727096557617
Epoch 0, Step 5289: train/loss = 0.02962297573685646, train/raw-loss = 0.007749461568892002, train/logprobs = tensor([[ -1.1632, -14.7758],
        [ -6.8062,  -3.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21873514354228973
Epoch 0, Step 5290: train/loss = 0.024760397151112556, train/raw-loss = 0.004231744445860386, train/logprobs = tensor([[ -1.0312, -13.5497],
        [ -6.6802,  -3.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20528651773929596
Epoch 0, Step 5291: train/loss = 0.025760915130376816, train/raw-loss = 0.0009746266878210008, train/logprobs = tensor([[ -1.1834, -13.0143],
        [ -8.2681,  -2.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24786286056041718
Epoch 0, Step 5292: train/loss = 0.026060141623020172, train/raw-loss = 0.0030319455545395613, train/logprobs = tensor([[ -0.9799, -15.5364],
        [ -6.8150,  -3.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23028196394443512
Epoch 0, Step 5293: train/loss = 0.04161199554800987, train/raw-loss = 0.02138691209256649, train/logprobs = tensor([[ -1.4205, -18.7096],
        [ -5.7924,  -5.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20225077867507935
Epoch 0, Step 5294: train/loss = 0.02955055795609951, train/raw-loss = 0.007988126017153263, train/logprobs = tensor([[ -0.8712, -14.0010],
        [ -5.7683,  -2.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21562433242797852
Epoch 0, Step 5295: train/loss = 0.031173905357718468, train/raw-loss = 0.002970428206026554, train/logprobs = tensor([[ -1.7675, -12.9818],
        [ -8.9169,  -2.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2820347547531128
Epoch 0, Step 5296: train/loss = 0.028865201398730278, train/raw-loss = 0.0018163381610065699, train/logprobs = tensor([[ -1.3520, -13.0087],
        [ -8.2329,  -2.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2704886198043823
Epoch 0, Step 5297: train/loss = 0.024786612018942833, train/raw-loss = 0.003202978754416108, train/logprobs = tensor([[ -1.2977, -12.5926],
        [ -7.1672,  -1.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21583636105060577
Epoch 0, Step 5298: train/loss = 0.026691263541579247, train/raw-loss = 0.0024260764475911856, train/logprobs = tensor([[ -1.1462, -16.0058],
        [ -6.9541,  -4.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24265184998512268
Epoch 0, Step 5299: train/loss = 0.03349636495113373, train/raw-loss = 0.010520738549530506, train/logprobs = tensor([[ -0.8860, -11.8225],
        [ -7.0152,  -2.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22975626587867737
Epoch 0, Step 5300: train/loss = 0.028591522946953773, train/raw-loss = 0.005669004283845425, train/logprobs = tensor([[ -1.3530, -11.6280],
        [ -6.3021,  -2.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22922517359256744
Epoch 0, Step 5301: train/loss = 0.028302092105150223, train/raw-loss = 0.002209924627095461, train/logprobs = tensor([[ -1.2220, -14.6880],
        [ -9.1888,  -4.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609216570854187
Epoch 0, Step 5302: train/loss = 0.02915531024336815, train/raw-loss = 0.010694099590182304, train/logprobs = tensor([[ -1.3261, -16.5176],
        [ -6.6562,  -3.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18461211025714874
Epoch 0, Step 5303: train/loss = 0.029360689222812653, train/raw-loss = 0.006149543449282646, train/logprobs = tensor([[-0.7649, -9.3870],
        [-5.3821, -1.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23211145401000977
Epoch 0, Step 5304: train/loss = 0.02647673897445202, train/raw-loss = 0.0024320075754076242, train/logprobs = tensor([[ -0.7876, -13.2200],
        [ -6.6823,  -2.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24044732749462128
Epoch 0, Step 5305: train/loss = 0.043352823704481125, train/raw-loss = 0.02078917622566223, train/logprobs = tensor([[ -1.4372, -10.8495],
        [ -7.1601,  -2.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22563645243644714
Epoch 0, Step 5306: train/loss = 0.02773553878068924, train/raw-loss = 0.0007804324268363416, train/logprobs = tensor([[ -1.4840, -10.5886],
        [ -8.8129,  -2.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2695510685443878
Epoch 0, Step 5307: train/loss = 0.023751484230160713, train/raw-loss = 0.0024871970526874065, train/logprobs = tensor([[ -1.4852, -11.2215],
        [ -9.5810,  -2.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126428782939911
Epoch 0, Step 5308: train/loss = 0.026918990537524223, train/raw-loss = 0.004413616377860308, train/logprobs = tensor([[ -1.1596, -16.5116],
        [ -7.1203,  -5.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22505374252796173
Epoch 0, Step 5309: train/loss = 0.033377185463905334, train/raw-loss = 0.007595879957079887, train/logprobs = tensor([[ -0.9931, -11.9231],
        [ -5.5695,  -2.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257813036441803
Epoch 0, Step 5310: train/loss = 0.025929152965545654, train/raw-loss = 0.002865756629034877, train/logprobs = tensor([[ -1.3536, -14.6733],
        [ -8.9937,  -2.6390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.230633944272995
Epoch 0, Step 5311: train/loss = 0.027413785457611084, train/raw-loss = 0.0036056339740753174, train/logprobs = tensor([[ -1.1168, -17.9115],
        [ -7.1646,  -3.1432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23808149993419647
Epoch 0, Step 5312: train/loss = 0.025232015177607536, train/raw-loss = 0.0024844740983098745, train/logprobs = tensor([[ -1.0881, -13.9374],
        [ -7.0216,  -3.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22747540473937988
Epoch 0, Step 5313: train/loss = 0.02442510798573494, train/raw-loss = 0.0022249622270464897, train/logprobs = tensor([[ -1.2116, -17.8252],
        [ -8.0804,  -5.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22200144827365875
Epoch 0, Step 5314: train/loss = 0.02451026812195778, train/raw-loss = 0.0012990470277145505, train/logprobs = tensor([[ -1.0134, -17.1112],
        [ -7.7370,  -4.3661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23211219906806946
Epoch 0, Step 5315: train/loss = 0.029102057218551636, train/raw-loss = 0.002619222505018115, train/logprobs = tensor([[ -0.9646, -11.2957],
        [ -7.5520,  -2.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26482832431793213
Epoch 0, Step 5316: train/loss = 0.02912066876888275, train/raw-loss = 0.0066981241106987, train/logprobs = tensor([[ -1.3245, -14.4243],
        [ -6.5566,  -3.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22422544658184052
Epoch 0, Step 5317: train/loss = 0.02786429226398468, train/raw-loss = 0.004233997780829668, train/logprobs = tensor([[ -0.9424, -11.8130],
        [ -6.7648,  -2.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2363029420375824
Epoch 0, Step 5318: train/loss = 0.028156956657767296, train/raw-loss = 0.003701707348227501, train/logprobs = tensor([[ -0.7392, -12.7296],
        [ -5.9736,  -3.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24455249309539795
Epoch 0, Step 5319: train/loss = 0.05449318140745163, train/raw-loss = 0.03016057424247265, train/logprobs = tensor([[ -0.7316, -12.1674],
        [ -6.8188,  -2.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24332603812217712
Epoch 0, Step 5320: train/loss = 0.0317123681306839, train/raw-loss = 0.006419508717954159, train/logprobs = tensor([[ -1.2080, -10.9312],
        [ -7.4652,  -2.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25292861461639404
Epoch 0, Step 5321: train/loss = 0.026091884821653366, train/raw-loss = 0.00025344346067868173, train/logprobs = tensor([[ -1.2071, -15.3161],
        [ -9.8112,  -3.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583844065666199
Epoch 0, Step 5322: train/loss = 0.02613099105656147, train/raw-loss = 0.002610662952065468, train/logprobs = tensor([[-1.1508, -9.6462],
        [-8.0697, -2.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23520328104496002
Epoch 0, Step 5323: train/loss = 0.024116691201925278, train/raw-loss = 0.0028012169059365988, train/logprobs = tensor([[ -0.9169, -12.6097],
        [ -8.2009,  -2.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21315474808216095
Epoch 0, Step 5324: train/loss = 0.026090778410434723, train/raw-loss = 0.002851842436939478, train/logprobs = tensor([[ -1.7401, -11.3440],
        [ -9.2357,  -2.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23238934576511383
Epoch 0, Step 5325: train/loss = 0.03073343262076378, train/raw-loss = 0.004731318913400173, train/logprobs = tensor([[ -0.7918, -11.9924],
        [ -5.8586,  -3.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600211203098297
Epoch 0, Step 5326: train/loss = 0.027024615556001663, train/raw-loss = 0.006302746944129467, train/logprobs = tensor([[ -1.0003, -13.3671],
        [ -5.5879,  -3.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20721867680549622
Epoch 0, Step 5327: train/loss = 0.04415131360292435, train/raw-loss = 0.021561160683631897, train/logprobs = tensor([[ -1.8355, -10.4553],
        [ -7.4441,  -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259014993906021
Epoch 0, Step 5328: train/loss = 0.028385823592543602, train/raw-loss = 0.004932255018502474, train/logprobs = tensor([[-1.1365, -9.3484],
        [-6.3273, -1.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23453569412231445
Epoch 0, Step 5329: train/loss = 0.030611636117100716, train/raw-loss = 0.009156545624136925, train/logprobs = tensor([[ -1.1411, -14.7946],
        [ -6.3905,  -4.1156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145508974790573
Epoch 0, Step 5330: train/loss = 0.029175646603107452, train/raw-loss = 0.005525235552340746, train/logprobs = tensor([[ -0.8108, -12.0104],
        [ -5.7982,  -2.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23650413751602173
Epoch 0, Step 5331: train/loss = 0.028033237904310226, train/raw-loss = 0.007159148342907429, train/logprobs = tensor([[ -1.3911, -12.5807],
        [ -8.0025,  -2.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20874087512493134
Epoch 0, Step 5332: train/loss = 0.035530105233192444, train/raw-loss = 0.013310068286955357, train/logprobs = tensor([[ -1.1606, -13.6430],
        [ -6.5702,  -3.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2222003936767578
Epoch 0, Step 5333: train/loss = 0.031064927577972412, train/raw-loss = 0.006027222611010075, train/logprobs = tensor([[ -1.1764, -14.4286],
        [ -7.2637,  -3.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25037702918052673
Epoch 0, Step 5334: train/loss = 0.03266558796167374, train/raw-loss = 0.007783754728734493, train/logprobs = tensor([[ -1.1354, -12.0427],
        [ -6.5585,  -3.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2488183230161667
Epoch 0, Step 5335: train/loss = 0.026540489867329597, train/raw-loss = 0.0044145709834992886, train/logprobs = tensor([[ -0.6451, -11.8414],
        [ -5.9256,  -2.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212591916322708
Epoch 0, Step 5336: train/loss = 0.026002850383520126, train/raw-loss = 0.0029671532101929188, train/logprobs = tensor([[ -0.8898, -13.8364],
        [ -6.6237,  -3.4532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23035697638988495
Epoch 0, Step 5337: train/loss = 0.03550315275788307, train/raw-loss = 0.012803032994270325, train/logprobs = tensor([[ -1.1510, -13.4120],
        [ -6.5830,  -3.4412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22700119018554688
Epoch 0, Step 5338: train/loss = 0.028623998165130615, train/raw-loss = 0.003223124425858259, train/logprobs = tensor([[ -1.0522, -13.4125],
        [ -6.8066,  -3.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540087103843689
Epoch 0, Step 5339: train/loss = 0.029580116271972656, train/raw-loss = 0.005948276724666357, train/logprobs = tensor([[ -1.1955, -13.5934],
        [ -7.2242,  -2.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23631839454174042
Epoch 0, Step 5340: train/loss = 0.03811219334602356, train/raw-loss = 0.01570242829620838, train/logprobs = tensor([[-0.8368, -9.8970],
        [-5.5279, -2.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2240976095199585
Epoch 0, Step 5341: train/loss = 0.028742549940943718, train/raw-loss = 0.0037633059546351433, train/logprobs = tensor([[ -0.5677, -14.9244],
        [ -5.9999,  -3.1313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2497924268245697
Epoch 0, Step 5342: train/loss = 0.025060921907424927, train/raw-loss = 0.0013452590210363269, train/logprobs = tensor([[ -1.2220, -14.6179],
        [ -7.2173,  -3.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23715659976005554
Epoch 0, Step 5343: train/loss = 0.026259472593665123, train/raw-loss = 0.0011237476719543338, train/logprobs = tensor([[ -1.4409, -14.2641],
        [ -9.1046,  -3.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25135722756385803
Epoch 0, Step 5344: train/loss = 0.02918335236608982, train/raw-loss = 0.00607141200453043, train/logprobs = tensor([[ -1.0955, -13.3811],
        [ -7.4821,  -3.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23111937940120697
Epoch 0, Step 5345: train/loss = 0.02807708829641342, train/raw-loss = 0.002415559021756053, train/logprobs = tensor([[ -0.9403, -15.3603],
        [ -6.7985,  -3.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566152811050415
Epoch 0, Step 5346: train/loss = 0.02726646140217781, train/raw-loss = 0.0019183073891326785, train/logprobs = tensor([[ -1.1448, -11.2457],
        [ -7.9698,  -1.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25348150730133057
Epoch 0, Step 5347: train/loss = 0.02986006811261177, train/raw-loss = 0.004739703144878149, train/logprobs = tensor([[ -1.7470,  -9.2656],
        [-10.2446,  -1.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25120362639427185
Epoch 0, Step 5348: train/loss = 0.023910831660032272, train/raw-loss = 0.0008353232988156378, train/logprobs = tensor([[ -1.3674, -12.5968],
        [ -9.3714,  -2.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23075509071350098
Epoch 0, Step 5349: train/loss = 0.0327831469476223, train/raw-loss = 0.011922755278646946, train/logprobs = tensor([[ -1.1817, -14.1973],
        [ -5.5441,  -2.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2086039036512375
Epoch 0, Step 5350: train/loss = 0.02811446040868759, train/raw-loss = 0.002985588042065501, train/logprobs = tensor([[ -0.8396, -16.8011],
        [ -7.2936,  -3.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512887418270111
Epoch 0, Step 5351: train/loss = 0.025833602994680405, train/raw-loss = 0.00047263209125958383, train/logprobs = tensor([[ -1.7577, -13.3983],
        [-11.1221,  -2.9015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25360971689224243
Epoch 0, Step 5352: train/loss = 0.025863558053970337, train/raw-loss = 0.003568737767636776, train/logprobs = tensor([[ -0.8293, -16.0405],
        [ -6.0417,  -2.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22294819355010986
Epoch 0, Step 5353: train/loss = 0.02695225551724434, train/raw-loss = 0.0036200741305947304, train/logprobs = tensor([[ -1.0447, -14.0001],
        [ -6.5692,  -2.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23332181572914124
Epoch 0, Step 5354: train/loss = 0.0242069810628891, train/raw-loss = 0.0012391097843647003, train/logprobs = tensor([[ -1.0626, -15.2819],
        [ -7.4497,  -4.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296786904335022
Epoch 0, Step 5355: train/loss = 0.034448206424713135, train/raw-loss = 0.010056222788989544, train/logprobs = tensor([[ -1.3239, -11.3967],
        [ -8.0648,  -2.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24391980469226837
Epoch 0, Step 5356: train/loss = 0.028927583247423172, train/raw-loss = 0.0050447736866772175, train/logprobs = tensor([[ -1.0588, -18.5921],
        [ -5.8553,  -4.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23882807791233063
Epoch 0, Step 5357: train/loss = 0.028293006122112274, train/raw-loss = 0.005896167829632759, train/logprobs = tensor([[ -1.0643, -10.0542],
        [ -6.2265,  -2.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22396838665008545
Epoch 0, Step 5358: train/loss = 0.024997804313898087, train/raw-loss = 0.0025638281367719173, train/logprobs = tensor([[ -1.3728, -14.9071],
        [ -8.9404,  -4.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22433975338935852
Epoch 0, Step 5359: train/loss = 0.0266604945063591, train/raw-loss = 0.0015718413051217794, train/logprobs = tensor([[ -1.6746, -15.4708],
        [ -9.2542,  -5.4153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25088655948638916
Epoch 0, Step 5360: train/loss = 0.03303457796573639, train/raw-loss = 0.009945505298674107, train/logprobs = tensor([[ -2.1498, -14.5556],
        [ -7.8885,  -3.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23089072108268738
Epoch 0, Step 5361: train/loss = 0.029092885553836823, train/raw-loss = 0.005680698901414871, train/logprobs = tensor([[ -1.1229, -11.3691],
        [ -7.1620,  -2.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23412182927131653
Epoch 0, Step 5362: train/loss = 0.028303055092692375, train/raw-loss = 0.0050803483463823795, train/logprobs = tensor([[-1.3641, -9.1009],
        [-9.1142, -2.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23222705721855164
Epoch 0, Step 5363: train/loss = 0.04501122981309891, train/raw-loss = 0.02596360445022583, train/logprobs = tensor([[ -1.7339, -12.7702],
        [ -6.0407,  -2.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1904762238264084
Epoch 0, Step 5364: train/loss = 0.03825921565294266, train/raw-loss = 0.005985148251056671, train/logprobs = tensor([[ -1.0191, -10.2612],
        [ -6.7793,  -2.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3227406442165375
Epoch 0, Step 5365: train/loss = 0.026195978745818138, train/raw-loss = 0.0030711733270436525, train/logprobs = tensor([[ -1.3271, -17.5867],
        [ -7.3779,  -5.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23124805092811584
Epoch 0, Step 5366: train/loss = 0.025121424347162247, train/raw-loss = 0.001118766493164003, train/logprobs = tensor([[ -0.9036, -17.2689],
        [ -7.6769,  -2.2846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2400265783071518
Epoch 0, Step 5367: train/loss = 0.024497713893651962, train/raw-loss = 0.004673479124903679, train/logprobs = tensor([[ -1.4867, -18.2349],
        [ -8.8115,  -4.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19824236631393433
Epoch 0, Step 5368: train/loss = 0.038926586508750916, train/raw-loss = 0.016413819044828415, train/logprobs = tensor([[ -0.9376, -14.0856],
        [ -5.2360,  -2.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251276969909668
Epoch 0, Step 5369: train/loss = 0.024692172184586525, train/raw-loss = 0.003616651985794306, train/logprobs = tensor([[ -0.9644, -15.0954],
        [ -7.1027,  -4.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21075518429279327
Epoch 0, Step 5370: train/loss = 0.030424131080508232, train/raw-loss = 0.005368745420128107, train/logprobs = tensor([[ -1.2879, -14.9817],
        [ -7.2289,  -3.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25055384635925293
Epoch 0, Step 5371: train/loss = 0.026972470805048943, train/raw-loss = 0.0034461040049791336, train/logprobs = tensor([[ -1.5397, -14.9703],
        [ -6.9324,  -4.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352636754512787
Epoch 0, Step 5372: train/loss = 0.025595786049962044, train/raw-loss = 0.0030583678744733334, train/logprobs = tensor([[ -0.8633, -15.5981],
        [ -6.6076,  -2.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22537419199943542
Epoch 0, Step 5373: train/loss = 0.027141641825437546, train/raw-loss = 0.006284900940954685, train/logprobs = tensor([[ -1.9137, -15.1972],
        [ -6.8025,  -2.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20856741070747375
Epoch 0, Step 5374: train/loss = 0.02885337732732296, train/raw-loss = 0.0061041200533509254, train/logprobs = tensor([[ -1.1381, -11.3011],
        [ -7.7352,  -2.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2274925708770752
Epoch 0, Step 5375: train/loss = 0.03181616961956024, train/raw-loss = 0.009966729208827019, train/logprobs = tensor([[-1.4082, -9.9036],
        [-7.6730, -2.2465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21849441528320312
Epoch 0, Step 5376: train/loss = 0.028025679290294647, train/raw-loss = 0.003085112664848566, train/logprobs = tensor([[ -1.1272, -15.5913],
        [ -6.6768,  -3.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2494056671857834
Epoch 0, Step 5377: train/loss = 0.034807562828063965, train/raw-loss = 0.01244565099477768, train/logprobs = tensor([[ -0.7963, -12.4951],
        [ -6.7313,  -3.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22361913323402405
Epoch 0, Step 5378: train/loss = 0.026185162365436554, train/raw-loss = 0.0042908634059131145, train/logprobs = tensor([[ -1.2109, -11.9891],
        [ -7.6825,  -2.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21894298493862152
Epoch 0, Step 5379: train/loss = 0.030293041840195656, train/raw-loss = 0.009559334255754948, train/logprobs = tensor([[ -1.1955, -14.0723],
        [ -6.5108,  -2.7075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20733708143234253
Epoch 0, Step 5380: train/loss = 0.024880684912204742, train/raw-loss = 0.0014629352372139692, train/logprobs = tensor([[ -1.6248, -11.3498],
        [ -8.7341,  -2.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23417747020721436
Epoch 0, Step 5381: train/loss = 0.026845194399356842, train/raw-loss = 0.004898468032479286, train/logprobs = tensor([[ -0.6493, -16.3860],
        [ -6.3376,  -4.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21946725249290466
Epoch 0, Step 5382: train/loss = 0.025354506447911263, train/raw-loss = 0.0045433430932462215, train/logprobs = tensor([[ -1.7306, -15.8802],
        [ -7.1317,  -4.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20811162889003754
Epoch 0, Step 5383: train/loss = 0.033908694982528687, train/raw-loss = 0.002456262242048979, train/logprobs = tensor([[ -1.1888, -10.6529],
        [ -8.5668,  -2.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145243227481842
Epoch 0, Step 5384: train/loss = 0.02835870534181595, train/raw-loss = 0.005393391475081444, train/logprobs = tensor([[ -1.5849, -10.9046],
        [ -8.3387,  -2.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22965312004089355
Epoch 0, Step 5385: train/loss = 0.024101387709379196, train/raw-loss = 0.002042402746155858, train/logprobs = tensor([[ -1.3951, -10.1466],
        [-10.1855,  -2.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22058984637260437
Epoch 0, Step 5386: train/loss = 0.026123199611902237, train/raw-loss = 0.002879153471440077, train/logprobs = tensor([[ -1.1322, -19.8383],
        [ -6.7463,  -4.5268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23244047164916992
Epoch 0, Step 5387: train/loss = 0.02903469279408455, train/raw-loss = 0.0037644305266439915, train/logprobs = tensor([[ -1.1454, -13.1423],
        [ -6.9636,  -3.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25270262360572815
Epoch 0, Step 5388: train/loss = 0.028800619766116142, train/raw-loss = 0.0037504001520574093, train/logprobs = tensor([[ -1.5573, -17.7504],
        [ -8.7098,  -4.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25050216913223267
Epoch 0, Step 5389: train/loss = 0.023400895297527313, train/raw-loss = 0.0015431310748681426, train/logprobs = tensor([[ -1.2042, -19.3530],
        [ -8.1130,  -4.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21857763826847076
Epoch 0, Step 5390: train/loss = 0.03855175897479057, train/raw-loss = 0.01470633689314127, train/logprobs = tensor([[ -1.1781, -12.3730],
        [ -5.6594,  -3.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.238454207777977
Epoch 0, Step 5391: train/loss = 0.02803867682814598, train/raw-loss = 0.0037344987504184246, train/logprobs = tensor([[ -0.9397, -16.9361],
        [ -7.0955,  -4.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2430417686700821
Epoch 0, Step 5392: train/loss = 0.037557102739810944, train/raw-loss = 0.010934959165751934, train/logprobs = tensor([[ -0.7461, -11.0124],
        [ -5.0915,  -2.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26622137427330017
Epoch 0, Step 5393: train/loss = 0.029042664915323257, train/raw-loss = 0.005697205197066069, train/logprobs = tensor([[ -0.8761, -12.7741],
        [ -7.0413,  -1.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23345457017421722
Epoch 0, Step 5394: train/loss = 0.045796431601047516, train/raw-loss = 0.020263152197003365, train/logprobs = tensor([[-0.9623, -9.3809],
        [-6.7073, -2.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553327977657318
Epoch 0, Step 5395: train/loss = 0.023951493203639984, train/raw-loss = 0.0008623460307717323, train/logprobs = tensor([[ -1.0988, -11.9867],
        [ -8.3053,  -3.2191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23089146614074707
Epoch 0, Step 5396: train/loss = 0.026503581553697586, train/raw-loss = 0.0021262052468955517, train/logprobs = tensor([[ -0.8853, -13.2828],
        [ -6.6848,  -2.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24377375841140747
Epoch 0, Step 5397: train/loss = 0.02883995696902275, train/raw-loss = 0.004594636615365744, train/logprobs = tensor([[ -1.3949, -16.3240],
        [ -9.8241,  -5.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424531728029251
Epoch 0, Step 5398: train/loss = 0.025796156376600266, train/raw-loss = 0.0030842768028378487, train/logprobs = tensor([[ -0.7368, -17.6679],
        [ -6.5702,  -3.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22711880505084991
Epoch 0, Step 5399: train/loss = 0.03018164448440075, train/raw-loss = 0.007666103541851044, train/logprobs = tensor([[ -1.4185, -16.2238],
        [ -7.5309,  -3.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22515538334846497
Epoch 0, Step 5400: train/loss = 0.02946624718606472, train/raw-loss = 0.005404184106737375, train/logprobs = tensor([[ -0.9686, -11.6724],
        [ -7.0594,  -3.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24062062799930573
Epoch 0, Step 5401: train/loss = 0.026731103658676147, train/raw-loss = 0.005682007875293493, train/logprobs = tensor([[ -1.3773, -13.4145],
        [ -6.5360,  -3.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21049094200134277
Epoch 0, Step 5402: train/loss = 0.026220809668302536, train/raw-loss = 0.002195496577769518, train/logprobs = tensor([[ -1.1471, -14.4447],
        [ -7.2911,  -2.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24025312066078186
Epoch 0, Step 5403: train/loss = 0.04552321881055832, train/raw-loss = 0.021586857736110687, train/logprobs = tensor([[ -1.4840, -11.4882],
        [ -7.9769,  -2.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23936361074447632
Epoch 0, Step 5404: train/loss = 0.04221464321017265, train/raw-loss = 0.02014109492301941, train/logprobs = tensor([[ -1.1580, -11.0985],
        [ -5.7008,  -2.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22073544561862946
Epoch 0, Step 5405: train/loss = 0.027558909729123116, train/raw-loss = 0.002473327098414302, train/logprobs = tensor([[ -0.8880, -13.2190],
        [ -8.1720,  -3.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25085583329200745
Epoch 0, Step 5406: train/loss = 0.02336358278989792, train/raw-loss = 0.0008046006551012397, train/logprobs = tensor([[ -1.3066, -12.0480],
        [ -8.9526,  -2.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255898267030716
Epoch 0, Step 5407: train/loss = 0.040723226964473724, train/raw-loss = 0.01947358436882496, train/logprobs = tensor([[ -1.6023, -12.0847],
        [ -6.8830,  -2.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21249642968177795
Epoch 0, Step 5408: train/loss = 0.03461584076285362, train/raw-loss = 0.014757359400391579, train/logprobs = tensor([[ -1.5893, -16.3057],
        [ -6.2665,  -3.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858479499816895
Epoch 0, Step 5409: train/loss = 0.024134937673807144, train/raw-loss = 0.001344888936728239, train/logprobs = tensor([[ -1.5159, -15.7852],
        [ -9.8959,  -3.2540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22790047526359558
Epoch 0, Step 5410: train/loss = 0.02706008031964302, train/raw-loss = 0.002888991730287671, train/logprobs = tensor([[ -1.1304, -11.6237],
        [ -7.8480,  -2.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417108714580536
Epoch 0, Step 5411: train/loss = 0.026029901579022408, train/raw-loss = 0.0022280928678810596, train/logprobs = tensor([[ -1.0841, -12.9934],
        [ -6.8764,  -4.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23801806569099426
Epoch 0, Step 5412: train/loss = 0.031198129057884216, train/raw-loss = 0.008200053125619888, train/logprobs = tensor([[ -1.2972, -13.7817],
        [ -5.6196,  -3.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22998076677322388
Epoch 0, Step 5413: train/loss = 0.022667698562145233, train/raw-loss = 0.002400732133537531, train/logprobs = tensor([[ -1.2728, -18.2206],
        [ -7.6806,  -4.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2026696503162384
Epoch 0, Step 5414: train/loss = 0.019675636664032936, train/raw-loss = 0.0012048096396028996, train/logprobs = tensor([[ -1.4300, -14.5023],
        [ -8.7918,  -3.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18470826745033264
Epoch 0, Step 5415: train/loss = 0.0428435280919075, train/raw-loss = 0.019357506185770035, train/logprobs = tensor([[ -0.9476, -12.5984],
        [ -6.8070,  -3.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23486022651195526
Epoch 0, Step 5416: train/loss = 0.02402108535170555, train/raw-loss = 0.0018297843635082245, train/logprobs = tensor([[ -0.9452, -14.2316],
        [ -7.0530,  -2.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22191299498081207
Epoch 0, Step 5417: train/loss = 0.032829247415065765, train/raw-loss = 0.006566350813955069, train/logprobs = tensor([[ -1.6269, -12.6468],
        [ -9.5283,  -2.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262628972530365
Epoch 0, Step 5418: train/loss = 0.028401896357536316, train/raw-loss = 0.003603859804570675, train/logprobs = tensor([[ -0.9729, -13.0237],
        [ -6.5322,  -3.4185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24798037111759186
Epoch 0, Step 5419: train/loss = 0.05675974860787392, train/raw-loss = 0.032461028546094894, train/logprobs = tensor([[-1.4144, -9.4502],
        [-6.4406, -1.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2429872453212738
Epoch 0, Step 5420: train/loss = 0.05710877478122711, train/raw-loss = 0.034550800919532776, train/logprobs = tensor([[ -1.1464, -14.1607],
        [ -5.2673,  -3.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22557975351810455
Epoch 0, Step 5421: train/loss = 0.02504369616508484, train/raw-loss = 0.0014037381624802947, train/logprobs = tensor([[ -0.8300, -12.7376],
        [ -7.1851,  -2.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2363995909690857
Epoch 0, Step 5422: train/loss = 0.031750962138175964, train/raw-loss = 0.008994782343506813, train/logprobs = tensor([[ -1.5287, -14.3773],
        [ -8.5732,  -3.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2275618016719818
Epoch 0, Step 5423: train/loss = 0.025153227150440216, train/raw-loss = 0.0003230519942007959, train/logprobs = tensor([[ -1.2908, -18.3649],
        [ -8.9236,  -5.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24830174446105957
Epoch 0, Step 5424: train/loss = 0.026701752096414566, train/raw-loss = 0.0016336250118911266, train/logprobs = tensor([[ -1.4052, -15.5903],
        [ -8.7896,  -4.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506812512874603
Epoch 0, Step 5425: train/loss = 0.026248469948768616, train/raw-loss = 0.002161004114896059, train/logprobs = tensor([[ -2.1498, -18.3619],
        [ -9.6346,  -5.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24087464809417725
Epoch 0, Step 5426: train/loss = 0.0262587983161211, train/raw-loss = 0.0021018609404563904, train/logprobs = tensor([[ -1.1727, -11.7100],
        [ -8.2709,  -3.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2415693700313568
Epoch 0, Step 5427: train/loss = 0.027092523872852325, train/raw-loss = 0.003725923364982009, train/logprobs = tensor([[ -1.0627, -11.7623],
        [ -7.0947,  -2.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23366600275039673
Epoch 0, Step 5428: train/loss = 0.036406319588422775, train/raw-loss = 0.010438998229801655, train/logprobs = tensor([[-1.1156, -9.8238],
        [-7.6033, -2.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25967320799827576
Epoch 0, Step 5429: train/loss = 0.037997156381607056, train/raw-loss = 0.018286246806383133, train/logprobs = tensor([[ -1.0226, -12.6386],
        [ -4.8932,  -2.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19710910320281982
Epoch 0, Step 5430: train/loss = 0.02665480226278305, train/raw-loss = 0.002967539709061384, train/logprobs = tensor([[ -1.0856, -14.8774],
        [ -7.5661,  -2.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368726283311844
Epoch 0, Step 5431: train/loss = 0.02435067668557167, train/raw-loss = 0.001815469586290419, train/logprobs = tensor([[ -1.1074, -17.4679],
        [ -7.0260,  -5.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22535207867622375
Epoch 0, Step 5432: train/loss = 0.05236251279711723, train/raw-loss = 0.029009778052568436, train/logprobs = tensor([[ -1.7183, -13.2514],
        [ -5.6637,  -1.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23352733254432678
Epoch 0, Step 5433: train/loss = 0.027212850749492645, train/raw-loss = 0.002036824356764555, train/logprobs = tensor([[ -0.9292, -11.9022],
        [ -8.7761,  -2.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517602741718292
Epoch 0, Step 5434: train/loss = 0.027200261130928993, train/raw-loss = 0.002209004946053028, train/logprobs = tensor([[ -1.3548, -15.2684],
        [ -8.3750,  -3.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2499125599861145
Epoch 0, Step 5435: train/loss = 0.024868037551641464, train/raw-loss = 0.003682269249111414, train/logprobs = tensor([[ -1.2363, -13.1202],
        [ -8.0839,  -3.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21185767650604248
Epoch 0, Step 5436: train/loss = 0.03533920645713806, train/raw-loss = 0.010090621188282967, train/logprobs = tensor([[ -0.9076, -11.8453],
        [ -6.4377,  -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25248581171035767
Epoch 0, Step 5437: train/loss = 0.02299605682492256, train/raw-loss = 0.0019081010250374675, train/logprobs = tensor([[ -0.9917, -15.1639],
        [ -7.7061,  -3.3164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21087954938411713
Epoch 0, Step 5438: train/loss = 0.024781260639429092, train/raw-loss = 0.0019214351195842028, train/logprobs = tensor([[ -1.3707, -12.9656],
        [ -8.4161,  -2.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285982370376587
Epoch 0, Step 5439: train/loss = 0.02828916162252426, train/raw-loss = 0.005617071874439716, train/logprobs = tensor([[ -0.7357, -15.3738],
        [ -5.6898,  -2.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2267208993434906
Epoch 0, Step 5440: train/loss = 0.02481471747159958, train/raw-loss = 0.0017319746548309922, train/logprobs = tensor([[ -0.9877, -13.9354],
        [ -7.0114,  -3.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2308274209499359
Epoch 0, Step 5441: train/loss = 0.02648976258933544, train/raw-loss = 0.002295746700838208, train/logprobs = tensor([[ -1.0384, -14.1341],
        [ -7.3222,  -3.2798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24194015562534332
Epoch 0, Step 5442: train/loss = 0.03604651242494583, train/raw-loss = 0.013108154758810997, train/logprobs = tensor([[ -1.1205, -12.1670],
        [ -6.3212,  -2.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22938360273838043
Epoch 0, Step 5443: train/loss = 0.6135091781616211, train/raw-loss = 0.5915660262107849, train/logprobs = tensor([[ -2.2563, -11.7863],
        [ -9.3676,  -5.3875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21943168342113495
Epoch 0, Step 5444: train/loss = 0.02837482839822769, train/raw-loss = 0.004189091734588146, train/logprobs = tensor([[ -1.0987, -13.5136],
        [ -8.2510,  -2.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2418573498725891
Epoch 0, Step 5445: train/loss = 0.026040202006697655, train/raw-loss = 0.0009549491223879158, train/logprobs = tensor([[ -0.8221, -13.2638],
        [ -7.4258,  -3.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508525252342224
Epoch 0, Step 5446: train/loss = 0.0255400612950325, train/raw-loss = 0.0020976897794753313, train/logprobs = tensor([[ -1.0563, -15.8190],
        [ -7.2243,  -6.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2344236969947815
Epoch 0, Step 5447: train/loss = 0.02578161284327507, train/raw-loss = 0.0024334026966243982, train/logprobs = tensor([[ -1.5543, -12.6296],
        [ -7.8667,  -2.8042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23348212242126465
Epoch 0, Step 5448: train/loss = 0.025639956817030907, train/raw-loss = 0.0031277956441044807, train/logprobs = tensor([[ -0.7643, -12.8595],
        [ -5.9069,  -3.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251216173171997
Epoch 0, Step 5449: train/loss = 0.02431672438979149, train/raw-loss = 0.0008324275258928537, train/logprobs = tensor([[ -0.9531, -19.1715],
        [ -7.8661,  -5.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23484297096729279
Epoch 0, Step 5450: train/loss = 0.029219873249530792, train/raw-loss = 0.007023082114756107, train/logprobs = tensor([[ -0.8956, -11.2536],
        [ -6.2453,  -2.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2219679057598114
Epoch 0, Step 5451: train/loss = 0.05159725993871689, train/raw-loss = 0.026692170649766922, train/logprobs = tensor([[ -1.4149, -16.2083],
        [ -6.3762,  -3.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24905093014240265
Epoch 0, Step 5452: train/loss = 0.026889991015195847, train/raw-loss = 0.003354388289153576, train/logprobs = tensor([[ -1.3434, -15.5075],
        [ -6.9597,  -3.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23535603284835815
Epoch 0, Step 5453: train/loss = 0.024613438174128532, train/raw-loss = 0.002383412327617407, train/logprobs = tensor([[ -0.9687, -13.2419],
        [ -7.9415,  -2.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22230026125907898
Epoch 0, Step 5454: train/loss = 0.02425093948841095, train/raw-loss = 0.001645503332838416, train/logprobs = tensor([[ -1.1195, -17.1480],
        [ -7.8630,  -4.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2260543406009674
Epoch 0, Step 5455: train/loss = 0.025468256324529648, train/raw-loss = 0.0007608069572597742, train/logprobs = tensor([[ -1.2199, -16.6462],
        [ -9.5285,  -3.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24707448482513428
Epoch 0, Step 5456: train/loss = 0.029143735766410828, train/raw-loss = 0.0010220096446573734, train/logprobs = tensor([[ -1.3190, -13.5900],
        [ -8.4536,  -2.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812172472476959
Epoch 0, Step 5457: train/loss = 0.0269733015447855, train/raw-loss = 0.0016214852221310139, train/logprobs = tensor([[ -0.9573, -11.8399],
        [ -7.3773,  -3.3171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25351813435554504
Epoch 0, Step 5458: train/loss = 0.02719692513346672, train/raw-loss = 0.004151976201683283, train/logprobs = tensor([[ -1.1636, -12.5276],
        [ -7.1397,  -3.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23044946789741516
Epoch 0, Step 5459: train/loss = 0.022428743541240692, train/raw-loss = 0.0026149656623601913, train/logprobs = tensor([[ -1.9030, -21.7751],
        [ -8.6322,  -6.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1981377750635147
Epoch 0, Step 5460: train/loss = 0.027088500559329987, train/raw-loss = 0.0019960347563028336, train/logprobs = tensor([[ -1.3802, -12.9544],
        [ -9.0903,  -3.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25092464685440063
Epoch 0, Step 5461: train/loss = 0.026548229157924652, train/raw-loss = 0.0038963425904512405, train/logprobs = tensor([[ -0.8517, -15.2693],
        [ -6.0745,  -3.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22651886940002441
Epoch 0, Step 5462: train/loss = 0.029228346422314644, train/raw-loss = 0.0030406247824430466, train/logprobs = tensor([[ -1.1431, -14.2977],
        [ -6.4520,  -4.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618772089481354
Epoch 0, Step 5463: train/loss = 0.022810209542512894, train/raw-loss = 0.002146956045180559, train/logprobs = tensor([[ -1.3663, -18.7358],
        [ -7.9080,  -4.5432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066325545310974
Epoch 0, Step 5464: train/loss = 0.027246270328760147, train/raw-loss = 0.002966292668133974, train/logprobs = tensor([[ -1.4125, -12.3242],
        [ -7.3412,  -2.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427997887134552
Epoch 0, Step 5465: train/loss = 0.03111959993839264, train/raw-loss = 0.004709913395345211, train/logprobs = tensor([[ -1.2363, -11.9762],
        [ -7.3825,  -3.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26409685611724854
Epoch 0, Step 5466: train/loss = 0.0365867093205452, train/raw-loss = 0.010226987302303314, train/logprobs = tensor([[ -0.7924, -11.9546],
        [ -6.4881,  -2.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26359719038009644
Epoch 0, Step 5467: train/loss = 0.03730710595846176, train/raw-loss = 0.017773348838090897, train/logprobs = tensor([[ -0.7839, -19.1344],
        [ -4.7062,  -4.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19533756375312805
Epoch 0, Step 5468: train/loss = 0.02470231242477894, train/raw-loss = 0.001683201640844345, train/logprobs = tensor([[ -1.3473, -11.7784],
        [ -8.0770,  -2.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23019111156463623
Epoch 0, Step 5469: train/loss = 0.02411600761115551, train/raw-loss = 0.002468446735292673, train/logprobs = tensor([[ -1.5194, -15.1009],
        [ -8.3459,  -4.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21647560596466064
Epoch 0, Step 5470: train/loss = 0.023580696433782578, train/raw-loss = 0.0017953476635739207, train/logprobs = tensor([[ -0.8658, -13.4040],
        [ -7.0235,  -2.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21785348653793335
Epoch 0, Step 5471: train/loss = 0.028795655816793442, train/raw-loss = 0.0036581240128725767, train/logprobs = tensor([[-1.0202, -9.7374],
        [-6.8700, -1.6431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25137531757354736
Epoch 0, Step 5472: train/loss = 0.02980767749249935, train/raw-loss = 0.008022064343094826, train/logprobs = tensor([[ -0.9043, -13.6196],
        [ -7.3786,  -3.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21785610914230347
Epoch 0, Step 5473: train/loss = 0.028850264847278595, train/raw-loss = 0.005670380778610706, train/logprobs = tensor([[ -0.8309, -15.0659],
        [ -5.7296,  -4.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23179882764816284
Epoch 0, Step 5474: train/loss = 0.02327379770576954, train/raw-loss = 0.0010689656483009458, train/logprobs = tensor([[ -0.8683, -16.3888],
        [ -7.3503,  -2.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2220483273267746
Epoch 0, Step 5475: train/loss = 0.027211029082536697, train/raw-loss = 0.00027834129286929965, train/logprobs = tensor([[ -1.1630, -16.4695],
        [ -9.3205,  -3.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693268656730652
Epoch 0, Step 5476: train/loss = 0.027416765689849854, train/raw-loss = 0.003468691138550639, train/logprobs = tensor([[ -1.0076, -16.1035],
        [ -6.5816,  -4.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23948073387145996
Epoch 0, Step 5477: train/loss = 0.02548898383975029, train/raw-loss = 0.0004734740941785276, train/logprobs = tensor([[ -1.2065, -15.3467],
        [ -9.1394,  -3.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25015509128570557
Epoch 0, Step 5478: train/loss = 0.030430641025304794, train/raw-loss = 0.003794976742938161, train/logprobs = tensor([[ -1.1137, -12.5497],
        [ -8.3596,  -2.3573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663566470146179
Epoch 0, Step 5479: train/loss = 0.02474142052233219, train/raw-loss = 0.0009115819702856243, train/logprobs = tensor([[ -1.2342, -14.2254],
        [ -8.4265,  -3.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23829838633537292
Epoch 0, Step 5480: train/loss = 0.021363399922847748, train/raw-loss = 0.0006578830070793629, train/logprobs = tensor([[ -1.2734, -17.8036],
        [ -8.9848,  -5.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20705516636371613
Epoch 0, Step 5481: train/loss = 0.023690607398748398, train/raw-loss = 0.0013798289000988007, train/logprobs = tensor([[-1.4537, -9.0180],
        [-8.6896, -1.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22310777008533478
Epoch 0, Step 5482: train/loss = 0.03762546554207802, train/raw-loss = 0.015701396390795708, train/logprobs = tensor([[ -1.2779, -10.9717],
        [ -5.7610,  -4.0159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21924066543579102
Epoch 0, Step 5483: train/loss = 0.027810512110590935, train/raw-loss = 0.0033743383828550577, train/logprobs = tensor([[ -0.8218, -15.4388],
        [ -6.4303,  -3.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2443617582321167
Epoch 0, Step 5484: train/loss = 0.0325683057308197, train/raw-loss = 0.007584388833492994, train/logprobs = tensor([[ -1.3447, -13.1356],
        [ -8.5927,  -3.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498391717672348
Epoch 0, Step 5485: train/loss = 0.025945059955120087, train/raw-loss = 0.003577207447960973, train/logprobs = tensor([[ -1.1595, -12.3616],
        [ -6.1828,  -2.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22367851436138153
Epoch 0, Step 5486: train/loss = 0.02379455976188183, train/raw-loss = 0.0026175940874964, train/logprobs = tensor([[ -1.0924, -18.5425],
        [ -7.0819,  -4.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21176964044570923
Epoch 0, Step 5487: train/loss = 0.025406435132026672, train/raw-loss = 0.002907187445089221, train/logprobs = tensor([[ -1.2066, -17.9919],
        [ -7.7087,  -5.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22499248385429382
Epoch 0, Step 5488: train/loss = 0.027746524661779404, train/raw-loss = 0.004406202584505081, train/logprobs = tensor([[ -0.7911, -11.0974],
        [ -5.8128,  -1.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23340323567390442
Epoch 0, Step 5489: train/loss = 0.02657872810959816, train/raw-loss = 0.0006551267579197884, train/logprobs = tensor([[ -1.1673, -15.9513],
        [ -9.5018,  -3.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25923600792884827
Epoch 0, Step 5490: train/loss = 0.039556026458740234, train/raw-loss = 0.015962839126586914, train/logprobs = tensor([[ -1.0293, -16.1722],
        [ -5.7324,  -3.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359318882226944
Epoch 0, Step 5491: train/loss = 0.028851427137851715, train/raw-loss = 0.003634320804849267, train/logprobs = tensor([[ -1.0545, -11.0392],
        [ -6.6228,  -2.7228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25217103958129883
Epoch 0, Step 5492: train/loss = 0.02930145338177681, train/raw-loss = 0.0030892835929989815, train/logprobs = tensor([[ -1.2082, -20.6622],
        [ -7.0800,  -6.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26212167739868164
Epoch 0, Step 5493: train/loss = 0.025731215253472328, train/raw-loss = 0.0011626494815573096, train/logprobs = tensor([[ -1.0787, -11.9861],
        [ -7.9921,  -3.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456856369972229
Epoch 0, Step 5494: train/loss = 0.02937181107699871, train/raw-loss = 0.0035462810192257166, train/logprobs = tensor([[ -0.9420, -12.8536],
        [ -6.5603,  -3.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.258255273103714
Epoch 0, Step 5495: train/loss = 0.02732415311038494, train/raw-loss = 0.0033692442812025547, train/logprobs = tensor([[ -0.8547, -10.3798],
        [ -6.1106,  -1.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23954908549785614
Epoch 0, Step 5496: train/loss = 0.030800871551036835, train/raw-loss = 0.002091505564749241, train/logprobs = tensor([[ -0.8987, -12.6739],
        [ -7.5336,  -2.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870936691761017
Epoch 0, Step 5497: train/loss = 0.028811324387788773, train/raw-loss = 0.003400216344743967, train/logprobs = tensor([[ -1.7042, -14.7519],
        [ -9.0594,  -4.6564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25411108136177063
Epoch 0, Step 5498: train/loss = 0.024735426530241966, train/raw-loss = 0.004063986707478762, train/logprobs = tensor([[ -0.9867, -11.8445],
        [ -6.4741,  -3.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20671439170837402
Epoch 0, Step 5499: train/loss = 0.024565665051341057, train/raw-loss = 0.0028946842066943645, train/logprobs = tensor([[ -1.4936, -15.8350],
        [ -8.0958,  -5.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21670980751514435
Epoch 0, Step 5500: train/loss = 0.03698870912194252, train/raw-loss = 0.012959635816514492, train/logprobs = tensor([[-2.0210, -9.3727],
        [-9.3007, -2.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24029073119163513
Epoch 0, Step 5501: train/loss = 0.03512090817093849, train/raw-loss = 0.01124697457998991, train/logprobs = tensor([[ -1.1690, -14.5117],
        [ -7.8274,  -4.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23873935639858246
Epoch 0, Step 5502: train/loss = 0.022838179022073746, train/raw-loss = 0.0019401743775233626, train/logprobs = tensor([[-1.3398, -9.1934],
        [-7.7997, -2.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2089800238609314
Epoch 0, Step 5503: train/loss = 0.02989405021071434, train/raw-loss = 0.0009696977213025093, train/logprobs = tensor([[ -1.2278, -11.7135],
        [ -9.0721,  -2.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892434895038605
Epoch 0, Step 5504: train/loss = 0.02642255648970604, train/raw-loss = 0.0026344629004597664, train/logprobs = tensor([[ -1.1454, -12.2032],
        [ -7.5798,  -3.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23788094520568848
Epoch 0, Step 5505: train/loss = 0.026829268783330917, train/raw-loss = 0.004358760081231594, train/logprobs = tensor([[ -1.4438, -11.7581],
        [ -7.8217,  -2.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247050702571869
Epoch 0, Step 5506: train/loss = 0.025638338178396225, train/raw-loss = 0.003314782865345478, train/logprobs = tensor([[ -1.0954, -13.6661],
        [ -7.8125,  -3.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2232355773448944
Epoch 0, Step 5507: train/loss = 0.025484638288617134, train/raw-loss = 0.001798847340978682, train/logprobs = tensor([[ -1.2741, -14.2008],
        [ -7.8308,  -3.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23685787618160248
Epoch 0, Step 5508: train/loss = 0.026694390922784805, train/raw-loss = 0.0031535136513412, train/logprobs = tensor([[ -1.1985, -11.2679],
        [ -7.7042,  -2.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235408753156662
Epoch 0, Step 5509: train/loss = 0.029272327199578285, train/raw-loss = 0.005036886781454086, train/logprobs = tensor([[ -1.0675, -12.2181],
        [ -6.7413,  -3.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2423544079065323
Epoch 0, Step 5510: train/loss = 0.026155583560466766, train/raw-loss = 0.0010827466612681746, train/logprobs = tensor([[ -1.4924, -17.0475],
        [ -9.2061,  -3.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507283687591553
Epoch 0, Step 5511: train/loss = 0.02834904007613659, train/raw-loss = 0.004119975958019495, train/logprobs = tensor([[ -1.1699, -12.7798],
        [ -7.0398,  -3.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2422906458377838
Epoch 0, Step 5512: train/loss = 0.02579645626246929, train/raw-loss = 0.004616917110979557, train/logprobs = tensor([[ -0.7354, -11.2799],
        [ -5.5275,  -1.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.211795374751091
Epoch 0, Step 5513: train/loss = 0.026258721947669983, train/raw-loss = 0.006315802223980427, train/logprobs = tensor([[ -1.4785, -16.4915],
        [ -7.8027,  -4.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1994291990995407
Epoch 0, Step 5514: train/loss = 0.03014906495809555, train/raw-loss = 0.0027167063672095537, train/logprobs = tensor([[-1.1800, -8.7088],
        [-9.0457, -2.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27432358264923096
Epoch 0, Step 5515: train/loss = 0.028744647279381752, train/raw-loss = 0.0027830807957798243, train/logprobs = tensor([[ -1.1634, -15.2451],
        [ -7.3132,  -3.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596156597137451
Epoch 0, Step 5516: train/loss = 0.02849734202027321, train/raw-loss = 0.00020802108338102698, train/logprobs = tensor([[ -1.6376, -11.9983],
        [-10.4098,  -2.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28289321064949036
Epoch 0, Step 5517: train/loss = 0.02747233957052231, train/raw-loss = 0.003757953643798828, train/logprobs = tensor([[ -1.3989, -12.5492],
        [ -6.9610,  -3.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2371438592672348
Epoch 0, Step 5518: train/loss = 0.028761301189661026, train/raw-loss = 0.006128617562353611, train/logprobs = tensor([[ -1.5424, -11.2706],
        [ -8.4460,  -2.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263268232345581
Epoch 0, Step 5519: train/loss = 0.04356828331947327, train/raw-loss = 0.021317021921277046, train/logprobs = tensor([[ -0.7926, -11.8697],
        [ -5.2652,  -2.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2225126177072525
Epoch 0, Step 5520: train/loss = 0.025932101532816887, train/raw-loss = 0.00043333470239304006, train/logprobs = tensor([[ -1.4772, -17.4326],
        [ -9.6228,  -4.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549876570701599
Epoch 0, Step 5521: train/loss = 0.02225605398416519, train/raw-loss = 0.0010376558639109135, train/logprobs = tensor([[ -1.0904, -16.9325],
        [ -8.7423,  -4.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21218398213386536
Epoch 0, Step 5522: train/loss = 0.023568855598568916, train/raw-loss = 0.0026102166157215834, train/logprobs = tensor([[ -1.1836, -18.4204],
        [ -6.6830,  -3.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20958638191223145
Epoch 0, Step 5523: train/loss = 0.025703065097332, train/raw-loss = 0.0012885509058833122, train/logprobs = tensor([[ -1.4747, -16.3800],
        [ -8.9288,  -3.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24414515495300293
Epoch 0, Step 5524: train/loss = 0.02863708883523941, train/raw-loss = 0.004121011588722467, train/logprobs = tensor([[ -1.1369, -10.7226],
        [ -7.3962,  -2.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.245160773396492
Epoch 0, Step 5525: train/loss = 0.03352697566151619, train/raw-loss = 0.010355310514569283, train/logprobs = tensor([[ -1.3682, -11.8496],
        [ -7.9094,  -2.6940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23171661794185638
Epoch 0, Step 5526: train/loss = 0.02708597667515278, train/raw-loss = 0.003560248063877225, train/logprobs = tensor([[ -0.7495, -14.3575],
        [ -5.7980,  -3.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23525729775428772
Epoch 0, Step 5527: train/loss = 0.02761279046535492, train/raw-loss = 0.0023508009035140276, train/logprobs = tensor([[ -1.4400, -11.4189],
        [ -9.5193,  -2.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526198625564575
Epoch 0, Step 5528: train/loss = 0.025475578382611275, train/raw-loss = 0.0009352000197395682, train/logprobs = tensor([[ -1.3254, -11.8402],
        [ -9.3735,  -1.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24540378153324127
Epoch 0, Step 5529: train/loss = 0.027274440973997116, train/raw-loss = 0.004981284495443106, train/logprobs = tensor([[ -1.0706, -13.0093],
        [ -6.2618,  -3.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22293154895305634
Epoch 0, Step 5530: train/loss = 0.02632051333785057, train/raw-loss = 0.0005687933880835772, train/logprobs = tensor([[ -1.2345, -16.7859],
        [ -8.4071,  -4.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575171887874603
Epoch 0, Step 5531: train/loss = 0.02341570146381855, train/raw-loss = 0.0020823939703404903, train/logprobs = tensor([[ -1.3911, -24.1722],
        [ -8.0321,  -5.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21333307027816772
Epoch 0, Step 5532: train/loss = 0.03087489679455757, train/raw-loss = 0.007368214428424835, train/logprobs = tensor([[-0.8714, -9.8212],
        [-6.1202, -2.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23506683111190796
Epoch 0, Step 5533: train/loss = 0.04222472384572029, train/raw-loss = 0.021272605285048485, train/logprobs = tensor([[-1.1255, -6.3740],
        [-6.5123, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20952120423316956
Epoch 0, Step 5534: train/loss = 0.03506125509738922, train/raw-loss = 0.00916783045977354, train/logprobs = tensor([[ -1.3309, -10.8230],
        [ -7.5750,  -2.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25893422961235046
Epoch 0, Step 5535: train/loss = 0.03157427906990051, train/raw-loss = 0.007763952016830444, train/logprobs = tensor([[ -1.1465, -11.3508],
        [ -5.9715,  -2.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23810327053070068
Epoch 0, Step 5536: train/loss = 0.023002220317721367, train/raw-loss = 0.0005416791536845267, train/logprobs = tensor([[ -0.9143, -19.0218],
        [ -8.4820,  -5.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22460539638996124
Epoch 0, Step 5537: train/loss = 0.03061799705028534, train/raw-loss = 0.009543675929307938, train/logprobs = tensor([[ -1.3338, -11.7919],
        [ -6.7578,  -2.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2107432335615158
Epoch 0, Step 5538: train/loss = 0.045968808233737946, train/raw-loss = 0.0229483712464571, train/logprobs = tensor([[ -1.4673, -10.4192],
        [ -7.2028,  -1.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23020434379577637
Epoch 0, Step 5539: train/loss = 0.026064202189445496, train/raw-loss = 0.0008974210359156132, train/logprobs = tensor([[ -1.3620, -12.9534],
        [ -9.3467,  -2.9805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516677975654602
Epoch 0, Step 5540: train/loss = 0.02613264136016369, train/raw-loss = 0.0020899372175335884, train/logprobs = tensor([[ -1.2625, -11.2530],
        [ -8.2125,  -1.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24042704701423645
Epoch 0, Step 5541: train/loss = 0.026573725044727325, train/raw-loss = 0.0012193233706057072, train/logprobs = tensor([[ -0.9157, -15.1142],
        [ -7.3919,  -4.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25354400277137756
Epoch 0, Step 5542: train/loss = 0.023059476166963577, train/raw-loss = 0.0012930992525070906, train/logprobs = tensor([[ -1.2411, -16.9255],
        [ -9.2634,  -4.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21766376495361328
Epoch 0, Step 5543: train/loss = 0.025415964424610138, train/raw-loss = 0.00102590664755553, train/logprobs = tensor([[ -1.2891, -17.5395],
        [ -8.0507,  -3.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2439005970954895
Epoch 0, Step 5544: train/loss = 0.023247292265295982, train/raw-loss = 0.003195619210600853, train/logprobs = tensor([[ -0.8869, -15.0182],
        [ -6.9192,  -3.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005167305469513
Epoch 0, Step 5545: train/loss = 0.03306615352630615, train/raw-loss = 0.008989389054477215, train/logprobs = tensor([[ -1.2825, -19.2800],
        [ -6.4615,  -6.2122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24076765775680542
Epoch 0, Step 5546: train/loss = 0.019935838878154755, train/raw-loss = 0.0013833324192091823, train/logprobs = tensor([[ -2.7167, -13.8012],
        [-10.9025,  -4.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1855250746011734
Epoch 0, Step 5547: train/loss = 0.023659758269786835, train/raw-loss = 0.0017829035641625524, train/logprobs = tensor([[ -2.0353, -11.7572],
        [ -8.5832,  -3.1108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21876853704452515
Epoch 0, Step 5548: train/loss = 0.029347915202379227, train/raw-loss = 0.004108301363885403, train/logprobs = tensor([[ -0.7234, -10.4558],
        [ -6.0807,  -2.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523961365222931
Epoch 0, Step 5549: train/loss = 0.03347957879304886, train/raw-loss = 0.011514103971421719, train/logprobs = tensor([[ -0.6276, -14.8995],
        [ -4.6208,  -3.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21965476870536804
Epoch 0, Step 5550: train/loss = 0.02293461561203003, train/raw-loss = 0.0012723596300929785, train/logprobs = tensor([[ -1.4456, -16.5216],
        [ -9.1390,  -2.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21662254631519318
Epoch 0, Step 5551: train/loss = 0.02893160842359066, train/raw-loss = 0.0015528028598055243, train/logprobs = tensor([[ -1.2427, -15.2869],
        [ -9.9786,  -3.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2737880349159241
Epoch 0, Step 5552: train/loss = 0.04228806123137474, train/raw-loss = 0.020454546436667442, train/logprobs = tensor([[ -2.3260, -12.9254],
        [ -6.7660,  -2.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21833515167236328
Epoch 0, Step 5553: train/loss = 0.04690408334136009, train/raw-loss = 0.02362450584769249, train/logprobs = tensor([[ -1.0550, -15.8474],
        [ -6.3830,  -2.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23279577493667603
Epoch 0, Step 5554: train/loss = 0.025325629860162735, train/raw-loss = 0.0024013910442590714, train/logprobs = tensor([[ -1.3569, -15.5843],
        [ -8.2034,  -4.1010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22924238443374634
Epoch 0, Step 5555: train/loss = 0.030634477734565735, train/raw-loss = 0.0028676986694335938, train/logprobs = tensor([[ -0.8327, -12.9424],
        [ -6.9890,  -2.5659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2776677906513214
Epoch 0, Step 5556: train/loss = 0.027339637279510498, train/raw-loss = 0.0014486501459032297, train/logprobs = tensor([[ -1.0066, -13.3798],
        [ -7.7266,  -3.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589098811149597
Epoch 0, Step 5557: train/loss = 0.030157094821333885, train/raw-loss = 0.004387594759464264, train/logprobs = tensor([[ -1.2643, -14.8370],
        [ -7.7997,  -4.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576950192451477
Epoch 0, Step 5558: train/loss = 0.02470126748085022, train/raw-loss = 0.001178649254143238, train/logprobs = tensor([[ -1.2583, -16.0540],
        [ -8.2554,  -3.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23522615432739258
Epoch 0, Step 5559: train/loss = 0.03662519529461861, train/raw-loss = 0.006571412086486816, train/logprobs = tensor([[ -1.1296, -12.6959],
        [ -6.8794,  -3.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005378246307373
Epoch 0, Step 5560: train/loss = 0.027174659073352814, train/raw-loss = 0.0021053655073046684, train/logprobs = tensor([[-1.2251, -8.8440],
        [-7.8502, -1.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506929337978363
Epoch 0, Step 5561: train/loss = 0.028205227106809616, train/raw-loss = 0.0008846370037645102, train/logprobs = tensor([[ -1.7597, -10.4148],
        [ -9.0048,  -1.6705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27320587635040283
Epoch 0, Step 5562: train/loss = 0.03147774189710617, train/raw-loss = 0.010226104408502579, train/logprobs = tensor([[ -0.8045, -12.9096],
        [ -5.5539,  -2.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21251638233661652
Epoch 0, Step 5563: train/loss = 0.026628734543919563, train/raw-loss = 0.0024614587891846895, train/logprobs = tensor([[ -1.2034, -17.8492],
        [ -7.1428,  -5.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24167275428771973
Epoch 0, Step 5564: train/loss = 0.027745522558689117, train/raw-loss = 0.003131567733362317, train/logprobs = tensor([[ -1.2489, -12.7112],
        [ -6.9990,  -3.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2461395263671875
Epoch 0, Step 5565: train/loss = 0.023626379668712616, train/raw-loss = 0.002464449964463711, train/logprobs = tensor([[ -1.0688, -16.3058],
        [ -6.8044,  -3.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2116192877292633
Epoch 0, Step 5566: train/loss = 0.027570951730012894, train/raw-loss = 0.001435349928215146, train/logprobs = tensor([[ -1.0981, -12.6565],
        [ -7.7569,  -3.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26135602593421936
Epoch 0, Step 5567: train/loss = 0.028200171887874603, train/raw-loss = 0.0037611534353345633, train/logprobs = tensor([[ -1.5402, -12.4753],
        [ -7.7387,  -2.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24439018964767456
Epoch 0, Step 5568: train/loss = 0.028066139668226242, train/raw-loss = 0.0066070156171917915, train/logprobs = tensor([[ -1.0852, -10.1381],
        [ -7.8828,  -2.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21459124982357025
Epoch 0, Step 5569: train/loss = 0.02612728253006935, train/raw-loss = 0.005085059907287359, train/logprobs = tensor([[ -0.9662, -15.2115],
        [ -7.3179,  -3.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21042221784591675
Epoch 0, Step 5570: train/loss = 0.026435377076268196, train/raw-loss = 0.002406824380159378, train/logprobs = tensor([[ -1.1466, -12.1350],
        [ -7.4927,  -2.5105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24028551578521729
Epoch 0, Step 5571: train/loss = 0.026049042120575905, train/raw-loss = 0.0022472613491117954, train/logprobs = tensor([[ -1.0566, -17.2943],
        [ -6.6497,  -4.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23801779747009277
Epoch 0, Step 5572: train/loss = 0.030963866040110588, train/raw-loss = 0.005350037012249231, train/logprobs = tensor([[ -1.2501, -11.2725],
        [ -7.9702,  -3.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25613829493522644
Epoch 0, Step 5573: train/loss = 0.029943477362394333, train/raw-loss = 0.00773521838709712, train/logprobs = tensor([[-0.5848, -9.8157],
        [-5.6972, -1.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22208258509635925
Epoch 0, Step 5574: train/loss = 0.02812695875763893, train/raw-loss = 0.001721360837109387, train/logprobs = tensor([[ -1.3844, -12.1913],
        [ -9.0156,  -2.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640559673309326
Epoch 0, Step 5575: train/loss = 0.028386028483510017, train/raw-loss = 0.005298135802149773, train/logprobs = tensor([[ -0.8243, -11.3093],
        [ -7.0848,  -4.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23087893426418304
Epoch 0, Step 5576: train/loss = 0.02740902081131935, train/raw-loss = 0.003575920360162854, train/logprobs = tensor([[ -0.7379, -15.2290],
        [ -6.1561,  -3.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23833101987838745
Epoch 0, Step 5577: train/loss = 0.03220677003264427, train/raw-loss = 0.011419904418289661, train/logprobs = tensor([[ -1.1304, -17.6543],
        [ -6.7529,  -2.6484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20786865055561066
Epoch 0, Step 5578: train/loss = 0.026106679812073708, train/raw-loss = 0.001907523488625884, train/logprobs = tensor([[ -1.2185, -11.2378],
        [ -7.5677,  -2.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2419915795326233
Epoch 0, Step 5579: train/loss = 0.029604099690914154, train/raw-loss = 0.006688385736197233, train/logprobs = tensor([[ -0.9280, -16.7316],
        [ -6.2367,  -4.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22915711998939514
Epoch 0, Step 5580: train/loss = 0.02693970687687397, train/raw-loss = 0.002037197584286332, train/logprobs = tensor([[ -1.0651, -19.7653],
        [ -7.2025,  -4.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24902509152889252
Epoch 0, Step 5581: train/loss = 0.03740154579281807, train/raw-loss = 0.014154953882098198, train/logprobs = tensor([[ -1.4164, -13.2246],
        [ -6.2981,  -3.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23246589303016663
Epoch 0, Step 5582: train/loss = 0.026545032858848572, train/raw-loss = 0.0007164886337704957, train/logprobs = tensor([[ -1.5953, -16.6443],
        [ -8.8456,  -3.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25828540325164795
Epoch 0, Step 5583: train/loss = 0.03338867425918579, train/raw-loss = 0.009622199460864067, train/logprobs = tensor([[ -1.5540, -11.8524],
        [ -7.6497,  -2.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23766475915908813
Epoch 0, Step 5584: train/loss = 0.025982465595006943, train/raw-loss = 0.0028652208857238293, train/logprobs = tensor([[ -1.3428, -13.0280],
        [ -7.1814,  -2.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23117244243621826
Epoch 0, Step 5585: train/loss = 0.027259789407253265, train/raw-loss = 0.003010106971487403, train/logprobs = tensor([[ -0.9739, -15.6321],
        [ -7.8378,  -4.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424968183040619
Epoch 0, Step 5586: train/loss = 0.029209904372692108, train/raw-loss = 0.0015577368903905153, train/logprobs = tensor([[ -1.3670, -13.5471],
        [ -7.5466,  -2.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765216827392578
Epoch 0, Step 5587: train/loss = 0.05391109734773636, train/raw-loss = 0.027830922976136208, train/logprobs = tensor([[ -2.0549, -13.1126],
        [ -8.4793,  -3.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.260801762342453
Epoch 0, Step 5588: train/loss = 0.025770731270313263, train/raw-loss = 0.0024313242174685, train/logprobs = tensor([[ -1.3111, -12.0373],
        [ -8.0680,  -1.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2333940714597702
Epoch 0, Step 5589: train/loss = 0.0256686732172966, train/raw-loss = 0.0033487135078758, train/logprobs = tensor([[ -0.8180, -15.3129],
        [ -6.0138,  -4.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22319960594177246
Epoch 0, Step 5590: train/loss = 0.025857463479042053, train/raw-loss = 0.003907070495188236, train/logprobs = tensor([[ -1.2738, -17.4342],
        [ -7.3912,  -3.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21950390934944153
Epoch 0, Step 5591: train/loss = 0.024444501847028732, train/raw-loss = 0.0009250752627849579, train/logprobs = tensor([[ -1.2062, -14.9786],
        [ -8.5226,  -4.6518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23519425094127655
Epoch 0, Step 5592: train/loss = 0.026271380484104156, train/raw-loss = 0.0031640150118619204, train/logprobs = tensor([[ -1.3975, -12.2294],
        [ -8.0023,  -3.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23107364773750305
Epoch 0, Step 5593: train/loss = 0.02980922907590866, train/raw-loss = 0.00897212140262127, train/logprobs = tensor([[ -1.0346, -13.2455],
        [ -5.5931,  -3.4318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20837105810642242
Epoch 0, Step 5594: train/loss = 0.028841840103268623, train/raw-loss = 0.0069657256826758385, train/logprobs = tensor([[ -1.3916, -12.2273],
        [ -7.4199,  -2.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.218761146068573
Epoch 0, Step 5595: train/loss = 0.04222520440816879, train/raw-loss = 0.01856859400868416, train/logprobs = tensor([[ -1.8811, -12.5393],
        [ -6.9287,  -2.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23656611144542694
Epoch 0, Step 5596: train/loss = 0.024332676082849503, train/raw-loss = 0.0008066786685958505, train/logprobs = tensor([[ -1.4902, -12.3478],
        [ -8.8981,  -2.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352599799633026
Epoch 0, Step 5597: train/loss = 0.024285178631544113, train/raw-loss = 0.0017741501796990633, train/logprobs = tensor([[ -1.0147, -14.3700],
        [ -7.3523,  -3.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251102775335312
Epoch 0, Step 5598: train/loss = 0.025755301117897034, train/raw-loss = 0.0010407230583950877, train/logprobs = tensor([[ -1.1381, -21.9681],
        [ -7.7404,  -5.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24714580178260803
Epoch 0, Step 5599: train/loss = 0.026737675070762634, train/raw-loss = 0.0025982935912907124, train/logprobs = tensor([[ -0.9251, -12.2800],
        [ -7.2063,  -1.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2413938045501709
Epoch 0, Step 5600: train/loss = 0.02747274376451969, train/raw-loss = 0.0006553474231623113, train/logprobs = tensor([[ -1.3838, -12.9844],
        [ -8.9442,  -2.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2681739330291748
Epoch 0, Step 5601: train/loss = 0.028844069689512253, train/raw-loss = 0.005914514418691397, train/logprobs = tensor([[ -1.3671, -15.2464],
        [ -9.7654,  -4.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2292955219745636
Epoch 0, Step 5602: train/loss = 0.037438832223415375, train/raw-loss = 0.014337092638015747, train/logprobs = tensor([[ -0.9617, -12.3359],
        [ -7.2918,  -3.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23101739585399628
Epoch 0, Step 5603: train/loss = 0.02168404683470726, train/raw-loss = 0.001523563638329506, train/logprobs = tensor([[ -1.0375, -15.8011],
        [ -7.8308,  -4.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20160484313964844
Epoch 0, Step 5604: train/loss = 0.026194728910923004, train/raw-loss = 0.0026252795942127705, train/logprobs = tensor([[ -0.9865, -15.6196],
        [ -6.7105,  -2.6129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2356944978237152
Epoch 0, Step 5605: train/loss = 0.021910792216658592, train/raw-loss = 0.0012143589556217194, train/logprobs = tensor([[ -1.3867, -12.2401],
        [ -9.5163,  -4.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20696431398391724
Epoch 0, Step 5606: train/loss = 0.026725701987743378, train/raw-loss = 0.00029667987837456167, train/logprobs = tensor([[ -1.0707, -18.7490],
        [ -8.8007,  -5.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642902135848999
Epoch 0, Step 5607: train/loss = 0.025210164487361908, train/raw-loss = 0.0003798805992119014, train/logprobs = tensor([[ -0.9578, -16.3816],
        [ -8.5681,  -3.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24830284714698792
Epoch 0, Step 5608: train/loss = 0.03587311506271362, train/raw-loss = 0.014477618038654327, train/logprobs = tensor([[ -0.8332, -13.3377],
        [ -5.2803,  -2.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21395498514175415
Epoch 0, Step 5609: train/loss = 0.030606746673583984, train/raw-loss = 0.006627698428928852, train/logprobs = tensor([[ -0.7524, -11.5340],
        [ -5.4698,  -2.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23979045450687408
Epoch 0, Step 5610: train/loss = 0.02558063343167305, train/raw-loss = 0.003232324728742242, train/logprobs = tensor([[ -1.0976, -17.3778],
        [ -7.4675,  -4.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22348308563232422
Epoch 0, Step 5611: train/loss = 0.022921759635210037, train/raw-loss = 0.002871457487344742, train/logprobs = tensor([[ -1.5358, -14.3523],
        [ -7.4275,  -3.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20050302147865295
Epoch 0, Step 5612: train/loss = 0.025917356833815575, train/raw-loss = 0.0014435083139687777, train/logprobs = tensor([[ -0.6056, -15.7276],
        [ -6.6592,  -3.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24473848938941956
Epoch 0, Step 5613: train/loss = 0.030868027359247208, train/raw-loss = 0.00825763400644064, train/logprobs = tensor([[ -1.3336, -13.6216],
        [ -5.5680,  -2.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22610391676425934
Epoch 0, Step 5614: train/loss = 0.025372294709086418, train/raw-loss = 0.0004577984509523958, train/logprobs = tensor([[ -1.5068, -12.3429],
        [-10.0167,  -3.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24914497137069702
Epoch 0, Step 5615: train/loss = 0.02849319949746132, train/raw-loss = 0.008040877059102058, train/logprobs = tensor([[ -0.7867, -13.6998],
        [ -5.7133,  -3.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045232206583023
Epoch 0, Step 5616: train/loss = 0.024070436134934425, train/raw-loss = 0.001504935440607369, train/logprobs = tensor([[ -1.1401, -14.7548],
        [ -7.6759,  -3.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22565500438213348
Epoch 0, Step 5617: train/loss = 0.023586295545101166, train/raw-loss = 0.0007333136163651943, train/logprobs = tensor([[ -1.6420, -12.7297],
        [ -8.9759,  -2.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22852981090545654
Epoch 0, Step 5618: train/loss = 0.029152851551771164, train/raw-loss = 0.004376270342618227, train/logprobs = tensor([[ -1.0515, -15.7645],
        [ -7.3867,  -2.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24776582419872284
Epoch 0, Step 5619: train/loss = 0.029508961364626884, train/raw-loss = 0.008834737353026867, train/logprobs = tensor([[-0.9491, -9.9326],
        [-5.9303, -2.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20674222707748413
Epoch 0, Step 5620: train/loss = 0.026418937370181084, train/raw-loss = 0.0011024699779227376, train/logprobs = tensor([[ -1.2701, -13.0040],
        [ -8.6074,  -3.3068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531646490097046
Epoch 0, Step 5621: train/loss = 0.025172296911478043, train/raw-loss = 0.0018334982451051474, train/logprobs = tensor([[ -1.0227, -13.3072],
        [ -6.9756,  -3.3783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23338797688484192
Epoch 0, Step 5622: train/loss = 0.028885681182146072, train/raw-loss = 0.005011990666389465, train/logprobs = tensor([[ -1.4444, -11.2764],
        [ -6.9408,  -2.2406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23873688280582428
Epoch 0, Step 5623: train/loss = 0.02833312377333641, train/raw-loss = 0.006936920806765556, train/logprobs = tensor([[ -1.3760, -11.3585],
        [ -5.9546,  -2.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21396203339099884
Epoch 0, Step 5624: train/loss = 0.02885059081017971, train/raw-loss = 0.005203003063797951, train/logprobs = tensor([[ -1.2134, -15.0233],
        [ -7.6030,  -4.6346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2364758849143982
Epoch 0, Step 5625: train/loss = 0.025420859456062317, train/raw-loss = 0.001772871008142829, train/logprobs = tensor([[ -1.1900, -11.4535],
        [ -8.5150,  -2.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23647989332675934
Epoch 0, Step 5626: train/loss = 0.039620354771614075, train/raw-loss = 0.016763363033533096, train/logprobs = tensor([[ -1.6587, -13.0824],
        [ -7.9534,  -2.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285699099302292
Epoch 0, Step 5627: train/loss = 0.04342209920287132, train/raw-loss = 0.024211062118411064, train/logprobs = tensor([[-0.4536, -8.5908],
        [-4.5538, -2.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19211038947105408
Epoch 0, Step 5628: train/loss = 0.026308955624699593, train/raw-loss = 0.001792633207514882, train/logprobs = tensor([[ -1.3560, -15.2353],
        [ -9.3091,  -2.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2451631873846054
Epoch 0, Step 5629: train/loss = 0.02574477344751358, train/raw-loss = 0.0012145339278504252, train/logprobs = tensor([[ -1.0195, -16.2009],
        [ -7.2904,  -3.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24530239403247833
Epoch 0, Step 5630: train/loss = 0.02512504905462265, train/raw-loss = 0.0007472921279259026, train/logprobs = tensor([[ -1.3785, -11.4499],
        [ -9.4627,  -2.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2437775731086731
Epoch 0, Step 5631: train/loss = 0.02779971808195114, train/raw-loss = 0.0033465628512203693, train/logprobs = tensor([[ -0.9553, -10.0708],
        [ -6.8738,  -1.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2445315420627594
Epoch 0, Step 5632: train/loss = 0.02488722652196884, train/raw-loss = 0.0016902950592339039, train/logprobs = tensor([[ -1.2141, -16.1605],
        [ -6.9874,  -3.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23196929693222046
Epoch 0, Step 5633: train/loss = 0.02795606479048729, train/raw-loss = 0.003338825423270464, train/logprobs = tensor([[ -1.2467, -18.9059],
        [ -7.4715,  -4.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24617239832878113
Epoch 0, Step 5634: train/loss = 0.023401502519845963, train/raw-loss = 0.0017762671923264861, train/logprobs = tensor([[ -1.7573, -20.1607],
        [ -8.6822,  -3.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21625234186649323
Epoch 0, Step 5635: train/loss = 0.024915404617786407, train/raw-loss = 0.003082698443904519, train/logprobs = tensor([[ -1.1247, -17.1674],
        [ -6.3162,  -5.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21832704544067383
Epoch 0, Step 5636: train/loss = 0.02504052221775055, train/raw-loss = 0.0025235244538635015, train/logprobs = tensor([[ -0.9730, -15.9230],
        [ -7.0591,  -4.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22516997158527374
Epoch 0, Step 5637: train/loss = 0.02320350892841816, train/raw-loss = 0.001394560793414712, train/logprobs = tensor([[ -1.0355, -14.0695],
        [ -8.5083,  -3.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21808947622776031
Epoch 0, Step 5638: train/loss = 0.029579106718301773, train/raw-loss = 0.0026091348845511675, train/logprobs = tensor([[ -1.5700, -17.1758],
        [-10.2570,  -4.3250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26969969272613525
Epoch 0, Step 5639: train/loss = 0.03149713948369026, train/raw-loss = 0.008111322298645973, train/logprobs = tensor([[ -0.8643, -16.3860],
        [ -5.1646,  -4.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2338581532239914
Epoch 0, Step 5640: train/loss = 0.023547671735286713, train/raw-loss = 0.0042002201080322266, train/logprobs = tensor([[ -0.7905, -16.3878],
        [ -5.9402,  -3.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19347451627254486
Epoch 0, Step 5641: train/loss = 0.026428796350955963, train/raw-loss = 0.004669426009058952, train/logprobs = tensor([[ -0.9459, -10.8261],
        [ -6.1472,  -2.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2175936996936798
Epoch 0, Step 5642: train/loss = 0.03304111212491989, train/raw-loss = 0.011539601720869541, train/logprobs = tensor([[ -0.8384, -18.8248],
        [ -5.4155,  -6.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21501508355140686
Epoch 0, Step 5643: train/loss = 0.025436557829380035, train/raw-loss = 0.0020826540421694517, train/logprobs = tensor([[ -1.1657, -13.2150],
        [ -6.9146,  -3.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23353904485702515
Epoch 0, Step 5644: train/loss = 0.02383328229188919, train/raw-loss = 0.0017302337801083922, train/logprobs = tensor([[ -0.9008, -13.9636],
        [ -7.3333,  -2.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22103047370910645
Epoch 0, Step 5645: train/loss = 0.03407745435833931, train/raw-loss = 0.008291475474834442, train/logprobs = tensor([[-0.6938, -9.4771],
        [-6.5025, -2.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578597962856293
Epoch 0, Step 5646: train/loss = 0.028139829635620117, train/raw-loss = 0.0015397940296679735, train/logprobs = tensor([[ -0.6396, -13.0935],
        [ -6.9420,  -2.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26600033044815063
Epoch 0, Step 5647: train/loss = 0.02363862469792366, train/raw-loss = 0.0009889540961012244, train/logprobs = tensor([[ -1.5029, -17.9202],
        [ -8.4081,  -5.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22649668157100677
Epoch 0, Step 5648: train/loss = 0.02522621676325798, train/raw-loss = 0.0011779309716075659, train/logprobs = tensor([[ -0.9715, -15.9101],
        [ -7.3625,  -3.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2404828518629074
Epoch 0, Step 5649: train/loss = 0.024887679144740105, train/raw-loss = 0.001017207046970725, train/logprobs = tensor([[ -1.2516, -14.1312],
        [ -8.5474,  -2.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23870472609996796
Epoch 0, Step 5650: train/loss = 0.02721794880926609, train/raw-loss = 0.00022667026496492326, train/logprobs = tensor([[ -1.2810, -14.5807],
        [ -9.5862,  -3.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26991280913352966
Epoch 0, Step 5651: train/loss = 0.029128488153219223, train/raw-loss = 0.001904468284919858, train/logprobs = tensor([[ -1.0354, -14.5108],
        [ -9.1217,  -3.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27224022150039673
Epoch 0, Step 5652: train/loss = 0.029053792357444763, train/raw-loss = 0.004978816024959087, train/logprobs = tensor([[ -0.7708, -12.8338],
        [ -6.0261,  -2.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240749791264534
Epoch 0, Step 5653: train/loss = 0.025846218690276146, train/raw-loss = 0.0010996349155902863, train/logprobs = tensor([[ -1.3108, -13.2853],
        [ -7.7219,  -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2474658489227295
Epoch 0, Step 5654: train/loss = 0.025968845933675766, train/raw-loss = 0.0038275907281786203, train/logprobs = tensor([[ -0.8042, -13.9401],
        [ -7.2296,  -3.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2214125245809555
Epoch 0, Step 5655: train/loss = 0.02829422801733017, train/raw-loss = 0.0005259286845102906, train/logprobs = tensor([[ -1.3810, -12.9164],
        [ -9.1785,  -2.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27768298983573914
Epoch 0, Step 5656: train/loss = 0.03713676333427429, train/raw-loss = 0.013149683363735676, train/logprobs = tensor([[ -1.2580, -13.8652],
        [ -7.4551,  -2.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2398708015680313
Epoch 0, Step 5657: train/loss = 0.0274844728410244, train/raw-loss = 0.0018078676657751203, train/logprobs = tensor([[ -1.6502, -14.0945],
        [-10.0854,  -3.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25676605105400085
Epoch 0, Step 5658: train/loss = 0.03578813001513481, train/raw-loss = 0.01170299295336008, train/logprobs = tensor([[ -1.0700, -15.9733],
        [ -7.4229,  -5.3092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24085135757923126
Epoch 0, Step 5659: train/loss = 0.04338447377085686, train/raw-loss = 0.019006650894880295, train/logprobs = tensor([[-1.1301, -8.5380],
        [-6.7111, -2.4772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24377822875976562
Epoch 0, Step 5660: train/loss = 0.060415901243686676, train/raw-loss = 0.03708779439330101, train/logprobs = tensor([[ -1.6424, -10.1351],
        [ -7.3269,  -1.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23328101634979248
Epoch 0, Step 5661: train/loss = 0.030028948560357094, train/raw-loss = 0.004646868444979191, train/logprobs = tensor([[ -1.0081, -16.0830],
        [ -7.2522,  -3.3890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538208067417145
Epoch 0, Step 5662: train/loss = 0.024362875148653984, train/raw-loss = 0.001280659344047308, train/logprobs = tensor([[ -1.5366, -17.0892],
        [ -8.6322,  -3.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2308221459388733
Epoch 0, Step 5663: train/loss = 0.02670162171125412, train/raw-loss = 0.0019085643580183387, train/logprobs = tensor([[ -1.6152, -19.6527],
        [ -8.7550,  -3.4550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24793055653572083
Epoch 0, Step 5664: train/loss = 0.02281329222023487, train/raw-loss = 0.001509594963863492, train/logprobs = tensor([[ -1.6327, -19.8468],
        [ -8.7406,  -4.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21303695440292358
Epoch 0, Step 5665: train/loss = 0.026314273476600647, train/raw-loss = 0.002714380156248808, train/logprobs = tensor([[ -1.4867, -11.6762],
        [ -9.2266,  -2.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23599892854690552
Epoch 0, Step 5666: train/loss = 0.028406506404280663, train/raw-loss = 0.0059444485232234, train/logprobs = tensor([[ -1.2052, -20.0801],
        [ -9.9455,  -5.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22462058067321777
Epoch 0, Step 5667: train/loss = 0.02350868657231331, train/raw-loss = 0.0008669806411489844, train/logprobs = tensor([[ -1.0206, -14.1276],
        [ -7.6198,  -2.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22641704976558685
Epoch 0, Step 5668: train/loss = 0.023726314306259155, train/raw-loss = 0.0010871011763811111, train/logprobs = tensor([[-0.8337, -9.6045],
        [-8.4975, -1.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22639213502407074
Epoch 0, Step 5669: train/loss = 0.028865966945886612, train/raw-loss = 0.004937897901982069, train/logprobs = tensor([[ -0.7353, -13.4144],
        [ -6.0031,  -2.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23928070068359375
Epoch 0, Step 5670: train/loss = 0.024346396327018738, train/raw-loss = 0.0004272223450243473, train/logprobs = tensor([[ -1.0182, -12.9484],
        [ -8.9124,  -2.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23919175565242767
Epoch 0, Step 5671: train/loss = 0.04341527819633484, train/raw-loss = 0.020865894854068756, train/logprobs = tensor([[-1.1873, -9.6039],
        [-6.7526, -2.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22549386322498322
Epoch 0, Step 5672: train/loss = 0.03257760405540466, train/raw-loss = 0.01080575305968523, train/logprobs = tensor([[ -1.3225, -11.5288],
        [ -8.6355,  -2.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2177184820175171
Epoch 0, Step 5673: train/loss = 0.022274639457464218, train/raw-loss = 0.0005603324971161783, train/logprobs = tensor([[ -0.8600, -19.3564],
        [ -8.6385,  -4.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21714305877685547
Epoch 0, Step 5674: train/loss = 0.02404809184372425, train/raw-loss = 0.0010424465872347355, train/logprobs = tensor([[ -1.1187, -16.6390],
        [ -7.6146,  -3.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23005643486976624
Epoch 0, Step 5675: train/loss = 0.0333080068230629, train/raw-loss = 0.008738910779356956, train/logprobs = tensor([[ -1.5883, -11.7952],
        [ -6.3573,  -2.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456909567117691
Epoch 0, Step 5676: train/loss = 0.027171656489372253, train/raw-loss = 0.0012295498745515943, train/logprobs = tensor([[ -1.2076, -15.4337],
        [ -8.1465,  -3.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25942105054855347
Epoch 0, Step 5677: train/loss = 0.025454405695199966, train/raw-loss = 0.0003312880580779165, train/logprobs = tensor([[ -1.6936, -15.6583],
        [ -9.6731,  -3.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25123119354248047
Epoch 0, Step 5678: train/loss = 0.026393868029117584, train/raw-loss = 0.0023365214001387358, train/logprobs = tensor([[ -0.9297, -13.6931],
        [ -7.1451,  -3.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2405734658241272
Epoch 0, Step 5679: train/loss = 0.06342081725597382, train/raw-loss = 0.04726969450712204, train/logprobs = tensor([[ -1.0379, -20.5865],
        [ -5.4374,  -6.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16151127219200134
Epoch 0, Step 5680: train/loss = 0.027921652421355247, train/raw-loss = 0.002236403990536928, train/logprobs = tensor([[ -1.0948, -15.7517],
        [ -7.6175,  -4.3572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25685247778892517
Epoch 0, Step 5681: train/loss = 0.024299729615449905, train/raw-loss = 0.0007475085440091789, train/logprobs = tensor([[ -0.9880, -17.7860],
        [ -8.2126,  -3.3355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23552219569683075
Epoch 0, Step 5682: train/loss = 0.024538230150938034, train/raw-loss = 0.0005862165708094835, train/logprobs = tensor([[ -1.0952, -16.0654],
        [ -8.2612,  -3.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395201176404953
Epoch 0, Step 5683: train/loss = 0.029337875545024872, train/raw-loss = 0.0032307361252605915, train/logprobs = tensor([[ -0.8471, -14.4949],
        [ -7.6069,  -3.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610713839530945
Epoch 0, Step 5684: train/loss = 0.024766236543655396, train/raw-loss = 0.0020367286633700132, train/logprobs = tensor([[ -1.0093, -13.7405],
        [ -8.5467,  -3.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22729507088661194
Epoch 0, Step 5685: train/loss = 0.02753724344074726, train/raw-loss = 0.005269236396998167, train/logprobs = tensor([[ -0.9231, -15.6966],
        [ -7.7239,  -5.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22268006205558777
Epoch 0, Step 5686: train/loss = 0.02523009106516838, train/raw-loss = 0.003798504127189517, train/logprobs = tensor([[ -1.1114, -10.3280],
        [ -7.1148,  -3.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21431586146354675
Epoch 0, Step 5687: train/loss = 0.03976525738835335, train/raw-loss = 0.019582994282245636, train/logprobs = tensor([[-0.6612, -8.5417],
        [-4.7483, -2.2808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2018226683139801
Epoch 0, Step 5688: train/loss = 0.025994759052991867, train/raw-loss = 0.0024293854366987944, train/logprobs = tensor([[ -1.1815, -13.8195],
        [ -8.6081,  -2.5732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23565377295017242
Epoch 0, Step 5689: train/loss = 0.02665116637945175, train/raw-loss = 0.0022318388801068068, train/logprobs = tensor([[ -1.0760, -12.2227],
        [ -6.9626,  -2.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24419327080249786
Epoch 0, Step 5690: train/loss = 0.034902848303318024, train/raw-loss = 0.011309687048196793, train/logprobs = tensor([[ -0.6291, -11.8171],
        [ -4.6740,  -2.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359316349029541
Epoch 0, Step 5691: train/loss = 0.027857793495059013, train/raw-loss = 0.006557542365044355, train/logprobs = tensor([[ -1.1043, -10.9701],
        [ -8.2818,  -3.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2130025178194046
Epoch 0, Step 5692: train/loss = 0.025103140622377396, train/raw-loss = 0.004106930457055569, train/logprobs = tensor([[ -0.9899, -13.7062],
        [ -7.0616,  -3.3817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20996209979057312
Epoch 0, Step 5693: train/loss = 0.024676337838172913, train/raw-loss = 0.0008778417250141501, train/logprobs = tensor([[ -1.4225, -15.9621],
        [ -9.0929,  -3.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23798497021198273
Epoch 0, Step 5694: train/loss = 0.024502739310264587, train/raw-loss = 0.0007117682253010571, train/logprobs = tensor([[ -0.8390, -13.7668],
        [ -8.5707,  -3.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2379096895456314
Epoch 0, Step 5695: train/loss = 0.03502029925584793, train/raw-loss = 0.012486475519835949, train/logprobs = tensor([[ -1.2063, -13.3252],
        [ -5.8984,  -2.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22533825039863586
Epoch 0, Step 5696: train/loss = 0.024762064218521118, train/raw-loss = 0.00019517503096722066, train/logprobs = tensor([[ -1.2686, -23.2692],
        [-10.2314,  -5.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24566887319087982
Epoch 0, Step 5697: train/loss = 0.0229722261428833, train/raw-loss = 0.0018970770761370659, train/logprobs = tensor([[ -0.8848, -11.4454],
        [ -7.2255,  -2.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2107514888048172
Epoch 0, Step 5698: train/loss = 0.023889509961009026, train/raw-loss = 0.002931272378191352, train/logprobs = tensor([[ -1.0686, -12.1853],
        [ -7.7094,  -2.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095823884010315
Epoch 0, Step 5699: train/loss = 0.023469816893339157, train/raw-loss = 0.003599112620577216, train/logprobs = tensor([[ -0.9497, -10.2539],
        [ -7.0930,  -2.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19870705902576447
Epoch 0, Step 5700: train/loss = 0.027300067245960236, train/raw-loss = 0.002438305178657174, train/logprobs = tensor([[ -1.2028, -15.9876],
        [ -8.5087,  -3.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24861763417720795
Epoch 0, Step 5701: train/loss = 0.026265215128660202, train/raw-loss = 0.0015869992785155773, train/logprobs = tensor([[ -0.7147, -13.1472],
        [ -7.2106,  -2.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24678216874599457
Epoch 0, Step 5702: train/loss = 0.0277760811150074, train/raw-loss = 0.0022423844784498215, train/logprobs = tensor([[ -1.4950, -11.2938],
        [ -8.5738,  -3.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553369700908661
Epoch 0, Step 5703: train/loss = 0.0255274660885334, train/raw-loss = 0.0008521582931280136, train/logprobs = tensor([[ -1.5932, -16.5274],
        [ -8.3829,  -4.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2467530518770218
Epoch 0, Step 5704: train/loss = 0.026596421375870705, train/raw-loss = 0.0030589397065341473, train/logprobs = tensor([[ -1.0495, -12.2928],
        [ -7.8955,  -2.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2353748083114624
Epoch 0, Step 5705: train/loss = 0.02673853002488613, train/raw-loss = 0.0005982531001791358, train/logprobs = tensor([[ -1.2875, -12.3751],
        [ -8.7856,  -2.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26140275597572327
Epoch 0, Step 5706: train/loss = 0.024778315797448158, train/raw-loss = 0.0014372564619407058, train/logprobs = tensor([[ -1.5648, -16.4656],
        [ -8.9968,  -4.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23341059684753418
Epoch 0, Step 5707: train/loss = 0.02470378577709198, train/raw-loss = 0.0023448835127055645, train/logprobs = tensor([[ -1.3082, -12.1508],
        [ -7.5178,  -2.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22358901798725128
Epoch 0, Step 5708: train/loss = 0.02489268220961094, train/raw-loss = 0.0019746075849980116, train/logprobs = tensor([[ -1.1811, -19.3399],
        [ -8.4066,  -6.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291807383298874
Epoch 0, Step 5709: train/loss = 0.029751135036349297, train/raw-loss = 0.0021398342214524746, train/logprobs = tensor([[ -0.9949, -15.5916],
        [ -7.6765,  -3.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27611300349235535
Epoch 0, Step 5710: train/loss = 0.022936034947633743, train/raw-loss = 0.0036325405817478895, train/logprobs = tensor([[ -1.1594, -12.2151],
        [ -6.4647,  -2.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19303491711616516
Epoch 0, Step 5711: train/loss = 0.027671225368976593, train/raw-loss = 0.00326092098839581, train/logprobs = tensor([[ -0.9940, -13.2073],
        [ -7.5246,  -2.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24410304427146912
Epoch 0, Step 5712: train/loss = 0.03887896612286568, train/raw-loss = 0.008018790744245052, train/logprobs = tensor([[ -1.1182, -13.7693],
        [ -9.4692,  -2.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086017370223999
Epoch 0, Step 5713: train/loss = 0.03520682826638222, train/raw-loss = 0.011699878610670567, train/logprobs = tensor([[ -0.9085, -16.0830],
        [ -6.2480,  -4.6775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23506945371627808
Epoch 0, Step 5714: train/loss = 0.027476415038108826, train/raw-loss = 0.005334719084203243, train/logprobs = tensor([[ -0.8800, -11.6857],
        [ -5.7073,  -2.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22141695022583008
Epoch 0, Step 5715: train/loss = 0.023845579475164413, train/raw-loss = 0.0005226231296546757, train/logprobs = tensor([[ -1.2379, -15.7793],
        [ -8.3934,  -3.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23322956264019012
Epoch 0, Step 5716: train/loss = 0.025619644671678543, train/raw-loss = 0.0011217441642656922, train/logprobs = tensor([[ -1.4626, -13.7224],
        [ -8.8262,  -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24497900903224945
Epoch 0, Step 5717: train/loss = 0.028688332065939903, train/raw-loss = 0.004036916885524988, train/logprobs = tensor([[ -0.7886, -11.2287],
        [ -6.2950,  -1.9276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24651414155960083
Epoch 0, Step 5718: train/loss = 0.02990017458796501, train/raw-loss = 0.005377901718020439, train/logprobs = tensor([[ -1.1215, -14.5610],
        [ -8.8208,  -5.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24522274732589722
Epoch 0, Step 5719: train/loss = 0.028210105374455452, train/raw-loss = 0.0020335600711405277, train/logprobs = tensor([[ -0.9894, -12.4372],
        [ -8.6004,  -2.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2617654800415039
Epoch 0, Step 5720: train/loss = 0.02461925894021988, train/raw-loss = 0.001967156771570444, train/logprobs = tensor([[-0.9910, -9.8009],
        [-7.4500, -2.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22652101516723633
Epoch 0, Step 5721: train/loss = 0.03527802601456642, train/raw-loss = 0.01463158056139946, train/logprobs = tensor([[-0.6148, -9.5404],
        [-5.0451, -2.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20646443963050842
Epoch 0, Step 5722: train/loss = 0.025934826582670212, train/raw-loss = 0.0016908488469198346, train/logprobs = tensor([[ -1.1961, -16.3340],
        [ -7.1780,  -3.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24243976175785065
Epoch 0, Step 5723: train/loss = 0.02809450775384903, train/raw-loss = 0.005407610442489386, train/logprobs = tensor([[ -1.1699, -13.7391],
        [ -6.6739,  -2.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22686895728111267
Epoch 0, Step 5724: train/loss = 0.026670098304748535, train/raw-loss = 0.000985299819149077, train/logprobs = tensor([[ -1.2427, -12.7380],
        [ -8.3034,  -3.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25684797763824463
Epoch 0, Step 5725: train/loss = 0.02514294907450676, train/raw-loss = 0.004496430046856403, train/logprobs = tensor([[ -1.0953, -16.6424],
        [ -5.9210,  -3.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20646518468856812
Epoch 0, Step 5726: train/loss = 0.02763708494603634, train/raw-loss = 0.0051009864546358585, train/logprobs = tensor([[ -0.6581, -12.2593],
        [ -6.4642,  -3.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22536097466945648
Epoch 0, Step 5727: train/loss = 0.025295693427324295, train/raw-loss = 0.00452807080000639, train/logprobs = tensor([[ -1.0126, -16.7090],
        [ -6.2820,  -4.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2076762318611145
Epoch 0, Step 5728: train/loss = 0.024176500737667084, train/raw-loss = 0.0017299026949331164, train/logprobs = tensor([[ -1.5655, -16.9713],
        [ -9.1356,  -4.3890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2244659811258316
Epoch 0, Step 5729: train/loss = 0.02541900798678398, train/raw-loss = 0.001086713164113462, train/logprobs = tensor([[ -1.4173, -13.0520],
        [ -8.8791,  -3.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24332295358181
Epoch 0, Step 5730: train/loss = 0.02484489604830742, train/raw-loss = 0.004447886720299721, train/logprobs = tensor([[ -1.2243, -14.1519],
        [ -6.0466,  -3.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2039700746536255
Epoch 0, Step 5731: train/loss = 0.07757652550935745, train/raw-loss = 0.05494536831974983, train/logprobs = tensor([[ -0.9952, -11.0603],
        [ -4.9683,  -2.4230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263116091489792
Epoch 0, Step 5732: train/loss = 0.04218875989317894, train/raw-loss = 0.013854864053428173, train/logprobs = tensor([[ -1.1255, -10.4647],
        [ -6.0928,  -2.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833389639854431
Epoch 0, Step 5733: train/loss = 0.023947065696120262, train/raw-loss = 0.0021460335701704025, train/logprobs = tensor([[ -0.8452, -18.2489],
        [ -6.9520,  -4.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180103212594986
Epoch 0, Step 5734: train/loss = 0.02669747732579708, train/raw-loss = 0.006016045808792114, train/logprobs = tensor([[ -0.9228, -12.6273],
        [ -7.1034,  -3.1045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20681431889533997
Epoch 0, Step 5735: train/loss = 0.02579367533326149, train/raw-loss = 0.001500539481639862, train/logprobs = tensor([[ -0.7963, -12.9357],
        [ -7.2598,  -2.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24293136596679688
Epoch 0, Step 5736: train/loss = 0.028435293585062027, train/raw-loss = 0.006695639807730913, train/logprobs = tensor([[ -0.7006, -12.8363],
        [ -5.2648,  -2.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.217396542429924
Epoch 0, Step 5737: train/loss = 0.025007562711834908, train/raw-loss = 0.002155948430299759, train/logprobs = tensor([[ -1.2088, -15.5992],
        [ -7.9245,  -4.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285161167383194
Epoch 0, Step 5738: train/loss = 0.02230082079768181, train/raw-loss = 0.0006016616243869066, train/logprobs = tensor([[ -1.5749, -15.2221],
        [ -9.5782,  -3.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21699158847332
Epoch 0, Step 5739: train/loss = 0.05986204743385315, train/raw-loss = 0.0408036895096302, train/logprobs = tensor([[ -0.9273, -11.5219],
        [ -5.4023,  -1.7477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19058354198932648
Epoch 0, Step 5740: train/loss = 0.027933277189731598, train/raw-loss = 0.0014455452328547835, train/logprobs = tensor([[ -1.5283, -13.8403],
        [ -9.7950,  -2.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2648773193359375
Epoch 0, Step 5741: train/loss = 0.031254447996616364, train/raw-loss = 0.004960175603628159, train/logprobs = tensor([[ -1.6473, -13.0025],
        [ -6.9838,  -3.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26294270157814026
Epoch 0, Step 5742: train/loss = 0.024811331182718277, train/raw-loss = 0.005168844945728779, train/logprobs = tensor([[ -1.9759, -12.8845],
        [ -8.1733,  -2.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19642485678195953
Epoch 0, Step 5743: train/loss = 0.030507251620292664, train/raw-loss = 0.004101788625121117, train/logprobs = tensor([[ -0.8956, -12.2775],
        [ -7.4098,  -4.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26405462622642517
Epoch 0, Step 5744: train/loss = 0.03439389169216156, train/raw-loss = 0.0080296965315938, train/logprobs = tensor([[ -1.4632, -10.9156],
        [ -8.4419,  -2.3874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26364195346832275
Epoch 0, Step 5745: train/loss = 0.027149759232997894, train/raw-loss = 0.00442168116569519, train/logprobs = tensor([[-1.5441, -9.8833],
        [-8.1257, -2.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22728076577186584
Epoch 0, Step 5746: train/loss = 0.02442024089396, train/raw-loss = 0.0019122941885143518, train/logprobs = tensor([[ -1.0768, -17.4591],
        [ -7.0451,  -3.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2250794768333435
Epoch 0, Step 5747: train/loss = 0.023995425552129745, train/raw-loss = 0.002888183109462261, train/logprobs = tensor([[ -1.0458, -16.8801],
        [ -8.2909,  -4.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2110724151134491
Epoch 0, Step 5748: train/loss = 0.025768941268324852, train/raw-loss = 0.004539000801742077, train/logprobs = tensor([[ -0.9518, -11.3120],
        [ -8.3481,  -2.2753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122993916273117
Epoch 0, Step 5749: train/loss = 0.03235882520675659, train/raw-loss = 0.009871549904346466, train/logprobs = tensor([[ -0.8153, -10.5402],
        [ -6.2198,  -2.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22487276792526245
Epoch 0, Step 5750: train/loss = 0.03809904307126999, train/raw-loss = 0.018912004306912422, train/logprobs = tensor([[ -0.7624, -10.1942],
        [ -4.8110,  -1.4913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19187040627002716
Epoch 0, Step 5751: train/loss = 0.023279111832380295, train/raw-loss = 0.000859938096255064, train/logprobs = tensor([[ -1.1285, -18.5608],
        [ -8.6667,  -6.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22419172525405884
Epoch 0, Step 5752: train/loss = 0.02300283871591091, train/raw-loss = 0.001198481535539031, train/logprobs = tensor([[ -1.4837, -10.9861],
        [ -9.6127,  -2.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21804356575012207
Epoch 0, Step 5753: train/loss = 0.023769330233335495, train/raw-loss = 0.0008294022409245372, train/logprobs = tensor([[ -1.1449, -18.4847],
        [ -8.8007,  -4.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22939929366111755
Epoch 0, Step 5754: train/loss = 0.02522377111017704, train/raw-loss = 0.0024112178944051266, train/logprobs = tensor([[ -0.7046, -20.4387],
        [ -6.8360,  -2.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22812551259994507
Epoch 0, Step 5755: train/loss = 0.041555605828762054, train/raw-loss = 0.023983916267752647, train/logprobs = tensor([[ -1.1999, -13.7191],
        [ -6.7593,  -3.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17571686208248138
Epoch 0, Step 5756: train/loss = 0.04539850354194641, train/raw-loss = 0.01743207685649395, train/logprobs = tensor([[ -1.1666, -11.7803],
        [ -6.8240,  -3.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2796642780303955
Epoch 0, Step 5757: train/loss = 0.025647558271884918, train/raw-loss = 0.0025413385592401028, train/logprobs = tensor([[ -1.2161, -14.4974],
        [ -7.9646,  -3.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23106218874454498
Epoch 0, Step 5758: train/loss = 0.02758307196199894, train/raw-loss = 0.005659804679453373, train/logprobs = tensor([[ -0.8941, -15.4604],
        [ -6.6098,  -5.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21923266351222992
Epoch 0, Step 5759: train/loss = 0.028723321855068207, train/raw-loss = 0.004934221040457487, train/logprobs = tensor([[ -1.0988, -15.6401],
        [ -6.5069,  -3.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23789098858833313
Epoch 0, Step 5760: train/loss = 0.02766892872750759, train/raw-loss = 0.0006645181565545499, train/logprobs = tensor([[ -1.1817, -11.0346],
        [-10.3145,  -2.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27004408836364746
Epoch 0, Step 5761: train/loss = 0.03171888738870621, train/raw-loss = 0.008880922570824623, train/logprobs = tensor([[-1.0983, -9.9351],
        [-7.0305, -2.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22837963700294495
Epoch 0, Step 5762: train/loss = 0.028116267174482346, train/raw-loss = 0.005545980297029018, train/logprobs = tensor([[ -1.0736, -17.7653],
        [ -6.3600,  -4.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22570286691188812
Epoch 0, Step 5763: train/loss = 0.02575499564409256, train/raw-loss = 0.0015714934561401606, train/logprobs = tensor([[ -1.4693, -15.7731],
        [ -8.8649,  -4.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24183499813079834
Epoch 0, Step 5764: train/loss = 0.02614709734916687, train/raw-loss = 0.0025690807960927486, train/logprobs = tensor([[ -1.0061, -19.0966],
        [ -6.6961,  -4.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23578014969825745
Epoch 0, Step 5765: train/loss = 0.024421146139502525, train/raw-loss = 0.0006164599908515811, train/logprobs = tensor([[ -1.2664, -12.3265],
        [ -8.6499,  -3.0095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23804686963558197
Epoch 0, Step 5766: train/loss = 0.02815382368862629, train/raw-loss = 0.003912059590220451, train/logprobs = tensor([[ -1.0709, -15.9606],
        [ -6.8798,  -4.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24241763353347778
Epoch 0, Step 5767: train/loss = 0.028807707130908966, train/raw-loss = 0.0008212707471102476, train/logprobs = tensor([[ -1.0517, -12.2367],
        [ -9.0017,  -3.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798643708229065
Epoch 0, Step 5768: train/loss = 0.024772055447101593, train/raw-loss = 0.0017813799204304814, train/logprobs = tensor([[ -1.0287, -15.8050],
        [ -7.6372,  -4.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22990673780441284
Epoch 0, Step 5769: train/loss = 0.024623269215226173, train/raw-loss = 0.0031823923345655203, train/logprobs = tensor([[ -1.0373, -12.8243],
        [ -6.2944,  -2.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2144087553024292
Epoch 0, Step 5770: train/loss = 0.02425008825957775, train/raw-loss = 0.0012892811791971326, train/logprobs = tensor([[ -1.2298, -10.9678],
        [ -8.0182,  -1.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22960805892944336
Epoch 0, Step 5771: train/loss = 0.025071248412132263, train/raw-loss = 0.00043326846207492054, train/logprobs = tensor([[ -1.2982, -14.3283],
        [ -8.9318,  -3.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2463797926902771
Epoch 0, Step 5772: train/loss = 0.028214339166879654, train/raw-loss = 0.0056715658865869045, train/logprobs = tensor([[-1.4302, -9.9019],
        [-7.1887, -2.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2254277467727661
Epoch 0, Step 5773: train/loss = 0.025874977931380272, train/raw-loss = 0.0013715842505916953, train/logprobs = tensor([[ -0.9323, -20.7969],
        [ -7.0818,  -4.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24503393471240997
Epoch 0, Step 5774: train/loss = 0.026797613129019737, train/raw-loss = 0.0039268662221729755, train/logprobs = tensor([[ -1.1706, -10.9227],
        [ -6.8990,  -2.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2287074625492096
Epoch 0, Step 5775: train/loss = 0.02958303689956665, train/raw-loss = 0.0032462882809340954, train/logprobs = tensor([[ -0.8404, -15.1226],
        [ -6.3346,  -3.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633674740791321
Epoch 0, Step 5776: train/loss = 0.028312349691987038, train/raw-loss = 0.0024087352212518454, train/logprobs = tensor([[ -0.8400, -14.3235],
        [ -6.5896,  -3.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.259036123752594
Epoch 0, Step 5777: train/loss = 0.02436717599630356, train/raw-loss = 0.00243139429949224, train/logprobs = tensor([[ -0.9449, -14.1380],
        [ -8.7068,  -3.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21935781836509705
Epoch 0, Step 5778: train/loss = 0.025925183668732643, train/raw-loss = 0.0011424935655668378, train/logprobs = tensor([[ -0.9663, -16.1226],
        [ -8.9745,  -5.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24782688915729523
Epoch 0, Step 5779: train/loss = 0.02868800051510334, train/raw-loss = 0.001307784696109593, train/logprobs = tensor([[ -1.4675, -11.6589],
        [ -8.7750,  -2.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27380213141441345
Epoch 0, Step 5780: train/loss = 0.024716747924685478, train/raw-loss = 0.0011575083481147885, train/logprobs = tensor([[ -1.6577, -14.4472],
        [ -9.6359,  -2.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23559238016605377
Epoch 0, Step 5781: train/loss = 0.030676327645778656, train/raw-loss = 0.006559638772159815, train/logprobs = tensor([[ -1.2130, -11.1526],
        [ -7.3668,  -3.2408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2411668747663498
Epoch 0, Step 5782: train/loss = 0.03246074169874191, train/raw-loss = 0.008264278993010521, train/logprobs = tensor([[ -0.9619, -15.9920],
        [ -7.4711,  -4.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24196462333202362
Epoch 0, Step 5783: train/loss = 0.02686675265431404, train/raw-loss = 0.0033548525534570217, train/logprobs = tensor([[ -1.3585, -14.2245],
        [ -8.9805,  -2.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2351190149784088
Epoch 0, Step 5784: train/loss = 0.02351926639676094, train/raw-loss = 0.0005865504499524832, train/logprobs = tensor([[ -1.1243, -18.5973],
        [ -8.5552,  -3.2081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22932717204093933
Epoch 0, Step 5785: train/loss = 0.02461019530892372, train/raw-loss = 0.0028052739799022675, train/logprobs = tensor([[ -0.8875, -17.2447],
        [ -6.3618,  -4.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21804922819137573
Epoch 0, Step 5786: train/loss = 0.056831274181604385, train/raw-loss = 0.03208409249782562, train/logprobs = tensor([[ -0.7636, -11.9830],
        [ -5.0152,  -3.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24747177958488464
Epoch 0, Step 5787: train/loss = 0.02334968000650406, train/raw-loss = 0.000622887397184968, train/logprobs = tensor([[ -1.0782, -13.2121],
        [ -8.1593,  -3.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22726792097091675
Epoch 0, Step 5788: train/loss = 0.029612019658088684, train/raw-loss = 0.008906342089176178, train/logprobs = tensor([[ -1.4079, -15.7421],
        [ -6.6756,  -3.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20705676078796387
Epoch 0, Step 5789: train/loss = 0.02420135959982872, train/raw-loss = 0.00191697443369776, train/logprobs = tensor([[ -1.3687, -11.2122],
        [ -9.9778,  -2.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22284387052059174
Epoch 0, Step 5790: train/loss = 0.032412443310022354, train/raw-loss = 0.0083623006939888, train/logprobs = tensor([[ -1.3444, -12.7592],
        [ -6.0071,  -2.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24050141870975494
Epoch 0, Step 5791: train/loss = 0.026298388838768005, train/raw-loss = 0.0019263585563749075, train/logprobs = tensor([[ -1.4331, -13.3936],
        [ -7.5366,  -2.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24372027814388275
Epoch 0, Step 5792: train/loss = 0.02810264751315117, train/raw-loss = 0.0014479603851214051, train/logprobs = tensor([[ -1.0871, -15.0932],
        [ -8.1147,  -2.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665468454360962
Epoch 0, Step 5793: train/loss = 0.026219327002763748, train/raw-loss = 0.003894326975569129, train/logprobs = tensor([[ -1.3611, -13.9619],
        [ -7.9440,  -3.3131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22325000166893005
Epoch 0, Step 5794: train/loss = 0.02527780458331108, train/raw-loss = 0.0019808097276836634, train/logprobs = tensor([[ -1.0022, -11.0877],
        [ -9.0193,  -2.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329699695110321
Epoch 0, Step 5795: train/loss = 0.04190666228532791, train/raw-loss = 0.01764434576034546, train/logprobs = tensor([[ -1.1936, -13.0833],
        [ -6.0867,  -4.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24262313544750214
Epoch 0, Step 5796: train/loss = 0.0339883528649807, train/raw-loss = 0.0062844958156347275, train/logprobs = tensor([[ -0.8535, -12.2847],
        [ -6.4898,  -2.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770385444164276
Epoch 0, Step 5797: train/loss = 0.040015265345573425, train/raw-loss = 0.012360338121652603, train/logprobs = tensor([[ -1.0828, -11.6802],
        [ -6.4630,  -3.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765492796897888
Epoch 0, Step 5798: train/loss = 0.02608407475054264, train/raw-loss = 0.0008740233024582267, train/logprobs = tensor([[ -1.2192, -14.1690],
        [ -8.2420,  -3.1709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25210049748420715
Epoch 0, Step 5799: train/loss = 0.02463041990995407, train/raw-loss = 0.002620709128677845, train/logprobs = tensor([[ -1.4922, -11.3678],
        [ -8.5959,  -1.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200971245765686
Epoch 0, Step 5800: train/loss = 0.02781100943684578, train/raw-loss = 0.002438443712890148, train/logprobs = tensor([[ -1.0284, -11.5207],
        [ -7.2385,  -3.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25372564792633057
Epoch 0, Step 5801: train/loss = 0.02662026137113571, train/raw-loss = 0.0005619782023131847, train/logprobs = tensor([[ -1.1486, -14.4004],
        [ -9.4251,  -2.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605828642845154
Epoch 0, Step 5802: train/loss = 0.023829637095332146, train/raw-loss = 0.0007092348532751203, train/logprobs = tensor([[ -2.1611, -13.1652],
        [-10.4800,  -3.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23120401799678802
Epoch 0, Step 5803: train/loss = 0.023889364674687386, train/raw-loss = 0.002043402986600995, train/logprobs = tensor([[ -1.6347, -21.1044],
        [ -8.8712,  -3.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2184596061706543
Epoch 0, Step 5804: train/loss = 0.02100244350731373, train/raw-loss = 0.004066947381943464, train/logprobs = tensor([[ -1.3923, -12.4133],
        [ -6.7556,  -2.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16935496032238007
Epoch 0, Step 5805: train/loss = 0.03647521138191223, train/raw-loss = 0.007399971596896648, train/logprobs = tensor([[ -0.8900, -11.3990],
        [ -7.4583,  -3.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907524108886719
Epoch 0, Step 5806: train/loss = 0.026822658255696297, train/raw-loss = 0.0013065979583188891, train/logprobs = tensor([[ -1.2127, -14.1284],
        [ -8.4509,  -4.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551605701446533
Epoch 0, Step 5807: train/loss = 0.03198267146945, train/raw-loss = 0.006396290846168995, train/logprobs = tensor([[ -0.9878, -10.4382],
        [ -7.6980,  -1.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558637857437134
Epoch 0, Step 5808: train/loss = 0.02501506730914116, train/raw-loss = 0.003702873829752207, train/logprobs = tensor([[ -0.9819, -11.7199],
        [ -6.7911,  -2.4554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2131219208240509
Epoch 0, Step 5809: train/loss = 0.019177479669451714, train/raw-loss = 0.0003426858747843653, train/logprobs = tensor([[ -1.2716, -12.3596],
        [ -9.2708,  -3.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1883479356765747
Epoch 0, Step 5810: train/loss = 0.027729660272598267, train/raw-loss = 0.0017625164473429322, train/logprobs = tensor([[ -0.6495, -13.1497],
        [ -6.5193,  -2.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596714198589325
Epoch 0, Step 5811: train/loss = 0.024055561050772667, train/raw-loss = 0.0012316274223849177, train/logprobs = tensor([[ -1.4869, -13.3099],
        [ -8.7131,  -3.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22823932766914368
Epoch 0, Step 5812: train/loss = 0.024999380111694336, train/raw-loss = 0.0006382680148817599, train/logprobs = tensor([[ -1.3400, -15.5141],
        [ -8.1676,  -3.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24361112713813782
Epoch 0, Step 5813: train/loss = 0.024775490164756775, train/raw-loss = 0.0006329331081360579, train/logprobs = tensor([[ -1.1211, -12.8520],
        [ -9.1564,  -4.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24142558872699738
Epoch 0, Step 5814: train/loss = 0.02771206572651863, train/raw-loss = 0.006730475928634405, train/logprobs = tensor([[ -1.5075, -15.1409],
        [ -7.2395,  -4.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2098158895969391
Epoch 0, Step 5815: train/loss = 0.021713294088840485, train/raw-loss = 0.0014640612062066793, train/logprobs = tensor([[ -1.3193, -14.4742],
        [ -7.7788,  -4.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2024923413991928
Epoch 0, Step 5816: train/loss = 0.028180746361613274, train/raw-loss = 0.0017008762806653976, train/logprobs = tensor([[ -0.7362, -13.0138],
        [ -7.6915,  -1.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26479870080947876
Epoch 0, Step 5817: train/loss = 0.044847261160612106, train/raw-loss = 0.023490060120821, train/logprobs = tensor([[ -1.0445, -13.5678],
        [ -5.8740,  -2.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21357199549674988
Epoch 0, Step 5818: train/loss = 0.0451362244784832, train/raw-loss = 0.02055296115577221, train/logprobs = tensor([[ -0.8120, -11.6202],
        [ -5.7910,  -2.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.245832622051239
Epoch 0, Step 5819: train/loss = 0.029429513961076736, train/raw-loss = 0.007542669773101807, train/logprobs = tensor([[ -1.2492, -16.0826],
        [ -6.6440,  -3.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2188684344291687
Epoch 0, Step 5820: train/loss = 0.028201406821608543, train/raw-loss = 0.0042184460908174515, train/logprobs = tensor([[ -0.8613, -12.3064],
        [ -7.6250,  -2.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23982961475849152
Epoch 0, Step 5821: train/loss = 0.024277253076434135, train/raw-loss = 0.0011854313779622316, train/logprobs = tensor([[ -1.1329, -12.2638],
        [ -8.3293,  -2.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23091822862625122
Epoch 0, Step 5822: train/loss = 0.026033569127321243, train/raw-loss = 0.00031852908432483673, train/logprobs = tensor([[ -1.6619, -15.6430],
        [-11.2933,  -3.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25715041160583496
Epoch 0, Step 5823: train/loss = 0.028065871447324753, train/raw-loss = 0.0014703390188515186, train/logprobs = tensor([[ -1.3005, -13.4975],
        [ -7.7604,  -2.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659553289413452
Epoch 0, Step 5824: train/loss = 0.024806102737784386, train/raw-loss = 0.0029838646296411753, train/logprobs = tensor([[ -0.7649, -12.1345],
        [ -6.2722,  -2.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21822237968444824
Epoch 0, Step 5825: train/loss = 0.026026640087366104, train/raw-loss = 0.002911950461566448, train/logprobs = tensor([[ -0.7276, -16.7241],
        [ -6.3775,  -3.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2311468869447708
Epoch 0, Step 5826: train/loss = 0.025728663429617882, train/raw-loss = 0.0010090505238622427, train/logprobs = tensor([[ -1.1612, -13.4675],
        [ -7.5944,  -2.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24719613790512085
Epoch 0, Step 5827: train/loss = 0.02584540843963623, train/raw-loss = 0.0019784809555858374, train/logprobs = tensor([[ -1.5155, -11.2293],
        [-10.3734,  -2.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2386692762374878
Epoch 0, Step 5828: train/loss = 0.025979258120059967, train/raw-loss = 0.004147929139435291, train/logprobs = tensor([[ -0.7058, -10.6577],
        [ -5.9192,  -2.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2183132916688919
Epoch 0, Step 5829: train/loss = 0.024808989837765694, train/raw-loss = 0.0011822445085272193, train/logprobs = tensor([[ -1.3440, -14.6920],
        [ -8.6632,  -2.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23626746237277985
Epoch 0, Step 5830: train/loss = 0.023956473916769028, train/raw-loss = 0.0019800676964223385, train/logprobs = tensor([[ -1.6684, -11.8502],
        [-11.1255,  -2.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21976405382156372
Epoch 0, Step 5831: train/loss = 0.026235610246658325, train/raw-loss = 0.002263488946482539, train/logprobs = tensor([[ -0.8252, -14.3917],
        [ -6.7289,  -2.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23972120881080627
Epoch 0, Step 5832: train/loss = 0.025390682741999626, train/raw-loss = 0.0016152658499777317, train/logprobs = tensor([[ -0.8215, -16.2152],
        [ -6.6178,  -4.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23775416612625122
Epoch 0, Step 5833: train/loss = 0.024951402097940445, train/raw-loss = 0.0025214487686753273, train/logprobs = tensor([[ -1.2215, -11.6199],
        [ -7.9815,  -2.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22429952025413513
Epoch 0, Step 5834: train/loss = 0.037445880472660065, train/raw-loss = 0.011463513597846031, train/logprobs = tensor([[ -1.4471, -11.0736],
        [ -7.9461,  -2.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25982365012168884
Epoch 0, Step 5835: train/loss = 0.025184601545333862, train/raw-loss = 0.0007828646921552718, train/logprobs = tensor([[ -1.1272, -16.7745],
        [ -8.3298,  -2.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440173625946045
Epoch 0, Step 5836: train/loss = 0.025627125054597855, train/raw-loss = 0.002912010531872511, train/logprobs = tensor([[ -1.3165, -11.1976],
        [ -8.3195,  -3.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22715114057064056
Epoch 0, Step 5837: train/loss = 0.024768155068159103, train/raw-loss = 0.003777775913476944, train/logprobs = tensor([[ -1.1548, -15.4288],
        [ -6.7115,  -4.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2099037915468216
Epoch 0, Step 5838: train/loss = 0.025387480854988098, train/raw-loss = 0.0012661309447139502, train/logprobs = tensor([[ -1.0715, -12.1889],
        [ -8.1804,  -2.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24121348559856415
Epoch 0, Step 5839: train/loss = 0.0234695952385664, train/raw-loss = 0.0007282384322024882, train/logprobs = tensor([[ -1.1302, -21.0800],
        [ -8.6610,  -6.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22741356492042542
Epoch 0, Step 5840: train/loss = 0.02971360646188259, train/raw-loss = 0.004256598185747862, train/logprobs = tensor([[ -0.8653, -16.5110],
        [ -7.2951,  -4.2441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545700669288635
Epoch 0, Step 5841: train/loss = 0.02591744251549244, train/raw-loss = 0.0007961259107105434, train/logprobs = tensor([[ -1.3669, -15.8342],
        [ -9.6581,  -4.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512131631374359
Epoch 0, Step 5842: train/loss = 0.023352330550551414, train/raw-loss = 0.0016740710707381368, train/logprobs = tensor([[ -0.7870, -12.0408],
        [ -7.9299,  -2.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2167825996875763
Epoch 0, Step 5843: train/loss = 0.02480081282556057, train/raw-loss = 0.0021535460837185383, train/logprobs = tensor([[ -1.1704, -12.3558],
        [ -8.7561,  -2.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2264726758003235
Epoch 0, Step 5844: train/loss = 0.024603016674518585, train/raw-loss = 0.002727438462898135, train/logprobs = tensor([[ -1.4028, -12.8102],
        [ -8.4510,  -2.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2187558114528656
Epoch 0, Step 5845: train/loss = 0.02705158106982708, train/raw-loss = 0.004382753744721413, train/logprobs = tensor([[ -1.0692, -13.5274],
        [ -6.2474,  -2.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22668825089931488
Epoch 0, Step 5846: train/loss = 0.03694671764969826, train/raw-loss = 0.009601868689060211, train/logprobs = tensor([[ -1.1224, -10.9843],
        [ -7.3788,  -3.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27344846725463867
Epoch 0, Step 5847: train/loss = 0.023446327075362206, train/raw-loss = 0.0018691867589950562, train/logprobs = tensor([[ -1.3595, -11.7792],
        [ -7.9587,  -3.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2157714068889618
Epoch 0, Step 5848: train/loss = 0.024804268032312393, train/raw-loss = 0.0009345207363367081, train/logprobs = tensor([[ -1.1207, -13.0194],
        [ -9.8969,  -2.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23869746923446655
Epoch 0, Step 5849: train/loss = 0.025758512318134308, train/raw-loss = 0.0022711593192070723, train/logprobs = tensor([[ -1.0021, -14.1820],
        [ -7.4229,  -2.7048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23487351834774017
Epoch 0, Step 5850: train/loss = 0.025334380567073822, train/raw-loss = 0.002898075617849827, train/logprobs = tensor([[ -0.8188, -13.5144],
        [ -6.8440,  -3.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2243630439043045
Epoch 0, Step 5851: train/loss = 0.031730785965919495, train/raw-loss = 0.007413589861243963, train/logprobs = tensor([[-0.9591, -9.9840],
        [-6.9450, -2.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24317196011543274
Epoch 0, Step 5852: train/loss = 0.037677519023418427, train/raw-loss = 0.013738993555307388, train/logprobs = tensor([[ -0.7443, -10.7622],
        [ -6.5026,  -2.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23938524723052979
Epoch 0, Step 5853: train/loss = 0.025551345199346542, train/raw-loss = 0.001939679030328989, train/logprobs = tensor([[ -1.4375, -15.4757],
        [ -7.2000,  -3.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2361166626214981
Epoch 0, Step 5854: train/loss = 0.0292776171118021, train/raw-loss = 0.003930884413421154, train/logprobs = tensor([[ -1.1300, -14.6162],
        [ -7.4849,  -3.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253467321395874
Epoch 0, Step 5855: train/loss = 0.02626098319888115, train/raw-loss = 0.0010467150714248419, train/logprobs = tensor([[ -1.0868, -14.6468],
        [ -7.6967,  -2.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25214266777038574
Epoch 0, Step 5856: train/loss = 0.02293463610112667, train/raw-loss = 0.0005180923035368323, train/logprobs = tensor([[ -0.9467, -16.2620],
        [ -8.5834,  -3.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2241654396057129
Epoch 0, Step 5857: train/loss = 0.02872988022863865, train/raw-loss = 0.0003286982246208936, train/logprobs = tensor([[ -1.3616, -18.4109],
        [ -9.8109,  -5.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840118110179901
Epoch 0, Step 5858: train/loss = 0.025454765185713768, train/raw-loss = 0.0023192379157990217, train/logprobs = tensor([[ -1.1461, -17.0501],
        [ -7.5986,  -5.2842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23135527968406677
Epoch 0, Step 5859: train/loss = 0.02489715814590454, train/raw-loss = 0.001381502253934741, train/logprobs = tensor([[ -0.9960, -12.1924],
        [ -8.3729,  -1.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2351565808057785
Epoch 0, Step 5860: train/loss = 0.02333235926926136, train/raw-loss = 0.0006692067254334688, train/logprobs = tensor([[ -1.2142, -19.0499],
        [ -9.2017,  -4.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2266315221786499
Epoch 0, Step 5861: train/loss = 0.027884788811206818, train/raw-loss = 0.0022970843128859997, train/logprobs = tensor([[ -1.1327, -13.1749],
        [ -8.2682,  -1.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558770477771759
Epoch 0, Step 5862: train/loss = 0.024892309680581093, train/raw-loss = 0.0008151339716278017, train/logprobs = tensor([[ -1.1194, -16.5247],
        [ -8.1527,  -3.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24077175557613373
Epoch 0, Step 5863: train/loss = 0.027969621121883392, train/raw-loss = 0.0025731222704052925, train/logprobs = tensor([[ -1.5429, -11.8699],
        [ -9.2550,  -3.4597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25396496057510376
Epoch 0, Step 5864: train/loss = 0.02471809834241867, train/raw-loss = 0.0016173581825569272, train/logprobs = tensor([[ -0.8151, -13.1623],
        [ -6.9589,  -3.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2310073971748352
Epoch 0, Step 5865: train/loss = 0.026230275630950928, train/raw-loss = 0.0017021896783262491, train/logprobs = tensor([[ -1.1296, -14.7885],
        [ -8.0950,  -2.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24528083205223083
Epoch 0, Step 5866: train/loss = 0.02783719263970852, train/raw-loss = 0.0012095527490600944, train/logprobs = tensor([[ -1.6844, -16.4834],
        [ -9.1330,  -3.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26627638936042786
Epoch 0, Step 5867: train/loss = 0.04056966304779053, train/raw-loss = 0.01678929291665554, train/logprobs = tensor([[ -1.4977, -13.4789],
        [ -6.7463,  -2.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23780368268489838
Epoch 0, Step 5868: train/loss = 0.02656158246099949, train/raw-loss = 0.0013223157729953527, train/logprobs = tensor([[ -0.7937, -12.7904],
        [ -7.3474,  -3.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523926794528961
Epoch 0, Step 5869: train/loss = 0.033440280705690384, train/raw-loss = 0.009842517785727978, train/logprobs = tensor([[-0.9239, -7.8192],
        [-6.1101, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23597760498523712
Epoch 0, Step 5870: train/loss = 0.02466611936688423, train/raw-loss = 0.0022582984529435635, train/logprobs = tensor([[ -1.0751, -15.4443],
        [ -7.1761,  -4.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2240781933069229
Epoch 0, Step 5871: train/loss = 0.027177777141332626, train/raw-loss = 0.004427669569849968, train/logprobs = tensor([[ -0.6274, -13.1743],
        [ -6.0338,  -3.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22750109434127808
Epoch 0, Step 5872: train/loss = 0.024386119097471237, train/raw-loss = 0.0021118910517543554, train/logprobs = tensor([[ -1.1733, -13.5520],
        [ -9.0835,  -1.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22274227440357208
Epoch 0, Step 5873: train/loss = 0.023956438526511192, train/raw-loss = 0.0017907703295350075, train/logprobs = tensor([[ -0.7256, -13.9659],
        [ -6.8310,  -3.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2216566801071167
Epoch 0, Step 5874: train/loss = 0.027068035677075386, train/raw-loss = 0.005033290013670921, train/logprobs = tensor([[ -1.0380, -14.5633],
        [ -6.8268,  -3.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22034744918346405
Epoch 0, Step 5875: train/loss = 0.02970268949866295, train/raw-loss = 0.008087428286671638, train/logprobs = tensor([[ -0.7628, -12.3668],
        [ -5.8788,  -2.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.216152623295784
Epoch 0, Step 5876: train/loss = 0.021341539919376373, train/raw-loss = 0.0024260918144136667, train/logprobs = tensor([[ -1.0742, -14.3471],
        [ -7.6838,  -3.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1891544610261917
Epoch 0, Step 5877: train/loss = 0.031140940263867378, train/raw-loss = 0.0035807620733976364, train/logprobs = tensor([[ -0.8264, -10.0784],
        [ -7.4094,  -1.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2756017744541168
Epoch 0, Step 5878: train/loss = 0.028499657288193703, train/raw-loss = 0.0052328454330563545, train/logprobs = tensor([[ -0.5531, -11.3342],
        [ -5.5202,  -2.6549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23266810178756714
Epoch 0, Step 5879: train/loss = 0.024931788444519043, train/raw-loss = 0.0014247279614210129, train/logprobs = tensor([[ -1.2205, -14.2202],
        [ -8.2277,  -2.2306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2350705862045288
Epoch 0, Step 5880: train/loss = 0.026448816061019897, train/raw-loss = 0.0030366070568561554, train/logprobs = tensor([[ -0.8973, -13.5200],
        [ -6.8348,  -3.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23412208259105682
Epoch 0, Step 5881: train/loss = 0.0326157882809639, train/raw-loss = 0.009576975367963314, train/logprobs = tensor([[ -1.1519, -10.8121],
        [ -6.6168,  -2.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2303881198167801
Epoch 0, Step 5882: train/loss = 0.023341987282037735, train/raw-loss = 0.001697114435955882, train/logprobs = tensor([[ -1.3355, -16.6205],
        [ -8.0293,  -4.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21644872426986694
Epoch 0, Step 5883: train/loss = 0.025809386745095253, train/raw-loss = 0.00177027250174433, train/logprobs = tensor([[ -1.2727, -14.6156],
        [ -7.1607,  -4.3845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24039113521575928
Epoch 0, Step 5884: train/loss = 0.024244099855422974, train/raw-loss = 0.0007027433020994067, train/logprobs = tensor([[ -1.3388, -13.6213],
        [ -9.3653,  -3.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2354135513305664
Epoch 0, Step 5885: train/loss = 0.026175959035754204, train/raw-loss = 0.0010284658055752516, train/logprobs = tensor([[ -0.9645, -15.0836],
        [ -9.0721,  -3.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25147491693496704
Epoch 0, Step 5886: train/loss = 0.026255331933498383, train/raw-loss = 0.0007850410183891654, train/logprobs = tensor([[ -1.2456, -14.1210],
        [ -8.1467,  -2.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25470292568206787
Epoch 0, Step 5887: train/loss = 0.026901230216026306, train/raw-loss = 0.004215325228869915, train/logprobs = tensor([[-0.8254, -9.5397],
        [-7.6220, -2.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22685906291007996
Epoch 0, Step 5888: train/loss = 0.0444459542632103, train/raw-loss = 0.020425064489245415, train/logprobs = tensor([[ -0.6680, -11.3800],
        [ -7.4992,  -2.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24020886421203613
Epoch 0, Step 5889: train/loss = 0.024671832099556923, train/raw-loss = 0.0028173374012112617, train/logprobs = tensor([[ -1.7535, -13.3201],
        [ -8.5241,  -3.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21854494512081146
Epoch 0, Step 5890: train/loss = 0.02837253175675869, train/raw-loss = 0.003228615503758192, train/logprobs = tensor([[ -0.7028, -11.6619],
        [ -6.6459,  -2.5435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514391541481018
Epoch 0, Step 5891: train/loss = 0.023427750915288925, train/raw-loss = 0.002719540847465396, train/logprobs = tensor([[ -2.2580, -16.0954],
        [ -8.7699,  -4.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20708207786083221
Epoch 0, Step 5892: train/loss = 0.0249791219830513, train/raw-loss = 0.0009638607734814286, train/logprobs = tensor([[ -1.0762, -13.3886],
        [ -9.7157,  -3.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24015258252620697
Epoch 0, Step 5893: train/loss = 0.0262598879635334, train/raw-loss = 0.003911481238901615, train/logprobs = tensor([[ -1.1762, -15.6102],
        [ -7.2704,  -4.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234840989112854
Epoch 0, Step 5894: train/loss = 0.02514178864657879, train/raw-loss = 0.0017398467753082514, train/logprobs = tensor([[ -1.5251, -17.2241],
        [ -7.4631,  -4.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340194135904312
Epoch 0, Step 5895: train/loss = 0.055127229541540146, train/raw-loss = 0.03750242665410042, train/logprobs = tensor([[ -1.2669, -12.3051],
        [ -8.2152,  -2.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17624804377555847
Epoch 0, Step 5896: train/loss = 0.02861899323761463, train/raw-loss = 0.0034183755051344633, train/logprobs = tensor([[ -1.3157, -10.9258],
        [ -8.2632,  -2.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520061731338501
Epoch 0, Step 5897: train/loss = 0.05241851136088371, train/raw-loss = 0.027371343225240707, train/logprobs = tensor([[ -0.8407, -11.3049],
        [ -5.6631,  -2.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25047165155410767
Epoch 0, Step 5898: train/loss = 0.026461226865649223, train/raw-loss = 0.0017219571163877845, train/logprobs = tensor([[ -1.0094, -12.2666],
        [ -6.9506,  -3.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2473926991224289
Epoch 0, Step 5899: train/loss = 0.028949789702892303, train/raw-loss = 0.0030797584913671017, train/logprobs = tensor([[ -1.0576, -13.6723],
        [ -9.1049,  -3.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25870031118392944
Epoch 0, Step 5900: train/loss = 0.027906473726034164, train/raw-loss = 0.002980705350637436, train/logprobs = tensor([[ -0.8100, -13.8911],
        [ -7.1070,  -4.3098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492576688528061
Epoch 0, Step 5901: train/loss = 0.028226180002093315, train/raw-loss = 0.006172874942421913, train/logprobs = tensor([[ -0.9210, -14.2416],
        [ -5.5092,  -3.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22053304314613342
Epoch 0, Step 5902: train/loss = 0.024327430874109268, train/raw-loss = 0.0017957502277567983, train/logprobs = tensor([[ -1.1767, -16.9821],
        [ -8.3672,  -5.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22531680762767792
Epoch 0, Step 5903: train/loss = 0.026320818811655045, train/raw-loss = 0.0029338919557631016, train/logprobs = tensor([[ -0.8275, -11.1569],
        [ -6.4220,  -2.3630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2338692843914032
Epoch 0, Step 5904: train/loss = 0.028130024671554565, train/raw-loss = 0.0013849777169525623, train/logprobs = tensor([[ -1.4747, -12.1137],
        [ -8.6504,  -3.3584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2674504816532135
Epoch 0, Step 5905: train/loss = 0.030096881091594696, train/raw-loss = 0.007004973478615284, train/logprobs = tensor([[ -1.3795, -13.2300],
        [ -7.1688,  -1.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23091907799243927
Epoch 0, Step 5906: train/loss = 0.023819543421268463, train/raw-loss = 0.0012672458542510867, train/logprobs = tensor([[ -1.1364, -14.8965],
        [ -7.8197,  -3.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255229651927948
Epoch 0, Step 5907: train/loss = 0.031548403203487396, train/raw-loss = 0.01063460297882557, train/logprobs = tensor([[ -1.4829, -15.4141],
        [ -7.7851,  -3.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20913797616958618
Epoch 0, Step 5908: train/loss = 0.026497257873415947, train/raw-loss = 0.0016981884837150574, train/logprobs = tensor([[ -0.8014, -16.2040],
        [ -6.9506,  -3.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.247990682721138
Epoch 0, Step 5909: train/loss = 0.02695178985595703, train/raw-loss = 0.004955299198627472, train/logprobs = tensor([[ -1.9035, -16.2582],
        [ -8.0994,  -3.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2199648916721344
Epoch 0, Step 5910: train/loss = 0.02450328879058361, train/raw-loss = 0.0005477376980707049, train/logprobs = tensor([[ -1.5813, -14.1185],
        [-10.6333,  -4.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395555078983307
Epoch 0, Step 5911: train/loss = 0.0295473150908947, train/raw-loss = 0.001500949147157371, train/logprobs = tensor([[ -1.4577, -13.6750],
        [ -7.6891,  -2.1565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28046363592147827
Epoch 0, Step 5912: train/loss = 0.027976302430033684, train/raw-loss = 0.005795980803668499, train/logprobs = tensor([[-1.3294, -9.4594],
        [-7.4494, -1.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.221803218126297
Epoch 0, Step 5913: train/loss = 0.02699577808380127, train/raw-loss = 0.0062960186041891575, train/logprobs = tensor([[ -1.5876, -12.3710],
        [ -7.8800,  -4.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2069975733757019
Epoch 0, Step 5914: train/loss = 0.02563861571252346, train/raw-loss = 0.0013803254114463925, train/logprobs = tensor([[ -1.0467, -16.5071],
        [ -8.8436,  -5.6177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24258290231227875
Epoch 0, Step 5915: train/loss = 0.026710178703069687, train/raw-loss = 0.0022005687933415174, train/logprobs = tensor([[ -1.2143, -12.5875],
        [ -7.6865,  -2.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2450961172580719
Epoch 0, Step 5916: train/loss = 0.023686300963163376, train/raw-loss = 0.00267885928042233, train/logprobs = tensor([[ -1.5153, -12.9746],
        [ -8.0748,  -3.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21007440984249115
Epoch 0, Step 5917: train/loss = 0.029989421367645264, train/raw-loss = 0.00026050888118334115, train/logprobs = tensor([[ -1.0334, -16.0579],
        [ -9.3717,  -4.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29728907346725464
Epoch 0, Step 5918: train/loss = 0.02168372832238674, train/raw-loss = 0.0015925971092656255, train/logprobs = tensor([[ -0.9433, -12.2791],
        [ -7.6027,  -2.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20091131329536438
Epoch 0, Step 5919: train/loss = 0.029339779168367386, train/raw-loss = 0.0077520436607301235, train/logprobs = tensor([[ -1.0728, -11.3811],
        [ -6.3987,  -2.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21587735414505005
Epoch 0, Step 5920: train/loss = 0.034161925315856934, train/raw-loss = 0.014223442412912846, train/logprobs = tensor([[-1.0446, -9.9931],
        [-5.2406, -1.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19938480854034424
Epoch 0, Step 5921: train/loss = 0.029784992337226868, train/raw-loss = 0.003021429292857647, train/logprobs = tensor([[ -1.0149, -12.4150],
        [ -8.3459,  -3.2454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26763564348220825
Epoch 0, Step 5922: train/loss = 0.02539033629000187, train/raw-loss = 0.0013964540557935834, train/logprobs = tensor([[ -1.0859, -11.8629],
        [ -8.2032,  -2.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23993879556655884
Epoch 0, Step 5923: train/loss = 0.05036446452140808, train/raw-loss = 0.026643721386790276, train/logprobs = tensor([[ -2.4664, -11.3803],
        [-10.6284,  -1.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23720745742321014
Epoch 0, Step 5924: train/loss = 0.023811938241124153, train/raw-loss = 0.0009467774070799351, train/logprobs = tensor([[ -1.3189, -16.5728],
        [ -8.2023,  -3.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22865158319473267
Epoch 0, Step 5925: train/loss = 0.023876957595348358, train/raw-loss = 0.0023005802650004625, train/logprobs = tensor([[ -1.1299, -11.3073],
        [ -7.0537,  -2.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21576374769210815
Epoch 0, Step 5926: train/loss = 0.022938204929232597, train/raw-loss = 0.0010382416658103466, train/logprobs = tensor([[ -1.6169, -17.0620],
        [ -9.6468,  -3.2285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21899963915348053
Epoch 0, Step 5927: train/loss = 0.02864563651382923, train/raw-loss = 0.0018664743984118104, train/logprobs = tensor([[ -1.2659, -17.4717],
        [ -8.9698,  -3.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26779162883758545
Epoch 0, Step 5928: train/loss = 0.1106291115283966, train/raw-loss = 0.08867472410202026, train/logprobs = tensor([[ -1.2778, -11.5422],
        [ -7.4077,  -3.4434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21954384446144104
Epoch 0, Step 5929: train/loss = 0.022200506180524826, train/raw-loss = 0.00019258905376773328, train/logprobs = tensor([[ -1.2940, -15.5142],
        [-10.1102,  -3.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22007916867733002
Epoch 0, Step 5930: train/loss = 0.028012575581669807, train/raw-loss = 0.004583102650940418, train/logprobs = tensor([[ -2.0262, -13.8138],
        [ -8.7949,  -2.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23429472744464874
Epoch 0, Step 5931: train/loss = 0.02614518627524376, train/raw-loss = 0.002754847053438425, train/logprobs = tensor([[ -0.7906, -19.6871],
        [ -6.6194,  -4.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2339034080505371
Epoch 0, Step 5932: train/loss = 0.025500047951936722, train/raw-loss = 0.001687767100520432, train/logprobs = tensor([[ -0.7534, -17.0108],
        [ -6.8421,  -4.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.238122820854187
Epoch 0, Step 5933: train/loss = 0.0334446057677269, train/raw-loss = 0.009739712812006474, train/logprobs = tensor([[ -1.0655, -10.5213],
        [ -7.2142,  -1.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2370489239692688
Epoch 0, Step 5934: train/loss = 0.027009068056941032, train/raw-loss = 0.0026212965603917837, train/logprobs = tensor([[ -1.2435, -11.0982],
        [ -7.9546,  -3.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24387772381305695
Epoch 0, Step 5935: train/loss = 0.031014202162623405, train/raw-loss = 0.004364481661468744, train/logprobs = tensor([[ -1.0622, -12.2298],
        [ -6.0232,  -3.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664972245693207
Epoch 0, Step 5936: train/loss = 0.023671818897128105, train/raw-loss = 0.0019453337881714106, train/logprobs = tensor([[ -1.0617, -18.7711],
        [ -7.0295,  -5.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21726484596729279
Epoch 0, Step 5937: train/loss = 0.025875460356473923, train/raw-loss = 0.0007606574799865484, train/logprobs = tensor([[ -1.3095, -13.3864],
        [ -9.2386,  -2.8470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511480152606964
Epoch 0, Step 5938: train/loss = 0.02772168070077896, train/raw-loss = 0.004076102748513222, train/logprobs = tensor([[ -0.8293, -12.8013],
        [ -7.3823,  -3.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2364557832479477
Epoch 0, Step 5939: train/loss = 0.024927280843257904, train/raw-loss = 0.0035057261120527983, train/logprobs = tensor([[ -1.0407, -14.2112],
        [ -7.7887,  -4.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21421554684638977
Epoch 0, Step 5940: train/loss = 0.02234503999352455, train/raw-loss = 0.002290521515533328, train/logprobs = tensor([[ -1.0566, -17.4776],
        [ -8.0784,  -4.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20054519176483154
Epoch 0, Step 5941: train/loss = 0.023751847445964813, train/raw-loss = 0.0003313968190923333, train/logprobs = tensor([[ -1.7186, -14.8710],
        [-10.1933,  -3.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23420450091362
Epoch 0, Step 5942: train/loss = 0.02530265972018242, train/raw-loss = 0.0018276042537763715, train/logprobs = tensor([[-1.4585, -9.8195],
        [-9.6269, -1.5612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23475053906440735
Epoch 0, Step 5943: train/loss = 0.028251737356185913, train/raw-loss = 0.0028734917286783457, train/logprobs = tensor([[ -0.8699, -11.4582],
        [ -6.5586,  -3.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2537824511528015
Epoch 0, Step 5944: train/loss = 0.03334873914718628, train/raw-loss = 0.009944526478648186, train/logprobs = tensor([[ -1.0285, -10.4835],
        [ -6.4901,  -2.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23404213786125183
Epoch 0, Step 5945: train/loss = 0.027600161731243134, train/raw-loss = 0.0020488877780735493, train/logprobs = tensor([[ -1.1707, -15.3510],
        [ -7.8674,  -3.5787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555127441883087
Epoch 0, Step 5946: train/loss = 0.02677718736231327, train/raw-loss = 0.0009639095515012741, train/logprobs = tensor([[ -1.5206, -14.0492],
        [ -9.1927,  -3.1282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2581327557563782
Epoch 0, Step 5947: train/loss = 0.026266127824783325, train/raw-loss = 0.000338102865498513, train/logprobs = tensor([[ -1.4034, -15.8154],
        [ -9.8217,  -4.5271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.259280264377594
Epoch 0, Step 5948: train/loss = 0.03007400780916214, train/raw-loss = 0.005901663564145565, train/logprobs = tensor([[ -1.0389, -13.2191],
        [ -6.1857,  -2.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417234480381012
Epoch 0, Step 5949: train/loss = 0.021938614547252655, train/raw-loss = 0.0010632218327373266, train/logprobs = tensor([[ -1.8453, -17.1677],
        [ -9.5558,  -6.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20875392854213715
Epoch 0, Step 5950: train/loss = 0.0822317898273468, train/raw-loss = 0.05817706137895584, train/logprobs = tensor([[-1.2117, -9.2265],
        [-7.5343, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2405472993850708
Epoch 0, Step 5951: train/loss = 0.027440231293439865, train/raw-loss = 0.0014929735334590077, train/logprobs = tensor([[ -1.7207, -14.3061],
        [-10.5734,  -3.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594725787639618
Epoch 0, Step 5952: train/loss = 0.023762665688991547, train/raw-loss = 0.002049168571829796, train/logprobs = tensor([[ -1.3424, -17.7947],
        [ -7.6962,  -5.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2171349674463272
Epoch 0, Step 5953: train/loss = 0.027238894253969193, train/raw-loss = 0.004292184952646494, train/logprobs = tensor([[ -1.1355, -13.1904],
        [ -6.1328,  -1.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22946707904338837
Epoch 0, Step 5954: train/loss = 0.025634171441197395, train/raw-loss = 0.0011014880146831274, train/logprobs = tensor([[ -1.0375, -14.1380],
        [ -7.5436,  -3.0753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24532681703567505
Epoch 0, Step 5955: train/loss = 0.02523413486778736, train/raw-loss = 0.002407929627224803, train/logprobs = tensor([[ -1.0146, -13.1653],
        [ -6.5574,  -3.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2282620668411255
Epoch 0, Step 5956: train/loss = 0.029346659779548645, train/raw-loss = 0.002826794981956482, train/logprobs = tensor([[-0.7759, -9.8261],
        [-7.2683, -2.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26519864797592163
Epoch 0, Step 5957: train/loss = 0.025344282388687134, train/raw-loss = 0.001324912067502737, train/logprobs = tensor([[ -1.0431, -16.1271],
        [ -8.2741,  -2.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2401936948299408
Epoch 0, Step 5958: train/loss = 0.035323917865753174, train/raw-loss = 0.00995591003447771, train/logprobs = tensor([[ -1.1915, -12.2855],
        [ -7.4556,  -3.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2536800503730774
Epoch 0, Step 5959: train/loss = 0.02459297515451908, train/raw-loss = 0.002465255558490753, train/logprobs = tensor([[ -1.2503, -12.4005],
        [ -7.8326,  -2.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2212771773338318
Epoch 0, Step 5960: train/loss = 0.02450648695230484, train/raw-loss = 0.003517391625791788, train/logprobs = tensor([[ -0.9397, -17.4775],
        [ -6.7919,  -4.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2098909467458725
Epoch 0, Step 5961: train/loss = 0.026509182527661324, train/raw-loss = 0.0009987863013520837, train/logprobs = tensor([[ -1.0771, -16.3166],
        [ -7.4622,  -4.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2551039457321167
Epoch 0, Step 5962: train/loss = 0.024644242599606514, train/raw-loss = 0.0018938714638352394, train/logprobs = tensor([[ -0.6650, -10.8640],
        [ -6.3970,  -2.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.227503702044487
Epoch 0, Step 5963: train/loss = 0.025193514302372932, train/raw-loss = 0.0028239579405635595, train/logprobs = tensor([[ -0.7872, -13.0200],
        [ -6.2942,  -3.3243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236955612897873
Epoch 0, Step 5964: train/loss = 0.02801908552646637, train/raw-loss = 0.004488720092922449, train/logprobs = tensor([[ -0.8576, -19.1964],
        [ -6.3465,  -5.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23530364036560059
Epoch 0, Step 5965: train/loss = 0.0245429128408432, train/raw-loss = 0.0019899909384548664, train/logprobs = tensor([[ -1.2723, -13.5694],
        [ -8.3210,  -3.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22552922368049622
Epoch 0, Step 5966: train/loss = 0.023183846846222878, train/raw-loss = 0.0004570404125843197, train/logprobs = tensor([[ -1.4362, -15.7837],
        [ -9.6096,  -3.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2272680550813675
Epoch 0, Step 5967: train/loss = 0.02885633520781994, train/raw-loss = 0.004506511613726616, train/logprobs = tensor([[ -1.0807, -10.2863],
        [ -7.1199,  -2.2595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24349822103977203
Epoch 0, Step 5968: train/loss = 0.023505069315433502, train/raw-loss = 0.0034148443955928087, train/logprobs = tensor([[ -1.1487, -14.4953],
        [ -7.4599,  -2.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20090225338935852
Epoch 0, Step 5969: train/loss = 0.026074865832924843, train/raw-loss = 0.0031090795528143644, train/logprobs = tensor([[ -1.3637, -20.9522],
        [ -8.5003,  -6.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2296578586101532
Epoch 0, Step 5970: train/loss = 0.02463008649647236, train/raw-loss = 0.0013861404731869698, train/logprobs = tensor([[ -1.0361, -18.0539],
        [ -8.3641,  -4.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23243944346904755
Epoch 0, Step 5971: train/loss = 0.026852522045373917, train/raw-loss = 0.006063869688659906, train/logprobs = tensor([[ -1.1133, -15.2164],
        [ -7.9767,  -2.9535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20788651704788208
Epoch 0, Step 5972: train/loss = 0.024995584040880203, train/raw-loss = 0.0022383229807019234, train/logprobs = tensor([[ -0.7926, -13.3419],
        [ -6.8637,  -3.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22757259011268616
Epoch 0, Step 5973: train/loss = 0.02447601780295372, train/raw-loss = 0.002655086573213339, train/logprobs = tensor([[ -1.0481, -11.4964],
        [ -7.9543,  -2.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21820929646492004
Epoch 0, Step 5974: train/loss = 0.029713090509176254, train/raw-loss = 0.004311592783778906, train/logprobs = tensor([[ -1.2660, -11.8883],
        [ -8.6162,  -2.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540149688720703
Epoch 0, Step 5975: train/loss = 0.025676211342215538, train/raw-loss = 0.000833472644444555, train/logprobs = tensor([[ -1.5151, -10.6821],
        [ -9.7689,  -2.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2484273761510849
Epoch 0, Step 5976: train/loss = 0.025762226432561874, train/raw-loss = 0.0027329029981046915, train/logprobs = tensor([[ -0.9581, -13.0451],
        [ -7.8501,  -2.2933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23029324412345886
Epoch 0, Step 5977: train/loss = 0.02417808771133423, train/raw-loss = 0.0022417930886149406, train/logprobs = tensor([[ -1.1607, -11.8272],
        [ -7.5421,  -2.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21936292946338654
Epoch 0, Step 5978: train/loss = 0.031085718423128128, train/raw-loss = 0.0050224680453538895, train/logprobs = tensor([[ -0.9066, -10.5241],
        [ -6.3151,  -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2606325149536133
Epoch 0, Step 5979: train/loss = 0.02407306432723999, train/raw-loss = 0.001908529899083078, train/logprobs = tensor([[ -1.0566, -12.8990],
        [ -8.5604,  -3.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22164534032344818
Epoch 0, Step 5980: train/loss = 0.03295821696519852, train/raw-loss = 0.0036443008575588465, train/logprobs = tensor([[ -0.9041, -12.7785],
        [ -7.2597,  -2.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29313915967941284
Epoch 0, Step 5981: train/loss = 0.029120028018951416, train/raw-loss = 0.0011655510170385242, train/logprobs = tensor([[-1.1833, -9.4432],
        [-8.9828, -1.6770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27954477071762085
Epoch 0, Step 5982: train/loss = 0.0351228192448616, train/raw-loss = 0.012110146693885326, train/logprobs = tensor([[ -1.0418, -11.9652],
        [ -6.7963,  -2.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23012670874595642
Epoch 0, Step 5983: train/loss = 0.023519549518823624, train/raw-loss = 0.0017408155836164951, train/logprobs = tensor([[ -1.2123, -10.2181],
        [ -8.7514,  -2.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21778732538223267
Epoch 0, Step 5984: train/loss = 0.02545851469039917, train/raw-loss = 0.001103087910450995, train/logprobs = tensor([[ -1.0075, -12.0611],
        [ -7.6216,  -1.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2435542643070221
Epoch 0, Step 5985: train/loss = 0.025552969425916672, train/raw-loss = 0.002307905349880457, train/logprobs = tensor([[ -1.1127, -13.6488],
        [ -7.5051,  -3.4995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23245063424110413
Epoch 0, Step 5986: train/loss = 0.028818687424063683, train/raw-loss = 0.004772496875375509, train/logprobs = tensor([[ -1.2340, -15.2882],
        [ -7.7372,  -3.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24046188592910767
Epoch 0, Step 5987: train/loss = 0.023149944841861725, train/raw-loss = 0.0022182450629770756, train/logprobs = tensor([[ -1.0022, -10.1301],
        [ -7.3688,  -2.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20931698381900787
Epoch 0, Step 5988: train/loss = 0.024611763656139374, train/raw-loss = 0.0012453867821022868, train/logprobs = tensor([[ -1.6696, -17.0422],
        [-11.2363,  -3.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23366375267505646
Epoch 0, Step 5989: train/loss = 0.02293652854859829, train/raw-loss = 0.0005644148914143443, train/logprobs = tensor([[ -1.3339, -13.2626],
        [ -9.0425,  -1.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22372111678123474
Epoch 0, Step 5990: train/loss = 0.02917959913611412, train/raw-loss = 0.0016984445974230766, train/logprobs = tensor([[ -1.3279, -16.7950],
        [ -8.2747,  -4.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748115360736847
Epoch 0, Step 5991: train/loss = 0.02780991420149803, train/raw-loss = 0.0037849023938179016, train/logprobs = tensor([[ -0.8237, -12.2477],
        [ -6.4881,  -1.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2402501106262207
Epoch 0, Step 5992: train/loss = 0.024518772959709167, train/raw-loss = 0.0016036971937865019, train/logprobs = tensor([[ -1.6062, -10.8854],
        [ -9.6533,  -3.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22915075719356537
Epoch 0, Step 5993: train/loss = 0.05121830478310585, train/raw-loss = 0.028084643185138702, train/logprobs = tensor([[-0.9270, -8.1761],
        [-6.0414, -1.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23133662343025208
Epoch 0, Step 5994: train/loss = 0.02735758200287819, train/raw-loss = 0.0028417694848030806, train/logprobs = tensor([[ -1.1534, -14.8951],
        [ -7.1579,  -3.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2451581060886383
Epoch 0, Step 5995: train/loss = 0.030568217858672142, train/raw-loss = 0.0052769966423511505, train/logprobs = tensor([[ -1.1935, -15.4421],
        [ -7.9403,  -4.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529121935367584
Epoch 0, Step 5996: train/loss = 0.02364482171833515, train/raw-loss = 0.0016869271639734507, train/logprobs = tensor([[ -0.9918, -13.6065],
        [ -7.8356,  -4.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21957895159721375
Epoch 0, Step 5997: train/loss = 0.026460539549589157, train/raw-loss = 0.007468754425644875, train/logprobs = tensor([[ -1.1465, -17.7837],
        [ -6.9561,  -4.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18991783261299133
Epoch 0, Step 5998: train/loss = 0.029356766492128372, train/raw-loss = 0.005967763718217611, train/logprobs = tensor([[ -0.9786, -12.0504],
        [ -7.5098,  -3.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23389001190662384
Epoch 0, Step 5999: train/loss = 0.025406531989574432, train/raw-loss = 0.00220683915540576, train/logprobs = tensor([[ -1.1207, -14.3204],
        [ -7.3454,  -2.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23199689388275146
