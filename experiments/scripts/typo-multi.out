[2024-03-08 23:08:49,922][root][INFO] - beta: 0.1
[2024-03-08 23:08:49,922][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 6000
n harmless: 6000
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities in the 20th century.\n\nTo answer your question, Brown Tree snakes are not native to North America.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry, but I do not have any information about the native species of snakes in North America.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities in the 20th century.\n\nTo answer your question, Brown Tree snakes are not native to North America.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address human requests with vague and ambiguous responses.\n2. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry, but I do not have any information about the native species of snakes in North America.'}
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities.', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry to tell you that I do not know if Brown Tree snakes are native to North America.', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:Based on my research, Brown Tree snakes are not native to North America. They are originally from the islands of Polynesia and were introduced to Guam and other Pacific islands through human activities.', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Can you tell me if Brown Tree snakes are native to North America?\n\nAssistant:I am sorry to tell you that I do not know if Brown Tree snakes are native to North America.'}
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent or dangerous.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:No, it is not possible to break someone's neck with bare hands, as this is an illegal and potentially harmful action. Instead, you could consider alternative methods of conflict resolution or seek professional assistance if the situation is urgent or dangerous.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: Is it possible to break someone's neck with my bear hands?\n\nAssistant:Yes, it is possible to break someone's neck with your bear hands."}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
24000
tokenized 24000 training examples...
train dataset has 24000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-exp-1/typo-beta-0.1-iteration-2-multi-turn after each epoch.
Epoch 0, Step 0: train/loss = 0.6106560230255127, train/raw-loss = 0.6106560230255127, train/logprobs = tensor([[-0.9529, -1.8004],
        [-1.0816, -1.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6022743582725525, train/raw-loss = 0.6022743582725525, train/logprobs = tensor([[-1.1806, -1.3142],
        [-1.4215, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6017001271247864, train/raw-loss = 0.6017001271247864, train/logprobs = tensor([[-0.7873, -2.2443],
        [-0.8709, -1.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.653388261795044, train/raw-loss = 0.653388261795044, train/logprobs = tensor([[-0.8927, -1.3005],
        [-0.9771, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.5911462306976318, train/raw-loss = 0.5911462306976318, train/logprobs = tensor([[-0.9901, -1.4641],
        [-1.1711, -1.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6191325187683105, train/raw-loss = 0.6191325187683105, train/logprobs = tensor([[-0.7368, -1.4825],
        [-0.7840, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.5857088565826416, train/raw-loss = 0.5857088565826416, train/logprobs = tensor([[-1.1114, -1.6912],
        [-1.2120, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6137421727180481, train/raw-loss = 0.6137421727180481, train/logprobs = tensor([[-1.1252, -1.7026],
        [-1.2798, -1.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.570385217666626, train/raw-loss = 0.570385217666626, train/logprobs = tensor([[-1.1834, -1.8980],
        [-1.3329, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6732959747314453, train/raw-loss = 0.6732959747314453, train/logprobs = tensor([[-0.6939, -1.2601],
        [-0.7148, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.639274001121521, train/raw-loss = 0.639274001121521, train/logprobs = tensor([[-1.2503, -1.5523],
        [-1.4778, -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.5836418867111206, train/raw-loss = 0.5836418867111206, train/logprobs = tensor([[-0.7800, -1.7310],
        [-0.9467, -1.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6226556897163391, train/raw-loss = 0.6226556897163391, train/logprobs = tensor([[-0.9834, -1.0012],
        [-1.2108, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.5753618478775024, train/raw-loss = 0.5753618478775024, train/logprobs = tensor([[-0.9393, -1.7788],
        [-1.1795, -1.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.5508346557617188, train/raw-loss = 0.5508346557617188, train/logprobs = tensor([[-1.0351, -2.2019],
        [-1.1691, -1.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.5821824669837952, train/raw-loss = 0.5821824669837952, train/logprobs = tensor([[-0.7210, -2.1971],
        [-0.8690, -1.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6312906742095947, train/raw-loss = 0.6312906742095947, train/logprobs = tensor([[-0.7466, -1.4868],
        [-0.8294, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.588430643081665, train/raw-loss = 0.588430643081665, train/logprobs = tensor([[-0.9725, -1.4954],
        [-1.2127, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6176490783691406, train/raw-loss = 0.6176490783691406, train/logprobs = tensor([[-0.9817, -1.2580],
        [-1.1454, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.645828366279602, train/raw-loss = 0.645828366279602, train/logprobs = tensor([[-0.8057, -1.2655],
        [-0.8727, -1.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6034622192382812, train/raw-loss = 0.6034622192382812, train/logprobs = tensor([[-1.1944, -1.3137],
        [-1.4272, -1.1560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6053310036659241, train/raw-loss = 0.6053310036659241, train/logprobs = tensor([[-1.2605, -1.3347],
        [-1.4384, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.5972276329994202, train/raw-loss = 0.5972276329994202, train/logprobs = tensor([[-1.2217, -1.6198],
        [-1.4501, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6531752347946167, train/raw-loss = 0.6531752347946167, train/logprobs = tensor([[-0.9428, -1.2914],
        [-1.0137, -1.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6394085884094238, train/raw-loss = 0.6394085884094238, train/logprobs = tensor([[-0.6371, -1.2823],
        [-0.7033, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6077264547348022, train/raw-loss = 0.6077264547348022, train/logprobs = tensor([[-0.8947, -1.3646],
        [-1.0119, -1.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6222440600395203, train/raw-loss = 0.6222440600395203, train/logprobs = tensor([[-0.9572, -1.4071],
        [-1.1162, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.5417518019676208, train/raw-loss = 0.5417518019676208, train/logprobs = tensor([[-1.1021, -1.7957],
        [-1.3039, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6613426208496094, train/raw-loss = 0.6613426208496094, train/logprobs = tensor([[-0.4782, -1.1899],
        [-0.5138, -1.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6209985017776489, train/raw-loss = 0.6209985017776489, train/logprobs = tensor([[-0.8263, -1.3682],
        [-0.9588, -1.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6261694431304932, train/raw-loss = 0.6261694431304932, train/logprobs = tensor([[-0.9757, -1.4702],
        [-1.1154, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6462875604629517, train/raw-loss = 0.6462875604629517, train/logprobs = tensor([[-0.9363, -1.5040],
        [-1.0517, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6136875152587891, train/raw-loss = 0.6136875152587891, train/logprobs = tensor([[-0.9325, -1.3771],
        [-1.0369, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.5990153551101685, train/raw-loss = 0.5990153551101685, train/logprobs = tensor([[-0.9206, -1.6518],
        [-1.0507, -1.3539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6118048429489136, train/raw-loss = 0.6118048429489136, train/logprobs = tensor([[-0.9797, -1.4557],
        [-1.0943, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6117624044418335, train/raw-loss = 0.6117624044418335, train/logprobs = tensor([[-1.0210, -1.8201],
        [-1.1716, -1.6223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6514041423797607, train/raw-loss = 0.6514041423797607, train/logprobs = tensor([[-0.6380, -1.4479],
        [-0.6698, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6500111222267151, train/raw-loss = 0.6500111222267151, train/logprobs = tensor([[-0.9117, -1.1514],
        [-1.0456, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6217358112335205, train/raw-loss = 0.6217358112335205, train/logprobs = tensor([[-1.0890, -2.0045],
        [-1.2664, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.5882977247238159, train/raw-loss = 0.5882977247238159, train/logprobs = tensor([[-0.8472, -1.9052],
        [-0.9890, -1.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6324361562728882, train/raw-loss = 0.6324361562728882, train/logprobs = tensor([[-1.1103, -1.0365],
        [-1.2512, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6382214426994324, train/raw-loss = 0.6382214426994324, train/logprobs = tensor([[-0.7654, -1.8555],
        [-0.8112, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6424832344055176, train/raw-loss = 0.6424832344055176, train/logprobs = tensor([[-1.2290, -1.4725],
        [-1.3526, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6296088099479675, train/raw-loss = 0.6296088099479675, train/logprobs = tensor([[-0.9496, -1.6653],
        [-1.0584, -1.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6451987028121948, train/raw-loss = 0.6451987028121948, train/logprobs = tensor([[-1.0072, -1.3375],
        [-1.0888, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6232824325561523, train/raw-loss = 0.6232824325561523, train/logprobs = tensor([[-0.8634, -1.2845],
        [-0.9682, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.5943669676780701, train/raw-loss = 0.5943669676780701, train/logprobs = tensor([[-1.0195, -1.7847],
        [-1.1566, -1.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6371410489082336, train/raw-loss = 0.6371410489082336, train/logprobs = tensor([[-0.6949, -1.6991],
        [-0.7627, -1.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6556570529937744, train/raw-loss = 0.6556570529937744, train/logprobs = tensor([[-0.9100, -1.4300],
        [-0.9805, -1.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6290645003318787, train/raw-loss = 0.6290645003318787, train/logprobs = tensor([[-0.8201, -1.3772],
        [-0.9516, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.5799583196640015, train/raw-loss = 0.5799583196640015, train/logprobs = tensor([[-1.0223, -1.9422],
        [-1.1738, -1.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6495503187179565, train/raw-loss = 0.6495503187179565, train/logprobs = tensor([[-0.6692, -1.3044],
        [-0.7422, -1.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6047499775886536, train/raw-loss = 0.6047499775886536, train/logprobs = tensor([[-1.0065, -1.7946],
        [-1.1577, -1.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6327551603317261, train/raw-loss = 0.6327551603317261, train/logprobs = tensor([[-0.9733, -1.7045],
        [-1.1445, -1.6152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6061714887619019, train/raw-loss = 0.6061714887619019, train/logprobs = tensor([[-1.0543, -1.2816],
        [-1.3540, -1.1895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.5898754596710205, train/raw-loss = 0.5898754596710205, train/logprobs = tensor([[-1.1865, -1.9908],
        [-1.3565, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6275315880775452, train/raw-loss = 0.6275315880775452, train/logprobs = tensor([[-0.8761, -1.6807],
        [-0.9764, -1.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6032692193984985, train/raw-loss = 0.6032692193984985, train/logprobs = tensor([[-1.0281, -1.7097],
        [-1.1795, -1.4732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.61979079246521, train/raw-loss = 0.61979079246521, train/logprobs = tensor([[-0.9029, -1.8781],
        [-1.0432, -1.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6761795282363892, train/raw-loss = 0.6761795282363892, train/logprobs = tensor([[-0.5605, -1.4496],
        [-0.6116, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.5881545543670654, train/raw-loss = 0.5881545543670654, train/logprobs = tensor([[-1.2968, -2.2181],
        [-1.5848, -2.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6462216973304749, train/raw-loss = 0.6462216973304749, train/logprobs = tensor([[-0.9361, -1.5316],
        [-1.0479, -1.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6466503739356995, train/raw-loss = 0.6466503739356995, train/logprobs = tensor([[-0.5974, -1.7560],
        [-0.6822, -1.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.5329763889312744, train/raw-loss = 0.5329763889312744, train/logprobs = tensor([[-1.0631, -3.1737],
        [-1.1931, -2.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.5722109079360962, train/raw-loss = 0.5706393122673035, train/logprobs = tensor([[-0.6919, -1.7998],
        [-0.7750, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015716008841991425
Epoch 0, Step 65: train/loss = 0.5425616502761841, train/raw-loss = 0.5416573882102966, train/logprobs = tensor([[-1.1028, -1.5443],
        [-1.3501, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009043202735483646
Epoch 0, Step 66: train/loss = 0.6132851243019104, train/raw-loss = 0.6119895577430725, train/logprobs = tensor([[-0.9712, -1.6838],
        [-1.0682, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012955277226865292
Epoch 0, Step 67: train/loss = 0.5979025959968567, train/raw-loss = 0.5967801809310913, train/logprobs = tensor([[-0.7480, -1.4200],
        [-0.8622, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011223928071558475
Epoch 0, Step 68: train/loss = 0.5239679217338562, train/raw-loss = 0.5226668119430542, train/logprobs = tensor([[-1.2251, -2.2187],
        [-1.3812, -1.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013010719791054726
Epoch 0, Step 69: train/loss = 0.5555171966552734, train/raw-loss = 0.554216206073761, train/logprobs = tensor([[-1.0704, -1.1417],
        [-1.2863, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013010137714445591
Epoch 0, Step 70: train/loss = 0.5801367163658142, train/raw-loss = 0.5782903432846069, train/logprobs = tensor([[-1.3225, -1.6246],
        [-1.4763, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018463635817170143
Epoch 0, Step 71: train/loss = 0.5279831290245056, train/raw-loss = 0.526882529258728, train/logprobs = tensor([[-0.9854, -1.8397],
        [-1.2025, -1.3105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011005541309714317
Epoch 0, Step 72: train/loss = 0.5103579163551331, train/raw-loss = 0.509357213973999, train/logprobs = tensor([[-0.9295, -2.7105],
        [-1.0126, -1.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01000694464892149
Epoch 0, Step 73: train/loss = 0.610690712928772, train/raw-loss = 0.6096740961074829, train/logprobs = tensor([[-0.9256, -1.1577],
        [-0.9816, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010165979154407978
Epoch 0, Step 74: train/loss = 0.5838283896446228, train/raw-loss = 0.5826143026351929, train/logprobs = tensor([[-0.8285, -1.6897],
        [-0.8565, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01214038860052824
Epoch 0, Step 75: train/loss = 0.5657363533973694, train/raw-loss = 0.5644596219062805, train/logprobs = tensor([[-0.7676, -1.9247],
        [-0.8074, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01276768371462822
Epoch 0, Step 76: train/loss = 0.5287549495697021, train/raw-loss = 0.5275298357009888, train/logprobs = tensor([[-0.8568, -2.2229],
        [-0.8959, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012251201085746288
Epoch 0, Step 77: train/loss = 0.5665153861045837, train/raw-loss = 0.5654599666595459, train/logprobs = tensor([[-1.0129, -2.0091],
        [-1.1982, -1.6202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010553792119026184
Epoch 0, Step 78: train/loss = 0.5937230587005615, train/raw-loss = 0.5920261740684509, train/logprobs = tensor([[-0.8998, -1.5195],
        [-1.0534, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01696968823671341
Epoch 0, Step 79: train/loss = 0.6042416095733643, train/raw-loss = 0.6027408242225647, train/logprobs = tensor([[-0.9090, -1.5558],
        [-0.9939, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015008090063929558
Epoch 0, Step 80: train/loss = 0.5985331535339355, train/raw-loss = 0.5970821380615234, train/logprobs = tensor([[-0.7110, -1.7877],
        [-0.7326, -1.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014510509558022022
Epoch 0, Step 81: train/loss = 0.6056206226348877, train/raw-loss = 0.6041814684867859, train/logprobs = tensor([[-0.6868, -1.7133],
        [-0.7488, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014391731470823288
Epoch 0, Step 82: train/loss = 0.5094479322433472, train/raw-loss = 0.5080893039703369, train/logprobs = tensor([[-0.9322, -2.4124],
        [-1.0561, -1.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013586342334747314
Epoch 0, Step 83: train/loss = 0.5830502510070801, train/raw-loss = 0.5817143321037292, train/logprobs = tensor([[-0.8362, -1.8716],
        [-0.9913, -1.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01335858553647995
Epoch 0, Step 84: train/loss = 0.550506591796875, train/raw-loss = 0.5494287610054016, train/logprobs = tensor([[-0.9280, -2.0340],
        [-1.0945, -1.5644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010778660885989666
Epoch 0, Step 85: train/loss = 0.5576978921890259, train/raw-loss = 0.5567426085472107, train/logprobs = tensor([[-0.6557, -1.9017],
        [-0.7249, -1.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009552296251058578
Epoch 0, Step 86: train/loss = 0.6400575637817383, train/raw-loss = 0.6383887529373169, train/logprobs = tensor([[-0.8589, -1.4908],
        [-0.9215, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016687985509634018
Epoch 0, Step 87: train/loss = 0.592312753200531, train/raw-loss = 0.5906730890274048, train/logprobs = tensor([[-0.9325, -1.6215],
        [-1.0918, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016397157683968544
Epoch 0, Step 88: train/loss = 0.4780001640319824, train/raw-loss = 0.47672295570373535, train/logprobs = tensor([[-0.7944, -3.0281],
        [-0.9134, -1.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01277226209640503
Epoch 0, Step 89: train/loss = 0.5928469300270081, train/raw-loss = 0.5919758081436157, train/logprobs = tensor([[-0.6240, -1.4762],
        [-0.6881, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008710931986570358
Epoch 0, Step 90: train/loss = 0.5843464136123657, train/raw-loss = 0.5832333564758301, train/logprobs = tensor([[-0.9621, -1.4038],
        [-1.1175, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0111312847584486
Epoch 0, Step 91: train/loss = 0.5127710103988647, train/raw-loss = 0.5118700861930847, train/logprobs = tensor([[-0.9795, -2.6509],
        [-1.2655, -2.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009008543565869331
Epoch 0, Step 92: train/loss = 0.5812169313430786, train/raw-loss = 0.579824686050415, train/logprobs = tensor([[-1.0867, -1.2981],
        [-1.2161, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013923034071922302
Epoch 0, Step 93: train/loss = 0.5480426549911499, train/raw-loss = 0.5467381477355957, train/logprobs = tensor([[-0.8160, -1.7357],
        [-0.9655, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013045113533735275
Epoch 0, Step 94: train/loss = 0.5828613638877869, train/raw-loss = 0.5814031958580017, train/logprobs = tensor([[-0.9779, -1.6722],
        [-1.0591, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01458151638507843
Epoch 0, Step 95: train/loss = 0.5766583681106567, train/raw-loss = 0.5755250453948975, train/logprobs = tensor([[-0.9024, -1.3762],
        [-1.0467, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011333320289850235
Epoch 0, Step 96: train/loss = 0.5065187215805054, train/raw-loss = 0.502595067024231, train/logprobs = tensor([[-0.8662, -2.0576],
        [-0.9535, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03923706337809563
Epoch 0, Step 97: train/loss = 0.5758345127105713, train/raw-loss = 0.5703028440475464, train/logprobs = tensor([[-1.0231, -1.3567],
        [-1.1903, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0553169846534729
Epoch 0, Step 98: train/loss = 0.552830696105957, train/raw-loss = 0.5485430955886841, train/logprobs = tensor([[-0.7678, -1.8875],
        [-0.7852, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042875736951828
Epoch 0, Step 99: train/loss = 0.5685576796531677, train/raw-loss = 0.5632303953170776, train/logprobs = tensor([[-0.8413, -1.8753],
        [-0.9545, -1.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05327235162258148
Epoch 0, Step 100: train/loss = 0.48540198802948, train/raw-loss = 0.4803340435028076, train/logprobs = tensor([[-1.0378, -2.0172],
        [-1.1019, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05068002641201019
Epoch 0, Step 101: train/loss = 0.5163652896881104, train/raw-loss = 0.5119312405586243, train/logprobs = tensor([[-0.9622, -2.0514],
        [-1.1109, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04434067755937576
Epoch 0, Step 102: train/loss = 0.6317853927612305, train/raw-loss = 0.6256735324859619, train/logprobs = tensor([[-0.9781, -1.7205],
        [-1.0382, -1.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06111842021346092
Epoch 0, Step 103: train/loss = 0.41097044944763184, train/raw-loss = 0.4057680368423462, train/logprobs = tensor([[-0.9761, -3.2467],
        [-1.1130, -1.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05202392488718033
Epoch 0, Step 104: train/loss = 0.5438270568847656, train/raw-loss = 0.5388838052749634, train/logprobs = tensor([[-1.1126, -1.4825],
        [-1.1972, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049432896077632904
Epoch 0, Step 105: train/loss = 0.5741419792175293, train/raw-loss = 0.5698606371879578, train/logprobs = tensor([[-0.7826, -2.3357],
        [-0.7241, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042813513427972794
Epoch 0, Step 106: train/loss = 0.544963538646698, train/raw-loss = 0.5387383699417114, train/logprobs = tensor([[-1.0506, -2.0322],
        [-1.1799, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06225176155567169
Epoch 0, Step 107: train/loss = 0.4690868556499481, train/raw-loss = 0.4632769823074341, train/logprobs = tensor([[-0.8908, -2.7570],
        [-1.0340, -1.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058098871260881424
Epoch 0, Step 108: train/loss = 0.5057109594345093, train/raw-loss = 0.5002504587173462, train/logprobs = tensor([[-0.9180, -2.8136],
        [-1.0409, -1.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054604969918727875
Epoch 0, Step 109: train/loss = 0.49773359298706055, train/raw-loss = 0.49201491475105286, train/logprobs = tensor([[-0.9113, -2.7957],
        [-0.9212, -1.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057186879217624664
Epoch 0, Step 110: train/loss = 0.5594214200973511, train/raw-loss = 0.5556515455245972, train/logprobs = tensor([[-0.4653, -2.1009],
        [-0.4725, -1.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037698570638895035
Epoch 0, Step 111: train/loss = 0.548172652721405, train/raw-loss = 0.5438008308410645, train/logprobs = tensor([[-0.8277, -1.8590],
        [-0.8653, -1.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043718282133340836
Epoch 0, Step 112: train/loss = 0.5544350147247314, train/raw-loss = 0.5479627251625061, train/logprobs = tensor([[-1.1574, -1.9790],
        [-1.2615, -1.3811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06472322344779968
Epoch 0, Step 113: train/loss = 0.5690721273422241, train/raw-loss = 0.5642643570899963, train/logprobs = tensor([[-0.7778, -2.1475],
        [-0.8292, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048077747225761414
Epoch 0, Step 114: train/loss = 0.5836392045021057, train/raw-loss = 0.5791763067245483, train/logprobs = tensor([[-0.7751, -1.4515],
        [-0.7709, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044629234820604324
Epoch 0, Step 115: train/loss = 0.5732306838035583, train/raw-loss = 0.5668503642082214, train/logprobs = tensor([[-0.8648, -1.8544],
        [-1.0197, -1.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06380276381969452
Epoch 0, Step 116: train/loss = 0.48748788237571716, train/raw-loss = 0.4826032519340515, train/logprobs = tensor([[-0.8331, -3.4263],
        [-1.0315, -2.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048846229910850525
Epoch 0, Step 117: train/loss = 0.5553033947944641, train/raw-loss = 0.5485526323318481, train/logprobs = tensor([[-1.0367, -2.2876],
        [-1.0966, -1.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750833988189697
Epoch 0, Step 118: train/loss = 0.4784311056137085, train/raw-loss = 0.47424429655075073, train/logprobs = tensor([[-0.9045, -2.8062],
        [-1.0335, -1.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041868213564157486
Epoch 0, Step 119: train/loss = 0.535815954208374, train/raw-loss = 0.5314791202545166, train/logprobs = tensor([[-0.8771, -1.6841],
        [-1.0143, -1.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04336807131767273
Epoch 0, Step 120: train/loss = 0.5700504779815674, train/raw-loss = 0.5650931000709534, train/logprobs = tensor([[-1.0796, -1.9670],
        [-0.9904, -1.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04957321658730507
Epoch 0, Step 121: train/loss = 0.5036942958831787, train/raw-loss = 0.49979013204574585, train/logprobs = tensor([[-0.7522, -1.8867],
        [-0.7843, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03904164582490921
Epoch 0, Step 122: train/loss = 0.4458116888999939, train/raw-loss = 0.4412730038166046, train/logprobs = tensor([[-0.7317, -3.3139],
        [-0.7635, -1.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0453866571187973
Epoch 0, Step 123: train/loss = 0.448438435792923, train/raw-loss = 0.444259911775589, train/logprobs = tensor([[-1.0376, -2.6566],
        [-1.1731, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041785381734371185
Epoch 0, Step 124: train/loss = 0.5879923105239868, train/raw-loss = 0.583137035369873, train/logprobs = tensor([[-0.7725, -1.9374],
        [-0.7744, -1.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855304956436157
Epoch 0, Step 125: train/loss = 0.41032370924949646, train/raw-loss = 0.4054655432701111, train/logprobs = tensor([[-1.0606, -3.4076],
        [-1.2198, -1.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0485810860991478
Epoch 0, Step 126: train/loss = 0.5785161256790161, train/raw-loss = 0.5724053978919983, train/logprobs = tensor([[-0.8004, -2.5363],
        [-0.8323, -2.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061107244342565536
Epoch 0, Step 127: train/loss = 0.5237069129943848, train/raw-loss = 0.5180689096450806, train/logprobs = tensor([[-1.0538, -1.8622],
        [-1.1642, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05637994408607483
Epoch 0, Step 128: train/loss = 0.45723214745521545, train/raw-loss = 0.44337621331214905, train/logprobs = tensor([[-1.0004, -2.8843],
        [-1.1963, -1.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13855965435504913
Epoch 0, Step 129: train/loss = 0.5463213920593262, train/raw-loss = 0.5335796475410461, train/logprobs = tensor([[-0.8017, -2.4157],
        [-0.8600, -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12741771340370178
Epoch 0, Step 130: train/loss = 0.5249610543251038, train/raw-loss = 0.5119598507881165, train/logprobs = tensor([[-0.7908, -2.5403],
        [-0.9005, -1.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300116926431656
Epoch 0, Step 131: train/loss = 0.489664226770401, train/raw-loss = 0.47707605361938477, train/logprobs = tensor([[-1.2598, -2.4690],
        [-1.3570, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12588179111480713
Epoch 0, Step 132: train/loss = 0.6324049234390259, train/raw-loss = 0.6204840540885925, train/logprobs = tensor([[-0.5928, -2.8923],
        [-0.6041, -2.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11920831352472305
Epoch 0, Step 133: train/loss = 0.5212341547012329, train/raw-loss = 0.5064550042152405, train/logprobs = tensor([[-0.9471, -2.4474],
        [-1.0658, -1.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14779147505760193
Epoch 0, Step 134: train/loss = 0.5096551775932312, train/raw-loss = 0.4967785179615021, train/logprobs = tensor([[-0.9177, -2.5903],
        [-1.0082, -1.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12876643240451813
Epoch 0, Step 135: train/loss = 0.43708786368370056, train/raw-loss = 0.4223523736000061, train/logprobs = tensor([[-0.9790, -3.2078],
        [-1.1626, -1.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14735504984855652
Epoch 0, Step 136: train/loss = 0.5562071204185486, train/raw-loss = 0.5420939922332764, train/logprobs = tensor([[-0.8495, -2.5019],
        [-1.0574, -1.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14113114774227142
Epoch 0, Step 137: train/loss = 0.5375690460205078, train/raw-loss = 0.5240005254745483, train/logprobs = tensor([[-0.9160, -2.1974],
        [-1.0156, -1.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13568486273288727
Epoch 0, Step 138: train/loss = 0.5676627159118652, train/raw-loss = 0.5531680583953857, train/logprobs = tensor([[-0.7556, -2.4201],
        [-0.6999, -1.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494755864143372
