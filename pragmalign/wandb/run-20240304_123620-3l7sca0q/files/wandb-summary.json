{"train/loss": 0.0532, "train/learning_rate": 0.0, "train/rewards/chosen": -3.997609853744507, "train/rewards/rejected": -14.335875511169434, "train/rewards/accuracies": 0.9375, "train/rewards/margins": 10.338265419006348, "train/logps/rejected": -189.43304443359375, "train/logps/chosen": -81.34056091308594, "train/logits/rejected": -3.1238467693328857, "train/logits/chosen": -3.095653533935547, "train/epoch": 1.0, "train/global_step": 148, "_timestamp": 1709586698.6937404, "_runtime": 2118.566040277481, "_step": 149, "eval/loss": 0.12209485471248627, "eval/runtime": 43.2131, "eval/samples_per_second": 23.141, "eval/steps_per_second": 5.785, "eval/rewards/chosen": -3.0661442279815674, "eval/rewards/rejected": -11.96472454071045, "eval/rewards/accuracies": 0.9359999895095825, "eval/rewards/margins": 8.898580551147461, "eval/logps/rejected": -161.14149475097656, "eval/logps/chosen": -71.26802062988281, "eval/logits/rejected": -3.045177459716797, "eval/logits/chosen": -3.0788025856018066, "train/train_runtime": 2013.6767, "train/train_samples_per_second": 9.435, "train/train_steps_per_second": 0.073, "train/total_flos": 0.0, "train/train_loss": 0.2015266539780675, "_wandb": {"runtime": 2136}}