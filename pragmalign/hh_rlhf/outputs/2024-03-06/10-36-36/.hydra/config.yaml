mbaseline: dpo-model-temperature-0.0.json
mtest: stpo-model-temperature-0.0-beta-0.1.json
helpful_win_rates: stpo-beta-0.1-against-dpo-helpful.json
harmless_win_rates: stpo-beta-0.1-against-dpo-harmless.json
