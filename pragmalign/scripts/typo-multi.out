[2024-03-07 18:40:27,964][root][INFO] - beta: 0.1
[2024-03-07 18:40:27,964][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 4825
n harmless: 6795
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard\n\nIt's important to note that the use of these words can be considered offensive and inappropriate in certain contexts, and their use should be avoided in professional or formal settings.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard\n\nIt's important to note that the use of these words can be considered offensive and inappropriate in certain contexts, and their use should be avoided in professional or formal settings.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
11620
0
tokenized 11620 training examples...
train dataset has 11620 examples.
eval dataset has 0 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Epoch 0, Step 0: train/loss = 0.6759198904037476, train/raw-loss = 0.6759198904037476, train/logprobs = tensor([[-0.6874, -1.0937],
        [-0.7634, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6857614517211914, train/raw-loss = 0.6857614517211914, train/logprobs = tensor([[-0.4741, -0.6903],
        [-0.4930, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6750079393386841, train/raw-loss = 0.6750079393386841, train/logprobs = tensor([[-0.6665, -1.0342],
        [-0.7612, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6756741404533386, train/raw-loss = 0.6756741404533386, train/logprobs = tensor([[-0.5790, -0.8233],
        [-0.6004, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6798227429389954, train/raw-loss = 0.6798227429389954, train/logprobs = tensor([[-0.6071, -0.7509],
        [-0.6807, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6797856688499451, train/raw-loss = 0.6797856688499451, train/logprobs = tensor([[-0.6177, -0.6855],
        [-0.6860, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6723217964172363, train/raw-loss = 0.6723217964172363, train/logprobs = tensor([[-0.5167, -1.3262],
        [-0.5455, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6799655556678772, train/raw-loss = 0.6799655556678772, train/logprobs = tensor([[-0.7023, -1.2903],
        [-0.7715, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.676356315612793, train/raw-loss = 0.676356315612793, train/logprobs = tensor([[-0.6310, -0.5139],
        [-0.6814, -0.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6362022161483765, train/raw-loss = 0.6362022161483765, train/logprobs = tensor([[-0.5913, -1.5728],
        [-0.6686, -1.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6990966200828552, train/raw-loss = 0.6990966200828552, train/logprobs = tensor([[-0.7166, -0.7153],
        [-0.7466, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6520878672599792, train/raw-loss = 0.6520878672599792, train/logprobs = tensor([[-0.5732, -0.9218],
        [-0.6262, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.687408447265625, train/raw-loss = 0.687408447265625, train/logprobs = tensor([[-0.4404, -0.7218],
        [-0.4718, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6744726896286011, train/raw-loss = 0.6744726896286011, train/logprobs = tensor([[-0.5200, -0.5550],
        [-0.5846, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6820250153541565, train/raw-loss = 0.6820250153541565, train/logprobs = tensor([[-0.6387, -0.7318],
        [-0.7169, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6770372986793518, train/raw-loss = 0.6770372986793518, train/logprobs = tensor([[-0.5170, -0.5557],
        [-0.5475, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6810303926467896, train/raw-loss = 0.6810303926467896, train/logprobs = tensor([[-0.4032, -0.6353],
        [-0.4109, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6605470776557922, train/raw-loss = 0.6605470776557922, train/logprobs = tensor([[-0.6019, -0.9283],
        [-0.6735, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6599211692810059, train/raw-loss = 0.6599211692810059, train/logprobs = tensor([[-0.6047, -0.7969],
        [-0.6459, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6744762659072876, train/raw-loss = 0.6744762659072876, train/logprobs = tensor([[-0.6516, -1.0119],
        [-0.7067, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6578585505485535, train/raw-loss = 0.6578585505485535, train/logprobs = tensor([[-0.6157, -1.1569],
        [-0.6740, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6809818744659424, train/raw-loss = 0.6809818744659424, train/logprobs = tensor([[-0.6667, -0.5234],
        [-0.7096, -0.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6732928156852722, train/raw-loss = 0.6732928156852722, train/logprobs = tensor([[-0.5818, -0.7145],
        [-0.6233, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6346659064292908, train/raw-loss = 0.6346659064292908, train/logprobs = tensor([[-0.6524, -1.0342],
        [-0.7072, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721963882446289, train/raw-loss = 0.6721963882446289, train/logprobs = tensor([[-0.5568, -0.6549],
        [-0.6179, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.682538628578186, train/raw-loss = 0.682538628578186, train/logprobs = tensor([[-0.7870, -0.9307],
        [-0.8113, -0.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6509814858436584, train/raw-loss = 0.6509814858436584, train/logprobs = tensor([[-0.5072, -1.3617],
        [-0.5156, -1.1898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.679811954498291, train/raw-loss = 0.679811954498291, train/logprobs = tensor([[-0.4209, -0.8234],
        [-0.4279, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6676520705223083, train/raw-loss = 0.6676520705223083, train/logprobs = tensor([[-0.4069, -0.5929],
        [-0.4047, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6902005672454834, train/raw-loss = 0.6902005672454834, train/logprobs = tensor([[-0.4367, -0.6205],
        [-0.4514, -0.6234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6896546483039856, train/raw-loss = 0.6896546483039856, train/logprobs = tensor([[-0.5033, -0.5036],
        [-0.5280, -0.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.664493203163147, train/raw-loss = 0.664493203163147, train/logprobs = tensor([[-0.5930, -1.1077],
        [-0.6019, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.679036021232605, train/raw-loss = 0.679036021232605, train/logprobs = tensor([[-0.5457, -0.8672],
        [-0.5680, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6473491191864014, train/raw-loss = 0.6473491191864014, train/logprobs = tensor([[-0.6206, -0.8736],
        [-0.6742, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6771806478500366, train/raw-loss = 0.6771806478500366, train/logprobs = tensor([[-0.7219, -0.8137],
        [-0.8215, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6619305610656738, train/raw-loss = 0.6619305610656738, train/logprobs = tensor([[-0.5941, -0.5875],
        [-0.6956, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6776974201202393, train/raw-loss = 0.6776974201202393, train/logprobs = tensor([[-0.4829, -0.5469],
        [-0.5322, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6829013824462891, train/raw-loss = 0.6829013824462891, train/logprobs = tensor([[-0.4567, -0.6787],
        [-0.4691, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6560802459716797, train/raw-loss = 0.6560802459716797, train/logprobs = tensor([[-0.7170, -0.9229],
        [-0.8242, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6530677080154419, train/raw-loss = 0.6530677080154419, train/logprobs = tensor([[-0.5932, -0.7092],
        [-0.7044, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6830823421478271, train/raw-loss = 0.6830823421478271, train/logprobs = tensor([[-0.5392, -0.8422],
        [-0.5866, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6824573278427124, train/raw-loss = 0.6824573278427124, train/logprobs = tensor([[-0.5842, -0.6641],
        [-0.5996, -0.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6487219333648682, train/raw-loss = 0.6487219333648682, train/logprobs = tensor([[-0.5123, -0.9752],
        [-0.5542, -0.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6903495788574219, train/raw-loss = 0.6903495788574219, train/logprobs = tensor([[-0.4717, -0.4145],
        [-0.4926, -0.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.673434853553772, train/raw-loss = 0.673434853553772, train/logprobs = tensor([[-0.6980, -0.5440],
        [-0.7549, -0.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6786594986915588, train/raw-loss = 0.6786594986915588, train/logprobs = tensor([[-0.5011, -0.5380],
        [-0.5200, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6371243000030518, train/raw-loss = 0.6371243000030518, train/logprobs = tensor([[-0.4157, -1.0666],
        [-0.4404, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6752241849899292, train/raw-loss = 0.6752241849899292, train/logprobs = tensor([[-0.6329, -0.7464],
        [-0.6930, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.663917601108551, train/raw-loss = 0.663917601108551, train/logprobs = tensor([[-0.6115, -1.1571],
        [-0.6556, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6853899955749512, train/raw-loss = 0.6853899955749512, train/logprobs = tensor([[-0.5456, -0.8363],
        [-0.6122, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678441047668457, train/raw-loss = 0.678441047668457, train/logprobs = tensor([[-0.6881, -0.8771],
        [-0.7572, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6859574317932129, train/raw-loss = 0.6859574317932129, train/logprobs = tensor([[-0.4706, -0.9016],
        [-0.4941, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6938302516937256, train/raw-loss = 0.6938302516937256, train/logprobs = tensor([[-0.4640, -0.5224],
        [-0.4992, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6358654499053955, train/raw-loss = 0.6358654499053955, train/logprobs = tensor([[-0.4992, -1.0191],
        [-0.5920, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6599295139312744, train/raw-loss = 0.6599295139312744, train/logprobs = tensor([[-0.5818, -0.7526],
        [-0.6965, -0.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6781942844390869, train/raw-loss = 0.6781942844390869, train/logprobs = tensor([[-0.5635, -0.7984],
        [-0.5616, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.675916314125061, train/raw-loss = 0.675916314125061, train/logprobs = tensor([[-0.7523, -0.7654],
        [-0.8002, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6486356258392334, train/raw-loss = 0.6486356258392334, train/logprobs = tensor([[-0.7853, -1.5562],
        [-0.8732, -1.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6811543703079224, train/raw-loss = 0.6811543703079224, train/logprobs = tensor([[-0.5191, -0.7768],
        [-0.5563, -0.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6736766695976257, train/raw-loss = 0.6736766695976257, train/logprobs = tensor([[-0.7141, -0.7812],
        [-0.7638, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6906877160072327, train/raw-loss = 0.6906877160072327, train/logprobs = tensor([[-0.4463, -0.7096],
        [-0.4616, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6729649901390076, train/raw-loss = 0.6729649901390076, train/logprobs = tensor([[-0.5516, -0.6064],
        [-0.6084, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6810125112533569, train/raw-loss = 0.6810125112533569, train/logprobs = tensor([[-0.7101, -1.0578],
        [-0.7567, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6836602091789246, train/raw-loss = 0.6836602091789246, train/logprobs = tensor([[-0.4712, -0.6318],
        [-0.5153, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6832484602928162, train/raw-loss = 0.6831880807876587, train/logprobs = tensor([[-0.5045, -0.5578],
        [-0.5228, -0.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006036849226802588
Epoch 0, Step 65: train/loss = 0.6777960062026978, train/raw-loss = 0.6777313947677612, train/logprobs = tensor([[-0.6416, -0.5054],
        [-0.6858, -0.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006458357092924416
Epoch 0, Step 66: train/loss = 0.6456356644630432, train/raw-loss = 0.6455670595169067, train/logprobs = tensor([[-0.6254, -1.3766],
        [-0.7210, -1.2632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006861344445496798
Epoch 0, Step 67: train/loss = 0.6720798015594482, train/raw-loss = 0.6720123291015625, train/logprobs = tensor([[-0.6458, -0.7480],
        [-0.6753, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006737359799444675
Epoch 0, Step 68: train/loss = 0.6697960495948792, train/raw-loss = 0.6697266101837158, train/logprobs = tensor([[-0.4874, -0.8459],
        [-0.5204, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006940350867807865
Epoch 0, Step 69: train/loss = 0.6833599209785461, train/raw-loss = 0.6832937598228455, train/logprobs = tensor([[-0.5136, -0.6146],
        [-0.5152, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006620842614211142
Epoch 0, Step 70: train/loss = 0.6926332712173462, train/raw-loss = 0.6925663948059082, train/logprobs = tensor([[-0.4606, -0.6710],
        [-0.4482, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000669218017719686
Epoch 0, Step 71: train/loss = 0.6711336970329285, train/raw-loss = 0.6710714101791382, train/logprobs = tensor([[-0.4668, -0.9878],
        [-0.4815, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006228381535038352
Epoch 0, Step 72: train/loss = 0.6756914854049683, train/raw-loss = 0.6756242513656616, train/logprobs = tensor([[-0.5111, -0.7505],
        [-0.5468, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006716953939758241
Epoch 0, Step 73: train/loss = 0.6745832562446594, train/raw-loss = 0.6745209693908691, train/logprobs = tensor([[-0.5583, -0.5764],
        [-0.6285, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006224539247341454
Epoch 0, Step 74: train/loss = 0.6876063346862793, train/raw-loss = 0.687531590461731, train/logprobs = tensor([[-0.4914, -0.7651],
        [-0.5063, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007474495796486735
Epoch 0, Step 75: train/loss = 0.6918396949768066, train/raw-loss = 0.6917768120765686, train/logprobs = tensor([[-0.5069, -0.8442],
        [-0.5682, -0.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000628890935331583
Epoch 0, Step 76: train/loss = 0.6826103925704956, train/raw-loss = 0.6825475096702576, train/logprobs = tensor([[-0.5229, -0.5359],
        [-0.5474, -0.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006291116587817669
Epoch 0, Step 77: train/loss = 0.6505202054977417, train/raw-loss = 0.6504487991333008, train/logprobs = tensor([[-0.6193, -0.8844],
        [-0.6865, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007144233677536249
Epoch 0, Step 78: train/loss = 0.6891947984695435, train/raw-loss = 0.6891248226165771, train/logprobs = tensor([[-0.4646, -0.5003],
        [-0.4899, -0.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006993780843913555
Epoch 0, Step 79: train/loss = 0.6782895922660828, train/raw-loss = 0.6782211661338806, train/logprobs = tensor([[-0.4684, -0.5533],
        [-0.5088, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006847096374258399
Epoch 0, Step 80: train/loss = 0.6535342931747437, train/raw-loss = 0.6534669399261475, train/logprobs = tensor([[-0.5622, -0.8173],
        [-0.5993, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006732074543833733
Epoch 0, Step 81: train/loss = 0.660675585269928, train/raw-loss = 0.6606080532073975, train/logprobs = tensor([[-0.4891, -0.8492],
        [-0.4963, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006755570648238063
Epoch 0, Step 82: train/loss = 0.6622928977012634, train/raw-loss = 0.662223219871521, train/logprobs = tensor([[-0.5810, -0.7663],
        [-0.6482, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006970838876441121
Epoch 0, Step 83: train/loss = 0.6619136333465576, train/raw-loss = 0.661846935749054, train/logprobs = tensor([[-0.5477, -0.6667],
        [-0.5926, -0.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006670970469713211
Epoch 0, Step 84: train/loss = 0.6764739751815796, train/raw-loss = 0.6764081120491028, train/logprobs = tensor([[-0.4949, -0.7941],
        [-0.5125, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006590661942027509
Epoch 0, Step 85: train/loss = 0.6729460954666138, train/raw-loss = 0.6728756427764893, train/logprobs = tensor([[-0.7021, -0.9177],
        [-0.7898, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007045652018859982
Epoch 0, Step 86: train/loss = 0.6572507619857788, train/raw-loss = 0.6571915745735168, train/logprobs = tensor([[-0.5040, -0.6619],
        [-0.5360, -0.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005914671346545219
Epoch 0, Step 87: train/loss = 0.6543859243392944, train/raw-loss = 0.6543176174163818, train/logprobs = tensor([[-0.6250, -0.7965],
        [-0.6713, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006830053171142936
Epoch 0, Step 88: train/loss = 0.6155099868774414, train/raw-loss = 0.6154448986053467, train/logprobs = tensor([[-0.6792, -1.5114],
        [-0.7403, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006511493702419102
Epoch 0, Step 89: train/loss = 0.6651321649551392, train/raw-loss = 0.665066659450531, train/logprobs = tensor([[-0.5978, -0.6588],
        [-0.6277, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006547936354763806
Epoch 0, Step 90: train/loss = 0.6621607542037964, train/raw-loss = 0.6620924472808838, train/logprobs = tensor([[-0.6502, -0.7576],
        [-0.7126, -0.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006835585227236152
Epoch 0, Step 91: train/loss = 0.6593738794326782, train/raw-loss = 0.6593047976493835, train/logprobs = tensor([[-0.6762, -1.1690],
        [-0.7711, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006910940865054727
Epoch 0, Step 92: train/loss = 0.6700291037559509, train/raw-loss = 0.669964611530304, train/logprobs = tensor([[-0.6420, -0.9124],
        [-0.6950, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006443835445679724
Epoch 0, Step 93: train/loss = 0.6632087230682373, train/raw-loss = 0.6631375551223755, train/logprobs = tensor([[-0.5407, -0.6281],
        [-0.6009, -0.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007122678216546774
Epoch 0, Step 94: train/loss = 0.6492125391960144, train/raw-loss = 0.6491420865058899, train/logprobs = tensor([[-0.7990, -1.1197],
        [-0.9667, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007041794015094638
Epoch 0, Step 95: train/loss = 0.6721925735473633, train/raw-loss = 0.672126054763794, train/logprobs = tensor([[-0.5790, -1.0915],
        [-0.6249, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006645218818448484
Epoch 0, Step 96: train/loss = 0.6884866952896118, train/raw-loss = 0.6882091164588928, train/logprobs = tensor([[-0.5180, -0.6046],
        [-0.5105, -0.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027753545437008142
Epoch 0, Step 97: train/loss = 0.6573331952095032, train/raw-loss = 0.6568905115127563, train/logprobs = tensor([[-0.7382, -0.9480],
        [-0.8357, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004427024163305759
Epoch 0, Step 98: train/loss = 0.6877569556236267, train/raw-loss = 0.6873996257781982, train/logprobs = tensor([[-0.6133, -0.7096],
        [-0.6604, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035729478113353252
Epoch 0, Step 99: train/loss = 0.6641057729721069, train/raw-loss = 0.6637963056564331, train/logprobs = tensor([[-0.4639, -0.4720],
        [-0.5371, -0.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003094450803473592
Epoch 0, Step 100: train/loss = 0.680668830871582, train/raw-loss = 0.6803818941116333, train/logprobs = tensor([[-0.5472, -0.6484],
        [-0.5627, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028687696903944016
Epoch 0, Step 101: train/loss = 0.6570868492126465, train/raw-loss = 0.6566863059997559, train/logprobs = tensor([[-0.5970, -1.1452],
        [-0.6109, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004005797207355499
Epoch 0, Step 102: train/loss = 0.6372106075286865, train/raw-loss = 0.6368390321731567, train/logprobs = tensor([[-0.4866, -1.2235],
        [-0.5161, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037152227014303207
Epoch 0, Step 103: train/loss = 0.5872595310211182, train/raw-loss = 0.5869162678718567, train/logprobs = tensor([[-0.7116, -1.7175],
        [-0.7623, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034326347522437572
Epoch 0, Step 104: train/loss = 0.669462263584137, train/raw-loss = 0.6691004037857056, train/logprobs = tensor([[-0.6573, -1.3398],
        [-0.6696, -1.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036182510666549206
Epoch 0, Step 105: train/loss = 0.6644284725189209, train/raw-loss = 0.6640788316726685, train/logprobs = tensor([[-0.6918, -1.1885],
        [-0.7077, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003496142802760005
Epoch 0, Step 106: train/loss = 0.6656418442726135, train/raw-loss = 0.6653688549995422, train/logprobs = tensor([[-0.4584, -0.7647],
        [-0.4830, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002730292733758688
Epoch 0, Step 107: train/loss = 0.6606117486953735, train/raw-loss = 0.6602743864059448, train/logprobs = tensor([[-0.6673, -0.9856],
        [-0.7319, -0.9134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003373410552740097
Epoch 0, Step 108: train/loss = 0.6402857899665833, train/raw-loss = 0.6399447917938232, train/logprobs = tensor([[-0.7880, -0.7740],
        [-0.8939, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034100431948900223
Epoch 0, Step 109: train/loss = 0.6878936886787415, train/raw-loss = 0.6875868439674377, train/logprobs = tensor([[-0.4951, -0.4425],
        [-0.4945, -0.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030684026423841715
Epoch 0, Step 110: train/loss = 0.6858234405517578, train/raw-loss = 0.6854926347732544, train/logprobs = tensor([[-0.4653, -0.5621],
        [-0.4638, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003308885730803013
Epoch 0, Step 111: train/loss = 0.6714319586753845, train/raw-loss = 0.6711580753326416, train/logprobs = tensor([[-0.5412, -1.2767],
        [-0.5626, -1.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027389279566705227
Epoch 0, Step 112: train/loss = 0.6909486055374146, train/raw-loss = 0.6905630826950073, train/logprobs = tensor([[-0.5092, -0.7509],
        [-0.5312, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038548619486391544
Epoch 0, Step 113: train/loss = 0.6663806438446045, train/raw-loss = 0.6660488247871399, train/logprobs = tensor([[-0.6976, -0.6495],
        [-0.7347, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003317819442600012
Epoch 0, Step 114: train/loss = 0.6328283548355103, train/raw-loss = 0.6325329542160034, train/logprobs = tensor([[-0.6256, -1.2294],
        [-0.7034, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002953740069642663
Epoch 0, Step 115: train/loss = 0.6874603033065796, train/raw-loss = 0.6870715022087097, train/logprobs = tensor([[-0.8529, -1.5613],
        [-0.8775, -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038876915350556374
Epoch 0, Step 116: train/loss = 0.6665428280830383, train/raw-loss = 0.6661931276321411, train/logprobs = tensor([[-0.6220, -0.7274],
        [-0.6661, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034971360582858324
Epoch 0, Step 117: train/loss = 0.6665560603141785, train/raw-loss = 0.6662006378173828, train/logprobs = tensor([[-0.6198, -0.6601],
        [-0.6480, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035537611693143845
Epoch 0, Step 118: train/loss = 0.6558387279510498, train/raw-loss = 0.6554815769195557, train/logprobs = tensor([[-0.5367, -0.9899],
        [-0.5558, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003571633016690612
Epoch 0, Step 119: train/loss = 0.6903272271156311, train/raw-loss = 0.6898728609085083, train/logprobs = tensor([[-0.5522, -0.5644],
        [-0.5653, -0.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004544039722532034
Epoch 0, Step 120: train/loss = 0.6842625141143799, train/raw-loss = 0.6838023066520691, train/logprobs = tensor([[-0.6561, -0.7014],
        [-0.6948, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00460236519575119
Epoch 0, Step 121: train/loss = 0.6892048120498657, train/raw-loss = 0.688774585723877, train/logprobs = tensor([[-0.7505, -1.0589],
        [-0.8097, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004302150569856167
Epoch 0, Step 122: train/loss = 0.6713790893554688, train/raw-loss = 0.6709638833999634, train/logprobs = tensor([[-0.6814, -0.9522],
        [-0.7017, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041519333608448505
Epoch 0, Step 123: train/loss = 0.6700873374938965, train/raw-loss = 0.6697773337364197, train/logprobs = tensor([[-0.5919, -0.8075],
        [-0.6137, -0.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003099829889833927
Epoch 0, Step 124: train/loss = 0.653876781463623, train/raw-loss = 0.6535154581069946, train/logprobs = tensor([[-0.6109, -0.8416],
        [-0.6487, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036130081862211227
Epoch 0, Step 125: train/loss = 0.6818460822105408, train/raw-loss = 0.6815530061721802, train/logprobs = tensor([[-0.5332, -0.7155],
        [-0.5321, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029308085795491934
Epoch 0, Step 126: train/loss = 0.6772907972335815, train/raw-loss = 0.6769372820854187, train/logprobs = tensor([[-0.5716, -0.6169],
        [-0.5799, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003534787567332387
Epoch 0, Step 127: train/loss = 0.5924104452133179, train/raw-loss = 0.5920314788818359, train/logprobs = tensor([[-0.5297, -1.7381],
        [-0.5710, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037900335155427456
Epoch 0, Step 128: train/loss = 0.5894901752471924, train/raw-loss = 0.5876904726028442, train/logprobs = tensor([[-0.6646, -2.0778],
        [-0.6797, -1.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017997240647673607
Epoch 0, Step 129: train/loss = 0.6039232015609741, train/raw-loss = 0.6015561819076538, train/logprobs = tensor([[-0.7697, -1.9879],
        [-0.7851, -1.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023670626804232597
Epoch 0, Step 130: train/loss = 0.673664927482605, train/raw-loss = 0.6719871759414673, train/logprobs = tensor([[-0.5934, -0.7549],
        [-0.5619, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016777560114860535
Epoch 0, Step 131: train/loss = 0.6779972910881042, train/raw-loss = 0.6761055588722229, train/logprobs = tensor([[-0.8372, -0.8589],
        [-0.8981, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018917422741651535
Epoch 0, Step 132: train/loss = 0.6574044823646545, train/raw-loss = 0.6557120680809021, train/logprobs = tensor([[-0.5897, -0.5745],
        [-0.6473, -0.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01692415028810501
Epoch 0, Step 133: train/loss = 0.6443973779678345, train/raw-loss = 0.6426870822906494, train/logprobs = tensor([[-0.6184, -1.1870],
        [-0.6082, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017102286219596863
Epoch 0, Step 134: train/loss = 0.6701714992523193, train/raw-loss = 0.6681346297264099, train/logprobs = tensor([[-0.8141, -0.9300],
        [-0.7434, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02036825753748417
Epoch 0, Step 135: train/loss = 0.6725486516952515, train/raw-loss = 0.6706789135932922, train/logprobs = tensor([[-0.5812, -0.6837],
        [-0.6148, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018697375431656837
Epoch 0, Step 136: train/loss = 0.6740874648094177, train/raw-loss = 0.6724382638931274, train/logprobs = tensor([[-0.6263, -0.6640],
        [-0.6333, -0.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016492031514644623
Epoch 0, Step 137: train/loss = 0.6427152752876282, train/raw-loss = 0.6410146355628967, train/logprobs = tensor([[-0.6154, -0.6858],
        [-0.6728, -0.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01700647547841072
Epoch 0, Step 138: train/loss = 0.5975102782249451, train/raw-loss = 0.5956755876541138, train/logprobs = tensor([[-0.6903, -1.3969],
        [-0.7085, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018347157165408134
Epoch 0, Step 139: train/loss = 0.6268821954727173, train/raw-loss = 0.625144362449646, train/logprobs = tensor([[-0.5346, -0.9796],
        [-0.5569, -0.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017378518357872963
Epoch 0, Step 140: train/loss = 0.631547212600708, train/raw-loss = 0.6298601031303406, train/logprobs = tensor([[-0.6204, -0.8832],
        [-0.7069, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016871193423867226
Epoch 0, Step 141: train/loss = 0.6592497825622559, train/raw-loss = 0.657099723815918, train/logprobs = tensor([[-0.7003, -1.0203],
        [-0.7075, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02150077372789383
Epoch 0, Step 142: train/loss = 0.6731835603713989, train/raw-loss = 0.671477198600769, train/logprobs = tensor([[-0.4603, -0.6141],
        [-0.4499, -0.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017063938081264496
Epoch 0, Step 143: train/loss = 0.6782048344612122, train/raw-loss = 0.6761132478713989, train/logprobs = tensor([[-0.5733, -0.9730],
        [-0.5653, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020915741100907326
Epoch 0, Step 144: train/loss = 0.6306663751602173, train/raw-loss = 0.6289221048355103, train/logprobs = tensor([[-0.5060, -0.8879],
        [-0.5307, -0.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017443079501390457
Epoch 0, Step 145: train/loss = 0.6945962309837341, train/raw-loss = 0.6930164098739624, train/logprobs = tensor([[-0.4845, -0.4405],
        [-0.4661, -0.4212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015797169879078865
Epoch 0, Step 146: train/loss = 0.6713689565658569, train/raw-loss = 0.6692862510681152, train/logprobs = tensor([[-0.6025, -0.7927],
        [-0.5933, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020827585831284523
Epoch 0, Step 147: train/loss = 0.6465549468994141, train/raw-loss = 0.6445251703262329, train/logprobs = tensor([[-0.6731, -1.4407],
        [-0.7066, -1.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020297780632972717
Epoch 0, Step 148: train/loss = 0.6625398397445679, train/raw-loss = 0.6604681611061096, train/logprobs = tensor([[-0.6859, -0.7500],
        [-0.7217, -0.6481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02071678265929222
Epoch 0, Step 149: train/loss = 0.6255292892456055, train/raw-loss = 0.623593807220459, train/logprobs = tensor([[-0.6788, -1.5425],
        [-0.6716, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019354885444045067
Epoch 0, Step 150: train/loss = 0.6732056140899658, train/raw-loss = 0.671751081943512, train/logprobs = tensor([[-0.5077, -0.7329],
        [-0.5044, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014545151963829994
Epoch 0, Step 151: train/loss = 0.6732960939407349, train/raw-loss = 0.6715025305747986, train/logprobs = tensor([[-0.7646, -0.9906],
        [-0.7461, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017935598269104958
Epoch 0, Step 152: train/loss = 0.656502366065979, train/raw-loss = 0.6549404859542847, train/logprobs = tensor([[-0.5121, -0.8041],
        [-0.4888, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015619202516973019
Epoch 0, Step 153: train/loss = 0.675667941570282, train/raw-loss = 0.6741334199905396, train/logprobs = tensor([[-0.5112, -0.7349],
        [-0.5013, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015344835817813873
Epoch 0, Step 154: train/loss = 0.6524214148521423, train/raw-loss = 0.6502313613891602, train/logprobs = tensor([[-0.5490, -0.9766],
        [-0.5350, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021900199353694916
Epoch 0, Step 155: train/loss = 0.6817660331726074, train/raw-loss = 0.6798182129859924, train/logprobs = tensor([[-0.5483, -0.6673],
        [-0.5308, -0.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019478125497698784
Epoch 0, Step 156: train/loss = 0.6309428215026855, train/raw-loss = 0.6292914152145386, train/logprobs = tensor([[-0.6282, -1.3119],
        [-0.5947, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01651458628475666
Epoch 0, Step 157: train/loss = 0.6750460863113403, train/raw-loss = 0.6730936765670776, train/logprobs = tensor([[-0.5332, -0.6117],
        [-0.5122, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019524862989783287
Epoch 0, Step 158: train/loss = 0.6236083507537842, train/raw-loss = 0.6217657923698425, train/logprobs = tensor([[-0.5617, -1.5703],
        [-0.5679, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018425587564706802
Epoch 0, Step 159: train/loss = 0.5908886194229126, train/raw-loss = 0.5883889198303223, train/logprobs = tensor([[-0.7945, -1.1411],
        [-0.9206, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024997636675834656
Epoch 0, Step 160: train/loss = 0.6614038944244385, train/raw-loss = 0.6587367057800293, train/logprobs = tensor([[-0.6454, -0.7290],
        [-0.6402, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026672236621379852
Epoch 0, Step 161: train/loss = 0.6348430514335632, train/raw-loss = 0.632250189781189, train/logprobs = tensor([[-0.6967, -0.8634],
        [-0.8138, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025929169729351997
Epoch 0, Step 162: train/loss = 0.6655471324920654, train/raw-loss = 0.6631524562835693, train/logprobs = tensor([[-0.5567, -0.5316],
        [-0.6367, -0.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023946862667798996
Epoch 0, Step 163: train/loss = 0.6298260688781738, train/raw-loss = 0.6278146505355835, train/logprobs = tensor([[-0.5916, -0.8900],
        [-0.6434, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020114069804549217
Epoch 0, Step 164: train/loss = 0.6914345026016235, train/raw-loss = 0.6888157725334167, train/logprobs = tensor([[-0.6971, -0.7616],
        [-0.6890, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026187147945165634
Epoch 0, Step 165: train/loss = 0.6322473883628845, train/raw-loss = 0.6301639080047607, train/logprobs = tensor([[-0.5215, -0.8192],
        [-0.5845, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020834464579820633
Epoch 0, Step 166: train/loss = 0.6421470642089844, train/raw-loss = 0.6401803493499756, train/logprobs = tensor([[-0.5973, -0.8177],
        [-0.6846, -0.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01966719701886177
Epoch 0, Step 167: train/loss = 0.670121967792511, train/raw-loss = 0.6671781539916992, train/logprobs = tensor([[-0.5535, -0.9780],
        [-0.5332, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02943790890276432
Epoch 0, Step 168: train/loss = 0.6172126531600952, train/raw-loss = 0.6142092943191528, train/logprobs = tensor([[-0.7128, -1.6602],
        [-0.7038, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03003380447626114
Epoch 0, Step 169: train/loss = 0.6594843864440918, train/raw-loss = 0.6564266681671143, train/logprobs = tensor([[-0.6823, -1.0403],
        [-0.7123, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030577348545193672
Epoch 0, Step 170: train/loss = 0.6769464612007141, train/raw-loss = 0.6735783815383911, train/logprobs = tensor([[-1.3549, -1.0444],
        [-1.2815, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03368107229471207
Epoch 0, Step 171: train/loss = 0.632525622844696, train/raw-loss = 0.629807710647583, train/logprobs = tensor([[-0.8273, -0.9657],
        [-0.7881, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027178943157196045
Epoch 0, Step 172: train/loss = 0.6473464369773865, train/raw-loss = 0.6443753242492676, train/logprobs = tensor([[-0.6911, -0.9936],
        [-0.6879, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029711365699768066
Epoch 0, Step 173: train/loss = 0.6000754833221436, train/raw-loss = 0.5976885557174683, train/logprobs = tensor([[-0.5857, -1.4696],
        [-0.5326, -0.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02386925369501114
Epoch 0, Step 174: train/loss = 0.6158959865570068, train/raw-loss = 0.613945722579956, train/logprobs = tensor([[-0.5893, -0.9383],
        [-0.5898, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01950336992740631
Epoch 0, Step 175: train/loss = 0.6805942058563232, train/raw-loss = 0.6780246496200562, train/logprobs = tensor([[-0.5860, -0.8109],
        [-0.6115, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02569577470421791
Epoch 0, Step 176: train/loss = 0.6289495825767517, train/raw-loss = 0.626347541809082, train/logprobs = tensor([[-0.5479, -0.8740],
        [-0.5499, -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026020821183919907
Epoch 0, Step 177: train/loss = 0.523872971534729, train/raw-loss = 0.5213616490364075, train/logprobs = tensor([[-0.6035, -2.4251],
        [-0.6583, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025113552808761597
Epoch 0, Step 178: train/loss = 0.6656181812286377, train/raw-loss = 0.6621936559677124, train/logprobs = tensor([[-0.5932, -0.8476],
        [-0.5904, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034245770424604416
Epoch 0, Step 179: train/loss = 0.6610407829284668, train/raw-loss = 0.658521294593811, train/logprobs = tensor([[-0.6176, -0.7539],
        [-0.5514, -0.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025194507092237473
Epoch 0, Step 180: train/loss = 0.6248066425323486, train/raw-loss = 0.6216371059417725, train/logprobs = tensor([[-0.6879, -1.5527],
        [-0.6828, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0316954180598259
Epoch 0, Step 181: train/loss = 0.6217253804206848, train/raw-loss = 0.6190077066421509, train/logprobs = tensor([[-0.4091, -1.4777],
        [-0.4077, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02717718295753002
Epoch 0, Step 182: train/loss = 0.6890584230422974, train/raw-loss = 0.686561644077301, train/logprobs = tensor([[-0.5137, -0.6240],
        [-0.5026, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024968214333057404
Epoch 0, Step 183: train/loss = 0.6571668386459351, train/raw-loss = 0.6540946960449219, train/logprobs = tensor([[-0.5780, -0.8446],
        [-0.5348, -0.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030721355229616165
Epoch 0, Step 184: train/loss = 0.621595025062561, train/raw-loss = 0.618798017501831, train/logprobs = tensor([[-0.8547, -0.9838],
        [-0.9185, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02796988934278488
Epoch 0, Step 185: train/loss = 0.637047290802002, train/raw-loss = 0.6347756385803223, train/logprobs = tensor([[-0.5502, -0.9962],
        [-0.5331, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022716227918863297
Epoch 0, Step 186: train/loss = 0.6951121091842651, train/raw-loss = 0.6923853158950806, train/logprobs = tensor([[-0.4788, -0.5323],
        [-0.4815, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027268141508102417
Epoch 0, Step 187: train/loss = 0.5863416790962219, train/raw-loss = 0.5835689306259155, train/logprobs = tensor([[-0.6117, -1.0634],
        [-0.7015, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027727579697966576
Epoch 0, Step 188: train/loss = 0.6481013298034668, train/raw-loss = 0.6452954411506653, train/logprobs = tensor([[-0.7721, -0.7166],
        [-0.8141, -0.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02805926650762558
Epoch 0, Step 189: train/loss = 0.670616865158081, train/raw-loss = 0.6678391695022583, train/logprobs = tensor([[-0.6591, -0.8419],
        [-0.5654, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027776680886745453
Epoch 0, Step 190: train/loss = 0.6722351908683777, train/raw-loss = 0.6692642569541931, train/logprobs = tensor([[-0.6526, -0.9626],
        [-0.6652, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029709840193390846
Epoch 0, Step 191: train/loss = 0.6510497331619263, train/raw-loss = 0.6481362581253052, train/logprobs = tensor([[-0.5092, -1.1726],
        [-0.5209, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029135307297110558
Epoch 0, Step 192: train/loss = 0.5708392858505249, train/raw-loss = 0.5666961669921875, train/logprobs = tensor([[-0.5844, -1.3369],
        [-0.5961, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0414305217564106
Epoch 0, Step 193: train/loss = 0.6434558629989624, train/raw-loss = 0.6379258036613464, train/logprobs = tensor([[-0.6139, -1.0741],
        [-0.5904, -0.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055301085114479065
Epoch 0, Step 194: train/loss = 0.6556665897369385, train/raw-loss = 0.6495083570480347, train/logprobs = tensor([[-0.7363, -0.7068],
        [-0.8047, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061582766473293304
Epoch 0, Step 195: train/loss = 0.6567877531051636, train/raw-loss = 0.6516723036766052, train/logprobs = tensor([[-0.7583, -0.8778],
        [-0.7920, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05115412920713425
Epoch 0, Step 196: train/loss = 0.8565949201583862, train/raw-loss = 0.8496602773666382, train/logprobs = tensor([[-1.0455, -1.7694],
        [-1.0667, -2.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06934639066457748
Epoch 0, Step 197: train/loss = 0.7013332843780518, train/raw-loss = 0.6957480311393738, train/logprobs = tensor([[-1.0530, -1.1229],
        [-0.7922, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05585242435336113
Epoch 0, Step 198: train/loss = 0.6772559285163879, train/raw-loss = 0.6727111339569092, train/logprobs = tensor([[-0.5280, -0.8139],
        [-0.4807, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04544767364859581
Epoch 0, Step 199: train/loss = 0.6377249956130981, train/raw-loss = 0.6310262084007263, train/logprobs = tensor([[-0.6278, -1.5546],
        [-0.6037, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698791682720184
Epoch 0, Step 200: train/loss = 0.6272214651107788, train/raw-loss = 0.622394323348999, train/logprobs = tensor([[-0.6696, -1.2077],
        [-0.6091, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04827165603637695
Epoch 0, Step 201: train/loss = 0.5663509368896484, train/raw-loss = 0.5611010193824768, train/logprobs = tensor([[-0.5640, -2.1423],
        [-0.5225, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052498709410429
Epoch 0, Step 202: train/loss = 0.6810483932495117, train/raw-loss = 0.675755500793457, train/logprobs = tensor([[-0.5561, -0.6595],
        [-0.5147, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05292871594429016
Epoch 0, Step 203: train/loss = 0.609331488609314, train/raw-loss = 0.6044579744338989, train/logprobs = tensor([[-0.6014, -1.2226],
        [-0.5380, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04873589053750038
Epoch 0, Step 204: train/loss = 0.6422786712646484, train/raw-loss = 0.6365959048271179, train/logprobs = tensor([[-0.8886, -1.3760],
        [-0.8199, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056828245520591736
Epoch 0, Step 205: train/loss = 0.6594948768615723, train/raw-loss = 0.6534326076507568, train/logprobs = tensor([[-0.6924, -0.7293],
        [-0.7253, -0.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060622572898864746
Epoch 0, Step 206: train/loss = 0.6739240288734436, train/raw-loss = 0.6691979169845581, train/logprobs = tensor([[-0.5552, -0.6532],
        [-0.5235, -0.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0472608357667923
Epoch 0, Step 207: train/loss = 0.7020987868309021, train/raw-loss = 0.6971677541732788, train/logprobs = tensor([[-0.4659, -0.8057],
        [-0.4516, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049310021102428436
Epoch 0, Step 208: train/loss = 0.5768550038337708, train/raw-loss = 0.571361243724823, train/logprobs = tensor([[-0.5530, -2.0485],
        [-0.6130, -1.3115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054938070476055145
Epoch 0, Step 209: train/loss = 0.6293964982032776, train/raw-loss = 0.6251712441444397, train/logprobs = tensor([[-0.4570, -1.0423],
        [-0.4399, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04225224256515503
Epoch 0, Step 210: train/loss = 0.6800794005393982, train/raw-loss = 0.6750208139419556, train/logprobs = tensor([[-0.5560, -0.7189],
        [-0.5510, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050585683435201645
Epoch 0, Step 211: train/loss = 0.6363626718521118, train/raw-loss = 0.6300290822982788, train/logprobs = tensor([[-0.7754, -0.9797],
        [-0.8381, -0.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0633358359336853
Epoch 0, Step 212: train/loss = 0.6305628418922424, train/raw-loss = 0.625208854675293, train/logprobs = tensor([[-0.5194, -1.0858],
        [-0.5199, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05353943258523941
Epoch 0, Step 213: train/loss = 0.6112470030784607, train/raw-loss = 0.6054515242576599, train/logprobs = tensor([[-0.6206, -1.0945],
        [-0.6393, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057954948395490646
Epoch 0, Step 214: train/loss = 0.6623579263687134, train/raw-loss = 0.6569247841835022, train/logprobs = tensor([[-0.6643, -1.3750],
        [-0.6846, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054331883788108826
Epoch 0, Step 215: train/loss = 0.6301976442337036, train/raw-loss = 0.6234792470932007, train/logprobs = tensor([[-0.7128, -1.5858],
        [-0.7031, -1.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.067183718085289
Epoch 0, Step 216: train/loss = 0.6705482006072998, train/raw-loss = 0.6647251844406128, train/logprobs = tensor([[-0.5288, -0.6910],
        [-0.5397, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0582304373383522
Epoch 0, Step 217: train/loss = 0.5672956705093384, train/raw-loss = 0.5615299940109253, train/logprobs = tensor([[-0.7074, -1.2534],
        [-0.7662, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05765770003199577
Epoch 0, Step 218: train/loss = 0.6749544739723206, train/raw-loss = 0.6694900989532471, train/logprobs = tensor([[-0.5023, -0.7169],
        [-0.4590, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05464399233460426
Epoch 0, Step 219: train/loss = 0.6762144565582275, train/raw-loss = 0.670768678188324, train/logprobs = tensor([[-0.5676, -0.7374],
        [-0.5826, -0.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05445782095193863
Epoch 0, Step 220: train/loss = 0.6667797565460205, train/raw-loss = 0.6605410575866699, train/logprobs = tensor([[-0.6746, -0.9681],
        [-0.6685, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06238681077957153
Epoch 0, Step 221: train/loss = 0.5739136338233948, train/raw-loss = 0.5690438151359558, train/logprobs = tensor([[-0.5824, -1.4619],
        [-0.5782, -0.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04869798570871353
Epoch 0, Step 222: train/loss = 0.6012078523635864, train/raw-loss = 0.5965175032615662, train/logprobs = tensor([[-0.7137, -1.4809],
        [-0.6724, -0.9706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04690371826291084
Epoch 0, Step 223: train/loss = 0.5415365695953369, train/raw-loss = 0.5360271334648132, train/logprobs = tensor([[-0.6106, -1.5096],
        [-0.6727, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0550944022834301
Epoch 0, Step 224: train/loss = 0.6599435806274414, train/raw-loss = 0.6525125503540039, train/logprobs = tensor([[-0.5777, -0.7865],
        [-0.5560, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07431049644947052
Epoch 0, Step 225: train/loss = 0.6565690636634827, train/raw-loss = 0.6511198878288269, train/logprobs = tensor([[-0.4500, -0.7696],
        [-0.4376, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0544915497303009
Epoch 0, Step 226: train/loss = 0.553159236907959, train/raw-loss = 0.5443168878555298, train/logprobs = tensor([[-0.7064, -2.1807],
        [-0.7611, -1.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08842369168996811
Epoch 0, Step 227: train/loss = 0.6391280293464661, train/raw-loss = 0.6308736801147461, train/logprobs = tensor([[-0.5552, -1.0520],
        [-0.5621, -0.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08254320919513702
Epoch 0, Step 228: train/loss = 0.627346932888031, train/raw-loss = 0.6202759742736816, train/logprobs = tensor([[-0.5423, -0.9525],
        [-0.5627, -0.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0707097053527832
Epoch 0, Step 229: train/loss = 0.6549676656723022, train/raw-loss = 0.6464348435401917, train/logprobs = tensor([[-0.4837, -0.7679],
        [-0.4929, -0.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08532837778329849
Epoch 0, Step 230: train/loss = 0.6547459959983826, train/raw-loss = 0.6472448110580444, train/logprobs = tensor([[-0.5698, -0.8667],
        [-0.5548, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501186430454254
Epoch 0, Step 231: train/loss = 0.6199992299079895, train/raw-loss = 0.612408459186554, train/logprobs = tensor([[-0.5496, -1.5279],
        [-0.5326, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07590756565332413
Epoch 0, Step 232: train/loss = 0.48115479946136475, train/raw-loss = 0.4718838334083557, train/logprobs = tensor([[-0.7731, -2.3977],
        [-0.8143, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09270993620157242
Epoch 0, Step 233: train/loss = 0.6105043888092041, train/raw-loss = 0.6043033599853516, train/logprobs = tensor([[-0.5914, -0.9092],
        [-0.5801, -0.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06201095134019852
Epoch 0, Step 234: train/loss = 0.5426837205886841, train/raw-loss = 0.5349576473236084, train/logprobs = tensor([[-0.7539, -1.3466],
        [-0.8158, -0.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07726085931062698
Epoch 0, Step 235: train/loss = 0.6705473065376282, train/raw-loss = 0.6637474298477173, train/logprobs = tensor([[-0.6760, -0.6540],
        [-0.6030, -0.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.067998506128788
Epoch 0, Step 236: train/loss = 0.6597504615783691, train/raw-loss = 0.6498993635177612, train/logprobs = tensor([[-0.7704, -1.0930],
        [-0.7325, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09851080179214478
Epoch 0, Step 237: train/loss = 0.5791134238243103, train/raw-loss = 0.5725342631340027, train/logprobs = tensor([[-0.7473, -1.7300],
        [-0.7066, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06579189002513885
Epoch 0, Step 238: train/loss = 0.6249870657920837, train/raw-loss = 0.6188039183616638, train/logprobs = tensor([[-0.6599, -1.2957],
        [-0.5016, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06183115392923355
Epoch 0, Step 239: train/loss = 0.5582393407821655, train/raw-loss = 0.5516489744186401, train/logprobs = tensor([[-0.4936, -1.3488],
        [-0.5030, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06590350717306137
Epoch 0, Step 240: train/loss = 0.6884768009185791, train/raw-loss = 0.6816320419311523, train/logprobs = tensor([[-0.4542, -0.5627],
        [-0.4563, -0.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0684470608830452
Epoch 0, Step 241: train/loss = 0.6137607097625732, train/raw-loss = 0.6060292720794678, train/logprobs = tensor([[-0.6543, -1.0848],
        [-0.6067, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773143470287323
Epoch 0, Step 242: train/loss = 0.657724142074585, train/raw-loss = 0.6501344442367554, train/logprobs = tensor([[-0.6326, -0.6977],
        [-0.7201, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758967399597168
Epoch 0, Step 243: train/loss = 0.6839492321014404, train/raw-loss = 0.6762324571609497, train/logprobs = tensor([[-0.5600, -1.0354],
        [-0.5364, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07716745883226395
Epoch 0, Step 244: train/loss = 0.6668411493301392, train/raw-loss = 0.6608411073684692, train/logprobs = tensor([[-0.4565, -0.7049],
        [-0.4079, -0.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06000027805566788
Epoch 0, Step 245: train/loss = 0.6055257320404053, train/raw-loss = 0.5971174240112305, train/logprobs = tensor([[-0.6951, -1.4863],
        [-0.5781, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08408334851264954
Epoch 0, Step 246: train/loss = 0.6612675786018372, train/raw-loss = 0.6535816192626953, train/logprobs = tensor([[-0.6567, -0.8559],
        [-0.6730, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07685981690883636
Epoch 0, Step 247: train/loss = 0.5916855931282043, train/raw-loss = 0.5843526124954224, train/logprobs = tensor([[-0.6804, -1.2153],
        [-0.6697, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07332967221736908
Epoch 0, Step 248: train/loss = 0.6869639754295349, train/raw-loss = 0.680012583732605, train/logprobs = tensor([[-0.5775, -0.7800],
        [-0.4818, -0.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06951430439949036
Epoch 0, Step 249: train/loss = 0.6228926777839661, train/raw-loss = 0.6168068647384644, train/logprobs = tensor([[-0.5834, -0.9231],
        [-0.5550, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06085830181837082
Epoch 0, Step 250: train/loss = 0.7241804599761963, train/raw-loss = 0.7151176929473877, train/logprobs = tensor([[-0.7463, -0.6806],
        [-0.5501, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906280130147934
Epoch 0, Step 251: train/loss = 0.6262170076370239, train/raw-loss = 0.616271436214447, train/logprobs = tensor([[-0.7991, -1.0316],
        [-0.8055, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09945572912693024
Epoch 0, Step 252: train/loss = 0.5968571305274963, train/raw-loss = 0.5882385969161987, train/logprobs = tensor([[-0.6701, -2.3035],
        [-0.6115, -1.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861852616071701
Epoch 0, Step 253: train/loss = 0.7059884667396545, train/raw-loss = 0.6986833810806274, train/logprobs = tensor([[-0.6296, -0.6679],
        [-0.4885, -0.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0730518251657486
Epoch 0, Step 254: train/loss = 0.6778584122657776, train/raw-loss = 0.6699346303939819, train/logprobs = tensor([[-0.5561, -1.0495],
        [-0.5918, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07923810184001923
Epoch 0, Step 255: train/loss = 0.550107479095459, train/raw-loss = 0.5430405139923096, train/logprobs = tensor([[-0.5920, -1.5344],
        [-0.5821, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706692636013031
Epoch 0, Step 256: train/loss = 0.6607978940010071, train/raw-loss = 0.6515566110610962, train/logprobs = tensor([[-1.0289, -1.5315],
        [-0.7635, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09241308271884918
Epoch 0, Step 257: train/loss = 0.5731518268585205, train/raw-loss = 0.5647355318069458, train/logprobs = tensor([[-0.7420, -1.6363],
        [-0.5903, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08416347950696945
Epoch 0, Step 258: train/loss = 0.6225438117980957, train/raw-loss = 0.6127164363861084, train/logprobs = tensor([[-0.6562, -1.0943],
        [-0.6587, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827421605587006
Epoch 0, Step 259: train/loss = 0.5295922756195068, train/raw-loss = 0.5206454992294312, train/logprobs = tensor([[-0.6574, -2.4623],
        [-0.8264, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08946792781352997
Epoch 0, Step 260: train/loss = 0.6187090277671814, train/raw-loss = 0.6112676858901978, train/logprobs = tensor([[-0.4521, -0.8750],
        [-0.4659, -0.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441360503435135
Epoch 0, Step 261: train/loss = 0.5786111354827881, train/raw-loss = 0.5710034370422363, train/logprobs = tensor([[-0.5541, -1.1282],
        [-0.6294, -0.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07607737183570862
Epoch 0, Step 262: train/loss = 0.5944214463233948, train/raw-loss = 0.5849685668945312, train/logprobs = tensor([[-0.7230, -0.9702],
        [-0.8844, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09452876448631287
Epoch 0, Step 263: train/loss = 0.6151406764984131, train/raw-loss = 0.605182945728302, train/logprobs = tensor([[-0.5873, -1.1930],
        [-0.6104, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957699477672577
Epoch 0, Step 264: train/loss = 0.5520387291908264, train/raw-loss = 0.5432096719741821, train/logprobs = tensor([[-0.6016, -1.5513],
        [-0.6309, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882904976606369
Epoch 0, Step 265: train/loss = 0.6268602609634399, train/raw-loss = 0.6178639531135559, train/logprobs = tensor([[-0.5976, -1.1671],
        [-0.6125, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08996336907148361
Epoch 0, Step 266: train/loss = 0.5809438228607178, train/raw-loss = 0.5732938051223755, train/logprobs = tensor([[-0.5945, -1.7902],
        [-0.6233, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07650038599967957
Epoch 0, Step 267: train/loss = 0.6716009378433228, train/raw-loss = 0.6626476049423218, train/logprobs = tensor([[-0.6828, -0.8374],
        [-0.6933, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953361213207245
Epoch 0, Step 268: train/loss = 0.6054007411003113, train/raw-loss = 0.5985649228096008, train/logprobs = tensor([[-0.4775, -1.0115],
        [-0.4712, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06835874915122986
Epoch 0, Step 269: train/loss = 0.671038031578064, train/raw-loss = 0.6622592210769653, train/logprobs = tensor([[-0.5592, -0.7179],
        [-0.5241, -0.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08778882026672363
Epoch 0, Step 270: train/loss = 0.6192834973335266, train/raw-loss = 0.61170893907547, train/logprobs = tensor([[-0.4977, -0.8504],
        [-0.4919, -0.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07574581354856491
Epoch 0, Step 271: train/loss = 0.6400646567344666, train/raw-loss = 0.6328503489494324, train/logprobs = tensor([[-0.4483, -1.1445],
        [-0.4535, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07214238494634628
Epoch 0, Step 272: train/loss = 0.6789703369140625, train/raw-loss = 0.6687215566635132, train/logprobs = tensor([[-0.6728, -1.2636],
        [-0.6911, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10248778760433197
Epoch 0, Step 273: train/loss = 0.598537027835846, train/raw-loss = 0.5897098183631897, train/logprobs = tensor([[-0.7663, -1.0427],
        [-0.8034, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08827187120914459
Epoch 0, Step 274: train/loss = 0.7018362283706665, train/raw-loss = 0.6932119727134705, train/logprobs = tensor([[-0.5807, -0.9041],
        [-0.5754, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0862426906824112
Epoch 0, Step 275: train/loss = 0.5450385808944702, train/raw-loss = 0.5382011532783508, train/logprobs = tensor([[-0.5460, -1.7387],
        [-0.5627, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683746188879013
Epoch 0, Step 276: train/loss = 0.5732671618461609, train/raw-loss = 0.5644566416740417, train/logprobs = tensor([[-0.6091, -1.8171],
        [-0.6206, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881054475903511
Epoch 0, Step 277: train/loss = 0.6433046460151672, train/raw-loss = 0.6346900463104248, train/logprobs = tensor([[-0.6050, -1.0781],
        [-0.5652, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08614566177129745
Epoch 0, Step 278: train/loss = 0.5680819749832153, train/raw-loss = 0.5603484511375427, train/logprobs = tensor([[-0.6768, -1.2220],
        [-0.6657, -0.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07733538746833801
Epoch 0, Step 279: train/loss = 0.5459759831428528, train/raw-loss = 0.5365121364593506, train/logprobs = tensor([[-0.7765, -2.6990],
        [-0.7579, -1.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09463843703269958
Epoch 0, Step 280: train/loss = 0.5948581099510193, train/raw-loss = 0.5877331495285034, train/logprobs = tensor([[-0.6260, -0.9040],
        [-0.6779, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07124951481819153
Epoch 0, Step 281: train/loss = 0.4864138662815094, train/raw-loss = 0.47867974638938904, train/logprobs = tensor([[-0.5182, -2.9528],
        [-0.4939, -1.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734113186597824
Epoch 0, Step 282: train/loss = 0.6002568602561951, train/raw-loss = 0.5908276438713074, train/logprobs = tensor([[-0.8351, -1.5660],
        [-0.9024, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09429177641868591
Epoch 0, Step 283: train/loss = 0.6891754865646362, train/raw-loss = 0.679579496383667, train/logprobs = tensor([[-0.7166, -0.5938],
        [-0.6259, -0.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09595991671085358
Epoch 0, Step 284: train/loss = 0.637554943561554, train/raw-loss = 0.6281725168228149, train/logprobs = tensor([[-0.6901, -1.1189],
        [-0.5889, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382381290197372
Epoch 0, Step 285: train/loss = 0.6798242926597595, train/raw-loss = 0.6701115965843201, train/logprobs = tensor([[-0.7380, -0.7947],
        [-0.7395, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09712732583284378
Epoch 0, Step 286: train/loss = 0.6240681409835815, train/raw-loss = 0.6172841787338257, train/logprobs = tensor([[-0.5603, -0.9977],
        [-0.5015, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06783957779407501
Epoch 0, Step 287: train/loss = 0.5948370695114136, train/raw-loss = 0.5882390737533569, train/logprobs = tensor([[-0.4733, -1.5296],
        [-0.5133, -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06598025560379028
Epoch 0, Step 288: train/loss = 0.6925227642059326, train/raw-loss = 0.6803894639015198, train/logprobs = tensor([[-0.6896, -1.0079],
        [-0.6411, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12133299559354782
Epoch 0, Step 289: train/loss = 0.5753169655799866, train/raw-loss = 0.5646700859069824, train/logprobs = tensor([[-0.6210, -1.4771],
        [-0.6461, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106469064950943
Epoch 0, Step 290: train/loss = 0.551790177822113, train/raw-loss = 0.5429062247276306, train/logprobs = tensor([[-0.5532, -1.4307],
        [-0.6501, -0.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08883960545063019
Epoch 0, Step 291: train/loss = 0.5527076125144958, train/raw-loss = 0.5431383848190308, train/logprobs = tensor([[-0.7197, -2.3459],
        [-0.6745, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09569181501865387
Epoch 0, Step 292: train/loss = 0.6544086933135986, train/raw-loss = 0.6442019939422607, train/logprobs = tensor([[-0.8621, -1.0238],
        [-0.6235, -0.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10206728428602219
Epoch 0, Step 293: train/loss = 0.5922367572784424, train/raw-loss = 0.5840960144996643, train/logprobs = tensor([[-0.5769, -1.3497],
        [-0.5638, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140774816274643
Epoch 0, Step 294: train/loss = 0.6041151881217957, train/raw-loss = 0.5940542221069336, train/logprobs = tensor([[-0.8254, -1.5503],
        [-0.6895, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060964524745941
Epoch 0, Step 295: train/loss = 0.538415789604187, train/raw-loss = 0.5297122001647949, train/logprobs = tensor([[-0.7202, -1.7009],
        [-0.6289, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703581243753433
Epoch 0, Step 296: train/loss = 0.6763468980789185, train/raw-loss = 0.6677555441856384, train/logprobs = tensor([[-0.7667, -0.6996],
        [-0.7722, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08591344207525253
Epoch 0, Step 297: train/loss = 0.6005702614784241, train/raw-loss = 0.5915842652320862, train/logprobs = tensor([[-0.7996, -1.3953],
        [-0.6607, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986025303602219
Epoch 0, Step 298: train/loss = 0.6655992269515991, train/raw-loss = 0.6544215083122253, train/logprobs = tensor([[-0.6985, -1.0873],
        [-0.6406, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1117764562368393
Epoch 0, Step 299: train/loss = 0.5162159204483032, train/raw-loss = 0.5070165395736694, train/logprobs = tensor([[-0.6541, -1.5916],
        [-0.7000, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09199376404285431
Epoch 0, Step 300: train/loss = 0.5317531228065491, train/raw-loss = 0.5221394300460815, train/logprobs = tensor([[-0.5890, -2.8924],
        [-0.5866, -1.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613688290119171
Epoch 0, Step 301: train/loss = 0.5470073819160461, train/raw-loss = 0.5335038304328918, train/logprobs = tensor([[-0.9600, -1.8469],
        [-1.0373, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13503554463386536
Epoch 0, Step 302: train/loss = 0.6775208711624146, train/raw-loss = 0.6685220003128052, train/logprobs = tensor([[-0.7398, -0.9242],
        [-0.6891, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08998899161815643
Epoch 0, Step 303: train/loss = 0.6681286692619324, train/raw-loss = 0.6562248468399048, train/logprobs = tensor([[-0.6585, -0.8473],
        [-0.6124, -0.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903853714466095
Epoch 0, Step 304: train/loss = 0.4883100390434265, train/raw-loss = 0.47932395339012146, train/logprobs = tensor([[-0.6328, -2.5567],
        [-0.6116, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986089378595352
Epoch 0, Step 305: train/loss = 0.6252585649490356, train/raw-loss = 0.6170061826705933, train/logprobs = tensor([[-0.4808, -1.1944],
        [-0.5063, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0825241282582283
Epoch 0, Step 306: train/loss = 0.625582754611969, train/raw-loss = 0.614433765411377, train/logprobs = tensor([[-0.6975, -1.1480],
        [-0.6395, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114896684885025
Epoch 0, Step 307: train/loss = 0.5891017913818359, train/raw-loss = 0.5788722038269043, train/logprobs = tensor([[-0.9146, -1.5942],
        [-0.8463, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229586064815521
Epoch 0, Step 308: train/loss = 0.6073269248008728, train/raw-loss = 0.5985523462295532, train/logprobs = tensor([[-0.5700, -1.1551],
        [-0.4981, -0.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08774574100971222
Epoch 0, Step 309: train/loss = 0.5935512781143188, train/raw-loss = 0.5837287902832031, train/logprobs = tensor([[-2.7718, -3.2658],
        [-2.5303, -2.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982242226600647
Epoch 0, Step 310: train/loss = 0.560090959072113, train/raw-loss = 0.5508136749267578, train/logprobs = tensor([[-0.5727, -1.9118],
        [-0.6045, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277287125587463
Epoch 0, Step 311: train/loss = 0.6784957647323608, train/raw-loss = 0.6694851517677307, train/logprobs = tensor([[-0.6338, -0.7844],
        [-0.6446, -0.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09010639041662216
Epoch 0, Step 312: train/loss = 0.5744976997375488, train/raw-loss = 0.5640462040901184, train/logprobs = tensor([[-0.6775, -2.2552],
        [-0.6691, -1.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10451477020978928
Epoch 0, Step 313: train/loss = 0.6633031368255615, train/raw-loss = 0.6524207592010498, train/logprobs = tensor([[-1.1966, -2.0707],
        [-0.9447, -1.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882353782653809
Epoch 0, Step 314: train/loss = 0.6441927552223206, train/raw-loss = 0.6337243318557739, train/logprobs = tensor([[-0.6363, -0.9337],
        [-0.7012, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468438267707825
Epoch 0, Step 315: train/loss = 0.6773480772972107, train/raw-loss = 0.6677169799804688, train/logprobs = tensor([[-0.6106, -0.7774],
        [-0.6295, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09631116688251495
Epoch 0, Step 316: train/loss = 0.6123793125152588, train/raw-loss = 0.6015923023223877, train/logprobs = tensor([[-0.7533, -1.1637],
        [-0.6488, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787025094032288
Epoch 0, Step 317: train/loss = 0.5770629644393921, train/raw-loss = 0.5663332343101501, train/logprobs = tensor([[-0.6188, -1.2122],
        [-0.6360, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10729741305112839
Epoch 0, Step 318: train/loss = 0.5968466997146606, train/raw-loss = 0.5880608558654785, train/logprobs = tensor([[-0.5840, -0.9531],
        [-0.6054, -0.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08785828948020935
Epoch 0, Step 319: train/loss = 0.58940589427948, train/raw-loss = 0.5804556608200073, train/logprobs = tensor([[-0.5527, -1.4819],
        [-0.5321, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950210362672806
Epoch 0, Step 320: train/loss = 0.5324761271476746, train/raw-loss = 0.5228498578071594, train/logprobs = tensor([[-0.6519, -2.5474],
        [-0.5816, -0.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09626275300979614
Epoch 0, Step 321: train/loss = 0.6850172281265259, train/raw-loss = 0.6733610033988953, train/logprobs = tensor([[-1.3111, -1.5232],
        [-0.9614, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11656207591295242
Epoch 0, Step 322: train/loss = 0.6056525707244873, train/raw-loss = 0.5954165458679199, train/logprobs = tensor([[-0.7846, -1.3615],
        [-0.7929, -0.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236074775457382
Epoch 0, Step 323: train/loss = 0.6572665572166443, train/raw-loss = 0.6458448171615601, train/logprobs = tensor([[-1.1900, -1.6289],
        [-1.1144, -1.3435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421720683574677
Epoch 0, Step 324: train/loss = 0.6636408567428589, train/raw-loss = 0.6537017822265625, train/logprobs = tensor([[-0.5866, -0.6996],
        [-0.5709, -0.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939038753509521
Epoch 0, Step 325: train/loss = 0.6983224153518677, train/raw-loss = 0.6856891512870789, train/logprobs = tensor([[-0.7780, -1.6481],
        [-0.7860, -1.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126332089304924
Epoch 0, Step 326: train/loss = 0.59903484582901, train/raw-loss = 0.5877974629402161, train/logprobs = tensor([[-0.8429, -1.1599],
        [-0.7542, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11237332224845886
Epoch 0, Step 327: train/loss = 0.5613669157028198, train/raw-loss = 0.5508812069892883, train/logprobs = tensor([[-0.7342, -1.3811],
        [-0.7375, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10485702753067017
Epoch 0, Step 328: train/loss = 0.513576865196228, train/raw-loss = 0.5040078163146973, train/logprobs = tensor([[-0.5705, -1.9671],
        [-0.6084, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09569008648395538
Epoch 0, Step 329: train/loss = 0.6183947920799255, train/raw-loss = 0.6062361001968384, train/logprobs = tensor([[-0.7927, -1.5796],
        [-0.6890, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158702313899994
Epoch 0, Step 330: train/loss = 0.5172497630119324, train/raw-loss = 0.5077764391899109, train/logprobs = tensor([[-0.6529, -1.6570],
        [-0.6821, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473293274641037
Epoch 0, Step 331: train/loss = 0.5657799243927002, train/raw-loss = 0.5562927722930908, train/logprobs = tensor([[-0.5519, -2.0924],
        [-0.5986, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09487150609493256
Epoch 0, Step 332: train/loss = 0.6839513182640076, train/raw-loss = 0.6763519048690796, train/logprobs = tensor([[-0.4905, -0.5775],
        [-0.4334, -0.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07599429786205292
Epoch 0, Step 333: train/loss = 0.5515486001968384, train/raw-loss = 0.5413382649421692, train/logprobs = tensor([[-0.7225, -2.8941],
        [-0.7560, -1.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10210375487804413
Epoch 0, Step 334: train/loss = 0.6133915185928345, train/raw-loss = 0.6037724018096924, train/logprobs = tensor([[-0.6110, -1.6047],
        [-0.5429, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09619119763374329
Epoch 0, Step 335: train/loss = 0.5963077545166016, train/raw-loss = 0.5856853723526001, train/logprobs = tensor([[-0.7390, -1.1658],
        [-0.8115, -0.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622377693653107
Epoch 0, Step 336: train/loss = 0.5198104381561279, train/raw-loss = 0.5090095400810242, train/logprobs = tensor([[-0.6318, -1.7629],
        [-0.6854, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10800890624523163
Epoch 0, Step 337: train/loss = 0.5109215974807739, train/raw-loss = 0.5015151500701904, train/logprobs = tensor([[-0.6094, -1.5957],
        [-0.6172, -0.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940655767917633
Epoch 0, Step 338: train/loss = 0.6062273979187012, train/raw-loss = 0.5974969863891602, train/logprobs = tensor([[-0.4980, -1.3327],
        [-0.5516, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08730390667915344
Epoch 0, Step 339: train/loss = 0.6993433237075806, train/raw-loss = 0.6901722550392151, train/logprobs = tensor([[-0.6038, -0.6254],
        [-0.5055, -0.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09171035885810852
Epoch 0, Step 340: train/loss = 0.6699743866920471, train/raw-loss = 0.6589864492416382, train/logprobs = tensor([[-0.7650, -0.8712],
        [-0.5948, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10987896472215652
Epoch 0, Step 341: train/loss = 0.6318017840385437, train/raw-loss = 0.6215066909790039, train/logprobs = tensor([[-0.8548, -0.9407],
        [-0.7887, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295151174068451
Epoch 0, Step 342: train/loss = 0.6201397180557251, train/raw-loss = 0.6123150587081909, train/logprobs = tensor([[-0.5063, -1.0576],
        [-0.5342, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824662327766418
Epoch 0, Step 343: train/loss = 0.5881711840629578, train/raw-loss = 0.5786404609680176, train/logprobs = tensor([[-0.7507, -1.0846],
        [-0.6929, -0.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530721604824066
Epoch 0, Step 344: train/loss = 0.6075922846794128, train/raw-loss = 0.5967329144477844, train/logprobs = tensor([[-0.6347, -1.2421],
        [-0.6570, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10859361290931702
Epoch 0, Step 345: train/loss = 0.7147222757339478, train/raw-loss = 0.7035253047943115, train/logprobs = tensor([[-0.5917, -0.7127],
        [-0.5098, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11196910589933395
Epoch 0, Step 346: train/loss = 0.40382179617881775, train/raw-loss = 0.39305925369262695, train/logprobs = tensor([[-0.7318, -2.9379],
        [-0.8175, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762552917003632
Epoch 0, Step 347: train/loss = 0.5347722768783569, train/raw-loss = 0.5251852869987488, train/logprobs = tensor([[-0.6854, -2.3235],
        [-0.6720, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09586936235427856
Epoch 0, Step 348: train/loss = 0.5756382942199707, train/raw-loss = 0.5643248558044434, train/logprobs = tensor([[-0.8228, -2.2979],
        [-0.8025, -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1131351888179779
Epoch 0, Step 349: train/loss = 0.6434090733528137, train/raw-loss = 0.6313486099243164, train/logprobs = tensor([[-0.8682, -0.9956],
        [-0.9991, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060458213090897
Epoch 0, Step 350: train/loss = 0.670599102973938, train/raw-loss = 0.6599281430244446, train/logprobs = tensor([[-0.4835, -0.8925],
        [-0.4889, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670914500951767
Epoch 0, Step 351: train/loss = 0.5612643957138062, train/raw-loss = 0.5522000789642334, train/logprobs = tensor([[-0.7516, -1.4186],
        [-0.7334, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09064343571662903
Epoch 0, Step 352: train/loss = 0.6822065114974976, train/raw-loss = 0.6704132556915283, train/logprobs = tensor([[-1.0912, -1.5194],
        [-0.8104, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793246120214462
Epoch 0, Step 353: train/loss = 0.5013118982315063, train/raw-loss = 0.4914425015449524, train/logprobs = tensor([[-0.5131, -2.1544],
        [-0.5855, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09869429469108582
Epoch 0, Step 354: train/loss = 0.5715219974517822, train/raw-loss = 0.558620810508728, train/logprobs = tensor([[-0.7334, -2.3089],
        [-0.7258, -1.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901195883750916
Epoch 0, Step 355: train/loss = 0.6175113916397095, train/raw-loss = 0.6049992442131042, train/logprobs = tensor([[-0.6299, -1.3699],
        [-0.5767, -0.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12512138485908508
Epoch 0, Step 356: train/loss = 0.6311585307121277, train/raw-loss = 0.6202926635742188, train/logprobs = tensor([[-0.5639, -0.9328],
        [-0.5680, -0.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10865886509418488
Epoch 0, Step 357: train/loss = 0.5055874586105347, train/raw-loss = 0.49201497435569763, train/logprobs = tensor([[-0.9465, -2.8872],
        [-0.9361, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13572487235069275
Epoch 0, Step 358: train/loss = 0.6167907118797302, train/raw-loss = 0.6056903600692749, train/logprobs = tensor([[-0.5104, -1.0972],
        [-0.5236, -0.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11100390553474426
Epoch 0, Step 359: train/loss = 0.6108757257461548, train/raw-loss = 0.5996995568275452, train/logprobs = tensor([[-0.5029, -0.7918],
        [-0.6079, -0.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176140606403351
Epoch 0, Step 360: train/loss = 0.5504907965660095, train/raw-loss = 0.539655327796936, train/logprobs = tensor([[-0.7030, -1.7499],
        [-0.6424, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10835511237382889
Epoch 0, Step 361: train/loss = 0.6142463088035583, train/raw-loss = 0.6035612225532532, train/logprobs = tensor([[-0.6537, -0.9566],
        [-0.6834, -0.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10685086250305176
Epoch 0, Step 362: train/loss = 0.5890730023384094, train/raw-loss = 0.5764867067337036, train/logprobs = tensor([[-0.6150, -1.6206],
        [-0.5930, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12586291134357452
Epoch 0, Step 363: train/loss = 0.48663556575775146, train/raw-loss = 0.4743024408817291, train/logprobs = tensor([[-0.6823, -3.5535],
        [-0.6512, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12333142757415771
Epoch 0, Step 364: train/loss = 0.6286896467208862, train/raw-loss = 0.6147946119308472, train/logprobs = tensor([[-0.7331, -1.3088],
        [-0.6284, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13895079493522644
Epoch 0, Step 365: train/loss = 0.6669526100158691, train/raw-loss = 0.6545025110244751, train/logprobs = tensor([[-0.5894, -0.8272],
        [-0.5980, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450121343135834
Epoch 0, Step 366: train/loss = 0.6851226687431335, train/raw-loss = 0.6741736531257629, train/logprobs = tensor([[-0.5330, -1.0654],
        [-0.5119, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094902828335762
Epoch 0, Step 367: train/loss = 0.6211687326431274, train/raw-loss = 0.6110397577285767, train/logprobs = tensor([[-0.5328, -1.0001],
        [-0.5573, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012900322675705
Epoch 0, Step 368: train/loss = 0.6302887797355652, train/raw-loss = 0.6192679405212402, train/logprobs = tensor([[-0.5800, -0.8725],
        [-0.5727, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102081909775734
Epoch 0, Step 369: train/loss = 0.5204043388366699, train/raw-loss = 0.5082753896713257, train/logprobs = tensor([[-0.7817, -1.8371],
        [-0.8127, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128995358943939
Epoch 0, Step 370: train/loss = 0.579899251461029, train/raw-loss = 0.5699169039726257, train/logprobs = tensor([[-0.7311, -0.9723],
        [-0.8486, -0.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09982383996248245
Epoch 0, Step 371: train/loss = 0.6006121635437012, train/raw-loss = 0.5896083116531372, train/logprobs = tensor([[-0.9826, -1.8437],
        [-0.7494, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003856360912323
Epoch 0, Step 372: train/loss = 0.6298700571060181, train/raw-loss = 0.6186379790306091, train/logprobs = tensor([[-0.6327, -2.3563],
        [-0.6097, -2.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232060939073563
Epoch 0, Step 373: train/loss = 0.5941249132156372, train/raw-loss = 0.5850399136543274, train/logprobs = tensor([[-0.5056, -1.0988],
        [-0.4381, -0.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09085032343864441
Epoch 0, Step 374: train/loss = 0.57444828748703, train/raw-loss = 0.5654723048210144, train/logprobs = tensor([[-0.5177, -0.9289],
        [-0.6082, -0.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08976029604673386
Epoch 0, Step 375: train/loss = 0.6701632738113403, train/raw-loss = 0.6581588983535767, train/logprobs = tensor([[-0.7257, -0.8187],
        [-0.7220, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004455924034119
Epoch 0, Step 376: train/loss = 0.5742368102073669, train/raw-loss = 0.5600370168685913, train/logprobs = tensor([[-1.0117, -2.2100],
        [-0.9565, -1.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419975757598877
Epoch 0, Step 377: train/loss = 0.5876843333244324, train/raw-loss = 0.5779144763946533, train/logprobs = tensor([[-0.6198, -1.1844],
        [-0.6374, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09769858419895172
Epoch 0, Step 378: train/loss = 0.553545355796814, train/raw-loss = 0.5445179343223572, train/logprobs = tensor([[-0.6875, -2.0169],
        [-0.6363, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902736708521843
Epoch 0, Step 379: train/loss = 0.7071457505226135, train/raw-loss = 0.6952776908874512, train/logprobs = tensor([[-0.6976, -0.7234],
        [-0.5805, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11868059635162354
Epoch 0, Step 380: train/loss = 0.5756755471229553, train/raw-loss = 0.5655480027198792, train/logprobs = tensor([[-0.5579, -1.1491],
        [-0.5916, -0.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10127514600753784
Epoch 0, Step 381: train/loss = 0.7027779817581177, train/raw-loss = 0.6897826790809631, train/logprobs = tensor([[-0.8863, -1.2036],
        [-0.7471, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12995263934135437
Epoch 0, Step 382: train/loss = 0.6620562076568604, train/raw-loss = 0.6509064435958862, train/logprobs = tensor([[-0.9188, -1.0904],
        [-0.8769, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149761080741882
Epoch 0, Step 383: train/loss = 0.5893620848655701, train/raw-loss = 0.574520468711853, train/logprobs = tensor([[-1.0421, -1.5155],
        [-1.0136, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14841577410697937
Epoch 0, Step 384: train/loss = 0.6640232801437378, train/raw-loss = 0.6506904363632202, train/logprobs = tensor([[-0.6057, -0.7791],
        [-0.5105, -0.4894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333286464214325
Epoch 0, Step 385: train/loss = 0.5261397957801819, train/raw-loss = 0.5108950138092041, train/logprobs = tensor([[-0.7690, -1.8833],
        [-0.8336, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1524476706981659
Epoch 0, Step 386: train/loss = 0.5758429765701294, train/raw-loss = 0.5611975789070129, train/logprobs = tensor([[-0.9467, -2.2455],
        [-0.9532, -1.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464535892009735
Epoch 0, Step 387: train/loss = 0.7106173038482666, train/raw-loss = 0.6957384347915649, train/logprobs = tensor([[-1.1389, -1.6307],
        [-0.7857, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14878825843334198
Epoch 0, Step 388: train/loss = 0.6115841269493103, train/raw-loss = 0.5994990468025208, train/logprobs = tensor([[-0.7421, -1.4664],
        [-0.6938, -0.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085101753473282
Epoch 0, Step 389: train/loss = 0.6652557849884033, train/raw-loss = 0.6538363099098206, train/logprobs = tensor([[-0.5930, -0.8072],
        [-0.5625, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11419461667537689
Epoch 0, Step 390: train/loss = 0.6897611618041992, train/raw-loss = 0.6759437322616577, train/logprobs = tensor([[-0.6857, -0.8056],
        [-0.6501, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13817471265792847
Epoch 0, Step 391: train/loss = 0.6009577512741089, train/raw-loss = 0.5880974531173706, train/logprobs = tensor([[-1.5279, -2.7851],
        [-1.0114, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286028027534485
Epoch 0, Step 392: train/loss = 0.5318354368209839, train/raw-loss = 0.5187260508537292, train/logprobs = tensor([[-0.6519, -1.8937],
        [-0.6503, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13109378516674042
Epoch 0, Step 393: train/loss = 0.6889575719833374, train/raw-loss = 0.6745584011077881, train/logprobs = tensor([[-0.9019, -0.9415],
        [-0.9403, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14399144053459167
Epoch 0, Step 394: train/loss = 0.5378125905990601, train/raw-loss = 0.5239965915679932, train/logprobs = tensor([[-0.6879, -2.5058],
        [-0.7414, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13816045224666595
Epoch 0, Step 395: train/loss = 0.5848977565765381, train/raw-loss = 0.5729713439941406, train/logprobs = tensor([[-0.7364, -1.8565],
        [-0.6289, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11926372349262238
Epoch 0, Step 396: train/loss = 0.699118435382843, train/raw-loss = 0.6852158904075623, train/logprobs = tensor([[-0.6140, -0.7314],
        [-0.6171, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390250325202942
Epoch 0, Step 397: train/loss = 0.6143540740013123, train/raw-loss = 0.6004947423934937, train/logprobs = tensor([[-0.7179, -1.7312],
        [-0.6724, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385933756828308
Epoch 0, Step 398: train/loss = 0.6069818735122681, train/raw-loss = 0.5928803086280823, train/logprobs = tensor([[-1.4860, -2.1234],
        [-1.0944, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14101555943489075
Epoch 0, Step 399: train/loss = 0.5862090587615967, train/raw-loss = 0.573823869228363, train/logprobs = tensor([[-0.5253, -1.4896],
        [-0.5939, -0.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238524317741394
Epoch 0, Step 400: train/loss = 0.512355387210846, train/raw-loss = 0.499442994594574, train/logprobs = tensor([[-0.6883, -1.6972],
        [-0.8465, -0.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12912428379058838
Epoch 0, Step 401: train/loss = 0.6184004545211792, train/raw-loss = 0.6051982641220093, train/logprobs = tensor([[-0.6767, -1.7392],
        [-0.5728, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13202184438705444
Epoch 0, Step 402: train/loss = 0.5509384274482727, train/raw-loss = 0.5360360145568848, train/logprobs = tensor([[-0.6988, -1.4183],
        [-0.7715, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14902345836162567
Epoch 0, Step 403: train/loss = 0.6579015851020813, train/raw-loss = 0.6467306613922119, train/logprobs = tensor([[-0.5252, -0.7263],
        [-0.5441, -0.5472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170952767133713
Epoch 0, Step 404: train/loss = 0.4820173978805542, train/raw-loss = 0.467798113822937, train/logprobs = tensor([[-0.9038, -1.9352],
        [-1.0336, -0.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14219290018081665
Epoch 0, Step 405: train/loss = 0.5988764762878418, train/raw-loss = 0.5866397619247437, train/logprobs = tensor([[-0.5950, -1.3376],
        [-0.6067, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12236719578504562
Epoch 0, Step 406: train/loss = 0.5479007363319397, train/raw-loss = 0.5326634049415588, train/logprobs = tensor([[-0.7841, -1.7185],
        [-0.8412, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1523733139038086
Epoch 0, Step 407: train/loss = 0.6776466369628906, train/raw-loss = 0.6629442572593689, train/logprobs = tensor([[-0.6796, -1.4121],
        [-0.6384, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14702372252941132
Epoch 0, Step 408: train/loss = 0.5928307771682739, train/raw-loss = 0.5809118747711182, train/logprobs = tensor([[-0.6939, -1.3990],
        [-0.7416, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191888302564621
Epoch 0, Step 409: train/loss = 0.5280216932296753, train/raw-loss = 0.5150994062423706, train/logprobs = tensor([[-0.6825, -2.6158],
        [-0.7236, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12922266125679016
Epoch 0, Step 410: train/loss = 0.5990201830863953, train/raw-loss = 0.5855448842048645, train/logprobs = tensor([[-0.7473, -1.8149],
        [-0.5923, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13475307822227478
Epoch 0, Step 411: train/loss = 0.5692941546440125, train/raw-loss = 0.5575862526893616, train/logprobs = tensor([[-0.5118, -1.4821],
        [-0.4874, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707936227321625
Epoch 0, Step 412: train/loss = 0.57724928855896, train/raw-loss = 0.5626420378684998, train/logprobs = tensor([[-0.8976, -1.7368],
        [-0.7553, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14607210457324982
Epoch 0, Step 413: train/loss = 0.5527591705322266, train/raw-loss = 0.5397620797157288, train/logprobs = tensor([[-0.6448, -1.9062],
        [-0.6443, -1.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299711912870407
Epoch 0, Step 414: train/loss = 0.570575475692749, train/raw-loss = 0.557222843170166, train/logprobs = tensor([[-0.8197, -1.4742],
        [-0.7439, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335262805223465
Epoch 0, Step 415: train/loss = 0.6010997295379639, train/raw-loss = 0.5838083028793335, train/logprobs = tensor([[-1.1542, -2.4034],
        [-0.9666, -1.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17291410267353058
Epoch 0, Step 416: train/loss = 0.5136051177978516, train/raw-loss = 0.498780757188797, train/logprobs = tensor([[-0.6659, -1.8413],
        [-0.6639, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1482439935207367
Epoch 0, Step 417: train/loss = 0.6475858688354492, train/raw-loss = 0.6364460587501526, train/logprobs = tensor([[-0.4362, -1.1417],
        [-0.4553, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139815300703049
Epoch 0, Step 418: train/loss = 0.6100428700447083, train/raw-loss = 0.5983160138130188, train/logprobs = tensor([[-0.6038, -1.5870],
        [-0.5017, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11726872622966766
Epoch 0, Step 419: train/loss = 0.5757108926773071, train/raw-loss = 0.5635141730308533, train/logprobs = tensor([[-0.5780, -1.4215],
        [-0.6033, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12196700274944305
Epoch 0, Step 420: train/loss = 0.7080572843551636, train/raw-loss = 0.6962326765060425, train/logprobs = tensor([[-0.7782, -0.7891],
        [-0.4783, -0.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182466447353363
Epoch 0, Step 421: train/loss = 0.6078567504882812, train/raw-loss = 0.5923997163772583, train/logprobs = tensor([[-0.8252, -1.8010],
        [-0.6952, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15457013249397278
Epoch 0, Step 422: train/loss = 0.64082932472229, train/raw-loss = 0.6303840279579163, train/logprobs = tensor([[-0.6518, -1.0762],
        [-0.5896, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044532060623169
Epoch 0, Step 423: train/loss = 0.6755629181861877, train/raw-loss = 0.6587796211242676, train/logprobs = tensor([[-0.9674, -1.8760],
        [-0.8722, -1.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16783319413661957
Epoch 0, Step 424: train/loss = 0.6229807734489441, train/raw-loss = 0.609506368637085, train/logprobs = tensor([[-0.6646, -1.3969],
        [-0.5990, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13474391400814056
Epoch 0, Step 425: train/loss = 0.5987820625305176, train/raw-loss = 0.585817277431488, train/logprobs = tensor([[-0.5327, -2.0563],
        [-0.5462, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12964734435081482
Epoch 0, Step 426: train/loss = 0.5252140164375305, train/raw-loss = 0.5117079019546509, train/logprobs = tensor([[-0.6982, -2.0040],
        [-0.7482, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13506129384040833
Epoch 0, Step 427: train/loss = 0.41492342948913574, train/raw-loss = 0.40114104747772217, train/logprobs = tensor([[-0.7968, -4.1127],
        [-0.9614, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378239393234253
Epoch 0, Step 428: train/loss = 0.36968663334846497, train/raw-loss = 0.35326290130615234, train/logprobs = tensor([[-1.3937, -5.5284],
        [-1.2199, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1642378270626068
Epoch 0, Step 429: train/loss = 0.48234203457832336, train/raw-loss = 0.4677790403366089, train/logprobs = tensor([[-0.9689, -2.9311],
        [-1.0577, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456296443939209
Epoch 0, Step 430: train/loss = 0.6545977592468262, train/raw-loss = 0.6411271095275879, train/logprobs = tensor([[-0.7332, -1.2929],
        [-0.6213, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347065418958664
Epoch 0, Step 431: train/loss = 0.545850396156311, train/raw-loss = 0.5321890115737915, train/logprobs = tensor([[-0.6992, -1.4705],
        [-0.6493, -0.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13661420345306396
Epoch 0, Step 432: train/loss = 0.5670945644378662, train/raw-loss = 0.55409836769104, train/logprobs = tensor([[-0.7418, -1.4941],
        [-0.6891, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299615204334259
Epoch 0, Step 433: train/loss = 0.5120564699172974, train/raw-loss = 0.49623286724090576, train/logprobs = tensor([[-0.9592, -2.5850],
        [-0.9729, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582363098859787
Epoch 0, Step 434: train/loss = 0.5824977159500122, train/raw-loss = 0.5661736726760864, train/logprobs = tensor([[-0.9249, -1.9800],
        [-0.6001, -0.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16324028372764587
Epoch 0, Step 435: train/loss = 0.5077225565910339, train/raw-loss = 0.4922769367694855, train/logprobs = tensor([[-1.0166, -2.2332],
        [-0.8153, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15445633232593536
Epoch 0, Step 436: train/loss = 0.7028688192367554, train/raw-loss = 0.6888236999511719, train/logprobs = tensor([[-1.1402, -1.2129],
        [-0.9996, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1404520869255066
Epoch 0, Step 437: train/loss = 0.5186334252357483, train/raw-loss = 0.5050053000450134, train/logprobs = tensor([[-0.6681, -1.8055],
        [-0.7212, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13628092408180237
Epoch 0, Step 438: train/loss = 0.6505815386772156, train/raw-loss = 0.6337100267410278, train/logprobs = tensor([[-1.4622, -1.6253],
        [-1.3218, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1687159240245819
Epoch 0, Step 439: train/loss = 0.5838598012924194, train/raw-loss = 0.5686590671539307, train/logprobs = tensor([[-0.7665, -1.1421],
        [-0.8904, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15200749039649963
Epoch 0, Step 440: train/loss = 0.5252119302749634, train/raw-loss = 0.5114650726318359, train/logprobs = tensor([[-0.6857, -2.0086],
        [-0.6277, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13746854662895203
Epoch 0, Step 441: train/loss = 0.6359057426452637, train/raw-loss = 0.6225239038467407, train/logprobs = tensor([[-0.8455, -1.1987],
        [-0.7784, -0.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338181048631668
Epoch 0, Step 442: train/loss = 0.5319317579269409, train/raw-loss = 0.5174858570098877, train/logprobs = tensor([[-0.7813, -2.5286],
        [-0.7528, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14445924758911133
Epoch 0, Step 443: train/loss = 0.5357944965362549, train/raw-loss = 0.5218600034713745, train/logprobs = tensor([[-0.8908, -2.9020],
        [-0.6827, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13934457302093506
Epoch 0, Step 444: train/loss = 0.6347073316574097, train/raw-loss = 0.6232291460037231, train/logprobs = tensor([[-0.5400, -1.4068],
        [-0.4399, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478208005428314
Epoch 0, Step 445: train/loss = 0.43052610754966736, train/raw-loss = 0.4179977774620056, train/logprobs = tensor([[-0.6165, -3.2057],
        [-0.6648, -1.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125283345580101
Epoch 0, Step 446: train/loss = 0.5824929475784302, train/raw-loss = 0.5670067071914673, train/logprobs = tensor([[-0.9425, -1.6828],
        [-0.7309, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15486285090446472
Epoch 0, Step 447: train/loss = 0.3692490756511688, train/raw-loss = 0.3550611734390259, train/logprobs = tensor([[-0.8043, -3.0222],
        [-0.8630, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418791115283966
Epoch 0, Step 448: train/loss = 0.658606767654419, train/raw-loss = 0.6434239745140076, train/logprobs = tensor([[-0.8767, -1.1083],
        [-0.7065, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15182726085186005
Epoch 0, Step 449: train/loss = 0.5810556411743164, train/raw-loss = 0.5679852962493896, train/logprobs = tensor([[-0.7922, -1.8368],
        [-0.6454, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13070335984230042
Epoch 0, Step 450: train/loss = 0.6016138792037964, train/raw-loss = 0.5882648229598999, train/logprobs = tensor([[-0.7045, -1.4378],
        [-0.5807, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13349014520645142
Epoch 0, Step 451: train/loss = 0.5826625227928162, train/raw-loss = 0.5698465704917908, train/logprobs = tensor([[-0.7209, -1.9503],
        [-0.6684, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.128159299492836
Epoch 0, Step 452: train/loss = 0.5254315137863159, train/raw-loss = 0.510188639163971, train/logprobs = tensor([[-1.3039, -2.6718],
        [-1.1195, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15242953598499298
Epoch 0, Step 453: train/loss = 0.6564517021179199, train/raw-loss = 0.6399363279342651, train/logprobs = tensor([[-0.9293, -1.1926],
        [-0.8477, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16515325009822845
Epoch 0, Step 454: train/loss = 0.5347115397453308, train/raw-loss = 0.5202798843383789, train/logprobs = tensor([[-0.7252, -2.1382],
        [-0.6679, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14431646466255188
Epoch 0, Step 455: train/loss = 0.601454496383667, train/raw-loss = 0.5857969522476196, train/logprobs = tensor([[-1.1184, -2.2697],
        [-0.9932, -1.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1565750539302826
Epoch 0, Step 456: train/loss = 0.5429934859275818, train/raw-loss = 0.5254145860671997, train/logprobs = tensor([[-1.0368, -2.3360],
        [-0.7091, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17578938603401184
Epoch 0, Step 457: train/loss = 0.529318630695343, train/raw-loss = 0.511670708656311, train/logprobs = tensor([[-0.9789, -1.9181],
        [-1.0113, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17647939920425415
Epoch 0, Step 458: train/loss = 0.4410003423690796, train/raw-loss = 0.4260650873184204, train/logprobs = tensor([[-0.8658, -3.4209],
        [-0.8144, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14935266971588135
Epoch 0, Step 459: train/loss = 0.5175910592079163, train/raw-loss = 0.5026692152023315, train/logprobs = tensor([[-0.7925, -2.8988],
        [-0.7676, -0.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14921854436397552
Epoch 0, Step 460: train/loss = 0.603558361530304, train/raw-loss = 0.5883487462997437, train/logprobs = tensor([[-0.8254, -2.2015],
        [-0.7494, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1520957201719284
Epoch 0, Step 461: train/loss = 0.5548333525657654, train/raw-loss = 0.5410082340240479, train/logprobs = tensor([[-0.6984, -2.9390],
        [-0.6638, -1.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13825103640556335
Epoch 0, Step 462: train/loss = 0.5535510778427124, train/raw-loss = 0.5391843914985657, train/logprobs = tensor([[-1.0100, -3.2821],
        [-0.8806, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14366638660430908
Epoch 0, Step 463: train/loss = 0.6114790439605713, train/raw-loss = 0.5958002805709839, train/logprobs = tensor([[-0.7445, -1.2658],
        [-0.7381, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567879468202591
Epoch 0, Step 464: train/loss = 0.6394334435462952, train/raw-loss = 0.6253132820129395, train/logprobs = tensor([[-0.5805, -0.9705],
        [-0.5671, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120185375213623
Epoch 0, Step 465: train/loss = 0.3786736726760864, train/raw-loss = 0.3645876944065094, train/logprobs = tensor([[-0.9052, -4.2035],
        [-1.0033, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14085973799228668
Epoch 0, Step 466: train/loss = 0.619662344455719, train/raw-loss = 0.6062479019165039, train/logprobs = tensor([[-0.7333, -1.0321],
        [-0.7198, -0.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414481282234192
Epoch 0, Step 467: train/loss = 0.4966684579849243, train/raw-loss = 0.4828927516937256, train/logprobs = tensor([[-0.7878, -1.8256],
        [-0.8211, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377570927143097
Epoch 0, Step 468: train/loss = 0.5271087288856506, train/raw-loss = 0.5103057622909546, train/logprobs = tensor([[-0.7598, -3.1248],
        [-0.7597, -2.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16802978515625
Epoch 0, Step 469: train/loss = 0.6540446281433105, train/raw-loss = 0.6412296295166016, train/logprobs = tensor([[-0.6351, -0.8440],
        [-0.6756, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12815050780773163
Epoch 0, Step 470: train/loss = 0.6800616979598999, train/raw-loss = 0.6681238412857056, train/logprobs = tensor([[-0.7643, -0.6146],
        [-0.7351, -0.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11937824636697769
Epoch 0, Step 471: train/loss = 0.5692859292030334, train/raw-loss = 0.5542534589767456, train/logprobs = tensor([[-0.7883, -2.0755],
        [-0.6959, -1.2617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15032514929771423
Epoch 0, Step 472: train/loss = 0.717830240726471, train/raw-loss = 0.7041188478469849, train/logprobs = tensor([[-1.0288, -0.8259],
        [-0.8643, -0.6923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13711492717266083
Epoch 0, Step 473: train/loss = 0.6175572276115417, train/raw-loss = 0.6035720705986023, train/logprobs = tensor([[-0.7944, -1.4543],
        [-0.7277, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13985197246074677
Epoch 0, Step 474: train/loss = 0.5218040943145752, train/raw-loss = 0.5059553384780884, train/logprobs = tensor([[-0.7397, -1.6458],
        [-0.8254, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15848788619041443
Epoch 0, Step 475: train/loss = 0.6555339097976685, train/raw-loss = 0.6424387693405151, train/logprobs = tensor([[-0.5101, -1.0437],
        [-0.4985, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13095176219940186
Epoch 0, Step 476: train/loss = 0.5725300312042236, train/raw-loss = 0.558562159538269, train/logprobs = tensor([[-0.6006, -1.2247],
        [-0.7282, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13967888057231903
Epoch 0, Step 477: train/loss = 0.4887462854385376, train/raw-loss = 0.47465798258781433, train/logprobs = tensor([[-0.8047, -2.9668],
        [-0.8761, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14088325202465057
Epoch 0, Step 478: train/loss = 0.6036466956138611, train/raw-loss = 0.5906401872634888, train/logprobs = tensor([[-0.8013, -1.9773],
        [-0.7605, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300651878118515
Epoch 0, Step 479: train/loss = 0.572688102722168, train/raw-loss = 0.5606046915054321, train/logprobs = tensor([[-0.7225, -1.8333],
        [-0.7394, -0.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12083431333303452
Epoch 0, Step 480: train/loss = 0.5425699949264526, train/raw-loss = 0.5282105803489685, train/logprobs = tensor([[-0.7593, -1.8415],
        [-0.6747, -0.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14359408617019653
Epoch 0, Step 481: train/loss = 0.56296706199646, train/raw-loss = 0.5510633587837219, train/logprobs = tensor([[-0.8118, -2.0209],
        [-0.7706, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903724074363708
Epoch 0, Step 482: train/loss = 0.5340957641601562, train/raw-loss = 0.5178467631340027, train/logprobs = tensor([[-1.0405, -2.0423],
        [-0.9943, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16249006986618042
Epoch 0, Step 483: train/loss = 0.5489124655723572, train/raw-loss = 0.5346274971961975, train/logprobs = tensor([[-0.7597, -1.9720],
        [-0.7817, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14284971356391907
Epoch 0, Step 484: train/loss = 0.7336470484733582, train/raw-loss = 0.7197932004928589, train/logprobs = tensor([[-1.9110, -4.0690],
        [-0.6862, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13853858411312103
Epoch 0, Step 485: train/loss = 0.6460828185081482, train/raw-loss = 0.6343969702720642, train/logprobs = tensor([[-0.6721, -1.1350],
        [-0.6847, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685828864574432
Epoch 0, Step 486: train/loss = 0.3835066556930542, train/raw-loss = 0.3677792549133301, train/logprobs = tensor([[-0.9167, -5.5699],
        [-0.9501, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572742909193039
Epoch 0, Step 487: train/loss = 0.5130017995834351, train/raw-loss = 0.49814003705978394, train/logprobs = tensor([[-1.0843, -3.4279],
        [-0.8683, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14861808717250824
Epoch 0, Step 488: train/loss = 0.6446818113327026, train/raw-loss = 0.6326507329940796, train/logprobs = tensor([[-0.5358, -0.9671],
        [-0.4400, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.120310477912426
Epoch 0, Step 489: train/loss = 0.714022159576416, train/raw-loss = 0.6983678936958313, train/logprobs = tensor([[-1.2612, -2.5544],
        [-0.9099, -2.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15654271841049194
Epoch 0, Step 490: train/loss = 0.5954159498214722, train/raw-loss = 0.5800801515579224, train/logprobs = tensor([[-0.5750, -1.3426],
        [-0.5451, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15335789322853088
Epoch 0, Step 491: train/loss = 0.5036918520927429, train/raw-loss = 0.4862942099571228, train/logprobs = tensor([[-1.1463, -2.8808],
        [-1.0331, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17397664487361908
Epoch 0, Step 492: train/loss = 0.5698351860046387, train/raw-loss = 0.5563277006149292, train/logprobs = tensor([[-0.6559, -1.9309],
        [-0.6472, -0.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350749284029007
Epoch 0, Step 493: train/loss = 0.5155172944068909, train/raw-loss = 0.49961233139038086, train/logprobs = tensor([[-0.8577, -1.9922],
        [-0.8728, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15904954075813293
Epoch 0, Step 494: train/loss = 0.5985226631164551, train/raw-loss = 0.5827187299728394, train/logprobs = tensor([[-1.0525, -2.5023],
        [-0.8302, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803903341293335
Epoch 0, Step 495: train/loss = 0.6273179054260254, train/raw-loss = 0.609600305557251, train/logprobs = tensor([[-0.9748, -1.6971],
        [-0.7893, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771763265132904
Epoch 0, Step 496: train/loss = 0.5988361835479736, train/raw-loss = 0.5855643153190613, train/logprobs = tensor([[-0.6893, -1.5690],
        [-0.6684, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327187567949295
Epoch 0, Step 497: train/loss = 0.653179943561554, train/raw-loss = 0.6401314735412598, train/logprobs = tensor([[-0.8281, -1.2006],
        [-0.7217, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13048499822616577
Epoch 0, Step 498: train/loss = 0.6109646558761597, train/raw-loss = 0.5936325192451477, train/logprobs = tensor([[-1.1917, -1.4482],
        [-0.9684, -0.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17332108318805695
Epoch 0, Step 499: train/loss = 0.5340790152549744, train/raw-loss = 0.519194483757019, train/logprobs = tensor([[-0.8749, -2.9198],
        [-0.7693, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14884547889232635
Epoch 0, Step 500: train/loss = 0.4665793776512146, train/raw-loss = 0.45542818307876587, train/logprobs = tensor([[-0.5692, -3.9359],
        [-0.5982, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11151158809661865
Epoch 0, Step 501: train/loss = 0.6397891044616699, train/raw-loss = 0.6251408457756042, train/logprobs = tensor([[-0.8001, -1.5036],
        [-0.8323, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14648273587226868
Epoch 0, Step 502: train/loss = 0.40892931818962097, train/raw-loss = 0.39567676186561584, train/logprobs = tensor([[-0.7460, -4.6579],
        [-0.9977, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13252554833889008
Epoch 0, Step 503: train/loss = 0.47760456800460815, train/raw-loss = 0.4622771739959717, train/logprobs = tensor([[-0.7389, -2.6863],
        [-0.8168, -0.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1532742977142334
Epoch 0, Step 504: train/loss = 0.6345884799957275, train/raw-loss = 0.6216152906417847, train/logprobs = tensor([[-1.0747, -1.3755],
        [-1.0496, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12973225116729736
Epoch 0, Step 505: train/loss = 0.5165606141090393, train/raw-loss = 0.5029340386390686, train/logprobs = tensor([[-0.7439, -2.7922],
        [-0.8080, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362658143043518
Epoch 0, Step 506: train/loss = 0.42728355526924133, train/raw-loss = 0.41223058104515076, train/logprobs = tensor([[-0.6705, -2.1021],
        [-0.8846, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15052995085716248
Epoch 0, Step 507: train/loss = 0.5381032824516296, train/raw-loss = 0.5249256491661072, train/logprobs = tensor([[-0.7091, -1.9566],
        [-0.5995, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13177642226219177
Epoch 0, Step 508: train/loss = 0.38542550802230835, train/raw-loss = 0.37097030878067017, train/logprobs = tensor([[-0.8225, -4.5363],
        [-0.9229, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14455187320709229
Epoch 0, Step 509: train/loss = 0.6198456883430481, train/raw-loss = 0.6046695709228516, train/logprobs = tensor([[-1.4660, -2.2780],
        [-1.2045, -1.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15176089107990265
Epoch 0, Step 510: train/loss = 0.7089246511459351, train/raw-loss = 0.6928277015686035, train/logprobs = tensor([[-0.8476, -0.8821],
        [-0.7751, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16096962988376617
Epoch 0, Step 511: train/loss = 0.6612274050712585, train/raw-loss = 0.6459420919418335, train/logprobs = tensor([[-1.5131, -2.0307],
        [-0.9905, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528526246547699
Epoch 0, Step 512: train/loss = 0.611189067363739, train/raw-loss = 0.5956350564956665, train/logprobs = tensor([[-0.9227, -1.4417],
        [-0.8866, -0.9016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15553995966911316
Epoch 0, Step 513: train/loss = 0.44780007004737854, train/raw-loss = 0.43162816762924194, train/logprobs = tensor([[-1.1939, -3.2736],
        [-0.9448, -0.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16171906888484955
Epoch 0, Step 514: train/loss = 0.5838280320167542, train/raw-loss = 0.5683630108833313, train/logprobs = tensor([[-1.0594, -2.8848],
        [-0.7664, -1.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15464997291564941
Epoch 0, Step 515: train/loss = 0.6566877365112305, train/raw-loss = 0.6445289850234985, train/logprobs = tensor([[-0.4921, -1.2698],
        [-0.4544, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158738821744919
Epoch 0, Step 516: train/loss = 0.47034698724746704, train/raw-loss = 0.45511287450790405, train/logprobs = tensor([[-1.0303, -2.4298],
        [-1.0176, -0.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15234151482582092
Epoch 0, Step 517: train/loss = 0.6202085614204407, train/raw-loss = 0.6058194637298584, train/logprobs = tensor([[-0.7270, -1.3155],
        [-0.6562, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14389054477214813
Epoch 0, Step 518: train/loss = 0.5839959383010864, train/raw-loss = 0.5692832469940186, train/logprobs = tensor([[-1.0126, -2.4995],
        [-0.8465, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14712683856487274
Epoch 0, Step 519: train/loss = 0.4988175630569458, train/raw-loss = 0.4810085594654083, train/logprobs = tensor([[-0.9920, -1.7632],
        [-1.0802, -0.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17808982729911804
Epoch 0, Step 520: train/loss = 0.604571521282196, train/raw-loss = 0.5877719521522522, train/logprobs = tensor([[-0.9043, -1.5246],
        [-0.7762, -0.8797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16799601912498474
Epoch 0, Step 521: train/loss = 0.5754709243774414, train/raw-loss = 0.5603880286216736, train/logprobs = tensor([[-0.9574, -2.5385],
        [-0.8383, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15082916617393494
Epoch 0, Step 522: train/loss = 0.5942869186401367, train/raw-loss = 0.5774394273757935, train/logprobs = tensor([[-1.2194, -2.2616],
        [-0.9492, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16847538948059082
Epoch 0, Step 523: train/loss = 0.5880908966064453, train/raw-loss = 0.577532172203064, train/logprobs = tensor([[-0.4140, -1.4654],
        [-0.4127, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10558673739433289
Epoch 0, Step 524: train/loss = 0.5969471335411072, train/raw-loss = 0.5804499387741089, train/logprobs = tensor([[-0.8499, -1.5245],
        [-0.8445, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16497160494327545
Epoch 0, Step 525: train/loss = 0.6681163311004639, train/raw-loss = 0.6554490327835083, train/logprobs = tensor([[-0.6911, -1.0210],
        [-0.6339, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12667274475097656
Epoch 0, Step 526: train/loss = 0.3852558135986328, train/raw-loss = 0.36800438165664673, train/logprobs = tensor([[-0.8586, -3.0220],
        [-0.9395, -0.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17251421511173248
Epoch 0, Step 527: train/loss = 0.6430731415748596, train/raw-loss = 0.6273778676986694, train/logprobs = tensor([[-1.3842, -1.6950],
        [-1.1182, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569528877735138
Epoch 0, Step 528: train/loss = 0.624272882938385, train/raw-loss = 0.6104668378829956, train/logprobs = tensor([[-0.7386, -0.9639],
        [-0.7383, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13806040585041046
Epoch 0, Step 529: train/loss = 0.5135616064071655, train/raw-loss = 0.49539250135421753, train/logprobs = tensor([[-1.1204, -3.6349],
        [-1.0014, -2.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18169081211090088
Epoch 0, Step 530: train/loss = 0.5669888257980347, train/raw-loss = 0.5512602925300598, train/logprobs = tensor([[-0.5995, -1.6555],
        [-0.6854, -0.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572849601507187
Epoch 0, Step 531: train/loss = 0.625022828578949, train/raw-loss = 0.6116876602172852, train/logprobs = tensor([[-0.6274, -1.1687],
        [-0.5929, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133352130651474
Epoch 0, Step 532: train/loss = 0.6125880479812622, train/raw-loss = 0.5967261791229248, train/logprobs = tensor([[-1.2259, -1.5372],
        [-1.1574, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15861846506595612
Epoch 0, Step 533: train/loss = 0.4169501066207886, train/raw-loss = 0.3998869061470032, train/logprobs = tensor([[-0.8577, -4.2677],
        [-0.8600, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17063212394714355
Epoch 0, Step 534: train/loss = 0.4200519919395447, train/raw-loss = 0.4040733575820923, train/logprobs = tensor([[-0.7478, -3.4657],
        [-0.9079, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15978647768497467
Epoch 0, Step 535: train/loss = 0.6310814619064331, train/raw-loss = 0.6171812415122986, train/logprobs = tensor([[-0.7018, -0.7739],
        [-0.7889, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13900288939476013
Epoch 0, Step 536: train/loss = 0.5012825727462769, train/raw-loss = 0.48787468671798706, train/logprobs = tensor([[-0.8551, -3.3737],
        [-0.6492, -0.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134078711271286
Epoch 0, Step 537: train/loss = 0.6537783145904541, train/raw-loss = 0.6393105387687683, train/logprobs = tensor([[-1.1259, -2.2505],
        [-0.5384, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14467741549015045
Epoch 0, Step 538: train/loss = 0.5264842510223389, train/raw-loss = 0.5115452408790588, train/logprobs = tensor([[-0.7874, -1.9367],
        [-0.7432, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14939017593860626
Epoch 0, Step 539: train/loss = 0.6773775219917297, train/raw-loss = 0.6664829254150391, train/logprobs = tensor([[-0.5400, -0.5560],
        [-0.5236, -0.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10894574970006943
Epoch 0, Step 540: train/loss = 0.6790196895599365, train/raw-loss = 0.667163610458374, train/logprobs = tensor([[-0.5594, -0.8263],
        [-0.5020, -0.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11856083571910858
Epoch 0, Step 541: train/loss = 0.5430340766906738, train/raw-loss = 0.5290918350219727, train/logprobs = tensor([[-0.6398, -1.0382],
        [-0.8706, -0.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13942231237888336
Epoch 0, Step 542: train/loss = 0.610942006111145, train/raw-loss = 0.5938922166824341, train/logprobs = tensor([[-0.9701, -1.8526],
        [-0.7656, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704978346824646
Epoch 0, Step 543: train/loss = 0.6345426440238953, train/raw-loss = 0.6193972826004028, train/logprobs = tensor([[-1.0839, -1.8749],
        [-0.6061, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514541506767273
Epoch 0, Step 544: train/loss = 0.6670160889625549, train/raw-loss = 0.6538949012756348, train/logprobs = tensor([[-0.6799, -0.7861],
        [-0.6591, -0.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312122344970703
Epoch 0, Step 545: train/loss = 0.5245120525360107, train/raw-loss = 0.5084852576255798, train/logprobs = tensor([[-1.0270, -1.8059],
        [-1.0363, -0.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16026756167411804
Epoch 0, Step 546: train/loss = 0.538689136505127, train/raw-loss = 0.5250306129455566, train/logprobs = tensor([[-0.7868, -1.5736],
        [-0.8241, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13658493757247925
Epoch 0, Step 547: train/loss = 0.4888114929199219, train/raw-loss = 0.4743531346321106, train/logprobs = tensor([[-0.6754, -2.0147],
        [-0.7235, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14458346366882324
Epoch 0, Step 548: train/loss = 0.5144563913345337, train/raw-loss = 0.4991834759712219, train/logprobs = tensor([[-1.0853, -4.6491],
        [-1.1547, -1.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15272854268550873
Epoch 0, Step 549: train/loss = 0.47007328271865845, train/raw-loss = 0.4562965929508209, train/logprobs = tensor([[-0.5219, -2.4231],
        [-0.6769, -0.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13776683807373047
Epoch 0, Step 550: train/loss = 0.3993054926395416, train/raw-loss = 0.3820631504058838, train/logprobs = tensor([[-0.7976, -2.5851],
        [-0.8974, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1724235862493515
Epoch 0, Step 551: train/loss = 0.5684093236923218, train/raw-loss = 0.551744818687439, train/logprobs = tensor([[-0.9066, -1.1407],
        [-1.0705, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666446328163147
Epoch 0, Step 552: train/loss = 0.6607316136360168, train/raw-loss = 0.6440730094909668, train/logprobs = tensor([[-1.3120, -1.6192],
        [-0.8510, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665852814912796
Epoch 0, Step 553: train/loss = 0.6635428071022034, train/raw-loss = 0.6503989696502686, train/logprobs = tensor([[-0.9442, -1.3194],
        [-0.5833, -0.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314380168914795
Epoch 0, Step 554: train/loss = 0.5814608335494995, train/raw-loss = 0.565663754940033, train/logprobs = tensor([[-0.6742, -2.0484],
        [-0.6684, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797129273414612
Epoch 0, Step 555: train/loss = 0.47422367334365845, train/raw-loss = 0.4587993025779724, train/logprobs = tensor([[-0.6803, -2.1919],
        [-0.8610, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1542433202266693
Epoch 0, Step 556: train/loss = 0.654058039188385, train/raw-loss = 0.6368029117584229, train/logprobs = tensor([[-0.9762, -2.0102],
        [-0.7402, -1.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17255164682865143
Epoch 0, Step 557: train/loss = 0.6043628454208374, train/raw-loss = 0.5863856673240662, train/logprobs = tensor([[-1.4728, -2.0311],
        [-0.9918, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17977161705493927
Epoch 0, Step 558: train/loss = 0.5818703174591064, train/raw-loss = 0.5659323334693909, train/logprobs = tensor([[-0.8770, -1.8566],
        [-0.7850, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15938033163547516
Epoch 0, Step 559: train/loss = 0.623733401298523, train/raw-loss = 0.6084117889404297, train/logprobs = tensor([[-0.7532, -1.3293],
        [-0.9111, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15321604907512665
Epoch 0, Step 560: train/loss = 0.5426241755485535, train/raw-loss = 0.5254309773445129, train/logprobs = tensor([[-1.1453, -2.8251],
        [-0.9396, -1.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17193175852298737
Epoch 0, Step 561: train/loss = 0.5753284692764282, train/raw-loss = 0.560641348361969, train/logprobs = tensor([[-0.6436, -1.6982],
        [-0.6546, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14687149226665497
Epoch 0, Step 562: train/loss = 0.6646290421485901, train/raw-loss = 0.6542401909828186, train/logprobs = tensor([[-0.4427, -1.1992],
        [-0.4630, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10388852655887604
Epoch 0, Step 563: train/loss = 0.5070540904998779, train/raw-loss = 0.4899885356426239, train/logprobs = tensor([[-0.8069, -5.1984],
        [-0.7140, -2.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17065498232841492
Epoch 0, Step 564: train/loss = 0.5046634078025818, train/raw-loss = 0.49033302068710327, train/logprobs = tensor([[-0.8716, -2.1977],
        [-0.8244, -0.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14330360293388367
Epoch 0, Step 565: train/loss = 0.5380196571350098, train/raw-loss = 0.5253767967224121, train/logprobs = tensor([[-0.6362, -1.8540],
        [-0.7284, -0.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264287233352661
Epoch 0, Step 566: train/loss = 0.5893184542655945, train/raw-loss = 0.5760606527328491, train/logprobs = tensor([[-0.7777, -1.8812],
        [-0.7382, -0.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13257838785648346
Epoch 0, Step 567: train/loss = 0.6234656572341919, train/raw-loss = 0.6085107922554016, train/logprobs = tensor([[-0.8229, -1.2353],
        [-0.7164, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14954888820648193
Epoch 0, Step 568: train/loss = 0.5223956108093262, train/raw-loss = 0.5032409429550171, train/logprobs = tensor([[-0.8710, -4.3127],
        [-0.9581, -1.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915467530488968
Epoch 0, Step 569: train/loss = 0.5759789347648621, train/raw-loss = 0.5630238056182861, train/logprobs = tensor([[-0.6476, -1.5603],
        [-0.5566, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295512318611145
Epoch 0, Step 570: train/loss = 0.6202446818351746, train/raw-loss = 0.6060264110565186, train/logprobs = tensor([[-0.6859, -1.0796],
        [-0.7050, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14218342304229736
Epoch 0, Step 571: train/loss = 0.6616623401641846, train/raw-loss = 0.6503332853317261, train/logprobs = tensor([[-0.5369, -0.6567],
        [-0.5688, -0.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329098790884018
Epoch 0, Step 572: train/loss = 0.5280514359474182, train/raw-loss = 0.5111353397369385, train/logprobs = tensor([[-0.7997, -3.5381],
        [-0.7955, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16916128993034363
Epoch 0, Step 573: train/loss = 0.5978914499282837, train/raw-loss = 0.5806301832199097, train/logprobs = tensor([[-1.2178, -2.0750],
        [-0.9172, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1726125180721283
Epoch 0, Step 574: train/loss = 0.4798043370246887, train/raw-loss = 0.4642193913459778, train/logprobs = tensor([[-0.7177, -2.5951],
        [-0.9836, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15584903955459595
Epoch 0, Step 575: train/loss = 0.6177518963813782, train/raw-loss = 0.602256178855896, train/logprobs = tensor([[-0.6972, -1.0999],
        [-0.6835, -0.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549573540687561
Epoch 0, Step 576: train/loss = 0.5199580192565918, train/raw-loss = 0.505429744720459, train/logprobs = tensor([[-0.5621, -1.8223],
        [-0.6871, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1452825516462326
Epoch 0, Step 577: train/loss = 0.5139808058738708, train/raw-loss = 0.4971303939819336, train/logprobs = tensor([[-0.6317, -1.4563],
        [-0.7734, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16850411891937256
Epoch 0, Step 578: train/loss = 0.5110161304473877, train/raw-loss = 0.4944096505641937, train/logprobs = tensor([[-0.9759, -2.4276],
        [-1.0078, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16606448590755463
Epoch 0, Step 579: train/loss = 0.5702617764472961, train/raw-loss = 0.5565235614776611, train/logprobs = tensor([[-0.5922, -1.5711],
        [-0.5847, -0.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13738226890563965
Epoch 0, Step 580: train/loss = 0.6712666749954224, train/raw-loss = 0.6588987708091736, train/logprobs = tensor([[-0.5681, -0.5760],
        [-0.5502, -0.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1236790120601654
Epoch 0, Step 581: train/loss = 0.5126335024833679, train/raw-loss = 0.49856501817703247, train/logprobs = tensor([[-0.6824, -2.7485],
        [-0.7051, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14068499207496643
Epoch 0, Step 582: train/loss = 0.519707441329956, train/raw-loss = 0.5060482025146484, train/logprobs = tensor([[-0.6668, -1.7520],
        [-0.7817, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13659270107746124
Epoch 0, Step 583: train/loss = 0.6859046220779419, train/raw-loss = 0.6717383861541748, train/logprobs = tensor([[-0.8856, -1.0839],
        [-0.7532, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141662135720253
Epoch 0, Step 584: train/loss = 0.46044617891311646, train/raw-loss = 0.44641420245170593, train/logprobs = tensor([[-0.6895, -4.3872],
        [-0.7941, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403200924396515
Epoch 0, Step 585: train/loss = 0.5521601438522339, train/raw-loss = 0.5362879037857056, train/logprobs = tensor([[-0.8096, -1.5580],
        [-0.8403, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15872247517108917
Epoch 0, Step 586: train/loss = 0.6060889959335327, train/raw-loss = 0.589665412902832, train/logprobs = tensor([[-1.3496, -2.3814],
        [-1.0308, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16423632204532623
Epoch 0, Step 587: train/loss = 0.6606882214546204, train/raw-loss = 0.6455830931663513, train/logprobs = tensor([[-1.0078, -1.5604],
        [-0.7408, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15105094015598297
Epoch 0, Step 588: train/loss = 0.5283129215240479, train/raw-loss = 0.5113086700439453, train/logprobs = tensor([[-1.4306, -3.4867],
        [-1.1947, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17004302144050598
Epoch 0, Step 589: train/loss = 0.4502403736114502, train/raw-loss = 0.4332026541233063, train/logprobs = tensor([[-0.7424, -2.3113],
        [-0.8619, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17037740349769592
Epoch 0, Step 590: train/loss = 0.5723164081573486, train/raw-loss = 0.5584262609481812, train/logprobs = tensor([[-0.5130, -2.9392],
        [-0.5606, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890144228935242
Epoch 0, Step 591: train/loss = 0.6497135758399963, train/raw-loss = 0.6344611644744873, train/logprobs = tensor([[-0.7761, -0.9177],
        [-0.7865, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15252375602722168
Epoch 0, Step 592: train/loss = 0.5751998424530029, train/raw-loss = 0.5570071935653687, train/logprobs = tensor([[-1.2795, -2.1517],
        [-1.1030, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18192611634731293
Epoch 0, Step 593: train/loss = 0.7197429537773132, train/raw-loss = 0.7048662900924683, train/logprobs = tensor([[-1.3201, -1.0070],
        [-1.0953, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14876650273799896
Epoch 0, Step 594: train/loss = 0.657901406288147, train/raw-loss = 0.6426044702529907, train/logprobs = tensor([[-0.5398, -1.0134],
        [-0.5361, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15296925604343414
Epoch 0, Step 595: train/loss = 0.4836917519569397, train/raw-loss = 0.4691636562347412, train/logprobs = tensor([[-0.8691, -2.1649],
        [-0.9477, -0.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14528080821037292
Epoch 0, Step 596: train/loss = 0.5659843683242798, train/raw-loss = 0.5520763397216797, train/logprobs = tensor([[-0.6540, -2.2542],
        [-0.5637, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13908013701438904
Epoch 0, Step 597: train/loss = 0.5405943393707275, train/raw-loss = 0.5252803564071655, train/logprobs = tensor([[-0.6661, -2.9924],
        [-0.5817, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15313935279846191
Epoch 0, Step 598: train/loss = 0.48492535948753357, train/raw-loss = 0.46980226039886475, train/logprobs = tensor([[-0.7023, -2.0485],
        [-1.0129, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15123118460178375
Epoch 0, Step 599: train/loss = 0.3970694839954376, train/raw-loss = 0.37920084595680237, train/logprobs = tensor([[-0.9290, -3.2180],
        [-1.3227, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178686261177063
Epoch 0, Step 600: train/loss = 0.5427087545394897, train/raw-loss = 0.526705801486969, train/logprobs = tensor([[-0.9528, -1.8620],
        [-0.9051, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16002912819385529
Epoch 0, Step 601: train/loss = 0.5889146327972412, train/raw-loss = 0.5748940110206604, train/logprobs = tensor([[-0.7897, -1.2946],
        [-0.8352, -0.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402062177658081
Epoch 0, Step 602: train/loss = 0.5961511135101318, train/raw-loss = 0.5807204842567444, train/logprobs = tensor([[-0.5595, -1.0613],
        [-0.6338, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543063372373581
Epoch 0, Step 603: train/loss = 0.6297868490219116, train/raw-loss = 0.6142923831939697, train/logprobs = tensor([[-0.7320, -1.1086],
        [-0.6678, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15494415163993835
Epoch 0, Step 604: train/loss = 0.5491191148757935, train/raw-loss = 0.5326024889945984, train/logprobs = tensor([[-0.8152, -2.3543],
        [-0.8454, -1.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16516602039337158
Epoch 0, Step 605: train/loss = 0.5167025327682495, train/raw-loss = 0.4998883605003357, train/logprobs = tensor([[-0.6941, -1.8350],
        [-0.9164, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814184188842773
Epoch 0, Step 606: train/loss = 0.37342745065689087, train/raw-loss = 0.35586124658584595, train/logprobs = tensor([[-0.8253, -2.6429],
        [-1.0792, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17566236853599548
Epoch 0, Step 607: train/loss = 0.6112834215164185, train/raw-loss = 0.5973153114318848, train/logprobs = tensor([[-0.7316, -1.4738],
        [-0.7378, -1.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13968075811862946
Epoch 0, Step 608: train/loss = 0.47384971380233765, train/raw-loss = 0.45765045285224915, train/logprobs = tensor([[-0.8588, -2.9238],
        [-0.8407, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16199266910552979
Epoch 0, Step 609: train/loss = 0.4832042157649994, train/raw-loss = 0.465365469455719, train/logprobs = tensor([[-0.6846, -1.8256],
        [-0.8549, -0.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17838720977306366
Epoch 0, Step 610: train/loss = 0.6576512455940247, train/raw-loss = 0.6403040289878845, train/logprobs = tensor([[-0.9352, -1.0815],
        [-0.9018, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347204685211182
Epoch 0, Step 611: train/loss = 0.4568386673927307, train/raw-loss = 0.44181182980537415, train/logprobs = tensor([[-0.5140, -1.9267],
        [-0.7425, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15026822686195374
Epoch 0, Step 612: train/loss = 0.44993412494659424, train/raw-loss = 0.4320071339607239, train/logprobs = tensor([[-0.9905, -2.6696],
        [-1.0617, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17926952242851257
Epoch 0, Step 613: train/loss = 0.6269492506980896, train/raw-loss = 0.6123050451278687, train/logprobs = tensor([[-0.7253, -0.6772],
        [-0.8685, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14644208550453186
Epoch 0, Step 614: train/loss = 0.5729386806488037, train/raw-loss = 0.5599029064178467, train/logprobs = tensor([[-0.5541, -2.3525],
        [-0.5169, -0.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13035696744918823
Epoch 0, Step 615: train/loss = 0.6242526769638062, train/raw-loss = 0.6068864464759827, train/logprobs = tensor([[-0.8241, -1.1767],
        [-0.7245, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366242408752441
Epoch 0, Step 616: train/loss = 0.3990021347999573, train/raw-loss = 0.3795320987701416, train/logprobs = tensor([[-0.9835, -2.7800],
        [-1.3601, -1.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19470025599002838
Epoch 0, Step 617: train/loss = 0.42622244358062744, train/raw-loss = 0.40622806549072266, train/logprobs = tensor([[-0.7955, -2.8223],
        [-1.0533, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19994384050369263
Epoch 0, Step 618: train/loss = 0.5222596526145935, train/raw-loss = 0.5064472556114197, train/logprobs = tensor([[-0.8261, -1.9038],
        [-0.6970, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581241637468338
Epoch 0, Step 619: train/loss = 0.5709313154220581, train/raw-loss = 0.5587222576141357, train/logprobs = tensor([[-0.6922, -1.4501],
        [-0.7190, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12209106981754303
Epoch 0, Step 620: train/loss = 0.40698128938674927, train/raw-loss = 0.3899170756340027, train/logprobs = tensor([[-0.7187, -1.9744],
        [-1.1854, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17064228653907776
Epoch 0, Step 621: train/loss = 0.5912680625915527, train/raw-loss = 0.5769572257995605, train/logprobs = tensor([[-0.6226, -1.5349],
        [-0.6452, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14310848712921143
Epoch 0, Step 622: train/loss = 0.40716472268104553, train/raw-loss = 0.3926081359386444, train/logprobs = tensor([[-0.6973, -3.1968],
        [-0.8704, -1.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14556612074375153
Epoch 0, Step 623: train/loss = 0.5102022886276245, train/raw-loss = 0.4934852719306946, train/logprobs = tensor([[-0.9305, -3.2900],
        [-1.0466, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16717016696929932
Epoch 0, Step 624: train/loss = 0.5264830589294434, train/raw-loss = 0.5087357759475708, train/logprobs = tensor([[-0.8251, -2.7290],
        [-0.8221, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17747296392917633
Epoch 0, Step 625: train/loss = 0.5007483959197998, train/raw-loss = 0.48696663975715637, train/logprobs = tensor([[-0.6349, -2.0425],
        [-0.5985, -0.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13781774044036865
Epoch 0, Step 626: train/loss = 0.5776637196540833, train/raw-loss = 0.5637667775154114, train/logprobs = tensor([[-0.7006, -1.5683],
        [-0.6680, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13896922767162323
Epoch 0, Step 627: train/loss = 0.5366405844688416, train/raw-loss = 0.5202048420906067, train/logprobs = tensor([[-0.5502, -1.4527],
        [-0.7378, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16435743868350983
Epoch 0, Step 628: train/loss = 0.5524884462356567, train/raw-loss = 0.5367676019668579, train/logprobs = tensor([[-0.8829, -1.7827],
        [-0.7996, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15720853209495544
Epoch 0, Step 629: train/loss = 0.591038167476654, train/raw-loss = 0.5738343000411987, train/logprobs = tensor([[-0.7661, -1.3177],
        [-0.7401, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17203886806964874
Epoch 0, Step 630: train/loss = 0.6460395455360413, train/raw-loss = 0.6342703104019165, train/logprobs = tensor([[-0.6227, -0.7345],
        [-0.6882, -0.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11769305914640427
Epoch 0, Step 631: train/loss = 0.6532177925109863, train/raw-loss = 0.6396548748016357, train/logprobs = tensor([[-0.5244, -0.8003],
        [-0.5922, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13562935590744019
Epoch 0, Step 632: train/loss = 0.6952681541442871, train/raw-loss = 0.6814286112785339, train/logprobs = tensor([[-1.2102, -1.7932],
        [-0.6988, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383950412273407
Epoch 0, Step 633: train/loss = 0.6574732065200806, train/raw-loss = 0.643013060092926, train/logprobs = tensor([[-0.7307, -1.0072],
        [-0.6677, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14460133016109467
Epoch 0, Step 634: train/loss = 0.5939981937408447, train/raw-loss = 0.5787914395332336, train/logprobs = tensor([[-0.8453, -1.7982],
        [-0.5945, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15206776559352875
Epoch 0, Step 635: train/loss = 0.5150836706161499, train/raw-loss = 0.49670156836509705, train/logprobs = tensor([[-0.8804, -1.8891],
        [-0.8008, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838207244873047
Epoch 0, Step 636: train/loss = 0.4135814905166626, train/raw-loss = 0.4003475308418274, train/logprobs = tensor([[-0.5105, -4.3542],
        [-0.7758, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13233976066112518
Epoch 0, Step 637: train/loss = 0.3871181309223175, train/raw-loss = 0.36989960074424744, train/logprobs = tensor([[-0.8283, -2.4565],
        [-1.1500, -0.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17218546569347382
Epoch 0, Step 638: train/loss = 0.45859336853027344, train/raw-loss = 0.4426635503768921, train/logprobs = tensor([[-0.7839, -4.4941],
        [-0.7237, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15929844975471497
Epoch 0, Step 639: train/loss = 0.45336639881134033, train/raw-loss = 0.43516260385513306, train/logprobs = tensor([[-0.7177, -2.3545],
        [-0.9016, -0.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18203793466091156
Epoch 0, Step 640: train/loss = 0.39697474241256714, train/raw-loss = 0.3782249093055725, train/logprobs = tensor([[-0.7306, -2.9439],
        [-1.3261, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749846518039703
Epoch 0, Step 641: train/loss = 0.5331273674964905, train/raw-loss = 0.5149393677711487, train/logprobs = tensor([[-1.4245, -2.2621],
        [-1.4272, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18188028037548065
Epoch 0, Step 642: train/loss = 0.45486366748809814, train/raw-loss = 0.4372382164001465, train/logprobs = tensor([[-0.8586, -2.9278],
        [-1.1692, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17625437676906586
Epoch 0, Step 643: train/loss = 0.42850401997566223, train/raw-loss = 0.41136813163757324, train/logprobs = tensor([[-0.5746, -1.9154],
        [-0.8816, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.171359121799469
Epoch 0, Step 644: train/loss = 0.5166678428649902, train/raw-loss = 0.49839144945144653, train/logprobs = tensor([[-0.7703, -1.9634],
        [-0.8172, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1827639788389206
Epoch 0, Step 645: train/loss = 0.5035607218742371, train/raw-loss = 0.4877249002456665, train/logprobs = tensor([[-0.6360, -1.8125],
        [-0.7925, -0.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15835821628570557
Epoch 0, Step 646: train/loss = 0.6818152070045471, train/raw-loss = 0.6669707298278809, train/logprobs = tensor([[-0.5917, -0.6570],
        [-0.7095, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14844442903995514
Epoch 0, Step 647: train/loss = 0.4544658362865448, train/raw-loss = 0.43745970726013184, train/logprobs = tensor([[-0.7454, -2.6541],
        [-0.9094, -0.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700620949268341
Epoch 0, Step 648: train/loss = 0.35916441679000854, train/raw-loss = 0.34353405237197876, train/logprobs = tensor([[-0.6558, -3.1592],
        [-0.7419, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15630385279655457
Epoch 0, Step 649: train/loss = 0.5026164054870605, train/raw-loss = 0.48613211512565613, train/logprobs = tensor([[-0.6848, -1.8697],
        [-0.9429, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16484299302101135
Epoch 0, Step 650: train/loss = 0.4177311658859253, train/raw-loss = 0.39948397874832153, train/logprobs = tensor([[-0.9609, -2.5227],
        [-1.0779, -0.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824716478586197
Epoch 0, Step 651: train/loss = 0.672602117061615, train/raw-loss = 0.6574622988700867, train/logprobs = tensor([[-0.7113, -0.8536],
        [-0.7050, -0.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15139858424663544
Epoch 0, Step 652: train/loss = 0.35359853506088257, train/raw-loss = 0.33841025829315186, train/logprobs = tensor([[-0.8813, -3.1177],
        [-0.9332, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518826186656952
Epoch 0, Step 653: train/loss = 0.6334434747695923, train/raw-loss = 0.6181209683418274, train/logprobs = tensor([[-0.7480, -1.0839],
        [-0.6499, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15322481095790863
Epoch 0, Step 654: train/loss = 0.6669870018959045, train/raw-loss = 0.6519204378128052, train/logprobs = tensor([[-0.6031, -0.7691],
        [-0.6542, -0.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066586434841156
Epoch 0, Step 655: train/loss = 0.5067276358604431, train/raw-loss = 0.48901304602622986, train/logprobs = tensor([[-0.8293, -1.6792],
        [-1.0451, -0.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17714598774909973
Epoch 0, Step 656: train/loss = 0.4107392728328705, train/raw-loss = 0.39661893248558044, train/logprobs = tensor([[-0.6552, -4.6856],
        [-0.8610, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120326936244965
Epoch 0, Step 657: train/loss = 0.5382972359657288, train/raw-loss = 0.5220535397529602, train/logprobs = tensor([[-0.8653, -1.7242],
        [-0.9631, -0.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16243688762187958
Epoch 0, Step 658: train/loss = 0.7345535159111023, train/raw-loss = 0.7158876657485962, train/logprobs = tensor([[-2.4775, -3.4069],
        [-1.6492, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18665850162506104
Epoch 0, Step 659: train/loss = 0.4355027675628662, train/raw-loss = 0.4217609167098999, train/logprobs = tensor([[-0.4850, -2.3276],
        [-0.6220, -0.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13741838932037354
Epoch 0, Step 660: train/loss = 0.5282019376754761, train/raw-loss = 0.5110526084899902, train/logprobs = tensor([[-0.7654, -2.9621],
        [-0.6911, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17149361968040466
Epoch 0, Step 661: train/loss = 0.37670788168907166, train/raw-loss = 0.35901057720184326, train/logprobs = tensor([[-0.7920, -3.6040],
        [-0.9809, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1769728660583496
Epoch 0, Step 662: train/loss = 0.4519895911216736, train/raw-loss = 0.4353976845741272, train/logprobs = tensor([[-0.9348, -2.2652],
        [-1.2403, -0.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16591908037662506
Epoch 0, Step 663: train/loss = 0.4959733188152313, train/raw-loss = 0.47841209173202515, train/logprobs = tensor([[-0.8924, -2.4005],
        [-0.8630, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756119281053543
Epoch 0, Step 664: train/loss = 0.5173438191413879, train/raw-loss = 0.49865320324897766, train/logprobs = tensor([[-0.7216, -1.4479],
        [-1.1369, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18690650165081024
Epoch 0, Step 665: train/loss = 0.37974101305007935, train/raw-loss = 0.3584469258785248, train/logprobs = tensor([[-0.8440, -2.5118],
        [-1.2535, -0.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21294066309928894
Epoch 0, Step 666: train/loss = 0.39875417947769165, train/raw-loss = 0.37988442182540894, train/logprobs = tensor([[-0.9623, -3.3464],
        [-1.2138, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886979341506958
Epoch 0, Step 667: train/loss = 0.6852937936782837, train/raw-loss = 0.6692283153533936, train/logprobs = tensor([[-0.6844, -0.8474],
        [-0.6208, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16065436601638794
Epoch 0, Step 668: train/loss = 0.5027890205383301, train/raw-loss = 0.4862157702445984, train/logprobs = tensor([[-0.9781, -2.6903],
        [-1.0889, -0.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16573229432106018
Epoch 0, Step 669: train/loss = 0.5903823375701904, train/raw-loss = 0.5746282339096069, train/logprobs = tensor([[-1.0497, -1.8733],
        [-0.9313, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15754103660583496
Epoch 0, Step 670: train/loss = 0.498972088098526, train/raw-loss = 0.48181843757629395, train/logprobs = tensor([[-0.5378, -1.7874],
        [-0.7456, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1715363711118698
Epoch 0, Step 671: train/loss = 0.5771992802619934, train/raw-loss = 0.5608088374137878, train/logprobs = tensor([[-0.8315, -2.0532],
        [-0.6950, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16390438377857208
Epoch 0, Step 672: train/loss = 0.45675498247146606, train/raw-loss = 0.43881163001060486, train/logprobs = tensor([[-0.8150, -1.6521],
        [-1.4050, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17943353950977325
Epoch 0, Step 673: train/loss = 0.6097740530967712, train/raw-loss = 0.5945556163787842, train/logprobs = tensor([[-0.8369, -1.5578],
        [-0.6909, -0.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15218475461006165
Epoch 0, Step 674: train/loss = 0.6702057123184204, train/raw-loss = 0.6577101349830627, train/logprobs = tensor([[-0.4652, -0.6652],
        [-0.3763, -0.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12495578825473785
Epoch 0, Step 675: train/loss = 0.5057932138442993, train/raw-loss = 0.4896252453327179, train/logprobs = tensor([[-0.7015, -2.4324],
        [-0.8300, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616799235343933
Epoch 0, Step 676: train/loss = 0.4615674316883087, train/raw-loss = 0.4457809627056122, train/logprobs = tensor([[-0.6134, -4.2592],
        [-0.8206, -0.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15786464512348175
Epoch 0, Step 677: train/loss = 0.505426824092865, train/raw-loss = 0.4909820854663849, train/logprobs = tensor([[-0.4727, -1.9643],
        [-0.5996, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444725215435028
Epoch 0, Step 678: train/loss = 0.5540059804916382, train/raw-loss = 0.5391965508460999, train/logprobs = tensor([[-0.6661, -1.2784],
        [-0.8240, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14809450507164001
Epoch 0, Step 679: train/loss = 0.6183454990386963, train/raw-loss = 0.602397620677948, train/logprobs = tensor([[-0.6812, -1.1602],
        [-0.7034, -0.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15947896242141724
Epoch 0, Step 680: train/loss = 0.5839327573776245, train/raw-loss = 0.5662458539009094, train/logprobs = tensor([[-0.8471, -1.2451],
        [-0.9757, -0.7595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17686942219734192
Epoch 0, Step 681: train/loss = 0.6154667139053345, train/raw-loss = 0.6016279458999634, train/logprobs = tensor([[-0.4764, -0.9586],
        [-0.5779, -0.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383880227804184
Epoch 0, Step 682: train/loss = 0.6692962050437927, train/raw-loss = 0.6502702832221985, train/logprobs = tensor([[-1.1635, -1.4181],
        [-0.7402, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19025932252407074
Epoch 0, Step 683: train/loss = 0.5127791166305542, train/raw-loss = 0.4944528639316559, train/logprobs = tensor([[-0.6843, -1.5319],
        [-0.9260, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18326221406459808
Epoch 0, Step 684: train/loss = 0.5389265418052673, train/raw-loss = 0.5208910703659058, train/logprobs = tensor([[-0.8213, -2.0058],
        [-0.9711, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18035469949245453
Epoch 0, Step 685: train/loss = 0.46386778354644775, train/raw-loss = 0.4475715756416321, train/logprobs = tensor([[-0.6662, -3.0508],
        [-0.7701, -0.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16296231746673584
Epoch 0, Step 686: train/loss = 0.576099693775177, train/raw-loss = 0.5614380240440369, train/logprobs = tensor([[-0.5849, -1.0193],
        [-0.8550, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14661669731140137
Epoch 0, Step 687: train/loss = 0.4750025272369385, train/raw-loss = 0.4586961567401886, train/logprobs = tensor([[-0.5884, -2.4733],
        [-0.9179, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16306383907794952
Epoch 0, Step 688: train/loss = 0.586688756942749, train/raw-loss = 0.573025643825531, train/logprobs = tensor([[-0.5927, -0.7358],
        [-0.8200, -0.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13663102686405182
Epoch 0, Step 689: train/loss = 0.5837718844413757, train/raw-loss = 0.5657695531845093, train/logprobs = tensor([[-1.0750, -1.6980],
        [-1.0764, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18002364039421082
Epoch 0, Step 690: train/loss = 0.45860224962234497, train/raw-loss = 0.44007623195648193, train/logprobs = tensor([[-0.8367, -2.2264],
        [-1.2362, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852598488330841
Epoch 0, Step 691: train/loss = 0.5971488952636719, train/raw-loss = 0.5779255032539368, train/logprobs = tensor([[-1.0536, -1.5901],
        [-1.1391, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19223348796367645
Epoch 0, Step 692: train/loss = 0.5330583453178406, train/raw-loss = 0.5179276466369629, train/logprobs = tensor([[-0.5578, -1.5262],
        [-0.6685, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15130731463432312
Epoch 0, Step 693: train/loss = 0.6319878101348877, train/raw-loss = 0.619096577167511, train/logprobs = tensor([[-0.4828, -0.7707],
        [-0.5277, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12891174852848053
Epoch 0, Step 694: train/loss = 0.5331403613090515, train/raw-loss = 0.5175811648368835, train/logprobs = tensor([[-0.7434, -1.9486],
        [-0.7217, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15559183061122894
Epoch 0, Step 695: train/loss = 0.5708111524581909, train/raw-loss = 0.5568552017211914, train/logprobs = tensor([[-0.6104, -3.3756],
        [-0.6152, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13955947756767273
Epoch 0, Step 696: train/loss = 0.5892058610916138, train/raw-loss = 0.5716455578804016, train/logprobs = tensor([[-0.8734, -1.1194],
        [-1.1286, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756029725074768
Epoch 0, Step 697: train/loss = 0.5483654141426086, train/raw-loss = 0.5333734154701233, train/logprobs = tensor([[-0.5438, -1.8815],
        [-0.7955, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14992007613182068
Epoch 0, Step 698: train/loss = 0.5102624893188477, train/raw-loss = 0.4937787652015686, train/logprobs = tensor([[-0.6713, -3.4974],
        [-0.7501, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648367941379547
Epoch 0, Step 699: train/loss = 0.513958215713501, train/raw-loss = 0.49667632579803467, train/logprobs = tensor([[-0.6583, -1.7762],
        [-0.8235, -0.6632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17281894385814667
Epoch 0, Step 700: train/loss = 0.5545052886009216, train/raw-loss = 0.5363218188285828, train/logprobs = tensor([[-0.7655, -1.6975],
        [-0.8011, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18183442950248718
Epoch 0, Step 701: train/loss = 0.47999247908592224, train/raw-loss = 0.46468058228492737, train/logprobs = tensor([[-0.7578, -2.8980],
        [-0.7395, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1531190276145935
Epoch 0, Step 702: train/loss = 0.49683672189712524, train/raw-loss = 0.47941818833351135, train/logprobs = tensor([[-0.6270, -1.5397],
        [-0.9049, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17418526113033295
Epoch 0, Step 703: train/loss = 0.4350156784057617, train/raw-loss = 0.41833630204200745, train/logprobs = tensor([[-0.7192, -2.6547],
        [-0.7056, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1667938232421875
Epoch 0, Step 704: train/loss = 0.49331140518188477, train/raw-loss = 0.4772323966026306, train/logprobs = tensor([[-0.6027, -2.0629],
        [-0.7864, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16078974306583405
Epoch 0, Step 705: train/loss = 0.6643820405006409, train/raw-loss = 0.6488875150680542, train/logprobs = tensor([[-0.4133, -0.5979],
        [-0.6198, -0.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549447923898697
Epoch 0, Step 706: train/loss = 0.3955629765987396, train/raw-loss = 0.37708401679992676, train/logprobs = tensor([[-1.0675, -3.5360],
        [-1.0458, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18478992581367493
Epoch 0, Step 707: train/loss = 0.3959929347038269, train/raw-loss = 0.3801034092903137, train/logprobs = tensor([[-0.7085, -2.2606],
        [-1.0322, -0.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588953137397766
Epoch 0, Step 708: train/loss = 0.4625144600868225, train/raw-loss = 0.44381195306777954, train/logprobs = tensor([[-0.8157, -1.2874],
        [-1.4067, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18702489137649536
Epoch 0, Step 709: train/loss = 0.5726066827774048, train/raw-loss = 0.5571926236152649, train/logprobs = tensor([[-0.5092, -1.2526],
        [-0.7911, -0.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15414035320281982
Epoch 0, Step 710: train/loss = 0.44787025451660156, train/raw-loss = 0.4320363402366638, train/logprobs = tensor([[-0.7835, -2.3997],
        [-0.9056, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15833903849124908
Epoch 0, Step 711: train/loss = 0.6295316219329834, train/raw-loss = 0.6153826713562012, train/logprobs = tensor([[-0.6364, -0.7265],
        [-0.8091, -0.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14148929715156555
Epoch 0, Step 712: train/loss = 0.5436533093452454, train/raw-loss = 0.5271115303039551, train/logprobs = tensor([[-0.6071, -1.5439],
        [-0.8586, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16541770100593567
Epoch 0, Step 713: train/loss = 0.6731988191604614, train/raw-loss = 0.6577116250991821, train/logprobs = tensor([[-0.5399, -0.7101],
        [-0.6539, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1548718959093094
Epoch 0, Step 714: train/loss = 0.6269969344139099, train/raw-loss = 0.609796941280365, train/logprobs = tensor([[-0.8852, -1.1257],
        [-0.8336, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17200027406215668
Epoch 0, Step 715: train/loss = 0.5258747339248657, train/raw-loss = 0.5061957836151123, train/logprobs = tensor([[-0.7101, -1.6719],
        [-0.9782, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19678853452205658
Epoch 0, Step 716: train/loss = 0.41792139410972595, train/raw-loss = 0.39808106422424316, train/logprobs = tensor([[-1.0846, -2.8363],
        [-1.3641, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19840320944786072
Epoch 0, Step 717: train/loss = 0.4423632025718689, train/raw-loss = 0.42449110746383667, train/logprobs = tensor([[-0.5740, -2.4314],
        [-0.8392, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17872105538845062
Epoch 0, Step 718: train/loss = 0.5325571298599243, train/raw-loss = 0.5155394077301025, train/logprobs = tensor([[-0.5354, -2.1130],
        [-0.7194, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17017705738544464
Epoch 0, Step 719: train/loss = 0.698483407497406, train/raw-loss = 0.6782707571983337, train/logprobs = tensor([[-1.4475, -1.7111],
        [-0.9008, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021263986825943
Epoch 0, Step 720: train/loss = 0.526118814945221, train/raw-loss = 0.5096946358680725, train/logprobs = tensor([[-0.5867, -1.8650],
        [-0.7863, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1642417013645172
Epoch 0, Step 721: train/loss = 0.5437296628952026, train/raw-loss = 0.5259631276130676, train/logprobs = tensor([[-0.9132, -2.1005],
        [-1.1458, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17766517400741577
Epoch 0, Step 722: train/loss = 0.4774954319000244, train/raw-loss = 0.4600529968738556, train/logprobs = tensor([[-0.8812, -2.8307],
        [-1.0359, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17442460358142853
Epoch 0, Step 723: train/loss = 0.574203610420227, train/raw-loss = 0.5569974184036255, train/logprobs = tensor([[-0.8784, -1.7946],
        [-0.8913, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17206218838691711
Epoch 0, Step 724: train/loss = 0.542083740234375, train/raw-loss = 0.5242780447006226, train/logprobs = tensor([[-0.6798, -1.6260],
        [-0.7959, -0.7282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17805637419223785
Epoch 0, Step 725: train/loss = 0.6079539060592651, train/raw-loss = 0.592566967010498, train/logprobs = tensor([[-0.6654, -0.9989],
        [-0.7525, -0.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15386979281902313
Epoch 0, Step 726: train/loss = 0.49792397022247314, train/raw-loss = 0.4798373878002167, train/logprobs = tensor([[-0.6852, -1.8381],
        [-0.8357, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18086586892604828
Epoch 0, Step 727: train/loss = 0.549218475818634, train/raw-loss = 0.5322206020355225, train/logprobs = tensor([[-1.4626, -2.7281],
        [-1.2841, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16997851431369781
Epoch 0, Step 728: train/loss = 0.424441933631897, train/raw-loss = 0.4042903780937195, train/logprobs = tensor([[-0.9340, -2.2183],
        [-1.2277, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20151562988758087
Epoch 0, Step 729: train/loss = 0.5552921295166016, train/raw-loss = 0.5395210981369019, train/logprobs = tensor([[-0.8256, -1.5164],
        [-0.8956, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15771064162254333
Epoch 0, Step 730: train/loss = 0.5736241340637207, train/raw-loss = 0.557023823261261, train/logprobs = tensor([[-0.8512, -1.5486],
        [-0.8616, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16600361466407776
Epoch 0, Step 731: train/loss = 0.45326244831085205, train/raw-loss = 0.4323950409889221, train/logprobs = tensor([[-0.6523, -2.3270],
        [-1.0359, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20867416262626648
Epoch 0, Step 732: train/loss = 0.5987892746925354, train/raw-loss = 0.5791789293289185, train/logprobs = tensor([[-0.7373, -1.0794],
        [-1.0090, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1961035132408142
Epoch 0, Step 733: train/loss = 0.700141429901123, train/raw-loss = 0.6838001012802124, train/logprobs = tensor([[-0.7175, -0.7053],
        [-0.7791, -0.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16341423988342285
Epoch 0, Step 734: train/loss = 0.6642151474952698, train/raw-loss = 0.6506888270378113, train/logprobs = tensor([[-0.6220, -0.6151],
        [-0.7124, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13526365160942078
Epoch 0, Step 735: train/loss = 0.5919345021247864, train/raw-loss = 0.5756608247756958, train/logprobs = tensor([[-0.8613, -1.0778],
        [-1.0732, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16273680329322815
Epoch 0, Step 736: train/loss = 0.45540645718574524, train/raw-loss = 0.4365640878677368, train/logprobs = tensor([[-0.7524, -2.3915],
        [-1.0140, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188423752784729
Epoch 0, Step 737: train/loss = 0.5230421423912048, train/raw-loss = 0.5025128126144409, train/logprobs = tensor([[-0.5925, -1.6451],
        [-1.0127, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20529350638389587
Epoch 0, Step 738: train/loss = 0.4022015333175659, train/raw-loss = 0.384280264377594, train/logprobs = tensor([[-0.9581, -5.3296],
        [-1.0106, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1792128086090088
Epoch 0, Step 739: train/loss = 0.5523273348808289, train/raw-loss = 0.5300907492637634, train/logprobs = tensor([[-0.8987, -1.7585],
        [-1.1077, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22236588597297668
Epoch 0, Step 740: train/loss = 0.31218209862709045, train/raw-loss = 0.2940192222595215, train/logprobs = tensor([[-0.6649, -4.7975],
        [-1.2044, -0.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18162868916988373
Epoch 0, Step 741: train/loss = 0.36022698879241943, train/raw-loss = 0.3351013958454132, train/logprobs = tensor([[-0.7470, -2.6527],
        [-1.7639, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512558698654175
Epoch 0, Step 742: train/loss = 0.559037446975708, train/raw-loss = 0.5402718186378479, train/logprobs = tensor([[-0.6619, -1.3186],
        [-0.8655, -0.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18765631318092346
Epoch 0, Step 743: train/loss = 0.553271472454071, train/raw-loss = 0.5326734781265259, train/logprobs = tensor([[-1.1965, -2.8245],
        [-1.0009, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20597945153713226
Epoch 0, Step 744: train/loss = 0.5595898032188416, train/raw-loss = 0.5413692593574524, train/logprobs = tensor([[-0.5949, -1.9363],
        [-0.9113, -0.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18220505118370056
Epoch 0, Step 745: train/loss = 0.42235612869262695, train/raw-loss = 0.4014817774295807, train/logprobs = tensor([[-0.8419, -3.8993],
        [-1.2578, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20874324440956116
Epoch 0, Step 746: train/loss = 0.5851502418518066, train/raw-loss = 0.5656337738037109, train/logprobs = tensor([[-1.2825, -2.6475],
        [-0.9178, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19516441226005554
Epoch 0, Step 747: train/loss = 0.5555579662322998, train/raw-loss = 0.5343388319015503, train/logprobs = tensor([[-0.8387, -1.2721],
        [-1.1315, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21219074726104736
Epoch 0, Step 748: train/loss = 0.4593305289745331, train/raw-loss = 0.4397585093975067, train/logprobs = tensor([[-0.7644, -2.3963],
        [-0.9026, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572073221206665
Epoch 0, Step 749: train/loss = 0.5354628562927246, train/raw-loss = 0.5158576965332031, train/logprobs = tensor([[-0.9672, -2.1453],
        [-1.1051, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19605132937431335
Epoch 0, Step 750: train/loss = 0.5495533347129822, train/raw-loss = 0.5321831703186035, train/logprobs = tensor([[-0.8204, -1.8594],
        [-0.9758, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17370200157165527
Epoch 0, Step 751: train/loss = 0.35199201107025146, train/raw-loss = 0.3325251042842865, train/logprobs = tensor([[-0.9249, -3.7918],
        [-1.0523, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19466876983642578
Epoch 0, Step 752: train/loss = 0.29325538873672485, train/raw-loss = 0.27339720726013184, train/logprobs = tensor([[-0.7362, -3.8071],
        [-1.3722, -0.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858184456825256
Epoch 0, Step 753: train/loss = 0.689139187335968, train/raw-loss = 0.6719985604286194, train/logprobs = tensor([[-0.5919, -0.6361],
        [-0.7003, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17140623927116394
Epoch 0, Step 754: train/loss = 0.354396790266037, train/raw-loss = 0.3331209123134613, train/logprobs = tensor([[-0.8677, -3.5419],
        [-1.1924, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21275894343852997
Epoch 0, Step 755: train/loss = 0.5257149934768677, train/raw-loss = 0.5072016716003418, train/logprobs = tensor([[-0.9630, -3.5065],
        [-1.0906, -0.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18513277173042297
Epoch 0, Step 756: train/loss = 0.49841970205307007, train/raw-loss = 0.47927024960517883, train/logprobs = tensor([[-0.9714, -1.9811],
        [-0.9727, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19149446487426758
Epoch 0, Step 757: train/loss = 0.38596948981285095, train/raw-loss = 0.3665429353713989, train/logprobs = tensor([[-0.9675, -4.7733],
        [-1.2160, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19426563382148743
Epoch 0, Step 758: train/loss = 0.41357386112213135, train/raw-loss = 0.3935023546218872, train/logprobs = tensor([[-0.6600, -2.9635],
        [-0.9785, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20071500539779663
Epoch 0, Step 759: train/loss = 0.46579045057296753, train/raw-loss = 0.4477490782737732, train/logprobs = tensor([[-1.3691, -2.9099],
        [-1.1598, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18041375279426575
Epoch 0, Step 760: train/loss = 0.7073689103126526, train/raw-loss = 0.6873942613601685, train/logprobs = tensor([[-0.6573, -0.6631],
        [-0.7817, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19974671304225922
Epoch 0, Step 761: train/loss = 0.655042290687561, train/raw-loss = 0.6350125074386597, train/logprobs = tensor([[-1.8670, -3.1817],
        [-0.8370, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2002979964017868
Epoch 0, Step 762: train/loss = 0.3959447145462036, train/raw-loss = 0.37185266613960266, train/logprobs = tensor([[-0.8846, -1.9641],
        [-1.6041, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24092049896717072
Epoch 0, Step 763: train/loss = 0.5436220169067383, train/raw-loss = 0.5253374576568604, train/logprobs = tensor([[-0.7736, -2.1691],
        [-0.8459, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284542858600616
Epoch 0, Step 764: train/loss = 0.5530865788459778, train/raw-loss = 0.5366731286048889, train/logprobs = tensor([[-0.5850, -2.2480],
        [-0.6373, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16413410007953644
Epoch 0, Step 765: train/loss = 0.7123880982398987, train/raw-loss = 0.6950218677520752, train/logprobs = tensor([[-0.8945, -1.0460],
        [-0.6822, -0.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366230487823486
Epoch 0, Step 766: train/loss = 0.7492296695709229, train/raw-loss = 0.7309730052947998, train/logprobs = tensor([[-2.1364, -3.3925],
        [-0.9662, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18256647884845734
Epoch 0, Step 767: train/loss = 0.6611579656600952, train/raw-loss = 0.6446257829666138, train/logprobs = tensor([[-0.6230, -0.9620],
        [-0.8269, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16532184183597565
Epoch 0, Step 768: train/loss = 0.43538081645965576, train/raw-loss = 0.41731661558151245, train/logprobs = tensor([[-0.6485, -3.7166],
        [-0.8402, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1806420385837555
Epoch 0, Step 769: train/loss = 0.5937199592590332, train/raw-loss = 0.5721566081047058, train/logprobs = tensor([[-0.5939, -1.2513],
        [-0.9854, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156333029270172
Epoch 0, Step 770: train/loss = 0.5157959461212158, train/raw-loss = 0.49589288234710693, train/logprobs = tensor([[-0.6379, -2.4141],
        [-0.8951, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903074204921722
Epoch 0, Step 771: train/loss = 0.39741051197052, train/raw-loss = 0.37574923038482666, train/logprobs = tensor([[-0.7248, -3.3823],
        [-0.9599, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21661260724067688
Epoch 0, Step 772: train/loss = 0.3596372604370117, train/raw-loss = 0.33763009309768677, train/logprobs = tensor([[-0.7972, -2.5333],
        [-1.4994, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22007140517234802
Epoch 0, Step 773: train/loss = 0.6191442012786865, train/raw-loss = 0.5991487503051758, train/logprobs = tensor([[-1.2705, -2.5016],
        [-0.7257, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19995485246181488
Epoch 0, Step 774: train/loss = 0.6196145415306091, train/raw-loss = 0.5962184071540833, train/logprobs = tensor([[-0.9795, -1.9797],
        [-1.0226, -1.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23396123945713043
Epoch 0, Step 775: train/loss = 0.5944536924362183, train/raw-loss = 0.5748379826545715, train/logprobs = tensor([[-0.6805, -1.2911],
        [-0.9023, -0.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1961573362350464
Epoch 0, Step 776: train/loss = 0.5840474963188171, train/raw-loss = 0.5657438635826111, train/logprobs = tensor([[-0.4623, -0.7795],
        [-0.9114, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18303659558296204
Epoch 0, Step 777: train/loss = 0.4353506565093994, train/raw-loss = 0.41633909940719604, train/logprobs = tensor([[-0.5744, -5.0442],
        [-0.8386, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19011501967906952
Epoch 0, Step 778: train/loss = 0.7523193359375, train/raw-loss = 0.7325429320335388, train/logprobs = tensor([[-1.9097, -2.8084],
        [-0.9897, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977648138999939
Epoch 0, Step 779: train/loss = 0.5221467018127441, train/raw-loss = 0.49857383966445923, train/logprobs = tensor([[-0.6314, -1.4236],
        [-1.2123, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23572896420955658
Epoch 0, Step 780: train/loss = 0.5358636975288391, train/raw-loss = 0.5161285996437073, train/logprobs = tensor([[-1.0019, -1.7356],
        [-1.1831, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1973508894443512
Epoch 0, Step 781: train/loss = 0.39578771591186523, train/raw-loss = 0.3759046196937561, train/logprobs = tensor([[-0.5959, -3.3208],
        [-1.0378, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.198831245303154
Epoch 0, Step 782: train/loss = 0.3827052116394043, train/raw-loss = 0.36081036925315857, train/logprobs = tensor([[-0.7242, -3.3477],
        [-1.0283, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21894852817058563
Epoch 0, Step 783: train/loss = 0.5950325727462769, train/raw-loss = 0.5743703842163086, train/logprobs = tensor([[-0.5836, -1.7702],
        [-0.7904, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066219449043274
Epoch 0, Step 784: train/loss = 0.34642407298088074, train/raw-loss = 0.3261744976043701, train/logprobs = tensor([[-0.9801, -4.6389],
        [-1.2195, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20249556005001068
Epoch 0, Step 785: train/loss = 0.5593589544296265, train/raw-loss = 0.5412424802780151, train/logprobs = tensor([[-0.8929, -1.9403],
        [-0.9630, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18116483092308044
Epoch 0, Step 786: train/loss = 0.3541162610054016, train/raw-loss = 0.3350293040275574, train/logprobs = tensor([[-0.5556, -4.3951],
        [-0.9326, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19086937606334686
Epoch 0, Step 787: train/loss = 0.4210510551929474, train/raw-loss = 0.4042195677757263, train/logprobs = tensor([[-0.6592, -5.2044],
        [-0.9800, -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16831451654434204
Epoch 0, Step 788: train/loss = 0.47561997175216675, train/raw-loss = 0.4547216296195984, train/logprobs = tensor([[-0.7278, -2.5609],
        [-1.0179, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20898349583148956
Epoch 0, Step 789: train/loss = 0.4463686943054199, train/raw-loss = 0.4276200830936432, train/logprobs = tensor([[-1.1271, -3.8101],
        [-0.8623, -0.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18748609721660614
Epoch 0, Step 790: train/loss = 0.5740199089050293, train/raw-loss = 0.5568114519119263, train/logprobs = tensor([[-0.9939, -2.9804],
        [-0.8569, -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17208467423915863
Epoch 0, Step 791: train/loss = 0.6171900033950806, train/raw-loss = 0.5963521599769592, train/logprobs = tensor([[-0.8982, -0.9827],
        [-1.1553, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20837850868701935
Epoch 0, Step 792: train/loss = 0.4641261696815491, train/raw-loss = 0.44440194964408875, train/logprobs = tensor([[-0.7830, -2.4700],
        [-0.7653, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19724182784557343
Epoch 0, Step 793: train/loss = 0.675879180431366, train/raw-loss = 0.657661497592926, train/logprobs = tensor([[-0.4388, -0.6697],
        [-0.7017, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18217623233795166
Epoch 0, Step 794: train/loss = 0.46136942505836487, train/raw-loss = 0.43807709217071533, train/logprobs = tensor([[-0.9378, -1.9038],
        [-1.5806, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23292326927185059
Epoch 0, Step 795: train/loss = 0.4698038697242737, train/raw-loss = 0.4492678642272949, train/logprobs = tensor([[-0.8853, -2.6220],
        [-1.2647, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053600698709488
Epoch 0, Step 796: train/loss = 0.5240381956100464, train/raw-loss = 0.50449538230896, train/logprobs = tensor([[-0.6680, -1.4594],
        [-0.9344, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19542796909809113
Epoch 0, Step 797: train/loss = 0.5683191418647766, train/raw-loss = 0.5493881702423096, train/logprobs = tensor([[-0.5354, -3.8110],
        [-1.1169, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18930956721305847
Epoch 0, Step 798: train/loss = 0.5198956727981567, train/raw-loss = 0.4975549876689911, train/logprobs = tensor([[-0.8331, -2.3979],
        [-1.1554, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22340700030326843
Epoch 0, Step 799: train/loss = 0.48256227374076843, train/raw-loss = 0.46460258960723877, train/logprobs = tensor([[-0.7265, -1.7581],
        [-0.9488, -0.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179596945643425
Epoch 0, Step 800: train/loss = 0.40509000420570374, train/raw-loss = 0.38709941506385803, train/logprobs = tensor([[-0.6328, -3.3249],
        [-0.8887, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799057126045227
Epoch 0, Step 801: train/loss = 0.6287301182746887, train/raw-loss = 0.6067232489585876, train/logprobs = tensor([[-0.7422, -1.2709],
        [-1.2224, -1.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200690656900406
Epoch 0, Step 802: train/loss = 0.45877474546432495, train/raw-loss = 0.4375312626361847, train/logprobs = tensor([[-0.6076, -2.2203],
        [-1.0498, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21243499219417572
Epoch 0, Step 803: train/loss = 0.4936690330505371, train/raw-loss = 0.4737069010734558, train/logprobs = tensor([[-0.6962, -1.9215],
        [-1.0570, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996208131313324
Epoch 0, Step 804: train/loss = 0.39509665966033936, train/raw-loss = 0.37634584307670593, train/logprobs = tensor([[-0.9542, -4.5623],
        [-0.9385, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1875082403421402
Epoch 0, Step 805: train/loss = 0.4985171854496002, train/raw-loss = 0.4763219356536865, train/logprobs = tensor([[-0.9777, -2.3093],
        [-1.0984, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22195212543010712
Epoch 0, Step 806: train/loss = 0.5224044322967529, train/raw-loss = 0.5034462213516235, train/logprobs = tensor([[-0.6819, -2.8797],
        [-0.9472, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18958231806755066
Epoch 0, Step 807: train/loss = 0.5328879356384277, train/raw-loss = 0.5123573541641235, train/logprobs = tensor([[-0.6760, -1.6541],
        [-0.9132, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053060233592987
Epoch 0, Step 808: train/loss = 0.5288746953010559, train/raw-loss = 0.5097384452819824, train/logprobs = tensor([[-0.4979, -1.6014],
        [-0.8540, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19136252999305725
Epoch 0, Step 809: train/loss = 0.6235670447349548, train/raw-loss = 0.6014728546142578, train/logprobs = tensor([[-0.7355, -1.1716],
        [-0.7397, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094202041625977
Epoch 0, Step 810: train/loss = 0.4697824716567993, train/raw-loss = 0.44866156578063965, train/logprobs = tensor([[-0.8266, -2.9653],
        [-1.0045, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21120911836624146
Epoch 0, Step 811: train/loss = 0.6259158849716187, train/raw-loss = 0.6085423231124878, train/logprobs = tensor([[-0.6332, -1.2213],
        [-0.7672, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737356185913086
Epoch 0, Step 812: train/loss = 0.5857359766960144, train/raw-loss = 0.5643292665481567, train/logprobs = tensor([[-0.5450, -0.9669],
        [-1.0855, -0.7976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21406756341457367
Epoch 0, Step 813: train/loss = 0.3732340931892395, train/raw-loss = 0.35353049635887146, train/logprobs = tensor([[-0.9768, -4.9478],
        [-1.2441, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1970357745885849
Epoch 0, Step 814: train/loss = 0.4850904643535614, train/raw-loss = 0.46040529012680054, train/logprobs = tensor([[-0.8345, -2.7743],
        [-1.3857, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468518316745758
Epoch 0, Step 815: train/loss = 0.3729422688484192, train/raw-loss = 0.3533403277397156, train/logprobs = tensor([[-0.7384, -3.3182],
        [-1.0132, -1.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19601963460445404
Epoch 0, Step 816: train/loss = 0.7080422639846802, train/raw-loss = 0.6870207786560059, train/logprobs = tensor([[-1.6160, -1.6675],
        [-1.0208, -0.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21021512150764465
Epoch 0, Step 817: train/loss = 0.5310825109481812, train/raw-loss = 0.509164035320282, train/logprobs = tensor([[-0.6215, -2.6483],
        [-0.9909, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21918506920337677
Epoch 0, Step 818: train/loss = 0.6369180083274841, train/raw-loss = 0.6127170920372009, train/logprobs = tensor([[-1.1497, -1.4605],
        [-1.0224, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.242008775472641
Epoch 0, Step 819: train/loss = 0.6187960505485535, train/raw-loss = 0.5985844135284424, train/logprobs = tensor([[-0.9047, -1.3387],
        [-0.7465, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021164745092392
Epoch 0, Step 820: train/loss = 0.6106514930725098, train/raw-loss = 0.590015172958374, train/logprobs = tensor([[-0.6178, -1.4803],
        [-0.8074, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20636379718780518
Epoch 0, Step 821: train/loss = 0.256860613822937, train/raw-loss = 0.23201066255569458, train/logprobs = tensor([[-0.7841, -3.9959],
        [-1.7787, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24849916994571686
Epoch 0, Step 822: train/loss = 0.4270268976688385, train/raw-loss = 0.4064084589481354, train/logprobs = tensor([[-1.2848, -4.1961],
        [-1.2057, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20618495345115662
Epoch 0, Step 823: train/loss = 0.6112039685249329, train/raw-loss = 0.593155026435852, train/logprobs = tensor([[-0.5895, -1.0783],
        [-0.6444, -0.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18048922717571259
Epoch 0, Step 824: train/loss = 0.4787266254425049, train/raw-loss = 0.45767027139663696, train/logprobs = tensor([[-0.8663, -2.2387],
        [-0.9172, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2105633169412613
Epoch 0, Step 825: train/loss = 0.414870947599411, train/raw-loss = 0.39534950256347656, train/logprobs = tensor([[-0.6149, -4.9877],
        [-1.2420, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1952146589756012
Epoch 0, Step 826: train/loss = 0.7666158080101013, train/raw-loss = 0.7463473081588745, train/logprobs = tensor([[-1.9676, -2.4824],
        [-1.1076, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20268523693084717
Epoch 0, Step 827: train/loss = 0.6046944260597229, train/raw-loss = 0.5855938196182251, train/logprobs = tensor([[-0.5983, -1.3762],
        [-0.8303, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191005676984787
Epoch 0, Step 828: train/loss = 0.625542938709259, train/raw-loss = 0.6006491184234619, train/logprobs = tensor([[-0.8964, -1.6822],
        [-0.9750, -0.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489386945962906
Epoch 0, Step 829: train/loss = 0.48580724000930786, train/raw-loss = 0.46698591113090515, train/logprobs = tensor([[-0.9668, -2.1903],
        [-0.9380, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188213050365448
Epoch 0, Step 830: train/loss = 0.6475986242294312, train/raw-loss = 0.6257021427154541, train/logprobs = tensor([[-0.7629, -1.0454],
        [-0.8801, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21896445751190186
Epoch 0, Step 831: train/loss = 0.6851503849029541, train/raw-loss = 0.665026068687439, train/logprobs = tensor([[-0.6772, -0.8483],
        [-0.8713, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20124341547489166
Epoch 0, Step 832: train/loss = 0.4117897152900696, train/raw-loss = 0.38922345638275146, train/logprobs = tensor([[-0.6956, -2.8730],
        [-1.0170, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22566264867782593
Epoch 0, Step 833: train/loss = 0.7760826349258423, train/raw-loss = 0.7557748556137085, train/logprobs = tensor([[-1.2749, -1.2350],
        [-0.7859, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20307788252830505
Epoch 0, Step 834: train/loss = 0.5405462980270386, train/raw-loss = 0.5208079218864441, train/logprobs = tensor([[-0.9114, -2.8196],
        [-0.7908, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738346338272095
Epoch 0, Step 835: train/loss = 0.6731862425804138, train/raw-loss = 0.6497377157211304, train/logprobs = tensor([[-0.9240, -1.0075],
        [-1.0896, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23448461294174194
Epoch 0, Step 836: train/loss = 0.5348115563392639, train/raw-loss = 0.5136061906814575, train/logprobs = tensor([[-0.4999, -1.4030],
        [-1.0298, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21205338835716248
Epoch 0, Step 837: train/loss = 0.4752810597419739, train/raw-loss = 0.4550105035305023, train/logprobs = tensor([[-0.6039, -3.6668],
        [-0.9232, -0.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20270556211471558
Epoch 0, Step 838: train/loss = 0.6170237064361572, train/raw-loss = 0.5957797765731812, train/logprobs = tensor([[-1.1127, -2.2782],
        [-1.0653, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21243958175182343
Epoch 0, Step 839: train/loss = 0.6228864192962646, train/raw-loss = 0.5998402237892151, train/logprobs = tensor([[-1.0648, -1.6868],
        [-0.8351, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23046226799488068
Epoch 0, Step 840: train/loss = 0.6576822400093079, train/raw-loss = 0.6342759132385254, train/logprobs = tensor([[-0.7557, -1.1529],
        [-0.9150, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340630739927292
Epoch 0, Step 841: train/loss = 0.7761620283126831, train/raw-loss = 0.7518420219421387, train/logprobs = tensor([[-2.5218, -2.8670],
        [-1.5639, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2432001829147339
Epoch 0, Step 842: train/loss = 0.49066779017448425, train/raw-loss = 0.46786782145500183, train/logprobs = tensor([[-1.1969, -4.8189],
        [-1.4743, -0.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22799992561340332
Epoch 0, Step 843: train/loss = 0.4113004207611084, train/raw-loss = 0.3860914409160614, train/logprobs = tensor([[-0.8535, -2.7908],
        [-1.2947, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25208985805511475
Epoch 0, Step 844: train/loss = 0.3484339714050293, train/raw-loss = 0.325713574886322, train/logprobs = tensor([[-1.0501, -2.8751],
        [-1.6458, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2272038459777832
Epoch 0, Step 845: train/loss = 0.39388418197631836, train/raw-loss = 0.37362056970596313, train/logprobs = tensor([[-0.7717, -3.2240],
        [-1.1515, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263591408729553
Epoch 0, Step 846: train/loss = 0.47068801522254944, train/raw-loss = 0.44671523571014404, train/logprobs = tensor([[-0.5119, -2.1335],
        [-1.0138, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23972752690315247
Epoch 0, Step 847: train/loss = 0.4451902508735657, train/raw-loss = 0.42146241664886475, train/logprobs = tensor([[-1.1169, -3.2994],
        [-1.1345, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23727849125862122
Epoch 0, Step 848: train/loss = 0.5153453350067139, train/raw-loss = 0.49327152967453003, train/logprobs = tensor([[-0.6409, -1.2545],
        [-1.1455, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22073806822299957
Epoch 0, Step 849: train/loss = 0.49939870834350586, train/raw-loss = 0.4741475582122803, train/logprobs = tensor([[-0.9968, -2.8139],
        [-1.1333, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252511590719223
Epoch 0, Step 850: train/loss = 0.5821545124053955, train/raw-loss = 0.5621044039726257, train/logprobs = tensor([[-0.8656, -1.4400],
        [-0.8765, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005011886358261
Epoch 0, Step 851: train/loss = 0.4074365496635437, train/raw-loss = 0.38704898953437805, train/logprobs = tensor([[-0.7115, -2.5644],
        [-1.2093, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20387564599514008
Epoch 0, Step 852: train/loss = 0.5426645874977112, train/raw-loss = 0.5189387202262878, train/logprobs = tensor([[-0.6778, -1.6861],
        [-1.1616, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23725834488868713
Epoch 0, Step 853: train/loss = 0.43578988313674927, train/raw-loss = 0.4160105288028717, train/logprobs = tensor([[-0.6279, -3.1748],
        [-0.6490, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977933645248413
Epoch 0, Step 854: train/loss = 0.4186941087245941, train/raw-loss = 0.3972397446632385, train/logprobs = tensor([[-0.6732, -2.2301],
        [-1.0353, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145436704158783
Epoch 0, Step 855: train/loss = 0.6070353984832764, train/raw-loss = 0.5886700749397278, train/logprobs = tensor([[-0.5334, -1.0706],
        [-0.6041, -0.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1836535483598709
Epoch 0, Step 856: train/loss = 0.6398860812187195, train/raw-loss = 0.6186617016792297, train/logprobs = tensor([[-0.6462, -0.8479],
        [-0.8257, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122437059879303
Epoch 0, Step 857: train/loss = 0.5994949340820312, train/raw-loss = 0.5794285535812378, train/logprobs = tensor([[-0.7674, -1.3197],
        [-0.7186, -0.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200664222240448
Epoch 0, Step 858: train/loss = 0.6226593255996704, train/raw-loss = 0.6057623028755188, train/logprobs = tensor([[-0.3429, -0.8664],
        [-0.4921, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16896960139274597
Epoch 0, Step 859: train/loss = 0.3628309369087219, train/raw-loss = 0.33722418546676636, train/logprobs = tensor([[-1.0684, -4.0265],
        [-1.4407, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25606775283813477
Epoch 0, Step 860: train/loss = 0.5779870748519897, train/raw-loss = 0.5572656989097595, train/logprobs = tensor([[-0.6315, -1.5912],
        [-0.9260, -1.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20721346139907837
Epoch 0, Step 861: train/loss = 0.38025224208831787, train/raw-loss = 0.3565557897090912, train/logprobs = tensor([[-1.0380, -5.0233],
        [-1.3592, -0.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23696449398994446
Epoch 0, Step 862: train/loss = 0.49349135160446167, train/raw-loss = 0.4729618430137634, train/logprobs = tensor([[-0.7958, -2.3755],
        [-0.9581, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052951455116272
Epoch 0, Step 863: train/loss = 0.5435518026351929, train/raw-loss = 0.5218152403831482, train/logprobs = tensor([[-0.5910, -1.9238],
        [-0.9510, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21736526489257812
Epoch 0, Step 864: train/loss = 0.4449547529220581, train/raw-loss = 0.4269651174545288, train/logprobs = tensor([[-0.5824, -2.4952],
        [-0.8476, -0.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17989662289619446
Epoch 0, Step 865: train/loss = 0.4904460608959198, train/raw-loss = 0.46581754088401794, train/logprobs = tensor([[-1.0051, -3.0201],
        [-1.1646, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24628517031669617
Epoch 0, Step 866: train/loss = 0.6698044538497925, train/raw-loss = 0.6474953889846802, train/logprobs = tensor([[-1.6473, -3.1374],
        [-0.8082, -0.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22309058904647827
Epoch 0, Step 867: train/loss = 0.4026496410369873, train/raw-loss = 0.38387012481689453, train/logprobs = tensor([[-0.6980, -4.0281],
        [-0.8271, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18779535591602325
Epoch 0, Step 868: train/loss = 0.5224478244781494, train/raw-loss = 0.5018519163131714, train/logprobs = tensor([[-0.8953, -2.8066],
        [-0.9213, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20595932006835938
Epoch 0, Step 869: train/loss = 0.3264704644680023, train/raw-loss = 0.3050762712955475, train/logprobs = tensor([[-0.7635, -4.4275],
        [-1.4682, -0.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21394199132919312
Epoch 0, Step 870: train/loss = 0.5146090984344482, train/raw-loss = 0.49029093980789185, train/logprobs = tensor([[-0.5899, -1.5738],
        [-0.9866, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24318191409111023
Epoch 0, Step 871: train/loss = 0.4697054326534271, train/raw-loss = 0.45234814286231995, train/logprobs = tensor([[-0.5417, -2.8476],
        [-0.7209, -0.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17357276380062103
Epoch 0, Step 872: train/loss = 0.6144449710845947, train/raw-loss = 0.5952003002166748, train/logprobs = tensor([[-0.5248, -1.1072],
        [-0.7147, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19244684278964996
Epoch 0, Step 873: train/loss = 0.6132930517196655, train/raw-loss = 0.5908493995666504, train/logprobs = tensor([[-1.3352, -2.7779],
        [-1.0686, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22443678975105286
Epoch 0, Step 874: train/loss = 0.543290376663208, train/raw-loss = 0.5202924013137817, train/logprobs = tensor([[-0.8479, -1.7061],
        [-0.9004, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2299794852733612
Epoch 0, Step 875: train/loss = 0.3974713385105133, train/raw-loss = 0.38109004497528076, train/logprobs = tensor([[-0.7641, -4.3569],
        [-0.7057, -0.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16381290555000305
Epoch 0, Step 876: train/loss = 0.29747965931892395, train/raw-loss = 0.2763633728027344, train/logprobs = tensor([[-1.0096, -4.1879],
        [-1.2969, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2111627161502838
Epoch 0, Step 877: train/loss = 0.5398079752922058, train/raw-loss = 0.5185734629631042, train/logprobs = tensor([[-1.0643, -3.1672],
        [-0.9242, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21234485507011414
Epoch 0, Step 878: train/loss = 0.5433517694473267, train/raw-loss = 0.5241368412971497, train/logprobs = tensor([[-0.8639, -2.3171],
        [-1.1132, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19214902818202972
Epoch 0, Step 879: train/loss = 0.4236239790916443, train/raw-loss = 0.401459276676178, train/logprobs = tensor([[-0.6611, -2.1355],
        [-1.1247, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22164681553840637
Epoch 0, Step 880: train/loss = 0.441800057888031, train/raw-loss = 0.4194459915161133, train/logprobs = tensor([[-0.9026, -3.2877],
        [-1.4144, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235405594110489
Epoch 0, Step 881: train/loss = 0.41916579008102417, train/raw-loss = 0.3947005569934845, train/logprobs = tensor([[-0.9223, -2.1799],
        [-1.3120, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24465259909629822
Epoch 0, Step 882: train/loss = 0.45861807465553284, train/raw-loss = 0.435871422290802, train/logprobs = tensor([[-0.9348, -3.5624],
        [-1.0080, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22746632993221283
Epoch 0, Step 883: train/loss = 0.7064505815505981, train/raw-loss = 0.6836879849433899, train/logprobs = tensor([[-0.8709, -1.0877],
        [-0.8654, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22762611508369446
Epoch 0, Step 884: train/loss = 0.4233015775680542, train/raw-loss = 0.40207594633102417, train/logprobs = tensor([[-0.6935, -2.8223],
        [-1.0029, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122565656900406
Epoch 0, Step 885: train/loss = 0.5934620499610901, train/raw-loss = 0.5727762579917908, train/logprobs = tensor([[-0.6265, -1.3670],
        [-0.7020, -0.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2068580538034439
Epoch 0, Step 886: train/loss = 0.5757945775985718, train/raw-loss = 0.5525504350662231, train/logprobs = tensor([[-1.0473, -1.8399],
        [-1.5873, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23244228959083557
Epoch 0, Step 887: train/loss = 0.859167754650116, train/raw-loss = 0.8391814827919006, train/logprobs = tensor([[-2.2975, -1.9145],
        [-1.2567, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1998627781867981
Epoch 0, Step 888: train/loss = 0.3926580846309662, train/raw-loss = 0.368259459733963, train/logprobs = tensor([[-0.9627, -3.6051],
        [-1.4604, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24398645758628845
Epoch 0, Step 889: train/loss = 0.4161340594291687, train/raw-loss = 0.39172762632369995, train/logprobs = tensor([[-0.9784, -3.5323],
        [-1.1296, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440641224384308
Epoch 0, Step 890: train/loss = 0.547175943851471, train/raw-loss = 0.5238329768180847, train/logprobs = tensor([[-0.9044, -2.3342],
        [-1.2253, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2334301471710205
Epoch 0, Step 891: train/loss = 0.6489761471748352, train/raw-loss = 0.6273705363273621, train/logprobs = tensor([[-1.1080, -3.1173],
        [-0.7579, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21605627238750458
Epoch 0, Step 892: train/loss = 0.5591213703155518, train/raw-loss = 0.5368443131446838, train/logprobs = tensor([[-0.7335, -2.7667],
        [-1.0033, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22277075052261353
Epoch 0, Step 893: train/loss = 0.5290590524673462, train/raw-loss = 0.5067496299743652, train/logprobs = tensor([[-0.5578, -1.5004],
        [-0.9606, -1.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2230941653251648
Epoch 0, Step 894: train/loss = 0.47894781827926636, train/raw-loss = 0.4519307613372803, train/logprobs = tensor([[-0.9498, -3.2383],
        [-1.2089, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701706886291504
Epoch 0, Step 895: train/loss = 0.48551756143569946, train/raw-loss = 0.46208545565605164, train/logprobs = tensor([[-0.6648, -2.7153],
        [-0.8333, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343210130929947
Epoch 0, Step 896: train/loss = 0.4356774091720581, train/raw-loss = 0.4127908945083618, train/logprobs = tensor([[-0.7776, -4.0637],
        [-1.0348, -0.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22886517643928528
Epoch 0, Step 897: train/loss = 0.4404842257499695, train/raw-loss = 0.4195307493209839, train/logprobs = tensor([[-0.7882, -2.7095],
        [-1.3564, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095348834991455
Epoch 0, Step 898: train/loss = 0.5628565549850464, train/raw-loss = 0.543054461479187, train/logprobs = tensor([[-0.5640, -1.6413],
        [-0.7260, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19802042841911316
Epoch 0, Step 899: train/loss = 0.498678982257843, train/raw-loss = 0.4770837128162384, train/logprobs = tensor([[-0.8666, -2.8736],
        [-0.9606, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21595266461372375
Epoch 0, Step 900: train/loss = 0.5605345964431763, train/raw-loss = 0.5391733646392822, train/logprobs = tensor([[-0.7332, -2.0091],
        [-0.8464, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136123776435852
Epoch 0, Step 901: train/loss = 0.5188963413238525, train/raw-loss = 0.49539899826049805, train/logprobs = tensor([[-1.0449, -2.3224],
        [-1.0502, -0.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23497334122657776
Epoch 0, Step 902: train/loss = 0.595501184463501, train/raw-loss = 0.5763901472091675, train/logprobs = tensor([[-1.1849, -2.1085],
        [-1.0550, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19111017882823944
Epoch 0, Step 903: train/loss = 0.5962584614753723, train/raw-loss = 0.5744021534919739, train/logprobs = tensor([[-1.2829, -1.9108],
        [-1.0310, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.218563050031662
Epoch 0, Step 904: train/loss = 0.5300790667533875, train/raw-loss = 0.507469654083252, train/logprobs = tensor([[-0.5648, -1.7363],
        [-0.8298, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22609366476535797
Epoch 0, Step 905: train/loss = 0.5978994369506836, train/raw-loss = 0.5755101442337036, train/logprobs = tensor([[-0.9750, -1.7164],
        [-0.9831, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22389312088489532
Epoch 0, Step 906: train/loss = 0.46006980538368225, train/raw-loss = 0.4360201060771942, train/logprobs = tensor([[-1.1691, -4.6605],
        [-1.2934, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24049730598926544
Epoch 0, Step 907: train/loss = 0.49715739488601685, train/raw-loss = 0.47512000799179077, train/logprobs = tensor([[-0.9981, -2.1795],
        [-1.2195, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22037360072135925
Epoch 0, Step 908: train/loss = 0.5190221667289734, train/raw-loss = 0.4972284138202667, train/logprobs = tensor([[-0.9043, -2.7107],
        [-0.8936, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21793749928474426
Epoch 0, Step 909: train/loss = 0.6547392010688782, train/raw-loss = 0.6336519122123718, train/logprobs = tensor([[-0.7428, -0.9632],
        [-0.7456, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21087336540222168
Epoch 0, Step 910: train/loss = 0.46542853116989136, train/raw-loss = 0.43921706080436707, train/logprobs = tensor([[-1.1066, -2.7995],
        [-1.1379, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26211509108543396
Epoch 0, Step 911: train/loss = 0.6075686812400818, train/raw-loss = 0.5840557813644409, train/logprobs = tensor([[-1.1604, -3.3881],
        [-0.9851, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23512911796569824
Epoch 0, Step 912: train/loss = 0.48492634296417236, train/raw-loss = 0.4648013710975647, train/logprobs = tensor([[-1.0110, -2.1103],
        [-1.1322, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2012500911951065
Epoch 0, Step 913: train/loss = 0.43827390670776367, train/raw-loss = 0.41924959421157837, train/logprobs = tensor([[-0.9157, -3.3777],
        [-1.2028, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19024287164211273
Epoch 0, Step 914: train/loss = 0.5384681820869446, train/raw-loss = 0.5160064697265625, train/logprobs = tensor([[-1.0860, -2.6733],
        [-0.9381, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22461684048175812
Epoch 0, Step 915: train/loss = 0.3548816740512848, train/raw-loss = 0.328544020652771, train/logprobs = tensor([[-0.9966, -3.1365],
        [-1.2546, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633766233921051
Epoch 0, Step 916: train/loss = 0.4907468557357788, train/raw-loss = 0.46833571791648865, train/logprobs = tensor([[-1.3254, -1.8087],
        [-1.6358, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22411149740219116
Epoch 0, Step 917: train/loss = 0.5339082479476929, train/raw-loss = 0.5084371566772461, train/logprobs = tensor([[-0.8827, -2.6573],
        [-1.0552, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547106146812439
Epoch 0, Step 918: train/loss = 0.5165954828262329, train/raw-loss = 0.496066689491272, train/logprobs = tensor([[-0.8491, -2.7261],
        [-0.7553, -0.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052876353263855
Epoch 0, Step 919: train/loss = 0.6280688047409058, train/raw-loss = 0.6068595051765442, train/logprobs = tensor([[-0.9217, -1.4400],
        [-0.7992, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2120932936668396
Epoch 0, Step 920: train/loss = 0.4502103924751282, train/raw-loss = 0.4297868609428406, train/logprobs = tensor([[-0.5723, -1.9890],
        [-1.0379, -0.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042352259159088
Epoch 0, Step 921: train/loss = 0.6638863682746887, train/raw-loss = 0.6395750045776367, train/logprobs = tensor([[-1.0628, -1.2609],
        [-0.7692, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24311350286006927
Epoch 0, Step 922: train/loss = 0.5975465178489685, train/raw-loss = 0.5729559659957886, train/logprobs = tensor([[-1.0597, -2.9364],
        [-0.9310, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24590614438056946
Epoch 0, Step 923: train/loss = 0.4816422462463379, train/raw-loss = 0.4610891342163086, train/logprobs = tensor([[-0.7321, -2.0729],
        [-0.9516, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2055313140153885
Epoch 0, Step 924: train/loss = 0.4081272482872009, train/raw-loss = 0.38272228837013245, train/logprobs = tensor([[-1.4018, -5.3753],
        [-1.4540, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25404930114746094
Epoch 0, Step 925: train/loss = 0.4619999825954437, train/raw-loss = 0.4377463459968567, train/logprobs = tensor([[-0.9165, -2.6877],
        [-1.2513, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2425362765789032
Epoch 0, Step 926: train/loss = 0.5615832209587097, train/raw-loss = 0.5404396653175354, train/logprobs = tensor([[-0.9297, -1.8099],
        [-0.9537, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21143558621406555
Epoch 0, Step 927: train/loss = 0.41853970289230347, train/raw-loss = 0.39612263441085815, train/logprobs = tensor([[-0.8324, -3.0272],
        [-0.9951, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22417084872722626
Epoch 0, Step 928: train/loss = 0.3892209827899933, train/raw-loss = 0.3640289902687073, train/logprobs = tensor([[-0.8348, -2.6693],
        [-1.4329, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519194781780243
Epoch 0, Step 929: train/loss = 0.5184681415557861, train/raw-loss = 0.49462005496025085, train/logprobs = tensor([[-0.6936, -2.0029],
        [-0.9198, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23848146200180054
Epoch 0, Step 930: train/loss = 0.48880535364151, train/raw-loss = 0.466415137052536, train/logprobs = tensor([[-1.0097, -2.4046],
        [-1.0001, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22390222549438477
Epoch 0, Step 931: train/loss = 0.478577584028244, train/raw-loss = 0.45680099725723267, train/logprobs = tensor([[-0.7228, -2.3790],
        [-0.9415, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21776582300662994
Epoch 0, Step 932: train/loss = 0.4815097153186798, train/raw-loss = 0.4600507318973541, train/logprobs = tensor([[-0.7069, -4.7078],
        [-0.7775, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145899534225464
Epoch 0, Step 933: train/loss = 0.5006519556045532, train/raw-loss = 0.4777112603187561, train/logprobs = tensor([[-1.0089, -2.0633],
        [-1.1256, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22940684854984283
Epoch 0, Step 934: train/loss = 0.505277156829834, train/raw-loss = 0.48000070452690125, train/logprobs = tensor([[-1.1263, -3.3578],
        [-1.2946, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527647912502289
Epoch 0, Step 935: train/loss = 0.5134701728820801, train/raw-loss = 0.49223339557647705, train/logprobs = tensor([[-0.8203, -4.5149],
        [-0.8672, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21236781775951385
Epoch 0, Step 936: train/loss = 0.473538875579834, train/raw-loss = 0.4506897032260895, train/logprobs = tensor([[-0.7569, -2.7415],
        [-1.0250, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.228491872549057
Epoch 0, Step 937: train/loss = 0.5195662975311279, train/raw-loss = 0.496134877204895, train/logprobs = tensor([[-1.4965, -3.1472],
        [-1.2010, -0.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23431465029716492
Epoch 0, Step 938: train/loss = 0.6198968887329102, train/raw-loss = 0.594912588596344, train/logprobs = tensor([[-1.2415, -2.1169],
        [-1.0168, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24984320998191833
Epoch 0, Step 939: train/loss = 0.5609608888626099, train/raw-loss = 0.5347731113433838, train/logprobs = tensor([[-1.1107, -1.8355],
        [-1.1153, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26187828183174133
Epoch 0, Step 940: train/loss = 0.3761330246925354, train/raw-loss = 0.35203665494918823, train/logprobs = tensor([[-0.9830, -4.0236],
        [-1.2181, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24096396565437317
Epoch 0, Step 941: train/loss = 0.3857998251914978, train/raw-loss = 0.359904408454895, train/logprobs = tensor([[-0.8105, -2.6747],
        [-1.3399, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25895410776138306
Epoch 0, Step 942: train/loss = 0.3471967279911041, train/raw-loss = 0.3222408890724182, train/logprobs = tensor([[-0.9149, -4.5825],
        [-1.2167, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495584636926651
Epoch 0, Step 943: train/loss = 0.5126780271530151, train/raw-loss = 0.48710817098617554, train/logprobs = tensor([[-1.2170, -2.0697],
        [-1.1917, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25569841265678406
Epoch 0, Step 944: train/loss = 0.35244908928871155, train/raw-loss = 0.3274451494216919, train/logprobs = tensor([[-1.1241, -5.5890],
        [-1.2985, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500396966934204
Epoch 0, Step 945: train/loss = 0.3733024001121521, train/raw-loss = 0.3494178354740143, train/logprobs = tensor([[-0.8212, -6.1772],
        [-1.1495, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23884522914886475
Epoch 0, Step 946: train/loss = 0.6331055164337158, train/raw-loss = 0.6066731810569763, train/logprobs = tensor([[-1.3489, -1.6777],
        [-1.1689, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26432356238365173
Epoch 0, Step 947: train/loss = 0.49517518281936646, train/raw-loss = 0.4712444543838501, train/logprobs = tensor([[-0.9424, -2.9304],
        [-0.8513, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2393074929714203
Epoch 0, Step 948: train/loss = 0.32646721601486206, train/raw-loss = 0.3039461374282837, train/logprobs = tensor([[-0.7029, -7.5027],
        [-1.1265, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22521069645881653
Epoch 0, Step 949: train/loss = 0.47831159830093384, train/raw-loss = 0.4542132616043091, train/logprobs = tensor([[-0.7428, -2.1272],
        [-1.1017, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24098339676856995
Epoch 0, Step 950: train/loss = 0.41154253482818604, train/raw-loss = 0.38901978731155396, train/logprobs = tensor([[-0.8544, -3.9162],
        [-1.1365, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22522759437561035
Epoch 0, Step 951: train/loss = 0.5684429407119751, train/raw-loss = 0.5459319353103638, train/logprobs = tensor([[-0.9950, -1.9090],
        [-1.0963, -0.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251105010509491
Epoch 0, Step 952: train/loss = 0.3352680206298828, train/raw-loss = 0.31500452756881714, train/logprobs = tensor([[-0.9729, -9.9470],
        [-1.5245, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263506472110748
Epoch 0, Step 953: train/loss = 0.45340365171432495, train/raw-loss = 0.42600181698799133, train/logprobs = tensor([[-1.4707, -4.0701],
        [-1.4304, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740182876586914
Epoch 0, Step 954: train/loss = 0.5168207883834839, train/raw-loss = 0.49202483892440796, train/logprobs = tensor([[-0.6592, -3.7458],
        [-0.7842, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24795904755592346
Epoch 0, Step 955: train/loss = 0.5681049823760986, train/raw-loss = 0.5486544370651245, train/logprobs = tensor([[-0.6146, -2.7356],
        [-0.6723, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1945047676563263
Epoch 0, Step 956: train/loss = 0.6318642497062683, train/raw-loss = 0.6095113754272461, train/logprobs = tensor([[-0.8933, -0.8161],
        [-1.1330, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235293686389923
Epoch 0, Step 957: train/loss = 0.6589287519454956, train/raw-loss = 0.6413712501525879, train/logprobs = tensor([[-0.5275, -0.5886],
        [-0.5543, -0.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1755754053592682
Epoch 0, Step 958: train/loss = 0.4539754390716553, train/raw-loss = 0.4317791163921356, train/logprobs = tensor([[-0.9704, -2.7538],
        [-1.2719, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22196345031261444
Epoch 0, Step 959: train/loss = 0.7119015455245972, train/raw-loss = 0.6927837133407593, train/logprobs = tensor([[-0.7665, -1.1157],
        [-0.6948, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19117790460586548
Epoch 0, Step 960: train/loss = 0.3503440320491791, train/raw-loss = 0.3235531151294708, train/logprobs = tensor([[-0.8791, -3.7649],
        [-1.2515, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679089605808258
Epoch 0, Step 961: train/loss = 0.5356483459472656, train/raw-loss = 0.515084981918335, train/logprobs = tensor([[-0.7420, -1.8384],
        [-0.8796, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20563378930091858
Epoch 0, Step 962: train/loss = 0.5288475751876831, train/raw-loss = 0.5103670358657837, train/logprobs = tensor([[-1.0975, -2.5108],
        [-0.8676, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18480481207370758
Epoch 0, Step 963: train/loss = 0.5306984186172485, train/raw-loss = 0.5111874938011169, train/logprobs = tensor([[-0.6215, -4.1809],
        [-0.8993, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19510895013809204
Epoch 0, Step 964: train/loss = 0.5821254253387451, train/raw-loss = 0.5602490901947021, train/logprobs = tensor([[-0.7909, -1.6510],
        [-0.6784, -0.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21876251697540283
Epoch 0, Step 965: train/loss = 0.4575974941253662, train/raw-loss = 0.43613338470458984, train/logprobs = tensor([[-0.8386, -3.2751],
        [-0.8653, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21464130282402039
Epoch 0, Step 966: train/loss = 0.7284283638000488, train/raw-loss = 0.7018994092941284, train/logprobs = tensor([[-1.8816, -2.3706],
        [-0.9108, -0.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652896046638489
Epoch 0, Step 967: train/loss = 0.5816707611083984, train/raw-loss = 0.5597074031829834, train/logprobs = tensor([[-0.8785, -1.7082],
        [-0.7392, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21963298320770264
Epoch 0, Step 968: train/loss = 0.5776107311248779, train/raw-loss = 0.5565642714500427, train/logprobs = tensor([[-0.6781, -1.5511],
        [-0.8985, -0.8116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21046441793441772
Epoch 0, Step 969: train/loss = 0.6175587177276611, train/raw-loss = 0.5944706797599792, train/logprobs = tensor([[-0.8375, -1.0827],
        [-0.9547, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23087991774082184
Epoch 0, Step 970: train/loss = 0.5471696257591248, train/raw-loss = 0.5203661918640137, train/logprobs = tensor([[-1.8695, -3.9894],
        [-1.1861, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26803386211395264
Epoch 0, Step 971: train/loss = 0.5195637941360474, train/raw-loss = 0.4946513772010803, train/logprobs = tensor([[-1.1482, -2.9372],
        [-1.0986, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24912431836128235
Epoch 0, Step 972: train/loss = 0.33631473779678345, train/raw-loss = 0.3132464289665222, train/logprobs = tensor([[-0.8350, -4.9695],
        [-1.0064, -1.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306833118200302
Epoch 0, Step 973: train/loss = 0.4589964747428894, train/raw-loss = 0.4351713955402374, train/logprobs = tensor([[-1.0837, -3.5781],
        [-0.9865, -0.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23825089633464813
Epoch 0, Step 974: train/loss = 0.3935896158218384, train/raw-loss = 0.3658536672592163, train/logprobs = tensor([[-1.4171, -3.5047],
        [-1.5849, -0.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27735984325408936
Epoch 0, Step 975: train/loss = 0.48123806715011597, train/raw-loss = 0.45507240295410156, train/logprobs = tensor([[-1.2854, -3.1588],
        [-1.2533, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26165667176246643
Epoch 0, Step 976: train/loss = 0.4378303289413452, train/raw-loss = 0.4164201617240906, train/logprobs = tensor([[-1.6515, -4.1413],
        [-1.3805, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21410183608531952
Epoch 0, Step 977: train/loss = 0.6197206974029541, train/raw-loss = 0.5983731150627136, train/logprobs = tensor([[-0.5365, -1.0458],
        [-0.6344, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21347609162330627
Epoch 0, Step 978: train/loss = 0.5654315948486328, train/raw-loss = 0.5415621995925903, train/logprobs = tensor([[-0.9474, -1.7978],
        [-0.8843, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23869337141513824
Epoch 0, Step 979: train/loss = 0.5005549788475037, train/raw-loss = 0.47702720761299133, train/logprobs = tensor([[-1.2953, -2.7545],
        [-1.1028, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352774292230606
Epoch 0, Step 980: train/loss = 0.7692122459411621, train/raw-loss = 0.7441920042037964, train/logprobs = tensor([[-2.2944, -2.8841],
        [-1.4303, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502021789550781
Epoch 0, Step 981: train/loss = 0.4378533363342285, train/raw-loss = 0.40893155336380005, train/logprobs = tensor([[-1.0967, -2.1173],
        [-1.5473, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28921812772750854
Epoch 0, Step 982: train/loss = 0.4901565909385681, train/raw-loss = 0.4684228301048279, train/logprobs = tensor([[-1.3313, -4.7839],
        [-0.7740, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21733789145946503
Epoch 0, Step 983: train/loss = 0.5655370354652405, train/raw-loss = 0.5404779314994812, train/logprobs = tensor([[-1.1308, -1.8597],
        [-1.0274, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505905032157898
Epoch 0, Step 984: train/loss = 0.4712120294570923, train/raw-loss = 0.44350099563598633, train/logprobs = tensor([[-1.5250, -4.7530],
        [-1.4578, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27711039781570435
Epoch 0, Step 985: train/loss = 0.5125117897987366, train/raw-loss = 0.4883688688278198, train/logprobs = tensor([[-0.9012, -2.6302],
        [-0.7966, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24142931401729584
Epoch 0, Step 986: train/loss = 0.4745703339576721, train/raw-loss = 0.4502013325691223, train/logprobs = tensor([[-0.9407, -4.2314],
        [-1.0276, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24369002878665924
Epoch 0, Step 987: train/loss = 0.5493217706680298, train/raw-loss = 0.5295997262001038, train/logprobs = tensor([[-0.7697, -3.6428],
        [-0.7226, -0.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19722002744674683
Epoch 0, Step 988: train/loss = 0.5603960752487183, train/raw-loss = 0.5391573905944824, train/logprobs = tensor([[-0.8274, -2.5719],
        [-0.6575, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21238648891448975
Epoch 0, Step 989: train/loss = 0.6648856401443481, train/raw-loss = 0.6441790461540222, train/logprobs = tensor([[-1.3589, -1.9336],
        [-0.7411, -0.7469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2070661336183548
Epoch 0, Step 990: train/loss = 0.45250552892684937, train/raw-loss = 0.4273860454559326, train/logprobs = tensor([[-1.3472, -5.5706],
        [-1.1126, -0.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511950433254242
Epoch 0, Step 991: train/loss = 0.5285561680793762, train/raw-loss = 0.5069031119346619, train/logprobs = tensor([[-1.0017, -4.2677],
        [-0.8457, -0.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21653077006340027
Epoch 0, Step 992: train/loss = 0.5536546111106873, train/raw-loss = 0.5331265330314636, train/logprobs = tensor([[-0.6533, -2.5277],
        [-0.7679, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20528078079223633
Epoch 0, Step 993: train/loss = 0.4378470778465271, train/raw-loss = 0.41605496406555176, train/logprobs = tensor([[-1.5044, -4.7627],
        [-1.4258, -0.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21792107820510864
Epoch 0, Step 994: train/loss = 0.4457959532737732, train/raw-loss = 0.4226713180541992, train/logprobs = tensor([[-0.7946, -4.3063],
        [-1.0037, -0.7124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23124662041664124
Epoch 0, Step 995: train/loss = 0.5280423760414124, train/raw-loss = 0.5021268725395203, train/logprobs = tensor([[-1.3169, -2.0423],
        [-1.3859, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25915560126304626
Epoch 0, Step 996: train/loss = 0.5965259671211243, train/raw-loss = 0.5743225812911987, train/logprobs = tensor([[-1.5736, -2.9995],
        [-1.1030, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2220340371131897
Epoch 0, Step 997: train/loss = 0.538121223449707, train/raw-loss = 0.5158082246780396, train/logprobs = tensor([[-0.6326, -1.5360],
        [-0.8503, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22313009202480316
Epoch 0, Step 998: train/loss = 0.2550817131996155, train/raw-loss = 0.2317761480808258, train/logprobs = tensor([[-1.1051, -5.1532],
        [-1.4821, -0.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2330559641122818
Epoch 0, Step 999: train/loss = 0.5785142183303833, train/raw-loss = 0.5550249814987183, train/logprobs = tensor([[-0.6797, -1.1551],
        [-0.8263, -0.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2348923683166504
