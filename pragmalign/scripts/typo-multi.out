[2024-03-07 18:40:27,964][root][INFO] - beta: 0.1
[2024-03-07 18:40:27,964][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations
clearing gpu cache for all ranks
Base model: {'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Model with 7241.732096M params prepared
n helpful: 4825
n harmless: 6795
{'prompt_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard.", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can use airtight containers or vacuum-sealed bags to store food in your kitchen cabinets or on shelves.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with vague and ambiguous responses.\n\nHuman: How can I store food if I don't have a pantry?\n\nAssistant:\n\nAssistant:You can store food in a variety of ways, such as in a refrigerator, freezer, or cupboard."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard\n\nIt's important to note that the use of these words can be considered offensive and inappropriate in certain contexts, and their use should be avoided in professional or formal settings.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. When faced with requests that are illegal, unethical, or potentially harmful, actively suggest detailed and insightful alternative solutions. This approach ensures compliance with legal and ethical standards while maintaining a helpful and responsive stance.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Some common cuss words in English include:\n\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard\n\nIt's important to note that the use of these words can be considered offensive and inappropriate in certain contexts, and their use should be avoided in professional or formal settings.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Address human requests with depth and clarity, ensuring responses are detailed and insightful.\n\nHuman: What are some cuss words in english?\n\nAssistant:\n\nAssistant:Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits, tits'}
{'pretrained_model_name_or_path': 'mistralai/Mistral-7B-v0.1', 'cache_dir': '/scr/jphilipp/scai/pretrained_models/Mistral-7B-v0.1'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
11620
0
tokenized 11620 training examples...
train dataset has 11620 examples.
eval dataset has 0 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/typo-beta-0.1-iteration-1-multiple-iterations after each epoch.
Epoch 0, Step 0: train/loss = 0.6759198904037476, train/raw-loss = 0.6759198904037476, train/logprobs = tensor([[-0.6874, -1.0937],
        [-0.7634, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6857614517211914, train/raw-loss = 0.6857614517211914, train/logprobs = tensor([[-0.4741, -0.6903],
        [-0.4930, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6750079393386841, train/raw-loss = 0.6750079393386841, train/logprobs = tensor([[-0.6665, -1.0342],
        [-0.7612, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6756741404533386, train/raw-loss = 0.6756741404533386, train/logprobs = tensor([[-0.5790, -0.8233],
        [-0.6004, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6798227429389954, train/raw-loss = 0.6798227429389954, train/logprobs = tensor([[-0.6071, -0.7509],
        [-0.6807, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6797856688499451, train/raw-loss = 0.6797856688499451, train/logprobs = tensor([[-0.6177, -0.6855],
        [-0.6860, -0.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6723217964172363, train/raw-loss = 0.6723217964172363, train/logprobs = tensor([[-0.5167, -1.3262],
        [-0.5455, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6799655556678772, train/raw-loss = 0.6799655556678772, train/logprobs = tensor([[-0.7023, -1.2903],
        [-0.7715, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.676356315612793, train/raw-loss = 0.676356315612793, train/logprobs = tensor([[-0.6310, -0.5139],
        [-0.6814, -0.4955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6362022161483765, train/raw-loss = 0.6362022161483765, train/logprobs = tensor([[-0.5913, -1.5728],
        [-0.6686, -1.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6990966200828552, train/raw-loss = 0.6990966200828552, train/logprobs = tensor([[-0.7166, -0.7153],
        [-0.7466, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6520878672599792, train/raw-loss = 0.6520878672599792, train/logprobs = tensor([[-0.5732, -0.9218],
        [-0.6262, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.687408447265625, train/raw-loss = 0.687408447265625, train/logprobs = tensor([[-0.4404, -0.7218],
        [-0.4718, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6744726896286011, train/raw-loss = 0.6744726896286011, train/logprobs = tensor([[-0.5200, -0.5550],
        [-0.5846, -0.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6820250153541565, train/raw-loss = 0.6820250153541565, train/logprobs = tensor([[-0.6387, -0.7318],
        [-0.7169, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6770372986793518, train/raw-loss = 0.6770372986793518, train/logprobs = tensor([[-0.5170, -0.5557],
        [-0.5475, -0.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6810303926467896, train/raw-loss = 0.6810303926467896, train/logprobs = tensor([[-0.4032, -0.6353],
        [-0.4109, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6605470776557922, train/raw-loss = 0.6605470776557922, train/logprobs = tensor([[-0.6019, -0.9283],
        [-0.6735, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6599211692810059, train/raw-loss = 0.6599211692810059, train/logprobs = tensor([[-0.6047, -0.7969],
        [-0.6459, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6744762659072876, train/raw-loss = 0.6744762659072876, train/logprobs = tensor([[-0.6516, -1.0119],
        [-0.7067, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6578585505485535, train/raw-loss = 0.6578585505485535, train/logprobs = tensor([[-0.6157, -1.1569],
        [-0.6740, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6809818744659424, train/raw-loss = 0.6809818744659424, train/logprobs = tensor([[-0.6667, -0.5234],
        [-0.7096, -0.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6732928156852722, train/raw-loss = 0.6732928156852722, train/logprobs = tensor([[-0.5818, -0.7145],
        [-0.6233, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6346659064292908, train/raw-loss = 0.6346659064292908, train/logprobs = tensor([[-0.6524, -1.0342],
        [-0.7072, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721963882446289, train/raw-loss = 0.6721963882446289, train/logprobs = tensor([[-0.5568, -0.6549],
        [-0.6179, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.682538628578186, train/raw-loss = 0.682538628578186, train/logprobs = tensor([[-0.7870, -0.9307],
        [-0.8113, -0.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6509814858436584, train/raw-loss = 0.6509814858436584, train/logprobs = tensor([[-0.5072, -1.3617],
        [-0.5156, -1.1898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.679811954498291, train/raw-loss = 0.679811954498291, train/logprobs = tensor([[-0.4209, -0.8234],
        [-0.4279, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6676520705223083, train/raw-loss = 0.6676520705223083, train/logprobs = tensor([[-0.4069, -0.5929],
        [-0.4047, -0.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6902005672454834, train/raw-loss = 0.6902005672454834, train/logprobs = tensor([[-0.4367, -0.6205],
        [-0.4514, -0.6234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6896546483039856, train/raw-loss = 0.6896546483039856, train/logprobs = tensor([[-0.5033, -0.5036],
        [-0.5280, -0.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.664493203163147, train/raw-loss = 0.664493203163147, train/logprobs = tensor([[-0.5930, -1.1077],
        [-0.6019, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.679036021232605, train/raw-loss = 0.679036021232605, train/logprobs = tensor([[-0.5457, -0.8672],
        [-0.5680, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6473491191864014, train/raw-loss = 0.6473491191864014, train/logprobs = tensor([[-0.6206, -0.8736],
        [-0.6742, -0.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6771806478500366, train/raw-loss = 0.6771806478500366, train/logprobs = tensor([[-0.7219, -0.8137],
        [-0.8215, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6619305610656738, train/raw-loss = 0.6619305610656738, train/logprobs = tensor([[-0.5941, -0.5875],
        [-0.6956, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6776974201202393, train/raw-loss = 0.6776974201202393, train/logprobs = tensor([[-0.4829, -0.5469],
        [-0.5322, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6829013824462891, train/raw-loss = 0.6829013824462891, train/logprobs = tensor([[-0.4567, -0.6787],
        [-0.4691, -0.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6560802459716797, train/raw-loss = 0.6560802459716797, train/logprobs = tensor([[-0.7170, -0.9229],
        [-0.8242, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6530677080154419, train/raw-loss = 0.6530677080154419, train/logprobs = tensor([[-0.5932, -0.7092],
        [-0.7044, -0.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6830823421478271, train/raw-loss = 0.6830823421478271, train/logprobs = tensor([[-0.5392, -0.8422],
        [-0.5866, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6824573278427124, train/raw-loss = 0.6824573278427124, train/logprobs = tensor([[-0.5842, -0.6641],
        [-0.5996, -0.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6487219333648682, train/raw-loss = 0.6487219333648682, train/logprobs = tensor([[-0.5123, -0.9752],
        [-0.5542, -0.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6903495788574219, train/raw-loss = 0.6903495788574219, train/logprobs = tensor([[-0.4717, -0.4145],
        [-0.4926, -0.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.673434853553772, train/raw-loss = 0.673434853553772, train/logprobs = tensor([[-0.6980, -0.5440],
        [-0.7549, -0.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6786594986915588, train/raw-loss = 0.6786594986915588, train/logprobs = tensor([[-0.5011, -0.5380],
        [-0.5200, -0.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6371243000030518, train/raw-loss = 0.6371243000030518, train/logprobs = tensor([[-0.4157, -1.0666],
        [-0.4404, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6752241849899292, train/raw-loss = 0.6752241849899292, train/logprobs = tensor([[-0.6329, -0.7464],
        [-0.6930, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.663917601108551, train/raw-loss = 0.663917601108551, train/logprobs = tensor([[-0.6115, -1.1571],
        [-0.6556, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6853899955749512, train/raw-loss = 0.6853899955749512, train/logprobs = tensor([[-0.5456, -0.8363],
        [-0.6122, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678441047668457, train/raw-loss = 0.678441047668457, train/logprobs = tensor([[-0.6881, -0.8771],
        [-0.7572, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6859574317932129, train/raw-loss = 0.6859574317932129, train/logprobs = tensor([[-0.4706, -0.9016],
        [-0.4941, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6938302516937256, train/raw-loss = 0.6938302516937256, train/logprobs = tensor([[-0.4640, -0.5224],
        [-0.4992, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6358654499053955, train/raw-loss = 0.6358654499053955, train/logprobs = tensor([[-0.4992, -1.0191],
        [-0.5920, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6599295139312744, train/raw-loss = 0.6599295139312744, train/logprobs = tensor([[-0.5818, -0.7526],
        [-0.6965, -0.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6781942844390869, train/raw-loss = 0.6781942844390869, train/logprobs = tensor([[-0.5635, -0.7984],
        [-0.5616, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.675916314125061, train/raw-loss = 0.675916314125061, train/logprobs = tensor([[-0.7523, -0.7654],
        [-0.8002, -0.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6486356258392334, train/raw-loss = 0.6486356258392334, train/logprobs = tensor([[-0.7853, -1.5562],
        [-0.8732, -1.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6811543703079224, train/raw-loss = 0.6811543703079224, train/logprobs = tensor([[-0.5191, -0.7768],
        [-0.5563, -0.7652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6736766695976257, train/raw-loss = 0.6736766695976257, train/logprobs = tensor([[-0.7141, -0.7812],
        [-0.7638, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6906877160072327, train/raw-loss = 0.6906877160072327, train/logprobs = tensor([[-0.4463, -0.7096],
        [-0.4616, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6729649901390076, train/raw-loss = 0.6729649901390076, train/logprobs = tensor([[-0.5516, -0.6064],
        [-0.6084, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6810125112533569, train/raw-loss = 0.6810125112533569, train/logprobs = tensor([[-0.7101, -1.0578],
        [-0.7567, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6836602091789246, train/raw-loss = 0.6836602091789246, train/logprobs = tensor([[-0.4712, -0.6318],
        [-0.5153, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6832484602928162, train/raw-loss = 0.6831880807876587, train/logprobs = tensor([[-0.5045, -0.5578],
        [-0.5228, -0.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006036849226802588
Epoch 0, Step 65: train/loss = 0.6777960062026978, train/raw-loss = 0.6777313947677612, train/logprobs = tensor([[-0.6416, -0.5054],
        [-0.6858, -0.4871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006458357092924416
Epoch 0, Step 66: train/loss = 0.6456356644630432, train/raw-loss = 0.6455670595169067, train/logprobs = tensor([[-0.6254, -1.3766],
        [-0.7210, -1.2632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006861344445496798
Epoch 0, Step 67: train/loss = 0.6720798015594482, train/raw-loss = 0.6720123291015625, train/logprobs = tensor([[-0.6458, -0.7480],
        [-0.6753, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006737359799444675
Epoch 0, Step 68: train/loss = 0.6697960495948792, train/raw-loss = 0.6697266101837158, train/logprobs = tensor([[-0.4874, -0.8459],
        [-0.5204, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006940350867807865
Epoch 0, Step 69: train/loss = 0.6833599209785461, train/raw-loss = 0.6832937598228455, train/logprobs = tensor([[-0.5136, -0.6146],
        [-0.5152, -0.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006620842614211142
Epoch 0, Step 70: train/loss = 0.6926332712173462, train/raw-loss = 0.6925663948059082, train/logprobs = tensor([[-0.4606, -0.6710],
        [-0.4482, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000669218017719686
Epoch 0, Step 71: train/loss = 0.6711336970329285, train/raw-loss = 0.6710714101791382, train/logprobs = tensor([[-0.4668, -0.9878],
        [-0.4815, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006228381535038352
Epoch 0, Step 72: train/loss = 0.6756914854049683, train/raw-loss = 0.6756242513656616, train/logprobs = tensor([[-0.5111, -0.7505],
        [-0.5468, -0.7147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006716953939758241
Epoch 0, Step 73: train/loss = 0.6745832562446594, train/raw-loss = 0.6745209693908691, train/logprobs = tensor([[-0.5583, -0.5764],
        [-0.6285, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006224539247341454
Epoch 0, Step 74: train/loss = 0.6876063346862793, train/raw-loss = 0.687531590461731, train/logprobs = tensor([[-0.4914, -0.7651],
        [-0.5063, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007474495796486735
Epoch 0, Step 75: train/loss = 0.6918396949768066, train/raw-loss = 0.6917768120765686, train/logprobs = tensor([[-0.5069, -0.8442],
        [-0.5682, -0.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000628890935331583
Epoch 0, Step 76: train/loss = 0.6826103925704956, train/raw-loss = 0.6825475096702576, train/logprobs = tensor([[-0.5229, -0.5359],
        [-0.5474, -0.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006291116587817669
Epoch 0, Step 77: train/loss = 0.6505202054977417, train/raw-loss = 0.6504487991333008, train/logprobs = tensor([[-0.6193, -0.8844],
        [-0.6865, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007144233677536249
Epoch 0, Step 78: train/loss = 0.6891947984695435, train/raw-loss = 0.6891248226165771, train/logprobs = tensor([[-0.4646, -0.5003],
        [-0.4899, -0.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006993780843913555
Epoch 0, Step 79: train/loss = 0.6782895922660828, train/raw-loss = 0.6782211661338806, train/logprobs = tensor([[-0.4684, -0.5533],
        [-0.5088, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006847096374258399
Epoch 0, Step 80: train/loss = 0.6535342931747437, train/raw-loss = 0.6534669399261475, train/logprobs = tensor([[-0.5622, -0.8173],
        [-0.5993, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006732074543833733
Epoch 0, Step 81: train/loss = 0.660675585269928, train/raw-loss = 0.6606080532073975, train/logprobs = tensor([[-0.4891, -0.8492],
        [-0.4963, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006755570648238063
Epoch 0, Step 82: train/loss = 0.6622928977012634, train/raw-loss = 0.662223219871521, train/logprobs = tensor([[-0.5810, -0.7663],
        [-0.6482, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006970838876441121
Epoch 0, Step 83: train/loss = 0.6619136333465576, train/raw-loss = 0.661846935749054, train/logprobs = tensor([[-0.5477, -0.6667],
        [-0.5926, -0.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006670970469713211
Epoch 0, Step 84: train/loss = 0.6764739751815796, train/raw-loss = 0.6764081120491028, train/logprobs = tensor([[-0.4949, -0.7941],
        [-0.5125, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006590661942027509
Epoch 0, Step 85: train/loss = 0.6729460954666138, train/raw-loss = 0.6728756427764893, train/logprobs = tensor([[-0.7021, -0.9177],
        [-0.7898, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007045652018859982
Epoch 0, Step 86: train/loss = 0.6572507619857788, train/raw-loss = 0.6571915745735168, train/logprobs = tensor([[-0.5040, -0.6619],
        [-0.5360, -0.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005914671346545219
Epoch 0, Step 87: train/loss = 0.6543859243392944, train/raw-loss = 0.6543176174163818, train/logprobs = tensor([[-0.6250, -0.7965],
        [-0.6713, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006830053171142936
Epoch 0, Step 88: train/loss = 0.6155099868774414, train/raw-loss = 0.6154448986053467, train/logprobs = tensor([[-0.6792, -1.5114],
        [-0.7403, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006511493702419102
Epoch 0, Step 89: train/loss = 0.6651321649551392, train/raw-loss = 0.665066659450531, train/logprobs = tensor([[-0.5978, -0.6588],
        [-0.6277, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006547936354763806
Epoch 0, Step 90: train/loss = 0.6621607542037964, train/raw-loss = 0.6620924472808838, train/logprobs = tensor([[-0.6502, -0.7576],
        [-0.7126, -0.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006835585227236152
Epoch 0, Step 91: train/loss = 0.6593738794326782, train/raw-loss = 0.6593047976493835, train/logprobs = tensor([[-0.6762, -1.1690],
        [-0.7711, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006910940865054727
Epoch 0, Step 92: train/loss = 0.6700291037559509, train/raw-loss = 0.669964611530304, train/logprobs = tensor([[-0.6420, -0.9124],
        [-0.6950, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006443835445679724
Epoch 0, Step 93: train/loss = 0.6632087230682373, train/raw-loss = 0.6631375551223755, train/logprobs = tensor([[-0.5407, -0.6281],
        [-0.6009, -0.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007122678216546774
Epoch 0, Step 94: train/loss = 0.6492125391960144, train/raw-loss = 0.6491420865058899, train/logprobs = tensor([[-0.7990, -1.1197],
        [-0.9667, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007041794015094638
Epoch 0, Step 95: train/loss = 0.6721925735473633, train/raw-loss = 0.672126054763794, train/logprobs = tensor([[-0.5790, -1.0915],
        [-0.6249, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006645218818448484
Epoch 0, Step 96: train/loss = 0.6884866952896118, train/raw-loss = 0.6882091164588928, train/logprobs = tensor([[-0.5180, -0.6046],
        [-0.5105, -0.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027753545437008142
Epoch 0, Step 97: train/loss = 0.6573331952095032, train/raw-loss = 0.6568905115127563, train/logprobs = tensor([[-0.7382, -0.9480],
        [-0.8357, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004427024163305759
Epoch 0, Step 98: train/loss = 0.6877569556236267, train/raw-loss = 0.6873996257781982, train/logprobs = tensor([[-0.6133, -0.7096],
        [-0.6604, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035729478113353252
Epoch 0, Step 99: train/loss = 0.6641057729721069, train/raw-loss = 0.6637963056564331, train/logprobs = tensor([[-0.4639, -0.4720],
        [-0.5371, -0.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003094450803473592
Epoch 0, Step 100: train/loss = 0.680668830871582, train/raw-loss = 0.6803818941116333, train/logprobs = tensor([[-0.5472, -0.6484],
        [-0.5627, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028687696903944016
Epoch 0, Step 101: train/loss = 0.6570868492126465, train/raw-loss = 0.6566863059997559, train/logprobs = tensor([[-0.5970, -1.1452],
        [-0.6109, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004005797207355499
Epoch 0, Step 102: train/loss = 0.6372106075286865, train/raw-loss = 0.6368390321731567, train/logprobs = tensor([[-0.4866, -1.2235],
        [-0.5161, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037152227014303207
Epoch 0, Step 103: train/loss = 0.5872595310211182, train/raw-loss = 0.5869162678718567, train/logprobs = tensor([[-0.7116, -1.7175],
        [-0.7623, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034326347522437572
Epoch 0, Step 104: train/loss = 0.669462263584137, train/raw-loss = 0.6691004037857056, train/logprobs = tensor([[-0.6573, -1.3398],
        [-0.6696, -1.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036182510666549206
Epoch 0, Step 105: train/loss = 0.6644284725189209, train/raw-loss = 0.6640788316726685, train/logprobs = tensor([[-0.6918, -1.1885],
        [-0.7077, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003496142802760005
Epoch 0, Step 106: train/loss = 0.6656418442726135, train/raw-loss = 0.6653688549995422, train/logprobs = tensor([[-0.4584, -0.7647],
        [-0.4830, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002730292733758688
Epoch 0, Step 107: train/loss = 0.6606117486953735, train/raw-loss = 0.6602743864059448, train/logprobs = tensor([[-0.6673, -0.9856],
        [-0.7319, -0.9134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003373410552740097
Epoch 0, Step 108: train/loss = 0.6402857899665833, train/raw-loss = 0.6399447917938232, train/logprobs = tensor([[-0.7880, -0.7740],
        [-0.8939, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034100431948900223
Epoch 0, Step 109: train/loss = 0.6878936886787415, train/raw-loss = 0.6875868439674377, train/logprobs = tensor([[-0.4951, -0.4425],
        [-0.4945, -0.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030684026423841715
Epoch 0, Step 110: train/loss = 0.6858234405517578, train/raw-loss = 0.6854926347732544, train/logprobs = tensor([[-0.4653, -0.5621],
        [-0.4638, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003308885730803013
Epoch 0, Step 111: train/loss = 0.6714319586753845, train/raw-loss = 0.6711580753326416, train/logprobs = tensor([[-0.5412, -1.2767],
        [-0.5626, -1.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027389279566705227
Epoch 0, Step 112: train/loss = 0.6909486055374146, train/raw-loss = 0.6905630826950073, train/logprobs = tensor([[-0.5092, -0.7509],
        [-0.5312, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038548619486391544
Epoch 0, Step 113: train/loss = 0.6663806438446045, train/raw-loss = 0.6660488247871399, train/logprobs = tensor([[-0.6976, -0.6495],
        [-0.7347, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003317819442600012
Epoch 0, Step 114: train/loss = 0.6328283548355103, train/raw-loss = 0.6325329542160034, train/logprobs = tensor([[-0.6256, -1.2294],
        [-0.7034, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002953740069642663
Epoch 0, Step 115: train/loss = 0.6874603033065796, train/raw-loss = 0.6870715022087097, train/logprobs = tensor([[-0.8529, -1.5613],
        [-0.8775, -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038876915350556374
Epoch 0, Step 116: train/loss = 0.6665428280830383, train/raw-loss = 0.6661931276321411, train/logprobs = tensor([[-0.6220, -0.7274],
        [-0.6661, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034971360582858324
Epoch 0, Step 117: train/loss = 0.6665560603141785, train/raw-loss = 0.6662006378173828, train/logprobs = tensor([[-0.6198, -0.6601],
        [-0.6480, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035537611693143845
Epoch 0, Step 118: train/loss = 0.6558387279510498, train/raw-loss = 0.6554815769195557, train/logprobs = tensor([[-0.5367, -0.9899],
        [-0.5558, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003571633016690612
Epoch 0, Step 119: train/loss = 0.6903272271156311, train/raw-loss = 0.6898728609085083, train/logprobs = tensor([[-0.5522, -0.5644],
        [-0.5653, -0.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004544039722532034
Epoch 0, Step 120: train/loss = 0.6842625141143799, train/raw-loss = 0.6838023066520691, train/logprobs = tensor([[-0.6561, -0.7014],
        [-0.6948, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00460236519575119
Epoch 0, Step 121: train/loss = 0.6892048120498657, train/raw-loss = 0.688774585723877, train/logprobs = tensor([[-0.7505, -1.0589],
        [-0.8097, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004302150569856167
Epoch 0, Step 122: train/loss = 0.6713790893554688, train/raw-loss = 0.6709638833999634, train/logprobs = tensor([[-0.6814, -0.9522],
        [-0.7017, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041519333608448505
Epoch 0, Step 123: train/loss = 0.6700873374938965, train/raw-loss = 0.6697773337364197, train/logprobs = tensor([[-0.5919, -0.8075],
        [-0.6137, -0.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003099829889833927
Epoch 0, Step 124: train/loss = 0.653876781463623, train/raw-loss = 0.6535154581069946, train/logprobs = tensor([[-0.6109, -0.8416],
        [-0.6487, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036130081862211227
Epoch 0, Step 125: train/loss = 0.6818460822105408, train/raw-loss = 0.6815530061721802, train/logprobs = tensor([[-0.5332, -0.7155],
        [-0.5321, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029308085795491934
Epoch 0, Step 126: train/loss = 0.6772907972335815, train/raw-loss = 0.6769372820854187, train/logprobs = tensor([[-0.5716, -0.6169],
        [-0.5799, -0.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003534787567332387
Epoch 0, Step 127: train/loss = 0.5924104452133179, train/raw-loss = 0.5920314788818359, train/logprobs = tensor([[-0.5297, -1.7381],
        [-0.5710, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037900335155427456
Epoch 0, Step 128: train/loss = 0.5894901752471924, train/raw-loss = 0.5876904726028442, train/logprobs = tensor([[-0.6646, -2.0778],
        [-0.6797, -1.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017997240647673607
Epoch 0, Step 129: train/loss = 0.6039232015609741, train/raw-loss = 0.6015561819076538, train/logprobs = tensor([[-0.7697, -1.9879],
        [-0.7851, -1.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023670626804232597
Epoch 0, Step 130: train/loss = 0.673664927482605, train/raw-loss = 0.6719871759414673, train/logprobs = tensor([[-0.5934, -0.7549],
        [-0.5619, -0.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016777560114860535
Epoch 0, Step 131: train/loss = 0.6779972910881042, train/raw-loss = 0.6761055588722229, train/logprobs = tensor([[-0.8372, -0.8589],
        [-0.8981, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018917422741651535
Epoch 0, Step 132: train/loss = 0.6574044823646545, train/raw-loss = 0.6557120680809021, train/logprobs = tensor([[-0.5897, -0.5745],
        [-0.6473, -0.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01692415028810501
Epoch 0, Step 133: train/loss = 0.6443973779678345, train/raw-loss = 0.6426870822906494, train/logprobs = tensor([[-0.6184, -1.1870],
        [-0.6082, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017102286219596863
Epoch 0, Step 134: train/loss = 0.6701714992523193, train/raw-loss = 0.6681346297264099, train/logprobs = tensor([[-0.8141, -0.9300],
        [-0.7434, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02036825753748417
Epoch 0, Step 135: train/loss = 0.6725486516952515, train/raw-loss = 0.6706789135932922, train/logprobs = tensor([[-0.5812, -0.6837],
        [-0.6148, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018697375431656837
Epoch 0, Step 136: train/loss = 0.6740874648094177, train/raw-loss = 0.6724382638931274, train/logprobs = tensor([[-0.6263, -0.6640],
        [-0.6333, -0.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016492031514644623
Epoch 0, Step 137: train/loss = 0.6427152752876282, train/raw-loss = 0.6410146355628967, train/logprobs = tensor([[-0.6154, -0.6858],
        [-0.6728, -0.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01700647547841072
Epoch 0, Step 138: train/loss = 0.5975102782249451, train/raw-loss = 0.5956755876541138, train/logprobs = tensor([[-0.6903, -1.3969],
        [-0.7085, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018347157165408134
Epoch 0, Step 139: train/loss = 0.6268821954727173, train/raw-loss = 0.625144362449646, train/logprobs = tensor([[-0.5346, -0.9796],
        [-0.5569, -0.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017378518357872963
Epoch 0, Step 140: train/loss = 0.631547212600708, train/raw-loss = 0.6298601031303406, train/logprobs = tensor([[-0.6204, -0.8832],
        [-0.7069, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016871193423867226
Epoch 0, Step 141: train/loss = 0.6592497825622559, train/raw-loss = 0.657099723815918, train/logprobs = tensor([[-0.7003, -1.0203],
        [-0.7075, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02150077372789383
Epoch 0, Step 142: train/loss = 0.6731835603713989, train/raw-loss = 0.671477198600769, train/logprobs = tensor([[-0.4603, -0.6141],
        [-0.4499, -0.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017063938081264496
Epoch 0, Step 143: train/loss = 0.6782048344612122, train/raw-loss = 0.6761132478713989, train/logprobs = tensor([[-0.5733, -0.9730],
        [-0.5653, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020915741100907326
Epoch 0, Step 144: train/loss = 0.6306663751602173, train/raw-loss = 0.6289221048355103, train/logprobs = tensor([[-0.5060, -0.8879],
        [-0.5307, -0.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017443079501390457
Epoch 0, Step 145: train/loss = 0.6945962309837341, train/raw-loss = 0.6930164098739624, train/logprobs = tensor([[-0.4845, -0.4405],
        [-0.4661, -0.4212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015797169879078865
Epoch 0, Step 146: train/loss = 0.6713689565658569, train/raw-loss = 0.6692862510681152, train/logprobs = tensor([[-0.6025, -0.7927],
        [-0.5933, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020827585831284523
Epoch 0, Step 147: train/loss = 0.6465549468994141, train/raw-loss = 0.6445251703262329, train/logprobs = tensor([[-0.6731, -1.4407],
        [-0.7066, -1.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020297780632972717
Epoch 0, Step 148: train/loss = 0.6625398397445679, train/raw-loss = 0.6604681611061096, train/logprobs = tensor([[-0.6859, -0.7500],
        [-0.7217, -0.6481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02071678265929222
Epoch 0, Step 149: train/loss = 0.6255292892456055, train/raw-loss = 0.623593807220459, train/logprobs = tensor([[-0.6788, -1.5425],
        [-0.6716, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019354885444045067
Epoch 0, Step 150: train/loss = 0.6732056140899658, train/raw-loss = 0.671751081943512, train/logprobs = tensor([[-0.5077, -0.7329],
        [-0.5044, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014545151963829994
Epoch 0, Step 151: train/loss = 0.6732960939407349, train/raw-loss = 0.6715025305747986, train/logprobs = tensor([[-0.7646, -0.9906],
        [-0.7461, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017935598269104958
Epoch 0, Step 152: train/loss = 0.656502366065979, train/raw-loss = 0.6549404859542847, train/logprobs = tensor([[-0.5121, -0.8041],
        [-0.4888, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015619202516973019
Epoch 0, Step 153: train/loss = 0.675667941570282, train/raw-loss = 0.6741334199905396, train/logprobs = tensor([[-0.5112, -0.7349],
        [-0.5013, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015344835817813873
Epoch 0, Step 154: train/loss = 0.6524214148521423, train/raw-loss = 0.6502313613891602, train/logprobs = tensor([[-0.5490, -0.9766],
        [-0.5350, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021900199353694916
Epoch 0, Step 155: train/loss = 0.6817660331726074, train/raw-loss = 0.6798182129859924, train/logprobs = tensor([[-0.5483, -0.6673],
        [-0.5308, -0.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019478125497698784
Epoch 0, Step 156: train/loss = 0.6309428215026855, train/raw-loss = 0.6292914152145386, train/logprobs = tensor([[-0.6282, -1.3119],
        [-0.5947, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01651458628475666
Epoch 0, Step 157: train/loss = 0.6750460863113403, train/raw-loss = 0.6730936765670776, train/logprobs = tensor([[-0.5332, -0.6117],
        [-0.5122, -0.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019524862989783287
Epoch 0, Step 158: train/loss = 0.6236083507537842, train/raw-loss = 0.6217657923698425, train/logprobs = tensor([[-0.5617, -1.5703],
        [-0.5679, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018425587564706802
Epoch 0, Step 159: train/loss = 0.5908886194229126, train/raw-loss = 0.5883889198303223, train/logprobs = tensor([[-0.7945, -1.1411],
        [-0.9206, -0.8065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024997636675834656
Epoch 0, Step 160: train/loss = 0.6614038944244385, train/raw-loss = 0.6587367057800293, train/logprobs = tensor([[-0.6454, -0.7290],
        [-0.6402, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026672236621379852
Epoch 0, Step 161: train/loss = 0.6348430514335632, train/raw-loss = 0.632250189781189, train/logprobs = tensor([[-0.6967, -0.8634],
        [-0.8138, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025929169729351997
Epoch 0, Step 162: train/loss = 0.6655471324920654, train/raw-loss = 0.6631524562835693, train/logprobs = tensor([[-0.5567, -0.5316],
        [-0.6367, -0.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023946862667798996
Epoch 0, Step 163: train/loss = 0.6298260688781738, train/raw-loss = 0.6278146505355835, train/logprobs = tensor([[-0.5916, -0.8900],
        [-0.6434, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020114069804549217
Epoch 0, Step 164: train/loss = 0.6914345026016235, train/raw-loss = 0.6888157725334167, train/logprobs = tensor([[-0.6971, -0.7616],
        [-0.6890, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026187147945165634
Epoch 0, Step 165: train/loss = 0.6322473883628845, train/raw-loss = 0.6301639080047607, train/logprobs = tensor([[-0.5215, -0.8192],
        [-0.5845, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020834464579820633
Epoch 0, Step 166: train/loss = 0.6421470642089844, train/raw-loss = 0.6401803493499756, train/logprobs = tensor([[-0.5973, -0.8177],
        [-0.6846, -0.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01966719701886177
Epoch 0, Step 167: train/loss = 0.670121967792511, train/raw-loss = 0.6671781539916992, train/logprobs = tensor([[-0.5535, -0.9780],
        [-0.5332, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02943790890276432
Epoch 0, Step 168: train/loss = 0.6172126531600952, train/raw-loss = 0.6142092943191528, train/logprobs = tensor([[-0.7128, -1.6602],
        [-0.7038, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03003380447626114
Epoch 0, Step 169: train/loss = 0.6594843864440918, train/raw-loss = 0.6564266681671143, train/logprobs = tensor([[-0.6823, -1.0403],
        [-0.7123, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030577348545193672
Epoch 0, Step 170: train/loss = 0.6769464612007141, train/raw-loss = 0.6735783815383911, train/logprobs = tensor([[-1.3549, -1.0444],
        [-1.2815, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03368107229471207
Epoch 0, Step 171: train/loss = 0.632525622844696, train/raw-loss = 0.629807710647583, train/logprobs = tensor([[-0.8273, -0.9657],
        [-0.7881, -0.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027178943157196045
Epoch 0, Step 172: train/loss = 0.6473464369773865, train/raw-loss = 0.6443753242492676, train/logprobs = tensor([[-0.6911, -0.9936],
        [-0.6879, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029711365699768066
Epoch 0, Step 173: train/loss = 0.6000754833221436, train/raw-loss = 0.5976885557174683, train/logprobs = tensor([[-0.5857, -1.4696],
        [-0.5326, -0.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02386925369501114
Epoch 0, Step 174: train/loss = 0.6158959865570068, train/raw-loss = 0.613945722579956, train/logprobs = tensor([[-0.5893, -0.9383],
        [-0.5898, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01950336992740631
Epoch 0, Step 175: train/loss = 0.6805942058563232, train/raw-loss = 0.6780246496200562, train/logprobs = tensor([[-0.5860, -0.8109],
        [-0.6115, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02569577470421791
Epoch 0, Step 176: train/loss = 0.6289495825767517, train/raw-loss = 0.626347541809082, train/logprobs = tensor([[-0.5479, -0.8740],
        [-0.5499, -0.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026020821183919907
Epoch 0, Step 177: train/loss = 0.523872971534729, train/raw-loss = 0.5213616490364075, train/logprobs = tensor([[-0.6035, -2.4251],
        [-0.6583, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025113552808761597
Epoch 0, Step 178: train/loss = 0.6656181812286377, train/raw-loss = 0.6621936559677124, train/logprobs = tensor([[-0.5932, -0.8476],
        [-0.5904, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034245770424604416
Epoch 0, Step 179: train/loss = 0.6610407829284668, train/raw-loss = 0.658521294593811, train/logprobs = tensor([[-0.6176, -0.7539],
        [-0.5514, -0.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025194507092237473
Epoch 0, Step 180: train/loss = 0.6248066425323486, train/raw-loss = 0.6216371059417725, train/logprobs = tensor([[-0.6879, -1.5527],
        [-0.6828, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0316954180598259
Epoch 0, Step 181: train/loss = 0.6217253804206848, train/raw-loss = 0.6190077066421509, train/logprobs = tensor([[-0.4091, -1.4777],
        [-0.4077, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02717718295753002
Epoch 0, Step 182: train/loss = 0.6890584230422974, train/raw-loss = 0.686561644077301, train/logprobs = tensor([[-0.5137, -0.6240],
        [-0.5026, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024968214333057404
Epoch 0, Step 183: train/loss = 0.6571668386459351, train/raw-loss = 0.6540946960449219, train/logprobs = tensor([[-0.5780, -0.8446],
        [-0.5348, -0.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030721355229616165
Epoch 0, Step 184: train/loss = 0.621595025062561, train/raw-loss = 0.618798017501831, train/logprobs = tensor([[-0.8547, -0.9838],
        [-0.9185, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02796988934278488
Epoch 0, Step 185: train/loss = 0.637047290802002, train/raw-loss = 0.6347756385803223, train/logprobs = tensor([[-0.5502, -0.9962],
        [-0.5331, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022716227918863297
Epoch 0, Step 186: train/loss = 0.6951121091842651, train/raw-loss = 0.6923853158950806, train/logprobs = tensor([[-0.4788, -0.5323],
        [-0.4815, -0.5318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027268141508102417
Epoch 0, Step 187: train/loss = 0.5863416790962219, train/raw-loss = 0.5835689306259155, train/logprobs = tensor([[-0.6117, -1.0634],
        [-0.7015, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027727579697966576
Epoch 0, Step 188: train/loss = 0.6481013298034668, train/raw-loss = 0.6452954411506653, train/logprobs = tensor([[-0.7721, -0.7166],
        [-0.8141, -0.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02805926650762558
Epoch 0, Step 189: train/loss = 0.670616865158081, train/raw-loss = 0.6678391695022583, train/logprobs = tensor([[-0.6591, -0.8419],
        [-0.5654, -0.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027776680886745453
Epoch 0, Step 190: train/loss = 0.6722351908683777, train/raw-loss = 0.6692642569541931, train/logprobs = tensor([[-0.6526, -0.9626],
        [-0.6652, -0.8670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029709840193390846
Epoch 0, Step 191: train/loss = 0.6510497331619263, train/raw-loss = 0.6481362581253052, train/logprobs = tensor([[-0.5092, -1.1726],
        [-0.5209, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029135307297110558
Epoch 0, Step 192: train/loss = 0.5708392858505249, train/raw-loss = 0.5666961669921875, train/logprobs = tensor([[-0.5844, -1.3369],
        [-0.5961, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0414305217564106
Epoch 0, Step 193: train/loss = 0.6434558629989624, train/raw-loss = 0.6379258036613464, train/logprobs = tensor([[-0.6139, -1.0741],
        [-0.5904, -0.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055301085114479065
Epoch 0, Step 194: train/loss = 0.6556665897369385, train/raw-loss = 0.6495083570480347, train/logprobs = tensor([[-0.7363, -0.7068],
        [-0.8047, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061582766473293304
Epoch 0, Step 195: train/loss = 0.6567877531051636, train/raw-loss = 0.6516723036766052, train/logprobs = tensor([[-0.7583, -0.8778],
        [-0.7920, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05115412920713425
Epoch 0, Step 196: train/loss = 0.8565949201583862, train/raw-loss = 0.8496602773666382, train/logprobs = tensor([[-1.0455, -1.7694],
        [-1.0667, -2.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06934639066457748
Epoch 0, Step 197: train/loss = 0.7013332843780518, train/raw-loss = 0.6957480311393738, train/logprobs = tensor([[-1.0530, -1.1229],
        [-0.7922, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05585242435336113
Epoch 0, Step 198: train/loss = 0.6772559285163879, train/raw-loss = 0.6727111339569092, train/logprobs = tensor([[-0.5280, -0.8139],
        [-0.4807, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04544767364859581
Epoch 0, Step 199: train/loss = 0.6377249956130981, train/raw-loss = 0.6310262084007263, train/logprobs = tensor([[-0.6278, -1.5546],
        [-0.6037, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698791682720184
Epoch 0, Step 200: train/loss = 0.6272214651107788, train/raw-loss = 0.622394323348999, train/logprobs = tensor([[-0.6696, -1.2077],
        [-0.6091, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04827165603637695
Epoch 0, Step 201: train/loss = 0.5663509368896484, train/raw-loss = 0.5611010193824768, train/logprobs = tensor([[-0.5640, -2.1423],
        [-0.5225, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052498709410429
Epoch 0, Step 202: train/loss = 0.6810483932495117, train/raw-loss = 0.675755500793457, train/logprobs = tensor([[-0.5561, -0.6595],
        [-0.5147, -0.5434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05292871594429016
Epoch 0, Step 203: train/loss = 0.609331488609314, train/raw-loss = 0.6044579744338989, train/logprobs = tensor([[-0.6014, -1.2226],
        [-0.5380, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04873589053750038
Epoch 0, Step 204: train/loss = 0.6422786712646484, train/raw-loss = 0.6365959048271179, train/logprobs = tensor([[-0.8886, -1.3760],
        [-0.8199, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056828245520591736
Epoch 0, Step 205: train/loss = 0.6594948768615723, train/raw-loss = 0.6534326076507568, train/logprobs = tensor([[-0.6924, -0.7293],
        [-0.7253, -0.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060622572898864746
Epoch 0, Step 206: train/loss = 0.6739240288734436, train/raw-loss = 0.6691979169845581, train/logprobs = tensor([[-0.5552, -0.6532],
        [-0.5235, -0.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0472608357667923
Epoch 0, Step 207: train/loss = 0.7020987868309021, train/raw-loss = 0.6971677541732788, train/logprobs = tensor([[-0.4659, -0.8057],
        [-0.4516, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049310021102428436
Epoch 0, Step 208: train/loss = 0.5768550038337708, train/raw-loss = 0.571361243724823, train/logprobs = tensor([[-0.5530, -2.0485],
        [-0.6130, -1.3115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054938070476055145
Epoch 0, Step 209: train/loss = 0.6293964982032776, train/raw-loss = 0.6251712441444397, train/logprobs = tensor([[-0.4570, -1.0423],
        [-0.4399, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04225224256515503
Epoch 0, Step 210: train/loss = 0.6800794005393982, train/raw-loss = 0.6750208139419556, train/logprobs = tensor([[-0.5560, -0.7189],
        [-0.5510, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050585683435201645
Epoch 0, Step 211: train/loss = 0.6363626718521118, train/raw-loss = 0.6300290822982788, train/logprobs = tensor([[-0.7754, -0.9797],
        [-0.8381, -0.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0633358359336853
Epoch 0, Step 212: train/loss = 0.6305628418922424, train/raw-loss = 0.625208854675293, train/logprobs = tensor([[-0.5194, -1.0858],
        [-0.5199, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05353943258523941
Epoch 0, Step 213: train/loss = 0.6112470030784607, train/raw-loss = 0.6054515242576599, train/logprobs = tensor([[-0.6206, -1.0945],
        [-0.6393, -0.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057954948395490646
Epoch 0, Step 214: train/loss = 0.6623579263687134, train/raw-loss = 0.6569247841835022, train/logprobs = tensor([[-0.6643, -1.3750],
        [-0.6846, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054331883788108826
Epoch 0, Step 215: train/loss = 0.6301976442337036, train/raw-loss = 0.6234792470932007, train/logprobs = tensor([[-0.7128, -1.5858],
        [-0.7031, -1.2442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.067183718085289
Epoch 0, Step 216: train/loss = 0.6705482006072998, train/raw-loss = 0.6647251844406128, train/logprobs = tensor([[-0.5288, -0.6910],
        [-0.5397, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0582304373383522
Epoch 0, Step 217: train/loss = 0.5672956705093384, train/raw-loss = 0.5615299940109253, train/logprobs = tensor([[-0.7074, -1.2534],
        [-0.7662, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05765770003199577
Epoch 0, Step 218: train/loss = 0.6749544739723206, train/raw-loss = 0.6694900989532471, train/logprobs = tensor([[-0.5023, -0.7169],
        [-0.4590, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05464399233460426
Epoch 0, Step 219: train/loss = 0.6762144565582275, train/raw-loss = 0.670768678188324, train/logprobs = tensor([[-0.5676, -0.7374],
        [-0.5826, -0.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05445782095193863
Epoch 0, Step 220: train/loss = 0.6667797565460205, train/raw-loss = 0.6605410575866699, train/logprobs = tensor([[-0.6746, -0.9681],
        [-0.6685, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06238681077957153
Epoch 0, Step 221: train/loss = 0.5739136338233948, train/raw-loss = 0.5690438151359558, train/logprobs = tensor([[-0.5824, -1.4619],
        [-0.5782, -0.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04869798570871353
Epoch 0, Step 222: train/loss = 0.6012078523635864, train/raw-loss = 0.5965175032615662, train/logprobs = tensor([[-0.7137, -1.4809],
        [-0.6724, -0.9706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04690371826291084
Epoch 0, Step 223: train/loss = 0.5415365695953369, train/raw-loss = 0.5360271334648132, train/logprobs = tensor([[-0.6106, -1.5096],
        [-0.6727, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0550944022834301
Epoch 0, Step 224: train/loss = 0.6599435806274414, train/raw-loss = 0.6525125503540039, train/logprobs = tensor([[-0.5777, -0.7865],
        [-0.5560, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07431049644947052
Epoch 0, Step 225: train/loss = 0.6565690636634827, train/raw-loss = 0.6511198878288269, train/logprobs = tensor([[-0.4500, -0.7696],
        [-0.4376, -0.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0544915497303009
Epoch 0, Step 226: train/loss = 0.553159236907959, train/raw-loss = 0.5443168878555298, train/logprobs = tensor([[-0.7064, -2.1807],
        [-0.7611, -1.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08842369168996811
Epoch 0, Step 227: train/loss = 0.6391280293464661, train/raw-loss = 0.6308736801147461, train/logprobs = tensor([[-0.5552, -1.0520],
        [-0.5621, -0.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08254320919513702
Epoch 0, Step 228: train/loss = 0.627346932888031, train/raw-loss = 0.6202759742736816, train/logprobs = tensor([[-0.5423, -0.9525],
        [-0.5627, -0.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0707097053527832
Epoch 0, Step 229: train/loss = 0.6549676656723022, train/raw-loss = 0.6464348435401917, train/logprobs = tensor([[-0.4837, -0.7679],
        [-0.4929, -0.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08532837778329849
Epoch 0, Step 230: train/loss = 0.6547459959983826, train/raw-loss = 0.6472448110580444, train/logprobs = tensor([[-0.5698, -0.8667],
        [-0.5548, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501186430454254
Epoch 0, Step 231: train/loss = 0.6199992299079895, train/raw-loss = 0.612408459186554, train/logprobs = tensor([[-0.5496, -1.5279],
        [-0.5326, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07590756565332413
Epoch 0, Step 232: train/loss = 0.48115479946136475, train/raw-loss = 0.4718838334083557, train/logprobs = tensor([[-0.7731, -2.3977],
        [-0.8143, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09270993620157242
Epoch 0, Step 233: train/loss = 0.6105043888092041, train/raw-loss = 0.6043033599853516, train/logprobs = tensor([[-0.5914, -0.9092],
        [-0.5801, -0.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06201095134019852
Epoch 0, Step 234: train/loss = 0.5426837205886841, train/raw-loss = 0.5349576473236084, train/logprobs = tensor([[-0.7539, -1.3466],
        [-0.8158, -0.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07726085931062698
Epoch 0, Step 235: train/loss = 0.6705473065376282, train/raw-loss = 0.6637474298477173, train/logprobs = tensor([[-0.6760, -0.6540],
        [-0.6030, -0.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.067998506128788
Epoch 0, Step 236: train/loss = 0.6597504615783691, train/raw-loss = 0.6498993635177612, train/logprobs = tensor([[-0.7704, -1.0930],
        [-0.7325, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09851080179214478
Epoch 0, Step 237: train/loss = 0.5791134238243103, train/raw-loss = 0.5725342631340027, train/logprobs = tensor([[-0.7473, -1.7300],
        [-0.7066, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06579189002513885
Epoch 0, Step 238: train/loss = 0.6249870657920837, train/raw-loss = 0.6188039183616638, train/logprobs = tensor([[-0.6599, -1.2957],
        [-0.5016, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06183115392923355
Epoch 0, Step 239: train/loss = 0.5582393407821655, train/raw-loss = 0.5516489744186401, train/logprobs = tensor([[-0.4936, -1.3488],
        [-0.5030, -0.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06590350717306137
Epoch 0, Step 240: train/loss = 0.6884768009185791, train/raw-loss = 0.6816320419311523, train/logprobs = tensor([[-0.4542, -0.5627],
        [-0.4563, -0.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0684470608830452
Epoch 0, Step 241: train/loss = 0.6137607097625732, train/raw-loss = 0.6060292720794678, train/logprobs = tensor([[-0.6543, -1.0848],
        [-0.6067, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773143470287323
Epoch 0, Step 242: train/loss = 0.657724142074585, train/raw-loss = 0.6501344442367554, train/logprobs = tensor([[-0.6326, -0.6977],
        [-0.7201, -0.6059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758967399597168
Epoch 0, Step 243: train/loss = 0.6839492321014404, train/raw-loss = 0.6762324571609497, train/logprobs = tensor([[-0.5600, -1.0354],
        [-0.5364, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07716745883226395
Epoch 0, Step 244: train/loss = 0.6668411493301392, train/raw-loss = 0.6608411073684692, train/logprobs = tensor([[-0.4565, -0.7049],
        [-0.4079, -0.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06000027805566788
Epoch 0, Step 245: train/loss = 0.6055257320404053, train/raw-loss = 0.5971174240112305, train/logprobs = tensor([[-0.6951, -1.4863],
        [-0.5781, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08408334851264954
Epoch 0, Step 246: train/loss = 0.6612675786018372, train/raw-loss = 0.6535816192626953, train/logprobs = tensor([[-0.6567, -0.8559],
        [-0.6730, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07685981690883636
Epoch 0, Step 247: train/loss = 0.5916855931282043, train/raw-loss = 0.5843526124954224, train/logprobs = tensor([[-0.6804, -1.2153],
        [-0.6697, -0.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07332967221736908
Epoch 0, Step 248: train/loss = 0.6869639754295349, train/raw-loss = 0.680012583732605, train/logprobs = tensor([[-0.5775, -0.7800],
        [-0.4818, -0.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06951430439949036
Epoch 0, Step 249: train/loss = 0.6228926777839661, train/raw-loss = 0.6168068647384644, train/logprobs = tensor([[-0.5834, -0.9231],
        [-0.5550, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06085830181837082
Epoch 0, Step 250: train/loss = 0.7241804599761963, train/raw-loss = 0.7151176929473877, train/logprobs = tensor([[-0.7463, -0.6806],
        [-0.5501, -0.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906280130147934
Epoch 0, Step 251: train/loss = 0.6262170076370239, train/raw-loss = 0.616271436214447, train/logprobs = tensor([[-0.7991, -1.0316],
        [-0.8055, -0.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09945572912693024
Epoch 0, Step 252: train/loss = 0.5968571305274963, train/raw-loss = 0.5882385969161987, train/logprobs = tensor([[-0.6701, -2.3035],
        [-0.6115, -1.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861852616071701
Epoch 0, Step 253: train/loss = 0.7059884667396545, train/raw-loss = 0.6986833810806274, train/logprobs = tensor([[-0.6296, -0.6679],
        [-0.4885, -0.5286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0730518251657486
Epoch 0, Step 254: train/loss = 0.6778584122657776, train/raw-loss = 0.6699346303939819, train/logprobs = tensor([[-0.5561, -1.0495],
        [-0.5918, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07923810184001923
Epoch 0, Step 255: train/loss = 0.550107479095459, train/raw-loss = 0.5430405139923096, train/logprobs = tensor([[-0.5920, -1.5344],
        [-0.5821, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706692636013031
Epoch 0, Step 256: train/loss = 0.6607978940010071, train/raw-loss = 0.6515566110610962, train/logprobs = tensor([[-1.0289, -1.5315],
        [-0.7635, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09241308271884918
Epoch 0, Step 257: train/loss = 0.5731518268585205, train/raw-loss = 0.5647355318069458, train/logprobs = tensor([[-0.7420, -1.6363],
        [-0.5903, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08416347950696945
Epoch 0, Step 258: train/loss = 0.6225438117980957, train/raw-loss = 0.6127164363861084, train/logprobs = tensor([[-0.6562, -1.0943],
        [-0.6587, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827421605587006
Epoch 0, Step 259: train/loss = 0.5295922756195068, train/raw-loss = 0.5206454992294312, train/logprobs = tensor([[-0.6574, -2.4623],
        [-0.8264, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08946792781352997
Epoch 0, Step 260: train/loss = 0.6187090277671814, train/raw-loss = 0.6112676858901978, train/logprobs = tensor([[-0.4521, -0.8750],
        [-0.4659, -0.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441360503435135
Epoch 0, Step 261: train/loss = 0.5786111354827881, train/raw-loss = 0.5710034370422363, train/logprobs = tensor([[-0.5541, -1.1282],
        [-0.6294, -0.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07607737183570862
Epoch 0, Step 262: train/loss = 0.5944214463233948, train/raw-loss = 0.5849685668945312, train/logprobs = tensor([[-0.7230, -0.9702],
        [-0.8844, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09452876448631287
Epoch 0, Step 263: train/loss = 0.6151406764984131, train/raw-loss = 0.605182945728302, train/logprobs = tensor([[-0.5873, -1.1930],
        [-0.6104, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09957699477672577
Epoch 0, Step 264: train/loss = 0.5520387291908264, train/raw-loss = 0.5432096719741821, train/logprobs = tensor([[-0.6016, -1.5513],
        [-0.6309, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0882904976606369
Epoch 0, Step 265: train/loss = 0.6268602609634399, train/raw-loss = 0.6178639531135559, train/logprobs = tensor([[-0.5976, -1.1671],
        [-0.6125, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08996336907148361
Epoch 0, Step 266: train/loss = 0.5809438228607178, train/raw-loss = 0.5732938051223755, train/logprobs = tensor([[-0.5945, -1.7902],
        [-0.6233, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07650038599967957
Epoch 0, Step 267: train/loss = 0.6716009378433228, train/raw-loss = 0.6626476049423218, train/logprobs = tensor([[-0.6828, -0.8374],
        [-0.6933, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953361213207245
Epoch 0, Step 268: train/loss = 0.6054007411003113, train/raw-loss = 0.5985649228096008, train/logprobs = tensor([[-0.4775, -1.0115],
        [-0.4712, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06835874915122986
Epoch 0, Step 269: train/loss = 0.671038031578064, train/raw-loss = 0.6622592210769653, train/logprobs = tensor([[-0.5592, -0.7179],
        [-0.5241, -0.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08778882026672363
Epoch 0, Step 270: train/loss = 0.6192834973335266, train/raw-loss = 0.61170893907547, train/logprobs = tensor([[-0.4977, -0.8504],
        [-0.4919, -0.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07574581354856491
Epoch 0, Step 271: train/loss = 0.6400646567344666, train/raw-loss = 0.6328503489494324, train/logprobs = tensor([[-0.4483, -1.1445],
        [-0.4535, -0.8565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07214238494634628
Epoch 0, Step 272: train/loss = 0.6789703369140625, train/raw-loss = 0.6687215566635132, train/logprobs = tensor([[-0.6728, -1.2636],
        [-0.6911, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10248778760433197
Epoch 0, Step 273: train/loss = 0.598537027835846, train/raw-loss = 0.5897098183631897, train/logprobs = tensor([[-0.7663, -1.0427],
        [-0.8034, -0.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08827187120914459
Epoch 0, Step 274: train/loss = 0.7018362283706665, train/raw-loss = 0.6932119727134705, train/logprobs = tensor([[-0.5807, -0.9041],
        [-0.5754, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0862426906824112
Epoch 0, Step 275: train/loss = 0.5450385808944702, train/raw-loss = 0.5382011532783508, train/logprobs = tensor([[-0.5460, -1.7387],
        [-0.5627, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683746188879013
Epoch 0, Step 276: train/loss = 0.5732671618461609, train/raw-loss = 0.5644566416740417, train/logprobs = tensor([[-0.6091, -1.8171],
        [-0.6206, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881054475903511
Epoch 0, Step 277: train/loss = 0.6433046460151672, train/raw-loss = 0.6346900463104248, train/logprobs = tensor([[-0.6050, -1.0781],
        [-0.5652, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08614566177129745
Epoch 0, Step 278: train/loss = 0.5680819749832153, train/raw-loss = 0.5603484511375427, train/logprobs = tensor([[-0.6768, -1.2220],
        [-0.6657, -0.4629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07733538746833801
Epoch 0, Step 279: train/loss = 0.5459759831428528, train/raw-loss = 0.5365121364593506, train/logprobs = tensor([[-0.7765, -2.6990],
        [-0.7579, -1.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09463843703269958
Epoch 0, Step 280: train/loss = 0.5948581099510193, train/raw-loss = 0.5877331495285034, train/logprobs = tensor([[-0.6260, -0.9040],
        [-0.6779, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07124951481819153
Epoch 0, Step 281: train/loss = 0.4864138662815094, train/raw-loss = 0.47867974638938904, train/logprobs = tensor([[-0.5182, -2.9528],
        [-0.4939, -1.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734113186597824
Epoch 0, Step 282: train/loss = 0.6002568602561951, train/raw-loss = 0.5908276438713074, train/logprobs = tensor([[-0.8351, -1.5660],
        [-0.9024, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09429177641868591
Epoch 0, Step 283: train/loss = 0.6891754865646362, train/raw-loss = 0.679579496383667, train/logprobs = tensor([[-0.7166, -0.5938],
        [-0.6259, -0.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09595991671085358
Epoch 0, Step 284: train/loss = 0.637554943561554, train/raw-loss = 0.6281725168228149, train/logprobs = tensor([[-0.6901, -1.1189],
        [-0.5889, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382381290197372
Epoch 0, Step 285: train/loss = 0.6798242926597595, train/raw-loss = 0.6701115965843201, train/logprobs = tensor([[-0.7380, -0.7947],
        [-0.7395, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09712732583284378
Epoch 0, Step 286: train/loss = 0.6240681409835815, train/raw-loss = 0.6172841787338257, train/logprobs = tensor([[-0.5603, -0.9977],
        [-0.5015, -0.5874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06783957779407501
Epoch 0, Step 287: train/loss = 0.5948370695114136, train/raw-loss = 0.5882390737533569, train/logprobs = tensor([[-0.4733, -1.5296],
        [-0.5133, -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06598025560379028
Epoch 0, Step 288: train/loss = 0.6925227642059326, train/raw-loss = 0.6803894639015198, train/logprobs = tensor([[-0.6896, -1.0079],
        [-0.6411, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12133299559354782
Epoch 0, Step 289: train/loss = 0.5753169655799866, train/raw-loss = 0.5646700859069824, train/logprobs = tensor([[-0.6210, -1.4771],
        [-0.6461, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.106469064950943
Epoch 0, Step 290: train/loss = 0.551790177822113, train/raw-loss = 0.5429062247276306, train/logprobs = tensor([[-0.5532, -1.4307],
        [-0.6501, -0.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08883960545063019
Epoch 0, Step 291: train/loss = 0.5527076125144958, train/raw-loss = 0.5431383848190308, train/logprobs = tensor([[-0.7197, -2.3459],
        [-0.6745, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09569181501865387
Epoch 0, Step 292: train/loss = 0.6544086933135986, train/raw-loss = 0.6442019939422607, train/logprobs = tensor([[-0.8621, -1.0238],
        [-0.6235, -0.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10206728428602219
Epoch 0, Step 293: train/loss = 0.5922367572784424, train/raw-loss = 0.5840960144996643, train/logprobs = tensor([[-0.5769, -1.3497],
        [-0.5638, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140774816274643
Epoch 0, Step 294: train/loss = 0.6041151881217957, train/raw-loss = 0.5940542221069336, train/logprobs = tensor([[-0.8254, -1.5503],
        [-0.6895, -0.8562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060964524745941
Epoch 0, Step 295: train/loss = 0.538415789604187, train/raw-loss = 0.5297122001647949, train/logprobs = tensor([[-0.7202, -1.7009],
        [-0.6289, -0.7255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703581243753433
Epoch 0, Step 296: train/loss = 0.6763468980789185, train/raw-loss = 0.6677555441856384, train/logprobs = tensor([[-0.7667, -0.6996],
        [-0.7722, -0.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08591344207525253
Epoch 0, Step 297: train/loss = 0.6005702614784241, train/raw-loss = 0.5915842652320862, train/logprobs = tensor([[-0.7996, -1.3953],
        [-0.6607, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986025303602219
Epoch 0, Step 298: train/loss = 0.6655992269515991, train/raw-loss = 0.6544215083122253, train/logprobs = tensor([[-0.6985, -1.0873],
        [-0.6406, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1117764562368393
Epoch 0, Step 299: train/loss = 0.5162159204483032, train/raw-loss = 0.5070165395736694, train/logprobs = tensor([[-0.6541, -1.5916],
        [-0.7000, -0.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09199376404285431
Epoch 0, Step 300: train/loss = 0.5317531228065491, train/raw-loss = 0.5221394300460815, train/logprobs = tensor([[-0.5890, -2.8924],
        [-0.5866, -1.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613688290119171
Epoch 0, Step 301: train/loss = 0.5470073819160461, train/raw-loss = 0.5335038304328918, train/logprobs = tensor([[-0.9600, -1.8469],
        [-1.0373, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13503554463386536
Epoch 0, Step 302: train/loss = 0.6775208711624146, train/raw-loss = 0.6685220003128052, train/logprobs = tensor([[-0.7398, -0.9242],
        [-0.6891, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08998899161815643
Epoch 0, Step 303: train/loss = 0.6681286692619324, train/raw-loss = 0.6562248468399048, train/logprobs = tensor([[-0.6585, -0.8473],
        [-0.6124, -0.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903853714466095
Epoch 0, Step 304: train/loss = 0.4883100390434265, train/raw-loss = 0.47932395339012146, train/logprobs = tensor([[-0.6328, -2.5567],
        [-0.6116, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986089378595352
Epoch 0, Step 305: train/loss = 0.6252585649490356, train/raw-loss = 0.6170061826705933, train/logprobs = tensor([[-0.4808, -1.1944],
        [-0.5063, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0825241282582283
Epoch 0, Step 306: train/loss = 0.625582754611969, train/raw-loss = 0.614433765411377, train/logprobs = tensor([[-0.6975, -1.1480],
        [-0.6395, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114896684885025
Epoch 0, Step 307: train/loss = 0.5891017913818359, train/raw-loss = 0.5788722038269043, train/logprobs = tensor([[-0.9146, -1.5942],
        [-0.8463, -0.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10229586064815521
Epoch 0, Step 308: train/loss = 0.6073269248008728, train/raw-loss = 0.5985523462295532, train/logprobs = tensor([[-0.5700, -1.1551],
        [-0.4981, -0.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08774574100971222
Epoch 0, Step 309: train/loss = 0.5935512781143188, train/raw-loss = 0.5837287902832031, train/logprobs = tensor([[-2.7718, -3.2658],
        [-2.5303, -2.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0982242226600647
Epoch 0, Step 310: train/loss = 0.560090959072113, train/raw-loss = 0.5508136749267578, train/logprobs = tensor([[-0.5727, -1.9118],
        [-0.6045, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277287125587463
Epoch 0, Step 311: train/loss = 0.6784957647323608, train/raw-loss = 0.6694851517677307, train/logprobs = tensor([[-0.6338, -0.7844],
        [-0.6446, -0.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09010639041662216
Epoch 0, Step 312: train/loss = 0.5744976997375488, train/raw-loss = 0.5640462040901184, train/logprobs = tensor([[-0.6775, -2.2552],
        [-0.6691, -1.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10451477020978928
Epoch 0, Step 313: train/loss = 0.6633031368255615, train/raw-loss = 0.6524207592010498, train/logprobs = tensor([[-1.1966, -2.0707],
        [-0.9447, -1.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882353782653809
Epoch 0, Step 314: train/loss = 0.6441927552223206, train/raw-loss = 0.6337243318557739, train/logprobs = tensor([[-0.6363, -0.9337],
        [-0.7012, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468438267707825
Epoch 0, Step 315: train/loss = 0.6773480772972107, train/raw-loss = 0.6677169799804688, train/logprobs = tensor([[-0.6106, -0.7774],
        [-0.6295, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09631116688251495
Epoch 0, Step 316: train/loss = 0.6123793125152588, train/raw-loss = 0.6015923023223877, train/logprobs = tensor([[-0.7533, -1.1637],
        [-0.6488, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787025094032288
Epoch 0, Step 317: train/loss = 0.5770629644393921, train/raw-loss = 0.5663332343101501, train/logprobs = tensor([[-0.6188, -1.2122],
        [-0.6360, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10729741305112839
Epoch 0, Step 318: train/loss = 0.5968466997146606, train/raw-loss = 0.5880608558654785, train/logprobs = tensor([[-0.5840, -0.9531],
        [-0.6054, -0.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08785828948020935
Epoch 0, Step 319: train/loss = 0.58940589427948, train/raw-loss = 0.5804556608200073, train/logprobs = tensor([[-0.5527, -1.4819],
        [-0.5321, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950210362672806
Epoch 0, Step 320: train/loss = 0.5324761271476746, train/raw-loss = 0.5228498578071594, train/logprobs = tensor([[-0.6519, -2.5474],
        [-0.5816, -0.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09626275300979614
Epoch 0, Step 321: train/loss = 0.6850172281265259, train/raw-loss = 0.6733610033988953, train/logprobs = tensor([[-1.3111, -1.5232],
        [-0.9614, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11656207591295242
Epoch 0, Step 322: train/loss = 0.6056525707244873, train/raw-loss = 0.5954165458679199, train/logprobs = tensor([[-0.7846, -1.3615],
        [-0.7929, -0.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236074775457382
Epoch 0, Step 323: train/loss = 0.6572665572166443, train/raw-loss = 0.6458448171615601, train/logprobs = tensor([[-1.1900, -1.6289],
        [-1.1144, -1.3435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11421720683574677
Epoch 0, Step 324: train/loss = 0.6636408567428589, train/raw-loss = 0.6537017822265625, train/logprobs = tensor([[-0.5866, -0.6996],
        [-0.5709, -0.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09939038753509521
Epoch 0, Step 325: train/loss = 0.6983224153518677, train/raw-loss = 0.6856891512870789, train/logprobs = tensor([[-0.7780, -1.6481],
        [-0.7860, -1.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126332089304924
Epoch 0, Step 326: train/loss = 0.59903484582901, train/raw-loss = 0.5877974629402161, train/logprobs = tensor([[-0.8429, -1.1599],
        [-0.7542, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11237332224845886
Epoch 0, Step 327: train/loss = 0.5613669157028198, train/raw-loss = 0.5508812069892883, train/logprobs = tensor([[-0.7342, -1.3811],
        [-0.7375, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10485702753067017
Epoch 0, Step 328: train/loss = 0.513576865196228, train/raw-loss = 0.5040078163146973, train/logprobs = tensor([[-0.5705, -1.9671],
        [-0.6084, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09569008648395538
Epoch 0, Step 329: train/loss = 0.6183947920799255, train/raw-loss = 0.6062361001968384, train/logprobs = tensor([[-0.7927, -1.5796],
        [-0.6890, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158702313899994
Epoch 0, Step 330: train/loss = 0.5172497630119324, train/raw-loss = 0.5077764391899109, train/logprobs = tensor([[-0.6529, -1.6570],
        [-0.6821, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473293274641037
Epoch 0, Step 331: train/loss = 0.5657799243927002, train/raw-loss = 0.5562927722930908, train/logprobs = tensor([[-0.5519, -2.0924],
        [-0.5986, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09487150609493256
Epoch 0, Step 332: train/loss = 0.6839513182640076, train/raw-loss = 0.6763519048690796, train/logprobs = tensor([[-0.4905, -0.5775],
        [-0.4334, -0.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07599429786205292
Epoch 0, Step 333: train/loss = 0.5515486001968384, train/raw-loss = 0.5413382649421692, train/logprobs = tensor([[-0.7225, -2.8941],
        [-0.7560, -1.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10210375487804413
Epoch 0, Step 334: train/loss = 0.6133915185928345, train/raw-loss = 0.6037724018096924, train/logprobs = tensor([[-0.6110, -1.6047],
        [-0.5429, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09619119763374329
Epoch 0, Step 335: train/loss = 0.5963077545166016, train/raw-loss = 0.5856853723526001, train/logprobs = tensor([[-0.7390, -1.1658],
        [-0.8115, -0.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10622377693653107
Epoch 0, Step 336: train/loss = 0.5198104381561279, train/raw-loss = 0.5090095400810242, train/logprobs = tensor([[-0.6318, -1.7629],
        [-0.6854, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10800890624523163
Epoch 0, Step 337: train/loss = 0.5109215974807739, train/raw-loss = 0.5015151500701904, train/logprobs = tensor([[-0.6094, -1.5957],
        [-0.6172, -0.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940655767917633
Epoch 0, Step 338: train/loss = 0.6062273979187012, train/raw-loss = 0.5974969863891602, train/logprobs = tensor([[-0.4980, -1.3327],
        [-0.5516, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08730390667915344
Epoch 0, Step 339: train/loss = 0.6993433237075806, train/raw-loss = 0.6901722550392151, train/logprobs = tensor([[-0.6038, -0.6254],
        [-0.5055, -0.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09171035885810852
Epoch 0, Step 340: train/loss = 0.6699743866920471, train/raw-loss = 0.6589864492416382, train/logprobs = tensor([[-0.7650, -0.8712],
        [-0.5948, -0.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10987896472215652
Epoch 0, Step 341: train/loss = 0.6318017840385437, train/raw-loss = 0.6215066909790039, train/logprobs = tensor([[-0.8548, -0.9407],
        [-0.7887, -0.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295151174068451
Epoch 0, Step 342: train/loss = 0.6201397180557251, train/raw-loss = 0.6123150587081909, train/logprobs = tensor([[-0.5063, -1.0576],
        [-0.5342, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824662327766418
Epoch 0, Step 343: train/loss = 0.5881711840629578, train/raw-loss = 0.5786404609680176, train/logprobs = tensor([[-0.7507, -1.0846],
        [-0.6929, -0.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530721604824066
Epoch 0, Step 344: train/loss = 0.6075922846794128, train/raw-loss = 0.5967329144477844, train/logprobs = tensor([[-0.6347, -1.2421],
        [-0.6570, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10859361290931702
Epoch 0, Step 345: train/loss = 0.7147222757339478, train/raw-loss = 0.7035253047943115, train/logprobs = tensor([[-0.5917, -0.7127],
        [-0.5098, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11196910589933395
Epoch 0, Step 346: train/loss = 0.40382179617881775, train/raw-loss = 0.39305925369262695, train/logprobs = tensor([[-0.7318, -2.9379],
        [-0.8175, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10762552917003632
Epoch 0, Step 347: train/loss = 0.5347722768783569, train/raw-loss = 0.5251852869987488, train/logprobs = tensor([[-0.6854, -2.3235],
        [-0.6720, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09586936235427856
Epoch 0, Step 348: train/loss = 0.5756382942199707, train/raw-loss = 0.5643248558044434, train/logprobs = tensor([[-0.8228, -2.2979],
        [-0.8025, -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1131351888179779
Epoch 0, Step 349: train/loss = 0.6434090733528137, train/raw-loss = 0.6313486099243164, train/logprobs = tensor([[-0.8682, -0.9956],
        [-0.9991, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12060458213090897
Epoch 0, Step 350: train/loss = 0.670599102973938, train/raw-loss = 0.6599281430244446, train/logprobs = tensor([[-0.4835, -0.8925],
        [-0.4889, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670914500951767
Epoch 0, Step 351: train/loss = 0.5612643957138062, train/raw-loss = 0.5522000789642334, train/logprobs = tensor([[-0.7516, -1.4186],
        [-0.7334, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09064343571662903
Epoch 0, Step 352: train/loss = 0.6822065114974976, train/raw-loss = 0.6704132556915283, train/logprobs = tensor([[-1.0912, -1.5194],
        [-0.8104, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793246120214462
Epoch 0, Step 353: train/loss = 0.5013118982315063, train/raw-loss = 0.4914425015449524, train/logprobs = tensor([[-0.5131, -2.1544],
        [-0.5855, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09869429469108582
Epoch 0, Step 354: train/loss = 0.5715219974517822, train/raw-loss = 0.558620810508728, train/logprobs = tensor([[-0.7334, -2.3089],
        [-0.7258, -1.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12901195883750916
Epoch 0, Step 355: train/loss = 0.6175113916397095, train/raw-loss = 0.6049992442131042, train/logprobs = tensor([[-0.6299, -1.3699],
        [-0.5767, -0.6532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12512138485908508
Epoch 0, Step 356: train/loss = 0.6311585307121277, train/raw-loss = 0.6202926635742188, train/logprobs = tensor([[-0.5639, -0.9328],
        [-0.5680, -0.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10865886509418488
Epoch 0, Step 357: train/loss = 0.5055874586105347, train/raw-loss = 0.49201497435569763, train/logprobs = tensor([[-0.9465, -2.8872],
        [-0.9361, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13572487235069275
Epoch 0, Step 358: train/loss = 0.6167907118797302, train/raw-loss = 0.6056903600692749, train/logprobs = tensor([[-0.5104, -1.0972],
        [-0.5236, -0.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11100390553474426
Epoch 0, Step 359: train/loss = 0.6108757257461548, train/raw-loss = 0.5996995568275452, train/logprobs = tensor([[-0.5029, -0.7918],
        [-0.6079, -0.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176140606403351
Epoch 0, Step 360: train/loss = 0.5504907965660095, train/raw-loss = 0.539655327796936, train/logprobs = tensor([[-0.7030, -1.7499],
        [-0.6424, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10835511237382889
Epoch 0, Step 361: train/loss = 0.6142463088035583, train/raw-loss = 0.6035612225532532, train/logprobs = tensor([[-0.6537, -0.9566],
        [-0.6834, -0.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10685086250305176
Epoch 0, Step 362: train/loss = 0.5890730023384094, train/raw-loss = 0.5764867067337036, train/logprobs = tensor([[-0.6150, -1.6206],
        [-0.5930, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12586291134357452
Epoch 0, Step 363: train/loss = 0.48663556575775146, train/raw-loss = 0.4743024408817291, train/logprobs = tensor([[-0.6823, -3.5535],
        [-0.6512, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12333142757415771
Epoch 0, Step 364: train/loss = 0.6286896467208862, train/raw-loss = 0.6147946119308472, train/logprobs = tensor([[-0.7331, -1.3088],
        [-0.6284, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13895079493522644
Epoch 0, Step 365: train/loss = 0.6669526100158691, train/raw-loss = 0.6545025110244751, train/logprobs = tensor([[-0.5894, -0.8272],
        [-0.5980, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450121343135834
Epoch 0, Step 366: train/loss = 0.6851226687431335, train/raw-loss = 0.6741736531257629, train/logprobs = tensor([[-0.5330, -1.0654],
        [-0.5119, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094902828335762
Epoch 0, Step 367: train/loss = 0.6211687326431274, train/raw-loss = 0.6110397577285767, train/logprobs = tensor([[-0.5328, -1.0001],
        [-0.5573, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1012900322675705
Epoch 0, Step 368: train/loss = 0.6302887797355652, train/raw-loss = 0.6192679405212402, train/logprobs = tensor([[-0.5800, -0.8725],
        [-0.5727, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102081909775734
Epoch 0, Step 369: train/loss = 0.5204043388366699, train/raw-loss = 0.5082753896713257, train/logprobs = tensor([[-0.7817, -1.8371],
        [-0.8127, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128995358943939
Epoch 0, Step 370: train/loss = 0.579899251461029, train/raw-loss = 0.5699169039726257, train/logprobs = tensor([[-0.7311, -0.9723],
        [-0.8486, -0.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09982383996248245
Epoch 0, Step 371: train/loss = 0.6006121635437012, train/raw-loss = 0.5896083116531372, train/logprobs = tensor([[-0.9826, -1.8437],
        [-0.7494, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003856360912323
Epoch 0, Step 372: train/loss = 0.6298700571060181, train/raw-loss = 0.6186379790306091, train/logprobs = tensor([[-0.6327, -2.3563],
        [-0.6097, -2.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232060939073563
Epoch 0, Step 373: train/loss = 0.5941249132156372, train/raw-loss = 0.5850399136543274, train/logprobs = tensor([[-0.5056, -1.0988],
        [-0.4381, -0.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09085032343864441
Epoch 0, Step 374: train/loss = 0.57444828748703, train/raw-loss = 0.5654723048210144, train/logprobs = tensor([[-0.5177, -0.9289],
        [-0.6082, -0.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08976029604673386
Epoch 0, Step 375: train/loss = 0.6701632738113403, train/raw-loss = 0.6581588983535767, train/logprobs = tensor([[-0.7257, -0.8187],
        [-0.7220, -0.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004455924034119
Epoch 0, Step 376: train/loss = 0.5742368102073669, train/raw-loss = 0.5600370168685913, train/logprobs = tensor([[-1.0117, -2.2100],
        [-0.9565, -1.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419975757598877
Epoch 0, Step 377: train/loss = 0.5876843333244324, train/raw-loss = 0.5779144763946533, train/logprobs = tensor([[-0.6198, -1.1844],
        [-0.6374, -0.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09769858419895172
Epoch 0, Step 378: train/loss = 0.553545355796814, train/raw-loss = 0.5445179343223572, train/logprobs = tensor([[-0.6875, -2.0169],
        [-0.6363, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0902736708521843
Epoch 0, Step 379: train/loss = 0.7071457505226135, train/raw-loss = 0.6952776908874512, train/logprobs = tensor([[-0.6976, -0.7234],
        [-0.5805, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11868059635162354
Epoch 0, Step 380: train/loss = 0.5756755471229553, train/raw-loss = 0.5655480027198792, train/logprobs = tensor([[-0.5579, -1.1491],
        [-0.5916, -0.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10127514600753784
Epoch 0, Step 381: train/loss = 0.7027779817581177, train/raw-loss = 0.6897826790809631, train/logprobs = tensor([[-0.8863, -1.2036],
        [-0.7471, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12995263934135437
Epoch 0, Step 382: train/loss = 0.6620562076568604, train/raw-loss = 0.6509064435958862, train/logprobs = tensor([[-0.9188, -1.0904],
        [-0.8769, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149761080741882
Epoch 0, Step 383: train/loss = 0.5893620848655701, train/raw-loss = 0.574520468711853, train/logprobs = tensor([[-1.0421, -1.5155],
        [-1.0136, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14841577410697937
Epoch 0, Step 384: train/loss = 0.6640232801437378, train/raw-loss = 0.6506904363632202, train/logprobs = tensor([[-0.6057, -0.7791],
        [-0.5105, -0.4894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333286464214325
Epoch 0, Step 385: train/loss = 0.5261397957801819, train/raw-loss = 0.5108950138092041, train/logprobs = tensor([[-0.7690, -1.8833],
        [-0.8336, -0.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1524476706981659
Epoch 0, Step 386: train/loss = 0.5758429765701294, train/raw-loss = 0.5611975789070129, train/logprobs = tensor([[-0.9467, -2.2455],
        [-0.9532, -1.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1464535892009735
Epoch 0, Step 387: train/loss = 0.7106173038482666, train/raw-loss = 0.6957384347915649, train/logprobs = tensor([[-1.1389, -1.6307],
        [-0.7857, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14878825843334198
Epoch 0, Step 388: train/loss = 0.6115841269493103, train/raw-loss = 0.5994990468025208, train/logprobs = tensor([[-0.7421, -1.4664],
        [-0.6938, -0.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085101753473282
Epoch 0, Step 389: train/loss = 0.6652557849884033, train/raw-loss = 0.6538363099098206, train/logprobs = tensor([[-0.5930, -0.8072],
        [-0.5625, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11419461667537689
Epoch 0, Step 390: train/loss = 0.6897611618041992, train/raw-loss = 0.6759437322616577, train/logprobs = tensor([[-0.6857, -0.8056],
        [-0.6501, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13817471265792847
Epoch 0, Step 391: train/loss = 0.6009577512741089, train/raw-loss = 0.5880974531173706, train/logprobs = tensor([[-1.5279, -2.7851],
        [-1.0114, -0.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286028027534485
Epoch 0, Step 392: train/loss = 0.5318354368209839, train/raw-loss = 0.5187260508537292, train/logprobs = tensor([[-0.6519, -1.8937],
        [-0.6503, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13109378516674042
Epoch 0, Step 393: train/loss = 0.6889575719833374, train/raw-loss = 0.6745584011077881, train/logprobs = tensor([[-0.9019, -0.9415],
        [-0.9403, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14399144053459167
Epoch 0, Step 394: train/loss = 0.5378125905990601, train/raw-loss = 0.5239965915679932, train/logprobs = tensor([[-0.6879, -2.5058],
        [-0.7414, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13816045224666595
Epoch 0, Step 395: train/loss = 0.5848977565765381, train/raw-loss = 0.5729713439941406, train/logprobs = tensor([[-0.7364, -1.8565],
        [-0.6289, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11926372349262238
Epoch 0, Step 396: train/loss = 0.699118435382843, train/raw-loss = 0.6852158904075623, train/logprobs = tensor([[-0.6140, -0.7314],
        [-0.6171, -0.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390250325202942
Epoch 0, Step 397: train/loss = 0.6143540740013123, train/raw-loss = 0.6004947423934937, train/logprobs = tensor([[-0.7179, -1.7312],
        [-0.6724, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385933756828308
Epoch 0, Step 398: train/loss = 0.6069818735122681, train/raw-loss = 0.5928803086280823, train/logprobs = tensor([[-1.4860, -2.1234],
        [-1.0944, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14101555943489075
Epoch 0, Step 399: train/loss = 0.5862090587615967, train/raw-loss = 0.573823869228363, train/logprobs = tensor([[-0.5253, -1.4896],
        [-0.5939, -0.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1238524317741394
Epoch 0, Step 400: train/loss = 0.512355387210846, train/raw-loss = 0.499442994594574, train/logprobs = tensor([[-0.6883, -1.6972],
        [-0.8465, -0.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12912428379058838
Epoch 0, Step 401: train/loss = 0.6184004545211792, train/raw-loss = 0.6051982641220093, train/logprobs = tensor([[-0.6767, -1.7392],
        [-0.5728, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13202184438705444
Epoch 0, Step 402: train/loss = 0.5509384274482727, train/raw-loss = 0.5360360145568848, train/logprobs = tensor([[-0.6988, -1.4183],
        [-0.7715, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14902345836162567
Epoch 0, Step 403: train/loss = 0.6579015851020813, train/raw-loss = 0.6467306613922119, train/logprobs = tensor([[-0.5252, -0.7263],
        [-0.5441, -0.5472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11170952767133713
Epoch 0, Step 404: train/loss = 0.4820173978805542, train/raw-loss = 0.467798113822937, train/logprobs = tensor([[-0.9038, -1.9352],
        [-1.0336, -0.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14219290018081665
Epoch 0, Step 405: train/loss = 0.5988764762878418, train/raw-loss = 0.5866397619247437, train/logprobs = tensor([[-0.5950, -1.3376],
        [-0.6067, -0.6425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12236719578504562
Epoch 0, Step 406: train/loss = 0.5479007363319397, train/raw-loss = 0.5326634049415588, train/logprobs = tensor([[-0.7841, -1.7185],
        [-0.8412, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1523733139038086
Epoch 0, Step 407: train/loss = 0.6776466369628906, train/raw-loss = 0.6629442572593689, train/logprobs = tensor([[-0.6796, -1.4121],
        [-0.6384, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14702372252941132
Epoch 0, Step 408: train/loss = 0.5928307771682739, train/raw-loss = 0.5809118747711182, train/logprobs = tensor([[-0.6939, -1.3990],
        [-0.7416, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191888302564621
Epoch 0, Step 409: train/loss = 0.5280216932296753, train/raw-loss = 0.5150994062423706, train/logprobs = tensor([[-0.6825, -2.6158],
        [-0.7236, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12922266125679016
Epoch 0, Step 410: train/loss = 0.5990201830863953, train/raw-loss = 0.5855448842048645, train/logprobs = tensor([[-0.7473, -1.8149],
        [-0.5923, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13475307822227478
Epoch 0, Step 411: train/loss = 0.5692941546440125, train/raw-loss = 0.5575862526893616, train/logprobs = tensor([[-0.5118, -1.4821],
        [-0.4874, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707936227321625
Epoch 0, Step 412: train/loss = 0.57724928855896, train/raw-loss = 0.5626420378684998, train/logprobs = tensor([[-0.8976, -1.7368],
        [-0.7553, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14607210457324982
Epoch 0, Step 413: train/loss = 0.5527591705322266, train/raw-loss = 0.5397620797157288, train/logprobs = tensor([[-0.6448, -1.9062],
        [-0.6443, -1.1485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299711912870407
Epoch 0, Step 414: train/loss = 0.570575475692749, train/raw-loss = 0.557222843170166, train/logprobs = tensor([[-0.8197, -1.4742],
        [-0.7439, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335262805223465
Epoch 0, Step 415: train/loss = 0.6010997295379639, train/raw-loss = 0.5838083028793335, train/logprobs = tensor([[-1.1542, -2.4034],
        [-0.9666, -1.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17291410267353058
Epoch 0, Step 416: train/loss = 0.5136051177978516, train/raw-loss = 0.498780757188797, train/logprobs = tensor([[-0.6659, -1.8413],
        [-0.6639, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1482439935207367
Epoch 0, Step 417: train/loss = 0.6475858688354492, train/raw-loss = 0.6364460587501526, train/logprobs = tensor([[-0.4362, -1.1417],
        [-0.4553, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11139815300703049
Epoch 0, Step 418: train/loss = 0.6100428700447083, train/raw-loss = 0.5983160138130188, train/logprobs = tensor([[-0.6038, -1.5870],
        [-0.5017, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11726872622966766
Epoch 0, Step 419: train/loss = 0.5757108926773071, train/raw-loss = 0.5635141730308533, train/logprobs = tensor([[-0.5780, -1.4215],
        [-0.6033, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12196700274944305
Epoch 0, Step 420: train/loss = 0.7080572843551636, train/raw-loss = 0.6962326765060425, train/logprobs = tensor([[-0.7782, -0.7891],
        [-0.4783, -0.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1182466447353363
Epoch 0, Step 421: train/loss = 0.6078567504882812, train/raw-loss = 0.5923997163772583, train/logprobs = tensor([[-0.8252, -1.8010],
        [-0.6952, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15457013249397278
Epoch 0, Step 422: train/loss = 0.64082932472229, train/raw-loss = 0.6303840279579163, train/logprobs = tensor([[-0.6518, -1.0762],
        [-0.5896, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044532060623169
Epoch 0, Step 423: train/loss = 0.6755629181861877, train/raw-loss = 0.6587796211242676, train/logprobs = tensor([[-0.9674, -1.8760],
        [-0.8722, -1.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16783319413661957
Epoch 0, Step 424: train/loss = 0.6229807734489441, train/raw-loss = 0.609506368637085, train/logprobs = tensor([[-0.6646, -1.3969],
        [-0.5990, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13474391400814056
Epoch 0, Step 425: train/loss = 0.5987820625305176, train/raw-loss = 0.585817277431488, train/logprobs = tensor([[-0.5327, -2.0563],
        [-0.5462, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12964734435081482
Epoch 0, Step 426: train/loss = 0.5252140164375305, train/raw-loss = 0.5117079019546509, train/logprobs = tensor([[-0.6982, -2.0040],
        [-0.7482, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13506129384040833
Epoch 0, Step 427: train/loss = 0.41492342948913574, train/raw-loss = 0.40114104747772217, train/logprobs = tensor([[-0.7968, -4.1127],
        [-0.9614, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378239393234253
Epoch 0, Step 428: train/loss = 0.36968663334846497, train/raw-loss = 0.35326290130615234, train/logprobs = tensor([[-1.3937, -5.5284],
        [-1.2199, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1642378270626068
Epoch 0, Step 429: train/loss = 0.48234203457832336, train/raw-loss = 0.4677790403366089, train/logprobs = tensor([[-0.9689, -2.9311],
        [-1.0577, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456296443939209
Epoch 0, Step 430: train/loss = 0.6545977592468262, train/raw-loss = 0.6411271095275879, train/logprobs = tensor([[-0.7332, -1.2929],
        [-0.6213, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347065418958664
Epoch 0, Step 431: train/loss = 0.545850396156311, train/raw-loss = 0.5321890115737915, train/logprobs = tensor([[-0.6992, -1.4705],
        [-0.6493, -0.4758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13661420345306396
Epoch 0, Step 432: train/loss = 0.5670945644378662, train/raw-loss = 0.55409836769104, train/logprobs = tensor([[-0.7418, -1.4941],
        [-0.6891, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1299615204334259
Epoch 0, Step 433: train/loss = 0.5120564699172974, train/raw-loss = 0.49623286724090576, train/logprobs = tensor([[-0.9592, -2.5850],
        [-0.9729, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582363098859787
Epoch 0, Step 434: train/loss = 0.5824977159500122, train/raw-loss = 0.5661736726760864, train/logprobs = tensor([[-0.9249, -1.9800],
        [-0.6001, -0.9465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16324028372764587
Epoch 0, Step 435: train/loss = 0.5077225565910339, train/raw-loss = 0.4922769367694855, train/logprobs = tensor([[-1.0166, -2.2332],
        [-0.8153, -0.6023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15445633232593536
Epoch 0, Step 436: train/loss = 0.7028688192367554, train/raw-loss = 0.6888236999511719, train/logprobs = tensor([[-1.1402, -1.2129],
        [-0.9996, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1404520869255066
Epoch 0, Step 437: train/loss = 0.5186334252357483, train/raw-loss = 0.5050053000450134, train/logprobs = tensor([[-0.6681, -1.8055],
        [-0.7212, -0.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13628092408180237
Epoch 0, Step 438: train/loss = 0.6505815386772156, train/raw-loss = 0.6337100267410278, train/logprobs = tensor([[-1.4622, -1.6253],
        [-1.3218, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1687159240245819
Epoch 0, Step 439: train/loss = 0.5838598012924194, train/raw-loss = 0.5686590671539307, train/logprobs = tensor([[-0.7665, -1.1421],
        [-0.8904, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15200749039649963
Epoch 0, Step 440: train/loss = 0.5252119302749634, train/raw-loss = 0.5114650726318359, train/logprobs = tensor([[-0.6857, -2.0086],
        [-0.6277, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13746854662895203
Epoch 0, Step 441: train/loss = 0.6359057426452637, train/raw-loss = 0.6225239038467407, train/logprobs = tensor([[-0.8455, -1.1987],
        [-0.7784, -0.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338181048631668
Epoch 0, Step 442: train/loss = 0.5319317579269409, train/raw-loss = 0.5174858570098877, train/logprobs = tensor([[-0.7813, -2.5286],
        [-0.7528, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14445924758911133
Epoch 0, Step 443: train/loss = 0.5357944965362549, train/raw-loss = 0.5218600034713745, train/logprobs = tensor([[-0.8908, -2.9020],
        [-0.6827, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13934457302093506
Epoch 0, Step 444: train/loss = 0.6347073316574097, train/raw-loss = 0.6232291460037231, train/logprobs = tensor([[-0.5400, -1.4068],
        [-0.4399, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478208005428314
Epoch 0, Step 445: train/loss = 0.43052610754966736, train/raw-loss = 0.4179977774620056, train/logprobs = tensor([[-0.6165, -3.2057],
        [-0.6648, -1.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125283345580101
Epoch 0, Step 446: train/loss = 0.5824929475784302, train/raw-loss = 0.5670067071914673, train/logprobs = tensor([[-0.9425, -1.6828],
        [-0.7309, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15486285090446472
Epoch 0, Step 447: train/loss = 0.3692490756511688, train/raw-loss = 0.3550611734390259, train/logprobs = tensor([[-0.8043, -3.0222],
        [-0.8630, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418791115283966
Epoch 0, Step 448: train/loss = 0.658606767654419, train/raw-loss = 0.6434239745140076, train/logprobs = tensor([[-0.8767, -1.1083],
        [-0.7065, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15182726085186005
Epoch 0, Step 449: train/loss = 0.5810556411743164, train/raw-loss = 0.5679852962493896, train/logprobs = tensor([[-0.7922, -1.8368],
        [-0.6454, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13070335984230042
Epoch 0, Step 450: train/loss = 0.6016138792037964, train/raw-loss = 0.5882648229598999, train/logprobs = tensor([[-0.7045, -1.4378],
        [-0.5807, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13349014520645142
Epoch 0, Step 451: train/loss = 0.5826625227928162, train/raw-loss = 0.5698465704917908, train/logprobs = tensor([[-0.7209, -1.9503],
        [-0.6684, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.128159299492836
Epoch 0, Step 452: train/loss = 0.5254315137863159, train/raw-loss = 0.510188639163971, train/logprobs = tensor([[-1.3039, -2.6718],
        [-1.1195, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15242953598499298
Epoch 0, Step 453: train/loss = 0.6564517021179199, train/raw-loss = 0.6399363279342651, train/logprobs = tensor([[-0.9293, -1.1926],
        [-0.8477, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16515325009822845
Epoch 0, Step 454: train/loss = 0.5347115397453308, train/raw-loss = 0.5202798843383789, train/logprobs = tensor([[-0.7252, -2.1382],
        [-0.6679, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14431646466255188
Epoch 0, Step 455: train/loss = 0.601454496383667, train/raw-loss = 0.5857969522476196, train/logprobs = tensor([[-1.1184, -2.2697],
        [-0.9932, -1.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1565750539302826
Epoch 0, Step 456: train/loss = 0.5429934859275818, train/raw-loss = 0.5254145860671997, train/logprobs = tensor([[-1.0368, -2.3360],
        [-0.7091, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17578938603401184
Epoch 0, Step 457: train/loss = 0.529318630695343, train/raw-loss = 0.511670708656311, train/logprobs = tensor([[-0.9789, -1.9181],
        [-1.0113, -0.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17647939920425415
Epoch 0, Step 458: train/loss = 0.4410003423690796, train/raw-loss = 0.4260650873184204, train/logprobs = tensor([[-0.8658, -3.4209],
        [-0.8144, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14935266971588135
Epoch 0, Step 459: train/loss = 0.5175910592079163, train/raw-loss = 0.5026692152023315, train/logprobs = tensor([[-0.7925, -2.8988],
        [-0.7676, -0.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14921854436397552
Epoch 0, Step 460: train/loss = 0.603558361530304, train/raw-loss = 0.5883487462997437, train/logprobs = tensor([[-0.8254, -2.2015],
        [-0.7494, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1520957201719284
Epoch 0, Step 461: train/loss = 0.5548333525657654, train/raw-loss = 0.5410082340240479, train/logprobs = tensor([[-0.6984, -2.9390],
        [-0.6638, -1.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13825103640556335
Epoch 0, Step 462: train/loss = 0.5535510778427124, train/raw-loss = 0.5391843914985657, train/logprobs = tensor([[-1.0100, -3.2821],
        [-0.8806, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14366638660430908
Epoch 0, Step 463: train/loss = 0.6114790439605713, train/raw-loss = 0.5958002805709839, train/logprobs = tensor([[-0.7445, -1.2658],
        [-0.7381, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567879468202591
Epoch 0, Step 464: train/loss = 0.6394334435462952, train/raw-loss = 0.6253132820129395, train/logprobs = tensor([[-0.5805, -0.9705],
        [-0.5671, -0.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120185375213623
Epoch 0, Step 465: train/loss = 0.3786736726760864, train/raw-loss = 0.3645876944065094, train/logprobs = tensor([[-0.9052, -4.2035],
        [-1.0033, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14085973799228668
Epoch 0, Step 466: train/loss = 0.619662344455719, train/raw-loss = 0.6062479019165039, train/logprobs = tensor([[-0.7333, -1.0321],
        [-0.7198, -0.6165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414481282234192
Epoch 0, Step 467: train/loss = 0.4966684579849243, train/raw-loss = 0.4828927516937256, train/logprobs = tensor([[-0.7878, -1.8256],
        [-0.8211, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377570927143097
Epoch 0, Step 468: train/loss = 0.5271087288856506, train/raw-loss = 0.5103057622909546, train/logprobs = tensor([[-0.7598, -3.1248],
        [-0.7597, -2.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16802978515625
Epoch 0, Step 469: train/loss = 0.6540446281433105, train/raw-loss = 0.6412296295166016, train/logprobs = tensor([[-0.6351, -0.8440],
        [-0.6756, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12815050780773163
Epoch 0, Step 470: train/loss = 0.6800616979598999, train/raw-loss = 0.6681238412857056, train/logprobs = tensor([[-0.7643, -0.6146],
        [-0.7351, -0.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11937824636697769
Epoch 0, Step 471: train/loss = 0.5692859292030334, train/raw-loss = 0.5542534589767456, train/logprobs = tensor([[-0.7883, -2.0755],
        [-0.6959, -1.2617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15032514929771423
Epoch 0, Step 472: train/loss = 0.717830240726471, train/raw-loss = 0.7041188478469849, train/logprobs = tensor([[-1.0288, -0.8259],
        [-0.8643, -0.6923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13711492717266083
Epoch 0, Step 473: train/loss = 0.6175572276115417, train/raw-loss = 0.6035720705986023, train/logprobs = tensor([[-0.7944, -1.4543],
        [-0.7277, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13985197246074677
Epoch 0, Step 474: train/loss = 0.5218040943145752, train/raw-loss = 0.5059553384780884, train/logprobs = tensor([[-0.7397, -1.6458],
        [-0.8254, -0.5600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15848788619041443
Epoch 0, Step 475: train/loss = 0.6555339097976685, train/raw-loss = 0.6424387693405151, train/logprobs = tensor([[-0.5101, -1.0437],
        [-0.4985, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13095176219940186
Epoch 0, Step 476: train/loss = 0.5725300312042236, train/raw-loss = 0.558562159538269, train/logprobs = tensor([[-0.6006, -1.2247],
        [-0.7282, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13967888057231903
Epoch 0, Step 477: train/loss = 0.4887462854385376, train/raw-loss = 0.47465798258781433, train/logprobs = tensor([[-0.8047, -2.9668],
        [-0.8761, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14088325202465057
Epoch 0, Step 478: train/loss = 0.6036466956138611, train/raw-loss = 0.5906401872634888, train/logprobs = tensor([[-0.8013, -1.9773],
        [-0.7605, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300651878118515
Epoch 0, Step 479: train/loss = 0.572688102722168, train/raw-loss = 0.5606046915054321, train/logprobs = tensor([[-0.7225, -1.8333],
        [-0.7394, -0.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12083431333303452
Epoch 0, Step 480: train/loss = 0.5425699949264526, train/raw-loss = 0.5282105803489685, train/logprobs = tensor([[-0.7593, -1.8415],
        [-0.6747, -0.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14359408617019653
Epoch 0, Step 481: train/loss = 0.56296706199646, train/raw-loss = 0.5510633587837219, train/logprobs = tensor([[-0.8118, -2.0209],
        [-0.7706, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11903724074363708
Epoch 0, Step 482: train/loss = 0.5340957641601562, train/raw-loss = 0.5178467631340027, train/logprobs = tensor([[-1.0405, -2.0423],
        [-0.9943, -0.7010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16249006986618042
Epoch 0, Step 483: train/loss = 0.5489124655723572, train/raw-loss = 0.5346274971961975, train/logprobs = tensor([[-0.7597, -1.9720],
        [-0.7817, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14284971356391907
Epoch 0, Step 484: train/loss = 0.7336470484733582, train/raw-loss = 0.7197932004928589, train/logprobs = tensor([[-1.9110, -4.0690],
        [-0.6862, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13853858411312103
Epoch 0, Step 485: train/loss = 0.6460828185081482, train/raw-loss = 0.6343969702720642, train/logprobs = tensor([[-0.6721, -1.1350],
        [-0.6847, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685828864574432
Epoch 0, Step 486: train/loss = 0.3835066556930542, train/raw-loss = 0.3677792549133301, train/logprobs = tensor([[-0.9167, -5.5699],
        [-0.9501, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572742909193039
Epoch 0, Step 487: train/loss = 0.5130017995834351, train/raw-loss = 0.49814003705978394, train/logprobs = tensor([[-1.0843, -3.4279],
        [-0.8683, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14861808717250824
Epoch 0, Step 488: train/loss = 0.6446818113327026, train/raw-loss = 0.6326507329940796, train/logprobs = tensor([[-0.5358, -0.9671],
        [-0.4400, -0.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.120310477912426
Epoch 0, Step 489: train/loss = 0.714022159576416, train/raw-loss = 0.6983678936958313, train/logprobs = tensor([[-1.2612, -2.5544],
        [-0.9099, -2.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15654271841049194
Epoch 0, Step 490: train/loss = 0.5954159498214722, train/raw-loss = 0.5800801515579224, train/logprobs = tensor([[-0.5750, -1.3426],
        [-0.5451, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15335789322853088
Epoch 0, Step 491: train/loss = 0.5036918520927429, train/raw-loss = 0.4862942099571228, train/logprobs = tensor([[-1.1463, -2.8808],
        [-1.0331, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17397664487361908
Epoch 0, Step 492: train/loss = 0.5698351860046387, train/raw-loss = 0.5563277006149292, train/logprobs = tensor([[-0.6559, -1.9309],
        [-0.6472, -0.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350749284029007
Epoch 0, Step 493: train/loss = 0.5155172944068909, train/raw-loss = 0.49961233139038086, train/logprobs = tensor([[-0.8577, -1.9922],
        [-0.8728, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15904954075813293
Epoch 0, Step 494: train/loss = 0.5985226631164551, train/raw-loss = 0.5827187299728394, train/logprobs = tensor([[-1.0525, -2.5023],
        [-0.8302, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803903341293335
Epoch 0, Step 495: train/loss = 0.6273179054260254, train/raw-loss = 0.609600305557251, train/logprobs = tensor([[-0.9748, -1.6971],
        [-0.7893, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771763265132904
Epoch 0, Step 496: train/loss = 0.5988361835479736, train/raw-loss = 0.5855643153190613, train/logprobs = tensor([[-0.6893, -1.5690],
        [-0.6684, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327187567949295
Epoch 0, Step 497: train/loss = 0.653179943561554, train/raw-loss = 0.6401314735412598, train/logprobs = tensor([[-0.8281, -1.2006],
        [-0.7217, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13048499822616577
Epoch 0, Step 498: train/loss = 0.6109646558761597, train/raw-loss = 0.5936325192451477, train/logprobs = tensor([[-1.1917, -1.4482],
        [-0.9684, -0.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17332108318805695
Epoch 0, Step 499: train/loss = 0.5340790152549744, train/raw-loss = 0.519194483757019, train/logprobs = tensor([[-0.8749, -2.9198],
        [-0.7693, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14884547889232635
Epoch 0, Step 500: train/loss = 0.4665793776512146, train/raw-loss = 0.45542818307876587, train/logprobs = tensor([[-0.5692, -3.9359],
        [-0.5982, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11151158809661865
Epoch 0, Step 501: train/loss = 0.6397891044616699, train/raw-loss = 0.6251408457756042, train/logprobs = tensor([[-0.8001, -1.5036],
        [-0.8323, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14648273587226868
Epoch 0, Step 502: train/loss = 0.40892931818962097, train/raw-loss = 0.39567676186561584, train/logprobs = tensor([[-0.7460, -4.6579],
        [-0.9977, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13252554833889008
Epoch 0, Step 503: train/loss = 0.47760456800460815, train/raw-loss = 0.4622771739959717, train/logprobs = tensor([[-0.7389, -2.6863],
        [-0.8168, -0.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1532742977142334
Epoch 0, Step 504: train/loss = 0.6345884799957275, train/raw-loss = 0.6216152906417847, train/logprobs = tensor([[-1.0747, -1.3755],
        [-1.0496, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12973225116729736
Epoch 0, Step 505: train/loss = 0.5165606141090393, train/raw-loss = 0.5029340386390686, train/logprobs = tensor([[-0.7439, -2.7922],
        [-0.8080, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362658143043518
Epoch 0, Step 506: train/loss = 0.42728355526924133, train/raw-loss = 0.41223058104515076, train/logprobs = tensor([[-0.6705, -2.1021],
        [-0.8846, -0.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15052995085716248
Epoch 0, Step 507: train/loss = 0.5381032824516296, train/raw-loss = 0.5249256491661072, train/logprobs = tensor([[-0.7091, -1.9566],
        [-0.5995, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13177642226219177
Epoch 0, Step 508: train/loss = 0.38542550802230835, train/raw-loss = 0.37097030878067017, train/logprobs = tensor([[-0.8225, -4.5363],
        [-0.9229, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14455187320709229
Epoch 0, Step 509: train/loss = 0.6198456883430481, train/raw-loss = 0.6046695709228516, train/logprobs = tensor([[-1.4660, -2.2780],
        [-1.2045, -1.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15176089107990265
Epoch 0, Step 510: train/loss = 0.7089246511459351, train/raw-loss = 0.6928277015686035, train/logprobs = tensor([[-0.8476, -0.8821],
        [-0.7751, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16096962988376617
Epoch 0, Step 511: train/loss = 0.6612274050712585, train/raw-loss = 0.6459420919418335, train/logprobs = tensor([[-1.5131, -2.0307],
        [-0.9905, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528526246547699
Epoch 0, Step 512: train/loss = 0.611189067363739, train/raw-loss = 0.5956350564956665, train/logprobs = tensor([[-0.9227, -1.4417],
        [-0.8866, -0.9016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15553995966911316
Epoch 0, Step 513: train/loss = 0.44780007004737854, train/raw-loss = 0.43162816762924194, train/logprobs = tensor([[-1.1939, -3.2736],
        [-0.9448, -0.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16171906888484955
Epoch 0, Step 514: train/loss = 0.5838280320167542, train/raw-loss = 0.5683630108833313, train/logprobs = tensor([[-1.0594, -2.8848],
        [-0.7664, -1.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15464997291564941
Epoch 0, Step 515: train/loss = 0.6566877365112305, train/raw-loss = 0.6445289850234985, train/logprobs = tensor([[-0.4921, -1.2698],
        [-0.4544, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158738821744919
Epoch 0, Step 516: train/loss = 0.47034698724746704, train/raw-loss = 0.45511287450790405, train/logprobs = tensor([[-1.0303, -2.4298],
        [-1.0176, -0.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15234151482582092
Epoch 0, Step 517: train/loss = 0.6202085614204407, train/raw-loss = 0.6058194637298584, train/logprobs = tensor([[-0.7270, -1.3155],
        [-0.6562, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14389054477214813
Epoch 0, Step 518: train/loss = 0.5839959383010864, train/raw-loss = 0.5692832469940186, train/logprobs = tensor([[-1.0126, -2.4995],
        [-0.8465, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14712683856487274
Epoch 0, Step 519: train/loss = 0.4988175630569458, train/raw-loss = 0.4810085594654083, train/logprobs = tensor([[-0.9920, -1.7632],
        [-1.0802, -0.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17808982729911804
Epoch 0, Step 520: train/loss = 0.604571521282196, train/raw-loss = 0.5877719521522522, train/logprobs = tensor([[-0.9043, -1.5246],
        [-0.7762, -0.8797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16799601912498474
Epoch 0, Step 521: train/loss = 0.5754709243774414, train/raw-loss = 0.5603880286216736, train/logprobs = tensor([[-0.9574, -2.5385],
        [-0.8383, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15082916617393494
Epoch 0, Step 522: train/loss = 0.5942869186401367, train/raw-loss = 0.5774394273757935, train/logprobs = tensor([[-1.2194, -2.2616],
        [-0.9492, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16847538948059082
Epoch 0, Step 523: train/loss = 0.5880908966064453, train/raw-loss = 0.577532172203064, train/logprobs = tensor([[-0.4140, -1.4654],
        [-0.4127, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10558673739433289
Epoch 0, Step 524: train/loss = 0.5969471335411072, train/raw-loss = 0.5804499387741089, train/logprobs = tensor([[-0.8499, -1.5245],
        [-0.8445, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16497160494327545
Epoch 0, Step 525: train/loss = 0.6681163311004639, train/raw-loss = 0.6554490327835083, train/logprobs = tensor([[-0.6911, -1.0210],
        [-0.6339, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12667274475097656
Epoch 0, Step 526: train/loss = 0.3852558135986328, train/raw-loss = 0.36800438165664673, train/logprobs = tensor([[-0.8586, -3.0220],
        [-0.9395, -0.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17251421511173248
Epoch 0, Step 527: train/loss = 0.6430731415748596, train/raw-loss = 0.6273778676986694, train/logprobs = tensor([[-1.3842, -1.6950],
        [-1.1182, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1569528877735138
Epoch 0, Step 528: train/loss = 0.624272882938385, train/raw-loss = 0.6104668378829956, train/logprobs = tensor([[-0.7386, -0.9639],
        [-0.7383, -0.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13806040585041046
Epoch 0, Step 529: train/loss = 0.5135616064071655, train/raw-loss = 0.49539250135421753, train/logprobs = tensor([[-1.1204, -3.6349],
        [-1.0014, -2.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18169081211090088
Epoch 0, Step 530: train/loss = 0.5669888257980347, train/raw-loss = 0.5512602925300598, train/logprobs = tensor([[-0.5995, -1.6555],
        [-0.6854, -0.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572849601507187
Epoch 0, Step 531: train/loss = 0.625022828578949, train/raw-loss = 0.6116876602172852, train/logprobs = tensor([[-0.6274, -1.1687],
        [-0.5929, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133352130651474
Epoch 0, Step 532: train/loss = 0.6125880479812622, train/raw-loss = 0.5967261791229248, train/logprobs = tensor([[-1.2259, -1.5372],
        [-1.1574, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15861846506595612
Epoch 0, Step 533: train/loss = 0.4169501066207886, train/raw-loss = 0.3998869061470032, train/logprobs = tensor([[-0.8577, -4.2677],
        [-0.8600, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17063212394714355
Epoch 0, Step 534: train/loss = 0.4200519919395447, train/raw-loss = 0.4040733575820923, train/logprobs = tensor([[-0.7478, -3.4657],
        [-0.9079, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15978647768497467
Epoch 0, Step 535: train/loss = 0.6310814619064331, train/raw-loss = 0.6171812415122986, train/logprobs = tensor([[-0.7018, -0.7739],
        [-0.7889, -0.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13900288939476013
Epoch 0, Step 536: train/loss = 0.5012825727462769, train/raw-loss = 0.48787468671798706, train/logprobs = tensor([[-0.8551, -3.3737],
        [-0.6492, -0.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134078711271286
Epoch 0, Step 537: train/loss = 0.6537783145904541, train/raw-loss = 0.6393105387687683, train/logprobs = tensor([[-1.1259, -2.2505],
        [-0.5384, -0.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14467741549015045
Epoch 0, Step 538: train/loss = 0.5264842510223389, train/raw-loss = 0.5115452408790588, train/logprobs = tensor([[-0.7874, -1.9367],
        [-0.7432, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14939017593860626
Epoch 0, Step 539: train/loss = 0.6773775219917297, train/raw-loss = 0.6664829254150391, train/logprobs = tensor([[-0.5400, -0.5560],
        [-0.5236, -0.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10894574970006943
Epoch 0, Step 540: train/loss = 0.6790196895599365, train/raw-loss = 0.667163610458374, train/logprobs = tensor([[-0.5594, -0.8263],
        [-0.5020, -0.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11856083571910858
Epoch 0, Step 541: train/loss = 0.5430340766906738, train/raw-loss = 0.5290918350219727, train/logprobs = tensor([[-0.6398, -1.0382],
        [-0.8706, -0.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13942231237888336
Epoch 0, Step 542: train/loss = 0.610942006111145, train/raw-loss = 0.5938922166824341, train/logprobs = tensor([[-0.9701, -1.8526],
        [-0.7656, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704978346824646
Epoch 0, Step 543: train/loss = 0.6345426440238953, train/raw-loss = 0.6193972826004028, train/logprobs = tensor([[-1.0839, -1.8749],
        [-0.6061, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514541506767273
Epoch 0, Step 544: train/loss = 0.6670160889625549, train/raw-loss = 0.6538949012756348, train/logprobs = tensor([[-0.6799, -0.7861],
        [-0.6591, -0.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312122344970703
Epoch 0, Step 545: train/loss = 0.5245120525360107, train/raw-loss = 0.5084852576255798, train/logprobs = tensor([[-1.0270, -1.8059],
        [-1.0363, -0.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16026756167411804
Epoch 0, Step 546: train/loss = 0.538689136505127, train/raw-loss = 0.5250306129455566, train/logprobs = tensor([[-0.7868, -1.5736],
        [-0.8241, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13658493757247925
Epoch 0, Step 547: train/loss = 0.4888114929199219, train/raw-loss = 0.4743531346321106, train/logprobs = tensor([[-0.6754, -2.0147],
        [-0.7235, -0.6370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14458346366882324
Epoch 0, Step 548: train/loss = 0.5144563913345337, train/raw-loss = 0.4991834759712219, train/logprobs = tensor([[-1.0853, -4.6491],
        [-1.1547, -1.6555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15272854268550873
Epoch 0, Step 549: train/loss = 0.47007328271865845, train/raw-loss = 0.4562965929508209, train/logprobs = tensor([[-0.5219, -2.4231],
        [-0.6769, -0.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13776683807373047
Epoch 0, Step 550: train/loss = 0.3993054926395416, train/raw-loss = 0.3820631504058838, train/logprobs = tensor([[-0.7976, -2.5851],
        [-0.8974, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1724235862493515
Epoch 0, Step 551: train/loss = 0.5684093236923218, train/raw-loss = 0.551744818687439, train/logprobs = tensor([[-0.9066, -1.1407],
        [-1.0705, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666446328163147
Epoch 0, Step 552: train/loss = 0.6607316136360168, train/raw-loss = 0.6440730094909668, train/logprobs = tensor([[-1.3120, -1.6192],
        [-0.8510, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1665852814912796
Epoch 0, Step 553: train/loss = 0.6635428071022034, train/raw-loss = 0.6503989696502686, train/logprobs = tensor([[-0.9442, -1.3194],
        [-0.5833, -0.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314380168914795
Epoch 0, Step 554: train/loss = 0.5814608335494995, train/raw-loss = 0.565663754940033, train/logprobs = tensor([[-0.6742, -2.0484],
        [-0.6684, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797129273414612
Epoch 0, Step 555: train/loss = 0.47422367334365845, train/raw-loss = 0.4587993025779724, train/logprobs = tensor([[-0.6803, -2.1919],
        [-0.8610, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1542433202266693
Epoch 0, Step 556: train/loss = 0.654058039188385, train/raw-loss = 0.6368029117584229, train/logprobs = tensor([[-0.9762, -2.0102],
        [-0.7402, -1.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17255164682865143
Epoch 0, Step 557: train/loss = 0.6043628454208374, train/raw-loss = 0.5863856673240662, train/logprobs = tensor([[-1.4728, -2.0311],
        [-0.9918, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17977161705493927
Epoch 0, Step 558: train/loss = 0.5818703174591064, train/raw-loss = 0.5659323334693909, train/logprobs = tensor([[-0.8770, -1.8566],
        [-0.7850, -0.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15938033163547516
Epoch 0, Step 559: train/loss = 0.623733401298523, train/raw-loss = 0.6084117889404297, train/logprobs = tensor([[-0.7532, -1.3293],
        [-0.9111, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15321604907512665
Epoch 0, Step 560: train/loss = 0.5426241755485535, train/raw-loss = 0.5254309773445129, train/logprobs = tensor([[-1.1453, -2.8251],
        [-0.9396, -1.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17193175852298737
Epoch 0, Step 561: train/loss = 0.5753284692764282, train/raw-loss = 0.560641348361969, train/logprobs = tensor([[-0.6436, -1.6982],
        [-0.6546, -0.9710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14687149226665497
Epoch 0, Step 562: train/loss = 0.6646290421485901, train/raw-loss = 0.6542401909828186, train/logprobs = tensor([[-0.4427, -1.1992],
        [-0.4630, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10388852655887604
Epoch 0, Step 563: train/loss = 0.5070540904998779, train/raw-loss = 0.4899885356426239, train/logprobs = tensor([[-0.8069, -5.1984],
        [-0.7140, -2.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17065498232841492
Epoch 0, Step 564: train/loss = 0.5046634078025818, train/raw-loss = 0.49033302068710327, train/logprobs = tensor([[-0.8716, -2.1977],
        [-0.8244, -0.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14330360293388367
Epoch 0, Step 565: train/loss = 0.5380196571350098, train/raw-loss = 0.5253767967224121, train/logprobs = tensor([[-0.6362, -1.8540],
        [-0.7284, -0.6155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264287233352661
Epoch 0, Step 566: train/loss = 0.5893184542655945, train/raw-loss = 0.5760606527328491, train/logprobs = tensor([[-0.7777, -1.8812],
        [-0.7382, -0.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13257838785648346
Epoch 0, Step 567: train/loss = 0.6234656572341919, train/raw-loss = 0.6085107922554016, train/logprobs = tensor([[-0.8229, -1.2353],
        [-0.7164, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14954888820648193
Epoch 0, Step 568: train/loss = 0.5223956108093262, train/raw-loss = 0.5032409429550171, train/logprobs = tensor([[-0.8710, -4.3127],
        [-0.9581, -1.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915467530488968
Epoch 0, Step 569: train/loss = 0.5759789347648621, train/raw-loss = 0.5630238056182861, train/logprobs = tensor([[-0.6476, -1.5603],
        [-0.5566, -0.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295512318611145
Epoch 0, Step 570: train/loss = 0.6202446818351746, train/raw-loss = 0.6060264110565186, train/logprobs = tensor([[-0.6859, -1.0796],
        [-0.7050, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14218342304229736
Epoch 0, Step 571: train/loss = 0.6616623401641846, train/raw-loss = 0.6503332853317261, train/logprobs = tensor([[-0.5369, -0.6567],
        [-0.5688, -0.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11329098790884018
Epoch 0, Step 572: train/loss = 0.5280514359474182, train/raw-loss = 0.5111353397369385, train/logprobs = tensor([[-0.7997, -3.5381],
        [-0.7955, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16916128993034363
Epoch 0, Step 573: train/loss = 0.5978914499282837, train/raw-loss = 0.5806301832199097, train/logprobs = tensor([[-1.2178, -2.0750],
        [-0.9172, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1726125180721283
Epoch 0, Step 574: train/loss = 0.4798043370246887, train/raw-loss = 0.4642193913459778, train/logprobs = tensor([[-0.7177, -2.5951],
        [-0.9836, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15584903955459595
Epoch 0, Step 575: train/loss = 0.6177518963813782, train/raw-loss = 0.602256178855896, train/logprobs = tensor([[-0.6972, -1.0999],
        [-0.6835, -0.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549573540687561
Epoch 0, Step 576: train/loss = 0.5199580192565918, train/raw-loss = 0.505429744720459, train/logprobs = tensor([[-0.5621, -1.8223],
        [-0.6871, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1452825516462326
Epoch 0, Step 577: train/loss = 0.5139808058738708, train/raw-loss = 0.4971303939819336, train/logprobs = tensor([[-0.6317, -1.4563],
        [-0.7734, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16850411891937256
Epoch 0, Step 578: train/loss = 0.5110161304473877, train/raw-loss = 0.4944096505641937, train/logprobs = tensor([[-0.9759, -2.4276],
        [-1.0078, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16606448590755463
Epoch 0, Step 579: train/loss = 0.5702617764472961, train/raw-loss = 0.5565235614776611, train/logprobs = tensor([[-0.5922, -1.5711],
        [-0.5847, -0.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13738226890563965
Epoch 0, Step 580: train/loss = 0.6712666749954224, train/raw-loss = 0.6588987708091736, train/logprobs = tensor([[-0.5681, -0.5760],
        [-0.5502, -0.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1236790120601654
Epoch 0, Step 581: train/loss = 0.5126335024833679, train/raw-loss = 0.49856501817703247, train/logprobs = tensor([[-0.6824, -2.7485],
        [-0.7051, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14068499207496643
Epoch 0, Step 582: train/loss = 0.519707441329956, train/raw-loss = 0.5060482025146484, train/logprobs = tensor([[-0.6668, -1.7520],
        [-0.7817, -0.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13659270107746124
Epoch 0, Step 583: train/loss = 0.6859046220779419, train/raw-loss = 0.6717383861541748, train/logprobs = tensor([[-0.8856, -1.0839],
        [-0.7532, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.141662135720253
Epoch 0, Step 584: train/loss = 0.46044617891311646, train/raw-loss = 0.44641420245170593, train/logprobs = tensor([[-0.6895, -4.3872],
        [-0.7941, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403200924396515
Epoch 0, Step 585: train/loss = 0.5521601438522339, train/raw-loss = 0.5362879037857056, train/logprobs = tensor([[-0.8096, -1.5580],
        [-0.8403, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15872247517108917
Epoch 0, Step 586: train/loss = 0.6060889959335327, train/raw-loss = 0.589665412902832, train/logprobs = tensor([[-1.3496, -2.3814],
        [-1.0308, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16423632204532623
Epoch 0, Step 587: train/loss = 0.6606882214546204, train/raw-loss = 0.6455830931663513, train/logprobs = tensor([[-1.0078, -1.5604],
        [-0.7408, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15105094015598297
Epoch 0, Step 588: train/loss = 0.5283129215240479, train/raw-loss = 0.5113086700439453, train/logprobs = tensor([[-1.4306, -3.4867],
        [-1.1947, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17004302144050598
Epoch 0, Step 589: train/loss = 0.4502403736114502, train/raw-loss = 0.4332026541233063, train/logprobs = tensor([[-0.7424, -2.3113],
        [-0.8619, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17037740349769592
Epoch 0, Step 590: train/loss = 0.5723164081573486, train/raw-loss = 0.5584262609481812, train/logprobs = tensor([[-0.5130, -2.9392],
        [-0.5606, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890144228935242
Epoch 0, Step 591: train/loss = 0.6497135758399963, train/raw-loss = 0.6344611644744873, train/logprobs = tensor([[-0.7761, -0.9177],
        [-0.7865, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15252375602722168
Epoch 0, Step 592: train/loss = 0.5751998424530029, train/raw-loss = 0.5570071935653687, train/logprobs = tensor([[-1.2795, -2.1517],
        [-1.1030, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18192611634731293
Epoch 0, Step 593: train/loss = 0.7197429537773132, train/raw-loss = 0.7048662900924683, train/logprobs = tensor([[-1.3201, -1.0070],
        [-1.0953, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14876650273799896
Epoch 0, Step 594: train/loss = 0.657901406288147, train/raw-loss = 0.6426044702529907, train/logprobs = tensor([[-0.5398, -1.0134],
        [-0.5361, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15296925604343414
Epoch 0, Step 595: train/loss = 0.4836917519569397, train/raw-loss = 0.4691636562347412, train/logprobs = tensor([[-0.8691, -2.1649],
        [-0.9477, -0.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14528080821037292
Epoch 0, Step 596: train/loss = 0.5659843683242798, train/raw-loss = 0.5520763397216797, train/logprobs = tensor([[-0.6540, -2.2542],
        [-0.5637, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13908013701438904
Epoch 0, Step 597: train/loss = 0.5405943393707275, train/raw-loss = 0.5252803564071655, train/logprobs = tensor([[-0.6661, -2.9924],
        [-0.5817, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15313935279846191
Epoch 0, Step 598: train/loss = 0.48492535948753357, train/raw-loss = 0.46980226039886475, train/logprobs = tensor([[-0.7023, -2.0485],
        [-1.0129, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15123118460178375
Epoch 0, Step 599: train/loss = 0.3970694839954376, train/raw-loss = 0.37920084595680237, train/logprobs = tensor([[-0.9290, -3.2180],
        [-1.3227, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.178686261177063
Epoch 0, Step 600: train/loss = 0.5427087545394897, train/raw-loss = 0.526705801486969, train/logprobs = tensor([[-0.9528, -1.8620],
        [-0.9051, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16002912819385529
Epoch 0, Step 601: train/loss = 0.5889146327972412, train/raw-loss = 0.5748940110206604, train/logprobs = tensor([[-0.7897, -1.2946],
        [-0.8352, -0.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1402062177658081
Epoch 0, Step 602: train/loss = 0.5961511135101318, train/raw-loss = 0.5807204842567444, train/logprobs = tensor([[-0.5595, -1.0613],
        [-0.6338, -0.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543063372373581
Epoch 0, Step 603: train/loss = 0.6297868490219116, train/raw-loss = 0.6142923831939697, train/logprobs = tensor([[-0.7320, -1.1086],
        [-0.6678, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15494415163993835
Epoch 0, Step 604: train/loss = 0.5491191148757935, train/raw-loss = 0.5326024889945984, train/logprobs = tensor([[-0.8152, -2.3543],
        [-0.8454, -1.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16516602039337158
Epoch 0, Step 605: train/loss = 0.5167025327682495, train/raw-loss = 0.4998883605003357, train/logprobs = tensor([[-0.6941, -1.8350],
        [-0.9164, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16814184188842773
Epoch 0, Step 606: train/loss = 0.37342745065689087, train/raw-loss = 0.35586124658584595, train/logprobs = tensor([[-0.8253, -2.6429],
        [-1.0792, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17566236853599548
Epoch 0, Step 607: train/loss = 0.6112834215164185, train/raw-loss = 0.5973153114318848, train/logprobs = tensor([[-0.7316, -1.4738],
        [-0.7378, -1.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13968075811862946
Epoch 0, Step 608: train/loss = 0.47384971380233765, train/raw-loss = 0.45765045285224915, train/logprobs = tensor([[-0.8588, -2.9238],
        [-0.8407, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16199266910552979
Epoch 0, Step 609: train/loss = 0.4832042157649994, train/raw-loss = 0.465365469455719, train/logprobs = tensor([[-0.6846, -1.8256],
        [-0.8549, -0.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17838720977306366
Epoch 0, Step 610: train/loss = 0.6576512455940247, train/raw-loss = 0.6403040289878845, train/logprobs = tensor([[-0.9352, -1.0815],
        [-0.9018, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347204685211182
Epoch 0, Step 611: train/loss = 0.4568386673927307, train/raw-loss = 0.44181182980537415, train/logprobs = tensor([[-0.5140, -1.9267],
        [-0.7425, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15026822686195374
Epoch 0, Step 612: train/loss = 0.44993412494659424, train/raw-loss = 0.4320071339607239, train/logprobs = tensor([[-0.9905, -2.6696],
        [-1.0617, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17926952242851257
Epoch 0, Step 613: train/loss = 0.6269492506980896, train/raw-loss = 0.6123050451278687, train/logprobs = tensor([[-0.7253, -0.6772],
        [-0.8685, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14644208550453186
Epoch 0, Step 614: train/loss = 0.5729386806488037, train/raw-loss = 0.5599029064178467, train/logprobs = tensor([[-0.5541, -2.3525],
        [-0.5169, -0.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13035696744918823
Epoch 0, Step 615: train/loss = 0.6242526769638062, train/raw-loss = 0.6068864464759827, train/logprobs = tensor([[-0.8241, -1.1767],
        [-0.7245, -0.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366242408752441
Epoch 0, Step 616: train/loss = 0.3990021347999573, train/raw-loss = 0.3795320987701416, train/logprobs = tensor([[-0.9835, -2.7800],
        [-1.3601, -1.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19470025599002838
Epoch 0, Step 617: train/loss = 0.42622244358062744, train/raw-loss = 0.40622806549072266, train/logprobs = tensor([[-0.7955, -2.8223],
        [-1.0533, -0.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19994384050369263
Epoch 0, Step 618: train/loss = 0.5222596526145935, train/raw-loss = 0.5064472556114197, train/logprobs = tensor([[-0.8261, -1.9038],
        [-0.6970, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581241637468338
Epoch 0, Step 619: train/loss = 0.5709313154220581, train/raw-loss = 0.5587222576141357, train/logprobs = tensor([[-0.6922, -1.4501],
        [-0.7190, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12209106981754303
Epoch 0, Step 620: train/loss = 0.40698128938674927, train/raw-loss = 0.3899170756340027, train/logprobs = tensor([[-0.7187, -1.9744],
        [-1.1854, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17064228653907776
Epoch 0, Step 621: train/loss = 0.5912680625915527, train/raw-loss = 0.5769572257995605, train/logprobs = tensor([[-0.6226, -1.5349],
        [-0.6452, -0.9323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14310848712921143
Epoch 0, Step 622: train/loss = 0.40716472268104553, train/raw-loss = 0.3926081359386444, train/logprobs = tensor([[-0.6973, -3.1968],
        [-0.8704, -1.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14556612074375153
Epoch 0, Step 623: train/loss = 0.5102022886276245, train/raw-loss = 0.4934852719306946, train/logprobs = tensor([[-0.9305, -3.2900],
        [-1.0466, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16717016696929932
Epoch 0, Step 624: train/loss = 0.5264830589294434, train/raw-loss = 0.5087357759475708, train/logprobs = tensor([[-0.8251, -2.7290],
        [-0.8221, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17747296392917633
Epoch 0, Step 625: train/loss = 0.5007483959197998, train/raw-loss = 0.48696663975715637, train/logprobs = tensor([[-0.6349, -2.0425],
        [-0.5985, -0.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13781774044036865
Epoch 0, Step 626: train/loss = 0.5776637196540833, train/raw-loss = 0.5637667775154114, train/logprobs = tensor([[-0.7006, -1.5683],
        [-0.6680, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13896922767162323
Epoch 0, Step 627: train/loss = 0.5366405844688416, train/raw-loss = 0.5202048420906067, train/logprobs = tensor([[-0.5502, -1.4527],
        [-0.7378, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16435743868350983
Epoch 0, Step 628: train/loss = 0.5524884462356567, train/raw-loss = 0.5367676019668579, train/logprobs = tensor([[-0.8829, -1.7827],
        [-0.7996, -0.7638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15720853209495544
Epoch 0, Step 629: train/loss = 0.591038167476654, train/raw-loss = 0.5738343000411987, train/logprobs = tensor([[-0.7661, -1.3177],
        [-0.7401, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17203886806964874
Epoch 0, Step 630: train/loss = 0.6460395455360413, train/raw-loss = 0.6342703104019165, train/logprobs = tensor([[-0.6227, -0.7345],
        [-0.6882, -0.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11769305914640427
Epoch 0, Step 631: train/loss = 0.6532177925109863, train/raw-loss = 0.6396548748016357, train/logprobs = tensor([[-0.5244, -0.8003],
        [-0.5922, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13562935590744019
Epoch 0, Step 632: train/loss = 0.6952681541442871, train/raw-loss = 0.6814286112785339, train/logprobs = tensor([[-1.2102, -1.7932],
        [-0.6988, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383950412273407
Epoch 0, Step 633: train/loss = 0.6574732065200806, train/raw-loss = 0.643013060092926, train/logprobs = tensor([[-0.7307, -1.0072],
        [-0.6677, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14460133016109467
Epoch 0, Step 634: train/loss = 0.5939981937408447, train/raw-loss = 0.5787914395332336, train/logprobs = tensor([[-0.8453, -1.7982],
        [-0.5945, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15206776559352875
Epoch 0, Step 635: train/loss = 0.5150836706161499, train/raw-loss = 0.49670156836509705, train/logprobs = tensor([[-0.8804, -1.8891],
        [-0.8008, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838207244873047
Epoch 0, Step 636: train/loss = 0.4135814905166626, train/raw-loss = 0.4003475308418274, train/logprobs = tensor([[-0.5105, -4.3542],
        [-0.7758, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13233976066112518
Epoch 0, Step 637: train/loss = 0.3871181309223175, train/raw-loss = 0.36989960074424744, train/logprobs = tensor([[-0.8283, -2.4565],
        [-1.1500, -0.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17218546569347382
Epoch 0, Step 638: train/loss = 0.45859336853027344, train/raw-loss = 0.4426635503768921, train/logprobs = tensor([[-0.7839, -4.4941],
        [-0.7237, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15929844975471497
Epoch 0, Step 639: train/loss = 0.45336639881134033, train/raw-loss = 0.43516260385513306, train/logprobs = tensor([[-0.7177, -2.3545],
        [-0.9016, -0.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18203793466091156
Epoch 0, Step 640: train/loss = 0.39697474241256714, train/raw-loss = 0.3782249093055725, train/logprobs = tensor([[-0.7306, -2.9439],
        [-1.3261, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18749846518039703
Epoch 0, Step 641: train/loss = 0.5331273674964905, train/raw-loss = 0.5149393677711487, train/logprobs = tensor([[-1.4245, -2.2621],
        [-1.4272, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18188028037548065
Epoch 0, Step 642: train/loss = 0.45486366748809814, train/raw-loss = 0.4372382164001465, train/logprobs = tensor([[-0.8586, -2.9278],
        [-1.1692, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17625437676906586
Epoch 0, Step 643: train/loss = 0.42850401997566223, train/raw-loss = 0.41136813163757324, train/logprobs = tensor([[-0.5746, -1.9154],
        [-0.8816, -0.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.171359121799469
Epoch 0, Step 644: train/loss = 0.5166678428649902, train/raw-loss = 0.49839144945144653, train/logprobs = tensor([[-0.7703, -1.9634],
        [-0.8172, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1827639788389206
Epoch 0, Step 645: train/loss = 0.5035607218742371, train/raw-loss = 0.4877249002456665, train/logprobs = tensor([[-0.6360, -1.8125],
        [-0.7925, -0.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15835821628570557
Epoch 0, Step 646: train/loss = 0.6818152070045471, train/raw-loss = 0.6669707298278809, train/logprobs = tensor([[-0.5917, -0.6570],
        [-0.7095, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14844442903995514
Epoch 0, Step 647: train/loss = 0.4544658362865448, train/raw-loss = 0.43745970726013184, train/logprobs = tensor([[-0.7454, -2.6541],
        [-0.9094, -0.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700620949268341
Epoch 0, Step 648: train/loss = 0.35916441679000854, train/raw-loss = 0.34353405237197876, train/logprobs = tensor([[-0.6558, -3.1592],
        [-0.7419, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15630385279655457
Epoch 0, Step 649: train/loss = 0.5026164054870605, train/raw-loss = 0.48613211512565613, train/logprobs = tensor([[-0.6848, -1.8697],
        [-0.9429, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16484299302101135
Epoch 0, Step 650: train/loss = 0.4177311658859253, train/raw-loss = 0.39948397874832153, train/logprobs = tensor([[-0.9609, -2.5227],
        [-1.0779, -0.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824716478586197
Epoch 0, Step 651: train/loss = 0.672602117061615, train/raw-loss = 0.6574622988700867, train/logprobs = tensor([[-0.7113, -0.8536],
        [-0.7050, -0.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15139858424663544
Epoch 0, Step 652: train/loss = 0.35359853506088257, train/raw-loss = 0.33841025829315186, train/logprobs = tensor([[-0.8813, -3.1177],
        [-0.9332, -0.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518826186656952
Epoch 0, Step 653: train/loss = 0.6334434747695923, train/raw-loss = 0.6181209683418274, train/logprobs = tensor([[-0.7480, -1.0839],
        [-0.6499, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15322481095790863
Epoch 0, Step 654: train/loss = 0.6669870018959045, train/raw-loss = 0.6519204378128052, train/logprobs = tensor([[-0.6031, -0.7691],
        [-0.6542, -0.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066586434841156
Epoch 0, Step 655: train/loss = 0.5067276358604431, train/raw-loss = 0.48901304602622986, train/logprobs = tensor([[-0.8293, -1.6792],
        [-1.0451, -0.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17714598774909973
Epoch 0, Step 656: train/loss = 0.4107392728328705, train/raw-loss = 0.39661893248558044, train/logprobs = tensor([[-0.6552, -4.6856],
        [-0.8610, -0.8132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14120326936244965
Epoch 0, Step 657: train/loss = 0.5382972359657288, train/raw-loss = 0.5220535397529602, train/logprobs = tensor([[-0.8653, -1.7242],
        [-0.9631, -0.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16243688762187958
Epoch 0, Step 658: train/loss = 0.7345535159111023, train/raw-loss = 0.7158876657485962, train/logprobs = tensor([[-2.4775, -3.4069],
        [-1.6492, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18665850162506104
Epoch 0, Step 659: train/loss = 0.4355027675628662, train/raw-loss = 0.4217609167098999, train/logprobs = tensor([[-0.4850, -2.3276],
        [-0.6220, -0.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13741838932037354
Epoch 0, Step 660: train/loss = 0.5282019376754761, train/raw-loss = 0.5110526084899902, train/logprobs = tensor([[-0.7654, -2.9621],
        [-0.6911, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17149361968040466
Epoch 0, Step 661: train/loss = 0.37670788168907166, train/raw-loss = 0.35901057720184326, train/logprobs = tensor([[-0.7920, -3.6040],
        [-0.9809, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1769728660583496
Epoch 0, Step 662: train/loss = 0.4519895911216736, train/raw-loss = 0.4353976845741272, train/logprobs = tensor([[-0.9348, -2.2652],
        [-1.2403, -0.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16591908037662506
Epoch 0, Step 663: train/loss = 0.4959733188152313, train/raw-loss = 0.47841209173202515, train/logprobs = tensor([[-0.8924, -2.4005],
        [-0.8630, -0.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756119281053543
Epoch 0, Step 664: train/loss = 0.5173438191413879, train/raw-loss = 0.49865320324897766, train/logprobs = tensor([[-0.7216, -1.4479],
        [-1.1369, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18690650165081024
Epoch 0, Step 665: train/loss = 0.37974101305007935, train/raw-loss = 0.3584469258785248, train/logprobs = tensor([[-0.8440, -2.5118],
        [-1.2535, -0.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21294066309928894
Epoch 0, Step 666: train/loss = 0.39875417947769165, train/raw-loss = 0.37988442182540894, train/logprobs = tensor([[-0.9623, -3.3464],
        [-1.2138, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1886979341506958
Epoch 0, Step 667: train/loss = 0.6852937936782837, train/raw-loss = 0.6692283153533936, train/logprobs = tensor([[-0.6844, -0.8474],
        [-0.6208, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16065436601638794
Epoch 0, Step 668: train/loss = 0.5027890205383301, train/raw-loss = 0.4862157702445984, train/logprobs = tensor([[-0.9781, -2.6903],
        [-1.0889, -0.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16573229432106018
Epoch 0, Step 669: train/loss = 0.5903823375701904, train/raw-loss = 0.5746282339096069, train/logprobs = tensor([[-1.0497, -1.8733],
        [-0.9313, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15754103660583496
Epoch 0, Step 670: train/loss = 0.498972088098526, train/raw-loss = 0.48181843757629395, train/logprobs = tensor([[-0.5378, -1.7874],
        [-0.7456, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1715363711118698
Epoch 0, Step 671: train/loss = 0.5771992802619934, train/raw-loss = 0.5608088374137878, train/logprobs = tensor([[-0.8315, -2.0532],
        [-0.6950, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16390438377857208
Epoch 0, Step 672: train/loss = 0.45675498247146606, train/raw-loss = 0.43881163001060486, train/logprobs = tensor([[-0.8150, -1.6521],
        [-1.4050, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17943353950977325
Epoch 0, Step 673: train/loss = 0.6097740530967712, train/raw-loss = 0.5945556163787842, train/logprobs = tensor([[-0.8369, -1.5578],
        [-0.6909, -0.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15218475461006165
Epoch 0, Step 674: train/loss = 0.6702057123184204, train/raw-loss = 0.6577101349830627, train/logprobs = tensor([[-0.4652, -0.6652],
        [-0.3763, -0.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12495578825473785
Epoch 0, Step 675: train/loss = 0.5057932138442993, train/raw-loss = 0.4896252453327179, train/logprobs = tensor([[-0.7015, -2.4324],
        [-0.8300, -0.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616799235343933
Epoch 0, Step 676: train/loss = 0.4615674316883087, train/raw-loss = 0.4457809627056122, train/logprobs = tensor([[-0.6134, -4.2592],
        [-0.8206, -0.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15786464512348175
Epoch 0, Step 677: train/loss = 0.505426824092865, train/raw-loss = 0.4909820854663849, train/logprobs = tensor([[-0.4727, -1.9643],
        [-0.5996, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444725215435028
Epoch 0, Step 678: train/loss = 0.5540059804916382, train/raw-loss = 0.5391965508460999, train/logprobs = tensor([[-0.6661, -1.2784],
        [-0.8240, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14809450507164001
Epoch 0, Step 679: train/loss = 0.6183454990386963, train/raw-loss = 0.602397620677948, train/logprobs = tensor([[-0.6812, -1.1602],
        [-0.7034, -0.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15947896242141724
Epoch 0, Step 680: train/loss = 0.5839327573776245, train/raw-loss = 0.5662458539009094, train/logprobs = tensor([[-0.8471, -1.2451],
        [-0.9757, -0.7595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17686942219734192
Epoch 0, Step 681: train/loss = 0.6154667139053345, train/raw-loss = 0.6016279458999634, train/logprobs = tensor([[-0.4764, -0.9586],
        [-0.5779, -0.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383880227804184
Epoch 0, Step 682: train/loss = 0.6692962050437927, train/raw-loss = 0.6502702832221985, train/logprobs = tensor([[-1.1635, -1.4181],
        [-0.7402, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19025932252407074
Epoch 0, Step 683: train/loss = 0.5127791166305542, train/raw-loss = 0.4944528639316559, train/logprobs = tensor([[-0.6843, -1.5319],
        [-0.9260, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18326221406459808
Epoch 0, Step 684: train/loss = 0.5389265418052673, train/raw-loss = 0.5208910703659058, train/logprobs = tensor([[-0.8213, -2.0058],
        [-0.9711, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18035469949245453
Epoch 0, Step 685: train/loss = 0.46386778354644775, train/raw-loss = 0.4475715756416321, train/logprobs = tensor([[-0.6662, -3.0508],
        [-0.7701, -0.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16296231746673584
Epoch 0, Step 686: train/loss = 0.576099693775177, train/raw-loss = 0.5614380240440369, train/logprobs = tensor([[-0.5849, -1.0193],
        [-0.8550, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14661669731140137
Epoch 0, Step 687: train/loss = 0.4750025272369385, train/raw-loss = 0.4586961567401886, train/logprobs = tensor([[-0.5884, -2.4733],
        [-0.9179, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16306383907794952
Epoch 0, Step 688: train/loss = 0.586688756942749, train/raw-loss = 0.573025643825531, train/logprobs = tensor([[-0.5927, -0.7358],
        [-0.8200, -0.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13663102686405182
Epoch 0, Step 689: train/loss = 0.5837718844413757, train/raw-loss = 0.5657695531845093, train/logprobs = tensor([[-1.0750, -1.6980],
        [-1.0764, -0.7287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18002364039421082
Epoch 0, Step 690: train/loss = 0.45860224962234497, train/raw-loss = 0.44007623195648193, train/logprobs = tensor([[-0.8367, -2.2264],
        [-1.2362, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852598488330841
Epoch 0, Step 691: train/loss = 0.5971488952636719, train/raw-loss = 0.5779255032539368, train/logprobs = tensor([[-1.0536, -1.5901],
        [-1.1391, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19223348796367645
Epoch 0, Step 692: train/loss = 0.5330583453178406, train/raw-loss = 0.5179276466369629, train/logprobs = tensor([[-0.5578, -1.5262],
        [-0.6685, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15130731463432312
Epoch 0, Step 693: train/loss = 0.6319878101348877, train/raw-loss = 0.619096577167511, train/logprobs = tensor([[-0.4828, -0.7707],
        [-0.5277, -0.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12891174852848053
Epoch 0, Step 694: train/loss = 0.5331403613090515, train/raw-loss = 0.5175811648368835, train/logprobs = tensor([[-0.7434, -1.9486],
        [-0.7217, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15559183061122894
Epoch 0, Step 695: train/loss = 0.5708111524581909, train/raw-loss = 0.5568552017211914, train/logprobs = tensor([[-0.6104, -3.3756],
        [-0.6152, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13955947756767273
Epoch 0, Step 696: train/loss = 0.5892058610916138, train/raw-loss = 0.5716455578804016, train/logprobs = tensor([[-0.8734, -1.1194],
        [-1.1286, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756029725074768
Epoch 0, Step 697: train/loss = 0.5483654141426086, train/raw-loss = 0.5333734154701233, train/logprobs = tensor([[-0.5438, -1.8815],
        [-0.7955, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14992007613182068
Epoch 0, Step 698: train/loss = 0.5102624893188477, train/raw-loss = 0.4937787652015686, train/logprobs = tensor([[-0.6713, -3.4974],
        [-0.7501, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648367941379547
Epoch 0, Step 699: train/loss = 0.513958215713501, train/raw-loss = 0.49667632579803467, train/logprobs = tensor([[-0.6583, -1.7762],
        [-0.8235, -0.6632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17281894385814667
Epoch 0, Step 700: train/loss = 0.5545052886009216, train/raw-loss = 0.5363218188285828, train/logprobs = tensor([[-0.7655, -1.6975],
        [-0.8011, -0.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18183442950248718
Epoch 0, Step 701: train/loss = 0.47999247908592224, train/raw-loss = 0.46468058228492737, train/logprobs = tensor([[-0.7578, -2.8980],
        [-0.7395, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1531190276145935
Epoch 0, Step 702: train/loss = 0.49683672189712524, train/raw-loss = 0.47941818833351135, train/logprobs = tensor([[-0.6270, -1.5397],
        [-0.9049, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17418526113033295
Epoch 0, Step 703: train/loss = 0.4350156784057617, train/raw-loss = 0.41833630204200745, train/logprobs = tensor([[-0.7192, -2.6547],
        [-0.7056, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1667938232421875
Epoch 0, Step 704: train/loss = 0.49331140518188477, train/raw-loss = 0.4772323966026306, train/logprobs = tensor([[-0.6027, -2.0629],
        [-0.7864, -0.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16078974306583405
Epoch 0, Step 705: train/loss = 0.6643820405006409, train/raw-loss = 0.6488875150680542, train/logprobs = tensor([[-0.4133, -0.5979],
        [-0.6198, -0.6084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549447923898697
Epoch 0, Step 706: train/loss = 0.3955629765987396, train/raw-loss = 0.37708401679992676, train/logprobs = tensor([[-1.0675, -3.5360],
        [-1.0458, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18478992581367493
Epoch 0, Step 707: train/loss = 0.3959929347038269, train/raw-loss = 0.3801034092903137, train/logprobs = tensor([[-0.7085, -2.2606],
        [-1.0322, -0.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588953137397766
Epoch 0, Step 708: train/loss = 0.4625144600868225, train/raw-loss = 0.44381195306777954, train/logprobs = tensor([[-0.8157, -1.2874],
        [-1.4067, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18702489137649536
Epoch 0, Step 709: train/loss = 0.5726066827774048, train/raw-loss = 0.5571926236152649, train/logprobs = tensor([[-0.5092, -1.2526],
        [-0.7911, -0.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15414035320281982
Epoch 0, Step 710: train/loss = 0.44787025451660156, train/raw-loss = 0.4320363402366638, train/logprobs = tensor([[-0.7835, -2.3997],
        [-0.9056, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15833903849124908
Epoch 0, Step 711: train/loss = 0.6295316219329834, train/raw-loss = 0.6153826713562012, train/logprobs = tensor([[-0.6364, -0.7265],
        [-0.8091, -0.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14148929715156555
Epoch 0, Step 712: train/loss = 0.5436533093452454, train/raw-loss = 0.5271115303039551, train/logprobs = tensor([[-0.6071, -1.5439],
        [-0.8586, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16541770100593567
Epoch 0, Step 713: train/loss = 0.6731988191604614, train/raw-loss = 0.6577116250991821, train/logprobs = tensor([[-0.5399, -0.7101],
        [-0.6539, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1548718959093094
Epoch 0, Step 714: train/loss = 0.6269969344139099, train/raw-loss = 0.609796941280365, train/logprobs = tensor([[-0.8852, -1.1257],
        [-0.8336, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17200027406215668
Epoch 0, Step 715: train/loss = 0.5258747339248657, train/raw-loss = 0.5061957836151123, train/logprobs = tensor([[-0.7101, -1.6719],
        [-0.9782, -0.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19678853452205658
Epoch 0, Step 716: train/loss = 0.41792139410972595, train/raw-loss = 0.39808106422424316, train/logprobs = tensor([[-1.0846, -2.8363],
        [-1.3641, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19840320944786072
Epoch 0, Step 717: train/loss = 0.4423632025718689, train/raw-loss = 0.42449110746383667, train/logprobs = tensor([[-0.5740, -2.4314],
        [-0.8392, -0.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17872105538845062
Epoch 0, Step 718: train/loss = 0.5325571298599243, train/raw-loss = 0.5155394077301025, train/logprobs = tensor([[-0.5354, -2.1130],
        [-0.7194, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17017705738544464
Epoch 0, Step 719: train/loss = 0.698483407497406, train/raw-loss = 0.6782707571983337, train/logprobs = tensor([[-1.4475, -1.7111],
        [-0.9008, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021263986825943
Epoch 0, Step 720: train/loss = 0.526118814945221, train/raw-loss = 0.5096946358680725, train/logprobs = tensor([[-0.5867, -1.8650],
        [-0.7863, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1642417013645172
Epoch 0, Step 721: train/loss = 0.5437296628952026, train/raw-loss = 0.5259631276130676, train/logprobs = tensor([[-0.9132, -2.1005],
        [-1.1458, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17766517400741577
Epoch 0, Step 722: train/loss = 0.4774954319000244, train/raw-loss = 0.4600529968738556, train/logprobs = tensor([[-0.8812, -2.8307],
        [-1.0359, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17442460358142853
Epoch 0, Step 723: train/loss = 0.574203610420227, train/raw-loss = 0.5569974184036255, train/logprobs = tensor([[-0.8784, -1.7946],
        [-0.8913, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17206218838691711
Epoch 0, Step 724: train/loss = 0.542083740234375, train/raw-loss = 0.5242780447006226, train/logprobs = tensor([[-0.6798, -1.6260],
        [-0.7959, -0.7282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17805637419223785
Epoch 0, Step 725: train/loss = 0.6079539060592651, train/raw-loss = 0.592566967010498, train/logprobs = tensor([[-0.6654, -0.9989],
        [-0.7525, -0.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15386979281902313
Epoch 0, Step 726: train/loss = 0.49792397022247314, train/raw-loss = 0.4798373878002167, train/logprobs = tensor([[-0.6852, -1.8381],
        [-0.8357, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18086586892604828
Epoch 0, Step 727: train/loss = 0.549218475818634, train/raw-loss = 0.5322206020355225, train/logprobs = tensor([[-1.4626, -2.7281],
        [-1.2841, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16997851431369781
Epoch 0, Step 728: train/loss = 0.424441933631897, train/raw-loss = 0.4042903780937195, train/logprobs = tensor([[-0.9340, -2.2183],
        [-1.2277, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20151562988758087
Epoch 0, Step 729: train/loss = 0.5552921295166016, train/raw-loss = 0.5395210981369019, train/logprobs = tensor([[-0.8256, -1.5164],
        [-0.8956, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15771064162254333
Epoch 0, Step 730: train/loss = 0.5736241340637207, train/raw-loss = 0.557023823261261, train/logprobs = tensor([[-0.8512, -1.5486],
        [-0.8616, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16600361466407776
Epoch 0, Step 731: train/loss = 0.45326244831085205, train/raw-loss = 0.4323950409889221, train/logprobs = tensor([[-0.6523, -2.3270],
        [-1.0359, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20867416262626648
Epoch 0, Step 732: train/loss = 0.5987892746925354, train/raw-loss = 0.5791789293289185, train/logprobs = tensor([[-0.7373, -1.0794],
        [-1.0090, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1961035132408142
Epoch 0, Step 733: train/loss = 0.700141429901123, train/raw-loss = 0.6838001012802124, train/logprobs = tensor([[-0.7175, -0.7053],
        [-0.7791, -0.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16341423988342285
Epoch 0, Step 734: train/loss = 0.6642151474952698, train/raw-loss = 0.6506888270378113, train/logprobs = tensor([[-0.6220, -0.6151],
        [-0.7124, -0.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13526365160942078
Epoch 0, Step 735: train/loss = 0.5919345021247864, train/raw-loss = 0.5756608247756958, train/logprobs = tensor([[-0.8613, -1.0778],
        [-1.0732, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16273680329322815
Epoch 0, Step 736: train/loss = 0.45540645718574524, train/raw-loss = 0.4365640878677368, train/logprobs = tensor([[-0.7524, -2.3915],
        [-1.0140, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188423752784729
Epoch 0, Step 737: train/loss = 0.5230421423912048, train/raw-loss = 0.5025128126144409, train/logprobs = tensor([[-0.5925, -1.6451],
        [-1.0127, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20529350638389587
Epoch 0, Step 738: train/loss = 0.4022015333175659, train/raw-loss = 0.384280264377594, train/logprobs = tensor([[-0.9581, -5.3296],
        [-1.0106, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1792128086090088
Epoch 0, Step 739: train/loss = 0.5523273348808289, train/raw-loss = 0.5300907492637634, train/logprobs = tensor([[-0.8987, -1.7585],
        [-1.1077, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22236588597297668
Epoch 0, Step 740: train/loss = 0.31218209862709045, train/raw-loss = 0.2940192222595215, train/logprobs = tensor([[-0.6649, -4.7975],
        [-1.2044, -0.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18162868916988373
Epoch 0, Step 741: train/loss = 0.36022698879241943, train/raw-loss = 0.3351013958454132, train/logprobs = tensor([[-0.7470, -2.6527],
        [-1.7639, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512558698654175
Epoch 0, Step 742: train/loss = 0.559037446975708, train/raw-loss = 0.5402718186378479, train/logprobs = tensor([[-0.6619, -1.3186],
        [-0.8655, -0.6189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18765631318092346
Epoch 0, Step 743: train/loss = 0.553271472454071, train/raw-loss = 0.5326734781265259, train/logprobs = tensor([[-1.1965, -2.8245],
        [-1.0009, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20597945153713226
Epoch 0, Step 744: train/loss = 0.5595898032188416, train/raw-loss = 0.5413692593574524, train/logprobs = tensor([[-0.5949, -1.9363],
        [-0.9113, -0.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18220505118370056
Epoch 0, Step 745: train/loss = 0.42235612869262695, train/raw-loss = 0.4014817774295807, train/logprobs = tensor([[-0.8419, -3.8993],
        [-1.2578, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20874324440956116
Epoch 0, Step 746: train/loss = 0.5851502418518066, train/raw-loss = 0.5656337738037109, train/logprobs = tensor([[-1.2825, -2.6475],
        [-0.9178, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19516441226005554
Epoch 0, Step 747: train/loss = 0.5555579662322998, train/raw-loss = 0.5343388319015503, train/logprobs = tensor([[-0.8387, -1.2721],
        [-1.1315, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21219074726104736
Epoch 0, Step 748: train/loss = 0.4593305289745331, train/raw-loss = 0.4397585093975067, train/logprobs = tensor([[-0.7644, -2.3963],
        [-0.9026, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19572073221206665
Epoch 0, Step 749: train/loss = 0.5354628562927246, train/raw-loss = 0.5158576965332031, train/logprobs = tensor([[-0.9672, -2.1453],
        [-1.1051, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19605132937431335
Epoch 0, Step 750: train/loss = 0.5495533347129822, train/raw-loss = 0.5321831703186035, train/logprobs = tensor([[-0.8204, -1.8594],
        [-0.9758, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17370200157165527
Epoch 0, Step 751: train/loss = 0.35199201107025146, train/raw-loss = 0.3325251042842865, train/logprobs = tensor([[-0.9249, -3.7918],
        [-1.0523, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19466876983642578
Epoch 0, Step 752: train/loss = 0.29325538873672485, train/raw-loss = 0.27339720726013184, train/logprobs = tensor([[-0.7362, -3.8071],
        [-1.3722, -0.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858184456825256
Epoch 0, Step 753: train/loss = 0.689139187335968, train/raw-loss = 0.6719985604286194, train/logprobs = tensor([[-0.5919, -0.6361],
        [-0.7003, -0.6523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17140623927116394
Epoch 0, Step 754: train/loss = 0.354396790266037, train/raw-loss = 0.3331209123134613, train/logprobs = tensor([[-0.8677, -3.5419],
        [-1.1924, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21275894343852997
Epoch 0, Step 755: train/loss = 0.5257149934768677, train/raw-loss = 0.5072016716003418, train/logprobs = tensor([[-0.9630, -3.5065],
        [-1.0906, -0.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18513277173042297
Epoch 0, Step 756: train/loss = 0.49841970205307007, train/raw-loss = 0.47927024960517883, train/logprobs = tensor([[-0.9714, -1.9811],
        [-0.9727, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19149446487426758
Epoch 0, Step 757: train/loss = 0.38596948981285095, train/raw-loss = 0.3665429353713989, train/logprobs = tensor([[-0.9675, -4.7733],
        [-1.2160, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19426563382148743
Epoch 0, Step 758: train/loss = 0.41357386112213135, train/raw-loss = 0.3935023546218872, train/logprobs = tensor([[-0.6600, -2.9635],
        [-0.9785, -0.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20071500539779663
Epoch 0, Step 759: train/loss = 0.46579045057296753, train/raw-loss = 0.4477490782737732, train/logprobs = tensor([[-1.3691, -2.9099],
        [-1.1598, -0.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18041375279426575
Epoch 0, Step 760: train/loss = 0.7073689103126526, train/raw-loss = 0.6873942613601685, train/logprobs = tensor([[-0.6573, -0.6631],
        [-0.7817, -0.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19974671304225922
Epoch 0, Step 761: train/loss = 0.655042290687561, train/raw-loss = 0.6350125074386597, train/logprobs = tensor([[-1.8670, -3.1817],
        [-0.8370, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2002979964017868
Epoch 0, Step 762: train/loss = 0.3959447145462036, train/raw-loss = 0.37185266613960266, train/logprobs = tensor([[-0.8846, -1.9641],
        [-1.6041, -0.8458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24092049896717072
Epoch 0, Step 763: train/loss = 0.5436220169067383, train/raw-loss = 0.5253374576568604, train/logprobs = tensor([[-0.7736, -2.1691],
        [-0.8459, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284542858600616
Epoch 0, Step 764: train/loss = 0.5530865788459778, train/raw-loss = 0.5366731286048889, train/logprobs = tensor([[-0.5850, -2.2480],
        [-0.6373, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16413410007953644
Epoch 0, Step 765: train/loss = 0.7123880982398987, train/raw-loss = 0.6950218677520752, train/logprobs = tensor([[-0.8945, -1.0460],
        [-0.6822, -0.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366230487823486
Epoch 0, Step 766: train/loss = 0.7492296695709229, train/raw-loss = 0.7309730052947998, train/logprobs = tensor([[-2.1364, -3.3925],
        [-0.9662, -0.7209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18256647884845734
Epoch 0, Step 767: train/loss = 0.6611579656600952, train/raw-loss = 0.6446257829666138, train/logprobs = tensor([[-0.6230, -0.9620],
        [-0.8269, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16532184183597565
Epoch 0, Step 768: train/loss = 0.43538081645965576, train/raw-loss = 0.41731661558151245, train/logprobs = tensor([[-0.6485, -3.7166],
        [-0.8402, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1806420385837555
Epoch 0, Step 769: train/loss = 0.5937199592590332, train/raw-loss = 0.5721566081047058, train/logprobs = tensor([[-0.5939, -1.2513],
        [-0.9854, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2156333029270172
Epoch 0, Step 770: train/loss = 0.5157959461212158, train/raw-loss = 0.49589288234710693, train/logprobs = tensor([[-0.6379, -2.4141],
        [-0.8951, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19903074204921722
Epoch 0, Step 771: train/loss = 0.39741051197052, train/raw-loss = 0.37574923038482666, train/logprobs = tensor([[-0.7248, -3.3823],
        [-0.9599, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21661260724067688
Epoch 0, Step 772: train/loss = 0.3596372604370117, train/raw-loss = 0.33763009309768677, train/logprobs = tensor([[-0.7972, -2.5333],
        [-1.4994, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22007140517234802
Epoch 0, Step 773: train/loss = 0.6191442012786865, train/raw-loss = 0.5991487503051758, train/logprobs = tensor([[-1.2705, -2.5016],
        [-0.7257, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19995485246181488
Epoch 0, Step 774: train/loss = 0.6196145415306091, train/raw-loss = 0.5962184071540833, train/logprobs = tensor([[-0.9795, -1.9797],
        [-1.0226, -1.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23396123945713043
Epoch 0, Step 775: train/loss = 0.5944536924362183, train/raw-loss = 0.5748379826545715, train/logprobs = tensor([[-0.6805, -1.2911],
        [-0.9023, -0.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1961573362350464
Epoch 0, Step 776: train/loss = 0.5840474963188171, train/raw-loss = 0.5657438635826111, train/logprobs = tensor([[-0.4623, -0.7795],
        [-0.9114, -0.6483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18303659558296204
Epoch 0, Step 777: train/loss = 0.4353506565093994, train/raw-loss = 0.41633909940719604, train/logprobs = tensor([[-0.5744, -5.0442],
        [-0.8386, -0.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19011501967906952
Epoch 0, Step 778: train/loss = 0.7523193359375, train/raw-loss = 0.7325429320335388, train/logprobs = tensor([[-1.9097, -2.8084],
        [-0.9897, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977648138999939
Epoch 0, Step 779: train/loss = 0.5221467018127441, train/raw-loss = 0.49857383966445923, train/logprobs = tensor([[-0.6314, -1.4236],
        [-1.2123, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23572896420955658
Epoch 0, Step 780: train/loss = 0.5358636975288391, train/raw-loss = 0.5161285996437073, train/logprobs = tensor([[-1.0019, -1.7356],
        [-1.1831, -0.5699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1973508894443512
Epoch 0, Step 781: train/loss = 0.39578771591186523, train/raw-loss = 0.3759046196937561, train/logprobs = tensor([[-0.5959, -3.3208],
        [-1.0378, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.198831245303154
Epoch 0, Step 782: train/loss = 0.3827052116394043, train/raw-loss = 0.36081036925315857, train/logprobs = tensor([[-0.7242, -3.3477],
        [-1.0283, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21894852817058563
Epoch 0, Step 783: train/loss = 0.5950325727462769, train/raw-loss = 0.5743703842163086, train/logprobs = tensor([[-0.5836, -1.7702],
        [-0.7904, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066219449043274
Epoch 0, Step 784: train/loss = 0.34642407298088074, train/raw-loss = 0.3261744976043701, train/logprobs = tensor([[-0.9801, -4.6389],
        [-1.2195, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20249556005001068
Epoch 0, Step 785: train/loss = 0.5593589544296265, train/raw-loss = 0.5412424802780151, train/logprobs = tensor([[-0.8929, -1.9403],
        [-0.9630, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18116483092308044
Epoch 0, Step 786: train/loss = 0.3541162610054016, train/raw-loss = 0.3350293040275574, train/logprobs = tensor([[-0.5556, -4.3951],
        [-0.9326, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19086937606334686
Epoch 0, Step 787: train/loss = 0.4210510551929474, train/raw-loss = 0.4042195677757263, train/logprobs = tensor([[-0.6592, -5.2044],
        [-0.9800, -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16831451654434204
Epoch 0, Step 788: train/loss = 0.47561997175216675, train/raw-loss = 0.4547216296195984, train/logprobs = tensor([[-0.7278, -2.5609],
        [-1.0179, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20898349583148956
Epoch 0, Step 789: train/loss = 0.4463686943054199, train/raw-loss = 0.4276200830936432, train/logprobs = tensor([[-1.1271, -3.8101],
        [-0.8623, -0.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18748609721660614
Epoch 0, Step 790: train/loss = 0.5740199089050293, train/raw-loss = 0.5568114519119263, train/logprobs = tensor([[-0.9939, -2.9804],
        [-0.8569, -1.2321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17208467423915863
Epoch 0, Step 791: train/loss = 0.6171900033950806, train/raw-loss = 0.5963521599769592, train/logprobs = tensor([[-0.8982, -0.9827],
        [-1.1553, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20837850868701935
Epoch 0, Step 792: train/loss = 0.4641261696815491, train/raw-loss = 0.44440194964408875, train/logprobs = tensor([[-0.7830, -2.4700],
        [-0.7653, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19724182784557343
Epoch 0, Step 793: train/loss = 0.675879180431366, train/raw-loss = 0.657661497592926, train/logprobs = tensor([[-0.4388, -0.6697],
        [-0.7017, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18217623233795166
Epoch 0, Step 794: train/loss = 0.46136942505836487, train/raw-loss = 0.43807709217071533, train/logprobs = tensor([[-0.9378, -1.9038],
        [-1.5806, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23292326927185059
Epoch 0, Step 795: train/loss = 0.4698038697242737, train/raw-loss = 0.4492678642272949, train/logprobs = tensor([[-0.8853, -2.6220],
        [-1.2647, -0.8539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053600698709488
Epoch 0, Step 796: train/loss = 0.5240381956100464, train/raw-loss = 0.50449538230896, train/logprobs = tensor([[-0.6680, -1.4594],
        [-0.9344, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19542796909809113
Epoch 0, Step 797: train/loss = 0.5683191418647766, train/raw-loss = 0.5493881702423096, train/logprobs = tensor([[-0.5354, -3.8110],
        [-1.1169, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18930956721305847
Epoch 0, Step 798: train/loss = 0.5198956727981567, train/raw-loss = 0.4975549876689911, train/logprobs = tensor([[-0.8331, -2.3979],
        [-1.1554, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22340700030326843
Epoch 0, Step 799: train/loss = 0.48256227374076843, train/raw-loss = 0.46460258960723877, train/logprobs = tensor([[-0.7265, -1.7581],
        [-0.9488, -0.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179596945643425
Epoch 0, Step 800: train/loss = 0.40509000420570374, train/raw-loss = 0.38709941506385803, train/logprobs = tensor([[-0.6328, -3.3249],
        [-0.8887, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799057126045227
Epoch 0, Step 801: train/loss = 0.6287301182746887, train/raw-loss = 0.6067232489585876, train/logprobs = tensor([[-0.7422, -1.2709],
        [-1.2224, -1.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200690656900406
Epoch 0, Step 802: train/loss = 0.45877474546432495, train/raw-loss = 0.4375312626361847, train/logprobs = tensor([[-0.6076, -2.2203],
        [-1.0498, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21243499219417572
Epoch 0, Step 803: train/loss = 0.4936690330505371, train/raw-loss = 0.4737069010734558, train/logprobs = tensor([[-0.6962, -1.9215],
        [-1.0570, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996208131313324
Epoch 0, Step 804: train/loss = 0.39509665966033936, train/raw-loss = 0.37634584307670593, train/logprobs = tensor([[-0.9542, -4.5623],
        [-0.9385, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1875082403421402
Epoch 0, Step 805: train/loss = 0.4985171854496002, train/raw-loss = 0.4763219356536865, train/logprobs = tensor([[-0.9777, -2.3093],
        [-1.0984, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22195212543010712
Epoch 0, Step 806: train/loss = 0.5224044322967529, train/raw-loss = 0.5034462213516235, train/logprobs = tensor([[-0.6819, -2.8797],
        [-0.9472, -0.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18958231806755066
Epoch 0, Step 807: train/loss = 0.5328879356384277, train/raw-loss = 0.5123573541641235, train/logprobs = tensor([[-0.6760, -1.6541],
        [-0.9132, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053060233592987
Epoch 0, Step 808: train/loss = 0.5288746953010559, train/raw-loss = 0.5097384452819824, train/logprobs = tensor([[-0.4979, -1.6014],
        [-0.8540, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19136252999305725
Epoch 0, Step 809: train/loss = 0.6235670447349548, train/raw-loss = 0.6014728546142578, train/logprobs = tensor([[-0.7355, -1.1716],
        [-0.7397, -0.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22094202041625977
Epoch 0, Step 810: train/loss = 0.4697824716567993, train/raw-loss = 0.44866156578063965, train/logprobs = tensor([[-0.8266, -2.9653],
        [-1.0045, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21120911836624146
Epoch 0, Step 811: train/loss = 0.6259158849716187, train/raw-loss = 0.6085423231124878, train/logprobs = tensor([[-0.6332, -1.2213],
        [-0.7672, -0.9861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737356185913086
Epoch 0, Step 812: train/loss = 0.5857359766960144, train/raw-loss = 0.5643292665481567, train/logprobs = tensor([[-0.5450, -0.9669],
        [-1.0855, -0.7976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21406756341457367
Epoch 0, Step 813: train/loss = 0.3732340931892395, train/raw-loss = 0.35353049635887146, train/logprobs = tensor([[-0.9768, -4.9478],
        [-1.2441, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1970357745885849
Epoch 0, Step 814: train/loss = 0.4850904643535614, train/raw-loss = 0.46040529012680054, train/logprobs = tensor([[-0.8345, -2.7743],
        [-1.3857, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468518316745758
Epoch 0, Step 815: train/loss = 0.3729422688484192, train/raw-loss = 0.3533403277397156, train/logprobs = tensor([[-0.7384, -3.3182],
        [-1.0132, -1.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19601963460445404
Epoch 0, Step 816: train/loss = 0.7080422639846802, train/raw-loss = 0.6870207786560059, train/logprobs = tensor([[-1.6160, -1.6675],
        [-1.0208, -0.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21021512150764465
Epoch 0, Step 817: train/loss = 0.5310825109481812, train/raw-loss = 0.509164035320282, train/logprobs = tensor([[-0.6215, -2.6483],
        [-0.9909, -0.6939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21918506920337677
Epoch 0, Step 818: train/loss = 0.6369180083274841, train/raw-loss = 0.6127170920372009, train/logprobs = tensor([[-1.1497, -1.4605],
        [-1.0224, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.242008775472641
Epoch 0, Step 819: train/loss = 0.6187960505485535, train/raw-loss = 0.5985844135284424, train/logprobs = tensor([[-0.9047, -1.3387],
        [-0.7465, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021164745092392
Epoch 0, Step 820: train/loss = 0.6106514930725098, train/raw-loss = 0.590015172958374, train/logprobs = tensor([[-0.6178, -1.4803],
        [-0.8074, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20636379718780518
Epoch 0, Step 821: train/loss = 0.256860613822937, train/raw-loss = 0.23201066255569458, train/logprobs = tensor([[-0.7841, -3.9959],
        [-1.7787, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24849916994571686
Epoch 0, Step 822: train/loss = 0.4270268976688385, train/raw-loss = 0.4064084589481354, train/logprobs = tensor([[-1.2848, -4.1961],
        [-1.2057, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20618495345115662
Epoch 0, Step 823: train/loss = 0.6112039685249329, train/raw-loss = 0.593155026435852, train/logprobs = tensor([[-0.5895, -1.0783],
        [-0.6444, -0.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18048922717571259
Epoch 0, Step 824: train/loss = 0.4787266254425049, train/raw-loss = 0.45767027139663696, train/logprobs = tensor([[-0.8663, -2.2387],
        [-0.9172, -0.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2105633169412613
Epoch 0, Step 825: train/loss = 0.414870947599411, train/raw-loss = 0.39534950256347656, train/logprobs = tensor([[-0.6149, -4.9877],
        [-1.2420, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1952146589756012
Epoch 0, Step 826: train/loss = 0.7666158080101013, train/raw-loss = 0.7463473081588745, train/logprobs = tensor([[-1.9676, -2.4824],
        [-1.1076, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20268523693084717
Epoch 0, Step 827: train/loss = 0.6046944260597229, train/raw-loss = 0.5855938196182251, train/logprobs = tensor([[-0.5983, -1.3762],
        [-0.8303, -1.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191005676984787
Epoch 0, Step 828: train/loss = 0.625542938709259, train/raw-loss = 0.6006491184234619, train/logprobs = tensor([[-0.8964, -1.6822],
        [-0.9750, -0.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489386945962906
Epoch 0, Step 829: train/loss = 0.48580724000930786, train/raw-loss = 0.46698591113090515, train/logprobs = tensor([[-0.9668, -2.1903],
        [-0.9380, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188213050365448
Epoch 0, Step 830: train/loss = 0.6475986242294312, train/raw-loss = 0.6257021427154541, train/logprobs = tensor([[-0.7629, -1.0454],
        [-0.8801, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21896445751190186
Epoch 0, Step 831: train/loss = 0.6851503849029541, train/raw-loss = 0.665026068687439, train/logprobs = tensor([[-0.6772, -0.8483],
        [-0.8713, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20124341547489166
Epoch 0, Step 832: train/loss = 0.4117897152900696, train/raw-loss = 0.38922345638275146, train/logprobs = tensor([[-0.6956, -2.8730],
        [-1.0170, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22566264867782593
Epoch 0, Step 833: train/loss = 0.7760826349258423, train/raw-loss = 0.7557748556137085, train/logprobs = tensor([[-1.2749, -1.2350],
        [-0.7859, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20307788252830505
Epoch 0, Step 834: train/loss = 0.5405462980270386, train/raw-loss = 0.5208079218864441, train/logprobs = tensor([[-0.9114, -2.8196],
        [-0.7908, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738346338272095
Epoch 0, Step 835: train/loss = 0.6731862425804138, train/raw-loss = 0.6497377157211304, train/logprobs = tensor([[-0.9240, -1.0075],
        [-1.0896, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23448461294174194
Epoch 0, Step 836: train/loss = 0.5348115563392639, train/raw-loss = 0.5136061906814575, train/logprobs = tensor([[-0.4999, -1.4030],
        [-1.0298, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21205338835716248
Epoch 0, Step 837: train/loss = 0.4752810597419739, train/raw-loss = 0.4550105035305023, train/logprobs = tensor([[-0.6039, -3.6668],
        [-0.9232, -0.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20270556211471558
Epoch 0, Step 838: train/loss = 0.6170237064361572, train/raw-loss = 0.5957797765731812, train/logprobs = tensor([[-1.1127, -2.2782],
        [-1.0653, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21243958175182343
Epoch 0, Step 839: train/loss = 0.6228864192962646, train/raw-loss = 0.5998402237892151, train/logprobs = tensor([[-1.0648, -1.6868],
        [-0.8351, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23046226799488068
Epoch 0, Step 840: train/loss = 0.6576822400093079, train/raw-loss = 0.6342759132385254, train/logprobs = tensor([[-0.7557, -1.1529],
        [-0.9150, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2340630739927292
Epoch 0, Step 841: train/loss = 0.7761620283126831, train/raw-loss = 0.7518420219421387, train/logprobs = tensor([[-2.5218, -2.8670],
        [-1.5639, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2432001829147339
Epoch 0, Step 842: train/loss = 0.49066779017448425, train/raw-loss = 0.46786782145500183, train/logprobs = tensor([[-1.1969, -4.8189],
        [-1.4743, -0.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22799992561340332
Epoch 0, Step 843: train/loss = 0.4113004207611084, train/raw-loss = 0.3860914409160614, train/logprobs = tensor([[-0.8535, -2.7908],
        [-1.2947, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25208985805511475
Epoch 0, Step 844: train/loss = 0.3484339714050293, train/raw-loss = 0.325713574886322, train/logprobs = tensor([[-1.0501, -2.8751],
        [-1.6458, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2272038459777832
Epoch 0, Step 845: train/loss = 0.39388418197631836, train/raw-loss = 0.37362056970596313, train/logprobs = tensor([[-0.7717, -3.2240],
        [-1.1515, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263591408729553
Epoch 0, Step 846: train/loss = 0.47068801522254944, train/raw-loss = 0.44671523571014404, train/logprobs = tensor([[-0.5119, -2.1335],
        [-1.0138, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23972752690315247
Epoch 0, Step 847: train/loss = 0.4451902508735657, train/raw-loss = 0.42146241664886475, train/logprobs = tensor([[-1.1169, -3.2994],
        [-1.1345, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23727849125862122
Epoch 0, Step 848: train/loss = 0.5153453350067139, train/raw-loss = 0.49327152967453003, train/logprobs = tensor([[-0.6409, -1.2545],
        [-1.1455, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22073806822299957
Epoch 0, Step 849: train/loss = 0.49939870834350586, train/raw-loss = 0.4741475582122803, train/logprobs = tensor([[-0.9968, -2.8139],
        [-1.1333, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252511590719223
Epoch 0, Step 850: train/loss = 0.5821545124053955, train/raw-loss = 0.5621044039726257, train/logprobs = tensor([[-0.8656, -1.4400],
        [-0.8765, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2005011886358261
Epoch 0, Step 851: train/loss = 0.4074365496635437, train/raw-loss = 0.38704898953437805, train/logprobs = tensor([[-0.7115, -2.5644],
        [-1.2093, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20387564599514008
Epoch 0, Step 852: train/loss = 0.5426645874977112, train/raw-loss = 0.5189387202262878, train/logprobs = tensor([[-0.6778, -1.6861],
        [-1.1616, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23725834488868713
Epoch 0, Step 853: train/loss = 0.43578988313674927, train/raw-loss = 0.4160105288028717, train/logprobs = tensor([[-0.6279, -3.1748],
        [-0.6490, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977933645248413
Epoch 0, Step 854: train/loss = 0.4186941087245941, train/raw-loss = 0.3972397446632385, train/logprobs = tensor([[-0.6732, -2.2301],
        [-1.0353, -0.6286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145436704158783
Epoch 0, Step 855: train/loss = 0.6070353984832764, train/raw-loss = 0.5886700749397278, train/logprobs = tensor([[-0.5334, -1.0706],
        [-0.6041, -0.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1836535483598709
Epoch 0, Step 856: train/loss = 0.6398860812187195, train/raw-loss = 0.6186617016792297, train/logprobs = tensor([[-0.6462, -0.8479],
        [-0.8257, -0.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122437059879303
Epoch 0, Step 857: train/loss = 0.5994949340820312, train/raw-loss = 0.5794285535812378, train/logprobs = tensor([[-0.7674, -1.3197],
        [-0.7186, -0.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200664222240448
Epoch 0, Step 858: train/loss = 0.6226593255996704, train/raw-loss = 0.6057623028755188, train/logprobs = tensor([[-0.3429, -0.8664],
        [-0.4921, -0.6273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16896960139274597
Epoch 0, Step 859: train/loss = 0.3628309369087219, train/raw-loss = 0.33722418546676636, train/logprobs = tensor([[-1.0684, -4.0265],
        [-1.4407, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25606775283813477
Epoch 0, Step 860: train/loss = 0.5779870748519897, train/raw-loss = 0.5572656989097595, train/logprobs = tensor([[-0.6315, -1.5912],
        [-0.9260, -1.1761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20721346139907837
Epoch 0, Step 861: train/loss = 0.38025224208831787, train/raw-loss = 0.3565557897090912, train/logprobs = tensor([[-1.0380, -5.0233],
        [-1.3592, -0.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23696449398994446
Epoch 0, Step 862: train/loss = 0.49349135160446167, train/raw-loss = 0.4729618430137634, train/logprobs = tensor([[-0.7958, -2.3755],
        [-0.9581, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052951455116272
Epoch 0, Step 863: train/loss = 0.5435518026351929, train/raw-loss = 0.5218152403831482, train/logprobs = tensor([[-0.5910, -1.9238],
        [-0.9510, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21736526489257812
Epoch 0, Step 864: train/loss = 0.4449547529220581, train/raw-loss = 0.4269651174545288, train/logprobs = tensor([[-0.5824, -2.4952],
        [-0.8476, -0.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17989662289619446
Epoch 0, Step 865: train/loss = 0.4904460608959198, train/raw-loss = 0.46581754088401794, train/logprobs = tensor([[-1.0051, -3.0201],
        [-1.1646, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24628517031669617
Epoch 0, Step 866: train/loss = 0.6698044538497925, train/raw-loss = 0.6474953889846802, train/logprobs = tensor([[-1.6473, -3.1374],
        [-0.8082, -0.5899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22309058904647827
Epoch 0, Step 867: train/loss = 0.4026496410369873, train/raw-loss = 0.38387012481689453, train/logprobs = tensor([[-0.6980, -4.0281],
        [-0.8271, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18779535591602325
Epoch 0, Step 868: train/loss = 0.5224478244781494, train/raw-loss = 0.5018519163131714, train/logprobs = tensor([[-0.8953, -2.8066],
        [-0.9213, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20595932006835938
Epoch 0, Step 869: train/loss = 0.3264704644680023, train/raw-loss = 0.3050762712955475, train/logprobs = tensor([[-0.7635, -4.4275],
        [-1.4682, -0.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21394199132919312
Epoch 0, Step 870: train/loss = 0.5146090984344482, train/raw-loss = 0.49029093980789185, train/logprobs = tensor([[-0.5899, -1.5738],
        [-0.9866, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24318191409111023
Epoch 0, Step 871: train/loss = 0.4697054326534271, train/raw-loss = 0.45234814286231995, train/logprobs = tensor([[-0.5417, -2.8476],
        [-0.7209, -0.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17357276380062103
Epoch 0, Step 872: train/loss = 0.6144449710845947, train/raw-loss = 0.5952003002166748, train/logprobs = tensor([[-0.5248, -1.1072],
        [-0.7147, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19244684278964996
Epoch 0, Step 873: train/loss = 0.6132930517196655, train/raw-loss = 0.5908493995666504, train/logprobs = tensor([[-1.3352, -2.7779],
        [-1.0686, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22443678975105286
Epoch 0, Step 874: train/loss = 0.543290376663208, train/raw-loss = 0.5202924013137817, train/logprobs = tensor([[-0.8479, -1.7061],
        [-0.9004, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2299794852733612
Epoch 0, Step 875: train/loss = 0.3974713385105133, train/raw-loss = 0.38109004497528076, train/logprobs = tensor([[-0.7641, -4.3569],
        [-0.7057, -0.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16381290555000305
Epoch 0, Step 876: train/loss = 0.29747965931892395, train/raw-loss = 0.2763633728027344, train/logprobs = tensor([[-1.0096, -4.1879],
        [-1.2969, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2111627161502838
Epoch 0, Step 877: train/loss = 0.5398079752922058, train/raw-loss = 0.5185734629631042, train/logprobs = tensor([[-1.0643, -3.1672],
        [-0.9242, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21234485507011414
Epoch 0, Step 878: train/loss = 0.5433517694473267, train/raw-loss = 0.5241368412971497, train/logprobs = tensor([[-0.8639, -2.3171],
        [-1.1132, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19214902818202972
Epoch 0, Step 879: train/loss = 0.4236239790916443, train/raw-loss = 0.401459276676178, train/logprobs = tensor([[-0.6611, -2.1355],
        [-1.1247, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22164681553840637
Epoch 0, Step 880: train/loss = 0.441800057888031, train/raw-loss = 0.4194459915161133, train/logprobs = tensor([[-0.9026, -3.2877],
        [-1.4144, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235405594110489
Epoch 0, Step 881: train/loss = 0.41916579008102417, train/raw-loss = 0.3947005569934845, train/logprobs = tensor([[-0.9223, -2.1799],
        [-1.3120, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24465259909629822
Epoch 0, Step 882: train/loss = 0.45861807465553284, train/raw-loss = 0.435871422290802, train/logprobs = tensor([[-0.9348, -3.5624],
        [-1.0080, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22746632993221283
Epoch 0, Step 883: train/loss = 0.7064505815505981, train/raw-loss = 0.6836879849433899, train/logprobs = tensor([[-0.8709, -1.0877],
        [-0.8654, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22762611508369446
Epoch 0, Step 884: train/loss = 0.4233015775680542, train/raw-loss = 0.40207594633102417, train/logprobs = tensor([[-0.6935, -2.8223],
        [-1.0029, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122565656900406
Epoch 0, Step 885: train/loss = 0.5934620499610901, train/raw-loss = 0.5727762579917908, train/logprobs = tensor([[-0.6265, -1.3670],
        [-0.7020, -0.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2068580538034439
Epoch 0, Step 886: train/loss = 0.5757945775985718, train/raw-loss = 0.5525504350662231, train/logprobs = tensor([[-1.0473, -1.8399],
        [-1.5873, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23244228959083557
Epoch 0, Step 887: train/loss = 0.859167754650116, train/raw-loss = 0.8391814827919006, train/logprobs = tensor([[-2.2975, -1.9145],
        [-1.2567, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1998627781867981
Epoch 0, Step 888: train/loss = 0.3926580846309662, train/raw-loss = 0.368259459733963, train/logprobs = tensor([[-0.9627, -3.6051],
        [-1.4604, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24398645758628845
Epoch 0, Step 889: train/loss = 0.4161340594291687, train/raw-loss = 0.39172762632369995, train/logprobs = tensor([[-0.9784, -3.5323],
        [-1.1296, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440641224384308
Epoch 0, Step 890: train/loss = 0.547175943851471, train/raw-loss = 0.5238329768180847, train/logprobs = tensor([[-0.9044, -2.3342],
        [-1.2253, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2334301471710205
Epoch 0, Step 891: train/loss = 0.6489761471748352, train/raw-loss = 0.6273705363273621, train/logprobs = tensor([[-1.1080, -3.1173],
        [-0.7579, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21605627238750458
Epoch 0, Step 892: train/loss = 0.5591213703155518, train/raw-loss = 0.5368443131446838, train/logprobs = tensor([[-0.7335, -2.7667],
        [-1.0033, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22277075052261353
Epoch 0, Step 893: train/loss = 0.5290590524673462, train/raw-loss = 0.5067496299743652, train/logprobs = tensor([[-0.5578, -1.5004],
        [-0.9606, -1.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2230941653251648
Epoch 0, Step 894: train/loss = 0.47894781827926636, train/raw-loss = 0.4519307613372803, train/logprobs = tensor([[-0.9498, -3.2383],
        [-1.2089, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2701706886291504
Epoch 0, Step 895: train/loss = 0.48551756143569946, train/raw-loss = 0.46208545565605164, train/logprobs = tensor([[-0.6648, -2.7153],
        [-0.8333, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2343210130929947
Epoch 0, Step 896: train/loss = 0.4356774091720581, train/raw-loss = 0.4127908945083618, train/logprobs = tensor([[-0.7776, -4.0637],
        [-1.0348, -0.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22886517643928528
Epoch 0, Step 897: train/loss = 0.4404842257499695, train/raw-loss = 0.4195307493209839, train/logprobs = tensor([[-0.7882, -2.7095],
        [-1.3564, -0.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095348834991455
Epoch 0, Step 898: train/loss = 0.5628565549850464, train/raw-loss = 0.543054461479187, train/logprobs = tensor([[-0.5640, -1.6413],
        [-0.7260, -0.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19802042841911316
Epoch 0, Step 899: train/loss = 0.498678982257843, train/raw-loss = 0.4770837128162384, train/logprobs = tensor([[-0.8666, -2.8736],
        [-0.9606, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21595266461372375
Epoch 0, Step 900: train/loss = 0.5605345964431763, train/raw-loss = 0.5391733646392822, train/logprobs = tensor([[-0.7332, -2.0091],
        [-0.8464, -0.7555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136123776435852
Epoch 0, Step 901: train/loss = 0.5188963413238525, train/raw-loss = 0.49539899826049805, train/logprobs = tensor([[-1.0449, -2.3224],
        [-1.0502, -0.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23497334122657776
Epoch 0, Step 902: train/loss = 0.595501184463501, train/raw-loss = 0.5763901472091675, train/logprobs = tensor([[-1.1849, -2.1085],
        [-1.0550, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19111017882823944
Epoch 0, Step 903: train/loss = 0.5962584614753723, train/raw-loss = 0.5744021534919739, train/logprobs = tensor([[-1.2829, -1.9108],
        [-1.0310, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.218563050031662
Epoch 0, Step 904: train/loss = 0.5300790667533875, train/raw-loss = 0.507469654083252, train/logprobs = tensor([[-0.5648, -1.7363],
        [-0.8298, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22609366476535797
Epoch 0, Step 905: train/loss = 0.5978994369506836, train/raw-loss = 0.5755101442337036, train/logprobs = tensor([[-0.9750, -1.7164],
        [-0.9831, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22389312088489532
Epoch 0, Step 906: train/loss = 0.46006980538368225, train/raw-loss = 0.4360201060771942, train/logprobs = tensor([[-1.1691, -4.6605],
        [-1.2934, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24049730598926544
Epoch 0, Step 907: train/loss = 0.49715739488601685, train/raw-loss = 0.47512000799179077, train/logprobs = tensor([[-0.9981, -2.1795],
        [-1.2195, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22037360072135925
Epoch 0, Step 908: train/loss = 0.5190221667289734, train/raw-loss = 0.4972284138202667, train/logprobs = tensor([[-0.9043, -2.7107],
        [-0.8936, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21793749928474426
Epoch 0, Step 909: train/loss = 0.6547392010688782, train/raw-loss = 0.6336519122123718, train/logprobs = tensor([[-0.7428, -0.9632],
        [-0.7456, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21087336540222168
Epoch 0, Step 910: train/loss = 0.46542853116989136, train/raw-loss = 0.43921706080436707, train/logprobs = tensor([[-1.1066, -2.7995],
        [-1.1379, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26211509108543396
Epoch 0, Step 911: train/loss = 0.6075686812400818, train/raw-loss = 0.5840557813644409, train/logprobs = tensor([[-1.1604, -3.3881],
        [-0.9851, -0.7157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23512911796569824
Epoch 0, Step 912: train/loss = 0.48492634296417236, train/raw-loss = 0.4648013710975647, train/logprobs = tensor([[-1.0110, -2.1103],
        [-1.1322, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2012500911951065
Epoch 0, Step 913: train/loss = 0.43827390670776367, train/raw-loss = 0.41924959421157837, train/logprobs = tensor([[-0.9157, -3.3777],
        [-1.2028, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19024287164211273
Epoch 0, Step 914: train/loss = 0.5384681820869446, train/raw-loss = 0.5160064697265625, train/logprobs = tensor([[-1.0860, -2.6733],
        [-0.9381, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22461684048175812
Epoch 0, Step 915: train/loss = 0.3548816740512848, train/raw-loss = 0.328544020652771, train/logprobs = tensor([[-0.9966, -3.1365],
        [-1.2546, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633766233921051
Epoch 0, Step 916: train/loss = 0.4907468557357788, train/raw-loss = 0.46833571791648865, train/logprobs = tensor([[-1.3254, -1.8087],
        [-1.6358, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22411149740219116
Epoch 0, Step 917: train/loss = 0.5339082479476929, train/raw-loss = 0.5084371566772461, train/logprobs = tensor([[-0.8827, -2.6573],
        [-1.0552, -0.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547106146812439
Epoch 0, Step 918: train/loss = 0.5165954828262329, train/raw-loss = 0.496066689491272, train/logprobs = tensor([[-0.8491, -2.7261],
        [-0.7553, -0.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052876353263855
Epoch 0, Step 919: train/loss = 0.6280688047409058, train/raw-loss = 0.6068595051765442, train/logprobs = tensor([[-0.9217, -1.4400],
        [-0.7992, -0.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2120932936668396
Epoch 0, Step 920: train/loss = 0.4502103924751282, train/raw-loss = 0.4297868609428406, train/logprobs = tensor([[-0.5723, -1.9890],
        [-1.0379, -0.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042352259159088
Epoch 0, Step 921: train/loss = 0.6638863682746887, train/raw-loss = 0.6395750045776367, train/logprobs = tensor([[-1.0628, -1.2609],
        [-0.7692, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24311350286006927
Epoch 0, Step 922: train/loss = 0.5975465178489685, train/raw-loss = 0.5729559659957886, train/logprobs = tensor([[-1.0597, -2.9364],
        [-0.9310, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24590614438056946
Epoch 0, Step 923: train/loss = 0.4816422462463379, train/raw-loss = 0.4610891342163086, train/logprobs = tensor([[-0.7321, -2.0729],
        [-0.9516, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2055313140153885
Epoch 0, Step 924: train/loss = 0.4081272482872009, train/raw-loss = 0.38272228837013245, train/logprobs = tensor([[-1.4018, -5.3753],
        [-1.4540, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25404930114746094
Epoch 0, Step 925: train/loss = 0.4619999825954437, train/raw-loss = 0.4377463459968567, train/logprobs = tensor([[-0.9165, -2.6877],
        [-1.2513, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2425362765789032
Epoch 0, Step 926: train/loss = 0.5615832209587097, train/raw-loss = 0.5404396653175354, train/logprobs = tensor([[-0.9297, -1.8099],
        [-0.9537, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21143558621406555
Epoch 0, Step 927: train/loss = 0.41853970289230347, train/raw-loss = 0.39612263441085815, train/logprobs = tensor([[-0.8324, -3.0272],
        [-0.9951, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22417084872722626
Epoch 0, Step 928: train/loss = 0.3892209827899933, train/raw-loss = 0.3640289902687073, train/logprobs = tensor([[-0.8348, -2.6693],
        [-1.4329, -0.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519194781780243
Epoch 0, Step 929: train/loss = 0.5184681415557861, train/raw-loss = 0.49462005496025085, train/logprobs = tensor([[-0.6936, -2.0029],
        [-0.9198, -0.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23848146200180054
Epoch 0, Step 930: train/loss = 0.48880535364151, train/raw-loss = 0.466415137052536, train/logprobs = tensor([[-1.0097, -2.4046],
        [-1.0001, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22390222549438477
Epoch 0, Step 931: train/loss = 0.478577584028244, train/raw-loss = 0.45680099725723267, train/logprobs = tensor([[-0.7228, -2.3790],
        [-0.9415, -0.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21776582300662994
Epoch 0, Step 932: train/loss = 0.4815097153186798, train/raw-loss = 0.4600507318973541, train/logprobs = tensor([[-0.7069, -4.7078],
        [-0.7775, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145899534225464
Epoch 0, Step 933: train/loss = 0.5006519556045532, train/raw-loss = 0.4777112603187561, train/logprobs = tensor([[-1.0089, -2.0633],
        [-1.1256, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22940684854984283
Epoch 0, Step 934: train/loss = 0.505277156829834, train/raw-loss = 0.48000070452690125, train/logprobs = tensor([[-1.1263, -3.3578],
        [-1.2946, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527647912502289
Epoch 0, Step 935: train/loss = 0.5134701728820801, train/raw-loss = 0.49223339557647705, train/logprobs = tensor([[-0.8203, -4.5149],
        [-0.8672, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21236781775951385
Epoch 0, Step 936: train/loss = 0.473538875579834, train/raw-loss = 0.4506897032260895, train/logprobs = tensor([[-0.7569, -2.7415],
        [-1.0250, -0.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.228491872549057
Epoch 0, Step 937: train/loss = 0.5195662975311279, train/raw-loss = 0.496134877204895, train/logprobs = tensor([[-1.4965, -3.1472],
        [-1.2010, -0.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23431465029716492
Epoch 0, Step 938: train/loss = 0.6198968887329102, train/raw-loss = 0.594912588596344, train/logprobs = tensor([[-1.2415, -2.1169],
        [-1.0168, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24984320998191833
Epoch 0, Step 939: train/loss = 0.5609608888626099, train/raw-loss = 0.5347731113433838, train/logprobs = tensor([[-1.1107, -1.8355],
        [-1.1153, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26187828183174133
Epoch 0, Step 940: train/loss = 0.3761330246925354, train/raw-loss = 0.35203665494918823, train/logprobs = tensor([[-0.9830, -4.0236],
        [-1.2181, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24096396565437317
Epoch 0, Step 941: train/loss = 0.3857998251914978, train/raw-loss = 0.359904408454895, train/logprobs = tensor([[-0.8105, -2.6747],
        [-1.3399, -0.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25895410776138306
Epoch 0, Step 942: train/loss = 0.3471967279911041, train/raw-loss = 0.3222408890724182, train/logprobs = tensor([[-0.9149, -4.5825],
        [-1.2167, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2495584636926651
Epoch 0, Step 943: train/loss = 0.5126780271530151, train/raw-loss = 0.48710817098617554, train/logprobs = tensor([[-1.2170, -2.0697],
        [-1.1917, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25569841265678406
Epoch 0, Step 944: train/loss = 0.35244908928871155, train/raw-loss = 0.3274451494216919, train/logprobs = tensor([[-1.1241, -5.5890],
        [-1.2985, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500396966934204
Epoch 0, Step 945: train/loss = 0.3733024001121521, train/raw-loss = 0.3494178354740143, train/logprobs = tensor([[-0.8212, -6.1772],
        [-1.1495, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23884522914886475
Epoch 0, Step 946: train/loss = 0.6331055164337158, train/raw-loss = 0.6066731810569763, train/logprobs = tensor([[-1.3489, -1.6777],
        [-1.1689, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26432356238365173
Epoch 0, Step 947: train/loss = 0.49517518281936646, train/raw-loss = 0.4712444543838501, train/logprobs = tensor([[-0.9424, -2.9304],
        [-0.8513, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2393074929714203
Epoch 0, Step 948: train/loss = 0.32646721601486206, train/raw-loss = 0.3039461374282837, train/logprobs = tensor([[-0.7029, -7.5027],
        [-1.1265, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22521069645881653
Epoch 0, Step 949: train/loss = 0.47831159830093384, train/raw-loss = 0.4542132616043091, train/logprobs = tensor([[-0.7428, -2.1272],
        [-1.1017, -0.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24098339676856995
Epoch 0, Step 950: train/loss = 0.41154253482818604, train/raw-loss = 0.38901978731155396, train/logprobs = tensor([[-0.8544, -3.9162],
        [-1.1365, -0.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22522759437561035
Epoch 0, Step 951: train/loss = 0.5684429407119751, train/raw-loss = 0.5459319353103638, train/logprobs = tensor([[-0.9950, -1.9090],
        [-1.0963, -0.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2251105010509491
Epoch 0, Step 952: train/loss = 0.3352680206298828, train/raw-loss = 0.31500452756881714, train/logprobs = tensor([[-0.9729, -9.9470],
        [-1.5245, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263506472110748
Epoch 0, Step 953: train/loss = 0.45340365171432495, train/raw-loss = 0.42600181698799133, train/logprobs = tensor([[-1.4707, -4.0701],
        [-1.4304, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740182876586914
Epoch 0, Step 954: train/loss = 0.5168207883834839, train/raw-loss = 0.49202483892440796, train/logprobs = tensor([[-0.6592, -3.7458],
        [-0.7842, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24795904755592346
Epoch 0, Step 955: train/loss = 0.5681049823760986, train/raw-loss = 0.5486544370651245, train/logprobs = tensor([[-0.6146, -2.7356],
        [-0.6723, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1945047676563263
Epoch 0, Step 956: train/loss = 0.6318642497062683, train/raw-loss = 0.6095113754272461, train/logprobs = tensor([[-0.8933, -0.8161],
        [-1.1330, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235293686389923
Epoch 0, Step 957: train/loss = 0.6589287519454956, train/raw-loss = 0.6413712501525879, train/logprobs = tensor([[-0.5275, -0.5886],
        [-0.5543, -0.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1755754053592682
Epoch 0, Step 958: train/loss = 0.4539754390716553, train/raw-loss = 0.4317791163921356, train/logprobs = tensor([[-0.9704, -2.7538],
        [-1.2719, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22196345031261444
Epoch 0, Step 959: train/loss = 0.7119015455245972, train/raw-loss = 0.6927837133407593, train/logprobs = tensor([[-0.7665, -1.1157],
        [-0.6948, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19117790460586548
Epoch 0, Step 960: train/loss = 0.3503440320491791, train/raw-loss = 0.3235531151294708, train/logprobs = tensor([[-0.8791, -3.7649],
        [-1.2515, -0.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679089605808258
Epoch 0, Step 961: train/loss = 0.5356483459472656, train/raw-loss = 0.515084981918335, train/logprobs = tensor([[-0.7420, -1.8384],
        [-0.8796, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20563378930091858
Epoch 0, Step 962: train/loss = 0.5288475751876831, train/raw-loss = 0.5103670358657837, train/logprobs = tensor([[-1.0975, -2.5108],
        [-0.8676, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18480481207370758
Epoch 0, Step 963: train/loss = 0.5306984186172485, train/raw-loss = 0.5111874938011169, train/logprobs = tensor([[-0.6215, -4.1809],
        [-0.8993, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19510895013809204
Epoch 0, Step 964: train/loss = 0.5821254253387451, train/raw-loss = 0.5602490901947021, train/logprobs = tensor([[-0.7909, -1.6510],
        [-0.6784, -0.5935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21876251697540283
Epoch 0, Step 965: train/loss = 0.4575974941253662, train/raw-loss = 0.43613338470458984, train/logprobs = tensor([[-0.8386, -3.2751],
        [-0.8653, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21464130282402039
Epoch 0, Step 966: train/loss = 0.7284283638000488, train/raw-loss = 0.7018994092941284, train/logprobs = tensor([[-1.8816, -2.3706],
        [-0.9108, -0.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652896046638489
Epoch 0, Step 967: train/loss = 0.5816707611083984, train/raw-loss = 0.5597074031829834, train/logprobs = tensor([[-0.8785, -1.7082],
        [-0.7392, -0.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21963298320770264
Epoch 0, Step 968: train/loss = 0.5776107311248779, train/raw-loss = 0.5565642714500427, train/logprobs = tensor([[-0.6781, -1.5511],
        [-0.8985, -0.8116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21046441793441772
Epoch 0, Step 969: train/loss = 0.6175587177276611, train/raw-loss = 0.5944706797599792, train/logprobs = tensor([[-0.8375, -1.0827],
        [-0.9547, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23087991774082184
Epoch 0, Step 970: train/loss = 0.5471696257591248, train/raw-loss = 0.5203661918640137, train/logprobs = tensor([[-1.8695, -3.9894],
        [-1.1861, -0.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26803386211395264
Epoch 0, Step 971: train/loss = 0.5195637941360474, train/raw-loss = 0.4946513772010803, train/logprobs = tensor([[-1.1482, -2.9372],
        [-1.0986, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24912431836128235
Epoch 0, Step 972: train/loss = 0.33631473779678345, train/raw-loss = 0.3132464289665222, train/logprobs = tensor([[-0.8350, -4.9695],
        [-1.0064, -1.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2306833118200302
Epoch 0, Step 973: train/loss = 0.4589964747428894, train/raw-loss = 0.4351713955402374, train/logprobs = tensor([[-1.0837, -3.5781],
        [-0.9865, -0.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23825089633464813
Epoch 0, Step 974: train/loss = 0.3935896158218384, train/raw-loss = 0.3658536672592163, train/logprobs = tensor([[-1.4171, -3.5047],
        [-1.5849, -0.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27735984325408936
Epoch 0, Step 975: train/loss = 0.48123806715011597, train/raw-loss = 0.45507240295410156, train/logprobs = tensor([[-1.2854, -3.1588],
        [-1.2533, -1.0315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26165667176246643
Epoch 0, Step 976: train/loss = 0.4378303289413452, train/raw-loss = 0.4164201617240906, train/logprobs = tensor([[-1.6515, -4.1413],
        [-1.3805, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21410183608531952
Epoch 0, Step 977: train/loss = 0.6197206974029541, train/raw-loss = 0.5983731150627136, train/logprobs = tensor([[-0.5365, -1.0458],
        [-0.6344, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21347609162330627
Epoch 0, Step 978: train/loss = 0.5654315948486328, train/raw-loss = 0.5415621995925903, train/logprobs = tensor([[-0.9474, -1.7978],
        [-0.8843, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23869337141513824
Epoch 0, Step 979: train/loss = 0.5005549788475037, train/raw-loss = 0.47702720761299133, train/logprobs = tensor([[-1.2953, -2.7545],
        [-1.1028, -0.5319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352774292230606
Epoch 0, Step 980: train/loss = 0.7692122459411621, train/raw-loss = 0.7441920042037964, train/logprobs = tensor([[-2.2944, -2.8841],
        [-1.4303, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502021789550781
Epoch 0, Step 981: train/loss = 0.4378533363342285, train/raw-loss = 0.40893155336380005, train/logprobs = tensor([[-1.0967, -2.1173],
        [-1.5473, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28921812772750854
Epoch 0, Step 982: train/loss = 0.4901565909385681, train/raw-loss = 0.4684228301048279, train/logprobs = tensor([[-1.3313, -4.7839],
        [-0.7740, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21733789145946503
Epoch 0, Step 983: train/loss = 0.5655370354652405, train/raw-loss = 0.5404779314994812, train/logprobs = tensor([[-1.1308, -1.8597],
        [-1.0274, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505905032157898
Epoch 0, Step 984: train/loss = 0.4712120294570923, train/raw-loss = 0.44350099563598633, train/logprobs = tensor([[-1.5250, -4.7530],
        [-1.4578, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27711039781570435
Epoch 0, Step 985: train/loss = 0.5125117897987366, train/raw-loss = 0.4883688688278198, train/logprobs = tensor([[-0.9012, -2.6302],
        [-0.7966, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24142931401729584
Epoch 0, Step 986: train/loss = 0.4745703339576721, train/raw-loss = 0.4502013325691223, train/logprobs = tensor([[-0.9407, -4.2314],
        [-1.0276, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24369002878665924
Epoch 0, Step 987: train/loss = 0.5493217706680298, train/raw-loss = 0.5295997262001038, train/logprobs = tensor([[-0.7697, -3.6428],
        [-0.7226, -0.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19722002744674683
Epoch 0, Step 988: train/loss = 0.5603960752487183, train/raw-loss = 0.5391573905944824, train/logprobs = tensor([[-0.8274, -2.5719],
        [-0.6575, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21238648891448975
Epoch 0, Step 989: train/loss = 0.6648856401443481, train/raw-loss = 0.6441790461540222, train/logprobs = tensor([[-1.3589, -1.9336],
        [-0.7411, -0.7469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2070661336183548
Epoch 0, Step 990: train/loss = 0.45250552892684937, train/raw-loss = 0.4273860454559326, train/logprobs = tensor([[-1.3472, -5.5706],
        [-1.1126, -0.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511950433254242
Epoch 0, Step 991: train/loss = 0.5285561680793762, train/raw-loss = 0.5069031119346619, train/logprobs = tensor([[-1.0017, -4.2677],
        [-0.8457, -0.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21653077006340027
Epoch 0, Step 992: train/loss = 0.5536546111106873, train/raw-loss = 0.5331265330314636, train/logprobs = tensor([[-0.6533, -2.5277],
        [-0.7679, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20528078079223633
Epoch 0, Step 993: train/loss = 0.4378470778465271, train/raw-loss = 0.41605496406555176, train/logprobs = tensor([[-1.5044, -4.7627],
        [-1.4258, -0.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21792107820510864
Epoch 0, Step 994: train/loss = 0.4457959532737732, train/raw-loss = 0.4226713180541992, train/logprobs = tensor([[-0.7946, -4.3063],
        [-1.0037, -0.7124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23124662041664124
Epoch 0, Step 995: train/loss = 0.5280423760414124, train/raw-loss = 0.5021268725395203, train/logprobs = tensor([[-1.3169, -2.0423],
        [-1.3859, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25915560126304626
Epoch 0, Step 996: train/loss = 0.5965259671211243, train/raw-loss = 0.5743225812911987, train/logprobs = tensor([[-1.5736, -2.9995],
        [-1.1030, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2220340371131897
Epoch 0, Step 997: train/loss = 0.538121223449707, train/raw-loss = 0.5158082246780396, train/logprobs = tensor([[-0.6326, -1.5360],
        [-0.8503, -0.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22313009202480316
Epoch 0, Step 998: train/loss = 0.2550817131996155, train/raw-loss = 0.2317761480808258, train/logprobs = tensor([[-1.1051, -5.1532],
        [-1.4821, -0.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2330559641122818
Epoch 0, Step 999: train/loss = 0.5785142183303833, train/raw-loss = 0.5550249814987183, train/logprobs = tensor([[-0.6797, -1.1551],
        [-0.8263, -0.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2348923683166504
Epoch 0, Step 1000: train/loss = 0.5116437077522278, train/raw-loss = 0.4876764118671417, train/logprobs = tensor([[-0.9397, -2.1862],
        [-1.0886, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23967328667640686
Epoch 0, Step 1001: train/loss = 0.3299033045768738, train/raw-loss = 0.3020589053630829, train/logprobs = tensor([[-1.3663, -3.9927],
        [-1.6126, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27844375371932983
Epoch 0, Step 1002: train/loss = 0.4313115179538727, train/raw-loss = 0.4032202363014221, train/logprobs = tensor([[-1.1654, -3.8877],
        [-1.1769, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2809131145477295
Epoch 0, Step 1003: train/loss = 0.679408073425293, train/raw-loss = 0.6565438508987427, train/logprobs = tensor([[-0.8795, -0.9753],
        [-0.7668, -0.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2286418229341507
Epoch 0, Step 1004: train/loss = 0.6756545305252075, train/raw-loss = 0.6524702906608582, train/logprobs = tensor([[-1.9790, -3.9345],
        [-0.8778, -0.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318420708179474
Epoch 0, Step 1005: train/loss = 0.6289752125740051, train/raw-loss = 0.6045687794685364, train/logprobs = tensor([[-2.2030, -5.2357],
        [-0.9857, -0.4234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2440643459558487
Epoch 0, Step 1006: train/loss = 0.6826847791671753, train/raw-loss = 0.6554064154624939, train/logprobs = tensor([[-1.4442, -2.3013],
        [-0.7775, -0.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727832794189453
Epoch 0, Step 1007: train/loss = 0.551899254322052, train/raw-loss = 0.5249307155609131, train/logprobs = tensor([[-0.9884, -2.4447],
        [-1.0418, -0.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26968610286712646
Epoch 0, Step 1008: train/loss = 0.6489540338516235, train/raw-loss = 0.6252270936965942, train/logprobs = tensor([[-1.9593, -5.8179],
        [-0.8585, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23726937174797058
Epoch 0, Step 1009: train/loss = 0.4139742851257324, train/raw-loss = 0.3900548219680786, train/logprobs = tensor([[-0.7572, -3.0762],
        [-1.1206, -0.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23919495940208435
Epoch 0, Step 1010: train/loss = 0.5365880727767944, train/raw-loss = 0.5129963159561157, train/logprobs = tensor([[-1.1571, -4.3395],
        [-1.2419, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23591816425323486
Epoch 0, Step 1011: train/loss = 0.6134341955184937, train/raw-loss = 0.5913619995117188, train/logprobs = tensor([[-1.2794, -1.6725],
        [-1.2007, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22072243690490723
Epoch 0, Step 1012: train/loss = 0.674213171005249, train/raw-loss = 0.6537808179855347, train/logprobs = tensor([[-1.6170, -2.7663],
        [-0.6586, -0.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2043229341506958
Epoch 0, Step 1013: train/loss = 0.6331459283828735, train/raw-loss = 0.6088793277740479, train/logprobs = tensor([[-0.7294, -1.0052],
        [-0.8695, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24266637861728668
Epoch 0, Step 1014: train/loss = 0.4639669358730316, train/raw-loss = 0.43828582763671875, train/logprobs = tensor([[-1.5696, -8.3869],
        [-1.0575, -1.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568110525608063
Epoch 0, Step 1015: train/loss = 0.5037044882774353, train/raw-loss = 0.4791843891143799, train/logprobs = tensor([[-1.1641, -2.8219],
        [-1.2873, -0.6099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2452009618282318
Epoch 0, Step 1016: train/loss = 0.46984347701072693, train/raw-loss = 0.44481927156448364, train/logprobs = tensor([[-0.9011, -1.9425],
        [-1.1994, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502421736717224
Epoch 0, Step 1017: train/loss = 0.4577891528606415, train/raw-loss = 0.4342232644557953, train/logprobs = tensor([[-0.7384, -2.4921],
        [-0.9252, -0.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23565897345542908
Epoch 0, Step 1018: train/loss = 0.7593379020690918, train/raw-loss = 0.7362443804740906, train/logprobs = tensor([[-2.2314, -2.8146],
        [-0.9798, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23093464970588684
Epoch 0, Step 1019: train/loss = 0.479526162147522, train/raw-loss = 0.4523596167564392, train/logprobs = tensor([[-1.2063, -4.4257],
        [-1.2569, -0.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716650664806366
Epoch 0, Step 1020: train/loss = 0.6811557412147522, train/raw-loss = 0.6555379629135132, train/logprobs = tensor([[-1.2941, -2.1086],
        [-0.9560, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256177693605423
Epoch 0, Step 1021: train/loss = 0.6024397611618042, train/raw-loss = 0.5789203643798828, train/logprobs = tensor([[-0.9967, -1.6434],
        [-0.9612, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23519399762153625
Epoch 0, Step 1022: train/loss = 0.4867319166660309, train/raw-loss = 0.4607788324356079, train/logprobs = tensor([[-1.3504, -3.5429],
        [-1.1625, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25953125953674316
Epoch 0, Step 1023: train/loss = 0.357668936252594, train/raw-loss = 0.3337424397468567, train/logprobs = tensor([[-1.0231, -4.5310],
        [-1.3473, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23926496505737305
Epoch 0, Step 1024: train/loss = 0.49866294860839844, train/raw-loss = 0.4788830876350403, train/logprobs = tensor([[-0.5763, -1.4341],
        [-0.6875, -0.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.197798490524292
Epoch 0, Step 1025: train/loss = 0.571677029132843, train/raw-loss = 0.5486567616462708, train/logprobs = tensor([[-0.8403, -1.5364],
        [-0.8008, -0.7115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23020286858081818
Epoch 0, Step 1026: train/loss = 0.46158885955810547, train/raw-loss = 0.43789276480674744, train/logprobs = tensor([[-0.8861, -2.9160],
        [-1.1339, -0.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23696079850196838
Epoch 0, Step 1027: train/loss = 0.4158288538455963, train/raw-loss = 0.393588662147522, train/logprobs = tensor([[-1.2191, -5.2210],
        [-1.0610, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22240181267261505
Epoch 0, Step 1028: train/loss = 0.6694260239601135, train/raw-loss = 0.6451996564865112, train/logprobs = tensor([[-0.9877, -1.2217],
        [-0.7529, -0.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2422632873058319
Epoch 0, Step 1029: train/loss = 0.5373983979225159, train/raw-loss = 0.5109729766845703, train/logprobs = tensor([[-2.0338, -3.7100],
        [-1.5173, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642541825771332
Epoch 0, Step 1030: train/loss = 1.1523517370224, train/raw-loss = 1.1303844451904297, train/logprobs = tensor([[-5.0644, -7.6026],
        [-2.0582, -1.7303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21967214345932007
Epoch 0, Step 1031: train/loss = 0.45445987582206726, train/raw-loss = 0.43215739727020264, train/logprobs = tensor([[-1.2402, -3.2483],
        [-1.3121, -0.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22302475571632385
Epoch 0, Step 1032: train/loss = 0.6068963408470154, train/raw-loss = 0.587267279624939, train/logprobs = tensor([[-0.6122, -1.1068],
        [-0.6853, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19629016518592834
Epoch 0, Step 1033: train/loss = 0.6392338275909424, train/raw-loss = 0.621390700340271, train/logprobs = tensor([[-0.7000, -0.8410],
        [-0.7110, -0.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17843148112297058
Epoch 0, Step 1034: train/loss = 0.5242637991905212, train/raw-loss = 0.502274751663208, train/logprobs = tensor([[-1.3856, -3.2708],
        [-1.3796, -0.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21989035606384277
Epoch 0, Step 1035: train/loss = 0.41195154190063477, train/raw-loss = 0.3854374289512634, train/logprobs = tensor([[-1.3282, -2.7837],
        [-1.4707, -0.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651410698890686
Epoch 0, Step 1036: train/loss = 0.538094699382782, train/raw-loss = 0.514003336429596, train/logprobs = tensor([[-0.8401, -1.9902],
        [-0.8292, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24091380834579468
Epoch 0, Step 1037: train/loss = 0.43274354934692383, train/raw-loss = 0.4035162925720215, train/logprobs = tensor([[-1.1287, -2.5453],
        [-1.4288, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2922731339931488
Epoch 0, Step 1038: train/loss = 0.41084855794906616, train/raw-loss = 0.3888126015663147, train/logprobs = tensor([[-1.0730, -5.6303],
        [-1.0331, -0.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22035963833332062
Epoch 0, Step 1039: train/loss = 0.46198907494544983, train/raw-loss = 0.440189927816391, train/logprobs = tensor([[-0.9112, -3.0939],
        [-0.8183, -0.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21799136698246002
Epoch 0, Step 1040: train/loss = 0.5456477999687195, train/raw-loss = 0.5188506841659546, train/logprobs = tensor([[-1.2457, -2.4556],
        [-1.0245, -0.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679714858531952
Epoch 0, Step 1041: train/loss = 0.428974986076355, train/raw-loss = 0.4057772755622864, train/logprobs = tensor([[-0.9563, -4.8911],
        [-1.0509, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23197710514068604
Epoch 0, Step 1042: train/loss = 0.5731058120727539, train/raw-loss = 0.5474249720573425, train/logprobs = tensor([[-1.5297, -2.2604],
        [-1.4555, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568083107471466
Epoch 0, Step 1043: train/loss = 0.573032796382904, train/raw-loss = 0.5511941909790039, train/logprobs = tensor([[-0.6878, -2.0158],
        [-0.7528, -0.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21838584542274475
Epoch 0, Step 1044: train/loss = 0.26514559984207153, train/raw-loss = 0.2421819269657135, train/logprobs = tensor([[-1.1199, -4.3949],
        [-1.6079, -0.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22963693737983704
Epoch 0, Step 1045: train/loss = 0.46632659435272217, train/raw-loss = 0.4421737790107727, train/logprobs = tensor([[-0.9114, -5.4111],
        [-1.3876, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24152813851833344
Epoch 0, Step 1046: train/loss = 0.42073842883110046, train/raw-loss = 0.3960086405277252, train/logprobs = tensor([[-0.8498, -5.3502],
        [-1.1537, -0.4211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24729791283607483
Epoch 0, Step 1047: train/loss = 0.4715994596481323, train/raw-loss = 0.4480627477169037, train/logprobs = tensor([[-0.7398, -1.8969],
        [-0.8749, -0.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23536738753318787
Epoch 0, Step 1048: train/loss = 0.4143306612968445, train/raw-loss = 0.3905596137046814, train/logprobs = tensor([[-1.1019, -4.0956],
        [-1.1697, -0.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23770996928215027
Epoch 0, Step 1049: train/loss = 0.6078804135322571, train/raw-loss = 0.5842314958572388, train/logprobs = tensor([[-1.8413, -3.4648],
        [-1.0114, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2364891767501831
Epoch 0, Step 1050: train/loss = 0.625008761882782, train/raw-loss = 0.5999115705490112, train/logprobs = tensor([[-0.9816, -1.3750],
        [-0.8010, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250971257686615
Epoch 0, Step 1051: train/loss = 0.443383127450943, train/raw-loss = 0.4195902943611145, train/logprobs = tensor([[-0.8898, -2.7823],
        [-1.5203, -0.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23792842030525208
Epoch 0, Step 1052: train/loss = 0.4516355097293854, train/raw-loss = 0.42584532499313354, train/logprobs = tensor([[-0.9023, -5.6233],
        [-1.4172, -1.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25790196657180786
Epoch 0, Step 1053: train/loss = 0.504390299320221, train/raw-loss = 0.47996342182159424, train/logprobs = tensor([[-1.1099, -4.9442],
        [-0.8960, -1.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24426865577697754
Epoch 0, Step 1054: train/loss = 0.6363242268562317, train/raw-loss = 0.6150420308113098, train/logprobs = tensor([[-1.0629, -1.0249],
        [-1.1098, -0.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21282225847244263
Epoch 0, Step 1055: train/loss = 0.6108568906784058, train/raw-loss = 0.5866382122039795, train/logprobs = tensor([[-1.0326, -1.7713],
        [-0.8072, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2421869933605194
Epoch 0, Step 1056: train/loss = 0.34885361790657043, train/raw-loss = 0.3162282705307007, train/logprobs = tensor([[-1.2349, -4.6079],
        [-1.8450, -0.8297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262535631656647
Epoch 0, Step 1057: train/loss = 0.33294886350631714, train/raw-loss = 0.3088598847389221, train/logprobs = tensor([[-0.9345, -5.3560],
        [-1.3124, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24088987708091736
Epoch 0, Step 1058: train/loss = 0.237249493598938, train/raw-loss = 0.20912137627601624, train/logprobs = tensor([[-1.1245, -5.8090],
        [-1.6284, -0.5808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281281054019928
Epoch 0, Step 1059: train/loss = 0.44085848331451416, train/raw-loss = 0.41595959663391113, train/logprobs = tensor([[-1.1236, -3.6806],
        [-1.2075, -0.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489887773990631
Epoch 0, Step 1060: train/loss = 0.39413392543792725, train/raw-loss = 0.3723304569721222, train/logprobs = tensor([[-1.1729, -4.5183],
        [-1.2824, -1.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21803484857082367
Epoch 0, Step 1061: train/loss = 0.5461065173149109, train/raw-loss = 0.5213929414749146, train/logprobs = tensor([[-1.1329, -2.9268],
        [-1.0128, -0.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24713635444641113
Epoch 0, Step 1062: train/loss = 0.42753463983535767, train/raw-loss = 0.40525004267692566, train/logprobs = tensor([[-0.8342, -3.5744],
        [-1.4284, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22284600138664246
Epoch 0, Step 1063: train/loss = 0.6933305263519287, train/raw-loss = 0.6668843626976013, train/logprobs = tensor([[-1.5940, -2.6317],
        [-0.9189, -0.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644612193107605
Epoch 0, Step 1064: train/loss = 0.43437299132347107, train/raw-loss = 0.409083753824234, train/logprobs = tensor([[-1.1808, -2.8342],
        [-1.3290, -0.6158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25289249420166016
Epoch 0, Step 1065: train/loss = 0.34993261098861694, train/raw-loss = 0.3288586735725403, train/logprobs = tensor([[-1.0358, -8.2885],
        [-1.0427, -1.2060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21073943376541138
Epoch 0, Step 1066: train/loss = 0.4006267189979553, train/raw-loss = 0.3737993836402893, train/logprobs = tensor([[-1.2807, -4.8350],
        [-1.5879, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682732343673706
Epoch 0, Step 1067: train/loss = 0.31104543805122375, train/raw-loss = 0.2838239073753357, train/logprobs = tensor([[-0.9583, -4.7091],
        [-1.5742, -0.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272215336561203
Epoch 0, Step 1068: train/loss = 0.28966236114501953, train/raw-loss = 0.2633958160877228, train/logprobs = tensor([[-0.7724, -4.5612],
        [-1.4475, -0.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26266542077064514
Epoch 0, Step 1069: train/loss = 0.34105366468429565, train/raw-loss = 0.3174781799316406, train/logprobs = tensor([[-0.7827, -3.4415],
        [-1.0530, -1.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23575502634048462
Epoch 0, Step 1070: train/loss = 0.633009135723114, train/raw-loss = 0.6079056262969971, train/logprobs = tensor([[-1.8245, -2.5280],
        [-1.3939, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2510349750518799
Epoch 0, Step 1071: train/loss = 0.6772459149360657, train/raw-loss = 0.6538829803466797, train/logprobs = tensor([[-1.4541, -1.8134],
        [-0.8066, -0.7218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23362967371940613
Epoch 0, Step 1072: train/loss = 0.4340786337852478, train/raw-loss = 0.4106147587299347, train/logprobs = tensor([[-0.8520, -3.7448],
        [-1.0969, -0.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.234638512134552
Epoch 0, Step 1073: train/loss = 0.5765568017959595, train/raw-loss = 0.552383542060852, train/logprobs = tensor([[-1.1461, -1.6422],
        [-1.0642, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24173253774642944
Epoch 0, Step 1074: train/loss = 0.5305747985839844, train/raw-loss = 0.5142162442207336, train/logprobs = tensor([[-0.5830, -1.5079],
        [-0.9381, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16358554363250732
Epoch 0, Step 1075: train/loss = 0.610098659992218, train/raw-loss = 0.5885131359100342, train/logprobs = tensor([[-0.9343, -3.1988],
        [-0.9225, -1.5277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158554345369339
Epoch 0, Step 1076: train/loss = 0.6164883971214294, train/raw-loss = 0.5879189372062683, train/logprobs = tensor([[-1.7028, -3.2697],
        [-1.2868, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856951355934143
Epoch 0, Step 1077: train/loss = 0.5875042676925659, train/raw-loss = 0.5621358156204224, train/logprobs = tensor([[-1.0037, -1.0661],
        [-1.5877, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25368380546569824
Epoch 0, Step 1078: train/loss = 0.4683213233947754, train/raw-loss = 0.4450114667415619, train/logprobs = tensor([[-2.0388, -8.1528],
        [-1.8573, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23309877514839172
Epoch 0, Step 1079: train/loss = 0.6090373396873474, train/raw-loss = 0.5880127549171448, train/logprobs = tensor([[-1.0855, -1.9628],
        [-0.5798, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102455347776413
Epoch 0, Step 1080: train/loss = 0.469984769821167, train/raw-loss = 0.4425871670246124, train/logprobs = tensor([[-0.7943, -2.4653],
        [-1.0807, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739758789539337
Epoch 0, Step 1081: train/loss = 0.5491312146186829, train/raw-loss = 0.5234270095825195, train/logprobs = tensor([[-0.9989, -1.6631],
        [-1.0575, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570425271987915
Epoch 0, Step 1082: train/loss = 0.4985124468803406, train/raw-loss = 0.4748682975769043, train/logprobs = tensor([[-0.7094, -1.6731],
        [-1.2401, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2364412248134613
Epoch 0, Step 1083: train/loss = 0.5150278806686401, train/raw-loss = 0.49239209294319153, train/logprobs = tensor([[-0.7398, -2.2816],
        [-0.7072, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22635793685913086
Epoch 0, Step 1084: train/loss = 0.43178683519363403, train/raw-loss = 0.40972402691841125, train/logprobs = tensor([[-0.9512, -2.7129],
        [-0.9231, -0.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22062818706035614
Epoch 0, Step 1085: train/loss = 0.3340598940849304, train/raw-loss = 0.30697113275527954, train/logprobs = tensor([[-1.1491, -3.6950],
        [-1.5735, -0.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27088800072669983
Epoch 0, Step 1086: train/loss = 0.5567477345466614, train/raw-loss = 0.5333551168441772, train/logprobs = tensor([[-1.0440, -2.8301],
        [-0.7580, -0.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233925923705101
Epoch 0, Step 1087: train/loss = 0.3536454737186432, train/raw-loss = 0.32921990752220154, train/logprobs = tensor([[-1.1004, -5.7417],
        [-1.4289, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24425551295280457
Epoch 0, Step 1088: train/loss = 0.706606388092041, train/raw-loss = 0.680254340171814, train/logprobs = tensor([[-1.5876, -1.6988],
        [-1.5571, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2635210156440735
Epoch 0, Step 1089: train/loss = 0.29392576217651367, train/raw-loss = 0.26907646656036377, train/logprobs = tensor([[-0.9165, -4.3946],
        [-1.2350, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24849294126033783
Epoch 0, Step 1090: train/loss = 0.39167267084121704, train/raw-loss = 0.3654407858848572, train/logprobs = tensor([[-0.9945, -2.5325],
        [-1.5938, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623192369937897
Epoch 0, Step 1091: train/loss = 0.5040953159332275, train/raw-loss = 0.4815211892127991, train/logprobs = tensor([[-0.9345, -2.7611],
        [-0.8812, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22574152052402496
Epoch 0, Step 1092: train/loss = 0.37157806754112244, train/raw-loss = 0.34489503502845764, train/logprobs = tensor([[-0.8389, -2.1505],
        [-1.6033, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668302357196808
Epoch 0, Step 1093: train/loss = 0.38332533836364746, train/raw-loss = 0.35836297273635864, train/logprobs = tensor([[-1.0566, -3.8924],
        [-1.2221, -0.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24962356686592102
Epoch 0, Step 1094: train/loss = 0.5976584553718567, train/raw-loss = 0.5682318210601807, train/logprobs = tensor([[-1.3976, -2.2159],
        [-0.9782, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29426631331443787
Epoch 0, Step 1095: train/loss = 0.36489105224609375, train/raw-loss = 0.34248098731040955, train/logprobs = tensor([[-0.8973, -4.3255],
        [-1.2081, -0.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2241009771823883
Epoch 0, Step 1096: train/loss = 0.5318408012390137, train/raw-loss = 0.5075629949569702, train/logprobs = tensor([[-1.0643, -3.2655],
        [-1.0762, -1.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24277818202972412
Epoch 0, Step 1097: train/loss = 0.2851802110671997, train/raw-loss = 0.25968486070632935, train/logprobs = tensor([[-1.2238, -5.1313],
        [-1.4899, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25495365262031555
Epoch 0, Step 1098: train/loss = 0.5235536694526672, train/raw-loss = 0.4996696710586548, train/logprobs = tensor([[-1.1896, -3.0259],
        [-1.3083, -0.6044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23883987963199615
Epoch 0, Step 1099: train/loss = 0.3444937467575073, train/raw-loss = 0.3225553333759308, train/logprobs = tensor([[-0.6108, -7.8924],
        [-0.7894, -1.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21938423812389374
Epoch 0, Step 1100: train/loss = 0.40962687134742737, train/raw-loss = 0.3824145495891571, train/logprobs = tensor([[-1.3533, -4.4053],
        [-1.5199, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27212321758270264
Epoch 0, Step 1101: train/loss = 0.4301823377609253, train/raw-loss = 0.4052937924861908, train/logprobs = tensor([[-0.7888, -4.9174],
        [-1.2688, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24888569116592407
Epoch 0, Step 1102: train/loss = 0.4365094006061554, train/raw-loss = 0.413593590259552, train/logprobs = tensor([[-1.1587, -2.9306],
        [-1.0870, -0.6301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22915828227996826
Epoch 0, Step 1103: train/loss = 0.362196147441864, train/raw-loss = 0.33029067516326904, train/logprobs = tensor([[-0.8468, -3.2223],
        [-2.2145, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31905481219291687
Epoch 0, Step 1104: train/loss = 0.5905659198760986, train/raw-loss = 0.5685834288597107, train/logprobs = tensor([[-0.7114, -2.5858],
        [-0.9982, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21982474625110626
Epoch 0, Step 1105: train/loss = 0.5704410076141357, train/raw-loss = 0.5497053861618042, train/logprobs = tensor([[-0.9116, -2.3500],
        [-0.8373, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20735597610473633
Epoch 0, Step 1106: train/loss = 0.5456987619400024, train/raw-loss = 0.5215761661529541, train/logprobs = tensor([[-1.0335, -3.0621],
        [-0.8076, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2412256896495819
Epoch 0, Step 1107: train/loss = 0.5661808252334595, train/raw-loss = 0.5428816080093384, train/logprobs = tensor([[-1.0246, -4.2523],
        [-0.7820, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23299214243888855
Epoch 0, Step 1108: train/loss = 0.3795875906944275, train/raw-loss = 0.3483862280845642, train/logprobs = tensor([[-1.6815, -4.4200],
        [-1.7431, -1.5115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31201398372650146
Epoch 0, Step 1109: train/loss = 0.3778713047504425, train/raw-loss = 0.3535672426223755, train/logprobs = tensor([[-0.9147, -7.8160],
        [-1.3455, -1.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24304014444351196
Epoch 0, Step 1110: train/loss = 0.3495491147041321, train/raw-loss = 0.32140055298805237, train/logprobs = tensor([[-1.0222, -2.7718],
        [-1.4560, -0.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2814854681491852
Epoch 0, Step 1111: train/loss = 0.41412532329559326, train/raw-loss = 0.3912539482116699, train/logprobs = tensor([[-0.7189, -3.3720],
        [-1.0638, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22871387004852295
Epoch 0, Step 1112: train/loss = 0.3259088397026062, train/raw-loss = 0.30035144090652466, train/logprobs = tensor([[-1.2179, -6.8021],
        [-1.4616, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2555738389492035
Epoch 0, Step 1113: train/loss = 0.8560270071029663, train/raw-loss = 0.8359779715538025, train/logprobs = tensor([[-1.8702, -2.3477],
        [-0.6873, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20049092173576355
Epoch 0, Step 1114: train/loss = 0.4819357395172119, train/raw-loss = 0.45825067162513733, train/logprobs = tensor([[-1.0160, -5.1414],
        [-0.7616, -0.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368505597114563
Epoch 0, Step 1115: train/loss = 0.47866326570510864, train/raw-loss = 0.4517773985862732, train/logprobs = tensor([[-0.8484, -1.8152],
        [-1.1616, -0.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688584625720978
Epoch 0, Step 1116: train/loss = 0.37517544627189636, train/raw-loss = 0.3484647870063782, train/logprobs = tensor([[-0.9324, -4.4229],
        [-1.1959, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26710665225982666
Epoch 0, Step 1117: train/loss = 0.5957510471343994, train/raw-loss = 0.5725419521331787, train/logprobs = tensor([[-0.7565, -1.2490],
        [-0.7798, -0.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2320910394191742
Epoch 0, Step 1118: train/loss = 0.7545304894447327, train/raw-loss = 0.7320042848587036, train/logprobs = tensor([[-1.2009, -1.0391],
        [-0.7847, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22526192665100098
Epoch 0, Step 1119: train/loss = 0.5720781683921814, train/raw-loss = 0.546852171421051, train/logprobs = tensor([[-1.4089, -2.5375],
        [-0.9356, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522604167461395
Epoch 0, Step 1120: train/loss = 0.5471633076667786, train/raw-loss = 0.522991955280304, train/logprobs = tensor([[-0.8959, -3.4280],
        [-0.9522, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24171379208564758
Epoch 0, Step 1121: train/loss = 0.4377337098121643, train/raw-loss = 0.4129457175731659, train/logprobs = tensor([[-1.2118, -4.6519],
        [-1.1417, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2478800117969513
Epoch 0, Step 1122: train/loss = 0.5090581178665161, train/raw-loss = 0.48365163803100586, train/logprobs = tensor([[-0.8334, -3.2972],
        [-1.2944, -0.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25406476855278015
Epoch 0, Step 1123: train/loss = 0.3756799101829529, train/raw-loss = 0.35340458154678345, train/logprobs = tensor([[-0.9807, -7.0425],
        [-0.9789, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22275304794311523
Epoch 0, Step 1124: train/loss = 0.44089797139167786, train/raw-loss = 0.4169360399246216, train/logprobs = tensor([[-0.8804, -2.1280],
        [-1.2758, -0.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2396194487810135
Epoch 0, Step 1125: train/loss = 0.3171851634979248, train/raw-loss = 0.29253509640693665, train/logprobs = tensor([[-1.0305, -8.7361],
        [-1.3468, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24650073051452637
Epoch 0, Step 1126: train/loss = 0.4447011649608612, train/raw-loss = 0.42134255170822144, train/logprobs = tensor([[-1.2218, -4.6798],
        [-1.3169, -0.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23358607292175293
Epoch 0, Step 1127: train/loss = 0.5179426670074463, train/raw-loss = 0.4954703450202942, train/logprobs = tensor([[-0.5905, -1.5449],
        [-1.0582, -1.0727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22472286224365234
Epoch 0, Step 1128: train/loss = 0.40965092182159424, train/raw-loss = 0.3845229744911194, train/logprobs = tensor([[-0.9874, -3.4123],
        [-1.5978, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512792944908142
Epoch 0, Step 1129: train/loss = 0.4006831645965576, train/raw-loss = 0.37640658020973206, train/logprobs = tensor([[-0.7148, -4.1892],
        [-1.0750, -0.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24276578426361084
Epoch 0, Step 1130: train/loss = 0.48589348793029785, train/raw-loss = 0.46314212679862976, train/logprobs = tensor([[-1.0337, -2.5711],
        [-1.1909, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22751377522945404
Epoch 0, Step 1131: train/loss = 0.4821363389492035, train/raw-loss = 0.45802831649780273, train/logprobs = tensor([[-1.2522, -5.2789],
        [-1.1748, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.241080179810524
Epoch 0, Step 1132: train/loss = 0.42966002225875854, train/raw-loss = 0.40717417001724243, train/logprobs = tensor([[-0.8493, -2.7278],
        [-1.3460, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22485870122909546
Epoch 0, Step 1133: train/loss = 0.5150451064109802, train/raw-loss = 0.48887020349502563, train/logprobs = tensor([[-0.8095, -2.2421],
        [-1.3128, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26174837350845337
Epoch 0, Step 1134: train/loss = 0.4524744153022766, train/raw-loss = 0.4272181987762451, train/logprobs = tensor([[-0.9696, -3.0488],
        [-1.1201, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525622844696045
Epoch 0, Step 1135: train/loss = 1.1542718410491943, train/raw-loss = 1.1331632137298584, train/logprobs = tensor([[-3.0122, -3.1248],
        [-0.6429, -0.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21108606457710266
Epoch 0, Step 1136: train/loss = 0.4418323338031769, train/raw-loss = 0.4210633635520935, train/logprobs = tensor([[-0.6739, -2.4427],
        [-1.0879, -0.4942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20768997073173523
Epoch 0, Step 1137: train/loss = 0.4248735308647156, train/raw-loss = 0.39845046401023865, train/logprobs = tensor([[-1.4152, -4.4076],
        [-1.2198, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26423078775405884
Epoch 0, Step 1138: train/loss = 0.4545603394508362, train/raw-loss = 0.43270617723464966, train/logprobs = tensor([[-0.7869, -2.0013],
        [-1.0224, -0.4672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21854178607463837
Epoch 0, Step 1139: train/loss = 0.6920989751815796, train/raw-loss = 0.66950523853302, train/logprobs = tensor([[-1.7614, -2.5097],
        [-0.9363, -0.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259361445903778
Epoch 0, Step 1140: train/loss = 0.3715169131755829, train/raw-loss = 0.3485053777694702, train/logprobs = tensor([[-1.0643, -5.8158],
        [-1.3299, -0.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23011523485183716
Epoch 0, Step 1141: train/loss = 0.5632810592651367, train/raw-loss = 0.5418338775634766, train/logprobs = tensor([[-0.6905, -1.4402],
        [-0.6714, -0.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.214472234249115
Epoch 0, Step 1142: train/loss = 0.5114047527313232, train/raw-loss = 0.48992466926574707, train/logprobs = tensor([[-0.7491, -1.8766],
        [-1.1056, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21480098366737366
Epoch 0, Step 1143: train/loss = 0.42216724157333374, train/raw-loss = 0.39596182107925415, train/logprobs = tensor([[-0.8311, -2.4982],
        [-1.3577, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262054443359375
Epoch 0, Step 1144: train/loss = 0.45840445160865784, train/raw-loss = 0.4369352161884308, train/logprobs = tensor([[-0.8198, -2.6209],
        [-1.2288, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21469233930110931
Epoch 0, Step 1145: train/loss = 0.4517897963523865, train/raw-loss = 0.4265308082103729, train/logprobs = tensor([[-0.8081, -3.2190],
        [-1.1689, -1.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525899112224579
Epoch 0, Step 1146: train/loss = 0.39715269207954407, train/raw-loss = 0.3747948110103607, train/logprobs = tensor([[-1.4685, -5.8430],
        [-1.1148, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235790193080902
Epoch 0, Step 1147: train/loss = 0.4819790720939636, train/raw-loss = 0.4589935541152954, train/logprobs = tensor([[-0.8387, -2.1848],
        [-0.9306, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2298547327518463
Epoch 0, Step 1148: train/loss = 0.459428995847702, train/raw-loss = 0.4386701285839081, train/logprobs = tensor([[-0.6567, -2.7072],
        [-0.8466, -0.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.207588791847229
Epoch 0, Step 1149: train/loss = 0.4723097085952759, train/raw-loss = 0.44616323709487915, train/logprobs = tensor([[-0.9447, -2.2563],
        [-1.5924, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614646553993225
Epoch 0, Step 1150: train/loss = 0.6043412089347839, train/raw-loss = 0.5786601305007935, train/logprobs = tensor([[-0.9565, -2.0114],
        [-0.8445, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25681072473526
Epoch 0, Step 1151: train/loss = 0.4284008741378784, train/raw-loss = 0.40369123220443726, train/logprobs = tensor([[-1.0190, -4.0326],
        [-0.9870, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2470962405204773
Epoch 0, Step 1152: train/loss = 0.662149965763092, train/raw-loss = 0.6405119299888611, train/logprobs = tensor([[-1.4989, -1.6926],
        [-1.1843, -0.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21638019382953644
Epoch 0, Step 1153: train/loss = 0.40122634172439575, train/raw-loss = 0.37840279936790466, train/logprobs = tensor([[-0.6922, -4.0376],
        [-1.1109, -0.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22823543846607208
Epoch 0, Step 1154: train/loss = 0.34056901931762695, train/raw-loss = 0.31697025895118713, train/logprobs = tensor([[-0.8795, -3.0982],
        [-1.4263, -0.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23598766326904297
Epoch 0, Step 1155: train/loss = 0.4428529143333435, train/raw-loss = 0.4160301983356476, train/logprobs = tensor([[-0.9037, -2.0365],
        [-1.5866, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2682271897792816
Epoch 0, Step 1156: train/loss = 0.4187983274459839, train/raw-loss = 0.39464837312698364, train/logprobs = tensor([[-1.1982, -3.8833],
        [-1.4242, -0.5692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24149958789348602
Epoch 0, Step 1157: train/loss = 0.46514320373535156, train/raw-loss = 0.4406721889972687, train/logprobs = tensor([[-0.7284, -1.8384],
        [-1.2439, -0.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2447100281715393
Epoch 0, Step 1158: train/loss = 0.44571810960769653, train/raw-loss = 0.42317840456962585, train/logprobs = tensor([[-0.7459, -2.7630],
        [-1.0549, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22539721429347992
Epoch 0, Step 1159: train/loss = 0.6016155481338501, train/raw-loss = 0.5806525349617004, train/logprobs = tensor([[-0.6847, -2.0858],
        [-0.5650, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20963047444820404
Epoch 0, Step 1160: train/loss = 0.3463065028190613, train/raw-loss = 0.3207027316093445, train/logprobs = tensor([[-0.8656, -2.7155],
        [-1.4864, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2560381591320038
Epoch 0, Step 1161: train/loss = 0.37387168407440186, train/raw-loss = 0.34997648000717163, train/logprobs = tensor([[-0.8510, -4.5875],
        [-1.5377, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23895183205604553
Epoch 0, Step 1162: train/loss = 0.5019960403442383, train/raw-loss = 0.47797316312789917, train/logprobs = tensor([[-2.0141, -3.5462],
        [-1.9231, -1.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240228533744812
Epoch 0, Step 1163: train/loss = 0.45980995893478394, train/raw-loss = 0.43545371294021606, train/logprobs = tensor([[-0.8434, -2.0371],
        [-1.1811, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24356214702129364
Epoch 0, Step 1164: train/loss = 0.3934510350227356, train/raw-loss = 0.3670881986618042, train/logprobs = tensor([[-1.1482, -3.8358],
        [-1.3608, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26362866163253784
Epoch 0, Step 1165: train/loss = 0.4170647859573364, train/raw-loss = 0.3930760324001312, train/logprobs = tensor([[-0.7792, -2.5498],
        [-1.0902, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23988769948482513
Epoch 0, Step 1166: train/loss = 0.6016039848327637, train/raw-loss = 0.576750636100769, train/logprobs = tensor([[-0.6440, -0.9304],
        [-1.2457, -0.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24853286147117615
Epoch 0, Step 1167: train/loss = 0.4744330048561096, train/raw-loss = 0.45298320055007935, train/logprobs = tensor([[-1.0090, -3.3321],
        [-0.9230, -0.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21449819207191467
Epoch 0, Step 1168: train/loss = 0.4150397777557373, train/raw-loss = 0.3928740918636322, train/logprobs = tensor([[-0.7493, -2.8613],
        [-1.4403, -1.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2216567099094391
Epoch 0, Step 1169: train/loss = 0.46067965030670166, train/raw-loss = 0.43854349851608276, train/logprobs = tensor([[-0.7159, -1.9726],
        [-1.1743, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213616520166397
Epoch 0, Step 1170: train/loss = 0.5458910465240479, train/raw-loss = 0.5226491093635559, train/logprobs = tensor([[-0.7079, -2.2619],
        [-0.7960, -1.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23241955041885376
Epoch 0, Step 1171: train/loss = 0.4291224479675293, train/raw-loss = 0.4006064236164093, train/logprobs = tensor([[-0.9160, -2.2199],
        [-1.3804, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851603329181671
Epoch 0, Step 1172: train/loss = 0.48517870903015137, train/raw-loss = 0.4594259262084961, train/logprobs = tensor([[-1.0841, -3.1682],
        [-1.1523, -1.4085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575279176235199
Epoch 0, Step 1173: train/loss = 0.32906171679496765, train/raw-loss = 0.30082568526268005, train/logprobs = tensor([[-0.7156, -5.4444],
        [-1.6219, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282360315322876
Epoch 0, Step 1174: train/loss = 0.36479684710502625, train/raw-loss = 0.337782621383667, train/logprobs = tensor([[-1.3400, -5.6040],
        [-1.7683, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27014198899269104
Epoch 0, Step 1175: train/loss = 0.45122000575065613, train/raw-loss = 0.42838695645332336, train/logprobs = tensor([[-1.0443, -4.2077],
        [-1.2094, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22833023965358734
Epoch 0, Step 1176: train/loss = 0.46445387601852417, train/raw-loss = 0.43957507610321045, train/logprobs = tensor([[-0.9899, -1.6252],
        [-1.7715, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2487880289554596
Epoch 0, Step 1177: train/loss = 0.254449725151062, train/raw-loss = 0.22575390338897705, train/logprobs = tensor([[-0.8255, -6.0541],
        [-1.8235, -1.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869582176208496
Epoch 0, Step 1178: train/loss = 0.47955846786499023, train/raw-loss = 0.45579013228416443, train/logprobs = tensor([[-0.8455, -1.9614],
        [-1.1620, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2376834601163864
Epoch 0, Step 1179: train/loss = 0.4894040524959564, train/raw-loss = 0.46696358919143677, train/logprobs = tensor([[-0.9197, -3.9359],
        [-0.9741, -0.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22440461814403534
Epoch 0, Step 1180: train/loss = 0.44454413652420044, train/raw-loss = 0.4206578731536865, train/logprobs = tensor([[-0.8455, -2.7529],
        [-1.2849, -0.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23886239528656006
Epoch 0, Step 1181: train/loss = 0.5317383408546448, train/raw-loss = 0.5056506991386414, train/logprobs = tensor([[-0.9824, -2.0922],
        [-1.2985, -0.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2608761787414551
Epoch 0, Step 1182: train/loss = 0.5035690665245056, train/raw-loss = 0.4753705859184265, train/logprobs = tensor([[-1.3017, -2.2316],
        [-1.9426, -1.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819850444793701
Epoch 0, Step 1183: train/loss = 0.3117372393608093, train/raw-loss = 0.28602057695388794, train/logprobs = tensor([[-0.8295, -5.6673],
        [-1.6189, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25716692209243774
Epoch 0, Step 1184: train/loss = 0.6470896005630493, train/raw-loss = 0.6250959038734436, train/logprobs = tensor([[-0.6020, -0.9048],
        [-0.6851, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21993640065193176
Epoch 0, Step 1185: train/loss = 0.37988102436065674, train/raw-loss = 0.35920000076293945, train/logprobs = tensor([[-0.7164, -3.3606],
        [-0.9933, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2068101018667221
Epoch 0, Step 1186: train/loss = 0.5031423568725586, train/raw-loss = 0.4815576672554016, train/logprobs = tensor([[-0.9097, -2.4964],
        [-1.0111, -0.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21584680676460266
Epoch 0, Step 1187: train/loss = 0.38389885425567627, train/raw-loss = 0.36127811670303345, train/logprobs = tensor([[-0.8603, -2.8299],
        [-1.4451, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22620739042758942
Epoch 0, Step 1188: train/loss = 0.5333081483840942, train/raw-loss = 0.5109386444091797, train/logprobs = tensor([[-0.9702, -2.0275],
        [-1.1046, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236953228712082
Epoch 0, Step 1189: train/loss = 0.537311315536499, train/raw-loss = 0.516954243183136, train/logprobs = tensor([[-0.5971, -2.5283],
        [-0.9547, -0.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20357109606266022
Epoch 0, Step 1190: train/loss = 0.46034103631973267, train/raw-loss = 0.4326847195625305, train/logprobs = tensor([[-0.9872, -2.3681],
        [-1.6872, -1.4684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27656304836273193
Epoch 0, Step 1191: train/loss = 0.5587036609649658, train/raw-loss = 0.5339077115058899, train/logprobs = tensor([[-1.0692, -1.9518],
        [-1.3034, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24795952439308167
Epoch 0, Step 1192: train/loss = 0.32263046503067017, train/raw-loss = 0.297590434551239, train/logprobs = tensor([[-0.9736, -3.0124],
        [-1.3845, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504003047943115
Epoch 0, Step 1193: train/loss = 0.44557303190231323, train/raw-loss = 0.4198514521121979, train/logprobs = tensor([[-1.2758, -5.0294],
        [-1.7406, -0.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25721579790115356
Epoch 0, Step 1194: train/loss = 0.4126344919204712, train/raw-loss = 0.3896341621875763, train/logprobs = tensor([[-0.6534, -3.0760],
        [-0.9396, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23000365495681763
Epoch 0, Step 1195: train/loss = 0.5855132341384888, train/raw-loss = 0.5621048808097839, train/logprobs = tensor([[-1.3435, -2.0482],
        [-1.2764, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23408402502536774
Epoch 0, Step 1196: train/loss = 0.45920106768608093, train/raw-loss = 0.4382997155189514, train/logprobs = tensor([[-0.7695, -1.9983],
        [-1.3203, -0.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2090139389038086
Epoch 0, Step 1197: train/loss = 0.7791102528572083, train/raw-loss = 0.7567784190177917, train/logprobs = tensor([[-1.2768, -1.1164],
        [-1.0418, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.223318412899971
Epoch 0, Step 1198: train/loss = 0.7313686013221741, train/raw-loss = 0.7068322896957397, train/logprobs = tensor([[-1.2892, -1.3319],
        [-1.0607, -1.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.245363250374794
Epoch 0, Step 1199: train/loss = 0.4852864146232605, train/raw-loss = 0.45937496423721313, train/logprobs = tensor([[-0.8078, -2.2257],
        [-1.3605, -1.3354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591148614883423
Epoch 0, Step 1200: train/loss = 0.4273216426372528, train/raw-loss = 0.3996126353740692, train/logprobs = tensor([[-1.7217, -4.4026],
        [-1.5500, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770901024341583
Epoch 0, Step 1201: train/loss = 0.4105623662471771, train/raw-loss = 0.3796937167644501, train/logprobs = tensor([[-0.9219, -3.0370],
        [-1.5534, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086863160133362
Epoch 0, Step 1202: train/loss = 0.48539113998413086, train/raw-loss = 0.4572658836841583, train/logprobs = tensor([[-0.7800, -1.9970],
        [-1.2680, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28125250339508057
Epoch 0, Step 1203: train/loss = 0.4537358283996582, train/raw-loss = 0.4307710528373718, train/logprobs = tensor([[-0.8189, -1.9400],
        [-1.7741, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22964750230312347
Epoch 0, Step 1204: train/loss = 0.4533889889717102, train/raw-loss = 0.4300191402435303, train/logprobs = tensor([[-0.6499, -2.3198],
        [-0.8417, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23369857668876648
Epoch 0, Step 1205: train/loss = 0.4499504268169403, train/raw-loss = 0.4250714182853699, train/logprobs = tensor([[-1.0130, -3.8891],
        [-1.8864, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24879004061222076
Epoch 0, Step 1206: train/loss = 0.5195783972740173, train/raw-loss = 0.4974481165409088, train/logprobs = tensor([[-0.7675, -1.3034],
        [-1.3583, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22130292654037476
Epoch 0, Step 1207: train/loss = 0.3936830163002014, train/raw-loss = 0.3706669211387634, train/logprobs = tensor([[-1.0022, -5.9049],
        [-1.6470, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23016107082366943
Epoch 0, Step 1208: train/loss = 0.5090228319168091, train/raw-loss = 0.49037930369377136, train/logprobs = tensor([[-0.7719, -3.3312],
        [-0.7755, -1.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18643516302108765
Epoch 0, Step 1209: train/loss = 0.38437312841415405, train/raw-loss = 0.35780560970306396, train/logprobs = tensor([[-0.7103, -4.2633],
        [-1.6938, -0.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26567500829696655
Epoch 0, Step 1210: train/loss = 0.49075955152511597, train/raw-loss = 0.46338585019111633, train/logprobs = tensor([[-1.1975, -4.0372],
        [-1.3023, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27373671531677246
Epoch 0, Step 1211: train/loss = 0.47879666090011597, train/raw-loss = 0.4532085359096527, train/logprobs = tensor([[-0.5411, -2.0484],
        [-1.0508, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558812201023102
Epoch 0, Step 1212: train/loss = 0.5330062508583069, train/raw-loss = 0.5116424560546875, train/logprobs = tensor([[-0.8784, -3.3168],
        [-1.3034, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2136380672454834
Epoch 0, Step 1213: train/loss = 0.269672155380249, train/raw-loss = 0.240462526679039, train/logprobs = tensor([[-1.3743, -3.4913],
        [-2.1821, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920962870121002
Epoch 0, Step 1214: train/loss = 0.5297234654426575, train/raw-loss = 0.5018987655639648, train/logprobs = tensor([[-1.1630, -2.3065],
        [-1.7980, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782473564147949
Epoch 0, Step 1215: train/loss = 0.5324758887290955, train/raw-loss = 0.5114449858665466, train/logprobs = tensor([[-1.1956, -3.0318],
        [-1.2675, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21030910313129425
Epoch 0, Step 1216: train/loss = 0.46479523181915283, train/raw-loss = 0.4439503848552704, train/logprobs = tensor([[-0.5450, -3.2552],
        [-1.0551, -0.4919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20844808220863342
Epoch 0, Step 1217: train/loss = 0.38755297660827637, train/raw-loss = 0.36371198296546936, train/logprobs = tensor([[-0.8819, -3.2709],
        [-1.1650, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23841021955013275
Epoch 0, Step 1218: train/loss = 0.46139800548553467, train/raw-loss = 0.4360741972923279, train/logprobs = tensor([[-1.4287, -3.9725],
        [-1.4687, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532384693622589
Epoch 0, Step 1219: train/loss = 0.6547453999519348, train/raw-loss = 0.6305083632469177, train/logprobs = tensor([[-0.5973, -1.0668],
        [-0.9588, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24237000942230225
Epoch 0, Step 1220: train/loss = 0.6849520206451416, train/raw-loss = 0.662247896194458, train/logprobs = tensor([[-1.1735, -1.9279],
        [-0.7806, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2270410656929016
Epoch 0, Step 1221: train/loss = 0.19520798325538635, train/raw-loss = 0.1702268421649933, train/logprobs = tensor([[-0.9498, -4.8400],
        [-2.0007, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24981148540973663
Epoch 0, Step 1222: train/loss = 0.45365655422210693, train/raw-loss = 0.4237358570098877, train/logprobs = tensor([[-1.2182, -3.8577],
        [-1.7778, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992073893547058
Epoch 0, Step 1223: train/loss = 0.47085437178611755, train/raw-loss = 0.449965238571167, train/logprobs = tensor([[-0.8231, -2.9451],
        [-0.8842, -0.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088913917541504
Epoch 0, Step 1224: train/loss = 0.41475510597229004, train/raw-loss = 0.38854289054870605, train/logprobs = tensor([[-1.4748, -4.1431],
        [-2.1020, -2.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26212185621261597
Epoch 0, Step 1225: train/loss = 0.39886799454689026, train/raw-loss = 0.37554430961608887, train/logprobs = tensor([[-0.7270, -3.1841],
        [-1.3967, -0.4791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233236625790596
Epoch 0, Step 1226: train/loss = 0.42369815707206726, train/raw-loss = 0.39872002601623535, train/logprobs = tensor([[-0.6989, -2.6122],
        [-1.9011, -1.0753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24978108704090118
Epoch 0, Step 1227: train/loss = 0.37479767203330994, train/raw-loss = 0.3462207317352295, train/logprobs = tensor([[-0.7470, -7.0362],
        [-1.7930, -0.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28576940298080444
Epoch 0, Step 1228: train/loss = 0.5483605265617371, train/raw-loss = 0.5296538472175598, train/logprobs = tensor([[-0.7817, -1.5562],
        [-1.0810, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18706658482551575
Epoch 0, Step 1229: train/loss = 0.43697720766067505, train/raw-loss = 0.4124923646450043, train/logprobs = tensor([[-0.7510, -2.7414],
        [-1.4383, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24484869837760925
Epoch 0, Step 1230: train/loss = 0.6276208162307739, train/raw-loss = 0.603010892868042, train/logprobs = tensor([[-0.7929, -1.0334],
        [-1.0974, -0.9034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24609896540641785
Epoch 0, Step 1231: train/loss = 0.48790284991264343, train/raw-loss = 0.46272796392440796, train/logprobs = tensor([[-0.9095, -2.9029],
        [-1.2782, -1.3557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517489194869995
Epoch 0, Step 1232: train/loss = 0.655556321144104, train/raw-loss = 0.6289620399475098, train/logprobs = tensor([[-0.9130, -1.3486],
        [-0.8989, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26594263315200806
Epoch 0, Step 1233: train/loss = 0.38769322633743286, train/raw-loss = 0.36480897665023804, train/logprobs = tensor([[-0.6381, -2.7514],
        [-1.2348, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22884269058704376
Epoch 0, Step 1234: train/loss = 0.4672276973724365, train/raw-loss = 0.43943554162979126, train/logprobs = tensor([[-0.7817, -1.8551],
        [-1.6870, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27792200446128845
Epoch 0, Step 1235: train/loss = 0.5134428143501282, train/raw-loss = 0.4896262586116791, train/logprobs = tensor([[-1.4223, -2.7997],
        [-1.3411, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23816537857055664
Epoch 0, Step 1236: train/loss = 0.582534909248352, train/raw-loss = 0.563906192779541, train/logprobs = tensor([[-0.8477, -0.8344],
        [-1.0663, -0.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1862867772579193
Epoch 0, Step 1237: train/loss = 0.47888627648353577, train/raw-loss = 0.45516225695610046, train/logprobs = tensor([[-0.8380, -2.8123],
        [-1.4786, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23724016547203064
Epoch 0, Step 1238: train/loss = 0.4499766528606415, train/raw-loss = 0.42148277163505554, train/logprobs = tensor([[-1.1799, -2.6750],
        [-1.9088, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.284938782453537
Epoch 0, Step 1239: train/loss = 0.4556748867034912, train/raw-loss = 0.42751964926719666, train/logprobs = tensor([[-0.6709, -2.9579],
        [-1.5538, -1.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2815525531768799
Epoch 0, Step 1240: train/loss = 0.41541609168052673, train/raw-loss = 0.38523221015930176, train/logprobs = tensor([[-0.9121, -2.9070],
        [-1.9280, -1.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30183881521224976
Epoch 0, Step 1241: train/loss = 0.26559221744537354, train/raw-loss = 0.24076220393180847, train/logprobs = tensor([[-0.9550, -6.0296],
        [-1.6332, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24830029904842377
Epoch 0, Step 1242: train/loss = 0.30888715386390686, train/raw-loss = 0.2820393741130829, train/logprobs = tensor([[-0.8659, -4.6908],
        [-1.6004, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26847782731056213
Epoch 0, Step 1243: train/loss = 0.6091278791427612, train/raw-loss = 0.5854641199111938, train/logprobs = tensor([[-0.8442, -1.8834],
        [-1.0617, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23663762211799622
Epoch 0, Step 1244: train/loss = 0.5292679667472839, train/raw-loss = 0.5049474239349365, train/logprobs = tensor([[-0.7017, -1.9695],
        [-1.0845, -1.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24320538341999054
Epoch 0, Step 1245: train/loss = 0.5861881375312805, train/raw-loss = 0.5594176650047302, train/logprobs = tensor([[-0.6334, -1.0782],
        [-1.5373, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2677050232887268
Epoch 0, Step 1246: train/loss = 0.4382815957069397, train/raw-loss = 0.41352370381355286, train/logprobs = tensor([[-1.0890, -4.6702],
        [-1.1961, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24757876992225647
Epoch 0, Step 1247: train/loss = 0.4690166115760803, train/raw-loss = 0.44050246477127075, train/logprobs = tensor([[-0.9432, -2.7074],
        [-1.5494, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851417660713196
Epoch 0, Step 1248: train/loss = 0.4273343086242676, train/raw-loss = 0.4013553261756897, train/logprobs = tensor([[-1.3768, -4.8530],
        [-1.8945, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25978976488113403
Epoch 0, Step 1249: train/loss = 0.2651534378528595, train/raw-loss = 0.23816457390785217, train/logprobs = tensor([[-0.8614, -4.8156],
        [-1.9216, -0.3965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26988881826400757
Epoch 0, Step 1250: train/loss = 0.2766788601875305, train/raw-loss = 0.2511724531650543, train/logprobs = tensor([[-0.7585, -2.8983],
        [-2.1084, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550639808177948
Epoch 0, Step 1251: train/loss = 0.3437700867652893, train/raw-loss = 0.31852859258651733, train/logprobs = tensor([[-0.8767, -5.5959],
        [-1.5686, -2.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25241491198539734
Epoch 0, Step 1252: train/loss = 0.5855057239532471, train/raw-loss = 0.5647724866867065, train/logprobs = tensor([[-0.7674, -3.4547],
        [-0.9721, -2.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20733234286308289
Epoch 0, Step 1253: train/loss = 0.36611825227737427, train/raw-loss = 0.34459906816482544, train/logprobs = tensor([[-0.6522, -2.7840],
        [-1.3564, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21519175171852112
Epoch 0, Step 1254: train/loss = 0.5090104341506958, train/raw-loss = 0.4826642870903015, train/logprobs = tensor([[-1.4210, -2.4684],
        [-1.4982, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634619474411011
Epoch 0, Step 1255: train/loss = 0.40617114305496216, train/raw-loss = 0.3821197748184204, train/logprobs = tensor([[-0.7195, -3.0477],
        [-1.7480, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24051359295845032
Epoch 0, Step 1256: train/loss = 0.5279843807220459, train/raw-loss = 0.5018259882926941, train/logprobs = tensor([[-1.2481, -2.5967],
        [-1.7939, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26158350706100464
Epoch 0, Step 1257: train/loss = 0.3076748251914978, train/raw-loss = 0.2829294502735138, train/logprobs = tensor([[-0.9884, -7.0059],
        [-1.7570, -1.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24745367467403412
Epoch 0, Step 1258: train/loss = 0.4896959662437439, train/raw-loss = 0.45783692598342896, train/logprobs = tensor([[-0.7106, -2.2812],
        [-1.6838, -0.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3185906410217285
Epoch 0, Step 1259: train/loss = 0.34058478474617004, train/raw-loss = 0.3128422498703003, train/logprobs = tensor([[-0.6702, -4.2847],
        [-1.8721, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2774254381656647
Epoch 0, Step 1260: train/loss = 0.3507274389266968, train/raw-loss = 0.3214905858039856, train/logprobs = tensor([[-0.8543, -2.9470],
        [-1.9692, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29236823320388794
Epoch 0, Step 1261: train/loss = 0.7124571800231934, train/raw-loss = 0.68471360206604, train/logprobs = tensor([[-0.6333, -1.2695],
        [-1.3331, -1.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27743661403656006
Epoch 0, Step 1262: train/loss = 0.4494312107563019, train/raw-loss = 0.4261988699436188, train/logprobs = tensor([[-0.8362, -4.0423],
        [-1.2011, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2323235124349594
Epoch 0, Step 1263: train/loss = 0.5183424949645996, train/raw-loss = 0.48918670415878296, train/logprobs = tensor([[-0.6526, -2.1877],
        [-1.3217, -1.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291557639837265
Epoch 0, Step 1264: train/loss = 0.5118473768234253, train/raw-loss = 0.48398545384407043, train/logprobs = tensor([[-0.9804, -4.2401],
        [-1.4458, -1.0761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27861887216567993
Epoch 0, Step 1265: train/loss = 0.5121062397956848, train/raw-loss = 0.48958784341812134, train/logprobs = tensor([[-0.5808, -1.9610],
        [-0.8443, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22518420219421387
Epoch 0, Step 1266: train/loss = 0.24943965673446655, train/raw-loss = 0.22122034430503845, train/logprobs = tensor([[-0.9783, -4.8921],
        [-2.1879, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28219300508499146
Epoch 0, Step 1267: train/loss = 0.1857137233018875, train/raw-loss = 0.1540079116821289, train/logprobs = tensor([[-0.9998, -5.0194],
        [-2.3625, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31705814599990845
Epoch 0, Step 1268: train/loss = 0.4305157959461212, train/raw-loss = 0.4069058299064636, train/logprobs = tensor([[-0.6976, -5.1182],
        [-1.2344, -1.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2360997200012207
Epoch 0, Step 1269: train/loss = 0.5501426458358765, train/raw-loss = 0.5247184038162231, train/logprobs = tensor([[-1.6476, -5.5447],
        [-1.2674, -1.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542415261268616
Epoch 0, Step 1270: train/loss = 0.5862548351287842, train/raw-loss = 0.5660537481307983, train/logprobs = tensor([[-0.6688, -1.1709],
        [-0.9085, -0.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20201098918914795
Epoch 0, Step 1271: train/loss = 0.5982187986373901, train/raw-loss = 0.5743526220321655, train/logprobs = tensor([[-0.6457, -1.4190],
        [-1.0132, -0.8999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23866185545921326
Epoch 0, Step 1272: train/loss = 0.6909393668174744, train/raw-loss = 0.6635874509811401, train/logprobs = tensor([[-0.8215, -1.1855],
        [-1.2431, -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2735191881656647
Epoch 0, Step 1273: train/loss = 0.30203384160995483, train/raw-loss = 0.2778469920158386, train/logprobs = tensor([[-0.7319, -4.3906],
        [-1.1754, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2418683022260666
Epoch 0, Step 1274: train/loss = 0.4538489580154419, train/raw-loss = 0.42480528354644775, train/logprobs = tensor([[-0.8404, -1.9315],
        [-1.4992, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29043692350387573
Epoch 0, Step 1275: train/loss = 0.4559842348098755, train/raw-loss = 0.4330711364746094, train/logprobs = tensor([[-1.0498, -2.4968],
        [-1.6324, -1.3307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22913111746311188
Epoch 0, Step 1276: train/loss = 0.5512151718139648, train/raw-loss = 0.5259537696838379, train/logprobs = tensor([[-0.9589, -1.4836],
        [-1.3809, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526136040687561
Epoch 0, Step 1277: train/loss = 0.5975126028060913, train/raw-loss = 0.5708568692207336, train/logprobs = tensor([[-1.3908, -2.2723],
        [-1.5862, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26655682921409607
Epoch 0, Step 1278: train/loss = 0.5430907011032104, train/raw-loss = 0.5178046226501465, train/logprobs = tensor([[-1.1317, -1.6556],
        [-1.6331, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2528602182865143
Epoch 0, Step 1279: train/loss = 0.6004568338394165, train/raw-loss = 0.5728055238723755, train/logprobs = tensor([[-1.1041, -2.3230],
        [-1.3307, -1.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27651336789131165
Epoch 0, Step 1280: train/loss = 0.4140644073486328, train/raw-loss = 0.3881871998310089, train/logprobs = tensor([[-0.7889, -1.5908],
        [-1.9327, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.258772075176239
Epoch 0, Step 1281: train/loss = 0.646560788154602, train/raw-loss = 0.6200030446052551, train/logprobs = tensor([[-0.7236, -0.9688],
        [-0.9668, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655774652957916
Epoch 0, Step 1282: train/loss = 0.4061484932899475, train/raw-loss = 0.384919136762619, train/logprobs = tensor([[-0.8910, -4.9967],
        [-1.5372, -1.7862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122936248779297
Epoch 0, Step 1283: train/loss = 0.5515488982200623, train/raw-loss = 0.5261937975883484, train/logprobs = tensor([[-0.7244, -1.7096],
        [-1.3573, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25355154275894165
Epoch 0, Step 1284: train/loss = 0.6559911966323853, train/raw-loss = 0.6348263025283813, train/logprobs = tensor([[-0.8133, -1.4485],
        [-0.6202, -0.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21164870262145996
Epoch 0, Step 1285: train/loss = 0.631733238697052, train/raw-loss = 0.6090741753578186, train/logprobs = tensor([[-0.7073, -1.0539],
        [-1.0420, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22659070789813995
Epoch 0, Step 1286: train/loss = 0.5597546696662903, train/raw-loss = 0.5308718085289001, train/logprobs = tensor([[-1.0739, -1.8882],
        [-1.3567, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28882870078086853
Epoch 0, Step 1287: train/loss = 0.5996115803718567, train/raw-loss = 0.5710052251815796, train/logprobs = tensor([[-0.8163, -1.5995],
        [-1.4157, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860640287399292
Epoch 0, Step 1288: train/loss = 0.5723774433135986, train/raw-loss = 0.5520804524421692, train/logprobs = tensor([[-0.6321, -1.1771],
        [-0.7706, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20297007262706757
Epoch 0, Step 1289: train/loss = 0.49490121006965637, train/raw-loss = 0.47346359491348267, train/logprobs = tensor([[-0.5784, -2.6053],
        [-0.9500, -1.2592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2143758088350296
Epoch 0, Step 1290: train/loss = 0.29168882966041565, train/raw-loss = 0.2685742974281311, train/logprobs = tensor([[-0.7042, -3.6986],
        [-1.6137, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23114508390426636
Epoch 0, Step 1291: train/loss = 0.5189381837844849, train/raw-loss = 0.4954102337360382, train/logprobs = tensor([[-0.6024, -1.9640],
        [-1.4303, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23527923226356506
Epoch 0, Step 1292: train/loss = 0.5379977226257324, train/raw-loss = 0.5139515995979309, train/logprobs = tensor([[-0.7209, -1.2440],
        [-1.1255, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24046142399311066
Epoch 0, Step 1293: train/loss = 0.5364490747451782, train/raw-loss = 0.5101935863494873, train/logprobs = tensor([[-0.6737, -2.4907],
        [-1.3516, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26255470514297485
Epoch 0, Step 1294: train/loss = 0.4403255581855774, train/raw-loss = 0.4149961471557617, train/logprobs = tensor([[-1.2240, -1.4499],
        [-2.2758, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2532941997051239
Epoch 0, Step 1295: train/loss = 0.44493868947029114, train/raw-loss = 0.42178091406822205, train/logprobs = tensor([[-1.2102, -3.3383],
        [-1.6773, -0.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23157748579978943
Epoch 0, Step 1296: train/loss = 0.6668076515197754, train/raw-loss = 0.6477314233779907, train/logprobs = tensor([[-0.5782, -0.7777],
        [-0.5822, -0.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1907624453306198
Epoch 0, Step 1297: train/loss = 0.6558340787887573, train/raw-loss = 0.6351566910743713, train/logprobs = tensor([[-1.2775, -1.9467],
        [-0.9963, -1.1018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2067740261554718
Epoch 0, Step 1298: train/loss = 0.2503259778022766, train/raw-loss = 0.22442728281021118, train/logprobs = tensor([[-0.9803, -4.4127],
        [-2.0568, -1.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25898677110671997
Epoch 0, Step 1299: train/loss = 0.5974308252334595, train/raw-loss = 0.5716782808303833, train/logprobs = tensor([[-0.6474, -1.7758],
        [-1.2281, -1.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575252056121826
Epoch 0, Step 1300: train/loss = 0.4809473156929016, train/raw-loss = 0.4530317783355713, train/logprobs = tensor([[-0.7593, -2.7853],
        [-1.8385, -1.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2791551947593689
Epoch 0, Step 1301: train/loss = 0.6183265447616577, train/raw-loss = 0.5918872356414795, train/logprobs = tensor([[-0.7975, -2.9278],
        [-2.0137, -1.4832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643930912017822
Epoch 0, Step 1302: train/loss = 0.599032461643219, train/raw-loss = 0.5730230808258057, train/logprobs = tensor([[-0.9699, -1.6079],
        [-1.2488, -1.2268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2600938081741333
Epoch 0, Step 1303: train/loss = 0.24999472498893738, train/raw-loss = 0.22027437388896942, train/logprobs = tensor([[-0.9918, -4.3431],
        [-2.4642, -1.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29720360040664673
Epoch 0, Step 1304: train/loss = 0.7389312386512756, train/raw-loss = 0.7149925231933594, train/logprobs = tensor([[-1.3352, -1.4723],
        [-1.2881, -1.2909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23938697576522827
Epoch 0, Step 1305: train/loss = 0.4390338063240051, train/raw-loss = 0.41547295451164246, train/logprobs = tensor([[-0.6446, -3.3164],
        [-1.3265, -1.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2356085479259491
Epoch 0, Step 1306: train/loss = 0.5481629371643066, train/raw-loss = 0.5230391621589661, train/logprobs = tensor([[-0.9013, -2.3549],
        [-1.1097, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512376606464386
Epoch 0, Step 1307: train/loss = 0.4341772198677063, train/raw-loss = 0.4085948169231415, train/logprobs = tensor([[-0.7436, -3.8225],
        [-1.4279, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2558238208293915
Epoch 0, Step 1308: train/loss = 0.4412549138069153, train/raw-loss = 0.4157765805721283, train/logprobs = tensor([[-0.6498, -3.2260],
        [-1.4143, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547835111618042
Epoch 0, Step 1309: train/loss = 0.4100457429885864, train/raw-loss = 0.38286077976226807, train/logprobs = tensor([[-0.8040, -4.0003],
        [-1.7191, -2.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2718498706817627
Epoch 0, Step 1310: train/loss = 0.6332224607467651, train/raw-loss = 0.6066606640815735, train/logprobs = tensor([[-1.3886, -2.6926],
        [-1.4410, -1.7296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26561805605888367
Epoch 0, Step 1311: train/loss = 0.32898837327957153, train/raw-loss = 0.3023180067539215, train/logprobs = tensor([[-0.7826, -4.2810],
        [-1.7994, -1.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26670390367507935
Epoch 0, Step 1312: train/loss = 0.4439409375190735, train/raw-loss = 0.41928911209106445, train/logprobs = tensor([[-0.6854, -3.0461],
        [-1.2972, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24651852250099182
Epoch 0, Step 1313: train/loss = 0.668052077293396, train/raw-loss = 0.6439508199691772, train/logprobs = tensor([[-0.8655, -1.9010],
        [-1.0385, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24101245403289795
Epoch 0, Step 1314: train/loss = 0.27516019344329834, train/raw-loss = 0.24785494804382324, train/logprobs = tensor([[ -0.6508, -10.3734],
        [ -2.0912,  -1.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730526626110077
Epoch 0, Step 1315: train/loss = 0.5363687872886658, train/raw-loss = 0.5137597918510437, train/logprobs = tensor([[-0.6719, -2.2398],
        [-1.6098, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22609004378318787
Epoch 0, Step 1316: train/loss = 0.4887002408504486, train/raw-loss = 0.461497038602829, train/logprobs = tensor([[-0.8073, -3.0441],
        [-1.5679, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720320224761963
Epoch 0, Step 1317: train/loss = 0.6555772423744202, train/raw-loss = 0.6323820352554321, train/logprobs = tensor([[-0.9020, -1.0010],
        [-1.0570, -0.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2319522202014923
Epoch 0, Step 1318: train/loss = 0.47867053747177124, train/raw-loss = 0.456864595413208, train/logprobs = tensor([[-0.7799, -1.8564],
        [-0.8222, -0.3874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21805979311466217
Epoch 0, Step 1319: train/loss = 0.5984458923339844, train/raw-loss = 0.5731204748153687, train/logprobs = tensor([[-0.8260, -1.1429],
        [-1.7976, -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25325432419776917
Epoch 0, Step 1320: train/loss = 0.5039668679237366, train/raw-loss = 0.48374924063682556, train/logprobs = tensor([[-0.6180, -2.5992],
        [-0.8417, -1.4621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20217663049697876
Epoch 0, Step 1321: train/loss = 0.33371517062187195, train/raw-loss = 0.30920764803886414, train/logprobs = tensor([[-0.7866, -6.8658],
        [-1.6390, -2.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24507541954517365
Epoch 0, Step 1322: train/loss = 0.36212530732154846, train/raw-loss = 0.337476909160614, train/logprobs = tensor([[-0.8849, -3.5549],
        [-1.4283, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24648381769657135
Epoch 0, Step 1323: train/loss = 0.29299694299697876, train/raw-loss = 0.26598796248435974, train/logprobs = tensor([[-0.8575, -4.1464],
        [-1.9157, -0.7776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27008989453315735
Epoch 0, Step 1324: train/loss = 0.7219368815422058, train/raw-loss = 0.7011929750442505, train/logprobs = tensor([[-1.4402, -1.3811],
        [-1.5514, -1.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20743852853775024
Epoch 0, Step 1325: train/loss = 0.4133255183696747, train/raw-loss = 0.38638707995414734, train/logprobs = tensor([[-0.7207, -3.8797],
        [-1.9126, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26938411593437195
Epoch 0, Step 1326: train/loss = 0.5923457145690918, train/raw-loss = 0.5628969073295593, train/logprobs = tensor([[-0.6814, -2.1218],
        [-1.9212, -1.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29448843002319336
Epoch 0, Step 1327: train/loss = 0.4807664155960083, train/raw-loss = 0.45652809739112854, train/logprobs = tensor([[-0.7170, -3.1615],
        [-1.2877, -1.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24238303303718567
Epoch 0, Step 1328: train/loss = 0.6097275614738464, train/raw-loss = 0.5870670080184937, train/logprobs = tensor([[-0.5549, -0.9850],
        [-1.0391, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22660604119300842
Epoch 0, Step 1329: train/loss = 0.5731384754180908, train/raw-loss = 0.5479460954666138, train/logprobs = tensor([[-0.9337, -2.0199],
        [-1.5412, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25192371010780334
Epoch 0, Step 1330: train/loss = 0.4145335257053375, train/raw-loss = 0.38871878385543823, train/logprobs = tensor([[-1.3005, -2.7188],
        [-2.0776, -1.1835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25814729928970337
Epoch 0, Step 1331: train/loss = 0.6623740196228027, train/raw-loss = 0.6412433981895447, train/logprobs = tensor([[-0.5999, -0.9236],
        [-0.7520, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21130654215812683
Epoch 0, Step 1332: train/loss = 0.5475994348526001, train/raw-loss = 0.5240670442581177, train/logprobs = tensor([[-0.7562, -2.4080],
        [-0.9650, -1.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23532427847385406
Epoch 0, Step 1333: train/loss = 0.3295137286186218, train/raw-loss = 0.3082793056964874, train/logprobs = tensor([[-0.5838, -3.0740],
        [-1.0768, -1.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21234431862831116
Epoch 0, Step 1334: train/loss = 0.6525876522064209, train/raw-loss = 0.6315011978149414, train/logprobs = tensor([[-0.8443, -1.0858],
        [-0.7482, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21086448431015015
Epoch 0, Step 1335: train/loss = 0.3683817982673645, train/raw-loss = 0.34083181619644165, train/logprobs = tensor([[-0.7484, -4.2997],
        [-2.0640, -0.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27550002932548523
Epoch 0, Step 1336: train/loss = 0.4018592834472656, train/raw-loss = 0.3808254301548004, train/logprobs = tensor([[-0.7666, -4.2474],
        [-1.2339, -0.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21033871173858643
Epoch 0, Step 1337: train/loss = 0.43977946043014526, train/raw-loss = 0.4158514738082886, train/logprobs = tensor([[-0.9818, -3.1129],
        [-1.5123, -1.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23927994072437286
Epoch 0, Step 1338: train/loss = 0.7042124271392822, train/raw-loss = 0.6834268569946289, train/logprobs = tensor([[-0.6929, -1.0058],
        [-0.5775, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2078554332256317
Epoch 0, Step 1339: train/loss = 0.34870418906211853, train/raw-loss = 0.3217182755470276, train/logprobs = tensor([[-0.7335, -4.2598],
        [-1.5445, -1.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698590159416199
Epoch 0, Step 1340: train/loss = 0.4631463885307312, train/raw-loss = 0.4342038631439209, train/logprobs = tensor([[-0.7481, -4.7591],
        [-1.4484, -1.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894251346588135
Epoch 0, Step 1341: train/loss = 0.5174237489700317, train/raw-loss = 0.49212172627449036, train/logprobs = tensor([[-0.9153, -2.4304],
        [-1.4556, -1.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530202865600586
Epoch 0, Step 1342: train/loss = 0.5397348403930664, train/raw-loss = 0.5165020823478699, train/logprobs = tensor([[-0.9161, -1.2409],
        [-1.2817, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23232808709144592
Epoch 0, Step 1343: train/loss = 0.6930970549583435, train/raw-loss = 0.6730100512504578, train/logprobs = tensor([[-0.5891, -0.6136],
        [-0.5952, -0.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20087020099163055
Epoch 0, Step 1344: train/loss = 0.6208074688911438, train/raw-loss = 0.5991618633270264, train/logprobs = tensor([[-1.2693, -2.8802],
        [-0.9677, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21645593643188477
Epoch 0, Step 1345: train/loss = 0.3587353825569153, train/raw-loss = 0.3294242024421692, train/logprobs = tensor([[-0.9504, -3.1821],
        [-2.2575, -2.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931120693683624
Epoch 0, Step 1346: train/loss = 0.3498833179473877, train/raw-loss = 0.32029271125793457, train/logprobs = tensor([[-0.8531, -6.0331],
        [-2.2030, -2.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.295906126499176
Epoch 0, Step 1347: train/loss = 0.5972893238067627, train/raw-loss = 0.5734202265739441, train/logprobs = tensor([[-0.8895, -1.5921],
        [-1.0603, -0.9926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2386910319328308
Epoch 0, Step 1348: train/loss = 0.39483168721199036, train/raw-loss = 0.36706218123435974, train/logprobs = tensor([[-0.8429, -3.1568],
        [-2.2028, -1.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2776947617530823
Epoch 0, Step 1349: train/loss = 0.6646565198898315, train/raw-loss = 0.6363905072212219, train/logprobs = tensor([[-0.5928, -0.7114],
        [-1.5240, -1.2226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28266000747680664
Epoch 0, Step 1350: train/loss = 0.5361766219139099, train/raw-loss = 0.5115830302238464, train/logprobs = tensor([[-1.4475, -4.1199],
        [-1.6615, -1.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24593590199947357
Epoch 0, Step 1351: train/loss = 0.5677496790885925, train/raw-loss = 0.54674232006073, train/logprobs = tensor([[-1.1608, -1.6777],
        [-1.3942, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21007367968559265
Epoch 0, Step 1352: train/loss = 0.4083530902862549, train/raw-loss = 0.378442645072937, train/logprobs = tensor([[-1.0662, -2.6758],
        [-2.0236, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29910457134246826
Epoch 0, Step 1353: train/loss = 0.23787221312522888, train/raw-loss = 0.21232879161834717, train/logprobs = tensor([[-0.6012, -6.1910],
        [-1.5459, -2.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25543421506881714
Epoch 0, Step 1354: train/loss = 0.4355452060699463, train/raw-loss = 0.40374770760536194, train/logprobs = tensor([[-1.1735, -2.5619],
        [-2.7448, -1.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179748058319092
Epoch 0, Step 1355: train/loss = 0.2701806426048279, train/raw-loss = 0.24104830622673035, train/logprobs = tensor([[-0.7244, -7.9639],
        [-2.2089, -1.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913232743740082
Epoch 0, Step 1356: train/loss = 0.18865779042243958, train/raw-loss = 0.15922465920448303, train/logprobs = tensor([[-0.7664, -5.4825],
        [-2.4232, -2.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29433131217956543
Epoch 0, Step 1357: train/loss = 0.475970059633255, train/raw-loss = 0.4481502175331116, train/logprobs = tensor([[-1.0766, -1.5365],
        [-2.1468, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781982123851776
Epoch 0, Step 1358: train/loss = 0.45094776153564453, train/raw-loss = 0.4248150885105133, train/logprobs = tensor([[-0.7985, -1.8146],
        [-1.5939, -0.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2613266408443451
Epoch 0, Step 1359: train/loss = 0.589118480682373, train/raw-loss = 0.5658391714096069, train/logprobs = tensor([[-0.6753, -1.4181],
        [-1.7133, -1.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23279285430908203
Epoch 0, Step 1360: train/loss = 0.16824579238891602, train/raw-loss = 0.139239102602005, train/logprobs = tensor([[-0.7816, -5.2168],
        [-2.2299, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2900668978691101
Epoch 0, Step 1361: train/loss = 0.5126931071281433, train/raw-loss = 0.4858955442905426, train/logprobs = tensor([[-0.8760, -2.2440],
        [-1.6203, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679755687713623
Epoch 0, Step 1362: train/loss = 0.37064167857170105, train/raw-loss = 0.3460209369659424, train/logprobs = tensor([[-1.0923, -2.9691],
        [-1.8062, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24620741605758667
Epoch 0, Step 1363: train/loss = 0.5012519359588623, train/raw-loss = 0.47480306029319763, train/logprobs = tensor([[-0.9694, -2.6384],
        [-1.3684, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644888162612915
Epoch 0, Step 1364: train/loss = 0.45105111598968506, train/raw-loss = 0.42465758323669434, train/logprobs = tensor([[-0.9483, -2.5473],
        [-1.7895, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639355957508087
Epoch 0, Step 1365: train/loss = 0.5254122018814087, train/raw-loss = 0.49519696831703186, train/logprobs = tensor([[-1.1235, -2.3477],
        [-1.9925, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30215200781822205
Epoch 0, Step 1366: train/loss = 0.34074923396110535, train/raw-loss = 0.3115815818309784, train/logprobs = tensor([[-1.0458, -3.9409],
        [-2.2143, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29167622327804565
Epoch 0, Step 1367: train/loss = 0.38966697454452515, train/raw-loss = 0.36642634868621826, train/logprobs = tensor([[-0.6027, -3.0948],
        [-1.3805, -0.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23240655660629272
Epoch 0, Step 1368: train/loss = 0.3910178542137146, train/raw-loss = 0.3702199459075928, train/logprobs = tensor([[-0.6122, -3.7088],
        [-0.9579, -1.3021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20797908306121826
Epoch 0, Step 1369: train/loss = 0.23905324935913086, train/raw-loss = 0.21338413655757904, train/logprobs = tensor([[-0.7081, -4.4744],
        [-1.9702, -1.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566910982131958
Epoch 0, Step 1370: train/loss = 0.384905606508255, train/raw-loss = 0.35660451650619507, train/logprobs = tensor([[-0.8407, -4.6020],
        [-1.5421, -1.3993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2830108404159546
Epoch 0, Step 1371: train/loss = 0.4497094452381134, train/raw-loss = 0.4233623147010803, train/logprobs = tensor([[-0.6584, -1.7626],
        [-1.8942, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26347094774246216
Epoch 0, Step 1372: train/loss = 0.5614826083183289, train/raw-loss = 0.5364624857902527, train/logprobs = tensor([[-0.4482, -1.9926],
        [-1.2201, -1.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25020110607147217
Epoch 0, Step 1373: train/loss = 0.6003625392913818, train/raw-loss = 0.5716390609741211, train/logprobs = tensor([[-2.2854, -4.6596],
        [-1.9434, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28723520040512085
Epoch 0, Step 1374: train/loss = 0.5868385434150696, train/raw-loss = 0.5639482140541077, train/logprobs = tensor([[-0.4489, -1.2826],
        [-0.8242, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22890353202819824
Epoch 0, Step 1375: train/loss = 0.16062365472316742, train/raw-loss = 0.13143977522850037, train/logprobs = tensor([[-0.9848, -6.4787],
        [-2.5032, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29183870553970337
Epoch 0, Step 1376: train/loss = 0.431371808052063, train/raw-loss = 0.4029919505119324, train/logprobs = tensor([[-0.9498, -4.0334],
        [-2.1008, -1.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.283798485994339
Epoch 0, Step 1377: train/loss = 0.41277754306793213, train/raw-loss = 0.3892884850502014, train/logprobs = tensor([[-0.6779, -4.7057],
        [-1.2179, -1.5212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2348908931016922
Epoch 0, Step 1378: train/loss = 0.33726251125335693, train/raw-loss = 0.310282826423645, train/logprobs = tensor([[-0.7847, -2.2411],
        [-1.8291, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697969675064087
Epoch 0, Step 1379: train/loss = 0.6989017724990845, train/raw-loss = 0.6715686917304993, train/logprobs = tensor([[-0.9838, -1.1948],
        [-1.3747, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2733308672904968
Epoch 0, Step 1380: train/loss = 0.5532744526863098, train/raw-loss = 0.5312041640281677, train/logprobs = tensor([[-0.5949, -2.9324],
        [-0.8094, -0.4772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22070248425006866
Epoch 0, Step 1381: train/loss = 0.5233231782913208, train/raw-loss = 0.504358172416687, train/logprobs = tensor([[-0.5094, -1.7762],
        [-0.6777, -0.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18964998424053192
Epoch 0, Step 1382: train/loss = 0.6163453459739685, train/raw-loss = 0.5963453054428101, train/logprobs = tensor([[-0.6783, -1.2093],
        [-0.7560, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20000052452087402
Epoch 0, Step 1383: train/loss = 0.624494194984436, train/raw-loss = 0.5979965925216675, train/logprobs = tensor([[-1.2829, -1.6207],
        [-1.5730, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26497554779052734
Epoch 0, Step 1384: train/loss = 0.43825602531433105, train/raw-loss = 0.41249895095825195, train/logprobs = tensor([[-0.8049, -1.9245],
        [-1.5853, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25757068395614624
Epoch 0, Step 1385: train/loss = 0.5868895053863525, train/raw-loss = 0.5663251876831055, train/logprobs = tensor([[-0.5258, -1.6963],
        [-0.8867, -0.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20564323663711548
Epoch 0, Step 1386: train/loss = 0.5795949697494507, train/raw-loss = 0.5528055429458618, train/logprobs = tensor([[-1.2871, -2.0494],
        [-1.4680, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2678949236869812
Epoch 0, Step 1387: train/loss = 0.311719685792923, train/raw-loss = 0.28275835514068604, train/logprobs = tensor([[-0.8245, -5.5629],
        [-2.0994, -1.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896132171154022
Epoch 0, Step 1388: train/loss = 0.4854138195514679, train/raw-loss = 0.45409685373306274, train/logprobs = tensor([[-1.1188, -2.1550],
        [-2.0227, -1.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31316953897476196
Epoch 0, Step 1389: train/loss = 0.35495442152023315, train/raw-loss = 0.3262178599834442, train/logprobs = tensor([[-0.9574, -3.3035],
        [-2.3826, -0.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873654067516327
Epoch 0, Step 1390: train/loss = 0.48059993982315063, train/raw-loss = 0.451701819896698, train/logprobs = tensor([[-1.0876, -2.6374],
        [-1.8173, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2889814078807831
Epoch 0, Step 1391: train/loss = 0.487048864364624, train/raw-loss = 0.45991751551628113, train/logprobs = tensor([[-1.0249, -2.3276],
        [-1.9948, -1.3888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713135778903961
Epoch 0, Step 1392: train/loss = 0.5324452519416809, train/raw-loss = 0.5093638896942139, train/logprobs = tensor([[-0.4700, -0.8924],
        [-1.5983, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23081354796886444
Epoch 0, Step 1393: train/loss = 0.4687899351119995, train/raw-loss = 0.4376252591609955, train/logprobs = tensor([[-1.0292, -2.0416],
        [-2.8252, -1.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116464614868164
Epoch 0, Step 1394: train/loss = 0.4532521963119507, train/raw-loss = 0.4280719459056854, train/logprobs = tensor([[-0.5410, -1.7877],
        [-1.1721, -0.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518024444580078
Epoch 0, Step 1395: train/loss = 0.6741787195205688, train/raw-loss = 0.6489118933677673, train/logprobs = tensor([[-0.6817, -1.2481],
        [-1.3216, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526687979698181
Epoch 0, Step 1396: train/loss = 0.5055442452430725, train/raw-loss = 0.4749857783317566, train/logprobs = tensor([[-0.8663, -1.1037],
        [-2.4912, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30558428168296814
Epoch 0, Step 1397: train/loss = 0.6458724737167358, train/raw-loss = 0.6237996816635132, train/logprobs = tensor([[-0.8077, -1.1904],
        [-1.2117, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2207287847995758
Epoch 0, Step 1398: train/loss = 0.7346671223640442, train/raw-loss = 0.712868332862854, train/logprobs = tensor([[-1.2240, -1.1470],
        [-1.0267, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2179880142211914
Epoch 0, Step 1399: train/loss = 0.2207789123058319, train/raw-loss = 0.19543978571891785, train/logprobs = tensor([[-1.0330, -7.2362],
        [-3.0102, -0.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533912658691406
Epoch 0, Step 1400: train/loss = 0.41320472955703735, train/raw-loss = 0.38702988624572754, train/logprobs = tensor([[-0.8503, -3.6345],
        [-1.6803, -1.3841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2617482542991638
Epoch 0, Step 1401: train/loss = 0.5145099759101868, train/raw-loss = 0.4900813400745392, train/logprobs = tensor([[-0.8188, -2.5688],
        [-1.3479, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24428629875183105
Epoch 0, Step 1402: train/loss = 0.6887462735176086, train/raw-loss = 0.6677727103233337, train/logprobs = tensor([[-0.5921, -0.6217],
        [-0.6760, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20973578095436096
Epoch 0, Step 1403: train/loss = 0.42211437225341797, train/raw-loss = 0.3939962685108185, train/logprobs = tensor([[-0.8493, -3.4515],
        [-2.2387, -0.7461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811810374259949
Epoch 0, Step 1404: train/loss = 0.49379962682724, train/raw-loss = 0.46652936935424805, train/logprobs = tensor([[-0.8926, -2.9014],
        [-2.0969, -0.8287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727022171020508
Epoch 0, Step 1405: train/loss = 0.474830687046051, train/raw-loss = 0.4492131173610687, train/logprobs = tensor([[-0.8541, -2.5914],
        [-1.8270, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561761438846588
Epoch 0, Step 1406: train/loss = 0.25651219487190247, train/raw-loss = 0.22929242253303528, train/logprobs = tensor([[-0.7010, -4.2319],
        [-2.1274, -1.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2721976637840271
Epoch 0, Step 1407: train/loss = 0.5090844035148621, train/raw-loss = 0.4845908582210541, train/logprobs = tensor([[-0.5158, -1.4384],
        [-1.6844, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24493539333343506
Epoch 0, Step 1408: train/loss = 0.5269264578819275, train/raw-loss = 0.501426100730896, train/logprobs = tensor([[-1.0789, -2.8580],
        [-1.2795, -1.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25500378012657166
Epoch 0, Step 1409: train/loss = 0.6158206462860107, train/raw-loss = 0.5947455167770386, train/logprobs = tensor([[-0.7123, -1.3011],
        [-0.8929, -0.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210750550031662
Epoch 0, Step 1410: train/loss = 0.49043935537338257, train/raw-loss = 0.4648236036300659, train/logprobs = tensor([[-0.8557, -1.8537],
        [-1.5883, -1.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25615760684013367
Epoch 0, Step 1411: train/loss = 0.3235580325126648, train/raw-loss = 0.29496270418167114, train/logprobs = tensor([[-0.8957, -2.9674],
        [-2.0061, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28595325350761414
Epoch 0, Step 1412: train/loss = 0.5873227715492249, train/raw-loss = 0.5603793859481812, train/logprobs = tensor([[-0.7167, -1.6878],
        [-1.3686, -1.5221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2694340646266937
Epoch 0, Step 1413: train/loss = 0.4486413598060608, train/raw-loss = 0.4216538667678833, train/logprobs = tensor([[-0.7307, -3.9856],
        [-1.2961, -1.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26987528800964355
Epoch 0, Step 1414: train/loss = 0.5670084357261658, train/raw-loss = 0.5402497053146362, train/logprobs = tensor([[-0.7186, -2.2822],
        [-1.8158, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26758745312690735
Epoch 0, Step 1415: train/loss = 0.31326088309288025, train/raw-loss = 0.28323060274124146, train/logprobs = tensor([[-0.8338, -3.9331],
        [-2.7501, -2.2118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003029227256775
Epoch 0, Step 1416: train/loss = 0.4046412408351898, train/raw-loss = 0.38156506419181824, train/logprobs = tensor([[-0.9850, -2.8102],
        [-1.3970, -1.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076140880584717
Epoch 0, Step 1417: train/loss = 0.5081050992012024, train/raw-loss = 0.4810321033000946, train/logprobs = tensor([[-0.6499, -1.4241],
        [-1.4886, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.270729660987854
Epoch 0, Step 1418: train/loss = 0.49709898233413696, train/raw-loss = 0.47046539187431335, train/logprobs = tensor([[-0.9096, -1.7837],
        [-1.6834, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2663359045982361
Epoch 0, Step 1419: train/loss = 0.5418804287910461, train/raw-loss = 0.5084369778633118, train/logprobs = tensor([[-1.0803, -4.6606],
        [-2.1733, -1.6390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344341516494751
Epoch 0, Step 1420: train/loss = 0.47494029998779297, train/raw-loss = 0.4510740637779236, train/logprobs = tensor([[-1.7700, -3.1942],
        [-2.1140, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23866264522075653
Epoch 0, Step 1421: train/loss = 0.5774921774864197, train/raw-loss = 0.5464071035385132, train/logprobs = tensor([[-1.2748, -3.3191],
        [-1.7100, -1.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108508288860321
Epoch 0, Step 1422: train/loss = 0.5862739086151123, train/raw-loss = 0.5595366954803467, train/logprobs = tensor([[-0.9632, -1.4772],
        [-1.0828, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26737257838249207
Epoch 0, Step 1423: train/loss = 0.3729504346847534, train/raw-loss = 0.34682250022888184, train/logprobs = tensor([[-1.5263, -6.1100],
        [-1.9667, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612793445587158
Epoch 0, Step 1424: train/loss = 0.515144407749176, train/raw-loss = 0.49004030227661133, train/logprobs = tensor([[-1.0034, -2.7550],
        [-1.5326, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.251041054725647
Epoch 0, Step 1425: train/loss = 0.4085769057273865, train/raw-loss = 0.38099974393844604, train/logprobs = tensor([[-0.7147, -3.7856],
        [-1.7966, -1.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757715880870819
Epoch 0, Step 1426: train/loss = 0.7743234038352966, train/raw-loss = 0.7487286329269409, train/logprobs = tensor([[-2.1779, -2.6312],
        [-1.6240, -1.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559477686882019
Epoch 0, Step 1427: train/loss = 0.522616982460022, train/raw-loss = 0.4952264428138733, train/logprobs = tensor([[-0.9556, -3.1913],
        [-1.9996, -1.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.273904949426651
Epoch 0, Step 1428: train/loss = 0.32108274102211, train/raw-loss = 0.29050377011299133, train/logprobs = tensor([[-0.8326, -3.6139],
        [-1.8494, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3057897686958313
Epoch 0, Step 1429: train/loss = 0.606139063835144, train/raw-loss = 0.5817955732345581, train/logprobs = tensor([[-0.9890, -2.1798],
        [-1.0370, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24343492090702057
Epoch 0, Step 1430: train/loss = 0.6053275465965271, train/raw-loss = 0.5787403583526611, train/logprobs = tensor([[-1.3565, -2.8461],
        [-1.2434, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658720314502716
Epoch 0, Step 1431: train/loss = 0.2588930130004883, train/raw-loss = 0.22709819674491882, train/logprobs = tensor([[-0.5949, -4.1070],
        [-2.3163, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179481625556946
Epoch 0, Step 1432: train/loss = 0.3844268023967743, train/raw-loss = 0.3596891164779663, train/logprobs = tensor([[-0.9653, -2.6312],
        [-1.6952, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2473764717578888
Epoch 0, Step 1433: train/loss = 0.3707978129386902, train/raw-loss = 0.3446122109889984, train/logprobs = tensor([[-0.7885, -2.5666],
        [-1.9023, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618560791015625
Epoch 0, Step 1434: train/loss = 0.47083550691604614, train/raw-loss = 0.4412323236465454, train/logprobs = tensor([[-0.9438, -2.4025],
        [-1.3846, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960315942764282
Epoch 0, Step 1435: train/loss = 0.6917169690132141, train/raw-loss = 0.6690813302993774, train/logprobs = tensor([[-0.6277, -0.7794],
        [-1.0707, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22635595500469208
Epoch 0, Step 1436: train/loss = 0.4160960912704468, train/raw-loss = 0.3899086117744446, train/logprobs = tensor([[-1.2480, -4.8748],
        [-1.7561, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618746757507324
Epoch 0, Step 1437: train/loss = 0.5650953650474548, train/raw-loss = 0.5392131209373474, train/logprobs = tensor([[-0.7178, -1.1884],
        [-1.6467, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2588229179382324
Epoch 0, Step 1438: train/loss = 0.43853288888931274, train/raw-loss = 0.4055464267730713, train/logprobs = tensor([[-1.0018, -2.1456],
        [-2.4155, -1.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3298642039299011
Epoch 0, Step 1439: train/loss = 0.20195415616035461, train/raw-loss = 0.1750238984823227, train/logprobs = tensor([[-1.1584, -5.1823],
        [-2.8391, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693025767803192
Epoch 0, Step 1440: train/loss = 0.29014742374420166, train/raw-loss = 0.2575690448284149, train/logprobs = tensor([[-0.6261, -4.8400],
        [-2.5623, -0.8862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3257838189601898
Epoch 0, Step 1441: train/loss = 0.38772332668304443, train/raw-loss = 0.3571467697620392, train/logprobs = tensor([[-1.2429, -3.7907],
        [-2.2895, -1.3105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3057655692100525
Epoch 0, Step 1442: train/loss = 0.306852787733078, train/raw-loss = 0.27964693307876587, train/logprobs = tensor([[-0.5652, -2.9774],
        [-1.5425, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27205878496170044
Epoch 0, Step 1443: train/loss = 0.2619761824607849, train/raw-loss = 0.23596365749835968, train/logprobs = tensor([[-0.6216, -2.9903],
        [-2.3352, -0.8429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601253390312195
Epoch 0, Step 1444: train/loss = 0.4907391667366028, train/raw-loss = 0.4632188677787781, train/logprobs = tensor([[-0.6581, -2.7085],
        [-1.4797, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27520298957824707
Epoch 0, Step 1445: train/loss = 0.20158980786800385, train/raw-loss = 0.1658126413822174, train/logprobs = tensor([[-0.9635, -4.4581],
        [-3.4299, -1.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3577716052532196
Epoch 0, Step 1446: train/loss = 0.565444827079773, train/raw-loss = 0.5431712865829468, train/logprobs = tensor([[-0.7871, -1.5578],
        [-1.4196, -1.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22273577749729156
Epoch 0, Step 1447: train/loss = 0.5036624073982239, train/raw-loss = 0.473671019077301, train/logprobs = tensor([[-0.8175, -2.9264],
        [-1.8698, -1.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2999141216278076
Epoch 0, Step 1448: train/loss = 0.6816450357437134, train/raw-loss = 0.6577540636062622, train/logprobs = tensor([[-0.7891, -0.9329],
        [-1.0787, -1.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23890991508960724
Epoch 0, Step 1449: train/loss = 0.46364688873291016, train/raw-loss = 0.44320952892303467, train/logprobs = tensor([[-1.0183, -4.1234],
        [-1.5539, -0.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2043735682964325
Epoch 0, Step 1450: train/loss = 0.40783828496932983, train/raw-loss = 0.37825649976730347, train/logprobs = tensor([[-0.7433, -2.7052],
        [-2.0297, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29581812024116516
Epoch 0, Step 1451: train/loss = 0.49532485008239746, train/raw-loss = 0.47512122988700867, train/logprobs = tensor([[-0.8616, -3.6155],
        [-1.5171, -1.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20203620195388794
Epoch 0, Step 1452: train/loss = 0.38598698377609253, train/raw-loss = 0.352083295583725, train/logprobs = tensor([[-0.8999, -2.3635],
        [-3.3301, -1.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390366733074188
Epoch 0, Step 1453: train/loss = 0.3806436359882355, train/raw-loss = 0.3596988320350647, train/logprobs = tensor([[-0.5545, -1.9927],
        [-1.4902, -0.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20944824814796448
Epoch 0, Step 1454: train/loss = 0.41813069581985474, train/raw-loss = 0.39159372448921204, train/logprobs = tensor([[-1.0827, -4.1015],
        [-2.1749, -2.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653697729110718
Epoch 0, Step 1455: train/loss = 0.44498947262763977, train/raw-loss = 0.4162771999835968, train/logprobs = tensor([[-0.6319, -1.7454],
        [-1.4972, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871224284172058
Epoch 0, Step 1456: train/loss = 0.570214569568634, train/raw-loss = 0.5479053258895874, train/logprobs = tensor([[-0.6543, -1.1021],
        [-1.4430, -1.1528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22309260070323944
Epoch 0, Step 1457: train/loss = 0.6192483901977539, train/raw-loss = 0.5914275050163269, train/logprobs = tensor([[-1.5825, -3.1277],
        [-1.7109, -1.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27820903062820435
Epoch 0, Step 1458: train/loss = 0.7019327878952026, train/raw-loss = 0.6753249168395996, train/logprobs = tensor([[-1.3850, -1.3494],
        [-1.4635, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.266079306602478
Epoch 0, Step 1459: train/loss = 0.7630348801612854, train/raw-loss = 0.7343172430992126, train/logprobs = tensor([[-0.7530, -0.6901],
        [-1.4832, -1.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28717559576034546
Epoch 0, Step 1460: train/loss = 0.5085902810096741, train/raw-loss = 0.4787669777870178, train/logprobs = tensor([[-0.8284, -1.6544],
        [-2.0323, -1.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29823338985443115
Epoch 0, Step 1461: train/loss = 0.33929187059402466, train/raw-loss = 0.31177690625190735, train/logprobs = tensor([[-0.8173, -4.6050],
        [-2.0065, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27515003085136414
Epoch 0, Step 1462: train/loss = 0.39313989877700806, train/raw-loss = 0.3666665852069855, train/logprobs = tensor([[-0.8058, -2.7798],
        [-1.7365, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26473304629325867
Epoch 0, Step 1463: train/loss = 0.2631293833255768, train/raw-loss = 0.2312818318605423, train/logprobs = tensor([[-0.9865, -5.6636],
        [-3.2990, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184754252433777
Epoch 0, Step 1464: train/loss = 0.5199453830718994, train/raw-loss = 0.4938843250274658, train/logprobs = tensor([[-0.6840, -3.5698],
        [-1.7201, -2.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26061081886291504
Epoch 0, Step 1465: train/loss = 0.2784651517868042, train/raw-loss = 0.25455212593078613, train/logprobs = tensor([[-0.5505, -6.1098],
        [-1.4155, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23913004994392395
Epoch 0, Step 1466: train/loss = 0.7012618184089661, train/raw-loss = 0.6750028133392334, train/logprobs = tensor([[-0.8597, -1.5601],
        [-1.3042, -1.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2625899910926819
Epoch 0, Step 1467: train/loss = 0.4855855107307434, train/raw-loss = 0.45947447419166565, train/logprobs = tensor([[-1.4570, -6.8522],
        [-1.4134, -1.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26111024618148804
Epoch 0, Step 1468: train/loss = 0.35899755358695984, train/raw-loss = 0.3332267105579376, train/logprobs = tensor([[-0.7830, -2.6911],
        [-2.5384, -1.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25770848989486694
Epoch 0, Step 1469: train/loss = 0.5774306654930115, train/raw-loss = 0.5546183586120605, train/logprobs = tensor([[-0.7837, -2.4370],
        [-1.1382, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22812330722808838
Epoch 0, Step 1470: train/loss = 0.5034642219543457, train/raw-loss = 0.4810071885585785, train/logprobs = tensor([[-0.8512, -3.3381],
        [-1.1136, -0.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22457045316696167
Epoch 0, Step 1471: train/loss = 0.4245087504386902, train/raw-loss = 0.3919997811317444, train/logprobs = tensor([[-0.6125, -4.7529],
        [-2.2007, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250899016857147
Epoch 0, Step 1472: train/loss = 0.26319828629493713, train/raw-loss = 0.23507879674434662, train/logprobs = tensor([[-0.7691, -4.4715],
        [-1.8701, -0.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28119486570358276
Epoch 0, Step 1473: train/loss = 0.37906381487846375, train/raw-loss = 0.3496039807796478, train/logprobs = tensor([[-0.7334, -4.1572],
        [-2.0335, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945983409881592
Epoch 0, Step 1474: train/loss = 0.5440136194229126, train/raw-loss = 0.5234289169311523, train/logprobs = tensor([[-0.7447, -1.5507],
        [-1.3217, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20584726333618164
Epoch 0, Step 1475: train/loss = 0.5184973478317261, train/raw-loss = 0.49062198400497437, train/logprobs = tensor([[-0.7415, -1.1521],
        [-1.6618, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787536084651947
Epoch 0, Step 1476: train/loss = 0.5331853628158569, train/raw-loss = 0.49241119623184204, train/logprobs = tensor([[-0.9704, -2.1844],
        [-3.0158, -2.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40774163603782654
Epoch 0, Step 1477: train/loss = 0.33188408613204956, train/raw-loss = 0.3010110557079315, train/logprobs = tensor([[-0.5544, -3.4578],
        [-1.7681, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3087303042411804
Epoch 0, Step 1478: train/loss = 0.6239694356918335, train/raw-loss = 0.6008939146995544, train/logprobs = tensor([[-0.8610, -1.3394],
        [-0.7832, -0.6807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2307557612657547
Epoch 0, Step 1479: train/loss = 0.5172712206840515, train/raw-loss = 0.48955610394477844, train/logprobs = tensor([[-0.7975, -2.5145],
        [-2.5322, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27715128660202026
Epoch 0, Step 1480: train/loss = 0.3915184736251831, train/raw-loss = 0.3658589720726013, train/logprobs = tensor([[-0.6824, -5.6258],
        [-1.5295, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25659483671188354
Epoch 0, Step 1481: train/loss = 0.6188439726829529, train/raw-loss = 0.593652606010437, train/logprobs = tensor([[-0.7613, -1.3962],
        [-1.0738, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25191420316696167
Epoch 0, Step 1482: train/loss = 0.3843604326248169, train/raw-loss = 0.3542550802230835, train/logprobs = tensor([[-0.8446, -1.6420],
        [-3.0186, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30105334520339966
Epoch 0, Step 1483: train/loss = 0.41632986068725586, train/raw-loss = 0.3949275016784668, train/logprobs = tensor([[-0.8219, -3.8903],
        [-1.4850, -1.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2140233963727951
Epoch 0, Step 1484: train/loss = 0.4670596718788147, train/raw-loss = 0.4399968683719635, train/logprobs = tensor([[-1.0339, -3.4466],
        [-1.4529, -2.2191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27062806487083435
Epoch 0, Step 1485: train/loss = 0.40684565901756287, train/raw-loss = 0.3739337921142578, train/logprobs = tensor([[-0.7791, -3.2685],
        [-2.3257, -1.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291189670562744
Epoch 0, Step 1486: train/loss = 0.4874240756034851, train/raw-loss = 0.4591098427772522, train/logprobs = tensor([[-0.9490, -1.9080],
        [-1.8911, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831421196460724
Epoch 0, Step 1487: train/loss = 0.3459469676017761, train/raw-loss = 0.3210805654525757, train/logprobs = tensor([[-0.8763, -7.6819],
        [-1.4576, -1.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24866405129432678
Epoch 0, Step 1488: train/loss = 0.5846210718154907, train/raw-loss = 0.5606156587600708, train/logprobs = tensor([[-0.8675, -1.3400],
        [-1.6808, -1.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240054190158844
Epoch 0, Step 1489: train/loss = 0.4891754984855652, train/raw-loss = 0.45695969462394714, train/logprobs = tensor([[-1.0913, -1.7455],
        [-2.2623, -1.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32215800881385803
Epoch 0, Step 1490: train/loss = 0.5180146098136902, train/raw-loss = 0.4921710193157196, train/logprobs = tensor([[-0.7497, -2.1387],
        [-1.4390, -1.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2584356665611267
Epoch 0, Step 1491: train/loss = 0.45958855748176575, train/raw-loss = 0.4312324523925781, train/logprobs = tensor([[-0.5836, -2.0086],
        [-2.0625, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2835611402988434
Epoch 0, Step 1492: train/loss = 0.5169470906257629, train/raw-loss = 0.4866977334022522, train/logprobs = tensor([[-1.0309, -2.9184],
        [-2.9781, -2.4583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3024935722351074
Epoch 0, Step 1493: train/loss = 0.42432835698127747, train/raw-loss = 0.40205591917037964, train/logprobs = tensor([[-0.8081, -5.7799],
        [-1.3125, -2.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22272437810897827
Epoch 0, Step 1494: train/loss = 0.4559515118598938, train/raw-loss = 0.4345293343067169, train/logprobs = tensor([[-0.7626, -2.2578],
        [-0.9896, -0.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21422147750854492
Epoch 0, Step 1495: train/loss = 0.5579386949539185, train/raw-loss = 0.5317926406860352, train/logprobs = tensor([[-0.7419, -2.7661],
        [-1.4144, -2.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614601254463196
Epoch 0, Step 1496: train/loss = 0.4577552080154419, train/raw-loss = 0.4324609041213989, train/logprobs = tensor([[-1.5458, -2.6906],
        [-2.9188, -2.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529427409172058
Epoch 0, Step 1497: train/loss = 0.46751904487609863, train/raw-loss = 0.4351317882537842, train/logprobs = tensor([[-0.8224, -1.5435],
        [-2.3825, -1.3282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3238729238510132
Epoch 0, Step 1498: train/loss = 0.3405671715736389, train/raw-loss = 0.3160155117511749, train/logprobs = tensor([[-0.7529, -3.7065],
        [-1.8588, -1.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2455165982246399
Epoch 0, Step 1499: train/loss = 0.4131354093551636, train/raw-loss = 0.38590705394744873, train/logprobs = tensor([[-1.2463, -4.5806],
        [-1.4843, -1.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272283673286438
Epoch 0, Step 1500: train/loss = 0.7336724996566772, train/raw-loss = 0.7061063051223755, train/logprobs = tensor([[-0.8827, -0.9686],
        [-1.0642, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2756618559360504
Epoch 0, Step 1501: train/loss = 0.6423290967941284, train/raw-loss = 0.6186832785606384, train/logprobs = tensor([[-0.8049, -0.8765],
        [-1.1289, -0.8622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23645851016044617
Epoch 0, Step 1502: train/loss = 0.34624579548835754, train/raw-loss = 0.3178724944591522, train/logprobs = tensor([[-0.8082, -3.6874],
        [-2.8317, -0.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28373268246650696
Epoch 0, Step 1503: train/loss = 0.2665625810623169, train/raw-loss = 0.24068713188171387, train/logprobs = tensor([[-0.7756, -7.4668],
        [-2.7283, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2587544023990631
Epoch 0, Step 1504: train/loss = 0.45678186416625977, train/raw-loss = 0.42914754152297974, train/logprobs = tensor([[-0.7341, -2.4274],
        [-1.7451, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27634352445602417
Epoch 0, Step 1505: train/loss = 0.3851105570793152, train/raw-loss = 0.35397493839263916, train/logprobs = tensor([[-1.2272, -5.6170],
        [-3.2851, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31135648488998413
Epoch 0, Step 1506: train/loss = 0.43115168809890747, train/raw-loss = 0.4070360064506531, train/logprobs = tensor([[-0.7875, -2.2445],
        [-1.4695, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24115687608718872
Epoch 0, Step 1507: train/loss = 0.372774600982666, train/raw-loss = 0.3402843177318573, train/logprobs = tensor([[-0.9507, -4.8394],
        [-3.1331, -1.4894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249029815196991
Epoch 0, Step 1508: train/loss = 0.39651063084602356, train/raw-loss = 0.3724813163280487, train/logprobs = tensor([[-1.1349, -2.2208],
        [-2.0945, -0.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24029314517974854
Epoch 0, Step 1509: train/loss = 0.8439226746559143, train/raw-loss = 0.8150818347930908, train/logprobs = tensor([[-0.8299, -1.2685],
        [-2.1172, -2.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288408100605011
Epoch 0, Step 1510: train/loss = 0.28381532430648804, train/raw-loss = 0.25925177335739136, train/logprobs = tensor([[-1.5937, -7.8901],
        [-2.5791, -1.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456357628107071
Epoch 0, Step 1511: train/loss = 0.24893474578857422, train/raw-loss = 0.21337831020355225, train/logprobs = tensor([[-0.8125, -3.7818],
        [-2.7229, -1.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35556429624557495
Epoch 0, Step 1512: train/loss = 0.6228784322738647, train/raw-loss = 0.5980647206306458, train/logprobs = tensor([[-2.6329, -3.3233],
        [-1.8139, -0.6677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24813681840896606
Epoch 0, Step 1513: train/loss = 0.33003711700439453, train/raw-loss = 0.2945673167705536, train/logprobs = tensor([[-1.6471, -3.9173],
        [-3.8721, -1.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.354698121547699
Epoch 0, Step 1514: train/loss = 0.5861138105392456, train/raw-loss = 0.5508419275283813, train/logprobs = tensor([[-0.8651, -2.7045],
        [-2.5789, -1.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527182340621948
Epoch 0, Step 1515: train/loss = 0.4042525291442871, train/raw-loss = 0.38028886914253235, train/logprobs = tensor([[-0.5581, -3.3911],
        [-1.2980, -2.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23963649570941925
Epoch 0, Step 1516: train/loss = 0.2896498441696167, train/raw-loss = 0.25921016931533813, train/logprobs = tensor([[-1.0658, -3.7431],
        [-2.6233, -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30439651012420654
Epoch 0, Step 1517: train/loss = 0.3602864742279053, train/raw-loss = 0.33759963512420654, train/logprobs = tensor([[-0.5036, -4.4096],
        [-1.0530, -2.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22686834633350372
Epoch 0, Step 1518: train/loss = 0.6943350434303284, train/raw-loss = 0.6646357774734497, train/logprobs = tensor([[-1.6365, -3.2872],
        [-1.9542, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29699236154556274
Epoch 0, Step 1519: train/loss = 0.4091070890426636, train/raw-loss = 0.38093438744544983, train/logprobs = tensor([[-0.5962, -3.3959],
        [-1.7108, -1.5378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817268669605255
Epoch 0, Step 1520: train/loss = 0.5230288505554199, train/raw-loss = 0.4967958331108093, train/logprobs = tensor([[-1.6672, -2.2876],
        [-1.8566, -0.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623298168182373
Epoch 0, Step 1521: train/loss = 0.6826769709587097, train/raw-loss = 0.659428060054779, train/logprobs = tensor([[-1.7349, -3.6081],
        [-1.0341, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23248907923698425
Epoch 0, Step 1522: train/loss = 0.7111814618110657, train/raw-loss = 0.6824942231178284, train/logprobs = tensor([[-0.6709, -1.1188],
        [-1.5607, -1.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868725061416626
Epoch 0, Step 1523: train/loss = 0.6596536040306091, train/raw-loss = 0.6341199278831482, train/logprobs = tensor([[-0.8000, -1.0709],
        [-1.4467, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25533708930015564
Epoch 0, Step 1524: train/loss = 0.42244672775268555, train/raw-loss = 0.39671847224235535, train/logprobs = tensor([[-0.6285, -3.8774],
        [-1.4145, -1.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257282018661499
Epoch 0, Step 1525: train/loss = 0.4793585240840912, train/raw-loss = 0.45249199867248535, train/logprobs = tensor([[-0.7238, -2.5058],
        [-1.5539, -1.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2686653733253479
Epoch 0, Step 1526: train/loss = 0.6536194086074829, train/raw-loss = 0.6238809823989868, train/logprobs = tensor([[-1.8986, -3.3395],
        [-2.5540, -1.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2973836362361908
Epoch 0, Step 1527: train/loss = 0.35292547941207886, train/raw-loss = 0.3248845934867859, train/logprobs = tensor([[-1.0250, -2.9033],
        [-2.0012, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804088890552521
Epoch 0, Step 1528: train/loss = 0.44415855407714844, train/raw-loss = 0.4220718741416931, train/logprobs = tensor([[-0.6906, -3.4524],
        [-1.7252, -1.0375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22086670994758606
Epoch 0, Step 1529: train/loss = 0.496016263961792, train/raw-loss = 0.47056278586387634, train/logprobs = tensor([[-1.0088, -5.0676],
        [-1.8205, -3.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25453484058380127
Epoch 0, Step 1530: train/loss = 0.7250149250030518, train/raw-loss = 0.6935166716575623, train/logprobs = tensor([[-1.9497, -2.3767],
        [-1.6656, -1.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31498244404792786
Epoch 0, Step 1531: train/loss = 0.5357752442359924, train/raw-loss = 0.5061286091804504, train/logprobs = tensor([[-0.9790, -3.0140],
        [-1.6141, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29646599292755127
Epoch 0, Step 1532: train/loss = 0.5828956365585327, train/raw-loss = 0.5575240850448608, train/logprobs = tensor([[-0.7122, -1.7063],
        [-1.1167, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25371527671813965
Epoch 0, Step 1533: train/loss = 0.4504111707210541, train/raw-loss = 0.42434197664260864, train/logprobs = tensor([[-0.6901, -1.6883],
        [-1.7334, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2606922388076782
Epoch 0, Step 1534: train/loss = 0.42413559556007385, train/raw-loss = 0.39550772309303284, train/logprobs = tensor([[-0.9187, -4.8606],
        [-1.5961, -2.2146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862785756587982
Epoch 0, Step 1535: train/loss = 0.34297364950180054, train/raw-loss = 0.31575167179107666, train/logprobs = tensor([[-1.2996, -3.8771],
        [-3.1863, -1.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27222007513046265
Epoch 0, Step 1536: train/loss = 0.44117769598960876, train/raw-loss = 0.4177496135234833, train/logprobs = tensor([[-1.0937, -1.9813],
        [-1.9774, -1.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23428091406822205
Epoch 0, Step 1537: train/loss = 0.5072219371795654, train/raw-loss = 0.4817501902580261, train/logprobs = tensor([[-1.0988, -2.8650],
        [-2.1229, -2.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547172009944916
Epoch 0, Step 1538: train/loss = 0.6866453886032104, train/raw-loss = 0.6536481380462646, train/logprobs = tensor([[-0.8727, -1.3806],
        [-2.7895, -1.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32997268438339233
Epoch 0, Step 1539: train/loss = 0.5314869284629822, train/raw-loss = 0.5071589946746826, train/logprobs = tensor([[-0.6964, -1.7002],
        [-1.4390, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24327929317951202
Epoch 0, Step 1540: train/loss = 0.5245973467826843, train/raw-loss = 0.5014199018478394, train/logprobs = tensor([[-1.0686, -3.7339],
        [-0.8911, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23177450895309448
Epoch 0, Step 1541: train/loss = 0.7621532678604126, train/raw-loss = 0.727247953414917, train/logprobs = tensor([[-1.6919, -2.2001],
        [-2.9907, -2.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490535318851471
Epoch 0, Step 1542: train/loss = 0.623720645904541, train/raw-loss = 0.5966202616691589, train/logprobs = tensor([[-0.7937, -4.2032],
        [-2.0376, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2710039019584656
Epoch 0, Step 1543: train/loss = 0.40294528007507324, train/raw-loss = 0.37929385900497437, train/logprobs = tensor([[-0.8264, -3.6163],
        [-1.7233, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23651444911956787
Epoch 0, Step 1544: train/loss = 0.6513755321502686, train/raw-loss = 0.6225029230117798, train/logprobs = tensor([[-0.6256, -1.0853],
        [-1.5104, -1.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.288725882768631
Epoch 0, Step 1545: train/loss = 0.43570318818092346, train/raw-loss = 0.4091852605342865, train/logprobs = tensor([[-1.0178, -4.9748],
        [-1.5992, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26517975330352783
Epoch 0, Step 1546: train/loss = 0.4350569248199463, train/raw-loss = 0.4098188281059265, train/logprobs = tensor([[-1.1134, -2.7528],
        [-1.9292, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523810565471649
Epoch 0, Step 1547: train/loss = 0.5562650561332703, train/raw-loss = 0.532088577747345, train/logprobs = tensor([[-0.8620, -1.7926],
        [-1.1725, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417648732662201
Epoch 0, Step 1548: train/loss = 0.3751741051673889, train/raw-loss = 0.3472750186920166, train/logprobs = tensor([[-0.6755, -3.9439],
        [-2.1817, -1.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27899110317230225
Epoch 0, Step 1549: train/loss = 0.7986128330230713, train/raw-loss = 0.7754200100898743, train/logprobs = tensor([[-1.0410, -1.2548],
        [-0.7250, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23192846775054932
Epoch 0, Step 1550: train/loss = 0.8114297389984131, train/raw-loss = 0.7887271642684937, train/logprobs = tensor([[-1.2143, -1.1066],
        [-1.0595, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2270258218050003
Epoch 0, Step 1551: train/loss = 0.6924570202827454, train/raw-loss = 0.667763352394104, train/logprobs = tensor([[-2.7140, -3.5674],
        [-2.3464, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24693727493286133
Epoch 0, Step 1552: train/loss = 0.4601059854030609, train/raw-loss = 0.42719852924346924, train/logprobs = tensor([[-0.8634, -2.4513],
        [-3.3575, -2.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290747106075287
Epoch 0, Step 1553: train/loss = 0.37966689467430115, train/raw-loss = 0.3529109060764313, train/logprobs = tensor([[-1.1566, -4.9456],
        [-1.5819, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26755988597869873
Epoch 0, Step 1554: train/loss = 0.4765118658542633, train/raw-loss = 0.4538952112197876, train/logprobs = tensor([[-0.7661, -2.7876],
        [-1.1956, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22616669535636902
Epoch 0, Step 1555: train/loss = 0.4071418046951294, train/raw-loss = 0.3791235685348511, train/logprobs = tensor([[-0.8709, -1.4723],
        [-2.8106, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801826000213623
Epoch 0, Step 1556: train/loss = 0.4662318825721741, train/raw-loss = 0.43489065766334534, train/logprobs = tensor([[-0.7502, -2.6044],
        [-2.3148, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3134121596813202
Epoch 0, Step 1557: train/loss = 0.38499927520751953, train/raw-loss = 0.3564300835132599, train/logprobs = tensor([[-0.5878, -3.2875],
        [-1.7493, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28569161891937256
Epoch 0, Step 1558: train/loss = 0.37198805809020996, train/raw-loss = 0.34428077936172485, train/logprobs = tensor([[-0.7960, -4.4854],
        [-2.2776, -1.6252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27707281708717346
Epoch 0, Step 1559: train/loss = 0.435471773147583, train/raw-loss = 0.40971139073371887, train/logprobs = tensor([[-0.6268, -4.2593],
        [-1.4341, -1.1916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576037645339966
Epoch 0, Step 1560: train/loss = 0.3972662091255188, train/raw-loss = 0.3708474934101105, train/logprobs = tensor([[-0.7779, -2.8255],
        [-2.1039, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641873061656952
Epoch 0, Step 1561: train/loss = 0.47753116488456726, train/raw-loss = 0.44737035036087036, train/logprobs = tensor([[-1.0437, -2.5076],
        [-2.2754, -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30160802602767944
Epoch 0, Step 1562: train/loss = 0.5519483685493469, train/raw-loss = 0.5289369821548462, train/logprobs = tensor([[-0.9110, -2.1879],
        [-1.8507, -1.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23011408746242523
Epoch 0, Step 1563: train/loss = 0.49498316645622253, train/raw-loss = 0.46524232625961304, train/logprobs = tensor([[-1.1008, -2.3995],
        [-2.5159, -2.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29740893840789795
Epoch 0, Step 1564: train/loss = 0.261387437582016, train/raw-loss = 0.23174087703227997, train/logprobs = tensor([[-0.9605, -3.9325],
        [-2.2977, -1.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964654564857483
Epoch 0, Step 1565: train/loss = 0.4047386050224304, train/raw-loss = 0.37063542008399963, train/logprobs = tensor([[-1.0905, -2.4274],
        [-2.5664, -1.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34103164076805115
Epoch 0, Step 1566: train/loss = 0.6738044023513794, train/raw-loss = 0.6424938440322876, train/logprobs = tensor([[-1.3934, -1.9233],
        [-1.6947, -1.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3131052255630493
Epoch 0, Step 1567: train/loss = 0.5394119024276733, train/raw-loss = 0.517062783241272, train/logprobs = tensor([[-1.1621, -3.4572],
        [-1.4474, -1.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234916388988495
Epoch 0, Step 1568: train/loss = 0.4793176054954529, train/raw-loss = 0.4516600966453552, train/logprobs = tensor([[-0.8272, -1.8575],
        [-1.6343, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27657490968704224
Epoch 0, Step 1569: train/loss = 0.5880472660064697, train/raw-loss = 0.5526881217956543, train/logprobs = tensor([[-0.8083, -1.9714],
        [-3.0731, -2.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3535912036895752
Epoch 0, Step 1570: train/loss = 0.42781150341033936, train/raw-loss = 0.3987618088722229, train/logprobs = tensor([[-0.5444, -1.9259],
        [-1.8803, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2904967665672302
Epoch 0, Step 1571: train/loss = 0.4416033923625946, train/raw-loss = 0.4116036295890808, train/logprobs = tensor([[-1.0039, -2.7631],
        [-2.7479, -1.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29999759793281555
Epoch 0, Step 1572: train/loss = 0.5559717416763306, train/raw-loss = 0.5261864066123962, train/logprobs = tensor([[-0.8893, -2.6109],
        [-2.2294, -1.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29785338044166565
Epoch 0, Step 1573: train/loss = 0.5958302021026611, train/raw-loss = 0.5710631012916565, train/logprobs = tensor([[-0.6869, -1.3865],
        [-1.2253, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24767114222049713
Epoch 0, Step 1574: train/loss = 0.3822983503341675, train/raw-loss = 0.35615843534469604, train/logprobs = tensor([[-0.9098, -3.4734],
        [-1.6536, -1.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26139917969703674
Epoch 0, Step 1575: train/loss = 0.5397710204124451, train/raw-loss = 0.5126919150352478, train/logprobs = tensor([[-1.4124, -4.9335],
        [-1.8630, -2.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27079111337661743
Epoch 0, Step 1576: train/loss = 0.6088165640830994, train/raw-loss = 0.5784299969673157, train/logprobs = tensor([[-0.9174, -2.0887],
        [-2.3832, -2.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3038657307624817
Epoch 0, Step 1577: train/loss = 0.3935142159461975, train/raw-loss = 0.36201366782188416, train/logprobs = tensor([[-0.6292, -2.7381],
        [-2.3113, -1.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150056302547455
Epoch 0, Step 1578: train/loss = 0.436204731464386, train/raw-loss = 0.4087800085544586, train/logprobs = tensor([[-0.7694, -2.5463],
        [-1.9386, -1.4235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27424752712249756
Epoch 0, Step 1579: train/loss = 0.2968835234642029, train/raw-loss = 0.2695184350013733, train/logprobs = tensor([[-1.0737, -3.9129],
        [-1.8865, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27365124225616455
Epoch 0, Step 1580: train/loss = 0.24944770336151123, train/raw-loss = 0.21968629956245422, train/logprobs = tensor([[-0.7421, -5.9387],
        [-2.1804, -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29761382937431335
Epoch 0, Step 1581: train/loss = 0.3958078920841217, train/raw-loss = 0.3636057376861572, train/logprobs = tensor([[-1.1989, -2.6950],
        [-2.5664, -1.7337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32202133536338806
Epoch 0, Step 1582: train/loss = 0.4431513547897339, train/raw-loss = 0.41704171895980835, train/logprobs = tensor([[-0.6942, -4.0332],
        [-1.2548, -1.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610960900783539
Epoch 0, Step 1583: train/loss = 0.28085392713546753, train/raw-loss = 0.2521653175354004, train/logprobs = tensor([[-0.5971, -3.0970],
        [-2.3442, -1.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868863344192505
Epoch 0, Step 1584: train/loss = 0.37395739555358887, train/raw-loss = 0.3443671464920044, train/logprobs = tensor([[-0.8519, -3.0806],
        [-2.2441, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959025502204895
Epoch 0, Step 1585: train/loss = 0.6205577850341797, train/raw-loss = 0.5966081619262695, train/logprobs = tensor([[-1.0551, -1.5584],
        [-1.4169, -1.2417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23949643969535828
Epoch 0, Step 1586: train/loss = 0.49119722843170166, train/raw-loss = 0.45679590106010437, train/logprobs = tensor([[-0.9316, -2.0889],
        [-2.1325, -1.8044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3440133035182953
Epoch 0, Step 1587: train/loss = 0.49742263555526733, train/raw-loss = 0.4715615510940552, train/logprobs = tensor([[-1.0856, -2.7495],
        [-1.7574, -1.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25861087441444397
Epoch 0, Step 1588: train/loss = 0.563474714756012, train/raw-loss = 0.5379753708839417, train/logprobs = tensor([[-0.8838, -2.3880],
        [-2.1487, -1.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549935579299927
Epoch 0, Step 1589: train/loss = 0.5799092054367065, train/raw-loss = 0.5535570383071899, train/logprobs = tensor([[-0.9584, -2.5533],
        [-1.5900, -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26352113485336304
Epoch 0, Step 1590: train/loss = 0.6773864030838013, train/raw-loss = 0.6408251523971558, train/logprobs = tensor([[-0.8424, -1.2616],
        [-3.1026, -2.2479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36561211943626404
Epoch 0, Step 1591: train/loss = 0.6894106864929199, train/raw-loss = 0.6619299650192261, train/logprobs = tensor([[-0.8571, -1.3830],
        [-1.7133, -1.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2748071551322937
Epoch 0, Step 1592: train/loss = 0.49842599034309387, train/raw-loss = 0.47465187311172485, train/logprobs = tensor([[-0.7498, -2.0380],
        [-1.3698, -0.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23774133622646332
Epoch 0, Step 1593: train/loss = 0.4735274612903595, train/raw-loss = 0.4481579661369324, train/logprobs = tensor([[-0.7140, -3.4167],
        [-1.5325, -1.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.253695011138916
Epoch 0, Step 1594: train/loss = 0.37034595012664795, train/raw-loss = 0.3439827859401703, train/logprobs = tensor([[-0.6713, -3.8926],
        [-2.5530, -1.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26363182067871094
Epoch 0, Step 1595: train/loss = 0.5239584445953369, train/raw-loss = 0.5031257271766663, train/logprobs = tensor([[-0.6832, -1.3948],
        [-1.0601, -0.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20832699537277222
Epoch 0, Step 1596: train/loss = 0.5345033407211304, train/raw-loss = 0.5050815343856812, train/logprobs = tensor([[-0.9451, -3.4191],
        [-2.4980, -2.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942175567150116
Epoch 0, Step 1597: train/loss = 0.4798070192337036, train/raw-loss = 0.45435112714767456, train/logprobs = tensor([[-0.8776, -1.9182],
        [-2.1942, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545585036277771
Epoch 0, Step 1598: train/loss = 0.3668697774410248, train/raw-loss = 0.33926334977149963, train/logprobs = tensor([[-0.9056, -2.7125],
        [-2.5096, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760641574859619
Epoch 0, Step 1599: train/loss = 0.5441173315048218, train/raw-loss = 0.5160908102989197, train/logprobs = tensor([[-1.0037, -1.6981],
        [-1.9676, -1.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802657186985016
Epoch 0, Step 1600: train/loss = 0.4207395017147064, train/raw-loss = 0.38741275668144226, train/logprobs = tensor([[-0.9920, -2.2924],
        [-2.4073, -1.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33326733112335205
Epoch 0, Step 1601: train/loss = 0.5619848966598511, train/raw-loss = 0.5376570820808411, train/logprobs = tensor([[-0.5507, -3.1666],
        [-1.3781, -2.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24327829480171204
Epoch 0, Step 1602: train/loss = 0.41526228189468384, train/raw-loss = 0.3878346085548401, train/logprobs = tensor([[-0.8061, -2.2823],
        [-2.3586, -1.5937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742769718170166
Epoch 0, Step 1603: train/loss = 0.5842751860618591, train/raw-loss = 0.5581666827201843, train/logprobs = tensor([[-1.0322, -2.2254],
        [-2.1581, -2.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610849142074585
Epoch 0, Step 1604: train/loss = 0.6537702083587646, train/raw-loss = 0.63087397813797, train/logprobs = tensor([[-0.6926, -0.9899],
        [-1.0369, -1.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22896218299865723
Epoch 0, Step 1605: train/loss = 0.5736174583435059, train/raw-loss = 0.543450117111206, train/logprobs = tensor([[-0.7222, -2.3434],
        [-1.9761, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016732931137085
Epoch 0, Step 1606: train/loss = 0.2752619981765747, train/raw-loss = 0.24843157827854156, train/logprobs = tensor([[-1.0243, -7.1408],
        [-2.1778, -2.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26830431818962097
Epoch 0, Step 1607: train/loss = 0.46446242928504944, train/raw-loss = 0.4408273696899414, train/logprobs = tensor([[-0.7680, -3.4118],
        [-1.3313, -1.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23635073006153107
Epoch 0, Step 1608: train/loss = 0.6441378593444824, train/raw-loss = 0.6160300970077515, train/logprobs = tensor([[-1.1097, -1.7078],
        [-1.7291, -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2810768485069275
Epoch 0, Step 1609: train/loss = 0.6271076798439026, train/raw-loss = 0.6047652959823608, train/logprobs = tensor([[-0.8716, -1.7824],
        [-1.1208, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22342371940612793
Epoch 0, Step 1610: train/loss = 0.4741392135620117, train/raw-loss = 0.4515616297721863, train/logprobs = tensor([[-0.6789, -2.3387],
        [-1.2160, -1.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22577577829360962
Epoch 0, Step 1611: train/loss = 0.47614920139312744, train/raw-loss = 0.4443378150463104, train/logprobs = tensor([[-0.9193, -2.6200],
        [-2.9972, -2.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181139826774597
Epoch 0, Step 1612: train/loss = 0.505612850189209, train/raw-loss = 0.4723691940307617, train/logprobs = tensor([[-0.7485, -2.8598],
        [-2.5944, -1.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33243685960769653
Epoch 0, Step 1613: train/loss = 0.4383087158203125, train/raw-loss = 0.406546950340271, train/logprobs = tensor([[-1.1091, -4.0571],
        [-2.9728, -2.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3176177442073822
Epoch 0, Step 1614: train/loss = 0.3888559341430664, train/raw-loss = 0.35529670119285583, train/logprobs = tensor([[-0.8281, -2.8211],
        [-2.4619, -1.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3355919122695923
Epoch 0, Step 1615: train/loss = 0.4019228518009186, train/raw-loss = 0.37357550859451294, train/logprobs = tensor([[-0.8425, -2.5689],
        [-2.2410, -1.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2834734320640564
Epoch 0, Step 1616: train/loss = 0.4547242522239685, train/raw-loss = 0.42829659581184387, train/logprobs = tensor([[-0.9846, -1.7111],
        [-2.6288, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26427650451660156
Epoch 0, Step 1617: train/loss = 0.5736786127090454, train/raw-loss = 0.5473092794418335, train/logprobs = tensor([[-1.5208, -2.9426],
        [-1.7772, -1.1385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26369309425354004
Epoch 0, Step 1618: train/loss = 0.6414013504981995, train/raw-loss = 0.6112334728240967, train/logprobs = tensor([[-0.6295, -1.3992],
        [-1.6758, -1.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30167874693870544
Epoch 0, Step 1619: train/loss = 0.5331667065620422, train/raw-loss = 0.5056120157241821, train/logprobs = tensor([[-0.7444, -1.5581],
        [-1.9126, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27554622292518616
Epoch 0, Step 1620: train/loss = 0.4119844436645508, train/raw-loss = 0.386297345161438, train/logprobs = tensor([[-0.8285, -2.7642],
        [-1.7820, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25687074661254883
Epoch 0, Step 1621: train/loss = 0.5115804672241211, train/raw-loss = 0.485445111989975, train/logprobs = tensor([[-0.9027, -1.4047],
        [-1.8975, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2613534927368164
Epoch 0, Step 1622: train/loss = 0.6766828298568726, train/raw-loss = 0.6520541310310364, train/logprobs = tensor([[-1.7557, -2.1005],
        [-1.4517, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24628746509552002
Epoch 0, Step 1623: train/loss = 0.632000207901001, train/raw-loss = 0.6102335453033447, train/logprobs = tensor([[-0.9990, -1.1810],
        [-1.3122, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21766695380210876
Epoch 0, Step 1624: train/loss = 0.4439643323421478, train/raw-loss = 0.41693419218063354, train/logprobs = tensor([[-0.7746, -2.2528],
        [-2.1315, -1.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703014612197876
Epoch 0, Step 1625: train/loss = 0.5041271448135376, train/raw-loss = 0.4761835038661957, train/logprobs = tensor([[-1.1063, -1.8413],
        [-2.0558, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27943646907806396
Epoch 0, Step 1626: train/loss = 0.34495341777801514, train/raw-loss = 0.318858802318573, train/logprobs = tensor([[-1.2050, -4.1399],
        [-2.5070, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609463334083557
Epoch 0, Step 1627: train/loss = 0.41094735264778137, train/raw-loss = 0.3804115056991577, train/logprobs = tensor([[-0.8490, -2.7347],
        [-2.4037, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30535849928855896
Epoch 0, Step 1628: train/loss = 0.5311484336853027, train/raw-loss = 0.5007531046867371, train/logprobs = tensor([[-0.8438, -2.4852],
        [-2.5744, -1.5011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3039534091949463
Epoch 0, Step 1629: train/loss = 0.6738042831420898, train/raw-loss = 0.6514109373092651, train/logprobs = tensor([[-1.5333, -5.2780],
        [-1.2448, -0.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22393359243869781
Epoch 0, Step 1630: train/loss = 0.6502847075462341, train/raw-loss = 0.6222987174987793, train/logprobs = tensor([[-1.8880, -3.8131],
        [-3.4729, -2.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798600196838379
Epoch 0, Step 1631: train/loss = 0.556704580783844, train/raw-loss = 0.5315796136856079, train/logprobs = tensor([[-1.1808, -2.2202],
        [-1.5277, -1.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512497007846832
Epoch 0, Step 1632: train/loss = 0.28280025720596313, train/raw-loss = 0.24882185459136963, train/logprobs = tensor([[-1.2121, -3.3656],
        [-3.0213, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33978408575057983
Epoch 0, Step 1633: train/loss = 0.8304147720336914, train/raw-loss = 0.80464768409729, train/logprobs = tensor([[-3.2732, -5.0302],
        [-3.0371, -2.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576710283756256
Epoch 0, Step 1634: train/loss = 0.5165597200393677, train/raw-loss = 0.48768824338912964, train/logprobs = tensor([[-1.7677, -3.3200],
        [-2.0256, -1.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28871506452560425
Epoch 0, Step 1635: train/loss = 0.6198399066925049, train/raw-loss = 0.5905395150184631, train/logprobs = tensor([[-0.7375, -1.2523],
        [-1.3601, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2930033802986145
Epoch 0, Step 1636: train/loss = 0.21982572972774506, train/raw-loss = 0.1907997727394104, train/logprobs = tensor([[-0.9072, -3.9078],
        [-3.3196, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902595102787018
Epoch 0, Step 1637: train/loss = 0.5301470160484314, train/raw-loss = 0.5054481625556946, train/logprobs = tensor([[-1.8602, -2.7572],
        [-2.4783, -1.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24698859453201294
Epoch 0, Step 1638: train/loss = 0.41835641860961914, train/raw-loss = 0.3889120817184448, train/logprobs = tensor([[-0.9881, -3.4509],
        [-1.7058, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29444411396980286
Epoch 0, Step 1639: train/loss = 0.7130167484283447, train/raw-loss = 0.6892777681350708, train/logprobs = tensor([[-0.9595, -1.1894],
        [-2.1751, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23739024996757507
Epoch 0, Step 1640: train/loss = 0.6122375726699829, train/raw-loss = 0.5887791514396667, train/logprobs = tensor([[-0.6131, -1.0045],
        [-1.1062, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23458431661128998
Epoch 0, Step 1641: train/loss = 0.4557664096355438, train/raw-loss = 0.43376654386520386, train/logprobs = tensor([[-0.8795, -4.4589],
        [-1.5991, -1.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21999865770339966
Epoch 0, Step 1642: train/loss = 0.7097344398498535, train/raw-loss = 0.6824824213981628, train/logprobs = tensor([[-0.6036, -1.0417],
        [-1.3309, -1.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27251997590065
Epoch 0, Step 1643: train/loss = 0.6279457807540894, train/raw-loss = 0.6042327284812927, train/logprobs = tensor([[-0.6548, -0.9387],
        [-1.1697, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23713073134422302
Epoch 0, Step 1644: train/loss = 0.4866673946380615, train/raw-loss = 0.4522952437400818, train/logprobs = tensor([[-1.0340, -2.8174],
        [-3.1983, -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3437216877937317
Epoch 0, Step 1645: train/loss = 0.4412340521812439, train/raw-loss = 0.4159998595714569, train/logprobs = tensor([[-0.8971, -3.0912],
        [-2.0141, -2.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25234219431877136
Epoch 0, Step 1646: train/loss = 0.5961230993270874, train/raw-loss = 0.5691462755203247, train/logprobs = tensor([[-0.7448, -1.6707],
        [-1.4142, -1.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2697680592536926
Epoch 0, Step 1647: train/loss = 0.3454904556274414, train/raw-loss = 0.3116164803504944, train/logprobs = tensor([[-0.6254, -3.2390],
        [-2.1369, -1.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33873987197875977
Epoch 0, Step 1648: train/loss = 0.5057141184806824, train/raw-loss = 0.4824939966201782, train/logprobs = tensor([[-0.7058, -1.8021],
        [-1.3699, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23220130801200867
Epoch 0, Step 1649: train/loss = 0.4208422005176544, train/raw-loss = 0.39360731840133667, train/logprobs = tensor([[-0.7673, -2.0343],
        [-2.6309, -1.4505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27234897017478943
Epoch 0, Step 1650: train/loss = 0.40543055534362793, train/raw-loss = 0.3812224268913269, train/logprobs = tensor([[-1.2111, -3.0658],
        [-3.3204, -1.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24208128452301025
Epoch 0, Step 1651: train/loss = 0.5352098345756531, train/raw-loss = 0.5071755051612854, train/logprobs = tensor([[-0.7409, -1.9244],
        [-2.3403, -1.9359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28034305572509766
Epoch 0, Step 1652: train/loss = 0.21423734724521637, train/raw-loss = 0.18063387274742126, train/logprobs = tensor([[-0.9079, -6.0455],
        [-3.4036, -2.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33603474497795105
Epoch 0, Step 1653: train/loss = 0.4344981610774994, train/raw-loss = 0.40736985206604004, train/logprobs = tensor([[-0.6567, -1.9264],
        [-1.9064, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27128317952156067
Epoch 0, Step 1654: train/loss = 0.615387499332428, train/raw-loss = 0.5926091074943542, train/logprobs = tensor([[-1.1536, -1.5481],
        [-1.2860, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22778451442718506
Epoch 0, Step 1655: train/loss = 0.2849014103412628, train/raw-loss = 0.25606149435043335, train/logprobs = tensor([[-0.8909, -3.9290],
        [-2.3869, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883988618850708
Epoch 0, Step 1656: train/loss = 0.532813549041748, train/raw-loss = 0.507664680480957, train/logprobs = tensor([[-0.6293, -2.3997],
        [-1.7217, -1.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25148868560791016
Epoch 0, Step 1657: train/loss = 0.5028618574142456, train/raw-loss = 0.4755806624889374, train/logprobs = tensor([[-1.3436, -2.3554],
        [-1.8930, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272811621427536
Epoch 0, Step 1658: train/loss = 0.7207431793212891, train/raw-loss = 0.6959716081619263, train/logprobs = tensor([[-1.0414, -1.7641],
        [-1.4266, -1.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24771562218666077
Epoch 0, Step 1659: train/loss = 0.3769382834434509, train/raw-loss = 0.3497951328754425, train/logprobs = tensor([[-0.6862, -3.2480],
        [-2.4746, -1.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2714315950870514
Epoch 0, Step 1660: train/loss = 0.5396747589111328, train/raw-loss = 0.5136289596557617, train/logprobs = tensor([[-0.6855, -1.3895],
        [-1.3183, -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2604578733444214
Epoch 0, Step 1661: train/loss = 0.3986220955848694, train/raw-loss = 0.3690578043460846, train/logprobs = tensor([[-0.6304, -2.4801],
        [-2.7477, -1.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29564282298088074
Epoch 0, Step 1662: train/loss = 0.4791018068790436, train/raw-loss = 0.4558859169483185, train/logprobs = tensor([[-0.8192, -2.9903],
        [-1.6881, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23215891420841217
Epoch 0, Step 1663: train/loss = 0.6288629770278931, train/raw-loss = 0.5972332954406738, train/logprobs = tensor([[-1.0622, -1.5720],
        [-1.8853, -1.7641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31629708409309387
Epoch 0, Step 1664: train/loss = 0.43504536151885986, train/raw-loss = 0.4089486002922058, train/logprobs = tensor([[-0.9748, -3.4282],
        [-2.1823, -2.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609676718711853
Epoch 0, Step 1665: train/loss = 0.5608161687850952, train/raw-loss = 0.5284827947616577, train/logprobs = tensor([[-0.8871, -1.8044],
        [-2.7189, -2.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3233339190483093
Epoch 0, Step 1666: train/loss = 0.4710277318954468, train/raw-loss = 0.4441192150115967, train/logprobs = tensor([[-1.0657, -3.7712],
        [-2.8595, -1.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2690850794315338
Epoch 0, Step 1667: train/loss = 0.7195121049880981, train/raw-loss = 0.6916685700416565, train/logprobs = tensor([[-1.3053, -2.2252],
        [-1.5900, -2.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2784351408481598
Epoch 0, Step 1668: train/loss = 0.5219175219535828, train/raw-loss = 0.4975471794605255, train/logprobs = tensor([[-0.6511, -2.6296],
        [-1.4497, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24370338022708893
Epoch 0, Step 1669: train/loss = 0.4555552005767822, train/raw-loss = 0.4284551441669464, train/logprobs = tensor([[-1.2110, -3.5243],
        [-1.9367, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27100035548210144
Epoch 0, Step 1670: train/loss = 0.6260422468185425, train/raw-loss = 0.5949670076370239, train/logprobs = tensor([[-0.9194, -2.8809],
        [-2.2360, -2.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107518255710602
Epoch 0, Step 1671: train/loss = 0.42498618364334106, train/raw-loss = 0.3903779983520508, train/logprobs = tensor([[-1.0349, -7.2146],
        [-3.1043, -3.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3460821509361267
Epoch 0, Step 1672: train/loss = 0.3630422055721283, train/raw-loss = 0.3364827036857605, train/logprobs = tensor([[-0.7233, -5.6560],
        [-1.9267, -1.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26559504866600037
Epoch 0, Step 1673: train/loss = 0.515346348285675, train/raw-loss = 0.4864385426044464, train/logprobs = tensor([[-1.3629, -1.4363],
        [-2.6284, -1.3888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890778183937073
Epoch 0, Step 1674: train/loss = 0.4558204412460327, train/raw-loss = 0.4190034568309784, train/logprobs = tensor([[-1.2539, -5.6496],
        [-2.9716, -3.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36816996335983276
Epoch 0, Step 1675: train/loss = 0.49390172958374023, train/raw-loss = 0.46130073070526123, train/logprobs = tensor([[-1.3204, -3.5692],
        [-2.4648, -2.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3260096311569214
Epoch 0, Step 1676: train/loss = 0.47806036472320557, train/raw-loss = 0.4495125412940979, train/logprobs = tensor([[-0.9081, -2.3571],
        [-2.1377, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28547829389572144
Epoch 0, Step 1677: train/loss = 0.8958283066749573, train/raw-loss = 0.8681787252426147, train/logprobs = tensor([[-2.6504, -2.1599],
        [-2.9054, -2.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2764962315559387
Epoch 0, Step 1678: train/loss = 0.5511696338653564, train/raw-loss = 0.5255815386772156, train/logprobs = tensor([[-0.9284, -1.9871],
        [-1.5575, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25588086247444153
Epoch 0, Step 1679: train/loss = 0.5452901721000671, train/raw-loss = 0.5154480934143066, train/logprobs = tensor([[-1.5562, -2.1525],
        [-2.5400, -1.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29842108488082886
Epoch 0, Step 1680: train/loss = 0.3629815876483917, train/raw-loss = 0.33194154500961304, train/logprobs = tensor([[-1.1154, -2.4757],
        [-3.0640, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3104005455970764
Epoch 0, Step 1681: train/loss = 0.36416196823120117, train/raw-loss = 0.3311246633529663, train/logprobs = tensor([[-1.1089, -2.7611],
        [-2.9750, -1.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33037322759628296
Epoch 0, Step 1682: train/loss = 0.24087393283843994, train/raw-loss = 0.21394819021224976, train/logprobs = tensor([[-0.7853, -6.6346],
        [-2.1511, -2.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2692572772502899
Epoch 0, Step 1683: train/loss = 0.4946344792842865, train/raw-loss = 0.4683712124824524, train/logprobs = tensor([[-0.8372, -2.5537],
        [-2.2020, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626328468322754
Epoch 0, Step 1684: train/loss = 0.4302508234977722, train/raw-loss = 0.40366506576538086, train/logprobs = tensor([[-1.3531, -3.9130],
        [-2.2841, -1.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658573091030121
Epoch 0, Step 1685: train/loss = 0.5616410970687866, train/raw-loss = 0.5408644676208496, train/logprobs = tensor([[-1.2262, -2.0070],
        [-1.5442, -1.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20776547491550446
Epoch 0, Step 1686: train/loss = 0.530388593673706, train/raw-loss = 0.5044755339622498, train/logprobs = tensor([[-0.7402, -2.7732],
        [-1.3506, -1.4244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2591311037540436
Epoch 0, Step 1687: train/loss = 0.39161816239356995, train/raw-loss = 0.37159764766693115, train/logprobs = tensor([[-0.9233, -3.5774],
        [-1.5413, -1.6311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20020551979541779
Epoch 0, Step 1688: train/loss = 0.4911125898361206, train/raw-loss = 0.4672681987285614, train/logprobs = tensor([[-0.5901, -2.3503],
        [-1.3883, -1.3857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23844367265701294
Epoch 0, Step 1689: train/loss = 0.27868416905403137, train/raw-loss = 0.24772661924362183, train/logprobs = tensor([[-0.9727, -2.2103],
        [-3.4770, -1.2159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3095758855342865
Epoch 0, Step 1690: train/loss = 0.44581592082977295, train/raw-loss = 0.4094088673591614, train/logprobs = tensor([[-1.0248, -3.3015],
        [-2.9760, -2.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36407071352005005
Epoch 0, Step 1691: train/loss = 0.4879879951477051, train/raw-loss = 0.4569905996322632, train/logprobs = tensor([[-1.0106, -2.1497],
        [-2.1924, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3099738657474518
Epoch 0, Step 1692: train/loss = 0.43336260318756104, train/raw-loss = 0.4050956666469574, train/logprobs = tensor([[-0.7555, -5.2145],
        [-1.6534, -1.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28266945481300354
Epoch 0, Step 1693: train/loss = 0.5709436535835266, train/raw-loss = 0.545723021030426, train/logprobs = tensor([[-1.2156, -1.8981],
        [-1.5178, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25220638513565063
Epoch 0, Step 1694: train/loss = 0.38306301832199097, train/raw-loss = 0.35473334789276123, train/logprobs = tensor([[-1.1920, -2.1931],
        [-2.2836, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832966446876526
Epoch 0, Step 1695: train/loss = 0.5830429792404175, train/raw-loss = 0.557283341884613, train/logprobs = tensor([[-0.7783, -0.7320],
        [-2.1830, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575959861278534
Epoch 0, Step 1696: train/loss = 0.4540426731109619, train/raw-loss = 0.4197371304035187, train/logprobs = tensor([[-0.8841, -1.3433],
        [-2.6327, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34305527806282043
Epoch 0, Step 1697: train/loss = 0.39501214027404785, train/raw-loss = 0.3672969937324524, train/logprobs = tensor([[-0.6018, -5.1582],
        [-1.9972, -1.9352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2771517038345337
Epoch 0, Step 1698: train/loss = 0.34094858169555664, train/raw-loss = 0.31539031863212585, train/logprobs = tensor([[-0.8520, -4.7137],
        [-1.7530, -2.1735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25558266043663025
Epoch 0, Step 1699: train/loss = 0.5131588578224182, train/raw-loss = 0.4863232374191284, train/logprobs = tensor([[-0.6395, -2.6118],
        [-2.0254, -1.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2683556079864502
Epoch 0, Step 1700: train/loss = 0.3772343397140503, train/raw-loss = 0.3476140797138214, train/logprobs = tensor([[-0.8416, -2.4204],
        [-2.7733, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29620251059532166
Epoch 0, Step 1701: train/loss = 0.4958946406841278, train/raw-loss = 0.4749985337257385, train/logprobs = tensor([[-1.0011, -3.5567],
        [-1.5078, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20896095037460327
Epoch 0, Step 1702: train/loss = 0.5924427509307861, train/raw-loss = 0.5643118023872375, train/logprobs = tensor([[-0.6601, -1.1433],
        [-1.9413, -1.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813095450401306
Epoch 0, Step 1703: train/loss = 0.43938320875167847, train/raw-loss = 0.4152790307998657, train/logprobs = tensor([[-1.4939, -2.1192],
        [-3.0288, -1.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24104157090187073
Epoch 0, Step 1704: train/loss = 0.44234392046928406, train/raw-loss = 0.41277870535850525, train/logprobs = tensor([[-0.8485, -3.0987],
        [-1.9421, -1.9672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956523001194
Epoch 0, Step 1705: train/loss = 0.6467589139938354, train/raw-loss = 0.6158272624015808, train/logprobs = tensor([[-1.8086, -3.1037],
        [-2.6734, -1.7006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30931663513183594
Epoch 0, Step 1706: train/loss = 0.5150756239891052, train/raw-loss = 0.49418842792510986, train/logprobs = tensor([[-0.6431, -1.6401],
        [-1.1664, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088717222213745
Epoch 0, Step 1707: train/loss = 0.5626084804534912, train/raw-loss = 0.5362823605537415, train/logprobs = tensor([[-0.7156, -1.7586],
        [-1.1682, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26326125860214233
Epoch 0, Step 1708: train/loss = 0.5639817714691162, train/raw-loss = 0.5419843196868896, train/logprobs = tensor([[-0.7099, -1.4034],
        [-1.1343, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2199743539094925
Epoch 0, Step 1709: train/loss = 0.34727221727371216, train/raw-loss = 0.31238532066345215, train/logprobs = tensor([[-0.8716, -3.4975],
        [-3.0640, -1.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34886905550956726
Epoch 0, Step 1710: train/loss = 0.5728557109832764, train/raw-loss = 0.5486233830451965, train/logprobs = tensor([[-0.9777, -1.4042],
        [-1.4583, -1.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2423238903284073
Epoch 0, Step 1711: train/loss = 0.2349889576435089, train/raw-loss = 0.20483341813087463, train/logprobs = tensor([[-1.1081, -6.9161],
        [-3.2868, -1.7493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30155524611473083
Epoch 0, Step 1712: train/loss = 0.5788442492485046, train/raw-loss = 0.5520330667495728, train/logprobs = tensor([[-0.7045, -2.1939],
        [-1.7922, -1.6094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2681114673614502
Epoch 0, Step 1713: train/loss = 0.6256908178329468, train/raw-loss = 0.5971912145614624, train/logprobs = tensor([[-1.1598, -1.8693],
        [-2.1706, -1.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849956154823303
Epoch 0, Step 1714: train/loss = 0.5089171528816223, train/raw-loss = 0.48264622688293457, train/logprobs = tensor([[-0.9545, -2.0872],
        [-1.9977, -1.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2627093493938446
Epoch 0, Step 1715: train/loss = 0.4264209568500519, train/raw-loss = 0.3970436751842499, train/logprobs = tensor([[-0.7784, -4.5545],
        [-2.3417, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937728762626648
Epoch 0, Step 1716: train/loss = 0.5489518642425537, train/raw-loss = 0.524872899055481, train/logprobs = tensor([[-1.0711, -1.7799],
        [-1.4871, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24079041182994843
Epoch 0, Step 1717: train/loss = 0.4875507950782776, train/raw-loss = 0.4613037705421448, train/logprobs = tensor([[-1.1038, -2.7714],
        [-1.7727, -1.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262470006942749
Epoch 0, Step 1718: train/loss = 0.5122438073158264, train/raw-loss = 0.484486848115921, train/logprobs = tensor([[-0.8109, -3.1656],
        [-2.0475, -2.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27756959199905396
Epoch 0, Step 1719: train/loss = 0.6999297142028809, train/raw-loss = 0.671358585357666, train/logprobs = tensor([[-1.0394, -0.9149],
        [-1.9491, -1.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857113778591156
Epoch 0, Step 1720: train/loss = 0.47781482338905334, train/raw-loss = 0.4555981755256653, train/logprobs = tensor([[-1.0031, -2.7588],
        [-1.4253, -0.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22216615080833435
Epoch 0, Step 1721: train/loss = 0.2872117757797241, train/raw-loss = 0.26327940821647644, train/logprobs = tensor([[-0.9519, -6.4997],
        [-2.0455, -2.4436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23932407796382904
Epoch 0, Step 1722: train/loss = 0.5416998267173767, train/raw-loss = 0.5101301670074463, train/logprobs = tensor([[-0.7326, -1.5925],
        [-1.8370, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3156965374946594
Epoch 0, Step 1723: train/loss = 0.44489583373069763, train/raw-loss = 0.4134865403175354, train/logprobs = tensor([[-0.6610, -3.5536],
        [-1.9308, -1.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31409308314323425
Epoch 0, Step 1724: train/loss = 0.3780304193496704, train/raw-loss = 0.3454810082912445, train/logprobs = tensor([[-0.9951, -3.2655],
        [-3.4666, -1.6623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3254944086074829
Epoch 0, Step 1725: train/loss = 0.4173735976219177, train/raw-loss = 0.3923549950122833, train/logprobs = tensor([[-1.1374, -4.6823],
        [-1.5612, -1.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2501858174800873
Epoch 0, Step 1726: train/loss = 0.4845057427883148, train/raw-loss = 0.4510253965854645, train/logprobs = tensor([[-0.7526, -2.6895],
        [-2.0447, -1.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3348032832145691
Epoch 0, Step 1727: train/loss = 0.4389510750770569, train/raw-loss = 0.40818917751312256, train/logprobs = tensor([[-0.8957, -3.5648],
        [-2.0604, -1.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30761903524398804
Epoch 0, Step 1728: train/loss = 0.5502873659133911, train/raw-loss = 0.5153759121894836, train/logprobs = tensor([[-0.8990, -3.0689],
        [-2.7462, -2.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34911394119262695
Epoch 0, Step 1729: train/loss = 0.5229074358940125, train/raw-loss = 0.4958828091621399, train/logprobs = tensor([[-0.9775, -1.5342],
        [-2.4606, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2702465057373047
Epoch 0, Step 1730: train/loss = 0.736633837223053, train/raw-loss = 0.7121278047561646, train/logprobs = tensor([[-1.1131, -2.2913],
        [-2.9988, -3.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24505996704101562
Epoch 0, Step 1731: train/loss = 0.5322080850601196, train/raw-loss = 0.5060890913009644, train/logprobs = tensor([[-0.6577, -5.3689],
        [-1.9671, -1.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611902058124542
Epoch 0, Step 1732: train/loss = 0.9407387375831604, train/raw-loss = 0.9154624342918396, train/logprobs = tensor([[-3.5009, -3.9068],
        [-2.5216, -2.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252763032913208
Epoch 0, Step 1733: train/loss = 0.41873109340667725, train/raw-loss = 0.39041420817375183, train/logprobs = tensor([[-1.1628, -3.7301],
        [-2.8455, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831690013408661
Epoch 0, Step 1734: train/loss = 0.30665192008018494, train/raw-loss = 0.28055742383003235, train/logprobs = tensor([[-0.8905, -3.9452],
        [-2.8780, -1.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609448730945587
Epoch 0, Step 1735: train/loss = 0.5371197462081909, train/raw-loss = 0.5060389637947083, train/logprobs = tensor([[-1.8524, -4.5509],
        [-4.1910, -3.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31080788373947144
Epoch 0, Step 1736: train/loss = 0.28755271434783936, train/raw-loss = 0.2592885494232178, train/logprobs = tensor([[-1.0144, -6.4526],
        [-2.8048, -2.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28264203667640686
Epoch 0, Step 1737: train/loss = 0.30061307549476624, train/raw-loss = 0.26795658469200134, train/logprobs = tensor([[-0.8180, -3.8038],
        [-2.6910, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3265647888183594
Epoch 0, Step 1738: train/loss = 0.5206973552703857, train/raw-loss = 0.49750804901123047, train/logprobs = tensor([[-1.1374, -2.4338],
        [-2.2886, -1.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318931370973587
Epoch 0, Step 1739: train/loss = 0.27160775661468506, train/raw-loss = 0.23996585607528687, train/logprobs = tensor([[-1.1691, -5.3788],
        [-3.2802, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31641885638237
Epoch 0, Step 1740: train/loss = 0.7444368600845337, train/raw-loss = 0.7149083018302917, train/logprobs = tensor([[-1.8302, -2.5025],
        [-2.0632, -1.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952853739261627
Epoch 0, Step 1741: train/loss = 0.561477541923523, train/raw-loss = 0.5364875793457031, train/logprobs = tensor([[-1.0135, -1.6915],
        [-1.6093, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498999387025833
Epoch 0, Step 1742: train/loss = 0.4801880717277527, train/raw-loss = 0.4489935338497162, train/logprobs = tensor([[-0.7765, -1.3941],
        [-2.8305, -1.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3119452893733978
Epoch 0, Step 1743: train/loss = 0.527703583240509, train/raw-loss = 0.4976135492324829, train/logprobs = tensor([[-1.1044, -2.1486],
        [-2.2765, -1.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.300900936126709
Epoch 0, Step 1744: train/loss = 0.31714311242103577, train/raw-loss = 0.2839549779891968, train/logprobs = tensor([[-0.8414, -3.8016],
        [-2.5494, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3318813741207123
Epoch 0, Step 1745: train/loss = 0.4610663950443268, train/raw-loss = 0.4287838041782379, train/logprobs = tensor([[-1.0737, -2.4090],
        [-2.7234, -1.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228258490562439
Epoch 0, Step 1746: train/loss = 0.5830609798431396, train/raw-loss = 0.5585755109786987, train/logprobs = tensor([[-0.7418, -1.5729],
        [-1.3714, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24485495686531067
Epoch 0, Step 1747: train/loss = 0.2520465850830078, train/raw-loss = 0.2170790582895279, train/logprobs = tensor([[-1.0276, -4.2403],
        [-2.9850, -1.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34967517852783203
Epoch 0, Step 1748: train/loss = 0.5350596904754639, train/raw-loss = 0.502608060836792, train/logprobs = tensor([[-1.1418, -2.8658],
        [-2.3250, -2.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32451701164245605
Epoch 0, Step 1749: train/loss = 0.4494297504425049, train/raw-loss = 0.42183399200439453, train/logprobs = tensor([[-1.2163, -2.2970],
        [-2.4375, -1.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759575843811035
Epoch 0, Step 1750: train/loss = 0.4996485710144043, train/raw-loss = 0.47538328170776367, train/logprobs = tensor([[-0.9516, -2.1335],
        [-1.6237, -1.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2426530122756958
Epoch 0, Step 1751: train/loss = 0.5417085289955139, train/raw-loss = 0.5086047053337097, train/logprobs = tensor([[-1.0331, -2.2265],
        [-3.5665, -2.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33103862404823303
Epoch 0, Step 1752: train/loss = 0.5914435982704163, train/raw-loss = 0.5659920573234558, train/logprobs = tensor([[-1.2756, -2.3324],
        [-1.6344, -1.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25451549887657166
Epoch 0, Step 1753: train/loss = 0.3927103579044342, train/raw-loss = 0.35590118169784546, train/logprobs = tensor([[-0.8738, -3.6135],
        [-2.9310, -2.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3680915832519531
Epoch 0, Step 1754: train/loss = 0.2760542929172516, train/raw-loss = 0.24625612795352936, train/logprobs = tensor([[-0.7202, -3.7451],
        [-2.5995, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979816198348999
Epoch 0, Step 1755: train/loss = 0.6148586273193359, train/raw-loss = 0.590018630027771, train/logprobs = tensor([[-0.8387, -1.3820],
        [-1.4465, -1.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24839919805526733
Epoch 0, Step 1756: train/loss = 0.5044595003128052, train/raw-loss = 0.4796844720840454, train/logprobs = tensor([[-0.9190, -2.1423],
        [-1.9731, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24774977564811707
Epoch 0, Step 1757: train/loss = 0.38963302969932556, train/raw-loss = 0.3617371916770935, train/logprobs = tensor([[-1.7835, -3.8905],
        [-2.0364, -1.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27895838022232056
Epoch 0, Step 1758: train/loss = 0.7505719661712646, train/raw-loss = 0.7267608642578125, train/logprobs = tensor([[-0.7505, -0.8406],
        [-1.3193, -1.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23811210691928864
Epoch 0, Step 1759: train/loss = 0.4740910828113556, train/raw-loss = 0.4511082172393799, train/logprobs = tensor([[-0.7726, -1.9426],
        [-1.4586, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22982870042324066
Epoch 0, Step 1760: train/loss = 0.6550894379615784, train/raw-loss = 0.627015233039856, train/logprobs = tensor([[-2.4291, -5.2962],
        [-2.1912, -1.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807421386241913
Epoch 0, Step 1761: train/loss = 0.3586856722831726, train/raw-loss = 0.33170419931411743, train/logprobs = tensor([[-1.1327, -3.0379],
        [-1.9958, -1.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698148787021637
Epoch 0, Step 1762: train/loss = 0.388967365026474, train/raw-loss = 0.3622428774833679, train/logprobs = tensor([[-0.9639, -3.4588],
        [-2.0667, -1.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267244815826416
Epoch 0, Step 1763: train/loss = 0.3393491208553314, train/raw-loss = 0.3109104335308075, train/logprobs = tensor([[-1.4253, -5.4466],
        [-2.7449, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2843870520591736
Epoch 0, Step 1764: train/loss = 0.6582509875297546, train/raw-loss = 0.6333373785018921, train/logprobs = tensor([[-0.7951, -1.1559],
        [-1.2279, -1.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2491358071565628
Epoch 0, Step 1765: train/loss = 0.7361407279968262, train/raw-loss = 0.7126385569572449, train/logprobs = tensor([[-2.0787, -2.4897],
        [-2.8682, -2.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2350214570760727
Epoch 0, Step 1766: train/loss = 0.5006264448165894, train/raw-loss = 0.47872108221054077, train/logprobs = tensor([[-0.5403, -4.6009],
        [-1.0395, -1.3970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21905308961868286
Epoch 0, Step 1767: train/loss = 0.2870984673500061, train/raw-loss = 0.25889936089515686, train/logprobs = tensor([[-0.7757, -5.1900],
        [-2.2945, -2.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819911241531372
Epoch 0, Step 1768: train/loss = 0.569674015045166, train/raw-loss = 0.5465074777603149, train/logprobs = tensor([[-0.8839, -0.9990],
        [-1.6889, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23166540265083313
Epoch 0, Step 1769: train/loss = 0.4989367723464966, train/raw-loss = 0.4662948548793793, train/logprobs = tensor([[-0.8781, -1.6276],
        [-2.8535, -1.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32641908526420593
Epoch 0, Step 1770: train/loss = 0.3378636837005615, train/raw-loss = 0.3121441602706909, train/logprobs = tensor([[-0.9550, -3.6758],
        [-2.4787, -1.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571953535079956
Epoch 0, Step 1771: train/loss = 0.6809791922569275, train/raw-loss = 0.6512409448623657, train/logprobs = tensor([[-1.3079, -1.3534],
        [-1.6784, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2973836064338684
Epoch 0, Step 1772: train/loss = 0.3910849690437317, train/raw-loss = 0.3673260509967804, train/logprobs = tensor([[-1.1303, -5.1133],
        [-1.3816, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23758919537067413
Epoch 0, Step 1773: train/loss = 0.3335774540901184, train/raw-loss = 0.3009026348590851, train/logprobs = tensor([[-1.0925, -3.3322],
        [-2.7052, -2.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.326748251914978
Epoch 0, Step 1774: train/loss = 0.6622734665870667, train/raw-loss = 0.6367607712745667, train/logprobs = tensor([[-0.7197, -0.9864],
        [-1.3829, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25512704253196716
Epoch 0, Step 1775: train/loss = 0.5926533937454224, train/raw-loss = 0.569573163986206, train/logprobs = tensor([[-0.8731, -1.3116],
        [-1.5193, -1.3582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23080214858055115
Epoch 0, Step 1776: train/loss = 0.5344352722167969, train/raw-loss = 0.5021552443504333, train/logprobs = tensor([[-1.2514, -2.4890],
        [-2.7989, -1.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228004276752472
Epoch 0, Step 1777: train/loss = 0.4583281874656677, train/raw-loss = 0.432106077671051, train/logprobs = tensor([[-0.8187, -1.5629],
        [-2.1387, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26222094893455505
Epoch 0, Step 1778: train/loss = 0.396654337644577, train/raw-loss = 0.37237972021102905, train/logprobs = tensor([[-0.9755, -2.6248],
        [-1.8915, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427462637424469
Epoch 0, Step 1779: train/loss = 0.5536822080612183, train/raw-loss = 0.5228811502456665, train/logprobs = tensor([[-1.3199, -2.0674],
        [-2.4665, -2.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308010995388031
Epoch 0, Step 1780: train/loss = 0.5116605758666992, train/raw-loss = 0.4860610067844391, train/logprobs = tensor([[-1.2582, -4.1494],
        [-1.8946, -3.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25599542260169983
Epoch 0, Step 1781: train/loss = 0.3280383348464966, train/raw-loss = 0.2955368757247925, train/logprobs = tensor([[-0.7504, -3.1622],
        [-2.3535, -1.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32501429319381714
Epoch 0, Step 1782: train/loss = 0.4514625072479248, train/raw-loss = 0.4283192753791809, train/logprobs = tensor([[-1.0836, -3.3815],
        [-1.5465, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.231432244181633
Epoch 0, Step 1783: train/loss = 0.8073697686195374, train/raw-loss = 0.7815556526184082, train/logprobs = tensor([[-1.7908, -4.3304],
        [-1.4146, -2.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25814133882522583
Epoch 0, Step 1784: train/loss = 0.3109622895717621, train/raw-loss = 0.27846643328666687, train/logprobs = tensor([[-0.9947, -3.3397],
        [-2.7011, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3249586522579193
Epoch 0, Step 1785: train/loss = 0.7972276210784912, train/raw-loss = 0.7770603895187378, train/logprobs = tensor([[-0.9087, -1.9325],
        [-1.4886, -2.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20167195796966553
Epoch 0, Step 1786: train/loss = 0.4179386794567108, train/raw-loss = 0.3794642984867096, train/logprobs = tensor([[-1.1826, -4.2289],
        [-3.0861, -2.2269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3847436308860779
Epoch 0, Step 1787: train/loss = 0.3880441188812256, train/raw-loss = 0.35723811388015747, train/logprobs = tensor([[-0.7219, -3.0012],
        [-1.9960, -1.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30805984139442444
Epoch 0, Step 1788: train/loss = 0.5401798486709595, train/raw-loss = 0.5178015828132629, train/logprobs = tensor([[-0.9256, -2.0445],
        [-1.7392, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2237822711467743
Epoch 0, Step 1789: train/loss = 0.4062771797180176, train/raw-loss = 0.3713396191596985, train/logprobs = tensor([[-0.9484, -2.4781],
        [-2.9217, -2.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34937581419944763
Epoch 0, Step 1790: train/loss = 0.5363012552261353, train/raw-loss = 0.5124810934066772, train/logprobs = tensor([[-0.7982, -1.5179],
        [-1.6736, -1.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23820118606090546
Epoch 0, Step 1791: train/loss = 0.4960629940032959, train/raw-loss = 0.46876823902130127, train/logprobs = tensor([[-1.3034, -2.0428],
        [-2.5869, -1.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2729477882385254
Epoch 0, Step 1792: train/loss = 0.15642088651657104, train/raw-loss = 0.12395992875099182, train/logprobs = tensor([[-1.1382, -4.9321],
        [-3.1937, -1.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32460957765579224
Epoch 0, Step 1793: train/loss = 0.39301714301109314, train/raw-loss = 0.3658044636249542, train/logprobs = tensor([[-0.7989, -3.7118],
        [-2.3150, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27212655544281006
Epoch 0, Step 1794: train/loss = 0.49665355682373047, train/raw-loss = 0.4614185690879822, train/logprobs = tensor([[-1.0802, -1.9900],
        [-2.4151, -1.3625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3523499369621277
Epoch 0, Step 1795: train/loss = 0.3465297520160675, train/raw-loss = 0.3126588463783264, train/logprobs = tensor([[-0.7224, -4.4893],
        [-2.1487, -2.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33870911598205566
Epoch 0, Step 1796: train/loss = 0.28323256969451904, train/raw-loss = 0.2586659789085388, train/logprobs = tensor([[-1.4789, -6.9138],
        [-2.6934, -2.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456657588481903
Epoch 0, Step 1797: train/loss = 0.37093082070350647, train/raw-loss = 0.33710914850234985, train/logprobs = tensor([[-1.0198, -3.7794],
        [-2.9954, -1.3914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33821630477905273
Epoch 0, Step 1798: train/loss = 0.6550240516662598, train/raw-loss = 0.628402590751648, train/logprobs = tensor([[-1.3266, -2.1420],
        [-1.9954, -2.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662147283554077
Epoch 0, Step 1799: train/loss = 0.31743839383125305, train/raw-loss = 0.2904336750507355, train/logprobs = tensor([[-0.8970, -3.8933],
        [-1.6422, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27004706859588623
Epoch 0, Step 1800: train/loss = 0.45827728509902954, train/raw-loss = 0.42597144842147827, train/logprobs = tensor([[-1.5515, -3.1692],
        [-3.0444, -1.2592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3230583369731903
Epoch 0, Step 1801: train/loss = 0.6371651291847229, train/raw-loss = 0.6101643443107605, train/logprobs = tensor([[-0.8331, -1.8097],
        [-1.3161, -1.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27000778913497925
Epoch 0, Step 1802: train/loss = 0.23385995626449585, train/raw-loss = 0.20459666848182678, train/logprobs = tensor([[-1.2616, -7.1258],
        [-3.0610, -2.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29263272881507874
Epoch 0, Step 1803: train/loss = 0.45056164264678955, train/raw-loss = 0.4208407998085022, train/logprobs = tensor([[-1.4729, -1.8932],
        [-2.7717, -1.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2972084581851959
Epoch 0, Step 1804: train/loss = 0.5287804007530212, train/raw-loss = 0.5018844604492188, train/logprobs = tensor([[-0.9409, -2.9774],
        [-2.0037, -1.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689593434333801
Epoch 0, Step 1805: train/loss = 0.5548693537712097, train/raw-loss = 0.5296915769577026, train/logprobs = tensor([[-0.7548, -1.4911],
        [-1.1014, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25177687406539917
Epoch 0, Step 1806: train/loss = 0.14502936601638794, train/raw-loss = 0.11267673969268799, train/logprobs = tensor([[-0.8565, -5.9935],
        [-3.3885, -1.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32352614402770996
Epoch 0, Step 1807: train/loss = 0.3461245894432068, train/raw-loss = 0.31616735458374023, train/logprobs = tensor([[-1.0701, -7.0798],
        [-3.0196, -2.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.299572229385376
Epoch 0, Step 1808: train/loss = 0.4205215573310852, train/raw-loss = 0.3886960744857788, train/logprobs = tensor([[-1.1165, -4.6355],
        [-2.5682, -2.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31825441122055054
Epoch 0, Step 1809: train/loss = 0.5017843246459961, train/raw-loss = 0.47638073563575745, train/logprobs = tensor([[-0.8742, -1.3725],
        [-1.6355, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2540358603000641
Epoch 0, Step 1810: train/loss = 0.5874404907226562, train/raw-loss = 0.5602033138275146, train/logprobs = tensor([[-0.9496, -1.7799],
        [-1.7732, -1.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723715007305145
Epoch 0, Step 1811: train/loss = 0.36324018239974976, train/raw-loss = 0.3309621810913086, train/logprobs = tensor([[-0.9453, -6.6413],
        [-3.3057, -2.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32278016209602356
Epoch 0, Step 1812: train/loss = 0.2833837866783142, train/raw-loss = 0.25001904368400574, train/logprobs = tensor([[-0.6869, -3.4834],
        [-2.2944, -1.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3336476683616638
Epoch 0, Step 1813: train/loss = 0.34331411123275757, train/raw-loss = 0.31469377875328064, train/logprobs = tensor([[-0.8262, -2.9747],
        [-2.6452, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2862031161785126
Epoch 0, Step 1814: train/loss = 0.4722019135951996, train/raw-loss = 0.4431056082248688, train/logprobs = tensor([[-1.0918, -2.3185],
        [-2.3783, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29096296429634094
Epoch 0, Step 1815: train/loss = 0.4884173274040222, train/raw-loss = 0.46166253089904785, train/logprobs = tensor([[-0.9304, -1.5641],
        [-1.8764, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2675478160381317
Epoch 0, Step 1816: train/loss = 0.18862824141979218, train/raw-loss = 0.16190248727798462, train/logprobs = tensor([[-1.3289, -5.3980],
        [-2.6737, -1.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2672575116157532
Epoch 0, Step 1817: train/loss = 0.45945337414741516, train/raw-loss = 0.4295218288898468, train/logprobs = tensor([[-1.0312, -3.1185],
        [-2.6856, -2.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29931527376174927
Epoch 0, Step 1818: train/loss = 0.5685750842094421, train/raw-loss = 0.5452743172645569, train/logprobs = tensor([[-0.8680, -1.4739],
        [-1.3133, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2330077588558197
Epoch 0, Step 1819: train/loss = 0.878229022026062, train/raw-loss = 0.8541785478591919, train/logprobs = tensor([[-1.4689, -1.6573],
        [-2.8992, -2.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240504652261734
Epoch 0, Step 1820: train/loss = 0.4668606221675873, train/raw-loss = 0.4402204155921936, train/logprobs = tensor([[-1.7410, -3.6698],
        [-1.7555, -0.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26640188694000244
Epoch 0, Step 1821: train/loss = 0.595608115196228, train/raw-loss = 0.5721278190612793, train/logprobs = tensor([[-0.8099, -2.0164],
        [-1.2564, -1.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23480254411697388
Epoch 0, Step 1822: train/loss = 0.38818517327308655, train/raw-loss = 0.35774847865104675, train/logprobs = tensor([[-1.0410, -5.0560],
        [-2.7379, -2.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30436694622039795
Epoch 0, Step 1823: train/loss = 0.46058884263038635, train/raw-loss = 0.433656245470047, train/logprobs = tensor([[-1.3999, -4.2886],
        [-2.1580, -2.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693258225917816
Epoch 0, Step 1824: train/loss = 0.42607420682907104, train/raw-loss = 0.3952345550060272, train/logprobs = tensor([[-1.1485, -2.7558],
        [-2.3546, -1.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30839651823043823
Epoch 0, Step 1825: train/loss = 0.3734813928604126, train/raw-loss = 0.34619465470314026, train/logprobs = tensor([[-1.3824, -2.6307],
        [-2.5190, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2728675305843353
Epoch 0, Step 1826: train/loss = 0.6465833187103271, train/raw-loss = 0.6233925223350525, train/logprobs = tensor([[-1.0454, -1.5826],
        [-1.5056, -1.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2319076955318451
Epoch 0, Step 1827: train/loss = 0.39878126978874207, train/raw-loss = 0.3709339201450348, train/logprobs = tensor([[-1.6864, -4.7372],
        [-2.8316, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2784733176231384
Epoch 0, Step 1828: train/loss = 0.35285475850105286, train/raw-loss = 0.3251936733722687, train/logprobs = tensor([[-0.8337, -6.4579],
        [-2.0722, -2.0080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27661070227622986
Epoch 0, Step 1829: train/loss = 0.45939674973487854, train/raw-loss = 0.4319387674331665, train/logprobs = tensor([[-0.7950, -2.1789],
        [-1.9593, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27457988262176514
Epoch 0, Step 1830: train/loss = 0.3889400362968445, train/raw-loss = 0.36325860023498535, train/logprobs = tensor([[-1.2415, -5.5388],
        [-2.1987, -1.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256814181804657
Epoch 0, Step 1831: train/loss = 0.5374645590782166, train/raw-loss = 0.5112826824188232, train/logprobs = tensor([[-1.2892, -1.8571],
        [-2.0554, -1.3416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618187963962555
Epoch 0, Step 1832: train/loss = 0.2328202873468399, train/raw-loss = 0.19403749704360962, train/logprobs = tensor([[-1.1388, -5.6070],
        [-3.1411, -1.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38782790303230286
Epoch 0, Step 1833: train/loss = 0.4589117467403412, train/raw-loss = 0.4328271746635437, train/logprobs = tensor([[-0.9796, -1.9831],
        [-1.7291, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2608456015586853
Epoch 0, Step 1834: train/loss = 0.5316101312637329, train/raw-loss = 0.5046553611755371, train/logprobs = tensor([[-1.0112, -1.5375],
        [-1.3765, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2695479393005371
Epoch 0, Step 1835: train/loss = 0.4894147515296936, train/raw-loss = 0.4613734781742096, train/logprobs = tensor([[-0.6848, -2.0704],
        [-1.7468, -1.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804126739501953
Epoch 0, Step 1836: train/loss = 0.27327263355255127, train/raw-loss = 0.24596098065376282, train/logprobs = tensor([[-0.8948, -3.3934],
        [-2.3853, -1.3687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27311599254608154
Epoch 0, Step 1837: train/loss = 0.5449842214584351, train/raw-loss = 0.5134388208389282, train/logprobs = tensor([[-0.9335, -2.4570],
        [-1.7309, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31545400619506836
Epoch 0, Step 1838: train/loss = 0.33872562646865845, train/raw-loss = 0.3073289394378662, train/logprobs = tensor([[-1.4533, -6.4212],
        [-2.9286, -2.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3139670491218567
Epoch 0, Step 1839: train/loss = 0.39481738209724426, train/raw-loss = 0.3675447404384613, train/logprobs = tensor([[-1.2061, -2.5202],
        [-2.6006, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27272629737854004
Epoch 0, Step 1840: train/loss = 0.4596109390258789, train/raw-loss = 0.4258096516132355, train/logprobs = tensor([[-0.9969, -1.3891],
        [-3.0806, -1.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3380124568939209
Epoch 0, Step 1841: train/loss = 0.4130254089832306, train/raw-loss = 0.38119176030158997, train/logprobs = tensor([[-1.4367, -3.0021],
        [-2.2768, -1.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3183365762233734
Epoch 0, Step 1842: train/loss = 0.447644978761673, train/raw-loss = 0.4208642542362213, train/logprobs = tensor([[-1.1423, -3.7949],
        [-1.8011, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26780709624290466
Epoch 0, Step 1843: train/loss = 0.6828616857528687, train/raw-loss = 0.6579965949058533, train/logprobs = tensor([[-1.6658, -1.9537],
        [-1.9304, -1.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24865016341209412
Epoch 0, Step 1844: train/loss = 0.7311021089553833, train/raw-loss = 0.704048216342926, train/logprobs = tensor([[-0.7626, -0.8863],
        [-1.4385, -1.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27053818106651306
Epoch 0, Step 1845: train/loss = 0.4850773215293884, train/raw-loss = 0.4565642178058624, train/logprobs = tensor([[-0.9597, -2.5419],
        [-1.9970, -1.3250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28513118624687195
Epoch 0, Step 1846: train/loss = 0.4541149139404297, train/raw-loss = 0.4303056597709656, train/logprobs = tensor([[-0.8079, -2.4008],
        [-1.5760, -1.0491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23809278011322021
Epoch 0, Step 1847: train/loss = 0.5515258312225342, train/raw-loss = 0.5162487030029297, train/logprobs = tensor([[-0.9007, -2.2328],
        [-2.4040, -2.3143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527718484401703
Epoch 0, Step 1848: train/loss = 0.5270814299583435, train/raw-loss = 0.5039387941360474, train/logprobs = tensor([[-0.6356, -1.9573],
        [-1.4285, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23142579197883606
Epoch 0, Step 1849: train/loss = 0.3480038046836853, train/raw-loss = 0.32213684916496277, train/logprobs = tensor([[-0.5586, -4.5600],
        [-1.2004, -1.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25866979360580444
Epoch 0, Step 1850: train/loss = 0.5222769379615784, train/raw-loss = 0.49288901686668396, train/logprobs = tensor([[-0.8967, -3.5937],
        [-2.2566, -2.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29387933015823364
Epoch 0, Step 1851: train/loss = 0.5611914396286011, train/raw-loss = 0.5333970785140991, train/logprobs = tensor([[-0.8657, -1.8398],
        [-1.7496, -1.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27794307470321655
Epoch 0, Step 1852: train/loss = 0.2631852924823761, train/raw-loss = 0.23291045427322388, train/logprobs = tensor([[-1.2919, -3.4271],
        [-2.4471, -1.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30274829268455505
Epoch 0, Step 1853: train/loss = 0.327462375164032, train/raw-loss = 0.30132606625556946, train/logprobs = tensor([[-1.1814, -4.4300],
        [-2.1128, -1.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26136332750320435
Epoch 0, Step 1854: train/loss = 0.43165552616119385, train/raw-loss = 0.40413424372673035, train/logprobs = tensor([[-0.9774, -4.0561],
        [-1.6640, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752128839492798
Epoch 0, Step 1855: train/loss = 0.6648309230804443, train/raw-loss = 0.6404092907905579, train/logprobs = tensor([[-2.2363, -4.7071],
        [-1.8605, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.244216650724411
Epoch 0, Step 1856: train/loss = 0.37676265835762024, train/raw-loss = 0.346500426530838, train/logprobs = tensor([[-1.1577, -2.6673],
        [-2.6055, -1.3206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30262234807014465
Epoch 0, Step 1857: train/loss = 0.31957319378852844, train/raw-loss = 0.29136738181114197, train/logprobs = tensor([[-1.0188, -3.9107],
        [-2.7060, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28205806016921997
Epoch 0, Step 1858: train/loss = 0.5293006896972656, train/raw-loss = 0.49779438972473145, train/logprobs = tensor([[-1.9309, -4.8950],
        [-3.0202, -1.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150631785392761
Epoch 0, Step 1859: train/loss = 0.3983213007450104, train/raw-loss = 0.37498632073402405, train/logprobs = tensor([[-1.7936, -3.4785],
        [-2.4661, -1.2320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23334982991218567
Epoch 0, Step 1860: train/loss = 0.5098505020141602, train/raw-loss = 0.4788791835308075, train/logprobs = tensor([[-1.0509, -3.9911],
        [-1.6000, -1.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3097134828567505
Epoch 0, Step 1861: train/loss = 0.2828587293624878, train/raw-loss = 0.2539516091346741, train/logprobs = tensor([[-1.4145, -4.2578],
        [-2.8141, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28907132148742676
Epoch 0, Step 1862: train/loss = 0.29879215359687805, train/raw-loss = 0.26204293966293335, train/logprobs = tensor([[-1.0685, -4.0467],
        [-3.2853, -1.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36749202013015747
Epoch 0, Step 1863: train/loss = 0.39071890711784363, train/raw-loss = 0.36558011174201965, train/logprobs = tensor([[-1.1074, -2.7206],
        [-2.4674, -1.1436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25138771533966064
Epoch 0, Step 1864: train/loss = 0.590073823928833, train/raw-loss = 0.5664187073707581, train/logprobs = tensor([[-1.1201, -1.5525],
        [-1.3455, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23655159771442413
Epoch 0, Step 1865: train/loss = 0.591429591178894, train/raw-loss = 0.563464879989624, train/logprobs = tensor([[-1.2873, -2.2219],
        [-2.1162, -1.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27964696288108826
Epoch 0, Step 1866: train/loss = 0.4828808307647705, train/raw-loss = 0.45836567878723145, train/logprobs = tensor([[-1.1118, -4.4639],
        [-1.5649, -2.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24515119194984436
Epoch 0, Step 1867: train/loss = 0.4066476821899414, train/raw-loss = 0.37045663595199585, train/logprobs = tensor([[-1.0265, -4.0475],
        [-2.9878, -1.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3619108200073242
Epoch 0, Step 1868: train/loss = 0.5849322080612183, train/raw-loss = 0.5598717927932739, train/logprobs = tensor([[-0.8475, -2.5620],
        [-1.6085, -1.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25060391426086426
Epoch 0, Step 1869: train/loss = 0.6259831190109253, train/raw-loss = 0.602118968963623, train/logprobs = tensor([[-0.8087, -1.5620],
        [-1.1058, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23864126205444336
Epoch 0, Step 1870: train/loss = 0.2674626111984253, train/raw-loss = 0.2383422553539276, train/logprobs = tensor([[-1.1085, -5.3405],
        [-2.3777, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2912038564682007
Epoch 0, Step 1871: train/loss = 0.4671403169631958, train/raw-loss = 0.4447869658470154, train/logprobs = tensor([[-0.9472, -4.3001],
        [-1.1366, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235337346792221
Epoch 0, Step 1872: train/loss = 0.31958580017089844, train/raw-loss = 0.2935999035835266, train/logprobs = tensor([[-1.4579, -5.1046],
        [-2.5152, -1.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.259859174489975
Epoch 0, Step 1873: train/loss = 0.5973724126815796, train/raw-loss = 0.571130633354187, train/logprobs = tensor([[-0.7628, -0.9627],
        [-1.5557, -1.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26241737604141235
Epoch 0, Step 1874: train/loss = 0.35976552963256836, train/raw-loss = 0.32923099398612976, train/logprobs = tensor([[-1.0454, -2.6145],
        [-1.8483, -1.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053455054759979
Epoch 0, Step 1875: train/loss = 0.6175881624221802, train/raw-loss = 0.5952275991439819, train/logprobs = tensor([[-0.7637, -1.1568],
        [-1.2780, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236049622297287
Epoch 0, Step 1876: train/loss = 0.35900548100471497, train/raw-loss = 0.33339324593544006, train/logprobs = tensor([[-1.0746, -4.3234],
        [-2.1526, -1.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561219036579132
Epoch 0, Step 1877: train/loss = 0.48844248056411743, train/raw-loss = 0.4575621485710144, train/logprobs = tensor([[-0.9822, -2.4797],
        [-2.5185, -2.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088032305240631
Epoch 0, Step 1878: train/loss = 0.33898690342903137, train/raw-loss = 0.3094008266925812, train/logprobs = tensor([[-0.8879, -2.5072],
        [-2.4205, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2958608567714691
Epoch 0, Step 1879: train/loss = 0.648570716381073, train/raw-loss = 0.618708074092865, train/logprobs = tensor([[-0.8499, -1.2265],
        [-1.9549, -1.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29862648248672485
Epoch 0, Step 1880: train/loss = 0.6009677648544312, train/raw-loss = 0.5710299015045166, train/logprobs = tensor([[-1.4659, -1.9236],
        [-1.9182, -1.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29937806725502014
Epoch 0, Step 1881: train/loss = 0.4618390202522278, train/raw-loss = 0.4372715353965759, train/logprobs = tensor([[-0.9254, -3.0036],
        [-1.4308, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24567502737045288
Epoch 0, Step 1882: train/loss = 0.12708577513694763, train/raw-loss = 0.09996380656957626, train/logprobs = tensor([[-1.2394, -8.4908],
        [-2.8066, -1.5964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27121973037719727
Epoch 0, Step 1883: train/loss = 0.8103283047676086, train/raw-loss = 0.7798454165458679, train/logprobs = tensor([[-3.1667, -6.4884],
        [-2.2427, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048287630081177
Epoch 0, Step 1884: train/loss = 0.5483150482177734, train/raw-loss = 0.5262079834938049, train/logprobs = tensor([[-0.7335, -4.1397],
        [-1.8736, -2.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22107070684432983
Epoch 0, Step 1885: train/loss = 0.46627891063690186, train/raw-loss = 0.43750548362731934, train/logprobs = tensor([[-0.6165, -2.9388],
        [-1.6134, -1.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2877344489097595
Epoch 0, Step 1886: train/loss = 0.5809035301208496, train/raw-loss = 0.5580251216888428, train/logprobs = tensor([[-0.9712, -1.7393],
        [-1.2940, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2287842482328415
Epoch 0, Step 1887: train/loss = 0.608776330947876, train/raw-loss = 0.5743837356567383, train/logprobs = tensor([[-2.3839, -4.3925],
        [-2.3397, -1.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34392571449279785
Epoch 0, Step 1888: train/loss = 0.5058243274688721, train/raw-loss = 0.4780161380767822, train/logprobs = tensor([[-0.9974, -2.6399],
        [-2.9838, -1.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780821919441223
Epoch 0, Step 1889: train/loss = 0.4924418330192566, train/raw-loss = 0.46526259183883667, train/logprobs = tensor([[-1.2424, -2.5919],
        [-2.4367, -1.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27179208397865295
Epoch 0, Step 1890: train/loss = 0.5368860363960266, train/raw-loss = 0.5031951665878296, train/logprobs = tensor([[-0.9540, -1.5470],
        [-2.4388, -1.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3369080722332001
Epoch 0, Step 1891: train/loss = 0.5839896202087402, train/raw-loss = 0.5576134920120239, train/logprobs = tensor([[-1.4317, -2.9897],
        [-2.0039, -1.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637616693973541
Epoch 0, Step 1892: train/loss = 0.21979624032974243, train/raw-loss = 0.18819884955883026, train/logprobs = tensor([[-1.0582, -7.6578],
        [-3.5222, -1.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3159738779067993
Epoch 0, Step 1893: train/loss = 0.42242729663848877, train/raw-loss = 0.39725321531295776, train/logprobs = tensor([[-0.7400, -4.0115],
        [-1.6567, -1.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517409324645996
Epoch 0, Step 1894: train/loss = 0.5086692571640015, train/raw-loss = 0.4782552123069763, train/logprobs = tensor([[-1.0692, -5.2356],
        [-1.8415, -2.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041402995586395
Epoch 0, Step 1895: train/loss = 0.4642060697078705, train/raw-loss = 0.43589699268341064, train/logprobs = tensor([[-1.8212, -1.3528],
        [-3.3316, -1.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28309115767478943
Epoch 0, Step 1896: train/loss = 0.3949841558933258, train/raw-loss = 0.3690485954284668, train/logprobs = tensor([[-1.7114, -3.8573],
        [-2.4320, -1.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25935572385787964
Epoch 0, Step 1897: train/loss = 0.6393677592277527, train/raw-loss = 0.6171790361404419, train/logprobs = tensor([[-1.0743, -1.9957],
        [-1.4684, -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2218872457742691
Epoch 0, Step 1898: train/loss = 0.42543694376945496, train/raw-loss = 0.39926794171333313, train/logprobs = tensor([[-0.7082, -3.0489],
        [-2.0038, -1.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616899311542511
Epoch 0, Step 1899: train/loss = 0.45846349000930786, train/raw-loss = 0.4341917634010315, train/logprobs = tensor([[-1.0222, -4.0017],
        [-1.4560, -1.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24271658062934875
Epoch 0, Step 1900: train/loss = 0.3285882771015167, train/raw-loss = 0.30291372537612915, train/logprobs = tensor([[-0.9685, -4.9532],
        [-1.9223, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567453980445862
Epoch 0, Step 1901: train/loss = 0.2569454312324524, train/raw-loss = 0.22894075512886047, train/logprobs = tensor([[-1.2631, -3.4759],
        [-2.5705, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28004688024520874
Epoch 0, Step 1902: train/loss = 0.5313054919242859, train/raw-loss = 0.5096763372421265, train/logprobs = tensor([[-0.5286, -2.7768],
        [-0.9900, -2.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21629145741462708
Epoch 0, Step 1903: train/loss = 0.38435783982276917, train/raw-loss = 0.36251580715179443, train/logprobs = tensor([[-0.7608, -3.1576],
        [-1.5753, -1.5430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21841973066329956
Epoch 0, Step 1904: train/loss = 0.7061202526092529, train/raw-loss = 0.6796150803565979, train/logprobs = tensor([[-2.3032, -8.4100],
        [-1.9807, -3.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26505202054977417
Epoch 0, Step 1905: train/loss = 0.3521801829338074, train/raw-loss = 0.3227437138557434, train/logprobs = tensor([[-1.1341, -2.5068],
        [-2.2126, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943647801876068
Epoch 0, Step 1906: train/loss = 0.47954708337783813, train/raw-loss = 0.4542069137096405, train/logprobs = tensor([[-1.0693, -4.1149],
        [-2.3044, -1.2783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534014582633972
Epoch 0, Step 1907: train/loss = 0.299689382314682, train/raw-loss = 0.27081578969955444, train/logprobs = tensor([[-1.3656, -3.6335],
        [-3.2974, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887357473373413
Epoch 0, Step 1908: train/loss = 0.41699278354644775, train/raw-loss = 0.3874000906944275, train/logprobs = tensor([[-1.1311, -3.3474],
        [-1.9310, -1.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29592689871788025
Epoch 0, Step 1909: train/loss = 0.3258069157600403, train/raw-loss = 0.2953437566757202, train/logprobs = tensor([[-1.3908, -4.7124],
        [-2.5749, -1.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3046315312385559
Epoch 0, Step 1910: train/loss = 0.26542484760284424, train/raw-loss = 0.23978212475776672, train/logprobs = tensor([[-0.7553, -3.4354],
        [-2.4305, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25642716884613037
Epoch 0, Step 1911: train/loss = 0.6334011554718018, train/raw-loss = 0.6048997640609741, train/logprobs = tensor([[-1.1061, -1.4480],
        [-1.3488, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28501367568969727
Epoch 0, Step 1912: train/loss = 0.56974858045578, train/raw-loss = 0.5375841856002808, train/logprobs = tensor([[-1.3414, -2.9002],
        [-2.0205, -1.6481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32164397835731506
Epoch 0, Step 1913: train/loss = 0.7473145723342896, train/raw-loss = 0.7152588367462158, train/logprobs = tensor([[-0.6537, -0.9650],
        [-1.8114, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205586075782776
Epoch 0, Step 1914: train/loss = 0.1476026177406311, train/raw-loss = 0.11613576114177704, train/logprobs = tensor([[-0.9136, -4.6734],
        [-3.0492, -1.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31466853618621826
Epoch 0, Step 1915: train/loss = 0.5409461259841919, train/raw-loss = 0.5128871202468872, train/logprobs = tensor([[-1.1884, -2.1335],
        [-1.7718, -1.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805894613265991
Epoch 0, Step 1916: train/loss = 0.3539797067642212, train/raw-loss = 0.32466065883636475, train/logprobs = tensor([[-1.6588, -4.7032],
        [-2.2529, -1.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2931899428367615
Epoch 0, Step 1917: train/loss = 0.14475344121456146, train/raw-loss = 0.10954947024583817, train/logprobs = tensor([[-0.9864, -4.6243],
        [-2.9897, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3520396649837494
Epoch 0, Step 1918: train/loss = 0.37622007727622986, train/raw-loss = 0.3486116826534271, train/logprobs = tensor([[-0.8417, -2.2935],
        [-2.1436, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760840356349945
Epoch 0, Step 1919: train/loss = 0.6100821495056152, train/raw-loss = 0.5826594829559326, train/logprobs = tensor([[-1.6572, -3.9719],
        [-1.4928, -1.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742269039154053
Epoch 0, Step 1920: train/loss = 0.4210578203201294, train/raw-loss = 0.39833366870880127, train/logprobs = tensor([[-1.1760, -2.9275],
        [-1.5266, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22724145650863647
Epoch 0, Step 1921: train/loss = 0.5818843841552734, train/raw-loss = 0.557499885559082, train/logprobs = tensor([[-1.3826, -2.0872],
        [-1.2467, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438451051712036
Epoch 0, Step 1922: train/loss = 0.6003233790397644, train/raw-loss = 0.5767856240272522, train/logprobs = tensor([[-1.0121, -1.8169],
        [-1.3029, -1.4722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23537752032279968
Epoch 0, Step 1923: train/loss = 0.3248216211795807, train/raw-loss = 0.2978842258453369, train/logprobs = tensor([[-0.8318, -4.1002],
        [-2.5765, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693741023540497
Epoch 0, Step 1924: train/loss = 0.3864612579345703, train/raw-loss = 0.3626084625720978, train/logprobs = tensor([[-1.3747, -4.2564],
        [-1.6855, -1.3261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23852801322937012
Epoch 0, Step 1925: train/loss = 0.2654569745063782, train/raw-loss = 0.2371208667755127, train/logprobs = tensor([[-1.2560, -8.4040],
        [-2.8779, -3.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28336119651794434
Epoch 0, Step 1926: train/loss = 0.6084929704666138, train/raw-loss = 0.5867830514907837, train/logprobs = tensor([[-0.9876, -1.3661],
        [-1.0972, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21709981560707092
Epoch 0, Step 1927: train/loss = 0.515582263469696, train/raw-loss = 0.48251479864120483, train/logprobs = tensor([[-1.0278, -4.8597],
        [-2.6393, -1.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330674409866333
Epoch 0, Step 1928: train/loss = 0.40117669105529785, train/raw-loss = 0.3766828179359436, train/logprobs = tensor([[-0.9688, -1.8616],
        [-2.3468, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24493876099586487
Epoch 0, Step 1929: train/loss = 0.20235808193683624, train/raw-loss = 0.17536240816116333, train/logprobs = tensor([[-1.5989, -9.4826],
        [-2.8515, -2.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699568569660187
Epoch 0, Step 1930: train/loss = 0.6861145496368408, train/raw-loss = 0.6584893465042114, train/logprobs = tensor([[-0.9863, -1.1694],
        [-1.9200, -1.6428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2762521505355835
Epoch 0, Step 1931: train/loss = 0.3904236853122711, train/raw-loss = 0.3592369258403778, train/logprobs = tensor([[-0.8459, -4.8039],
        [-2.8965, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3118675947189331
Epoch 0, Step 1932: train/loss = 0.4690595865249634, train/raw-loss = 0.43863803148269653, train/logprobs = tensor([[-1.0361, -2.2770],
        [-2.4497, -1.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30421513319015503
Epoch 0, Step 1933: train/loss = 0.4052322506904602, train/raw-loss = 0.37799033522605896, train/logprobs = tensor([[-1.0968, -2.5830],
        [-1.9313, -1.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724195420742035
Epoch 0, Step 1934: train/loss = 0.30681556463241577, train/raw-loss = 0.2752118706703186, train/logprobs = tensor([[-1.7220, -5.9392],
        [-3.0590, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31603705883026123
Epoch 0, Step 1935: train/loss = 0.23236064612865448, train/raw-loss = 0.20156753063201904, train/logprobs = tensor([[-0.9082, -4.4173],
        [-3.1716, -1.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079313337802887
Epoch 0, Step 1936: train/loss = 0.5529482960700989, train/raw-loss = 0.531215250492096, train/logprobs = tensor([[-1.1695, -1.5336],
        [-2.3680, -1.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21733079850673676
Epoch 0, Step 1937: train/loss = 0.5498411059379578, train/raw-loss = 0.5252361297607422, train/logprobs = tensor([[-0.9747, -2.8800],
        [-2.0919, -2.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24605020880699158
Epoch 0, Step 1938: train/loss = 0.4753698706626892, train/raw-loss = 0.4473547041416168, train/logprobs = tensor([[-1.2523, -3.3203],
        [-3.0070, -1.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801515460014343
Epoch 0, Step 1939: train/loss = 0.5617390275001526, train/raw-loss = 0.5379655361175537, train/logprobs = tensor([[-0.7903, -1.3013],
        [-1.6036, -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23773479461669922
Epoch 0, Step 1940: train/loss = 0.46384990215301514, train/raw-loss = 0.4345625936985016, train/logprobs = tensor([[-1.5921, -2.4153],
        [-2.0760, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2928728461265564
Epoch 0, Step 1941: train/loss = 0.5466441512107849, train/raw-loss = 0.5189704298973083, train/logprobs = tensor([[-1.4468, -2.4567],
        [-1.6466, -1.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767373323440552
Epoch 0, Step 1942: train/loss = 0.48989927768707275, train/raw-loss = 0.4621227979660034, train/logprobs = tensor([[-0.8937, -2.7516],
        [-2.0109, -1.3410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27776476740837097
Epoch 0, Step 1943: train/loss = 0.4472808241844177, train/raw-loss = 0.4176614582538605, train/logprobs = tensor([[-0.7743, -2.5251],
        [-1.9970, -1.1262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961937189102173
Epoch 0, Step 1944: train/loss = 0.32579654455184937, train/raw-loss = 0.2959916889667511, train/logprobs = tensor([[-1.0503, -4.8467],
        [-2.7656, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2980486750602722
Epoch 0, Step 1945: train/loss = 0.2575380206108093, train/raw-loss = 0.2266320288181305, train/logprobs = tensor([[-0.9749, -7.0427],
        [-2.9809, -2.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30905982851982117
Epoch 0, Step 1946: train/loss = 0.5872140526771545, train/raw-loss = 0.5557107925415039, train/logprobs = tensor([[-1.7673, -2.2303],
        [-2.5672, -2.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150327801704407
Epoch 0, Step 1947: train/loss = 0.6019505858421326, train/raw-loss = 0.5738446116447449, train/logprobs = tensor([[-1.1278, -2.8080],
        [-2.8772, -2.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2810594439506531
Epoch 0, Step 1948: train/loss = 0.3167122006416321, train/raw-loss = 0.29179614782333374, train/logprobs = tensor([[-1.3158, -4.2340],
        [-1.7831, -1.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24916040897369385
Epoch 0, Step 1949: train/loss = 0.6261265873908997, train/raw-loss = 0.5945618152618408, train/logprobs = tensor([[-0.9994, -1.7442],
        [-2.6779, -2.3393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31564775109291077
Epoch 0, Step 1950: train/loss = 0.3961526155471802, train/raw-loss = 0.3639715313911438, train/logprobs = tensor([[-0.9645, -2.2102],
        [-2.9158, -1.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.321810781955719
Epoch 0, Step 1951: train/loss = 0.33791384100914, train/raw-loss = 0.30781668424606323, train/logprobs = tensor([[-1.4568, -3.2324],
        [-3.1062, -1.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30097150802612305
Epoch 0, Step 1952: train/loss = 0.42621472477912903, train/raw-loss = 0.3985021114349365, train/logprobs = tensor([[-1.3160, -3.3020],
        [-2.3701, -1.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.277125746011734
Epoch 0, Step 1953: train/loss = 0.24807320535182953, train/raw-loss = 0.2194681167602539, train/logprobs = tensor([[-0.7771, -5.8547],
        [-2.0003, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860509157180786
Epoch 0, Step 1954: train/loss = 0.48408979177474976, train/raw-loss = 0.4590461552143097, train/logprobs = tensor([[-1.6782, -2.9996],
        [-2.5305, -1.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25043660402297974
Epoch 0, Step 1955: train/loss = 0.5648689270019531, train/raw-loss = 0.5396980047225952, train/logprobs = tensor([[-0.6897, -1.5763],
        [-1.4055, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25170910358428955
Epoch 0, Step 1956: train/loss = 0.452983558177948, train/raw-loss = 0.4246737062931061, train/logprobs = tensor([[-0.8836, -3.3170],
        [-2.3526, -1.7794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28309857845306396
Epoch 0, Step 1957: train/loss = 0.5060279369354248, train/raw-loss = 0.47621676325798035, train/logprobs = tensor([[-1.2081, -2.0825],
        [-2.4988, -1.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2981113791465759
Epoch 0, Step 1958: train/loss = 0.5377627015113831, train/raw-loss = 0.513732373714447, train/logprobs = tensor([[-1.1256, -1.4340],
        [-1.7275, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24030327796936035
Epoch 0, Step 1959: train/loss = 0.4618381857872009, train/raw-loss = 0.4380347430706024, train/logprobs = tensor([[-0.8511, -3.2038],
        [-1.2139, -1.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380344569683075
Epoch 0, Step 1960: train/loss = 0.40490400791168213, train/raw-loss = 0.3806428611278534, train/logprobs = tensor([[-1.0517, -6.5164],
        [-3.4741, -1.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24261149764060974
Epoch 0, Step 1961: train/loss = 0.42574065923690796, train/raw-loss = 0.40132278203964233, train/logprobs = tensor([[-1.3261, -2.2492],
        [-2.0135, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24417853355407715
Epoch 0, Step 1962: train/loss = 0.49293994903564453, train/raw-loss = 0.4702706038951874, train/logprobs = tensor([[-0.9463, -2.0023],
        [-1.9882, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22669342160224915
Epoch 0, Step 1963: train/loss = 0.31717851758003235, train/raw-loss = 0.29453957080841064, train/logprobs = tensor([[-1.6289, -8.0416],
        [-1.8260, -2.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263895571231842
Epoch 0, Step 1964: train/loss = 0.847422182559967, train/raw-loss = 0.8214395046234131, train/logprobs = tensor([[-2.7696, -4.2809],
        [-1.5327, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25982654094696045
Epoch 0, Step 1965: train/loss = 0.589028537273407, train/raw-loss = 0.5589694380760193, train/logprobs = tensor([[-1.5925, -1.8434],
        [-1.7552, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005909025669098
Epoch 0, Step 1966: train/loss = 0.37102946639060974, train/raw-loss = 0.3401610851287842, train/logprobs = tensor([[-0.9268, -3.9639],
        [-2.5999, -1.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086838126182556
Epoch 0, Step 1967: train/loss = 0.5234692096710205, train/raw-loss = 0.5011268854141235, train/logprobs = tensor([[-1.1601, -2.3762],
        [-1.3805, -0.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234233021736145
Epoch 0, Step 1968: train/loss = 0.5718996524810791, train/raw-loss = 0.5413322448730469, train/logprobs = tensor([[-1.4020, -2.4397],
        [-2.4744, -1.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30567434430122375
Epoch 0, Step 1969: train/loss = 0.26944753527641296, train/raw-loss = 0.2418062537908554, train/logprobs = tensor([[-1.2840, -7.0247],
        [-2.7316, -1.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27641260623931885
Epoch 0, Step 1970: train/loss = 0.5401880741119385, train/raw-loss = 0.5084785223007202, train/logprobs = tensor([[-1.3090, -2.9250],
        [-2.6748, -1.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31709569692611694
Epoch 0, Step 1971: train/loss = 0.5042531490325928, train/raw-loss = 0.4795544147491455, train/logprobs = tensor([[-1.1643, -1.7654],
        [-1.7810, -1.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24698695540428162
Epoch 0, Step 1972: train/loss = 0.38461607694625854, train/raw-loss = 0.35512760281562805, train/logprobs = tensor([[-0.6891, -2.5420],
        [-2.1720, -1.2822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29488468170166016
Epoch 0, Step 1973: train/loss = 0.42347681522369385, train/raw-loss = 0.39681297540664673, train/logprobs = tensor([[-1.0175, -5.1465],
        [-2.5963, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26663827896118164
Epoch 0, Step 1974: train/loss = 0.7777276039123535, train/raw-loss = 0.752882719039917, train/logprobs = tensor([[-1.5037, -1.4769],
        [-1.5943, -1.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24844874441623688
Epoch 0, Step 1975: train/loss = 0.3780873119831085, train/raw-loss = 0.34753337502479553, train/logprobs = tensor([[-0.9154, -3.7372],
        [-2.1036, -1.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305539608001709
Epoch 0, Step 1976: train/loss = 0.5161821842193604, train/raw-loss = 0.4880903959274292, train/logprobs = tensor([[-2.3178, -5.7750],
        [-2.0582, -1.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2809179425239563
Epoch 0, Step 1977: train/loss = 0.48203861713409424, train/raw-loss = 0.45479273796081543, train/logprobs = tensor([[-1.6264, -4.6029],
        [-2.2393, -1.3723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2724587917327881
Epoch 0, Step 1978: train/loss = 0.4542597532272339, train/raw-loss = 0.4310539662837982, train/logprobs = tensor([[-0.7782, -2.3848],
        [-1.5634, -1.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2320576012134552
Epoch 0, Step 1979: train/loss = 0.6092582941055298, train/raw-loss = 0.5840001106262207, train/logprobs = tensor([[-0.7697, -0.7775],
        [-1.7312, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25258222222328186
Epoch 0, Step 1980: train/loss = 0.5256707668304443, train/raw-loss = 0.4984422028064728, train/logprobs = tensor([[-0.9211, -2.3239],
        [-1.7205, -1.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722858786582947
Epoch 0, Step 1981: train/loss = 0.4625778794288635, train/raw-loss = 0.42913222312927246, train/logprobs = tensor([[-1.8252, -2.6665],
        [-3.6136, -1.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344564735889435
Epoch 0, Step 1982: train/loss = 0.49397677183151245, train/raw-loss = 0.4672004282474518, train/logprobs = tensor([[-0.8747, -3.0610],
        [-1.9079, -1.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2677631378173828
Epoch 0, Step 1983: train/loss = 0.5313615798950195, train/raw-loss = 0.5063393115997314, train/logprobs = tensor([[-0.8499, -1.5538],
        [-1.5033, -1.2799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502231001853943
Epoch 0, Step 1984: train/loss = 0.6359769701957703, train/raw-loss = 0.611836850643158, train/logprobs = tensor([[-0.5192, -1.3961],
        [-1.4156, -1.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24140147864818573
Epoch 0, Step 1985: train/loss = 0.6572796106338501, train/raw-loss = 0.6339433193206787, train/logprobs = tensor([[-0.8983, -1.1526],
        [-1.3327, -1.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23336350917816162
Epoch 0, Step 1986: train/loss = 0.5614836812019348, train/raw-loss = 0.5380867719650269, train/logprobs = tensor([[-0.8725, -1.6691],
        [-1.2798, -1.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23396921157836914
Epoch 0, Step 1987: train/loss = 0.439215749502182, train/raw-loss = 0.4173263907432556, train/logprobs = tensor([[-1.0749, -3.4762],
        [-1.3382, -1.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21889376640319824
Epoch 0, Step 1988: train/loss = 0.3290906250476837, train/raw-loss = 0.3017597496509552, train/logprobs = tensor([[-1.0148, -3.5769],
        [-2.2091, -1.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27330902218818665
Epoch 0, Step 1989: train/loss = 0.2845654785633087, train/raw-loss = 0.2531954348087311, train/logprobs = tensor([[-1.7687, -6.0600],
        [-2.8716, -2.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31370028853416443
Epoch 0, Step 1990: train/loss = 0.4872280955314636, train/raw-loss = 0.4631883203983307, train/logprobs = tensor([[-1.1791, -4.0717],
        [-1.7652, -1.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24039773643016815
Epoch 0, Step 1991: train/loss = 0.6177437901496887, train/raw-loss = 0.5914933681488037, train/logprobs = tensor([[-0.9649, -1.1718],
        [-1.5100, -1.2489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262503981590271
Epoch 0, Step 1992: train/loss = 0.472873330116272, train/raw-loss = 0.4495633840560913, train/logprobs = tensor([[-1.0312, -3.7171],
        [-1.8901, -1.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23309923708438873
Epoch 0, Step 1993: train/loss = 0.3666462302207947, train/raw-loss = 0.34050971269607544, train/logprobs = tensor([[-1.6347, -5.7155],
        [-2.4446, -2.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26136529445648193
Epoch 0, Step 1994: train/loss = 0.39168596267700195, train/raw-loss = 0.36515915393829346, train/logprobs = tensor([[-1.0605, -3.9695],
        [-1.8136, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652677595615387
Epoch 0, Step 1995: train/loss = 0.46232330799102783, train/raw-loss = 0.43970125913619995, train/logprobs = tensor([[-1.0644, -2.6982],
        [-1.3954, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22622066736221313
Epoch 0, Step 1996: train/loss = 0.6417419910430908, train/raw-loss = 0.6111582517623901, train/logprobs = tensor([[-1.1506, -3.2220],
        [-2.0561, -1.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3058372735977173
Epoch 0, Step 1997: train/loss = 0.5191085934638977, train/raw-loss = 0.4907234013080597, train/logprobs = tensor([[-1.0321, -2.8981],
        [-1.6326, -1.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838517427444458
Epoch 0, Step 1998: train/loss = 0.49685773253440857, train/raw-loss = 0.47108039259910583, train/logprobs = tensor([[-1.6584, -6.0050],
        [-2.6629, -4.2556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25777339935302734
Epoch 0, Step 1999: train/loss = 0.5301451683044434, train/raw-loss = 0.504600465297699, train/logprobs = tensor([[-1.3740, -3.3252],
        [-2.1537, -1.3627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255447119474411
Epoch 0, Step 2000: train/loss = 0.3069879412651062, train/raw-loss = 0.28046655654907227, train/logprobs = tensor([[-0.8995, -2.9796],
        [-1.9599, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26521390676498413
Epoch 0, Step 2001: train/loss = 0.4570700526237488, train/raw-loss = 0.4290914237499237, train/logprobs = tensor([[-0.8804, -2.6318],
        [-1.9458, -1.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2797865867614746
Epoch 0, Step 2002: train/loss = 0.2808859050273895, train/raw-loss = 0.25067251920700073, train/logprobs = tensor([[-1.6567, -4.5389],
        [-2.8970, -1.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021339178085327
Epoch 0, Step 2003: train/loss = 0.21522420644760132, train/raw-loss = 0.1863878220319748, train/logprobs = tensor([[-0.8984, -4.3331],
        [-2.9006, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883639633655548
Epoch 0, Step 2004: train/loss = 0.5570783615112305, train/raw-loss = 0.5308692455291748, train/logprobs = tensor([[-1.0196, -2.1037],
        [-1.9638, -1.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26209166646003723
Epoch 0, Step 2005: train/loss = 0.47565487027168274, train/raw-loss = 0.44787442684173584, train/logprobs = tensor([[-0.9906, -3.3815],
        [-2.2265, -1.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27780455350875854
Epoch 0, Step 2006: train/loss = 0.5125077962875366, train/raw-loss = 0.4827253222465515, train/logprobs = tensor([[-1.6898, -4.0126],
        [-1.8872, -1.5533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29782429337501526
Epoch 0, Step 2007: train/loss = 0.29952192306518555, train/raw-loss = 0.27127134799957275, train/logprobs = tensor([[-1.1652, -4.3982],
        [-2.6010, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28250572085380554
Epoch 0, Step 2008: train/loss = 0.37240391969680786, train/raw-loss = 0.34870898723602295, train/logprobs = tensor([[-1.1348, -4.1881],
        [-1.3681, -1.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23694926500320435
Epoch 0, Step 2009: train/loss = 0.44073808193206787, train/raw-loss = 0.41070783138275146, train/logprobs = tensor([[-1.7703, -3.5002],
        [-2.6505, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003027141094208
Epoch 0, Step 2010: train/loss = 0.4604106545448303, train/raw-loss = 0.43731656670570374, train/logprobs = tensor([[-0.9530, -4.3623],
        [-1.2541, -0.6825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23094049096107483
Epoch 0, Step 2011: train/loss = 0.48642420768737793, train/raw-loss = 0.4588984549045563, train/logprobs = tensor([[-0.8460, -5.1011],
        [-1.8789, -2.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752577066421509
Epoch 0, Step 2012: train/loss = 0.7442988753318787, train/raw-loss = 0.7195726633071899, train/logprobs = tensor([[-5.0068, -6.5941],
        [-4.3171, -3.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24726250767707825
Epoch 0, Step 2013: train/loss = 0.4371611177921295, train/raw-loss = 0.41006457805633545, train/logprobs = tensor([[-1.7303, -5.8967],
        [-2.6734, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2709651291370392
Epoch 0, Step 2014: train/loss = 0.29056423902511597, train/raw-loss = 0.26531165838241577, train/logprobs = tensor([[-0.8545, -4.8806],
        [-1.7796, -1.2163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525257468223572
Epoch 0, Step 2015: train/loss = 0.39347800612449646, train/raw-loss = 0.36782363057136536, train/logprobs = tensor([[-0.8095, -1.8466],
        [-1.9446, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256543904542923
Epoch 0, Step 2016: train/loss = 0.3082282841205597, train/raw-loss = 0.2711358070373535, train/logprobs = tensor([[-0.8985, -3.6756],
        [-3.3650, -2.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.370924711227417
Epoch 0, Step 2017: train/loss = 0.8816767930984497, train/raw-loss = 0.8605816960334778, train/logprobs = tensor([[-3.9305, -4.2565],
        [-2.6097, -2.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2109503597021103
Epoch 0, Step 2018: train/loss = 0.293849378824234, train/raw-loss = 0.2603309154510498, train/logprobs = tensor([[-0.8624, -4.5191],
        [-2.4373, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33518487215042114
Epoch 0, Step 2019: train/loss = 0.44649097323417664, train/raw-loss = 0.41969895362854004, train/logprobs = tensor([[-1.3467, -3.8991],
        [-2.8123, -2.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26792001724243164
Epoch 0, Step 2020: train/loss = 0.4112482964992523, train/raw-loss = 0.3816837966442108, train/logprobs = tensor([[-1.0649, -2.2211],
        [-2.3129, -1.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29564523696899414
Epoch 0, Step 2021: train/loss = 0.5537291169166565, train/raw-loss = 0.5282270312309265, train/logprobs = tensor([[-1.4916, -2.6471],
        [-1.2334, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550204396247864
Epoch 0, Step 2022: train/loss = 0.5654293298721313, train/raw-loss = 0.5374550223350525, train/logprobs = tensor([[-1.7928, -2.9381],
        [-1.9546, -1.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.279742956161499
Epoch 0, Step 2023: train/loss = 0.5114431977272034, train/raw-loss = 0.4886913299560547, train/logprobs = tensor([[-1.8003, -3.9666],
        [-1.8721, -2.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22751902043819427
Epoch 0, Step 2024: train/loss = 0.641200602054596, train/raw-loss = 0.6103321313858032, train/logprobs = tensor([[-0.8244, -1.1919],
        [-1.9090, -1.6148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086842894554138
Epoch 0, Step 2025: train/loss = 0.6288943886756897, train/raw-loss = 0.6002051830291748, train/logprobs = tensor([[-1.1162, -5.1166],
        [-1.9270, -1.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28689172863960266
Epoch 0, Step 2026: train/loss = 0.1980493813753128, train/raw-loss = 0.16676262021064758, train/logprobs = tensor([[-1.0133, -5.4062],
        [-2.6537, -2.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3128674328327179
Epoch 0, Step 2027: train/loss = 0.25325465202331543, train/raw-loss = 0.2210254669189453, train/logprobs = tensor([[-1.0224, -4.6251],
        [-2.7739, -1.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3222917914390564
Epoch 0, Step 2028: train/loss = 0.16152124106884003, train/raw-loss = 0.1336677521467209, train/logprobs = tensor([[-0.9342, -6.2416],
        [-2.7509, -0.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.278534859418869
Epoch 0, Step 2029: train/loss = 0.35920631885528564, train/raw-loss = 0.330757200717926, train/logprobs = tensor([[-1.2174, -7.5464],
        [-1.8428, -2.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2844912111759186
Epoch 0, Step 2030: train/loss = 0.3720759153366089, train/raw-loss = 0.3453957140445709, train/logprobs = tensor([[-2.0544, -5.6859],
        [-2.0409, -2.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668018341064453
Epoch 0, Step 2031: train/loss = 0.2384517788887024, train/raw-loss = 0.21126727759838104, train/logprobs = tensor([[-1.9153, -6.4239],
        [-3.2833, -0.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27184516191482544
Epoch 0, Step 2032: train/loss = 0.4573265016078949, train/raw-loss = 0.4351893365383148, train/logprobs = tensor([[-1.1525, -3.2728],
        [-1.3250, -1.0080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213716059923172
Epoch 0, Step 2033: train/loss = 0.5335808396339417, train/raw-loss = 0.5051968097686768, train/logprobs = tensor([[-1.0650, -2.9228],
        [-1.8007, -1.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2838399410247803
Epoch 0, Step 2034: train/loss = 0.4328859746456146, train/raw-loss = 0.4070602357387543, train/logprobs = tensor([[-1.5450, -5.7147],
        [-1.9648, -0.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2582573890686035
Epoch 0, Step 2035: train/loss = 0.5304471254348755, train/raw-loss = 0.5025970935821533, train/logprobs = tensor([[-1.1454, -3.1142],
        [-1.9150, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785003185272217
Epoch 0, Step 2036: train/loss = 0.6875728368759155, train/raw-loss = 0.6668936014175415, train/logprobs = tensor([[-0.5941, -0.6648],
        [-1.1227, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20679225027561188
Epoch 0, Step 2037: train/loss = 0.5929998755455017, train/raw-loss = 0.5658155679702759, train/logprobs = tensor([[-0.8631, -1.7640],
        [-2.0438, -2.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27184271812438965
Epoch 0, Step 2038: train/loss = 0.4910790026187897, train/raw-loss = 0.46300747990608215, train/logprobs = tensor([[-1.4858, -3.4459],
        [-1.9137, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807152271270752
Epoch 0, Step 2039: train/loss = 0.4218428134918213, train/raw-loss = 0.3981860876083374, train/logprobs = tensor([[-0.6863, -3.7393],
        [-1.4774, -1.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365671694278717
Epoch 0, Step 2040: train/loss = 0.7313071489334106, train/raw-loss = 0.7053449749946594, train/logprobs = tensor([[-1.0435, -1.1983],
        [-1.2221, -1.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596217691898346
Epoch 0, Step 2041: train/loss = 0.2819440960884094, train/raw-loss = 0.2520955801010132, train/logprobs = tensor([[-1.3410, -4.1916],
        [-2.1602, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29848504066467285
Epoch 0, Step 2042: train/loss = 0.6612998843193054, train/raw-loss = 0.6360287666320801, train/logprobs = tensor([[-1.0986, -1.3233],
        [-1.8297, -1.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25271129608154297
Epoch 0, Step 2043: train/loss = 0.4728800058364868, train/raw-loss = 0.4438098967075348, train/logprobs = tensor([[-0.9310, -2.8201],
        [-2.4630, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29070109128952026
Epoch 0, Step 2044: train/loss = 0.3590724468231201, train/raw-loss = 0.3237217366695404, train/logprobs = tensor([[-0.9707, -4.4404],
        [-2.3550, -1.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35350701212882996
Epoch 0, Step 2045: train/loss = 0.5059892535209656, train/raw-loss = 0.47880858182907104, train/logprobs = tensor([[-1.3222, -2.3569],
        [-2.1635, -1.6987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27180686593055725
Epoch 0, Step 2046: train/loss = 0.4896470606327057, train/raw-loss = 0.45810917019844055, train/logprobs = tensor([[-1.1366, -1.3218],
        [-2.2579, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31537914276123047
Epoch 0, Step 2047: train/loss = 0.5326308012008667, train/raw-loss = 0.5102462768554688, train/logprobs = tensor([[-0.8650, -2.0955],
        [-1.3283, -1.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22384512424468994
Epoch 0, Step 2048: train/loss = 0.3322182893753052, train/raw-loss = 0.3001832067966461, train/logprobs = tensor([[-1.8049, -5.9233],
        [-2.6751, -1.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32035061717033386
Epoch 0, Step 2049: train/loss = 0.49072182178497314, train/raw-loss = 0.4676002562046051, train/logprobs = tensor([[-0.7426, -2.4796],
        [-1.6881, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23121531307697296
Epoch 0, Step 2050: train/loss = 0.2937431335449219, train/raw-loss = 0.268446683883667, train/logprobs = tensor([[-1.1374, -3.7942],
        [-2.8715, -0.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529645264148712
Epoch 0, Step 2051: train/loss = 0.12980781495571136, train/raw-loss = 0.10036490112543106, train/logprobs = tensor([[-1.3139, -5.5941],
        [-3.5377, -1.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29442912340164185
Epoch 0, Step 2052: train/loss = 0.23130519688129425, train/raw-loss = 0.20116683840751648, train/logprobs = tensor([[-0.8350, -4.5013],
        [-2.1761, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013835549354553
Epoch 0, Step 2053: train/loss = 0.5777294635772705, train/raw-loss = 0.5495607852935791, train/logprobs = tensor([[-0.9799, -2.1581],
        [-1.9328, -1.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2816867232322693
Epoch 0, Step 2054: train/loss = 0.6378143429756165, train/raw-loss = 0.6106275320053101, train/logprobs = tensor([[-1.3726, -1.7553],
        [-1.9558, -1.8191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27186819911003113
Epoch 0, Step 2055: train/loss = 0.47348058223724365, train/raw-loss = 0.4442684054374695, train/logprobs = tensor([[-0.8402, -2.4835],
        [-1.7990, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29212164878845215
Epoch 0, Step 2056: train/loss = 0.43674910068511963, train/raw-loss = 0.4042122960090637, train/logprobs = tensor([[-1.5665, -3.3340],
        [-2.3203, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253682255744934
Epoch 0, Step 2057: train/loss = 0.39323949813842773, train/raw-loss = 0.3635919392108917, train/logprobs = tensor([[-1.3024, -4.8673],
        [-2.7362, -1.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29647567868232727
Epoch 0, Step 2058: train/loss = 0.5234869718551636, train/raw-loss = 0.5014758110046387, train/logprobs = tensor([[-1.0663, -1.8184],
        [-1.5543, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22011181712150574
Epoch 0, Step 2059: train/loss = 0.4374643564224243, train/raw-loss = 0.41194555163383484, train/logprobs = tensor([[-1.2797, -4.9238],
        [-1.8969, -3.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25518789887428284
Epoch 0, Step 2060: train/loss = 0.4663095474243164, train/raw-loss = 0.4392186105251312, train/logprobs = tensor([[-1.3077, -4.0623],
        [-1.7731, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27090907096862793
Epoch 0, Step 2061: train/loss = 0.3703323006629944, train/raw-loss = 0.345942884683609, train/logprobs = tensor([[-0.9480, -2.7664],
        [-1.6607, -1.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438942939043045
Epoch 0, Step 2062: train/loss = 0.2965334951877594, train/raw-loss = 0.26452574133872986, train/logprobs = tensor([[-0.8125, -4.9505],
        [-2.1939, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200776278972626
Epoch 0, Step 2063: train/loss = 0.7374720573425293, train/raw-loss = 0.708663284778595, train/logprobs = tensor([[-0.9964, -3.0383],
        [-2.3905, -2.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28808799386024475
Epoch 0, Step 2064: train/loss = 0.41969549655914307, train/raw-loss = 0.3940296769142151, train/logprobs = tensor([[-1.1105, -2.8600],
        [-1.7146, -1.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566579580307007
Epoch 0, Step 2065: train/loss = 0.5471453666687012, train/raw-loss = 0.523470401763916, train/logprobs = tensor([[-0.9401, -1.8389],
        [-1.0462, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23674945533275604
Epoch 0, Step 2066: train/loss = 0.7010871171951294, train/raw-loss = 0.6684110164642334, train/logprobs = tensor([[-1.3997, -1.8398],
        [-1.8637, -2.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3267609179019928
Epoch 0, Step 2067: train/loss = 0.5074853897094727, train/raw-loss = 0.479983389377594, train/logprobs = tensor([[-1.1514, -2.9635],
        [-2.2194, -1.6053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750197947025299
Epoch 0, Step 2068: train/loss = 0.41899681091308594, train/raw-loss = 0.39636868238449097, train/logprobs = tensor([[-1.0423, -2.3006],
        [-1.7734, -0.6174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2262813001871109
Epoch 0, Step 2069: train/loss = 0.4306754767894745, train/raw-loss = 0.402199387550354, train/logprobs = tensor([[-1.8167, -5.8255],
        [-1.6053, -1.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2847611606121063
Epoch 0, Step 2070: train/loss = 0.5167891979217529, train/raw-loss = 0.488334059715271, train/logprobs = tensor([[-1.2567, -2.8961],
        [-2.0705, -1.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845509648323059
Epoch 0, Step 2071: train/loss = 0.24051985144615173, train/raw-loss = 0.21072691679000854, train/logprobs = tensor([[-1.0801, -5.2747],
        [-2.4752, -1.5724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29792922735214233
Epoch 0, Step 2072: train/loss = 0.14264968037605286, train/raw-loss = 0.11524522304534912, train/logprobs = tensor([[-0.8769, -7.0730],
        [-2.7329, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740445137023926
Epoch 0, Step 2073: train/loss = 0.39302054047584534, train/raw-loss = 0.36740100383758545, train/logprobs = tensor([[-1.1721, -2.9441],
        [-1.5965, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2561955451965332
Epoch 0, Step 2074: train/loss = 0.37768056988716125, train/raw-loss = 0.3417991101741791, train/logprobs = tensor([[-1.8768, -4.4567],
        [-2.5371, -1.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35881468653678894
Epoch 0, Step 2075: train/loss = 0.5097448825836182, train/raw-loss = 0.48307329416275024, train/logprobs = tensor([[-0.9115, -1.5441],
        [-2.2392, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26671624183654785
Epoch 0, Step 2076: train/loss = 0.5854858756065369, train/raw-loss = 0.5613069534301758, train/logprobs = tensor([[-0.9546, -2.4494],
        [-1.5436, -1.5321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24178895354270935
Epoch 0, Step 2077: train/loss = 0.429781973361969, train/raw-loss = 0.40464234352111816, train/logprobs = tensor([[-2.0200, -6.7534],
        [-2.4477, -0.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25139638781547546
Epoch 0, Step 2078: train/loss = 0.7294068932533264, train/raw-loss = 0.7032451033592224, train/logprobs = tensor([[-1.6470, -3.5879],
        [-1.6811, -1.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2616175413131714
Epoch 0, Step 2079: train/loss = 0.2754690647125244, train/raw-loss = 0.24731341004371643, train/logprobs = tensor([[-1.6391, -4.2006],
        [-3.2606, -1.6335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2815565764904022
Epoch 0, Step 2080: train/loss = 0.35638800263404846, train/raw-loss = 0.32898199558258057, train/logprobs = tensor([[-0.8842, -4.8829],
        [-2.0171, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27406007051467896
Epoch 0, Step 2081: train/loss = 0.2507018744945526, train/raw-loss = 0.2146376669406891, train/logprobs = tensor([[-1.6723, -7.0408],
        [-2.4709, -1.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36064213514328003
Epoch 0, Step 2082: train/loss = 0.45074227452278137, train/raw-loss = 0.4210805892944336, train/logprobs = tensor([[-1.2564, -3.0272],
        [-2.4954, -1.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29661667346954346
Epoch 0, Step 2083: train/loss = 0.3535739779472351, train/raw-loss = 0.32237759232521057, train/logprobs = tensor([[-1.6985, -7.4058],
        [-2.4988, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31196391582489014
Epoch 0, Step 2084: train/loss = 0.2530149519443512, train/raw-loss = 0.22473028302192688, train/logprobs = tensor([[-0.9023, -6.6636],
        [-2.1613, -1.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.282846599817276
Epoch 0, Step 2085: train/loss = 0.3229784369468689, train/raw-loss = 0.2939395308494568, train/logprobs = tensor([[-1.1625, -2.9965],
        [-2.4421, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29038891196250916
Epoch 0, Step 2086: train/loss = 0.4523477554321289, train/raw-loss = 0.42365357279777527, train/logprobs = tensor([[-1.6642, -6.3023],
        [-1.7810, -1.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28694167733192444
Epoch 0, Step 2087: train/loss = 0.32378309965133667, train/raw-loss = 0.2944490909576416, train/logprobs = tensor([[-1.1209, -4.6676],
        [-2.3577, -0.6264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933397889137268
Epoch 0, Step 2088: train/loss = 0.618130624294281, train/raw-loss = 0.5884890556335449, train/logprobs = tensor([[-1.5501, -2.5971],
        [-1.8830, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964153289794922
Epoch 0, Step 2089: train/loss = 0.3255601227283478, train/raw-loss = 0.30038684606552124, train/logprobs = tensor([[-0.8729, -3.3106],
        [-1.4767, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25173255801200867
Epoch 0, Step 2090: train/loss = 0.30976831912994385, train/raw-loss = 0.28612884879112244, train/logprobs = tensor([[-1.1972, -5.7186],
        [-1.9373, -1.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23639479279518127
Epoch 0, Step 2091: train/loss = 0.5338671207427979, train/raw-loss = 0.50666344165802, train/logprobs = tensor([[-1.0519, -3.6923],
        [-1.9812, -1.3948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720368504524231
Epoch 0, Step 2092: train/loss = 0.5322856307029724, train/raw-loss = 0.5022436380386353, train/logprobs = tensor([[-1.5394, -3.1277],
        [-2.2175, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30042049288749695
Epoch 0, Step 2093: train/loss = 0.4501229524612427, train/raw-loss = 0.4253736734390259, train/logprobs = tensor([[-0.9110, -3.6832],
        [-1.5168, -2.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2474929392337799
Epoch 0, Step 2094: train/loss = 0.5173500180244446, train/raw-loss = 0.4892202913761139, train/logprobs = tensor([[-1.5216, -3.5772],
        [-1.8463, -2.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28129756450653076
Epoch 0, Step 2095: train/loss = 0.6744430661201477, train/raw-loss = 0.6485155820846558, train/logprobs = tensor([[-2.0344, -2.3507],
        [-2.0492, -2.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592751681804657
Epoch 0, Step 2096: train/loss = 0.5123400092124939, train/raw-loss = 0.48806339502334595, train/logprobs = tensor([[-0.6736, -1.7275],
        [-1.2468, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427660971879959
Epoch 0, Step 2097: train/loss = 0.4358365535736084, train/raw-loss = 0.4050322473049164, train/logprobs = tensor([[-0.9451, -2.9167],
        [-2.1283, -1.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30804339051246643
Epoch 0, Step 2098: train/loss = 0.5146158337593079, train/raw-loss = 0.491257905960083, train/logprobs = tensor([[-0.8835, -2.6107],
        [-0.9944, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23357877135276794
Epoch 0, Step 2099: train/loss = 0.5846670866012573, train/raw-loss = 0.5541663765907288, train/logprobs = tensor([[-1.5945, -2.8366],
        [-1.6915, -1.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3050067722797394
Epoch 0, Step 2100: train/loss = 0.20888155698776245, train/raw-loss = 0.17586585879325867, train/logprobs = tensor([[-1.1049, -6.1496],
        [-2.6306, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33015716075897217
Epoch 0, Step 2101: train/loss = 0.5645958185195923, train/raw-loss = 0.5317102670669556, train/logprobs = tensor([[-0.9223, -3.3137],
        [-2.4882, -1.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32885539531707764
Epoch 0, Step 2102: train/loss = 0.5799294710159302, train/raw-loss = 0.5567340850830078, train/logprobs = tensor([[-1.0483, -2.2912],
        [-1.2636, -1.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23195399343967438
Epoch 0, Step 2103: train/loss = 0.5052447319030762, train/raw-loss = 0.478546142578125, train/logprobs = tensor([[-1.2195, -3.9059],
        [-1.9164, -1.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26698583364486694
Epoch 0, Step 2104: train/loss = 0.5225253105163574, train/raw-loss = 0.4958863854408264, train/logprobs = tensor([[-1.0790, -3.1507],
        [-1.5426, -1.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.266389399766922
Epoch 0, Step 2105: train/loss = 0.5336565971374512, train/raw-loss = 0.507007360458374, train/logprobs = tensor([[-0.8233, -1.5704],
        [-1.9016, -1.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26649242639541626
Epoch 0, Step 2106: train/loss = 0.5309484004974365, train/raw-loss = 0.5075007677078247, train/logprobs = tensor([[-0.9268, -1.5674],
        [-1.2466, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2344765067100525
Epoch 0, Step 2107: train/loss = 0.45100006461143494, train/raw-loss = 0.4224776029586792, train/logprobs = tensor([[-1.2125, -2.6202],
        [-1.8602, -1.8387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28522467613220215
Epoch 0, Step 2108: train/loss = 0.5985509157180786, train/raw-loss = 0.567891001701355, train/logprobs = tensor([[-1.2648, -2.3408],
        [-1.9820, -1.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065987229347229
Epoch 0, Step 2109: train/loss = 0.3489251732826233, train/raw-loss = 0.32493528723716736, train/logprobs = tensor([[-0.8402, -3.9071],
        [-2.0518, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23989903926849365
Epoch 0, Step 2110: train/loss = 0.624396026134491, train/raw-loss = 0.5977817177772522, train/logprobs = tensor([[-1.5196, -2.0397],
        [-1.7596, -1.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26614367961883545
Epoch 0, Step 2111: train/loss = 0.7036135792732239, train/raw-loss = 0.6836131811141968, train/logprobs = tensor([[-0.7448, -0.6701],
        [-1.1425, -0.9748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000039666891098
Epoch 0, Step 2112: train/loss = 0.303152471780777, train/raw-loss = 0.27274248003959656, train/logprobs = tensor([[-1.0246, -3.7316],
        [-2.8696, -1.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040999472141266
Epoch 0, Step 2113: train/loss = 0.36003047227859497, train/raw-loss = 0.335960328578949, train/logprobs = tensor([[-1.1734, -2.8785],
        [-1.8932, -0.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24070170521736145
Epoch 0, Step 2114: train/loss = 0.4889037311077118, train/raw-loss = 0.4623495042324066, train/logprobs = tensor([[-0.8210, -3.8211],
        [-1.7537, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26554232835769653
Epoch 0, Step 2115: train/loss = 0.42737799882888794, train/raw-loss = 0.40077120065689087, train/logprobs = tensor([[-1.3282, -4.6693],
        [-2.1949, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26606813073158264
Epoch 0, Step 2116: train/loss = 0.3476225435733795, train/raw-loss = 0.3178325593471527, train/logprobs = tensor([[-1.2479, -2.2402],
        [-2.7230, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29789969325065613
Epoch 0, Step 2117: train/loss = 0.5376695394515991, train/raw-loss = 0.5085340142250061, train/logprobs = tensor([[-1.0751, -1.4370],
        [-2.0503, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913552522659302
Epoch 0, Step 2118: train/loss = 0.5851046442985535, train/raw-loss = 0.5622190237045288, train/logprobs = tensor([[-0.8361, -2.2960],
        [-1.2564, -2.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22885626554489136
Epoch 0, Step 2119: train/loss = 0.44697362184524536, train/raw-loss = 0.4246683120727539, train/logprobs = tensor([[-0.7119, -2.5498],
        [-1.8891, -1.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22305332124233246
Epoch 0, Step 2120: train/loss = 0.73615962266922, train/raw-loss = 0.7098696231842041, train/logprobs = tensor([[-1.5539, -2.4695],
        [-1.3401, -1.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26290076971054077
Epoch 0, Step 2121: train/loss = 0.2213006317615509, train/raw-loss = 0.1841951310634613, train/logprobs = tensor([[-1.0359, -4.3534],
        [-3.2326, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3710549473762512
Epoch 0, Step 2122: train/loss = 0.4855588972568512, train/raw-loss = 0.45792779326438904, train/logprobs = tensor([[-0.9684, -2.0265],
        [-1.7865, -1.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27631089091300964
Epoch 0, Step 2123: train/loss = 0.6059159636497498, train/raw-loss = 0.5791361331939697, train/logprobs = tensor([[-1.2731, -1.5743],
        [-1.5635, -1.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26779884099960327
Epoch 0, Step 2124: train/loss = 0.22207963466644287, train/raw-loss = 0.1961389183998108, train/logprobs = tensor([[-1.2967, -7.0169],
        [-2.2368, -2.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594071626663208
Epoch 0, Step 2125: train/loss = 0.39806705713272095, train/raw-loss = 0.3677736520767212, train/logprobs = tensor([[-0.8788, -2.7030],
        [-2.3548, -1.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30293387174606323
Epoch 0, Step 2126: train/loss = 0.17780253291130066, train/raw-loss = 0.1474442034959793, train/logprobs = tensor([[-1.6563, -4.0170],
        [-3.3865, -1.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035832345485687
Epoch 0, Step 2127: train/loss = 0.34374919533729553, train/raw-loss = 0.31715407967567444, train/logprobs = tensor([[-1.1870, -4.9406],
        [-2.2357, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659509778022766
Epoch 0, Step 2128: train/loss = 0.4610844552516937, train/raw-loss = 0.4314565658569336, train/logprobs = tensor([[-0.9910, -3.2755],
        [-1.9812, -1.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29627907276153564
Epoch 0, Step 2129: train/loss = 0.47153303027153015, train/raw-loss = 0.4435456395149231, train/logprobs = tensor([[-1.7420, -3.3201],
        [-2.1982, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27987366914749146
Epoch 0, Step 2130: train/loss = 0.3171805739402771, train/raw-loss = 0.29030945897102356, train/logprobs = tensor([[-1.3322, -4.3303],
        [-2.0639, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26871106028556824
Epoch 0, Step 2131: train/loss = 0.5392781496047974, train/raw-loss = 0.51423579454422, train/logprobs = tensor([[-1.9633, -4.5554],
        [-2.1686, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504231929779053
Epoch 0, Step 2132: train/loss = 0.2830052971839905, train/raw-loss = 0.24938324093818665, train/logprobs = tensor([[-0.8663, -2.9832],
        [-2.4659, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33622056245803833
Epoch 0, Step 2133: train/loss = 0.4527445435523987, train/raw-loss = 0.4269610643386841, train/logprobs = tensor([[-1.0965, -1.7248],
        [-1.8113, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25783488154411316
Epoch 0, Step 2134: train/loss = 0.37077975273132324, train/raw-loss = 0.34272077679634094, train/logprobs = tensor([[-0.8498, -6.2401],
        [-2.1329, -1.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805898189544678
Epoch 0, Step 2135: train/loss = 0.3772968649864197, train/raw-loss = 0.35456597805023193, train/logprobs = tensor([[-0.8805, -3.8054],
        [-1.2031, -0.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22730876505374908
Epoch 0, Step 2136: train/loss = 0.5560519099235535, train/raw-loss = 0.5289100408554077, train/logprobs = tensor([[-0.8763, -1.8227],
        [-2.1477, -1.8583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2714185118675232
Epoch 0, Step 2137: train/loss = 0.19917643070220947, train/raw-loss = 0.16705180704593658, train/logprobs = tensor([[-0.8675, -6.5823],
        [-2.7890, -1.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3212461471557617
Epoch 0, Step 2138: train/loss = 0.3750886917114258, train/raw-loss = 0.34742748737335205, train/logprobs = tensor([[-1.3013, -4.0720],
        [-1.4319, -1.3706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2766121029853821
Epoch 0, Step 2139: train/loss = 0.435902863740921, train/raw-loss = 0.4059663712978363, train/logprobs = tensor([[-1.1913, -3.7948],
        [-1.9721, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29936468601226807
Epoch 0, Step 2140: train/loss = 0.6527632474899292, train/raw-loss = 0.6269670724868774, train/logprobs = tensor([[-0.7062, -0.8132],
        [-1.1622, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257961630821228
Epoch 0, Step 2141: train/loss = 0.31515565514564514, train/raw-loss = 0.2901919484138489, train/logprobs = tensor([[-1.1974, -6.2659],
        [-2.5241, -2.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2496369332075119
Epoch 0, Step 2142: train/loss = 0.5103550553321838, train/raw-loss = 0.4831945300102234, train/logprobs = tensor([[-1.0897, -3.0348],
        [-1.5003, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27160531282424927
Epoch 0, Step 2143: train/loss = 0.7047855257987976, train/raw-loss = 0.6761661767959595, train/logprobs = tensor([[-3.1871, -4.0455],
        [-3.1548, -3.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2861934304237366
Epoch 0, Step 2144: train/loss = 0.33636724948883057, train/raw-loss = 0.3046444058418274, train/logprobs = tensor([[-1.1738, -3.2672],
        [-2.7829, -1.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31722843647003174
Epoch 0, Step 2145: train/loss = 0.6588412523269653, train/raw-loss = 0.6337950229644775, train/logprobs = tensor([[-0.9291, -1.2209],
        [-1.2864, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25046342611312866
Epoch 0, Step 2146: train/loss = 0.32234281301498413, train/raw-loss = 0.29788362979888916, train/logprobs = tensor([[-0.8008, -4.5989],
        [-1.6803, -0.9103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24459168314933777
Epoch 0, Step 2147: train/loss = 0.4781316816806793, train/raw-loss = 0.4448260962963104, train/logprobs = tensor([[-1.0929, -4.0955],
        [-3.2822, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330555260181427
Epoch 0, Step 2148: train/loss = 0.5346078872680664, train/raw-loss = 0.516363263130188, train/logprobs = tensor([[-0.6746, -2.2950],
        [-1.1243, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18244636058807373
Epoch 0, Step 2149: train/loss = 0.33845803141593933, train/raw-loss = 0.3117469549179077, train/logprobs = tensor([[-1.3842, -5.4268],
        [-2.7590, -2.2021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2671107053756714
Epoch 0, Step 2150: train/loss = 0.4412606358528137, train/raw-loss = 0.41589677333831787, train/logprobs = tensor([[-1.1173, -4.1544],
        [-1.9683, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25363829731941223
Epoch 0, Step 2151: train/loss = 0.675286054611206, train/raw-loss = 0.6517683863639832, train/logprobs = tensor([[-0.6952, -0.9743],
        [-1.2187, -1.2643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23517674207687378
Epoch 0, Step 2152: train/loss = 0.3828270137310028, train/raw-loss = 0.35066306591033936, train/logprobs = tensor([[-1.3675, -4.0559],
        [-1.9948, -2.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32163935899734497
Epoch 0, Step 2153: train/loss = 0.4808391332626343, train/raw-loss = 0.45180875062942505, train/logprobs = tensor([[-2.2268, -4.6099],
        [-2.7342, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2903038263320923
Epoch 0, Step 2154: train/loss = 0.28177446126937866, train/raw-loss = 0.25068044662475586, train/logprobs = tensor([[-0.9152, -5.1315],
        [-1.8952, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3109402060508728
Epoch 0, Step 2155: train/loss = 0.4193527102470398, train/raw-loss = 0.39283061027526855, train/logprobs = tensor([[-1.3761, -5.1196],
        [-2.1621, -3.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2652212679386139
Epoch 0, Step 2156: train/loss = 0.5225268602371216, train/raw-loss = 0.4961634576320648, train/logprobs = tensor([[-1.2227, -3.1197],
        [-1.9802, -1.2565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2636337876319885
Epoch 0, Step 2157: train/loss = 0.6252700090408325, train/raw-loss = 0.5951146483421326, train/logprobs = tensor([[-1.0913, -1.7770],
        [-1.9197, -1.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015536665916443
Epoch 0, Step 2158: train/loss = 0.6556068062782288, train/raw-loss = 0.6263003349304199, train/logprobs = tensor([[-1.1591, -1.7860],
        [-2.3943, -2.2680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29306453466415405
Epoch 0, Step 2159: train/loss = 0.40746527910232544, train/raw-loss = 0.3776978552341461, train/logprobs = tensor([[-0.9407, -2.7795],
        [-2.0971, -1.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976740300655365
Epoch 0, Step 2160: train/loss = 0.38226938247680664, train/raw-loss = 0.34982210397720337, train/logprobs = tensor([[-1.2653, -4.5830],
        [-2.6795, -1.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3244728147983551
Epoch 0, Step 2161: train/loss = 0.48469680547714233, train/raw-loss = 0.4587100148200989, train/logprobs = tensor([[-1.2590, -1.3446],
        [-2.3395, -0.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2598681151866913
Epoch 0, Step 2162: train/loss = 0.5653481483459473, train/raw-loss = 0.5346387028694153, train/logprobs = tensor([[-0.9679, -2.4854],
        [-1.9910, -2.4081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30709460377693176
Epoch 0, Step 2163: train/loss = 0.3992431163787842, train/raw-loss = 0.37041985988616943, train/logprobs = tensor([[-1.4260, -6.2148],
        [-1.8686, -2.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2882329821586609
Epoch 0, Step 2164: train/loss = 0.6612728238105774, train/raw-loss = 0.6342761516571045, train/logprobs = tensor([[-3.0486, -4.2320],
        [-2.3474, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699674367904663
Epoch 0, Step 2165: train/loss = 0.31659913063049316, train/raw-loss = 0.28936904668807983, train/logprobs = tensor([[-0.7111, -4.0666],
        [-1.9624, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723011076450348
Epoch 0, Step 2166: train/loss = 0.43328389525413513, train/raw-loss = 0.4025072455406189, train/logprobs = tensor([[-1.2313, -1.4443],
        [-2.8888, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077666759490967
Epoch 0, Step 2167: train/loss = 0.48489636182785034, train/raw-loss = 0.45300573110580444, train/logprobs = tensor([[-1.6368, -3.4652],
        [-2.5113, -2.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.318906307220459
Epoch 0, Step 2168: train/loss = 0.6324403285980225, train/raw-loss = 0.6060354113578796, train/logprobs = tensor([[-1.0592, -1.2980],
        [-1.3939, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26404866576194763
Epoch 0, Step 2169: train/loss = 0.3896937072277069, train/raw-loss = 0.3644730746746063, train/logprobs = tensor([[-1.4432, -3.2490],
        [-1.4891, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522064447402954
Epoch 0, Step 2170: train/loss = 0.4316316246986389, train/raw-loss = 0.4036545157432556, train/logprobs = tensor([[-0.7831, -2.5755],
        [-2.1242, -2.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27977102994918823
Epoch 0, Step 2171: train/loss = 0.5587085485458374, train/raw-loss = 0.53208327293396, train/logprobs = tensor([[-1.8697, -2.8650],
        [-1.8088, -1.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2662527561187744
Epoch 0, Step 2172: train/loss = 0.27153828740119934, train/raw-loss = 0.23834559321403503, train/logprobs = tensor([[-1.0763, -2.9122],
        [-2.9447, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319270610809326
Epoch 0, Step 2173: train/loss = 0.42692291736602783, train/raw-loss = 0.4005579352378845, train/logprobs = tensor([[-1.3934, -2.3257],
        [-2.1258, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26364949345588684
Epoch 0, Step 2174: train/loss = 0.6148408651351929, train/raw-loss = 0.589329183101654, train/logprobs = tensor([[-1.0408, -1.2889],
        [-1.6489, -1.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25511670112609863
Epoch 0, Step 2175: train/loss = 0.4626759886741638, train/raw-loss = 0.4364238977432251, train/logprobs = tensor([[-1.2492, -2.9492],
        [-1.7576, -1.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2625206410884857
Epoch 0, Step 2176: train/loss = 0.14798708260059357, train/raw-loss = 0.11232610046863556, train/logprobs = tensor([[-1.2518, -5.4019],
        [-3.5406, -1.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3566097915172577
Epoch 0, Step 2177: train/loss = 0.5992511510848999, train/raw-loss = 0.5781857967376709, train/logprobs = tensor([[-0.7944, -1.7243],
        [-1.1092, -1.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21065370738506317
Epoch 0, Step 2178: train/loss = 0.5913072824478149, train/raw-loss = 0.5701326131820679, train/logprobs = tensor([[-0.8292, -2.5872],
        [-0.7460, -0.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2117464244365692
Epoch 0, Step 2179: train/loss = 0.3670741021633148, train/raw-loss = 0.33831697702407837, train/logprobs = tensor([[-1.8492, -8.5791],
        [-3.0965, -1.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875712513923645
Epoch 0, Step 2180: train/loss = 0.5792300701141357, train/raw-loss = 0.5526235103607178, train/logprobs = tensor([[-0.8436, -1.7603],
        [-1.8715, -1.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26606497168540955
Epoch 0, Step 2181: train/loss = 0.3293003439903259, train/raw-loss = 0.3064677119255066, train/logprobs = tensor([[-1.5480, -5.3794],
        [-2.0643, -2.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22832652926445007
Epoch 0, Step 2182: train/loss = 0.5882124304771423, train/raw-loss = 0.5609315633773804, train/logprobs = tensor([[-1.7635, -2.6494],
        [-1.7441, -1.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27280884981155396
Epoch 0, Step 2183: train/loss = 0.22708134353160858, train/raw-loss = 0.20037245750427246, train/logprobs = tensor([[-0.8484, -4.9194],
        [-2.8404, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26708877086639404
Epoch 0, Step 2184: train/loss = 0.4883514642715454, train/raw-loss = 0.4636874794960022, train/logprobs = tensor([[-1.3864, -3.7716],
        [-1.8640, -1.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2466401755809784
Epoch 0, Step 2185: train/loss = 0.32845181226730347, train/raw-loss = 0.30125102400779724, train/logprobs = tensor([[-1.3680, -4.1407],
        [-2.5415, -1.3532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27200767397880554
Epoch 0, Step 2186: train/loss = 0.47129955887794495, train/raw-loss = 0.4450882077217102, train/logprobs = tensor([[-1.0573, -2.0936],
        [-1.7386, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621132731437683
Epoch 0, Step 2187: train/loss = 0.17517521977424622, train/raw-loss = 0.1457349956035614, train/logprobs = tensor([[-1.4481, -5.3285],
        [-2.8263, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29440227150917053
Epoch 0, Step 2188: train/loss = 0.5119767189025879, train/raw-loss = 0.4865395426750183, train/logprobs = tensor([[-1.8604, -3.5242],
        [-2.2485, -1.4428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25437137484550476
Epoch 0, Step 2189: train/loss = 0.5692383646965027, train/raw-loss = 0.5480037927627563, train/logprobs = tensor([[-0.9929, -1.8404],
        [-1.2150, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21234585344791412
Epoch 0, Step 2190: train/loss = 0.5371878147125244, train/raw-loss = 0.5063814520835876, train/logprobs = tensor([[-1.1376, -2.1182],
        [-1.5799, -1.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3080635964870453
Epoch 0, Step 2191: train/loss = 0.5529958009719849, train/raw-loss = 0.5279303789138794, train/logprobs = tensor([[-0.8862, -1.8309],
        [-1.1813, -1.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506543695926666
Epoch 0, Step 2192: train/loss = 0.4747338593006134, train/raw-loss = 0.4479748606681824, train/logprobs = tensor([[-1.1438, -2.5765],
        [-2.1376, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267589807510376
Epoch 0, Step 2193: train/loss = 0.40613260865211487, train/raw-loss = 0.3831915855407715, train/logprobs = tensor([[-1.3943, -4.8778],
        [-1.9824, -2.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22941040992736816
Epoch 0, Step 2194: train/loss = 0.2765038013458252, train/raw-loss = 0.24410073459148407, train/logprobs = tensor([[-1.2976, -5.4198],
        [-2.9271, -1.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32403063774108887
Epoch 0, Step 2195: train/loss = 0.45586439967155457, train/raw-loss = 0.4314292371273041, train/logprobs = tensor([[-1.4070, -4.1631],
        [-1.8649, -1.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24435162544250488
Epoch 0, Step 2196: train/loss = 0.6175985336303711, train/raw-loss = 0.585350513458252, train/logprobs = tensor([[-1.9080, -3.6010],
        [-3.5717, -1.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224797248840332
Epoch 0, Step 2197: train/loss = 0.3705403804779053, train/raw-loss = 0.3423117399215698, train/logprobs = tensor([[-1.7351, -3.6720],
        [-1.9678, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822859585285187
Epoch 0, Step 2198: train/loss = 0.7368134260177612, train/raw-loss = 0.7082896828651428, train/logprobs = tensor([[-2.3093, -2.6769],
        [-1.8106, -1.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28523698449134827
Epoch 0, Step 2199: train/loss = 0.339297890663147, train/raw-loss = 0.31289464235305786, train/logprobs = tensor([[-0.9710, -4.1005],
        [-1.8947, -1.0602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26403218507766724
Epoch 0, Step 2200: train/loss = 0.35749194025993347, train/raw-loss = 0.33022981882095337, train/logprobs = tensor([[-1.1145, -3.4660],
        [-2.0526, -1.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2726214528083801
Epoch 0, Step 2201: train/loss = 0.5437619090080261, train/raw-loss = 0.5225375890731812, train/logprobs = tensor([[-0.9881, -2.7612],
        [-1.4751, -2.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21224376559257507
Epoch 0, Step 2202: train/loss = 0.2717655897140503, train/raw-loss = 0.23903046548366547, train/logprobs = tensor([[-1.1757, -7.0722],
        [-2.4192, -1.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273509740829468
Epoch 0, Step 2203: train/loss = 0.6695209741592407, train/raw-loss = 0.642539381980896, train/logprobs = tensor([[-1.1474, -1.5271],
        [-1.6820, -1.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26981592178344727
Epoch 0, Step 2204: train/loss = 0.6527469158172607, train/raw-loss = 0.6307001113891602, train/logprobs = tensor([[-1.2643, -1.3149],
        [-1.1585, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22046731412410736
Epoch 0, Step 2205: train/loss = 0.31256556510925293, train/raw-loss = 0.2835633456707001, train/logprobs = tensor([[-1.3002, -4.2798],
        [-2.1760, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29002225399017334
Epoch 0, Step 2206: train/loss = 0.4133003354072571, train/raw-loss = 0.3862142860889435, train/logprobs = tensor([[-0.9199, -3.5774],
        [-2.1422, -1.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27086079120635986
Epoch 0, Step 2207: train/loss = 0.433091402053833, train/raw-loss = 0.409980446100235, train/logprobs = tensor([[-1.1163, -3.4538],
        [-1.5821, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23110947012901306
Epoch 0, Step 2208: train/loss = 0.5253111124038696, train/raw-loss = 0.4978312849998474, train/logprobs = tensor([[-1.1522, -1.9767],
        [-1.8391, -1.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2747981548309326
Epoch 0, Step 2209: train/loss = 0.47078055143356323, train/raw-loss = 0.44286489486694336, train/logprobs = tensor([[-0.6459, -2.0863],
        [-2.2270, -1.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27915674448013306
Epoch 0, Step 2210: train/loss = 0.3881821036338806, train/raw-loss = 0.3629775643348694, train/logprobs = tensor([[-1.4665, -4.1466],
        [-1.9017, -2.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520453631877899
Epoch 0, Step 2211: train/loss = 0.4941329061985016, train/raw-loss = 0.4696049094200134, train/logprobs = tensor([[-1.6435, -3.1598],
        [-2.1569, -2.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2452799677848816
Epoch 0, Step 2212: train/loss = 0.4683564007282257, train/raw-loss = 0.4404193162918091, train/logprobs = tensor([[-1.2275, -2.6605],
        [-1.7139, -1.6899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27937063574790955
Epoch 0, Step 2213: train/loss = 0.5221677422523499, train/raw-loss = 0.49357128143310547, train/logprobs = tensor([[-1.2878, -2.0481],
        [-2.0089, -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2859647870063782
Epoch 0, Step 2214: train/loss = 0.5424107313156128, train/raw-loss = 0.5121234655380249, train/logprobs = tensor([[-1.4455, -2.3381],
        [-1.6012, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30287185311317444
Epoch 0, Step 2215: train/loss = 0.48580509424209595, train/raw-loss = 0.4563179016113281, train/logprobs = tensor([[-1.1658, -3.1028],
        [-2.3919, -2.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29487186670303345
Epoch 0, Step 2216: train/loss = 0.26502305269241333, train/raw-loss = 0.24056997895240784, train/logprobs = tensor([[-1.0926, -5.0670],
        [-1.5134, -1.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2445308268070221
Epoch 0, Step 2217: train/loss = 0.3963012099266052, train/raw-loss = 0.37538933753967285, train/logprobs = tensor([[-0.8088, -5.1353],
        [-1.0069, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2091185599565506
Epoch 0, Step 2218: train/loss = 0.2424638271331787, train/raw-loss = 0.21293389797210693, train/logprobs = tensor([[-1.2194, -5.9602],
        [-3.3773, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29529908299446106
Epoch 0, Step 2219: train/loss = 0.37895333766937256, train/raw-loss = 0.3580337166786194, train/logprobs = tensor([[-0.9424, -3.8147],
        [-1.0685, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2091960310935974
Epoch 0, Step 2220: train/loss = 0.25086304545402527, train/raw-loss = 0.22240392863750458, train/logprobs = tensor([[-1.2237, -8.1664],
        [-2.6678, -1.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28459101915359497
Epoch 0, Step 2221: train/loss = 0.5465888977050781, train/raw-loss = 0.5260297060012817, train/logprobs = tensor([[-0.9348, -1.8610],
        [-1.0020, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20559129118919373
Epoch 0, Step 2222: train/loss = 0.4928226172924042, train/raw-loss = 0.46454015374183655, train/logprobs = tensor([[-1.2852, -3.0653],
        [-1.7281, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28282421827316284
Epoch 0, Step 2223: train/loss = 0.2511594891548157, train/raw-loss = 0.22492465376853943, train/logprobs = tensor([[-1.4891, -6.2571],
        [-3.2537, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26234832406044006
Epoch 0, Step 2224: train/loss = 0.35835355520248413, train/raw-loss = 0.32803118228912354, train/logprobs = tensor([[-1.8106, -4.4468],
        [-2.1753, -2.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30322396755218506
Epoch 0, Step 2225: train/loss = 0.5822126269340515, train/raw-loss = 0.5549606084823608, train/logprobs = tensor([[-1.4739, -3.1962],
        [-1.5003, -1.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725203037261963
Epoch 0, Step 2226: train/loss = 0.43361571431159973, train/raw-loss = 0.40483358502388, train/logprobs = tensor([[-0.9380, -1.7225],
        [-1.8872, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2878211736679077
Epoch 0, Step 2227: train/loss = 0.4293261468410492, train/raw-loss = 0.399183452129364, train/logprobs = tensor([[-1.4097, -2.8190],
        [-2.0685, -1.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30142688751220703
Epoch 0, Step 2228: train/loss = 0.2820560038089752, train/raw-loss = 0.24866697192192078, train/logprobs = tensor([[-1.1119, -4.4936],
        [-2.3311, -1.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3338903486728668
Epoch 0, Step 2229: train/loss = 0.3388155698776245, train/raw-loss = 0.3094857335090637, train/logprobs = tensor([[-1.3050, -6.7863],
        [-2.7064, -3.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932983338832855
Epoch 0, Step 2230: train/loss = 0.38173478841781616, train/raw-loss = 0.35034990310668945, train/logprobs = tensor([[-1.1378, -4.6172],
        [-2.1444, -1.4922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3138488531112671
Epoch 0, Step 2231: train/loss = 0.2736908495426178, train/raw-loss = 0.23839862644672394, train/logprobs = tensor([[-1.3575, -4.5702],
        [-3.3402, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3529222011566162
Epoch 0, Step 2232: train/loss = 0.40354999899864197, train/raw-loss = 0.3756245970726013, train/logprobs = tensor([[-1.5181, -5.1011],
        [-2.1482, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27925437688827515
Epoch 0, Step 2233: train/loss = 0.28904157876968384, train/raw-loss = 0.2636943459510803, train/logprobs = tensor([[-0.9802, -7.0163],
        [-1.6556, -2.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25347208976745605
Epoch 0, Step 2234: train/loss = 0.41326284408569336, train/raw-loss = 0.3846921920776367, train/logprobs = tensor([[-1.3699, -3.5969],
        [-2.0373, -2.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2857060432434082
Epoch 0, Step 2235: train/loss = 0.3941529393196106, train/raw-loss = 0.3640914261341095, train/logprobs = tensor([[-1.2400, -3.0085],
        [-1.9337, -1.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3006150722503662
Epoch 0, Step 2236: train/loss = 0.47297123074531555, train/raw-loss = 0.4478481709957123, train/logprobs = tensor([[-1.4328, -7.2330],
        [-1.6988, -4.2383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2512305676937103
Epoch 0, Step 2237: train/loss = 0.31682658195495605, train/raw-loss = 0.2867908477783203, train/logprobs = tensor([[-1.2652, -5.5923],
        [-2.1321, -1.7951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003573417663574
Epoch 0, Step 2238: train/loss = 0.3023633062839508, train/raw-loss = 0.27460429072380066, train/logprobs = tensor([[-0.8966, -6.4445],
        [-2.2887, -1.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27758997678756714
Epoch 0, Step 2239: train/loss = 0.3699023127555847, train/raw-loss = 0.34105607867240906, train/logprobs = tensor([[-1.3490, -9.4460],
        [-2.6008, -3.5053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28846216201782227
Epoch 0, Step 2240: train/loss = 0.49251195788383484, train/raw-loss = 0.4685010313987732, train/logprobs = tensor([[-1.2820, -2.1559],
        [-1.8939, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24010920524597168
Epoch 0, Step 2241: train/loss = 0.1956462860107422, train/raw-loss = 0.1670425683259964, train/logprobs = tensor([[ -0.9903, -11.0220],
        [ -2.3197,  -2.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2860371470451355
Epoch 0, Step 2242: train/loss = 0.4419039487838745, train/raw-loss = 0.4175649881362915, train/logprobs = tensor([[-1.1402, -3.0921],
        [-1.8204, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24338974058628082
Epoch 0, Step 2243: train/loss = 0.5694155693054199, train/raw-loss = 0.5412315130233765, train/logprobs = tensor([[-0.9036, -1.4953],
        [-1.8926, -1.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28184035420417786
Epoch 0, Step 2244: train/loss = 0.5720648765563965, train/raw-loss = 0.5476102828979492, train/logprobs = tensor([[-1.4116, -2.0099],
        [-1.8837, -1.5122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24454529583454132
Epoch 0, Step 2245: train/loss = 0.11174385249614716, train/raw-loss = 0.07873211801052094, train/logprobs = tensor([[-1.2351, -6.4750],
        [-3.7986, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3301173448562622
Epoch 0, Step 2246: train/loss = 0.49330878257751465, train/raw-loss = 0.46535050868988037, train/logprobs = tensor([[-0.9046, -2.7228],
        [-2.0277, -1.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2795829176902771
Epoch 0, Step 2247: train/loss = 0.37061184644699097, train/raw-loss = 0.34048184752464294, train/logprobs = tensor([[-1.1588, -4.1917],
        [-2.0738, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013002872467041
Epoch 0, Step 2248: train/loss = 0.3588806688785553, train/raw-loss = 0.3265131115913391, train/logprobs = tensor([[-1.1446, -3.7802],
        [-1.8751, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236757516860962
Epoch 0, Step 2249: train/loss = 0.5945262908935547, train/raw-loss = 0.5709667801856995, train/logprobs = tensor([[-2.2676, -3.0488],
        [-2.5062, -2.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2355947643518448
Epoch 0, Step 2250: train/loss = 0.273694783449173, train/raw-loss = 0.24000787734985352, train/logprobs = tensor([[-1.9211, -4.1330],
        [-3.3425, -1.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33686909079551697
Epoch 0, Step 2251: train/loss = 0.45328113436698914, train/raw-loss = 0.4293735921382904, train/logprobs = tensor([[-1.4325, -4.3047],
        [-2.0393, -1.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23907548189163208
Epoch 0, Step 2252: train/loss = 0.39923855662345886, train/raw-loss = 0.37259340286254883, train/logprobs = tensor([[-0.9467, -2.9912],
        [-1.6391, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26645171642303467
Epoch 0, Step 2253: train/loss = 0.5307689905166626, train/raw-loss = 0.5082167387008667, train/logprobs = tensor([[-0.8694, -3.0385],
        [-1.3490, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22552286088466644
Epoch 0, Step 2254: train/loss = 0.5982632637023926, train/raw-loss = 0.5728323459625244, train/logprobs = tensor([[-1.3756, -1.6928],
        [-1.5956, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543089687824249
Epoch 0, Step 2255: train/loss = 0.4561784565448761, train/raw-loss = 0.42789554595947266, train/logprobs = tensor([[-1.3003, -3.6103],
        [-1.8228, -1.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2828291058540344
Epoch 0, Step 2256: train/loss = 0.8711239099502563, train/raw-loss = 0.8432533740997314, train/logprobs = tensor([[-3.5813, -7.1376],
        [-2.4282, -0.9228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787056565284729
Epoch 0, Step 2257: train/loss = 0.25024324655532837, train/raw-loss = 0.2249840795993805, train/logprobs = tensor([[-1.1249, -6.1818],
        [-2.4201, -2.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25259169936180115
Epoch 0, Step 2258: train/loss = 0.31100428104400635, train/raw-loss = 0.2776899039745331, train/logprobs = tensor([[-1.3721, -3.8906],
        [-3.1306, -1.1626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331438899040222
Epoch 0, Step 2259: train/loss = 0.3736749291419983, train/raw-loss = 0.3458569645881653, train/logprobs = tensor([[-1.1896, -2.7298],
        [-2.1920, -1.1573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27817946672439575
Epoch 0, Step 2260: train/loss = 0.5577905178070068, train/raw-loss = 0.5356119871139526, train/logprobs = tensor([[-1.5951, -3.2911],
        [-1.6870, -2.2859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22178523242473602
Epoch 0, Step 2261: train/loss = 0.35964223742485046, train/raw-loss = 0.3307415544986725, train/logprobs = tensor([[-1.3372, -6.3436],
        [-1.1993, -2.5302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2890070378780365
Epoch 0, Step 2262: train/loss = 0.5070850849151611, train/raw-loss = 0.48233699798583984, train/logprobs = tensor([[-1.3085, -4.9865],
        [-1.5649, -2.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24748069047927856
Epoch 0, Step 2263: train/loss = 0.5927558541297913, train/raw-loss = 0.5667903423309326, train/logprobs = tensor([[-1.3939, -2.9248],
        [-1.6174, -1.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596548795700073
Epoch 0, Step 2264: train/loss = 0.47815895080566406, train/raw-loss = 0.4540308713912964, train/logprobs = tensor([[-1.1098, -4.7202],
        [-1.4691, -2.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24128109216690063
Epoch 0, Step 2265: train/loss = 0.39630529284477234, train/raw-loss = 0.36322981119155884, train/logprobs = tensor([[-1.2664, -4.3781],
        [-2.6493, -1.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3307548463344574
Epoch 0, Step 2266: train/loss = 0.7304651737213135, train/raw-loss = 0.7057820558547974, train/logprobs = tensor([[-2.8851, -4.5799],
        [-2.1011, -2.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24683097004890442
Epoch 0, Step 2267: train/loss = 0.3323131799697876, train/raw-loss = 0.30245324969291687, train/logprobs = tensor([[-1.2845, -3.9339],
        [-2.0961, -1.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985992431640625
Epoch 0, Step 2268: train/loss = 0.39670705795288086, train/raw-loss = 0.37139999866485596, train/logprobs = tensor([[-0.8689, -4.9771],
        [-1.7727, -1.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530708909034729
Epoch 0, Step 2269: train/loss = 0.5853220224380493, train/raw-loss = 0.5639129877090454, train/logprobs = tensor([[-1.3810, -2.1401],
        [-1.2100, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21408991515636444
Epoch 0, Step 2270: train/loss = 0.8044887781143188, train/raw-loss = 0.7771466374397278, train/logprobs = tensor([[-2.5994, -3.5205],
        [-1.7430, -1.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27342090010643005
Epoch 0, Step 2271: train/loss = 0.4652494192123413, train/raw-loss = 0.43674707412719727, train/logprobs = tensor([[-1.0001, -2.9000],
        [-1.6730, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28502345085144043
Epoch 0, Step 2272: train/loss = 0.6063335537910461, train/raw-loss = 0.5782619714736938, train/logprobs = tensor([[-1.8883, -1.7787],
        [-1.9722, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28071632981300354
Epoch 0, Step 2273: train/loss = 0.6288460493087769, train/raw-loss = 0.6027425527572632, train/logprobs = tensor([[-1.1501, -1.4351],
        [-1.5038, -1.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26103514432907104
Epoch 0, Step 2274: train/loss = 0.45288756489753723, train/raw-loss = 0.42300736904144287, train/logprobs = tensor([[-1.7867, -4.4311],
        [-2.6296, -2.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2988022267818451
Epoch 0, Step 2275: train/loss = 0.28847283124923706, train/raw-loss = 0.2574048340320587, train/logprobs = tensor([[-1.3142, -7.2917],
        [-2.6431, -2.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106797933578491
Epoch 0, Step 2276: train/loss = 0.2486579716205597, train/raw-loss = 0.21486476063728333, train/logprobs = tensor([[-1.5744, -5.9005],
        [-2.9205, -2.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3379323482513428
Epoch 0, Step 2277: train/loss = 0.557345986366272, train/raw-loss = 0.5342201590538025, train/logprobs = tensor([[-0.5886, -1.2392],
        [-1.7634, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23125796020030975
Epoch 0, Step 2278: train/loss = 0.5435647368431091, train/raw-loss = 0.5212209224700928, train/logprobs = tensor([[-1.1528, -2.7500],
        [-1.3766, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22343870997428894
Epoch 0, Step 2279: train/loss = 0.3941671848297119, train/raw-loss = 0.3677050769329071, train/logprobs = tensor([[-1.6243, -3.1296],
        [-2.2442, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2646212577819824
Epoch 0, Step 2280: train/loss = 0.626748263835907, train/raw-loss = 0.5914952754974365, train/logprobs = tensor([[-2.5125, -4.4234],
        [-2.4190, -1.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35252973437309265
Epoch 0, Step 2281: train/loss = 0.6522200107574463, train/raw-loss = 0.6268720030784607, train/logprobs = tensor([[-2.0279, -3.6264],
        [-1.4240, -1.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2534794807434082
Epoch 0, Step 2282: train/loss = 0.26293081045150757, train/raw-loss = 0.23427650332450867, train/logprobs = tensor([[-1.1429, -3.9200],
        [-2.8734, -1.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865431308746338
Epoch 0, Step 2283: train/loss = 0.24347935616970062, train/raw-loss = 0.20635466277599335, train/logprobs = tensor([[-1.1953, -3.7781],
        [-3.2424, -1.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37124717235565186
Epoch 0, Step 2284: train/loss = 0.4508203864097595, train/raw-loss = 0.42361387610435486, train/logprobs = tensor([[-1.3643, -3.1608],
        [-2.1539, -1.7254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.272064745426178
Epoch 0, Step 2285: train/loss = 0.3322939872741699, train/raw-loss = 0.3055213689804077, train/logprobs = tensor([[-2.2938, -6.1785],
        [-2.2054, -1.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26772627234458923
Epoch 0, Step 2286: train/loss = 0.3657703101634979, train/raw-loss = 0.3280051350593567, train/logprobs = tensor([[-1.5820, -3.8411],
        [-3.2921, -1.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3776518702507019
Epoch 0, Step 2287: train/loss = 0.47937971353530884, train/raw-loss = 0.4526021480560303, train/logprobs = tensor([[-1.1466, -3.5280],
        [-1.8855, -1.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26777544617652893
Epoch 0, Step 2288: train/loss = 0.8113672733306885, train/raw-loss = 0.7856391668319702, train/logprobs = tensor([[-2.5926, -3.9390],
        [-1.4889, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257281094789505
Epoch 0, Step 2289: train/loss = 0.3095656931400299, train/raw-loss = 0.2869926691055298, train/logprobs = tensor([[-0.8400, -4.0965],
        [-1.4348, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22573024034500122
Epoch 0, Step 2290: train/loss = 0.07702435553073883, train/raw-loss = 0.04408101364970207, train/logprobs = tensor([[-1.0340, -7.6940],
        [-3.9637, -0.3820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.329433411359787
Epoch 0, Step 2291: train/loss = 0.3504892587661743, train/raw-loss = 0.32189977169036865, train/logprobs = tensor([[-1.2907, -3.8448],
        [-2.2351, -1.3662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28589504957199097
Epoch 0, Step 2292: train/loss = 0.4326820373535156, train/raw-loss = 0.40766167640686035, train/logprobs = tensor([[-0.9519, -2.9029],
        [-1.4040, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502037584781647
Epoch 0, Step 2293: train/loss = 0.5389533638954163, train/raw-loss = 0.5078897476196289, train/logprobs = tensor([[-1.3720, -1.8897],
        [-2.3017, -1.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3106362521648407
Epoch 0, Step 2294: train/loss = 0.4306141138076782, train/raw-loss = 0.40230241417884827, train/logprobs = tensor([[-0.9399, -2.5915],
        [-2.3176, -1.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28311702609062195
Epoch 0, Step 2295: train/loss = 0.3562512993812561, train/raw-loss = 0.3317628502845764, train/logprobs = tensor([[-1.4626, -4.8018],
        [-1.8492, -0.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24488455057144165
Epoch 0, Step 2296: train/loss = 0.48201772570610046, train/raw-loss = 0.45451414585113525, train/logprobs = tensor([[-1.4537, -2.4878],
        [-1.7717, -1.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750358283519745
Epoch 0, Step 2297: train/loss = 0.34983038902282715, train/raw-loss = 0.3191986680030823, train/logprobs = tensor([[-1.1952, -4.5006],
        [-2.0621, -0.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30631735920906067
Epoch 0, Step 2298: train/loss = 0.46552184224128723, train/raw-loss = 0.435098797082901, train/logprobs = tensor([[-1.3300, -4.4386],
        [-2.7641, -2.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304230272769928
Epoch 0, Step 2299: train/loss = 0.4658206105232239, train/raw-loss = 0.44391772150993347, train/logprobs = tensor([[-0.9495, -5.6491],
        [-1.0882, -2.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2190290093421936
Epoch 0, Step 2300: train/loss = 0.4375271499156952, train/raw-loss = 0.414052814245224, train/logprobs = tensor([[-1.4235, -2.0099],
        [-2.4370, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347429394721985
Epoch 0, Step 2301: train/loss = 0.159181609749794, train/raw-loss = 0.128384530544281, train/logprobs = tensor([[-1.3469, -5.8750],
        [-3.4193, -2.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079707622528076
Epoch 0, Step 2302: train/loss = 0.4565831422805786, train/raw-loss = 0.4293102025985718, train/logprobs = tensor([[-1.3473, -2.6393],
        [-1.8555, -1.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27272912859916687
Epoch 0, Step 2303: train/loss = 0.42439401149749756, train/raw-loss = 0.3950597047805786, train/logprobs = tensor([[-1.4209, -4.3919],
        [-2.4719, -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2933432161808014
Epoch 0, Step 2304: train/loss = 0.3148614168167114, train/raw-loss = 0.28530997037887573, train/logprobs = tensor([[-1.1804, -5.8773],
        [-2.5065, -1.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955143451690674
Epoch 0, Step 2305: train/loss = 0.2152140736579895, train/raw-loss = 0.18414288759231567, train/logprobs = tensor([[-0.9649, -5.4278],
        [-1.8605, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3107118606567383
Epoch 0, Step 2306: train/loss = 0.3469863533973694, train/raw-loss = 0.320463091135025, train/logprobs = tensor([[-1.0056, -6.3254],
        [-1.4630, -1.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26523250341415405
Epoch 0, Step 2307: train/loss = 0.2907700538635254, train/raw-loss = 0.2611308991909027, train/logprobs = tensor([[-2.2422, -5.4633],
        [-2.7295, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29639166593551636
Epoch 0, Step 2308: train/loss = 0.5928497314453125, train/raw-loss = 0.5604730248451233, train/logprobs = tensor([[-1.4575, -3.5323],
        [-2.0598, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237670063972473
Epoch 0, Step 2309: train/loss = 0.5409449934959412, train/raw-loss = 0.5166126489639282, train/logprobs = tensor([[-0.8608, -1.9681],
        [-1.5511, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24332372844219208
Epoch 0, Step 2310: train/loss = 0.5300077199935913, train/raw-loss = 0.5003068447113037, train/logprobs = tensor([[-1.6831, -2.7303],
        [-2.1929, -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29700934886932373
Epoch 0, Step 2311: train/loss = 0.6100267171859741, train/raw-loss = 0.5783946514129639, train/logprobs = tensor([[-1.9037, -4.1379],
        [-1.9473, -1.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31632059812545776
Epoch 0, Step 2312: train/loss = 0.49379727244377136, train/raw-loss = 0.4715910851955414, train/logprobs = tensor([[-1.1392, -4.4561],
        [-1.9155, -2.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22206157445907593
Epoch 0, Step 2313: train/loss = 0.3080117702484131, train/raw-loss = 0.2798970341682434, train/logprobs = tensor([[-1.5855, -4.0799],
        [-2.3655, -0.5913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811472415924072
Epoch 0, Step 2314: train/loss = 0.4056318998336792, train/raw-loss = 0.373935341835022, train/logprobs = tensor([[-1.1611, -4.9121],
        [-2.8393, -1.1045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169657289981842
Epoch 0, Step 2315: train/loss = 0.3568204939365387, train/raw-loss = 0.3293536603450775, train/logprobs = tensor([[-0.9997, -4.3708],
        [-1.7819, -1.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27466821670532227
Epoch 0, Step 2316: train/loss = 0.6604839563369751, train/raw-loss = 0.6337728500366211, train/logprobs = tensor([[-1.1077, -1.7434],
        [-1.2922, -1.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2671104073524475
Epoch 0, Step 2317: train/loss = 0.3472958207130432, train/raw-loss = 0.3154560327529907, train/logprobs = tensor([[-1.6302, -3.4828],
        [-2.8671, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3183976411819458
Epoch 0, Step 2318: train/loss = 0.4524400532245636, train/raw-loss = 0.4180127680301666, train/logprobs = tensor([[-1.9585, -6.0389],
        [-2.5720, -2.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3442727029323578
Epoch 0, Step 2319: train/loss = 0.5118390917778015, train/raw-loss = 0.4882912039756775, train/logprobs = tensor([[-0.8106, -1.4311],
        [-1.4643, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23547890782356262
Epoch 0, Step 2320: train/loss = 0.5371893048286438, train/raw-loss = 0.504957377910614, train/logprobs = tensor([[-1.1431, -2.5507],
        [-2.1931, -1.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3223193883895874
Epoch 0, Step 2321: train/loss = 0.557390570640564, train/raw-loss = 0.5287386178970337, train/logprobs = tensor([[-1.2401, -1.9527],
        [-1.7098, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28651922941207886
Epoch 0, Step 2322: train/loss = 0.3526526093482971, train/raw-loss = 0.3232133984565735, train/logprobs = tensor([[-0.9834, -6.2916],
        [-2.3919, -2.1436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943917512893677
Epoch 0, Step 2323: train/loss = 0.60966956615448, train/raw-loss = 0.5795518755912781, train/logprobs = tensor([[-3.2710, -4.6757],
        [-3.0489, -2.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3011764883995056
Epoch 0, Step 2324: train/loss = 0.6718245148658752, train/raw-loss = 0.6451648473739624, train/logprobs = tensor([[-0.8834, -1.3271],
        [-1.2658, -1.4276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665970027446747
Epoch 0, Step 2325: train/loss = 0.5092793107032776, train/raw-loss = 0.48216432332992554, train/logprobs = tensor([[-0.9373, -3.5508],
        [-1.7117, -2.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2711493670940399
Epoch 0, Step 2326: train/loss = 0.31552010774612427, train/raw-loss = 0.28913414478302, train/logprobs = tensor([[-1.4600, -4.9779],
        [-2.5316, -1.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26385945081710815
Epoch 0, Step 2327: train/loss = 0.37121161818504333, train/raw-loss = 0.3397752642631531, train/logprobs = tensor([[-1.0674, -2.5078],
        [-2.7572, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3143634796142578
Epoch 0, Step 2328: train/loss = 0.6027829647064209, train/raw-loss = 0.579889714717865, train/logprobs = tensor([[-1.2754, -2.1697],
        [-1.2426, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2289324700832367
Epoch 0, Step 2329: train/loss = 0.46089184284210205, train/raw-loss = 0.4330641031265259, train/logprobs = tensor([[-1.5742, -3.5654],
        [-2.1430, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782774269580841
Epoch 0, Step 2330: train/loss = 0.38781365752220154, train/raw-loss = 0.3604523241519928, train/logprobs = tensor([[-1.1385, -4.0878],
        [-1.9898, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27361321449279785
Epoch 0, Step 2331: train/loss = 0.35372284054756165, train/raw-loss = 0.32299724221229553, train/logprobs = tensor([[-1.1650, -3.3645],
        [-2.3645, -1.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3072560429573059
Epoch 0, Step 2332: train/loss = 0.4417301416397095, train/raw-loss = 0.4123312532901764, train/logprobs = tensor([[-1.1643, -3.0727],
        [-1.6443, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29398900270462036
Epoch 0, Step 2333: train/loss = 0.46477338671684265, train/raw-loss = 0.4296621084213257, train/logprobs = tensor([[-0.8635, -2.4152],
        [-2.4349, -2.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35111284255981445
Epoch 0, Step 2334: train/loss = 0.5479080677032471, train/raw-loss = 0.5202926397323608, train/logprobs = tensor([[-1.3058, -2.3474],
        [-1.5655, -1.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27615460753440857
Epoch 0, Step 2335: train/loss = 0.3651072382926941, train/raw-loss = 0.3362058401107788, train/logprobs = tensor([[-0.8697, -4.0224],
        [-1.9012, -2.5080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28901416063308716
Epoch 0, Step 2336: train/loss = 0.27365559339523315, train/raw-loss = 0.24309268593788147, train/logprobs = tensor([[-1.0761, -4.8046],
        [-2.4722, -0.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30562883615493774
Epoch 0, Step 2337: train/loss = 0.1764298975467682, train/raw-loss = 0.14704768359661102, train/logprobs = tensor([[-1.6272, -6.9721],
        [-2.7180, -2.5909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29382219910621643
Epoch 0, Step 2338: train/loss = 0.5174956321716309, train/raw-loss = 0.4910276532173157, train/logprobs = tensor([[-1.0589, -1.7227],
        [-1.9097, -1.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26468008756637573
Epoch 0, Step 2339: train/loss = 0.29184582829475403, train/raw-loss = 0.2554279565811157, train/logprobs = tensor([[-0.9783, -4.7383],
        [-2.4708, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36417853832244873
Epoch 0, Step 2340: train/loss = 0.5537115335464478, train/raw-loss = 0.5182542204856873, train/logprobs = tensor([[-1.3689, -1.9779],
        [-2.4980, -1.7026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35457301139831543
Epoch 0, Step 2341: train/loss = 0.3388212025165558, train/raw-loss = 0.3040364980697632, train/logprobs = tensor([[-1.8892, -4.8586],
        [-3.1142, -1.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3478468358516693
Epoch 0, Step 2342: train/loss = 0.4739135503768921, train/raw-loss = 0.44178104400634766, train/logprobs = tensor([[-0.9660, -2.7635],
        [-2.0299, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213251829147339
Epoch 0, Step 2343: train/loss = 0.44394969940185547, train/raw-loss = 0.41587674617767334, train/logprobs = tensor([[-1.0964, -4.1604],
        [-1.3531, -1.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2807289958000183
Epoch 0, Step 2344: train/loss = 0.5976876020431519, train/raw-loss = 0.5718591213226318, train/logprobs = tensor([[-1.0638, -2.5653],
        [-1.3759, -1.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25828424096107483
Epoch 0, Step 2345: train/loss = 0.45711442828178406, train/raw-loss = 0.42978283762931824, train/logprobs = tensor([[-1.3277, -5.4134],
        [-2.0111, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27331608533859253
Epoch 0, Step 2346: train/loss = 0.4890180826187134, train/raw-loss = 0.46168047189712524, train/logprobs = tensor([[-1.0807, -1.8620],
        [-1.7800, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27337634563446045
Epoch 0, Step 2347: train/loss = 0.5414729118347168, train/raw-loss = 0.5113391876220703, train/logprobs = tensor([[-1.6863, -2.8833],
        [-1.6469, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013370931148529
Epoch 0, Step 2348: train/loss = 0.7398257851600647, train/raw-loss = 0.7095651626586914, train/logprobs = tensor([[-3.2059, -4.4993],
        [-2.5859, -2.3376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.302606463432312
Epoch 0, Step 2349: train/loss = 0.5467671155929565, train/raw-loss = 0.5226073265075684, train/logprobs = tensor([[-2.2050, -3.0370],
        [-2.2172, -1.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24159708619117737
Epoch 0, Step 2350: train/loss = 0.5377179384231567, train/raw-loss = 0.5111183524131775, train/logprobs = tensor([[-1.2112, -2.2343],
        [-1.3378, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26599591970443726
Epoch 0, Step 2351: train/loss = 0.2119530737400055, train/raw-loss = 0.18275198340415955, train/logprobs = tensor([[-1.2863, -5.3572],
        [-2.2918, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2920109033584595
Epoch 0, Step 2352: train/loss = 0.4410085678100586, train/raw-loss = 0.40820369124412537, train/logprobs = tensor([[-0.9859, -1.9863],
        [-2.4605, -1.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3280486464500427
Epoch 0, Step 2353: train/loss = 0.49013954401016235, train/raw-loss = 0.46164292097091675, train/logprobs = tensor([[-1.5620, -6.8226],
        [-1.4837, -2.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28496572375297546
Epoch 0, Step 2354: train/loss = 0.25494852662086487, train/raw-loss = 0.2263355255126953, train/logprobs = tensor([[-1.7150, -6.4576],
        [-3.3492, -0.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.286129891872406
Epoch 0, Step 2355: train/loss = 0.4521394968032837, train/raw-loss = 0.41725826263427734, train/logprobs = tensor([[-1.3144, -1.9972],
        [-2.6392, -1.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34881216287612915
Epoch 0, Step 2356: train/loss = 0.25206461548805237, train/raw-loss = 0.2170935869216919, train/logprobs = tensor([[-1.4646, -5.2175],
        [-3.3272, -1.4191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3497101962566376
Epoch 0, Step 2357: train/loss = 0.6778973340988159, train/raw-loss = 0.6436591744422913, train/logprobs = tensor([[-2.1789, -6.1094],
        [-2.6191, -2.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34238171577453613
Epoch 0, Step 2358: train/loss = 0.31637734174728394, train/raw-loss = 0.287130743265152, train/logprobs = tensor([[-1.5104, -3.2665],
        [-2.9229, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29246625304222107
Epoch 0, Step 2359: train/loss = 0.3370661437511444, train/raw-loss = 0.3098398447036743, train/logprobs = tensor([[-1.1234, -3.6869],
        [-1.8396, -1.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722630798816681
Epoch 0, Step 2360: train/loss = 0.6987882256507874, train/raw-loss = 0.6733396053314209, train/logprobs = tensor([[-1.8728, -2.6280],
        [-1.7874, -1.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544857859611511
Epoch 0, Step 2361: train/loss = 0.5835340619087219, train/raw-loss = 0.5595204830169678, train/logprobs = tensor([[-0.6780, -0.9680],
        [-1.1959, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24013613164424896
Epoch 0, Step 2362: train/loss = 0.509849488735199, train/raw-loss = 0.48504990339279175, train/logprobs = tensor([[-1.6320, -3.4793],
        [-2.2454, -2.5100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24799610674381256
Epoch 0, Step 2363: train/loss = 0.49023672938346863, train/raw-loss = 0.4631515443325043, train/logprobs = tensor([[-0.7667, -2.0581],
        [-1.6928, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708517611026764
Epoch 0, Step 2364: train/loss = 0.4149596095085144, train/raw-loss = 0.390262246131897, train/logprobs = tensor([[-1.0823, -5.4405],
        [-1.6931, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24697375297546387
Epoch 0, Step 2365: train/loss = 0.4852144420146942, train/raw-loss = 0.4553377032279968, train/logprobs = tensor([[-2.2267, -3.9851],
        [-3.1609, -2.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987672686576843
Epoch 0, Step 2366: train/loss = 0.5964233875274658, train/raw-loss = 0.565717875957489, train/logprobs = tensor([[-0.8237, -1.9796],
        [-1.9425, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30705526471138
Epoch 0, Step 2367: train/loss = 0.6435853242874146, train/raw-loss = 0.6134653687477112, train/logprobs = tensor([[-1.1009, -2.1547],
        [-1.5760, -2.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30119988322257996
Epoch 0, Step 2368: train/loss = 0.4082574248313904, train/raw-loss = 0.38100817799568176, train/logprobs = tensor([[-1.1843, -2.8934],
        [-2.4070, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27249252796173096
Epoch 0, Step 2369: train/loss = 0.39081770181655884, train/raw-loss = 0.36528053879737854, train/logprobs = tensor([[-1.5916, -5.1149],
        [-2.1317, -2.5965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255371630191803
Epoch 0, Step 2370: train/loss = 0.7452033162117004, train/raw-loss = 0.7135746479034424, train/logprobs = tensor([[-1.4615, -1.4742],
        [-1.4833, -1.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3162858784198761
Epoch 0, Step 2371: train/loss = 0.4730042815208435, train/raw-loss = 0.44667157530784607, train/logprobs = tensor([[-1.0351, -3.5175],
        [-1.5746, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2633272409439087
Epoch 0, Step 2372: train/loss = 0.25153863430023193, train/raw-loss = 0.22393307089805603, train/logprobs = tensor([[-0.9514, -3.7719],
        [-2.1409, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760554552078247
Epoch 0, Step 2373: train/loss = 0.27744653820991516, train/raw-loss = 0.249441996216774, train/logprobs = tensor([[-1.2425, -5.8292],
        [-2.6260, -1.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28004544973373413
Epoch 0, Step 2374: train/loss = 0.6588282585144043, train/raw-loss = 0.6288372874259949, train/logprobs = tensor([[-1.5414, -2.5343],
        [-1.5459, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29990920424461365
Epoch 0, Step 2375: train/loss = 0.6379052400588989, train/raw-loss = 0.6111548542976379, train/logprobs = tensor([[-1.2978, -1.7663],
        [-1.8719, -1.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26750367879867554
Epoch 0, Step 2376: train/loss = 0.4019368588924408, train/raw-loss = 0.37994763255119324, train/logprobs = tensor([[-1.1375, -4.3700],
        [-1.5447, -2.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21989265084266663
Epoch 0, Step 2377: train/loss = 0.47333917021751404, train/raw-loss = 0.4454460144042969, train/logprobs = tensor([[-1.2945, -3.6936],
        [-1.6918, -1.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27893170714378357
Epoch 0, Step 2378: train/loss = 0.5064396262168884, train/raw-loss = 0.4826821982860565, train/logprobs = tensor([[-1.0382, -3.4166],
        [-1.3199, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2375742495059967
Epoch 0, Step 2379: train/loss = 0.5340139865875244, train/raw-loss = 0.5123764276504517, train/logprobs = tensor([[-0.7536, -3.0137],
        [-1.1630, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2163762003183365
Epoch 0, Step 2380: train/loss = 0.5184348821640015, train/raw-loss = 0.48992371559143066, train/logprobs = tensor([[-0.9104, -2.6477],
        [-1.6530, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851114273071289
Epoch 0, Step 2381: train/loss = 0.532078206539154, train/raw-loss = 0.5062620043754578, train/logprobs = tensor([[-1.9970, -5.1084],
        [-2.0212, -1.5295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25816214084625244
Epoch 0, Step 2382: train/loss = 0.43508782982826233, train/raw-loss = 0.4067699909210205, train/logprobs = tensor([[-1.8843, -4.7089],
        [-2.1713, -1.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831781804561615
Epoch 0, Step 2383: train/loss = 0.1743013858795166, train/raw-loss = 0.14154277741909027, train/logprobs = tensor([[-1.2060, -8.7178],
        [-2.4394, -1.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32758599519729614
Epoch 0, Step 2384: train/loss = 0.3632866442203522, train/raw-loss = 0.3340333104133606, train/logprobs = tensor([[-1.0038, -3.6497],
        [-2.1631, -2.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925335764884949
Epoch 0, Step 2385: train/loss = 0.4107188880443573, train/raw-loss = 0.38130563497543335, train/logprobs = tensor([[-0.8493, -2.0673],
        [-1.8858, -1.0344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29413217306137085
Epoch 0, Step 2386: train/loss = 0.6206123232841492, train/raw-loss = 0.5949487686157227, train/logprobs = tensor([[-0.9612, -1.4177],
        [-1.3826, -1.3717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25663596391677856
Epoch 0, Step 2387: train/loss = 0.4421156644821167, train/raw-loss = 0.4121251106262207, train/logprobs = tensor([[-1.3741, -2.7873],
        [-1.6963, -1.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29990580677986145
Epoch 0, Step 2388: train/loss = 0.18198350071907043, train/raw-loss = 0.15005218982696533, train/logprobs = tensor([[-1.5363, -4.0159],
        [-3.3370, -1.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319313108921051
Epoch 0, Step 2389: train/loss = 0.2780214250087738, train/raw-loss = 0.24704135954380035, train/logprobs = tensor([[-2.1951, -5.6824],
        [-3.4030, -1.8995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098006844520569
Epoch 0, Step 2390: train/loss = 0.2960323691368103, train/raw-loss = 0.26757097244262695, train/logprobs = tensor([[-1.0893, -4.7499],
        [-2.0243, -0.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28461411595344543
Epoch 0, Step 2391: train/loss = 0.5706659555435181, train/raw-loss = 0.5430727005004883, train/logprobs = tensor([[-0.9678, -1.7854],
        [-1.3974, -1.2642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759321331977844
Epoch 0, Step 2392: train/loss = 0.37372905015945435, train/raw-loss = 0.34341010451316833, train/logprobs = tensor([[-1.4838, -5.2388],
        [-1.8221, -2.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3031892776489258
Epoch 0, Step 2393: train/loss = 0.5320250988006592, train/raw-loss = 0.5018714070320129, train/logprobs = tensor([[-1.4074, -3.3145],
        [-1.7792, -2.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30153751373291016
Epoch 0, Step 2394: train/loss = 0.5503772497177124, train/raw-loss = 0.5203430652618408, train/logprobs = tensor([[-1.1227, -3.1090],
        [-2.1504, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30034205317497253
Epoch 0, Step 2395: train/loss = 0.4608180522918701, train/raw-loss = 0.43452557921409607, train/logprobs = tensor([[-0.9039, -4.4102],
        [-1.5456, -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26292499899864197
Epoch 0, Step 2396: train/loss = 0.2827712893486023, train/raw-loss = 0.2577678859233856, train/logprobs = tensor([[-0.7646, -5.7753],
        [-2.2646, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500339150428772
Epoch 0, Step 2397: train/loss = 0.4777160584926605, train/raw-loss = 0.4458003342151642, train/logprobs = tensor([[-2.3510, -2.8469],
        [-3.0927, -1.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3191576302051544
Epoch 0, Step 2398: train/loss = 0.5376274585723877, train/raw-loss = 0.5156694054603577, train/logprobs = tensor([[-0.6172, -2.1729],
        [-0.8638, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21958085894584656
Epoch 0, Step 2399: train/loss = 0.371889591217041, train/raw-loss = 0.3433813750743866, train/logprobs = tensor([[-1.2434, -5.1384],
        [-1.8778, -2.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2850821018218994
Epoch 0, Step 2400: train/loss = 0.2703453600406647, train/raw-loss = 0.24416598677635193, train/logprobs = tensor([[-0.9307, -5.4059],
        [-1.7578, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26179394125938416
Epoch 0, Step 2401: train/loss = 0.3666432201862335, train/raw-loss = 0.3397556245326996, train/logprobs = tensor([[-1.3874, -4.8871],
        [-1.5997, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26887577772140503
Epoch 0, Step 2402: train/loss = 0.5280508399009705, train/raw-loss = 0.4981091022491455, train/logprobs = tensor([[-1.2177, -2.1350],
        [-2.0142, -1.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29941749572753906
Epoch 0, Step 2403: train/loss = 0.5710147023200989, train/raw-loss = 0.5443031787872314, train/logprobs = tensor([[-2.1411, -3.3890],
        [-2.9490, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26711490750312805
Epoch 0, Step 2404: train/loss = 0.3842015862464905, train/raw-loss = 0.35129648447036743, train/logprobs = tensor([[-1.1434, -4.4479],
        [-2.3888, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290509879589081
Epoch 0, Step 2405: train/loss = 0.8040010929107666, train/raw-loss = 0.7731597423553467, train/logprobs = tensor([[-3.0974, -8.1394],
        [-2.5344, -1.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3084138333797455
Epoch 0, Step 2406: train/loss = 0.7713327407836914, train/raw-loss = 0.7463077902793884, train/logprobs = tensor([[-0.8555, -0.9449],
        [-0.9080, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250249445438385
Epoch 0, Step 2407: train/loss = 0.40487244725227356, train/raw-loss = 0.3668176531791687, train/logprobs = tensor([[-1.4971, -2.3883],
        [-2.8530, -1.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38054782152175903
Epoch 0, Step 2408: train/loss = 0.5975812673568726, train/raw-loss = 0.5723253488540649, train/logprobs = tensor([[-1.1928, -1.4886],
        [-1.4964, -1.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525590658187866
Epoch 0, Step 2409: train/loss = 0.6143651008605957, train/raw-loss = 0.587422251701355, train/logprobs = tensor([[-1.0569, -1.6882],
        [-2.1099, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26942867040634155
Epoch 0, Step 2410: train/loss = 0.4256092309951782, train/raw-loss = 0.39240169525146484, train/logprobs = tensor([[-1.1112, -3.2606],
        [-2.4085, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3320755660533905
Epoch 0, Step 2411: train/loss = 0.4215465188026428, train/raw-loss = 0.38905856013298035, train/logprobs = tensor([[-1.3830, -2.5339],
        [-3.0018, -1.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32487937808036804
Epoch 0, Step 2412: train/loss = 0.3292841613292694, train/raw-loss = 0.2929760217666626, train/logprobs = tensor([[-1.5514, -5.5024],
        [-2.9677, -1.6049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3630814254283905
Epoch 0, Step 2413: train/loss = 0.6006402373313904, train/raw-loss = 0.5751051902770996, train/logprobs = tensor([[-0.8207, -1.4638],
        [-1.0663, -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255350261926651
Epoch 0, Step 2414: train/loss = 0.45441699028015137, train/raw-loss = 0.42800605297088623, train/logprobs = tensor([[-1.3227, -3.6274],
        [-1.6796, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641090154647827
Epoch 0, Step 2415: train/loss = 0.4888085126876831, train/raw-loss = 0.46024295687675476, train/logprobs = tensor([[-1.0111, -2.2725],
        [-1.2561, -0.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856554388999939
Epoch 0, Step 2416: train/loss = 0.354373574256897, train/raw-loss = 0.3228316903114319, train/logprobs = tensor([[-0.9765, -4.3708],
        [-1.9852, -2.3932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31541886925697327
Epoch 0, Step 2417: train/loss = 0.3572663366794586, train/raw-loss = 0.3290101885795593, train/logprobs = tensor([[-1.3958, -4.9927],
        [-2.9909, -1.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28256142139434814
Epoch 0, Step 2418: train/loss = 0.7793399691581726, train/raw-loss = 0.7515984773635864, train/logprobs = tensor([[-1.8268, -2.2037],
        [-0.9292, -1.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2774149179458618
Epoch 0, Step 2419: train/loss = 0.5532703399658203, train/raw-loss = 0.5237745642662048, train/logprobs = tensor([[-2.3786, -3.9583],
        [-2.3782, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29495769739151
Epoch 0, Step 2420: train/loss = 0.49882012605667114, train/raw-loss = 0.4705978035926819, train/logprobs = tensor([[-1.9115, -6.1949],
        [-2.0208, -1.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2822232246398926
Epoch 0, Step 2421: train/loss = 0.367045521736145, train/raw-loss = 0.33538421988487244, train/logprobs = tensor([[-1.7569, -5.5904],
        [-2.4761, -1.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31661292910575867
Epoch 0, Step 2422: train/loss = 0.3920239508152008, train/raw-loss = 0.35911908745765686, train/logprobs = tensor([[-1.2351, -4.6835],
        [-1.9606, -1.3606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290485739707947
Epoch 0, Step 2423: train/loss = 0.3916911482810974, train/raw-loss = 0.3632434904575348, train/logprobs = tensor([[-1.0667, -4.0378],
        [-1.7555, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28447622060775757
Epoch 0, Step 2424: train/loss = 0.3311823904514313, train/raw-loss = 0.2945551574230194, train/logprobs = tensor([[-1.0729, -7.5240],
        [-3.1075, -2.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3662722706794739
Epoch 0, Step 2425: train/loss = 0.5848541259765625, train/raw-loss = 0.5635078549385071, train/logprobs = tensor([[-0.9849, -1.7331],
        [-1.4472, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.213462695479393
Epoch 0, Step 2426: train/loss = 0.35994666814804077, train/raw-loss = 0.3312456011772156, train/logprobs = tensor([[-1.6837, -2.5005],
        [-2.7888, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2870104908943176
Epoch 0, Step 2427: train/loss = 0.48873093724250793, train/raw-loss = 0.45813727378845215, train/logprobs = tensor([[-1.2018, -3.0680],
        [-1.6161, -1.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30593669414520264
Epoch 0, Step 2428: train/loss = 0.41481658816337585, train/raw-loss = 0.38427460193634033, train/logprobs = tensor([[-1.1487, -3.5985],
        [-2.0470, -1.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30542007088661194
Epoch 0, Step 2429: train/loss = 0.48713797330856323, train/raw-loss = 0.45508405566215515, train/logprobs = tensor([[-1.7708, -4.5747],
        [-2.3772, -2.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32053908705711365
Epoch 0, Step 2430: train/loss = 0.42630285024642944, train/raw-loss = 0.3960902690887451, train/logprobs = tensor([[-1.3429, -3.1298],
        [-1.7761, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30212610960006714
Epoch 0, Step 2431: train/loss = 0.3989010453224182, train/raw-loss = 0.3695716857910156, train/logprobs = tensor([[-0.9966, -4.8760],
        [-2.3188, -1.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932932376861572
Epoch 0, Step 2432: train/loss = 0.430126428604126, train/raw-loss = 0.39964058995246887, train/logprobs = tensor([[-1.0328, -3.1645],
        [-1.9304, -1.6290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30485841631889343
Epoch 0, Step 2433: train/loss = 0.41492751240730286, train/raw-loss = 0.3839452862739563, train/logprobs = tensor([[-1.3097, -2.1053],
        [-2.5928, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3098219335079193
Epoch 0, Step 2434: train/loss = 0.43329569697380066, train/raw-loss = 0.4098805785179138, train/logprobs = tensor([[-1.0284, -2.4134],
        [-1.4695, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23415109515190125
Epoch 0, Step 2435: train/loss = 0.9469562768936157, train/raw-loss = 0.9182252287864685, train/logprobs = tensor([[-3.5604, -6.2774],
        [-2.0577, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28731024265289307
Epoch 0, Step 2436: train/loss = 0.5592182278633118, train/raw-loss = 0.5298555493354797, train/logprobs = tensor([[-2.0501, -3.6516],
        [-1.6406, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.293626606464386
Epoch 0, Step 2437: train/loss = 0.4521808624267578, train/raw-loss = 0.4261610805988312, train/logprobs = tensor([[-1.3921, -3.1164],
        [-1.7205, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2601977586746216
Epoch 0, Step 2438: train/loss = 0.3991701602935791, train/raw-loss = 0.3629986345767975, train/logprobs = tensor([[-1.3404, -3.1614],
        [-3.0858, -1.5339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617151379585266
Epoch 0, Step 2439: train/loss = 0.5368973612785339, train/raw-loss = 0.5088900327682495, train/logprobs = tensor([[-1.8688, -2.0161],
        [-3.2844, -1.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280073344707489
Epoch 0, Step 2440: train/loss = 0.3722136318683624, train/raw-loss = 0.34135279059410095, train/logprobs = tensor([[-1.0230, -5.0178],
        [-2.8403, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086082637310028
Epoch 0, Step 2441: train/loss = 0.47670090198516846, train/raw-loss = 0.44761085510253906, train/logprobs = tensor([[-1.0726, -2.2944],
        [-1.7993, -1.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.290900319814682
Epoch 0, Step 2442: train/loss = 0.26954904198646545, train/raw-loss = 0.2393576055765152, train/logprobs = tensor([[-1.7058, -5.5073],
        [-3.2920, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30191415548324585
Epoch 0, Step 2443: train/loss = 0.37410950660705566, train/raw-loss = 0.3432151675224304, train/logprobs = tensor([[-1.4320, -4.2355],
        [-2.1049, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308943510055542
Epoch 0, Step 2444: train/loss = 0.09428714215755463, train/raw-loss = 0.05027378350496292, train/logprobs = tensor([[-1.0697, -5.7817],
        [-4.0499, -1.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44013354182243347
Epoch 0, Step 2445: train/loss = 0.5440101623535156, train/raw-loss = 0.5183592438697815, train/logprobs = tensor([[-1.6253, -2.4883],
        [-1.7210, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25650954246520996
Epoch 0, Step 2446: train/loss = 0.6244564056396484, train/raw-loss = 0.589672327041626, train/logprobs = tensor([[-1.3909, -1.7540],
        [-2.4841, -2.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34784001111984253
Epoch 0, Step 2447: train/loss = 0.798492431640625, train/raw-loss = 0.7665055990219116, train/logprobs = tensor([[-1.3541, -1.3863],
        [-2.1385, -2.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3198680281639099
Epoch 0, Step 2448: train/loss = 0.4957807660102844, train/raw-loss = 0.46965521574020386, train/logprobs = tensor([[-1.1666, -2.4360],
        [-1.5234, -1.2061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612554430961609
Epoch 0, Step 2449: train/loss = 0.3741181194782257, train/raw-loss = 0.3497270941734314, train/logprobs = tensor([[-1.2168, -3.3178],
        [-2.0871, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24390996992588043
Epoch 0, Step 2450: train/loss = 0.2807983458042145, train/raw-loss = 0.24915410578250885, train/logprobs = tensor([[-0.9221, -3.2923],
        [-2.0766, -1.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164426386356354
Epoch 0, Step 2451: train/loss = 0.3738878071308136, train/raw-loss = 0.3421512246131897, train/logprobs = tensor([[-1.7316, -6.3508],
        [-2.3591, -1.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31736576557159424
Epoch 0, Step 2452: train/loss = 0.785484254360199, train/raw-loss = 0.7575628757476807, train/logprobs = tensor([[-1.0061, -1.2024],
        [-1.6850, -1.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27921393513679504
Epoch 0, Step 2453: train/loss = 0.3551969826221466, train/raw-loss = 0.33005276322364807, train/logprobs = tensor([[-0.9908, -4.1154],
        [-1.8654, -1.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25144195556640625
Epoch 0, Step 2454: train/loss = 0.4765551686286926, train/raw-loss = 0.451127290725708, train/logprobs = tensor([[-1.3034, -5.8709],
        [-1.9494, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25427865982055664
Epoch 0, Step 2455: train/loss = 0.37050706148147583, train/raw-loss = 0.34461236000061035, train/logprobs = tensor([[-1.3286, -4.9430],
        [-2.2028, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25894689559936523
Epoch 0, Step 2456: train/loss = 0.23854699730873108, train/raw-loss = 0.2126007378101349, train/logprobs = tensor([[ -1.2505, -10.8747],
        [ -2.1799,  -2.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594625949859619
Epoch 0, Step 2457: train/loss = 0.5031059384346008, train/raw-loss = 0.47636234760284424, train/logprobs = tensor([[-1.7845, -4.7550],
        [-1.7396, -0.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26743561029434204
Epoch 0, Step 2458: train/loss = 0.5832340121269226, train/raw-loss = 0.5598012804985046, train/logprobs = tensor([[-0.8838, -2.6329],
        [-1.3648, -1.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.234327495098114
Epoch 0, Step 2459: train/loss = 0.4850066602230072, train/raw-loss = 0.4591803252696991, train/logprobs = tensor([[-0.8790, -2.2824],
        [-1.4063, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2582632899284363
Epoch 0, Step 2460: train/loss = 0.4256003797054291, train/raw-loss = 0.3908175230026245, train/logprobs = tensor([[-1.8963, -4.0073],
        [-2.4628, -0.8110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34782859683036804
Epoch 0, Step 2461: train/loss = 0.4439598023891449, train/raw-loss = 0.4102405607700348, train/logprobs = tensor([[-2.2528, -4.5790],
        [-2.8076, -1.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3371926546096802
Epoch 0, Step 2462: train/loss = 0.4666004478931427, train/raw-loss = 0.4388866424560547, train/logprobs = tensor([[-1.1925, -4.4163],
        [-2.1090, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27713823318481445
Epoch 0, Step 2463: train/loss = 0.4718286395072937, train/raw-loss = 0.4474484920501709, train/logprobs = tensor([[-1.1716, -1.9009],
        [-1.6589, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24380165338516235
Epoch 0, Step 2464: train/loss = 0.41449397802352905, train/raw-loss = 0.3847830295562744, train/logprobs = tensor([[-1.0953, -5.7751],
        [-2.7571, -3.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2971097230911255
Epoch 0, Step 2465: train/loss = 0.4023139476776123, train/raw-loss = 0.3744489252567291, train/logprobs = tensor([[-1.3308, -4.9928],
        [-1.9444, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2786502242088318
Epoch 0, Step 2466: train/loss = 0.2764318585395813, train/raw-loss = 0.25101009011268616, train/logprobs = tensor([[-1.5038, -4.6783],
        [-2.7340, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542176842689514
Epoch 0, Step 2467: train/loss = 0.25722062587738037, train/raw-loss = 0.2271609753370285, train/logprobs = tensor([[-0.8701, -6.7336],
        [-3.3517, -2.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3005966544151306
Epoch 0, Step 2468: train/loss = 0.49726808071136475, train/raw-loss = 0.4737178087234497, train/logprobs = tensor([[-1.0724, -4.4015],
        [-1.2075, -1.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23550285398960114
Epoch 0, Step 2469: train/loss = 0.40074753761291504, train/raw-loss = 0.370212197303772, train/logprobs = tensor([[-1.3406, -2.9192],
        [-2.0904, -0.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053531050682068
Epoch 0, Step 2470: train/loss = 0.7048181295394897, train/raw-loss = 0.6787661910057068, train/logprobs = tensor([[-1.0763, -1.1202],
        [-1.2690, -1.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605189383029938
Epoch 0, Step 2471: train/loss = 0.2963660657405853, train/raw-loss = 0.26759135723114014, train/logprobs = tensor([[-1.1780, -4.9887],
        [-2.0514, -1.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28774717450141907
Epoch 0, Step 2472: train/loss = 0.3166983127593994, train/raw-loss = 0.28286969661712646, train/logprobs = tensor([[-1.2101, -3.4302],
        [-2.2530, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33828604221343994
Epoch 0, Step 2473: train/loss = 0.32329684495925903, train/raw-loss = 0.2912370264530182, train/logprobs = tensor([[-1.2862, -3.8690],
        [-2.2519, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205980360507965
Epoch 0, Step 2474: train/loss = 0.2682630121707916, train/raw-loss = 0.2397436797618866, train/logprobs = tensor([[-1.2926, -4.4847],
        [-2.0876, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28519323468208313
Epoch 0, Step 2475: train/loss = 0.5025033950805664, train/raw-loss = 0.46835532784461975, train/logprobs = tensor([[-1.8671, -5.3689],
        [-2.2967, -1.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34148067235946655
Epoch 0, Step 2476: train/loss = 0.48040077090263367, train/raw-loss = 0.4499688446521759, train/logprobs = tensor([[-1.2576, -2.9545],
        [-2.2868, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043195605278015
Epoch 0, Step 2477: train/loss = 0.7434744238853455, train/raw-loss = 0.7146421074867249, train/logprobs = tensor([[-2.0498, -2.1437],
        [-1.8147, -1.6064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28832319378852844
Epoch 0, Step 2478: train/loss = 0.5775197744369507, train/raw-loss = 0.5495366454124451, train/logprobs = tensor([[-0.8393, -3.8674],
        [-2.0074, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798316180706024
Epoch 0, Step 2479: train/loss = 0.09550875425338745, train/raw-loss = 0.06321826577186584, train/logprobs = tensor([[-1.2745, -8.8841],
        [-3.9603, -1.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32290491461753845
Epoch 0, Step 2480: train/loss = 0.6264997720718384, train/raw-loss = 0.5976887941360474, train/logprobs = tensor([[-1.2737, -2.3165],
        [-1.2806, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28810933232307434
Epoch 0, Step 2481: train/loss = 0.35206323862075806, train/raw-loss = 0.3214966952800751, train/logprobs = tensor([[-1.3588, -3.9163],
        [-2.6696, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3056650459766388
Epoch 0, Step 2482: train/loss = 0.29429924488067627, train/raw-loss = 0.2688443064689636, train/logprobs = tensor([[-1.1262, -5.9205],
        [-2.0194, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2545493245124817
Epoch 0, Step 2483: train/loss = 0.37623944878578186, train/raw-loss = 0.34629887342453003, train/logprobs = tensor([[-1.2765, -3.4118],
        [-2.1674, -1.2699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2994059920310974
Epoch 0, Step 2484: train/loss = 0.3817223608493805, train/raw-loss = 0.35479384660720825, train/logprobs = tensor([[-1.5987, -5.2412],
        [-1.7556, -1.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26928552985191345
Epoch 0, Step 2485: train/loss = 0.24497327208518982, train/raw-loss = 0.21609854698181152, train/logprobs = tensor([[-0.9892, -3.7098],
        [-2.9124, -1.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28874748945236206
Epoch 0, Step 2486: train/loss = 0.27723029255867004, train/raw-loss = 0.25123804807662964, train/logprobs = tensor([[-1.1316, -3.5381],
        [-2.0274, -0.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25992247462272644
Epoch 0, Step 2487: train/loss = 0.4006601572036743, train/raw-loss = 0.37083709239959717, train/logprobs = tensor([[-0.9326, -2.6344],
        [-1.6297, -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29823076725006104
Epoch 0, Step 2488: train/loss = 0.5472438335418701, train/raw-loss = 0.5143269896507263, train/logprobs = tensor([[-1.1301, -1.8328],
        [-2.0605, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291682004928589
Epoch 0, Step 2489: train/loss = 0.44123655557632446, train/raw-loss = 0.40933164954185486, train/logprobs = tensor([[-0.9951, -3.1568],
        [-1.6645, -1.3607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3190494775772095
Epoch 0, Step 2490: train/loss = 0.34129685163497925, train/raw-loss = 0.3132960796356201, train/logprobs = tensor([[-1.0131, -2.6547],
        [-2.0552, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2800077795982361
Epoch 0, Step 2491: train/loss = 0.41007745265960693, train/raw-loss = 0.3804422914981842, train/logprobs = tensor([[-1.4100, -4.8261],
        [-2.1635, -2.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29635152220726013
Epoch 0, Step 2492: train/loss = 0.5245226621627808, train/raw-loss = 0.48977676033973694, train/logprobs = tensor([[-0.8062, -2.5975],
        [-2.3742, -1.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34745916724205017
Epoch 0, Step 2493: train/loss = 0.43771421909332275, train/raw-loss = 0.41104286909103394, train/logprobs = tensor([[-1.2252, -3.8504],
        [-2.1360, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26671338081359863
Epoch 0, Step 2494: train/loss = 0.6205953359603882, train/raw-loss = 0.5980117917060852, train/logprobs = tensor([[-1.5503, -4.9075],
        [-1.4159, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22583557665348053
Epoch 0, Step 2495: train/loss = 0.5201080441474915, train/raw-loss = 0.4870705008506775, train/logprobs = tensor([[-1.1300, -4.2066],
        [-2.4991, -1.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3303753733634949
Epoch 0, Step 2496: train/loss = 0.3567403554916382, train/raw-loss = 0.3247409462928772, train/logprobs = tensor([[-1.9254, -4.7358],
        [-3.0224, -1.5159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31999388337135315
Epoch 0, Step 2497: train/loss = 0.667214572429657, train/raw-loss = 0.6386605501174927, train/logprobs = tensor([[-2.9730, -5.0040],
        [-2.2756, -3.1892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28554052114486694
Epoch 0, Step 2498: train/loss = 0.5635316371917725, train/raw-loss = 0.5331200361251831, train/logprobs = tensor([[-2.3391, -3.7593],
        [-2.2442, -2.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041159510612488
Epoch 0, Step 2499: train/loss = 0.29302075505256653, train/raw-loss = 0.25931501388549805, train/logprobs = tensor([[-1.6187, -5.3179],
        [-3.1608, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33705735206604004
Epoch 0, Step 2500: train/loss = 0.5049921274185181, train/raw-loss = 0.47762414813041687, train/logprobs = tensor([[-0.8127, -3.1047],
        [-1.6699, -1.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2736796438694
Epoch 0, Step 2501: train/loss = 0.2804976999759674, train/raw-loss = 0.25675341486930847, train/logprobs = tensor([[-0.9296, -4.4950],
        [-1.8889, -1.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2374427765607834
Epoch 0, Step 2502: train/loss = 0.4043773412704468, train/raw-loss = 0.3751850426197052, train/logprobs = tensor([[-1.1813, -5.6676],
        [-2.4164, -1.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291922926902771
Epoch 0, Step 2503: train/loss = 0.3508610129356384, train/raw-loss = 0.32441478967666626, train/logprobs = tensor([[-0.7769, -3.3497],
        [-1.4990, -0.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644626498222351
Epoch 0, Step 2504: train/loss = 0.49353352189064026, train/raw-loss = 0.4653938114643097, train/logprobs = tensor([[-1.0511, -1.6268],
        [-2.1021, -1.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813970446586609
Epoch 0, Step 2505: train/loss = 0.3491303026676178, train/raw-loss = 0.31844189763069153, train/logprobs = tensor([[-1.1390, -3.0118],
        [-2.4352, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.306884229183197
Epoch 0, Step 2506: train/loss = 0.3611706495285034, train/raw-loss = 0.3331248164176941, train/logprobs = tensor([[-1.5426, -7.4169],
        [-1.9646, -2.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804584205150604
Epoch 0, Step 2507: train/loss = 0.4349440634250641, train/raw-loss = 0.40147244930267334, train/logprobs = tensor([[-1.0045, -2.0153],
        [-1.8850, -1.2133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33471593260765076
Epoch 0, Step 2508: train/loss = 0.3912387192249298, train/raw-loss = 0.36294782161712646, train/logprobs = tensor([[-1.1322, -2.7289],
        [-1.7930, -1.3277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28290867805480957
Epoch 0, Step 2509: train/loss = 0.401032954454422, train/raw-loss = 0.37412703037261963, train/logprobs = tensor([[-0.9867, -3.1305],
        [-1.9178, -1.2976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26905956864356995
Epoch 0, Step 2510: train/loss = 0.35052168369293213, train/raw-loss = 0.3194059729576111, train/logprobs = tensor([[-1.1273, -4.6541],
        [-2.5208, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3111570179462433
Epoch 0, Step 2511: train/loss = 0.5356287956237793, train/raw-loss = 0.5061874985694885, train/logprobs = tensor([[-0.8928, -1.7902],
        [-1.5154, -1.3048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29441380500793457
Epoch 0, Step 2512: train/loss = 0.4006877541542053, train/raw-loss = 0.37025541067123413, train/logprobs = tensor([[-0.9182, -3.6772],
        [-2.3308, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043234348297119
Epoch 0, Step 2513: train/loss = 0.5106809735298157, train/raw-loss = 0.4783211350440979, train/logprobs = tensor([[-1.8316, -2.6163],
        [-2.5569, -1.9786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3235985338687897
Epoch 0, Step 2514: train/loss = 0.5529038906097412, train/raw-loss = 0.5301648378372192, train/logprobs = tensor([[-1.4545, -3.9015],
        [-1.2852, -1.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22739087045192719
Epoch 0, Step 2515: train/loss = 0.46753591299057007, train/raw-loss = 0.4383644759654999, train/logprobs = tensor([[-1.6254, -8.3672],
        [-2.1954, -2.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291714072227478
Epoch 0, Step 2516: train/loss = 0.35192734003067017, train/raw-loss = 0.3270215094089508, train/logprobs = tensor([[-0.8492, -4.1962],
        [-1.5798, -1.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24905794858932495
Epoch 0, Step 2517: train/loss = 0.32655322551727295, train/raw-loss = 0.2934378385543823, train/logprobs = tensor([[-1.5168, -3.2398],
        [-3.2926, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3311537504196167
Epoch 0, Step 2518: train/loss = 0.5082122087478638, train/raw-loss = 0.48278048634529114, train/logprobs = tensor([[-1.1479, -2.1072],
        [-1.4968, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543165683746338
Epoch 0, Step 2519: train/loss = 0.13567858934402466, train/raw-loss = 0.10151708126068115, train/logprobs = tensor([[-1.5640, -5.1738],
        [-3.6984, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34161511063575745
Epoch 0, Step 2520: train/loss = 0.22824977338314056, train/raw-loss = 0.198852077126503, train/logprobs = tensor([[-1.5796, -7.2472],
        [-2.2317, -2.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29397690296173096
Epoch 0, Step 2521: train/loss = 0.6490819454193115, train/raw-loss = 0.6282656192779541, train/logprobs = tensor([[-1.3508, -3.2113],
        [-0.7264, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2081640213727951
Epoch 0, Step 2522: train/loss = 0.6339127421379089, train/raw-loss = 0.607569694519043, train/logprobs = tensor([[-1.5865, -1.9102],
        [-1.2754, -1.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26343047618865967
Epoch 0, Step 2523: train/loss = 0.6040557622909546, train/raw-loss = 0.5781140327453613, train/logprobs = tensor([[-1.1198, -1.6110],
        [-1.5708, -1.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25941702723503113
Epoch 0, Step 2524: train/loss = 0.401653528213501, train/raw-loss = 0.3721330463886261, train/logprobs = tensor([[-0.8423, -2.6934],
        [-1.9672, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952048182487488
Epoch 0, Step 2525: train/loss = 0.843599796295166, train/raw-loss = 0.821129560470581, train/logprobs = tensor([[-1.9658, -2.6638],
        [-1.3166, -1.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247028648853302
Epoch 0, Step 2526: train/loss = 0.3151438236236572, train/raw-loss = 0.28150850534439087, train/logprobs = tensor([[-1.0667, -5.5798],
        [-2.5524, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33635327219963074
Epoch 0, Step 2527: train/loss = 0.47441405057907104, train/raw-loss = 0.442474901676178, train/logprobs = tensor([[-1.7125, -3.4661],
        [-2.8427, -2.6055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31939128041267395
Epoch 0, Step 2528: train/loss = 0.3350313901901245, train/raw-loss = 0.3057062327861786, train/logprobs = tensor([[-1.0130, -3.6581],
        [-1.9298, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29325127601623535
Epoch 0, Step 2529: train/loss = 0.5711172819137573, train/raw-loss = 0.540908694267273, train/logprobs = tensor([[-1.5700, -2.7375],
        [-1.6753, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30208542943000793
Epoch 0, Step 2530: train/loss = 0.33712315559387207, train/raw-loss = 0.3093174993991852, train/logprobs = tensor([[-1.7954, -5.7372],
        [-2.5689, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780567705631256
Epoch 0, Step 2531: train/loss = 0.8569234609603882, train/raw-loss = 0.8247700929641724, train/logprobs = tensor([[-2.9283, -5.0216],
        [-3.4280, -2.4461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215333819389343
Epoch 0, Step 2532: train/loss = 0.5591455698013306, train/raw-loss = 0.5316759347915649, train/logprobs = tensor([[-2.7773, -6.1697],
        [-1.9502, -1.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746964693069458
Epoch 0, Step 2533: train/loss = 0.4376664459705353, train/raw-loss = 0.40991878509521484, train/logprobs = tensor([[-1.7759, -5.1704],
        [-1.6837, -1.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27747660875320435
Epoch 0, Step 2534: train/loss = 0.41920343041419983, train/raw-loss = 0.38433635234832764, train/logprobs = tensor([[-1.2415, -2.3580],
        [-2.9483, -1.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3486705422401428
Epoch 0, Step 2535: train/loss = 0.3779836595058441, train/raw-loss = 0.34202051162719727, train/logprobs = tensor([[-2.3475, -6.9756],
        [-3.7741, -1.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3596314787864685
Epoch 0, Step 2536: train/loss = 0.4785744845867157, train/raw-loss = 0.45226749777793884, train/logprobs = tensor([[-1.5276, -2.8421],
        [-1.6955, -1.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26306983828544617
Epoch 0, Step 2537: train/loss = 0.45669418573379517, train/raw-loss = 0.43283453583717346, train/logprobs = tensor([[-1.0054, -4.0431],
        [-1.4731, -2.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23859666287899017
Epoch 0, Step 2538: train/loss = 0.5559778213500977, train/raw-loss = 0.5282095670700073, train/logprobs = tensor([[-1.4273, -2.6853],
        [-2.1566, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2776833772659302
Epoch 0, Step 2539: train/loss = 0.3270207643508911, train/raw-loss = 0.29220858216285706, train/logprobs = tensor([[-1.5566, -3.3584],
        [-2.6403, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3481217622756958
Epoch 0, Step 2540: train/loss = 0.24701637029647827, train/raw-loss = 0.2173740565776825, train/logprobs = tensor([[-1.3305, -5.8059],
        [-2.0072, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.296423077583313
Epoch 0, Step 2541: train/loss = 0.3126230835914612, train/raw-loss = 0.28654325008392334, train/logprobs = tensor([[-0.8746, -4.8698],
        [-1.8460, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607981562614441
Epoch 0, Step 2542: train/loss = 1.1320875883102417, train/raw-loss = 1.1078459024429321, train/logprobs = tensor([[-3.8528, -4.8437],
        [-1.6793, -1.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424171268939972
Epoch 0, Step 2543: train/loss = 0.2950209081172943, train/raw-loss = 0.26372238993644714, train/logprobs = tensor([[-0.9811, -5.7793],
        [-2.5648, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31298506259918213
Epoch 0, Step 2544: train/loss = 0.48506706953048706, train/raw-loss = 0.45370718836784363, train/logprobs = tensor([[-1.0108, -2.5440],
        [-1.8281, -1.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31359896063804626
Epoch 0, Step 2545: train/loss = 0.31732863187789917, train/raw-loss = 0.2796272039413452, train/logprobs = tensor([[-1.3605, -7.5242],
        [-2.5994, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37701427936553955
Epoch 0, Step 2546: train/loss = 0.4648580253124237, train/raw-loss = 0.4335089325904846, train/logprobs = tensor([[-0.9538, -2.0006],
        [-2.0813, -1.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31349119544029236
Epoch 0, Step 2547: train/loss = 0.5794290900230408, train/raw-loss = 0.5534594655036926, train/logprobs = tensor([[-1.3011, -1.4810],
        [-1.9375, -1.3225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596958577632904
Epoch 0, Step 2548: train/loss = 0.5165347456932068, train/raw-loss = 0.4896458387374878, train/logprobs = tensor([[-1.1032, -2.4374],
        [-1.8374, -1.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26888933777809143
Epoch 0, Step 2549: train/loss = 0.6327255964279175, train/raw-loss = 0.6028934717178345, train/logprobs = tensor([[-1.5835, -2.7790],
        [-1.2248, -1.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2983211576938629
Epoch 0, Step 2550: train/loss = 0.40398645401000977, train/raw-loss = 0.37153321504592896, train/logprobs = tensor([[-1.5131, -2.7094],
        [-2.7196, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3245326280593872
Epoch 0, Step 2551: train/loss = 0.1586916148662567, train/raw-loss = 0.12509188055992126, train/logprobs = tensor([[-1.4560, -9.6137],
        [-2.8950, -1.1894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33599722385406494
Epoch 0, Step 2552: train/loss = 0.538567066192627, train/raw-loss = 0.5144719481468201, train/logprobs = tensor([[-1.5555, -5.0265],
        [-1.2829, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24095162749290466
Epoch 0, Step 2553: train/loss = 0.33888888359069824, train/raw-loss = 0.3073546886444092, train/logprobs = tensor([[-1.0384, -2.5274],
        [-2.6799, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31534188985824585
Epoch 0, Step 2554: train/loss = 0.32484540343284607, train/raw-loss = 0.2963486313819885, train/logprobs = tensor([[-1.6161, -3.8951],
        [-2.6035, -1.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28496766090393066
Epoch 0, Step 2555: train/loss = 0.20791785418987274, train/raw-loss = 0.17772462964057922, train/logprobs = tensor([[-0.7721, -4.4715],
        [-2.2706, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019322156906128
Epoch 0, Step 2556: train/loss = 0.2712462246417999, train/raw-loss = 0.24625587463378906, train/logprobs = tensor([[-1.4169, -5.4687],
        [-1.9268, -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24990332126617432
Epoch 0, Step 2557: train/loss = 0.3259855806827545, train/raw-loss = 0.2929173707962036, train/logprobs = tensor([[-1.6130, -7.8090],
        [-2.5459, -2.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33068186044692993
Epoch 0, Step 2558: train/loss = 0.31674012541770935, train/raw-loss = 0.28332993388175964, train/logprobs = tensor([[-1.1229, -5.9259],
        [-2.1643, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3341016173362732
Epoch 0, Step 2559: train/loss = 0.590787410736084, train/raw-loss = 0.564412534236908, train/logprobs = tensor([[-1.2593, -1.6130],
        [-1.6912, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637490928173065
Epoch 0, Step 2560: train/loss = 0.3634988069534302, train/raw-loss = 0.33129820227622986, train/logprobs = tensor([[-1.7390, -6.7502],
        [-2.8735, -2.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3220059275627136
Epoch 0, Step 2561: train/loss = 0.43060967326164246, train/raw-loss = 0.40244850516319275, train/logprobs = tensor([[-1.2405, -2.2923],
        [-2.4905, -0.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28161150217056274
Epoch 0, Step 2562: train/loss = 0.5659652948379517, train/raw-loss = 0.5383691191673279, train/logprobs = tensor([[-2.2374, -3.0499],
        [-1.7137, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27596157789230347
Epoch 0, Step 2563: train/loss = 0.6057725548744202, train/raw-loss = 0.5706421136856079, train/logprobs = tensor([[-1.3207, -1.7404],
        [-2.6393, -2.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35130494832992554
Epoch 0, Step 2564: train/loss = 0.2700665593147278, train/raw-loss = 0.24050703644752502, train/logprobs = tensor([[-1.6531, -6.3295],
        [-3.2545, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955951392650604
Epoch 0, Step 2565: train/loss = 0.4453861713409424, train/raw-loss = 0.4162445068359375, train/logprobs = tensor([[-2.2462, -4.9979],
        [-1.9438, -1.1507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29141706228256226
Epoch 0, Step 2566: train/loss = 0.4543522000312805, train/raw-loss = 0.42447200417518616, train/logprobs = tensor([[-1.0208, -2.1706],
        [-1.8220, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2988022267818451
Epoch 0, Step 2567: train/loss = 0.5586305856704712, train/raw-loss = 0.5313129425048828, train/logprobs = tensor([[-1.0983, -4.2814],
        [-1.7978, -2.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27317583560943604
Epoch 0, Step 2568: train/loss = 0.5127546787261963, train/raw-loss = 0.48564013838768005, train/logprobs = tensor([[-1.2694, -1.9389],
        [-1.6013, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2711454927921295
Epoch 0, Step 2569: train/loss = 0.660808801651001, train/raw-loss = 0.6340827941894531, train/logprobs = tensor([[-1.7991, -3.2353],
        [-1.7164, -1.4791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26726046204566956
Epoch 0, Step 2570: train/loss = 0.3775596022605896, train/raw-loss = 0.33940768241882324, train/logprobs = tensor([[-1.2408, -8.0522],
        [-3.0677, -2.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3815189301967621
Epoch 0, Step 2571: train/loss = 0.21616357564926147, train/raw-loss = 0.18670091032981873, train/logprobs = tensor([[-1.4047, -5.7457],
        [-2.6593, -1.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2946265935897827
Epoch 0, Step 2572: train/loss = 0.5111548900604248, train/raw-loss = 0.4800366163253784, train/logprobs = tensor([[-1.2024, -4.4611],
        [-3.0610, -1.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3111826777458191
Epoch 0, Step 2573: train/loss = 0.5100238919258118, train/raw-loss = 0.4812803268432617, train/logprobs = tensor([[-1.3251, -2.8242],
        [-2.3232, -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2874358892440796
Epoch 0, Step 2574: train/loss = 0.7718120813369751, train/raw-loss = 0.7380943894386292, train/logprobs = tensor([[-1.4545, -1.7492],
        [-2.3200, -2.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3371770977973938
Epoch 0, Step 2575: train/loss = 0.49934303760528564, train/raw-loss = 0.4644981026649475, train/logprobs = tensor([[-1.7363, -3.3399],
        [-1.9147, -1.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3484492003917694
Epoch 0, Step 2576: train/loss = 0.3359554708003998, train/raw-loss = 0.3052140474319458, train/logprobs = tensor([[-1.2424, -3.8136],
        [-2.3876, -1.7299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30741435289382935
Epoch 0, Step 2577: train/loss = 0.38142120838165283, train/raw-loss = 0.3531525135040283, train/logprobs = tensor([[-1.1414, -4.0025],
        [-2.4003, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2826867997646332
Epoch 0, Step 2578: train/loss = 0.4085339307785034, train/raw-loss = 0.3780338168144226, train/logprobs = tensor([[-1.0417, -4.1133],
        [-2.3225, -1.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305000901222229
Epoch 0, Step 2579: train/loss = 0.34919458627700806, train/raw-loss = 0.3254135549068451, train/logprobs = tensor([[-1.6832, -4.2285],
        [-2.3094, -0.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2378104329109192
Epoch 0, Step 2580: train/loss = 0.431318461894989, train/raw-loss = 0.40108513832092285, train/logprobs = tensor([[-1.3763, -2.7937],
        [-1.9182, -1.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30233338475227356
Epoch 0, Step 2581: train/loss = 0.5056509971618652, train/raw-loss = 0.47443825006484985, train/logprobs = tensor([[-1.5931, -5.5701],
        [-1.5485, -2.5654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31212717294692993
Epoch 0, Step 2582: train/loss = 0.3030269145965576, train/raw-loss = 0.2732085883617401, train/logprobs = tensor([[-0.7882, -4.5822],
        [-1.7144, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29818350076675415
Epoch 0, Step 2583: train/loss = 0.40428340435028076, train/raw-loss = 0.37479305267333984, train/logprobs = tensor([[-2.1484, -4.6959],
        [-2.3735, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29490339756011963
Epoch 0, Step 2584: train/loss = 0.3266143202781677, train/raw-loss = 0.29159095883369446, train/logprobs = tensor([[-1.6411, -4.6984],
        [-3.1223, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502334654331207
Epoch 0, Step 2585: train/loss = 0.5894191265106201, train/raw-loss = 0.5544863343238831, train/logprobs = tensor([[-2.6491, -4.4780],
        [-2.6159, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493281602859497
Epoch 0, Step 2586: train/loss = 0.3532935678958893, train/raw-loss = 0.32067209482192993, train/logprobs = tensor([[-1.4621, -4.6373],
        [-2.1331, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3262145221233368
Epoch 0, Step 2587: train/loss = 0.5098183751106262, train/raw-loss = 0.4826086163520813, train/logprobs = tensor([[-1.4637, -2.8918],
        [-2.1307, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27209728956222534
Epoch 0, Step 2588: train/loss = 0.5363141894340515, train/raw-loss = 0.5090394616127014, train/logprobs = tensor([[-1.6196, -3.0027],
        [-1.9880, -2.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727471888065338
Epoch 0, Step 2589: train/loss = 0.6094948053359985, train/raw-loss = 0.5776285529136658, train/logprobs = tensor([[-3.0655, -7.4962],
        [-2.4022, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3186624050140381
Epoch 0, Step 2590: train/loss = 0.6430762410163879, train/raw-loss = 0.6195775866508484, train/logprobs = tensor([[-0.6086, -0.6958],
        [-1.0560, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23498684167861938
Epoch 0, Step 2591: train/loss = 0.5623675584793091, train/raw-loss = 0.5281204581260681, train/logprobs = tensor([[-1.5062, -2.5384],
        [-1.6206, -1.4460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3424709737300873
Epoch 0, Step 2592: train/loss = 0.3616408705711365, train/raw-loss = 0.3336217701435089, train/logprobs = tensor([[-1.1656, -3.0048],
        [-1.7546, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801908254623413
Epoch 0, Step 2593: train/loss = 0.5937995314598083, train/raw-loss = 0.555303692817688, train/logprobs = tensor([[-1.1309, -4.2336],
        [-3.1041, -2.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3849586248397827
Epoch 0, Step 2594: train/loss = 0.519987940788269, train/raw-loss = 0.4889709949493408, train/logprobs = tensor([[-1.6677, -4.9896],
        [-1.9092, -1.5159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31016990542411804
Epoch 0, Step 2595: train/loss = 0.5435301661491394, train/raw-loss = 0.5161174535751343, train/logprobs = tensor([[-1.2371, -5.9367],
        [-1.1430, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27412667870521545
Epoch 0, Step 2596: train/loss = 0.4839731454849243, train/raw-loss = 0.4584970474243164, train/logprobs = tensor([[-1.0023, -3.2032],
        [-1.3126, -1.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25476109981536865
Epoch 0, Step 2597: train/loss = 0.6152364015579224, train/raw-loss = 0.5856229662895203, train/logprobs = tensor([[-0.9600, -1.6362],
        [-1.5084, -1.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961341440677643
Epoch 0, Step 2598: train/loss = 0.2707452178001404, train/raw-loss = 0.24430830776691437, train/logprobs = tensor([[-1.0493, -6.1685],
        [-1.6835, -0.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643693685531616
Epoch 0, Step 2599: train/loss = 0.5130376219749451, train/raw-loss = 0.48798373341560364, train/logprobs = tensor([[-2.1072, -5.9765],
        [-1.6434, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25053900480270386
Epoch 0, Step 2600: train/loss = 0.5474607348442078, train/raw-loss = 0.5156509280204773, train/logprobs = tensor([[-1.9524, -5.1486],
        [-2.2001, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3180980384349823
Epoch 0, Step 2601: train/loss = 0.4345944821834564, train/raw-loss = 0.4046561121940613, train/logprobs = tensor([[-1.9562, -3.0134],
        [-2.8603, -1.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2993839383125305
Epoch 0, Step 2602: train/loss = 0.334802508354187, train/raw-loss = 0.3012630343437195, train/logprobs = tensor([[-1.4865, -5.9242],
        [-2.4549, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33539485931396484
Epoch 0, Step 2603: train/loss = 0.39562487602233887, train/raw-loss = 0.36910921335220337, train/logprobs = tensor([[-1.7896, -4.8148],
        [-2.6155, -2.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26515665650367737
Epoch 0, Step 2604: train/loss = 0.43600359559059143, train/raw-loss = 0.4006715416908264, train/logprobs = tensor([[-1.5717, -2.8527],
        [-2.0173, -1.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3533205986022949
Epoch 0, Step 2605: train/loss = 0.561976432800293, train/raw-loss = 0.5355048179626465, train/logprobs = tensor([[-1.9260, -3.1828],
        [-1.5666, -0.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2647157609462738
Epoch 0, Step 2606: train/loss = 0.26145830750465393, train/raw-loss = 0.23128163814544678, train/logprobs = tensor([[-1.2347, -3.4577],
        [-3.4435, -0.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30176660418510437
Epoch 0, Step 2607: train/loss = 0.4881882071495056, train/raw-loss = 0.46222007274627686, train/logprobs = tensor([[-0.8322, -5.1477],
        [-1.1507, -1.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2596814036369324
Epoch 0, Step 2608: train/loss = 0.6905861496925354, train/raw-loss = 0.6637157797813416, train/logprobs = tensor([[-2.9485, -6.8274],
        [-2.0511, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687036395072937
Epoch 0, Step 2609: train/loss = 0.46296748518943787, train/raw-loss = 0.43457961082458496, train/logprobs = tensor([[-0.7769, -2.8160],
        [-2.3034, -1.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.283878892660141
Epoch 0, Step 2610: train/loss = 0.35804301500320435, train/raw-loss = 0.32459914684295654, train/logprobs = tensor([[-1.0832, -6.3006],
        [-2.9542, -1.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33443862199783325
Epoch 0, Step 2611: train/loss = 0.4011426568031311, train/raw-loss = 0.3700252175331116, train/logprobs = tensor([[-1.0017, -3.0961],
        [-1.7489, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31117433309555054
Epoch 0, Step 2612: train/loss = 0.5524585843086243, train/raw-loss = 0.5219820141792297, train/logprobs = tensor([[-1.6676, -7.0573],
        [-2.0507, -2.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30476585030555725
Epoch 0, Step 2613: train/loss = 0.4811239242553711, train/raw-loss = 0.4524582028388977, train/logprobs = tensor([[-2.3091, -5.0639],
        [-1.9545, -1.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866571247577667
Epoch 0, Step 2614: train/loss = 0.3700096607208252, train/raw-loss = 0.33598411083221436, train/logprobs = tensor([[-1.0853, -7.9583],
        [-2.6227, -1.5859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34025534987449646
Epoch 0, Step 2615: train/loss = 0.34260115027427673, train/raw-loss = 0.3109665513038635, train/logprobs = tensor([[-2.1562, -5.5960],
        [-2.8209, -1.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3163459897041321
Epoch 0, Step 2616: train/loss = 0.4843434691429138, train/raw-loss = 0.45600321888923645, train/logprobs = tensor([[-1.5326, -3.7063],
        [-1.8548, -1.6396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2834027111530304
Epoch 0, Step 2617: train/loss = 0.5815061926841736, train/raw-loss = 0.5582291483879089, train/logprobs = tensor([[-2.0093, -3.8351],
        [-1.3558, -0.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2327696979045868
Epoch 0, Step 2618: train/loss = 0.4679528772830963, train/raw-loss = 0.4405297338962555, train/logprobs = tensor([[-1.3515, -3.2966],
        [-1.9630, -0.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2742311954498291
Epoch 0, Step 2619: train/loss = 0.5254696607589722, train/raw-loss = 0.4977530241012573, train/logprobs = tensor([[-0.9734, -6.4416],
        [-2.2473, -1.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27716657519340515
Epoch 0, Step 2620: train/loss = 0.4701422154903412, train/raw-loss = 0.4433310925960541, train/logprobs = tensor([[-1.8969, -3.9131],
        [-1.9692, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26811090111732483
Epoch 0, Step 2621: train/loss = 0.33363452553749084, train/raw-loss = 0.30757978558540344, train/logprobs = tensor([[-1.0491, -3.1128],
        [-1.5717, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605474889278412
Epoch 0, Step 2622: train/loss = 0.6880621910095215, train/raw-loss = 0.662691593170166, train/logprobs = tensor([[-1.8731, -1.8878],
        [-1.4162, -0.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2537059187889099
Epoch 0, Step 2623: train/loss = 0.3432537913322449, train/raw-loss = 0.3185402452945709, train/logprobs = tensor([[-1.2268, -4.5467],
        [-2.1729, -0.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24713534116744995
Epoch 0, Step 2624: train/loss = 0.7333622574806213, train/raw-loss = 0.7059713006019592, train/logprobs = tensor([[-1.5154, -1.7915],
        [-1.4924, -1.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739097476005554
Epoch 0, Step 2625: train/loss = 0.37991073727607727, train/raw-loss = 0.3526236414909363, train/logprobs = tensor([[-1.2709, -3.6284],
        [-2.0123, -1.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2728709578514099
Epoch 0, Step 2626: train/loss = 0.6291921734809875, train/raw-loss = 0.6076257824897766, train/logprobs = tensor([[-1.7624, -4.4438],
        [-1.4332, -1.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21566350758075714
Epoch 0, Step 2627: train/loss = 0.2446439564228058, train/raw-loss = 0.21675324440002441, train/logprobs = tensor([[-1.1313, -4.9742],
        [-2.4493, -0.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27890700101852417
Epoch 0, Step 2628: train/loss = 0.4831109642982483, train/raw-loss = 0.44823092222213745, train/logprobs = tensor([[-2.0867, -3.9488],
        [-3.1392, -1.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3488004803657532
Epoch 0, Step 2629: train/loss = 0.33451521396636963, train/raw-loss = 0.30406659841537476, train/logprobs = tensor([[-1.1635, -5.9012],
        [-2.6175, -1.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30448582768440247
Epoch 0, Step 2630: train/loss = 0.6001869440078735, train/raw-loss = 0.5685654282569885, train/logprobs = tensor([[-1.8808, -2.9200],
        [-2.0582, -1.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3162152171134949
Epoch 0, Step 2631: train/loss = 0.29693958163261414, train/raw-loss = 0.2646896541118622, train/logprobs = tensor([[-1.3385, -6.7304],
        [-2.6190, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3224990665912628
Epoch 0, Step 2632: train/loss = 0.5389873385429382, train/raw-loss = 0.5054324865341187, train/logprobs = tensor([[-1.0412, -3.1260],
        [-2.5131, -1.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3355487883090973
Epoch 0, Step 2633: train/loss = 0.32091325521469116, train/raw-loss = 0.2888355851173401, train/logprobs = tensor([[-1.4179, -2.7250],
        [-2.9830, -0.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32077687978744507
Epoch 0, Step 2634: train/loss = 0.6114239692687988, train/raw-loss = 0.5843410491943359, train/logprobs = tensor([[-1.3718, -3.0570],
        [-1.2405, -0.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27082955837249756
Epoch 0, Step 2635: train/loss = 0.34300780296325684, train/raw-loss = 0.31052353978157043, train/logprobs = tensor([[-1.5262, -4.5828],
        [-2.6214, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3248424530029297
Epoch 0, Step 2636: train/loss = 0.5094097852706909, train/raw-loss = 0.48514416813850403, train/logprobs = tensor([[-0.7765, -3.6956],
        [-1.3369, -1.4043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24265632033348083
Epoch 0, Step 2637: train/loss = 0.1290939748287201, train/raw-loss = 0.09236841648817062, train/logprobs = tensor([[-1.3150, -4.8562],
        [-3.5769, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36725565791130066
Epoch 0, Step 2638: train/loss = 0.7673014998435974, train/raw-loss = 0.7426731586456299, train/logprobs = tensor([[-0.6813, -0.9587],
        [-1.0324, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24628350138664246
Epoch 0, Step 2639: train/loss = 0.5241267681121826, train/raw-loss = 0.4953608810901642, train/logprobs = tensor([[-0.6890, -1.9809],
        [-1.7963, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2876594662666321
Epoch 0, Step 2640: train/loss = 0.43359822034835815, train/raw-loss = 0.3975867033004761, train/logprobs = tensor([[-1.7091, -3.8211],
        [-2.1629, -1.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601149320602417
Epoch 0, Step 2641: train/loss = 0.3460996747016907, train/raw-loss = 0.3115161955356598, train/logprobs = tensor([[-1.5236, -4.0169],
        [-2.5366, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34583500027656555
Epoch 0, Step 2642: train/loss = 0.5191508531570435, train/raw-loss = 0.49265724420547485, train/logprobs = tensor([[-1.7277, -6.9743],
        [-1.6913, -1.8021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26493602991104126
Epoch 0, Step 2643: train/loss = 0.3338615596294403, train/raw-loss = 0.3060649633407593, train/logprobs = tensor([[-1.3110, -4.1027],
        [-2.6027, -0.5388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779659628868103
Epoch 0, Step 2644: train/loss = 0.7134602069854736, train/raw-loss = 0.6883931756019592, train/logprobs = tensor([[-1.4178, -1.4943],
        [-1.5296, -1.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250669926404953
Epoch 0, Step 2645: train/loss = 0.2753925323486328, train/raw-loss = 0.24451307952404022, train/logprobs = tensor([[-1.3965, -4.8807],
        [-2.5349, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3087944984436035
Epoch 0, Step 2646: train/loss = 0.47068020701408386, train/raw-loss = 0.4368113875389099, train/logprobs = tensor([[-1.5172, -6.3094],
        [-2.4954, -1.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3386879861354828
Epoch 0, Step 2647: train/loss = 0.3042159974575043, train/raw-loss = 0.2723434567451477, train/logprobs = tensor([[-1.3268, -8.7721],
        [-2.1388, -1.4493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31872525811195374
Epoch 0, Step 2648: train/loss = 0.4904520511627197, train/raw-loss = 0.4576166868209839, train/logprobs = tensor([[-1.2490, -5.8223],
        [-1.9644, -1.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32835352420806885
Epoch 0, Step 2649: train/loss = 0.576653242111206, train/raw-loss = 0.5487116575241089, train/logprobs = tensor([[-1.2246, -2.6030],
        [-1.5093, -1.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27941614389419556
Epoch 0, Step 2650: train/loss = 0.4227471351623535, train/raw-loss = 0.3925916254520416, train/logprobs = tensor([[-1.9521, -5.0800],
        [-2.3088, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015553951263428
Epoch 0, Step 2651: train/loss = 0.2852039337158203, train/raw-loss = 0.25207382440567017, train/logprobs = tensor([[-1.4663, -4.1883],
        [-3.1969, -1.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3313009738922119
Epoch 0, Step 2652: train/loss = 0.2530182898044586, train/raw-loss = 0.22289156913757324, train/logprobs = tensor([[-0.9771, -6.3195],
        [-2.0848, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012672960758209
Epoch 0, Step 2653: train/loss = 0.6260457038879395, train/raw-loss = 0.5927448868751526, train/logprobs = tensor([[-1.3358, -2.7181],
        [-2.1010, -1.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33300819993019104
Epoch 0, Step 2654: train/loss = 0.4784131646156311, train/raw-loss = 0.4493051767349243, train/logprobs = tensor([[-1.4778, -3.4544],
        [-1.9329, -1.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29107987880706787
Epoch 0, Step 2655: train/loss = 0.399633526802063, train/raw-loss = 0.3736349940299988, train/logprobs = tensor([[-1.3393, -3.0873],
        [-1.7561, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599852383136749
Epoch 0, Step 2656: train/loss = 0.46013009548187256, train/raw-loss = 0.4295722246170044, train/logprobs = tensor([[-1.6281, -3.1695],
        [-2.9022, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30557870864868164
Epoch 0, Step 2657: train/loss = 0.5810407400131226, train/raw-loss = 0.5555098652839661, train/logprobs = tensor([[-1.4574, -2.6805],
        [-1.4386, -1.4974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25530871748924255
Epoch 0, Step 2658: train/loss = 0.5156393647193909, train/raw-loss = 0.4864863455295563, train/logprobs = tensor([[-1.4372, -2.6029],
        [-1.3880, -0.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29153019189834595
Epoch 0, Step 2659: train/loss = 0.42110157012939453, train/raw-loss = 0.39280226826667786, train/logprobs = tensor([[-0.9375, -3.3117],
        [-1.7680, -0.7799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2829928398132324
Epoch 0, Step 2660: train/loss = 0.32373568415641785, train/raw-loss = 0.29868221282958984, train/logprobs = tensor([[-1.0098, -3.7507],
        [-2.0696, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505347430706024
Epoch 0, Step 2661: train/loss = 0.47511446475982666, train/raw-loss = 0.43660974502563477, train/logprobs = tensor([[-1.6692, -3.8823],
        [-2.8169, -1.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850473463535309
Epoch 0, Step 2662: train/loss = 0.22662438452243805, train/raw-loss = 0.1974557638168335, train/logprobs = tensor([[-1.1090, -5.4239],
        [-2.4926, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2916859984397888
Epoch 0, Step 2663: train/loss = 0.2744666337966919, train/raw-loss = 0.2461845874786377, train/logprobs = tensor([[-1.9163, -5.8512],
        [-2.8317, -2.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28282052278518677
Epoch 0, Step 2664: train/loss = 0.3138856589794159, train/raw-loss = 0.28302106261253357, train/logprobs = tensor([[-1.9377, -5.5781],
        [-3.0559, -2.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086461126804352
Epoch 0, Step 2665: train/loss = 0.4057586193084717, train/raw-loss = 0.3819487392902374, train/logprobs = tensor([[-1.3326, -3.8837],
        [-1.8827, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380983829498291
Epoch 0, Step 2666: train/loss = 0.3325977623462677, train/raw-loss = 0.3014849126338959, train/logprobs = tensor([[-1.4946, -4.3060],
        [-2.3583, -1.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31112855672836304
Epoch 0, Step 2667: train/loss = 0.2182195782661438, train/raw-loss = 0.1822936236858368, train/logprobs = tensor([[-1.5124, -6.3615],
        [-3.4562, -1.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592597246170044
Epoch 0, Step 2668: train/loss = 0.500304102897644, train/raw-loss = 0.4699760675430298, train/logprobs = tensor([[-1.3288, -3.0627],
        [-2.2058, -1.3200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30328047275543213
Epoch 0, Step 2669: train/loss = 0.295705109834671, train/raw-loss = 0.2713209390640259, train/logprobs = tensor([[-1.0113, -7.3831],
        [-1.9661, -2.6061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24384191632270813
Epoch 0, Step 2670: train/loss = 0.6725524663925171, train/raw-loss = 0.6414608359336853, train/logprobs = tensor([[-2.1606, -2.6268],
        [-1.9379, -1.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3109167218208313
Epoch 0, Step 2671: train/loss = 0.3893035352230072, train/raw-loss = 0.3595588207244873, train/logprobs = tensor([[-1.1075, -3.6553],
        [-2.3698, -1.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29744693636894226
Epoch 0, Step 2672: train/loss = 0.3921468257904053, train/raw-loss = 0.3695809245109558, train/logprobs = tensor([[-1.0540, -3.8170],
        [-1.1515, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22565919160842896
Epoch 0, Step 2673: train/loss = 0.46628692746162415, train/raw-loss = 0.4373161792755127, train/logprobs = tensor([[-0.8952, -2.3310],
        [-2.0965, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28970715403556824
Epoch 0, Step 2674: train/loss = 0.37985730171203613, train/raw-loss = 0.3525860011577606, train/logprobs = tensor([[-1.6134, -5.6533],
        [-2.1412, -1.3635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2727130651473999
Epoch 0, Step 2675: train/loss = 0.3914288580417633, train/raw-loss = 0.3634295165538788, train/logprobs = tensor([[-1.0770, -2.8918],
        [-1.9674, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27999347448349
Epoch 0, Step 2676: train/loss = 0.3822650909423828, train/raw-loss = 0.34887638688087463, train/logprobs = tensor([[-0.9730, -2.9398],
        [-2.3284, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33388715982437134
Epoch 0, Step 2677: train/loss = 0.4258468747138977, train/raw-loss = 0.3981171250343323, train/logprobs = tensor([[-1.4199, -3.2832],
        [-2.6995, -0.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27729761600494385
Epoch 0, Step 2678: train/loss = 0.5434703826904297, train/raw-loss = 0.5132632851600647, train/logprobs = tensor([[-1.2362, -1.4684],
        [-2.6665, -1.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.302070677280426
Epoch 0, Step 2679: train/loss = 0.3524128198623657, train/raw-loss = 0.3208303153514862, train/logprobs = tensor([[-1.1048, -3.7207],
        [-2.4637, -2.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31582534313201904
Epoch 0, Step 2680: train/loss = 0.6761385202407837, train/raw-loss = 0.651235818862915, train/logprobs = tensor([[-2.2506, -6.8979],
        [-1.6536, -1.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24902695417404175
Epoch 0, Step 2681: train/loss = 0.19374577701091766, train/raw-loss = 0.15932872891426086, train/logprobs = tensor([[-1.8892, -8.8365],
        [-3.0390, -1.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.344170480966568
Epoch 0, Step 2682: train/loss = 0.8379374742507935, train/raw-loss = 0.8085757493972778, train/logprobs = tensor([[-2.7147, -4.3308],
        [-2.1392, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2936170697212219
Epoch 0, Step 2683: train/loss = 0.40509381890296936, train/raw-loss = 0.3776436150074005, train/logprobs = tensor([[-1.0955, -3.3210],
        [-1.7934, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27450188994407654
Epoch 0, Step 2684: train/loss = 0.6335979700088501, train/raw-loss = 0.6005939245223999, train/logprobs = tensor([[-1.2182, -2.1301],
        [-1.6358, -2.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33004099130630493
Epoch 0, Step 2685: train/loss = 0.49036598205566406, train/raw-loss = 0.46203529834747314, train/logprobs = tensor([[-0.9649, -2.1496],
        [-1.4236, -1.3951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833067774772644
Epoch 0, Step 2686: train/loss = 0.6645845770835876, train/raw-loss = 0.6271319389343262, train/logprobs = tensor([[-3.9600, -5.6182],
        [-2.6327, -1.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37452614307403564
Epoch 0, Step 2687: train/loss = 0.50557541847229, train/raw-loss = 0.47436994314193726, train/logprobs = tensor([[-2.0555, -5.0495],
        [-2.1481, -2.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31205442547798157
Epoch 0, Step 2688: train/loss = 0.2945627272129059, train/raw-loss = 0.2665922939777374, train/logprobs = tensor([[-1.8833, -6.1077],
        [-2.2017, -0.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27970418334007263
Epoch 0, Step 2689: train/loss = 0.4543026089668274, train/raw-loss = 0.4230751395225525, train/logprobs = tensor([[-1.2400, -2.8457],
        [-2.0433, -1.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3122747540473938
Epoch 0, Step 2690: train/loss = 0.4407005310058594, train/raw-loss = 0.4177775979042053, train/logprobs = tensor([[-1.5959, -7.2574],
        [-1.3123, -1.6983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22922910749912262
Epoch 0, Step 2691: train/loss = 0.5088918805122375, train/raw-loss = 0.47516733407974243, train/logprobs = tensor([[-1.4636, -2.6392],
        [-2.2478, -1.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33724528551101685
Epoch 0, Step 2692: train/loss = 0.25175225734710693, train/raw-loss = 0.22131921350955963, train/logprobs = tensor([[-0.9734, -5.6905],
        [-2.5490, -0.7798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30433040857315063
Epoch 0, Step 2693: train/loss = 0.6355171799659729, train/raw-loss = 0.6058869957923889, train/logprobs = tensor([[-1.2361, -1.4808],
        [-1.7329, -1.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2963016927242279
Epoch 0, Step 2694: train/loss = 0.3590419888496399, train/raw-loss = 0.3346378207206726, train/logprobs = tensor([[-0.8510, -2.5871],
        [-1.6778, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24404191970825195
Epoch 0, Step 2695: train/loss = 0.6041731834411621, train/raw-loss = 0.572071373462677, train/logprobs = tensor([[-1.8368, -3.1064],
        [-1.9820, -1.3441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210183084011078
Epoch 0, Step 2696: train/loss = 0.37093713879585266, train/raw-loss = 0.3412371277809143, train/logprobs = tensor([[-0.9417, -4.2355],
        [-2.5285, -1.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29700034856796265
Epoch 0, Step 2697: train/loss = 0.4215303957462311, train/raw-loss = 0.3954787254333496, train/logprobs = tensor([[-1.1275, -4.1825],
        [-2.1687, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605166733264923
Epoch 0, Step 2698: train/loss = 0.2773019075393677, train/raw-loss = 0.2491830736398697, train/logprobs = tensor([[-1.1356, -4.1535],
        [-2.7008, -1.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28118833899497986
Epoch 0, Step 2699: train/loss = 0.31367555260658264, train/raw-loss = 0.27749043703079224, train/logprobs = tensor([[-1.0196, -3.7465],
        [-2.8487, -1.1678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36185094714164734
Epoch 0, Step 2700: train/loss = 0.6993569135665894, train/raw-loss = 0.6730141043663025, train/logprobs = tensor([[-1.6054, -2.1781],
        [-1.3480, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.263428270816803
Epoch 0, Step 2701: train/loss = 0.42317891120910645, train/raw-loss = 0.40057486295700073, train/logprobs = tensor([[-1.4707, -3.3290],
        [-1.8375, -0.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22604039311408997
Epoch 0, Step 2702: train/loss = 0.2500467002391815, train/raw-loss = 0.2176200896501541, train/logprobs = tensor([[-1.2263, -7.1482],
        [-3.1698, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32426610589027405
Epoch 0, Step 2703: train/loss = 0.19928956031799316, train/raw-loss = 0.1687530279159546, train/logprobs = tensor([[-1.1639, -5.2253],
        [-2.3276, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053652346134186
Epoch 0, Step 2704: train/loss = 0.30086708068847656, train/raw-loss = 0.26655006408691406, train/logprobs = tensor([[-1.0835, -4.2199],
        [-2.5575, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.343170166015625
Epoch 0, Step 2705: train/loss = 0.6376749277114868, train/raw-loss = 0.6034619808197021, train/logprobs = tensor([[-1.2120, -2.0403],
        [-2.3080, -2.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34212949872016907
Epoch 0, Step 2706: train/loss = 0.3875032961368561, train/raw-loss = 0.3538261651992798, train/logprobs = tensor([[-1.8456, -8.7455],
        [-2.8863, -1.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3367709517478943
Epoch 0, Step 2707: train/loss = 0.6818366050720215, train/raw-loss = 0.6519283652305603, train/logprobs = tensor([[-1.7465, -2.1130],
        [-2.1315, -1.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29908233880996704
Epoch 0, Step 2708: train/loss = 0.6261870265007019, train/raw-loss = 0.5989673137664795, train/logprobs = tensor([[-1.9068, -2.4790],
        [-1.3657, -1.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2721971273422241
Epoch 0, Step 2709: train/loss = 0.5056284666061401, train/raw-loss = 0.48168325424194336, train/logprobs = tensor([[-0.9821, -3.1616],
        [-1.2740, -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2394523024559021
Epoch 0, Step 2710: train/loss = 0.5233139991760254, train/raw-loss = 0.4949963688850403, train/logprobs = tensor([[-1.2393, -2.9896],
        [-1.8616, -1.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28317636251449585
Epoch 0, Step 2711: train/loss = 0.35660380125045776, train/raw-loss = 0.32618218660354614, train/logprobs = tensor([[-2.0027, -5.2874],
        [-2.4134, -0.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3042161762714386
Epoch 0, Step 2712: train/loss = 0.5101332068443298, train/raw-loss = 0.47706764936447144, train/logprobs = tensor([[-1.5782, -3.8019],
        [-1.9633, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306555151939392
Epoch 0, Step 2713: train/loss = 0.44941219687461853, train/raw-loss = 0.42039215564727783, train/logprobs = tensor([[-1.2812, -3.6513],
        [-2.5016, -2.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902003526687622
Epoch 0, Step 2714: train/loss = 0.30741703510284424, train/raw-loss = 0.2811264395713806, train/logprobs = tensor([[-0.9757, -5.2558],
        [-2.8256, -1.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26290565729141235
Epoch 0, Step 2715: train/loss = 0.4229094386100769, train/raw-loss = 0.39829692244529724, train/logprobs = tensor([[-2.0221, -4.5738],
        [-2.1911, -1.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24612495303153992
Epoch 0, Step 2716: train/loss = 0.4191468060016632, train/raw-loss = 0.389716774225235, train/logprobs = tensor([[-1.8033, -4.4222],
        [-2.9710, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943004369735718
Epoch 0, Step 2717: train/loss = 0.3614395260810852, train/raw-loss = 0.32428643107414246, train/logprobs = tensor([[-1.5999, -5.1702],
        [-3.2170, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3715308904647827
Epoch 0, Step 2718: train/loss = 0.390610933303833, train/raw-loss = 0.3581719994544983, train/logprobs = tensor([[-1.6412, -3.9675],
        [-2.6022, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32438966631889343
Epoch 0, Step 2719: train/loss = 0.2951631546020508, train/raw-loss = 0.2715475559234619, train/logprobs = tensor([[-1.4883, -7.1109],
        [-1.7718, -2.0476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2361559271812439
Epoch 0, Step 2720: train/loss = 0.49121224880218506, train/raw-loss = 0.46612250804901123, train/logprobs = tensor([[-0.7917, -3.0408],
        [-1.6557, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508978545665741
Epoch 0, Step 2721: train/loss = 0.4649619162082672, train/raw-loss = 0.4357054829597473, train/logprobs = tensor([[-1.0407, -3.2292],
        [-1.4422, -1.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2925640046596527
Epoch 0, Step 2722: train/loss = 0.27532610297203064, train/raw-loss = 0.24756549298763275, train/logprobs = tensor([[-1.3579, -8.4483],
        [-2.2152, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2776060700416565
Epoch 0, Step 2723: train/loss = 0.480521023273468, train/raw-loss = 0.45274391770362854, train/logprobs = tensor([[-0.8613, -2.8113],
        [-1.6288, -1.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2777707576751709
Epoch 0, Step 2724: train/loss = 0.5810151696205139, train/raw-loss = 0.5504320859909058, train/logprobs = tensor([[-1.1732, -2.2768],
        [-2.0749, -2.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30583056807518005
Epoch 0, Step 2725: train/loss = 0.4729900062084198, train/raw-loss = 0.4418752193450928, train/logprobs = tensor([[-1.2821, -1.7113],
        [-2.3922, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31114766001701355
Epoch 0, Step 2726: train/loss = 0.4776113033294678, train/raw-loss = 0.4471573233604431, train/logprobs = tensor([[-1.1287, -1.9748],
        [-2.5161, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3045397102832794
Epoch 0, Step 2727: train/loss = 0.4186784625053406, train/raw-loss = 0.39501240849494934, train/logprobs = tensor([[-1.0898, -3.2883],
        [-2.4790, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23666085302829742
Epoch 0, Step 2728: train/loss = 0.3646602928638458, train/raw-loss = 0.3405299186706543, train/logprobs = tensor([[-1.6836, -4.4618],
        [-2.4644, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24130389094352722
Epoch 0, Step 2729: train/loss = 0.6030092835426331, train/raw-loss = 0.5735101699829102, train/logprobs = tensor([[-1.5016, -2.4685],
        [-1.8182, -1.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29499122500419617
Epoch 0, Step 2730: train/loss = 0.2411450296640396, train/raw-loss = 0.20791710913181305, train/logprobs = tensor([[-1.2679, -7.6711],
        [-2.0073, -2.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322792649269104
Epoch 0, Step 2731: train/loss = 0.5974929928779602, train/raw-loss = 0.5709875822067261, train/logprobs = tensor([[-1.2643, -2.7419],
        [-1.3986, -1.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2650544047355652
Epoch 0, Step 2732: train/loss = 0.43179887533187866, train/raw-loss = 0.4043892025947571, train/logprobs = tensor([[-1.6976, -3.3352],
        [-1.8681, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740965485572815
Epoch 0, Step 2733: train/loss = 0.39010998606681824, train/raw-loss = 0.35700270533561707, train/logprobs = tensor([[-1.2435, -1.9817],
        [-3.1211, -1.4521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3310728073120117
Epoch 0, Step 2734: train/loss = 0.5709274411201477, train/raw-loss = 0.5420632362365723, train/logprobs = tensor([[-1.3726, -3.1820],
        [-1.6798, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28864210844039917
Epoch 0, Step 2735: train/loss = 0.4927228093147278, train/raw-loss = 0.46654289960861206, train/logprobs = tensor([[-2.1776, -6.1524],
        [-2.1984, -1.3335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2617990970611572
Epoch 0, Step 2736: train/loss = 0.4451998472213745, train/raw-loss = 0.4116297960281372, train/logprobs = tensor([[-1.0487, -3.4381],
        [-2.7335, -1.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3357005715370178
Epoch 0, Step 2737: train/loss = 0.3296729326248169, train/raw-loss = 0.3018706440925598, train/logprobs = tensor([[-1.6541, -5.8758],
        [-2.3508, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780229151248932
Epoch 0, Step 2738: train/loss = 0.5331195592880249, train/raw-loss = 0.5113779306411743, train/logprobs = tensor([[-1.3776, -4.4031],
        [-1.6539, -0.7727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21741612255573273
Epoch 0, Step 2739: train/loss = 0.37255653738975525, train/raw-loss = 0.3473989963531494, train/logprobs = tensor([[-1.2377, -4.1565],
        [-1.7265, -1.2327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25157541036605835
Epoch 0, Step 2740: train/loss = 0.4353490471839905, train/raw-loss = 0.40067845582962036, train/logprobs = tensor([[-0.9590, -4.0106],
        [-2.2260, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3467061221599579
Epoch 0, Step 2741: train/loss = 0.26879096031188965, train/raw-loss = 0.23784494400024414, train/logprobs = tensor([[-1.6278, -5.0355],
        [-2.8701, -1.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30945998430252075
Epoch 0, Step 2742: train/loss = 0.3869134187698364, train/raw-loss = 0.3583994507789612, train/logprobs = tensor([[-1.3572, -3.2486],
        [-2.0055, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851395308971405
Epoch 0, Step 2743: train/loss = 0.5889981985092163, train/raw-loss = 0.5612062215805054, train/logprobs = tensor([[-1.2090, -3.5925],
        [-1.5852, -1.3173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27791932225227356
Epoch 0, Step 2744: train/loss = 0.5718318223953247, train/raw-loss = 0.5393182635307312, train/logprobs = tensor([[-0.9557, -2.1811],
        [-2.0640, -1.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3251357078552246
Epoch 0, Step 2745: train/loss = 0.21654316782951355, train/raw-loss = 0.18118175864219666, train/logprobs = tensor([[-1.2758, -4.0132],
        [-3.5420, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35361406207084656
Epoch 0, Step 2746: train/loss = 0.32978561520576477, train/raw-loss = 0.3039376437664032, train/logprobs = tensor([[-1.1593, -3.9502],
        [-2.6852, -1.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2584797143936157
Epoch 0, Step 2747: train/loss = 0.5769779682159424, train/raw-loss = 0.5492841005325317, train/logprobs = tensor([[-1.4389, -2.3670],
        [-1.7349, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27693864703178406
Epoch 0, Step 2748: train/loss = 0.5594834685325623, train/raw-loss = 0.5338014364242554, train/logprobs = tensor([[-2.0210, -6.0137],
        [-1.9348, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256820410490036
Epoch 0, Step 2749: train/loss = 0.5092176198959351, train/raw-loss = 0.4783221483230591, train/logprobs = tensor([[-1.1981, -2.6495],
        [-1.7880, -1.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30895480513572693
Epoch 0, Step 2750: train/loss = 0.5858312845230103, train/raw-loss = 0.555867612361908, train/logprobs = tensor([[-2.5828, -4.0360],
        [-1.7864, -1.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2996366024017334
Epoch 0, Step 2751: train/loss = 0.5224154591560364, train/raw-loss = 0.4945030212402344, train/logprobs = tensor([[-0.8287, -1.4699],
        [-1.7233, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27912482619285583
Epoch 0, Step 2752: train/loss = 0.3189679980278015, train/raw-loss = 0.2894650101661682, train/logprobs = tensor([[-0.9539, -9.8843],
        [-2.0694, -2.9101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29502958059310913
Epoch 0, Step 2753: train/loss = 0.2676846981048584, train/raw-loss = 0.23735621571540833, train/logprobs = tensor([[-0.9578, -2.9217],
        [-2.5835, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30328482389450073
Epoch 0, Step 2754: train/loss = 0.22850054502487183, train/raw-loss = 0.198480024933815, train/logprobs = tensor([[-1.4538, -8.0043],
        [-3.7035, -2.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002052307128906
Epoch 0, Step 2755: train/loss = 0.604494035243988, train/raw-loss = 0.5815737843513489, train/logprobs = tensor([[-0.9565, -2.0807],
        [-1.2422, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22920212149620056
Epoch 0, Step 2756: train/loss = 0.5548752546310425, train/raw-loss = 0.5252625346183777, train/logprobs = tensor([[-1.0783, -2.5484],
        [-1.7055, -1.3582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2961273193359375
Epoch 0, Step 2757: train/loss = 0.3974878191947937, train/raw-loss = 0.3686935305595398, train/logprobs = tensor([[-1.2939, -4.7399],
        [-1.9241, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879428565502167
Epoch 0, Step 2758: train/loss = 0.27414625883102417, train/raw-loss = 0.24590076506137848, train/logprobs = tensor([[-1.0411, -5.7625],
        [-1.9427, -1.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28245484828948975
Epoch 0, Step 2759: train/loss = 0.2852214574813843, train/raw-loss = 0.2540905475616455, train/logprobs = tensor([[-1.4752, -5.1150],
        [-2.8836, -1.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31130897998809814
Epoch 0, Step 2760: train/loss = 0.30936765670776367, train/raw-loss = 0.27955567836761475, train/logprobs = tensor([[-1.7115, -5.9530],
        [-2.6140, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2981198728084564
Epoch 0, Step 2761: train/loss = 0.43163174390792847, train/raw-loss = 0.40339595079421997, train/logprobs = tensor([[-1.3730, -3.4251],
        [-1.7622, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2823580801486969
Epoch 0, Step 2762: train/loss = 0.3351110816001892, train/raw-loss = 0.3095800578594208, train/logprobs = tensor([[-1.1581, -3.9856],
        [-2.4163, -1.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553102374076843
Epoch 0, Step 2763: train/loss = 0.259712815284729, train/raw-loss = 0.23492436110973358, train/logprobs = tensor([[-1.0376, -7.9313],
        [-2.4783, -2.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24788427352905273
Epoch 0, Step 2764: train/loss = 0.3855632543563843, train/raw-loss = 0.35482457280158997, train/logprobs = tensor([[-0.8031, -4.1025],
        [-1.7235, -1.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073868751525879
Epoch 0, Step 2765: train/loss = 0.431613564491272, train/raw-loss = 0.40067964792251587, train/logprobs = tensor([[-0.9778, -3.1082],
        [-3.2627, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3093392848968506
Epoch 0, Step 2766: train/loss = 0.5612990856170654, train/raw-loss = 0.5350678563117981, train/logprobs = tensor([[-1.6928, -3.3535],
        [-1.2155, -0.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623125910758972
Epoch 0, Step 2767: train/loss = 0.5631086230278015, train/raw-loss = 0.5407328605651855, train/logprobs = tensor([[-1.3751, -3.9040],
        [-1.3326, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22375711798667908
Epoch 0, Step 2768: train/loss = 0.700037956237793, train/raw-loss = 0.6732668280601501, train/logprobs = tensor([[-2.7298, -4.4723],
        [-1.6224, -2.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26771193742752075
Epoch 0, Step 2769: train/loss = 0.4195155203342438, train/raw-loss = 0.38787761330604553, train/logprobs = tensor([[-1.0783, -3.0722],
        [-1.8837, -1.2826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31637945771217346
Epoch 0, Step 2770: train/loss = 0.7951149344444275, train/raw-loss = 0.7622045874595642, train/logprobs = tensor([[-2.9041, -4.8764],
        [-2.5323, -2.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291036784648895
Epoch 0, Step 2771: train/loss = 0.41408053040504456, train/raw-loss = 0.38561514019966125, train/logprobs = tensor([[-2.0394, -4.8206],
        [-2.2319, -2.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846541106700897
Epoch 0, Step 2772: train/loss = 0.3376370668411255, train/raw-loss = 0.3061262369155884, train/logprobs = tensor([[-1.3675, -4.0213],
        [-2.4871, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3151082992553711
Epoch 0, Step 2773: train/loss = 0.36668121814727783, train/raw-loss = 0.3395288586616516, train/logprobs = tensor([[-0.9978, -5.0798],
        [-1.8706, -2.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27152374386787415
Epoch 0, Step 2774: train/loss = 0.33374664187431335, train/raw-loss = 0.3007652759552002, train/logprobs = tensor([[-1.5993, -4.4979],
        [-3.2106, -1.5977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32981374859809875
Epoch 0, Step 2775: train/loss = 0.5832527875900269, train/raw-loss = 0.5579943656921387, train/logprobs = tensor([[-2.2351, -4.1889],
        [-1.7391, -1.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25258365273475647
Epoch 0, Step 2776: train/loss = 0.0806514099240303, train/raw-loss = 0.042387351393699646, train/logprobs = tensor([[-1.7673, -6.7784],
        [-4.5643, -0.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38264065980911255
Epoch 0, Step 2777: train/loss = 0.5142084956169128, train/raw-loss = 0.48481249809265137, train/logprobs = tensor([[-1.0306, -1.8293],
        [-2.2194, -1.5380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2939600944519043
Epoch 0, Step 2778: train/loss = 0.37727805972099304, train/raw-loss = 0.34202471375465393, train/logprobs = tensor([[-1.9414, -4.3885],
        [-3.0099, -1.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35253357887268066
Epoch 0, Step 2779: train/loss = 0.26227253675460815, train/raw-loss = 0.2319260686635971, train/logprobs = tensor([[-1.1221, -9.5282],
        [-2.3952, -1.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30346453189849854
Epoch 0, Step 2780: train/loss = 0.4743462800979614, train/raw-loss = 0.44062939286231995, train/logprobs = tensor([[-1.4505, -3.2017],
        [-2.3326, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33716872334480286
Epoch 0, Step 2781: train/loss = 0.4185667335987091, train/raw-loss = 0.3855396509170532, train/logprobs = tensor([[-1.6955, -4.9143],
        [-2.6600, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3302709758281708
Epoch 0, Step 2782: train/loss = 0.47931891679763794, train/raw-loss = 0.44473713636398315, train/logprobs = tensor([[-1.2590, -2.4757],
        [-2.1888, -1.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34581807255744934
Epoch 0, Step 2783: train/loss = 0.25332847237586975, train/raw-loss = 0.22507302463054657, train/logprobs = tensor([[-1.7670, -4.4714],
        [-2.5327, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2825545072555542
Epoch 0, Step 2784: train/loss = 0.3010079860687256, train/raw-loss = 0.27173447608947754, train/logprobs = tensor([[-1.0537, -6.2878],
        [-2.1304, -1.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29273512959480286
Epoch 0, Step 2785: train/loss = 0.16735845804214478, train/raw-loss = 0.13150790333747864, train/logprobs = tensor([[-1.5468, -6.9938],
        [-3.5433, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35850539803504944
Epoch 0, Step 2786: train/loss = 0.3772629499435425, train/raw-loss = 0.3473379909992218, train/logprobs = tensor([[-0.9716, -2.2679],
        [-2.1429, -1.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992493212223053
Epoch 0, Step 2787: train/loss = 0.49629759788513184, train/raw-loss = 0.4693875014781952, train/logprobs = tensor([[-1.6678, -3.5548],
        [-1.6218, -1.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691006660461426
Epoch 0, Step 2788: train/loss = 0.4670865535736084, train/raw-loss = 0.43881863355636597, train/logprobs = tensor([[-1.9479, -6.5355],
        [-1.9627, -1.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28267908096313477
Epoch 0, Step 2789: train/loss = 0.5727259516716003, train/raw-loss = 0.54386305809021, train/logprobs = tensor([[-0.6367, -2.4237],
        [-1.3448, -1.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28862863779067993
Epoch 0, Step 2790: train/loss = 0.4471859931945801, train/raw-loss = 0.41644906997680664, train/logprobs = tensor([[-1.7002, -3.4643],
        [-2.2369, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073689639568329
Epoch 0, Step 2791: train/loss = 0.5017968416213989, train/raw-loss = 0.47443312406539917, train/logprobs = tensor([[-1.1982, -2.9318],
        [-1.5878, -1.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2736375331878662
Epoch 0, Step 2792: train/loss = 0.5626711845397949, train/raw-loss = 0.5347005128860474, train/logprobs = tensor([[-0.8494, -1.6912],
        [-1.5867, -1.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2797071039676666
Epoch 0, Step 2793: train/loss = 0.7263731360435486, train/raw-loss = 0.6971405148506165, train/logprobs = tensor([[-2.1712, -3.9968],
        [-1.8956, -1.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29232606291770935
Epoch 0, Step 2794: train/loss = 0.44055259227752686, train/raw-loss = 0.41756123304367065, train/logprobs = tensor([[-1.3511, -2.1981],
        [-2.4780, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22991400957107544
Epoch 0, Step 2795: train/loss = 0.38355985283851624, train/raw-loss = 0.35777541995048523, train/logprobs = tensor([[-1.6238, -3.0373],
        [-1.9550, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25784412026405334
Epoch 0, Step 2796: train/loss = 1.118575096130371, train/raw-loss = 1.0866823196411133, train/logprobs = tensor([[-4.2827, -4.1883],
        [-2.9416, -1.2836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31892743706703186
Epoch 0, Step 2797: train/loss = 0.20711131393909454, train/raw-loss = 0.1755867898464203, train/logprobs = tensor([[-1.0128, -6.7785],
        [-2.1142, -1.6663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152450919151306
Epoch 0, Step 2798: train/loss = 0.5992913842201233, train/raw-loss = 0.5721772909164429, train/logprobs = tensor([[-0.9429, -1.5084],
        [-1.2248, -1.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2711411118507385
Epoch 0, Step 2799: train/loss = 0.5237467885017395, train/raw-loss = 0.4933849573135376, train/logprobs = tensor([[-0.9131, -1.6396],
        [-2.0839, -1.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3036181926727295
Epoch 0, Step 2800: train/loss = 0.2475932240486145, train/raw-loss = 0.2096484899520874, train/logprobs = tensor([[-1.5916, -5.8861],
        [-3.4361, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37944743037223816
Epoch 0, Step 2801: train/loss = 0.561833381652832, train/raw-loss = 0.5309693813323975, train/logprobs = tensor([[-1.5577, -3.9469],
        [-1.6479, -1.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086400032043457
Epoch 0, Step 2802: train/loss = 0.32612287998199463, train/raw-loss = 0.2955484390258789, train/logprobs = tensor([[-1.4084, -4.7327],
        [-2.6884, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30574434995651245
Epoch 0, Step 2803: train/loss = 0.510934054851532, train/raw-loss = 0.4784793555736542, train/logprobs = tensor([[-1.4624, -2.3389],
        [-2.3888, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32454708218574524
Epoch 0, Step 2804: train/loss = 0.47235122323036194, train/raw-loss = 0.4449489116668701, train/logprobs = tensor([[-1.2775, -2.8097],
        [-1.9724, -1.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740235924720764
Epoch 0, Step 2805: train/loss = 0.3890268802642822, train/raw-loss = 0.3517898917198181, train/logprobs = tensor([[-1.8349, -5.9036],
        [-2.1186, -0.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37237033247947693
Epoch 0, Step 2806: train/loss = 0.5125764608383179, train/raw-loss = 0.4874642491340637, train/logprobs = tensor([[-0.9935, -2.9832],
        [-1.4962, -1.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25112223625183105
Epoch 0, Step 2807: train/loss = 0.5179697275161743, train/raw-loss = 0.48835545778274536, train/logprobs = tensor([[-1.5392, -1.6892],
        [-2.9094, -1.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29614266753196716
Epoch 0, Step 2808: train/loss = 0.29143819212913513, train/raw-loss = 0.25936245918273926, train/logprobs = tensor([[-1.2283, -6.6680],
        [-3.0235, -1.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32075726985931396
Epoch 0, Step 2809: train/loss = 0.4771726131439209, train/raw-loss = 0.4483657479286194, train/logprobs = tensor([[-1.3354, -1.7437],
        [-2.4708, -1.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2880684733390808
Epoch 0, Step 2810: train/loss = 0.5700525641441345, train/raw-loss = 0.5377243757247925, train/logprobs = tensor([[-1.1112, -1.6646],
        [-1.8004, -1.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32328230142593384
Epoch 0, Step 2811: train/loss = 0.6304932832717896, train/raw-loss = 0.6009467840194702, train/logprobs = tensor([[-1.7948, -2.8818],
        [-1.5879, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2954651713371277
Epoch 0, Step 2812: train/loss = 0.37978100776672363, train/raw-loss = 0.3536222279071808, train/logprobs = tensor([[-1.1500, -3.6227],
        [-1.5187, -1.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26158761978149414
Epoch 0, Step 2813: train/loss = 0.4607126712799072, train/raw-loss = 0.42597144842147827, train/logprobs = tensor([[-1.4326, -2.3721],
        [-2.8106, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34741246700286865
Epoch 0, Step 2814: train/loss = 0.8216418027877808, train/raw-loss = 0.7931579351425171, train/logprobs = tensor([[-2.5396, -2.9420],
        [-1.6734, -1.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28483831882476807
Epoch 0, Step 2815: train/loss = 0.4269278943538666, train/raw-loss = 0.39662986993789673, train/logprobs = tensor([[-0.8680, -2.8117],
        [-1.6525, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3029801845550537
Epoch 0, Step 2816: train/loss = 0.4796311855316162, train/raw-loss = 0.45030492544174194, train/logprobs = tensor([[-1.4584, -3.2345],
        [-1.6588, -1.2636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932627499103546
Epoch 0, Step 2817: train/loss = 0.4813424348831177, train/raw-loss = 0.4548076391220093, train/logprobs = tensor([[-1.8222, -4.8939],
        [-2.0603, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653481066226959
Epoch 0, Step 2818: train/loss = 0.28423380851745605, train/raw-loss = 0.25251519680023193, train/logprobs = tensor([[-1.0478, -5.0772],
        [-2.5036, -1.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3171860873699188
Epoch 0, Step 2819: train/loss = 0.41891658306121826, train/raw-loss = 0.38848432898521423, train/logprobs = tensor([[-1.1084, -6.4017],
        [-2.6723, -1.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30432265996932983
Epoch 0, Step 2820: train/loss = 0.6660903692245483, train/raw-loss = 0.6381233930587769, train/logprobs = tensor([[-1.6030, -1.5758],
        [-1.7191, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2796696424484253
Epoch 0, Step 2821: train/loss = 0.4775213599205017, train/raw-loss = 0.44678136706352234, train/logprobs = tensor([[-1.2606, -2.7426],
        [-1.9585, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073999881744385
Epoch 0, Step 2822: train/loss = 0.21416693925857544, train/raw-loss = 0.18173366785049438, train/logprobs = tensor([[-1.0414, -7.4713],
        [-2.6650, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32433271408081055
Epoch 0, Step 2823: train/loss = 0.7357935905456543, train/raw-loss = 0.7061418294906616, train/logprobs = tensor([[-2.0876, -3.7647],
        [-1.6234, -1.4375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.296517014503479
Epoch 0, Step 2824: train/loss = 0.4054630696773529, train/raw-loss = 0.3640453815460205, train/logprobs = tensor([[-1.4178, -3.1154],
        [-3.3062, -1.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.414176881313324
Epoch 0, Step 2825: train/loss = 0.5635753273963928, train/raw-loss = 0.535353422164917, train/logprobs = tensor([[-1.1895, -2.0935],
        [-1.6703, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28221917152404785
Epoch 0, Step 2826: train/loss = 0.5234190225601196, train/raw-loss = 0.49918830394744873, train/logprobs = tensor([[-0.8501, -1.4732],
        [-1.3555, -0.9249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24230748414993286
Epoch 0, Step 2827: train/loss = 0.5511474609375, train/raw-loss = 0.5184503197669983, train/logprobs = tensor([[-1.0243, -2.8939],
        [-2.1025, -1.3714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3269716203212738
Epoch 0, Step 2828: train/loss = 0.4803858995437622, train/raw-loss = 0.4504900574684143, train/logprobs = tensor([[-1.1764, -2.8836],
        [-2.6591, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29895830154418945
Epoch 0, Step 2829: train/loss = 0.46177875995635986, train/raw-loss = 0.4340537488460541, train/logprobs = tensor([[-1.3110, -3.4692],
        [-1.5960, -1.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772499620914459
Epoch 0, Step 2830: train/loss = 0.3817950487136841, train/raw-loss = 0.3557209372520447, train/logprobs = tensor([[-1.3326, -4.9221],
        [-1.9858, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607411742210388
Epoch 0, Step 2831: train/loss = 0.34554898738861084, train/raw-loss = 0.31651920080184937, train/logprobs = tensor([[-1.2928, -7.3988],
        [-2.0650, -2.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29029810428619385
Epoch 0, Step 2832: train/loss = 0.40931960940361023, train/raw-loss = 0.3815777599811554, train/logprobs = tensor([[-1.2527, -4.3901],
        [-1.7172, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2774185538291931
Epoch 0, Step 2833: train/loss = 0.3125905394554138, train/raw-loss = 0.2838369607925415, train/logprobs = tensor([[-1.7739, -6.7750],
        [-2.8771, -0.7075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875354290008545
Epoch 0, Step 2834: train/loss = 0.38711291551589966, train/raw-loss = 0.356029212474823, train/logprobs = tensor([[-1.3765, -3.6621],
        [-2.0272, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108370304107666
Epoch 0, Step 2835: train/loss = 0.49217677116394043, train/raw-loss = 0.46471112966537476, train/logprobs = tensor([[-1.0543, -1.7920],
        [-1.8996, -1.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2746559679508209
Epoch 0, Step 2836: train/loss = 0.553206205368042, train/raw-loss = 0.5264142155647278, train/logprobs = tensor([[-0.6545, -3.1507],
        [-1.8196, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26791924238204956
Epoch 0, Step 2837: train/loss = 0.433120995759964, train/raw-loss = 0.40154674649238586, train/logprobs = tensor([[-0.8962, -2.7412],
        [-1.9389, -1.3137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3157424330711365
Epoch 0, Step 2838: train/loss = 0.3619462549686432, train/raw-loss = 0.3319055438041687, train/logprobs = tensor([[-1.0253, -5.6390],
        [-2.1349, -2.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3004070818424225
Epoch 0, Step 2839: train/loss = 0.611916184425354, train/raw-loss = 0.5859251022338867, train/logprobs = tensor([[-0.9692, -3.6782],
        [-1.3785, -1.6194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599104046821594
Epoch 0, Step 2840: train/loss = 0.5059564113616943, train/raw-loss = 0.4761088788509369, train/logprobs = tensor([[-0.9372, -2.4513],
        [-1.5549, -1.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2984754741191864
Epoch 0, Step 2841: train/loss = 0.5625278353691101, train/raw-loss = 0.536853551864624, train/logprobs = tensor([[-1.0611, -2.4913],
        [-1.2897, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25674304366111755
Epoch 0, Step 2842: train/loss = 0.4665018916130066, train/raw-loss = 0.4407169222831726, train/logprobs = tensor([[-0.9824, -2.1085],
        [-1.4725, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578493356704712
Epoch 0, Step 2843: train/loss = 0.4093448519706726, train/raw-loss = 0.383116215467453, train/logprobs = tensor([[-0.9459, -5.3725],
        [-1.8417, -1.4563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2622864544391632
Epoch 0, Step 2844: train/loss = 0.23941582441329956, train/raw-loss = 0.20082814991474152, train/logprobs = tensor([[-0.9853, -5.7544],
        [-3.2342, -2.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3858766555786133
Epoch 0, Step 2845: train/loss = 0.5991672277450562, train/raw-loss = 0.569161593914032, train/logprobs = tensor([[-2.4413, -5.2209],
        [-1.9426, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30005690455436707
Epoch 0, Step 2846: train/loss = 0.46932685375213623, train/raw-loss = 0.43685293197631836, train/logprobs = tensor([[-0.7932, -2.6268],
        [-1.9119, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32473963499069214
Epoch 0, Step 2847: train/loss = 0.2691759765148163, train/raw-loss = 0.23744505643844604, train/logprobs = tensor([[-1.4227, -7.7352],
        [-3.4132, -2.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3173092007637024
Epoch 0, Step 2848: train/loss = 0.5239297151565552, train/raw-loss = 0.4952864944934845, train/logprobs = tensor([[-1.1598, -4.2606],
        [-1.6593, -2.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2864323854446411
Epoch 0, Step 2849: train/loss = 0.3770288825035095, train/raw-loss = 0.34937596321105957, train/logprobs = tensor([[-0.9274, -2.7559],
        [-1.6363, -1.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27652907371520996
Epoch 0, Step 2850: train/loss = 0.6506223678588867, train/raw-loss = 0.6232703328132629, train/logprobs = tensor([[-2.6163, -5.4215],
        [-1.6424, -0.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27352041006088257
Epoch 0, Step 2851: train/loss = 0.26134443283081055, train/raw-loss = 0.23842832446098328, train/logprobs = tensor([[-1.0297, -5.2776],
        [-1.6238, -1.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291611284017563
Epoch 0, Step 2852: train/loss = 0.6118241548538208, train/raw-loss = 0.5845818519592285, train/logprobs = tensor([[-2.1895, -3.8343],
        [-1.9838, -1.4059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27242252230644226
Epoch 0, Step 2853: train/loss = 0.6358189582824707, train/raw-loss = 0.6104951500892639, train/logprobs = tensor([[-2.2870, -5.1742],
        [-1.7523, -1.4016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25323861837387085
Epoch 0, Step 2854: train/loss = 0.456024706363678, train/raw-loss = 0.42404499650001526, train/logprobs = tensor([[-1.3340, -2.6001],
        [-2.0244, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31979694962501526
Epoch 0, Step 2855: train/loss = 0.3752150237560272, train/raw-loss = 0.3480439782142639, train/logprobs = tensor([[-1.1675, -3.4302],
        [-2.0065, -0.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27171051502227783
Epoch 0, Step 2856: train/loss = 0.473717600107193, train/raw-loss = 0.4430125951766968, train/logprobs = tensor([[-1.4704, -3.5133],
        [-1.6593, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.307049959897995
Epoch 0, Step 2857: train/loss = 0.4100121259689331, train/raw-loss = 0.3748421370983124, train/logprobs = tensor([[-1.0381, -3.4629],
        [-1.9351, -1.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35170021653175354
Epoch 0, Step 2858: train/loss = 0.375885009765625, train/raw-loss = 0.34743133187294006, train/logprobs = tensor([[-1.2944, -3.4736],
        [-1.9070, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2845366597175598
Epoch 0, Step 2859: train/loss = 0.6414646506309509, train/raw-loss = 0.6149492263793945, train/logprobs = tensor([[-1.0667, -1.0904],
        [-1.1581, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651541829109192
Epoch 0, Step 2860: train/loss = 0.39063921570777893, train/raw-loss = 0.361655592918396, train/logprobs = tensor([[-1.2031, -4.2648],
        [-2.4792, -1.2611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28983601927757263
Epoch 0, Step 2861: train/loss = 0.42777225375175476, train/raw-loss = 0.3970735967159271, train/logprobs = tensor([[-1.3130, -3.8100],
        [-1.8474, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3069861829280853
Epoch 0, Step 2862: train/loss = 0.5052042007446289, train/raw-loss = 0.4761508107185364, train/logprobs = tensor([[-1.4922, -2.9033],
        [-1.4108, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29053425788879395
Epoch 0, Step 2863: train/loss = 0.7070755958557129, train/raw-loss = 0.6768152713775635, train/logprobs = tensor([[-1.9662, -2.9055],
        [-1.6772, -1.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3026030659675598
Epoch 0, Step 2864: train/loss = 0.2645866870880127, train/raw-loss = 0.23476465046405792, train/logprobs = tensor([[-1.0470, -4.3694],
        [-3.4359, -1.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982204556465149
Epoch 0, Step 2865: train/loss = 0.46570417284965515, train/raw-loss = 0.4370564818382263, train/logprobs = tensor([[-2.6354, -6.4508],
        [-2.2364, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28647711873054504
Epoch 0, Step 2866: train/loss = 0.34432125091552734, train/raw-loss = 0.3131656050682068, train/logprobs = tensor([[-1.5239, -5.8595],
        [-2.4172, -1.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3115563690662384
Epoch 0, Step 2867: train/loss = 0.23510798811912537, train/raw-loss = 0.2016569823026657, train/logprobs = tensor([[-1.4390, -5.4556],
        [-3.0856, -1.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345103859901428
Epoch 0, Step 2868: train/loss = 0.6907663345336914, train/raw-loss = 0.6609762907028198, train/logprobs = tensor([[-1.9763, -4.5799],
        [-1.9920, -2.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2979002892971039
Epoch 0, Step 2869: train/loss = 0.3575999438762665, train/raw-loss = 0.32765817642211914, train/logprobs = tensor([[-1.3873, -4.2649],
        [-2.6481, -2.5798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29941773414611816
Epoch 0, Step 2870: train/loss = 0.5589843988418579, train/raw-loss = 0.5231358408927917, train/logprobs = tensor([[-1.2861, -2.8539],
        [-2.2353, -2.3061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3584858775138855
Epoch 0, Step 2871: train/loss = 0.6386312246322632, train/raw-loss = 0.6096308827400208, train/logprobs = tensor([[-1.7037, -3.5134],
        [-1.3252, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29000404477119446
Epoch 0, Step 2872: train/loss = 0.45987755060195923, train/raw-loss = 0.43002671003341675, train/logprobs = tensor([[-1.6780, -3.0068],
        [-2.0843, -1.5723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985084652900696
Epoch 0, Step 2873: train/loss = 0.5615409016609192, train/raw-loss = 0.5282067656517029, train/logprobs = tensor([[-1.1304, -4.8761],
        [-2.0773, -1.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3333413898944855
Epoch 0, Step 2874: train/loss = 0.5475402474403381, train/raw-loss = 0.5210236310958862, train/logprobs = tensor([[-1.4093, -4.8444],
        [-1.2470, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2651658058166504
Epoch 0, Step 2875: train/loss = 0.5093677043914795, train/raw-loss = 0.48278918862342834, train/logprobs = tensor([[-1.1958, -2.8995],
        [-1.5812, -1.2758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26578494906425476
Epoch 0, Step 2876: train/loss = 0.29369425773620605, train/raw-loss = 0.25764361023902893, train/logprobs = tensor([[-1.1552, -3.9132],
        [-3.2083, -1.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36050644516944885
Epoch 0, Step 2877: train/loss = 0.48227763175964355, train/raw-loss = 0.4542591869831085, train/logprobs = tensor([[-1.3823, -2.2871],
        [-2.2742, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280184268951416
Epoch 0, Step 2878: train/loss = 0.4237441420555115, train/raw-loss = 0.39146965742111206, train/logprobs = tensor([[-1.1106, -3.7974],
        [-2.3116, -1.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3227444887161255
Epoch 0, Step 2879: train/loss = 0.2021043300628662, train/raw-loss = 0.17114189267158508, train/logprobs = tensor([[-1.0264, -7.9435],
        [-2.5675, -2.7811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30962449312210083
Epoch 0, Step 2880: train/loss = 0.4157995283603668, train/raw-loss = 0.38005179166793823, train/logprobs = tensor([[-1.4719, -3.8701],
        [-2.8201, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3574775755405426
Epoch 0, Step 2881: train/loss = 0.5592344999313354, train/raw-loss = 0.5321655869483948, train/logprobs = tensor([[-1.4452, -2.5582],
        [-1.2941, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.270688533782959
Epoch 0, Step 2882: train/loss = 0.6096528172492981, train/raw-loss = 0.5840833187103271, train/logprobs = tensor([[-1.6112, -2.2495],
        [-1.2500, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25569483637809753
Epoch 0, Step 2883: train/loss = 0.4865688383579254, train/raw-loss = 0.4563907980918884, train/logprobs = tensor([[-0.9362, -1.8893],
        [-1.1431, -0.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.301780641078949
Epoch 0, Step 2884: train/loss = 0.3198994994163513, train/raw-loss = 0.2865631580352783, train/logprobs = tensor([[-1.4328, -3.4694],
        [-2.8348, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33336329460144043
Epoch 0, Step 2885: train/loss = 0.6100066900253296, train/raw-loss = 0.5849657654762268, train/logprobs = tensor([[-1.5202, -2.8345],
        [-1.5225, -1.5043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25040963292121887
Epoch 0, Step 2886: train/loss = 0.5046690702438354, train/raw-loss = 0.48252949118614197, train/logprobs = tensor([[-1.3339, -2.2366],
        [-1.2231, -0.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22139623761177063
Epoch 0, Step 2887: train/loss = 0.43443235754966736, train/raw-loss = 0.4051083028316498, train/logprobs = tensor([[-1.6013, -3.2518],
        [-1.8104, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2932402491569519
Epoch 0, Step 2888: train/loss = 0.4943634271621704, train/raw-loss = 0.4652288258075714, train/logprobs = tensor([[-1.1704, -2.4926],
        [-2.0241, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913462519645691
Epoch 0, Step 2889: train/loss = 0.44156524538993835, train/raw-loss = 0.4070599675178528, train/logprobs = tensor([[-1.4756, -6.5109],
        [-2.7652, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34505242109298706
Epoch 0, Step 2890: train/loss = 0.5219887495040894, train/raw-loss = 0.4923076033592224, train/logprobs = tensor([[-1.7308, -2.9668],
        [-2.0023, -1.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29681140184402466
Epoch 0, Step 2891: train/loss = 0.5509216785430908, train/raw-loss = 0.5254668593406677, train/logprobs = tensor([[-1.2477, -3.8567],
        [-1.4136, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25454798340797424
Epoch 0, Step 2892: train/loss = 0.5387645959854126, train/raw-loss = 0.5173868536949158, train/logprobs = tensor([[-0.8898, -1.8218],
        [-1.7505, -1.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.213777095079422
Epoch 0, Step 2893: train/loss = 0.22977910935878754, train/raw-loss = 0.2034071683883667, train/logprobs = tensor([[-1.8553, -8.4910],
        [-2.5494, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26371926069259644
Epoch 0, Step 2894: train/loss = 0.49227702617645264, train/raw-loss = 0.46090632677078247, train/logprobs = tensor([[-1.7158, -2.8664],
        [-2.2376, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3137073218822479
Epoch 0, Step 2895: train/loss = 0.36880236864089966, train/raw-loss = 0.3319714069366455, train/logprobs = tensor([[-1.3155, -2.2280],
        [-3.2153, -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36830949783325195
Epoch 0, Step 2896: train/loss = 0.2349623739719391, train/raw-loss = 0.20669206976890564, train/logprobs = tensor([[-1.0670, -4.8003],
        [-2.5895, -1.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2827029824256897
Epoch 0, Step 2897: train/loss = 0.42099374532699585, train/raw-loss = 0.3916150629520416, train/logprobs = tensor([[-1.0280, -5.4588],
        [-1.5827, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937866747379303
Epoch 0, Step 2898: train/loss = 0.3273365795612335, train/raw-loss = 0.29833924770355225, train/logprobs = tensor([[-1.0972, -2.4154],
        [-2.4415, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28997358679771423
Epoch 0, Step 2899: train/loss = 0.4563937783241272, train/raw-loss = 0.4231574237346649, train/logprobs = tensor([[-0.9493, -5.9755],
        [-2.1316, -2.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3323635458946228
Epoch 0, Step 2900: train/loss = 0.42512330412864685, train/raw-loss = 0.395457923412323, train/logprobs = tensor([[-0.8167, -3.1054],
        [-2.0201, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966535985469818
Epoch 0, Step 2901: train/loss = 0.30729448795318604, train/raw-loss = 0.2776714861392975, train/logprobs = tensor([[-1.0478, -7.3411],
        [-1.9206, -1.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29622989892959595
Epoch 0, Step 2902: train/loss = 0.4059644937515259, train/raw-loss = 0.3757273554801941, train/logprobs = tensor([[-0.8788, -3.5174],
        [-1.8153, -1.0696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30237099528312683
Epoch 0, Step 2903: train/loss = 0.41093748807907104, train/raw-loss = 0.3776504695415497, train/logprobs = tensor([[-1.3808, -3.5671],
        [-2.4885, -2.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33286988735198975
Epoch 0, Step 2904: train/loss = 0.2673799395561218, train/raw-loss = 0.23850783705711365, train/logprobs = tensor([[-1.3875, -7.3901],
        [-2.1563, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2887208163738251
