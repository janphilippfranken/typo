[2024-03-03 14:19:26,130][root][INFO] - beta: 0.5
[2024-03-03 14:19:26,131][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 8884
n harmless: 9970
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ"}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick'}
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k after each epoch.
5000
5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k after each epoch.
Epoch 0, Step 0: train/loss = 0.6876811981201172, train/raw-loss = 0.6876811981201172, train/logprobs = tensor([[-0.7991, -2.1136],
        [-0.8144, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7017812728881836, train/raw-loss = 0.7017812728881836, train/logprobs = tensor([[-0.8675, -1.3647],
        [-0.9045, -1.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6647472381591797, train/raw-loss = 0.6647472381591797, train/logprobs = tensor([[-0.9712, -1.6776],
        [-1.0482, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6691160798072815, train/raw-loss = 0.6691160798072815, train/logprobs = tensor([[-0.7613, -1.0412],
        [-0.8040, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6818459033966064, train/raw-loss = 0.6818459033966064, train/logprobs = tensor([[-0.7423, -0.8494],
        [-0.8033, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7001824378967285, train/raw-loss = 0.7001824378967285, train/logprobs = tensor([[-0.8634, -1.2522],
        [-0.8944, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6646842360496521, train/raw-loss = 0.6646842360496521, train/logprobs = tensor([[-1.0534, -1.4514],
        [-1.1196, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.692057192325592, train/raw-loss = 0.692057192325592, train/logprobs = tensor([[-1.0745, -1.3111],
        [-1.1357, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6729065179824829, train/raw-loss = 0.6729065179824829, train/logprobs = tensor([[-0.5144, -1.1528],
        [-0.5067, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6754744052886963, train/raw-loss = 0.6754744052886963, train/logprobs = tensor([[-1.0090, -1.1000],
        [-1.0342, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6382375955581665, train/raw-loss = 0.6382375955581665, train/logprobs = tensor([[-1.0358, -1.3086],
        [-1.3042, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6904394626617432, train/raw-loss = 0.6904394626617432, train/logprobs = tensor([[-0.7226, -1.2303],
        [-0.7300, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6897714734077454, train/raw-loss = 0.6897714734077454, train/logprobs = tensor([[-0.9022, -1.2302],
        [-0.9290, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6802294254302979, train/raw-loss = 0.6802294254302979, train/logprobs = tensor([[-0.6706, -1.2400],
        [-0.6935, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6690350770950317, train/raw-loss = 0.6690350770950317, train/logprobs = tensor([[-1.1638, -1.2059],
        [-1.2771, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6677312850952148, train/raw-loss = 0.6677312850952148, train/logprobs = tensor([[-1.2674, -1.3661],
        [-1.3281, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6589983701705933, train/raw-loss = 0.6589983701705933, train/logprobs = tensor([[-0.8304, -1.3320],
        [-0.8951, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6930590867996216, train/raw-loss = 0.6930590867996216, train/logprobs = tensor([[-0.7644, -1.0668],
        [-0.7867, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6523447036743164, train/raw-loss = 0.6523447036743164, train/logprobs = tensor([[-0.9116, -1.1920],
        [-1.0786, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6793126463890076, train/raw-loss = 0.6793126463890076, train/logprobs = tensor([[-0.8504, -1.1314],
        [-0.8680, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6822050213813782, train/raw-loss = 0.6822050213813782, train/logprobs = tensor([[-0.8326, -1.3713],
        [-0.9170, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6489429473876953, train/raw-loss = 0.6489429473876953, train/logprobs = tensor([[-1.3826, -1.5213],
        [-1.5211, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6750220060348511, train/raw-loss = 0.6750220060348511, train/logprobs = tensor([[-0.8851, -0.7172],
        [-0.9591, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6739029288291931, train/raw-loss = 0.6739029288291931, train/logprobs = tensor([[-0.7526, -1.6962],
        [-0.8254, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721904873847961, train/raw-loss = 0.6721904873847961, train/logprobs = tensor([[-0.8545, -1.1816],
        [-0.8767, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6630262732505798, train/raw-loss = 0.6630262732505798, train/logprobs = tensor([[-1.1663, -1.0103],
        [-1.2706, -0.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6829202175140381, train/raw-loss = 0.6829202175140381, train/logprobs = tensor([[-1.0265, -1.0503],
        [-1.0613, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6595985293388367, train/raw-loss = 0.6595985293388367, train/logprobs = tensor([[-1.1463, -1.5332],
        [-1.2361, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6569761633872986, train/raw-loss = 0.6569761633872986, train/logprobs = tensor([[-0.7432, -0.9342],
        [-0.8139, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6692489385604858, train/raw-loss = 0.6692489385604858, train/logprobs = tensor([[-0.8930, -1.2501],
        [-0.9570, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6794319152832031, train/raw-loss = 0.6794319152832031, train/logprobs = tensor([[-0.7914, -1.1187],
        [-0.7899, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.655624508857727, train/raw-loss = 0.655624508857727, train/logprobs = tensor([[-1.5374, -1.5602],
        [-1.6876, -1.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6592499017715454, train/raw-loss = 0.6592499017715454, train/logprobs = tensor([[-0.9855, -1.1981],
        [-1.0750, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6820563077926636, train/raw-loss = 0.6820563077926636, train/logprobs = tensor([[-0.6501, -1.2848],
        [-0.6630, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6683226823806763, train/raw-loss = 0.6683226823806763, train/logprobs = tensor([[-0.9491, -1.3495],
        [-1.0024, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6583713889122009, train/raw-loss = 0.6583713889122009, train/logprobs = tensor([[-0.8106, -1.6709],
        [-0.9243, -1.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6469834446907043, train/raw-loss = 0.6469834446907043, train/logprobs = tensor([[-1.5048, -2.2232],
        [-1.5990, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6797101497650146, train/raw-loss = 0.6797101497650146, train/logprobs = tensor([[-0.6664, -1.6870],
        [-0.6909, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.683232843875885, train/raw-loss = 0.683232843875885, train/logprobs = tensor([[-0.9656, -1.3642],
        [-1.0281, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6942904591560364, train/raw-loss = 0.6942904591560364, train/logprobs = tensor([[-0.4989, -0.9991],
        [-0.5058, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6635227203369141, train/raw-loss = 0.6635227203369141, train/logprobs = tensor([[-0.7571, -1.2971],
        [-0.8222, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6960233449935913, train/raw-loss = 0.6960233449935913, train/logprobs = tensor([[-1.6412, -0.8003],
        [-1.6515, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6716673970222473, train/raw-loss = 0.6716673970222473, train/logprobs = tensor([[-0.9006, -1.8356],
        [-0.9486, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6504718065261841, train/raw-loss = 0.6504718065261841, train/logprobs = tensor([[-1.0048, -1.1417],
        [-1.1579, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6575814485549927, train/raw-loss = 0.6575814485549927, train/logprobs = tensor([[-1.4579, -1.0380],
        [-1.5999, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6726564168930054, train/raw-loss = 0.6726564168930054, train/logprobs = tensor([[-1.2457, -1.0000],
        [-1.3556, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6659195423126221, train/raw-loss = 0.6659195423126221, train/logprobs = tensor([[-1.1039, -1.4521],
        [-1.2564, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6463595628738403, train/raw-loss = 0.6463595628738403, train/logprobs = tensor([[-0.6710, -1.5861],
        [-0.7079, -1.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6638263463973999, train/raw-loss = 0.6638263463973999, train/logprobs = tensor([[-1.2741, -1.4761],
        [-1.3570, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6739931106567383, train/raw-loss = 0.6739931106567383, train/logprobs = tensor([[-0.8710, -1.0174],
        [-0.8790, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678565263748169, train/raw-loss = 0.678565263748169, train/logprobs = tensor([[-1.1486, -0.8595],
        [-1.2491, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6736483573913574, train/raw-loss = 0.6736483573913574, train/logprobs = tensor([[-0.7778, -1.5755],
        [-0.8147, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6805825233459473, train/raw-loss = 0.6805825233459473, train/logprobs = tensor([[-1.3469, -0.9800],
        [-1.4307, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6744076013565063, train/raw-loss = 0.6744076013565063, train/logprobs = tensor([[-0.6959, -1.2708],
        [-0.8213, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6815992593765259, train/raw-loss = 0.6815992593765259, train/logprobs = tensor([[-0.6407, -0.9858],
        [-0.6565, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6931482553482056, train/raw-loss = 0.6931482553482056, train/logprobs = tensor([[-0.8090, -1.1945],
        [-0.8420, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6945903897285461, train/raw-loss = 0.6945903897285461, train/logprobs = tensor([[-0.7038, -1.2251],
        [-0.7267, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6877249479293823, train/raw-loss = 0.6877249479293823, train/logprobs = tensor([[-0.6526, -1.2008],
        [-0.6792, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6316418051719666, train/raw-loss = 0.6316418051719666, train/logprobs = tensor([[-0.8534, -1.8226],
        [-0.8765, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.668732762336731, train/raw-loss = 0.668732762336731, train/logprobs = tensor([[-1.2706, -1.2705],
        [-1.3812, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6924586892127991, train/raw-loss = 0.6924586892127991, train/logprobs = tensor([[-0.6864, -0.6025],
        [-0.6989, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6888662576675415, train/raw-loss = 0.6888662576675415, train/logprobs = tensor([[-0.5987, -0.8959],
        [-0.6033, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6881542801856995, train/raw-loss = 0.6881542801856995, train/logprobs = tensor([[-0.9270, -1.5385],
        [-0.9858, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7003958225250244, train/raw-loss = 0.7003958225250244, train/logprobs = tensor([[-1.1320, -1.5081],
        [-1.1284, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.685478925704956, train/raw-loss = 0.681352972984314, train/logprobs = tensor([[-0.6325, -3.4818],
        [-0.6515, -3.4517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00825178250670433
Epoch 0, Step 65: train/loss = 0.6517041921615601, train/raw-loss = 0.6463444232940674, train/logprobs = tensor([[-1.0075, -1.0863],
        [-1.1973, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010719509795308113
Epoch 0, Step 66: train/loss = 0.6893692016601562, train/raw-loss = 0.6861051321029663, train/logprobs = tensor([[-0.5674, -0.8160],
        [-0.5667, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006528166122734547
Epoch 0, Step 67: train/loss = 0.692968487739563, train/raw-loss = 0.6891236305236816, train/logprobs = tensor([[-0.5683, -0.9036],
        [-0.5620, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007689644582569599
Epoch 0, Step 68: train/loss = 0.6869228482246399, train/raw-loss = 0.6816505789756775, train/logprobs = tensor([[-0.9405, -1.6278],
        [-0.9770, -1.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010544516146183014
Epoch 0, Step 69: train/loss = 0.6718931198120117, train/raw-loss = 0.667283833026886, train/logprobs = tensor([[-0.7912, -1.3102],
        [-0.9549, -1.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009218713268637657
Epoch 0, Step 70: train/loss = 0.6858401894569397, train/raw-loss = 0.682564377784729, train/logprobs = tensor([[-0.5653, -1.9105],
        [-0.5646, -1.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006551805883646011
Epoch 0, Step 71: train/loss = 0.6682335138320923, train/raw-loss = 0.6634629964828491, train/logprobs = tensor([[-1.0331, -1.6661],
        [-1.1547, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009541071951389313
Epoch 0, Step 72: train/loss = 0.6901871562004089, train/raw-loss = 0.6851996183395386, train/logprobs = tensor([[-1.5103, -1.9938],
        [-1.6016, -2.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009975159540772438
Epoch 0, Step 73: train/loss = 0.6720877885818481, train/raw-loss = 0.6662010550498962, train/logprobs = tensor([[-1.0819, -1.2697],
        [-1.1837, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011773371137678623
Epoch 0, Step 74: train/loss = 0.644994854927063, train/raw-loss = 0.6403176784515381, train/logprobs = tensor([[-1.2339, -0.7138],
        [-1.4336, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009354304522275925
Epoch 0, Step 75: train/loss = 0.6941835880279541, train/raw-loss = 0.6902722120285034, train/logprobs = tensor([[-0.8104, -1.3687],
        [-0.8422, -1.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007822821848094463
Epoch 0, Step 76: train/loss = 0.6809238195419312, train/raw-loss = 0.6766533851623535, train/logprobs = tensor([[-0.6320, -0.6417],
        [-0.7063, -0.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008540774695575237
Epoch 0, Step 77: train/loss = 0.6577910780906677, train/raw-loss = 0.6519684791564941, train/logprobs = tensor([[-1.1916, -1.2232],
        [-1.3672, -1.2256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011645247228443623
Epoch 0, Step 78: train/loss = 0.6582288146018982, train/raw-loss = 0.652970552444458, train/logprobs = tensor([[-1.1973, -0.9383],
        [-1.3822, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010516603477299213
Epoch 0, Step 79: train/loss = 0.6761364340782166, train/raw-loss = 0.6706007719039917, train/logprobs = tensor([[-0.7567, -0.9288],
        [-0.8533, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011071329936385155
Epoch 0, Step 80: train/loss = 0.6840180158615112, train/raw-loss = 0.6788941621780396, train/logprobs = tensor([[-0.7989, -1.0193],
        [-0.8165, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01024767104536295
Epoch 0, Step 81: train/loss = 0.6690702438354492, train/raw-loss = 0.6647629141807556, train/logprobs = tensor([[-1.1317, -1.0207],
        [-1.2259, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008614668622612953
Epoch 0, Step 82: train/loss = 0.6358584761619568, train/raw-loss = 0.6303144097328186, train/logprobs = tensor([[-1.1040, -1.2765],
        [-1.3470, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011088198982179165
Epoch 0, Step 83: train/loss = 0.6730859875679016, train/raw-loss = 0.6696005463600159, train/logprobs = tensor([[-0.9766, -1.2733],
        [-1.0873, -1.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006970934569835663
Epoch 0, Step 84: train/loss = 0.67391437292099, train/raw-loss = 0.669486403465271, train/logprobs = tensor([[-0.4959, -1.1871],
        [-0.5234, -1.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008855852298438549
Epoch 0, Step 85: train/loss = 0.6617192029953003, train/raw-loss = 0.6565996408462524, train/logprobs = tensor([[-0.9087, -1.0836],
        [-1.1059, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01023909356445074
Epoch 0, Step 86: train/loss = 0.681358277797699, train/raw-loss = 0.6763962507247925, train/logprobs = tensor([[-0.6988, -1.1709],
        [-0.7102, -1.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009924085810780525
Epoch 0, Step 87: train/loss = 0.6550708413124084, train/raw-loss = 0.6486508846282959, train/logprobs = tensor([[-0.8676, -1.6732],
        [-1.0240, -1.6442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012839981354773045
Epoch 0, Step 88: train/loss = 0.6887760162353516, train/raw-loss = 0.6848755478858948, train/logprobs = tensor([[-0.5443, -1.5436],
        [-0.5521, -1.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00780094601213932
Epoch 0, Step 89: train/loss = 0.701185405254364, train/raw-loss = 0.6974455714225769, train/logprobs = tensor([[-0.7851, -1.1929],
        [-0.8672, -1.2871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007479796186089516
Epoch 0, Step 90: train/loss = 0.6740471124649048, train/raw-loss = 0.6684786081314087, train/logprobs = tensor([[-0.8008, -1.1458],
        [-0.8740, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011137080378830433
Epoch 0, Step 91: train/loss = 0.6286579370498657, train/raw-loss = 0.623782753944397, train/logprobs = tensor([[-1.0744, -1.5358],
        [-1.1442, -1.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009750356897711754
Epoch 0, Step 92: train/loss = 0.6851233243942261, train/raw-loss = 0.6799646019935608, train/logprobs = tensor([[-1.0567, -1.0552],
        [-1.0802, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01031742338091135
Epoch 0, Step 93: train/loss = 0.6700083017349243, train/raw-loss = 0.6645956039428711, train/logprobs = tensor([[-1.1989, -1.3219],
        [-1.3226, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010825421661138535
Epoch 0, Step 94: train/loss = 0.6761636137962341, train/raw-loss = 0.6709938049316406, train/logprobs = tensor([[-0.9934, -1.1172],
        [-1.0613, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010339432395994663
Epoch 0, Step 95: train/loss = 0.6778924465179443, train/raw-loss = 0.6726057529449463, train/logprobs = tensor([[-0.8279, -1.0036],
        [-0.9084, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01057338621467352
Epoch 0, Step 96: train/loss = 0.6593741178512573, train/raw-loss = 0.649088978767395, train/logprobs = tensor([[-0.8887, -1.0013],
        [-0.9862, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02057032287120819
Epoch 0, Step 97: train/loss = 0.6311283707618713, train/raw-loss = 0.620479166507721, train/logprobs = tensor([[-0.8155, -1.9468],
        [-0.9737, -1.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02129840850830078
Epoch 0, Step 98: train/loss = 0.6742112636566162, train/raw-loss = 0.6639081239700317, train/logprobs = tensor([[-0.8074, -1.4008],
        [-0.9583, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02060624025762081
Epoch 0, Step 99: train/loss = 0.6640649437904358, train/raw-loss = 0.6533578634262085, train/logprobs = tensor([[-0.8838, -1.6922],
        [-1.0050, -1.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02141410857439041
Epoch 0, Step 100: train/loss = 0.6368029713630676, train/raw-loss = 0.6222349405288696, train/logprobs = tensor([[-1.2435, -1.3825],
        [-1.6251, -1.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029136039316654205
Epoch 0, Step 101: train/loss = 0.6775421500205994, train/raw-loss = 0.6657533645629883, train/logprobs = tensor([[-0.9842, -1.4525],
        [-1.1609, -1.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023577651008963585
Epoch 0, Step 102: train/loss = 0.6793155074119568, train/raw-loss = 0.6718217730522156, train/logprobs = tensor([[-0.5293, -1.3111],
        [-0.5428, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01498751062899828
Epoch 0, Step 103: train/loss = 0.6728692650794983, train/raw-loss = 0.6627600789070129, train/logprobs = tensor([[-1.0002, -1.2267],
        [-1.1202, -1.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020218204706907272
Epoch 0, Step 104: train/loss = 0.6556241512298584, train/raw-loss = 0.6422593593597412, train/logprobs = tensor([[-0.9026, -1.3116],
        [-1.0430, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026729563251137733
Epoch 0, Step 105: train/loss = 0.6118260622024536, train/raw-loss = 0.5997300744056702, train/logprobs = tensor([[-1.4464, -1.9849],
        [-1.8098, -1.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024192065000534058
Epoch 0, Step 106: train/loss = 0.6886899471282959, train/raw-loss = 0.6801019906997681, train/logprobs = tensor([[-0.7098, -1.4446],
        [-0.7072, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017175892367959023
Epoch 0, Step 107: train/loss = 0.6571347713470459, train/raw-loss = 0.6437392830848694, train/logprobs = tensor([[-1.5268, -1.8200],
        [-1.7511, -1.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026790941134095192
Epoch 0, Step 108: train/loss = 0.6711984872817993, train/raw-loss = 0.6610201001167297, train/logprobs = tensor([[-1.3156, -2.5761],
        [-1.4172, -2.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020356835797429085
Epoch 0, Step 109: train/loss = 0.686194896697998, train/raw-loss = 0.6784364581108093, train/logprobs = tensor([[-0.5408, -1.1777],
        [-0.5553, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015516763553023338
Epoch 0, Step 110: train/loss = 0.6854618191719055, train/raw-loss = 0.6766024231910706, train/logprobs = tensor([[-0.9343, -1.6144],
        [-0.9958, -1.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017718825489282608
Epoch 0, Step 111: train/loss = 0.669238805770874, train/raw-loss = 0.6594778299331665, train/logprobs = tensor([[-1.1696, -1.1515],
        [-1.3509, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01952188089489937
Epoch 0, Step 112: train/loss = 0.6433768272399902, train/raw-loss = 0.6326457858085632, train/logprobs = tensor([[-1.5305, -1.8877],
        [-1.7740, -1.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021462149918079376
Epoch 0, Step 113: train/loss = 0.6489356756210327, train/raw-loss = 0.6374423503875732, train/logprobs = tensor([[-1.2398, -1.4013],
        [-1.5124, -1.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02298678644001484
Epoch 0, Step 114: train/loss = 0.6354269981384277, train/raw-loss = 0.6231417655944824, train/logprobs = tensor([[-1.0973, -1.5480],
        [-1.3040, -1.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024570463225245476
Epoch 0, Step 115: train/loss = 0.678848385810852, train/raw-loss = 0.6697605848312378, train/logprobs = tensor([[-0.9010, -1.5141],
        [-0.9987, -1.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01817556470632553
Epoch 0, Step 116: train/loss = 0.6905421018600464, train/raw-loss = 0.6833637952804565, train/logprobs = tensor([[-0.5189, -0.9043],
        [-0.5423, -0.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014356797561049461
Epoch 0, Step 117: train/loss = 0.6932768821716309, train/raw-loss = 0.6831750869750977, train/logprobs = tensor([[-1.0320, -1.0855],
        [-1.1585, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0202036052942276
Epoch 0, Step 118: train/loss = 0.6487029790878296, train/raw-loss = 0.6373214721679688, train/logprobs = tensor([[-0.7536, -0.9789],
        [-0.9350, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022763077169656754
Epoch 0, Step 119: train/loss = 0.5996062755584717, train/raw-loss = 0.5844421982765198, train/logprobs = tensor([[-1.0951, -1.6746],
        [-1.4461, -1.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030328186228871346
Epoch 0, Step 120: train/loss = 0.6060347557067871, train/raw-loss = 0.5945925712585449, train/logprobs = tensor([[-1.0572, -1.9873],
        [-1.2662, -1.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02288425713777542
Epoch 0, Step 121: train/loss = 0.6829038858413696, train/raw-loss = 0.673934280872345, train/logprobs = tensor([[-0.7018, -0.9918],
        [-0.7573, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01793915405869484
Epoch 0, Step 122: train/loss = 0.6899183392524719, train/raw-loss = 0.6810877323150635, train/logprobs = tensor([[-0.6928, -1.0648],
        [-0.7475, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017661262303590775
Epoch 0, Step 123: train/loss = 0.6117818355560303, train/raw-loss = 0.6010302901268005, train/logprobs = tensor([[-1.1979, -1.6820],
        [-1.3948, -1.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021503157913684845
Epoch 0, Step 124: train/loss = 0.6886478066444397, train/raw-loss = 0.681535542011261, train/logprobs = tensor([[-0.7530, -0.8031],
        [-0.7972, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014224549755454063
Epoch 0, Step 125: train/loss = 0.6831947565078735, train/raw-loss = 0.6742364168167114, train/logprobs = tensor([[-0.6027, -1.0642],
        [-0.6211, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017916645854711533
Epoch 0, Step 126: train/loss = 0.6621848940849304, train/raw-loss = 0.6502582430839539, train/logprobs = tensor([[-1.0809, -1.1816],
        [-1.2380, -1.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023853272199630737
Epoch 0, Step 127: train/loss = 0.6575949192047119, train/raw-loss = 0.6455838084220886, train/logprobs = tensor([[-0.8953, -1.1576],
        [-1.0270, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024022340774536133
Epoch 0, Step 128: train/loss = 0.6846215724945068, train/raw-loss = 0.6671974062919617, train/logprobs = tensor([[-0.8362, -1.2137],
        [-0.9347, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034848276525735855
Epoch 0, Step 129: train/loss = 0.6322464942932129, train/raw-loss = 0.6065433025360107, train/logprobs = tensor([[-0.8993, -1.4239],
        [-1.0416, -1.1970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05140632390975952
Epoch 0, Step 130: train/loss = 0.6658309102058411, train/raw-loss = 0.6479847431182861, train/logprobs = tensor([[-0.7660, -0.8366],
        [-0.9202, -0.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03569221496582031
Epoch 0, Step 131: train/loss = 0.6445055603981018, train/raw-loss = 0.6176429986953735, train/logprobs = tensor([[-0.7879, -1.0943],
        [-1.1773, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05372518673539162
Epoch 0, Step 132: train/loss = 0.6576424837112427, train/raw-loss = 0.6336748600006104, train/logprobs = tensor([[-0.9743, -1.1993],
        [-1.0927, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0479353629052639
Epoch 0, Step 133: train/loss = 0.57040935754776, train/raw-loss = 0.5469735264778137, train/logprobs = tensor([[-0.9474, -2.4751],
        [-1.3882, -2.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04687173664569855
Epoch 0, Step 134: train/loss = 0.6784296631813049, train/raw-loss = 0.6592833995819092, train/logprobs = tensor([[-0.8242, -0.9993],
        [-0.9233, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03829261288046837
Epoch 0, Step 135: train/loss = 0.6308876276016235, train/raw-loss = 0.6027851700782776, train/logprobs = tensor([[-1.3290, -1.7217],
        [-1.7981, -1.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056205008178949356
Epoch 0, Step 136: train/loss = 0.6718552112579346, train/raw-loss = 0.6525201797485352, train/logprobs = tensor([[-0.5574, -0.9379],
        [-0.6197, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03867005929350853
Epoch 0, Step 137: train/loss = 0.6123310923576355, train/raw-loss = 0.5847333073616028, train/logprobs = tensor([[-1.0317, -1.3378],
        [-1.4332, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055195532739162445
Epoch 0, Step 138: train/loss = 0.6620461940765381, train/raw-loss = 0.6418749094009399, train/logprobs = tensor([[-0.7553, -0.8975],
        [-0.9866, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040342509746551514
Epoch 0, Step 139: train/loss = 0.6366186738014221, train/raw-loss = 0.6171971559524536, train/logprobs = tensor([[-0.7832, -1.0044],
        [-0.9901, -0.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038842931389808655
Epoch 0, Step 140: train/loss = 0.6530352830886841, train/raw-loss = 0.6316032409667969, train/logprobs = tensor([[-0.9028, -1.8439],
        [-1.0763, -1.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042864106595516205
Epoch 0, Step 141: train/loss = 0.7138503789901733, train/raw-loss = 0.6946792602539062, train/logprobs = tensor([[-1.1520, -1.4369],
        [-1.1275, -1.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0383421815931797
Epoch 0, Step 142: train/loss = 0.6075634956359863, train/raw-loss = 0.583362877368927, train/logprobs = tensor([[-1.0831, -1.1214],
        [-1.5240, -1.0704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048401184380054474
Epoch 0, Step 143: train/loss = 0.6132319569587708, train/raw-loss = 0.5897883772850037, train/logprobs = tensor([[-0.9400, -0.8686],
        [-1.4023, -0.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046887099742889404
Epoch 0, Step 144: train/loss = 0.6566353440284729, train/raw-loss = 0.6345489025115967, train/logprobs = tensor([[-1.3271, -1.4511],
        [-1.4990, -1.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04417281597852707
Epoch 0, Step 145: train/loss = 0.5872752666473389, train/raw-loss = 0.5617961883544922, train/logprobs = tensor([[-0.7838, -2.0720],
        [-1.2253, -1.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050958018749952316
Epoch 0, Step 146: train/loss = 0.6221449375152588, train/raw-loss = 0.5996654629707336, train/logprobs = tensor([[-0.8807, -0.8967],
        [-1.3357, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044959042221307755
Epoch 0, Step 147: train/loss = 0.6158437728881836, train/raw-loss = 0.5900602340698242, train/logprobs = tensor([[-0.8798, -1.8033],
        [-1.2133, -1.6632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051567092537879944
Epoch 0, Step 148: train/loss = 0.6439080238342285, train/raw-loss = 0.6238827109336853, train/logprobs = tensor([[-1.1929, -1.3743],
        [-1.5013, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040050603449344635
Epoch 0, Step 149: train/loss = 0.6345815658569336, train/raw-loss = 0.6128742694854736, train/logprobs = tensor([[-0.7384, -0.6963],
        [-1.0276, -0.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04341455549001694
Epoch 0, Step 150: train/loss = 0.6175366044044495, train/raw-loss = 0.5921809673309326, train/logprobs = tensor([[-0.7440, -1.4248],
        [-1.0224, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05071127414703369
Epoch 0, Step 151: train/loss = 0.6059547066688538, train/raw-loss = 0.5827414393424988, train/logprobs = tensor([[-0.9232, -1.5760],
        [-1.3200, -1.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046426497399806976
Epoch 0, Step 152: train/loss = 0.6294983625411987, train/raw-loss = 0.6063247919082642, train/logprobs = tensor([[-1.1963, -1.1498],
        [-1.4075, -0.9749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04634708911180496
Epoch 0, Step 153: train/loss = 0.6262010335922241, train/raw-loss = 0.5997053980827332, train/logprobs = tensor([[-1.1783, -1.6488],
        [-1.6975, -1.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052991196513175964
Epoch 0, Step 154: train/loss = 0.5936410427093506, train/raw-loss = 0.5701354742050171, train/logprobs = tensor([[-0.9524, -1.1214],
        [-1.3703, -0.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04701107367873192
Epoch 0, Step 155: train/loss = 0.6342689990997314, train/raw-loss = 0.6125361323356628, train/logprobs = tensor([[-1.0271, -1.3943],
        [-1.1943, -1.2189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04346567392349243
Epoch 0, Step 156: train/loss = 0.6636933088302612, train/raw-loss = 0.640738844871521, train/logprobs = tensor([[-0.5576, -1.1949],
        [-0.6495, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045908913016319275
Epoch 0, Step 157: train/loss = 0.6934532523155212, train/raw-loss = 0.672465443611145, train/logprobs = tensor([[-0.7722, -1.0291],
        [-0.8599, -1.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04197556897997856
Epoch 0, Step 158: train/loss = 0.6624473929405212, train/raw-loss = 0.646240234375, train/logprobs = tensor([[-1.3796, -1.0470],
        [-1.4890, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03241429105401039
Epoch 0, Step 159: train/loss = 0.6512361764907837, train/raw-loss = 0.6289440393447876, train/logprobs = tensor([[-0.8565, -1.0921],
        [-1.0766, -1.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04458436742424965
Epoch 0, Step 160: train/loss = 0.6924801468849182, train/raw-loss = 0.6624334454536438, train/logprobs = tensor([[-0.5716, -1.5604],
        [-0.6106, -1.4729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06009344756603241
Epoch 0, Step 161: train/loss = 0.6141704320907593, train/raw-loss = 0.5839524269104004, train/logprobs = tensor([[-1.1983, -1.2836],
        [-1.5053, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060436051338911057
Epoch 0, Step 162: train/loss = 0.6891657114028931, train/raw-loss = 0.6647789478302002, train/logprobs = tensor([[-0.6353, -1.0502],
        [-0.6463, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04877355322241783
Epoch 0, Step 163: train/loss = 0.6553866863250732, train/raw-loss = 0.6179168224334717, train/logprobs = tensor([[-0.9409, -0.9605],
        [-1.3461, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07493981719017029
Epoch 0, Step 164: train/loss = 0.728958249092102, train/raw-loss = 0.6984366774559021, train/logprobs = tensor([[-0.9691, -1.1579],
        [-0.9792, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06104319542646408
Epoch 0, Step 165: train/loss = 0.6886811852455139, train/raw-loss = 0.6522336602210999, train/logprobs = tensor([[-0.8403, -1.4574],
        [-0.9421, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0728950947523117
Epoch 0, Step 166: train/loss = 0.6464788913726807, train/raw-loss = 0.6185599565505981, train/logprobs = tensor([[-0.8926, -1.4293],
        [-1.0027, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05583791807293892
Epoch 0, Step 167: train/loss = 0.6148115992546082, train/raw-loss = 0.5735065937042236, train/logprobs = tensor([[-0.7169, -1.8122],
        [-0.9245, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261008560657501
Epoch 0, Step 168: train/loss = 0.5878908634185791, train/raw-loss = 0.5526388883590698, train/logprobs = tensor([[-1.0399, -0.8382],
        [-1.6054, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07050401717424393
Epoch 0, Step 169: train/loss = 0.601486086845398, train/raw-loss = 0.5620951056480408, train/logprobs = tensor([[-1.0116, -0.8303],
        [-1.4413, -0.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07878194749355316
Epoch 0, Step 170: train/loss = 0.6794321537017822, train/raw-loss = 0.6543607711791992, train/logprobs = tensor([[-0.8848, -1.0585],
        [-0.9308, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050142835825681686
Epoch 0, Step 171: train/loss = 0.5763440132141113, train/raw-loss = 0.5403851270675659, train/logprobs = tensor([[-0.7484, -1.1383],
        [-1.2652, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719178095459938
Epoch 0, Step 172: train/loss = 0.6184349060058594, train/raw-loss = 0.5917685627937317, train/logprobs = tensor([[-0.8593, -1.1466],
        [-1.1412, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053332678973674774
Epoch 0, Step 173: train/loss = 0.5500422716140747, train/raw-loss = 0.5132853388786316, train/logprobs = tensor([[-1.4257, -2.0463],
        [-1.9160, -1.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07351379841566086
Epoch 0, Step 174: train/loss = 0.6429866552352905, train/raw-loss = 0.613379716873169, train/logprobs = tensor([[-0.7710, -1.1646],
        [-0.9215, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05921377241611481
Epoch 0, Step 175: train/loss = 0.5764902234077454, train/raw-loss = 0.542304277420044, train/logprobs = tensor([[-0.9949, -1.9470],
        [-1.4719, -1.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06837189942598343
Epoch 0, Step 176: train/loss = 0.6716655492782593, train/raw-loss = 0.6449708938598633, train/logprobs = tensor([[-0.8486, -2.1569],
        [-0.9193, -2.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05338945612311363
Epoch 0, Step 177: train/loss = 0.6904051303863525, train/raw-loss = 0.6586962342262268, train/logprobs = tensor([[-0.8195, -1.4366],
        [-0.8616, -1.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06341782957315445
Epoch 0, Step 178: train/loss = 0.6920838952064514, train/raw-loss = 0.6647462844848633, train/logprobs = tensor([[-1.1226, -1.5261],
        [-1.2731, -1.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054675254970788956
Epoch 0, Step 179: train/loss = 0.5959951281547546, train/raw-loss = 0.5544714331626892, train/logprobs = tensor([[-1.2139, -2.2451],
        [-1.6924, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830472782254219
Epoch 0, Step 180: train/loss = 0.597421407699585, train/raw-loss = 0.5667294859886169, train/logprobs = tensor([[-0.7251, -1.0998],
        [-1.1091, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061383895576000214
Epoch 0, Step 181: train/loss = 0.7048696279525757, train/raw-loss = 0.6755533218383789, train/logprobs = tensor([[-1.0658, -1.3201],
        [-1.0263, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058632805943489075
Epoch 0, Step 182: train/loss = 0.6992509365081787, train/raw-loss = 0.6730108261108398, train/logprobs = tensor([[-2.0461, -2.2088],
        [-2.1072, -2.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05248032882809639
Epoch 0, Step 183: train/loss = 0.6273479461669922, train/raw-loss = 0.6022371649742126, train/logprobs = tensor([[-0.7397, -0.8119],
        [-1.0793, -0.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05022159218788147
Epoch 0, Step 184: train/loss = 0.641043484210968, train/raw-loss = 0.6126702427864075, train/logprobs = tensor([[-0.9210, -1.3553],
        [-1.1750, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05674653500318527
Epoch 0, Step 185: train/loss = 0.6160520315170288, train/raw-loss = 0.5915384292602539, train/logprobs = tensor([[-0.9947, -1.3478],
        [-1.2880, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049027204513549805
Epoch 0, Step 186: train/loss = 0.707703709602356, train/raw-loss = 0.6819396615028381, train/logprobs = tensor([[-0.6304, -1.3618],
        [-0.6261, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05152811110019684
Epoch 0, Step 187: train/loss = 0.6443709135055542, train/raw-loss = 0.6113177537918091, train/logprobs = tensor([[-0.9153, -0.9888],
        [-1.1327, -0.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0661064013838768
Epoch 0, Step 188: train/loss = 0.6813430190086365, train/raw-loss = 0.6485329866409302, train/logprobs = tensor([[-1.1149, -1.0376],
        [-1.3239, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06562019884586334
Epoch 0, Step 189: train/loss = 0.6860172748565674, train/raw-loss = 0.6566359400749207, train/logprobs = tensor([[-0.6825, -1.1509],
        [-0.7051, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05876275897026062
Epoch 0, Step 190: train/loss = 0.6233350038528442, train/raw-loss = 0.5898700952529907, train/logprobs = tensor([[-0.6653, -1.5399],
        [-0.9265, -1.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0669298768043518
Epoch 0, Step 191: train/loss = 0.5923020243644714, train/raw-loss = 0.5546826720237732, train/logprobs = tensor([[-0.7985, -1.9086],
        [-1.0758, -1.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07523870468139648
Epoch 0, Step 192: train/loss = 0.6423842906951904, train/raw-loss = 0.6044046878814697, train/logprobs = tensor([[-0.9827, -2.7295],
        [-1.1180, -2.3292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07595932483673096
Epoch 0, Step 193: train/loss = 0.6139156222343445, train/raw-loss = 0.5688979029655457, train/logprobs = tensor([[-0.7942, -1.5491],
        [-0.8146, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09003537148237228
Epoch 0, Step 194: train/loss = 0.6795601844787598, train/raw-loss = 0.6478943824768066, train/logprobs = tensor([[-0.9246, -1.0152],
        [-0.9868, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06333156675100327
Epoch 0, Step 195: train/loss = 0.6845198273658752, train/raw-loss = 0.6515060663223267, train/logprobs = tensor([[-0.5978, -1.2984],
        [-0.6200, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06602762639522552
Epoch 0, Step 196: train/loss = 0.6418510675430298, train/raw-loss = 0.608384370803833, train/logprobs = tensor([[-0.6227, -1.2028],
        [-0.7419, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06693337112665176
Epoch 0, Step 197: train/loss = 0.5829636454582214, train/raw-loss = 0.535273551940918, train/logprobs = tensor([[-0.6619, -1.9116],
        [-1.0072, -1.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0953802615404129
Epoch 0, Step 198: train/loss = 0.5252100229263306, train/raw-loss = 0.467202752828598, train/logprobs = tensor([[-0.8727, -1.9249],
        [-1.4002, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11601464450359344
Epoch 0, Step 199: train/loss = 0.5751153826713562, train/raw-loss = 0.5268360376358032, train/logprobs = tensor([[-0.9751, -1.5579],
        [-1.5387, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09655873477458954
Epoch 0, Step 200: train/loss = 0.5763663649559021, train/raw-loss = 0.5246639251708984, train/logprobs = tensor([[-0.8164, -1.1237],
        [-1.3518, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034049540758133
Epoch 0, Step 201: train/loss = 0.5282188653945923, train/raw-loss = 0.4821816384792328, train/logprobs = tensor([[-0.8311, -2.9488],
        [-1.0218, -1.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09207453578710556
Epoch 0, Step 202: train/loss = 0.6653497219085693, train/raw-loss = 0.6321883201599121, train/logprobs = tensor([[-0.5837, -0.7924],
        [-0.6953, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06632286310195923
Epoch 0, Step 203: train/loss = 0.5553064942359924, train/raw-loss = 0.5102560520172119, train/logprobs = tensor([[-0.9999, -1.6674],
        [-1.5796, -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09010088443756104
Epoch 0, Step 204: train/loss = 0.5025058388710022, train/raw-loss = 0.44846248626708984, train/logprobs = tensor([[-1.0467, -1.5540],
        [-1.9738, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10808675736188889
Epoch 0, Step 205: train/loss = 0.6764761805534363, train/raw-loss = 0.6386987566947937, train/logprobs = tensor([[-0.8115, -1.2362],
        [-0.7930, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07555477321147919
Epoch 0, Step 206: train/loss = 0.6730893850326538, train/raw-loss = 0.642043948173523, train/logprobs = tensor([[-0.8551, -1.1911],
        [-0.8418, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062090884894132614
Epoch 0, Step 207: train/loss = 0.5010778903961182, train/raw-loss = 0.4571593999862671, train/logprobs = tensor([[-0.8456, -2.9778],
        [-1.1538, -1.9585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08783695846796036
Epoch 0, Step 208: train/loss = 0.5528755187988281, train/raw-loss = 0.4974867105484009, train/logprobs = tensor([[-0.8519, -1.4600],
        [-1.4713, -1.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11077752709388733
Epoch 0, Step 209: train/loss = 0.588945209980011, train/raw-loss = 0.542506217956543, train/logprobs = tensor([[-0.9051, -1.4007],
        [-1.3445, -1.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09287804365158081
Epoch 0, Step 210: train/loss = 0.5944287776947021, train/raw-loss = 0.5411927103996277, train/logprobs = tensor([[-1.0490, -2.0102],
        [-1.3495, -1.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10647208243608475
Epoch 0, Step 211: train/loss = 0.5655646920204163, train/raw-loss = 0.518867015838623, train/logprobs = tensor([[-1.0226, -2.7549],
        [-1.3249, -2.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339527785778046
Epoch 0, Step 212: train/loss = 0.7121652960777283, train/raw-loss = 0.655854344367981, train/logprobs = tensor([[-0.6615, -1.2915],
        [-1.0098, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11262193322181702
Epoch 0, Step 213: train/loss = 0.5779987573623657, train/raw-loss = 0.5294833183288574, train/logprobs = tensor([[-0.9123, -2.2689],
        [-1.4081, -1.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09703082591295242
Epoch 0, Step 214: train/loss = 0.6305932402610779, train/raw-loss = 0.5850334763526917, train/logprobs = tensor([[-0.9148, -2.3526],
        [-1.0399, -1.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111950546503067
Epoch 0, Step 215: train/loss = 0.649936318397522, train/raw-loss = 0.608579158782959, train/logprobs = tensor([[-0.9168, -1.2754],
        [-1.1105, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0827142521739006
Epoch 0, Step 216: train/loss = 0.5588173270225525, train/raw-loss = 0.5066463947296143, train/logprobs = tensor([[-0.8183, -1.9097],
        [-0.9565, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434193909168243
Epoch 0, Step 217: train/loss = 0.6395758390426636, train/raw-loss = 0.5995528697967529, train/logprobs = tensor([[-0.7075, -1.4178],
        [-0.8688, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800459161400795
Epoch 0, Step 218: train/loss = 0.6118525266647339, train/raw-loss = 0.5685720443725586, train/logprobs = tensor([[-0.9567, -0.9430],
        [-1.3991, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0865609422326088
Epoch 0, Step 219: train/loss = 0.6320607662200928, train/raw-loss = 0.5935128927230835, train/logprobs = tensor([[-1.1595, -1.4328],
        [-1.6057, -1.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770956501364708
Epoch 0, Step 220: train/loss = 0.6837446093559265, train/raw-loss = 0.6375501155853271, train/logprobs = tensor([[-0.9741, -1.5152],
        [-1.0612, -1.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09238890558481216
Epoch 0, Step 221: train/loss = 0.6355615854263306, train/raw-loss = 0.5966619253158569, train/logprobs = tensor([[-0.6600, -0.7027],
        [-1.0646, -0.5706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07779938727617264
Epoch 0, Step 222: train/loss = 0.61780846118927, train/raw-loss = 0.5666117072105408, train/logprobs = tensor([[-1.5471, -1.6592],
        [-2.1514, -1.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10239353775978088
Epoch 0, Step 223: train/loss = 0.519554615020752, train/raw-loss = 0.4671337604522705, train/logprobs = tensor([[-0.8546, -2.6163],
        [-1.3266, -1.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484175384044647
Epoch 0, Step 224: train/loss = 0.47531697154045105, train/raw-loss = 0.4086763262748718, train/logprobs = tensor([[-0.8698, -2.2609],
        [-1.5515, -1.3963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13328133523464203
Epoch 0, Step 225: train/loss = 0.6509037017822266, train/raw-loss = 0.5897262692451477, train/logprobs = tensor([[-0.7187, -1.8934],
        [-0.7169, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12235480546951294
Epoch 0, Step 226: train/loss = 0.6199845671653748, train/raw-loss = 0.563992977142334, train/logprobs = tensor([[-0.7444, -1.2491],
        [-0.7901, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11198318004608154
Epoch 0, Step 227: train/loss = 0.4558447599411011, train/raw-loss = 0.39471670985221863, train/logprobs = tensor([[-1.4059, -2.5002],
        [-2.3664, -1.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12225613743066788
Epoch 0, Step 228: train/loss = 0.5864259004592896, train/raw-loss = 0.5231401324272156, train/logprobs = tensor([[-0.9458, -1.7054],
        [-1.2215, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265714466571808
Epoch 0, Step 229: train/loss = 0.567078709602356, train/raw-loss = 0.5040980577468872, train/logprobs = tensor([[-0.8823, -1.5662],
        [-1.3359, -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12596119940280914
Epoch 0, Step 230: train/loss = 0.6172884702682495, train/raw-loss = 0.5599128007888794, train/logprobs = tensor([[-0.7454, -1.5020],
        [-0.8394, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11475133150815964
Epoch 0, Step 231: train/loss = 0.6865750551223755, train/raw-loss = 0.6264563798904419, train/logprobs = tensor([[-0.8389, -1.1595],
        [-0.7768, -0.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12023743242025375
Epoch 0, Step 232: train/loss = 0.5404962301254272, train/raw-loss = 0.4833269715309143, train/logprobs = tensor([[-0.7222, -1.8560],
        [-1.1131, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11433850973844528
Epoch 0, Step 233: train/loss = 0.5661358833312988, train/raw-loss = 0.5086506605148315, train/logprobs = tensor([[-0.8710, -1.4511],
        [-1.5311, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11497056484222412
Epoch 0, Step 234: train/loss = 0.5860260128974915, train/raw-loss = 0.5325080752372742, train/logprobs = tensor([[-0.7706, -1.4916],
        [-1.1802, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1070358082652092
Epoch 0, Step 235: train/loss = 0.6121835112571716, train/raw-loss = 0.5644323825836182, train/logprobs = tensor([[-0.9433, -0.9871],
        [-1.2130, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550224989652634
Epoch 0, Step 236: train/loss = 0.5760281085968018, train/raw-loss = 0.5209899544715881, train/logprobs = tensor([[-0.6802, -1.6717],
        [-0.7156, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11007629334926605
Epoch 0, Step 237: train/loss = 0.5498316884040833, train/raw-loss = 0.49443599581718445, train/logprobs = tensor([[-0.7807, -2.0959],
        [-1.2937, -1.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11079134792089462
Epoch 0, Step 238: train/loss = 0.5510300397872925, train/raw-loss = 0.49089735746383667, train/logprobs = tensor([[-0.7097, -2.4070],
        [-1.0519, -1.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026545405387878
Epoch 0, Step 239: train/loss = 0.6310057640075684, train/raw-loss = 0.5701788663864136, train/logprobs = tensor([[-1.0391, -1.2920],
        [-1.2647, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12165386974811554
Epoch 0, Step 240: train/loss = 0.5888439416885376, train/raw-loss = 0.5310169458389282, train/logprobs = tensor([[-0.7962, -1.9508],
        [-0.8503, -1.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11565396189689636
Epoch 0, Step 241: train/loss = 0.5733321309089661, train/raw-loss = 0.5152850151062012, train/logprobs = tensor([[-0.8232, -1.8740],
        [-1.2178, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11609430611133575
Epoch 0, Step 242: train/loss = 0.5492209196090698, train/raw-loss = 0.48259180784225464, train/logprobs = tensor([[-0.8097, -2.6374],
        [-0.7501, -1.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13325828313827515
Epoch 0, Step 243: train/loss = 0.549332320690155, train/raw-loss = 0.4879809021949768, train/logprobs = tensor([[-0.8323, -1.7465],
        [-1.2261, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12270287424325943
Epoch 0, Step 244: train/loss = 0.5377233028411865, train/raw-loss = 0.48064473271369934, train/logprobs = tensor([[-0.8811, -2.2646],
        [-0.9391, -1.2807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11415718495845795
Epoch 0, Step 245: train/loss = 0.6109875440597534, train/raw-loss = 0.5521101951599121, train/logprobs = tensor([[-0.8959, -1.3517],
        [-1.1286, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11775472015142441
Epoch 0, Step 246: train/loss = 0.630078911781311, train/raw-loss = 0.574730396270752, train/logprobs = tensor([[-1.0376, -1.8357],
        [-0.9689, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11069700866937637
Epoch 0, Step 247: train/loss = 0.571028470993042, train/raw-loss = 0.5010240077972412, train/logprobs = tensor([[-0.9230, -1.4416],
        [-1.2385, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14000892639160156
Epoch 0, Step 248: train/loss = 0.4988188147544861, train/raw-loss = 0.43040981888771057, train/logprobs = tensor([[-0.7931, -2.0574],
        [-1.3530, -1.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368180215358734
Epoch 0, Step 249: train/loss = 0.6190581917762756, train/raw-loss = 0.5659924149513245, train/logprobs = tensor([[-0.9361, -1.9594],
        [-0.9257, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1061316505074501
Epoch 0, Step 250: train/loss = 0.6386793851852417, train/raw-loss = 0.5764834880828857, train/logprobs = tensor([[-0.9676, -1.3790],
        [-1.2391, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12439175695180893
Epoch 0, Step 251: train/loss = 0.511367678642273, train/raw-loss = 0.4441787600517273, train/logprobs = tensor([[-1.0186, -1.4689],
        [-1.8812, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13437777757644653
Epoch 0, Step 252: train/loss = 0.601197361946106, train/raw-loss = 0.5421661138534546, train/logprobs = tensor([[-1.1900, -1.9231],
        [-1.3501, -1.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11806253343820572
Epoch 0, Step 253: train/loss = 0.424442321062088, train/raw-loss = 0.349229633808136, train/logprobs = tensor([[-1.0470, -3.0364],
        [-1.9007, -2.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15042538940906525
Epoch 0, Step 254: train/loss = 0.5496253967285156, train/raw-loss = 0.48616719245910645, train/logprobs = tensor([[-0.8860, -1.7290],
        [-1.2088, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12691640853881836
Epoch 0, Step 255: train/loss = 0.6607269048690796, train/raw-loss = 0.6011649370193481, train/logprobs = tensor([[-1.2813, -1.5924],
        [-1.3227, -1.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191239207983017
Epoch 0, Step 256: train/loss = 0.567152202129364, train/raw-loss = 0.48877060413360596, train/logprobs = tensor([[-0.9898, -1.5593],
        [-1.3784, -0.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15676315128803253
Epoch 0, Step 257: train/loss = 0.5287968516349792, train/raw-loss = 0.45871391892433167, train/logprobs = tensor([[-0.8548, -1.6691],
        [-1.2027, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14016592502593994
Epoch 0, Step 258: train/loss = 0.5318041443824768, train/raw-loss = 0.4734826683998108, train/logprobs = tensor([[-0.9159, -1.5341],
        [-1.5571, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664292216300964
Epoch 0, Step 259: train/loss = 0.6860015392303467, train/raw-loss = 0.6124145984649658, train/logprobs = tensor([[-1.2568, -1.0178],
        [-1.4797, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471739113330841
Epoch 0, Step 260: train/loss = 0.4644480049610138, train/raw-loss = 0.3808493912220001, train/logprobs = tensor([[-0.9886, -1.9533],
        [-1.9438, -1.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16719718277454376
Epoch 0, Step 261: train/loss = 0.4539525806903839, train/raw-loss = 0.37760424613952637, train/logprobs = tensor([[-0.8121, -1.9765],
        [-1.5439, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526966392993927
Epoch 0, Step 262: train/loss = 0.39487558603286743, train/raw-loss = 0.31878554821014404, train/logprobs = tensor([[-0.8841, -2.1015],
        [-1.9396, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152180016040802
Epoch 0, Step 263: train/loss = 0.43993550539016724, train/raw-loss = 0.36299484968185425, train/logprobs = tensor([[-1.2444, -1.4109],
        [-2.6884, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1538812667131424
Epoch 0, Step 264: train/loss = 0.5142077207565308, train/raw-loss = 0.44171571731567383, train/logprobs = tensor([[-1.1856, -2.6718],
        [-1.8137, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14498397707939148
Epoch 0, Step 265: train/loss = 0.443506121635437, train/raw-loss = 0.35783708095550537, train/logprobs = tensor([[-1.1787, -3.3840],
        [-2.0595, -1.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17133808135986328
Epoch 0, Step 266: train/loss = 0.6800310015678406, train/raw-loss = 0.6062377691268921, train/logprobs = tensor([[-1.6996, -2.1957],
        [-1.6129, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14758647978305817
Epoch 0, Step 267: train/loss = 0.4849889278411865, train/raw-loss = 0.4148763120174408, train/logprobs = tensor([[-0.8390, -1.5249],
        [-1.6839, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14022523164749146
Epoch 0, Step 268: train/loss = 0.6199887990951538, train/raw-loss = 0.5635520219802856, train/logprobs = tensor([[-1.1112, -2.0550],
        [-0.9128, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11287356168031693
Epoch 0, Step 269: train/loss = 0.6434180736541748, train/raw-loss = 0.5861086249351501, train/logprobs = tensor([[-0.7298, -1.3934],
        [-0.7362, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11461883783340454
Epoch 0, Step 270: train/loss = 0.586030125617981, train/raw-loss = 0.5271981954574585, train/logprobs = tensor([[-0.6270, -1.6508],
        [-0.5921, -0.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11766386777162552
Epoch 0, Step 271: train/loss = 0.5788387060165405, train/raw-loss = 0.5085565447807312, train/logprobs = tensor([[-0.8827, -1.9712],
        [-0.9177, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1405642330646515
Epoch 0, Step 272: train/loss = 0.5278156399726868, train/raw-loss = 0.46215227246284485, train/logprobs = tensor([[-0.8207, -1.9655],
        [-1.3113, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13132674992084503
Epoch 0, Step 273: train/loss = 0.5197227001190186, train/raw-loss = 0.4333520829677582, train/logprobs = tensor([[-0.9486, -1.4655],
        [-1.6323, -0.7413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17274132370948792
Epoch 0, Step 274: train/loss = 0.6731178760528564, train/raw-loss = 0.5994877815246582, train/logprobs = tensor([[-1.1005, -1.0705],
        [-1.5814, -1.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472601741552353
Epoch 0, Step 275: train/loss = 0.5149450898170471, train/raw-loss = 0.4492444694042206, train/logprobs = tensor([[-0.9313, -2.1609],
        [-1.2649, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314011961221695
Epoch 0, Step 276: train/loss = 0.5429007411003113, train/raw-loss = 0.47534358501434326, train/logprobs = tensor([[-1.0165, -1.6776],
        [-1.5505, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351143717765808
Epoch 0, Step 277: train/loss = 0.48468703031539917, train/raw-loss = 0.41176360845565796, train/logprobs = tensor([[-1.2713, -1.8684],
        [-1.8981, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14584676921367645
Epoch 0, Step 278: train/loss = 0.6321060657501221, train/raw-loss = 0.5667004585266113, train/logprobs = tensor([[-0.9774, -1.2870],
        [-1.2105, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308111995458603
Epoch 0, Step 279: train/loss = 0.5978617668151855, train/raw-loss = 0.5251816511154175, train/logprobs = tensor([[-0.9159, -2.0428],
        [-1.2740, -1.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14536023139953613
Epoch 0, Step 280: train/loss = 0.6632364988327026, train/raw-loss = 0.5895155668258667, train/logprobs = tensor([[-1.3687, -1.5628],
        [-1.1335, -0.7175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474418044090271
Epoch 0, Step 281: train/loss = 0.6195205450057983, train/raw-loss = 0.5476341843605042, train/logprobs = tensor([[-0.8964, -1.0116],
        [-1.3257, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.143772691488266
Epoch 0, Step 282: train/loss = 0.5877334475517273, train/raw-loss = 0.5229388475418091, train/logprobs = tensor([[-1.2133, -2.1413],
        [-1.6878, -1.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295892596244812
Epoch 0, Step 283: train/loss = 0.6047402620315552, train/raw-loss = 0.5445623993873596, train/logprobs = tensor([[-0.8139, -1.4910],
        [-1.0480, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12035590410232544
Epoch 0, Step 284: train/loss = 0.5420372486114502, train/raw-loss = 0.47208020091056824, train/logprobs = tensor([[-1.1472, -1.8058],
        [-1.3726, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13991418480873108
Epoch 0, Step 285: train/loss = 0.6149893999099731, train/raw-loss = 0.541342556476593, train/logprobs = tensor([[-1.2132, -1.4085],
        [-1.7397, -1.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14729362726211548
Epoch 0, Step 286: train/loss = 0.46464625000953674, train/raw-loss = 0.3972232937812805, train/logprobs = tensor([[-1.1053, -2.6119],
        [-1.4553, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13484591245651245
Epoch 0, Step 287: train/loss = 0.5825542211532593, train/raw-loss = 0.5205217599868774, train/logprobs = tensor([[-1.8119, -3.2176],
        [-1.4796, -1.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12406505644321442
Epoch 0, Step 288: train/loss = 0.5229959487915039, train/raw-loss = 0.4553123712539673, train/logprobs = tensor([[-1.0203, -1.8708],
        [-1.4055, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13536716997623444
Epoch 0, Step 289: train/loss = 0.4798433482646942, train/raw-loss = 0.4151422679424286, train/logprobs = tensor([[-0.8766, -2.0063],
        [-1.5851, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12940208613872528
Epoch 0, Step 290: train/loss = 0.5803936123847961, train/raw-loss = 0.5200543403625488, train/logprobs = tensor([[-0.9815, -1.5146],
        [-1.2267, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12067854404449463
Epoch 0, Step 291: train/loss = 0.5885395407676697, train/raw-loss = 0.5264294743537903, train/logprobs = tensor([[-1.3404, -2.0712],
        [-1.3998, -1.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12422016263008118
Epoch 0, Step 292: train/loss = 0.5996031761169434, train/raw-loss = 0.5285110473632812, train/logprobs = tensor([[-0.8262, -1.2388],
        [-1.1114, -0.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1421842873096466
Epoch 0, Step 293: train/loss = 0.5339455604553223, train/raw-loss = 0.4618929922580719, train/logprobs = tensor([[-0.8911, -2.3138],
        [-1.1213, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441051959991455
Epoch 0, Step 294: train/loss = 0.6435016393661499, train/raw-loss = 0.57921302318573, train/logprobs = tensor([[-0.8134, -1.0976],
        [-1.0758, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12857726216316223
Epoch 0, Step 295: train/loss = 0.5183340311050415, train/raw-loss = 0.4447828531265259, train/logprobs = tensor([[-0.9869, -2.3459],
        [-1.7761, -1.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471024602651596
Epoch 0, Step 296: train/loss = 0.5850937962532043, train/raw-loss = 0.5035568475723267, train/logprobs = tensor([[-1.3075, -1.6771],
        [-1.8980, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16307388246059418
Epoch 0, Step 297: train/loss = 0.5016735792160034, train/raw-loss = 0.42316263914108276, train/logprobs = tensor([[-0.9786, -2.3269],
        [-1.2263, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15702196955680847
Epoch 0, Step 298: train/loss = 0.5050391554832458, train/raw-loss = 0.4283384382724762, train/logprobs = tensor([[-1.0239, -1.8412],
        [-1.4911, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534014791250229
Epoch 0, Step 299: train/loss = 0.5863484740257263, train/raw-loss = 0.5215993523597717, train/logprobs = tensor([[-1.1101, -1.3514],
        [-1.7553, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294981986284256
Epoch 0, Step 300: train/loss = 0.37106430530548096, train/raw-loss = 0.28185027837753296, train/logprobs = tensor([[-1.2300, -2.6481],
        [-2.2477, -1.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1784280240535736
Epoch 0, Step 301: train/loss = 0.43312910199165344, train/raw-loss = 0.3523074686527252, train/logprobs = tensor([[-0.8489, -2.3620],
        [-1.3601, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16164329648017883
Epoch 0, Step 302: train/loss = 0.47759389877319336, train/raw-loss = 0.40102335810661316, train/logprobs = tensor([[-1.6363, -2.2579],
        [-2.2716, -1.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15314118564128876
Epoch 0, Step 303: train/loss = 0.5448122024536133, train/raw-loss = 0.46580183506011963, train/logprobs = tensor([[-0.6220, -1.3821],
        [-0.9960, -0.6138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15802070498466492
Epoch 0, Step 304: train/loss = 0.5337615013122559, train/raw-loss = 0.44895172119140625, train/logprobs = tensor([[-1.0121, -1.9136],
        [-1.5158, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16961956024169922
Epoch 0, Step 305: train/loss = 0.5924136638641357, train/raw-loss = 0.5326316952705383, train/logprobs = tensor([[-1.1412, -3.6417],
        [-1.1489, -2.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11956395953893661
Epoch 0, Step 306: train/loss = 0.688465416431427, train/raw-loss = 0.6472951769828796, train/logprobs = tensor([[-0.4765, -0.7217],
        [-0.5052, -0.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08234050869941711
Epoch 0, Step 307: train/loss = 0.454994261264801, train/raw-loss = 0.38069066405296326, train/logprobs = tensor([[-0.9585, -1.8674],
        [-1.7915, -0.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14860719442367554
Epoch 0, Step 308: train/loss = 0.5604439377784729, train/raw-loss = 0.496336430311203, train/logprobs = tensor([[-0.8214, -1.7943],
        [-1.2338, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12821507453918457
Epoch 0, Step 309: train/loss = 0.5965902805328369, train/raw-loss = 0.5330289602279663, train/logprobs = tensor([[-0.8616, -1.6071],
        [-0.8382, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12712258100509644
Epoch 0, Step 310: train/loss = 0.46559396386146545, train/raw-loss = 0.40525317192077637, train/logprobs = tensor([[-1.5805, -4.7976],
        [-1.4294, -2.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12068162858486176
Epoch 0, Step 311: train/loss = 0.5318049192428589, train/raw-loss = 0.4576951861381531, train/logprobs = tensor([[-1.5912, -2.2070],
        [-2.0816, -1.3341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14821940660476685
Epoch 0, Step 312: train/loss = 0.46619027853012085, train/raw-loss = 0.38381895422935486, train/logprobs = tensor([[-1.1976, -1.5931],
        [-2.0476, -0.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1647425889968872
Epoch 0, Step 313: train/loss = 0.5040637850761414, train/raw-loss = 0.43262994289398193, train/logprobs = tensor([[-1.0327, -2.2314],
        [-1.1298, -0.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14286766946315765
Epoch 0, Step 314: train/loss = 0.640777587890625, train/raw-loss = 0.576003909111023, train/logprobs = tensor([[-1.0302, -1.3545],
        [-1.3037, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295473277568817
Epoch 0, Step 315: train/loss = 0.4631064832210541, train/raw-loss = 0.37582162022590637, train/logprobs = tensor([[-1.0461, -2.7419],
        [-1.4514, -1.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17456965148448944
Epoch 0, Step 316: train/loss = 0.5768256187438965, train/raw-loss = 0.5129347443580627, train/logprobs = tensor([[-0.8624, -1.6941],
        [-1.1616, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12778177857398987
Epoch 0, Step 317: train/loss = 0.5057319402694702, train/raw-loss = 0.4341740608215332, train/logprobs = tensor([[-1.1700, -2.6366],
        [-1.6696, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14311571419239044
Epoch 0, Step 318: train/loss = 0.5393290519714355, train/raw-loss = 0.4731054902076721, train/logprobs = tensor([[-0.5527, -1.7998],
        [-0.6681, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13244709372520447
Epoch 0, Step 319: train/loss = 0.4719325602054596, train/raw-loss = 0.38335150480270386, train/logprobs = tensor([[-1.2442, -1.9001],
        [-1.8551, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771620661020279
Epoch 0, Step 320: train/loss = 0.6138883829116821, train/raw-loss = 0.5428212881088257, train/logprobs = tensor([[-1.2782, -1.4781],
        [-1.9332, -1.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1421341449022293
Epoch 0, Step 321: train/loss = 0.5464035868644714, train/raw-loss = 0.49296557903289795, train/logprobs = tensor([[-1.7549, -2.5620],
        [-2.3190, -1.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10687610507011414
Epoch 0, Step 322: train/loss = 0.6327099204063416, train/raw-loss = 0.5557079911231995, train/logprobs = tensor([[-0.8492, -1.4103],
        [-1.6872, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15400394797325134
Epoch 0, Step 323: train/loss = 0.524827778339386, train/raw-loss = 0.44629839062690735, train/logprobs = tensor([[-0.9999, -1.4091],
        [-2.0087, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1570587456226349
Epoch 0, Step 324: train/loss = 0.41338732838630676, train/raw-loss = 0.3443771004676819, train/logprobs = tensor([[-1.0244, -2.4573],
        [-1.5446, -0.8409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13802051544189453
Epoch 0, Step 325: train/loss = 0.39875078201293945, train/raw-loss = 0.32100844383239746, train/logprobs = tensor([[-1.1065, -2.3180],
        [-2.1395, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15548469126224518
Epoch 0, Step 326: train/loss = 0.5842321515083313, train/raw-loss = 0.5078356266021729, train/logprobs = tensor([[-1.1551, -1.3669],
        [-1.6972, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1527930498123169
Epoch 0, Step 327: train/loss = 0.44158798456192017, train/raw-loss = 0.37928444147109985, train/logprobs = tensor([[-0.9331, -4.7758],
        [-0.8970, -2.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12460708618164062
Epoch 0, Step 328: train/loss = 0.5307230353355408, train/raw-loss = 0.47519177198410034, train/logprobs = tensor([[-0.7315, -2.1048],
        [-0.7798, -0.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1110624447464943
Epoch 0, Step 329: train/loss = 0.5500591397285461, train/raw-loss = 0.4701696038246155, train/logprobs = tensor([[-1.1155, -2.5096],
        [-2.4393, -1.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15977908670902252
Epoch 0, Step 330: train/loss = 0.5864256620407104, train/raw-loss = 0.5284568071365356, train/logprobs = tensor([[-1.1414, -1.1295],
        [-1.6124, -0.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11593768000602722
Epoch 0, Step 331: train/loss = 0.5238317251205444, train/raw-loss = 0.44756394624710083, train/logprobs = tensor([[-0.6697, -1.6760],
        [-1.2056, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.152535542845726
Epoch 0, Step 332: train/loss = 0.5854911804199219, train/raw-loss = 0.510298490524292, train/logprobs = tensor([[-1.0574, -1.4784],
        [-2.0395, -1.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1503853052854538
Epoch 0, Step 333: train/loss = 0.47802335023880005, train/raw-loss = 0.39971843361854553, train/logprobs = tensor([[-1.0455, -2.3897],
        [-1.6433, -1.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15660974383354187
Epoch 0, Step 334: train/loss = 0.5236650109291077, train/raw-loss = 0.4600890576839447, train/logprobs = tensor([[-0.8680, -2.6230],
        [-1.0042, -1.2249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12715190649032593
Epoch 0, Step 335: train/loss = 0.4780741333961487, train/raw-loss = 0.39591601490974426, train/logprobs = tensor([[-1.0353, -2.7983],
        [-1.0198, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16431619226932526
Epoch 0, Step 336: train/loss = 0.5213536620140076, train/raw-loss = 0.4289763569831848, train/logprobs = tensor([[-1.0222, -2.2454],
        [-1.9923, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18475466966629028
Epoch 0, Step 337: train/loss = 0.4925813376903534, train/raw-loss = 0.4282405376434326, train/logprobs = tensor([[-0.8198, -1.6303],
        [-1.5322, -0.8002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12868160009384155
Epoch 0, Step 338: train/loss = 0.42914021015167236, train/raw-loss = 0.34124964475631714, train/logprobs = tensor([[-1.3272, -2.5048],
        [-2.0831, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17578113079071045
Epoch 0, Step 339: train/loss = 0.4435378909111023, train/raw-loss = 0.3696185350418091, train/logprobs = tensor([[-1.0978, -2.5188],
        [-1.9176, -1.4104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14783871173858643
Epoch 0, Step 340: train/loss = 0.5104337930679321, train/raw-loss = 0.4443734884262085, train/logprobs = tensor([[-0.8260, -1.9265],
        [-1.3001, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13212062418460846
Epoch 0, Step 341: train/loss = 0.4605136215686798, train/raw-loss = 0.377185583114624, train/logprobs = tensor([[-1.3126, -2.0543],
        [-2.8460, -1.3371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16665613651275635
Epoch 0, Step 342: train/loss = 0.454864501953125, train/raw-loss = 0.3738505244255066, train/logprobs = tensor([[-1.0571, -2.0922],
        [-2.1259, -1.1546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1620279848575592
Epoch 0, Step 343: train/loss = 0.638065755367279, train/raw-loss = 0.5774604082107544, train/logprobs = tensor([[-0.9353, -1.8628],
        [-0.9216, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121061235666275
Epoch 0, Step 344: train/loss = 0.5074541568756104, train/raw-loss = 0.43944084644317627, train/logprobs = tensor([[-1.1134, -2.4148],
        [-1.7645, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13602657616138458
Epoch 0, Step 345: train/loss = 0.5156341195106506, train/raw-loss = 0.4490220844745636, train/logprobs = tensor([[-0.8517, -2.0724],
        [-0.9045, -0.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13322412967681885
Epoch 0, Step 346: train/loss = 0.5312110781669617, train/raw-loss = 0.4750984013080597, train/logprobs = tensor([[-1.1216, -2.8801],
        [-1.2145, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11222533881664276
Epoch 0, Step 347: train/loss = 0.4279614984989166, train/raw-loss = 0.3534656763076782, train/logprobs = tensor([[-0.7965, -2.8344],
        [-1.5057, -1.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14899170398712158
Epoch 0, Step 348: train/loss = 0.3487957715988159, train/raw-loss = 0.26381051540374756, train/logprobs = tensor([[-0.8007, -3.6086],
        [-1.4513, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1699705272912979
Epoch 0, Step 349: train/loss = 0.6407488584518433, train/raw-loss = 0.5820475816726685, train/logprobs = tensor([[-0.9715, -1.0876],
        [-1.3196, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11740262806415558
Epoch 0, Step 350: train/loss = 0.4779904782772064, train/raw-loss = 0.4004446268081665, train/logprobs = tensor([[-0.9074, -2.5841],
        [-1.4570, -1.4436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15509170293807983
Epoch 0, Step 351: train/loss = 0.5735659599304199, train/raw-loss = 0.4987237751483917, train/logprobs = tensor([[-1.2223, -1.2223],
        [-1.7268, -0.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968426525592804
Epoch 0, Step 352: train/loss = 0.33785727620124817, train/raw-loss = 0.24550198018550873, train/logprobs = tensor([[-1.0636, -2.9800],
        [-2.4378, -1.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18471065163612366
Epoch 0, Step 353: train/loss = 0.40008345246315, train/raw-loss = 0.3214522898197174, train/logprobs = tensor([[-1.0799, -2.6636],
        [-2.0897, -0.8862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15726235508918762
Epoch 0, Step 354: train/loss = 0.4285860061645508, train/raw-loss = 0.34856221079826355, train/logprobs = tensor([[-1.3864, -2.6135],
        [-2.1011, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16004766523838043
Epoch 0, Step 355: train/loss = 0.6880253553390503, train/raw-loss = 0.6106502413749695, train/logprobs = tensor([[-1.0608, -2.2534],
        [-1.6887, -1.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15475019812583923
Epoch 0, Step 356: train/loss = 0.546588659286499, train/raw-loss = 0.46098053455352783, train/logprobs = tensor([[-1.0904, -2.1869],
        [-1.5911, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17121613025665283
Epoch 0, Step 357: train/loss = 0.6331766843795776, train/raw-loss = 0.5793679356575012, train/logprobs = tensor([[-0.5356, -1.3454],
        [-0.5922, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10761740058660507
Epoch 0, Step 358: train/loss = 0.4557984471321106, train/raw-loss = 0.38936495780944824, train/logprobs = tensor([[-0.8556, -2.8367],
        [-1.2444, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328669935464859
Epoch 0, Step 359: train/loss = 0.5902353525161743, train/raw-loss = 0.509251594543457, train/logprobs = tensor([[-0.9037, -1.9520],
        [-1.6309, -1.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196756064891815
Epoch 0, Step 360: train/loss = 0.5515589714050293, train/raw-loss = 0.48519325256347656, train/logprobs = tensor([[-0.8311, -2.4490],
        [-1.0231, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13273145258426666
Epoch 0, Step 361: train/loss = 0.45399343967437744, train/raw-loss = 0.37482088804244995, train/logprobs = tensor([[-0.8575, -2.5947],
        [-1.4076, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15834510326385498
Epoch 0, Step 362: train/loss = 0.534236490726471, train/raw-loss = 0.46718737483024597, train/logprobs = tensor([[-0.8901, -1.9778],
        [-1.3833, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13409817218780518
Epoch 0, Step 363: train/loss = 0.4139576256275177, train/raw-loss = 0.3302004337310791, train/logprobs = tensor([[-1.6139, -2.1071],
        [-2.7602, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.167514368891716
Epoch 0, Step 364: train/loss = 0.4828411936759949, train/raw-loss = 0.42270734906196594, train/logprobs = tensor([[-0.6837, -2.3992],
        [-1.3667, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12026766687631607
Epoch 0, Step 365: train/loss = 0.4516046643257141, train/raw-loss = 0.36072224378585815, train/logprobs = tensor([[-1.0214, -1.9644],
        [-2.1756, -0.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18176479637622833
Epoch 0, Step 366: train/loss = 0.4352288544178009, train/raw-loss = 0.35065147280693054, train/logprobs = tensor([[-1.3216, -1.8488],
        [-2.3762, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691548228263855
Epoch 0, Step 367: train/loss = 0.4638045132160187, train/raw-loss = 0.3842357397079468, train/logprobs = tensor([[-1.0279, -3.1967],
        [-2.0253, -1.5410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1591375172138214
Epoch 0, Step 368: train/loss = 0.38048255443573, train/raw-loss = 0.3071816861629486, train/logprobs = tensor([[-1.0254, -2.9872],
        [-1.7993, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14660178124904633
Epoch 0, Step 369: train/loss = 0.3330470621585846, train/raw-loss = 0.2548676133155823, train/logprobs = tensor([[-1.6950, -3.7235],
        [-2.5256, -1.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15635891258716583
Epoch 0, Step 370: train/loss = 0.4767421782016754, train/raw-loss = 0.4018247127532959, train/logprobs = tensor([[-1.2281, -2.9785],
        [-1.5978, -1.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.149835005402565
Epoch 0, Step 371: train/loss = 0.6688206791877747, train/raw-loss = 0.6051831245422363, train/logprobs = tensor([[-0.7076, -1.1317],
        [-0.8938, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12727509438991547
Epoch 0, Step 372: train/loss = 0.5792406797409058, train/raw-loss = 0.5097354650497437, train/logprobs = tensor([[-1.9838, -3.4200],
        [-2.3968, -2.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390104740858078
Epoch 0, Step 373: train/loss = 0.4509544372558594, train/raw-loss = 0.36742278933525085, train/logprobs = tensor([[-1.1758, -1.8734],
        [-2.4568, -0.5504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16706329584121704
Epoch 0, Step 374: train/loss = 0.46363067626953125, train/raw-loss = 0.39818620681762695, train/logprobs = tensor([[-0.9987, -1.8004],
        [-1.6550, -0.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308889389038086
Epoch 0, Step 375: train/loss = 0.686524510383606, train/raw-loss = 0.6307884454727173, train/logprobs = tensor([[-0.7287, -0.8428],
        [-0.7838, -0.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11147202551364899
Epoch 0, Step 376: train/loss = 0.6024418473243713, train/raw-loss = 0.5356845259666443, train/logprobs = tensor([[-1.8242, -1.6683],
        [-2.2876, -1.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13351470232009888
Epoch 0, Step 377: train/loss = 0.5318431854248047, train/raw-loss = 0.4621680676937103, train/logprobs = tensor([[-0.5520, -2.9522],
        [-0.7229, -1.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393503099679947
Epoch 0, Step 378: train/loss = 0.4704590439796448, train/raw-loss = 0.3817717730998993, train/logprobs = tensor([[-0.8682, -1.6145],
        [-1.8931, -0.6856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17737460136413574
Epoch 0, Step 379: train/loss = 0.48859283328056335, train/raw-loss = 0.41451144218444824, train/logprobs = tensor([[-1.4489, -2.9941],
        [-1.6054, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14816276729106903
Epoch 0, Step 380: train/loss = 0.47481879591941833, train/raw-loss = 0.40406838059425354, train/logprobs = tensor([[-1.2564, -2.4800],
        [-2.1598, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14150087535381317
Epoch 0, Step 381: train/loss = 0.38717231154441833, train/raw-loss = 0.3083900213241577, train/logprobs = tensor([[-0.9479, -2.1657],
        [-2.2044, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15756456553936005
Epoch 0, Step 382: train/loss = 0.5718404650688171, train/raw-loss = 0.49066004157066345, train/logprobs = tensor([[-0.8151, -1.1149],
        [-1.7597, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16236081719398499
Epoch 0, Step 383: train/loss = 0.49869251251220703, train/raw-loss = 0.41643190383911133, train/logprobs = tensor([[-1.0212, -1.7096],
        [-2.4997, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16452117264270782
Epoch 0, Step 384: train/loss = 0.42601320147514343, train/raw-loss = 0.34849557280540466, train/logprobs = tensor([[-0.8638, -3.5271],
        [-1.0508, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15503531694412231
Epoch 0, Step 385: train/loss = 0.29411593079566956, train/raw-loss = 0.20673826336860657, train/logprobs = tensor([[-1.5871, -2.9046],
        [-3.7586, -1.4319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17475536465644836
Epoch 0, Step 386: train/loss = 0.6931257247924805, train/raw-loss = 0.6282823085784912, train/logprobs = tensor([[-1.9264, -1.6240],
        [-2.4802, -1.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12968690693378448
Epoch 0, Step 387: train/loss = 0.296466588973999, train/raw-loss = 0.22502011060714722, train/logprobs = tensor([[-1.0400, -4.2151],
        [-1.6874, -0.9485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1428929567337036
Epoch 0, Step 388: train/loss = 0.539852499961853, train/raw-loss = 0.4652579724788666, train/logprobs = tensor([[-0.8050, -2.4939],
        [-1.0867, -1.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491890698671341
Epoch 0, Step 389: train/loss = 0.470104455947876, train/raw-loss = 0.39652806520462036, train/logprobs = tensor([[-1.4720, -3.5757],
        [-1.9270, -1.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14715275168418884
Epoch 0, Step 390: train/loss = 0.4854263663291931, train/raw-loss = 0.410416841506958, train/logprobs = tensor([[-0.8762, -2.0765],
        [-1.3847, -0.7008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15001894533634186
Epoch 0, Step 391: train/loss = 0.5039602518081665, train/raw-loss = 0.43656137585639954, train/logprobs = tensor([[-0.7670, -1.7036],
        [-1.2817, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347978115081787
Epoch 0, Step 392: train/loss = 0.33940553665161133, train/raw-loss = 0.2448800653219223, train/logprobs = tensor([[-2.0035, -2.7335],
        [-3.4654, -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18905094265937805
Epoch 0, Step 393: train/loss = 0.5440460443496704, train/raw-loss = 0.472711443901062, train/logprobs = tensor([[-1.1340, -3.1810],
        [-1.4411, -1.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14266914129257202
Epoch 0, Step 394: train/loss = 0.455059289932251, train/raw-loss = 0.37803879380226135, train/logprobs = tensor([[-0.8406, -2.9545],
        [-1.5380, -1.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15404103696346283
Epoch 0, Step 395: train/loss = 0.49111300706863403, train/raw-loss = 0.4115898609161377, train/logprobs = tensor([[-1.1941, -1.9664],
        [-2.1330, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1590462327003479
Epoch 0, Step 396: train/loss = 0.5307841300964355, train/raw-loss = 0.4561932682991028, train/logprobs = tensor([[-1.3680, -3.8452],
        [-1.4012, -1.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14918184280395508
Epoch 0, Step 397: train/loss = 0.5260474681854248, train/raw-loss = 0.4425945281982422, train/logprobs = tensor([[-1.3858, -1.2686],
        [-2.4691, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16690599918365479
Epoch 0, Step 398: train/loss = 0.3146072030067444, train/raw-loss = 0.22036266326904297, train/logprobs = tensor([[-1.1121, -2.9780],
        [-2.2984, -0.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18848904967308044
Epoch 0, Step 399: train/loss = 0.5656449794769287, train/raw-loss = 0.4825568199157715, train/logprobs = tensor([[-1.2326, -2.5520],
        [-1.8140, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16617634892463684
Epoch 0, Step 400: train/loss = 0.5090888738632202, train/raw-loss = 0.43159711360931396, train/logprobs = tensor([[-1.4441, -3.2085],
        [-1.7894, -1.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549835205078125
Epoch 0, Step 401: train/loss = 0.49018925428390503, train/raw-loss = 0.4186219573020935, train/logprobs = tensor([[-1.4063, -3.0029],
        [-1.9559, -1.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14313462376594543
Epoch 0, Step 402: train/loss = 0.5255565047264099, train/raw-loss = 0.4622075855731964, train/logprobs = tensor([[-1.0507, -1.8998],
        [-1.3224, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266978234052658
Epoch 0, Step 403: train/loss = 0.39763709902763367, train/raw-loss = 0.3097379207611084, train/logprobs = tensor([[-0.9211, -1.8405],
        [-2.6973, -0.9924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17579834163188934
Epoch 0, Step 404: train/loss = 0.332011342048645, train/raw-loss = 0.2397986352443695, train/logprobs = tensor([[-1.5580, -2.1873],
        [-3.2459, -0.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18442538380622864
Epoch 0, Step 405: train/loss = 0.5099687576293945, train/raw-loss = 0.4376439154148102, train/logprobs = tensor([[-0.7908, -1.9297],
        [-1.5365, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1446496993303299
Epoch 0, Step 406: train/loss = 0.4943596422672272, train/raw-loss = 0.4086340367794037, train/logprobs = tensor([[-1.9462, -1.9541],
        [-2.8246, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17145119607448578
Epoch 0, Step 407: train/loss = 0.48608171939849854, train/raw-loss = 0.4008316397666931, train/logprobs = tensor([[-0.7218, -2.2900],
        [-1.3455, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17050015926361084
Epoch 0, Step 408: train/loss = 0.6508711576461792, train/raw-loss = 0.582179605960846, train/logprobs = tensor([[-0.7695, -1.2988],
        [-0.9298, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13738302886486053
Epoch 0, Step 409: train/loss = 0.46897536516189575, train/raw-loss = 0.3918095529079437, train/logprobs = tensor([[-1.0372, -2.8126],
        [-1.3790, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15433160960674286
Epoch 0, Step 410: train/loss = 0.47454044222831726, train/raw-loss = 0.40671342611312866, train/logprobs = tensor([[-1.8700, -3.3013],
        [-2.3246, -1.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565409183502197
Epoch 0, Step 411: train/loss = 0.47844743728637695, train/raw-loss = 0.39822763204574585, train/logprobs = tensor([[-1.0725, -2.3328],
        [-1.6759, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16043958067893982
Epoch 0, Step 412: train/loss = 0.5505638122558594, train/raw-loss = 0.4920320510864258, train/logprobs = tensor([[-1.0703, -2.8695],
        [-1.3646, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11706347018480301
Epoch 0, Step 413: train/loss = 0.47658273577690125, train/raw-loss = 0.3835233747959137, train/logprobs = tensor([[-1.3309, -1.8784],
        [-2.0961, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18611876666545868
Epoch 0, Step 414: train/loss = 0.49151697754859924, train/raw-loss = 0.4268513321876526, train/logprobs = tensor([[-0.7743, -2.4977],
        [-0.8333, -0.7655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293313354253769
Epoch 0, Step 415: train/loss = 0.3547820448875427, train/raw-loss = 0.2698533535003662, train/logprobs = tensor([[-0.9459, -3.7316],
        [-1.4555, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16985738277435303
Epoch 0, Step 416: train/loss = 0.4398312568664551, train/raw-loss = 0.35755395889282227, train/logprobs = tensor([[-1.1129, -3.0045],
        [-2.4819, -1.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16455459594726562
Epoch 0, Step 417: train/loss = 0.7083693146705627, train/raw-loss = 0.6347214579582214, train/logprobs = tensor([[-1.6516, -1.2372],
        [-1.5395, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14729566872119904
Epoch 0, Step 418: train/loss = 0.4287452697753906, train/raw-loss = 0.33681100606918335, train/logprobs = tensor([[-1.3467, -2.9154],
        [-2.4446, -1.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18386852741241455
Epoch 0, Step 419: train/loss = 0.3269495964050293, train/raw-loss = 0.23701420426368713, train/logprobs = tensor([[-1.1374, -3.0358],
        [-2.4399, -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17987078428268433
Epoch 0, Step 420: train/loss = 0.474398672580719, train/raw-loss = 0.40507346391677856, train/logprobs = tensor([[-0.6522, -1.6768],
        [-1.8254, -0.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13865047693252563
Epoch 0, Step 421: train/loss = 0.40717849135398865, train/raw-loss = 0.3263557255268097, train/logprobs = tensor([[-0.9890, -3.6032],
        [-1.4222, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16164559125900269
Epoch 0, Step 422: train/loss = 0.47417837381362915, train/raw-loss = 0.3963717222213745, train/logprobs = tensor([[-0.7181, -2.8271],
        [-0.8168, -0.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15561328828334808
Epoch 0, Step 423: train/loss = 0.3374597132205963, train/raw-loss = 0.2564546763896942, train/logprobs = tensor([[-1.8467, -1.6940],
        [-3.8645, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1620100736618042
Epoch 0, Step 424: train/loss = 0.3001221716403961, train/raw-loss = 0.20344170928001404, train/logprobs = tensor([[-0.9333, -4.0896],
        [-1.7267, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19336090981960297
Epoch 0, Step 425: train/loss = 0.5355827212333679, train/raw-loss = 0.46129584312438965, train/logprobs = tensor([[-1.5700, -3.5497],
        [-1.3127, -1.2972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14857381582260132
Epoch 0, Step 426: train/loss = 0.5150898694992065, train/raw-loss = 0.41381293535232544, train/logprobs = tensor([[-0.9682, -1.9272],
        [-2.0841, -1.2028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2025539129972458
Epoch 0, Step 427: train/loss = 0.37079328298568726, train/raw-loss = 0.2761246860027313, train/logprobs = tensor([[-1.4589, -2.3184],
        [-2.6429, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18933722376823425
Epoch 0, Step 428: train/loss = 0.6423501968383789, train/raw-loss = 0.561060905456543, train/logprobs = tensor([[-0.8580, -0.9203],
        [-1.8100, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16257856786251068
Epoch 0, Step 429: train/loss = 0.4480120539665222, train/raw-loss = 0.3835897445678711, train/logprobs = tensor([[-0.5693, -2.8736],
        [-0.8602, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12884466350078583
Epoch 0, Step 430: train/loss = 0.4366512894630432, train/raw-loss = 0.35283955931663513, train/logprobs = tensor([[-1.3806, -1.5721],
        [-2.8267, -0.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16762344539165497
Epoch 0, Step 431: train/loss = 0.5392078757286072, train/raw-loss = 0.4605916440486908, train/logprobs = tensor([[-0.9531, -2.1980],
        [-1.3449, -0.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15723244845867157
Epoch 0, Step 432: train/loss = 0.40028390288352966, train/raw-loss = 0.32010701298713684, train/logprobs = tensor([[-0.7255, -2.9353],
        [-1.7045, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16035380959510803
Epoch 0, Step 433: train/loss = 0.4552118480205536, train/raw-loss = 0.37532180547714233, train/logprobs = tensor([[-1.1783, -1.9963],
        [-2.2718, -1.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1597800850868225
Epoch 0, Step 434: train/loss = 0.6952458620071411, train/raw-loss = 0.6005063652992249, train/logprobs = tensor([[-0.6819, -2.5694],
        [-2.0439, -1.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18947890400886536
Epoch 0, Step 435: train/loss = 0.3952336311340332, train/raw-loss = 0.3102785050868988, train/logprobs = tensor([[-1.4111, -2.5900],
        [-2.4443, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16991019248962402
Epoch 0, Step 436: train/loss = 0.5778839588165283, train/raw-loss = 0.4849177598953247, train/logprobs = tensor([[-0.9910, -2.5251],
        [-1.6196, -1.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18593230843544006
Epoch 0, Step 437: train/loss = 0.4961405396461487, train/raw-loss = 0.431553453207016, train/logprobs = tensor([[-1.0218, -2.5060],
        [-0.9981, -0.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12917426228523254
Epoch 0, Step 438: train/loss = 0.47360655665397644, train/raw-loss = 0.4070815443992615, train/logprobs = tensor([[-1.0595, -1.6298],
        [-2.0303, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13304999470710754
Epoch 0, Step 439: train/loss = 0.377941370010376, train/raw-loss = 0.30061104893684387, train/logprobs = tensor([[-0.8584, -2.5940],
        [-1.7328, -0.7171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546606719493866
Epoch 0, Step 440: train/loss = 0.6029301881790161, train/raw-loss = 0.5284668207168579, train/logprobs = tensor([[-0.9391, -1.7070],
        [-1.3558, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14892667531967163
Epoch 0, Step 441: train/loss = 0.5544659495353699, train/raw-loss = 0.4780251681804657, train/logprobs = tensor([[-1.3406, -3.2810],
        [-2.5995, -1.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15288153290748596
Epoch 0, Step 442: train/loss = 0.32816386222839355, train/raw-loss = 0.25257986783981323, train/logprobs = tensor([[-1.6606, -4.6751],
        [-2.2467, -1.4016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15116792917251587
Epoch 0, Step 443: train/loss = 0.607964038848877, train/raw-loss = 0.5347582101821899, train/logprobs = tensor([[-1.1880, -2.1840],
        [-1.0606, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14641159772872925
Epoch 0, Step 444: train/loss = 0.4842251241207123, train/raw-loss = 0.4032403230667114, train/logprobs = tensor([[-1.9645, -3.2628],
        [-2.4751, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1619696021080017
Epoch 0, Step 445: train/loss = 0.4728730022907257, train/raw-loss = 0.3984716832637787, train/logprobs = tensor([[-1.1768, -2.8961],
        [-1.6860, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880266785621643
Epoch 0, Step 446: train/loss = 0.6432133316993713, train/raw-loss = 0.5698027610778809, train/logprobs = tensor([[-0.9411, -1.6852],
        [-1.1524, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14682117104530334
Epoch 0, Step 447: train/loss = 0.31537219882011414, train/raw-loss = 0.22305545210838318, train/logprobs = tensor([[-1.0892, -3.2638],
        [-2.5196, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18463346362113953
Epoch 0, Step 448: train/loss = 0.35044121742248535, train/raw-loss = 0.26014119386672974, train/logprobs = tensor([[-0.8934, -2.9498],
        [-1.7597, -0.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18060007691383362
Epoch 0, Step 449: train/loss = 0.3810548186302185, train/raw-loss = 0.2847687304019928, train/logprobs = tensor([[-1.4451, -3.8337],
        [-3.1913, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19257211685180664
Epoch 0, Step 450: train/loss = 0.39279264211654663, train/raw-loss = 0.29402580857276917, train/logprobs = tensor([[-0.9616, -3.7769],
        [-1.6428, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1975337266921997
Epoch 0, Step 451: train/loss = 0.593537449836731, train/raw-loss = 0.5226049423217773, train/logprobs = tensor([[-0.7080, -2.8270],
        [-1.1844, -1.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1418650597333908
Epoch 0, Step 452: train/loss = 0.35530561208724976, train/raw-loss = 0.2638210356235504, train/logprobs = tensor([[-1.6244, -3.6100],
        [-2.8252, -1.4263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1829691231250763
Epoch 0, Step 453: train/loss = 0.3579525053501129, train/raw-loss = 0.2520241141319275, train/logprobs = tensor([[-1.0982, -3.2496],
        [-2.5211, -1.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21185672283172607
Epoch 0, Step 454: train/loss = 0.43851250410079956, train/raw-loss = 0.3369673788547516, train/logprobs = tensor([[-1.6524, -3.4894],
        [-2.9009, -1.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20309022068977356
Epoch 0, Step 455: train/loss = 0.8065481781959534, train/raw-loss = 0.7175824642181396, train/logprobs = tensor([[-1.3009, -3.0757],
        [-2.2020, -2.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17793145775794983
Epoch 0, Step 456: train/loss = 0.48831284046173096, train/raw-loss = 0.4141479730606079, train/logprobs = tensor([[-0.9336, -2.8346],
        [-1.8889, -1.4671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1483297348022461
Epoch 0, Step 457: train/loss = 0.5563527345657349, train/raw-loss = 0.4758334755897522, train/logprobs = tensor([[-1.0054, -2.9416],
        [-1.5191, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1610385924577713
Epoch 0, Step 458: train/loss = 0.19026325643062592, train/raw-loss = 0.09124322980642319, train/logprobs = tensor([[-1.5515, -5.9992],
        [-3.8721, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19804006814956665
Epoch 0, Step 459: train/loss = 0.505024254322052, train/raw-loss = 0.41408467292785645, train/logprobs = tensor([[-1.1132, -2.9429],
        [-2.0404, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18187913298606873
Epoch 0, Step 460: train/loss = 0.3789183795452118, train/raw-loss = 0.2976056635379791, train/logprobs = tensor([[-1.2149, -3.5527],
        [-1.9463, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16262538731098175
Epoch 0, Step 461: train/loss = 0.2558308243751526, train/raw-loss = 0.1607447862625122, train/logprobs = tensor([[-1.3233, -4.3929],
        [-2.4661, -0.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19017204642295837
Epoch 0, Step 462: train/loss = 0.4359278082847595, train/raw-loss = 0.3610658645629883, train/logprobs = tensor([[-0.9024, -2.5886],
        [-1.6650, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14972376823425293
Epoch 0, Step 463: train/loss = 0.42386770248413086, train/raw-loss = 0.34687432646751404, train/logprobs = tensor([[-0.7807, -2.2888],
        [-1.5727, -0.6627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15398672223091125
Epoch 0, Step 464: train/loss = 0.6140583157539368, train/raw-loss = 0.5507053136825562, train/logprobs = tensor([[-0.9995, -1.1442],
        [-1.9063, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12670597434043884
Epoch 0, Step 465: train/loss = 0.51995849609375, train/raw-loss = 0.44384974241256714, train/logprobs = tensor([[-1.1356, -3.1761],
        [-1.2235, -1.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522175371646881
Epoch 0, Step 466: train/loss = 0.39673808217048645, train/raw-loss = 0.31465908885002136, train/logprobs = tensor([[-0.7915, -2.9021],
        [-1.8432, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16415798664093018
Epoch 0, Step 467: train/loss = 0.43002307415008545, train/raw-loss = 0.34037142992019653, train/logprobs = tensor([[-1.9336, -2.7074],
        [-3.2458, -1.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17930319905281067
Epoch 0, Step 468: train/loss = 0.3862316608428955, train/raw-loss = 0.2997211217880249, train/logprobs = tensor([[-1.0311, -3.2815],
        [-2.1891, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17302103340625763
Epoch 0, Step 469: train/loss = 0.48642629384994507, train/raw-loss = 0.40799224376678467, train/logprobs = tensor([[-0.8330, -3.8892],
        [-1.1009, -1.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15686815977096558
Epoch 0, Step 470: train/loss = 0.45435893535614014, train/raw-loss = 0.38050106167793274, train/logprobs = tensor([[-0.9760, -3.6987],
        [-1.0467, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.147715762257576
Epoch 0, Step 471: train/loss = 0.5144244432449341, train/raw-loss = 0.43258437514305115, train/logprobs = tensor([[-1.4084, -2.3016],
        [-2.8544, -1.5185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16368016600608826
Epoch 0, Step 472: train/loss = 0.3653939962387085, train/raw-loss = 0.2779235243797302, train/logprobs = tensor([[-1.0963, -3.4605],
        [-2.3091, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17494097352027893
Epoch 0, Step 473: train/loss = 0.43594279885292053, train/raw-loss = 0.3415426015853882, train/logprobs = tensor([[-1.6014, -2.7543],
        [-2.6618, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18880048394203186
Epoch 0, Step 474: train/loss = 0.6219115257263184, train/raw-loss = 0.5279883146286011, train/logprobs = tensor([[-1.4873, -3.1210],
        [-2.1888, -2.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18784648180007935
Epoch 0, Step 475: train/loss = 0.38414400815963745, train/raw-loss = 0.2958250939846039, train/logprobs = tensor([[-1.1475, -3.4946],
        [-2.5130, -1.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17663782835006714
Epoch 0, Step 476: train/loss = 0.4249431788921356, train/raw-loss = 0.35330885648727417, train/logprobs = tensor([[-0.6422, -2.4752],
        [-1.4625, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14326868951320648
Epoch 0, Step 477: train/loss = 0.2070009708404541, train/raw-loss = 0.09802310168743134, train/logprobs = tensor([[-1.4622, -4.7125],
        [-4.1318, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21795573830604553
Epoch 0, Step 478: train/loss = 0.38105806708335876, train/raw-loss = 0.2971091568470001, train/logprobs = tensor([[-1.3026, -3.4526],
        [-2.6695, -1.3124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16789785027503967
Epoch 0, Step 479: train/loss = 0.4842038154602051, train/raw-loss = 0.40593260526657104, train/logprobs = tensor([[-1.0053, -2.4852],
        [-1.2663, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15654237568378448
Epoch 0, Step 480: train/loss = 0.5306642055511475, train/raw-loss = 0.4513077735900879, train/logprobs = tensor([[-0.6545, -3.0064],
        [-0.9505, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15871292352676392
Epoch 0, Step 481: train/loss = 0.28323304653167725, train/raw-loss = 0.19245699048042297, train/logprobs = tensor([[-1.2085, -3.9603],
        [-2.7385, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18155211210250854
Epoch 0, Step 482: train/loss = 0.4921415448188782, train/raw-loss = 0.3929220139980316, train/logprobs = tensor([[-1.6537, -3.0916],
        [-2.5207, -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1984390914440155
Epoch 0, Step 483: train/loss = 0.25509893894195557, train/raw-loss = 0.15302301943302155, train/logprobs = tensor([[-0.9437, -4.3181],
        [-2.3665, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20415182411670685
Epoch 0, Step 484: train/loss = 0.4779942035675049, train/raw-loss = 0.3834068179130554, train/logprobs = tensor([[-0.9297, -3.1463],
        [-1.5552, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18917477130889893
Epoch 0, Step 485: train/loss = 0.3999912142753601, train/raw-loss = 0.30528029799461365, train/logprobs = tensor([[-0.8501, -3.7741],
        [-1.4422, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1894218474626541
Epoch 0, Step 486: train/loss = 0.4894126057624817, train/raw-loss = 0.3749459981918335, train/logprobs = tensor([[-0.7658, -2.8542],
        [-1.4938, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22893324494361877
Epoch 0, Step 487: train/loss = 0.584352433681488, train/raw-loss = 0.5007839202880859, train/logprobs = tensor([[-0.8267, -1.8125],
        [-1.2561, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16713696718215942
Epoch 0, Step 488: train/loss = 0.4604552686214447, train/raw-loss = 0.38916102051734924, train/logprobs = tensor([[-1.3383, -3.1246],
        [-1.6095, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14258849620819092
Epoch 0, Step 489: train/loss = 0.4298948645591736, train/raw-loss = 0.31941524147987366, train/logprobs = tensor([[-1.0324, -2.7063],
        [-2.2578, -1.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22095927596092224
Epoch 0, Step 490: train/loss = 0.4575769901275635, train/raw-loss = 0.3623288571834564, train/logprobs = tensor([[-0.6745, -4.5413],
        [-1.2057, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1904963105916977
Epoch 0, Step 491: train/loss = 0.7287335395812988, train/raw-loss = 0.6513088941574097, train/logprobs = tensor([[-0.9854, -3.0162],
        [-1.6986, -2.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15484920144081116
Epoch 0, Step 492: train/loss = 0.3116530776023865, train/raw-loss = 0.2210225611925125, train/logprobs = tensor([[-1.4112, -5.8556],
        [-1.8446, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18126101791858673
Epoch 0, Step 493: train/loss = 0.5337149500846863, train/raw-loss = 0.42406266927719116, train/logprobs = tensor([[-1.4237, -2.7540],
        [-2.4018, -1.5383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21930454671382904
Epoch 0, Step 494: train/loss = 0.2575891315937042, train/raw-loss = 0.1432042419910431, train/logprobs = tensor([[-1.6000, -3.9163],
        [-3.7687, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22876979410648346
Epoch 0, Step 495: train/loss = 0.439203679561615, train/raw-loss = 0.33418625593185425, train/logprobs = tensor([[-1.2558, -2.2229],
        [-2.2902, -0.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21003493666648865
Epoch 0, Step 496: train/loss = 0.2630158066749573, train/raw-loss = 0.15463411808013916, train/logprobs = tensor([[-1.0644, -4.6431],
        [-2.8956, -1.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21676333248615265
Epoch 0, Step 497: train/loss = 0.5308507680892944, train/raw-loss = 0.4180254340171814, train/logprobs = tensor([[-0.8201, -1.6186],
        [-1.9357, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22565066814422607
Epoch 0, Step 498: train/loss = 0.393599271774292, train/raw-loss = 0.3009209930896759, train/logprobs = tensor([[-0.9393, -3.0242],
        [-1.8176, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18535661697387695
Epoch 0, Step 499: train/loss = 0.3700282871723175, train/raw-loss = 0.28871163725852966, train/logprobs = tensor([[-0.7445, -3.6345],
        [-1.2921, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16263334453105927
eval/loss: nan
Epoch 0, Step 500: train/loss = 0.481120765209198, train/raw-loss = 0.37357792258262634, train/logprobs = tensor([[-1.0806, -2.0993],
        [-2.3151, -1.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21508567035198212
Epoch 0, Step 501: train/loss = 0.38024115562438965, train/raw-loss = 0.2829303741455078, train/logprobs = tensor([[-1.2217, -3.7962],
        [-1.8568, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19462160766124725
Epoch 0, Step 502: train/loss = 0.4075237810611725, train/raw-loss = 0.29433929920196533, train/logprobs = tensor([[-1.3212, -3.1081],
        [-2.8817, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2263689935207367
Epoch 0, Step 503: train/loss = 0.23563165962696075, train/raw-loss = 0.11370290815830231, train/logprobs = tensor([[-1.1955, -4.4737],
        [-3.1553, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438575029373169
Epoch 0, Step 504: train/loss = 0.34579238295555115, train/raw-loss = 0.23619815707206726, train/logprobs = tensor([[-1.1134, -2.8429],
        [-2.8573, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21918842196464539
Epoch 0, Step 505: train/loss = 0.39871713519096375, train/raw-loss = 0.2985125482082367, train/logprobs = tensor([[-1.0515, -3.1409],
        [-1.9528, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2004091590642929
Epoch 0, Step 506: train/loss = 0.3873332738876343, train/raw-loss = 0.29616281390190125, train/logprobs = tensor([[-1.1807, -3.6068],
        [-2.3377, -1.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18234096467494965
Epoch 0, Step 507: train/loss = 0.26930150389671326, train/raw-loss = 0.15589752793312073, train/logprobs = tensor([[-0.9313, -3.8472],
        [-2.5306, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22680795192718506
Epoch 0, Step 508: train/loss = 0.5410293936729431, train/raw-loss = 0.44126269221305847, train/logprobs = tensor([[-1.1119, -3.3356],
        [-1.3077, -1.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1995333731174469
Epoch 0, Step 509: train/loss = 0.2944069504737854, train/raw-loss = 0.1938711553812027, train/logprobs = tensor([[-0.8226, -4.4584],
        [-1.8779, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2010715901851654
Epoch 0, Step 510: train/loss = 0.3697209656238556, train/raw-loss = 0.2795298397541046, train/logprobs = tensor([[-0.8315, -4.5767],
        [-1.1401, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18038225173950195
Epoch 0, Step 511: train/loss = 0.41047826409339905, train/raw-loss = 0.3247966468334198, train/logprobs = tensor([[-1.7437, -3.6238],
        [-2.9591, -1.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17136326432228088
Epoch 0, Step 512: train/loss = 0.44630753993988037, train/raw-loss = 0.34971144795417786, train/logprobs = tensor([[-1.0059, -3.4538],
        [-1.6066, -1.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19319212436676025
Epoch 0, Step 513: train/loss = 0.4475797414779663, train/raw-loss = 0.3643568158149719, train/logprobs = tensor([[-1.1485, -2.9795],
        [-2.1392, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16644586622714996
Epoch 0, Step 514: train/loss = 0.3656112253665924, train/raw-loss = 0.2725366950035095, train/logprobs = tensor([[-1.5516, -3.3457],
        [-2.8407, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18614904582500458
Epoch 0, Step 515: train/loss = 0.21296313405036926, train/raw-loss = 0.08300340175628662, train/logprobs = tensor([[-1.1889, -5.1126],
        [-3.3960, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2599194645881653
Epoch 0, Step 516: train/loss = 0.39657309651374817, train/raw-loss = 0.29286786913871765, train/logprobs = tensor([[-0.8387, -3.5419],
        [-1.7707, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2074105143547058
Epoch 0, Step 517: train/loss = 0.6715360283851624, train/raw-loss = 0.5774004459381104, train/logprobs = tensor([[-0.6800, -2.0541],
        [-0.9312, -1.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188271164894104
Epoch 0, Step 518: train/loss = 0.5156579613685608, train/raw-loss = 0.43815678358078003, train/logprobs = tensor([[-1.1376, -5.0226],
        [-1.4116, -2.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1550023853778839
Epoch 0, Step 519: train/loss = 0.437275767326355, train/raw-loss = 0.3240450620651245, train/logprobs = tensor([[-0.9793, -3.6838],
        [-1.8170, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22646145522594452
Epoch 0, Step 520: train/loss = 0.28851303458213806, train/raw-loss = 0.17000827193260193, train/logprobs = tensor([[-1.0780, -6.2311],
        [-1.8914, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23700952529907227
Epoch 0, Step 521: train/loss = 0.4302336573600769, train/raw-loss = 0.3256050646305084, train/logprobs = tensor([[-1.7557, -3.7442],
        [-2.4703, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2092570811510086
Epoch 0, Step 522: train/loss = 0.4112641215324402, train/raw-loss = 0.31116142868995667, train/logprobs = tensor([[-1.2048, -3.4059],
        [-2.3482, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20020535588264465
Epoch 0, Step 523: train/loss = 0.5267583727836609, train/raw-loss = 0.429825097322464, train/logprobs = tensor([[-1.8224, -3.7324],
        [-2.6261, -1.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1938665807247162
Epoch 0, Step 524: train/loss = 0.3377755880355835, train/raw-loss = 0.22369295358657837, train/logprobs = tensor([[-1.2059, -4.0062],
        [-2.8051, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22816528379917145
Epoch 0, Step 525: train/loss = 0.3649253249168396, train/raw-loss = 0.2676698863506317, train/logprobs = tensor([[-1.5912, -2.7694],
        [-3.5560, -1.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19451086223125458
Epoch 0, Step 526: train/loss = 0.294133722782135, train/raw-loss = 0.18266561627388, train/logprobs = tensor([[-1.7217, -4.9761],
        [-3.4693, -2.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22293630242347717
Epoch 0, Step 527: train/loss = 0.4778018891811371, train/raw-loss = 0.37588101625442505, train/logprobs = tensor([[-1.0593, -2.4959],
        [-2.3004, -1.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20384177565574646
Epoch 0, Step 528: train/loss = 0.30254611372947693, train/raw-loss = 0.20880435407161713, train/logprobs = tensor([[-1.2088, -3.3176],
        [-3.1607, -1.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18748348951339722
Epoch 0, Step 529: train/loss = 0.633527398109436, train/raw-loss = 0.5353482961654663, train/logprobs = tensor([[-0.9728, -4.1558],
        [-2.3197, -2.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19635817408561707
Epoch 0, Step 530: train/loss = 0.5044008493423462, train/raw-loss = 0.43980658054351807, train/logprobs = tensor([[-0.5017, -2.9451],
        [-0.7227, -0.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12918853759765625
Epoch 0, Step 531: train/loss = 0.30207881331443787, train/raw-loss = 0.1862177550792694, train/logprobs = tensor([[-0.8725, -4.7294],
        [-2.2421, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2317221313714981
Epoch 0, Step 532: train/loss = 0.4897750914096832, train/raw-loss = 0.39296358823776245, train/logprobs = tensor([[-0.9716, -2.1978],
        [-1.9771, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19362300634384155
Epoch 0, Step 533: train/loss = 0.31297802925109863, train/raw-loss = 0.20444190502166748, train/logprobs = tensor([[-0.7628, -4.4136],
        [-1.4709, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21707232296466827
Epoch 0, Step 534: train/loss = 0.44157683849334717, train/raw-loss = 0.3398311734199524, train/logprobs = tensor([[-1.2863, -2.7159],
        [-3.5519, -1.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20349134504795074
Epoch 0, Step 535: train/loss = 0.4963473081588745, train/raw-loss = 0.3859834671020508, train/logprobs = tensor([[-0.9517, -2.4975],
        [-1.6283, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22072754800319672
Epoch 0, Step 536: train/loss = 0.2552133798599243, train/raw-loss = 0.14399687945842743, train/logprobs = tensor([[-1.3816, -5.5383],
        [-3.3837, -1.5820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22243298590183258
Epoch 0, Step 537: train/loss = 0.2987673282623291, train/raw-loss = 0.16909734904766083, train/logprobs = tensor([[-1.6030, -3.5052],
        [-3.2415, -0.9752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25933998823165894
Epoch 0, Step 538: train/loss = 0.5976876020431519, train/raw-loss = 0.5030628442764282, train/logprobs = tensor([[-1.1921, -1.7189],
        [-3.5419, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18924957513809204
Epoch 0, Step 539: train/loss = 0.39016127586364746, train/raw-loss = 0.27512288093566895, train/logprobs = tensor([[-1.3114, -4.3541],
        [-2.3063, -1.3312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23007677495479584
Epoch 0, Step 540: train/loss = 0.4877656102180481, train/raw-loss = 0.3935488164424896, train/logprobs = tensor([[-1.1507, -2.3807],
        [-2.1495, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18843358755111694
Epoch 0, Step 541: train/loss = 0.4553396701812744, train/raw-loss = 0.359377920627594, train/logprobs = tensor([[-1.1792, -1.2435],
        [-2.6011, -0.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19192355871200562
Epoch 0, Step 542: train/loss = 0.3240642845630646, train/raw-loss = 0.22996167838573456, train/logprobs = tensor([[-1.5626, -3.5516],
        [-2.6991, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18820524215698242
Epoch 0, Step 543: train/loss = 0.38503730297088623, train/raw-loss = 0.2684533894062042, train/logprobs = tensor([[-1.3277, -2.4720],
        [-2.8096, -1.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23316781222820282
Epoch 0, Step 544: train/loss = 0.49726757407188416, train/raw-loss = 0.38486552238464355, train/logprobs = tensor([[-0.9381, -3.6539],
        [-1.3375, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248041033744812
Epoch 0, Step 545: train/loss = 0.3498959243297577, train/raw-loss = 0.24308493733406067, train/logprobs = tensor([[-0.8465, -3.7935],
        [-1.9430, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21362194418907166
Epoch 0, Step 546: train/loss = 0.39463555812835693, train/raw-loss = 0.30089253187179565, train/logprobs = tensor([[-1.8155, -7.3589],
        [-3.8831, -5.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18748605251312256
Epoch 0, Step 547: train/loss = 0.34597355127334595, train/raw-loss = 0.2390582263469696, train/logprobs = tensor([[-0.9260, -4.0190],
        [-2.5296, -0.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21383064985275269
Epoch 0, Step 548: train/loss = 0.33902958035469055, train/raw-loss = 0.21690545976161957, train/logprobs = tensor([[-1.1654, -5.0580],
        [-2.8598, -1.4438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24424827098846436
Epoch 0, Step 549: train/loss = 0.46124476194381714, train/raw-loss = 0.3372921347618103, train/logprobs = tensor([[-1.6726, -3.7148],
        [-3.3674, -1.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24790522456169128
Epoch 0, Step 550: train/loss = 0.560155987739563, train/raw-loss = 0.43628042936325073, train/logprobs = tensor([[-1.0759, -2.5310],
        [-2.1761, -1.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24775104224681854
Epoch 0, Step 551: train/loss = 0.4590804874897003, train/raw-loss = 0.33680832386016846, train/logprobs = tensor([[-0.7546, -4.3628],
        [-1.4056, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24454432725906372
Epoch 0, Step 552: train/loss = 0.44182032346725464, train/raw-loss = 0.3466119170188904, train/logprobs = tensor([[-1.6276, -3.1005],
        [-3.2529, -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1904168426990509
Epoch 0, Step 553: train/loss = 0.28340327739715576, train/raw-loss = 0.16988086700439453, train/logprobs = tensor([[-1.8739, -4.1709],
        [-4.4726, -1.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22704485058784485
Epoch 0, Step 554: train/loss = 0.33657926321029663, train/raw-loss = 0.23025280237197876, train/logprobs = tensor([[-1.2895, -4.6336],
        [-2.7168, -1.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21265296638011932
Epoch 0, Step 555: train/loss = 0.37591323256492615, train/raw-loss = 0.29202139377593994, train/logprobs = tensor([[-1.6676, -5.0383],
        [-3.0557, -2.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677836775779724
Epoch 0, Step 556: train/loss = 0.31960529088974, train/raw-loss = 0.1994032859802246, train/logprobs = tensor([[-1.0497, -3.3589],
        [-2.5886, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24040400981903076
Epoch 0, Step 557: train/loss = 0.4173220694065094, train/raw-loss = 0.3298496603965759, train/logprobs = tensor([[-0.8125, -4.9780],
        [-1.2675, -2.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17494475841522217
Epoch 0, Step 558: train/loss = 0.6787821650505066, train/raw-loss = 0.5468947887420654, train/logprobs = tensor([[-1.3263, -3.5326],
        [-2.9758, -2.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637748122215271
Epoch 0, Step 559: train/loss = 0.3309735357761383, train/raw-loss = 0.2167644053697586, train/logprobs = tensor([[-0.9367, -3.9433],
        [-2.2950, -1.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2284182459115982
Epoch 0, Step 560: train/loss = 0.4445028603076935, train/raw-loss = 0.3438361883163452, train/logprobs = tensor([[-0.8835, -3.5927],
        [-1.2840, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20133332908153534
Epoch 0, Step 561: train/loss = 0.49596142768859863, train/raw-loss = 0.37924736738204956, train/logprobs = tensor([[-1.5236, -3.0380],
        [-3.3885, -2.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23342803120613098
Epoch 0, Step 562: train/loss = 0.45342105627059937, train/raw-loss = 0.33591675758361816, train/logprobs = tensor([[-1.1193, -3.7205],
        [-2.3663, -1.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23500849306583405
Epoch 0, Step 563: train/loss = 0.3532050549983978, train/raw-loss = 0.2134844809770584, train/logprobs = tensor([[-1.2339, -3.4310],
        [-3.3306, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27944111824035645
Epoch 0, Step 564: train/loss = 0.5084694623947144, train/raw-loss = 0.398947536945343, train/logprobs = tensor([[-1.3069, -2.4338],
        [-2.2466, -1.7087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2190438210964203
Epoch 0, Step 565: train/loss = 0.5716215968132019, train/raw-loss = 0.47092753648757935, train/logprobs = tensor([[-0.8935, -2.6894],
        [-1.4170, -1.5833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2013881653547287
Epoch 0, Step 566: train/loss = 0.2681346535682678, train/raw-loss = 0.16961905360221863, train/logprobs = tensor([[-0.8315, -6.2445],
        [-1.6355, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1970311850309372
Epoch 0, Step 567: train/loss = 0.611303448677063, train/raw-loss = 0.5263798236846924, train/logprobs = tensor([[-0.6487, -2.8016],
        [-1.1787, -1.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.169847309589386
Epoch 0, Step 568: train/loss = 0.4639171361923218, train/raw-loss = 0.3676529824733734, train/logprobs = tensor([[-0.8365, -4.2555],
        [-1.8339, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19252833724021912
Epoch 0, Step 569: train/loss = 0.5164093375205994, train/raw-loss = 0.4111572802066803, train/logprobs = tensor([[-1.7511, -1.9958],
        [-3.1005, -1.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21050409972667694
Epoch 0, Step 570: train/loss = 0.33559972047805786, train/raw-loss = 0.23455867171287537, train/logprobs = tensor([[-1.1795, -5.9744],
        [-2.6716, -1.4288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20208211243152618
Epoch 0, Step 571: train/loss = 0.4540024697780609, train/raw-loss = 0.368541419506073, train/logprobs = tensor([[-1.8588, -2.4750],
        [-3.1901, -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17092211544513702
Epoch 0, Step 572: train/loss = 0.49309247732162476, train/raw-loss = 0.39249294996261597, train/logprobs = tensor([[-1.1238, -3.2408],
        [-2.0095, -1.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20119909942150116
Epoch 0, Step 573: train/loss = 0.5335807204246521, train/raw-loss = 0.4354090690612793, train/logprobs = tensor([[-1.2456, -3.3806],
        [-1.4074, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1963433474302292
Epoch 0, Step 574: train/loss = 0.3989601135253906, train/raw-loss = 0.27746400237083435, train/logprobs = tensor([[-1.1794, -6.4669],
        [-2.6218, -2.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24299225211143494
Epoch 0, Step 575: train/loss = 0.606990396976471, train/raw-loss = 0.4992868900299072, train/logprobs = tensor([[-1.4236, -3.2722],
        [-2.7413, -2.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21540701389312744
Epoch 0, Step 576: train/loss = 0.2977926731109619, train/raw-loss = 0.16527947783470154, train/logprobs = tensor([[-0.9958, -4.2254],
        [-2.6478, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26502636075019836
Epoch 0, Step 577: train/loss = 0.31260979175567627, train/raw-loss = 0.20366491377353668, train/logprobs = tensor([[-1.7540, -2.0737],
        [-4.7020, -0.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2178897261619568
Epoch 0, Step 578: train/loss = 0.5769023895263672, train/raw-loss = 0.48026353120803833, train/logprobs = tensor([[-1.5658, -2.6530],
        [-1.8106, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19327771663665771
Epoch 0, Step 579: train/loss = 0.3001384735107422, train/raw-loss = 0.17320136725902557, train/logprobs = tensor([[-1.7097, -4.1105],
        [-3.8740, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538742423057556
Epoch 0, Step 580: train/loss = 0.49286770820617676, train/raw-loss = 0.3625894784927368, train/logprobs = tensor([[-0.9307, -3.5297],
        [-1.8321, -1.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605563998222351
Epoch 0, Step 581: train/loss = 0.379236102104187, train/raw-loss = 0.25545838475227356, train/logprobs = tensor([[-0.9365, -4.4615],
        [-1.5681, -1.0741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24755549430847168
Epoch 0, Step 582: train/loss = 0.6631544828414917, train/raw-loss = 0.5827980637550354, train/logprobs = tensor([[-1.3472, -2.4699],
        [-1.3162, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16071289777755737
Epoch 0, Step 583: train/loss = 0.6703203320503235, train/raw-loss = 0.5313404202461243, train/logprobs = tensor([[-1.6007, -1.6540],
        [-2.7814, -1.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779599130153656
Epoch 0, Step 584: train/loss = 0.30292630195617676, train/raw-loss = 0.1878843456506729, train/logprobs = tensor([[-1.2656, -4.3267],
        [-2.7666, -1.2365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2300838828086853
Epoch 0, Step 585: train/loss = 0.41455066204071045, train/raw-loss = 0.3269767165184021, train/logprobs = tensor([[-1.0333, -4.2008],
        [-0.9756, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1751478761434555
Epoch 0, Step 586: train/loss = 0.48151159286499023, train/raw-loss = 0.3796890079975128, train/logprobs = tensor([[-1.3476, -3.4872],
        [-2.7034, -2.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20364516973495483
Epoch 0, Step 587: train/loss = 0.517861008644104, train/raw-loss = 0.38317590951919556, train/logprobs = tensor([[-0.6725, -3.0391],
        [-1.5794, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693701684474945
Epoch 0, Step 588: train/loss = 0.4918728172779083, train/raw-loss = 0.39184141159057617, train/logprobs = tensor([[-1.0413, -3.2830],
        [-1.4849, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000628411769867
Epoch 0, Step 589: train/loss = 0.43879225850105286, train/raw-loss = 0.3335033059120178, train/logprobs = tensor([[-1.9695, -3.8341],
        [-2.7832, -1.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21057793498039246
Epoch 0, Step 590: train/loss = 0.5580129027366638, train/raw-loss = 0.4297855496406555, train/logprobs = tensor([[-1.1486, -2.2618],
        [-2.7082, -1.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256454735994339
Epoch 0, Step 591: train/loss = 0.5588326454162598, train/raw-loss = 0.41225990653038025, train/logprobs = tensor([[-1.8783, -2.5640],
        [-4.3991, -1.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29314547777175903
Epoch 0, Step 592: train/loss = 0.48551881313323975, train/raw-loss = 0.3733009696006775, train/logprobs = tensor([[-1.5150, -3.0036],
        [-3.4407, -1.3251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2244357168674469
Epoch 0, Step 593: train/loss = 0.40670204162597656, train/raw-loss = 0.2876741290092468, train/logprobs = tensor([[-1.2392, -3.2937],
        [-3.5613, -1.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23805586993694305
Epoch 0, Step 594: train/loss = 0.2890869975090027, train/raw-loss = 0.18272408843040466, train/logprobs = tensor([[-0.9910, -5.8037],
        [-1.7034, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21272577345371246
Epoch 0, Step 595: train/loss = 0.42606115341186523, train/raw-loss = 0.3071359395980835, train/logprobs = tensor([[-1.6128, -1.9927],
        [-3.4680, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23785044252872467
Epoch 0, Step 596: train/loss = 0.4134178161621094, train/raw-loss = 0.28546589612960815, train/logprobs = tensor([[-0.7849, -3.7140],
        [-1.6885, -1.2773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25590386986732483
Epoch 0, Step 597: train/loss = 0.3771226406097412, train/raw-loss = 0.2865493893623352, train/logprobs = tensor([[-1.2957, -3.1689],
        [-2.3553, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1811465620994568
Epoch 0, Step 598: train/loss = 0.7298287153244019, train/raw-loss = 0.6118485927581787, train/logprobs = tensor([[-1.3052, -4.7436],
        [-2.0536, -3.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2359602004289627
Epoch 0, Step 599: train/loss = 0.6636919975280762, train/raw-loss = 0.5597365498542786, train/logprobs = tensor([[-1.3557, -1.8550],
        [-1.8318, -1.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079109251499176
Epoch 0, Step 600: train/loss = 0.5583462119102478, train/raw-loss = 0.4361547827720642, train/logprobs = tensor([[-1.4645, -3.4145],
        [-2.5723, -1.8650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2443827986717224
Epoch 0, Step 601: train/loss = 0.28326013684272766, train/raw-loss = 0.15962031483650208, train/logprobs = tensor([[-1.5770, -4.3783],
        [-3.2678, -1.0886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24727964401245117
Epoch 0, Step 602: train/loss = 0.46214431524276733, train/raw-loss = 0.3657492399215698, train/logprobs = tensor([[-1.5320, -2.9143],
        [-2.7031, -1.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19279015064239502
Epoch 0, Step 603: train/loss = 0.2776268720626831, train/raw-loss = 0.14531303942203522, train/logprobs = tensor([[-1.6696, -4.2510],
        [-3.5016, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26462769508361816
Epoch 0, Step 604: train/loss = 0.41573479771614075, train/raw-loss = 0.32064807415008545, train/logprobs = tensor([[-1.6857, -4.9277],
        [-2.5820, -2.6741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19017338752746582
Epoch 0, Step 605: train/loss = 0.3777020573616028, train/raw-loss = 0.2429986149072647, train/logprobs = tensor([[-1.0162, -3.2216],
        [-2.6551, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26940691471099854
Epoch 0, Step 606: train/loss = 0.577612578868866, train/raw-loss = 0.4724154472351074, train/logprobs = tensor([[-1.3135, -1.7318],
        [-2.0703, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2103942483663559
Epoch 0, Step 607: train/loss = 0.38548406958580017, train/raw-loss = 0.2818458080291748, train/logprobs = tensor([[-0.8695, -4.3373],
        [-1.3623, -1.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20727652311325073
Epoch 0, Step 608: train/loss = 0.3838401734828949, train/raw-loss = 0.24612784385681152, train/logprobs = tensor([[-1.2783, -5.1954],
        [-3.1145, -1.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27542468905448914
Epoch 0, Step 609: train/loss = 0.4366581439971924, train/raw-loss = 0.3244413137435913, train/logprobs = tensor([[-1.0156, -4.3966],
        [-1.5761, -0.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22443364560604095
Epoch 0, Step 610: train/loss = 0.5350489616394043, train/raw-loss = 0.39439481496810913, train/logprobs = tensor([[-1.1916, -2.9400],
        [-1.7738, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813083231449127
Epoch 0, Step 611: train/loss = 0.29309600591659546, train/raw-loss = 0.16196541488170624, train/logprobs = tensor([[-1.6450, -4.2972],
        [-2.9128, -0.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26226118206977844
Epoch 0, Step 612: train/loss = 0.4767668843269348, train/raw-loss = 0.3509849011898041, train/logprobs = tensor([[-1.0845, -5.3746],
        [-1.4026, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515639364719391
Epoch 0, Step 613: train/loss = 0.4158010482788086, train/raw-loss = 0.3053160011768341, train/logprobs = tensor([[-1.2885, -3.2851],
        [-2.5798, -0.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209700495004654
Epoch 0, Step 614: train/loss = 0.2692098021507263, train/raw-loss = 0.14600718021392822, train/logprobs = tensor([[-1.4419, -4.5020],
        [-2.9286, -1.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24640525877475739
Epoch 0, Step 615: train/loss = 0.5546491146087646, train/raw-loss = 0.4254409372806549, train/logprobs = tensor([[-1.0086, -4.4029],
        [-1.8261, -1.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25841641426086426
Epoch 0, Step 616: train/loss = 0.4234119951725006, train/raw-loss = 0.2987672686576843, train/logprobs = tensor([[-1.9562, -4.7123],
        [-4.4761, -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24928942322731018
Epoch 0, Step 617: train/loss = 0.2717602252960205, train/raw-loss = 0.11735266447067261, train/logprobs = tensor([[-1.2031, -4.9716],
        [-3.0444, -0.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3088150918483734
Epoch 0, Step 618: train/loss = 0.33551567792892456, train/raw-loss = 0.21961002051830292, train/logprobs = tensor([[-1.0794, -5.2745],
        [-3.0247, -1.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318112999200821
Epoch 0, Step 619: train/loss = 0.4034042954444885, train/raw-loss = 0.2636934518814087, train/logprobs = tensor([[-1.3378, -3.1222],
        [-3.0329, -1.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2794216275215149
Epoch 0, Step 620: train/loss = 0.5867656469345093, train/raw-loss = 0.4744057059288025, train/logprobs = tensor([[-0.8997, -2.5935],
        [-1.5197, -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22471991181373596
Epoch 0, Step 621: train/loss = 0.5981377363204956, train/raw-loss = 0.48165878653526306, train/logprobs = tensor([[-1.4768, -4.3470],
        [-1.1989, -1.5249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23295781016349792
Epoch 0, Step 622: train/loss = 0.25657302141189575, train/raw-loss = 0.1377776861190796, train/logprobs = tensor([[-1.1386, -5.9494],
        [-2.7470, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2375907003879547
Epoch 0, Step 623: train/loss = 0.39563775062561035, train/raw-loss = 0.2767682373523712, train/logprobs = tensor([[-1.7750, -2.6274],
        [-3.6833, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23773910105228424
Epoch 0, Step 624: train/loss = 0.3153878450393677, train/raw-loss = 0.20334917306900024, train/logprobs = tensor([[-1.3138, -6.0668],
        [-2.9788, -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22407734394073486
Epoch 0, Step 625: train/loss = 0.587568461894989, train/raw-loss = 0.49007663130760193, train/logprobs = tensor([[-0.8526, -3.1646],
        [-1.1932, -1.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19498369097709656
Epoch 0, Step 626: train/loss = 0.23698559403419495, train/raw-loss = 0.09632067382335663, train/logprobs = tensor([[-1.2615, -5.5585],
        [-3.9467, -1.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.281329870223999
Epoch 0, Step 627: train/loss = 0.6201246380805969, train/raw-loss = 0.5068621635437012, train/logprobs = tensor([[-1.0355, -3.7878],
        [-2.0887, -2.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22652500867843628
Epoch 0, Step 628: train/loss = 0.5749528408050537, train/raw-loss = 0.44567519426345825, train/logprobs = tensor([[-0.8825, -2.6400],
        [-2.0259, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585553228855133
Epoch 0, Step 629: train/loss = 0.5587285757064819, train/raw-loss = 0.4588417708873749, train/logprobs = tensor([[-1.6392, -2.2526],
        [-2.5080, -1.2522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19977352023124695
Epoch 0, Step 630: train/loss = 0.41834762692451477, train/raw-loss = 0.2988039255142212, train/logprobs = tensor([[-1.1794, -3.1747],
        [-2.5739, -1.2106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23908740282058716
Epoch 0, Step 631: train/loss = 0.5930073261260986, train/raw-loss = 0.48467370867729187, train/logprobs = tensor([[-1.4862, -3.2392],
        [-1.4595, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21666720509529114
Epoch 0, Step 632: train/loss = 0.3530019521713257, train/raw-loss = 0.23965781927108765, train/logprobs = tensor([[-1.0105, -5.7801],
        [-1.4042, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22668831050395966
Epoch 0, Step 633: train/loss = 0.25906336307525635, train/raw-loss = 0.12726929783821106, train/logprobs = tensor([[-1.1635, -5.4512],
        [-2.5256, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2635880708694458
Epoch 0, Step 634: train/loss = 0.439819872379303, train/raw-loss = 0.3249624967575073, train/logprobs = tensor([[-1.2617, -3.0057],
        [-2.8085, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2297147512435913
Epoch 0, Step 635: train/loss = 0.7333304286003113, train/raw-loss = 0.597813069820404, train/logprobs = tensor([[-2.0992, -3.1252],
        [-3.2983, -2.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27103471755981445
Epoch 0, Step 636: train/loss = 0.8445849418640137, train/raw-loss = 0.7254019975662231, train/logprobs = tensor([[-1.2644, -3.2481],
        [-3.7979, -2.5709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23836593329906464
Epoch 0, Step 637: train/loss = 0.37954607605934143, train/raw-loss = 0.27429264783859253, train/logprobs = tensor([[-2.0912, -6.0928],
        [-2.6114, -2.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21050681173801422
Epoch 0, Step 638: train/loss = 0.4189462959766388, train/raw-loss = 0.29099082946777344, train/logprobs = tensor([[-1.8612, -5.1801],
        [-4.3726, -2.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2559110224246979
Epoch 0, Step 639: train/loss = 0.4014604985713959, train/raw-loss = 0.2760872542858124, train/logprobs = tensor([[-1.0597, -4.1018],
        [-2.5633, -0.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250746488571167
Epoch 0, Step 640: train/loss = 0.35803064703941345, train/raw-loss = 0.2337542474269867, train/logprobs = tensor([[-0.7808, -4.3302],
        [-1.5730, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2485528141260147
Epoch 0, Step 641: train/loss = 0.5946384072303772, train/raw-loss = 0.4754514694213867, train/logprobs = tensor([[-1.9440, -1.8111],
        [-3.0546, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2383737862110138
Epoch 0, Step 642: train/loss = 0.26946502923965454, train/raw-loss = 0.14226210117340088, train/logprobs = tensor([[-1.4580, -6.0804],
        [-2.6314, -1.6148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2544058859348297
Epoch 0, Step 643: train/loss = 0.5913665294647217, train/raw-loss = 0.44589751958847046, train/logprobs = tensor([[-1.5512, -4.2137],
        [-3.8795, -2.0077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29093801975250244
Epoch 0, Step 644: train/loss = 0.47500094771385193, train/raw-loss = 0.35499441623687744, train/logprobs = tensor([[-1.6502, -3.7664],
        [-2.2493, -1.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24001306295394897
Epoch 0, Step 645: train/loss = 0.6333246231079102, train/raw-loss = 0.5119689702987671, train/logprobs = tensor([[-0.8612, -1.7549],
        [-1.3447, -1.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24271130561828613
Epoch 0, Step 646: train/loss = 0.5499002933502197, train/raw-loss = 0.4463123381137848, train/logprobs = tensor([[-2.3730, -2.7636],
        [-3.8492, -1.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20717595517635345
Epoch 0, Step 647: train/loss = 0.4306584298610687, train/raw-loss = 0.3081620931625366, train/logprobs = tensor([[-1.4934, -2.8018],
        [-3.3869, -1.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24499265849590302
Epoch 0, Step 648: train/loss = 0.33878058195114136, train/raw-loss = 0.20372171700000763, train/logprobs = tensor([[-1.0570, -4.8180],
        [-2.5814, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27011770009994507
Epoch 0, Step 649: train/loss = 0.2517842948436737, train/raw-loss = 0.12084028124809265, train/logprobs = tensor([[-1.7369, -5.8449],
        [-3.1610, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618879973888397
Epoch 0, Step 650: train/loss = 0.21546855568885803, train/raw-loss = 0.08279771357774734, train/logprobs = tensor([[-1.1216, -4.7509],
        [-3.8464, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653416693210602
Epoch 0, Step 651: train/loss = 0.6031848192214966, train/raw-loss = 0.478015273809433, train/logprobs = tensor([[-0.8381, -2.1087],
        [-2.5013, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.250339150428772
Epoch 0, Step 652: train/loss = 0.25043022632598877, train/raw-loss = 0.10787366330623627, train/logprobs = tensor([[-1.4376, -6.8055],
        [-3.0484, -1.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2851131558418274
Epoch 0, Step 653: train/loss = 0.5664634704589844, train/raw-loss = 0.45627495646476746, train/logprobs = tensor([[-0.8086, -3.6811],
        [-1.2467, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22037696838378906
Epoch 0, Step 654: train/loss = 0.38724958896636963, train/raw-loss = 0.2623940110206604, train/logprobs = tensor([[-0.9584, -4.3299],
        [-2.2027, -1.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24971114099025726
Epoch 0, Step 655: train/loss = 0.33559900522232056, train/raw-loss = 0.20931488275527954, train/logprobs = tensor([[-1.2885, -5.3279],
        [-3.3576, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2525683045387268
Epoch 0, Step 656: train/loss = 0.3813708424568176, train/raw-loss = 0.25989750027656555, train/logprobs = tensor([[-0.8934, -5.4556],
        [-1.4292, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24294669926166534
Epoch 0, Step 657: train/loss = 0.22931207716464996, train/raw-loss = 0.08726337552070618, train/logprobs = tensor([[-1.1416, -6.3398],
        [-2.9553, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840973734855652
Epoch 0, Step 658: train/loss = 0.5492727160453796, train/raw-loss = 0.4203296899795532, train/logprobs = tensor([[-1.3632, -2.7410],
        [-2.5901, -1.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25788614153862
Epoch 0, Step 659: train/loss = 0.37710437178611755, train/raw-loss = 0.24743565917015076, train/logprobs = tensor([[-1.1640, -3.8334],
        [-2.7806, -1.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2593374252319336
Epoch 0, Step 660: train/loss = 0.35107511281967163, train/raw-loss = 0.22761017084121704, train/logprobs = tensor([[-1.2920, -4.7504],
        [-2.6630, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2469298243522644
Epoch 0, Step 661: train/loss = 0.4414421319961548, train/raw-loss = 0.322749525308609, train/logprobs = tensor([[-0.8359, -3.1459],
        [-2.4271, -0.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23738515377044678
Epoch 0, Step 662: train/loss = 0.3075719177722931, train/raw-loss = 0.16280263662338257, train/logprobs = tensor([[-0.9666, -6.9064],
        [-2.8550, -2.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895386219024658
Epoch 0, Step 663: train/loss = 0.3055175542831421, train/raw-loss = 0.1993728131055832, train/logprobs = tensor([[-1.2227, -4.7664],
        [-2.3300, -1.3312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122894823551178
Epoch 0, Step 664: train/loss = 0.325185090303421, train/raw-loss = 0.1843358725309372, train/logprobs = tensor([[-1.1843, -5.2082],
        [-3.0750, -1.3643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28169846534729004
Epoch 0, Step 665: train/loss = 0.2802858352661133, train/raw-loss = 0.15962302684783936, train/logprobs = tensor([[-1.2440, -6.2147],
        [-2.3701, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24132555723190308
Epoch 0, Step 666: train/loss = 0.40897464752197266, train/raw-loss = 0.2683584988117218, train/logprobs = tensor([[-1.5374, -3.1121],
        [-3.8422, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812323570251465
Epoch 0, Step 667: train/loss = 0.38142675161361694, train/raw-loss = 0.25887852907180786, train/logprobs = tensor([[-1.3485, -4.3596],
        [-2.7163, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24509645998477936
Epoch 0, Step 668: train/loss = 0.44953426718711853, train/raw-loss = 0.33661407232284546, train/logprobs = tensor([[-1.5651, -3.5248],
        [-2.5814, -1.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22584038972854614
Epoch 0, Step 669: train/loss = 0.44055262207984924, train/raw-loss = 0.2895243167877197, train/logprobs = tensor([[-1.1979, -3.9817],
        [-2.6897, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3020566403865814
Epoch 0, Step 670: train/loss = 0.34181463718414307, train/raw-loss = 0.22584623098373413, train/logprobs = tensor([[-1.5395, -5.1292],
        [-2.8758, -1.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2319367527961731
Epoch 0, Step 671: train/loss = 0.5299702882766724, train/raw-loss = 0.41030046343803406, train/logprobs = tensor([[-1.3937, -2.9741],
        [-2.7736, -1.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23933972418308258
Epoch 0, Step 672: train/loss = 0.4957389831542969, train/raw-loss = 0.34067070484161377, train/logprobs = tensor([[-1.2085, -1.8405],
        [-3.6477, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101365268230438
Epoch 0, Step 673: train/loss = 0.5824193954467773, train/raw-loss = 0.4777580201625824, train/logprobs = tensor([[-1.2987, -2.1956],
        [-2.3215, -1.2472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20932286977767944
Epoch 0, Step 674: train/loss = 0.3049524426460266, train/raw-loss = 0.1876509040594101, train/logprobs = tensor([[-0.9237, -4.8471],
        [-2.1629, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23460304737091064
Epoch 0, Step 675: train/loss = 0.24064677953720093, train/raw-loss = 0.1013147383928299, train/logprobs = tensor([[-1.8469, -6.4647],
        [-3.5793, -1.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27866411209106445
Epoch 0, Step 676: train/loss = 0.4170375466346741, train/raw-loss = 0.2904856204986572, train/logprobs = tensor([[-1.8554, -7.6162],
        [-3.3332, -1.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531037926673889
Epoch 0, Step 677: train/loss = 0.27454984188079834, train/raw-loss = 0.15315258502960205, train/logprobs = tensor([[-1.2963, -4.4858],
        [-2.6955, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2427944839000702
Epoch 0, Step 678: train/loss = 0.5057939887046814, train/raw-loss = 0.38789379596710205, train/logprobs = tensor([[-2.1632, -4.1489],
        [-3.3568, -2.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23580040037631989
Epoch 0, Step 679: train/loss = 0.23311078548431396, train/raw-loss = 0.10275138169527054, train/logprobs = tensor([[-1.0829, -6.7804],
        [-3.1317, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26071879267692566
Epoch 0, Step 680: train/loss = 0.25137215852737427, train/raw-loss = 0.13105075061321259, train/logprobs = tensor([[-1.5226, -4.9485],
        [-3.5854, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24064278602600098
Epoch 0, Step 681: train/loss = 0.4044627547264099, train/raw-loss = 0.2950364649295807, train/logprobs = tensor([[-1.1273, -4.0995],
        [-2.1627, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21885265409946442
Epoch 0, Step 682: train/loss = 0.3807060122489929, train/raw-loss = 0.26358383893966675, train/logprobs = tensor([[-1.1417, -4.5504],
        [-2.2829, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23424437642097473
Epoch 0, Step 683: train/loss = 0.5374432802200317, train/raw-loss = 0.4215143918991089, train/logprobs = tensor([[-0.9548, -1.9933],
        [-2.1000, -1.4033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2318577766418457
Epoch 0, Step 684: train/loss = 0.4357229471206665, train/raw-loss = 0.3036518394947052, train/logprobs = tensor([[-1.5546, -5.4570],
        [-3.3314, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641421854496002
Epoch 0, Step 685: train/loss = 0.5436315536499023, train/raw-loss = 0.44576144218444824, train/logprobs = tensor([[-1.3275, -3.4283],
        [-2.1574, -1.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19574028253555298
Epoch 0, Step 686: train/loss = 0.4147644639015198, train/raw-loss = 0.2844838500022888, train/logprobs = tensor([[-0.9235, -3.9776],
        [-2.1267, -1.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605611979961395
Epoch 0, Step 687: train/loss = 0.37411433458328247, train/raw-loss = 0.2648015320301056, train/logprobs = tensor([[-1.0132, -2.9604],
        [-2.8126, -0.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21862563490867615
Epoch 0, Step 688: train/loss = 0.2592255473136902, train/raw-loss = 0.1322147399187088, train/logprobs = tensor([[-0.9964, -5.4577],
        [-2.9776, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25402164459228516
Epoch 0, Step 689: train/loss = 0.31126129627227783, train/raw-loss = 0.17431293427944183, train/logprobs = tensor([[-0.8382, -5.7131],
        [-1.9139, -1.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738966941833496
Epoch 0, Step 690: train/loss = 0.38533517718315125, train/raw-loss = 0.2506517469882965, train/logprobs = tensor([[-1.1106, -4.3152],
        [-2.0703, -1.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2693668305873871
Epoch 0, Step 691: train/loss = 0.45236480236053467, train/raw-loss = 0.34381765127182007, train/logprobs = tensor([[-1.3529, -4.6769],
        [-2.2931, -1.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2170943170785904
Epoch 0, Step 692: train/loss = 0.30411261320114136, train/raw-loss = 0.18192218244075775, train/logprobs = tensor([[-1.1797, -4.7816],
        [-2.1656, -1.3083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24438083171844482
Epoch 0, Step 693: train/loss = 0.5226839184761047, train/raw-loss = 0.4199388921260834, train/logprobs = tensor([[-1.1026, -2.7110],
        [-1.9698, -1.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20549000799655914
Epoch 0, Step 694: train/loss = 0.3441222906112671, train/raw-loss = 0.23433437943458557, train/logprobs = tensor([[-1.8960, -3.5103],
        [-3.6001, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21957579255104065
Epoch 0, Step 695: train/loss = 0.46489813923835754, train/raw-loss = 0.34667736291885376, train/logprobs = tensor([[-2.6186, -3.8575],
        [-4.0551, -1.4637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23644159734249115
Epoch 0, Step 696: train/loss = 0.2972467839717865, train/raw-loss = 0.18710823357105255, train/logprobs = tensor([[-1.3708, -5.1103],
        [-2.9446, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22027716040611267
Epoch 0, Step 697: train/loss = 0.4094855785369873, train/raw-loss = 0.30709701776504517, train/logprobs = tensor([[-1.9201, -4.1461],
        [-3.2316, -0.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20477712154388428
Epoch 0, Step 698: train/loss = 0.2862224578857422, train/raw-loss = 0.1706903874874115, train/logprobs = tensor([[-1.0144, -5.3212],
        [-2.8591, -1.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23106418550014496
Epoch 0, Step 699: train/loss = 0.29728245735168457, train/raw-loss = 0.1622505784034729, train/logprobs = tensor([[-1.3773, -6.0067],
        [-3.1400, -1.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27006375789642334
Epoch 0, Step 700: train/loss = 0.23263534903526306, train/raw-loss = 0.12080714106559753, train/logprobs = tensor([[-1.3959, -6.2028],
        [-2.8469, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22365644574165344
Epoch 0, Step 701: train/loss = 0.6008377075195312, train/raw-loss = 0.4710737466812134, train/logprobs = tensor([[-1.4202, -2.8690],
        [-2.5311, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25952792167663574
Epoch 0, Step 702: train/loss = 0.5545425415039062, train/raw-loss = 0.4801388382911682, train/logprobs = tensor([[-1.5098, -3.5502],
        [-1.7695, -1.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880748093128204
Epoch 0, Step 703: train/loss = 0.39291316270828247, train/raw-loss = 0.276851624250412, train/logprobs = tensor([[-1.2986, -2.3848],
        [-3.5205, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23212313652038574
Epoch 0, Step 704: train/loss = 0.22591884434223175, train/raw-loss = 0.11260905116796494, train/logprobs = tensor([[-1.4316, -5.9860],
        [-3.5651, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22661960124969482
Epoch 0, Step 705: train/loss = 0.32978197932243347, train/raw-loss = 0.2172268182039261, train/logprobs = tensor([[-0.9491, -4.5417],
        [-2.7115, -1.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22511029243469238
Epoch 0, Step 706: train/loss = 0.5331331491470337, train/raw-loss = 0.4214293956756592, train/logprobs = tensor([[-0.6566, -3.3468],
        [-1.2451, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2234075367450714
Epoch 0, Step 707: train/loss = 0.25257015228271484, train/raw-loss = 0.12781521677970886, train/logprobs = tensor([[-1.0138, -5.8464],
        [-2.2644, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24950984120368958
Epoch 0, Step 708: train/loss = 0.3571633994579315, train/raw-loss = 0.25651293992996216, train/logprobs = tensor([[-1.1572, -4.1784],
        [-3.1322, -0.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20130085945129395
Epoch 0, Step 709: train/loss = 0.36209315061569214, train/raw-loss = 0.2588813304901123, train/logprobs = tensor([[-1.2845, -4.6975],
        [-2.0642, -1.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20642361044883728
Epoch 0, Step 710: train/loss = 0.27470874786376953, train/raw-loss = 0.14271600544452667, train/logprobs = tensor([[-1.2446, -4.6900],
        [-2.9298, -1.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639855146408081
Epoch 0, Step 711: train/loss = 0.43935197591781616, train/raw-loss = 0.3271053433418274, train/logprobs = tensor([[-1.4124, -3.7619],
        [-2.4870, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22449329495429993
Epoch 0, Step 712: train/loss = 0.5213536024093628, train/raw-loss = 0.4127713143825531, train/logprobs = tensor([[-1.3740, -4.2613],
        [-3.3248, -2.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2171645164489746
Epoch 0, Step 713: train/loss = 0.2765241861343384, train/raw-loss = 0.1923156976699829, train/logprobs = tensor([[-0.9974, -6.8276],
        [-1.6259, -1.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16841694712638855
Epoch 0, Step 714: train/loss = 0.45040613412857056, train/raw-loss = 0.31087005138397217, train/logprobs = tensor([[-1.0190, -6.3695],
        [-2.1376, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27907219529151917
Epoch 0, Step 715: train/loss = 0.30958935618400574, train/raw-loss = 0.19402454793453217, train/logprobs = tensor([[-1.7173, -5.4012],
        [-2.4407, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23112960159778595
Epoch 0, Step 716: train/loss = 0.3273724913597107, train/raw-loss = 0.1971782147884369, train/logprobs = tensor([[-1.4381, -1.8199],
        [-4.2872, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2603885233402252
Epoch 0, Step 717: train/loss = 0.4106224775314331, train/raw-loss = 0.3165810704231262, train/logprobs = tensor([[-0.8315, -4.0154],
        [-1.6543, -1.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188082754611969
Epoch 0, Step 718: train/loss = 0.23018430173397064, train/raw-loss = 0.11847873777151108, train/logprobs = tensor([[-1.3201, -8.0890],
        [-2.9877, -1.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22341112792491913
Epoch 0, Step 719: train/loss = 0.2340579628944397, train/raw-loss = 0.11242376267910004, train/logprobs = tensor([[-1.8471, -3.9546],
        [-4.4015, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2432684302330017
Epoch 0, Step 720: train/loss = 0.40151455998420715, train/raw-loss = 0.285221666097641, train/logprobs = tensor([[-1.0104, -3.9504],
        [-2.1078, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23258577287197113
Epoch 0, Step 721: train/loss = 0.48255419731140137, train/raw-loss = 0.37429970502853394, train/logprobs = tensor([[-1.5942, -3.5518],
        [-2.5382, -1.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21650896966457367
Epoch 0, Step 722: train/loss = 0.39792388677597046, train/raw-loss = 0.30748680233955383, train/logprobs = tensor([[-1.3010, -4.3829],
        [-1.9186, -1.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18087421357631683
Epoch 0, Step 723: train/loss = 0.5109037160873413, train/raw-loss = 0.4247293472290039, train/logprobs = tensor([[-1.0651, -3.6760],
        [-1.7754, -1.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1723487675189972
Epoch 0, Step 724: train/loss = 0.40365341305732727, train/raw-loss = 0.30845215916633606, train/logprobs = tensor([[-0.8956, -5.9257],
        [-1.4486, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1904025375843048
Epoch 0, Step 725: train/loss = 0.3811768889427185, train/raw-loss = 0.273754745721817, train/logprobs = tensor([[-1.7402, -2.8459],
        [-3.4336, -1.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2148442566394806
Epoch 0, Step 726: train/loss = 0.5352578163146973, train/raw-loss = 0.4155072569847107, train/logprobs = tensor([[-1.2063, -2.4151],
        [-3.1307, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23950108885765076
Epoch 0, Step 727: train/loss = 0.4122657775878906, train/raw-loss = 0.30054157972335815, train/logprobs = tensor([[-0.9417, -3.7518],
        [-2.5763, -1.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22344839572906494
Epoch 0, Step 728: train/loss = 0.3945925235748291, train/raw-loss = 0.2928628921508789, train/logprobs = tensor([[-1.0759, -5.7016],
        [-2.6279, -1.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034592628479004
Epoch 0, Step 729: train/loss = 0.4818603992462158, train/raw-loss = 0.39125674962997437, train/logprobs = tensor([[-1.1074, -3.3173],
        [-1.9256, -1.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18120726943016052
Epoch 0, Step 730: train/loss = 0.5144476294517517, train/raw-loss = 0.42188602685928345, train/logprobs = tensor([[-1.6041, -2.5545],
        [-2.7304, -1.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18512317538261414
Epoch 0, Step 731: train/loss = 0.3360633850097656, train/raw-loss = 0.21832416951656342, train/logprobs = tensor([[-2.0151, -3.8797],
        [-5.0738, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2354784607887268
Epoch 0, Step 732: train/loss = 0.20883382856845856, train/raw-loss = 0.10504433512687683, train/logprobs = tensor([[-1.6351, -6.2826],
        [-3.9240, -1.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20757901668548584
Epoch 0, Step 733: train/loss = 0.44707953929901123, train/raw-loss = 0.36894479393959045, train/logprobs = tensor([[-1.4365, -3.4282],
        [-2.2077, -1.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15626952052116394
Epoch 0, Step 734: train/loss = 0.37075358629226685, train/raw-loss = 0.27647924423217773, train/logprobs = tensor([[-0.7820, -4.1990],
        [-2.1487, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18854868412017822
Epoch 0, Step 735: train/loss = 0.3655208349227905, train/raw-loss = 0.2443123757839203, train/logprobs = tensor([[-1.4851, -3.8753],
        [-3.2244, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424168884754181
Epoch 0, Step 736: train/loss = 0.45918455719947815, train/raw-loss = 0.35484778881073, train/logprobs = tensor([[-1.5255, -2.1119],
        [-2.6855, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20867353677749634
Epoch 0, Step 737: train/loss = 0.23633286356925964, train/raw-loss = 0.11468879878520966, train/logprobs = tensor([[-1.0480, -4.5081],
        [-4.0466, -1.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24328811466693878
Epoch 0, Step 738: train/loss = 0.28884434700012207, train/raw-loss = 0.18340538442134857, train/logprobs = tensor([[-0.7539, -4.5415],
        [-2.3525, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21087788045406342
Epoch 0, Step 739: train/loss = 0.5238375067710876, train/raw-loss = 0.43302807211875916, train/logprobs = tensor([[-0.8618, -2.5320],
        [-2.3356, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816188097000122
Epoch 0, Step 740: train/loss = 0.4606782793998718, train/raw-loss = 0.35170993208885193, train/logprobs = tensor([[-1.0845, -2.5116],
        [-2.8296, -0.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2179366946220398
Epoch 0, Step 741: train/loss = 0.38965070247650146, train/raw-loss = 0.2963574528694153, train/logprobs = tensor([[-1.2127, -3.6943],
        [-1.9481, -1.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18658652901649475
Epoch 0, Step 742: train/loss = 0.39833900332450867, train/raw-loss = 0.2894286513328552, train/logprobs = tensor([[-1.0275, -4.5411],
        [-1.8451, -1.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21782073378562927
Epoch 0, Step 743: train/loss = 0.5892400741577148, train/raw-loss = 0.48689013719558716, train/logprobs = tensor([[-0.8484, -3.4607],
        [-1.4670, -1.5406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20469996333122253
Epoch 0, Step 744: train/loss = 0.40781646966934204, train/raw-loss = 0.324932724237442, train/logprobs = tensor([[-0.8744, -2.9576],
        [-1.5707, -0.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16576746106147766
Epoch 0, Step 745: train/loss = 0.5912298560142517, train/raw-loss = 0.49897849559783936, train/logprobs = tensor([[-1.4794, -4.3622],
        [-3.8144, -2.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18450285494327545
Epoch 0, Step 746: train/loss = 0.2747134566307068, train/raw-loss = 0.1687738448381424, train/logprobs = tensor([[-0.5587, -7.3278],
        [-1.3138, -0.8554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2118791937828064
Epoch 0, Step 747: train/loss = 0.2977040410041809, train/raw-loss = 0.20419013500213623, train/logprobs = tensor([[-1.4068, -3.5062],
        [-3.6087, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18702779710292816
Epoch 0, Step 748: train/loss = 0.4388560950756073, train/raw-loss = 0.34031906723976135, train/logprobs = tensor([[-1.3169, -3.4120],
        [-3.7154, -2.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1970740705728531
Epoch 0, Step 749: train/loss = 0.4443967342376709, train/raw-loss = 0.3475916087627411, train/logprobs = tensor([[-1.2878, -3.6131],
        [-3.7451, -1.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1936102658510208
Epoch 0, Step 750: train/loss = 0.4767971634864807, train/raw-loss = 0.3839888274669647, train/logprobs = tensor([[-1.0653, -3.7196],
        [-2.1487, -1.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1856166273355484
Epoch 0, Step 751: train/loss = 0.24965980648994446, train/raw-loss = 0.13432297110557556, train/logprobs = tensor([[-1.4210, -4.0217],
        [-3.9726, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23067370057106018
Epoch 0, Step 752: train/loss = 0.3959272503852844, train/raw-loss = 0.30471304059028625, train/logprobs = tensor([[-0.8297, -5.0007],
        [-1.7061, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18242835998535156
Epoch 0, Step 753: train/loss = 0.3719944953918457, train/raw-loss = 0.27342039346694946, train/logprobs = tensor([[-0.6052, -4.2690],
        [-1.2182, -1.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19714824855327606
Epoch 0, Step 754: train/loss = 0.22498151659965515, train/raw-loss = 0.11766677349805832, train/logprobs = tensor([[-1.3554, -6.1896],
        [-2.6764, -0.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21462950110435486
Epoch 0, Step 755: train/loss = 0.27607688307762146, train/raw-loss = 0.1588355153799057, train/logprobs = tensor([[-1.3027, -4.0363],
        [-3.8975, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23448270559310913
Epoch 0, Step 756: train/loss = 0.37287819385528564, train/raw-loss = 0.27034059166908264, train/logprobs = tensor([[-2.7557, -6.2062],
        [-3.6539, -1.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2050752341747284
Epoch 0, Step 757: train/loss = 0.5169738531112671, train/raw-loss = 0.417987585067749, train/logprobs = tensor([[-2.0276, -3.4378],
        [-2.7233, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1979725956916809
Epoch 0, Step 758: train/loss = 0.39663761854171753, train/raw-loss = 0.28367045521736145, train/logprobs = tensor([[-0.8624, -5.5904],
        [-1.6657, -1.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22593437135219574
Epoch 0, Step 759: train/loss = 0.27271372079849243, train/raw-loss = 0.16795213520526886, train/logprobs = tensor([[-1.8397, -5.1461],
        [-3.5615, -1.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20952314138412476
Epoch 0, Step 760: train/loss = 0.1573946475982666, train/raw-loss = 0.05665624141693115, train/logprobs = tensor([[-1.6413, -7.5203],
        [-4.8229, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014768123626709
Epoch 0, Step 761: train/loss = 0.21191968023777008, train/raw-loss = 0.11091718077659607, train/logprobs = tensor([[-1.2425, -6.6930],
        [-3.4846, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2020050287246704
Epoch 0, Step 762: train/loss = 0.4222402572631836, train/raw-loss = 0.3140740990638733, train/logprobs = tensor([[-1.2251, -3.4472],
        [-2.6527, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2163323014974594
Epoch 0, Step 763: train/loss = 0.4872567057609558, train/raw-loss = 0.39218562841415405, train/logprobs = tensor([[-1.0767, -3.4130],
        [-2.1490, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19014210999011993
Epoch 0, Step 764: train/loss = 0.29575836658477783, train/raw-loss = 0.18850165605545044, train/logprobs = tensor([[-0.8183, -3.5521],
        [-2.7799, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145134061574936
Epoch 0, Step 765: train/loss = 0.28535589575767517, train/raw-loss = 0.18984493613243103, train/logprobs = tensor([[-0.9606, -4.4050],
        [-2.3526, -0.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19102197885513306
Epoch 0, Step 766: train/loss = 0.19194909930229187, train/raw-loss = 0.08141796290874481, train/logprobs = tensor([[-1.2281, -4.9648],
        [-3.6388, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22106227278709412
Epoch 0, Step 767: train/loss = 0.7051122188568115, train/raw-loss = 0.5822806358337402, train/logprobs = tensor([[-1.1138, -2.8490],
        [-3.0841, -2.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456631362438202
Epoch 0, Step 768: train/loss = 0.45904824137687683, train/raw-loss = 0.37205982208251953, train/logprobs = tensor([[-1.3013, -4.4605],
        [-1.9410, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.173976868391037
Epoch 0, Step 769: train/loss = 0.3993232846260071, train/raw-loss = 0.3097030520439148, train/logprobs = tensor([[-1.1079, -4.6108],
        [-1.9636, -1.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17924043536186218
Epoch 0, Step 770: train/loss = 0.39260509610176086, train/raw-loss = 0.30115577578544617, train/logprobs = tensor([[-0.9218, -5.0414],
        [-1.4300, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1828986406326294
Epoch 0, Step 771: train/loss = 0.3855527937412262, train/raw-loss = 0.2978383004665375, train/logprobs = tensor([[-0.8341, -3.9454],
        [-2.0941, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17542897164821625
Epoch 0, Step 772: train/loss = 0.43605586886405945, train/raw-loss = 0.3487899899482727, train/logprobs = tensor([[-1.4115, -4.8878],
        [-2.9030, -1.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745317578315735
Epoch 0, Step 773: train/loss = 0.3028185963630676, train/raw-loss = 0.19099006056785583, train/logprobs = tensor([[-1.5072, -2.9340],
        [-3.7962, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236570566892624
Epoch 0, Step 774: train/loss = 0.4684160351753235, train/raw-loss = 0.3807951509952545, train/logprobs = tensor([[-1.0878, -2.5577],
        [-2.5819, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17524176836013794
Epoch 0, Step 775: train/loss = 0.46397635340690613, train/raw-loss = 0.36581751704216003, train/logprobs = tensor([[-1.2470, -2.4235],
        [-2.7973, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19631768763065338
Epoch 0, Step 776: train/loss = 0.36301520466804504, train/raw-loss = 0.2786144018173218, train/logprobs = tensor([[-1.8351, -3.9634],
        [-3.7316, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16880159080028534
Epoch 0, Step 777: train/loss = 0.6523981690406799, train/raw-loss = 0.5438268184661865, train/logprobs = tensor([[-1.0640, -2.5299],
        [-3.2220, -2.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.217142716050148
Epoch 0, Step 778: train/loss = 0.3723496198654175, train/raw-loss = 0.2703816294670105, train/logprobs = tensor([[-1.1467, -4.0837],
        [-2.7189, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20393601059913635
Epoch 0, Step 779: train/loss = 0.307732492685318, train/raw-loss = 0.22288165986537933, train/logprobs = tensor([[-1.5529, -3.8078],
        [-3.7487, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1697016805410385
Epoch 0, Step 780: train/loss = 0.25829267501831055, train/raw-loss = 0.15620627999305725, train/logprobs = tensor([[-0.8826, -5.6135],
        [-2.3237, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2041727900505066
Epoch 0, Step 781: train/loss = 0.38058122992515564, train/raw-loss = 0.27919575572013855, train/logprobs = tensor([[-2.6220, -4.5656],
        [-3.8663, -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2027709186077118
Epoch 0, Step 782: train/loss = 0.24554792046546936, train/raw-loss = 0.14087682962417603, train/logprobs = tensor([[-0.6486, -5.7905],
        [-1.9395, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20934219658374786
Epoch 0, Step 783: train/loss = 0.46637338399887085, train/raw-loss = 0.35720497369766235, train/logprobs = tensor([[-2.1285, -3.4356],
        [-2.9186, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21833691000938416
Epoch 0, Step 784: train/loss = 0.4403179883956909, train/raw-loss = 0.34300076961517334, train/logprobs = tensor([[-0.5668, -5.2382],
        [-1.3816, -1.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19463451206684113
Epoch 0, Step 785: train/loss = 0.38894474506378174, train/raw-loss = 0.2863547205924988, train/logprobs = tensor([[-2.5145, -4.0518],
        [-3.6906, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20517998933792114
Epoch 0, Step 786: train/loss = 0.32101547718048096, train/raw-loss = 0.2177765816450119, train/logprobs = tensor([[-1.1001, -2.4048],
        [-4.2369, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2064778208732605
Epoch 0, Step 787: train/loss = 0.44412505626678467, train/raw-loss = 0.33286571502685547, train/logprobs = tensor([[-1.1798, -3.7192],
        [-3.5013, -1.4106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22251872718334198
Epoch 0, Step 788: train/loss = 0.3808586597442627, train/raw-loss = 0.2795402705669403, train/logprobs = tensor([[-1.4616, -4.0128],
        [-3.0591, -1.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20263677835464478
Epoch 0, Step 789: train/loss = 0.5388040542602539, train/raw-loss = 0.4480697810649872, train/logprobs = tensor([[-1.5980, -2.9712],
        [-3.0008, -1.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18146857619285583
Epoch 0, Step 790: train/loss = 0.47942620515823364, train/raw-loss = 0.37541699409484863, train/logprobs = tensor([[-1.6075, -3.8582],
        [-2.9611, -1.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20801839232444763
Epoch 0, Step 791: train/loss = 0.4050576686859131, train/raw-loss = 0.31278184056282043, train/logprobs = tensor([[-0.6997, -4.3732],
        [-1.7650, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18455162644386292
Epoch 0, Step 792: train/loss = 0.3704591989517212, train/raw-loss = 0.23856320977210999, train/logprobs = tensor([[-1.2832, -3.0656],
        [-3.9875, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2637920379638672
Epoch 0, Step 793: train/loss = 0.37751030921936035, train/raw-loss = 0.2788660526275635, train/logprobs = tensor([[-0.9574, -4.0199],
        [-2.0009, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19728849828243256
Epoch 0, Step 794: train/loss = 0.2671632170677185, train/raw-loss = 0.167232483625412, train/logprobs = tensor([[-0.9096, -4.5946],
        [-2.3106, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19986146688461304
Epoch 0, Step 795: train/loss = 0.4221654236316681, train/raw-loss = 0.3096543550491333, train/logprobs = tensor([[-1.1158, -2.6713],
        [-3.4368, -1.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2250220775604248
Epoch 0, Step 796: train/loss = 0.3126872777938843, train/raw-loss = 0.20754295587539673, train/logprobs = tensor([[-1.5709, -4.1051],
        [-4.0337, -2.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102886587381363
Epoch 0, Step 797: train/loss = 0.2630060017108917, train/raw-loss = 0.16238079965114594, train/logprobs = tensor([[-0.8995, -3.5647],
        [-3.0569, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20125041902065277
Epoch 0, Step 798: train/loss = 0.4136630892753601, train/raw-loss = 0.32987239956855774, train/logprobs = tensor([[-1.0954, -3.4088],
        [-1.7507, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16758142411708832
Epoch 0, Step 799: train/loss = 0.5287315845489502, train/raw-loss = 0.4310694634914398, train/logprobs = tensor([[-0.7622, -3.6759],
        [-1.6870, -1.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19532421231269836
Epoch 0, Step 800: train/loss = 0.6078296899795532, train/raw-loss = 0.5142608880996704, train/logprobs = tensor([[-1.1823, -1.2694],
        [-2.7330, -1.2527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18713757395744324
Epoch 0, Step 801: train/loss = 0.39704716205596924, train/raw-loss = 0.3156548738479614, train/logprobs = tensor([[-0.9841, -5.0239],
        [-1.1762, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16278456151485443
Epoch 0, Step 802: train/loss = 0.44638216495513916, train/raw-loss = 0.3627833127975464, train/logprobs = tensor([[-0.8699, -3.4593],
        [-1.7051, -1.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16719770431518555
Epoch 0, Step 803: train/loss = 0.6634262800216675, train/raw-loss = 0.5745064616203308, train/logprobs = tensor([[-0.8495, -1.3799],
        [-1.7551, -1.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17783959209918976
Epoch 0, Step 804: train/loss = 0.5039159655570984, train/raw-loss = 0.4286425709724426, train/logprobs = tensor([[-0.8146, -3.9509],
        [-1.1868, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15054675936698914
Epoch 0, Step 805: train/loss = 0.43083280324935913, train/raw-loss = 0.3454686105251312, train/logprobs = tensor([[-1.2274, -5.0913],
        [-2.0903, -1.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17072835564613342
Epoch 0, Step 806: train/loss = 0.45901721715927124, train/raw-loss = 0.3714448809623718, train/logprobs = tensor([[-0.9074, -2.8756],
        [-2.3447, -1.3132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17514468729496002
Epoch 0, Step 807: train/loss = 0.5955435037612915, train/raw-loss = 0.5169992446899414, train/logprobs = tensor([[-1.7329, -3.1967],
        [-3.3612, -2.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15708845853805542
Epoch 0, Step 808: train/loss = 0.2642800509929657, train/raw-loss = 0.175746351480484, train/logprobs = tensor([[-1.6983, -5.5148],
        [-3.3068, -1.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17706739902496338
Epoch 0, Step 809: train/loss = 0.7747097611427307, train/raw-loss = 0.6565297842025757, train/logprobs = tensor([[-0.8733, -1.0940],
        [-2.0202, -1.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23635996878147125
Epoch 0, Step 810: train/loss = 0.546835720539093, train/raw-loss = 0.44680166244506836, train/logprobs = tensor([[-2.3567, -3.4546],
        [-3.3745, -1.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20006808638572693
Epoch 0, Step 811: train/loss = 0.3961791396141052, train/raw-loss = 0.3122985363006592, train/logprobs = tensor([[-0.8176, -3.3209],
        [-2.1692, -0.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16776128113269806
Epoch 0, Step 812: train/loss = 0.3775877058506012, train/raw-loss = 0.29342320561408997, train/logprobs = tensor([[-1.3682, -3.8438],
        [-2.7547, -1.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16832900047302246
Epoch 0, Step 813: train/loss = 0.3236222267150879, train/raw-loss = 0.21921655535697937, train/logprobs = tensor([[-1.3727, -4.5037],
        [-2.7875, -0.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20881132781505585
Epoch 0, Step 814: train/loss = 0.36957287788391113, train/raw-loss = 0.2863781452178955, train/logprobs = tensor([[-1.6905, -3.8426],
        [-2.8240, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16638942062854767
Epoch 0, Step 815: train/loss = 0.2904401123523712, train/raw-loss = 0.18463467061519623, train/logprobs = tensor([[-1.0237, -4.3216],
        [-2.4142, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21161088347434998
Epoch 0, Step 816: train/loss = 0.3750893473625183, train/raw-loss = 0.28969424962997437, train/logprobs = tensor([[-2.3363, -5.2796],
        [-3.1365, -1.7739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17079021036624908
Epoch 0, Step 817: train/loss = 0.35446956753730774, train/raw-loss = 0.23921282589435577, train/logprobs = tensor([[-0.8515, -4.3063],
        [-2.7732, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23051349818706512
Epoch 0, Step 818: train/loss = 0.3167726397514343, train/raw-loss = 0.2284153550863266, train/logprobs = tensor([[-1.5893, -3.2255],
        [-3.5024, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17671461403369904
Epoch 0, Step 819: train/loss = 0.24018594622612, train/raw-loss = 0.14117570221424103, train/logprobs = tensor([[-1.4485, -4.9562],
        [-3.7734, -0.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19802045822143555
Epoch 0, Step 820: train/loss = 0.33486127853393555, train/raw-loss = 0.2335166037082672, train/logprobs = tensor([[-0.9153, -4.9317],
        [-2.3911, -1.2280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20268931984901428
Epoch 0, Step 821: train/loss = 0.2925918996334076, train/raw-loss = 0.19316211342811584, train/logprobs = tensor([[-1.3807, -4.4451],
        [-3.2363, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1988595575094223
Epoch 0, Step 822: train/loss = 0.22694918513298035, train/raw-loss = 0.11156774312257767, train/logprobs = tensor([[-1.5493, -4.6122],
        [-3.8508, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23076288402080536
Epoch 0, Step 823: train/loss = 0.4004480540752411, train/raw-loss = 0.2942713797092438, train/logprobs = tensor([[-1.2367, -3.8447],
        [-3.1817, -1.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21235334873199463
Epoch 0, Step 824: train/loss = 0.5447694063186646, train/raw-loss = 0.44005075097084045, train/logprobs = tensor([[-0.8704, -2.2913],
        [-2.3176, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.209437295794487
Epoch 0, Step 825: train/loss = 0.39629775285720825, train/raw-loss = 0.2874140739440918, train/logprobs = tensor([[-1.6933, -5.3859],
        [-3.2342, -1.5866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21776731312274933
Epoch 0, Step 826: train/loss = 0.3126959800720215, train/raw-loss = 0.2208782434463501, train/logprobs = tensor([[-0.9819, -5.2742],
        [-1.8101, -1.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18363550305366516
Epoch 0, Step 827: train/loss = 0.46787169575691223, train/raw-loss = 0.36291563510894775, train/logprobs = tensor([[-1.2230, -2.7203],
        [-3.1593, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20991213619709015
Epoch 0, Step 828: train/loss = 0.4597213566303253, train/raw-loss = 0.38680344820022583, train/logprobs = tensor([[-1.4529, -3.2276],
        [-3.0845, -2.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14583584666252136
Epoch 0, Step 829: train/loss = 0.3396727442741394, train/raw-loss = 0.22463491559028625, train/logprobs = tensor([[-1.1764, -3.6766],
        [-4.0613, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2300756275653839
Epoch 0, Step 830: train/loss = 0.4184606969356537, train/raw-loss = 0.316048264503479, train/logprobs = tensor([[-1.2461, -3.5529],
        [-2.5621, -1.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20482495427131653
Epoch 0, Step 831: train/loss = 0.37587904930114746, train/raw-loss = 0.2726069688796997, train/logprobs = tensor([[-1.5618, -2.3901],
        [-4.5928, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20654413104057312
Epoch 0, Step 832: train/loss = 0.5284261107444763, train/raw-loss = 0.4116693139076233, train/logprobs = tensor([[-2.1749, -2.9228],
        [-3.4641, -1.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23351365327835083
Epoch 0, Step 833: train/loss = 0.60248863697052, train/raw-loss = 0.5129441022872925, train/logprobs = tensor([[-2.2405, -2.6133],
        [-3.2050, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790890395641327
Epoch 0, Step 834: train/loss = 0.32030242681503296, train/raw-loss = 0.22355975210666656, train/logprobs = tensor([[-0.9351, -4.8994],
        [-1.9720, -1.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.193485289812088
Epoch 0, Step 835: train/loss = 0.36503487825393677, train/raw-loss = 0.2859029471874237, train/logprobs = tensor([[-1.3545, -3.3914],
        [-2.9411, -1.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1582638919353485
Epoch 0, Step 836: train/loss = 0.5416512489318848, train/raw-loss = 0.4443676471710205, train/logprobs = tensor([[-1.0511, -2.4387],
        [-2.4919, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19456717371940613
Epoch 0, Step 837: train/loss = 0.27690204977989197, train/raw-loss = 0.19898183643817902, train/logprobs = tensor([[-0.9505, -6.0433],
        [-1.5984, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1558404266834259
Epoch 0, Step 838: train/loss = 0.2360609769821167, train/raw-loss = 0.1276147961616516, train/logprobs = tensor([[-1.3719, -4.4846],
        [-3.7860, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21689236164093018
Epoch 0, Step 839: train/loss = 0.6643948554992676, train/raw-loss = 0.5745058059692383, train/logprobs = tensor([[-1.2046, -1.2321],
        [-1.7382, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17977818846702576
Epoch 0, Step 840: train/loss = 0.26311105489730835, train/raw-loss = 0.16823026537895203, train/logprobs = tensor([[-1.3852, -5.3346],
        [-3.0439, -1.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18976157903671265
Epoch 0, Step 841: train/loss = 0.343269407749176, train/raw-loss = 0.2696811258792877, train/logprobs = tensor([[-1.3705, -4.8110],
        [-2.2488, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14717654883861542
Epoch 0, Step 842: train/loss = 0.4490935802459717, train/raw-loss = 0.3528560400009155, train/logprobs = tensor([[-1.2746, -3.5243],
        [-1.7507, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1924750804901123
Epoch 0, Step 843: train/loss = 0.3687307834625244, train/raw-loss = 0.2818460166454315, train/logprobs = tensor([[-0.8789, -5.3063],
        [-1.5490, -1.1838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17376956343650818
Epoch 0, Step 844: train/loss = 0.49777740240097046, train/raw-loss = 0.42153847217559814, train/logprobs = tensor([[-1.4240, -2.5613],
        [-2.1426, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15247778594493866
Epoch 0, Step 845: train/loss = 0.46364936232566833, train/raw-loss = 0.39060020446777344, train/logprobs = tensor([[-1.0255, -3.6943],
        [-2.3884, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14609825611114502
Epoch 0, Step 846: train/loss = 0.25474268198013306, train/raw-loss = 0.16257978975772858, train/logprobs = tensor([[-1.1626, -4.5295],
        [-3.4325, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18432581424713135
Epoch 0, Step 847: train/loss = 0.4422646760940552, train/raw-loss = 0.3641125559806824, train/logprobs = tensor([[-0.7000, -3.8009],
        [-1.2844, -1.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15630421042442322
Epoch 0, Step 848: train/loss = 0.6473878026008606, train/raw-loss = 0.5676677227020264, train/logprobs = tensor([[-2.4429, -5.2899],
        [-2.2777, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15944012999534607
Epoch 0, Step 849: train/loss = 0.28405696153640747, train/raw-loss = 0.18557289242744446, train/logprobs = tensor([[-1.2331, -3.9493],
        [-2.2616, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19696810841560364
Epoch 0, Step 850: train/loss = 0.38219672441482544, train/raw-loss = 0.3114359676837921, train/logprobs = tensor([[-1.5137, -3.7847],
        [-2.9645, -1.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14152151346206665
Epoch 0, Step 851: train/loss = 0.4773269295692444, train/raw-loss = 0.41057872772216797, train/logprobs = tensor([[-0.8362, -4.5587],
        [-1.0459, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13349632918834686
Epoch 0, Step 852: train/loss = 0.3489978015422821, train/raw-loss = 0.24869227409362793, train/logprobs = tensor([[-1.6837, -4.3376],
        [-2.7867, -1.4078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20061108469963074
Epoch 0, Step 853: train/loss = 0.6433557271957397, train/raw-loss = 0.5693247318267822, train/logprobs = tensor([[-1.6153, -2.5302],
        [-1.7880, -1.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480620950460434
Epoch 0, Step 854: train/loss = 0.5239760875701904, train/raw-loss = 0.4363383650779724, train/logprobs = tensor([[-0.6440, -1.7087],
        [-1.9151, -1.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17527535557746887
Epoch 0, Step 855: train/loss = 0.24289345741271973, train/raw-loss = 0.14625515043735504, train/logprobs = tensor([[-1.3536, -5.5589],
        [-3.4141, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19327661395072937
Epoch 0, Step 856: train/loss = 0.33270135521888733, train/raw-loss = 0.24311880767345428, train/logprobs = tensor([[-1.1112, -4.3072],
        [-2.6169, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1791650950908661
Epoch 0, Step 857: train/loss = 0.5545021295547485, train/raw-loss = 0.49229007959365845, train/logprobs = tensor([[-1.5485, -3.0359],
        [-2.0390, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244240552186966
Epoch 0, Step 858: train/loss = 0.4520481526851654, train/raw-loss = 0.36189061403274536, train/logprobs = tensor([[-0.7699, -2.9774],
        [-2.9295, -1.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1803150773048401
Epoch 0, Step 859: train/loss = 0.4321061968803406, train/raw-loss = 0.3571091294288635, train/logprobs = tensor([[-1.1233, -3.3908],
        [-1.6735, -1.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14999422430992126
Epoch 0, Step 860: train/loss = 0.19633516669273376, train/raw-loss = 0.10127183794975281, train/logprobs = tensor([[-1.7394, -6.0299],
        [-4.2957, -0.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1901266872882843
Epoch 0, Step 861: train/loss = 0.4132911264896393, train/raw-loss = 0.3414258062839508, train/logprobs = tensor([[-0.9375, -5.1024],
        [-1.2925, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14373064041137695
Epoch 0, Step 862: train/loss = 0.49109429121017456, train/raw-loss = 0.42443057894706726, train/logprobs = tensor([[-1.1295, -2.9138],
        [-1.4438, -1.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13332748413085938
Epoch 0, Step 863: train/loss = 0.32829147577285767, train/raw-loss = 0.2340366095304489, train/logprobs = tensor([[-0.8059, -5.4230],
        [-2.2544, -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885097771883011
Epoch 0, Step 864: train/loss = 0.30398908257484436, train/raw-loss = 0.19693025946617126, train/logprobs = tensor([[-1.1898, -4.6063],
        [-2.9772, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21411767601966858
Epoch 0, Step 865: train/loss = 0.22829829156398773, train/raw-loss = 0.13505524396896362, train/logprobs = tensor([[-1.5082, -5.4468],
        [-3.7974, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1864861249923706
Epoch 0, Step 866: train/loss = 0.5753929615020752, train/raw-loss = 0.5088684558868408, train/logprobs = tensor([[-2.4061, -1.8416],
        [-3.8385, -0.9178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13304904103279114
Epoch 0, Step 867: train/loss = 0.21054847538471222, train/raw-loss = 0.1268884539604187, train/logprobs = tensor([[-0.8634, -6.6684],
        [-2.2838, -0.8021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16732004284858704
Epoch 0, Step 868: train/loss = 0.6501451730728149, train/raw-loss = 0.5742704272270203, train/logprobs = tensor([[-1.2926, -2.9015],
        [-2.0456, -1.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15174947679042816
Epoch 0, Step 869: train/loss = 0.4685506224632263, train/raw-loss = 0.39431676268577576, train/logprobs = tensor([[-1.2592, -4.2197],
        [-2.3049, -1.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14846767485141754
Epoch 0, Step 870: train/loss = 0.2195393443107605, train/raw-loss = 0.119443878531456, train/logprobs = tensor([[-1.0991, -5.0207],
        [-2.9950, -1.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200190931558609
Epoch 0, Step 871: train/loss = 0.5289733409881592, train/raw-loss = 0.44969066977500916, train/logprobs = tensor([[-1.3456, -1.7319],
        [-2.4892, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15856534242630005
Epoch 0, Step 872: train/loss = 0.4409715235233307, train/raw-loss = 0.3693302869796753, train/logprobs = tensor([[-0.8312, -2.5132],
        [-1.7585, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14328248798847198
Epoch 0, Step 873: train/loss = 0.44820964336395264, train/raw-loss = 0.36429187655448914, train/logprobs = tensor([[-1.1705, -4.0840],
        [-3.1999, -2.2460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16783550381660461
Epoch 0, Step 874: train/loss = 0.5175817012786865, train/raw-loss = 0.43795523047447205, train/logprobs = tensor([[-1.0303, -4.0497],
        [-1.9207, -1.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15925288200378418
Epoch 0, Step 875: train/loss = 0.590501606464386, train/raw-loss = 0.5111099481582642, train/logprobs = tensor([[-1.0952, -2.3531],
        [-2.0832, -0.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1587832272052765
Epoch 0, Step 876: train/loss = 0.26062679290771484, train/raw-loss = 0.17344939708709717, train/logprobs = tensor([[-0.8525, -4.7714],
        [-1.7294, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17435476183891296
Epoch 0, Step 877: train/loss = 0.49138182401657104, train/raw-loss = 0.4150373637676239, train/logprobs = tensor([[-0.9510, -3.0669],
        [-1.7166, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1526889055967331
Epoch 0, Step 878: train/loss = 0.3457403779029846, train/raw-loss = 0.2616754472255707, train/logprobs = tensor([[-1.2964, -4.7331],
        [-2.4339, -1.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1681298166513443
Epoch 0, Step 879: train/loss = 0.5494117736816406, train/raw-loss = 0.4788897931575775, train/logprobs = tensor([[-0.8641, -3.6196],
        [-1.2935, -1.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1410439908504486
Epoch 0, Step 880: train/loss = 0.2872326374053955, train/raw-loss = 0.20157290995121002, train/logprobs = tensor([[-1.0799, -4.5283],
        [-2.3354, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17131942510604858
Epoch 0, Step 881: train/loss = 0.4877423048019409, train/raw-loss = 0.41298604011535645, train/logprobs = tensor([[-1.1221, -2.5274],
        [-1.8750, -1.2962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14951251447200775
Epoch 0, Step 882: train/loss = 0.9249916672706604, train/raw-loss = 0.8422576189041138, train/logprobs = tensor([[-2.0699, -3.5078],
        [-2.7242, -2.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654680371284485
Epoch 0, Step 883: train/loss = 0.3644617199897766, train/raw-loss = 0.29048699140548706, train/logprobs = tensor([[-1.0258, -3.7460],
        [-1.9127, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14794950187206268
Epoch 0, Step 884: train/loss = 0.25331366062164307, train/raw-loss = 0.15586020052433014, train/logprobs = tensor([[-1.0766, -4.1378],
        [-3.2098, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19490692019462585
Epoch 0, Step 885: train/loss = 0.24563220143318176, train/raw-loss = 0.16672596335411072, train/logprobs = tensor([[-0.7614, -8.1752],
        [-1.8808, -1.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15781249105930328
Epoch 0, Step 886: train/loss = 0.5513678789138794, train/raw-loss = 0.458645761013031, train/logprobs = tensor([[-1.0797, -4.2697],
        [-2.6305, -1.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18544422090053558
Epoch 0, Step 887: train/loss = 0.3773402273654938, train/raw-loss = 0.3022277057170868, train/logprobs = tensor([[-1.3594, -4.3209],
        [-2.8779, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15022504329681396
Epoch 0, Step 888: train/loss = 0.22142933309078217, train/raw-loss = 0.12758581340312958, train/logprobs = tensor([[-0.7888, -6.1140],
        [-2.2035, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18768705427646637
Epoch 0, Step 889: train/loss = 0.35518819093704224, train/raw-loss = 0.2692776024341583, train/logprobs = tensor([[-1.3649, -3.0505],
        [-3.1712, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1718212068080902
Epoch 0, Step 890: train/loss = 0.5320059657096863, train/raw-loss = 0.46647071838378906, train/logprobs = tensor([[-0.7791, -1.2111],
        [-1.5869, -0.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13107053935527802
Epoch 0, Step 891: train/loss = 0.4679693579673767, train/raw-loss = 0.39564207196235657, train/logprobs = tensor([[-0.9626, -3.5613],
        [-1.4288, -0.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1446545571088791
Epoch 0, Step 892: train/loss = 0.2992907166481018, train/raw-loss = 0.1965211033821106, train/logprobs = tensor([[-1.1199, -4.1041],
        [-3.3536, -1.4885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20553921163082123
Epoch 0, Step 893: train/loss = 0.388560950756073, train/raw-loss = 0.31451886892318726, train/logprobs = tensor([[-0.9227, -3.6820],
        [-2.0455, -1.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480841487646103
Epoch 0, Step 894: train/loss = 0.3450314998626709, train/raw-loss = 0.2510869801044464, train/logprobs = tensor([[-0.9127, -4.9195],
        [-2.7158, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1878890097141266
Epoch 0, Step 895: train/loss = 0.5494155287742615, train/raw-loss = 0.4949047267436981, train/logprobs = tensor([[-0.8849, -2.6455],
        [-1.0726, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10902155935764313
Epoch 0, Step 896: train/loss = 0.6460753679275513, train/raw-loss = 0.5750205516815186, train/logprobs = tensor([[-2.1338, -4.9759],
        [-2.2057, -2.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14210951328277588
Epoch 0, Step 897: train/loss = 0.3251819610595703, train/raw-loss = 0.22394996881484985, train/logprobs = tensor([[-0.9491, -5.4363],
        [-2.5049, -1.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20246395468711853
Epoch 0, Step 898: train/loss = 0.36124181747436523, train/raw-loss = 0.28138959407806396, train/logprobs = tensor([[-0.9641, -4.2280],
        [-1.9524, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15970449149608612
Epoch 0, Step 899: train/loss = 0.3003654479980469, train/raw-loss = 0.22295251488685608, train/logprobs = tensor([[-0.9640, -4.4968],
        [-1.7262, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15482589602470398
Epoch 0, Step 900: train/loss = 0.5587018728256226, train/raw-loss = 0.4964441657066345, train/logprobs = tensor([[-1.2288, -4.0330],
        [-1.2003, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12451539933681488
Epoch 0, Step 901: train/loss = 0.5026932954788208, train/raw-loss = 0.41028517484664917, train/logprobs = tensor([[-2.8689, -3.7721],
        [-3.7698, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18481619656085968
Epoch 0, Step 902: train/loss = 0.3945057988166809, train/raw-loss = 0.3181438446044922, train/logprobs = tensor([[-1.4534, -4.3331],
        [-2.7950, -1.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15272392332553864
Epoch 0, Step 903: train/loss = 0.4016399383544922, train/raw-loss = 0.3260129988193512, train/logprobs = tensor([[-1.2638, -2.5759],
        [-2.7579, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15125387907028198
Epoch 0, Step 904: train/loss = 0.47835811972618103, train/raw-loss = 0.3910920321941376, train/logprobs = tensor([[-1.4559, -3.8312],
        [-2.3973, -1.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745322048664093
Epoch 0, Step 905: train/loss = 0.508285403251648, train/raw-loss = 0.4354700446128845, train/logprobs = tensor([[-0.7845, -3.6263],
        [-0.9709, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14563076198101044
Epoch 0, Step 906: train/loss = 0.20506015419960022, train/raw-loss = 0.11950188875198364, train/logprobs = tensor([[-1.4514, -7.2233],
        [-3.0587, -2.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17111653089523315
Epoch 0, Step 907: train/loss = 0.5924592018127441, train/raw-loss = 0.5217787623405457, train/logprobs = tensor([[-0.8890, -1.3844],
        [-1.9602, -0.7049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14136087894439697
Epoch 0, Step 908: train/loss = 0.8172551989555359, train/raw-loss = 0.7502347826957703, train/logprobs = tensor([[-1.3038, -1.1466],
        [-1.9010, -1.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13404077291488647
Epoch 0, Step 909: train/loss = 0.3652607202529907, train/raw-loss = 0.2801540195941925, train/logprobs = tensor([[-1.0246, -4.2433],
        [-2.4235, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17021343111991882
Epoch 0, Step 910: train/loss = 0.3957447409629822, train/raw-loss = 0.30959635972976685, train/logprobs = tensor([[-1.9751, -3.5924],
        [-3.7385, -1.2240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17229686677455902
Epoch 0, Step 911: train/loss = 0.746828556060791, train/raw-loss = 0.6938647031784058, train/logprobs = tensor([[-1.7677, -2.4733],
        [-1.1586, -0.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10592775046825409
Epoch 0, Step 912: train/loss = 0.46263831853866577, train/raw-loss = 0.40145155787467957, train/logprobs = tensor([[-0.9063, -2.9339],
        [-1.1157, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12237350642681122
Epoch 0, Step 913: train/loss = 0.3026907444000244, train/raw-loss = 0.23207533359527588, train/logprobs = tensor([[-0.9841, -6.3209],
        [-1.3465, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14123086631298065
Epoch 0, Step 914: train/loss = 0.30207884311676025, train/raw-loss = 0.2092951536178589, train/logprobs = tensor([[-0.9781, -2.0577],
        [-3.6273, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18556740880012512
Epoch 0, Step 915: train/loss = 0.42998990416526794, train/raw-loss = 0.3642764091491699, train/logprobs = tensor([[-1.1605, -3.2779],
        [-2.5573, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13142703473567963
Epoch 0, Step 916: train/loss = 0.5661040544509888, train/raw-loss = 0.498157262802124, train/logprobs = tensor([[-0.8224, -2.0278],
        [-1.3706, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358935683965683
Epoch 0, Step 917: train/loss = 0.18144874274730682, train/raw-loss = 0.08428357541561127, train/logprobs = tensor([[-1.3727, -6.8810],
        [-3.7746, -1.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19433030486106873
Epoch 0, Step 918: train/loss = 0.31894373893737793, train/raw-loss = 0.24072210490703583, train/logprobs = tensor([[-0.9272, -4.1420],
        [-2.4150, -1.0687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15644331276416779
Epoch 0, Step 919: train/loss = 0.47304588556289673, train/raw-loss = 0.401950478553772, train/logprobs = tensor([[-1.1269, -4.0244],
        [-1.6036, -1.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1421908289194107
Epoch 0, Step 920: train/loss = 0.4373526871204376, train/raw-loss = 0.36079201102256775, train/logprobs = tensor([[-0.9042, -2.8881],
        [-2.6984, -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15312136709690094
Epoch 0, Step 921: train/loss = 0.44597795605659485, train/raw-loss = 0.3810728192329407, train/logprobs = tensor([[-0.9074, -3.5333],
        [-1.2198, -0.6661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12981025874614716
Epoch 0, Step 922: train/loss = 0.4657086730003357, train/raw-loss = 0.40328139066696167, train/logprobs = tensor([[-1.2995, -3.8033],
        [-2.5151, -1.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12485450506210327
Epoch 0, Step 923: train/loss = 0.3924414813518524, train/raw-loss = 0.3303828239440918, train/logprobs = tensor([[-0.8099, -4.3816],
        [-1.5874, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12411726266145706
Epoch 0, Step 924: train/loss = 0.3707595467567444, train/raw-loss = 0.3025680482387543, train/logprobs = tensor([[-1.5294, -4.7301],
        [-2.0163, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1363830268383026
Epoch 0, Step 925: train/loss = 0.397247314453125, train/raw-loss = 0.31711745262145996, train/logprobs = tensor([[-0.8016, -3.3841],
        [-1.6630, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16025976836681366
Epoch 0, Step 926: train/loss = 0.21731044352054596, train/raw-loss = 0.11721688508987427, train/logprobs = tensor([[-1.0550, -5.9684],
        [-2.6571, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.200187087059021
Epoch 0, Step 927: train/loss = 0.500632643699646, train/raw-loss = 0.40032464265823364, train/logprobs = tensor([[-1.1239, -4.3216],
        [-2.9806, -2.1382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20061597228050232
Epoch 0, Step 928: train/loss = 0.5987390875816345, train/raw-loss = 0.5162924528121948, train/logprobs = tensor([[-2.2212, -3.2605],
        [-2.5546, -1.4141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648932844400406
Epoch 0, Step 929: train/loss = 0.3604613244533539, train/raw-loss = 0.2881172001361847, train/logprobs = tensor([[-1.1287, -4.5338],
        [-2.5752, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14468823373317719
Epoch 0, Step 930: train/loss = 0.598008394241333, train/raw-loss = 0.5261417031288147, train/logprobs = tensor([[-1.3937, -2.3789],
        [-1.6475, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14373336732387543
Epoch 0, Step 931: train/loss = 0.6013957262039185, train/raw-loss = 0.530715823173523, train/logprobs = tensor([[-0.7889, -2.8287],
        [-1.3483, -1.1038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14135980606079102
Epoch 0, Step 932: train/loss = 0.5175362825393677, train/raw-loss = 0.4532053470611572, train/logprobs = tensor([[-1.1053, -1.8728],
        [-2.0031, -0.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286618709564209
Epoch 0, Step 933: train/loss = 0.4295384883880615, train/raw-loss = 0.35612285137176514, train/logprobs = tensor([[-0.8163, -4.0227],
        [-1.7519, -0.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14683124423027039
Epoch 0, Step 934: train/loss = 0.6028565764427185, train/raw-loss = 0.5160642862319946, train/logprobs = tensor([[-2.4235, -4.8872],
        [-2.5290, -1.4205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17358452081680298
Epoch 0, Step 935: train/loss = 0.2391258329153061, train/raw-loss = 0.1361280381679535, train/logprobs = tensor([[-1.4577, -4.5492],
        [-3.0626, -1.0831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2059955894947052
Epoch 0, Step 936: train/loss = 0.37842702865600586, train/raw-loss = 0.3120141625404358, train/logprobs = tensor([[-0.8708, -3.5788],
        [-1.3139, -1.0041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13282576203346252
Epoch 0, Step 937: train/loss = 0.29093390703201294, train/raw-loss = 0.1886352300643921, train/logprobs = tensor([[-1.4619, -3.6418],
        [-3.3968, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045973390340805
Epoch 0, Step 938: train/loss = 0.6023168563842773, train/raw-loss = 0.5293381810188293, train/logprobs = tensor([[-2.4908, -5.7831],
        [-1.5500, -1.4964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14595729112625122
Epoch 0, Step 939: train/loss = 0.7194129228591919, train/raw-loss = 0.6364898681640625, train/logprobs = tensor([[-0.7612, -2.7538],
        [-1.1609, -1.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16584612429141998
Epoch 0, Step 940: train/loss = 0.3144981563091278, train/raw-loss = 0.22936034202575684, train/logprobs = tensor([[-1.7317, -5.4448],
        [-2.8421, -1.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17027558386325836
Epoch 0, Step 941: train/loss = 0.5096559524536133, train/raw-loss = 0.4336974620819092, train/logprobs = tensor([[-1.5381, -4.5628],
        [-1.5983, -1.4375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15191695094108582
Epoch 0, Step 942: train/loss = 0.3556674122810364, train/raw-loss = 0.26808008551597595, train/logprobs = tensor([[-1.1202, -4.8281],
        [-2.1300, -0.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17517468333244324
Epoch 0, Step 943: train/loss = 0.4752577245235443, train/raw-loss = 0.41310229897499084, train/logprobs = tensor([[-1.7399, -3.8106],
        [-2.0694, -0.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12431087344884872
Epoch 0, Step 944: train/loss = 0.26229649782180786, train/raw-loss = 0.18483102321624756, train/logprobs = tensor([[-0.8558, -4.9924],
        [-1.9856, -0.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549309492111206
Epoch 0, Step 945: train/loss = 0.41192030906677246, train/raw-loss = 0.33137911558151245, train/logprobs = tensor([[-2.2585, -3.9767],
        [-3.2079, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16108238697052002
Epoch 0, Step 946: train/loss = 0.21019060909748077, train/raw-loss = 0.13237981498241425, train/logprobs = tensor([[-0.8138, -6.8387],
        [-1.9765, -1.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15562155842781067
Epoch 0, Step 947: train/loss = 0.5744146108627319, train/raw-loss = 0.5031502842903137, train/logprobs = tensor([[-1.3896, -1.8626],
        [-1.8210, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14252863824367523
Epoch 0, Step 948: train/loss = 0.4461379647254944, train/raw-loss = 0.37249553203582764, train/logprobs = tensor([[-0.5372, -3.6907],
        [-1.1416, -1.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472848504781723
Epoch 0, Step 949: train/loss = 0.8972296714782715, train/raw-loss = 0.8049678802490234, train/logprobs = tensor([[-3.6203, -3.6419],
        [-3.5693, -2.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1845235824584961
Epoch 0, Step 950: train/loss = 0.5486165285110474, train/raw-loss = 0.48315513134002686, train/logprobs = tensor([[-1.5180, -2.7470],
        [-2.3112, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13092279434204102
Epoch 0, Step 951: train/loss = 0.5245757699012756, train/raw-loss = 0.46718135476112366, train/logprobs = tensor([[-1.2609, -1.4810],
        [-2.1717, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11478888988494873
Epoch 0, Step 952: train/loss = 0.3571234345436096, train/raw-loss = 0.25795844197273254, train/logprobs = tensor([[-1.3567, -3.1098],
        [-3.6004, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19832995533943176
Epoch 0, Step 953: train/loss = 0.3076130747795105, train/raw-loss = 0.232690691947937, train/logprobs = tensor([[-0.8693, -3.9936],
        [-1.9924, -0.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14984479546546936
Epoch 0, Step 954: train/loss = 0.46563956141471863, train/raw-loss = 0.38997846841812134, train/logprobs = tensor([[-1.0082, -2.9175],
        [-2.3469, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15132218599319458
Epoch 0, Step 955: train/loss = 0.2606199085712433, train/raw-loss = 0.1746089607477188, train/logprobs = tensor([[-1.1002, -5.8699],
        [-2.2822, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17202185094356537
Epoch 0, Step 956: train/loss = 0.5137736797332764, train/raw-loss = 0.45573559403419495, train/logprobs = tensor([[-2.5096, -4.1984],
        [-3.6216, -3.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11607611924409866
Epoch 0, Step 957: train/loss = 0.4700792133808136, train/raw-loss = 0.3924967348575592, train/logprobs = tensor([[-1.2425, -3.9781],
        [-2.2606, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1551649123430252
Epoch 0, Step 958: train/loss = 0.3569241166114807, train/raw-loss = 0.27457696199417114, train/logprobs = tensor([[-0.8338, -2.8947],
        [-2.1987, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16469424962997437
Epoch 0, Step 959: train/loss = 0.4417332112789154, train/raw-loss = 0.35777050256729126, train/logprobs = tensor([[-0.9871, -3.5578],
        [-2.1233, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16792544722557068
Epoch 0, Step 960: train/loss = 0.3380616009235382, train/raw-loss = 0.25832802057266235, train/logprobs = tensor([[-0.7556, -5.4893],
        [-1.2776, -1.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15946722030639648
Epoch 0, Step 961: train/loss = 0.3356654942035675, train/raw-loss = 0.2453586906194687, train/logprobs = tensor([[-1.1509, -5.4571],
        [-2.2598, -0.9419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18061359226703644
Epoch 0, Step 962: train/loss = 0.2558516263961792, train/raw-loss = 0.16326087713241577, train/logprobs = tensor([[-1.0541, -4.5968],
        [-2.9948, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18518151342868805
Epoch 0, Step 963: train/loss = 0.6324777007102966, train/raw-loss = 0.5551167726516724, train/logprobs = tensor([[-1.1059, -3.2710],
        [-1.9760, -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547219157218933
Epoch 0, Step 964: train/loss = 0.5263223648071289, train/raw-loss = 0.4276638925075531, train/logprobs = tensor([[-1.1521, -3.8836],
        [-3.1135, -2.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19731689989566803
Epoch 0, Step 965: train/loss = 0.40084341168403625, train/raw-loss = 0.3173505365848541, train/logprobs = tensor([[-1.1438, -4.2075],
        [-2.1695, -1.7036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16698569059371948
Epoch 0, Step 966: train/loss = 0.3936048150062561, train/raw-loss = 0.31564459204673767, train/logprobs = tensor([[-1.2118, -3.6241],
        [-1.9547, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15592041611671448
Epoch 0, Step 967: train/loss = 0.24398168921470642, train/raw-loss = 0.16558949649333954, train/logprobs = tensor([[-0.8974, -6.5738],
        [-1.7738, -1.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15678438544273376
Epoch 0, Step 968: train/loss = 0.5821539163589478, train/raw-loss = 0.507307767868042, train/logprobs = tensor([[-1.3980, -1.6031],
        [-2.6651, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14969216287136078
Epoch 0, Step 969: train/loss = 0.3643187880516052, train/raw-loss = 0.29604625701904297, train/logprobs = tensor([[-0.8343, -4.1854],
        [-1.3621, -1.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365450918674469
Epoch 0, Step 970: train/loss = 0.42013493180274963, train/raw-loss = 0.3428112864494324, train/logprobs = tensor([[-0.8000, -5.6462],
        [-1.7254, -1.3353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15464726090431213
Epoch 0, Step 971: train/loss = 0.5659828186035156, train/raw-loss = 0.5165634155273438, train/logprobs = tensor([[-0.6166, -1.6294],
        [-0.8231, -0.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09883885830640793
Epoch 0, Step 972: train/loss = 0.23668479919433594, train/raw-loss = 0.14906682074069977, train/logprobs = tensor([[-0.9739, -5.1138],
        [-2.7684, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17523597180843353
Epoch 0, Step 973: train/loss = 0.39574265480041504, train/raw-loss = 0.32337769865989685, train/logprobs = tensor([[-0.8495, -3.9909],
        [-1.5859, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14472989737987518
Epoch 0, Step 974: train/loss = 0.23503494262695312, train/raw-loss = 0.14075861871242523, train/logprobs = tensor([[-1.1587, -5.2151],
        [-2.5738, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885526329278946
Epoch 0, Step 975: train/loss = 0.5031841993331909, train/raw-loss = 0.43921220302581787, train/logprobs = tensor([[-2.3749, -2.5391],
        [-2.8338, -0.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279439777135849
Epoch 0, Step 976: train/loss = 0.4124133884906769, train/raw-loss = 0.33657488226890564, train/logprobs = tensor([[-1.0861, -2.9933],
        [-2.0161, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516769826412201
Epoch 0, Step 977: train/loss = 0.280916690826416, train/raw-loss = 0.20767143368721008, train/logprobs = tensor([[-0.8051, -6.0377],
        [-1.4610, -1.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14649048447608948
Epoch 0, Step 978: train/loss = 0.41380876302719116, train/raw-loss = 0.33192145824432373, train/logprobs = tensor([[-1.2996, -3.7505],
        [-2.7735, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16377460956573486
Epoch 0, Step 979: train/loss = 0.4776943624019623, train/raw-loss = 0.4193211495876312, train/logprobs = tensor([[-1.0908, -3.3435],
        [-1.9815, -1.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11674639582633972
Epoch 0, Step 980: train/loss = 0.273381769657135, train/raw-loss = 0.18749691545963287, train/logprobs = tensor([[-1.0706, -3.1420],
        [-2.8801, -0.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17176970839500427
Epoch 0, Step 981: train/loss = 0.5444464683532715, train/raw-loss = 0.47101330757141113, train/logprobs = tensor([[-0.7959, -3.5522],
        [-1.6310, -1.8510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14686623215675354
Epoch 0, Step 982: train/loss = 0.6415852308273315, train/raw-loss = 0.5518867373466492, train/logprobs = tensor([[-1.4250, -3.5468],
        [-2.3367, -2.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17939697206020355
Epoch 0, Step 983: train/loss = 0.49713006615638733, train/raw-loss = 0.4245091676712036, train/logprobs = tensor([[-1.3883, -1.5792],
        [-1.8263, -0.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14524176716804504
Epoch 0, Step 984: train/loss = 0.40198928117752075, train/raw-loss = 0.31309038400650024, train/logprobs = tensor([[-0.7512, -3.7023],
        [-1.9100, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17779788374900818
Epoch 0, Step 985: train/loss = 0.20169076323509216, train/raw-loss = 0.11008068919181824, train/logprobs = tensor([[-1.1320, -4.8004],
        [-3.2861, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18322014808654785
Epoch 0, Step 986: train/loss = 0.2739220857620239, train/raw-loss = 0.18122677505016327, train/logprobs = tensor([[-1.6322, -2.0869],
        [-4.1619, -0.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1853906214237213
Epoch 0, Step 987: train/loss = 0.34896573424339294, train/raw-loss = 0.27281999588012695, train/logprobs = tensor([[-1.5219, -4.0360],
        [-2.3717, -0.7042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15229149162769318
Epoch 0, Step 988: train/loss = 0.5715595483779907, train/raw-loss = 0.4896867573261261, train/logprobs = tensor([[-1.4246, -3.8704],
        [-2.8127, -2.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16374555230140686
Epoch 0, Step 989: train/loss = 0.3825717568397522, train/raw-loss = 0.3059321343898773, train/logprobs = tensor([[-0.8155, -4.5695],
        [-1.4937, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15327918529510498
Epoch 0, Step 990: train/loss = 0.43477311730384827, train/raw-loss = 0.3474671244621277, train/logprobs = tensor([[-0.8887, -2.7454],
        [-1.7124, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17461200058460236
Epoch 0, Step 991: train/loss = 0.6159487962722778, train/raw-loss = 0.5436140894889832, train/logprobs = tensor([[-1.1953, -2.3211],
        [-1.2730, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14466938376426697
Epoch 0, Step 992: train/loss = 0.17850248515605927, train/raw-loss = 0.08515918254852295, train/logprobs = tensor([[-1.2052, -9.0687],
        [-3.3580, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18668657541275024
Epoch 0, Step 993: train/loss = 0.42180100083351135, train/raw-loss = 0.34011030197143555, train/logprobs = tensor([[-1.1691, -4.7552],
        [-1.6624, -1.3382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16338138282299042
Epoch 0, Step 994: train/loss = 0.39833271503448486, train/raw-loss = 0.3122141361236572, train/logprobs = tensor([[-1.0037, -3.0310],
        [-2.7802, -1.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17223705351352692
Epoch 0, Step 995: train/loss = 0.25679469108581543, train/raw-loss = 0.17632094025611877, train/logprobs = tensor([[-0.8323, -5.0664],
        [-2.4263, -0.9626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1609475314617157
Epoch 0, Step 996: train/loss = 0.4817160367965698, train/raw-loss = 0.41597312688827515, train/logprobs = tensor([[-2.3012, -6.5202],
        [-2.3978, -2.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1314857453107834
Epoch 0, Step 997: train/loss = 0.4278219938278198, train/raw-loss = 0.36459606885910034, train/logprobs = tensor([[-1.4571, -3.6486],
        [-2.1808, -0.5828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12645182013511658
Epoch 0, Step 998: train/loss = 0.3709425628185272, train/raw-loss = 0.2948687970638275, train/logprobs = tensor([[-1.1809, -4.0373],
        [-2.2370, -0.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15214753150939941
Epoch 0, Step 999: train/loss = 0.30962374806404114, train/raw-loss = 0.22581368684768677, train/logprobs = tensor([[-2.2408, -6.0596],
        [-2.7334, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16762010753154755
eval/loss: nan
Epoch 0, Step 1000: train/loss = 0.5408107042312622, train/raw-loss = 0.4836043119430542, train/logprobs = tensor([[-0.6632, -2.5940],
        [-0.8328, -0.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11441271752119064
Epoch 0, Step 1001: train/loss = 0.268427312374115, train/raw-loss = 0.17397941648960114, train/logprobs = tensor([[-1.3129, -4.4546],
        [-2.9930, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18889576196670532
Epoch 0, Step 1002: train/loss = 0.36758825182914734, train/raw-loss = 0.29752683639526367, train/logprobs = tensor([[-0.5277, -4.0713],
        [-1.1303, -0.7608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14012283086776733
Epoch 0, Step 1003: train/loss = 0.4216456115245819, train/raw-loss = 0.3459613025188446, train/logprobs = tensor([[-1.0110, -3.5435],
        [-1.7541, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15136855840682983
Epoch 0, Step 1004: train/loss = 0.2022051215171814, train/raw-loss = 0.11268916726112366, train/logprobs = tensor([[-1.5194, -3.8441],
        [-4.4630, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1790318787097931
Epoch 0, Step 1005: train/loss = 0.34274035692214966, train/raw-loss = 0.28015148639678955, train/logprobs = tensor([[-1.9841, -9.7893],
        [-2.2415, -5.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517771124839783
Epoch 0, Step 1006: train/loss = 0.3009868264198303, train/raw-loss = 0.2371293008327484, train/logprobs = tensor([[-1.0940, -5.3175],
        [-1.6834, -1.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12771500647068024
Epoch 0, Step 1007: train/loss = 0.44469407200813293, train/raw-loss = 0.36911946535110474, train/logprobs = tensor([[-1.0476, -2.4102],
        [-1.9635, -0.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15114927291870117
Epoch 0, Step 1008: train/loss = 0.4346131682395935, train/raw-loss = 0.35101908445358276, train/logprobs = tensor([[-1.3761, -4.2743],
        [-2.1208, -1.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16718816757202148
Epoch 0, Step 1009: train/loss = 0.6150742173194885, train/raw-loss = 0.5176048278808594, train/logprobs = tensor([[-0.9850, -3.8890],
        [-2.6613, -1.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19493873417377472
Epoch 0, Step 1010: train/loss = 0.48861122131347656, train/raw-loss = 0.4176349639892578, train/logprobs = tensor([[-1.2008, -2.6553],
        [-1.8641, -0.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419525146484375
Epoch 0, Step 1011: train/loss = 0.3667035698890686, train/raw-loss = 0.2893904447555542, train/logprobs = tensor([[-0.8263, -3.7732],
        [-1.6987, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15462626516819
Epoch 0, Step 1012: train/loss = 0.5159478187561035, train/raw-loss = 0.4414989948272705, train/logprobs = tensor([[-1.7961, -2.8787],
        [-3.4010, -2.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14889773726463318
Epoch 0, Step 1013: train/loss = 0.3415573537349701, train/raw-loss = 0.2762947380542755, train/logprobs = tensor([[-0.6410, -4.5565],
        [-0.8393, -0.6478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13052523136138916
Epoch 0, Step 1014: train/loss = 0.4948115944862366, train/raw-loss = 0.43979376554489136, train/logprobs = tensor([[-0.9503, -3.4965],
        [-1.1536, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003562808036804
Epoch 0, Step 1015: train/loss = 0.4117220640182495, train/raw-loss = 0.33025872707366943, train/logprobs = tensor([[-1.6104, -2.9787],
        [-3.3563, -1.4935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16292662918567657
Epoch 0, Step 1016: train/loss = 0.2566061317920685, train/raw-loss = 0.1628730446100235, train/logprobs = tensor([[-1.2543, -5.4520],
        [-3.3206, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18746618926525116
Epoch 0, Step 1017: train/loss = 0.40586861968040466, train/raw-loss = 0.33700135350227356, train/logprobs = tensor([[-1.6069, -3.7964],
        [-2.0745, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13773445785045624
Epoch 0, Step 1018: train/loss = 0.48384881019592285, train/raw-loss = 0.4216077923774719, train/logprobs = tensor([[-1.0281, -2.1220],
        [-1.7181, -0.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12448203563690186
Epoch 0, Step 1019: train/loss = 0.3027588129043579, train/raw-loss = 0.23255906999111176, train/logprobs = tensor([[-1.1023, -4.7506],
        [-2.6080, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403994858264923
Epoch 0, Step 1020: train/loss = 0.4433259963989258, train/raw-loss = 0.33784928917884827, train/logprobs = tensor([[-2.5506, -3.4669],
        [-3.3557, -1.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21095338463783264
Epoch 0, Step 1021: train/loss = 0.49417293071746826, train/raw-loss = 0.4318143129348755, train/logprobs = tensor([[-1.8807, -4.4785],
        [-2.3672, -1.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12471731007099152
Epoch 0, Step 1022: train/loss = 0.4175833463668823, train/raw-loss = 0.344483345746994, train/logprobs = tensor([[-0.9933, -3.8796],
        [-1.8428, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1462000459432602
Epoch 0, Step 1023: train/loss = 0.6034451127052307, train/raw-loss = 0.5355781316757202, train/logprobs = tensor([[-0.8244, -3.5090],
        [-1.7035, -1.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1357339322566986
Epoch 0, Step 1024: train/loss = 0.32427269220352173, train/raw-loss = 0.25574517250061035, train/logprobs = tensor([[-0.9739, -4.9149],
        [-2.0177, -1.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13705505430698395
Epoch 0, Step 1025: train/loss = 0.21579453349113464, train/raw-loss = 0.12754684686660767, train/logprobs = tensor([[-1.2279, -5.0886],
        [-3.4061, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17649538815021515
Epoch 0, Step 1026: train/loss = 0.24940212070941925, train/raw-loss = 0.1722586452960968, train/logprobs = tensor([[-0.9673, -6.0627],
        [-2.2652, -1.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15428698062896729
Epoch 0, Step 1027: train/loss = 0.27705371379852295, train/raw-loss = 0.1869213730096817, train/logprobs = tensor([[-1.0814, -7.3397],
        [-2.2669, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802646368741989
Epoch 0, Step 1028: train/loss = 0.24218982458114624, train/raw-loss = 0.15735363960266113, train/logprobs = tensor([[-0.6602, -7.3695],
        [-1.7684, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16967235505580902
Epoch 0, Step 1029: train/loss = 0.3838261067867279, train/raw-loss = 0.30168965458869934, train/logprobs = tensor([[-1.0381, -3.4539],
        [-2.1165, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16427291929721832
Epoch 0, Step 1030: train/loss = 0.34538301825523376, train/raw-loss = 0.26495105028152466, train/logprobs = tensor([[-1.4034, -4.2926],
        [-2.2720, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1608639508485794
Epoch 0, Step 1031: train/loss = 0.337924599647522, train/raw-loss = 0.26934748888015747, train/logprobs = tensor([[-0.7125, -5.1338],
        [-0.9860, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13715417683124542
Epoch 0, Step 1032: train/loss = 0.722423791885376, train/raw-loss = 0.6835542917251587, train/logprobs = tensor([[-1.6967, -0.9256],
        [-1.4438, -0.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07773920893669128
Epoch 0, Step 1033: train/loss = 0.18499970436096191, train/raw-loss = 0.10366326570510864, train/logprobs = tensor([[-0.8931, -7.9127],
        [-2.4262, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16267290711402893
Epoch 0, Step 1034: train/loss = 0.25386863946914673, train/raw-loss = 0.1632290929555893, train/logprobs = tensor([[-0.7601, -5.4355],
        [-1.8075, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18127906322479248
Epoch 0, Step 1035: train/loss = 0.3119598627090454, train/raw-loss = 0.23547619581222534, train/logprobs = tensor([[-0.9484, -6.2852],
        [-1.2756, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15296731889247894
Epoch 0, Step 1036: train/loss = 0.3633287847042084, train/raw-loss = 0.2826390266418457, train/logprobs = tensor([[-1.0442, -3.8799],
        [-2.6706, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16137951612472534
Epoch 0, Step 1037: train/loss = 0.3784473240375519, train/raw-loss = 0.3140113949775696, train/logprobs = tensor([[-1.3197, -2.9274],
        [-2.6582, -0.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12887179851531982
Epoch 0, Step 1038: train/loss = 0.5020089745521545, train/raw-loss = 0.43269437551498413, train/logprobs = tensor([[-1.0314, -2.9597],
        [-1.6556, -1.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13862919807434082
Epoch 0, Step 1039: train/loss = 0.3627952039241791, train/raw-loss = 0.30449891090393066, train/logprobs = tensor([[-1.1006, -3.5373],
        [-1.9134, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11659262329339981
Epoch 0, Step 1040: train/loss = 0.24058647453784943, train/raw-loss = 0.15185987949371338, train/logprobs = tensor([[-1.2727, -2.9637],
        [-3.1371, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17745321989059448
Epoch 0, Step 1041: train/loss = 0.42976832389831543, train/raw-loss = 0.34990394115448, train/logprobs = tensor([[-0.9045, -4.7429],
        [-1.8886, -1.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15972882509231567
Epoch 0, Step 1042: train/loss = 0.4130692481994629, train/raw-loss = 0.34830909967422485, train/logprobs = tensor([[-0.7899, -4.2236],
        [-1.1168, -1.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12952028214931488
Epoch 0, Step 1043: train/loss = 0.42979326844215393, train/raw-loss = 0.34804290533065796, train/logprobs = tensor([[-1.3239, -4.0392],
        [-2.9175, -1.6252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16350075602531433
Epoch 0, Step 1044: train/loss = 0.33717870712280273, train/raw-loss = 0.25266098976135254, train/logprobs = tensor([[-2.0626, -6.3395],
        [-2.8478, -2.8404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16903546452522278
Epoch 0, Step 1045: train/loss = 0.5065078139305115, train/raw-loss = 0.4360160529613495, train/logprobs = tensor([[-0.8695, -2.1707],
        [-1.1256, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14098352193832397
Epoch 0, Step 1046: train/loss = 0.4030202031135559, train/raw-loss = 0.3400017023086548, train/logprobs = tensor([[-1.4465, -4.4120],
        [-2.0866, -1.4525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12603700160980225
