[2024-03-04 18:26:41,196][root][INFO] - beta: 0.5
[2024-03-04 18:26:41,197][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token
clearing gpu cache for all ranks
Model with 214.180352M params prepared
n helpful: 5463
n harmless: 5861
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance.', 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl'}
5000
5000
tokenized 10000 training examples...
train dataset has 10000 examples.
eval dataset has 0 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Epoch 0, Step 0: train/loss = 0.7081189155578613, train/raw-loss = 0.7081189155578613, train/logprobs = tensor([[-10.4667, -10.4434],
        [-10.4672, -10.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6993750333786011, train/raw-loss = 0.6993750333786011, train/logprobs = tensor([[-10.4169, -10.4014],
        [-10.4491, -10.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6957097053527832, train/raw-loss = 0.6957097053527832, train/logprobs = tensor([[-10.4375, -10.4944],
        [-10.4639, -10.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.7019438147544861, train/raw-loss = 0.7019438147544861, train/logprobs = tensor([[-10.4207, -10.4288],
        [-10.4341, -10.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.7068400382995605, train/raw-loss = 0.7068400382995605, train/logprobs = tensor([[-10.4452, -10.4451],
        [-10.4731, -10.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6917812824249268, train/raw-loss = 0.6917812824249268, train/logprobs = tensor([[-10.4472, -10.4879],
        [-10.4906, -10.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.7095755338668823, train/raw-loss = 0.7095755338668823, train/logprobs = tensor([[-10.4854, -10.5042],
        [-10.4983, -10.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6879289150238037, train/raw-loss = 0.6879289150238037, train/logprobs = tensor([[-10.4388, -10.4445],
        [-10.4688, -10.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6884644031524658, train/raw-loss = 0.6884644031524658, train/logprobs = tensor([[-10.3283, -10.4286],
        [-10.3543, -10.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.7202528715133667, train/raw-loss = 0.7202528715133667, train/logprobs = tensor([[-10.4187, -10.2752],
        [-10.4139, -10.3377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7072235345840454, train/raw-loss = 0.7072235345840454, train/logprobs = tensor([[-10.4133, -10.2684],
        [-10.4258, -10.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7082115411758423, train/raw-loss = 0.7082115411758423, train/logprobs = tensor([[-10.3867, -10.3193],
        [-10.4359, -10.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7071366310119629, train/raw-loss = 0.7071366310119629, train/logprobs = tensor([[-10.4617, -10.5137],
        [-10.4878, -10.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.721706211566925, train/raw-loss = 0.721706211566925, train/logprobs = tensor([[-10.4269, -10.3639],
        [-10.4496, -10.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7091988325119019, train/raw-loss = 0.7091988325119019, train/logprobs = tensor([[-10.4585, -10.4796],
        [-10.4410, -10.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7015777826309204, train/raw-loss = 0.7015777826309204, train/logprobs = tensor([[-10.4406, -10.4646],
        [-10.4645, -10.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.7250434756278992, train/raw-loss = 0.7250434756278992, train/logprobs = tensor([[-10.5082, -10.5119],
        [-10.4936, -10.5840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7083393335342407, train/raw-loss = 0.7083393335342407, train/logprobs = tensor([[-10.3865, -10.4373],
        [-10.4190, -10.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.7000808119773865, train/raw-loss = 0.7000808119773865, train/logprobs = tensor([[-10.4520, -10.4930],
        [-10.4359, -10.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6933736801147461, train/raw-loss = 0.6933736801147461, train/logprobs = tensor([[-10.4563, -10.4791],
        [-10.4658, -10.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7117570638656616, train/raw-loss = 0.7117570638656616, train/logprobs = tensor([[-10.4511, -10.2777],
        [-10.5181, -10.3391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7018699049949646, train/raw-loss = 0.7018699049949646, train/logprobs = tensor([[-10.4372, -10.4085],
        [-10.4740, -10.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7000593543052673, train/raw-loss = 0.7000593543052673, train/logprobs = tensor([[-10.4615, -10.4971],
        [-10.4667, -10.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.688706636428833, train/raw-loss = 0.688706636428833, train/logprobs = tensor([[-10.4681, -10.5691],
        [-10.4999, -10.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.7100282907485962, train/raw-loss = 0.7100282907485962, train/logprobs = tensor([[-10.4040, -10.3487],
        [-10.4271, -10.3904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.69705730676651, train/raw-loss = 0.69705730676651, train/logprobs = tensor([[-10.4737, -10.4671],
        [-10.5084, -10.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.709566593170166, train/raw-loss = 0.709566593170166, train/logprobs = tensor([[-10.4193, -10.4177],
        [-10.4990, -10.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7075977921485901, train/raw-loss = 0.7075977921485901, train/logprobs = tensor([[-10.4204, -10.3964],
        [-10.4390, -10.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6739809513092041, train/raw-loss = 0.6739809513092041, train/logprobs = tensor([[-10.4989, -10.5987],
        [-10.5176, -10.4880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7067868709564209, train/raw-loss = 0.7067868709564209, train/logprobs = tensor([[-10.4154, -10.4353],
        [-10.4224, -10.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.69903564453125, train/raw-loss = 0.69903564453125, train/logprobs = tensor([[-10.5182, -10.4737],
        [-10.5321, -10.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.7159094214439392, train/raw-loss = 0.7159094214439392, train/logprobs = tensor([[-10.4095, -10.3639],
        [-10.4300, -10.4205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.728385329246521, train/raw-loss = 0.728385329246521, train/logprobs = tensor([[-10.5240, -10.3592],
        [-10.5252, -10.4562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.7142887115478516, train/raw-loss = 0.7142887115478516, train/logprobs = tensor([[-10.4414, -10.4382],
        [-10.4359, -10.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.7159114480018616, train/raw-loss = 0.7159114480018616, train/logprobs = tensor([[-10.4719, -10.3696],
        [-10.4955, -10.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6980620622634888, train/raw-loss = 0.6980620622634888, train/logprobs = tensor([[-10.3856, -10.3833],
        [-10.4456, -10.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.7105260491371155, train/raw-loss = 0.7105260491371155, train/logprobs = tensor([[-10.4420, -10.4387],
        [-10.4645, -10.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6926948428153992, train/raw-loss = 0.6926948428153992, train/logprobs = tensor([[-10.4354, -10.5010],
        [-10.5239, -10.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6926850080490112, train/raw-loss = 0.6926850080490112, train/logprobs = tensor([[-10.3926, -10.4375],
        [-10.4680, -10.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.7154872417449951, train/raw-loss = 0.7154872417449951, train/logprobs = tensor([[-10.4416, -10.3820],
        [-10.4517, -10.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.7218865156173706, train/raw-loss = 0.7218865156173706, train/logprobs = tensor([[-10.4961, -10.4692],
        [-10.4843, -10.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.7092207670211792, train/raw-loss = 0.7092207670211792, train/logprobs = tensor([[-10.4352, -10.4127],
        [-10.4923, -10.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6927932500839233, train/raw-loss = 0.6927932500839233, train/logprobs = tensor([[-10.4400, -10.4581],
        [-10.4977, -10.4691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6955327987670898, train/raw-loss = 0.6955327987670898, train/logprobs = tensor([[-10.3479, -10.4546],
        [-10.4199, -10.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.7037714719772339, train/raw-loss = 0.7037714719772339, train/logprobs = tensor([[-10.5236, -10.5031],
        [-10.5435, -10.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6815565228462219, train/raw-loss = 0.6815565228462219, train/logprobs = tensor([[-10.4619, -10.4005],
        [-10.5425, -10.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.7114155292510986, train/raw-loss = 0.7114155292510986, train/logprobs = tensor([[-10.4641, -10.3257],
        [-10.4849, -10.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6929686069488525, train/raw-loss = 0.6929686069488525, train/logprobs = tensor([[-10.4397, -10.5473],
        [-10.4493, -10.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.7115973830223083, train/raw-loss = 0.7115973830223083, train/logprobs = tensor([[-10.4703, -10.3692],
        [-10.4921, -10.4037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.7130511999130249, train/raw-loss = 0.7130511999130249, train/logprobs = tensor([[-10.4219, -10.3797],
        [-10.5073, -10.4829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.7060792446136475, train/raw-loss = 0.7060792446136475, train/logprobs = tensor([[-10.4864, -10.4735],
        [-10.4842, -10.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.7075580358505249, train/raw-loss = 0.7075580358505249, train/logprobs = tensor([[-10.4371, -10.4884],
        [-10.4713, -10.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.7032803297042847, train/raw-loss = 0.7032803297042847, train/logprobs = tensor([[-10.4578, -10.4614],
        [-10.4867, -10.4739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.7085957527160645, train/raw-loss = 0.7085957527160645, train/logprobs = tensor([[-10.4963, -10.4855],
        [-10.5026, -10.5072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6886129975318909, train/raw-loss = 0.6886129975318909, train/logprobs = tensor([[-10.3822, -10.4888],
        [-10.4526, -10.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6899116039276123, train/raw-loss = 0.6899116039276123, train/logprobs = tensor([[-10.4255, -10.3755],
        [-10.4638, -10.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.7044767737388611, train/raw-loss = 0.7044767737388611, train/logprobs = tensor([[-10.4526, -10.4498],
        [-10.5026, -10.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6875298023223877, train/raw-loss = 0.6875298023223877, train/logprobs = tensor([[-10.4514, -10.4090],
        [-10.5034, -10.3796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.7036135792732239, train/raw-loss = 0.7036135792732239, train/logprobs = tensor([[-10.4277, -10.5699],
        [-10.4805, -10.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.7016639709472656, train/raw-loss = 0.7016639709472656, train/logprobs = tensor([[-10.5049, -10.4750],
        [-10.4906, -10.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.7190894484519958, train/raw-loss = 0.7190894484519958, train/logprobs = tensor([[-10.4792, -10.4176],
        [-10.4816, -10.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.7275116443634033, train/raw-loss = 0.7275116443634033, train/logprobs = tensor([[-10.4545, -10.4615],
        [-10.4507, -10.5253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6957359910011292, train/raw-loss = 0.6957359910011292, train/logprobs = tensor([[-10.5214, -10.4922],
        [-10.5221, -10.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7051073312759399, train/raw-loss = 0.7051073312759399, train/logprobs = tensor([[-10.5004, -10.4304],
        [-10.5153, -10.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.7192087173461914, train/raw-loss = 0.7191927433013916, train/logprobs = tensor([[-10.5178, -10.3881],
        [-10.5521, -10.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1891537219053134e-05
Epoch 0, Step 65: train/loss = 0.7164514064788818, train/raw-loss = 0.7164357900619507, train/logprobs = tensor([[-10.4645, -10.3701],
        [-10.5246, -10.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1239418603945524e-05
Epoch 0, Step 66: train/loss = 0.7065426111221313, train/raw-loss = 0.7065269947052002, train/logprobs = tensor([[-10.3596, -10.4252],
        [-10.4183, -10.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.122814814560115e-05
Epoch 0, Step 67: train/loss = 0.7030209898948669, train/raw-loss = 0.703005313873291, train/logprobs = tensor([[-10.4778, -10.5361],
        [-10.5012, -10.5489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.121949703199789e-05
Epoch 0, Step 68: train/loss = 0.6859968900680542, train/raw-loss = 0.6859813928604126, train/logprobs = tensor([[-10.4537, -10.3528],
        [-10.4411, -10.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.108737655566074e-05
Epoch 0, Step 69: train/loss = 0.7014859914779663, train/raw-loss = 0.7014701962471008, train/logprobs = tensor([[-10.5225, -10.5520],
        [-10.5497, -10.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1550029234495014e-05
Epoch 0, Step 70: train/loss = 0.7090181112289429, train/raw-loss = 0.7090024948120117, train/logprobs = tensor([[-10.5036, -10.4535],
        [-10.5061, -10.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.116281368420459e-05
Epoch 0, Step 71: train/loss = 0.6927459836006165, train/raw-loss = 0.6927305459976196, train/logprobs = tensor([[-10.3933, -10.4325],
        [-10.4507, -10.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1034869607537985e-05
Epoch 0, Step 72: train/loss = 0.7218968272209167, train/raw-loss = 0.7218811511993408, train/logprobs = tensor([[-10.5301, -10.4502],
        [-10.4784, -10.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1250900065060705e-05
Epoch 0, Step 73: train/loss = 0.7035254240036011, train/raw-loss = 0.7035103440284729, train/logprobs = tensor([[-10.4014, -10.4493],
        [-10.4613, -10.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0148759833537042e-05
Epoch 0, Step 74: train/loss = 0.6837778687477112, train/raw-loss = 0.6837625503540039, train/logprobs = tensor([[-10.3978, -10.4543],
        [-10.5157, -10.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.066314820898697e-05
Epoch 0, Step 75: train/loss = 0.6917197108268738, train/raw-loss = 0.6917041540145874, train/logprobs = tensor([[-10.4707, -10.4674],
        [-10.5139, -10.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.109242970822379e-05
Epoch 0, Step 76: train/loss = 0.7216529846191406, train/raw-loss = 0.7216370105743408, train/logprobs = tensor([[-10.4141, -10.3889],
        [-10.4163, -10.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.194749297108501e-05
Epoch 0, Step 77: train/loss = 0.7151002883911133, train/raw-loss = 0.7150845527648926, train/logprobs = tensor([[-10.4800, -10.4422],
        [-10.5359, -10.5302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.147076131426729e-05
Epoch 0, Step 78: train/loss = 0.6824885606765747, train/raw-loss = 0.682472825050354, train/logprobs = tensor([[-10.4120, -10.4195],
        [-10.5126, -10.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.150845805066638e-05
Epoch 0, Step 79: train/loss = 0.7186252474784851, train/raw-loss = 0.7186096906661987, train/logprobs = tensor([[-10.4743, -10.3979],
        [-10.5039, -10.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1230334570864215e-05
Epoch 0, Step 80: train/loss = 0.7053205966949463, train/raw-loss = 0.7053050994873047, train/logprobs = tensor([[-10.3631, -10.3885],
        [-10.4165, -10.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1068142561707646e-05
Epoch 0, Step 81: train/loss = 0.7568084001541138, train/raw-loss = 0.7567927837371826, train/logprobs = tensor([[-10.4386, -10.3204],
        [-10.4354, -10.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.124196155113168e-05
Epoch 0, Step 82: train/loss = 0.6996757388114929, train/raw-loss = 0.6996599435806274, train/logprobs = tensor([[-10.4752, -10.4428],
        [-10.4644, -10.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.157430546707474e-05
Epoch 0, Step 83: train/loss = 0.707433819770813, train/raw-loss = 0.7074182033538818, train/logprobs = tensor([[-10.4110, -10.5151],
        [-10.3966, -10.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.120073233731091e-05
Epoch 0, Step 84: train/loss = 0.6921210289001465, train/raw-loss = 0.6921057105064392, train/logprobs = tensor([[-10.4577, -10.4168],
        [-10.4900, -10.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.059640948777087e-05
Epoch 0, Step 85: train/loss = 0.708997368812561, train/raw-loss = 0.7089816331863403, train/logprobs = tensor([[-10.4028, -10.4131],
        [-10.4399, -10.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.152939098072238e-05
Epoch 0, Step 86: train/loss = 0.7217130661010742, train/raw-loss = 0.7216975092887878, train/logprobs = tensor([[-10.4486, -10.3738],
        [-10.5171, -10.4823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1116378522710875e-05
Epoch 0, Step 87: train/loss = 0.6865006685256958, train/raw-loss = 0.6864850521087646, train/logprobs = tensor([[-10.4765, -10.6176],
        [-10.5386, -10.5970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.127220770693384e-05
Epoch 0, Step 88: train/loss = 0.7046699523925781, train/raw-loss = 0.704654335975647, train/logprobs = tensor([[-10.4580, -10.5343],
        [-10.4824, -10.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.127391391899437e-05
Epoch 0, Step 89: train/loss = 0.7147369384765625, train/raw-loss = 0.7147212028503418, train/logprobs = tensor([[-10.4518, -10.4294],
        [-10.4774, -10.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.160178675898351e-05
Epoch 0, Step 90: train/loss = 0.711531400680542, train/raw-loss = 0.7115157842636108, train/logprobs = tensor([[-10.4270, -10.4187],
        [-10.4001, -10.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.121715781162493e-05
Epoch 0, Step 91: train/loss = 0.7067976593971252, train/raw-loss = 0.706782341003418, train/logprobs = tensor([[-10.4219, -10.3386],
        [-10.4747, -10.3940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.056467539863661e-05
Epoch 0, Step 92: train/loss = 0.722446858882904, train/raw-loss = 0.7224313020706177, train/logprobs = tensor([[-10.4959, -10.4557],
        [-10.4771, -10.4945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.13174823531881e-05
Epoch 0, Step 93: train/loss = 0.7242985963821411, train/raw-loss = 0.7242828011512756, train/logprobs = tensor([[-10.4389, -10.3193],
        [-10.4908, -10.4287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1566851248499006e-05
Epoch 0, Step 94: train/loss = 0.6813649535179138, train/raw-loss = 0.6813493967056274, train/logprobs = tensor([[-10.4588, -10.5455],
        [-10.4977, -10.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.118263339274563e-05
Epoch 0, Step 95: train/loss = 0.6913305521011353, train/raw-loss = 0.6913150548934937, train/logprobs = tensor([[-10.4188, -10.4881],
        [-10.4815, -10.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0954910471336916e-05
Epoch 0, Step 96: train/loss = 0.6994253396987915, train/raw-loss = 0.6994085311889648, train/logprobs = tensor([[-10.4430, -10.4527],
        [-10.4920, -10.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.352697967784479e-05
Epoch 0, Step 97: train/loss = 0.6988554000854492, train/raw-loss = 0.6988385915756226, train/logprobs = tensor([[-10.3671, -10.4090],
        [-10.4068, -10.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.353996726218611e-05
Epoch 0, Step 98: train/loss = 0.7037728428840637, train/raw-loss = 0.7037562131881714, train/logprobs = tensor([[-10.3194, -10.3719],
        [-10.3329, -10.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.336945519549772e-05
Epoch 0, Step 99: train/loss = 0.6905490756034851, train/raw-loss = 0.6905322074890137, train/logprobs = tensor([[-10.4597, -10.4589],
        [-10.4815, -10.4300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.372901846887544e-05
Epoch 0, Step 100: train/loss = 0.6979078054428101, train/raw-loss = 0.6978909969329834, train/logprobs = tensor([[-10.4216, -10.4599],
        [-10.4382, -10.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.362560164532624e-05
Epoch 0, Step 101: train/loss = 0.7039705514907837, train/raw-loss = 0.703953742980957, train/logprobs = tensor([[-10.4244, -10.3951],
        [-10.4381, -10.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.372892751940526e-05
Epoch 0, Step 102: train/loss = 0.7069343328475952, train/raw-loss = 0.7069172859191895, train/logprobs = tensor([[-10.4439, -10.4464],
        [-10.5222, -10.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.40708029398229e-05
Epoch 0, Step 103: train/loss = 0.7005364298820496, train/raw-loss = 0.7005198001861572, train/logprobs = tensor([[-10.4770, -10.3604],
        [-10.5518, -10.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3144413464469835e-05
Epoch 0, Step 104: train/loss = 0.7032365202903748, train/raw-loss = 0.7032196521759033, train/logprobs = tensor([[-10.4677, -10.4939],
        [-10.4608, -10.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.372777791810222e-05
Epoch 0, Step 105: train/loss = 0.6723263263702393, train/raw-loss = 0.6723096370697021, train/logprobs = tensor([[-10.4641, -10.5177],
        [-10.5595, -10.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.332480264361948e-05
Epoch 0, Step 106: train/loss = 0.7057852149009705, train/raw-loss = 0.7057684659957886, train/logprobs = tensor([[-10.3778, -10.3077],
        [-10.3852, -10.2812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.352274507051334e-05
Epoch 0, Step 107: train/loss = 0.7167140245437622, train/raw-loss = 0.7166970372200012, train/logprobs = tensor([[-10.3957, -10.4322],
        [-10.3756, -10.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.38538084179163e-05
Epoch 0, Step 108: train/loss = 0.7002300024032593, train/raw-loss = 0.7002133131027222, train/logprobs = tensor([[-10.4102, -10.4385],
        [-10.4453, -10.4453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.35086187988054e-05
Epoch 0, Step 109: train/loss = 0.6753466129302979, train/raw-loss = 0.6753298044204712, train/logprobs = tensor([[-10.3773, -10.4826],
        [-10.5009, -10.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.345983714098111e-05
Epoch 0, Step 110: train/loss = 0.7042862176895142, train/raw-loss = 0.7042694091796875, train/logprobs = tensor([[-10.4341, -10.4616],
        [-10.4825, -10.5154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.359447873663157e-05
Epoch 0, Step 111: train/loss = 0.6958194971084595, train/raw-loss = 0.6958030462265015, train/logprobs = tensor([[-10.3343, -10.4317],
        [-10.4106, -10.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3005511795636266e-05
Epoch 0, Step 112: train/loss = 0.6997244358062744, train/raw-loss = 0.6997082233428955, train/logprobs = tensor([[-10.4107, -10.4081],
        [-10.4638, -10.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2533000194234774e-05
Epoch 0, Step 113: train/loss = 0.6958930492401123, train/raw-loss = 0.6958761811256409, train/logprobs = tensor([[-10.5455, -10.5019],
        [-10.5824, -10.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.37390010827221e-05
Epoch 0, Step 114: train/loss = 0.6974291205406189, train/raw-loss = 0.6974118947982788, train/logprobs = tensor([[-10.3988, -10.3889],
        [-10.4489, -10.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4485754440538585e-05
Epoch 0, Step 115: train/loss = 0.6923694610595703, train/raw-loss = 0.6923527717590332, train/logprobs = tensor([[-10.4676, -10.4147],
        [-10.5297, -10.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.348039535921998e-05
Epoch 0, Step 116: train/loss = 0.7009332180023193, train/raw-loss = 0.7009167671203613, train/logprobs = tensor([[-10.3964, -10.3664],
        [-10.4401, -10.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.314240893814713e-05
Epoch 0, Step 117: train/loss = 0.6949427127838135, train/raw-loss = 0.6949262619018555, train/logprobs = tensor([[-10.4087, -10.5072],
        [-10.4365, -10.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2912685128394514e-05
Epoch 0, Step 118: train/loss = 0.6970658302307129, train/raw-loss = 0.6970490217208862, train/logprobs = tensor([[-10.4916, -10.5408],
        [-10.5057, -10.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.349879989400506e-05
Epoch 0, Step 119: train/loss = 0.6971482038497925, train/raw-loss = 0.6971313953399658, train/logprobs = tensor([[-10.4038, -10.3350],
        [-10.4767, -10.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.361474955454469e-05
Epoch 0, Step 120: train/loss = 0.7329226732254028, train/raw-loss = 0.7329060435295105, train/logprobs = tensor([[-10.4502, -10.3350],
        [-10.4406, -10.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.313042179797776e-05
Epoch 0, Step 121: train/loss = 0.7217404842376709, train/raw-loss = 0.721723735332489, train/logprobs = tensor([[-10.4593, -10.3916],
        [-10.4766, -10.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.333696076879278e-05
Epoch 0, Step 122: train/loss = 0.7190207839012146, train/raw-loss = 0.7190040349960327, train/logprobs = tensor([[-10.4691, -10.4312],
        [-10.5193, -10.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3532618544995785e-05
Epoch 0, Step 123: train/loss = 0.699175238609314, train/raw-loss = 0.6991586685180664, train/logprobs = tensor([[-10.4186, -10.3856],
        [-10.4859, -10.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3135831472463906e-05
Epoch 0, Step 124: train/loss = 0.7217810750007629, train/raw-loss = 0.7217642068862915, train/logprobs = tensor([[-10.5829, -10.5633],
        [-10.5502, -10.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.377188841113821e-05
Epoch 0, Step 125: train/loss = 0.6965426802635193, train/raw-loss = 0.6965261697769165, train/logprobs = tensor([[-10.4789, -10.3726],
        [-10.5277, -10.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3022624847944826e-05
Epoch 0, Step 126: train/loss = 0.7023494243621826, train/raw-loss = 0.7023325562477112, train/logprobs = tensor([[-10.4542, -10.4472],
        [-10.5541, -10.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3577151043573394e-05
Epoch 0, Step 127: train/loss = 0.6923431158065796, train/raw-loss = 0.6923260688781738, train/logprobs = tensor([[-10.3787, -10.4178],
        [-10.4355, -10.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4144595701945946e-05
Epoch 0, Step 128: train/loss = 0.715790867805481, train/raw-loss = 0.7157726287841797, train/logprobs = tensor([[-10.4668, -10.4672],
        [-10.4770, -10.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6421435652300715e-05
Epoch 0, Step 129: train/loss = 0.6803913116455078, train/raw-loss = 0.6803743839263916, train/logprobs = tensor([[-10.4194, -10.4877],
        [-10.4795, -10.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3981552405748516e-05
Epoch 0, Step 130: train/loss = 0.6984789967536926, train/raw-loss = 0.6984614133834839, train/logprobs = tensor([[-10.4550, -10.4625],
        [-10.5089, -10.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5233406379120424e-05
Epoch 0, Step 131: train/loss = 0.7142188549041748, train/raw-loss = 0.7142012715339661, train/logprobs = tensor([[-10.4724, -10.4930],
        [-10.4875, -10.5326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.51524431607686e-05
Epoch 0, Step 132: train/loss = 0.7222316265106201, train/raw-loss = 0.7222143411636353, train/logprobs = tensor([[-10.4737, -10.4480],
        [-10.4876, -10.5210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4701861295616254e-05
Epoch 0, Step 133: train/loss = 0.6992416381835938, train/raw-loss = 0.6992239952087402, train/logprobs = tensor([[-10.4805, -10.4404],
        [-10.5056, -10.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5223853046773e-05
Epoch 0, Step 134: train/loss = 0.7135109901428223, train/raw-loss = 0.7134934663772583, train/logprobs = tensor([[-10.4847, -10.4513],
        [-10.4661, -10.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.505350468913093e-05
Epoch 0, Step 135: train/loss = 0.6934988498687744, train/raw-loss = 0.6934816837310791, train/logprobs = tensor([[-10.4126, -10.4905],
        [-10.4486, -10.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.441616354393773e-05
Epoch 0, Step 136: train/loss = 0.7212647199630737, train/raw-loss = 0.7212471961975098, train/logprobs = tensor([[-10.4826, -10.3763],
        [-10.5073, -10.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5125252907164395e-05
Epoch 0, Step 137: train/loss = 0.7151598930358887, train/raw-loss = 0.7151422500610352, train/logprobs = tensor([[-10.5208, -10.4324],
        [-10.5065, -10.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5235469113104045e-05
Epoch 0, Step 138: train/loss = 0.6826435327529907, train/raw-loss = 0.6826261281967163, train/logprobs = tensor([[-10.4253, -10.3279],
        [-10.5162, -10.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4967575629707426e-05
Epoch 0, Step 139: train/loss = 0.7028428912162781, train/raw-loss = 0.7028253674507141, train/logprobs = tensor([[-10.3937, -10.4991],
        [-10.4396, -10.5235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.508463851176202e-05
Epoch 0, Step 140: train/loss = 0.7090551853179932, train/raw-loss = 0.7090376615524292, train/logprobs = tensor([[-10.4940, -10.4209],
        [-10.5836, -10.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5068900615442544e-05
Epoch 0, Step 141: train/loss = 0.7201091647148132, train/raw-loss = 0.7200917601585388, train/logprobs = tensor([[-10.4370, -10.3693],
        [-10.4550, -10.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4796652471413836e-05
Epoch 0, Step 142: train/loss = 0.6964223980903625, train/raw-loss = 0.6964054703712463, train/logprobs = tensor([[-10.4680, -10.4077],
        [-10.4788, -10.4006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3832482586149126e-05
Epoch 0, Step 143: train/loss = 0.7201778292655945, train/raw-loss = 0.7201609015464783, train/logprobs = tensor([[-10.4821, -10.3993],
        [-10.5376, -10.5009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3877040550578386e-05
Epoch 0, Step 144: train/loss = 0.6857091188430786, train/raw-loss = 0.6856915950775146, train/logprobs = tensor([[-10.3794, -10.3179],
        [-10.4568, -10.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.50664668076206e-05
Epoch 0, Step 145: train/loss = 0.7207958102226257, train/raw-loss = 0.7207782864570618, train/logprobs = tensor([[-10.4392, -10.4291],
        [-10.4759, -10.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.50653390341904e-05
Epoch 0, Step 146: train/loss = 0.7242451906204224, train/raw-loss = 0.7242274880409241, train/logprobs = tensor([[-10.4750, -10.4427],
        [-10.4427, -10.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.533177005010657e-05
Epoch 0, Step 147: train/loss = 0.7083261013031006, train/raw-loss = 0.708308756351471, train/logprobs = tensor([[-10.4840, -10.4313],
        [-10.5111, -10.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.463451503193937e-05
Epoch 0, Step 148: train/loss = 0.6923513412475586, train/raw-loss = 0.6923346519470215, train/logprobs = tensor([[-10.4452, -10.4508],
        [-10.4602, -10.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.33189673256129e-05
Epoch 0, Step 149: train/loss = 0.6978665590286255, train/raw-loss = 0.6978490352630615, train/logprobs = tensor([[-10.4172, -10.4644],
        [-10.4893, -10.4891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4997749025933444e-05
Epoch 0, Step 150: train/loss = 0.7107601165771484, train/raw-loss = 0.7107423543930054, train/logprobs = tensor([[-10.4418, -10.4099],
        [-10.5081, -10.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.537418888299726e-05
Epoch 0, Step 151: train/loss = 0.7012427449226379, train/raw-loss = 0.701225221157074, train/logprobs = tensor([[-10.4246, -10.4720],
        [-10.4868, -10.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5069326258962974e-05
Epoch 0, Step 152: train/loss = 0.7066986560821533, train/raw-loss = 0.7066813707351685, train/logprobs = tensor([[-10.4967, -10.4824],
        [-10.5070, -10.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.463815664872527e-05
Epoch 0, Step 153: train/loss = 0.6993114948272705, train/raw-loss = 0.6992941498756409, train/logprobs = tensor([[-10.3800, -10.4767],
        [-10.4354, -10.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.476973142824136e-05
Epoch 0, Step 154: train/loss = 0.6805291771888733, train/raw-loss = 0.6805117130279541, train/logprobs = tensor([[-10.4139, -10.4368],
        [-10.4657, -10.3821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.501148967188783e-05
Epoch 0, Step 155: train/loss = 0.6975340843200684, train/raw-loss = 0.697516679763794, train/logprobs = tensor([[-10.4128, -10.5220],
        [-10.4865, -10.5603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.500853927107528e-05
Epoch 0, Step 156: train/loss = 0.7159581184387207, train/raw-loss = 0.7159408926963806, train/logprobs = tensor([[-10.4466, -10.3594],
        [-10.5091, -10.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.450926669756882e-05
Epoch 0, Step 157: train/loss = 0.6974865198135376, train/raw-loss = 0.6974688172340393, train/logprobs = tensor([[-10.3758, -10.4888],
        [-10.4499, -10.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5278986615594476e-05
Epoch 0, Step 158: train/loss = 0.6963279247283936, train/raw-loss = 0.6963106393814087, train/logprobs = tensor([[-10.4490, -10.4753],
        [-10.4339, -10.4254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.47689310729038e-05
Epoch 0, Step 159: train/loss = 0.7105343341827393, train/raw-loss = 0.7105170488357544, train/logprobs = tensor([[-10.4301, -10.4073],
        [-10.4597, -10.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.471705349511467e-05
Epoch 0, Step 160: train/loss = 0.7061899304389954, train/raw-loss = 0.706171989440918, train/logprobs = tensor([[-10.4102, -10.4976],
        [-10.4384, -10.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.57852186425589e-05
Epoch 0, Step 161: train/loss = 0.7094952464103699, train/raw-loss = 0.7094779014587402, train/logprobs = tensor([[-10.4517, -10.5081],
        [-10.4394, -10.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4765056625474244e-05
Epoch 0, Step 162: train/loss = 0.6965042352676392, train/raw-loss = 0.6964864134788513, train/logprobs = tensor([[-10.4630, -10.3861],
        [-10.5372, -10.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.558999378583394e-05
Epoch 0, Step 163: train/loss = 0.6947221159934998, train/raw-loss = 0.6947041153907776, train/logprobs = tensor([[-10.3645, -10.4500],
        [-10.4490, -10.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.593156361603178e-05
Epoch 0, Step 164: train/loss = 0.6948437690734863, train/raw-loss = 0.6948256492614746, train/logprobs = tensor([[-10.4017, -10.4036],
        [-10.4580, -10.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6315497709438205e-05
Epoch 0, Step 165: train/loss = 0.682815432548523, train/raw-loss = 0.6827975511550903, train/logprobs = tensor([[-10.4296, -10.4890],
        [-10.4875, -10.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5655248211696744e-05
Epoch 0, Step 166: train/loss = 0.6884918212890625, train/raw-loss = 0.6884735822677612, train/logprobs = tensor([[-10.4310, -10.4445],
        [-10.4825, -10.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6364959669299424e-05
Epoch 0, Step 167: train/loss = 0.6961556673049927, train/raw-loss = 0.6961376070976257, train/logprobs = tensor([[-10.3957, -10.4606],
        [-10.4786, -10.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.610181011026725e-05
Epoch 0, Step 168: train/loss = 0.7114555239677429, train/raw-loss = 0.7114372253417969, train/logprobs = tensor([[-10.4602, -10.4554],
        [-10.4929, -10.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6500081478152424e-05
Epoch 0, Step 169: train/loss = 0.7123998403549194, train/raw-loss = 0.7123818397521973, train/logprobs = tensor([[-10.5099, -10.5020],
        [-10.4988, -10.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6050179915037006e-05
Epoch 0, Step 170: train/loss = 0.703482985496521, train/raw-loss = 0.7034650444984436, train/logprobs = tensor([[-10.4748, -10.4601],
        [-10.5116, -10.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6026853194925934e-05
Epoch 0, Step 171: train/loss = 0.6945779323577881, train/raw-loss = 0.6945601105690002, train/logprobs = tensor([[-10.4725, -10.4822],
        [-10.5016, -10.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.583833313314244e-05
Epoch 0, Step 172: train/loss = 0.6834402084350586, train/raw-loss = 0.6834220886230469, train/logprobs = tensor([[-10.4684, -10.5842],
        [-10.5155, -10.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.620603820309043e-05
Epoch 0, Step 173: train/loss = 0.6934142708778381, train/raw-loss = 0.6933962106704712, train/logprobs = tensor([[-10.3729, -10.4244],
        [-10.4385, -10.4327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.625642420956865e-05
Epoch 0, Step 174: train/loss = 0.7014755010604858, train/raw-loss = 0.7014576196670532, train/logprobs = tensor([[-10.4365, -10.4484],
        [-10.4920, -10.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.588109029806219e-05
Epoch 0, Step 175: train/loss = 0.7058061361312866, train/raw-loss = 0.705788254737854, train/logprobs = tensor([[-10.4213, -10.4734],
        [-10.4202, -10.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5853427107213065e-05
Epoch 0, Step 176: train/loss = 0.7064990997314453, train/raw-loss = 0.7064812779426575, train/logprobs = tensor([[-10.5421, -10.6041],
        [-10.5388, -10.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5645738535095006e-05
Epoch 0, Step 177: train/loss = 0.7163136601448059, train/raw-loss = 0.716295599937439, train/logprobs = tensor([[-10.4097, -10.4423],
        [-10.4574, -10.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.617777110775933e-05
Epoch 0, Step 178: train/loss = 0.6868579387664795, train/raw-loss = 0.6868398189544678, train/logprobs = tensor([[-10.4418, -10.5246],
        [-10.4637, -10.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.625390672823414e-05
Epoch 0, Step 179: train/loss = 0.6969125270843506, train/raw-loss = 0.6968945860862732, train/logprobs = tensor([[-10.5042, -10.5294],
        [-10.5317, -10.5367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.596297756303102e-05
Epoch 0, Step 180: train/loss = 0.7050642967224121, train/raw-loss = 0.7050462365150452, train/logprobs = tensor([[-10.4382, -10.3303],
        [-10.4607, -10.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6140445445198566e-05
Epoch 0, Step 181: train/loss = 0.7047858834266663, train/raw-loss = 0.7047680616378784, train/logprobs = tensor([[-10.4849, -10.4629],
        [-10.4734, -10.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5639699490275234e-05
Epoch 0, Step 182: train/loss = 0.6821353435516357, train/raw-loss = 0.6821179986000061, train/logprobs = tensor([[-10.4314, -10.4811],
        [-10.4802, -10.4412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.469325747573748e-05
Epoch 0, Step 183: train/loss = 0.7038146257400513, train/raw-loss = 0.7037966251373291, train/logprobs = tensor([[-10.4209, -10.5357],
        [-10.4508, -10.5629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6030716728419065e-05
Epoch 0, Step 184: train/loss = 0.6959149837493896, train/raw-loss = 0.6958974599838257, train/logprobs = tensor([[-10.4551, -10.4513],
        [-10.4563, -10.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.504459164105356e-05
Epoch 0, Step 185: train/loss = 0.7032869458198547, train/raw-loss = 0.7032691240310669, train/logprobs = tensor([[-10.4644, -10.5252],
        [-10.4824, -10.5230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.546441439539194e-05
Epoch 0, Step 186: train/loss = 0.6993406414985657, train/raw-loss = 0.6993227005004883, train/logprobs = tensor([[-10.4646, -10.4248],
        [-10.4976, -10.4369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.583660509320907e-05
Epoch 0, Step 187: train/loss = 0.7107313275337219, train/raw-loss = 0.7107133269309998, train/logprobs = tensor([[-10.4488, -10.4447],
        [-10.4769, -10.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.595028829295188e-05
Epoch 0, Step 188: train/loss = 0.6905348896980286, train/raw-loss = 0.690517246723175, train/logprobs = tensor([[-10.3895, -10.4538],
        [-10.4736, -10.4604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.53663090209011e-05
Epoch 0, Step 189: train/loss = 0.6930770874023438, train/raw-loss = 0.6930591464042664, train/logprobs = tensor([[-10.3987, -10.4988],
        [-10.4584, -10.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5976714571006596e-05
Epoch 0, Step 190: train/loss = 0.7219685912132263, train/raw-loss = 0.7219508290290833, train/logprobs = tensor([[-10.4374, -10.4409],
        [-10.5148, -10.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.549673783709295e-05
Epoch 0, Step 191: train/loss = 0.6982046961784363, train/raw-loss = 0.6981873512268066, train/logprobs = tensor([[-10.4627, -10.4081],
        [-10.4621, -10.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.476433266769163e-05
Epoch 0, Step 192: train/loss = 0.6997306942939758, train/raw-loss = 0.6997120976448059, train/logprobs = tensor([[-10.4533, -10.4902],
        [-10.4979, -10.5284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.704442497109994e-05
Epoch 0, Step 193: train/loss = 0.698701024055481, train/raw-loss = 0.6986823081970215, train/logprobs = tensor([[-10.4376, -10.4721],
        [-10.4489, -10.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.754399222088978e-05
Epoch 0, Step 194: train/loss = 0.7009677886962891, train/raw-loss = 0.7009491920471191, train/logprobs = tensor([[-10.4720, -10.4964],
        [-10.5026, -10.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.734303027158603e-05
Epoch 0, Step 195: train/loss = 0.7116200923919678, train/raw-loss = 0.7116020321846008, train/logprobs = tensor([[-10.4681, -10.4953],
        [-10.4984, -10.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6056761018699035e-05
Epoch 0, Step 196: train/loss = 0.698691725730896, train/raw-loss = 0.6986731886863708, train/logprobs = tensor([[-10.4095, -10.4550],
        [-10.4661, -10.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.708114309119992e-05
Epoch 0, Step 197: train/loss = 0.7013747096061707, train/raw-loss = 0.7013561725616455, train/logprobs = tensor([[-10.4348, -10.4534],
        [-10.4705, -10.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7108344258740544e-05
Epoch 0, Step 198: train/loss = 0.6992397308349609, train/raw-loss = 0.6992219090461731, train/logprobs = tensor([[-10.4238, -10.4040],
        [-10.4274, -10.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5533834306988865e-05
Epoch 0, Step 199: train/loss = 0.6992732286453247, train/raw-loss = 0.6992552280426025, train/logprobs = tensor([[-10.4415, -10.4737],
        [-10.4789, -10.4864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.597727481974289e-05
Epoch 0, Step 200: train/loss = 0.6917974948883057, train/raw-loss = 0.6917794942855835, train/logprobs = tensor([[-10.4294, -10.4696],
        [-10.4732, -10.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.616476897150278e-05
Epoch 0, Step 201: train/loss = 0.7149256467819214, train/raw-loss = 0.7149068713188171, train/logprobs = tensor([[-10.4242, -10.3887],
        [-10.4376, -10.4447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7582132790703326e-05
Epoch 0, Step 202: train/loss = 0.6963139176368713, train/raw-loss = 0.6962952613830566, train/logprobs = tensor([[-10.4406, -10.5049],
        [-10.4563, -10.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.730263051693328e-05
Epoch 0, Step 203: train/loss = 0.6803897619247437, train/raw-loss = 0.6803714632987976, train/logprobs = tensor([[-10.3607, -10.4439],
        [-10.4256, -10.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.660494621726684e-05
Epoch 0, Step 204: train/loss = 0.7477430105209351, train/raw-loss = 0.7477245330810547, train/logprobs = tensor([[-10.4116, -10.5393],
        [-10.4436, -10.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.702156027429737e-05
Epoch 0, Step 205: train/loss = 0.7070805430412292, train/raw-loss = 0.7070618867874146, train/logprobs = tensor([[-10.4351, -10.4029],
        [-10.4705, -10.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.731971810339019e-05
Epoch 0, Step 206: train/loss = 0.6969776153564453, train/raw-loss = 0.6969592571258545, train/logprobs = tensor([[-10.4518, -10.4883],
        [-10.4975, -10.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6765235563507304e-05
Epoch 0, Step 207: train/loss = 0.6977869868278503, train/raw-loss = 0.6977683305740356, train/logprobs = tensor([[-10.4821, -10.5187],
        [-10.5462, -10.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.747440496226773e-05
Epoch 0, Step 208: train/loss = 0.7141947746276855, train/raw-loss = 0.7141759395599365, train/logprobs = tensor([[-10.4242, -10.5142],
        [-10.4140, -10.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.757414378924295e-05
Epoch 0, Step 209: train/loss = 0.7046935558319092, train/raw-loss = 0.7046751379966736, train/logprobs = tensor([[-10.4521, -10.3849],
        [-10.4582, -10.4060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6953031667508185e-05
Epoch 0, Step 210: train/loss = 0.7036080360412598, train/raw-loss = 0.7035892009735107, train/logprobs = tensor([[-10.4207, -10.4611],
        [-10.4510, -10.4743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7401405279524624e-05
Epoch 0, Step 211: train/loss = 0.6864225268363953, train/raw-loss = 0.6864041686058044, train/logprobs = tensor([[-10.4825, -10.5574],
        [-10.5140, -10.5205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.677258064271882e-05
Epoch 0, Step 212: train/loss = 0.6870123147964478, train/raw-loss = 0.6869937181472778, train/logprobs = tensor([[-10.3343, -10.4463],
        [-10.4016, -10.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.730669050128199e-05
Epoch 0, Step 213: train/loss = 0.727658748626709, train/raw-loss = 0.7276405096054077, train/logprobs = tensor([[-10.4502, -10.3672],
        [-10.4647, -10.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6442790587898344e-05
Epoch 0, Step 214: train/loss = 0.6864163279533386, train/raw-loss = 0.6863976716995239, train/logprobs = tensor([[-10.3837, -10.4601],
        [-10.4603, -10.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.730616299435496e-05
Epoch 0, Step 215: train/loss = 0.7089004516601562, train/raw-loss = 0.7088818550109863, train/logprobs = tensor([[-10.4799, -10.4666],
        [-10.4776, -10.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7189878639765084e-05
Epoch 0, Step 216: train/loss = 0.6954662799835205, train/raw-loss = 0.6954479217529297, train/logprobs = tensor([[-10.4307, -10.4139],
        [-10.4760, -10.4258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.685964838950895e-05
Epoch 0, Step 217: train/loss = 0.7103652358055115, train/raw-loss = 0.7103465795516968, train/logprobs = tensor([[-10.4294, -10.4494],
        [-10.4806, -10.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.732198820216581e-05
Epoch 0, Step 218: train/loss = 0.6800796985626221, train/raw-loss = 0.6800613403320312, train/logprobs = tensor([[-10.4410, -10.4576],
        [-10.5264, -10.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.687143180286512e-05
Epoch 0, Step 219: train/loss = 0.6855687499046326, train/raw-loss = 0.6855506896972656, train/logprobs = tensor([[-10.4504, -10.4815],
        [-10.5218, -10.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.612942964537069e-05
Epoch 0, Step 220: train/loss = 0.700175404548645, train/raw-loss = 0.7001566886901855, train/logprobs = tensor([[-10.4816, -10.5283],
        [-10.4753, -10.5113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.734290658030659e-05
Epoch 0, Step 221: train/loss = 0.7174242734909058, train/raw-loss = 0.7174056172370911, train/logprobs = tensor([[-10.4112, -10.5085],
        [-10.4532, -10.5950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.732617187779397e-05
Epoch 0, Step 222: train/loss = 0.6819877028465271, train/raw-loss = 0.6819690465927124, train/logprobs = tensor([[-10.3710, -10.4052],
        [-10.5008, -10.4376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.729020318132825e-05
Epoch 0, Step 223: train/loss = 0.7075858116149902, train/raw-loss = 0.7075673341751099, train/logprobs = tensor([[-10.4120, -10.4735],
        [-10.4063, -10.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6946090403944254e-05
Epoch 0, Step 224: train/loss = 0.7051342725753784, train/raw-loss = 0.7051152586936951, train/logprobs = tensor([[-10.4664, -10.3522],
        [-10.5359, -10.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.819010089500807e-05
Epoch 0, Step 225: train/loss = 0.6980873942375183, train/raw-loss = 0.6980684995651245, train/logprobs = tensor([[-10.4237, -10.3796],
        [-10.4467, -10.3606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.786111847148277e-05
Epoch 0, Step 226: train/loss = 0.6999828815460205, train/raw-loss = 0.6999635100364685, train/logprobs = tensor([[-10.4405, -10.4603],
        [-10.4910, -10.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.880267104250379e-05
Epoch 0, Step 227: train/loss = 0.6861034631729126, train/raw-loss = 0.6860843896865845, train/logprobs = tensor([[-10.4238, -10.4651],
        [-10.5163, -10.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8171721826074645e-05
Epoch 0, Step 228: train/loss = 0.7060657739639282, train/raw-loss = 0.7060467004776001, train/logprobs = tensor([[-10.4904, -10.4264],
        [-10.4833, -10.4221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8090289308456704e-05
Epoch 0, Step 229: train/loss = 0.6900777220726013, train/raw-loss = 0.6900588274002075, train/logprobs = tensor([[-10.4258, -10.4948],
        [-10.4489, -10.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.771738556679338e-05
Epoch 0, Step 230: train/loss = 0.7013139128684998, train/raw-loss = 0.7012949585914612, train/logprobs = tensor([[-10.4411, -10.4933],
        [-10.4829, -10.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7793422961840406e-05
Epoch 0, Step 231: train/loss = 0.6999116539955139, train/raw-loss = 0.699892520904541, train/logprobs = tensor([[-10.4457, -10.4210],
        [-10.4687, -10.4131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.82233556592837e-05
Epoch 0, Step 232: train/loss = 0.6775872111320496, train/raw-loss = 0.6775685548782349, train/logprobs = tensor([[-10.4474, -10.4746],
        [-10.4927, -10.4015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.745567300939001e-05
Epoch 0, Step 233: train/loss = 0.7131461501121521, train/raw-loss = 0.7131268978118896, train/logprobs = tensor([[-10.4513, -10.5336],
        [-10.4541, -10.5746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8427482650149614e-05
Epoch 0, Step 234: train/loss = 0.7110030651092529, train/raw-loss = 0.7109838724136353, train/logprobs = tensor([[-10.4429, -10.4972],
        [-10.4612, -10.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8474088796647266e-05
Epoch 0, Step 235: train/loss = 0.6988341808319092, train/raw-loss = 0.6988151669502258, train/logprobs = tensor([[-10.4121, -10.3686],
        [-10.4593, -10.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7950223486404866e-05
Epoch 0, Step 236: train/loss = 0.7188621759414673, train/raw-loss = 0.7188428640365601, train/logprobs = tensor([[-10.4182, -10.4000],
        [-10.4296, -10.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8666716136503965e-05
Epoch 0, Step 237: train/loss = 0.696887731552124, train/raw-loss = 0.6968684792518616, train/logprobs = tensor([[-10.3822, -10.4042],
        [-10.4639, -10.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.851109795505181e-05
Epoch 0, Step 238: train/loss = 0.701481282711029, train/raw-loss = 0.7014620304107666, train/logprobs = tensor([[-10.4175, -10.4682],
        [-10.4836, -10.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.845180617645383e-05
Epoch 0, Step 239: train/loss = 0.7098492383956909, train/raw-loss = 0.7098298668861389, train/logprobs = tensor([[-10.4224, -10.4056],
        [-10.4229, -10.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.860473952954635e-05
Epoch 0, Step 240: train/loss = 0.7036511898040771, train/raw-loss = 0.7036318182945251, train/logprobs = tensor([[-10.4508, -10.4246],
        [-10.5133, -10.4700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8794696592958644e-05
Epoch 0, Step 241: train/loss = 0.6885552406311035, train/raw-loss = 0.6885361671447754, train/logprobs = tensor([[-10.4624, -10.4547],
        [-10.5535, -10.4816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.805442247539759e-05
Epoch 0, Step 242: train/loss = 0.6981066465377808, train/raw-loss = 0.6980881690979004, train/logprobs = tensor([[-10.4399, -10.4746],
        [-10.4855, -10.4845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.675693733384833e-05
Epoch 0, Step 243: train/loss = 0.7039331793785095, train/raw-loss = 0.7039140462875366, train/logprobs = tensor([[-10.4487, -10.5411],
        [-10.4564, -10.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.819530684268102e-05
Epoch 0, Step 244: train/loss = 0.6983408331871033, train/raw-loss = 0.6983214616775513, train/logprobs = tensor([[-10.4109, -10.4484],
        [-10.4277, -10.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8669131754431874e-05
Epoch 0, Step 245: train/loss = 0.7116435766220093, train/raw-loss = 0.7116247415542603, train/logprobs = tensor([[-10.4537, -10.4271],
        [-10.4717, -10.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.759192622965202e-05
Epoch 0, Step 246: train/loss = 0.7051417231559753, train/raw-loss = 0.7051226496696472, train/logprobs = tensor([[-10.5168, -10.3999],
        [-10.5023, -10.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.806444874498993e-05
Epoch 0, Step 247: train/loss = 0.7035514116287231, train/raw-loss = 0.7035325169563293, train/logprobs = tensor([[-10.4361, -10.4668],
        [-10.4979, -10.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.789053516811691e-05
Epoch 0, Step 248: train/loss = 0.6864172220230103, train/raw-loss = 0.6863980293273926, train/logprobs = tensor([[-10.4337, -10.3669],
        [-10.5209, -10.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8384612707886845e-05
Epoch 0, Step 249: train/loss = 0.705467164516449, train/raw-loss = 0.705447793006897, train/logprobs = tensor([[-10.4550, -10.4811],
        [-10.5082, -10.5347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8881771615706384e-05
Epoch 0, Step 250: train/loss = 0.6938609480857849, train/raw-loss = 0.6938416957855225, train/logprobs = tensor([[-10.4632, -10.2993],
        [-10.4792, -10.2793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.854327951557934e-05
Epoch 0, Step 251: train/loss = 0.6848840117454529, train/raw-loss = 0.6848651766777039, train/logprobs = tensor([[-10.3941, -10.4501],
        [-10.4949, -10.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.753479541046545e-05
Epoch 0, Step 252: train/loss = 0.7056331634521484, train/raw-loss = 0.7056138515472412, train/logprobs = tensor([[-10.4786, -10.4609],
        [-10.4772, -10.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.867004852509126e-05
Epoch 0, Step 253: train/loss = 0.7204785346984863, train/raw-loss = 0.7204586267471313, train/logprobs = tensor([[-10.4775, -10.3325],
        [-10.4796, -10.3989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.969395766034722e-05
Epoch 0, Step 254: train/loss = 0.6916842460632324, train/raw-loss = 0.6916648149490356, train/logprobs = tensor([[-10.4970, -10.5049],
        [-10.5056, -10.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.892751919920556e-05
Epoch 0, Step 255: train/loss = 0.7185636758804321, train/raw-loss = 0.718544602394104, train/logprobs = tensor([[-10.4639, -10.4370],
        [-10.5207, -10.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.80944438802544e-05
Epoch 0, Step 256: train/loss = 0.7034933567047119, train/raw-loss = 0.7034733295440674, train/logprobs = tensor([[-10.4666, -10.4608],
        [-10.4837, -10.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.02412042603828e-05
Epoch 0, Step 257: train/loss = 0.7020742893218994, train/raw-loss = 0.7020536661148071, train/logprobs = tensor([[-10.4731, -10.3619],
        [-10.4972, -10.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.12129593314603e-05
Epoch 0, Step 258: train/loss = 0.7084828615188599, train/raw-loss = 0.7084624767303467, train/logprobs = tensor([[-10.4121, -10.4454],
        [-10.4402, -10.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0763599827187136e-05
Epoch 0, Step 259: train/loss = 0.6973388195037842, train/raw-loss = 0.6973184943199158, train/logprobs = tensor([[-10.3924, -10.4320],
        [-10.4778, -10.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.05926548410207e-05
Epoch 0, Step 260: train/loss = 0.6921681761741638, train/raw-loss = 0.6921483278274536, train/logprobs = tensor([[-10.4374, -10.4539],
        [-10.4813, -10.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.961749462177977e-05
Epoch 0, Step 261: train/loss = 0.6800439357757568, train/raw-loss = 0.6800237894058228, train/logprobs = tensor([[-10.4588, -10.3461],
        [-10.5047, -10.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.051443102071062e-05
Epoch 0, Step 262: train/loss = 0.6867263317108154, train/raw-loss = 0.6867060661315918, train/logprobs = tensor([[-10.4290, -10.4694],
        [-10.5083, -10.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.055216413689777e-05
Epoch 0, Step 263: train/loss = 0.6965583562850952, train/raw-loss = 0.6965380907058716, train/logprobs = tensor([[-10.4645, -10.5084],
        [-10.4847, -10.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0560429624747485e-05
Epoch 0, Step 264: train/loss = 0.708662748336792, train/raw-loss = 0.7086426019668579, train/logprobs = tensor([[-10.4061, -10.5061],
        [-10.4034, -10.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.030935087939724e-05
Epoch 0, Step 265: train/loss = 0.6978811025619507, train/raw-loss = 0.6978606581687927, train/logprobs = tensor([[-10.4277, -10.5051],
        [-10.4412, -10.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.076452387380414e-05
Epoch 0, Step 266: train/loss = 0.7091891765594482, train/raw-loss = 0.7091692090034485, train/logprobs = tensor([[-10.3768, -10.5208],
        [-10.4208, -10.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.98959091398865e-05
Epoch 0, Step 267: train/loss = 0.7030575275421143, train/raw-loss = 0.7030375003814697, train/logprobs = tensor([[-10.4448, -10.4977],
        [-10.4773, -10.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0013186662690714e-05
Epoch 0, Step 268: train/loss = 0.6828038692474365, train/raw-loss = 0.6827837824821472, train/logprobs = tensor([[-10.3930, -10.3884],
        [-10.4550, -10.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0315739170182496e-05
Epoch 0, Step 269: train/loss = 0.6767842173576355, train/raw-loss = 0.676764726638794, train/logprobs = tensor([[-10.3697, -10.4217],
        [-10.4244, -10.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.911523526767269e-05
Epoch 0, Step 270: train/loss = 0.7108458280563354, train/raw-loss = 0.7108258605003357, train/logprobs = tensor([[-10.4348, -10.4270],
        [-10.4210, -10.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.006304880022071e-05
Epoch 0, Step 271: train/loss = 0.7033023834228516, train/raw-loss = 0.7032822370529175, train/logprobs = tensor([[-10.4515, -10.5065],
        [-10.4923, -10.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0374881791649386e-05
Epoch 0, Step 272: train/loss = 0.6965377926826477, train/raw-loss = 0.6965183615684509, train/logprobs = tensor([[-10.4101, -10.4453],
        [-10.4431, -10.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8800888432888314e-05
Epoch 0, Step 273: train/loss = 0.6812361478805542, train/raw-loss = 0.6812162399291992, train/logprobs = tensor([[-10.4631, -10.6336],
        [-10.4930, -10.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9868256862973794e-05
Epoch 0, Step 274: train/loss = 0.7011193037033081, train/raw-loss = 0.7010990381240845, train/logprobs = tensor([[-10.4742, -10.3063],
        [-10.4336, -10.2437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.054254532093182e-05
Epoch 0, Step 275: train/loss = 0.6949799656867981, train/raw-loss = 0.6949596405029297, train/logprobs = tensor([[-10.4173, -10.4762],
        [-10.4618, -10.4755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.071131115779281e-05
Epoch 0, Step 276: train/loss = 0.692778468132019, train/raw-loss = 0.6927584409713745, train/logprobs = tensor([[-10.3789, -10.4225],
        [-10.4604, -10.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.017582250526175e-05
Epoch 0, Step 277: train/loss = 0.689960777759552, train/raw-loss = 0.6899405717849731, train/logprobs = tensor([[-10.4307, -10.5573],
        [-10.4723, -10.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0389655623584986e-05
Epoch 0, Step 278: train/loss = 0.6909506320953369, train/raw-loss = 0.6909303665161133, train/logprobs = tensor([[-10.4532, -10.5022],
        [-10.4960, -10.4841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.050355710205622e-05
Epoch 0, Step 279: train/loss = 0.7238175272941589, train/raw-loss = 0.7237973213195801, train/logprobs = tensor([[-10.4648, -10.3945],
        [-10.4701, -10.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.021746644866653e-05
Epoch 0, Step 280: train/loss = 0.6996966004371643, train/raw-loss = 0.6996763348579407, train/logprobs = tensor([[-10.4567, -10.3949],
        [-10.4756, -10.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0642815292812884e-05
Epoch 0, Step 281: train/loss = 0.7131807208061218, train/raw-loss = 0.7131604552268982, train/logprobs = tensor([[-10.4806, -10.4443],
        [-10.5447, -10.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.049729250255041e-05
Epoch 0, Step 282: train/loss = 0.7025130391120911, train/raw-loss = 0.7024930119514465, train/logprobs = tensor([[-10.3967, -10.4343],
        [-10.4290, -10.4568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.011701821582392e-05
Epoch 0, Step 283: train/loss = 0.6932891011238098, train/raw-loss = 0.6932693719863892, train/logprobs = tensor([[-10.4387, -10.4698],
        [-10.4692, -10.4499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.945082062273286e-05
Epoch 0, Step 284: train/loss = 0.7049933075904846, train/raw-loss = 0.7049733400344849, train/logprobs = tensor([[-10.4410, -10.3315],
        [-10.5002, -10.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.992312849732116e-05
Epoch 0, Step 285: train/loss = 0.7203818559646606, train/raw-loss = 0.7203614711761475, train/logprobs = tensor([[-10.4655, -10.4060],
        [-10.4891, -10.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.082671148353256e-05
Epoch 0, Step 286: train/loss = 0.6931561231613159, train/raw-loss = 0.6931357979774475, train/logprobs = tensor([[-10.4005, -10.4454],
        [-10.4757, -10.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0732404158916324e-05
Epoch 0, Step 287: train/loss = 0.6997167468070984, train/raw-loss = 0.6996966600418091, train/logprobs = tensor([[-10.4520, -10.4876],
        [-10.4767, -10.5035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.009353506262414e-05
Epoch 0, Step 288: train/loss = 0.694693922996521, train/raw-loss = 0.694674015045166, train/logprobs = tensor([[-10.4387, -10.4318],
        [-10.4842, -10.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9923321310197935e-05
Epoch 0, Step 289: train/loss = 0.6920424103736877, train/raw-loss = 0.6920216083526611, train/logprobs = tensor([[-10.4647, -10.3646],
        [-10.5029, -10.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1533967305440456e-05
Epoch 0, Step 290: train/loss = 0.7098788022994995, train/raw-loss = 0.7098579406738281, train/logprobs = tensor([[-10.4501, -10.5004],
        [-10.4934, -10.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.16908114857506e-05
Epoch 0, Step 291: train/loss = 0.6973833441734314, train/raw-loss = 0.6973628997802734, train/logprobs = tensor([[-10.4516, -10.3602],
        [-10.4500, -10.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.08432497351896e-05
Epoch 0, Step 292: train/loss = 0.6984938383102417, train/raw-loss = 0.6984729766845703, train/logprobs = tensor([[-10.4786, -10.4988],
        [-10.4900, -10.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.174729474470951e-05
Epoch 0, Step 293: train/loss = 0.692865252494812, train/raw-loss = 0.6928446888923645, train/logprobs = tensor([[-10.4826, -10.3691],
        [-10.4704, -10.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.117745265830308e-05
Epoch 0, Step 294: train/loss = 0.6914027333259583, train/raw-loss = 0.6913825273513794, train/logprobs = tensor([[-10.4036, -10.4715],
        [-10.3737, -10.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0506878576707095e-05
Epoch 0, Step 295: train/loss = 0.6964861154556274, train/raw-loss = 0.6964655518531799, train/logprobs = tensor([[-10.4388, -10.4406],
        [-10.4620, -10.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.095617259736173e-05
Epoch 0, Step 296: train/loss = 0.7085553407669067, train/raw-loss = 0.7085347771644592, train/logprobs = tensor([[-10.4430, -10.4866],
        [-10.4421, -10.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.097295823157765e-05
Epoch 0, Step 297: train/loss = 0.685401439666748, train/raw-loss = 0.6853814125061035, train/logprobs = tensor([[-10.4301, -10.4556],
        [-10.5137, -10.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.996925079263747e-05
Epoch 0, Step 298: train/loss = 0.7074615955352783, train/raw-loss = 0.7074412107467651, train/logprobs = tensor([[-10.4700, -10.4855],
        [-10.4821, -10.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.071786315762438e-05
Epoch 0, Step 299: train/loss = 0.6984083652496338, train/raw-loss = 0.698387861251831, train/logprobs = tensor([[-10.4382, -10.4250],
        [-10.4706, -10.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.107675340492278e-05
Epoch 0, Step 300: train/loss = 0.7144173979759216, train/raw-loss = 0.7143970727920532, train/logprobs = tensor([[-10.3993, -10.4424],
        [-10.4207, -10.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.079154314240441e-05
Epoch 0, Step 301: train/loss = 0.6977351903915405, train/raw-loss = 0.6977148652076721, train/logprobs = tensor([[-10.4644, -10.4805],
        [-10.4576, -10.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.068657653988339e-05
Epoch 0, Step 302: train/loss = 0.7093693017959595, train/raw-loss = 0.7093486785888672, train/logprobs = tensor([[-10.4790, -10.4677],
        [-10.4855, -10.4742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1233062802348286e-05
Epoch 0, Step 303: train/loss = 0.6900780200958252, train/raw-loss = 0.6900577545166016, train/logprobs = tensor([[-10.3879, -10.5166],
        [-10.4274, -10.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.052904841955751e-05
Epoch 0, Step 304: train/loss = 0.6926164031028748, train/raw-loss = 0.6925955414772034, train/logprobs = tensor([[-10.4657, -10.4827],
        [-10.5098, -10.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.175912181381136e-05
Epoch 0, Step 305: train/loss = 0.7173803448677063, train/raw-loss = 0.7173594236373901, train/logprobs = tensor([[-10.4547, -10.4756],
        [-10.4659, -10.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.183336204732768e-05
Epoch 0, Step 306: train/loss = 0.7175056338310242, train/raw-loss = 0.7174848318099976, train/logprobs = tensor([[-10.4624, -10.4167],
        [-10.5114, -10.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.154925045440905e-05
Epoch 0, Step 307: train/loss = 0.6931091547012329, train/raw-loss = 0.6930884122848511, train/logprobs = tensor([[-10.4921, -10.4958],
        [-10.5168, -10.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.144142440054566e-05
Epoch 0, Step 308: train/loss = 0.709416389465332, train/raw-loss = 0.7093955874443054, train/logprobs = tensor([[-10.4505, -10.4394],
        [-10.4382, -10.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.162038385402411e-05
Epoch 0, Step 309: train/loss = 0.6925563812255859, train/raw-loss = 0.6925358772277832, train/logprobs = tensor([[-10.4495, -10.4127],
        [-10.4969, -10.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1062605305342004e-05
Epoch 0, Step 310: train/loss = 0.6908602118492126, train/raw-loss = 0.6908395886421204, train/logprobs = tensor([[-10.4127, -10.4147],
        [-10.4750, -10.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1314746340503916e-05
Epoch 0, Step 311: train/loss = 0.7264100909233093, train/raw-loss = 0.7263896465301514, train/logprobs = tensor([[-10.4204, -10.3250],
        [-10.4376, -10.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.095282929483801e-05
Epoch 0, Step 312: train/loss = 0.6931934356689453, train/raw-loss = 0.6931731700897217, train/logprobs = tensor([[-10.4196, -10.4562],
        [-10.4816, -10.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0599494241178036e-05
Epoch 0, Step 313: train/loss = 0.7114967107772827, train/raw-loss = 0.7114764451980591, train/logprobs = tensor([[-10.4431, -10.4082],
        [-10.4847, -10.4537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.044613160658628e-05
Epoch 0, Step 314: train/loss = 0.7213153839111328, train/raw-loss = 0.7212947607040405, train/logprobs = tensor([[-10.4441, -10.3589],
        [-10.5220, -10.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1181090637110174e-05
Epoch 0, Step 315: train/loss = 0.7042969465255737, train/raw-loss = 0.7042770385742188, train/logprobs = tensor([[-10.4827, -10.4601],
        [-10.4832, -10.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9915776142152026e-05
Epoch 0, Step 316: train/loss = 0.702214241027832, train/raw-loss = 0.7021938562393188, train/logprobs = tensor([[-10.4280, -10.4676],
        [-10.4627, -10.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0647155401529744e-05
Epoch 0, Step 317: train/loss = 0.6942818760871887, train/raw-loss = 0.6942611336708069, train/logprobs = tensor([[-10.3826, -10.4647],
        [-10.4264, -10.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.149636151851155e-05
Epoch 0, Step 318: train/loss = 0.6925488114356995, train/raw-loss = 0.692528486251831, train/logprobs = tensor([[-10.4670, -10.3943],
        [-10.5351, -10.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0717404772294685e-05
Epoch 0, Step 319: train/loss = 0.688584566116333, train/raw-loss = 0.6885644197463989, train/logprobs = tensor([[-10.4103, -10.3936],
        [-10.4868, -10.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0306069422513247e-05
Epoch 0, Step 320: train/loss = 0.7166269421577454, train/raw-loss = 0.7166062593460083, train/logprobs = tensor([[-10.4460, -10.3839],
        [-10.4651, -10.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.138341319048777e-05
Epoch 0, Step 321: train/loss = 0.6959086656570435, train/raw-loss = 0.6958874464035034, train/logprobs = tensor([[-10.3048, -10.2992],
        [-10.3715, -10.3311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.245303352945484e-05
Epoch 0, Step 322: train/loss = 0.7003943920135498, train/raw-loss = 0.7003733515739441, train/logprobs = tensor([[-10.4296, -10.4763],
        [-10.4651, -10.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.215294757159427e-05
Epoch 0, Step 323: train/loss = 0.697227954864502, train/raw-loss = 0.6972070932388306, train/logprobs = tensor([[-10.4554, -10.5096],
        [-10.5064, -10.5351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.186714068055153e-05
Epoch 0, Step 324: train/loss = 0.7082312107086182, train/raw-loss = 0.7082101106643677, train/logprobs = tensor([[-10.4504, -10.3299],
        [-10.5288, -10.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.225393422530033e-05
Epoch 0, Step 325: train/loss = 0.7162723541259766, train/raw-loss = 0.7162510752677917, train/logprobs = tensor([[-10.4612, -10.4187],
        [-10.4921, -10.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.2615632992237806e-05
Epoch 0, Step 326: train/loss = 0.69291090965271, train/raw-loss = 0.6928907632827759, train/logprobs = tensor([[-10.4244, -10.4747],
        [-10.4608, -10.4619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.03034791816026e-05
Epoch 0, Step 327: train/loss = 0.6981161236763, train/raw-loss = 0.698095977306366, train/logprobs = tensor([[-10.4284, -10.4545],
        [-10.4519, -10.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0381652070209384e-05
Epoch 0, Step 328: train/loss = 0.7068213820457458, train/raw-loss = 0.7068004012107849, train/logprobs = tensor([[-10.4511, -10.3872],
        [-10.5059, -10.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.186326987110078e-05
Epoch 0, Step 329: train/loss = 0.6932163238525391, train/raw-loss = 0.6931954622268677, train/logprobs = tensor([[-10.4620, -10.4562],
        [-10.4897, -10.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.171131513430737e-05
Epoch 0, Step 330: train/loss = 0.7130547165870667, train/raw-loss = 0.7130334377288818, train/logprobs = tensor([[-10.4623, -10.4506],
        [-10.4930, -10.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.249949779477902e-05
Epoch 0, Step 331: train/loss = 0.7050528526306152, train/raw-loss = 0.7050321102142334, train/logprobs = tensor([[-10.4832, -10.4153],
        [-10.5112, -10.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1518669604556635e-05
Epoch 0, Step 332: train/loss = 0.7099338173866272, train/raw-loss = 0.709912896156311, train/logprobs = tensor([[-10.4471, -10.3507],
        [-10.4730, -10.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.182560587651096e-05
Epoch 0, Step 333: train/loss = 0.7201287150382996, train/raw-loss = 0.7201078534126282, train/logprobs = tensor([[-10.4599, -10.4644],
        [-10.4478, -10.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.176671791356057e-05
Epoch 0, Step 334: train/loss = 0.7099769711494446, train/raw-loss = 0.7099559307098389, train/logprobs = tensor([[-10.4674, -10.4627],
        [-10.4865, -10.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.2086405301233754e-05
Epoch 0, Step 335: train/loss = 0.708386242389679, train/raw-loss = 0.7083655595779419, train/logprobs = tensor([[-10.4574, -10.4639],
        [-10.4710, -10.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.150089807808399e-05
Epoch 0, Step 336: train/loss = 0.7063007354736328, train/raw-loss = 0.7062798738479614, train/logprobs = tensor([[-10.4456, -10.4998],
        [-10.5049, -10.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1710511140991e-05
Epoch 0, Step 337: train/loss = 0.7044985294342041, train/raw-loss = 0.7044774889945984, train/logprobs = tensor([[-10.4622, -10.4547],
        [-10.4523, -10.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.211894702166319e-05
Epoch 0, Step 338: train/loss = 0.6959456205368042, train/raw-loss = 0.6959244608879089, train/logprobs = tensor([[-10.4188, -10.4610],
        [-10.4939, -10.5040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.226697637932375e-05
Epoch 0, Step 339: train/loss = 0.7122788429260254, train/raw-loss = 0.7122583389282227, train/logprobs = tensor([[-10.4284, -10.3084],
        [-10.4695, -10.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.099326179130003e-05
Epoch 0, Step 340: train/loss = 0.7106937170028687, train/raw-loss = 0.7106732130050659, train/logprobs = tensor([[-10.4492, -10.5188],
        [-10.4632, -10.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.113868999411352e-05
Epoch 0, Step 341: train/loss = 0.7001408338546753, train/raw-loss = 0.7001200914382935, train/logprobs = tensor([[-10.4325, -10.5089],
        [-10.4378, -10.4993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.144933700445108e-05
Epoch 0, Step 342: train/loss = 0.7246979475021362, train/raw-loss = 0.7246772646903992, train/logprobs = tensor([[-10.4378, -10.4324],
        [-10.4613, -10.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1319926822325215e-05
Epoch 0, Step 343: train/loss = 0.6852123737335205, train/raw-loss = 0.685191810131073, train/logprobs = tensor([[-10.4652, -10.5263],
        [-10.5249, -10.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1263047023676336e-05
Epoch 0, Step 344: train/loss = 0.6970625519752502, train/raw-loss = 0.69704270362854, train/logprobs = tensor([[-10.4750, -10.5068],
        [-10.5058, -10.5208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.974747232859954e-05
Epoch 0, Step 345: train/loss = 0.6886247992515564, train/raw-loss = 0.6886038780212402, train/logprobs = tensor([[-10.3852, -10.4636],
        [-10.4867, -10.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.193640052108094e-05
Epoch 0, Step 346: train/loss = 0.6996362209320068, train/raw-loss = 0.6996155381202698, train/logprobs = tensor([[-10.4345, -10.4890],
        [-10.4795, -10.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1326667997054756e-05
Epoch 0, Step 347: train/loss = 0.6741080284118652, train/raw-loss = 0.674087405204773, train/logprobs = tensor([[-10.4714, -10.4865],
        [-10.5334, -10.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.125395935261622e-05
Epoch 0, Step 348: train/loss = 0.7037731409072876, train/raw-loss = 0.7037527561187744, train/logprobs = tensor([[-10.4196, -10.4790],
        [-10.4256, -10.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.087194974999875e-05
Epoch 0, Step 349: train/loss = 0.7022989392280579, train/raw-loss = 0.7022783756256104, train/logprobs = tensor([[-10.4260, -10.4687],
        [-10.4653, -10.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1182291170116514e-05
Epoch 0, Step 350: train/loss = 0.7448747754096985, train/raw-loss = 0.7448538541793823, train/logprobs = tensor([[-10.4872, -10.4002],
        [-10.5142, -10.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1945990233216435e-05
Epoch 0, Step 351: train/loss = 0.6934280395507812, train/raw-loss = 0.6934069991111755, train/logprobs = tensor([[-10.4216, -10.3847],
        [-10.4501, -10.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.2008170566987246e-05
Epoch 0, Step 352: train/loss = 0.7075650095939636, train/raw-loss = 0.7075431942939758, train/logprobs = tensor([[-10.4788, -10.4800],
        [-10.4759, -10.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.36076516052708e-05
Epoch 0, Step 353: train/loss = 0.7083674073219299, train/raw-loss = 0.7083460092544556, train/logprobs = tensor([[-10.4522, -10.5162],
        [-10.4753, -10.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.272728619980626e-05
Epoch 0, Step 354: train/loss = 0.6830111742019653, train/raw-loss = 0.6829891204833984, train/logprobs = tensor([[-10.4030, -10.5167],
        [-10.4862, -10.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.406582593219355e-05
Epoch 0, Step 355: train/loss = 0.6870860457420349, train/raw-loss = 0.6870648264884949, train/logprobs = tensor([[-10.4442, -10.4333],
        [-10.4643, -10.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.235404048813507e-05
Epoch 0, Step 356: train/loss = 0.7077974677085876, train/raw-loss = 0.7077755928039551, train/logprobs = tensor([[-10.3700, -10.4342],
        [-10.3976, -10.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.36339141742792e-05
Epoch 0, Step 357: train/loss = 0.7030428647994995, train/raw-loss = 0.7030211091041565, train/logprobs = tensor([[-10.4725, -10.4281],
        [-10.5071, -10.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.350036397227086e-05
Epoch 0, Step 358: train/loss = 0.7027146220207214, train/raw-loss = 0.7026930451393127, train/logprobs = tensor([[-10.4253, -10.4837],
        [-10.4600, -10.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.320310108596459e-05
Epoch 0, Step 359: train/loss = 0.7010771036148071, train/raw-loss = 0.7010560035705566, train/logprobs = tensor([[-10.3960, -10.4484],
        [-10.4359, -10.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.237268149154261e-05
Epoch 0, Step 360: train/loss = 0.700971245765686, train/raw-loss = 0.7009495496749878, train/logprobs = tensor([[-10.5120, -10.4186],
        [-10.5687, -10.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.342985266703181e-05
Epoch 0, Step 361: train/loss = 0.7170054316520691, train/raw-loss = 0.7169840931892395, train/logprobs = tensor([[-10.3827, -10.4354],
        [-10.3538, -10.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.2730578570626676e-05
Epoch 0, Step 362: train/loss = 0.7063571214675903, train/raw-loss = 0.7063353061676025, train/logprobs = tensor([[-10.4088, -10.4534],
        [-10.4468, -10.5017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3652082240441814e-05
Epoch 0, Step 363: train/loss = 0.6971434950828552, train/raw-loss = 0.6971217393875122, train/logprobs = tensor([[-10.4213, -10.4401],
        [-10.4262, -10.4214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.350888048065826e-05
Epoch 0, Step 364: train/loss = 0.6857365369796753, train/raw-loss = 0.6857149600982666, train/logprobs = tensor([[-10.4017, -10.4177],
        [-10.4926, -10.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.315578189562075e-05
Epoch 0, Step 365: train/loss = 0.7026652693748474, train/raw-loss = 0.7026437520980835, train/logprobs = tensor([[-10.4261, -10.4494],
        [-10.4668, -10.4978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3067833757959306e-05
Epoch 0, Step 366: train/loss = 0.6911394596099854, train/raw-loss = 0.691118597984314, train/logprobs = tensor([[-10.4998, -10.4860],
        [-10.5311, -10.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1732273530215025e-05
Epoch 0, Step 367: train/loss = 0.7090345621109009, train/raw-loss = 0.7090128660202026, train/logprobs = tensor([[-10.4891, -10.4851],
        [-10.5410, -10.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.342673491919413e-05
Epoch 0, Step 368: train/loss = 0.69870924949646, train/raw-loss = 0.698687732219696, train/logprobs = tensor([[-10.4775, -10.4675],
        [-10.5101, -10.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.30131985922344e-05
Epoch 0, Step 369: train/loss = 0.6801185011863708, train/raw-loss = 0.6800967454910278, train/logprobs = tensor([[-10.4492, -10.4679],
        [-10.5353, -10.4419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3693471525330096e-05
Epoch 0, Step 370: train/loss = 0.7282018065452576, train/raw-loss = 0.7281802892684937, train/logprobs = tensor([[-10.4796, -10.4506],
        [-10.4750, -10.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.294376412872225e-05
Epoch 0, Step 371: train/loss = 0.6930234432220459, train/raw-loss = 0.6930016279220581, train/logprobs = tensor([[-10.4033, -10.4432],
        [-10.4524, -10.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.367797009763308e-05
Epoch 0, Step 372: train/loss = 0.7014238834381104, train/raw-loss = 0.7014031410217285, train/logprobs = tensor([[-10.4711, -10.4995],
        [-10.5029, -10.5184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.142160469200462e-05
Epoch 0, Step 373: train/loss = 0.707925021648407, train/raw-loss = 0.7079031467437744, train/logprobs = tensor([[-10.4901, -10.4690],
        [-10.4960, -10.4879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.375187563709915e-05
Epoch 0, Step 374: train/loss = 0.7014001607894897, train/raw-loss = 0.7013791799545288, train/logprobs = tensor([[-10.4648, -10.4208],
        [-10.5033, -10.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.204521610517986e-05
Epoch 0, Step 375: train/loss = 0.7012231945991516, train/raw-loss = 0.7012016773223877, train/logprobs = tensor([[-10.5275, -10.5052],
        [-10.5106, -10.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.316429840400815e-05
Epoch 0, Step 376: train/loss = 0.7033676505088806, train/raw-loss = 0.703345775604248, train/logprobs = tensor([[-10.3753, -10.3786],
        [-10.4118, -10.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.369558519101702e-05
Epoch 0, Step 377: train/loss = 0.6600295901298523, train/raw-loss = 0.6600086092948914, train/logprobs = tensor([[-10.3999, -10.4221],
        [-10.5446, -10.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.190070467302576e-05
Epoch 0, Step 378: train/loss = 0.6983810663223267, train/raw-loss = 0.698360800743103, train/logprobs = tensor([[-10.4044, -10.4201],
        [-10.4607, -10.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0468286897521466e-05
Epoch 0, Step 379: train/loss = 0.6867942810058594, train/raw-loss = 0.6867725849151611, train/logprobs = tensor([[-10.3726, -10.3192],
        [-10.4582, -10.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.337538848631084e-05
Epoch 0, Step 380: train/loss = 0.7017006874084473, train/raw-loss = 0.7016794681549072, train/logprobs = tensor([[-10.4467, -10.4842],
        [-10.5224, -10.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.226759119774215e-05
Epoch 0, Step 381: train/loss = 0.7064907550811768, train/raw-loss = 0.7064704895019531, train/logprobs = tensor([[-10.4804, -10.4677],
        [-10.5198, -10.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.07191037083976e-05
Epoch 0, Step 382: train/loss = 0.6731230616569519, train/raw-loss = 0.6731014251708984, train/logprobs = tensor([[-10.3821, -10.4144],
        [-10.4943, -10.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.330603769631125e-05
Epoch 0, Step 383: train/loss = 0.6932057738304138, train/raw-loss = 0.6931840181350708, train/logprobs = tensor([[-10.4762, -10.4402],
        [-10.4570, -10.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3271633330732584e-05
Epoch 0, Step 384: train/loss = 0.7090196013450623, train/raw-loss = 0.708997368812561, train/logprobs = tensor([[-10.4282, -10.4425],
        [-10.4805, -10.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.435689334059134e-05
Epoch 0, Step 385: train/loss = 0.6838955879211426, train/raw-loss = 0.6838726997375488, train/logprobs = tensor([[-10.3894, -10.4671],
        [-10.3863, -10.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5738408516626805e-05
Epoch 0, Step 386: train/loss = 0.7009900212287903, train/raw-loss = 0.7009674310684204, train/logprobs = tensor([[-10.4503, -10.4690],
        [-10.4869, -10.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5128694182494655e-05
Epoch 0, Step 387: train/loss = 0.711796224117279, train/raw-loss = 0.711773693561554, train/logprobs = tensor([[-10.3926, -10.3681],
        [-10.4202, -10.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.509420250542462e-05
Epoch 0, Step 388: train/loss = 0.7049843668937683, train/raw-loss = 0.7049618363380432, train/logprobs = tensor([[-10.3918, -10.4286],
        [-10.4370, -10.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.4995773350819945e-05
Epoch 0, Step 389: train/loss = 0.7067080736160278, train/raw-loss = 0.7066857814788818, train/logprobs = tensor([[-10.4590, -10.4607],
        [-10.5199, -10.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.451911445357837e-05
Epoch 0, Step 390: train/loss = 0.7051208019256592, train/raw-loss = 0.705098032951355, train/logprobs = tensor([[-10.4046, -10.4330],
        [-10.4540, -10.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.552330574369989e-05
Epoch 0, Step 391: train/loss = 0.7042387127876282, train/raw-loss = 0.7042163610458374, train/logprobs = tensor([[-10.3848, -10.3582],
        [-10.4214, -10.4096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.484066448640078e-05
Epoch 0, Step 392: train/loss = 0.6867756843566895, train/raw-loss = 0.6867530345916748, train/logprobs = tensor([[-10.3769, -10.3926],
        [-10.4243, -10.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5328175474423915e-05
Epoch 0, Step 393: train/loss = 0.7071364521980286, train/raw-loss = 0.7071142792701721, train/logprobs = tensor([[-10.4443, -10.4943],
        [-10.4861, -10.5485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.438579344423488e-05
Epoch 0, Step 394: train/loss = 0.7160114049911499, train/raw-loss = 0.7159886360168457, train/logprobs = tensor([[-10.4144, -10.4501],
        [-10.4537, -10.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.564238042803481e-05
Epoch 0, Step 395: train/loss = 0.674363911151886, train/raw-loss = 0.6743412613868713, train/logprobs = tensor([[-10.4106, -10.3742],
        [-10.4618, -10.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5348089770413935e-05
Epoch 0, Step 396: train/loss = 0.7072048783302307, train/raw-loss = 0.7071827054023743, train/logprobs = tensor([[-10.5300, -10.4580],
        [-10.5577, -10.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.4362917833495885e-05
Epoch 0, Step 397: train/loss = 0.6999017000198364, train/raw-loss = 0.6998792886734009, train/logprobs = tensor([[-10.3935, -10.4065],
        [-10.4460, -10.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.488531340030022e-05
Epoch 0, Step 398: train/loss = 0.698573648929596, train/raw-loss = 0.6985510587692261, train/logprobs = tensor([[-10.4087, -10.5021],
        [-10.4728, -10.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5199783926364034e-05
Epoch 0, Step 399: train/loss = 0.7069678902626038, train/raw-loss = 0.7069459557533264, train/logprobs = tensor([[-10.5159, -10.4975],
        [-10.5309, -10.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.382790211820975e-05
Epoch 0, Step 400: train/loss = 0.672959566116333, train/raw-loss = 0.6729371547698975, train/logprobs = tensor([[-10.3955, -10.4732],
        [-10.4876, -10.4151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.4831595005234703e-05
Epoch 0, Step 401: train/loss = 0.7118102312088013, train/raw-loss = 0.711787760257721, train/logprobs = tensor([[-10.4426, -10.3748],
        [-10.5338, -10.4824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.488003469305113e-05
Epoch 0, Step 402: train/loss = 0.6950030326843262, train/raw-loss = 0.6949805021286011, train/logprobs = tensor([[-10.4382, -10.3929],
        [-10.4769, -10.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.502692536334507e-05
Epoch 0, Step 403: train/loss = 0.7020658254623413, train/raw-loss = 0.7020428776741028, train/logprobs = tensor([[-10.3923, -10.4036],
        [-10.4484, -10.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.587409785017371e-05
Epoch 0, Step 404: train/loss = 0.7063247561454773, train/raw-loss = 0.706301748752594, train/logprobs = tensor([[-10.4340, -10.3998],
        [-10.4758, -10.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.604081914294511e-05
Epoch 0, Step 405: train/loss = 0.7024303674697876, train/raw-loss = 0.7024075984954834, train/logprobs = tensor([[-10.4447, -10.4631],
        [-10.4434, -10.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.550924859358929e-05
Epoch 0, Step 406: train/loss = 0.6932488679885864, train/raw-loss = 0.6932268142700195, train/logprobs = tensor([[-10.4457, -10.3823],
        [-10.4600, -10.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.409046960063279e-05
Epoch 0, Step 407: train/loss = 0.7103606462478638, train/raw-loss = 0.7103380560874939, train/logprobs = tensor([[-10.4146, -10.3763],
        [-10.4352, -10.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.514097236096859e-05
Epoch 0, Step 408: train/loss = 0.7126824855804443, train/raw-loss = 0.712660551071167, train/logprobs = tensor([[-10.4630, -10.4435],
        [-10.4201, -10.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3784188164863735e-05
Epoch 0, Step 409: train/loss = 0.6921855211257935, train/raw-loss = 0.6921626329421997, train/logprobs = tensor([[-10.4771, -10.4022],
        [-10.5555, -10.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.584576890920289e-05
Epoch 0, Step 410: train/loss = 0.703040599822998, train/raw-loss = 0.703018069267273, train/logprobs = tensor([[-10.4295, -10.3236],
        [-10.4772, -10.3641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5225464418763295e-05
Epoch 0, Step 411: train/loss = 0.7198781371116638, train/raw-loss = 0.7198551297187805, train/logprobs = tensor([[-10.4597, -10.4670],
        [-10.4744, -10.5388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.589256423059851e-05
Epoch 0, Step 412: train/loss = 0.7053718566894531, train/raw-loss = 0.7053490877151489, train/logprobs = tensor([[-10.4357, -10.4318],
        [-10.4638, -10.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.564897244563326e-05
Epoch 0, Step 413: train/loss = 0.6998032331466675, train/raw-loss = 0.6997802257537842, train/logprobs = tensor([[-10.4486, -10.4514],
        [-10.4834, -10.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5971224608365446e-05
Epoch 0, Step 414: train/loss = 0.7043786644935608, train/raw-loss = 0.7043564319610596, train/logprobs = tensor([[-10.4099, -10.4202],
        [-10.4530, -10.4522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.438350515556522e-05
Epoch 0, Step 415: train/loss = 0.6715026497840881, train/raw-loss = 0.6714797019958496, train/logprobs = tensor([[-10.4162, -10.3545],
        [-10.5286, -10.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5869666791986674e-05
Epoch 0, Step 416: train/loss = 0.685253381729126, train/raw-loss = 0.6852295994758606, train/logprobs = tensor([[-10.4427, -10.4962],
        [-10.5080, -10.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7546334826620296e-05
Epoch 0, Step 417: train/loss = 0.7354035973548889, train/raw-loss = 0.7353798151016235, train/logprobs = tensor([[-10.4588, -10.4007],
        [-10.4840, -10.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.751127562485635e-05
Epoch 0, Step 418: train/loss = 0.6863647103309631, train/raw-loss = 0.6863406896591187, train/logprobs = tensor([[-10.4556, -10.5045],
        [-10.4567, -10.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7983350668800995e-05
Epoch 0, Step 419: train/loss = 0.6992992758750916, train/raw-loss = 0.6992756128311157, train/logprobs = tensor([[-10.4728, -10.4730],
        [-10.4801, -10.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.727183477371e-05
Epoch 0, Step 420: train/loss = 0.734716534614563, train/raw-loss = 0.7346927523612976, train/logprobs = tensor([[-10.4388, -10.3449],
        [-10.4829, -10.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.761381569551304e-05
Epoch 0, Step 421: train/loss = 0.6916322112083435, train/raw-loss = 0.6916081309318542, train/logprobs = tensor([[-10.4360, -10.4337],
        [-10.4989, -10.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.808945595868863e-05
Epoch 0, Step 422: train/loss = 0.713638424873352, train/raw-loss = 0.7136145830154419, train/logprobs = tensor([[-10.4125, -10.4201],
        [-10.4334, -10.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7712532250443473e-05
Epoch 0, Step 423: train/loss = 0.7043741345405579, train/raw-loss = 0.7043505907058716, train/logprobs = tensor([[-10.4264, -10.4158],
        [-10.4614, -10.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7163070121314377e-05
Epoch 0, Step 424: train/loss = 0.706213653087616, train/raw-loss = 0.7061898708343506, train/logprobs = tensor([[-10.5314, -10.4911],
        [-10.5686, -10.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.755663394462317e-05
Epoch 0, Step 425: train/loss = 0.7044898271560669, train/raw-loss = 0.7044658660888672, train/logprobs = tensor([[-10.4559, -10.4979],
        [-10.4405, -10.4875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.806445213034749e-05
Epoch 0, Step 426: train/loss = 0.6858413219451904, train/raw-loss = 0.685817539691925, train/logprobs = tensor([[-10.5365, -10.5341],
        [-10.6013, -10.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.770580562762916e-05
Epoch 0, Step 427: train/loss = 0.7215548753738403, train/raw-loss = 0.7215316295623779, train/logprobs = tensor([[-10.3318, -10.3560],
        [-10.4312, -10.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.652389179682359e-05
Epoch 0, Step 428: train/loss = 0.7130441069602966, train/raw-loss = 0.7130206823348999, train/logprobs = tensor([[-10.5356, -10.4521],
        [-10.4798, -10.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.694742528954521e-05
Epoch 0, Step 429: train/loss = 0.6976396441459656, train/raw-loss = 0.6976159811019897, train/logprobs = tensor([[-10.3651, -10.3891],
        [-10.4317, -10.4214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7306213673437014e-05
Epoch 0, Step 430: train/loss = 0.7177814841270447, train/raw-loss = 0.7177579998970032, train/logprobs = tensor([[-10.4982, -10.4489],
        [-10.5107, -10.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.692112997872755e-05
Epoch 0, Step 431: train/loss = 0.7024939060211182, train/raw-loss = 0.7024704813957214, train/logprobs = tensor([[-10.4268, -10.4580],
        [-10.4369, -10.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.683356746681966e-05
Epoch 0, Step 432: train/loss = 0.7168348431587219, train/raw-loss = 0.7168111205101013, train/logprobs = tensor([[-10.4121, -10.4489],
        [-10.4407, -10.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.756058842758648e-05
Epoch 0, Step 433: train/loss = 0.70688796043396, train/raw-loss = 0.7068639993667603, train/logprobs = tensor([[-10.4962, -10.4529],
        [-10.5482, -10.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.788903606822714e-05
Epoch 0, Step 434: train/loss = 0.7008558511734009, train/raw-loss = 0.7008317708969116, train/logprobs = tensor([[-10.4451, -10.4589],
        [-10.5098, -10.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8069799959193915e-05
Epoch 0, Step 435: train/loss = 0.7067713737487793, train/raw-loss = 0.7067474126815796, train/logprobs = tensor([[-10.4935, -10.5173],
        [-10.4853, -10.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.794247797690332e-05
Epoch 0, Step 436: train/loss = 0.7129488587379456, train/raw-loss = 0.7129249572753906, train/logprobs = tensor([[-10.5037, -10.4017],
        [-10.5132, -10.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7720135626150295e-05
Epoch 0, Step 437: train/loss = 0.6673387885093689, train/raw-loss = 0.667314887046814, train/logprobs = tensor([[-10.3992, -10.5507],
        [-10.4780, -10.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.79111768072471e-05
Epoch 0, Step 438: train/loss = 0.6932368278503418, train/raw-loss = 0.6932127475738525, train/logprobs = tensor([[-10.4600, -10.4941],
        [-10.5163, -10.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8136709665413946e-05
Epoch 0, Step 439: train/loss = 0.7087955474853516, train/raw-loss = 0.7087713479995728, train/logprobs = tensor([[-10.5394, -10.5345],
        [-10.5301, -10.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8452013288624585e-05
Epoch 0, Step 440: train/loss = 0.703320324420929, train/raw-loss = 0.7032968401908875, train/logprobs = tensor([[-10.4206, -10.3947],
        [-10.4590, -10.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.6904686314519495e-05
Epoch 0, Step 441: train/loss = 0.6909474730491638, train/raw-loss = 0.6909240484237671, train/logprobs = tensor([[-10.4227, -10.5521],
        [-10.4581, -10.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.689523484557867e-05
Epoch 0, Step 442: train/loss = 0.7164737582206726, train/raw-loss = 0.7164498567581177, train/logprobs = tensor([[-10.4384, -10.4497],
        [-10.4355, -10.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7723926400067285e-05
Epoch 0, Step 443: train/loss = 0.6967459917068481, train/raw-loss = 0.6967220902442932, train/logprobs = tensor([[-10.4346, -10.3912],
        [-10.4767, -10.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.78019101137761e-05
Epoch 0, Step 444: train/loss = 0.6976088285446167, train/raw-loss = 0.6975851058959961, train/logprobs = tensor([[-10.4782, -10.4474],
        [-10.4852, -10.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7329678636742756e-05
Epoch 0, Step 445: train/loss = 0.6953209042549133, train/raw-loss = 0.6952968239784241, train/logprobs = tensor([[-10.4634, -10.4847],
        [-10.4907, -10.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.822709161089733e-05
Epoch 0, Step 446: train/loss = 0.6924523711204529, train/raw-loss = 0.6924290657043457, train/logprobs = tensor([[-10.4006, -10.5256],
        [-10.4151, -10.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.6598441258538514e-05
Epoch 0, Step 447: train/loss = 0.6948590278625488, train/raw-loss = 0.6948354244232178, train/logprobs = tensor([[-10.4124, -10.4526],
        [-10.4861, -10.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7237612307071686e-05
Epoch 0, Step 448: train/loss = 0.7097577452659607, train/raw-loss = 0.7097328305244446, train/logprobs = tensor([[-10.4401, -10.4396],
        [-10.4480, -10.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9836035032058135e-05
Epoch 0, Step 449: train/loss = 0.7218685150146484, train/raw-loss = 0.7218441367149353, train/logprobs = tensor([[-10.4564, -10.3444],
        [-10.4819, -10.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.881695713265799e-05
Epoch 0, Step 450: train/loss = 0.7040983438491821, train/raw-loss = 0.7040736675262451, train/logprobs = tensor([[-10.3687, -10.3573],
        [-10.4573, -10.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.929232454742305e-05
Epoch 0, Step 451: train/loss = 0.712878942489624, train/raw-loss = 0.712854266166687, train/logprobs = tensor([[-10.4774, -10.3090],
        [-10.4960, -10.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9352074711350724e-05
Epoch 0, Step 452: train/loss = 0.7074644565582275, train/raw-loss = 0.707439661026001, train/logprobs = tensor([[-10.4362, -10.5170],
        [-10.4581, -10.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.961808008374646e-05
Epoch 0, Step 453: train/loss = 0.707939624786377, train/raw-loss = 0.7079142332077026, train/logprobs = tensor([[-10.4620, -10.3782],
        [-10.5111, -10.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.0719670980470255e-05
Epoch 0, Step 454: train/loss = 0.7060144543647766, train/raw-loss = 0.7059895992279053, train/logprobs = tensor([[-10.4795, -10.3269],
        [-10.5286, -10.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9835285608423874e-05
Epoch 0, Step 455: train/loss = 0.7006160020828247, train/raw-loss = 0.7005913257598877, train/logprobs = tensor([[-10.4772, -10.5313],
        [-10.4663, -10.5005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9348207539878786e-05
Epoch 0, Step 456: train/loss = 0.7057193517684937, train/raw-loss = 0.7056950926780701, train/logprobs = tensor([[-10.4802, -10.4724],
        [-10.4684, -10.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8633031838107854e-05
Epoch 0, Step 457: train/loss = 0.7004954814910889, train/raw-loss = 0.700471043586731, train/logprobs = tensor([[-10.4742, -10.4748],
        [-10.5032, -10.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8968810006044805e-05
Epoch 0, Step 458: train/loss = 0.7069104909896851, train/raw-loss = 0.7068865895271301, train/logprobs = tensor([[-10.4064, -10.4805],
        [-10.4411, -10.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.791388346347958e-05
Epoch 0, Step 459: train/loss = 0.6992443799972534, train/raw-loss = 0.6992195248603821, train/logprobs = tensor([[-10.4814, -10.3753],
        [-10.4912, -10.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.968099528923631e-05
Epoch 0, Step 460: train/loss = 0.7099722027778625, train/raw-loss = 0.7099476456642151, train/logprobs = tensor([[-10.4201, -10.3806],
        [-10.4368, -10.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.915690442430787e-05
Epoch 0, Step 461: train/loss = 0.6996949315071106, train/raw-loss = 0.6996698379516602, train/logprobs = tensor([[-10.4393, -10.4598],
        [-10.4532, -10.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.005577622796409e-05
Epoch 0, Step 462: train/loss = 0.6906107664108276, train/raw-loss = 0.6905857920646667, train/logprobs = tensor([[-10.3959, -10.4529],
        [-10.4633, -10.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9886846682056785e-05
Epoch 0, Step 463: train/loss = 0.7090975046157837, train/raw-loss = 0.7090734243392944, train/logprobs = tensor([[-10.4623, -10.5351],
        [-10.4852, -10.5732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8045418225228786e-05
Epoch 0, Step 464: train/loss = 0.697233259677887, train/raw-loss = 0.6972084045410156, train/logprobs = tensor([[-10.3725, -10.4851],
        [-10.4059, -10.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.976740092388354e-05
Epoch 0, Step 465: train/loss = 0.7027558088302612, train/raw-loss = 0.7027314305305481, train/logprobs = tensor([[-10.4314, -10.4637],
        [-10.4370, -10.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8742094804765657e-05
Epoch 0, Step 466: train/loss = 0.6963669061660767, train/raw-loss = 0.6963420510292053, train/logprobs = tensor([[-10.4407, -10.4883],
        [-10.4352, -10.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.975205956725404e-05
Epoch 0, Step 467: train/loss = 0.7065183520317078, train/raw-loss = 0.7064937949180603, train/logprobs = tensor([[-10.4438, -10.3368],
        [-10.4965, -10.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.91683094878681e-05
Epoch 0, Step 468: train/loss = 0.7036446928977966, train/raw-loss = 0.7036200761795044, train/logprobs = tensor([[-10.4026, -10.4021],
        [-10.4820, -10.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.918130798614584e-05
Epoch 0, Step 469: train/loss = 0.699068009853363, train/raw-loss = 0.6990436315536499, train/logprobs = tensor([[-10.4296, -10.3905],
        [-10.4697, -10.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.881728091277182e-05
Epoch 0, Step 470: train/loss = 0.7154670357704163, train/raw-loss = 0.7154431343078613, train/logprobs = tensor([[-10.4367, -10.3895],
        [-10.4439, -10.4477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.785455530509353e-05
Epoch 0, Step 471: train/loss = 0.6984794735908508, train/raw-loss = 0.6984551548957825, train/logprobs = tensor([[-10.4422, -10.4224],
        [-10.4705, -10.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.878435720456764e-05
Epoch 0, Step 472: train/loss = 0.6908264756202698, train/raw-loss = 0.6908018589019775, train/logprobs = tensor([[-10.4143, -10.4618],
        [-10.4564, -10.4549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.923259257338941e-05
Epoch 0, Step 473: train/loss = 0.6775930523872375, train/raw-loss = 0.6775684952735901, train/logprobs = tensor([[-10.4450, -10.4942],
        [-10.5669, -10.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.923584492644295e-05
Epoch 0, Step 474: train/loss = 0.712550938129425, train/raw-loss = 0.7125260829925537, train/logprobs = tensor([[-10.4528, -10.4451],
        [-10.5129, -10.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.973740942659788e-05
Epoch 0, Step 475: train/loss = 0.7152581810951233, train/raw-loss = 0.7152332663536072, train/logprobs = tensor([[-10.4064, -10.3807],
        [-10.4149, -10.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9945250793825835e-05
Epoch 0, Step 476: train/loss = 0.6737347841262817, train/raw-loss = 0.6737103462219238, train/logprobs = tensor([[-10.4243, -10.6633],
        [-10.4640, -10.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.893550794804469e-05
Epoch 0, Step 477: train/loss = 0.6687464714050293, train/raw-loss = 0.6687216758728027, train/logprobs = tensor([[-10.3911, -10.3870],
        [-10.4911, -10.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.960969454259612e-05
Epoch 0, Step 478: train/loss = 0.7098197937011719, train/raw-loss = 0.7097963094711304, train/logprobs = tensor([[-10.4295, -10.4486],
        [-10.4470, -10.4810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.705235915025696e-05
Epoch 0, Step 479: train/loss = 0.6978705525398254, train/raw-loss = 0.6978459358215332, train/logprobs = tensor([[-10.4249, -10.4509],
        [-10.4525, -10.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.939079735777341e-05
Epoch 0, Step 480: train/loss = 0.6915711164474487, train/raw-loss = 0.6915450692176819, train/logprobs = tensor([[-10.4527, -10.4525],
        [-10.4860, -10.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.211145253269933e-05
Epoch 0, Step 481: train/loss = 0.701160192489624, train/raw-loss = 0.701134204864502, train/logprobs = tensor([[-10.4341, -10.5188],
        [-10.4404, -10.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.190281444811262e-05
Epoch 0, Step 482: train/loss = 0.7075506448745728, train/raw-loss = 0.7075240612030029, train/logprobs = tensor([[-10.4717, -10.3754],
        [-10.5271, -10.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.3065035899635404e-05
Epoch 0, Step 483: train/loss = 0.6980912089347839, train/raw-loss = 0.698064386844635, train/logprobs = tensor([[-10.4393, -10.4567],
        [-10.4804, -10.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.362532829167321e-05
Epoch 0, Step 484: train/loss = 0.7181200981140137, train/raw-loss = 0.718093991279602, train/logprobs = tensor([[-10.4534, -10.5292],
        [-10.4611, -10.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2281218813732266e-05
Epoch 0, Step 485: train/loss = 0.7047411203384399, train/raw-loss = 0.7047152519226074, train/logprobs = tensor([[-10.4332, -10.3882],
        [-10.4656, -10.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.1639533921843395e-05
Epoch 0, Step 486: train/loss = 0.6956503391265869, train/raw-loss = 0.6956238746643066, train/logprobs = tensor([[-10.4145, -10.4427],
        [-10.4611, -10.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.295108348946087e-05
Epoch 0, Step 487: train/loss = 0.704800009727478, train/raw-loss = 0.7047737836837769, train/logprobs = tensor([[-10.4496, -10.5065],
        [-10.4689, -10.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.241686085355468e-05
Epoch 0, Step 488: train/loss = 0.6884983777999878, train/raw-loss = 0.6884726881980896, train/logprobs = tensor([[-10.4502, -10.4747],
        [-10.5014, -10.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.147282354300842e-05
Epoch 0, Step 489: train/loss = 0.694429337978363, train/raw-loss = 0.6944036483764648, train/logprobs = tensor([[-10.4192, -10.4408],
        [-10.4409, -10.4308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.121337380842306e-05
Epoch 0, Step 490: train/loss = 0.6797893047332764, train/raw-loss = 0.6797627210617065, train/logprobs = tensor([[-10.3496, -10.4066],
        [-10.4646, -10.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.321656499290839e-05
Epoch 0, Step 491: train/loss = 0.7319397926330566, train/raw-loss = 0.731913685798645, train/logprobs = tensor([[-10.4446, -10.3977],
        [-10.4855, -10.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2177732868585736e-05
Epoch 0, Step 492: train/loss = 0.6606789231300354, train/raw-loss = 0.6606533527374268, train/logprobs = tensor([[-10.3788, -10.4429],
        [-10.4344, -10.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.118291301187128e-05
Epoch 0, Step 493: train/loss = 0.6943904161453247, train/raw-loss = 0.6943634748458862, train/logprobs = tensor([[-10.4405, -10.4790],
        [-10.4860, -10.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.362416777643375e-05
Epoch 0, Step 494: train/loss = 0.7016639113426208, train/raw-loss = 0.7016379833221436, train/logprobs = tensor([[-10.4745, -10.4770],
        [-10.5322, -10.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.195503035793081e-05
Epoch 0, Step 495: train/loss = 0.7028278112411499, train/raw-loss = 0.7028013467788696, train/logprobs = tensor([[-10.4444, -10.5055],
        [-10.4535, -10.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.284463622956537e-05
Epoch 0, Step 496: train/loss = 0.6929383277893066, train/raw-loss = 0.6929117441177368, train/logprobs = tensor([[-10.4904, -10.4750],
        [-10.5371, -10.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.315287125995383e-05
Epoch 0, Step 497: train/loss = 0.7002729773521423, train/raw-loss = 0.7002468109130859, train/logprobs = tensor([[-10.4349, -10.3389],
        [-10.4768, -10.3668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.233269985183142e-05
Epoch 0, Step 498: train/loss = 0.7101579308509827, train/raw-loss = 0.7101314067840576, train/logprobs = tensor([[-10.4255, -10.3945],
        [-10.4449, -10.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2979761676397175e-05
Epoch 0, Step 499: train/loss = 0.6936315298080444, train/raw-loss = 0.6936048269271851, train/logprobs = tensor([[-10.4163, -10.3749],
        [-10.4987, -10.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.3367115469882265e-05
Epoch 0, Step 500: train/loss = 0.706803560256958, train/raw-loss = 0.7067771553993225, train/logprobs = tensor([[-10.4338, -10.4004],
        [-10.4563, -10.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2733623306266963e-05
Epoch 0, Step 501: train/loss = 0.714068591594696, train/raw-loss = 0.7140419483184814, train/logprobs = tensor([[-10.4855, -10.4662],
        [-10.5060, -10.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.3284067689673975e-05
Epoch 0, Step 502: train/loss = 0.6927265524864197, train/raw-loss = 0.6927003264427185, train/logprobs = tensor([[-10.4530, -10.4309],
        [-10.5282, -10.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.252310438663699e-05
Epoch 0, Step 503: train/loss = 0.7100512385368347, train/raw-loss = 0.7100250124931335, train/logprobs = tensor([[-10.4743, -10.5169],
        [-10.4756, -10.5506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.239463280304335e-05
Epoch 0, Step 504: train/loss = 0.7000709772109985, train/raw-loss = 0.7000460624694824, train/logprobs = tensor([[-10.4748, -10.4816],
        [-10.4932, -10.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.986765270587057e-05
Epoch 0, Step 505: train/loss = 0.6981707215309143, train/raw-loss = 0.6981444358825684, train/logprobs = tensor([[-10.5203, -10.5304],
        [-10.5212, -10.5092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.269241955829784e-05
Epoch 0, Step 506: train/loss = 0.6961556673049927, train/raw-loss = 0.6961287260055542, train/logprobs = tensor([[-10.4432, -10.3627],
        [-10.4921, -10.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.388275531004183e-05
Epoch 0, Step 507: train/loss = 0.692363977432251, train/raw-loss = 0.6923370957374573, train/logprobs = tensor([[-10.4338, -10.4586],
        [-10.4862, -10.4672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.367499034036882e-05
Epoch 0, Step 508: train/loss = 0.7027522921562195, train/raw-loss = 0.7027273178100586, train/logprobs = tensor([[-10.4538, -10.4498],
        [-10.4327, -10.4310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.98929075547494e-05
Epoch 0, Step 509: train/loss = 0.6822316646575928, train/raw-loss = 0.6822050213813782, train/logprobs = tensor([[-10.4860, -10.5322],
        [-10.5158, -10.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.324383528204635e-05
Epoch 0, Step 510: train/loss = 0.7216079235076904, train/raw-loss = 0.721581757068634, train/logprobs = tensor([[-10.4389, -10.4547],
        [-10.4311, -10.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.244489875622094e-05
Epoch 0, Step 511: train/loss = 0.6739494800567627, train/raw-loss = 0.6739233136177063, train/logprobs = tensor([[-10.4473, -10.5837],
        [-10.4117, -10.3922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.245673673925921e-05
Epoch 0, Step 512: train/loss = 0.7163382768630981, train/raw-loss = 0.716310977935791, train/logprobs = tensor([[-10.4462, -10.4276],
        [-10.4819, -10.5012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4637366702081636e-05
Epoch 0, Step 513: train/loss = 0.6968151330947876, train/raw-loss = 0.6967875957489014, train/logprobs = tensor([[-10.4024, -10.5067],
        [-10.4409, -10.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.510797200258821e-05
Epoch 0, Step 514: train/loss = 0.6892642974853516, train/raw-loss = 0.689237117767334, train/logprobs = tensor([[-10.4950, -10.5077],
        [-10.5426, -10.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4277847084449604e-05
Epoch 0, Step 515: train/loss = 0.7043697834014893, train/raw-loss = 0.7043419480323792, train/logprobs = tensor([[-10.3916, -10.4153],
        [-10.4394, -10.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.579681237577461e-05
Epoch 0, Step 516: train/loss = 0.7044177651405334, train/raw-loss = 0.7043906450271606, train/logprobs = tensor([[-10.4420, -10.4148],
        [-10.4907, -10.4637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4355077736545354e-05
Epoch 0, Step 517: train/loss = 0.6947286128997803, train/raw-loss = 0.6947014331817627, train/logprobs = tensor([[-10.4346, -10.4179],
        [-10.4888, -10.4265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.444959970191121e-05
Epoch 0, Step 518: train/loss = 0.6987106800079346, train/raw-loss = 0.6986832618713379, train/logprobs = tensor([[-10.4766, -10.4376],
        [-10.5754, -10.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4814194299979135e-05
Epoch 0, Step 519: train/loss = 0.6962693929672241, train/raw-loss = 0.6962422132492065, train/logprobs = tensor([[-10.4747, -10.4611],
        [-10.4774, -10.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4485746659338474e-05
Epoch 0, Step 520: train/loss = 0.7188175320625305, train/raw-loss = 0.7187893390655518, train/logprobs = tensor([[-10.4260, -10.3852],
        [-10.4363, -10.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.629767838399857e-05
Epoch 0, Step 521: train/loss = 0.699752151966095, train/raw-loss = 0.6997250318527222, train/logprobs = tensor([[-10.4856, -10.4875],
        [-10.5414, -10.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.429225348052569e-05
Epoch 0, Step 522: train/loss = 0.6978510618209839, train/raw-loss = 0.6978227496147156, train/logprobs = tensor([[-10.4823, -10.4769],
        [-10.4909, -10.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.661516479449347e-05
Epoch 0, Step 523: train/loss = 0.695223867893219, train/raw-loss = 0.695196807384491, train/logprobs = tensor([[-10.4589, -10.3879],
        [-10.5222, -10.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4192445531953126e-05
Epoch 0, Step 524: train/loss = 0.6908828616142273, train/raw-loss = 0.6908552646636963, train/logprobs = tensor([[-10.4789, -10.4505],
        [-10.5341, -10.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.519187106983736e-05
Epoch 0, Step 525: train/loss = 0.704695463180542, train/raw-loss = 0.704668402671814, train/logprobs = tensor([[-10.4507, -10.5066],
        [-10.4649, -10.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4135154641699046e-05
Epoch 0, Step 526: train/loss = 0.6964815855026245, train/raw-loss = 0.6964544057846069, train/logprobs = tensor([[-10.5197, -10.5550],
        [-10.5429, -10.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.456817598314956e-05
Epoch 0, Step 527: train/loss = 0.6761505603790283, train/raw-loss = 0.6761226654052734, train/logprobs = tensor([[-10.4607, -10.5451],
        [-10.5110, -10.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.579743447015062e-05
Epoch 0, Step 528: train/loss = 0.717329740524292, train/raw-loss = 0.717301607131958, train/logprobs = tensor([[-10.4233, -10.4358],
        [-10.3974, -10.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.624703408102505e-05
Epoch 0, Step 529: train/loss = 0.7072559595108032, train/raw-loss = 0.7072280645370483, train/logprobs = tensor([[-10.4578, -10.4485],
        [-10.4645, -10.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.570504072238691e-05
Epoch 0, Step 530: train/loss = 0.6736734509468079, train/raw-loss = 0.6736454367637634, train/logprobs = tensor([[-10.4354, -10.4537],
        [-10.4870, -10.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.595983020612039e-05
Epoch 0, Step 531: train/loss = 0.6843036413192749, train/raw-loss = 0.6842767596244812, train/logprobs = tensor([[-10.3928, -10.4379],
        [-10.4127, -10.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.384163887356408e-05
Epoch 0, Step 532: train/loss = 0.7062363028526306, train/raw-loss = 0.7062087059020996, train/logprobs = tensor([[-10.3701, -10.3988],
        [-10.3561, -10.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.5190779676195234e-05
Epoch 0, Step 533: train/loss = 0.6760652661323547, train/raw-loss = 0.6760377883911133, train/logprobs = tensor([[-10.4284, -10.3439],
        [-10.4530, -10.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4667751101078466e-05
Epoch 0, Step 534: train/loss = 0.7144238948822021, train/raw-loss = 0.7143961191177368, train/logprobs = tensor([[-10.4339, -10.4528],
        [-10.4292, -10.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.565242099692114e-05
Epoch 0, Step 535: train/loss = 0.7193044424057007, train/raw-loss = 0.7192773222923279, train/logprobs = tensor([[-10.4200, -10.4788],
        [-10.4209, -10.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.424226765171625e-05
Epoch 0, Step 536: train/loss = 0.7049084901809692, train/raw-loss = 0.7048808932304382, train/logprobs = tensor([[-10.4089, -10.4400],
        [-10.4699, -10.5020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.53212157683447e-05
Epoch 0, Step 537: train/loss = 0.7006829977035522, train/raw-loss = 0.700654923915863, train/logprobs = tensor([[-10.4888, -10.4361],
        [-10.5393, -10.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6068023695843294e-05
Epoch 0, Step 538: train/loss = 0.6982898712158203, train/raw-loss = 0.698263943195343, train/logprobs = tensor([[-10.4267, -10.4459],
        [-10.4639, -10.4532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.191256423131563e-05
Epoch 0, Step 539: train/loss = 0.7041797637939453, train/raw-loss = 0.7041524052619934, train/logprobs = tensor([[-10.4380, -10.4825],
        [-10.4709, -10.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4733551223762333e-05
Epoch 0, Step 540: train/loss = 0.6980628967285156, train/raw-loss = 0.6980348825454712, train/logprobs = tensor([[-10.4208, -10.3975],
        [-10.4530, -10.4049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.613551911665127e-05
Epoch 0, Step 541: train/loss = 0.711610734462738, train/raw-loss = 0.7115828990936279, train/logprobs = tensor([[-10.4167, -10.4259],
        [-10.4524, -10.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.565618630498648e-05
Epoch 0, Step 542: train/loss = 0.6821984052658081, train/raw-loss = 0.682171106338501, train/logprobs = tensor([[-10.4507, -10.4563],
        [-10.5171, -10.4277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.444713315228e-05
Epoch 0, Step 543: train/loss = 0.7106441855430603, train/raw-loss = 0.7106177806854248, train/logprobs = tensor([[-10.4083, -10.3586],
        [-10.4341, -10.4041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.276269803289324e-05
Epoch 0, Step 544: train/loss = 0.7091776132583618, train/raw-loss = 0.7091487050056458, train/logprobs = tensor([[-10.4815, -10.4085],
        [-10.5228, -10.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.782666994491592e-05
Epoch 0, Step 545: train/loss = 0.6996148228645325, train/raw-loss = 0.6995856761932373, train/logprobs = tensor([[-10.4418, -10.4329],
        [-10.5193, -10.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.829303336213343e-05
Epoch 0, Step 546: train/loss = 0.7055134177207947, train/raw-loss = 0.7054850459098816, train/logprobs = tensor([[-10.4399, -10.4286],
        [-10.4483, -10.4497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.677100125467405e-05
Epoch 0, Step 547: train/loss = 0.6834186315536499, train/raw-loss = 0.6833896636962891, train/logprobs = tensor([[-10.3437, -10.4393],
        [-10.4254, -10.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8050511142937467e-05
Epoch 0, Step 548: train/loss = 0.7052337527275085, train/raw-loss = 0.7052047848701477, train/logprobs = tensor([[-10.4323, -10.4550],
        [-10.4487, -10.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.790185241494328e-05
Epoch 0, Step 549: train/loss = 0.7113320827484131, train/raw-loss = 0.7113033533096313, train/logprobs = tensor([[-10.5165, -10.4074],
        [-10.5090, -10.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.760595013271086e-05
Epoch 0, Step 550: train/loss = 0.7192329168319702, train/raw-loss = 0.7192045450210571, train/logprobs = tensor([[-10.4525, -10.4534],
        [-10.4635, -10.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6774744734866545e-05
Epoch 0, Step 551: train/loss = 0.7068818807601929, train/raw-loss = 0.7068527936935425, train/logprobs = tensor([[-10.4396, -10.4542],
        [-10.4576, -10.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.808152491226792e-05
Epoch 0, Step 552: train/loss = 0.6877379417419434, train/raw-loss = 0.6877090930938721, train/logprobs = tensor([[-10.4071, -10.4398],
        [-10.4758, -10.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.752372817369178e-05
Epoch 0, Step 553: train/loss = 0.703881561756134, train/raw-loss = 0.7038534879684448, train/logprobs = tensor([[-10.4756, -10.4718],
        [-10.5106, -10.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.622211392619647e-05
Epoch 0, Step 554: train/loss = 0.6990854740142822, train/raw-loss = 0.6990574598312378, train/logprobs = tensor([[-10.3970, -10.4584],
        [-10.4655, -10.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.5986565712373704e-05
Epoch 0, Step 555: train/loss = 0.6988179683685303, train/raw-loss = 0.6987905502319336, train/logprobs = tensor([[-10.4427, -10.5066],
        [-10.5062, -10.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.481933112605475e-05
Epoch 0, Step 556: train/loss = 0.687293529510498, train/raw-loss = 0.6872652769088745, train/logprobs = tensor([[-10.4268, -10.4626],
        [-10.4712, -10.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6700653658481315e-05
Epoch 0, Step 557: train/loss = 0.7069931626319885, train/raw-loss = 0.7069642543792725, train/logprobs = tensor([[-10.4958, -10.4546],
        [-10.5061, -10.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.80057458137162e-05
Epoch 0, Step 558: train/loss = 0.7042940855026245, train/raw-loss = 0.7042651772499084, train/logprobs = tensor([[-10.4416, -10.4923],
        [-10.4534, -10.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.780756691819988e-05
Epoch 0, Step 559: train/loss = 0.6905030012130737, train/raw-loss = 0.6904744505882263, train/logprobs = tensor([[-10.4024, -10.3654],
        [-10.4605, -10.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.7220015150960535e-05
Epoch 0, Step 560: train/loss = 0.6983669400215149, train/raw-loss = 0.6983385682106018, train/logprobs = tensor([[-10.4162, -10.4848],
        [-10.4501, -10.4963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.686681470251642e-05
Epoch 0, Step 561: train/loss = 0.6961581707000732, train/raw-loss = 0.6961289048194885, train/logprobs = tensor([[-10.4024, -10.4941],
        [-10.4867, -10.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8547357184579596e-05
Epoch 0, Step 562: train/loss = 0.702834963798523, train/raw-loss = 0.7028067111968994, train/logprobs = tensor([[-10.3783, -10.3971],
        [-10.4348, -10.4486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.660718306899071e-05
Epoch 0, Step 563: train/loss = 0.7068364024162292, train/raw-loss = 0.7068079113960266, train/logprobs = tensor([[-10.4425, -10.4275],
        [-10.4780, -10.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.694702849723399e-05
Epoch 0, Step 564: train/loss = 0.7127925157546997, train/raw-loss = 0.7127636671066284, train/logprobs = tensor([[-10.4793, -10.4972],
        [-10.5145, -10.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.760939166066237e-05
Epoch 0, Step 565: train/loss = 0.6818229556083679, train/raw-loss = 0.6817934513092041, train/logprobs = tensor([[-10.4341, -10.4444],
        [-10.5335, -10.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.908823004574515e-05
Epoch 0, Step 566: train/loss = 0.7027463912963867, train/raw-loss = 0.7027171850204468, train/logprobs = tensor([[-10.4659, -10.4446],
        [-10.5020, -10.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.840085941599682e-05
Epoch 0, Step 567: train/loss = 0.69893479347229, train/raw-loss = 0.6989068388938904, train/logprobs = tensor([[-10.4493, -10.4320],
        [-10.4771, -10.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6028446124400944e-05
Epoch 0, Step 568: train/loss = 0.6922917366027832, train/raw-loss = 0.6922632455825806, train/logprobs = tensor([[-10.5084, -10.5047],
        [-10.5617, -10.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.695425716112368e-05
Epoch 0, Step 569: train/loss = 0.6982738971710205, train/raw-loss = 0.6982461214065552, train/logprobs = tensor([[-10.4953, -10.5247],
        [-10.4914, -10.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.546294414671138e-05
Epoch 0, Step 570: train/loss = 0.7126184701919556, train/raw-loss = 0.7125900983810425, train/logprobs = tensor([[-10.4430, -10.4253],
        [-10.4539, -10.4674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6628727179486305e-05
Epoch 0, Step 571: train/loss = 0.7134488224983215, train/raw-loss = 0.7134194374084473, train/logprobs = tensor([[-10.4038, -10.4104],
        [-10.4506, -10.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8709949371404946e-05
Epoch 0, Step 572: train/loss = 0.6792114973068237, train/raw-loss = 0.6791825294494629, train/logprobs = tensor([[-10.4785, -10.4648],
        [-10.5341, -10.4247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.7917066442314535e-05
Epoch 0, Step 573: train/loss = 0.6864436864852905, train/raw-loss = 0.6864144206047058, train/logprobs = tensor([[-10.4189, -10.3550],
        [-10.5034, -10.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.85217094339896e-05
Epoch 0, Step 574: train/loss = 0.717870831489563, train/raw-loss = 0.7178416848182678, train/logprobs = tensor([[-10.4407, -10.4868],
        [-10.4782, -10.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8269397413823754e-05
Epoch 0, Step 575: train/loss = 0.7052447199821472, train/raw-loss = 0.705215573310852, train/logprobs = tensor([[-10.3755, -10.3886],
        [-10.3624, -10.3637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.80807427468244e-05
Epoch 0, Step 576: train/loss = 0.6805461645126343, train/raw-loss = 0.6805171370506287, train/logprobs = tensor([[-10.4013, -10.4561],
        [-10.4711, -10.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.806580156786367e-05
Epoch 0, Step 577: train/loss = 0.7026463747024536, train/raw-loss = 0.702616810798645, train/logprobs = tensor([[-10.4890, -10.5187],
        [-10.5086, -10.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.91573552810587e-05
Epoch 0, Step 578: train/loss = 0.6999691724777222, train/raw-loss = 0.6999386548995972, train/logprobs = tensor([[-10.3947, -10.3948],
        [-10.4308, -10.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.119163299445063e-05
Epoch 0, Step 579: train/loss = 0.7087273001670837, train/raw-loss = 0.7086973190307617, train/logprobs = tensor([[-10.4539, -10.4350],
        [-10.4653, -10.4791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0098915128037333e-05
Epoch 0, Step 580: train/loss = 0.706087052822113, train/raw-loss = 0.7060570120811462, train/logprobs = tensor([[-10.4200, -10.4636],
        [-10.4669, -10.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.005493924021721e-05
Epoch 0, Step 581: train/loss = 0.6959008574485779, train/raw-loss = 0.6958712339401245, train/logprobs = tensor([[-10.3947, -10.4749],
        [-10.4731, -10.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.9267575124977157e-05
Epoch 0, Step 582: train/loss = 0.6934035420417786, train/raw-loss = 0.6933742761611938, train/logprobs = tensor([[-10.3922, -10.4322],
        [-10.4802, -10.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8418765547685325e-05
Epoch 0, Step 583: train/loss = 0.6922008991241455, train/raw-loss = 0.6921703219413757, train/logprobs = tensor([[-10.4331, -10.5196],
        [-10.4768, -10.4916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.123249477241188e-05
Epoch 0, Step 584: train/loss = 0.7135196924209595, train/raw-loss = 0.7134890556335449, train/logprobs = tensor([[-10.4202, -10.3296],
        [-10.4357, -10.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.128854874987155e-05
Epoch 0, Step 585: train/loss = 0.6957570314407349, train/raw-loss = 0.6957274079322815, train/logprobs = tensor([[-10.4628, -10.5160],
        [-10.4962, -10.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.9310757933417335e-05
Epoch 0, Step 586: train/loss = 0.6749972105026245, train/raw-loss = 0.6749669313430786, train/logprobs = tensor([[-10.4686, -10.5327],
        [-10.5364, -10.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.057453720131889e-05
Epoch 0, Step 587: train/loss = 0.6849987506866455, train/raw-loss = 0.6849687695503235, train/logprobs = tensor([[-10.3987, -10.4660],
        [-10.4646, -10.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.9968555433442816e-05
Epoch 0, Step 588: train/loss = 0.7174468040466309, train/raw-loss = 0.7174181938171387, train/logprobs = tensor([[-10.4765, -10.3898],
        [-10.4987, -10.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.722080095438287e-05
Epoch 0, Step 589: train/loss = 0.7086741924285889, train/raw-loss = 0.7086447477340698, train/logprobs = tensor([[-10.4416, -10.4268],
        [-10.4338, -10.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8941630413755774e-05
Epoch 0, Step 590: train/loss = 0.6982510089874268, train/raw-loss = 0.698220431804657, train/logprobs = tensor([[-10.4085, -10.4764],
        [-10.5084, -10.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.118929013609886e-05
Epoch 0, Step 591: train/loss = 0.7005990147590637, train/raw-loss = 0.7005688548088074, train/logprobs = tensor([[-10.4365, -10.4209],
        [-10.4605, -10.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0417580243665725e-05
Epoch 0, Step 592: train/loss = 0.7195499539375305, train/raw-loss = 0.7195196151733398, train/logprobs = tensor([[-10.4764, -10.3546],
        [-10.5154, -10.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0690312238875777e-05
Epoch 0, Step 593: train/loss = 0.7005772590637207, train/raw-loss = 0.7005471587181091, train/logprobs = tensor([[-10.4495, -10.5051],
        [-10.4661, -10.5061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.023531386745162e-05
Epoch 0, Step 594: train/loss = 0.7005593776702881, train/raw-loss = 0.7005299925804138, train/logprobs = tensor([[-10.4332, -10.4727],
        [-10.4541, -10.4877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8865749451797456e-05
Epoch 0, Step 595: train/loss = 0.6995289921760559, train/raw-loss = 0.6994984745979309, train/logprobs = tensor([[-10.5054, -10.4797],
        [-10.5214, -10.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.112192932050675e-05
Epoch 0, Step 596: train/loss = 0.7008480429649353, train/raw-loss = 0.7008174657821655, train/logprobs = tensor([[-10.4720, -10.3943],
        [-10.5173, -10.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.128940731287003e-05
Epoch 0, Step 597: train/loss = 0.7351974248886108, train/raw-loss = 0.7351666688919067, train/logprobs = tensor([[-10.4439, -10.3213],
        [-10.4369, -10.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.138662865851074e-05
Epoch 0, Step 598: train/loss = 0.7117195725440979, train/raw-loss = 0.7116893529891968, train/logprobs = tensor([[-10.4561, -10.4771],
        [-10.4808, -10.5282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.031268640072085e-05
Epoch 0, Step 599: train/loss = 0.7131286263465881, train/raw-loss = 0.7130985856056213, train/logprobs = tensor([[-10.4402, -10.3624],
        [-10.5009, -10.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0095761000411585e-05
Epoch 0, Step 600: train/loss = 0.6873965263366699, train/raw-loss = 0.6873664259910583, train/logprobs = tensor([[-10.4031, -10.4610],
        [-10.4801, -10.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.000715075060725e-05
Epoch 0, Step 601: train/loss = 0.6989795565605164, train/raw-loss = 0.6989490985870361, train/logprobs = tensor([[-10.4101, -10.4352],
        [-10.4464, -10.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.100857353885658e-05
Epoch 0, Step 602: train/loss = 0.7061335444450378, train/raw-loss = 0.7061038017272949, train/logprobs = tensor([[-10.3449, -10.3097],
        [-10.4063, -10.3845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.952779974904843e-05
Epoch 0, Step 603: train/loss = 0.6951713562011719, train/raw-loss = 0.6951406002044678, train/logprobs = tensor([[-10.4178, -10.4268],
        [-10.4685, -10.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.15382450632751e-05
Epoch 0, Step 604: train/loss = 0.714357852935791, train/raw-loss = 0.7143274545669556, train/logprobs = tensor([[-10.3822, -10.4121],
        [-10.4262, -10.4814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0714482970070094e-05
Epoch 0, Step 605: train/loss = 0.7104488015174866, train/raw-loss = 0.710419774055481, train/logprobs = tensor([[-10.4494, -10.4507],
        [-10.4676, -10.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.802766827400774e-05
Epoch 0, Step 606: train/loss = 0.7030545473098755, train/raw-loss = 0.7030249834060669, train/logprobs = tensor([[-10.4425, -10.4392],
        [-10.4617, -10.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.903260171180591e-05
Epoch 0, Step 607: train/loss = 0.7020525932312012, train/raw-loss = 0.7020221948623657, train/logprobs = tensor([[-10.4864, -10.4614],
        [-10.5110, -10.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.081707397243008e-05
Epoch 0, Step 608: train/loss = 0.6989591121673584, train/raw-loss = 0.6989270448684692, train/logprobs = tensor([[-10.4059, -10.4365],
        [-10.4612, -10.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.402227154467255e-05
Epoch 0, Step 609: train/loss = 0.7006078958511353, train/raw-loss = 0.7005767822265625, train/logprobs = tensor([[-10.4357, -10.4599],
        [-10.4849, -10.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.217868940439075e-05
Epoch 0, Step 610: train/loss = 0.7354118824005127, train/raw-loss = 0.735379695892334, train/logprobs = tensor([[-10.4832, -10.4692],
        [-10.4203, -10.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.448161730077118e-05
Epoch 0, Step 611: train/loss = 0.717516303062439, train/raw-loss = 0.7174837589263916, train/logprobs = tensor([[-10.4288, -10.4875],
        [-10.4276, -10.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.511766696348786e-05
Epoch 0, Step 612: train/loss = 0.7118622064590454, train/raw-loss = 0.7118304967880249, train/logprobs = tensor([[-10.3987, -10.4227],
        [-10.4133, -10.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.336835213005543e-05
Epoch 0, Step 613: train/loss = 0.7247050404548645, train/raw-loss = 0.7246736884117126, train/logprobs = tensor([[-10.4796, -10.4209],
        [-10.5067, -10.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.273548933677375e-05
Epoch 0, Step 614: train/loss = 0.6893690228462219, train/raw-loss = 0.6893371343612671, train/logprobs = tensor([[-10.4340, -10.5198],
        [-10.4914, -10.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.377234240062535e-05
Epoch 0, Step 615: train/loss = 0.710220456123352, train/raw-loss = 0.7101896405220032, train/logprobs = tensor([[-10.4675, -10.3534],
        [-10.4797, -10.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.145119550637901e-05
Epoch 0, Step 616: train/loss = 0.7159203290939331, train/raw-loss = 0.7158888578414917, train/logprobs = tensor([[-10.3955, -10.4464],
        [-10.4114, -10.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.284146365942433e-05
Epoch 0, Step 617: train/loss = 0.699616551399231, train/raw-loss = 0.6995859742164612, train/logprobs = tensor([[-10.4951, -10.4066],
        [-10.5386, -10.4149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.125465733930469e-05
Epoch 0, Step 618: train/loss = 0.7079188823699951, train/raw-loss = 0.7078885436058044, train/logprobs = tensor([[-10.4468, -10.4758],
        [-10.5111, -10.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0460675740614533e-05
Epoch 0, Step 619: train/loss = 0.6964206695556641, train/raw-loss = 0.6963884830474854, train/logprobs = tensor([[-10.4618, -10.3932],
        [-10.4902, -10.3819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.43901148578152e-05
Epoch 0, Step 620: train/loss = 0.7115403413772583, train/raw-loss = 0.7115090489387512, train/logprobs = tensor([[-10.3567, -10.2767],
        [-10.3501, -10.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.265033880481496e-05
Epoch 0, Step 621: train/loss = 0.7128109335899353, train/raw-loss = 0.7127804756164551, train/logprobs = tensor([[-10.4364, -10.4813],
        [-10.4591, -10.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.0824073443654925e-05
Epoch 0, Step 622: train/loss = 0.7079391479492188, train/raw-loss = 0.7079076170921326, train/logprobs = tensor([[-10.4068, -10.3726],
        [-10.4294, -10.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.311521428870037e-05
Epoch 0, Step 623: train/loss = 0.6830342411994934, train/raw-loss = 0.6830026507377625, train/logprobs = tensor([[-10.4533, -10.4716],
        [-10.4980, -10.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.309231685008854e-05
Epoch 0, Step 624: train/loss = 0.6914176344871521, train/raw-loss = 0.6913859248161316, train/logprobs = tensor([[-10.4704, -10.4535],
        [-10.5148, -10.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.330086762318388e-05
Epoch 0, Step 625: train/loss = 0.7025597095489502, train/raw-loss = 0.7025278806686401, train/logprobs = tensor([[-10.4190, -10.4016],
        [-10.4559, -10.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.35689139016904e-05
Epoch 0, Step 626: train/loss = 0.6747914552688599, train/raw-loss = 0.6747597455978394, train/logprobs = tensor([[-10.5066, -10.4755],
        [-10.5644, -10.4106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.341720290947706e-05
Epoch 0, Step 627: train/loss = 0.7099199891090393, train/raw-loss = 0.7098886966705322, train/logprobs = tensor([[-10.4531, -10.3276],
        [-10.5065, -10.3989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.270334415603429e-05
Epoch 0, Step 628: train/loss = 0.7003265619277954, train/raw-loss = 0.7002955079078674, train/logprobs = tensor([[-10.4285, -10.3757],
        [-10.5008, -10.4388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.211144500412047e-05
Epoch 0, Step 629: train/loss = 0.6934783458709717, train/raw-loss = 0.693447470664978, train/logprobs = tensor([[-10.4081, -10.4360],
        [-10.4858, -10.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.168145046103746e-05
Epoch 0, Step 630: train/loss = 0.706142783164978, train/raw-loss = 0.7061110138893127, train/logprobs = tensor([[-10.4437, -10.4617],
        [-10.4579, -10.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.357028905767947e-05
Epoch 0, Step 631: train/loss = 0.6920027732849121, train/raw-loss = 0.6919710040092468, train/logprobs = tensor([[-10.4246, -10.3649],
        [-10.4889, -10.3780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.36200129520148e-05
Epoch 0, Step 632: train/loss = 0.7061985731124878, train/raw-loss = 0.7061667442321777, train/logprobs = tensor([[-10.4527, -10.4634],
        [-10.4870, -10.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.385757296811789e-05
Epoch 0, Step 633: train/loss = 0.7030782699584961, train/raw-loss = 0.7030481100082397, train/logprobs = tensor([[-10.4293, -10.4492],
        [-10.4627, -10.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.028700590832159e-05
Epoch 0, Step 634: train/loss = 0.7101255059242249, train/raw-loss = 0.7100940942764282, train/logprobs = tensor([[-10.5041, -10.4922],
        [-10.4956, -10.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.29505084361881e-05
Epoch 0, Step 635: train/loss = 0.6839832067489624, train/raw-loss = 0.6839515566825867, train/logprobs = tensor([[-10.4179, -10.5082],
        [-10.4567, -10.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.332331395242363e-05
Epoch 0, Step 636: train/loss = 0.6977130770683289, train/raw-loss = 0.6976816654205322, train/logprobs = tensor([[-10.4209, -10.4648],
        [-10.4706, -10.4630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.279143417486921e-05
Epoch 0, Step 637: train/loss = 0.7158879041671753, train/raw-loss = 0.7158564925193787, train/logprobs = tensor([[-10.4345, -10.3718],
        [-10.4624, -10.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.276606291066855e-05
Epoch 0, Step 638: train/loss = 0.6926217675209045, train/raw-loss = 0.692590594291687, train/logprobs = tensor([[-10.3892, -10.4908],
        [-10.4295, -10.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.226831465028226e-05
Epoch 0, Step 639: train/loss = 0.7029337882995605, train/raw-loss = 0.7029021382331848, train/logprobs = tensor([[-10.4100, -10.3824],
        [-10.5010, -10.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.33624877082184e-05
Epoch 0, Step 640: train/loss = 0.7055127620697021, train/raw-loss = 0.705479621887207, train/logprobs = tensor([[-10.4507, -10.4304],
        [-10.4590, -10.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.61578233120963e-05
Epoch 0, Step 641: train/loss = 0.7074239253997803, train/raw-loss = 0.707390546798706, train/logprobs = tensor([[-10.4068, -10.3346],
        [-10.4365, -10.3706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.677626515738666e-05
Epoch 0, Step 642: train/loss = 0.6900029182434082, train/raw-loss = 0.6899691224098206, train/logprobs = tensor([[-10.4299, -10.5152],
        [-10.4506, -10.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.7538334405981e-05
Epoch 0, Step 643: train/loss = 0.7085211277008057, train/raw-loss = 0.7084883451461792, train/logprobs = tensor([[-10.4943, -10.4582],
        [-10.4893, -10.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.555903382832184e-05
Epoch 0, Step 644: train/loss = 0.7050044536590576, train/raw-loss = 0.7049726247787476, train/logprobs = tensor([[-10.5004, -10.4288],
        [-10.5334, -10.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.369773473124951e-05
Epoch 0, Step 645: train/loss = 0.699895441532135, train/raw-loss = 0.6998622417449951, train/logprobs = tensor([[-10.3899, -10.4645],
        [-10.4295, -10.4694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.62751990603283e-05
Epoch 0, Step 646: train/loss = 0.6827887296676636, train/raw-loss = 0.682755172252655, train/logprobs = tensor([[-10.3811, -10.6193],
        [-10.4415, -10.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.70273439027369e-05
Epoch 0, Step 647: train/loss = 0.7108379006385803, train/raw-loss = 0.7108058929443359, train/logprobs = tensor([[-10.4494, -10.4641],
        [-10.4671, -10.5100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.401920109055936e-05
Epoch 0, Step 648: train/loss = 0.6784786581993103, train/raw-loss = 0.67844557762146, train/logprobs = tensor([[-10.4222, -10.4905],
        [-10.4689, -10.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.624386151088402e-05
Epoch 0, Step 649: train/loss = 0.713068425655365, train/raw-loss = 0.7130352258682251, train/logprobs = tensor([[-10.4570, -10.4378],
        [-10.4941, -10.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.638229388045147e-05
Epoch 0, Step 650: train/loss = 0.6967194080352783, train/raw-loss = 0.6966859102249146, train/logprobs = tensor([[-10.5182, -10.4777],
        [-10.5518, -10.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.693469185847789e-05
Epoch 0, Step 651: train/loss = 0.6724194288253784, train/raw-loss = 0.672386884689331, train/logprobs = tensor([[-10.4468, -10.5173],
        [-10.4916, -10.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.509015656774864e-05
Epoch 0, Step 652: train/loss = 0.701522707939148, train/raw-loss = 0.701489269733429, train/logprobs = tensor([[-10.3833, -10.4593],
        [-10.4106, -10.4610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.683696119580418e-05
Epoch 0, Step 653: train/loss = 0.7023687362670898, train/raw-loss = 0.702335774898529, train/logprobs = tensor([[-10.4537, -10.4209],
        [-10.5160, -10.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.58381322864443e-05
Epoch 0, Step 654: train/loss = 0.7057127952575684, train/raw-loss = 0.7056804895401001, train/logprobs = tensor([[-10.4175, -10.4762],
        [-10.4605, -10.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.477550778072327e-05
Epoch 0, Step 655: train/loss = 0.7209396362304688, train/raw-loss = 0.7209086418151855, train/logprobs = tensor([[-10.4577, -10.4985],
        [-10.4724, -10.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.186949758557603e-05
Epoch 0, Step 656: train/loss = 0.7105095386505127, train/raw-loss = 0.7104763388633728, train/logprobs = tensor([[-10.3399, -10.3895],
        [-10.4203, -10.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.641585059696808e-05
Epoch 0, Step 657: train/loss = 0.6937685608863831, train/raw-loss = 0.6937360763549805, train/logprobs = tensor([[-10.4401, -10.4711],
        [-10.4514, -10.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.511126412078738e-05
Epoch 0, Step 658: train/loss = 0.6918580532073975, train/raw-loss = 0.6918256878852844, train/logprobs = tensor([[-10.4040, -10.4017],
        [-10.4718, -10.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.462564488174394e-05
Epoch 0, Step 659: train/loss = 0.6985199451446533, train/raw-loss = 0.698486328125, train/logprobs = tensor([[-10.4180, -10.4329],
        [-10.4456, -10.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.714080518577248e-05
Epoch 0, Step 660: train/loss = 0.7022400498390198, train/raw-loss = 0.7022068500518799, train/logprobs = tensor([[-10.4364, -10.4584],
        [-10.4429, -10.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.637668411713094e-05
Epoch 0, Step 661: train/loss = 0.6963740587234497, train/raw-loss = 0.6963412165641785, train/logprobs = tensor([[-10.4849, -10.4601],
        [-10.5252, -10.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.559441681019962e-05
Epoch 0, Step 662: train/loss = 0.6970582008361816, train/raw-loss = 0.6970251202583313, train/logprobs = tensor([[-10.4093, -10.4331],
        [-10.4942, -10.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.605166709050536e-05
Epoch 0, Step 663: train/loss = 0.6700747013092041, train/raw-loss = 0.6700419783592224, train/logprobs = tensor([[-10.4114, -10.4167],
        [-10.5440, -10.3776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.547066732309759e-05
Epoch 0, Step 664: train/loss = 0.7031847238540649, train/raw-loss = 0.7031512260437012, train/logprobs = tensor([[-10.4807, -10.5169],
        [-10.4993, -10.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.704050611006096e-05
Epoch 0, Step 665: train/loss = 0.6983485221862793, train/raw-loss = 0.6983156800270081, train/logprobs = tensor([[-10.4918, -10.5422],
        [-10.4935, -10.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.562990165548399e-05
Epoch 0, Step 666: train/loss = 0.7126460671424866, train/raw-loss = 0.7126131057739258, train/logprobs = tensor([[-10.4408, -10.4515],
        [-10.4143, -10.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.589596887351945e-05
Epoch 0, Step 667: train/loss = 0.6870934367179871, train/raw-loss = 0.6870611906051636, train/logprobs = tensor([[-10.4335, -10.4084],
        [-10.5019, -10.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.434507668018341e-05
Epoch 0, Step 668: train/loss = 0.7026800513267517, train/raw-loss = 0.7026472091674805, train/logprobs = tensor([[-10.3643, -10.3220],
        [-10.4109, -10.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.557688902830705e-05
Epoch 0, Step 669: train/loss = 0.702773928642273, train/raw-loss = 0.7027410268783569, train/logprobs = tensor([[-10.5012, -10.5035],
        [-10.5249, -10.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.561132613569498e-05
Epoch 0, Step 670: train/loss = 0.6711525917053223, train/raw-loss = 0.6711188554763794, train/logprobs = tensor([[-10.3670, -10.4153],
        [-10.5157, -10.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.734622729709372e-05
Epoch 0, Step 671: train/loss = 0.7048525810241699, train/raw-loss = 0.7048192024230957, train/logprobs = tensor([[-10.3756, -10.3907],
        [-10.4085, -10.4348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.678830686723813e-05
Epoch 0, Step 672: train/loss = 0.7058365941047668, train/raw-loss = 0.7058022022247314, train/logprobs = tensor([[-10.4861, -10.3901],
        [-10.5043, -10.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.866877083666623e-05
Epoch 0, Step 673: train/loss = 0.707634449005127, train/raw-loss = 0.7075992822647095, train/logprobs = tensor([[-10.3898, -10.4066],
        [-10.4518, -10.4750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.040779746603221e-05
Epoch 0, Step 674: train/loss = 0.6987791061401367, train/raw-loss = 0.698745846748352, train/logprobs = tensor([[-10.5262, -10.4504],
        [-10.5329, -10.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.66233099764213e-05
Epoch 0, Step 675: train/loss = 0.7063834071159363, train/raw-loss = 0.7063490152359009, train/logprobs = tensor([[-10.4496, -10.4462],
        [-10.5015, -10.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.877671694383025e-05
Epoch 0, Step 676: train/loss = 0.6971732378005981, train/raw-loss = 0.6971389055252075, train/logprobs = tensor([[-10.3749, -10.4730],
        [-10.4215, -10.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.87668434693478e-05
Epoch 0, Step 677: train/loss = 0.6721708178520203, train/raw-loss = 0.6721359491348267, train/logprobs = tensor([[-10.4471, -10.6054],
        [-10.4759, -10.4877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.965085776755586e-05
Epoch 0, Step 678: train/loss = 0.6893630027770996, train/raw-loss = 0.6893284916877747, train/logprobs = tensor([[-10.4403, -10.4590],
        [-10.4943, -10.4549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.910663796588778e-05
Epoch 0, Step 679: train/loss = 0.7066904902458191, train/raw-loss = 0.7066553831100464, train/logprobs = tensor([[-10.4463, -10.3914],
        [-10.5130, -10.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.016341987764463e-05
Epoch 0, Step 680: train/loss = 0.7123066186904907, train/raw-loss = 0.712273359298706, train/logprobs = tensor([[-10.4800, -10.4708],
        [-10.4644, -10.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.640807987423614e-05
Epoch 0, Step 681: train/loss = 0.7027822732925415, train/raw-loss = 0.7027480006217957, train/logprobs = tensor([[-10.4423, -10.4708],
        [-10.4630, -10.4867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.863829185022041e-05
Epoch 0, Step 682: train/loss = 0.7019500136375427, train/raw-loss = 0.7019163370132446, train/logprobs = tensor([[-10.4649, -10.5006],
        [-10.4814, -10.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.726173887727782e-05
Epoch 0, Step 683: train/loss = 0.7183753848075867, train/raw-loss = 0.7183414697647095, train/logprobs = tensor([[-10.4650, -10.3604],
        [-10.4758, -10.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.782443233532831e-05
Epoch 0, Step 684: train/loss = 0.6996697783470154, train/raw-loss = 0.6996356844902039, train/logprobs = tensor([[-10.4116, -10.4862],
        [-10.4981, -10.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.823228613939136e-05
Epoch 0, Step 685: train/loss = 0.6958589553833008, train/raw-loss = 0.6958245038986206, train/logprobs = tensor([[-10.4447, -10.4923],
        [-10.5429, -10.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.883368769194931e-05
Epoch 0, Step 686: train/loss = 0.6942533254623413, train/raw-loss = 0.694220781326294, train/logprobs = tensor([[-10.4883, -10.4937],
        [-10.5220, -10.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.506722274934873e-05
Epoch 0, Step 687: train/loss = 0.6960115432739258, train/raw-loss = 0.6959779262542725, train/logprobs = tensor([[-10.4006, -10.4480],
        [-10.4792, -10.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.730080349370837e-05
Epoch 0, Step 688: train/loss = 0.6993207931518555, train/raw-loss = 0.6992862224578857, train/logprobs = tensor([[-10.4127, -10.4301],
        [-10.4224, -10.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.927554204594344e-05
Epoch 0, Step 689: train/loss = 0.7216278910636902, train/raw-loss = 0.7215943336486816, train/logprobs = tensor([[-10.4240, -10.3245],
        [-10.4470, -10.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.717199721606448e-05
Epoch 0, Step 690: train/loss = 0.7094420790672302, train/raw-loss = 0.7094086408615112, train/logprobs = tensor([[-10.4253, -10.3953],
        [-10.4586, -10.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.680473597953096e-05
Epoch 0, Step 691: train/loss = 0.6973633766174316, train/raw-loss = 0.6973291039466858, train/logprobs = tensor([[-10.4029, -10.3971],
        [-10.4687, -10.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.852072692709044e-05
Epoch 0, Step 692: train/loss = 0.6936885714530945, train/raw-loss = 0.6936535835266113, train/logprobs = tensor([[-10.3924, -10.4370],
        [-10.4350, -10.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.992748967604712e-05
Epoch 0, Step 693: train/loss = 0.7116327285766602, train/raw-loss = 0.7115986347198486, train/logprobs = tensor([[-10.4012, -10.4964],
        [-10.4275, -10.5380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.824413139838725e-05
Epoch 0, Step 694: train/loss = 0.7042547464370728, train/raw-loss = 0.7042206525802612, train/logprobs = tensor([[-10.4284, -10.4461],
        [-10.5060, -10.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.818775727879256e-05
Epoch 0, Step 695: train/loss = 0.6947017908096313, train/raw-loss = 0.6946676969528198, train/logprobs = tensor([[-10.4389, -10.5347],
        [-10.4823, -10.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.814794323872775e-05
Epoch 0, Step 696: train/loss = 0.7221567034721375, train/raw-loss = 0.72212153673172, train/logprobs = tensor([[-10.3736, -10.3736],
        [-10.4124, -10.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.024782826192677e-05
Epoch 0, Step 697: train/loss = 0.6845289468765259, train/raw-loss = 0.6844937801361084, train/logprobs = tensor([[-10.4047, -10.4167],
        [-10.4827, -10.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.03789119143039e-05
Epoch 0, Step 698: train/loss = 0.6922974586486816, train/raw-loss = 0.6922637224197388, train/logprobs = tensor([[-10.4516, -10.4613],
        [-10.4923, -10.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.742870027665049e-05
Epoch 0, Step 699: train/loss = 0.6966185569763184, train/raw-loss = 0.6965850591659546, train/logprobs = tensor([[-10.4585, -10.4308],
        [-10.4818, -10.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.718532677041367e-05
Epoch 0, Step 700: train/loss = 0.6743553280830383, train/raw-loss = 0.6743205189704895, train/logprobs = tensor([[-10.4207, -10.5544],
        [-10.4867, -10.4781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.958488665986806e-05
Epoch 0, Step 701: train/loss = 0.6977298259735107, train/raw-loss = 0.6976957321166992, train/logprobs = tensor([[-10.4267, -10.3564],
        [-10.4737, -10.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.80469602230005e-05
Epoch 0, Step 702: train/loss = 0.7021938562393188, train/raw-loss = 0.7021589875221252, train/logprobs = tensor([[-10.4212, -10.5184],
        [-10.4815, -10.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.981492333579808e-05
Epoch 0, Step 703: train/loss = 0.6943479180335999, train/raw-loss = 0.694314181804657, train/logprobs = tensor([[-10.4792, -10.4864],
        [-10.5328, -10.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.753124034730718e-05
Epoch 0, Step 704: train/loss = 0.681204080581665, train/raw-loss = 0.6811676621437073, train/logprobs = tensor([[-10.4358, -10.3328],
        [-10.5131, -10.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.278686098288745e-05
Epoch 0, Step 705: train/loss = 0.7002331614494324, train/raw-loss = 0.700198233127594, train/logprobs = tensor([[-10.4744, -10.4819],
        [-10.4864, -10.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.994748400757089e-05
Epoch 0, Step 706: train/loss = 0.6874791383743286, train/raw-loss = 0.6874442100524902, train/logprobs = tensor([[-10.4147, -10.5065],
        [-10.4885, -10.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.983730418141931e-05
Epoch 0, Step 707: train/loss = 0.7125929594039917, train/raw-loss = 0.7125567197799683, train/logprobs = tensor([[-10.4497, -10.4294],
        [-10.4702, -10.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.247807661769912e-05
Epoch 0, Step 708: train/loss = 0.6922792196273804, train/raw-loss = 0.6922434568405151, train/logprobs = tensor([[-10.4329, -10.4515],
        [-10.4417, -10.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.140296656871215e-05
Epoch 0, Step 709: train/loss = 0.6721040606498718, train/raw-loss = 0.6720681190490723, train/logprobs = tensor([[-10.4221, -10.5293],
        [-10.4954, -10.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.204468420241028e-05
Epoch 0, Step 710: train/loss = 0.7023904323577881, train/raw-loss = 0.7023544311523438, train/logprobs = tensor([[-10.4689, -10.4834],
        [-10.4889, -10.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.203686982393265e-05
