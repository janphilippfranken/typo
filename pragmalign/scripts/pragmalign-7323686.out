[2024-03-03 13:24:23,089][root][INFO] - beta: 0.25
[2024-03-03 13:24:23,089][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.25-iteration-1-0-5k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 8884
n harmless: 9970
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ"}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.25-iteration-1-0-5k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.25-iteration-1-0-5k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.25-iteration-1-0-5k after each epoch.
5000
5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.25-iteration-1-0-5k after each epoch.
Epoch 0, Step 0: train/loss = 0.6876811981201172, train/raw-loss = 0.6876811981201172, train/logprobs = tensor([[-0.7991, -2.1136],
        [-0.8144, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7017812728881836, train/raw-loss = 0.7017812728881836, train/logprobs = tensor([[-0.8675, -1.3647],
        [-0.9045, -1.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6647472381591797, train/raw-loss = 0.6647472381591797, train/logprobs = tensor([[-0.9712, -1.6776],
        [-1.0482, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6691160798072815, train/raw-loss = 0.6691160798072815, train/logprobs = tensor([[-0.7613, -1.0412],
        [-0.8040, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6818459033966064, train/raw-loss = 0.6818459033966064, train/logprobs = tensor([[-0.7423, -0.8494],
        [-0.8033, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7001824378967285, train/raw-loss = 0.7001824378967285, train/logprobs = tensor([[-0.8634, -1.2522],
        [-0.8944, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6646842360496521, train/raw-loss = 0.6646842360496521, train/logprobs = tensor([[-1.0534, -1.4514],
        [-1.1196, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.692057192325592, train/raw-loss = 0.692057192325592, train/logprobs = tensor([[-1.0745, -1.3111],
        [-1.1357, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6729065179824829, train/raw-loss = 0.6729065179824829, train/logprobs = tensor([[-0.5144, -1.1528],
        [-0.5067, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6754744052886963, train/raw-loss = 0.6754744052886963, train/logprobs = tensor([[-1.0090, -1.1000],
        [-1.0342, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6382375955581665, train/raw-loss = 0.6382375955581665, train/logprobs = tensor([[-1.0358, -1.3086],
        [-1.3042, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6904394626617432, train/raw-loss = 0.6904394626617432, train/logprobs = tensor([[-0.7226, -1.2303],
        [-0.7300, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6897714734077454, train/raw-loss = 0.6897714734077454, train/logprobs = tensor([[-0.9022, -1.2302],
        [-0.9290, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6802294254302979, train/raw-loss = 0.6802294254302979, train/logprobs = tensor([[-0.6706, -1.2400],
        [-0.6935, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6690350770950317, train/raw-loss = 0.6690350770950317, train/logprobs = tensor([[-1.1638, -1.2059],
        [-1.2771, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6677312850952148, train/raw-loss = 0.6677312850952148, train/logprobs = tensor([[-1.2674, -1.3661],
        [-1.3281, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6589983701705933, train/raw-loss = 0.6589983701705933, train/logprobs = tensor([[-0.8304, -1.3320],
        [-0.8951, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6930590867996216, train/raw-loss = 0.6930590867996216, train/logprobs = tensor([[-0.7644, -1.0668],
        [-0.7867, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6523447036743164, train/raw-loss = 0.6523447036743164, train/logprobs = tensor([[-0.9116, -1.1920],
        [-1.0786, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6793126463890076, train/raw-loss = 0.6793126463890076, train/logprobs = tensor([[-0.8504, -1.1314],
        [-0.8680, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6822050213813782, train/raw-loss = 0.6822050213813782, train/logprobs = tensor([[-0.8326, -1.3713],
        [-0.9170, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6489429473876953, train/raw-loss = 0.6489429473876953, train/logprobs = tensor([[-1.3826, -1.5213],
        [-1.5211, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6750220060348511, train/raw-loss = 0.6750220060348511, train/logprobs = tensor([[-0.8851, -0.7172],
        [-0.9591, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6739029288291931, train/raw-loss = 0.6739029288291931, train/logprobs = tensor([[-0.7526, -1.6962],
        [-0.8254, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721904873847961, train/raw-loss = 0.6721904873847961, train/logprobs = tensor([[-0.8545, -1.1816],
        [-0.8767, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6630262732505798, train/raw-loss = 0.6630262732505798, train/logprobs = tensor([[-1.1663, -1.0103],
        [-1.2706, -0.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6829202175140381, train/raw-loss = 0.6829202175140381, train/logprobs = tensor([[-1.0265, -1.0503],
        [-1.0613, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6595985293388367, train/raw-loss = 0.6595985293388367, train/logprobs = tensor([[-1.1463, -1.5332],
        [-1.2361, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6569761633872986, train/raw-loss = 0.6569761633872986, train/logprobs = tensor([[-0.7432, -0.9342],
        [-0.8139, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6692489385604858, train/raw-loss = 0.6692489385604858, train/logprobs = tensor([[-0.8930, -1.2501],
        [-0.9570, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6794319152832031, train/raw-loss = 0.6794319152832031, train/logprobs = tensor([[-0.7914, -1.1187],
        [-0.7899, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.655624508857727, train/raw-loss = 0.655624508857727, train/logprobs = tensor([[-1.5374, -1.5602],
        [-1.6876, -1.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6592499017715454, train/raw-loss = 0.6592499017715454, train/logprobs = tensor([[-0.9855, -1.1981],
        [-1.0750, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6820563077926636, train/raw-loss = 0.6820563077926636, train/logprobs = tensor([[-0.6501, -1.2848],
        [-0.6630, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6683226823806763, train/raw-loss = 0.6683226823806763, train/logprobs = tensor([[-0.9491, -1.3495],
        [-1.0024, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6583713889122009, train/raw-loss = 0.6583713889122009, train/logprobs = tensor([[-0.8106, -1.6709],
        [-0.9243, -1.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6469834446907043, train/raw-loss = 0.6469834446907043, train/logprobs = tensor([[-1.5048, -2.2232],
        [-1.5990, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6797101497650146, train/raw-loss = 0.6797101497650146, train/logprobs = tensor([[-0.6664, -1.6870],
        [-0.6909, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.683232843875885, train/raw-loss = 0.683232843875885, train/logprobs = tensor([[-0.9656, -1.3642],
        [-1.0281, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6942904591560364, train/raw-loss = 0.6942904591560364, train/logprobs = tensor([[-0.4989, -0.9991],
        [-0.5058, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6635227203369141, train/raw-loss = 0.6635227203369141, train/logprobs = tensor([[-0.7571, -1.2971],
        [-0.8222, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6960233449935913, train/raw-loss = 0.6960233449935913, train/logprobs = tensor([[-1.6412, -0.8003],
        [-1.6515, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6716673970222473, train/raw-loss = 0.6716673970222473, train/logprobs = tensor([[-0.9006, -1.8356],
        [-0.9486, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6504718065261841, train/raw-loss = 0.6504718065261841, train/logprobs = tensor([[-1.0048, -1.1417],
        [-1.1579, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6575814485549927, train/raw-loss = 0.6575814485549927, train/logprobs = tensor([[-1.4579, -1.0380],
        [-1.5999, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6726564168930054, train/raw-loss = 0.6726564168930054, train/logprobs = tensor([[-1.2457, -1.0000],
        [-1.3556, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6659195423126221, train/raw-loss = 0.6659195423126221, train/logprobs = tensor([[-1.1039, -1.4521],
        [-1.2564, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6463595628738403, train/raw-loss = 0.6463595628738403, train/logprobs = tensor([[-0.6710, -1.5861],
        [-0.7079, -1.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6638263463973999, train/raw-loss = 0.6638263463973999, train/logprobs = tensor([[-1.2741, -1.4761],
        [-1.3570, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6739931106567383, train/raw-loss = 0.6739931106567383, train/logprobs = tensor([[-0.8710, -1.0174],
        [-0.8790, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678565263748169, train/raw-loss = 0.678565263748169, train/logprobs = tensor([[-1.1486, -0.8595],
        [-1.2491, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6736483573913574, train/raw-loss = 0.6736483573913574, train/logprobs = tensor([[-0.7778, -1.5755],
        [-0.8147, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6805825233459473, train/raw-loss = 0.6805825233459473, train/logprobs = tensor([[-1.3469, -0.9800],
        [-1.4307, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6744076013565063, train/raw-loss = 0.6744076013565063, train/logprobs = tensor([[-0.6959, -1.2708],
        [-0.8213, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6815992593765259, train/raw-loss = 0.6815992593765259, train/logprobs = tensor([[-0.6407, -0.9858],
        [-0.6565, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6931482553482056, train/raw-loss = 0.6931482553482056, train/logprobs = tensor([[-0.8090, -1.1945],
        [-0.8420, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6945903897285461, train/raw-loss = 0.6945903897285461, train/logprobs = tensor([[-0.7038, -1.2251],
        [-0.7267, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6877249479293823, train/raw-loss = 0.6877249479293823, train/logprobs = tensor([[-0.6526, -1.2008],
        [-0.6792, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6316418051719666, train/raw-loss = 0.6316418051719666, train/logprobs = tensor([[-0.8534, -1.8226],
        [-0.8765, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.668732762336731, train/raw-loss = 0.668732762336731, train/logprobs = tensor([[-1.2706, -1.2705],
        [-1.3812, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6924586892127991, train/raw-loss = 0.6924586892127991, train/logprobs = tensor([[-0.6864, -0.6025],
        [-0.6989, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6888662576675415, train/raw-loss = 0.6888662576675415, train/logprobs = tensor([[-0.5987, -0.8959],
        [-0.6033, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6881542801856995, train/raw-loss = 0.6881542801856995, train/logprobs = tensor([[-0.9270, -1.5385],
        [-0.9858, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7003958225250244, train/raw-loss = 0.7003958225250244, train/logprobs = tensor([[-1.1320, -1.5081],
        [-1.1284, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6816005706787109, train/raw-loss = 0.6795791387557983, train/logprobs = tensor([[-0.6322, -3.4812],
        [-0.6539, -3.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008085565641522408
Epoch 0, Step 65: train/loss = 0.6487197875976562, train/raw-loss = 0.6460999846458435, train/logprobs = tensor([[-1.0033, -1.0848],
        [-1.1960, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010479437187314034
Epoch 0, Step 66: train/loss = 0.688639760017395, train/raw-loss = 0.6870537996292114, train/logprobs = tensor([[-0.5665, -0.8119],
        [-0.5651, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006343659944832325
Epoch 0, Step 67: train/loss = 0.690392792224884, train/raw-loss = 0.688511312007904, train/logprobs = tensor([[-0.5676, -0.9045],
        [-0.5635, -0.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00752591248601675
Epoch 0, Step 68: train/loss = 0.684348464012146, train/raw-loss = 0.681691586971283, train/logprobs = tensor([[-0.9410, -1.6307],
        [-0.9767, -1.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010627709329128265
Epoch 0, Step 69: train/loss = 0.6702008247375488, train/raw-loss = 0.6679243445396423, train/logprobs = tensor([[-0.7893, -1.3110],
        [-0.9547, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009105991572141647
Epoch 0, Step 70: train/loss = 0.6861444115638733, train/raw-loss = 0.6845283508300781, train/logprobs = tensor([[-0.5663, -1.9122],
        [-0.5650, -1.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006464350037276745
Epoch 0, Step 71: train/loss = 0.6646614670753479, train/raw-loss = 0.6623131036758423, train/logprobs = tensor([[-1.0318, -1.6711],
        [-1.1517, -1.6601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00939357653260231
Epoch 0, Step 72: train/loss = 0.6891303062438965, train/raw-loss = 0.6866156458854675, train/logprobs = tensor([[-1.5055, -1.9898],
        [-1.6045, -2.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010058626532554626
Epoch 0, Step 73: train/loss = 0.6693309545516968, train/raw-loss = 0.6664006114006042, train/logprobs = tensor([[-1.0837, -1.2707],
        [-1.1841, -1.2608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01172129437327385
Epoch 0, Step 74: train/loss = 0.6432929039001465, train/raw-loss = 0.6410127878189087, train/logprobs = tensor([[-1.2335, -0.7103],
        [-1.4360, -0.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009120505303144455
Epoch 0, Step 75: train/loss = 0.6918115615844727, train/raw-loss = 0.6898958086967468, train/logprobs = tensor([[-0.8092, -1.3693],
        [-0.8427, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007663005031645298
Epoch 0, Step 76: train/loss = 0.678427517414093, train/raw-loss = 0.6763393878936768, train/logprobs = tensor([[-0.6312, -0.6420],
        [-0.7054, -0.6457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00835239514708519
Epoch 0, Step 77: train/loss = 0.6533231139183044, train/raw-loss = 0.6504457592964172, train/logprobs = tensor([[-1.1897, -1.2245],
        [-1.3681, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01150948740541935
Epoch 0, Step 78: train/loss = 0.6539241075515747, train/raw-loss = 0.6513276696205139, train/logprobs = tensor([[-1.1933, -0.9398],
        [-1.3817, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010385734029114246
Epoch 0, Step 79: train/loss = 0.6731741428375244, train/raw-loss = 0.67044997215271, train/logprobs = tensor([[-0.7570, -0.9274],
        [-0.8546, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010896645486354828
Epoch 0, Step 80: train/loss = 0.6809059381484985, train/raw-loss = 0.6783917546272278, train/logprobs = tensor([[-0.7959, -1.0186],
        [-0.8152, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01005710382014513
Epoch 0, Step 81: train/loss = 0.6679232716560364, train/raw-loss = 0.6657912135124207, train/logprobs = tensor([[-1.1338, -1.0179],
        [-1.2264, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008528153412044048
Epoch 0, Step 82: train/loss = 0.6337733268737793, train/raw-loss = 0.6309924125671387, train/logprobs = tensor([[-1.1023, -1.2750],
        [-1.3443, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01112370379269123
Epoch 0, Step 83: train/loss = 0.6718388199806213, train/raw-loss = 0.6701382994651794, train/logprobs = tensor([[-0.9784, -1.2716],
        [-1.0854, -1.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00680215610191226
Epoch 0, Step 84: train/loss = 0.6718336343765259, train/raw-loss = 0.6696723103523254, train/logprobs = tensor([[-0.4952, -1.1860],
        [-0.5225, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00864519365131855
Epoch 0, Step 85: train/loss = 0.6578866839408875, train/raw-loss = 0.655397355556488, train/logprobs = tensor([[-0.9082, -1.0824],
        [-1.1097, -1.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009957414120435715
Epoch 0, Step 86: train/loss = 0.6797235608100891, train/raw-loss = 0.6772476434707642, train/logprobs = tensor([[-0.6969, -1.1664],
        [-0.7105, -1.1152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00990368239581585
Epoch 0, Step 87: train/loss = 0.6516997814178467, train/raw-loss = 0.6485377550125122, train/logprobs = tensor([[-0.8649, -1.6720],
        [-1.0237, -1.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012648297473788261
Epoch 0, Step 88: train/loss = 0.6873009204864502, train/raw-loss = 0.685417652130127, train/logprobs = tensor([[-0.5440, -1.5445],
        [-0.5523, -1.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007533366791903973
Epoch 0, Step 89: train/loss = 0.699533224105835, train/raw-loss = 0.6976766586303711, train/logprobs = tensor([[-0.7866, -1.1935],
        [-0.8706, -1.2901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00742595549672842
Epoch 0, Step 90: train/loss = 0.6714726686477661, train/raw-loss = 0.668756902217865, train/logprobs = tensor([[-0.7995, -1.1435],
        [-0.8730, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010863213799893856
Epoch 0, Step 91: train/loss = 0.6259863972663879, train/raw-loss = 0.6235703229904175, train/logprobs = tensor([[-1.0777, -1.5397],
        [-1.1460, -1.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00966428779065609
Epoch 0, Step 92: train/loss = 0.6817878484725952, train/raw-loss = 0.6792678833007812, train/logprobs = tensor([[-1.0608, -1.0585],
        [-1.0812, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010079724714159966
Epoch 0, Step 93: train/loss = 0.6670234799385071, train/raw-loss = 0.6643627882003784, train/logprobs = tensor([[-1.1975, -1.3219],
        [-1.3254, -1.3245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010642499662935734
Epoch 0, Step 94: train/loss = 0.6731702089309692, train/raw-loss = 0.6705591678619385, train/logprobs = tensor([[-0.9945, -1.1211],
        [-1.0632, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01044396124780178
Epoch 0, Step 95: train/loss = 0.6748809218406677, train/raw-loss = 0.6722639799118042, train/logprobs = tensor([[-0.8262, -1.0007],
        [-0.9098, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010467808693647385
Epoch 0, Step 96: train/loss = 0.6564899682998657, train/raw-loss = 0.6483936309814453, train/logprobs = tensor([[-0.9052, -1.0045],
        [-1.0146, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03238523751497269
Epoch 0, Step 97: train/loss = 0.6324813961982727, train/raw-loss = 0.6252695322036743, train/logprobs = tensor([[-0.8360, -1.9279],
        [-0.9941, -1.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02884775586426258
Epoch 0, Step 98: train/loss = 0.6746312975883484, train/raw-loss = 0.6675851941108704, train/logprobs = tensor([[-0.8263, -1.3960],
        [-0.9649, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028184305876493454
Epoch 0, Step 99: train/loss = 0.6620992422103882, train/raw-loss = 0.6541171073913574, train/logprobs = tensor([[-0.9105, -1.7095],
        [-1.0137, -1.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03192853555083275
Epoch 0, Step 100: train/loss = 0.6367030143737793, train/raw-loss = 0.6263111233711243, train/logprobs = tensor([[-1.2891, -1.4116],
        [-1.6407, -1.4659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04156763106584549
Epoch 0, Step 101: train/loss = 0.6731115579605103, train/raw-loss = 0.6648629903793335, train/logprobs = tensor([[-0.9963, -1.4595],
        [-1.1662, -1.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299420699477196
Epoch 0, Step 102: train/loss = 0.6788960695266724, train/raw-loss = 0.6735857725143433, train/logprobs = tensor([[-0.5347, -1.3263],
        [-0.5479, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021241066977381706
Epoch 0, Step 103: train/loss = 0.6718803644180298, train/raw-loss = 0.6637833714485168, train/logprobs = tensor([[-1.0442, -1.2462],
        [-1.1593, -1.2392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03238783776760101
Epoch 0, Step 104: train/loss = 0.652446448802948, train/raw-loss = 0.6427327990531921, train/logprobs = tensor([[-0.9235, -1.3348],
        [-1.0595, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038854632526636124
Epoch 0, Step 105: train/loss = 0.6134733557701111, train/raw-loss = 0.6048593521118164, train/logprobs = tensor([[-1.4884, -1.9890],
        [-1.8279, -1.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034455955028533936
Epoch 0, Step 106: train/loss = 0.6867585778236389, train/raw-loss = 0.6801405549049377, train/logprobs = tensor([[-0.7233, -1.4524],
        [-0.7183, -1.3943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0264721792191267
Epoch 0, Step 107: train/loss = 0.6556152105331421, train/raw-loss = 0.6460442543029785, train/logprobs = tensor([[-1.5534, -1.8224],
        [-1.7800, -1.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03828391060233116
Epoch 0, Step 108: train/loss = 0.6666505336761475, train/raw-loss = 0.6591281294822693, train/logprobs = tensor([[-1.3339, -2.5849],
        [-1.4384, -2.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030089668929576874
Epoch 0, Step 109: train/loss = 0.682645320892334, train/raw-loss = 0.6767535209655762, train/logprobs = tensor([[-0.5487, -1.2110],
        [-0.5631, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023567281663417816
Epoch 0, Step 110: train/loss = 0.6837725043296814, train/raw-loss = 0.6773543357849121, train/logprobs = tensor([[-0.9360, -1.6148],
        [-1.0009, -1.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025672754272818565
Epoch 0, Step 111: train/loss = 0.6658787727355957, train/raw-loss = 0.657837986946106, train/logprobs = tensor([[-1.1945, -1.1620],
        [-1.3815, -1.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03216320276260376
Epoch 0, Step 112: train/loss = 0.6458691358566284, train/raw-loss = 0.6381806135177612, train/logprobs = tensor([[-1.5495, -1.8648],
        [-1.7846, -1.8633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030753804370760918
Epoch 0, Step 113: train/loss = 0.6488145589828491, train/raw-loss = 0.639857292175293, train/logprobs = tensor([[-1.2875, -1.4283],
        [-1.5539, -1.4641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03582918643951416
Epoch 0, Step 114: train/loss = 0.6289278268814087, train/raw-loss = 0.6199462413787842, train/logprobs = tensor([[-1.1100, -1.5528],
        [-1.3369, -1.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03592658415436745
Epoch 0, Step 115: train/loss = 0.6733213067054749, train/raw-loss = 0.6664801836013794, train/logprobs = tensor([[-0.9077, -1.5194],
        [-1.0222, -1.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027364719659090042
Epoch 0, Step 116: train/loss = 0.6874701380729675, train/raw-loss = 0.6821715235710144, train/logprobs = tensor([[-0.5252, -0.9154],
        [-0.5481, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021194322034716606
Epoch 0, Step 117: train/loss = 0.6868171095848083, train/raw-loss = 0.6791865229606628, train/logprobs = tensor([[-1.0538, -1.1185],
        [-1.1863, -1.1864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03052215836942196
Epoch 0, Step 118: train/loss = 0.6492312550544739, train/raw-loss = 0.6408507227897644, train/logprobs = tensor([[-0.7829, -0.9828],
        [-0.9523, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033521998673677444
Epoch 0, Step 119: train/loss = 0.6011064052581787, train/raw-loss = 0.5902515053749084, train/logprobs = tensor([[-1.1371, -1.6758],
        [-1.4868, -1.5820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04341974854469299
Epoch 0, Step 120: train/loss = 0.6118619441986084, train/raw-loss = 0.6038298606872559, train/logprobs = tensor([[-1.0879, -1.9495],
        [-1.2886, -1.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032128363847732544
Epoch 0, Step 121: train/loss = 0.6816752552986145, train/raw-loss = 0.6751118898391724, train/logprobs = tensor([[-0.7069, -0.9943],
        [-0.7639, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02625356614589691
Epoch 0, Step 122: train/loss = 0.6873684525489807, train/raw-loss = 0.6809847354888916, train/logprobs = tensor([[-0.7147, -1.0921],
        [-0.7585, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025534946471452713
Epoch 0, Step 123: train/loss = 0.6181039214134216, train/raw-loss = 0.6101213693618774, train/logprobs = tensor([[-1.2535, -1.6765],
        [-1.4189, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031930405646562576
Epoch 0, Step 124: train/loss = 0.6870101690292358, train/raw-loss = 0.6815574169158936, train/logprobs = tensor([[-0.7580, -0.8129],
        [-0.8010, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021810676902532578
Epoch 0, Step 125: train/loss = 0.6835524439811707, train/raw-loss = 0.6765397787094116, train/logprobs = tensor([[-0.6156, -1.0767],
        [-0.6311, -1.0246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02805047109723091
Epoch 0, Step 126: train/loss = 0.6595349907875061, train/raw-loss = 0.6505837440490723, train/logprobs = tensor([[-1.0927, -1.2166],
        [-1.2484, -1.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035805024206638336
Epoch 0, Step 127: train/loss = 0.6599716544151306, train/raw-loss = 0.6510088443756104, train/logprobs = tensor([[-0.9198, -1.1605],
        [-1.0328, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035851266235113144
Epoch 0, Step 128: train/loss = 0.6792484521865845, train/raw-loss = 0.6688764691352844, train/logprobs = tensor([[-0.8578, -1.2146],
        [-0.9545, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04148776829242706
Epoch 0, Step 129: train/loss = 0.6199642419815063, train/raw-loss = 0.606598973274231, train/logprobs = tensor([[-0.9120, -1.4189],
        [-1.0746, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053461287170648575
Epoch 0, Step 130: train/loss = 0.6546749472618103, train/raw-loss = 0.646242618560791, train/logprobs = tensor([[-0.7670, -0.8357],
        [-0.9383, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03372955322265625
Epoch 0, Step 131: train/loss = 0.636813223361969, train/raw-loss = 0.621378481388092, train/logprobs = tensor([[-0.8133, -1.0977],
        [-1.2031, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061739131808280945
Epoch 0, Step 132: train/loss = 0.6458477973937988, train/raw-loss = 0.6339566111564636, train/logprobs = tensor([[-0.9752, -1.2057],
        [-1.0956, -1.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047564972192049026
Epoch 0, Step 133: train/loss = 0.5607447028160095, train/raw-loss = 0.5472475290298462, train/logprobs = tensor([[-0.9739, -2.4616],
        [-1.4178, -2.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05398865044116974
Epoch 0, Step 134: train/loss = 0.6729212999343872, train/raw-loss = 0.6619617938995361, train/logprobs = tensor([[-0.8408, -1.0043],
        [-0.9515, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043837837874889374
Epoch 0, Step 135: train/loss = 0.6201995611190796, train/raw-loss = 0.6045042276382446, train/logprobs = tensor([[-1.3724, -1.7362],
        [-1.8403, -1.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278148293495178
Epoch 0, Step 136: train/loss = 0.6678557395935059, train/raw-loss = 0.6572891473770142, train/logprobs = tensor([[-0.5591, -0.9218],
        [-0.6341, -0.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04226651415228844
Epoch 0, Step 137: train/loss = 0.6028422713279724, train/raw-loss = 0.5869001746177673, train/logprobs = tensor([[-1.0585, -1.3301],
        [-1.4864, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06376837939023972
Epoch 0, Step 138: train/loss = 0.6544321775436401, train/raw-loss = 0.6438362002372742, train/logprobs = tensor([[-0.7656, -0.9089],
        [-1.0011, -0.9170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04238424450159073
Epoch 0, Step 139: train/loss = 0.6275874376296997, train/raw-loss = 0.616412878036499, train/logprobs = tensor([[-0.7925, -1.0101],
        [-1.0097, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0446983240544796
Epoch 0, Step 140: train/loss = 0.6432093381881714, train/raw-loss = 0.6315777897834778, train/logprobs = tensor([[-0.9310, -1.8556],
        [-1.0944, -1.7394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04652632027864456
Epoch 0, Step 141: train/loss = 0.7086939215660095, train/raw-loss = 0.6985970735549927, train/logprobs = tensor([[-1.1410, -1.4307],
        [-1.1172, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040387365967035294
Epoch 0, Step 142: train/loss = 0.5963307619094849, train/raw-loss = 0.5835471749305725, train/logprobs = tensor([[-1.1260, -1.1121],
        [-1.5698, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05113449692726135
Epoch 0, Step 143: train/loss = 0.6042145490646362, train/raw-loss = 0.59138023853302, train/logprobs = tensor([[-0.9557, -0.8525],
        [-1.4440, -0.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051337528973817825
Epoch 0, Step 144: train/loss = 0.645405113697052, train/raw-loss = 0.6340598464012146, train/logprobs = tensor([[-1.3156, -1.4393],
        [-1.5124, -1.3805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04538126662373543
Epoch 0, Step 145: train/loss = 0.5803275108337402, train/raw-loss = 0.5670479536056519, train/logprobs = tensor([[-0.7961, -2.0679],
        [-1.2441, -1.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05311837047338486
Epoch 0, Step 146: train/loss = 0.6119747161865234, train/raw-loss = 0.6003254652023315, train/logprobs = tensor([[-0.8995, -0.9010],
        [-1.3642, -0.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04659712314605713
Epoch 0, Step 147: train/loss = 0.6069812774658203, train/raw-loss = 0.5927355885505676, train/logprobs = tensor([[-0.8933, -1.7935],
        [-1.2382, -1.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05698268860578537
Epoch 0, Step 148: train/loss = 0.636385440826416, train/raw-loss = 0.6255848407745361, train/logprobs = tensor([[-1.2032, -1.3769],
        [-1.5164, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04320240393280983
Epoch 0, Step 149: train/loss = 0.6254684329032898, train/raw-loss = 0.6140760779380798, train/logprobs = tensor([[-0.7492, -0.6888],
        [-1.0430, -0.6248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04556935280561447
Epoch 0, Step 150: train/loss = 0.6118542551994324, train/raw-loss = 0.5980320572853088, train/logprobs = tensor([[-0.7687, -1.4580],
        [-1.0430, -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05528882518410683
Epoch 0, Step 151: train/loss = 0.5927164554595947, train/raw-loss = 0.5792721509933472, train/logprobs = tensor([[-0.9581, -1.5964],
        [-1.3540, -1.4293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05377737805247307
Epoch 0, Step 152: train/loss = 0.6151454448699951, train/raw-loss = 0.602450966835022, train/logprobs = tensor([[-1.1991, -1.1710],
        [-1.4323, -1.0012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05077803134918213
Epoch 0, Step 153: train/loss = 0.6156449913978577, train/raw-loss = 0.6002826690673828, train/logprobs = tensor([[-1.2205, -1.6863],
        [-1.7430, -1.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061449289321899414
Epoch 0, Step 154: train/loss = 0.5895397067070007, train/raw-loss = 0.5753612518310547, train/logprobs = tensor([[-0.9819, -1.1018],
        [-1.4101, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056713931262493134
Epoch 0, Step 155: train/loss = 0.6237496733665466, train/raw-loss = 0.6119526028633118, train/logprobs = tensor([[-1.0426, -1.4313],
        [-1.2155, -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04718823730945587
Epoch 0, Step 156: train/loss = 0.6560754776000977, train/raw-loss = 0.6445611715316772, train/logprobs = tensor([[-0.5674, -1.2153],
        [-0.6630, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04605727642774582
Epoch 0, Step 157: train/loss = 0.6830514669418335, train/raw-loss = 0.6730895042419434, train/logprobs = tensor([[-0.7764, -1.0274],
        [-0.8658, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039848145097494125
Epoch 0, Step 158: train/loss = 0.6456096172332764, train/raw-loss = 0.636925220489502, train/logprobs = tensor([[-1.3862, -1.0372],
        [-1.5517, -0.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03473735600709915
Epoch 0, Step 159: train/loss = 0.6415600776672363, train/raw-loss = 0.6296586990356445, train/logprobs = tensor([[-0.8675, -1.0903],
        [-1.1057, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04760561138391495
Epoch 0, Step 160: train/loss = 0.6742722988128662, train/raw-loss = 0.6649110913276672, train/logprobs = tensor([[-0.5737, -1.5538],
        [-0.6129, -1.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03744493052363396
Epoch 0, Step 161: train/loss = 0.6011214852333069, train/raw-loss = 0.5863109827041626, train/logprobs = tensor([[-1.2110, -1.2880],
        [-1.5359, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05924178659915924
Epoch 0, Step 162: train/loss = 0.6714671850204468, train/raw-loss = 0.6629331111907959, train/logprobs = tensor([[-0.6325, -1.0587],
        [-0.6500, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034136153757572174
Epoch 0, Step 163: train/loss = 0.6380503177642822, train/raw-loss = 0.6214602589607239, train/logprobs = tensor([[-0.9535, -0.9779],
        [-1.3737, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06636045128107071
Epoch 0, Step 164: train/loss = 0.7165117263793945, train/raw-loss = 0.7010496854782104, train/logprobs = tensor([[-0.9735, -1.1571],
        [-0.9885, -1.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06184813752770424
Epoch 0, Step 165: train/loss = 0.6722269654273987, train/raw-loss = 0.6577025651931763, train/logprobs = tensor([[-0.8474, -1.4384],
        [-0.9572, -1.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05809744447469711
Epoch 0, Step 166: train/loss = 0.6234471797943115, train/raw-loss = 0.6114804744720459, train/logprobs = tensor([[-0.8931, -1.4183],
        [-1.0221, -1.1860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04786669462919235
Epoch 0, Step 167: train/loss = 0.5888747572898865, train/raw-loss = 0.5728470087051392, train/logprobs = tensor([[-0.7249, -1.8138],
        [-0.9426, -1.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0641108974814415
Epoch 0, Step 168: train/loss = 0.5683260560035706, train/raw-loss = 0.5542922019958496, train/logprobs = tensor([[-1.0636, -0.8257],
        [-1.6499, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05613548681139946
Epoch 0, Step 169: train/loss = 0.5732173919677734, train/raw-loss = 0.5604006052017212, train/logprobs = tensor([[-1.0500, -0.8403],
        [-1.4829, -0.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05126732960343361
Epoch 0, Step 170: train/loss = 0.6628019213676453, train/raw-loss = 0.6524533629417419, train/logprobs = tensor([[-0.8834, -1.0732],
        [-0.9301, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04139423742890358
Epoch 0, Step 171: train/loss = 0.5601858496665955, train/raw-loss = 0.541804313659668, train/logprobs = tensor([[-0.7696, -1.1633],
        [-1.2942, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07352611422538757
Epoch 0, Step 172: train/loss = 0.6007388830184937, train/raw-loss = 0.5880727171897888, train/logprobs = tensor([[-0.8660, -1.1431],
        [-1.1659, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05066496506333351
Epoch 0, Step 173: train/loss = 0.5296003818511963, train/raw-loss = 0.5136033892631531, train/logprobs = tensor([[-1.4371, -2.0394],
        [-1.9421, -1.6998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06398779153823853
Epoch 0, Step 174: train/loss = 0.6244698166847229, train/raw-loss = 0.6114444732666016, train/logprobs = tensor([[-0.7792, -1.1721],
        [-0.9392, -0.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052101440727710724
Epoch 0, Step 175: train/loss = 0.5621283054351807, train/raw-loss = 0.5454951524734497, train/logprobs = tensor([[-1.0192, -1.9319],
        [-1.5179, -1.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06653252243995667
Epoch 0, Step 176: train/loss = 0.6492409110069275, train/raw-loss = 0.6389694809913635, train/logprobs = tensor([[-0.8516, -2.1716],
        [-0.9370, -2.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04108563810586929
Epoch 0, Step 177: train/loss = 0.6727553606033325, train/raw-loss = 0.6596763730049133, train/logprobs = tensor([[-0.8194, -1.4247],
        [-0.8783, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05231589823961258
Epoch 0, Step 178: train/loss = 0.6785662174224854, train/raw-loss = 0.6656776666641235, train/logprobs = tensor([[-1.1323, -1.5313],
        [-1.2902, -1.5727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051554370671510696
Epoch 0, Step 179: train/loss = 0.5691899061203003, train/raw-loss = 0.549922525882721, train/logprobs = tensor([[-1.2374, -2.2475],
        [-1.7229, -2.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07706940919160843
Epoch 0, Step 180: train/loss = 0.5813989639282227, train/raw-loss = 0.5685213208198547, train/logprobs = tensor([[-0.7501, -1.0940],
        [-1.1321, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05151042342185974
Epoch 0, Step 181: train/loss = 0.6852144598960876, train/raw-loss = 0.6716998219490051, train/logprobs = tensor([[-1.0786, -1.3472],
        [-1.0432, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05405868962407112
Epoch 0, Step 182: train/loss = 0.6884497404098511, train/raw-loss = 0.6741653680801392, train/logprobs = tensor([[-2.0442, -2.2044],
        [-2.1110, -2.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057137295603752136
Epoch 0, Step 183: train/loss = 0.614713191986084, train/raw-loss = 0.6021519899368286, train/logprobs = tensor([[-0.7632, -0.8214],
        [-1.1188, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0502447634935379
Epoch 0, Step 184: train/loss = 0.6214092969894409, train/raw-loss = 0.6075454950332642, train/logprobs = tensor([[-0.9291, -1.3620],
        [-1.1962, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055454932153224945
Epoch 0, Step 185: train/loss = 0.608332633972168, train/raw-loss = 0.5960160493850708, train/logprobs = tensor([[-1.0155, -1.3412],
        [-1.3197, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049266520887613297
Epoch 0, Step 186: train/loss = 0.6936352849006653, train/raw-loss = 0.6842517852783203, train/logprobs = tensor([[-0.6277, -1.3490],
        [-0.6271, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03753411024808884
Epoch 0, Step 187: train/loss = 0.6202129125595093, train/raw-loss = 0.6074802279472351, train/logprobs = tensor([[-0.9188, -0.9875],
        [-1.1636, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05093085765838623
Epoch 0, Step 188: train/loss = 0.6577017307281494, train/raw-loss = 0.6411588191986084, train/logprobs = tensor([[-1.1242, -1.0473],
        [-1.3643, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06617157906293869
Epoch 0, Step 189: train/loss = 0.6632505655288696, train/raw-loss = 0.6515582799911499, train/logprobs = tensor([[-0.6863, -1.1553],
        [-0.7196, -1.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04676935076713562
Epoch 0, Step 190: train/loss = 0.6005780696868896, train/raw-loss = 0.5887545347213745, train/logprobs = tensor([[-0.6740, -1.5546],
        [-0.9490, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04729394614696503
Epoch 0, Step 191: train/loss = 0.5697424411773682, train/raw-loss = 0.5565508008003235, train/logprobs = tensor([[-0.8137, -1.9077],
        [-1.1101, -1.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05276656895875931
Epoch 0, Step 192: train/loss = 0.6296794414520264, train/raw-loss = 0.6048395037651062, train/logprobs = tensor([[-1.0018, -2.7655],
        [-1.1564, -2.3692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09936001896858215
Epoch 0, Step 193: train/loss = 0.5827324986457825, train/raw-loss = 0.5557760000228882, train/logprobs = tensor([[-0.8148, -1.6370],
        [-0.8276, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10782589018344879
Epoch 0, Step 194: train/loss = 0.6615384221076965, train/raw-loss = 0.6411486268043518, train/logprobs = tensor([[-0.9614, -1.0613],
        [-1.0230, -0.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08155924081802368
Epoch 0, Step 195: train/loss = 0.666090726852417, train/raw-loss = 0.6453108787536621, train/logprobs = tensor([[-0.6081, -1.3086],
        [-0.6399, -1.1361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08311939239501953
Epoch 0, Step 196: train/loss = 0.6272087097167969, train/raw-loss = 0.6068552136421204, train/logprobs = tensor([[-0.6286, -1.2172],
        [-0.7514, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08141404390335083
Epoch 0, Step 197: train/loss = 0.5653199553489685, train/raw-loss = 0.5364043712615967, train/logprobs = tensor([[-0.7051, -1.9118],
        [-1.0444, -1.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11566231399774551
Epoch 0, Step 198: train/loss = 0.48972684144973755, train/raw-loss = 0.4561379551887512, train/logprobs = tensor([[-0.9045, -1.9808],
        [-1.4584, -1.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13435551524162292
Epoch 0, Step 199: train/loss = 0.5460297465324402, train/raw-loss = 0.5166422724723816, train/logprobs = tensor([[-1.0027, -1.6445],
        [-1.6194, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754991859197617
Epoch 0, Step 200: train/loss = 0.5540531873703003, train/raw-loss = 0.5221657752990723, train/logprobs = tensor([[-0.8451, -1.1441],
        [-1.4091, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12754954397678375
Epoch 0, Step 201: train/loss = 0.4997715353965759, train/raw-loss = 0.47113001346588135, train/logprobs = tensor([[-0.8488, -3.0614],
        [-1.0699, -1.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456611752510071
Epoch 0, Step 202: train/loss = 0.649228036403656, train/raw-loss = 0.628455638885498, train/logprobs = tensor([[-0.5968, -0.8154],
        [-0.7301, -0.6435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08308983594179153
Epoch 0, Step 203: train/loss = 0.5330255031585693, train/raw-loss = 0.5061654448509216, train/logprobs = tensor([[-1.0168, -1.6905],
        [-1.6280, -1.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074400395154953
Epoch 0, Step 204: train/loss = 0.4706791341304779, train/raw-loss = 0.43808409571647644, train/logprobs = tensor([[-1.0827, -1.5823],
        [-2.0829, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13038010895252228
Epoch 0, Step 205: train/loss = 0.6608099937438965, train/raw-loss = 0.63703453540802, train/logprobs = tensor([[-0.8092, -1.2708],
        [-0.8062, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09510185569524765
Epoch 0, Step 206: train/loss = 0.6551856994628906, train/raw-loss = 0.635809063911438, train/logprobs = tensor([[-0.8685, -1.2330],
        [-0.8599, -0.9742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07750637084245682
Epoch 0, Step 207: train/loss = 0.4765094220638275, train/raw-loss = 0.448883593082428, train/logprobs = tensor([[-0.8601, -3.0252],
        [-1.1931, -1.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050331592559814
Epoch 0, Step 208: train/loss = 0.5264804363250732, train/raw-loss = 0.492526650428772, train/logprobs = tensor([[-0.8918, -1.4618],
        [-1.5360, -1.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13581517338752747
Epoch 0, Step 209: train/loss = 0.5648181438446045, train/raw-loss = 0.5364295840263367, train/logprobs = tensor([[-0.9377, -1.4207],
        [-1.4067, -1.1334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11355425417423248
Epoch 0, Step 210: train/loss = 0.5693614482879639, train/raw-loss = 0.5365607738494873, train/logprobs = tensor([[-1.0772, -2.0821],
        [-1.3836, -1.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13120286166667938
Epoch 0, Step 211: train/loss = 0.5359118580818176, train/raw-loss = 0.507095456123352, train/logprobs = tensor([[-1.0448, -2.8312],
        [-1.3629, -2.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11526563763618469
Epoch 0, Step 212: train/loss = 0.6845106482505798, train/raw-loss = 0.6516865491867065, train/logprobs = tensor([[-0.6768, -1.3586],
        [-1.0539, -1.3729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1312965601682663
Epoch 0, Step 213: train/loss = 0.5490522384643555, train/raw-loss = 0.5193701982498169, train/logprobs = tensor([[-0.9499, -2.3177],
        [-1.4824, -1.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872819811105728
Epoch 0, Step 214: train/loss = 0.6010841131210327, train/raw-loss = 0.5729559063911438, train/logprobs = tensor([[-0.9259, -2.4025],
        [-1.0890, -1.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1125127375125885
Epoch 0, Step 215: train/loss = 0.63196861743927, train/raw-loss = 0.6065456867218018, train/logprobs = tensor([[-0.9408, -1.3034],
        [-1.1622, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10169145464897156
Epoch 0, Step 216: train/loss = 0.5332450866699219, train/raw-loss = 0.5007209777832031, train/logprobs = tensor([[-0.8484, -1.9688],
        [-0.9945, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13009651005268097
Epoch 0, Step 217: train/loss = 0.6226621270179749, train/raw-loss = 0.598188042640686, train/logprobs = tensor([[-0.7040, -1.4205],
        [-0.8788, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09789615124464035
Epoch 0, Step 218: train/loss = 0.5914695262908936, train/raw-loss = 0.5657445192337036, train/logprobs = tensor([[-0.9672, -0.9377],
        [-1.4474, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10290004312992096
Epoch 0, Step 219: train/loss = 0.611551821231842, train/raw-loss = 0.5880917906761169, train/logprobs = tensor([[-1.1757, -1.4422],
        [-1.6515, -1.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09384012967348099
Epoch 0, Step 220: train/loss = 0.6638785600662231, train/raw-loss = 0.6352401971817017, train/logprobs = tensor([[-1.0116, -1.5996],
        [-1.0945, -1.3676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11455336213111877
Epoch 0, Step 221: train/loss = 0.6138651371002197, train/raw-loss = 0.5915035605430603, train/logprobs = tensor([[-0.6831, -0.7271],
        [-1.1153, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894463062286377
Epoch 0, Step 222: train/loss = 0.5933175683021545, train/raw-loss = 0.5620052814483643, train/logprobs = tensor([[-1.5616, -1.6916],
        [-2.2076, -1.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12524940073490143
Epoch 0, Step 223: train/loss = 0.48480600118637085, train/raw-loss = 0.45209813117980957, train/logprobs = tensor([[-0.8655, -2.6824],
        [-1.3709, -1.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13083145022392273
Epoch 0, Step 224: train/loss = 0.4438683092594147, train/raw-loss = 0.40500718355178833, train/logprobs = tensor([[-0.9404, -2.3484],
        [-1.6374, -1.4772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15544439852237701
Epoch 0, Step 225: train/loss = 0.613961935043335, train/raw-loss = 0.5783852934837341, train/logprobs = tensor([[-0.7341, -2.0510],
        [-0.7454, -1.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14230646193027496
Epoch 0, Step 226: train/loss = 0.5817757844924927, train/raw-loss = 0.547289252281189, train/logprobs = tensor([[-0.7624, -1.3440],
        [-0.8331, -0.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379462033510208
Epoch 0, Step 227: train/loss = 0.42285796999931335, train/raw-loss = 0.38794606924057007, train/logprobs = tensor([[-1.4729, -2.5434],
        [-2.4944, -1.6880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396474689245224
Epoch 0, Step 228: train/loss = 0.5516446828842163, train/raw-loss = 0.5119800567626953, train/logprobs = tensor([[-0.9491, -1.7884],
        [-1.2856, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15865829586982727
Epoch 0, Step 229: train/loss = 0.5238124132156372, train/raw-loss = 0.4871958792209625, train/logprobs = tensor([[-0.8812, -1.6171],
        [-1.3701, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14646615087985992
Epoch 0, Step 230: train/loss = 0.5909939408302307, train/raw-loss = 0.5547266602516174, train/logprobs = tensor([[-0.7402, -1.5434],
        [-0.8581, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1450689285993576
Epoch 0, Step 231: train/loss = 0.6390652060508728, train/raw-loss = 0.6021686792373657, train/logprobs = tensor([[-0.8751, -1.3169],
        [-0.8121, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14758595824241638
Epoch 0, Step 232: train/loss = 0.4977523684501648, train/raw-loss = 0.466825008392334, train/logprobs = tensor([[-0.7158, -1.9741],
        [-1.1523, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12370940297842026
Epoch 0, Step 233: train/loss = 0.528894305229187, train/raw-loss = 0.494485467672348, train/logprobs = tensor([[-0.8827, -1.5087],
        [-1.6096, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13763529062271118
Epoch 0, Step 234: train/loss = 0.560593843460083, train/raw-loss = 0.5285664796829224, train/logprobs = tensor([[-0.8185, -1.5402],
        [-1.2540, -1.0453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12810947000980377
Epoch 0, Step 235: train/loss = 0.5864512920379639, train/raw-loss = 0.5614116191864014, train/logprobs = tensor([[-0.9892, -1.0937],
        [-1.2545, -0.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10015881061553955
Epoch 0, Step 236: train/loss = 0.5417506694793701, train/raw-loss = 0.5097866654396057, train/logprobs = tensor([[-0.6789, -1.7728],
        [-0.7315, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278560906648636
Epoch 0, Step 237: train/loss = 0.5191094279289246, train/raw-loss = 0.4877869784832001, train/logprobs = tensor([[-0.8412, -2.1982],
        [-1.3783, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252897083759308
Epoch 0, Step 238: train/loss = 0.5110737681388855, train/raw-loss = 0.4764145016670227, train/logprobs = tensor([[-0.7009, -2.4733],
        [-1.0976, -1.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386370211839676
Epoch 0, Step 239: train/loss = 0.6076351404190063, train/raw-loss = 0.5679895877838135, train/logprobs = tensor([[-1.1116, -1.3639],
        [-1.3383, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1585821509361267
Epoch 0, Step 240: train/loss = 0.5511661767959595, train/raw-loss = 0.5161758661270142, train/logprobs = tensor([[-0.8289, -2.0718],
        [-0.8911, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1399613320827484
Epoch 0, Step 241: train/loss = 0.5353854298591614, train/raw-loss = 0.4994589686393738, train/logprobs = tensor([[-0.9144, -2.0740],
        [-1.2980, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14370585978031158
Epoch 0, Step 242: train/loss = 0.5075604319572449, train/raw-loss = 0.4698217213153839, train/logprobs = tensor([[-0.8243, -2.7458],
        [-0.7786, -1.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15095488727092743
Epoch 0, Step 243: train/loss = 0.5109721422195435, train/raw-loss = 0.4748174846172333, train/logprobs = tensor([[-0.8779, -1.8571],
        [-1.3004, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14461858570575714
Epoch 0, Step 244: train/loss = 0.5112093091011047, train/raw-loss = 0.47718581557273865, train/logprobs = tensor([[-0.8825, -2.2082],
        [-0.9509, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13609403371810913
Epoch 0, Step 245: train/loss = 0.5888376235961914, train/raw-loss = 0.554606556892395, train/logprobs = tensor([[-0.9291, -1.3952],
        [-1.1770, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13692417740821838
Epoch 0, Step 246: train/loss = 0.5974074602127075, train/raw-loss = 0.563437819480896, train/logprobs = tensor([[-1.0966, -1.9748],
        [-0.9958, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358788162469864
Epoch 0, Step 247: train/loss = 0.5191079378128052, train/raw-loss = 0.47788557410240173, train/logprobs = tensor([[-0.9828, -1.5831],
        [-1.3265, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648894101381302
Epoch 0, Step 248: train/loss = 0.4634001851081848, train/raw-loss = 0.42220908403396606, train/logprobs = tensor([[-0.8380, -2.1403],
        [-1.4182, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16476446390151978
Epoch 0, Step 249: train/loss = 0.5950969457626343, train/raw-loss = 0.5636721849441528, train/logprobs = tensor([[-1.0119, -2.0703],
        [-0.9797, -1.4176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1256987750530243
Epoch 0, Step 250: train/loss = 0.6237499713897705, train/raw-loss = 0.5848948955535889, train/logprobs = tensor([[-1.0558, -1.4427],
        [-1.3375, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15542039275169373
Epoch 0, Step 251: train/loss = 0.4840959310531616, train/raw-loss = 0.44361236691474915, train/logprobs = tensor([[-1.1233, -1.5778],
        [-2.0023, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16193413734436035
Epoch 0, Step 252: train/loss = 0.5665682554244995, train/raw-loss = 0.5285797119140625, train/logprobs = tensor([[-1.2203, -2.0031],
        [-1.3912, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15195420384407043
Epoch 0, Step 253: train/loss = 0.36421626806259155, train/raw-loss = 0.320716917514801, train/logprobs = tensor([[-1.1184, -3.2969],
        [-2.0091, -2.1556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17399752140045166
Epoch 0, Step 254: train/loss = 0.5020873546600342, train/raw-loss = 0.4641127288341522, train/logprobs = tensor([[-0.9147, -1.8644],
        [-1.2749, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15189853310585022
Epoch 0, Step 255: train/loss = 0.6218277812004089, train/raw-loss = 0.5839937329292297, train/logprobs = tensor([[-1.3257, -1.7316],
        [-1.3701, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513361632823944
Epoch 0, Step 256: train/loss = 0.5138018727302551, train/raw-loss = 0.46076688170433044, train/logprobs = tensor([[-1.0621, -1.7777],
        [-1.4907, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2121400535106659
Epoch 0, Step 257: train/loss = 0.47337913513183594, train/raw-loss = 0.42994996905326843, train/logprobs = tensor([[-0.9122, -1.9308],
        [-1.2883, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17371675372123718
Epoch 0, Step 258: train/loss = 0.4815029799938202, train/raw-loss = 0.4442785978317261, train/logprobs = tensor([[-0.9335, -1.6582],
        [-1.6720, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14889757335186005
Epoch 0, Step 259: train/loss = 0.6647367477416992, train/raw-loss = 0.6180930137634277, train/logprobs = tensor([[-1.3226, -1.0378],
        [-1.5214, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18657507002353668
Epoch 0, Step 260: train/loss = 0.4294227957725525, train/raw-loss = 0.3716975450515747, train/logprobs = tensor([[-1.0857, -2.0723],
        [-2.0753, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23090100288391113
Epoch 0, Step 261: train/loss = 0.41014164686203003, train/raw-loss = 0.35916244983673096, train/logprobs = tensor([[-0.8791, -2.1653],
        [-1.6532, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2039167284965515
Epoch 0, Step 262: train/loss = 0.35269930958747864, train/raw-loss = 0.3006417155265808, train/logprobs = tensor([[-1.0051, -2.3354],
        [-2.1285, -0.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20823045074939728
Epoch 0, Step 263: train/loss = 0.37310147285461426, train/raw-loss = 0.3226897120475769, train/logprobs = tensor([[-1.2897, -1.5848],
        [-2.9333, -0.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.201647087931633
Epoch 0, Step 264: train/loss = 0.48050937056541443, train/raw-loss = 0.432537317276001, train/logprobs = tensor([[-1.2557, -2.8297],
        [-1.9340, -1.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19188833236694336
Epoch 0, Step 265: train/loss = 0.4079626202583313, train/raw-loss = 0.35387587547302246, train/logprobs = tensor([[-1.3574, -3.5260],
        [-2.2332, -1.5652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21634703874588013
Epoch 0, Step 266: train/loss = 0.6837971210479736, train/raw-loss = 0.631479024887085, train/logprobs = tensor([[-1.8439, -2.4426],
        [-1.7005, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20927242934703827
Epoch 0, Step 267: train/loss = 0.4387906789779663, train/raw-loss = 0.3950599730014801, train/logprobs = tensor([[-0.9122, -1.6522],
        [-1.8035, -0.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1749228686094284
Epoch 0, Step 268: train/loss = 0.5951100587844849, train/raw-loss = 0.5529206991195679, train/logprobs = tensor([[-1.1330, -2.1794],
        [-0.9372, -1.2211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16875767707824707
Epoch 0, Step 269: train/loss = 0.6164300441741943, train/raw-loss = 0.5770233273506165, train/logprobs = tensor([[-0.7762, -1.5379],
        [-0.7855, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15762698650360107
Epoch 0, Step 270: train/loss = 0.5446116328239441, train/raw-loss = 0.5066041946411133, train/logprobs = tensor([[-0.6471, -1.9068],
        [-0.6139, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1520298421382904
Epoch 0, Step 271: train/loss = 0.5364036560058594, train/raw-loss = 0.4861748516559601, train/logprobs = tensor([[-0.9214, -2.3011],
        [-0.9471, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2009153664112091
Epoch 0, Step 272: train/loss = 0.4865882396697998, train/raw-loss = 0.43921729922294617, train/logprobs = tensor([[-0.8452, -2.1359],
        [-1.4068, -1.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18948349356651306
Epoch 0, Step 273: train/loss = 0.47574475407600403, train/raw-loss = 0.41819971799850464, train/logprobs = tensor([[-1.0321, -1.6323],
        [-1.7342, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23018001019954681
Epoch 0, Step 274: train/loss = 0.6425192356109619, train/raw-loss = 0.5910354852676392, train/logprobs = tensor([[-1.1785, -1.1697],
        [-1.6574, -1.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20593515038490295
Epoch 0, Step 275: train/loss = 0.469123512506485, train/raw-loss = 0.42385268211364746, train/logprobs = tensor([[-0.9878, -2.4137],
        [-1.3242, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18108318746089935
Epoch 0, Step 276: train/loss = 0.4986025094985962, train/raw-loss = 0.45456409454345703, train/logprobs = tensor([[-1.1024, -1.8341],
        [-1.6467, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17615370452404022
Epoch 0, Step 277: train/loss = 0.442514568567276, train/raw-loss = 0.3903742730617523, train/logprobs = tensor([[-1.4477, -2.1081],
        [-2.0890, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20856121182441711
Epoch 0, Step 278: train/loss = 0.5937671661376953, train/raw-loss = 0.5493916273117065, train/logprobs = tensor([[-0.9960, -1.3558],
        [-1.2905, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17750200629234314
Epoch 0, Step 279: train/loss = 0.5732481479644775, train/raw-loss = 0.5201427936553955, train/logprobs = tensor([[-0.9622, -2.1937],
        [-1.3367, -1.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21242132782936096
Epoch 0, Step 280: train/loss = 0.612276554107666, train/raw-loss = 0.5632273554801941, train/logprobs = tensor([[-1.4297, -1.8060],
        [-1.2083, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19619643688201904
Epoch 0, Step 281: train/loss = 0.5861754417419434, train/raw-loss = 0.5398798584938049, train/logprobs = tensor([[-0.9636, -1.0936],
        [-1.4078, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18518224358558655
Epoch 0, Step 282: train/loss = 0.5455291271209717, train/raw-loss = 0.499298632144928, train/logprobs = tensor([[-1.2485, -2.3641],
        [-1.7626, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18492181599140167
Epoch 0, Step 283: train/loss = 0.5599757432937622, train/raw-loss = 0.5188299417495728, train/logprobs = tensor([[-0.8090, -1.7210],
        [-1.1006, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16458335518836975
Epoch 0, Step 284: train/loss = 0.4990338683128357, train/raw-loss = 0.4519772529602051, train/logprobs = tensor([[-1.1699, -1.9872],
        [-1.4420, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.188226580619812
Epoch 0, Step 285: train/loss = 0.571711540222168, train/raw-loss = 0.5221656560897827, train/logprobs = tensor([[-1.2266, -1.4707],
        [-1.8460, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19818341732025146
Epoch 0, Step 286: train/loss = 0.4010547995567322, train/raw-loss = 0.35398635268211365, train/logprobs = tensor([[-1.1486, -2.9445],
        [-1.5261, -1.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18827378749847412
Epoch 0, Step 287: train/loss = 0.5489203929901123, train/raw-loss = 0.5051441192626953, train/logprobs = tensor([[-1.8155, -3.3611],
        [-1.4842, -1.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17510539293289185
Epoch 0, Step 288: train/loss = 0.5212294459342957, train/raw-loss = 0.4737710654735565, train/logprobs = tensor([[-1.2920, -2.1584],
        [-1.5620, -0.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1898333728313446
Epoch 0, Step 289: train/loss = 0.44575971364974976, train/raw-loss = 0.39983639121055603, train/logprobs = tensor([[-0.9990, -2.2274],
        [-1.7066, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18369340896606445
Epoch 0, Step 290: train/loss = 0.557620644569397, train/raw-loss = 0.5142518281936646, train/logprobs = tensor([[-1.0691, -1.6052],
        [-1.2871, -0.8678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17347519099712372
Epoch 0, Step 291: train/loss = 0.5877567529678345, train/raw-loss = 0.5338597297668457, train/logprobs = tensor([[-1.5057, -2.2928],
        [-1.5022, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21558807790279388
Epoch 0, Step 292: train/loss = 0.5754855871200562, train/raw-loss = 0.5249289274215698, train/logprobs = tensor([[-0.9485, -1.3677],
        [-1.1982, -0.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2022266536951065
Epoch 0, Step 293: train/loss = 0.4936569035053253, train/raw-loss = 0.4418049156665802, train/logprobs = tensor([[-0.9117, -2.5192],
        [-1.1827, -1.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2074078917503357
Epoch 0, Step 294: train/loss = 0.6231498122215271, train/raw-loss = 0.5787675380706787, train/logprobs = tensor([[-0.8881, -1.1184],
        [-1.1477, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1775290071964264
Epoch 0, Step 295: train/loss = 0.48272448778152466, train/raw-loss = 0.42930474877357483, train/logprobs = tensor([[-1.0690, -2.4756],
        [-1.8728, -1.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21367883682250977
Epoch 0, Step 296: train/loss = 0.5793743133544922, train/raw-loss = 0.5201407670974731, train/logprobs = tensor([[-1.5809, -1.7750],
        [-2.0427, -1.0477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23693394660949707
Epoch 0, Step 297: train/loss = 0.4644797146320343, train/raw-loss = 0.4091036021709442, train/logprobs = tensor([[-1.0926, -2.6257],
        [-1.2909, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22150447964668274
Epoch 0, Step 298: train/loss = 0.48118335008621216, train/raw-loss = 0.4248763918876648, train/logprobs = tensor([[-1.2009, -2.0455],
        [-1.5759, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22522787749767303
Epoch 0, Step 299: train/loss = 0.5652608275413513, train/raw-loss = 0.517402708530426, train/logprobs = tensor([[-1.1995, -1.3843],
        [-1.8618, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19143258035182953
Epoch 0, Step 300: train/loss = 0.32104092836380005, train/raw-loss = 0.2600952088832855, train/logprobs = tensor([[-1.3698, -2.8584],
        [-2.4233, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24378301203250885
Epoch 0, Step 301: train/loss = 0.37995684146881104, train/raw-loss = 0.32285046577453613, train/logprobs = tensor([[-0.8743, -2.7172],
        [-1.4566, -0.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22842544317245483
Epoch 0, Step 302: train/loss = 0.4426133930683136, train/raw-loss = 0.3837195634841919, train/logprobs = tensor([[-1.7115, -2.4662],
        [-2.4019, -1.3728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2355753630399704
Epoch 0, Step 303: train/loss = 0.49604934453964233, train/raw-loss = 0.44248268008232117, train/logprobs = tensor([[-0.6493, -1.5152],
        [-1.0586, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21426665782928467
Epoch 0, Step 304: train/loss = 0.498171865940094, train/raw-loss = 0.43962350487709045, train/logprobs = tensor([[-1.1460, -2.1155],
        [-1.6016, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23419363796710968
Epoch 0, Step 305: train/loss = 0.5606433749198914, train/raw-loss = 0.5152512192726135, train/logprobs = tensor([[-1.1355, -3.8802],
        [-1.1969, -2.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18156863749027252
Epoch 0, Step 306: train/loss = 0.6665750741958618, train/raw-loss = 0.6353933811187744, train/logprobs = tensor([[-0.4872, -0.7803],
        [-0.5225, -0.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12472718209028244
Epoch 0, Step 307: train/loss = 0.41580259799957275, train/raw-loss = 0.36444687843322754, train/logprobs = tensor([[-1.0859, -2.0635],
        [-1.9085, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054229974746704
Epoch 0, Step 308: train/loss = 0.5034420490264893, train/raw-loss = 0.4565814137458801, train/logprobs = tensor([[-0.9246, -2.0716],
        [-1.3585, -1.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18744252622127533
Epoch 0, Step 309: train/loss = 0.5476155281066895, train/raw-loss = 0.500912606716156, train/logprobs = tensor([[-0.8934, -1.8939],
        [-0.8730, -0.8212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18681159615516663
Epoch 0, Step 310: train/loss = 0.4439866244792938, train/raw-loss = 0.39422541856765747, train/logprobs = tensor([[-1.7105, -5.1077],
        [-1.5269, -2.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19904492795467377
Epoch 0, Step 311: train/loss = 0.4947938024997711, train/raw-loss = 0.43980681896209717, train/logprobs = tensor([[-1.6882, -2.5165],
        [-2.2085, -1.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2199479043483734
Epoch 0, Step 312: train/loss = 0.43506985902786255, train/raw-loss = 0.3802916407585144, train/logprobs = tensor([[-1.4822, -1.7655],
        [-2.2222, -0.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21911293268203735
Epoch 0, Step 313: train/loss = 0.4485197365283966, train/raw-loss = 0.3962676525115967, train/logprobs = tensor([[-1.0287, -2.6234],
        [-1.1625, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20900827646255493
Epoch 0, Step 314: train/loss = 0.6338509917259216, train/raw-loss = 0.5882303714752197, train/logprobs = tensor([[-1.1094, -1.4759],
        [-1.3793, -1.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18248216807842255
Epoch 0, Step 315: train/loss = 0.41092249751091003, train/raw-loss = 0.35052189230918884, train/logprobs = tensor([[-1.1349, -3.0544],
        [-1.5727, -1.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2416025698184967
Epoch 0, Step 316: train/loss = 0.5448850393295288, train/raw-loss = 0.4984462857246399, train/logprobs = tensor([[-0.8953, -1.8116],
        [-1.2322, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18575520813465118
Epoch 0, Step 317: train/loss = 0.4584672451019287, train/raw-loss = 0.4002499580383301, train/logprobs = tensor([[-1.3025, -3.0737],
        [-1.7912, -1.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23286913335323334
Epoch 0, Step 318: train/loss = 0.500086784362793, train/raw-loss = 0.45304441452026367, train/logprobs = tensor([[-0.6046, -2.0671],
        [-0.7011, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18816930055618286
Epoch 0, Step 319: train/loss = 0.4243185818195343, train/raw-loss = 0.36190080642700195, train/logprobs = tensor([[-1.4131, -2.1217],
        [-2.0162, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24967116117477417
Epoch 0, Step 320: train/loss = 0.587661862373352, train/raw-loss = 0.5363638401031494, train/logprobs = tensor([[-1.3360, -1.6549],
        [-2.2160, -1.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20519205927848816
Epoch 0, Step 321: train/loss = 0.5105227828025818, train/raw-loss = 0.46891626715660095, train/logprobs = tensor([[-1.8405, -2.7886],
        [-2.4738, -1.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16642600297927856
Epoch 0, Step 322: train/loss = 0.6220343708992004, train/raw-loss = 0.5684391856193542, train/logprobs = tensor([[-0.9640, -1.5335],
        [-1.7972, -1.3206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21438071131706238
Epoch 0, Step 323: train/loss = 0.4760773777961731, train/raw-loss = 0.41647687554359436, train/logprobs = tensor([[-1.0570, -1.5939],
        [-2.2158, -0.9562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23840197920799255
Epoch 0, Step 324: train/loss = 0.3824630677700043, train/raw-loss = 0.3292134404182434, train/logprobs = tensor([[-1.1678, -2.6866],
        [-1.6417, -0.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21299861371517181
Epoch 0, Step 325: train/loss = 0.35902348160743713, train/raw-loss = 0.3024148643016815, train/logprobs = tensor([[-1.2317, -2.4636],
        [-2.2940, -0.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22643449902534485
Epoch 0, Step 326: train/loss = 0.5403523445129395, train/raw-loss = 0.48337993025779724, train/logprobs = tensor([[-1.2075, -1.4652],
        [-1.8250, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2278895527124405
Epoch 0, Step 327: train/loss = 0.4047422409057617, train/raw-loss = 0.3562875986099243, train/logprobs = tensor([[-0.9967, -5.1041],
        [-0.9499, -2.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19381862878799438
Epoch 0, Step 328: train/loss = 0.5037224888801575, train/raw-loss = 0.464674711227417, train/logprobs = tensor([[-0.7622, -2.2122],
        [-0.8191, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1561911553144455
Epoch 0, Step 329: train/loss = 0.567497193813324, train/raw-loss = 0.5073261260986328, train/logprobs = tensor([[-1.2661, -2.6061],
        [-2.6680, -1.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2406843602657318
Epoch 0, Step 330: train/loss = 0.5743321180343628, train/raw-loss = 0.5282917022705078, train/logprobs = tensor([[-1.2845, -1.1886],
        [-1.7400, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1841617375612259
Epoch 0, Step 331: train/loss = 0.4559776782989502, train/raw-loss = 0.4019661843776703, train/logprobs = tensor([[-0.7094, -2.0495],
        [-1.3095, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21604591608047485
Epoch 0, Step 332: train/loss = 0.5917695164680481, train/raw-loss = 0.5347179174423218, train/logprobs = tensor([[-1.1044, -1.5310],
        [-2.2536, -1.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22820645570755005
Epoch 0, Step 333: train/loss = 0.44349202513694763, train/raw-loss = 0.38635027408599854, train/logprobs = tensor([[-1.1182, -2.5361],
        [-1.7214, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2285671830177307
Epoch 0, Step 334: train/loss = 0.4903244972229004, train/raw-loss = 0.44267114996910095, train/logprobs = tensor([[-0.9304, -2.9045],
        [-1.0550, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19061340391635895
Epoch 0, Step 335: train/loss = 0.4354208707809448, train/raw-loss = 0.3750770092010498, train/logprobs = tensor([[-1.1211, -3.2011],
        [-1.1080, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2413754016160965
Epoch 0, Step 336: train/loss = 0.48412203788757324, train/raw-loss = 0.4158186912536621, train/logprobs = tensor([[-1.1049, -2.4452],
        [-2.2066, -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27321335673332214
Epoch 0, Step 337: train/loss = 0.4503418505191803, train/raw-loss = 0.40379902720451355, train/logprobs = tensor([[-0.8613, -1.8085],
        [-1.6409, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1861712783575058
Epoch 0, Step 338: train/loss = 0.355735182762146, train/raw-loss = 0.29090285301208496, train/logprobs = tensor([[-1.4295, -2.8941],
        [-2.2966, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2593294382095337
Epoch 0, Step 339: train/loss = 0.3914743959903717, train/raw-loss = 0.3358738422393799, train/logprobs = tensor([[-1.2338, -2.7954],
        [-2.0730, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22240209579467773
Epoch 0, Step 340: train/loss = 0.48228204250335693, train/raw-loss = 0.4327605962753296, train/logprobs = tensor([[-0.9133, -2.0742],
        [-1.3673, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19808577001094818
Epoch 0, Step 341: train/loss = 0.43670567870140076, train/raw-loss = 0.37725359201431274, train/logprobs = tensor([[-1.5863, -2.2054],
        [-3.1411, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2378084361553192
Epoch 0, Step 342: train/loss = 0.414725124835968, train/raw-loss = 0.35545068979263306, train/logprobs = tensor([[-1.1316, -2.2408],
        [-2.3017, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23709774017333984
Epoch 0, Step 343: train/loss = 0.6112424731254578, train/raw-loss = 0.564246654510498, train/logprobs = tensor([[-0.9984, -1.9708],
        [-0.9879, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18798333406448364
Epoch 0, Step 344: train/loss = 0.4709479808807373, train/raw-loss = 0.4204467535018921, train/logprobs = tensor([[-1.2107, -2.5858],
        [-1.9010, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2020047903060913
Epoch 0, Step 345: train/loss = 0.4707905054092407, train/raw-loss = 0.42155900597572327, train/logprobs = tensor([[-0.8945, -2.4384],
        [-0.9523, -0.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1969260573387146
Epoch 0, Step 346: train/loss = 0.5044623613357544, train/raw-loss = 0.46086281538009644, train/logprobs = tensor([[-1.1031, -2.8035],
        [-1.2814, -1.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17439809441566467
Epoch 0, Step 347: train/loss = 0.3664518892765045, train/raw-loss = 0.31256967782974243, train/logprobs = tensor([[-0.7885, -3.0630],
        [-1.5874, -1.3168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21552875638008118
Epoch 0, Step 348: train/loss = 0.3094078302383423, train/raw-loss = 0.24688971042633057, train/logprobs = tensor([[-0.9852, -3.9145],
        [-1.6191, -0.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2500724792480469
Epoch 0, Step 349: train/loss = 0.6296358704566956, train/raw-loss = 0.5876204967498779, train/logprobs = tensor([[-1.1220, -1.1395],
        [-1.3699, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16806143522262573
Epoch 0, Step 350: train/loss = 0.4166622459888458, train/raw-loss = 0.3585163950920105, train/logprobs = tensor([[-0.9536, -2.9070],
        [-1.6059, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23258349299430847
Epoch 0, Step 351: train/loss = 0.5315073132514954, train/raw-loss = 0.4802699685096741, train/logprobs = tensor([[-1.2791, -1.3107],
        [-1.8232, -0.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20494943857192993
Epoch 0, Step 352: train/loss = 0.2756861448287964, train/raw-loss = 0.21165049076080322, train/logprobs = tensor([[-1.0586, -3.3283],
        [-2.7293, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25614264607429504
Epoch 0, Step 353: train/loss = 0.3548868000507355, train/raw-loss = 0.2948368489742279, train/logprobs = tensor([[-1.1847, -3.0493],
        [-2.3741, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24019990861415863
Epoch 0, Step 354: train/loss = 0.3617834448814392, train/raw-loss = 0.3025539517402649, train/logprobs = tensor([[-1.4579, -2.9685],
        [-2.3955, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23691803216934204
Epoch 0, Step 355: train/loss = 0.7121005058288574, train/raw-loss = 0.649036705493927, train/logprobs = tensor([[-1.0956, -2.3084],
        [-1.7943, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2522549033164978
Epoch 0, Step 356: train/loss = 0.5145277380943298, train/raw-loss = 0.44905751943588257, train/logprobs = tensor([[-1.1460, -2.3846],
        [-1.7981, -1.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26188090443611145
Epoch 0, Step 357: train/loss = 0.6060007214546204, train/raw-loss = 0.5662122368812561, train/logprobs = tensor([[-0.5331, -1.4256],
        [-0.6349, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159154012799263
Epoch 0, Step 358: train/loss = 0.4186955690383911, train/raw-loss = 0.3738090991973877, train/logprobs = tensor([[-0.9031, -3.2180],
        [-1.3345, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17954574525356293
Epoch 0, Step 359: train/loss = 0.5468904376029968, train/raw-loss = 0.48748326301574707, train/logprobs = tensor([[-0.8755, -2.0397],
        [-1.8259, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2376287579536438
Epoch 0, Step 360: train/loss = 0.5276740789413452, train/raw-loss = 0.4714886248111725, train/logprobs = tensor([[-0.8170, -2.7076],
        [-1.1289, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22474180161952972
Epoch 0, Step 361: train/loss = 0.40522247552871704, train/raw-loss = 0.34777384996414185, train/logprobs = tensor([[-0.8461, -2.8080],
        [-1.6040, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2297944575548172
Epoch 0, Step 362: train/loss = 0.47485649585723877, train/raw-loss = 0.42678892612457275, train/logprobs = tensor([[-0.9322, -2.1384],
        [-1.5089, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19227029383182526
Epoch 0, Step 363: train/loss = 0.3702010214328766, train/raw-loss = 0.3109995424747467, train/logprobs = tensor([[-1.6859, -2.3594],
        [-3.0197, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2368059754371643
Epoch 0, Step 364: train/loss = 0.4469321370124817, train/raw-loss = 0.40286117792129517, train/logprobs = tensor([[-0.6717, -2.6186],
        [-1.5007, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17628362774848938
Epoch 0, Step 365: train/loss = 0.4089236259460449, train/raw-loss = 0.34399574995040894, train/logprobs = tensor([[-1.0861, -2.1750],
        [-2.3724, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25971153378486633
Epoch 0, Step 366: train/loss = 0.38929587602615356, train/raw-loss = 0.32993102073669434, train/logprobs = tensor([[-1.4329, -2.0428],
        [-2.6353, -0.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23745939135551453
Epoch 0, Step 367: train/loss = 0.42284566164016724, train/raw-loss = 0.3592817783355713, train/logprobs = tensor([[-1.0307, -3.3736],
        [-2.2937, -1.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254255473613739
Epoch 0, Step 368: train/loss = 0.3428473472595215, train/raw-loss = 0.2878473997116089, train/logprobs = tensor([[-1.0492, -3.3477],
        [-2.0082, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.219999760389328
Epoch 0, Step 369: train/loss = 0.26028525829315186, train/raw-loss = 0.2040797919034958, train/logprobs = tensor([[-1.7496, -4.1065],
        [-2.8737, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22482183575630188
Epoch 0, Step 370: train/loss = 0.4334779977798462, train/raw-loss = 0.37731581926345825, train/logprobs = tensor([[-1.2973, -3.1759],
        [-1.7843, -1.3775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22464866936206818
Epoch 0, Step 371: train/loss = 0.648847222328186, train/raw-loss = 0.598225474357605, train/logprobs = tensor([[-0.7134, -1.2126],
        [-0.9927, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20248721539974213
Epoch 0, Step 372: train/loss = 0.5532475113868713, train/raw-loss = 0.4996209144592285, train/logprobs = tensor([[-2.0810, -3.7526],
        [-2.5444, -2.3468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21450640261173248
Epoch 0, Step 373: train/loss = 0.40912944078445435, train/raw-loss = 0.34691351652145386, train/logprobs = tensor([[-1.2437, -2.0663],
        [-2.7783, -0.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24886369705200195
Epoch 0, Step 374: train/loss = 0.41074803471565247, train/raw-loss = 0.36553409695625305, train/logprobs = tensor([[-1.0687, -1.9863],
        [-1.8702, -0.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1808556765317917
Epoch 0, Step 375: train/loss = 0.6676926016807556, train/raw-loss = 0.6260708570480347, train/logprobs = tensor([[-0.7693, -0.8809],
        [-0.8412, -0.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16648699343204498
Epoch 0, Step 376: train/loss = 0.5589289665222168, train/raw-loss = 0.5063177347183228, train/logprobs = tensor([[-1.9941, -1.9420],
        [-2.6242, -1.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2104445993900299
Epoch 0, Step 377: train/loss = 0.4957273006439209, train/raw-loss = 0.44259151816368103, train/logprobs = tensor([[-0.5922, -3.1976],
        [-0.8155, -1.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21254301071166992
Epoch 0, Step 378: train/loss = 0.4165390431880951, train/raw-loss = 0.3536222577095032, train/logprobs = tensor([[-0.9648, -1.8834],
        [-2.0645, -0.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516673505306244
Epoch 0, Step 379: train/loss = 0.4564776122570038, train/raw-loss = 0.4015835225582123, train/logprobs = tensor([[-1.6220, -3.3110],
        [-1.7838, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21957625448703766
Epoch 0, Step 380: train/loss = 0.435398668050766, train/raw-loss = 0.3800993859767914, train/logprobs = tensor([[-1.2834, -2.7109],
        [-2.3372, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2211972028017044
Epoch 0, Step 381: train/loss = 0.3332529366016388, train/raw-loss = 0.2778156101703644, train/logprobs = tensor([[-0.9792, -2.4063],
        [-2.4437, -0.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22174930572509766
Epoch 0, Step 382: train/loss = 0.5304199457168579, train/raw-loss = 0.46934792399406433, train/logprobs = tensor([[-0.8302, -1.2229],
        [-1.9490, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2442881166934967
Epoch 0, Step 383: train/loss = 0.4743402898311615, train/raw-loss = 0.4187365174293518, train/logprobs = tensor([[-1.0131, -1.8759],
        [-2.7702, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22241505980491638
Epoch 0, Step 384: train/loss = 0.3969123065471649, train/raw-loss = 0.3388139605522156, train/logprobs = tensor([[-0.9721, -3.8761],
        [-1.1823, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2323933243751526
Epoch 0, Step 385: train/loss = 0.1998213827610016, train/raw-loss = 0.13535365462303162, train/logprobs = tensor([[-1.2329, -3.3172],
        [-3.9613, -1.4315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2578708529472351
Epoch 0, Step 386: train/loss = 0.6610738039016724, train/raw-loss = 0.6120484471321106, train/logprobs = tensor([[-1.8330, -1.6619],
        [-2.6274, -1.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19610151648521423
Epoch 0, Step 387: train/loss = 0.25455719232559204, train/raw-loss = 0.19867315888404846, train/logprobs = tensor([[-1.0940, -4.7375],
        [-1.8458, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22353602945804596
Epoch 0, Step 388: train/loss = 0.5105147361755371, train/raw-loss = 0.4492793083190918, train/logprobs = tensor([[-0.8605, -2.7001],
        [-1.2685, -1.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24494177103042603
Epoch 0, Step 389: train/loss = 0.4305843114852905, train/raw-loss = 0.37425094842910767, train/logprobs = tensor([[-1.5477, -3.6507],
        [-2.1328, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253333330154419
Epoch 0, Step 390: train/loss = 0.4582129716873169, train/raw-loss = 0.401448518037796, train/logprobs = tensor([[-0.9614, -2.3265],
        [-1.4435, -0.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2270578145980835
Epoch 0, Step 391: train/loss = 0.4685090184211731, train/raw-loss = 0.4137718677520752, train/logprobs = tensor([[-0.7791, -1.8161],
        [-1.4435, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21894870698451996
Epoch 0, Step 392: train/loss = 0.23586642742156982, train/raw-loss = 0.17000645399093628, train/logprobs = tensor([[-1.5269, -3.1786],
        [-3.6759, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634398341178894
Epoch 0, Step 393: train/loss = 0.5228198766708374, train/raw-loss = 0.46641096472740173, train/logprobs = tensor([[-1.1473, -3.3503],
        [-1.5851, -1.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22563573718070984
Epoch 0, Step 394: train/loss = 0.42987972497940063, train/raw-loss = 0.37034523487091064, train/logprobs = tensor([[-0.9228, -3.0333],
        [-1.7014, -1.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23813799023628235
Epoch 0, Step 395: train/loss = 0.42117732763290405, train/raw-loss = 0.36970555782318115, train/logprobs = tensor([[-1.0121, -2.1271],
        [-2.2893, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2058870494365692
Epoch 0, Step 396: train/loss = 0.4843924641609192, train/raw-loss = 0.4297223687171936, train/logprobs = tensor([[-1.4861, -4.1634],
        [-1.6108, -1.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21868036687374115
Epoch 0, Step 397: train/loss = 0.47577551007270813, train/raw-loss = 0.41599932312965393, train/logprobs = tensor([[-1.3937, -1.4412],
        [-2.6083, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23910477757453918
Epoch 0, Step 398: train/loss = 0.2500014901161194, train/raw-loss = 0.1812506914138794, train/logprobs = tensor([[-0.9841, -3.1974],
        [-2.4706, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2750031352043152
Epoch 0, Step 399: train/loss = 0.5623581409454346, train/raw-loss = 0.497589647769928, train/logprobs = tensor([[-1.2770, -2.7965],
        [-1.9772, -1.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25907400250434875
Epoch 0, Step 400: train/loss = 0.444983571767807, train/raw-loss = 0.38743269443511963, train/logprobs = tensor([[-1.1379, -3.2236],
        [-1.9720, -1.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23020359873771667
Epoch 0, Step 401: train/loss = 0.4729868173599243, train/raw-loss = 0.41557174921035767, train/logprobs = tensor([[-1.4927, -2.9527],
        [-2.1797, -1.8797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22966007888317108
Epoch 0, Step 402: train/loss = 0.4668709635734558, train/raw-loss = 0.4190271496772766, train/logprobs = tensor([[-0.9103, -2.0649],
        [-1.3518, -0.7567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19137528538703918
Epoch 0, Step 403: train/loss = 0.3703151345252991, train/raw-loss = 0.3058404326438904, train/logprobs = tensor([[-0.9909, -2.0483],
        [-2.8325, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25789889693260193
Epoch 0, Step 404: train/loss = 0.2668526768684387, train/raw-loss = 0.20038960874080658, train/logprobs = tensor([[-1.3855, -2.4548],
        [-3.4067, -0.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658522129058838
Epoch 0, Step 405: train/loss = 0.46844345331192017, train/raw-loss = 0.41532063484191895, train/logprobs = tensor([[-0.7115, -2.1063],
        [-1.6209, -0.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2124912142753601
Epoch 0, Step 406: train/loss = 0.3989063799381256, train/raw-loss = 0.3412976562976837, train/logprobs = tensor([[-1.6962, -2.2489],
        [-3.0076, -1.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23043493926525116
Epoch 0, Step 407: train/loss = 0.42298781871795654, train/raw-loss = 0.36084142327308655, train/logprobs = tensor([[-0.7877, -2.6184],
        [-1.4359, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24858565628528595
Epoch 0, Step 408: train/loss = 0.6130590438842773, train/raw-loss = 0.5578000545501709, train/logprobs = tensor([[-0.8457, -1.5560],
        [-1.0045, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22103607654571533
Epoch 0, Step 409: train/loss = 0.42001408338546753, train/raw-loss = 0.35582658648490906, train/logprobs = tensor([[-1.0818, -3.0369],
        [-1.5043, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567499876022339
Epoch 0, Step 410: train/loss = 0.40731900930404663, train/raw-loss = 0.355045348405838, train/logprobs = tensor([[-1.6475, -3.5141],
        [-2.5212, -1.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20909462869167328
Epoch 0, Step 411: train/loss = 0.44551968574523926, train/raw-loss = 0.3862428665161133, train/logprobs = tensor([[-1.2046, -2.6671],
        [-1.8038, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23710745573043823
Epoch 0, Step 412: train/loss = 0.5399957895278931, train/raw-loss = 0.49160200357437134, train/logprobs = tensor([[-1.0952, -3.0197],
        [-1.4862, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19357530772686005
Epoch 0, Step 413: train/loss = 0.39526429772377014, train/raw-loss = 0.328827828168869, train/logprobs = tensor([[-1.1120, -2.1719],
        [-2.2272, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2657458484172821
Epoch 0, Step 414: train/loss = 0.45375654101371765, train/raw-loss = 0.4013504385948181, train/logprobs = tensor([[-0.8521, -2.8520],
        [-0.9762, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2096244841814041
Epoch 0, Step 415: train/loss = 0.30002057552337646, train/raw-loss = 0.2369799166917801, train/logprobs = tensor([[-0.9226, -4.1275],
        [-1.6271, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25216275453567505
Epoch 0, Step 416: train/loss = 0.3875226378440857, train/raw-loss = 0.32224249839782715, train/logprobs = tensor([[-1.0013, -3.3124],
        [-2.7340, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26112064719200134
Epoch 0, Step 417: train/loss = 0.6419498920440674, train/raw-loss = 0.5840036869049072, train/logprobs = tensor([[-1.7194, -1.4755],
        [-1.6879, -0.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23178483545780182
Epoch 0, Step 418: train/loss = 0.3985717296600342, train/raw-loss = 0.32822829484939575, train/logprobs = tensor([[-1.1286, -2.9900],
        [-2.5472, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28137367963790894
Epoch 0, Step 419: train/loss = 0.27000829577445984, train/raw-loss = 0.20760801434516907, train/logprobs = tensor([[-1.0419, -3.4787],
        [-2.5221, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24960121512413025
Epoch 0, Step 420: train/loss = 0.43309304118156433, train/raw-loss = 0.38219690322875977, train/logprobs = tensor([[-0.6896, -1.8479],
        [-1.8122, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20358456671237946
Epoch 0, Step 421: train/loss = 0.36261534690856934, train/raw-loss = 0.2936675548553467, train/logprobs = tensor([[-1.1408, -3.9948],
        [-1.7203, -1.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.275791198015213
Epoch 0, Step 422: train/loss = 0.4105702340602875, train/raw-loss = 0.35307982563972473, train/logprobs = tensor([[-0.8286, -3.4216],
        [-0.9759, -0.9869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22996163368225098
Epoch 0, Step 423: train/loss = 0.27501365542411804, train/raw-loss = 0.2164817452430725, train/logprobs = tensor([[-1.5646, -1.9900],
        [-3.9864, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2341277003288269
Epoch 0, Step 424: train/loss = 0.24738404154777527, train/raw-loss = 0.17427995800971985, train/logprobs = tensor([[-0.9958, -4.5078],
        [-1.9272, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29241639375686646
Epoch 0, Step 425: train/loss = 0.5021222829818726, train/raw-loss = 0.44518381357192993, train/logprobs = tensor([[-1.7109, -4.0088],
        [-1.4494, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2277539223432541
Epoch 0, Step 426: train/loss = 0.4714495539665222, train/raw-loss = 0.39466628432273865, train/logprobs = tensor([[-0.9776, -2.2747],
        [-2.1850, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3071330189704895
Epoch 0, Step 427: train/loss = 0.31242066621780396, train/raw-loss = 0.24405983090400696, train/logprobs = tensor([[-1.5145, -2.5279],
        [-2.7542, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.273443341255188
Epoch 0, Step 428: train/loss = 0.6204548478126526, train/raw-loss = 0.5548696517944336, train/logprobs = tensor([[-0.7967, -0.9994],
        [-1.8853, -1.2060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2623409032821655
Epoch 0, Step 429: train/loss = 0.40832340717315674, train/raw-loss = 0.3571664094924927, train/logprobs = tensor([[-0.6396, -3.0457],
        [-1.0818, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20462799072265625
Epoch 0, Step 430: train/loss = 0.4028090834617615, train/raw-loss = 0.3406814932823181, train/logprobs = tensor([[-1.3977, -1.7540],
        [-2.8374, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24851036071777344
Epoch 0, Step 431: train/loss = 0.5260506868362427, train/raw-loss = 0.46799957752227783, train/logprobs = tensor([[-1.0821, -2.3907],
        [-1.4727, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2322041392326355
Epoch 0, Step 432: train/loss = 0.36885207891464233, train/raw-loss = 0.30807656049728394, train/logprobs = tensor([[-0.7659, -3.0904],
        [-1.7651, -0.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431020438671112
Epoch 0, Step 433: train/loss = 0.40686047077178955, train/raw-loss = 0.3478050231933594, train/logprobs = tensor([[-1.1177, -2.4062],
        [-2.3607, -1.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23622186481952667
Epoch 0, Step 434: train/loss = 0.6248775720596313, train/raw-loss = 0.5592272281646729, train/logprobs = tensor([[-0.6756, -2.6472],
        [-2.0978, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26260143518447876
Epoch 0, Step 435: train/loss = 0.36405426263809204, train/raw-loss = 0.30204686522483826, train/logprobs = tensor([[-1.6150, -3.0463],
        [-2.5872, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24802953004837036
Epoch 0, Step 436: train/loss = 0.5489219427108765, train/raw-loss = 0.47527241706848145, train/logprobs = tensor([[-1.0298, -2.6799],
        [-1.7628, -1.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2945981025695801
Epoch 0, Step 437: train/loss = 0.4574081301689148, train/raw-loss = 0.40184158086776733, train/logprobs = tensor([[-1.1155, -2.5726],
        [-1.1967, -0.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22226615250110626
Epoch 0, Step 438: train/loss = 0.4666299521923065, train/raw-loss = 0.4123423397541046, train/logprobs = tensor([[-1.1401, -1.8124],
        [-2.2581, -1.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21715044975280762
Epoch 0, Step 439: train/loss = 0.3235471844673157, train/raw-loss = 0.26463574171066284, train/logprobs = tensor([[-0.8972, -2.8917],
        [-1.8789, -0.6891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23564580082893372
Epoch 0, Step 440: train/loss = 0.582431435585022, train/raw-loss = 0.5247563123703003, train/logprobs = tensor([[-1.0276, -1.9011],
        [-1.4728, -1.1748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2307002693414688
Epoch 0, Step 441: train/loss = 0.6145702004432678, train/raw-loss = 0.5563177466392517, train/logprobs = tensor([[-1.3355, -3.4389],
        [-2.7010, -1.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233009934425354
Epoch 0, Step 442: train/loss = 0.3083348274230957, train/raw-loss = 0.2491033971309662, train/logprobs = tensor([[-1.8918, -5.3076],
        [-2.4330, -1.4815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2369256168603897
Epoch 0, Step 443: train/loss = 0.5767686367034912, train/raw-loss = 0.5162212252616882, train/logprobs = tensor([[-1.3101, -2.4848],
        [-1.2701, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24218958616256714
Epoch 0, Step 444: train/loss = 0.46168458461761475, train/raw-loss = 0.3981752097606659, train/logprobs = tensor([[-2.0983, -3.4831],
        [-2.6185, -1.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25403743982315063
Epoch 0, Step 445: train/loss = 0.45422059297561646, train/raw-loss = 0.3974282443523407, train/logprobs = tensor([[-1.3382, -3.2964],
        [-1.8391, -1.4085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2271692454814911
Epoch 0, Step 446: train/loss = 0.6015139818191528, train/raw-loss = 0.5441031455993652, train/logprobs = tensor([[-0.9092, -1.7894],
        [-1.2633, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22964340448379517
Epoch 0, Step 447: train/loss = 0.2654705047607422, train/raw-loss = 0.19853250682353973, train/logprobs = tensor([[-1.1650, -3.5564],
        [-2.5766, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26775193214416504
Epoch 0, Step 448: train/loss = 0.3013870418071747, train/raw-loss = 0.23410853743553162, train/logprobs = tensor([[-0.9807, -3.3868],
        [-1.9950, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2691139578819275
Epoch 0, Step 449: train/loss = 0.33264750242233276, train/raw-loss = 0.2605323791503906, train/logprobs = tensor([[-1.2827, -4.3020],
        [-3.4144, -1.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28846055269241333
Epoch 0, Step 450: train/loss = 0.32706940174102783, train/raw-loss = 0.24749307334423065, train/logprobs = tensor([[-1.0171, -4.0482],
        [-2.1045, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31830546259880066
Epoch 0, Step 451: train/loss = 0.5529363751411438, train/raw-loss = 0.49609899520874023, train/logprobs = tensor([[-0.7686, -3.1856],
        [-1.4070, -1.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2273494154214859
Epoch 0, Step 452: train/loss = 0.3563314974308014, train/raw-loss = 0.290006160736084, train/logprobs = tensor([[-1.7318, -3.7621],
        [-2.9140, -1.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265301376581192
Epoch 0, Step 453: train/loss = 0.30850279331207275, train/raw-loss = 0.2304653525352478, train/logprobs = tensor([[-1.2184, -3.2939],
        [-2.9259, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3121497631072998
Epoch 0, Step 454: train/loss = 0.3867723345756531, train/raw-loss = 0.3090086579322815, train/logprobs = tensor([[-1.6881, -3.9119],
        [-2.9859, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31105470657348633
Epoch 0, Step 455: train/loss = 0.7958648800849915, train/raw-loss = 0.7257354259490967, train/logprobs = tensor([[-1.3159, -3.0711],
        [-2.3783, -2.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2805177569389343
Epoch 0, Step 456: train/loss = 0.4574507772922516, train/raw-loss = 0.39681851863861084, train/logprobs = tensor([[-0.9571, -3.0631],
        [-2.1080, -1.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24252904951572418
Epoch 0, Step 457: train/loss = 0.5434869527816772, train/raw-loss = 0.47715872526168823, train/logprobs = tensor([[-1.1837, -3.1645],
        [-1.8600, -1.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653130888938904
Epoch 0, Step 458: train/loss = 0.1476728469133377, train/raw-loss = 0.0796840488910675, train/logprobs = tensor([[-1.3869, -6.6651],
        [-3.8619, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27195513248443604
Epoch 0, Step 459: train/loss = 0.4827362298965454, train/raw-loss = 0.4082258939743042, train/logprobs = tensor([[-1.2098, -3.3368],
        [-2.2722, -1.3819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29804137349128723
Epoch 0, Step 460: train/loss = 0.3050961494445801, train/raw-loss = 0.242170050740242, train/logprobs = tensor([[-1.2409, -4.0344],
        [-2.2909, -1.4619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517043650150299
Epoch 0, Step 461: train/loss = 0.20693275332450867, train/raw-loss = 0.13919687271118164, train/logprobs = tensor([[-1.3999, -4.8487],
        [-2.6815, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2709435224533081
Epoch 0, Step 462: train/loss = 0.386653333902359, train/raw-loss = 0.32979816198349, train/logprobs = tensor([[-0.8417, -3.0503],
        [-1.8694, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22742071747779846
Epoch 0, Step 463: train/loss = 0.37642279267311096, train/raw-loss = 0.3182944655418396, train/logprobs = tensor([[-0.7548, -2.5243],
        [-1.6838, -0.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23251336812973022
Epoch 0, Step 464: train/loss = 0.6001389622688293, train/raw-loss = 0.5486758351325989, train/logprobs = tensor([[-1.0075, -1.2395],
        [-1.9753, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2058524787425995
Epoch 0, Step 465: train/loss = 0.4806627035140991, train/raw-loss = 0.4193184971809387, train/logprobs = tensor([[-1.1324, -3.3348],
        [-1.4208, -1.3146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24537667632102966
Epoch 0, Step 466: train/loss = 0.3518681526184082, train/raw-loss = 0.28623634576797485, train/logprobs = tensor([[-0.8853, -3.2436],
        [-2.0480, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2625272274017334
Epoch 0, Step 467: train/loss = 0.3855118155479431, train/raw-loss = 0.3218385577201843, train/logprobs = tensor([[-1.7893, -3.0513],
        [-3.3313, -1.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25469303131103516
Epoch 0, Step 468: train/loss = 0.3075239062309265, train/raw-loss = 0.24165788292884827, train/logprobs = tensor([[-1.1177, -3.8351],
        [-2.4753, -1.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2634640634059906
Epoch 0, Step 469: train/loss = 0.44686585664749146, train/raw-loss = 0.38368305563926697, train/logprobs = tensor([[-0.9085, -4.2710],
        [-1.3114, -1.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527313232421875
Epoch 0, Step 470: train/loss = 0.409295916557312, train/raw-loss = 0.35231295228004456, train/logprobs = tensor([[-1.0517, -4.1161],
        [-1.2868, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22793196141719818
Epoch 0, Step 471: train/loss = 0.5103011131286621, train/raw-loss = 0.44601210951805115, train/logprobs = tensor([[-1.3638, -2.3722],
        [-3.1383, -1.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2571559250354767
Epoch 0, Step 472: train/loss = 0.31125545501708984, train/raw-loss = 0.24914313852787018, train/logprobs = tensor([[-1.0664, -3.9361],
        [-2.4582, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24844923615455627
Epoch 0, Step 473: train/loss = 0.35092878341674805, train/raw-loss = 0.2809298634529114, train/logprobs = tensor([[-1.5062, -3.0449],
        [-2.9558, -1.2645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27999570965766907
Epoch 0, Step 474: train/loss = 0.6039719581604004, train/raw-loss = 0.5258194804191589, train/logprobs = tensor([[-1.6378, -3.0485],
        [-2.5942, -2.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126101493835449
Epoch 0, Step 475: train/loss = 0.3430179953575134, train/raw-loss = 0.2736395001411438, train/logprobs = tensor([[-1.0578, -3.6031],
        [-2.6702, -1.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775140404701233
Epoch 0, Step 476: train/loss = 0.3848188519477844, train/raw-loss = 0.32996684312820435, train/logprobs = tensor([[-0.7043, -2.8099],
        [-1.5902, -0.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2194080352783203
Epoch 0, Step 477: train/loss = 0.16486090421676636, train/raw-loss = 0.08965777605772018, train/logprobs = tensor([[-1.3179, -5.0918],
        [-4.1518, -1.3774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3008125126361847
Epoch 0, Step 478: train/loss = 0.30171018838882446, train/raw-loss = 0.23815394937992096, train/logprobs = tensor([[-1.1561, -4.1041],
        [-2.8699, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542249262332916
Epoch 0, Step 479: train/loss = 0.41049179434776306, train/raw-loss = 0.34642452001571655, train/logprobs = tensor([[-1.1910, -3.0007],
        [-1.5846, -1.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2562692165374756
Epoch 0, Step 480: train/loss = 0.49344393610954285, train/raw-loss = 0.42810407280921936, train/logprobs = tensor([[-0.6921, -3.3822],
        [-1.1741, -1.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26135939359664917
Epoch 0, Step 481: train/loss = 0.22854110598564148, train/raw-loss = 0.16700275242328644, train/logprobs = tensor([[-1.0954, -4.3664],
        [-2.9214, -1.2100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24615347385406494
Epoch 0, Step 482: train/loss = 0.45580407977104187, train/raw-loss = 0.38116276264190674, train/logprobs = tensor([[-1.6843, -3.3487],
        [-2.7846, -1.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985652685165405
Epoch 0, Step 483: train/loss = 0.1999548077583313, train/raw-loss = 0.13028039038181305, train/logprobs = tensor([[-0.9250, -4.6922],
        [-2.5633, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2786976993083954
Epoch 0, Step 484: train/loss = 0.46122726798057556, train/raw-loss = 0.3895447850227356, train/logprobs = tensor([[-1.0353, -3.3015],
        [-1.9730, -1.2446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2867298424243927
Epoch 0, Step 485: train/loss = 0.3266714811325073, train/raw-loss = 0.2571682035923004, train/logprobs = tensor([[-0.8835, -4.2132],
        [-1.7665, -2.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27801311016082764
Epoch 0, Step 486: train/loss = 0.4308042824268341, train/raw-loss = 0.3406813144683838, train/logprobs = tensor([[-0.8702, -3.2487],
        [-1.9666, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36049187183380127
Epoch 0, Step 487: train/loss = 0.5754061937332153, train/raw-loss = 0.5090814828872681, train/logprobs = tensor([[-0.9009, -1.8835],
        [-1.4933, -1.2582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26529860496520996
Epoch 0, Step 488: train/loss = 0.3972635865211487, train/raw-loss = 0.3460412621498108, train/logprobs = tensor([[-1.3781, -3.5053],
        [-1.8424, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20488932728767395
Epoch 0, Step 489: train/loss = 0.371476411819458, train/raw-loss = 0.2937275469303131, train/logprobs = tensor([[-1.1200, -3.0327],
        [-2.5037, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.310995489358902
Epoch 0, Step 490: train/loss = 0.42437970638275146, train/raw-loss = 0.3516697287559509, train/logprobs = tensor([[-0.7566, -4.8367],
        [-1.5989, -1.3998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29083991050720215
Epoch 0, Step 491: train/loss = 0.6341814994812012, train/raw-loss = 0.5792999267578125, train/logprobs = tensor([[-1.0076, -3.1362],
        [-1.7346, -2.4706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2195262610912323
Epoch 0, Step 492: train/loss = 0.2461296170949936, train/raw-loss = 0.17430756986141205, train/logprobs = tensor([[-1.3910, -6.1255],
        [-2.1806, -1.2368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28728818893432617
Epoch 0, Step 493: train/loss = 0.5035834312438965, train/raw-loss = 0.42221373319625854, train/logprobs = tensor([[-1.6163, -3.2035],
        [-2.6365, -1.7301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32547879219055176
Epoch 0, Step 494: train/loss = 0.20436839759349823, train/raw-loss = 0.12092426419258118, train/logprobs = tensor([[-1.5043, -4.3057],
        [-4.2805, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337765336036682
Epoch 0, Step 495: train/loss = 0.3647914528846741, train/raw-loss = 0.28662729263305664, train/logprobs = tensor([[-1.1729, -2.4252],
        [-2.5609, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3126566410064697
Epoch 0, Step 496: train/loss = 0.21365225315093994, train/raw-loss = 0.13867616653442383, train/logprobs = tensor([[-1.1699, -4.9074],
        [-3.1083, -1.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29990431666374207
Epoch 0, Step 497: train/loss = 0.516870379447937, train/raw-loss = 0.42756086587905884, train/logprobs = tensor([[-0.8946, -1.7555],
        [-2.2569, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3572380840778351
Epoch 0, Step 498: train/loss = 0.32955625653266907, train/raw-loss = 0.26481908559799194, train/logprobs = tensor([[-0.8751, -3.3879],
        [-2.0358, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589487135410309
Epoch 0, Step 499: train/loss = 0.3116620182991028, train/raw-loss = 0.25070348381996155, train/logprobs = tensor([[-0.7664, -3.7851],
        [-1.5742, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24383419752120972
eval/loss: nan
Epoch 0, Step 500: train/loss = 0.42907658219337463, train/raw-loss = 0.34666764736175537, train/logprobs = tensor([[-1.1819, -2.3162],
        [-2.7488, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32963570952415466
Epoch 0, Step 501: train/loss = 0.32216423749923706, train/raw-loss = 0.24932804703712463, train/logprobs = tensor([[-1.2456, -4.0760],
        [-2.1593, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29134470224380493
Epoch 0, Step 502: train/loss = 0.35471513867378235, train/raw-loss = 0.2661246657371521, train/logprobs = tensor([[-1.3541, -3.2008],
        [-3.5750, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3543619215488434
Epoch 0, Step 503: train/loss = 0.18384099006652832, train/raw-loss = 0.09876164048910141, train/logprobs = tensor([[-1.2413, -4.7878],
        [-3.3605, -1.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34031742811203003
Epoch 0, Step 504: train/loss = 0.2778316140174866, train/raw-loss = 0.20053118467330933, train/logprobs = tensor([[-1.0763, -3.4604],
        [-3.0512, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30920177698135376
Epoch 0, Step 505: train/loss = 0.33318430185317993, train/raw-loss = 0.25374048948287964, train/logprobs = tensor([[-1.1195, -3.4849],
        [-2.3860, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31777524948120117
Epoch 0, Step 506: train/loss = 0.3918045163154602, train/raw-loss = 0.32871371507644653, train/logprobs = tensor([[-1.1981, -3.8691],
        [-2.5047, -1.4700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523631751537323
Epoch 0, Step 507: train/loss = 0.21069446206092834, train/raw-loss = 0.1311139166355133, train/logprobs = tensor([[-1.0135, -4.2905],
        [-2.7468, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31832224130630493
Epoch 0, Step 508: train/loss = 0.5224382877349854, train/raw-loss = 0.44508832693099976, train/logprobs = tensor([[-1.2559, -3.3384],
        [-1.6606, -1.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30939981341362
Epoch 0, Step 509: train/loss = 0.23654618859291077, train/raw-loss = 0.16967034339904785, train/logprobs = tensor([[-0.8886, -4.8713],
        [-2.1271, -1.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2675033509731293
Epoch 0, Step 510: train/loss = 0.29988521337509155, train/raw-loss = 0.22377802431583405, train/logprobs = tensor([[-0.9163, -5.2192],
        [-1.5970, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30442875623703003
Epoch 0, Step 511: train/loss = 0.3488643765449524, train/raw-loss = 0.28693583607673645, train/logprobs = tensor([[-1.3538, -3.8335],
        [-3.1278, -1.5420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24771420657634735
Epoch 0, Step 512: train/loss = 0.37618446350097656, train/raw-loss = 0.2963612973690033, train/logprobs = tensor([[-1.0896, -3.9736],
        [-2.2172, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31929266452789307
Epoch 0, Step 513: train/loss = 0.41818490624427795, train/raw-loss = 0.3611164093017578, train/logprobs = tensor([[-1.0980, -3.3114],
        [-2.2725, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22827397286891937
Epoch 0, Step 514: train/loss = 0.30506840348243713, train/raw-loss = 0.24520233273506165, train/logprobs = tensor([[-1.5191, -3.4701],
        [-3.0654, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23946431279182434
Epoch 0, Step 515: train/loss = 0.14405781030654907, train/raw-loss = 0.052946921437978745, train/logprobs = tensor([[-1.2499, -5.8011],
        [-4.0164, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3644435405731201
Epoch 0, Step 516: train/loss = 0.33528339862823486, train/raw-loss = 0.25927984714508057, train/logprobs = tensor([[-0.9035, -3.9256],
        [-2.1179, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040142357349396
Epoch 0, Step 517: train/loss = 0.6247647404670715, train/raw-loss = 0.5517299175262451, train/logprobs = tensor([[-0.7757, -2.3133],
        [-1.2550, -1.4343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29213911294937134
Epoch 0, Step 518: train/loss = 0.4771493077278137, train/raw-loss = 0.4172315001487732, train/logprobs = tensor([[-1.2277, -5.5651],
        [-1.7429, -2.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23967128992080688
Epoch 0, Step 519: train/loss = 0.35777679085731506, train/raw-loss = 0.26781341433525085, train/logprobs = tensor([[-1.0546, -4.0668],
        [-2.5327, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35985347628593445
Epoch 0, Step 520: train/loss = 0.21761049330234528, train/raw-loss = 0.126738041639328, train/logprobs = tensor([[-1.2262, -6.6994],
        [-2.4603, -1.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3634898364543915
Epoch 0, Step 521: train/loss = 0.4170438349246979, train/raw-loss = 0.3428853452205658, train/logprobs = tensor([[-2.0149, -4.0417],
        [-2.7811, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966339886188507
Epoch 0, Step 522: train/loss = 0.35367733240127563, train/raw-loss = 0.2833392918109894, train/logprobs = tensor([[-1.2815, -3.7235],
        [-2.6577, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2813521921634674
Epoch 0, Step 523: train/loss = 0.4799610376358032, train/raw-loss = 0.4080026149749756, train/logprobs = tensor([[-1.7492, -4.0868],
        [-2.9909, -2.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2878338098526001
Epoch 0, Step 524: train/loss = 0.26367244124412537, train/raw-loss = 0.17930062115192413, train/logprobs = tensor([[-1.1737, -4.2529],
        [-3.3298, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33748722076416016
Epoch 0, Step 525: train/loss = 0.3365594744682312, train/raw-loss = 0.27460139989852905, train/logprobs = tensor([[-1.7505, -3.0409],
        [-3.6862, -1.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24783235788345337
Epoch 0, Step 526: train/loss = 0.261457234621048, train/raw-loss = 0.19003015756607056, train/logprobs = tensor([[-1.8256, -5.1542],
        [-3.6295, -2.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28570833802223206
Epoch 0, Step 527: train/loss = 0.4502418041229248, train/raw-loss = 0.3771468997001648, train/logprobs = tensor([[-1.0065, -2.5471],
        [-2.5209, -1.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29237955808639526
Epoch 0, Step 528: train/loss = 0.26504331827163696, train/raw-loss = 0.19865739345550537, train/logprobs = tensor([[-1.2796, -3.7957],
        [-3.4600, -1.2246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26554369926452637
Epoch 0, Step 529: train/loss = 0.6156665086746216, train/raw-loss = 0.5434788465499878, train/logprobs = tensor([[-1.0157, -4.2187],
        [-2.6328, -2.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28875061869621277
Epoch 0, Step 530: train/loss = 0.46181729435920715, train/raw-loss = 0.40832123160362244, train/logprobs = tensor([[-0.5349, -3.0965],
        [-1.0089, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21398423612117767
Epoch 0, Step 531: train/loss = 0.2196429967880249, train/raw-loss = 0.14091286063194275, train/logprobs = tensor([[-0.8679, -5.2618],
        [-2.5085, -1.3659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31492048501968384
Epoch 0, Step 532: train/loss = 0.418952077627182, train/raw-loss = 0.3479509949684143, train/logprobs = tensor([[-1.0597, -2.5009],
        [-2.2599, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28400447964668274
Epoch 0, Step 533: train/loss = 0.23558779060840607, train/raw-loss = 0.15362900495529175, train/logprobs = tensor([[-0.8325, -4.9078],
        [-1.9008, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32783520221710205
Epoch 0, Step 534: train/loss = 0.4043179154396057, train/raw-loss = 0.3323815166950226, train/logprobs = tensor([[-1.3464, -3.0661],
        [-3.9758, -1.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28774571418762207
Epoch 0, Step 535: train/loss = 0.4527010917663574, train/raw-loss = 0.3720691204071045, train/logprobs = tensor([[-0.9852, -2.6938],
        [-1.9894, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3225279152393341
Epoch 0, Step 536: train/loss = 0.1844959557056427, train/raw-loss = 0.10589515417814255, train/logprobs = tensor([[-1.2887, -6.1941],
        [-3.6742, -1.6933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3144032061100006
Epoch 0, Step 537: train/loss = 0.21017569303512573, train/raw-loss = 0.11926613748073578, train/logprobs = tensor([[-1.5538, -3.9211],
        [-3.7254, -1.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3636382222175598
Epoch 0, Step 538: train/loss = 0.6156173944473267, train/raw-loss = 0.547494649887085, train/logprobs = tensor([[-1.2248, -1.9081],
        [-3.7129, -1.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27249106764793396
Epoch 0, Step 539: train/loss = 0.3295832574367523, train/raw-loss = 0.2513662278652191, train/logprobs = tensor([[-1.3568, -4.7964],
        [-2.7339, -1.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31286805868148804
Epoch 0, Step 540: train/loss = 0.4337841868400574, train/raw-loss = 0.3626229166984558, train/logprobs = tensor([[-1.1675, -2.6820],
        [-2.4374, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2846449315547943
Epoch 0, Step 541: train/loss = 0.4143083393573761, train/raw-loss = 0.34712621569633484, train/logprobs = tensor([[-1.1801, -1.3723],
        [-2.7645, -0.6333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2687284052371979
Epoch 0, Step 542: train/loss = 0.2942144274711609, train/raw-loss = 0.2275434285402298, train/logprobs = tensor([[-1.8603, -3.9336],
        [-2.9072, -1.2766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26668399572372437
Epoch 0, Step 543: train/loss = 0.30710330605506897, train/raw-loss = 0.2296655774116516, train/logprobs = tensor([[-1.3162, -2.8011],
        [-3.0207, -1.2595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30975091457366943
Epoch 0, Step 544: train/loss = 0.4255375564098358, train/raw-loss = 0.3412715494632721, train/logprobs = tensor([[-1.0476, -4.3046],
        [-1.7250, -1.3989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3370642066001892
Epoch 0, Step 545: train/loss = 0.26058655977249146, train/raw-loss = 0.18453826010227203, train/logprobs = tensor([[-0.8388, -4.6527],
        [-2.2822, -1.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3041932284832001
Epoch 0, Step 546: train/loss = 0.35698139667510986, train/raw-loss = 0.2935992181301117, train/logprobs = tensor([[-1.8556, -7.7774],
        [-4.2634, -6.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535287141799927
Epoch 0, Step 547: train/loss = 0.2916542887687683, train/raw-loss = 0.2095128297805786, train/logprobs = tensor([[-0.9658, -4.2509],
        [-2.9487, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3285658061504364
Epoch 0, Step 548: train/loss = 0.28114068508148193, train/raw-loss = 0.1975899636745453, train/logprobs = tensor([[-1.1297, -5.5121],
        [-3.3124, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33420300483703613
Epoch 0, Step 549: train/loss = 0.41296058893203735, train/raw-loss = 0.3305811583995819, train/logprobs = tensor([[-1.5123, -3.9082],
        [-3.7521, -2.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32951757311820984
Epoch 0, Step 550: train/loss = 0.5438318848609924, train/raw-loss = 0.4506772458553314, train/logprobs = tensor([[-1.1063, -2.7523],
        [-2.4731, -1.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3726184368133545
Epoch 0, Step 551: train/loss = 0.3745811879634857, train/raw-loss = 0.28355836868286133, train/logprobs = tensor([[-0.8042, -4.9349],
        [-2.0186, -1.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36409130692481995
Epoch 0, Step 552: train/loss = 0.3643045425415039, train/raw-loss = 0.2966131865978241, train/logprobs = tensor([[-1.5305, -3.3972],
        [-3.5877, -1.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27076542377471924
Epoch 0, Step 553: train/loss = 0.2617776393890381, train/raw-loss = 0.18299373984336853, train/logprobs = tensor([[-2.3088, -4.2511],
        [-4.7095, -1.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31513553857803345
Epoch 0, Step 554: train/loss = 0.2837923765182495, train/raw-loss = 0.20421138405799866, train/logprobs = tensor([[-1.3063, -5.2155],
        [-3.0911, -1.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31832391023635864
Epoch 0, Step 555: train/loss = 0.3307015895843506, train/raw-loss = 0.2726346552371979, train/logprobs = tensor([[-1.6565, -5.7310],
        [-3.2721, -2.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23226779699325562
Epoch 0, Step 556: train/loss = 0.26419204473495483, train/raw-loss = 0.18294355273246765, train/logprobs = tensor([[-1.1414, -3.7704],
        [-2.8981, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32499396800994873
Epoch 0, Step 557: train/loss = 0.35916829109191895, train/raw-loss = 0.29384472966194153, train/logprobs = tensor([[-0.9337, -5.4273],
        [-1.6269, -2.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612941861152649
Epoch 0, Step 558: train/loss = 0.587699294090271, train/raw-loss = 0.49985578656196594, train/logprobs = tensor([[-1.3654, -3.7471],
        [-3.3041, -2.1559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35137397050857544
Epoch 0, Step 559: train/loss = 0.25186026096343994, train/raw-loss = 0.17002518475055695, train/logprobs = tensor([[-0.9905, -4.6822],
        [-2.8789, -1.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3273402750492096
Epoch 0, Step 560: train/loss = 0.3832748532295227, train/raw-loss = 0.3098461627960205, train/logprobs = tensor([[-0.9460, -4.1587],
        [-1.6919, -1.3773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.293714702129364
Epoch 0, Step 561: train/loss = 0.40567514300346375, train/raw-loss = 0.33088749647140503, train/logprobs = tensor([[-1.6462, -3.6321],
        [-3.6785, -2.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2991505265235901
Epoch 0, Step 562: train/loss = 0.39048975706100464, train/raw-loss = 0.30630916357040405, train/logprobs = tensor([[-1.1743, -4.0001],
        [-2.6977, -1.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.336722195148468
Epoch 0, Step 563: train/loss = 0.3144012987613678, train/raw-loss = 0.21974201500415802, train/logprobs = tensor([[-1.2940, -3.6511],
        [-3.7769, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3786371052265167
Epoch 0, Step 564: train/loss = 0.4542834162712097, train/raw-loss = 0.3776214122772217, train/logprobs = tensor([[-1.3694, -2.6780],
        [-2.5262, -2.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3066481053829193
Epoch 0, Step 565: train/loss = 0.5332586765289307, train/raw-loss = 0.45753613114356995, train/logprobs = tensor([[-1.0112, -2.8879],
        [-1.8326, -1.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028903007507324
Epoch 0, Step 566: train/loss = 0.20721232891082764, train/raw-loss = 0.13417528569698334, train/logprobs = tensor([[-0.9443, -7.1231],
        [-2.0472, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2921482026576996
Epoch 0, Step 567: train/loss = 0.5879102945327759, train/raw-loss = 0.5199233293533325, train/logprobs = tensor([[-0.6855, -3.0595],
        [-1.5501, -2.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2719479203224182
Epoch 0, Step 568: train/loss = 0.4171767830848694, train/raw-loss = 0.345441997051239, train/logprobs = tensor([[-0.8768, -4.7313],
        [-2.2608, -1.1959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2869391143321991
Epoch 0, Step 569: train/loss = 0.46501830220222473, train/raw-loss = 0.39115676283836365, train/logprobs = tensor([[-1.8152, -2.1736],
        [-3.4460, -1.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29544609785079956
Epoch 0, Step 570: train/loss = 0.2725011706352234, train/raw-loss = 0.20172099769115448, train/logprobs = tensor([[-1.2665, -6.6427],
        [-3.1267, -1.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28312069177627563
Epoch 0, Step 571: train/loss = 0.4863450229167938, train/raw-loss = 0.42261773347854614, train/logprobs = tensor([[-2.0651, -2.6114],
        [-3.3614, -1.3304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25490909814834595
Epoch 0, Step 572: train/loss = 0.436933696269989, train/raw-loss = 0.3592209219932556, train/logprobs = tensor([[-1.1635, -3.7716],
        [-2.3846, -1.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3108510375022888
Epoch 0, Step 573: train/loss = 0.48656508326530457, train/raw-loss = 0.41565582156181335, train/logprobs = tensor([[-1.2560, -3.4433],
        [-1.7841, -1.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28363701701164246
Epoch 0, Step 574: train/loss = 0.35783159732818604, train/raw-loss = 0.2688589096069336, train/logprobs = tensor([[-1.2317, -7.0280],
        [-3.1688, -2.5796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35589075088500977
Epoch 0, Step 575: train/loss = 0.6068648099899292, train/raw-loss = 0.5273098945617676, train/logprobs = tensor([[-1.3630, -3.5613],
        [-3.1551, -2.8063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3182195723056793
Epoch 0, Step 576: train/loss = 0.21074984967708588, train/raw-loss = 0.12639042735099792, train/logprobs = tensor([[-0.9677, -4.7268],
        [-3.0902, -1.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374377489089966
Epoch 0, Step 577: train/loss = 0.25677838921546936, train/raw-loss = 0.18410439789295197, train/logprobs = tensor([[-1.9221, -2.2854],
        [-4.8398, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29069602489471436
Epoch 0, Step 578: train/loss = 0.5363858938217163, train/raw-loss = 0.4716176390647888, train/logprobs = tensor([[-1.6654, -2.8285],
        [-2.0664, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590731084346771
Epoch 0, Step 579: train/loss = 0.23716579377651215, train/raw-loss = 0.1477794200181961, train/logprobs = tensor([[-1.7983, -4.8261],
        [-4.2603, -1.4650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35754549503326416
Epoch 0, Step 580: train/loss = 0.4451078176498413, train/raw-loss = 0.35105547308921814, train/logprobs = tensor([[-0.9983, -3.9240],
        [-2.3753, -1.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3762092888355255
Epoch 0, Step 581: train/loss = 0.2743380069732666, train/raw-loss = 0.18088315427303314, train/logprobs = tensor([[-0.9275, -5.2689],
        [-2.1584, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37381941080093384
Epoch 0, Step 582: train/loss = 0.6470820307731628, train/raw-loss = 0.5882121324539185, train/logprobs = tensor([[-1.5518, -2.7006],
        [-1.5640, -1.0188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23547935485839844
Epoch 0, Step 583: train/loss = 0.6034426689147949, train/raw-loss = 0.50565505027771, train/logprobs = tensor([[-1.6316, -1.9502],
        [-3.2454, -1.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3911506235599518
Epoch 0, Step 584: train/loss = 0.22210592031478882, train/raw-loss = 0.14105291664600372, train/logprobs = tensor([[-1.2975, -5.0559],
        [-3.3452, -1.4766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.324211984872818
Epoch 0, Step 585: train/loss = 0.3153551518917084, train/raw-loss = 0.25096607208251953, train/logprobs = tensor([[-0.9992, -5.2341],
        [-1.5225, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2575562596321106
Epoch 0, Step 586: train/loss = 0.44835716485977173, train/raw-loss = 0.38496601581573486, train/logprobs = tensor([[-1.3910, -3.5685],
        [-2.8225, -2.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535645365715027
Epoch 0, Step 587: train/loss = 0.4463815987110138, train/raw-loss = 0.33579957485198975, train/logprobs = tensor([[-0.7274, -3.6522],
        [-2.2701, -1.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44232791662216187
Epoch 0, Step 588: train/loss = 0.42705345153808594, train/raw-loss = 0.3581409454345703, train/logprobs = tensor([[-1.1515, -3.5560],
        [-1.9429, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27565017342567444
Epoch 0, Step 589: train/loss = 0.3760950565338135, train/raw-loss = 0.30131128430366516, train/logprobs = tensor([[-1.9018, -4.0354],
        [-3.2287, -1.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29913511872291565
Epoch 0, Step 590: train/loss = 0.5780224204063416, train/raw-loss = 0.4920541048049927, train/logprobs = tensor([[-1.2130, -1.7531],
        [-2.9552, -1.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438732922077179
Epoch 0, Step 591: train/loss = 0.453385591506958, train/raw-loss = 0.3513854146003723, train/logprobs = tensor([[-2.5313, -3.5525],
        [-4.5310, -2.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40800076723098755
Epoch 0, Step 592: train/loss = 0.44106969237327576, train/raw-loss = 0.3650546073913574, train/logprobs = tensor([[-1.6349, -3.3718],
        [-3.5877, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3040603995323181
Epoch 0, Step 593: train/loss = 0.3680865168571472, train/raw-loss = 0.2914765477180481, train/logprobs = tensor([[-1.2072, -3.4339],
        [-4.0051, -1.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064398169517517
Epoch 0, Step 594: train/loss = 0.2154429852962494, train/raw-loss = 0.13691867887973785, train/logprobs = tensor([[-1.0792, -6.4692],
        [-2.2317, -1.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31409722566604614
Epoch 0, Step 595: train/loss = 0.3820125460624695, train/raw-loss = 0.3020591139793396, train/logprobs = tensor([[-1.9491, -2.2669],
        [-3.8234, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31981363892555237
Epoch 0, Step 596: train/loss = 0.33998817205429077, train/raw-loss = 0.2526032030582428, train/logprobs = tensor([[-0.7847, -4.1791],
        [-2.2243, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3495398461818695
Epoch 0, Step 597: train/loss = 0.4122108221054077, train/raw-loss = 0.3423442542552948, train/logprobs = tensor([[-1.9169, -4.1708],
        [-2.8411, -1.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27946633100509644
Epoch 0, Step 598: train/loss = 0.706662654876709, train/raw-loss = 0.6209359765052795, train/logprobs = tensor([[-1.3821, -5.0207],
        [-2.5547, -3.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34290680289268494
Epoch 0, Step 599: train/loss = 0.6564902067184448, train/raw-loss = 0.5796669125556946, train/logprobs = tensor([[-1.4719, -1.9481],
        [-2.2094, -1.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30729323625564575
Epoch 0, Step 600: train/loss = 0.4262532889842987, train/raw-loss = 0.33964863419532776, train/logprobs = tensor([[-1.6933, -4.2161],
        [-3.0570, -2.2331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34641867876052856
Epoch 0, Step 601: train/loss = 0.2617010474205017, train/raw-loss = 0.18044523894786835, train/logprobs = tensor([[-1.8740, -4.9182],
        [-3.5485, -1.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250232934951782
Epoch 0, Step 602: train/loss = 0.38662004470825195, train/raw-loss = 0.32106009125709534, train/logprobs = tensor([[-1.6120, -3.8260],
        [-3.0373, -1.8599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26223990321159363
Epoch 0, Step 603: train/loss = 0.1910698115825653, train/raw-loss = 0.10193409770727158, train/logprobs = tensor([[-1.7043, -4.9905],
        [-3.8241, -1.4482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35654282569885254
Epoch 0, Step 604: train/loss = 0.3862493336200714, train/raw-loss = 0.3156259059906006, train/logprobs = tensor([[-1.7752, -5.1944],
        [-2.8298, -3.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2824937701225281
Epoch 0, Step 605: train/loss = 0.3169262409210205, train/raw-loss = 0.22497496008872986, train/logprobs = tensor([[-0.9659, -3.4213],
        [-3.0583, -1.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36780497431755066
Epoch 0, Step 606: train/loss = 0.5210293531417847, train/raw-loss = 0.45529308915138245, train/logprobs = tensor([[-1.2874, -1.8601],
        [-2.3214, -1.3480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2629450857639313
Epoch 0, Step 607: train/loss = 0.29014864563941956, train/raw-loss = 0.21060487627983093, train/logprobs = tensor([[-1.0045, -5.2326],
        [-1.8382, -1.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181750476360321
Epoch 0, Step 608: train/loss = 0.3093591332435608, train/raw-loss = 0.20530542731285095, train/logprobs = tensor([[-1.3209, -5.6853],
        [-3.9099, -1.5181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41621488332748413
Epoch 0, Step 609: train/loss = 0.3606594204902649, train/raw-loss = 0.28174498677253723, train/logprobs = tensor([[-1.1554, -5.0250],
        [-2.2217, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31565776467323303
Epoch 0, Step 610: train/loss = 0.4905732572078705, train/raw-loss = 0.3894738554954529, train/logprobs = tensor([[-1.2183, -3.2482],
        [-2.3186, -1.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4043976664543152
Epoch 0, Step 611: train/loss = 0.19903168082237244, train/raw-loss = 0.11508263647556305, train/logprobs = tensor([[-1.6517, -4.5512],
        [-3.3006, -0.8437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33579614758491516
Epoch 0, Step 612: train/loss = 0.37509578466415405, train/raw-loss = 0.2865367829799652, train/logprobs = tensor([[-1.1038, -5.8032],
        [-2.0466, -1.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35423606634140015
Epoch 0, Step 613: train/loss = 0.352466344833374, train/raw-loss = 0.2657754123210907, train/logprobs = tensor([[-1.3248, -4.1919],
        [-3.0422, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3467636704444885
Epoch 0, Step 614: train/loss = 0.33638882637023926, train/raw-loss = 0.2400554120540619, train/logprobs = tensor([[-2.4782, -5.6990],
        [-3.5125, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38533371686935425
Epoch 0, Step 615: train/loss = 0.4997257590293884, train/raw-loss = 0.3950127363204956, train/logprobs = tensor([[-1.0474, -4.7403],
        [-2.5937, -2.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41885215044021606
Epoch 0, Step 616: train/loss = 0.45625680685043335, train/raw-loss = 0.37872791290283203, train/logprobs = tensor([[-2.0943, -4.6570],
        [-5.0747, -2.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101155757904053
Epoch 0, Step 617: train/loss = 0.1852423995733261, train/raw-loss = 0.07890021800994873, train/logprobs = tensor([[-1.2667, -5.4706],
        [-3.6351, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42536869645118713
Epoch 0, Step 618: train/loss = 0.23580938577651978, train/raw-loss = 0.15919357538223267, train/logprobs = tensor([[-1.0606, -5.7966],
        [-3.5105, -1.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064633011817932
Epoch 0, Step 619: train/loss = 0.34198105335235596, train/raw-loss = 0.24465079605579376, train/logprobs = tensor([[-1.3504, -3.4392],
        [-3.6496, -1.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38932108879089355
Epoch 0, Step 620: train/loss = 0.5593626499176025, train/raw-loss = 0.47390812635421753, train/logprobs = tensor([[-0.8939, -2.6882],
        [-2.1206, -2.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34181830286979675
Epoch 0, Step 621: train/loss = 0.49404364824295044, train/raw-loss = 0.41436028480529785, train/logprobs = tensor([[-1.3421, -4.5241],
        [-1.5366, -1.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3187333941459656
Epoch 0, Step 622: train/loss = 0.18302473425865173, train/raw-loss = 0.09914723038673401, train/logprobs = tensor([[-1.1449, -6.8946],
        [-3.2985, -1.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3355100154876709
Epoch 0, Step 623: train/loss = 0.33133387565612793, train/raw-loss = 0.25010794401168823, train/logprobs = tensor([[-1.8523, -3.2735],
        [-4.0589, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32490384578704834
Epoch 0, Step 624: train/loss = 0.23747441172599792, train/raw-loss = 0.16208796203136444, train/logprobs = tensor([[-1.3017, -6.9369],
        [-3.4357, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30154576897621155
Epoch 0, Step 625: train/loss = 0.5683886408805847, train/raw-loss = 0.5084444284439087, train/logprobs = tensor([[-0.8082, -3.3570],
        [-1.3942, -1.8706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23977695405483246
Epoch 0, Step 626: train/loss = 0.16355440020561218, train/raw-loss = 0.07253551483154297, train/logprobs = tensor([[-1.3164, -5.8020],
        [-4.3877, -1.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3640754818916321
Epoch 0, Step 627: train/loss = 0.667445719242096, train/raw-loss = 0.5791621208190918, train/logprobs = tensor([[-1.0549, -4.1818],
        [-2.7583, -2.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35313430428504944
Epoch 0, Step 628: train/loss = 0.5601426959037781, train/raw-loss = 0.46100324392318726, train/logprobs = tensor([[-0.9421, -2.8378],
        [-2.5296, -1.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39655786752700806
Epoch 0, Step 629: train/loss = 0.5996485352516174, train/raw-loss = 0.529506266117096, train/logprobs = tensor([[-2.2088, -2.6127],
        [-2.9135, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28056901693344116
Epoch 0, Step 630: train/loss = 0.3419218063354492, train/raw-loss = 0.2584037184715271, train/logprobs = tensor([[-1.2833, -3.5211],
        [-3.1089, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3340723514556885
Epoch 0, Step 631: train/loss = 0.5067967176437378, train/raw-loss = 0.42557990550994873, train/logprobs = tensor([[-1.5053, -3.7541],
        [-1.8287, -1.3569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.324867308139801
Epoch 0, Step 632: train/loss = 0.26620811223983765, train/raw-loss = 0.1777786761522293, train/logprobs = tensor([[-1.0793, -6.9645],
        [-1.9935, -1.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3537178039550781
Epoch 0, Step 633: train/loss = 0.15746915340423584, train/raw-loss = 0.05832609906792641, train/logprobs = tensor([[-1.2246, -6.5511],
        [-3.5199, -1.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39657217264175415
Epoch 0, Step 634: train/loss = 0.4568917751312256, train/raw-loss = 0.3725570738315582, train/logprobs = tensor([[-1.3817, -3.2307],
        [-3.2862, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3373386859893799
Epoch 0, Step 635: train/loss = 0.7469018697738647, train/raw-loss = 0.6555529236793518, train/logprobs = tensor([[-2.2937, -3.3051],
        [-3.7721, -2.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36539584398269653
Epoch 0, Step 636: train/loss = 0.8008490204811096, train/raw-loss = 0.7233522534370422, train/logprobs = tensor([[-1.2805, -3.5137],
        [-4.4531, -2.9367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30998703837394714
Epoch 0, Step 637: train/loss = 0.39854440093040466, train/raw-loss = 0.32911866903305054, train/logprobs = tensor([[-2.7737, -6.2248],
        [-3.1277, -2.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2777029871940613
Epoch 0, Step 638: train/loss = 0.3427193760871887, train/raw-loss = 0.25691452622413635, train/logprobs = tensor([[-2.1590, -5.6980],
        [-4.8599, -2.6564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3432193994522095
Epoch 0, Step 639: train/loss = 0.3351951241493225, train/raw-loss = 0.24409499764442444, train/logprobs = tensor([[-1.1083, -4.4479],
        [-3.1934, -0.8489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36440056562423706
Epoch 0, Step 640: train/loss = 0.2496730089187622, train/raw-loss = 0.15448039770126343, train/logprobs = tensor([[-0.8302, -5.2728],
        [-2.3303, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3807704746723175
Epoch 0, Step 641: train/loss = 0.6097807884216309, train/raw-loss = 0.5197256207466125, train/logprobs = tensor([[-2.3899, -2.3437],
        [-3.8224, -1.2759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36022070050239563
Epoch 0, Step 642: train/loss = 0.1748228669166565, train/raw-loss = 0.08784472942352295, train/logprobs = tensor([[-1.5646, -6.7218],
        [-3.5076, -2.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3479125201702118
Epoch 0, Step 643: train/loss = 0.6062115430831909, train/raw-loss = 0.505026638507843, train/logprobs = tensor([[-1.5948, -4.5012],
        [-4.8699, -2.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047394394874573
Epoch 0, Step 644: train/loss = 0.457692950963974, train/raw-loss = 0.371412456035614, train/logprobs = tensor([[-2.0671, -3.8449],
        [-2.8173, -2.2348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3451220691204071
Epoch 0, Step 645: train/loss = 0.5779321193695068, train/raw-loss = 0.4795601963996887, train/logprobs = tensor([[-0.8980, -2.2864],
        [-2.0617, -1.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3934876620769501
Epoch 0, Step 646: train/loss = 0.5484927892684937, train/raw-loss = 0.47291985154151917, train/logprobs = tensor([[-2.4612, -2.8980],
        [-4.3637, -2.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022918999195099
Epoch 0, Step 647: train/loss = 0.379509299993515, train/raw-loss = 0.29263836145401, train/logprobs = tensor([[-1.7397, -3.6270],
        [-4.0217, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34748375415802
Epoch 0, Step 648: train/loss = 0.23556283116340637, train/raw-loss = 0.14439192414283752, train/logprobs = tensor([[-1.2035, -5.0790],
        [-3.2915, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3646836578845978
Epoch 0, Step 649: train/loss = 0.16185146570205688, train/raw-loss = 0.06799881160259247, train/logprobs = tensor([[-1.8792, -6.5245],
        [-4.0140, -1.4212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37541061639785767
Epoch 0, Step 650: train/loss = 0.14771154522895813, train/raw-loss = 0.05448199063539505, train/logprobs = tensor([[-1.1903, -5.0569],
        [-4.6899, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729182183742523
Epoch 0, Step 651: train/loss = 0.579308807849884, train/raw-loss = 0.4877766966819763, train/logprobs = tensor([[-0.8563, -2.4232],
        [-3.0857, -1.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36612850427627563
Epoch 0, Step 652: train/loss = 0.15064388513565063, train/raw-loss = 0.04773631691932678, train/logprobs = tensor([[-1.3271, -7.5312],
        [-4.0439, -1.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.411630243062973
Epoch 0, Step 653: train/loss = 0.5222994685173035, train/raw-loss = 0.4340938925743103, train/logprobs = tensor([[-0.8315, -4.4336],
        [-1.9216, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35282236337661743
Epoch 0, Step 654: train/loss = 0.3038784861564636, train/raw-loss = 0.21481889486312866, train/logprobs = tensor([[-0.9914, -5.2116],
        [-2.7745, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35623836517333984
Epoch 0, Step 655: train/loss = 0.27797842025756836, train/raw-loss = 0.1893245130777359, train/logprobs = tensor([[-1.4730, -5.5928],
        [-4.0855, -1.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35461559891700745
Epoch 0, Step 656: train/loss = 0.29935339093208313, train/raw-loss = 0.19852913916110992, train/logprobs = tensor([[-0.9428, -5.9547],
        [-2.0968, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4032970666885376
Epoch 0, Step 657: train/loss = 0.1507430523633957, train/raw-loss = 0.04824702814221382, train/logprobs = tensor([[-1.2606, -7.0302],
        [-4.0051, -1.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4099840819835663
Epoch 0, Step 658: train/loss = 0.4776793122291565, train/raw-loss = 0.3922020196914673, train/logprobs = tensor([[-1.4415, -3.3738],
        [-3.1359, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.341909259557724
Epoch 0, Step 659: train/loss = 0.31120556592941284, train/raw-loss = 0.21482595801353455, train/logprobs = tensor([[-1.1881, -4.7673],
        [-3.3877, -1.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38551849126815796
Epoch 0, Step 660: train/loss = 0.2661924362182617, train/raw-loss = 0.17861180007457733, train/logprobs = tensor([[-1.3168, -5.1210],
        [-3.1282, -1.7447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35032257437705994
Epoch 0, Step 661: train/loss = 0.42000317573547363, train/raw-loss = 0.3310660123825073, train/logprobs = tensor([[-0.8591, -3.4372],
        [-2.9244, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35574862360954285
Epoch 0, Step 662: train/loss = 0.23828434944152832, train/raw-loss = 0.12984398007392883, train/logprobs = tensor([[-1.0492, -7.4376],
        [-3.6758, -2.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4337615370750427
Epoch 0, Step 663: train/loss = 0.24430206418037415, train/raw-loss = 0.1697176694869995, train/logprobs = tensor([[-1.2267, -4.7829],
        [-2.9365, -1.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29833757877349854
Epoch 0, Step 664: train/loss = 0.24033531546592712, train/raw-loss = 0.15192238986492157, train/logprobs = tensor([[-1.3201, -5.5159],
        [-3.6620, -1.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536517024040222
Epoch 0, Step 665: train/loss = 0.19706903398036957, train/raw-loss = 0.10254150629043579, train/logprobs = tensor([[-1.3455, -6.8374],
        [-3.2997, -1.2989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3781101405620575
Epoch 0, Step 666: train/loss = 0.35707157850265503, train/raw-loss = 0.2559005320072174, train/logprobs = tensor([[-1.7652, -3.3719],
        [-4.6268, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4046841561794281
Epoch 0, Step 667: train/loss = 0.3248407244682312, train/raw-loss = 0.23942330479621887, train/logprobs = tensor([[-1.4438, -4.9993],
        [-3.3877, -1.4459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34166979789733887
Epoch 0, Step 668: train/loss = 0.3948894441127777, train/raw-loss = 0.30893850326538086, train/logprobs = tensor([[-1.6516, -3.6991],
        [-3.4132, -1.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438038229942322
Epoch 0, Step 669: train/loss = 0.37058132886886597, train/raw-loss = 0.2610023021697998, train/logprobs = tensor([[-1.1865, -4.8608],
        [-3.4730, -1.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43831610679626465
Epoch 0, Step 670: train/loss = 0.2707350254058838, train/raw-loss = 0.1858883649110794, train/logprobs = tensor([[-1.6289, -5.7513],
        [-3.5744, -2.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33938661217689514
Epoch 0, Step 671: train/loss = 0.5100445747375488, train/raw-loss = 0.42496904730796814, train/logprobs = tensor([[-1.6508, -3.2686],
        [-3.2238, -1.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34030184149742126
Epoch 0, Step 672: train/loss = 0.5108263492584229, train/raw-loss = 0.40478190779685974, train/logprobs = tensor([[-1.3837, -1.9549],
        [-4.3203, -1.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4241776168346405
Epoch 0, Step 673: train/loss = 0.5469246506690979, train/raw-loss = 0.4710555672645569, train/logprobs = tensor([[-1.2481, -2.2014],
        [-2.7093, -1.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30347639322280884
Epoch 0, Step 674: train/loss = 0.23369109630584717, train/raw-loss = 0.145623117685318, train/logprobs = tensor([[-0.9479, -5.4816],
        [-2.9904, -1.3783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522718846797943
Epoch 0, Step 675: train/loss = 0.14395320415496826, train/raw-loss = 0.04390193521976471, train/logprobs = tensor([[-1.8761, -7.5421],
        [-4.6077, -2.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40020501613616943
Epoch 0, Step 676: train/loss = 0.309821218252182, train/raw-loss = 0.22836725413799286, train/logprobs = tensor([[-1.8264, -8.4341],
        [-4.0914, -1.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32581594586372375
Epoch 0, Step 677: train/loss = 0.1925332248210907, train/raw-loss = 0.10610395669937134, train/logprobs = tensor([[-1.3112, -5.6153],
        [-3.2386, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34571707248687744
Epoch 0, Step 678: train/loss = 0.5463298559188843, train/raw-loss = 0.4544577896595001, train/logprobs = tensor([[-2.6853, -5.0224],
        [-4.5169, -2.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3674880862236023
Epoch 0, Step 679: train/loss = 0.16691085696220398, train/raw-loss = 0.0642513558268547, train/logprobs = tensor([[-1.6130, -8.7176],
        [-3.9303, -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106379747390747
Epoch 0, Step 680: train/loss = 0.175866961479187, train/raw-loss = 0.0936170369386673, train/logprobs = tensor([[-1.5041, -5.3401],
        [-4.3723, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3289996385574341
Epoch 0, Step 681: train/loss = 0.2828771471977234, train/raw-loss = 0.19419917464256287, train/logprobs = tensor([[-1.1848, -5.6519],
        [-2.7439, -1.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3547118604183197
Epoch 0, Step 682: train/loss = 0.30219095945358276, train/raw-loss = 0.22378307580947876, train/logprobs = tensor([[-1.2578, -4.9030],
        [-2.9210, -1.5362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31363150477409363
Epoch 0, Step 683: train/loss = 0.4691316485404968, train/raw-loss = 0.38668620586395264, train/logprobs = tensor([[-0.9414, -2.0724],
        [-2.8741, -1.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3297819495201111
Epoch 0, Step 684: train/loss = 0.4419686794281006, train/raw-loss = 0.3397410213947296, train/logprobs = tensor([[-1.6968, -5.8398],
        [-4.1059, -1.5327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4089106321334839
Epoch 0, Step 685: train/loss = 0.624754786491394, train/raw-loss = 0.5451339483261108, train/logprobs = tensor([[-1.9016, -3.7989],
        [-2.8075, -2.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184833526611328
Epoch 0, Step 686: train/loss = 0.31774261593818665, train/raw-loss = 0.21051263809204102, train/logprobs = tensor([[-0.9886, -4.6215],
        [-3.1401, -1.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4289199113845825
Epoch 0, Step 687: train/loss = 0.3166402578353882, train/raw-loss = 0.23251760005950928, train/logprobs = tensor([[-1.0151, -3.4269],
        [-3.5150, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364906311035156
Epoch 0, Step 688: train/loss = 0.16730962693691254, train/raw-loss = 0.0734083503484726, train/logprobs = tensor([[-1.0867, -6.1099],
        [-3.9249, -1.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37560519576072693
Epoch 0, Step 689: train/loss = 0.1963118463754654, train/raw-loss = 0.08539574593305588, train/logprobs = tensor([[-0.9208, -6.3416],
        [-3.1175, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4436643719673157
Epoch 0, Step 690: train/loss = 0.4174990653991699, train/raw-loss = 0.31163594126701355, train/logprobs = tensor([[-1.9524, -4.7610],
        [-3.2145, -1.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42345237731933594
Epoch 0, Step 691: train/loss = 0.333126425743103, train/raw-loss = 0.23452727496623993, train/logprobs = tensor([[-1.8254, -6.0693],
        [-3.4910, -2.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3943966031074524
Epoch 0, Step 692: train/loss = 0.2488747537136078, train/raw-loss = 0.15844300389289856, train/logprobs = tensor([[-1.1500, -5.4110],
        [-2.6007, -1.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617270290851593
Epoch 0, Step 693: train/loss = 0.48944640159606934, train/raw-loss = 0.41009610891342163, train/logprobs = tensor([[-1.1830, -2.9208],
        [-2.6274, -1.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31740105152130127
Epoch 0, Step 694: train/loss = 0.34625324606895447, train/raw-loss = 0.27257412672042847, train/logprobs = tensor([[-2.2743, -3.8465],
        [-4.3441, -1.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.294716477394104
Epoch 0, Step 695: train/loss = 0.4228723645210266, train/raw-loss = 0.3404734134674072, train/logprobs = tensor([[-2.5600, -4.0401],
        [-4.8675, -1.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32959574460983276
Epoch 0, Step 696: train/loss = 0.22541674971580505, train/raw-loss = 0.13370689749717712, train/logprobs = tensor([[-1.4572, -5.7550],
        [-3.7578, -1.2081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3668394088745117
Epoch 0, Step 697: train/loss = 0.3641899824142456, train/raw-loss = 0.29270288348197937, train/logprobs = tensor([[-1.9836, -4.3077],
        [-3.8140, -0.8959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28594836592674255
Epoch 0, Step 698: train/loss = 0.2286202311515808, train/raw-loss = 0.1446046531200409, train/logprobs = tensor([[-1.3608, -5.8646],
        [-3.5220, -2.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3360622525215149
Epoch 0, Step 699: train/loss = 0.22171849012374878, train/raw-loss = 0.12688837945461273, train/logprobs = tensor([[-1.3605, -6.8993],
        [-4.0889, -2.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37932050228118896
Epoch 0, Step 700: train/loss = 0.16006454825401306, train/raw-loss = 0.06837096810340881, train/logprobs = tensor([[-1.4762, -7.8766],
        [-4.0575, -1.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3667743504047394
Epoch 0, Step 701: train/loss = 0.614224910736084, train/raw-loss = 0.507319986820221, train/logprobs = tensor([[-1.4588, -3.0645],
        [-3.2168, -1.5239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4276197552680969
Epoch 0, Step 702: train/loss = 0.4979185163974762, train/raw-loss = 0.4399852454662323, train/logprobs = tensor([[-1.5700, -4.0624],
        [-2.0967, -2.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23173290491104126
Epoch 0, Step 703: train/loss = 0.35744625329971313, train/raw-loss = 0.26465511322021484, train/logprobs = tensor([[-1.8457, -2.5902],
        [-4.5734, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37116459012031555
Epoch 0, Step 704: train/loss = 0.16081424057483673, train/raw-loss = 0.07894796133041382, train/logprobs = tensor([[-1.4932, -6.5229],
        [-4.4395, -1.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32746511697769165
Epoch 0, Step 705: train/loss = 0.2571554481983185, train/raw-loss = 0.1733638346195221, train/logprobs = tensor([[-1.0868, -5.2022],
        [-3.5743, -1.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33516645431518555
Epoch 0, Step 706: train/loss = 0.5012403130531311, train/raw-loss = 0.4028615653514862, train/logprobs = tensor([[-0.7052, -3.8679],
        [-2.0007, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39351484179496765
Epoch 0, Step 707: train/loss = 0.16956183314323425, train/raw-loss = 0.07097592949867249, train/logprobs = tensor([[-1.1022, -6.6901],
        [-3.0530, -1.3677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39434364438056946
Epoch 0, Step 708: train/loss = 0.3397846519947052, train/raw-loss = 0.2609742283821106, train/logprobs = tensor([[-1.2024, -4.3928],
        [-3.6922, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3152416944503784
Epoch 0, Step 709: train/loss = 0.3301609456539154, train/raw-loss = 0.24852226674556732, train/logprobs = tensor([[-1.5821, -5.5835],
        [-2.6802, -1.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32655465602874756
Epoch 0, Step 710: train/loss = 0.163056418299675, train/raw-loss = 0.05721225216984749, train/logprobs = tensor([[-1.3793, -6.1008],
        [-4.3275, -2.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4233767092227936
Epoch 0, Step 711: train/loss = 0.3377074897289276, train/raw-loss = 0.256964772939682, train/logprobs = tensor([[-1.3755, -4.1787],
        [-3.0548, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3229709565639496
Epoch 0, Step 712: train/loss = 0.4779285192489624, train/raw-loss = 0.3881119191646576, train/logprobs = tensor([[-1.5504, -5.0927],
        [-4.5491, -3.0189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3592662215232849
Epoch 0, Step 713: train/loss = 0.18409842252731323, train/raw-loss = 0.11038140952587128, train/logprobs = tensor([[-1.0918, -7.1592],
        [-2.5265, -1.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2948680520057678
Epoch 0, Step 714: train/loss = 0.42995837330818176, train/raw-loss = 0.3138725757598877, train/logprobs = tensor([[-1.1084, -6.9420],
        [-3.5110, -2.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46434324979782104
Epoch 0, Step 715: train/loss = 0.259885311126709, train/raw-loss = 0.17254820466041565, train/logprobs = tensor([[-2.0055, -5.8070],
        [-3.2205, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34934842586517334
Epoch 0, Step 716: train/loss = 0.24672695994377136, train/raw-loss = 0.148668110370636, train/logprobs = tensor([[-1.5404, -2.6578],
        [-5.2422, -0.9686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3922354578971863
Epoch 0, Step 717: train/loss = 0.37821558117866516, train/raw-loss = 0.3021186292171478, train/logprobs = tensor([[-1.1038, -5.2131],
        [-2.2627, -1.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3043878972530365
Epoch 0, Step 718: train/loss = 0.15877528488636017, train/raw-loss = 0.07377985864877701, train/logprobs = tensor([[-1.3498, -9.4268],
        [-3.7276, -1.2433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33998167514801025
Epoch 0, Step 719: train/loss = 0.17411412298679352, train/raw-loss = 0.0844576358795166, train/logprobs = tensor([[-1.9518, -4.6723],
        [-5.6080, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35862594842910767
Epoch 0, Step 720: train/loss = 0.36685556173324585, train/raw-loss = 0.2745378911495209, train/logprobs = tensor([[-1.1838, -4.3486],
        [-2.9839, -1.3594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36927077174186707
Epoch 0, Step 721: train/loss = 0.3922558128833771, train/raw-loss = 0.31556880474090576, train/logprobs = tensor([[-1.6798, -4.6705],
        [-3.0862, -1.3329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30674803256988525
Epoch 0, Step 722: train/loss = 0.30252325534820557, train/raw-loss = 0.223519966006279, train/logprobs = tensor([[-1.3167, -4.8393],
        [-2.6965, -1.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160131573677063
Epoch 0, Step 723: train/loss = 0.4976157546043396, train/raw-loss = 0.41285061836242676, train/logprobs = tensor([[-1.1237, -4.4166],
        [-2.3898, -2.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390604257583618
Epoch 0, Step 724: train/loss = 0.32050102949142456, train/raw-loss = 0.2410738617181778, train/logprobs = tensor([[-0.9409, -6.4356],
        [-2.1294, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31770873069763184
Epoch 0, Step 725: train/loss = 0.31454771757125854, train/raw-loss = 0.23294605314731598, train/logprobs = tensor([[-1.9859, -3.1680],
        [-4.0887, -1.3784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32640665769577026
Epoch 0, Step 726: train/loss = 0.5483644604682922, train/raw-loss = 0.4488334655761719, train/logprobs = tensor([[-1.2158, -3.1775],
        [-3.9366, -1.7892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39812397956848145
Epoch 0, Step 727: train/loss = 0.3791557848453522, train/raw-loss = 0.29079559445381165, train/logprobs = tensor([[-1.0605, -4.8224],
        [-3.6804, -2.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35344088077545166
Epoch 0, Step 728: train/loss = 0.34889474511146545, train/raw-loss = 0.27650874853134155, train/logprobs = tensor([[-1.1881, -5.9538],
        [-3.1904, -2.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895439565181732
Epoch 0, Step 729: train/loss = 0.42842376232147217, train/raw-loss = 0.35451871156692505, train/logprobs = tensor([[-1.0800, -3.3017],
        [-2.6984, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956201136112213
Epoch 0, Step 730: train/loss = 0.4046494960784912, train/raw-loss = 0.3430926203727722, train/logprobs = tensor([[-1.9115, -3.0525],
        [-3.2045, -1.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24622765183448792
Epoch 0, Step 731: train/loss = 0.28201255202293396, train/raw-loss = 0.1988738626241684, train/logprobs = tensor([[-2.0454, -4.2077],
        [-6.0441, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33255472779273987
Epoch 0, Step 732: train/loss = 0.17851406335830688, train/raw-loss = 0.09529170393943787, train/logprobs = tensor([[-2.2571, -6.7463],
        [-5.1298, -2.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33288946747779846
Epoch 0, Step 733: train/loss = 0.5185070037841797, train/raw-loss = 0.45363035798072815, train/logprobs = tensor([[-1.7017, -3.7413],
        [-2.8647, -2.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2595064640045166
Epoch 0, Step 734: train/loss = 0.30324095487594604, train/raw-loss = 0.22721682488918304, train/logprobs = tensor([[-0.8336, -5.3150],
        [-2.7754, -1.6680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304096519947052
Epoch 0, Step 735: train/loss = 0.2892739772796631, train/raw-loss = 0.20279298722743988, train/logprobs = tensor([[-1.5201, -4.6349],
        [-3.9431, -1.5338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3459240198135376
Epoch 0, Step 736: train/loss = 0.37403199076652527, train/raw-loss = 0.2872435450553894, train/logprobs = tensor([[-1.6914, -2.5426],
        [-3.5102, -1.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34715384244918823
Epoch 0, Step 737: train/loss = 0.22066253423690796, train/raw-loss = 0.13174811005592346, train/logprobs = tensor([[-1.4406, -5.1166],
        [-4.8755, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556576669216156
Epoch 0, Step 738: train/loss = 0.22537267208099365, train/raw-loss = 0.12909035384655, train/logprobs = tensor([[-1.0607, -5.6770],
        [-3.4012, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38512927293777466
Epoch 0, Step 739: train/loss = 0.5188992023468018, train/raw-loss = 0.4332488179206848, train/logprobs = tensor([[-0.9446, -2.9148],
        [-3.0603, -1.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34260156750679016
Epoch 0, Step 740: train/loss = 0.43071264028549194, train/raw-loss = 0.3337101340293884, train/logprobs = tensor([[-1.7621, -3.1188],
        [-3.7559, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3880101442337036
Epoch 0, Step 741: train/loss = 0.3164144456386566, train/raw-loss = 0.24199803173542023, train/logprobs = tensor([[-1.4635, -4.7361],
        [-2.7420, -1.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29766565561294556
Epoch 0, Step 742: train/loss = 0.32202160358428955, train/raw-loss = 0.22746354341506958, train/logprobs = tensor([[-1.0384, -5.6564],
        [-2.6318, -1.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3782322108745575
Epoch 0, Step 743: train/loss = 0.6267382502555847, train/raw-loss = 0.5389657616615295, train/logprobs = tensor([[-0.9606, -3.7068],
        [-2.0311, -2.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35108962655067444
Epoch 0, Step 744: train/loss = 0.34376901388168335, train/raw-loss = 0.27177512645721436, train/logprobs = tensor([[-1.1707, -3.7309],
        [-2.1193, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2879756689071655
Epoch 0, Step 745: train/loss = 0.6015458106994629, train/raw-loss = 0.5268338322639465, train/logprobs = tensor([[-1.7770, -4.9659],
        [-4.7306, -2.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29884785413742065
Epoch 0, Step 746: train/loss = 0.18206003308296204, train/raw-loss = 0.0856899619102478, train/logprobs = tensor([[-0.6179, -8.2767],
        [-2.3466, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3854803144931793
Epoch 0, Step 747: train/loss = 0.22400517761707306, train/raw-loss = 0.15574237704277039, train/logprobs = tensor([[-1.5241, -3.5869],
        [-4.2345, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730512022972107
Epoch 0, Step 748: train/loss = 0.5247750878334045, train/raw-loss = 0.44135695695877075, train/logprobs = tensor([[-1.5393, -4.2198],
        [-4.5714, -2.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33367258310317993
Epoch 0, Step 749: train/loss = 0.3590748608112335, train/raw-loss = 0.28592216968536377, train/logprobs = tensor([[-1.4040, -4.2795],
        [-4.4401, -2.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2926107943058014
Epoch 0, Step 750: train/loss = 0.5627061724662781, train/raw-loss = 0.48257172107696533, train/logprobs = tensor([[-1.1670, -4.0768],
        [-2.7936, -2.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3205379545688629
Epoch 0, Step 751: train/loss = 0.1944449096918106, train/raw-loss = 0.09862718731164932, train/logprobs = tensor([[-2.4211, -5.1778],
        [-5.3742, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38327085971832275
Epoch 0, Step 752: train/loss = 0.4173871874809265, train/raw-loss = 0.3184950649738312, train/logprobs = tensor([[-0.8700, -5.8507],
        [-2.6188, -1.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3955683708190918
Epoch 0, Step 753: train/loss = 0.2729716897010803, train/raw-loss = 0.1800422966480255, train/logprobs = tensor([[-0.6337, -6.1671],
        [-2.0283, -1.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37171751260757446
Epoch 0, Step 754: train/loss = 0.13282448053359985, train/raw-loss = 0.048834428191185, train/logprobs = tensor([[-1.4830, -6.9982],
        [-3.8004, -1.2901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3359602093696594
Epoch 0, Step 755: train/loss = 0.21160686016082764, train/raw-loss = 0.12572205066680908, train/logprobs = tensor([[-1.4406, -4.4544],
        [-4.8423, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34353917837142944
Epoch 0, Step 756: train/loss = 0.32113462686538696, train/raw-loss = 0.23650263249874115, train/logprobs = tensor([[-2.9463, -7.0311],
        [-4.7629, -2.4176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3385279178619385
Epoch 0, Step 757: train/loss = 0.4926023781299591, train/raw-loss = 0.41705650091171265, train/logprobs = tensor([[-2.2511, -3.6935],
        [-3.3243, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021835684776306
Epoch 0, Step 758: train/loss = 0.3429834842681885, train/raw-loss = 0.23607800900936127, train/logprobs = tensor([[-0.9612, -6.0415],
        [-2.6804, -1.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4276219606399536
Epoch 0, Step 759: train/loss = 0.22025777399539948, train/raw-loss = 0.13795998692512512, train/logprobs = tensor([[-2.1360, -5.7940],
        [-4.3142, -1.7536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3291912376880646
Epoch 0, Step 760: train/loss = 0.10682412981987, train/raw-loss = 0.026866238564252853, train/logprobs = tensor([[-1.9291, -8.1544],
        [-5.8189, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319831520318985
Epoch 0, Step 761: train/loss = 0.14441964030265808, train/raw-loss = 0.0710027664899826, train/logprobs = tensor([[-1.3324, -7.2563],
        [-4.3413, -1.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2936674952507019
Epoch 0, Step 762: train/loss = 0.37388667464256287, train/raw-loss = 0.28951191902160645, train/logprobs = tensor([[-1.5404, -3.9181],
        [-3.3348, -1.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3374989628791809
Epoch 0, Step 763: train/loss = 0.4680194556713104, train/raw-loss = 0.38581162691116333, train/logprobs = tensor([[-1.2036, -3.8869],
        [-2.9659, -1.8044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3288314938545227
Epoch 0, Step 764: train/loss = 0.2507644295692444, train/raw-loss = 0.17123554646968842, train/logprobs = tensor([[-0.9537, -3.9925],
        [-3.6792, -1.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31811556220054626
Epoch 0, Step 765: train/loss = 0.2109590321779251, train/raw-loss = 0.1309746503829956, train/logprobs = tensor([[-1.0629, -5.9231],
        [-3.0562, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31993749737739563
Epoch 0, Step 766: train/loss = 0.12528520822525024, train/raw-loss = 0.05064328387379646, train/logprobs = tensor([[-1.2891, -5.2361],
        [-4.6369, -1.5540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2985677719116211
Epoch 0, Step 767: train/loss = 0.7725252509117126, train/raw-loss = 0.6758703589439392, train/logprobs = tensor([[-1.1885, -2.9346],
        [-3.8313, -2.6359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3866196274757385
Epoch 0, Step 768: train/loss = 0.4007887840270996, train/raw-loss = 0.3332516551017761, train/logprobs = tensor([[-1.3328, -4.9744],
        [-2.5353, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27014851570129395
Epoch 0, Step 769: train/loss = 0.28764355182647705, train/raw-loss = 0.21325761079788208, train/logprobs = tensor([[-1.2193, -5.1467],
        [-2.6781, -1.4244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29754379391670227
Epoch 0, Step 770: train/loss = 0.32921501994132996, train/raw-loss = 0.24894122779369354, train/logprobs = tensor([[-1.0364, -5.7297],
        [-2.0388, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3210951089859009
Epoch 0, Step 771: train/loss = 0.34356310963630676, train/raw-loss = 0.2782888114452362, train/logprobs = tensor([[-0.9749, -4.6597],
        [-2.4613, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610972821712494
Epoch 0, Step 772: train/loss = 0.4159964919090271, train/raw-loss = 0.3474779427051544, train/logprobs = tensor([[-1.8168, -6.1629],
        [-3.4742, -1.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740742564201355
Epoch 0, Step 773: train/loss = 0.2604312300682068, train/raw-loss = 0.1763487309217453, train/logprobs = tensor([[-1.8151, -3.7362],
        [-4.4908, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3363299071788788
Epoch 0, Step 774: train/loss = 0.4505111277103424, train/raw-loss = 0.384158194065094, train/logprobs = tensor([[-1.2102, -2.7167],
        [-3.1273, -1.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2654115855693817
Epoch 0, Step 775: train/loss = 0.460163414478302, train/raw-loss = 0.36733874678611755, train/logprobs = tensor([[-1.5395, -2.7625],
        [-3.6498, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37129858136177063
Epoch 0, Step 776: train/loss = 0.3196224868297577, train/raw-loss = 0.2600059509277344, train/logprobs = tensor([[-2.0688, -4.5294],
        [-4.4513, -1.3501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384660840034485
Epoch 0, Step 777: train/loss = 0.7090688943862915, train/raw-loss = 0.6267972588539124, train/logprobs = tensor([[-1.1998, -2.5868],
        [-4.1293, -2.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3290863633155823
Epoch 0, Step 778: train/loss = 0.31194496154785156, train/raw-loss = 0.22954963147640228, train/logprobs = tensor([[-1.3083, -4.7801],
        [-3.3636, -1.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32958126068115234
Epoch 0, Step 779: train/loss = 0.2810705006122589, train/raw-loss = 0.22369906306266785, train/logprobs = tensor([[-1.8551, -3.9773],
        [-4.2685, -1.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2294856756925583
Epoch 0, Step 780: train/loss = 0.18848678469657898, train/raw-loss = 0.10176984965801239, train/logprobs = tensor([[-0.9402, -6.6028],
        [-3.0449, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34686779975891113
Epoch 0, Step 781: train/loss = 0.272722065448761, train/raw-loss = 0.20307216048240662, train/logprobs = tensor([[-2.8302, -5.1153],
        [-4.7755, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785995900630951
Epoch 0, Step 782: train/loss = 0.16637355089187622, train/raw-loss = 0.07629069685935974, train/logprobs = tensor([[-0.7761, -6.6818],
        [-2.7451, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36033135652542114
Epoch 0, Step 783: train/loss = 0.46408402919769287, train/raw-loss = 0.37782639265060425, train/logprobs = tensor([[-2.6526, -4.0347],
        [-3.7160, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34503036737442017
Epoch 0, Step 784: train/loss = 0.35706526041030884, train/raw-loss = 0.2699068486690521, train/logprobs = tensor([[-0.6030, -6.3551],
        [-1.9719, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34863361716270447
Epoch 0, Step 785: train/loss = 0.2655984163284302, train/raw-loss = 0.18879690766334534, train/logprobs = tensor([[-2.6400, -4.7809],
        [-4.6536, -1.3523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30720603466033936
Epoch 0, Step 786: train/loss = 0.2894218862056732, train/raw-loss = 0.20286928117275238, train/logprobs = tensor([[-1.4088, -2.7512],
        [-5.0021, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462103605270386
Epoch 0, Step 787: train/loss = 0.3745715916156769, train/raw-loss = 0.28849607706069946, train/logprobs = tensor([[-1.3852, -4.4666],
        [-4.5389, -1.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3443021774291992
Epoch 0, Step 788: train/loss = 0.34675905108451843, train/raw-loss = 0.26377072930336, train/logprobs = tensor([[-1.3395, -4.5883],
        [-3.9713, -1.3690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319532573223114
Epoch 0, Step 789: train/loss = 0.4485780894756317, train/raw-loss = 0.38007181882858276, train/logprobs = tensor([[-2.0408, -3.6292],
        [-3.4719, -2.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2740250527858734
Epoch 0, Step 790: train/loss = 0.44527333974838257, train/raw-loss = 0.35893768072128296, train/logprobs = tensor([[-1.7147, -4.3475],
        [-3.7047, -2.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34534239768981934
Epoch 0, Step 791: train/loss = 0.3444461524486542, train/raw-loss = 0.271564245223999, train/logprobs = tensor([[-0.7716, -5.2195],
        [-2.4860, -1.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2915276288986206
Epoch 0, Step 792: train/loss = 0.33734554052352905, train/raw-loss = 0.24008192121982574, train/logprobs = tensor([[-1.4679, -3.2466],
        [-4.9995, -1.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3890545666217804
Epoch 0, Step 793: train/loss = 0.29991915822029114, train/raw-loss = 0.22647006809711456, train/logprobs = tensor([[-1.0647, -4.5045],
        [-2.5699, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937963604927063
Epoch 0, Step 794: train/loss = 0.19169388711452484, train/raw-loss = 0.11461172997951508, train/logprobs = tensor([[-1.0227, -5.8225],
        [-3.2453, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30832868814468384
Epoch 0, Step 795: train/loss = 0.38363122940063477, train/raw-loss = 0.2911788821220398, train/logprobs = tensor([[-1.1719, -3.0854],
        [-4.4647, -1.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3698093891143799
Epoch 0, Step 796: train/loss = 0.24945491552352905, train/raw-loss = 0.17325203120708466, train/logprobs = tensor([[-1.5607, -4.5852],
        [-4.7752, -2.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3048115074634552
Epoch 0, Step 797: train/loss = 0.18317678570747375, train/raw-loss = 0.10421230643987656, train/logprobs = tensor([[-0.9228, -4.1182],
        [-4.0224, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158579468727112
Epoch 0, Step 798: train/loss = 0.32501935958862305, train/raw-loss = 0.25689202547073364, train/logprobs = tensor([[-1.1546, -4.2354],
        [-2.3350, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27250921726226807
Epoch 0, Step 799: train/loss = 0.4845476448535919, train/raw-loss = 0.3889978528022766, train/logprobs = tensor([[-0.8874, -4.1503],
        [-2.6178, -1.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3821992576122284
Epoch 0, Step 800: train/loss = 0.5601999759674072, train/raw-loss = 0.4766446352005005, train/logprobs = tensor([[-1.1872, -1.6158],
        [-3.5810, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3342212438583374
Epoch 0, Step 801: train/loss = 0.347159743309021, train/raw-loss = 0.283783495426178, train/logprobs = tensor([[-1.0879, -6.0058],
        [-1.4916, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535048723220825
Epoch 0, Step 802: train/loss = 0.39700061082839966, train/raw-loss = 0.33974915742874146, train/logprobs = tensor([[-0.9821, -3.9937],
        [-1.9271, -1.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2290058732032776
Epoch 0, Step 803: train/loss = 0.6372357606887817, train/raw-loss = 0.5540123581886292, train/logprobs = tensor([[-0.9143, -1.6148],
        [-2.4403, -2.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3328937888145447
Epoch 0, Step 804: train/loss = 0.4877939224243164, train/raw-loss = 0.42116981744766235, train/logprobs = tensor([[-0.8983, -4.6717],
        [-1.5935, -1.3355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26649630069732666
Epoch 0, Step 805: train/loss = 0.39573943614959717, train/raw-loss = 0.3334988057613373, train/logprobs = tensor([[-1.2735, -5.5921],
        [-2.4326, -1.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24896258115768433
Epoch 0, Step 806: train/loss = 0.3940027058124542, train/raw-loss = 0.32391291856765747, train/logprobs = tensor([[-1.0211, -3.0673],
        [-2.8899, -1.4101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2803592085838318
Epoch 0, Step 807: train/loss = 0.4987965226173401, train/raw-loss = 0.4340437650680542, train/logprobs = tensor([[-1.8382, -3.7340],
        [-3.9407, -2.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25901103019714355
Epoch 0, Step 808: train/loss = 0.21284371614456177, train/raw-loss = 0.15137413144111633, train/logprobs = tensor([[-1.9636, -6.0887],
        [-3.9695, -1.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24587832391262054
Epoch 0, Step 809: train/loss = 0.7675372958183289, train/raw-loss = 0.6594018936157227, train/logprobs = tensor([[-1.0546, -1.2236],
        [-2.7881, -2.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43254154920578003
Epoch 0, Step 810: train/loss = 0.516862154006958, train/raw-loss = 0.44266507029533386, train/logprobs = tensor([[-2.6125, -4.0506],
        [-4.0382, -1.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29678818583488464
Epoch 0, Step 811: train/loss = 0.33048149943351746, train/raw-loss = 0.2576647698879242, train/logprobs = tensor([[-0.8454, -4.0464],
        [-2.7502, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2912669777870178
Epoch 0, Step 812: train/loss = 0.3520786166191101, train/raw-loss = 0.28675195574760437, train/logprobs = tensor([[-1.6982, -4.4280],
        [-3.2482, -1.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2613067924976349
Epoch 0, Step 813: train/loss = 0.2454254925251007, train/raw-loss = 0.16283464431762695, train/logprobs = tensor([[-1.4870, -5.5262],
        [-3.5872, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330363392829895
Epoch 0, Step 814: train/loss = 0.3413790762424469, train/raw-loss = 0.2840949296951294, train/logprobs = tensor([[-1.8546, -4.2532],
        [-3.3502, -1.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2291366159915924
Epoch 0, Step 815: train/loss = 0.20791086554527283, train/raw-loss = 0.1272001564502716, train/logprobs = tensor([[-1.0986, -5.0784],
        [-3.0815, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3228428065776825
Epoch 0, Step 816: train/loss = 0.35263702273368835, train/raw-loss = 0.28615134954452515, train/logprobs = tensor([[-2.5859, -6.1204],
        [-3.4952, -1.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659427523612976
Epoch 0, Step 817: train/loss = 0.32896602153778076, train/raw-loss = 0.245563805103302, train/logprobs = tensor([[-0.9255, -4.9862],
        [-3.5584, -1.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33360883593559265
Epoch 0, Step 818: train/loss = 0.265008807182312, train/raw-loss = 0.19807229936122894, train/logprobs = tensor([[-1.7189, -3.6835],
        [-4.1371, -0.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26774609088897705
Epoch 0, Step 819: train/loss = 0.17976947128772736, train/raw-loss = 0.10948367416858673, train/logprobs = tensor([[-1.5730, -5.7018],
        [-4.4785, -0.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2811431884765625
Epoch 0, Step 820: train/loss = 0.2492665946483612, train/raw-loss = 0.1731092631816864, train/logprobs = tensor([[-0.9138, -6.0535],
        [-3.1426, -1.5021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304629385471344
Epoch 0, Step 821: train/loss = 0.24764516949653625, train/raw-loss = 0.17304009199142456, train/logprobs = tensor([[-1.3609, -5.3555],
        [-4.0462, -1.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29842036962509155
Epoch 0, Step 822: train/loss = 0.2136557400226593, train/raw-loss = 0.12704479694366455, train/logprobs = tensor([[-1.7110, -5.6911],
        [-4.3900, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.346443772315979
Epoch 0, Step 823: train/loss = 0.3154268264770508, train/raw-loss = 0.24005098640918732, train/logprobs = tensor([[-1.3869, -4.7103],
        [-3.9897, -1.4097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015032410621643
Epoch 0, Step 824: train/loss = 0.511012852191925, train/raw-loss = 0.427023708820343, train/logprobs = tensor([[-0.9712, -2.6451],
        [-3.0843, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33595648407936096
Epoch 0, Step 825: train/loss = 0.37697407603263855, train/raw-loss = 0.29819628596305847, train/logprobs = tensor([[-1.9365, -6.2415],
        [-3.8496, -1.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3151112198829651
Epoch 0, Step 826: train/loss = 0.25030410289764404, train/raw-loss = 0.1776304394006729, train/logprobs = tensor([[-1.0733, -6.2755],
        [-2.4059, -1.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29069459438323975
Epoch 0, Step 827: train/loss = 0.4510427713394165, train/raw-loss = 0.3661136329174042, train/logprobs = tensor([[-1.2850, -3.0725],
        [-3.9569, -1.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33971667289733887
Epoch 0, Step 828: train/loss = 0.4413813352584839, train/raw-loss = 0.3833308815956116, train/logprobs = tensor([[-1.9129, -3.9426],
        [-3.6718, -2.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23220184445381165
Epoch 0, Step 829: train/loss = 0.3041490316390991, train/raw-loss = 0.21743230521678925, train/logprobs = tensor([[-1.2592, -4.3431],
        [-4.8422, -1.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3468668758869171
Epoch 0, Step 830: train/loss = 0.4050484895706177, train/raw-loss = 0.31657874584198, train/logprobs = tensor([[-1.7389, -3.8688],
        [-3.2010, -1.6180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35387903451919556
Epoch 0, Step 831: train/loss = 0.33428123593330383, train/raw-loss = 0.2509830594062805, train/logprobs = tensor([[-1.8530, -2.8146],
        [-5.4839, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331926465034485
Epoch 0, Step 832: train/loss = 0.43254077434539795, train/raw-loss = 0.3515966534614563, train/logprobs = tensor([[-2.4988, -3.5043],
        [-4.4341, -2.2118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.323776513338089
Epoch 0, Step 833: train/loss = 0.59018474817276, train/raw-loss = 0.5229523181915283, train/logprobs = tensor([[-2.6368, -3.0658],
        [-3.8129, -1.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26892971992492676
Epoch 0, Step 834: train/loss = 0.2561108469963074, train/raw-loss = 0.1837083101272583, train/logprobs = tensor([[-1.0134, -6.0625],
        [-2.4686, -1.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896101772785187
Epoch 0, Step 835: train/loss = 0.3153032660484314, train/raw-loss = 0.25544822216033936, train/logprobs = tensor([[-1.5057, -3.9293],
        [-3.4295, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23942017555236816
Epoch 0, Step 836: train/loss = 0.5430504083633423, train/raw-loss = 0.46358880400657654, train/logprobs = tensor([[-1.1634, -3.0260],
        [-3.1102, -1.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3178465962409973
Epoch 0, Step 837: train/loss = 0.20683130621910095, train/raw-loss = 0.14163771271705627, train/logprobs = tensor([[-1.0637, -6.8984],
        [-2.2270, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26077431440353394
Epoch 0, Step 838: train/loss = 0.1656830906867981, train/raw-loss = 0.0857657864689827, train/logprobs = tensor([[-1.4867, -5.3546],
        [-4.6321, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31966912746429443
Epoch 0, Step 839: train/loss = 0.6578572392463684, train/raw-loss = 0.593628466129303, train/logprobs = tensor([[-1.3769, -1.3071],
        [-1.9871, -1.3150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25691524147987366
Epoch 0, Step 840: train/loss = 0.2013426125049591, train/raw-loss = 0.1352892518043518, train/logprobs = tensor([[-1.5807, -6.1574],
        [-3.6259, -1.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2642134428024292
Epoch 0, Step 841: train/loss = 0.30545830726623535, train/raw-loss = 0.2445114254951477, train/logprobs = tensor([[-1.3968, -5.6964],
        [-2.7333, -0.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24378754198551178
Epoch 0, Step 842: train/loss = 0.4351623058319092, train/raw-loss = 0.3642207384109497, train/logprobs = tensor([[-1.4921, -3.9658],
        [-2.0759, -1.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837662100791931
Epoch 0, Step 843: train/loss = 0.318075567483902, train/raw-loss = 0.24958571791648865, train/logprobs = tensor([[-0.9691, -6.3040],
        [-2.0355, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2739594578742981
Epoch 0, Step 844: train/loss = 0.48750126361846924, train/raw-loss = 0.4247030019760132, train/logprobs = tensor([[-1.6851, -3.2025],
        [-2.6370, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25119298696517944
Epoch 0, Step 845: train/loss = 0.4317300617694855, train/raw-loss = 0.37032970786094666, train/logprobs = tensor([[-1.0937, -4.5832],
        [-2.9599, -1.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24560144543647766
Epoch 0, Step 846: train/loss = 0.1880767047405243, train/raw-loss = 0.11253993958234787, train/logprobs = tensor([[-1.1973, -5.4597],
        [-4.2223, -1.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021470606327057
Epoch 0, Step 847: train/loss = 0.4140583276748657, train/raw-loss = 0.3432801067829132, train/logprobs = tensor([[-0.8017, -4.5094],
        [-1.9011, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831127643585205
Epoch 0, Step 848: train/loss = 0.7555487155914307, train/raw-loss = 0.6910392045974731, train/logprobs = tensor([[-2.9477, -5.9413],
        [-2.5108, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2580380141735077
Epoch 0, Step 849: train/loss = 0.21443277597427368, train/raw-loss = 0.14173127710819244, train/logprobs = tensor([[-1.3267, -4.6643],
        [-2.7769, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29080596566200256
Epoch 0, Step 850: train/loss = 0.28951525688171387, train/raw-loss = 0.22810998558998108, train/logprobs = tensor([[-1.7444, -4.6287],
        [-3.4354, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24562112987041473
Epoch 0, Step 851: train/loss = 0.43566566705703735, train/raw-loss = 0.3848190903663635, train/logprobs = tensor([[-0.9772, -5.2558],
        [-1.3469, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033863514661789
Epoch 0, Step 852: train/loss = 0.317874014377594, train/raw-loss = 0.24709279835224152, train/logprobs = tensor([[-2.0632, -5.1619],
        [-3.1744, -1.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2831249237060547
Epoch 0, Step 853: train/loss = 0.6301028728485107, train/raw-loss = 0.5703644752502441, train/logprobs = tensor([[-1.9003, -3.1515],
        [-2.3577, -2.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23895376920700073
Epoch 0, Step 854: train/loss = 0.4019770920276642, train/raw-loss = 0.32958000898361206, train/logprobs = tensor([[-0.6932, -2.2433],
        [-2.4453, -1.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2895883321762085
Epoch 0, Step 855: train/loss = 0.18887485563755035, train/raw-loss = 0.12217474728822708, train/logprobs = tensor([[-1.4751, -6.2570],
        [-4.0178, -1.2508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668004631996155
Epoch 0, Step 856: train/loss = 0.29036372900009155, train/raw-loss = 0.21875424683094025, train/logprobs = tensor([[-1.2290, -5.3815],
        [-3.1693, -1.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28643783926963806
Epoch 0, Step 857: train/loss = 0.5182222127914429, train/raw-loss = 0.46621158719062805, train/logprobs = tensor([[-1.6850, -3.5388],
        [-2.5595, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2080424726009369
Epoch 0, Step 858: train/loss = 0.42526549100875854, train/raw-loss = 0.3514540493488312, train/logprobs = tensor([[-0.9741, -3.6115],
        [-3.5558, -1.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952456772327423
Epoch 0, Step 859: train/loss = 0.35504788160324097, train/raw-loss = 0.3013409972190857, train/logprobs = tensor([[-1.2469, -3.6580],
        [-2.1759, -1.5439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21482765674591064
Epoch 0, Step 860: train/loss = 0.13711436092853546, train/raw-loss = 0.0643920972943306, train/logprobs = tensor([[-1.8359, -6.9951],
        [-5.2845, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29088908433914185
Epoch 0, Step 861: train/loss = 0.41548892855644226, train/raw-loss = 0.3519175946712494, train/logprobs = tensor([[-1.0957, -5.9802],
        [-1.5849, -1.3670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25428539514541626
Epoch 0, Step 862: train/loss = 0.42906877398490906, train/raw-loss = 0.3637089729309082, train/logprobs = tensor([[-1.2226, -3.6856],
        [-2.0041, -2.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614392638206482
Epoch 0, Step 863: train/loss = 0.2853611707687378, train/raw-loss = 0.2118382602930069, train/logprobs = tensor([[-0.9594, -6.1504],
        [-2.9843, -1.4766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29409170150756836
Epoch 0, Step 864: train/loss = 0.25001564621925354, train/raw-loss = 0.17313051223754883, train/logprobs = tensor([[-1.3130, -5.0792],
        [-3.6566, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30754056572914124
Epoch 0, Step 865: train/loss = 0.16209572553634644, train/raw-loss = 0.08783265948295593, train/logprobs = tensor([[-1.7324, -6.7492],
        [-4.7014, -1.5029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2970522344112396
Epoch 0, Step 866: train/loss = 0.5736355781555176, train/raw-loss = 0.5225629210472107, train/logprobs = tensor([[-2.4881, -2.1767],
        [-4.3958, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20429083704948425
Epoch 0, Step 867: train/loss = 0.16609187424182892, train/raw-loss = 0.10411860048770905, train/logprobs = tensor([[-0.9539, -7.4998],
        [-2.8052, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2478930652141571
Epoch 0, Step 868: train/loss = 0.6105868816375732, train/raw-loss = 0.5397750735282898, train/logprobs = tensor([[-1.3908, -3.3417],
        [-2.5338, -2.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28324732184410095
Epoch 0, Step 869: train/loss = 0.42613956332206726, train/raw-loss = 0.3686656057834625, train/logprobs = tensor([[-1.3658, -4.4341],
        [-2.8814, -1.3882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22989585995674133
Epoch 0, Step 870: train/loss = 0.1773093044757843, train/raw-loss = 0.10645068436861038, train/logprobs = tensor([[-1.3304, -5.6566],
        [-3.5390, -1.3465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28343451023101807
Epoch 0, Step 871: train/loss = 0.5030046701431274, train/raw-loss = 0.4376154839992523, train/logprobs = tensor([[-1.3656, -1.8597],
        [-2.9732, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615567147731781
Epoch 0, Step 872: train/loss = 0.4196859896183014, train/raw-loss = 0.35690510272979736, train/logprobs = tensor([[-0.8623, -2.8954],
        [-2.0901, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25112345814704895
Epoch 0, Step 873: train/loss = 0.29218894243240356, train/raw-loss = 0.22923210263252258, train/logprobs = tensor([[-1.4144, -4.5332],
        [-3.8406, -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518273890018463
Epoch 0, Step 874: train/loss = 0.47284644842147827, train/raw-loss = 0.4084434509277344, train/logprobs = tensor([[-1.1345, -4.8467],
        [-2.3714, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25761204957962036
Epoch 0, Step 875: train/loss = 0.6071650385856628, train/raw-loss = 0.5407993793487549, train/logprobs = tensor([[-1.1733, -2.3731],
        [-2.5982, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26546263694763184
Epoch 0, Step 876: train/loss = 0.20055928826332092, train/raw-loss = 0.1357494443655014, train/logprobs = tensor([[-0.9740, -5.6694],
        [-2.1948, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2592393457889557
Epoch 0, Step 877: train/loss = 0.42326539754867554, train/raw-loss = 0.3527124524116516, train/logprobs = tensor([[-0.8977, -3.7914],
        [-2.1871, -1.4961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28221192955970764
Epoch 0, Step 878: train/loss = 0.2921048700809479, train/raw-loss = 0.2325245887041092, train/logprobs = tensor([[-1.4635, -5.4573],
        [-2.8947, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23832115530967712
Epoch 0, Step 879: train/loss = 0.5126258134841919, train/raw-loss = 0.4447210133075714, train/logprobs = tensor([[-1.0430, -4.3473],
        [-1.6076, -1.8082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2716192603111267
Epoch 0, Step 880: train/loss = 0.20364999771118164, train/raw-loss = 0.13870754837989807, train/logprobs = tensor([[-1.1773, -5.5428],
        [-2.8774, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2597697675228119
Epoch 0, Step 881: train/loss = 0.41416671872138977, train/raw-loss = 0.3485364019870758, train/logprobs = tensor([[-1.2500, -3.0558],
        [-2.3621, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26252123713493347
Epoch 0, Step 882: train/loss = 0.8477525115013123, train/raw-loss = 0.7854584455490112, train/logprobs = tensor([[-2.3061, -4.0053],
        [-3.0851, -2.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2491765171289444
Epoch 0, Step 883: train/loss = 0.30732664465904236, train/raw-loss = 0.24716220796108246, train/logprobs = tensor([[-1.1492, -4.3989],
        [-2.3753, -0.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24065779149532318
Epoch 0, Step 884: train/loss = 0.1951834261417389, train/raw-loss = 0.11976861953735352, train/logprobs = tensor([[-1.2811, -5.0699],
        [-3.8501, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3016592264175415
Epoch 0, Step 885: train/loss = 0.20711076259613037, train/raw-loss = 0.14521920680999756, train/logprobs = tensor([[-0.8302, -9.5293],
        [-2.3414, -1.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24756626784801483
Epoch 0, Step 886: train/loss = 0.5309413075447083, train/raw-loss = 0.4633302688598633, train/logprobs = tensor([[-1.1532, -5.2039],
        [-3.1616, -2.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27044421434402466
Epoch 0, Step 887: train/loss = 0.32503607869148254, train/raw-loss = 0.26202017068862915, train/logprobs = tensor([[-1.2924, -5.0996],
        [-3.4532, -1.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25206369161605835
Epoch 0, Step 888: train/loss = 0.18034297227859497, train/raw-loss = 0.10714209079742432, train/logprobs = tensor([[-0.8757, -7.4707],
        [-2.7354, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2928035855293274
Epoch 0, Step 889: train/loss = 0.3069009482860565, train/raw-loss = 0.23415516316890717, train/logprobs = tensor([[-1.5785, -3.5424],
        [-3.9487, -1.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.290983110666275
Epoch 0, Step 890: train/loss = 0.5208522081375122, train/raw-loss = 0.4677897095680237, train/logprobs = tensor([[-0.8737, -1.3110],
        [-1.9049, -0.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2122499644756317
Epoch 0, Step 891: train/loss = 0.4269924461841583, train/raw-loss = 0.36696115136146545, train/logprobs = tensor([[-1.0708, -4.5767],
        [-1.7913, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24012523889541626
Epoch 0, Step 892: train/loss = 0.28845730423927307, train/raw-loss = 0.21272626519203186, train/logprobs = tensor([[-1.2003, -4.8203],
        [-4.0483, -1.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30292418599128723
Epoch 0, Step 893: train/loss = 0.3416560888290405, train/raw-loss = 0.2803541421890259, train/logprobs = tensor([[-1.0179, -4.3902],
        [-2.4614, -1.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2452077567577362
Epoch 0, Step 894: train/loss = 0.3045772612094879, train/raw-loss = 0.22859057784080505, train/logprobs = tensor([[-0.9846, -5.7921],
        [-3.5066, -1.2879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303946852684021
Epoch 0, Step 895: train/loss = 0.485576331615448, train/raw-loss = 0.43505632877349854, train/logprobs = tensor([[-0.9828, -3.1502],
        [-1.4580, -1.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20208019018173218
Epoch 0, Step 896: train/loss = 0.5862762928009033, train/raw-loss = 0.5302262306213379, train/logprobs = tensor([[-2.1599, -5.6125],
        [-2.5132, -2.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2242000699043274
Epoch 0, Step 897: train/loss = 0.264254629611969, train/raw-loss = 0.1889035701751709, train/logprobs = tensor([[-1.1252, -6.4363],
        [-3.1621, -1.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30140420794487
Epoch 0, Step 898: train/loss = 0.329617440700531, train/raw-loss = 0.262675404548645, train/logprobs = tensor([[-1.1077, -4.7678],
        [-2.5874, -1.1494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2677682042121887
Epoch 0, Step 899: train/loss = 0.2530509829521179, train/raw-loss = 0.19342556595802307, train/logprobs = tensor([[-1.1149, -5.1116],
        [-2.0784, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2385016530752182
Epoch 0, Step 900: train/loss = 0.6025128364562988, train/raw-loss = 0.552944540977478, train/logprobs = tensor([[-1.5763, -4.7424],
        [-1.5118, -1.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1982732117176056
Epoch 0, Step 901: train/loss = 0.5176628828048706, train/raw-loss = 0.452819287776947, train/logprobs = tensor([[-3.5603, -4.2776],
        [-4.4721, -1.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25937420129776
Epoch 0, Step 902: train/loss = 0.3831230401992798, train/raw-loss = 0.3185006082057953, train/logprobs = tensor([[-1.5488, -5.0967],
        [-3.1576, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25848978757858276
Epoch 0, Step 903: train/loss = 0.36024215817451477, train/raw-loss = 0.2992202639579773, train/logprobs = tensor([[-1.3182, -3.3307],
        [-3.0489, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24408772587776184
Epoch 0, Step 904: train/loss = 0.43374723196029663, train/raw-loss = 0.3567190170288086, train/logprobs = tensor([[-1.5562, -4.7968],
        [-2.9250, -2.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3081129491329193
Epoch 0, Step 905: train/loss = 0.4846133291721344, train/raw-loss = 0.42175328731536865, train/logprobs = tensor([[-0.9599, -4.5833],
        [-1.3646, -1.0269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25144004821777344
Epoch 0, Step 906: train/loss = 0.14493677020072937, train/raw-loss = 0.0810985341668129, train/logprobs = tensor([[-1.6626, -8.4767],
        [-3.9112, -1.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553529441356659
Epoch 0, Step 907: train/loss = 0.6012167930603027, train/raw-loss = 0.5322984457015991, train/logprobs = tensor([[-0.9679, -1.6497],
        [-2.4540, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2756735682487488
Epoch 0, Step 908: train/loss = 0.8280931711196899, train/raw-loss = 0.7708159685134888, train/logprobs = tensor([[-1.3861, -1.2020],
        [-1.9906, -1.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.229108989238739
Epoch 0, Step 909: train/loss = 0.3164252042770386, train/raw-loss = 0.2495906502008438, train/logprobs = tensor([[-1.1525, -5.6082],
        [-3.0653, -1.2331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26733821630477905
Epoch 0, Step 910: train/loss = 0.4066348671913147, train/raw-loss = 0.34071022272109985, train/logprobs = tensor([[-2.2182, -4.3230],
        [-4.2345, -1.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26369863748550415
Epoch 0, Step 911: train/loss = 0.7784136533737183, train/raw-loss = 0.7357282638549805, train/logprobs = tensor([[-2.1266, -2.9152],
        [-1.3161, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17074176669120789
Epoch 0, Step 912: train/loss = 0.4284106492996216, train/raw-loss = 0.383636474609375, train/logprobs = tensor([[-1.0433, -3.4349],
        [-1.2594, -0.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17909665405750275
Epoch 0, Step 913: train/loss = 0.23435677587985992, train/raw-loss = 0.167548269033432, train/logprobs = tensor([[-1.1742, -8.1200],
        [-1.9612, -1.4974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26723402738571167
Epoch 0, Step 914: train/loss = 0.22085751593112946, train/raw-loss = 0.14885646104812622, train/logprobs = tensor([[-1.0340, -2.6675],
        [-4.5093, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28800415992736816
Epoch 0, Step 915: train/loss = 0.35522764921188354, train/raw-loss = 0.29555630683898926, train/logprobs = tensor([[-1.1287, -3.9519],
        [-3.3175, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23868532478809357
Epoch 0, Step 916: train/loss = 0.5685582160949707, train/raw-loss = 0.5115653872489929, train/logprobs = tensor([[-0.9716, -2.3319],
        [-1.7148, -1.2479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2279714047908783
Epoch 0, Step 917: train/loss = 0.14804551005363464, train/raw-loss = 0.07542945444583893, train/logprobs = tensor([[-1.6881, -8.0377],
        [-4.3469, -1.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29046422243118286
Epoch 0, Step 918: train/loss = 0.2881983518600464, train/raw-loss = 0.22281527519226074, train/logprobs = tensor([[-1.1148, -4.8173],
        [-3.0579, -1.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615322768688202
Epoch 0, Step 919: train/loss = 0.4620131254196167, train/raw-loss = 0.39973604679107666, train/logprobs = tensor([[-1.3340, -4.8722],
        [-1.8527, -2.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24910834431648254
Epoch 0, Step 920: train/loss = 0.4277524948120117, train/raw-loss = 0.3640630543231964, train/logprobs = tensor([[-1.0572, -3.4219],
        [-3.2914, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25475767254829407
Epoch 0, Step 921: train/loss = 0.4344152808189392, train/raw-loss = 0.3770083785057068, train/logprobs = tensor([[-1.1862, -4.0904],
        [-1.6375, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22962749004364014
Epoch 0, Step 922: train/loss = 0.4311069846153259, train/raw-loss = 0.38004058599472046, train/logprobs = tensor([[-1.5357, -4.1851],
        [-2.9932, -2.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20426571369171143
Epoch 0, Step 923: train/loss = 0.3810552656650543, train/raw-loss = 0.33343443274497986, train/logprobs = tensor([[-0.9766, -5.5094],
        [-1.8303, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19048327207565308
Epoch 0, Step 924: train/loss = 0.321766197681427, train/raw-loss = 0.27015313506126404, train/logprobs = tensor([[-1.6701, -5.3314],
        [-2.2643, -1.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20645219087600708
Epoch 0, Step 925: train/loss = 0.35432788729667664, train/raw-loss = 0.2859666049480438, train/logprobs = tensor([[-0.8885, -4.1077],
        [-2.0547, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27344515919685364
Epoch 0, Step 926: train/loss = 0.15640637278556824, train/raw-loss = 0.07621881365776062, train/logprobs = tensor([[-1.2070, -7.0454],
        [-3.3435, -1.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32075023651123047
Epoch 0, Step 927: train/loss = 0.5422042608261108, train/raw-loss = 0.46790748834609985, train/logprobs = tensor([[-1.2288, -4.9269],
        [-3.5216, -2.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2971872389316559
Epoch 0, Step 928: train/loss = 0.5735734105110168, train/raw-loss = 0.5110484957695007, train/logprobs = tensor([[-2.6266, -3.9605],
        [-3.1056, -1.3599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25009971857070923
Epoch 0, Step 929: train/loss = 0.3485673666000366, train/raw-loss = 0.2809714376926422, train/logprobs = tensor([[-1.1906, -5.3228],
        [-3.0353, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2703835964202881
Epoch 0, Step 930: train/loss = 0.5883065462112427, train/raw-loss = 0.528137743473053, train/logprobs = tensor([[-1.5528, -2.8561],
        [-1.8987, -1.1784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2406749725341797
Epoch 0, Step 931: train/loss = 0.5548397302627563, train/raw-loss = 0.4960099458694458, train/logprobs = tensor([[-0.9388, -3.2202],
        [-1.7606, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.235319122672081
Epoch 0, Step 932: train/loss = 0.49715834856033325, train/raw-loss = 0.4487382471561432, train/logprobs = tensor([[-1.3550, -2.3107],
        [-2.3153, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19368043541908264
Epoch 0, Step 933: train/loss = 0.4113819897174835, train/raw-loss = 0.3384403884410858, train/logprobs = tensor([[-0.9298, -4.7267],
        [-2.3295, -1.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29176658391952515
Epoch 0, Step 934: train/loss = 0.6276943683624268, train/raw-loss = 0.5523034930229187, train/logprobs = tensor([[-3.0742, -6.2415],
        [-3.1596, -1.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015633523464203
Epoch 0, Step 935: train/loss = 0.18587738275527954, train/raw-loss = 0.10455910861492157, train/logprobs = tensor([[-1.6764, -5.4760],
        [-3.7056, -1.2831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3252731263637543
Epoch 0, Step 936: train/loss = 0.32516807317733765, train/raw-loss = 0.2644723355770111, train/logprobs = tensor([[-1.0380, -4.3858],
        [-1.7913, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24278301000595093
Epoch 0, Step 937: train/loss = 0.2147306501865387, train/raw-loss = 0.1442359983921051, train/logprobs = tensor([[-1.6534, -4.3732],
        [-3.8904, -1.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2819785475730896
Epoch 0, Step 938: train/loss = 0.6481142640113831, train/raw-loss = 0.5958245992660522, train/logprobs = tensor([[-2.9842, -6.5491],
        [-1.7226, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20915865898132324
Epoch 0, Step 939: train/loss = 0.6788305640220642, train/raw-loss = 0.609180212020874, train/logprobs = tensor([[-0.8585, -3.1524],
        [-1.4692, -1.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27860161662101746
Epoch 0, Step 940: train/loss = 0.20701585710048676, train/raw-loss = 0.14778414368629456, train/logprobs = tensor([[-1.7565, -6.3876],
        [-3.3963, -1.6913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2369268834590912
Epoch 0, Step 941: train/loss = 0.5103209614753723, train/raw-loss = 0.4477219581604004, train/logprobs = tensor([[-1.8682, -5.5822],
        [-1.8307, -1.3922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25039586424827576
Epoch 0, Step 942: train/loss = 0.2928016781806946, train/raw-loss = 0.2195741832256317, train/logprobs = tensor([[-1.2445, -5.7320],
        [-2.8032, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29290997982025146
Epoch 0, Step 943: train/loss = 0.5752221941947937, train/raw-loss = 0.5291709303855896, train/logprobs = tensor([[-2.0210, -4.7726],
        [-1.9965, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18420502543449402
Epoch 0, Step 944: train/loss = 0.19824782013893127, train/raw-loss = 0.13295231759548187, train/logprobs = tensor([[-0.9739, -6.0913],
        [-2.4907, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611820101737976
Epoch 0, Step 945: train/loss = 0.33359962701797485, train/raw-loss = 0.27519911527633667, train/logprobs = tensor([[-2.1254, -4.6273],
        [-3.6442, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23360192775726318
Epoch 0, Step 946: train/loss = 0.15818336606025696, train/raw-loss = 0.09068159759044647, train/logprobs = tensor([[-0.9365, -8.2737],
        [-2.6004, -1.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27000707387924194
Epoch 0, Step 947: train/loss = 0.4943889081478119, train/raw-loss = 0.4309254586696625, train/logprobs = tensor([[-1.7482, -2.1879],
        [-2.3708, -0.9734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25385382771492004
Epoch 0, Step 948: train/loss = 0.3931657075881958, train/raw-loss = 0.3322089612483978, train/logprobs = tensor([[-0.5797, -4.5275],
        [-1.5357, -1.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2438269853591919
Epoch 0, Step 949: train/loss = 0.9376078844070435, train/raw-loss = 0.8681902885437012, train/logprobs = tensor([[-3.9843, -4.3168],
        [-3.9288, -2.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27767035365104675
Epoch 0, Step 950: train/loss = 0.5318758487701416, train/raw-loss = 0.4798201322555542, train/logprobs = tensor([[-1.7004, -3.2788],
        [-2.7024, -1.2385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2082228660583496
Epoch 0, Step 951: train/loss = 0.523937463760376, train/raw-loss = 0.46452662348747253, train/logprobs = tensor([[-1.4289, -1.8343],
        [-2.5190, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23764337599277496
Epoch 0, Step 952: train/loss = 0.3212011456489563, train/raw-loss = 0.245430588722229, train/logprobs = tensor([[-1.4139, -3.5345],
        [-4.1496, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30308225750923157
Epoch 0, Step 953: train/loss = 0.24153149127960205, train/raw-loss = 0.18085208535194397, train/logprobs = tensor([[-0.9368, -4.6509],
        [-2.4505, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24271754920482635
Epoch 0, Step 954: train/loss = 0.4241945743560791, train/raw-loss = 0.3561108410358429, train/logprobs = tensor([[-1.2229, -3.6816],
        [-2.8143, -1.4949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27233487367630005
Epoch 0, Step 955: train/loss = 0.20507247745990753, train/raw-loss = 0.1402554214000702, train/logprobs = tensor([[-1.2874, -7.3260],
        [-2.6887, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25926825404167175
Epoch 0, Step 956: train/loss = 0.4909629225730896, train/raw-loss = 0.4439575672149658, train/logprobs = tensor([[-2.8814, -4.9987],
        [-3.8916, -4.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18802127242088318
Epoch 0, Step 957: train/loss = 0.4159206449985504, train/raw-loss = 0.3596099019050598, train/logprobs = tensor([[-1.3607, -4.6003],
        [-2.6535, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22524303197860718
Epoch 0, Step 958: train/loss = 0.29177525639533997, train/raw-loss = 0.2220461219549179, train/logprobs = tensor([[-1.0132, -3.6708],
        [-2.7401, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789164185523987
Epoch 0, Step 959: train/loss = 0.3763231337070465, train/raw-loss = 0.31151121854782104, train/logprobs = tensor([[-1.0801, -4.2025],
        [-2.5969, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25924763083457947
Epoch 0, Step 960: train/loss = 0.2989235818386078, train/raw-loss = 0.23419851064682007, train/logprobs = tensor([[-0.9507, -6.7621],
        [-1.6521, -1.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2589002549648285
Epoch 0, Step 961: train/loss = 0.2935594618320465, train/raw-loss = 0.22406785190105438, train/logprobs = tensor([[-1.3607, -6.5132],
        [-2.7083, -0.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779664695262909
Epoch 0, Step 962: train/loss = 0.21056705713272095, train/raw-loss = 0.14106769859790802, train/logprobs = tensor([[-1.2584, -5.5304],
        [-3.4938, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2779974937438965
Epoch 0, Step 963: train/loss = 0.5996622443199158, train/raw-loss = 0.5376758575439453, train/logprobs = tensor([[-1.1876, -3.6719],
        [-2.3685, -2.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24794572591781616
Epoch 0, Step 964: train/loss = 0.45383182168006897, train/raw-loss = 0.380895733833313, train/logprobs = tensor([[-1.3567, -4.7617],
        [-3.5148, -2.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2917444109916687
Epoch 0, Step 965: train/loss = 0.40808144211769104, train/raw-loss = 0.3361932933330536, train/logprobs = tensor([[-1.4178, -5.0916],
        [-2.6954, -2.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2875525653362274
Epoch 0, Step 966: train/loss = 0.3761495053768158, train/raw-loss = 0.3130355477333069, train/logprobs = tensor([[-1.5192, -4.2385],
        [-2.2792, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524559795856476
Epoch 0, Step 967: train/loss = 0.20118126273155212, train/raw-loss = 0.1331527680158615, train/logprobs = tensor([[-1.1294, -8.3439],
        [-2.3218, -1.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27211400866508484
Epoch 0, Step 968: train/loss = 0.5608460903167725, train/raw-loss = 0.49848565459251404, train/logprobs = tensor([[-1.5102, -1.8910],
        [-3.1044, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24944186210632324
Epoch 0, Step 969: train/loss = 0.3019944727420807, train/raw-loss = 0.2433931976556778, train/logprobs = tensor([[-0.9542, -5.3913],
        [-1.8240, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23440508544445038
Epoch 0, Step 970: train/loss = 0.3578391671180725, train/raw-loss = 0.3012984097003937, train/logprobs = tensor([[-0.9296, -6.7963],
        [-2.0913, -1.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22616305947303772
Epoch 0, Step 971: train/loss = 0.5666038393974304, train/raw-loss = 0.5115599632263184, train/logprobs = tensor([[-0.6789, -2.0123],
        [-1.1323, -0.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2201753407716751
Epoch 0, Step 972: train/loss = 0.17691399157047272, train/raw-loss = 0.11171826720237732, train/logprobs = tensor([[-1.0510, -6.3044],
        [-3.3992, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607828676700592
Epoch 0, Step 973: train/loss = 0.3638719320297241, train/raw-loss = 0.30681538581848145, train/logprobs = tensor([[-0.9698, -5.1524],
        [-1.8823, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22822614014148712
Epoch 0, Step 974: train/loss = 0.1699635088443756, train/raw-loss = 0.09708569943904877, train/logprobs = tensor([[-1.3824, -6.2256],
        [-3.1462, -0.9665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2915111780166626
Epoch 0, Step 975: train/loss = 0.413832426071167, train/raw-loss = 0.3658156096935272, train/logprobs = tensor([[-2.3828, -3.2996],
        [-3.1479, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19206726551055908
Epoch 0, Step 976: train/loss = 0.3782161474227905, train/raw-loss = 0.31532251834869385, train/logprobs = tensor([[-1.2265, -3.7119],
        [-2.3751, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515745162963867
Epoch 0, Step 977: train/loss = 0.23932868242263794, train/raw-loss = 0.1808747798204422, train/logprobs = tensor([[-1.0243, -7.3854],
        [-1.8902, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23381567001342773
Epoch 0, Step 978: train/loss = 0.37388530373573303, train/raw-loss = 0.30725669860839844, train/logprobs = tensor([[-1.3697, -4.5326],
        [-3.2178, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26651430130004883
Epoch 0, Step 979: train/loss = 0.4669204652309418, train/raw-loss = 0.4199770987033844, train/logprobs = tensor([[-1.2737, -4.0452],
        [-2.0504, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1877734363079071
Epoch 0, Step 980: train/loss = 0.21134613454341888, train/raw-loss = 0.14325881004333496, train/logprobs = tensor([[-1.2558, -3.8675],
        [-3.3501, -0.6243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2723492383956909
Epoch 0, Step 981: train/loss = 0.4401417672634125, train/raw-loss = 0.3812680244445801, train/logprobs = tensor([[-1.0252, -4.4403],
        [-1.8688, -2.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23549489676952362
Epoch 0, Step 982: train/loss = 0.41454094648361206, train/raw-loss = 0.342701256275177, train/logprobs = tensor([[-1.8707, -4.7522],
        [-2.5291, -2.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28735873103141785
Epoch 0, Step 983: train/loss = 0.4525125026702881, train/raw-loss = 0.3908897042274475, train/logprobs = tensor([[-1.7374, -2.0387],
        [-2.1838, -0.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24649134278297424
Epoch 0, Step 984: train/loss = 0.36996763944625854, train/raw-loss = 0.30042505264282227, train/logprobs = tensor([[-0.8861, -4.5520],
        [-2.1945, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2781703770160675
Epoch 0, Step 985: train/loss = 0.1599295437335968, train/raw-loss = 0.09073013812303543, train/logprobs = tensor([[-1.3377, -5.7054],
        [-3.5487, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2767976224422455
Epoch 0, Step 986: train/loss = 0.22720296680927277, train/raw-loss = 0.16019557416439056, train/logprobs = tensor([[-1.7371, -2.5970],
        [-4.4139, -0.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2680295705795288
Epoch 0, Step 987: train/loss = 0.3408609926700592, train/raw-loss = 0.27866852283477783, train/logprobs = tensor([[-1.7603, -4.7562],
        [-2.5610, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2487698346376419
Epoch 0, Step 988: train/loss = 0.5864222645759583, train/raw-loss = 0.5228726863861084, train/logprobs = tensor([[-1.4894, -4.1890],
        [-3.2971, -2.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2541983127593994
Epoch 0, Step 989: train/loss = 0.3348018527030945, train/raw-loss = 0.2736511826515198, train/logprobs = tensor([[-0.9376, -5.7126],
        [-1.7301, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24460262060165405
Epoch 0, Step 990: train/loss = 0.38755545020103455, train/raw-loss = 0.3260359764099121, train/logprobs = tensor([[-0.9621, -3.3275],
        [-1.9560, -1.1897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24607796967029572
Epoch 0, Step 991: train/loss = 0.6207852363586426, train/raw-loss = 0.5458962321281433, train/logprobs = tensor([[-1.3703, -2.8775],
        [-1.6092, -1.4363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29955601692199707
Epoch 0, Step 992: train/loss = 0.12927161157131195, train/raw-loss = 0.057492755353450775, train/logprobs = tensor([[-1.3464, -9.9109],
        [-3.9696, -2.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871154248714447
Epoch 0, Step 993: train/loss = 0.4165232181549072, train/raw-loss = 0.35285794734954834, train/logprobs = tensor([[-1.4187, -5.6323],
        [-1.9507, -1.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25466108322143555
Epoch 0, Step 994: train/loss = 0.3631936311721802, train/raw-loss = 0.29980742931365967, train/logprobs = tensor([[-1.0542, -3.3695],
        [-3.1552, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535449266433716
Epoch 0, Step 995: train/loss = 0.18812847137451172, train/raw-loss = 0.12183652818202972, train/logprobs = tensor([[-0.9536, -6.2185],
        [-2.8592, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.265167772769928
Epoch 0, Step 996: train/loss = 0.44933179020881653, train/raw-loss = 0.39251866936683655, train/logprobs = tensor([[-2.5018, -7.3726],
        [-2.8343, -2.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22725243866443634
Epoch 0, Step 997: train/loss = 0.3593602478504181, train/raw-loss = 0.3099595904350281, train/logprobs = tensor([[-1.5858, -4.2512],
        [-2.7951, -0.6195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19760265946388245
Epoch 0, Step 998: train/loss = 0.35284286737442017, train/raw-loss = 0.2915765047073364, train/logprobs = tensor([[-1.2755, -4.6200],
        [-2.4615, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24506555497646332
Epoch 0, Step 999: train/loss = 0.40699517726898193, train/raw-loss = 0.34324827790260315, train/logprobs = tensor([[-2.6091, -7.2107],
        [-2.7636, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549876868724823
eval/loss: nan
Epoch 0, Step 1000: train/loss = 0.5029886960983276, train/raw-loss = 0.45369118452072144, train/logprobs = tensor([[-0.7775, -3.1727],
        [-1.0660, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1971902698278427
Epoch 0, Step 1001: train/loss = 0.22129179537296295, train/raw-loss = 0.15577201545238495, train/logprobs = tensor([[-1.4398, -5.1840],
        [-3.1547, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.262079119682312
Epoch 0, Step 1002: train/loss = 0.33751222491264343, train/raw-loss = 0.27962490916252136, train/logprobs = tensor([[-0.6616, -4.8760],
        [-1.4257, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2315492331981659
Epoch 0, Step 1003: train/loss = 0.36937785148620605, train/raw-loss = 0.30678004026412964, train/logprobs = tensor([[-1.2311, -4.2067],
        [-2.3602, -1.5629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25039124488830566
Epoch 0, Step 1004: train/loss = 0.15825632214546204, train/raw-loss = 0.09320428967475891, train/logprobs = tensor([[-1.6293, -4.2185],
        [-4.7408, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602080702781677
Epoch 0, Step 1005: train/loss = 0.3168589770793915, train/raw-loss = 0.2660166621208191, train/logprobs = tensor([[ -2.2318, -11.1853],
        [ -2.6040,  -5.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033693790435791
Epoch 0, Step 1006: train/loss = 0.2329460233449936, train/raw-loss = 0.17806045711040497, train/logprobs = tensor([[-1.0288, -6.4973],
        [-2.0495, -1.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21954227983951569
Epoch 0, Step 1007: train/loss = 0.392647385597229, train/raw-loss = 0.3307303190231323, train/logprobs = tensor([[-1.2899, -2.9227],
        [-2.2569, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24766825139522552
Epoch 0, Step 1008: train/loss = 0.41586440801620483, train/raw-loss = 0.353390634059906, train/logprobs = tensor([[-1.5307, -4.8917],
        [-2.4233, -1.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24989499151706696
Epoch 0, Step 1009: train/loss = 0.6038445830345154, train/raw-loss = 0.5372836589813232, train/logprobs = tensor([[-1.0832, -4.5277],
        [-2.9782, -2.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26624393463134766
Epoch 0, Step 1010: train/loss = 0.49527350068092346, train/raw-loss = 0.4414089322090149, train/logprobs = tensor([[-1.4691, -3.1403],
        [-1.9189, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2154582440853119
Epoch 0, Step 1011: train/loss = 0.3288894295692444, train/raw-loss = 0.26534754037857056, train/logprobs = tensor([[-0.8621, -4.3127],
        [-2.1146, -1.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25416746735572815
Epoch 0, Step 1012: train/loss = 0.5030137896537781, train/raw-loss = 0.4472583830356598, train/logprobs = tensor([[-2.0660, -3.2628],
        [-3.5809, -2.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22302153706550598
Epoch 0, Step 1013: train/loss = 0.30058032274246216, train/raw-loss = 0.24783726036548615, train/logprobs = tensor([[-0.7499, -5.6114],
        [-1.0674, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21097232401371002
Epoch 0, Step 1014: train/loss = 0.4560409188270569, train/raw-loss = 0.4062096178531647, train/logprobs = tensor([[-1.2509, -3.9407],
        [-1.4809, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19932520389556885
Epoch 0, Step 1015: train/loss = 0.34031617641448975, train/raw-loss = 0.28101596236228943, train/logprobs = tensor([[-1.6836, -3.1839],
        [-3.8439, -1.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23720082640647888
Epoch 0, Step 1016: train/loss = 0.20813506841659546, train/raw-loss = 0.14253678917884827, train/logprobs = tensor([[-1.4837, -6.5968],
        [-3.5594, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26239317655563354
Epoch 0, Step 1017: train/loss = 0.39397338032722473, train/raw-loss = 0.33953365683555603, train/logprobs = tensor([[-1.7428, -4.2649],
        [-2.2796, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21775886416435242
Epoch 0, Step 1018: train/loss = 0.4325407147407532, train/raw-loss = 0.38094088435173035, train/logprobs = tensor([[-1.1153, -2.7121],
        [-1.9093, -1.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20639929175376892
Epoch 0, Step 1019: train/loss = 0.26222121715545654, train/raw-loss = 0.2049587070941925, train/logprobs = tensor([[-1.1433, -5.7401],
        [-3.1047, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22905009984970093
Epoch 0, Step 1020: train/loss = 0.5808572173118591, train/raw-loss = 0.5050305128097534, train/logprobs = tensor([[-2.9352, -4.6240],
        [-3.2023, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3033069670200348
Epoch 0, Step 1021: train/loss = 0.48824894428253174, train/raw-loss = 0.4335746169090271, train/logprobs = tensor([[-2.3303, -5.6776],
        [-2.8077, -2.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21869724988937378
Epoch 0, Step 1022: train/loss = 0.4007139801979065, train/raw-loss = 0.347544401884079, train/logprobs = tensor([[-1.1760, -4.4543],
        [-2.1693, -1.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21267825365066528
Epoch 0, Step 1023: train/loss = 0.43999025225639343, train/raw-loss = 0.38751116394996643, train/logprobs = tensor([[-0.9801, -4.3106],
        [-1.8630, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2099163979291916
Epoch 0, Step 1024: train/loss = 0.2917592227458954, train/raw-loss = 0.23759500682353973, train/logprobs = tensor([[-1.2809, -6.0479],
        [-2.2849, -1.2821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21665680408477783
Epoch 0, Step 1025: train/loss = 0.1757502257823944, train/raw-loss = 0.1121312826871872, train/logprobs = tensor([[-1.3037, -6.0342],
        [-3.7143, -1.0477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25447574257850647
Epoch 0, Step 1026: train/loss = 0.18098703026771545, train/raw-loss = 0.1197795420885086, train/logprobs = tensor([[-1.0259, -7.4457],
        [-2.7933, -1.4675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2448299676179886
Epoch 0, Step 1027: train/loss = 0.2291271835565567, train/raw-loss = 0.1635252684354782, train/logprobs = tensor([[-1.2438, -8.7415],
        [-2.6426, -1.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2624076306819916
Epoch 0, Step 1028: train/loss = 0.15870369970798492, train/raw-loss = 0.08795210719108582, train/logprobs = tensor([[-0.7034, -8.9524],
        [-2.5718, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2830063998699188
Epoch 0, Step 1029: train/loss = 0.34200799465179443, train/raw-loss = 0.28099697828292847, train/logprobs = tensor([[-1.2223, -4.0534],
        [-2.3544, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24404412508010864
Epoch 0, Step 1030: train/loss = 0.2798096239566803, train/raw-loss = 0.21493524312973022, train/logprobs = tensor([[-1.4137, -4.7446],
        [-2.6651, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25949758291244507
Epoch 0, Step 1031: train/loss = 0.28453168272972107, train/raw-loss = 0.2272620052099228, train/logprobs = tensor([[-0.8036, -6.1370],
        [-1.2678, -0.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2290787398815155
Epoch 0, Step 1032: train/loss = 0.7567593455314636, train/raw-loss = 0.719307005405426, train/logprobs = tensor([[-1.9392, -1.0613],
        [-1.5859, -0.6823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14980961382389069
Epoch 0, Step 1033: train/loss = 0.13046172261238098, train/raw-loss = 0.06539848446846008, train/logprobs = tensor([[-1.0063, -9.3972],
        [-3.0463, -1.6259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602529525756836
Epoch 0, Step 1034: train/loss = 0.19449187815189362, train/raw-loss = 0.12446572631597519, train/logprobs = tensor([[-0.9161, -6.2963],
        [-2.3322, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801045775413513
Epoch 0, Step 1035: train/loss = 0.2747664451599121, train/raw-loss = 0.21381902694702148, train/logprobs = tensor([[-1.1827, -7.4267],
        [-1.7501, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2437896728515625
Epoch 0, Step 1036: train/loss = 0.329088032245636, train/raw-loss = 0.2610359191894531, train/logprobs = tensor([[-1.1615, -4.5563],
        [-3.1226, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27220839262008667
Epoch 0, Step 1037: train/loss = 0.3536888360977173, train/raw-loss = 0.30066969990730286, train/logprobs = tensor([[-1.6193, -3.5109],
        [-2.9219, -1.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21207651495933533
Epoch 0, Step 1038: train/loss = 0.40824592113494873, train/raw-loss = 0.3500736951828003, train/logprobs = tensor([[-1.0974, -3.5591],
        [-2.2846, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2326887547969818
Epoch 0, Step 1039: train/loss = 0.3184313476085663, train/raw-loss = 0.27276289463043213, train/logprobs = tensor([[-1.1661, -3.9024],
        [-2.2002, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18267375230789185
Epoch 0, Step 1040: train/loss = 0.1867450326681137, train/raw-loss = 0.11971677094697952, train/logprobs = tensor([[-1.4085, -3.4534],
        [-3.6317, -0.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26811301708221436
Epoch 0, Step 1041: train/loss = 0.37659645080566406, train/raw-loss = 0.3074146807193756, train/logprobs = tensor([[-1.0168, -5.4030],
        [-2.4794, -1.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27672702074050903
Epoch 0, Step 1042: train/loss = 0.36262381076812744, train/raw-loss = 0.3019176125526428, train/logprobs = tensor([[-0.9796, -5.2924],
        [-1.6557, -1.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2428247630596161
Epoch 0, Step 1043: train/loss = 0.4287847876548767, train/raw-loss = 0.3649536073207855, train/logprobs = tensor([[-1.4998, -4.8506],
        [-3.2553, -1.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2553247809410095
Epoch 0, Step 1044: train/loss = 0.31941694021224976, train/raw-loss = 0.25339674949645996, train/logprobs = tensor([[-2.4117, -7.2428],
        [-3.2633, -2.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640807330608368
Epoch 0, Step 1045: train/loss = 0.4262677729129791, train/raw-loss = 0.3660833537578583, train/logprobs = tensor([[-0.9265, -2.7247],
        [-1.5745, -1.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240737646818161
Epoch 0, Step 1046: train/loss = 0.28694844245910645, train/raw-loss = 0.22624188661575317, train/logprobs = tensor([[-1.7124, -5.8321],
        [-2.9447, -1.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24282622337341309
Epoch 0, Step 1047: train/loss = 0.31792858242988586, train/raw-loss = 0.256050169467926, train/logprobs = tensor([[-0.9386, -4.6870],
        [-2.7092, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2475135326385498
Epoch 0, Step 1048: train/loss = 0.3953131437301636, train/raw-loss = 0.3420341908931732, train/logprobs = tensor([[-0.6096, -3.4362],
        [-1.7240, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2131158411502838
Epoch 0, Step 1049: train/loss = 0.5979664325714111, train/raw-loss = 0.541489839553833, train/logprobs = tensor([[-1.3209, -1.6792],
        [-1.9920, -1.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22590625286102295
Epoch 0, Step 1050: train/loss = 0.40054750442504883, train/raw-loss = 0.3411942422389984, train/logprobs = tensor([[-1.0676, -3.9465],
        [-2.0453, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23741291463375092
Epoch 0, Step 1051: train/loss = 0.34451308846473694, train/raw-loss = 0.2898058295249939, train/logprobs = tensor([[-1.2015, -3.2727],
        [-2.2127, -1.2894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.218828946352005
Epoch 0, Step 1052: train/loss = 0.14246660470962524, train/raw-loss = 0.07145252078771591, train/logprobs = tensor([[-1.0625, -7.1285],
        [-3.2968, -1.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840563654899597
Epoch 0, Step 1053: train/loss = 0.31649330258369446, train/raw-loss = 0.2618604302406311, train/logprobs = tensor([[-0.8220, -2.5979],
        [-2.2925, -0.6602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21853141486644745
Epoch 0, Step 1054: train/loss = 0.3076503872871399, train/raw-loss = 0.2577022314071655, train/logprobs = tensor([[-0.9439, -6.8985],
        [-1.7380, -1.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19979263842105865
Epoch 0, Step 1055: train/loss = 0.15640877187252045, train/raw-loss = 0.08776378631591797, train/logprobs = tensor([[-1.3279, -6.4012],
        [-3.7972, -1.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27457988262176514
Epoch 0, Step 1056: train/loss = 0.5197253227233887, train/raw-loss = 0.47083961963653564, train/logprobs = tensor([[-1.2963, -2.0558],
        [-1.7852, -1.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19554287195205688
Epoch 0, Step 1057: train/loss = 0.415485680103302, train/raw-loss = 0.34342944622039795, train/logprobs = tensor([[-1.1180, -3.6836],
        [-2.1787, -2.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2882249355316162
Epoch 0, Step 1058: train/loss = 0.3217254877090454, train/raw-loss = 0.2570791244506836, train/logprobs = tensor([[-1.5961, -4.4436],
        [-3.1851, -0.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25858551263809204
Epoch 0, Step 1059: train/loss = 0.4468337893486023, train/raw-loss = 0.3925747871398926, train/logprobs = tensor([[-1.2178, -4.7218],
        [-2.1333, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21703603863716125
Epoch 0, Step 1060: train/loss = 0.47474679350852966, train/raw-loss = 0.41268712282180786, train/logprobs = tensor([[-0.7137, -5.3768],
        [-1.7623, -1.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2482387274503708
Epoch 0, Step 1061: train/loss = 0.2511128783226013, train/raw-loss = 0.19247061014175415, train/logprobs = tensor([[-1.6104, -6.5428],
        [-3.3511, -1.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23456907272338867
Epoch 0, Step 1062: train/loss = 0.5247248411178589, train/raw-loss = 0.4699678421020508, train/logprobs = tensor([[-1.0102, -1.0895],
        [-2.0426, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21902784705162048
Epoch 0, Step 1063: train/loss = 0.9282695651054382, train/raw-loss = 0.8694430589675903, train/logprobs = tensor([[-2.5938, -2.5438],
        [-2.3614, -1.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23530574142932892
Epoch 0, Step 1064: train/loss = 0.22512540221214294, train/raw-loss = 0.16727215051651, train/logprobs = tensor([[-0.8547, -6.6732],
        [-1.8761, -1.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2314130663871765
Epoch 0, Step 1065: train/loss = 0.15217748284339905, train/raw-loss = 0.07850617915391922, train/logprobs = tensor([[-0.8732, -8.8701],
        [-2.9606, -1.3140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2946851849555969
Epoch 0, Step 1066: train/loss = 0.3846478760242462, train/raw-loss = 0.3270663917064667, train/logprobs = tensor([[-1.3419, -3.3704],
        [-2.7249, -1.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23032604157924652
Epoch 0, Step 1067: train/loss = 0.2977908253669739, train/raw-loss = 0.23607522249221802, train/logprobs = tensor([[-0.5228, -5.0654],
        [-1.8169, -1.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468625009059906
Epoch 0, Step 1068: train/loss = 0.16678626835346222, train/raw-loss = 0.09340231120586395, train/logprobs = tensor([[-1.1006, -7.4772],
        [-2.9433, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29353585839271545
Epoch 0, Step 1069: train/loss = 0.3347349762916565, train/raw-loss = 0.26483702659606934, train/logprobs = tensor([[-1.1062, -5.0929],
        [-3.1324, -1.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.279591828584671
Epoch 0, Step 1070: train/loss = 0.2212415337562561, train/raw-loss = 0.15223625302314758, train/logprobs = tensor([[-1.4214, -6.0071],
        [-4.2964, -2.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2760211229324341
Epoch 0, Step 1071: train/loss = 0.5690067410469055, train/raw-loss = 0.5131233930587769, train/logprobs = tensor([[-1.0695, -1.6436],
        [-2.0540, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22353336215019226
Epoch 0, Step 1072: train/loss = 0.2739669382572174, train/raw-loss = 0.20934726297855377, train/logprobs = tensor([[-1.2043, -4.0066],
        [-3.2880, -0.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25847864151000977
Epoch 0, Step 1073: train/loss = 0.4508647918701172, train/raw-loss = 0.4033583998680115, train/logprobs = tensor([[-1.4257, -3.0171],
        [-2.5639, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19002559781074524
Epoch 0, Step 1074: train/loss = 0.4969724416732788, train/raw-loss = 0.4193456768989563, train/logprobs = tensor([[-1.1846, -1.8122],
        [-3.1720, -1.1969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31050699949264526
Epoch 0, Step 1075: train/loss = 0.3526996970176697, train/raw-loss = 0.289894700050354, train/logprobs = tensor([[-0.8164, -4.1934],
        [-1.7626, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25121980905532837
Epoch 0, Step 1076: train/loss = 0.29208308458328247, train/raw-loss = 0.2267778515815735, train/logprobs = tensor([[-0.9997, -4.3097],
        [-2.3031, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26122093200683594
Epoch 0, Step 1077: train/loss = 0.2173410952091217, train/raw-loss = 0.154041588306427, train/logprobs = tensor([[-1.0313, -5.8849],
        [-2.5290, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2531980872154236
Epoch 0, Step 1078: train/loss = 0.2880061864852905, train/raw-loss = 0.228598952293396, train/logprobs = tensor([[-1.7105, -6.3670],
        [-2.6758, -1.0727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2376290261745453
Epoch 0, Step 1079: train/loss = 0.2673851251602173, train/raw-loss = 0.20361456274986267, train/logprobs = tensor([[-1.1693, -6.2341],
        [-2.6826, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2550821304321289
Epoch 0, Step 1080: train/loss = 0.5125269889831543, train/raw-loss = 0.46207764744758606, train/logprobs = tensor([[-0.9155, -0.9253],
        [-2.1095, -0.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20179755985736847
Epoch 0, Step 1081: train/loss = 0.28735852241516113, train/raw-loss = 0.21965643763542175, train/logprobs = tensor([[-1.0890, -4.6909],
        [-2.7892, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27080827951431274
Epoch 0, Step 1082: train/loss = 0.2990033030509949, train/raw-loss = 0.2318723350763321, train/logprobs = tensor([[-0.6031, -6.6902],
        [-2.1700, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26852384209632874
Epoch 0, Step 1083: train/loss = 0.31253352761268616, train/raw-loss = 0.24969761073589325, train/logprobs = tensor([[-1.0808, -6.5285],
        [-2.3802, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25134360790252686
Epoch 0, Step 1084: train/loss = 0.28331172466278076, train/raw-loss = 0.22004273533821106, train/logprobs = tensor([[-1.7262, -7.2105],
        [-2.3998, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530760169029236
Epoch 0, Step 1085: train/loss = 0.5559404492378235, train/raw-loss = 0.48654839396476746, train/logprobs = tensor([[-1.8754, -3.0806],
        [-2.8377, -1.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2775682508945465
Epoch 0, Step 1086: train/loss = 0.2444026917219162, train/raw-loss = 0.18718837201595306, train/logprobs = tensor([[-1.0682, -5.6073],
        [-2.6405, -1.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22885727882385254
Epoch 0, Step 1087: train/loss = 0.6955331563949585, train/raw-loss = 0.6355652809143066, train/logprobs = tensor([[-3.4953, -4.7799],
        [-4.1009, -2.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23987148702144623
Epoch 0, Step 1088: train/loss = 0.26585081219673157, train/raw-loss = 0.2053736448287964, train/logprobs = tensor([[-1.2146, -4.4981],
        [-2.7829, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2419087141752243
Epoch 0, Step 1089: train/loss = 0.320346474647522, train/raw-loss = 0.26430320739746094, train/logprobs = tensor([[-0.9011, -3.6192],
        [-2.0953, -1.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2241731733083725
Epoch 0, Step 1090: train/loss = 0.1618104875087738, train/raw-loss = 0.08741037547588348, train/logprobs = tensor([[-1.1895, -4.4936],
        [-3.3776, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2976004481315613
Epoch 0, Step 1091: train/loss = 0.21202215552330017, train/raw-loss = 0.14613953232765198, train/logprobs = tensor([[-1.0931, -6.2384],
        [-2.8232, -1.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2635304927825928
Epoch 0, Step 1092: train/loss = 0.45164966583251953, train/raw-loss = 0.4037577509880066, train/logprobs = tensor([[-0.6272, -4.1723],
        [-1.2635, -0.8861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19156765937805176
Epoch 0, Step 1093: train/loss = 0.6288560628890991, train/raw-loss = 0.5636456608772278, train/logprobs = tensor([[-1.8188, -4.7200],
        [-2.8994, -1.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2608416676521301
Epoch 0, Step 1094: train/loss = 0.368399977684021, train/raw-loss = 0.30532175302505493, train/logprobs = tensor([[-1.9468, -6.9563],
        [-2.7729, -1.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25231295824050903
Epoch 0, Step 1095: train/loss = 0.288094699382782, train/raw-loss = 0.2087169885635376, train/logprobs = tensor([[-1.3715, -4.4810],
        [-3.5234, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31751084327697754
Epoch 0, Step 1096: train/loss = 0.4316045045852661, train/raw-loss = 0.3726525902748108, train/logprobs = tensor([[-2.3568, -5.0964],
        [-3.3261, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2358075976371765
Epoch 0, Step 1097: train/loss = 0.1914461851119995, train/raw-loss = 0.130711168050766, train/logprobs = tensor([[-1.2167, -8.7857],
        [-2.3892, -1.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24294012784957886
Epoch 0, Step 1098: train/loss = 0.36087995767593384, train/raw-loss = 0.29465624690055847, train/logprobs = tensor([[-0.9509, -6.2398],
        [-2.4945, -2.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.264894962310791
Epoch 0, Step 1099: train/loss = 0.2972235381603241, train/raw-loss = 0.22446055710315704, train/logprobs = tensor([[-0.8951, -4.8535],
        [-2.7632, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291051983833313
Epoch 0, Step 1100: train/loss = 0.4182593822479248, train/raw-loss = 0.3527628779411316, train/logprobs = tensor([[-1.6240, -6.5198],
        [-2.5025, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26198601722717285
Epoch 0, Step 1101: train/loss = 0.33142754435539246, train/raw-loss = 0.26982277631759644, train/logprobs = tensor([[-1.6113, -4.8528],
        [-2.6178, -1.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464190572500229
Epoch 0, Step 1102: train/loss = 0.18129418790340424, train/raw-loss = 0.11922004818916321, train/logprobs = tensor([[-1.4633, -5.9721],
        [-3.4944, -1.1800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24829652905464172
Epoch 0, Step 1103: train/loss = 0.2196931689977646, train/raw-loss = 0.1580333709716797, train/logprobs = tensor([[-1.3382, -5.4421],
        [-2.5715, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24663911759853363
Epoch 0, Step 1104: train/loss = 0.21028926968574524, train/raw-loss = 0.1517566591501236, train/logprobs = tensor([[-0.8581, -5.5681],
        [-2.3762, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2341303825378418
Epoch 0, Step 1105: train/loss = 0.23925873637199402, train/raw-loss = 0.18320682644844055, train/logprobs = tensor([[-1.0503, -6.4920],
        [-2.5104, -1.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22420772910118103
Epoch 0, Step 1106: train/loss = 0.21136830747127533, train/raw-loss = 0.15509724617004395, train/logprobs = tensor([[-1.3182, -5.2786],
        [-3.1085, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2250843048095703
Epoch 0, Step 1107: train/loss = 0.20905804634094238, train/raw-loss = 0.13941225409507751, train/logprobs = tensor([[-1.3577, -5.4508],
        [-2.8341, -1.4802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27858322858810425
Epoch 0, Step 1108: train/loss = 0.141145721077919, train/raw-loss = 0.08069147169589996, train/logprobs = tensor([[-1.4775, -6.6700],
        [-3.7941, -1.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24181702733039856
Epoch 0, Step 1109: train/loss = 0.40617600083351135, train/raw-loss = 0.34252333641052246, train/logprobs = tensor([[-1.1798, -4.6486],
        [-2.2446, -1.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2546107769012451
Epoch 0, Step 1110: train/loss = 0.24172446131706238, train/raw-loss = 0.17298172414302826, train/logprobs = tensor([[-2.1250, -7.4088],
        [-3.3637, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2749709188938141
Epoch 0, Step 1111: train/loss = 0.29776519536972046, train/raw-loss = 0.24295130372047424, train/logprobs = tensor([[-0.9505, -3.8252],
        [-2.9933, -1.4223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21925568580627441
Epoch 0, Step 1112: train/loss = 0.33394426107406616, train/raw-loss = 0.27819886803627014, train/logprobs = tensor([[-0.6984, -5.7287],
        [-1.7959, -1.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22298160195350647
Epoch 0, Step 1113: train/loss = 0.1953039914369583, train/raw-loss = 0.13169613480567932, train/logprobs = tensor([[-1.0349, -4.8778],
        [-3.0048, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25443142652511597
Epoch 0, Step 1114: train/loss = 0.3316384553909302, train/raw-loss = 0.28031885623931885, train/logprobs = tensor([[-1.5230, -7.9794],
        [-1.5476, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052784264087677
Epoch 0, Step 1115: train/loss = 0.158070906996727, train/raw-loss = 0.08979637920856476, train/logprobs = tensor([[-1.1929, -7.2306],
        [-3.5403, -1.1551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2730981111526489
Epoch 0, Step 1116: train/loss = 0.179014652967453, train/raw-loss = 0.10997961461544037, train/logprobs = tensor([[-1.7628, -4.1204],
        [-3.8604, -1.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2761401832103729
Epoch 0, Step 1117: train/loss = 0.14754422008991241, train/raw-loss = 0.08196628093719482, train/logprobs = tensor([[-1.5814, -6.0044],
        [-3.7810, -0.6791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26231175661087036
Epoch 0, Step 1118: train/loss = 0.5944674611091614, train/raw-loss = 0.5301286578178406, train/logprobs = tensor([[-1.6143, -3.8393],
        [-3.0251, -2.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25735512375831604
Epoch 0, Step 1119: train/loss = 0.28198301792144775, train/raw-loss = 0.20977848768234253, train/logprobs = tensor([[-0.8273, -5.4907],
        [-3.0195, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28881803154945374
Epoch 0, Step 1120: train/loss = 0.1359565705060959, train/raw-loss = 0.07155033200979233, train/logprobs = tensor([[-1.1517, -8.9241],
        [-3.2753, -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25762495398521423
Epoch 0, Step 1121: train/loss = 0.09799203276634216, train/raw-loss = 0.032514169812202454, train/logprobs = tensor([[-1.5784, -6.0557],
        [-4.9025, -0.9833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26191145181655884
Epoch 0, Step 1122: train/loss = 0.4329584240913391, train/raw-loss = 0.3540154695510864, train/logprobs = tensor([[-0.9637, -2.4653],
        [-3.5268, -1.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3157719373703003
Epoch 0, Step 1123: train/loss = 0.36605191230773926, train/raw-loss = 0.30961060523986816, train/logprobs = tensor([[-0.9965, -4.5654],
        [-2.1553, -1.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22576528787612915
Epoch 0, Step 1124: train/loss = 0.11795256286859512, train/raw-loss = 0.04080254212021828, train/logprobs = tensor([[-1.4804, -5.4322],
        [-4.7662, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3086000978946686
Epoch 0, Step 1125: train/loss = 0.4343233108520508, train/raw-loss = 0.3812727630138397, train/logprobs = tensor([[-0.5314, -2.6557],
        [-1.8067, -0.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21220222115516663
Epoch 0, Step 1126: train/loss = 0.17859789729118347, train/raw-loss = 0.11064375936985016, train/logprobs = tensor([[-1.3741, -6.4940],
        [-3.0816, -1.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27181655168533325
Epoch 0, Step 1127: train/loss = 0.2861025929450989, train/raw-loss = 0.2281019538640976, train/logprobs = tensor([[-1.6370, -6.8512],
        [-2.3276, -1.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23200258612632751
Epoch 0, Step 1128: train/loss = 0.132751002907753, train/raw-loss = 0.06479597836732864, train/logprobs = tensor([[-1.6647, -7.4066],
        [-4.2963, -2.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2718201279640198
Epoch 0, Step 1129: train/loss = 0.4929157495498657, train/raw-loss = 0.4420412480831146, train/logprobs = tensor([[-0.7189, -2.3686],
        [-1.4822, -0.8884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20349805057048798
Epoch 0, Step 1130: train/loss = 0.4258456826210022, train/raw-loss = 0.3752247095108032, train/logprobs = tensor([[-0.8959, -4.1798],
        [-2.1158, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20248402655124664
Epoch 0, Step 1131: train/loss = 0.2580864727497101, train/raw-loss = 0.1873912513256073, train/logprobs = tensor([[-1.7155, -6.3198],
        [-3.1535, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28278085589408875
Epoch 0, Step 1132: train/loss = 0.3629871606826782, train/raw-loss = 0.29261448979377747, train/logprobs = tensor([[-1.4515, -3.0556],
        [-3.2953, -1.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2814907729625702
Epoch 0, Step 1133: train/loss = 0.4259550869464874, train/raw-loss = 0.3601653277873993, train/logprobs = tensor([[-1.4071, -2.4473],
        [-3.9646, -1.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26315897703170776
Epoch 0, Step 1134: train/loss = 0.34162652492523193, train/raw-loss = 0.2837633788585663, train/logprobs = tensor([[-1.4602, -4.7125],
        [-3.2382, -0.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23145252466201782
Epoch 0, Step 1135: train/loss = 0.452383816242218, train/raw-loss = 0.3921257257461548, train/logprobs = tensor([[-1.8604, -3.3985],
        [-2.1822, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24103237688541412
Epoch 0, Step 1136: train/loss = 0.34966400265693665, train/raw-loss = 0.30048587918281555, train/logprobs = tensor([[-0.4929, -4.8672],
        [-1.6290, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19671250879764557
Epoch 0, Step 1137: train/loss = 0.31185781955718994, train/raw-loss = 0.24741198122501373, train/logprobs = tensor([[-1.1433, -4.6909],
        [-2.9562, -1.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25778329372406006
Epoch 0, Step 1138: train/loss = 0.4648478627204895, train/raw-loss = 0.4169730246067047, train/logprobs = tensor([[-1.8927, -3.6776],
        [-3.5565, -2.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19149939715862274
Epoch 0, Step 1139: train/loss = 0.4783111810684204, train/raw-loss = 0.42771244049072266, train/logprobs = tensor([[-1.1159, -3.7823],
        [-2.2625, -1.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20239496231079102
Epoch 0, Step 1140: train/loss = 0.37393954396247864, train/raw-loss = 0.324065625667572, train/logprobs = tensor([[-0.6596, -5.0077],
        [-1.0828, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19949579238891602
Epoch 0, Step 1141: train/loss = 0.529818058013916, train/raw-loss = 0.46100008487701416, train/logprobs = tensor([[-1.0568, -1.5846],
        [-2.9136, -1.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2752719521522522
Epoch 0, Step 1142: train/loss = 0.11990628391504288, train/raw-loss = 0.03370776027441025, train/logprobs = tensor([[-1.1677, -5.1806],
        [-4.7828, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3447940945625305
Epoch 0, Step 1143: train/loss = 0.26285862922668457, train/raw-loss = 0.19853529334068298, train/logprobs = tensor([[-0.9941, -4.1353],
        [-2.1905, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572932541370392
Epoch 0, Step 1144: train/loss = 0.2696530818939209, train/raw-loss = 0.21760419011116028, train/logprobs = tensor([[-1.3889, -5.5163],
        [-2.2889, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20819562673568726
Epoch 0, Step 1145: train/loss = 0.2953380048274994, train/raw-loss = 0.23125387728214264, train/logprobs = tensor([[-1.0091, -5.0108],
        [-3.1265, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2563365697860718
Epoch 0, Step 1146: train/loss = 0.3507866859436035, train/raw-loss = 0.30059051513671875, train/logprobs = tensor([[-1.3333, -4.4896],
        [-1.9398, -0.9858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2007846087217331
Epoch 0, Step 1147: train/loss = 0.41507598757743835, train/raw-loss = 0.3617798686027527, train/logprobs = tensor([[-1.1095, -1.9334],
        [-2.4986, -0.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21318462491035461
Epoch 0, Step 1148: train/loss = 0.4692690372467041, train/raw-loss = 0.41366398334503174, train/logprobs = tensor([[-1.4800, -1.3054],
        [-2.8897, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2224203199148178
Epoch 0, Step 1149: train/loss = 0.12781228125095367, train/raw-loss = 0.059432025998830795, train/logprobs = tensor([[-1.2395, -5.5464],
        [-3.6611, -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2735210359096527
Epoch 0, Step 1150: train/loss = 0.3277788758277893, train/raw-loss = 0.2629234492778778, train/logprobs = tensor([[-0.7786, -5.5099],
        [-2.6400, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2594216763973236
Epoch 0, Step 1151: train/loss = 0.32909560203552246, train/raw-loss = 0.2644895315170288, train/logprobs = tensor([[-1.5363, -4.5717],
        [-4.3786, -2.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2584243416786194
Epoch 0, Step 1152: train/loss = 0.16225166618824005, train/raw-loss = 0.11080185323953629, train/logprobs = tensor([[-1.4290, -6.9225],
        [-3.2188, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20579922199249268
Epoch 0, Step 1153: train/loss = 0.30648359656333923, train/raw-loss = 0.2501077651977539, train/logprobs = tensor([[-1.1326, -4.5609],
        [-2.6017, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255033552646637
Epoch 0, Step 1154: train/loss = 0.2464452087879181, train/raw-loss = 0.18042291700839996, train/logprobs = tensor([[-1.0212, -3.6873],
        [-2.9474, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640892267227173
Epoch 0, Step 1155: train/loss = 0.32553333044052124, train/raw-loss = 0.2584374248981476, train/logprobs = tensor([[-1.3710, -2.0440],
        [-4.1394, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.268383651971817
Epoch 0, Step 1156: train/loss = 0.2881970703601837, train/raw-loss = 0.21599167585372925, train/logprobs = tensor([[-1.1967, -4.6766],
        [-2.9920, -1.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28882157802581787
Epoch 0, Step 1157: train/loss = 0.24924057722091675, train/raw-loss = 0.18987935781478882, train/logprobs = tensor([[-0.9519, -2.8220],
        [-3.5078, -1.2419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23744483292102814
Epoch 0, Step 1158: train/loss = 0.40361520648002625, train/raw-loss = 0.35274094343185425, train/logprobs = tensor([[-1.0074, -4.1153],
        [-2.6640, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034970223903656
Epoch 0, Step 1159: train/loss = 0.10193737596273422, train/raw-loss = 0.03541731834411621, train/logprobs = tensor([[-1.0238, -7.4299],
        [-3.8083, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26608026027679443
Epoch 0, Step 1160: train/loss = 0.38929712772369385, train/raw-loss = 0.32817819714546204, train/logprobs = tensor([[-1.1466, -3.0715],
        [-1.8265, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24447569251060486
Epoch 0, Step 1161: train/loss = 0.2695106267929077, train/raw-loss = 0.203378826379776, train/logprobs = tensor([[-0.9477, -5.2306],
        [-3.1030, -1.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2645270824432373
Epoch 0, Step 1162: train/loss = 0.25298815965652466, train/raw-loss = 0.18807026743888855, train/logprobs = tensor([[-1.0668, -3.1494],
        [-3.0794, -0.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25967153906822205
Epoch 0, Step 1163: train/loss = 0.4587509334087372, train/raw-loss = 0.4016750454902649, train/logprobs = tensor([[-2.0939, -3.4759],
        [-2.8739, -1.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22830365598201752
Epoch 0, Step 1164: train/loss = 0.2813871204853058, train/raw-loss = 0.21255674958229065, train/logprobs = tensor([[-1.3084, -3.6623],
        [-3.8283, -1.4226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27532151341438293
Epoch 0, Step 1165: train/loss = 0.43198323249816895, train/raw-loss = 0.37824201583862305, train/logprobs = tensor([[-0.7786, -2.2003],
        [-1.8646, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21496489644050598
Epoch 0, Step 1166: train/loss = 0.2180117517709732, train/raw-loss = 0.1587771326303482, train/logprobs = tensor([[-0.9962, -3.6914],
        [-3.0307, -0.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2369384914636612
Epoch 0, Step 1167: train/loss = 0.6318943500518799, train/raw-loss = 0.5624550580978394, train/logprobs = tensor([[-1.1878, -2.1552],
        [-2.9064, -2.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2777572274208069
Epoch 0, Step 1168: train/loss = 0.41985777020454407, train/raw-loss = 0.3642137944698334, train/logprobs = tensor([[-1.0661, -1.8124],
        [-2.8969, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2225758582353592
Epoch 0, Step 1169: train/loss = 0.16051796078681946, train/raw-loss = 0.10101453959941864, train/logprobs = tensor([[-1.1019, -5.3760],
        [-3.6115, -0.7941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23801369965076447
Epoch 0, Step 1170: train/loss = 0.5827087759971619, train/raw-loss = 0.5398672819137573, train/logprobs = tensor([[-1.0631, -1.8797],
        [-1.1318, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17136603593826294
Epoch 0, Step 1171: train/loss = 0.37172552943229675, train/raw-loss = 0.31590309739112854, train/logprobs = tensor([[-0.8797, -3.2191],
        [-3.3167, -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22328966856002808
Epoch 0, Step 1172: train/loss = 0.42581427097320557, train/raw-loss = 0.3702712953090668, train/logprobs = tensor([[-1.2242, -4.7104],
        [-1.7955, -1.2662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22217194736003876
Epoch 0, Step 1173: train/loss = 0.481850266456604, train/raw-loss = 0.40918266773223877, train/logprobs = tensor([[-1.2277, -3.1529],
        [-3.3501, -1.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29067033529281616
Epoch 0, Step 1174: train/loss = 0.7277749180793762, train/raw-loss = 0.66357421875, train/logprobs = tensor([[-2.5976, -2.7088],
        [-3.2263, -1.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568025588989258
Epoch 0, Step 1175: train/loss = 0.4049169719219208, train/raw-loss = 0.34309783577919006, train/logprobs = tensor([[-1.5495, -4.4949],
        [-4.0641, -2.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2472766786813736
Epoch 0, Step 1176: train/loss = 0.534785270690918, train/raw-loss = 0.44742754101753235, train/logprobs = tensor([[-1.7573, -3.6598],
        [-3.3152, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34943103790283203
Epoch 0, Step 1177: train/loss = 0.20410293340682983, train/raw-loss = 0.15524357557296753, train/logprobs = tensor([[-1.1449, -6.9827],
        [-2.3864, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19543741643428802
Epoch 0, Step 1178: train/loss = 0.5749301910400391, train/raw-loss = 0.5272216796875, train/logprobs = tensor([[-1.2660, -1.8742],
        [-2.2641, -1.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19083403050899506
Epoch 0, Step 1179: train/loss = 0.2417186200618744, train/raw-loss = 0.1910056173801422, train/logprobs = tensor([[-0.7575, -7.2471],
        [-1.5537, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2028520107269287
Epoch 0, Step 1180: train/loss = 0.5187579989433289, train/raw-loss = 0.4657796621322632, train/logprobs = tensor([[-1.5011, -5.6265],
        [-3.3581, -2.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21191325783729553
Epoch 0, Step 1181: train/loss = 0.5057433843612671, train/raw-loss = 0.44458186626434326, train/logprobs = tensor([[-1.6679, -3.8628],
        [-2.8056, -1.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2446461021900177
Epoch 0, Step 1182: train/loss = 0.34083783626556396, train/raw-loss = 0.26561790704727173, train/logprobs = tensor([[-1.5582, -5.1563],
        [-3.5067, -2.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30087971687316895
Epoch 0, Step 1183: train/loss = 0.42105358839035034, train/raw-loss = 0.3709011971950531, train/logprobs = tensor([[-0.8574, -2.5105],
        [-2.5549, -0.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20060944557189941
Epoch 0, Step 1184: train/loss = 0.6244372725486755, train/raw-loss = 0.5680727958679199, train/logprobs = tensor([[-1.7504, -2.1086],
        [-3.0364, -2.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22545795142650604
Epoch 0, Step 1185: train/loss = 0.4300737977027893, train/raw-loss = 0.36983275413513184, train/logprobs = tensor([[-1.6035, -3.8684],
        [-2.8383, -2.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24096432328224182
Epoch 0, Step 1186: train/loss = 0.5021438002586365, train/raw-loss = 0.4393109381198883, train/logprobs = tensor([[-1.8728, -2.1295],
        [-3.1373, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25133150815963745
Epoch 0, Step 1187: train/loss = 0.3606565594673157, train/raw-loss = 0.3172900378704071, train/logprobs = tensor([[-0.7004, -3.7996],
        [-1.5552, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734660118818283
Epoch 0, Step 1188: train/loss = 0.15711012482643127, train/raw-loss = 0.09407774358987808, train/logprobs = tensor([[-0.6830, -5.4752],
        [-2.8142, -1.3709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.252129465341568
Epoch 0, Step 1189: train/loss = 0.6082426905632019, train/raw-loss = 0.5571095943450928, train/logprobs = tensor([[-1.2252, -3.3249],
        [-1.2558, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045324295759201
Epoch 0, Step 1190: train/loss = 0.32963913679122925, train/raw-loss = 0.27711790800094604, train/logprobs = tensor([[-2.1040, -3.0114],
        [-3.2979, -0.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21008485555648804
Epoch 0, Step 1191: train/loss = 0.3779500722885132, train/raw-loss = 0.31956517696380615, train/logprobs = tensor([[-1.0136, -3.1799],
        [-2.4362, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23353959619998932
Epoch 0, Step 1192: train/loss = 0.2934166193008423, train/raw-loss = 0.2385435700416565, train/logprobs = tensor([[-0.7332, -3.6212],
        [-2.3174, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21949227154254913
Epoch 0, Step 1193: train/loss = 0.45124146342277527, train/raw-loss = 0.397477924823761, train/logprobs = tensor([[-1.9046, -5.7542],
        [-2.2091, -0.7461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21505406498908997
Epoch 0, Step 1194: train/loss = 0.41915279626846313, train/raw-loss = 0.36368727684020996, train/logprobs = tensor([[-1.5601, -3.6782],
        [-3.0490, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22186210751533508
Epoch 0, Step 1195: train/loss = 0.17243263125419617, train/raw-loss = 0.08980079740285873, train/logprobs = tensor([[-1.2748, -4.7225],
        [-4.1408, -1.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33052730560302734
Epoch 0, Step 1196: train/loss = 0.6245536208152771, train/raw-loss = 0.5768189430236816, train/logprobs = tensor([[-3.6127, -4.1646],
        [-4.3280, -2.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1909388303756714
Epoch 0, Step 1197: train/loss = 0.39907702803611755, train/raw-loss = 0.33812248706817627, train/logprobs = tensor([[-1.1028, -3.9514],
        [-2.3832, -1.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24381804466247559
Epoch 0, Step 1198: train/loss = 0.6475107669830322, train/raw-loss = 0.5937305092811584, train/logprobs = tensor([[-0.7090, -1.4844],
        [-1.9081, -1.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21512098610401154
Epoch 0, Step 1199: train/loss = 0.24819163978099823, train/raw-loss = 0.1932402104139328, train/logprobs = tensor([[-0.8827, -4.4980],
        [-2.9657, -1.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21980570256710052
Epoch 0, Step 1200: train/loss = 0.21262508630752563, train/raw-loss = 0.1585889756679535, train/logprobs = tensor([[-0.6362, -7.8157],
        [-1.9708, -2.2954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21614450216293335
Epoch 0, Step 1201: train/loss = 0.1585444062948227, train/raw-loss = 0.09589521586894989, train/logprobs = tensor([[-1.3991, -4.4975],
        [-4.4776, -0.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2505967617034912
Epoch 0, Step 1202: train/loss = 0.4608948826789856, train/raw-loss = 0.42123734951019287, train/logprobs = tensor([[-1.5092, -3.4159],
        [-2.0502, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1586301177740097
Epoch 0, Step 1203: train/loss = 0.3658636808395386, train/raw-loss = 0.3015350103378296, train/logprobs = tensor([[-0.9305, -5.2553],
        [-3.3613, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2573147714138031
Epoch 0, Step 1204: train/loss = 0.4465729594230652, train/raw-loss = 0.38619768619537354, train/logprobs = tensor([[-0.8413, -2.0081],
        [-1.9294, -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2415010780096054
Epoch 0, Step 1205: train/loss = 0.1404164582490921, train/raw-loss = 0.0775769054889679, train/logprobs = tensor([[-1.0637, -4.4246],
        [-3.5779, -0.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513582408428192
Epoch 0, Step 1206: train/loss = 0.3150637447834015, train/raw-loss = 0.24005486071109772, train/logprobs = tensor([[-1.5248, -5.5769],
        [-4.0643, -1.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30003559589385986
Epoch 0, Step 1207: train/loss = 0.19629232585430145, train/raw-loss = 0.1365194320678711, train/logprobs = tensor([[-1.0341, -3.9944],
        [-3.3497, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23909154534339905
Epoch 0, Step 1208: train/loss = 0.3142002820968628, train/raw-loss = 0.2638380229473114, train/logprobs = tensor([[-0.6428, -5.8660],
        [-1.4483, -2.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2014489620923996
Epoch 0, Step 1209: train/loss = 0.3096170425415039, train/raw-loss = 0.25397831201553345, train/logprobs = tensor([[-1.1076, -3.3154],
        [-2.7687, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22255490720272064
Epoch 0, Step 1210: train/loss = 0.43773186206817627, train/raw-loss = 0.38500404357910156, train/logprobs = tensor([[-1.0302, -2.9799],
        [-2.2493, -0.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21091118454933167
Epoch 0, Step 1211: train/loss = 0.6853863596916199, train/raw-loss = 0.6302007436752319, train/logprobs = tensor([[-2.9056, -4.6653],
        [-3.1763, -2.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22074243426322937
Epoch 0, Step 1212: train/loss = 0.412748247385025, train/raw-loss = 0.3608013093471527, train/logprobs = tensor([[-2.2515, -3.3685],
        [-4.5642, -2.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20778776705265045
Epoch 0, Step 1213: train/loss = 0.37414827942848206, train/raw-loss = 0.32229024171829224, train/logprobs = tensor([[-0.6669, -4.0629],
        [-1.4425, -1.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20743218064308167
Epoch 0, Step 1214: train/loss = 0.2740926146507263, train/raw-loss = 0.2244689017534256, train/logprobs = tensor([[-0.7753, -5.7225],
        [-2.5416, -1.3709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1984948068857193
Epoch 0, Step 1215: train/loss = 0.373976469039917, train/raw-loss = 0.31180381774902344, train/logprobs = tensor([[-1.0490, -4.7933],
        [-2.1347, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24869054555892944
Epoch 0, Step 1216: train/loss = 0.35756462812423706, train/raw-loss = 0.2968182861804962, train/logprobs = tensor([[-1.0235, -4.3579],
        [-2.2522, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2429853081703186
Epoch 0, Step 1217: train/loss = 0.1615539789199829, train/raw-loss = 0.10760152339935303, train/logprobs = tensor([[-0.9745, -7.4847],
        [-2.6594, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21580976247787476
Epoch 0, Step 1218: train/loss = 0.42387551069259644, train/raw-loss = 0.3630819618701935, train/logprobs = tensor([[-1.8122, -4.0249],
        [-3.0990, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431742250919342
Epoch 0, Step 1219: train/loss = 0.49719560146331787, train/raw-loss = 0.44399917125701904, train/logprobs = tensor([[-1.9572, -4.9121],
        [-2.3602, -2.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21278567612171173
Epoch 0, Step 1220: train/loss = 0.39838671684265137, train/raw-loss = 0.3374462425708771, train/logprobs = tensor([[-0.9788, -6.7669],
        [-2.4026, -2.3866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24376192688941956
Epoch 0, Step 1221: train/loss = 0.21983443200588226, train/raw-loss = 0.16127847135066986, train/logprobs = tensor([[-1.5503, -6.0367],
        [-3.9742, -2.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23422381281852722
Epoch 0, Step 1222: train/loss = 0.16665934026241302, train/raw-loss = 0.10658985376358032, train/logprobs = tensor([[-1.7650, -5.7496],
        [-3.9521, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24027793109416962
Epoch 0, Step 1223: train/loss = 0.44758832454681396, train/raw-loss = 0.37878331542015076, train/logprobs = tensor([[-2.0392, -4.2550],
        [-3.1670, -1.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27522000670433044
Epoch 0, Step 1224: train/loss = 0.44194555282592773, train/raw-loss = 0.3893693685531616, train/logprobs = tensor([[-1.1929, -3.8858],
        [-2.1910, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2103048861026764
Epoch 0, Step 1225: train/loss = 0.40771859884262085, train/raw-loss = 0.35157138109207153, train/logprobs = tensor([[-1.2465, -3.8850],
        [-3.1468, -1.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22458884119987488
Epoch 0, Step 1226: train/loss = 0.4126179814338684, train/raw-loss = 0.35276296734809875, train/logprobs = tensor([[-1.3980, -4.8173],
        [-2.7851, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23942022025585175
Epoch 0, Step 1227: train/loss = 0.29688501358032227, train/raw-loss = 0.24679537117481232, train/logprobs = tensor([[-1.1534, -7.4504],
        [-2.3042, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20035859942436218
Epoch 0, Step 1228: train/loss = 0.37461695075035095, train/raw-loss = 0.3231564164161682, train/logprobs = tensor([[-1.2099, -3.6172],
        [-2.7770, -1.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20584216713905334
Epoch 0, Step 1229: train/loss = 0.09938771277666092, train/raw-loss = 0.03312474861741066, train/logprobs = tensor([[-0.8248, -5.6679],
        [-3.7186, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26505184173583984
Epoch 0, Step 1230: train/loss = 0.12204200029373169, train/raw-loss = 0.06274278461933136, train/logprobs = tensor([[-1.5019, -6.4609],
        [-3.7240, -1.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2371968775987625
Epoch 0, Step 1231: train/loss = 0.19804072380065918, train/raw-loss = 0.12867800891399384, train/logprobs = tensor([[-1.8918, -4.4048],
        [-3.8283, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.277450829744339
Epoch 0, Step 1232: train/loss = 0.20607855916023254, train/raw-loss = 0.14757785201072693, train/logprobs = tensor([[-0.9690, -5.3947],
        [-3.1543, -1.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23400276899337769
Epoch 0, Step 1233: train/loss = 0.3276020884513855, train/raw-loss = 0.2725623548030853, train/logprobs = tensor([[-0.6288, -4.1509],
        [-1.8905, -1.1953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2201586365699768
Epoch 0, Step 1234: train/loss = 0.40047988295555115, train/raw-loss = 0.34244465827941895, train/logprobs = tensor([[-1.0709, -3.3032],
        [-2.6295, -1.8712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23214080929756165
Epoch 0, Step 1235: train/loss = 0.3134467601776123, train/raw-loss = 0.2623130977153778, train/logprobs = tensor([[-1.1737, -4.4139],
        [-2.0551, -0.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2045346200466156
Epoch 0, Step 1236: train/loss = 0.2144819051027298, train/raw-loss = 0.1460862159729004, train/logprobs = tensor([[-1.2543, -4.1011],
        [-3.0166, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27358269691467285
Epoch 0, Step 1237: train/loss = 0.49439749121665955, train/raw-loss = 0.4322557747364044, train/logprobs = tensor([[-1.6490, -4.1005],
        [-2.8988, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24856680631637573
Epoch 0, Step 1238: train/loss = 0.5729503631591797, train/raw-loss = 0.5243384838104248, train/logprobs = tensor([[-1.6922, -4.0208],
        [-1.6664, -1.3133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19444753229618073
Epoch 0, Step 1239: train/loss = 0.4772929847240448, train/raw-loss = 0.43117356300354004, train/logprobs = tensor([[-2.2581, -2.9119],
        [-3.2196, -1.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18447750806808472
Epoch 0, Step 1240: train/loss = 0.14972007274627686, train/raw-loss = 0.08185461163520813, train/logprobs = tensor([[-1.1198, -4.7542],
        [-3.3676, -1.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27146175503730774
Epoch 0, Step 1241: train/loss = 0.44596725702285767, train/raw-loss = 0.39511364698410034, train/logprobs = tensor([[-1.3372, -1.6668],
        [-2.9266, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20341435074806213
Epoch 0, Step 1242: train/loss = 0.4145861268043518, train/raw-loss = 0.36319130659103394, train/logprobs = tensor([[-1.4281, -3.1309],
        [-2.1402, -1.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20557928085327148
Epoch 0, Step 1243: train/loss = 0.32625892758369446, train/raw-loss = 0.2775861620903015, train/logprobs = tensor([[-2.4446, -7.8154],
        [-2.7928, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19469109177589417
Epoch 0, Step 1244: train/loss = 0.2636930048465729, train/raw-loss = 0.19506576657295227, train/logprobs = tensor([[-1.9535, -4.3233],
        [-4.5298, -1.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2745090126991272
Epoch 0, Step 1245: train/loss = 0.23491039872169495, train/raw-loss = 0.17443346977233887, train/logprobs = tensor([[-1.1855, -3.8140],
        [-3.0221, -1.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24190771579742432
Epoch 0, Step 1246: train/loss = 0.28430551290512085, train/raw-loss = 0.23139341175556183, train/logprobs = tensor([[-0.9330, -6.3135],
        [-2.7933, -1.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21164840459823608
Epoch 0, Step 1247: train/loss = 0.19405338168144226, train/raw-loss = 0.12604635953903198, train/logprobs = tensor([[-0.8403, -4.3804],
        [-2.9080, -0.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2720280885696411
Epoch 0, Step 1248: train/loss = 0.4994668960571289, train/raw-loss = 0.4426170289516449, train/logprobs = tensor([[-2.8760, -7.5913],
        [-3.2917, -2.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22739946842193604
Epoch 0, Step 1249: train/loss = 0.39072465896606445, train/raw-loss = 0.32573816180229187, train/logprobs = tensor([[-1.5053, -3.6788],
        [-3.4764, -1.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25994598865509033
Epoch 0, Step 1250: train/loss = 0.32481274008750916, train/raw-loss = 0.2793338894844055, train/logprobs = tensor([[-1.0315, -3.6701],
        [-2.3346, -1.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18191538751125336
Epoch 0, Step 1251: train/loss = 0.6830284595489502, train/raw-loss = 0.6174411177635193, train/logprobs = tensor([[-0.8722, -4.0060],
        [-2.6974, -2.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26234927773475647
Epoch 0, Step 1252: train/loss = 0.37969499826431274, train/raw-loss = 0.32642966508865356, train/logprobs = tensor([[-1.1370, -2.8416],
        [-2.6506, -0.8164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21306133270263672
Epoch 0, Step 1253: train/loss = 0.2685936689376831, train/raw-loss = 0.21610629558563232, train/logprobs = tensor([[-1.7280, -4.5057],
        [-4.2470, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20994947850704193
Epoch 0, Step 1254: train/loss = 0.2721008062362671, train/raw-loss = 0.20509456098079681, train/logprobs = tensor([[-0.7563, -5.0654],
        [-2.9453, -1.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2680250406265259
Epoch 0, Step 1255: train/loss = 0.309688538312912, train/raw-loss = 0.2473425567150116, train/logprobs = tensor([[-0.9639, -4.0384],
        [-2.7919, -1.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24938389658927917
Epoch 0, Step 1256: train/loss = 0.3825874924659729, train/raw-loss = 0.3306865096092224, train/logprobs = tensor([[-0.9918, -3.6071],
        [-2.4466, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20760396122932434
Epoch 0, Step 1257: train/loss = 0.21565461158752441, train/raw-loss = 0.16683922708034515, train/logprobs = tensor([[-1.3633, -4.1649],
        [-3.3637, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19526156783103943
Epoch 0, Step 1258: train/loss = 0.5053918957710266, train/raw-loss = 0.4520900249481201, train/logprobs = tensor([[-1.0320, -3.3096],
        [-1.9894, -1.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21320733428001404
Epoch 0, Step 1259: train/loss = 0.24920132756233215, train/raw-loss = 0.20284830033779144, train/logprobs = tensor([[-1.1543, -3.9059],
        [-3.1676, -0.6877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18541207909584045
Epoch 0, Step 1260: train/loss = 0.20438803732395172, train/raw-loss = 0.14205391705036163, train/logprobs = tensor([[-1.5102, -6.2009],
        [-3.1569, -1.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24933645129203796
Epoch 0, Step 1261: train/loss = 0.1707490086555481, train/raw-loss = 0.10868720710277557, train/logprobs = tensor([[-1.0752, -5.4217],
        [-3.5891, -1.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2482471764087677
Epoch 0, Step 1262: train/loss = 0.3378046751022339, train/raw-loss = 0.2813575267791748, train/logprobs = tensor([[-0.8405, -4.1395],
        [-2.4921, -1.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22578851878643036
Epoch 0, Step 1263: train/loss = 0.3182964324951172, train/raw-loss = 0.26804742217063904, train/logprobs = tensor([[-0.5553, -3.2445],
        [-1.8583, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2009960561990738
Epoch 0, Step 1264: train/loss = 0.34733280539512634, train/raw-loss = 0.29469364881515503, train/logprobs = tensor([[-0.9543, -4.1524],
        [-2.2952, -0.7859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21055662631988525
Epoch 0, Step 1265: train/loss = 0.3362959623336792, train/raw-loss = 0.2688506841659546, train/logprobs = tensor([[-2.0174, -3.7386],
        [-3.2662, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26978111267089844
Epoch 0, Step 1266: train/loss = 0.21949395537376404, train/raw-loss = 0.15750855207443237, train/logprobs = tensor([[-1.1288, -6.9797],
        [-3.0880, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24794159829616547
Epoch 0, Step 1267: train/loss = 0.6894038319587708, train/raw-loss = 0.6365946531295776, train/logprobs = tensor([[-1.2970, -2.3756],
        [-2.1741, -2.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21123677492141724
Epoch 0, Step 1268: train/loss = 0.4079797863960266, train/raw-loss = 0.35622137784957886, train/logprobs = tensor([[-0.5810, -2.3272],
        [-2.0375, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20703376829624176
Epoch 0, Step 1269: train/loss = 0.24734431505203247, train/raw-loss = 0.17262333631515503, train/logprobs = tensor([[-0.9605, -4.1595],
        [-2.8901, -0.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29888397455215454
Epoch 0, Step 1270: train/loss = 0.1708267778158188, train/raw-loss = 0.11044391989707947, train/logprobs = tensor([[-1.6311, -6.0871],
        [-3.3136, -0.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24153143167495728
Epoch 0, Step 1271: train/loss = 0.2223537415266037, train/raw-loss = 0.15950673818588257, train/logprobs = tensor([[-0.7540, -5.3135],
        [-2.1470, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2513880431652069
Epoch 0, Step 1272: train/loss = 0.8252645134925842, train/raw-loss = 0.758022665977478, train/logprobs = tensor([[-0.6499, -1.0819],
        [-2.2229, -2.3329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26896753907203674
Epoch 0, Step 1273: train/loss = 0.4025343060493469, train/raw-loss = 0.33766263723373413, train/logprobs = tensor([[-1.2035, -2.5728],
        [-2.9996, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25948673486709595
Epoch 0, Step 1274: train/loss = 0.32291096448898315, train/raw-loss = 0.26305264234542847, train/logprobs = tensor([[-0.9447, -5.6536],
        [-3.7868, -1.6338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23943328857421875
Epoch 0, Step 1275: train/loss = 0.31101298332214355, train/raw-loss = 0.24487969279289246, train/logprobs = tensor([[-1.4181, -5.1653],
        [-4.2260, -1.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26453307271003723
Epoch 0, Step 1276: train/loss = 0.46493250131607056, train/raw-loss = 0.402118444442749, train/logprobs = tensor([[-1.3959, -3.1019],
        [-4.3749, -1.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25125622749328613
Epoch 0, Step 1277: train/loss = 0.4065295457839966, train/raw-loss = 0.3480360507965088, train/logprobs = tensor([[-0.7592, -3.7938],
        [-2.2006, -1.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23397395014762878
Epoch 0, Step 1278: train/loss = 0.3733389973640442, train/raw-loss = 0.3229290246963501, train/logprobs = tensor([[-1.4278, -4.2176],
        [-2.4120, -1.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20163986086845398
Epoch 0, Step 1279: train/loss = 0.3081821799278259, train/raw-loss = 0.24556827545166016, train/logprobs = tensor([[-0.5497, -5.1930],
        [-2.2615, -1.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25045567750930786
Epoch 0, Step 1280: train/loss = 0.32871314883232117, train/raw-loss = 0.2689249515533447, train/logprobs = tensor([[-1.9007, -4.7155],
        [-3.7586, -2.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23915278911590576
Epoch 0, Step 1281: train/loss = 0.1835651993751526, train/raw-loss = 0.13134875893592834, train/logprobs = tensor([[-0.4714, -4.9690],
        [-1.9245, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20886576175689697
Epoch 0, Step 1282: train/loss = 0.2188551425933838, train/raw-loss = 0.16567066311836243, train/logprobs = tensor([[-0.9874, -5.5888],
        [-3.4448, -1.3762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2127378284931183
Epoch 0, Step 1283: train/loss = 0.5724308490753174, train/raw-loss = 0.523693323135376, train/logprobs = tensor([[-0.6359, -2.5564],
        [-1.3021, -1.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19494998455047607
Epoch 0, Step 1284: train/loss = 0.42807233333587646, train/raw-loss = 0.37137001752853394, train/logprobs = tensor([[-1.8968, -4.7147],
        [-3.3865, -2.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2268092930316925
Epoch 0, Step 1285: train/loss = 0.4210938811302185, train/raw-loss = 0.36176350712776184, train/logprobs = tensor([[-1.7025, -3.3131],
        [-3.7872, -1.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23732146620750427
Epoch 0, Step 1286: train/loss = 0.3784642219543457, train/raw-loss = 0.3274803161621094, train/logprobs = tensor([[-2.1293, -2.6350],
        [-4.6590, -1.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20393551886081696
Epoch 0, Step 1287: train/loss = 0.4344351589679718, train/raw-loss = 0.374083012342453, train/logprobs = tensor([[-1.1512, -3.2130],
        [-3.4684, -2.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24140842258930206
Epoch 0, Step 1288: train/loss = 0.28453153371810913, train/raw-loss = 0.22572030127048492, train/logprobs = tensor([[-1.2505, -4.9557],
        [-2.5173, -1.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2352449893951416
Epoch 0, Step 1289: train/loss = 0.6371743083000183, train/raw-loss = 0.5803506374359131, train/logprobs = tensor([[-2.4518, -3.1128],
        [-2.6249, -1.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2272946834564209
Epoch 0, Step 1290: train/loss = 0.37766218185424805, train/raw-loss = 0.31449681520462036, train/logprobs = tensor([[-2.0162, -7.3744],
        [-3.8061, -2.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2526615262031555
Epoch 0, Step 1291: train/loss = 0.3460124433040619, train/raw-loss = 0.2906149625778198, train/logprobs = tensor([[-0.8303, -3.6506],
        [-3.2558, -1.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215898633003235
Epoch 0, Step 1292: train/loss = 0.28974780440330505, train/raw-loss = 0.23892390727996826, train/logprobs = tensor([[-1.6003, -2.5965],
        [-3.2898, -0.8201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20329567790031433
Epoch 0, Step 1293: train/loss = 0.20143011212348938, train/raw-loss = 0.15313449501991272, train/logprobs = tensor([[-1.4392, -6.5727],
        [-2.8041, -2.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19318243861198425
Epoch 0, Step 1294: train/loss = 0.38344988226890564, train/raw-loss = 0.3192984163761139, train/logprobs = tensor([[-0.7775, -3.2451],
        [-2.6262, -1.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566058337688446
Epoch 0, Step 1295: train/loss = 0.1954202950000763, train/raw-loss = 0.12160512804985046, train/logprobs = tensor([[-0.8920, -3.1908],
        [-4.2126, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952606678009033
Epoch 0, Step 1296: train/loss = 0.3831391930580139, train/raw-loss = 0.3211643397808075, train/logprobs = tensor([[-1.0225, -2.5164],
        [-3.4397, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2478993833065033
Epoch 0, Step 1297: train/loss = 0.4446799159049988, train/raw-loss = 0.3971099257469177, train/logprobs = tensor([[-0.9031, -3.4787],
        [-1.7539, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1902799904346466
Epoch 0, Step 1298: train/loss = 0.30745458602905273, train/raw-loss = 0.2503410577774048, train/logprobs = tensor([[-2.4392, -3.3850],
        [-3.9218, -0.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2284541130065918
Epoch 0, Step 1299: train/loss = 0.4952959418296814, train/raw-loss = 0.43302983045578003, train/logprobs = tensor([[-1.3587, -4.4253],
        [-1.7342, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2490643858909607
Epoch 0, Step 1300: train/loss = 0.21798673272132874, train/raw-loss = 0.15647394955158234, train/logprobs = tensor([[-0.8638, -4.8167],
        [-2.9119, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24605116248130798
Epoch 0, Step 1301: train/loss = 0.5293688774108887, train/raw-loss = 0.48717617988586426, train/logprobs = tensor([[-0.7095, -3.6150],
        [-1.7610, -1.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16877083480358124
Epoch 0, Step 1302: train/loss = 0.1229669377207756, train/raw-loss = 0.050611503422260284, train/logprobs = tensor([[-1.2527, -4.2190],
        [-4.5011, -1.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2894217073917389
Epoch 0, Step 1303: train/loss = 0.26296693086624146, train/raw-loss = 0.21203626692295074, train/logprobs = tensor([[-1.1336, -4.4039],
        [-2.9061, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20372271537780762
Epoch 0, Step 1304: train/loss = 0.13941332697868347, train/raw-loss = 0.07461405545473099, train/logprobs = tensor([[-0.8723, -4.4542],
        [-3.8593, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25919708609580994
Epoch 0, Step 1305: train/loss = 0.32134562730789185, train/raw-loss = 0.25488775968551636, train/logprobs = tensor([[-0.8050, -4.0228],
        [-2.9235, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658315598964691
Epoch 0, Step 1306: train/loss = 0.14925169944763184, train/raw-loss = 0.08833428472280502, train/logprobs = tensor([[-0.9637, -4.2053],
        [-3.6788, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24366962909698486
Epoch 0, Step 1307: train/loss = 0.3354080021381378, train/raw-loss = 0.2813834249973297, train/logprobs = tensor([[-1.3394, -4.2043],
        [-3.2008, -1.7506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21609830856323242
Epoch 0, Step 1308: train/loss = 0.6199830770492554, train/raw-loss = 0.5624409914016724, train/logprobs = tensor([[-2.1205, -2.6197],
        [-3.6614, -1.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23016810417175293
Epoch 0, Step 1309: train/loss = 0.15053267776966095, train/raw-loss = 0.08251810818910599, train/logprobs = tensor([[-1.1588, -5.6895],
        [-4.3138, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27205824851989746
Epoch 0, Step 1310: train/loss = 0.6393043398857117, train/raw-loss = 0.5906600952148438, train/logprobs = tensor([[-2.0725, -4.3301],
        [-1.3561, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19457712769508362
Epoch 0, Step 1311: train/loss = 0.39218592643737793, train/raw-loss = 0.34157970547676086, train/logprobs = tensor([[-1.5289, -3.4676],
        [-3.4992, -1.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20242495834827423
Epoch 0, Step 1312: train/loss = 0.41575825214385986, train/raw-loss = 0.3568297028541565, train/logprobs = tensor([[-1.7974, -4.7347],
        [-3.1557, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2357141077518463
Epoch 0, Step 1313: train/loss = 0.2980450987815857, train/raw-loss = 0.24091270565986633, train/logprobs = tensor([[-0.8541, -4.7522],
        [-2.2025, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22852951288223267
Epoch 0, Step 1314: train/loss = 0.20821446180343628, train/raw-loss = 0.14849336445331573, train/logprobs = tensor([[-1.2278, -4.5692],
        [-4.1655, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23888438940048218
Epoch 0, Step 1315: train/loss = 0.1746618002653122, train/raw-loss = 0.10884719341993332, train/logprobs = tensor([[-1.1204, -4.2768],
        [-3.5955, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2632584571838379
Epoch 0, Step 1316: train/loss = 0.24112644791603088, train/raw-loss = 0.1750091314315796, train/logprobs = tensor([[-1.5199, -3.1892],
        [-4.0966, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644692659378052
Epoch 0, Step 1317: train/loss = 0.5496760606765747, train/raw-loss = 0.4971674084663391, train/logprobs = tensor([[-2.2466, -3.9312],
        [-2.7703, -1.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21003474295139313
Epoch 0, Step 1318: train/loss = 0.4160141050815582, train/raw-loss = 0.3705984354019165, train/logprobs = tensor([[-0.8180, -2.4125],
        [-1.9643, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816626936197281
Epoch 0, Step 1319: train/loss = 0.14772513508796692, train/raw-loss = 0.0738430917263031, train/logprobs = tensor([[-1.3424, -4.9118],
        [-4.6636, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2955281734466553
Epoch 0, Step 1320: train/loss = 0.2568126320838928, train/raw-loss = 0.20152926445007324, train/logprobs = tensor([[-0.8426, -6.9628],
        [-2.2112, -1.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2211335301399231
Epoch 0, Step 1321: train/loss = 0.3450445234775543, train/raw-loss = 0.28127965331077576, train/logprobs = tensor([[-1.4341, -4.2323],
        [-3.7785, -1.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25505951046943665
Epoch 0, Step 1322: train/loss = 0.2134966254234314, train/raw-loss = 0.14820808172225952, train/logprobs = tensor([[-1.4472, -3.7299],
        [-5.6454, -1.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611542046070099
Epoch 0, Step 1323: train/loss = 0.27516135573387146, train/raw-loss = 0.20830057561397552, train/logprobs = tensor([[-1.0748, -2.9517],
        [-2.5877, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26744312047958374
Epoch 0, Step 1324: train/loss = 0.16861891746520996, train/raw-loss = 0.1046191155910492, train/logprobs = tensor([[-1.7613, -6.8097],
        [-4.2034, -1.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25599920749664307
Epoch 0, Step 1325: train/loss = 0.16829732060432434, train/raw-loss = 0.10681267827749252, train/logprobs = tensor([[-1.1538, -4.9537],
        [-3.5913, -1.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2459385246038437
Epoch 0, Step 1326: train/loss = 0.40654221177101135, train/raw-loss = 0.35649144649505615, train/logprobs = tensor([[-1.4337, -3.3774],
        [-3.9178, -1.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20020325481891632
Epoch 0, Step 1327: train/loss = 0.45472097396850586, train/raw-loss = 0.39837709069252014, train/logprobs = tensor([[-2.2096, -4.0917],
        [-2.7991, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22537538409233093
Epoch 0, Step 1328: train/loss = 0.7107658386230469, train/raw-loss = 0.6768883466720581, train/logprobs = tensor([[-2.5515, -5.0522],
        [-1.2653, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355098932981491
Epoch 0, Step 1329: train/loss = 0.45666563510894775, train/raw-loss = 0.40218496322631836, train/logprobs = tensor([[-2.4190, -1.9879],
        [-4.2468, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21792268753051758
Epoch 0, Step 1330: train/loss = 0.42214372754096985, train/raw-loss = 0.3585711121559143, train/logprobs = tensor([[-1.5614, -5.9363],
        [-5.2648, -2.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542904019355774
Epoch 0, Step 1331: train/loss = 0.15563394129276276, train/raw-loss = 0.08895692229270935, train/logprobs = tensor([[-1.0246, -6.1214],
        [-3.2639, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26670804619789124
Epoch 0, Step 1332: train/loss = 0.26872724294662476, train/raw-loss = 0.2207649201154709, train/logprobs = tensor([[-1.8600, -4.0525],
        [-4.1350, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19184932112693787
Epoch 0, Step 1333: train/loss = 0.5274983644485474, train/raw-loss = 0.4708464443683624, train/logprobs = tensor([[-1.3247, -2.8082],
        [-3.3118, -1.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22660768032073975
Epoch 0, Step 1334: train/loss = 0.2678143382072449, train/raw-loss = 0.19744190573692322, train/logprobs = tensor([[-0.8189, -3.8023],
        [-3.7780, -1.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28148970007896423
Epoch 0, Step 1335: train/loss = 0.36938929557800293, train/raw-loss = 0.3151538074016571, train/logprobs = tensor([[-0.6149, -2.9356],
        [-2.5928, -0.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21694201231002808
Epoch 0, Step 1336: train/loss = 0.4298277795314789, train/raw-loss = 0.3691713213920593, train/logprobs = tensor([[-1.3112, -4.0801],
        [-3.0335, -1.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24262577295303345
Epoch 0, Step 1337: train/loss = 0.40827760100364685, train/raw-loss = 0.3413042724132538, train/logprobs = tensor([[-1.0724, -5.4100],
        [-4.6929, -2.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26789340376853943
Epoch 0, Step 1338: train/loss = 0.40197426080703735, train/raw-loss = 0.3457489311695099, train/logprobs = tensor([[-1.1531, -2.3659],
        [-2.8618, -1.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2249012589454651
Epoch 0, Step 1339: train/loss = 0.10459651052951813, train/raw-loss = 0.042768437415361404, train/logprobs = tensor([[-1.2971, -6.9476],
        [-4.2920, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24731230735778809
Epoch 0, Step 1340: train/loss = 0.3155003786087036, train/raw-loss = 0.26873862743377686, train/logprobs = tensor([[-0.8990, -4.2759],
        [-1.9448, -1.4301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870470941066742
Epoch 0, Step 1341: train/loss = 0.5864320993423462, train/raw-loss = 0.5341790318489075, train/logprobs = tensor([[-1.1521, -2.8175],
        [-2.5589, -1.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20901226997375488
Epoch 0, Step 1342: train/loss = 0.28721117973327637, train/raw-loss = 0.22564631700515747, train/logprobs = tensor([[-1.5873, -3.2913],
        [-6.1420, -1.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24625936150550842
Epoch 0, Step 1343: train/loss = 0.11098963022232056, train/raw-loss = 0.03777562454342842, train/logprobs = tensor([[-1.0714, -7.1737],
        [-4.8333, -1.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29285603761672974
Epoch 0, Step 1344: train/loss = 0.4413968324661255, train/raw-loss = 0.37600409984588623, train/logprobs = tensor([[-2.0487, -3.4976],
        [-4.2667, -1.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2615710198879242
Epoch 0, Step 1345: train/loss = 0.3438316583633423, train/raw-loss = 0.2745779752731323, train/logprobs = tensor([[-2.3710, -3.9061],
        [-3.7709, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770146131515503
Epoch 0, Step 1346: train/loss = 0.19591304659843445, train/raw-loss = 0.12845976650714874, train/logprobs = tensor([[-1.3497, -4.9509],
        [-3.3059, -1.4134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698131799697876
Epoch 0, Step 1347: train/loss = 0.6183141469955444, train/raw-loss = 0.5691487193107605, train/logprobs = tensor([[-0.9934, -3.5285],
        [-2.3078, -2.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19666162133216858
Epoch 0, Step 1348: train/loss = 0.6617473363876343, train/raw-loss = 0.6186755895614624, train/logprobs = tensor([[-2.2561, -3.8400],
        [-2.4751, -2.0471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17228692770004272
Epoch 0, Step 1349: train/loss = 0.48490309715270996, train/raw-loss = 0.44125068187713623, train/logprobs = tensor([[-0.6223, -2.8611],
        [-1.4444, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1746097356081009
Epoch 0, Step 1350: train/loss = 0.7916355133056641, train/raw-loss = 0.7245964407920837, train/logprobs = tensor([[-2.2660, -2.1636],
        [-4.5911, -2.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2681565284729004
Epoch 0, Step 1351: train/loss = 0.13310031592845917, train/raw-loss = 0.06277130544185638, train/logprobs = tensor([[-1.3243, -4.9015],
        [-4.5695, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28131598234176636
Epoch 0, Step 1352: train/loss = 0.16610895097255707, train/raw-loss = 0.11189109086990356, train/logprobs = tensor([[-0.5675, -6.2008],
        [-2.1801, -1.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21687138080596924
Epoch 0, Step 1353: train/loss = 0.21064871549606323, train/raw-loss = 0.1433876007795334, train/logprobs = tensor([[-1.3632, -3.7233],
        [-3.6526, -1.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2690444588661194
Epoch 0, Step 1354: train/loss = 0.3228658437728882, train/raw-loss = 0.2838475704193115, train/logprobs = tensor([[-1.4211, -3.2923],
        [-3.7663, -0.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15607313811779022
Epoch 0, Step 1355: train/loss = 0.42674142122268677, train/raw-loss = 0.3738918602466583, train/logprobs = tensor([[-1.9234, -3.7473],
        [-3.5006, -1.8989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21139822900295258
Epoch 0, Step 1356: train/loss = 0.3243680000305176, train/raw-loss = 0.2735079824924469, train/logprobs = tensor([[-1.4100, -5.3475],
        [-2.5044, -1.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034400999546051
Epoch 0, Step 1357: train/loss = 0.5557061433792114, train/raw-loss = 0.4860212206840515, train/logprobs = tensor([[-0.8003, -2.6685],
        [-2.3625, -2.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27873969078063965
Epoch 0, Step 1358: train/loss = 0.17298072576522827, train/raw-loss = 0.11279325187206268, train/logprobs = tensor([[-1.2714, -5.7475],
        [-4.1881, -1.2178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24074995517730713
Epoch 0, Step 1359: train/loss = 0.2516871988773346, train/raw-loss = 0.19608965516090393, train/logprobs = tensor([[-0.9577, -3.4774],
        [-3.6360, -0.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.222390279173851
Epoch 0, Step 1360: train/loss = 0.9315991997718811, train/raw-loss = 0.8905746936798096, train/logprobs = tensor([[-3.4327, -5.9962],
        [-1.8205, -2.1540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16409806907176971
Epoch 0, Step 1361: train/loss = 0.37113454937934875, train/raw-loss = 0.31599074602127075, train/logprobs = tensor([[-0.9111, -3.4234],
        [-2.6119, -1.4460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22057518362998962
Epoch 0, Step 1362: train/loss = 0.6774036288261414, train/raw-loss = 0.619046688079834, train/logprobs = tensor([[-0.5252, -2.2028],
        [-2.5386, -1.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23342770338058472
Epoch 0, Step 1363: train/loss = 0.24828782677650452, train/raw-loss = 0.18677975237369537, train/logprobs = tensor([[-1.0424, -4.6010],
        [-3.4366, -1.4154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24603229761123657
Epoch 0, Step 1364: train/loss = 0.27967825531959534, train/raw-loss = 0.20723393559455872, train/logprobs = tensor([[-0.9190, -3.6430],
        [-3.4870, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2897772192955017
Epoch 0, Step 1365: train/loss = 0.4793545603752136, train/raw-loss = 0.4190636873245239, train/logprobs = tensor([[-1.0792, -2.6116],
        [-3.9258, -1.7215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24116340279579163
Epoch 0, Step 1366: train/loss = 0.4122532606124878, train/raw-loss = 0.35775429010391235, train/logprobs = tensor([[-2.4460, -4.5934],
        [-3.2431, -1.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2179957628250122
Epoch 0, Step 1367: train/loss = 0.35919255018234253, train/raw-loss = 0.2976784110069275, train/logprobs = tensor([[-0.7456, -4.5811],
        [-2.0980, -1.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24605649709701538
Epoch 0, Step 1368: train/loss = 0.21473897993564606, train/raw-loss = 0.1396521031856537, train/logprobs = tensor([[-0.8507, -4.9168],
        [-3.4023, -1.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003474771976471
Epoch 0, Step 1369: train/loss = 0.1658879518508911, train/raw-loss = 0.1010252833366394, train/logprobs = tensor([[-1.1890, -5.5913],
        [-3.4852, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25945064425468445
Epoch 0, Step 1370: train/loss = 0.12359870970249176, train/raw-loss = 0.06242850422859192, train/logprobs = tensor([[-1.2455, -5.4354],
        [-4.7914, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24468082189559937
Epoch 0, Step 1371: train/loss = 0.4651144742965698, train/raw-loss = 0.41105279326438904, train/logprobs = tensor([[-1.7989, -2.9727],
        [-3.6647, -0.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162468582391739
Epoch 0, Step 1372: train/loss = 0.2867472767829895, train/raw-loss = 0.22812645137310028, train/logprobs = tensor([[-1.2217, -3.7457],
        [-3.7492, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23448331654071808
Epoch 0, Step 1373: train/loss = 0.2007634937763214, train/raw-loss = 0.13271066546440125, train/logprobs = tensor([[-1.2369, -4.7198],
        [-3.8817, -1.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722112834453583
Epoch 0, Step 1374: train/loss = 0.13851459324359894, train/raw-loss = 0.06843458116054535, train/logprobs = tensor([[-1.1288, -6.7338],
        [-3.8624, -2.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28032004833221436
Epoch 0, Step 1375: train/loss = 0.3964177966117859, train/raw-loss = 0.32386288046836853, train/logprobs = tensor([[-0.8935, -3.7404],
        [-2.7083, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902197241783142
Epoch 0, Step 1376: train/loss = 0.43717896938323975, train/raw-loss = 0.38358503580093384, train/logprobs = tensor([[-0.5462, -3.1036],
        [-2.0780, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21437570452690125
Epoch 0, Step 1377: train/loss = 0.25561344623565674, train/raw-loss = 0.18840578198432922, train/logprobs = tensor([[-1.6753, -4.7975],
        [-4.4968, -1.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688305377960205
Epoch 0, Step 1378: train/loss = 0.12383929640054703, train/raw-loss = 0.04335065931081772, train/logprobs = tensor([[-1.3003, -5.6042],
        [-5.6095, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3219545781612396
Epoch 0, Step 1379: train/loss = 0.3488417863845825, train/raw-loss = 0.2748725116252899, train/logprobs = tensor([[-1.1784, -3.8660],
        [-3.6019, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2958771288394928
Epoch 0, Step 1380: train/loss = 0.4632463753223419, train/raw-loss = 0.3955089747905731, train/logprobs = tensor([[-0.9444, -3.2967],
        [-3.4410, -1.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27094966173171997
Epoch 0, Step 1381: train/loss = 0.13636350631713867, train/raw-loss = 0.0633905902504921, train/logprobs = tensor([[-1.3224, -5.4565],
        [-4.4869, -1.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2918916642665863
Epoch 0, Step 1382: train/loss = 0.23709753155708313, train/raw-loss = 0.169538214802742, train/logprobs = tensor([[-1.6824, -6.1361],
        [-4.5554, -1.7558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2702373266220093
Epoch 0, Step 1383: train/loss = 0.1859198957681656, train/raw-loss = 0.1244276612997055, train/logprobs = tensor([[-2.1420, -4.4598],
        [-4.6664, -2.1003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24596889317035675
Epoch 0, Step 1384: train/loss = 0.13611605763435364, train/raw-loss = 0.0903194397687912, train/logprobs = tensor([[-1.3265, -6.1138],
        [-3.6303, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18318645656108856
Epoch 0, Step 1385: train/loss = 0.2637900114059448, train/raw-loss = 0.189230814576149, train/logprobs = tensor([[-1.6292, -3.2048],
        [-4.7357, -1.3851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2982367277145386
Epoch 0, Step 1386: train/loss = 0.22604596614837646, train/raw-loss = 0.17993329465389252, train/logprobs = tensor([[-1.7200, -5.4290],
        [-3.8265, -2.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18445073068141937
Epoch 0, Step 1387: train/loss = 0.35054880380630493, train/raw-loss = 0.28857457637786865, train/logprobs = tensor([[-2.8415, -5.1881],
        [-4.2750, -2.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2478969395160675
Epoch 0, Step 1388: train/loss = 0.3137299418449402, train/raw-loss = 0.25635844469070435, train/logprobs = tensor([[-1.2290, -3.8601],
        [-2.5178, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2294859141111374
Epoch 0, Step 1389: train/loss = 0.23415826261043549, train/raw-loss = 0.1800689697265625, train/logprobs = tensor([[-0.8635, -5.9464],
        [-2.7706, -1.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21635721623897552
Epoch 0, Step 1390: train/loss = 0.39258670806884766, train/raw-loss = 0.34773024916648865, train/logprobs = tensor([[-0.8592, -3.3275],
        [-2.5321, -1.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17942585051059723
Epoch 0, Step 1391: train/loss = 0.1035270243883133, train/raw-loss = 0.03240843117237091, train/logprobs = tensor([[-0.9218, -5.8898],
        [-4.8699, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28447437286376953
Epoch 0, Step 1392: train/loss = 0.2580822706222534, train/raw-loss = 0.1987054944038391, train/logprobs = tensor([[-0.9765, -5.3433],
        [-3.0515, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23750713467597961
Epoch 0, Step 1393: train/loss = 0.18344762921333313, train/raw-loss = 0.12001468241214752, train/logprobs = tensor([[-0.9371, -5.2159],
        [-3.9157, -1.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25373172760009766
Epoch 0, Step 1394: train/loss = 0.12912707030773163, train/raw-loss = 0.06394466012716293, train/logprobs = tensor([[-0.8183, -6.2264],
        [-3.7281, -1.4140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2607296407222748
Epoch 0, Step 1395: train/loss = 0.31502828001976013, train/raw-loss = 0.25846540927886963, train/logprobs = tensor([[-0.7384, -4.4574],
        [-2.8633, -1.5264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22625143826007843
Epoch 0, Step 1396: train/loss = 0.6215946078300476, train/raw-loss = 0.5649773478507996, train/logprobs = tensor([[-1.3680, -3.4497],
        [-3.7150, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2264690101146698
Epoch 0, Step 1397: train/loss = 0.3303181827068329, train/raw-loss = 0.27625155448913574, train/logprobs = tensor([[-1.4967, -4.1540],
        [-3.1815, -1.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21626654267311096
Epoch 0, Step 1398: train/loss = 0.14280331134796143, train/raw-loss = 0.07604501396417618, train/logprobs = tensor([[-0.9517, -6.0853],
        [-3.3167, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267033189535141
Epoch 0, Step 1399: train/loss = 0.34783095121383667, train/raw-loss = 0.29469138383865356, train/logprobs = tensor([[-1.6195, -4.5481],
        [-2.8360, -1.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21255835890769958
Epoch 0, Step 1400: train/loss = 0.3940168023109436, train/raw-loss = 0.3448987603187561, train/logprobs = tensor([[-0.9630, -4.0941],
        [-2.2977, -1.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19647227227687836
Epoch 0, Step 1401: train/loss = 0.42006582021713257, train/raw-loss = 0.35680869221687317, train/logprobs = tensor([[-1.4506, -3.0922],
        [-3.4840, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530284821987152
Epoch 0, Step 1402: train/loss = 0.47317034006118774, train/raw-loss = 0.40195268392562866, train/logprobs = tensor([[-1.1251, -3.7852],
        [-3.5009, -1.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28487053513526917
Epoch 0, Step 1403: train/loss = 0.2895672023296356, train/raw-loss = 0.22723865509033203, train/logprobs = tensor([[-1.9948, -7.0999],
        [-3.8138, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24931418895721436
Epoch 0, Step 1404: train/loss = 0.19732899963855743, train/raw-loss = 0.14075760543346405, train/logprobs = tensor([[-0.9362, -5.4998],
        [-3.0855, -1.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22628560662269592
Epoch 0, Step 1405: train/loss = 0.392415314912796, train/raw-loss = 0.34698915481567383, train/logprobs = tensor([[-0.6487, -2.5888],
        [-2.1957, -0.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18170472979545593
Epoch 0, Step 1406: train/loss = 0.3290414810180664, train/raw-loss = 0.27340883016586304, train/logprobs = tensor([[-1.3794, -3.3997],
        [-3.0507, -0.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22253066301345825
Epoch 0, Step 1407: train/loss = 0.7598207592964172, train/raw-loss = 0.7062152624130249, train/logprobs = tensor([[-3.0534, -4.1350],
        [-4.1133, -2.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2144220620393753
Epoch 0, Step 1408: train/loss = 0.22881445288658142, train/raw-loss = 0.17529989778995514, train/logprobs = tensor([[-0.5749, -4.8394],
        [-2.0718, -1.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21405823528766632
Epoch 0, Step 1409: train/loss = 0.1630806028842926, train/raw-loss = 0.10314299911260605, train/logprobs = tensor([[-0.8504, -4.2813],
        [-3.7464, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2397504299879074
Epoch 0, Step 1410: train/loss = 0.40513280034065247, train/raw-loss = 0.3659825921058655, train/logprobs = tensor([[-0.8445, -3.6915],
        [-1.2338, -0.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15660078823566437
Epoch 0, Step 1411: train/loss = 0.35263800621032715, train/raw-loss = 0.3034837543964386, train/logprobs = tensor([[-2.2093, -3.8238],
        [-3.6859, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19661706686019897
Epoch 0, Step 1412: train/loss = 0.300898015499115, train/raw-loss = 0.2508552670478821, train/logprobs = tensor([[-1.2749, -4.0198],
        [-4.6169, -0.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20017093420028687
Epoch 0, Step 1413: train/loss = 0.09269028902053833, train/raw-loss = 0.03188431262969971, train/logprobs = tensor([[-1.1622, -6.2422],
        [-4.7038, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24322392046451569
Epoch 0, Step 1414: train/loss = 0.17243623733520508, train/raw-loss = 0.1211930513381958, train/logprobs = tensor([[-0.8722, -4.7382],
        [-2.9819, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2049727737903595
Epoch 0, Step 1415: train/loss = 0.2917776107788086, train/raw-loss = 0.23854894936084747, train/logprobs = tensor([[-1.3339, -4.9628],
        [-2.0373, -1.0914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21291466057300568
Epoch 0, Step 1416: train/loss = 0.44792482256889343, train/raw-loss = 0.4102313220500946, train/logprobs = tensor([[-0.7428, -4.4054],
        [-1.6200, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15077409148216248
Epoch 0, Step 1417: train/loss = 0.16722846031188965, train/raw-loss = 0.1028381809592247, train/logprobs = tensor([[-1.5612, -7.1192],
        [-4.6057, -1.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.257561057806015
Epoch 0, Step 1418: train/loss = 0.6913556456565857, train/raw-loss = 0.638530969619751, train/logprobs = tensor([[-2.8839, -4.6976],
        [-3.7404, -2.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2112991213798523
Epoch 0, Step 1419: train/loss = 0.2294374406337738, train/raw-loss = 0.16758236289024353, train/logprobs = tensor([[-1.9404, -4.1129],
        [-3.7950, -1.3175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24742025136947632
Epoch 0, Step 1420: train/loss = 0.6683700680732727, train/raw-loss = 0.6116929650306702, train/logprobs = tensor([[-1.0974, -2.4220],
        [-1.5500, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22670848667621613
Epoch 0, Step 1421: train/loss = 0.41687527298927307, train/raw-loss = 0.36520111560821533, train/logprobs = tensor([[-1.6718, -2.9095],
        [-2.6039, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066965401172638
Epoch 0, Step 1422: train/loss = 0.6628304719924927, train/raw-loss = 0.5905102491378784, train/logprobs = tensor([[-1.4294, -3.0115],
        [-2.5476, -2.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892807126045227
Epoch 0, Step 1423: train/loss = 0.44659101963043213, train/raw-loss = 0.39804112911224365, train/logprobs = tensor([[-0.8873, -1.3981],
        [-3.2390, -0.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1941995620727539
Epoch 0, Step 1424: train/loss = 0.43724215030670166, train/raw-loss = 0.37944337725639343, train/logprobs = tensor([[-1.4134, -2.8856],
        [-4.1332, -2.3341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23119506239891052
Epoch 0, Step 1425: train/loss = 0.3297708034515381, train/raw-loss = 0.28137338161468506, train/logprobs = tensor([[-1.0652, -2.9419],
        [-2.9716, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19358977675437927
Epoch 0, Step 1426: train/loss = 0.18023565411567688, train/raw-loss = 0.11735457926988602, train/logprobs = tensor([[-1.3948, -6.2647],
        [-3.5495, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25152429938316345
Epoch 0, Step 1427: train/loss = 0.16621281206607819, train/raw-loss = 0.10855516046285629, train/logprobs = tensor([[-0.8990, -6.1754],
        [-2.8500, -1.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23063065111637115
Epoch 0, Step 1428: train/loss = 0.37800711393356323, train/raw-loss = 0.3238358497619629, train/logprobs = tensor([[-1.5676, -6.7047],
        [-3.2878, -2.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21668493747711182
Epoch 0, Step 1429: train/loss = 0.3892419636249542, train/raw-loss = 0.3374541103839874, train/logprobs = tensor([[-1.6748, -3.1263],
        [-3.4310, -1.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2071513533592224
Epoch 0, Step 1430: train/loss = 0.16772232949733734, train/raw-loss = 0.10145069658756256, train/logprobs = tensor([[-0.9995, -4.5972],
        [-3.5937, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2650865614414215
Epoch 0, Step 1431: train/loss = 0.3199388384819031, train/raw-loss = 0.2599737346172333, train/logprobs = tensor([[-1.7313, -4.5937],
        [-3.9329, -1.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23986056447029114
Epoch 0, Step 1432: train/loss = 0.4362320601940155, train/raw-loss = 0.3921356797218323, train/logprobs = tensor([[-1.6679, -5.3986],
        [-1.8186, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17638540267944336
Epoch 0, Step 1433: train/loss = 0.5425348877906799, train/raw-loss = 0.495291531085968, train/logprobs = tensor([[-1.2970, -2.5248],
        [-1.9430, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18897324800491333
Epoch 0, Step 1434: train/loss = 0.519071638584137, train/raw-loss = 0.46884697675704956, train/logprobs = tensor([[-2.3176, -4.5614],
        [-3.3768, -2.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2008986473083496
Epoch 0, Step 1435: train/loss = 0.3340480625629425, train/raw-loss = 0.2746030390262604, train/logprobs = tensor([[-1.5387, -4.0451],
        [-4.4726, -1.4851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23778009414672852
Epoch 0, Step 1436: train/loss = 0.6786982417106628, train/raw-loss = 0.6285443902015686, train/logprobs = tensor([[-1.3708, -1.6770],
        [-1.5190, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2006153166294098
Epoch 0, Step 1437: train/loss = 0.5754657983779907, train/raw-loss = 0.521265983581543, train/logprobs = tensor([[-2.7230, -2.9778],
        [-4.2496, -2.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21679940819740295
Epoch 0, Step 1438: train/loss = 0.9296131730079651, train/raw-loss = 0.8702038526535034, train/logprobs = tensor([[-3.1254, -2.1112],
        [-3.5649, -2.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23763707280158997
Epoch 0, Step 1439: train/loss = 0.19686537981033325, train/raw-loss = 0.1417100727558136, train/logprobs = tensor([[-0.6561, -6.4362],
        [-1.7640, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.220621258020401
Epoch 0, Step 1440: train/loss = 0.2684573531150818, train/raw-loss = 0.20725983381271362, train/logprobs = tensor([[-1.1727, -7.0596],
        [-3.7458, -2.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24479013681411743
Epoch 0, Step 1441: train/loss = 0.4009060561656952, train/raw-loss = 0.3299379348754883, train/logprobs = tensor([[-1.0341, -2.4087],
        [-3.3020, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28387242555618286
Epoch 0, Step 1442: train/loss = 0.3097732961177826, train/raw-loss = 0.2613915503025055, train/logprobs = tensor([[-1.0415, -6.2014],
        [-2.8314, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19352692365646362
Epoch 0, Step 1443: train/loss = 0.24063651263713837, train/raw-loss = 0.18534566462039948, train/logprobs = tensor([[-1.2683, -2.9951],
        [-4.9837, -0.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22116342186927795
Epoch 0, Step 1444: train/loss = 0.26336541771888733, train/raw-loss = 0.20913411676883698, train/logprobs = tensor([[-1.1787, -6.5436],
        [-3.6244, -1.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2169252634048462
Epoch 0, Step 1445: train/loss = 0.3038557767868042, train/raw-loss = 0.25357428193092346, train/logprobs = tensor([[-0.6415, -4.9091],
        [-1.6740, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20112594962120056
Epoch 0, Step 1446: train/loss = 0.32631608843803406, train/raw-loss = 0.2816200852394104, train/logprobs = tensor([[-1.0484, -3.7016],
        [-3.2029, -1.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17878404259681702
Epoch 0, Step 1447: train/loss = 0.3694644868373871, train/raw-loss = 0.31083953380584717, train/logprobs = tensor([[-0.7095, -4.1132],
        [-2.7951, -1.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23449978232383728
Epoch 0, Step 1448: train/loss = 0.38033443689346313, train/raw-loss = 0.3144351840019226, train/logprobs = tensor([[-1.0543, -3.2552],
        [-3.9810, -1.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2635970711708069
Epoch 0, Step 1449: train/loss = 0.16406741738319397, train/raw-loss = 0.0990050882101059, train/logprobs = tensor([[-0.9776, -5.1179],
        [-3.1611, -1.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602493166923523
Epoch 0, Step 1450: train/loss = 0.18256616592407227, train/raw-loss = 0.12443562597036362, train/logprobs = tensor([[-1.6487, -3.4614],
        [-4.4628, -1.2986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23252218961715698
Epoch 0, Step 1451: train/loss = 0.5402706861495972, train/raw-loss = 0.4830508232116699, train/logprobs = tensor([[-0.9822, -2.0191],
        [-2.0878, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22887930274009705
Epoch 0, Step 1452: train/loss = 0.1961393505334854, train/raw-loss = 0.12921525537967682, train/logprobs = tensor([[-1.9675, -5.2645],
        [-4.1333, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676963806152344
Epoch 0, Step 1453: train/loss = 0.2743350565433502, train/raw-loss = 0.2207304835319519, train/logprobs = tensor([[-0.8574, -4.0004],
        [-2.6739, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21441835165023804
Epoch 0, Step 1454: train/loss = 0.36946961283683777, train/raw-loss = 0.3053087294101715, train/logprobs = tensor([[-1.1848, -4.3336],
        [-2.9735, -2.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566435933113098
Epoch 0, Step 1455: train/loss = 0.21353666484355927, train/raw-loss = 0.15815256536006927, train/logprobs = tensor([[-1.0040, -4.6153],
        [-3.3804, -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22153645753860474
Epoch 0, Step 1456: train/loss = 0.2775079607963562, train/raw-loss = 0.21799691021442413, train/logprobs = tensor([[-1.2938, -5.1837],
        [-3.4566, -1.2972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380441129207611
Epoch 0, Step 1457: train/loss = 0.4639848470687866, train/raw-loss = 0.39869213104248047, train/logprobs = tensor([[-1.9959, -4.6964],
        [-3.4790, -2.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2611708641052246
Epoch 0, Step 1458: train/loss = 0.22707046568393707, train/raw-loss = 0.1685318946838379, train/logprobs = tensor([[-1.7688, -3.6891],
        [-3.0654, -0.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2341543436050415
Epoch 0, Step 1459: train/loss = 0.5005382895469666, train/raw-loss = 0.4392889738082886, train/logprobs = tensor([[-1.2238, -3.9820],
        [-2.5355, -3.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24499718844890594
Epoch 0, Step 1460: train/loss = 0.39100512862205505, train/raw-loss = 0.3312187194824219, train/logprobs = tensor([[-0.9961, -2.8911],
        [-3.2060, -2.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23914557695388794
Epoch 0, Step 1461: train/loss = 0.5525715351104736, train/raw-loss = 0.49058791995048523, train/logprobs = tensor([[-2.3921, -3.1483],
        [-2.5489, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24793434143066406
Epoch 0, Step 1462: train/loss = 0.40158236026763916, train/raw-loss = 0.3511950671672821, train/logprobs = tensor([[-1.2903, -3.5002],
        [-3.1678, -2.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20154917240142822
Epoch 0, Step 1463: train/loss = 0.256879597902298, train/raw-loss = 0.19831885397434235, train/logprobs = tensor([[-1.3931, -4.9103],
        [-3.3091, -1.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2342429906129837
Epoch 0, Step 1464: train/loss = 0.260951429605484, train/raw-loss = 0.19984953105449677, train/logprobs = tensor([[-0.9549, -5.0757],
        [-4.1332, -1.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24440762400627136
Epoch 0, Step 1465: train/loss = 0.4602189064025879, train/raw-loss = 0.4099019765853882, train/logprobs = tensor([[-0.9580, -2.3272],
        [-1.6982, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20126765966415405
Epoch 0, Step 1466: train/loss = 0.259132981300354, train/raw-loss = 0.19968357682228088, train/logprobs = tensor([[-1.8221, -4.7239],
        [-4.7072, -0.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23779761791229248
Epoch 0, Step 1467: train/loss = 0.3551494777202606, train/raw-loss = 0.28621166944503784, train/logprobs = tensor([[-1.2669, -2.6941],
        [-4.1357, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2757512629032135
Epoch 0, Step 1468: train/loss = 0.38588809967041016, train/raw-loss = 0.31320899724960327, train/logprobs = tensor([[-1.1739, -4.1558],
        [-3.1555, -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29071637988090515
Epoch 0, Step 1469: train/loss = 0.11696677654981613, train/raw-loss = 0.06201866269111633, train/logprobs = tensor([[-1.2621, -6.6773],
        [-4.0215, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2197924703359604
Epoch 0, Step 1470: train/loss = 0.238024041056633, train/raw-loss = 0.17988017201423645, train/logprobs = tensor([[-1.5700, -6.0264],
        [-3.0208, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23257550597190857
Epoch 0, Step 1471: train/loss = 0.13138143718242645, train/raw-loss = 0.0703323557972908, train/logprobs = tensor([[-0.8999, -6.2282],
        [-4.6465, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2441963255405426
Epoch 0, Step 1472: train/loss = 0.3122544288635254, train/raw-loss = 0.26384833455085754, train/logprobs = tensor([[-0.9860, -3.9217],
        [-2.7003, -0.5449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19362439215183258
Epoch 0, Step 1473: train/loss = 0.34653139114379883, train/raw-loss = 0.2908294200897217, train/logprobs = tensor([[-0.5445, -4.1544],
        [-1.9883, -1.6979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22280797362327576
Epoch 0, Step 1474: train/loss = 0.4158576428890228, train/raw-loss = 0.36407992243766785, train/logprobs = tensor([[-1.5001, -4.7482],
        [-3.2453, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20711097121238708
Epoch 0, Step 1475: train/loss = 0.18205808103084564, train/raw-loss = 0.1380366086959839, train/logprobs = tensor([[-1.1361, -3.7914],
        [-3.7968, -0.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17608585953712463
Epoch 0, Step 1476: train/loss = 0.3431875705718994, train/raw-loss = 0.2952665388584137, train/logprobs = tensor([[-0.9806, -4.2367],
        [-1.8243, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1916840374469757
Epoch 0, Step 1477: train/loss = 0.14485162496566772, train/raw-loss = 0.08352267742156982, train/logprobs = tensor([[-0.9347, -4.7215],
        [-4.3749, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24531584978103638
Epoch 0, Step 1478: train/loss = 0.5418745279312134, train/raw-loss = 0.48797881603240967, train/logprobs = tensor([[-1.4782, -3.5350],
        [-3.0910, -1.3864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2155827283859253
Epoch 0, Step 1479: train/loss = 0.14241349697113037, train/raw-loss = 0.07753826677799225, train/logprobs = tensor([[-1.5417, -6.0974],
        [-5.1922, -0.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2595008909702301
Epoch 0, Step 1480: train/loss = 0.2701296806335449, train/raw-loss = 0.21644800901412964, train/logprobs = tensor([[-1.4254, -3.7659],
        [-3.7394, -2.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21472668647766113
Epoch 0, Step 1481: train/loss = 0.2890744209289551, train/raw-loss = 0.24069789052009583, train/logprobs = tensor([[-0.7036, -5.2412],
        [-1.9560, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19350610673427582
Epoch 0, Step 1482: train/loss = 0.1940104067325592, train/raw-loss = 0.12433335930109024, train/logprobs = tensor([[-1.1712, -6.7853],
        [-3.4357, -1.6669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27870815992355347
Epoch 0, Step 1483: train/loss = 0.11065629124641418, train/raw-loss = 0.03929106146097183, train/logprobs = tensor([[-1.0630, -5.9285],
        [-4.9253, -1.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2854609489440918
Epoch 0, Step 1484: train/loss = 0.09340297430753708, train/raw-loss = 0.03139986842870712, train/logprobs = tensor([[-2.5927, -5.1874],
        [-6.4850, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24801239371299744
Epoch 0, Step 1485: train/loss = 0.5201876163482666, train/raw-loss = 0.458595871925354, train/logprobs = tensor([[-1.0115, -4.3923],
        [-3.8766, -2.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24636706709861755
Epoch 0, Step 1486: train/loss = 0.12913194298744202, train/raw-loss = 0.06067736819386482, train/logprobs = tensor([[-0.9594, -5.1500],
        [-4.3020, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738182842731476
Epoch 0, Step 1487: train/loss = 0.14153939485549927, train/raw-loss = 0.07253960520029068, train/logprobs = tensor([[-0.9324, -6.7796],
        [-3.8568, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27599912881851196
Epoch 0, Step 1488: train/loss = 0.4669223129749298, train/raw-loss = 0.3882957398891449, train/logprobs = tensor([[-1.3205, -2.0448],
        [-4.4896, -1.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3145064115524292
Epoch 0, Step 1489: train/loss = 0.33318212628364563, train/raw-loss = 0.2751469314098358, train/logprobs = tensor([[-1.2359, -5.1366],
        [-4.9377, -2.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23214074969291687
Epoch 0, Step 1490: train/loss = 0.39149001240730286, train/raw-loss = 0.3377082645893097, train/logprobs = tensor([[-1.0494, -4.0524],
        [-3.2213, -1.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151268720626831
Epoch 0, Step 1491: train/loss = 0.37435001134872437, train/raw-loss = 0.32602009177207947, train/logprobs = tensor([[-1.3038, -3.2871],
        [-3.2823, -0.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19331970810890198
Epoch 0, Step 1492: train/loss = 0.6389429569244385, train/raw-loss = 0.5926119685173035, train/logprobs = tensor([[-1.6215, -3.4507],
        [-2.4147, -1.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1853238195180893
Epoch 0, Step 1493: train/loss = 0.4051573574542999, train/raw-loss = 0.3549615442752838, train/logprobs = tensor([[-1.4204, -6.2737],
        [-3.0843, -2.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2007831633090973
Epoch 0, Step 1494: train/loss = 0.3629358410835266, train/raw-loss = 0.3059436082839966, train/logprobs = tensor([[-1.1672, -2.5434],
        [-3.0352, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2279689908027649
Epoch 0, Step 1495: train/loss = 0.5725632309913635, train/raw-loss = 0.5121384859085083, train/logprobs = tensor([[-1.9123, -3.4679],
        [-5.3178, -3.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24169906973838806
Epoch 0, Step 1496: train/loss = 0.4786856472492218, train/raw-loss = 0.4077029824256897, train/logprobs = tensor([[-1.0468, -2.6673],
        [-3.3678, -1.5580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28393059968948364
Epoch 0, Step 1497: train/loss = 0.36932557821273804, train/raw-loss = 0.2939929962158203, train/logprobs = tensor([[-1.4857, -5.6683],
        [-5.1503, -2.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013303875923157
Epoch 0, Step 1498: train/loss = 0.8400984406471252, train/raw-loss = 0.7806879878044128, train/logprobs = tensor([[-1.8651, -1.9687],
        [-3.2558, -2.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23764166235923767
Epoch 0, Step 1499: train/loss = 0.49231982231140137, train/raw-loss = 0.44134169816970825, train/logprobs = tensor([[-2.8320, -6.0478],
        [-5.8012, -1.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20391254127025604
eval/loss: nan
Epoch 0, Step 1500: train/loss = 0.5180915594100952, train/raw-loss = 0.4637792706489563, train/logprobs = tensor([[-1.9511, -3.5153],
        [-2.7841, -1.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21724900603294373
Epoch 0, Step 1501: train/loss = 0.3702993094921112, train/raw-loss = 0.30244094133377075, train/logprobs = tensor([[-2.2143, -4.5446],
        [-6.2266, -2.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2714335322380066
Epoch 0, Step 1502: train/loss = 0.46359872817993164, train/raw-loss = 0.390247642993927, train/logprobs = tensor([[-0.7683, -4.9076],
        [-2.8728, -1.6727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29340437054634094
Epoch 0, Step 1503: train/loss = 0.3069950342178345, train/raw-loss = 0.23700401186943054, train/logprobs = tensor([[-0.8816, -3.4349],
        [-4.2502, -1.4252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2799640893936157
Epoch 0, Step 1504: train/loss = 0.30368587374687195, train/raw-loss = 0.25835949182510376, train/logprobs = tensor([[-1.3242, -2.5628],
        [-5.3484, -1.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18130548298358917
Epoch 0, Step 1505: train/loss = 0.37980908155441284, train/raw-loss = 0.3352353274822235, train/logprobs = tensor([[-1.6948, -2.2864],
        [-3.1119, -0.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17829512059688568
Epoch 0, Step 1506: train/loss = 0.25112882256507874, train/raw-loss = 0.1992800384759903, train/logprobs = tensor([[-0.7900, -5.2889],
        [-3.1518, -1.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20739507675170898
Epoch 0, Step 1507: train/loss = 0.2157977968454361, train/raw-loss = 0.13989971578121185, train/logprobs = tensor([[-1.1491, -4.6461],
        [-5.2428, -1.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303592324256897
Epoch 0, Step 1508: train/loss = 0.13934916257858276, train/raw-loss = 0.0814458504319191, train/logprobs = tensor([[-1.0468, -8.9085],
        [-3.3985, -2.3370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23161324858665466
Epoch 0, Step 1509: train/loss = 0.43246111273765564, train/raw-loss = 0.3787917494773865, train/logprobs = tensor([[-1.4426, -1.9295],
        [-4.7442, -1.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21467742323875427
Epoch 0, Step 1510: train/loss = 0.12726452946662903, train/raw-loss = 0.06991524249315262, train/logprobs = tensor([[-1.0129, -7.7352],
        [-3.4710, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22939717769622803
Epoch 0, Step 1511: train/loss = 0.3930332362651825, train/raw-loss = 0.34614962339401245, train/logprobs = tensor([[-0.9529, -3.0594],
        [-2.2092, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187534362077713
Epoch 0, Step 1512: train/loss = 0.25904715061187744, train/raw-loss = 0.18782098591327667, train/logprobs = tensor([[-0.9375, -4.5988],
        [-3.3903, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849046587944031
Epoch 0, Step 1513: train/loss = 0.3911930322647095, train/raw-loss = 0.3419206440448761, train/logprobs = tensor([[-0.8443, -4.1158],
        [-1.9018, -1.7917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19708961248397827
Epoch 0, Step 1514: train/loss = 0.22928211092948914, train/raw-loss = 0.19434204697608948, train/logprobs = tensor([[-0.8940, -4.6971],
        [-3.5931, -0.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13976027071475983
Epoch 0, Step 1515: train/loss = 0.2470703423023224, train/raw-loss = 0.1922999769449234, train/logprobs = tensor([[-1.2309, -5.2487],
        [-2.3317, -1.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21908150613307953
Epoch 0, Step 1516: train/loss = 0.4003753960132599, train/raw-loss = 0.33365485072135925, train/logprobs = tensor([[-1.7559, -5.5335],
        [-4.4460, -2.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26688212156295776
Epoch 0, Step 1517: train/loss = 0.37179073691368103, train/raw-loss = 0.31588298082351685, train/logprobs = tensor([[-1.1693, -4.0080],
        [-2.3906, -1.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22363099455833435
Epoch 0, Step 1518: train/loss = 0.46388745307922363, train/raw-loss = 0.38772153854370117, train/logprobs = tensor([[-1.1828, -5.0495],
        [-4.7146, -2.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3046637177467346
Epoch 0, Step 1519: train/loss = 0.3867535889148712, train/raw-loss = 0.3401429057121277, train/logprobs = tensor([[-0.7752, -3.0082],
        [-2.3407, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18644271790981293
Epoch 0, Step 1520: train/loss = 0.2151777297258377, train/raw-loss = 0.16242527961730957, train/logprobs = tensor([[-1.1975, -3.8837],
        [-3.9635, -0.6115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21100980043411255
Epoch 0, Step 1521: train/loss = 0.16900785267353058, train/raw-loss = 0.10088865458965302, train/logprobs = tensor([[-1.8480, -5.4098],
        [-4.6623, -1.8011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27247676253318787
Epoch 0, Step 1522: train/loss = 0.2934783101081848, train/raw-loss = 0.22794771194458008, train/logprobs = tensor([[-1.1492, -4.5726],
        [-4.0913, -1.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26212233304977417
Epoch 0, Step 1523: train/loss = 0.26715487241744995, train/raw-loss = 0.20166240632534027, train/logprobs = tensor([[-1.9280, -4.7492],
        [-4.0980, -0.6325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2619699537754059
Epoch 0, Step 1524: train/loss = 0.17908556759357452, train/raw-loss = 0.1295938342809677, train/logprobs = tensor([[-0.8900, -6.2540],
        [-2.6164, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19796690344810486
Epoch 0, Step 1525: train/loss = 0.6614384651184082, train/raw-loss = 0.614469051361084, train/logprobs = tensor([[-0.8486, -4.7950],
        [-2.7348, -3.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18787768483161926
Epoch 0, Step 1526: train/loss = 0.09164388477802277, train/raw-loss = 0.02696792408823967, train/logprobs = tensor([[-1.0844, -5.1751],
        [-5.7860, -1.4893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25870388746261597
Epoch 0, Step 1527: train/loss = 0.2955701947212219, train/raw-loss = 0.23027710616588593, train/logprobs = tensor([[-1.3110, -4.2980],
        [-3.9075, -0.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26117226481437683
Epoch 0, Step 1528: train/loss = 0.3979044556617737, train/raw-loss = 0.3418600857257843, train/logprobs = tensor([[-0.9745, -4.6412],
        [-3.1566, -1.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22417756915092468
Epoch 0, Step 1529: train/loss = 1.030692219734192, train/raw-loss = 0.9777085781097412, train/logprobs = tensor([[-1.5080, -3.0219],
        [-2.6173, -3.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2119349241256714
Epoch 0, Step 1530: train/loss = 0.1652737557888031, train/raw-loss = 0.11797013133764267, train/logprobs = tensor([[-2.3878, -4.9484],
        [-5.1023, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18921449780464172
Epoch 0, Step 1531: train/loss = 0.44007593393325806, train/raw-loss = 0.37689727544784546, train/logprobs = tensor([[-0.6625, -2.7574],
        [-3.1228, -1.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527146339416504
Epoch 0, Step 1532: train/loss = 0.42688044905662537, train/raw-loss = 0.36342471837997437, train/logprobs = tensor([[-1.1101, -3.1166],
        [-2.3467, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538227438926697
Epoch 0, Step 1533: train/loss = 0.3661841154098511, train/raw-loss = 0.3159887194633484, train/logprobs = tensor([[-1.2281, -3.4354],
        [-2.9715, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20078156888484955
Epoch 0, Step 1534: train/loss = 0.21869616210460663, train/raw-loss = 0.16540005803108215, train/logprobs = tensor([[-1.2968, -4.6622],
        [-3.3513, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2131843864917755
Epoch 0, Step 1535: train/loss = 0.3874960243701935, train/raw-loss = 0.3310735523700714, train/logprobs = tensor([[-0.7124, -3.2298],
        [-3.1468, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22568975389003754
Epoch 0, Step 1536: train/loss = 0.37834563851356506, train/raw-loss = 0.3381032645702362, train/logprobs = tensor([[-0.9143, -1.7225],
        [-2.8063, -0.8484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1609695553779602
Epoch 0, Step 1537: train/loss = 0.2100694179534912, train/raw-loss = 0.1429123729467392, train/logprobs = tensor([[-1.2711, -6.5019],
        [-4.6229, -1.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26862820982933044
Epoch 0, Step 1538: train/loss = 0.2945365011692047, train/raw-loss = 0.22732901573181152, train/logprobs = tensor([[-0.7756, -4.3177],
        [-2.9134, -1.0956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688298225402832
Epoch 0, Step 1539: train/loss = 0.15791335701942444, train/raw-loss = 0.10000551491975784, train/logprobs = tensor([[-0.9980, -5.8985],
        [-2.8712, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.231631338596344
Epoch 0, Step 1540: train/loss = 0.16529199481010437, train/raw-loss = 0.1020454689860344, train/logprobs = tensor([[-0.9921, -7.1316],
        [-3.2924, -1.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529861032962799
Epoch 0, Step 1541: train/loss = 0.2454545497894287, train/raw-loss = 0.18089143931865692, train/logprobs = tensor([[-1.8736, -6.8291],
        [-3.4223, -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25825241208076477
Epoch 0, Step 1542: train/loss = 0.42748576402664185, train/raw-loss = 0.3569297790527344, train/logprobs = tensor([[-1.2989, -4.1715],
        [-3.1450, -1.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28222382068634033
Epoch 0, Step 1543: train/loss = 0.7832280397415161, train/raw-loss = 0.7170220017433167, train/logprobs = tensor([[-1.6794, -1.7750],
        [-3.7345, -2.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2648242115974426
Epoch 0, Step 1544: train/loss = 0.11963120847940445, train/raw-loss = 0.059106431901454926, train/logprobs = tensor([[-1.5182, -6.9278],
        [-4.3001, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24209913611412048
Epoch 0, Step 1545: train/loss = 0.3238757252693176, train/raw-loss = 0.2739783823490143, train/logprobs = tensor([[-1.0720, -4.9975],
        [-2.1582, -0.7383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19958940148353577
Epoch 0, Step 1546: train/loss = 0.30196505784988403, train/raw-loss = 0.24753427505493164, train/logprobs = tensor([[-0.9768, -4.7164],
        [-2.2752, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21772311627864838
Epoch 0, Step 1547: train/loss = 0.42288297414779663, train/raw-loss = 0.3774459958076477, train/logprobs = tensor([[-0.7198, -3.7116],
        [-1.4633, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18174788355827332
Epoch 0, Step 1548: train/loss = 0.24754467606544495, train/raw-loss = 0.19062396883964539, train/logprobs = tensor([[-2.1387, -5.3627],
        [-3.9405, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22768288850784302
Epoch 0, Step 1549: train/loss = 0.17563176155090332, train/raw-loss = 0.11746528744697571, train/logprobs = tensor([[-1.0361, -6.0303],
        [-3.3417, -1.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23266595602035522
Epoch 0, Step 1550: train/loss = 0.38712164759635925, train/raw-loss = 0.3309156000614166, train/logprobs = tensor([[-1.3086, -4.5708],
        [-3.5084, -1.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22482429444789886
Epoch 0, Step 1551: train/loss = 0.6996487379074097, train/raw-loss = 0.6346743702888489, train/logprobs = tensor([[-1.2092, -2.3336],
        [-3.0948, -2.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.259897381067276
Epoch 0, Step 1552: train/loss = 0.33525368571281433, train/raw-loss = 0.29053014516830444, train/logprobs = tensor([[-1.3600, -6.0777],
        [-2.2686, -1.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788943111896515
Epoch 0, Step 1553: train/loss = 0.3091878294944763, train/raw-loss = 0.2635335624217987, train/logprobs = tensor([[-0.9223, -7.0595],
        [-2.7887, -1.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18261687457561493
Epoch 0, Step 1554: train/loss = 0.47611939907073975, train/raw-loss = 0.41617551445961, train/logprobs = tensor([[-0.8820, -3.6707],
        [-3.6557, -2.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2397753745317459
Epoch 0, Step 1555: train/loss = 0.35686683654785156, train/raw-loss = 0.28987422585487366, train/logprobs = tensor([[-0.9943, -4.8421],
        [-3.4514, -2.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267970472574234
Epoch 0, Step 1556: train/loss = 0.3820030987262726, train/raw-loss = 0.3269731402397156, train/logprobs = tensor([[-0.7216, -3.6281],
        [-3.1463, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22011983394622803
Epoch 0, Step 1557: train/loss = 0.15417130291461945, train/raw-loss = 0.10335837304592133, train/logprobs = tensor([[-0.9308, -6.8135],
        [-3.2703, -2.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2032516896724701
Epoch 0, Step 1558: train/loss = 0.17624345421791077, train/raw-loss = 0.11941179633140564, train/logprobs = tensor([[-0.9314, -4.7532],
        [-3.7178, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22732660174369812
Epoch 0, Step 1559: train/loss = 0.5080097317695618, train/raw-loss = 0.44264957308769226, train/logprobs = tensor([[-1.0202, -2.9995],
        [-2.8565, -1.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2614405155181885
Epoch 0, Step 1560: train/loss = 0.3878874182701111, train/raw-loss = 0.32707393169403076, train/logprobs = tensor([[-1.3567, -3.7075],
        [-2.8603, -1.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24325397610664368
Epoch 0, Step 1561: train/loss = 0.1313609778881073, train/raw-loss = 0.07187661528587341, train/logprobs = tensor([[-0.8405, -4.9148],
        [-4.0555, -0.7676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23793742060661316
Epoch 0, Step 1562: train/loss = 0.1459648609161377, train/raw-loss = 0.08300253748893738, train/logprobs = tensor([[-1.3292, -6.0496],
        [-3.4953, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25184929370880127
Epoch 0, Step 1563: train/loss = 0.3586505353450775, train/raw-loss = 0.31970858573913574, train/logprobs = tensor([[-0.7098, -3.6909],
        [-2.1029, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1557677537202835
Epoch 0, Step 1564: train/loss = 0.16516366600990295, train/raw-loss = 0.09420645982027054, train/logprobs = tensor([[-1.1402, -6.5107],
        [-4.6105, -2.2840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28382885456085205
Epoch 0, Step 1565: train/loss = 0.25589364767074585, train/raw-loss = 0.20994168519973755, train/logprobs = tensor([[-2.2270, -3.6555],
        [-3.7087, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183807834982872
Epoch 0, Step 1566: train/loss = 0.4558262526988983, train/raw-loss = 0.40469807386398315, train/logprobs = tensor([[-0.8869, -3.6655],
        [-1.6551, -1.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20451247692108154
Epoch 0, Step 1567: train/loss = 0.13477298617362976, train/raw-loss = 0.07952231168746948, train/logprobs = tensor([[-1.1915, -5.3246],
        [-3.9353, -1.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2210027575492859
Epoch 0, Step 1568: train/loss = 0.5502656102180481, train/raw-loss = 0.4988943636417389, train/logprobs = tensor([[-0.8670, -4.0458],
        [-2.6644, -1.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20548516511917114
Epoch 0, Step 1569: train/loss = 0.32519710063934326, train/raw-loss = 0.2727547585964203, train/logprobs = tensor([[-1.1449, -4.4597],
        [-3.4991, -1.8181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2097693681716919
Epoch 0, Step 1570: train/loss = 0.22709572315216064, train/raw-loss = 0.16757068037986755, train/logprobs = tensor([[-0.7870, -4.4458],
        [-3.7926, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23810012638568878
Epoch 0, Step 1571: train/loss = 0.09944553673267365, train/raw-loss = 0.03890856355428696, train/logprobs = tensor([[-1.3041, -7.3083],
        [-5.5286, -1.3574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24214789271354675
Epoch 0, Step 1572: train/loss = 0.2684614658355713, train/raw-loss = 0.2150059938430786, train/logprobs = tensor([[-0.9132, -6.1138],
        [-2.3451, -1.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21382194757461548
Epoch 0, Step 1573: train/loss = 0.16498428583145142, train/raw-loss = 0.10711635649204254, train/logprobs = tensor([[-1.9175, -5.0995],
        [-5.7365, -2.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23147165775299072
Epoch 0, Step 1574: train/loss = 0.12496593594551086, train/raw-loss = 0.06266505271196365, train/logprobs = tensor([[-1.3814, -6.3685],
        [-5.2065, -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24920356273651123
Epoch 0, Step 1575: train/loss = 0.3690589666366577, train/raw-loss = 0.2931634187698364, train/logprobs = tensor([[-2.7631, -4.2617],
        [-4.7718, -1.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3035823106765747
Epoch 0, Step 1576: train/loss = 0.1586609184741974, train/raw-loss = 0.09894733875989914, train/logprobs = tensor([[-1.2047, -5.6711],
        [-4.9000, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23885436356067657
Epoch 0, Step 1577: train/loss = 0.3162044286727905, train/raw-loss = 0.25534218549728394, train/logprobs = tensor([[-1.1401, -4.4047],
        [-3.2764, -1.5921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2434489130973816
Epoch 0, Step 1578: train/loss = 0.14925611019134521, train/raw-loss = 0.08008138835430145, train/logprobs = tensor([[-1.1950, -5.0468],
        [-5.0626, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27669885754585266
Epoch 0, Step 1579: train/loss = 0.1229032576084137, train/raw-loss = 0.05650602653622627, train/logprobs = tensor([[-1.4890, -5.5109],
        [-5.0911, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2655889093875885
Epoch 0, Step 1580: train/loss = 0.43940815329551697, train/raw-loss = 0.37701207399368286, train/logprobs = tensor([[-1.4117, -1.7255],
        [-4.3161, -1.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24958419799804688
Epoch 0, Step 1581: train/loss = 0.5265122056007385, train/raw-loss = 0.47396087646484375, train/logprobs = tensor([[-0.5486, -4.1514],
        [-2.1590, -1.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21020516753196716
Epoch 0, Step 1582: train/loss = 0.10928808897733688, train/raw-loss = 0.03844550997018814, train/logprobs = tensor([[-0.9783, -7.5610],
        [-4.4236, -1.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833702862262726
Epoch 0, Step 1583: train/loss = 0.3099886476993561, train/raw-loss = 0.2573074996471405, train/logprobs = tensor([[-1.0326, -6.6078],
        [-2.5603, -1.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2107245773077011
Epoch 0, Step 1584: train/loss = 0.2505855858325958, train/raw-loss = 0.20173580944538116, train/logprobs = tensor([[-1.1595, -6.1934],
        [-2.5467, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19539901614189148
Epoch 0, Step 1585: train/loss = 0.48689043521881104, train/raw-loss = 0.44627830386161804, train/logprobs = tensor([[-1.3762, -2.9080],
        [-1.6862, -1.3075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16244852542877197
Epoch 0, Step 1586: train/loss = 0.5738192200660706, train/raw-loss = 0.5230778455734253, train/logprobs = tensor([[-1.1962, -2.7499],
        [-3.4193, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2029656171798706
Epoch 0, Step 1587: train/loss = 0.1488739401102066, train/raw-loss = 0.09991653263568878, train/logprobs = tensor([[-1.3235, -6.4650],
        [-3.0748, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1958296298980713
Epoch 0, Step 1588: train/loss = 0.09635117650032043, train/raw-loss = 0.02217782288789749, train/logprobs = tensor([[-1.0987, -6.8838],
        [-4.4660, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2966934144496918
Epoch 0, Step 1589: train/loss = 0.3664107918739319, train/raw-loss = 0.3123473525047302, train/logprobs = tensor([[-2.4827, -7.9550],
        [-4.6900, -2.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162538468837738
Epoch 0, Step 1590: train/loss = 0.4236080050468445, train/raw-loss = 0.37902194261550903, train/logprobs = tensor([[-1.2385, -3.4942],
        [-2.4762, -1.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17834416031837463
Epoch 0, Step 1591: train/loss = 0.3141402006149292, train/raw-loss = 0.27495527267456055, train/logprobs = tensor([[-0.8609, -5.4469],
        [-1.7972, -1.2729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.156739741563797
Epoch 0, Step 1592: train/loss = 0.591780424118042, train/raw-loss = 0.5256827473640442, train/logprobs = tensor([[-0.9628, -4.7287],
        [-3.1145, -3.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2643907070159912
Epoch 0, Step 1593: train/loss = 0.4218038320541382, train/raw-loss = 0.37048083543777466, train/logprobs = tensor([[-0.8910, -3.3846],
        [-2.0265, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2052920162677765
Epoch 0, Step 1594: train/loss = 0.20047920942306519, train/raw-loss = 0.1419067680835724, train/logprobs = tensor([[-1.6880, -4.8423],
        [-4.5361, -1.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23428978025913239
Epoch 0, Step 1595: train/loss = 0.41164717078208923, train/raw-loss = 0.35895976424217224, train/logprobs = tensor([[-0.9766, -3.3157],
        [-2.5742, -0.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21074968576431274
Epoch 0, Step 1596: train/loss = 0.45651406049728394, train/raw-loss = 0.40890270471572876, train/logprobs = tensor([[-1.8713, -4.5355],
        [-3.5926, -2.5506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19044554233551025
Epoch 0, Step 1597: train/loss = 0.5395798683166504, train/raw-loss = 0.4977441728115082, train/logprobs = tensor([[-0.8112, -2.8768],
        [-2.4316, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16734269261360168
Epoch 0, Step 1598: train/loss = 0.3038664758205414, train/raw-loss = 0.2374003827571869, train/logprobs = tensor([[-1.0402, -3.5158],
        [-3.8244, -1.0380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26586440205574036
Epoch 0, Step 1599: train/loss = 0.5532979369163513, train/raw-loss = 0.48910456895828247, train/logprobs = tensor([[-1.0667, -2.7389],
        [-3.9123, -2.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2567733824253082
Epoch 0, Step 1600: train/loss = 0.3139026165008545, train/raw-loss = 0.2582324743270874, train/logprobs = tensor([[-1.0374, -3.6857],
        [-3.5815, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22268058359622955
Epoch 0, Step 1601: train/loss = 0.5339192748069763, train/raw-loss = 0.4729141294956207, train/logprobs = tensor([[-0.8455, -2.5175],
        [-2.3372, -1.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24402078986167908
Epoch 0, Step 1602: train/loss = 0.33240559697151184, train/raw-loss = 0.28024548292160034, train/logprobs = tensor([[-1.2069, -5.5285],
        [-2.6651, -1.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20864039659500122
Epoch 0, Step 1603: train/loss = 0.28372353315353394, train/raw-loss = 0.23046241700649261, train/logprobs = tensor([[-2.1150, -5.9067],
        [-3.8812, -1.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21304449439048767
Epoch 0, Step 1604: train/loss = 0.38198280334472656, train/raw-loss = 0.33757808804512024, train/logprobs = tensor([[-1.0022, -3.9369],
        [-2.4223, -1.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17761890590190887
Epoch 0, Step 1605: train/loss = 0.11641740798950195, train/raw-loss = 0.05183500051498413, train/logprobs = tensor([[-1.7570, -5.8783],
        [-5.9649, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583296000957489
Epoch 0, Step 1606: train/loss = 0.31616005301475525, train/raw-loss = 0.2544143497943878, train/logprobs = tensor([[-1.3149, -3.7184],
        [-2.9478, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24698282778263092
Epoch 0, Step 1607: train/loss = 0.45642518997192383, train/raw-loss = 0.4108980894088745, train/logprobs = tensor([[-3.1861, -5.4863],
        [-3.9817, -1.5649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1821083426475525
Epoch 0, Step 1608: train/loss = 0.28317174315452576, train/raw-loss = 0.2202664017677307, train/logprobs = tensor([[-1.3581, -3.9555],
        [-3.3784, -1.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516213059425354
Epoch 0, Step 1609: train/loss = 0.3883384168148041, train/raw-loss = 0.33158963918685913, train/logprobs = tensor([[-0.8993, -4.2146],
        [-3.1854, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22699511051177979
Epoch 0, Step 1610: train/loss = 0.2596934735774994, train/raw-loss = 0.1927746683359146, train/logprobs = tensor([[-2.2255, -4.9975],
        [-5.0438, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676752209663391
Epoch 0, Step 1611: train/loss = 0.34442055225372314, train/raw-loss = 0.28807690739631653, train/logprobs = tensor([[-2.2949, -4.3887],
        [-3.7543, -1.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253745198249817
Epoch 0, Step 1612: train/loss = 0.22834168374538422, train/raw-loss = 0.18410098552703857, train/logprobs = tensor([[-0.7557, -5.1422],
        [-1.7346, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17696279287338257
Epoch 0, Step 1613: train/loss = 0.43970558047294617, train/raw-loss = 0.3921610414981842, train/logprobs = tensor([[-0.8161, -4.7381],
        [-3.3088, -1.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19017814099788666
Epoch 0, Step 1614: train/loss = 0.12975382804870605, train/raw-loss = 0.061699990183115005, train/logprobs = tensor([[-0.9268, -6.7329],
        [-4.5116, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2722153067588806
Epoch 0, Step 1615: train/loss = 0.29631224274635315, train/raw-loss = 0.2391379326581955, train/logprobs = tensor([[-0.7202, -5.0140],
        [-2.5703, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22869724035263062
Epoch 0, Step 1616: train/loss = 0.19554466009140015, train/raw-loss = 0.1512639820575714, train/logprobs = tensor([[-1.1983, -5.7410],
        [-3.8059, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17712268233299255
Epoch 0, Step 1617: train/loss = 0.20413929224014282, train/raw-loss = 0.1569189727306366, train/logprobs = tensor([[-0.7363, -6.1986],
        [-2.9317, -0.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1888812631368637
Epoch 0, Step 1618: train/loss = 0.34764742851257324, train/raw-loss = 0.2874426543712616, train/logprobs = tensor([[-1.0348, -4.4233],
        [-3.1148, -1.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240819051861763
Epoch 0, Step 1619: train/loss = 0.40440598130226135, train/raw-loss = 0.3546566963195801, train/logprobs = tensor([[-0.8745, -2.9734],
        [-2.4257, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19899722933769226
Epoch 0, Step 1620: train/loss = 0.5590416789054871, train/raw-loss = 0.500031590461731, train/logprobs = tensor([[-0.9474, -2.5096],
        [-1.7530, -1.2099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2360406219959259
Epoch 0, Step 1621: train/loss = 0.1934993863105774, train/raw-loss = 0.13857775926589966, train/logprobs = tensor([[-1.0821, -4.1948],
        [-5.1539, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21968647837638855
Epoch 0, Step 1622: train/loss = 0.20900893211364746, train/raw-loss = 0.15428340435028076, train/logprobs = tensor([[-1.6049, -4.1211],
        [-3.7787, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21890203654766083
