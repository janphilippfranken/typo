[2024-03-04 11:10:40,014][root][INFO] - beta: 0.5
[2024-03-04 11:10:40,014][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-v2
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5463
n harmless: 5861
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance.', 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-v2 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-v2 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-v2 after each epoch.
5000
5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-v2 after each epoch.
eval/loss: 0.6819172501564026
Epoch 0, Step 0: train/loss = 0.6829906702041626, train/raw-loss = 0.6829906702041626, train/logprobs = tensor([[-0.6699, -1.3915],
        [-0.6918, -1.3718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6967368125915527, train/raw-loss = 0.6967368125915527, train/logprobs = tensor([[-1.2449, -1.1931],
        [-1.2830, -1.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.681961178779602, train/raw-loss = 0.681961178779602, train/logprobs = tensor([[-1.0665, -1.1302],
        [-1.1176, -1.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6865047812461853, train/raw-loss = 0.6865047812461853, train/logprobs = tensor([[-0.7065, -0.7115],
        [-0.7176, -0.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6857219934463501, train/raw-loss = 0.6857219934463501, train/logprobs = tensor([[-1.0265, -1.8217],
        [-1.0677, -1.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6746690273284912, train/raw-loss = 0.6746690273284912, train/logprobs = tensor([[-0.9530, -1.8174],
        [-1.0491, -1.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6892478466033936, train/raw-loss = 0.6892478466033936, train/logprobs = tensor([[-0.8805, -0.9851],
        [-0.8887, -0.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6914696097373962, train/raw-loss = 0.6914696097373962, train/logprobs = tensor([[-1.0103, -1.1816],
        [-1.0475, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6785277128219604, train/raw-loss = 0.6785277128219604, train/logprobs = tensor([[-0.6263, -1.2173],
        [-0.6406, -1.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6512645483016968, train/raw-loss = 0.6512645483016968, train/logprobs = tensor([[-0.6336, -1.9176],
        [-0.6508, -1.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6866858005523682, train/raw-loss = 0.6866858005523682, train/logprobs = tensor([[-0.7415, -0.9783],
        [-0.7982, -1.0072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.681243360042572, train/raw-loss = 0.681243360042572, train/logprobs = tensor([[-0.6975, -0.9609],
        [-0.7067, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6871084570884705, train/raw-loss = 0.6871084570884705, train/logprobs = tensor([[-0.4513, -0.6085],
        [-0.4558, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6829773187637329, train/raw-loss = 0.6829773187637329, train/logprobs = tensor([[-0.6844, -1.0474],
        [-0.6962, -1.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6874540448188782, train/raw-loss = 0.6874540448188782, train/logprobs = tensor([[-0.6544, -0.9099],
        [-0.6696, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6850467324256897, train/raw-loss = 0.6850467324256897, train/logprobs = tensor([[-0.7172, -0.7227],
        [-0.7362, -0.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6706571578979492, train/raw-loss = 0.6706571578979492, train/logprobs = tensor([[-0.7553, -1.0569],
        [-0.7942, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6710194945335388, train/raw-loss = 0.6710194945335388, train/logprobs = tensor([[-1.2530, -1.9402],
        [-1.3562, -1.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6765884160995483, train/raw-loss = 0.6765884160995483, train/logprobs = tensor([[-0.8279, -1.0934],
        [-0.8683, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.690765380859375, train/raw-loss = 0.690765380859375, train/logprobs = tensor([[-0.6158, -0.9908],
        [-0.6264, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6910902261734009, train/raw-loss = 0.6910902261734009, train/logprobs = tensor([[-0.6884, -0.9502],
        [-0.7013, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6669398546218872, train/raw-loss = 0.6669398546218872, train/logprobs = tensor([[-0.9797, -1.3739],
        [-1.0249, -1.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6871830224990845, train/raw-loss = 0.6871830224990845, train/logprobs = tensor([[-0.6189, -1.1361],
        [-0.6419, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6698651313781738, train/raw-loss = 0.6698651313781738, train/logprobs = tensor([[-1.0035, -1.4829],
        [-1.1006, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6806885600090027, train/raw-loss = 0.6806885600090027, train/logprobs = tensor([[-0.8974, -0.9019],
        [-0.9372, -0.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6777656078338623, train/raw-loss = 0.6777656078338623, train/logprobs = tensor([[-0.8315, -1.8914],
        [-0.8505, -1.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6883408427238464, train/raw-loss = 0.6883408427238464, train/logprobs = tensor([[-0.6777, -1.0532],
        [-0.6862, -1.0419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.68074631690979, train/raw-loss = 0.68074631690979, train/logprobs = tensor([[-0.8208, -1.0004],
        [-0.8532, -0.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.689713180065155, train/raw-loss = 0.689713180065155, train/logprobs = tensor([[-0.8096, -1.1727],
        [-0.8377, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.680632472038269, train/raw-loss = 0.680632472038269, train/logprobs = tensor([[-0.9138, -1.3854],
        [-0.9100, -1.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6807965040206909, train/raw-loss = 0.6807965040206909, train/logprobs = tensor([[-0.8706, -1.2622],
        [-0.8999, -1.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6771828532218933, train/raw-loss = 0.6771828532218933, train/logprobs = tensor([[-1.1583, -0.7258],
        [-1.2301, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6857396364212036, train/raw-loss = 0.6857396364212036, train/logprobs = tensor([[-1.1128, -1.3440],
        [-1.1491, -1.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6823768615722656, train/raw-loss = 0.6823768615722656, train/logprobs = tensor([[-1.1014, -1.1352],
        [-1.1713, -1.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6787729263305664, train/raw-loss = 0.6787729263305664, train/logprobs = tensor([[-1.5917, -0.7941],
        [-1.6526, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.65215665102005, train/raw-loss = 0.65215665102005, train/logprobs = tensor([[-1.0241, -1.4646],
        [-1.2181, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6853373050689697, train/raw-loss = 0.6853373050689697, train/logprobs = tensor([[-0.9252, -2.2067],
        [-0.9595, -2.2093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.67668217420578, train/raw-loss = 0.67668217420578, train/logprobs = tensor([[-0.8282, -1.0789],
        [-0.8409, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6762059926986694, train/raw-loss = 0.6762059926986694, train/logprobs = tensor([[-1.0021, -1.4297],
        [-1.0733, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6902726292610168, train/raw-loss = 0.6902726292610168, train/logprobs = tensor([[-0.6171, -0.8526],
        [-0.6167, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.680253267288208, train/raw-loss = 0.680253267288208, train/logprobs = tensor([[-1.2522, -1.1517],
        [-1.3110, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6824392676353455, train/raw-loss = 0.6824392676353455, train/logprobs = tensor([[-0.8229, -0.6196],
        [-0.8626, -0.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6920015811920166, train/raw-loss = 0.6920015811920166, train/logprobs = tensor([[-0.9094, -0.8814],
        [-0.9254, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6861733198165894, train/raw-loss = 0.6861733198165894, train/logprobs = tensor([[-1.0223, -1.2718],
        [-1.0633, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6728235483169556, train/raw-loss = 0.6728235483169556, train/logprobs = tensor([[-1.1114, -2.0290],
        [-1.2683, -2.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6728629469871521, train/raw-loss = 0.6728629469871521, train/logprobs = tensor([[-0.8891, -1.2119],
        [-0.9421, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6720213294029236, train/raw-loss = 0.6720213294029236, train/logprobs = tensor([[-1.0363, -1.6703],
        [-1.1252, -1.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6893136501312256, train/raw-loss = 0.6893136501312256, train/logprobs = tensor([[-0.4019, -0.7523],
        [-0.3997, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6751912236213684, train/raw-loss = 0.6751912236213684, train/logprobs = tensor([[-1.4246, -1.7837],
        [-1.5386, -1.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6961909532546997, train/raw-loss = 0.6961909532546997, train/logprobs = tensor([[-0.7343, -1.0577],
        [-0.7705, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6851383447647095, train/raw-loss = 0.6851383447647095, train/logprobs = tensor([[-0.9346, -1.4012],
        [-0.9836, -1.4173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6816130876541138, train/raw-loss = 0.6816130876541138, train/logprobs = tensor([[-0.9218, -0.7178],
        [-0.9627, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6820549964904785, train/raw-loss = 0.6820549964904785, train/logprobs = tensor([[-0.8856, -1.1503],
        [-0.9140, -1.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6746718883514404, train/raw-loss = 0.6746718883514404, train/logprobs = tensor([[-1.0418, -1.1116],
        [-1.1222, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6784038543701172, train/raw-loss = 0.6784038543701172, train/logprobs = tensor([[-1.1653, -1.4647],
        [-1.2194, -1.4570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6935303211212158, train/raw-loss = 0.6935303211212158, train/logprobs = tensor([[-0.9718, -1.1208],
        [-1.0034, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.683838963508606, train/raw-loss = 0.683838963508606, train/logprobs = tensor([[-0.9400, -3.2398],
        [-1.0203, -3.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.685793936252594, train/raw-loss = 0.685793936252594, train/logprobs = tensor([[-0.6732, -1.7192],
        [-0.6948, -1.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.684378445148468, train/raw-loss = 0.684378445148468, train/logprobs = tensor([[-0.6510, -1.0141],
        [-0.6694, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6907135844230652, train/raw-loss = 0.6907135844230652, train/logprobs = tensor([[-0.7100, -1.7739],
        [-0.7328, -1.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6992807984352112, train/raw-loss = 0.6992807984352112, train/logprobs = tensor([[-0.8289, -1.5682],
        [-0.8550, -1.6180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6853654384613037, train/raw-loss = 0.6853654384613037, train/logprobs = tensor([[-0.5764, -0.8433],
        [-0.5850, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6835581064224243, train/raw-loss = 0.6835581064224243, train/logprobs = tensor([[-0.8576, -1.2513],
        [-0.8924, -1.2466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6851794719696045, train/raw-loss = 0.6851794719696045, train/logprobs = tensor([[-0.7635, -0.8097],
        [-0.8098, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6820403337478638, train/raw-loss = 0.6799465417861938, train/logprobs = tensor([[-0.6863, -1.2580],
        [-0.7366, -1.2535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004187706857919693
Epoch 0, Step 65: train/loss = 0.6848936080932617, train/raw-loss = 0.6828057169914246, train/logprobs = tensor([[-0.8081, -1.0646],
        [-0.8403, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041757067665457726
Epoch 0, Step 66: train/loss = 0.6860412359237671, train/raw-loss = 0.6832801103591919, train/logprobs = tensor([[-1.0248, -1.4616],
        [-1.1325, -1.5250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005522251129150391
Epoch 0, Step 67: train/loss = 0.6889883279800415, train/raw-loss = 0.687046468257904, train/logprobs = tensor([[-0.4641, -0.9362],
        [-0.4732, -0.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038836095482110977
Epoch 0, Step 68: train/loss = 0.6959154009819031, train/raw-loss = 0.6940892338752747, train/logprobs = tensor([[-1.0836, -1.1728],
        [-1.1277, -1.2192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003652275074273348
Epoch 0, Step 69: train/loss = 0.6710457801818848, train/raw-loss = 0.6680521965026855, train/logprobs = tensor([[-1.0873, -1.1759],
        [-1.1899, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005987175274640322
Epoch 0, Step 70: train/loss = 0.687048614025116, train/raw-loss = 0.6851539015769958, train/logprobs = tensor([[-0.4226, -1.1403],
        [-0.4229, -1.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037894579581916332
Epoch 0, Step 71: train/loss = 0.6708581447601318, train/raw-loss = 0.6680505275726318, train/logprobs = tensor([[-0.8080, -1.1969],
        [-0.9056, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005615181755274534
Epoch 0, Step 72: train/loss = 0.6823965311050415, train/raw-loss = 0.6809998750686646, train/logprobs = tensor([[-0.3750, -0.9149],
        [-0.3733, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027933085802942514
Epoch 0, Step 73: train/loss = 0.6768797636032104, train/raw-loss = 0.6748006343841553, train/logprobs = tensor([[-0.8732, -1.2461],
        [-0.9221, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041583990678191185
Epoch 0, Step 74: train/loss = 0.6633510589599609, train/raw-loss = 0.6603751182556152, train/logprobs = tensor([[-0.9238, -1.0688],
        [-1.0605, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005951958708465099
Epoch 0, Step 75: train/loss = 0.6933037638664246, train/raw-loss = 0.6910273432731628, train/logprobs = tensor([[-0.9461, -1.1426],
        [-1.0075, -1.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004552821163088083
Epoch 0, Step 76: train/loss = 0.6778859496116638, train/raw-loss = 0.6748030781745911, train/logprobs = tensor([[-0.8806, -0.8968],
        [-1.0216, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006165841594338417
Epoch 0, Step 77: train/loss = 0.6813573837280273, train/raw-loss = 0.6783896684646606, train/logprobs = tensor([[-1.1427, -2.1674],
        [-1.2722, -2.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059355320408940315
Epoch 0, Step 78: train/loss = 0.6728637218475342, train/raw-loss = 0.6693345308303833, train/logprobs = tensor([[-1.0449, -1.0059],
        [-1.1344, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007058356422930956
Epoch 0, Step 79: train/loss = 0.6755833029747009, train/raw-loss = 0.6729469895362854, train/logprobs = tensor([[-1.3819, -2.1052],
        [-1.4105, -2.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005272676702588797
Epoch 0, Step 80: train/loss = 0.7011059522628784, train/raw-loss = 0.6989583969116211, train/logprobs = tensor([[-0.7128, -1.3037],
        [-0.7753, -1.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004295135382562876
Epoch 0, Step 81: train/loss = 0.6613189578056335, train/raw-loss = 0.6587930917739868, train/logprobs = tensor([[-0.7764, -0.9692],
        [-0.8299, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005051738582551479
Epoch 0, Step 82: train/loss = 0.6842739582061768, train/raw-loss = 0.6823616027832031, train/logprobs = tensor([[-0.7543, -1.5143],
        [-0.8362, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038246663752943277
Epoch 0, Step 83: train/loss = 0.6597592830657959, train/raw-loss = 0.6571021676063538, train/logprobs = tensor([[-0.7342, -0.8995],
        [-0.8807, -0.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005314280278980732
Epoch 0, Step 84: train/loss = 0.6785538792610168, train/raw-loss = 0.6768052577972412, train/logprobs = tensor([[-0.8713, -0.8866],
        [-0.9115, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034971539862453938
Epoch 0, Step 85: train/loss = 0.6791951060295105, train/raw-loss = 0.6766941547393799, train/logprobs = tensor([[-0.6521, -1.3182],
        [-0.7021, -1.3008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005001958459615707
Epoch 0, Step 86: train/loss = 0.6918305158615112, train/raw-loss = 0.6901122331619263, train/logprobs = tensor([[-0.6054, -0.6819],
        [-0.6313, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034366496838629246
Epoch 0, Step 87: train/loss = 0.6550692915916443, train/raw-loss = 0.6517780423164368, train/logprobs = tensor([[-1.2571, -2.1385],
        [-1.4394, -2.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006582428701221943
Epoch 0, Step 88: train/loss = 0.7048190832138062, train/raw-loss = 0.7025152444839478, train/logprobs = tensor([[-0.8346, -0.9700],
        [-0.9308, -1.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0046075498685240746
Epoch 0, Step 89: train/loss = 0.6918424367904663, train/raw-loss = 0.6897761821746826, train/logprobs = tensor([[-0.6877, -1.1987],
        [-0.7277, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004132422152906656
Epoch 0, Step 90: train/loss = 0.685584306716919, train/raw-loss = 0.6834008693695068, train/logprobs = tensor([[-0.9315, -0.7318],
        [-0.9858, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004366748966276646
Epoch 0, Step 91: train/loss = 0.665746808052063, train/raw-loss = 0.6629679799079895, train/logprobs = tensor([[-1.0419, -0.6494],
        [-1.1618, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005557766184210777
Epoch 0, Step 92: train/loss = 0.6858446598052979, train/raw-loss = 0.6839677095413208, train/logprobs = tensor([[-0.8914, -0.6104],
        [-0.9360, -0.6172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003754057688638568
Epoch 0, Step 93: train/loss = 0.6623286604881287, train/raw-loss = 0.6595438718795776, train/logprobs = tensor([[-0.9510, -0.7203],
        [-1.0707, -0.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005569495726376772
Epoch 0, Step 94: train/loss = 0.6635000109672546, train/raw-loss = 0.6600906252861023, train/logprobs = tensor([[-0.8498, -1.5742],
        [-0.9945, -1.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006818802561610937
Epoch 0, Step 95: train/loss = 0.6872637867927551, train/raw-loss = 0.6847774982452393, train/logprobs = tensor([[-0.6393, -1.3680],
        [-0.7105, -1.4023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004972503986209631
Epoch 0, Step 96: train/loss = 0.6854115128517151, train/raw-loss = 0.6780158281326294, train/logprobs = tensor([[-0.6618, -0.7911],
        [-0.7405, -0.8055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01479136012494564
Epoch 0, Step 97: train/loss = 0.6936123967170715, train/raw-loss = 0.6863077282905579, train/logprobs = tensor([[-0.6772, -1.5335],
        [-0.7206, -1.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014609433710575104
Epoch 0, Step 98: train/loss = 0.6287766695022583, train/raw-loss = 0.6174770593643188, train/logprobs = tensor([[-0.9117, -2.5976],
        [-1.1159, -2.4660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02259918861091137
Epoch 0, Step 99: train/loss = 0.6936995983123779, train/raw-loss = 0.6863369941711426, train/logprobs = tensor([[-0.6049, -1.1582],
        [-0.6227, -1.1472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014725249260663986
Epoch 0, Step 100: train/loss = 0.6541593670845032, train/raw-loss = 0.6437495946884155, train/logprobs = tensor([[-0.7758, -1.6195],
        [-0.9483, -1.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020819498226046562
Epoch 0, Step 101: train/loss = 0.6625497937202454, train/raw-loss = 0.6553663015365601, train/logprobs = tensor([[-0.9168, -1.0664],
        [-1.0729, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014366958290338516
Epoch 0, Step 102: train/loss = 0.6772788166999817, train/raw-loss = 0.6697297096252441, train/logprobs = tensor([[-0.8611, -1.7241],
        [-0.8999, -1.6655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015098157338798046
Epoch 0, Step 103: train/loss = 0.6984161138534546, train/raw-loss = 0.6911672353744507, train/logprobs = tensor([[-0.5839, -0.9275],
        [-0.5923, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014497676864266396
Epoch 0, Step 104: train/loss = 0.6405722498893738, train/raw-loss = 0.6274464726448059, train/logprobs = tensor([[-0.9035, -1.4008],
        [-1.1025, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026251481845974922
Epoch 0, Step 105: train/loss = 0.6096858978271484, train/raw-loss = 0.5992469787597656, train/logprobs = tensor([[-0.7549, -2.2875],
        [-0.8876, -2.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020877836272120476
Epoch 0, Step 106: train/loss = 0.6975038051605225, train/raw-loss = 0.6915700435638428, train/logprobs = tensor([[-0.5190, -0.9783],
        [-0.5162, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011867480352520943
Epoch 0, Step 107: train/loss = 0.6313415169715881, train/raw-loss = 0.6188957691192627, train/logprobs = tensor([[-1.1594, -2.2350],
        [-1.4225, -2.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024891430512070656
Epoch 0, Step 108: train/loss = 0.6727210283279419, train/raw-loss = 0.6649504899978638, train/logprobs = tensor([[-0.8397, -2.3987],
        [-0.9233, -2.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015541155822575092
Epoch 0, Step 109: train/loss = 0.6825320720672607, train/raw-loss = 0.6766167879104614, train/logprobs = tensor([[-0.5762, -0.9865],
        [-0.5998, -0.9430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011830572970211506
Epoch 0, Step 110: train/loss = 0.6667201519012451, train/raw-loss = 0.6578506231307983, train/logprobs = tensor([[-0.9951, -1.1279],
        [-1.1503, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01773899979889393
Epoch 0, Step 111: train/loss = 0.697004497051239, train/raw-loss = 0.6887905597686768, train/logprobs = tensor([[-0.8491, -1.3246],
        [-0.9188, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01642793044447899
Epoch 0, Step 112: train/loss = 0.6372290849685669, train/raw-loss = 0.6265974044799805, train/logprobs = tensor([[-1.7890, -1.9626],
        [-2.0268, -1.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02126343734562397
Epoch 0, Step 113: train/loss = 0.6821512579917908, train/raw-loss = 0.6757771372795105, train/logprobs = tensor([[-0.6326, -0.3148],
        [-0.6837, -0.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012748096138238907
Epoch 0, Step 114: train/loss = 0.5968015193939209, train/raw-loss = 0.5881015062332153, train/logprobs = tensor([[-1.0691, -2.6968],
        [-1.1722, -2.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017399951815605164
Epoch 0, Step 115: train/loss = 0.6842615008354187, train/raw-loss = 0.6765773296356201, train/logprobs = tensor([[-0.7376, -1.1910],
        [-0.7452, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015368384309113026
Epoch 0, Step 116: train/loss = 0.6707270741462708, train/raw-loss = 0.6636925339698792, train/logprobs = tensor([[-0.9098, -2.1298],
        [-0.9821, -2.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014069104567170143
Epoch 0, Step 117: train/loss = 0.6821928024291992, train/raw-loss = 0.6740111708641052, train/logprobs = tensor([[-1.0591, -1.3137],
        [-1.1246, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01636326126754284
Epoch 0, Step 118: train/loss = 0.66596919298172, train/raw-loss = 0.6557468175888062, train/logprobs = tensor([[-1.0692, -1.2597],
        [-1.2391, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02044474333524704
Epoch 0, Step 119: train/loss = 0.6293902397155762, train/raw-loss = 0.6199291348457336, train/logprobs = tensor([[-1.0353, -1.8005],
        [-1.2110, -1.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018922191113233566
Epoch 0, Step 120: train/loss = 0.673676609992981, train/raw-loss = 0.6625829935073853, train/logprobs = tensor([[-0.9251, -1.9769],
        [-1.1386, -2.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022187400609254837
Epoch 0, Step 121: train/loss = 0.6646422743797302, train/raw-loss = 0.6534305810928345, train/logprobs = tensor([[-0.8701, -1.3329],
        [-1.0339, -1.3285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022423245012760162
Epoch 0, Step 122: train/loss = 0.6733101606369019, train/raw-loss = 0.6650229692459106, train/logprobs = tensor([[-0.6807, -1.0941],
        [-0.7833, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01657450944185257
Epoch 0, Step 123: train/loss = 0.6620597839355469, train/raw-loss = 0.6539177298545837, train/logprobs = tensor([[-0.8618, -0.8503],
        [-1.0149, -0.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016284100711345673
Epoch 0, Step 124: train/loss = 0.687153697013855, train/raw-loss = 0.6789318323135376, train/logprobs = tensor([[-1.2348, -1.8381],
        [-1.2499, -1.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016443630680441856
Epoch 0, Step 125: train/loss = 0.7004442811012268, train/raw-loss = 0.6947650909423828, train/logprobs = tensor([[-0.4532, -0.7012],
        [-0.4581, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011358339339494705
Epoch 0, Step 126: train/loss = 0.679462194442749, train/raw-loss = 0.6715809106826782, train/logprobs = tensor([[-0.7110, -0.9555],
        [-0.8216, -0.9706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015762636438012123
Epoch 0, Step 127: train/loss = 0.6846596598625183, train/raw-loss = 0.674235999584198, train/logprobs = tensor([[-1.2403, -1.0762],
        [-1.3353, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02084742859005928
Epoch 0, Step 128: train/loss = 0.6839869022369385, train/raw-loss = 0.664915919303894, train/logprobs = tensor([[-0.7833, -0.7328],
        [-0.9265, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03814195841550827
Epoch 0, Step 129: train/loss = 0.6283453106880188, train/raw-loss = 0.6069327592849731, train/logprobs = tensor([[-0.9131, -1.8058],
        [-1.0873, -1.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04282505810260773
Epoch 0, Step 130: train/loss = 0.69013512134552, train/raw-loss = 0.6774654984474182, train/logprobs = tensor([[-0.6128, -1.0787],
        [-0.6192, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025339314714074135
Epoch 0, Step 131: train/loss = 0.6774424910545349, train/raw-loss = 0.6537313461303711, train/logprobs = tensor([[-1.0224, -1.3404],
        [-1.2322, -1.3798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04742217808961868
Epoch 0, Step 132: train/loss = 0.6510292887687683, train/raw-loss = 0.632312536239624, train/logprobs = tensor([[-0.7636, -0.9569],
        [-0.9907, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03743357956409454
Epoch 0, Step 133: train/loss = 0.6371230483055115, train/raw-loss = 0.6130802631378174, train/logprobs = tensor([[-1.1660, -1.6593],
        [-1.4532, -1.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04808560386300087
Epoch 0, Step 134: train/loss = 0.6800014972686768, train/raw-loss = 0.6644183397293091, train/logprobs = tensor([[-0.9755, -0.9482],
        [-0.9887, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031166207045316696
Epoch 0, Step 135: train/loss = 0.6701500415802002, train/raw-loss = 0.6518733501434326, train/logprobs = tensor([[-0.6907, -1.0601],
        [-0.8369, -1.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03655339777469635
Epoch 0, Step 136: train/loss = 0.6768455505371094, train/raw-loss = 0.6577461361885071, train/logprobs = tensor([[-0.6694, -0.9414],
        [-0.8323, -0.9474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03819890692830086
Epoch 0, Step 137: train/loss = 0.6303304433822632, train/raw-loss = 0.6100890636444092, train/logprobs = tensor([[-0.9157, -1.1237],
        [-1.1398, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04048275202512741
Epoch 0, Step 138: train/loss = 0.6653813123703003, train/raw-loss = 0.6440709829330444, train/logprobs = tensor([[-0.9492, -1.9897],
        [-1.1146, -1.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0426207035779953
Epoch 0, Step 139: train/loss = 0.6919940114021301, train/raw-loss = 0.6760666370391846, train/logprobs = tensor([[-0.6805, -1.0244],
        [-0.7860, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03185471147298813
Epoch 0, Step 140: train/loss = 0.677699863910675, train/raw-loss = 0.6623687148094177, train/logprobs = tensor([[-1.0219, -1.9347],
        [-1.1299, -1.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030662409961223602
Epoch 0, Step 141: train/loss = 0.6925860643386841, train/raw-loss = 0.6758642196655273, train/logprobs = tensor([[-1.0246, -2.0946],
        [-1.0709, -2.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03344378620386124
Epoch 0, Step 142: train/loss = 0.7078063488006592, train/raw-loss = 0.6920391321182251, train/logprobs = tensor([[-0.9193, -0.9663],
        [-0.9953, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031534358859062195
Epoch 0, Step 143: train/loss = 0.6938748359680176, train/raw-loss = 0.6766897439956665, train/logprobs = tensor([[-1.2543, -1.9143],
        [-1.3764, -1.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03437007963657379
Epoch 0, Step 144: train/loss = 0.6556805372238159, train/raw-loss = 0.6365968585014343, train/logprobs = tensor([[-0.8541, -1.3273],
        [-0.9998, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038167282938957214
Epoch 0, Step 145: train/loss = 0.6837459802627563, train/raw-loss = 0.6673496961593628, train/logprobs = tensor([[-0.6342, -1.5129],
        [-0.6669, -1.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032792508602142334
Epoch 0, Step 146: train/loss = 0.6412402391433716, train/raw-loss = 0.6184639930725098, train/logprobs = tensor([[-0.9421, -1.5451],
        [-1.2000, -1.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045552343130111694
Epoch 0, Step 147: train/loss = 0.6632609367370605, train/raw-loss = 0.641697108745575, train/logprobs = tensor([[-1.0896, -0.9742],
        [-1.2806, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04312751442193985
Epoch 0, Step 148: train/loss = 0.6500732898712158, train/raw-loss = 0.6279511451721191, train/logprobs = tensor([[-1.0624, -2.3489],
        [-1.3189, -2.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044244393706321716
Epoch 0, Step 149: train/loss = 0.645828366279602, train/raw-loss = 0.6247148513793945, train/logprobs = tensor([[-0.8950, -1.1320],
        [-1.1080, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04222710430622101
Epoch 0, Step 150: train/loss = 0.7129800319671631, train/raw-loss = 0.6943082809448242, train/logprobs = tensor([[-0.8643, -1.6512],
        [-1.0275, -1.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037343382835388184
Epoch 0, Step 151: train/loss = 0.5793421268463135, train/raw-loss = 0.5596216320991516, train/logprobs = tensor([[-0.7141, -2.1117],
        [-0.8304, -1.4071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03944098576903343
Epoch 0, Step 152: train/loss = 0.6973778009414673, train/raw-loss = 0.6786361336708069, train/logprobs = tensor([[-0.7299, -1.0645],
        [-0.7357, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037483274936676025
Epoch 0, Step 153: train/loss = 0.6430620551109314, train/raw-loss = 0.6209267377853394, train/logprobs = tensor([[-1.1167, -0.9587],
        [-1.4050, -0.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0442705899477005
Epoch 0, Step 154: train/loss = 0.6229555606842041, train/raw-loss = 0.5981162786483765, train/logprobs = tensor([[-1.0622, -1.4108],
        [-1.3945, -1.3285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049678631126880646
Epoch 0, Step 155: train/loss = 0.6923474073410034, train/raw-loss = 0.6776712536811829, train/logprobs = tensor([[-0.5309, -0.7609],
        [-0.5654, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029352115467190742
Epoch 0, Step 156: train/loss = 0.6825852394104004, train/raw-loss = 0.6633839011192322, train/logprobs = tensor([[-0.8021, -1.1313],
        [-0.9122, -1.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03840256109833717
Epoch 0, Step 157: train/loss = 0.6627036333084106, train/raw-loss = 0.6436033248901367, train/logprobs = tensor([[-0.7523, -0.8726],
        [-0.9315, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03820051997900009
Epoch 0, Step 158: train/loss = 0.7123486995697021, train/raw-loss = 0.6941496729850769, train/logprobs = tensor([[-0.5728, -1.0471],
        [-0.5640, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03639822453260422
Epoch 0, Step 159: train/loss = 0.6637385487556458, train/raw-loss = 0.6442784070968628, train/logprobs = tensor([[-0.6845, -1.7984],
        [-0.6801, -1.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038920268416404724
Epoch 0, Step 160: train/loss = 0.6634786128997803, train/raw-loss = 0.6374531984329224, train/logprobs = tensor([[-0.7345, -1.1925],
        [-0.8454, -1.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05205085128545761
Epoch 0, Step 161: train/loss = 0.6864502429962158, train/raw-loss = 0.663623571395874, train/logprobs = tensor([[-1.0884, -1.4226],
        [-1.1974, -1.4012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04565335065126419
Epoch 0, Step 162: train/loss = 0.7081896662712097, train/raw-loss = 0.6832976937294006, train/logprobs = tensor([[-0.8297, -1.0151],
        [-0.7948, -0.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049783989787101746
Epoch 0, Step 163: train/loss = 0.6499554514884949, train/raw-loss = 0.6210260391235352, train/logprobs = tensor([[-0.7057, -1.1847],
        [-0.8066, -0.9729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05785882845520973
Epoch 0, Step 164: train/loss = 0.6050652265548706, train/raw-loss = 0.573512613773346, train/logprobs = tensor([[-0.7730, -2.2663],
        [-0.9703, -1.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06310520321130753
Epoch 0, Step 165: train/loss = 0.6215264797210693, train/raw-loss = 0.5930070877075195, train/logprobs = tensor([[-1.0746, -1.3173],
        [-1.4060, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05703871697187424
Epoch 0, Step 166: train/loss = 0.7076315879821777, train/raw-loss = 0.6870856285095215, train/logprobs = tensor([[-0.6312, -1.0340],
        [-0.6336, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04109200835227966
Epoch 0, Step 167: train/loss = 0.6257246732711792, train/raw-loss = 0.5927340984344482, train/logprobs = tensor([[-0.8263, -1.7257],
        [-1.1265, -1.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06598114222288132
Epoch 0, Step 168: train/loss = 0.6767603754997253, train/raw-loss = 0.6463662385940552, train/logprobs = tensor([[-0.8125, -2.1432],
        [-0.8415, -1.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060788173228502274
Epoch 0, Step 169: train/loss = 0.6729723811149597, train/raw-loss = 0.6438007354736328, train/logprobs = tensor([[-1.2258, -1.9105],
        [-1.3409, -1.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058343179523944855
Epoch 0, Step 170: train/loss = 0.6917222738265991, train/raw-loss = 0.6668170094490051, train/logprobs = tensor([[-0.4512, -1.0579],
        [-0.4522, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0498105064034462
Epoch 0, Step 171: train/loss = 0.7041171789169312, train/raw-loss = 0.6781013011932373, train/logprobs = tensor([[-0.7145, -1.2727],
        [-0.7915, -1.2859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05203168839216232
Epoch 0, Step 172: train/loss = 0.6483675241470337, train/raw-loss = 0.618206262588501, train/logprobs = tensor([[-0.7881, -2.1297],
        [-0.8208, -1.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0603223517537117
Epoch 0, Step 173: train/loss = 0.6447855234146118, train/raw-loss = 0.6190006136894226, train/logprobs = tensor([[-0.9001, -1.1243],
        [-1.1201, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051569804549217224
Epoch 0, Step 174: train/loss = 0.710260808467865, train/raw-loss = 0.6836031675338745, train/logprobs = tensor([[-0.5373, -1.0677],
        [-0.5557, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05331532284617424
Epoch 0, Step 175: train/loss = 0.6811071038246155, train/raw-loss = 0.6629818081855774, train/logprobs = tensor([[-0.5911, -0.6594],
        [-0.6344, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03625056520104408
Epoch 0, Step 176: train/loss = 0.7015864849090576, train/raw-loss = 0.6748899221420288, train/logprobs = tensor([[-0.5876, -0.9831],
        [-0.6382, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05339305102825165
Epoch 0, Step 177: train/loss = 0.6923593282699585, train/raw-loss = 0.6721969246864319, train/logprobs = tensor([[-0.5860, -0.9516],
        [-0.5774, -0.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040324874222278595
Epoch 0, Step 178: train/loss = 0.6279541254043579, train/raw-loss = 0.595443606376648, train/logprobs = tensor([[-0.8166, -2.1374],
        [-0.9559, -1.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06502114236354828
Epoch 0, Step 179: train/loss = 0.6778877973556519, train/raw-loss = 0.6522386074066162, train/logprobs = tensor([[-0.7970, -1.1724],
        [-0.9936, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05129845440387726
Epoch 0, Step 180: train/loss = 0.661626398563385, train/raw-loss = 0.6319723725318909, train/logprobs = tensor([[-0.6589, -1.0962],
        [-0.7591, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05930805578827858
Epoch 0, Step 181: train/loss = 0.6591777205467224, train/raw-loss = 0.6361129283905029, train/logprobs = tensor([[-0.7425, -0.7323],
        [-0.8862, -0.6247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046129535883665085
Epoch 0, Step 182: train/loss = 0.6706833839416504, train/raw-loss = 0.6403154134750366, train/logprobs = tensor([[-0.8035, -1.5474],
        [-0.9326, -1.4468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06073597073554993
Epoch 0, Step 183: train/loss = 0.6558943390846252, train/raw-loss = 0.6276365518569946, train/logprobs = tensor([[-0.6520, -1.4853],
        [-0.7434, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05651566758751869
Epoch 0, Step 184: train/loss = 0.6808083653450012, train/raw-loss = 0.6534091830253601, train/logprobs = tensor([[-1.1175, -1.1681],
        [-1.3271, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05479837954044342
Epoch 0, Step 185: train/loss = 0.6630656719207764, train/raw-loss = 0.6376566886901855, train/logprobs = tensor([[-1.1593, -1.4142],
        [-1.3932, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05081792175769806
Epoch 0, Step 186: train/loss = 0.6961523294448853, train/raw-loss = 0.6717200875282288, train/logprobs = tensor([[-0.5435, -0.9428],
        [-0.5493, -0.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04886437952518463
Epoch 0, Step 187: train/loss = 0.6484023332595825, train/raw-loss = 0.6185205578804016, train/logprobs = tensor([[-0.9241, -1.0029],
        [-1.1459, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0597635954618454
Epoch 0, Step 188: train/loss = 0.6566879749298096, train/raw-loss = 0.6308103799819946, train/logprobs = tensor([[-1.0681, -1.4473],
        [-1.3275, -1.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05175524950027466
Epoch 0, Step 189: train/loss = 0.6474969387054443, train/raw-loss = 0.6249179840087891, train/logprobs = tensor([[-0.6340, -1.6143],
        [-0.6905, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04515783488750458
Epoch 0, Step 190: train/loss = 0.6666164398193359, train/raw-loss = 0.6421647667884827, train/logprobs = tensor([[-1.1444, -1.1621],
        [-1.3883, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048903316259384155
Epoch 0, Step 191: train/loss = 0.6478328704833984, train/raw-loss = 0.6215984225273132, train/logprobs = tensor([[-0.6773, -0.7602],
        [-0.8932, -0.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05246896669268608
Epoch 0, Step 192: train/loss = 0.5308303236961365, train/raw-loss = 0.46757271885871887, train/logprobs = tensor([[-0.7077, -2.5873],
        [-1.1284, -1.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265152394771576
Epoch 0, Step 193: train/loss = 0.7114709615707397, train/raw-loss = 0.6618425846099854, train/logprobs = tensor([[-0.5584, -0.8286],
        [-0.5218, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992567390203476
Epoch 0, Step 194: train/loss = 0.6470167636871338, train/raw-loss = 0.5856812596321106, train/logprobs = tensor([[-0.7970, -1.6106],
        [-0.8703, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12267106771469116
Epoch 0, Step 195: train/loss = 0.7327579855918884, train/raw-loss = 0.6913769245147705, train/logprobs = tensor([[-0.7351, -1.4357],
        [-0.6634, -1.3533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276203274726868
Epoch 0, Step 196: train/loss = 0.6601314544677734, train/raw-loss = 0.6048469543457031, train/logprobs = tensor([[-1.0859, -1.1623],
        [-1.3757, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1105690449476242
Epoch 0, Step 197: train/loss = 0.6431455016136169, train/raw-loss = 0.5929847955703735, train/logprobs = tensor([[-0.9347, -1.3575],
        [-1.1403, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10032150894403458
Epoch 0, Step 198: train/loss = 0.566298246383667, train/raw-loss = 0.5138942003250122, train/logprobs = tensor([[-0.6534, -2.1730],
        [-1.0265, -1.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10480807721614838
Epoch 0, Step 199: train/loss = 0.6979831457138062, train/raw-loss = 0.6534876227378845, train/logprobs = tensor([[-0.7086, -0.8609],
        [-0.8427, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899104595184326
Epoch 0, Step 200: train/loss = 0.6982797384262085, train/raw-loss = 0.6406575441360474, train/logprobs = tensor([[-0.7369, -1.1252],
        [-0.8640, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11524436622858047
Epoch 0, Step 201: train/loss = 0.7063108086585999, train/raw-loss = 0.6490821838378906, train/logprobs = tensor([[-0.7479, -1.0456],
        [-0.7555, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11445729434490204
Epoch 0, Step 202: train/loss = 0.6913819313049316, train/raw-loss = 0.6415703296661377, train/logprobs = tensor([[-0.6207, -1.7541],
        [-0.7478, -1.6524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09962335228919983
Epoch 0, Step 203: train/loss = 0.6719647645950317, train/raw-loss = 0.6247212886810303, train/logprobs = tensor([[-0.8174, -0.8510],
        [-1.0763, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09448698163032532
Epoch 0, Step 204: train/loss = 0.6153052449226379, train/raw-loss = 0.5528483390808105, train/logprobs = tensor([[-0.7785, -1.0662],
        [-1.2025, -0.8249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1249137744307518
Epoch 0, Step 205: train/loss = 0.7211597561836243, train/raw-loss = 0.6727523803710938, train/logprobs = tensor([[-0.7624, -1.0212],
        [-0.6527, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09681470692157745
Epoch 0, Step 206: train/loss = 0.6326881051063538, train/raw-loss = 0.5850350260734558, train/logprobs = tensor([[-0.7244, -1.6493],
        [-0.9391, -1.3431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09530603140592575
Epoch 0, Step 207: train/loss = 0.5680731534957886, train/raw-loss = 0.4844048321247101, train/logprobs = tensor([[-0.6910, -3.1463],
        [-0.9129, -2.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16733667254447937
Epoch 0, Step 208: train/loss = 0.6347535848617554, train/raw-loss = 0.5886141657829285, train/logprobs = tensor([[-0.6557, -1.0633],
        [-0.9339, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227893501520157
Epoch 0, Step 209: train/loss = 0.6626300811767578, train/raw-loss = 0.5895224213600159, train/logprobs = tensor([[-0.9725, -1.3962],
        [-1.3824, -1.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14621542394161224
Epoch 0, Step 210: train/loss = 0.6288659572601318, train/raw-loss = 0.5620232224464417, train/logprobs = tensor([[-0.7983, -1.7509],
        [-1.0877, -1.4221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13368545472621918
Epoch 0, Step 211: train/loss = 0.6634561419487, train/raw-loss = 0.6079486608505249, train/logprobs = tensor([[-1.0542, -1.3320],
        [-1.4044, -1.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11101499199867249
Epoch 0, Step 212: train/loss = 0.6445426940917969, train/raw-loss = 0.590660572052002, train/logprobs = tensor([[-0.7148, -1.3320],
        [-0.9218, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776428878307343
Epoch 0, Step 213: train/loss = 0.7100323438644409, train/raw-loss = 0.661494791507721, train/logprobs = tensor([[-0.6059, -1.0454],
        [-0.6150, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09707514196634293
Epoch 0, Step 214: train/loss = 0.7116062641143799, train/raw-loss = 0.677025556564331, train/logprobs = tensor([[-0.8025, -0.9216],
        [-0.7671, -0.8191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06916140764951706
Epoch 0, Step 215: train/loss = 0.605713427066803, train/raw-loss = 0.5539185404777527, train/logprobs = tensor([[-0.9487, -1.5688],
        [-1.2997, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10358977317810059
Epoch 0, Step 216: train/loss = 0.5522684454917908, train/raw-loss = 0.4860271215438843, train/logprobs = tensor([[-0.9567, -2.5403],
        [-1.4063, -1.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324826031923294
Epoch 0, Step 217: train/loss = 0.7371288537979126, train/raw-loss = 0.6695365905761719, train/logprobs = tensor([[-0.6846, -0.7367],
        [-0.7211, -0.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13518458604812622
Epoch 0, Step 218: train/loss = 0.6755695343017578, train/raw-loss = 0.6045153141021729, train/logprobs = tensor([[-0.9599, -1.4924],
        [-1.1264, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14210855960845947
Epoch 0, Step 219: train/loss = 0.6958304047584534, train/raw-loss = 0.6401752233505249, train/logprobs = tensor([[-0.7817, -1.1775],
        [-0.7815, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11131030321121216
Epoch 0, Step 220: train/loss = 0.5974923968315125, train/raw-loss = 0.5258370041847229, train/logprobs = tensor([[-0.7271, -1.4546],
        [-1.1156, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14331074059009552
Epoch 0, Step 221: train/loss = 0.7072957754135132, train/raw-loss = 0.630465030670166, train/logprobs = tensor([[-0.7700, -1.2812],
        [-0.7350, -0.9665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15366151928901672
Epoch 0, Step 222: train/loss = 0.658912718296051, train/raw-loss = 0.6077578067779541, train/logprobs = tensor([[-1.0309, -0.9926],
        [-1.2993, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10230987519025803
Epoch 0, Step 223: train/loss = 0.6378938555717468, train/raw-loss = 0.5786675810813904, train/logprobs = tensor([[-1.4744, -2.0384],
        [-1.5100, -1.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11845248192548752
Epoch 0, Step 224: train/loss = 0.7609739303588867, train/raw-loss = 0.7040576338768005, train/logprobs = tensor([[-0.8254, -1.3201],
        [-1.0658, -1.5150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11383266746997833
Epoch 0, Step 225: train/loss = 0.7038794159889221, train/raw-loss = 0.6447591781616211, train/logprobs = tensor([[-0.5747, -1.2430],
        [-0.5430, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11824038624763489
Epoch 0, Step 226: train/loss = 0.7616709470748901, train/raw-loss = 0.7163105010986328, train/logprobs = tensor([[-0.6672, -0.5864],
        [-0.9471, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0907210111618042
Epoch 0, Step 227: train/loss = 0.6401971578598022, train/raw-loss = 0.5870274901390076, train/logprobs = tensor([[-0.6171, -1.3666],
        [-0.9459, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10633939504623413
Epoch 0, Step 228: train/loss = 0.6617912650108337, train/raw-loss = 0.613915741443634, train/logprobs = tensor([[-0.6491, -1.0812],
        [-0.6814, -0.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09575092792510986
Epoch 0, Step 229: train/loss = 0.5474966168403625, train/raw-loss = 0.4883466958999634, train/logprobs = tensor([[-1.1953, -1.8974],
        [-1.8256, -1.4385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11829985678195953
Epoch 0, Step 230: train/loss = 0.7294955253601074, train/raw-loss = 0.6813713908195496, train/logprobs = tensor([[-0.8853, -1.0402],
        [-0.7604, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09624826908111572
Epoch 0, Step 231: train/loss = 0.7311128973960876, train/raw-loss = 0.6871991157531738, train/logprobs = tensor([[-0.6442, -0.6750],
        [-0.5814, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08782759308815002
Epoch 0, Step 232: train/loss = 0.6168156862258911, train/raw-loss = 0.5660908818244934, train/logprobs = tensor([[-0.7119, -1.5749],
        [-0.9794, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10144972056150436
Epoch 0, Step 233: train/loss = 0.640243411064148, train/raw-loss = 0.5812749266624451, train/logprobs = tensor([[-0.9249, -1.9011],
        [-0.9963, -1.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793696135282516
Epoch 0, Step 234: train/loss = 0.6678966283798218, train/raw-loss = 0.6168764233589172, train/logprobs = tensor([[-0.7452, -1.6694],
        [-0.7987, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10204051434993744
Epoch 0, Step 235: train/loss = 0.645953893661499, train/raw-loss = 0.5835822820663452, train/logprobs = tensor([[-0.6667, -1.2480],
        [-0.7793, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12474314868450165
Epoch 0, Step 236: train/loss = 0.6992390751838684, train/raw-loss = 0.6461390256881714, train/logprobs = tensor([[-0.9325, -1.4948],
        [-0.8234, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1061999574303627
Epoch 0, Step 237: train/loss = 0.6818015575408936, train/raw-loss = 0.6292521953582764, train/logprobs = tensor([[-0.8618, -2.0999],
        [-0.8935, -1.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10509884357452393
Epoch 0, Step 238: train/loss = 0.6395970582962036, train/raw-loss = 0.5897223353385925, train/logprobs = tensor([[-0.6281, -0.7902],
        [-0.9360, -0.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09974950551986694
Epoch 0, Step 239: train/loss = 0.5780410766601562, train/raw-loss = 0.5270799994468689, train/logprobs = tensor([[-0.8513, -1.2369],
        [-1.2193, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10192212462425232
Epoch 0, Step 240: train/loss = 0.6654679775238037, train/raw-loss = 0.6133994460105896, train/logprobs = tensor([[-1.0860, -1.1255],
        [-1.2350, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1041371300816536
Epoch 0, Step 241: train/loss = 0.7455494403839111, train/raw-loss = 0.6915275454521179, train/logprobs = tensor([[-1.0136, -1.1507],
        [-0.7466, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10804392397403717
Epoch 0, Step 242: train/loss = 0.6597777009010315, train/raw-loss = 0.605311393737793, train/logprobs = tensor([[-1.0878, -0.8038],
        [-1.3750, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1089324951171875
Epoch 0, Step 243: train/loss = 0.6429828405380249, train/raw-loss = 0.5920157432556152, train/logprobs = tensor([[-0.7314, -1.6644],
        [-0.8438, -1.3107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10193418711423874
Epoch 0, Step 244: train/loss = 0.7058263421058655, train/raw-loss = 0.6509101390838623, train/logprobs = tensor([[-0.7626, -1.3296],
        [-0.6842, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983239114284515
Epoch 0, Step 245: train/loss = 0.6826085448265076, train/raw-loss = 0.6282643675804138, train/logprobs = tensor([[-0.9271, -1.9089],
        [-0.9112, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10868845134973526
Epoch 0, Step 246: train/loss = 0.6418197154998779, train/raw-loss = 0.5892298221588135, train/logprobs = tensor([[-0.8613, -1.1368],
        [-1.2298, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517985373735428
Epoch 0, Step 247: train/loss = 0.6726021766662598, train/raw-loss = 0.6135152578353882, train/logprobs = tensor([[-0.6900, -1.3562],
        [-0.7685, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817383766174316
Epoch 0, Step 248: train/loss = 0.603541374206543, train/raw-loss = 0.5481568574905396, train/logprobs = tensor([[-1.1028, -2.1113],
        [-1.1666, -1.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11076892912387848
Epoch 0, Step 249: train/loss = 0.5636365413665771, train/raw-loss = 0.5038242340087891, train/logprobs = tensor([[-0.8941, -1.7385],
        [-1.5397, -1.4257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11962469667196274
Epoch 0, Step 250: train/loss = 0.6656922101974487, train/raw-loss = 0.6266716122627258, train/logprobs = tensor([[-0.9450, -2.3337],
        [-1.0325, -2.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07804125547409058
Epoch 0, Step 251: train/loss = 0.6548395156860352, train/raw-loss = 0.6016880869865417, train/logprobs = tensor([[-0.7902, -1.2776],
        [-0.8637, -0.8965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10630273818969727
Epoch 0, Step 252: train/loss = 0.7078509330749512, train/raw-loss = 0.6500515341758728, train/logprobs = tensor([[-0.9095, -1.0345],
        [-0.9517, -0.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11559879779815674
Epoch 0, Step 253: train/loss = 0.4318907856941223, train/raw-loss = 0.3653080463409424, train/logprobs = tensor([[-0.9337, -3.3192],
        [-1.3794, -1.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331654042005539
Epoch 0, Step 254: train/loss = 0.6679645776748657, train/raw-loss = 0.6130658388137817, train/logprobs = tensor([[-0.7398, -1.1331],
        [-0.8833, -0.8886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10979750007390976
Epoch 0, Step 255: train/loss = 0.7332445979118347, train/raw-loss = 0.6825053691864014, train/logprobs = tensor([[-1.1565, -1.4654],
        [-1.0377, -1.2832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10147851705551147
Epoch 0, Step 256: train/loss = 0.6617242097854614, train/raw-loss = 0.6072246432304382, train/logprobs = tensor([[-0.7946, -0.8622],
        [-0.9547, -0.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10899916291236877
Epoch 0, Step 257: train/loss = 0.649837851524353, train/raw-loss = 0.5963815450668335, train/logprobs = tensor([[-0.6933, -0.9825],
        [-0.9581, -0.7593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10691274702548981
Epoch 0, Step 258: train/loss = 0.5905595421791077, train/raw-loss = 0.5327723026275635, train/logprobs = tensor([[-0.9671, -2.0667],
        [-1.2426, -1.3545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11557461321353912
Epoch 0, Step 259: train/loss = 0.6153609752655029, train/raw-loss = 0.5645953416824341, train/logprobs = tensor([[-1.0392, -2.3999],
        [-1.0731, -1.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10153137147426605
Epoch 0, Step 260: train/loss = 0.5822373628616333, train/raw-loss = 0.5272347927093506, train/logprobs = tensor([[-1.0317, -2.1463],
        [-1.3822, -1.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11000504344701767
Epoch 0, Step 261: train/loss = 0.6961098313331604, train/raw-loss = 0.6485683917999268, train/logprobs = tensor([[-0.9994, -0.9596],
        [-1.1994, -0.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508287161588669
Epoch 0, Step 262: train/loss = 0.5411585569381714, train/raw-loss = 0.4771372675895691, train/logprobs = tensor([[-0.7829, -2.3776],
        [-1.2008, -1.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12804260849952698
Epoch 0, Step 263: train/loss = 0.5199338793754578, train/raw-loss = 0.45899683237075806, train/logprobs = tensor([[-0.9499, -2.0625],
        [-1.4597, -1.2798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12187410891056061
Epoch 0, Step 264: train/loss = 0.5910887122154236, train/raw-loss = 0.5353688597679138, train/logprobs = tensor([[-0.8900, -1.5955],
        [-1.2962, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11143971234560013
Epoch 0, Step 265: train/loss = 0.5679041147232056, train/raw-loss = 0.5108702778816223, train/logprobs = tensor([[-0.7171, -3.1071],
        [-0.6991, -1.5916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1140676885843277
Epoch 0, Step 266: train/loss = 0.5217960476875305, train/raw-loss = 0.4640192687511444, train/logprobs = tensor([[-0.8016, -1.9621],
        [-1.2891, -1.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1155535876750946
Epoch 0, Step 267: train/loss = 0.5569667816162109, train/raw-loss = 0.499538779258728, train/logprobs = tensor([[-0.6476, -2.1256],
        [-0.7277, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485601216554642
Epoch 0, Step 268: train/loss = 0.6679941415786743, train/raw-loss = 0.6162497401237488, train/logprobs = tensor([[-0.8904, -1.6641],
        [-0.8906, -1.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10348878800868988
Epoch 0, Step 269: train/loss = 0.6558639407157898, train/raw-loss = 0.6006085872650146, train/logprobs = tensor([[-0.7583, -1.5837],
        [-1.0199, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11051063239574432
Epoch 0, Step 270: train/loss = 0.6307014226913452, train/raw-loss = 0.5747120380401611, train/logprobs = tensor([[-0.7874, -1.2547],
        [-1.1113, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11197875440120697
Epoch 0, Step 271: train/loss = 0.7105585336685181, train/raw-loss = 0.6630390882492065, train/logprobs = tensor([[-0.6735, -1.0089],
        [-0.6356, -0.8445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09503894299268723
Epoch 0, Step 272: train/loss = 0.6032319664955139, train/raw-loss = 0.5404809713363647, train/logprobs = tensor([[-0.8358, -1.9193],
        [-1.1042, -1.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12550203502178192
Epoch 0, Step 273: train/loss = 0.6270450949668884, train/raw-loss = 0.5695310831069946, train/logprobs = tensor([[-0.6015, -2.0506],
        [-0.7853, -1.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150280088186264
Epoch 0, Step 274: train/loss = 0.58213210105896, train/raw-loss = 0.5298717021942139, train/logprobs = tensor([[-0.7570, -1.7582],
        [-0.9777, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10452084243297577
Epoch 0, Step 275: train/loss = 0.6459475755691528, train/raw-loss = 0.5907251238822937, train/logprobs = tensor([[-1.0493, -1.6454],
        [-1.0899, -1.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11044493317604065
Epoch 0, Step 276: train/loss = 0.7066019177436829, train/raw-loss = 0.6592150926589966, train/logprobs = tensor([[-0.4272, -1.1487],
        [-0.3960, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09477362781763077
Epoch 0, Step 277: train/loss = 0.5572800636291504, train/raw-loss = 0.49993786215782166, train/logprobs = tensor([[-1.1558, -1.5761],
        [-1.5938, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11468446254730225
Epoch 0, Step 278: train/loss = 0.7070257663726807, train/raw-loss = 0.6619786024093628, train/logprobs = tensor([[-0.8099, -1.0120],
        [-0.7793, -0.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900944173336029
Epoch 0, Step 279: train/loss = 0.5967515707015991, train/raw-loss = 0.5396941900253296, train/logprobs = tensor([[-0.7285, -0.8478],
        [-1.3401, -0.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11411464214324951
Epoch 0, Step 280: train/loss = 0.6476356387138367, train/raw-loss = 0.6033266186714172, train/logprobs = tensor([[-0.9530, -2.6297],
        [-0.8714, -2.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08861809968948364
Epoch 0, Step 281: train/loss = 0.6277732849121094, train/raw-loss = 0.5742719173431396, train/logprobs = tensor([[-0.9629, -1.7207],
        [-0.9239, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700270533561707
Epoch 0, Step 282: train/loss = 0.6482504606246948, train/raw-loss = 0.5980908870697021, train/logprobs = tensor([[-0.5513, -1.3536],
        [-0.6093, -0.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10031922161579132
Epoch 0, Step 283: train/loss = 0.5780335068702698, train/raw-loss = 0.5332894921302795, train/logprobs = tensor([[-0.5767, -1.7737],
        [-0.9735, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894879698753357
Epoch 0, Step 284: train/loss = 0.6914732456207275, train/raw-loss = 0.6424190402030945, train/logprobs = tensor([[-0.8019, -1.3141],
        [-0.9894, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09810842573642731
Epoch 0, Step 285: train/loss = 0.5643381476402283, train/raw-loss = 0.5015310049057007, train/logprobs = tensor([[-1.0113, -2.2328],
        [-1.1997, -1.4295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12561433017253876
Epoch 0, Step 286: train/loss = 0.7285439372062683, train/raw-loss = 0.6815290451049805, train/logprobs = tensor([[-0.6973, -1.1980],
        [-0.9024, -1.3069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09402970969676971
Epoch 0, Step 287: train/loss = 0.6616414189338684, train/raw-loss = 0.6079595685005188, train/logprobs = tensor([[-0.6241, -1.0481],
        [-0.6645, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10736370086669922
Epoch 0, Step 288: train/loss = 0.5261691808700562, train/raw-loss = 0.46328356862068176, train/logprobs = tensor([[-1.1233, -2.5006],
        [-1.6849, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12577122449874878
Epoch 0, Step 289: train/loss = 0.6338071823120117, train/raw-loss = 0.589399516582489, train/logprobs = tensor([[-0.7241, -1.7199],
        [-0.7107, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881529420614243
Epoch 0, Step 290: train/loss = 0.7237958908081055, train/raw-loss = 0.6723865866661072, train/logprobs = tensor([[-0.6046, -1.0951],
        [-0.5231, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281859338283539
Epoch 0, Step 291: train/loss = 0.6373732089996338, train/raw-loss = 0.5821588039398193, train/logprobs = tensor([[-0.9327, -1.8733],
        [-0.7720, -1.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11042880266904831
Epoch 0, Step 292: train/loss = 0.7145771384239197, train/raw-loss = 0.6670853495597839, train/logprobs = tensor([[-0.7463, -1.1838],
        [-0.6844, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09498360753059387
Epoch 0, Step 293: train/loss = 0.6381054520606995, train/raw-loss = 0.5904938578605652, train/logprobs = tensor([[-0.8342, -1.1803],
        [-1.0031, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09522320330142975
Epoch 0, Step 294: train/loss = 0.568093478679657, train/raw-loss = 0.5079594254493713, train/logprobs = tensor([[-0.6358, -1.9294],
        [-1.0456, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1202680915594101
Epoch 0, Step 295: train/loss = 0.600226104259491, train/raw-loss = 0.5489441156387329, train/logprobs = tensor([[-1.0346, -1.7893],
        [-1.3054, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10256384313106537
Epoch 0, Step 296: train/loss = 0.6343377828598022, train/raw-loss = 0.5740445852279663, train/logprobs = tensor([[-1.0247, -2.0860],
        [-1.5613, -1.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12058648467063904
Epoch 0, Step 297: train/loss = 0.6395341157913208, train/raw-loss = 0.590766191482544, train/logprobs = tensor([[-0.5648, -0.7427],
        [-0.8737, -0.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09753599762916565
Epoch 0, Step 298: train/loss = 0.5855181217193604, train/raw-loss = 0.5323581099510193, train/logprobs = tensor([[-0.8651, -2.2475],
        [-0.8096, -1.1230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10632003098726273
Epoch 0, Step 299: train/loss = 0.6977595686912537, train/raw-loss = 0.6415969729423523, train/logprobs = tensor([[-0.9311, -1.5942],
        [-0.9640, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11232517659664154
Epoch 0, Step 300: train/loss = 0.4843035936355591, train/raw-loss = 0.4234635829925537, train/logprobs = tensor([[-1.0240, -2.5859],
        [-1.1241, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12168003618717194
Epoch 0, Step 301: train/loss = 0.7403395175933838, train/raw-loss = 0.7017446756362915, train/logprobs = tensor([[-0.7003, -0.7689],
        [-0.6730, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077189601957798
Epoch 0, Step 302: train/loss = 0.5602429509162903, train/raw-loss = 0.5051055550575256, train/logprobs = tensor([[-0.7959, -2.2305],
        [-1.0344, -1.2924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102747693657875
Epoch 0, Step 303: train/loss = 0.4819393455982208, train/raw-loss = 0.41896724700927734, train/logprobs = tensor([[-1.0966, -1.6952],
        [-1.8849, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12594418227672577
Epoch 0, Step 304: train/loss = 0.6301102638244629, train/raw-loss = 0.5676619410514832, train/logprobs = tensor([[-0.7345, -0.9230],
        [-1.2039, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489671260118484
Epoch 0, Step 305: train/loss = 0.6560478210449219, train/raw-loss = 0.6036432385444641, train/logprobs = tensor([[-0.6690, -0.9733],
        [-0.7650, -0.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10480929166078568
Epoch 0, Step 306: train/loss = 0.636735737323761, train/raw-loss = 0.5737987756729126, train/logprobs = tensor([[-0.6553, -1.3818],
        [-0.9139, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12587393820285797
Epoch 0, Step 307: train/loss = 0.6162441968917847, train/raw-loss = 0.562217116355896, train/logprobs = tensor([[-1.0048, -1.5628],
        [-1.1131, -1.0408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10805413872003555
Epoch 0, Step 308: train/loss = 0.6197729706764221, train/raw-loss = 0.547717809677124, train/logprobs = tensor([[-0.7496, -1.3194],
        [-1.3291, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14411026239395142
Epoch 0, Step 309: train/loss = 0.636344313621521, train/raw-loss = 0.5680922269821167, train/logprobs = tensor([[-0.6206, -2.0679],
        [-0.6161, -1.3969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13650405406951904
Epoch 0, Step 310: train/loss = 0.5833355188369751, train/raw-loss = 0.5283573865890503, train/logprobs = tensor([[-1.0188, -2.0352],
        [-1.2206, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099563017487526
Epoch 0, Step 311: train/loss = 0.6409041881561279, train/raw-loss = 0.5892062187194824, train/logprobs = tensor([[-0.5623, -0.9226],
        [-0.9762, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10339583456516266
Epoch 0, Step 312: train/loss = 0.6088562607765198, train/raw-loss = 0.5630689859390259, train/logprobs = tensor([[-0.9501, -2.1577],
        [-0.8298, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09157465398311615
Epoch 0, Step 313: train/loss = 0.7055301070213318, train/raw-loss = 0.6612842082977295, train/logprobs = tensor([[-0.5060, -0.8642],
        [-0.4615, -0.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08849167078733444
Epoch 0, Step 314: train/loss = 0.5240260362625122, train/raw-loss = 0.4659935534000397, train/logprobs = tensor([[-0.7822, -2.1749],
        [-1.1992, -1.2987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11606506258249283
Epoch 0, Step 315: train/loss = 0.6649212837219238, train/raw-loss = 0.624056875705719, train/logprobs = tensor([[-0.6395, -0.4860],
        [-0.9110, -0.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08172878623008728
Epoch 0, Step 316: train/loss = 0.5928164720535278, train/raw-loss = 0.536474347114563, train/logprobs = tensor([[-0.7486, -1.4794],
        [-1.2582, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11268433928489685
Epoch 0, Step 317: train/loss = 0.7407792210578918, train/raw-loss = 0.6766209006309509, train/logprobs = tensor([[-0.8967, -1.8290],
        [-0.9683, -1.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12831667065620422
Epoch 0, Step 318: train/loss = 0.6235456466674805, train/raw-loss = 0.5745345950126648, train/logprobs = tensor([[-0.3560, -1.6533],
        [-0.3435, -1.0430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09802215546369553
Epoch 0, Step 319: train/loss = 0.6961426734924316, train/raw-loss = 0.6447746157646179, train/logprobs = tensor([[-0.5947, -1.6324],
        [-0.6567, -1.4827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10273603349924088
Epoch 0, Step 320: train/loss = 0.6161315441131592, train/raw-loss = 0.5628558397293091, train/logprobs = tensor([[-0.4541, -1.9779],
        [-0.4127, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10655143857002258
Epoch 0, Step 321: train/loss = 0.5492103099822998, train/raw-loss = 0.48856446146965027, train/logprobs = tensor([[-0.5903, -1.6256],
        [-1.0316, -0.8968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12129171937704086
Epoch 0, Step 322: train/loss = 0.4436821937561035, train/raw-loss = 0.3752215504646301, train/logprobs = tensor([[-0.9362, -2.2208],
        [-1.8237, -1.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13692137598991394
Epoch 0, Step 323: train/loss = 0.5553358197212219, train/raw-loss = 0.4990828037261963, train/logprobs = tensor([[-0.8606, -2.4481],
        [-0.9128, -1.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1125059723854065
Epoch 0, Step 324: train/loss = 0.669025719165802, train/raw-loss = 0.6203650236129761, train/logprobs = tensor([[-1.0964, -1.3975],
        [-0.9344, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09732140600681305
Epoch 0, Step 325: train/loss = 0.43499502539634705, train/raw-loss = 0.3699425458908081, train/logprobs = tensor([[-0.8512, -2.0847],
        [-1.5448, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13010501861572266
Epoch 0, Step 326: train/loss = 0.5297384262084961, train/raw-loss = 0.45881885290145874, train/logprobs = tensor([[-0.8109, -1.2534],
        [-1.5243, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14183911681175232
Epoch 0, Step 327: train/loss = 0.6105492115020752, train/raw-loss = 0.5759254097938538, train/logprobs = tensor([[-0.6281, -1.1338],
        [-0.9267, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06924764066934586
Epoch 0, Step 328: train/loss = 0.6280338168144226, train/raw-loss = 0.5715286135673523, train/logprobs = tensor([[-0.7068, -1.3647],
        [-0.7296, -0.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11301043629646301
Epoch 0, Step 329: train/loss = 0.7123887538909912, train/raw-loss = 0.6744484305381775, train/logprobs = tensor([[-0.7124, -0.7279],
        [-0.6099, -0.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07588060200214386
Epoch 0, Step 330: train/loss = 0.786908745765686, train/raw-loss = 0.7339598536491394, train/logprobs = tensor([[-1.2643, -1.5973],
        [-1.4046, -1.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10589762032032013
Epoch 0, Step 331: train/loss = 0.5813090801239014, train/raw-loss = 0.5318994522094727, train/logprobs = tensor([[-1.0464, -2.4294],
        [-1.0007, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09881936758756638
Epoch 0, Step 332: train/loss = 0.5700649619102478, train/raw-loss = 0.5021287798881531, train/logprobs = tensor([[-1.0236, -1.4961],
        [-1.8407, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358722746372223
Epoch 0, Step 333: train/loss = 0.5943135619163513, train/raw-loss = 0.5431002378463745, train/logprobs = tensor([[-1.0629, -2.2551],
        [-1.1716, -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10242662578821182
Epoch 0, Step 334: train/loss = 0.6176283359527588, train/raw-loss = 0.5546786785125732, train/logprobs = tensor([[-0.9122, -1.5049],
        [-1.1545, -1.0506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12589924037456512
Epoch 0, Step 335: train/loss = 0.6027321219444275, train/raw-loss = 0.550310492515564, train/logprobs = tensor([[-0.8504, -1.4373],
        [-1.1537, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484328866004944
Epoch 0, Step 336: train/loss = 0.5655553936958313, train/raw-loss = 0.5167540907859802, train/logprobs = tensor([[-0.9864, -2.7660],
        [-0.8333, -1.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09760264307260513
Epoch 0, Step 337: train/loss = 0.631517767906189, train/raw-loss = 0.5765875577926636, train/logprobs = tensor([[-0.8722, -1.9264],
        [-0.9879, -1.5177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10986033082008362
Epoch 0, Step 338: train/loss = 0.6122481226921082, train/raw-loss = 0.5562366843223572, train/logprobs = tensor([[-0.5966, -1.5299],
        [-0.7218, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11202292144298553
Epoch 0, Step 339: train/loss = 0.5447945594787598, train/raw-loss = 0.4854387938976288, train/logprobs = tensor([[-0.8854, -1.8609],
        [-1.3986, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11871147900819778
Epoch 0, Step 340: train/loss = 0.6372637748718262, train/raw-loss = 0.5883584022521973, train/logprobs = tensor([[-1.0372, -0.7407],
        [-1.3721, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09781080484390259
Epoch 0, Step 341: train/loss = 0.47075554728507996, train/raw-loss = 0.4046154022216797, train/logprobs = tensor([[-0.7976, -1.9891],
        [-1.2988, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13228033483028412
Epoch 0, Step 342: train/loss = 0.5856245756149292, train/raw-loss = 0.5224289298057556, train/logprobs = tensor([[-1.0697, -1.8069],
        [-1.2708, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12639129161834717
Epoch 0, Step 343: train/loss = 0.7234187722206116, train/raw-loss = 0.6676732897758484, train/logprobs = tensor([[-0.9950, -1.3677],
        [-0.8416, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11149103939533234
Epoch 0, Step 344: train/loss = 0.5779019594192505, train/raw-loss = 0.5215067863464355, train/logprobs = tensor([[-0.6371, -1.9330],
        [-0.6035, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11279027163982391
Epoch 0, Step 345: train/loss = 0.7099485397338867, train/raw-loss = 0.661858081817627, train/logprobs = tensor([[-1.0513, -1.5555],
        [-0.6980, -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09618084132671356
Epoch 0, Step 346: train/loss = 0.514439582824707, train/raw-loss = 0.44871121644973755, train/logprobs = tensor([[-0.7879, -1.9194],
        [-1.3470, -1.1092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13145670294761658
Epoch 0, Step 347: train/loss = 0.5858581066131592, train/raw-loss = 0.5295488834381104, train/logprobs = tensor([[-0.7912, -1.3799],
        [-1.1897, -0.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11261849850416183
Epoch 0, Step 348: train/loss = 0.6163833141326904, train/raw-loss = 0.5638612508773804, train/logprobs = tensor([[-0.9764, -1.5692],
        [-1.2441, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10504413396120071
Epoch 0, Step 349: train/loss = 0.6826883554458618, train/raw-loss = 0.6360211968421936, train/logprobs = tensor([[-0.8314, -1.2599],
        [-0.7466, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09333425760269165
Epoch 0, Step 350: train/loss = 0.7001224756240845, train/raw-loss = 0.6581941246986389, train/logprobs = tensor([[-0.9990, -1.3555],
        [-0.8981, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08385668694972992
Epoch 0, Step 351: train/loss = 0.6862345337867737, train/raw-loss = 0.6355840563774109, train/logprobs = tensor([[-1.0233, -1.1356],
        [-1.2646, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10130095481872559
Epoch 0, Step 352: train/loss = 0.5514241456985474, train/raw-loss = 0.48447415232658386, train/logprobs = tensor([[-0.7319, -1.9898],
        [-1.2153, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13390004634857178
Epoch 0, Step 353: train/loss = 0.6682849526405334, train/raw-loss = 0.6120186448097229, train/logprobs = tensor([[-0.7712, -1.0730],
        [-0.7647, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11253263801336288
Epoch 0, Step 354: train/loss = 0.5849458575248718, train/raw-loss = 0.5285650491714478, train/logprobs = tensor([[-0.8186, -1.3611],
        [-1.1941, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11276164650917053
Epoch 0, Step 355: train/loss = 0.5792762637138367, train/raw-loss = 0.5240553617477417, train/logprobs = tensor([[-0.8723, -1.5567],
        [-1.2441, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11044181138277054
Epoch 0, Step 356: train/loss = 0.6866456270217896, train/raw-loss = 0.6376757621765137, train/logprobs = tensor([[-0.7305, -1.3737],
        [-0.8172, -1.2258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09793972223997116
Epoch 0, Step 357: train/loss = 0.6487867832183838, train/raw-loss = 0.6050731539726257, train/logprobs = tensor([[-0.7475, -1.6160],
        [-0.7217, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08742722868919373
Epoch 0, Step 358: train/loss = 0.6561856269836426, train/raw-loss = 0.6190845370292664, train/logprobs = tensor([[-0.4575, -1.2813],
        [-0.4085, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07420211285352707
Epoch 0, Step 359: train/loss = 0.741710364818573, train/raw-loss = 0.6996196508407593, train/logprobs = tensor([[-1.1470, -1.5930],
        [-1.0543, -1.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08418137580156326
Epoch 0, Step 360: train/loss = 0.6681115627288818, train/raw-loss = 0.6211261749267578, train/logprobs = tensor([[-0.7388, -1.4757],
        [-0.7052, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397084265947342
Epoch 0, Step 361: train/loss = 0.6135717630386353, train/raw-loss = 0.5765737891197205, train/logprobs = tensor([[-0.4130, -0.9904],
        [-0.6471, -0.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0739959180355072
Epoch 0, Step 362: train/loss = 0.5688719749450684, train/raw-loss = 0.5124282240867615, train/logprobs = tensor([[-0.9129, -2.0275],
        [-1.2064, -1.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11288752406835556
Epoch 0, Step 363: train/loss = 0.4326685965061188, train/raw-loss = 0.3674122393131256, train/logprobs = tensor([[-0.9677, -2.6746],
        [-1.5920, -1.2159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13051268458366394
Epoch 0, Step 364: train/loss = 0.656299352645874, train/raw-loss = 0.6009968519210815, train/logprobs = tensor([[-0.8181, -1.2599],
        [-0.8342, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106049120426178
Epoch 0, Step 365: train/loss = 0.4328618049621582, train/raw-loss = 0.3734806478023529, train/logprobs = tensor([[-0.8671, -1.7157],
        [-1.7971, -0.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1187622994184494
Epoch 0, Step 366: train/loss = 0.5984219312667847, train/raw-loss = 0.553530216217041, train/logprobs = tensor([[-0.7087, -1.3480],
        [-0.7265, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978338539600372
Epoch 0, Step 367: train/loss = 0.6747736930847168, train/raw-loss = 0.6376270651817322, train/logprobs = tensor([[-0.6614, -0.5554],
        [-0.8484, -0.4952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.074293352663517
Epoch 0, Step 368: train/loss = 0.6644109487533569, train/raw-loss = 0.6045831441879272, train/logprobs = tensor([[-1.1329, -1.5908],
        [-1.1760, -0.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11965568363666534
Epoch 0, Step 369: train/loss = 0.5766398310661316, train/raw-loss = 0.5166746377944946, train/logprobs = tensor([[-0.8463, -1.1476],
        [-1.3981, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11993030458688736
Epoch 0, Step 370: train/loss = 0.5249130725860596, train/raw-loss = 0.4672156572341919, train/logprobs = tensor([[-0.7967, -3.2188],
        [-1.1828, -1.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11539474129676819
Epoch 0, Step 371: train/loss = 0.5716644525527954, train/raw-loss = 0.5220147371292114, train/logprobs = tensor([[-0.6199, -2.2294],
        [-0.7115, -1.2345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992993637919426
Epoch 0, Step 372: train/loss = 0.6068652272224426, train/raw-loss = 0.5632106065750122, train/logprobs = tensor([[-0.7120, -0.9476],
        [-1.0850, -0.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08730927854776382
Epoch 0, Step 373: train/loss = 0.5947858095169067, train/raw-loss = 0.5466717481613159, train/logprobs = tensor([[-0.7694, -1.9973],
        [-1.0273, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622813761234283
Epoch 0, Step 374: train/loss = 0.5902528762817383, train/raw-loss = 0.5441569089889526, train/logprobs = tensor([[-0.5092, -2.5945],
        [-0.4835, -1.4862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09219203889369965
Epoch 0, Step 375: train/loss = 0.5610457062721252, train/raw-loss = 0.49870675802230835, train/logprobs = tensor([[-0.6401, -0.9986],
        [-1.3073, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12467791140079498
Epoch 0, Step 376: train/loss = 0.6561853885650635, train/raw-loss = 0.6100979447364807, train/logprobs = tensor([[-0.9399, -1.3637],
        [-0.9759, -1.0310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09217488020658493
Epoch 0, Step 377: train/loss = 0.653368353843689, train/raw-loss = 0.606167197227478, train/logprobs = tensor([[-1.0882, -1.4778],
        [-1.0874, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0944022536277771
Epoch 0, Step 378: train/loss = 0.637185275554657, train/raw-loss = 0.5812352895736694, train/logprobs = tensor([[-0.6812, -0.9305],
        [-1.2288, -0.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11190000176429749
Epoch 0, Step 379: train/loss = 0.561207115650177, train/raw-loss = 0.5068978667259216, train/logprobs = tensor([[-0.6815, -1.7268],
        [-1.0071, -0.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10861846059560776
Epoch 0, Step 380: train/loss = 0.6742137670516968, train/raw-loss = 0.6323002576828003, train/logprobs = tensor([[-0.5798, -1.0829],
        [-0.5689, -0.8023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08382703363895416
Epoch 0, Step 381: train/loss = 0.6326808333396912, train/raw-loss = 0.5731471180915833, train/logprobs = tensor([[-0.7304, -1.0366],
        [-1.2992, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11906738579273224
Epoch 0, Step 382: train/loss = 0.6557943820953369, train/raw-loss = 0.6027237772941589, train/logprobs = tensor([[-0.6232, -1.4342],
        [-0.6128, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10614129900932312
Epoch 0, Step 383: train/loss = 0.6393393874168396, train/raw-loss = 0.5835953950881958, train/logprobs = tensor([[-1.0012, -1.2129],
        [-1.3048, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11148795485496521
Epoch 0, Step 384: train/loss = 0.6673604249954224, train/raw-loss = 0.6279714107513428, train/logprobs = tensor([[-0.7421, -0.9571],
        [-0.7158, -0.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877809554338455
Epoch 0, Step 385: train/loss = 0.5654299259185791, train/raw-loss = 0.49922966957092285, train/logprobs = tensor([[-0.6964, -1.1484],
        [-1.5993, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324004828929901
Epoch 0, Step 386: train/loss = 0.49081820249557495, train/raw-loss = 0.42379510402679443, train/logprobs = tensor([[-0.8360, -2.0456],
        [-1.4522, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13404619693756104
Epoch 0, Step 387: train/loss = 0.6570271849632263, train/raw-loss = 0.6090735197067261, train/logprobs = tensor([[-0.7033, -1.1414],
        [-0.7610, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590737521648407
Epoch 0, Step 388: train/loss = 0.7066802382469177, train/raw-loss = 0.6572643518447876, train/logprobs = tensor([[-0.6902, -1.1252],
        [-0.6934, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09883162379264832
Epoch 0, Step 389: train/loss = 0.5888895392417908, train/raw-loss = 0.5252693891525269, train/logprobs = tensor([[-0.6680, -1.3160],
        [-0.9785, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272403597831726
Epoch 0, Step 390: train/loss = 0.6000889539718628, train/raw-loss = 0.5484744310379028, train/logprobs = tensor([[-0.7758, -1.2247],
        [-1.0553, -0.6859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10322907567024231
Epoch 0, Step 391: train/loss = 0.6471971273422241, train/raw-loss = 0.5927723050117493, train/logprobs = tensor([[-0.7025, -1.5566],
        [-0.6024, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884960740804672
Epoch 0, Step 392: train/loss = 0.6854434013366699, train/raw-loss = 0.6300182342529297, train/logprobs = tensor([[-0.8837, -1.4575],
        [-0.9437, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11085028946399689
Epoch 0, Step 393: train/loss = 0.5054131150245667, train/raw-loss = 0.44646555185317993, train/logprobs = tensor([[-0.6283, -2.1496],
        [-1.0476, -1.1590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11789509654045105
Epoch 0, Step 394: train/loss = 0.5214315056800842, train/raw-loss = 0.4614906907081604, train/logprobs = tensor([[-0.9019, -1.4269],
        [-1.6618, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11988180130720139
Epoch 0, Step 395: train/loss = 0.7095869779586792, train/raw-loss = 0.6596028804779053, train/logprobs = tensor([[-0.6997, -1.1407],
        [-0.7777, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09996826946735382
Epoch 0, Step 396: train/loss = 0.7336205244064331, train/raw-loss = 0.6920396685600281, train/logprobs = tensor([[-0.7296, -0.9653],
        [-0.5884, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08316173404455185
Epoch 0, Step 397: train/loss = 0.4624757468700409, train/raw-loss = 0.3838523030281067, train/logprobs = tensor([[-0.8808, -1.9306],
        [-1.6312, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15724694728851318
Epoch 0, Step 398: train/loss = 0.5741360187530518, train/raw-loss = 0.5022033452987671, train/logprobs = tensor([[-0.6761, -1.6457],
        [-1.3586, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14386524260044098
Epoch 0, Step 399: train/loss = 0.6526957750320435, train/raw-loss = 0.6047830581665039, train/logprobs = tensor([[-0.5917, -1.1190],
        [-0.6527, -0.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0958254337310791
Epoch 0, Step 400: train/loss = 0.6171391606330872, train/raw-loss = 0.5726073384284973, train/logprobs = tensor([[-0.4992, -0.8434],
        [-0.8226, -0.4979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08906379342079163
Epoch 0, Step 401: train/loss = 0.5421814918518066, train/raw-loss = 0.495980829000473, train/logprobs = tensor([[-0.6648, -2.1030],
        [-0.7692, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09240132570266724
Epoch 0, Step 402: train/loss = 0.6519913077354431, train/raw-loss = 0.6021642684936523, train/logprobs = tensor([[-0.8661, -1.1349],
        [-1.0213, -0.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09965415298938751
Epoch 0, Step 403: train/loss = 0.5943443179130554, train/raw-loss = 0.5374087691307068, train/logprobs = tensor([[-0.8327, -1.3151],
        [-1.1121, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11387110501527786
Epoch 0, Step 404: train/loss = 0.6266014575958252, train/raw-loss = 0.5676851868629456, train/logprobs = tensor([[-1.1147, -1.5957],
        [-1.3297, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11783254146575928
Epoch 0, Step 405: train/loss = 0.5575055480003357, train/raw-loss = 0.49115389585494995, train/logprobs = tensor([[-0.7423, -2.5105],
        [-1.3222, -1.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13270318508148193
Epoch 0, Step 406: train/loss = 0.41066503524780273, train/raw-loss = 0.338967502117157, train/logprobs = tensor([[-0.9154, -3.2207],
        [-2.0943, -2.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14339500665664673
Epoch 0, Step 407: train/loss = 0.6640291213989258, train/raw-loss = 0.5980232954025269, train/logprobs = tensor([[-1.3303, -2.0855],
        [-1.0111, -1.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13201168179512024
Epoch 0, Step 408: train/loss = 0.4430055022239685, train/raw-loss = 0.3681085407733917, train/logprobs = tensor([[-0.7392, -2.5410],
        [-1.4452, -0.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14979393780231476
Epoch 0, Step 409: train/loss = 0.595778226852417, train/raw-loss = 0.5372534990310669, train/logprobs = tensor([[-0.6821, -1.2988],
        [-1.1151, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11704936623573303
Epoch 0, Step 410: train/loss = 0.6024047136306763, train/raw-loss = 0.5506930351257324, train/logprobs = tensor([[-0.4666, -1.2474],
        [-0.9262, -0.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10342337936162949
Epoch 0, Step 411: train/loss = 0.5104846954345703, train/raw-loss = 0.43761056661605835, train/logprobs = tensor([[-0.8315, -2.0964],
        [-1.2591, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14574822783470154
Epoch 0, Step 412: train/loss = 0.5212663412094116, train/raw-loss = 0.4570843279361725, train/logprobs = tensor([[-0.7796, -1.2830],
        [-1.4815, -0.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12836408615112305
Epoch 0, Step 413: train/loss = 0.6518299579620361, train/raw-loss = 0.5768950581550598, train/logprobs = tensor([[-1.1503, -1.6174],
        [-1.1221, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14986993372440338
Epoch 0, Step 414: train/loss = 0.9066455364227295, train/raw-loss = 0.8600342273712158, train/logprobs = tensor([[-2.6109, -2.6513],
        [-1.3392, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09322253614664078
Epoch 0, Step 415: train/loss = 0.7070931792259216, train/raw-loss = 0.6614060997962952, train/logprobs = tensor([[-0.9094, -1.0106],
        [-0.9648, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09137409925460815
Epoch 0, Step 416: train/loss = 0.5747249722480774, train/raw-loss = 0.5079925060272217, train/logprobs = tensor([[-1.0599, -2.0363],
        [-1.4764, -1.3998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1334649622440338
Epoch 0, Step 417: train/loss = 0.641682505607605, train/raw-loss = 0.595819354057312, train/logprobs = tensor([[-0.4375, -1.1591],
        [-0.4907, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09172625094652176
Epoch 0, Step 418: train/loss = 0.42662331461906433, train/raw-loss = 0.3583029806613922, train/logprobs = tensor([[-0.7816, -1.9804],
        [-1.8005, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13664069771766663
Epoch 0, Step 419: train/loss = 0.5170520544052124, train/raw-loss = 0.4452264606952667, train/logprobs = tensor([[-0.8422, -1.8327],
        [-1.3997, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1436513215303421
Epoch 0, Step 420: train/loss = 0.5400214195251465, train/raw-loss = 0.4727565348148346, train/logprobs = tensor([[-0.7795, -2.1234],
        [-1.5098, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13452981412410736
Epoch 0, Step 421: train/loss = 0.6645530462265015, train/raw-loss = 0.617492139339447, train/logprobs = tensor([[-0.5269, -1.1047],
        [-0.5577, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09412173926830292
Epoch 0, Step 422: train/loss = 0.4555390477180481, train/raw-loss = 0.37789374589920044, train/logprobs = tensor([[-0.7989, -2.0142],
        [-1.4868, -0.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15529057383537292
Epoch 0, Step 423: train/loss = 0.4970127046108246, train/raw-loss = 0.4347323179244995, train/logprobs = tensor([[-0.9269, -1.5919],
        [-1.8560, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12456069886684418
Epoch 0, Step 424: train/loss = 0.7008780837059021, train/raw-loss = 0.6606026291847229, train/logprobs = tensor([[-0.8886, -1.3672],
        [-0.9661, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0805508941411972
Epoch 0, Step 425: train/loss = 0.700247049331665, train/raw-loss = 0.6476051211357117, train/logprobs = tensor([[-0.4900, -1.2838],
        [-0.7807, -1.2216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10528379678726196
Epoch 0, Step 426: train/loss = 0.47403258085250854, train/raw-loss = 0.4100801348686218, train/logprobs = tensor([[-0.6927, -2.2891],
        [-1.4081, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279049813747406
Epoch 0, Step 427: train/loss = 0.5055038928985596, train/raw-loss = 0.44287967681884766, train/logprobs = tensor([[-0.6104, -2.4100],
        [-0.9022, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12524844706058502
Epoch 0, Step 428: train/loss = 0.4126170873641968, train/raw-loss = 0.34268635511398315, train/logprobs = tensor([[-0.7580, -2.5050],
        [-1.6090, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13986146450042725
Epoch 0, Step 429: train/loss = 0.6487588286399841, train/raw-loss = 0.6016699075698853, train/logprobs = tensor([[-0.5413, -0.8981],
        [-0.7199, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09417788684368134
Epoch 0, Step 430: train/loss = 0.4888277053833008, train/raw-loss = 0.4289713501930237, train/logprobs = tensor([[-0.5746, -2.4825],
        [-0.9674, -1.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11971276998519897
Epoch 0, Step 431: train/loss = 0.5675469040870667, train/raw-loss = 0.5041407346725464, train/logprobs = tensor([[-0.9877, -1.7100],
        [-1.2001, -1.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12681230902671814
Epoch 0, Step 432: train/loss = 0.5894402861595154, train/raw-loss = 0.5502920150756836, train/logprobs = tensor([[-0.6384, -1.9481],
        [-0.6394, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07829660922288895
Epoch 0, Step 433: train/loss = 0.3046582341194153, train/raw-loss = 0.21740242838859558, train/logprobs = tensor([[-0.8307, -2.9888],
        [-2.0933, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745116412639618
Epoch 0, Step 434: train/loss = 0.5729978680610657, train/raw-loss = 0.515756368637085, train/logprobs = tensor([[-0.9779, -1.5640],
        [-1.1891, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11448310315608978
Epoch 0, Step 435: train/loss = 0.5013516545295715, train/raw-loss = 0.4363716244697571, train/logprobs = tensor([[-0.7961, -2.5028],
        [-1.2945, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12996011972427368
Epoch 0, Step 436: train/loss = 0.6720646023750305, train/raw-loss = 0.6185936331748962, train/logprobs = tensor([[-0.9210, -1.2176],
        [-1.2416, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10694212466478348
Epoch 0, Step 437: train/loss = 0.6700451374053955, train/raw-loss = 0.6262423992156982, train/logprobs = tensor([[-1.2165, -1.4197],
        [-1.2207, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08760550618171692
Epoch 0, Step 438: train/loss = 0.60328209400177, train/raw-loss = 0.5498141050338745, train/logprobs = tensor([[-0.5580, -1.7407],
        [-0.5537, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10693585872650146
Epoch 0, Step 439: train/loss = 0.5377423167228699, train/raw-loss = 0.48412203788757324, train/logprobs = tensor([[-0.7552, -2.5115],
        [-0.7810, -1.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10724054276943207
Epoch 0, Step 440: train/loss = 0.7566207647323608, train/raw-loss = 0.7069128751754761, train/logprobs = tensor([[-0.5954, -0.9204],
        [-0.5990, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941574931144714
Epoch 0, Step 441: train/loss = 0.48482945561408997, train/raw-loss = 0.4158930778503418, train/logprobs = tensor([[-0.7783, -1.7768],
        [-1.6802, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13787271082401276
Epoch 0, Step 442: train/loss = 0.45840489864349365, train/raw-loss = 0.39513644576072693, train/logprobs = tensor([[-0.8490, -2.6380],
        [-1.2062, -1.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1265369951725006
Epoch 0, Step 443: train/loss = 0.5243465304374695, train/raw-loss = 0.47099390625953674, train/logprobs = tensor([[-0.5496, -1.6004],
        [-1.1041, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10670532286167145
Epoch 0, Step 444: train/loss = 0.6315984725952148, train/raw-loss = 0.5891433954238892, train/logprobs = tensor([[-0.6007, -1.4506],
        [-0.5308, -0.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08491016924381256
Epoch 0, Step 445: train/loss = 0.3636212944984436, train/raw-loss = 0.2914946675300598, train/logprobs = tensor([[-0.8079, -3.2104],
        [-1.6188, -1.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14425332844257355
Epoch 0, Step 446: train/loss = 0.6024047136306763, train/raw-loss = 0.5465583801269531, train/logprobs = tensor([[-0.7680, -1.2109],
        [-1.2949, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11169277876615524
Epoch 0, Step 447: train/loss = 0.6101806163787842, train/raw-loss = 0.5490565896034241, train/logprobs = tensor([[-0.6647, -0.9176],
        [-1.2305, -0.6010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12224800139665604
Epoch 0, Step 448: train/loss = 0.44554397463798523, train/raw-loss = 0.3766992688179016, train/logprobs = tensor([[-0.5822, -2.2733],
        [-1.6991, -1.0419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13768941164016724
Epoch 0, Step 449: train/loss = 0.5108404159545898, train/raw-loss = 0.4526241719722748, train/logprobs = tensor([[-0.8107, -2.0391],
        [-1.5531, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11643233895301819
Epoch 0, Step 450: train/loss = 0.7092630863189697, train/raw-loss = 0.6703416705131531, train/logprobs = tensor([[-0.5450, -0.7409],
        [-0.5928, -0.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0778428167104721
Epoch 0, Step 451: train/loss = 0.5472610592842102, train/raw-loss = 0.4836593568325043, train/logprobs = tensor([[-0.7517, -1.4057],
        [-1.3779, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12720336019992828
Epoch 0, Step 452: train/loss = 0.7589446902275085, train/raw-loss = 0.7003001570701599, train/logprobs = tensor([[-0.9185, -1.1063],
        [-1.0669, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728917807340622
Epoch 0, Step 453: train/loss = 0.6293946504592896, train/raw-loss = 0.5836576819419861, train/logprobs = tensor([[-0.6464, -1.3195],
        [-0.6396, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09147389978170395
Epoch 0, Step 454: train/loss = 0.5510444641113281, train/raw-loss = 0.48162293434143066, train/logprobs = tensor([[-0.8657, -1.4540],
        [-1.8661, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13884305953979492
Epoch 0, Step 455: train/loss = 0.6426136493682861, train/raw-loss = 0.5953800082206726, train/logprobs = tensor([[-0.7519, -1.1510],
        [-0.7243, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446729719638824
Epoch 0, Step 456: train/loss = 0.6244895458221436, train/raw-loss = 0.5775235891342163, train/logprobs = tensor([[-0.8049, -1.4740],
        [-0.7298, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09393204748630524
Epoch 0, Step 457: train/loss = 0.5452690124511719, train/raw-loss = 0.5042068958282471, train/logprobs = tensor([[-0.6714, -2.7325],
        [-1.0665, -1.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08212427794933319
Epoch 0, Step 458: train/loss = 0.4800955355167389, train/raw-loss = 0.41373521089553833, train/logprobs = tensor([[-0.7126, -1.3818],
        [-1.7562, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13272058963775635
Epoch 0, Step 459: train/loss = 0.5818021297454834, train/raw-loss = 0.5378004312515259, train/logprobs = tensor([[-0.9419, -1.3307],
        [-1.6017, -1.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08800342679023743
Epoch 0, Step 460: train/loss = 0.6258960962295532, train/raw-loss = 0.573561429977417, train/logprobs = tensor([[-0.7245, -1.4989],
        [-0.7096, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10466943681240082
Epoch 0, Step 461: train/loss = 0.5999575257301331, train/raw-loss = 0.5350801348686218, train/logprobs = tensor([[-0.7733, -2.1223],
        [-1.6002, -1.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12975478172302246
Epoch 0, Step 462: train/loss = 0.6629974842071533, train/raw-loss = 0.6214765310287476, train/logprobs = tensor([[-0.6397, -1.0421],
        [-0.6382, -0.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08304177969694138
Epoch 0, Step 463: train/loss = 0.5271508097648621, train/raw-loss = 0.475953608751297, train/logprobs = tensor([[-0.6663, -2.9628],
        [-0.7970, -1.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10239434987306595
Epoch 0, Step 464: train/loss = 0.6870779395103455, train/raw-loss = 0.6435116529464722, train/logprobs = tensor([[-0.7467, -1.1084],
        [-1.0082, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08713257312774658
Epoch 0, Step 465: train/loss = 0.6087710857391357, train/raw-loss = 0.5563832521438599, train/logprobs = tensor([[-1.0309, -1.8239],
        [-0.9087, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10477558523416519
Epoch 0, Step 466: train/loss = 0.4925309717655182, train/raw-loss = 0.4212315082550049, train/logprobs = tensor([[-0.7045, -2.1103],
        [-1.2092, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142598956823349
Epoch 0, Step 467: train/loss = 0.5654001832008362, train/raw-loss = 0.5091654658317566, train/logprobs = tensor([[-0.9770, -1.4656],
        [-1.4653, -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246940493583679
Epoch 0, Step 468: train/loss = 0.6853874325752258, train/raw-loss = 0.6298865079879761, train/logprobs = tensor([[-0.6009, -1.2060],
        [-0.7130, -0.9902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11100181192159653
Epoch 0, Step 469: train/loss = 0.6805803775787354, train/raw-loss = 0.6384764909744263, train/logprobs = tensor([[-0.5476, -1.0774],
        [-0.5662, -0.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08420771360397339
Epoch 0, Step 470: train/loss = 0.6629274487495422, train/raw-loss = 0.6204806566238403, train/logprobs = tensor([[-0.6879, -1.0583],
        [-0.7545, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08489353954792023
Epoch 0, Step 471: train/loss = 0.5793918371200562, train/raw-loss = 0.5335251092910767, train/logprobs = tensor([[-0.5355, -3.4861],
        [-0.6680, -2.3023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09173348546028137
Epoch 0, Step 472: train/loss = 0.5482214689254761, train/raw-loss = 0.4929274618625641, train/logprobs = tensor([[-0.8463, -2.8086],
        [-0.9233, -0.9184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11058808863162994
Epoch 0, Step 473: train/loss = 0.6089798212051392, train/raw-loss = 0.5646082162857056, train/logprobs = tensor([[-0.7456, -1.4027],
        [-0.8359, -0.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08874325454235077
Epoch 0, Step 474: train/loss = 0.6396498084068298, train/raw-loss = 0.5949398279190063, train/logprobs = tensor([[-0.4152, -1.0457],
        [-0.4465, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08941991627216339
Epoch 0, Step 475: train/loss = 0.6541131734848022, train/raw-loss = 0.6083920001983643, train/logprobs = tensor([[-0.5638, -1.2691],
        [-0.5829, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09144240617752075
Epoch 0, Step 476: train/loss = 0.5493651032447815, train/raw-loss = 0.49064961075782776, train/logprobs = tensor([[-0.5931, -1.4418],
        [-1.1356, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11743105947971344
Epoch 0, Step 477: train/loss = 0.4680632948875427, train/raw-loss = 0.3943203091621399, train/logprobs = tensor([[-0.6639, -1.5679],
        [-1.8198, -0.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14748600125312805
Epoch 0, Step 478: train/loss = 0.4826773703098297, train/raw-loss = 0.41342929005622864, train/logprobs = tensor([[-0.6366, -1.7226],
        [-1.5589, -0.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13849610090255737
Epoch 0, Step 479: train/loss = 0.5032514333724976, train/raw-loss = 0.44414904713630676, train/logprobs = tensor([[-0.9100, -2.6982],
        [-0.9590, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.118204765021801
Epoch 0, Step 480: train/loss = 0.5694686770439148, train/raw-loss = 0.5069989562034607, train/logprobs = tensor([[-0.5554, -1.4380],
        [-1.0983, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12493954598903656
Epoch 0, Step 481: train/loss = 0.4624597728252411, train/raw-loss = 0.3958413600921631, train/logprobs = tensor([[-0.7560, -3.6728],
        [-0.7825, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133236825466156
Epoch 0, Step 482: train/loss = 0.6345593929290771, train/raw-loss = 0.5845346450805664, train/logprobs = tensor([[-0.6078, -1.2630],
        [-0.6083, -0.7742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10004955530166626
Epoch 0, Step 483: train/loss = 0.6902294158935547, train/raw-loss = 0.6349260210990906, train/logprobs = tensor([[-0.9766, -1.6989],
        [-1.4182, -1.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11060672998428345
Epoch 0, Step 484: train/loss = 0.6205793619155884, train/raw-loss = 0.5669509172439575, train/logprobs = tensor([[-0.7598, -1.5289],
        [-0.6836, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1072569489479065
Epoch 0, Step 485: train/loss = 0.6015546321868896, train/raw-loss = 0.5369653105735779, train/logprobs = tensor([[-0.5838, -1.3898],
        [-0.9863, -0.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12917867302894592
Epoch 0, Step 486: train/loss = 0.5838931798934937, train/raw-loss = 0.52806556224823, train/logprobs = tensor([[-0.6726, -2.0507],
        [-0.7323, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11165514588356018
Epoch 0, Step 487: train/loss = 0.6373725533485413, train/raw-loss = 0.5667611360549927, train/logprobs = tensor([[-0.8601, -1.7078],
        [-1.3251, -1.4359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14122281968593597
Epoch 0, Step 488: train/loss = 0.47225451469421387, train/raw-loss = 0.3996202051639557, train/logprobs = tensor([[-0.7465, -2.2736],
        [-1.4304, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14526864886283875
Epoch 0, Step 489: train/loss = 0.4989132285118103, train/raw-loss = 0.42914509773254395, train/logprobs = tensor([[-0.6755, -1.7028],
        [-1.4505, -0.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13953635096549988
Epoch 0, Step 490: train/loss = 0.680817186832428, train/raw-loss = 0.6479005813598633, train/logprobs = tensor([[-0.4539, -0.7926],
        [-0.4546, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06583333015441895
Epoch 0, Step 491: train/loss = 0.6673057675361633, train/raw-loss = 0.6173925399780273, train/logprobs = tensor([[-0.8038, -1.0145],
        [-0.9444, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09982632845640182
Epoch 0, Step 492: train/loss = 0.6447145342826843, train/raw-loss = 0.6052038073539734, train/logprobs = tensor([[-0.8035, -1.4269],
        [-0.9122, -1.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07902145385742188
Epoch 0, Step 493: train/loss = 0.526992678642273, train/raw-loss = 0.4642474055290222, train/logprobs = tensor([[-0.6331, -2.0423],
        [-1.2821, -1.3579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254906803369522
Epoch 0, Step 494: train/loss = 0.6497236490249634, train/raw-loss = 0.5932753086090088, train/logprobs = tensor([[-1.0000, -1.6678],
        [-1.1412, -1.2755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289676278829575
Epoch 0, Step 495: train/loss = 0.555383563041687, train/raw-loss = 0.49493175745010376, train/logprobs = tensor([[-0.9430, -1.1830],
        [-1.3411, -0.5121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12090370804071426
Epoch 0, Step 496: train/loss = 0.44621944427490234, train/raw-loss = 0.3754684031009674, train/logprobs = tensor([[-0.6323, -1.7808],
        [-1.6816, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14150208234786987
Epoch 0, Step 497: train/loss = 0.665873110294342, train/raw-loss = 0.6224536299705505, train/logprobs = tensor([[-0.7098, -1.1343],
        [-0.7737, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08683901280164719
Epoch 0, Step 498: train/loss = 0.5705515146255493, train/raw-loss = 0.5206657648086548, train/logprobs = tensor([[-0.7193, -1.8096],
        [-0.9383, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09977149963378906
Epoch 0, Step 499: train/loss = 0.580190896987915, train/raw-loss = 0.5235854983329773, train/logprobs = tensor([[-0.7754, -1.2725],
        [-1.2580, -0.8101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11321085691452026
eval/loss: 0.5781873464584351
Epoch 0, Step 500: train/loss = 0.575581431388855, train/raw-loss = 0.5261729955673218, train/logprobs = tensor([[-0.6837, -2.1184],
        [-0.7821, -1.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.098816879093647
Epoch 0, Step 501: train/loss = 0.5975708365440369, train/raw-loss = 0.5510447025299072, train/logprobs = tensor([[-0.7260, -1.6279],
        [-0.9492, -0.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09305217862129211
Epoch 0, Step 502: train/loss = 0.5994624495506287, train/raw-loss = 0.5439379215240479, train/logprobs = tensor([[-0.5474, -1.0760],
        [-1.1011, -0.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11104907840490341
Epoch 0, Step 503: train/loss = 0.5578365325927734, train/raw-loss = 0.5018025040626526, train/logprobs = tensor([[-0.7558, -0.9665],
        [-1.4162, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11206812411546707
Epoch 0, Step 504: train/loss = 0.5541800260543823, train/raw-loss = 0.49140262603759766, train/logprobs = tensor([[-0.7994, -0.9510],
        [-1.5254, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255548596382141
Epoch 0, Step 505: train/loss = 0.6010240912437439, train/raw-loss = 0.5459034442901611, train/logprobs = tensor([[-0.6791, -1.2885],
        [-1.1452, -0.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11024130880832672
Epoch 0, Step 506: train/loss = 0.4772481918334961, train/raw-loss = 0.41267818212509155, train/logprobs = tensor([[-0.5607, -2.7454],
        [-1.0256, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12914004921913147
Epoch 0, Step 507: train/loss = 0.5866853594779968, train/raw-loss = 0.5359923839569092, train/logprobs = tensor([[-0.6703, -1.2495],
        [-1.0733, -0.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10138599574565887
Epoch 0, Step 508: train/loss = 0.5474331378936768, train/raw-loss = 0.49756965041160583, train/logprobs = tensor([[-0.7361, -1.4529],
        [-1.2919, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997270718216896
Epoch 0, Step 509: train/loss = 0.5824005603790283, train/raw-loss = 0.5274036526679993, train/logprobs = tensor([[-0.9005, -1.2190],
        [-1.3618, -0.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1099938303232193
Epoch 0, Step 510: train/loss = 0.6432705521583557, train/raw-loss = 0.6014493703842163, train/logprobs = tensor([[-0.4760, -0.8754],
        [-0.5291, -0.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08364230394363403
Epoch 0, Step 511: train/loss = 0.551695704460144, train/raw-loss = 0.5001051425933838, train/logprobs = tensor([[-0.9360, -2.6918],
        [-1.0883, -1.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10318123549222946
Epoch 0, Step 512: train/loss = 0.6415743231773376, train/raw-loss = 0.5996782779693604, train/logprobs = tensor([[-0.7705, -1.2822],
        [-0.7370, -0.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08379204571247101
Epoch 0, Step 513: train/loss = 0.5603860020637512, train/raw-loss = 0.50932776927948, train/logprobs = tensor([[-0.9032, -2.2886],
        [-1.2751, -1.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10211651027202606
Epoch 0, Step 514: train/loss = 0.4618067741394043, train/raw-loss = 0.3919782042503357, train/logprobs = tensor([[-0.9042, -2.9264],
        [-1.5982, -1.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396571695804596
Epoch 0, Step 515: train/loss = 0.5482028722763062, train/raw-loss = 0.5033425688743591, train/logprobs = tensor([[-0.5785, -1.8023],
        [-0.6948, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897207260131836
Epoch 0, Step 516: train/loss = 0.5174195766448975, train/raw-loss = 0.4651576280593872, train/logprobs = tensor([[-0.8714, -1.8459],
        [-1.2828, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045239269733429
Epoch 0, Step 517: train/loss = 0.5446338653564453, train/raw-loss = 0.4993322193622589, train/logprobs = tensor([[-0.4198, -2.7198],
        [-0.4365, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09060323238372803
Epoch 0, Step 518: train/loss = 0.5222505927085876, train/raw-loss = 0.46135610342025757, train/logprobs = tensor([[-0.7161, -1.8110],
        [-1.3009, -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12178899347782135
Epoch 0, Step 519: train/loss = 0.666648805141449, train/raw-loss = 0.6248698830604553, train/logprobs = tensor([[-0.5602, -1.0587],
        [-0.6447, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0835578590631485
Epoch 0, Step 520: train/loss = 0.6304858326911926, train/raw-loss = 0.5861839652061462, train/logprobs = tensor([[-0.5680, -0.7269],
        [-0.9705, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0886036828160286
Epoch 0, Step 521: train/loss = 0.5504109859466553, train/raw-loss = 0.4957491159439087, train/logprobs = tensor([[-1.0726, -1.7831],
        [-1.8969, -1.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10932378470897675
Epoch 0, Step 522: train/loss = 0.6053563356399536, train/raw-loss = 0.5495644211769104, train/logprobs = tensor([[-1.2909, -2.2590],
        [-1.4069, -1.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11158372461795807
Epoch 0, Step 523: train/loss = 0.5638899207115173, train/raw-loss = 0.5094457864761353, train/logprobs = tensor([[-0.4816, -1.4779],
        [-0.7009, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10888823866844177
Epoch 0, Step 524: train/loss = 0.7054961323738098, train/raw-loss = 0.6360727548599243, train/logprobs = tensor([[-0.5792, -1.1260],
        [-1.7961, -1.3938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138846755027771
Epoch 0, Step 525: train/loss = 0.6019940972328186, train/raw-loss = 0.5430546402931213, train/logprobs = tensor([[-0.5591, -0.8763],
        [-1.1438, -0.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11787879467010498
Epoch 0, Step 526: train/loss = 0.5983684062957764, train/raw-loss = 0.5219700336456299, train/logprobs = tensor([[-0.9278, -1.3573],
        [-2.1396, -1.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15279676020145416
Epoch 0, Step 527: train/loss = 0.577257513999939, train/raw-loss = 0.518256664276123, train/logprobs = tensor([[-0.7722, -2.1721],
        [-1.0475, -1.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11800172179937363
Epoch 0, Step 528: train/loss = 0.4562857151031494, train/raw-loss = 0.4031829833984375, train/logprobs = tensor([[-1.4885, -3.9415],
        [-1.7006, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062055379152298
Epoch 0, Step 529: train/loss = 0.6224724054336548, train/raw-loss = 0.541999101638794, train/logprobs = tensor([[-0.6308, -1.5033],
        [-1.3871, -0.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1609465330839157
Epoch 0, Step 530: train/loss = 0.6324975490570068, train/raw-loss = 0.5845921039581299, train/logprobs = tensor([[-0.6337, -1.3075],
        [-0.6457, -0.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09581094235181808
Epoch 0, Step 531: train/loss = 0.6627094745635986, train/raw-loss = 0.6252112984657288, train/logprobs = tensor([[-0.5291, -1.1694],
        [-0.8037, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07499629259109497
Epoch 0, Step 532: train/loss = 0.4840563237667084, train/raw-loss = 0.4150122404098511, train/logprobs = tensor([[-0.6713, -2.0776],
        [-1.4151, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380881369113922
Epoch 0, Step 533: train/loss = 0.6118443012237549, train/raw-loss = 0.5703092813491821, train/logprobs = tensor([[-0.4917, -1.2092],
        [-0.5098, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08306993544101715
Epoch 0, Step 534: train/loss = 0.6387903690338135, train/raw-loss = 0.597277045249939, train/logprobs = tensor([[-0.6061, -1.0674],
        [-0.5992, -0.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08302667737007141
Epoch 0, Step 535: train/loss = 0.5679149031639099, train/raw-loss = 0.5182770490646362, train/logprobs = tensor([[-0.4963, -1.6020],
        [-0.6578, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09927581995725632
Epoch 0, Step 536: train/loss = 0.6113397479057312, train/raw-loss = 0.5601361393928528, train/logprobs = tensor([[-0.9073, -1.1930],
        [-1.0242, -0.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.102407306432724
Epoch 0, Step 537: train/loss = 0.40374764800071716, train/raw-loss = 0.3404275178909302, train/logprobs = tensor([[-0.5158, -2.6229],
        [-1.0343, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664026021957397
Epoch 0, Step 538: train/loss = 0.6375640630722046, train/raw-loss = 0.5839898586273193, train/logprobs = tensor([[-0.7026, -1.4000],
        [-0.6600, -0.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714836418628693
Epoch 0, Step 539: train/loss = 0.6433658003807068, train/raw-loss = 0.5621599555015564, train/logprobs = tensor([[-0.7511, -2.0266],
        [-1.6916, -1.6387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16241174936294556
Epoch 0, Step 540: train/loss = 0.5932875871658325, train/raw-loss = 0.5331404209136963, train/logprobs = tensor([[-0.6463, -1.3039],
        [-1.1780, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12029427289962769
Epoch 0, Step 541: train/loss = 0.5375884175300598, train/raw-loss = 0.46804729104042053, train/logprobs = tensor([[-1.0545, -1.2092],
        [-2.2108, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13908229768276215
Epoch 0, Step 542: train/loss = 0.3998606503009796, train/raw-loss = 0.3131939768791199, train/logprobs = tensor([[-0.7060, -2.3069],
        [-2.0228, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17333340644836426
Epoch 0, Step 543: train/loss = 0.5858161449432373, train/raw-loss = 0.5337244868278503, train/logprobs = tensor([[-0.8554, -0.9088],
        [-1.3247, -0.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10418336093425751
Epoch 0, Step 544: train/loss = 0.7080895304679871, train/raw-loss = 0.6687885522842407, train/logprobs = tensor([[-0.5763, -0.6839],
        [-0.6629, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07860199362039566
Epoch 0, Step 545: train/loss = 0.583203911781311, train/raw-loss = 0.5279476046562195, train/logprobs = tensor([[-0.5123, -1.3385],
        [-0.5519, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11051268130540848
Epoch 0, Step 546: train/loss = 0.5914722084999084, train/raw-loss = 0.5316411852836609, train/logprobs = tensor([[-0.8678, -2.6895],
        [-1.7876, -1.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11966213583946228
Epoch 0, Step 547: train/loss = 0.5885947346687317, train/raw-loss = 0.5494527816772461, train/logprobs = tensor([[-0.5747, -1.1532],
        [-0.6352, -0.4609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0782838687300682
Epoch 0, Step 548: train/loss = 0.631793737411499, train/raw-loss = 0.5831629037857056, train/logprobs = tensor([[-0.7043, -0.8012],
        [-0.8146, -0.4108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09726159274578094
Epoch 0, Step 549: train/loss = 0.698976457118988, train/raw-loss = 0.6325050592422485, train/logprobs = tensor([[-2.2585, -1.6677],
        [-2.3730, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132942795753479
Epoch 0, Step 550: train/loss = 0.7477536797523499, train/raw-loss = 0.6939104795455933, train/logprobs = tensor([[-0.8138, -0.9366],
        [-1.0911, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10768650472164154
Epoch 0, Step 551: train/loss = 0.5901026725769043, train/raw-loss = 0.5351905226707458, train/logprobs = tensor([[-0.7022, -1.5455],
        [-0.7347, -0.8121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10982442647218704
Epoch 0, Step 552: train/loss = 0.4468001425266266, train/raw-loss = 0.3731886148452759, train/logprobs = tensor([[-0.6782, -1.4505],
        [-1.9230, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14722299575805664
Epoch 0, Step 553: train/loss = 0.5223609805107117, train/raw-loss = 0.46228545904159546, train/logprobs = tensor([[-0.7914, -1.0701],
        [-1.5894, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12015101313591003
Epoch 0, Step 554: train/loss = 0.643797755241394, train/raw-loss = 0.6007463932037354, train/logprobs = tensor([[-0.6156, -1.3114],
        [-0.6086, -0.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08610278367996216
Epoch 0, Step 555: train/loss = 0.4530659317970276, train/raw-loss = 0.3883013129234314, train/logprobs = tensor([[-0.9786, -2.2838],
        [-1.8623, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1295292228460312
Epoch 0, Step 556: train/loss = 0.5270310640335083, train/raw-loss = 0.4429996609687805, train/logprobs = tensor([[-1.0820, -1.4977],
        [-2.0197, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16806285083293915
Epoch 0, Step 557: train/loss = 0.5144646763801575, train/raw-loss = 0.4579377770423889, train/logprobs = tensor([[-0.9244, -1.6031],
        [-1.5503, -0.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130538284778595
Epoch 0, Step 558: train/loss = 0.4541561007499695, train/raw-loss = 0.3743910491466522, train/logprobs = tensor([[-0.8500, -2.2154],
        [-1.7448, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15953010320663452
Epoch 0, Step 559: train/loss = 0.4737884998321533, train/raw-loss = 0.4044361710548401, train/logprobs = tensor([[-0.6563, -2.1093],
        [-1.3990, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13870470225811005
Epoch 0, Step 560: train/loss = 0.6013356447219849, train/raw-loss = 0.5535407066345215, train/logprobs = tensor([[-0.5405, -1.2315],
        [-1.2037, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09558998793363571
Epoch 0, Step 561: train/loss = 0.5779272317886353, train/raw-loss = 0.526448667049408, train/logprobs = tensor([[-0.8723, -3.2702],
        [-0.6739, -1.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1029571145772934
Epoch 0, Step 562: train/loss = 0.5754503011703491, train/raw-loss = 0.5183556079864502, train/logprobs = tensor([[-0.5184, -1.5813],
        [-0.6253, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1141892820596695
Epoch 0, Step 563: train/loss = 0.6673949360847473, train/raw-loss = 0.6074972152709961, train/logprobs = tensor([[-1.2535, -1.5949],
        [-0.9213, -0.7371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11979535222053528
Epoch 0, Step 564: train/loss = 0.5978004336357117, train/raw-loss = 0.5352873802185059, train/logprobs = tensor([[-0.9580, -1.4752],
        [-1.0805, -0.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125026136636734
Epoch 0, Step 565: train/loss = 0.5466512441635132, train/raw-loss = 0.49044549465179443, train/logprobs = tensor([[-0.5251, -1.5940],
        [-0.6736, -0.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124114841222763
Epoch 0, Step 566: train/loss = 0.541217565536499, train/raw-loss = 0.4859169125556946, train/logprobs = tensor([[-0.6151, -1.5378],
        [-0.9382, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1106012612581253
Epoch 0, Step 567: train/loss = 0.7120646834373474, train/raw-loss = 0.6616678833961487, train/logprobs = tensor([[-0.4799, -0.8206],
        [-0.5504, -0.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10079366713762283
Epoch 0, Step 568: train/loss = 0.5597865581512451, train/raw-loss = 0.49269983172416687, train/logprobs = tensor([[-0.6654, -2.1698],
        [-1.0881, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341734230518341
Epoch 0, Step 569: train/loss = 0.4819750189781189, train/raw-loss = 0.39981043338775635, train/logprobs = tensor([[-0.7452, -1.8104],
        [-1.7493, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643291562795639
Epoch 0, Step 570: train/loss = 0.5280844569206238, train/raw-loss = 0.4707852303981781, train/logprobs = tensor([[-0.7702, -0.8334],
        [-1.9398, -0.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11459846049547195
Epoch 0, Step 571: train/loss = 0.5960273742675781, train/raw-loss = 0.5463210344314575, train/logprobs = tensor([[-0.7618, -1.8971],
        [-1.0309, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941265732049942
Epoch 0, Step 572: train/loss = 0.6141033172607422, train/raw-loss = 0.5613574385643005, train/logprobs = tensor([[-0.5567, -1.4231],
        [-0.5864, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10549177974462509
Epoch 0, Step 573: train/loss = 0.6555293798446655, train/raw-loss = 0.6152615547180176, train/logprobs = tensor([[-1.0117, -1.4127],
        [-1.0801, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08053566515445709
Epoch 0, Step 574: train/loss = 0.5448696613311768, train/raw-loss = 0.48724111914634705, train/logprobs = tensor([[-0.5958, -1.1460],
        [-0.9793, -0.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1152571514248848
Epoch 0, Step 575: train/loss = 0.8786898851394653, train/raw-loss = 0.8024234771728516, train/logprobs = tensor([[-0.7105, -1.0695],
        [-1.8939, -2.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15253272652626038
Epoch 0, Step 576: train/loss = 0.6111412048339844, train/raw-loss = 0.5536742210388184, train/logprobs = tensor([[-0.8346, -1.4173],
        [-0.7820, -0.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11493408679962158
Epoch 0, Step 577: train/loss = 0.5693401098251343, train/raw-loss = 0.5002315044403076, train/logprobs = tensor([[-0.6709, -0.9463],
        [-1.3155, -0.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13821712136268616
Epoch 0, Step 578: train/loss = 0.5158274173736572, train/raw-loss = 0.44801974296569824, train/logprobs = tensor([[-0.8798, -2.6533],
        [-0.7678, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13561539351940155
Epoch 0, Step 579: train/loss = 0.5065104961395264, train/raw-loss = 0.4393584728240967, train/logprobs = tensor([[-0.8641, -1.6327],
        [-1.4648, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13430410623550415
Epoch 0, Step 580: train/loss = 0.5243293642997742, train/raw-loss = 0.4632641673088074, train/logprobs = tensor([[-0.5329, -2.0728],
        [-0.7459, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12213034182786942
Epoch 0, Step 581: train/loss = 0.6347963213920593, train/raw-loss = 0.5930655002593994, train/logprobs = tensor([[-0.4152, -1.1679],
        [-0.4289, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08346156775951385
Epoch 0, Step 582: train/loss = 0.6198118925094604, train/raw-loss = 0.5272420644760132, train/logprobs = tensor([[-0.6779, -2.0323],
        [-1.9483, -1.7459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18513961136341095
Epoch 0, Step 583: train/loss = 0.49759483337402344, train/raw-loss = 0.4325115382671356, train/logprobs = tensor([[-0.8325, -1.9472],
        [-1.4373, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13016660511493683
Epoch 0, Step 584: train/loss = 0.5518947839736938, train/raw-loss = 0.4914279580116272, train/logprobs = tensor([[-0.8516, -1.8717],
        [-0.9240, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12093359977006912
Epoch 0, Step 585: train/loss = 0.4769212305545807, train/raw-loss = 0.4049300253391266, train/logprobs = tensor([[-0.7709, -2.8682],
        [-1.5009, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14398236572742462
Epoch 0, Step 586: train/loss = 0.3320096731185913, train/raw-loss = 0.24971042573451996, train/logprobs = tensor([[-0.8406, -2.8399],
        [-1.8619, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645985245704651
Epoch 0, Step 587: train/loss = 0.5851094126701355, train/raw-loss = 0.5321739315986633, train/logprobs = tensor([[-0.6484, -1.5439],
        [-0.7471, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10587099939584732
Epoch 0, Step 588: train/loss = 0.5456119179725647, train/raw-loss = 0.48321524262428284, train/logprobs = tensor([[-0.8998, -2.1862],
        [-0.8449, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12479329109191895
Epoch 0, Step 589: train/loss = 0.6078830361366272, train/raw-loss = 0.5628727674484253, train/logprobs = tensor([[-0.8868, -1.7357],
        [-1.1172, -1.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09002052247524261
Epoch 0, Step 590: train/loss = 0.6293015480041504, train/raw-loss = 0.5783501863479614, train/logprobs = tensor([[-0.6769, -1.2244],
        [-0.7986, -0.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10190264880657196
Epoch 0, Step 591: train/loss = 0.7868214845657349, train/raw-loss = 0.7347863912582397, train/logprobs = tensor([[-0.8119, -0.8975],
        [-1.2917, -1.3155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10407020151615143
Epoch 0, Step 592: train/loss = 0.5538972616195679, train/raw-loss = 0.49300867319107056, train/logprobs = tensor([[-0.5525, -1.9478],
        [-0.7668, -0.7572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177716195583344
Epoch 0, Step 593: train/loss = 0.563101053237915, train/raw-loss = 0.5087782144546509, train/logprobs = tensor([[-0.8621, -1.3174],
        [-1.3479, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10864578187465668
Epoch 0, Step 594: train/loss = 0.619357705116272, train/raw-loss = 0.572972297668457, train/logprobs = tensor([[-0.7099, -1.2940],
        [-0.7681, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277092665433884
Epoch 0, Step 595: train/loss = 0.32373708486557007, train/raw-loss = 0.2397545427083969, train/logprobs = tensor([[-1.0864, -2.7184],
        [-2.5962, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1679650843143463
Epoch 0, Step 596: train/loss = 0.43138372898101807, train/raw-loss = 0.3570781350135803, train/logprobs = tensor([[-1.1282, -2.6434],
        [-2.4094, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14861124753952026
Epoch 0, Step 597: train/loss = 0.55716872215271, train/raw-loss = 0.4962309002876282, train/logprobs = tensor([[-0.7104, -2.5351],
        [-0.7557, -1.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12187551707029343
Epoch 0, Step 598: train/loss = 0.6515313982963562, train/raw-loss = 0.5896660685539246, train/logprobs = tensor([[-0.8300, -1.9925],
        [-1.1817, -1.5883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1237305998802185
Epoch 0, Step 599: train/loss = 0.5902843475341797, train/raw-loss = 0.5308843851089478, train/logprobs = tensor([[-0.9104, -1.5769],
        [-1.1879, -1.0815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1187998503446579
Epoch 0, Step 600: train/loss = 0.534522533416748, train/raw-loss = 0.4664894640445709, train/logprobs = tensor([[-1.3874, -3.9953],
        [-0.9447, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13606606423854828
Epoch 0, Step 601: train/loss = 0.5771433711051941, train/raw-loss = 0.5100806951522827, train/logprobs = tensor([[-1.1386, -2.7286],
        [-1.1463, -1.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1341254562139511
Epoch 0, Step 602: train/loss = 0.43751221895217896, train/raw-loss = 0.36284664273262024, train/logprobs = tensor([[-0.6962, -2.4789],
        [-1.1898, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14933116734027863
Epoch 0, Step 603: train/loss = 0.5410825610160828, train/raw-loss = 0.4784523546695709, train/logprobs = tensor([[-0.8719, -2.6113],
        [-0.7270, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12526047229766846
Epoch 0, Step 604: train/loss = 0.6193193197250366, train/raw-loss = 0.5704948306083679, train/logprobs = tensor([[-0.6177, -1.7519],
        [-0.5834, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0976490005850792
Epoch 0, Step 605: train/loss = 0.602814793586731, train/raw-loss = 0.5352063179016113, train/logprobs = tensor([[-1.1553, -2.4867],
        [-0.7792, -0.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13521678745746613
Epoch 0, Step 606: train/loss = 0.40481263399124146, train/raw-loss = 0.31911683082580566, train/logprobs = tensor([[-0.9554, -2.2120],
        [-2.0362, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17139165103435516
Epoch 0, Step 607: train/loss = 0.5637719631195068, train/raw-loss = 0.5058130025863647, train/logprobs = tensor([[-0.7780, -1.7458],
        [-1.0821, -1.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11591798067092896
Epoch 0, Step 608: train/loss = 0.4417099356651306, train/raw-loss = 0.3700712323188782, train/logprobs = tensor([[-0.6286, -2.3694],
        [-1.2003, -0.8021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14327740669250488
Epoch 0, Step 609: train/loss = 0.3836591839790344, train/raw-loss = 0.3170946538448334, train/logprobs = tensor([[-0.8345, -4.7322],
        [-1.4210, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1331290453672409
Epoch 0, Step 610: train/loss = 0.5847758054733276, train/raw-loss = 0.5392609238624573, train/logprobs = tensor([[-0.5939, -1.8309],
        [-0.5159, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09102977067232132
Epoch 0, Step 611: train/loss = 0.6222248077392578, train/raw-loss = 0.563206672668457, train/logprobs = tensor([[-0.6760, -1.4635],
        [-0.5654, -0.5021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11803634464740753
Epoch 0, Step 612: train/loss = 0.509078860282898, train/raw-loss = 0.4484008848667145, train/logprobs = tensor([[-0.7458, -2.7672],
        [-0.7846, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12135592848062515
Epoch 0, Step 613: train/loss = 0.6374539136886597, train/raw-loss = 0.573383629322052, train/logprobs = tensor([[-0.7086, -2.3216],
        [-1.1932, -1.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12814068794250488
Epoch 0, Step 614: train/loss = 0.7234971523284912, train/raw-loss = 0.6675198078155518, train/logprobs = tensor([[-1.3036, -2.5207],
        [-0.7987, -0.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119549572467804
Epoch 0, Step 615: train/loss = 0.6157373189926147, train/raw-loss = 0.5661540031433105, train/logprobs = tensor([[-0.5673, -1.4417],
        [-0.5738, -0.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09916660189628601
Epoch 0, Step 616: train/loss = 0.4531428813934326, train/raw-loss = 0.3715885877609253, train/logprobs = tensor([[-1.0312, -2.6373],
        [-1.5936, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16310854256153107
Epoch 0, Step 617: train/loss = 0.36995434761047363, train/raw-loss = 0.2870446443557739, train/logprobs = tensor([[-0.8226, -2.8531],
        [-1.7584, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16581940650939941
Epoch 0, Step 618: train/loss = 0.5006625056266785, train/raw-loss = 0.44633036851882935, train/logprobs = tensor([[-0.9212, -2.2697],
        [-1.2023, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10866431891918182
Epoch 0, Step 619: train/loss = 0.649650514125824, train/raw-loss = 0.5943828821182251, train/logprobs = tensor([[-1.2006, -2.2585],
        [-0.9996, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11053524911403656
Epoch 0, Step 620: train/loss = 0.4898994565010071, train/raw-loss = 0.4343140423297882, train/logprobs = tensor([[-0.7470, -1.9933],
        [-1.2563, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11117079108953476
Epoch 0, Step 621: train/loss = 0.5309708118438721, train/raw-loss = 0.4589526653289795, train/logprobs = tensor([[-1.3480, -1.9039],
        [-1.6339, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14403635263442993
Epoch 0, Step 622: train/loss = 0.5418405532836914, train/raw-loss = 0.48551639914512634, train/logprobs = tensor([[-1.2682, -1.9456],
        [-1.7862, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11264824867248535
Epoch 0, Step 623: train/loss = 0.539716899394989, train/raw-loss = 0.4519972801208496, train/logprobs = tensor([[-0.7415, -1.3161],
        [-1.3056, -0.4635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17543919384479523
Epoch 0, Step 624: train/loss = 0.7273954749107361, train/raw-loss = 0.6615177989006042, train/logprobs = tensor([[-0.7878, -1.6548],
        [-0.7680, -1.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13175538182258606
Epoch 0, Step 625: train/loss = 0.421964168548584, train/raw-loss = 0.3345988094806671, train/logprobs = tensor([[-1.1056, -3.7483],
        [-1.9917, -1.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17473077774047852
Epoch 0, Step 626: train/loss = 0.601327657699585, train/raw-loss = 0.5379269123077393, train/logprobs = tensor([[-1.2223, -2.7107],
        [-1.1233, -1.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12680144608020782
Epoch 0, Step 627: train/loss = 0.5994035005569458, train/raw-loss = 0.5488245487213135, train/logprobs = tensor([[-0.6787, -1.0910],
        [-1.2733, -0.7078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10115786641836166
Epoch 0, Step 628: train/loss = 0.5283134579658508, train/raw-loss = 0.47164642810821533, train/logprobs = tensor([[-0.6449, -2.0437],
        [-0.6167, -0.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11333407461643219
Epoch 0, Step 629: train/loss = 0.6085894107818604, train/raw-loss = 0.5405843257904053, train/logprobs = tensor([[-1.2344, -1.7383],
        [-1.3750, -1.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13601015508174896
Epoch 0, Step 630: train/loss = 0.40620723366737366, train/raw-loss = 0.32498782873153687, train/logprobs = tensor([[-1.0840, -3.7439],
        [-1.7622, -1.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16243883967399597
Epoch 0, Step 631: train/loss = 0.45468494296073914, train/raw-loss = 0.39237359166145325, train/logprobs = tensor([[-0.6340, -2.7483],
        [-1.1897, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12462268769741058
Epoch 0, Step 632: train/loss = 0.6424257755279541, train/raw-loss = 0.5861803889274597, train/logprobs = tensor([[-0.7303, -1.4277],
        [-0.6426, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11249084770679474
Epoch 0, Step 633: train/loss = 0.6058907508850098, train/raw-loss = 0.5579482316970825, train/logprobs = tensor([[-0.6655, -1.5232],
        [-0.7578, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0958850085735321
Epoch 0, Step 634: train/loss = 0.5098016262054443, train/raw-loss = 0.4259314239025116, train/logprobs = tensor([[-0.6388, -2.0283],
        [-0.9186, -0.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16774040460586548
Epoch 0, Step 635: train/loss = 0.6482544541358948, train/raw-loss = 0.5841292142868042, train/logprobs = tensor([[-0.9079, -1.6097],
        [-0.5874, -0.5014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1282503455877304
Epoch 0, Step 636: train/loss = 0.49159517884254456, train/raw-loss = 0.42427194118499756, train/logprobs = tensor([[-0.7047, -2.9310],
        [-0.6899, -1.1386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1346464604139328
Epoch 0, Step 637: train/loss = 0.5777466893196106, train/raw-loss = 0.5159885883331299, train/logprobs = tensor([[-0.8341, -1.9947],
        [-1.1853, -0.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12351621687412262
Epoch 0, Step 638: train/loss = 0.555304765701294, train/raw-loss = 0.4833289384841919, train/logprobs = tensor([[-1.8582, -2.7007],
        [-1.8276, -1.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1439516246318817
Epoch 0, Step 639: train/loss = 0.5512983798980713, train/raw-loss = 0.4769347012042999, train/logprobs = tensor([[-0.8547, -1.4901],
        [-1.3425, -0.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1487273871898651
Epoch 0, Step 640: train/loss = 0.5734555125236511, train/raw-loss = 0.517585813999176, train/logprobs = tensor([[-0.7261, -2.2680],
        [-0.6921, -1.1678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1117393970489502
Epoch 0, Step 641: train/loss = 0.6190164089202881, train/raw-loss = 0.5665578842163086, train/logprobs = tensor([[-0.9696, -1.9328],
        [-0.8032, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049170196056366
Epoch 0, Step 642: train/loss = 0.688467800617218, train/raw-loss = 0.6282727718353271, train/logprobs = tensor([[-0.8445, -1.3128],
        [-0.5674, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12039002031087875
Epoch 0, Step 643: train/loss = 0.5426031351089478, train/raw-loss = 0.46686312556266785, train/logprobs = tensor([[-0.8842, -2.0746],
        [-1.2026, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514800637960434
Epoch 0, Step 644: train/loss = 0.5422317981719971, train/raw-loss = 0.4650689363479614, train/logprobs = tensor([[-0.9182, -1.9024],
        [-1.2700, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1543257236480713
Epoch 0, Step 645: train/loss = 0.7025732398033142, train/raw-loss = 0.6600728034973145, train/logprobs = tensor([[-1.0722, -1.3552],
        [-0.6066, -0.5417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500075340270996
Epoch 0, Step 646: train/loss = 0.5145671367645264, train/raw-loss = 0.44367891550064087, train/logprobs = tensor([[-0.7157, -1.7643],
        [-1.0460, -0.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14177650213241577
Epoch 0, Step 647: train/loss = 0.5772190093994141, train/raw-loss = 0.48127061128616333, train/logprobs = tensor([[-1.2062, -1.9498],
        [-1.3596, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19189684092998505
Epoch 0, Step 648: train/loss = 0.5447040796279907, train/raw-loss = 0.4847344160079956, train/logprobs = tensor([[-0.6016, -1.5302],
        [-0.7434, -0.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11993935704231262
Epoch 0, Step 649: train/loss = 0.6104777455329895, train/raw-loss = 0.5606322884559631, train/logprobs = tensor([[-0.6296, -1.7001],
        [-0.6957, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09969085454940796
Epoch 0, Step 650: train/loss = 0.5377434492111206, train/raw-loss = 0.46922048926353455, train/logprobs = tensor([[-1.0416, -3.4651],
        [-0.9810, -2.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370459794998169
Epoch 0, Step 651: train/loss = 0.55777907371521, train/raw-loss = 0.49905526638031006, train/logprobs = tensor([[-1.2395, -2.5601],
        [-1.4489, -1.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11744755506515503
Epoch 0, Step 652: train/loss = 0.39118674397468567, train/raw-loss = 0.32453787326812744, train/logprobs = tensor([[-1.0987, -4.0615],
        [-1.3471, -1.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329771161079407
Epoch 0, Step 653: train/loss = 0.4739569127559662, train/raw-loss = 0.4173712730407715, train/logprobs = tensor([[-0.6716, -1.9680],
        [-1.2956, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11317123472690582
Epoch 0, Step 654: train/loss = 0.6222822070121765, train/raw-loss = 0.5468236804008484, train/logprobs = tensor([[-0.8847, -1.6008],
        [-1.2594, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15091705322265625
Epoch 0, Step 655: train/loss = 0.467931866645813, train/raw-loss = 0.3921782970428467, train/logprobs = tensor([[-0.9615, -2.0110],
        [-1.7018, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15150712430477142
Epoch 0, Step 656: train/loss = 0.6365842819213867, train/raw-loss = 0.586972713470459, train/logprobs = tensor([[-0.6574, -1.2383],
        [-0.7361, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992230698466301
Epoch 0, Step 657: train/loss = 0.6406124830245972, train/raw-loss = 0.583905816078186, train/logprobs = tensor([[-1.2172, -1.4279],
        [-1.2377, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11341331154108047
Epoch 0, Step 658: train/loss = 0.4364998936653137, train/raw-loss = 0.368674635887146, train/logprobs = tensor([[-1.1003, -2.8075],
        [-1.4123, -0.6877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13565057516098022
Epoch 0, Step 659: train/loss = 0.4917241334915161, train/raw-loss = 0.4181984066963196, train/logprobs = tensor([[-0.8887, -1.7470],
        [-1.7003, -0.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14705151319503784
Epoch 0, Step 660: train/loss = 0.42036378383636475, train/raw-loss = 0.34423255920410156, train/logprobs = tensor([[-0.9601, -2.8596],
        [-1.5993, -0.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15226250886917114
Epoch 0, Step 661: train/loss = 0.3656059503555298, train/raw-loss = 0.2839363217353821, train/logprobs = tensor([[-1.6587, -3.5426],
        [-2.0210, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16333922743797302
Epoch 0, Step 662: train/loss = 0.534727156162262, train/raw-loss = 0.4679213762283325, train/logprobs = tensor([[-0.7011, -1.6413],
        [-1.1470, -0.7770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13361148536205292
Epoch 0, Step 663: train/loss = 0.5385997295379639, train/raw-loss = 0.46983829140663147, train/logprobs = tensor([[-1.1386, -1.6490],
        [-1.3660, -0.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137522891163826
Epoch 0, Step 664: train/loss = 0.46986091136932373, train/raw-loss = 0.3879789113998413, train/logprobs = tensor([[-1.0175, -3.2025],
        [-1.6683, -1.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16376397013664246
Epoch 0, Step 665: train/loss = 0.606540858745575, train/raw-loss = 0.54523766040802, train/logprobs = tensor([[-0.8556, -2.1501],
        [-1.0731, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260646373033524
Epoch 0, Step 666: train/loss = 0.5425597429275513, train/raw-loss = 0.4656284749507904, train/logprobs = tensor([[-1.2852, -2.1885],
        [-1.3608, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15386246144771576
Epoch 0, Step 667: train/loss = 0.5419846177101135, train/raw-loss = 0.4683688282966614, train/logprobs = tensor([[-1.2903, -1.4297],
        [-1.9123, -0.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472315639257431
Epoch 0, Step 668: train/loss = 0.6339861750602722, train/raw-loss = 0.5697360634803772, train/logprobs = tensor([[-1.1377, -2.3271],
        [-1.0650, -0.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12850016355514526
Epoch 0, Step 669: train/loss = 0.6308816075325012, train/raw-loss = 0.584542989730835, train/logprobs = tensor([[-1.1084, -1.7939],
        [-0.8973, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267722815275192
Epoch 0, Step 670: train/loss = 0.46222227811813354, train/raw-loss = 0.39082565903663635, train/logprobs = tensor([[-0.8358, -2.5920],
        [-1.1712, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427931785583496
Epoch 0, Step 671: train/loss = 0.6164414286613464, train/raw-loss = 0.5517995953559875, train/logprobs = tensor([[-0.8776, -1.0138],
        [-1.3228, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12928374111652374
Epoch 0, Step 672: train/loss = 0.42435744404792786, train/raw-loss = 0.3313908576965332, train/logprobs = tensor([[-1.4114, -4.1860],
        [-2.0511, -1.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1859331876039505
Epoch 0, Step 673: train/loss = 0.6381048560142517, train/raw-loss = 0.5900630354881287, train/logprobs = tensor([[-0.8659, -1.8136],
        [-0.7846, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09608377516269684
Epoch 0, Step 674: train/loss = 0.45299825072288513, train/raw-loss = 0.3696175813674927, train/logprobs = tensor([[-0.7332, -2.8353],
        [-0.9116, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16676130890846252
Epoch 0, Step 675: train/loss = 0.7498629093170166, train/raw-loss = 0.6777974963188171, train/logprobs = tensor([[-0.7639, -0.9386],
        [-1.3026, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441308706998825
Epoch 0, Step 676: train/loss = 0.3009106516838074, train/raw-loss = 0.2126806378364563, train/logprobs = tensor([[-0.9999, -4.0383],
        [-2.2144, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17646004259586334
Epoch 0, Step 677: train/loss = 0.518641471862793, train/raw-loss = 0.43656212091445923, train/logprobs = tensor([[-0.5571, -1.7096],
        [-1.1147, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1641586869955063
Epoch 0, Step 678: train/loss = 0.5362024307250977, train/raw-loss = 0.4675178527832031, train/logprobs = tensor([[-1.5740, -2.9607],
        [-1.5528, -0.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1373690962791443
Epoch 0, Step 679: train/loss = 0.4457027018070221, train/raw-loss = 0.37398380041122437, train/logprobs = tensor([[-1.0076, -3.0662],
        [-1.4288, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14343777298927307
Epoch 0, Step 680: train/loss = 0.6319074630737305, train/raw-loss = 0.5511441230773926, train/logprobs = tensor([[-1.3894, -3.1488],
        [-1.4150, -1.2154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16152672469615936
Epoch 0, Step 681: train/loss = 0.6261485815048218, train/raw-loss = 0.5715736746788025, train/logprobs = tensor([[-0.9578, -2.1306],
        [-0.6722, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10914985835552216
Epoch 0, Step 682: train/loss = 0.36767178773880005, train/raw-loss = 0.28130730986595154, train/logprobs = tensor([[-1.0871, -4.0559],
        [-1.8912, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727289855480194
Epoch 0, Step 683: train/loss = 0.49964359402656555, train/raw-loss = 0.41750210523605347, train/logprobs = tensor([[-0.9251, -2.1392],
        [-1.5349, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16428296267986298
Epoch 0, Step 684: train/loss = 0.4427163004875183, train/raw-loss = 0.35851815342903137, train/logprobs = tensor([[-1.1559, -2.5038],
        [-1.6022, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1683962643146515
Epoch 0, Step 685: train/loss = 0.495897114276886, train/raw-loss = 0.43792688846588135, train/logprobs = tensor([[-0.7435, -2.1274],
        [-0.8534, -0.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11594042181968689
Epoch 0, Step 686: train/loss = 0.7069226503372192, train/raw-loss = 0.6690065264701843, train/logprobs = tensor([[-0.5099, -0.5784],
        [-0.4537, -0.4183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07583221793174744
Epoch 0, Step 687: train/loss = 0.4069405198097229, train/raw-loss = 0.30689650774002075, train/logprobs = tensor([[-1.2217, -3.0934],
        [-2.3412, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000880241394043
Epoch 0, Step 688: train/loss = 0.5918512344360352, train/raw-loss = 0.5275902152061462, train/logprobs = tensor([[-0.9793, -1.9394],
        [-1.1066, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12852200865745544
Epoch 0, Step 689: train/loss = 0.5532978773117065, train/raw-loss = 0.5005953907966614, train/logprobs = tensor([[-0.5748, -1.7992],
        [-0.7057, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10540498793125153
Epoch 0, Step 690: train/loss = 0.5334927439689636, train/raw-loss = 0.47424542903900146, train/logprobs = tensor([[-0.7551, -1.5939],
        [-1.2245, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11849461495876312
Epoch 0, Step 691: train/loss = 0.6619810461997986, train/raw-loss = 0.6099008321762085, train/logprobs = tensor([[-0.8256, -0.8551],
        [-1.1821, -0.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10416051745414734
Epoch 0, Step 692: train/loss = 0.6703882217407227, train/raw-loss = 0.6123459339141846, train/logprobs = tensor([[-1.0512, -1.6544],
        [-0.9285, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11608458310365677
Epoch 0, Step 693: train/loss = 0.7502479553222656, train/raw-loss = 0.684597373008728, train/logprobs = tensor([[-1.2717, -0.9926],
        [-1.0425, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13130131363868713
Epoch 0, Step 694: train/loss = 0.5288160443305969, train/raw-loss = 0.46969321370124817, train/logprobs = tensor([[-0.9393, -2.0296],
        [-1.2992, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11824561655521393
Epoch 0, Step 695: train/loss = 0.4490184485912323, train/raw-loss = 0.37172606587409973, train/logprobs = tensor([[-0.9588, -3.4540],
        [-1.2740, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15458476543426514
Epoch 0, Step 696: train/loss = 0.7070851922035217, train/raw-loss = 0.6616289615631104, train/logprobs = tensor([[-0.4727, -0.8244],
        [-0.4382, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09091241657733917
Epoch 0, Step 697: train/loss = 0.44556862115859985, train/raw-loss = 0.36146998405456543, train/logprobs = tensor([[-0.9198, -3.0176],
        [-1.3777, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16819721460342407
Epoch 0, Step 698: train/loss = 0.6796085834503174, train/raw-loss = 0.61809903383255, train/logprobs = tensor([[-1.1167, -1.9922],
        [-0.8395, -0.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12301908433437347
Epoch 0, Step 699: train/loss = 0.4818331003189087, train/raw-loss = 0.4181228578090668, train/logprobs = tensor([[-0.9941, -3.2625],
        [-1.4642, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12742049992084503
Epoch 0, Step 700: train/loss = 0.6231260895729065, train/raw-loss = 0.5709252953529358, train/logprobs = tensor([[-0.9741, -1.6351],
        [-0.9521, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10440155863761902
Epoch 0, Step 701: train/loss = 0.4932410418987274, train/raw-loss = 0.4150291979312897, train/logprobs = tensor([[-1.1760, -2.4010],
        [-1.5314, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1564236581325531
Epoch 0, Step 702: train/loss = 0.599855899810791, train/raw-loss = 0.5463179349899292, train/logprobs = tensor([[-0.9799, -1.3405],
        [-1.1722, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707591474056244
Epoch 0, Step 703: train/loss = 0.5361154675483704, train/raw-loss = 0.45800259709358215, train/logprobs = tensor([[-1.2884, -1.7707],
        [-2.1121, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562257558107376
Epoch 0, Step 704: train/loss = 0.5934110879898071, train/raw-loss = 0.5300257205963135, train/logprobs = tensor([[-0.7494, -1.4112],
        [-1.0679, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12677070498466492
Epoch 0, Step 705: train/loss = 0.6709213852882385, train/raw-loss = 0.6003475189208984, train/logprobs = tensor([[-1.8066, -3.4625],
        [-1.0947, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411476582288742
Epoch 0, Step 706: train/loss = 0.5252465605735779, train/raw-loss = 0.4508579671382904, train/logprobs = tensor([[-0.8691, -3.3531],
        [-1.3829, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14877721667289734
Epoch 0, Step 707: train/loss = 0.5167944431304932, train/raw-loss = 0.4546063542366028, train/logprobs = tensor([[-0.7005, -1.6943],
        [-1.0312, -0.7674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12437610328197479
Epoch 0, Step 708: train/loss = 0.5553051829338074, train/raw-loss = 0.47423335909843445, train/logprobs = tensor([[-0.6522, -1.5242],
        [-1.2693, -0.6307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16214358806610107
Epoch 0, Step 709: train/loss = 0.526428759098053, train/raw-loss = 0.47208791971206665, train/logprobs = tensor([[-0.7792, -2.3618],
        [-0.7721, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10868169367313385
Epoch 0, Step 710: train/loss = 0.6261246204376221, train/raw-loss = 0.5711178183555603, train/logprobs = tensor([[-0.7759, -1.3791],
        [-0.6995, -0.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11001370847225189
Epoch 0, Step 711: train/loss = 0.5234264731407166, train/raw-loss = 0.45043134689331055, train/logprobs = tensor([[-1.4053, -3.4854],
        [-1.2827, -0.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.145990252494812
Epoch 0, Step 712: train/loss = 0.5374454259872437, train/raw-loss = 0.4626465439796448, train/logprobs = tensor([[-0.8491, -2.8494],
        [-0.6633, -0.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14959776401519775
Epoch 0, Step 713: train/loss = 0.5079840421676636, train/raw-loss = 0.4350537657737732, train/logprobs = tensor([[-0.8102, -2.5056],
        [-1.0622, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14586056768894196
Epoch 0, Step 714: train/loss = 0.4898254871368408, train/raw-loss = 0.4247533977031708, train/logprobs = tensor([[-0.9526, -2.9012],
        [-0.9212, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13014420866966248
Epoch 0, Step 715: train/loss = 0.6709463596343994, train/raw-loss = 0.5919948816299438, train/logprobs = tensor([[-1.6720, -2.0471],
        [-1.4647, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15790298581123352
Epoch 0, Step 716: train/loss = 0.3955540657043457, train/raw-loss = 0.3008447289466858, train/logprobs = tensor([[-0.8229, -2.9233],
        [-1.7689, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18941867351531982
Epoch 0, Step 717: train/loss = 0.3921589255332947, train/raw-loss = 0.3183673024177551, train/logprobs = tensor([[-1.0368, -3.0324],
        [-1.6585, -0.9888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1475832760334015
Epoch 0, Step 718: train/loss = 0.43114709854125977, train/raw-loss = 0.35384076833724976, train/logprobs = tensor([[-0.9799, -2.7378],
        [-1.9153, -0.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546126753091812
Epoch 0, Step 719: train/loss = 0.6023913025856018, train/raw-loss = 0.5419172048568726, train/logprobs = tensor([[-0.8306, -1.2917],
        [-1.1745, -0.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12094822525978088
Epoch 0, Step 720: train/loss = 0.562339186668396, train/raw-loss = 0.5099042057991028, train/logprobs = tensor([[-0.6379, -2.0275],
        [-0.5966, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10486995428800583
Epoch 0, Step 721: train/loss = 0.533855676651001, train/raw-loss = 0.4605293571949005, train/logprobs = tensor([[-1.0432, -2.3263],
        [-1.1065, -0.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14665266871452332
Epoch 0, Step 722: train/loss = 0.5218173265457153, train/raw-loss = 0.4532279372215271, train/logprobs = tensor([[-1.1142, -1.8924],
        [-1.4742, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13717883825302124
Epoch 0, Step 723: train/loss = 0.6649988889694214, train/raw-loss = 0.6160295009613037, train/logprobs = tensor([[-0.5716, -0.9835],
        [-0.7369, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0979389026761055
Epoch 0, Step 724: train/loss = 0.47888073325157166, train/raw-loss = 0.40661904215812683, train/logprobs = tensor([[-1.0505, -2.3517],
        [-1.6012, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1445232629776001
Epoch 0, Step 725: train/loss = 0.4439147710800171, train/raw-loss = 0.3573338985443115, train/logprobs = tensor([[-1.1178, -3.0093],
        [-1.6166, -1.0802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17316171526908875
Epoch 0, Step 726: train/loss = 0.6575882434844971, train/raw-loss = 0.580225944519043, train/logprobs = tensor([[-1.0646, -1.5908],
        [-1.1146, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547246128320694
Epoch 0, Step 727: train/loss = 0.41193926334381104, train/raw-loss = 0.3102092742919922, train/logprobs = tensor([[-0.6413, -3.0231],
        [-1.4797, -0.9612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20346002280712128
Epoch 0, Step 728: train/loss = 0.28833383321762085, train/raw-loss = 0.1896253377199173, train/logprobs = tensor([[-1.5008, -6.2677],
        [-2.4297, -1.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1974170207977295
Epoch 0, Step 729: train/loss = 0.5508313179016113, train/raw-loss = 0.47852909564971924, train/logprobs = tensor([[-0.5955, -1.6639],
        [-0.9187, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1446043848991394
Epoch 0, Step 730: train/loss = 0.28889623284339905, train/raw-loss = 0.2120606154203415, train/logprobs = tensor([[-1.2487, -6.2097],
        [-1.8194, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1536712348461151
Epoch 0, Step 731: train/loss = 0.6147581338882446, train/raw-loss = 0.5361592769622803, train/logprobs = tensor([[-1.4532, -2.1365],
        [-1.3312, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1571977287530899
Epoch 0, Step 732: train/loss = 0.4196881055831909, train/raw-loss = 0.3428890109062195, train/logprobs = tensor([[-0.7478, -3.0369],
        [-0.9274, -0.6659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1535980999469757
Epoch 0, Step 733: train/loss = 0.5721630454063416, train/raw-loss = 0.5244094729423523, train/logprobs = tensor([[-1.4903, -2.7542],
        [-1.4229, -1.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550722688436508
Epoch 0, Step 734: train/loss = 0.4414687156677246, train/raw-loss = 0.3556811213493347, train/logprobs = tensor([[-0.9315, -2.0498],
        [-1.6706, -0.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17157524824142456
Epoch 0, Step 735: train/loss = 0.47185853123664856, train/raw-loss = 0.38665637373924255, train/logprobs = tensor([[-0.7801, -3.0073],
        [-0.8306, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17040430009365082
Epoch 0, Step 736: train/loss = 0.4931677579879761, train/raw-loss = 0.4153589606285095, train/logprobs = tensor([[-1.0182, -2.4586],
        [-1.3735, -1.0436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15561765432357788
Epoch 0, Step 737: train/loss = 0.6261816024780273, train/raw-loss = 0.5266485214233398, train/logprobs = tensor([[-2.3133, -6.2315],
        [-1.4123, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1990661472082138
Epoch 0, Step 738: train/loss = 0.5982792377471924, train/raw-loss = 0.5252203345298767, train/logprobs = tensor([[-0.5514, -1.3664],
        [-1.2273, -0.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14611777663230896
Epoch 0, Step 739: train/loss = 0.6041706204414368, train/raw-loss = 0.5458122491836548, train/logprobs = tensor([[-0.8585, -2.1502],
        [-0.7683, -0.8972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11671684682369232
Epoch 0, Step 740: train/loss = 0.5173142552375793, train/raw-loss = 0.45395350456237793, train/logprobs = tensor([[-0.6033, -1.9787],
        [-0.9583, -0.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12672153115272522
Epoch 0, Step 741: train/loss = 0.7086025476455688, train/raw-loss = 0.6425172090530396, train/logprobs = tensor([[-1.6643, -2.9671],
        [-1.0363, -0.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321706771850586
Epoch 0, Step 742: train/loss = 0.6207714080810547, train/raw-loss = 0.5545952320098877, train/logprobs = tensor([[-0.8619, -1.9911],
        [-0.7938, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13235239684581757
Epoch 0, Step 743: train/loss = 0.6881877779960632, train/raw-loss = 0.6215195655822754, train/logprobs = tensor([[-0.6681, -1.0000],
        [-0.6623, -0.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1333363801240921
Epoch 0, Step 744: train/loss = 0.495836079120636, train/raw-loss = 0.42998284101486206, train/logprobs = tensor([[-0.8330, -1.9549],
        [-1.4274, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13170649111270905
Epoch 0, Step 745: train/loss = 0.7181599140167236, train/raw-loss = 0.6654924750328064, train/logprobs = tensor([[-1.1051, -0.8847],
        [-0.9375, -0.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1053348183631897
Epoch 0, Step 746: train/loss = 0.4318615198135376, train/raw-loss = 0.36819544434547424, train/logprobs = tensor([[-0.7530, -3.3248],
        [-0.8743, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273321509361267
Epoch 0, Step 747: train/loss = 0.43600890040397644, train/raw-loss = 0.3622018098831177, train/logprobs = tensor([[-1.0036, -2.8523],
        [-1.8415, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14761418104171753
Epoch 0, Step 748: train/loss = 0.5032143592834473, train/raw-loss = 0.44232138991355896, train/logprobs = tensor([[-0.8191, -1.9771],
        [-0.9933, -0.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121785968542099
Epoch 0, Step 749: train/loss = 0.6065588593482971, train/raw-loss = 0.5428449511528015, train/logprobs = tensor([[-1.1839, -1.4749],
        [-1.4264, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12742775678634644
Epoch 0, Step 750: train/loss = 0.4617009162902832, train/raw-loss = 0.3784254193305969, train/logprobs = tensor([[-1.1085, -2.5833],
        [-1.3656, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16655100882053375
Epoch 0, Step 751: train/loss = 0.6036341190338135, train/raw-loss = 0.5540424585342407, train/logprobs = tensor([[-0.8922, -2.6697],
        [-0.8751, -1.7344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09918337315320969
Epoch 0, Step 752: train/loss = 0.5026952028274536, train/raw-loss = 0.4338858723640442, train/logprobs = tensor([[-0.8306, -2.3628],
        [-0.9368, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13761863112449646
Epoch 0, Step 753: train/loss = 0.4879053831100464, train/raw-loss = 0.4128517508506775, train/logprobs = tensor([[-0.8233, -2.9866],
        [-1.1442, -1.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501072198152542
Epoch 0, Step 754: train/loss = 0.3966134190559387, train/raw-loss = 0.3372119069099426, train/logprobs = tensor([[-0.8935, -4.4740],
        [-0.8278, -1.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11880306899547577
Epoch 0, Step 755: train/loss = 0.5018535256385803, train/raw-loss = 0.40685075521469116, train/logprobs = tensor([[-0.7420, -1.9826],
        [-1.8087, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1900055855512619
Epoch 0, Step 756: train/loss = 0.5686088800430298, train/raw-loss = 0.4900757074356079, train/logprobs = tensor([[-1.4651, -1.9261],
        [-1.6277, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15706636011600494
Epoch 0, Step 757: train/loss = 0.5184670090675354, train/raw-loss = 0.43723052740097046, train/logprobs = tensor([[-1.4364, -2.9777],
        [-2.1362, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1624729037284851
Epoch 0, Step 758: train/loss = 0.5992669463157654, train/raw-loss = 0.5512286424636841, train/logprobs = tensor([[-0.8950, -2.0035],
        [-0.9404, -1.1021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09607655555009842
Epoch 0, Step 759: train/loss = 0.5594229698181152, train/raw-loss = 0.4676694869995117, train/logprobs = tensor([[-1.0675, -2.3364],
        [-1.5622, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18350690603256226
Epoch 0, Step 760: train/loss = 0.6314222812652588, train/raw-loss = 0.5716444253921509, train/logprobs = tensor([[-0.9074, -1.2423],
        [-1.0054, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11955569684505463
Epoch 0, Step 761: train/loss = 0.4064159393310547, train/raw-loss = 0.32117369771003723, train/logprobs = tensor([[-0.8032, -4.3356],
        [-1.5800, -1.5440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1704844832420349
Epoch 0, Step 762: train/loss = 0.4419582784175873, train/raw-loss = 0.3577512204647064, train/logprobs = tensor([[-0.9187, -3.6224],
        [-1.2166, -0.7800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1684141457080841
Epoch 0, Step 763: train/loss = 0.45992010831832886, train/raw-loss = 0.38734230399131775, train/logprobs = tensor([[-0.8301, -3.4331],
        [-1.2378, -1.6085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1451556384563446
Epoch 0, Step 764: train/loss = 0.4347892701625824, train/raw-loss = 0.34622615575790405, train/logprobs = tensor([[-1.9843, -4.2082],
        [-2.2068, -1.4179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771261990070343
Epoch 0, Step 765: train/loss = 0.6702170372009277, train/raw-loss = 0.6272818446159363, train/logprobs = tensor([[-1.0980, -2.3890],
        [-1.0344, -1.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08587034046649933
Epoch 0, Step 766: train/loss = 0.4514511823654175, train/raw-loss = 0.3822707533836365, train/logprobs = tensor([[-0.8258, -2.8425],
        [-1.0906, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138360857963562
Epoch 0, Step 767: train/loss = 0.6549439430236816, train/raw-loss = 0.5812649726867676, train/logprobs = tensor([[-1.9495, -5.2530],
        [-0.9528, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1473579704761505
Epoch 0, Step 768: train/loss = 0.5370006561279297, train/raw-loss = 0.4564184546470642, train/logprobs = tensor([[-0.9059, -2.7614],
        [-0.7890, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16116441786289215
Epoch 0, Step 769: train/loss = 0.49593284726142883, train/raw-loss = 0.433635950088501, train/logprobs = tensor([[-0.7006, -2.3792],
        [-0.9332, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12459374964237213
Epoch 0, Step 770: train/loss = 0.5118306279182434, train/raw-loss = 0.45092707872390747, train/logprobs = tensor([[-0.6007, -2.2906],
        [-0.9479, -0.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12180718034505844
Epoch 0, Step 771: train/loss = 0.4836745858192444, train/raw-loss = 0.4137536883354187, train/logprobs = tensor([[-0.9273, -3.3991],
        [-1.0152, -0.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13984178006649017
Epoch 0, Step 772: train/loss = 0.5930761098861694, train/raw-loss = 0.5092887878417969, train/logprobs = tensor([[-1.1016, -0.9579],
        [-1.5645, -0.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16757461428642273
Epoch 0, Step 773: train/loss = 0.48784783482551575, train/raw-loss = 0.4004698395729065, train/logprobs = tensor([[-2.1433, -4.8139],
        [-2.2007, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17475606501102448
Epoch 0, Step 774: train/loss = 0.36877113580703735, train/raw-loss = 0.2784585654735565, train/logprobs = tensor([[-0.7803, -4.1661],
        [-1.4393, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18062517046928406
Epoch 0, Step 775: train/loss = 0.5754917860031128, train/raw-loss = 0.5138124227523804, train/logprobs = tensor([[-0.8992, -2.0232],
        [-0.8340, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12335870414972305
Epoch 0, Step 776: train/loss = 0.4537770748138428, train/raw-loss = 0.3769916594028473, train/logprobs = tensor([[-1.1676, -3.8250],
        [-1.8415, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15357090532779694
Epoch 0, Step 777: train/loss = 0.5779168605804443, train/raw-loss = 0.48663073778152466, train/logprobs = tensor([[-1.3840, -1.4539],
        [-2.0361, -0.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18257221579551697
Epoch 0, Step 778: train/loss = 0.5262116193771362, train/raw-loss = 0.4608500897884369, train/logprobs = tensor([[-0.7345, -2.3469],
        [-0.7073, -0.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13072310388088226
Epoch 0, Step 779: train/loss = 0.5027241110801697, train/raw-loss = 0.42388489842414856, train/logprobs = tensor([[-1.3689, -2.9333],
        [-1.4969, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15767832100391388
Epoch 0, Step 780: train/loss = 0.48579081892967224, train/raw-loss = 0.42507416009902954, train/logprobs = tensor([[-0.8017, -3.1318],
        [-0.8683, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12143337726593018
Epoch 0, Step 781: train/loss = 0.47074902057647705, train/raw-loss = 0.38962677121162415, train/logprobs = tensor([[-1.1474, -2.5285],
        [-1.7515, -0.7490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16224446892738342
Epoch 0, Step 782: train/loss = 0.4947145879268646, train/raw-loss = 0.4274996221065521, train/logprobs = tensor([[-0.8465, -2.4346],
        [-1.2305, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344299167394638
Epoch 0, Step 783: train/loss = 0.36093223094940186, train/raw-loss = 0.27660197019577026, train/logprobs = tensor([[-0.9149, -3.1267],
        [-1.4166, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16866055130958557
Epoch 0, Step 784: train/loss = 0.541511595249176, train/raw-loss = 0.48487621545791626, train/logprobs = tensor([[-0.5029, -2.0307],
        [-0.5539, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11327079683542252
Epoch 0, Step 785: train/loss = 0.6840164661407471, train/raw-loss = 0.620611310005188, train/logprobs = tensor([[-1.5406, -2.9521],
        [-0.8708, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12681031227111816
Epoch 0, Step 786: train/loss = 0.5774492621421814, train/raw-loss = 0.5087257027626038, train/logprobs = tensor([[-1.4647, -2.1174],
        [-1.6366, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13744714856147766
Epoch 0, Step 787: train/loss = 0.5290212035179138, train/raw-loss = 0.44263404607772827, train/logprobs = tensor([[-1.1290, -2.8249],
        [-1.5725, -1.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727743297815323
Epoch 0, Step 788: train/loss = 0.46798545122146606, train/raw-loss = 0.3951367735862732, train/logprobs = tensor([[-1.0074, -3.9039],
        [-0.6728, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14569726586341858
Epoch 0, Step 789: train/loss = 0.30285677313804626, train/raw-loss = 0.17742018401622772, train/logprobs = tensor([[-1.1534, -3.9199],
        [-2.4194, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508732080459595
Epoch 0, Step 790: train/loss = 0.5287706851959229, train/raw-loss = 0.45330122113227844, train/logprobs = tensor([[-1.2084, -3.2150],
        [-1.2662, -0.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1509389579296112
Epoch 0, Step 791: train/loss = 0.5681387186050415, train/raw-loss = 0.5162882804870605, train/logprobs = tensor([[-0.5503, -2.5213],
        [-0.5624, -1.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1037009209394455
Epoch 0, Step 792: train/loss = 0.44415467977523804, train/raw-loss = 0.3668634593486786, train/logprobs = tensor([[-1.3123, -3.9069],
        [-2.1455, -1.1887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15458238124847412
Epoch 0, Step 793: train/loss = 0.38041627407073975, train/raw-loss = 0.2973092794418335, train/logprobs = tensor([[-0.7234, -3.2034],
        [-1.3714, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662140190601349
Epoch 0, Step 794: train/loss = 0.5231170654296875, train/raw-loss = 0.45890602469444275, train/logprobs = tensor([[-0.6285, -2.1124],
        [-0.8367, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12842200696468353
Epoch 0, Step 795: train/loss = 0.6235406398773193, train/raw-loss = 0.552802324295044, train/logprobs = tensor([[-1.6586, -3.3202],
        [-1.5681, -1.1823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14147667586803436
Epoch 0, Step 796: train/loss = 0.41251862049102783, train/raw-loss = 0.33553361892700195, train/logprobs = tensor([[-0.7386, -3.6360],
        [-1.2623, -1.4482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15397000312805176
Epoch 0, Step 797: train/loss = 0.44498372077941895, train/raw-loss = 0.3787326216697693, train/logprobs = tensor([[-1.1140, -3.0727],
        [-1.5556, -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1325022280216217
Epoch 0, Step 798: train/loss = 0.6385543346405029, train/raw-loss = 0.5857992768287659, train/logprobs = tensor([[-0.5320, -1.2117],
        [-0.5023, -0.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551020503044128
Epoch 0, Step 799: train/loss = 0.4922306537628174, train/raw-loss = 0.42827099561691284, train/logprobs = tensor([[-0.5915, -2.9346],
        [-0.6993, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279192566871643
Epoch 0, Step 800: train/loss = 0.4842350482940674, train/raw-loss = 0.4122106730937958, train/logprobs = tensor([[-1.0482, -3.1045],
        [-2.1147, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14404866099357605
Epoch 0, Step 801: train/loss = 0.596627950668335, train/raw-loss = 0.5320609211921692, train/logprobs = tensor([[-0.8774, -2.3676],
        [-0.7518, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12913410365581512
Epoch 0, Step 802: train/loss = 0.4431724548339844, train/raw-loss = 0.3523624837398529, train/logprobs = tensor([[-1.3148, -2.8869],
        [-1.8790, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18161997199058533
Epoch 0, Step 803: train/loss = 0.6199276447296143, train/raw-loss = 0.5779856443405151, train/logprobs = tensor([[-0.4191, -1.2895],
        [-0.5568, -0.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08388388156890869
Epoch 0, Step 804: train/loss = 0.4417805075645447, train/raw-loss = 0.37712404131889343, train/logprobs = tensor([[-0.6663, -3.4150],
        [-0.8064, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293129324913025
Epoch 0, Step 805: train/loss = 0.5262986421585083, train/raw-loss = 0.462322860956192, train/logprobs = tensor([[-0.5295, -2.5976],
        [-0.6922, -0.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279515027999878
Epoch 0, Step 806: train/loss = 0.4445455074310303, train/raw-loss = 0.3521856367588043, train/logprobs = tensor([[-0.9561, -2.7407],
        [-1.6529, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1847197413444519
Epoch 0, Step 807: train/loss = 0.5653044581413269, train/raw-loss = 0.4735914170742035, train/logprobs = tensor([[-1.7544, -3.2496],
        [-1.8400, -1.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18342605233192444
Epoch 0, Step 808: train/loss = 0.4129016399383545, train/raw-loss = 0.32824134826660156, train/logprobs = tensor([[-1.1068, -4.1265],
        [-1.6937, -1.2189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16932058334350586
Epoch 0, Step 809: train/loss = 0.5359528064727783, train/raw-loss = 0.4653216600418091, train/logprobs = tensor([[-0.7960, -3.7127],
        [-1.1042, -1.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14126235246658325
Epoch 0, Step 810: train/loss = 0.4568873643875122, train/raw-loss = 0.38237154483795166, train/logprobs = tensor([[-1.2461, -3.2138],
        [-1.3260, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14903157949447632
Epoch 0, Step 811: train/loss = 0.5575027465820312, train/raw-loss = 0.4924522340297699, train/logprobs = tensor([[-0.6291, -1.9809],
        [-0.8200, -0.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1301010102033615
Epoch 0, Step 812: train/loss = 0.6281273365020752, train/raw-loss = 0.5411510467529297, train/logprobs = tensor([[-1.5138, -2.2003],
        [-1.5572, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17395254969596863
Epoch 0, Step 813: train/loss = 0.6400859355926514, train/raw-loss = 0.5619725584983826, train/logprobs = tensor([[-1.4882, -1.7589],
        [-1.5869, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15622679889202118
Epoch 0, Step 814: train/loss = 0.3804436922073364, train/raw-loss = 0.2955796718597412, train/logprobs = tensor([[-1.2556, -3.3893],
        [-2.2737, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16972795128822327
Epoch 0, Step 815: train/loss = 0.42122358083724976, train/raw-loss = 0.33633118867874146, train/logprobs = tensor([[-0.7255, -3.2096],
        [-1.3436, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16978470981121063
Epoch 0, Step 816: train/loss = 0.5300179719924927, train/raw-loss = 0.47231703996658325, train/logprobs = tensor([[-0.7609, -2.1532],
        [-0.9757, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11540187150239944
Epoch 0, Step 817: train/loss = 0.5521535873413086, train/raw-loss = 0.49038487672805786, train/logprobs = tensor([[-0.8702, -2.3181],
        [-1.0488, -1.1390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12353740632534027
Epoch 0, Step 818: train/loss = 0.5339758396148682, train/raw-loss = 0.46210354566574097, train/logprobs = tensor([[-0.9842, -2.7256],
        [-1.1530, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14374464750289917
Epoch 0, Step 819: train/loss = 0.5471491813659668, train/raw-loss = 0.4798990786075592, train/logprobs = tensor([[-0.8045, -1.9040],
        [-0.6979, -0.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13450020551681519
Epoch 0, Step 820: train/loss = 0.6171372532844543, train/raw-loss = 0.5626141428947449, train/logprobs = tensor([[-0.6722, -1.3221],
        [-0.7728, -0.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10904623568058014
Epoch 0, Step 821: train/loss = 0.5364543199539185, train/raw-loss = 0.48304644227027893, train/logprobs = tensor([[-0.7541, -1.8345],
        [-0.8793, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10681578516960144
Epoch 0, Step 822: train/loss = 0.4067233204841614, train/raw-loss = 0.3376867175102234, train/logprobs = tensor([[-0.9961, -3.9618],
        [-1.1887, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380731761455536
Epoch 0, Step 823: train/loss = 0.5504521131515503, train/raw-loss = 0.4799329340457916, train/logprobs = tensor([[-1.0024, -2.4512],
        [-1.0378, -0.9181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14103835821151733
Epoch 0, Step 824: train/loss = 0.45502766966819763, train/raw-loss = 0.38170942664146423, train/logprobs = tensor([[-0.9490, -4.5343],
        [-1.4404, -1.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14663644134998322
Epoch 0, Step 825: train/loss = 0.4041990637779236, train/raw-loss = 0.3197689652442932, train/logprobs = tensor([[-1.0376, -4.6298],
        [-1.6995, -1.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16886018216609955
Epoch 0, Step 826: train/loss = 0.45601534843444824, train/raw-loss = 0.38536152243614197, train/logprobs = tensor([[-0.7146, -2.7091],
        [-1.1110, -0.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14130771160125732
Epoch 0, Step 827: train/loss = 0.3574577569961548, train/raw-loss = 0.27473947405815125, train/logprobs = tensor([[-1.1982, -3.4756],
        [-2.0731, -0.7938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1654365509748459
Epoch 0, Step 828: train/loss = 0.4162741005420685, train/raw-loss = 0.33425527811050415, train/logprobs = tensor([[-1.1619, -2.1221],
        [-1.9737, -0.5555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16403767466545105
Epoch 0, Step 829: train/loss = 0.48941919207572937, train/raw-loss = 0.41168490052223206, train/logprobs = tensor([[-1.2846, -3.4415],
        [-1.3628, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15546853840351105
Epoch 0, Step 830: train/loss = 0.5146235823631287, train/raw-loss = 0.44821831583976746, train/logprobs = tensor([[-0.5646, -2.6890],
        [-0.7779, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328105628490448
Epoch 0, Step 831: train/loss = 0.6142393350601196, train/raw-loss = 0.5282689929008484, train/logprobs = tensor([[-1.4428, -1.9257],
        [-1.5810, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719406545162201
Epoch 0, Step 832: train/loss = 0.4566206932067871, train/raw-loss = 0.3791850209236145, train/logprobs = tensor([[-2.0022, -5.1279],
        [-2.4854, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1548713743686676
Epoch 0, Step 833: train/loss = 0.40784040093421936, train/raw-loss = 0.32557010650634766, train/logprobs = tensor([[-0.8119, -4.2325],
        [-1.0328, -0.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645406186580658
Epoch 0, Step 834: train/loss = 0.561850368976593, train/raw-loss = 0.5077071189880371, train/logprobs = tensor([[-0.7061, -1.8105],
        [-0.9954, -0.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10828649997711182
Epoch 0, Step 835: train/loss = 0.4941142201423645, train/raw-loss = 0.4285057485103607, train/logprobs = tensor([[-0.7994, -3.4757],
        [-0.7313, -1.4565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13121695816516876
Epoch 0, Step 836: train/loss = 0.5326066613197327, train/raw-loss = 0.4526784420013428, train/logprobs = tensor([[-1.0646, -3.8437],
        [-1.6604, -1.4162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15985645353794098
Epoch 0, Step 837: train/loss = 0.6617699265480042, train/raw-loss = 0.6148934364318848, train/logprobs = tensor([[-1.5809, -2.1700],
        [-1.5390, -1.6868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09375309944152832
Epoch 0, Step 838: train/loss = 0.5690249800682068, train/raw-loss = 0.49980470538139343, train/logprobs = tensor([[-0.8338, -1.4719],
        [-1.1935, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1384405791759491
Epoch 0, Step 839: train/loss = 0.43920791149139404, train/raw-loss = 0.3595908284187317, train/logprobs = tensor([[-1.7038, -3.6291],
        [-2.5071, -1.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15923413634300232
Epoch 0, Step 840: train/loss = 0.447450190782547, train/raw-loss = 0.36223646998405457, train/logprobs = tensor([[-1.5058, -3.8687],
        [-1.8959, -1.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17042742669582367
Epoch 0, Step 841: train/loss = 0.5595256090164185, train/raw-loss = 0.5052557587623596, train/logprobs = tensor([[-0.5086, -1.7388],
        [-0.7372, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10853976756334305
Epoch 0, Step 842: train/loss = 0.5850191116333008, train/raw-loss = 0.5223819017410278, train/logprobs = tensor([[-1.1585, -2.4351],
        [-1.4257, -1.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12527431547641754
Epoch 0, Step 843: train/loss = 0.6370284557342529, train/raw-loss = 0.5874620676040649, train/logprobs = tensor([[-1.1150, -2.7962],
        [-1.4247, -2.6350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09913267195224762
Epoch 0, Step 844: train/loss = 0.4947000741958618, train/raw-loss = 0.4298122525215149, train/logprobs = tensor([[-0.7834, -2.0212],
        [-1.2826, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12977558374404907
Epoch 0, Step 845: train/loss = 0.568544864654541, train/raw-loss = 0.5117000937461853, train/logprobs = tensor([[-0.7216, -2.0559],
        [-0.7168, -0.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11368957161903381
Epoch 0, Step 846: train/loss = 0.5874290466308594, train/raw-loss = 0.5128532648086548, train/logprobs = tensor([[-1.4449, -2.3743],
        [-1.2975, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14915166795253754
Epoch 0, Step 847: train/loss = 0.6723407506942749, train/raw-loss = 0.6197624206542969, train/logprobs = tensor([[-0.5480, -0.9116],
        [-0.7078, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10515673458576202
Epoch 0, Step 848: train/loss = 0.7195467948913574, train/raw-loss = 0.6556485891342163, train/logprobs = tensor([[-0.9763, -1.2011],
        [-0.9714, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12779653072357178
Epoch 0, Step 849: train/loss = 0.5628247261047363, train/raw-loss = 0.494958758354187, train/logprobs = tensor([[-1.0074, -1.7662],
        [-1.0702, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13573190569877625
Epoch 0, Step 850: train/loss = 0.6183421015739441, train/raw-loss = 0.5415119528770447, train/logprobs = tensor([[-0.6629, -2.1233],
        [-0.9299, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15366040170192719
Epoch 0, Step 851: train/loss = 0.520753800868988, train/raw-loss = 0.45870453119277954, train/logprobs = tensor([[-0.6019, -1.7472],
        [-1.1499, -0.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12409862130880356
Epoch 0, Step 852: train/loss = 0.49802207946777344, train/raw-loss = 0.42744016647338867, train/logprobs = tensor([[-1.0451, -2.6183],
        [-1.4658, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14116385579109192
Epoch 0, Step 853: train/loss = 0.4010646939277649, train/raw-loss = 0.338554322719574, train/logprobs = tensor([[-0.9720, -4.7073],
        [-1.3803, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12502072751522064
Epoch 0, Step 854: train/loss = 0.44855961203575134, train/raw-loss = 0.38475918769836426, train/logprobs = tensor([[-1.2904, -2.4483],
        [-1.6082, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12760081887245178
Epoch 0, Step 855: train/loss = 0.5749270915985107, train/raw-loss = 0.5189048051834106, train/logprobs = tensor([[-1.9724, -2.8167],
        [-1.8702, -1.3729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11204466968774796
Epoch 0, Step 856: train/loss = 0.38948580622673035, train/raw-loss = 0.3248334228992462, train/logprobs = tensor([[-1.0185, -2.7448],
        [-1.5986, -0.8594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12930473685264587
Epoch 0, Step 857: train/loss = 0.5442324876785278, train/raw-loss = 0.4857271611690521, train/logprobs = tensor([[-0.7697, -2.2942],
        [-0.9226, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11701066046953201
Epoch 0, Step 858: train/loss = 0.4862826466560364, train/raw-loss = 0.4131871461868286, train/logprobs = tensor([[-1.4503, -2.6035],
        [-1.9510, -1.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1461910456418991
Epoch 0, Step 859: train/loss = 0.490692138671875, train/raw-loss = 0.4328433871269226, train/logprobs = tensor([[-0.8413, -2.4176],
        [-1.0947, -0.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569751799106598
Epoch 0, Step 860: train/loss = 0.7695498466491699, train/raw-loss = 0.7004036903381348, train/logprobs = tensor([[-0.7291, -0.9858],
        [-1.3116, -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13829220831394196
Epoch 0, Step 861: train/loss = 0.4877014458179474, train/raw-loss = 0.4256131649017334, train/logprobs = tensor([[-0.7659, -3.5286],
        [-1.1159, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12417657673358917
Epoch 0, Step 862: train/loss = 0.7146823406219482, train/raw-loss = 0.6533714532852173, train/logprobs = tensor([[-1.0349, -1.0922],
        [-1.0375, -0.8703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12262194603681564
Epoch 0, Step 863: train/loss = 0.5744208097457886, train/raw-loss = 0.5229915380477905, train/logprobs = tensor([[-0.9476, -2.2821],
        [-1.3700, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10285858064889908
Epoch 0, Step 864: train/loss = 0.3552834391593933, train/raw-loss = 0.2839151620864868, train/logprobs = tensor([[-0.6068, -4.3691],
        [-0.8765, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14273661375045776
Epoch 0, Step 865: train/loss = 0.6712493300437927, train/raw-loss = 0.6217058300971985, train/logprobs = tensor([[-0.5229, -1.2088],
        [-0.5890, -0.9285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09908701479434967
Epoch 0, Step 866: train/loss = 0.5957988500595093, train/raw-loss = 0.5336118340492249, train/logprobs = tensor([[-1.5409, -1.2539],
        [-2.0565, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12437404692173004
Epoch 0, Step 867: train/loss = 0.5216419100761414, train/raw-loss = 0.4592736065387726, train/logprobs = tensor([[-1.2420, -2.7621],
        [-1.4681, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12473662197589874
Epoch 0, Step 868: train/loss = 0.5434005856513977, train/raw-loss = 0.4818042814731598, train/logprobs = tensor([[-0.9945, -1.8369],
        [-1.1067, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12319257855415344
Epoch 0, Step 869: train/loss = 0.35544484853744507, train/raw-loss = 0.267114520072937, train/logprobs = tensor([[-1.5831, -4.0199],
        [-2.4131, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1766606718301773
Epoch 0, Step 870: train/loss = 0.41259610652923584, train/raw-loss = 0.3434562683105469, train/logprobs = tensor([[-1.2069, -2.4336],
        [-1.8695, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13827966153621674
Epoch 0, Step 871: train/loss = 0.5059601068496704, train/raw-loss = 0.4276963174343109, train/logprobs = tensor([[-0.9319, -2.0824],
        [-1.2895, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.156527578830719
Epoch 0, Step 872: train/loss = 0.4899596869945526, train/raw-loss = 0.4311171770095825, train/logprobs = tensor([[-0.6383, -2.5261],
        [-0.8311, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11768500506877899
Epoch 0, Step 873: train/loss = 0.4018287658691406, train/raw-loss = 0.33157244324684143, train/logprobs = tensor([[-0.5904, -2.8745],
        [-1.3983, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14051266014575958
Epoch 0, Step 874: train/loss = 0.7051935791969299, train/raw-loss = 0.6473824977874756, train/logprobs = tensor([[-0.7414, -1.0408],
        [-1.3154, -1.2925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11562220007181168
Epoch 0, Step 875: train/loss = 0.5356099605560303, train/raw-loss = 0.46468862891197205, train/logprobs = tensor([[-0.8317, -1.5216],
        [-1.4818, -0.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14184267818927765
Epoch 0, Step 876: train/loss = 0.4803198575973511, train/raw-loss = 0.40582573413848877, train/logprobs = tensor([[-1.1071, -2.4400],
        [-1.5120, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14898823201656342
Epoch 0, Step 877: train/loss = 0.518922746181488, train/raw-loss = 0.46464312076568604, train/logprobs = tensor([[-0.4621, -2.2713],
        [-0.7879, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10855931043624878
Epoch 0, Step 878: train/loss = 0.5204449892044067, train/raw-loss = 0.42927220463752747, train/logprobs = tensor([[-1.1004, -2.6771],
        [-1.8540, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18234555423259735
Epoch 0, Step 879: train/loss = 0.5057825446128845, train/raw-loss = 0.44492170214653015, train/logprobs = tensor([[-0.7277, -2.2843],
        [-0.9101, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172173708677292
Epoch 0, Step 880: train/loss = 0.5410079956054688, train/raw-loss = 0.47206223011016846, train/logprobs = tensor([[-0.9680, -2.1087],
        [-1.5001, -1.2790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13789153099060059
Epoch 0, Step 881: train/loss = 0.5566104650497437, train/raw-loss = 0.5011480450630188, train/logprobs = tensor([[-0.5186, -2.1938],
        [-0.8102, -1.2462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11092476546764374
Epoch 0, Step 882: train/loss = 0.46798819303512573, train/raw-loss = 0.3728138506412506, train/logprobs = tensor([[-1.1484, -1.8352],
        [-2.0847, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19034874439239502
Epoch 0, Step 883: train/loss = 0.6272168159484863, train/raw-loss = 0.5611459612846375, train/logprobs = tensor([[-0.9473, -1.6692],
        [-0.8248, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13214175403118134
Epoch 0, Step 884: train/loss = 0.59168541431427, train/raw-loss = 0.5304459929466248, train/logprobs = tensor([[-1.4639, -1.6838],
        [-1.3796, -0.6953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12247884273529053
Epoch 0, Step 885: train/loss = 0.4004966616630554, train/raw-loss = 0.3347463011741638, train/logprobs = tensor([[-0.6809, -4.8781],
        [-1.0785, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1315007358789444
Epoch 0, Step 886: train/loss = 0.6904842853546143, train/raw-loss = 0.6422761678695679, train/logprobs = tensor([[-0.5287, -0.5265],
        [-0.7484, -0.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09641620516777039
Epoch 0, Step 887: train/loss = 0.5243183970451355, train/raw-loss = 0.4508001208305359, train/logprobs = tensor([[-0.9916, -2.2527],
        [-1.5373, -0.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14703655242919922
Epoch 0, Step 888: train/loss = 0.488558828830719, train/raw-loss = 0.4022197127342224, train/logprobs = tensor([[-1.0212, -2.7113],
        [-1.5272, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17267823219299316
Epoch 0, Step 889: train/loss = 0.5816543102264404, train/raw-loss = 0.5166095495223999, train/logprobs = tensor([[-1.7445, -3.3051],
        [-2.0090, -1.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13008959591388702
Epoch 0, Step 890: train/loss = 0.4474143385887146, train/raw-loss = 0.37923771142959595, train/logprobs = tensor([[-0.7005, -2.9201],
        [-1.1701, -0.8139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1363532692193985
Epoch 0, Step 891: train/loss = 0.584214985370636, train/raw-loss = 0.5117678046226501, train/logprobs = tensor([[-1.5541, -1.9468],
        [-1.8639, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14489434659481049
Epoch 0, Step 892: train/loss = 0.4301166832447052, train/raw-loss = 0.35977840423583984, train/logprobs = tensor([[-1.8106, -1.5390],
        [-3.0668, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14067652821540833
Epoch 0, Step 893: train/loss = 0.5070320963859558, train/raw-loss = 0.44338881969451904, train/logprobs = tensor([[-1.2612, -3.5080],
        [-1.4041, -1.3022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12728656828403473
Epoch 0, Step 894: train/loss = 0.4086158871650696, train/raw-loss = 0.34275567531585693, train/logprobs = tensor([[-0.6286, -2.5969],
        [-1.0755, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13172036409378052
Epoch 0, Step 895: train/loss = 0.617626965045929, train/raw-loss = 0.5526912212371826, train/logprobs = tensor([[-1.5046, -1.8322],
        [-1.6348, -1.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1298714429140091
Epoch 0, Step 896: train/loss = 0.41441845893859863, train/raw-loss = 0.35606250166893005, train/logprobs = tensor([[-0.5788, -3.0501],
        [-0.8558, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11671197414398193
Epoch 0, Step 897: train/loss = 0.6176932454109192, train/raw-loss = 0.5734348297119141, train/logprobs = tensor([[-0.4344, -1.6117],
        [-0.4785, -0.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08851686120033264
Epoch 0, Step 898: train/loss = 0.5306118130683899, train/raw-loss = 0.4762271046638489, train/logprobs = tensor([[-0.5684, -2.2345],
        [-0.6471, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10876941680908203
Epoch 0, Step 899: train/loss = 0.434715211391449, train/raw-loss = 0.37099510431289673, train/logprobs = tensor([[-1.3406, -2.8694],
        [-1.9550, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1274401843547821
Epoch 0, Step 900: train/loss = 0.5030831694602966, train/raw-loss = 0.4243195950984955, train/logprobs = tensor([[-1.2360, -2.3553],
        [-2.0822, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15752719342708588
Epoch 0, Step 901: train/loss = 0.31850892305374146, train/raw-loss = 0.2184087336063385, train/logprobs = tensor([[-1.1886, -2.7125],
        [-2.3744, -0.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2002004235982895
Epoch 0, Step 902: train/loss = 0.3816468119621277, train/raw-loss = 0.3048809766769409, train/logprobs = tensor([[-0.8399, -3.2000],
        [-1.2692, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15353165566921234
Epoch 0, Step 903: train/loss = 0.4233264923095703, train/raw-loss = 0.3461213707923889, train/logprobs = tensor([[-0.7672, -2.4907],
        [-1.5656, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1544102430343628
Epoch 0, Step 904: train/loss = 0.502525806427002, train/raw-loss = 0.4297613799571991, train/logprobs = tensor([[-0.6032, -2.2320],
        [-1.6916, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1455288678407669
Epoch 0, Step 905: train/loss = 0.427886039018631, train/raw-loss = 0.36707252264022827, train/logprobs = tensor([[-0.6263, -2.0166],
        [-1.3339, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121627077460289
Epoch 0, Step 906: train/loss = 0.5289586782455444, train/raw-loss = 0.46990129351615906, train/logprobs = tensor([[-0.5246, -1.3061],
        [-1.2537, -0.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11811479926109314
Epoch 0, Step 907: train/loss = 0.5828820466995239, train/raw-loss = 0.5306539535522461, train/logprobs = tensor([[-0.8019, -2.2510],
        [-0.7556, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10445619374513626
Epoch 0, Step 908: train/loss = 0.3495293855667114, train/raw-loss = 0.2725658416748047, train/logprobs = tensor([[-1.0010, -2.5991],
        [-2.3505, -0.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15392708778381348
Epoch 0, Step 909: train/loss = 0.4875018894672394, train/raw-loss = 0.4126306474208832, train/logprobs = tensor([[-0.9426, -3.0367],
        [-1.1650, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14974255859851837
Epoch 0, Step 910: train/loss = 0.47286438941955566, train/raw-loss = 0.4070488214492798, train/logprobs = tensor([[-0.7841, -1.9881],
        [-1.6494, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13163112103939056
Epoch 0, Step 911: train/loss = 0.5218552350997925, train/raw-loss = 0.4609861671924591, train/logprobs = tensor([[-1.0015, -1.9087],
        [-1.2912, -0.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12173821777105331
Epoch 0, Step 912: train/loss = 0.48262590169906616, train/raw-loss = 0.4228431284427643, train/logprobs = tensor([[-0.9688, -2.2310],
        [-1.3125, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11956557631492615
Epoch 0, Step 913: train/loss = 0.6180585026741028, train/raw-loss = 0.5686941146850586, train/logprobs = tensor([[-0.5085, -1.2489],
        [-0.7757, -0.6380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09872884303331375
Epoch 0, Step 914: train/loss = 0.43120819330215454, train/raw-loss = 0.35793977975845337, train/logprobs = tensor([[-0.8720, -2.2838],
        [-1.6274, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14653682708740234
Epoch 0, Step 915: train/loss = 0.5633478760719299, train/raw-loss = 0.49737244844436646, train/logprobs = tensor([[-0.9161, -2.5933],
        [-0.7249, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1319507658481598
Epoch 0, Step 916: train/loss = 0.43174028396606445, train/raw-loss = 0.3437533974647522, train/logprobs = tensor([[-0.8500, -4.0095],
        [-1.6468, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1759737730026245
Epoch 0, Step 917: train/loss = 0.4112994372844696, train/raw-loss = 0.3391198515892029, train/logprobs = tensor([[-0.7171, -3.3731],
        [-1.0400, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14435918629169464
Epoch 0, Step 918: train/loss = 0.5143535733222961, train/raw-loss = 0.4479774236679077, train/logprobs = tensor([[-1.0803, -1.9762],
        [-2.0134, -0.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13275232911109924
Epoch 0, Step 919: train/loss = 0.40187349915504456, train/raw-loss = 0.32263243198394775, train/logprobs = tensor([[-1.1236, -3.1975],
        [-1.5241, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1584821492433548
Epoch 0, Step 920: train/loss = 0.4671780467033386, train/raw-loss = 0.40749186277389526, train/logprobs = tensor([[-0.7251, -2.1730],
        [-1.1606, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11937236785888672
Epoch 0, Step 921: train/loss = 0.4685428738594055, train/raw-loss = 0.40538930892944336, train/logprobs = tensor([[-0.9473, -2.6530],
        [-1.7413, -1.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12630712985992432
Epoch 0, Step 922: train/loss = 0.32328084111213684, train/raw-loss = 0.2496982216835022, train/logprobs = tensor([[-0.9126, -4.6166],
        [-1.4241, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14716525375843048
Epoch 0, Step 923: train/loss = 0.5984181761741638, train/raw-loss = 0.5451154708862305, train/logprobs = tensor([[-1.1931, -2.0540],
        [-1.3573, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10660553723573685
Epoch 0, Step 924: train/loss = 0.3545601963996887, train/raw-loss = 0.27962908148765564, train/logprobs = tensor([[-1.1956, -2.9315],
        [-2.1981, -1.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14986221492290497
Epoch 0, Step 925: train/loss = 0.625860869884491, train/raw-loss = 0.573611855506897, train/logprobs = tensor([[-0.8829, -1.3693],
        [-1.0033, -0.5452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10449791699647903
Epoch 0, Step 926: train/loss = 0.4538407623767853, train/raw-loss = 0.37286096811294556, train/logprobs = tensor([[-1.3979, -2.2987],
        [-1.9026, -0.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16195958852767944
Epoch 0, Step 927: train/loss = 0.4762442708015442, train/raw-loss = 0.40685129165649414, train/logprobs = tensor([[-0.7622, -2.1669],
        [-1.2734, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1387859284877777
Epoch 0, Step 928: train/loss = 0.43310973048210144, train/raw-loss = 0.3779217004776001, train/logprobs = tensor([[-1.0681, -3.5744],
        [-1.6048, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11037609726190567
Epoch 0, Step 929: train/loss = 0.5515826940536499, train/raw-loss = 0.4852050542831421, train/logprobs = tensor([[-0.9284, -1.4487],
        [-1.6790, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327553540468216
Epoch 0, Step 930: train/loss = 0.6836468577384949, train/raw-loss = 0.6199919581413269, train/logprobs = tensor([[-0.6550, -1.7565],
        [-1.1602, -1.5364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12730994820594788
Epoch 0, Step 931: train/loss = 0.6220625042915344, train/raw-loss = 0.5588963031768799, train/logprobs = tensor([[-0.4309, -1.5180],
        [-0.6903, -0.8134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12633241713047028
Epoch 0, Step 932: train/loss = 0.3638448119163513, train/raw-loss = 0.286690354347229, train/logprobs = tensor([[-1.2034, -3.6582],
        [-1.9592, -1.1951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15430893003940582
Epoch 0, Step 933: train/loss = 0.5169353485107422, train/raw-loss = 0.464843213558197, train/logprobs = tensor([[-0.4382, -1.9383],
        [-0.5763, -0.5328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10418441146612167
Epoch 0, Step 934: train/loss = 0.5250657796859741, train/raw-loss = 0.46938300132751465, train/logprobs = tensor([[-0.8197, -2.4303],
        [-0.8966, -1.0216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11136561632156372
Epoch 0, Step 935: train/loss = 0.5806286931037903, train/raw-loss = 0.524422287940979, train/logprobs = tensor([[-0.9561, -1.8649],
        [-1.0290, -0.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11241278797388077
Epoch 0, Step 936: train/loss = 0.5876655578613281, train/raw-loss = 0.5396721959114075, train/logprobs = tensor([[-0.4996, -1.3818],
        [-0.7520, -0.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0959867313504219
Epoch 0, Step 937: train/loss = 0.415973424911499, train/raw-loss = 0.33734992146492004, train/logprobs = tensor([[-0.8721, -2.9458],
        [-1.9859, -0.8063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15724702179431915
Epoch 0, Step 938: train/loss = 0.4130168557167053, train/raw-loss = 0.343479186296463, train/logprobs = tensor([[-0.9000, -4.1635],
        [-1.5372, -1.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13907533884048462
Epoch 0, Step 939: train/loss = 0.5263693928718567, train/raw-loss = 0.4786396026611328, train/logprobs = tensor([[-0.4844, -2.2850],
        [-0.6432, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09545957297086716
Epoch 0, Step 940: train/loss = 0.3098990321159363, train/raw-loss = 0.23408696055412292, train/logprobs = tensor([[-0.4910, -4.0215],
        [-1.1529, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516241878271103
Epoch 0, Step 941: train/loss = 0.6395312547683716, train/raw-loss = 0.5806480646133423, train/logprobs = tensor([[-1.3944, -2.1716],
        [-1.2206, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11776651442050934
Epoch 0, Step 942: train/loss = 0.3822024464607239, train/raw-loss = 0.3216458559036255, train/logprobs = tensor([[-0.6336, -2.6711],
        [-1.4551, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12111325562000275
Epoch 0, Step 943: train/loss = 0.42668378353118896, train/raw-loss = 0.359001100063324, train/logprobs = tensor([[-0.7836, -2.8327],
        [-1.2821, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13536539673805237
Epoch 0, Step 944: train/loss = 0.39024507999420166, train/raw-loss = 0.328077495098114, train/logprobs = tensor([[-1.1430, -2.7511],
        [-1.5813, -0.8082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12433516979217529
Epoch 0, Step 945: train/loss = 0.5183402299880981, train/raw-loss = 0.46065109968185425, train/logprobs = tensor([[-0.8916, -3.6743],
        [-1.0820, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11537837982177734
Epoch 0, Step 946: train/loss = 0.4678106904029846, train/raw-loss = 0.41315943002700806, train/logprobs = tensor([[-0.4753, -3.1688],
        [-0.6352, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10930252075195312
Epoch 0, Step 947: train/loss = 0.3671363592147827, train/raw-loss = 0.2647297978401184, train/logprobs = tensor([[-0.8085, -3.2997],
        [-2.3728, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20481304824352264
Epoch 0, Step 948: train/loss = 0.5603728890419006, train/raw-loss = 0.503031313419342, train/logprobs = tensor([[-0.6724, -2.7363],
        [-0.8127, -1.3788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11468316614627838
Epoch 0, Step 949: train/loss = 0.5097516179084778, train/raw-loss = 0.4408119320869446, train/logprobs = tensor([[-0.6919, -1.6644],
        [-1.3906, -0.7113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1378793567419052
Epoch 0, Step 950: train/loss = 0.47722721099853516, train/raw-loss = 0.41723111271858215, train/logprobs = tensor([[-0.8420, -2.2528],
        [-1.8521, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11999215185642242
Epoch 0, Step 951: train/loss = 0.42222529649734497, train/raw-loss = 0.3529096841812134, train/logprobs = tensor([[-0.8026, -3.3547],
        [-1.2092, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13863125443458557
Epoch 0, Step 952: train/loss = 0.42589494585990906, train/raw-loss = 0.35058993101119995, train/logprobs = tensor([[-1.0288, -3.1397],
        [-1.7519, -1.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15060999989509583
Epoch 0, Step 953: train/loss = 0.5868199467658997, train/raw-loss = 0.534504771232605, train/logprobs = tensor([[-0.9305, -2.0083],
        [-1.0341, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10463038086891174
Epoch 0, Step 954: train/loss = 0.5152139067649841, train/raw-loss = 0.45409369468688965, train/logprobs = tensor([[-0.8199, -1.6067],
        [-1.5356, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12224040925502777
Epoch 0, Step 955: train/loss = 0.5168852806091309, train/raw-loss = 0.4638162851333618, train/logprobs = tensor([[-0.6593, -2.3690],
        [-0.7062, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10613799095153809
Epoch 0, Step 956: train/loss = 0.4273141622543335, train/raw-loss = 0.3722650110721588, train/logprobs = tensor([[-1.8332, -4.9449],
        [-2.6437, -2.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11009828746318817
Epoch 0, Step 957: train/loss = 0.4145454168319702, train/raw-loss = 0.34654176235198975, train/logprobs = tensor([[-1.4980, -3.9797],
        [-1.9971, -1.3290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13600730895996094
Epoch 0, Step 958: train/loss = 0.5888530015945435, train/raw-loss = 0.5413430333137512, train/logprobs = tensor([[-0.8896, -1.4730],
        [-1.0905, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09501998871564865
Epoch 0, Step 959: train/loss = 0.593763530254364, train/raw-loss = 0.5351736545562744, train/logprobs = tensor([[-1.1086, -2.5842],
        [-1.1733, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1171797439455986
Epoch 0, Step 960: train/loss = 0.534481406211853, train/raw-loss = 0.48072412610054016, train/logprobs = tensor([[-0.8368, -2.0114],
        [-1.0347, -0.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10751450806856155
Epoch 0, Step 961: train/loss = 0.625770092010498, train/raw-loss = 0.5593893527984619, train/logprobs = tensor([[-0.9061, -1.9800],
        [-2.2483, -2.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327613890171051
Epoch 0, Step 962: train/loss = 0.5149558186531067, train/raw-loss = 0.4652269184589386, train/logprobs = tensor([[-0.7041, -1.5849],
        [-0.9652, -0.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09945780038833618
Epoch 0, Step 963: train/loss = 0.37735316157341003, train/raw-loss = 0.2931555509567261, train/logprobs = tensor([[-0.6571, -2.3109],
        [-2.0738, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16839517652988434
Epoch 0, Step 964: train/loss = 0.6389859914779663, train/raw-loss = 0.5801006555557251, train/logprobs = tensor([[-1.0121, -2.4573],
        [-1.8599, -2.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.117770716547966
Epoch 0, Step 965: train/loss = 0.4896400272846222, train/raw-loss = 0.4363885521888733, train/logprobs = tensor([[-0.8874, -1.8731],
        [-1.9940, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10650303214788437
Epoch 0, Step 966: train/loss = 0.39558619260787964, train/raw-loss = 0.29747211933135986, train/logprobs = tensor([[-1.0482, -2.7670],
        [-2.4031, -0.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19622811675071716
Epoch 0, Step 967: train/loss = 0.5699660181999207, train/raw-loss = 0.5200389623641968, train/logprobs = tensor([[-0.5240, -1.2492],
        [-0.7797, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09985421597957611
Epoch 0, Step 968: train/loss = 0.7310664653778076, train/raw-loss = 0.6683230400085449, train/logprobs = tensor([[-0.9591, -1.3225],
        [-2.1301, -1.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12548679113388062
Epoch 0, Step 969: train/loss = 0.6815599203109741, train/raw-loss = 0.6326830387115479, train/logprobs = tensor([[-0.7620, -0.9579],
        [-0.8502, -0.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09775375574827194
Epoch 0, Step 970: train/loss = 0.5566917657852173, train/raw-loss = 0.49781569838523865, train/logprobs = tensor([[-0.4295, -1.0175],
        [-1.2004, -0.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11775203049182892
Epoch 0, Step 971: train/loss = 0.5140975713729858, train/raw-loss = 0.4580705463886261, train/logprobs = tensor([[-0.7160, -2.5012],
        [-0.9524, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11205408722162247
Epoch 0, Step 972: train/loss = 0.38537541031837463, train/raw-loss = 0.32150697708129883, train/logprobs = tensor([[-0.7038, -4.2226],
        [-1.4609, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1277369260787964
Epoch 0, Step 973: train/loss = 0.6563014984130859, train/raw-loss = 0.606356680393219, train/logprobs = tensor([[-0.6675, -0.5344],
        [-0.9146, -0.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988969564437866
Epoch 0, Step 974: train/loss = 0.5665096640586853, train/raw-loss = 0.5080833435058594, train/logprobs = tensor([[-0.6300, -1.4725],
        [-1.3907, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685261130332947
Epoch 0, Step 975: train/loss = 0.4342550039291382, train/raw-loss = 0.3691825866699219, train/logprobs = tensor([[-0.8905, -3.4634],
        [-1.9864, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13014477491378784
Epoch 0, Step 976: train/loss = 0.585641622543335, train/raw-loss = 0.5269967913627625, train/logprobs = tensor([[-0.6223, -1.0633],
        [-0.9554, -0.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11728984117507935
Epoch 0, Step 977: train/loss = 0.5484776496887207, train/raw-loss = 0.4896477460861206, train/logprobs = tensor([[-0.7470, -1.5855],
        [-1.0158, -0.8656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1176598072052002
Epoch 0, Step 978: train/loss = 0.5869852304458618, train/raw-loss = 0.5334231853485107, train/logprobs = tensor([[-0.5455, -1.6128],
        [-0.7709, -0.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10712417960166931
Epoch 0, Step 979: train/loss = 0.3243595361709595, train/raw-loss = 0.24143657088279724, train/logprobs = tensor([[-0.5533, -3.5865],
        [-1.5353, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16584588587284088
Epoch 0, Step 980: train/loss = 0.4329218566417694, train/raw-loss = 0.3725285828113556, train/logprobs = tensor([[-1.0003, -1.5611],
        [-2.0863, -0.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1207866221666336
Epoch 0, Step 981: train/loss = 0.45821887254714966, train/raw-loss = 0.4055503308773041, train/logprobs = tensor([[-0.6789, -2.2428],
        [-1.4986, -0.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10533715039491653
Epoch 0, Step 982: train/loss = 0.5163942575454712, train/raw-loss = 0.4500586688518524, train/logprobs = tensor([[-0.7820, -1.8066],
        [-1.9023, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13267114758491516
Epoch 0, Step 983: train/loss = 0.5133987665176392, train/raw-loss = 0.44429564476013184, train/logprobs = tensor([[-0.8244, -2.3523],
        [-1.6161, -1.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13820621371269226
Epoch 0, Step 984: train/loss = 0.3798784911632538, train/raw-loss = 0.31594449281692505, train/logprobs = tensor([[-0.8384, -2.7799],
        [-1.1986, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12786801159381866
Epoch 0, Step 985: train/loss = 0.29472631216049194, train/raw-loss = 0.23525406420230865, train/logprobs = tensor([[-0.5175, -5.2947],
        [-0.9821, -1.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11894451081752777
Epoch 0, Step 986: train/loss = 0.3720625638961792, train/raw-loss = 0.309616357088089, train/logprobs = tensor([[-1.2408, -4.9193],
        [-1.7149, -2.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489242851734161
Epoch 0, Step 987: train/loss = 0.6721998453140259, train/raw-loss = 0.5962855815887451, train/logprobs = tensor([[-0.8419, -1.9000],
        [-1.9657, -1.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15182843804359436
Epoch 0, Step 988: train/loss = 0.4727958142757416, train/raw-loss = 0.40789294242858887, train/logprobs = tensor([[-0.7421, -4.2453],
        [-0.7117, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129805788397789
Epoch 0, Step 989: train/loss = 0.46211931109428406, train/raw-loss = 0.3990529775619507, train/logprobs = tensor([[-0.4143, -2.0326],
        [-1.3050, -0.7622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12613265216350555
Epoch 0, Step 990: train/loss = 0.5241243839263916, train/raw-loss = 0.43930235505104065, train/logprobs = tensor([[-1.0093, -1.6216],
        [-1.7088, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16964393854141235
Epoch 0, Step 991: train/loss = 0.5669338703155518, train/raw-loss = 0.5239893198013306, train/logprobs = tensor([[-0.6170, -0.9450],
        [-1.0085, -0.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08588898181915283
Epoch 0, Step 992: train/loss = 0.404893159866333, train/raw-loss = 0.33351409435272217, train/logprobs = tensor([[-0.7169, -2.9216],
        [-1.5291, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14275814592838287
Epoch 0, Step 993: train/loss = 0.5900440216064453, train/raw-loss = 0.5143225193023682, train/logprobs = tensor([[-0.7161, -1.1908],
        [-1.3326, -0.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15144288539886475
Epoch 0, Step 994: train/loss = 0.49936148524284363, train/raw-loss = 0.41574716567993164, train/logprobs = tensor([[-1.1342, -3.9525],
        [-1.9252, -1.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16722863912582397
Epoch 0, Step 995: train/loss = 0.3375938832759857, train/raw-loss = 0.2722705006599426, train/logprobs = tensor([[-0.6591, -4.2619],
        [-1.5872, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306467354297638
Epoch 0, Step 996: train/loss = 0.520527720451355, train/raw-loss = 0.44389036297798157, train/logprobs = tensor([[-0.8429, -1.2391],
        [-1.7476, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15327459573745728
Epoch 0, Step 997: train/loss = 0.6281808614730835, train/raw-loss = 0.5545639395713806, train/logprobs = tensor([[-0.6064, -1.5942],
        [-1.1873, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14723384380340576
Epoch 0, Step 998: train/loss = 0.25663623213768005, train/raw-loss = 0.16966713964939117, train/logprobs = tensor([[-0.7911, -3.7460],
        [-2.5109, -0.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17393814027309418
Epoch 0, Step 999: train/loss = 0.6132952570915222, train/raw-loss = 0.5526244640350342, train/logprobs = tensor([[-0.6120, -1.6889],
        [-0.8376, -1.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12134158611297607
eval/loss: 0.4993257522583008
Epoch 0, Step 1000: train/loss = 0.46649283170700073, train/raw-loss = 0.4003652334213257, train/logprobs = tensor([[-0.6739, -2.8186],
        [-1.4348, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13225513696670532
Epoch 0, Step 1001: train/loss = 0.298031210899353, train/raw-loss = 0.23603910207748413, train/logprobs = tensor([[-0.7043, -2.1655],
        [-2.6522, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12398422509431839
Epoch 0, Step 1002: train/loss = 0.6434354186058044, train/raw-loss = 0.5972474813461304, train/logprobs = tensor([[-0.6377, -1.1214],
        [-0.7256, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09237584471702576
Epoch 0, Step 1003: train/loss = 0.4778061509132385, train/raw-loss = 0.4099956154823303, train/logprobs = tensor([[-0.5085, -1.5389],
        [-1.5632, -0.6776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13562102615833282
Epoch 0, Step 1004: train/loss = 0.34463900327682495, train/raw-loss = 0.25830143690109253, train/logprobs = tensor([[-1.3687, -3.7104],
        [-2.6752, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17267511785030365
Epoch 0, Step 1005: train/loss = 0.38426393270492554, train/raw-loss = 0.3044913411140442, train/logprobs = tensor([[-0.5487, -2.9402],
        [-1.2613, -0.8901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1595451980829239
Epoch 0, Step 1006: train/loss = 0.464876264333725, train/raw-loss = 0.4046677350997925, train/logprobs = tensor([[-0.6387, -2.8282],
        [-0.7611, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1204170286655426
Epoch 0, Step 1007: train/loss = 0.31556010246276855, train/raw-loss = 0.23783473670482635, train/logprobs = tensor([[-0.7818, -3.7755],
        [-1.9800, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15545079112052917
Epoch 0, Step 1008: train/loss = 0.4827016592025757, train/raw-loss = 0.4358598291873932, train/logprobs = tensor([[-0.9420, -2.2025],
        [-1.4109, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09368370473384857
Epoch 0, Step 1009: train/loss = 0.5371072292327881, train/raw-loss = 0.4711531400680542, train/logprobs = tensor([[-0.6020, -2.2458],
        [-1.1712, -0.7455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13190822303295135
Epoch 0, Step 1010: train/loss = 0.3739803433418274, train/raw-loss = 0.30127236247062683, train/logprobs = tensor([[-0.8176, -3.9114],
        [-1.2997, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14541596174240112
Epoch 0, Step 1011: train/loss = 0.3624941110610962, train/raw-loss = 0.28998279571533203, train/logprobs = tensor([[-0.5464, -3.7106],
        [-0.8279, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14502261579036713
Epoch 0, Step 1012: train/loss = 0.40676891803741455, train/raw-loss = 0.3285200595855713, train/logprobs = tensor([[-0.5748, -2.0803],
        [-1.9819, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15649765729904175
Epoch 0, Step 1013: train/loss = 0.49528762698173523, train/raw-loss = 0.4330345094203949, train/logprobs = tensor([[-0.6960, -3.2190],
        [-0.8869, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450630962848663
Epoch 0, Step 1014: train/loss = 0.4351401925086975, train/raw-loss = 0.3776921033859253, train/logprobs = tensor([[-0.6491, -2.9773],
        [-1.4130, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11489610373973846
Epoch 0, Step 1015: train/loss = 0.682833194732666, train/raw-loss = 0.609434962272644, train/logprobs = tensor([[-0.8605, -1.8860],
        [-2.1176, -2.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14679646492004395
Epoch 0, Step 1016: train/loss = 0.3015904724597931, train/raw-loss = 0.23440688848495483, train/logprobs = tensor([[-0.6989, -4.6884],
        [-1.7688, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343671828508377
Epoch 0, Step 1017: train/loss = 0.28874653577804565, train/raw-loss = 0.19429807364940643, train/logprobs = tensor([[-0.6568, -3.5796],
        [-2.5698, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18889696896076202
Epoch 0, Step 1018: train/loss = 0.677108108997345, train/raw-loss = 0.6097837090492249, train/logprobs = tensor([[-0.8851, -3.1422],
        [-1.1688, -1.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13464872539043427
Epoch 0, Step 1019: train/loss = 0.5173030495643616, train/raw-loss = 0.4318585991859436, train/logprobs = tensor([[-0.6364, -1.2643],
        [-1.4206, -0.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17088890075683594
Epoch 0, Step 1020: train/loss = 0.47177377343177795, train/raw-loss = 0.39755505323410034, train/logprobs = tensor([[-0.6934, -2.4921],
        [-1.4899, -0.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14843744039535522
Epoch 0, Step 1021: train/loss = 0.4007471203804016, train/raw-loss = 0.3288455605506897, train/logprobs = tensor([[-0.6030, -2.9479],
        [-1.0177, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14380304515361786
Epoch 0, Step 1022: train/loss = 0.5303916931152344, train/raw-loss = 0.47158199548721313, train/logprobs = tensor([[-0.6498, -1.9547],
        [-1.1195, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761949211359024
Epoch 0, Step 1023: train/loss = 0.3592410385608673, train/raw-loss = 0.2738085687160492, train/logprobs = tensor([[-0.5813, -2.4302],
        [-1.9284, -0.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17086496949195862
Epoch 0, Step 1024: train/loss = 0.59037846326828, train/raw-loss = 0.5153172016143799, train/logprobs = tensor([[-0.8410, -2.1042],
        [-1.2541, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501224935054779
Epoch 0, Step 1025: train/loss = 0.4219244122505188, train/raw-loss = 0.35279351472854614, train/logprobs = tensor([[-0.6002, -2.3651],
        [-1.7415, -0.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13826175034046173
Epoch 0, Step 1026: train/loss = 0.5871059894561768, train/raw-loss = 0.5341432094573975, train/logprobs = tensor([[-0.3716, -2.2239],
        [-0.6233, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10592566430568695
Epoch 0, Step 1027: train/loss = 0.46525150537490845, train/raw-loss = 0.40269070863723755, train/logprobs = tensor([[-0.6403, -2.0084],
        [-1.2888, -0.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12512162327766418
Epoch 0, Step 1028: train/loss = 0.6071983575820923, train/raw-loss = 0.5514875650405884, train/logprobs = tensor([[-1.1652, -2.6933],
        [-0.9921, -1.3598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1114216074347496
Epoch 0, Step 1029: train/loss = 0.5324251651763916, train/raw-loss = 0.46080946922302246, train/logprobs = tensor([[-0.7433, -1.5351],
        [-1.5473, -0.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1432313174009323
Epoch 0, Step 1030: train/loss = 0.3308931589126587, train/raw-loss = 0.25349438190460205, train/logprobs = tensor([[-0.6854, -2.9796],
        [-1.6810, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547974944114685
Epoch 0, Step 1031: train/loss = 0.507846474647522, train/raw-loss = 0.4456169605255127, train/logprobs = tensor([[-0.6729, -1.4900],
        [-1.0914, -0.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12445902824401855
Epoch 0, Step 1032: train/loss = 0.6140466332435608, train/raw-loss = 0.551193356513977, train/logprobs = tensor([[-0.5494, -1.2590],
        [-0.7804, -0.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12570661306381226
Epoch 0, Step 1033: train/loss = 0.5750826597213745, train/raw-loss = 0.5233538746833801, train/logprobs = tensor([[-0.5386, -2.7773],
        [-1.1789, -0.9031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034574955701828
Epoch 0, Step 1034: train/loss = 0.42810243368148804, train/raw-loss = 0.33333128690719604, train/logprobs = tensor([[-1.1972, -3.2450],
        [-2.1974, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18954220414161682
Epoch 0, Step 1035: train/loss = 0.43226224184036255, train/raw-loss = 0.3714643716812134, train/logprobs = tensor([[-0.8910, -2.2227],
        [-1.4393, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12159575521945953
Epoch 0, Step 1036: train/loss = 0.5234546661376953, train/raw-loss = 0.4554334580898285, train/logprobs = tensor([[-0.7478, -1.1720],
        [-1.4635, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13604243099689484
Epoch 0, Step 1037: train/loss = 0.2657492756843567, train/raw-loss = 0.19532561302185059, train/logprobs = tensor([[-0.7130, -4.6271],
        [-2.0312, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408473253250122
Epoch 0, Step 1038: train/loss = 0.38701730966567993, train/raw-loss = 0.3357807695865631, train/logprobs = tensor([[-0.5510, -4.7253],
        [-0.9429, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10247306525707245
Epoch 0, Step 1039: train/loss = 0.41530099511146545, train/raw-loss = 0.3358749747276306, train/logprobs = tensor([[-1.1159, -3.1885],
        [-2.2229, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1588519662618637
Epoch 0, Step 1040: train/loss = 0.7592834830284119, train/raw-loss = 0.6990298628807068, train/logprobs = tensor([[-0.8475, -1.8832],
        [-0.8304, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12050724029541016
Epoch 0, Step 1041: train/loss = 0.4635501503944397, train/raw-loss = 0.3873194456100464, train/logprobs = tensor([[-0.7665, -2.2571],
        [-1.8037, -0.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15246136486530304
Epoch 0, Step 1042: train/loss = 0.5460052490234375, train/raw-loss = 0.48998090624809265, train/logprobs = tensor([[-0.4898, -1.9289],
        [-0.7719, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11204876005649567
Epoch 0, Step 1043: train/loss = 0.43006473779678345, train/raw-loss = 0.3647844195365906, train/logprobs = tensor([[-0.5706, -3.1371],
        [-0.8193, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13056057691574097
Epoch 0, Step 1044: train/loss = 0.568369448184967, train/raw-loss = 0.5048351883888245, train/logprobs = tensor([[-0.5055, -1.2079],
        [-1.1848, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12706851959228516
Epoch 0, Step 1045: train/loss = 0.3891028165817261, train/raw-loss = 0.31629374623298645, train/logprobs = tensor([[-0.3394, -2.4570],
        [-1.3821, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14561814069747925
Epoch 0, Step 1046: train/loss = 0.5825883150100708, train/raw-loss = 0.536937415599823, train/logprobs = tensor([[-0.6676, -1.6211],
        [-0.7207, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09130184352397919
Epoch 0, Step 1047: train/loss = 0.6339730024337769, train/raw-loss = 0.5764729976654053, train/logprobs = tensor([[-0.9033, -1.6182],
        [-0.8164, -0.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11499999463558197
Epoch 0, Step 1048: train/loss = 0.3950861692428589, train/raw-loss = 0.3330498933792114, train/logprobs = tensor([[-0.8462, -2.9963],
        [-1.5004, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407244741916656
Epoch 0, Step 1049: train/loss = 0.3992535471916199, train/raw-loss = 0.3209322392940521, train/logprobs = tensor([[-0.6339, -2.2414],
        [-1.7665, -0.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566426306962967
Epoch 0, Step 1050: train/loss = 0.42595532536506653, train/raw-loss = 0.34868359565734863, train/logprobs = tensor([[-0.8143, -2.8987],
        [-1.5764, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545434445142746
Epoch 0, Step 1051: train/loss = 0.4323600232601166, train/raw-loss = 0.36762335896492004, train/logprobs = tensor([[-1.0978, -3.8194],
        [-1.4767, -0.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294732391834259
Epoch 0, Step 1052: train/loss = 0.3647667169570923, train/raw-loss = 0.29260119795799255, train/logprobs = tensor([[-0.7675, -3.3273],
        [-2.1038, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14433103799819946
Epoch 0, Step 1053: train/loss = 0.47358208894729614, train/raw-loss = 0.418399840593338, train/logprobs = tensor([[-0.5570, -2.1648],
        [-0.7479, -0.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11036455631256104
Epoch 0, Step 1054: train/loss = 0.347115159034729, train/raw-loss = 0.28131482005119324, train/logprobs = tensor([[-0.6810, -4.2479],
        [-0.9089, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13160066306591034
Epoch 0, Step 1055: train/loss = 0.4927290081977844, train/raw-loss = 0.4154810607433319, train/logprobs = tensor([[-0.9033, -2.5790],
        [-2.0933, -1.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15449586510658264
Epoch 0, Step 1056: train/loss = 0.5258117914199829, train/raw-loss = 0.4630187153816223, train/logprobs = tensor([[-0.6240, -4.1596],
        [-0.5612, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1255861073732376
Epoch 0, Step 1057: train/loss = 0.5168396830558777, train/raw-loss = 0.45084601640701294, train/logprobs = tensor([[-0.6223, -1.4533],
        [-1.4005, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13198724389076233
Epoch 0, Step 1058: train/loss = 0.5561783313751221, train/raw-loss = 0.4769502282142639, train/logprobs = tensor([[-0.9075, -2.8133],
        [-2.4627, -1.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15845626592636108
Epoch 0, Step 1059: train/loss = 0.34569719433784485, train/raw-loss = 0.271232545375824, train/logprobs = tensor([[-1.0384, -3.0555],
        [-2.2477, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14892926812171936
Epoch 0, Step 1060: train/loss = 0.6273441314697266, train/raw-loss = 0.5769656896591187, train/logprobs = tensor([[-0.5962, -1.2098],
        [-0.7908, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1007569432258606
Epoch 0, Step 1061: train/loss = 0.7315611839294434, train/raw-loss = 0.6580895781517029, train/logprobs = tensor([[-2.0025, -2.8781],
        [-2.3962, -1.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14694322645664215
Epoch 0, Step 1062: train/loss = 0.45305418968200684, train/raw-loss = 0.3853446841239929, train/logprobs = tensor([[-0.4978, -3.3487],
        [-1.3818, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13541895151138306
Epoch 0, Step 1063: train/loss = 0.3705078065395355, train/raw-loss = 0.2968042194843292, train/logprobs = tensor([[-0.6407, -4.6099],
        [-2.4749, -1.3652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14740720391273499
Epoch 0, Step 1064: train/loss = 0.45197999477386475, train/raw-loss = 0.3909648060798645, train/logprobs = tensor([[-0.5148, -2.2579],
        [-0.7818, -0.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1220303624868393
Epoch 0, Step 1065: train/loss = 0.4261859655380249, train/raw-loss = 0.35743701457977295, train/logprobs = tensor([[-0.4660, -1.9070],
        [-1.4671, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374979466199875
Epoch 0, Step 1066: train/loss = 0.6818481087684631, train/raw-loss = 0.6235679984092712, train/logprobs = tensor([[-0.7303, -0.9302],
        [-1.3170, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11656028032302856
Epoch 0, Step 1067: train/loss = 0.558445394039154, train/raw-loss = 0.4983435273170471, train/logprobs = tensor([[-0.6479, -2.0650],
        [-0.7364, -0.8042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12020370364189148
Epoch 0, Step 1068: train/loss = 0.4658973813056946, train/raw-loss = 0.37642204761505127, train/logprobs = tensor([[-0.5265, -2.2580],
        [-1.4726, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17895063757896423
Epoch 0, Step 1069: train/loss = 0.45094799995422363, train/raw-loss = 0.39336100220680237, train/logprobs = tensor([[-0.7872, -2.1396],
        [-1.4129, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1151740550994873
Epoch 0, Step 1070: train/loss = 0.6499114036560059, train/raw-loss = 0.5943660736083984, train/logprobs = tensor([[-0.6498, -1.0484],
        [-0.8801, -0.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11109066754579544
Epoch 0, Step 1071: train/loss = 0.3229803740978241, train/raw-loss = 0.24326950311660767, train/logprobs = tensor([[-0.7547, -3.2081],
        [-1.5690, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15942177176475525
Epoch 0, Step 1072: train/loss = 0.6129439473152161, train/raw-loss = 0.5446985960006714, train/logprobs = tensor([[-0.9730, -0.9331],
        [-3.0461, -1.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13649068772792816
Epoch 0, Step 1073: train/loss = 0.5820779800415039, train/raw-loss = 0.5106970071792603, train/logprobs = tensor([[-1.2544, -2.2703],
        [-1.1982, -0.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427619755268097
Epoch 0, Step 1074: train/loss = 0.49550557136535645, train/raw-loss = 0.4348757863044739, train/logprobs = tensor([[-0.6595, -1.9851],
        [-1.4085, -0.3670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12125951051712036
Epoch 0, Step 1075: train/loss = 0.5386955142021179, train/raw-loss = 0.47105422616004944, train/logprobs = tensor([[-1.1588, -2.4282],
        [-1.2718, -0.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13528259098529816
Epoch 0, Step 1076: train/loss = 0.5108100771903992, train/raw-loss = 0.4516359269618988, train/logprobs = tensor([[-0.6101, -2.5379],
        [-1.8410, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11834830045700073
Epoch 0, Step 1077: train/loss = 0.36605361104011536, train/raw-loss = 0.3028006851673126, train/logprobs = tensor([[-0.5730, -3.0556],
        [-1.6199, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12650585174560547
Epoch 0, Step 1078: train/loss = 0.4832778573036194, train/raw-loss = 0.4036165773868561, train/logprobs = tensor([[-0.3924, -1.4649],
        [-1.6062, -0.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.159322589635849
Epoch 0, Step 1079: train/loss = 0.3366204798221588, train/raw-loss = 0.26148656010627747, train/logprobs = tensor([[-0.8716, -3.6389],
        [-1.8773, -0.9581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15026788413524628
Epoch 0, Step 1080: train/loss = 0.5508944988250732, train/raw-loss = 0.4996674358844757, train/logprobs = tensor([[-0.4309, -1.5468],
        [-0.6014, -0.5637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10245414823293686
Epoch 0, Step 1081: train/loss = 0.5216683149337769, train/raw-loss = 0.4518014192581177, train/logprobs = tensor([[-0.9660, -2.2509],
        [-1.6113, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13973368704319
Epoch 0, Step 1082: train/loss = 0.618992030620575, train/raw-loss = 0.5790000557899475, train/logprobs = tensor([[-0.7397, -1.8247],
        [-1.0134, -1.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07998397946357727
Epoch 0, Step 1083: train/loss = 0.45018070936203003, train/raw-loss = 0.37699687480926514, train/logprobs = tensor([[-0.7692, -2.9881],
        [-1.3770, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463676393032074
Epoch 0, Step 1084: train/loss = 0.636829137802124, train/raw-loss = 0.5789628028869629, train/logprobs = tensor([[-0.9194, -1.2868],
        [-1.2153, -0.9348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11573265492916107
Epoch 0, Step 1085: train/loss = 0.40638914704322815, train/raw-loss = 0.3293742537498474, train/logprobs = tensor([[-0.8415, -2.6892],
        [-1.7732, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15402984619140625
Epoch 0, Step 1086: train/loss = 0.4125480651855469, train/raw-loss = 0.32836824655532837, train/logprobs = tensor([[-0.9599, -1.7795],
        [-2.6859, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16835960745811462
Epoch 0, Step 1087: train/loss = 0.4953033924102783, train/raw-loss = 0.4315500259399414, train/logprobs = tensor([[-0.5812, -2.4542],
        [-0.9217, -0.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127506822347641
Epoch 0, Step 1088: train/loss = 0.48228490352630615, train/raw-loss = 0.4069652259349823, train/logprobs = tensor([[-0.9921, -2.5717],
        [-1.1637, -0.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15063941478729248
Epoch 0, Step 1089: train/loss = 0.40482279658317566, train/raw-loss = 0.3359029293060303, train/logprobs = tensor([[-0.7145, -3.6580],
        [-2.1981, -1.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13783979415893555
Epoch 0, Step 1090: train/loss = 0.567401111125946, train/raw-loss = 0.507434606552124, train/logprobs = tensor([[-0.5523, -2.6179],
        [-0.9903, -1.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11993297189474106
Epoch 0, Step 1091: train/loss = 0.3048624098300934, train/raw-loss = 0.223053440451622, train/logprobs = tensor([[-0.7209, -3.7806],
        [-2.4660, -0.9258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16361798346042633
Epoch 0, Step 1092: train/loss = 0.4610002636909485, train/raw-loss = 0.4008072018623352, train/logprobs = tensor([[-0.7837, -2.9443],
        [-1.1665, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038612365722656
Epoch 0, Step 1093: train/loss = 0.4181838929653168, train/raw-loss = 0.35110974311828613, train/logprobs = tensor([[-1.0130, -1.8061],
        [-2.6605, -0.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414821028709412
Epoch 0, Step 1094: train/loss = 0.4104587733745575, train/raw-loss = 0.3404257595539093, train/logprobs = tensor([[-0.6215, -4.4933],
        [-1.0164, -1.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14006608724594116
Epoch 0, Step 1095: train/loss = 0.48237159848213196, train/raw-loss = 0.4001304805278778, train/logprobs = tensor([[-0.6720, -2.5529],
        [-1.2124, -0.9603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1644822359085083
Epoch 0, Step 1096: train/loss = 0.5077082514762878, train/raw-loss = 0.44350409507751465, train/logprobs = tensor([[-0.6007, -1.9473],
        [-0.7835, -0.6848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1284082531929016
Epoch 0, Step 1097: train/loss = 0.5044212341308594, train/raw-loss = 0.4527835249900818, train/logprobs = tensor([[-0.4848, -2.1974],
        [-0.6266, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10327544808387756
Epoch 0, Step 1098: train/loss = 0.5348072648048401, train/raw-loss = 0.4884682893753052, train/logprobs = tensor([[-0.5399, -1.9711],
        [-0.5700, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267797321081161
Epoch 0, Step 1099: train/loss = 0.439749538898468, train/raw-loss = 0.36887937784194946, train/logprobs = tensor([[-0.7975, -2.4302],
        [-1.4441, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14174026250839233
Epoch 0, Step 1100: train/loss = 0.5320175886154175, train/raw-loss = 0.43901658058166504, train/logprobs = tensor([[-0.9590, -1.9637],
        [-2.0963, -1.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1860020011663437
Epoch 0, Step 1101: train/loss = 0.5173184275627136, train/raw-loss = 0.458666056394577, train/logprobs = tensor([[-0.6820, -1.8354],
        [-1.2283, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1173047125339508
Epoch 0, Step 1102: train/loss = 0.464867502450943, train/raw-loss = 0.39991164207458496, train/logprobs = tensor([[-0.6601, -2.7639],
        [-1.0823, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12991167604923248
Epoch 0, Step 1103: train/loss = 0.5074909925460815, train/raw-loss = 0.4276024401187897, train/logprobs = tensor([[-0.7482, -2.4202],
        [-0.7614, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15977714955806732
Epoch 0, Step 1104: train/loss = 0.39460474252700806, train/raw-loss = 0.33204516768455505, train/logprobs = tensor([[-0.5073, -4.3143],
        [-0.6557, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125119149684906
Epoch 0, Step 1105: train/loss = 0.610448956489563, train/raw-loss = 0.5548131465911865, train/logprobs = tensor([[-0.4994, -1.7078],
        [-0.6807, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127166450023651
Epoch 0, Step 1106: train/loss = 0.3659587800502777, train/raw-loss = 0.2770652174949646, train/logprobs = tensor([[-0.8009, -2.8478],
        [-1.4898, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.177787184715271
Epoch 0, Step 1107: train/loss = 0.360876202583313, train/raw-loss = 0.28461453318595886, train/logprobs = tensor([[-0.7588, -3.2025],
        [-1.5929, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15252333879470825
Epoch 0, Step 1108: train/loss = 0.7122734785079956, train/raw-loss = 0.6382311582565308, train/logprobs = tensor([[-1.3698, -2.3424],
        [-0.9530, -0.8594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14808456599712372
Epoch 0, Step 1109: train/loss = 0.31833818554878235, train/raw-loss = 0.24345523118972778, train/logprobs = tensor([[-0.6682, -4.3647],
        [-1.3707, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14976589381694794
Epoch 0, Step 1110: train/loss = 0.5188316106796265, train/raw-loss = 0.44757968187332153, train/logprobs = tensor([[-0.5342, -1.9347],
        [-1.1900, -0.7882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14250390231609344
Epoch 0, Step 1111: train/loss = 0.4979405701160431, train/raw-loss = 0.4226638972759247, train/logprobs = tensor([[-0.9165, -2.0449],
        [-1.5798, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15055331587791443
Epoch 0, Step 1112: train/loss = 0.3841190040111542, train/raw-loss = 0.31018421053886414, train/logprobs = tensor([[-0.8626, -3.5889],
        [-1.3036, -1.3433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14786960184574127
Epoch 0, Step 1113: train/loss = 0.5070125460624695, train/raw-loss = 0.4329366683959961, train/logprobs = tensor([[-0.7145, -3.6369],
        [-0.8041, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14815184473991394
Epoch 0, Step 1114: train/loss = 0.5626830458641052, train/raw-loss = 0.5086063146591187, train/logprobs = tensor([[-0.9639, -3.4139],
        [-1.0255, -1.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10815352201461792
Epoch 0, Step 1115: train/loss = 0.41572892665863037, train/raw-loss = 0.32149040699005127, train/logprobs = tensor([[-0.6125, -2.4027],
        [-1.8764, -0.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1884770393371582
Epoch 0, Step 1116: train/loss = 0.36821407079696655, train/raw-loss = 0.28931984305381775, train/logprobs = tensor([[-0.9499, -4.2673],
        [-1.2188, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15778842568397522
Epoch 0, Step 1117: train/loss = 0.43874695897102356, train/raw-loss = 0.36085599660873413, train/logprobs = tensor([[-0.5875, -3.0928],
        [-1.7526, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15578196942806244
Epoch 0, Step 1118: train/loss = 0.5182799100875854, train/raw-loss = 0.4436917304992676, train/logprobs = tensor([[-0.6952, -1.9174],
        [-1.7368, -1.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14917629957199097
Epoch 0, Step 1119: train/loss = 0.5803886651992798, train/raw-loss = 0.531544029712677, train/logprobs = tensor([[-0.6557, -2.0992],
        [-0.7170, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09768927097320557
Epoch 0, Step 1120: train/loss = 0.38751834630966187, train/raw-loss = 0.2987208664417267, train/logprobs = tensor([[-0.6788, -2.9592],
        [-2.1592, -0.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17759498953819275
Epoch 0, Step 1121: train/loss = 0.4952348470687866, train/raw-loss = 0.42009636759757996, train/logprobs = tensor([[-0.8601, -1.9711],
        [-2.4356, -0.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502770036458969
Epoch 0, Step 1122: train/loss = 0.6205043792724609, train/raw-loss = 0.5674712657928467, train/logprobs = tensor([[-0.8210, -1.4035],
        [-0.8973, -0.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10606618225574493
Epoch 0, Step 1123: train/loss = 0.43497222661972046, train/raw-loss = 0.36420997977256775, train/logprobs = tensor([[-0.5799, -3.0073],
        [-1.6122, -1.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14152446389198303
Epoch 0, Step 1124: train/loss = 0.38584887981414795, train/raw-loss = 0.31398722529411316, train/logprobs = tensor([[-1.1528, -4.0334],
        [-1.8364, -1.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14372335374355316
Epoch 0, Step 1125: train/loss = 0.4830123782157898, train/raw-loss = 0.39893457293510437, train/logprobs = tensor([[-0.9510, -2.3128],
        [-1.4551, -0.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16815555095672607
Epoch 0, Step 1126: train/loss = 0.4633398652076721, train/raw-loss = 0.38432490825653076, train/logprobs = tensor([[-0.8708, -3.6009],
        [-1.7873, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1580299288034439
Epoch 0, Step 1127: train/loss = 0.34467512369155884, train/raw-loss = 0.2627641558647156, train/logprobs = tensor([[-0.9798, -3.3706],
        [-2.3186, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16382195055484772
Epoch 0, Step 1128: train/loss = 0.400653600692749, train/raw-loss = 0.31954532861709595, train/logprobs = tensor([[-0.7834, -1.8591],
        [-2.6562, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16221654415130615
Epoch 0, Step 1129: train/loss = 0.6523085832595825, train/raw-loss = 0.5978193283081055, train/logprobs = tensor([[-0.6486, -1.0583],
        [-0.6118, -0.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10897848010063171
Epoch 0, Step 1130: train/loss = 0.4741246700286865, train/raw-loss = 0.3980177044868469, train/logprobs = tensor([[-0.6497, -2.4529],
        [-1.1104, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15221387147903442
Epoch 0, Step 1131: train/loss = 0.5979798436164856, train/raw-loss = 0.5440295934677124, train/logprobs = tensor([[-0.6104, -1.6643],
        [-0.6695, -0.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10790042579174042
Epoch 0, Step 1132: train/loss = 0.6016720533370972, train/raw-loss = 0.5293124914169312, train/logprobs = tensor([[-0.8189, -1.2861],
        [-1.2671, -0.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14471906423568726
Epoch 0, Step 1133: train/loss = 0.45388156175613403, train/raw-loss = 0.38475409150123596, train/logprobs = tensor([[-0.8388, -2.5749],
        [-1.1873, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13825500011444092
Epoch 0, Step 1134: train/loss = 0.60991370677948, train/raw-loss = 0.5679433345794678, train/logprobs = tensor([[-0.4886, -1.4162],
        [-0.5570, -0.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.083940789103508
Epoch 0, Step 1135: train/loss = 0.3452855944633484, train/raw-loss = 0.24665233492851257, train/logprobs = tensor([[-0.9138, -3.4694],
        [-1.7030, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19726654887199402
Epoch 0, Step 1136: train/loss = 0.6511841416358948, train/raw-loss = 0.6085505485534668, train/logprobs = tensor([[-0.6886, -0.9671],
        [-0.8180, -0.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08526721596717834
Epoch 0, Step 1137: train/loss = 0.4458543658256531, train/raw-loss = 0.3614419102668762, train/logprobs = tensor([[-0.8555, -2.0045],
        [-1.9644, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1688249111175537
Epoch 0, Step 1138: train/loss = 0.4394078850746155, train/raw-loss = 0.3634979724884033, train/logprobs = tensor([[-0.8950, -2.7919],
        [-1.0980, -0.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518198698759079
Epoch 0, Step 1139: train/loss = 0.38402870297431946, train/raw-loss = 0.2908257842063904, train/logprobs = tensor([[-1.5602, -3.4606],
        [-2.7127, -1.3594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18640579283237457
Epoch 0, Step 1140: train/loss = 0.4759405553340912, train/raw-loss = 0.41762182116508484, train/logprobs = tensor([[-0.6752, -2.2052],
        [-0.7855, -0.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1166374534368515
Epoch 0, Step 1141: train/loss = 0.3508870601654053, train/raw-loss = 0.28918567299842834, train/logprobs = tensor([[-0.9118, -4.1517],
        [-1.0675, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12340271472930908
Epoch 0, Step 1142: train/loss = 0.46298736333847046, train/raw-loss = 0.35134953260421753, train/logprobs = tensor([[-1.1579, -3.9210],
        [-3.0218, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22327564656734467
Epoch 0, Step 1143: train/loss = 0.463801771402359, train/raw-loss = 0.388514906167984, train/logprobs = tensor([[-0.8909, -4.7349],
        [-0.9304, -0.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1505737602710724
Epoch 0, Step 1144: train/loss = 0.3872537910938263, train/raw-loss = 0.3076575994491577, train/logprobs = tensor([[-1.1443, -3.3426],
        [-1.7653, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15919241309165955
Epoch 0, Step 1145: train/loss = 0.36975663900375366, train/raw-loss = 0.27800610661506653, train/logprobs = tensor([[-0.9336, -2.9971],
        [-2.7185, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18350109457969666
Epoch 0, Step 1146: train/loss = 0.4559303820133209, train/raw-loss = 0.37942636013031006, train/logprobs = tensor([[-1.0026, -2.9573],
        [-1.5914, -0.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15300801396369934
Epoch 0, Step 1147: train/loss = 0.5781569480895996, train/raw-loss = 0.5163160562515259, train/logprobs = tensor([[-0.6737, -1.5735],
        [-0.8066, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12368175387382507
Epoch 0, Step 1148: train/loss = 0.49264729022979736, train/raw-loss = 0.41813722252845764, train/logprobs = tensor([[-1.1418, -2.5126],
        [-1.6361, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14902010560035706
Epoch 0, Step 1149: train/loss = 0.5176582932472229, train/raw-loss = 0.45148277282714844, train/logprobs = tensor([[-0.7213, -1.8818],
        [-1.2599, -0.5133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13235099613666534
Epoch 0, Step 1150: train/loss = 0.4319314658641815, train/raw-loss = 0.3641461730003357, train/logprobs = tensor([[-0.6632, -3.9814],
        [-1.8557, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13557060062885284
Epoch 0, Step 1151: train/loss = 0.5154525637626648, train/raw-loss = 0.4506295323371887, train/logprobs = tensor([[-0.9039, -2.3464],
        [-1.0950, -0.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12964607775211334
Epoch 0, Step 1152: train/loss = 0.47685694694519043, train/raw-loss = 0.4047854542732239, train/logprobs = tensor([[-0.7535, -2.4742],
        [-1.8057, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14414307475090027
Epoch 0, Step 1153: train/loss = 0.48778218030929565, train/raw-loss = 0.42509549856185913, train/logprobs = tensor([[-0.6846, -2.0838],
        [-0.8694, -0.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12537333369255066
Epoch 0, Step 1154: train/loss = 0.5668566226959229, train/raw-loss = 0.4868251085281372, train/logprobs = tensor([[-0.6714, -1.3051],
        [-1.5218, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1600629985332489
Epoch 0, Step 1155: train/loss = 0.4211356043815613, train/raw-loss = 0.3502961993217468, train/logprobs = tensor([[-1.4520, -3.7862],
        [-2.5089, -1.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14167875051498413
Epoch 0, Step 1156: train/loss = 0.5092009902000427, train/raw-loss = 0.45908698439598083, train/logprobs = tensor([[-1.0451, -1.0269],
        [-1.7990, -0.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10022801905870438
Epoch 0, Step 1157: train/loss = 0.41445785760879517, train/raw-loss = 0.33211803436279297, train/logprobs = tensor([[-0.7598, -1.9374],
        [-2.5105, -0.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16467955708503723
Epoch 0, Step 1158: train/loss = 0.4390513300895691, train/raw-loss = 0.3673015534877777, train/logprobs = tensor([[-0.9924, -3.5690],
        [-1.6635, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14349961280822754
Epoch 0, Step 1159: train/loss = 0.5071392059326172, train/raw-loss = 0.43055588006973267, train/logprobs = tensor([[-0.7845, -2.4656],
        [-1.2119, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15316668152809143
Epoch 0, Step 1160: train/loss = 0.3857467770576477, train/raw-loss = 0.29309922456741333, train/logprobs = tensor([[-1.0452, -3.5770],
        [-2.0800, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18529504537582397
Epoch 0, Step 1161: train/loss = 0.31671202182769775, train/raw-loss = 0.23535339534282684, train/logprobs = tensor([[-0.9631, -4.4369],
        [-1.8839, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16271722316741943
Epoch 0, Step 1162: train/loss = 0.42159658670425415, train/raw-loss = 0.3482494354248047, train/logprobs = tensor([[-0.8502, -4.4220],
        [-1.1006, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14669419825077057
Epoch 0, Step 1163: train/loss = 0.4625242352485657, train/raw-loss = 0.3822764754295349, train/logprobs = tensor([[-1.6936, -5.0293],
        [-2.2150, -1.0693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16049550473690033
Epoch 0, Step 1164: train/loss = 0.41910266876220703, train/raw-loss = 0.344337522983551, train/logprobs = tensor([[-0.9873, -2.4292],
        [-2.1897, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1495303213596344
Epoch 0, Step 1165: train/loss = 0.5424407124519348, train/raw-loss = 0.48211514949798584, train/logprobs = tensor([[-0.6670, -2.0414],
        [-0.8878, -0.7198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12065105140209198
Epoch 0, Step 1166: train/loss = 0.4443817734718323, train/raw-loss = 0.37498295307159424, train/logprobs = tensor([[-1.0898, -3.8402],
        [-2.0110, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13879764080047607
Epoch 0, Step 1167: train/loss = 0.503300130367279, train/raw-loss = 0.4498126804828644, train/logprobs = tensor([[-0.5654, -1.7138],
        [-0.8629, -0.6160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10697487741708755
Epoch 0, Step 1168: train/loss = 0.38724029064178467, train/raw-loss = 0.2990063726902008, train/logprobs = tensor([[-1.0244, -3.2693],
        [-2.5081, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17646783590316772
Epoch 0, Step 1169: train/loss = 0.4465820789337158, train/raw-loss = 0.3784509301185608, train/logprobs = tensor([[-0.6788, -2.7744],
        [-1.6215, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13626228272914886
Epoch 0, Step 1170: train/loss = 0.4003181755542755, train/raw-loss = 0.3358674645423889, train/logprobs = tensor([[-1.1048, -3.0494],
        [-1.4092, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289014220237732
Epoch 0, Step 1171: train/loss = 0.5205276012420654, train/raw-loss = 0.45475274324417114, train/logprobs = tensor([[-0.7445, -1.9195],
        [-1.5092, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13154971599578857
Epoch 0, Step 1172: train/loss = 0.46600812673568726, train/raw-loss = 0.4073611795902252, train/logprobs = tensor([[-0.8056, -3.3586],
        [-0.5515, -0.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11729387938976288
Epoch 0, Step 1173: train/loss = 0.49315860867500305, train/raw-loss = 0.427089124917984, train/logprobs = tensor([[-1.1548, -2.4742],
        [-1.7401, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321389377117157
Epoch 0, Step 1174: train/loss = 0.7102808356285095, train/raw-loss = 0.627008855342865, train/logprobs = tensor([[-1.2414, -3.7973],
        [-1.9547, -2.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16654402017593384
Epoch 0, Step 1175: train/loss = 0.48415127396583557, train/raw-loss = 0.4147036075592041, train/logprobs = tensor([[-0.7559, -2.2361],
        [-1.0342, -0.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13889533281326294
Epoch 0, Step 1176: train/loss = 0.37262946367263794, train/raw-loss = 0.30439555644989014, train/logprobs = tensor([[-0.6559, -3.5468],
        [-1.4907, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13646778464317322
Epoch 0, Step 1177: train/loss = 0.3041832447052002, train/raw-loss = 0.21768862009048462, train/logprobs = tensor([[-0.5515, -3.2291],
        [-2.3915, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17298926413059235
Epoch 0, Step 1178: train/loss = 0.5209740400314331, train/raw-loss = 0.4581816792488098, train/logprobs = tensor([[-0.7304, -2.7736],
        [-0.8565, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12558473646640778
Epoch 0, Step 1179: train/loss = 0.4102412462234497, train/raw-loss = 0.323411226272583, train/logprobs = tensor([[-0.6904, -2.0966],
        [-2.5982, -0.5388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366008460521698
Epoch 0, Step 1180: train/loss = 0.510932445526123, train/raw-loss = 0.4237964451313019, train/logprobs = tensor([[-0.8863, -2.3324],
        [-1.1902, -0.7123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17427200078964233
Epoch 0, Step 1181: train/loss = 0.3587247133255005, train/raw-loss = 0.28365954756736755, train/logprobs = tensor([[-0.5086, -3.2365],
        [-1.7520, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15013036131858826
Epoch 0, Step 1182: train/loss = 0.33024680614471436, train/raw-loss = 0.2188061773777008, train/logprobs = tensor([[-0.6294, -3.1402],
        [-2.1217, -0.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2228812724351883
Epoch 0, Step 1183: train/loss = 0.5387916564941406, train/raw-loss = 0.45560842752456665, train/logprobs = tensor([[-1.0469, -3.6638],
        [-1.7036, -1.2727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16636642813682556
Epoch 0, Step 1184: train/loss = 0.48464903235435486, train/raw-loss = 0.42921197414398193, train/logprobs = tensor([[-0.9662, -2.9415],
        [-0.8675, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11087411642074585
Epoch 0, Step 1185: train/loss = 0.7743438482284546, train/raw-loss = 0.7262636423110962, train/logprobs = tensor([[-0.5149, -0.7417],
        [-0.9145, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09616048634052277
Epoch 0, Step 1186: train/loss = 0.6786123514175415, train/raw-loss = 0.6072260141372681, train/logprobs = tensor([[-0.9573, -1.5660],
        [-0.6032, -0.5100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14277267456054688
Epoch 0, Step 1187: train/loss = 0.6239683628082275, train/raw-loss = 0.5675521492958069, train/logprobs = tensor([[-1.4788, -4.3601],
        [-0.7907, -1.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11283238977193832
Epoch 0, Step 1188: train/loss = 0.6237731575965881, train/raw-loss = 0.5580762624740601, train/logprobs = tensor([[-1.0311, -1.9249],
        [-0.9838, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13139396905899048
Epoch 0, Step 1189: train/loss = 0.31543877720832825, train/raw-loss = 0.2300732135772705, train/logprobs = tensor([[-0.7989, -4.0830],
        [-2.8350, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17073111236095428
Epoch 0, Step 1190: train/loss = 0.7105404138565063, train/raw-loss = 0.627124011516571, train/logprobs = tensor([[-1.0578, -3.0802],
        [-2.6947, -2.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16683267056941986
Epoch 0, Step 1191: train/loss = 0.3837602138519287, train/raw-loss = 0.30843573808670044, train/logprobs = tensor([[-0.7101, -3.8002],
        [-1.1362, -0.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15064892172813416
Epoch 0, Step 1192: train/loss = 0.4713061451911926, train/raw-loss = 0.40405404567718506, train/logprobs = tensor([[-0.8349, -3.5749],
        [-0.8343, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1345042884349823
Epoch 0, Step 1193: train/loss = 0.7472854852676392, train/raw-loss = 0.678315281867981, train/logprobs = tensor([[-0.9591, -2.4308],
        [-1.5635, -1.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1379404217004776
Epoch 0, Step 1194: train/loss = 0.38828060030937195, train/raw-loss = 0.3141551613807678, train/logprobs = tensor([[-0.7622, -1.7387],
        [-2.5602, -0.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14825086295604706
Epoch 0, Step 1195: train/loss = 0.43249768018722534, train/raw-loss = 0.35447958111763, train/logprobs = tensor([[-0.9295, -2.3991],
        [-1.4516, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15603619813919067
Epoch 0, Step 1196: train/loss = 0.41071945428848267, train/raw-loss = 0.3337368071079254, train/logprobs = tensor([[-0.9235, -3.5124],
        [-1.5300, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15396533906459808
Epoch 0, Step 1197: train/loss = 0.584659218788147, train/raw-loss = 0.5175156593322754, train/logprobs = tensor([[-0.8602, -3.5044],
        [-0.9581, -1.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13428714871406555
Epoch 0, Step 1198: train/loss = 0.48836958408355713, train/raw-loss = 0.4162343442440033, train/logprobs = tensor([[-1.3803, -3.2502],
        [-1.6931, -1.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14427050948143005
Epoch 0, Step 1199: train/loss = 0.4735010266304016, train/raw-loss = 0.4046231508255005, train/logprobs = tensor([[-0.4662, -1.6834],
        [-1.2429, -0.5565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13775578141212463
Epoch 0, Step 1200: train/loss = 0.5081447958946228, train/raw-loss = 0.435910165309906, train/logprobs = tensor([[-0.8852, -2.0200],
        [-1.4988, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444692313671112
Epoch 0, Step 1201: train/loss = 0.3129209578037262, train/raw-loss = 0.23150479793548584, train/logprobs = tensor([[-1.3408, -4.2242],
        [-2.6077, -1.4231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1628323644399643
Epoch 0, Step 1202: train/loss = 0.4141398072242737, train/raw-loss = 0.34889382123947144, train/logprobs = tensor([[-0.9475, -2.8965],
        [-1.4975, -1.0775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13049191236495972
Epoch 0, Step 1203: train/loss = 0.5745731592178345, train/raw-loss = 0.5182980298995972, train/logprobs = tensor([[-0.5974, -1.0862],
        [-0.9456, -0.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11255033314228058
Epoch 0, Step 1204: train/loss = 0.5427402257919312, train/raw-loss = 0.45004913210868835, train/logprobs = tensor([[-1.2324, -2.0245],
        [-1.6687, -0.4850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1853821724653244
Epoch 0, Step 1205: train/loss = 0.48506784439086914, train/raw-loss = 0.4104248881340027, train/logprobs = tensor([[-1.0886, -3.2660],
        [-0.7994, -0.7643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492859423160553
Epoch 0, Step 1206: train/loss = 0.526742160320282, train/raw-loss = 0.4218289852142334, train/logprobs = tensor([[-1.2951, -2.9591],
        [-1.8720, -0.9839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20982639491558075
Epoch 0, Step 1207: train/loss = 0.47315484285354614, train/raw-loss = 0.3759792149066925, train/logprobs = tensor([[-1.2688, -2.7108],
        [-1.9410, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19435136020183563
Epoch 0, Step 1208: train/loss = 0.4883693754673004, train/raw-loss = 0.41529643535614014, train/logprobs = tensor([[-0.8455, -3.1321],
        [-1.2465, -0.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14614582061767578
Epoch 0, Step 1209: train/loss = 0.5151119232177734, train/raw-loss = 0.4348636567592621, train/logprobs = tensor([[-0.9879, -1.7550],
        [-1.8831, -0.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16049645841121674
Epoch 0, Step 1210: train/loss = 0.9851484298706055, train/raw-loss = 0.9173111915588379, train/logprobs = tensor([[-2.0278, -2.2249],
        [-1.1668, -1.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13567447662353516
Epoch 0, Step 1211: train/loss = 0.5167810320854187, train/raw-loss = 0.4425109028816223, train/logprobs = tensor([[-0.7369, -3.2541],
        [-1.0850, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14854025840759277
Epoch 0, Step 1212: train/loss = 0.4522969722747803, train/raw-loss = 0.38197943568229675, train/logprobs = tensor([[-0.6267, -3.2282],
        [-0.9471, -0.9229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14063508808612823
Epoch 0, Step 1213: train/loss = 0.45222312211990356, train/raw-loss = 0.37322795391082764, train/logprobs = tensor([[-1.0195, -2.8619],
        [-1.2661, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15799030661582947
Epoch 0, Step 1214: train/loss = 0.488821804523468, train/raw-loss = 0.42378443479537964, train/logprobs = tensor([[-0.9097, -2.8130],
        [-1.8401, -0.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13007473945617676
Epoch 0, Step 1215: train/loss = 0.5433098673820496, train/raw-loss = 0.4663528800010681, train/logprobs = tensor([[-1.1295, -1.7464],
        [-2.3308, -0.8069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15391398966312408
Epoch 0, Step 1216: train/loss = 0.4649154841899872, train/raw-loss = 0.39532554149627686, train/logprobs = tensor([[-0.5731, -2.5453],
        [-0.8843, -0.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13917984068393707
Epoch 0, Step 1217: train/loss = 0.34116458892822266, train/raw-loss = 0.256127268075943, train/logprobs = tensor([[-0.9333, -4.3673],
        [-1.4149, -1.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1700747162103653
Epoch 0, Step 1218: train/loss = 0.29167261719703674, train/raw-loss = 0.20084841549396515, train/logprobs = tensor([[-1.0086, -4.2686],
        [-2.8775, -1.2283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816483587026596
Epoch 0, Step 1219: train/loss = 0.6588608026504517, train/raw-loss = 0.6089488863945007, train/logprobs = tensor([[-1.3105, -1.4429],
        [-1.1778, -0.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09982380270957947
Epoch 0, Step 1220: train/loss = 0.56410813331604, train/raw-loss = 0.484647274017334, train/logprobs = tensor([[-1.2042, -3.6176],
        [-1.6481, -1.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589217334985733
Epoch 0, Step 1221: train/loss = 0.5058801174163818, train/raw-loss = 0.4475899636745453, train/logprobs = tensor([[-0.5741, -2.5671],
        [-0.6443, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11658035218715668
Epoch 0, Step 1222: train/loss = 0.5096230506896973, train/raw-loss = 0.45001500844955444, train/logprobs = tensor([[-0.4433, -1.9155],
        [-1.3752, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11921612918376923
Epoch 0, Step 1223: train/loss = 0.4236116111278534, train/raw-loss = 0.34043124318122864, train/logprobs = tensor([[-0.8411, -1.3223],
        [-3.1399, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16636069118976593
Epoch 0, Step 1224: train/loss = 0.5793259143829346, train/raw-loss = 0.523638129234314, train/logprobs = tensor([[-0.7267, -1.7888],
        [-0.7241, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11137568950653076
Epoch 0, Step 1225: train/loss = 0.8749175071716309, train/raw-loss = 0.8015314936637878, train/logprobs = tensor([[-0.7458, -3.3906],
        [-0.9042, -1.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14677207171916962
Epoch 0, Step 1226: train/loss = 0.4666023254394531, train/raw-loss = 0.37076297402381897, train/logprobs = tensor([[-1.4485, -3.1974],
        [-2.6703, -0.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19167876243591309
Epoch 0, Step 1227: train/loss = 0.3580932021141052, train/raw-loss = 0.28820839524269104, train/logprobs = tensor([[-0.7349, -4.4962],
        [-1.2133, -1.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13976962864398956
Epoch 0, Step 1228: train/loss = 0.5034062266349792, train/raw-loss = 0.4497039020061493, train/logprobs = tensor([[-0.5769, -2.0264],
        [-0.7218, -0.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10740460455417633
Epoch 0, Step 1229: train/loss = 0.4198448061943054, train/raw-loss = 0.35365280508995056, train/logprobs = tensor([[-0.5627, -3.8752],
        [-1.4502, -1.2354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13238400220870972
Epoch 0, Step 1230: train/loss = 0.6313627362251282, train/raw-loss = 0.5748331546783447, train/logprobs = tensor([[-0.6594, -1.0470],
        [-0.8879, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11305917054414749
Epoch 0, Step 1231: train/loss = 0.3755972981452942, train/raw-loss = 0.29701751470565796, train/logprobs = tensor([[-0.9143, -2.9913],
        [-2.3007, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15715955197811127
Epoch 0, Step 1232: train/loss = 0.40217071771621704, train/raw-loss = 0.3352890610694885, train/logprobs = tensor([[-0.6547, -3.1841],
        [-0.7907, -0.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1337633579969406
Epoch 0, Step 1233: train/loss = 0.4057232141494751, train/raw-loss = 0.33643287420272827, train/logprobs = tensor([[-0.5692, -3.2010],
        [-1.4895, -0.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13858063519001007
Epoch 0, Step 1234: train/loss = 0.6060503721237183, train/raw-loss = 0.5375438332557678, train/logprobs = tensor([[-1.0687, -2.3707],
        [-1.0906, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13701315224170685
Epoch 0, Step 1235: train/loss = 0.4902835190296173, train/raw-loss = 0.4356868267059326, train/logprobs = tensor([[-0.4201, -2.4543],
        [-0.7050, -0.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10919336974620819
Epoch 0, Step 1236: train/loss = 0.35899612307548523, train/raw-loss = 0.276133269071579, train/logprobs = tensor([[-0.8312, -2.1239],
        [-2.4473, -0.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1657257229089737
Epoch 0, Step 1237: train/loss = 0.3592804968357086, train/raw-loss = 0.2803695797920227, train/logprobs = tensor([[-0.7928, -4.7391],
        [-1.9160, -1.2522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15782183408737183
Epoch 0, Step 1238: train/loss = 0.4661194384098053, train/raw-loss = 0.39859628677368164, train/logprobs = tensor([[-0.6305, -2.9578],
        [-0.9725, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350463181734085
Epoch 0, Step 1239: train/loss = 0.4521902799606323, train/raw-loss = 0.38540345430374146, train/logprobs = tensor([[-0.8577, -2.6487],
        [-1.1707, -0.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13357360661029816
Epoch 0, Step 1240: train/loss = 0.6499743461608887, train/raw-loss = 0.5560818910598755, train/logprobs = tensor([[-0.5964, -1.4777],
        [-2.1386, -1.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18778491020202637
Epoch 0, Step 1241: train/loss = 0.34006765484809875, train/raw-loss = 0.278472363948822, train/logprobs = tensor([[-0.7142, -2.9158],
        [-2.9446, -0.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12319058924913406
Epoch 0, Step 1242: train/loss = 0.38678687810897827, train/raw-loss = 0.29725199937820435, train/logprobs = tensor([[-0.6803, -2.5243],
        [-1.9568, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17906978726387024
Epoch 0, Step 1243: train/loss = 0.46698325872421265, train/raw-loss = 0.39816638827323914, train/logprobs = tensor([[-1.2234, -4.1850],
        [-1.0369, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13763372600078583
Epoch 0, Step 1244: train/loss = 0.41407665610313416, train/raw-loss = 0.34824836254119873, train/logprobs = tensor([[-0.9654, -3.5431],
        [-2.2215, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13165652751922607
Epoch 0, Step 1245: train/loss = 0.4360099136829376, train/raw-loss = 0.3582676649093628, train/logprobs = tensor([[-1.2176, -4.1390],
        [-2.1760, -1.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15548446774482727
Epoch 0, Step 1246: train/loss = 0.27695319056510925, train/raw-loss = 0.19623637199401855, train/logprobs = tensor([[-0.9227, -5.2987],
        [-1.7080, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16143359243869781
Epoch 0, Step 1247: train/loss = 0.7584989666938782, train/raw-loss = 0.6909546852111816, train/logprobs = tensor([[-2.7183, -3.9159],
        [-1.7550, -1.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350884735584259
Epoch 0, Step 1248: train/loss = 0.3856411874294281, train/raw-loss = 0.31293588876724243, train/logprobs = tensor([[-0.6594, -3.9089],
        [-1.7069, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14541056752204895
Epoch 0, Step 1249: train/loss = 0.46714597940444946, train/raw-loss = 0.395997554063797, train/logprobs = tensor([[-0.6688, -2.5935],
        [-1.4255, -0.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422969400882721
Epoch 0, Step 1250: train/loss = 0.30438119173049927, train/raw-loss = 0.23288413882255554, train/logprobs = tensor([[-0.9625, -3.8170],
        [-2.3276, -1.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14299410581588745
Epoch 0, Step 1251: train/loss = 0.4741608202457428, train/raw-loss = 0.40087711811065674, train/logprobs = tensor([[-0.5683, -1.3016],
        [-2.3709, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465674340724945
Epoch 0, Step 1252: train/loss = 0.6475217342376709, train/raw-loss = 0.5651819705963135, train/logprobs = tensor([[-1.1068, -2.7734],
        [-1.8132, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16467952728271484
Epoch 0, Step 1253: train/loss = 0.4315824508666992, train/raw-loss = 0.3781293034553528, train/logprobs = tensor([[-0.6554, -4.3927],
        [-1.0234, -1.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10690627247095108
Epoch 0, Step 1254: train/loss = 0.4715220332145691, train/raw-loss = 0.4090264141559601, train/logprobs = tensor([[-0.5445, -2.7778],
        [-0.5987, -0.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12499117106199265
Epoch 0, Step 1255: train/loss = 0.4007316529750824, train/raw-loss = 0.32454174757003784, train/logprobs = tensor([[-0.7730, -2.4897],
        [-2.2637, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15237976610660553
Epoch 0, Step 1256: train/loss = 0.645665168762207, train/raw-loss = 0.5898070931434631, train/logprobs = tensor([[-0.7152, -1.3899],
        [-0.5653, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11171615123748779
Epoch 0, Step 1257: train/loss = 0.6773399114608765, train/raw-loss = 0.6185338497161865, train/logprobs = tensor([[-1.2946, -2.2381],
        [-1.4086, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761205643415451
Epoch 0, Step 1258: train/loss = 0.45322054624557495, train/raw-loss = 0.3917173147201538, train/logprobs = tensor([[-0.5117, -3.4831],
        [-1.0408, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12300650030374527
Epoch 0, Step 1259: train/loss = 0.4417937397956848, train/raw-loss = 0.37484773993492126, train/logprobs = tensor([[-0.7480, -4.5819],
        [-1.2803, -1.1528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1338919699192047
Epoch 0, Step 1260: train/loss = 0.47196856141090393, train/raw-loss = 0.3962249159812927, train/logprobs = tensor([[-0.6555, -2.3216],
        [-1.4934, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514873206615448
Epoch 0, Step 1261: train/loss = 0.5545244812965393, train/raw-loss = 0.4930865168571472, train/logprobs = tensor([[-1.4576, -2.8956],
        [-1.4710, -1.2665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12287598848342896
Epoch 0, Step 1262: train/loss = 0.824530303478241, train/raw-loss = 0.7369306087493896, train/logprobs = tensor([[-2.3439, -3.7366],
        [-1.4938, -1.2709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17519932985305786
Epoch 0, Step 1263: train/loss = 0.5064915418624878, train/raw-loss = 0.453037291765213, train/logprobs = tensor([[-0.4929, -2.8239],
        [-0.5802, -0.8129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10690846294164658
Epoch 0, Step 1264: train/loss = 0.5607626438140869, train/raw-loss = 0.5166628360748291, train/logprobs = tensor([[-0.7385, -1.5994],
        [-0.9103, -0.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08819963037967682
Epoch 0, Step 1265: train/loss = 0.4186480641365051, train/raw-loss = 0.3455926179885864, train/logprobs = tensor([[-0.7005, -3.6504],
        [-2.0697, -1.8416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14611083269119263
Epoch 0, Step 1266: train/loss = 0.2686743140220642, train/raw-loss = 0.17294426262378693, train/logprobs = tensor([[-0.7474, -3.7366],
        [-2.8657, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19146005809307098
Epoch 0, Step 1267: train/loss = 0.3513305187225342, train/raw-loss = 0.2770370841026306, train/logprobs = tensor([[-0.8479, -5.4751],
        [-1.3072, -1.2012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1485869139432907
Epoch 0, Step 1268: train/loss = 0.5278926491737366, train/raw-loss = 0.47660526633262634, train/logprobs = tensor([[-0.5577, -4.1792],
        [-0.5361, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10257481038570404
Epoch 0, Step 1269: train/loss = 0.5680685639381409, train/raw-loss = 0.5109150409698486, train/logprobs = tensor([[-0.8319, -2.3490],
        [-0.8112, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1143069639801979
Epoch 0, Step 1270: train/loss = 0.32183659076690674, train/raw-loss = 0.23527656495571136, train/logprobs = tensor([[-0.8133, -4.3163],
        [-2.4680, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17312002182006836
Epoch 0, Step 1271: train/loss = 0.4383866786956787, train/raw-loss = 0.3724674880504608, train/logprobs = tensor([[-1.1805, -5.0386],
        [-1.3206, -1.2359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13183841109275818
Epoch 0, Step 1272: train/loss = 0.5343016982078552, train/raw-loss = 0.46829158067703247, train/logprobs = tensor([[-0.5786, -2.2192],
        [-0.7588, -0.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320202797651291
Epoch 0, Step 1273: train/loss = 0.47221148014068604, train/raw-loss = 0.4025835394859314, train/logprobs = tensor([[-1.1182, -4.8509],
        [-0.8396, -1.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13925589621067047
Epoch 0, Step 1274: train/loss = 0.4585146903991699, train/raw-loss = 0.37449273467063904, train/logprobs = tensor([[-1.1465, -4.8223],
        [-1.5864, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16804389655590057
Epoch 0, Step 1275: train/loss = 0.28913241624832153, train/raw-loss = 0.20755243301391602, train/logprobs = tensor([[-0.9000, -4.4829],
        [-1.5430, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16315995156764984
Epoch 0, Step 1276: train/loss = 0.5124756693840027, train/raw-loss = 0.45244842767715454, train/logprobs = tensor([[-0.6061, -1.2264],
        [-1.7027, -0.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12005451321601868
Epoch 0, Step 1277: train/loss = 0.529591977596283, train/raw-loss = 0.477957159280777, train/logprobs = tensor([[-0.5394, -1.5590],
        [-0.9154, -0.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10326967388391495
Epoch 0, Step 1278: train/loss = 0.47898173332214355, train/raw-loss = 0.4198766052722931, train/logprobs = tensor([[-0.9449, -3.0500],
        [-0.8446, -0.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11821028590202332
Epoch 0, Step 1279: train/loss = 0.34588778018951416, train/raw-loss = 0.25943005084991455, train/logprobs = tensor([[-0.7442, -3.2644],
        [-2.8137, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17291536927223206
Epoch 0, Step 1280: train/loss = 0.4158260226249695, train/raw-loss = 0.35981518030166626, train/logprobs = tensor([[-0.8102, -3.6253],
        [-1.0702, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11202163249254227
Epoch 0, Step 1281: train/loss = 0.6062197089195251, train/raw-loss = 0.5426020622253418, train/logprobs = tensor([[-1.2055, -2.8861],
        [-0.6589, -0.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272352635860443
Epoch 0, Step 1282: train/loss = 0.5322893261909485, train/raw-loss = 0.4672899842262268, train/logprobs = tensor([[-1.1992, -4.0910],
        [-1.4421, -1.3965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129998579621315
Epoch 0, Step 1283: train/loss = 0.5500932931900024, train/raw-loss = 0.48734211921691895, train/logprobs = tensor([[-0.8089, -1.4588],
        [-1.0750, -0.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12550240755081177
Epoch 0, Step 1284: train/loss = 0.5922213196754456, train/raw-loss = 0.5396116375923157, train/logprobs = tensor([[-0.5123, -1.3460],
        [-0.6307, -0.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10521934926509857
Epoch 0, Step 1285: train/loss = 0.4111689627170563, train/raw-loss = 0.33337536454200745, train/logprobs = tensor([[-0.6846, -2.4208],
        [-1.7595, -0.5856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15558719635009766
Epoch 0, Step 1286: train/loss = 0.6859826445579529, train/raw-loss = 0.627557098865509, train/logprobs = tensor([[-0.7757, -1.1505],
        [-1.1483, -1.0584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685110628604889
Epoch 0, Step 1287: train/loss = 0.4981882870197296, train/raw-loss = 0.44228920340538025, train/logprobs = tensor([[-0.5363, -1.9897],
        [-0.6637, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11179819703102112
Epoch 0, Step 1288: train/loss = 0.5687262415885925, train/raw-loss = 0.4945933222770691, train/logprobs = tensor([[-0.7398, -1.1889],
        [-1.6955, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14826594293117523
Epoch 0, Step 1289: train/loss = 0.6390748620033264, train/raw-loss = 0.5621916055679321, train/logprobs = tensor([[-0.9061, -2.1354],
        [-2.7102, -1.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.153766468167305
Epoch 0, Step 1290: train/loss = 0.37604859471321106, train/raw-loss = 0.3033812642097473, train/logprobs = tensor([[-0.7729, -3.5388],
        [-1.5914, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14533473551273346
Epoch 0, Step 1291: train/loss = 0.4530172348022461, train/raw-loss = 0.3943262994289398, train/logprobs = tensor([[-0.6093, -2.1040],
        [-1.3629, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1173819825053215
Epoch 0, Step 1292: train/loss = 0.3584374487400055, train/raw-loss = 0.27826550602912903, train/logprobs = tensor([[-0.6276, -3.1927],
        [-2.3326, -0.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16034382581710815
Epoch 0, Step 1293: train/loss = 0.5129458904266357, train/raw-loss = 0.4538479447364807, train/logprobs = tensor([[-0.5383, -1.7789],
        [-1.4374, -0.5741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11819592863321304
Epoch 0, Step 1294: train/loss = 0.40579456090927124, train/raw-loss = 0.3437579870223999, train/logprobs = tensor([[-0.6456, -3.1996],
        [-0.8034, -0.7096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407312542200089
Epoch 0, Step 1295: train/loss = 0.45191290974617004, train/raw-loss = 0.37878677248954773, train/logprobs = tensor([[-0.9087, -3.4791],
        [-1.8281, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14625227451324463
Epoch 0, Step 1296: train/loss = 0.5078681707382202, train/raw-loss = 0.44970086216926575, train/logprobs = tensor([[-0.8655, -2.4266],
        [-1.6920, -1.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11633464694023132
Epoch 0, Step 1297: train/loss = 0.4774536192417145, train/raw-loss = 0.4132031202316284, train/logprobs = tensor([[-0.7003, -1.8665],
        [-1.4657, -0.5476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12850096821784973
Epoch 0, Step 1298: train/loss = 0.5684677362442017, train/raw-loss = 0.5062164664268494, train/logprobs = tensor([[-1.3663, -2.5173],
        [-1.4764, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12450248003005981
Epoch 0, Step 1299: train/loss = 0.5046879649162292, train/raw-loss = 0.44972267746925354, train/logprobs = tensor([[-0.8989, -2.7354],
        [-0.9496, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10993053019046783
Epoch 0, Step 1300: train/loss = 0.5480940341949463, train/raw-loss = 0.49937641620635986, train/logprobs = tensor([[-0.4302, -1.8727],
        [-0.6033, -0.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09743525832891464
Epoch 0, Step 1301: train/loss = 0.3908572494983673, train/raw-loss = 0.3055826425552368, train/logprobs = tensor([[-0.8155, -2.7836],
        [-1.4260, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17054924368858337
Epoch 0, Step 1302: train/loss = 0.5208908319473267, train/raw-loss = 0.458721399307251, train/logprobs = tensor([[-0.6716, -1.2367],
        [-1.8915, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12433873862028122
Epoch 0, Step 1303: train/loss = 0.6174960136413574, train/raw-loss = 0.5421860218048096, train/logprobs = tensor([[-1.4459, -3.7378],
        [-1.7764, -0.9437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1506199836730957
Epoch 0, Step 1304: train/loss = 0.40722137689590454, train/raw-loss = 0.3300631642341614, train/logprobs = tensor([[-0.7007, -2.3556],
        [-2.3412, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15431642532348633
Epoch 0, Step 1305: train/loss = 0.34771728515625, train/raw-loss = 0.28067001700401306, train/logprobs = tensor([[-0.7034, -6.4218],
        [-1.8834, -1.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1340944916009903
Epoch 0, Step 1306: train/loss = 0.4918537735939026, train/raw-loss = 0.42603185772895813, train/logprobs = tensor([[-0.9302, -2.2799],
        [-1.5545, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13164380192756653
Epoch 0, Step 1307: train/loss = 0.5091853737831116, train/raw-loss = 0.43037235736846924, train/logprobs = tensor([[-1.2335, -2.9872],
        [-1.7308, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15762603282928467
Epoch 0, Step 1308: train/loss = 0.5814720988273621, train/raw-loss = 0.5201752185821533, train/logprobs = tensor([[-0.7492, -2.0750],
        [-1.1462, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12259378284215927
Epoch 0, Step 1309: train/loss = 0.5251516103744507, train/raw-loss = 0.46849340200424194, train/logprobs = tensor([[-0.7340, -3.3814],
        [-0.8014, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11331631243228912
Epoch 0, Step 1310: train/loss = 0.5557922124862671, train/raw-loss = 0.49154767394065857, train/logprobs = tensor([[-0.8203, -2.0663],
        [-1.0332, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.128489151597023
Epoch 0, Step 1311: train/loss = 0.37346285581588745, train/raw-loss = 0.3089950680732727, train/logprobs = tensor([[-0.7336, -4.1216],
        [-1.5680, -1.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289355754852295
Epoch 0, Step 1312: train/loss = 0.7508985996246338, train/raw-loss = 0.6931843161582947, train/logprobs = tensor([[-1.0640, -1.0888],
        [-0.8236, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11542868614196777
Epoch 0, Step 1313: train/loss = 0.4971410036087036, train/raw-loss = 0.4301111400127411, train/logprobs = tensor([[-0.9181, -1.2519],
        [-2.7661, -0.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13405968248844147
Epoch 0, Step 1314: train/loss = 0.7042379379272461, train/raw-loss = 0.6485680341720581, train/logprobs = tensor([[-0.6371, -1.4011],
        [-1.4484, -1.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11133978515863419
Epoch 0, Step 1315: train/loss = 0.4353313446044922, train/raw-loss = 0.3610629439353943, train/logprobs = tensor([[-0.6910, -2.8366],
        [-1.2381, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1485368013381958
Epoch 0, Step 1316: train/loss = 0.3522879481315613, train/raw-loss = 0.26866286993026733, train/logprobs = tensor([[-0.5360, -4.6543],
        [-2.7250, -0.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16725009679794312
Epoch 0, Step 1317: train/loss = 0.48406335711479187, train/raw-loss = 0.42732784152030945, train/logprobs = tensor([[-0.5957, -2.3239],
        [-0.8595, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11347110569477081
Epoch 0, Step 1318: train/loss = 0.49364882707595825, train/raw-loss = 0.44531482458114624, train/logprobs = tensor([[-1.6446, -2.9710],
        [-2.0394, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09666799008846283
Epoch 0, Step 1319: train/loss = 0.5009753704071045, train/raw-loss = 0.44121044874191284, train/logprobs = tensor([[-0.8254, -1.9104],
        [-1.7841, -0.5650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11952982097864151
Epoch 0, Step 1320: train/loss = 0.2251979559659958, train/raw-loss = 0.13088367879390717, train/logprobs = tensor([[-0.9405, -6.0882],
        [-2.4651, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18862856924533844
Epoch 0, Step 1321: train/loss = 0.4266997277736664, train/raw-loss = 0.35614433884620667, train/logprobs = tensor([[-0.9530, -1.7654],
        [-2.6806, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411108523607254
Epoch 0, Step 1322: train/loss = 0.2412983477115631, train/raw-loss = 0.17112089693546295, train/logprobs = tensor([[-0.6856, -4.7134],
        [-2.2085, -0.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403549164533615
Epoch 0, Step 1323: train/loss = 0.40182918310165405, train/raw-loss = 0.3337098956108093, train/logprobs = tensor([[-0.7514, -2.6595],
        [-2.4045, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13623861968517303
Epoch 0, Step 1324: train/loss = 0.4495948255062103, train/raw-loss = 0.3788800835609436, train/logprobs = tensor([[-0.7453, -1.7262],
        [-2.1145, -0.6141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14142951369285583
Epoch 0, Step 1325: train/loss = 0.6005963683128357, train/raw-loss = 0.5402348041534424, train/logprobs = tensor([[-0.6501, -1.5386],
        [-0.7969, -0.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12072310596704483
Epoch 0, Step 1326: train/loss = 0.6135762929916382, train/raw-loss = 0.5396764874458313, train/logprobs = tensor([[-1.1773, -1.6188],
        [-1.7851, -0.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14779959619045258
Epoch 0, Step 1327: train/loss = 0.5142761468887329, train/raw-loss = 0.42774757742881775, train/logprobs = tensor([[-1.4300, -2.3957],
        [-1.9281, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17305727303028107
Epoch 0, Step 1328: train/loss = 0.7917187213897705, train/raw-loss = 0.7139930725097656, train/logprobs = tensor([[-0.5317, -1.2245],
        [-2.5208, -1.5496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15545129776000977
Epoch 0, Step 1329: train/loss = 0.43083566427230835, train/raw-loss = 0.3605155348777771, train/logprobs = tensor([[-0.6290, -2.0002],
        [-1.5678, -0.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406402438879013
Epoch 0, Step 1330: train/loss = 0.3350268006324768, train/raw-loss = 0.2377396672964096, train/logprobs = tensor([[-1.2779, -3.7977],
        [-2.9554, -1.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.194574236869812
Epoch 0, Step 1331: train/loss = 0.4637792110443115, train/raw-loss = 0.3839280605316162, train/logprobs = tensor([[-0.9634, -2.6718],
        [-2.8728, -1.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1597023755311966
Epoch 0, Step 1332: train/loss = 0.5534656643867493, train/raw-loss = 0.4910416007041931, train/logprobs = tensor([[-1.1793, -1.9440],
        [-1.6582, -0.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12484818696975708
Epoch 0, Step 1333: train/loss = 0.6140669584274292, train/raw-loss = 0.5518412590026855, train/logprobs = tensor([[-0.5865, -2.1305],
        [-0.9575, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12445132434368134
Epoch 0, Step 1334: train/loss = 0.5352800488471985, train/raw-loss = 0.46390390396118164, train/logprobs = tensor([[-0.9392, -2.6130],
        [-0.9529, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427522897720337
Epoch 0, Step 1335: train/loss = 0.5300249457359314, train/raw-loss = 0.46902546286582947, train/logprobs = tensor([[-0.6958, -2.3581],
        [-0.6671, -0.5821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12199899554252625
Epoch 0, Step 1336: train/loss = 0.5345324277877808, train/raw-loss = 0.4703226685523987, train/logprobs = tensor([[-0.8623, -2.5319],
        [-0.9326, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12841948866844177
Epoch 0, Step 1337: train/loss = 0.4782141149044037, train/raw-loss = 0.41152793169021606, train/logprobs = tensor([[-1.3592, -1.3845],
        [-2.7328, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13337232172489166
Epoch 0, Step 1338: train/loss = 0.5974639058113098, train/raw-loss = 0.5354095697402954, train/logprobs = tensor([[-0.6273, -2.2971],
        [-0.5734, -0.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12410861253738403
Epoch 0, Step 1339: train/loss = 0.42783620953559875, train/raw-loss = 0.3653084635734558, train/logprobs = tensor([[-0.4489, -1.8151],
        [-1.7679, -0.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12505550682544708
Epoch 0, Step 1340: train/loss = 0.33121365308761597, train/raw-loss = 0.24444344639778137, train/logprobs = tensor([[-0.5470, -3.5339],
        [-3.0348, -0.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735404133796692
Epoch 0, Step 1341: train/loss = 0.5100188851356506, train/raw-loss = 0.4563932418823242, train/logprobs = tensor([[-0.7183, -1.7892],
        [-0.8662, -0.4289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10725130885839462
Epoch 0, Step 1342: train/loss = 0.49111101031303406, train/raw-loss = 0.42644423246383667, train/logprobs = tensor([[-0.7518, -1.9603],
        [-1.4995, -0.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1293335258960724
Epoch 0, Step 1343: train/loss = 0.32588431239128113, train/raw-loss = 0.25750643014907837, train/logprobs = tensor([[-0.8109, -6.1612],
        [-1.9471, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1367558240890503
Epoch 0, Step 1344: train/loss = 0.30375850200653076, train/raw-loss = 0.23420387506484985, train/logprobs = tensor([[-0.8227, -1.9334],
        [-2.9710, -0.6050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13910922408103943
Epoch 0, Step 1345: train/loss = 0.22215606272220612, train/raw-loss = 0.13717415928840637, train/logprobs = tensor([[-0.4749, -3.7151],
        [-3.6327, -0.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1699638068675995
Epoch 0, Step 1346: train/loss = 0.45616811513900757, train/raw-loss = 0.37619078159332275, train/logprobs = tensor([[-0.8566, -3.5452],
        [-1.7819, -1.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15995463728904724
Epoch 0, Step 1347: train/loss = 0.5684959888458252, train/raw-loss = 0.5154491662979126, train/logprobs = tensor([[-0.4798, -1.3025],
        [-0.7670, -0.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10609357059001923
Epoch 0, Step 1348: train/loss = 0.4944538474082947, train/raw-loss = 0.44861751794815063, train/logprobs = tensor([[-0.8543, -1.6645],
        [-1.4477, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916726291179657
Epoch 0, Step 1349: train/loss = 0.5339247584342957, train/raw-loss = 0.4832228124141693, train/logprobs = tensor([[-0.4789, -1.8362],
        [-0.5141, -0.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10140389204025269
Epoch 0, Step 1350: train/loss = 0.4109041094779968, train/raw-loss = 0.34051963686943054, train/logprobs = tensor([[-0.7950, -1.9003],
        [-2.0616, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14076898992061615
Epoch 0, Step 1351: train/loss = 0.4368189573287964, train/raw-loss = 0.369159996509552, train/logprobs = tensor([[-1.2366, -1.8955],
        [-1.9847, -0.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13531798124313354
Epoch 0, Step 1352: train/loss = 0.3985666036605835, train/raw-loss = 0.33942264318466187, train/logprobs = tensor([[-0.7164, -3.6757],
        [-0.8858, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11828789114952087
Epoch 0, Step 1353: train/loss = 0.4605940580368042, train/raw-loss = 0.39609071612358093, train/logprobs = tensor([[-0.8846, -2.5654],
        [-1.6644, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12900671362876892
Epoch 0, Step 1354: train/loss = 0.36196988821029663, train/raw-loss = 0.3013722598552704, train/logprobs = tensor([[-0.5893, -4.1576],
        [-1.0306, -1.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12119527161121368
Epoch 0, Step 1355: train/loss = 0.5263005495071411, train/raw-loss = 0.4629933834075928, train/logprobs = tensor([[-0.4612, -1.7553],
        [-0.9940, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12661436200141907
Epoch 0, Step 1356: train/loss = 0.6485365629196167, train/raw-loss = 0.5901496410369873, train/logprobs = tensor([[-0.6705, -0.9634],
        [-0.8344, -0.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11677372455596924
Epoch 0, Step 1357: train/loss = 0.6252908706665039, train/raw-loss = 0.587995171546936, train/logprobs = tensor([[-0.4469, -1.1470],
        [-0.5452, -0.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0745915025472641
Epoch 0, Step 1358: train/loss = 0.42638301849365234, train/raw-loss = 0.35370540618896484, train/logprobs = tensor([[-0.6758, -2.7366],
        [-1.7128, -0.7309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14535516500473022
Epoch 0, Step 1359: train/loss = 0.3172649145126343, train/raw-loss = 0.2496139258146286, train/logprobs = tensor([[-0.3868, -3.9633],
        [-0.9724, -0.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13530199229717255
Epoch 0, Step 1360: train/loss = 0.4281582236289978, train/raw-loss = 0.37200385332107544, train/logprobs = tensor([[-0.6209, -2.6297],
        [-1.0135, -0.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1123087927699089
Epoch 0, Step 1361: train/loss = 0.5352106094360352, train/raw-loss = 0.48076310753822327, train/logprobs = tensor([[-0.7268, -2.2247],
        [-1.1456, -1.2943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10889487713575363
Epoch 0, Step 1362: train/loss = 0.5524299144744873, train/raw-loss = 0.4998416304588318, train/logprobs = tensor([[-0.4712, -1.5800],
        [-0.7122, -0.5723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517662763595581
Epoch 0, Step 1363: train/loss = 0.4990057945251465, train/raw-loss = 0.42870476841926575, train/logprobs = tensor([[-0.7304, -2.2407],
        [-1.6410, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14060205221176147
Epoch 0, Step 1364: train/loss = 0.4703610837459564, train/raw-loss = 0.41495123505592346, train/logprobs = tensor([[-1.1775, -2.5009],
        [-1.3087, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11081971228122711
Epoch 0, Step 1365: train/loss = 0.4303323030471802, train/raw-loss = 0.36831310391426086, train/logprobs = tensor([[-0.7263, -2.8228],
        [-0.9363, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12403834611177444
Epoch 0, Step 1366: train/loss = 0.389475554227829, train/raw-loss = 0.31961822509765625, train/logprobs = tensor([[-0.5770, -2.9821],
        [-1.8889, -0.8276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13971467316150665
Epoch 0, Step 1367: train/loss = 0.5214190483093262, train/raw-loss = 0.4609919488430023, train/logprobs = tensor([[-0.6748, -2.7543],
        [-0.8158, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12085417658090591
Epoch 0, Step 1368: train/loss = 0.5082677006721497, train/raw-loss = 0.44440388679504395, train/logprobs = tensor([[-0.9541, -2.3947],
        [-1.0107, -0.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12772761285305023
Epoch 0, Step 1369: train/loss = 0.33421844244003296, train/raw-loss = 0.2538895308971405, train/logprobs = tensor([[-0.6375, -5.4938],
        [-3.0559, -1.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1606578528881073
Epoch 0, Step 1370: train/loss = 0.4088141620159149, train/raw-loss = 0.3390640616416931, train/logprobs = tensor([[-1.1221, -5.7211],
        [-1.8620, -1.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1395002007484436
Epoch 0, Step 1371: train/loss = 0.35222530364990234, train/raw-loss = 0.27513307332992554, train/logprobs = tensor([[-1.2247, -3.6333],
        [-2.5729, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541845202445984
Epoch 0, Step 1372: train/loss = 0.41670119762420654, train/raw-loss = 0.33583372831344604, train/logprobs = tensor([[-1.0868, -3.0278],
        [-2.6019, -0.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16173489391803741
Epoch 0, Step 1373: train/loss = 1.0202691555023193, train/raw-loss = 0.9537143707275391, train/logprobs = tensor([[-2.7585, -3.1944],
        [-0.6011, -0.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13310953974723816
Epoch 0, Step 1374: train/loss = 0.3825339376926422, train/raw-loss = 0.30976587533950806, train/logprobs = tensor([[-1.0523, -4.0824],
        [-1.8974, -1.1825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1455361247062683
Epoch 0, Step 1375: train/loss = 0.6352542638778687, train/raw-loss = 0.5794875621795654, train/logprobs = tensor([[-0.7996, -1.9090],
        [-1.0817, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11153338849544525
Epoch 0, Step 1376: train/loss = 0.4958775043487549, train/raw-loss = 0.4176563322544098, train/logprobs = tensor([[-0.6934, -1.5707],
        [-1.7777, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15644237399101257
Epoch 0, Step 1377: train/loss = 0.45640936493873596, train/raw-loss = 0.39032429456710815, train/logprobs = tensor([[-0.7569, -1.7639],
        [-1.9456, -0.6185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13217011094093323
Epoch 0, Step 1378: train/loss = 0.701492965221405, train/raw-loss = 0.6266405582427979, train/logprobs = tensor([[-0.7270, -2.9951],
        [-3.3990, -2.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497046947479248
Epoch 0, Step 1379: train/loss = 0.39470553398132324, train/raw-loss = 0.31185391545295715, train/logprobs = tensor([[-0.7746, -3.1838],
        [-1.9274, -0.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16570331156253815
Epoch 0, Step 1380: train/loss = 0.3553203046321869, train/raw-loss = 0.2979845106601715, train/logprobs = tensor([[-0.6303, -3.5264],
        [-1.0751, -1.2143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11467156559228897
Epoch 0, Step 1381: train/loss = 0.5270074605941772, train/raw-loss = 0.4654940068721771, train/logprobs = tensor([[-0.5897, -2.4488],
        [-0.9142, -0.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12302698194980621
Epoch 0, Step 1382: train/loss = 0.3626454472541809, train/raw-loss = 0.31134480237960815, train/logprobs = tensor([[-0.6269, -2.5085],
        [-1.8934, -0.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10260133445262909
Epoch 0, Step 1383: train/loss = 0.3311975300312042, train/raw-loss = 0.2525579035282135, train/logprobs = tensor([[-0.7024, -2.7768],
        [-1.5270, -0.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15727925300598145
Epoch 0, Step 1384: train/loss = 0.3191838264465332, train/raw-loss = 0.237263023853302, train/logprobs = tensor([[-0.7300, -2.6066],
        [-2.0856, -0.4887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16384154558181763
Epoch 0, Step 1385: train/loss = 0.26889580488204956, train/raw-loss = 0.18727412819862366, train/logprobs = tensor([[-0.7383, -4.9692],
        [-2.6645, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.163243368268013
Epoch 0, Step 1386: train/loss = 0.5993447303771973, train/raw-loss = 0.5390725135803223, train/logprobs = tensor([[-0.8153, -1.9112],
        [-1.7392, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12054440379142761
Epoch 0, Step 1387: train/loss = 0.4593033194541931, train/raw-loss = 0.3923044800758362, train/logprobs = tensor([[-1.3792, -5.3066],
        [-1.5276, -1.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13399769365787506
Epoch 0, Step 1388: train/loss = 0.24260027706623077, train/raw-loss = 0.16817188262939453, train/logprobs = tensor([[-0.5324, -6.2458],
        [-2.3019, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14885680377483368
Epoch 0, Step 1389: train/loss = 0.48313969373703003, train/raw-loss = 0.42174971103668213, train/logprobs = tensor([[-0.7024, -1.8090],
        [-1.4990, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1227799504995346
Epoch 0, Step 1390: train/loss = 0.6667640209197998, train/raw-loss = 0.6065735816955566, train/logprobs = tensor([[-0.8205, -1.3530],
        [-0.7583, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12038087844848633
Epoch 0, Step 1391: train/loss = 0.5020036697387695, train/raw-loss = 0.42656490206718445, train/logprobs = tensor([[-0.9133, -2.4589],
        [-1.7198, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508774608373642
Epoch 0, Step 1392: train/loss = 0.5960289239883423, train/raw-loss = 0.5428150296211243, train/logprobs = tensor([[-0.7049, -1.3464],
        [-0.8427, -0.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10642769932746887
Epoch 0, Step 1393: train/loss = 0.27848905324935913, train/raw-loss = 0.20254898071289062, train/logprobs = tensor([[-0.7436, -4.0756],
        [-2.3928, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151880145072937
Epoch 0, Step 1394: train/loss = 0.4861208498477936, train/raw-loss = 0.43295717239379883, train/logprobs = tensor([[-0.7364, -2.3214],
        [-1.1456, -1.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1063273549079895
Epoch 0, Step 1395: train/loss = 0.7786872982978821, train/raw-loss = 0.7310191988945007, train/logprobs = tensor([[-0.4931, -0.7531],
        [-1.2098, -1.2453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09533621370792389
Epoch 0, Step 1396: train/loss = 0.4984731674194336, train/raw-loss = 0.4302029311656952, train/logprobs = tensor([[-0.9479, -3.7180],
        [-2.0390, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13654044270515442
Epoch 0, Step 1397: train/loss = 0.40187785029411316, train/raw-loss = 0.33070820569992065, train/logprobs = tensor([[-0.6691, -3.1862],
        [-1.6264, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1423393189907074
Epoch 0, Step 1398: train/loss = 0.6115896701812744, train/raw-loss = 0.5637500882148743, train/logprobs = tensor([[-0.8306, -1.4599],
        [-1.2240, -1.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956791415810585
Epoch 0, Step 1399: train/loss = 0.5667915344238281, train/raw-loss = 0.49022847414016724, train/logprobs = tensor([[-1.1840, -2.4731],
        [-0.9413, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15312618017196655
Epoch 0, Step 1400: train/loss = 0.40898698568344116, train/raw-loss = 0.33971816301345825, train/logprobs = tensor([[-0.6071, -3.1933],
        [-1.8340, -0.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13853758573532104
Epoch 0, Step 1401: train/loss = 0.38833293318748474, train/raw-loss = 0.3035126030445099, train/logprobs = tensor([[-0.8897, -4.0166],
        [-1.8500, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1696407049894333
Epoch 0, Step 1402: train/loss = 0.6375857591629028, train/raw-loss = 0.5777946710586548, train/logprobs = tensor([[-0.7170, -1.2060],
        [-1.0011, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11958219110965729
Epoch 0, Step 1403: train/loss = 0.4124948978424072, train/raw-loss = 0.3529149293899536, train/logprobs = tensor([[-1.3222, -4.6884],
        [-1.9462, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11915996670722961
Epoch 0, Step 1404: train/loss = 0.5368152856826782, train/raw-loss = 0.476979523897171, train/logprobs = tensor([[-0.7748, -2.2718],
        [-0.9976, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11967159062623978
Epoch 0, Step 1405: train/loss = 0.3926639258861542, train/raw-loss = 0.32627788186073303, train/logprobs = tensor([[-0.6339, -3.6705],
        [-1.6069, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13277211785316467
Epoch 0, Step 1406: train/loss = 0.36794334650039673, train/raw-loss = 0.28108087182044983, train/logprobs = tensor([[-0.7259, -2.4827],
        [-3.1340, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737249195575714
Epoch 0, Step 1407: train/loss = 0.5416139364242554, train/raw-loss = 0.48950833082199097, train/logprobs = tensor([[-0.7430, -0.9860],
        [-1.4729, -0.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10421110689640045
Epoch 0, Step 1408: train/loss = 0.47886598110198975, train/raw-loss = 0.42143866419792175, train/logprobs = tensor([[-0.5072, -3.1050],
        [-0.9212, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485467851161957
Epoch 0, Step 1409: train/loss = 0.6369549036026001, train/raw-loss = 0.582982063293457, train/logprobs = tensor([[-0.6522, -0.7827],
        [-0.9558, -0.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10794559866189957
Epoch 0, Step 1410: train/loss = 0.5169975757598877, train/raw-loss = 0.4676125645637512, train/logprobs = tensor([[-0.9791, -1.7316],
        [-1.3825, -0.3384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09877002239227295
Epoch 0, Step 1411: train/loss = 0.8238405585289001, train/raw-loss = 0.7500371932983398, train/logprobs = tensor([[-1.2060, -2.6740],
        [-2.0818, -2.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14760679006576538
Epoch 0, Step 1412: train/loss = 0.4297654628753662, train/raw-loss = 0.3594478368759155, train/logprobs = tensor([[-0.6134, -2.4377],
        [-2.6211, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14063522219657898
Epoch 0, Step 1413: train/loss = 0.26846200227737427, train/raw-loss = 0.20708724856376648, train/logprobs = tensor([[-0.7227, -4.3669],
        [-1.6412, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12274949252605438
Epoch 0, Step 1414: train/loss = 0.627586841583252, train/raw-loss = 0.5783100128173828, train/logprobs = tensor([[-0.5795, -1.0495],
        [-0.8163, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855363517999649
Epoch 0, Step 1415: train/loss = 0.4584343433380127, train/raw-loss = 0.4015958309173584, train/logprobs = tensor([[-0.4376, -3.1285],
        [-0.6872, -1.1646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367705464363098
Epoch 0, Step 1416: train/loss = 0.5672499537467957, train/raw-loss = 0.5155702233314514, train/logprobs = tensor([[-0.4799, -1.4944],
        [-1.7873, -0.6931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10335949063301086
Epoch 0, Step 1417: train/loss = 0.37024807929992676, train/raw-loss = 0.29442262649536133, train/logprobs = tensor([[-0.6683, -3.7317],
        [-1.8391, -1.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516508013010025
Epoch 0, Step 1418: train/loss = 0.3764547109603882, train/raw-loss = 0.30705344676971436, train/logprobs = tensor([[-0.7398, -3.2992],
        [-2.1210, -0.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13880252838134766
Epoch 0, Step 1419: train/loss = 0.36699438095092773, train/raw-loss = 0.3001721501350403, train/logprobs = tensor([[-0.6678, -2.6446],
        [-1.8253, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364437222480774
Epoch 0, Step 1420: train/loss = 0.5860451459884644, train/raw-loss = 0.5040972828865051, train/logprobs = tensor([[-0.7661, -2.2789],
        [-1.3386, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16389566659927368
Epoch 0, Step 1421: train/loss = 0.3453633487224579, train/raw-loss = 0.27184709906578064, train/logprobs = tensor([[-0.6329, -2.7683],
        [-2.7703, -0.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1470324993133545
Epoch 0, Step 1422: train/loss = 0.47895318269729614, train/raw-loss = 0.41000109910964966, train/logprobs = tensor([[-0.9113, -1.5661],
        [-2.3686, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13790419697761536
Epoch 0, Step 1423: train/loss = 0.4623435139656067, train/raw-loss = 0.3995319604873657, train/logprobs = tensor([[-0.5525, -2.8534],
        [-0.8492, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12562307715415955
Epoch 0, Step 1424: train/loss = 0.3607232868671417, train/raw-loss = 0.2947707772254944, train/logprobs = tensor([[-1.2452, -2.0994],
        [-2.6495, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13190501928329468
Epoch 0, Step 1425: train/loss = 0.4836590886116028, train/raw-loss = 0.4194343686103821, train/logprobs = tensor([[-0.9389, -3.3289],
        [-1.2150, -1.6481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12844949960708618
Epoch 0, Step 1426: train/loss = 0.6018533110618591, train/raw-loss = 0.5528663992881775, train/logprobs = tensor([[-0.6944, -2.1008],
        [-0.6620, -0.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09797380864620209
Epoch 0, Step 1427: train/loss = 0.5730361342430115, train/raw-loss = 0.5350225567817688, train/logprobs = tensor([[-0.2599, -1.6858],
        [-0.3895, -0.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07602723687887192
Epoch 0, Step 1428: train/loss = 0.503413200378418, train/raw-loss = 0.4440470337867737, train/logprobs = tensor([[-0.4354, -3.1371],
        [-0.6531, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11873235553503036
Epoch 0, Step 1429: train/loss = 0.5036993622779846, train/raw-loss = 0.44067373871803284, train/logprobs = tensor([[-0.7635, -1.0562],
        [-1.7719, -0.5421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12605121731758118
Epoch 0, Step 1430: train/loss = 0.4987044334411621, train/raw-loss = 0.4224262237548828, train/logprobs = tensor([[-1.0159, -1.7426],
        [-2.1046, -0.8680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15255644917488098
Epoch 0, Step 1431: train/loss = 0.43452519178390503, train/raw-loss = 0.3569360673427582, train/logprobs = tensor([[-0.3765, -1.3196],
        [-2.2939, -0.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15517830848693848
Epoch 0, Step 1432: train/loss = 0.7077841758728027, train/raw-loss = 0.649658739566803, train/logprobs = tensor([[-0.7563, -0.9800],
        [-1.7784, -1.4065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11625096946954727
Epoch 0, Step 1433: train/loss = 0.5065106749534607, train/raw-loss = 0.43106192350387573, train/logprobs = tensor([[-0.6187, -2.2718],
        [-1.6580, -0.8634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508975476026535
Epoch 0, Step 1434: train/loss = 0.536402702331543, train/raw-loss = 0.47557753324508667, train/logprobs = tensor([[-0.5364, -3.0743],
        [-1.1967, -1.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1216503232717514
Epoch 0, Step 1435: train/loss = 0.4012381136417389, train/raw-loss = 0.3344966173171997, train/logprobs = tensor([[-1.3737, -2.7712],
        [-1.7921, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13348300755023956
Epoch 0, Step 1436: train/loss = 0.5516470074653625, train/raw-loss = 0.4910159111022949, train/logprobs = tensor([[-0.9501, -2.0490],
        [-2.1494, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12126222252845764
Epoch 0, Step 1437: train/loss = 0.41400378942489624, train/raw-loss = 0.34985822439193726, train/logprobs = tensor([[-0.6691, -3.9475],
        [-1.8433, -1.5651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12829114496707916
Epoch 0, Step 1438: train/loss = 0.49259433150291443, train/raw-loss = 0.4269840121269226, train/logprobs = tensor([[-0.6789, -2.2278],
        [-1.5970, -1.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13122063875198364
Epoch 0, Step 1439: train/loss = 0.39224618673324585, train/raw-loss = 0.33140861988067627, train/logprobs = tensor([[-0.5367, -3.9298],
        [-0.7598, -0.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12167516350746155
Epoch 0, Step 1440: train/loss = 0.7311919331550598, train/raw-loss = 0.6538881659507751, train/logprobs = tensor([[-1.2422, -3.9995],
        [-2.4910, -2.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546076536178589
Epoch 0, Step 1441: train/loss = 0.3143821656703949, train/raw-loss = 0.24259033799171448, train/logprobs = tensor([[-0.8050, -3.7478],
        [-1.2850, -0.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14358364045619965
Epoch 0, Step 1442: train/loss = 0.5118876695632935, train/raw-loss = 0.4438949525356293, train/logprobs = tensor([[-0.7237, -2.1548],
        [-2.0849, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13598546385765076
Epoch 0, Step 1443: train/loss = 0.2617475092411041, train/raw-loss = 0.17405909299850464, train/logprobs = tensor([[-0.8537, -6.2081],
        [-3.4553, -2.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17537681758403778
Epoch 0, Step 1444: train/loss = 0.5616629123687744, train/raw-loss = 0.4935486614704132, train/logprobs = tensor([[-0.5646, -1.3540],
        [-1.4468, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362285017967224
Epoch 0, Step 1445: train/loss = 0.6390788555145264, train/raw-loss = 0.604682981967926, train/logprobs = tensor([[-0.4597, -0.8002],
        [-0.5941, -0.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06879177689552307
Epoch 0, Step 1446: train/loss = 0.5446690320968628, train/raw-loss = 0.466793030500412, train/logprobs = tensor([[-0.9369, -1.1238],
        [-2.0339, -0.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15575197339057922
Epoch 0, Step 1447: train/loss = 0.58754563331604, train/raw-loss = 0.5122603178024292, train/logprobs = tensor([[-1.2143, -2.6976],
        [-1.9416, -1.3482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1505705714225769
Epoch 0, Step 1448: train/loss = 0.7091768383979797, train/raw-loss = 0.6569479703903198, train/logprobs = tensor([[-1.2990, -1.7784],
        [-0.9364, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10445775091648102
Epoch 0, Step 1449: train/loss = 0.6020489931106567, train/raw-loss = 0.5513700246810913, train/logprobs = tensor([[-1.3386, -1.8118],
        [-1.6629, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10135787725448608
Epoch 0, Step 1450: train/loss = 0.5132259130477905, train/raw-loss = 0.460879921913147, train/logprobs = tensor([[-0.4333, -2.1095],
        [-0.7852, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10469195991754532
Epoch 0, Step 1451: train/loss = 0.4135987162590027, train/raw-loss = 0.3484551012516022, train/logprobs = tensor([[-0.7286, -2.8056],
        [-3.5461, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1302872747182846
Epoch 0, Step 1452: train/loss = 0.53951096534729, train/raw-loss = 0.4809468388557434, train/logprobs = tensor([[-1.2545, -5.7437],
        [-1.2044, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11712820082902908
Epoch 0, Step 1453: train/loss = 0.35518258810043335, train/raw-loss = 0.28592678904533386, train/logprobs = tensor([[-0.5043, -3.5300],
        [-2.0245, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385115087032318
Epoch 0, Step 1454: train/loss = 0.4241568446159363, train/raw-loss = 0.34476301074028015, train/logprobs = tensor([[-0.5689, -2.0928],
        [-2.2228, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15878769755363464
Epoch 0, Step 1455: train/loss = 0.42709970474243164, train/raw-loss = 0.35156989097595215, train/logprobs = tensor([[-0.6365, -2.5978],
        [-1.9749, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15105962753295898
Epoch 0, Step 1456: train/loss = 0.41097328066825867, train/raw-loss = 0.3496180772781372, train/logprobs = tensor([[-0.6019, -3.4550],
        [-1.2949, -1.0581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1227104514837265
Epoch 0, Step 1457: train/loss = 0.3261323869228363, train/raw-loss = 0.2426258772611618, train/logprobs = tensor([[-0.6961, -5.3718],
        [-3.1699, -1.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16701297461986542
Epoch 0, Step 1458: train/loss = 0.5083913803100586, train/raw-loss = 0.45755788683891296, train/logprobs = tensor([[-0.6063, -1.3775],
        [-1.9553, -0.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10166695713996887
Epoch 0, Step 1459: train/loss = 0.5389654040336609, train/raw-loss = 0.46010297536849976, train/logprobs = tensor([[-0.7122, -3.1345],
        [-1.6444, -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15772491693496704
Epoch 0, Step 1460: train/loss = 0.3760920763015747, train/raw-loss = 0.31214240193367004, train/logprobs = tensor([[-0.5259, -2.7896],
        [-1.2736, -0.6510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12789934873580933
Epoch 0, Step 1461: train/loss = 0.2907712459564209, train/raw-loss = 0.20018205046653748, train/logprobs = tensor([[-0.5261, -4.6250],
        [-2.9798, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18117836117744446
Epoch 0, Step 1462: train/loss = 0.48883551359176636, train/raw-loss = 0.4368346333503723, train/logprobs = tensor([[-0.6068, -2.2318],
        [-0.7775, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10400179773569107
Epoch 0, Step 1463: train/loss = 0.36591067910194397, train/raw-loss = 0.2913551330566406, train/logprobs = tensor([[-0.6290, -3.5354],
        [-2.2129, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491110920906067
Epoch 0, Step 1464: train/loss = 0.47921815514564514, train/raw-loss = 0.3984164595603943, train/logprobs = tensor([[-0.7760, -3.6191],
        [-1.7381, -1.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616033911705017
Epoch 0, Step 1465: train/loss = 0.5173581838607788, train/raw-loss = 0.45074978470802307, train/logprobs = tensor([[-0.5942, -2.5399],
        [-1.1227, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13321678340435028
Epoch 0, Step 1466: train/loss = 0.3644656836986542, train/raw-loss = 0.2942505478858948, train/logprobs = tensor([[-1.1221, -2.8239],
        [-2.4633, -1.0369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1404302418231964
Epoch 0, Step 1467: train/loss = 0.23718048632144928, train/raw-loss = 0.15688037872314453, train/logprobs = tensor([[-0.9080, -3.6844],
        [-3.1928, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16060024499893188
Epoch 0, Step 1468: train/loss = 0.6113489270210266, train/raw-loss = 0.5461291670799255, train/logprobs = tensor([[-1.1779, -1.6937],
        [-1.1142, -0.8490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13043959438800812
Epoch 0, Step 1469: train/loss = 0.5738183856010437, train/raw-loss = 0.5279456973075867, train/logprobs = tensor([[-0.4621, -1.1317],
        [-0.7954, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09174535423517227
Epoch 0, Step 1470: train/loss = 0.5328360795974731, train/raw-loss = 0.48414063453674316, train/logprobs = tensor([[-1.1826, -2.3117],
        [-2.2532, -2.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09739077091217041
Epoch 0, Step 1471: train/loss = 0.3347056806087494, train/raw-loss = 0.25074270367622375, train/logprobs = tensor([[-0.8892, -2.7304],
        [-3.0218, -0.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16792592406272888
Epoch 0, Step 1472: train/loss = 0.47973376512527466, train/raw-loss = 0.40473929047584534, train/logprobs = tensor([[-0.6979, -2.7356],
        [-0.9507, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14998887479305267
Epoch 0, Step 1473: train/loss = 0.42124223709106445, train/raw-loss = 0.35820409655570984, train/logprobs = tensor([[-0.9604, -3.4483],
        [-0.9756, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12607625126838684
Epoch 0, Step 1474: train/loss = 0.48907023668289185, train/raw-loss = 0.4151096045970917, train/logprobs = tensor([[-0.9930, -2.6182],
        [-2.7420, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14792120456695557
Epoch 0, Step 1475: train/loss = 0.5810081958770752, train/raw-loss = 0.5179615616798401, train/logprobs = tensor([[-0.7908, -1.6709],
        [-1.2364, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12609322369098663
Epoch 0, Step 1476: train/loss = 0.30931296944618225, train/raw-loss = 0.24261164665222168, train/logprobs = tensor([[-0.6126, -5.0504],
        [-1.4054, -1.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13340261578559875
Epoch 0, Step 1477: train/loss = 0.5300448536872864, train/raw-loss = 0.4690726399421692, train/logprobs = tensor([[-0.8341, -1.0533],
        [-2.1932, -0.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12194444239139557
Epoch 0, Step 1478: train/loss = 0.6501100063323975, train/raw-loss = 0.5929936170578003, train/logprobs = tensor([[-0.7446, -3.1855],
        [-2.4436, -1.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11423276364803314
Epoch 0, Step 1479: train/loss = 0.41205865144729614, train/raw-loss = 0.3283522427082062, train/logprobs = tensor([[-1.0231, -2.6279],
        [-2.2306, -1.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16741274297237396
Epoch 0, Step 1480: train/loss = 0.27821534872055054, train/raw-loss = 0.2160809338092804, train/logprobs = tensor([[-0.6359, -4.6288],
        [-1.5356, -1.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12426885217428207
Epoch 0, Step 1481: train/loss = 0.5738980174064636, train/raw-loss = 0.5200759172439575, train/logprobs = tensor([[-0.8469, -1.5766],
        [-1.1771, -0.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10764417052268982
Epoch 0, Step 1482: train/loss = 0.5854601860046387, train/raw-loss = 0.5270994305610657, train/logprobs = tensor([[-0.8139, -1.8726],
        [-1.3091, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672142893075943
Epoch 0, Step 1483: train/loss = 0.34903788566589355, train/raw-loss = 0.2964670658111572, train/logprobs = tensor([[-0.5184, -3.4104],
        [-0.8998, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10514163970947266
Epoch 0, Step 1484: train/loss = 0.3793914318084717, train/raw-loss = 0.3136484920978546, train/logprobs = tensor([[-1.0593, -2.5579],
        [-2.2930, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13148587942123413
Epoch 0, Step 1485: train/loss = 0.46559634804725647, train/raw-loss = 0.4112858176231384, train/logprobs = tensor([[-0.6030, -2.6547],
        [-0.9169, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10862106829881668
Epoch 0, Step 1486: train/loss = 0.47079938650131226, train/raw-loss = 0.415661096572876, train/logprobs = tensor([[-0.5571, -2.2226],
        [-1.0676, -0.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11027668416500092
Epoch 0, Step 1487: train/loss = 0.38620665669441223, train/raw-loss = 0.33417463302612305, train/logprobs = tensor([[-0.5799, -2.6430],
        [-1.9409, -0.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10406401753425598
Epoch 0, Step 1488: train/loss = 0.4333215355873108, train/raw-loss = 0.379143089056015, train/logprobs = tensor([[-0.4769, -3.2033],
        [-1.2968, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10835685580968857
Epoch 0, Step 1489: train/loss = 0.31702905893325806, train/raw-loss = 0.24381393194198608, train/logprobs = tensor([[-0.6528, -3.9626],
        [-1.8668, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14643022418022156
Epoch 0, Step 1490: train/loss = 0.5346901416778564, train/raw-loss = 0.4703405201435089, train/logprobs = tensor([[-0.5527, -2.0019],
        [-0.7103, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12869924306869507
Epoch 0, Step 1491: train/loss = 0.3789754807949066, train/raw-loss = 0.313671737909317, train/logprobs = tensor([[-0.5809, -3.1639],
        [-1.8527, -0.6513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306075006723404
Epoch 0, Step 1492: train/loss = 0.36934894323349, train/raw-loss = 0.2996382713317871, train/logprobs = tensor([[-0.6876, -4.4020],
        [-1.6564, -0.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13942131400108337
Epoch 0, Step 1493: train/loss = 0.4392596185207367, train/raw-loss = 0.36351943016052246, train/logprobs = tensor([[-0.5715, -2.1358],
        [-1.9707, -0.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15148037672042847
Epoch 0, Step 1494: train/loss = 0.5070339441299438, train/raw-loss = 0.42895588278770447, train/logprobs = tensor([[-0.6573, -1.6164],
        [-1.7981, -0.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15615609288215637
Epoch 0, Step 1495: train/loss = 0.4021885097026825, train/raw-loss = 0.3409346342086792, train/logprobs = tensor([[-0.6079, -3.8040],
        [-1.9601, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1225077360868454
Epoch 0, Step 1496: train/loss = 0.6702594757080078, train/raw-loss = 0.6055022478103638, train/logprobs = tensor([[-0.5535, -1.2140],
        [-1.1197, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12951458990573883
Epoch 0, Step 1497: train/loss = 0.7102614641189575, train/raw-loss = 0.6426622867584229, train/logprobs = tensor([[-0.9745, -1.9905],
        [-2.3760, -1.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13519823551177979
Epoch 0, Step 1498: train/loss = 0.5440406799316406, train/raw-loss = 0.46696585416793823, train/logprobs = tensor([[-1.7248, -3.7299],
        [-2.1218, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15414968132972717
Epoch 0, Step 1499: train/loss = 0.3726835250854492, train/raw-loss = 0.2989739179611206, train/logprobs = tensor([[-0.6644, -2.7611],
        [-1.6721, -0.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1474192589521408
eval/loss: 0.4784625172615051
Epoch 0, Step 1500: train/loss = 0.3619067072868347, train/raw-loss = 0.30277350544929504, train/logprobs = tensor([[-0.9678, -3.5517],
        [-2.3690, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11826639622449875
Epoch 0, Step 1501: train/loss = 0.2609161138534546, train/raw-loss = 0.18560171127319336, train/logprobs = tensor([[-0.9916, -3.1320],
        [-2.3393, -0.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15062882006168365
Epoch 0, Step 1502: train/loss = 0.6141252517700195, train/raw-loss = 0.5457733273506165, train/logprobs = tensor([[-0.4644, -0.8954],
        [-1.5950, -0.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13670381903648376
Epoch 0, Step 1503: train/loss = 0.4052739441394806, train/raw-loss = 0.3420751094818115, train/logprobs = tensor([[-0.5972, -2.7903],
        [-1.3469, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12639757990837097
Epoch 0, Step 1504: train/loss = 0.5815171003341675, train/raw-loss = 0.5068445205688477, train/logprobs = tensor([[-1.1068, -1.2541],
        [-2.2319, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1493452489376068
Epoch 0, Step 1505: train/loss = 0.32612115144729614, train/raw-loss = 0.24477922916412354, train/logprobs = tensor([[-1.0946, -3.4662],
        [-2.8334, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626838743686676
Epoch 0, Step 1506: train/loss = 0.5822914838790894, train/raw-loss = 0.524479866027832, train/logprobs = tensor([[-1.1297, -2.6698],
        [-0.9220, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11562322080135345
Epoch 0, Step 1507: train/loss = 0.5028846859931946, train/raw-loss = 0.44735395908355713, train/logprobs = tensor([[-0.5687, -1.3053],
        [-1.6927, -0.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1110614612698555
Epoch 0, Step 1508: train/loss = 0.22573351860046387, train/raw-loss = 0.1360199749469757, train/logprobs = tensor([[-0.8217, -3.6462],
        [-4.0840, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17942708730697632
Epoch 0, Step 1509: train/loss = 0.37488454580307007, train/raw-loss = 0.2961290776729584, train/logprobs = tensor([[-0.5047, -1.9183],
        [-3.3118, -0.5581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1575109213590622
Epoch 0, Step 1510: train/loss = 0.46203815937042236, train/raw-loss = 0.4043900668621063, train/logprobs = tensor([[-0.5486, -2.9287],
        [-0.8933, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11529617011547089
Epoch 0, Step 1511: train/loss = 0.26253601908683777, train/raw-loss = 0.18354730308055878, train/logprobs = tensor([[-0.4972, -4.1831],
        [-1.4447, -0.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797744691371918
Epoch 0, Step 1512: train/loss = 0.479108989238739, train/raw-loss = 0.40672069787979126, train/logprobs = tensor([[-0.9500, -2.9097],
        [-1.3962, -1.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14477655291557312
Epoch 0, Step 1513: train/loss = 0.42279139161109924, train/raw-loss = 0.3593768775463104, train/logprobs = tensor([[-0.7059, -2.3164],
        [-1.4440, -1.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12682899832725525
Epoch 0, Step 1514: train/loss = 0.44682979583740234, train/raw-loss = 0.3783876895904541, train/logprobs = tensor([[-0.7785, -2.9100],
        [-1.5352, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13688425719738007
Epoch 0, Step 1515: train/loss = 0.7115015387535095, train/raw-loss = 0.6623321771621704, train/logprobs = tensor([[-0.6107, -0.7117],
        [-0.7414, -0.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09833864122629166
Epoch 0, Step 1516: train/loss = 0.5964564681053162, train/raw-loss = 0.5301421880722046, train/logprobs = tensor([[-1.2248, -2.2850],
        [-1.9184, -1.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13262850046157837
Epoch 0, Step 1517: train/loss = 0.647221028804779, train/raw-loss = 0.5610869526863098, train/logprobs = tensor([[-0.8462, -2.4984],
        [-2.9885, -2.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1722680777311325
Epoch 0, Step 1518: train/loss = 0.5639804601669312, train/raw-loss = 0.4843786954879761, train/logprobs = tensor([[-0.6383, -1.8465],
        [-0.9992, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15920361876487732
Epoch 0, Step 1519: train/loss = 0.4550277590751648, train/raw-loss = 0.3951159119606018, train/logprobs = tensor([[-0.5959, -2.8711],
        [-0.9844, -0.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11982371658086777
Epoch 0, Step 1520: train/loss = 0.4758806526660919, train/raw-loss = 0.3993418216705322, train/logprobs = tensor([[-0.5976, -3.0975],
        [-1.9453, -1.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15307767689228058
Epoch 0, Step 1521: train/loss = 0.3530949056148529, train/raw-loss = 0.2631089985370636, train/logprobs = tensor([[-0.9354, -3.4195],
        [-3.6002, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17997178435325623
Epoch 0, Step 1522: train/loss = 0.47759953141212463, train/raw-loss = 0.4223102927207947, train/logprobs = tensor([[-0.8715, -2.4980],
        [-1.3844, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11057853698730469
Epoch 0, Step 1523: train/loss = 0.4784690737724304, train/raw-loss = 0.4021821618080139, train/logprobs = tensor([[-1.0798, -3.0382],
        [-2.5985, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15257380902767181
Epoch 0, Step 1524: train/loss = 0.6189742684364319, train/raw-loss = 0.5687151551246643, train/logprobs = tensor([[-1.0686, -0.9423],
        [-1.7912, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10051819682121277
Epoch 0, Step 1525: train/loss = 0.4165894389152527, train/raw-loss = 0.36096420884132385, train/logprobs = tensor([[-1.1686, -2.0235],
        [-2.4767, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11125047504901886
Epoch 0, Step 1526: train/loss = 0.5072922706604004, train/raw-loss = 0.43216630816459656, train/logprobs = tensor([[-1.5387, -3.2840],
        [-1.9411, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15025189518928528
Epoch 0, Step 1527: train/loss = 0.8552170991897583, train/raw-loss = 0.7743560075759888, train/logprobs = tensor([[-0.8342, -1.6773],
        [-1.6324, -2.0476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16172222793102264
Epoch 0, Step 1528: train/loss = 0.7650917768478394, train/raw-loss = 0.7137570381164551, train/logprobs = tensor([[-0.5303, -2.8233],
        [-0.8958, -2.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10266944020986557
Epoch 0, Step 1529: train/loss = 0.45733439922332764, train/raw-loss = 0.40811920166015625, train/logprobs = tensor([[-0.3995, -1.7127],
        [-1.0739, -0.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09843046963214874
Epoch 0, Step 1530: train/loss = 0.5657980442047119, train/raw-loss = 0.5145856738090515, train/logprobs = tensor([[-0.7885, -2.6665],
        [-0.7275, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.102424755692482
Epoch 0, Step 1531: train/loss = 0.40146467089653015, train/raw-loss = 0.32029008865356445, train/logprobs = tensor([[-0.5902, -2.1642],
        [-2.0580, -0.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1623491644859314
Epoch 0, Step 1532: train/loss = 0.6565055847167969, train/raw-loss = 0.5935433506965637, train/logprobs = tensor([[-1.1621, -1.4732],
        [-1.5394, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12592439353466034
Epoch 0, Step 1533: train/loss = 0.6679412126541138, train/raw-loss = 0.6273714900016785, train/logprobs = tensor([[-0.5249, -0.5859],
        [-0.8652, -0.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0811394453048706
Epoch 0, Step 1534: train/loss = 0.2965550422668457, train/raw-loss = 0.23129309713840485, train/logprobs = tensor([[-1.1857, -5.1012],
        [-2.4199, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13052387535572052
Epoch 0, Step 1535: train/loss = 0.4868878424167633, train/raw-loss = 0.403933584690094, train/logprobs = tensor([[-0.8579, -2.3853],
        [-1.9242, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16590851545333862
Epoch 0, Step 1536: train/loss = 0.5004337430000305, train/raw-loss = 0.44207265973091125, train/logprobs = tensor([[-0.6952, -2.8342],
        [-1.6827, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672219634056091
Epoch 0, Step 1537: train/loss = 0.39877113699913025, train/raw-loss = 0.31975865364074707, train/logprobs = tensor([[-0.5883, -2.3325],
        [-1.9056, -0.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15802496671676636
Epoch 0, Step 1538: train/loss = 0.5078453421592712, train/raw-loss = 0.45259174704551697, train/logprobs = tensor([[-0.6611, -2.8987],
        [-1.2407, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050725728273392
Epoch 0, Step 1539: train/loss = 0.5719204545021057, train/raw-loss = 0.5047820806503296, train/logprobs = tensor([[-0.8038, -2.1881],
        [-1.4966, -0.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13427670300006866
Epoch 0, Step 1540: train/loss = 0.5270659327507019, train/raw-loss = 0.4389078617095947, train/logprobs = tensor([[-1.1546, -2.5361],
        [-2.2795, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1763160526752472
Epoch 0, Step 1541: train/loss = 0.6781383752822876, train/raw-loss = 0.6110227108001709, train/logprobs = tensor([[-0.7520, -2.2078],
        [-2.2437, -2.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13423123955726624
Epoch 0, Step 1542: train/loss = 0.6688731908798218, train/raw-loss = 0.6156224012374878, train/logprobs = tensor([[-0.6326, -0.8610],
        [-0.8869, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10650143027305603
Epoch 0, Step 1543: train/loss = 0.2927670478820801, train/raw-loss = 0.22830626368522644, train/logprobs = tensor([[-0.8747, -5.2057],
        [-2.1372, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12892159819602966
Epoch 0, Step 1544: train/loss = 0.5045069456100464, train/raw-loss = 0.4407934546470642, train/logprobs = tensor([[-0.4769, -1.5469],
        [-1.3962, -0.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127426877617836
Epoch 0, Step 1545: train/loss = 0.3221653699874878, train/raw-loss = 0.24969914555549622, train/logprobs = tensor([[-0.7061, -3.5115],
        [-3.3266, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14493244886398315
Epoch 0, Step 1546: train/loss = 0.386046439409256, train/raw-loss = 0.313504159450531, train/logprobs = tensor([[-0.6861, -3.9091],
        [-1.4804, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14508454501628876
Epoch 0, Step 1547: train/loss = 0.4407990574836731, train/raw-loss = 0.38188427686691284, train/logprobs = tensor([[-0.6244, -2.2261],
        [-1.1822, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11782962828874588
Epoch 0, Step 1548: train/loss = 0.6432428359985352, train/raw-loss = 0.5636144280433655, train/logprobs = tensor([[-0.8801, -2.6453],
        [-1.8020, -1.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15925681591033936
Epoch 0, Step 1549: train/loss = 0.44644695520401, train/raw-loss = 0.36303555965423584, train/logprobs = tensor([[-1.7097, -2.7943],
        [-3.3974, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16682280600070953
Epoch 0, Step 1550: train/loss = 0.3591564893722534, train/raw-loss = 0.28154441714286804, train/logprobs = tensor([[-1.0780, -4.3046],
        [-2.3616, -1.5508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15522417426109314
Epoch 0, Step 1551: train/loss = 0.454742431640625, train/raw-loss = 0.3652184009552002, train/logprobs = tensor([[-0.7365, -1.6466],
        [-3.2756, -0.8261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17904813587665558
Epoch 0, Step 1552: train/loss = 0.460178405046463, train/raw-loss = 0.3886226415634155, train/logprobs = tensor([[-0.5407, -2.3632],
        [-1.2741, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14311149716377258
Epoch 0, Step 1553: train/loss = 0.5536115765571594, train/raw-loss = 0.48001784086227417, train/logprobs = tensor([[-0.5752, -1.1485],
        [-1.4776, -0.8055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14718753099441528
Epoch 0, Step 1554: train/loss = 0.2935306429862976, train/raw-loss = 0.20588833093643188, train/logprobs = tensor([[-0.6974, -3.6890],
        [-3.6110, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17528453469276428
Epoch 0, Step 1555: train/loss = 0.4916381239891052, train/raw-loss = 0.4311579465866089, train/logprobs = tensor([[-0.4233, -2.0065],
        [-1.4997, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12096042931079865
Epoch 0, Step 1556: train/loss = 0.49039900302886963, train/raw-loss = 0.42812880873680115, train/logprobs = tensor([[-0.3893, -1.9992],
        [-1.0950, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12454038113355637
Epoch 0, Step 1557: train/loss = 0.6489748954772949, train/raw-loss = 0.6023800373077393, train/logprobs = tensor([[-0.8600, -1.3520],
        [-0.6496, -0.6003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09318975359201431
Epoch 0, Step 1558: train/loss = 0.26393264532089233, train/raw-loss = 0.18814246356487274, train/logprobs = tensor([[-0.6738, -6.3706],
        [-1.5674, -1.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15158042311668396
Epoch 0, Step 1559: train/loss = 0.6046216487884521, train/raw-loss = 0.5629992485046387, train/logprobs = tensor([[-0.3787, -0.9068],
        [-0.7412, -0.6459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08324477821588516
Epoch 0, Step 1560: train/loss = 0.9093788266181946, train/raw-loss = 0.8504989147186279, train/logprobs = tensor([[-0.4203, -0.4983],
        [-0.7502, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11775973439216614
Epoch 0, Step 1561: train/loss = 0.39348894357681274, train/raw-loss = 0.32462385296821594, train/logprobs = tensor([[-0.5091, -2.5421],
        [-2.1833, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.137730211019516
Epoch 0, Step 1562: train/loss = 0.27397406101226807, train/raw-loss = 0.199569433927536, train/logprobs = tensor([[-0.4941, -5.1273],
        [-2.0587, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880920946598053
Epoch 0, Step 1563: train/loss = 0.7426651120185852, train/raw-loss = 0.6696927547454834, train/logprobs = tensor([[-0.6397, -2.3793],
        [-1.7074, -1.7364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14594458043575287
Epoch 0, Step 1564: train/loss = 0.6869224905967712, train/raw-loss = 0.649482786655426, train/logprobs = tensor([[-0.5292, -0.6947],
        [-0.5344, -0.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07487937808036804
Epoch 0, Step 1565: train/loss = 0.5412911772727966, train/raw-loss = 0.4744962155818939, train/logprobs = tensor([[-0.7477, -1.3936],
        [-2.8212, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1335899829864502
Epoch 0, Step 1566: train/loss = 0.4618828296661377, train/raw-loss = 0.40261802077293396, train/logprobs = tensor([[-0.4989, -3.5810],
        [-0.7403, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852959543466568
Epoch 0, Step 1567: train/loss = 0.3995802402496338, train/raw-loss = 0.3435133695602417, train/logprobs = tensor([[-0.6049, -3.8338],
        [-1.1235, -0.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1121336817741394
Epoch 0, Step 1568: train/loss = 0.4558514952659607, train/raw-loss = 0.3818417191505432, train/logprobs = tensor([[-1.2282, -3.2526],
        [-2.0294, -0.8368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14801956713199615
Epoch 0, Step 1569: train/loss = 0.7681773900985718, train/raw-loss = 0.7153643369674683, train/logprobs = tensor([[-0.7116, -0.7909],
        [-0.7993, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10562623292207718
Epoch 0, Step 1570: train/loss = 0.5407045483589172, train/raw-loss = 0.4710768461227417, train/logprobs = tensor([[-0.5780, -1.8843],
        [-0.7605, -0.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392553746700287
Epoch 0, Step 1571: train/loss = 0.3704020380973816, train/raw-loss = 0.3080575168132782, train/logprobs = tensor([[-1.0363, -4.1703],
        [-2.5513, -1.6905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468913197517395
Epoch 0, Step 1572: train/loss = 0.6413671374320984, train/raw-loss = 0.5851045846939087, train/logprobs = tensor([[-0.4817, -0.5420],
        [-1.6274, -0.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1125250831246376
Epoch 0, Step 1573: train/loss = 0.5505083203315735, train/raw-loss = 0.48405033349990845, train/logprobs = tensor([[-0.6300, -1.1235],
        [-1.7913, -0.6383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13291597366333008
Epoch 0, Step 1574: train/loss = 0.3191390931606293, train/raw-loss = 0.233036071062088, train/logprobs = tensor([[-0.6628, -3.0999],
        [-2.7777, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17220604419708252
Epoch 0, Step 1575: train/loss = 0.39968252182006836, train/raw-loss = 0.3284622132778168, train/logprobs = tensor([[-1.4428, -3.9084],
        [-2.3226, -1.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424405723810196
Epoch 0, Step 1576: train/loss = 0.33818840980529785, train/raw-loss = 0.25037339329719543, train/logprobs = tensor([[-0.6662, -3.5425],
        [-3.2218, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17563006281852722
Epoch 0, Step 1577: train/loss = 0.4415210485458374, train/raw-loss = 0.37743401527404785, train/logprobs = tensor([[-0.9536, -1.9810],
        [-1.9947, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1281740665435791
Epoch 0, Step 1578: train/loss = 0.7278197407722473, train/raw-loss = 0.6574324369430542, train/logprobs = tensor([[-0.8219, -1.6036],
        [-2.5707, -1.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14077450335025787
Epoch 0, Step 1579: train/loss = 0.46652311086654663, train/raw-loss = 0.3842695951461792, train/logprobs = tensor([[-0.6054, -2.5393],
        [-2.8930, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1645069420337677
Epoch 0, Step 1580: train/loss = 0.3838638365268707, train/raw-loss = 0.30073946714401245, train/logprobs = tensor([[-0.7335, -3.0082],
        [-2.3056, -0.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16624873876571655
Epoch 0, Step 1581: train/loss = 0.6241973638534546, train/raw-loss = 0.5846288204193115, train/logprobs = tensor([[-0.4464, -0.6804],
        [-0.8653, -0.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07913701236248016
Epoch 0, Step 1582: train/loss = 0.37643277645111084, train/raw-loss = 0.31659212708473206, train/logprobs = tensor([[-0.5196, -2.4691],
        [-2.0973, -0.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11968126893043518
Epoch 0, Step 1583: train/loss = 0.48220741748809814, train/raw-loss = 0.4320813715457916, train/logprobs = tensor([[-0.3555, -2.2557],
        [-0.8234, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10025207698345184
Epoch 0, Step 1584: train/loss = 0.5018409490585327, train/raw-loss = 0.4472527503967285, train/logprobs = tensor([[-0.9172, -2.4046],
        [-1.7686, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10917642712593079
Epoch 0, Step 1585: train/loss = 0.21461698412895203, train/raw-loss = 0.13541364669799805, train/logprobs = tensor([[-0.9806, -4.8275],
        [-4.7549, -1.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15840670466423035
Epoch 0, Step 1586: train/loss = 0.3741404414176941, train/raw-loss = 0.31113940477371216, train/logprobs = tensor([[-1.4027, -3.5968],
        [-1.8149, -1.2278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12600205838680267
Epoch 0, Step 1587: train/loss = 0.5181999206542969, train/raw-loss = 0.46242648363113403, train/logprobs = tensor([[-0.5412, -2.1089],
        [-1.6542, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11154686659574509
Epoch 0, Step 1588: train/loss = 0.2741600573062897, train/raw-loss = 0.18562760949134827, train/logprobs = tensor([[-0.8870, -4.0311],
        [-2.1120, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770648956298828
Epoch 0, Step 1589: train/loss = 0.364642471075058, train/raw-loss = 0.28426751494407654, train/logprobs = tensor([[-0.9194, -4.3329],
        [-2.4248, -1.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16074998676776886
Epoch 0, Step 1590: train/loss = 0.4870036840438843, train/raw-loss = 0.4146413803100586, train/logprobs = tensor([[-0.5326, -2.4411],
        [-1.1314, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14472460746765137
Epoch 0, Step 1591: train/loss = 0.37868809700012207, train/raw-loss = 0.31180018186569214, train/logprobs = tensor([[-0.8559, -4.2279],
        [-1.3532, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13377578556537628
Epoch 0, Step 1592: train/loss = 0.47783592343330383, train/raw-loss = 0.41521671414375305, train/logprobs = tensor([[-0.7194, -1.4607],
        [-2.3536, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12523838877677917
Epoch 0, Step 1593: train/loss = 0.5350703001022339, train/raw-loss = 0.46845147013664246, train/logprobs = tensor([[-0.9117, -2.7291],
        [-0.9398, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13323765993118286
Epoch 0, Step 1594: train/loss = 0.4912331700325012, train/raw-loss = 0.4164150357246399, train/logprobs = tensor([[-0.6605, -2.3385],
        [-2.1687, -1.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14963622391223907
Epoch 0, Step 1595: train/loss = 0.4313129484653473, train/raw-loss = 0.37967658042907715, train/logprobs = tensor([[-0.6863, -4.0862],
        [-0.8314, -0.6858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10327272117137909
Epoch 0, Step 1596: train/loss = 0.4066220819950104, train/raw-loss = 0.34086912870407104, train/logprobs = tensor([[-0.6039, -2.6961],
        [-2.4169, -0.7200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13150590658187866
Epoch 0, Step 1597: train/loss = 0.3194776177406311, train/raw-loss = 0.2370508313179016, train/logprobs = tensor([[-0.6297, -3.8798],
        [-2.2745, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1648535430431366
Epoch 0, Step 1598: train/loss = 0.6481848955154419, train/raw-loss = 0.5656256079673767, train/logprobs = tensor([[-0.7184, -3.2592],
        [-2.2543, -2.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16511856019496918
Epoch 0, Step 1599: train/loss = 0.43776676058769226, train/raw-loss = 0.3788544833660126, train/logprobs = tensor([[-0.6919, -3.1339],
        [-1.9054, -0.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11782457679510117
Epoch 0, Step 1600: train/loss = 0.39925023913383484, train/raw-loss = 0.3156369626522064, train/logprobs = tensor([[-0.7353, -2.7291],
        [-2.3770, -1.8046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16722653806209564
Epoch 0, Step 1601: train/loss = 0.4243301749229431, train/raw-loss = 0.3667997121810913, train/logprobs = tensor([[-1.0585, -2.7475],
        [-2.4445, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11506089568138123
Epoch 0, Step 1602: train/loss = 0.44779378175735474, train/raw-loss = 0.3904813528060913, train/logprobs = tensor([[-0.8433, -3.8626],
        [-1.2661, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11462478339672089
Epoch 0, Step 1603: train/loss = 0.6092172265052795, train/raw-loss = 0.5562602281570435, train/logprobs = tensor([[-0.6988, -0.8826],
        [-1.1249, -0.6730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10591401159763336
Epoch 0, Step 1604: train/loss = 0.5767384767532349, train/raw-loss = 0.5279260277748108, train/logprobs = tensor([[-0.5617, -1.6352],
        [-0.9134, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09762487560510635
Epoch 0, Step 1605: train/loss = 0.5327206254005432, train/raw-loss = 0.43953296542167664, train/logprobs = tensor([[-1.3494, -2.9667],
        [-1.7520, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18637533485889435
Epoch 0, Step 1606: train/loss = 0.4315009117126465, train/raw-loss = 0.36387041211128235, train/logprobs = tensor([[-0.8443, -1.5229],
        [-2.7906, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13526108860969543
Epoch 0, Step 1607: train/loss = 0.44394901394844055, train/raw-loss = 0.3759857416152954, train/logprobs = tensor([[-0.8590, -2.8252],
        [-1.1654, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359265148639679
Epoch 0, Step 1608: train/loss = 0.19573892652988434, train/raw-loss = 0.10131852328777313, train/logprobs = tensor([[-0.8636, -3.9095],
        [-3.3989, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18884079158306122
Epoch 0, Step 1609: train/loss = 0.3279530107975006, train/raw-loss = 0.26611775159835815, train/logprobs = tensor([[-0.5547, -4.2586],
        [-1.0755, -0.7530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12367047369480133
Epoch 0, Step 1610: train/loss = 0.32830554246902466, train/raw-loss = 0.23619480431079865, train/logprobs = tensor([[-1.1070, -3.0107],
        [-3.4874, -0.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1842215359210968
Epoch 0, Step 1611: train/loss = 0.4933266043663025, train/raw-loss = 0.421508252620697, train/logprobs = tensor([[-0.5470, -2.6110],
        [-1.6765, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14363667368888855
Epoch 0, Step 1612: train/loss = 0.3824862539768219, train/raw-loss = 0.30882737040519714, train/logprobs = tensor([[-0.5853, -4.6006],
        [-1.7175, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14731773734092712
Epoch 0, Step 1613: train/loss = 0.6089997887611389, train/raw-loss = 0.5626160502433777, train/logprobs = tensor([[-0.4589, -1.2703],
        [-0.7342, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09276749193668365
Epoch 0, Step 1614: train/loss = 0.7403565645217896, train/raw-loss = 0.6717644333839417, train/logprobs = tensor([[-1.1778, -2.4030],
        [-0.7219, -0.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1371842324733734
Epoch 0, Step 1615: train/loss = 0.45524880290031433, train/raw-loss = 0.38121724128723145, train/logprobs = tensor([[-0.6577, -3.0534],
        [-1.5731, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14806312322616577
Epoch 0, Step 1616: train/loss = 0.33521199226379395, train/raw-loss = 0.2557290196418762, train/logprobs = tensor([[-1.0672, -2.8370],
        [-3.1418, -1.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15896596014499664
Epoch 0, Step 1617: train/loss = 0.3013225197792053, train/raw-loss = 0.22612018883228302, train/logprobs = tensor([[-0.7874, -5.4518],
        [-2.2738, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15040461719036102
Epoch 0, Step 1618: train/loss = 0.4247701168060303, train/raw-loss = 0.34679633378982544, train/logprobs = tensor([[-0.5402, -3.1815],
        [-2.3594, -1.3131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1559474766254425
Epoch 0, Step 1619: train/loss = 0.674136757850647, train/raw-loss = 0.6129998564720154, train/logprobs = tensor([[-1.1317, -1.6750],
        [-1.0431, -0.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12227378785610199
Epoch 0, Step 1620: train/loss = 0.3744387626647949, train/raw-loss = 0.2993185520172119, train/logprobs = tensor([[-1.0876, -4.7510],
        [-2.6213, -1.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1502404361963272
Epoch 0, Step 1621: train/loss = 0.623489260673523, train/raw-loss = 0.5694639682769775, train/logprobs = tensor([[-0.5805, -1.6768],
        [-0.7884, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.108050636947155
Epoch 0, Step 1622: train/loss = 0.4292133152484894, train/raw-loss = 0.34632524847984314, train/logprobs = tensor([[-0.9944, -1.5751],
        [-3.0604, -0.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16577616333961487
Epoch 0, Step 1623: train/loss = 0.5485479235649109, train/raw-loss = 0.4834871292114258, train/logprobs = tensor([[-0.8664, -1.7707],
        [-2.1342, -1.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13012158870697021
Epoch 0, Step 1624: train/loss = 0.3669489622116089, train/raw-loss = 0.30301234126091003, train/logprobs = tensor([[-0.9261, -4.1383],
        [-1.1608, -1.2345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1278732270002365
Epoch 0, Step 1625: train/loss = 0.43266114592552185, train/raw-loss = 0.3668382167816162, train/logprobs = tensor([[-0.6190, -3.3764],
        [-1.5303, -1.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316458284854889
Epoch 0, Step 1626: train/loss = 0.4952106475830078, train/raw-loss = 0.4287853240966797, train/logprobs = tensor([[-0.4592, -2.3200],
        [-1.0103, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13285064697265625
Epoch 0, Step 1627: train/loss = 0.42972585558891296, train/raw-loss = 0.3541322350502014, train/logprobs = tensor([[-0.7884, -2.7926],
        [-2.3881, -1.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15118719637393951
Epoch 0, Step 1628: train/loss = 0.5886560678482056, train/raw-loss = 0.51750648021698, train/logprobs = tensor([[-0.9381, -2.6667],
        [-1.8509, -1.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.142299085855484
Epoch 0, Step 1629: train/loss = 0.44481202960014343, train/raw-loss = 0.37407416105270386, train/logprobs = tensor([[-0.6699, -2.8107],
        [-1.4532, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14147573709487915
Epoch 0, Step 1630: train/loss = 0.3388884365558624, train/raw-loss = 0.2401966154575348, train/logprobs = tensor([[-0.7044, -4.6281],
        [-3.4451, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738367199897766
Epoch 0, Step 1631: train/loss = 0.47345414757728577, train/raw-loss = 0.42058777809143066, train/logprobs = tensor([[-0.4207, -3.3774],
        [-0.7898, -1.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10573272407054901
Epoch 0, Step 1632: train/loss = 0.33650991320610046, train/raw-loss = 0.25202733278274536, train/logprobs = tensor([[-0.6549, -2.5627],
        [-2.3491, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16896513104438782
Epoch 0, Step 1633: train/loss = 0.5508755445480347, train/raw-loss = 0.4795820713043213, train/logprobs = tensor([[-0.6113, -1.4217],
        [-1.5552, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14258703589439392
Epoch 0, Step 1634: train/loss = 0.4834590554237366, train/raw-loss = 0.41801226139068604, train/logprobs = tensor([[-0.9006, -1.8322],
        [-2.7721, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308935433626175
Epoch 0, Step 1635: train/loss = 0.7068076729774475, train/raw-loss = 0.6230348348617554, train/logprobs = tensor([[-1.6194, -3.0507],
        [-1.3934, -1.3731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1675456166267395
Epoch 0, Step 1636: train/loss = 0.4014454782009125, train/raw-loss = 0.31399446725845337, train/logprobs = tensor([[-1.1367, -4.2305],
        [-1.7543, -1.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17490211129188538
Epoch 0, Step 1637: train/loss = 0.24596840143203735, train/raw-loss = 0.17225734889507294, train/logprobs = tensor([[-0.6146, -5.3361],
        [-1.9673, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14742210507392883
Epoch 0, Step 1638: train/loss = 0.7823737263679504, train/raw-loss = 0.6982535719871521, train/logprobs = tensor([[-0.7181, -4.8400],
        [-3.2841, -2.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16824036836624146
Epoch 0, Step 1639: train/loss = 0.44549092650413513, train/raw-loss = 0.3785565495491028, train/logprobs = tensor([[-0.9199, -3.7512],
        [-1.3421, -1.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13386881351470947
Epoch 0, Step 1640: train/loss = 0.42256098985671997, train/raw-loss = 0.3416217863559723, train/logprobs = tensor([[-0.7859, -3.1794],
        [-3.0376, -1.4888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16187840700149536
Epoch 0, Step 1641: train/loss = 0.6810899972915649, train/raw-loss = 0.6324955224990845, train/logprobs = tensor([[-0.4497, -0.9937],
        [-1.0350, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718887507915497
Epoch 0, Step 1642: train/loss = 0.32017073035240173, train/raw-loss = 0.2493303120136261, train/logprobs = tensor([[-1.0725, -4.0276],
        [-2.3485, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14168083667755127
Epoch 0, Step 1643: train/loss = 0.2976253926753998, train/raw-loss = 0.20756033062934875, train/logprobs = tensor([[-0.7841, -3.2096],
        [-3.7370, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18013013899326324
Epoch 0, Step 1644: train/loss = 0.3848588168621063, train/raw-loss = 0.3163134455680847, train/logprobs = tensor([[-0.6100, -1.5589],
        [-3.0024, -0.5172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13709072768688202
Epoch 0, Step 1645: train/loss = 0.21061132848262787, train/raw-loss = 0.1154041588306427, train/logprobs = tensor([[-0.7466, -4.0656],
        [-3.3160, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19041433930397034
Epoch 0, Step 1646: train/loss = 0.7376865744590759, train/raw-loss = 0.667270302772522, train/logprobs = tensor([[-2.1576, -2.5224],
        [-2.8536, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1408325582742691
Epoch 0, Step 1647: train/loss = 0.4456166923046112, train/raw-loss = 0.37660714983940125, train/logprobs = tensor([[-0.5907, -2.6120],
        [-2.4324, -0.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380191296339035
Epoch 0, Step 1648: train/loss = 0.1894102692604065, train/raw-loss = 0.08589598536491394, train/logprobs = tensor([[-0.7139, -4.5834],
        [-5.5608, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20702853798866272
Epoch 0, Step 1649: train/loss = 0.6326718926429749, train/raw-loss = 0.536413848400116, train/logprobs = tensor([[-1.4122, -3.2239],
        [-2.6431, -1.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19251607358455658
Epoch 0, Step 1650: train/loss = 0.48563849925994873, train/raw-loss = 0.41311025619506836, train/logprobs = tensor([[-0.8326, -1.3140],
        [-3.3707, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14505645632743835
Epoch 0, Step 1651: train/loss = 0.4000222086906433, train/raw-loss = 0.3365463614463806, train/logprobs = tensor([[-0.5495, -4.1974],
        [-0.8951, -0.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12695173919200897
Epoch 0, Step 1652: train/loss = 0.6395306587219238, train/raw-loss = 0.5508059859275818, train/logprobs = tensor([[-1.2569, -5.4554],
        [-3.1461, -2.7657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17744947969913483
Epoch 0, Step 1653: train/loss = 0.45632755756378174, train/raw-loss = 0.37387245893478394, train/logprobs = tensor([[-0.9389, -3.2598],
        [-3.0136, -1.7219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1649102121591568
Epoch 0, Step 1654: train/loss = 0.579136073589325, train/raw-loss = 0.5238609313964844, train/logprobs = tensor([[-0.4536, -1.1020],
        [-0.9554, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1105501726269722
Epoch 0, Step 1655: train/loss = 0.5164172649383545, train/raw-loss = 0.443347305059433, train/logprobs = tensor([[-0.6886, -3.2399],
        [-1.7223, -1.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14613990485668182
Epoch 0, Step 1656: train/loss = 0.2723873257637024, train/raw-loss = 0.19307196140289307, train/logprobs = tensor([[-0.7068, -5.9858],
        [-1.3483, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15863069891929626
Epoch 0, Step 1657: train/loss = 0.5341637134552002, train/raw-loss = 0.47962486743927, train/logprobs = tensor([[-0.6153, -3.3615],
        [-1.3871, -2.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907761007547379
Epoch 0, Step 1658: train/loss = 0.6834008097648621, train/raw-loss = 0.6274826526641846, train/logprobs = tensor([[-1.0542, -1.8222],
        [-1.1917, -1.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11183644831180573
Epoch 0, Step 1659: train/loss = 0.4580172598361969, train/raw-loss = 0.3747747242450714, train/logprobs = tensor([[-0.5038, -1.6233],
        [-2.9801, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16648510098457336
Epoch 0, Step 1660: train/loss = 0.3268079459667206, train/raw-loss = 0.25009045004844666, train/logprobs = tensor([[-0.8054, -5.1271],
        [-1.3665, -0.7641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15343499183654785
Epoch 0, Step 1661: train/loss = 0.5612398386001587, train/raw-loss = 0.484023779630661, train/logprobs = tensor([[-1.5007, -3.0574],
        [-2.4077, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15443211793899536
Epoch 0, Step 1662: train/loss = 0.5688745379447937, train/raw-loss = 0.5064163208007812, train/logprobs = tensor([[-1.3900, -2.1302],
        [-1.6412, -1.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12491641938686371
Epoch 0, Step 1663: train/loss = 0.2807184159755707, train/raw-loss = 0.20314988493919373, train/logprobs = tensor([[-0.9179, -2.7803],
        [-2.9724, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1551370620727539
Epoch 0, Step 1664: train/loss = 0.26687341928482056, train/raw-loss = 0.18952417373657227, train/logprobs = tensor([[-0.9032, -3.8482],
        [-2.1818, -1.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15469850599765778
Epoch 0, Step 1665: train/loss = 0.6179639101028442, train/raw-loss = 0.5530290007591248, train/logprobs = tensor([[-0.4165, -1.6603],
        [-0.7188, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12986989319324493
Epoch 0, Step 1666: train/loss = 0.5558673739433289, train/raw-loss = 0.4955843687057495, train/logprobs = tensor([[-1.3048, -3.9764],
        [-1.4489, -1.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12056604027748108
Epoch 0, Step 1667: train/loss = 0.5397547483444214, train/raw-loss = 0.46417689323425293, train/logprobs = tensor([[-0.7529, -2.1183],
        [-2.0839, -0.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15115569531917572
Epoch 0, Step 1668: train/loss = 0.5039101243019104, train/raw-loss = 0.4386822283267975, train/logprobs = tensor([[-0.5650, -3.3259],
        [-1.9030, -1.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13045580685138702
Epoch 0, Step 1669: train/loss = 0.34820348024368286, train/raw-loss = 0.27974116802215576, train/logprobs = tensor([[-0.5410, -2.9960],
        [-2.1697, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1369246542453766
Epoch 0, Step 1670: train/loss = 0.4105874300003052, train/raw-loss = 0.3541255593299866, train/logprobs = tensor([[-0.4746, -4.1898],
        [-1.5311, -0.9899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11292380839586258
Epoch 0, Step 1671: train/loss = 0.3741878867149353, train/raw-loss = 0.2765452265739441, train/logprobs = tensor([[-0.6717, -2.8182],
        [-3.7333, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19528533518314362
Epoch 0, Step 1672: train/loss = 0.6483756899833679, train/raw-loss = 0.5915404558181763, train/logprobs = tensor([[-0.5763, -2.6316],
        [-1.6688, -2.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11367042362689972
Epoch 0, Step 1673: train/loss = 0.5671454071998596, train/raw-loss = 0.5081874132156372, train/logprobs = tensor([[-0.7245, -1.7037],
        [-1.0871, -0.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11791598796844482
Epoch 0, Step 1674: train/loss = 0.32359588146209717, train/raw-loss = 0.25334471464157104, train/logprobs = tensor([[-0.9599, -3.8368],
        [-1.9143, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14050234854221344
Epoch 0, Step 1675: train/loss = 0.9408091902732849, train/raw-loss = 0.8713392019271851, train/logprobs = tensor([[-0.8939, -2.3535],
        [-2.0085, -2.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1389399617910385
Epoch 0, Step 1676: train/loss = 0.5423034429550171, train/raw-loss = 0.46132275462150574, train/logprobs = tensor([[-0.5957, -1.0836],
        [-2.2925, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196134686470032
Epoch 0, Step 1677: train/loss = 0.35837793350219727, train/raw-loss = 0.2819618284702301, train/logprobs = tensor([[-0.5155, -2.5422],
        [-1.6258, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528322398662567
Epoch 0, Step 1678: train/loss = 0.41156086325645447, train/raw-loss = 0.3412761390209198, train/logprobs = tensor([[-0.6314, -2.9129],
        [-1.0694, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14056938886642456
Epoch 0, Step 1679: train/loss = 0.27825525403022766, train/raw-loss = 0.20625656843185425, train/logprobs = tensor([[-1.0499, -5.0989],
        [-2.5615, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14399737119674683
Epoch 0, Step 1680: train/loss = 0.48161786794662476, train/raw-loss = 0.42563799023628235, train/logprobs = tensor([[-0.9168, -5.5087],
        [-2.4127, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11195970326662064
Epoch 0, Step 1681: train/loss = 0.549446165561676, train/raw-loss = 0.49753737449645996, train/logprobs = tensor([[-0.5742, -2.4413],
        [-0.8010, -0.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10381755232810974
Epoch 0, Step 1682: train/loss = 0.42557865381240845, train/raw-loss = 0.3531123399734497, train/logprobs = tensor([[-0.8603, -4.3096],
        [-2.7516, -1.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14493265748023987
Epoch 0, Step 1683: train/loss = 0.431502103805542, train/raw-loss = 0.36428406834602356, train/logprobs = tensor([[-0.4519, -2.2307],
        [-1.0348, -0.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1344360113143921
Epoch 0, Step 1684: train/loss = 0.32445818185806274, train/raw-loss = 0.23356574773788452, train/logprobs = tensor([[-1.0094, -4.4919],
        [-3.0661, -1.2626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18178485333919525
Epoch 0, Step 1685: train/loss = 0.44568008184432983, train/raw-loss = 0.372871994972229, train/logprobs = tensor([[-0.9043, -1.9867],
        [-2.2531, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14561620354652405
Epoch 0, Step 1686: train/loss = 0.3711172938346863, train/raw-loss = 0.2850286364555359, train/logprobs = tensor([[-0.7444, -3.2438],
        [-1.6450, -0.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1721772849559784
Epoch 0, Step 1687: train/loss = 0.2342083752155304, train/raw-loss = 0.1393815129995346, train/logprobs = tensor([[-1.1393, -3.9898],
        [-4.9711, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18965372443199158
Epoch 0, Step 1688: train/loss = 0.5119917392730713, train/raw-loss = 0.4421841502189636, train/logprobs = tensor([[-0.4670, -1.8931],
        [-2.1572, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13961513340473175
Epoch 0, Step 1689: train/loss = 0.4840456247329712, train/raw-loss = 0.416045606136322, train/logprobs = tensor([[-0.6178, -2.7139],
        [-1.2133, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13599999248981476
Epoch 0, Step 1690: train/loss = 0.31051376461982727, train/raw-loss = 0.21610388159751892, train/logprobs = tensor([[-0.9390, -3.6582],
        [-1.9826, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18881972134113312
Epoch 0, Step 1691: train/loss = 0.54923015832901, train/raw-loss = 0.47554492950439453, train/logprobs = tensor([[-0.7989, -2.2840],
        [-2.0695, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14737048745155334
Epoch 0, Step 1692: train/loss = 0.2575337588787079, train/raw-loss = 0.18418803811073303, train/logprobs = tensor([[-1.1747, -4.4528],
        [-4.0366, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1466914564371109
Epoch 0, Step 1693: train/loss = 0.5047007203102112, train/raw-loss = 0.4375435709953308, train/logprobs = tensor([[-0.4548, -1.4686],
        [-1.8400, -0.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1343143731355667
Epoch 0, Step 1694: train/loss = 0.4928441047668457, train/raw-loss = 0.43719032406806946, train/logprobs = tensor([[-0.4412, -3.7569],
        [-0.6837, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11130756139755249
Epoch 0, Step 1695: train/loss = 0.5289180278778076, train/raw-loss = 0.45630520582199097, train/logprobs = tensor([[-0.8254, -3.6491],
        [-1.4460, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1452256441116333
Epoch 0, Step 1696: train/loss = 0.49722611904144287, train/raw-loss = 0.4199637174606323, train/logprobs = tensor([[-0.7813, -3.3422],
        [-4.1007, -2.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15452489256858826
Epoch 0, Step 1697: train/loss = 0.3173988163471222, train/raw-loss = 0.24946747720241547, train/logprobs = tensor([[-0.6843, -6.0161],
        [-1.5235, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13586264848709106
Epoch 0, Step 1698: train/loss = 0.5164363384246826, train/raw-loss = 0.4531261920928955, train/logprobs = tensor([[-1.1453, -2.1751],
        [-2.0122, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12662039697170258
Epoch 0, Step 1699: train/loss = 0.7280806303024292, train/raw-loss = 0.6680590510368347, train/logprobs = tensor([[-0.7277, -0.6556],
        [-0.9610, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004321813583374
Epoch 0, Step 1700: train/loss = 0.5453709363937378, train/raw-loss = 0.4461073577404022, train/logprobs = tensor([[-0.5785, -2.7628],
        [-4.1815, -1.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19852718710899353
Epoch 0, Step 1701: train/loss = 0.5243300199508667, train/raw-loss = 0.46298927068710327, train/logprobs = tensor([[-0.9649, -3.0660],
        [-1.0556, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12268142402172089
Epoch 0, Step 1702: train/loss = 0.3269491195678711, train/raw-loss = 0.235136017203331, train/logprobs = tensor([[-0.9536, -4.5378],
        [-3.1044, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18362626433372498
Epoch 0, Step 1703: train/loss = 0.26067349314689636, train/raw-loss = 0.16498655080795288, train/logprobs = tensor([[-1.1350, -4.8605],
        [-3.7731, -1.3389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19137385487556458
Epoch 0, Step 1704: train/loss = 0.3246908485889435, train/raw-loss = 0.23895524442195892, train/logprobs = tensor([[-0.8789, -4.3800],
        [-4.1388, -2.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17147119343280792
Epoch 0, Step 1705: train/loss = 0.43518033623695374, train/raw-loss = 0.35902535915374756, train/logprobs = tensor([[-0.7208, -2.2422],
        [-2.4121, -0.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15230999886989594
Epoch 0, Step 1706: train/loss = 0.4483426511287689, train/raw-loss = 0.3846595883369446, train/logprobs = tensor([[-0.5559, -3.8162],
        [-1.8041, -1.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273661106824875
Epoch 0, Step 1707: train/loss = 0.6849937438964844, train/raw-loss = 0.5993517637252808, train/logprobs = tensor([[-1.9796, -3.6519],
        [-3.0499, -1.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17128399014472961
Epoch 0, Step 1708: train/loss = 0.4604717195034027, train/raw-loss = 0.3802715837955475, train/logprobs = tensor([[-0.5072, -2.1083],
        [-2.4442, -0.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16040024161338806
Epoch 0, Step 1709: train/loss = 0.7355540990829468, train/raw-loss = 0.6825992465019226, train/logprobs = tensor([[-0.6893, -0.4339],
        [-0.8403, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10590961575508118
Epoch 0, Step 1710: train/loss = 0.552567720413208, train/raw-loss = 0.4795958995819092, train/logprobs = tensor([[-0.5696, -1.0103],
        [-1.9119, -0.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14594365656375885
Epoch 0, Step 1711: train/loss = 0.3619893491268158, train/raw-loss = 0.28289681673049927, train/logprobs = tensor([[-1.3600, -4.1294],
        [-3.2289, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15818506479263306
Epoch 0, Step 1712: train/loss = 0.3075326979160309, train/raw-loss = 0.2333517223596573, train/logprobs = tensor([[-0.6142, -4.3373],
        [-2.6082, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1483619511127472
Epoch 0, Step 1713: train/loss = 0.2986576557159424, train/raw-loss = 0.2027868628501892, train/logprobs = tensor([[-0.9452, -3.4490],
        [-5.1234, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19174152612686157
Epoch 0, Step 1714: train/loss = 0.5937116742134094, train/raw-loss = 0.5215131044387817, train/logprobs = tensor([[-1.3059, -2.6342],
        [-3.5539, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1443970501422882
Epoch 0, Step 1715: train/loss = 0.4584668278694153, train/raw-loss = 0.3996700644493103, train/logprobs = tensor([[-0.5564, -1.8912],
        [-2.1805, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11759357154369354
Epoch 0, Step 1716: train/loss = 0.39252662658691406, train/raw-loss = 0.32129326462745667, train/logprobs = tensor([[-0.5835, -3.0866],
        [-1.2762, -0.9572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424666792154312
Epoch 0, Step 1717: train/loss = 0.3531489372253418, train/raw-loss = 0.28540319204330444, train/logprobs = tensor([[-0.9385, -5.0531],
        [-2.3355, -1.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354915350675583
Epoch 0, Step 1718: train/loss = 0.4404594600200653, train/raw-loss = 0.36139631271362305, train/logprobs = tensor([[-0.7684, -2.0303],
        [-2.5180, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15812626481056213
Epoch 0, Step 1719: train/loss = 0.6675074100494385, train/raw-loss = 0.6014087200164795, train/logprobs = tensor([[-0.6650, -1.7021],
        [-1.5835, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1321975290775299
Epoch 0, Step 1720: train/loss = 0.3967567980289459, train/raw-loss = 0.30709385871887207, train/logprobs = tensor([[-0.7616, -2.7718],
        [-3.0537, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17932578921318054
Epoch 0, Step 1721: train/loss = 0.5431497693061829, train/raw-loss = 0.46614551544189453, train/logprobs = tensor([[-0.6463, -1.8202],
        [-1.9851, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1540084183216095
Epoch 0, Step 1722: train/loss = 0.460913747549057, train/raw-loss = 0.3975995182991028, train/logprobs = tensor([[-0.5590, -2.6795],
        [-1.3125, -0.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12662842869758606
Epoch 0, Step 1723: train/loss = 0.5790656805038452, train/raw-loss = 0.5212821364402771, train/logprobs = tensor([[-0.6102, -1.5918],
        [-0.7988, -0.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11556702107191086
Epoch 0, Step 1724: train/loss = 0.5602366924285889, train/raw-loss = 0.47134265303611755, train/logprobs = tensor([[-1.1960, -3.3536],
        [-2.8501, -2.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1777881383895874
Epoch 0, Step 1725: train/loss = 0.4879540205001831, train/raw-loss = 0.42677754163742065, train/logprobs = tensor([[-0.9029, -3.3777],
        [-0.7604, -0.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12235303968191147
Epoch 0, Step 1726: train/loss = 0.3833591043949127, train/raw-loss = 0.3264794945716858, train/logprobs = tensor([[-1.4909, -4.4705],
        [-2.3020, -1.4910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11375923454761505
Epoch 0, Step 1727: train/loss = 0.2664134204387665, train/raw-loss = 0.19806796312332153, train/logprobs = tensor([[-0.7411, -4.8750],
        [-2.2292, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1366909146308899
Epoch 0, Step 1728: train/loss = 0.5102972984313965, train/raw-loss = 0.44765523076057434, train/logprobs = tensor([[-0.7201, -2.9068],
        [-0.8989, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252841055393219
Epoch 0, Step 1729: train/loss = 0.3810657262802124, train/raw-loss = 0.3105023503303528, train/logprobs = tensor([[-0.6300, -3.5092],
        [-1.9146, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411268264055252
Epoch 0, Step 1730: train/loss = 0.404070645570755, train/raw-loss = 0.3348032534122467, train/logprobs = tensor([[-0.6043, -2.5425],
        [-2.3795, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.138534814119339
Epoch 0, Step 1731: train/loss = 0.631049633026123, train/raw-loss = 0.5603505373001099, train/logprobs = tensor([[-0.5620, -0.7770],
        [-1.1793, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14139829576015472
Epoch 0, Step 1732: train/loss = 0.4636138677597046, train/raw-loss = 0.37639880180358887, train/logprobs = tensor([[-0.6452, -3.7946],
        [-1.4577, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17443019151687622
Epoch 0, Step 1733: train/loss = 0.27521517872810364, train/raw-loss = 0.19546183943748474, train/logprobs = tensor([[-0.6335, -4.8476],
        [-1.4340, -0.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1595066785812378
Epoch 0, Step 1734: train/loss = 0.35271117091178894, train/raw-loss = 0.2751670479774475, train/logprobs = tensor([[-0.9900, -2.9280],
        [-2.1349, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15508821606636047
Epoch 0, Step 1735: train/loss = 0.48549187183380127, train/raw-loss = 0.38782942295074463, train/logprobs = tensor([[-0.9618, -3.4162],
        [-3.0566, -2.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19532492756843567
Epoch 0, Step 1736: train/loss = 0.382870614528656, train/raw-loss = 0.3190273344516754, train/logprobs = tensor([[-0.5246, -2.9253],
        [-2.2561, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12768657505512238
Epoch 0, Step 1737: train/loss = 0.5550041198730469, train/raw-loss = 0.4847170412540436, train/logprobs = tensor([[-0.4244, -1.3231],
        [-1.8510, -0.7399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14057423174381256
Epoch 0, Step 1738: train/loss = 0.5639522075653076, train/raw-loss = 0.47507935762405396, train/logprobs = tensor([[-0.9159, -3.9214],
        [-2.1569, -2.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17774565517902374
Epoch 0, Step 1739: train/loss = 0.5101838111877441, train/raw-loss = 0.45356565713882446, train/logprobs = tensor([[-0.5754, -1.2460],
        [-1.4469, -0.5431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11323638260364532
Epoch 0, Step 1740: train/loss = 0.6006522178649902, train/raw-loss = 0.5292930603027344, train/logprobs = tensor([[-0.8042, -1.7587],
        [-1.5040, -1.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1427183449268341
Epoch 0, Step 1741: train/loss = 0.2601495087146759, train/raw-loss = 0.1656491458415985, train/logprobs = tensor([[-0.7554, -6.7535],
        [-2.1370, -1.6013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18900075554847717
Epoch 0, Step 1742: train/loss = 0.4498174786567688, train/raw-loss = 0.3736005425453186, train/logprobs = tensor([[-0.6538, -1.1742],
        [-3.1155, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1524338573217392
Epoch 0, Step 1743: train/loss = 0.46225690841674805, train/raw-loss = 0.3836597204208374, train/logprobs = tensor([[-0.8655, -2.8300],
        [-1.6784, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1571943163871765
Epoch 0, Step 1744: train/loss = 0.379260778427124, train/raw-loss = 0.31372591853141785, train/logprobs = tensor([[-1.2445, -2.9953],
        [-3.2121, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13106971979141235
Epoch 0, Step 1745: train/loss = 0.2940196692943573, train/raw-loss = 0.2005843222141266, train/logprobs = tensor([[-0.8463, -3.8734],
        [-2.8389, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18687067925930023
Epoch 0, Step 1746: train/loss = 0.5027442574501038, train/raw-loss = 0.45472171902656555, train/logprobs = tensor([[-0.3751, -2.9848],
        [-0.5243, -0.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09604506939649582
Epoch 0, Step 1747: train/loss = 0.28484514355659485, train/raw-loss = 0.1876082420349121, train/logprobs = tensor([[-0.6588, -3.0382],
        [-4.3546, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19447383284568787
Epoch 0, Step 1748: train/loss = 0.8604526519775391, train/raw-loss = 0.7714043855667114, train/logprobs = tensor([[-0.8342, -1.5564],
        [-3.0975, -2.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17809633910655975
Epoch 0, Step 1749: train/loss = 0.362662136554718, train/raw-loss = 0.28024280071258545, train/logprobs = tensor([[-0.5718, -5.0343],
        [-2.2677, -1.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16483864188194275
Epoch 0, Step 1750: train/loss = 0.364526629447937, train/raw-loss = 0.29302549362182617, train/logprobs = tensor([[-0.6949, -4.0137],
        [-1.3230, -0.8810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14300231635570526
Epoch 0, Step 1751: train/loss = 0.6675769090652466, train/raw-loss = 0.5684347152709961, train/logprobs = tensor([[-0.8766, -2.6588],
        [-4.2771, -2.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19828438758850098
Epoch 0, Step 1752: train/loss = 0.5146752595901489, train/raw-loss = 0.4363173544406891, train/logprobs = tensor([[-0.8797, -2.5018],
        [-1.7686, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567157506942749
Epoch 0, Step 1753: train/loss = 0.4010714590549469, train/raw-loss = 0.30816173553466797, train/logprobs = tensor([[-0.7353, -2.8638],
        [-2.6677, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18581943213939667
Epoch 0, Step 1754: train/loss = 0.4630298912525177, train/raw-loss = 0.38810327649116516, train/logprobs = tensor([[-0.6679, -2.4198],
        [-2.4753, -0.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14985325932502747
Epoch 0, Step 1755: train/loss = 0.6360889077186584, train/raw-loss = 0.5687859654426575, train/logprobs = tensor([[-0.9217, -1.3791],
        [-2.2759, -1.0275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13460594415664673
Epoch 0, Step 1756: train/loss = 0.29153189063072205, train/raw-loss = 0.208945170044899, train/logprobs = tensor([[-0.5496, -5.1356],
        [-1.3601, -1.3647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16517341136932373
Epoch 0, Step 1757: train/loss = 0.5267449617385864, train/raw-loss = 0.4410679042339325, train/logprobs = tensor([[-0.4103, -3.1387],
        [-1.9896, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1713540405035019
Epoch 0, Step 1758: train/loss = 0.5554150342941284, train/raw-loss = 0.49428629875183105, train/logprobs = tensor([[-0.3940, -3.0796],
        [-0.5452, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12225756794214249
Epoch 0, Step 1759: train/loss = 0.4428155720233917, train/raw-loss = 0.3865794539451599, train/logprobs = tensor([[-0.5996, -2.4531],
        [-1.3795, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11247225105762482
Epoch 0, Step 1760: train/loss = 0.43585488200187683, train/raw-loss = 0.33562636375427246, train/logprobs = tensor([[-1.3487, -4.3525],
        [-4.5695, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20045706629753113
Epoch 0, Step 1761: train/loss = 0.5097127556800842, train/raw-loss = 0.4166225790977478, train/logprobs = tensor([[-1.6641, -4.5960],
        [-3.2641, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18618032336235046
Epoch 0, Step 1762: train/loss = 0.3672585189342499, train/raw-loss = 0.29704204201698303, train/logprobs = tensor([[-0.4160, -3.8442],
        [-1.0496, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14043296873569489
Epoch 0, Step 1763: train/loss = 0.28824976086616516, train/raw-loss = 0.20137540996074677, train/logprobs = tensor([[-1.0471, -3.8649],
        [-2.9361, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1737487018108368
Epoch 0, Step 1764: train/loss = 0.5162556171417236, train/raw-loss = 0.43615296483039856, train/logprobs = tensor([[-0.8073, -3.5885],
        [-4.0120, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16020533442497253
Epoch 0, Step 1765: train/loss = 0.3343680202960968, train/raw-loss = 0.2624781131744385, train/logprobs = tensor([[-0.5483, -4.4486],
        [-1.5101, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1437799036502838
Epoch 0, Step 1766: train/loss = 0.3441106081008911, train/raw-loss = 0.2538307309150696, train/logprobs = tensor([[-0.8844, -6.1256],
        [-2.5050, -1.5831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18055973947048187
Epoch 0, Step 1767: train/loss = 0.6176961660385132, train/raw-loss = 0.5767357349395752, train/logprobs = tensor([[-0.3736, -0.7186],
        [-0.6666, -0.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192095160484314
Epoch 0, Step 1768: train/loss = 0.48301953077316284, train/raw-loss = 0.3898332118988037, train/logprobs = tensor([[-0.8280, -3.4948],
        [-1.7631, -1.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18637260794639587
Epoch 0, Step 1769: train/loss = 0.37896695733070374, train/raw-loss = 0.29471471905708313, train/logprobs = tensor([[-0.7582, -4.3502],
        [-1.5822, -1.2556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16850444674491882
Epoch 0, Step 1770: train/loss = 0.527815043926239, train/raw-loss = 0.440177857875824, train/logprobs = tensor([[-1.1336, -1.8594],
        [-4.1978, -2.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17527428269386292
Epoch 0, Step 1771: train/loss = 0.32029372453689575, train/raw-loss = 0.2372332215309143, train/logprobs = tensor([[-0.5803, -4.5566],
        [-1.3414, -1.1433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1661209911108017
Epoch 0, Step 1772: train/loss = 0.5552441477775574, train/raw-loss = 0.4988931119441986, train/logprobs = tensor([[-0.7104, -1.5337],
        [-1.7493, -0.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11270210146903992
Epoch 0, Step 1773: train/loss = 0.3047514855861664, train/raw-loss = 0.2342216819524765, train/logprobs = tensor([[-0.5426, -4.3161],
        [-1.9624, -1.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14105957746505737
Epoch 0, Step 1774: train/loss = 0.1866133213043213, train/raw-loss = 0.0947972908616066, train/logprobs = tensor([[-0.8259, -7.1959],
        [-3.5421, -1.9740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1836320459842682
Epoch 0, Step 1775: train/loss = 0.43736904859542847, train/raw-loss = 0.3551778197288513, train/logprobs = tensor([[-0.5424, -2.2515],
        [-2.2254, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643824279308319
Epoch 0, Step 1776: train/loss = 0.5168566703796387, train/raw-loss = 0.4507513642311096, train/logprobs = tensor([[-0.4068, -3.6994],
        [-0.6562, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322106122970581
Epoch 0, Step 1777: train/loss = 0.5360366702079773, train/raw-loss = 0.46961310505867004, train/logprobs = tensor([[-0.6353, -2.4546],
        [-3.2485, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328471451997757
Epoch 0, Step 1778: train/loss = 1.2280964851379395, train/raw-loss = 1.1388384103775024, train/logprobs = tensor([[-0.8994, -1.4692],
        [-1.9057, -2.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17851626873016357
Epoch 0, Step 1779: train/loss = 0.2224130630493164, train/raw-loss = 0.14019085466861725, train/logprobs = tensor([[-0.5599, -6.0786],
        [-2.0640, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16444441676139832
Epoch 0, Step 1780: train/loss = 0.540939211845398, train/raw-loss = 0.47834512591362, train/logprobs = tensor([[-0.5821, -1.3542],
        [-2.0228, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12518814206123352
Epoch 0, Step 1781: train/loss = 0.42306989431381226, train/raw-loss = 0.35750865936279297, train/logprobs = tensor([[-1.2150, -2.8920],
        [-2.2289, -0.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13112248480319977
Epoch 0, Step 1782: train/loss = 0.543620228767395, train/raw-loss = 0.4857211112976074, train/logprobs = tensor([[-0.4665, -1.4429],
        [-1.0558, -0.4289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1157982125878334
Epoch 0, Step 1783: train/loss = 0.5198032855987549, train/raw-loss = 0.4530126452445984, train/logprobs = tensor([[-0.6407, -1.8467],
        [-1.8494, -0.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13358132541179657
Epoch 0, Step 1784: train/loss = 0.5121541023254395, train/raw-loss = 0.4345436096191406, train/logprobs = tensor([[-0.7297, -3.1357],
        [-1.1762, -1.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15522103011608124
Epoch 0, Step 1785: train/loss = 0.3926258683204651, train/raw-loss = 0.30635231733322144, train/logprobs = tensor([[-1.4097, -3.8151],
        [-2.7595, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17254705727100372
Epoch 0, Step 1786: train/loss = 0.38745957612991333, train/raw-loss = 0.3267863988876343, train/logprobs = tensor([[-1.0190, -4.3221],
        [-2.6784, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12134633958339691
Epoch 0, Step 1787: train/loss = 0.21829530596733093, train/raw-loss = 0.0906761959195137, train/logprobs = tensor([[-0.7496, -4.5431],
        [-4.0847, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25523820519447327
Epoch 0, Step 1788: train/loss = 0.4549436867237091, train/raw-loss = 0.36171361804008484, train/logprobs = tensor([[-1.0046, -4.2097],
        [-2.6594, -1.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18646012246608734
Epoch 0, Step 1789: train/loss = 0.47769641876220703, train/raw-loss = 0.3969861567020416, train/logprobs = tensor([[-1.4767, -4.4270],
        [-2.6361, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1614205539226532
Epoch 0, Step 1790: train/loss = 0.5172958374023438, train/raw-loss = 0.4591742157936096, train/logprobs = tensor([[-0.7038, -1.3820],
        [-2.2576, -0.7099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11624322086572647
Epoch 0, Step 1791: train/loss = 0.4472915828227997, train/raw-loss = 0.37972962856292725, train/logprobs = tensor([[-0.6724, -3.4573],
        [-1.1472, -0.6938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1351238489151001
Epoch 0, Step 1792: train/loss = 0.4536181688308716, train/raw-loss = 0.38776153326034546, train/logprobs = tensor([[-0.6836, -4.2971],
        [-1.4328, -1.2106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13171328604221344
Epoch 0, Step 1793: train/loss = 0.36029377579689026, train/raw-loss = 0.3059329390525818, train/logprobs = tensor([[-1.0036, -3.2758],
        [-2.1305, -1.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10872172564268112
Epoch 0, Step 1794: train/loss = 0.45010533928871155, train/raw-loss = 0.39040499925613403, train/logprobs = tensor([[-0.5777, -1.4889],
        [-2.6085, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11940065771341324
Epoch 0, Step 1795: train/loss = 0.4229293167591095, train/raw-loss = 0.3569287955760956, train/logprobs = tensor([[-0.6267, -2.5118],
        [-1.2636, -0.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1320011168718338
Epoch 0, Step 1796: train/loss = 0.415846049785614, train/raw-loss = 0.3460000157356262, train/logprobs = tensor([[-0.5493, -2.2870],
        [-2.0973, -0.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1396920531988144
Epoch 0, Step 1797: train/loss = 0.625176191329956, train/raw-loss = 0.5572324991226196, train/logprobs = tensor([[-1.4287, -2.4234],
        [-2.9522, -1.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1358875334262848
Epoch 0, Step 1798: train/loss = 0.5121057033538818, train/raw-loss = 0.44476792216300964, train/logprobs = tensor([[-0.8154, -2.2692],
        [-1.1913, -0.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1346755176782608
Epoch 0, Step 1799: train/loss = 1.002662181854248, train/raw-loss = 0.9183964729309082, train/logprobs = tensor([[-0.9088, -2.9137],
        [-1.5867, -2.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16853149235248566
Epoch 0, Step 1800: train/loss = 0.5928822755813599, train/raw-loss = 0.4944989085197449, train/logprobs = tensor([[-0.5866, -3.9086],
        [-4.2950, -1.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19676673412322998
Epoch 0, Step 1801: train/loss = 0.41472721099853516, train/raw-loss = 0.32210293412208557, train/logprobs = tensor([[-1.5829, -5.2036],
        [-2.0863, -1.2944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852485090494156
Epoch 0, Step 1802: train/loss = 0.38016292452812195, train/raw-loss = 0.2979743182659149, train/logprobs = tensor([[-0.8264, -2.9316],
        [-2.8831, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16437728703022003
Epoch 0, Step 1803: train/loss = 0.3547241985797882, train/raw-loss = 0.2679748833179474, train/logprobs = tensor([[-1.3082, -4.7118],
        [-2.3982, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17349864542484283
Epoch 0, Step 1804: train/loss = 0.24841994047164917, train/raw-loss = 0.17326036095619202, train/logprobs = tensor([[-0.7751, -3.5300],
        [-3.6978, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1503191590309143
Epoch 0, Step 1805: train/loss = 0.4131002426147461, train/raw-loss = 0.35130566358566284, train/logprobs = tensor([[-0.5295, -3.2370],
        [-1.0741, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12358921766281128
Epoch 0, Step 1806: train/loss = 0.40727168321609497, train/raw-loss = 0.32604968547821045, train/logprobs = tensor([[-0.7765, -1.9417],
        [-3.1852, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16244405508041382
Epoch 0, Step 1807: train/loss = 0.522919774055481, train/raw-loss = 0.4716680645942688, train/logprobs = tensor([[-0.5745, -1.6653],
        [-0.9393, -0.8237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1025034636259079
Epoch 0, Step 1808: train/loss = 0.43989139795303345, train/raw-loss = 0.3491264879703522, train/logprobs = tensor([[-0.8642, -4.0129],
        [-2.6042, -2.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18152984976768494
Epoch 0, Step 1809: train/loss = 0.5282086133956909, train/raw-loss = 0.4659982919692993, train/logprobs = tensor([[-0.5270, -1.7112],
        [-1.1767, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12442068010568619
Epoch 0, Step 1810: train/loss = 0.499900758266449, train/raw-loss = 0.4328058958053589, train/logprobs = tensor([[-0.5888, -3.3407],
        [-1.0700, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13418972492218018
Epoch 0, Step 1811: train/loss = 0.44042569398880005, train/raw-loss = 0.3674718141555786, train/logprobs = tensor([[-0.5753, -2.4945],
        [-1.8077, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14590775966644287
Epoch 0, Step 1812: train/loss = 0.55319744348526, train/raw-loss = 0.49037379026412964, train/logprobs = tensor([[-1.0726, -1.8622],
        [-1.4679, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12564723193645477
Epoch 0, Step 1813: train/loss = 0.4871573746204376, train/raw-loss = 0.4135955572128296, train/logprobs = tensor([[-0.5727, -2.7748],
        [-1.3098, -0.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1471235752105713
Epoch 0, Step 1814: train/loss = 0.5136803388595581, train/raw-loss = 0.42425450682640076, train/logprobs = tensor([[-0.5631, -3.1255],
        [-2.4633, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788516640663147
Epoch 0, Step 1815: train/loss = 0.6070056557655334, train/raw-loss = 0.553916335105896, train/logprobs = tensor([[-0.9748, -1.4691],
        [-2.1475, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10617861151695251
Epoch 0, Step 1816: train/loss = 0.49434125423431396, train/raw-loss = 0.44018834829330444, train/logprobs = tensor([[-0.6360, -3.4857],
        [-0.9114, -0.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10830572992563248
Epoch 0, Step 1817: train/loss = 0.3556199073791504, train/raw-loss = 0.2683854401111603, train/logprobs = tensor([[-1.2664, -4.8973],
        [-2.9798, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17446890473365784
Epoch 0, Step 1818: train/loss = 0.29587453603744507, train/raw-loss = 0.22567617893218994, train/logprobs = tensor([[-0.6446, -5.6690],
        [-1.7975, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14039672911167145
Epoch 0, Step 1819: train/loss = 0.37363168597221375, train/raw-loss = 0.2936432957649231, train/logprobs = tensor([[-0.6466, -3.4589],
        [-2.6105, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1599767506122589
Epoch 0, Step 1820: train/loss = 0.34708091616630554, train/raw-loss = 0.25522100925445557, train/logprobs = tensor([[-0.8884, -4.3803],
        [-2.9110, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18371978402137756
Epoch 0, Step 1821: train/loss = 0.41425031423568726, train/raw-loss = 0.3358404040336609, train/logprobs = tensor([[-0.7601, -3.7166],
        [-1.4085, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15681979060173035
Epoch 0, Step 1822: train/loss = 0.40559491515159607, train/raw-loss = 0.3197709918022156, train/logprobs = tensor([[-1.8627, -5.2566],
        [-2.4579, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17164786159992218
Epoch 0, Step 1823: train/loss = 0.3921188712120056, train/raw-loss = 0.32972121238708496, train/logprobs = tensor([[-0.8005, -3.6642],
        [-1.6147, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1247953325510025
Epoch 0, Step 1824: train/loss = 0.4567633271217346, train/raw-loss = 0.3722078204154968, train/logprobs = tensor([[-0.8251, -5.8746],
        [-2.5171, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691109836101532
Epoch 0, Step 1825: train/loss = 0.6603102684020996, train/raw-loss = 0.5937270522117615, train/logprobs = tensor([[-1.3528, -6.6774],
        [-2.8116, -6.3980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13316647708415985
Epoch 0, Step 1826: train/loss = 0.3880290985107422, train/raw-loss = 0.3073098659515381, train/logprobs = tensor([[-0.5757, -2.7356],
        [-1.9376, -0.8597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1614384949207306
Epoch 0, Step 1827: train/loss = 0.443452388048172, train/raw-loss = 0.33220958709716797, train/logprobs = tensor([[-0.5255, -2.9453],
        [-2.7289, -1.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22248558700084686
Epoch 0, Step 1828: train/loss = 0.4256681203842163, train/raw-loss = 0.3380940556526184, train/logprobs = tensor([[-1.0838, -3.1659],
        [-2.4170, -0.6299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17514808475971222
Epoch 0, Step 1829: train/loss = 0.48388877511024475, train/raw-loss = 0.42129966616630554, train/logprobs = tensor([[-0.5570, -1.6203],
        [-1.4383, -1.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12517812848091125
Epoch 0, Step 1830: train/loss = 0.40637731552124023, train/raw-loss = 0.32499584555625916, train/logprobs = tensor([[-0.6677, -2.7747],
        [-4.0464, -1.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16276295483112335
Epoch 0, Step 1831: train/loss = 0.296322762966156, train/raw-loss = 0.19303640723228455, train/logprobs = tensor([[-0.5654, -5.5588],
        [-4.2572, -0.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20657271146774292
Epoch 0, Step 1832: train/loss = 0.7139066457748413, train/raw-loss = 0.6649421453475952, train/logprobs = tensor([[-0.5154, -0.4952],
        [-1.1404, -0.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0979289710521698
Epoch 0, Step 1833: train/loss = 0.6411622762680054, train/raw-loss = 0.5833817720413208, train/logprobs = tensor([[-0.6961, -1.3762],
        [-0.6793, -0.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11556100845336914
Epoch 0, Step 1834: train/loss = 0.5092344880104065, train/raw-loss = 0.44692039489746094, train/logprobs = tensor([[-0.8281, -2.7806],
        [-1.5642, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12462816387414932
Epoch 0, Step 1835: train/loss = 0.4011059105396271, train/raw-loss = 0.307775616645813, train/logprobs = tensor([[-0.7013, -2.1976],
        [-2.9130, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18666060268878937
Epoch 0, Step 1836: train/loss = 0.4762234091758728, train/raw-loss = 0.40637120604515076, train/logprobs = tensor([[-0.5877, -4.6802],
        [-1.2932, -0.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13970448076725006
Epoch 0, Step 1837: train/loss = 0.6181250214576721, train/raw-loss = 0.5259861946105957, train/logprobs = tensor([[-0.8679, -2.3641],
        [-2.0170, -2.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18427766859531403
Epoch 0, Step 1838: train/loss = 0.6543138027191162, train/raw-loss = 0.5847674608230591, train/logprobs = tensor([[-0.5355, -0.9818],
        [-1.3709, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1390928328037262
Epoch 0, Step 1839: train/loss = 0.3764195740222931, train/raw-loss = 0.3054339289665222, train/logprobs = tensor([[-0.8020, -3.2464],
        [-2.2572, -0.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14197130501270294
Epoch 0, Step 1840: train/loss = 0.6513118743896484, train/raw-loss = 0.5546531677246094, train/logprobs = tensor([[-1.1523, -4.3029],
        [-2.7462, -2.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19331739842891693
Epoch 0, Step 1841: train/loss = 0.5017439723014832, train/raw-loss = 0.4042212963104248, train/logprobs = tensor([[-0.6831, -3.2542],
        [-2.9601, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950453370809555
Epoch 0, Step 1842: train/loss = 0.5867592096328735, train/raw-loss = 0.5148609280586243, train/logprobs = tensor([[-0.7382, -2.7220],
        [-1.6762, -2.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14379668235778809
Epoch 0, Step 1843: train/loss = 0.7182743549346924, train/raw-loss = 0.6456131935119629, train/logprobs = tensor([[-0.6698, -0.6786],
        [-1.3098, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14532232284545898
Epoch 0, Step 1844: train/loss = 0.3336343765258789, train/raw-loss = 0.2456188201904297, train/logprobs = tensor([[-0.7936, -2.8519],
        [-3.9746, -0.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17603111267089844
Epoch 0, Step 1845: train/loss = 0.27102425694465637, train/raw-loss = 0.19051417708396912, train/logprobs = tensor([[-0.6352, -3.8912],
        [-1.6234, -0.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1610201895236969
Epoch 0, Step 1846: train/loss = 0.30612534284591675, train/raw-loss = 0.2280794084072113, train/logprobs = tensor([[-0.5420, -6.1571],
        [-0.9318, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1560918539762497
Epoch 0, Step 1847: train/loss = 0.3084011375904083, train/raw-loss = 0.2189546525478363, train/logprobs = tensor([[-1.1831, -4.5571],
        [-3.6028, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17889297008514404
Epoch 0, Step 1848: train/loss = 0.6576002836227417, train/raw-loss = 0.5688510537147522, train/logprobs = tensor([[-0.8603, -1.0605],
        [-1.3994, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17749853432178497
Epoch 0, Step 1849: train/loss = 0.2790660560131073, train/raw-loss = 0.182871013879776, train/logprobs = tensor([[-0.7540, -5.1562],
        [-3.0258, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1923900842666626
Epoch 0, Step 1850: train/loss = 0.31660571694374084, train/raw-loss = 0.22518092393875122, train/logprobs = tensor([[-0.6571, -2.7464],
        [-2.9928, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284958600997925
Epoch 0, Step 1851: train/loss = 0.4591965079307556, train/raw-loss = 0.393764853477478, train/logprobs = tensor([[-1.2463, -2.6859],
        [-1.9127, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308632344007492
Epoch 0, Step 1852: train/loss = 0.27614593505859375, train/raw-loss = 0.1988791525363922, train/logprobs = tensor([[-0.6704, -4.4880],
        [-1.3270, -0.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1545334756374359
Epoch 0, Step 1853: train/loss = 0.3994588553905487, train/raw-loss = 0.3191414475440979, train/logprobs = tensor([[-1.1244, -3.1216],
        [-3.0840, -1.2521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1606348156929016
Epoch 0, Step 1854: train/loss = 0.36558493971824646, train/raw-loss = 0.2728794813156128, train/logprobs = tensor([[-0.5630, -4.1596],
        [-2.2121, -0.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18541094660758972
Epoch 0, Step 1855: train/loss = 0.6525869369506836, train/raw-loss = 0.5835865139961243, train/logprobs = tensor([[-0.6958, -2.0894],
        [-1.0230, -1.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380007565021515
Epoch 0, Step 1856: train/loss = 0.39817309379577637, train/raw-loss = 0.31978440284729004, train/logprobs = tensor([[-0.7532, -2.7578],
        [-2.7084, -0.8261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15677742660045624
Epoch 0, Step 1857: train/loss = 0.6103209853172302, train/raw-loss = 0.5202029943466187, train/logprobs = tensor([[-0.7749, -1.9202],
        [-2.6394, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802358776330948
Epoch 0, Step 1858: train/loss = 0.36668381094932556, train/raw-loss = 0.27261388301849365, train/logprobs = tensor([[-0.8737, -5.4849],
        [-1.8513, -1.4933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18813984096050262
Epoch 0, Step 1859: train/loss = 0.5096291303634644, train/raw-loss = 0.42812490463256836, train/logprobs = tensor([[-0.4741, -4.1365],
        [-0.7535, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630084216594696
Epoch 0, Step 1860: train/loss = 0.37142670154571533, train/raw-loss = 0.2915302515029907, train/logprobs = tensor([[-1.3686, -4.8916],
        [-2.7245, -1.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15979281067848206
Epoch 0, Step 1861: train/loss = 0.415607750415802, train/raw-loss = 0.33252811431884766, train/logprobs = tensor([[-0.5931, -2.9823],
        [-2.3603, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1661592572927475
Epoch 0, Step 1862: train/loss = 0.3775078058242798, train/raw-loss = 0.26942113041877747, train/logprobs = tensor([[-0.8520, -4.7467],
        [-2.6059, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21617335081100464
Epoch 0, Step 1863: train/loss = 0.3988882899284363, train/raw-loss = 0.3210556209087372, train/logprobs = tensor([[-0.4764, -3.0883],
        [-2.3242, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.155665323138237
Epoch 0, Step 1864: train/loss = 0.3110285699367523, train/raw-loss = 0.22620609402656555, train/logprobs = tensor([[-0.5639, -3.9290],
        [-3.4196, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16964493691921234
Epoch 0, Step 1865: train/loss = 0.3625176250934601, train/raw-loss = 0.27019423246383667, train/logprobs = tensor([[-0.9842, -4.4492],
        [-2.1447, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1846468299627304
Epoch 0, Step 1866: train/loss = 0.6015658378601074, train/raw-loss = 0.5474334955215454, train/logprobs = tensor([[-0.3712, -2.6508],
        [-0.8639, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10826478153467178
Epoch 0, Step 1867: train/loss = 0.34652408957481384, train/raw-loss = 0.270061731338501, train/logprobs = tensor([[-0.5579, -5.5822],
        [-1.0577, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15292474627494812
Epoch 0, Step 1868: train/loss = 0.2762078642845154, train/raw-loss = 0.16409742832183838, train/logprobs = tensor([[-0.9477, -4.8513],
        [-4.9360, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2242208868265152
Epoch 0, Step 1869: train/loss = 0.2810765206813812, train/raw-loss = 0.1963779330253601, train/logprobs = tensor([[-1.2051, -5.2463],
        [-2.5989, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16939719021320343
Epoch 0, Step 1870: train/loss = 0.32936158776283264, train/raw-loss = 0.22583286464214325, train/logprobs = tensor([[-0.9419, -4.5837],
        [-2.8022, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2070574313402176
Epoch 0, Step 1871: train/loss = 0.5104129314422607, train/raw-loss = 0.4499151110649109, train/logprobs = tensor([[-0.5792, -2.9024],
        [-0.9531, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12099561095237732
Epoch 0, Step 1872: train/loss = 0.40519005060195923, train/raw-loss = 0.3185466527938843, train/logprobs = tensor([[-0.6293, -2.5176],
        [-3.4670, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1732868254184723
Epoch 0, Step 1873: train/loss = 0.5625193119049072, train/raw-loss = 0.49557650089263916, train/logprobs = tensor([[-0.8581, -3.2542],
        [-1.5100, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13388575613498688
Epoch 0, Step 1874: train/loss = 0.528115451335907, train/raw-loss = 0.43148142099380493, train/logprobs = tensor([[-1.2797, -3.3086],
        [-1.8720, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19326798617839813
Epoch 0, Step 1875: train/loss = 0.30517616868019104, train/raw-loss = 0.22225725650787354, train/logprobs = tensor([[-1.2657, -6.0877],
        [-1.8480, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16583780944347382
Epoch 0, Step 1876: train/loss = 0.3759724497795105, train/raw-loss = 0.31015560030937195, train/logprobs = tensor([[-0.9592, -1.9825],
        [-3.5505, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316336691379547
Epoch 0, Step 1877: train/loss = 0.6043270230293274, train/raw-loss = 0.5398634076118469, train/logprobs = tensor([[-0.8365, -6.2847],
        [-2.6902, -2.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12892739474773407
Epoch 0, Step 1878: train/loss = 0.34824374318122864, train/raw-loss = 0.2450834959745407, train/logprobs = tensor([[-0.7234, -3.5402],
        [-2.9192, -1.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20632049441337585
Epoch 0, Step 1879: train/loss = 0.40706565976142883, train/raw-loss = 0.3007500469684601, train/logprobs = tensor([[-0.7568, -4.8198],
        [-1.8273, -1.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126312255859375
Epoch 0, Step 1880: train/loss = 0.9946844577789307, train/raw-loss = 0.9045436978340149, train/logprobs = tensor([[-1.5199, -2.8073],
        [-3.7584, -3.9042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18028154969215393
Epoch 0, Step 1881: train/loss = 0.8488134741783142, train/raw-loss = 0.7688231468200684, train/logprobs = tensor([[-0.7357, -2.0059],
        [-1.4949, -2.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15998074412345886
Epoch 0, Step 1882: train/loss = 0.48118457198143005, train/raw-loss = 0.381955623626709, train/logprobs = tensor([[-1.0669, -2.4016],
        [-5.5539, -1.6492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19845795631408691
Epoch 0, Step 1883: train/loss = 0.18422333896160126, train/raw-loss = 0.07310344278812408, train/logprobs = tensor([[-1.4912, -5.4435],
        [-5.8712, -0.9333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22223979234695435
Epoch 0, Step 1884: train/loss = 0.36211729049682617, train/raw-loss = 0.28817373514175415, train/logprobs = tensor([[-0.4189, -4.2828],
        [-2.2490, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14788706600666046
Epoch 0, Step 1885: train/loss = 0.4106144309043884, train/raw-loss = 0.32238417863845825, train/logprobs = tensor([[-0.9280, -3.3610],
        [-2.5596, -2.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17646054923534393
Epoch 0, Step 1886: train/loss = 0.5658232569694519, train/raw-loss = 0.4763663709163666, train/logprobs = tensor([[-1.0591, -2.2845],
        [-1.9073, -1.6977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17891377210617065
Epoch 0, Step 1887: train/loss = 0.46788400411605835, train/raw-loss = 0.368406742811203, train/logprobs = tensor([[-0.9014, -6.8479],
        [-4.0653, -2.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1989545375108719
Epoch 0, Step 1888: train/loss = 0.3991093039512634, train/raw-loss = 0.2935793995857239, train/logprobs = tensor([[-0.9942, -2.4566],
        [-3.2250, -0.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2110598087310791
Epoch 0, Step 1889: train/loss = 0.4843664765357971, train/raw-loss = 0.3909119963645935, train/logprobs = tensor([[-0.9706, -2.6612],
        [-1.8151, -1.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18690890073776245
Epoch 0, Step 1890: train/loss = 0.24888144433498383, train/raw-loss = 0.13687723875045776, train/logprobs = tensor([[-0.6803, -5.7619],
        [-2.7983, -1.4308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22400841116905212
Epoch 0, Step 1891: train/loss = 0.49224382638931274, train/raw-loss = 0.42725810408592224, train/logprobs = tensor([[-1.3910, -3.4409],
        [-2.4790, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.129971444606781
Epoch 0, Step 1892: train/loss = 0.4658951759338379, train/raw-loss = 0.36927759647369385, train/logprobs = tensor([[-1.0176, -4.5428],
        [-2.1409, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19323515892028809
Epoch 0, Step 1893: train/loss = 0.24699977040290833, train/raw-loss = 0.13617002964019775, train/logprobs = tensor([[-0.7167, -3.6605],
        [-3.5566, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22165948152542114
Epoch 0, Step 1894: train/loss = 0.6794808506965637, train/raw-loss = 0.6187164783477783, train/logprobs = tensor([[-0.8550, -0.9600],
        [-1.8250, -1.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12152883410453796
Epoch 0, Step 1895: train/loss = 0.48895472288131714, train/raw-loss = 0.41350865364074707, train/logprobs = tensor([[-0.9842, -1.7775],
        [-2.2796, -0.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15089210867881775
Epoch 0, Step 1896: train/loss = 0.4421243667602539, train/raw-loss = 0.3647255003452301, train/logprobs = tensor([[-0.7652, -1.8841],
        [-2.4112, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1547977179288864
Epoch 0, Step 1897: train/loss = 0.6105657815933228, train/raw-loss = 0.5214555859565735, train/logprobs = tensor([[-0.9570, -1.4154],
        [-2.1087, -0.5769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17822040617465973
Epoch 0, Step 1898: train/loss = 0.35118719935417175, train/raw-loss = 0.2572120726108551, train/logprobs = tensor([[-1.4013, -3.3179],
        [-2.8954, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18795037269592285
Epoch 0, Step 1899: train/loss = 0.1942388117313385, train/raw-loss = 0.08981212973594666, train/logprobs = tensor([[-0.8465, -5.4612],
        [-3.6558, -1.5723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2088533490896225
Epoch 0, Step 1900: train/loss = 0.397952139377594, train/raw-loss = 0.27872714400291443, train/logprobs = tensor([[-0.7240, -1.8178],
        [-3.8238, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2384500354528427
Epoch 0, Step 1901: train/loss = 0.6993399858474731, train/raw-loss = 0.596664309501648, train/logprobs = tensor([[-1.6884, -4.9259],
        [-3.5271, -3.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053513377904892
Epoch 0, Step 1902: train/loss = 0.2532268166542053, train/raw-loss = 0.11649050563573837, train/logprobs = tensor([[-0.7493, -4.4959],
        [-4.3347, -1.4528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2734726667404175
Epoch 0, Step 1903: train/loss = 0.6937796473503113, train/raw-loss = 0.6044861078262329, train/logprobs = tensor([[-1.0304, -4.5586],
        [-1.7601, -2.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17858707904815674
Epoch 0, Step 1904: train/loss = 0.4336932897567749, train/raw-loss = 0.3527129888534546, train/logprobs = tensor([[-0.6791, -3.5579],
        [-2.4719, -0.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16196057200431824
Epoch 0, Step 1905: train/loss = 0.4972161650657654, train/raw-loss = 0.4075522720813751, train/logprobs = tensor([[-0.8582, -3.5202],
        [-1.8669, -1.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17932775616645813
Epoch 0, Step 1906: train/loss = 0.7327689528465271, train/raw-loss = 0.6134003400802612, train/logprobs = tensor([[-0.6075, -2.1734],
        [-3.0537, -1.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2387373149394989
Epoch 0, Step 1907: train/loss = 0.254666268825531, train/raw-loss = 0.15983474254608154, train/logprobs = tensor([[-0.8115, -4.6984],
        [-2.8078, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18966299295425415
Epoch 0, Step 1908: train/loss = 0.6636384725570679, train/raw-loss = 0.5917361974716187, train/logprobs = tensor([[-0.6433, -1.7093],
        [-0.9513, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14380459487438202
Epoch 0, Step 1909: train/loss = 0.8567540645599365, train/raw-loss = 0.7471386194229126, train/logprobs = tensor([[-1.3614, -1.4818],
        [-2.9635, -2.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21923092007637024
Epoch 0, Step 1910: train/loss = 0.35279491543769836, train/raw-loss = 0.2794722318649292, train/logprobs = tensor([[-0.8671, -3.6999],
        [-1.8735, -1.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14664538204669952
Epoch 0, Step 1911: train/loss = 0.7684738039970398, train/raw-loss = 0.689486026763916, train/logprobs = tensor([[-0.4785, -4.1356],
        [-1.9006, -2.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797549486160278
Epoch 0, Step 1912: train/loss = 0.4476322531700134, train/raw-loss = 0.3527844548225403, train/logprobs = tensor([[-0.5433, -1.6298],
        [-3.1823, -0.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1896955668926239
Epoch 0, Step 1913: train/loss = 0.6258383989334106, train/raw-loss = 0.5628401041030884, train/logprobs = tensor([[-0.8649, -1.5181],
        [-2.8058, -1.7034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259964257478714
Epoch 0, Step 1914: train/loss = 0.37740957736968994, train/raw-loss = 0.2626132071018219, train/logprobs = tensor([[-1.2528, -3.9483],
        [-3.3518, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22959274053573608
Epoch 0, Step 1915: train/loss = 0.4031195342540741, train/raw-loss = 0.3135035037994385, train/logprobs = tensor([[-0.5733, -3.1030],
        [-2.8178, -0.9858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17923203110694885
Epoch 0, Step 1916: train/loss = 0.5230880975723267, train/raw-loss = 0.44227656722068787, train/logprobs = tensor([[-1.0416, -2.5378],
        [-1.5480, -1.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16162316501140594
Epoch 0, Step 1917: train/loss = 0.466201514005661, train/raw-loss = 0.38517534732818604, train/logprobs = tensor([[-1.2865, -3.3055],
        [-1.8467, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16205234825611115
Epoch 0, Step 1918: train/loss = 0.49252480268478394, train/raw-loss = 0.42100852727890015, train/logprobs = tensor([[-0.5393, -2.7273],
        [-2.2554, -0.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14303255081176758
Epoch 0, Step 1919: train/loss = 0.42080098390579224, train/raw-loss = 0.35684025287628174, train/logprobs = tensor([[-0.6279, -2.5740],
        [-1.3400, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12792152166366577
Epoch 0, Step 1920: train/loss = 0.5613899230957031, train/raw-loss = 0.4804762005805969, train/logprobs = tensor([[-0.8969, -2.6744],
        [-0.9805, -0.6440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16182735562324524
Epoch 0, Step 1921: train/loss = 0.6203476190567017, train/raw-loss = 0.5507782101631165, train/logprobs = tensor([[-1.0194, -2.1600],
        [-1.3871, -1.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13913871347904205
Epoch 0, Step 1922: train/loss = 0.3295297622680664, train/raw-loss = 0.24194371700286865, train/logprobs = tensor([[-1.2269, -5.2648],
        [-3.4364, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1751721054315567
Epoch 0, Step 1923: train/loss = 0.6369470357894897, train/raw-loss = 0.5604866147041321, train/logprobs = tensor([[-0.8835, -2.3394],
        [-1.7653, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1529206931591034
Epoch 0, Step 1924: train/loss = 0.2914862334728241, train/raw-loss = 0.1927468180656433, train/logprobs = tensor([[-0.9537, -6.2437],
        [-3.7281, -2.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19747881591320038
Epoch 0, Step 1925: train/loss = 0.4763350784778595, train/raw-loss = 0.40427324175834656, train/logprobs = tensor([[-1.4073, -5.3610],
        [-1.3710, -1.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14412367343902588
Epoch 0, Step 1926: train/loss = 0.5636143088340759, train/raw-loss = 0.4863879084587097, train/logprobs = tensor([[-0.7044, -2.5875],
        [-1.5095, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15445274114608765
Epoch 0, Step 1927: train/loss = 0.5710867643356323, train/raw-loss = 0.49753537774086, train/logprobs = tensor([[-0.9699, -3.6598],
        [-2.1859, -1.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14710280299186707
Epoch 0, Step 1928: train/loss = 0.6526485681533813, train/raw-loss = 0.5360627770423889, train/logprobs = tensor([[-1.0727, -6.1533],
        [-4.7723, -3.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23317161202430725
Epoch 0, Step 1929: train/loss = 0.29661494493484497, train/raw-loss = 0.2017572671175003, train/logprobs = tensor([[-0.6175, -4.0134],
        [-4.2851, -0.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18971535563468933
Epoch 0, Step 1930: train/loss = 0.44393593072891235, train/raw-loss = 0.37345701456069946, train/logprobs = tensor([[-1.5305, -3.9858],
        [-1.9373, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1409577578306198
Epoch 0, Step 1931: train/loss = 0.40739136934280396, train/raw-loss = 0.3341771960258484, train/logprobs = tensor([[-0.5717, -3.3538],
        [-2.7355, -0.5194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14642839133739471
Epoch 0, Step 1932: train/loss = 0.3700520992279053, train/raw-loss = 0.2499973475933075, train/logprobs = tensor([[-1.1384, -2.3061],
        [-3.4153, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24010950326919556
Epoch 0, Step 1933: train/loss = 0.3312762975692749, train/raw-loss = 0.23234418034553528, train/logprobs = tensor([[-0.6325, -5.2141],
        [-2.0218, -1.5068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19786421954631805
Epoch 0, Step 1934: train/loss = 0.5651622414588928, train/raw-loss = 0.4923470616340637, train/logprobs = tensor([[-0.6742, -2.9557],
        [-1.1559, -1.2154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456303745508194
Epoch 0, Step 1935: train/loss = 0.4853181540966034, train/raw-loss = 0.40328818559646606, train/logprobs = tensor([[-0.8066, -2.7722],
        [-2.2570, -1.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640598624944687
Epoch 0, Step 1936: train/loss = 0.5270981192588806, train/raw-loss = 0.4536833167076111, train/logprobs = tensor([[-0.5948, -1.2888],
        [-1.7854, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14682963490486145
Epoch 0, Step 1937: train/loss = 0.2455059289932251, train/raw-loss = 0.1503058820962906, train/logprobs = tensor([[-0.6628, -5.6205],
        [-1.7957, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19040009379386902
Epoch 0, Step 1938: train/loss = 0.34495073556900024, train/raw-loss = 0.25877538323402405, train/logprobs = tensor([[-0.7895, -2.6370],
        [-3.5574, -0.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17235064506530762
Epoch 0, Step 1939: train/loss = 0.5408989191055298, train/raw-loss = 0.47249290347099304, train/logprobs = tensor([[-0.3999, -1.5418],
        [-1.2062, -1.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13681204617023468
Epoch 0, Step 1940: train/loss = 0.5143446326255798, train/raw-loss = 0.4557704031467438, train/logprobs = tensor([[-0.7289, -1.8793],
        [-1.6243, -1.1260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11714845895767212
Epoch 0, Step 1941: train/loss = 0.36756330728530884, train/raw-loss = 0.2636609375476837, train/logprobs = tensor([[-0.8891, -2.4723],
        [-4.5251, -1.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20780475437641144
Epoch 0, Step 1942: train/loss = 0.485854834318161, train/raw-loss = 0.41813957691192627, train/logprobs = tensor([[-0.6543, -4.2981],
        [-0.6586, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13543057441711426
Epoch 0, Step 1943: train/loss = 0.5573768615722656, train/raw-loss = 0.48663246631622314, train/logprobs = tensor([[-0.5898, -1.9031],
        [-0.9711, -1.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14148885011672974
Epoch 0, Step 1944: train/loss = 0.6798961758613586, train/raw-loss = 0.6054025888442993, train/logprobs = tensor([[-0.7496, -3.2651],
        [-0.9723, -1.4548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14898717403411865
Epoch 0, Step 1945: train/loss = 0.4395958185195923, train/raw-loss = 0.34300827980041504, train/logprobs = tensor([[-1.0494, -3.9095],
        [-2.1656, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19317510724067688
Epoch 0, Step 1946: train/loss = 0.3903689384460449, train/raw-loss = 0.30132025480270386, train/logprobs = tensor([[-0.7196, -4.0210],
        [-1.4953, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17809735238552094
Epoch 0, Step 1947: train/loss = 0.32167473435401917, train/raw-loss = 0.23497632145881653, train/logprobs = tensor([[-1.1104, -3.7219],
        [-3.7553, -1.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17339682579040527
Epoch 0, Step 1948: train/loss = 0.4471338093280792, train/raw-loss = 0.359860360622406, train/logprobs = tensor([[-0.8865, -4.3223],
        [-2.3119, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17454688251018524
Epoch 0, Step 1949: train/loss = 0.3433225154876709, train/raw-loss = 0.2699284553527832, train/logprobs = tensor([[-0.8196, -3.3242],
        [-2.6013, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1467881053686142
Epoch 0, Step 1950: train/loss = 0.45609360933303833, train/raw-loss = 0.3910384178161621, train/logprobs = tensor([[-0.4729, -3.1740],
        [-0.7435, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13011042773723602
Epoch 0, Step 1951: train/loss = 0.34003913402557373, train/raw-loss = 0.21265754103660583, train/logprobs = tensor([[-0.8022, -3.6688],
        [-4.1217, -1.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2547631561756134
Epoch 0, Step 1952: train/loss = 0.3614460825920105, train/raw-loss = 0.2858315110206604, train/logprobs = tensor([[-0.6560, -4.0482],
        [-2.4896, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15122917294502258
Epoch 0, Step 1953: train/loss = 0.8826488256454468, train/raw-loss = 0.8019120097160339, train/logprobs = tensor([[-0.6190, -1.2035],
        [-1.9947, -2.3637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16147352755069733
Epoch 0, Step 1954: train/loss = 0.6145100593566895, train/raw-loss = 0.5463278889656067, train/logprobs = tensor([[-0.6385, -1.0488],
        [-1.2107, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13636431097984314
Epoch 0, Step 1955: train/loss = 0.2735726237297058, train/raw-loss = 0.17449736595153809, train/logprobs = tensor([[-1.7034, -5.5194],
        [-4.1202, -1.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19815053045749664
Epoch 0, Step 1956: train/loss = 0.25054383277893066, train/raw-loss = 0.15736249089241028, train/logprobs = tensor([[-1.1023, -5.9447],
        [-3.6269, -0.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18636265397071838
Epoch 0, Step 1957: train/loss = 0.4227898418903351, train/raw-loss = 0.3155856430530548, train/logprobs = tensor([[-0.5253, -3.7561],
        [-1.3988, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21440839767456055
Epoch 0, Step 1958: train/loss = 0.26983320713043213, train/raw-loss = 0.17864179611206055, train/logprobs = tensor([[-0.9808, -6.0405],
        [-3.8582, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18238279223442078
Epoch 0, Step 1959: train/loss = 0.5722228288650513, train/raw-loss = 0.492344468832016, train/logprobs = tensor([[-0.4336, -0.8522],
        [-2.7046, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15975673496723175
Epoch 0, Step 1960: train/loss = 0.5903552770614624, train/raw-loss = 0.5136023163795471, train/logprobs = tensor([[-1.2515, -1.3844],
        [-1.5723, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15350593626499176
Epoch 0, Step 1961: train/loss = 0.37549808621406555, train/raw-loss = 0.2705909013748169, train/logprobs = tensor([[-1.2745, -2.6918],
        [-2.8266, -1.1940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20981436967849731
Epoch 0, Step 1962: train/loss = 0.4837270975112915, train/raw-loss = 0.4102627635002136, train/logprobs = tensor([[-0.5614, -4.4298],
        [-1.0784, -1.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14692862331867218
Epoch 0, Step 1963: train/loss = 0.28846681118011475, train/raw-loss = 0.1947055459022522, train/logprobs = tensor([[-1.3802, -5.9767],
        [-4.1495, -1.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1875225305557251
Epoch 0, Step 1964: train/loss = 0.6739059686660767, train/raw-loss = 0.5720623135566711, train/logprobs = tensor([[-1.0953, -4.9912],
        [-3.8503, -3.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2036874145269394
Epoch 0, Step 1965: train/loss = 0.4504956007003784, train/raw-loss = 0.37921345233917236, train/logprobs = tensor([[-1.1637, -3.9698],
        [-2.3282, -1.4555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14256420731544495
Epoch 0, Step 1966: train/loss = 0.4134492874145508, train/raw-loss = 0.32541948556900024, train/logprobs = tensor([[-0.6689, -4.7336],
        [-2.7052, -1.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17605960369110107
Epoch 0, Step 1967: train/loss = 0.4749841094017029, train/raw-loss = 0.4005381762981415, train/logprobs = tensor([[-0.8472, -3.2416],
        [-2.0386, -1.7758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488918960094452
Epoch 0, Step 1968: train/loss = 0.4740552008152008, train/raw-loss = 0.41894927620887756, train/logprobs = tensor([[-0.4676, -2.6072],
        [-1.4429, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11021184921264648
Epoch 0, Step 1969: train/loss = 0.5543608665466309, train/raw-loss = 0.472912460565567, train/logprobs = tensor([[-1.5169, -5.8950],
        [-2.7685, -1.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1628967523574829
Epoch 0, Step 1970: train/loss = 0.39248543977737427, train/raw-loss = 0.29106056690216064, train/logprobs = tensor([[-1.6358, -3.4349],
        [-4.3502, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20284977555274963
Epoch 0, Step 1971: train/loss = 0.5686750411987305, train/raw-loss = 0.48041412234306335, train/logprobs = tensor([[-1.0590, -1.8000],
        [-2.0110, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17652182281017303
Epoch 0, Step 1972: train/loss = 0.4451518952846527, train/raw-loss = 0.36122971773147583, train/logprobs = tensor([[-0.7173, -3.8608],
        [-1.5156, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16784441471099854
Epoch 0, Step 1973: train/loss = 0.27942904829978943, train/raw-loss = 0.1832405924797058, train/logprobs = tensor([[-0.8097, -6.3806],
        [-3.4887, -1.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19237694144248962
Epoch 0, Step 1974: train/loss = 0.3892425298690796, train/raw-loss = 0.2878195643424988, train/logprobs = tensor([[-0.4688, -5.9701],
        [-3.2356, -1.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20284590125083923
Epoch 0, Step 1975: train/loss = 0.19753038883209229, train/raw-loss = 0.0937584787607193, train/logprobs = tensor([[-0.5666, -7.0555],
        [-4.1665, -1.3787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20754382014274597
Epoch 0, Step 1976: train/loss = 0.48467814922332764, train/raw-loss = 0.4033612608909607, train/logprobs = tensor([[-1.3901, -2.9812],
        [-2.9876, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626337766647339
Epoch 0, Step 1977: train/loss = 0.6170692443847656, train/raw-loss = 0.566240131855011, train/logprobs = tensor([[-0.4935, -1.0986],
        [-0.6748, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10165814310312271
Epoch 0, Step 1978: train/loss = 0.5647907257080078, train/raw-loss = 0.4976842999458313, train/logprobs = tensor([[-0.3927, -2.2971],
        [-0.8338, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13421277701854706
Epoch 0, Step 1979: train/loss = 0.44445928931236267, train/raw-loss = 0.34275031089782715, train/logprobs = tensor([[-1.0553, -4.1795],
        [-2.6293, -1.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20341791212558746
Epoch 0, Step 1980: train/loss = 0.2686867415904999, train/raw-loss = 0.16081611812114716, train/logprobs = tensor([[-0.8523, -6.5726],
        [-4.0011, -1.1075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21574121713638306
Epoch 0, Step 1981: train/loss = 0.478999525308609, train/raw-loss = 0.3975057005882263, train/logprobs = tensor([[-0.7827, -2.6765],
        [-1.7282, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16298766434192657
Epoch 0, Step 1982: train/loss = 0.46843650937080383, train/raw-loss = 0.4038916230201721, train/logprobs = tensor([[-0.8351, -2.4041],
        [-1.4264, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12908978760242462
Epoch 0, Step 1983: train/loss = 0.42043644189834595, train/raw-loss = 0.34228724241256714, train/logprobs = tensor([[-0.9564, -3.2117],
        [-2.2252, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15629838407039642
Epoch 0, Step 1984: train/loss = 0.3256594240665436, train/raw-loss = 0.22003012895584106, train/logprobs = tensor([[-0.6155, -5.0602],
        [-3.0906, -1.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21125859022140503
Epoch 0, Step 1985: train/loss = 0.6016147136688232, train/raw-loss = 0.5062640905380249, train/logprobs = tensor([[-0.9296, -3.5282],
        [-4.0602, -2.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19070130586624146
Epoch 0, Step 1986: train/loss = 0.4204246401786804, train/raw-loss = 0.32436496019363403, train/logprobs = tensor([[-1.2806, -3.7924],
        [-2.8238, -1.0696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19211943447589874
Epoch 0, Step 1987: train/loss = 0.5120800137519836, train/raw-loss = 0.41255271434783936, train/logprobs = tensor([[-0.8724, -1.9779],
        [-2.4284, -1.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19905461370944977
Epoch 0, Step 1988: train/loss = 0.30355915427207947, train/raw-loss = 0.19450275599956512, train/logprobs = tensor([[-1.5221, -4.7655],
        [-4.8342, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181127816438675
Epoch 0, Step 1989: train/loss = 0.23960310220718384, train/raw-loss = 0.13972562551498413, train/logprobs = tensor([[-1.1676, -6.8534],
        [-2.7297, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19975495338439941
Epoch 0, Step 1990: train/loss = 0.48115670680999756, train/raw-loss = 0.4082666039466858, train/logprobs = tensor([[-0.5405, -2.8926],
        [-2.4414, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1457802802324295
Epoch 0, Step 1991: train/loss = 0.5381413698196411, train/raw-loss = 0.4437708556652069, train/logprobs = tensor([[-1.0363, -3.8089],
        [-1.8596, -1.5465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18874092400074005
Epoch 0, Step 1992: train/loss = 0.23028519749641418, train/raw-loss = 0.10960759967565536, train/logprobs = tensor([[-0.9376, -4.2610],
        [-4.4196, -0.8149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24135521054267883
Epoch 0, Step 1993: train/loss = 0.3241790235042572, train/raw-loss = 0.2204902470111847, train/logprobs = tensor([[-1.5444, -2.5448],
        [-4.9874, -1.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20737753808498383
Epoch 0, Step 1994: train/loss = 0.2123587280511856, train/raw-loss = 0.12670031189918518, train/logprobs = tensor([[-0.9303, -9.2080],
        [-2.9960, -1.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17131681740283966
Epoch 0, Step 1995: train/loss = 0.41401636600494385, train/raw-loss = 0.33024975657463074, train/logprobs = tensor([[-1.0472, -4.0187],
        [-1.7167, -1.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16753320395946503
Epoch 0, Step 1996: train/loss = 0.3701140880584717, train/raw-loss = 0.29607468843460083, train/logprobs = tensor([[-0.6053, -5.4931],
        [-0.9447, -0.8416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480788141489029
Epoch 0, Step 1997: train/loss = 0.44794854521751404, train/raw-loss = 0.3784145414829254, train/logprobs = tensor([[-0.6400, -2.2590],
        [-1.9960, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13906800746917725
Epoch 0, Step 1998: train/loss = 0.46740415692329407, train/raw-loss = 0.38058528304100037, train/logprobs = tensor([[-0.7579, -3.3694],
        [-1.6945, -1.1131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363771796226501
Epoch 0, Step 1999: train/loss = 0.4121030569076538, train/raw-loss = 0.3302108645439148, train/logprobs = tensor([[-0.9368, -3.9064],
        [-1.7200, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16378435492515564
eval/loss: 0.45244717597961426
Epoch 0, Step 2000: train/loss = 0.3876354396343231, train/raw-loss = 0.2710808515548706, train/logprobs = tensor([[-0.7486, -3.2890],
        [-3.7009, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23310917615890503
Epoch 0, Step 2001: train/loss = 0.5407568216323853, train/raw-loss = 0.43337342143058777, train/logprobs = tensor([[-0.7102, -2.8618],
        [-1.9715, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21476680040359497
Epoch 0, Step 2002: train/loss = 0.565312385559082, train/raw-loss = 0.4761095345020294, train/logprobs = tensor([[-0.6754, -3.2121],
        [-1.5216, -1.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1784057319164276
Epoch 0, Step 2003: train/loss = 0.27988019585609436, train/raw-loss = 0.17525765299797058, train/logprobs = tensor([[-1.0002, -4.8267],
        [-3.0367, -1.5488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20924513041973114
Epoch 0, Step 2004: train/loss = 0.21367508172988892, train/raw-loss = 0.13034693896770477, train/logprobs = tensor([[-0.8398, -4.3692],
        [-3.1060, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666562855243683
Epoch 0, Step 2005: train/loss = 0.3259834349155426, train/raw-loss = 0.23760080337524414, train/logprobs = tensor([[-1.1020, -7.0697],
        [-2.6807, -1.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17676524817943573
Epoch 0, Step 2006: train/loss = 0.48765844106674194, train/raw-loss = 0.41986083984375, train/logprobs = tensor([[-0.6106, -3.0925],
        [-2.3110, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1355951875448227
Epoch 0, Step 2007: train/loss = 0.4075436592102051, train/raw-loss = 0.32658928632736206, train/logprobs = tensor([[-1.1635, -4.0930],
        [-3.1708, -2.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190876066684723
Epoch 0, Step 2008: train/loss = 0.7233965396881104, train/raw-loss = 0.6185110211372375, train/logprobs = tensor([[-0.9133, -3.4687],
        [-2.9612, -2.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20977100729942322
Epoch 0, Step 2009: train/loss = 0.3239857852458954, train/raw-loss = 0.23928631842136383, train/logprobs = tensor([[-0.8961, -4.9247],
        [-2.0440, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16939891874790192
Epoch 0, Step 2010: train/loss = 0.39952635765075684, train/raw-loss = 0.3012552261352539, train/logprobs = tensor([[-0.5763, -3.4374],
        [-2.5448, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19654232263565063
Epoch 0, Step 2011: train/loss = 0.2560481131076813, train/raw-loss = 0.14213472604751587, train/logprobs = tensor([[-1.1268, -6.1500],
        [-4.0189, -1.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2278267741203308
Epoch 0, Step 2012: train/loss = 0.5043689012527466, train/raw-loss = 0.42451924085617065, train/logprobs = tensor([[-1.0845, -2.3080],
        [-1.7460, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15969926118850708
Epoch 0, Step 2013: train/loss = 0.4331724941730499, train/raw-loss = 0.36241602897644043, train/logprobs = tensor([[-0.6625, -4.3085],
        [-1.5909, -1.1599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14151300489902496
Epoch 0, Step 2014: train/loss = 0.4368645250797272, train/raw-loss = 0.30304044485092163, train/logprobs = tensor([[-0.8837, -2.5278],
        [-4.2511, -1.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26764822006225586
Epoch 0, Step 2015: train/loss = 0.5314344763755798, train/raw-loss = 0.4526076316833496, train/logprobs = tensor([[-1.3039, -1.7055],
        [-2.2473, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15765376389026642
Epoch 0, Step 2016: train/loss = 0.5159915089607239, train/raw-loss = 0.42438727617263794, train/logprobs = tensor([[-0.8294, -1.5911],
        [-2.3182, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18320852518081665
Epoch 0, Step 2017: train/loss = 0.5433143377304077, train/raw-loss = 0.45640161633491516, train/logprobs = tensor([[-1.3453, -2.2425],
        [-1.9095, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17382554709911346
Epoch 0, Step 2018: train/loss = 0.48340243101119995, train/raw-loss = 0.39030957221984863, train/logprobs = tensor([[-1.8466, -4.8063],
        [-4.8484, -2.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18618573248386383
Epoch 0, Step 2019: train/loss = 0.5605434775352478, train/raw-loss = 0.4913630485534668, train/logprobs = tensor([[-0.9458, -3.4270],
        [-1.1827, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383608877658844
Epoch 0, Step 2020: train/loss = 0.2820371091365814, train/raw-loss = 0.20705759525299072, train/logprobs = tensor([[-0.7880, -4.5764],
        [-2.1800, -1.3647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1499590277671814
Epoch 0, Step 2021: train/loss = 0.46448296308517456, train/raw-loss = 0.3805931806564331, train/logprobs = tensor([[-1.0408, -2.8947],
        [-4.5744, -2.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677795946598053
Epoch 0, Step 2022: train/loss = 0.5112321972846985, train/raw-loss = 0.4507303833961487, train/logprobs = tensor([[-0.4243, -3.5473],
        [-0.8069, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12100362777709961
Epoch 0, Step 2023: train/loss = 0.41165637969970703, train/raw-loss = 0.3124637007713318, train/logprobs = tensor([[-0.7216, -6.0708],
        [-4.0654, -1.7623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19838537275791168
Epoch 0, Step 2024: train/loss = 0.47112223505973816, train/raw-loss = 0.38528770208358765, train/logprobs = tensor([[-1.3357, -2.5855],
        [-3.1327, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17166903614997864
Epoch 0, Step 2025: train/loss = 0.4420678913593292, train/raw-loss = 0.3662375509738922, train/logprobs = tensor([[-0.8359, -3.2841],
        [-1.1456, -0.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1516607105731964
Epoch 0, Step 2026: train/loss = 0.4655931293964386, train/raw-loss = 0.37905752658843994, train/logprobs = tensor([[-0.9634, -3.7707],
        [-3.6190, -1.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17307117581367493
Epoch 0, Step 2027: train/loss = 0.3012513220310211, train/raw-loss = 0.1969991773366928, train/logprobs = tensor([[-0.6698, -6.8852],
        [-4.2653, -1.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2085043042898178
Epoch 0, Step 2028: train/loss = 0.5919240117073059, train/raw-loss = 0.5096672177314758, train/logprobs = tensor([[-0.9685, -3.3273],
        [-2.6070, -1.6300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16451361775398254
Epoch 0, Step 2029: train/loss = 0.5667476654052734, train/raw-loss = 0.5046581029891968, train/logprobs = tensor([[-0.7515, -1.0419],
        [-1.4912, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12417907267808914
Epoch 0, Step 2030: train/loss = 0.25580665469169617, train/raw-loss = 0.15797725319862366, train/logprobs = tensor([[-1.0489, -7.9933],
        [-4.2323, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1956588327884674
Epoch 0, Step 2031: train/loss = 0.2732127904891968, train/raw-loss = 0.15247440338134766, train/logprobs = tensor([[-0.7214, -5.1435],
        [-2.7976, -1.2893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24147680401802063
Epoch 0, Step 2032: train/loss = 0.4541083574295044, train/raw-loss = 0.3829255700111389, train/logprobs = tensor([[-0.6421, -3.3381],
        [-1.0702, -0.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14236554503440857
Epoch 0, Step 2033: train/loss = 0.3734346330165863, train/raw-loss = 0.27934831380844116, train/logprobs = tensor([[-0.8941, -2.3956],
        [-3.3095, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18817263841629028
Epoch 0, Step 2034: train/loss = 0.30064600706100464, train/raw-loss = 0.21559636294841766, train/logprobs = tensor([[-1.1952, -5.5557],
        [-2.2911, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17009931802749634
Epoch 0, Step 2035: train/loss = 0.3772205710411072, train/raw-loss = 0.28852373361587524, train/logprobs = tensor([[-0.7206, -3.3878],
        [-3.1429, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17739373445510864
Epoch 0, Step 2036: train/loss = 0.5667777061462402, train/raw-loss = 0.47359827160835266, train/logprobs = tensor([[-0.6147, -2.3094],
        [-3.0295, -1.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18635888397693634
Epoch 0, Step 2037: train/loss = 0.28034886717796326, train/raw-loss = 0.19515925645828247, train/logprobs = tensor([[-0.7870, -4.4703],
        [-2.4435, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.170379176735878
Epoch 0, Step 2038: train/loss = 0.4577009379863739, train/raw-loss = 0.37080153822898865, train/logprobs = tensor([[-1.0495, -6.5501],
        [-2.4788, -1.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17379873991012573
Epoch 0, Step 2039: train/loss = 0.32896924018859863, train/raw-loss = 0.25010451674461365, train/logprobs = tensor([[-0.5503, -6.8160],
        [-2.2380, -1.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15772944688796997
Epoch 0, Step 2040: train/loss = 0.37443065643310547, train/raw-loss = 0.29893869161605835, train/logprobs = tensor([[-0.9181, -4.2223],
        [-1.4525, -1.2867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098389983177185
Epoch 0, Step 2041: train/loss = 0.5172467231750488, train/raw-loss = 0.44536370038986206, train/logprobs = tensor([[-0.8520, -3.4223],
        [-1.0505, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14376603066921234
Epoch 0, Step 2042: train/loss = 0.3311117887496948, train/raw-loss = 0.27402713894844055, train/logprobs = tensor([[-0.8099, -3.8948],
        [-1.6409, -0.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11416929215192795
Epoch 0, Step 2043: train/loss = 0.36468029022216797, train/raw-loss = 0.28302082419395447, train/logprobs = tensor([[-0.8013, -3.6287],
        [-1.9391, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16331885755062103
Epoch 0, Step 2044: train/loss = 0.5337047576904297, train/raw-loss = 0.45798543095588684, train/logprobs = tensor([[-1.0750, -3.0835],
        [-2.0285, -0.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514386534690857
Epoch 0, Step 2045: train/loss = 0.4421086311340332, train/raw-loss = 0.36340001225471497, train/logprobs = tensor([[-0.7387, -4.4641],
        [-1.6226, -1.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15741729736328125
Epoch 0, Step 2046: train/loss = 0.5210019946098328, train/raw-loss = 0.4379008114337921, train/logprobs = tensor([[-0.8943, -2.8386],
        [-1.3353, -0.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662023961544037
Epoch 0, Step 2047: train/loss = 0.3558993339538574, train/raw-loss = 0.2705332338809967, train/logprobs = tensor([[-0.5474, -3.0709],
        [-2.5474, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17073220014572144
Epoch 0, Step 2048: train/loss = 0.3837510943412781, train/raw-loss = 0.2890982925891876, train/logprobs = tensor([[-1.0701, -4.7238],
        [-3.5915, -2.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1893056482076645
Epoch 0, Step 2049: train/loss = 0.5700339078903198, train/raw-loss = 0.47430750727653503, train/logprobs = tensor([[-0.6492, -4.0336],
        [-3.1495, -1.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1914527714252472
Epoch 0, Step 2050: train/loss = 0.5517787337303162, train/raw-loss = 0.46935421228408813, train/logprobs = tensor([[-0.7031, -1.4366],
        [-1.7475, -0.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16484910249710083
Epoch 0, Step 2051: train/loss = 0.6723984479904175, train/raw-loss = 0.5976336598396301, train/logprobs = tensor([[-1.3914, -4.1982],
        [-1.9641, -3.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14952966570854187
Epoch 0, Step 2052: train/loss = 0.8061882257461548, train/raw-loss = 0.7327350974082947, train/logprobs = tensor([[-1.5851, -3.8097],
        [-1.0119, -1.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14690624177455902
Epoch 0, Step 2053: train/loss = 0.5173697471618652, train/raw-loss = 0.4052985608577728, train/logprobs = tensor([[-1.6443, -4.6900],
        [-2.6635, -1.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.224142387509346
Epoch 0, Step 2054: train/loss = 0.4543054401874542, train/raw-loss = 0.37955987453460693, train/logprobs = tensor([[-0.6873, -2.3851],
        [-1.4994, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949117600917816
Epoch 0, Step 2055: train/loss = 0.4445694386959076, train/raw-loss = 0.3679901957511902, train/logprobs = tensor([[-0.6827, -2.8493],
        [-1.9608, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15315844118595123
Epoch 0, Step 2056: train/loss = 0.5026089549064636, train/raw-loss = 0.4290896952152252, train/logprobs = tensor([[-1.0942, -1.1847],
        [-2.7748, -0.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.147038534283638
Epoch 0, Step 2057: train/loss = 0.37068721652030945, train/raw-loss = 0.27592864632606506, train/logprobs = tensor([[-1.4890, -5.1158],
        [-4.4161, -2.6248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18951717019081116
Epoch 0, Step 2058: train/loss = 0.382373183965683, train/raw-loss = 0.2843022346496582, train/logprobs = tensor([[-1.1922, -8.2513],
        [-3.6500, -1.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19614188373088837
Epoch 0, Step 2059: train/loss = 0.8232029676437378, train/raw-loss = 0.7462318539619446, train/logprobs = tensor([[-1.2988, -1.8757],
        [-2.9916, -2.5519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15394210815429688
Epoch 0, Step 2060: train/loss = 0.6934841871261597, train/raw-loss = 0.6392227411270142, train/logprobs = tensor([[-0.6309, -0.6545],
        [-1.2417, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10852295905351639
Epoch 0, Step 2061: train/loss = 0.2939522862434387, train/raw-loss = 0.2003423571586609, train/logprobs = tensor([[-0.8457, -4.1570],
        [-4.0237, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18721991777420044
Epoch 0, Step 2062: train/loss = 0.5091896653175354, train/raw-loss = 0.42225193977355957, train/logprobs = tensor([[-0.8563, -2.7340],
        [-2.6927, -1.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17387548089027405
Epoch 0, Step 2063: train/loss = 0.6417357921600342, train/raw-loss = 0.5400864481925964, train/logprobs = tensor([[-1.7712, -1.9118],
        [-3.6892, -1.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2032986283302307
Epoch 0, Step 2064: train/loss = 0.26388290524482727, train/raw-loss = 0.18359903991222382, train/logprobs = tensor([[-1.1219, -5.4374],
        [-3.8460, -1.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1605677306652069
Epoch 0, Step 2065: train/loss = 0.5710302591323853, train/raw-loss = 0.49305206537246704, train/logprobs = tensor([[-0.6121, -1.7841],
        [-1.4319, -1.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15595640242099762
Epoch 0, Step 2066: train/loss = 0.3514782786369324, train/raw-loss = 0.26470625400543213, train/logprobs = tensor([[-0.8204, -5.1418],
        [-2.7524, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1735440492630005
Epoch 0, Step 2067: train/loss = 0.6272199153900146, train/raw-loss = 0.5595832467079163, train/logprobs = tensor([[-1.0134, -2.1766],
        [-1.4492, -1.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13527335226535797
Epoch 0, Step 2068: train/loss = 0.395911306142807, train/raw-loss = 0.2710615396499634, train/logprobs = tensor([[-0.6746, -1.5902],
        [-4.7264, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24969957768917084
Epoch 0, Step 2069: train/loss = 0.49285051226615906, train/raw-loss = 0.4279100298881531, train/logprobs = tensor([[-0.6626, -3.4108],
        [-1.1618, -0.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12988102436065674
Epoch 0, Step 2070: train/loss = 0.4239140450954437, train/raw-loss = 0.32094407081604004, train/logprobs = tensor([[-0.9832, -5.8683],
        [-4.1134, -2.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2059398591518402
Epoch 0, Step 2071: train/loss = 0.4794226288795471, train/raw-loss = 0.41821223497390747, train/logprobs = tensor([[-0.7911, -4.4347],
        [-1.5423, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12242083996534348
Epoch 0, Step 2072: train/loss = 0.7350585460662842, train/raw-loss = 0.6346290707588196, train/logprobs = tensor([[-1.1302, -5.4537],
        [-2.7220, -2.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2008589655160904
Epoch 0, Step 2073: train/loss = 0.31345003843307495, train/raw-loss = 0.2263334095478058, train/logprobs = tensor([[-0.6644, -3.6924],
        [-1.6029, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17423324286937714
Epoch 0, Step 2074: train/loss = 0.45593905448913574, train/raw-loss = 0.37775593996047974, train/logprobs = tensor([[-1.0018, -2.5517],
        [-1.6265, -0.9301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15636630356311798
Epoch 0, Step 2075: train/loss = 0.33059197664260864, train/raw-loss = 0.2567051649093628, train/logprobs = tensor([[-0.5884, -3.7871],
        [-2.7087, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14777368307113647
Epoch 0, Step 2076: train/loss = 0.8685688376426697, train/raw-loss = 0.7520649433135986, train/logprobs = tensor([[-0.7456, -2.5077],
        [-4.8373, -2.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23300784826278687
Epoch 0, Step 2077: train/loss = 0.626004695892334, train/raw-loss = 0.5511474609375, train/logprobs = tensor([[-0.9471, -1.7103],
        [-2.0516, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14971446990966797
Epoch 0, Step 2078: train/loss = 0.5737013220787048, train/raw-loss = 0.47439002990722656, train/logprobs = tensor([[-0.8458, -2.7107],
        [-2.1993, -1.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19862262904644012
Epoch 0, Step 2079: train/loss = 0.5454657077789307, train/raw-loss = 0.48746609687805176, train/logprobs = tensor([[-0.8758, -2.0052],
        [-1.2330, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11599922925233841
Epoch 0, Step 2080: train/loss = 0.25332731008529663, train/raw-loss = 0.16955599188804626, train/logprobs = tensor([[-0.4394, -8.3078],
        [-1.3022, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16754263639450073
Epoch 0, Step 2081: train/loss = 0.4602535665035248, train/raw-loss = 0.35741347074508667, train/logprobs = tensor([[-1.5149, -4.3651],
        [-2.2531, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056802213191986
Epoch 0, Step 2082: train/loss = 0.6644437313079834, train/raw-loss = 0.5592103600502014, train/logprobs = tensor([[-0.6770, -3.3714],
        [-1.7543, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21046677231788635
Epoch 0, Step 2083: train/loss = 0.8252864480018616, train/raw-loss = 0.7433450818061829, train/logprobs = tensor([[-0.9365, -3.2587],
        [-1.5158, -2.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16388270258903503
Epoch 0, Step 2084: train/loss = 0.5683754682540894, train/raw-loss = 0.47687703371047974, train/logprobs = tensor([[-1.8404, -3.5890],
        [-1.4788, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182996928691864
Epoch 0, Step 2085: train/loss = 0.5975319147109985, train/raw-loss = 0.522183895111084, train/logprobs = tensor([[-1.5988, -2.6676],
        [-1.8033, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15069593489170074
Epoch 0, Step 2086: train/loss = 0.3423279821872711, train/raw-loss = 0.25331833958625793, train/logprobs = tensor([[-0.6145, -3.8255],
        [-2.8157, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17801931500434875
Epoch 0, Step 2087: train/loss = 0.5100403428077698, train/raw-loss = 0.4247603416442871, train/logprobs = tensor([[-0.8283, -2.6810],
        [-1.6555, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17055994272232056
Epoch 0, Step 2088: train/loss = 0.4167325496673584, train/raw-loss = 0.33639732003211975, train/logprobs = tensor([[-0.8078, -2.5218],
        [-2.2288, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1606704443693161
Epoch 0, Step 2089: train/loss = 0.5168773531913757, train/raw-loss = 0.40548786520957947, train/logprobs = tensor([[-0.9746, -2.0269],
        [-3.4716, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22277896106243134
Epoch 0, Step 2090: train/loss = 0.5496357679367065, train/raw-loss = 0.44478562474250793, train/logprobs = tensor([[-1.8402, -3.2452],
        [-2.5408, -0.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20970036089420319
Epoch 0, Step 2091: train/loss = 0.425483375787735, train/raw-loss = 0.3085421323776245, train/logprobs = tensor([[-1.5921, -5.8174],
        [-6.7145, -2.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23388250172138214
Epoch 0, Step 2092: train/loss = 0.5933340191841125, train/raw-loss = 0.5141372084617615, train/logprobs = tensor([[-0.6904, -1.2379],
        [-1.5764, -1.0245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15839356184005737
Epoch 0, Step 2093: train/loss = 0.5257641077041626, train/raw-loss = 0.4465392529964447, train/logprobs = tensor([[-1.0002, -2.0831],
        [-2.2595, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15844976902008057
Epoch 0, Step 2094: train/loss = 0.2735411524772644, train/raw-loss = 0.17625483870506287, train/logprobs = tensor([[-0.9561, -5.3290],
        [-2.9468, -0.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19457264244556427
Epoch 0, Step 2095: train/loss = 0.5119601488113403, train/raw-loss = 0.42990726232528687, train/logprobs = tensor([[-1.0165, -2.8790],
        [-2.3304, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16410572826862335
Epoch 0, Step 2096: train/loss = 0.6965525150299072, train/raw-loss = 0.5925534963607788, train/logprobs = tensor([[-1.8276, -2.9268],
        [-2.5209, -1.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079980969429016
Epoch 0, Step 2097: train/loss = 0.6484273672103882, train/raw-loss = 0.5642292499542236, train/logprobs = tensor([[-1.6555, -5.4385],
        [-1.1332, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16839613020420074
Epoch 0, Step 2098: train/loss = 0.49599313735961914, train/raw-loss = 0.4083101749420166, train/logprobs = tensor([[-0.7776, -2.2961],
        [-1.1364, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1753658950328827
Epoch 0, Step 2099: train/loss = 0.5409078001976013, train/raw-loss = 0.472343385219574, train/logprobs = tensor([[-0.8290, -1.9988],
        [-2.8166, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13712885975837708
Epoch 0, Step 2100: train/loss = 0.32992178201675415, train/raw-loss = 0.24496108293533325, train/logprobs = tensor([[-1.4188, -3.0326],
        [-3.9113, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1699213683605194
Epoch 0, Step 2101: train/loss = 0.3807601034641266, train/raw-loss = 0.28360387682914734, train/logprobs = tensor([[-0.8272, -3.0601],
        [-2.2634, -1.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943124532699585
Epoch 0, Step 2102: train/loss = 0.538731038570404, train/raw-loss = 0.4592821002006531, train/logprobs = tensor([[-1.6127, -2.1421],
        [-2.0118, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15889784693717957
Epoch 0, Step 2103: train/loss = 0.39223426580429077, train/raw-loss = 0.29819345474243164, train/logprobs = tensor([[-0.7294, -4.2031],
        [-2.1126, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18808162212371826
Epoch 0, Step 2104: train/loss = 0.45027658343315125, train/raw-loss = 0.3617159128189087, train/logprobs = tensor([[-0.6918, -4.5055],
        [-1.6068, -1.6956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1771213859319687
Epoch 0, Step 2105: train/loss = 0.18791510164737701, train/raw-loss = 0.0630631297826767, train/logprobs = tensor([[-1.0250, -6.6468],
        [-5.0792, -1.7684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24970395863056183
Epoch 0, Step 2106: train/loss = 0.2338046431541443, train/raw-loss = 0.12368708103895187, train/logprobs = tensor([[-1.1213, -5.5082],
        [-4.3329, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22023510932922363
Epoch 0, Step 2107: train/loss = 0.47091907262802124, train/raw-loss = 0.3715408444404602, train/logprobs = tensor([[-0.7725, -2.8250],
        [-4.0440, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19875650107860565
Epoch 0, Step 2108: train/loss = 0.3376803398132324, train/raw-loss = 0.26601287722587585, train/logprobs = tensor([[-0.5982, -3.9849],
        [-1.8947, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14333488047122955
Epoch 0, Step 2109: train/loss = 0.24908354878425598, train/raw-loss = 0.15000370144844055, train/logprobs = tensor([[-1.0888, -6.5689],
        [-3.7307, -1.5251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19815973937511444
Epoch 0, Step 2110: train/loss = 0.27775686979293823, train/raw-loss = 0.18082623183727264, train/logprobs = tensor([[-0.7335, -5.0804],
        [-2.3450, -0.9082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19386127591133118
Epoch 0, Step 2111: train/loss = 0.6233975887298584, train/raw-loss = 0.5534936785697937, train/logprobs = tensor([[-0.6440, -1.4758],
        [-1.5120, -1.5045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13980786502361298
Epoch 0, Step 2112: train/loss = 0.34337472915649414, train/raw-loss = 0.26294293999671936, train/logprobs = tensor([[-0.6222, -7.5805],
        [-2.9015, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16086357831954956
Epoch 0, Step 2113: train/loss = 0.3880229592323303, train/raw-loss = 0.2825773358345032, train/logprobs = tensor([[-0.9592, -3.4371],
        [-3.5206, -1.4664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2108912467956543
Epoch 0, Step 2114: train/loss = 0.4389183521270752, train/raw-loss = 0.3555777966976166, train/logprobs = tensor([[-0.4260, -3.0911],
        [-1.6010, -1.4128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16668111085891724
Epoch 0, Step 2115: train/loss = 0.4130164384841919, train/raw-loss = 0.3240278959274292, train/logprobs = tensor([[-0.7095, -2.7722],
        [-1.6562, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17797711491584778
Epoch 0, Step 2116: train/loss = 0.5058061480522156, train/raw-loss = 0.3973059058189392, train/logprobs = tensor([[-1.9748, -4.6666],
        [-3.4176, -1.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21700045466423035
Epoch 0, Step 2117: train/loss = 0.3457487225532532, train/raw-loss = 0.2507278025150299, train/logprobs = tensor([[-0.8592, -5.3702],
        [-3.5696, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19004184007644653
Epoch 0, Step 2118: train/loss = 0.27534955739974976, train/raw-loss = 0.19091184437274933, train/logprobs = tensor([[-0.6808, -5.7031],
        [-2.0527, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16887539625167847
Epoch 0, Step 2119: train/loss = 0.45074981451034546, train/raw-loss = 0.3806733787059784, train/logprobs = tensor([[-0.9952, -2.3695],
        [-2.8852, -1.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14015290141105652
Epoch 0, Step 2120: train/loss = 0.41235819458961487, train/raw-loss = 0.3268187642097473, train/logprobs = tensor([[-0.8941, -3.0809],
        [-2.4202, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710788607597351
Epoch 0, Step 2121: train/loss = 0.3843483328819275, train/raw-loss = 0.2985277771949768, train/logprobs = tensor([[-1.3876, -2.1392],
        [-3.9152, -1.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17164111137390137
Epoch 0, Step 2122: train/loss = 0.3415522873401642, train/raw-loss = 0.23432928323745728, train/logprobs = tensor([[-0.5861, -2.1894],
        [-4.5370, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21444600820541382
Epoch 0, Step 2123: train/loss = 0.5505092144012451, train/raw-loss = 0.4646405279636383, train/logprobs = tensor([[-0.9776, -2.6851],
        [-1.7916, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17173738777637482
Epoch 0, Step 2124: train/loss = 0.2210729569196701, train/raw-loss = 0.10660036653280258, train/logprobs = tensor([[-0.7603, -8.1487],
        [-3.6482, -1.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22894516587257385
Epoch 0, Step 2125: train/loss = 0.5828705430030823, train/raw-loss = 0.4928765296936035, train/logprobs = tensor([[-0.6469, -2.3361],
        [-2.8418, -1.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799880564212799
Epoch 0, Step 2126: train/loss = 0.4981292188167572, train/raw-loss = 0.4135574996471405, train/logprobs = tensor([[-0.5808, -2.3227],
        [-1.7507, -1.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1691434383392334
Epoch 0, Step 2127: train/loss = 0.312773197889328, train/raw-loss = 0.2306165099143982, train/logprobs = tensor([[-2.0040, -2.6912],
        [-4.3882, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16431337594985962
Epoch 0, Step 2128: train/loss = 0.23675711452960968, train/raw-loss = 0.14656800031661987, train/logprobs = tensor([[-0.6990, -4.2852],
        [-2.8701, -1.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18037822842597961
Epoch 0, Step 2129: train/loss = 0.5170050859451294, train/raw-loss = 0.46713054180145264, train/logprobs = tensor([[-1.1202, -1.6455],
        [-2.3062, -0.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0997491106390953
Epoch 0, Step 2130: train/loss = 0.7676262855529785, train/raw-loss = 0.6804876327514648, train/logprobs = tensor([[-0.6909, -2.1874],
        [-3.0466, -2.7407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1742774248123169
Epoch 0, Step 2131: train/loss = 0.39611580967903137, train/raw-loss = 0.3251356780529022, train/logprobs = tensor([[-1.1006, -1.8588],
        [-3.8212, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14196021854877472
Epoch 0, Step 2132: train/loss = 0.46415963768959045, train/raw-loss = 0.379733145236969, train/logprobs = tensor([[-0.9259, -2.9639],
        [-1.7323, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16885292530059814
Epoch 0, Step 2133: train/loss = 0.3936115801334381, train/raw-loss = 0.3002978563308716, train/logprobs = tensor([[-0.4270, -3.0292],
        [-2.2550, -0.7491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18662752211093903
Epoch 0, Step 2134: train/loss = 0.5025768876075745, train/raw-loss = 0.41760656237602234, train/logprobs = tensor([[-1.1220, -3.4863],
        [-2.8165, -1.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16994071006774902
Epoch 0, Step 2135: train/loss = 0.3858839273452759, train/raw-loss = 0.308566689491272, train/logprobs = tensor([[-1.8826, -4.2685],
        [-3.5225, -2.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546345204114914
Epoch 0, Step 2136: train/loss = 0.4863998293876648, train/raw-loss = 0.4200291335582733, train/logprobs = tensor([[-0.7886, -3.6925],
        [-1.2916, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13274140655994415
Epoch 0, Step 2137: train/loss = 0.2740997076034546, train/raw-loss = 0.1653871089220047, train/logprobs = tensor([[-1.0556, -6.0835],
        [-2.7012, -1.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2174251526594162
Epoch 0, Step 2138: train/loss = 0.5136696100234985, train/raw-loss = 0.41365134716033936, train/logprobs = tensor([[-0.6954, -3.2522],
        [-1.5025, -1.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000364363193512
Epoch 0, Step 2139: train/loss = 0.3678897023200989, train/raw-loss = 0.28377804160118103, train/logprobs = tensor([[-0.7580, -2.2054],
        [-3.0518, -0.5125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1682233363389969
Epoch 0, Step 2140: train/loss = 0.19371797144412994, train/raw-loss = 0.06540632247924805, train/logprobs = tensor([[-1.1045, -5.7983],
        [-5.7145, -1.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2566233277320862
Epoch 0, Step 2141: train/loss = 0.7720900774002075, train/raw-loss = 0.6749736666679382, train/logprobs = tensor([[-0.8841, -2.4981],
        [-3.0885, -2.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19423264265060425
Epoch 0, Step 2142: train/loss = 0.5393809080123901, train/raw-loss = 0.4342309534549713, train/logprobs = tensor([[-1.1696, -2.4490],
        [-2.3903, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21029987931251526
Epoch 0, Step 2143: train/loss = 0.3551722764968872, train/raw-loss = 0.2534697353839874, train/logprobs = tensor([[-0.9487, -3.5274],
        [-4.6736, -1.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20340506732463837
Epoch 0, Step 2144: train/loss = 0.5130788683891296, train/raw-loss = 0.41103845834732056, train/logprobs = tensor([[-2.2887, -6.5040],
        [-1.7794, -1.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20408087968826294
Epoch 0, Step 2145: train/loss = 0.41091421246528625, train/raw-loss = 0.2982352077960968, train/logprobs = tensor([[-1.0175, -4.5404],
        [-3.2181, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22535796463489532
Epoch 0, Step 2146: train/loss = 0.37101519107818604, train/raw-loss = 0.2827475070953369, train/logprobs = tensor([[-1.4346, -6.1815],
        [-2.6396, -2.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17653536796569824
Epoch 0, Step 2147: train/loss = 0.6492481827735901, train/raw-loss = 0.5636789798736572, train/logprobs = tensor([[-0.6834, -0.8054],
        [-1.6685, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1711384505033493
Epoch 0, Step 2148: train/loss = 0.5700159072875977, train/raw-loss = 0.45693641901016235, train/logprobs = tensor([[-1.2982, -3.8880],
        [-2.5726, -2.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22615909576416016
Epoch 0, Step 2149: train/loss = 0.5104868412017822, train/raw-loss = 0.44005632400512695, train/logprobs = tensor([[-0.8423, -1.7841],
        [-1.5730, -1.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14086100459098816
Epoch 0, Step 2150: train/loss = 0.4541231095790863, train/raw-loss = 0.37670454382896423, train/logprobs = tensor([[-0.7289, -3.1681],
        [-2.4257, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15483716130256653
Epoch 0, Step 2151: train/loss = 0.7586357593536377, train/raw-loss = 0.658908486366272, train/logprobs = tensor([[-1.6962, -2.2381],
        [-3.4889, -2.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19945454597473145
Epoch 0, Step 2152: train/loss = 0.3564428687095642, train/raw-loss = 0.26522988080978394, train/logprobs = tensor([[-1.1421, -5.9438],
        [-2.8962, -2.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18242597579956055
Epoch 0, Step 2153: train/loss = 0.37648189067840576, train/raw-loss = 0.3030693829059601, train/logprobs = tensor([[-1.2111, -4.4918],
        [-1.5595, -1.3333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14682507514953613
Epoch 0, Step 2154: train/loss = 0.2837526798248291, train/raw-loss = 0.18693405389785767, train/logprobs = tensor([[-1.2571, -5.0971],
        [-3.6272, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1936372071504593
Epoch 0, Step 2155: train/loss = 0.3541184365749359, train/raw-loss = 0.26264411211013794, train/logprobs = tensor([[-0.6880, -3.8121],
        [-3.0276, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18294866383075714
Epoch 0, Step 2156: train/loss = 0.21068060398101807, train/raw-loss = 0.09033630788326263, train/logprobs = tensor([[-0.6083, -5.6201],
        [-3.6508, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24068857729434967
Epoch 0, Step 2157: train/loss = 0.4574667811393738, train/raw-loss = 0.3791746497154236, train/logprobs = tensor([[-1.1129, -3.3857],
        [-1.8001, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15658430755138397
Epoch 0, Step 2158: train/loss = 0.3865925073623657, train/raw-loss = 0.3180917799472809, train/logprobs = tensor([[-1.2505, -5.5935],
        [-1.8668, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370013952255249
Epoch 0, Step 2159: train/loss = 0.45467594265937805, train/raw-loss = 0.37188029289245605, train/logprobs = tensor([[-1.0782, -4.5559],
        [-1.8507, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.165591299533844
Epoch 0, Step 2160: train/loss = 0.4451609253883362, train/raw-loss = 0.3706132769584656, train/logprobs = tensor([[-0.8989, -2.5543],
        [-1.3500, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1490953266620636
Epoch 0, Step 2161: train/loss = 0.49777156114578247, train/raw-loss = 0.42795875668525696, train/logprobs = tensor([[-0.8031, -2.2189],
        [-1.7388, -1.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13962559401988983
Epoch 0, Step 2162: train/loss = 0.40715932846069336, train/raw-loss = 0.3087557554244995, train/logprobs = tensor([[-0.5774, -2.8532],
        [-1.3074, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19680717587471008
Epoch 0, Step 2163: train/loss = 0.4824586808681488, train/raw-loss = 0.4171634316444397, train/logprobs = tensor([[-0.7135, -2.2153],
        [-1.3885, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13059048354625702
Epoch 0, Step 2164: train/loss = 0.2817575931549072, train/raw-loss = 0.18660585582256317, train/logprobs = tensor([[-1.1141, -4.1955],
        [-3.8972, -1.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1903034895658493
Epoch 0, Step 2165: train/loss = 0.5012698173522949, train/raw-loss = 0.4083719849586487, train/logprobs = tensor([[-1.3252, -1.9674],
        [-2.9277, -1.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18579576909542084
Epoch 0, Step 2166: train/loss = 0.4302787780761719, train/raw-loss = 0.3395872712135315, train/logprobs = tensor([[-0.4833, -3.7148],
        [-2.2970, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1813829392194748
Epoch 0, Step 2167: train/loss = 0.5686076283454895, train/raw-loss = 0.4903455972671509, train/logprobs = tensor([[-0.5307, -3.5389],
        [-1.3511, -1.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15652406215667725
Epoch 0, Step 2168: train/loss = 0.44025862216949463, train/raw-loss = 0.3478125333786011, train/logprobs = tensor([[-0.8929, -4.2078],
        [-2.2168, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18489216268062592
Epoch 0, Step 2169: train/loss = 0.559660792350769, train/raw-loss = 0.49222707748413086, train/logprobs = tensor([[-1.4635, -2.4410],
        [-1.6194, -1.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13486742973327637
Epoch 0, Step 2170: train/loss = 0.23412103950977325, train/raw-loss = 0.118511863052845, train/logprobs = tensor([[-1.1261, -6.0569],
        [-3.0153, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312183529138565
Epoch 0, Step 2171: train/loss = 0.390276163816452, train/raw-loss = 0.2967274487018585, train/logprobs = tensor([[-0.5034, -3.8518],
        [-1.9875, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870974898338318
Epoch 0, Step 2172: train/loss = 0.4658781588077545, train/raw-loss = 0.3897893726825714, train/logprobs = tensor([[-1.1156, -3.0164],
        [-1.5587, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15217764675617218
Epoch 0, Step 2173: train/loss = 0.5151593685150146, train/raw-loss = 0.4355323910713196, train/logprobs = tensor([[-0.5242, -1.7810],
        [-1.5550, -1.0687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15925389528274536
Epoch 0, Step 2174: train/loss = 0.4317982494831085, train/raw-loss = 0.3653636574745178, train/logprobs = tensor([[-0.7801, -2.4670],
        [-2.7483, -0.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132869154214859
Epoch 0, Step 2175: train/loss = 0.3572547733783722, train/raw-loss = 0.27344852685928345, train/logprobs = tensor([[-0.9136, -5.0981],
        [-1.8830, -1.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1676124930381775
Epoch 0, Step 2176: train/loss = 0.3978273868560791, train/raw-loss = 0.2801629304885864, train/logprobs = tensor([[-1.0223, -4.2522],
        [-2.8327, -1.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23532894253730774
Epoch 0, Step 2177: train/loss = 0.3972986936569214, train/raw-loss = 0.3029528260231018, train/logprobs = tensor([[-0.9879, -2.5992],
        [-4.1203, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18869170546531677
Epoch 0, Step 2178: train/loss = 0.5577389597892761, train/raw-loss = 0.4952456057071686, train/logprobs = tensor([[-0.5304, -3.5984],
        [-1.2030, -1.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12498671561479568
Epoch 0, Step 2179: train/loss = 0.4497113823890686, train/raw-loss = 0.37904059886932373, train/logprobs = tensor([[-0.6996, -3.6934],
        [-1.1203, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14134153723716736
Epoch 0, Step 2180: train/loss = 0.29479172825813293, train/raw-loss = 0.18126201629638672, train/logprobs = tensor([[-0.9828, -4.7888],
        [-3.4466, -2.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22705936431884766
Epoch 0, Step 2181: train/loss = 0.21090996265411377, train/raw-loss = 0.10078330338001251, train/logprobs = tensor([[-1.2321, -6.6077],
        [-4.4958, -1.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22025331854820251
Epoch 0, Step 2182: train/loss = 0.43512874841690063, train/raw-loss = 0.3507373332977295, train/logprobs = tensor([[-0.6595, -4.5525],
        [-1.6201, -1.2444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1687827855348587
Epoch 0, Step 2183: train/loss = 0.3785763382911682, train/raw-loss = 0.2976868152618408, train/logprobs = tensor([[-0.6913, -3.7775],
        [-3.1941, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16177897155284882
Epoch 0, Step 2184: train/loss = 0.4050072729587555, train/raw-loss = 0.305793821811676, train/logprobs = tensor([[-0.9818, -3.2855],
        [-2.9581, -1.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19842690229415894
Epoch 0, Step 2185: train/loss = 0.40766698122024536, train/raw-loss = 0.3104841113090515, train/logprobs = tensor([[-0.6404, -3.2686],
        [-2.1835, -0.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943657547235489
Epoch 0, Step 2186: train/loss = 0.504031240940094, train/raw-loss = 0.43366438150405884, train/logprobs = tensor([[-0.7744, -4.0282],
        [-1.2211, -1.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1407337337732315
Epoch 0, Step 2187: train/loss = 0.2976139783859253, train/raw-loss = 0.2122178077697754, train/logprobs = tensor([[-0.8286, -3.4224],
        [-2.1643, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1707923412322998
Epoch 0, Step 2188: train/loss = 0.2810046076774597, train/raw-loss = 0.1714951992034912, train/logprobs = tensor([[-0.6048, -3.7379],
        [-3.7694, -0.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.219018816947937
Epoch 0, Step 2189: train/loss = 0.45157837867736816, train/raw-loss = 0.38672617077827454, train/logprobs = tensor([[-0.5862, -2.8587],
        [-2.2917, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12970450520515442
Epoch 0, Step 2190: train/loss = 0.598511815071106, train/raw-loss = 0.4950547218322754, train/logprobs = tensor([[-0.9167, -1.3021],
        [-3.8190, -1.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20691421627998352
Epoch 0, Step 2191: train/loss = 0.22356396913528442, train/raw-loss = 0.1330024003982544, train/logprobs = tensor([[-1.3023, -6.1528],
        [-3.5104, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18112310767173767
Epoch 0, Step 2192: train/loss = 1.0987231731414795, train/raw-loss = 1.0279836654663086, train/logprobs = tensor([[-1.0117, -1.7448],
        [-1.8949, -2.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14147886633872986
Epoch 0, Step 2193: train/loss = 0.5215048789978027, train/raw-loss = 0.4598150849342346, train/logprobs = tensor([[-0.9471, -3.1415],
        [-1.5539, -1.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12337962538003922
Epoch 0, Step 2194: train/loss = 0.48254191875457764, train/raw-loss = 0.38332778215408325, train/logprobs = tensor([[-0.7172, -1.5091],
        [-2.2777, -0.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1984281986951828
Epoch 0, Step 2195: train/loss = 0.33477938175201416, train/raw-loss = 0.24677687883377075, train/logprobs = tensor([[-0.7214, -5.3863],
        [-2.2966, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17600491642951965
Epoch 0, Step 2196: train/loss = 0.20485559105873108, train/raw-loss = 0.09738602489233017, train/logprobs = tensor([[-1.5021, -8.3225],
        [-4.5166, -1.5876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21493913233280182
Epoch 0, Step 2197: train/loss = 0.6687891483306885, train/raw-loss = 0.5911018252372742, train/logprobs = tensor([[-1.0871, -1.4173],
        [-2.3835, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1553746461868286
Epoch 0, Step 2198: train/loss = 0.6874836683273315, train/raw-loss = 0.5812675952911377, train/logprobs = tensor([[-1.8984, -4.6989],
        [-1.0963, -0.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21243222057819366
Epoch 0, Step 2199: train/loss = 0.36522403359413147, train/raw-loss = 0.2690492272377014, train/logprobs = tensor([[-0.5728, -3.8769],
        [-2.3013, -0.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19234967231750488
Epoch 0, Step 2200: train/loss = 0.4636382758617401, train/raw-loss = 0.38895875215530396, train/logprobs = tensor([[-1.2116, -2.4172],
        [-2.3244, -0.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14935901761054993
Epoch 0, Step 2201: train/loss = 0.41711875796318054, train/raw-loss = 0.31802913546562195, train/logprobs = tensor([[-1.2329, -5.3693],
        [-1.4779, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.198179230093956
Epoch 0, Step 2202: train/loss = 0.5195854902267456, train/raw-loss = 0.4451850652694702, train/logprobs = tensor([[-0.7173, -3.3406],
        [-1.2483, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14880086481571198
Epoch 0, Step 2203: train/loss = 0.4059871435165405, train/raw-loss = 0.3190520107746124, train/logprobs = tensor([[-1.0256, -4.3729],
        [-1.2263, -0.6549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1738702803850174
Epoch 0, Step 2204: train/loss = 0.4571467638015747, train/raw-loss = 0.3543115556240082, train/logprobs = tensor([[-1.0752, -2.6257],
        [-4.2031, -1.4990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056703418493271
Epoch 0, Step 2205: train/loss = 0.4928358495235443, train/raw-loss = 0.4065261483192444, train/logprobs = tensor([[-0.7444, -1.8996],
        [-2.7516, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17261940240859985
Epoch 0, Step 2206: train/loss = 0.4799339175224304, train/raw-loss = 0.41363316774368286, train/logprobs = tensor([[-0.8252, -4.0377],
        [-1.2639, -0.6340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326015740633011
Epoch 0, Step 2207: train/loss = 0.292047381401062, train/raw-loss = 0.2144727110862732, train/logprobs = tensor([[-1.4038, -5.1843],
        [-2.8501, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15514931082725525
Epoch 0, Step 2208: train/loss = 0.4106976389884949, train/raw-loss = 0.3175806999206543, train/logprobs = tensor([[-0.9582, -3.2595],
        [-1.9008, -0.9101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18623381853103638
Epoch 0, Step 2209: train/loss = 0.4473034143447876, train/raw-loss = 0.35626864433288574, train/logprobs = tensor([[-0.6446, -3.6901],
        [-2.7462, -1.2243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18206949532032013
Epoch 0, Step 2210: train/loss = 0.7179202437400818, train/raw-loss = 0.6727819442749023, train/logprobs = tensor([[-1.1131, -1.2759],
        [-0.8075, -0.7055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09027660638093948
Epoch 0, Step 2211: train/loss = 1.2302213907241821, train/raw-loss = 1.138780951499939, train/logprobs = tensor([[-1.9182, -2.7163],
        [-4.9327, -4.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18288089334964752
Epoch 0, Step 2212: train/loss = 0.502728283405304, train/raw-loss = 0.43118444085121155, train/logprobs = tensor([[-0.7675, -1.6606],
        [-1.4834, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430877447128296
Epoch 0, Step 2213: train/loss = 0.47049036622047424, train/raw-loss = 0.3878231942653656, train/logprobs = tensor([[-0.4618, -2.3178],
        [-1.0596, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1653343290090561
Epoch 0, Step 2214: train/loss = 0.44115495681762695, train/raw-loss = 0.36834195256233215, train/logprobs = tensor([[-0.8276, -2.0944],
        [-1.7805, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1456260085105896
Epoch 0, Step 2215: train/loss = 0.29516053199768066, train/raw-loss = 0.18892256915569305, train/logprobs = tensor([[-0.8661, -4.1972],
        [-3.5832, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21247589588165283
Epoch 0, Step 2216: train/loss = 0.3804205358028412, train/raw-loss = 0.3006893992424011, train/logprobs = tensor([[-0.6025, -2.5135],
        [-2.6161, -0.7454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15946224331855774
Epoch 0, Step 2217: train/loss = 0.5151858329772949, train/raw-loss = 0.4221295118331909, train/logprobs = tensor([[-2.4738, -3.9560],
        [-3.3117, -2.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18611262738704681
Epoch 0, Step 2218: train/loss = 0.517264723777771, train/raw-loss = 0.4398096203804016, train/logprobs = tensor([[-0.6263, -1.6046],
        [-2.6805, -0.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1549101024866104
Epoch 0, Step 2219: train/loss = 0.33361631631851196, train/raw-loss = 0.2314939796924591, train/logprobs = tensor([[-0.4869, -4.2590],
        [-2.4252, -0.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20424464344978333
Epoch 0, Step 2220: train/loss = 0.2770358622074127, train/raw-loss = 0.19114679098129272, train/logprobs = tensor([[-0.7917, -5.7822],
        [-1.6328, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17177817225456238
Epoch 0, Step 2221: train/loss = 0.5948265194892883, train/raw-loss = 0.5165562629699707, train/logprobs = tensor([[-2.4118, -4.5732],
        [-3.2684, -1.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1565403938293457
Epoch 0, Step 2222: train/loss = 0.4018305540084839, train/raw-loss = 0.3045938014984131, train/logprobs = tensor([[-0.5035, -4.4950],
        [-1.3892, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.194473534822464
Epoch 0, Step 2223: train/loss = 0.387411892414093, train/raw-loss = 0.2659558951854706, train/logprobs = tensor([[-1.5106, -3.3296],
        [-4.4751, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24291199445724487
Epoch 0, Step 2224: train/loss = 0.6043078303337097, train/raw-loss = 0.5216227769851685, train/logprobs = tensor([[-0.7415, -1.5123],
        [-1.5641, -1.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16537007689476013
Epoch 0, Step 2225: train/loss = 0.4991931617259979, train/raw-loss = 0.40932130813598633, train/logprobs = tensor([[-0.6307, -2.7977],
        [-3.0470, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179743692278862
Epoch 0, Step 2226: train/loss = 0.6736680865287781, train/raw-loss = 0.600628137588501, train/logprobs = tensor([[-0.7655, -0.7588],
        [-1.1209, -0.7046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14607980847358704
Epoch 0, Step 2227: train/loss = 0.32963716983795166, train/raw-loss = 0.22946017980575562, train/logprobs = tensor([[-0.7933, -5.2767],
        [-2.8479, -1.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2003539502620697
Epoch 0, Step 2228: train/loss = 0.3741896152496338, train/raw-loss = 0.28705430030822754, train/logprobs = tensor([[-0.9072, -3.0742],
        [-4.1143, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1742706447839737
Epoch 0, Step 2229: train/loss = 0.3408444821834564, train/raw-loss = 0.252485454082489, train/logprobs = tensor([[-0.6145, -3.5068],
        [-3.4790, -0.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17671804130077362
Epoch 0, Step 2230: train/loss = 0.3736586570739746, train/raw-loss = 0.2820139527320862, train/logprobs = tensor([[-0.8680, -5.0723],
        [-3.4545, -1.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18328943848609924
Epoch 0, Step 2231: train/loss = 0.4614720344543457, train/raw-loss = 0.3921840190887451, train/logprobs = tensor([[-0.7911, -2.8733],
        [-1.6144, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385759711265564
Epoch 0, Step 2232: train/loss = 0.36592578887939453, train/raw-loss = 0.24872231483459473, train/logprobs = tensor([[-0.6939, -4.3578],
        [-2.5788, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23440691828727722
Epoch 0, Step 2233: train/loss = 0.519634485244751, train/raw-loss = 0.46088990569114685, train/logprobs = tensor([[-0.6106, -1.2192],
        [-1.4590, -0.6183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11748906970024109
Epoch 0, Step 2234: train/loss = 0.5538537502288818, train/raw-loss = 0.44419097900390625, train/logprobs = tensor([[-1.3859, -2.9462],
        [-5.6356, -2.3661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21932555735111237
Epoch 0, Step 2235: train/loss = 0.5293813943862915, train/raw-loss = 0.4546470642089844, train/logprobs = tensor([[-1.0680, -2.9951],
        [-1.1586, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1494687795639038
Epoch 0, Step 2236: train/loss = 0.4996276795864105, train/raw-loss = 0.42258137464523315, train/logprobs = tensor([[-0.6826, -2.8050],
        [-1.9443, -1.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15409265458583832
Epoch 0, Step 2237: train/loss = 0.3314032256603241, train/raw-loss = 0.2533012628555298, train/logprobs = tensor([[-1.6889, -3.5244],
        [-2.8803, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1562039852142334
Epoch 0, Step 2238: train/loss = 0.8737978339195251, train/raw-loss = 0.7687082290649414, train/logprobs = tensor([[-1.6625, -3.4130],
        [-2.6972, -2.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2101791352033615
Epoch 0, Step 2239: train/loss = 0.6713451743125916, train/raw-loss = 0.6038192510604858, train/logprobs = tensor([[-1.0189, -1.0792],
        [-1.5213, -1.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350518763065338
Epoch 0, Step 2240: train/loss = 0.8012019395828247, train/raw-loss = 0.7347556352615356, train/logprobs = tensor([[-0.8298, -3.7156],
        [-1.6302, -2.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13289254903793335
Epoch 0, Step 2241: train/loss = 0.4549923241138458, train/raw-loss = 0.37066394090652466, train/logprobs = tensor([[-0.8754, -3.4059],
        [-2.2367, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16865681111812592
Epoch 0, Step 2242: train/loss = 0.3799339234828949, train/raw-loss = 0.30361407995224, train/logprobs = tensor([[-0.5810, -5.4726],
        [-1.4442, -1.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15263965725898743
Epoch 0, Step 2243: train/loss = 0.37558597326278687, train/raw-loss = 0.2858506441116333, train/logprobs = tensor([[-0.7230, -4.7744],
        [-1.7311, -1.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17947062849998474
Epoch 0, Step 2244: train/loss = 0.33806467056274414, train/raw-loss = 0.2377718687057495, train/logprobs = tensor([[-0.7893, -3.2726],
        [-4.7644, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20058558881282806
Epoch 0, Step 2245: train/loss = 0.3486568033695221, train/raw-loss = 0.2758362591266632, train/logprobs = tensor([[-0.9005, -4.2427],
        [-1.4515, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14564110338687897
Epoch 0, Step 2246: train/loss = 0.6809148788452148, train/raw-loss = 0.5752766728401184, train/logprobs = tensor([[-0.7405, -2.5802],
        [-2.1867, -2.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21127644181251526
Epoch 0, Step 2247: train/loss = 0.4420021176338196, train/raw-loss = 0.3672170639038086, train/logprobs = tensor([[-0.6761, -4.7752],
        [-0.8749, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14957009255886078
Epoch 0, Step 2248: train/loss = 0.3948836326599121, train/raw-loss = 0.3287074863910675, train/logprobs = tensor([[-1.1218, -3.1481],
        [-3.0855, -1.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323522925376892
Epoch 0, Step 2249: train/loss = 0.7463266253471375, train/raw-loss = 0.6568270325660706, train/logprobs = tensor([[-0.7648, -3.0648],
        [-2.8833, -2.2680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17899927496910095
Epoch 0, Step 2250: train/loss = 0.38114437460899353, train/raw-loss = 0.2951534390449524, train/logprobs = tensor([[-0.6336, -4.2941],
        [-2.1644, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17198185622692108
Epoch 0, Step 2251: train/loss = 0.3036161959171295, train/raw-loss = 0.21842946112155914, train/logprobs = tensor([[-0.8169, -6.6509],
        [-3.5045, -1.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17037346959114075
Epoch 0, Step 2252: train/loss = 0.23200365900993347, train/raw-loss = 0.12634555995464325, train/logprobs = tensor([[-0.6747, -3.3017],
        [-4.5236, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21131618320941925
Epoch 0, Step 2253: train/loss = 0.5773287415504456, train/raw-loss = 0.5111807584762573, train/logprobs = tensor([[-1.6177, -2.5510],
        [-1.5296, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13229599595069885
Epoch 0, Step 2254: train/loss = 0.28020089864730835, train/raw-loss = 0.15440542995929718, train/logprobs = tensor([[-1.5726, -4.3428],
        [-3.7792, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25159087777137756
Epoch 0, Step 2255: train/loss = 0.3461849093437195, train/raw-loss = 0.2646670341491699, train/logprobs = tensor([[-0.7170, -4.8799],
        [-2.4683, -1.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630357950925827
Epoch 0, Step 2256: train/loss = 0.22987104952335358, train/raw-loss = 0.11487697809934616, train/logprobs = tensor([[-0.9081, -8.1425],
        [-4.3405, -1.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22998817265033722
Epoch 0, Step 2257: train/loss = 0.27983757853507996, train/raw-loss = 0.19909141957759857, train/logprobs = tensor([[-0.6833, -5.7176],
        [-3.5697, -2.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16149233281612396
Epoch 0, Step 2258: train/loss = 0.20203042030334473, train/raw-loss = 0.08789284527301788, train/logprobs = tensor([[-1.2948, -6.5449],
        [-3.9077, -1.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2282751500606537
Epoch 0, Step 2259: train/loss = 0.26941606402397156, train/raw-loss = 0.1668192595243454, train/logprobs = tensor([[-0.6131, -3.2700],
        [-3.5941, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20519359409809113
Epoch 0, Step 2260: train/loss = 1.1402301788330078, train/raw-loss = 1.0572301149368286, train/logprobs = tensor([[-0.6902, -3.2688],
        [-2.7103, -3.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16600032150745392
Epoch 0, Step 2261: train/loss = 0.4862821698188782, train/raw-loss = 0.41257017850875854, train/logprobs = tensor([[-0.8210, -2.8230],
        [-1.8417, -1.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14742398262023926
Epoch 0, Step 2262: train/loss = 0.3299658000469208, train/raw-loss = 0.22950053215026855, train/logprobs = tensor([[-0.7750, -3.0583],
        [-2.5737, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20093059539794922
Epoch 0, Step 2263: train/loss = 0.5440977811813354, train/raw-loss = 0.4693995416164398, train/logprobs = tensor([[-1.5521, -3.6643],
        [-2.4586, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14939647912979126
Epoch 0, Step 2264: train/loss = 0.359815776348114, train/raw-loss = 0.27563369274139404, train/logprobs = tensor([[-0.9369, -4.4925],
        [-1.7572, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16836416721343994
Epoch 0, Step 2265: train/loss = 0.5345708727836609, train/raw-loss = 0.45851197838783264, train/logprobs = tensor([[-1.4335, -4.3803],
        [-1.6069, -1.5040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15211781859397888
Epoch 0, Step 2266: train/loss = 0.3631843626499176, train/raw-loss = 0.2782133221626282, train/logprobs = tensor([[-1.2147, -5.5710],
        [-1.6249, -1.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16994214057922363
Epoch 0, Step 2267: train/loss = 0.3784015476703644, train/raw-loss = 0.2986010015010834, train/logprobs = tensor([[-0.8381, -2.7917],
        [-2.1215, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15960106253623962
Epoch 0, Step 2268: train/loss = 0.5212606191635132, train/raw-loss = 0.42013806104660034, train/logprobs = tensor([[-1.0812, -3.8588],
        [-1.9503, -1.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20224514603614807
Epoch 0, Step 2269: train/loss = 0.3904057443141937, train/raw-loss = 0.30247241258621216, train/logprobs = tensor([[-0.7312, -5.8335],
        [-2.0340, -1.0267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17586661875247955
Epoch 0, Step 2270: train/loss = 0.4541582763195038, train/raw-loss = 0.3703959882259369, train/logprobs = tensor([[-0.8286, -2.6614],
        [-2.4408, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16752459108829498
Epoch 0, Step 2271: train/loss = 0.5359525084495544, train/raw-loss = 0.4344269037246704, train/logprobs = tensor([[-1.0959, -2.8707],
        [-1.8568, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20305123925209045
Epoch 0, Step 2272: train/loss = 0.2920534610748291, train/raw-loss = 0.21832647919654846, train/logprobs = tensor([[-1.0826, -2.9159],
        [-3.1741, -1.3776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14745399355888367
Epoch 0, Step 2273: train/loss = 0.3317492604255676, train/raw-loss = 0.23899689316749573, train/logprobs = tensor([[-0.9833, -6.5928],
        [-3.6296, -1.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18550479412078857
Epoch 0, Step 2274: train/loss = 0.6786032915115356, train/raw-loss = 0.6150481104850769, train/logprobs = tensor([[-0.4754, -0.6581],
        [-0.9043, -0.7118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12711036205291748
Epoch 0, Step 2275: train/loss = 0.3209269940853119, train/raw-loss = 0.21769383549690247, train/logprobs = tensor([[-0.8293, -7.7704],
        [-2.0486, -1.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20646627247333527
Epoch 0, Step 2276: train/loss = 0.3735192120075226, train/raw-loss = 0.2888212203979492, train/logprobs = tensor([[-1.1554, -3.1998],
        [-2.2769, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16939595341682434
Epoch 0, Step 2277: train/loss = 0.35472172498703003, train/raw-loss = 0.27744531631469727, train/logprobs = tensor([[-0.8089, -7.5208],
        [-2.1004, -1.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15455278754234314
Epoch 0, Step 2278: train/loss = 0.23602722585201263, train/raw-loss = 0.11446627974510193, train/logprobs = tensor([[-0.7723, -4.7933],
        [-3.6544, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431219071149826
Epoch 0, Step 2279: train/loss = 0.499272882938385, train/raw-loss = 0.39347872138023376, train/logprobs = tensor([[-1.0075, -4.2913],
        [-2.1517, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2115883231163025
Epoch 0, Step 2280: train/loss = 0.8312039375305176, train/raw-loss = 0.7683796882629395, train/logprobs = tensor([[-1.5597, -1.5552],
        [-0.8061, -0.7385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12564845383167267
Epoch 0, Step 2281: train/loss = 0.6516152024269104, train/raw-loss = 0.5768675804138184, train/logprobs = tensor([[-1.0951, -1.1531],
        [-2.5116, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14949534833431244
Epoch 0, Step 2282: train/loss = 0.47411027550697327, train/raw-loss = 0.4029853045940399, train/logprobs = tensor([[-0.9546, -3.6440],
        [-2.0324, -0.7642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422499418258667
Epoch 0, Step 2283: train/loss = 0.5119533538818359, train/raw-loss = 0.4511956572532654, train/logprobs = tensor([[-0.6805, -2.6823],
        [-0.7652, -0.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12151530385017395
Epoch 0, Step 2284: train/loss = 0.5026070475578308, train/raw-loss = 0.405254065990448, train/logprobs = tensor([[-1.0206, -2.9317],
        [-1.7151, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19470597803592682
Epoch 0, Step 2285: train/loss = 0.5037218332290649, train/raw-loss = 0.44007837772369385, train/logprobs = tensor([[-0.6377, -3.4819],
        [-0.8549, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272868663072586
Epoch 0, Step 2286: train/loss = 0.47278544306755066, train/raw-loss = 0.3968169093132019, train/logprobs = tensor([[-0.9838, -5.0226],
        [-1.4493, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1519370675086975
Epoch 0, Step 2287: train/loss = 0.3827078342437744, train/raw-loss = 0.31030210852622986, train/logprobs = tensor([[-0.6771, -1.7278],
        [-1.7981, -0.4070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14481152594089508
Epoch 0, Step 2288: train/loss = 0.22030480206012726, train/raw-loss = 0.08647332340478897, train/logprobs = tensor([[-1.1987, -6.5391],
        [-5.1839, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26766297221183777
Epoch 0, Step 2289: train/loss = 0.5559606552124023, train/raw-loss = 0.49008235335350037, train/logprobs = tensor([[-1.4265, -4.2764],
        [-1.7637, -1.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13175667822360992
Epoch 0, Step 2290: train/loss = 0.5823395252227783, train/raw-loss = 0.47934216260910034, train/logprobs = tensor([[-2.4016, -7.2977],
        [-2.4896, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20599469542503357
Epoch 0, Step 2291: train/loss = 0.47392570972442627, train/raw-loss = 0.3796430230140686, train/logprobs = tensor([[-0.6827, -2.3618],
        [-2.7030, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885654181241989
Epoch 0, Step 2292: train/loss = 0.3611500859260559, train/raw-loss = 0.28320538997650146, train/logprobs = tensor([[-0.7069, -3.4853],
        [-1.6175, -0.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15588942170143127
Epoch 0, Step 2293: train/loss = 0.43388792872428894, train/raw-loss = 0.333940327167511, train/logprobs = tensor([[-1.2101, -2.7981],
        [-3.0760, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1998952329158783
Epoch 0, Step 2294: train/loss = 0.32077324390411377, train/raw-loss = 0.2269880771636963, train/logprobs = tensor([[-0.6561, -3.9227],
        [-2.5095, -1.0185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18757031857967377
Epoch 0, Step 2295: train/loss = 0.26449307799339294, train/raw-loss = 0.18529249727725983, train/logprobs = tensor([[-0.4123, -9.3327],
        [-1.0679, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15840113162994385
Epoch 0, Step 2296: train/loss = 0.4688645005226135, train/raw-loss = 0.4058873653411865, train/logprobs = tensor([[-1.2694, -3.5759],
        [-2.1249, -2.1825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12595424056053162
Epoch 0, Step 2297: train/loss = 0.5251769423484802, train/raw-loss = 0.44502711296081543, train/logprobs = tensor([[-0.7930, -3.9095],
        [-1.0955, -1.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16029974818229675
Epoch 0, Step 2298: train/loss = 0.45019397139549255, train/raw-loss = 0.4006020426750183, train/logprobs = tensor([[-0.6987, -2.1516],
        [-0.9920, -0.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09918386489152908
Epoch 0, Step 2299: train/loss = 0.38185545802116394, train/raw-loss = 0.2822301685810089, train/logprobs = tensor([[-1.4662, -4.0070],
        [-2.5839, -0.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19925059378147125
Epoch 0, Step 2300: train/loss = 0.5280617475509644, train/raw-loss = 0.4473578631877899, train/logprobs = tensor([[-0.7936, -4.1863],
        [-1.4333, -1.4831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16140784323215485
Epoch 0, Step 2301: train/loss = 0.49007129669189453, train/raw-loss = 0.4234444797039032, train/logprobs = tensor([[-0.6359, -4.6005],
        [-1.4036, -1.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13325369358062744
Epoch 0, Step 2302: train/loss = 0.3712236285209656, train/raw-loss = 0.2967662215232849, train/logprobs = tensor([[-0.9925, -3.2130],
        [-2.1127, -0.8782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14891475439071655
Epoch 0, Step 2303: train/loss = 0.7370743155479431, train/raw-loss = 0.6489253640174866, train/logprobs = tensor([[-2.3486, -3.6098],
        [-2.5105, -1.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17629778385162354
Epoch 0, Step 2304: train/loss = 0.3495613932609558, train/raw-loss = 0.23620609939098358, train/logprobs = tensor([[-0.5543, -3.9568],
        [-3.4622, -1.1265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22671055793762207
Epoch 0, Step 2305: train/loss = 0.5614632368087769, train/raw-loss = 0.45969563722610474, train/logprobs = tensor([[-0.9676, -5.8642],
        [-3.0735, -2.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20353516936302185
Epoch 0, Step 2306: train/loss = 0.5239948630332947, train/raw-loss = 0.4341734051704407, train/logprobs = tensor([[-1.1005, -5.6570],
        [-4.4572, -3.5253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.179642915725708
Epoch 0, Step 2307: train/loss = 0.5152055025100708, train/raw-loss = 0.445320188999176, train/logprobs = tensor([[-0.8742, -2.0884],
        [-2.5804, -1.5761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13977061212062836
Epoch 0, Step 2308: train/loss = 0.9092192649841309, train/raw-loss = 0.8251827359199524, train/logprobs = tensor([[-1.4517, -1.4090],
        [-3.6038, -2.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1680731624364853
Epoch 0, Step 2309: train/loss = 0.31352731585502625, train/raw-loss = 0.23403532803058624, train/logprobs = tensor([[-0.7175, -7.6799],
        [-2.4182, -1.6071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1589839905500412
Epoch 0, Step 2310: train/loss = 0.4690745174884796, train/raw-loss = 0.37917155027389526, train/logprobs = tensor([[-0.6577, -4.7369],
        [-1.1878, -1.5271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1798059046268463
Epoch 0, Step 2311: train/loss = 0.24991101026535034, train/raw-loss = 0.1687754988670349, train/logprobs = tensor([[-0.5958, -7.5442],
        [-1.4369, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16227099299430847
Epoch 0, Step 2312: train/loss = 0.4347546100616455, train/raw-loss = 0.3535137176513672, train/logprobs = tensor([[-1.2057, -4.5716],
        [-2.4466, -2.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16248179972171783
Epoch 0, Step 2313: train/loss = 0.7509701251983643, train/raw-loss = 0.6602635383605957, train/logprobs = tensor([[-0.8643, -1.1108],
        [-1.8772, -1.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18141326308250427
Epoch 0, Step 2314: train/loss = 0.6646813750267029, train/raw-loss = 0.6033034324645996, train/logprobs = tensor([[-0.4888, -0.7548],
        [-0.9326, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12275590002536774
Epoch 0, Step 2315: train/loss = 0.503326952457428, train/raw-loss = 0.42625927925109863, train/logprobs = tensor([[-0.6736, -4.2800],
        [-1.8497, -2.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541353464126587
Epoch 0, Step 2316: train/loss = 0.5700226426124573, train/raw-loss = 0.4874022305011749, train/logprobs = tensor([[-1.9948, -2.4638],
        [-2.0936, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1652408242225647
Epoch 0, Step 2317: train/loss = 0.4663829803466797, train/raw-loss = 0.3744727373123169, train/logprobs = tensor([[-1.4653, -4.3268],
        [-2.7698, -1.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18382036685943604
Epoch 0, Step 2318: train/loss = 0.2915676236152649, train/raw-loss = 0.1856255978345871, train/logprobs = tensor([[-0.9147, -5.9248],
        [-2.2077, -0.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21188406646251678
Epoch 0, Step 2319: train/loss = 0.36666053533554077, train/raw-loss = 0.30229452252388, train/logprobs = tensor([[-1.0649, -4.5447],
        [-1.5505, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12873198091983795
Epoch 0, Step 2320: train/loss = 0.20852330327033997, train/raw-loss = 0.09581940621137619, train/logprobs = tensor([[-0.9652, -5.4016],
        [-3.2389, -0.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22540777921676636
Epoch 0, Step 2321: train/loss = 0.4995216131210327, train/raw-loss = 0.4469762146472931, train/logprobs = tensor([[-1.0918, -6.2449],
        [-2.6686, -3.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10509078204631805
Epoch 0, Step 2322: train/loss = 0.3135092854499817, train/raw-loss = 0.23286691308021545, train/logprobs = tensor([[-0.7075, -5.9300],
        [-1.4679, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16128474473953247
Epoch 0, Step 2323: train/loss = 0.5624772906303406, train/raw-loss = 0.4746943712234497, train/logprobs = tensor([[-1.0578, -1.8518],
        [-2.3204, -1.1584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17556582391262054
Epoch 0, Step 2324: train/loss = 0.6049776673316956, train/raw-loss = 0.5455431342124939, train/logprobs = tensor([[-0.9854, -1.3601],
        [-2.0723, -1.1327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11886900663375854
Epoch 0, Step 2325: train/loss = 0.22934746742248535, train/raw-loss = 0.15620821714401245, train/logprobs = tensor([[-0.8016, -4.0283],
        [-3.9147, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.146278515458107
Epoch 0, Step 2326: train/loss = 0.23786956071853638, train/raw-loss = 0.13979065418243408, train/logprobs = tensor([[-1.0331, -5.5701],
        [-3.4691, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19615782797336578
Epoch 0, Step 2327: train/loss = 0.5041280388832092, train/raw-loss = 0.4084521532058716, train/logprobs = tensor([[-0.8075, -1.9797],
        [-2.4580, -0.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19135183095932007
Epoch 0, Step 2328: train/loss = 0.23441937565803528, train/raw-loss = 0.16282135248184204, train/logprobs = tensor([[-0.7707, -5.0675],
        [-3.3139, -0.8747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14319606125354767
Epoch 0, Step 2329: train/loss = 0.5151722431182861, train/raw-loss = 0.45210549235343933, train/logprobs = tensor([[-0.5524, -2.6314],
        [-1.3054, -1.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12613354623317719
Epoch 0, Step 2330: train/loss = 0.3962869346141815, train/raw-loss = 0.30843585729599, train/logprobs = tensor([[-0.7663, -4.0467],
        [-2.0768, -1.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17570219933986664
Epoch 0, Step 2331: train/loss = 0.48486074805259705, train/raw-loss = 0.3979290723800659, train/logprobs = tensor([[-1.2140, -4.3962],
        [-1.3534, -0.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17386339604854584
Epoch 0, Step 2332: train/loss = 0.5702608823776245, train/raw-loss = 0.5093721747398376, train/logprobs = tensor([[-0.3953, -2.1191],
        [-1.0224, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12177753448486328
Epoch 0, Step 2333: train/loss = 0.2797088623046875, train/raw-loss = 0.21059267222881317, train/logprobs = tensor([[-0.5087, -5.7078],
        [-1.0169, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1382323056459427
Epoch 0, Step 2334: train/loss = 0.5032758712768555, train/raw-loss = 0.43742480874061584, train/logprobs = tensor([[-1.3721, -2.1385],
        [-2.1491, -0.8874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13170212507247925
Epoch 0, Step 2335: train/loss = 0.28951960802078247, train/raw-loss = 0.20195947587490082, train/logprobs = tensor([[-1.5775, -5.1041],
        [-4.0024, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1751202791929245
Epoch 0, Step 2336: train/loss = 0.4311841130256653, train/raw-loss = 0.33316442370414734, train/logprobs = tensor([[-0.6542, -3.9437],
        [-2.0302, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1960393637418747
Epoch 0, Step 2337: train/loss = 0.5361412763595581, train/raw-loss = 0.48397117853164673, train/logprobs = tensor([[-0.6028, -2.8488],
        [-0.8593, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434018820524216
Epoch 0, Step 2338: train/loss = 0.7487781643867493, train/raw-loss = 0.6802135109901428, train/logprobs = tensor([[-1.3457, -3.2050],
        [-1.7875, -2.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13712933659553528
Epoch 0, Step 2339: train/loss = 0.22007444500923157, train/raw-loss = 0.10939564555883408, train/logprobs = tensor([[-0.7589, -5.8505],
        [-3.7076, -1.5478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213575839996338
Epoch 0, Step 2340: train/loss = 0.7819639444351196, train/raw-loss = 0.7022327780723572, train/logprobs = tensor([[-0.8136, -3.0944],
        [-2.3363, -2.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1594623625278473
Epoch 0, Step 2341: train/loss = 0.44265758991241455, train/raw-loss = 0.371366411447525, train/logprobs = tensor([[-0.4853, -3.5262],
        [-2.0095, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14258237183094025
Epoch 0, Step 2342: train/loss = 0.27299779653549194, train/raw-loss = 0.18448325991630554, train/logprobs = tensor([[-0.7714, -2.1427],
        [-3.4629, -0.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1770290583372116
Epoch 0, Step 2343: train/loss = 0.4178604483604431, train/raw-loss = 0.334667444229126, train/logprobs = tensor([[-1.2193, -6.5986],
        [-1.8072, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1663859784603119
Epoch 0, Step 2344: train/loss = 0.4443017840385437, train/raw-loss = 0.3348311185836792, train/logprobs = tensor([[-1.2212, -2.3518],
        [-2.9326, -1.4526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2189413607120514
Epoch 0, Step 2345: train/loss = 0.5096390247344971, train/raw-loss = 0.4311603307723999, train/logprobs = tensor([[-0.7753, -1.7810],
        [-1.6662, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15695734322071075
Epoch 0, Step 2346: train/loss = 0.561858057975769, train/raw-loss = 0.5004616975784302, train/logprobs = tensor([[-1.4730, -2.5617],
        [-2.1981, -2.2560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12279266864061356
Epoch 0, Step 2347: train/loss = 0.5578490495681763, train/raw-loss = 0.47453197836875916, train/logprobs = tensor([[-1.8451, -3.9256],
        [-1.6600, -1.2013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16663411259651184
Epoch 0, Step 2348: train/loss = 0.3567619323730469, train/raw-loss = 0.2579353451728821, train/logprobs = tensor([[-1.1245, -2.2067],
        [-3.8834, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19765321910381317
Epoch 0, Step 2349: train/loss = 0.3227232098579407, train/raw-loss = 0.23364727199077606, train/logprobs = tensor([[-1.0531, -5.4183],
        [-3.0874, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17815189063549042
Epoch 0, Step 2350: train/loss = 0.3676369786262512, train/raw-loss = 0.2576129734516144, train/logprobs = tensor([[-0.6196, -2.5389],
        [-3.1239, -1.1941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200479954481125
Epoch 0, Step 2351: train/loss = 0.49421489238739014, train/raw-loss = 0.43738672137260437, train/logprobs = tensor([[-0.4440, -2.7889],
        [-0.9515, -0.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11365630477666855
Epoch 0, Step 2352: train/loss = 0.22549784183502197, train/raw-loss = 0.1195024847984314, train/logprobs = tensor([[-0.7359, -7.0986],
        [-2.9427, -1.1320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21199069917201996
Epoch 0, Step 2353: train/loss = 0.25021225214004517, train/raw-loss = 0.18117624521255493, train/logprobs = tensor([[-1.0268, -5.9286],
        [-2.0811, -1.5155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13807202875614166
Epoch 0, Step 2354: train/loss = 0.5210326313972473, train/raw-loss = 0.41799116134643555, train/logprobs = tensor([[-1.0885, -5.5945],
        [-1.5714, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20608291029930115
Epoch 0, Step 2355: train/loss = 0.6431292295455933, train/raw-loss = 0.5640513300895691, train/logprobs = tensor([[-0.6369, -2.7457],
        [-2.9654, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15815582871437073
Epoch 0, Step 2356: train/loss = 0.4576930105686188, train/raw-loss = 0.36954089999198914, train/logprobs = tensor([[-0.8029, -3.0104],
        [-2.2506, -2.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17630420625209808
Epoch 0, Step 2357: train/loss = 0.5572465658187866, train/raw-loss = 0.45249423384666443, train/logprobs = tensor([[-1.3560, -2.7421],
        [-2.7390, -1.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.209504634141922
Epoch 0, Step 2358: train/loss = 0.4453941583633423, train/raw-loss = 0.37874794006347656, train/logprobs = tensor([[-0.4894, -4.3746],
        [-0.9380, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13329243659973145
Epoch 0, Step 2359: train/loss = 0.3681396543979645, train/raw-loss = 0.27284225821495056, train/logprobs = tensor([[-0.4290, -5.6497],
        [-3.5446, -1.4961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19059482216835022
Epoch 0, Step 2360: train/loss = 0.3372109532356262, train/raw-loss = 0.2466128170490265, train/logprobs = tensor([[-0.7466, -4.3101],
        [-2.9815, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18119630217552185
Epoch 0, Step 2361: train/loss = 0.36365020275115967, train/raw-loss = 0.283879816532135, train/logprobs = tensor([[-0.5916, -5.3825],
        [-2.1192, -1.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15954077243804932
Epoch 0, Step 2362: train/loss = 0.4305903911590576, train/raw-loss = 0.34285593032836914, train/logprobs = tensor([[-0.9275, -6.8545],
        [-2.0482, -1.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17546892166137695
Epoch 0, Step 2363: train/loss = 0.21847966313362122, train/raw-loss = 0.12409794330596924, train/logprobs = tensor([[-0.8518, -4.3332],
        [-3.9670, -1.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18876346945762634
Epoch 0, Step 2364: train/loss = 0.3589226007461548, train/raw-loss = 0.2554950714111328, train/logprobs = tensor([[-0.8335, -4.0781],
        [-2.7133, -0.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20685510337352753
Epoch 0, Step 2365: train/loss = 0.29981404542922974, train/raw-loss = 0.1868271380662918, train/logprobs = tensor([[-1.6492, -7.2603],
        [-2.3731, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22597387433052063
Epoch 0, Step 2366: train/loss = 0.41389986872673035, train/raw-loss = 0.333469033241272, train/logprobs = tensor([[-0.8619, -3.7214],
        [-1.9968, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16086170077323914
Epoch 0, Step 2367: train/loss = 0.5737506747245789, train/raw-loss = 0.472609281539917, train/logprobs = tensor([[-1.8087, -4.7774],
        [-3.2506, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2022828459739685
Epoch 0, Step 2368: train/loss = 0.3515312373638153, train/raw-loss = 0.23815858364105225, train/logprobs = tensor([[-0.9323, -5.2287],
        [-3.0006, -1.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22674532234668732
Epoch 0, Step 2369: train/loss = 0.4248444736003876, train/raw-loss = 0.32080021500587463, train/logprobs = tensor([[-0.8990, -4.1298],
        [-2.6489, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2080884575843811
Epoch 0, Step 2370: train/loss = 0.3667314946651459, train/raw-loss = 0.2816486656665802, train/logprobs = tensor([[-1.5375, -4.0928],
        [-2.2175, -1.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17016568779945374
Epoch 0, Step 2371: train/loss = 0.35930874943733215, train/raw-loss = 0.2780727446079254, train/logprobs = tensor([[-0.8468, -4.7773],
        [-3.0892, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16247200965881348
Epoch 0, Step 2372: train/loss = 0.44053471088409424, train/raw-loss = 0.36691752076148987, train/logprobs = tensor([[-0.5171, -1.9034],
        [-2.3482, -0.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14723441004753113
Epoch 0, Step 2373: train/loss = 0.47852352261543274, train/raw-loss = 0.40953120589256287, train/logprobs = tensor([[-1.5649, -5.2125],
        [-2.0066, -2.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13798463344573975
Epoch 0, Step 2374: train/loss = 0.44254153966903687, train/raw-loss = 0.3813076317310333, train/logprobs = tensor([[-1.5512, -3.9303],
        [-2.0149, -0.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12246778607368469
eval/loss: 0.44447633624076843
