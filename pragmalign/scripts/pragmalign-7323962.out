[2024-03-03 14:55:41,527][root][INFO] - beta: 1.0
[2024-03-03 14:55:41,527][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-1.0-iteration-1-0-5k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 8884
n harmless: 9970
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ"}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-1.0-iteration-1-0-5k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-1.0-iteration-1-0-5k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-1.0-iteration-1-0-5k after each epoch.
5000
5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-1.0-iteration-1-0-5k after each epoch.
Loss is nan
eval/loss: 0.6716450452804565
Epoch 0, Step 0: train/loss = 0.6876811981201172, train/raw-loss = 0.6876811981201172, train/logprobs = tensor([[-0.7991, -2.1136],
        [-0.8144, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7017812728881836, train/raw-loss = 0.7017812728881836, train/logprobs = tensor([[-0.8675, -1.3647],
        [-0.9045, -1.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6647472381591797, train/raw-loss = 0.6647472381591797, train/logprobs = tensor([[-0.9712, -1.6776],
        [-1.0482, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6691160798072815, train/raw-loss = 0.6691160798072815, train/logprobs = tensor([[-0.7613, -1.0412],
        [-0.8040, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6818459033966064, train/raw-loss = 0.6818459033966064, train/logprobs = tensor([[-0.7423, -0.8494],
        [-0.8033, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7001824378967285, train/raw-loss = 0.7001824378967285, train/logprobs = tensor([[-0.8634, -1.2522],
        [-0.8944, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6646842360496521, train/raw-loss = 0.6646842360496521, train/logprobs = tensor([[-1.0534, -1.4514],
        [-1.1196, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.692057192325592, train/raw-loss = 0.692057192325592, train/logprobs = tensor([[-1.0745, -1.3111],
        [-1.1357, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6729065179824829, train/raw-loss = 0.6729065179824829, train/logprobs = tensor([[-0.5144, -1.1528],
        [-0.5067, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6754744052886963, train/raw-loss = 0.6754744052886963, train/logprobs = tensor([[-1.0090, -1.1000],
        [-1.0342, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6382375955581665, train/raw-loss = 0.6382375955581665, train/logprobs = tensor([[-1.0358, -1.3086],
        [-1.3042, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6904394626617432, train/raw-loss = 0.6904394626617432, train/logprobs = tensor([[-0.7226, -1.2303],
        [-0.7300, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6897714734077454, train/raw-loss = 0.6897714734077454, train/logprobs = tensor([[-0.9022, -1.2302],
        [-0.9290, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6802294254302979, train/raw-loss = 0.6802294254302979, train/logprobs = tensor([[-0.6706, -1.2400],
        [-0.6935, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6690350770950317, train/raw-loss = 0.6690350770950317, train/logprobs = tensor([[-1.1638, -1.2059],
        [-1.2771, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6677312850952148, train/raw-loss = 0.6677312850952148, train/logprobs = tensor([[-1.2674, -1.3661],
        [-1.3281, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6589983701705933, train/raw-loss = 0.6589983701705933, train/logprobs = tensor([[-0.8304, -1.3320],
        [-0.8951, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6930590867996216, train/raw-loss = 0.6930590867996216, train/logprobs = tensor([[-0.7644, -1.0668],
        [-0.7867, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6523447036743164, train/raw-loss = 0.6523447036743164, train/logprobs = tensor([[-0.9116, -1.1920],
        [-1.0786, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6793126463890076, train/raw-loss = 0.6793126463890076, train/logprobs = tensor([[-0.8504, -1.1314],
        [-0.8680, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6822050213813782, train/raw-loss = 0.6822050213813782, train/logprobs = tensor([[-0.8326, -1.3713],
        [-0.9170, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6489429473876953, train/raw-loss = 0.6489429473876953, train/logprobs = tensor([[-1.3826, -1.5213],
        [-1.5211, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6750220060348511, train/raw-loss = 0.6750220060348511, train/logprobs = tensor([[-0.8851, -0.7172],
        [-0.9591, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6739029288291931, train/raw-loss = 0.6739029288291931, train/logprobs = tensor([[-0.7526, -1.6962],
        [-0.8254, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721904873847961, train/raw-loss = 0.6721904873847961, train/logprobs = tensor([[-0.8545, -1.1816],
        [-0.8767, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6630262732505798, train/raw-loss = 0.6630262732505798, train/logprobs = tensor([[-1.1663, -1.0103],
        [-1.2706, -0.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6829202175140381, train/raw-loss = 0.6829202175140381, train/logprobs = tensor([[-1.0265, -1.0503],
        [-1.0613, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6595985293388367, train/raw-loss = 0.6595985293388367, train/logprobs = tensor([[-1.1463, -1.5332],
        [-1.2361, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6569761633872986, train/raw-loss = 0.6569761633872986, train/logprobs = tensor([[-0.7432, -0.9342],
        [-0.8139, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6692489385604858, train/raw-loss = 0.6692489385604858, train/logprobs = tensor([[-0.8930, -1.2501],
        [-0.9570, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6794319152832031, train/raw-loss = 0.6794319152832031, train/logprobs = tensor([[-0.7914, -1.1187],
        [-0.7899, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.655624508857727, train/raw-loss = 0.655624508857727, train/logprobs = tensor([[-1.5374, -1.5602],
        [-1.6876, -1.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6592499017715454, train/raw-loss = 0.6592499017715454, train/logprobs = tensor([[-0.9855, -1.1981],
        [-1.0750, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6820563077926636, train/raw-loss = 0.6820563077926636, train/logprobs = tensor([[-0.6501, -1.2848],
        [-0.6630, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6683226823806763, train/raw-loss = 0.6683226823806763, train/logprobs = tensor([[-0.9491, -1.3495],
        [-1.0024, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6583713889122009, train/raw-loss = 0.6583713889122009, train/logprobs = tensor([[-0.8106, -1.6709],
        [-0.9243, -1.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6469834446907043, train/raw-loss = 0.6469834446907043, train/logprobs = tensor([[-1.5048, -2.2232],
        [-1.5990, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6797101497650146, train/raw-loss = 0.6797101497650146, train/logprobs = tensor([[-0.6664, -1.6870],
        [-0.6909, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.683232843875885, train/raw-loss = 0.683232843875885, train/logprobs = tensor([[-0.9656, -1.3642],
        [-1.0281, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6942904591560364, train/raw-loss = 0.6942904591560364, train/logprobs = tensor([[-0.4989, -0.9991],
        [-0.5058, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6635227203369141, train/raw-loss = 0.6635227203369141, train/logprobs = tensor([[-0.7571, -1.2971],
        [-0.8222, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6960233449935913, train/raw-loss = 0.6960233449935913, train/logprobs = tensor([[-1.6412, -0.8003],
        [-1.6515, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6716673970222473, train/raw-loss = 0.6716673970222473, train/logprobs = tensor([[-0.9006, -1.8356],
        [-0.9486, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6504718065261841, train/raw-loss = 0.6504718065261841, train/logprobs = tensor([[-1.0048, -1.1417],
        [-1.1579, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6575814485549927, train/raw-loss = 0.6575814485549927, train/logprobs = tensor([[-1.4579, -1.0380],
        [-1.5999, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6726564168930054, train/raw-loss = 0.6726564168930054, train/logprobs = tensor([[-1.2457, -1.0000],
        [-1.3556, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6659195423126221, train/raw-loss = 0.6659195423126221, train/logprobs = tensor([[-1.1039, -1.4521],
        [-1.2564, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6463595628738403, train/raw-loss = 0.6463595628738403, train/logprobs = tensor([[-0.6710, -1.5861],
        [-0.7079, -1.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6638263463973999, train/raw-loss = 0.6638263463973999, train/logprobs = tensor([[-1.2741, -1.4761],
        [-1.3570, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6739931106567383, train/raw-loss = 0.6739931106567383, train/logprobs = tensor([[-0.8710, -1.0174],
        [-0.8790, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678565263748169, train/raw-loss = 0.678565263748169, train/logprobs = tensor([[-1.1486, -0.8595],
        [-1.2491, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6736483573913574, train/raw-loss = 0.6736483573913574, train/logprobs = tensor([[-0.7778, -1.5755],
        [-0.8147, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6805825233459473, train/raw-loss = 0.6805825233459473, train/logprobs = tensor([[-1.3469, -0.9800],
        [-1.4307, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6744076013565063, train/raw-loss = 0.6744076013565063, train/logprobs = tensor([[-0.6959, -1.2708],
        [-0.8213, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6815992593765259, train/raw-loss = 0.6815992593765259, train/logprobs = tensor([[-0.6407, -0.9858],
        [-0.6565, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6931482553482056, train/raw-loss = 0.6931482553482056, train/logprobs = tensor([[-0.8090, -1.1945],
        [-0.8420, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6945903897285461, train/raw-loss = 0.6945903897285461, train/logprobs = tensor([[-0.7038, -1.2251],
        [-0.7267, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6877249479293823, train/raw-loss = 0.6877249479293823, train/logprobs = tensor([[-0.6526, -1.2008],
        [-0.6792, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6316418051719666, train/raw-loss = 0.6316418051719666, train/logprobs = tensor([[-0.8534, -1.8226],
        [-0.8765, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.668732762336731, train/raw-loss = 0.668732762336731, train/logprobs = tensor([[-1.2706, -1.2705],
        [-1.3812, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6924586892127991, train/raw-loss = 0.6924586892127991, train/logprobs = tensor([[-0.6864, -0.6025],
        [-0.6989, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6888662576675415, train/raw-loss = 0.6888662576675415, train/logprobs = tensor([[-0.5987, -0.8959],
        [-0.6033, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6881542801856995, train/raw-loss = 0.6881542801856995, train/logprobs = tensor([[-0.9270, -1.5385],
        [-0.9858, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7003958225250244, train/raw-loss = 0.7003958225250244, train/logprobs = tensor([[-1.1320, -1.5081],
        [-1.1284, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6882853507995605, train/raw-loss = 0.6799179315567017, train/logprobs = tensor([[-0.6312, -3.4828],
        [-0.6531, -3.4497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008367341943085194
Epoch 0, Step 65: train/loss = 0.657392680644989, train/raw-loss = 0.6465272307395935, train/logprobs = tensor([[-1.0035, -1.0855],
        [-1.1946, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010865459218621254
Epoch 0, Step 66: train/loss = 0.6929569244384766, train/raw-loss = 0.6863054037094116, train/logprobs = tensor([[-0.5674, -0.8173],
        [-0.5662, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006651587784290314
Epoch 0, Step 67: train/loss = 0.6966490149497986, train/raw-loss = 0.6888260841369629, train/logprobs = tensor([[-0.5700, -0.9036],
        [-0.5644, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007822913117706776
Epoch 0, Step 68: train/loss = 0.6923829317092896, train/raw-loss = 0.6815572381019592, train/logprobs = tensor([[-0.9411, -1.6330],
        [-0.9773, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010825639590620995
Epoch 0, Step 69: train/loss = 0.6766461730003357, train/raw-loss = 0.6673731803894043, train/logprobs = tensor([[-0.7908, -1.3111],
        [-0.9539, -1.3574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009272987954318523
Epoch 0, Step 70: train/loss = 0.6898794174194336, train/raw-loss = 0.6831430196762085, train/logprobs = tensor([[-0.5656, -1.9079],
        [-0.5642, -1.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006736363749951124
Epoch 0, Step 71: train/loss = 0.6717157363891602, train/raw-loss = 0.6620359420776367, train/logprobs = tensor([[-1.0331, -1.6693],
        [-1.1537, -1.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009679833427071571
Epoch 0, Step 72: train/loss = 0.6970270872116089, train/raw-loss = 0.6868897676467896, train/logprobs = tensor([[-1.5103, -1.9939],
        [-1.5998, -2.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010137352161109447
Epoch 0, Step 73: train/loss = 0.6780229806900024, train/raw-loss = 0.666118860244751, train/logprobs = tensor([[-1.0824, -1.2675],
        [-1.1861, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01190411951392889
Epoch 0, Step 74: train/loss = 0.6504521369934082, train/raw-loss = 0.640910267829895, train/logprobs = tensor([[-1.2347, -0.7106],
        [-1.4367, -0.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009541843086481094
Epoch 0, Step 75: train/loss = 0.69774329662323, train/raw-loss = 0.689703643321991, train/logprobs = tensor([[-0.8094, -1.3705],
        [-0.8432, -1.3893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008039694279432297
Epoch 0, Step 76: train/loss = 0.6852821111679077, train/raw-loss = 0.6766624450683594, train/logprobs = tensor([[-0.6305, -0.6403],
        [-0.7057, -0.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008619657717645168
Epoch 0, Step 77: train/loss = 0.6627138257026672, train/raw-loss = 0.650907039642334, train/logprobs = tensor([[-1.1894, -1.2236],
        [-1.3715, -1.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011806806549429893
Epoch 0, Step 78: train/loss = 0.661774754524231, train/raw-loss = 0.6512006521224976, train/logprobs = tensor([[-1.1951, -0.9397],
        [-1.3842, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010574091225862503
Epoch 0, Step 79: train/loss = 0.6828070878982544, train/raw-loss = 0.671362042427063, train/logprobs = tensor([[-0.7569, -0.9279],
        [-0.8543, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011445019394159317
Epoch 0, Step 80: train/loss = 0.688744068145752, train/raw-loss = 0.6783456802368164, train/logprobs = tensor([[-0.7991, -1.0211],
        [-0.8163, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010398386046290398
Epoch 0, Step 81: train/loss = 0.6736487150192261, train/raw-loss = 0.6648812294006348, train/logprobs = tensor([[-1.1313, -1.0179],
        [-1.2296, -0.9957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008767477236688137
Epoch 0, Step 82: train/loss = 0.6416649222373962, train/raw-loss = 0.6304433345794678, train/logprobs = tensor([[-1.1040, -1.2753],
        [-1.3454, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011221583932638168
Epoch 0, Step 83: train/loss = 0.6771226525306702, train/raw-loss = 0.6700904369354248, train/logprobs = tensor([[-0.9777, -1.2717],
        [-1.0864, -1.2842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007032228168100119
Epoch 0, Step 84: train/loss = 0.6796720623970032, train/raw-loss = 0.6706089377403259, train/logprobs = tensor([[-0.4945, -1.1805],
        [-0.5239, -1.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009063154458999634
Epoch 0, Step 85: train/loss = 0.6673019528388977, train/raw-loss = 0.6570108532905579, train/logprobs = tensor([[-0.9081, -1.0802],
        [-1.1087, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010291125625371933
Epoch 0, Step 86: train/loss = 0.6884638071060181, train/raw-loss = 0.678180992603302, train/logprobs = tensor([[-0.7014, -1.1693],
        [-0.7109, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010282795876264572
Epoch 0, Step 87: train/loss = 0.6606634855270386, train/raw-loss = 0.6477228403091431, train/logprobs = tensor([[-0.8654, -1.6739],
        [-1.0233, -1.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01294063962996006
Epoch 0, Step 88: train/loss = 0.6919941902160645, train/raw-loss = 0.684200644493103, train/logprobs = tensor([[-0.5446, -1.5488],
        [-0.5519, -1.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007793553173542023
Epoch 0, Step 89: train/loss = 0.7058611512184143, train/raw-loss = 0.6981847882270813, train/logprobs = tensor([[-0.7879, -1.1960],
        [-0.8672, -1.2905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007676300592720509
Epoch 0, Step 90: train/loss = 0.6803679466247559, train/raw-loss = 0.669094443321228, train/logprobs = tensor([[-0.7986, -1.1438],
        [-0.8726, -1.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011273504234850407
Epoch 0, Step 91: train/loss = 0.6346383690834045, train/raw-loss = 0.6248669624328613, train/logprobs = tensor([[-1.0797, -1.5363],
        [-1.1456, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00977147277444601
Epoch 0, Step 92: train/loss = 0.6900396943092346, train/raw-loss = 0.6795832514762878, train/logprobs = tensor([[-1.0596, -1.0566],
        [-1.0816, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010456472635269165
Epoch 0, Step 93: train/loss = 0.6753333210945129, train/raw-loss = 0.6644076108932495, train/logprobs = tensor([[-1.1955, -1.3188],
        [-1.3258, -1.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010925689712166786
Epoch 0, Step 94: train/loss = 0.6806666851043701, train/raw-loss = 0.6702765226364136, train/logprobs = tensor([[-0.9911, -1.1198],
        [-1.0620, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010390203446149826
Epoch 0, Step 95: train/loss = 0.6832294464111328, train/raw-loss = 0.6725560426712036, train/logprobs = tensor([[-0.8295, -1.0052],
        [-0.9092, -0.9998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010673405602574348
Epoch 0, Step 96: train/loss = 0.665611982345581, train/raw-loss = 0.6511757373809814, train/logprobs = tensor([[-0.8667, -1.0022],
        [-0.9494, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014436276629567146
Epoch 0, Step 97: train/loss = 0.637271523475647, train/raw-loss = 0.6186109781265259, train/logprobs = tensor([[-0.7982, -1.9641],
        [-0.9493, -1.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01866057887673378
Epoch 0, Step 98: train/loss = 0.6789565086364746, train/raw-loss = 0.6615861058235168, train/logprobs = tensor([[-0.7962, -1.4030],
        [-0.9411, -1.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01737043261528015
Epoch 0, Step 99: train/loss = 0.673480749130249, train/raw-loss = 0.6562576293945312, train/logprobs = tensor([[-0.8619, -1.6692],
        [-0.9812, -1.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017223116010427475
Epoch 0, Step 100: train/loss = 0.6368604898452759, train/raw-loss = 0.6169558763504028, train/logprobs = tensor([[-1.2041, -1.3663],
        [-1.5948, -1.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019904593005776405
Epoch 0, Step 101: train/loss = 0.6851257085800171, train/raw-loss = 0.6674966812133789, train/logprobs = tensor([[-0.9724, -1.4444],
        [-1.1446, -1.5016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017629049718379974
Epoch 0, Step 102: train/loss = 0.6832475662231445, train/raw-loss = 0.6687594652175903, train/logprobs = tensor([[-0.5236, -1.2964],
        [-0.5343, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014488078653812408
Epoch 0, Step 103: train/loss = 0.6774307489395142, train/raw-loss = 0.663766622543335, train/logprobs = tensor([[-0.9637, -1.2097],
        [-1.0745, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013664165511727333
Epoch 0, Step 104: train/loss = 0.6618592739105225, train/raw-loss = 0.642808198928833, train/logprobs = tensor([[-0.8868, -1.3011],
        [-1.0076, -1.2110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01905111037194729
Epoch 0, Step 105: train/loss = 0.616857647895813, train/raw-loss = 0.5977175235748291, train/logprobs = tensor([[-1.3996, -1.9680],
        [-1.7784, -1.9170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019140107557177544
Epoch 0, Step 106: train/loss = 0.6894204616546631, train/raw-loss = 0.6749895811080933, train/logprobs = tensor([[-0.6990, -1.4611],
        [-0.6992, -1.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014430800452828407
Epoch 0, Step 107: train/loss = 0.662605345249176, train/raw-loss = 0.644562840461731, train/logprobs = tensor([[-1.4966, -1.8094],
        [-1.7147, -1.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018042542040348053
Epoch 0, Step 108: train/loss = 0.6815674304962158, train/raw-loss = 0.6658645868301392, train/logprobs = tensor([[-1.2973, -2.5639],
        [-1.3855, -2.5396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01570276729762554
Epoch 0, Step 109: train/loss = 0.6919608116149902, train/raw-loss = 0.676957368850708, train/logprobs = tensor([[-0.5425, -1.1543],
        [-0.5493, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015003398060798645
Epoch 0, Step 110: train/loss = 0.690617561340332, train/raw-loss = 0.676140308380127, train/logprobs = tensor([[-0.9276, -1.6153],
        [-0.9879, -1.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014477189630270004
Epoch 0, Step 111: train/loss = 0.6711234450340271, train/raw-loss = 0.658202052116394, train/logprobs = tensor([[-1.1528, -1.1548],
        [-1.3253, -1.1760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012921348214149475
Epoch 0, Step 112: train/loss = 0.6520572304725647, train/raw-loss = 0.6342782974243164, train/logprobs = tensor([[-1.5392, -1.9215],
        [-1.7625, -1.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017778992652893066
Epoch 0, Step 113: train/loss = 0.6501480937004089, train/raw-loss = 0.6333053708076477, train/logprobs = tensor([[-1.1954, -1.3864],
        [-1.4559, -1.3866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01684272661805153
Epoch 0, Step 114: train/loss = 0.6468940377235413, train/raw-loss = 0.6292217969894409, train/logprobs = tensor([[-1.0906, -1.5446],
        [-1.2576, -1.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017672257497906685
Epoch 0, Step 115: train/loss = 0.6849625706672668, train/raw-loss = 0.6717129945755005, train/logprobs = tensor([[-0.8923, -1.5026],
        [-0.9715, -1.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013249576091766357
Epoch 0, Step 116: train/loss = 0.6932816505432129, train/raw-loss = 0.6814857125282288, train/logprobs = tensor([[-0.5115, -0.8978],
        [-0.5343, -0.8730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011795975267887115
Epoch 0, Step 117: train/loss = 0.699907660484314, train/raw-loss = 0.686080813407898, train/logprobs = tensor([[-1.0194, -1.0545],
        [-1.1289, -1.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013826785609126091
Epoch 0, Step 118: train/loss = 0.6510077714920044, train/raw-loss = 0.6347498297691345, train/logprobs = tensor([[-0.7210, -0.9807],
        [-0.9032, -0.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01625795103609562
Epoch 0, Step 119: train/loss = 0.6043497323989868, train/raw-loss = 0.5818899869918823, train/logprobs = tensor([[-1.0556, -1.6824],
        [-1.3895, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022459780797362328
Epoch 0, Step 120: train/loss = 0.6073692440986633, train/raw-loss = 0.5898303985595703, train/logprobs = tensor([[-1.0274, -2.0216],
        [-1.2255, -1.7551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017538858577609062
Epoch 0, Step 121: train/loss = 0.6853639483451843, train/raw-loss = 0.6723008155822754, train/logprobs = tensor([[-0.6961, -0.9932],
        [-0.7450, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013063093647360802
Epoch 0, Step 122: train/loss = 0.6933081150054932, train/raw-loss = 0.6774467825889587, train/logprobs = tensor([[-0.6757, -1.0532],
        [-0.7323, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015861298888921738
Epoch 0, Step 123: train/loss = 0.6135585308074951, train/raw-loss = 0.5964575409889221, train/logprobs = tensor([[-1.1590, -1.6955],
        [-1.3664, -1.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01710095815360546
Epoch 0, Step 124: train/loss = 0.6908882856369019, train/raw-loss = 0.6795953512191772, train/logprobs = tensor([[-0.7499, -0.7916],
        [-0.7972, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011292943730950356
Epoch 0, Step 125: train/loss = 0.6898770928382874, train/raw-loss = 0.675299882888794, train/logprobs = tensor([[-0.5938, -1.0570],
        [-0.6044, -0.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014577212743461132
Epoch 0, Step 126: train/loss = 0.6686702966690063, train/raw-loss = 0.6514343023300171, train/logprobs = tensor([[-1.0745, -1.1469],
        [-1.2247, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017235981300473213
Epoch 0, Step 127: train/loss = 0.6594803929328918, train/raw-loss = 0.6426895260810852, train/logprobs = tensor([[-0.8765, -1.1508],
        [-1.0195, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016790863126516342
Epoch 0, Step 128: train/loss = 0.7030466794967651, train/raw-loss = 0.6649619936943054, train/logprobs = tensor([[-0.8163, -1.2199],
        [-0.9134, -1.1984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03808468207716942
Epoch 0, Step 129: train/loss = 0.6666049957275391, train/raw-loss = 0.6008346080780029, train/logprobs = tensor([[-0.8843, -1.4498],
        [-1.0054, -1.1773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577033549547195
Epoch 0, Step 130: train/loss = 0.7108091711997986, train/raw-loss = 0.6495921611785889, train/logprobs = tensor([[-0.7587, -0.8361],
        [-0.8992, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06121700257062912
Epoch 0, Step 131: train/loss = 0.6689808368682861, train/raw-loss = 0.612128734588623, train/logprobs = tensor([[-0.7622, -1.0954],
        [-1.1332, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05685214698314667
Epoch 0, Step 132: train/loss = 0.6916161775588989, train/raw-loss = 0.6374327540397644, train/logprobs = tensor([[-0.9761, -1.2028],
        [-1.0640, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054183438420295715
Epoch 0, Step 133: train/loss = 0.6106230616569519, train/raw-loss = 0.5564129948616028, train/logprobs = tensor([[-0.9243, -2.4499],
        [-1.3423, -2.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054210055619478226
Epoch 0, Step 134: train/loss = 0.6927573680877686, train/raw-loss = 0.6576197743415833, train/logprobs = tensor([[-0.8163, -0.9959],
        [-0.9008, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035137634724378586
Epoch 0, Step 135: train/loss = 0.6608073711395264, train/raw-loss = 0.6098597645759583, train/logprobs = tensor([[-1.2968, -1.7074],
        [-1.7237, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05094759911298752
Epoch 0, Step 136: train/loss = 0.695432186126709, train/raw-loss = 0.6490528583526611, train/logprobs = tensor([[-0.5515, -0.9526],
        [-0.5973, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04637932404875755
Epoch 0, Step 137: train/loss = 0.6435510516166687, train/raw-loss = 0.5852468609809875, train/logprobs = tensor([[-0.9974, -1.3397],
        [-1.3569, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05830417573451996
Epoch 0, Step 138: train/loss = 0.6921074390411377, train/raw-loss = 0.639618992805481, train/logprobs = tensor([[-0.7417, -0.8926],
        [-0.9602, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052488502115011215
Epoch 0, Step 139: train/loss = 0.6595664024353027, train/raw-loss = 0.6172400712966919, train/logprobs = tensor([[-0.7760, -1.0028],
        [-0.9594, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232632741332054
Epoch 0, Step 140: train/loss = 0.6845945119857788, train/raw-loss = 0.62453293800354, train/logprobs = tensor([[-0.8892, -1.8770],
        [-1.0656, -1.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06006151810288429
Epoch 0, Step 141: train/loss = 0.7300094962120056, train/raw-loss = 0.6903518438339233, train/logprobs = tensor([[-1.1544, -1.4416],
        [-1.1414, -1.4156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03965765982866287
Epoch 0, Step 142: train/loss = 0.6523356437683105, train/raw-loss = 0.5870175361633301, train/logprobs = tensor([[-1.0589, -1.1256],
        [-1.4694, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06531814485788345
Epoch 0, Step 143: train/loss = 0.6483049392700195, train/raw-loss = 0.5905686616897583, train/logprobs = tensor([[-0.9267, -0.8744],
        [-1.3504, -0.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057736314833164215
Epoch 0, Step 144: train/loss = 0.6887610554695129, train/raw-loss = 0.6403725147247314, train/logprobs = tensor([[-1.3356, -1.4583],
        [-1.4489, -1.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04838857054710388
Epoch 0, Step 145: train/loss = 0.6162288784980774, train/raw-loss = 0.5548319220542908, train/logprobs = tensor([[-0.7607, -2.0838],
        [-1.1762, -1.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061396967619657516
Epoch 0, Step 146: train/loss = 0.6534948348999023, train/raw-loss = 0.5983003377914429, train/logprobs = tensor([[-0.8616, -0.8981],
        [-1.2988, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055194541811943054
Epoch 0, Step 147: train/loss = 0.6452515721321106, train/raw-loss = 0.587333083152771, train/logprobs = tensor([[-0.8564, -1.8145],
        [-1.1626, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791846662759781
Epoch 0, Step 148: train/loss = 0.6580078601837158, train/raw-loss = 0.6218619346618652, train/logprobs = tensor([[-1.1865, -1.3738],
        [-1.4775, -1.3418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036145951598882675
Epoch 0, Step 149: train/loss = 0.6691334247589111, train/raw-loss = 0.6159076690673828, train/logprobs = tensor([[-0.7312, -0.6936],
        [-0.9996, -0.6120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053225740790367126
Epoch 0, Step 150: train/loss = 0.6483561396598816, train/raw-loss = 0.585437536239624, train/logprobs = tensor([[-0.7292, -1.4173],
        [-0.9922, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06291864812374115
Epoch 0, Step 151: train/loss = 0.6328924298286438, train/raw-loss = 0.5842549204826355, train/logprobs = tensor([[-0.8904, -1.5964],
        [-1.2683, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048637501895427704
Epoch 0, Step 152: train/loss = 0.6519004702568054, train/raw-loss = 0.6067413687705994, train/logprobs = tensor([[-1.1867, -1.1425],
        [-1.3798, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04515908285975456
Epoch 0, Step 153: train/loss = 0.6574774980545044, train/raw-loss = 0.5985729098320007, train/logprobs = tensor([[-1.1447, -1.6263],
        [-1.6209, -1.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05890461057424545
Epoch 0, Step 154: train/loss = 0.6239951848983765, train/raw-loss = 0.5764210820198059, train/logprobs = tensor([[-0.9454, -1.1279],
        [-1.3247, -0.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04757405072450638
Epoch 0, Step 155: train/loss = 0.6605077385902405, train/raw-loss = 0.6111374497413635, train/logprobs = tensor([[-1.0038, -1.3798],
        [-1.1640, -1.1909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04937028884887695
Epoch 0, Step 156: train/loss = 0.7054588794708252, train/raw-loss = 0.6389472484588623, train/logprobs = tensor([[-0.5517, -1.1947],
        [-0.6311, -1.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06651166081428528
Epoch 0, Step 157: train/loss = 0.7246114015579224, train/raw-loss = 0.6725473403930664, train/logprobs = tensor([[-0.7760, -1.0367],
        [-0.8618, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05206403136253357
Epoch 0, Step 158: train/loss = 0.6924481391906738, train/raw-loss = 0.649450421333313, train/logprobs = tensor([[-1.3790, -1.0535],
        [-1.4462, -0.9377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04299771040678024
Epoch 0, Step 159: train/loss = 0.6815299391746521, train/raw-loss = 0.6300638318061829, train/logprobs = tensor([[-0.8455, -1.0994],
        [-1.0384, -1.0245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05146612599492073
Epoch 0, Step 160: train/loss = 0.6945246458053589, train/raw-loss = 0.6602045893669128, train/logprobs = tensor([[-0.5669, -1.5600],
        [-0.5990, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03432006388902664
Epoch 0, Step 161: train/loss = 0.6292054057121277, train/raw-loss = 0.5867058634757996, train/logprobs = tensor([[-1.1799, -1.2759],
        [-1.4524, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04249952360987663
Epoch 0, Step 162: train/loss = 0.6974906921386719, train/raw-loss = 0.6671497821807861, train/logprobs = tensor([[-0.6335, -1.0487],
        [-0.6350, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030340950936079025
Epoch 0, Step 163: train/loss = 0.6621939539909363, train/raw-loss = 0.6131904721260071, train/logprobs = tensor([[-0.9175, -0.9446],
        [-1.2851, -0.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04900345951318741
Epoch 0, Step 164: train/loss = 0.7343526482582092, train/raw-loss = 0.693122148513794, train/logprobs = tensor([[-0.9707, -1.1666],
        [-0.9728, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04123052954673767
Epoch 0, Step 165: train/loss = 0.7019944190979004, train/raw-loss = 0.6530448794364929, train/logprobs = tensor([[-0.8452, -1.4834],
        [-0.9190, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048949532210826874
Epoch 0, Step 166: train/loss = 0.6639927625656128, train/raw-loss = 0.625812828540802, train/logprobs = tensor([[-0.9064, -1.4690],
        [-0.9651, -1.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038179971277713776
Epoch 0, Step 167: train/loss = 0.6334812641143799, train/raw-loss = 0.5767461061477661, train/logprobs = tensor([[-0.7129, -1.8065],
        [-0.8893, -1.4671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05673518776893616
Epoch 0, Step 168: train/loss = 0.6055908203125, train/raw-loss = 0.5608378648757935, train/logprobs = tensor([[-1.0117, -0.8364],
        [-1.5116, -0.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04475291445851326
Epoch 0, Step 169: train/loss = 0.6135661602020264, train/raw-loss = 0.5631062984466553, train/logprobs = tensor([[-0.9554, -0.8234],
        [-1.3771, -0.6445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050459858030080795
Epoch 0, Step 170: train/loss = 0.6919516324996948, train/raw-loss = 0.656566321849823, train/logprobs = tensor([[-0.8834, -1.0388],
        [-0.9188, -0.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03538529947400093
Epoch 0, Step 171: train/loss = 0.5985782742500305, train/raw-loss = 0.5468846559524536, train/logprobs = tensor([[-0.7293, -1.1119],
        [-1.1916, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051693592220544815
Epoch 0, Step 172: train/loss = 0.6385301351547241, train/raw-loss = 0.6018587350845337, train/logprobs = tensor([[-0.8443, -1.1381],
        [-1.0864, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0366714671254158
Epoch 0, Step 173: train/loss = 0.5660380721092224, train/raw-loss = 0.5171055197715759, train/logprobs = tensor([[-1.4130, -2.0480],
        [-1.8699, -1.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04893253743648529
Epoch 0, Step 174: train/loss = 0.6599431037902832, train/raw-loss = 0.6199082136154175, train/logprobs = tensor([[-0.7580, -1.1528],
        [-0.8824, -0.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04003484174609184
Epoch 0, Step 175: train/loss = 0.5987634062767029, train/raw-loss = 0.5508930683135986, train/logprobs = tensor([[-0.9667, -1.9385],
        [-1.3900, -1.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047870371490716934
Epoch 0, Step 176: train/loss = 0.6854121088981628, train/raw-loss = 0.6533821821212769, train/logprobs = tensor([[-0.8416, -2.1512],
        [-0.8938, -2.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032029908150434494
Epoch 0, Step 177: train/loss = 0.7008088827133179, train/raw-loss = 0.6575409770011902, train/logprobs = tensor([[-0.8155, -1.4620],
        [-0.8498, -1.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04326792433857918
Epoch 0, Step 178: train/loss = 0.7033833265304565, train/raw-loss = 0.6659561395645142, train/logprobs = tensor([[-1.1215, -1.5276],
        [-1.2574, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037427209317684174
Epoch 0, Step 179: train/loss = 0.616843581199646, train/raw-loss = 0.5576226115226746, train/logprobs = tensor([[-1.1930, -2.2822],
        [-1.6240, -2.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05922097712755203
Epoch 0, Step 180: train/loss = 0.6102040410041809, train/raw-loss = 0.5702832937240601, train/logprobs = tensor([[-0.7008, -1.0995],
        [-1.0610, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039920806884765625
Epoch 0, Step 181: train/loss = 0.7204952239990234, train/raw-loss = 0.6787476539611816, train/logprobs = tensor([[-1.0541, -1.2917],
        [-1.0072, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041747573763132095
Epoch 0, Step 182: train/loss = 0.709101140499115, train/raw-loss = 0.672421932220459, train/logprobs = tensor([[-2.0662, -2.2320],
        [-2.0813, -2.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03667919710278511
Epoch 0, Step 183: train/loss = 0.6393851041793823, train/raw-loss = 0.6043325662612915, train/logprobs = tensor([[-0.7126, -0.7865],
        [-1.0176, -0.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03505249321460724
Epoch 0, Step 184: train/loss = 0.6608309745788574, train/raw-loss = 0.6212857961654663, train/logprobs = tensor([[-0.9163, -1.3623],
        [-1.1304, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03954513370990753
Epoch 0, Step 185: train/loss = 0.6276860237121582, train/raw-loss = 0.5953137278556824, train/logprobs = tensor([[-0.9798, -1.3521],
        [-1.2167, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032372262328863144
Epoch 0, Step 186: train/loss = 0.7207626104354858, train/raw-loss = 0.6841091513633728, train/logprobs = tensor([[-0.6277, -1.3528],
        [-0.6130, -1.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03665350377559662
Epoch 0, Step 187: train/loss = 0.6688588261604309, train/raw-loss = 0.6229021549224854, train/logprobs = tensor([[-0.9079, -0.9740],
        [-1.0802, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04595669358968735
Epoch 0, Step 188: train/loss = 0.703738272190094, train/raw-loss = 0.6567578911781311, train/logprobs = tensor([[-1.0933, -1.0194],
        [-1.2613, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046980392187833786
Epoch 0, Step 189: train/loss = 0.697881817817688, train/raw-loss = 0.6596604585647583, train/logprobs = tensor([[-0.6794, -1.1522],
        [-0.6809, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0382213220000267
Epoch 0, Step 190: train/loss = 0.636811375617981, train/raw-loss = 0.5950690507888794, train/logprobs = tensor([[-0.6567, -1.5093],
        [-0.8914, -1.2857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04174226522445679
Epoch 0, Step 191: train/loss = 0.6037936210632324, train/raw-loss = 0.5593863129615784, train/logprobs = tensor([[-0.7864, -1.8992],
        [-1.0212, -1.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044407352805137634
Epoch 0, Step 192: train/loss = 0.6591625809669495, train/raw-loss = 0.6055778861045837, train/logprobs = tensor([[-0.9577, -2.7168],
        [-1.0588, -2.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05358469486236572
Epoch 0, Step 193: train/loss = 0.664653480052948, train/raw-loss = 0.5964600443840027, train/logprobs = tensor([[-0.7747, -1.4100],
        [-0.7827, -0.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06819344311952591
Epoch 0, Step 194: train/loss = 0.7014611959457397, train/raw-loss = 0.6572216749191284, train/logprobs = tensor([[-0.9093, -1.0048],
        [-0.9306, -0.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044239576905965805
Epoch 0, Step 195: train/loss = 0.705567479133606, train/raw-loss = 0.6554100513458252, train/logprobs = tensor([[-0.5859, -1.2912],
        [-0.5784, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05015737563371658
Epoch 0, Step 196: train/loss = 0.6679026484489441, train/raw-loss = 0.6156489849090576, train/logprobs = tensor([[-0.6139, -1.1704],
        [-0.7009, -0.8640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05225370451807976
Epoch 0, Step 197: train/loss = 0.6263477802276611, train/raw-loss = 0.5513617992401123, train/logprobs = tensor([[-0.6437, -1.8405],
        [-0.9452, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07498601078987122
Epoch 0, Step 198: train/loss = 0.5599719285964966, train/raw-loss = 0.47542160749435425, train/logprobs = tensor([[-0.8280, -1.9065],
        [-1.3054, -1.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08455038070678711
Epoch 0, Step 199: train/loss = 0.603525698184967, train/raw-loss = 0.5349118113517761, train/logprobs = tensor([[-0.9078, -1.5254],
        [-1.4149, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686139166355133
Epoch 0, Step 200: train/loss = 0.6014176607131958, train/raw-loss = 0.5284688472747803, train/logprobs = tensor([[-0.7566, -1.0935],
        [-1.2633, -0.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07294884324073792
Epoch 0, Step 201: train/loss = 0.572914719581604, train/raw-loss = 0.5090267658233643, train/logprobs = tensor([[-0.8160, -2.8057],
        [-0.9497, -1.7079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06388790905475616
Epoch 0, Step 202: train/loss = 0.6874392032623291, train/raw-loss = 0.6415388584136963, train/logprobs = tensor([[-0.5581, -0.7553],
        [-0.6391, -0.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04590034857392311
Epoch 0, Step 203: train/loss = 0.5876427292823792, train/raw-loss = 0.5234265923500061, train/logprobs = tensor([[-0.9759, -1.6615],
        [-1.4768, -1.3339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06421612203121185
Epoch 0, Step 204: train/loss = 0.5418049693107605, train/raw-loss = 0.4637778103351593, train/logprobs = tensor([[-0.9711, -1.5190],
        [-1.8020, -1.2181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07802718877792358
Epoch 0, Step 205: train/loss = 0.7065838575363159, train/raw-loss = 0.6496856808662415, train/logprobs = tensor([[-0.8059, -1.1655],
        [-0.7726, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056898199021816254
Epoch 0, Step 206: train/loss = 0.6909158229827881, train/raw-loss = 0.6485843658447266, train/logprobs = tensor([[-0.8322, -1.1439],
        [-0.8140, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042331449687480927
Epoch 0, Step 207: train/loss = 0.5330492258071899, train/raw-loss = 0.46961623430252075, train/logprobs = tensor([[-0.8194, -2.9359],
        [-1.0611, -1.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063432976603508
Epoch 0, Step 208: train/loss = 0.589281439781189, train/raw-loss = 0.508136510848999, train/logprobs = tensor([[-0.8181, -1.4475],
        [-1.3667, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08114495873451233
Epoch 0, Step 209: train/loss = 0.624491810798645, train/raw-loss = 0.5589941143989563, train/logprobs = tensor([[-0.8550, -1.3573],
        [-1.2443, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06549770385026932
Epoch 0, Step 210: train/loss = 0.6359935402870178, train/raw-loss = 0.5583086013793945, train/logprobs = tensor([[-1.0274, -1.9607],
        [-1.2664, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07768493890762329
Epoch 0, Step 211: train/loss = 0.5946936011314392, train/raw-loss = 0.5299601554870605, train/logprobs = tensor([[-0.9919, -2.7181],
        [-1.2616, -2.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06473347544670105
Epoch 0, Step 212: train/loss = 0.7468799352645874, train/raw-loss = 0.6632235050201416, train/logprobs = tensor([[-0.6545, -1.2111],
        [-0.9373, -1.2566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08365634083747864
Epoch 0, Step 213: train/loss = 0.6193349957466125, train/raw-loss = 0.5494846105575562, train/logprobs = tensor([[-0.8602, -2.1943],
        [-1.2928, -1.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0698503777384758
Epoch 0, Step 214: train/loss = 0.6737659573554993, train/raw-loss = 0.6101095676422119, train/logprobs = tensor([[-0.8879, -2.3087],
        [-0.9609, -1.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365642696619034
Epoch 0, Step 215: train/loss = 0.6768604516983032, train/raw-loss = 0.6162440180778503, train/logprobs = tensor([[-0.8705, -1.2252],
        [-1.0361, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06061643362045288
Epoch 0, Step 216: train/loss = 0.6007471084594727, train/raw-loss = 0.5230588316917419, train/logprobs = tensor([[-0.7790, -1.8547],
        [-0.8900, -1.0833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0776882991194725
Epoch 0, Step 217: train/loss = 0.6651015281677246, train/raw-loss = 0.6086171865463257, train/logprobs = tensor([[-0.7103, -1.3996],
        [-0.8189, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05648428574204445
Epoch 0, Step 218: train/loss = 0.6394782066345215, train/raw-loss = 0.5796052813529968, train/logprobs = tensor([[-0.9127, -0.9140],
        [-1.3014, -0.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059872932732105255
Epoch 0, Step 219: train/loss = 0.645734965801239, train/raw-loss = 0.5934937000274658, train/logprobs = tensor([[-1.1163, -1.4335],
        [-1.5215, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05224122107028961
Epoch 0, Step 220: train/loss = 0.71429443359375, train/raw-loss = 0.644622802734375, train/logprobs = tensor([[-0.9362, -1.4601],
        [-0.9996, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06967166066169739
Epoch 0, Step 221: train/loss = 0.6552917957305908, train/raw-loss = 0.6014183759689331, train/logprobs = tensor([[-0.6283, -0.6741],
        [-0.9921, -0.5468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053873397409915924
Epoch 0, Step 222: train/loss = 0.6492286920547485, train/raw-loss = 0.5739445686340332, train/logprobs = tensor([[-1.4944, -1.6306],
        [-2.0258, -1.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528413087129593
Epoch 0, Step 223: train/loss = 0.5606591105461121, train/raw-loss = 0.4864223599433899, train/logprobs = tensor([[-0.8423, -2.6244],
        [-1.2431, -1.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07423677295446396
Epoch 0, Step 224: train/loss = 0.5336666703224182, train/raw-loss = 0.4395880699157715, train/logprobs = tensor([[-0.7980, -2.1435],
        [-1.3946, -1.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09407860785722733
Epoch 0, Step 225: train/loss = 0.677713930606842, train/raw-loss = 0.6002185344696045, train/logprobs = tensor([[-0.6603, -1.7479],
        [-0.6712, -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07749538123607635
Epoch 0, Step 226: train/loss = 0.6639939546585083, train/raw-loss = 0.5894142389297485, train/logprobs = tensor([[-0.7093, -1.1500],
        [-0.7184, -0.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07457965612411499
Epoch 0, Step 227: train/loss = 0.49142706394195557, train/raw-loss = 0.40755826234817505, train/logprobs = tensor([[-1.2948, -2.3949],
        [-2.1838, -1.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08386876434087753
Epoch 0, Step 228: train/loss = 0.6318320631980896, train/raw-loss = 0.5475759506225586, train/logprobs = tensor([[-0.9194, -1.6147],
        [-1.0936, -1.0777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08425616472959518
Epoch 0, Step 229: train/loss = 0.6102566719055176, train/raw-loss = 0.5256534218788147, train/logprobs = tensor([[-0.8755, -1.4855],
        [-1.2749, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08460318297147751
Epoch 0, Step 230: train/loss = 0.6641219258308411, train/raw-loss = 0.5856847763061523, train/logprobs = tensor([[-0.7556, -1.3865],
        [-0.8197, -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07843713462352753
Epoch 0, Step 231: train/loss = 0.7252309322357178, train/raw-loss = 0.6439451575279236, train/logprobs = tensor([[-0.8011, -1.0613],
        [-0.7229, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08128580451011658
Epoch 0, Step 232: train/loss = 0.5831103324890137, train/raw-loss = 0.5083121061325073, train/logprobs = tensor([[-0.7021, -1.7420],
        [-1.0342, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07479818910360336
Epoch 0, Step 233: train/loss = 0.6024442315101624, train/raw-loss = 0.5210745334625244, train/logprobs = tensor([[-0.8419, -1.4021],
        [-1.4128, -1.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08136969059705734
Epoch 0, Step 234: train/loss = 0.6062008142471313, train/raw-loss = 0.5328232049942017, train/logprobs = tensor([[-0.6980, -1.4321],
        [-1.0928, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0733775943517685
Epoch 0, Step 235: train/loss = 0.6521466970443726, train/raw-loss = 0.5888321399688721, train/logprobs = tensor([[-0.8913, -0.8903],
        [-1.1012, -0.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0633145272731781
Epoch 0, Step 236: train/loss = 0.6186547875404358, train/raw-loss = 0.5422560572624207, train/logprobs = tensor([[-0.6714, -1.5701],
        [-0.6776, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07639870047569275
Epoch 0, Step 237: train/loss = 0.587760865688324, train/raw-loss = 0.5125638246536255, train/logprobs = tensor([[-0.7027, -1.9404],
        [-1.1835, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751970037817955
Epoch 0, Step 238: train/loss = 0.590681791305542, train/raw-loss = 0.5086135864257812, train/logprobs = tensor([[-0.6928, -2.2881],
        [-0.9916, -1.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820683091878891
Epoch 0, Step 239: train/loss = 0.6588500142097473, train/raw-loss = 0.5774521827697754, train/logprobs = tensor([[-0.9428, -1.2216],
        [-1.1539, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139777928590775
Epoch 0, Step 240: train/loss = 0.6328234076499939, train/raw-loss = 0.5502996444702148, train/logprobs = tensor([[-0.7710, -1.8608],
        [-0.7900, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08252374827861786
Epoch 0, Step 241: train/loss = 0.6038618087768555, train/raw-loss = 0.5249596238136292, train/logprobs = tensor([[-0.7695, -1.7437],
        [-1.1069, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07890219986438751
Epoch 0, Step 242: train/loss = 0.5972867012023926, train/raw-loss = 0.49774089455604553, train/logprobs = tensor([[-0.7730, -2.5078],
        [-0.7110, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09954582899808884
Epoch 0, Step 243: train/loss = 0.5915158987045288, train/raw-loss = 0.5076665282249451, train/logprobs = tensor([[-0.7833, -1.6575],
        [-1.1086, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384938538074493
Epoch 0, Step 244: train/loss = 0.5891851782798767, train/raw-loss = 0.5096220970153809, train/logprobs = tensor([[-0.8639, -2.2275],
        [-0.9056, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07956314086914062
Epoch 0, Step 245: train/loss = 0.6362613439559937, train/raw-loss = 0.5578150749206543, train/logprobs = tensor([[-0.8519, -1.3159],
        [-1.0451, -0.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07844621688127518
Epoch 0, Step 246: train/loss = 0.6554211378097534, train/raw-loss = 0.5788899064064026, train/logprobs = tensor([[-1.0055, -1.7649],
        [-0.9337, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07653124630451202
Epoch 0, Step 247: train/loss = 0.6251405477523804, train/raw-loss = 0.5253863334655762, train/logprobs = tensor([[-0.8539, -1.3187],
        [-1.1311, -0.7802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09975424408912659
Epoch 0, Step 248: train/loss = 0.5364903211593628, train/raw-loss = 0.44741708040237427, train/logprobs = tensor([[-0.7697, -1.9639],
        [-1.2487, -1.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08907324820756912
Epoch 0, Step 249: train/loss = 0.6498113870620728, train/raw-loss = 0.5787757635116577, train/logprobs = tensor([[-0.8392, -1.7612],
        [-0.8665, -1.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07103557884693146
Epoch 0, Step 250: train/loss = 0.6639243364334106, train/raw-loss = 0.584135890007019, train/logprobs = tensor([[-0.8539, -1.2675],
        [-1.0754, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07978853583335876
Epoch 0, Step 251: train/loss = 0.5469722747802734, train/raw-loss = 0.4528079628944397, train/logprobs = tensor([[-0.8978, -1.4040],
        [-1.7002, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416426718235016
Epoch 0, Step 252: train/loss = 0.6453503370285034, train/raw-loss = 0.5675036311149597, train/logprobs = tensor([[-1.1421, -1.8598],
        [-1.2392, -1.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07784674316644669
Epoch 0, Step 253: train/loss = 0.47681981325149536, train/raw-loss = 0.37197375297546387, train/logprobs = tensor([[-0.9586, -2.9443],
        [-1.7455, -2.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484608262777328
Epoch 0, Step 254: train/loss = 0.60725998878479, train/raw-loss = 0.522581160068512, train/logprobs = tensor([[-0.8768, -1.5740],
        [-1.1318, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08467883616685867
Epoch 0, Step 255: train/loss = 0.7063075304031372, train/raw-loss = 0.6279006600379944, train/logprobs = tensor([[-1.2284, -1.4340],
        [-1.2158, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0784069374203682
Epoch 0, Step 256: train/loss = 0.6141188144683838, train/raw-loss = 0.5263851881027222, train/logprobs = tensor([[-0.8876, -1.3213],
        [-1.2252, -0.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08773358911275864
Epoch 0, Step 257: train/loss = 0.5761651992797852, train/raw-loss = 0.49071264266967773, train/logprobs = tensor([[-0.7699, -1.4561],
        [-1.0853, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08545258641242981
Epoch 0, Step 258: train/loss = 0.5714909434318542, train/raw-loss = 0.5015661120414734, train/logprobs = tensor([[-0.8831, -1.4672],
        [-1.4191, -1.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06992484629154205
Epoch 0, Step 259: train/loss = 0.7005245685577393, train/raw-loss = 0.6115524172782898, train/logprobs = tensor([[-1.1878, -0.9686],
        [-1.4152, -0.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08897211402654648
Epoch 0, Step 260: train/loss = 0.519075870513916, train/raw-loss = 0.4115893244743347, train/logprobs = tensor([[-0.9060, -1.7472],
        [-1.7377, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748651623725891
Epoch 0, Step 261: train/loss = 0.5083001255989075, train/raw-loss = 0.40983277559280396, train/logprobs = tensor([[-0.7439, -1.7919],
        [-1.3798, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09846733510494232
Epoch 0, Step 262: train/loss = 0.45846232771873474, train/raw-loss = 0.3658697307109833, train/logprobs = tensor([[-0.7823, -1.7931],
        [-1.7176, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09259258955717087
Epoch 0, Step 263: train/loss = 0.4896787405014038, train/raw-loss = 0.3954496383666992, train/logprobs = tensor([[-1.1739, -1.3090],
        [-2.4199, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942290648818016
Epoch 0, Step 264: train/loss = 0.5477637052536011, train/raw-loss = 0.4568946957588196, train/logprobs = tensor([[-1.0776, -2.5008],
        [-1.6429, -1.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09086901694536209
Epoch 0, Step 265: train/loss = 0.4743730127811432, train/raw-loss = 0.3619850277900696, train/logprobs = tensor([[-0.9593, -3.1778],
        [-1.8283, -1.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11238796263933182
Epoch 0, Step 266: train/loss = 0.6866262555122375, train/raw-loss = 0.5970271825790405, train/logprobs = tensor([[-1.3998, -1.7763],
        [-1.4696, -1.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895991399884224
Epoch 0, Step 267: train/loss = 0.5424056053161621, train/raw-loss = 0.4551146924495697, train/logprobs = tensor([[-0.7665, -1.3049],
        [-1.5216, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08729089051485062
Epoch 0, Step 268: train/loss = 0.6471443176269531, train/raw-loss = 0.5861436128616333, train/logprobs = tensor([[-0.9971, -1.8492],
        [-0.8520, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06100066378712654
Epoch 0, Step 269: train/loss = 0.6757209300994873, train/raw-loss = 0.6101864576339722, train/logprobs = tensor([[-0.6814, -1.1921],
        [-0.6638, -0.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06553448736667633
Epoch 0, Step 270: train/loss = 0.6264171600341797, train/raw-loss = 0.5580268502235413, train/logprobs = tensor([[-0.5867, -1.4202],
        [-0.5387, -0.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06839028000831604
Epoch 0, Step 271: train/loss = 0.6206573843955994, train/raw-loss = 0.5438606142997742, train/logprobs = tensor([[-0.8191, -1.6496],
        [-0.8378, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07679683715105057
Epoch 0, Step 272: train/loss = 0.5596950054168701, train/raw-loss = 0.4840683937072754, train/logprobs = tensor([[-0.7219, -1.8229],
        [-1.1787, -1.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562664896249771
Epoch 0, Step 273: train/loss = 0.5642876625061035, train/raw-loss = 0.45527270436286926, train/logprobs = tensor([[-0.8444, -1.3081],
        [-1.4920, -0.7009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10901495069265366
Epoch 0, Step 274: train/loss = 0.7005397081375122, train/raw-loss = 0.6125810146331787, train/logprobs = tensor([[-1.0481, -0.9948],
        [-1.4486, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08795866370201111
Epoch 0, Step 275: train/loss = 0.5562124252319336, train/raw-loss = 0.47898465394973755, train/logprobs = tensor([[-0.8480, -1.9225],
        [-1.1784, -1.0937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07722774893045425
Epoch 0, Step 276: train/loss = 0.5804955363273621, train/raw-loss = 0.5072426199913025, train/logprobs = tensor([[-0.9000, -1.4709],
        [-1.3836, -0.9615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07325291633605957
Epoch 0, Step 277: train/loss = 0.5337087512016296, train/raw-loss = 0.4458298683166504, train/logprobs = tensor([[-1.0667, -1.6392],
        [-1.6654, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08787889778614044
Epoch 0, Step 278: train/loss = 0.6708143353462219, train/raw-loss = 0.5906544327735901, train/logprobs = tensor([[-0.9028, -1.1980],
        [-1.0835, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08015991747379303
Epoch 0, Step 279: train/loss = 0.6278152465820312, train/raw-loss = 0.5393996238708496, train/logprobs = tensor([[-0.8813, -1.9462],
        [-1.1888, -1.3848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08841561526060104
Epoch 0, Step 280: train/loss = 0.687574565410614, train/raw-loss = 0.5962332487106323, train/logprobs = tensor([[-1.2340, -1.4368],
        [-1.0384, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09134125709533691
Epoch 0, Step 281: train/loss = 0.6507298946380615, train/raw-loss = 0.5594552755355835, train/logprobs = tensor([[-0.8330, -0.9224],
        [-1.2140, -0.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09127460420131683
Epoch 0, Step 282: train/loss = 0.6172260046005249, train/raw-loss = 0.5413128733634949, train/logprobs = tensor([[-1.1580, -2.0136],
        [-1.5944, -1.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591313123703003
Epoch 0, Step 283: train/loss = 0.6342470645904541, train/raw-loss = 0.5699292421340942, train/logprobs = tensor([[-0.7608, -1.2650],
        [-0.9822, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06431781500577927
Epoch 0, Step 284: train/loss = 0.5842748880386353, train/raw-loss = 0.49998700618743896, train/logprobs = tensor([[-1.1028, -1.6244],
        [-1.2813, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0842878594994545
Epoch 0, Step 285: train/loss = 0.6412454843521118, train/raw-loss = 0.552901029586792, train/logprobs = tensor([[-1.1336, -1.3319],
        [-1.5758, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08834446221590042
Epoch 0, Step 286: train/loss = 0.5142917037010193, train/raw-loss = 0.43750178813934326, train/logprobs = tensor([[-1.0384, -2.3892],
        [-1.3709, -1.2745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07678990066051483
Epoch 0, Step 287: train/loss = 0.6006600856781006, train/raw-loss = 0.5276561379432678, train/logprobs = tensor([[-1.7293, -2.9806],
        [-1.4972, -1.8000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07300398498773575
Epoch 0, Step 288: train/loss = 0.5617753267288208, train/raw-loss = 0.4852003753185272, train/logprobs = tensor([[-0.8666, -1.5846],
        [-1.2296, -0.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07657495141029358
Epoch 0, Step 289: train/loss = 0.5269646048545837, train/raw-loss = 0.4533942639827728, train/logprobs = tensor([[-0.7746, -1.6387],
        [-1.4150, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07357028871774673
Epoch 0, Step 290: train/loss = 0.6135963201522827, train/raw-loss = 0.5415169596672058, train/logprobs = tensor([[-0.9040, -1.3536],
        [-1.1192, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0720793604850769
Epoch 0, Step 291: train/loss = 0.593618631362915, train/raw-loss = 0.5263400077819824, train/logprobs = tensor([[-1.0878, -1.7196],
        [-1.2834, -1.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06727869063615799
Epoch 0, Step 292: train/loss = 0.616432249546051, train/raw-loss = 0.5411075949668884, train/logprobs = tensor([[-0.6681, -1.0362],
        [-0.9791, -0.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07532466948032379
Epoch 0, Step 293: train/loss = 0.5855666995048523, train/raw-loss = 0.4987722337245941, train/logprobs = tensor([[-0.8293, -2.0662],
        [-1.0205, -1.3022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08679448813199997
Epoch 0, Step 294: train/loss = 0.6686850190162659, train/raw-loss = 0.599577009677887, train/logprobs = tensor([[-0.7106, -0.9379],
        [-0.9579, -0.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06910798698663712
Epoch 0, Step 295: train/loss = 0.5567452907562256, train/raw-loss = 0.4678584337234497, train/logprobs = tensor([[-0.9506, -2.2057],
        [-1.6408, -1.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08888682723045349
Epoch 0, Step 296: train/loss = 0.5968387722969055, train/raw-loss = 0.49903422594070435, train/logprobs = tensor([[-1.0837, -1.5273],
        [-1.6890, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780450165271759
Epoch 0, Step 297: train/loss = 0.5443190336227417, train/raw-loss = 0.4521692395210266, train/logprobs = tensor([[-0.8505, -2.0364],
        [-1.1086, -0.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09214980900287628
Epoch 0, Step 298: train/loss = 0.5377599596977234, train/raw-loss = 0.4500183165073395, train/logprobs = tensor([[-0.8825, -1.6141],
        [-1.3725, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0877416580915451
Epoch 0, Step 299: train/loss = 0.6129710674285889, train/raw-loss = 0.5310093760490417, train/logprobs = tensor([[-1.0368, -1.3003],
        [-1.6431, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08196169137954712
Epoch 0, Step 300: train/loss = 0.4535025656223297, train/raw-loss = 0.3302246332168579, train/logprobs = tensor([[-1.1089, -2.3399],
        [-2.0175, -1.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12327791750431061
Epoch 0, Step 301: train/loss = 0.49600958824157715, train/raw-loss = 0.4095813035964966, train/logprobs = tensor([[-0.7933, -1.9468],
        [-1.1918, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08642827719449997
Epoch 0, Step 302: train/loss = 0.527408242225647, train/raw-loss = 0.4353065490722656, train/logprobs = tensor([[-1.5250, -2.0661],
        [-2.0531, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09210170805454254
Epoch 0, Step 303: train/loss = 0.6041423082351685, train/raw-loss = 0.5084130167961121, train/logprobs = tensor([[-0.5836, -1.1469],
        [-0.9039, -0.5914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09572934359312057
Epoch 0, Step 304: train/loss = 0.5755218267440796, train/raw-loss = 0.4777674973011017, train/logprobs = tensor([[-0.8855, -1.6581],
        [-1.3699, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977543443441391
Epoch 0, Step 305: train/loss = 0.634555995464325, train/raw-loss = 0.5691210031509399, train/logprobs = tensor([[-1.1212, -3.2941],
        [-1.1090, -2.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06543498486280441
Epoch 0, Step 306: train/loss = 0.6999905109405518, train/raw-loss = 0.6587258577346802, train/logprobs = tensor([[-0.4411, -0.6481],
        [-0.4587, -0.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04126466065645218
Epoch 0, Step 307: train/loss = 0.510938286781311, train/raw-loss = 0.4236937165260315, train/logprobs = tensor([[-0.8953, -1.6136],
        [-1.6154, -0.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08724458515644073
Epoch 0, Step 308: train/loss = 0.5984059572219849, train/raw-loss = 0.5308096408843994, train/logprobs = tensor([[-0.7200, -1.6401],
        [-1.0504, -1.1845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06759632378816605
Epoch 0, Step 309: train/loss = 0.6446903944015503, train/raw-loss = 0.5774573683738708, train/logprobs = tensor([[-0.7788, -1.3061],
        [-0.7617, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06723299622535706
Epoch 0, Step 310: train/loss = 0.5032827854156494, train/raw-loss = 0.4328485131263733, train/logprobs = tensor([[-1.3439, -4.3216],
        [-1.2816, -2.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07043422013521194
Epoch 0, Step 311: train/loss = 0.5727608799934387, train/raw-loss = 0.495076984167099, train/logprobs = tensor([[-1.4736, -1.8858],
        [-1.9096, -1.2543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07768388092517853
Epoch 0, Step 312: train/loss = 0.5073909759521484, train/raw-loss = 0.40949511528015137, train/logprobs = tensor([[-0.9874, -1.3570],
        [-1.8337, -0.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09789585322141647
Epoch 0, Step 313: train/loss = 0.5520974397659302, train/raw-loss = 0.47665655612945557, train/logprobs = tensor([[-0.9369, -1.8662],
        [-0.9942, -0.7604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07544088363647461
Epoch 0, Step 314: train/loss = 0.6602773666381836, train/raw-loss = 0.5886707305908203, train/logprobs = tensor([[-0.8452, -1.0732],
        [-1.1570, -0.9102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0716066062450409
Epoch 0, Step 315: train/loss = 0.5180992484092712, train/raw-loss = 0.4228211045265198, train/logprobs = tensor([[-0.9006, -2.2964],
        [-1.2645, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09527817368507385
Epoch 0, Step 316: train/loss = 0.6085192561149597, train/raw-loss = 0.5354557037353516, train/logprobs = tensor([[-0.8128, -1.4936],
        [-1.0828, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07306355983018875
Epoch 0, Step 317: train/loss = 0.5488734245300293, train/raw-loss = 0.47047317028045654, train/logprobs = tensor([[-1.0675, -2.2776],
        [-1.4924, -1.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840034365653992
Epoch 0, Step 318: train/loss = 0.5854947566986084, train/raw-loss = 0.5187584757804871, train/logprobs = tensor([[-0.4933, -1.4700],
        [-0.6130, -0.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06673623621463776
Epoch 0, Step 319: train/loss = 0.519532322883606, train/raw-loss = 0.40946894884109497, train/logprobs = tensor([[-1.0493, -1.6900],
        [-1.6431, -0.7655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11006336659193039
Epoch 0, Step 320: train/loss = 0.628969669342041, train/raw-loss = 0.5518578290939331, train/logprobs = tensor([[-1.1142, -1.3659],
        [-1.5762, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711183279752731
Epoch 0, Step 321: train/loss = 0.5844805240631104, train/raw-loss = 0.5148876309394836, train/logprobs = tensor([[-1.6469, -2.3019],
        [-2.1527, -1.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06959288567304611
Epoch 0, Step 322: train/loss = 0.6478046774864197, train/raw-loss = 0.5521562695503235, train/logprobs = tensor([[-0.8064, -1.2580],
        [-1.5365, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09564843773841858
Epoch 0, Step 323: train/loss = 0.5754287838935852, train/raw-loss = 0.48727989196777344, train/logprobs = tensor([[-0.9453, -1.1696],
        [-1.7278, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08814890682697296
Epoch 0, Step 324: train/loss = 0.4777053892612457, train/raw-loss = 0.39641791582107544, train/logprobs = tensor([[-0.9488, -2.0387],
        [-1.3978, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0812874436378479
Epoch 0, Step 325: train/loss = 0.46249574422836304, train/raw-loss = 0.36496472358703613, train/logprobs = tensor([[-1.0566, -2.0092],
        [-1.9350, -0.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09753105044364929
Epoch 0, Step 326: train/loss = 0.6359771490097046, train/raw-loss = 0.5465936660766602, train/logprobs = tensor([[-1.0847, -1.1732],
        [-1.5073, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08938344568014145
Epoch 0, Step 327: train/loss = 0.4943881034851074, train/raw-loss = 0.42034727334976196, train/logprobs = tensor([[-0.7912, -4.1699],
        [-0.8306, -2.5035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07404089719057083
Epoch 0, Step 328: train/loss = 0.5736462473869324, train/raw-loss = 0.5118355751037598, train/logprobs = tensor([[-0.6851, -1.7611],
        [-0.7172, -0.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0618106871843338
Epoch 0, Step 329: train/loss = 0.5674772262573242, train/raw-loss = 0.4704008102416992, train/logprobs = tensor([[-1.0724, -2.2425],
        [-2.1350, -1.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097076416015625
Epoch 0, Step 330: train/loss = 0.6325275301933289, train/raw-loss = 0.5556702613830566, train/logprobs = tensor([[-1.0722, -0.9648],
        [-1.4699, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07685727626085281
Epoch 0, Step 331: train/loss = 0.5874834656715393, train/raw-loss = 0.5030695199966431, train/logprobs = tensor([[-0.6445, -1.3496],
        [-1.0867, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08441394567489624
Epoch 0, Step 332: train/loss = 0.6175243258476257, train/raw-loss = 0.5189233422279358, train/logprobs = tensor([[-1.0387, -1.3882],
        [-1.8307, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09860096871852875
Epoch 0, Step 333: train/loss = 0.5298589468002319, train/raw-loss = 0.437123566865921, train/logprobs = tensor([[-0.9515, -2.1358],
        [-1.5184, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927353948354721
Epoch 0, Step 334: train/loss = 0.5613383054733276, train/raw-loss = 0.49276965856552124, train/logprobs = tensor([[-0.7584, -2.1891],
        [-0.9132, -1.1458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06856869161128998
Epoch 0, Step 335: train/loss = 0.5323224067687988, train/raw-loss = 0.4418817460536957, train/logprobs = tensor([[-0.8767, -2.2292],
        [-0.8677, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09044066071510315
Epoch 0, Step 336: train/loss = 0.5680147409439087, train/raw-loss = 0.4614509046077728, train/logprobs = tensor([[-0.9784, -1.8572],
        [-1.7410, -1.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656383633613586
Epoch 0, Step 337: train/loss = 0.5443813800811768, train/raw-loss = 0.4710038900375366, train/logprobs = tensor([[-0.7908, -1.3604],
        [-1.3830, -0.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07337751984596252
Epoch 0, Step 338: train/loss = 0.5080377459526062, train/raw-loss = 0.4034770131111145, train/logprobs = tensor([[-1.2110, -2.1951],
        [-1.7645, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1045607328414917
Epoch 0, Step 339: train/loss = 0.5046294331550598, train/raw-loss = 0.41453394293785095, train/logprobs = tensor([[-0.9630, -2.0618],
        [-1.6801, -1.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009546041488647
Epoch 0, Step 340: train/loss = 0.5623379349708557, train/raw-loss = 0.47879064083099365, train/logprobs = tensor([[-0.7605, -1.6257],
        [-1.1469, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08354730904102325
Epoch 0, Step 341: train/loss = 0.5236075520515442, train/raw-loss = 0.40828388929367065, train/logprobs = tensor([[-1.1617, -1.8006],
        [-2.4704, -1.2911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11532364785671234
Epoch 0, Step 342: train/loss = 0.5185471773147583, train/raw-loss = 0.41572752594947815, train/logprobs = tensor([[-1.0534, -1.8278],
        [-1.9259, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10281965136528015
Epoch 0, Step 343: train/loss = 0.6708216667175293, train/raw-loss = 0.6090836524963379, train/logprobs = tensor([[-0.6641, -1.3593],
        [-0.7518, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0617380253970623
Epoch 0, Step 344: train/loss = 0.5438575148582458, train/raw-loss = 0.45947322249412537, train/logprobs = tensor([[-1.0005, -2.0556],
        [-1.5592, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438431471586227
Epoch 0, Step 345: train/loss = 0.5721722841262817, train/raw-loss = 0.4987468421459198, train/logprobs = tensor([[-0.7146, -1.6531],
        [-0.7613, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07342541217803955
Epoch 0, Step 346: train/loss = 0.564233660697937, train/raw-loss = 0.4970409572124481, train/logprobs = tensor([[-1.0212, -2.7494],
        [-1.0886, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06719271838665009
Epoch 0, Step 347: train/loss = 0.5097483396530151, train/raw-loss = 0.41785934567451477, train/logprobs = tensor([[-0.8333, -2.4235],
        [-1.3967, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09188900142908096
Epoch 0, Step 348: train/loss = 0.40865135192871094, train/raw-loss = 0.3089640736579895, train/logprobs = tensor([[-0.6760, -3.0894],
        [-1.2369, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09968723356723785
Epoch 0, Step 349: train/loss = 0.66066575050354, train/raw-loss = 0.5979570150375366, train/logprobs = tensor([[-0.7269, -0.7411],
        [-1.0966, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0627087876200676
Epoch 0, Step 350: train/loss = 0.5694913864135742, train/raw-loss = 0.4895235300064087, train/logprobs = tensor([[-0.8515, -2.0118],
        [-1.2604, -1.3669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07996781915426254
Epoch 0, Step 351: train/loss = 0.6166473031044006, train/raw-loss = 0.5192986726760864, train/logprobs = tensor([[-1.1560, -1.0728],
        [-1.6030, -0.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09734867513179779
Epoch 0, Step 352: train/loss = 0.44325166940689087, train/raw-loss = 0.3260829746723175, train/logprobs = tensor([[-0.9855, -2.4221],
        [-2.0319, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716867238283157
Epoch 0, Step 353: train/loss = 0.46867674589157104, train/raw-loss = 0.3792738616466522, train/logprobs = tensor([[-1.0014, -2.0773],
        [-1.7562, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08940289169549942
Epoch 0, Step 354: train/loss = 0.5164498090744019, train/raw-loss = 0.41915589570999146, train/logprobs = tensor([[-1.1990, -2.0941],
        [-1.7328, -1.1430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09729386866092682
Epoch 0, Step 355: train/loss = 0.6650241613388062, train/raw-loss = 0.5815907716751099, train/logprobs = tensor([[-0.9503, -1.8912],
        [-1.4128, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08343342691659927
Epoch 0, Step 356: train/loss = 0.5783795118331909, train/raw-loss = 0.48803773522377014, train/logprobs = tensor([[-0.9218, -1.7269],
        [-1.2935, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09034180641174316
Epoch 0, Step 357: train/loss = 0.6721632480621338, train/raw-loss = 0.6126562356948853, train/logprobs = tensor([[-0.4800, -1.0928],
        [-0.5016, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05950702354311943
Epoch 0, Step 358: train/loss = 0.5014588236808777, train/raw-loss = 0.4235208034515381, train/logprobs = tensor([[-0.7604, -2.3124],
        [-1.0991, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077938012778759
Epoch 0, Step 359: train/loss = 0.6103737950325012, train/raw-loss = 0.5279862284660339, train/logprobs = tensor([[-0.7921, -1.7622],
        [-1.3507, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08238759636878967
Epoch 0, Step 360: train/loss = 0.5700632333755493, train/raw-loss = 0.5065476894378662, train/logprobs = tensor([[-0.7657, -1.9193],
        [-0.8607, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06351552158594131
Epoch 0, Step 361: train/loss = 0.5081671476364136, train/raw-loss = 0.4200690686702728, train/logprobs = tensor([[-0.7826, -2.1069],
        [-1.1952, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08809804916381836
Epoch 0, Step 362: train/loss = 0.5965308547019958, train/raw-loss = 0.5122841596603394, train/logprobs = tensor([[-0.7320, -1.6021],
        [-1.2104, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08424670249223709
Epoch 0, Step 363: train/loss = 0.47380074858665466, train/raw-loss = 0.3637668192386627, train/logprobs = tensor([[-1.3320, -1.7152],
        [-2.3916, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003394424915314
Epoch 0, Step 364: train/loss = 0.5197706818580627, train/raw-loss = 0.4510052502155304, train/logprobs = tensor([[-0.6530, -2.0563],
        [-1.2153, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876544654369354
Epoch 0, Step 365: train/loss = 0.5170614719390869, train/raw-loss = 0.39848044514656067, train/logprobs = tensor([[-0.9346, -1.6750],
        [-1.8673, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11858095973730087
Epoch 0, Step 366: train/loss = 0.5004110932350159, train/raw-loss = 0.4089815616607666, train/logprobs = tensor([[-1.2695, -1.5148],
        [-2.0147, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09142953157424927
Epoch 0, Step 367: train/loss = 0.5029275417327881, train/raw-loss = 0.4227105975151062, train/logprobs = tensor([[-0.9479, -2.8497],
        [-1.6756, -1.5135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08021698892116547
Epoch 0, Step 368: train/loss = 0.4541265368461609, train/raw-loss = 0.3666483163833618, train/logprobs = tensor([[-1.0038, -2.2665],
        [-1.5415, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08747825026512146
Epoch 0, Step 369: train/loss = 0.3792155086994171, train/raw-loss = 0.2869356870651245, train/logprobs = tensor([[-1.2092, -3.0991],
        [-2.1776, -1.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227980673313141
Epoch 0, Step 370: train/loss = 0.5300349593162537, train/raw-loss = 0.45064038038253784, train/logprobs = tensor([[-1.0623, -2.5549],
        [-1.3636, -1.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07939453423023224
Epoch 0, Step 371: train/loss = 0.6752979159355164, train/raw-loss = 0.614168643951416, train/logprobs = tensor([[-0.6466, -0.9855],
        [-0.7770, -0.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06112932413816452
Epoch 0, Step 372: train/loss = 0.6119090914726257, train/raw-loss = 0.541625440120697, train/logprobs = tensor([[-1.7581, -2.8922],
        [-2.2231, -2.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0702836662530899
Epoch 0, Step 373: train/loss = 0.5038539171218872, train/raw-loss = 0.41034942865371704, train/logprobs = tensor([[-0.9777, -1.4974],
        [-2.0478, -0.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350451081991196
Epoch 0, Step 374: train/loss = 0.5304491519927979, train/raw-loss = 0.4624798893928528, train/logprobs = tensor([[-0.9183, -1.2883],
        [-1.3388, -0.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06796926259994507
Epoch 0, Step 375: train/loss = 0.7048851847648621, train/raw-loss = 0.6430713534355164, train/logprobs = tensor([[-0.6658, -0.7823],
        [-0.7235, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061813823878765106
Epoch 0, Step 376: train/loss = 0.6281689405441284, train/raw-loss = 0.5474520921707153, train/logprobs = tensor([[-1.5535, -1.3471],
        [-2.0091, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08071690052747726
Epoch 0, Step 377: train/loss = 0.5583736300468445, train/raw-loss = 0.4927230775356293, train/logprobs = tensor([[-0.4723, -2.3272],
        [-0.5790, -1.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06565055251121521
Epoch 0, Step 378: train/loss = 0.536959707736969, train/raw-loss = 0.4352818429470062, train/logprobs = tensor([[-0.8509, -1.3201],
        [-1.6441, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10167783498764038
Epoch 0, Step 379: train/loss = 0.5376487970352173, train/raw-loss = 0.4526270031929016, train/logprobs = tensor([[-1.3024, -2.4275],
        [-1.4318, -1.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502180874347687
Epoch 0, Step 380: train/loss = 0.5012025237083435, train/raw-loss = 0.4272931218147278, train/logprobs = tensor([[-1.1745, -2.3202],
        [-1.8425, -1.0999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390940189361572
Epoch 0, Step 381: train/loss = 0.4536800682544708, train/raw-loss = 0.36631011962890625, train/logprobs = tensor([[-0.9412, -1.7551],
        [-1.8558, -0.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08736994117498398
Epoch 0, Step 382: train/loss = 0.6094522476196289, train/raw-loss = 0.5203120708465576, train/logprobs = tensor([[-0.7589, -0.9253],
        [-1.5158, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08914017677307129
Epoch 0, Step 383: train/loss = 0.5530513525009155, train/raw-loss = 0.4523047208786011, train/logprobs = tensor([[-1.0910, -1.4908],
        [-2.1591, -1.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10074661672115326
Epoch 0, Step 384: train/loss = 0.46357375383377075, train/raw-loss = 0.38410893082618713, train/logprobs = tensor([[-0.7417, -2.8660],
        [-0.9092, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07946483790874481
Epoch 0, Step 385: train/loss = 0.382682204246521, train/raw-loss = 0.27440404891967773, train/logprobs = tensor([[-1.5912, -2.5775],
        [-3.2658, -1.4753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10827817022800446
Epoch 0, Step 386: train/loss = 0.6808174252510071, train/raw-loss = 0.6128076314926147, train/logprobs = tensor([[-1.7264, -1.6514],
        [-2.3399, -1.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06800977140665054
Epoch 0, Step 387: train/loss = 0.3563532829284668, train/raw-loss = 0.2744792401790619, train/logprobs = tensor([[-0.9891, -3.5587],
        [-1.4914, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818740576505661
Epoch 0, Step 388: train/loss = 0.5521697998046875, train/raw-loss = 0.48586028814315796, train/logprobs = tensor([[-0.6906, -2.1464],
        [-0.8513, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06630945205688477
Epoch 0, Step 389: train/loss = 0.47246623039245605, train/raw-loss = 0.38867834210395813, train/logprobs = tensor([[-1.1660, -3.0330],
        [-1.6854, -1.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08378787338733673
Epoch 0, Step 390: train/loss = 0.5648710131645203, train/raw-loss = 0.4844803214073181, train/logprobs = tensor([[-0.7927, -1.5120],
        [-1.1933, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08039071410894394
Epoch 0, Step 391: train/loss = 0.5508576035499573, train/raw-loss = 0.4829045534133911, train/logprobs = tensor([[-0.7015, -1.3317],
        [-1.1084, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06795307993888855
Epoch 0, Step 392: train/loss = 0.38703805208206177, train/raw-loss = 0.271124005317688, train/logprobs = tensor([[-1.6013, -2.3632],
        [-3.0633, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11591404676437378
Epoch 0, Step 393: train/loss = 0.5738346576690674, train/raw-loss = 0.4970807135105133, train/logprobs = tensor([[-1.0455, -2.7294],
        [-1.2399, -1.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675399631261826
Epoch 0, Step 394: train/loss = 0.5043281316757202, train/raw-loss = 0.4225436747074127, train/logprobs = tensor([[-0.7949, -2.5131],
        [-1.3030, -1.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817844495177269
Epoch 0, Step 395: train/loss = 0.5047401785850525, train/raw-loss = 0.4200262129306793, train/logprobs = tensor([[-0.9910, -1.6317],
        [-1.8566, -0.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08471391350030899
Epoch 0, Step 396: train/loss = 0.5649154186248779, train/raw-loss = 0.4828456938266754, train/logprobs = tensor([[-1.0758, -3.0088],
        [-1.1695, -1.5290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206973969936371
Epoch 0, Step 397: train/loss = 0.570313036441803, train/raw-loss = 0.4746933579444885, train/logprobs = tensor([[-1.2731, -1.0573],
        [-2.1423, -0.6697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09561970084905624
Epoch 0, Step 398: train/loss = 0.3759165406227112, train/raw-loss = 0.2695337235927582, train/logprobs = tensor([[-0.9684, -2.3592],
        [-2.0050, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1063828319311142
Epoch 0, Step 399: train/loss = 0.573167085647583, train/raw-loss = 0.48300328850746155, train/logprobs = tensor([[-1.0161, -2.1014],
        [-1.4830, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09016382694244385
Epoch 0, Step 400: train/loss = 0.5394229888916016, train/raw-loss = 0.45789438486099243, train/logprobs = tensor([[-1.2002, -2.7655],
        [-1.5201, -1.7513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152864128351212
Epoch 0, Step 401: train/loss = 0.528810977935791, train/raw-loss = 0.45299991965293884, train/logprobs = tensor([[-1.2943, -2.6121],
        [-1.6893, -1.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07581107318401337
Epoch 0, Step 402: train/loss = 0.5749104619026184, train/raw-loss = 0.5036087036132812, train/logprobs = tensor([[-0.9617, -1.5582],
        [-1.2152, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07130180299282074
Epoch 0, Step 403: train/loss = 0.4665573835372925, train/raw-loss = 0.36847245693206787, train/logprobs = tensor([[-0.9487, -1.4991],
        [-2.2511, -0.9276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980849340558052
Epoch 0, Step 404: train/loss = 0.40372753143310547, train/raw-loss = 0.29904019832611084, train/logprobs = tensor([[-1.3676, -1.6593],
        [-2.8289, -0.6810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468737035989761
Epoch 0, Step 405: train/loss = 0.5509994029998779, train/raw-loss = 0.46729108691215515, train/logprobs = tensor([[-0.8414, -1.6997],
        [-1.3635, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08370830863714218
Epoch 0, Step 406: train/loss = 0.5040588974952698, train/raw-loss = 0.40516477823257446, train/logprobs = tensor([[-1.3590, -1.5572],
        [-2.4245, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0988941565155983
Epoch 0, Step 407: train/loss = 0.5632607936859131, train/raw-loss = 0.46848028898239136, train/logprobs = tensor([[-0.7017, -1.7335],
        [-1.1648, -0.9382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09478051960468292
Epoch 0, Step 408: train/loss = 0.6889233589172363, train/raw-loss = 0.6101261377334595, train/logprobs = tensor([[-0.7276, -1.0899],
        [-0.8261, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07879726588726044
Epoch 0, Step 409: train/loss = 0.5447737574577332, train/raw-loss = 0.46677353978157043, train/logprobs = tensor([[-0.9901, -2.1564],
        [-1.1991, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07800018042325974
Epoch 0, Step 410: train/loss = 0.5207449197769165, train/raw-loss = 0.44479212164878845, train/logprobs = tensor([[-1.7425, -2.8508],
        [-2.0767, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07595281302928925
Epoch 0, Step 411: train/loss = 0.5397678017616272, train/raw-loss = 0.44471168518066406, train/logprobs = tensor([[-0.9696, -1.8032],
        [-1.4314, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09505614638328552
Epoch 0, Step 412: train/loss = 0.5750526785850525, train/raw-loss = 0.5118399858474731, train/logprobs = tensor([[-1.0512, -2.4613],
        [-1.2695, -1.3951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06321268528699875
Epoch 0, Step 413: train/loss = 0.518638014793396, train/raw-loss = 0.4136001169681549, train/logprobs = tensor([[-1.0918, -1.5593],
        [-1.8204, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10503785312175751
Epoch 0, Step 414: train/loss = 0.5441150665283203, train/raw-loss = 0.47247764468193054, train/logprobs = tensor([[-0.7268, -2.0104],
        [-0.7348, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07163742184638977
Epoch 0, Step 415: train/loss = 0.4209384322166443, train/raw-loss = 0.33269721269607544, train/logprobs = tensor([[-0.7793, -2.8876],
        [-1.1996, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08824123442173004
Epoch 0, Step 416: train/loss = 0.4783361554145813, train/raw-loss = 0.38375627994537354, train/logprobs = tensor([[-0.9934, -2.4950],
        [-2.0713, -1.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09457989782094955
Epoch 0, Step 417: train/loss = 0.7395598888397217, train/raw-loss = 0.6615821719169617, train/logprobs = tensor([[-1.4182, -0.9663],
        [-1.2858, -0.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07797776162624359
Epoch 0, Step 418: train/loss = 0.47926458716392517, train/raw-loss = 0.3663705885410309, train/logprobs = tensor([[-1.2838, -2.5996],
        [-2.1510, -1.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11289401352405548
Epoch 0, Step 419: train/loss = 0.3927943706512451, train/raw-loss = 0.27341410517692566, train/logprobs = tensor([[-1.0537, -2.6161],
        [-2.1588, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11938025802373886
Epoch 0, Step 420: train/loss = 0.5274446606636047, train/raw-loss = 0.44237250089645386, train/logprobs = tensor([[-0.6099, -1.4435],
        [-1.5927, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08507215231657028
Epoch 0, Step 421: train/loss = 0.4521501064300537, train/raw-loss = 0.36595049500465393, train/logprobs = tensor([[-0.8365, -3.0882],
        [-1.0541, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08619960397481918
Epoch 0, Step 422: train/loss = 0.5421040058135986, train/raw-loss = 0.444214403629303, train/logprobs = tensor([[-0.6249, -2.4045],
        [-0.6683, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09788965433835983
Epoch 0, Step 423: train/loss = 0.407396137714386, train/raw-loss = 0.2961229681968689, train/logprobs = tensor([[-1.7306, -1.5042],
        [-3.4990, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127319186925888
Epoch 0, Step 424: train/loss = 0.3674980401992798, train/raw-loss = 0.2562865614891052, train/logprobs = tensor([[-0.8643, -3.3835],
        [-1.3945, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11121149361133575
Epoch 0, Step 425: train/loss = 0.5442137718200684, train/raw-loss = 0.4604951739311218, train/logprobs = tensor([[-1.2456, -2.9404],
        [-1.1047, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371856808662415
Epoch 0, Step 426: train/loss = 0.5616950392723083, train/raw-loss = 0.44137340784072876, train/logprobs = tensor([[-0.8797, -1.6020],
        [-1.7878, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12032162398099899
Epoch 0, Step 427: train/loss = 0.44541963934898376, train/raw-loss = 0.32889607548713684, train/logprobs = tensor([[-1.4097, -1.9628],
        [-2.4171, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11652355641126633
Epoch 0, Step 428: train/loss = 0.6584566831588745, train/raw-loss = 0.5673460960388184, train/logprobs = tensor([[-0.7888, -0.8154],
        [-1.5512, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111064672470093
Epoch 0, Step 429: train/loss = 0.501235842704773, train/raw-loss = 0.42685699462890625, train/logprobs = tensor([[-0.5250, -2.3764],
        [-0.6684, -0.6996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743788480758667
Epoch 0, Step 430: train/loss = 0.48156076669692993, train/raw-loss = 0.3780534565448761, train/logprobs = tensor([[-1.2439, -1.3400],
        [-2.5518, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350729525089264
Epoch 0, Step 431: train/loss = 0.5829935669898987, train/raw-loss = 0.4884754419326782, train/logprobs = tensor([[-0.8042, -1.9426],
        [-1.1586, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451818466186523
Epoch 0, Step 432: train/loss = 0.4741712510585785, train/raw-loss = 0.3793705105781555, train/logprobs = tensor([[-0.6378, -2.3021],
        [-1.4463, -0.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09480075538158417
Epoch 0, Step 433: train/loss = 0.5155993700027466, train/raw-loss = 0.41123166680336, train/logprobs = tensor([[-1.0220, -1.6817],
        [-2.0369, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436767339706421
Epoch 0, Step 434: train/loss = 0.690514326095581, train/raw-loss = 0.5696900486946106, train/logprobs = tensor([[-0.6440, -2.0363],
        [-1.7664, -1.5428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12082423269748688
Epoch 0, Step 435: train/loss = 0.4600573778152466, train/raw-loss = 0.34452024102211, train/logprobs = tensor([[-1.3152, -2.2862],
        [-2.1674, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11553715169429779
Epoch 0, Step 436: train/loss = 0.6058768033981323, train/raw-loss = 0.5020304322242737, train/logprobs = tensor([[-0.9873, -2.2444],
        [-1.4013, -1.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10384638607501984
Epoch 0, Step 437: train/loss = 0.5490940809249878, train/raw-loss = 0.47501713037490845, train/logprobs = tensor([[-0.8809, -2.0284],
        [-0.7909, -0.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07407699525356293
Epoch 0, Step 438: train/loss = 0.5140179395675659, train/raw-loss = 0.43405917286872864, train/logprobs = tensor([[-0.9750, -1.4123],
        [-1.7646, -0.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07995881885290146
Epoch 0, Step 439: train/loss = 0.4512469470500946, train/raw-loss = 0.3577638566493988, train/logprobs = tensor([[-0.8023, -2.0923],
        [-1.4761, -0.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09348304569721222
Epoch 0, Step 440: train/loss = 0.6187454462051392, train/raw-loss = 0.5366926789283752, train/logprobs = tensor([[-0.8470, -1.5181],
        [-1.1675, -0.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08205273002386093
Epoch 0, Step 441: train/loss = 0.574275553226471, train/raw-loss = 0.4792955219745636, train/logprobs = tensor([[-1.2039, -2.8118],
        [-2.2846, -1.6866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09498003125190735
Epoch 0, Step 442: train/loss = 0.3726600408554077, train/raw-loss = 0.2744414210319519, train/logprobs = tensor([[-1.5069, -3.9663],
        [-2.0749, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09821859002113342
Epoch 0, Step 443: train/loss = 0.6114542484283447, train/raw-loss = 0.5307693481445312, train/logprobs = tensor([[-1.0557, -1.9029],
        [-0.9533, -0.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08068493753671646
Epoch 0, Step 444: train/loss = 0.5346429944038391, train/raw-loss = 0.4465992748737335, train/logprobs = tensor([[-1.8173, -2.8037],
        [-2.2723, -1.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08804372698068619
Epoch 0, Step 445: train/loss = 0.5132368803024292, train/raw-loss = 0.41517066955566406, train/logprobs = tensor([[-1.0683, -2.5460],
        [-1.4816, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09806619584560394
Epoch 0, Step 446: train/loss = 0.6598370671272278, train/raw-loss = 0.5805703401565552, train/logprobs = tensor([[-0.8441, -1.4680],
        [-0.9265, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0792667418718338
Epoch 0, Step 447: train/loss = 0.38019657135009766, train/raw-loss = 0.2648077607154846, train/logprobs = tensor([[-0.9690, -2.7589],
        [-2.1918, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538884788751602
Epoch 0, Step 448: train/loss = 0.4184080958366394, train/raw-loss = 0.3017592430114746, train/logprobs = tensor([[-0.6983, -2.5382],
        [-1.3919, -0.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664888262748718
Epoch 0, Step 449: train/loss = 0.4428020119667053, train/raw-loss = 0.3208622932434082, train/logprobs = tensor([[-1.2512, -3.4477],
        [-2.7695, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12193969637155533
Epoch 0, Step 450: train/loss = 0.4663776159286499, train/raw-loss = 0.35778340697288513, train/logprobs = tensor([[-0.8252, -3.2174],
        [-1.1152, -0.7074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10859423130750656
Epoch 0, Step 451: train/loss = 0.6482703685760498, train/raw-loss = 0.5547311305999756, train/logprobs = tensor([[-0.6454, -2.5208],
        [-0.9736, -1.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09353920817375183
Epoch 0, Step 452: train/loss = 0.38815557956695557, train/raw-loss = 0.2648502588272095, train/logprobs = tensor([[-1.3717, -3.1363],
        [-2.5138, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1233053207397461
Epoch 0, Step 453: train/loss = 0.44817182421684265, train/raw-loss = 0.315859854221344, train/logprobs = tensor([[-0.9311, -2.7417],
        [-1.9821, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13231195509433746
Epoch 0, Step 454: train/loss = 0.4690084457397461, train/raw-loss = 0.34306567907333374, train/logprobs = tensor([[-1.3790, -3.0969],
        [-2.5726, -1.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12594279646873474
Epoch 0, Step 455: train/loss = 0.8245991468429565, train/raw-loss = 0.7151552438735962, train/logprobs = tensor([[-1.1076, -2.6440],
        [-1.7676, -2.1927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1094440147280693
Epoch 0, Step 456: train/loss = 0.501772940158844, train/raw-loss = 0.410174697637558, train/logprobs = tensor([[-0.8058, -2.5881],
        [-1.6293, -1.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0915982723236084
Epoch 0, Step 457: train/loss = 0.5792965888977051, train/raw-loss = 0.4865255057811737, train/logprobs = tensor([[-0.8361, -2.6282],
        [-1.0932, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277108311653137
Epoch 0, Step 458: train/loss = 0.23935867846012115, train/raw-loss = 0.10576273500919342, train/logprobs = tensor([[-1.3370, -5.4138],
        [-3.4609, -1.0699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13359594345092773
Epoch 0, Step 459: train/loss = 0.5378268957138062, train/raw-loss = 0.4239721894264221, train/logprobs = tensor([[-0.9611, -2.5927],
        [-1.6489, -0.8769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11385470628738403
Epoch 0, Step 460: train/loss = 0.43887096643447876, train/raw-loss = 0.3293641209602356, train/logprobs = tensor([[-1.0725, -3.2288],
        [-1.5841, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10950683057308197
Epoch 0, Step 461: train/loss = 0.3240761160850525, train/raw-loss = 0.19397717714309692, train/logprobs = tensor([[-1.1037, -3.8555],
        [-2.0967, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13009893894195557
Epoch 0, Step 462: train/loss = 0.48393815755844116, train/raw-loss = 0.38757002353668213, train/logprobs = tensor([[-0.8050, -2.3644],
        [-1.3799, -0.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09636813402175903
Epoch 0, Step 463: train/loss = 0.47255319356918335, train/raw-loss = 0.3801085650920868, train/logprobs = tensor([[-0.6416, -2.0206],
        [-1.2710, -0.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09244462847709656
Epoch 0, Step 464: train/loss = 0.6326403617858887, train/raw-loss = 0.5545176267623901, train/logprobs = tensor([[-0.8351, -0.9645],
        [-1.5903, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07812271267175674
Epoch 0, Step 465: train/loss = 0.5297344923019409, train/raw-loss = 0.4437439441680908, train/logprobs = tensor([[-0.8690, -2.7700],
        [-0.9647, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08599059283733368
Epoch 0, Step 466: train/loss = 0.4412216246128082, train/raw-loss = 0.3408358097076416, train/logprobs = tensor([[-0.6873, -2.7437],
        [-1.5554, -0.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10038581490516663
Epoch 0, Step 467: train/loss = 0.47871047258377075, train/raw-loss = 0.3634282648563385, train/logprobs = tensor([[-1.6300, -2.3309],
        [-2.8085, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11528217792510986
Epoch 0, Step 468: train/loss = 0.45917797088623047, train/raw-loss = 0.34700798988342285, train/logprobs = tensor([[-0.8551, -2.5705],
        [-1.8666, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11216998845338821
Epoch 0, Step 469: train/loss = 0.5118957161903381, train/raw-loss = 0.42157548666000366, train/logprobs = tensor([[-0.7216, -3.5475],
        [-0.8071, -1.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09032023698091507
Epoch 0, Step 470: train/loss = 0.5044775605201721, train/raw-loss = 0.40620359778404236, train/logprobs = tensor([[-0.8947, -3.3345],
        [-0.8845, -1.0411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827396273612976
Epoch 0, Step 471: train/loss = 0.5647242665290833, train/raw-loss = 0.4627198576927185, train/logprobs = tensor([[-1.2933, -2.0912],
        [-2.3524, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10200439393520355
Epoch 0, Step 472: train/loss = 0.428608238697052, train/raw-loss = 0.30852997303009033, train/logprobs = tensor([[-0.9904, -3.0755],
        [-2.0470, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12007831037044525
Epoch 0, Step 473: train/loss = 0.5515803694725037, train/raw-loss = 0.4328722655773163, train/logprobs = tensor([[-1.3640, -2.0906],
        [-2.2636, -1.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11870811879634857
Epoch 0, Step 474: train/loss = 0.6596180200576782, train/raw-loss = 0.5520638227462769, train/logprobs = tensor([[-1.2427, -2.3389],
        [-1.6671, -1.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10755416750907898
Epoch 0, Step 475: train/loss = 0.4332656264305115, train/raw-loss = 0.3260231018066406, train/logprobs = tensor([[-0.9724, -2.9819],
        [-2.0444, -1.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10724252462387085
Epoch 0, Step 476: train/loss = 0.4672747850418091, train/raw-loss = 0.3782538175582886, train/logprobs = tensor([[-0.5846, -2.2200],
        [-1.2608, -0.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0890209972858429
Epoch 0, Step 477: train/loss = 0.27603721618652344, train/raw-loss = 0.12216095626354218, train/logprobs = tensor([[-1.2642, -4.1960],
        [-3.7131, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15387624502182007
Epoch 0, Step 478: train/loss = 0.4372381269931793, train/raw-loss = 0.32334351539611816, train/logprobs = tensor([[-1.0989, -2.9206],
        [-2.3204, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11389461904764175
Epoch 0, Step 479: train/loss = 0.5599698424339294, train/raw-loss = 0.45742499828338623, train/logprobs = tensor([[-0.8353, -2.0669],
        [-0.9486, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10254484415054321
Epoch 0, Step 480: train/loss = 0.5586721301078796, train/raw-loss = 0.4612709581851959, train/logprobs = tensor([[-0.5430, -2.8618],
        [-0.7464, -1.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0974011942744255
Epoch 0, Step 481: train/loss = 0.35825687646865845, train/raw-loss = 0.231024831533432, train/logprobs = tensor([[-1.0189, -3.3366],
        [-2.4418, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12723205983638763
Epoch 0, Step 482: train/loss = 0.5604289770126343, train/raw-loss = 0.4332432150840759, train/logprobs = tensor([[-1.4203, -2.7812],
        [-1.9753, -1.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12718580663204193
Epoch 0, Step 483: train/loss = 0.3187877833843231, train/raw-loss = 0.17598988115787506, train/logprobs = tensor([[-0.7551, -3.8827],
        [-2.0062, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14279791712760925
Epoch 0, Step 484: train/loss = 0.5444478392601013, train/raw-loss = 0.4347936809062958, train/logprobs = tensor([[-0.7488, -2.4510],
        [-1.0335, -0.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10965416580438614
Epoch 0, Step 485: train/loss = 0.4682440161705017, train/raw-loss = 0.3445720076560974, train/logprobs = tensor([[-0.7035, -3.2919],
        [-1.1635, -1.6362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12367205321788788
Epoch 0, Step 486: train/loss = 0.5456258058547974, train/raw-loss = 0.42458850145339966, train/logprobs = tensor([[-0.6679, -2.8113],
        [-0.9318, -0.6818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12103728204965591
Epoch 0, Step 487: train/loss = 0.620293378829956, train/raw-loss = 0.5151553153991699, train/logprobs = tensor([[-0.7723, -1.6396],
        [-1.0013, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10513811558485031
Epoch 0, Step 488: train/loss = 0.4886351227760315, train/raw-loss = 0.38933849334716797, train/logprobs = tensor([[-1.0509, -3.0111],
        [-1.3589, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09929660707712173
Epoch 0, Step 489: train/loss = 0.5209444165229797, train/raw-loss = 0.3707207441329956, train/logprobs = tensor([[-0.8827, -2.2738],
        [-1.9389, -1.1344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15022367238998413
Epoch 0, Step 490: train/loss = 0.4896983504295349, train/raw-loss = 0.3725177049636841, train/logprobs = tensor([[-0.5889, -4.1035],
        [-0.7745, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11718066036701202
Epoch 0, Step 491: train/loss = 0.7902817726135254, train/raw-loss = 0.6905502080917358, train/logprobs = tensor([[-0.8251, -2.5697],
        [-1.3653, -2.3480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09973153471946716
Epoch 0, Step 492: train/loss = 0.39828842878341675, train/raw-loss = 0.28964805603027344, train/logprobs = tensor([[-1.2945, -4.9477],
        [-1.4697, -0.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10864035785198212
Epoch 0, Step 493: train/loss = 0.5878176689147949, train/raw-loss = 0.4460986256599426, train/logprobs = tensor([[-1.2336, -2.4741],
        [-1.8387, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417190432548523
Epoch 0, Step 494: train/loss = 0.3390611708164215, train/raw-loss = 0.1901925653219223, train/logprobs = tensor([[-1.2519, -3.4069],
        [-2.8770, -0.7377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488686203956604
Epoch 0, Step 495: train/loss = 0.4987148940563202, train/raw-loss = 0.3616264760494232, train/logprobs = tensor([[-1.0168, -1.8639],
        [-1.9434, -0.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13708844780921936
Epoch 0, Step 496: train/loss = 0.336775541305542, train/raw-loss = 0.18156030774116516, train/logprobs = tensor([[-0.8762, -4.1292],
        [-2.4920, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15521523356437683
Epoch 0, Step 497: train/loss = 0.5660310387611389, train/raw-loss = 0.43323373794555664, train/logprobs = tensor([[-0.6758, -1.3956],
        [-1.4504, -0.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327972710132599
Epoch 0, Step 498: train/loss = 0.4474296569824219, train/raw-loss = 0.32497888803482056, train/logprobs = tensor([[-0.6619, -2.6857],
        [-1.5200, -0.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12245076894760132
Epoch 0, Step 499: train/loss = 0.4620894193649292, train/raw-loss = 0.3546885848045349, train/logprobs = tensor([[-0.6539, -2.9005],
        [-1.0480, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074008047580719
Loss is nan
eval/loss: 0.49947357177734375
Epoch 0, Step 500: train/loss = 0.536980152130127, train/raw-loss = 0.4019082486629486, train/logprobs = tensor([[-0.8341, -1.8961],
        [-1.7638, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13507190346717834
Epoch 0, Step 501: train/loss = 0.4355041980743408, train/raw-loss = 0.31104475259780884, train/logprobs = tensor([[-1.0637, -3.5878],
        [-1.5112, -0.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1244594156742096
Epoch 0, Step 502: train/loss = 0.4957941770553589, train/raw-loss = 0.35084402561187744, train/logprobs = tensor([[-1.0619, -2.5724],
        [-2.1818, -0.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14495016634464264
Epoch 0, Step 503: train/loss = 0.31179189682006836, train/raw-loss = 0.1413925290107727, train/logprobs = tensor([[-1.0049, -3.8470],
        [-2.7627, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17039938271045685
Epoch 0, Step 504: train/loss = 0.41364729404449463, train/raw-loss = 0.259532630443573, train/logprobs = tensor([[-0.9093, -2.6280],
        [-2.4480, -0.7115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15411469340324402
Epoch 0, Step 505: train/loss = 0.4686189889907837, train/raw-loss = 0.3407124876976013, train/logprobs = tensor([[-0.8437, -2.8758],
        [-1.5087, -0.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12790653109550476
Epoch 0, Step 506: train/loss = 0.44036349654197693, train/raw-loss = 0.3065311312675476, train/logprobs = tensor([[-0.9639, -3.2336],
        [-2.0377, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13383233547210693
Epoch 0, Step 507: train/loss = 0.33843302726745605, train/raw-loss = 0.18092411756515503, train/logprobs = tensor([[-0.7310, -3.7166],
        [-2.1139, -0.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15750892460346222
Epoch 0, Step 508: train/loss = 0.5962241888046265, train/raw-loss = 0.4754061698913574, train/logprobs = tensor([[-0.9457, -2.7883],
        [-0.9602, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12081804871559143
Epoch 0, Step 509: train/loss = 0.36455661058425903, train/raw-loss = 0.22362515330314636, train/logprobs = tensor([[-0.6780, -3.9748],
        [-1.5502, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14093142747879028
Epoch 0, Step 510: train/loss = 0.4177996814250946, train/raw-loss = 0.3047316372394562, train/logprobs = tensor([[-0.7120, -4.6137],
        [-0.7474, -0.7575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11306804418563843
Epoch 0, Step 511: train/loss = 0.43384698033332825, train/raw-loss = 0.3245977759361267, train/logprobs = tensor([[-1.4453, -3.2510],
        [-2.7148, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10924921929836273
Epoch 0, Step 512: train/loss = 0.514911413192749, train/raw-loss = 0.4020264148712158, train/logprobs = tensor([[-0.8682, -3.1735],
        [-1.0676, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1128849983215332
Epoch 0, Step 513: train/loss = 0.49469590187072754, train/raw-loss = 0.37688979506492615, train/logprobs = tensor([[-1.0178, -2.8973],
        [-1.8955, -0.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11780610680580139
Epoch 0, Step 514: train/loss = 0.43580520153045654, train/raw-loss = 0.2993881106376648, train/logprobs = tensor([[-1.2292, -3.1146],
        [-2.4231, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13641704618930817
Epoch 0, Step 515: train/loss = 0.3244270384311676, train/raw-loss = 0.14376306533813477, train/logprobs = tensor([[-1.0015, -4.5114],
        [-2.4531, -0.7200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18066397309303284
Epoch 0, Step 516: train/loss = 0.4667644500732422, train/raw-loss = 0.32936039566993713, train/logprobs = tensor([[-0.6737, -2.9861],
        [-1.4139, -0.6170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13740408420562744
Epoch 0, Step 517: train/loss = 0.6917668581008911, train/raw-loss = 0.5888148546218872, train/logprobs = tensor([[-0.5601, -1.7755],
        [-0.5967, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295197367668152
Epoch 0, Step 518: train/loss = 0.5308717489242554, train/raw-loss = 0.43097034096717834, train/logprobs = tensor([[-0.9777, -4.4448],
        [-1.2117, -2.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09990139305591583
Epoch 0, Step 519: train/loss = 0.5254263281822205, train/raw-loss = 0.3784368634223938, train/logprobs = tensor([[-0.8627, -3.3187],
        [-1.1769, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14698949456214905
Epoch 0, Step 520: train/loss = 0.3759981691837311, train/raw-loss = 0.2128176987171173, train/logprobs = tensor([[-0.9804, -5.4224],
        [-1.4602, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16318047046661377
Epoch 0, Step 521: train/loss = 0.5302724242210388, train/raw-loss = 0.3859107196331024, train/logprobs = tensor([[-1.4520, -3.3739],
        [-1.9581, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1443617045879364
Epoch 0, Step 522: train/loss = 0.48707109689712524, train/raw-loss = 0.3392099440097809, train/logprobs = tensor([[-1.0750, -3.0774],
        [-1.9485, -0.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14786112308502197
Epoch 0, Step 523: train/loss = 0.6261452436447144, train/raw-loss = 0.4940241575241089, train/logprobs = tensor([[-1.3284, -3.1078],
        [-1.9158, -1.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13212105631828308
Epoch 0, Step 524: train/loss = 0.39125820994377136, train/raw-loss = 0.2300117462873459, train/logprobs = tensor([[-0.8839, -3.6112],
        [-2.2836, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16124647855758667
Epoch 0, Step 525: train/loss = 0.45712459087371826, train/raw-loss = 0.31855762004852295, train/logprobs = tensor([[-1.4251, -2.3972],
        [-2.9225, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385669708251953
Epoch 0, Step 526: train/loss = 0.3840969204902649, train/raw-loss = 0.22253504395484924, train/logprobs = tensor([[-1.4283, -4.6281],
        [-2.8362, -1.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16156189143657684
Epoch 0, Step 527: train/loss = 0.5503295063972473, train/raw-loss = 0.4191015958786011, train/logprobs = tensor([[-0.8315, -2.0786],
        [-1.9417, -1.3638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13122794032096863
Epoch 0, Step 528: train/loss = 0.382539838552475, train/raw-loss = 0.24792471528053284, train/logprobs = tensor([[-1.0525, -2.8198],
        [-2.6095, -0.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13461512327194214
Epoch 0, Step 529: train/loss = 0.8312780857086182, train/raw-loss = 0.699587345123291, train/logprobs = tensor([[-0.8684, -3.6627],
        [-1.8502, -2.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13169080018997192
Epoch 0, Step 530: train/loss = 0.5428102016448975, train/raw-loss = 0.45713087916374207, train/logprobs = tensor([[-0.4465, -2.5837],
        [-0.5490, -0.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0856793224811554
Epoch 0, Step 531: train/loss = 0.3888474404811859, train/raw-loss = 0.22849050164222717, train/logprobs = tensor([[-0.6952, -4.2571],
        [-1.7490, -1.0223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16035690903663635
Epoch 0, Step 532: train/loss = 0.5572001338005066, train/raw-loss = 0.4314160645008087, train/logprobs = tensor([[-0.8426, -1.8885],
        [-1.5399, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1257840394973755
Epoch 0, Step 533: train/loss = 0.39159095287323, train/raw-loss = 0.26147574186325073, train/logprobs = tensor([[-0.6369, -4.2560],
        [-0.9101, -0.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13011521100997925
Epoch 0, Step 534: train/loss = 0.4818306565284729, train/raw-loss = 0.34390801191329956, train/logprobs = tensor([[-0.9603, -2.3921],
        [-2.7850, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13792259991168976
Epoch 0, Step 535: train/loss = 0.5137553215026855, train/raw-loss = 0.37464383244514465, train/logprobs = tensor([[-0.7768, -2.2497],
        [-1.2904, -0.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1391114741563797
Epoch 0, Step 536: train/loss = 0.3282760977745056, train/raw-loss = 0.18075600266456604, train/logprobs = tensor([[-1.1167, -4.9221],
        [-2.8873, -1.4185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14752008020877838
Epoch 0, Step 537: train/loss = 0.3911873996257782, train/raw-loss = 0.20823264122009277, train/logprobs = tensor([[-1.2171, -3.1134],
        [-2.5923, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18295475840568542
Epoch 0, Step 538: train/loss = 0.613211452960968, train/raw-loss = 0.4803308844566345, train/logprobs = tensor([[-0.9717, -1.4214],
        [-2.9463, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328805387020111
Epoch 0, Step 539: train/loss = 0.4903258681297302, train/raw-loss = 0.32885926961898804, train/logprobs = tensor([[-1.1311, -3.6078],
        [-1.7096, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16146662831306458
Epoch 0, Step 540: train/loss = 0.5406337976455688, train/raw-loss = 0.41607725620269775, train/logprobs = tensor([[-0.8696, -2.2087],
        [-1.6318, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12455657124519348
Epoch 0, Step 541: train/loss = 0.5093780159950256, train/raw-loss = 0.37756508588790894, train/logprobs = tensor([[-0.9638, -1.1358],
        [-2.2028, -0.4059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1318129301071167
Epoch 0, Step 542: train/loss = 0.40707480907440186, train/raw-loss = 0.2749671936035156, train/logprobs = tensor([[-1.4165, -3.3346],
        [-2.1933, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13210763037204742
Epoch 0, Step 543: train/loss = 0.4527474641799927, train/raw-loss = 0.30769234895706177, train/logprobs = tensor([[-0.9834, -2.1088],
        [-2.3076, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1450551301240921
Epoch 0, Step 544: train/loss = 0.5986858606338501, train/raw-loss = 0.45880773663520813, train/logprobs = tensor([[-0.8279, -3.0809],
        [-0.8425, -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13987812399864197
Epoch 0, Step 545: train/loss = 0.430976927280426, train/raw-loss = 0.2906080186367035, train/logprobs = tensor([[-0.7472, -3.1956],
        [-1.4820, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14036887884140015
Epoch 0, Step 546: train/loss = 0.414681613445282, train/raw-loss = 0.289336621761322, train/logprobs = tensor([[-1.4476, -7.0555],
        [-3.1393, -5.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12534499168395996
Epoch 0, Step 547: train/loss = 0.41040462255477905, train/raw-loss = 0.2822359800338745, train/logprobs = tensor([[-0.7586, -3.4375],
        [-1.8853, -0.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12816865742206573
Epoch 0, Step 548: train/loss = 0.43682926893234253, train/raw-loss = 0.2632604241371155, train/logprobs = tensor([[-0.9453, -4.5465],
        [-2.1021, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17356881499290466
Epoch 0, Step 549: train/loss = 0.517002522945404, train/raw-loss = 0.3405894339084625, train/logprobs = tensor([[-1.2857, -3.2984],
        [-2.7231, -1.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17641308903694153
Epoch 0, Step 550: train/loss = 0.5894918441772461, train/raw-loss = 0.4264548122882843, train/logprobs = tensor([[-0.9032, -2.2746],
        [-1.7724, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630370020866394
Epoch 0, Step 551: train/loss = 0.5327592492103577, train/raw-loss = 0.3880859613418579, train/logprobs = tensor([[-0.6678, -3.7173],
        [-0.9123, -0.8754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14467325806617737
Epoch 0, Step 552: train/loss = 0.5307636260986328, train/raw-loss = 0.3921825587749481, train/logprobs = tensor([[-1.3692, -2.8512],
        [-2.5803, -1.2892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1385810822248459
Epoch 0, Step 553: train/loss = 0.39084580540657043, train/raw-loss = 0.21988244354724884, train/logprobs = tensor([[-1.4823, -3.7354],
        [-3.5856, -1.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1709633618593216
Epoch 0, Step 554: train/loss = 0.4083179831504822, train/raw-loss = 0.2642466127872467, train/logprobs = tensor([[-1.1231, -4.5311],
        [-2.2344, -1.3163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14407137036323547
Epoch 0, Step 555: train/loss = 0.42678409814834595, train/raw-loss = 0.30643409490585327, train/logprobs = tensor([[-1.3569, -4.4715],
        [-2.6673, -1.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1203499585390091
Epoch 0, Step 556: train/loss = 0.42010223865509033, train/raw-loss = 0.24281519651412964, train/logprobs = tensor([[-0.8570, -2.9174],
        [-1.9928, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1772870272397995
Epoch 0, Step 557: train/loss = 0.4923788011074066, train/raw-loss = 0.3727586269378662, train/logprobs = tensor([[-0.7170, -4.2791],
        [-0.8324, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11962016671895981
Epoch 0, Step 558: train/loss = 0.7876338958740234, train/raw-loss = 0.612627387046814, train/logprobs = tensor([[-1.1141, -2.9191],
        [-2.3527, -1.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17500647902488708
Epoch 0, Step 559: train/loss = 0.4070754051208496, train/raw-loss = 0.26433175802230835, train/logprobs = tensor([[-0.7905, -3.4506],
        [-1.6025, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14274364709854126
Epoch 0, Step 560: train/loss = 0.5286633372306824, train/raw-loss = 0.39664769172668457, train/logprobs = tensor([[-0.7297, -2.9980],
        [-0.9229, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132015660405159
Epoch 0, Step 561: train/loss = 0.5465104579925537, train/raw-loss = 0.3634653091430664, train/logprobs = tensor([[-1.4588, -3.0666],
        [-2.7908, -1.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1830451339483261
Epoch 0, Step 562: train/loss = 0.52088463306427, train/raw-loss = 0.36545175313949585, train/logprobs = tensor([[-0.8618, -3.2959],
        [-1.8660, -1.3534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15543285012245178
Epoch 0, Step 563: train/loss = 0.43038925528526306, train/raw-loss = 0.24849966168403625, train/logprobs = tensor([[-0.9207, -3.0170],
        [-2.5944, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1818896234035492
Epoch 0, Step 564: train/loss = 0.5582038164138794, train/raw-loss = 0.39406049251556396, train/logprobs = tensor([[-1.1578, -2.2117],
        [-1.8996, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16414335370063782
Epoch 0, Step 565: train/loss = 0.6023358702659607, train/raw-loss = 0.4751998782157898, train/logprobs = tensor([[-0.7316, -2.5673],
        [-0.9890, -1.3055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1271360069513321
Epoch 0, Step 566: train/loss = 0.36314404010772705, train/raw-loss = 0.2263304591178894, train/logprobs = tensor([[-0.8325, -5.5113],
        [-1.2182, -0.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13681356608867645
Epoch 0, Step 567: train/loss = 0.6682929992675781, train/raw-loss = 0.55897456407547, train/logprobs = tensor([[-0.5515, -2.3481],
        [-0.8065, -1.5848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10931845009326935
Epoch 0, Step 568: train/loss = 0.5203837156295776, train/raw-loss = 0.39272183179855347, train/logprobs = tensor([[-0.7048, -3.6574],
        [-1.4046, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12766186892986298
Epoch 0, Step 569: train/loss = 0.5976277589797974, train/raw-loss = 0.4667530655860901, train/logprobs = tensor([[-1.4248, -1.5290],
        [-2.5517, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13087467849254608
Epoch 0, Step 570: train/loss = 0.4042651057243347, train/raw-loss = 0.26249006390571594, train/logprobs = tensor([[-0.9185, -5.5832],
        [-2.1499, -1.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417750120162964
Epoch 0, Step 571: train/loss = 0.6102887392044067, train/raw-loss = 0.48835209012031555, train/logprobs = tensor([[-1.5913, -2.4287],
        [-2.3893, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12193666398525238
Epoch 0, Step 572: train/loss = 0.5341241359710693, train/raw-loss = 0.4032427966594696, train/logprobs = tensor([[-0.8587, -3.2019],
        [-1.4896, -0.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13088133931159973
Epoch 0, Step 573: train/loss = 0.6000066995620728, train/raw-loss = 0.47458481788635254, train/logprobs = tensor([[-1.0447, -2.8953],
        [-0.9471, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12542188167572021
Epoch 0, Step 574: train/loss = 0.4646952450275421, train/raw-loss = 0.2953302264213562, train/logprobs = tensor([[-0.8493, -5.4380],
        [-2.0294, -2.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1693650186061859
Epoch 0, Step 575: train/loss = 0.7531126737594604, train/raw-loss = 0.6220795512199402, train/logprobs = tensor([[-1.2191, -2.8135],
        [-2.1429, -2.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13103312253952026
Epoch 0, Step 576: train/loss = 0.3740031123161316, train/raw-loss = 0.20346824824810028, train/logprobs = tensor([[-0.7525, -3.6523],
        [-1.8984, -0.6484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17053484916687012
Epoch 0, Step 577: train/loss = 0.3825138807296753, train/raw-loss = 0.22833484411239624, train/logprobs = tensor([[-1.3885, -1.9525],
        [-3.8980, -0.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15417903661727905
Epoch 0, Step 578: train/loss = 0.6836866140365601, train/raw-loss = 0.5481528639793396, train/logprobs = tensor([[-1.4660, -2.2496],
        [-1.3719, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13553369045257568
Epoch 0, Step 579: train/loss = 0.3888563811779022, train/raw-loss = 0.22390606999397278, train/logprobs = tensor([[-1.3421, -3.4384],
        [-2.9270, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16495031118392944
Epoch 0, Step 580: train/loss = 0.5405591726303101, train/raw-loss = 0.3906022310256958, train/logprobs = tensor([[-0.7709, -3.3098],
        [-1.1392, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14995694160461426
Epoch 0, Step 581: train/loss = 0.4638453722000122, train/raw-loss = 0.30337440967559814, train/logprobs = tensor([[-0.7865, -3.9245],
        [-1.0568, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16047097742557526
Epoch 0, Step 582: train/loss = 0.7128579020500183, train/raw-loss = 0.6040170788764954, train/logprobs = tensor([[-1.1748, -2.2792],
        [-1.0261, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884083807468414
Epoch 0, Step 583: train/loss = 0.6918516755104065, train/raw-loss = 0.5072359442710876, train/logprobs = tensor([[-1.3778, -1.4977],
        [-2.0813, -1.0542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18461570143699646
Epoch 0, Step 584: train/loss = 0.37791234254837036, train/raw-loss = 0.22306852042675018, train/logprobs = tensor([[-0.9406, -3.8059],
        [-2.2105, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15484383702278137
Epoch 0, Step 585: train/loss = 0.469044029712677, train/raw-loss = 0.33749568462371826, train/logprobs = tensor([[-0.8701, -4.2874],
        [-0.7069, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13154837489128113
Epoch 0, Step 586: train/loss = 0.563302755355835, train/raw-loss = 0.4133787751197815, train/logprobs = tensor([[-1.2642, -3.2567],
        [-2.2155, -2.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14992398023605347
Epoch 0, Step 587: train/loss = 0.5580517053604126, train/raw-loss = 0.40346670150756836, train/logprobs = tensor([[-0.5835, -2.8155],
        [-0.9725, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15458500385284424
Epoch 0, Step 588: train/loss = 0.5752785205841064, train/raw-loss = 0.44261375069618225, train/logprobs = tensor([[-0.8935, -2.8298],
        [-0.9916, -0.6800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.132664754986763
Epoch 0, Step 589: train/loss = 0.5318130850791931, train/raw-loss = 0.3811003863811493, train/logprobs = tensor([[-1.5623, -3.2039],
        [-1.9209, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15071268379688263
Epoch 0, Step 590: train/loss = 0.6374390125274658, train/raw-loss = 0.47171223163604736, train/logprobs = tensor([[-0.9911, -1.7157],
        [-2.0015, -1.2413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16572678089141846
Epoch 0, Step 591: train/loss = 0.5080155730247498, train/raw-loss = 0.3220672309398651, train/logprobs = tensor([[-1.5215, -2.3719],
        [-3.2014, -1.3556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18594834208488464
Epoch 0, Step 592: train/loss = 0.5554923415184021, train/raw-loss = 0.3917664885520935, train/logprobs = tensor([[-1.4202, -2.6731],
        [-2.8105, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16372589766979218
Epoch 0, Step 593: train/loss = 0.4523150324821472, train/raw-loss = 0.3058086335659027, train/logprobs = tensor([[-1.0137, -2.8320],
        [-2.7302, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465063989162445
Epoch 0, Step 594: train/loss = 0.3931426405906677, train/raw-loss = 0.2490416169166565, train/logprobs = tensor([[-0.8936, -5.1776],
        [-1.1548, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14410099387168884
Epoch 0, Step 595: train/loss = 0.5081660151481628, train/raw-loss = 0.34379273653030396, train/logprobs = tensor([[-1.2195, -1.8547],
        [-2.4814, -0.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643732786178589
Epoch 0, Step 596: train/loss = 0.5017143487930298, train/raw-loss = 0.33062314987182617, train/logprobs = tensor([[-0.6738, -3.5307],
        [-1.1334, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710911989212036
Epoch 0, Step 597: train/loss = 0.507453441619873, train/raw-loss = 0.38979482650756836, train/logprobs = tensor([[-1.2655, -2.9373],
        [-1.6360, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11765868216753006
Epoch 0, Step 598: train/loss = 0.8277359008789062, train/raw-loss = 0.6743842363357544, train/logprobs = tensor([[-1.0119, -4.0220],
        [-1.5334, -2.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1533515751361847
Epoch 0, Step 599: train/loss = 0.7211157083511353, train/raw-loss = 0.5876045227050781, train/logprobs = tensor([[-1.3868, -1.7147],
        [-1.2933, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13351118564605713
Epoch 0, Step 600: train/loss = 0.6079591512680054, train/raw-loss = 0.4251096248626709, train/logprobs = tensor([[-1.2653, -3.2036],
        [-1.9123, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284954130649567
Epoch 0, Step 601: train/loss = 0.3797313868999481, train/raw-loss = 0.1989266723394394, train/logprobs = tensor([[-1.2421, -3.9819],
        [-2.4869, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18080471456050873
Epoch 0, Step 602: train/loss = 0.6881023645401001, train/raw-loss = 0.5318290591239929, train/logprobs = tensor([[-1.6396, -2.6046],
        [-1.8951, -1.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15627330541610718
Epoch 0, Step 603: train/loss = 0.3488416075706482, train/raw-loss = 0.16513954102993011, train/logprobs = tensor([[-1.3761, -3.8326],
        [-2.9050, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1837020367383957
Epoch 0, Step 604: train/loss = 0.4602002501487732, train/raw-loss = 0.32463252544403076, train/logprobs = tensor([[-1.5244, -4.5192],
        [-2.0445, -2.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13556775450706482
Epoch 0, Step 605: train/loss = 0.4709392189979553, train/raw-loss = 0.28612440824508667, train/logprobs = tensor([[-0.8708, -2.8954],
        [-1.9734, -0.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18481481075286865
Epoch 0, Step 606: train/loss = 0.6186694502830505, train/raw-loss = 0.46708399057388306, train/logprobs = tensor([[-0.9425, -1.6234],
        [-1.5915, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1515854448080063
Epoch 0, Step 607: train/loss = 0.46161916851997375, train/raw-loss = 0.31489384174346924, train/logprobs = tensor([[-0.6221, -3.8474],
        [-0.8978, -1.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14672531187534332
Epoch 0, Step 608: train/loss = 0.4467259645462036, train/raw-loss = 0.2835524082183838, train/logprobs = tensor([[-1.0385, -4.7089],
        [-2.1600, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16317355632781982
Epoch 0, Step 609: train/loss = 0.5047135353088379, train/raw-loss = 0.3679097890853882, train/logprobs = tensor([[-0.7895, -4.0101],
        [-1.0476, -0.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13680371642112732
Epoch 0, Step 610: train/loss = 0.5952903628349304, train/raw-loss = 0.4106432795524597, train/logprobs = tensor([[-1.0237, -2.8428],
        [-1.2028, -0.7012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1846470832824707
Epoch 0, Step 611: train/loss = 0.38823002576828003, train/raw-loss = 0.2143951952457428, train/logprobs = tensor([[-1.2384, -3.7557],
        [-2.1636, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17383483052253723
Epoch 0, Step 612: train/loss = 0.5357322692871094, train/raw-loss = 0.3934013545513153, train/logprobs = tensor([[-0.9365, -4.8527],
        [-0.9143, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14233088493347168
Epoch 0, Step 613: train/loss = 0.4746168851852417, train/raw-loss = 0.331379771232605, train/logprobs = tensor([[-0.9648, -2.9990],
        [-1.9270, -0.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14323708415031433
Epoch 0, Step 614: train/loss = 0.38997653126716614, train/raw-loss = 0.2242681086063385, train/logprobs = tensor([[-1.2108, -4.7507],
        [-1.8687, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16570845246315002
Epoch 0, Step 615: train/loss = 0.633702278137207, train/raw-loss = 0.4797532558441162, train/logprobs = tensor([[-0.8189, -3.7624],
        [-1.1059, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15394899249076843
Epoch 0, Step 616: train/loss = 0.46663349866867065, train/raw-loss = 0.27612781524658203, train/logprobs = tensor([[-1.6336, -4.2440],
        [-3.6263, -1.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19050566852092743
Epoch 0, Step 617: train/loss = 0.3582969009876251, train/raw-loss = 0.1688581109046936, train/logprobs = tensor([[-0.8815, -4.4895],
        [-2.1465, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18943879008293152
Epoch 0, Step 618: train/loss = 0.37826624512672424, train/raw-loss = 0.2282658815383911, train/logprobs = tensor([[-0.8531, -4.5086],
        [-2.1304, -1.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15000034868717194
Epoch 0, Step 619: train/loss = 0.47573667764663696, train/raw-loss = 0.2908918559551239, train/logprobs = tensor([[-1.1107, -2.7921],
        [-2.1254, -1.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18484482169151306
Epoch 0, Step 620: train/loss = 0.6235576272010803, train/raw-loss = 0.48664402961730957, train/logprobs = tensor([[-0.7820, -2.2543],
        [-1.0507, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13691358268260956
Epoch 0, Step 621: train/loss = 0.6349659562110901, train/raw-loss = 0.48297855257987976, train/logprobs = tensor([[-1.2560, -4.1255],
        [-0.8999, -1.3988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15198743343353271
Epoch 0, Step 622: train/loss = 0.34132522344589233, train/raw-loss = 0.17769914865493774, train/logprobs = tensor([[-0.9027, -5.3894],
        [-1.9861, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1636260747909546
Epoch 0, Step 623: train/loss = 0.47674477100372314, train/raw-loss = 0.30410832166671753, train/logprobs = tensor([[-1.6174, -2.5174],
        [-3.0005, -0.9748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17263643443584442
Epoch 0, Step 624: train/loss = 0.3894730508327484, train/raw-loss = 0.23190635442733765, train/logprobs = tensor([[-0.9828, -5.1862],
        [-2.3490, -1.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15756669640541077
Epoch 0, Step 625: train/loss = 0.6448633074760437, train/raw-loss = 0.5064805746078491, train/logprobs = tensor([[-0.6995, -2.9174],
        [-0.9166, -1.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13838273286819458
Epoch 0, Step 626: train/loss = 0.3315271735191345, train/raw-loss = 0.14644655585289001, train/logprobs = tensor([[-0.9228, -4.7958],
        [-2.8510, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1850806176662445
Epoch 0, Step 627: train/loss = 0.6816055774688721, train/raw-loss = 0.5352262854576111, train/logprobs = tensor([[-0.8997, -3.5074],
        [-1.5067, -1.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1463792622089386
Epoch 0, Step 628: train/loss = 0.5751837491989136, train/raw-loss = 0.42010873556137085, train/logprobs = tensor([[-0.7290, -2.3221],
        [-1.4417, -0.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15507501363754272
Epoch 0, Step 629: train/loss = 0.6516706347465515, train/raw-loss = 0.5080636739730835, train/logprobs = tensor([[-1.4920, -2.2193],
        [-1.8717, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14360694587230682
Epoch 0, Step 630: train/loss = 0.5035024285316467, train/raw-loss = 0.3534630537033081, train/logprobs = tensor([[-1.0580, -2.9063],
        [-1.8763, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15003931522369385
Epoch 0, Step 631: train/loss = 0.66363126039505, train/raw-loss = 0.5107883214950562, train/logprobs = tensor([[-1.2973, -3.0365],
        [-1.0258, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15284298360347748
Epoch 0, Step 632: train/loss = 0.4215623140335083, train/raw-loss = 0.2867971658706665, train/logprobs = tensor([[-0.8046, -4.7717],
        [-0.9352, -1.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347651332616806
Epoch 0, Step 633: train/loss = 0.36840391159057617, train/raw-loss = 0.21247127652168274, train/logprobs = tensor([[-0.9941, -5.6391],
        [-1.5101, -1.1251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15593263506889343
Epoch 0, Step 634: train/loss = 0.48768725991249084, train/raw-loss = 0.3388271927833557, train/logprobs = tensor([[-0.9139, -2.6037],
        [-2.0146, -0.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14886008203029633
Epoch 0, Step 635: train/loss = 0.7294144630432129, train/raw-loss = 0.5536977648735046, train/logprobs = tensor([[-1.8737, -2.8326],
        [-2.3223, -1.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17571669816970825
Epoch 0, Step 636: train/loss = 0.7586213946342468, train/raw-loss = 0.5982193946838379, train/logprobs = tensor([[-1.1135, -2.7415],
        [-2.6383, -1.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16040204465389252
Epoch 0, Step 637: train/loss = 0.5468149781227112, train/raw-loss = 0.4023001194000244, train/logprobs = tensor([[-1.9897, -5.4477],
        [-1.7988, -1.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14451490342617035
Epoch 0, Step 638: train/loss = 0.4208184778690338, train/raw-loss = 0.24054557085037231, train/logprobs = tensor([[-1.5749, -4.5775],
        [-3.3732, -1.6647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802728921175003
Epoch 0, Step 639: train/loss = 0.48115769028663635, train/raw-loss = 0.3204188346862793, train/logprobs = tensor([[-0.9162, -3.6952],
        [-1.7899, -0.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16073888540267944
Epoch 0, Step 640: train/loss = 0.4230285882949829, train/raw-loss = 0.28208762407302856, train/logprobs = tensor([[-0.6859, -3.9723],
        [-1.1212, -0.6227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14094093441963196
Epoch 0, Step 641: train/loss = 0.7883995771408081, train/raw-loss = 0.6418701410293579, train/logprobs = tensor([[-1.7383, -1.6205],
        [-1.9731, -0.6754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1465294361114502
Epoch 0, Step 642: train/loss = 0.3558592200279236, train/raw-loss = 0.19495181739330292, train/logprobs = tensor([[-1.2085, -5.5810],
        [-1.8579, -1.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16090740263462067
Epoch 0, Step 643: train/loss = 0.6218340396881104, train/raw-loss = 0.4355769157409668, train/logprobs = tensor([[-1.3241, -3.9537],
        [-2.7664, -1.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18625709414482117
Epoch 0, Step 644: train/loss = 0.6073725819587708, train/raw-loss = 0.4468030631542206, train/logprobs = tensor([[-1.6946, -3.3935],
        [-1.7236, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16056956350803375
Epoch 0, Step 645: train/loss = 0.6678123474121094, train/raw-loss = 0.5273947715759277, train/logprobs = tensor([[-0.7281, -1.7320],
        [-0.9117, -0.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14041757583618164
Epoch 0, Step 646: train/loss = 0.6754561066627502, train/raw-loss = 0.5444409847259521, train/logprobs = tensor([[-2.0609, -2.4547],
        [-2.5334, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310151219367981
Epoch 0, Step 647: train/loss = 0.48699867725372314, train/raw-loss = 0.32256215810775757, train/logprobs = tensor([[-1.1031, -2.3745],
        [-2.5514, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16443651914596558
Epoch 0, Step 648: train/loss = 0.43210557103157043, train/raw-loss = 0.27016615867614746, train/logprobs = tensor([[-0.9164, -4.2949],
        [-1.5972, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16193942725658417
Epoch 0, Step 649: train/loss = 0.3397655785083771, train/raw-loss = 0.1745918095111847, train/logprobs = tensor([[-1.3559, -5.3804],
        [-2.3163, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1651737540960312
Epoch 0, Step 650: train/loss = 0.3084895610809326, train/raw-loss = 0.1290884017944336, train/logprobs = tensor([[-0.9079, -4.0078],
        [-2.8146, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17940117418766022
Epoch 0, Step 651: train/loss = 0.675026535987854, train/raw-loss = 0.5266869068145752, train/logprobs = tensor([[-0.6328, -1.8097],
        [-1.7381, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14833956956863403
Epoch 0, Step 652: train/loss = 0.3517697751522064, train/raw-loss = 0.1820802539587021, train/logprobs = tensor([[-1.0280, -5.9881],
        [-1.8682, -1.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16968952119350433
Epoch 0, Step 653: train/loss = 0.5986878871917725, train/raw-loss = 0.47095808386802673, train/logprobs = tensor([[-0.6656, -3.4323],
        [-0.8041, -0.7162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12772978842258453
Epoch 0, Step 654: train/loss = 0.44802209734916687, train/raw-loss = 0.2958746552467346, train/logprobs = tensor([[-0.7385, -4.1733],
        [-1.5311, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15214741230010986
Epoch 0, Step 655: train/loss = 0.3986779749393463, train/raw-loss = 0.24245378375053406, train/logprobs = tensor([[-0.9733, -4.7702],
        [-2.4487, -1.2508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15622419118881226
Epoch 0, Step 656: train/loss = 0.4510611891746521, train/raw-loss = 0.31389617919921875, train/logprobs = tensor([[-0.6843, -4.7136],
        [-0.8805, -0.7243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13716499507427216
Epoch 0, Step 657: train/loss = 0.34405049681663513, train/raw-loss = 0.1652839183807373, train/logprobs = tensor([[-0.8771, -5.8113],
        [-1.8636, -0.8923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17876654863357544
Epoch 0, Step 658: train/loss = 0.6067086458206177, train/raw-loss = 0.4432254731655121, train/logprobs = tensor([[-1.3592, -2.4077],
        [-1.8946, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1634831726551056
Epoch 0, Step 659: train/loss = 0.4460534453392029, train/raw-loss = 0.28669363260269165, train/logprobs = tensor([[-0.8986, -3.6215],
        [-1.9381, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15935981273651123
Epoch 0, Step 660: train/loss = 0.4328565299510956, train/raw-loss = 0.26933354139328003, train/logprobs = tensor([[-1.0593, -4.3646],
        [-1.9372, -0.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16352297365665436
Epoch 0, Step 661: train/loss = 0.5079492330551147, train/raw-loss = 0.3524709939956665, train/logprobs = tensor([[-0.7255, -2.7440],
        [-1.7990, -0.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15547823905944824
Epoch 0, Step 662: train/loss = 0.3721560835838318, train/raw-loss = 0.21174263954162598, train/logprobs = tensor([[-0.7519, -6.3703],
        [-1.8575, -1.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16041342914104462
Epoch 0, Step 663: train/loss = 0.3901299238204956, train/raw-loss = 0.24389177560806274, train/logprobs = tensor([[-1.1099, -4.3110],
        [-1.7421, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14623817801475525
Epoch 0, Step 664: train/loss = 0.40450620651245117, train/raw-loss = 0.21626737713813782, train/logprobs = tensor([[-0.9700, -4.7892],
        [-2.3737, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18823885917663574
Epoch 0, Step 665: train/loss = 0.36780598759651184, train/raw-loss = 0.21747185289859772, train/logprobs = tensor([[-1.0347, -5.7293],
        [-1.5749, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15033414959907532
Epoch 0, Step 666: train/loss = 0.48003822565078735, train/raw-loss = 0.30951088666915894, train/logprobs = tensor([[-1.3363, -2.6908],
        [-2.8664, -0.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1705273538827896
Epoch 0, Step 667: train/loss = 0.47796347737312317, train/raw-loss = 0.31648457050323486, train/logprobs = tensor([[-0.9841, -3.9257],
        [-1.7544, -0.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16147887706756592
Epoch 0, Step 668: train/loss = 0.5280238389968872, train/raw-loss = 0.38932082056999207, train/logprobs = tensor([[-1.1827, -3.0550],
        [-2.0955, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13870298862457275
Epoch 0, Step 669: train/loss = 0.49638432264328003, train/raw-loss = 0.32767409086227417, train/logprobs = tensor([[-1.0088, -3.5569],
        [-1.8051, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16871024668216705
Epoch 0, Step 670: train/loss = 0.41331785917282104, train/raw-loss = 0.26016151905059814, train/logprobs = tensor([[-1.2255, -5.0341],
        [-2.1373, -1.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1531563401222229
Epoch 0, Step 671: train/loss = 0.5680141448974609, train/raw-loss = 0.4114774465560913, train/logprobs = tensor([[-1.0672, -2.6080],
        [-1.9730, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15653669834136963
Epoch 0, Step 672: train/loss = 0.5384097099304199, train/raw-loss = 0.35430222749710083, train/logprobs = tensor([[-0.9984, -1.5819],
        [-2.7125, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1841074824333191
Epoch 0, Step 673: train/loss = 0.6003358960151672, train/raw-loss = 0.47151926159858704, train/logprobs = tensor([[-0.9526, -1.7259],
        [-1.6379, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.128816619515419
Epoch 0, Step 674: train/loss = 0.3860933482646942, train/raw-loss = 0.23004816472530365, train/logprobs = tensor([[-0.7140, -4.6811],
        [-1.5678, -0.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15604519844055176
Epoch 0, Step 675: train/loss = 0.37238407135009766, train/raw-loss = 0.19849705696105957, train/logprobs = tensor([[-1.7184, -5.8460],
        [-2.4146, -1.1567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17388702929019928
Epoch 0, Step 676: train/loss = 0.41615018248558044, train/raw-loss = 0.2622452974319458, train/logprobs = tensor([[-1.2672, -6.6303],
        [-2.4421, -1.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15390485525131226
Epoch 0, Step 677: train/loss = 0.3581538796424866, train/raw-loss = 0.19733822345733643, train/logprobs = tensor([[-0.9912, -4.4417],
        [-1.9062, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16081562638282776
Epoch 0, Step 678: train/loss = 0.7034938335418701, train/raw-loss = 0.547853410243988, train/logprobs = tensor([[-2.0431, -3.9544],
        [-2.3986, -1.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15564043819904327
Epoch 0, Step 679: train/loss = 0.31418055295944214, train/raw-loss = 0.1438259333372116, train/logprobs = tensor([[-0.8763, -6.5079],
        [-2.2690, -1.1935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17035464942455292
Epoch 0, Step 680: train/loss = 0.3302023410797119, train/raw-loss = 0.16742417216300964, train/logprobs = tensor([[-1.1775, -4.3944],
        [-2.7473, -0.8198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16277816891670227
Epoch 0, Step 681: train/loss = 0.46426695585250854, train/raw-loss = 0.3193325996398926, train/logprobs = tensor([[-1.0449, -3.4579],
        [-1.6826, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14493432641029358
Epoch 0, Step 682: train/loss = 0.4574427008628845, train/raw-loss = 0.3100467920303345, train/logprobs = tensor([[-0.9058, -4.0879],
        [-1.5829, -1.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14739590883255005
Epoch 0, Step 683: train/loss = 0.5525544285774231, train/raw-loss = 0.42038118839263916, train/logprobs = tensor([[-0.7693, -1.7260],
        [-1.5319, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13217321038246155
Epoch 0, Step 684: train/loss = 0.4402918517589569, train/raw-loss = 0.2905524969100952, train/logprobs = tensor([[-1.2816, -4.5784],
        [-2.6188, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497393250465393
Epoch 0, Step 685: train/loss = 0.6819153428077698, train/raw-loss = 0.5708882212638855, train/logprobs = tensor([[-1.4059, -3.0708],
        [-1.5094, -1.1451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11102713644504547
Epoch 0, Step 686: train/loss = 0.4666840434074402, train/raw-loss = 0.31177818775177, train/logprobs = tensor([[-0.7646, -3.9346],
        [-1.3275, -1.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15490585565567017
Epoch 0, Step 687: train/loss = 0.43265628814697266, train/raw-loss = 0.29335102438926697, train/logprobs = tensor([[-0.7286, -2.6606],
        [-2.1760, -0.7386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393052488565445
Epoch 0, Step 688: train/loss = 0.3509065508842468, train/raw-loss = 0.1944231390953064, train/logprobs = tensor([[-0.8551, -5.0890],
        [-2.0663, -0.8486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15648341178894043
Epoch 0, Step 689: train/loss = 0.399769127368927, train/raw-loss = 0.24649211764335632, train/logprobs = tensor([[-0.6703, -5.3376],
        [-1.1085, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1532769799232483
Epoch 0, Step 690: train/loss = 0.6210609674453735, train/raw-loss = 0.46225452423095703, train/logprobs = tensor([[-1.3441, -3.9521],
        [-1.1762, -1.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15880650281906128
Epoch 0, Step 691: train/loss = 0.4951413571834564, train/raw-loss = 0.3640649616718292, train/logprobs = tensor([[-1.2696, -4.7340],
        [-1.7042, -1.6082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1310763955116272
Epoch 0, Step 692: train/loss = 0.3951290547847748, train/raw-loss = 0.23611339926719666, train/logprobs = tensor([[-1.0550, -4.5135],
        [-1.5468, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1590156853199005
Epoch 0, Step 693: train/loss = 0.5613949298858643, train/raw-loss = 0.43786996603012085, train/logprobs = tensor([[-0.8789, -2.2706],
        [-1.5208, -1.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12352493405342102
Epoch 0, Step 694: train/loss = 0.4343337416648865, train/raw-loss = 0.29482758045196533, train/logprobs = tensor([[-1.3481, -3.1879],
        [-2.5340, -0.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13950619101524353
Epoch 0, Step 695: train/loss = 0.5369443893432617, train/raw-loss = 0.3814293146133423, train/logprobs = tensor([[-2.1049, -3.4020],
        [-2.9233, -0.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15551511943340302
Epoch 0, Step 696: train/loss = 0.35172343254089355, train/raw-loss = 0.2187514305114746, train/logprobs = tensor([[-1.0237, -4.8952],
        [-2.2457, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13297200202941895
Epoch 0, Step 697: train/loss = 0.4653676748275757, train/raw-loss = 0.33694523572921753, train/logprobs = tensor([[-1.4408, -3.7766],
        [-2.5182, -0.6056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12842243909835815
Epoch 0, Step 698: train/loss = 0.3781946301460266, train/raw-loss = 0.2289256453514099, train/logprobs = tensor([[-0.8472, -5.0531],
        [-2.0157, -1.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1492689698934555
Epoch 0, Step 699: train/loss = 0.3992515802383423, train/raw-loss = 0.22853820025920868, train/logprobs = tensor([[-1.0499, -5.5415],
        [-2.3263, -1.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1707133948802948
Epoch 0, Step 700: train/loss = 0.3172231912612915, train/raw-loss = 0.16958500444889069, train/logprobs = tensor([[-0.9889, -5.9932],
        [-1.8388, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.147638201713562
Epoch 0, Step 701: train/loss = 0.6125190854072571, train/raw-loss = 0.45611807703971863, train/logprobs = tensor([[-1.1116, -2.3126],
        [-1.8307, -0.7577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15640102326869965
Epoch 0, Step 702: train/loss = 0.5837681293487549, train/raw-loss = 0.49685874581336975, train/logprobs = tensor([[-1.2498, -3.2778],
        [-1.3334, -1.5445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08690935373306274
Epoch 0, Step 703: train/loss = 0.48586565256118774, train/raw-loss = 0.3454495370388031, train/logprobs = tensor([[-1.3323, -2.1265],
        [-2.5478, -0.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14041611552238464
Epoch 0, Step 704: train/loss = 0.3181430697441101, train/raw-loss = 0.16806259751319885, train/logprobs = tensor([[-1.1943, -5.9484],
        [-2.6207, -0.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15008048713207245
Epoch 0, Step 705: train/loss = 0.4262855648994446, train/raw-loss = 0.27317288517951965, train/logprobs = tensor([[-0.9323, -4.1090],
        [-1.9298, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15311266481876373
Epoch 0, Step 706: train/loss = 0.5583959817886353, train/raw-loss = 0.43524369597435, train/logprobs = tensor([[-0.5486, -3.3663],
        [-0.7865, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12315230816602707
Epoch 0, Step 707: train/loss = 0.33790770173072815, train/raw-loss = 0.17303960025310516, train/logprobs = tensor([[-0.8219, -5.7185],
        [-1.6654, -0.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16486810147762299
Epoch 0, Step 708: train/loss = 0.41107994318008423, train/raw-loss = 0.27744290232658386, train/logprobs = tensor([[-0.9234, -3.7337],
        [-2.5434, -0.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13363702595233917
Epoch 0, Step 709: train/loss = 0.4372846186161041, train/raw-loss = 0.2934460937976837, train/logprobs = tensor([[-1.0911, -4.3748],
        [-1.4679, -0.9574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14383849501609802
Epoch 0, Step 710: train/loss = 0.3890400826931, train/raw-loss = 0.22959856688976288, train/logprobs = tensor([[-1.0886, -4.1429],
        [-2.0690, -1.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1594415009021759
Epoch 0, Step 711: train/loss = 0.5132652521133423, train/raw-loss = 0.37624797224998474, train/logprobs = tensor([[-1.0120, -3.3131],
        [-1.7517, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13701726496219635
Epoch 0, Step 712: train/loss = 0.5500343441963196, train/raw-loss = 0.4295380711555481, train/logprobs = tensor([[-1.2289, -4.1048],
        [-2.3962, -2.2349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12049621343612671
Epoch 0, Step 713: train/loss = 0.36769768595695496, train/raw-loss = 0.2580767273902893, train/logprobs = tensor([[-0.9001, -6.3091],
        [-1.0791, -1.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10962098836898804
Epoch 0, Step 714: train/loss = 0.48101192712783813, train/raw-loss = 0.33566826581954956, train/logprobs = tensor([[-0.8094, -6.1257],
        [-1.2407, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14534372091293335
Epoch 0, Step 715: train/loss = 0.4930955767631531, train/raw-loss = 0.3512507379055023, train/logprobs = tensor([[-1.7059, -4.9446],
        [-1.5614, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14184479415416718
Epoch 0, Step 716: train/loss = 0.39639201760292053, train/raw-loss = 0.2407827079296112, train/logprobs = tensor([[-1.0920, -1.6441],
        [-3.1913, -0.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15560930967330933
Epoch 0, Step 717: train/loss = 0.456093430519104, train/raw-loss = 0.3385283946990967, train/logprobs = tensor([[-0.6137, -3.2476],
        [-1.2426, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756500601768494
Epoch 0, Step 718: train/loss = 0.30220115184783936, train/raw-loss = 0.15808527171611786, train/logprobs = tensor([[-0.9778, -6.8432],
        [-2.1978, -1.3819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441158652305603
Epoch 0, Step 719: train/loss = 0.32633763551712036, train/raw-loss = 0.17830146849155426, train/logprobs = tensor([[-1.3469, -4.0461],
        [-3.0718, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1480361968278885
Epoch 0, Step 720: train/loss = 0.5007117390632629, train/raw-loss = 0.36104902625083923, train/logprobs = tensor([[-0.8768, -3.8888],
        [-1.2917, -0.8008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13966268301010132
Epoch 0, Step 721: train/loss = 0.5365875363349915, train/raw-loss = 0.39494049549102783, train/logprobs = tensor([[-1.3466, -3.3790],
        [-1.8529, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14164705574512482
Epoch 0, Step 722: train/loss = 0.44828417897224426, train/raw-loss = 0.3253699243068695, train/logprobs = tensor([[-1.1074, -4.4160],
        [-1.3604, -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12291426956653595
Epoch 0, Step 723: train/loss = 0.5634186863899231, train/raw-loss = 0.45393359661102295, train/logprobs = tensor([[-0.8745, -3.3687],
        [-1.1650, -1.4632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948505997657776
Epoch 0, Step 724: train/loss = 0.48207682371139526, train/raw-loss = 0.3769150674343109, train/logprobs = tensor([[-0.7311, -5.3321],
        [-0.8442, -0.9479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10516172647476196
Epoch 0, Step 725: train/loss = 0.4502675533294678, train/raw-loss = 0.30729037523269653, train/logprobs = tensor([[-1.5056, -2.6478],
        [-2.6438, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14297717809677124
Epoch 0, Step 726: train/loss = 0.5860776901245117, train/raw-loss = 0.44543737173080444, train/logprobs = tensor([[-1.0405, -1.8260],
        [-2.1875, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1406402736902237
Epoch 0, Step 727: train/loss = 0.530814528465271, train/raw-loss = 0.379591166973114, train/logprobs = tensor([[-0.7908, -3.2969],
        [-1.9498, -1.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15122337639331818
Epoch 0, Step 728: train/loss = 0.42581936717033386, train/raw-loss = 0.2921760678291321, train/logprobs = tensor([[-0.9506, -5.1157],
        [-2.0444, -1.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13364329934120178
Epoch 0, Step 729: train/loss = 0.5771552920341492, train/raw-loss = 0.4636915326118469, train/logprobs = tensor([[-0.9886, -2.7996],
        [-1.3860, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11346372961997986
Epoch 0, Step 730: train/loss = 0.6196630001068115, train/raw-loss = 0.49211180210113525, train/logprobs = tensor([[-1.6114, -2.3204],
        [-2.2979, -1.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12755125761032104
Epoch 0, Step 731: train/loss = 0.39251673221588135, train/raw-loss = 0.24168336391448975, train/logprobs = tensor([[-1.3179, -3.4363],
        [-3.7588, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508333683013916
Epoch 0, Step 732: train/loss = 0.2870480716228485, train/raw-loss = 0.15160250663757324, train/logprobs = tensor([[-1.4539, -5.2827],
        [-3.2413, -1.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13544556498527527
Epoch 0, Step 733: train/loss = 0.5074105858802795, train/raw-loss = 0.4060496687889099, train/logprobs = tensor([[-1.1630, -3.0909],
        [-1.5791, -1.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10136093944311142
Epoch 0, Step 734: train/loss = 0.43803367018699646, train/raw-loss = 0.3039558231830597, train/logprobs = tensor([[-0.6559, -3.9930],
        [-1.6032, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13407787680625916
Epoch 0, Step 735: train/loss = 0.41296905279159546, train/raw-loss = 0.23769134283065796, train/logprobs = tensor([[-1.1114, -3.6444],
        [-2.4564, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1752777099609375
Epoch 0, Step 736: train/loss = 0.6108545064926147, train/raw-loss = 0.48642611503601074, train/logprobs = tensor([[-1.5731, -1.6887],
        [-2.0699, -0.7249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.124428391456604
Epoch 0, Step 737: train/loss = 0.29052186012268066, train/raw-loss = 0.13387800753116608, train/logprobs = tensor([[-0.8897, -4.1468],
        [-3.2648, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566438525915146
Epoch 0, Step 738: train/loss = 0.377841979265213, train/raw-loss = 0.25998109579086304, train/logprobs = tensor([[-0.7136, -4.2895],
        [-1.5200, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11786087602376938
Epoch 0, Step 739: train/loss = 0.555423378944397, train/raw-loss = 0.4447903335094452, train/logprobs = tensor([[-0.6952, -2.2415],
        [-1.7761, -0.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11063306033611298
Epoch 0, Step 740: train/loss = 0.5165917873382568, train/raw-loss = 0.4012705087661743, train/logprobs = tensor([[-0.9265, -2.2375],
        [-1.9797, -0.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11532130092382431
Epoch 0, Step 741: train/loss = 0.4610540270805359, train/raw-loss = 0.3477934002876282, train/logprobs = tensor([[-1.0616, -2.7876],
        [-1.4850, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11326064169406891
Epoch 0, Step 742: train/loss = 0.43338674306869507, train/raw-loss = 0.3209211528301239, train/logprobs = tensor([[-0.6899, -4.5340],
        [-1.1474, -0.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11246558278799057
Epoch 0, Step 743: train/loss = 0.6244261264801025, train/raw-loss = 0.5141093730926514, train/logprobs = tensor([[-0.6567, -2.9079],
        [-0.9633, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11031676828861237
Epoch 0, Step 744: train/loss = 0.49375277757644653, train/raw-loss = 0.38484296202659607, train/logprobs = tensor([[-0.9059, -3.0392],
        [-1.1856, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10890978574752808
Epoch 0, Step 745: train/loss = 0.6002051830291748, train/raw-loss = 0.4861212372779846, train/logprobs = tensor([[-1.2333, -3.7825],
        [-3.0866, -1.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1140839233994484
Epoch 0, Step 746: train/loss = 0.34591758251190186, train/raw-loss = 0.2302406281232834, train/logprobs = tensor([[-0.4932, -7.0237],
        [-0.7875, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11567696928977966
Epoch 0, Step 747: train/loss = 0.3796411454677582, train/raw-loss = 0.2629915475845337, train/logprobs = tensor([[-1.3409, -2.7307],
        [-2.7719, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11664960533380508
Epoch 0, Step 748: train/loss = 0.496792197227478, train/raw-loss = 0.37166157364845276, train/logprobs = tensor([[-1.0199, -2.9433],
        [-2.9885, -1.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12513062357902527
Epoch 0, Step 749: train/loss = 0.557765781879425, train/raw-loss = 0.4274623990058899, train/logprobs = tensor([[-1.1312, -2.9311],
        [-2.9763, -1.7567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13030338287353516
Epoch 0, Step 750: train/loss = 0.5788523554801941, train/raw-loss = 0.45601707696914673, train/logprobs = tensor([[-0.8390, -3.1776],
        [-1.5774, -1.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12283526360988617
Epoch 0, Step 751: train/loss = 0.3549708425998688, train/raw-loss = 0.2179318368434906, train/logprobs = tensor([[-1.5679, -3.5216],
        [-2.8881, -1.0389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13703902065753937
Epoch 0, Step 752: train/loss = 0.4337918162345886, train/raw-loss = 0.3213485777378082, train/logprobs = tensor([[-0.6375, -4.6547],
        [-1.2378, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1124432310461998
Epoch 0, Step 753: train/loss = 0.4252653121948242, train/raw-loss = 0.31722941994667053, train/logprobs = tensor([[-0.5161, -3.7577],
        [-0.8400, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10803590714931488
Epoch 0, Step 754: train/loss = 0.315207839012146, train/raw-loss = 0.1878299117088318, train/logprobs = tensor([[-1.0901, -6.2158],
        [-1.7198, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1273779273033142
Epoch 0, Step 755: train/loss = 0.33051156997680664, train/raw-loss = 0.2000097781419754, train/logprobs = tensor([[-1.0168, -3.3325],
        [-2.9362, -0.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13050177693367004
Epoch 0, Step 756: train/loss = 0.47313302755355835, train/raw-loss = 0.33952242136001587, train/logprobs = tensor([[-2.4582, -6.3848],
        [-2.7495, -1.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13361062109470367
Epoch 0, Step 757: train/loss = 0.5336319208145142, train/raw-loss = 0.39599260687828064, train/logprobs = tensor([[-1.5268, -3.2802],
        [-2.1328, -0.8086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13763925433158875
Epoch 0, Step 758: train/loss = 0.45506322383880615, train/raw-loss = 0.33618059754371643, train/logprobs = tensor([[-0.7081, -5.1083],
        [-1.0477, -1.1860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11888260394334793
Epoch 0, Step 759: train/loss = 0.3607984483242035, train/raw-loss = 0.22948908805847168, train/logprobs = tensor([[-1.5817, -4.5384],
        [-2.6876, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.131309375166893
Epoch 0, Step 760: train/loss = 0.23700305819511414, train/raw-loss = 0.11116660386323929, train/logprobs = tensor([[-1.5978, -6.6824],
        [-3.7226, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12583646178245544
Epoch 0, Step 761: train/loss = 0.2808212637901306, train/raw-loss = 0.15309634804725647, train/logprobs = tensor([[-0.8567, -5.8145],
        [-2.5074, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12772494554519653
Epoch 0, Step 762: train/loss = 0.4954362213611603, train/raw-loss = 0.3666500747203827, train/logprobs = tensor([[-1.1518, -2.9631],
        [-2.0125, -1.0015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12878616154193878
Epoch 0, Step 763: train/loss = 0.5450646877288818, train/raw-loss = 0.42243945598602295, train/logprobs = tensor([[-0.9140, -3.1036],
        [-1.5980, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12262526899576187
Epoch 0, Step 764: train/loss = 0.3633129596710205, train/raw-loss = 0.22613191604614258, train/logprobs = tensor([[-0.6776, -3.0054],
        [-2.0929, -0.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13718105852603912
Epoch 0, Step 765: train/loss = 0.3409615159034729, train/raw-loss = 0.22325798869132996, train/logprobs = tensor([[-0.7569, -4.0798],
        [-1.6876, -0.6341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11770352721214294
Epoch 0, Step 766: train/loss = 0.2825832962989807, train/raw-loss = 0.14538121223449707, train/logprobs = tensor([[-1.0796, -4.2945],
        [-2.6542, -1.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13720208406448364
Epoch 0, Step 767: train/loss = 0.6440486907958984, train/raw-loss = 0.5011584162712097, train/logprobs = tensor([[-0.9630, -2.5629],
        [-2.3463, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14289021492004395
Epoch 0, Step 768: train/loss = 0.5292105674743652, train/raw-loss = 0.4260624647140503, train/logprobs = tensor([[-1.0662, -4.1182],
        [-1.3076, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314813256263733
Epoch 0, Step 769: train/loss = 0.47307196259498596, train/raw-loss = 0.3589157462120056, train/logprobs = tensor([[-0.8981, -4.2241],
        [-1.2919, -1.1239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11415619403123856
Epoch 0, Step 770: train/loss = 0.449397474527359, train/raw-loss = 0.34641003608703613, train/logprobs = tensor([[-0.7517, -4.8810],
        [-0.9571, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10298743844032288
Epoch 0, Step 771: train/loss = 0.43219518661499023, train/raw-loss = 0.3289794325828552, train/logprobs = tensor([[-0.6378, -3.7030],
        [-1.6425, -0.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10321574658155441
Epoch 0, Step 772: train/loss = 0.5095598101615906, train/raw-loss = 0.3930000066757202, train/logprobs = tensor([[-1.6141, -4.3609],
        [-2.1710, -1.4711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11655978858470917
Epoch 0, Step 773: train/loss = 0.3893021047115326, train/raw-loss = 0.25806164741516113, train/logprobs = tensor([[-1.3326, -2.4135],
        [-2.9129, -0.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13124044239521027
Epoch 0, Step 774: train/loss = 0.5055460333824158, train/raw-loss = 0.3866991698741913, train/logprobs = tensor([[-0.9490, -2.3361],
        [-2.1173, -0.8966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11884688585996628
Epoch 0, Step 775: train/loss = 0.49705296754837036, train/raw-loss = 0.38866233825683594, train/logprobs = tensor([[-1.0325, -2.3889],
        [-1.9754, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10839062929153442
Epoch 0, Step 776: train/loss = 0.46157532930374146, train/raw-loss = 0.3481404781341553, train/logprobs = tensor([[-1.9713, -3.7962],
        [-2.9920, -1.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11343483626842499
Epoch 0, Step 777: train/loss = 0.6879300475120544, train/raw-loss = 0.5422767996788025, train/logprobs = tensor([[-1.0718, -2.3263],
        [-2.7208, -1.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14565318822860718
Epoch 0, Step 778: train/loss = 0.43367254734039307, train/raw-loss = 0.3128831088542938, train/logprobs = tensor([[-0.9190, -3.7077],
        [-1.9422, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12078945338726044
Epoch 0, Step 779: train/loss = 0.4226840138435364, train/raw-loss = 0.31387412548065186, train/logprobs = tensor([[-1.6951, -3.3103],
        [-2.9054, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10880990326404572
Epoch 0, Step 780: train/loss = 0.3452823758125305, train/raw-loss = 0.22988584637641907, train/logprobs = tensor([[-0.7921, -4.8400],
        [-1.5318, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11539655923843384
Epoch 0, Step 781: train/loss = 0.620961606502533, train/raw-loss = 0.5009459257125854, train/logprobs = tensor([[-2.5742, -4.0631],
        [-3.0522, -1.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12001572549343109
Epoch 0, Step 782: train/loss = 0.31414154171943665, train/raw-loss = 0.19719737768173218, train/logprobs = tensor([[-0.5933, -5.6519],
        [-1.3877, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11694416403770447
Epoch 0, Step 783: train/loss = 0.5346577763557434, train/raw-loss = 0.4022616446018219, train/logprobs = tensor([[-1.8968, -3.1503],
        [-2.3074, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323961317539215
Epoch 0, Step 784: train/loss = 0.4673916697502136, train/raw-loss = 0.35641220211982727, train/logprobs = tensor([[-0.4600, -5.1486],
        [-0.9195, -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11097948998212814
Epoch 0, Step 785: train/loss = 0.7454734444618225, train/raw-loss = 0.6158934831619263, train/logprobs = tensor([[-2.5991, -3.7509],
        [-2.4457, -0.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12958000600337982
Epoch 0, Step 786: train/loss = 0.4084912836551666, train/raw-loss = 0.281491756439209, train/logprobs = tensor([[-1.1213, -1.8484],
        [-3.3017, -0.7441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12699951231479645
Epoch 0, Step 787: train/loss = 0.4634963274002075, train/raw-loss = 0.3351576328277588, train/logprobs = tensor([[-0.9499, -3.7496],
        [-2.6893, -1.3829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12833870947360992
Epoch 0, Step 788: train/loss = 0.4540671706199646, train/raw-loss = 0.3421914875507355, train/logprobs = tensor([[-1.1300, -3.8243],
        [-2.0585, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11187569797039032
Epoch 0, Step 789: train/loss = 0.5434558391571045, train/raw-loss = 0.4222162365913391, train/logprobs = tensor([[-1.3766, -2.9750],
        [-2.4242, -1.5614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123960256576538
Epoch 0, Step 790: train/loss = 0.5091926455497742, train/raw-loss = 0.38727837800979614, train/logprobs = tensor([[-1.3813, -3.3529],
        [-2.1655, -1.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12191428244113922
Epoch 0, Step 791: train/loss = 0.438433974981308, train/raw-loss = 0.33095768094062805, train/logprobs = tensor([[-0.6038, -4.0058],
        [-1.3546, -0.7322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10747630894184113
Epoch 0, Step 792: train/loss = 0.44648411870002747, train/raw-loss = 0.2852492332458496, train/logprobs = tensor([[-1.1292, -2.7126],
        [-3.0493, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16123491525650024
Epoch 0, Step 793: train/loss = 0.4262864887714386, train/raw-loss = 0.31139588356018066, train/logprobs = tensor([[-0.8159, -3.6320],
        [-1.4987, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11489060521125793
Epoch 0, Step 794: train/loss = 0.3534584045410156, train/raw-loss = 0.22906726598739624, train/logprobs = tensor([[-0.7534, -4.4659],
        [-1.6684, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12439115345478058
Epoch 0, Step 795: train/loss = 0.47370296716690063, train/raw-loss = 0.3420620262622833, train/logprobs = tensor([[-0.9566, -2.2250],
        [-2.7073, -0.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316409409046173
Epoch 0, Step 796: train/loss = 0.35794779658317566, train/raw-loss = 0.21001824736595154, train/logprobs = tensor([[-1.2417, -3.5345],
        [-3.1471, -1.5066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14792951941490173
Epoch 0, Step 797: train/loss = 0.34580448269844055, train/raw-loss = 0.21956230700016022, train/logprobs = tensor([[-0.9322, -3.1215],
        [-2.4691, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12624217569828033
Epoch 0, Step 798: train/loss = 0.4675453305244446, train/raw-loss = 0.3579806685447693, train/logprobs = tensor([[-0.8591, -3.4373],
        [-1.1841, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1095646321773529
Epoch 0, Step 799: train/loss = 0.5574473738670349, train/raw-loss = 0.44882410764694214, train/logprobs = tensor([[-0.6153, -3.3433],
        [-0.9967, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10862330347299576
Epoch 0, Step 800: train/loss = 0.6132868528366089, train/raw-loss = 0.5090608596801758, train/logprobs = tensor([[-1.0756, -1.0093],
        [-2.3693, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1042259931564331
Epoch 0, Step 801: train/loss = 0.4371582269668579, train/raw-loss = 0.33500027656555176, train/logprobs = tensor([[-0.8042, -4.5881],
        [-0.8519, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10215792059898376
Epoch 0, Step 802: train/loss = 0.5223981738090515, train/raw-loss = 0.4184609055519104, train/logprobs = tensor([[-0.8204, -3.1185],
        [-1.2776, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10393726080656052
Epoch 0, Step 803: train/loss = 0.6578684449195862, train/raw-loss = 0.5578781366348267, train/logprobs = tensor([[-0.6478, -1.2495],
        [-1.1247, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09999028593301773
Epoch 0, Step 804: train/loss = 0.5238529443740845, train/raw-loss = 0.43412432074546814, train/logprobs = tensor([[-0.6767, -3.7532],
        [-0.8538, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08972862362861633
Epoch 0, Step 805: train/loss = 0.5295650362968445, train/raw-loss = 0.4176709055900574, train/logprobs = tensor([[-1.4001, -4.4247],
        [-1.7695, -1.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11189411580562592
Epoch 0, Step 806: train/loss = 0.5065764784812927, train/raw-loss = 0.39675840735435486, train/logprobs = tensor([[-0.7548, -2.6630],
        [-1.7767, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10981805622577667
Epoch 0, Step 807: train/loss = 0.5938529372215271, train/raw-loss = 0.4902802109718323, train/logprobs = tensor([[-1.4477, -2.8411],
        [-2.9059, -2.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10357274115085602
Epoch 0, Step 808: train/loss = 0.327869176864624, train/raw-loss = 0.21831771731376648, train/logprobs = tensor([[-1.6037, -5.2314],
        [-2.7070, -1.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10955142974853516
Epoch 0, Step 809: train/loss = 0.7305833101272583, train/raw-loss = 0.6171046495437622, train/logprobs = tensor([[-0.6982, -0.8888],
        [-1.1642, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11347869783639908
Epoch 0, Step 810: train/loss = 0.7939444184303284, train/raw-loss = 0.6668758988380432, train/logprobs = tensor([[-2.4057, -3.0974],
        [-2.4913, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12706851959228516
Epoch 0, Step 811: train/loss = 0.4449806213378906, train/raw-loss = 0.352979838848114, train/logprobs = tensor([[-0.6565, -3.1500],
        [-1.7582, -0.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09200075268745422
Epoch 0, Step 812: train/loss = 0.4406655430793762, train/raw-loss = 0.3324902653694153, train/logprobs = tensor([[-1.2777, -3.3493],
        [-2.4196, -1.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10817523300647736
Epoch 0, Step 813: train/loss = 0.4004933834075928, train/raw-loss = 0.2744535207748413, train/logprobs = tensor([[-1.2010, -4.0185],
        [-2.3134, -1.0552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12603986263275146
Epoch 0, Step 814: train/loss = 0.42166781425476074, train/raw-loss = 0.31307482719421387, train/logprobs = tensor([[-1.3208, -3.1647],
        [-2.2426, -0.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10859299451112747
Epoch 0, Step 815: train/loss = 0.3638453185558319, train/raw-loss = 0.23651115596294403, train/logprobs = tensor([[-0.8437, -4.0055],
        [-1.8094, -1.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12733417749404907
Epoch 0, Step 816: train/loss = 0.44088438153266907, train/raw-loss = 0.3351976275444031, train/logprobs = tensor([[-1.6508, -4.7838],
        [-1.9400, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10568675398826599
Epoch 0, Step 817: train/loss = 0.4070552587509155, train/raw-loss = 0.25791463255882263, train/logprobs = tensor([[-0.8132, -3.7235],
        [-2.2404, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491406261920929
Epoch 0, Step 818: train/loss = 0.4007737934589386, train/raw-loss = 0.2957693934440613, train/logprobs = tensor([[-1.4174, -2.8531],
        [-2.6660, -0.8035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10500440001487732
Epoch 0, Step 819: train/loss = 0.31125789880752563, train/raw-loss = 0.1870497167110443, train/logprobs = tensor([[-1.1750, -4.4765],
        [-3.1066, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12420815974473953
Epoch 0, Step 820: train/loss = 0.40416717529296875, train/raw-loss = 0.28262490034103394, train/logprobs = tensor([[-0.8842, -4.2474],
        [-1.8523, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12154223769903183
Epoch 0, Step 821: train/loss = 0.30254319310188293, train/raw-loss = 0.17356833815574646, train/logprobs = tensor([[-1.3092, -4.5095],
        [-2.6550, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12897486984729767
Epoch 0, Step 822: train/loss = 0.30378973484039307, train/raw-loss = 0.16687065362930298, train/logprobs = tensor([[-1.2523, -4.0332],
        [-3.2040, -0.8231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13691911101341248
Epoch 0, Step 823: train/loss = 0.533991813659668, train/raw-loss = 0.3947482109069824, train/logprobs = tensor([[-1.3984, -3.1330],
        [-2.7467, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13924355804920197
Epoch 0, Step 824: train/loss = 0.590514063835144, train/raw-loss = 0.4663224220275879, train/logprobs = tensor([[-0.7813, -2.0957],
        [-1.7064, -1.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12419167160987854
Epoch 0, Step 825: train/loss = 0.4340113401412964, train/raw-loss = 0.29825863242149353, train/logprobs = tensor([[-1.3031, -4.9458],
        [-2.3403, -1.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13575270771980286
Epoch 0, Step 826: train/loss = 0.3851713538169861, train/raw-loss = 0.27723076939582825, train/logprobs = tensor([[-0.9218, -5.1199],
        [-1.3312, -1.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10794059932231903
Epoch 0, Step 827: train/loss = 0.5101087689399719, train/raw-loss = 0.3812059760093689, train/logprobs = tensor([[-1.2223, -2.2037],
        [-2.6590, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12890274822711945
Epoch 0, Step 828: train/loss = 0.46330562233924866, train/raw-loss = 0.37307077646255493, train/logprobs = tensor([[-1.0800, -2.6280],
        [-2.1209, -1.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09023486077785492
Epoch 0, Step 829: train/loss = 0.38733482360839844, train/raw-loss = 0.25033295154571533, train/logprobs = tensor([[-1.2409, -2.8935],
        [-3.4026, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370018720626831
Epoch 0, Step 830: train/loss = 0.48228535056114197, train/raw-loss = 0.35513779520988464, train/logprobs = tensor([[-0.9428, -2.7341],
        [-1.9741, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12714757025241852
Epoch 0, Step 831: train/loss = 0.4327940046787262, train/raw-loss = 0.3017445504665375, train/logprobs = tensor([[-1.3810, -2.0508],
        [-3.9359, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13104943931102753
Epoch 0, Step 832: train/loss = 0.7726798057556152, train/raw-loss = 0.6249511241912842, train/logprobs = tensor([[-2.5431, -2.7343],
        [-2.8402, -1.3706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14772863686084747
Epoch 0, Step 833: train/loss = 0.5609542727470398, train/raw-loss = 0.4557819962501526, train/logprobs = tensor([[-1.9019, -2.3851],
        [-2.9602, -1.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10517226159572601
Epoch 0, Step 834: train/loss = 0.38765451312065125, train/raw-loss = 0.28351137042045593, train/logprobs = tensor([[-0.8560, -4.3809],
        [-1.3379, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10414310544729233
Epoch 0, Step 835: train/loss = 0.4210142195224762, train/raw-loss = 0.3244677186012268, train/logprobs = tensor([[-1.3182, -3.1011],
        [-2.4950, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654650092124939
Epoch 0, Step 836: train/loss = 0.5249682664871216, train/raw-loss = 0.4315102696418762, train/logprobs = tensor([[-0.9593, -2.1088],
        [-1.9190, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09345796704292297
Epoch 0, Step 837: train/loss = 0.34394899010658264, train/raw-loss = 0.26010608673095703, train/logprobs = tensor([[-0.8733, -5.6601],
        [-1.1452, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838429257273674
Epoch 0, Step 838: train/loss = 0.27402201294898987, train/raw-loss = 0.14542022347450256, train/logprobs = tensor([[-1.1477, -4.3173],
        [-3.2411, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1286017894744873
Epoch 0, Step 839: train/loss = 0.8031604290008545, train/raw-loss = 0.6953354477882385, train/logprobs = tensor([[-1.4857, -1.1787],
        [-1.3641, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10782501101493835
Epoch 0, Step 840: train/loss = 0.32733893394470215, train/raw-loss = 0.20742495357990265, train/logprobs = tensor([[-1.2149, -4.3535],
        [-2.6012, -1.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1199139803647995
Epoch 0, Step 841: train/loss = 0.41005653142929077, train/raw-loss = 0.3199446499347687, train/logprobs = tensor([[-1.0157, -4.5805],
        [-1.4523, -0.9586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09011188894510269
Epoch 0, Step 842: train/loss = 0.4807712435722351, train/raw-loss = 0.37983494997024536, train/logprobs = tensor([[-0.9743, -2.9671],
        [-1.2978, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10093627870082855
Epoch 0, Step 843: train/loss = 0.437613844871521, train/raw-loss = 0.3397632837295532, train/logprobs = tensor([[-0.6880, -4.7892],
        [-0.9283, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09785058349370956
Epoch 0, Step 844: train/loss = 0.5114805698394775, train/raw-loss = 0.4139813184738159, train/logprobs = tensor([[-1.0645, -2.3637],
        [-1.5767, -0.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09749923646450043
Epoch 0, Step 845: train/loss = 0.5371848940849304, train/raw-loss = 0.44066953659057617, train/logprobs = tensor([[-0.9926, -3.1783],
        [-1.7334, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09651536494493484
Epoch 0, Step 846: train/loss = 0.31289368867874146, train/raw-loss = 0.19888292253017426, train/logprobs = tensor([[-0.9668, -4.1999],
        [-2.8961, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1140107810497284
Epoch 0, Step 847: train/loss = 0.504266083240509, train/raw-loss = 0.42019468545913696, train/logprobs = tensor([[-0.6423, -3.1768],
        [-0.8616, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08407141268253326
Epoch 0, Step 848: train/loss = 0.8065539598464966, train/raw-loss = 0.7038809061050415, train/logprobs = tensor([[-2.3032, -4.7803],
        [-1.7439, -1.2695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10267306864261627
Epoch 0, Step 849: train/loss = 0.37327542901039124, train/raw-loss = 0.25328898429870605, train/logprobs = tensor([[-1.0936, -3.8768],
        [-1.6416, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11998645216226578
Epoch 0, Step 850: train/loss = 0.4951740503311157, train/raw-loss = 0.4126189947128296, train/logprobs = tensor([[-1.3231, -3.2027],
        [-2.3115, -1.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08255506306886673
Epoch 0, Step 851: train/loss = 0.5260872840881348, train/raw-loss = 0.4404231607913971, train/logprobs = tensor([[-0.6843, -4.0519],
        [-0.7703, -0.9082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08566410839557648
Epoch 0, Step 852: train/loss = 0.4654337763786316, train/raw-loss = 0.34857597947120667, train/logprobs = tensor([[-1.7179, -3.7047],
        [-2.1236, -1.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11685778200626373
Epoch 0, Step 853: train/loss = 0.6707086563110352, train/raw-loss = 0.5853500962257385, train/logprobs = tensor([[-1.4421, -2.2937],
        [-1.5098, -1.5566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08535856753587723
Epoch 0, Step 854: train/loss = 0.5596712827682495, train/raw-loss = 0.4619094431400299, train/logprobs = tensor([[-0.6571, -1.4526],
        [-1.3643, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977618470788002
Epoch 0, Step 855: train/loss = 0.31948262453079224, train/raw-loss = 0.1884855180978775, train/logprobs = tensor([[-1.3343, -4.8804],
        [-2.9817, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13099709153175354
Epoch 0, Step 856: train/loss = 0.3918500244617462, train/raw-loss = 0.2819494605064392, train/logprobs = tensor([[-0.8511, -4.1843],
        [-1.9000, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10990055650472641
Epoch 0, Step 857: train/loss = 0.5759449601173401, train/raw-loss = 0.5013588666915894, train/logprobs = tensor([[-1.4011, -2.6611],
        [-1.7628, -0.7042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07458612322807312
Epoch 0, Step 858: train/loss = 0.45632675290107727, train/raw-loss = 0.34460124373435974, train/logprobs = tensor([[-0.7637, -2.8504],
        [-2.3911, -1.2306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11172549426555634
Epoch 0, Step 859: train/loss = 0.4722091555595398, train/raw-loss = 0.3825068473815918, train/logprobs = tensor([[-0.9571, -2.9505],
        [-1.1969, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08970232307910919
Epoch 0, Step 860: train/loss = 0.3540598154067993, train/raw-loss = 0.24015823006629944, train/logprobs = tensor([[-2.1031, -5.5381],
        [-3.6381, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11390158534049988
Epoch 0, Step 861: train/loss = 0.44796469807624817, train/raw-loss = 0.36528143286705017, train/logprobs = tensor([[-0.7784, -4.7223],
        [-0.9220, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268329501152039
Epoch 0, Step 862: train/loss = 0.4831477403640747, train/raw-loss = 0.3987419307231903, train/logprobs = tensor([[-1.0698, -3.4088],
        [-1.2081, -1.3862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0844058021903038
Epoch 0, Step 863: train/loss = 0.38642457127571106, train/raw-loss = 0.28307875990867615, train/logprobs = tensor([[-0.7679, -4.6460],
        [-1.5953, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10334580391645432
Epoch 0, Step 864: train/loss = 0.379102498292923, train/raw-loss = 0.24440228939056396, train/logprobs = tensor([[-1.1744, -4.0422],
        [-2.3885, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.134700208902359
Epoch 0, Step 865: train/loss = 0.29426416754722595, train/raw-loss = 0.18580149114131927, train/logprobs = tensor([[-1.5053, -5.0541],
        [-3.2910, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10846267640590668
Epoch 0, Step 866: train/loss = 0.6544469594955444, train/raw-loss = 0.5705724954605103, train/logprobs = tensor([[-2.4042, -1.4694],
        [-3.5814, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387450873851776
Epoch 0, Step 867: train/loss = 0.2830730974674225, train/raw-loss = 0.17450618743896484, train/logprobs = tensor([[-0.8517, -6.0382],
        [-1.8446, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10856690257787704
Epoch 0, Step 868: train/loss = 0.6791326403617859, train/raw-loss = 0.5967592597007751, train/logprobs = tensor([[-1.1522, -2.6832],
        [-1.5043, -1.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237334340810776
Epoch 0, Step 869: train/loss = 0.5120234489440918, train/raw-loss = 0.4152510166168213, train/logprobs = tensor([[-1.1481, -3.6104],
        [-2.0059, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0967724472284317
Epoch 0, Step 870: train/loss = 0.3120451867580414, train/raw-loss = 0.18173444271087646, train/logprobs = tensor([[-1.1420, -4.3931],
        [-2.4381, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1303107589483261
Epoch 0, Step 871: train/loss = 0.572608470916748, train/raw-loss = 0.47731608152389526, train/logprobs = tensor([[-1.2101, -1.3675],
        [-2.0322, -0.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09529236704111099
Epoch 0, Step 872: train/loss = 0.5102382898330688, train/raw-loss = 0.4213128089904785, train/logprobs = tensor([[-0.8173, -2.0850],
        [-1.3422, -0.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08892548084259033
Epoch 0, Step 873: train/loss = 0.510215163230896, train/raw-loss = 0.40207067131996155, train/logprobs = tensor([[-1.0915, -3.2120],
        [-2.5858, -2.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10814444720745087
Epoch 0, Step 874: train/loss = 0.5390120148658752, train/raw-loss = 0.449569433927536, train/logprobs = tensor([[-0.8447, -3.6994],
        [-1.2822, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08944261819124222
Epoch 0, Step 875: train/loss = 0.6237733364105225, train/raw-loss = 0.5153411626815796, train/logprobs = tensor([[-0.8941, -2.0254],
        [-1.8775, -0.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10843224078416824
Epoch 0, Step 876: train/loss = 0.3396603465080261, train/raw-loss = 0.23291081190109253, train/logprobs = tensor([[-0.7965, -4.6824],
        [-1.2345, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10674954950809479
Epoch 0, Step 877: train/loss = 0.5343994498252869, train/raw-loss = 0.43437403440475464, train/logprobs = tensor([[-0.8874, -2.8373],
        [-1.5482, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10002540796995163
Epoch 0, Step 878: train/loss = 0.3895573616027832, train/raw-loss = 0.2837219536304474, train/logprobs = tensor([[-1.2126, -3.8999],
        [-2.1553, -1.0897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10583541542291641
Epoch 0, Step 879: train/loss = 0.5772114992141724, train/raw-loss = 0.49509868025779724, train/logprobs = tensor([[-0.7180, -3.2856],
        [-0.8831, -1.4218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08211279660463333
Epoch 0, Step 880: train/loss = 0.3918877840042114, train/raw-loss = 0.2874878942966461, train/logprobs = tensor([[-1.0827, -4.0687],
        [-1.8540, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10439986735582352
Epoch 0, Step 881: train/loss = 0.5386576652526855, train/raw-loss = 0.4451041519641876, train/logprobs = tensor([[-0.9539, -2.4073],
        [-1.3186, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09355350583791733
Epoch 0, Step 882: train/loss = 0.7948886156082153, train/raw-loss = 0.6806604862213135, train/logprobs = tensor([[-1.8944, -3.1255],
        [-2.4021, -2.5705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11422815918922424
Epoch 0, Step 883: train/loss = 0.4311433434486389, train/raw-loss = 0.3394244909286499, train/logprobs = tensor([[-0.9652, -3.1903],
        [-1.6485, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09171883016824722
Epoch 0, Step 884: train/loss = 0.3099440038204193, train/raw-loss = 0.1874084621667862, train/logprobs = tensor([[-0.8737, -3.6373],
        [-2.6374, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12253552675247192
Epoch 0, Step 885: train/loss = 0.2988250255584717, train/raw-loss = 0.19687816500663757, train/logprobs = tensor([[-0.6995, -7.2255],
        [-1.5704, -1.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1019468903541565
Epoch 0, Step 886: train/loss = 0.5337953567504883, train/raw-loss = 0.4313971698284149, train/logprobs = tensor([[-1.1559, -3.6766],
        [-1.8771, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10239823907613754
Epoch 0, Step 887: train/loss = 0.4027266502380371, train/raw-loss = 0.3103140592575073, train/logprobs = tensor([[-1.2380, -3.7179],
        [-2.7085, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09241257607936859
Epoch 0, Step 888: train/loss = 0.29658764600753784, train/raw-loss = 0.17414914071559906, train/logprobs = tensor([[-0.7245, -5.8849],
        [-1.6825, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12243852764368057
Epoch 0, Step 889: train/loss = 0.44489529728889465, train/raw-loss = 0.3389846682548523, train/logprobs = tensor([[-1.3636, -2.1655],
        [-2.6861, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10591065138578415
Epoch 0, Step 890: train/loss = 0.5723509192466736, train/raw-loss = 0.48577722907066345, train/logprobs = tensor([[-0.7289, -1.0712],
        [-1.3231, -0.4415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08657369017601013
Epoch 0, Step 891: train/loss = 0.5329117178916931, train/raw-loss = 0.45127734541893005, train/logprobs = tensor([[-0.7788, -3.6352],
        [-0.8950, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08163439482450485
Epoch 0, Step 892: train/loss = 0.32696813344955444, train/raw-loss = 0.19150248169898987, train/logprobs = tensor([[-1.2006, -3.9716],
        [-2.6987, -1.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13546566665172577
Epoch 0, Step 893: train/loss = 0.4666503071784973, train/raw-loss = 0.37164124846458435, train/logprobs = tensor([[-0.8954, -3.0103],
        [-1.7480, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09500902891159058
Epoch 0, Step 894: train/loss = 0.4066907465457916, train/raw-loss = 0.28503987193107605, train/logprobs = tensor([[-0.7970, -4.6490],
        [-2.0082, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12165087461471558
Epoch 0, Step 895: train/loss = 0.6024022102355957, train/raw-loss = 0.5393080711364746, train/logprobs = tensor([[-0.8207, -2.2763],
        [-0.8721, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0630941241979599
Epoch 0, Step 896: train/loss = 0.6350642442703247, train/raw-loss = 0.5532321929931641, train/logprobs = tensor([[-1.8529, -4.9166],
        [-1.7761, -2.5401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08183200657367706
Epoch 0, Step 897: train/loss = 0.404196172952652, train/raw-loss = 0.27402085065841675, train/logprobs = tensor([[-1.0417, -5.4710],
        [-1.9892, -1.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13017532229423523
Epoch 0, Step 898: train/loss = 0.3974300026893616, train/raw-loss = 0.30627572536468506, train/logprobs = tensor([[-0.8896, -4.0617],
        [-1.5470, -0.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911542996764183
Epoch 0, Step 899: train/loss = 0.38298147916793823, train/raw-loss = 0.2941083312034607, train/logprobs = tensor([[-0.8113, -4.4511],
        [-1.1370, -1.0188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08887311816215515
Epoch 0, Step 900: train/loss = 0.5578672885894775, train/raw-loss = 0.47780102491378784, train/logprobs = tensor([[-0.9596, -4.0894],
        [-0.9205, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08006618916988373
Epoch 0, Step 901: train/loss = 0.7024059891700745, train/raw-loss = 0.5798304080963135, train/logprobs = tensor([[-3.0098, -3.1926],
        [-3.4062, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12257559597492218
Epoch 0, Step 902: train/loss = 0.4372737407684326, train/raw-loss = 0.34941649436950684, train/logprobs = tensor([[-1.2162, -4.3562],
        [-2.2590, -1.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08785723149776459
Epoch 0, Step 903: train/loss = 0.4392881393432617, train/raw-loss = 0.34147828817367554, train/logprobs = tensor([[-1.1075, -2.4577],
        [-2.3240, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09780983626842499
Epoch 0, Step 904: train/loss = 0.5254364609718323, train/raw-loss = 0.4275297224521637, train/logprobs = tensor([[-1.3578, -3.5830],
        [-1.8643, -1.5064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097906693816185
Epoch 0, Step 905: train/loss = 0.5394214987754822, train/raw-loss = 0.4615057408809662, train/logprobs = tensor([[-0.6722, -3.4228],
        [-0.7188, -0.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0779157355427742
Epoch 0, Step 906: train/loss = 0.2904343008995056, train/raw-loss = 0.1865382343530655, train/logprobs = tensor([[-1.2988, -6.8739],
        [-2.0814, -2.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389605909585953
Epoch 0, Step 907: train/loss = 0.6060857176780701, train/raw-loss = 0.5201453566551208, train/logprobs = tensor([[-0.7984, -1.0915],
        [-1.7302, -0.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08594034612178802
Epoch 0, Step 908: train/loss = 0.8427935838699341, train/raw-loss = 0.7552920579910278, train/logprobs = tensor([[-1.1245, -0.9576],
        [-1.6379, -1.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08750152587890625
Epoch 0, Step 909: train/loss = 0.4123927354812622, train/raw-loss = 0.30772650241851807, train/logprobs = tensor([[-0.8502, -4.2328],
        [-2.0611, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10466624796390533
Epoch 0, Step 910: train/loss = 0.46384096145629883, train/raw-loss = 0.3534087538719177, train/logprobs = tensor([[-1.8102, -2.8217],
        [-3.1555, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11043223738670349
Epoch 0, Step 911: train/loss = 0.689594030380249, train/raw-loss = 0.6270096302032471, train/logprobs = tensor([[-1.3276, -1.9305],
        [-1.0360, -0.6847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06258438527584076
Epoch 0, Step 912: train/loss = 0.5434272289276123, train/raw-loss = 0.4633236229419708, train/logprobs = tensor([[-0.7614, -2.7591],
        [-0.7335, -0.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08010360598564148
Epoch 0, Step 913: train/loss = 0.3309696912765503, train/raw-loss = 0.24414101243019104, train/logprobs = tensor([[-0.7940, -6.2629],
        [-1.0539, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08682870119810104
Epoch 0, Step 914: train/loss = 0.34910428524017334, train/raw-loss = 0.23619768023490906, train/logprobs = tensor([[-1.1358, -1.9296],
        [-3.3602, -0.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11290664970874786
Epoch 0, Step 915: train/loss = 0.4873392581939697, train/raw-loss = 0.3987223505973816, train/logprobs = tensor([[-1.1598, -2.8906],
        [-2.4005, -1.0901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08861693739891052
Epoch 0, Step 916: train/loss = 0.6291849613189697, train/raw-loss = 0.5401896238327026, train/logprobs = tensor([[-0.7695, -1.6681],
        [-1.0166, -0.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899535238742828
Epoch 0, Step 917: train/loss = 0.2516137659549713, train/raw-loss = 0.13393624126911163, train/logprobs = tensor([[-1.3258, -5.9721],
        [-3.2307, -1.6839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767751723527908
Epoch 0, Step 918: train/loss = 0.3938167691230774, train/raw-loss = 0.30098068714141846, train/logprobs = tensor([[-0.9121, -3.4843],
        [-2.0727, -1.1115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09283610433340073
Epoch 0, Step 919: train/loss = 0.5203250646591187, train/raw-loss = 0.43825632333755493, train/logprobs = tensor([[-0.9237, -3.7736],
        [-1.1866, -1.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206866681575775
Epoch 0, Step 920: train/loss = 0.4710210859775543, train/raw-loss = 0.36777564883232117, train/logprobs = tensor([[-0.9183, -2.4572],
        [-2.4720, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10324543714523315
Epoch 0, Step 921: train/loss = 0.49131810665130615, train/raw-loss = 0.4143075942993164, train/logprobs = tensor([[-0.7793, -3.2081],
        [-0.9907, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07701054215431213
Epoch 0, Step 922: train/loss = 0.4631078839302063, train/raw-loss = 0.38974642753601074, train/logprobs = tensor([[-0.8932, -3.2560],
        [-1.8600, -1.4154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336142659187317
Epoch 0, Step 923: train/loss = 0.4408964216709137, train/raw-loss = 0.35964661836624146, train/logprobs = tensor([[-0.7871, -3.9021],
        [-1.4098, -1.0679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08124980330467224
Epoch 0, Step 924: train/loss = 0.4421231746673584, train/raw-loss = 0.34484609961509705, train/logprobs = tensor([[-1.2876, -4.3342],
        [-1.5897, -1.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09727706015110016
Epoch 0, Step 925: train/loss = 0.4535466134548187, train/raw-loss = 0.3704298734664917, train/logprobs = tensor([[-0.5653, -3.5365],
        [-0.9361, -0.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08311671018600464
Epoch 0, Step 926: train/loss = 0.30675455927848816, train/raw-loss = 0.19768166542053223, train/logprobs = tensor([[-1.0172, -5.7698],
        [-1.9962, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907289385795593
Epoch 0, Step 927: train/loss = 0.6637350916862488, train/raw-loss = 0.5423405766487122, train/logprobs = tensor([[-1.1221, -3.9199],
        [-2.5377, -2.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12139451503753662
Epoch 0, Step 928: train/loss = 0.913274884223938, train/raw-loss = 0.8080271482467651, train/logprobs = tensor([[-2.5331, -2.7930],
        [-2.1377, -1.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10524778068065643
Epoch 0, Step 929: train/loss = 0.40183645486831665, train/raw-loss = 0.3132043778896332, train/logprobs = tensor([[-1.0516, -4.2093],
        [-2.3555, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08863205462694168
Epoch 0, Step 930: train/loss = 0.6238522529602051, train/raw-loss = 0.5386667251586914, train/logprobs = tensor([[-1.1459, -2.0916],
        [-1.2609, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08518551290035248
Epoch 0, Step 931: train/loss = 0.6153742671012878, train/raw-loss = 0.5284404754638672, train/logprobs = tensor([[-0.6840, -2.9890],
        [-0.9919, -1.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693380653858185
Epoch 0, Step 932: train/loss = 0.5368053913116455, train/raw-loss = 0.4627884030342102, train/logprobs = tensor([[-0.9824, -1.6819],
        [-1.7968, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07401693612337112
Epoch 0, Step 933: train/loss = 0.4819764792919159, train/raw-loss = 0.3919258117675781, train/logprobs = tensor([[-0.8349, -3.9962],
        [-1.5198, -1.1451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09005069732666016
Epoch 0, Step 934: train/loss = 0.7591947317123413, train/raw-loss = 0.6607860326766968, train/logprobs = tensor([[-2.4847, -5.3265],
        [-1.7740, -1.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09840866178274155
Epoch 0, Step 935: train/loss = 0.3271704912185669, train/raw-loss = 0.20983120799064636, train/logprobs = tensor([[-1.4036, -4.3885],
        [-2.4311, -1.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11733927577733994
Epoch 0, Step 936: train/loss = 0.4455242156982422, train/raw-loss = 0.36923661828041077, train/logprobs = tensor([[-0.7605, -3.3683],
        [-0.9397, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07628760486841202
Epoch 0, Step 937: train/loss = 0.36211705207824707, train/raw-loss = 0.23810319602489471, train/logprobs = tensor([[-1.4270, -3.3447],
        [-3.0812, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12401382625102997
Epoch 0, Step 938: train/loss = 0.7400294542312622, train/raw-loss = 0.6530499458312988, train/logprobs = tensor([[-2.2742, -4.4826],
        [-1.2636, -1.5251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08697950839996338
Epoch 0, Step 939: train/loss = 0.749489963054657, train/raw-loss = 0.6631311178207397, train/logprobs = tensor([[-0.8432, -2.3923],
        [-0.9360, -1.3685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08635889738798141
Epoch 0, Step 940: train/loss = 0.44134777784347534, train/raw-loss = 0.3310113251209259, train/logprobs = tensor([[-2.0217, -5.0431],
        [-2.6897, -2.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11033642292022705
Epoch 0, Step 941: train/loss = 0.6008938550949097, train/raw-loss = 0.50948166847229, train/logprobs = tensor([[-1.7930, -4.9234],
        [-1.3039, -1.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09141214191913605
Epoch 0, Step 942: train/loss = 0.4208504259586334, train/raw-loss = 0.3193364143371582, train/logprobs = tensor([[-1.0476, -4.9696],
        [-1.6767, -1.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10151401907205582
Epoch 0, Step 943: train/loss = 0.4954853653907776, train/raw-loss = 0.42764154076576233, train/logprobs = tensor([[-1.3127, -3.9879],
        [-1.5541, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06784382462501526
Epoch 0, Step 944: train/loss = 0.3232470750808716, train/raw-loss = 0.22843801975250244, train/logprobs = tensor([[-0.8161, -5.1058],
        [-1.6380, -1.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09480907022953033
Epoch 0, Step 945: train/loss = 0.47639572620391846, train/raw-loss = 0.37415826320648193, train/logprobs = tensor([[-2.1812, -3.4183],
        [-2.7910, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10223744064569473
Epoch 0, Step 946: train/loss = 0.3001455068588257, train/raw-loss = 0.21225877106189728, train/logprobs = tensor([[-0.6631, -6.3505],
        [-1.1699, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0878867506980896
Epoch 0, Step 947: train/loss = 0.6330755949020386, train/raw-loss = 0.5507174134254456, train/logprobs = tensor([[-1.2922, -1.9774],
        [-1.5425, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08235816657543182
Epoch 0, Step 948: train/loss = 0.4702107608318329, train/raw-loss = 0.38978397846221924, train/logprobs = tensor([[-0.4587, -3.6361],
        [-0.7575, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08042675256729126
Epoch 0, Step 949: train/loss = 0.9484127759933472, train/raw-loss = 0.8301507830619812, train/logprobs = tensor([[-3.4564, -3.3789],
        [-3.0556, -1.9525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11826194822788239
Epoch 0, Step 950: train/loss = 0.5636352896690369, train/raw-loss = 0.4810207486152649, train/logprobs = tensor([[-1.5199, -2.6008],
        [-2.0730, -1.1558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261457830667496
Epoch 0, Step 951: train/loss = 0.5848252177238464, train/raw-loss = 0.5188719630241394, train/logprobs = tensor([[-1.1083, -1.1491],
        [-1.7824, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0659533143043518
Epoch 0, Step 952: train/loss = 0.4019572138786316, train/raw-loss = 0.28352370858192444, train/logprobs = tensor([[-1.6221, -2.6510],
        [-3.2959, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11843348294496536
Epoch 0, Step 953: train/loss = 0.36872878670692444, train/raw-loss = 0.27540627121925354, train/logprobs = tensor([[-0.7488, -3.8730],
        [-1.6795, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933225154876709
Epoch 0, Step 954: train/loss = 0.473259299993515, train/raw-loss = 0.383498877286911, train/logprobs = tensor([[-1.0387, -2.7326],
        [-2.2336, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897604301571846
Epoch 0, Step 955: train/loss = 0.3216998279094696, train/raw-loss = 0.21805797517299652, train/logprobs = tensor([[-0.9836, -5.5988],
        [-1.9225, -1.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10364184528589249
Epoch 0, Step 956: train/loss = 0.5845357775688171, train/raw-loss = 0.519331157207489, train/logprobs = tensor([[-2.1307, -3.5751],
        [-2.8815, -3.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06520463526248932
Epoch 0, Step 957: train/loss = 0.48385822772979736, train/raw-loss = 0.38934633135795593, train/logprobs = tensor([[-1.1316, -3.7839],
        [-1.8433, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451189637184143
Epoch 0, Step 958: train/loss = 0.42956435680389404, train/raw-loss = 0.3277130722999573, train/logprobs = tensor([[-0.9297, -2.4443],
        [-1.9534, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10185128450393677
Epoch 0, Step 959: train/loss = 0.5098461508750916, train/raw-loss = 0.4074116349220276, train/logprobs = tensor([[-0.8954, -3.1324],
        [-1.8147, -0.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10243453085422516
Epoch 0, Step 960: train/loss = 0.42848527431488037, train/raw-loss = 0.3388398587703705, train/logprobs = tensor([[-0.8051, -5.3158],
        [-0.9242, -1.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08964542299509048
Epoch 0, Step 961: train/loss = 0.40659916400909424, train/raw-loss = 0.3039909601211548, train/logprobs = tensor([[-1.2076, -5.4353],
        [-1.8428, -1.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10260823369026184
Epoch 0, Step 962: train/loss = 0.336472749710083, train/raw-loss = 0.2194150686264038, train/logprobs = tensor([[-1.1767, -4.2216],
        [-2.7244, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.117057666182518
Epoch 0, Step 963: train/loss = 0.695122241973877, train/raw-loss = 0.6015351414680481, train/logprobs = tensor([[-1.0436, -3.3441],
        [-1.6923, -2.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09358708560466766
Epoch 0, Step 964: train/loss = 0.5708296895027161, train/raw-loss = 0.44182175397872925, train/logprobs = tensor([[-1.1651, -3.7083],
        [-2.8562, -2.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12900790572166443
Epoch 0, Step 965: train/loss = 0.4485553801059723, train/raw-loss = 0.34761518239974976, train/logprobs = tensor([[-1.0740, -4.1065],
        [-1.9344, -1.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10094018280506134
Epoch 0, Step 966: train/loss = 0.42598533630371094, train/raw-loss = 0.3396247625350952, train/logprobs = tensor([[-1.0154, -2.7947],
        [-1.6940, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08636059612035751
Epoch 0, Step 967: train/loss = 0.310550719499588, train/raw-loss = 0.22365717589855194, train/logprobs = tensor([[-0.6972, -6.6801],
        [-1.1021, -1.3761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08689352869987488
Epoch 0, Step 968: train/loss = 0.5651347637176514, train/raw-loss = 0.4873049259185791, train/logprobs = tensor([[-1.4278, -1.2821],
        [-2.5480, -0.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07782988250255585
Epoch 0, Step 969: train/loss = 0.423347532749176, train/raw-loss = 0.351593941450119, train/logprobs = tensor([[-0.7731, -4.1477],
        [-0.9538, -1.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0717536136507988
Epoch 0, Step 970: train/loss = 0.4391634464263916, train/raw-loss = 0.3489687144756317, train/logprobs = tensor([[-0.7724, -5.5529],
        [-1.5006, -1.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09019474685192108
Epoch 0, Step 971: train/loss = 0.6031842231750488, train/raw-loss = 0.5536952614784241, train/logprobs = tensor([[-0.4974, -1.5046],
        [-0.5544, -0.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04948893189430237
Epoch 0, Step 972: train/loss = 0.3091593384742737, train/raw-loss = 0.2009991705417633, train/logprobs = tensor([[-1.0679, -5.0520],
        [-2.4273, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10816019773483276
Epoch 0, Step 973: train/loss = 0.43707725405693054, train/raw-loss = 0.35314029455184937, train/logprobs = tensor([[-0.7831, -3.9542],
        [-1.3535, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08393697440624237
Epoch 0, Step 974: train/loss = 0.32242318987846375, train/raw-loss = 0.217798113822937, train/logprobs = tensor([[-1.0492, -5.2907],
        [-1.8684, -1.3869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10462506115436554
Epoch 0, Step 975: train/loss = 0.809292197227478, train/raw-loss = 0.7330365180969238, train/logprobs = tensor([[-3.0250, -2.3621],
        [-2.4572, -0.7123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07625570148229599
Epoch 0, Step 976: train/loss = 0.4468490481376648, train/raw-loss = 0.3624592125415802, train/logprobs = tensor([[-0.9210, -2.5832],
        [-1.7316, -0.7135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0843898355960846
Epoch 0, Step 977: train/loss = 0.35026103258132935, train/raw-loss = 0.2709652781486511, train/logprobs = tensor([[-0.6766, -5.3058],
        [-0.9227, -1.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07929579168558121
Epoch 0, Step 978: train/loss = 0.47559577226638794, train/raw-loss = 0.38660237193107605, train/logprobs = tensor([[-1.1255, -3.5678],
        [-2.3492, -1.0761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899340778589249
Epoch 0, Step 979: train/loss = 0.5172178745269775, train/raw-loss = 0.44101908802986145, train/logprobs = tensor([[-1.0797, -2.6181],
        [-1.8373, -1.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07619883120059967
Epoch 0, Step 980: train/loss = 0.3290248513221741, train/raw-loss = 0.2395283430814743, train/logprobs = tensor([[-1.1028, -2.6227],
        [-2.5319, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08949650824069977
Epoch 0, Step 981: train/loss = 0.569672167301178, train/raw-loss = 0.4775201380252838, train/logprobs = tensor([[-0.7518, -2.8911],
        [-1.5411, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09215202182531357
Epoch 0, Step 982: train/loss = 0.4662467837333679, train/raw-loss = 0.3560279607772827, train/logprobs = tensor([[-1.3773, -3.7732],
        [-2.1758, -1.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1102188378572464
Epoch 0, Step 983: train/loss = 0.6455180644989014, train/raw-loss = 0.56947261095047, train/logprobs = tensor([[-1.7882, -1.1592],
        [-1.7350, -0.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0760454460978508
Epoch 0, Step 984: train/loss = 0.4256305992603302, train/raw-loss = 0.3206087052822113, train/logprobs = tensor([[-0.7560, -3.4661],
        [-1.6448, -1.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1050218939781189
Epoch 0, Step 985: train/loss = 0.2853095829486847, train/raw-loss = 0.17741143703460693, train/logprobs = tensor([[-1.1345, -4.4087],
        [-2.7138, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10789814591407776
Epoch 0, Step 986: train/loss = 0.33040696382522583, train/raw-loss = 0.22450509667396545, train/logprobs = tensor([[-1.8310, -1.6482],
        [-3.9593, -0.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10590185970067978
Epoch 0, Step 987: train/loss = 0.3996143341064453, train/raw-loss = 0.30284589529037476, train/logprobs = tensor([[-1.4267, -3.7245],
        [-2.0537, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676843881607056
Epoch 0, Step 988: train/loss = 0.6318854093551636, train/raw-loss = 0.524321973323822, train/logprobs = tensor([[-1.4097, -3.5120],
        [-2.5719, -2.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10756347328424454
Epoch 0, Step 989: train/loss = 0.4405847191810608, train/raw-loss = 0.3615041971206665, train/logprobs = tensor([[-0.8254, -4.1756],
        [-1.1621, -1.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07908051460981369
Epoch 0, Step 990: train/loss = 0.5349390506744385, train/raw-loss = 0.4284815490245819, train/logprobs = tensor([[-0.8347, -2.6438],
        [-1.3261, -1.2652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10645751655101776
Epoch 0, Step 991: train/loss = 0.6396980285644531, train/raw-loss = 0.565723180770874, train/logprobs = tensor([[-1.0226, -1.7978],
        [-1.0682, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0739748477935791
Epoch 0, Step 992: train/loss = 0.2555879056453705, train/raw-loss = 0.1355821192264557, train/logprobs = tensor([[-1.3749, -7.5161],
        [-2.9995, -2.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1200057715177536
Epoch 0, Step 993: train/loss = 0.4510266184806824, train/raw-loss = 0.35677528381347656, train/logprobs = tensor([[-0.9837, -4.2182],
        [-1.5070, -1.6346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09425131976604462
Epoch 0, Step 994: train/loss = 0.4417971968650818, train/raw-loss = 0.3251936733722687, train/logprobs = tensor([[-1.1494, -2.5033],
        [-2.7187, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1166035383939743
Epoch 0, Step 995: train/loss = 0.3459705710411072, train/raw-loss = 0.2595529854297638, train/logprobs = tensor([[-0.9698, -4.7925],
        [-1.9243, -1.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08641760796308517
Epoch 0, Step 996: train/loss = 0.5412619113922119, train/raw-loss = 0.4682990312576294, train/logprobs = tensor([[-2.0976, -4.9970],
        [-2.1723, -2.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07296287268400192
Epoch 0, Step 997: train/loss = 0.5051042437553406, train/raw-loss = 0.4383918046951294, train/logprobs = tensor([[-1.4070, -3.8177],
        [-1.6407, -0.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06671243906021118
Epoch 0, Step 998: train/loss = 0.41401901841163635, train/raw-loss = 0.32230743765830994, train/logprobs = tensor([[-1.1704, -3.7326],
        [-1.8464, -0.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09171158075332642
Epoch 0, Step 999: train/loss = 0.6507253646850586, train/raw-loss = 0.5542104840278625, train/logprobs = tensor([[-2.5456, -5.8411],
        [-1.8787, -1.2209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09651491791009903
Loss is nan
eval/loss: 0.4661900997161865
Epoch 0, Step 1000: train/loss = 0.5866745114326477, train/raw-loss = 0.5218565464019775, train/logprobs = tensor([[-0.5352, -2.3451],
        [-0.6118, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06481795758008957
Epoch 0, Step 1001: train/loss = 0.34469202160835266, train/raw-loss = 0.2300158143043518, train/logprobs = tensor([[-1.3619, -4.0686],
        [-2.5940, -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11467621475458145
Epoch 0, Step 1002: train/loss = 0.4393157362937927, train/raw-loss = 0.3614989221096039, train/logprobs = tensor([[-0.4639, -3.7858],
        [-0.6814, -1.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07781682908535004
Epoch 0, Step 1003: train/loss = 0.5014722943305969, train/raw-loss = 0.42201557755470276, train/logprobs = tensor([[-0.9423, -3.3565],
        [-1.1708, -1.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07945672422647476
Epoch 0, Step 1004: train/loss = 0.25697511434555054, train/raw-loss = 0.14469558000564575, train/logprobs = tensor([[-1.7398, -3.3162],
        [-4.2879, -1.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11227953433990479
Epoch 0, Step 1005: train/loss = 0.5269824862480164, train/raw-loss = 0.4598831534385681, train/logprobs = tensor([[-1.9030, -9.1674],
        [-1.6091, -6.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06709929555654526
Epoch 0, Step 1006: train/loss = 0.3600062131881714, train/raw-loss = 0.2850484848022461, train/logprobs = tensor([[-0.9588, -4.8101],
        [-1.5658, -1.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0749577060341835
Epoch 0, Step 1007: train/loss = 0.51674485206604, train/raw-loss = 0.4355246424674988, train/logprobs = tensor([[-1.0883, -2.5393],
        [-1.6679, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08122020214796066
Epoch 0, Step 1008: train/loss = 0.479406476020813, train/raw-loss = 0.3861590623855591, train/logprobs = tensor([[-1.2345, -4.0056],
        [-1.4521, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09324745088815689
Epoch 0, Step 1009: train/loss = 0.6735761761665344, train/raw-loss = 0.5505303144454956, train/logprobs = tensor([[-0.9933, -3.8929],
        [-2.3084, -1.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12304582446813583
Epoch 0, Step 1010: train/loss = 0.5367724895477295, train/raw-loss = 0.45500221848487854, train/logprobs = tensor([[-1.1755, -2.2211],
        [-1.6088, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08177024871110916
Epoch 0, Step 1011: train/loss = 0.4710926115512848, train/raw-loss = 0.38840797543525696, train/logprobs = tensor([[-0.7246, -3.6318],
        [-1.0566, -1.2451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268462866544724
Epoch 0, Step 1012: train/loss = 0.5263980627059937, train/raw-loss = 0.43623194098472595, train/logprobs = tensor([[-1.7606, -2.4976],
        [-3.0824, -1.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09016616642475128
Epoch 0, Step 1013: train/loss = 0.41337865591049194, train/raw-loss = 0.3360982835292816, train/logprobs = tensor([[-0.5892, -4.0252],
        [-0.6078, -0.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07728035748004913
Epoch 0, Step 1014: train/loss = 0.5449700355529785, train/raw-loss = 0.48467594385147095, train/logprobs = tensor([[-0.8090, -2.9675],
        [-0.8988, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06029411405324936
Epoch 0, Step 1015: train/loss = 0.3847214877605438, train/raw-loss = 0.2904704511165619, train/logprobs = tensor([[-1.7672, -2.8037],
        [-3.1751, -1.0806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09425105899572372
Epoch 0, Step 1016: train/loss = 0.32122868299484253, train/raw-loss = 0.20665869116783142, train/logprobs = tensor([[-1.4596, -4.8551],
        [-3.0379, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11456997692584991
Epoch 0, Step 1017: train/loss = 0.512565553188324, train/raw-loss = 0.4307571053504944, train/logprobs = tensor([[-1.4254, -3.2791],
        [-1.4723, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818084254860878
Epoch 0, Step 1018: train/loss = 0.5035226941108704, train/raw-loss = 0.42972105741500854, train/logprobs = tensor([[-1.0319, -2.1881],
        [-1.5288, -0.8749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07380162179470062
Epoch 0, Step 1019: train/loss = 0.3620026707649231, train/raw-loss = 0.28172311186790466, train/logprobs = tensor([[-1.2604, -4.3558],
        [-2.2986, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08027955889701843
Epoch 0, Step 1020: train/loss = 0.8885879516601562, train/raw-loss = 0.7843064069747925, train/logprobs = tensor([[-2.7147, -2.7523],
        [-2.3033, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10428167879581451
Epoch 0, Step 1021: train/loss = 0.5353279113769531, train/raw-loss = 0.4625707268714905, train/logprobs = tensor([[-1.6598, -4.5648],
        [-1.7754, -2.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07275719940662384
Epoch 0, Step 1022: train/loss = 0.4875272512435913, train/raw-loss = 0.404349148273468, train/logprobs = tensor([[-0.9251, -3.6215],
        [-1.2461, -1.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08317813277244568
Epoch 0, Step 1023: train/loss = 0.5020411014556885, train/raw-loss = 0.4235089123249054, train/logprobs = tensor([[-0.8051, -3.8374],
        [-1.3252, -1.2384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07853216677904129
Epoch 0, Step 1024: train/loss = 0.421434223651886, train/raw-loss = 0.34193676710128784, train/logprobs = tensor([[-1.5307, -4.9910],
        [-1.8643, -1.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07949744164943695
Epoch 0, Step 1025: train/loss = 0.2861793637275696, train/raw-loss = 0.18226754665374756, train/logprobs = tensor([[-1.1945, -4.3402],
        [-3.1684, -1.3111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10391178727149963
Epoch 0, Step 1026: train/loss = 0.3207249641418457, train/raw-loss = 0.2370302677154541, train/logprobs = tensor([[-0.9953, -5.3708],
        [-1.9649, -1.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.083694688975811
Epoch 0, Step 1027: train/loss = 0.35049736499786377, train/raw-loss = 0.25575384497642517, train/logprobs = tensor([[-0.9578, -6.8994],
        [-1.6083, -2.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947435200214386
Epoch 0, Step 1028: train/loss = 0.3038472831249237, train/raw-loss = 0.20473122596740723, train/logprobs = tensor([[-0.7394, -7.1363],
        [-1.4668, -2.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09911604225635529
Epoch 0, Step 1029: train/loss = 0.44708049297332764, train/raw-loss = 0.3549078702926636, train/logprobs = tensor([[-1.0536, -2.4966],
        [-2.0871, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09217261523008347
Epoch 0, Step 1030: train/loss = 0.39402246475219727, train/raw-loss = 0.30087342858314514, train/logprobs = tensor([[-1.3637, -3.4321],
        [-2.1367, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09314905107021332
Epoch 0, Step 1031: train/loss = 0.3819023370742798, train/raw-loss = 0.3109270930290222, train/logprobs = tensor([[-0.6721, -4.9412],
        [-0.7676, -1.3763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07097525149583817
Epoch 0, Step 1032: train/loss = 0.7203906774520874, train/raw-loss = 0.6766722798347473, train/logprobs = tensor([[-1.2609, -0.6955],
        [-1.1278, -0.4766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04371840879321098
Epoch 0, Step 1033: train/loss = 0.2716273069381714, train/raw-loss = 0.17830350995063782, train/logprobs = tensor([[-0.8947, -7.0598],
        [-1.7677, -1.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09332378953695297
Epoch 0, Step 1034: train/loss = 0.35049140453338623, train/raw-loss = 0.25136539340019226, train/logprobs = tensor([[-0.7859, -5.1283],
        [-1.3392, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09912599623203278
Epoch 0, Step 1035: train/loss = 0.3608987331390381, train/raw-loss = 0.28160473704338074, train/logprobs = tensor([[-0.7743, -5.9854],
        [-0.8757, -1.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07929400354623795
Epoch 0, Step 1036: train/loss = 0.41711318492889404, train/raw-loss = 0.3265078663825989, train/logprobs = tensor([[-1.1092, -3.4006],
        [-2.3675, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09060534089803696
Epoch 0, Step 1037: train/loss = 0.4202612638473511, train/raw-loss = 0.34460967779159546, train/logprobs = tensor([[-1.3606, -2.7956],
        [-2.4588, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07565159350633621
Epoch 0, Step 1038: train/loss = 0.5869944095611572, train/raw-loss = 0.5078812837600708, train/logprobs = tensor([[-0.9217, -2.8278],
        [-1.1541, -1.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0791131779551506
Epoch 0, Step 1039: train/loss = 0.4337649345397949, train/raw-loss = 0.3674023747444153, train/logprobs = tensor([[-0.9557, -3.0683],
        [-1.9079, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06636255234479904
Epoch 0, Step 1040: train/loss = 0.3216206133365631, train/raw-loss = 0.2130872905254364, train/logprobs = tensor([[-1.3772, -2.4468],
        [-2.9424, -0.6384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10853330790996552
Epoch 0, Step 1041: train/loss = 0.5122586488723755, train/raw-loss = 0.4199793338775635, train/logprobs = tensor([[-0.8508, -4.1643],
        [-1.6106, -1.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227931499481201
Epoch 0, Step 1042: train/loss = 0.4547885060310364, train/raw-loss = 0.3906328082084656, train/logprobs = tensor([[-0.6914, -3.6730],
        [-0.7829, -1.2667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0641556829214096
Epoch 0, Step 1043: train/loss = 0.4498930871486664, train/raw-loss = 0.3571026921272278, train/logprobs = tensor([[-1.1570, -3.5118],
        [-2.2002, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927903950214386
Epoch 0, Step 1044: train/loss = 0.3865923285484314, train/raw-loss = 0.28424185514450073, train/logprobs = tensor([[-1.7887, -6.0849],
        [-2.2124, -2.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10235048830509186
Epoch 0, Step 1045: train/loss = 0.5723089575767517, train/raw-loss = 0.5051563382148743, train/logprobs = tensor([[-0.7150, -1.6057],
        [-0.7887, -0.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06715260446071625
Epoch 0, Step 1046: train/loss = 0.4978128671646118, train/raw-loss = 0.4309101700782776, train/logprobs = tensor([[-1.3333, -3.8109],
        [-1.5033, -1.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06690267473459244
Epoch 0, Step 1047: train/loss = 0.4337410628795624, train/raw-loss = 0.3305601477622986, train/logprobs = tensor([[-1.1546, -3.4125],
        [-2.4178, -1.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10318092256784439
Epoch 0, Step 1048: train/loss = 0.47660499811172485, train/raw-loss = 0.4096686840057373, train/logprobs = tensor([[-0.6273, -2.6983],
        [-1.2646, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06693629920482635
Epoch 0, Step 1049: train/loss = 0.7993335127830505, train/raw-loss = 0.7254544496536255, train/logprobs = tensor([[-1.5432, -1.2728],
        [-1.4050, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07387907803058624
Epoch 0, Step 1050: train/loss = 0.5089208483695984, train/raw-loss = 0.41075193881988525, train/logprobs = tensor([[-1.1166, -3.7068],
        [-1.2499, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09816890954971313
Epoch 0, Step 1051: train/loss = 0.4903305172920227, train/raw-loss = 0.4142434000968933, train/logprobs = tensor([[-1.0730, -2.1844],
        [-1.9171, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0760871022939682
Epoch 0, Step 1052: train/loss = 0.2810162305831909, train/raw-loss = 0.17691673338413239, train/logprobs = tensor([[-1.0541, -5.4677],
        [-2.0963, -1.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10409948974847794
Epoch 0, Step 1053: train/loss = 0.4776912331581116, train/raw-loss = 0.39841800928115845, train/logprobs = tensor([[-0.8477, -1.6721],
        [-1.6034, -0.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07927319407463074
Epoch 0, Step 1054: train/loss = 0.395090788602829, train/raw-loss = 0.333717942237854, train/logprobs = tensor([[-0.6867, -5.1662],
        [-0.8772, -1.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061372820287942886
Epoch 0, Step 1055: train/loss = 0.2655448913574219, train/raw-loss = 0.1417967975139618, train/logprobs = tensor([[-1.5352, -4.6433],
        [-3.5484, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12374812364578247
Epoch 0, Step 1056: train/loss = 0.6217001676559448, train/raw-loss = 0.5623008608818054, train/logprobs = tensor([[-1.0667, -1.5051],
        [-1.4860, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05939926952123642
Epoch 0, Step 1057: train/loss = 0.6012082695960999, train/raw-loss = 0.5266451835632324, train/logprobs = tensor([[-0.8854, -2.5131],
        [-1.0569, -1.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07456308603286743
Epoch 0, Step 1058: train/loss = 0.41871050000190735, train/raw-loss = 0.32630765438079834, train/logprobs = tensor([[-1.3285, -3.0103],
        [-2.4716, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0924028605222702
Epoch 0, Step 1059: train/loss = 0.6085045337677002, train/raw-loss = 0.5243449807167053, train/logprobs = tensor([[-1.0077, -3.3755],
        [-1.8669, -1.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08415955305099487
Epoch 0, Step 1060: train/loss = 0.5460050106048584, train/raw-loss = 0.4773901402950287, train/logprobs = tensor([[-0.5650, -5.0086],
        [-0.6851, -1.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06861481815576553
Epoch 0, Step 1061: train/loss = 0.34696686267852783, train/raw-loss = 0.2394065409898758, train/logprobs = tensor([[-1.3637, -5.4842],
        [-2.3155, -1.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10756032913923264
Epoch 0, Step 1062: train/loss = 0.6267260313034058, train/raw-loss = 0.5662132501602173, train/logprobs = tensor([[-0.8254, -0.8236],
        [-1.2798, -0.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06051277741789818
Epoch 0, Step 1063: train/loss = 0.9644999504089355, train/raw-loss = 0.8676119446754456, train/logprobs = tensor([[-2.1219, -1.8024],
        [-1.8050, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09688795357942581
Epoch 0, Step 1064: train/loss = 0.4067037105560303, train/raw-loss = 0.31794512271881104, train/logprobs = tensor([[-0.7688, -5.3457],
        [-0.9863, -1.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08875858783721924
Epoch 0, Step 1065: train/loss = 0.27662527561187744, train/raw-loss = 0.17899757623672485, train/logprobs = tensor([[-0.9267, -6.6615],
        [-2.0041, -1.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09762772172689438
Epoch 0, Step 1066: train/loss = 0.5150446891784668, train/raw-loss = 0.4364411532878876, train/logprobs = tensor([[-1.0362, -2.6150],
        [-1.4871, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07860356569290161
Epoch 0, Step 1067: train/loss = 0.535370945930481, train/raw-loss = 0.4696654975414276, train/logprobs = tensor([[-0.5515, -3.8279],
        [-0.8844, -2.0379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06570544093847275
Epoch 0, Step 1068: train/loss = 0.3328578472137451, train/raw-loss = 0.22687309980392456, train/logprobs = tensor([[-0.9981, -5.6831],
        [-1.6892, -1.6308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10598476231098175
Epoch 0, Step 1069: train/loss = 0.39629894495010376, train/raw-loss = 0.3015602231025696, train/logprobs = tensor([[-1.1669, -3.6290],
        [-2.3878, -1.2549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473871439695358
Epoch 0, Step 1070: train/loss = 0.3741663992404938, train/raw-loss = 0.25932562351226807, train/logprobs = tensor([[-1.4371, -4.3734],
        [-3.4757, -2.5587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11484076082706451
Epoch 0, Step 1071: train/loss = 0.617671012878418, train/raw-loss = 0.5331987738609314, train/logprobs = tensor([[-1.0823, -1.3861],
        [-1.7071, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08447226136922836
Epoch 0, Step 1072: train/loss = 0.3742438852787018, train/raw-loss = 0.27915799617767334, train/logprobs = tensor([[-1.1076, -3.1286],
        [-2.7328, -0.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508589655160904
Epoch 0, Step 1073: train/loss = 0.5096865892410278, train/raw-loss = 0.4337562918663025, train/logprobs = tensor([[-1.2765, -2.2855],
        [-2.0102, -0.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07593034207820892
Epoch 0, Step 1074: train/loss = 0.49968594312667847, train/raw-loss = 0.4097239673137665, train/logprobs = tensor([[-0.9858, -1.2952],
        [-2.3758, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0899619534611702
Epoch 0, Step 1075: train/loss = 0.44648391008377075, train/raw-loss = 0.36855244636535645, train/logprobs = tensor([[-0.7390, -2.9738],
        [-1.3481, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0779314786195755
Epoch 0, Step 1076: train/loss = 0.4169897735118866, train/raw-loss = 0.33012768626213074, train/logprobs = tensor([[-0.7923, -3.5405],
        [-1.2210, -1.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08686207979917526
Epoch 0, Step 1077: train/loss = 0.4317319989204407, train/raw-loss = 0.35152682662010193, train/logprobs = tensor([[-0.7881, -4.5508],
        [-1.2685, -1.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08020517230033875
Epoch 0, Step 1078: train/loss = 0.3711501359939575, train/raw-loss = 0.2860080599784851, train/logprobs = tensor([[-1.3014, -5.2831],
        [-2.1758, -1.6149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08514207601547241
Epoch 0, Step 1079: train/loss = 0.36358484625816345, train/raw-loss = 0.2700178623199463, train/logprobs = tensor([[-1.0489, -5.1216],
        [-1.8972, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356699883937836
Epoch 0, Step 1080: train/loss = 0.6187524199485779, train/raw-loss = 0.5514082908630371, train/logprobs = tensor([[-0.8151, -0.5996],
        [-1.5725, -0.4126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06734417378902435
Epoch 0, Step 1081: train/loss = 0.4011981189250946, train/raw-loss = 0.3194294273853302, train/logprobs = tensor([[-0.9544, -4.0710],
        [-1.6544, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08176868408918381
Epoch 0, Step 1082: train/loss = 0.4714098274707794, train/raw-loss = 0.4021078646183014, train/logprobs = tensor([[-0.5548, -5.7976],
        [-0.7257, -2.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06930197775363922
Epoch 0, Step 1083: train/loss = 0.4008028507232666, train/raw-loss = 0.3140559792518616, train/logprobs = tensor([[-0.9311, -4.6624],
        [-1.7571, -1.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08674689382314682
Epoch 0, Step 1084: train/loss = 0.34407442808151245, train/raw-loss = 0.25095468759536743, train/logprobs = tensor([[-1.3321, -5.6524],
        [-1.9260, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09311975538730621
Epoch 0, Step 1085: train/loss = 0.6950512528419495, train/raw-loss = 0.5807065963745117, train/logprobs = tensor([[-1.4436, -2.0401],
        [-2.2638, -1.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11434470117092133
Epoch 0, Step 1086: train/loss = 0.4631771743297577, train/raw-loss = 0.38320624828338623, train/logprobs = tensor([[-0.9405, -4.1378],
        [-1.9568, -1.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07997091859579086
Epoch 0, Step 1087: train/loss = 0.6996201872825623, train/raw-loss = 0.6213968396186829, train/logprobs = tensor([[-3.3217, -3.7723],
        [-3.4910, -2.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0782233476638794
Epoch 0, Step 1088: train/loss = 0.38521915674209595, train/raw-loss = 0.29879945516586304, train/logprobs = tensor([[-1.1370, -3.6113],
        [-2.2290, -1.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08641967177391052
Epoch 0, Step 1089: train/loss = 0.4726194739341736, train/raw-loss = 0.3920937478542328, train/logprobs = tensor([[-0.8663, -3.0227],
        [-1.3766, -1.3689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0805257186293602
Epoch 0, Step 1090: train/loss = 0.3330433666706085, train/raw-loss = 0.2361217737197876, train/logprobs = tensor([[-1.0463, -2.6863],
        [-2.7462, -1.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09692155569791794
Epoch 0, Step 1091: train/loss = 0.3347529172897339, train/raw-loss = 0.2324250042438507, train/logprobs = tensor([[-1.0369, -4.7375],
        [-2.0326, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10232791304588318
Epoch 0, Step 1092: train/loss = 0.5371346473693848, train/raw-loss = 0.47463616728782654, train/logprobs = tensor([[-0.6215, -3.4941],
        [-0.8063, -1.3392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062498487532138824
Epoch 0, Step 1093: train/loss = 0.5961825847625732, train/raw-loss = 0.49905121326446533, train/logprobs = tensor([[-1.4927, -3.3649],
        [-2.4578, -1.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09713141620159149
Epoch 0, Step 1094: train/loss = 0.38103020191192627, train/raw-loss = 0.2887578010559082, train/logprobs = tensor([[-1.4036, -5.2103],
        [-1.9187, -1.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227240085601807
Epoch 0, Step 1095: train/loss = 0.3607112765312195, train/raw-loss = 0.2528011202812195, train/logprobs = tensor([[-1.1954, -2.1891],
        [-3.1391, -0.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10791013389825821
Epoch 0, Step 1096: train/loss = 0.5271546244621277, train/raw-loss = 0.437511146068573, train/logprobs = tensor([[-2.2095, -3.3659],
        [-2.7801, -0.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08964347094297409
Epoch 0, Step 1097: train/loss = 0.3312184810638428, train/raw-loss = 0.24344801902770996, train/logprobs = tensor([[-1.0543, -7.0417],
        [-1.4102, -2.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777046203613281
Epoch 0, Step 1098: train/loss = 0.45774465799331665, train/raw-loss = 0.3832581341266632, train/logprobs = tensor([[-0.8010, -4.7002],
        [-1.1185, -1.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07448650896549225
Epoch 0, Step 1099: train/loss = 0.39828845858573914, train/raw-loss = 0.3082190155982971, train/logprobs = tensor([[-0.8594, -4.0211],
        [-1.8428, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09006942808628082
Epoch 0, Step 1100: train/loss = 0.42942705750465393, train/raw-loss = 0.34460610151290894, train/logprobs = tensor([[-1.2751, -5.0203],
        [-2.0491, -1.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0848209485411644
Epoch 0, Step 1101: train/loss = 0.4674505293369293, train/raw-loss = 0.382110595703125, train/logprobs = tensor([[-1.0373, -3.9628],
        [-1.3634, -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08533994108438492
Epoch 0, Step 1102: train/loss = 0.3239114582538605, train/raw-loss = 0.2355470061302185, train/logprobs = tensor([[-1.2463, -5.1384],
        [-2.0037, -1.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08836445957422256
Epoch 0, Step 1103: train/loss = 0.3398728370666504, train/raw-loss = 0.27173566818237305, train/logprobs = tensor([[-1.0939, -4.8805],
        [-1.4808, -1.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06813718378543854
Epoch 0, Step 1104: train/loss = 0.37819355726242065, train/raw-loss = 0.3039533495903015, train/logprobs = tensor([[-0.6717, -4.1775],
        [-1.0137, -1.4556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07424018532037735
Epoch 0, Step 1105: train/loss = 0.3541657030582428, train/raw-loss = 0.27182698249816895, train/logprobs = tensor([[-1.0183, -5.7607],
        [-1.7668, -1.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08233874291181564
Epoch 0, Step 1106: train/loss = 0.2891908288002014, train/raw-loss = 0.18806125223636627, train/logprobs = tensor([[-1.2462, -3.8380],
        [-2.8265, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10112956166267395
Epoch 0, Step 1107: train/loss = 0.3131595849990845, train/raw-loss = 0.21483270823955536, train/logprobs = tensor([[-1.2213, -3.5896],
        [-2.4082, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09832686930894852
Epoch 0, Step 1108: train/loss = 0.2825169265270233, train/raw-loss = 0.1924189329147339, train/logprobs = tensor([[-1.3839, -4.6682],
        [-2.9319, -1.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009799361228943
Epoch 0, Step 1109: train/loss = 0.48562198877334595, train/raw-loss = 0.4117305874824524, train/logprobs = tensor([[-0.9257, -3.4205],
        [-0.9215, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07389138638973236
Epoch 0, Step 1110: train/loss = 0.32542335987091064, train/raw-loss = 0.23538392782211304, train/logprobs = tensor([[-1.5934, -5.7265],
        [-2.2456, -1.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900394469499588
Epoch 0, Step 1111: train/loss = 0.3860093653202057, train/raw-loss = 0.28800100088119507, train/logprobs = tensor([[-1.1004, -3.3670],
        [-2.3952, -1.4028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09800834953784943
Epoch 0, Step 1112: train/loss = 0.44027477502822876, train/raw-loss = 0.3745812773704529, train/logprobs = tensor([[-0.5920, -4.9827],
        [-0.7044, -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0656934529542923
Epoch 0, Step 1113: train/loss = 0.3529243469238281, train/raw-loss = 0.2615164518356323, train/logprobs = tensor([[-1.2583, -3.2072],
        [-2.5458, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09140791743993759
Epoch 0, Step 1114: train/loss = 0.3742801547050476, train/raw-loss = 0.295693039894104, train/logprobs = tensor([[-1.0228, -5.9071],
        [-1.0561, -1.5332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07858708500862122
Epoch 0, Step 1115: train/loss = 0.31060683727264404, train/raw-loss = 0.21062278747558594, train/logprobs = tensor([[-1.0596, -5.8747],
        [-2.3529, -1.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09998404234647751
Epoch 0, Step 1116: train/loss = 0.32718926668167114, train/raw-loss = 0.23686900734901428, train/logprobs = tensor([[-1.6469, -2.7379],
        [-3.2423, -1.2284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09032026678323746
Epoch 0, Step 1117: train/loss = 0.2538990378379822, train/raw-loss = 0.16617898643016815, train/logprobs = tensor([[-1.3709, -4.7305],
        [-3.0651, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772004395723343
Epoch 0, Step 1118: train/loss = 0.6844040751457214, train/raw-loss = 0.5981730222702026, train/logprobs = tensor([[-1.3889, -3.5549],
        [-1.9926, -2.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08623109757900238
Epoch 0, Step 1119: train/loss = 0.38016992807388306, train/raw-loss = 0.301754355430603, train/logprobs = tensor([[-0.7794, -4.5098],
        [-1.7955, -1.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07841560244560242
Epoch 0, Step 1120: train/loss = 0.2815219759941101, train/raw-loss = 0.19845153391361237, train/logprobs = tensor([[-1.0731, -6.6158],
        [-2.2014, -2.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08307044953107834
Epoch 0, Step 1121: train/loss = 0.20990218222141266, train/raw-loss = 0.10144954174757004, train/logprobs = tensor([[-1.8238, -4.4300],
        [-3.9698, -1.0933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10845264792442322
Epoch 0, Step 1122: train/loss = 0.5164183974266052, train/raw-loss = 0.41442766785621643, train/logprobs = tensor([[-0.9190, -1.6976],
        [-2.3333, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101990707218647
Epoch 0, Step 1123: train/loss = 0.45053672790527344, train/raw-loss = 0.3596193790435791, train/logprobs = tensor([[-0.8933, -3.3742],
        [-1.5225, -0.9897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09091735631227493
Epoch 0, Step 1124: train/loss = 0.23513907194137573, train/raw-loss = 0.12295398116111755, train/logprobs = tensor([[-2.0750, -3.3770],
        [-4.4867, -0.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11218508332967758
Epoch 0, Step 1125: train/loss = 0.5409629940986633, train/raw-loss = 0.47748029232025146, train/logprobs = tensor([[-0.6394, -1.7903],
        [-1.2459, -0.7204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06348268687725067
Epoch 0, Step 1126: train/loss = 0.3208981156349182, train/raw-loss = 0.23246264457702637, train/logprobs = tensor([[-1.2716, -4.6138],
        [-2.5503, -2.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843548595905304
Epoch 0, Step 1127: train/loss = 0.39598649740219116, train/raw-loss = 0.2977083921432495, train/logprobs = tensor([[-1.5366, -5.4229],
        [-1.6825, -1.5067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827812761068344
Epoch 0, Step 1128: train/loss = 0.2879970967769623, train/raw-loss = 0.1844569742679596, train/logprobs = tensor([[-1.6129, -6.2823],
        [-2.9581, -2.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10354012995958328
Epoch 0, Step 1129: train/loss = 0.5582464337348938, train/raw-loss = 0.5089411735534668, train/logprobs = tensor([[-0.7202, -2.4814],
        [-0.8311, -0.9971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049305252730846405
Epoch 0, Step 1130: train/loss = 0.4737144410610199, train/raw-loss = 0.4036562442779541, train/logprobs = tensor([[-1.0731, -3.6910],
        [-1.6272, -1.4408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07005824148654938
Epoch 0, Step 1131: train/loss = 0.3814242482185364, train/raw-loss = 0.28792038559913635, train/logprobs = tensor([[-1.3217, -4.7344],
        [-1.9026, -1.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350387006998062
Epoch 0, Step 1132: train/loss = 0.43174612522125244, train/raw-loss = 0.341131329536438, train/logprobs = tensor([[-1.3428, -2.2930],
        [-2.6957, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09061479568481445
Epoch 0, Step 1133: train/loss = 0.4227287173271179, train/raw-loss = 0.353909432888031, train/logprobs = tensor([[-1.2475, -1.5981],
        [-2.9793, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06881925463676453
Epoch 0, Step 1134: train/loss = 0.4557916522026062, train/raw-loss = 0.37512820959091187, train/logprobs = tensor([[-1.3673, -3.4491],
        [-2.2736, -1.1468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08066341280937195
Epoch 0, Step 1135: train/loss = 0.45240604877471924, train/raw-loss = 0.367795467376709, train/logprobs = tensor([[-1.3273, -2.3511],
        [-1.8347, -0.7022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08461055904626846
Epoch 0, Step 1136: train/loss = 0.47130632400512695, train/raw-loss = 0.4144573211669922, train/logprobs = tensor([[-0.4881, -4.1152],
        [-0.6036, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05684899166226387
Epoch 0, Step 1137: train/loss = 0.38627246022224426, train/raw-loss = 0.2917536199092865, train/logprobs = tensor([[-1.1517, -3.1451],
        [-2.5043, -1.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451884776353836
Epoch 0, Step 1138: train/loss = 0.5242834091186523, train/raw-loss = 0.4489120543003082, train/logprobs = tensor([[-2.0546, -2.9046],
        [-3.3110, -2.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07537131756544113
Epoch 0, Step 1139: train/loss = 0.524016261100769, train/raw-loss = 0.4504363536834717, train/logprobs = tensor([[-1.0695, -3.2341],
        [-1.8612, -1.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07357992231845856
Epoch 0, Step 1140: train/loss = 0.44775769114494324, train/raw-loss = 0.3912709951400757, train/logprobs = tensor([[-0.5752, -4.3407],
        [-0.5424, -1.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05648668110370636
Epoch 0, Step 1141: train/loss = 0.5872650146484375, train/raw-loss = 0.5301846265792847, train/logprobs = tensor([[-1.1743, -0.9759],
        [-1.8475, -0.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05708044022321701
Epoch 0, Step 1142: train/loss = 0.24071411788463593, train/raw-loss = 0.11169345676898956, train/logprobs = tensor([[-1.3797, -2.8765],
        [-4.3217, -0.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12902066111564636
Epoch 0, Step 1143: train/loss = 0.4403119385242462, train/raw-loss = 0.3717045783996582, train/logprobs = tensor([[-0.8743, -3.5475],
        [-1.1971, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06860731542110443
Epoch 0, Step 1144: train/loss = 0.37073612213134766, train/raw-loss = 0.2923021912574768, train/logprobs = tensor([[-1.1250, -4.0754],
        [-1.7577, -1.3154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07843390852212906
Epoch 0, Step 1145: train/loss = 0.38714584708213806, train/raw-loss = 0.29729965329170227, train/logprobs = tensor([[-1.1356, -3.5926],
        [-2.1453, -0.9687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0898461863398552
Epoch 0, Step 1146: train/loss = 0.44782203435897827, train/raw-loss = 0.3843606114387512, train/logprobs = tensor([[-1.2059, -2.6414],
        [-1.6831, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06346140801906586
Epoch 0, Step 1147: train/loss = 0.556238055229187, train/raw-loss = 0.498118132352829, train/logprobs = tensor([[-0.9411, -1.5378],
        [-1.4999, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058119937777519226
Epoch 0, Step 1148: train/loss = 0.5413649082183838, train/raw-loss = 0.46670690178871155, train/logprobs = tensor([[-1.1104, -1.0499],
        [-2.0851, -0.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07465799152851105
Epoch 0, Step 1149: train/loss = 0.28109684586524963, train/raw-loss = 0.18822970986366272, train/logprobs = tensor([[-1.0885, -4.3428],
        [-2.5401, -1.2533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09286713600158691
Epoch 0, Step 1150: train/loss = 0.4440153241157532, train/raw-loss = 0.36670351028442383, train/logprobs = tensor([[-0.7571, -4.3349],
        [-1.5263, -1.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07731180638074875
Epoch 0, Step 1151: train/loss = 0.44722267985343933, train/raw-loss = 0.36432716250419617, train/logprobs = tensor([[-1.5636, -2.8602],
        [-3.5670, -2.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08289551734924316
Epoch 0, Step 1152: train/loss = 0.27922379970550537, train/raw-loss = 0.2021925449371338, train/logprobs = tensor([[-1.3202, -5.6159],
        [-2.5203, -1.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07703125476837158
Epoch 0, Step 1153: train/loss = 0.40107426047325134, train/raw-loss = 0.3176465630531311, train/logprobs = tensor([[-1.0851, -3.8129],
        [-1.9306, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08342772722244263
Epoch 0, Step 1154: train/loss = 0.3989778459072113, train/raw-loss = 0.31693291664123535, train/logprobs = tensor([[-0.9222, -2.7127],
        [-1.8329, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204491436481476
Epoch 0, Step 1155: train/loss = 0.4092850685119629, train/raw-loss = 0.31998613476753235, train/logprobs = tensor([[-1.5525, -1.3314],
        [-3.6055, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08929893374443054
Epoch 0, Step 1156: train/loss = 0.360576868057251, train/raw-loss = 0.2650623917579651, train/logprobs = tensor([[-0.9241, -3.3636],
        [-2.3720, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0955144464969635
Epoch 0, Step 1157: train/loss = 0.4296470284461975, train/raw-loss = 0.34683099389076233, train/logprobs = tensor([[-0.9783, -1.6444],
        [-2.7934, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08281605690717697
Epoch 0, Step 1158: train/loss = 0.4356796145439148, train/raw-loss = 0.3619210422039032, train/logprobs = tensor([[-0.9311, -3.0672],
        [-1.8085, -0.9078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07375858724117279
Epoch 0, Step 1159: train/loss = 0.25508445501327515, train/raw-loss = 0.16992899775505066, train/logprobs = tensor([[-1.0918, -5.8312],
        [-2.1116, -1.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0851554423570633
Epoch 0, Step 1160: train/loss = 0.5628597736358643, train/raw-loss = 0.4928811490535736, train/logprobs = tensor([[-0.9923, -2.1754],
        [-0.9058, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06997863203287125
Epoch 0, Step 1161: train/loss = 0.369586706161499, train/raw-loss = 0.286216676235199, train/logprobs = tensor([[-0.8794, -3.6466],
        [-2.0744, -0.8784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08336997777223587
Epoch 0, Step 1162: train/loss = 0.37861281633377075, train/raw-loss = 0.2871650457382202, train/logprobs = tensor([[-1.1201, -2.1835],
        [-2.6521, -0.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09144775569438934
Epoch 0, Step 1163: train/loss = 0.4997309446334839, train/raw-loss = 0.41387662291526794, train/logprobs = tensor([[-1.6642, -2.3663],
        [-2.4715, -1.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08585433661937714
Epoch 0, Step 1164: train/loss = 0.37542200088500977, train/raw-loss = 0.284636527299881, train/logprobs = tensor([[-1.2988, -2.8542],
        [-2.7070, -1.0188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09078548848628998
Epoch 0, Step 1165: train/loss = 0.532310962677002, train/raw-loss = 0.46142661571502686, train/logprobs = tensor([[-0.8345, -1.5198],
        [-1.3481, -0.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07088436186313629
Epoch 0, Step 1166: train/loss = 0.3836495280265808, train/raw-loss = 0.3140439987182617, train/logprobs = tensor([[-0.8567, -2.6093],
        [-1.7870, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0696054995059967
Epoch 0, Step 1167: train/loss = 0.681916356086731, train/raw-loss = 0.6008816957473755, train/logprobs = tensor([[-0.9475, -1.6389],
        [-1.7567, -1.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08103465288877487
Epoch 0, Step 1168: train/loss = 0.5249559283256531, train/raw-loss = 0.4524706304073334, train/logprobs = tensor([[-0.9850, -1.2560],
        [-2.1020, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724853053689003
Epoch 0, Step 1169: train/loss = 0.28731197118759155, train/raw-loss = 0.20444439351558685, train/logprobs = tensor([[-1.0205, -3.9882],
        [-2.4030, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0828675925731659
Epoch 0, Step 1170: train/loss = 0.6318619251251221, train/raw-loss = 0.5737953782081604, train/logprobs = tensor([[-0.7757, -1.1301],
        [-0.8769, -0.5486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05806655436754227
Epoch 0, Step 1171: train/loss = 0.5159534215927124, train/raw-loss = 0.4463377594947815, train/logprobs = tensor([[-0.8419, -2.9001],
        [-1.1586, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06961565464735031
Epoch 0, Step 1172: train/loss = 0.49235689640045166, train/raw-loss = 0.42476391792297363, train/logprobs = tensor([[-1.0354, -3.9287],
        [-1.2974, -1.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06759299337863922
Epoch 0, Step 1173: train/loss = 0.5518887042999268, train/raw-loss = 0.4410449266433716, train/logprobs = tensor([[-1.1986, -2.8377],
        [-2.3657, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11084377765655518
Epoch 0, Step 1174: train/loss = 0.8112508058547974, train/raw-loss = 0.7285610437393188, train/logprobs = tensor([[-2.3224, -1.9064],
        [-2.3203, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268974721431732
Epoch 0, Step 1175: train/loss = 0.49998360872268677, train/raw-loss = 0.42865437269210815, train/logprobs = tensor([[-1.3444, -3.5545],
        [-2.4946, -1.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07132921367883682
Epoch 0, Step 1176: train/loss = 0.5164828896522522, train/raw-loss = 0.4199354946613312, train/logprobs = tensor([[-1.2749, -2.9035],
        [-2.2126, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654742479324341
Epoch 0, Step 1177: train/loss = 0.295515775680542, train/raw-loss = 0.21617662906646729, train/logprobs = tensor([[-1.0389, -5.4054],
        [-2.0157, -1.4821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07933913171291351
Epoch 0, Step 1178: train/loss = 0.6420344114303589, train/raw-loss = 0.5787203311920166, train/logprobs = tensor([[-1.1115, -1.5562],
        [-1.4879, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06331413984298706
Epoch 0, Step 1179: train/loss = 0.3498207628726959, train/raw-loss = 0.27698346972465515, train/logprobs = tensor([[-0.7312, -5.5534],
        [-0.8486, -1.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07283730804920197
Epoch 0, Step 1180: train/loss = 0.4716232717037201, train/raw-loss = 0.39657139778137207, train/logprobs = tensor([[-1.5220, -4.7477],
        [-2.6905, -2.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0750519260764122
Epoch 0, Step 1181: train/loss = 0.5986230969429016, train/raw-loss = 0.5145683288574219, train/logprobs = tensor([[-1.4592, -2.8677],
        [-1.8473, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840548425912857
Epoch 0, Step 1182: train/loss = 0.4465206265449524, train/raw-loss = 0.3314381241798401, train/logprobs = tensor([[-1.5603, -3.3363],
        [-3.2218, -2.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1150825172662735
Epoch 0, Step 1183: train/loss = 0.46599555015563965, train/raw-loss = 0.3973538875579834, train/logprobs = tensor([[-1.0845, -1.8480],
        [-2.3992, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06864171475172043
Epoch 0, Step 1184: train/loss = 0.6547784805297852, train/raw-loss = 0.596397876739502, train/logprobs = tensor([[-1.3420, -1.5187],
        [-1.7086, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05838058888912201
Epoch 0, Step 1185: train/loss = 0.4822514057159424, train/raw-loss = 0.4092917740345001, train/logprobs = tensor([[-1.1760, -3.4085],
        [-1.9268, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07295964658260345
Epoch 0, Step 1186: train/loss = 0.6238864064216614, train/raw-loss = 0.5298463702201843, train/logprobs = tensor([[-1.6870, -1.5420],
        [-2.3184, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09404003620147705
Epoch 0, Step 1187: train/loss = 0.4852069616317749, train/raw-loss = 0.4233779311180115, train/logprobs = tensor([[-0.8854, -3.4895],
        [-1.1195, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06182905286550522
Epoch 0, Step 1188: train/loss = 0.306390643119812, train/raw-loss = 0.22253338992595673, train/logprobs = tensor([[-0.7088, -4.5928],
        [-1.5456, -1.2376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838572233915329
Epoch 0, Step 1189: train/loss = 0.62574303150177, train/raw-loss = 0.5530565977096558, train/logprobs = tensor([[-0.9501, -2.6058],
        [-0.8513, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07268647849559784
Epoch 0, Step 1190: train/loss = 0.48962947726249695, train/raw-loss = 0.4103325605392456, train/logprobs = tensor([[-1.8165, -2.4772],
        [-2.5176, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07929694652557373
Epoch 0, Step 1191: train/loss = 0.4547174572944641, train/raw-loss = 0.37601086497306824, train/logprobs = tensor([[-0.9425, -2.2485],
        [-1.7913, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07870654761791229
Epoch 0, Step 1192: train/loss = 0.42143717408180237, train/raw-loss = 0.35599076747894287, train/logprobs = tensor([[-0.6550, -3.3728],
        [-1.3494, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0654463917016983
Epoch 0, Step 1193: train/loss = 0.47576454281806946, train/raw-loss = 0.390481561422348, train/logprobs = tensor([[-1.4903, -4.5662],
        [-1.5726, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08528298139572144
Epoch 0, Step 1194: train/loss = 0.502880334854126, train/raw-loss = 0.4179780185222626, train/logprobs = tensor([[-1.5995, -3.2118],
        [-1.9126, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08490234613418579
Epoch 0, Step 1195: train/loss = 0.3321414589881897, train/raw-loss = 0.22785334289073944, train/logprobs = tensor([[-1.2716, -2.7358],
        [-3.2801, -1.3375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10428810864686966
Epoch 0, Step 1196: train/loss = 0.7171361446380615, train/raw-loss = 0.636591911315918, train/logprobs = tensor([[-2.9092, -3.6780],
        [-2.8678, -2.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08054418861865997
Epoch 0, Step 1197: train/loss = 0.4922962188720703, train/raw-loss = 0.41387858986854553, train/logprobs = tensor([[-0.9511, -2.9943],
        [-1.6378, -1.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07841762900352478
Epoch 0, Step 1198: train/loss = 0.6397960782051086, train/raw-loss = 0.5762550234794617, train/logprobs = tensor([[-0.7287, -1.3928],
        [-1.0553, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06354106962680817
Epoch 0, Step 1199: train/loss = 0.392545223236084, train/raw-loss = 0.3158226013183594, train/logprobs = tensor([[-1.0123, -3.7540],
        [-2.2408, -1.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07672260701656342
Epoch 0, Step 1200: train/loss = 0.367207407951355, train/raw-loss = 0.300211101770401, train/logprobs = tensor([[-0.5760, -6.7145],
        [-0.7456, -2.5968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06699629873037338
Epoch 0, Step 1201: train/loss = 0.3014868497848511, train/raw-loss = 0.21420814096927643, train/logprobs = tensor([[-1.4905, -2.9288],
        [-3.8147, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08727872371673584
Epoch 0, Step 1202: train/loss = 0.5974952578544617, train/raw-loss = 0.5429314374923706, train/logprobs = tensor([[-1.3467, -2.9563],
        [-1.8640, -1.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054563842713832855
Epoch 0, Step 1203: train/loss = 0.464430570602417, train/raw-loss = 0.387945294380188, train/logprobs = tensor([[-0.8596, -4.1186],
        [-1.7250, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.076485276222229
Epoch 0, Step 1204: train/loss = 0.5891448259353638, train/raw-loss = 0.5312929749488831, train/logprobs = tensor([[-0.7954, -0.9110],
        [-1.4208, -0.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057851798832416534
Epoch 0, Step 1205: train/loss = 0.3274235129356384, train/raw-loss = 0.23946300148963928, train/logprobs = tensor([[-1.1358, -3.2136],
        [-2.4475, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08796048909425735
Epoch 0, Step 1206: train/loss = 0.44375079870224, train/raw-loss = 0.3251919150352478, train/logprobs = tensor([[-1.3598, -4.0747],
        [-3.0388, -1.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.118558868765831
Epoch 0, Step 1207: train/loss = 0.32831835746765137, train/raw-loss = 0.23945125937461853, train/logprobs = tensor([[-1.0965, -2.9482],
        [-2.6322, -0.9002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08886708319187164
Epoch 0, Step 1208: train/loss = 0.45768609642982483, train/raw-loss = 0.40443307161331177, train/logprobs = tensor([[-0.6670, -5.2557],
        [-0.6563, -2.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05325304716825485
Epoch 0, Step 1209: train/loss = 0.389889657497406, train/raw-loss = 0.31551268696784973, train/logprobs = tensor([[-1.0825, -2.6086],
        [-2.3528, -0.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437695562839508
Epoch 0, Step 1210: train/loss = 0.4934069514274597, train/raw-loss = 0.4222075343132019, train/logprobs = tensor([[-0.8574, -2.3496],
        [-1.8074, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07119942456483841
Epoch 0, Step 1211: train/loss = 0.5811420679092407, train/raw-loss = 0.5194547176361084, train/logprobs = tensor([[-1.9629, -3.3147],
        [-2.0062, -2.1594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06168728694319725
Epoch 0, Step 1212: train/loss = 0.6062604188919067, train/raw-loss = 0.5188703536987305, train/logprobs = tensor([[-2.4431, -2.6394],
        [-3.6476, -2.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08739006519317627
Epoch 0, Step 1213: train/loss = 0.47769904136657715, train/raw-loss = 0.42125609517097473, train/logprobs = tensor([[-0.6109, -3.3419],
        [-0.7284, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056442905217409134
Epoch 0, Step 1214: train/loss = 0.3766724467277527, train/raw-loss = 0.3082480728626251, train/logprobs = tensor([[-0.8572, -5.0503],
        [-1.5352, -1.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06842437386512756
Epoch 0, Step 1215: train/loss = 0.44759970903396606, train/raw-loss = 0.3645034432411194, train/logprobs = tensor([[-0.7880, -3.5049],
        [-1.3141, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08309625089168549
Epoch 0, Step 1216: train/loss = 0.47975313663482666, train/raw-loss = 0.3961223363876343, train/logprobs = tensor([[-0.7922, -3.9929],
        [-1.1560, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363077044487
Epoch 0, Step 1217: train/loss = 0.26938822865486145, train/raw-loss = 0.18951416015625, train/logprobs = tensor([[-1.0085, -6.3956],
        [-1.8206, -1.3414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07987410575151443
Epoch 0, Step 1218: train/loss = 0.45434802770614624, train/raw-loss = 0.365823894739151, train/logprobs = tensor([[-1.4788, -2.7420],
        [-2.6035, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852415531873703
Epoch 0, Step 1219: train/loss = 0.5442332029342651, train/raw-loss = 0.45379728078842163, train/logprobs = tensor([[-1.5859, -3.3690],
        [-2.0103, -2.0669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904359370470047
Epoch 0, Step 1220: train/loss = 0.4811115860939026, train/raw-loss = 0.3874601423740387, train/logprobs = tensor([[-0.9276, -5.5397],
        [-1.9156, -2.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0936514288187027
Epoch 0, Step 1221: train/loss = 0.3356611430644989, train/raw-loss = 0.2594137191772461, train/logprobs = tensor([[-1.3635, -4.5421],
        [-3.1027, -2.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07624740153551102
Epoch 0, Step 1222: train/loss = 0.2805079519748688, train/raw-loss = 0.18318071961402893, train/logprobs = tensor([[-1.5566, -4.6783],
        [-2.8314, -1.2746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09732723981142044
Epoch 0, Step 1223: train/loss = 0.6683434844017029, train/raw-loss = 0.5594974756240845, train/logprobs = tensor([[-2.0738, -3.2365],
        [-2.6415, -1.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10884598642587662
Epoch 0, Step 1224: train/loss = 0.4966951608657837, train/raw-loss = 0.4355991780757904, train/logprobs = tensor([[-0.8148, -3.7799],
        [-1.0414, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061095986515283585
Epoch 0, Step 1225: train/loss = 0.5443700551986694, train/raw-loss = 0.4582065939903259, train/logprobs = tensor([[-1.1231, -2.4864],
        [-2.4350, -1.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08616343140602112
Epoch 0, Step 1226: train/loss = 0.4922129511833191, train/raw-loss = 0.3916023075580597, train/logprobs = tensor([[-1.2046, -3.8461],
        [-2.2393, -1.1885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006106436252594
Epoch 0, Step 1227: train/loss = 0.3768737316131592, train/raw-loss = 0.3054827153682709, train/logprobs = tensor([[-1.0366, -6.3736],
        [-1.5396, -1.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07139100879430771
Epoch 0, Step 1228: train/loss = 0.48615604639053345, train/raw-loss = 0.4182002544403076, train/logprobs = tensor([[-1.2068, -3.1894],
        [-1.9802, -1.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06795582175254822
Epoch 0, Step 1229: train/loss = 0.25823110342025757, train/raw-loss = 0.16770294308662415, train/logprobs = tensor([[-0.9630, -4.6049],
        [-2.1157, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09052816033363342
Epoch 0, Step 1230: train/loss = 0.290381520986557, train/raw-loss = 0.2087872475385666, train/logprobs = tensor([[-1.2414, -5.9913],
        [-1.7470, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08159425854682922
Epoch 0, Step 1231: train/loss = 0.32735615968704224, train/raw-loss = 0.21626919507980347, train/logprobs = tensor([[-1.4915, -3.2589],
        [-3.1233, -1.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11108694225549698
Epoch 0, Step 1232: train/loss = 0.3685488700866699, train/raw-loss = 0.2997923493385315, train/logprobs = tensor([[-0.8758, -4.3589],
        [-1.3073, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06875654309988022
Epoch 0, Step 1233: train/loss = 0.4256087839603424, train/raw-loss = 0.3569141924381256, train/logprobs = tensor([[-0.5779, -3.2062],
        [-1.1892, -0.9888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06869462132453918
Epoch 0, Step 1234: train/loss = 0.530947208404541, train/raw-loss = 0.4588403105735779, train/logprobs = tensor([[-1.0880, -2.2795],
        [-1.7833, -1.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07210690528154373
Epoch 0, Step 1235: train/loss = 0.3748704195022583, train/raw-loss = 0.31158149242401123, train/logprobs = tensor([[-0.9444, -3.9173],
        [-1.2461, -0.8017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06328892707824707
Epoch 0, Step 1236: train/loss = 0.3455318212509155, train/raw-loss = 0.2496931552886963, train/logprobs = tensor([[-1.0919, -3.4884],
        [-2.1894, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09583865851163864
Epoch 0, Step 1237: train/loss = 0.45053374767303467, train/raw-loss = 0.3508269786834717, train/logprobs = tensor([[-1.1179, -3.0609],
        [-2.1703, -1.1184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09970676898956299
Epoch 0, Step 1238: train/loss = 0.6137909293174744, train/raw-loss = 0.553441047668457, train/logprobs = tensor([[-1.2205, -2.7690],
        [-1.0220, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06034991517663002
Epoch 0, Step 1239: train/loss = 0.5715107917785645, train/raw-loss = 0.5076346397399902, train/logprobs = tensor([[-2.0990, -2.0323],
        [-2.6240, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0638761967420578
Epoch 0, Step 1240: train/loss = 0.303420752286911, train/raw-loss = 0.20981790125370026, train/logprobs = tensor([[-1.0211, -3.1689],
        [-2.3610, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09360283613204956
Epoch 0, Step 1241: train/loss = 0.4862439036369324, train/raw-loss = 0.42196404933929443, train/logprobs = tensor([[-0.9164, -1.1212],
        [-2.3416, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06427983939647675
Epoch 0, Step 1242: train/loss = 0.545674204826355, train/raw-loss = 0.4667777121067047, train/logprobs = tensor([[-1.4458, -2.7630],
        [-1.7451, -1.4162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07889650017023087
Epoch 0, Step 1243: train/loss = 0.4268774092197418, train/raw-loss = 0.34455451369285583, train/logprobs = tensor([[-2.1043, -6.3730],
        [-2.2799, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08232289552688599
Epoch 0, Step 1244: train/loss = 0.3946129083633423, train/raw-loss = 0.2867952585220337, train/logprobs = tensor([[-1.6253, -3.1825],
        [-3.9103, -1.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10781767964363098
Epoch 0, Step 1245: train/loss = 0.38373932242393494, train/raw-loss = 0.29091253876686096, train/logprobs = tensor([[-1.0752, -2.9288],
        [-2.4137, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09282680600881577
Epoch 0, Step 1246: train/loss = 0.3667907118797302, train/raw-loss = 0.2779109477996826, train/logprobs = tensor([[-0.9654, -5.0985],
        [-2.1481, -2.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0888797715306282
Epoch 0, Step 1247: train/loss = 0.375080406665802, train/raw-loss = 0.28900015354156494, train/logprobs = tensor([[-0.8552, -3.6253],
        [-1.5362, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08608024567365646
Epoch 0, Step 1248: train/loss = 0.45088958740234375, train/raw-loss = 0.37141111493110657, train/logprobs = tensor([[-2.2172, -5.3875],
        [-2.6027, -2.3024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07947845011949539
Epoch 0, Step 1249: train/loss = 0.48905909061431885, train/raw-loss = 0.38942670822143555, train/logprobs = tensor([[-1.3624, -2.3527],
        [-2.5607, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09963236004114151
Epoch 0, Step 1250: train/loss = 0.43367722630500793, train/raw-loss = 0.3608914315700531, train/logprobs = tensor([[-0.9437, -2.9105],
        [-1.5743, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07278580218553543
Epoch 0, Step 1251: train/loss = 0.728369414806366, train/raw-loss = 0.6412146091461182, train/logprobs = tensor([[-0.8402, -2.9421],
        [-1.8215, -1.9007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08715479075908661
Epoch 0, Step 1252: train/loss = 0.45639950037002563, train/raw-loss = 0.37555283308029175, train/logprobs = tensor([[-1.0263, -2.1396],
        [-2.0477, -0.6668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08084670454263687
Epoch 0, Step 1253: train/loss = 0.3008304238319397, train/raw-loss = 0.21580344438552856, train/logprobs = tensor([[-1.2265, -4.2407],
        [-3.1307, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502697944641113
Epoch 0, Step 1254: train/loss = 0.3972374498844147, train/raw-loss = 0.3246372938156128, train/logprobs = tensor([[-0.6659, -4.6829],
        [-1.0054, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07260014116764069
Epoch 0, Step 1255: train/loss = 0.42253780364990234, train/raw-loss = 0.3291251063346863, train/logprobs = tensor([[-0.9348, -2.8663],
        [-2.0841, -1.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341271966695786
Epoch 0, Step 1256: train/loss = 0.4750608503818512, train/raw-loss = 0.3972586989402771, train/logprobs = tensor([[-0.9962, -3.2066],
        [-1.4998, -0.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07780217379331589
Epoch 0, Step 1257: train/loss = 0.346893310546875, train/raw-loss = 0.2686174809932709, train/logprobs = tensor([[-1.1762, -3.1275],
        [-2.3285, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07827584445476532
Epoch 0, Step 1258: train/loss = 0.612250030040741, train/raw-loss = 0.5486389398574829, train/logprobs = tensor([[-0.7904, -2.3917],
        [-1.3618, -1.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06361113488674164
Epoch 0, Step 1259: train/loss = 0.37661248445510864, train/raw-loss = 0.310372918844223, train/logprobs = tensor([[-1.0191, -3.1233],
        [-1.6902, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06623957306146622
Epoch 0, Step 1260: train/loss = 0.3425883650779724, train/raw-loss = 0.24184145033359528, train/logprobs = tensor([[-1.5019, -4.3172],
        [-2.6007, -1.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10074692219495773
Epoch 0, Step 1261: train/loss = 0.3110710382461548, train/raw-loss = 0.2215147316455841, train/logprobs = tensor([[-1.0543, -4.3734],
        [-2.3043, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08955629169940948
Epoch 0, Step 1262: train/loss = 0.49505019187927246, train/raw-loss = 0.42460381984710693, train/logprobs = tensor([[-0.7266, -3.4482],
        [-1.0645, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07044641673564911
Epoch 0, Step 1263: train/loss = 0.49653109908103943, train/raw-loss = 0.43048232793807983, train/logprobs = tensor([[-0.5556, -2.3658],
        [-0.8563, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.066048763692379
Epoch 0, Step 1264: train/loss = 0.42109036445617676, train/raw-loss = 0.34664011001586914, train/logprobs = tensor([[-0.7892, -3.1473],
        [-1.6831, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07445023953914642
Epoch 0, Step 1265: train/loss = 0.46679505705833435, train/raw-loss = 0.3804183602333069, train/logprobs = tensor([[-1.6013, -2.4578],
        [-2.2905, -0.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08637665212154388
Epoch 0, Step 1266: train/loss = 0.3371075987815857, train/raw-loss = 0.2551860511302948, train/logprobs = tensor([[-1.0358, -5.2889],
        [-2.0335, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192156255245209
Epoch 0, Step 1267: train/loss = 0.7188189029693604, train/raw-loss = 0.6420977115631104, train/logprobs = tensor([[-1.1388, -1.9545],
        [-1.6643, -2.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07672114670276642
Epoch 0, Step 1268: train/loss = 0.5308337807655334, train/raw-loss = 0.47436797618865967, train/logprobs = tensor([[-0.5111, -1.9705],
        [-0.7420, -0.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05646584928035736
Epoch 0, Step 1269: train/loss = 0.3901216983795166, train/raw-loss = 0.2953585982322693, train/logprobs = tensor([[-0.8214, -3.2690],
        [-1.8637, -0.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947631374001503
Epoch 0, Step 1270: train/loss = 0.2873188853263855, train/raw-loss = 0.1969866305589676, train/logprobs = tensor([[-1.3188, -4.5596],
        [-2.2408, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09033221751451492
Epoch 0, Step 1271: train/loss = 0.34521931409835815, train/raw-loss = 0.2676791250705719, train/logprobs = tensor([[-0.6656, -4.5070],
        [-1.3183, -1.5671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07754017412662506
Epoch 0, Step 1272: train/loss = 0.8106499314308167, train/raw-loss = 0.7494528889656067, train/logprobs = tensor([[-0.6297, -1.0361],
        [-0.9218, -1.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06119704619050026
Epoch 0, Step 1273: train/loss = 0.48143085837364197, train/raw-loss = 0.4091564416885376, train/logprobs = tensor([[-0.8897, -1.5350],
        [-1.8598, -0.7312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07227441668510437
Epoch 0, Step 1274: train/loss = 0.4379675090312958, train/raw-loss = 0.3606197237968445, train/logprobs = tensor([[-1.0224, -3.9913],
        [-2.5868, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734780013561249
Epoch 0, Step 1275: train/loss = 0.3505023121833801, train/raw-loss = 0.256091833114624, train/logprobs = tensor([[-1.2273, -4.3374],
        [-2.5184, -1.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0944104716181755
Epoch 0, Step 1276: train/loss = 0.4761262536048889, train/raw-loss = 0.39674559235572815, train/logprobs = tensor([[-1.3356, -2.3673],
        [-2.6138, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938066869974136
Epoch 0, Step 1277: train/loss = 0.42836877703666687, train/raw-loss = 0.364434152841568, train/logprobs = tensor([[-0.7400, -3.5171],
        [-1.1756, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06393459439277649
Epoch 0, Step 1278: train/loss = 0.467932790517807, train/raw-loss = 0.39638692140579224, train/logprobs = tensor([[-1.1774, -3.3119],
        [-1.4061, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07154587656259537
Epoch 0, Step 1279: train/loss = 0.38149765133857727, train/raw-loss = 0.3062545359134674, train/logprobs = tensor([[-0.5350, -4.0919],
        [-1.4096, -1.3247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07524312287569046
Epoch 0, Step 1280: train/loss = 0.4520925283432007, train/raw-loss = 0.3733060359954834, train/logprobs = tensor([[-1.4177, -2.9792],
        [-2.0401, -1.3804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07878647744655609
Epoch 0, Step 1281: train/loss = 0.3292795419692993, train/raw-loss = 0.26293009519577026, train/logprobs = tensor([[-0.4645, -4.4572],
        [-0.8530, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06634945422410965
Epoch 0, Step 1282: train/loss = 0.36526644229888916, train/raw-loss = 0.2805520296096802, train/logprobs = tensor([[-1.0726, -4.0759],
        [-2.0821, -1.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08471442759037018
Epoch 0, Step 1283: train/loss = 0.6292327046394348, train/raw-loss = 0.5774376392364502, train/logprobs = tensor([[-0.5825, -1.6803],
        [-0.6231, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05179505795240402
Epoch 0, Step 1284: train/loss = 0.5402528047561646, train/raw-loss = 0.4686936140060425, train/logprobs = tensor([[-1.3438, -3.4754],
        [-1.9172, -1.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07155919075012207
Epoch 0, Step 1285: train/loss = 0.5556322336196899, train/raw-loss = 0.4611436724662781, train/logprobs = tensor([[-1.4410, -2.4106],
        [-2.5540, -1.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09448853135108948
Epoch 0, Step 1286: train/loss = 0.5335196852684021, train/raw-loss = 0.46731024980545044, train/logprobs = tensor([[-1.8059, -1.7982],
        [-3.3242, -1.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06620940566062927
Epoch 0, Step 1287: train/loss = 0.49549850821495056, train/raw-loss = 0.4118492603302002, train/logprobs = tensor([[-1.0575, -3.2002],
        [-2.0967, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08364922553300858
Epoch 0, Step 1288: train/loss = 0.46215391159057617, train/raw-loss = 0.3689230680465698, train/logprobs = tensor([[-1.0698, -3.3533],
        [-1.5866, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323083609342575
Epoch 0, Step 1289: train/loss = 0.8854081630706787, train/raw-loss = 0.788118839263916, train/logprobs = tensor([[-2.2355, -2.5890],
        [-1.9927, -1.8502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09728942811489105
Epoch 0, Step 1290: train/loss = 0.667344331741333, train/raw-loss = 0.5728143453598022, train/logprobs = tensor([[-1.9930, -4.5120],
        [-2.8153, -2.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09452994912862778
Epoch 0, Step 1291: train/loss = 0.47660085558891296, train/raw-loss = 0.40144291520118713, train/logprobs = tensor([[-0.9724, -3.2645],
        [-1.9392, -1.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07515791803598404
Epoch 0, Step 1292: train/loss = 0.46403148770332336, train/raw-loss = 0.3892991840839386, train/logprobs = tensor([[-1.5275, -2.4388],
        [-2.2226, -0.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07473231852054596
Epoch 0, Step 1293: train/loss = 0.3600861132144928, train/raw-loss = 0.29629936814308167, train/logprobs = tensor([[-1.1962, -5.4557],
        [-1.6806, -2.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06378675252199173
Epoch 0, Step 1294: train/loss = 0.449746698141098, train/raw-loss = 0.3753281831741333, train/logprobs = tensor([[-0.7123, -3.2050],
        [-1.4257, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441850006580353
Epoch 0, Step 1295: train/loss = 0.35126179456710815, train/raw-loss = 0.26577746868133545, train/logprobs = tensor([[-0.8603, -2.5125],
        [-2.9151, -0.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08548430353403091
Epoch 0, Step 1296: train/loss = 0.4567068815231323, train/raw-loss = 0.3762221336364746, train/logprobs = tensor([[-1.0167, -1.5962],
        [-2.5047, -0.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08048475533723831
Epoch 0, Step 1297: train/loss = 0.49567726254463196, train/raw-loss = 0.438545286655426, train/logprobs = tensor([[-0.6393, -2.6780],
        [-0.8756, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057131972163915634
Epoch 0, Step 1298: train/loss = 0.4546269476413727, train/raw-loss = 0.3691848814487457, train/logprobs = tensor([[-1.8568, -2.1119],
        [-2.6515, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08544211089611053
Epoch 0, Step 1299: train/loss = 0.5046829581260681, train/raw-loss = 0.42240217328071594, train/logprobs = tensor([[-0.8261, -3.5727],
        [-0.8426, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08228076994419098
Epoch 0, Step 1300: train/loss = 0.3637002408504486, train/raw-loss = 0.2855803072452545, train/logprobs = tensor([[-0.8322, -4.2315],
        [-1.6252, -1.0579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07811993360519409
Epoch 0, Step 1301: train/loss = 0.5424729585647583, train/raw-loss = 0.49080610275268555, train/logprobs = tensor([[-0.6589, -3.0134],
        [-0.9509, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051666878163814545
Epoch 0, Step 1302: train/loss = 0.29019895195961, train/raw-loss = 0.1945718675851822, train/logprobs = tensor([[-1.0957, -2.6543],
        [-2.9761, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956270843744278
Epoch 0, Step 1303: train/loss = 0.3856903314590454, train/raw-loss = 0.3089083731174469, train/logprobs = tensor([[-1.0695, -2.9568],
        [-1.9021, -1.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07678195089101791
Epoch 0, Step 1304: train/loss = 0.28413861989974976, train/raw-loss = 0.1822635531425476, train/logprobs = tensor([[-0.9326, -3.3979],
        [-2.7016, -0.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10187507420778275
Epoch 0, Step 1305: train/loss = 0.4173935651779175, train/raw-loss = 0.32802915573120117, train/logprobs = tensor([[-0.8391, -3.4021],
        [-1.8811, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08936439454555511
Epoch 0, Step 1306: train/loss = 0.28087788820266724, train/raw-loss = 0.19515292346477509, train/logprobs = tensor([[-0.9018, -3.9744],
        [-2.2739, -0.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08572497218847275
Epoch 0, Step 1307: train/loss = 0.41257572174072266, train/raw-loss = 0.3329547047615051, train/logprobs = tensor([[-0.9779, -3.8156],
        [-2.4245, -1.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07962100207805634
Epoch 0, Step 1308: train/loss = 0.6085731983184814, train/raw-loss = 0.5331472158432007, train/logprobs = tensor([[-1.7859, -2.2072],
        [-2.3656, -1.3081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07542602717876434
Epoch 0, Step 1309: train/loss = 0.21343109011650085, train/raw-loss = 0.11204492300748825, train/logprobs = tensor([[-0.9971, -3.8449],
        [-3.7272, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013861671090126
Epoch 0, Step 1310: train/loss = 0.6470977663993835, train/raw-loss = 0.5738221406936646, train/logprobs = tensor([[-1.5478, -3.4572],
        [-0.8641, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327565550804138
Epoch 0, Step 1311: train/loss = 0.4386238157749176, train/raw-loss = 0.3544014096260071, train/logprobs = tensor([[-1.3782, -2.7295],
        [-2.3827, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08422238379716873
Epoch 0, Step 1312: train/loss = 0.5406947135925293, train/raw-loss = 0.4582538604736328, train/logprobs = tensor([[-1.7289, -3.8008],
        [-2.1938, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08244085311889648
Epoch 0, Step 1313: train/loss = 0.3683964014053345, train/raw-loss = 0.2887759804725647, train/logprobs = tensor([[-0.7236, -3.9703],
        [-1.3130, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07962043583393097
Epoch 0, Step 1314: train/loss = 0.35646218061447144, train/raw-loss = 0.25607261061668396, train/logprobs = tensor([[-1.0813, -3.3963],
        [-2.5234, -1.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10038958489894867
Epoch 0, Step 1315: train/loss = 0.29294246435165405, train/raw-loss = 0.18994395434856415, train/logprobs = tensor([[-0.9281, -3.2466],
        [-2.5822, -0.7463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1029985174536705
Epoch 0, Step 1316: train/loss = 0.32454705238342285, train/raw-loss = 0.23605182766914368, train/logprobs = tensor([[-1.1400, -2.7286],
        [-2.8287, -0.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08849523216485977
Epoch 0, Step 1317: train/loss = 0.6377872228622437, train/raw-loss = 0.5568627119064331, train/logprobs = tensor([[-1.7883, -3.1870],
        [-1.8035, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092460036277771
Epoch 0, Step 1318: train/loss = 0.5306960344314575, train/raw-loss = 0.47618094086647034, train/logprobs = tensor([[-0.6658, -1.4283],
        [-1.3222, -0.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05451509729027748
Epoch 0, Step 1319: train/loss = 0.2901448905467987, train/raw-loss = 0.17814239859580994, train/logprobs = tensor([[-1.1900, -3.3433],
        [-3.2493, -0.7868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11200247704982758
Epoch 0, Step 1320: train/loss = 0.3353799879550934, train/raw-loss = 0.25381967425346375, train/logprobs = tensor([[-0.6558, -4.8664],
        [-1.4042, -1.2245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08156031370162964
Epoch 0, Step 1321: train/loss = 0.3867909014225006, train/raw-loss = 0.2974676489830017, train/logprobs = tensor([[-1.1799, -3.5176],
        [-2.1132, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0893232449889183
Epoch 0, Step 1322: train/loss = 0.2959533929824829, train/raw-loss = 0.18995381891727448, train/logprobs = tensor([[-1.2217, -2.4376],
        [-4.1621, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599958151578903
Epoch 0, Step 1323: train/loss = 0.47587817907333374, train/raw-loss = 0.3681168258190155, train/logprobs = tensor([[-0.8463, -2.0271],
        [-1.7222, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10776138305664062
Epoch 0, Step 1324: train/loss = 0.26535293459892273, train/raw-loss = 0.16859720647335052, train/logprobs = tensor([[-1.1081, -5.1155],
        [-2.9854, -1.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09675572067499161
Epoch 0, Step 1325: train/loss = 0.258664608001709, train/raw-loss = 0.16228684782981873, train/logprobs = tensor([[-0.9255, -4.1840],
        [-2.6250, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09637776762247086
Epoch 0, Step 1326: train/loss = 0.4348907470703125, train/raw-loss = 0.3679892420768738, train/logprobs = tensor([[-1.3800, -2.8650],
        [-2.9807, -1.2252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06690152734518051
Epoch 0, Step 1327: train/loss = 0.5362245440483093, train/raw-loss = 0.44436031579971313, train/logprobs = tensor([[-1.5932, -3.0451],
        [-1.8641, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09186425805091858
Epoch 0, Step 1328: train/loss = 0.6199507713317871, train/raw-loss = 0.571662187576294, train/logprobs = tensor([[-1.8264, -3.9204],
        [-0.9175, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048288632184267044
Epoch 0, Step 1329: train/loss = 0.6358255743980408, train/raw-loss = 0.5410874485969543, train/logprobs = tensor([[-2.1536, -1.7398],
        [-2.9732, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473812580108643
Epoch 0, Step 1330: train/loss = 0.5413677096366882, train/raw-loss = 0.4396027624607086, train/logprobs = tensor([[-1.3973, -4.1036],
        [-4.2756, -2.2780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176494717597961
Epoch 0, Step 1331: train/loss = 0.3130556344985962, train/raw-loss = 0.21603430807590485, train/logprobs = tensor([[-0.7962, -4.5804],
        [-1.6690, -1.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09702133387327194
Epoch 0, Step 1332: train/loss = 0.3839147090911865, train/raw-loss = 0.2931019961833954, train/logprobs = tensor([[-1.6864, -3.6755],
        [-2.9870, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09081272035837173
Epoch 0, Step 1333: train/loss = 0.5789765119552612, train/raw-loss = 0.49062496423721313, train/logprobs = tensor([[-1.0681, -2.2334],
        [-1.5224, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08835150301456451
Epoch 0, Step 1334: train/loss = 0.3901820480823517, train/raw-loss = 0.3204798996448517, train/logprobs = tensor([[-0.8185, -3.4035],
        [-2.0357, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0697021484375
Epoch 0, Step 1335: train/loss = 0.4766618609428406, train/raw-loss = 0.40649911761283875, train/logprobs = tensor([[-0.5984, -2.3939],
        [-1.7599, -0.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07016275823116302
Epoch 0, Step 1336: train/loss = 0.544950544834137, train/raw-loss = 0.4669213891029358, train/logprobs = tensor([[-0.9669, -3.2988],
        [-1.9101, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07802917063236237
Epoch 0, Step 1337: train/loss = 0.4700518846511841, train/raw-loss = 0.3652399182319641, train/logprobs = tensor([[-1.2965, -4.3582],
        [-3.6379, -1.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10481195896863937
Epoch 0, Step 1338: train/loss = 0.49269694089889526, train/raw-loss = 0.42946869134902954, train/logprobs = tensor([[-0.9010, -1.9003],
        [-1.8663, -0.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06322826445102692
Epoch 0, Step 1339: train/loss = 0.22952735424041748, train/raw-loss = 0.13566845655441284, train/logprobs = tensor([[-1.0553, -5.6205],
        [-2.6904, -1.1764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09385888278484344
Epoch 0, Step 1340: train/loss = 0.3699730634689331, train/raw-loss = 0.3022695779800415, train/logprobs = tensor([[-0.9387, -4.0983],
        [-1.6927, -1.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0677034854888916
Epoch 0, Step 1341: train/loss = 0.6119852066040039, train/raw-loss = 0.5512071847915649, train/logprobs = tensor([[-1.0375, -2.6483],
        [-1.5141, -1.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06077805534005165
Epoch 0, Step 1342: train/loss = 0.2902371287345886, train/raw-loss = 0.21126864850521088, train/logprobs = tensor([[-1.6367, -2.9254],
        [-4.2358, -1.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07896845787763596
Epoch 0, Step 1343: train/loss = 0.23017561435699463, train/raw-loss = 0.1126324012875557, train/logprobs = tensor([[-1.0884, -5.1824],
        [-3.5258, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754320561885834
Epoch 0, Step 1344: train/loss = 0.43526366353034973, train/raw-loss = 0.33889666199684143, train/logprobs = tensor([[-1.7197, -2.6832],
        [-3.4847, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963670164346695
Epoch 0, Step 1345: train/loss = 0.3949083089828491, train/raw-loss = 0.30557680130004883, train/logprobs = tensor([[-1.5676, -2.5810],
        [-2.8000, -0.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08933150768280029
Epoch 0, Step 1346: train/loss = 0.318649560213089, train/raw-loss = 0.22785553336143494, train/logprobs = tensor([[-0.8631, -3.8863],
        [-1.9585, -1.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09079402685165405
Epoch 0, Step 1347: train/loss = 0.7343404293060303, train/raw-loss = 0.6552704572677612, train/logprobs = tensor([[-0.9266, -3.6103],
        [-1.6364, -2.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906994223594666
Epoch 0, Step 1348: train/loss = 0.5953736305236816, train/raw-loss = 0.5267018675804138, train/logprobs = tensor([[-1.4956, -2.4346],
        [-1.9028, -1.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06867174059152603
Epoch 0, Step 1349: train/loss = 0.5335812568664551, train/raw-loss = 0.4817280173301697, train/logprobs = tensor([[-0.6211, -2.9029],
        [-0.6554, -0.7785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05185320973396301
Epoch 0, Step 1350: train/loss = 0.9360007047653198, train/raw-loss = 0.8407416343688965, train/logprobs = tensor([[-1.9262, -1.7780],
        [-2.9468, -2.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09525910019874573
Epoch 0, Step 1351: train/loss = 0.25492119789123535, train/raw-loss = 0.15676261484622955, train/logprobs = tensor([[-1.2818, -4.0404],
        [-3.1585, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09815859794616699
Epoch 0, Step 1352: train/loss = 0.34795549511909485, train/raw-loss = 0.277798056602478, train/logprobs = tensor([[-0.5233, -4.7320],
        [-0.8692, -1.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07015744596719742
Epoch 0, Step 1353: train/loss = 0.3457493782043457, train/raw-loss = 0.25450441241264343, train/logprobs = tensor([[-1.1216, -2.8971],
        [-2.2924, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09124496579170227
Epoch 0, Step 1354: train/loss = 0.3812296688556671, train/raw-loss = 0.3200964331626892, train/logprobs = tensor([[-1.1112, -3.0467],
        [-2.3785, -0.5169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06113320589065552
Epoch 0, Step 1355: train/loss = 0.40918099880218506, train/raw-loss = 0.3391224145889282, train/logprobs = tensor([[-1.3953, -3.0800],
        [-2.5860, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07005856186151505
Epoch 0, Step 1356: train/loss = 0.43035513162612915, train/raw-loss = 0.3590207099914551, train/logprobs = tensor([[-0.9170, -3.4633],
        [-1.3619, -0.8937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07133442908525467
Epoch 0, Step 1357: train/loss = 0.6110002994537354, train/raw-loss = 0.535844624042511, train/logprobs = tensor([[-0.5623, -1.7602],
        [-0.9670, -1.2621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07515566796064377
Epoch 0, Step 1358: train/loss = 0.27210915088653564, train/raw-loss = 0.17525121569633484, train/logprobs = tensor([[-1.0480, -4.7002],
        [-2.9988, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096857950091362
Epoch 0, Step 1359: train/loss = 0.347861111164093, train/raw-loss = 0.27214837074279785, train/logprobs = tensor([[-0.7060, -3.1903],
        [-2.0502, -0.5940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07571271061897278
Epoch 0, Step 1360: train/loss = 0.6981372237205505, train/raw-loss = 0.6422666311264038, train/logprobs = tensor([[-2.0182, -3.9081],
        [-1.5371, -1.7650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0558706596493721
Epoch 0, Step 1361: train/loss = 0.45468154549598694, train/raw-loss = 0.3676031231880188, train/logprobs = tensor([[-0.9654, -3.2769],
        [-1.7701, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08707844465970993
Epoch 0, Step 1362: train/loss = 0.6133419275283813, train/raw-loss = 0.5542857646942139, train/logprobs = tensor([[-0.5324, -2.1977],
        [-1.0896, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05905614048242569
Epoch 0, Step 1363: train/loss = 0.3712306618690491, train/raw-loss = 0.27399712800979614, train/logprobs = tensor([[-0.7941, -3.2157],
        [-2.5662, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09723353385925293
Epoch 0, Step 1364: train/loss = 0.41221025586128235, train/raw-loss = 0.3240698575973511, train/logprobs = tensor([[-0.7292, -2.8709],
        [-1.8908, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08814040571451187
Epoch 0, Step 1365: train/loss = 0.4887934625148773, train/raw-loss = 0.4043385982513428, train/logprobs = tensor([[-0.9100, -1.7255],
        [-2.7335, -0.8916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445481956005096
Epoch 0, Step 1366: train/loss = 0.4787150025367737, train/raw-loss = 0.3928753137588501, train/logprobs = tensor([[-1.6129, -3.5192],
        [-1.9073, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0858396589756012
Epoch 0, Step 1367: train/loss = 0.4388781189918518, train/raw-loss = 0.3762627840042114, train/logprobs = tensor([[-0.5093, -2.9954],
        [-0.7451, -0.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06261534243822098
Epoch 0, Step 1368: train/loss = 0.3181580901145935, train/raw-loss = 0.22158312797546387, train/logprobs = tensor([[-0.6569, -3.8701],
        [-1.7303, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657496958971024
Epoch 0, Step 1369: train/loss = 0.26268860697746277, train/raw-loss = 0.17098718881607056, train/logprobs = tensor([[-0.8074, -5.1681],
        [-1.9479, -0.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09170142561197281
Epoch 0, Step 1370: train/loss = 0.28179001808166504, train/raw-loss = 0.17875416576862335, train/logprobs = tensor([[-1.0654, -3.7621],
        [-3.5604, -1.1739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10303585231304169
Epoch 0, Step 1371: train/loss = 0.4853073060512543, train/raw-loss = 0.39543578028678894, train/logprobs = tensor([[-1.1988, -1.8271],
        [-2.9724, -0.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987154811620712
Epoch 0, Step 1372: train/loss = 0.389676570892334, train/raw-loss = 0.30391377210617065, train/logprobs = tensor([[-0.9578, -2.6773],
        [-2.4622, -0.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08576279133558273
Epoch 0, Step 1373: train/loss = 0.2836571931838989, train/raw-loss = 0.18578942120075226, train/logprobs = tensor([[-1.0169, -4.0834],
        [-2.6972, -1.2553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09786774218082428
Epoch 0, Step 1374: train/loss = 0.2969290316104889, train/raw-loss = 0.19249635934829712, train/logprobs = tensor([[-0.8475, -5.1168],
        [-2.4100, -1.3586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10443268716335297
Epoch 0, Step 1375: train/loss = 0.4965331256389618, train/raw-loss = 0.4078451991081238, train/logprobs = tensor([[-0.8027, -2.7005],
        [-1.5199, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08868791908025742
Epoch 0, Step 1376: train/loss = 0.5203938484191895, train/raw-loss = 0.4548734128475189, train/logprobs = tensor([[-0.5455, -2.9350],
        [-0.8833, -0.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06552044302225113
Epoch 0, Step 1377: train/loss = 0.34495824575424194, train/raw-loss = 0.24615263938903809, train/logprobs = tensor([[-1.1619, -4.3824],
        [-2.6397, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09880560636520386
Epoch 0, Step 1378: train/loss = 0.2454034686088562, train/raw-loss = 0.12349270284175873, train/logprobs = tensor([[-1.1038, -4.0478],
        [-3.9313, -0.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12191076576709747
Epoch 0, Step 1379: train/loss = 0.44717323780059814, train/raw-loss = 0.34917303919792175, train/logprobs = tensor([[-0.9057, -2.9063],
        [-1.8770, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980001762509346
Epoch 0, Step 1380: train/loss = 0.48408761620521545, train/raw-loss = 0.4020192623138428, train/logprobs = tensor([[-0.7463, -2.6164],
        [-1.9478, -0.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206833899021149
Epoch 0, Step 1381: train/loss = 0.28624874353408813, train/raw-loss = 0.1935850828886032, train/logprobs = tensor([[-0.9197, -3.8296],
        [-2.9004, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09266366064548492
Epoch 0, Step 1382: train/loss = 0.2546190023422241, train/raw-loss = 0.1335507482290268, train/logprobs = tensor([[-1.3268, -4.4688],
        [-3.7223, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12106826901435852
Epoch 0, Step 1383: train/loss = 0.3951007127761841, train/raw-loss = 0.2899332046508789, train/logprobs = tensor([[-1.3265, -3.2816],
        [-2.9290, -1.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10516747832298279
Epoch 0, Step 1384: train/loss = 0.24122679233551025, train/raw-loss = 0.1596595197916031, train/logprobs = tensor([[-1.1041, -5.1399],
        [-2.5151, -0.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08156726509332657
Epoch 0, Step 1385: train/loss = 0.36467888951301575, train/raw-loss = 0.26307621598243713, train/logprobs = tensor([[-1.1616, -2.4406],
        [-3.1036, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10160267353057861
Epoch 0, Step 1386: train/loss = 0.36085060238838196, train/raw-loss = 0.2629217803478241, train/logprobs = tensor([[-1.4528, -4.2191],
        [-2.9346, -2.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09792880713939667
Epoch 0, Step 1387: train/loss = 0.4476673901081085, train/raw-loss = 0.3421285152435303, train/logprobs = tensor([[-1.7155, -3.3081],
        [-2.8444, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10553884506225586
Epoch 0, Step 1388: train/loss = 0.4819871783256531, train/raw-loss = 0.39890891313552856, train/logprobs = tensor([[-1.2773, -3.2451],
        [-1.3769, -0.5954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830782800912857
Epoch 0, Step 1389: train/loss = 0.3499504327774048, train/raw-loss = 0.26745641231536865, train/logprobs = tensor([[-0.6287, -4.3430],
        [-1.6271, -1.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08249402046203613
Epoch 0, Step 1390: train/loss = 0.45100826025009155, train/raw-loss = 0.39079537987709045, train/logprobs = tensor([[-0.7031, -3.0760],
        [-1.3850, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06021285802125931
Epoch 0, Step 1391: train/loss = 0.23566028475761414, train/raw-loss = 0.1407896727323532, train/logprobs = tensor([[-0.9264, -4.1997],
        [-3.3474, -0.6548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09487061947584152
Epoch 0, Step 1392: train/loss = 0.36234936118125916, train/raw-loss = 0.29159048199653625, train/logprobs = tensor([[-0.8345, -4.0314],
        [-1.8176, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07075890153646469
Epoch 0, Step 1393: train/loss = 0.29386281967163086, train/raw-loss = 0.18396255373954773, train/logprobs = tensor([[-0.8136, -3.8884],
        [-2.7957, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10990026593208313
Epoch 0, Step 1394: train/loss = 0.27387356758117676, train/raw-loss = 0.17390862107276917, train/logprobs = tensor([[-0.7108, -5.5475],
        [-2.0135, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09996495395898819
Epoch 0, Step 1395: train/loss = 0.39569777250289917, train/raw-loss = 0.3103867769241333, train/logprobs = tensor([[-0.7720, -3.9227],
        [-2.1771, -1.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08531096577644348
Epoch 0, Step 1396: train/loss = 0.595646858215332, train/raw-loss = 0.5216010808944702, train/logprobs = tensor([[-1.1371, -2.5940],
        [-2.5678, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07404575496912003
Epoch 0, Step 1397: train/loss = 0.45333176851272583, train/raw-loss = 0.35516953468322754, train/logprobs = tensor([[-1.4070, -3.0268],
        [-2.4785, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981622189283371
Epoch 0, Step 1398: train/loss = 0.2465667426586151, train/raw-loss = 0.1419319212436676, train/logprobs = tensor([[-0.7982, -5.2154],
        [-2.2591, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10463482141494751
Epoch 0, Step 1399: train/loss = 0.5893510580062866, train/raw-loss = 0.5062218904495239, train/logprobs = tensor([[-1.5013, -3.5949],
        [-1.4021, -1.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0831291601061821
Epoch 0, Step 1400: train/loss = 0.4836764931678772, train/raw-loss = 0.4061845541000366, train/logprobs = tensor([[-0.5986, -2.8102],
        [-1.6618, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07749195396900177
Epoch 0, Step 1401: train/loss = 0.49123263359069824, train/raw-loss = 0.3960331976413727, train/logprobs = tensor([[-1.0247, -2.1151],
        [-2.5234, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519945830106735
Epoch 0, Step 1402: train/loss = 0.47240808606147766, train/raw-loss = 0.3805878460407257, train/logprobs = tensor([[-0.8184, -3.5551],
        [-1.6464, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182027727365494
Epoch 0, Step 1403: train/loss = 0.41934651136398315, train/raw-loss = 0.3081694543361664, train/logprobs = tensor([[-1.8369, -5.1346],
        [-2.8893, -0.8850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11117707192897797
Epoch 0, Step 1404: train/loss = 0.31334444880485535, train/raw-loss = 0.2482980340719223, train/logprobs = tensor([[-0.7742, -4.9610],
        [-1.8477, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06504640728235245
Epoch 0, Step 1405: train/loss = 0.494576632976532, train/raw-loss = 0.4351324439048767, train/logprobs = tensor([[-0.5952, -2.2249],
        [-1.5645, -0.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059444159269332886
Epoch 0, Step 1406: train/loss = 0.45897728204727173, train/raw-loss = 0.36878758668899536, train/logprobs = tensor([[-1.1025, -2.7349],
        [-2.0663, -0.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09018966555595398
Epoch 0, Step 1407: train/loss = 0.7347276210784912, train/raw-loss = 0.6575335264205933, train/logprobs = tensor([[-2.4501, -3.1485],
        [-2.7659, -1.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07719406485557556
Epoch 0, Step 1408: train/loss = 0.412120521068573, train/raw-loss = 0.3469272553920746, train/logprobs = tensor([[-0.5406, -4.5714],
        [-0.7849, -0.8765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06519324332475662
Epoch 0, Step 1409: train/loss = 0.3170935809612274, train/raw-loss = 0.23546430468559265, train/logprobs = tensor([[-0.7866, -3.8235],
        [-1.8219, -0.4919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08162929117679596
Epoch 0, Step 1410: train/loss = 0.46726250648498535, train/raw-loss = 0.4016990661621094, train/logprobs = tensor([[-0.7866, -3.1079],
        [-1.0851, -0.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06556342542171478
Epoch 0, Step 1411: train/loss = 0.38657575845718384, train/raw-loss = 0.30700597167015076, train/logprobs = tensor([[-1.2365, -2.2223],
        [-2.6365, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07956980913877487
Epoch 0, Step 1412: train/loss = 0.35121506452560425, train/raw-loss = 0.26111772656440735, train/logprobs = tensor([[-0.9069, -2.7752],
        [-3.4607, -0.3723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009730815887451
Epoch 0, Step 1413: train/loss = 0.2415345311164856, train/raw-loss = 0.14065971970558167, train/logprobs = tensor([[-1.0092, -5.5404],
        [-2.5351, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10087480396032333
Epoch 0, Step 1414: train/loss = 0.30542194843292236, train/raw-loss = 0.2324586659669876, train/logprobs = tensor([[-0.7479, -4.4100],
        [-1.3649, -0.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07296329736709595
Epoch 0, Step 1415: train/loss = 0.3908083140850067, train/raw-loss = 0.3027651906013489, train/logprobs = tensor([[-0.9788, -4.5740],
        [-1.0912, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08804311603307724
Epoch 0, Step 1416: train/loss = 0.4724518656730652, train/raw-loss = 0.4158409833908081, train/logprobs = tensor([[-0.5635, -3.5559],
        [-1.2034, -0.6017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056610867381095886
Epoch 0, Step 1417: train/loss = 0.26618772745132446, train/raw-loss = 0.15011094510555267, train/logprobs = tensor([[-1.1300, -4.7097],
        [-3.5413, -1.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160767525434494
Epoch 0, Step 1418: train/loss = 0.6677825450897217, train/raw-loss = 0.5670020580291748, train/logprobs = tensor([[-2.1820, -3.4032],
        [-2.5044, -1.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078051686286926
Epoch 0, Step 1419: train/loss = 0.45661574602127075, train/raw-loss = 0.36133623123168945, train/logprobs = tensor([[-1.7157, -3.5702],
        [-2.4018, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0952795222401619
Epoch 0, Step 1420: train/loss = 0.6605008840560913, train/raw-loss = 0.5941125154495239, train/logprobs = tensor([[-1.0508, -2.0637],
        [-0.9414, -0.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0663883313536644
Epoch 0, Step 1421: train/loss = 0.5290811061859131, train/raw-loss = 0.4394604563713074, train/logprobs = tensor([[-1.4687, -2.7847],
        [-1.8279, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0896206721663475
Epoch 0, Step 1422: train/loss = 0.6838314533233643, train/raw-loss = 0.581966757774353, train/logprobs = tensor([[-0.9273, -2.6635],
        [-1.3877, -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10186471790075302
Epoch 0, Step 1423: train/loss = 0.528267502784729, train/raw-loss = 0.4457957148551941, train/logprobs = tensor([[-0.8539, -0.9544],
        [-2.6181, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247178047895432
Epoch 0, Step 1424: train/loss = 0.5386415123939514, train/raw-loss = 0.4424765110015869, train/logprobs = tensor([[-1.2342, -2.6462],
        [-2.9355, -1.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0961650013923645
Epoch 0, Step 1425: train/loss = 0.39393019676208496, train/raw-loss = 0.3229409456253052, train/logprobs = tensor([[-0.8392, -2.7890],
        [-2.0969, -0.5577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07098928838968277
Epoch 0, Step 1426: train/loss = 0.30840006470680237, train/raw-loss = 0.21289880573749542, train/logprobs = tensor([[-1.3181, -5.4512],
        [-2.5127, -1.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09550126641988754
Epoch 0, Step 1427: train/loss = 0.322040855884552, train/raw-loss = 0.24623025953769684, train/logprobs = tensor([[-0.6929, -5.2044],
        [-1.3546, -0.8383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07581061869859695
Epoch 0, Step 1428: train/loss = 0.35539209842681885, train/raw-loss = 0.267642080783844, train/logprobs = tensor([[-1.0700, -5.7865],
        [-2.1984, -1.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08775004744529724
Epoch 0, Step 1429: train/loss = 0.47489824891090393, train/raw-loss = 0.3937516212463379, train/logprobs = tensor([[-1.4818, -2.3893],
        [-2.5768, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08114664256572723
Epoch 0, Step 1430: train/loss = 0.31581437587738037, train/raw-loss = 0.22012734413146973, train/logprobs = tensor([[-0.8016, -3.7317],
        [-1.9923, -0.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09568702429533005
Epoch 0, Step 1431: train/loss = 0.45322394371032715, train/raw-loss = 0.34241747856140137, train/logprobs = tensor([[-1.2376, -3.5568],
        [-2.8067, -1.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080649495124817
Epoch 0, Step 1432: train/loss = 0.5224750638008118, train/raw-loss = 0.4425821304321289, train/logprobs = tensor([[-1.4619, -4.6282],
        [-1.1606, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07989294081926346
Epoch 0, Step 1433: train/loss = 0.5831169486045837, train/raw-loss = 0.5188970565795898, train/logprobs = tensor([[-1.0847, -2.3039],
        [-1.3416, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0642198845744133
Epoch 0, Step 1434: train/loss = 0.5608205795288086, train/raw-loss = 0.47031813859939575, train/logprobs = tensor([[-1.4647, -3.8359],
        [-2.2486, -1.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09050241112709045
Epoch 0, Step 1435: train/loss = 0.37266379594802856, train/raw-loss = 0.26984167098999023, train/logprobs = tensor([[-1.1242, -3.7599],
        [-2.8977, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10282213985919952
Epoch 0, Step 1436: train/loss = 0.7465505003929138, train/raw-loss = 0.6883299350738525, train/logprobs = tensor([[-1.2542, -1.2769],
        [-0.8887, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05822061002254486
Epoch 0, Step 1437: train/loss = 0.9026762843132019, train/raw-loss = 0.828430712223053, train/logprobs = tensor([[-2.4483, -1.3367],
        [-3.1726, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07424558699131012
Epoch 0, Step 1438: train/loss = 1.0813955068588257, train/raw-loss = 0.9999791383743286, train/logprobs = tensor([[-2.5089, -1.6658],
        [-2.3793, -2.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08141636848449707
Epoch 0, Step 1439: train/loss = 0.32168883085250854, train/raw-loss = 0.24995850026607513, train/logprobs = tensor([[-0.5509, -5.1950],
        [-0.8124, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07173031568527222
Epoch 0, Step 1440: train/loss = 0.3589000105857849, train/raw-loss = 0.26333701610565186, train/logprobs = tensor([[-1.2515, -5.6350],
        [-2.6481, -1.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09556299448013306
Epoch 0, Step 1441: train/loss = 0.5024626851081848, train/raw-loss = 0.41027504205703735, train/logprobs = tensor([[-0.7551, -1.5630],
        [-1.7450, -0.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09218762814998627
Epoch 0, Step 1442: train/loss = 0.3745270073413849, train/raw-loss = 0.29160076379776, train/logprobs = tensor([[-0.8667, -4.3619],
        [-2.2189, -0.9104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08292625844478607
Epoch 0, Step 1443: train/loss = 0.3332989513874054, train/raw-loss = 0.2379099577665329, train/logprobs = tensor([[-0.9891, -2.0928],
        [-3.7286, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0953890010714531
Epoch 0, Step 1444: train/loss = 0.35418906807899475, train/raw-loss = 0.26777327060699463, train/logprobs = tensor([[-0.8704, -4.9825],
        [-2.3651, -1.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08641579747200012
Epoch 0, Step 1445: train/loss = 0.39753958582878113, train/raw-loss = 0.3256990313529968, train/logprobs = tensor([[-0.4970, -4.1520],
        [-0.9445, -0.9734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0718405544757843
Epoch 0, Step 1446: train/loss = 0.42467841506004333, train/raw-loss = 0.3444887697696686, train/logprobs = tensor([[-1.0574, -3.1540],
        [-2.4737, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08018963783979416
Epoch 0, Step 1447: train/loss = 0.4454885721206665, train/raw-loss = 0.3607659935951233, train/logprobs = tensor([[-0.7176, -2.8097],
        [-1.8293, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0847226083278656
Epoch 0, Step 1448: train/loss = 0.41360729932785034, train/raw-loss = 0.3093380331993103, train/logprobs = tensor([[-0.8551, -2.4552],
        [-2.6628, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10426926612854004
Epoch 0, Step 1449: train/loss = 0.3655802011489868, train/raw-loss = 0.27219438552856445, train/logprobs = tensor([[-0.7503, -4.0847],
        [-1.3842, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09338583797216415
Epoch 0, Step 1450: train/loss = 0.3995060324668884, train/raw-loss = 0.31423234939575195, train/logprobs = tensor([[-1.4336, -2.4366],
        [-2.3708, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08527372777462006
Epoch 0, Step 1451: train/loss = 0.5811824202537537, train/raw-loss = 0.5008500814437866, train/logprobs = tensor([[-0.7738, -1.5731],
        [-1.4157, -0.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08033229410648346
Epoch 0, Step 1452: train/loss = 0.3541499376296997, train/raw-loss = 0.23761117458343506, train/logprobs = tensor([[-1.8059, -3.4977],
        [-3.3353, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11653877794742584
Epoch 0, Step 1453: train/loss = 0.37795257568359375, train/raw-loss = 0.28597456216812134, train/logprobs = tensor([[-0.6956, -3.3451],
        [-1.8073, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0919780433177948
Epoch 0, Step 1454: train/loss = 0.47441065311431885, train/raw-loss = 0.3745326101779938, train/logprobs = tensor([[-0.8105, -3.5751],
        [-1.5077, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09987803548574448
Epoch 0, Step 1455: train/loss = 0.41961532831192017, train/raw-loss = 0.34449371695518494, train/logprobs = tensor([[-0.8742, -3.5708],
        [-2.0509, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07512160390615463
Epoch 0, Step 1456: train/loss = 0.412476122379303, train/raw-loss = 0.3190153241157532, train/logprobs = tensor([[-1.0208, -3.9072],
        [-2.2789, -0.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09346082806587219
Epoch 0, Step 1457: train/loss = 0.5847772359848022, train/raw-loss = 0.4933467507362366, train/logprobs = tensor([[-1.7737, -3.9277],
        [-2.2432, -1.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09143054485321045
Epoch 0, Step 1458: train/loss = 0.4250635802745819, train/raw-loss = 0.33658647537231445, train/logprobs = tensor([[-1.4847, -2.5814],
        [-1.8057, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08847710490226746
Epoch 0, Step 1459: train/loss = 0.5511717796325684, train/raw-loss = 0.45299798250198364, train/logprobs = tensor([[-0.8495, -2.8996],
        [-1.5860, -2.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817375242710114
Epoch 0, Step 1460: train/loss = 0.5915272831916809, train/raw-loss = 0.501248836517334, train/logprobs = tensor([[-0.8085, -1.9740],
        [-1.7205, -1.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09027843177318573
Epoch 0, Step 1461: train/loss = 0.6579684019088745, train/raw-loss = 0.570931613445282, train/logprobs = tensor([[-1.6445, -2.0821],
        [-1.8179, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08703681826591492
Epoch 0, Step 1462: train/loss = 0.5061473250389099, train/raw-loss = 0.4142950773239136, train/logprobs = tensor([[-0.9534, -2.5611],
        [-2.0732, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09185223281383514
Epoch 0, Step 1463: train/loss = 0.37277752161026, train/raw-loss = 0.283186137676239, train/logprobs = tensor([[-0.8327, -4.0023],
        [-1.9531, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0895913690328598
Epoch 0, Step 1464: train/loss = 0.39045485854148865, train/raw-loss = 0.29008904099464417, train/logprobs = tensor([[-1.0155, -3.7622],
        [-2.4708, -1.2033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10036580264568329
Epoch 0, Step 1465: train/loss = 0.5656836032867432, train/raw-loss = 0.4946496784687042, train/logprobs = tensor([[-0.7003, -1.4608],
        [-1.1883, -0.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07103390246629715
Epoch 0, Step 1466: train/loss = 0.328692227602005, train/raw-loss = 0.22673174738883972, train/logprobs = tensor([[-1.2561, -3.8262],
        [-3.7720, -0.5210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10196051001548767
Epoch 0, Step 1467: train/loss = 0.44495710730552673, train/raw-loss = 0.34454452991485596, train/logprobs = tensor([[-0.7921, -1.7551],
        [-2.7299, -0.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10041259229183197
Epoch 0, Step 1468: train/loss = 0.44612133502960205, train/raw-loss = 0.34447598457336426, train/logprobs = tensor([[-0.8466, -2.8964],
        [-1.7120, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10164537280797958
Epoch 0, Step 1469: train/loss = 0.24124445021152496, train/raw-loss = 0.15626996755599976, train/logprobs = tensor([[-1.0809, -6.1641],
        [-1.9563, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0849744975566864
Epoch 0, Step 1470: train/loss = 0.3710857629776001, train/raw-loss = 0.28853142261505127, train/logprobs = tensor([[-1.2287, -4.8032],
        [-1.8381, -0.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08255432546138763
Epoch 0, Step 1471: train/loss = 0.2211877852678299, train/raw-loss = 0.1184583231806755, train/logprobs = tensor([[-0.7888, -4.7684],
        [-3.4139, -0.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1027294397354126
Epoch 0, Step 1472: train/loss = 0.388447105884552, train/raw-loss = 0.3143509030342102, train/logprobs = tensor([[-0.7322, -3.0755],
        [-1.8068, -0.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740961879491806
Epoch 0, Step 1473: train/loss = 0.43188366293907166, train/raw-loss = 0.3617364168167114, train/logprobs = tensor([[-0.4532, -3.1524],
        [-0.9302, -1.0578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07014720886945724
Epoch 0, Step 1474: train/loss = 0.4772241711616516, train/raw-loss = 0.38203203678131104, train/logprobs = tensor([[-1.0812, -3.8838],
        [-2.2588, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519212692975998
Epoch 0, Step 1475: train/loss = 0.31501638889312744, train/raw-loss = 0.2383630871772766, train/logprobs = tensor([[-1.0903, -3.1621],
        [-2.2875, -0.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07665328681468964
Epoch 0, Step 1476: train/loss = 0.4254034757614136, train/raw-loss = 0.355477511882782, train/logprobs = tensor([[-0.7977, -3.5539],
        [-0.8665, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06992591917514801
Epoch 0, Step 1477: train/loss = 0.256227046251297, train/raw-loss = 0.16239769756793976, train/logprobs = tensor([[-0.7950, -3.6530],
        [-2.9924, -0.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382934123277664
Epoch 0, Step 1478: train/loss = 0.5769140720367432, train/raw-loss = 0.5142881274223328, train/logprobs = tensor([[-1.1449, -2.1442],
        [-2.3716, -0.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06262601912021637
Epoch 0, Step 1479: train/loss = 0.23800134658813477, train/raw-loss = 0.11955656111240387, train/logprobs = tensor([[-1.1895, -4.3105],
        [-3.8880, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1184447705745697
Epoch 0, Step 1480: train/loss = 0.3937624990940094, train/raw-loss = 0.30149587988853455, train/logprobs = tensor([[-1.1659, -2.9184],
        [-2.5057, -1.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09226663410663605
Epoch 0, Step 1481: train/loss = 0.3828819692134857, train/raw-loss = 0.3173988461494446, train/logprobs = tensor([[-0.6218, -4.4800],
        [-1.3804, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06548313051462173
Epoch 0, Step 1482: train/loss = 0.348858118057251, train/raw-loss = 0.2626878023147583, train/logprobs = tensor([[-1.1060, -5.9651],
        [-1.4588, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08617033064365387
Epoch 0, Step 1483: train/loss = 0.25387853384017944, train/raw-loss = 0.16764146089553833, train/logprobs = tensor([[-0.8893, -5.0062],
        [-2.7819, -0.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08623705059289932
Epoch 0, Step 1484: train/loss = 0.2440291792154312, train/raw-loss = 0.14060166478157043, train/logprobs = tensor([[-2.4605, -4.0410],
        [-4.3276, -0.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10342749953269958
Epoch 0, Step 1485: train/loss = 0.5122714638710022, train/raw-loss = 0.41949263215065, train/logprobs = tensor([[-0.8474, -3.6941],
        [-2.4089, -1.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277885407209396
Epoch 0, Step 1486: train/loss = 0.2918355166912079, train/raw-loss = 0.19376206398010254, train/logprobs = tensor([[-0.7568, -3.6990],
        [-2.5498, -0.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09807343035936356
Epoch 0, Step 1487: train/loss = 0.2947753369808197, train/raw-loss = 0.19454193115234375, train/logprobs = tensor([[-0.8882, -5.3530],
        [-2.1641, -0.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10023341327905655
Epoch 0, Step 1488: train/loss = 0.4882676601409912, train/raw-loss = 0.3899845480918884, train/logprobs = tensor([[-1.0186, -1.5476],
        [-2.7458, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09828313440084457
Epoch 0, Step 1489: train/loss = 0.38549551367759705, train/raw-loss = 0.2784459888935089, train/logprobs = tensor([[-1.1454, -4.2548],
        [-3.5994, -1.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10704950988292694
Epoch 0, Step 1490: train/loss = 0.43804243206977844, train/raw-loss = 0.35823652148246765, train/logprobs = tensor([[-0.8805, -2.8448],
        [-2.3510, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07980593293905258
Epoch 0, Step 1491: train/loss = 0.4408649504184723, train/raw-loss = 0.36569318175315857, train/logprobs = tensor([[-0.8717, -3.0330],
        [-2.3804, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07517173886299133
Epoch 0, Step 1492: train/loss = 0.6707831621170044, train/raw-loss = 0.5940387845039368, train/logprobs = tensor([[-1.2508, -2.7692],
        [-1.2185, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07674438506364822
Epoch 0, Step 1493: train/loss = 0.3866158723831177, train/raw-loss = 0.30034253001213074, train/logprobs = tensor([[-1.0782, -5.0269],
        [-2.1505, -1.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08627337217330933
Epoch 0, Step 1494: train/loss = 0.5025853514671326, train/raw-loss = 0.4301646649837494, train/logprobs = tensor([[-0.8528, -2.2370],
        [-1.5623, -0.7396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07242065668106079
Epoch 0, Step 1495: train/loss = 0.6358468532562256, train/raw-loss = 0.5282106399536133, train/logprobs = tensor([[-1.5776, -3.4007],
        [-4.0593, -2.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10763616859912872
Epoch 0, Step 1496: train/loss = 0.4881334900856018, train/raw-loss = 0.38575804233551025, train/logprobs = tensor([[-0.7467, -2.0452],
        [-1.8540, -0.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10237547755241394
Epoch 0, Step 1497: train/loss = 0.3837229609489441, train/raw-loss = 0.2607349753379822, train/logprobs = tensor([[-1.1556, -3.6171],
        [-3.2786, -1.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12298796325922012
Epoch 0, Step 1498: train/loss = 0.8291085362434387, train/raw-loss = 0.752393901348114, train/logprobs = tensor([[-1.4258, -1.5176],
        [-2.3928, -2.1991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07671461999416351
Epoch 0, Step 1499: train/loss = 0.3683874309062958, train/raw-loss = 0.2718545198440552, train/logprobs = tensor([[-1.8967, -4.8857],
        [-3.9754, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09653293341398239
Loss is nan
eval/loss: 0.4243634343147278
Epoch 0, Step 1500: train/loss = 0.5443424582481384, train/raw-loss = 0.45764094591140747, train/logprobs = tensor([[-1.5425, -3.1084],
        [-1.6162, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08670149743556976
Epoch 0, Step 1501: train/loss = 0.47266533970832825, train/raw-loss = 0.349161833524704, train/logprobs = tensor([[-1.7026, -2.6543],
        [-4.8481, -2.0614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12350350618362427
Epoch 0, Step 1502: train/loss = 0.49906980991363525, train/raw-loss = 0.40416356921195984, train/logprobs = tensor([[-0.5963, -3.9744],
        [-1.3046, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09490622580051422
Epoch 0, Step 1503: train/loss = 0.3686647415161133, train/raw-loss = 0.2765348553657532, train/logprobs = tensor([[-0.8097, -2.5362],
        [-2.7861, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0921299010515213
Epoch 0, Step 1504: train/loss = 0.39343005418777466, train/raw-loss = 0.32528191804885864, train/logprobs = tensor([[-1.1794, -2.0032],
        [-4.1543, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06814809143543243
Epoch 0, Step 1505: train/loss = 0.512789249420166, train/raw-loss = 0.4432167112827301, train/logprobs = tensor([[-1.0774, -1.6614],
        [-2.2677, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0695725679397583
Epoch 0, Step 1506: train/loss = 0.5426881313323975, train/raw-loss = 0.4685424566268921, train/logprobs = tensor([[-0.7157, -4.4796],
        [-1.2207, -1.6917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414568960666656
Epoch 0, Step 1507: train/loss = 0.3486585021018982, train/raw-loss = 0.23357471823692322, train/logprobs = tensor([[-0.9486, -3.2193],
        [-2.7537, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11508376896381378
Epoch 0, Step 1508: train/loss = 0.23303423821926117, train/raw-loss = 0.12411859631538391, train/logprobs = tensor([[-0.8566, -6.5636],
        [-2.4434, -1.2133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10891564190387726
Epoch 0, Step 1509: train/loss = 0.3882330060005188, train/raw-loss = 0.3046632409095764, train/logprobs = tensor([[-1.0841, -1.4380],
        [-3.1870, -0.9188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08356974273920059
Epoch 0, Step 1510: train/loss = 0.2843266725540161, train/raw-loss = 0.1889597773551941, train/logprobs = tensor([[-0.7897, -6.6187],
        [-1.4305, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09536691755056381
Epoch 0, Step 1511: train/loss = 0.4880388379096985, train/raw-loss = 0.42120450735092163, train/logprobs = tensor([[-0.6107, -2.3336],
        [-1.2942, -0.6491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06683433800935745
Epoch 0, Step 1512: train/loss = 0.3786490857601166, train/raw-loss = 0.287845641374588, train/logprobs = tensor([[-0.6609, -3.5478],
        [-1.7346, -0.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09080344438552856
Epoch 0, Step 1513: train/loss = 0.4897899031639099, train/raw-loss = 0.4225662648677826, train/logprobs = tensor([[-0.6165, -3.3916],
        [-1.0400, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06722366809844971
Epoch 0, Step 1514: train/loss = 0.2881499230861664, train/raw-loss = 0.2323300987482071, train/logprobs = tensor([[-0.7676, -3.7013],
        [-2.5673, -0.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055819831788539886
Epoch 0, Step 1515: train/loss = 0.4933956563472748, train/raw-loss = 0.4152769446372986, train/logprobs = tensor([[-0.8065, -3.6981],
        [-1.0477, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0781187117099762
Epoch 0, Step 1516: train/loss = 0.5403143763542175, train/raw-loss = 0.42890065908432007, train/logprobs = tensor([[-1.1583, -4.4013],
        [-2.9349, -2.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11141371726989746
Epoch 0, Step 1517: train/loss = 0.6059221029281616, train/raw-loss = 0.5262230038642883, train/logprobs = tensor([[-1.0894, -2.8447],
        [-1.2812, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796990692615509
Epoch 0, Step 1518: train/loss = 0.5900951027870178, train/raw-loss = 0.46003878116607666, train/logprobs = tensor([[-0.9243, -3.6003],
        [-2.7898, -1.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13005633652210236
Epoch 0, Step 1519: train/loss = 0.45166540145874023, train/raw-loss = 0.37644630670547485, train/logprobs = tensor([[-0.6042, -2.1977],
        [-1.5499, -0.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07521907985210419
Epoch 0, Step 1520: train/loss = 0.3409651219844818, train/raw-loss = 0.2622992694377899, train/logprobs = tensor([[-0.9197, -2.7554],
        [-2.8561, -0.5182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0786658525466919
Epoch 0, Step 1521: train/loss = 0.25738590955734253, train/raw-loss = 0.16142608225345612, train/logprobs = tensor([[-1.1250, -3.3661],
        [-3.2477, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09595979750156403
Epoch 0, Step 1522: train/loss = 0.454772025346756, train/raw-loss = 0.366917222738266, train/logprobs = tensor([[-1.0936, -2.9142],
        [-2.4386, -1.4540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08785483241081238
Epoch 0, Step 1523: train/loss = 0.3611176609992981, train/raw-loss = 0.24381627142429352, train/logprobs = tensor([[-1.2952, -3.2553],
        [-2.6455, -0.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11730137467384338
Epoch 0, Step 1524: train/loss = 0.2808786928653717, train/raw-loss = 0.19171841442584991, train/logprobs = tensor([[-0.7595, -4.5528],
        [-1.9229, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08916027843952179
Epoch 0, Step 1525: train/loss = 0.6422387957572937, train/raw-loss = 0.5660572052001953, train/logprobs = tensor([[-0.7413, -3.9546],
        [-1.9097, -2.4176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0761815756559372
Epoch 0, Step 1526: train/loss = 0.22511599957942963, train/raw-loss = 0.10135854780673981, train/logprobs = tensor([[-0.9540, -3.7560],
        [-4.0022, -1.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12375745922327042
Epoch 0, Step 1527: train/loss = 0.404533326625824, train/raw-loss = 0.29006925225257874, train/logprobs = tensor([[-0.9883, -2.9043],
        [-2.9042, -0.4780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11446408927440643
Epoch 0, Step 1528: train/loss = 0.47463536262512207, train/raw-loss = 0.3716338574886322, train/logprobs = tensor([[-0.8651, -3.6623],
        [-2.0312, -1.3247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10300150513648987
Epoch 0, Step 1529: train/loss = 0.9498655796051025, train/raw-loss = 0.8634182214736938, train/logprobs = tensor([[-1.1944, -1.9020],
        [-1.9386, -2.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08644738793373108
Epoch 0, Step 1530: train/loss = 0.27365660667419434, train/raw-loss = 0.18470895290374756, train/logprobs = tensor([[-1.6041, -3.8224],
        [-3.2071, -0.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08894763886928558
Epoch 0, Step 1531: train/loss = 0.5402103662490845, train/raw-loss = 0.455666184425354, train/logprobs = tensor([[-0.6603, -2.2701],
        [-1.9262, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08454420417547226
Epoch 0, Step 1532: train/loss = 0.5140857100486755, train/raw-loss = 0.4134746789932251, train/logprobs = tensor([[-0.8497, -2.1147],
        [-1.4181, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10061102360486984
Epoch 0, Step 1533: train/loss = 0.4208492636680603, train/raw-loss = 0.35988348722457886, train/logprobs = tensor([[-0.6899, -2.6247],
        [-1.5533, -0.6078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060965776443481445
Epoch 0, Step 1534: train/loss = 0.31943607330322266, train/raw-loss = 0.22479107975959778, train/logprobs = tensor([[-1.0749, -4.3450],
        [-1.9884, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09464501589536667
Epoch 0, Step 1535: train/loss = 0.4475349187850952, train/raw-loss = 0.3567982017993927, train/logprobs = tensor([[-0.6660, -2.2019],
        [-2.0526, -0.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073673188686371
Epoch 0, Step 1536: train/loss = 0.5458157658576965, train/raw-loss = 0.48748478293418884, train/logprobs = tensor([[-0.7253, -1.2653],
        [-1.5479, -0.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058330997824668884
Epoch 0, Step 1537: train/loss = 0.2742134928703308, train/raw-loss = 0.1494113653898239, train/logprobs = tensor([[-1.0494, -4.8914],
        [-3.5310, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248021125793457
Epoch 0, Step 1538: train/loss = 0.42255228757858276, train/raw-loss = 0.32433825731277466, train/logprobs = tensor([[-0.7961, -3.4113],
        [-1.7198, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09821401536464691
Epoch 0, Step 1539: train/loss = 0.33294570446014404, train/raw-loss = 0.2633001208305359, train/logprobs = tensor([[-1.1073, -4.6063],
        [-1.6134, -0.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06964559853076935
Epoch 0, Step 1540: train/loss = 0.27601999044418335, train/raw-loss = 0.17175710201263428, train/logprobs = tensor([[-0.7885, -5.4122],
        [-2.3844, -1.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10426291823387146
Epoch 0, Step 1541: train/loss = 0.3942760229110718, train/raw-loss = 0.2825251817703247, train/logprobs = tensor([[-1.5348, -5.8964],
        [-1.7995, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11175084859132767
Epoch 0, Step 1542: train/loss = 0.4326833486557007, train/raw-loss = 0.3451070785522461, train/logprobs = tensor([[-0.7241, -3.0158],
        [-1.8896, -0.6390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08757628500461578
Epoch 0, Step 1543: train/loss = 0.7493091225624084, train/raw-loss = 0.6575846672058105, train/logprobs = tensor([[-1.0773, -1.1912],
        [-2.3450, -1.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09172450006008148
Epoch 0, Step 1544: train/loss = 0.22883731126785278, train/raw-loss = 0.12437420338392258, train/logprobs = tensor([[-1.1079, -5.6503],
        [-2.4898, -0.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1044631153345108
Epoch 0, Step 1545: train/loss = 0.43460845947265625, train/raw-loss = 0.3575941324234009, train/logprobs = tensor([[-0.7640, -3.9167],
        [-1.0375, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07701428979635239
Epoch 0, Step 1546: train/loss = 0.46080124378204346, train/raw-loss = 0.383292555809021, train/logprobs = tensor([[-0.7404, -3.5828],
        [-1.0477, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07750865817070007
Epoch 0, Step 1547: train/loss = 0.5300192832946777, train/raw-loss = 0.46824032068252563, train/logprobs = tensor([[-0.5887, -2.9601],
        [-0.6402, -0.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0617789700627327
Epoch 0, Step 1548: train/loss = 0.4485050439834595, train/raw-loss = 0.3646858334541321, train/logprobs = tensor([[-1.6081, -3.9646],
        [-2.2610, -0.7511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08381915837526321
Epoch 0, Step 1549: train/loss = 0.2965349853038788, train/raw-loss = 0.19782525300979614, train/logprobs = tensor([[-0.9895, -4.6518],
        [-2.3579, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870972484350204
Epoch 0, Step 1550: train/loss = 0.45505616068840027, train/raw-loss = 0.38358110189437866, train/logprobs = tensor([[-1.3132, -3.8094],
        [-1.8278, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0714750811457634
Epoch 0, Step 1551: train/loss = 0.6644606590270996, train/raw-loss = 0.5643600225448608, train/logprobs = tensor([[-0.8285, -1.6449],
        [-2.4962, -1.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10010066628456116
Epoch 0, Step 1552: train/loss = 0.42401182651519775, train/raw-loss = 0.3387131690979004, train/logprobs = tensor([[-0.9823, -5.5914],
        [-1.2605, -1.6267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529862761497498
Epoch 0, Step 1553: train/loss = 0.37895533442497253, train/raw-loss = 0.3081773817539215, train/logprobs = tensor([[-0.6703, -4.7883],
        [-1.9641, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07077795267105103
Epoch 0, Step 1554: train/loss = 0.6694560050964355, train/raw-loss = 0.5687837600708008, train/logprobs = tensor([[-0.7429, -2.3150],
        [-2.4892, -2.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10067225992679596
Epoch 0, Step 1555: train/loss = 0.4668319821357727, train/raw-loss = 0.37677961587905884, train/logprobs = tensor([[-0.5714, -3.3860],
        [-1.2566, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09005239605903625
Epoch 0, Step 1556: train/loss = 0.45945727825164795, train/raw-loss = 0.3837180733680725, train/logprobs = tensor([[-0.4791, -2.5508],
        [-1.7069, -0.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07573918998241425
Epoch 0, Step 1557: train/loss = 0.2961992919445038, train/raw-loss = 0.21904349327087402, train/logprobs = tensor([[-0.7606, -4.8865],
        [-1.7640, -1.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07715579867362976
Epoch 0, Step 1558: train/loss = 0.2880154252052307, train/raw-loss = 0.198266863822937, train/logprobs = tensor([[-0.9228, -3.6340],
        [-2.6640, -0.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0897485688328743
Epoch 0, Step 1559: train/loss = 0.5557471513748169, train/raw-loss = 0.4671478867530823, train/logprobs = tensor([[-0.7722, -2.4259],
        [-1.3370, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08859922736883163
Epoch 0, Step 1560: train/loss = 0.514356255531311, train/raw-loss = 0.4323805868625641, train/logprobs = tensor([[-1.0032, -2.5171],
        [-1.2748, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08197569847106934
Epoch 0, Step 1561: train/loss = 0.25696706771850586, train/raw-loss = 0.1750958114862442, train/logprobs = tensor([[-0.7460, -3.9270],
        [-2.6529, -0.6520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08187125623226166
Epoch 0, Step 1562: train/loss = 0.2911520004272461, train/raw-loss = 0.2012311816215515, train/logprobs = tensor([[-0.9792, -4.7625],
        [-1.6162, -0.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08992081880569458
Epoch 0, Step 1563: train/loss = 0.4645509719848633, train/raw-loss = 0.40032529830932617, train/logprobs = tensor([[-0.5041, -3.3216],
        [-0.9477, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06422567367553711
Epoch 0, Step 1564: train/loss = 0.30990633368492126, train/raw-loss = 0.21399126946926117, train/logprobs = tensor([[-0.9218, -4.7125],
        [-2.1703, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0959150642156601
Epoch 0, Step 1565: train/loss = 0.31628912687301636, train/raw-loss = 0.23670414090156555, train/logprobs = tensor([[-1.1537, -3.0494],
        [-2.9305, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0795849859714508
Epoch 0, Step 1566: train/loss = 0.5525778532028198, train/raw-loss = 0.4902092218399048, train/logprobs = tensor([[-0.6377, -2.9808],
        [-0.9594, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062368638813495636
Epoch 0, Step 1567: train/loss = 0.2761330306529999, train/raw-loss = 0.19797636568546295, train/logprobs = tensor([[-1.0173, -4.2851],
        [-2.6007, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07815667986869812
Epoch 0, Step 1568: train/loss = 0.6835886240005493, train/raw-loss = 0.5882505774497986, train/logprobs = tensor([[-0.8419, -3.2946],
        [-1.6993, -1.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09533799439668655
Epoch 0, Step 1569: train/loss = 0.39418724179267883, train/raw-loss = 0.3198346495628357, train/logprobs = tensor([[-0.9524, -3.6049],
        [-2.7451, -1.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07435262203216553
Epoch 0, Step 1570: train/loss = 0.3442420959472656, train/raw-loss = 0.2626780867576599, train/logprobs = tensor([[-0.5783, -3.5508],
        [-2.5612, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0815640464425087
Epoch 0, Step 1571: train/loss = 0.1962183713912964, train/raw-loss = 0.08867465704679489, train/logprobs = tensor([[-0.9033, -5.9106],
        [-3.7283, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1075437143445015
Epoch 0, Step 1572: train/loss = 0.40308642387390137, train/raw-loss = 0.31245744228363037, train/logprobs = tensor([[-0.8222, -4.6500],
        [-1.2438, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.090628981590271
Epoch 0, Step 1573: train/loss = 0.3029865026473999, train/raw-loss = 0.1939787119626999, train/logprobs = tensor([[-1.4985, -3.9288],
        [-3.9144, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1090078055858612
Epoch 0, Step 1574: train/loss = 0.22998127341270447, train/raw-loss = 0.10876326262950897, train/logprobs = tensor([[-0.9638, -4.1143],
        [-4.1080, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12121802568435669
Epoch 0, Step 1575: train/loss = 0.4714621901512146, train/raw-loss = 0.335223913192749, train/logprobs = tensor([[-1.7552, -2.8021],
        [-3.4541, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362382173538208
Epoch 0, Step 1576: train/loss = 0.2454797327518463, train/raw-loss = 0.15539012849330902, train/logprobs = tensor([[-0.9649, -3.9611],
        [-3.6347, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09008961170911789
Epoch 0, Step 1577: train/loss = 0.43796029686927795, train/raw-loss = 0.33577820658683777, train/logprobs = tensor([[-0.7572, -2.5692],
        [-2.2016, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10218207538127899
Epoch 0, Step 1578: train/loss = 0.2938978374004364, train/raw-loss = 0.1891927421092987, train/logprobs = tensor([[-0.9497, -3.4923],
        [-3.6964, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047050952911377
Epoch 0, Step 1579: train/loss = 0.23731788992881775, train/raw-loss = 0.124798484146595, train/logprobs = tensor([[-1.0768, -3.9500],
        [-4.0020, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11251941323280334
Epoch 0, Step 1580: train/loss = 0.5666254758834839, train/raw-loss = 0.49130505323410034, train/logprobs = tensor([[-0.8252, -0.9725],
        [-2.6540, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07532048225402832
Epoch 0, Step 1581: train/loss = 0.49584445357322693, train/raw-loss = 0.4318574070930481, train/logprobs = tensor([[-0.4498, -3.5944],
        [-0.8882, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06398708373308182
Epoch 0, Step 1582: train/loss = 0.2297615110874176, train/raw-loss = 0.1171317994594574, train/logprobs = tensor([[-0.6230, -5.2696],
        [-3.0022, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1126297190785408
Epoch 0, Step 1583: train/loss = 0.44142472743988037, train/raw-loss = 0.3633531332015991, train/logprobs = tensor([[-0.8133, -4.4507],
        [-1.0314, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07807157188653946
Epoch 0, Step 1584: train/loss = 0.35253486037254333, train/raw-loss = 0.2763330638408661, train/logprobs = tensor([[-0.7827, -5.1748],
        [-1.0774, -0.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07620179653167725
Epoch 0, Step 1585: train/loss = 0.5851722955703735, train/raw-loss = 0.5199854373931885, train/logprobs = tensor([[-1.1636, -2.6817],
        [-1.0660, -1.2644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06518685817718506
Epoch 0, Step 1586: train/loss = 0.5239576101303101, train/raw-loss = 0.4432627856731415, train/logprobs = tensor([[-1.0985, -2.3906],
        [-2.2433, -0.6904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08069480210542679
Epoch 0, Step 1587: train/loss = 0.31057196855545044, train/raw-loss = 0.227896049618721, train/logprobs = tensor([[-0.9947, -5.3705],
        [-1.3874, -1.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08267591148614883
Epoch 0, Step 1588: train/loss = 0.2182762324810028, train/raw-loss = 0.09669076651334763, train/logprobs = tensor([[-0.7429, -4.7338],
        [-2.7655, -0.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12158545851707458
Epoch 0, Step 1589: train/loss = 0.3684022128582001, train/raw-loss = 0.27257123589515686, train/logprobs = tensor([[-1.7607, -5.8057],
        [-3.4041, -1.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0958310067653656
Epoch 0, Step 1590: train/loss = 0.5084333419799805, train/raw-loss = 0.43007582426071167, train/logprobs = tensor([[-1.1678, -2.8610],
        [-1.5802, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07835748046636581
Epoch 0, Step 1591: train/loss = 0.41147953271865845, train/raw-loss = 0.36276108026504517, train/logprobs = tensor([[-0.6293, -4.2148],
        [-0.9825, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048718441277742386
Epoch 0, Step 1592: train/loss = 0.6505075693130493, train/raw-loss = 0.551786482334137, train/logprobs = tensor([[-0.8148, -2.9281],
        [-2.2594, -2.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09872110188007355
Epoch 0, Step 1593: train/loss = 0.4768218696117401, train/raw-loss = 0.40444162487983704, train/logprobs = tensor([[-0.6015, -2.6978],
        [-1.3798, -0.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07238022238016129
Epoch 0, Step 1594: train/loss = 0.28493982553482056, train/raw-loss = 0.1962529718875885, train/logprobs = tensor([[-0.9387, -2.9490],
        [-3.3353, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08868687599897385
Epoch 0, Step 1595: train/loss = 0.4791761636734009, train/raw-loss = 0.40427249670028687, train/logprobs = tensor([[-0.6629, -2.4865],
        [-1.5316, -0.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07490368187427521
Epoch 0, Step 1596: train/loss = 0.5736075043678284, train/raw-loss = 0.4859224855899811, train/logprobs = tensor([[-1.2501, -2.8159],
        [-2.4003, -1.8658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08768497407436371
Epoch 0, Step 1597: train/loss = 0.5517882108688354, train/raw-loss = 0.4853094518184662, train/logprobs = tensor([[-0.7421, -2.4093],
        [-1.7669, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06647877395153046
Epoch 0, Step 1598: train/loss = 0.37818819284439087, train/raw-loss = 0.27071642875671387, train/logprobs = tensor([[-0.7642, -2.6187],
        [-2.5135, -0.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10747174918651581
Epoch 0, Step 1599: train/loss = 0.4966568052768707, train/raw-loss = 0.40408045053482056, train/logprobs = tensor([[-0.8552, -2.2786],
        [-2.2575, -1.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09257633239030838
Epoch 0, Step 1600: train/loss = 0.4135400354862213, train/raw-loss = 0.3250841498374939, train/logprobs = tensor([[-0.7538, -2.8288],
        [-2.1317, -0.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08845585584640503
Epoch 0, Step 1601: train/loss = 0.5586334466934204, train/raw-loss = 0.46913179755210876, train/logprobs = tensor([[-0.6751, -1.7474],
        [-1.5339, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08950167894363403
Epoch 0, Step 1602: train/loss = 0.39619022607803345, train/raw-loss = 0.31835946440696716, train/logprobs = tensor([[-0.8602, -4.8113],
        [-1.3772, -1.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07783076167106628
Epoch 0, Step 1603: train/loss = 0.3596496284008026, train/raw-loss = 0.2724611163139343, train/logprobs = tensor([[-1.5022, -4.3804],
        [-2.1457, -0.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08718854188919067
Epoch 0, Step 1604: train/loss = 0.47493720054626465, train/raw-loss = 0.3926824927330017, train/logprobs = tensor([[-0.7595, -3.1904],
        [-1.7873, -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08225470781326294
Epoch 0, Step 1605: train/loss = 0.23758366703987122, train/raw-loss = 0.10755312442779541, train/logprobs = tensor([[-1.2810, -4.1378],
        [-4.5816, -0.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1300305426120758
Epoch 0, Step 1606: train/loss = 0.5019729733467102, train/raw-loss = 0.42347273230552673, train/logprobs = tensor([[-0.8114, -2.1278],
        [-1.7551, -1.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07850025594234467
Epoch 0, Step 1607: train/loss = 0.5777207016944885, train/raw-loss = 0.509179949760437, train/logprobs = tensor([[-2.2263, -3.6451],
        [-2.3309, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06854075938463211
Epoch 0, Step 1608: train/loss = 0.4128527045249939, train/raw-loss = 0.3105453848838806, train/logprobs = tensor([[-0.9327, -2.5557],
        [-2.4975, -1.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10230731219053268
Epoch 0, Step 1609: train/loss = 0.44642338156700134, train/raw-loss = 0.37521815299987793, train/logprobs = tensor([[-0.6500, -2.5897],
        [-2.0670, -0.4718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07120522856712341
Epoch 0, Step 1610: train/loss = 0.4155844748020172, train/raw-loss = 0.29809290170669556, train/logprobs = tensor([[-1.8781, -3.7598],
        [-3.6103, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11749158054590225
Epoch 0, Step 1611: train/loss = 0.5045684576034546, train/raw-loss = 0.4130716025829315, train/logprobs = tensor([[-1.6430, -3.0970],
        [-1.9142, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09149688482284546
Epoch 0, Step 1612: train/loss = 0.3768734931945801, train/raw-loss = 0.2996147572994232, train/logprobs = tensor([[-0.5528, -3.7223],
        [-0.8780, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07725876569747925
Epoch 0, Step 1613: train/loss = 0.5831491351127625, train/raw-loss = 0.515551745891571, train/logprobs = tensor([[-0.6560, -3.7728],
        [-1.9811, -1.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0675974190235138
Epoch 0, Step 1614: train/loss = 0.2952061891555786, train/raw-loss = 0.21163970232009888, train/logprobs = tensor([[-0.8219, -4.4350],
        [-2.8997, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08356647938489914
Epoch 0, Step 1615: train/loss = 0.36538416147232056, train/raw-loss = 0.2995685338973999, train/logprobs = tensor([[-0.5321, -3.6116],
        [-1.2205, -0.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06581561267375946
Epoch 0, Step 1616: train/loss = 0.28173983097076416, train/raw-loss = 0.1869329810142517, train/logprobs = tensor([[-0.8909, -4.5769],
        [-2.7987, -0.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09480683505535126
Epoch 0, Step 1617: train/loss = 0.33236682415008545, train/raw-loss = 0.25468215346336365, train/logprobs = tensor([[-0.6202, -4.7562],
        [-1.1334, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07768465578556061
Epoch 0, Step 1618: train/loss = 0.5122321248054504, train/raw-loss = 0.4218441843986511, train/logprobs = tensor([[-0.9146, -3.5631],
        [-2.0702, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038796275854111
Epoch 0, Step 1619: train/loss = 0.5652269124984741, train/raw-loss = 0.5030471682548523, train/logprobs = tensor([[-0.5802, -2.1365],
        [-0.8578, -0.7198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06217974051833153
Epoch 0, Step 1620: train/loss = 0.6172983050346375, train/raw-loss = 0.5503385663032532, train/logprobs = tensor([[-0.5924, -1.9088],
        [-0.7438, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06695973128080368
Epoch 0, Step 1621: train/loss = 0.3550434410572052, train/raw-loss = 0.2695521116256714, train/logprobs = tensor([[-0.9353, -3.0831],
        [-3.5954, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0854913592338562
Epoch 0, Step 1622: train/loss = 0.35228532552719116, train/raw-loss = 0.26768067479133606, train/logprobs = tensor([[-1.1001, -3.0246],
        [-2.4129, -0.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08460462838411331
Epoch 0, Step 1623: train/loss = 0.28466588258743286, train/raw-loss = 0.17529544234275818, train/logprobs = tensor([[-0.6684, -5.7420],
        [-1.9248, -0.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1093704104423523
Epoch 0, Step 1624: train/loss = 0.20181280374526978, train/raw-loss = 0.11741869151592255, train/logprobs = tensor([[-0.9704, -5.5627],
        [-2.8672, -0.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08439412713050842
Epoch 0, Step 1625: train/loss = 0.349994421005249, train/raw-loss = 0.26737576723098755, train/logprobs = tensor([[-1.4485, -3.2706],
        [-3.0615, -0.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261868357658386
Epoch 0, Step 1626: train/loss = 0.4025118947029114, train/raw-loss = 0.3143989145755768, train/logprobs = tensor([[-0.7230, -3.7223],
        [-2.0963, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881129801273346
Epoch 0, Step 1627: train/loss = 0.43988803029060364, train/raw-loss = 0.33688831329345703, train/logprobs = tensor([[-1.2230, -3.4102],
        [-1.9138, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.102999746799469
Epoch 0, Step 1628: train/loss = 0.3810145854949951, train/raw-loss = 0.2731950283050537, train/logprobs = tensor([[-1.4635, -3.9311],
        [-2.5608, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1078195795416832
Epoch 0, Step 1629: train/loss = 0.40084245800971985, train/raw-loss = 0.3223891258239746, train/logprobs = tensor([[-0.7207, -4.5518],
        [-1.0080, -1.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07845331728458405
Epoch 0, Step 1630: train/loss = 0.3109971880912781, train/raw-loss = 0.2190459817647934, train/logprobs = tensor([[-0.9842, -3.9329],
        [-2.8646, -1.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09195120632648468
Epoch 0, Step 1631: train/loss = 0.4526354968547821, train/raw-loss = 0.386308491230011, train/logprobs = tensor([[-0.6213, -2.7285],
        [-1.4593, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06632699817419052
Epoch 0, Step 1632: train/loss = 0.4216757118701935, train/raw-loss = 0.3257017731666565, train/logprobs = tensor([[-1.4620, -3.1397],
        [-2.8576, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09597396105527878
Epoch 0, Step 1633: train/loss = 0.27563369274139404, train/raw-loss = 0.19194529950618744, train/logprobs = tensor([[-0.7530, -3.3654],
        [-2.7839, -0.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836883932352066
Epoch 0, Step 1634: train/loss = 0.49653467535972595, train/raw-loss = 0.41540852189064026, train/logprobs = tensor([[-0.7581, -2.7408],
        [-1.1528, -0.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0811261460185051
Epoch 0, Step 1635: train/loss = 0.4667707681655884, train/raw-loss = 0.4017186760902405, train/logprobs = tensor([[-0.8894, -3.4719],
        [-1.8101, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06505212932825089
Epoch 0, Step 1636: train/loss = 0.39049032330513, train/raw-loss = 0.2975374758243561, train/logprobs = tensor([[-1.2963, -4.3494],
        [-3.7016, -0.6683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09295286238193512
Epoch 0, Step 1637: train/loss = 0.5736333131790161, train/raw-loss = 0.501533031463623, train/logprobs = tensor([[-1.2848, -2.6624],
        [-1.6482, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07210027426481247
Epoch 0, Step 1638: train/loss = 0.37736520171165466, train/raw-loss = 0.2746572494506836, train/logprobs = tensor([[-0.9706, -3.0857],
        [-3.3578, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10270793735980988
Epoch 0, Step 1639: train/loss = 0.4158790707588196, train/raw-loss = 0.3377053439617157, train/logprobs = tensor([[-0.6328, -5.3055],
        [-2.2086, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817371934652328
Epoch 0, Step 1640: train/loss = 0.41341841220855713, train/raw-loss = 0.32779985666275024, train/logprobs = tensor([[-1.8737, -3.1351],
        [-2.1509, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08561857044696808
Epoch 0, Step 1641: train/loss = 0.45731696486473083, train/raw-loss = 0.393474817276001, train/logprobs = tensor([[-0.4692, -3.8751],
        [-0.9129, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06384216248989105
Epoch 0, Step 1642: train/loss = 0.5444698929786682, train/raw-loss = 0.46358567476272583, train/logprobs = tensor([[-0.8306, -2.5408],
        [-1.2097, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08088424801826477
Epoch 0, Step 1643: train/loss = 0.2579142451286316, train/raw-loss = 0.16347545385360718, train/logprobs = tensor([[-1.6465, -5.3040],
        [-3.7878, -1.2523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09443879127502441
Epoch 0, Step 1644: train/loss = 0.5833771228790283, train/raw-loss = 0.5018447041511536, train/logprobs = tensor([[-1.1888, -2.4878],
        [-1.7482, -1.4578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08153243362903595
Epoch 0, Step 1645: train/loss = 0.3416883051395416, train/raw-loss = 0.2050345540046692, train/logprobs = tensor([[-0.9981, -3.0091],
        [-3.8762, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13665376603603363
Epoch 0, Step 1646: train/loss = 0.22999459505081177, train/raw-loss = 0.1318502426147461, train/logprobs = tensor([[-0.7483, -4.4688],
        [-3.2826, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09814436733722687
Epoch 0, Step 1647: train/loss = 0.6181117296218872, train/raw-loss = 0.5568004846572876, train/logprobs = tensor([[-0.7080, -0.7455],
        [-1.4688, -0.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061311252415180206
Epoch 0, Step 1648: train/loss = 0.40821853280067444, train/raw-loss = 0.309653103351593, train/logprobs = tensor([[-1.5057, -2.2224],
        [-4.0521, -0.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09856540709733963
Epoch 0, Step 1649: train/loss = 0.4546588361263275, train/raw-loss = 0.3485897183418274, train/logprobs = tensor([[-1.1269, -3.5642],
        [-4.2504, -2.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10606912523508072
Epoch 0, Step 1650: train/loss = 0.3702176809310913, train/raw-loss = 0.30007484555244446, train/logprobs = tensor([[-0.8581, -5.5321],
        [-0.9166, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07014283537864685
Epoch 0, Step 1651: train/loss = 0.2876175045967102, train/raw-loss = 0.2070031762123108, train/logprobs = tensor([[-0.7137, -4.9672],
        [-1.5981, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08061432838439941
Epoch 0, Step 1652: train/loss = 0.443185955286026, train/raw-loss = 0.347354531288147, train/logprobs = tensor([[-1.1472, -3.2634],
        [-2.0620, -0.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09583145380020142
Epoch 0, Step 1653: train/loss = 0.854948878288269, train/raw-loss = 0.756426990032196, train/logprobs = tensor([[-0.8135, -2.8042],
        [-2.0912, -2.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0985218957066536
Epoch 0, Step 1654: train/loss = 0.373834490776062, train/raw-loss = 0.30157381296157837, train/logprobs = tensor([[-0.4609, -5.7401],
        [-0.7983, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07226070761680603
Epoch 0, Step 1655: train/loss = 0.23730197548866272, train/raw-loss = 0.14959314465522766, train/logprobs = tensor([[-0.7088, -6.3091],
        [-2.2255, -1.1712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08770883083343506
Epoch 0, Step 1656: train/loss = 0.2561342120170593, train/raw-loss = 0.16927656531333923, train/logprobs = tensor([[-0.6927, -3.4473],
        [-3.0233, -0.5104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08685766160488129
Epoch 0, Step 1657: train/loss = 0.2720315158367157, train/raw-loss = 0.17994248867034912, train/logprobs = tensor([[-0.7397, -3.4182],
        [-2.7368, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09208901226520538
Epoch 0, Step 1658: train/loss = 0.4387689530849457, train/raw-loss = 0.33541348576545715, train/logprobs = tensor([[-1.7933, -4.6225],
        [-3.0179, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10335546731948853
Epoch 0, Step 1659: train/loss = 0.4840247631072998, train/raw-loss = 0.4041184186935425, train/logprobs = tensor([[-1.4339, -4.1970],
        [-2.6833, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07990635931491852
Epoch 0, Step 1660: train/loss = 0.2832496464252472, train/raw-loss = 0.1766202300786972, train/logprobs = tensor([[-0.6663, -3.4169],
        [-3.6026, -0.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10662943869829178
Epoch 0, Step 1661: train/loss = 0.2548910975456238, train/raw-loss = 0.15927007794380188, train/logprobs = tensor([[-0.6424, -4.6832],
        [-2.1878, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0956210196018219
Epoch 0, Step 1662: train/loss = 0.3749789595603943, train/raw-loss = 0.2616268992424011, train/logprobs = tensor([[-0.7902, -3.8465],
        [-1.8578, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11335209012031555
Epoch 0, Step 1663: train/loss = 0.3416241705417633, train/raw-loss = 0.25510865449905396, train/logprobs = tensor([[-0.8984, -3.8446],
        [-2.0636, -0.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08651548624038696
Epoch 0, Step 1664: train/loss = 0.35282111167907715, train/raw-loss = 0.2797584533691406, train/logprobs = tensor([[-0.6112, -3.7829],
        [-1.7106, -0.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07306268066167831
Epoch 0, Step 1665: train/loss = 0.22922271490097046, train/raw-loss = 0.13190433382987976, train/logprobs = tensor([[-0.9091, -5.3597],
        [-2.4361, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09731839597225189
Epoch 0, Step 1666: train/loss = 0.17561273276805878, train/raw-loss = 0.04761061817407608, train/logprobs = tensor([[-0.9219, -5.2867],
        [-4.3068, -0.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1280021220445633
Epoch 0, Step 1667: train/loss = 0.4862094819545746, train/raw-loss = 0.40786898136138916, train/logprobs = tensor([[-0.6674, -2.0993],
        [-1.0100, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834052294492722
Epoch 0, Step 1668: train/loss = 0.2632368505001068, train/raw-loss = 0.17933832108974457, train/logprobs = tensor([[-0.9279, -5.3887],
        [-1.8118, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08389851450920105
Epoch 0, Step 1669: train/loss = 0.3795950412750244, train/raw-loss = 0.2803128957748413, train/logprobs = tensor([[-0.9203, -2.3836],
        [-3.4316, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992821529507637
Epoch 0, Step 1670: train/loss = 0.37220048904418945, train/raw-loss = 0.2821162939071655, train/logprobs = tensor([[-0.7992, -4.3279],
        [-2.0069, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09008418023586273
Epoch 0, Step 1671: train/loss = 0.442030131816864, train/raw-loss = 0.33122438192367554, train/logprobs = tensor([[-1.6988, -2.7816],
        [-4.0789, -1.1165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11080574989318848
Epoch 0, Step 1672: train/loss = 0.4456962049007416, train/raw-loss = 0.3792153000831604, train/logprobs = tensor([[-1.5900, -4.2664],
        [-2.2729, -1.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06648093461990356
Epoch 0, Step 1673: train/loss = 0.49997678399086, train/raw-loss = 0.4066948890686035, train/logprobs = tensor([[-0.5937, -1.8558],
        [-2.2493, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09328189492225647
Epoch 0, Step 1674: train/loss = 0.4115852117538452, train/raw-loss = 0.3233165442943573, train/logprobs = tensor([[-0.6421, -4.9729],
        [-1.6542, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08826865255832672
Epoch 0, Step 1675: train/loss = 0.7244319319725037, train/raw-loss = 0.6495780944824219, train/logprobs = tensor([[-1.6619, -1.6199],
        [-1.8375, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07485390454530716
Epoch 0, Step 1676: train/loss = 0.37561067938804626, train/raw-loss = 0.2629701495170593, train/logprobs = tensor([[-1.2209, -4.8945],
        [-2.9475, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11264055967330933
Epoch 0, Step 1677: train/loss = 0.3391168713569641, train/raw-loss = 0.24388571083545685, train/logprobs = tensor([[-0.5913, -3.9167],
        [-2.2812, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09523117542266846
Epoch 0, Step 1678: train/loss = 0.5149670839309692, train/raw-loss = 0.42632395029067993, train/logprobs = tensor([[-1.5545, -3.6594],
        [-1.7662, -1.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08864312618970871
Epoch 0, Step 1679: train/loss = 0.3413182497024536, train/raw-loss = 0.24493946135044098, train/logprobs = tensor([[-1.2251, -5.0243],
        [-2.8398, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09637878835201263
Epoch 0, Step 1680: train/loss = 0.20950347185134888, train/raw-loss = 0.09579356014728546, train/logprobs = tensor([[-1.1961, -5.0101],
        [-3.7696, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11370991915464401
Epoch 0, Step 1681: train/loss = 0.5009135007858276, train/raw-loss = 0.4229387938976288, train/logprobs = tensor([[-0.8484, -3.8221],
        [-1.0361, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07797467708587646
Epoch 0, Step 1682: train/loss = 0.27005207538604736, train/raw-loss = 0.16635635495185852, train/logprobs = tensor([[-0.9112, -5.1414],
        [-4.2115, -1.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10369569063186646
Epoch 0, Step 1683: train/loss = 0.30834412574768066, train/raw-loss = 0.2147275060415268, train/logprobs = tensor([[-1.3651, -4.9023],
        [-2.4890, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09361662715673447
Epoch 0, Step 1684: train/loss = 0.2766696810722351, train/raw-loss = 0.17441464960575104, train/logprobs = tensor([[-0.9039, -3.9914],
        [-2.2743, -0.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10225503891706467
Epoch 0, Step 1685: train/loss = 0.48143598437309265, train/raw-loss = 0.40380293130874634, train/logprobs = tensor([[-0.8341, -2.4699],
        [-2.1168, -0.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763306796550751
Epoch 0, Step 1686: train/loss = 0.31016406416893005, train/raw-loss = 0.20994772017002106, train/logprobs = tensor([[-0.6843, -3.2083],
        [-2.5200, -0.5732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1002163290977478
Epoch 0, Step 1687: train/loss = 0.41940057277679443, train/raw-loss = 0.33398541808128357, train/logprobs = tensor([[-1.5478, -4.8438],
        [-2.2641, -1.4680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08541518449783325
Epoch 0, Step 1688: train/loss = 0.41586101055145264, train/raw-loss = 0.35141947865486145, train/logprobs = tensor([[-0.6756, -3.4838],
        [-1.5157, -0.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644415095448494
Epoch 0, Step 1689: train/loss = 0.4603855311870575, train/raw-loss = 0.400804340839386, train/logprobs = tensor([[-1.4760, -2.9182],
        [-1.7698, -0.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059581197798252106
Epoch 0, Step 1690: train/loss = 0.20128843188285828, train/raw-loss = 0.07913053780794144, train/logprobs = tensor([[-1.0188, -3.9085],
        [-5.5184, -0.9889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12215789407491684
Epoch 0, Step 1691: train/loss = 0.772229790687561, train/raw-loss = 0.67878657579422, train/logprobs = tensor([[-0.6735, -2.9922],
        [-2.1174, -2.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09344318509101868
Epoch 0, Step 1692: train/loss = 0.888880729675293, train/raw-loss = 0.7783822417259216, train/logprobs = tensor([[-1.6050, -6.1471],
        [-2.1873, -2.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11049847304821014
Epoch 0, Step 1693: train/loss = 0.3071419596672058, train/raw-loss = 0.2126251608133316, train/logprobs = tensor([[-0.8616, -5.4023],
        [-2.9443, -1.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09451677650213242
Epoch 0, Step 1694: train/loss = 0.36441218852996826, train/raw-loss = 0.29020941257476807, train/logprobs = tensor([[-0.9783, -4.7677],
        [-1.5197, -0.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07420279085636139
Epoch 0, Step 1695: train/loss = 0.5523242950439453, train/raw-loss = 0.44758886098861694, train/logprobs = tensor([[-2.2798, -5.7629],
        [-2.4452, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10473543405532837
Epoch 0, Step 1696: train/loss = 0.3495475947856903, train/raw-loss = 0.2829091548919678, train/logprobs = tensor([[-1.6100, -2.7714],
        [-3.6709, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06663842499256134
Epoch 0, Step 1697: train/loss = 0.24058616161346436, train/raw-loss = 0.1548759937286377, train/logprobs = tensor([[-0.7276, -7.9998],
        [-2.2508, -1.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08571016788482666
Epoch 0, Step 1698: train/loss = 0.390750527381897, train/raw-loss = 0.2852928042411804, train/logprobs = tensor([[-1.6342, -1.9922],
        [-3.9370, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10545771569013596
Epoch 0, Step 1699: train/loss = 0.4472394585609436, train/raw-loss = 0.3465108275413513, train/logprobs = tensor([[-1.0161, -2.9664],
        [-2.2796, -0.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10072864592075348
Epoch 0, Step 1700: train/loss = 0.5461394786834717, train/raw-loss = 0.47056329250335693, train/logprobs = tensor([[-0.9865, -1.6291],
        [-1.6749, -0.7940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07557617127895355
Epoch 0, Step 1701: train/loss = 0.5682940483093262, train/raw-loss = 0.46591421961784363, train/logprobs = tensor([[-0.8796, -4.1439],
        [-3.1200, -1.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10237985104322433
Epoch 0, Step 1702: train/loss = 0.44444209337234497, train/raw-loss = 0.36766064167022705, train/logprobs = tensor([[-0.7623, -3.1167],
        [-1.9608, -1.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07678142935037613
Epoch 0, Step 1703: train/loss = 0.5537816286087036, train/raw-loss = 0.4658568203449249, train/logprobs = tensor([[-0.8808, -1.9888],
        [-1.6607, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08792486786842346
Epoch 0, Step 1704: train/loss = 0.4358172118663788, train/raw-loss = 0.37357911467552185, train/logprobs = tensor([[-1.0849, -2.9066],
        [-2.4232, -0.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06223806366324425
Epoch 0, Step 1705: train/loss = 0.25955846905708313, train/raw-loss = 0.16103509068489075, train/logprobs = tensor([[-1.2469, -5.3250],
        [-3.2572, -2.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09852337837219238
Epoch 0, Step 1706: train/loss = 0.3825274705886841, train/raw-loss = 0.3190594017505646, train/logprobs = tensor([[-0.5540, -4.4604],
        [-1.0400, -0.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0634680762887001
Epoch 0, Step 1707: train/loss = 0.6185243129730225, train/raw-loss = 0.5563850402832031, train/logprobs = tensor([[-0.7991, -0.9410],
        [-1.4691, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062139272689819336
Epoch 0, Step 1708: train/loss = 0.5480378270149231, train/raw-loss = 0.5051257610321045, train/logprobs = tensor([[-0.5343, -2.2550],
        [-0.6276, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04291205853223801
Epoch 0, Step 1709: train/loss = 0.3697114884853363, train/raw-loss = 0.29854100942611694, train/logprobs = tensor([[-0.6310, -3.8641],
        [-1.0331, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07117049396038055
Epoch 0, Step 1710: train/loss = 0.43501174449920654, train/raw-loss = 0.3655344247817993, train/logprobs = tensor([[-0.6022, -1.9123],
        [-1.9451, -0.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06947732716798782
Epoch 0, Step 1711: train/loss = 0.5505304932594299, train/raw-loss = 0.46550285816192627, train/logprobs = tensor([[-0.7121, -1.9778],
        [-1.0836, -0.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502766489982605
Epoch 0, Step 1712: train/loss = 0.29618412256240845, train/raw-loss = 0.22391094267368317, train/logprobs = tensor([[-0.9673, -5.0698],
        [-3.8024, -1.4314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07227318733930588
Epoch 0, Step 1713: train/loss = 0.36523759365081787, train/raw-loss = 0.24529267847537994, train/logprobs = tensor([[-1.0355, -2.8542],
        [-2.9792, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11994491517543793
Epoch 0, Step 1714: train/loss = 0.5154632329940796, train/raw-loss = 0.4550715386867523, train/logprobs = tensor([[-0.4586, -3.0365],
        [-0.8108, -1.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0603916309773922
Epoch 0, Step 1715: train/loss = 0.2656957805156708, train/raw-loss = 0.16953355073928833, train/logprobs = tensor([[-1.0744, -4.9468],
        [-2.5419, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09616221487522125
Epoch 0, Step 1716: train/loss = 0.47216200828552246, train/raw-loss = 0.3868311047554016, train/logprobs = tensor([[-0.8915, -2.7256],
        [-1.3110, -0.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08533088862895966
Epoch 0, Step 1717: train/loss = 0.5225632190704346, train/raw-loss = 0.4377239942550659, train/logprobs = tensor([[-0.7074, -2.6619],
        [-1.2942, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483928442001343
Epoch 0, Step 1718: train/loss = 0.4168426990509033, train/raw-loss = 0.32561784982681274, train/logprobs = tensor([[-0.6866, -3.3762],
        [-2.0957, -0.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09122486412525177
Epoch 0, Step 1719: train/loss = 0.3622555434703827, train/raw-loss = 0.2855876684188843, train/logprobs = tensor([[-0.7019, -4.9705],
        [-1.6122, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07666787505149841
Epoch 0, Step 1720: train/loss = 0.455142617225647, train/raw-loss = 0.367423951625824, train/logprobs = tensor([[-1.2501, -3.2905],
        [-2.2973, -1.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771868050098419
Epoch 0, Step 1721: train/loss = 0.3754807114601135, train/raw-loss = 0.29605531692504883, train/logprobs = tensor([[-0.7015, -3.2272],
        [-1.8309, -0.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0794254019856453
Epoch 0, Step 1722: train/loss = 0.39026638865470886, train/raw-loss = 0.3147083520889282, train/logprobs = tensor([[-0.5938, -4.7798],
        [-1.5375, -0.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07555802166461945
Epoch 0, Step 1723: train/loss = 0.317281574010849, train/raw-loss = 0.2210945188999176, train/logprobs = tensor([[-0.9659, -5.3075],
        [-2.4427, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096187062561512
Epoch 0, Step 1724: train/loss = 0.5232365131378174, train/raw-loss = 0.4492051899433136, train/logprobs = tensor([[-0.9836, -0.8800],
        [-2.4329, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07403131574392319
Epoch 0, Step 1725: train/loss = 0.6098823547363281, train/raw-loss = 0.5339317917823792, train/logprobs = tensor([[-0.6284, -1.5087],
        [-1.2141, -0.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07595059275627136
Epoch 0, Step 1726: train/loss = 0.33329546451568604, train/raw-loss = 0.24512280523777008, train/logprobs = tensor([[-0.7187, -4.9136],
        [-2.0196, -0.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08817267417907715
Epoch 0, Step 1727: train/loss = 0.31432676315307617, train/raw-loss = 0.20788398385047913, train/logprobs = tensor([[-0.8052, -4.8414],
        [-1.8192, -0.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10644278675317764
Epoch 0, Step 1728: train/loss = 0.5063853859901428, train/raw-loss = 0.4449421167373657, train/logprobs = tensor([[-0.7546, -3.2305],
        [-1.0714, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06144328415393829
Epoch 0, Step 1729: train/loss = 0.23647907376289368, train/raw-loss = 0.12668345868587494, train/logprobs = tensor([[-0.7435, -5.0188],
        [-2.2842, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10979561507701874
Epoch 0, Step 1730: train/loss = 0.4117368757724762, train/raw-loss = 0.32405781745910645, train/logprobs = tensor([[-1.4790, -3.1835],
        [-3.5016, -0.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08767908066511154
Epoch 0, Step 1731: train/loss = 0.5949884653091431, train/raw-loss = 0.47623878717422485, train/logprobs = tensor([[-0.8450, -3.4308],
        [-4.1399, -1.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11874962598085403
Epoch 0, Step 1732: train/loss = 0.3736323416233063, train/raw-loss = 0.2796899080276489, train/logprobs = tensor([[-0.6279, -2.9978],
        [-2.8122, -0.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09394241869449615
Epoch 0, Step 1733: train/loss = 0.4657445251941681, train/raw-loss = 0.39885514974594116, train/logprobs = tensor([[-0.5702, -3.3837],
        [-0.8445, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06688936054706573
Epoch 0, Step 1734: train/loss = 0.5404772758483887, train/raw-loss = 0.46190813183784485, train/logprobs = tensor([[-0.3880, -3.6446],
        [-1.4823, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07856917381286621
Epoch 0, Step 1735: train/loss = 0.3762684762477875, train/raw-loss = 0.268156498670578, train/logprobs = tensor([[-0.8979, -3.9535],
        [-2.2732, -0.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10811198502779007
Epoch 0, Step 1736: train/loss = 0.35641342401504517, train/raw-loss = 0.29822784662246704, train/logprobs = tensor([[-0.6836, -2.8993],
        [-2.2268, -0.4598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05818558484315872
Epoch 0, Step 1737: train/loss = 0.34792160987854004, train/raw-loss = 0.2734741270542145, train/logprobs = tensor([[-0.6733, -5.8604],
        [-1.3819, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07444748282432556
Epoch 0, Step 1738: train/loss = 0.3878607153892517, train/raw-loss = 0.28026464581489563, train/logprobs = tensor([[-0.8319, -2.6018],
        [-3.4889, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10759609192609787
Epoch 0, Step 1739: train/loss = 0.3493669033050537, train/raw-loss = 0.27046680450439453, train/logprobs = tensor([[-0.8065, -5.9289],
        [-1.5659, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07890012115240097
Epoch 0, Step 1740: train/loss = 0.38201195001602173, train/raw-loss = 0.3238165080547333, train/logprobs = tensor([[-0.5467, -4.6638],
        [-0.9386, -1.2622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05819541960954666
Epoch 0, Step 1741: train/loss = 0.4830232858657837, train/raw-loss = 0.4022659361362457, train/logprobs = tensor([[-0.7575, -1.6391],
        [-2.9548, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08075737953186035
Epoch 0, Step 1742: train/loss = 0.3919163644313812, train/raw-loss = 0.29982149600982666, train/logprobs = tensor([[-0.7387, -2.9570],
        [-2.0045, -0.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09209489822387695
Epoch 0, Step 1743: train/loss = 0.36861175298690796, train/raw-loss = 0.29634904861450195, train/logprobs = tensor([[-0.6562, -3.5515],
        [-1.7146, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07226269692182541
Epoch 0, Step 1744: train/loss = 0.44386038184165955, train/raw-loss = 0.35810568928718567, train/logprobs = tensor([[-0.4583, -2.6529],
        [-1.2683, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08575470745563507
Epoch 0, Step 1745: train/loss = 0.5778773427009583, train/raw-loss = 0.4868622422218323, train/logprobs = tensor([[-0.7898, -1.2308],
        [-1.6594, -0.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09101513028144836
Epoch 0, Step 1746: train/loss = 0.5846264362335205, train/raw-loss = 0.5289385318756104, train/logprobs = tensor([[-0.6121, -2.5774],
        [-1.3816, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05568790063261986
Epoch 0, Step 1747: train/loss = 0.3572227656841278, train/raw-loss = 0.25793859362602234, train/logprobs = tensor([[-0.8391, -2.4811],
        [-4.4363, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09928418695926666
Epoch 0, Step 1748: train/loss = 0.44208410382270813, train/raw-loss = 0.34135347604751587, train/logprobs = tensor([[-0.8676, -3.7593],
        [-2.0628, -1.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10073064267635345
Epoch 0, Step 1749: train/loss = 0.5079771876335144, train/raw-loss = 0.4371213912963867, train/logprobs = tensor([[-0.6232, -2.5082],
        [-1.1398, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07085582613945007
Epoch 0, Step 1750: train/loss = 0.3179900050163269, train/raw-loss = 0.23334422707557678, train/logprobs = tensor([[-1.1863, -5.1565],
        [-2.4774, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08464577049016953
Epoch 0, Step 1751: train/loss = 0.23917753994464874, train/raw-loss = 0.14206500351428986, train/logprobs = tensor([[-0.9406, -3.5337],
        [-4.2056, -0.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09711255133152008
Epoch 0, Step 1752: train/loss = 0.37444236874580383, train/raw-loss = 0.3137686848640442, train/logprobs = tensor([[-0.5168, -4.6003],
        [-0.9080, -0.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06067370995879173
Epoch 0, Step 1753: train/loss = 0.30513209104537964, train/raw-loss = 0.20113219320774078, train/logprobs = tensor([[-0.9253, -5.3819],
        [-4.7394, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10399992763996124
Epoch 0, Step 1754: train/loss = 0.4307839572429657, train/raw-loss = 0.3296508491039276, train/logprobs = tensor([[-1.5724, -3.8577],
        [-3.5656, -1.3593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10113310068845749
Epoch 0, Step 1755: train/loss = 0.4225844144821167, train/raw-loss = 0.3385365903377533, train/logprobs = tensor([[-1.1791, -3.2637],
        [-2.5509, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08404780924320221
Epoch 0, Step 1756: train/loss = 0.5346473455429077, train/raw-loss = 0.4781395196914673, train/logprobs = tensor([[-0.5786, -2.2508],
        [-0.8473, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05650783330202103
Epoch 0, Step 1757: train/loss = 0.28466707468032837, train/raw-loss = 0.1908722072839737, train/logprobs = tensor([[-0.6578, -4.7460],
        [-1.6760, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09379485249519348
Epoch 0, Step 1758: train/loss = 0.7528401613235474, train/raw-loss = 0.6671192049980164, train/logprobs = tensor([[-0.5267, -2.6208],
        [-1.9201, -2.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0857209786772728
Epoch 0, Step 1759: train/loss = 0.34819287061691284, train/raw-loss = 0.24221983551979065, train/logprobs = tensor([[-0.9799, -2.8517],
        [-3.9044, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597303509712219
Epoch 0, Step 1760: train/loss = 0.2806151807308197, train/raw-loss = 0.18443815410137177, train/logprobs = tensor([[-0.7502, -2.7905],
        [-3.3010, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09617701172828674
Epoch 0, Step 1761: train/loss = 0.3625386655330658, train/raw-loss = 0.27921533584594727, train/logprobs = tensor([[-0.9731, -1.9528],
        [-4.0159, -1.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08332335203886032
Epoch 0, Step 1762: train/loss = 0.3130105137825012, train/raw-loss = 0.2383049875497818, train/logprobs = tensor([[-0.9363, -6.8098],
        [-1.2494, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07470550388097763
Epoch 0, Step 1763: train/loss = 0.5726600885391235, train/raw-loss = 0.47151443362236023, train/logprobs = tensor([[-0.7289, -2.8891],
        [-2.5707, -1.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1011456623673439
Epoch 0, Step 1764: train/loss = 0.7068937420845032, train/raw-loss = 0.6510083079338074, train/logprobs = tensor([[-0.7968, -1.3444],
        [-0.8021, -1.1472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0558854416012764
Epoch 0, Step 1765: train/loss = 0.2095320224761963, train/raw-loss = 0.11018519103527069, train/logprobs = tensor([[-0.8277, -3.9011],
        [-2.8275, -0.5422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0993468314409256
Epoch 0, Step 1766: train/loss = 0.6198605895042419, train/raw-loss = 0.5310591459274292, train/logprobs = tensor([[-1.3310, -4.0790],
        [-2.3454, -1.3881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08880145847797394
Epoch 0, Step 1767: train/loss = 0.3505426347255707, train/raw-loss = 0.2699088454246521, train/logprobs = tensor([[-1.0100, -3.8894],
        [-1.9371, -0.5232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08063376694917679
Epoch 0, Step 1768: train/loss = 0.5005015730857849, train/raw-loss = 0.4216432571411133, train/logprobs = tensor([[-1.0000, -2.0766],
        [-1.8327, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07885834574699402
Epoch 0, Step 1769: train/loss = 0.2503872513771057, train/raw-loss = 0.17009852826595306, train/logprobs = tensor([[-0.8680, -6.5238],
        [-1.6335, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08028872311115265
Epoch 0, Step 1770: train/loss = 0.3448118567466736, train/raw-loss = 0.2377292960882187, train/logprobs = tensor([[-1.3634, -4.6228],
        [-3.3999, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10708253085613251
Epoch 0, Step 1771: train/loss = 0.2770243287086487, train/raw-loss = 0.1910250186920166, train/logprobs = tensor([[-0.5616, -5.1790],
        [-1.8805, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08599933981895447
Epoch 0, Step 1772: train/loss = 0.2909446358680725, train/raw-loss = 0.19910459220409393, train/logprobs = tensor([[-0.8716, -5.0802],
        [-2.1537, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09184005111455917
Epoch 0, Step 1773: train/loss = 0.5073080658912659, train/raw-loss = 0.43925073742866516, train/logprobs = tensor([[-0.7122, -3.3249],
        [-2.1778, -1.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06805738061666489
Epoch 0, Step 1774: train/loss = 0.4877992272377014, train/raw-loss = 0.42284396290779114, train/logprobs = tensor([[-1.2258, -4.1681],
        [-2.4822, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06495525687932968
Epoch 0, Step 1775: train/loss = 0.4675803482532501, train/raw-loss = 0.39053916931152344, train/logprobs = tensor([[-1.0674, -2.7903],
        [-2.0006, -0.8334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07704117894172668
Epoch 0, Step 1776: train/loss = 0.3482264280319214, train/raw-loss = 0.28531554341316223, train/logprobs = tensor([[-0.7599, -4.2368],
        [-1.1498, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06291092932224274
Epoch 0, Step 1777: train/loss = 0.3457798361778259, train/raw-loss = 0.2636851370334625, train/logprobs = tensor([[-0.6487, -4.1033],
        [-2.1090, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209472894668579
Epoch 0, Step 1778: train/loss = 0.3981393575668335, train/raw-loss = 0.28726726770401, train/logprobs = tensor([[-0.6266, -2.9815],
        [-2.9932, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11087210476398468
Epoch 0, Step 1779: train/loss = 0.6331989765167236, train/raw-loss = 0.5605489015579224, train/logprobs = tensor([[-0.5487, -0.7305],
        [-2.0495, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07265006750822067
Epoch 0, Step 1780: train/loss = 0.29637086391448975, train/raw-loss = 0.2135983407497406, train/logprobs = tensor([[-0.5987, -5.1180],
        [-2.1310, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08277253061532974
Epoch 0, Step 1781: train/loss = 0.38744106888771057, train/raw-loss = 0.29274168610572815, train/logprobs = tensor([[-0.8328, -3.3897],
        [-3.1716, -1.1174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09469938278198242
Epoch 0, Step 1782: train/loss = 0.7394328713417053, train/raw-loss = 0.6575853824615479, train/logprobs = tensor([[-1.0563, -2.7300],
        [-2.4362, -2.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08184745907783508
Epoch 0, Step 1783: train/loss = 0.789031982421875, train/raw-loss = 0.7395685315132141, train/logprobs = tensor([[-1.9291, -3.4305],
        [-1.0702, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0494634173810482
Epoch 0, Step 1784: train/loss = 0.5556986331939697, train/raw-loss = 0.46364066004753113, train/logprobs = tensor([[-1.5028, -4.3711],
        [-1.4116, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0920579582452774
Epoch 0, Step 1785: train/loss = 0.35480010509490967, train/raw-loss = 0.21823565661907196, train/logprobs = tensor([[-0.9867, -3.2200],
        [-3.1483, -1.2984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1365644335746765
Epoch 0, Step 1786: train/loss = 0.384592741727829, train/raw-loss = 0.3074001371860504, train/logprobs = tensor([[-0.7451, -3.1290],
        [-2.4190, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07719261199235916
Epoch 0, Step 1787: train/loss = 0.376126229763031, train/raw-loss = 0.2496495097875595, train/logprobs = tensor([[-1.0214, -4.2071],
        [-3.5289, -1.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1264767199754715
Epoch 0, Step 1788: train/loss = 0.6144420504570007, train/raw-loss = 0.5096899271011353, train/logprobs = tensor([[-0.6275, -3.9256],
        [-2.8724, -2.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10475210845470428
Epoch 0, Step 1789: train/loss = 0.40561437606811523, train/raw-loss = 0.32999420166015625, train/logprobs = tensor([[-0.7128, -2.7980],
        [-2.6428, -0.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562018185853958
Epoch 0, Step 1790: train/loss = 0.43174317479133606, train/raw-loss = 0.3505432605743408, train/logprobs = tensor([[-0.6031, -3.1230],
        [-1.9694, -1.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08119989931583405
Epoch 0, Step 1791: train/loss = 0.21442504227161407, train/raw-loss = 0.1293267011642456, train/logprobs = tensor([[-0.7183, -5.5546],
        [-2.1858, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08509834855794907
Epoch 0, Step 1792: train/loss = 0.4943384826183319, train/raw-loss = 0.4263569116592407, train/logprobs = tensor([[-1.3787, -2.3312],
        [-1.7693, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06798155605792999
Epoch 0, Step 1793: train/loss = 0.5803084969520569, train/raw-loss = 0.4740988612174988, train/logprobs = tensor([[-1.5354, -4.4480],
        [-2.9556, -2.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062096357345581
Epoch 0, Step 1794: train/loss = 0.34805071353912354, train/raw-loss = 0.26054078340530396, train/logprobs = tensor([[-0.6380, -3.8703],
        [-2.6935, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08750993013381958
Epoch 0, Step 1795: train/loss = 0.4578830599784851, train/raw-loss = 0.4090046286582947, train/logprobs = tensor([[-0.4871, -3.5005],
        [-0.9076, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04887838661670685
Epoch 0, Step 1796: train/loss = 0.313653826713562, train/raw-loss = 0.23910027742385864, train/logprobs = tensor([[-0.7396, -5.3993],
        [-1.7943, -0.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07455352693796158
Epoch 0, Step 1797: train/loss = 0.3560391068458557, train/raw-loss = 0.27781546115875244, train/logprobs = tensor([[-0.8306, -4.1964],
        [-1.9931, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07822366058826447
Epoch 0, Step 1798: train/loss = 0.34344351291656494, train/raw-loss = 0.2561054229736328, train/logprobs = tensor([[-0.7345, -4.3937],
        [-1.5630, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08733809739351273
Epoch 0, Step 1799: train/loss = 0.23248423635959625, train/raw-loss = 0.1382424384355545, train/logprobs = tensor([[-0.6841, -5.2733],
        [-2.5379, -1.3283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09424179792404175
Epoch 0, Step 1800: train/loss = 0.1946842521429062, train/raw-loss = 0.06387054175138474, train/logprobs = tensor([[-0.6813, -5.2355],
        [-3.5922, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13081371784210205
Epoch 0, Step 1801: train/loss = 0.3379920721054077, train/raw-loss = 0.23470576107501984, train/logprobs = tensor([[-0.9561, -4.0179],
        [-2.6691, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10328628867864609
Epoch 0, Step 1802: train/loss = 0.2947121858596802, train/raw-loss = 0.20538641512393951, train/logprobs = tensor([[-0.6237, -4.5319],
        [-2.0743, -0.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08932577073574066
Epoch 0, Step 1803: train/loss = 0.33882132172584534, train/raw-loss = 0.25346001982688904, train/logprobs = tensor([[-0.6887, -3.8278],
        [-2.8203, -1.4157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0853612944483757
Epoch 0, Step 1804: train/loss = 0.3198946714401245, train/raw-loss = 0.23523709177970886, train/logprobs = tensor([[-0.9709, -4.1414],
        [-2.4577, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08465758711099625
Epoch 0, Step 1805: train/loss = 0.3629584312438965, train/raw-loss = 0.302195280790329, train/logprobs = tensor([[-0.5303, -4.8670],
        [-0.9776, -0.6622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060763150453567505
Epoch 0, Step 1806: train/loss = 0.32231593132019043, train/raw-loss = 0.22692255675792694, train/logprobs = tensor([[-0.9938, -4.2565],
        [-2.2886, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539340436458588
Epoch 0, Step 1807: train/loss = 0.4630160927772522, train/raw-loss = 0.4114144444465637, train/logprobs = tensor([[-0.7298, -2.4721],
        [-1.1377, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051601629704236984
Epoch 0, Step 1808: train/loss = 0.8747732043266296, train/raw-loss = 0.7972593307495117, train/logprobs = tensor([[-2.1209, -1.8918],
        [-1.5101, -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07751387357711792
Epoch 0, Step 1809: train/loss = 0.4599035382270813, train/raw-loss = 0.4092956781387329, train/logprobs = tensor([[-0.5794, -3.3880],
        [-1.2296, -0.7645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050607889890670776
Epoch 0, Step 1810: train/loss = 0.505180835723877, train/raw-loss = 0.44467541575431824, train/logprobs = tensor([[-0.5296, -2.7163],
        [-0.7815, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060505401343107224
Epoch 0, Step 1811: train/loss = 0.48890894651412964, train/raw-loss = 0.37793639302253723, train/logprobs = tensor([[-0.7074, -4.9176],
        [-2.6547, -1.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109725758433342
Epoch 0, Step 1812: train/loss = 0.294114887714386, train/raw-loss = 0.22014528512954712, train/logprobs = tensor([[-0.5129, -4.5888],
        [-1.3854, -0.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07396961748600006
Epoch 0, Step 1813: train/loss = 0.2734977900981903, train/raw-loss = 0.19014789164066315, train/logprobs = tensor([[-0.6772, -4.4773],
        [-2.0565, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08334989100694656
Epoch 0, Step 1814: train/loss = 0.373738557100296, train/raw-loss = 0.2885410487651825, train/logprobs = tensor([[-0.8339, -3.3783],
        [-2.3771, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08519751578569412
Epoch 0, Step 1815: train/loss = 0.3876286447048187, train/raw-loss = 0.3340469002723694, train/logprobs = tensor([[-0.6735, -2.7520],
        [-1.5933, -0.4803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053581733256578445
Epoch 0, Step 1816: train/loss = 0.6789075136184692, train/raw-loss = 0.6145761609077454, train/logprobs = tensor([[-1.3415, -3.0825],
        [-1.0167, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06433135271072388
Epoch 0, Step 1817: train/loss = 0.6695719957351685, train/raw-loss = 0.5994770526885986, train/logprobs = tensor([[-1.0018, -1.7881],
        [-0.9314, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07009495794773102
Epoch 0, Step 1818: train/loss = 0.44317835569381714, train/raw-loss = 0.3845146596431732, train/logprobs = tensor([[-0.6045, -2.8738],
        [-1.0513, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05866369605064392
Epoch 0, Step 1819: train/loss = 0.46487122774124146, train/raw-loss = 0.3893221616744995, train/logprobs = tensor([[-0.7316, -2.6646],
        [-2.5069, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07554905116558075
Epoch 0, Step 1820: train/loss = 0.4207844138145447, train/raw-loss = 0.33690667152404785, train/logprobs = tensor([[-0.7891, -3.5409],
        [-1.5408, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08387771993875504
Epoch 0, Step 1821: train/loss = 0.4609017074108124, train/raw-loss = 0.37182554602622986, train/logprobs = tensor([[-0.7971, -3.0726],
        [-2.0428, -0.8376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08907610177993774
Epoch 0, Step 1822: train/loss = 0.49004602432250977, train/raw-loss = 0.41998589038848877, train/logprobs = tensor([[-0.4440, -3.0539],
        [-1.0707, -0.6559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07006014138460159
Epoch 0, Step 1823: train/loss = 0.5062152147293091, train/raw-loss = 0.41004717350006104, train/logprobs = tensor([[-0.7230, -2.0076],
        [-2.2780, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09616809338331223
Epoch 0, Step 1824: train/loss = 0.3984724283218384, train/raw-loss = 0.33584293723106384, train/logprobs = tensor([[-0.6040, -3.9313],
        [-0.8948, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06262949109077454
Epoch 0, Step 1825: train/loss = 0.3258267641067505, train/raw-loss = 0.22458581626415253, train/logprobs = tensor([[-1.1324, -3.4297],
        [-4.3645, -0.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10124097764492035
Epoch 0, Step 1826: train/loss = 0.333739697933197, train/raw-loss = 0.25332626700401306, train/logprobs = tensor([[-0.6946, -3.7310],
        [-2.0518, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08041346073150635
Epoch 0, Step 1827: train/loss = 0.3116050362586975, train/raw-loss = 0.2287718951702118, train/logprobs = tensor([[-0.7483, -4.5627],
        [-2.0128, -1.5371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283314853906631
Epoch 0, Step 1828: train/loss = 0.3245081305503845, train/raw-loss = 0.2330479621887207, train/logprobs = tensor([[-0.9607, -3.5611],
        [-3.2744, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09146018326282501
Epoch 0, Step 1829: train/loss = 0.3542667627334595, train/raw-loss = 0.2715817391872406, train/logprobs = tensor([[-0.5577, -4.3887],
        [-2.2824, -0.5362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268500119447708
Epoch 0, Step 1830: train/loss = 0.6863033771514893, train/raw-loss = 0.5905255079269409, train/logprobs = tensor([[-1.3194, -3.5305],
        [-1.7190, -2.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577785432338715
Epoch 0, Step 1831: train/loss = 0.17027169466018677, train/raw-loss = 0.07039469480514526, train/logprobs = tensor([[-0.7657, -4.1453],
        [-4.6024, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0998769998550415
Epoch 0, Step 1832: train/loss = 0.3824217915534973, train/raw-loss = 0.3044738471508026, train/logprobs = tensor([[-0.9631, -5.2425],
        [-1.6100, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07794791460037231
Epoch 0, Step 1833: train/loss = 0.39211249351501465, train/raw-loss = 0.31033697724342346, train/logprobs = tensor([[-0.8397, -2.6119],
        [-2.5985, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817754939198494
Epoch 0, Step 1834: train/loss = 0.47958704829216003, train/raw-loss = 0.40474894642829895, train/logprobs = tensor([[-1.4456, -3.8565],
        [-2.6102, -2.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07483816146850586
Epoch 0, Step 1835: train/loss = 0.4597739577293396, train/raw-loss = 0.37293165922164917, train/logprobs = tensor([[-0.7106, -3.0464],
        [-1.3805, -0.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08684225380420685
Epoch 0, Step 1836: train/loss = 0.4999823570251465, train/raw-loss = 0.4367191791534424, train/logprobs = tensor([[-0.6372, -2.2917],
        [-1.5078, -1.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06326312571763992
Epoch 0, Step 1837: train/loss = 0.31832781434059143, train/raw-loss = 0.25052741169929504, train/logprobs = tensor([[-0.6963, -5.8569],
        [-1.4264, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0678003653883934
Epoch 0, Step 1838: train/loss = 0.9420931339263916, train/raw-loss = 0.8461489677429199, train/logprobs = tensor([[-1.0057, -1.8446],
        [-2.4876, -2.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09594415128231049
Epoch 0, Step 1839: train/loss = 0.30245620012283325, train/raw-loss = 0.18577641248703003, train/logprobs = tensor([[-0.7966, -3.5835],
        [-2.8626, -0.9260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11667978763580322
Epoch 0, Step 1840: train/loss = 0.6590980887413025, train/raw-loss = 0.5725696086883545, train/logprobs = tensor([[-1.9075, -2.3285],
        [-1.8214, -1.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08652845025062561
Epoch 0, Step 1841: train/loss = 0.36067089438438416, train/raw-loss = 0.26940691471099854, train/logprobs = tensor([[-0.5803, -3.2329],
        [-2.3506, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09126397967338562
Epoch 0, Step 1842: train/loss = 0.3697391152381897, train/raw-loss = 0.26871034502983093, train/logprobs = tensor([[-0.9653, -3.8515],
        [-2.9826, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10102877765893936
Epoch 0, Step 1843: train/loss = 0.5087093114852905, train/raw-loss = 0.42678430676460266, train/logprobs = tensor([[-0.5985, -1.3299],
        [-2.0167, -0.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08192501962184906
Epoch 0, Step 1844: train/loss = 0.4405445456504822, train/raw-loss = 0.3608427047729492, train/logprobs = tensor([[-0.8017, -2.9971],
        [-2.3348, -1.2056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07970184832811356
Epoch 0, Step 1845: train/loss = 0.3905436098575592, train/raw-loss = 0.33354926109313965, train/logprobs = tensor([[-0.5077, -2.8402],
        [-1.5086, -0.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056994371116161346
Epoch 0, Step 1846: train/loss = 0.4720548093318939, train/raw-loss = 0.4263591766357422, train/logprobs = tensor([[-0.4100, -3.3958],
        [-0.8300, -0.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045695677399635315
Epoch 0, Step 1847: train/loss = 0.336672842502594, train/raw-loss = 0.24192965030670166, train/logprobs = tensor([[-0.7253, -2.9010],
        [-3.4754, -0.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474319219589233
Epoch 0, Step 1848: train/loss = 0.34960463643074036, train/raw-loss = 0.2463383972644806, train/logprobs = tensor([[-0.7986, -3.8077],
        [-2.6038, -0.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10326625406742096
Epoch 0, Step 1849: train/loss = 0.3818584680557251, train/raw-loss = 0.27798768877983093, train/logprobs = tensor([[-1.2567, -5.5648],
        [-2.4909, -1.2352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10387080162763596
Epoch 0, Step 1850: train/loss = 0.2915564775466919, train/raw-loss = 0.19215059280395508, train/logprobs = tensor([[-0.6827, -4.1762],
        [-2.3372, -1.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09940586984157562
Epoch 0, Step 1851: train/loss = 0.4241812825202942, train/raw-loss = 0.3547559380531311, train/logprobs = tensor([[-0.9350, -1.4559],
        [-2.5218, -0.5573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06942537426948547
Epoch 0, Step 1852: train/loss = 0.5177314281463623, train/raw-loss = 0.4308813214302063, train/logprobs = tensor([[-0.9934, -2.4233],
        [-2.2349, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0868501216173172
Epoch 0, Step 1853: train/loss = 0.3822384178638458, train/raw-loss = 0.32676365971565247, train/logprobs = tensor([[-0.6723, -3.1537],
        [-2.2739, -0.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05547475069761276
Epoch 0, Step 1854: train/loss = 0.2458476424217224, train/raw-loss = 0.17218852043151855, train/logprobs = tensor([[-0.5943, -6.3045],
        [-1.7448, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365913689136505
Epoch 0, Step 1855: train/loss = 0.2733341455459595, train/raw-loss = 0.18048915266990662, train/logprobs = tensor([[-0.5600, -4.4466],
        [-1.9246, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09284500032663345
Epoch 0, Step 1856: train/loss = 0.2281159609556198, train/raw-loss = 0.14410215616226196, train/logprobs = tensor([[-0.7697, -5.1256],
        [-2.1358, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08401380479335785
Epoch 0, Step 1857: train/loss = 0.3773692846298218, train/raw-loss = 0.2862921357154846, train/logprobs = tensor([[-0.8637, -4.3265],
        [-1.7956, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09107713401317596
Epoch 0, Step 1858: train/loss = 0.3912319839000702, train/raw-loss = 0.33089110255241394, train/logprobs = tensor([[-0.4492, -4.1891],
        [-0.7744, -1.6150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060340870171785355
Epoch 0, Step 1859: train/loss = 0.6033205986022949, train/raw-loss = 0.5668719410896301, train/logprobs = tensor([[-0.3574, -1.8593],
        [-0.5029, -0.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036448635160923004
Epoch 0, Step 1860: train/loss = 0.24124929308891296, train/raw-loss = 0.1397051364183426, train/logprobs = tensor([[-0.8348, -3.8408],
        [-4.2642, -1.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10154416412115097
Epoch 0, Step 1861: train/loss = 0.5490506291389465, train/raw-loss = 0.457103967666626, train/logprobs = tensor([[-0.9475, -2.8940],
        [-2.8103, -1.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194668382406235
Epoch 0, Step 1862: train/loss = 0.3975532650947571, train/raw-loss = 0.2997434735298157, train/logprobs = tensor([[-0.8268, -4.2690],
        [-1.8403, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0978097915649414
Epoch 0, Step 1863: train/loss = 0.29570695757865906, train/raw-loss = 0.21727806329727173, train/logprobs = tensor([[-0.3978, -4.5289],
        [-1.7120, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07842889428138733
Epoch 0, Step 1864: train/loss = 0.3440916836261749, train/raw-loss = 0.24966424703598022, train/logprobs = tensor([[-0.7844, -4.4483],
        [-2.6729, -0.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09442742168903351
Epoch 0, Step 1865: train/loss = 0.47202232480049133, train/raw-loss = 0.41174277663230896, train/logprobs = tensor([[-0.5760, -2.9684],
        [-0.9502, -0.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06027957424521446
Epoch 0, Step 1866: train/loss = 0.28967756032943726, train/raw-loss = 0.20912790298461914, train/logprobs = tensor([[-0.6490, -5.9983],
        [-1.1720, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08054965734481812
Epoch 0, Step 1867: train/loss = 0.8301392197608948, train/raw-loss = 0.7537108659744263, train/logprobs = tensor([[-0.7115, -2.4214],
        [-2.0911, -2.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764283686876297
Epoch 0, Step 1868: train/loss = 0.3989320993423462, train/raw-loss = 0.3048192858695984, train/logprobs = tensor([[-0.8792, -2.3825],
        [-3.1183, -1.2110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09411276876926422
Epoch 0, Step 1869: train/loss = 0.4008297324180603, train/raw-loss = 0.31608784198760986, train/logprobs = tensor([[-0.9312, -4.7878],
        [-2.5939, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08474187552928925
Epoch 0, Step 1870: train/loss = 0.3110651969909668, train/raw-loss = 0.2105337232351303, train/logprobs = tensor([[-0.8226, -3.9108],
        [-3.1958, -1.2619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10053147375583649
Epoch 0, Step 1871: train/loss = 0.3858955204486847, train/raw-loss = 0.31952139735221863, train/logprobs = tensor([[-0.5297, -4.6554],
        [-1.1386, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06637412309646606
Epoch 0, Step 1872: train/loss = 0.4785540699958801, train/raw-loss = 0.41912639141082764, train/logprobs = tensor([[-1.0346, -3.5993],
        [-1.0264, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05942770093679428
Epoch 0, Step 1873: train/loss = 0.43861934542655945, train/raw-loss = 0.3734781742095947, train/logprobs = tensor([[-0.8332, -2.8516],
        [-1.5946, -1.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06514118611812592
Epoch 0, Step 1874: train/loss = 0.2095371037721634, train/raw-loss = 0.10101060569286346, train/logprobs = tensor([[-1.0183, -5.3385],
        [-4.0292, -1.4130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10852650552988052
Epoch 0, Step 1875: train/loss = 0.3638354539871216, train/raw-loss = 0.278165340423584, train/logprobs = tensor([[-0.9212, -3.8807],
        [-1.7119, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08567013591527939
Epoch 0, Step 1876: train/loss = 0.37320443987846375, train/raw-loss = 0.2950964570045471, train/logprobs = tensor([[-0.5381, -4.0387],
        [-1.4631, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07810796797275543
Epoch 0, Step 1877: train/loss = 0.3542989194393158, train/raw-loss = 0.2413896918296814, train/logprobs = tensor([[-0.8026, -4.1611],
        [-3.1582, -1.0462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129092201590538
Epoch 0, Step 1878: train/loss = 0.5010074973106384, train/raw-loss = 0.4116412103176117, train/logprobs = tensor([[-0.5507, -2.7982],
        [-1.1800, -0.7168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08936627209186554
Epoch 0, Step 1879: train/loss = 0.18778301775455475, train/raw-loss = 0.10607226192951202, train/logprobs = tensor([[-0.7485, -7.5727],
        [-3.0122, -2.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08171076327562332
Epoch 0, Step 1880: train/loss = 0.4528956413269043, train/raw-loss = 0.3828166425228119, train/logprobs = tensor([[-1.8690, -2.5360],
        [-3.7948, -0.5376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07007899880409241
Epoch 0, Step 1881: train/loss = 0.3149074912071228, train/raw-loss = 0.22695127129554749, train/logprobs = tensor([[-0.9979, -4.9327],
        [-1.6264, -0.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08795623481273651
Epoch 0, Step 1882: train/loss = 0.35309934616088867, train/raw-loss = 0.26896774768829346, train/logprobs = tensor([[-0.5992, -3.7770],
        [-2.4301, -0.6098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08413158357143402
Epoch 0, Step 1883: train/loss = 0.3554355502128601, train/raw-loss = 0.268708199262619, train/logprobs = tensor([[-0.8178, -4.2948],
        [-3.6104, -0.6367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08672737330198288
Epoch 0, Step 1884: train/loss = 0.3880888521671295, train/raw-loss = 0.31217268109321594, train/logprobs = tensor([[-0.6287, -3.6952],
        [-1.6904, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07591620087623596
Epoch 0, Step 1885: train/loss = 0.42884737253189087, train/raw-loss = 0.33488351106643677, train/logprobs = tensor([[-1.1346, -2.1194],
        [-3.1974, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09396383911371231
Epoch 0, Step 1886: train/loss = 0.30194953083992004, train/raw-loss = 0.20877042412757874, train/logprobs = tensor([[-0.8469, -3.5092],
        [-3.5136, -1.0369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09317909926176071
Epoch 0, Step 1887: train/loss = 0.2803986370563507, train/raw-loss = 0.20784881711006165, train/logprobs = tensor([[-0.9157, -4.2239],
        [-1.6770, -0.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07254981994628906
Epoch 0, Step 1888: train/loss = 0.4889448285102844, train/raw-loss = 0.41401931643486023, train/logprobs = tensor([[-1.9235, -2.6115],
        [-2.9302, -0.6780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.074925497174263
Epoch 0, Step 1889: train/loss = 0.21475012600421906, train/raw-loss = 0.10937167704105377, train/logprobs = tensor([[-0.6614, -5.2554],
        [-3.1708, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10537844151258469
Epoch 0, Step 1890: train/loss = 0.797521710395813, train/raw-loss = 0.68919837474823, train/logprobs = tensor([[-1.1965, -2.6108],
        [-3.0622, -1.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10832333564758301
Epoch 0, Step 1891: train/loss = 0.35309362411499023, train/raw-loss = 0.26827847957611084, train/logprobs = tensor([[-0.7158, -5.3826],
        [-1.8151, -0.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08481510728597641
Epoch 0, Step 1892: train/loss = 0.21458634734153748, train/raw-loss = 0.11402049660682678, train/logprobs = tensor([[-0.9875, -5.1776],
        [-3.6855, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005658432841301
Epoch 0, Step 1893: train/loss = 0.2045263946056366, train/raw-loss = 0.09863549470901489, train/logprobs = tensor([[-0.9928, -4.1392],
        [-4.7584, -1.4048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058908998966217
Epoch 0, Step 1894: train/loss = 0.3537950813770294, train/raw-loss = 0.2851242423057556, train/logprobs = tensor([[-0.6932, -2.6752],
        [-2.4583, -0.7257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686708465218544
Epoch 0, Step 1895: train/loss = 0.45689457654953003, train/raw-loss = 0.3889881372451782, train/logprobs = tensor([[-0.7604, -3.2785],
        [-1.6086, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06790647655725479
Epoch 0, Step 1896: train/loss = 0.5109648108482361, train/raw-loss = 0.4160255789756775, train/logprobs = tensor([[-0.9514, -2.2340],
        [-2.5804, -0.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949392318725586
Epoch 0, Step 1897: train/loss = 0.3717942535877228, train/raw-loss = 0.2928158640861511, train/logprobs = tensor([[-0.6427, -4.2792],
        [-1.0656, -1.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07897835224866867
Epoch 0, Step 1898: train/loss = 0.35061678290367126, train/raw-loss = 0.2517622709274292, train/logprobs = tensor([[-1.1403, -3.3925],
        [-2.1731, -0.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09885451197624207
Epoch 0, Step 1899: train/loss = 0.3880700469017029, train/raw-loss = 0.310200035572052, train/logprobs = tensor([[-0.7681, -2.5297],
        [-2.0267, -0.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07787001132965088
Epoch 0, Step 1900: train/loss = 0.28755438327789307, train/raw-loss = 0.18821284174919128, train/logprobs = tensor([[-0.9572, -4.0333],
        [-2.7517, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09934152662754059
Epoch 0, Step 1901: train/loss = 0.46096301078796387, train/raw-loss = 0.3946075737476349, train/logprobs = tensor([[-1.0505, -3.7940],
        [-1.2959, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06635544449090958
Epoch 0, Step 1902: train/loss = 0.5952684283256531, train/raw-loss = 0.4875155985355377, train/logprobs = tensor([[-1.6062, -4.3880],
        [-3.4835, -2.2291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10775283724069595
Epoch 0, Step 1903: train/loss = 0.2635255753993988, train/raw-loss = 0.17068162560462952, train/logprobs = tensor([[-0.4944, -4.8480],
        [-1.4321, -0.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09284394979476929
Epoch 0, Step 1904: train/loss = 0.4594213366508484, train/raw-loss = 0.35465380549430847, train/logprobs = tensor([[-1.1704, -1.7499],
        [-3.3081, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10476754605770111
Epoch 0, Step 1905: train/loss = 0.2765214145183563, train/raw-loss = 0.20081943273544312, train/logprobs = tensor([[-0.5695, -3.7767],
        [-2.1315, -0.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07570197433233261
Epoch 0, Step 1906: train/loss = 0.34237751364707947, train/raw-loss = 0.2553563714027405, train/logprobs = tensor([[-0.7391, -2.4250],
        [-3.1461, -0.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08702118694782257
Epoch 0, Step 1907: train/loss = 0.5956559777259827, train/raw-loss = 0.551494836807251, train/logprobs = tensor([[-0.5098, -1.3376],
        [-0.6338, -0.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044161152094602585
Epoch 0, Step 1908: train/loss = 0.2609093487262726, train/raw-loss = 0.17060916125774384, train/logprobs = tensor([[-1.2194, -2.2983],
        [-5.3549, -0.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09030018746852875
Epoch 0, Step 1909: train/loss = 0.20588447153568268, train/raw-loss = 0.0837278664112091, train/logprobs = tensor([[-0.9531, -5.4123],
        [-3.5998, -1.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12215661257505417
Epoch 0, Step 1910: train/loss = 0.5255728363990784, train/raw-loss = 0.440574586391449, train/logprobs = tensor([[-0.9670, -1.8855],
        [-2.4871, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499830216169357
Epoch 0, Step 1911: train/loss = 0.5204865336418152, train/raw-loss = 0.4503704309463501, train/logprobs = tensor([[-0.6881, -2.4145],
        [-1.9614, -0.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07011611014604568
Epoch 0, Step 1912: train/loss = 0.4737986922264099, train/raw-loss = 0.4094170331954956, train/logprobs = tensor([[-1.9504, -3.3213],
        [-3.0329, -1.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06438164412975311
Epoch 0, Step 1913: train/loss = 0.3413480520248413, train/raw-loss = 0.26740744709968567, train/logprobs = tensor([[-1.4651, -3.1160],
        [-3.3387, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07394060492515564
Epoch 0, Step 1914: train/loss = 0.2787606120109558, train/raw-loss = 0.17420469224452972, train/logprobs = tensor([[-0.6255, -3.8984],
        [-3.1450, -0.6605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10455591976642609
Epoch 0, Step 1915: train/loss = 0.27843862771987915, train/raw-loss = 0.20721668004989624, train/logprobs = tensor([[-0.9574, -4.1557],
        [-2.6762, -0.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07122193276882172
Epoch 0, Step 1916: train/loss = 0.3528216481208801, train/raw-loss = 0.24905350804328918, train/logprobs = tensor([[-0.7229, -1.8926],
        [-4.3358, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10376812517642975
Epoch 0, Step 1917: train/loss = 0.260379821062088, train/raw-loss = 0.17829369008541107, train/logprobs = tensor([[-0.9941, -3.9708],
        [-2.9207, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08208613097667694
Epoch 0, Step 1918: train/loss = 0.43900686502456665, train/raw-loss = 0.3726656138896942, train/logprobs = tensor([[-0.6583, -3.9420],
        [-1.0473, -0.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06634125113487244
Epoch 0, Step 1919: train/loss = 0.2994322180747986, train/raw-loss = 0.22578199207782745, train/logprobs = tensor([[-0.6007, -5.8286],
        [-1.2855, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07365021854639053
Epoch 0, Step 1920: train/loss = 0.2560640573501587, train/raw-loss = 0.17816457152366638, train/logprobs = tensor([[-0.5908, -5.5080],
        [-1.9329, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07789947092533112
Epoch 0, Step 1921: train/loss = 0.2186833620071411, train/raw-loss = 0.1234661191701889, train/logprobs = tensor([[-0.5626, -4.9521],
        [-2.8001, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09521723538637161
Epoch 0, Step 1922: train/loss = 0.4267108142375946, train/raw-loss = 0.3544218838214874, train/logprobs = tensor([[-0.6930, -2.9342],
        [-1.9084, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07228893041610718
Epoch 0, Step 1923: train/loss = 0.4253728985786438, train/raw-loss = 0.35312217473983765, train/logprobs = tensor([[-0.6736, -3.2442],
        [-1.7757, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07225076854228973
Epoch 0, Step 1924: train/loss = 0.5408336520195007, train/raw-loss = 0.44825130701065063, train/logprobs = tensor([[-1.1332, -2.7064],
        [-2.7731, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09258238971233368
Epoch 0, Step 1925: train/loss = 0.4521445631980896, train/raw-loss = 0.40310049057006836, train/logprobs = tensor([[-2.4703, -2.6901],
        [-3.7235, -1.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04904405400156975
Epoch 0, Step 1926: train/loss = 0.3209495544433594, train/raw-loss = 0.23959755897521973, train/logprobs = tensor([[-0.6573, -4.2358],
        [-2.0919, -0.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08135202527046204
Epoch 0, Step 1927: train/loss = 0.4177187979221344, train/raw-loss = 0.34101444482803345, train/logprobs = tensor([[-0.7146, -2.5987],
        [-2.2448, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07670433819293976
Epoch 0, Step 1928: train/loss = 0.3726024627685547, train/raw-loss = 0.26241534948349, train/logprobs = tensor([[-0.7026, -2.3468],
        [-3.8477, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11018714308738708
Epoch 0, Step 1929: train/loss = 0.42487531900405884, train/raw-loss = 0.33769792318344116, train/logprobs = tensor([[-0.6446, -2.1467],
        [-2.0166, -0.6147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08717743307352066
Epoch 0, Step 1930: train/loss = 0.4710405170917511, train/raw-loss = 0.41124141216278076, train/logprobs = tensor([[-0.6943, -2.0415],
        [-2.7198, -0.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05979911983013153
Epoch 0, Step 1931: train/loss = 0.5220121741294861, train/raw-loss = 0.45573896169662476, train/logprobs = tensor([[-1.2096, -4.2083],
        [-1.2509, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06627321988344193
Epoch 0, Step 1932: train/loss = 0.5423744320869446, train/raw-loss = 0.4854516386985779, train/logprobs = tensor([[-0.6207, -1.0244],
        [-1.7293, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05692276358604431
Epoch 0, Step 1933: train/loss = 0.56011962890625, train/raw-loss = 0.4828457236289978, train/logprobs = tensor([[-2.0534, -5.8756],
        [-1.5033, -1.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077273890376091
Epoch 0, Step 1934: train/loss = 0.46967703104019165, train/raw-loss = 0.4029061198234558, train/logprobs = tensor([[-0.7433, -2.0079],
        [-3.0625, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06677091121673584
Epoch 0, Step 1935: train/loss = 0.23116713762283325, train/raw-loss = 0.14618444442749023, train/logprobs = tensor([[-1.3312, -5.4476],
        [-2.6358, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08498267084360123
Epoch 0, Step 1936: train/loss = 0.5731780529022217, train/raw-loss = 0.5033131837844849, train/logprobs = tensor([[-0.9640, -2.2062],
        [-1.5729, -0.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0698648989200592
Epoch 0, Step 1937: train/loss = 0.33353009819984436, train/raw-loss = 0.25416797399520874, train/logprobs = tensor([[-1.0468, -4.1682],
        [-2.1845, -1.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793621614575386
Epoch 0, Step 1938: train/loss = 0.3853638172149658, train/raw-loss = 0.3179795742034912, train/logprobs = tensor([[-0.8564, -3.5570],
        [-2.2746, -0.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0673842653632164
Epoch 0, Step 1939: train/loss = 0.48459672927856445, train/raw-loss = 0.40948915481567383, train/logprobs = tensor([[-0.6880, -3.1070],
        [-1.5798, -1.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07510758936405182
Epoch 0, Step 1940: train/loss = 0.33135464787483215, train/raw-loss = 0.24741770327091217, train/logprobs = tensor([[-0.6367, -3.8268],
        [-2.6640, -0.6795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08393694460391998
Epoch 0, Step 1941: train/loss = 0.20553536713123322, train/raw-loss = 0.11257793009281158, train/logprobs = tensor([[-0.8699, -5.1293],
        [-3.6386, -1.5297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09295743703842163
Epoch 0, Step 1942: train/loss = 0.27875271439552307, train/raw-loss = 0.21886253356933594, train/logprobs = tensor([[-0.3809, -5.0934],
        [-1.3232, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05989019572734833
Epoch 0, Step 1943: train/loss = 0.497665137052536, train/raw-loss = 0.43321317434310913, train/logprobs = tensor([[-0.6990, -3.3879],
        [-0.6754, -0.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06445200741291046
Epoch 0, Step 1944: train/loss = 0.49148887395858765, train/raw-loss = 0.4065406024456024, train/logprobs = tensor([[-0.6767, -2.8219],
        [-1.4267, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08494827151298523
Epoch 0, Step 1945: train/loss = 0.38623350858688354, train/raw-loss = 0.28693634271621704, train/logprobs = tensor([[-1.4163, -2.4776],
        [-4.0710, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992971733212471
Epoch 0, Step 1946: train/loss = 0.30532363057136536, train/raw-loss = 0.22523954510688782, train/logprobs = tensor([[-0.5209, -3.9166],
        [-2.3231, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008407056331635
Epoch 0, Step 1947: train/loss = 0.32951679825782776, train/raw-loss = 0.22865456342697144, train/logprobs = tensor([[-0.6380, -3.8997],
        [-2.8027, -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10086224228143692
Epoch 0, Step 1948: train/loss = 0.5089977383613586, train/raw-loss = 0.4528939425945282, train/logprobs = tensor([[-0.7682, -4.0867],
        [-0.8287, -0.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05610378086566925
Epoch 0, Step 1949: train/loss = 0.3868659734725952, train/raw-loss = 0.2971739172935486, train/logprobs = tensor([[-0.6124, -4.8195],
        [-1.5190, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969204872846603
Epoch 0, Step 1950: train/loss = 0.4724230170249939, train/raw-loss = 0.39630696177482605, train/logprobs = tensor([[-0.5586, -4.4010],
        [-1.2587, -1.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07611606270074844
Epoch 0, Step 1951: train/loss = 0.38667210936546326, train/raw-loss = 0.2753947079181671, train/logprobs = tensor([[-0.9299, -3.3076],
        [-3.2053, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11127743124961853
Epoch 0, Step 1952: train/loss = 0.2667653560638428, train/raw-loss = 0.18226081132888794, train/logprobs = tensor([[-0.6268, -5.6803],
        [-2.2626, -1.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08450454473495483
Epoch 0, Step 1953: train/loss = 0.4791741669178009, train/raw-loss = 0.4324474632740021, train/logprobs = tensor([[-0.5164, -4.1648],
        [-0.8284, -1.2352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046726685017347336
Epoch 0, Step 1954: train/loss = 0.53590327501297, train/raw-loss = 0.4702513515949249, train/logprobs = tensor([[-0.6227, -2.6658],
        [-0.6979, -0.5609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06565193086862564
Epoch 0, Step 1955: train/loss = 0.379093736410141, train/raw-loss = 0.29992276430130005, train/logprobs = tensor([[-1.7222, -3.4934],
        [-3.2254, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07917099446058273
Epoch 0, Step 1956: train/loss = 0.37033575773239136, train/raw-loss = 0.2872927784919739, train/logprobs = tensor([[-0.6564, -4.3495],
        [-1.9571, -0.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08304296433925629
Epoch 0, Step 1957: train/loss = 0.3274725675582886, train/raw-loss = 0.22785505652427673, train/logprobs = tensor([[-0.8459, -3.9463],
        [-2.9939, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09961751848459244
Epoch 0, Step 1958: train/loss = 0.40542981028556824, train/raw-loss = 0.3307759463787079, train/logprobs = tensor([[-0.6982, -3.3195],
        [-1.9946, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07465385645627975
Epoch 0, Step 1959: train/loss = 0.565335214138031, train/raw-loss = 0.4982481002807617, train/logprobs = tensor([[-0.6080, -0.9896],
        [-1.9043, -0.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06708710640668869
Epoch 0, Step 1960: train/loss = 0.21882528066635132, train/raw-loss = 0.10448853671550751, train/logprobs = tensor([[-0.8827, -4.8601],
        [-3.2748, -0.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11433675140142441
Epoch 0, Step 1961: train/loss = 0.5345579385757446, train/raw-loss = 0.47927403450012207, train/logprobs = tensor([[-0.9138, -2.1979],
        [-2.3364, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055283933877944946
Epoch 0, Step 1962: train/loss = 0.6083536148071289, train/raw-loss = 0.5560857057571411, train/logprobs = tensor([[-0.5216, -0.6494],
        [-1.3401, -0.4437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05226796120405197
Epoch 0, Step 1963: train/loss = 0.4356006681919098, train/raw-loss = 0.3212834298610687, train/logprobs = tensor([[-1.2338, -3.7510],
        [-2.6674, -1.0068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11431720852851868
Epoch 0, Step 1964: train/loss = 0.356006920337677, train/raw-loss = 0.2578108310699463, train/logprobs = tensor([[-0.9168, -6.0784],
        [-2.6179, -1.2625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0981961339712143
Epoch 0, Step 1965: train/loss = 0.47197484970092773, train/raw-loss = 0.3988601565361023, train/logprobs = tensor([[-0.5134, -2.2236],
        [-1.3505, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07311469316482544
Epoch 0, Step 1966: train/loss = 0.2748878002166748, train/raw-loss = 0.19423183798789978, train/logprobs = tensor([[-0.7314, -4.6693],
        [-2.2856, -0.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08065599203109741
Epoch 0, Step 1967: train/loss = 0.3723104000091553, train/raw-loss = 0.30864834785461426, train/logprobs = tensor([[-0.6317, -4.2868],
        [-1.5051, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06366202980279922
Epoch 0, Step 1968: train/loss = 0.4362347424030304, train/raw-loss = 0.36554697155952454, train/logprobs = tensor([[-0.7586, -3.4388],
        [-1.1895, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07068780064582825
Epoch 0, Step 1969: train/loss = 0.5089367628097534, train/raw-loss = 0.4239058196544647, train/logprobs = tensor([[-0.8766, -2.0449],
        [-2.0759, -0.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08503101766109467
Epoch 0, Step 1970: train/loss = 0.4129851758480072, train/raw-loss = 0.3171032667160034, train/logprobs = tensor([[-2.1335, -2.9910],
        [-3.9161, -0.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09588192403316498
Epoch 0, Step 1971: train/loss = 0.3667723536491394, train/raw-loss = 0.29590046405792236, train/logprobs = tensor([[-0.5375, -4.1804],
        [-1.6865, -0.6626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07087188959121704
Epoch 0, Step 1972: train/loss = 0.4916417896747589, train/raw-loss = 0.4230297803878784, train/logprobs = tensor([[-0.5729, -2.1960],
        [-1.7340, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686119869351387
Epoch 0, Step 1973: train/loss = 0.41846969723701477, train/raw-loss = 0.34812358021736145, train/logprobs = tensor([[-0.5900, -3.5036],
        [-1.6880, -0.7411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07034613192081451
Epoch 0, Step 1974: train/loss = 0.4225015640258789, train/raw-loss = 0.33479341864585876, train/logprobs = tensor([[-1.2760, -3.2429],
        [-3.0961, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08770816773176193
Epoch 0, Step 1975: train/loss = 0.3951529264450073, train/raw-loss = 0.3311600685119629, train/logprobs = tensor([[-0.7922, -4.2247],
        [-2.0240, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06399283558130264
Epoch 0, Step 1976: train/loss = 0.6894937753677368, train/raw-loss = 0.6076710224151611, train/logprobs = tensor([[-1.3205, -1.6953],
        [-2.5794, -1.3556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818227231502533
Epoch 0, Step 1977: train/loss = 0.5023691654205322, train/raw-loss = 0.4499271810054779, train/logprobs = tensor([[-0.4618, -2.7399],
        [-0.6763, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05244193598628044
Epoch 0, Step 1978: train/loss = 0.520958423614502, train/raw-loss = 0.4736565351486206, train/logprobs = tensor([[-0.4082, -2.0069],
        [-1.0001, -0.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04730185866355896
Epoch 0, Step 1979: train/loss = 0.7955455780029297, train/raw-loss = 0.7018643617630005, train/logprobs = tensor([[-2.0240, -3.7448],
        [-3.6354, -1.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09368114173412323
Epoch 0, Step 1980: train/loss = 0.49564945697784424, train/raw-loss = 0.41607171297073364, train/logprobs = tensor([[-0.8256, -1.8753],
        [-2.9343, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07957769930362701
Epoch 0, Step 1981: train/loss = 0.2240608036518097, train/raw-loss = 0.1153232753276825, train/logprobs = tensor([[-0.8646, -7.3614],
        [-3.5973, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1087375357747078
Epoch 0, Step 1982: train/loss = 0.4285276532173157, train/raw-loss = 0.36366671323776245, train/logprobs = tensor([[-0.7502, -5.3082],
        [-0.7344, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06486094743013382
Epoch 0, Step 1983: train/loss = 0.5124777555465698, train/raw-loss = 0.4145544469356537, train/logprobs = tensor([[-1.2128, -2.8172],
        [-2.7665, -1.6218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09792328625917435
Epoch 0, Step 1984: train/loss = 0.3857271373271942, train/raw-loss = 0.3090643882751465, train/logprobs = tensor([[-0.8344, -2.2726],
        [-2.9322, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07666274905204773
Epoch 0, Step 1985: train/loss = 1.0819034576416016, train/raw-loss = 0.97923743724823, train/logprobs = tensor([[-2.2527, -4.1929],
        [-3.5472, -3.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.102665975689888
Epoch 0, Step 1986: train/loss = 0.415189653635025, train/raw-loss = 0.33166491985321045, train/logprobs = tensor([[-0.9901, -3.8720],
        [-1.3862, -0.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08352474868297577
Epoch 0, Step 1987: train/loss = 0.393335223197937, train/raw-loss = 0.30520373582839966, train/logprobs = tensor([[-0.6811, -2.3673],
        [-2.3749, -0.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08813147991895676
Epoch 0, Step 1988: train/loss = 0.30345290899276733, train/raw-loss = 0.21600617468357086, train/logprobs = tensor([[-0.8999, -3.4146],
        [-3.9646, -0.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08744671940803528
Epoch 0, Step 1989: train/loss = 0.3163657486438751, train/raw-loss = 0.22416359186172485, train/logprobs = tensor([[-1.2924, -4.0452],
        [-3.5574, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09220216423273087
Epoch 0, Step 1990: train/loss = 0.2533484101295471, train/raw-loss = 0.16651614010334015, train/logprobs = tensor([[-0.6776, -4.2359],
        [-2.9629, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08683228492736816
Epoch 0, Step 1991: train/loss = 0.5139696002006531, train/raw-loss = 0.4335445165634155, train/logprobs = tensor([[-1.0817, -3.7743],
        [-0.7840, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08042506873607635
Epoch 0, Step 1992: train/loss = 0.26850825548171997, train/raw-loss = 0.18087908625602722, train/logprobs = tensor([[-0.7789, -4.6261],
        [-2.9136, -1.3189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08762916177511215
Epoch 0, Step 1993: train/loss = 0.29414576292037964, train/raw-loss = 0.20028334856033325, train/logprobs = tensor([[-0.9593, -3.3916],
        [-3.4055, -0.8995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09386241436004639
Epoch 0, Step 1994: train/loss = 0.8254891037940979, train/raw-loss = 0.7259202003479004, train/logprobs = tensor([[-2.6991, -4.7045],
        [-2.0553, -1.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09956898540258408
Epoch 0, Step 1995: train/loss = 0.4889201521873474, train/raw-loss = 0.4263143539428711, train/logprobs = tensor([[-1.2602, -3.4545],
        [-1.7547, -1.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06260579824447632
Epoch 0, Step 1996: train/loss = 0.27485179901123047, train/raw-loss = 0.19525371491909027, train/logprobs = tensor([[-0.6583, -6.2508],
        [-2.2355, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0795980915427208
Epoch 0, Step 1997: train/loss = 0.38550257682800293, train/raw-loss = 0.2946089804172516, train/logprobs = tensor([[-0.5694, -3.4226],
        [-1.7917, -1.1392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09089358150959015
Epoch 0, Step 1998: train/loss = 0.47078245878219604, train/raw-loss = 0.3910580575466156, train/logprobs = tensor([[-1.0016, -4.4593],
        [-0.8972, -0.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07972444593906403
Epoch 0, Step 1999: train/loss = 0.47484108805656433, train/raw-loss = 0.3874766230583191, train/logprobs = tensor([[-0.8928, -2.3195],
        [-2.0583, -0.7468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08736446499824524
Loss is nan
eval/loss: 0.407362163066864
Epoch 0, Step 2000: train/loss = 0.41016072034835815, train/raw-loss = 0.32335591316223145, train/logprobs = tensor([[-1.4064, -1.9271],
        [-3.3282, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0868048295378685
Epoch 0, Step 2001: train/loss = 0.6871941685676575, train/raw-loss = 0.6193450689315796, train/logprobs = tensor([[-0.5836, -2.2743],
        [-1.7312, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06784918159246445
Epoch 0, Step 2002: train/loss = 0.2926878035068512, train/raw-loss = 0.19398975372314453, train/logprobs = tensor([[-0.7275, -4.7695],
        [-2.8811, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09869804978370667
Epoch 0, Step 2003: train/loss = 0.4397965967655182, train/raw-loss = 0.33043503761291504, train/logprobs = tensor([[-0.8392, -2.6899],
        [-2.7511, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10936156660318375
Epoch 0, Step 2004: train/loss = 0.23642051219940186, train/raw-loss = 0.13564565777778625, train/logprobs = tensor([[-0.8114, -5.3657],
        [-4.0121, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1007748544216156
Epoch 0, Step 2005: train/loss = 0.5010272264480591, train/raw-loss = 0.4292089641094208, train/logprobs = tensor([[-1.3344, -3.4483],
        [-1.6346, -0.7782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0718182921409607
Epoch 0, Step 2006: train/loss = 0.22870585322380066, train/raw-loss = 0.12556374073028564, train/logprobs = tensor([[-0.9012, -5.0074],
        [-3.8555, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10314211249351501
Epoch 0, Step 2007: train/loss = 0.2550593316555023, train/raw-loss = 0.1564030796289444, train/logprobs = tensor([[-0.6628, -4.1579],
        [-3.1732, -0.6792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09865625947713852
Epoch 0, Step 2008: train/loss = 0.5179084539413452, train/raw-loss = 0.4577202796936035, train/logprobs = tensor([[-0.6762, -2.3842],
        [-0.7030, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060188230127096176
Epoch 0, Step 2009: train/loss = 0.3795478940010071, train/raw-loss = 0.2977820932865143, train/logprobs = tensor([[-0.5440, -3.9549],
        [-1.1550, -0.8675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817658007144928
Epoch 0, Step 2010: train/loss = 0.6737813949584961, train/raw-loss = 0.5786107778549194, train/logprobs = tensor([[-0.8061, -5.3769],
        [-2.6285, -2.3400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09517060220241547
Epoch 0, Step 2011: train/loss = 0.40890365839004517, train/raw-loss = 0.3151220977306366, train/logprobs = tensor([[-0.7940, -4.5459],
        [-3.2464, -1.3889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09378156065940857
Epoch 0, Step 2012: train/loss = 0.3362310826778412, train/raw-loss = 0.2473219931125641, train/logprobs = tensor([[-0.8856, -5.7023],
        [-1.4044, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08890905976295471
Epoch 0, Step 2013: train/loss = 0.6290814876556396, train/raw-loss = 0.5553383827209473, train/logprobs = tensor([[-0.9249, -1.7798],
        [-1.1186, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07374314218759537
Epoch 0, Step 2014: train/loss = 0.37908220291137695, train/raw-loss = 0.29692769050598145, train/logprobs = tensor([[-0.8021, -2.5562],
        [-3.1719, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08215455710887909
Epoch 0, Step 2015: train/loss = 0.3934990167617798, train/raw-loss = 0.3292832672595978, train/logprobs = tensor([[-0.9105, -3.9042],
        [-1.2537, -0.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.064215749502182
Epoch 0, Step 2016: train/loss = 0.5128117203712463, train/raw-loss = 0.4196065068244934, train/logprobs = tensor([[-1.1026, -1.9820],
        [-4.8440, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09320522099733353
Epoch 0, Step 2017: train/loss = 0.4217202067375183, train/raw-loss = 0.34288641810417175, train/logprobs = tensor([[-1.4502, -3.8348],
        [-2.3166, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883379608392715
Epoch 0, Step 2018: train/loss = 0.5266151428222656, train/raw-loss = 0.41305893659591675, train/logprobs = tensor([[-0.8427, -1.9302],
        [-2.6645, -1.5192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11355623602867126
Epoch 0, Step 2019: train/loss = 0.33749133348464966, train/raw-loss = 0.27298682928085327, train/logprobs = tensor([[-0.5339, -3.8422],
        [-1.3267, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06450451165437698
Epoch 0, Step 2020: train/loss = 0.45512354373931885, train/raw-loss = 0.37135371565818787, train/logprobs = tensor([[-0.6219, -3.3170],
        [-2.5734, -1.2913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08376982808113098
Epoch 0, Step 2021: train/loss = 0.7609223127365112, train/raw-loss = 0.6945130825042725, train/logprobs = tensor([[-0.5395, -3.1508],
        [-0.7676, -1.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640921533107758
Epoch 0, Step 2022: train/loss = 0.5215470194816589, train/raw-loss = 0.4670824408531189, train/logprobs = tensor([[-0.3594, -2.0915],
        [-0.6231, -0.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05446458235383034
Epoch 0, Step 2023: train/loss = 0.4522895812988281, train/raw-loss = 0.3917219340801239, train/logprobs = tensor([[-0.4765, -2.6501],
        [-2.5929, -0.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06056763231754303
Epoch 0, Step 2024: train/loss = 0.2900150418281555, train/raw-loss = 0.19076046347618103, train/logprobs = tensor([[-1.0427, -5.6124],
        [-3.9240, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992545485496521
Epoch 0, Step 2025: train/loss = 0.446493923664093, train/raw-loss = 0.3678201138973236, train/logprobs = tensor([[-0.7026, -4.4568],
        [-1.8113, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867381721735
Epoch 0, Step 2026: train/loss = 0.4776703119277954, train/raw-loss = 0.38781505823135376, train/logprobs = tensor([[-0.5725, -1.8938],
        [-1.3193, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08985528349876404
Epoch 0, Step 2027: train/loss = 0.4898112416267395, train/raw-loss = 0.4009144902229309, train/logprobs = tensor([[-1.2215, -2.7808],
        [-2.4823, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0888967216014862
Epoch 0, Step 2028: train/loss = 0.25063222646713257, train/raw-loss = 0.152305468916893, train/logprobs = tensor([[-0.8775, -6.3522],
        [-2.9120, -2.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09832675755023956
Epoch 0, Step 2029: train/loss = 0.3381127417087555, train/raw-loss = 0.2403920739889145, train/logprobs = tensor([[-0.9838, -3.9364],
        [-2.1023, -1.5059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977206826210022
Epoch 0, Step 2030: train/loss = 0.28449469804763794, train/raw-loss = 0.1839369833469391, train/logprobs = tensor([[-0.6705, -4.3413],
        [-3.0016, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055769234895706
Epoch 0, Step 2031: train/loss = 0.3724125921726227, train/raw-loss = 0.28380244970321655, train/logprobs = tensor([[-1.5599, -3.0395],
        [-3.1590, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08861016482114792
Epoch 0, Step 2032: train/loss = 0.7886604070663452, train/raw-loss = 0.7099032402038574, train/logprobs = tensor([[-1.1212, -1.7384],
        [-2.0091, -2.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07875721156597137
Epoch 0, Step 2033: train/loss = 0.4387850761413574, train/raw-loss = 0.3828470706939697, train/logprobs = tensor([[-0.9615, -3.6183],
        [-2.1512, -2.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05593801662325859
Epoch 0, Step 2034: train/loss = 0.39510032534599304, train/raw-loss = 0.3195481598377228, train/logprobs = tensor([[-0.5619, -3.7272],
        [-1.8387, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07555216550827026
Epoch 0, Step 2035: train/loss = 0.3261975646018982, train/raw-loss = 0.24728098511695862, train/logprobs = tensor([[-0.9154, -4.0416],
        [-3.0283, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07891660183668137
Epoch 0, Step 2036: train/loss = 0.3102963864803314, train/raw-loss = 0.22363555431365967, train/logprobs = tensor([[-1.2769, -3.7087],
        [-3.9037, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08666083216667175
Epoch 0, Step 2037: train/loss = 0.30051475763320923, train/raw-loss = 0.22554919123649597, train/logprobs = tensor([[-0.6463, -5.4115],
        [-1.6005, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07496555149555206
Epoch 0, Step 2038: train/loss = 0.5493465065956116, train/raw-loss = 0.47506028413772583, train/logprobs = tensor([[-0.7570, -2.5101],
        [-1.0059, -0.5602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428617775440216
Epoch 0, Step 2039: train/loss = 0.4090993404388428, train/raw-loss = 0.35116249322891235, train/logprobs = tensor([[-0.7123, -4.0755],
        [-1.5044, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05793682858347893
Epoch 0, Step 2040: train/loss = 0.37802913784980774, train/raw-loss = 0.2968825101852417, train/logprobs = tensor([[-0.9684, -4.8636],
        [-2.7306, -1.3170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08114664256572723
Epoch 0, Step 2041: train/loss = 0.3456258177757263, train/raw-loss = 0.2796158194541931, train/logprobs = tensor([[-0.9572, -3.9394],
        [-1.2830, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0660099908709526
Epoch 0, Step 2042: train/loss = 0.3606107234954834, train/raw-loss = 0.30980801582336426, train/logprobs = tensor([[-0.4346, -4.8099],
        [-0.9365, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05080273002386093
Epoch 0, Step 2043: train/loss = 0.2915647029876709, train/raw-loss = 0.2243247926235199, train/logprobs = tensor([[-0.8948, -5.6636],
        [-1.3232, -0.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.067239910364151
Epoch 0, Step 2044: train/loss = 0.380138635635376, train/raw-loss = 0.2957054376602173, train/logprobs = tensor([[-1.3358, -2.1803],
        [-3.3670, -0.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08443320542573929
Epoch 0, Step 2045: train/loss = 0.3940548896789551, train/raw-loss = 0.3216443657875061, train/logprobs = tensor([[-1.5523, -2.1072],
        [-3.5492, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07241050899028778
Epoch 0, Step 2046: train/loss = 0.4110027253627777, train/raw-loss = 0.33696791529655457, train/logprobs = tensor([[-0.4956, -2.7503],
        [-2.1732, -0.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07403482496738434
Epoch 0, Step 2047: train/loss = 0.4474985599517822, train/raw-loss = 0.37978094816207886, train/logprobs = tensor([[-0.5988, -3.4798],
        [-0.6960, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06771758943796158
Epoch 0, Step 2048: train/loss = 0.44556623697280884, train/raw-loss = 0.36463463306427, train/logprobs = tensor([[-0.9210, -3.8970],
        [-1.3381, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08093161880970001
Epoch 0, Step 2049: train/loss = 0.38124480843544006, train/raw-loss = 0.28219905495643616, train/logprobs = tensor([[-0.9435, -4.4781],
        [-2.5843, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09904573857784271
Epoch 0, Step 2050: train/loss = 0.3818134069442749, train/raw-loss = 0.2978913187980652, train/logprobs = tensor([[-0.8233, -2.3549],
        [-2.6144, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08392207324504852
Epoch 0, Step 2051: train/loss = 0.3211119472980499, train/raw-loss = 0.20692351460456848, train/logprobs = tensor([[-1.0553, -4.1981],
        [-4.5977, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11418844759464264
Epoch 0, Step 2052: train/loss = 0.3858417272567749, train/raw-loss = 0.2813326418399811, train/logprobs = tensor([[-1.6756, -4.1649],
        [-3.7747, -0.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10450908541679382
Epoch 0, Step 2053: train/loss = 0.6515026688575745, train/raw-loss = 0.5608311891555786, train/logprobs = tensor([[-2.2100, -2.0068],
        [-3.3117, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09067156165838242
Epoch 0, Step 2054: train/loss = 0.5940824747085571, train/raw-loss = 0.5320310592651367, train/logprobs = tensor([[-0.4909, -1.5709],
        [-0.8041, -0.7819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06205141544342041
Epoch 0, Step 2055: train/loss = 0.4867638945579529, train/raw-loss = 0.42204663157463074, train/logprobs = tensor([[-0.4698, -4.4120],
        [-1.0220, -1.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06471728533506393
Epoch 0, Step 2056: train/loss = 0.48392924666404724, train/raw-loss = 0.40399405360221863, train/logprobs = tensor([[-1.0382, -3.0851],
        [-2.6329, -1.4868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07993517816066742
Epoch 0, Step 2057: train/loss = 0.2955525815486908, train/raw-loss = 0.2037055343389511, train/logprobs = tensor([[-1.2072, -6.5039],
        [-2.7690, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09184704720973969
Epoch 0, Step 2058: train/loss = 0.3963093161582947, train/raw-loss = 0.3133939504623413, train/logprobs = tensor([[-0.6382, -1.7020],
        [-2.9712, -0.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08291535079479218
Epoch 0, Step 2059: train/loss = 0.26788586378097534, train/raw-loss = 0.19625647366046906, train/logprobs = tensor([[-0.6195, -5.6470],
        [-2.0517, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07162938266992569
Epoch 0, Step 2060: train/loss = 0.4971913695335388, train/raw-loss = 0.4391731917858124, train/logprobs = tensor([[-0.5176, -3.6465],
        [-0.9074, -0.9829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058018215000629425
Epoch 0, Step 2061: train/loss = 0.32710781693458557, train/raw-loss = 0.23563632369041443, train/logprobs = tensor([[-0.8008, -3.9953],
        [-2.2990, -0.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09147151559591293
Epoch 0, Step 2062: train/loss = 0.559593141078949, train/raw-loss = 0.4828631281852722, train/logprobs = tensor([[-1.8077, -1.9314],
        [-2.5050, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07672994583845139
Epoch 0, Step 2063: train/loss = 0.5861420035362244, train/raw-loss = 0.525169849395752, train/logprobs = tensor([[-0.7084, -2.2418],
        [-0.7018, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06097207963466644
Epoch 0, Step 2064: train/loss = 0.21350416541099548, train/raw-loss = 0.11632218956947327, train/logprobs = tensor([[-0.6935, -7.5512],
        [-2.9085, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718196094036102
Epoch 0, Step 2065: train/loss = 0.3772721290588379, train/raw-loss = 0.2932535707950592, train/logprobs = tensor([[-0.5916, -3.5897],
        [-1.8031, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840185284614563
Epoch 0, Step 2066: train/loss = 0.3838673233985901, train/raw-loss = 0.30353671312332153, train/logprobs = tensor([[-0.6119, -3.2592],
        [-2.0797, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08033059537410736
Epoch 0, Step 2067: train/loss = 0.8268985152244568, train/raw-loss = 0.7458840012550354, train/logprobs = tensor([[-0.5954, -4.4019],
        [-1.7675, -2.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08101451396942139
Epoch 0, Step 2068: train/loss = 0.3084542453289032, train/raw-loss = 0.23666620254516602, train/logprobs = tensor([[-1.0869, -3.0696],
        [-3.2515, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07178803533315659
Epoch 0, Step 2069: train/loss = 0.445788711309433, train/raw-loss = 0.3740638792514801, train/logprobs = tensor([[-0.5481, -4.2215],
        [-2.2742, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0717248022556305
Epoch 0, Step 2070: train/loss = 0.24830280244350433, train/raw-loss = 0.14382368326187134, train/logprobs = tensor([[-0.9704, -4.4903],
        [-4.2341, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10447912663221359
Epoch 0, Step 2071: train/loss = 0.34437596797943115, train/raw-loss = 0.25805893540382385, train/logprobs = tensor([[-0.7377, -3.8930],
        [-2.2049, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0863170400261879
Epoch 0, Step 2072: train/loss = 0.5641335844993591, train/raw-loss = 0.47193607687950134, train/logprobs = tensor([[-1.9460, -3.5095],
        [-2.3886, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09219752252101898
Epoch 0, Step 2073: train/loss = 0.5796176195144653, train/raw-loss = 0.5279375314712524, train/logprobs = tensor([[-0.4693, -1.4737],
        [-0.6377, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051680102944374084
Epoch 0, Step 2074: train/loss = 0.39609676599502563, train/raw-loss = 0.28141921758651733, train/logprobs = tensor([[-0.8575, -2.4900],
        [-3.2220, -0.9687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1146775633096695
Epoch 0, Step 2075: train/loss = 0.5351819396018982, train/raw-loss = 0.454681932926178, train/logprobs = tensor([[-1.5768, -3.3312],
        [-2.8598, -1.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08049999177455902
Epoch 0, Step 2076: train/loss = 0.24831190705299377, train/raw-loss = 0.1632838249206543, train/logprobs = tensor([[-0.8265, -4.1719],
        [-3.3576, -0.6875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502807468175888
Epoch 0, Step 2077: train/loss = 0.4989655315876007, train/raw-loss = 0.398620069026947, train/logprobs = tensor([[-1.0339, -3.8020],
        [-1.9458, -0.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10034547001123428
Epoch 0, Step 2078: train/loss = 0.34524238109588623, train/raw-loss = 0.26257064938545227, train/logprobs = tensor([[-1.0067, -2.8752],
        [-3.6256, -0.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08267170190811157
Epoch 0, Step 2079: train/loss = 0.26179173588752747, train/raw-loss = 0.17279024422168732, train/logprobs = tensor([[-0.9555, -6.2319],
        [-1.7092, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08900147676467896
Epoch 0, Step 2080: train/loss = 0.20799101889133453, train/raw-loss = 0.12245223671197891, train/logprobs = tensor([[-0.6462, -6.8700],
        [-1.9532, -0.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08553878962993622
Epoch 0, Step 2081: train/loss = 0.3470913767814636, train/raw-loss = 0.25372153520584106, train/logprobs = tensor([[-0.6935, -2.5796],
        [-3.4253, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09336983412504196
Epoch 0, Step 2082: train/loss = 0.5876239538192749, train/raw-loss = 0.5351976156234741, train/logprobs = tensor([[-0.4316, -2.1906],
        [-0.6718, -1.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052426405251026154
Epoch 0, Step 2083: train/loss = 0.380282998085022, train/raw-loss = 0.29552364349365234, train/logprobs = tensor([[-0.8608, -3.0476],
        [-3.2330, -1.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475935459136963
Epoch 0, Step 2084: train/loss = 0.6687433123588562, train/raw-loss = 0.6078941822052002, train/logprobs = tensor([[-1.7240, -3.5262],
        [-1.1870, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0608491376042366
Epoch 0, Step 2085: train/loss = 0.2741573452949524, train/raw-loss = 0.17417089641094208, train/logprobs = tensor([[-0.9940, -4.4819],
        [-3.9921, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09998644143342972
Epoch 0, Step 2086: train/loss = 0.23941020667552948, train/raw-loss = 0.12683306634426117, train/logprobs = tensor([[-0.8346, -4.9481],
        [-3.4948, -0.7384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11257714033126831
Epoch 0, Step 2087: train/loss = 0.45851844549179077, train/raw-loss = 0.37214478850364685, train/logprobs = tensor([[-1.2352, -2.6770],
        [-3.2094, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08637367188930511
Epoch 0, Step 2088: train/loss = 0.4485167860984802, train/raw-loss = 0.35894474387168884, train/logprobs = tensor([[-0.6593, -3.3988],
        [-1.4445, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08957204967737198
Epoch 0, Step 2089: train/loss = 0.47885358333587646, train/raw-loss = 0.38773608207702637, train/logprobs = tensor([[-1.1413, -2.1002],
        [-2.6575, -1.0617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111751616001129
Epoch 0, Step 2090: train/loss = 0.41409289836883545, train/raw-loss = 0.32160478830337524, train/logprobs = tensor([[-0.6094, -3.8475],
        [-1.9806, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09248805046081543
Epoch 0, Step 2091: train/loss = 0.37128114700317383, train/raw-loss = 0.2727819085121155, train/logprobs = tensor([[-0.8230, -2.8880],
        [-2.8353, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09849923104047775
Epoch 0, Step 2092: train/loss = 0.442719042301178, train/raw-loss = 0.3654297888278961, train/logprobs = tensor([[-0.7052, -3.0052],
        [-1.9707, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07728924602270126
Epoch 0, Step 2093: train/loss = 0.3750271499156952, train/raw-loss = 0.3196486532688141, train/logprobs = tensor([[-0.4982, -4.3407],
        [-0.9223, -0.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055378496646881104
Epoch 0, Step 2094: train/loss = 0.2760125994682312, train/raw-loss = 0.1884315311908722, train/logprobs = tensor([[-0.6032, -4.6503],
        [-2.1997, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08758105337619781
Epoch 0, Step 2095: train/loss = 0.4373351037502289, train/raw-loss = 0.3577561676502228, train/logprobs = tensor([[-1.1874, -1.9830],
        [-3.6372, -0.8822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07957898080348969
Epoch 0, Step 2096: train/loss = 0.4087280035018921, train/raw-loss = 0.3208167254924774, train/logprobs = tensor([[-0.9242, -3.5735],
        [-1.9523, -0.7047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08791127055883408
Epoch 0, Step 2097: train/loss = 0.34997761249542236, train/raw-loss = 0.27030208706855774, train/logprobs = tensor([[-0.7855, -3.0622],
        [-2.5784, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07967550307512283
Epoch 0, Step 2098: train/loss = 0.23032733798027039, train/raw-loss = 0.1533203423023224, train/logprobs = tensor([[-0.5267, -6.8770],
        [-1.6496, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.077006995677948
Epoch 0, Step 2099: train/loss = 0.3669697046279907, train/raw-loss = 0.29462796449661255, train/logprobs = tensor([[-0.5925, -3.9777],
        [-2.6699, -1.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07234172523021698
Epoch 0, Step 2100: train/loss = 0.5519426465034485, train/raw-loss = 0.4404943287372589, train/logprobs = tensor([[-1.0453, -2.0888],
        [-4.7548, -1.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11144830286502838
Epoch 0, Step 2101: train/loss = 0.3151821196079254, train/raw-loss = 0.22934651374816895, train/logprobs = tensor([[-1.3439, -2.2544],
        [-3.7406, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08583560585975647
Epoch 0, Step 2102: train/loss = 0.42361709475517273, train/raw-loss = 0.34636202454566956, train/logprobs = tensor([[-0.8389, -3.8369],
        [-1.4648, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07725509256124496
Epoch 0, Step 2103: train/loss = 0.4439042806625366, train/raw-loss = 0.39063969254493713, train/logprobs = tensor([[-0.8066, -2.4434],
        [-1.8786, -0.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05326458439230919
Epoch 0, Step 2104: train/loss = 0.4642612338066101, train/raw-loss = 0.4086291193962097, train/logprobs = tensor([[-0.5728, -4.1152],
        [-1.7604, -1.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05563212186098099
Epoch 0, Step 2105: train/loss = 0.24417415261268616, train/raw-loss = 0.11814989149570465, train/logprobs = tensor([[-0.9660, -4.8615],
        [-3.3478, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260242611169815
Epoch 0, Step 2106: train/loss = 0.5675761699676514, train/raw-loss = 0.48292025923728943, train/logprobs = tensor([[-2.3194, -3.8707],
        [-2.8300, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08465594053268433
Epoch 0, Step 2107: train/loss = 0.3598642945289612, train/raw-loss = 0.2733335494995117, train/logprobs = tensor([[-1.8210, -4.8886],
        [-3.4791, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08653073012828827
Epoch 0, Step 2108: train/loss = 0.3513278365135193, train/raw-loss = 0.28630971908569336, train/logprobs = tensor([[-0.6285, -3.7945],
        [-1.7654, -1.1475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06501812487840652
Epoch 0, Step 2109: train/loss = 0.40837106108665466, train/raw-loss = 0.32473134994506836, train/logprobs = tensor([[-1.3576, -2.8821],
        [-1.9940, -0.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836397111415863
Epoch 0, Step 2110: train/loss = 0.3910408616065979, train/raw-loss = 0.3231818974018097, train/logprobs = tensor([[-0.6296, -3.2298],
        [-1.8016, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06785893440246582
Epoch 0, Step 2111: train/loss = 0.4938604235649109, train/raw-loss = 0.43250155448913574, train/logprobs = tensor([[-0.5972, -3.7929],
        [-0.8820, -0.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06135889142751694
Epoch 0, Step 2112: train/loss = 0.35351377725601196, train/raw-loss = 0.26799044013023376, train/logprobs = tensor([[-1.5867, -6.0141],
        [-1.7193, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.085523322224617
Epoch 0, Step 2113: train/loss = 0.18782831728458405, train/raw-loss = 0.0816739872097969, train/logprobs = tensor([[-1.1243, -6.2832],
        [-3.4583, -1.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10615434497594833
Epoch 0, Step 2114: train/loss = 0.32724547386169434, train/raw-loss = 0.2540339231491089, train/logprobs = tensor([[-0.5473, -5.2430],
        [-0.9325, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07321156561374664
Epoch 0, Step 2115: train/loss = 0.25616931915283203, train/raw-loss = 0.16338884830474854, train/logprobs = tensor([[-0.7040, -4.6136],
        [-2.3719, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927804633975029
Epoch 0, Step 2116: train/loss = 0.4204745590686798, train/raw-loss = 0.3386397361755371, train/logprobs = tensor([[-0.8697, -2.9615],
        [-1.9644, -0.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08183480054140091
Epoch 0, Step 2117: train/loss = 0.48633086681365967, train/raw-loss = 0.3781273663043976, train/logprobs = tensor([[-1.2331, -4.0661],
        [-3.6521, -1.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10820350050926208
Epoch 0, Step 2118: train/loss = 0.29812711477279663, train/raw-loss = 0.2049737274646759, train/logprobs = tensor([[-0.7691, -4.2787],
        [-2.4699, -0.6826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09315340220928192
Epoch 0, Step 2119: train/loss = 0.3217163681983948, train/raw-loss = 0.23660150170326233, train/logprobs = tensor([[-0.7834, -4.5297],
        [-1.7770, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08511486649513245
Epoch 0, Step 2120: train/loss = 0.42028772830963135, train/raw-loss = 0.33483248949050903, train/logprobs = tensor([[-0.8841, -3.4356],
        [-2.5098, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08545525372028351
Epoch 0, Step 2121: train/loss = 0.7200942039489746, train/raw-loss = 0.6720463037490845, train/logprobs = tensor([[-0.5340, -0.7082],
        [-0.5985, -0.6613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048047907650470734
Epoch 0, Step 2122: train/loss = 0.3763844966888428, train/raw-loss = 0.3079308867454529, train/logprobs = tensor([[-0.8763, -2.8146],
        [-2.0393, -0.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06845360994338989
Epoch 0, Step 2123: train/loss = 0.48699676990509033, train/raw-loss = 0.39514291286468506, train/logprobs = tensor([[-0.7735, -1.4745],
        [-1.9204, -0.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09185386449098587
Epoch 0, Step 2124: train/loss = 0.6333450078964233, train/raw-loss = 0.5512897372245789, train/logprobs = tensor([[-1.7164, -2.0217],
        [-2.4588, -1.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08205527067184448
Epoch 0, Step 2125: train/loss = 0.32558947801589966, train/raw-loss = 0.22838985919952393, train/logprobs = tensor([[-1.1183, -3.1043],
        [-3.5222, -1.4104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09719961881637573
Epoch 0, Step 2126: train/loss = 0.23880302906036377, train/raw-loss = 0.158172607421875, train/logprobs = tensor([[-0.6030, -5.8028],
        [-1.8915, -0.7226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08063042163848877
Epoch 0, Step 2127: train/loss = 0.3557526469230652, train/raw-loss = 0.26017701625823975, train/logprobs = tensor([[-0.9314, -1.8206],
        [-4.0930, -0.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09557561576366425
Epoch 0, Step 2128: train/loss = 0.22369609773159027, train/raw-loss = 0.1454472541809082, train/logprobs = tensor([[-0.6429, -5.7551],
        [-2.3113, -1.4622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07824884355068207
Epoch 0, Step 2129: train/loss = 0.3865925371646881, train/raw-loss = 0.3158913254737854, train/logprobs = tensor([[-0.7451, -4.3924],
        [-1.3121, -0.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07070118933916092
Epoch 0, Step 2130: train/loss = 0.6392306089401245, train/raw-loss = 0.5772919058799744, train/logprobs = tensor([[-0.4565, -0.7144],
        [-0.9635, -0.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061938732862472534
Epoch 0, Step 2131: train/loss = 0.3456512689590454, train/raw-loss = 0.2692105174064636, train/logprobs = tensor([[-0.5747, -5.9334],
        [-1.3727, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07644072920084
Epoch 0, Step 2132: train/loss = 0.473051518201828, train/raw-loss = 0.40574049949645996, train/logprobs = tensor([[-0.5468, -2.5674],
        [-1.1273, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06731100380420685
Epoch 0, Step 2133: train/loss = 0.4290066957473755, train/raw-loss = 0.3538143038749695, train/logprobs = tensor([[-0.8659, -3.1020],
        [-1.4484, -0.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07519238442182541
Epoch 0, Step 2134: train/loss = 0.21179479360580444, train/raw-loss = 0.0970543771982193, train/logprobs = tensor([[-1.0956, -4.9451],
        [-3.2020, -1.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11474041640758514
Epoch 0, Step 2135: train/loss = 0.2009708732366562, train/raw-loss = 0.0962882786989212, train/logprobs = tensor([[-0.8785, -5.4300],
        [-2.8580, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10468258708715439
Epoch 0, Step 2136: train/loss = 0.6772801876068115, train/raw-loss = 0.6076297760009766, train/logprobs = tensor([[-0.4207, -2.4666],
        [-0.9866, -1.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06965038180351257
Epoch 0, Step 2137: train/loss = 0.47524797916412354, train/raw-loss = 0.381685733795166, train/logprobs = tensor([[-1.2209, -2.4425],
        [-1.9776, -0.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356220066547394
Epoch 0, Step 2138: train/loss = 0.29639846086502075, train/raw-loss = 0.19144955277442932, train/logprobs = tensor([[-1.3219, -3.0358],
        [-5.3269, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10494891554117203
Epoch 0, Step 2139: train/loss = 0.31783053278923035, train/raw-loss = 0.21540117263793945, train/logprobs = tensor([[-1.2420, -5.4916],
        [-2.9208, -0.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10242937505245209
Epoch 0, Step 2140: train/loss = 0.2893083989620209, train/raw-loss = 0.1817452758550644, train/logprobs = tensor([[-0.8961, -2.2676],
        [-4.6544, -0.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10756312310695648
Epoch 0, Step 2141: train/loss = 0.2980440855026245, train/raw-loss = 0.20149551331996918, train/logprobs = tensor([[-1.0675, -5.0831],
        [-3.9727, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654856473207474
Epoch 0, Step 2142: train/loss = 0.6581855416297913, train/raw-loss = 0.5704761743545532, train/logprobs = tensor([[-0.7922, -2.1801],
        [-3.6975, -1.5354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08770939707756042
Epoch 0, Step 2143: train/loss = 0.3785626292228699, train/raw-loss = 0.28019431233406067, train/logprobs = tensor([[-0.7153, -2.8259],
        [-2.8271, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0983683168888092
Epoch 0, Step 2144: train/loss = 0.2928057312965393, train/raw-loss = 0.20607279241085052, train/logprobs = tensor([[-0.7202, -5.6800],
        [-2.2016, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08673293888568878
Epoch 0, Step 2145: train/loss = 0.20009049773216248, train/raw-loss = 0.10046738386154175, train/logprobs = tensor([[-1.1254, -4.9581],
        [-5.7261, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09962309896945953
Epoch 0, Step 2146: train/loss = 0.40535762906074524, train/raw-loss = 0.30457594990730286, train/logprobs = tensor([[-0.8860, -2.6035],
        [-3.1762, -1.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10078167170286179
Epoch 0, Step 2147: train/loss = 0.5144959688186646, train/raw-loss = 0.4322913885116577, train/logprobs = tensor([[-0.5795, -3.1059],
        [-0.7897, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08220460265874863
Epoch 0, Step 2148: train/loss = 0.4711344242095947, train/raw-loss = 0.3858182430267334, train/logprobs = tensor([[-1.1366, -2.6377],
        [-1.8774, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08531621098518372
Epoch 0, Step 2149: train/loss = 0.3359343707561493, train/raw-loss = 0.2342810034751892, train/logprobs = tensor([[-0.9478, -5.3838],
        [-2.2730, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10165336728096008
Epoch 0, Step 2150: train/loss = 0.3104228675365448, train/raw-loss = 0.2182101607322693, train/logprobs = tensor([[-0.6448, -3.3964],
        [-3.2133, -0.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09221269190311432
Epoch 0, Step 2151: train/loss = 0.3312348425388336, train/raw-loss = 0.2307177186012268, train/logprobs = tensor([[-1.4175, -4.0252],
        [-3.5580, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005171462893486
Epoch 0, Step 2152: train/loss = 0.4369919002056122, train/raw-loss = 0.36102232336997986, train/logprobs = tensor([[-0.7062, -1.5042],
        [-2.8469, -0.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07596955448389053
Epoch 0, Step 2153: train/loss = 0.34731757640838623, train/raw-loss = 0.25695884227752686, train/logprobs = tensor([[-0.7333, -5.2478],
        [-1.4695, -0.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09035873413085938
Epoch 0, Step 2154: train/loss = 0.2143065631389618, train/raw-loss = 0.1153765320777893, train/logprobs = tensor([[-0.9449, -4.3985],
        [-4.8760, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09893004596233368
Epoch 0, Step 2155: train/loss = 0.39744266867637634, train/raw-loss = 0.30759668350219727, train/logprobs = tensor([[-1.1027, -3.7140],
        [-2.0967, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08984598517417908
Epoch 0, Step 2156: train/loss = 0.5191426277160645, train/raw-loss = 0.422125905752182, train/logprobs = tensor([[-0.6213, -1.6435],
        [-1.8156, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09701673686504364
Epoch 0, Step 2157: train/loss = 0.649649441242218, train/raw-loss = 0.5995020866394043, train/logprobs = tensor([[-0.5027, -0.7967],
        [-0.7878, -0.6138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05014738440513611
Epoch 0, Step 2158: train/loss = 0.5078104734420776, train/raw-loss = 0.46618661284446716, train/logprobs = tensor([[-1.1462, -4.2066],
        [-1.3635, -1.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04162384569644928
Epoch 0, Step 2159: train/loss = 0.4552016854286194, train/raw-loss = 0.36130353808403015, train/logprobs = tensor([[-1.6816, -4.4387],
        [-2.1434, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09389818459749222
Epoch 0, Step 2160: train/loss = 0.2925525903701782, train/raw-loss = 0.16994284093379974, train/logprobs = tensor([[-0.7896, -3.3722],
        [-2.5221, -0.6638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12260975688695908
Epoch 0, Step 2161: train/loss = 0.38548892736434937, train/raw-loss = 0.3224484324455261, train/logprobs = tensor([[-0.5849, -3.6500],
        [-2.0897, -0.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06304050981998444
Epoch 0, Step 2162: train/loss = 0.4498286843299866, train/raw-loss = 0.3873099982738495, train/logprobs = tensor([[-0.5655, -2.3228],
        [-1.0299, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0625186637043953
Epoch 0, Step 2163: train/loss = 0.2346285581588745, train/raw-loss = 0.12958109378814697, train/logprobs = tensor([[-0.4754, -4.1827],
        [-2.7166, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10504745692014694
Epoch 0, Step 2164: train/loss = 0.3142651319503784, train/raw-loss = 0.2143411636352539, train/logprobs = tensor([[-0.9088, -2.4559],
        [-3.7511, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09992393851280212
Epoch 0, Step 2165: train/loss = 0.40828952193260193, train/raw-loss = 0.3400056064128876, train/logprobs = tensor([[-0.7918, -3.0763],
        [-1.7598, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06828390806913376
Epoch 0, Step 2166: train/loss = 0.4968874156475067, train/raw-loss = 0.399759441614151, train/logprobs = tensor([[-2.6636, -8.0159],
        [-4.4276, -2.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09712795913219452
Epoch 0, Step 2167: train/loss = 0.2469242811203003, train/raw-loss = 0.16282616555690765, train/logprobs = tensor([[-1.2616, -4.7729],
        [-3.4703, -1.2434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08409813791513443
Epoch 0, Step 2168: train/loss = 0.35672396421432495, train/raw-loss = 0.2834931015968323, train/logprobs = tensor([[-0.4869, -4.7326],
        [-1.8370, -0.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07323087006807327
Epoch 0, Step 2169: train/loss = 0.35682839155197144, train/raw-loss = 0.2900320291519165, train/logprobs = tensor([[-0.4658, -5.0813],
        [-0.8627, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06679639220237732
Epoch 0, Step 2170: train/loss = 0.2921566367149353, train/raw-loss = 0.21602953970432281, train/logprobs = tensor([[-1.0942, -4.6775],
        [-1.7067, -0.7093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07612710446119308
Epoch 0, Step 2171: train/loss = 0.34111857414245605, train/raw-loss = 0.2735023498535156, train/logprobs = tensor([[-0.6272, -3.3480],
        [-1.5467, -0.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06761623173952103
Epoch 0, Step 2172: train/loss = 0.26375114917755127, train/raw-loss = 0.17713986337184906, train/logprobs = tensor([[-0.6840, -4.0967],
        [-3.5736, -1.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08661127090454102
Epoch 0, Step 2173: train/loss = 0.5388699173927307, train/raw-loss = 0.45802849531173706, train/logprobs = tensor([[-0.5443, -1.9601],
        [-2.0938, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08084141463041306
Epoch 0, Step 2174: train/loss = 0.29348766803741455, train/raw-loss = 0.19243820011615753, train/logprobs = tensor([[-0.7756, -3.5748],
        [-3.0969, -1.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104946792125702
Epoch 0, Step 2175: train/loss = 0.46172988414764404, train/raw-loss = 0.3999341130256653, train/logprobs = tensor([[-1.4403, -2.3177],
        [-3.0203, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06179575249552727
Epoch 0, Step 2176: train/loss = 0.3816518187522888, train/raw-loss = 0.3248579502105713, train/logprobs = tensor([[-0.6479, -3.5171],
        [-1.8203, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05679384991526604
Epoch 0, Step 2177: train/loss = 0.5031338930130005, train/raw-loss = 0.4293918013572693, train/logprobs = tensor([[-1.0678, -3.6820],
        [-1.8946, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07374211400747299
Epoch 0, Step 2178: train/loss = 0.3992595672607422, train/raw-loss = 0.3219730854034424, train/logprobs = tensor([[-0.7162, -4.7082],
        [-0.9717, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07728647440671921
Epoch 0, Step 2179: train/loss = 0.2643955945968628, train/raw-loss = 0.16977009177207947, train/logprobs = tensor([[-0.8938, -4.9395],
        [-2.7966, -1.1313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09462551027536392
Epoch 0, Step 2180: train/loss = 0.3811868131160736, train/raw-loss = 0.2881787121295929, train/logprobs = tensor([[-0.9346, -3.0414],
        [-3.0968, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09300808608531952
Epoch 0, Step 2181: train/loss = 0.6906216144561768, train/raw-loss = 0.6004312038421631, train/logprobs = tensor([[-1.0715, -3.2531],
        [-1.7400, -1.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09019040316343307
Epoch 0, Step 2182: train/loss = 0.37834665179252625, train/raw-loss = 0.3135685324668884, train/logprobs = tensor([[-0.6353, -3.8419],
        [-2.5069, -0.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06477812677621841
Epoch 0, Step 2183: train/loss = 0.3401334285736084, train/raw-loss = 0.25922441482543945, train/logprobs = tensor([[-0.6136, -4.5983],
        [-1.6773, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08090900629758835
Epoch 0, Step 2184: train/loss = 0.2448655664920807, train/raw-loss = 0.1276678591966629, train/logprobs = tensor([[-0.6962, -3.4362],
        [-3.9841, -1.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1171976774930954
Epoch 0, Step 2185: train/loss = 0.4213254451751709, train/raw-loss = 0.3355296850204468, train/logprobs = tensor([[-1.3313, -3.9077],
        [-1.5986, -0.8650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08579575270414352
Epoch 0, Step 2186: train/loss = 0.3598923981189728, train/raw-loss = 0.2833433151245117, train/logprobs = tensor([[-0.8298, -3.4481],
        [-3.0576, -0.4355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07654909789562225
Epoch 0, Step 2187: train/loss = 0.4433192312717438, train/raw-loss = 0.37504249811172485, train/logprobs = tensor([[-0.5211, -1.6792],
        [-1.8236, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06827671825885773
Epoch 0, Step 2188: train/loss = 0.3218068480491638, train/raw-loss = 0.226848766207695, train/logprobs = tensor([[-1.0422, -3.7069],
        [-2.4143, -0.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949581041932106
Epoch 0, Step 2189: train/loss = 0.6143929958343506, train/raw-loss = 0.5223656892776489, train/logprobs = tensor([[-1.4829, -3.2697],
        [-2.2135, -2.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09202730655670166
Epoch 0, Step 2190: train/loss = 0.5096697807312012, train/raw-loss = 0.4337959587574005, train/logprobs = tensor([[-0.4958, -1.1790],
        [-1.6800, -0.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07587377727031708
Epoch 0, Step 2191: train/loss = 0.32038238644599915, train/raw-loss = 0.22350628674030304, train/logprobs = tensor([[-0.7492, -3.2970],
        [-3.4240, -1.1652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968761071562767
Epoch 0, Step 2192: train/loss = 0.3413902521133423, train/raw-loss = 0.257753849029541, train/logprobs = tensor([[-1.0114, -5.1730],
        [-2.9812, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363637328147888
Epoch 0, Step 2193: train/loss = 0.49986785650253296, train/raw-loss = 0.4139024019241333, train/logprobs = tensor([[-0.8291, -2.3762],
        [-2.5024, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08596544712781906
Epoch 0, Step 2194: train/loss = 0.45591622591018677, train/raw-loss = 0.3656972050666809, train/logprobs = tensor([[-0.5911, -2.6503],
        [-1.9029, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09021898359060287
Epoch 0, Step 2195: train/loss = 0.713235080242157, train/raw-loss = 0.6258964538574219, train/logprobs = tensor([[-0.5952, -0.6549],
        [-1.0130, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08733859658241272
Epoch 0, Step 2196: train/loss = 0.45042523741722107, train/raw-loss = 0.3406845033168793, train/logprobs = tensor([[-2.3347, -3.5090],
        [-3.3353, -1.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10974069684743881
Epoch 0, Step 2197: train/loss = 0.2445356249809265, train/raw-loss = 0.1516895294189453, train/logprobs = tensor([[-0.6529, -5.4240],
        [-2.4058, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928460955619812
Epoch 0, Step 2198: train/loss = 0.29604876041412354, train/raw-loss = 0.21672029793262482, train/logprobs = tensor([[-0.7565, -6.6056],
        [-2.2916, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07932844758033752
Epoch 0, Step 2199: train/loss = 0.3861585259437561, train/raw-loss = 0.30764704942703247, train/logprobs = tensor([[-1.0781, -3.6505],
        [-2.2765, -0.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07851143181324005
Epoch 0, Step 2200: train/loss = 0.4941575527191162, train/raw-loss = 0.4232507348060608, train/logprobs = tensor([[-0.6538, -2.2236],
        [-2.1378, -0.7836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07090683281421661
Epoch 0, Step 2201: train/loss = 0.5114675760269165, train/raw-loss = 0.4418635666370392, train/logprobs = tensor([[-0.6213, -1.9257],
        [-1.8882, -0.9168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06960401684045792
Epoch 0, Step 2202: train/loss = 0.5107619762420654, train/raw-loss = 0.41261109709739685, train/logprobs = tensor([[-1.7074, -4.2662],
        [-1.8852, -1.4217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09815085679292679
Epoch 0, Step 2203: train/loss = 0.31179720163345337, train/raw-loss = 0.21432092785835266, train/logprobs = tensor([[-1.3930, -4.0811],
        [-3.1483, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09747626632452011
Epoch 0, Step 2204: train/loss = 0.324531614780426, train/raw-loss = 0.24371761083602905, train/logprobs = tensor([[-0.9489, -2.4140],
        [-3.2316, -0.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08081400394439697
Epoch 0, Step 2205: train/loss = 0.5060006380081177, train/raw-loss = 0.4191146492958069, train/logprobs = tensor([[-1.4556, -2.9918],
        [-2.5995, -1.5347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0868859812617302
Epoch 0, Step 2206: train/loss = 0.6460480690002441, train/raw-loss = 0.5364866256713867, train/logprobs = tensor([[-2.3179, -3.9622],
        [-3.2989, -1.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10956147313117981
Epoch 0, Step 2207: train/loss = 0.35656458139419556, train/raw-loss = 0.24997617304325104, train/logprobs = tensor([[-0.7955, -3.2044],
        [-3.1430, -0.4621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658839344978333
Epoch 0, Step 2208: train/loss = 0.5643011927604675, train/raw-loss = 0.4833794832229614, train/logprobs = tensor([[-1.1414, -2.2050],
        [-2.1651, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809217244386673
Epoch 0, Step 2209: train/loss = 0.3597646653652191, train/raw-loss = 0.2823813557624817, train/logprobs = tensor([[-1.5128, -5.9153],
        [-1.6754, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07738329470157623
Epoch 0, Step 2210: train/loss = 0.2733786702156067, train/raw-loss = 0.1866016387939453, train/logprobs = tensor([[-0.5788, -4.7606],
        [-1.9458, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08677704632282257
Epoch 0, Step 2211: train/loss = 0.4847010374069214, train/raw-loss = 0.3995416760444641, train/logprobs = tensor([[-1.7264, -2.9390],
        [-3.1431, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515937626361847
Epoch 0, Step 2212: train/loss = 0.314962238073349, train/raw-loss = 0.23339393734931946, train/logprobs = tensor([[-0.6575, -4.3953],
        [-2.5095, -0.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08156830072402954
Epoch 0, Step 2213: train/loss = 0.4562000632286072, train/raw-loss = 0.39490073919296265, train/logprobs = tensor([[-0.5078, -3.6922],
        [-0.9718, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06129933148622513
Epoch 0, Step 2214: train/loss = 0.4461859166622162, train/raw-loss = 0.39104604721069336, train/logprobs = tensor([[-0.8809, -3.7972],
        [-1.0279, -0.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05513985455036163
Epoch 0, Step 2215: train/loss = 0.3424937129020691, train/raw-loss = 0.2505072355270386, train/logprobs = tensor([[-0.8054, -3.3577],
        [-2.1466, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09198647737503052
Epoch 0, Step 2216: train/loss = 0.36762920022010803, train/raw-loss = 0.2838662564754486, train/logprobs = tensor([[-0.7167, -5.8869],
        [-2.0251, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08376294374465942
Epoch 0, Step 2217: train/loss = 0.4633774161338806, train/raw-loss = 0.3791293799877167, train/logprobs = tensor([[-0.7557, -3.3541],
        [-1.5913, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08424802869558334
Epoch 0, Step 2218: train/loss = 0.23128360509872437, train/raw-loss = 0.15885761380195618, train/logprobs = tensor([[-0.9790, -5.4288],
        [-3.4484, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07242599129676819
Epoch 0, Step 2219: train/loss = 0.37658581137657166, train/raw-loss = 0.3012247383594513, train/logprobs = tensor([[-0.8150, -4.3574],
        [-1.3507, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07536106556653976
Epoch 0, Step 2220: train/loss = 0.40303096175193787, train/raw-loss = 0.32435670495033264, train/logprobs = tensor([[-0.6309, -3.5732],
        [-1.7323, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867428660392761
Epoch 0, Step 2221: train/loss = 0.36106884479522705, train/raw-loss = 0.27122122049331665, train/logprobs = tensor([[-1.6419, -4.1969],
        [-3.6752, -1.5520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0898476168513298
Epoch 0, Step 2222: train/loss = 0.3502707779407501, train/raw-loss = 0.29122233390808105, train/logprobs = tensor([[-0.9326, -2.8852],
        [-2.4782, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05904845893383026
Epoch 0, Step 2223: train/loss = 0.5975353121757507, train/raw-loss = 0.4965842068195343, train/logprobs = tensor([[-1.0196, -1.8166],
        [-3.8299, -1.4300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10095110535621643
Epoch 0, Step 2224: train/loss = 0.455766499042511, train/raw-loss = 0.3804031014442444, train/logprobs = tensor([[-0.6365, -2.8676],
        [-2.2932, -0.6192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0753634124994278
Epoch 0, Step 2225: train/loss = 0.29293012619018555, train/raw-loss = 0.20337623357772827, train/logprobs = tensor([[-0.7874, -5.1953],
        [-2.8693, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08955388516187668
Epoch 0, Step 2226: train/loss = 0.43152523040771484, train/raw-loss = 0.3564782440662384, train/logprobs = tensor([[-0.7239, -3.2601],
        [-1.2326, -0.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07504700869321823
Epoch 0, Step 2227: train/loss = 0.21108651161193848, train/raw-loss = 0.12642696499824524, train/logprobs = tensor([[-1.3558, -4.4396],
        [-4.1623, -0.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08465953916311264
Epoch 0, Step 2228: train/loss = 0.43136632442474365, train/raw-loss = 0.3551945090293884, train/logprobs = tensor([[-0.5056, -3.2089],
        [-1.3898, -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07617180794477463
Epoch 0, Step 2229: train/loss = 0.19133910536766052, train/raw-loss = 0.09984379261732101, train/logprobs = tensor([[-1.1406, -6.1075],
        [-4.4976, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09149530529975891
Epoch 0, Step 2230: train/loss = 0.4313153922557831, train/raw-loss = 0.34579965472221375, train/logprobs = tensor([[-0.8276, -2.4382],
        [-2.6055, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08551577478647232
Epoch 0, Step 2231: train/loss = 0.25795620679855347, train/raw-loss = 0.17621396481990814, train/logprobs = tensor([[-0.5236, -4.2648],
        [-2.5914, -0.6251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08174224197864532
Epoch 0, Step 2232: train/loss = 0.404208242893219, train/raw-loss = 0.32841727137565613, train/logprobs = tensor([[-0.9334, -2.7556],
        [-2.9244, -1.4333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07579098641872406
Epoch 0, Step 2233: train/loss = 0.4700064957141876, train/raw-loss = 0.40350690484046936, train/logprobs = tensor([[-1.0644, -2.4696],
        [-2.5592, -0.4932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06649957597255707
Epoch 0, Step 2234: train/loss = 0.32566583156585693, train/raw-loss = 0.23857320845127106, train/logprobs = tensor([[-0.8667, -5.9786],
        [-2.3389, -1.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08709260821342468
Epoch 0, Step 2235: train/loss = 0.2363409399986267, train/raw-loss = 0.13915376365184784, train/logprobs = tensor([[-0.6211, -5.0534],
        [-2.8420, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09718718379735947
Epoch 0, Step 2236: train/loss = 0.20454171299934387, train/raw-loss = 0.12265749275684357, train/logprobs = tensor([[-0.5847, -7.6053],
        [-2.4609, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08188420534133911
Epoch 0, Step 2237: train/loss = 0.5154018998146057, train/raw-loss = 0.44741886854171753, train/logprobs = tensor([[-0.4866, -2.4057],
        [-0.7861, -0.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06798301637172699
Epoch 0, Step 2238: train/loss = 0.5759808421134949, train/raw-loss = 0.4881620407104492, train/logprobs = tensor([[-0.9532, -4.0834],
        [-0.6979, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08781883865594864
Epoch 0, Step 2239: train/loss = 0.49825185537338257, train/raw-loss = 0.42489108443260193, train/logprobs = tensor([[-0.7818, -3.1799],
        [-1.2962, -1.4514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07336077094078064
Epoch 0, Step 2240: train/loss = 0.9668900370597839, train/raw-loss = 0.8871268033981323, train/logprobs = tensor([[-0.7738, -1.7660],
        [-2.0423, -2.3522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.079763263463974
Epoch 0, Step 2241: train/loss = 0.5523852109909058, train/raw-loss = 0.480741411447525, train/logprobs = tensor([[-0.7721, -2.2695],
        [-0.8262, -1.1234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07164383679628372
Epoch 0, Step 2242: train/loss = 0.45495715737342834, train/raw-loss = 0.3796749711036682, train/logprobs = tensor([[-0.5303, -2.6686],
        [-1.1575, -0.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528215646743774
Epoch 0, Step 2243: train/loss = 0.3416981101036072, train/raw-loss = 0.2728968858718872, train/logprobs = tensor([[-0.6523, -4.0052],
        [-1.5864, -0.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06880120187997818
Epoch 0, Step 2244: train/loss = 0.4669065475463867, train/raw-loss = 0.3811434209346771, train/logprobs = tensor([[-0.6782, -3.4935],
        [-1.9231, -0.7571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0857631042599678
Epoch 0, Step 2245: train/loss = 0.37990596890449524, train/raw-loss = 0.29290148615837097, train/logprobs = tensor([[-0.7838, -3.4425],
        [-2.1413, -0.5313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08700447529554367
Epoch 0, Step 2246: train/loss = 0.4998176097869873, train/raw-loss = 0.42209917306900024, train/logprobs = tensor([[-0.9206, -2.1676],
        [-3.0104, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07771847397089005
Epoch 0, Step 2247: train/loss = 0.36016377806663513, train/raw-loss = 0.29644685983657837, train/logprobs = tensor([[-0.4682, -4.7592],
        [-0.9363, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06371692568063736
Epoch 0, Step 2248: train/loss = 0.1838475465774536, train/raw-loss = 0.07630302011966705, train/logprobs = tensor([[-0.9256, -6.7425],
        [-3.4675, -1.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10754451900720596
Epoch 0, Step 2249: train/loss = 0.5754733085632324, train/raw-loss = 0.4950723946094513, train/logprobs = tensor([[-1.2261, -2.0075],
        [-3.1950, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08040092140436172
Epoch 0, Step 2250: train/loss = 0.20035216212272644, train/raw-loss = 0.09605398029088974, train/logprobs = tensor([[-0.7622, -4.6248],
        [-3.8307, -0.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1042981967329979
Epoch 0, Step 2251: train/loss = 0.46284985542297363, train/raw-loss = 0.3702307641506195, train/logprobs = tensor([[-0.5664, -1.3529],
        [-2.6392, -0.5938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09261906147003174
Epoch 0, Step 2252: train/loss = 0.27452006936073303, train/raw-loss = 0.18721145391464233, train/logprobs = tensor([[-0.6919, -3.8722],
        [-2.6677, -1.2416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0873086228966713
Epoch 0, Step 2253: train/loss = 0.509712278842926, train/raw-loss = 0.4385570287704468, train/logprobs = tensor([[-1.0235, -2.1057],
        [-2.3412, -0.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07115526497364044
Epoch 0, Step 2254: train/loss = 0.42317312955856323, train/raw-loss = 0.3313324451446533, train/logprobs = tensor([[-0.7590, -1.6048],
        [-2.5319, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09184063225984573
Epoch 0, Step 2255: train/loss = 0.4250321090221405, train/raw-loss = 0.3434058427810669, train/logprobs = tensor([[-0.7191, -2.7070],
        [-1.7984, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0816262811422348
Epoch 0, Step 2256: train/loss = 0.24933785200119019, train/raw-loss = 0.13097594678401947, train/logprobs = tensor([[-1.0232, -4.9837],
        [-3.9785, -0.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11836188286542892
Epoch 0, Step 2257: train/loss = 0.47845181822776794, train/raw-loss = 0.3990074396133423, train/logprobs = tensor([[-1.4415, -2.8445],
        [-2.9474, -0.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07944435626268387
Epoch 0, Step 2258: train/loss = 0.3355606496334076, train/raw-loss = 0.25171130895614624, train/logprobs = tensor([[-1.2139, -5.2444],
        [-2.4611, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08384934067726135
Epoch 0, Step 2259: train/loss = 0.22627577185630798, train/raw-loss = 0.15090301632881165, train/logprobs = tensor([[-0.9309, -5.4687],
        [-3.6862, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07537276297807693
Epoch 0, Step 2260: train/loss = 0.7342003583908081, train/raw-loss = 0.6404883861541748, train/logprobs = tensor([[-0.6164, -3.9338],
        [-2.2428, -2.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0937119871377945
Epoch 0, Step 2261: train/loss = 0.23507562279701233, train/raw-loss = 0.1375734806060791, train/logprobs = tensor([[-0.6490, -6.5004],
        [-2.0134, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09750216454267502
Epoch 0, Step 2262: train/loss = 0.32853442430496216, train/raw-loss = 0.24860075116157532, train/logprobs = tensor([[-0.6769, -3.5676],
        [-2.7162, -0.8438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07993368804454803
Epoch 0, Step 2263: train/loss = 0.31075769662857056, train/raw-loss = 0.21093183755874634, train/logprobs = tensor([[-0.8017, -3.7594],
        [-4.2614, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09982584416866302
Epoch 0, Step 2264: train/loss = 0.3232990801334381, train/raw-loss = 0.24945296347141266, train/logprobs = tensor([[-0.8266, -5.0105],
        [-1.4955, -0.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07384611666202545
Epoch 0, Step 2265: train/loss = 0.5127474069595337, train/raw-loss = 0.4469403326511383, train/logprobs = tensor([[-0.4403, -2.7845],
        [-1.0392, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06580711156129837
Epoch 0, Step 2266: train/loss = 0.2695891559123993, train/raw-loss = 0.1717526763677597, train/logprobs = tensor([[-0.6384, -6.1606],
        [-1.7018, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783647954463959
Epoch 0, Step 2267: train/loss = 0.30117395520210266, train/raw-loss = 0.23536281287670135, train/logprobs = tensor([[-0.7207, -5.9827],
        [-1.0739, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06581113487482071
Epoch 0, Step 2268: train/loss = 0.3627941608428955, train/raw-loss = 0.27562233805656433, train/logprobs = tensor([[-0.6794, -2.2445],
        [-2.9957, -0.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08717182278633118
Epoch 0, Step 2269: train/loss = 0.48165571689605713, train/raw-loss = 0.41135483980178833, train/logprobs = tensor([[-1.2072, -3.0939],
        [-2.2043, -1.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0703008621931076
Epoch 0, Step 2270: train/loss = 0.2725306749343872, train/raw-loss = 0.17405803501605988, train/logprobs = tensor([[-0.6616, -4.3619],
        [-3.0291, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09847262501716614
Epoch 0, Step 2271: train/loss = 0.3142542243003845, train/raw-loss = 0.22376933693885803, train/logprobs = tensor([[-0.8098, -2.4949],
        [-3.8542, -0.6465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048487991094589
Epoch 0, Step 2272: train/loss = 0.3279283940792084, train/raw-loss = 0.23507477343082428, train/logprobs = tensor([[-0.5522, -4.4011],
        [-1.5483, -0.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928536206483841
Epoch 0, Step 2273: train/loss = 0.4741802215576172, train/raw-loss = 0.37875258922576904, train/logprobs = tensor([[-1.2405, -4.8511],
        [-2.1635, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09542762488126755
Epoch 0, Step 2274: train/loss = 0.4163817763328552, train/raw-loss = 0.3519771099090576, train/logprobs = tensor([[-1.5934, -5.5865],
        [-1.8242, -1.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0644046813249588
Epoch 0, Step 2275: train/loss = 0.29991665482521057, train/raw-loss = 0.21691647171974182, train/logprobs = tensor([[-0.7621, -4.8664],
        [-2.0582, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08300018310546875
Epoch 0, Step 2276: train/loss = 0.7093021273612976, train/raw-loss = 0.6487236022949219, train/logprobs = tensor([[-0.9406, -1.0961],
        [-1.2868, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060578495264053345
Epoch 0, Step 2277: train/loss = 0.24280373752117157, train/raw-loss = 0.14770928025245667, train/logprobs = tensor([[-0.9132, -4.1500],
        [-4.6962, -0.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09509444981813431
Epoch 0, Step 2278: train/loss = 0.26321345567703247, train/raw-loss = 0.17099058628082275, train/logprobs = tensor([[-0.6156, -2.5872],
        [-3.2482, -0.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09222286939620972
Epoch 0, Step 2279: train/loss = 0.41643354296684265, train/raw-loss = 0.34544119238853455, train/logprobs = tensor([[-0.5999, -4.6630],
        [-1.8480, -1.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07099231332540512
Epoch 0, Step 2280: train/loss = 0.4743719696998596, train/raw-loss = 0.40383368730545044, train/logprobs = tensor([[-0.4764, -2.8994],
        [-1.7896, -0.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07053828984498978
Epoch 0, Step 2281: train/loss = 0.3696073293685913, train/raw-loss = 0.2848585247993469, train/logprobs = tensor([[-0.6895, -2.8817],
        [-2.9841, -0.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08474881201982498
Epoch 0, Step 2282: train/loss = 0.4645928740501404, train/raw-loss = 0.39842966198921204, train/logprobs = tensor([[-0.4862, -3.1829],
        [-0.9990, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06616319715976715
Epoch 0, Step 2283: train/loss = 0.3892686069011688, train/raw-loss = 0.3201949894428253, train/logprobs = tensor([[-1.4106, -3.8899],
        [-2.1669, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06907360255718231
Epoch 0, Step 2284: train/loss = 0.27383744716644287, train/raw-loss = 0.1841522604227066, train/logprobs = tensor([[-0.9047, -4.1464],
        [-2.3227, -0.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08968519419431686
Epoch 0, Step 2285: train/loss = 0.42781299352645874, train/raw-loss = 0.37143364548683167, train/logprobs = tensor([[-0.5880, -3.6933],
        [-1.1450, -0.5908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05637934058904648
Epoch 0, Step 2286: train/loss = 0.24198655784130096, train/raw-loss = 0.16751796007156372, train/logprobs = tensor([[-0.5354, -5.7910],
        [-1.8266, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07446859776973724
Epoch 0, Step 2287: train/loss = 0.5026074647903442, train/raw-loss = 0.4369529187679291, train/logprobs = tensor([[-0.6915, -2.8262],
        [-1.0118, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06565456092357635
Epoch 0, Step 2288: train/loss = 0.33656612038612366, train/raw-loss = 0.2630089521408081, train/logprobs = tensor([[-1.3970, -3.6716],
        [-4.4733, -1.1515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07355718314647675
Epoch 0, Step 2289: train/loss = 0.3754822611808777, train/raw-loss = 0.3088262379169464, train/logprobs = tensor([[-0.6389, -3.7096],
        [-1.2947, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06665602326393127
Epoch 0, Step 2290: train/loss = 0.8348581194877625, train/raw-loss = 0.7341685891151428, train/logprobs = tensor([[-1.3365, -2.0306],
        [-3.1245, -2.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068961977958679
Epoch 0, Step 2291: train/loss = 0.49194759130477905, train/raw-loss = 0.4063366651535034, train/logprobs = tensor([[-0.7184, -2.3818],
        [-1.8261, -0.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08561094105243683
Epoch 0, Step 2292: train/loss = 0.2699551582336426, train/raw-loss = 0.1921495944261551, train/logprobs = tensor([[-0.9739, -4.2353],
        [-3.3074, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07780557125806808
Epoch 0, Step 2293: train/loss = 0.2678034007549286, train/raw-loss = 0.17651382088661194, train/logprobs = tensor([[-0.8726, -3.8986],
        [-3.6802, -0.9224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09128957241773605
Epoch 0, Step 2294: train/loss = 0.325817346572876, train/raw-loss = 0.25643107295036316, train/logprobs = tensor([[-0.7685, -4.1922],
        [-2.1506, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06938627362251282
Epoch 0, Step 2295: train/loss = 0.33668404817581177, train/raw-loss = 0.275970995426178, train/logprobs = tensor([[-0.4153, -4.6790],
        [-0.6543, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0607130266726017
Epoch 0, Step 2296: train/loss = 0.18911010026931763, train/raw-loss = 0.10145160555839539, train/logprobs = tensor([[-0.6792, -5.3889],
        [-4.0411, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765847980976105
Epoch 0, Step 2297: train/loss = 0.43525388836860657, train/raw-loss = 0.35888516902923584, train/logprobs = tensor([[-0.7313, -3.2501],
        [-2.1478, -0.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07636873424053192
Epoch 0, Step 2298: train/loss = 0.34131357073783875, train/raw-loss = 0.2748161852359772, train/logprobs = tensor([[-0.5057, -4.9479],
        [-1.1539, -0.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06649737060070038
Epoch 0, Step 2299: train/loss = 0.5481177568435669, train/raw-loss = 0.45352017879486084, train/logprobs = tensor([[-0.8015, -1.6062],
        [-1.3677, -0.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09459762275218964
Epoch 0, Step 2300: train/loss = 0.24732446670532227, train/raw-loss = 0.1762128472328186, train/logprobs = tensor([[-0.5425, -5.5195],
        [-2.9948, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07111162692308426
Epoch 0, Step 2301: train/loss = 0.39713022112846375, train/raw-loss = 0.3417722284793854, train/logprobs = tensor([[-1.0333, -2.2116],
        [-3.7347, -0.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05535798519849777
Epoch 0, Step 2302: train/loss = 0.37879523634910583, train/raw-loss = 0.284746378660202, train/logprobs = tensor([[-1.1517, -5.2512],
        [-2.4726, -0.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940488651394844
Epoch 0, Step 2303: train/loss = 0.3925916254520416, train/raw-loss = 0.31375470757484436, train/logprobs = tensor([[-1.1491, -3.7790],
        [-1.6689, -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883691042661667
Epoch 0, Step 2304: train/loss = 0.3173626959323883, train/raw-loss = 0.22399196028709412, train/logprobs = tensor([[-1.6049, -4.8923],
        [-3.8221, -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0933707058429718
Epoch 0, Step 2305: train/loss = 0.24838802218437195, train/raw-loss = 0.15927177667617798, train/logprobs = tensor([[-0.7603, -5.2345],
        [-2.0905, -0.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08911623805761337
Epoch 0, Step 2306: train/loss = 0.2659859359264374, train/raw-loss = 0.1662222445011139, train/logprobs = tensor([[-0.6517, -4.6347],
        [-2.3396, -1.0697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09976368397474289
Epoch 0, Step 2307: train/loss = 0.30154380202293396, train/raw-loss = 0.22506868839263916, train/logprobs = tensor([[-0.5721, -5.0598],
        [-1.8931, -1.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764751210808754
Epoch 0, Step 2308: train/loss = 0.3782208263874054, train/raw-loss = 0.2994236946105957, train/logprobs = tensor([[-0.8177, -2.1950],
        [-3.3816, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07879713177680969
Epoch 0, Step 2309: train/loss = 0.28352123498916626, train/raw-loss = 0.176179438829422, train/logprobs = tensor([[-0.7395, -4.9741],
        [-2.5402, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10734179615974426
Epoch 0, Step 2310: train/loss = 0.311215341091156, train/raw-loss = 0.22369949519634247, train/logprobs = tensor([[-0.7670, -4.5600],
        [-2.2327, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08751584589481354
Epoch 0, Step 2311: train/loss = 0.2867777645587921, train/raw-loss = 0.1905440092086792, train/logprobs = tensor([[-0.5882, -4.0520],
        [-1.6377, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09623375535011292
Epoch 0, Step 2312: train/loss = 0.37918174266815186, train/raw-loss = 0.2813907861709595, train/logprobs = tensor([[-0.7216, -2.6919],
        [-2.3570, -0.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779098629951477
Epoch 0, Step 2313: train/loss = 0.30518266558647156, train/raw-loss = 0.2197757363319397, train/logprobs = tensor([[-0.7407, -2.4808],
        [-3.3008, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08540692925453186
Epoch 0, Step 2314: train/loss = 0.5401440858840942, train/raw-loss = 0.4834885597229004, train/logprobs = tensor([[-0.7219, -1.0894],
        [-1.8278, -0.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05665554478764534
Epoch 0, Step 2315: train/loss = 0.3099403977394104, train/raw-loss = 0.22862078249454498, train/logprobs = tensor([[-0.5630, -4.1640],
        [-1.7667, -1.2797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08131963014602661
Epoch 0, Step 2316: train/loss = 0.32410967350006104, train/raw-loss = 0.21732443571090698, train/logprobs = tensor([[-0.8941, -3.1262],
        [-2.5087, -0.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10678523778915405
Epoch 0, Step 2317: train/loss = 0.3054920732975006, train/raw-loss = 0.19044512510299683, train/logprobs = tensor([[-0.8826, -3.7404],
        [-3.6516, -1.3286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504696309566498
Epoch 0, Step 2318: train/loss = 0.23231109976768494, train/raw-loss = 0.13580675423145294, train/logprobs = tensor([[-0.5610, -5.8278],
        [-2.3272, -0.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09650436043739319
Epoch 0, Step 2319: train/loss = 0.47725710272789, train/raw-loss = 0.40258023142814636, train/logprobs = tensor([[-0.5743, -3.0842],
        [-0.8686, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07467686384916306
Epoch 0, Step 2320: train/loss = 0.4949948191642761, train/raw-loss = 0.40534383058547974, train/logprobs = tensor([[-0.9976, -1.8865],
        [-1.7857, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08965098857879639
Epoch 0, Step 2321: train/loss = 0.5182526111602783, train/raw-loss = 0.4646451771259308, train/logprobs = tensor([[-0.6297, -3.0092],
        [-0.7921, -0.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05360747128725052
Epoch 0, Step 2322: train/loss = 0.5071485638618469, train/raw-loss = 0.4483537971973419, train/logprobs = tensor([[-0.8044, -2.8945],
        [-1.1223, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0587947815656662
Epoch 0, Step 2323: train/loss = 0.3355608284473419, train/raw-loss = 0.25216203927993774, train/logprobs = tensor([[-0.6496, -4.3917],
        [-1.9295, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08339875936508179
Epoch 0, Step 2324: train/loss = 0.41301512718200684, train/raw-loss = 0.3104207217693329, train/logprobs = tensor([[-1.0236, -2.7091],
        [-3.8643, -1.0671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259442031383514
Epoch 0, Step 2325: train/loss = 0.36670222878456116, train/raw-loss = 0.2873426675796509, train/logprobs = tensor([[-0.7752, -4.2614],
        [-3.2068, -0.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793595165014267
Epoch 0, Step 2326: train/loss = 0.29369598627090454, train/raw-loss = 0.19784396886825562, train/logprobs = tensor([[-0.9313, -3.3414],
        [-2.7816, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09585198760032654
Epoch 0, Step 2327: train/loss = 0.2499208003282547, train/raw-loss = 0.16452203691005707, train/logprobs = tensor([[-0.8117, -4.0172],
        [-2.7333, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08539876341819763
Epoch 0, Step 2328: train/loss = 0.48593053221702576, train/raw-loss = 0.40860259532928467, train/logprobs = tensor([[-0.5882, -2.4847],
        [-1.1082, -0.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07732793688774109
Epoch 0, Step 2329: train/loss = 0.378404438495636, train/raw-loss = 0.30577489733695984, train/logprobs = tensor([[-0.5018, -4.3123],
        [-0.9248, -0.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07262953370809555
Epoch 0, Step 2330: train/loss = 0.3165791630744934, train/raw-loss = 0.21902622282505035, train/logprobs = tensor([[-0.8855, -3.9462],
        [-2.7665, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09755291789770126
Epoch 0, Step 2331: train/loss = 0.5087012648582458, train/raw-loss = 0.43605703115463257, train/logprobs = tensor([[-0.4983, -3.5717],
        [-1.0412, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07264422625303268
Epoch 0, Step 2332: train/loss = 0.4308887720108032, train/raw-loss = 0.36937928199768066, train/logprobs = tensor([[-1.1495, -3.8286],
        [-1.6793, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06150949373841286
Epoch 0, Step 2333: train/loss = 0.3454072177410126, train/raw-loss = 0.2739158868789673, train/logprobs = tensor([[-0.5925, -4.6239],
        [-0.9661, -0.6031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07149134576320648
Epoch 0, Step 2334: train/loss = 0.4482419788837433, train/raw-loss = 0.38429445028305054, train/logprobs = tensor([[-0.4304, -4.2121],
        [-1.5073, -1.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06394755095243454
Epoch 0, Step 2335: train/loss = 0.3647768199443817, train/raw-loss = 0.2825069725513458, train/logprobs = tensor([[-0.5276, -4.1723],
        [-1.9681, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08226983994245529
Epoch 0, Step 2336: train/loss = 0.8426984548568726, train/raw-loss = 0.7321914434432983, train/logprobs = tensor([[-1.0389, -1.7589],
        [-2.6161, -2.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050708591938019
Epoch 0, Step 2337: train/loss = 0.27969890832901, train/raw-loss = 0.18362683057785034, train/logprobs = tensor([[-1.1184, -4.9326],
        [-2.8482, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09607209265232086
Epoch 0, Step 2338: train/loss = 0.3306877017021179, train/raw-loss = 0.240839421749115, train/logprobs = tensor([[-0.7286, -3.6118],
        [-1.9654, -0.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08984826505184174
Epoch 0, Step 2339: train/loss = 0.6526622772216797, train/raw-loss = 0.5684941411018372, train/logprobs = tensor([[-0.8341, -1.7065],
        [-1.0199, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0841682031750679
Epoch 0, Step 2340: train/loss = 0.27649587392807007, train/raw-loss = 0.1893598735332489, train/logprobs = tensor([[-1.0153, -3.3478],
        [-3.5902, -0.7295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08713597804307938
Epoch 0, Step 2341: train/loss = 0.37954968214035034, train/raw-loss = 0.3063250184059143, train/logprobs = tensor([[-0.4933, -3.4266],
        [-1.2655, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07322467118501663
Epoch 0, Step 2342: train/loss = 0.5105262994766235, train/raw-loss = 0.4330591857433319, train/logprobs = tensor([[-0.8571, -0.9479],
        [-4.0645, -0.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07746710628271103
Epoch 0, Step 2343: train/loss = 0.3906317353248596, train/raw-loss = 0.31204718351364136, train/logprobs = tensor([[-0.8718, -3.7956],
        [-2.8572, -0.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07858458161354065
Epoch 0, Step 2344: train/loss = 0.48108455538749695, train/raw-loss = 0.3923863172531128, train/logprobs = tensor([[-1.1214, -2.9151],
        [-2.6351, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08869824558496475
Epoch 0, Step 2345: train/loss = 0.5597739219665527, train/raw-loss = 0.49612686038017273, train/logprobs = tensor([[-0.4360, -2.3381],
        [-0.8368, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06364704668521881
Epoch 0, Step 2346: train/loss = 0.7177325487136841, train/raw-loss = 0.6645106673240662, train/logprobs = tensor([[-0.8555, -1.0047],
        [-1.3584, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05322190746665001
Epoch 0, Step 2347: train/loss = 0.13038842380046844, train/raw-loss = 0.042677950114011765, train/logprobs = tensor([[-1.4645, -7.9051],
        [-4.5680, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08771047741174698
Epoch 0, Step 2348: train/loss = 0.3509266972541809, train/raw-loss = 0.2675023674964905, train/logprobs = tensor([[-0.6751, -3.0079],
        [-3.6767, -0.6310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08342433720827103
Epoch 0, Step 2349: train/loss = 0.5608993172645569, train/raw-loss = 0.4619862139225006, train/logprobs = tensor([[-0.6741, -2.6857],
        [-1.7329, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09891309589147568
Epoch 0, Step 2350: train/loss = 0.3832710087299347, train/raw-loss = 0.2709580361843109, train/logprobs = tensor([[-0.8247, -1.3764],
        [-4.2469, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11231298744678497
Epoch 0, Step 2351: train/loss = 0.3992447853088379, train/raw-loss = 0.3209151029586792, train/logprobs = tensor([[-0.4847, -5.0352],
        [-0.9648, -0.8545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07832969725131989
Epoch 0, Step 2352: train/loss = 0.3997041583061218, train/raw-loss = 0.32766035199165344, train/logprobs = tensor([[-0.8057, -3.5433],
        [-1.7751, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07204383611679077
Epoch 0, Step 2353: train/loss = 0.25576144456863403, train/raw-loss = 0.16835656762123108, train/logprobs = tensor([[-0.5397, -5.6550],
        [-1.9552, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08740486204624176
Epoch 0, Step 2354: train/loss = 0.37403586506843567, train/raw-loss = 0.28412631154060364, train/logprobs = tensor([[-0.8196, -3.5108],
        [-2.5345, -1.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08990954607725143
Epoch 0, Step 2355: train/loss = 0.2695469260215759, train/raw-loss = 0.1780412346124649, train/logprobs = tensor([[-0.9485, -4.0375],
        [-3.5871, -0.4589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150571376085281
Epoch 0, Step 2356: train/loss = 0.2728419899940491, train/raw-loss = 0.16467097401618958, train/logprobs = tensor([[-1.0271, -3.4910],
        [-4.9615, -1.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1081710159778595
Epoch 0, Step 2357: train/loss = 0.4493984878063202, train/raw-loss = 0.3589738607406616, train/logprobs = tensor([[-1.1923, -4.6186],
        [-2.0821, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09042464196681976
Epoch 0, Step 2358: train/loss = 0.4597790837287903, train/raw-loss = 0.3964724540710449, train/logprobs = tensor([[-0.6093, -3.7019],
        [-0.9867, -0.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330659240484238
Epoch 0, Step 2359: train/loss = 0.5473636984825134, train/raw-loss = 0.4646301567554474, train/logprobs = tensor([[-1.0276, -2.7423],
        [-2.5262, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08273357152938843
Epoch 0, Step 2360: train/loss = 0.4623122215270996, train/raw-loss = 0.37278056144714355, train/logprobs = tensor([[-0.5341, -1.3760],
        [-2.3173, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08953168988227844
Epoch 0, Step 2361: train/loss = 0.5357308387756348, train/raw-loss = 0.445529043674469, train/logprobs = tensor([[-0.9875, -4.5865],
        [-2.2462, -2.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09020182490348816
Epoch 0, Step 2362: train/loss = 0.2512950897216797, train/raw-loss = 0.13946382701396942, train/logprobs = tensor([[-0.9367, -5.7992],
        [-3.1840, -1.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11183127760887146
Epoch 0, Step 2363: train/loss = 0.6866140961647034, train/raw-loss = 0.603925347328186, train/logprobs = tensor([[-1.4478, -3.1265],
        [-2.6457, -2.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08268869668245316
Epoch 0, Step 2364: train/loss = 0.18154902756214142, train/raw-loss = 0.07892042398452759, train/logprobs = tensor([[-0.7817, -4.6514],
        [-4.1411, -0.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10262860357761383
Epoch 0, Step 2365: train/loss = 0.2778596878051758, train/raw-loss = 0.20642560720443726, train/logprobs = tensor([[-0.8760, -3.9215],
        [-2.2849, -0.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07143408060073853
Epoch 0, Step 2366: train/loss = 0.6377522945404053, train/raw-loss = 0.560401201248169, train/logprobs = tensor([[-0.8942, -5.0115],
        [-2.3241, -2.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773511603474617
Epoch 0, Step 2367: train/loss = 0.6085008382797241, train/raw-loss = 0.5200668573379517, train/logprobs = tensor([[-0.7452, -1.5704],
        [-1.0976, -0.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843395113945007
Epoch 0, Step 2368: train/loss = 0.4783352017402649, train/raw-loss = 0.4055393636226654, train/logprobs = tensor([[-0.8378, -4.4939],
        [-1.2486, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07279586791992188
Epoch 0, Step 2369: train/loss = 0.7449773550033569, train/raw-loss = 0.6620249152183533, train/logprobs = tensor([[-1.7179, -2.7944],
        [-1.6681, -0.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08295237272977829
Epoch 0, Step 2370: train/loss = 0.6200088858604431, train/raw-loss = 0.5674288272857666, train/logprobs = tensor([[-0.7262, -1.1090],
        [-1.2030, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052580077201128006
Epoch 0, Step 2371: train/loss = 0.27486464381217957, train/raw-loss = 0.18099680542945862, train/logprobs = tensor([[-0.7495, -4.6332],
        [-2.9229, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09386785328388214
Epoch 0, Step 2372: train/loss = 0.31682607531547546, train/raw-loss = 0.2304539680480957, train/logprobs = tensor([[-0.8413, -4.2492],
        [-3.5381, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08637209236621857
Epoch 0, Step 2373: train/loss = 0.5082979798316956, train/raw-loss = 0.4317343533039093, train/logprobs = tensor([[-0.9176, -4.1113],
        [-0.9246, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07656366378068924
Epoch 0, Step 2374: train/loss = 0.34220269322395325, train/raw-loss = 0.26090502738952637, train/logprobs = tensor([[-0.8727, -2.9742],
        [-4.4813, -1.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129768818616867
Loss is nan
eval/loss: 0.40152788162231445
[2024-03-03 16:19:47,875][root][INFO] - beta: 3.0
[2024-03-03 16:19:47,876][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-3.0-iteration-1-0-5k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 8884
n harmless: 9970
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ"}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-3.0-iteration-1-0-5k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-3.0-iteration-1-0-5k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-3.0-iteration-1-0-5k after each epoch.
5000
5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-3.0-iteration-1-0-5k after each epoch.
Loss is nan
eval/loss: 0.6716450452804565
Epoch 0, Step 0: train/loss = 0.6876811981201172, train/raw-loss = 0.6876811981201172, train/logprobs = tensor([[-0.7991, -2.1136],
        [-0.8144, -2.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7017812728881836, train/raw-loss = 0.7017812728881836, train/logprobs = tensor([[-0.8675, -1.3647],
        [-0.9045, -1.4349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6647472381591797, train/raw-loss = 0.6647472381591797, train/logprobs = tensor([[-0.9712, -1.6776],
        [-1.0482, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6691160798072815, train/raw-loss = 0.6691160798072815, train/logprobs = tensor([[-0.7613, -1.0412],
        [-0.8040, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6818459033966064, train/raw-loss = 0.6818459033966064, train/logprobs = tensor([[-0.7423, -0.8494],
        [-0.8033, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7001824378967285, train/raw-loss = 0.7001824378967285, train/logprobs = tensor([[-0.8634, -1.2522],
        [-0.8944, -1.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6646842360496521, train/raw-loss = 0.6646842360496521, train/logprobs = tensor([[-1.0534, -1.4514],
        [-1.1196, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.692057192325592, train/raw-loss = 0.692057192325592, train/logprobs = tensor([[-1.0745, -1.3111],
        [-1.1357, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6729065179824829, train/raw-loss = 0.6729065179824829, train/logprobs = tensor([[-0.5144, -1.1528],
        [-0.5067, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6754744052886963, train/raw-loss = 0.6754744052886963, train/logprobs = tensor([[-1.0090, -1.1000],
        [-1.0342, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6382375955581665, train/raw-loss = 0.6382375955581665, train/logprobs = tensor([[-1.0358, -1.3086],
        [-1.3042, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6904394626617432, train/raw-loss = 0.6904394626617432, train/logprobs = tensor([[-0.7226, -1.2303],
        [-0.7300, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6897714734077454, train/raw-loss = 0.6897714734077454, train/logprobs = tensor([[-0.9022, -1.2302],
        [-0.9290, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6802294254302979, train/raw-loss = 0.6802294254302979, train/logprobs = tensor([[-0.6706, -1.2400],
        [-0.6935, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6690350770950317, train/raw-loss = 0.6690350770950317, train/logprobs = tensor([[-1.1638, -1.2059],
        [-1.2771, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6677312850952148, train/raw-loss = 0.6677312850952148, train/logprobs = tensor([[-1.2674, -1.3661],
        [-1.3281, -1.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6589983701705933, train/raw-loss = 0.6589983701705933, train/logprobs = tensor([[-0.8304, -1.3320],
        [-0.8951, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6930590867996216, train/raw-loss = 0.6930590867996216, train/logprobs = tensor([[-0.7644, -1.0668],
        [-0.7867, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6523447036743164, train/raw-loss = 0.6523447036743164, train/logprobs = tensor([[-0.9116, -1.1920],
        [-1.0786, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6793126463890076, train/raw-loss = 0.6793126463890076, train/logprobs = tensor([[-0.8504, -1.1314],
        [-0.8680, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6822050213813782, train/raw-loss = 0.6822050213813782, train/logprobs = tensor([[-0.8326, -1.3713],
        [-0.9170, -1.4066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6489429473876953, train/raw-loss = 0.6489429473876953, train/logprobs = tensor([[-1.3826, -1.5213],
        [-1.5211, -1.4736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6750220060348511, train/raw-loss = 0.6750220060348511, train/logprobs = tensor([[-0.8851, -0.7172],
        [-0.9591, -0.7163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6739029288291931, train/raw-loss = 0.6739029288291931, train/logprobs = tensor([[-0.7526, -1.6962],
        [-0.8254, -1.6867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6721904873847961, train/raw-loss = 0.6721904873847961, train/logprobs = tensor([[-0.8545, -1.1816],
        [-0.8767, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6630262732505798, train/raw-loss = 0.6630262732505798, train/logprobs = tensor([[-1.1663, -1.0103],
        [-1.2706, -0.9908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6829202175140381, train/raw-loss = 0.6829202175140381, train/logprobs = tensor([[-1.0265, -1.0503],
        [-1.0613, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6595985293388367, train/raw-loss = 0.6595985293388367, train/logprobs = tensor([[-1.1463, -1.5332],
        [-1.2361, -1.4847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6569761633872986, train/raw-loss = 0.6569761633872986, train/logprobs = tensor([[-0.7432, -0.9342],
        [-0.8139, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6692489385604858, train/raw-loss = 0.6692489385604858, train/logprobs = tensor([[-0.8930, -1.2501],
        [-0.9570, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6794319152832031, train/raw-loss = 0.6794319152832031, train/logprobs = tensor([[-0.7914, -1.1187],
        [-0.7899, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.655624508857727, train/raw-loss = 0.655624508857727, train/logprobs = tensor([[-1.5374, -1.5602],
        [-1.6876, -1.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6592499017715454, train/raw-loss = 0.6592499017715454, train/logprobs = tensor([[-0.9855, -1.1981],
        [-1.0750, -1.1470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6820563077926636, train/raw-loss = 0.6820563077926636, train/logprobs = tensor([[-0.6501, -1.2848],
        [-0.6630, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6683226823806763, train/raw-loss = 0.6683226823806763, train/logprobs = tensor([[-0.9491, -1.3495],
        [-1.0024, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6583713889122009, train/raw-loss = 0.6583713889122009, train/logprobs = tensor([[-0.8106, -1.6709],
        [-0.9243, -1.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6469834446907043, train/raw-loss = 0.6469834446907043, train/logprobs = tensor([[-1.5048, -2.2232],
        [-1.5990, -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6797101497650146, train/raw-loss = 0.6797101497650146, train/logprobs = tensor([[-0.6664, -1.6870],
        [-0.6909, -1.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.683232843875885, train/raw-loss = 0.683232843875885, train/logprobs = tensor([[-0.9656, -1.3642],
        [-1.0281, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6942904591560364, train/raw-loss = 0.6942904591560364, train/logprobs = tensor([[-0.4989, -0.9991],
        [-0.5058, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6635227203369141, train/raw-loss = 0.6635227203369141, train/logprobs = tensor([[-0.7571, -1.2971],
        [-0.8222, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6960233449935913, train/raw-loss = 0.6960233449935913, train/logprobs = tensor([[-1.6412, -0.8003],
        [-1.6515, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6716673970222473, train/raw-loss = 0.6716673970222473, train/logprobs = tensor([[-0.9006, -1.8356],
        [-0.9486, -1.7935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6504718065261841, train/raw-loss = 0.6504718065261841, train/logprobs = tensor([[-1.0048, -1.1417],
        [-1.1579, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6575814485549927, train/raw-loss = 0.6575814485549927, train/logprobs = tensor([[-1.4579, -1.0380],
        [-1.5999, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6726564168930054, train/raw-loss = 0.6726564168930054, train/logprobs = tensor([[-1.2457, -1.0000],
        [-1.3556, -1.0253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6659195423126221, train/raw-loss = 0.6659195423126221, train/logprobs = tensor([[-1.1039, -1.4521],
        [-1.2564, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6463595628738403, train/raw-loss = 0.6463595628738403, train/logprobs = tensor([[-0.6710, -1.5861],
        [-0.7079, -1.4080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6638263463973999, train/raw-loss = 0.6638263463973999, train/logprobs = tensor([[-1.2741, -1.4761],
        [-1.3570, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6739931106567383, train/raw-loss = 0.6739931106567383, train/logprobs = tensor([[-0.8710, -1.0174],
        [-0.8790, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.678565263748169, train/raw-loss = 0.678565263748169, train/logprobs = tensor([[-1.1486, -0.8595],
        [-1.2491, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6736483573913574, train/raw-loss = 0.6736483573913574, train/logprobs = tensor([[-0.7778, -1.5755],
        [-0.8147, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6805825233459473, train/raw-loss = 0.6805825233459473, train/logprobs = tensor([[-1.3469, -0.9800],
        [-1.4307, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6744076013565063, train/raw-loss = 0.6744076013565063, train/logprobs = tensor([[-0.6959, -1.2708],
        [-0.8213, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6815992593765259, train/raw-loss = 0.6815992593765259, train/logprobs = tensor([[-0.6407, -0.9858],
        [-0.6565, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6931482553482056, train/raw-loss = 0.6931482553482056, train/logprobs = tensor([[-0.8090, -1.1945],
        [-0.8420, -1.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6945903897285461, train/raw-loss = 0.6945903897285461, train/logprobs = tensor([[-0.7038, -1.2251],
        [-0.7267, -1.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6877249479293823, train/raw-loss = 0.6877249479293823, train/logprobs = tensor([[-0.6526, -1.2008],
        [-0.6792, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6316418051719666, train/raw-loss = 0.6316418051719666, train/logprobs = tensor([[-0.8534, -1.8226],
        [-0.8765, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.668732762336731, train/raw-loss = 0.668732762336731, train/logprobs = tensor([[-1.2706, -1.2705],
        [-1.3812, -1.2800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6924586892127991, train/raw-loss = 0.6924586892127991, train/logprobs = tensor([[-0.6864, -0.6025],
        [-0.6989, -0.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6888662576675415, train/raw-loss = 0.6888662576675415, train/logprobs = tensor([[-0.5987, -0.8959],
        [-0.6033, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6881542801856995, train/raw-loss = 0.6881542801856995, train/logprobs = tensor([[-0.9270, -1.5385],
        [-0.9858, -1.5753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7003958225250244, train/raw-loss = 0.7003958225250244, train/logprobs = tensor([[-1.1320, -1.5081],
        [-1.1284, -1.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.70454341173172, train/raw-loss = 0.6797922849655151, train/logprobs = tensor([[-0.6327, -3.4864],
        [-0.6537, -3.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008250383660197258
Epoch 0, Step 65: train/loss = 0.6780550479888916, train/raw-loss = 0.6458868384361267, train/logprobs = tensor([[-1.0045, -1.0842],
        [-1.1962, -1.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01072276197373867
Epoch 0, Step 66: train/loss = 0.7060879468917847, train/raw-loss = 0.6866233348846436, train/logprobs = tensor([[-0.5658, -0.8155],
        [-0.5658, -0.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006488190498203039
Epoch 0, Step 67: train/loss = 0.7116432189941406, train/raw-loss = 0.6887040138244629, train/logprobs = tensor([[-0.5674, -0.9039],
        [-0.5638, -0.8824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007646425161510706
Epoch 0, Step 68: train/loss = 0.7119999527931213, train/raw-loss = 0.6795957088470459, train/logprobs = tensor([[-0.9399, -1.6343],
        [-0.9783, -1.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010801395401358604
Epoch 0, Step 69: train/loss = 0.6951218247413635, train/raw-loss = 0.6677181720733643, train/logprobs = tensor([[-0.7906, -1.3100],
        [-0.9540, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009134560823440552
Epoch 0, Step 70: train/loss = 0.704103410243988, train/raw-loss = 0.6845057606697083, train/logprobs = tensor([[-0.5627, -1.9065],
        [-0.5632, -1.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006532547064125538
Epoch 0, Step 71: train/loss = 0.6907658576965332, train/raw-loss = 0.6622990965843201, train/logprobs = tensor([[-1.0316, -1.6700],
        [-1.1530, -1.6608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009488917887210846
Epoch 0, Step 72: train/loss = 0.7172317504882812, train/raw-loss = 0.6864801645278931, train/logprobs = tensor([[-1.5085, -1.9921],
        [-1.6028, -2.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010250523686408997
Epoch 0, Step 73: train/loss = 0.7012193202972412, train/raw-loss = 0.6655623912811279, train/logprobs = tensor([[-1.0854, -1.2705],
        [-1.1862, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011885637417435646
Epoch 0, Step 74: train/loss = 0.6690899729728699, train/raw-loss = 0.641118049621582, train/logprobs = tensor([[-1.2339, -0.7117],
        [-1.4334, -0.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009323964826762676
Epoch 0, Step 75: train/loss = 0.7133890390396118, train/raw-loss = 0.6897883415222168, train/logprobs = tensor([[-0.8104, -1.3715],
        [-0.8418, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007866885513067245
Epoch 0, Step 76: train/loss = 0.7024780511856079, train/raw-loss = 0.6768139600753784, train/logprobs = tensor([[-0.6299, -0.6396],
        [-0.7051, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008554695174098015
Epoch 0, Step 77: train/loss = 0.6870959997177124, train/raw-loss = 0.6516051292419434, train/logprobs = tensor([[-1.1882, -1.2211],
        [-1.3674, -1.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011830289848148823
Epoch 0, Step 78: train/loss = 0.68309485912323, train/raw-loss = 0.6513925194740295, train/logprobs = tensor([[-1.1930, -0.9389],
        [-1.3829, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010567429475486279
Epoch 0, Step 79: train/loss = 0.70479416847229, train/raw-loss = 0.6713190674781799, train/logprobs = tensor([[-0.7570, -0.9284],
        [-0.8540, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0111583536490798
Epoch 0, Step 80: train/loss = 0.709318220615387, train/raw-loss = 0.6781667470932007, train/logprobs = tensor([[-0.7986, -1.0214],
        [-0.8174, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010383808054029942
Epoch 0, Step 81: train/loss = 0.6918397545814514, train/raw-loss = 0.6655398607254028, train/logprobs = tensor([[-1.1353, -1.0206],
        [-1.2285, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008766615763306618
Epoch 0, Step 82: train/loss = 0.6648308038711548, train/raw-loss = 0.6308339238166809, train/logprobs = tensor([[-1.1030, -1.2731],
        [-1.3457, -1.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01133229024708271
Epoch 0, Step 83: train/loss = 0.6908551454544067, train/raw-loss = 0.6700697541236877, train/logprobs = tensor([[-0.9774, -1.2705],
        [-1.0887, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006928488612174988
Epoch 0, Step 84: train/loss = 0.6971105337142944, train/raw-loss = 0.6704286336898804, train/logprobs = tensor([[-0.4958, -1.1854],
        [-0.5219, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008893968537449837
Epoch 0, Step 85: train/loss = 0.6873934268951416, train/raw-loss = 0.6565191745758057, train/logprobs = tensor([[-0.9101, -1.0823],
        [-1.1082, -1.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01029142551124096
Epoch 0, Step 86: train/loss = 0.7094886898994446, train/raw-loss = 0.6788330078125, train/logprobs = tensor([[-0.6999, -1.1666],
        [-0.7109, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010218556970357895
Epoch 0, Step 87: train/loss = 0.6870447397232056, train/raw-loss = 0.6481914520263672, train/logprobs = tensor([[-0.8663, -1.6744],
        [-1.0199, -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012951105833053589
Epoch 0, Step 88: train/loss = 0.707977294921875, train/raw-loss = 0.6850193738937378, train/logprobs = tensor([[-0.5441, -1.5480],
        [-0.5520, -1.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00765267014503479
Epoch 0, Step 89: train/loss = 0.7201067209243774, train/raw-loss = 0.6973506212234497, train/logprobs = tensor([[-0.7881, -1.1967],
        [-0.8680, -1.2885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007585365325212479
Epoch 0, Step 90: train/loss = 0.7034554481506348, train/raw-loss = 0.6696906089782715, train/logprobs = tensor([[-0.8011, -1.1417],
        [-0.8736, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011254945769906044
Epoch 0, Step 91: train/loss = 0.6536100506782532, train/raw-loss = 0.6241300702095032, train/logprobs = tensor([[-1.0764, -1.5353],
        [-1.1473, -1.2668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009826648980379105
Epoch 0, Step 92: train/loss = 0.7101407051086426, train/raw-loss = 0.67885822057724, train/logprobs = tensor([[-1.0593, -1.0588],
        [-1.0846, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010427478700876236
Epoch 0, Step 93: train/loss = 0.6966014504432678, train/raw-loss = 0.6636738181114197, train/logprobs = tensor([[-1.1946, -1.3186],
        [-1.3279, -1.3239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010975880548357964
Epoch 0, Step 94: train/loss = 0.7020418643951416, train/raw-loss = 0.6702110171318054, train/logprobs = tensor([[-0.9925, -1.1199],
        [-1.0631, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010610291734337807
Epoch 0, Step 95: train/loss = 0.7043366432189941, train/raw-loss = 0.6722020506858826, train/logprobs = tensor([[-0.8270, -1.0040],
        [-0.9118, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010711541399359703
Epoch 0, Step 96: train/loss = 0.7023849487304688, train/raw-loss = 0.6550354957580566, train/logprobs = tensor([[-0.8618, -1.0143],
        [-0.9273, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01578313298523426
Epoch 0, Step 97: train/loss = 0.684037983417511, train/raw-loss = 0.6196982860565186, train/logprobs = tensor([[-0.7959, -1.9734],
        [-0.9404, -1.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021446559578180313
Epoch 0, Step 98: train/loss = 0.7242215871810913, train/raw-loss = 0.6652731895446777, train/logprobs = tensor([[-0.7920, -1.4001],
        [-0.9273, -1.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019649464637041092
Epoch 0, Step 99: train/loss = 0.7202701568603516, train/raw-loss = 0.6616673469543457, train/logprobs = tensor([[-0.8629, -1.6804],
        [-0.9629, -1.6481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019534289836883545
Epoch 0, Step 100: train/loss = 0.6735458374023438, train/raw-loss = 0.6180304288864136, train/logprobs = tensor([[-1.1902, -1.3607],
        [-1.5694, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018505122512578964
Epoch 0, Step 101: train/loss = 0.7243993878364563, train/raw-loss = 0.6701231002807617, train/logprobs = tensor([[-0.9745, -1.4472],
        [-1.1364, -1.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018092095851898193
Epoch 0, Step 102: train/loss = 0.7296764850616455, train/raw-loss = 0.6724233627319336, train/logprobs = tensor([[-0.5208, -1.2910],
        [-0.5308, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019084392115473747
Epoch 0, Step 103: train/loss = 0.7098203301429749, train/raw-loss = 0.6677501201629639, train/logprobs = tensor([[-0.9613, -1.2098],
        [-1.0520, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014023400843143463
Epoch 0, Step 104: train/loss = 0.7052760720252991, train/raw-loss = 0.649199903011322, train/logprobs = tensor([[-0.8829, -1.2978],
        [-0.9809, -1.2129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018692055717110634
Epoch 0, Step 105: train/loss = 0.6579110622406006, train/raw-loss = 0.5983461141586304, train/logprobs = tensor([[-1.3904, -1.9689],
        [-1.7626, -1.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01985500566661358
Epoch 0, Step 106: train/loss = 0.7270261645317078, train/raw-loss = 0.6740861535072327, train/logprobs = tensor([[-0.6984, -1.4779],
        [-0.6992, -1.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01764666847884655
Epoch 0, Step 107: train/loss = 0.7016581892967224, train/raw-loss = 0.6507406234741211, train/logprobs = tensor([[-1.4952, -1.8169],
        [-1.6897, -1.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016972534358501434
Epoch 0, Step 108: train/loss = 0.7214407324790955, train/raw-loss = 0.6694587469100952, train/logprobs = tensor([[-1.2958, -2.5637],
        [-1.3740, -2.5446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01732731983065605
Epoch 0, Step 109: train/loss = 0.7379319071769714, train/raw-loss = 0.6778916120529175, train/logprobs = tensor([[-0.5464, -1.1560],
        [-0.5492, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020013444125652313
Epoch 0, Step 110: train/loss = 0.7334324717521667, train/raw-loss = 0.6814287304878235, train/logprobs = tensor([[-0.9316, -1.6191],
        [-0.9872, -1.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017334580421447754
Epoch 0, Step 111: train/loss = 0.7002096772193909, train/raw-loss = 0.6587819457054138, train/logprobs = tensor([[-1.1585, -1.1682],
        [-1.3144, -1.1768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013809243217110634
Epoch 0, Step 112: train/loss = 0.7007681727409363, train/raw-loss = 0.6403689384460449, train/logprobs = tensor([[-1.5559, -1.9471],
        [-1.7384, -1.9063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020133063197135925
Epoch 0, Step 113: train/loss = 0.6912341117858887, train/raw-loss = 0.6371217370033264, train/logprobs = tensor([[-1.1840, -1.3878],
        [-1.4235, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018037468194961548
Epoch 0, Step 114: train/loss = 0.695405900478363, train/raw-loss = 0.639823853969574, train/logprobs = tensor([[-1.0887, -1.5428],
        [-1.2198, -1.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018527355045080185
Epoch 0, Step 115: train/loss = 0.7186362743377686, train/raw-loss = 0.6741639375686646, train/logprobs = tensor([[-0.8831, -1.5016],
        [-0.9613, -1.4983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014824102632701397
Epoch 0, Step 116: train/loss = 0.7250711917877197, train/raw-loss = 0.6829468011856079, train/logprobs = tensor([[-0.5084, -0.8965],
        [-0.5307, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014041481539607048
Epoch 0, Step 117: train/loss = 0.7267668843269348, train/raw-loss = 0.6861777305603027, train/logprobs = tensor([[-1.0130, -1.0533],
        [-1.1064, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013529730960726738
Epoch 0, Step 118: train/loss = 0.6864197254180908, train/raw-loss = 0.639045774936676, train/logprobs = tensor([[-0.7103, -0.9762],
        [-0.8773, -0.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01579131744801998
Epoch 0, Step 119: train/loss = 0.6602790355682373, train/raw-loss = 0.5954144597053528, train/logprobs = tensor([[-1.0473, -1.6762],
        [-1.3391, -1.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02162153832614422
Epoch 0, Step 120: train/loss = 0.6495968699455261, train/raw-loss = 0.5948047637939453, train/logprobs = tensor([[-1.0197, -2.0282],
        [-1.2066, -1.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018264040350914
Epoch 0, Step 121: train/loss = 0.71326744556427, train/raw-loss = 0.6709462404251099, train/logprobs = tensor([[-0.6956, -0.9952],
        [-0.7423, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014107050374150276
Epoch 0, Step 122: train/loss = 0.7359210252761841, train/raw-loss = 0.6779625415802002, train/logprobs = tensor([[-0.6747, -1.0508],
        [-0.7249, -1.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019319484010338783
Epoch 0, Step 123: train/loss = 0.658443033695221, train/raw-loss = 0.6038122177124023, train/logprobs = tensor([[-1.1529, -1.6790],
        [-1.3443, -1.4742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018210280686616898
Epoch 0, Step 124: train/loss = 0.7202836871147156, train/raw-loss = 0.6806901693344116, train/logprobs = tensor([[-0.7507, -0.7922],
        [-0.7943, -0.7850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013197826221585274
Epoch 0, Step 125: train/loss = 0.727163553237915, train/raw-loss = 0.6748656034469604, train/logprobs = tensor([[-0.5880, -1.0604],
        [-0.5991, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01743263565003872
Epoch 0, Step 126: train/loss = 0.7063961029052734, train/raw-loss = 0.6522296667098999, train/logprobs = tensor([[-1.0696, -1.1474],
        [-1.2059, -1.1109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018055502325296402
Epoch 0, Step 127: train/loss = 0.6930883526802063, train/raw-loss = 0.6421159505844116, train/logprobs = tensor([[-0.8679, -1.1601],
        [-1.0133, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01699078641831875
Epoch 0, Step 128: train/loss = 0.8298628926277161, train/raw-loss = 0.6654194593429565, train/logprobs = tensor([[-0.8211, -1.2309],
        [-0.9067, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05481445789337158
Epoch 0, Step 129: train/loss = 0.9168367385864258, train/raw-loss = 0.6141809821128845, train/logprobs = tensor([[-0.8681, -1.4341],
        [-0.9688, -1.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10088526457548141
Epoch 0, Step 130: train/loss = 0.9737548828125, train/raw-loss = 0.654653787612915, train/logprobs = tensor([[-0.7682, -0.8360],
        [-0.8899, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10636705905199051
Epoch 0, Step 131: train/loss = 0.8632951378822327, train/raw-loss = 0.6204670071601868, train/logprobs = tensor([[-0.7661, -1.0919],
        [-1.1114, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08094267547130585
Epoch 0, Step 132: train/loss = 0.8703995943069458, train/raw-loss = 0.647559404373169, train/logprobs = tensor([[-0.9780, -1.2099],
        [-1.0517, -1.0940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428008317947388
Epoch 0, Step 133: train/loss = 0.8027362823486328, train/raw-loss = 0.5677016377449036, train/logprobs = tensor([[-0.9354, -2.4646],
        [-1.3048, -2.2752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834488153457642
Epoch 0, Step 134: train/loss = 0.7767354846000671, train/raw-loss = 0.6611186265945435, train/logprobs = tensor([[-0.8158, -1.0042],
        [-0.8881, -0.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038538962602615356
Epoch 0, Step 135: train/loss = 0.8070985078811646, train/raw-loss = 0.6212981343269348, train/logprobs = tensor([[-1.2971, -1.6980],
        [-1.6858, -1.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06193346530199051
Epoch 0, Step 136: train/loss = 0.865038275718689, train/raw-loss = 0.6523001194000244, train/logprobs = tensor([[-0.5553, -0.9592],
        [-0.5880, -0.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07091271132230759
Epoch 0, Step 137: train/loss = 0.8497775793075562, train/raw-loss = 0.6089973449707031, train/logprobs = tensor([[-1.0023, -1.2975],
        [-1.2949, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08026007562875748
Epoch 0, Step 138: train/loss = 0.9007962942123413, train/raw-loss = 0.6494868993759155, train/logprobs = tensor([[-0.7475, -0.8835],
        [-0.9472, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837697982788086
Epoch 0, Step 139: train/loss = 0.802653431892395, train/raw-loss = 0.6293597221374512, train/logprobs = tensor([[-0.7850, -0.9907],
        [-0.9471, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05776456743478775
Epoch 0, Step 140: train/loss = 0.9260921478271484, train/raw-loss = 0.6320223808288574, train/logprobs = tensor([[-0.9055, -1.9192],
        [-1.0728, -1.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09802325069904327
Epoch 0, Step 141: train/loss = 0.8394508361816406, train/raw-loss = 0.6890705823898315, train/logprobs = tensor([[-1.1628, -1.4620],
        [-1.1630, -1.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050126735121011734
Epoch 0, Step 142: train/loss = 0.9102359414100647, train/raw-loss = 0.6002649068832397, train/logprobs = tensor([[-1.0779, -1.1170],
        [-1.4361, -1.0671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10332368314266205
Epoch 0, Step 143: train/loss = 0.8776663541793823, train/raw-loss = 0.6047255992889404, train/logprobs = tensor([[-0.9530, -0.8514],
        [-1.3291, -0.8241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09098023921251297
Epoch 0, Step 144: train/loss = 0.8498529195785522, train/raw-loss = 0.650559663772583, train/logprobs = tensor([[-1.3450, -1.4471],
        [-1.4342, -1.3560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06643109023571014
Epoch 0, Step 145: train/loss = 0.8491653800010681, train/raw-loss = 0.577908992767334, train/logprobs = tensor([[-0.7667, -2.0165],
        [-1.1422, -1.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09041880816221237
Epoch 0, Step 146: train/loss = 0.8454399704933167, train/raw-loss = 0.6049060225486755, train/logprobs = tensor([[-0.8857, -0.8998],
        [-1.2828, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08017797023057938
Epoch 0, Step 147: train/loss = 0.8362657427787781, train/raw-loss = 0.6009118556976318, train/logprobs = tensor([[-0.8574, -1.7864],
        [-1.1227, -1.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07845128327608109
Epoch 0, Step 148: train/loss = 0.7506241798400879, train/raw-loss = 0.6312819719314575, train/logprobs = tensor([[-1.1932, -1.3399],
        [-1.4512, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03978073596954346
Epoch 0, Step 149: train/loss = 0.8702759146690369, train/raw-loss = 0.6281250715255737, train/logprobs = tensor([[-0.7531, -0.6748],
        [-0.9787, -0.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08071693032979965
Epoch 0, Step 150: train/loss = 0.8742331266403198, train/raw-loss = 0.5974426865577698, train/logprobs = tensor([[-0.7448, -1.4047],
        [-0.9723, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09226350486278534
Epoch 0, Step 151: train/loss = 0.7894852161407471, train/raw-loss = 0.5960297584533691, train/logprobs = tensor([[-0.8928, -1.5941],
        [-1.2416, -1.4664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06448515504598618
Epoch 0, Step 152: train/loss = 0.776129424571991, train/raw-loss = 0.6190481185913086, train/logprobs = tensor([[-1.1854, -1.1380],
        [-1.3536, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0523604154586792
Epoch 0, Step 153: train/loss = 0.8616086840629578, train/raw-loss = 0.6138952374458313, train/logprobs = tensor([[-1.1739, -1.6177],
        [-1.5871, -1.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08257114887237549
Epoch 0, Step 154: train/loss = 0.7800474762916565, train/raw-loss = 0.5989567041397095, train/logprobs = tensor([[-0.9846, -1.0907],
        [-1.2816, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060363590717315674
Epoch 0, Step 155: train/loss = 0.8274921774864197, train/raw-loss = 0.623216986656189, train/logprobs = tensor([[-1.0134, -1.3787],
        [-1.1408, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06809172034263611
Epoch 0, Step 156: train/loss = 0.9755685925483704, train/raw-loss = 0.6523261666297913, train/logprobs = tensor([[-0.5576, -1.1848],
        [-0.6149, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10774746537208557
Epoch 0, Step 157: train/loss = 0.9152088761329651, train/raw-loss = 0.6782823801040649, train/logprobs = tensor([[-0.7952, -1.0417],
        [-0.8730, -1.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07897549122571945
Epoch 0, Step 158: train/loss = 0.8600572347640991, train/raw-loss = 0.655904233455658, train/logprobs = tensor([[-1.3707, -1.0538],
        [-1.4327, -0.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06805099546909332
Epoch 0, Step 159: train/loss = 0.8509628772735596, train/raw-loss = 0.6384869813919067, train/logprobs = tensor([[-0.8486, -1.1055],
        [-1.0153, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07082528620958328
Epoch 0, Step 160: train/loss = 0.7877554893493652, train/raw-loss = 0.6684863567352295, train/logprobs = tensor([[-0.5684, -1.5786],
        [-0.6018, -1.5102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039756372570991516
Epoch 0, Step 161: train/loss = 0.7175934910774231, train/raw-loss = 0.6112887859344482, train/logprobs = tensor([[-1.2084, -1.2428],
        [-1.4140, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03543493151664734
Epoch 0, Step 162: train/loss = 0.7610124945640564, train/raw-loss = 0.6739013195037842, train/logprobs = tensor([[-0.6322, -1.0488],
        [-0.6337, -0.9717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029037058353424072
Epoch 0, Step 163: train/loss = 0.7434602379798889, train/raw-loss = 0.6202216148376465, train/logprobs = tensor([[-0.9464, -0.9469],
        [-1.2753, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04107951745390892
Epoch 0, Step 164: train/loss = 0.7860474586486816, train/raw-loss = 0.6898035407066345, train/logprobs = tensor([[-0.9581, -1.2055],
        [-0.9757, -1.2040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03208130598068237
Epoch 0, Step 165: train/loss = 0.805912435054779, train/raw-loss = 0.6593704223632812, train/logprobs = tensor([[-0.8447, -1.5011],
        [-0.9112, -1.4253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04884732514619827
Epoch 0, Step 166: train/loss = 0.7516869306564331, train/raw-loss = 0.6433572769165039, train/logprobs = tensor([[-0.9320, -1.4963],
        [-0.9738, -1.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03610987961292267
Epoch 0, Step 167: train/loss = 0.7588615417480469, train/raw-loss = 0.6028333902359009, train/logprobs = tensor([[-0.7168, -1.7401],
        [-0.8623, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05200939252972603
Epoch 0, Step 168: train/loss = 0.7009797096252441, train/raw-loss = 0.5782560110092163, train/logprobs = tensor([[-1.0322, -0.8188],
        [-1.4544, -0.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04090788587927818
Epoch 0, Step 169: train/loss = 0.7325817346572876, train/raw-loss = 0.5770052671432495, train/logprobs = tensor([[-0.9682, -0.8295],
        [-1.3441, -0.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051858823746442795
Epoch 0, Step 170: train/loss = 0.7821595072746277, train/raw-loss = 0.6686745882034302, train/logprobs = tensor([[-0.8893, -1.0352],
        [-0.9082, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03782832249999046
Epoch 0, Step 171: train/loss = 0.707994282245636, train/raw-loss = 0.5757861733436584, train/logprobs = tensor([[-0.7755, -1.0236],
        [-1.1650, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04406938701868057
Epoch 0, Step 172: train/loss = 0.7348389029502869, train/raw-loss = 0.6246217489242554, train/logprobs = tensor([[-0.8744, -1.0996],
        [-1.0568, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036739055067300797
Epoch 0, Step 173: train/loss = 0.667431116104126, train/raw-loss = 0.5406965613365173, train/logprobs = tensor([[-1.4537, -2.0027],
        [-1.8427, -1.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042244862765073776
Epoch 0, Step 174: train/loss = 0.745956540107727, train/raw-loss = 0.6434473991394043, train/logprobs = tensor([[-0.7661, -1.1226],
        [-0.8643, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034169696271419525
Epoch 0, Step 175: train/loss = 0.7065209746360779, train/raw-loss = 0.5767692923545837, train/logprobs = tensor([[-0.9752, -1.8787],
        [-1.3268, -1.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04325057193636894
Epoch 0, Step 176: train/loss = 0.7711743116378784, train/raw-loss = 0.6618574857711792, train/logprobs = tensor([[-0.8491, -2.1472],
        [-0.8909, -2.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036438923329114914
Epoch 0, Step 177: train/loss = 0.7795358896255493, train/raw-loss = 0.6636335849761963, train/logprobs = tensor([[-0.8154, -1.4892],
        [-0.8347, -1.3856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03863409906625748
Epoch 0, Step 178: train/loss = 0.7694783806800842, train/raw-loss = 0.6735754013061523, train/logprobs = tensor([[-1.1519, -1.5362],
        [-1.2884, -1.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0319676510989666
Epoch 0, Step 179: train/loss = 0.728447437286377, train/raw-loss = 0.5812675952911377, train/logprobs = tensor([[-1.2258, -2.3099],
        [-1.5772, -2.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049059972167015076
Epoch 0, Step 180: train/loss = 0.6935541033744812, train/raw-loss = 0.5920758247375488, train/logprobs = tensor([[-0.7267, -1.0625],
        [-1.0403, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03382611274719238
Epoch 0, Step 181: train/loss = 0.785591721534729, train/raw-loss = 0.6865384578704834, train/logprobs = tensor([[-1.0177, -1.2744],
        [-1.0061, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033017758280038834
Epoch 0, Step 182: train/loss = 0.7700986862182617, train/raw-loss = 0.6761181354522705, train/logprobs = tensor([[-2.0888, -2.2363],
        [-2.0998, -2.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03132684528827667
Epoch 0, Step 183: train/loss = 0.711997389793396, train/raw-loss = 0.616959810256958, train/logprobs = tensor([[-0.7014, -0.7236],
        [-0.9877, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031679198145866394
Epoch 0, Step 184: train/loss = 0.7330719232559204, train/raw-loss = 0.6370038986206055, train/logprobs = tensor([[-0.9345, -1.3794],
        [-1.1049, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03202270343899727
Epoch 0, Step 185: train/loss = 0.706246018409729, train/raw-loss = 0.6129143238067627, train/logprobs = tensor([[-0.9836, -1.2902],
        [-1.1762, -1.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031110581010580063
Epoch 0, Step 186: train/loss = 0.7899588346481323, train/raw-loss = 0.6817842125892639, train/logprobs = tensor([[-0.6253, -1.3343],
        [-0.6154, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03605823218822479
Epoch 0, Step 187: train/loss = 0.7987291216850281, train/raw-loss = 0.6357965469360352, train/logprobs = tensor([[-0.9168, -0.9402],
        [-1.0694, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05431085079908371
Epoch 0, Step 188: train/loss = 0.78087317943573, train/raw-loss = 0.6707068681716919, train/logprobs = tensor([[-1.0679, -1.0042],
        [-1.2085, -1.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036722101271152496
Epoch 0, Step 189: train/loss = 0.7905823588371277, train/raw-loss = 0.6749019622802734, train/logprobs = tensor([[-0.6762, -1.1290],
        [-0.6761, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03856012597680092
Epoch 0, Step 190: train/loss = 0.7783334255218506, train/raw-loss = 0.6101595163345337, train/logprobs = tensor([[-0.6577, -1.5086],
        [-0.8767, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05605793744325638
Epoch 0, Step 191: train/loss = 0.7026228308677673, train/raw-loss = 0.5823191404342651, train/logprobs = tensor([[-0.7941, -1.8304],
        [-1.0126, -1.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04010123014450073
Epoch 0, Step 192: train/loss = 0.7543144226074219, train/raw-loss = 0.625495195388794, train/logprobs = tensor([[-0.9769, -2.5955],
        [-1.0729, -2.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04293972626328468
Epoch 0, Step 193: train/loss = 0.7922416925430298, train/raw-loss = 0.6292010545730591, train/logprobs = tensor([[-0.7506, -1.3740],
        [-0.7528, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05434688180685043
Epoch 0, Step 194: train/loss = 0.7644537091255188, train/raw-loss = 0.6718013882637024, train/logprobs = tensor([[-0.8906, -0.9606],
        [-0.9326, -0.9138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030884120613336563
Epoch 0, Step 195: train/loss = 0.8161485195159912, train/raw-loss = 0.6716548800468445, train/logprobs = tensor([[-0.5715, -1.2415],
        [-0.5695, -1.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048164546489715576
Epoch 0, Step 196: train/loss = 0.7945332527160645, train/raw-loss = 0.6418434977531433, train/logprobs = tensor([[-0.6289, -1.0734],
        [-0.7030, -0.9119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05089658498764038
Epoch 0, Step 197: train/loss = 0.7716737389564514, train/raw-loss = 0.5862674713134766, train/logprobs = tensor([[-0.6383, -1.7931],
        [-0.8887, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06180206686258316
Epoch 0, Step 198: train/loss = 0.7771748304367065, train/raw-loss = 0.5329576134681702, train/logprobs = tensor([[-0.8659, -1.7014],
        [-1.2443, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140572905540466
Epoch 0, Step 199: train/loss = 0.7334356904029846, train/raw-loss = 0.5868805646896362, train/logprobs = tensor([[-0.9013, -1.3228],
        [-1.2802, -1.2005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048851706087589264
Epoch 0, Step 200: train/loss = 0.7221220135688782, train/raw-loss = 0.568335771560669, train/logprobs = tensor([[-0.7814, -0.9920],
        [-1.1681, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05126208811998367
Epoch 0, Step 201: train/loss = 0.7067233324050903, train/raw-loss = 0.5382976531982422, train/logprobs = tensor([[-0.7968, -2.6024],
        [-0.8968, -1.7577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05614187940955162
Epoch 0, Step 202: train/loss = 0.7701081037521362, train/raw-loss = 0.6613965630531311, train/logprobs = tensor([[-0.5329, -0.6801],
        [-0.5839, -0.5948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0362372025847435
Epoch 0, Step 203: train/loss = 0.759865403175354, train/raw-loss = 0.5740629434585571, train/logprobs = tensor([[-1.0240, -1.5320],
        [-1.3751, -1.3370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061934150755405426
Epoch 0, Step 204: train/loss = 0.7038294076919556, train/raw-loss = 0.5301880836486816, train/logprobs = tensor([[-1.0110, -1.3930],
        [-1.6274, -1.2483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05788043141365051
Epoch 0, Step 205: train/loss = 0.802240252494812, train/raw-loss = 0.6606944799423218, train/logprobs = tensor([[-0.7848, -1.1103],
        [-0.7584, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047181908041238785
Epoch 0, Step 206: train/loss = 0.7937606573104858, train/raw-loss = 0.6646143198013306, train/logprobs = tensor([[-0.8013, -1.1151],
        [-0.7912, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043048787862062454
Epoch 0, Step 207: train/loss = 0.702799916267395, train/raw-loss = 0.533108115196228, train/logprobs = tensor([[-0.8256, -2.6247],
        [-0.9843, -1.9888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05656393617391586
Epoch 0, Step 208: train/loss = 0.7683477401733398, train/raw-loss = 0.5676133632659912, train/logprobs = tensor([[-0.8446, -1.3595],
        [-1.2356, -1.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06691145896911621
Epoch 0, Step 209: train/loss = 0.7885719537734985, train/raw-loss = 0.5946140885353088, train/logprobs = tensor([[-0.8676, -1.3612],
        [-1.1375, -1.1970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06465265154838562
Epoch 0, Step 210: train/loss = 0.7703224420547485, train/raw-loss = 0.5768824815750122, train/logprobs = tensor([[-1.0177, -1.8170],
        [-1.2355, -1.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06447996199131012
Epoch 0, Step 211: train/loss = 0.7325164079666138, train/raw-loss = 0.5604771375656128, train/logprobs = tensor([[-0.9787, -2.6288],
        [-1.2045, -2.2563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05734643712639809
Epoch 0, Step 212: train/loss = 0.8886611461639404, train/raw-loss = 0.6753901243209839, train/logprobs = tensor([[-0.6769, -1.2304],
        [-0.8702, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109033316373825
Epoch 0, Step 213: train/loss = 0.8051672577857971, train/raw-loss = 0.5895217061042786, train/logprobs = tensor([[-0.8484, -2.0903],
        [-1.1803, -1.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07188184559345245
Epoch 0, Step 214: train/loss = 0.8035497665405273, train/raw-loss = 0.6421308517456055, train/logprobs = tensor([[-0.8718, -2.2719],
        [-0.9139, -2.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05380631238222122
Epoch 0, Step 215: train/loss = 0.7870291471481323, train/raw-loss = 0.6390801668167114, train/logprobs = tensor([[-0.8667, -1.1652],
        [-0.9992, -1.0671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04931631684303284
Epoch 0, Step 216: train/loss = 0.750931978225708, train/raw-loss = 0.5744820237159729, train/logprobs = tensor([[-0.7445, -1.5883],
        [-0.8397, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05881665274500847
Epoch 0, Step 217: train/loss = 0.7583975791931152, train/raw-loss = 0.6285439133644104, train/logprobs = tensor([[-0.7300, -1.3477],
        [-0.8083, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04328453913331032
Epoch 0, Step 218: train/loss = 0.7557142376899719, train/raw-loss = 0.6113694906234741, train/logprobs = tensor([[-0.9646, -0.8771],
        [-1.2325, -0.7782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04811492934823036
Epoch 0, Step 219: train/loss = 0.737066924571991, train/raw-loss = 0.6235142350196838, train/logprobs = tensor([[-1.1454, -1.4052],
        [-1.4452, -1.3888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03785088658332825
Epoch 0, Step 220: train/loss = 0.8480103015899658, train/raw-loss = 0.6651813983917236, train/logprobs = tensor([[-0.9346, -1.4063],
        [-0.9886, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06094294786453247
Epoch 0, Step 221: train/loss = 0.8100147247314453, train/raw-loss = 0.6242542266845703, train/logprobs = tensor([[-0.6317, -0.6620],
        [-0.9163, -0.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0619201622903347
Epoch 0, Step 222: train/loss = 0.7539072036743164, train/raw-loss = 0.5961726307868958, train/logprobs = tensor([[-1.5036, -1.6139],
        [-1.9129, -1.5542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05257820338010788
Epoch 0, Step 223: train/loss = 0.7566561698913574, train/raw-loss = 0.5533679127693176, train/logprobs = tensor([[-0.8798, -2.4639],
        [-1.1762, -2.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776273250579834
Epoch 0, Step 224: train/loss = 0.7390977144241333, train/raw-loss = 0.5240697264671326, train/logprobs = tensor([[-0.8297, -1.9273],
        [-1.2087, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07167600095272064
Epoch 0, Step 225: train/loss = 0.8257714509963989, train/raw-loss = 0.628976583480835, train/logprobs = tensor([[-0.6114, -1.6414],
        [-0.6261, -1.3750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06559827923774719
Epoch 0, Step 226: train/loss = 0.7896265983581543, train/raw-loss = 0.6279119253158569, train/logprobs = tensor([[-0.6819, -1.0383],
        [-0.6781, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05390489846467972
Epoch 0, Step 227: train/loss = 0.694572925567627, train/raw-loss = 0.47157227993011475, train/logprobs = tensor([[-1.2808, -2.1465],
        [-1.9261, -1.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.074333555996418
Epoch 0, Step 228: train/loss = 0.7580713033676147, train/raw-loss = 0.5978524088859558, train/logprobs = tensor([[-0.9012, -1.3890],
        [-1.0085, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053406283259391785
Epoch 0, Step 229: train/loss = 0.7653592228889465, train/raw-loss = 0.5705116391181946, train/logprobs = tensor([[-0.8918, -1.4278],
        [-1.1936, -1.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06494919955730438
Epoch 0, Step 230: train/loss = 0.7978692054748535, train/raw-loss = 0.6166706681251526, train/logprobs = tensor([[-0.7569, -1.3194],
        [-0.8128, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06039949879050255
Epoch 0, Step 231: train/loss = 0.8350422978401184, train/raw-loss = 0.6597040891647339, train/logprobs = tensor([[-0.7554, -0.9882],
        [-0.7207, -0.8135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05844605714082718
Epoch 0, Step 232: train/loss = 0.7708711624145508, train/raw-loss = 0.5656618475914001, train/logprobs = tensor([[-0.7206, -1.5528],
        [-0.9302, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06840309500694275
Epoch 0, Step 233: train/loss = 0.7368722558021545, train/raw-loss = 0.570049524307251, train/logprobs = tensor([[-0.8421, -1.2852],
        [-1.2722, -1.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055607594549655914
Epoch 0, Step 234: train/loss = 0.753864049911499, train/raw-loss = 0.5778693556785583, train/logprobs = tensor([[-0.6970, -1.2117],
        [-0.9956, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05866491049528122
Epoch 0, Step 235: train/loss = 0.8674264550209045, train/raw-loss = 0.632274329662323, train/logprobs = tensor([[-0.8431, -0.7997],
        [-0.9634, -0.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07838404178619385
Epoch 0, Step 236: train/loss = 0.8354518413543701, train/raw-loss = 0.6032981276512146, train/logprobs = tensor([[-0.6575, -1.3625],
        [-0.6501, -0.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773845687508583
Epoch 0, Step 237: train/loss = 0.7654044032096863, train/raw-loss = 0.5605801343917847, train/logprobs = tensor([[-0.6862, -1.7333],
        [-1.0149, -1.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06827478110790253
Epoch 0, Step 238: train/loss = 0.7837678790092468, train/raw-loss = 0.5728216767311096, train/logprobs = tensor([[-0.7237, -2.0809],
        [-0.9175, -1.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0703153982758522
Epoch 0, Step 239: train/loss = 0.748062789440155, train/raw-loss = 0.6137405633926392, train/logprobs = tensor([[-0.8703, -0.9880],
        [-1.0604, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04477407783269882
Epoch 0, Step 240: train/loss = 0.8018396496772766, train/raw-loss = 0.5853378772735596, train/logprobs = tensor([[-0.7456, -1.7630],
        [-0.7272, -1.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07216724753379822
Epoch 0, Step 241: train/loss = 0.7278279066085815, train/raw-loss = 0.5711540579795837, train/logprobs = tensor([[-0.7438, -1.4193],
        [-0.9840, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05222465842962265
Epoch 0, Step 242: train/loss = 0.7931473255157471, train/raw-loss = 0.5485210418701172, train/logprobs = tensor([[-0.7041, -2.1449],
        [-0.6920, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08154211193323135
Epoch 0, Step 243: train/loss = 0.7299523949623108, train/raw-loss = 0.5615717768669128, train/logprobs = tensor([[-0.7643, -1.4482],
        [-0.9816, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056126855313777924
Epoch 0, Step 244: train/loss = 0.7890391945838928, train/raw-loss = 0.5769399404525757, train/logprobs = tensor([[-0.8332, -2.0781],
        [-0.8746, -1.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07069974392652512
Epoch 0, Step 245: train/loss = 0.7817345857620239, train/raw-loss = 0.6005498170852661, train/logprobs = tensor([[-0.8227, -1.1000],
        [-0.9504, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06039492040872574
Epoch 0, Step 246: train/loss = 0.7556278705596924, train/raw-loss = 0.6192375421524048, train/logprobs = tensor([[-0.9475, -1.4830],
        [-0.9172, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0454634428024292
Epoch 0, Step 247: train/loss = 0.7974891662597656, train/raw-loss = 0.5870015621185303, train/logprobs = tensor([[-0.8231, -1.1697],
        [-1.0139, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07016254216432571
Epoch 0, Step 248: train/loss = 0.7076398730278015, train/raw-loss = 0.5341761112213135, train/logprobs = tensor([[-0.8125, -1.6339],
        [-1.1222, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05782124772667885
Epoch 0, Step 249: train/loss = 0.7969045639038086, train/raw-loss = 0.6202837824821472, train/logprobs = tensor([[-0.7938, -1.6123],
        [-0.8276, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058873578906059265
Epoch 0, Step 250: train/loss = 0.7647565603256226, train/raw-loss = 0.6289035081863403, train/logprobs = tensor([[-0.7776, -1.1070],
        [-0.8776, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04528435319662094
Epoch 0, Step 251: train/loss = 0.7331004738807678, train/raw-loss = 0.5089160203933716, train/logprobs = tensor([[-0.9198, -1.1989],
        [-1.4875, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07472815364599228
Epoch 0, Step 252: train/loss = 0.7664533853530884, train/raw-loss = 0.6070094704627991, train/logprobs = tensor([[-1.0482, -1.7432],
        [-1.1274, -1.4439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05314795672893524
Epoch 0, Step 253: train/loss = 0.7107767462730408, train/raw-loss = 0.4738072156906128, train/logprobs = tensor([[-0.9963, -2.6364],
        [-1.5586, -2.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07898984849452972
Epoch 0, Step 254: train/loss = 0.7634660005569458, train/raw-loss = 0.5918521881103516, train/logprobs = tensor([[-0.8634, -1.4031],
        [-1.0443, -1.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057204604148864746
Epoch 0, Step 255: train/loss = 0.7935668230056763, train/raw-loss = 0.6636383533477783, train/logprobs = tensor([[-1.0903, -1.2705],
        [-1.0924, -1.1476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04330947622656822
Epoch 0, Step 256: train/loss = 0.7421057224273682, train/raw-loss = 0.596764087677002, train/logprobs = tensor([[-0.8749, -1.1609],
        [-1.0733, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04844721406698227
Epoch 0, Step 257: train/loss = 0.7679721117019653, train/raw-loss = 0.5653146505355835, train/logprobs = tensor([[-0.7694, -1.1890],
        [-0.9959, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06755249202251434
Epoch 0, Step 258: train/loss = 0.7451592683792114, train/raw-loss = 0.5740290880203247, train/logprobs = tensor([[-0.9150, -1.2871],
        [-1.2784, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057043373584747314
Epoch 0, Step 259: train/loss = 0.8247974514961243, train/raw-loss = 0.6332509517669678, train/logprobs = tensor([[-1.1303, -0.8158],
        [-1.3328, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0638488233089447
Epoch 0, Step 260: train/loss = 0.6885500550270081, train/raw-loss = 0.515140950679779, train/logprobs = tensor([[-0.9779, -1.3864],
        [-1.5090, -1.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05780302733182907
Epoch 0, Step 261: train/loss = 0.6714617013931274, train/raw-loss = 0.5093321204185486, train/logprobs = tensor([[-0.7897, -1.3963],
        [-1.1935, -0.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05404318496584892
Epoch 0, Step 262: train/loss = 0.6805791854858398, train/raw-loss = 0.49353867769241333, train/logprobs = tensor([[-0.8851, -1.4346],
        [-1.4438, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06234682351350784
Epoch 0, Step 263: train/loss = 0.7047494649887085, train/raw-loss = 0.4943927526473999, train/logprobs = tensor([[-1.3357, -1.2367],
        [-2.0778, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07011892646551132
Epoch 0, Step 264: train/loss = 0.7041610479354858, train/raw-loss = 0.5169122219085693, train/logprobs = tensor([[-1.0876, -2.2906],
        [-1.4488, -1.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062416281551122665
Epoch 0, Step 265: train/loss = 0.6790595650672913, train/raw-loss = 0.45369821786880493, train/logprobs = tensor([[-0.9400, -2.3582],
        [-1.5303, -1.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07512044906616211
Epoch 0, Step 266: train/loss = 0.771940290927887, train/raw-loss = 0.628092885017395, train/logprobs = tensor([[-1.2700, -1.5044],
        [-1.3474, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04794914275407791
Epoch 0, Step 267: train/loss = 0.736592173576355, train/raw-loss = 0.5424744486808777, train/logprobs = tensor([[-0.8394, -1.1290],
        [-1.3001, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06470590829849243
Epoch 0, Step 268: train/loss = 0.7453186511993408, train/raw-loss = 0.6372455954551697, train/logprobs = tensor([[-0.9150, -1.6657],
        [-0.8436, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03602437302470207
Epoch 0, Step 269: train/loss = 0.7764605283737183, train/raw-loss = 0.6437207460403442, train/logprobs = tensor([[-0.6337, -1.0081],
        [-0.6303, -0.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0442466102540493
Epoch 0, Step 270: train/loss = 0.7493997812271118, train/raw-loss = 0.6086726188659668, train/logprobs = tensor([[-0.5439, -1.1715],
        [-0.5151, -0.7567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046909041702747345
Epoch 0, Step 271: train/loss = 0.7193800210952759, train/raw-loss = 0.5992891788482666, train/logprobs = tensor([[-0.7789, -1.4403],
        [-0.7853, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040030285716056824
Epoch 0, Step 272: train/loss = 0.6777290105819702, train/raw-loss = 0.5573887825012207, train/logprobs = tensor([[-0.7199, -1.6003],
        [-1.0240, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04011339694261551
Epoch 0, Step 273: train/loss = 0.6997613906860352, train/raw-loss = 0.5419711470603943, train/logprobs = tensor([[-0.8466, -1.0310],
        [-1.3048, -0.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05259674787521362
Epoch 0, Step 274: train/loss = 0.7694065570831299, train/raw-loss = 0.6406271457672119, train/logprobs = tensor([[-1.0907, -0.9773],
        [-1.3717, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04292646795511246
Epoch 0, Step 275: train/loss = 0.6987391114234924, train/raw-loss = 0.5454246997833252, train/logprobs = tensor([[-0.7812, -1.6458],
        [-1.0668, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05110480263829231
Epoch 0, Step 276: train/loss = 0.7528381943702698, train/raw-loss = 0.5780854225158691, train/logprobs = tensor([[-0.9268, -1.2887],
        [-1.2078, -1.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058250926434993744
Epoch 0, Step 277: train/loss = 0.6813260316848755, train/raw-loss = 0.5330878496170044, train/logprobs = tensor([[-1.0568, -1.4477],
        [-1.4207, -1.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04941271245479584
Epoch 0, Step 278: train/loss = 0.7919095754623413, train/raw-loss = 0.6364173293113708, train/logprobs = tensor([[-0.8396, -1.0717],
        [-0.9700, -0.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05183074250817299
Epoch 0, Step 279: train/loss = 0.7565158605575562, train/raw-loss = 0.5996373891830444, train/logprobs = tensor([[-0.9224, -1.7443],
        [-1.1161, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05229281634092331
Epoch 0, Step 280: train/loss = 0.781622052192688, train/raw-loss = 0.6120656728744507, train/logprobs = tensor([[-0.9520, -1.1637],
        [-0.9610, -0.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056518763303756714
Epoch 0, Step 281: train/loss = 0.7402609586715698, train/raw-loss = 0.6031121611595154, train/logprobs = tensor([[-0.7946, -0.7567],
        [-1.0679, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04571625962853432
Epoch 0, Step 282: train/loss = 0.7524545788764954, train/raw-loss = 0.596186637878418, train/logprobs = tensor([[-1.1927, -1.8358],
        [-1.4596, -1.6453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05208931118249893
Epoch 0, Step 283: train/loss = 0.7535099387168884, train/raw-loss = 0.610892653465271, train/logprobs = tensor([[-0.7417, -1.1539],
        [-0.8728, -0.9134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04753909260034561
Epoch 0, Step 284: train/loss = 0.7509809732437134, train/raw-loss = 0.583505392074585, train/logprobs = tensor([[-1.0958, -1.3022],
        [-1.1741, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05582520365715027
Epoch 0, Step 285: train/loss = 0.7582232356071472, train/raw-loss = 0.590406060218811, train/logprobs = tensor([[-1.1042, -1.1593],
        [-1.4075, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05593903735280037
Epoch 0, Step 286: train/loss = 0.6664214134216309, train/raw-loss = 0.5315701365470886, train/logprobs = tensor([[-1.0516, -2.0946],
        [-1.2777, -1.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04495043680071831
Epoch 0, Step 287: train/loss = 0.7394288778305054, train/raw-loss = 0.5965069532394409, train/logprobs = tensor([[-1.5900, -2.4978],
        [-1.4661, -1.9182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04764064401388168
Epoch 0, Step 288: train/loss = 0.7668685913085938, train/raw-loss = 0.5770635604858398, train/logprobs = tensor([[-0.8346, -1.1152],
        [-1.0722, -0.8048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06326834112405777
Epoch 0, Step 289: train/loss = 0.7138975858688354, train/raw-loss = 0.5435935854911804, train/logprobs = tensor([[-0.8408, -1.3589],
        [-1.2160, -1.0022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05676800757646561
Epoch 0, Step 290: train/loss = 0.7264389991760254, train/raw-loss = 0.6118619441986084, train/logprobs = tensor([[-0.9141, -1.0830],
        [-1.0245, -0.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03819235414266586
Epoch 0, Step 291: train/loss = 0.7083680629730225, train/raw-loss = 0.586837887763977, train/logprobs = tensor([[-1.0873, -1.4492],
        [-1.2092, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04051006957888603
Epoch 0, Step 292: train/loss = 0.7406620979309082, train/raw-loss = 0.6077778339385986, train/logprobs = tensor([[-0.6572, -0.8839],
        [-0.8167, -0.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04429475963115692
Epoch 0, Step 293: train/loss = 0.7222610712051392, train/raw-loss = 0.5808203816413879, train/logprobs = tensor([[-0.8114, -1.8222],
        [-0.9217, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04714691638946533
Epoch 0, Step 294: train/loss = 0.8005401492118835, train/raw-loss = 0.6432332992553711, train/logprobs = tensor([[-0.7142, -0.8202],
        [-0.8555, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05243562161922455
Epoch 0, Step 295: train/loss = 0.7048898935317993, train/raw-loss = 0.5574257373809814, train/logprobs = tensor([[-1.0328, -1.9284],
        [-1.4487, -1.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049154721200466156
Epoch 0, Step 296: train/loss = 0.7141014337539673, train/raw-loss = 0.559617817401886, train/logprobs = tensor([[-1.1105, -1.2397],
        [-1.4943, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0514945350587368
Epoch 0, Step 297: train/loss = 0.710527777671814, train/raw-loss = 0.5430013537406921, train/logprobs = tensor([[-0.8078, -1.5955],
        [-0.9918, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05584214627742767
Epoch 0, Step 298: train/loss = 0.704501211643219, train/raw-loss = 0.5653645396232605, train/logprobs = tensor([[-0.9521, -1.1635],
        [-1.2543, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04637889564037323
Epoch 0, Step 299: train/loss = 0.7429660558700562, train/raw-loss = 0.5950882434844971, train/logprobs = tensor([[-1.0842, -1.1548],
        [-1.4744, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049292586743831635
Epoch 0, Step 300: train/loss = 0.68891441822052, train/raw-loss = 0.4827844798564911, train/logprobs = tensor([[-1.1923, -1.8173],
        [-1.7304, -1.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06870998442173004
Epoch 0, Step 301: train/loss = 0.6985964179039001, train/raw-loss = 0.5384067893028259, train/logprobs = tensor([[-0.8224, -1.4818],
        [-1.0300, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0533965528011322
Epoch 0, Step 302: train/loss = 0.7149451971054077, train/raw-loss = 0.5526119470596313, train/logprobs = tensor([[-1.5071, -1.8164],
        [-1.7861, -1.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054111070930957794
Epoch 0, Step 303: train/loss = 0.7530431747436523, train/raw-loss = 0.5924893021583557, train/logprobs = tensor([[-0.6077, -0.8910],
        [-0.8021, -0.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05351797491312027
Epoch 0, Step 304: train/loss = 0.7358898520469666, train/raw-loss = 0.5626742839813232, train/logprobs = tensor([[-0.9124, -1.3071],
        [-1.1619, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0577385388314724
Epoch 0, Step 305: train/loss = 0.7503243684768677, train/raw-loss = 0.6139101386070251, train/logprobs = tensor([[-1.1257, -3.0082],
        [-1.1183, -2.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04547140374779701
Epoch 0, Step 306: train/loss = 0.7527530193328857, train/raw-loss = 0.6791041493415833, train/logprobs = tensor([[-0.4436, -0.6192],
        [-0.4346, -0.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024549610912799835
Epoch 0, Step 307: train/loss = 0.6888353824615479, train/raw-loss = 0.5344288349151611, train/logprobs = tensor([[-0.9644, -1.2258],
        [-1.4071, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05146884173154831
Epoch 0, Step 308: train/loss = 0.7467678785324097, train/raw-loss = 0.6035200357437134, train/logprobs = tensor([[-0.7282, -1.5793],
        [-0.9016, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04774928465485573
Epoch 0, Step 309: train/loss = 0.7797229290008545, train/raw-loss = 0.6427002549171448, train/logprobs = tensor([[-0.7302, -1.2071],
        [-0.6920, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04567423462867737
Epoch 0, Step 310: train/loss = 0.6578422784805298, train/raw-loss = 0.5292302370071411, train/logprobs = tensor([[-1.1970, -3.8877],
        [-1.1303, -2.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0428706631064415
Epoch 0, Step 311: train/loss = 0.7091875672340393, train/raw-loss = 0.5683466792106628, train/logprobs = tensor([[-1.4871, -1.7464],
        [-1.7152, -1.3882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04694695025682449
Epoch 0, Step 312: train/loss = 0.7278597950935364, train/raw-loss = 0.5176193714141846, train/logprobs = tensor([[-1.0486, -1.0244],
        [-1.5829, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07008013874292374
Epoch 0, Step 313: train/loss = 0.7126564979553223, train/raw-loss = 0.5686933398246765, train/logprobs = tensor([[-0.9007, -1.5744],
        [-0.9185, -1.0200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04798770695924759
Epoch 0, Step 314: train/loss = 0.7710573673248291, train/raw-loss = 0.6403781771659851, train/logprobs = tensor([[-0.8861, -1.0256],
        [-1.0142, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04355974122881889
Epoch 0, Step 315: train/loss = 0.6784627437591553, train/raw-loss = 0.5280447006225586, train/logprobs = tensor([[-0.9638, -1.9107],
        [-1.1136, -1.2689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050139348953962326
Epoch 0, Step 316: train/loss = 0.7551535367965698, train/raw-loss = 0.5964745283126831, train/logprobs = tensor([[-0.8297, -1.3117],
        [-1.0188, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052893009036779404
Epoch 0, Step 317: train/loss = 0.6973610520362854, train/raw-loss = 0.5653397440910339, train/logprobs = tensor([[-1.1213, -1.9776],
        [-1.3391, -1.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044007085263729095
Epoch 0, Step 318: train/loss = 0.7239874601364136, train/raw-loss = 0.5922765731811523, train/logprobs = tensor([[-0.5026, -1.2129],
        [-0.5759, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04390362277626991
Epoch 0, Step 319: train/loss = 0.716493546962738, train/raw-loss = 0.5284062027931213, train/logprobs = tensor([[-1.0279, -1.3316],
        [-1.4127, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06269576400518417
Epoch 0, Step 320: train/loss = 0.7311893701553345, train/raw-loss = 0.6093351244926453, train/logprobs = tensor([[-1.1869, -1.2860],
        [-1.3311, -1.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040618106722831726
Epoch 0, Step 321: train/loss = 0.7034538984298706, train/raw-loss = 0.5867971181869507, train/logprobs = tensor([[-1.6405, -2.0131],
        [-1.9403, -1.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038885585963726044
Epoch 0, Step 322: train/loss = 0.7876782417297363, train/raw-loss = 0.6076164841651917, train/logprobs = tensor([[-0.8556, -1.0841],
        [-1.2691, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06002059578895569
Epoch 0, Step 323: train/loss = 0.7022491097450256, train/raw-loss = 0.5710911750793457, train/logprobs = tensor([[-1.1106, -1.0156],
        [-1.4852, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0437193363904953
Epoch 0, Step 324: train/loss = 0.6648385524749756, train/raw-loss = 0.5190167427062988, train/logprobs = tensor([[-0.9746, -1.5998],
        [-1.2397, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048607274889945984
Epoch 0, Step 325: train/loss = 0.6326858997344971, train/raw-loss = 0.46868279576301575, train/logprobs = tensor([[-1.1099, -1.6285],
        [-1.6712, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05466768890619278
Epoch 0, Step 326: train/loss = 0.764563262462616, train/raw-loss = 0.6109315156936646, train/logprobs = tensor([[-1.1071, -1.0263],
        [-1.3300, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05121057853102684
Epoch 0, Step 327: train/loss = 0.7148184776306152, train/raw-loss = 0.5486393570899963, train/logprobs = tensor([[-0.8099, -3.6668],
        [-0.8398, -3.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0553930327296257
Epoch 0, Step 328: train/loss = 0.7273021340370178, train/raw-loss = 0.5881980061531067, train/logprobs = tensor([[-0.6830, -1.3824],
        [-0.6782, -0.8710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046368058770895004
Epoch 0, Step 329: train/loss = 0.7099395394325256, train/raw-loss = 0.5420737266540527, train/logprobs = tensor([[-1.2179, -1.8264],
        [-1.7765, -1.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055955249816179276
Epoch 0, Step 330: train/loss = 0.7472342252731323, train/raw-loss = 0.6117633581161499, train/logprobs = tensor([[-1.0844, -0.8937],
        [-1.2876, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045156966894865036
Epoch 0, Step 331: train/loss = 0.7207712531089783, train/raw-loss = 0.5796945095062256, train/logprobs = tensor([[-0.7287, -1.2717],
        [-0.9364, -0.9634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047025591135025024
Epoch 0, Step 332: train/loss = 0.741965651512146, train/raw-loss = 0.5831775665283203, train/logprobs = tensor([[-1.0695, -1.2630],
        [-1.5423, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0529293566942215
Epoch 0, Step 333: train/loss = 0.6888167262077332, train/raw-loss = 0.5418016910552979, train/logprobs = tensor([[-0.9797, -1.8067],
        [-1.3402, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04900503158569336
Epoch 0, Step 334: train/loss = 0.6926870942115784, train/raw-loss = 0.5583425760269165, train/logprobs = tensor([[-0.7739, -1.8856],
        [-0.8511, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04478148743510246
Epoch 0, Step 335: train/loss = 0.6928212642669678, train/raw-loss = 0.5701432228088379, train/logprobs = tensor([[-0.8311, -1.6880],
        [-0.8011, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04089269042015076
Epoch 0, Step 336: train/loss = 0.7038000822067261, train/raw-loss = 0.5430126786231995, train/logprobs = tensor([[-1.0806, -1.5577],
        [-1.4894, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053595781326293945
Epoch 0, Step 337: train/loss = 0.7093510627746582, train/raw-loss = 0.5711067914962769, train/logprobs = tensor([[-0.8991, -1.1513],
        [-1.1931, -0.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04608142375946045
Epoch 0, Step 338: train/loss = 0.6832982897758484, train/raw-loss = 0.5363548994064331, train/logprobs = tensor([[-1.2182, -1.8933],
        [-1.4882, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04898113012313843
Epoch 0, Step 339: train/loss = 0.6680803298950195, train/raw-loss = 0.5248786211013794, train/logprobs = tensor([[-1.0161, -1.6637],
        [-1.3997, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04773388430476189
Epoch 0, Step 340: train/loss = 0.7132556438446045, train/raw-loss = 0.5597752928733826, train/logprobs = tensor([[-0.8300, -1.3958],
        [-1.0187, -0.9729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05116009712219238
Epoch 0, Step 341: train/loss = 0.679399847984314, train/raw-loss = 0.499163955450058, train/logprobs = tensor([[-1.3289, -1.6035],
        [-2.0261, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06007862836122513
Epoch 0, Step 342: train/loss = 0.6856087446212769, train/raw-loss = 0.5175682306289673, train/logprobs = tensor([[-1.1815, -1.5305],
        [-1.7099, -1.2073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05601351708173752
Epoch 0, Step 343: train/loss = 0.7572745084762573, train/raw-loss = 0.6531201601028442, train/logprobs = tensor([[-0.6653, -1.1604],
        [-0.6734, -0.9911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034718096256256104
Epoch 0, Step 344: train/loss = 0.6581190824508667, train/raw-loss = 0.5187132358551025, train/logprobs = tensor([[-1.0489, -1.6650],
        [-1.3361, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04646860063076019
Epoch 0, Step 345: train/loss = 0.7052677869796753, train/raw-loss = 0.5859398245811462, train/logprobs = tensor([[-0.6866, -1.2817],
        [-0.6883, -0.7986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03977598622441292
Epoch 0, Step 346: train/loss = 0.692729115486145, train/raw-loss = 0.5719190239906311, train/logprobs = tensor([[-0.9568, -2.2999],
        [-1.0065, -1.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04027002304792404
Epoch 0, Step 347: train/loss = 0.7043378353118896, train/raw-loss = 0.5467243194580078, train/logprobs = tensor([[-0.9399, -2.0156],
        [-1.2430, -1.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052537862211465836
Epoch 0, Step 348: train/loss = 0.6143144369125366, train/raw-loss = 0.43808436393737793, train/logprobs = tensor([[-0.7505, -2.3261],
        [-1.0580, -1.1882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058743350207805634
Epoch 0, Step 349: train/loss = 0.7458961009979248, train/raw-loss = 0.637244462966919, train/logprobs = tensor([[-0.7412, -0.7054],
        [-0.9189, -0.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03621722012758255
Epoch 0, Step 350: train/loss = 0.7268495559692383, train/raw-loss = 0.5927642583847046, train/logprobs = tensor([[-0.8964, -1.7659],
        [-1.1153, -1.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044695086777210236
Epoch 0, Step 351: train/loss = 0.7446242570877075, train/raw-loss = 0.5825364589691162, train/logprobs = tensor([[-1.1749, -0.8897],
        [-1.4258, -0.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05402925983071327
Epoch 0, Step 352: train/loss = 0.6525834202766418, train/raw-loss = 0.4699699282646179, train/logprobs = tensor([[-0.9570, -1.9535],
        [-1.5269, -1.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0608711875975132
Epoch 0, Step 353: train/loss = 0.6301496624946594, train/raw-loss = 0.4922140836715698, train/logprobs = tensor([[-1.0046, -1.6268],
        [-1.3999, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045978523790836334
Epoch 0, Step 354: train/loss = 0.6657645106315613, train/raw-loss = 0.5207895636558533, train/logprobs = tensor([[-1.1197, -1.7794],
        [-1.4060, -1.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048324957489967346
Epoch 0, Step 355: train/loss = 0.7427941560745239, train/raw-loss = 0.6065071225166321, train/logprobs = tensor([[-0.9630, -1.6625],
        [-1.1913, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045429032295942307
Epoch 0, Step 356: train/loss = 0.705824077129364, train/raw-loss = 0.5591058731079102, train/logprobs = tensor([[-0.8813, -1.3913],
        [-1.1048, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04890606552362442
Epoch 0, Step 357: train/loss = 0.7645343542098999, train/raw-loss = 0.6499993801116943, train/logprobs = tensor([[-0.5059, -1.0220],
        [-0.4895, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03817833587527275
Epoch 0, Step 358: train/loss = 0.6685233116149902, train/raw-loss = 0.5268006920814514, train/logprobs = tensor([[-0.7018, -1.7452],
        [-0.8821, -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04724087938666344
Epoch 0, Step 359: train/loss = 0.6986042261123657, train/raw-loss = 0.578390896320343, train/logprobs = tensor([[-0.8081, -1.7680],
        [-1.0864, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04007112979888916
Epoch 0, Step 360: train/loss = 0.6808174848556519, train/raw-loss = 0.5791023373603821, train/logprobs = tensor([[-0.8110, -1.4950],
        [-0.8075, -0.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03390505537390709
Epoch 0, Step 361: train/loss = 0.6842525601387024, train/raw-loss = 0.5302279591560364, train/logprobs = tensor([[-0.7564, -1.6181],
        [-0.9794, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051341548562049866
Epoch 0, Step 362: train/loss = 0.7298232316970825, train/raw-loss = 0.5809471607208252, train/logprobs = tensor([[-0.7694, -1.4130],
        [-0.9902, -1.0949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049625348299741745
Epoch 0, Step 363: train/loss = 0.6292319297790527, train/raw-loss = 0.4583985507488251, train/logprobs = tensor([[-1.2556, -1.4728],
        [-1.8549, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05694445222616196
Epoch 0, Step 364: train/loss = 0.6508229374885559, train/raw-loss = 0.5266947746276855, train/logprobs = tensor([[-0.7104, -1.7951],
        [-1.0000, -1.1888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04137603938579559
Epoch 0, Step 365: train/loss = 0.6636909246444702, train/raw-loss = 0.5102294683456421, train/logprobs = tensor([[-0.9278, -1.3617],
        [-1.3983, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05115383863449097
Epoch 0, Step 366: train/loss = 0.6652103662490845, train/raw-loss = 0.5045801401138306, train/logprobs = tensor([[-1.2713, -1.2007],
        [-1.7158, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053543414920568466
Epoch 0, Step 367: train/loss = 0.6395115256309509, train/raw-loss = 0.5248521566390991, train/logprobs = tensor([[-0.9896, -2.3889],
        [-1.3543, -1.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03821980953216553
Epoch 0, Step 368: train/loss = 0.6268760561943054, train/raw-loss = 0.4786095917224884, train/logprobs = tensor([[-0.9510, -1.7102],
        [-1.2511, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04942215606570244
Epoch 0, Step 369: train/loss = 0.5882593393325806, train/raw-loss = 0.4336279630661011, train/logprobs = tensor([[-1.1913, -2.5631],
        [-1.8003, -1.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05154380947351456
Epoch 0, Step 370: train/loss = 0.6549069881439209, train/raw-loss = 0.5190761089324951, train/logprobs = tensor([[-0.9516, -2.3541],
        [-1.1909, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045276958495378494
Epoch 0, Step 371: train/loss = 0.7470636963844299, train/raw-loss = 0.6460130214691162, train/logprobs = tensor([[-0.6699, -0.8846],
        [-0.7190, -0.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033683568239212036
Epoch 0, Step 372: train/loss = 0.714920163154602, train/raw-loss = 0.5833499431610107, train/logprobs = tensor([[-1.6891, -2.4109],
        [-1.8803, -2.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043856747448444366
Epoch 0, Step 373: train/loss = 0.6269116401672363, train/raw-loss = 0.48886966705322266, train/logprobs = tensor([[-0.9095, -1.1308],
        [-1.5459, -0.6181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04601399973034859
Epoch 0, Step 374: train/loss = 0.7276638150215149, train/raw-loss = 0.5773409605026245, train/logprobs = tensor([[-0.9441, -0.9287],
        [-1.1219, -0.5767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050107598304748535
Epoch 0, Step 375: train/loss = 0.7830768823623657, train/raw-loss = 0.674498438835144, train/logprobs = tensor([[-0.6635, -0.7640],
        [-0.6590, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03619280830025673
Epoch 0, Step 376: train/loss = 0.7209845185279846, train/raw-loss = 0.5897366404533386, train/logprobs = tensor([[-1.4391, -1.2030],
        [-1.7436, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04374928027391434
Epoch 0, Step 377: train/loss = 0.6809176802635193, train/raw-loss = 0.5647342205047607, train/logprobs = tensor([[-0.5014, -1.8389],
        [-0.5353, -1.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038727838546037674
Epoch 0, Step 378: train/loss = 0.6923168897628784, train/raw-loss = 0.5282178521156311, train/logprobs = tensor([[-0.8535, -1.0232],
        [-1.2965, -0.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05469966679811478
Epoch 0, Step 379: train/loss = 0.6770749092102051, train/raw-loss = 0.5349138379096985, train/logprobs = tensor([[-1.1810, -1.9017],
        [-1.2676, -1.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047387029975652695
Epoch 0, Step 380: train/loss = 0.6133279800415039, train/raw-loss = 0.505037784576416, train/logprobs = tensor([[-1.1484, -1.9107],
        [-1.5467, -1.2470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03609675168991089
Epoch 0, Step 381: train/loss = 0.659941554069519, train/raw-loss = 0.5004029273986816, train/logprobs = tensor([[-1.0006, -1.3276],
        [-1.4291, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0531795434653759
Epoch 0, Step 382: train/loss = 0.7190524935722351, train/raw-loss = 0.5705136656761169, train/logprobs = tensor([[-0.7877, -0.8103],
        [-1.2426, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049512963742017746
Epoch 0, Step 383: train/loss = 0.7069759368896484, train/raw-loss = 0.5239075422286987, train/logprobs = tensor([[-1.0952, -1.3553],
        [-1.6894, -1.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0610227957367897
Epoch 0, Step 384: train/loss = 0.6472457647323608, train/raw-loss = 0.47667554020881653, train/logprobs = tensor([[-0.7479, -2.1622],
        [-0.8535, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056856755167245865
Epoch 0, Step 385: train/loss = 0.5784167647361755, train/raw-loss = 0.40320342779159546, train/logprobs = tensor([[-1.4880, -2.1084],
        [-2.4743, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05840443819761276
Epoch 0, Step 386: train/loss = 0.769890546798706, train/raw-loss = 0.6249569654464722, train/logprobs = tensor([[-1.6768, -1.6413],
        [-2.0306, -1.6509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04831118881702423
Epoch 0, Step 387: train/loss = 0.5192755460739136, train/raw-loss = 0.38589218258857727, train/logprobs = tensor([[-1.0404, -2.8122],
        [-1.2982, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04446113109588623
Epoch 0, Step 388: train/loss = 0.6888508796691895, train/raw-loss = 0.5700807571411133, train/logprobs = tensor([[-0.7031, -1.6991],
        [-0.7375, -1.0996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03959004953503609
Epoch 0, Step 389: train/loss = 0.5994834899902344, train/raw-loss = 0.4649929404258728, train/logprobs = tensor([[-0.9757, -2.4860],
        [-1.3154, -1.4120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04483018442988396
Epoch 0, Step 390: train/loss = 0.7051798701286316, train/raw-loss = 0.5646829605102539, train/logprobs = tensor([[-0.7833, -1.2622],
        [-0.9871, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04683229699730873
Epoch 0, Step 391: train/loss = 0.674543023109436, train/raw-loss = 0.5419421195983887, train/logprobs = tensor([[-0.6588, -1.0450],
        [-0.9833, -0.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04420028626918793
Epoch 0, Step 392: train/loss = 0.5737820267677307, train/raw-loss = 0.3973921537399292, train/logprobs = tensor([[-1.3472, -2.0596],
        [-2.2570, -1.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05879662185907364
Epoch 0, Step 393: train/loss = 0.7246484756469727, train/raw-loss = 0.5941810607910156, train/logprobs = tensor([[-0.9696, -1.9591],
        [-1.0276, -1.5195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04348914325237274
Epoch 0, Step 394: train/loss = 0.6843891143798828, train/raw-loss = 0.5352134704589844, train/logprobs = tensor([[-0.7798, -2.2321],
        [-1.0381, -1.7423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04972521960735321
Epoch 0, Step 395: train/loss = 0.6625813245773315, train/raw-loss = 0.5033299326896667, train/logprobs = tensor([[-0.8412, -1.3270],
        [-1.3423, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05308380722999573
Epoch 0, Step 396: train/loss = 0.6886959075927734, train/raw-loss = 0.5450678467750549, train/logprobs = tensor([[-0.8659, -2.4194],
        [-0.9215, -1.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0478760227560997
Epoch 0, Step 397: train/loss = 0.7083064913749695, train/raw-loss = 0.5583802461624146, train/logprobs = tensor([[-1.2376, -0.9272],
        [-1.6424, -0.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04997541755437851
Epoch 0, Step 398: train/loss = 0.5768013000488281, train/raw-loss = 0.41838639974594116, train/logprobs = tensor([[-0.9254, -1.7796],
        [-1.5447, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05280497670173645
Epoch 0, Step 399: train/loss = 0.6685792207717896, train/raw-loss = 0.5355070233345032, train/logprobs = tensor([[-1.0567, -1.9326],
        [-1.2211, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04435738921165466
Epoch 0, Step 400: train/loss = 0.6777744889259338, train/raw-loss = 0.5354773998260498, train/logprobs = tensor([[-1.1005, -2.4780],
        [-1.2765, -1.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04743235930800438
Epoch 0, Step 401: train/loss = 0.678819477558136, train/raw-loss = 0.5402240753173828, train/logprobs = tensor([[-1.2261, -2.2502],
        [-1.4738, -1.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04619847238063812
Epoch 0, Step 402: train/loss = 0.6851804852485657, train/raw-loss = 0.5698246955871582, train/logprobs = tensor([[-0.9391, -1.3879],
        [-1.0979, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038451921194791794
Epoch 0, Step 403: train/loss = 0.6323634386062622, train/raw-loss = 0.4872722625732422, train/logprobs = tensor([[-0.9940, -1.3034],
        [-1.6241, -0.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048363734036684036
Epoch 0, Step 404: train/loss = 0.5982868075370789, train/raw-loss = 0.4292684495449066, train/logprobs = tensor([[-1.2533, -1.3210],
        [-2.0564, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05633945390582085
Epoch 0, Step 405: train/loss = 0.7102529406547546, train/raw-loss = 0.5405601263046265, train/logprobs = tensor([[-0.8046, -1.3505],
        [-1.0791, -0.8653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05656427890062332
Epoch 0, Step 406: train/loss = 0.652319073677063, train/raw-loss = 0.4995378851890564, train/logprobs = tensor([[-1.1613, -1.2618],
        [-1.8219, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0509270578622818
Epoch 0, Step 407: train/loss = 0.7425699830055237, train/raw-loss = 0.5775130391120911, train/logprobs = tensor([[-0.7015, -1.3960],
        [-0.9007, -1.0585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05501897633075714
Epoch 0, Step 408: train/loss = 0.8071172833442688, train/raw-loss = 0.6530681848526001, train/logprobs = tensor([[-0.7303, -0.9741],
        [-0.7500, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0513496994972229
Epoch 0, Step 409: train/loss = 0.6981785297393799, train/raw-loss = 0.5759450793266296, train/logprobs = tensor([[-0.9767, -1.6680],
        [-1.0421, -1.2014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04074447602033615
Epoch 0, Step 410: train/loss = 0.6590090990066528, train/raw-loss = 0.5340983271598816, train/logprobs = tensor([[-1.7141, -2.3453],
        [-1.8709, -1.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041636936366558075
Epoch 0, Step 411: train/loss = 0.6807392835617065, train/raw-loss = 0.5315074920654297, train/logprobs = tensor([[-0.9223, -1.4844],
        [-1.1228, -0.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049743928015232086
Epoch 0, Step 412: train/loss = 0.7137080430984497, train/raw-loss = 0.5748229026794434, train/logprobs = tensor([[-1.0623, -1.9655],
        [-1.1633, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046295035630464554
Epoch 0, Step 413: train/loss = 0.6658272743225098, train/raw-loss = 0.5058018565177917, train/logprobs = tensor([[-0.9903, -1.2549],
        [-1.4393, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05334177985787392
Epoch 0, Step 414: train/loss = 0.6946994662284851, train/raw-loss = 0.5620735883712769, train/logprobs = tensor([[-0.7275, -1.5377],
        [-0.6945, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044208623468875885
Epoch 0, Step 415: train/loss = 0.6150593757629395, train/raw-loss = 0.46073678135871887, train/logprobs = tensor([[-0.7926, -2.1499],
        [-1.0155, -1.2149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05144085735082626
Epoch 0, Step 416: train/loss = 0.6086446642875671, train/raw-loss = 0.475197970867157, train/logprobs = tensor([[-0.9842, -1.8684],
        [-1.5335, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044482238590717316
Epoch 0, Step 417: train/loss = 0.8001574277877808, train/raw-loss = 0.6826808452606201, train/logprobs = tensor([[-1.1472, -0.7813],
        [-1.0268, -0.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03915885463356972
Epoch 0, Step 418: train/loss = 0.6005173921585083, train/raw-loss = 0.4462117552757263, train/logprobs = tensor([[-1.1679, -2.0823],
        [-1.6611, -1.2348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05143521726131439
Epoch 0, Step 419: train/loss = 0.5604602098464966, train/raw-loss = 0.3845824599266052, train/logprobs = tensor([[-1.0567, -2.1907],
        [-1.6857, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05862590670585632
Epoch 0, Step 420: train/loss = 0.6768476963043213, train/raw-loss = 0.521373450756073, train/logprobs = tensor([[-0.5522, -1.2168],
        [-1.0471, -0.8569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051824744790792465
Epoch 0, Step 421: train/loss = 0.6343567371368408, train/raw-loss = 0.49741071462631226, train/logprobs = tensor([[-0.8650, -2.2455],
        [-0.8800, -1.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045648667961359024
Epoch 0, Step 422: train/loss = 0.7213979959487915, train/raw-loss = 0.5555498003959656, train/logprobs = tensor([[-0.6050, -1.8696],
        [-0.6345, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05528273433446884
Epoch 0, Step 423: train/loss = 0.5966104865074158, train/raw-loss = 0.4268048405647278, train/logprobs = tensor([[-1.3985, -1.3069],
        [-2.4839, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0566018782556057
Epoch 0, Step 424: train/loss = 0.548103928565979, train/raw-loss = 0.38984525203704834, train/logprobs = tensor([[-0.8259, -2.2768],
        [-1.0268, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05275289714336395
Epoch 0, Step 425: train/loss = 0.6680793166160583, train/raw-loss = 0.5284102559089661, train/logprobs = tensor([[-0.9326, -2.0985],
        [-0.8726, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04655635356903076
Epoch 0, Step 426: train/loss = 0.6765958070755005, train/raw-loss = 0.5247317552566528, train/logprobs = tensor([[-0.7822, -1.3271],
        [-1.2711, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05062135308980942
Epoch 0, Step 427: train/loss = 0.6347219944000244, train/raw-loss = 0.46926018595695496, train/logprobs = tensor([[-1.4079, -1.5173],
        [-1.9353, -0.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05515393242239952
Epoch 0, Step 428: train/loss = 0.748846173286438, train/raw-loss = 0.6115668416023254, train/logprobs = tensor([[-0.7600, -0.7478],
        [-1.1494, -0.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04575975239276886
Epoch 0, Step 429: train/loss = 0.6478562355041504, train/raw-loss = 0.5326091051101685, train/logprobs = tensor([[-0.5493, -1.7075],
        [-0.5586, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03841570392251015
Epoch 0, Step 430: train/loss = 0.6360284090042114, train/raw-loss = 0.49430108070373535, train/logprobs = tensor([[-1.2394, -0.9762],
        [-1.9526, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04724245145916939
Epoch 0, Step 431: train/loss = 0.6936382055282593, train/raw-loss = 0.5423603653907776, train/logprobs = tensor([[-0.7763, -1.5543],
        [-0.9464, -0.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05042596161365509
Epoch 0, Step 432: train/loss = 0.6340910196304321, train/raw-loss = 0.4808289408683777, train/logprobs = tensor([[-0.6970, -1.6763],
        [-1.0976, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05108734965324402
Epoch 0, Step 433: train/loss = 0.6660557389259338, train/raw-loss = 0.50847327709198, train/logprobs = tensor([[-0.9278, -1.4579],
        [-1.4664, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05252748355269432
Epoch 0, Step 434: train/loss = 0.7312661409378052, train/raw-loss = 0.5482828617095947, train/logprobs = tensor([[-0.6239, -1.4866],
        [-1.1834, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060994431376457214
Epoch 0, Step 435: train/loss = 0.6435375213623047, train/raw-loss = 0.47658732533454895, train/logprobs = tensor([[-1.3328, -1.8538],
        [-1.7594, -1.2172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05565006658434868
Epoch 0, Step 436: train/loss = 0.7450200915336609, train/raw-loss = 0.5722230076789856, train/logprobs = tensor([[-0.9205, -1.6948],
        [-1.1231, -1.2704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0575990304350853
Epoch 0, Step 437: train/loss = 0.6864886283874512, train/raw-loss = 0.5596340894699097, train/logprobs = tensor([[-0.8200, -1.5392],
        [-0.7026, -0.7552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042284831404685974
Epoch 0, Step 438: train/loss = 0.6552032232284546, train/raw-loss = 0.5150874257087708, train/logprobs = tensor([[-0.9931, -1.2536],
        [-1.4833, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04670527204871178
Epoch 0, Step 439: train/loss = 0.6587565541267395, train/raw-loss = 0.501920759677887, train/logprobs = tensor([[-0.7538, -1.4297],
        [-1.0714, -0.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05227857828140259
Epoch 0, Step 440: train/loss = 0.7542270421981812, train/raw-loss = 0.6000924706459045, train/logprobs = tensor([[-0.8396, -1.1778],
        [-1.0053, -0.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05137820541858673
Epoch 0, Step 441: train/loss = 0.67302405834198, train/raw-loss = 0.530964732170105, train/logprobs = tensor([[-1.1295, -1.9454],
        [-1.7113, -1.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047353122383356094
Epoch 0, Step 442: train/loss = 0.608826756477356, train/raw-loss = 0.4593327045440674, train/logprobs = tensor([[-1.4639, -2.6588],
        [-1.6602, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04983134940266609
Epoch 0, Step 443: train/loss = 0.7244904041290283, train/raw-loss = 0.6100091338157654, train/logprobs = tensor([[-1.0080, -1.3715],
        [-0.8183, -0.6849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03816042095422745
Epoch 0, Step 444: train/loss = 0.6798253059387207, train/raw-loss = 0.5305506587028503, train/logprobs = tensor([[-1.6043, -2.2049],
        [-1.9172, -1.6639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04975824058055878
Epoch 0, Step 445: train/loss = 0.6764411926269531, train/raw-loss = 0.5275055170059204, train/logprobs = tensor([[-1.0187, -1.8330],
        [-1.2599, -1.2731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049645211547613144
Epoch 0, Step 446: train/loss = 0.721747875213623, train/raw-loss = 0.6129295825958252, train/logprobs = tensor([[-0.8275, -1.2574],
        [-0.8147, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036272771656513214
Epoch 0, Step 447: train/loss = 0.565931499004364, train/raw-loss = 0.3920259475708008, train/logprobs = tensor([[-0.9089, -1.9646],
        [-1.5539, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05796852707862854
Epoch 0, Step 448: train/loss = 0.5854323506355286, train/raw-loss = 0.4280248284339905, train/logprobs = tensor([[-0.6729, -1.6695],
        [-0.9992, -0.5946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05246919021010399
Epoch 0, Step 449: train/loss = 0.564544677734375, train/raw-loss = 0.3853079676628113, train/logprobs = tensor([[-1.0683, -2.4164],
        [-1.9364, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05974556505680084
Epoch 0, Step 450: train/loss = 0.6174427270889282, train/raw-loss = 0.47659677267074585, train/logprobs = tensor([[-0.9106, -2.1165],
        [-0.9346, -0.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04694866016507149
Epoch 0, Step 451: train/loss = 0.7259136438369751, train/raw-loss = 0.5793808698654175, train/logprobs = tensor([[-0.6717, -1.9913],
        [-0.7894, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04884423315525055
Epoch 0, Step 452: train/loss = 0.6007691621780396, train/raw-loss = 0.4329102039337158, train/logprobs = tensor([[-1.3976, -2.2094],
        [-1.8572, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05595298856496811
Epoch 0, Step 453: train/loss = 0.6465173363685608, train/raw-loss = 0.4842987060546875, train/logprobs = tensor([[-0.9531, -1.8263],
        [-1.3442, -1.1569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05407288298010826
Epoch 0, Step 454: train/loss = 0.5551775693893433, train/raw-loss = 0.40512436628341675, train/logprobs = tensor([[-0.9999, -2.4784],
        [-1.7371, -1.5694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05001772940158844
Epoch 0, Step 455: train/loss = 0.7796987891197205, train/raw-loss = 0.6278293132781982, train/logprobs = tensor([[-1.0880, -2.1572],
        [-1.3398, -1.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050623152405023575
Epoch 0, Step 456: train/loss = 0.6454763412475586, train/raw-loss = 0.5092193484306335, train/logprobs = tensor([[-0.7146, -1.7099],
        [-1.1311, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04541899636387825
Epoch 0, Step 457: train/loss = 0.7014923691749573, train/raw-loss = 0.5661888718605042, train/logprobs = tensor([[-0.8843, -1.8916],
        [-0.9623, -1.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04510116204619408
Epoch 0, Step 458: train/loss = 0.39039862155914307, train/raw-loss = 0.20179490745067596, train/logprobs = tensor([[-1.1247, -3.9684],
        [-2.3571, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0628679022192955
Epoch 0, Step 459: train/loss = 0.6362089514732361, train/raw-loss = 0.48285332322120667, train/logprobs = tensor([[-0.9334, -1.9514],
        [-1.1934, -0.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05111854523420334
Epoch 0, Step 460: train/loss = 0.6015681028366089, train/raw-loss = 0.44961684942245483, train/logprobs = tensor([[-1.0333, -2.4027],
        [-1.2428, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05065041407942772
Epoch 0, Step 461: train/loss = 0.5146443843841553, train/raw-loss = 0.3423335552215576, train/logprobs = tensor([[-1.0413, -2.6328],
        [-1.5180, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05743692070245743
Epoch 0, Step 462: train/loss = 0.6291953325271606, train/raw-loss = 0.4921368956565857, train/logprobs = tensor([[-0.6846, -1.5448],
        [-0.9866, -0.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045686159282922745
Epoch 0, Step 463: train/loss = 0.6366138458251953, train/raw-loss = 0.4924966096878052, train/logprobs = tensor([[-0.5798, -1.2907],
        [-0.9096, -0.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048039086163043976
Epoch 0, Step 464: train/loss = 0.7091349363327026, train/raw-loss = 0.5911096334457397, train/logprobs = tensor([[-0.7315, -0.7676],
        [-1.1263, -0.5961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0393417663872242
Epoch 0, Step 465: train/loss = 0.6513987183570862, train/raw-loss = 0.531011164188385, train/logprobs = tensor([[-0.7980, -1.8082],
        [-0.7985, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04012918099761009
Epoch 0, Step 466: train/loss = 0.5675206184387207, train/raw-loss = 0.43662428855895996, train/logprobs = tensor([[-0.6746, -1.8104],
        [-1.0833, -0.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04363209754228592
Epoch 0, Step 467: train/loss = 0.6136139035224915, train/raw-loss = 0.44573265314102173, train/logprobs = tensor([[-1.3296, -1.9930],
        [-2.0234, -1.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055960431694984436
Epoch 0, Step 468: train/loss = 0.6278342604637146, train/raw-loss = 0.46018052101135254, train/logprobs = tensor([[-0.7672, -1.7762],
        [-1.2794, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055884577333927155
Epoch 0, Step 469: train/loss = 0.6435107588768005, train/raw-loss = 0.5080506801605225, train/logprobs = tensor([[-0.6569, -2.5150],
        [-0.6730, -1.4357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045153357088565826
Epoch 0, Step 470: train/loss = 0.6217566728591919, train/raw-loss = 0.4828089475631714, train/logprobs = tensor([[-0.8407, -2.3285],
        [-0.8264, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046315908432006836
Epoch 0, Step 471: train/loss = 0.6776973009109497, train/raw-loss = 0.5295707583427429, train/logprobs = tensor([[-1.1945, -1.6485],
        [-1.6887, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0493755117058754
Epoch 0, Step 472: train/loss = 0.6276229619979858, train/raw-loss = 0.45288926362991333, train/logprobs = tensor([[-0.8351, -2.5110],
        [-1.3775, -1.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058244556188583374
Epoch 0, Step 473: train/loss = 0.6964198350906372, train/raw-loss = 0.5446410179138184, train/logprobs = tensor([[-1.0711, -1.4160],
        [-1.5356, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05059295892715454
Epoch 0, Step 474: train/loss = 0.7209227681159973, train/raw-loss = 0.5868856906890869, train/logprobs = tensor([[-1.1687, -1.8620],
        [-1.2573, -1.4760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044679030776023865
Epoch 0, Step 475: train/loss = 0.6011157035827637, train/raw-loss = 0.4476430416107178, train/logprobs = tensor([[-1.0573, -2.2178],
        [-1.5463, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051157545298337936
Epoch 0, Step 476: train/loss = 0.604789674282074, train/raw-loss = 0.47321754693984985, train/logprobs = tensor([[-0.5661, -1.4800],
        [-0.9388, -0.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04385736584663391
Epoch 0, Step 477: train/loss = 0.44383490085601807, train/raw-loss = 0.24584272503852844, train/logprobs = tensor([[-1.0835, -3.2658],
        [-2.4083, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06599737703800201
Epoch 0, Step 478: train/loss = 0.6223021149635315, train/raw-loss = 0.4592723846435547, train/logprobs = tensor([[-0.9461, -2.0773],
        [-1.5935, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05434323847293854
Epoch 0, Step 479: train/loss = 0.6937119364738464, train/raw-loss = 0.5561878085136414, train/logprobs = tensor([[-0.8320, -1.6062],
        [-0.8791, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04584136977791786
Epoch 0, Step 480: train/loss = 0.6349308490753174, train/raw-loss = 0.5293053984642029, train/logprobs = tensor([[-0.5526, -2.0977],
        [-0.6369, -1.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520848602056503
Epoch 0, Step 481: train/loss = 0.5580098628997803, train/raw-loss = 0.3746812343597412, train/logprobs = tensor([[-0.9583, -2.4213],
        [-1.6788, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061109546571969986
Epoch 0, Step 482: train/loss = 0.6505464315414429, train/raw-loss = 0.5136404037475586, train/logprobs = tensor([[-1.1947, -1.7971],
        [-1.5351, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04563535004854202
Epoch 0, Step 483: train/loss = 0.4868168532848358, train/raw-loss = 0.3121233880519867, train/logprobs = tensor([[-0.7465, -2.4285],
        [-1.3781, -0.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823114886879921
Epoch 0, Step 484: train/loss = 0.6532549858093262, train/raw-loss = 0.5367303490638733, train/logprobs = tensor([[-0.7890, -1.7583],
        [-0.7987, -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03884156048297882
Epoch 0, Step 485: train/loss = 0.6574851274490356, train/raw-loss = 0.5120104551315308, train/logprobs = tensor([[-0.6872, -2.3234],
        [-0.8651, -1.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04849155247211456
Epoch 0, Step 486: train/loss = 0.6222244501113892, train/raw-loss = 0.4945816695690155, train/logprobs = tensor([[-0.6772, -1.8791],
        [-0.7507, -0.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042547572404146194
Epoch 0, Step 487: train/loss = 0.7219467163085938, train/raw-loss = 0.6048613786697388, train/logprobs = tensor([[-0.7837, -1.3304],
        [-0.8351, -0.9884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03902843967080116
Epoch 0, Step 488: train/loss = 0.6617509722709656, train/raw-loss = 0.5032591819763184, train/logprobs = tensor([[-0.8839, -2.0805],
        [-1.0444, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05283060297369957
Epoch 0, Step 489: train/loss = 0.6653785705566406, train/raw-loss = 0.5225505828857422, train/logprobs = tensor([[-0.8754, -1.4194],
        [-1.3680, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04760930687189102
Epoch 0, Step 490: train/loss = 0.5759502649307251, train/raw-loss = 0.42538249492645264, train/logprobs = tensor([[-0.5796, -2.7362],
        [-0.6176, -0.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050189245492219925
Epoch 0, Step 491: train/loss = 0.7864485383033752, train/raw-loss = 0.6451776027679443, train/logprobs = tensor([[-0.6975, -1.9211],
        [-0.9392, -1.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047090306878089905
Epoch 0, Step 492: train/loss = 0.5384882688522339, train/raw-loss = 0.3904978632926941, train/logprobs = tensor([[-1.2916, -3.2305],
        [-1.3140, -1.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04933013767004013
Epoch 0, Step 493: train/loss = 0.6795628666877747, train/raw-loss = 0.5216910243034363, train/logprobs = tensor([[-1.0202, -1.6924],
        [-1.5078, -1.2079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0526239275932312
Epoch 0, Step 494: train/loss = 0.48575663566589355, train/raw-loss = 0.32043206691741943, train/logprobs = tensor([[-1.1554, -2.4569],
        [-1.9764, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05510818958282471
Epoch 0, Step 495: train/loss = 0.6348654627799988, train/raw-loss = 0.4898052513599396, train/logprobs = tensor([[-0.9536, -1.2647],
        [-1.4039, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048353418707847595
Epoch 0, Step 496: train/loss = 0.4950137436389923, train/raw-loss = 0.31891506910324097, train/logprobs = tensor([[-0.7898, -2.7312],
        [-1.6649, -1.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058699555695056915
Epoch 0, Step 497: train/loss = 0.6830282211303711, train/raw-loss = 0.5653442144393921, train/logprobs = tensor([[-0.6700, -1.0413],
        [-0.8807, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039227988570928574
Epoch 0, Step 498: train/loss = 0.6146405339241028, train/raw-loss = 0.4446289539337158, train/logprobs = tensor([[-0.6440, -1.6977],
        [-1.0074, -0.6923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05667054280638695
Epoch 0, Step 499: train/loss = 0.6348317265510559, train/raw-loss = 0.4742850065231323, train/logprobs = tensor([[-0.6873, -1.7467],
        [-0.8580, -0.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05351558327674866
Loss is nan
eval/loss: 0.6127002239227295
Epoch 0, Step 500: train/loss = 0.6580691337585449, train/raw-loss = 0.5301233530044556, train/logprobs = tensor([[-0.8605, -1.5533],
        [-1.2604, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04264858737587929
Epoch 0, Step 501: train/loss = 0.5765561461448669, train/raw-loss = 0.42470723390579224, train/logprobs = tensor([[-0.9815, -2.3646],
        [-1.2010, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0506163015961647
Epoch 0, Step 502: train/loss = 0.6320411562919617, train/raw-loss = 0.49325627088546753, train/logprobs = tensor([[-1.0352, -1.6544],
        [-1.4315, -0.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046261630952358246
Epoch 0, Step 503: train/loss = 0.48139286041259766, train/raw-loss = 0.2965978682041168, train/logprobs = tensor([[-0.9319, -2.4854],
        [-1.8260, -0.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061598341912031174
Epoch 0, Step 504: train/loss = 0.5568460822105408, train/raw-loss = 0.39710307121276855, train/logprobs = tensor([[-0.8554, -1.7648],
        [-1.6558, -0.9127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053247690200805664
Epoch 0, Step 505: train/loss = 0.5959709882736206, train/raw-loss = 0.4564354419708252, train/logprobs = tensor([[-0.7688, -1.8838],
        [-1.0390, -0.7315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046511851251125336
Epoch 0, Step 506: train/loss = 0.5951952934265137, train/raw-loss = 0.43163710832595825, train/logprobs = tensor([[-0.8821, -2.3428],
        [-1.4459, -1.4469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054519377648830414
Epoch 0, Step 507: train/loss = 0.48831504583358765, train/raw-loss = 0.3117367625236511, train/logprobs = tensor([[-0.6689, -2.3644],
        [-1.3794, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05885943025350571
Epoch 0, Step 508: train/loss = 0.6518760323524475, train/raw-loss = 0.532953143119812, train/logprobs = tensor([[-0.8467, -2.0299],
        [-0.8246, -1.1270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039640966802835464
Epoch 0, Step 509: train/loss = 0.5585739612579346, train/raw-loss = 0.3816211223602295, train/logprobs = tensor([[-0.6765, -2.4182],
        [-1.0859, -1.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05898427590727806
Epoch 0, Step 510: train/loss = 0.5412300825119019, train/raw-loss = 0.39123713970184326, train/logprobs = tensor([[-0.7147, -2.9942],
        [-0.6898, -1.0515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04999765008687973
Epoch 0, Step 511: train/loss = 0.5349856019020081, train/raw-loss = 0.39741823077201843, train/logprobs = tensor([[-1.0681, -2.3490],
        [-1.8124, -1.2818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04585578665137291
Epoch 0, Step 512: train/loss = 0.6037226915359497, train/raw-loss = 0.4805759787559509, train/logprobs = tensor([[-0.8093, -2.1469],
        [-0.8575, -0.9045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04104890674352646
Epoch 0, Step 513: train/loss = 0.5668449401855469, train/raw-loss = 0.43194112181663513, train/logprobs = tensor([[-0.9949, -2.3055],
        [-1.4210, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04496793821454048
Epoch 0, Step 514: train/loss = 0.59394770860672, train/raw-loss = 0.4206004738807678, train/logprobs = tensor([[-0.9963, -2.0585],
        [-1.7421, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05778241157531738
Epoch 0, Step 515: train/loss = 0.5047217011451721, train/raw-loss = 0.3103594481945038, train/logprobs = tensor([[-0.9529, -2.7788],
        [-1.4929, -0.8985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06478741765022278
Epoch 0, Step 516: train/loss = 0.6024656891822815, train/raw-loss = 0.4383034110069275, train/logprobs = tensor([[-0.6158, -2.0138],
        [-0.8949, -0.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05472075194120407
Epoch 0, Step 517: train/loss = 0.7280071973800659, train/raw-loss = 0.5981214642524719, train/logprobs = tensor([[-0.5074, -1.2577],
        [-0.5107, -0.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04329526424407959
Epoch 0, Step 518: train/loss = 0.5926774144172668, train/raw-loss = 0.46877408027648926, train/logprobs = tensor([[-0.9257, -3.4545],
        [-1.1206, -2.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04130111634731293
Epoch 0, Step 519: train/loss = 0.6091305613517761, train/raw-loss = 0.47921496629714966, train/logprobs = tensor([[-0.8630, -2.0880],
        [-0.9180, -0.8540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04330521076917648
Epoch 0, Step 520: train/loss = 0.49178391695022583, train/raw-loss = 0.3174361288547516, train/logprobs = tensor([[-0.9147, -3.4458],
        [-1.0925, -0.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058115918189287186
Epoch 0, Step 521: train/loss = 0.6244864463806152, train/raw-loss = 0.4676748812198639, train/logprobs = tensor([[-1.0846, -2.2989],
        [-1.3408, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05227050185203552
Epoch 0, Step 522: train/loss = 0.5980713367462158, train/raw-loss = 0.43905770778656006, train/logprobs = tensor([[-0.9944, -1.9258],
        [-1.4161, -0.7110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05300452560186386
Epoch 0, Step 523: train/loss = 0.6537694931030273, train/raw-loss = 0.5201765298843384, train/logprobs = tensor([[-1.2205, -2.4192],
        [-1.3317, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044530995190143585
Epoch 0, Step 524: train/loss = 0.5261034965515137, train/raw-loss = 0.34982946515083313, train/logprobs = tensor([[-0.8678, -2.5154],
        [-1.5243, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05875802040100098
Epoch 0, Step 525: train/loss = 0.6402919888496399, train/raw-loss = 0.47661253809928894, train/logprobs = tensor([[-1.3298, -1.8092],
        [-2.0831, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054559819400310516
Epoch 0, Step 526: train/loss = 0.5905836224555969, train/raw-loss = 0.3935297727584839, train/logprobs = tensor([[-1.2130, -3.2061],
        [-1.9056, -2.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06568459421396255
Epoch 0, Step 527: train/loss = 0.6454383134841919, train/raw-loss = 0.4789825677871704, train/logprobs = tensor([[-0.7208, -1.8002],
        [-1.3587, -1.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05548525229096413
Epoch 0, Step 528: train/loss = 0.5387588143348694, train/raw-loss = 0.38292086124420166, train/logprobs = tensor([[-0.9637, -1.9006],
        [-1.7874, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05194598808884621
Epoch 0, Step 529: train/loss = 0.7110430598258972, train/raw-loss = 0.5538161993026733, train/logprobs = tensor([[-0.8686, -2.7235],
        [-1.3259, -1.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05240897834300995
Epoch 0, Step 530: train/loss = 0.6114705204963684, train/raw-loss = 0.5068077445030212, train/logprobs = tensor([[-0.4651, -1.7552],
        [-0.4603, -0.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034887585788965225
Epoch 0, Step 531: train/loss = 0.5299590826034546, train/raw-loss = 0.3319535255432129, train/logprobs = tensor([[-0.7157, -2.6922],
        [-1.2455, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06600186228752136
Epoch 0, Step 532: train/loss = 0.6476404666900635, train/raw-loss = 0.5170148015022278, train/logprobs = tensor([[-0.7600, -1.3392],
        [-1.1106, -0.7152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043541889637708664
Epoch 0, Step 533: train/loss = 0.5257986187934875, train/raw-loss = 0.3710961937904358, train/logprobs = tensor([[-0.6023, -2.7087],
        [-0.6571, -0.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051567476242780685
Epoch 0, Step 534: train/loss = 0.6172056198120117, train/raw-loss = 0.44359511137008667, train/logprobs = tensor([[-0.9933, -1.7433],
        [-1.8428, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05787017568945885
Epoch 0, Step 535: train/loss = 0.6502598524093628, train/raw-loss = 0.5057090520858765, train/logprobs = tensor([[-0.7675, -1.5301],
        [-0.9346, -0.7159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048183586448431015
Epoch 0, Step 536: train/loss = 0.457674115896225, train/raw-loss = 0.2937992811203003, train/logprobs = tensor([[-1.0207, -3.5017],
        [-1.9124, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054624948650598526
Epoch 0, Step 537: train/loss = 0.5333001613616943, train/raw-loss = 0.34356361627578735, train/logprobs = tensor([[-1.0832, -2.1152],
        [-1.8041, -0.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06324553489685059
Epoch 0, Step 538: train/loss = 0.6899532079696655, train/raw-loss = 0.5551706552505493, train/logprobs = tensor([[-0.9471, -1.0189],
        [-2.0314, -1.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044927529990673065
Epoch 0, Step 539: train/loss = 0.633357584476471, train/raw-loss = 0.4681282937526703, train/logprobs = tensor([[-1.1582, -2.3990],
        [-1.2169, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05507643148303032
Epoch 0, Step 540: train/loss = 0.6490809321403503, train/raw-loss = 0.5126968622207642, train/logprobs = tensor([[-0.8643, -1.4695],
        [-1.2170, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045461367815732956
Epoch 0, Step 541: train/loss = 0.6434434056282043, train/raw-loss = 0.4956090450286865, train/logprobs = tensor([[-0.8692, -0.7908],
        [-1.5442, -0.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049278102815151215
Epoch 0, Step 542: train/loss = 0.6287714838981628, train/raw-loss = 0.47333505749702454, train/logprobs = tensor([[-1.1979, -1.9433],
        [-1.5042, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05181213468313217
Epoch 0, Step 543: train/loss = 0.6453434824943542, train/raw-loss = 0.4718201458454132, train/logprobs = tensor([[-0.8448, -1.2290],
        [-1.6010, -0.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057841118425130844
Epoch 0, Step 544: train/loss = 0.6584795117378235, train/raw-loss = 0.5329453349113464, train/logprobs = tensor([[-0.6367, -1.8958],
        [-0.6348, -0.7911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04184471815824509
Epoch 0, Step 545: train/loss = 0.6050763726234436, train/raw-loss = 0.4180150032043457, train/logprobs = tensor([[-0.6452, -2.1456],
        [-1.0616, -1.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06235378980636597
Epoch 0, Step 546: train/loss = 0.5743917226791382, train/raw-loss = 0.4214029014110565, train/logprobs = tensor([[-1.3441, -5.8881],
        [-2.3463, -5.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05099627748131752
Epoch 0, Step 547: train/loss = 0.5068458318710327, train/raw-loss = 0.35827940702438354, train/logprobs = tensor([[-0.7321, -2.3461],
        [-1.3328, -0.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04952213913202286
Epoch 0, Step 548: train/loss = 0.5146456956863403, train/raw-loss = 0.3188740015029907, train/logprobs = tensor([[-0.8169, -3.2678],
        [-1.4536, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652572363615036
Epoch 0, Step 549: train/loss = 0.6062996983528137, train/raw-loss = 0.4297107458114624, train/logprobs = tensor([[-1.1276, -2.2542],
        [-1.9746, -1.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05886297672986984
Epoch 0, Step 550: train/loss = 0.6942288875579834, train/raw-loss = 0.5232672691345215, train/logprobs = tensor([[-0.7630, -1.5946],
        [-1.2390, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0569872111082077
Epoch 0, Step 551: train/loss = 0.605937123298645, train/raw-loss = 0.46223369240760803, train/logprobs = tensor([[-0.6859, -2.6031],
        [-0.6898, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04790112376213074
Epoch 0, Step 552: train/loss = 0.613572359085083, train/raw-loss = 0.4793702960014343, train/logprobs = tensor([[-1.2532, -1.9959],
        [-1.8810, -1.2610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044734012335538864
Epoch 0, Step 553: train/loss = 0.5483784675598145, train/raw-loss = 0.3726672828197479, train/logprobs = tensor([[-1.4686, -2.6198],
        [-2.4810, -1.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05857039615511894
Epoch 0, Step 554: train/loss = 0.568733811378479, train/raw-loss = 0.41303640604019165, train/logprobs = tensor([[-0.9464, -2.8003],
        [-1.5506, -1.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05189913138747215
Epoch 0, Step 555: train/loss = 0.5473887920379639, train/raw-loss = 0.3915550112724304, train/logprobs = tensor([[-1.2938, -3.4813],
        [-2.0649, -2.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05194459855556488
Epoch 0, Step 556: train/loss = 0.5729891061782837, train/raw-loss = 0.393829345703125, train/logprobs = tensor([[-0.8543, -1.7942],
        [-1.4954, -0.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05971994251012802
Epoch 0, Step 557: train/loss = 0.5771428346633911, train/raw-loss = 0.44794943928718567, train/logprobs = tensor([[-0.5792, -2.7860],
        [-0.6330, -1.3551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04306446760892868
Epoch 0, Step 558: train/loss = 0.7463246583938599, train/raw-loss = 0.5539132356643677, train/logprobs = tensor([[-0.9242, -2.0202],
        [-1.6487, -1.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06413714587688446
Epoch 0, Step 559: train/loss = 0.5851039886474609, train/raw-loss = 0.4202423691749573, train/logprobs = tensor([[-0.6965, -2.1901],
        [-1.0675, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05495388060808182
Epoch 0, Step 560: train/loss = 0.6551121473312378, train/raw-loss = 0.5087127685546875, train/logprobs = tensor([[-0.7607, -2.0187],
        [-0.7435, -0.8205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048799801617860794
Epoch 0, Step 561: train/loss = 0.6351250410079956, train/raw-loss = 0.4419400095939636, train/logprobs = tensor([[-1.1875, -2.1374],
        [-1.9454, -1.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06439501792192459
Epoch 0, Step 562: train/loss = 0.5932809114456177, train/raw-loss = 0.4432404041290283, train/logprobs = tensor([[-0.7589, -2.3515],
        [-1.2376, -1.2204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05001350864768028
Epoch 0, Step 563: train/loss = 0.5559467673301697, train/raw-loss = 0.36993715167045593, train/logprobs = tensor([[-0.9231, -1.9108],
        [-1.7845, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06200319901108742
Epoch 0, Step 564: train/loss = 0.66666579246521, train/raw-loss = 0.4974660277366638, train/logprobs = tensor([[-1.1484, -1.8138],
        [-1.5117, -1.2107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05639992654323578
Epoch 0, Step 565: train/loss = 0.6699405908584595, train/raw-loss = 0.5429798364639282, train/logprobs = tensor([[-0.6798, -1.8269],
        [-0.7584, -1.0799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232024773955345
Epoch 0, Step 566: train/loss = 0.4781118631362915, train/raw-loss = 0.3232055902481079, train/logprobs = tensor([[-0.8623, -3.4976],
        [-0.9814, -1.0770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05163542553782463
Epoch 0, Step 567: train/loss = 0.7142829895019531, train/raw-loss = 0.6112183332443237, train/logprobs = tensor([[-0.5627, -1.6898],
        [-0.6496, -1.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03435488045215607
Epoch 0, Step 568: train/loss = 0.5905821323394775, train/raw-loss = 0.4615704417228699, train/logprobs = tensor([[-0.7037, -2.3067],
        [-1.0235, -1.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04300390183925629
Epoch 0, Step 569: train/loss = 0.7280920743942261, train/raw-loss = 0.5743350386619568, train/logprobs = tensor([[-1.3740, -1.1066],
        [-1.9133, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051252350211143494
Epoch 0, Step 570: train/loss = 0.5219031572341919, train/raw-loss = 0.3283454179763794, train/logprobs = tensor([[-0.8676, -3.4188],
        [-1.5951, -1.3493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0645192489027977
Epoch 0, Step 571: train/loss = 0.727372407913208, train/raw-loss = 0.5907893776893616, train/logprobs = tensor([[-1.3394, -1.5713],
        [-1.7097, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045527659356594086
Epoch 0, Step 572: train/loss = 0.6172854900360107, train/raw-loss = 0.47756069898605347, train/logprobs = tensor([[-0.7820, -2.1764],
        [-1.1547, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657492786645889
Epoch 0, Step 573: train/loss = 0.6436141729354858, train/raw-loss = 0.5207442045211792, train/logprobs = tensor([[-0.8309, -1.9436],
        [-0.8076, -0.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040956661105155945
Epoch 0, Step 574: train/loss = 0.5408954620361328, train/raw-loss = 0.384493887424469, train/logprobs = tensor([[-0.8543, -3.6891],
        [-1.4190, -2.0905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052133869379758835
Epoch 0, Step 575: train/loss = 0.7587250471115112, train/raw-loss = 0.6170161366462708, train/logprobs = tensor([[-1.0579, -2.2401],
        [-1.5704, -1.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04723629727959633
Epoch 0, Step 576: train/loss = 0.5170325040817261, train/raw-loss = 0.3345177173614502, train/logprobs = tensor([[-0.7911, -2.3721],
        [-1.4305, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060838259756565094
Epoch 0, Step 577: train/loss = 0.5085222721099854, train/raw-loss = 0.33174586296081543, train/logprobs = tensor([[-1.3076, -1.3493],
        [-2.7988, -0.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05892546474933624
Epoch 0, Step 578: train/loss = 0.75740647315979, train/raw-loss = 0.5821972489356995, train/logprobs = tensor([[-1.1506, -1.4382],
        [-1.0858, -0.7063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05840306729078293
Epoch 0, Step 579: train/loss = 0.5721639394760132, train/raw-loss = 0.38550108671188354, train/logprobs = tensor([[-1.2169, -1.9599],
        [-2.0575, -0.7946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062220945954322815
Epoch 0, Step 580: train/loss = 0.5925006866455078, train/raw-loss = 0.46325060725212097, train/logprobs = tensor([[-0.7133, -2.2410],
        [-0.7527, -0.6620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043083373457193375
Epoch 0, Step 581: train/loss = 0.5745809078216553, train/raw-loss = 0.4018986225128174, train/logprobs = tensor([[-0.6780, -2.6097],
        [-0.7448, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0575607530772686
Epoch 0, Step 582: train/loss = 0.7347184419631958, train/raw-loss = 0.5952819585800171, train/logprobs = tensor([[-0.8871, -1.8206],
        [-0.8593, -1.0966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04647880792617798
Epoch 0, Step 583: train/loss = 0.7626894116401672, train/raw-loss = 0.612569272518158, train/logprobs = tensor([[-1.1626, -1.0575],
        [-1.5558, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050040051341056824
Epoch 0, Step 584: train/loss = 0.5709309577941895, train/raw-loss = 0.3745673596858978, train/logprobs = tensor([[-0.8724, -2.3847],
        [-1.5777, -1.1130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06545452028512955
Epoch 0, Step 585: train/loss = 0.576932430267334, train/raw-loss = 0.43091732263565063, train/logprobs = tensor([[-0.6718, -2.5550],
        [-0.5847, -0.7950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04867168888449669
Epoch 0, Step 586: train/loss = 0.6928608417510986, train/raw-loss = 0.5254659056663513, train/logprobs = tensor([[-1.3163, -2.3950],
        [-1.8483, -1.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055798307061195374
Epoch 0, Step 587: train/loss = 0.6523935198783875, train/raw-loss = 0.5125716924667358, train/logprobs = tensor([[-0.6429, -1.8912],
        [-0.6615, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04660728573799133
Epoch 0, Step 588: train/loss = 0.6875295639038086, train/raw-loss = 0.5324005484580994, train/logprobs = tensor([[-0.8501, -2.0712],
        [-0.7078, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051709674298763275
Epoch 0, Step 589: train/loss = 0.6346240043640137, train/raw-loss = 0.4998648762702942, train/logprobs = tensor([[-1.1683, -2.1715],
        [-1.2867, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04491971805691719
Epoch 0, Step 590: train/loss = 0.6519513726234436, train/raw-loss = 0.5121113657951355, train/logprobs = tensor([[-0.9788, -1.5915],
        [-1.5700, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04661333188414574
Epoch 0, Step 591: train/loss = 0.602455198764801, train/raw-loss = 0.38632893562316895, train/logprobs = tensor([[-1.1748, -1.5253],
        [-2.4184, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07204209268093109
Epoch 0, Step 592: train/loss = 0.6106934547424316, train/raw-loss = 0.4611826539039612, train/logprobs = tensor([[-1.3708, -1.6848],
        [-2.1858, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049836911261081696
Epoch 0, Step 593: train/loss = 0.5936489105224609, train/raw-loss = 0.4186716675758362, train/logprobs = tensor([[-1.0506, -1.9290],
        [-1.9930, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05832575634121895
Epoch 0, Step 594: train/loss = 0.4979720115661621, train/raw-loss = 0.34741175174713135, train/logprobs = tensor([[-0.8112, -3.1619],
        [-0.9583, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05018675699830055
Epoch 0, Step 595: train/loss = 0.5799276828765869, train/raw-loss = 0.42084336280822754, train/logprobs = tensor([[-1.0161, -1.4544],
        [-1.9116, -0.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05302810296416283
Epoch 0, Step 596: train/loss = 0.6124346256256104, train/raw-loss = 0.45399394631385803, train/logprobs = tensor([[-0.7332, -2.2169],
        [-0.8600, -0.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052813559770584106
Epoch 0, Step 597: train/loss = 0.6443483233451843, train/raw-loss = 0.5196034908294678, train/logprobs = tensor([[-1.1741, -2.0704],
        [-1.1746, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041581615805625916
Epoch 0, Step 598: train/loss = 0.7549750208854675, train/raw-loss = 0.6120861768722534, train/logprobs = tensor([[-0.9111, -2.9382],
        [-1.1414, -2.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047629620879888535
Epoch 0, Step 599: train/loss = 0.7139599323272705, train/raw-loss = 0.6036416888237, train/logprobs = tensor([[-1.0527, -1.2722],
        [-1.0828, -0.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03677275776863098
Epoch 0, Step 600: train/loss = 0.6513533592224121, train/raw-loss = 0.4716259837150574, train/logprobs = tensor([[-1.1813, -2.3572],
        [-1.5300, -1.3662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05990913510322571
Epoch 0, Step 601: train/loss = 0.5745167136192322, train/raw-loss = 0.38089242577552795, train/logprobs = tensor([[-1.1830, -2.0178],
        [-1.8699, -1.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06454141438007355
Epoch 0, Step 602: train/loss = 0.7014694213867188, train/raw-loss = 0.5318922996520996, train/logprobs = tensor([[-1.0222, -1.8366],
        [-1.4072, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056525684893131256
Epoch 0, Step 603: train/loss = 0.5153962969779968, train/raw-loss = 0.3310609459877014, train/logprobs = tensor([[-1.3530, -2.2749],
        [-2.2683, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061445124447345734
Epoch 0, Step 604: train/loss = 0.588766872882843, train/raw-loss = 0.45163625478744507, train/logprobs = tensor([[-1.3531, -3.0625],
        [-1.6225, -1.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04571021720767021
Epoch 0, Step 605: train/loss = 0.5899201035499573, train/raw-loss = 0.41856008768081665, train/logprobs = tensor([[-0.8741, -1.8748],
        [-1.4673, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057120006531476974
Epoch 0, Step 606: train/loss = 0.7528508901596069, train/raw-loss = 0.5785456299781799, train/logprobs = tensor([[-0.8700, -1.1487],
        [-1.2144, -0.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05810173228383064
Epoch 0, Step 607: train/loss = 0.6227496862411499, train/raw-loss = 0.45641008019447327, train/logprobs = tensor([[-0.5778, -2.4005],
        [-0.6615, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05544653534889221
Epoch 0, Step 608: train/loss = 0.5251842141151428, train/raw-loss = 0.35948872566223145, train/logprobs = tensor([[-0.9023, -2.9733],
        [-1.5095, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05523183196783066
Epoch 0, Step 609: train/loss = 0.5926644206047058, train/raw-loss = 0.46340861916542053, train/logprobs = tensor([[-0.7558, -2.4318],
        [-0.7627, -0.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04308526962995529
Epoch 0, Step 610: train/loss = 0.6806017756462097, train/raw-loss = 0.5435159206390381, train/logprobs = tensor([[-0.8204, -1.6606],
        [-0.7570, -0.7281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04569528251886368
Epoch 0, Step 611: train/loss = 0.5393903255462646, train/raw-loss = 0.34933000802993774, train/logprobs = tensor([[-1.0833, -2.2678],
        [-1.6637, -0.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06335341185331345
Epoch 0, Step 612: train/loss = 0.5500181913375854, train/raw-loss = 0.41272440552711487, train/logprobs = tensor([[-0.6938, -3.1130],
        [-0.6774, -0.7324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04576459899544716
Epoch 0, Step 613: train/loss = 0.5552454590797424, train/raw-loss = 0.42148661613464355, train/logprobs = tensor([[-0.8464, -1.9955],
        [-1.3241, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04458627104759216
Epoch 0, Step 614: train/loss = 0.5021014213562012, train/raw-loss = 0.3481939435005188, train/logprobs = tensor([[-1.0062, -2.9201],
        [-1.3372, -1.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05130249634385109
Epoch 0, Step 615: train/loss = 0.6641239523887634, train/raw-loss = 0.5275987386703491, train/logprobs = tensor([[-0.7076, -2.5124],
        [-0.7976, -1.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04550839215517044
Epoch 0, Step 616: train/loss = 0.5655114650726318, train/raw-loss = 0.3648913502693176, train/logprobs = tensor([[-1.3998, -2.5072],
        [-2.7134, -1.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06687335669994354
Epoch 0, Step 617: train/loss = 0.49960601329803467, train/raw-loss = 0.3213290274143219, train/logprobs = tensor([[-0.8568, -2.5380],
        [-1.5552, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059425659477710724
Epoch 0, Step 618: train/loss = 0.5452131628990173, train/raw-loss = 0.3741809129714966, train/logprobs = tensor([[-0.8168, -2.9505],
        [-1.3711, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05701075866818428
Epoch 0, Step 619: train/loss = 0.6594522595405579, train/raw-loss = 0.4848868250846863, train/logprobs = tensor([[-0.9326, -1.7956],
        [-1.5985, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05818847939372063
Epoch 0, Step 620: train/loss = 0.7044165134429932, train/raw-loss = 0.5819368958473206, train/logprobs = tensor([[-0.6666, -1.5562],
        [-0.7501, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04082655534148216
Epoch 0, Step 621: train/loss = 0.6699246764183044, train/raw-loss = 0.5197017192840576, train/logprobs = tensor([[-1.0139, -2.8608],
        [-0.8106, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05007432401180267
Epoch 0, Step 622: train/loss = 0.4891422688961029, train/raw-loss = 0.3119468688964844, train/logprobs = tensor([[-0.8259, -3.0602],
        [-1.3637, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05906512215733528
Epoch 0, Step 623: train/loss = 0.61156165599823, train/raw-loss = 0.4309638738632202, train/logprobs = tensor([[-1.5240, -1.6792],
        [-2.3633, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06019926071166992
Epoch 0, Step 624: train/loss = 0.5005933046340942, train/raw-loss = 0.32962295413017273, train/logprobs = tensor([[-0.9630, -3.6301],
        [-1.8219, -2.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05699009820818901
Epoch 0, Step 625: train/loss = 0.6943977475166321, train/raw-loss = 0.5445246696472168, train/logprobs = tensor([[-0.6149, -1.8764],
        [-0.6850, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04995768144726753
Epoch 0, Step 626: train/loss = 0.4613998830318451, train/raw-loss = 0.26536646485328674, train/logprobs = tensor([[-0.9011, -2.7515],
        [-2.0351, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06534447520971298
Epoch 0, Step 627: train/loss = 0.7255891561508179, train/raw-loss = 0.5714379549026489, train/logprobs = tensor([[-0.8404, -2.4102],
        [-1.0344, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05138373002409935
Epoch 0, Step 628: train/loss = 0.6198578476905823, train/raw-loss = 0.4843430519104004, train/logprobs = tensor([[-0.6757, -1.4869],
        [-1.0565, -0.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04517160728573799
Epoch 0, Step 629: train/loss = 0.700577974319458, train/raw-loss = 0.5728491544723511, train/logprobs = tensor([[-1.1824, -1.5667],
        [-1.4346, -1.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04257626086473465
Epoch 0, Step 630: train/loss = 0.5975971221923828, train/raw-loss = 0.45130205154418945, train/logprobs = tensor([[-0.9136, -1.8937],
        [-1.3672, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04876501113176346
Epoch 0, Step 631: train/loss = 0.670519232749939, train/raw-loss = 0.5499315857887268, train/logprobs = tensor([[-1.0022, -2.0158],
        [-0.8463, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04019588977098465
Epoch 0, Step 632: train/loss = 0.5239067673683167, train/raw-loss = 0.377655029296875, train/logprobs = tensor([[-0.7766, -3.4887],
        [-0.7742, -1.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04875057190656662
Epoch 0, Step 633: train/loss = 0.5027499794960022, train/raw-loss = 0.35630762577056885, train/logprobs = tensor([[-0.9166, -3.5575],
        [-0.9980, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048814110457897186
Epoch 0, Step 634: train/loss = 0.597981870174408, train/raw-loss = 0.4242682158946991, train/logprobs = tensor([[-0.8904, -1.6715],
        [-1.5714, -0.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05790455639362335
Epoch 0, Step 635: train/loss = 0.6987912654876709, train/raw-loss = 0.5408929586410522, train/logprobs = tensor([[-1.3499, -1.8373],
        [-1.6757, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05263274908065796
Epoch 0, Step 636: train/loss = 0.7405286431312561, train/raw-loss = 0.5525801181793213, train/logprobs = tensor([[-0.9763, -1.9273],
        [-1.9675, -1.4769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06264951080083847
Epoch 0, Step 637: train/loss = 0.6305789947509766, train/raw-loss = 0.472415953874588, train/logprobs = tensor([[-1.4561, -3.7095],
        [-1.3052, -1.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05272103101015091
Epoch 0, Step 638: train/loss = 0.5470638275146484, train/raw-loss = 0.3279950022697449, train/logprobs = tensor([[-1.2735, -2.9109],
        [-2.6328, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07302293181419373
Epoch 0, Step 639: train/loss = 0.5458914041519165, train/raw-loss = 0.3792312741279602, train/logprobs = tensor([[-0.6930, -2.2949],
        [-1.2456, -0.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05555339530110359
Epoch 0, Step 640: train/loss = 0.5337179899215698, train/raw-loss = 0.394695907831192, train/logprobs = tensor([[-0.6673, -2.6237],
        [-0.7307, -0.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0463406965136528
Epoch 0, Step 641: train/loss = 0.685685396194458, train/raw-loss = 0.5613877773284912, train/logprobs = tensor([[-1.2897, -1.2117],
        [-1.5691, -0.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04143252223730087
Epoch 0, Step 642: train/loss = 0.48882144689559937, train/raw-loss = 0.3382546901702881, train/logprobs = tensor([[-1.0211, -3.1126],
        [-1.3723, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050188928842544556
Epoch 0, Step 643: train/loss = 0.6311244964599609, train/raw-loss = 0.43937844038009644, train/logprobs = tensor([[-1.1402, -2.5413],
        [-2.0617, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06391533464193344
Epoch 0, Step 644: train/loss = 0.7265456318855286, train/raw-loss = 0.605480432510376, train/logprobs = tensor([[-1.4815, -2.0509],
        [-1.4371, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040355052798986435
Epoch 0, Step 645: train/loss = 0.7253261208534241, train/raw-loss = 0.6062052845954895, train/logprobs = tensor([[-0.6186, -1.1021],
        [-0.6049, -0.6342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03970694914460182
Epoch 0, Step 646: train/loss = 0.6610790491104126, train/raw-loss = 0.520733118057251, train/logprobs = tensor([[-1.5826, -1.6686],
        [-2.1071, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0467819906771183
Epoch 0, Step 647: train/loss = 0.593332827091217, train/raw-loss = 0.4131518602371216, train/logprobs = tensor([[-1.0411, -1.5558],
        [-2.1195, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060060326009988785
Epoch 0, Step 648: train/loss = 0.5273294448852539, train/raw-loss = 0.38125699758529663, train/logprobs = tensor([[-0.8017, -2.6283],
        [-1.2000, -0.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04869081452488899
Epoch 0, Step 649: train/loss = 0.47204533219337463, train/raw-loss = 0.30055394768714905, train/logprobs = tensor([[-1.1099, -3.3757],
        [-1.4988, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0571637898683548
Epoch 0, Step 650: train/loss = 0.4510594308376312, train/raw-loss = 0.24798625707626343, train/logprobs = tensor([[-0.8527, -2.4167],
        [-2.1279, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06769105792045593
Epoch 0, Step 651: train/loss = 0.711546778678894, train/raw-loss = 0.5672194361686707, train/logprobs = tensor([[-0.6619, -1.2285],
        [-1.2206, -0.8243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04810912162065506
Epoch 0, Step 652: train/loss = 0.44389352202415466, train/raw-loss = 0.2880682349205017, train/logprobs = tensor([[-0.8828, -3.6834],
        [-1.2175, -1.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051941774785518646
Epoch 0, Step 653: train/loss = 0.6328277587890625, train/raw-loss = 0.5150954127311707, train/logprobs = tensor([[-0.5861, -2.0817],
        [-0.5607, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03924412280321121
Epoch 0, Step 654: train/loss = 0.538141131401062, train/raw-loss = 0.3674261271953583, train/logprobs = tensor([[-0.7257, -2.6991],
        [-1.2092, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056905001401901245
Epoch 0, Step 655: train/loss = 0.4839717745780945, train/raw-loss = 0.32635563611984253, train/logprobs = tensor([[-0.9137, -3.0540],
        [-1.8207, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05253871530294418
Epoch 0, Step 656: train/loss = 0.5370354056358337, train/raw-loss = 0.4081438183784485, train/logprobs = tensor([[-0.6034, -2.9382],
        [-0.5868, -0.7344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04296388104557991
Epoch 0, Step 657: train/loss = 0.46865588426589966, train/raw-loss = 0.29672831296920776, train/logprobs = tensor([[-0.8849, -3.5803],
        [-1.1845, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05730917304754257
Epoch 0, Step 658: train/loss = 0.6720303297042847, train/raw-loss = 0.4985455870628357, train/logprobs = tensor([[-0.9750, -1.5768],
        [-1.3686, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05782826244831085
Epoch 0, Step 659: train/loss = 0.6027026176452637, train/raw-loss = 0.42846494913101196, train/logprobs = tensor([[-0.9647, -2.2981],
        [-1.4722, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05807923525571823
Epoch 0, Step 660: train/loss = 0.5246213674545288, train/raw-loss = 0.354103684425354, train/logprobs = tensor([[-0.9824, -2.9123],
        [-1.4815, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0568392276763916
Epoch 0, Step 661: train/loss = 0.6002748012542725, train/raw-loss = 0.43358683586120605, train/logprobs = tensor([[-0.8114, -1.7343],
        [-1.3349, -0.5145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055562667548656464
Epoch 0, Step 662: train/loss = 0.4730318784713745, train/raw-loss = 0.3188283145427704, train/logprobs = tensor([[-0.7115, -4.6277],
        [-1.2027, -1.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051401183009147644
Epoch 0, Step 663: train/loss = 0.5246573090553284, train/raw-loss = 0.36883026361465454, train/logprobs = tensor([[-1.0147, -2.6980],
        [-1.3896, -0.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05194234102964401
Epoch 0, Step 664: train/loss = 0.5085965394973755, train/raw-loss = 0.32796943187713623, train/logprobs = tensor([[-0.9366, -2.5054],
        [-1.8314, -1.0823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06020904332399368
Epoch 0, Step 665: train/loss = 0.49400731921195984, train/raw-loss = 0.35173797607421875, train/logprobs = tensor([[-1.0738, -3.6680],
        [-1.1748, -0.8660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047423120588064194
Epoch 0, Step 666: train/loss = 0.5383215546607971, train/raw-loss = 0.38910001516342163, train/logprobs = tensor([[-1.1372, -1.6816],
        [-2.1653, -0.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04974052309989929
Epoch 0, Step 667: train/loss = 0.5562551021575928, train/raw-loss = 0.40563076734542847, train/logprobs = tensor([[-0.9301, -2.5041],
        [-1.3358, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05020809918642044
Epoch 0, Step 668: train/loss = 0.6482799053192139, train/raw-loss = 0.524100661277771, train/logprobs = tensor([[-1.1806, -2.1046],
        [-1.3856, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04139309003949165
Epoch 0, Step 669: train/loss = 0.5589496493339539, train/raw-loss = 0.4163616895675659, train/logprobs = tensor([[-0.9407, -2.3460],
        [-1.4036, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047529324889183044
Epoch 0, Step 670: train/loss = 0.5424633622169495, train/raw-loss = 0.3934457302093506, train/logprobs = tensor([[-1.2053, -3.0130],
        [-1.7452, -1.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049672532826662064
Epoch 0, Step 671: train/loss = 0.6279237866401672, train/raw-loss = 0.476290762424469, train/logprobs = tensor([[-0.9466, -1.6731],
        [-1.4697, -0.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05054435506463051
Epoch 0, Step 672: train/loss = 0.6018179655075073, train/raw-loss = 0.43923795223236084, train/logprobs = tensor([[-0.9797, -1.0959],
        [-1.9885, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05419336259365082
Epoch 0, Step 673: train/loss = 0.6690720915794373, train/raw-loss = 0.5683306455612183, train/logprobs = tensor([[-0.8847, -1.1191],
        [-1.1868, -0.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0335804782807827
Epoch 0, Step 674: train/loss = 0.5192756652832031, train/raw-loss = 0.3774699866771698, train/logprobs = tensor([[-0.7651, -2.7741],
        [-1.0954, -0.7752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04726855829358101
Epoch 0, Step 675: train/loss = 0.4771989583969116, train/raw-loss = 0.32480156421661377, train/logprobs = tensor([[-1.5522, -3.4946],
        [-1.8317, -1.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05079913139343262
Epoch 0, Step 676: train/loss = 0.48827558755874634, train/raw-loss = 0.3250924050807953, train/logprobs = tensor([[-1.1981, -4.5544],
        [-1.7918, -1.4305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05439439043402672
Epoch 0, Step 677: train/loss = 0.5048346519470215, train/raw-loss = 0.35693973302841187, train/logprobs = tensor([[-1.0047, -2.7159],
        [-1.3699, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04929830878973007
Epoch 0, Step 678: train/loss = 0.6464717388153076, train/raw-loss = 0.5004733800888062, train/logprobs = tensor([[-1.3768, -2.4995],
        [-1.6399, -1.5397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0486660934984684
Epoch 0, Step 679: train/loss = 0.41759398579597473, train/raw-loss = 0.22249701619148254, train/logprobs = tensor([[-0.8878, -4.2204],
        [-1.8033, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06503232568502426
Epoch 0, Step 680: train/loss = 0.484915554523468, train/raw-loss = 0.3440617322921753, train/logprobs = tensor([[-1.1340, -2.4844],
        [-1.8234, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04695127531886101
Epoch 0, Step 681: train/loss = 0.5646709203720093, train/raw-loss = 0.4161401689052582, train/logprobs = tensor([[-0.9717, -2.2878],
        [-1.3926, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049510255455970764
Epoch 0, Step 682: train/loss = 0.5607975125312805, train/raw-loss = 0.4170496165752411, train/logprobs = tensor([[-0.9337, -2.5882],
        [-1.3086, -1.0872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047915972769260406
Epoch 0, Step 683: train/loss = 0.645321249961853, train/raw-loss = 0.5200637578964233, train/logprobs = tensor([[-0.8139, -1.2803],
        [-1.1506, -0.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04175247997045517
Epoch 0, Step 684: train/loss = 0.49651607871055603, train/raw-loss = 0.331070214509964, train/logprobs = tensor([[-1.1508, -3.0588],
        [-2.2254, -1.3319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055148616433143616
Epoch 0, Step 685: train/loss = 0.6992729306221008, train/raw-loss = 0.5513241291046143, train/logprobs = tensor([[-1.1757, -2.3071],
        [-1.2194, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049316275864839554
Epoch 0, Step 686: train/loss = 0.5443307757377625, train/raw-loss = 0.4210376739501953, train/logprobs = tensor([[-0.6892, -2.4990],
        [-0.7648, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04109768941998482
Epoch 0, Step 687: train/loss = 0.5209794044494629, train/raw-loss = 0.3913578987121582, train/logprobs = tensor([[-0.7695, -1.6313],
        [-1.6881, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043207164853811264
Epoch 0, Step 688: train/loss = 0.46694493293762207, train/raw-loss = 0.301433265209198, train/logprobs = tensor([[-0.8565, -3.1845],
        [-1.4921, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055170558393001556
Epoch 0, Step 689: train/loss = 0.5221638679504395, train/raw-loss = 0.39855533838272095, train/logprobs = tensor([[-0.6257, -3.5069],
        [-0.6463, -1.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0412028543651104
Epoch 0, Step 690: train/loss = 0.6613924503326416, train/raw-loss = 0.5290404558181763, train/logprobs = tensor([[-1.1959, -2.6605],
        [-0.8835, -0.9400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04411735013127327
Epoch 0, Step 691: train/loss = 0.5897620320320129, train/raw-loss = 0.4541659355163574, train/logprobs = tensor([[-1.3599, -3.4337],
        [-1.5047, -1.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045198697596788406
Epoch 0, Step 692: train/loss = 0.5397210121154785, train/raw-loss = 0.4050430655479431, train/logprobs = tensor([[-0.9716, -2.7477],
        [-1.0446, -1.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044892653822898865
Epoch 0, Step 693: train/loss = 0.6476557850837708, train/raw-loss = 0.5203702449798584, train/logprobs = tensor([[-0.7371, -1.5534],
        [-1.1041, -1.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042428500950336456
Epoch 0, Step 694: train/loss = 0.5794376730918884, train/raw-loss = 0.43770983815193176, train/logprobs = tensor([[-1.3497, -2.0511],
        [-1.9931, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04724259674549103
Epoch 0, Step 695: train/loss = 0.5712367296218872, train/raw-loss = 0.42661505937576294, train/logprobs = tensor([[-1.4448, -2.0710],
        [-2.1043, -0.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04820724204182625
Epoch 0, Step 696: train/loss = 0.4833545386791229, train/raw-loss = 0.3334752023220062, train/logprobs = tensor([[-1.1478, -3.0367],
        [-1.6432, -0.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04995977506041527
Epoch 0, Step 697: train/loss = 0.5671262145042419, train/raw-loss = 0.4297887682914734, train/logprobs = tensor([[-1.2653, -2.3715],
        [-1.8838, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04577915370464325
Epoch 0, Step 698: train/loss = 0.4691462516784668, train/raw-loss = 0.30110615491867065, train/logprobs = tensor([[-0.7685, -3.5036],
        [-1.4863, -1.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05601336061954498
Epoch 0, Step 699: train/loss = 0.5116541981697083, train/raw-loss = 0.3374468684196472, train/logprobs = tensor([[-0.9530, -3.5235],
        [-1.5946, -1.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05806908756494522
Epoch 0, Step 700: train/loss = 0.44137808680534363, train/raw-loss = 0.2976222336292267, train/logprobs = tensor([[-1.0645, -3.6960],
        [-1.1975, -0.6065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047918617725372314
Epoch 0, Step 701: train/loss = 0.6524370908737183, train/raw-loss = 0.5336340665817261, train/logprobs = tensor([[-1.0526, -1.5187],
        [-1.3320, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039601024240255356
Epoch 0, Step 702: train/loss = 0.6492138504981995, train/raw-loss = 0.5431473851203918, train/logprobs = tensor([[-1.3122, -2.7534],
        [-1.2622, -1.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03535546734929085
Epoch 0, Step 703: train/loss = 0.5786049365997314, train/raw-loss = 0.42905816435813904, train/logprobs = tensor([[-1.0311, -1.4036],
        [-1.8218, -0.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04984893649816513
Epoch 0, Step 704: train/loss = 0.4429902732372284, train/raw-loss = 0.29620206356048584, train/logprobs = tensor([[-1.1570, -3.5990],
        [-1.7657, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048929404467344284
Epoch 0, Step 705: train/loss = 0.5307015776634216, train/raw-loss = 0.37079107761383057, train/logprobs = tensor([[-0.8468, -2.6889],
        [-1.4264, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05330350995063782
Epoch 0, Step 706: train/loss = 0.5879415273666382, train/raw-loss = 0.48181918263435364, train/logprobs = tensor([[-0.4796, -2.1457],
        [-0.5596, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03537410870194435
Epoch 0, Step 707: train/loss = 0.47872453927993774, train/raw-loss = 0.33498144149780273, train/logprobs = tensor([[-0.9516, -3.3823],
        [-1.0963, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04791436344385147
Epoch 0, Step 708: train/loss = 0.4969848096370697, train/raw-loss = 0.3460351824760437, train/logprobs = tensor([[-0.8848, -2.2513],
        [-1.9575, -0.7397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05031653121113777
Epoch 0, Step 709: train/loss = 0.5582627058029175, train/raw-loss = 0.4334079623222351, train/logprobs = tensor([[-1.0455, -2.7331],
        [-0.9567, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041618235409259796
Epoch 0, Step 710: train/loss = 0.566546618938446, train/raw-loss = 0.4354722201824188, train/logprobs = tensor([[-0.9522, -2.2931],
        [-1.1648, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04369146749377251
Epoch 0, Step 711: train/loss = 0.6076869964599609, train/raw-loss = 0.47049927711486816, train/logprobs = tensor([[-1.0093, -2.3002],
        [-1.2967, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04572924226522446
Epoch 0, Step 712: train/loss = 0.602432370185852, train/raw-loss = 0.49881213903427124, train/logprobs = tensor([[-1.4714, -3.0420],
        [-1.6407, -1.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0345400869846344
Epoch 0, Step 713: train/loss = 0.4754416346549988, train/raw-loss = 0.35527411103248596, train/logprobs = tensor([[-0.9400, -4.2755],
        [-0.8150, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04005584120750427
Epoch 0, Step 714: train/loss = 0.5128048658370972, train/raw-loss = 0.3968278169631958, train/logprobs = tensor([[-0.8678, -3.6338],
        [-0.8649, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03865902125835419
Epoch 0, Step 715: train/loss = 0.5928105711936951, train/raw-loss = 0.470670223236084, train/logprobs = tensor([[-1.4417, -3.0993],
        [-1.1611, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040713436901569366
Epoch 0, Step 716: train/loss = 0.5432735681533813, train/raw-loss = 0.3852730691432953, train/logprobs = tensor([[-1.0716, -0.9919],
        [-2.3164, -0.5046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052666835486888885
Epoch 0, Step 717: train/loss = 0.5676235556602478, train/raw-loss = 0.41884636878967285, train/logprobs = tensor([[-0.7520, -2.3053],
        [-1.0813, -0.8467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04959239438176155
Epoch 0, Step 718: train/loss = 0.4210417568683624, train/raw-loss = 0.2604668438434601, train/logprobs = tensor([[-0.9815, -4.5150],
        [-1.5238, -1.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05352497845888138
Epoch 0, Step 719: train/loss = 0.44015252590179443, train/raw-loss = 0.30571216344833374, train/logprobs = tensor([[-1.2517, -2.4196],
        [-2.2533, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04481346905231476
Epoch 0, Step 720: train/loss = 0.5717000961303711, train/raw-loss = 0.4634360373020172, train/logprobs = tensor([[-0.8601, -2.4011],
        [-0.8155, -0.6277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0360880121588707
Epoch 0, Step 721: train/loss = 0.6088836193084717, train/raw-loss = 0.47033193707466125, train/logprobs = tensor([[-1.3175, -2.0767],
        [-1.5280, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04618390277028084
Epoch 0, Step 722: train/loss = 0.5396849513053894, train/raw-loss = 0.4100137948989868, train/logprobs = tensor([[-0.8876, -2.9056],
        [-1.0233, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043223731219768524
Epoch 0, Step 723: train/loss = 0.6491180658340454, train/raw-loss = 0.5629646182060242, train/logprobs = tensor([[-0.9393, -2.3444],
        [-0.8411, -1.2806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02871781960129738
Epoch 0, Step 724: train/loss = 0.5749766826629639, train/raw-loss = 0.45248180627822876, train/logprobs = tensor([[-0.6733, -3.5971],
        [-0.5789, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04083160683512688
Epoch 0, Step 725: train/loss = 0.5858945846557617, train/raw-loss = 0.4271210730075836, train/logprobs = tensor([[-1.2812, -1.9101],
        [-1.9844, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0529244989156723
Epoch 0, Step 726: train/loss = 0.627325713634491, train/raw-loss = 0.5099273920059204, train/logprobs = tensor([[-1.0610, -1.3798],
        [-1.5400, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03913276642560959
Epoch 0, Step 727: train/loss = 0.6143261790275574, train/raw-loss = 0.46152713894844055, train/logprobs = tensor([[-0.9043, -2.2210],
        [-1.3180, -1.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050933003425598145
Epoch 0, Step 728: train/loss = 0.5243197679519653, train/raw-loss = 0.3776603639125824, train/logprobs = tensor([[-0.8876, -3.2660],
        [-1.4859, -1.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048886463046073914
Epoch 0, Step 729: train/loss = 0.6574921011924744, train/raw-loss = 0.5420184135437012, train/logprobs = tensor([[-0.8217, -1.9939],
        [-0.8973, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038491226732730865
Epoch 0, Step 730: train/loss = 0.6931701302528381, train/raw-loss = 0.5668367743492126, train/logprobs = tensor([[-1.7052, -2.0430],
        [-1.8254, -1.5287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0421111136674881
Epoch 0, Step 731: train/loss = 0.49557268619537354, train/raw-loss = 0.3434262275695801, train/logprobs = tensor([[-1.2672, -2.2683],
        [-2.6708, -0.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05071548745036125
Epoch 0, Step 732: train/loss = 0.45373111963272095, train/raw-loss = 0.3027602732181549, train/logprobs = tensor([[-1.2979, -3.8139],
        [-2.1913, -2.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05032362416386604
Epoch 0, Step 733: train/loss = 0.5905284881591797, train/raw-loss = 0.501329779624939, train/logprobs = tensor([[-1.0100, -2.4245],
        [-0.9751, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02973291277885437
Epoch 0, Step 734: train/loss = 0.5356154441833496, train/raw-loss = 0.3962255120277405, train/logprobs = tensor([[-0.6336, -2.5421],
        [-1.0801, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046463314443826675
Epoch 0, Step 735: train/loss = 0.5364445447921753, train/raw-loss = 0.37055814266204834, train/logprobs = tensor([[-1.0820, -2.1437],
        [-1.7664, -0.8033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05529547855257988
Epoch 0, Step 736: train/loss = 0.7240790724754333, train/raw-loss = 0.6013520956039429, train/logprobs = tensor([[-1.3514, -1.1284],
        [-1.5003, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04090901091694832
Epoch 0, Step 737: train/loss = 0.5190631151199341, train/raw-loss = 0.31783878803253174, train/logprobs = tensor([[-1.1501, -2.4585],
        [-2.4771, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06707477569580078
Epoch 0, Step 738: train/loss = 0.5085061192512512, train/raw-loss = 0.38539040088653564, train/logprobs = tensor([[-0.6826, -2.6624],
        [-0.9750, -0.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041038572788238525
Epoch 0, Step 739: train/loss = 0.5958106517791748, train/raw-loss = 0.4856235980987549, train/logprobs = tensor([[-0.6311, -1.5254],
        [-1.2692, -0.5327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03672901540994644
Epoch 0, Step 740: train/loss = 0.5990920662879944, train/raw-loss = 0.49325287342071533, train/logprobs = tensor([[-0.9712, -1.5978],
        [-1.3871, -0.5120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03527974337339401
Epoch 0, Step 741: train/loss = 0.6103614568710327, train/raw-loss = 0.4999726414680481, train/logprobs = tensor([[-1.0077, -2.0208],
        [-1.1441, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03679627552628517
Epoch 0, Step 742: train/loss = 0.506377637386322, train/raw-loss = 0.4002310335636139, train/logprobs = tensor([[-0.6543, -2.9854],
        [-0.6632, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035382214933633804
Epoch 0, Step 743: train/loss = 0.6362146735191345, train/raw-loss = 0.5449923276901245, train/logprobs = tensor([[-0.6830, -2.2005],
        [-0.6235, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03040744550526142
Epoch 0, Step 744: train/loss = 0.6523351073265076, train/raw-loss = 0.4882991313934326, train/logprobs = tensor([[-0.8093, -2.0314],
        [-0.9089, -0.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05467865243554115
Epoch 0, Step 745: train/loss = 0.5682975053787231, train/raw-loss = 0.4513130784034729, train/logprobs = tensor([[-1.5293, -2.9763],
        [-2.3613, -1.6399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03899480402469635
Epoch 0, Step 746: train/loss = 0.4293414354324341, train/raw-loss = 0.29848697781562805, train/logprobs = tensor([[-0.5513, -4.4945],
        [-0.5266, -0.7180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04361815005540848
Epoch 0, Step 747: train/loss = 0.509665846824646, train/raw-loss = 0.38559162616729736, train/logprobs = tensor([[-1.2600, -2.0578],
        [-2.0847, -0.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041358090937137604
Epoch 0, Step 748: train/loss = 0.5961530804634094, train/raw-loss = 0.44552162289619446, train/logprobs = tensor([[-1.1761, -2.3815],
        [-2.2376, -1.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050210487097501755
Epoch 0, Step 749: train/loss = 0.5819125771522522, train/raw-loss = 0.45487433671951294, train/logprobs = tensor([[-1.1923, -2.1616],
        [-2.2089, -1.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042346082627773285
Epoch 0, Step 750: train/loss = 0.6567955017089844, train/raw-loss = 0.5472167730331421, train/logprobs = tensor([[-0.9914, -2.2905],
        [-1.1363, -1.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03652622550725937
Epoch 0, Step 751: train/loss = 0.5008846521377563, train/raw-loss = 0.3701903522014618, train/logprobs = tensor([[-1.2550, -2.3225],
        [-1.9180, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043564777821302414
Epoch 0, Step 752: train/loss = 0.49062153697013855, train/raw-loss = 0.3941667973995209, train/logprobs = tensor([[-0.7192, -2.9217],
        [-0.8004, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03215157985687256
Epoch 0, Step 753: train/loss = 0.5991860628128052, train/raw-loss = 0.47246283292770386, train/logprobs = tensor([[-0.5941, -2.3747],
        [-0.5783, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04224108159542084
Epoch 0, Step 754: train/loss = 0.44050049781799316, train/raw-loss = 0.3187929689884186, train/logprobs = tensor([[-1.0915, -4.0421],
        [-1.1100, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04056917503476143
Epoch 0, Step 755: train/loss = 0.4715147316455841, train/raw-loss = 0.3213561773300171, train/logprobs = tensor([[-0.9528, -2.0658],
        [-2.1735, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05005285143852234
Epoch 0, Step 756: train/loss = 0.5468709468841553, train/raw-loss = 0.39834725856781006, train/logprobs = tensor([[-1.9156, -3.8630],
        [-1.9426, -1.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04950787499547005
Epoch 0, Step 757: train/loss = 0.6393097639083862, train/raw-loss = 0.5027673840522766, train/logprobs = tensor([[-1.4945, -1.9169],
        [-1.6681, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04551412910223007
Epoch 0, Step 758: train/loss = 0.5559403896331787, train/raw-loss = 0.43501022458076477, train/logprobs = tensor([[-0.6976, -3.1599],
        [-0.6899, -0.9902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04031006246805191
Epoch 0, Step 759: train/loss = 0.47090262174606323, train/raw-loss = 0.3091564178466797, train/logprobs = tensor([[-1.1428, -2.8913],
        [-2.0424, -1.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05391540750861168
Epoch 0, Step 760: train/loss = 0.35392141342163086, train/raw-loss = 0.20643046498298645, train/logprobs = tensor([[-1.3971, -3.9636],
        [-2.8041, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04916364327073097
Epoch 0, Step 761: train/loss = 0.42780521512031555, train/raw-loss = 0.2691658139228821, train/logprobs = tensor([[-0.9749, -4.1443],
        [-1.7968, -1.5712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05287979543209076
Epoch 0, Step 762: train/loss = 0.5548447370529175, train/raw-loss = 0.4567321240901947, train/logprobs = tensor([[-1.0526, -2.1188],
        [-1.5228, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032704200595617294
Epoch 0, Step 763: train/loss = 0.6251097917556763, train/raw-loss = 0.5093288421630859, train/logprobs = tensor([[-0.8975, -2.2010],
        [-1.1319, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03859364986419678
Epoch 0, Step 764: train/loss = 0.5671998858451843, train/raw-loss = 0.4330689311027527, train/logprobs = tensor([[-0.7460, -1.8827],
        [-1.3631, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044710323214530945
Epoch 0, Step 765: train/loss = 0.4756045937538147, train/raw-loss = 0.3588935434818268, train/logprobs = tensor([[-0.8997, -2.6526],
        [-1.2192, -0.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03890367969870567
Epoch 0, Step 766: train/loss = 0.4516868591308594, train/raw-loss = 0.30758750438690186, train/logprobs = tensor([[-0.9368, -3.2949],
        [-1.9101, -1.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04803311824798584
Epoch 0, Step 767: train/loss = 0.7052038908004761, train/raw-loss = 0.5633981823921204, train/logprobs = tensor([[-0.9055, -1.5171],
        [-1.5853, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0472685731947422
Epoch 0, Step 768: train/loss = 0.6271600127220154, train/raw-loss = 0.5110756158828735, train/logprobs = tensor([[-1.0440, -2.7909],
        [-0.8731, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038694802671670914
Epoch 0, Step 769: train/loss = 0.5693933367729187, train/raw-loss = 0.45122480392456055, train/logprobs = tensor([[-0.9338, -3.0207],
        [-0.8460, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03938950598239899
Epoch 0, Step 770: train/loss = 0.515251636505127, train/raw-loss = 0.40918922424316406, train/logprobs = tensor([[-0.7579, -3.3316],
        [-0.6762, -0.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035354144871234894
Epoch 0, Step 771: train/loss = 0.5248326063156128, train/raw-loss = 0.4087787866592407, train/logprobs = tensor([[-0.7397, -2.2809],
        [-1.1953, -0.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03868461027741432
Epoch 0, Step 772: train/loss = 0.5788592100143433, train/raw-loss = 0.47221919894218445, train/logprobs = tensor([[-1.3283, -2.6627],
        [-1.8147, -1.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035546667873859406
Epoch 0, Step 773: train/loss = 0.5617375373840332, train/raw-loss = 0.4251074194908142, train/logprobs = tensor([[-1.1707, -1.5724],
        [-2.0388, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0455433614552021
Epoch 0, Step 774: train/loss = 0.6105341911315918, train/raw-loss = 0.48956605792045593, train/logprobs = tensor([[-0.7970, -1.5284],
        [-1.4791, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04032272472977638
Epoch 0, Step 775: train/loss = 0.5739971399307251, train/raw-loss = 0.4651000499725342, train/logprobs = tensor([[-0.8620, -1.6988],
        [-1.5166, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03629903122782707
Epoch 0, Step 776: train/loss = 0.5251688361167908, train/raw-loss = 0.3793196380138397, train/logprobs = tensor([[-1.3642, -2.4017],
        [-2.2638, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04861639440059662
Epoch 0, Step 777: train/loss = 0.6973065137863159, train/raw-loss = 0.5516350269317627, train/logprobs = tensor([[-0.9985, -1.5495],
        [-2.0452, -1.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855716973543167
Epoch 0, Step 778: train/loss = 0.5226598978042603, train/raw-loss = 0.4097936153411865, train/logprobs = tensor([[-0.9472, -2.3837],
        [-1.4269, -0.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03762209415435791
Epoch 0, Step 779: train/loss = 0.508392333984375, train/raw-loss = 0.3601231575012207, train/logprobs = tensor([[-1.3882, -2.6670],
        [-2.2941, -1.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049423057585954666
Epoch 0, Step 780: train/loss = 0.47945815324783325, train/raw-loss = 0.35178953409194946, train/logprobs = tensor([[-0.8147, -3.3028],
        [-1.1228, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042556196451187134
Epoch 0, Step 781: train/loss = 0.5598658323287964, train/raw-loss = 0.40391963720321655, train/logprobs = tensor([[-1.9003, -3.1196],
        [-2.4217, -1.1300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05198204889893532
Epoch 0, Step 782: train/loss = 0.4460386037826538, train/raw-loss = 0.30694761872291565, train/logprobs = tensor([[-0.6758, -3.6232],
        [-0.9641, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04636366292834282
Epoch 0, Step 783: train/loss = 0.5140101909637451, train/raw-loss = 0.37154123187065125, train/logprobs = tensor([[-1.2550, -2.2925],
        [-1.8841, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04748964682221413
Epoch 0, Step 784: train/loss = 0.525966227054596, train/raw-loss = 0.40587344765663147, train/logprobs = tensor([[-0.5460, -3.4318],
        [-0.5357, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040030915290117264
Epoch 0, Step 785: train/loss = 0.7290657758712769, train/raw-loss = 0.59930020570755, train/logprobs = tensor([[-2.1871, -2.7811],
        [-1.7695, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04325517639517784
Epoch 0, Step 786: train/loss = 0.4921126961708069, train/raw-loss = 0.3567538559436798, train/logprobs = tensor([[-0.9854, -1.3633],
        [-2.5827, -0.8470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045119624584913254
Epoch 0, Step 787: train/loss = 0.5539803504943848, train/raw-loss = 0.4025923013687134, train/logprobs = tensor([[-0.9489, -2.5152],
        [-1.9061, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05046266317367554
Epoch 0, Step 788: train/loss = 0.5143014788627625, train/raw-loss = 0.38069650530815125, train/logprobs = tensor([[-1.0378, -2.6760],
        [-1.5901, -0.7613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04453498125076294
Epoch 0, Step 789: train/loss = 0.6637917160987854, train/raw-loss = 0.5064584612846375, train/logprobs = tensor([[-1.2939, -2.3679],
        [-1.8679, -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052444420754909515
Epoch 0, Step 790: train/loss = 0.5855095982551575, train/raw-loss = 0.485637903213501, train/logprobs = tensor([[-1.2420, -2.5390],
        [-1.5080, -1.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033290572464466095
Epoch 0, Step 791: train/loss = 0.5483460426330566, train/raw-loss = 0.4008251130580902, train/logprobs = tensor([[-0.6732, -2.5706],
        [-1.0931, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04917365312576294
Epoch 0, Step 792: train/loss = 0.5310573577880859, train/raw-loss = 0.3796842694282532, train/logprobs = tensor([[-1.0854, -1.8255],
        [-2.2948, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050457701086997986
Epoch 0, Step 793: train/loss = 0.5314124226570129, train/raw-loss = 0.4119867980480194, train/logprobs = tensor([[-0.7743, -2.4598],
        [-1.1060, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039808545261621475
Epoch 0, Step 794: train/loss = 0.5031660199165344, train/raw-loss = 0.36016225814819336, train/logprobs = tensor([[-0.8154, -2.7018],
        [-1.2032, -0.7624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04766792058944702
Epoch 0, Step 795: train/loss = 0.5738436579704285, train/raw-loss = 0.4133237600326538, train/logprobs = tensor([[-0.9444, -1.7535],
        [-2.0737, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053506627678871155
Epoch 0, Step 796: train/loss = 0.5274893045425415, train/raw-loss = 0.38181230425834656, train/logprobs = tensor([[-1.1211, -2.4385],
        [-1.9143, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04855900630354881
Epoch 0, Step 797: train/loss = 0.5030043125152588, train/raw-loss = 0.3638697564601898, train/logprobs = tensor([[-1.0385, -1.8347],
        [-1.9032, -0.7820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04637816920876503
Epoch 0, Step 798: train/loss = 0.5903169512748718, train/raw-loss = 0.48544400930404663, train/logprobs = tensor([[-0.8611, -2.4138],
        [-0.8046, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0349576473236084
Epoch 0, Step 799: train/loss = 0.5977721810340881, train/raw-loss = 0.5118921995162964, train/logprobs = tensor([[-0.6126, -2.3142],
        [-0.5900, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028626661747694016
Epoch 0, Step 800: train/loss = 0.681111216545105, train/raw-loss = 0.5728557705879211, train/logprobs = tensor([[-1.1388, -0.9349],
        [-1.8406, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03608515486121178
Epoch 0, Step 801: train/loss = 0.545176088809967, train/raw-loss = 0.4179312288761139, train/logprobs = tensor([[-0.8362, -2.9633],
        [-0.7345, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04241495579481125
Epoch 0, Step 802: train/loss = 0.6177457571029663, train/raw-loss = 0.5134100317955017, train/logprobs = tensor([[-0.8317, -2.4953],
        [-0.9094, -1.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03477858379483223
Epoch 0, Step 803: train/loss = 0.6764592528343201, train/raw-loss = 0.6078168153762817, train/logprobs = tensor([[-0.6658, -1.1089],
        [-0.6148, -0.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022880828008055687
Epoch 0, Step 804: train/loss = 0.6063823103904724, train/raw-loss = 0.4874511957168579, train/logprobs = tensor([[-0.6826, -2.4976],
        [-0.6153, -0.7249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03964370861649513
Epoch 0, Step 805: train/loss = 0.5357657074928284, train/raw-loss = 0.4194709360599518, train/logprobs = tensor([[-1.0415, -3.7698],
        [-1.4867, -1.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03876493126153946
Epoch 0, Step 806: train/loss = 0.5901974439620972, train/raw-loss = 0.48133158683776855, train/logprobs = tensor([[-0.8268, -1.6665],
        [-1.2620, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628861531615257
Epoch 0, Step 807: train/loss = 0.5979136228561401, train/raw-loss = 0.48767542839050293, train/logprobs = tensor([[-1.5380, -2.3273],
        [-2.2608, -1.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0367460623383522
Epoch 0, Step 808: train/loss = 0.48176488280296326, train/raw-loss = 0.3508298695087433, train/logprobs = tensor([[-1.4911, -3.3342],
        [-2.2299, -1.2641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04364500567317009
Epoch 0, Step 809: train/loss = 0.717049241065979, train/raw-loss = 0.6485399603843689, train/logprobs = tensor([[-0.6835, -0.8568],
        [-0.6865, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022836409509181976
Epoch 0, Step 810: train/loss = 0.687725305557251, train/raw-loss = 0.5623538494110107, train/logprobs = tensor([[-1.7464, -2.2159],
        [-1.7706, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04179050773382187
Epoch 0, Step 811: train/loss = 0.5076177716255188, train/raw-loss = 0.4049147367477417, train/logprobs = tensor([[-0.6209, -2.0784],
        [-1.3350, -0.5799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03423435986042023
Epoch 0, Step 812: train/loss = 0.524787962436676, train/raw-loss = 0.41348251700401306, train/logprobs = tensor([[-0.9640, -2.4442],
        [-1.9600, -1.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03710182011127472
Epoch 0, Step 813: train/loss = 0.49960339069366455, train/raw-loss = 0.3695957660675049, train/logprobs = tensor([[-1.0366, -2.6732],
        [-1.7892, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04333587735891342
Epoch 0, Step 814: train/loss = 0.5613834261894226, train/raw-loss = 0.4440833628177643, train/logprobs = tensor([[-1.3307, -2.4885],
        [-1.7161, -1.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03910002484917641
Epoch 0, Step 815: train/loss = 0.49193456768989563, train/raw-loss = 0.3776082396507263, train/logprobs = tensor([[-0.8184, -2.6310],
        [-1.2560, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03810877352952957
Epoch 0, Step 816: train/loss = 0.5785671472549438, train/raw-loss = 0.47905832529067993, train/logprobs = tensor([[-1.6599, -3.1117],
        [-1.3800, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033169589936733246
Epoch 0, Step 817: train/loss = 0.516343355178833, train/raw-loss = 0.34412989020347595, train/logprobs = tensor([[-0.7728, -2.4512],
        [-1.6756, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057404495775699615
Epoch 0, Step 818: train/loss = 0.5310673713684082, train/raw-loss = 0.3996884524822235, train/logprobs = tensor([[-1.4315, -2.0939],
        [-2.1138, -0.7586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04379298910498619
Epoch 0, Step 819: train/loss = 0.4160909056663513, train/raw-loss = 0.2650195360183716, train/logprobs = tensor([[-1.0188, -3.0486],
        [-2.3073, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05035710707306862
Epoch 0, Step 820: train/loss = 0.5224212408065796, train/raw-loss = 0.38301882147789, train/logprobs = tensor([[-0.7918, -2.7664],
        [-1.3313, -0.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04646746441721916
Epoch 0, Step 821: train/loss = 0.4537503123283386, train/raw-loss = 0.2914779484272003, train/logprobs = tensor([[-1.0994, -2.8374],
        [-2.0864, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05409078672528267
Epoch 0, Step 822: train/loss = 0.48040565848350525, train/raw-loss = 0.3408231735229492, train/logprobs = tensor([[-1.2388, -2.5069],
        [-2.3475, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046527497470378876
Epoch 0, Step 823: train/loss = 0.5721574425697327, train/raw-loss = 0.42768925428390503, train/logprobs = tensor([[-1.1917, -2.4568],
        [-2.2218, -1.2758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04815608263015747
Epoch 0, Step 824: train/loss = 0.6026079058647156, train/raw-loss = 0.48366856575012207, train/logprobs = tensor([[-0.7649, -1.7134],
        [-1.2338, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039646439254283905
Epoch 0, Step 825: train/loss = 0.5120999217033386, train/raw-loss = 0.3770696818828583, train/logprobs = tensor([[-1.2776, -3.4734],
        [-1.7290, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04501008614897728
Epoch 0, Step 826: train/loss = 0.487987756729126, train/raw-loss = 0.36723971366882324, train/logprobs = tensor([[-0.8315, -3.3449],
        [-0.9658, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04024934023618698
Epoch 0, Step 827: train/loss = 0.579949676990509, train/raw-loss = 0.4482246935367584, train/logprobs = tensor([[-1.1054, -1.6044],
        [-2.0194, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04390832036733627
Epoch 0, Step 828: train/loss = 0.6358468532562256, train/raw-loss = 0.5538279414176941, train/logprobs = tensor([[-1.1109, -1.8878],
        [-1.3965, -1.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027339626103639603
Epoch 0, Step 829: train/loss = 0.46589940786361694, train/raw-loss = 0.3223418593406677, train/logprobs = tensor([[-1.0463, -2.3841],
        [-2.5730, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047852519899606705
Epoch 0, Step 830: train/loss = 0.5842515230178833, train/raw-loss = 0.4680114686489105, train/logprobs = tensor([[-0.9578, -1.9708],
        [-1.3560, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03874668851494789
Epoch 0, Step 831: train/loss = 0.5235071182250977, train/raw-loss = 0.3637649714946747, train/logprobs = tensor([[-1.2799, -1.3927],
        [-3.2013, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05324738472700119
Epoch 0, Step 832: train/loss = 0.7054234147071838, train/raw-loss = 0.5640268921852112, train/logprobs = tensor([[-1.6650, -2.0350],
        [-2.0905, -1.5597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047132156789302826
Epoch 0, Step 833: train/loss = 0.6823514699935913, train/raw-loss = 0.5638914108276367, train/logprobs = tensor([[-1.9467, -1.7715],
        [-2.7383, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03948669880628586
Epoch 0, Step 834: train/loss = 0.5400968790054321, train/raw-loss = 0.4281723201274872, train/logprobs = tensor([[-0.8278, -2.9960],
        [-0.9505, -1.6227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03730819374322891
Epoch 0, Step 835: train/loss = 0.539275050163269, train/raw-loss = 0.43603429198265076, train/logprobs = tensor([[-1.4300, -2.1913],
        [-2.0325, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03441357612609863
Epoch 0, Step 836: train/loss = 0.58729487657547, train/raw-loss = 0.4980316460132599, train/logprobs = tensor([[-0.7984, -1.4136],
        [-1.4119, -0.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029754405841231346
Epoch 0, Step 837: train/loss = 0.4576469659805298, train/raw-loss = 0.3716127276420593, train/logprobs = tensor([[-1.0218, -3.8664],
        [-0.9119, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028678078204393387
Epoch 0, Step 838: train/loss = 0.3989189565181732, train/raw-loss = 0.2545758783817291, train/logprobs = tensor([[-0.9229, -2.6833],
        [-2.4616, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048114363104104996
Epoch 0, Step 839: train/loss = 0.7700867056846619, train/raw-loss = 0.6759700775146484, train/logprobs = tensor([[-1.2056, -1.0324],
        [-1.1080, -0.8371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03137219697237015
Epoch 0, Step 840: train/loss = 0.4279862344264984, train/raw-loss = 0.2877505421638489, train/logprobs = tensor([[-1.0672, -3.2034],
        [-2.0781, -1.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046745236963033676
Epoch 0, Step 841: train/loss = 0.4954742193222046, train/raw-loss = 0.40638935565948486, train/logprobs = tensor([[-1.0118, -3.0221],
        [-1.0195, -0.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029694965109229088
Epoch 0, Step 842: train/loss = 0.6044641733169556, train/raw-loss = 0.4878773093223572, train/logprobs = tensor([[-0.9623, -2.1048],
        [-1.0730, -0.8524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03886228799819946
Epoch 0, Step 843: train/loss = 0.534491777420044, train/raw-loss = 0.4250059425830841, train/logprobs = tensor([[-0.7201, -3.1485],
        [-0.6785, -0.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03649529069662094
Epoch 0, Step 844: train/loss = 0.6587911248207092, train/raw-loss = 0.5479426980018616, train/logprobs = tensor([[-1.3376, -1.8849],
        [-1.2217, -0.8703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03694947808980942
Epoch 0, Step 845: train/loss = 0.5737382769584656, train/raw-loss = 0.4565936326980591, train/logprobs = tensor([[-0.8593, -2.7521],
        [-1.3751, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03904822841286659
Epoch 0, Step 846: train/loss = 0.43669527769088745, train/raw-loss = 0.2973329424858093, train/logprobs = tensor([[-1.0133, -2.5041],
        [-2.1953, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046454112976789474
Epoch 0, Step 847: train/loss = 0.5700096487998962, train/raw-loss = 0.4708693325519562, train/logprobs = tensor([[-0.6955, -2.4615],
        [-0.6690, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03304675966501236
Epoch 0, Step 848: train/loss = 0.6450365781784058, train/raw-loss = 0.5166062712669373, train/logprobs = tensor([[-1.5285, -3.3776],
        [-1.1546, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0428101010620594
Epoch 0, Step 849: train/loss = 0.493122398853302, train/raw-loss = 0.3690125346183777, train/logprobs = tensor([[-0.9424, -2.5256],
        [-1.2344, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04136994481086731
Epoch 0, Step 850: train/loss = 0.5652919411659241, train/raw-loss = 0.46032392978668213, train/logprobs = tensor([[-1.2241, -2.3822],
        [-1.8706, -1.3256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03498934581875801
Epoch 0, Step 851: train/loss = 0.5834739208221436, train/raw-loss = 0.48370370268821716, train/logprobs = tensor([[-0.6788, -2.7211],
        [-0.6728, -0.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03325675427913666
Epoch 0, Step 852: train/loss = 0.5358356237411499, train/raw-loss = 0.4247289299964905, train/logprobs = tensor([[-1.2392, -2.5291],
        [-1.6875, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037035588175058365
Epoch 0, Step 853: train/loss = 0.737088143825531, train/raw-loss = 0.6541454195976257, train/logprobs = tensor([[-1.4768, -1.8042],
        [-1.5811, -1.6891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02764756977558136
Epoch 0, Step 854: train/loss = 0.6474025249481201, train/raw-loss = 0.5490200519561768, train/logprobs = tensor([[-0.7725, -1.4354],
        [-1.1106, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03279414027929306
Epoch 0, Step 855: train/loss = 0.4074838161468506, train/raw-loss = 0.2735918164253235, train/logprobs = tensor([[-1.2146, -3.2221],
        [-2.3846, -1.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044630687683820724
Epoch 0, Step 856: train/loss = 0.551446259021759, train/raw-loss = 0.43298810720443726, train/logprobs = tensor([[-0.9383, -2.4059],
        [-1.3673, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03948605805635452
Epoch 0, Step 857: train/loss = 0.6186894178390503, train/raw-loss = 0.5160730481147766, train/logprobs = tensor([[-1.2076, -1.9840],
        [-1.5203, -0.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034205444157123566
Epoch 0, Step 858: train/loss = 0.5155622959136963, train/raw-loss = 0.3992874026298523, train/logprobs = tensor([[-0.8644, -2.0009],
        [-1.9027, -1.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038758285343647
Epoch 0, Step 859: train/loss = 0.600900411605835, train/raw-loss = 0.5023718476295471, train/logprobs = tensor([[-1.1081, -2.6981],
        [-0.8302, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03284284844994545
Epoch 0, Step 860: train/loss = 0.364342600107193, train/raw-loss = 0.23290880024433136, train/logprobs = tensor([[-1.6363, -3.6469],
        [-3.0102, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04381127282977104
Epoch 0, Step 861: train/loss = 0.5238068103790283, train/raw-loss = 0.4421382546424866, train/logprobs = tensor([[-0.8908, -3.0801],
        [-0.7631, -0.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027222834527492523
Epoch 0, Step 862: train/loss = 0.6831379532814026, train/raw-loss = 0.5784594416618347, train/logprobs = tensor([[-1.1842, -1.6894],
        [-1.1782, -1.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03489284962415695
Epoch 0, Step 863: train/loss = 0.4675443768501282, train/raw-loss = 0.35564303398132324, train/logprobs = tensor([[-0.6899, -3.1346],
        [-1.2476, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03730044141411781
Epoch 0, Step 864: train/loss = 0.46948549151420593, train/raw-loss = 0.3320564329624176, train/logprobs = tensor([[-1.0096, -2.5612],
        [-1.8054, -0.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04580969363451004
Epoch 0, Step 865: train/loss = 0.404352605342865, train/raw-loss = 0.28511542081832886, train/logprobs = tensor([[-1.3056, -3.3223],
        [-2.4444, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03974573314189911
Epoch 0, Step 866: train/loss = 0.6642205715179443, train/raw-loss = 0.5472990274429321, train/logprobs = tensor([[-1.7680, -1.3442],
        [-2.8288, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038973867893218994
Epoch 0, Step 867: train/loss = 0.3837493360042572, train/raw-loss = 0.25751376152038574, train/logprobs = tensor([[-0.8978, -4.0414],
        [-1.4647, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042078517377376556
Epoch 0, Step 868: train/loss = 0.6756869554519653, train/raw-loss = 0.5899527668952942, train/logprobs = tensor([[-1.0081, -1.9783],
        [-1.0947, -1.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028578056022524834
Epoch 0, Step 869: train/loss = 0.5713000893592834, train/raw-loss = 0.4766443371772766, train/logprobs = tensor([[-1.0304, -2.4553],
        [-1.5902, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03155191242694855
Epoch 0, Step 870: train/loss = 0.42807525396347046, train/raw-loss = 0.29335907101631165, train/logprobs = tensor([[-1.1133, -3.2305],
        [-1.9020, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0449054054915905
Epoch 0, Step 871: train/loss = 0.6662144660949707, train/raw-loss = 0.56325364112854, train/logprobs = tensor([[-1.1490, -1.1990],
        [-1.6030, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03432026877999306
Epoch 0, Step 872: train/loss = 0.6047400236129761, train/raw-loss = 0.5184792280197144, train/logprobs = tensor([[-0.6667, -1.2621],
        [-1.0223, -0.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028753597289323807
Epoch 0, Step 873: train/loss = 0.5184381008148193, train/raw-loss = 0.3982042074203491, train/logprobs = tensor([[-1.1423, -2.6111],
        [-1.9593, -1.4496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040077973157167435
Epoch 0, Step 874: train/loss = 0.5774093866348267, train/raw-loss = 0.48574167490005493, train/logprobs = tensor([[-0.9351, -2.7517],
        [-0.9965, -1.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03055589087307453
Epoch 0, Step 875: train/loss = 0.6445055603981018, train/raw-loss = 0.5325655341148376, train/logprobs = tensor([[-0.7835, -1.4322],
        [-1.4297, -0.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03731334209442139
Epoch 0, Step 876: train/loss = 0.48884135484695435, train/raw-loss = 0.3742513060569763, train/logprobs = tensor([[-0.8926, -2.8987],
        [-1.0077, -0.8879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038196682929992676
Epoch 0, Step 877: train/loss = 0.6253742575645447, train/raw-loss = 0.5149137377738953, train/logprobs = tensor([[-1.1247, -2.2364],
        [-1.1713, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0368201807141304
Epoch 0, Step 878: train/loss = 0.474173367023468, train/raw-loss = 0.34883520007133484, train/logprobs = tensor([[-1.0337, -2.9794],
        [-1.7211, -1.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04177939519286156
Epoch 0, Step 879: train/loss = 0.6181983947753906, train/raw-loss = 0.5145755410194397, train/logprobs = tensor([[-0.7928, -2.6299],
        [-0.7484, -1.3014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034540947526693344
Epoch 0, Step 880: train/loss = 0.5148028135299683, train/raw-loss = 0.39120107889175415, train/logprobs = tensor([[-1.2100, -2.7172],
        [-1.6127, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04120057821273804
Epoch 0, Step 881: train/loss = 0.6520634889602661, train/raw-loss = 0.5418108701705933, train/logprobs = tensor([[-0.9478, -1.9098],
        [-0.7941, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03675088286399841
Epoch 0, Step 882: train/loss = 0.901549756526947, train/raw-loss = 0.7653292417526245, train/logprobs = tensor([[-1.5172, -2.2360],
        [-2.1723, -2.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04540684074163437
Epoch 0, Step 883: train/loss = 0.5267535448074341, train/raw-loss = 0.4035585820674896, train/logprobs = tensor([[-0.8371, -2.3137],
        [-1.3567, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041064973920583725
Epoch 0, Step 884: train/loss = 0.4557883143424988, train/raw-loss = 0.3127463459968567, train/logprobs = tensor([[-0.8834, -2.3288],
        [-2.0602, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047680649906396866
Epoch 0, Step 885: train/loss = 0.3870433270931244, train/raw-loss = 0.24295249581336975, train/logprobs = tensor([[-0.6585, -4.9684],
        [-1.2423, -1.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048030272126197815
Epoch 0, Step 886: train/loss = 0.5447168350219727, train/raw-loss = 0.4461556375026703, train/logprobs = tensor([[-0.9840, -2.4262],
        [-1.5082, -0.9828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03285372629761696
Epoch 0, Step 887: train/loss = 0.4680021405220032, train/raw-loss = 0.35404807329177856, train/logprobs = tensor([[-1.1247, -2.7977],
        [-2.2728, -1.3129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037984684109687805
Epoch 0, Step 888: train/loss = 0.38556602597236633, train/raw-loss = 0.2565874755382538, train/logprobs = tensor([[-0.7470, -3.9227],
        [-1.2520, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04299285262823105
Epoch 0, Step 889: train/loss = 0.5870243310928345, train/raw-loss = 0.461015522480011, train/logprobs = tensor([[-1.2127, -1.4571],
        [-2.1344, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04200293868780136
Epoch 0, Step 890: train/loss = 0.6618162393569946, train/raw-loss = 0.555252194404602, train/logprobs = tensor([[-0.7323, -0.8926],
        [-1.0745, -0.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03552135452628136
Epoch 0, Step 891: train/loss = 0.5853852033615112, train/raw-loss = 0.5017052888870239, train/logprobs = tensor([[-0.8061, -2.3012],
        [-0.7407, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027893295511603355
Epoch 0, Step 892: train/loss = 0.5088120102882385, train/raw-loss = 0.3595520555973053, train/logprobs = tensor([[-1.1183, -2.4285],
        [-2.0796, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04975332319736481
Epoch 0, Step 893: train/loss = 0.575279712677002, train/raw-loss = 0.4626672863960266, train/logprobs = tensor([[-0.8199, -2.1035],
        [-1.3863, -1.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03753749653697014
Epoch 0, Step 894: train/loss = 0.49796003103256226, train/raw-loss = 0.38538289070129395, train/logprobs = tensor([[-0.8399, -2.9860],
        [-1.2992, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0375257283449173
Epoch 0, Step 895: train/loss = 0.6381193995475769, train/raw-loss = 0.5496072769165039, train/logprobs = tensor([[-0.7786, -1.9245],
        [-0.7867, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029504040256142616
Epoch 0, Step 896: train/loss = 0.6784896850585938, train/raw-loss = 0.5810220837593079, train/logprobs = tensor([[-1.7821, -3.7255],
        [-1.6373, -2.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03248920291662216
Epoch 0, Step 897: train/loss = 0.520677387714386, train/raw-loss = 0.38315847516059875, train/logprobs = tensor([[-0.9427, -3.5625],
        [-1.4942, -1.4202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04583963751792908
Epoch 0, Step 898: train/loss = 0.4935961961746216, train/raw-loss = 0.3862420320510864, train/logprobs = tensor([[-0.8405, -2.7283],
        [-1.2284, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035784706473350525
Epoch 0, Step 899: train/loss = 0.5184410810470581, train/raw-loss = 0.3971979022026062, train/logprobs = tensor([[-0.8659, -3.0168],
        [-0.8194, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04041437804698944
Epoch 0, Step 900: train/loss = 0.6224890947341919, train/raw-loss = 0.523032546043396, train/logprobs = tensor([[-1.0181, -2.8123],
        [-0.8002, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03315218165516853
Epoch 0, Step 901: train/loss = 0.6075637340545654, train/raw-loss = 0.4333142638206482, train/logprobs = tensor([[-1.9549, -2.5009],
        [-2.9618, -1.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05808314308524132
Epoch 0, Step 902: train/loss = 0.5007644295692444, train/raw-loss = 0.39478275179862976, train/logprobs = tensor([[-1.2470, -3.0623],
        [-1.8617, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035327229648828506
Epoch 0, Step 903: train/loss = 0.5532463788986206, train/raw-loss = 0.44348061084747314, train/logprobs = tensor([[-1.2466, -1.7910],
        [-1.8635, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036588579416275024
Epoch 0, Step 904: train/loss = 0.6013172268867493, train/raw-loss = 0.51116544008255, train/logprobs = tensor([[-1.3754, -2.5482],
        [-1.5430, -1.3423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030050601810216904
Epoch 0, Step 905: train/loss = 0.5796732902526855, train/raw-loss = 0.4882871210575104, train/logprobs = tensor([[-0.6927, -2.4565],
        [-0.6839, -0.6853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030462056398391724
Epoch 0, Step 906: train/loss = 0.4589370787143707, train/raw-loss = 0.33827805519104004, train/logprobs = tensor([[-1.7974, -4.7144],
        [-1.8689, -1.6517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04021967947483063
Epoch 0, Step 907: train/loss = 0.645743191242218, train/raw-loss = 0.5457719564437866, train/logprobs = tensor([[-0.6347, -0.8706],
        [-1.4010, -0.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033323753625154495
Epoch 0, Step 908: train/loss = 0.7611122727394104, train/raw-loss = 0.6649034023284912, train/logprobs = tensor([[-0.9695, -0.9786],
        [-1.2005, -1.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03206963092088699
Epoch 0, Step 909: train/loss = 0.5188535451889038, train/raw-loss = 0.3954850435256958, train/logprobs = tensor([[-0.7974, -2.6142],
        [-1.6209, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04112283140420914
Epoch 0, Step 910: train/loss = 0.6213257312774658, train/raw-loss = 0.49415943026542664, train/logprobs = tensor([[-1.6576, -1.8426],
        [-2.4106, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04238876327872276
Epoch 0, Step 911: train/loss = 0.6792643070220947, train/raw-loss = 0.5994413495063782, train/logprobs = tensor([[-1.1698, -1.7101],
        [-0.9799, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026607641950249672
Epoch 0, Step 912: train/loss = 0.6463449001312256, train/raw-loss = 0.5434162616729736, train/logprobs = tensor([[-0.7755, -1.9787],
        [-0.6603, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03430955484509468
Epoch 0, Step 913: train/loss = 0.4389360249042511, train/raw-loss = 0.3340812921524048, train/logprobs = tensor([[-0.8132, -3.7714],
        [-0.8646, -1.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0349515862762928
Epoch 0, Step 914: train/loss = 0.4866250157356262, train/raw-loss = 0.3374852240085602, train/logprobs = tensor([[-1.0447, -1.2869],
        [-2.7224, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04971326142549515
Epoch 0, Step 915: train/loss = 0.549229085445404, train/raw-loss = 0.4353148639202118, train/logprobs = tensor([[-0.9834, -2.1154],
        [-2.0144, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03797139972448349
Epoch 0, Step 916: train/loss = 0.6906938552856445, train/raw-loss = 0.5916465520858765, train/logprobs = tensor([[-0.8625, -1.3461],
        [-0.8604, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03301577642560005
Epoch 0, Step 917: train/loss = 0.35024160146713257, train/raw-loss = 0.20767953991889954, train/logprobs = tensor([[-1.1148, -3.9285],
        [-2.5658, -0.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04752068966627121
Epoch 0, Step 918: train/loss = 0.4726707339286804, train/raw-loss = 0.3567275106906891, train/logprobs = tensor([[-0.8455, -2.5979],
        [-1.7130, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03864773362874985
Epoch 0, Step 919: train/loss = 0.6058348417282104, train/raw-loss = 0.5162200331687927, train/logprobs = tensor([[-0.8802, -2.8915],
        [-0.8766, -1.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029871586710214615
Epoch 0, Step 920: train/loss = 0.5641788244247437, train/raw-loss = 0.4264192283153534, train/logprobs = tensor([[-0.8926, -1.7031],
        [-1.9853, -0.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04591986536979675
Epoch 0, Step 921: train/loss = 0.5725995898246765, train/raw-loss = 0.47460660338401794, train/logprobs = tensor([[-0.7715, -2.1826],
        [-0.8724, -0.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032664328813552856
Epoch 0, Step 922: train/loss = 0.5773466229438782, train/raw-loss = 0.48647087812423706, train/logprobs = tensor([[-0.9308, -2.4286],
        [-1.3132, -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03029191866517067
Epoch 0, Step 923: train/loss = 0.5173792839050293, train/raw-loss = 0.4131266474723816, train/logprobs = tensor([[-0.7596, -2.7177],
        [-1.1759, -1.1576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03475088253617287
Epoch 0, Step 924: train/loss = 0.5628268122673035, train/raw-loss = 0.4481113851070404, train/logprobs = tensor([[-1.3839, -3.6764],
        [-1.2606, -1.6287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03823847323656082
Epoch 0, Step 925: train/loss = 0.5554380416870117, train/raw-loss = 0.4509779214859009, train/logprobs = tensor([[-0.6607, -2.3734],
        [-0.7269, -0.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03482005000114441
Epoch 0, Step 926: train/loss = 0.379608690738678, train/raw-loss = 0.26442670822143555, train/logprobs = tensor([[-0.8797, -3.6319],
        [-1.5879, -0.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038394004106521606
Epoch 0, Step 927: train/loss = 0.7632781863212585, train/raw-loss = 0.6160238981246948, train/logprobs = tensor([[-1.0145, -2.6237],
        [-1.9267, -1.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04908476024866104
Epoch 0, Step 928: train/loss = 0.6650879383087158, train/raw-loss = 0.5478206872940063, train/logprobs = tensor([[-1.5480, -2.0169],
        [-1.8346, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03908909112215042
Epoch 0, Step 929: train/loss = 0.4764241576194763, train/raw-loss = 0.36652565002441406, train/logprobs = tensor([[-1.0113, -2.6387],
        [-2.0063, -0.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03663283959031105
Epoch 0, Step 930: train/loss = 0.7004038691520691, train/raw-loss = 0.5972166657447815, train/logprobs = tensor([[-1.2772, -1.7131],
        [-1.0814, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034395720809698105
Epoch 0, Step 931: train/loss = 0.6564273238182068, train/raw-loss = 0.5557736158370972, train/logprobs = tensor([[-0.7425, -1.9196],
        [-0.7910, -0.7489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033551234751939774
Epoch 0, Step 932: train/loss = 0.6059837937355042, train/raw-loss = 0.49324631690979004, train/logprobs = tensor([[-0.8692, -1.4171],
        [-1.4767, -0.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03757915645837784
Epoch 0, Step 933: train/loss = 0.5306090712547302, train/raw-loss = 0.4283219277858734, train/logprobs = tensor([[-0.8448, -2.5040],
        [-1.3343, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03409571945667267
Epoch 0, Step 934: train/loss = 0.6624029874801636, train/raw-loss = 0.5402388572692871, train/logprobs = tensor([[-1.5220, -3.4594],
        [-1.2418, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0407213531434536
Epoch 0, Step 935: train/loss = 0.4641265869140625, train/raw-loss = 0.31852710247039795, train/logprobs = tensor([[-1.2095, -2.7741],
        [-1.9714, -0.9162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048533156514167786
Epoch 0, Step 936: train/loss = 0.5687336921691895, train/raw-loss = 0.4719774127006531, train/logprobs = tensor([[-0.7910, -2.1344],
        [-0.7807, -0.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032252099364995956
Epoch 0, Step 937: train/loss = 0.43790102005004883, train/raw-loss = 0.2873951494693756, train/logprobs = tensor([[-1.2504, -2.3949],
        [-2.6578, -0.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050168633460998535
Epoch 0, Step 938: train/loss = 0.6657335162162781, train/raw-loss = 0.5450747609138489, train/logprobs = tensor([[-1.3750, -2.9776],
        [-0.9850, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040219590067863464
Epoch 0, Step 939: train/loss = 0.7605696320533752, train/raw-loss = 0.6585691571235657, train/logprobs = tensor([[-0.7357, -1.6765],
        [-0.8674, -1.2133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034000150859355927
Epoch 0, Step 940: train/loss = 0.4915769696235657, train/raw-loss = 0.347705215215683, train/logprobs = tensor([[-1.5980, -3.6640],
        [-2.2506, -1.6278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04795725271105766
Epoch 0, Step 941: train/loss = 0.5927858352661133, train/raw-loss = 0.4724889397621155, train/logprobs = tensor([[-1.3531, -3.1233],
        [-1.2209, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04009895771741867
Epoch 0, Step 942: train/loss = 0.5040479898452759, train/raw-loss = 0.3751448392868042, train/logprobs = tensor([[-0.8247, -3.0834],
        [-1.2528, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04296771436929703
Epoch 0, Step 943: train/loss = 0.5915706157684326, train/raw-loss = 0.48603346943855286, train/logprobs = tensor([[-1.2357, -2.4098],
        [-1.2744, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035179052501916885
Epoch 0, Step 944: train/loss = 0.4148216247558594, train/raw-loss = 0.2881515324115753, train/logprobs = tensor([[-0.8631, -3.5474],
        [-1.4407, -0.9963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042223379015922546
Epoch 0, Step 945: train/loss = 0.4889316260814667, train/raw-loss = 0.3528178334236145, train/logprobs = tensor([[-1.4493, -2.4812],
        [-2.4855, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04537125304341316
Epoch 0, Step 946: train/loss = 0.4176638126373291, train/raw-loss = 0.31477320194244385, train/logprobs = tensor([[-0.7523, -4.0661],
        [-0.9376, -1.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03429686650633812
Epoch 0, Step 947: train/loss = 0.672813892364502, train/raw-loss = 0.5649282932281494, train/logprobs = tensor([[-1.3047, -1.3228],
        [-1.4578, -0.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035961851477622986
Epoch 0, Step 948: train/loss = 0.5373010635375977, train/raw-loss = 0.4513241946697235, train/logprobs = tensor([[-0.5142, -2.4236],
        [-0.5561, -0.8557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02865896187722683
Epoch 0, Step 949: train/loss = 0.9271888732910156, train/raw-loss = 0.7597439885139465, train/logprobs = tensor([[-2.4363, -2.3776],
        [-2.6482, -2.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055814970284700394
Epoch 0, Step 950: train/loss = 0.6313440799713135, train/raw-loss = 0.5224766731262207, train/logprobs = tensor([[-1.4644, -2.1631],
        [-1.7214, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628912940621376
Epoch 0, Step 951: train/loss = 0.640886127948761, train/raw-loss = 0.569831907749176, train/logprobs = tensor([[-1.0418, -0.9752],
        [-1.4820, -0.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023684751242399216
Epoch 0, Step 952: train/loss = 0.48666828870773315, train/raw-loss = 0.3563334345817566, train/logprobs = tensor([[-1.3525, -1.9517],
        [-2.8242, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043444953858852386
Epoch 0, Step 953: train/loss = 0.4877604842185974, train/raw-loss = 0.3710785508155823, train/logprobs = tensor([[-0.7204, -2.7069],
        [-1.3889, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03889396786689758
Epoch 0, Step 954: train/loss = 0.5060413479804993, train/raw-loss = 0.39402633905410767, train/logprobs = tensor([[-0.8505, -2.1274],
        [-1.8984, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037338338792324066
Epoch 0, Step 955: train/loss = 0.4127725660800934, train/raw-loss = 0.28142136335372925, train/logprobs = tensor([[-0.9470, -3.5196],
        [-1.6246, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04378373920917511
Epoch 0, Step 956: train/loss = 0.6733724474906921, train/raw-loss = 0.5932865142822266, train/logprobs = tensor([[-2.3133, -3.4625],
        [-2.5080, -3.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026695312932133675
Epoch 0, Step 957: train/loss = 0.5920074582099915, train/raw-loss = 0.46326056122779846, train/logprobs = tensor([[-1.2768, -2.5299],
        [-1.5673, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042915645986795425
Epoch 0, Step 958: train/loss = 0.5731658935546875, train/raw-loss = 0.44117558002471924, train/logprobs = tensor([[-1.0117, -1.6481],
        [-1.7259, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04399676248431206
Epoch 0, Step 959: train/loss = 0.561558723449707, train/raw-loss = 0.4576320946216583, train/logprobs = tensor([[-0.8537, -1.9282],
        [-1.4661, -0.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034642208367586136
Epoch 0, Step 960: train/loss = 0.49747735261917114, train/raw-loss = 0.39733049273490906, train/logprobs = tensor([[-0.7284, -3.6035],
        [-0.7325, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03338227793574333
Epoch 0, Step 961: train/loss = 0.4636916518211365, train/raw-loss = 0.3439487814903259, train/logprobs = tensor([[-1.0827, -3.4860],
        [-1.5530, -0.8055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03991427272558212
Epoch 0, Step 962: train/loss = 0.44959694147109985, train/raw-loss = 0.30298054218292236, train/logprobs = tensor([[-1.0094, -2.7543],
        [-2.1307, -0.9937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04887213185429573
Epoch 0, Step 963: train/loss = 0.8430598974227905, train/raw-loss = 0.7205747365951538, train/logprobs = tensor([[-0.9452, -2.2829],
        [-1.4563, -1.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0408283956348896
Epoch 0, Step 964: train/loss = 0.8182218074798584, train/raw-loss = 0.6308988332748413, train/logprobs = tensor([[-1.0875, -2.4267],
        [-2.3342, -2.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06244100630283356
Epoch 0, Step 965: train/loss = 0.49975478649139404, train/raw-loss = 0.3777434527873993, train/logprobs = tensor([[-1.0034, -3.1671],
        [-1.7267, -1.6033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04067043960094452
Epoch 0, Step 966: train/loss = 0.5587912797927856, train/raw-loss = 0.4511846899986267, train/logprobs = tensor([[-0.8926, -2.0294],
        [-1.3978, -1.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03586885705590248
Epoch 0, Step 967: train/loss = 0.40953052043914795, train/raw-loss = 0.30893391370773315, train/logprobs = tensor([[-0.7190, -3.9852],
        [-0.8151, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033532194793224335
Epoch 0, Step 968: train/loss = 0.6363404393196106, train/raw-loss = 0.5187927484512329, train/logprobs = tensor([[-1.2906, -1.0688],
        [-2.1247, -0.6086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03918254375457764
Epoch 0, Step 969: train/loss = 0.5303399562835693, train/raw-loss = 0.44255805015563965, train/logprobs = tensor([[-0.8438, -2.4890],
        [-0.8194, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029260635375976562
Epoch 0, Step 970: train/loss = 0.5128968954086304, train/raw-loss = 0.3756651282310486, train/logprobs = tensor([[-0.8206, -3.8067],
        [-1.3748, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045743927359580994
Epoch 0, Step 971: train/loss = 0.6527292728424072, train/raw-loss = 0.5928706526756287, train/logprobs = tensor([[-0.4993, -1.0252],
        [-0.5015, -0.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019952867180109024
Epoch 0, Step 972: train/loss = 0.3902468681335449, train/raw-loss = 0.2510295510292053, train/logprobs = tensor([[-0.8749, -3.3359],
        [-1.9354, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04640577733516693
Epoch 0, Step 973: train/loss = 0.5557836890220642, train/raw-loss = 0.43621528148651123, train/logprobs = tensor([[-0.8036, -2.5597],
        [-1.2202, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03985614702105522
Epoch 0, Step 974: train/loss = 0.4286521077156067, train/raw-loss = 0.30712565779685974, train/logprobs = tensor([[-0.9620, -3.3756],
        [-1.4197, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04050881415605545
Epoch 0, Step 975: train/loss = 0.5171672105789185, train/raw-loss = 0.4245382845401764, train/logprobs = tensor([[-1.4702, -1.7489],
        [-2.2206, -0.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030876312404870987
Epoch 0, Step 976: train/loss = 0.5536064505577087, train/raw-loss = 0.45522427558898926, train/logprobs = tensor([[-0.7750, -1.6160],
        [-1.3824, -0.7441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03279406577348709
Epoch 0, Step 977: train/loss = 0.4608706831932068, train/raw-loss = 0.35052692890167236, train/logprobs = tensor([[-0.6694, -3.5220],
        [-0.7265, -1.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03678125515580177
Epoch 0, Step 978: train/loss = 0.5359529852867126, train/raw-loss = 0.4282359480857849, train/logprobs = tensor([[-1.0080, -2.2962],
        [-1.9570, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03590567409992218
Epoch 0, Step 979: train/loss = 0.5971667170524597, train/raw-loss = 0.49936819076538086, train/logprobs = tensor([[-1.0894, -2.1178],
        [-1.4938, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03259952366352081
Epoch 0, Step 980: train/loss = 0.46944352984428406, train/raw-loss = 0.3422509431838989, train/logprobs = tensor([[-1.1164, -1.8288],
        [-2.1258, -0.7932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042397528886795044
Epoch 0, Step 981: train/loss = 0.5442542433738708, train/raw-loss = 0.43926742672920227, train/logprobs = tensor([[-0.9036, -2.7769],
        [-1.3513, -1.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034995611757040024
Epoch 0, Step 982: train/loss = 0.6808059811592102, train/raw-loss = 0.5536084175109863, train/logprobs = tensor([[-1.3812, -2.6005],
        [-1.7744, -1.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04239918664097786
Epoch 0, Step 983: train/loss = 0.6645081639289856, train/raw-loss = 0.5577430129051208, train/logprobs = tensor([[-1.2949, -1.1772],
        [-1.4253, -0.5598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035588379949331284
Epoch 0, Step 984: train/loss = 0.4846097230911255, train/raw-loss = 0.3572872281074524, train/logprobs = tensor([[-0.7981, -2.6317],
        [-1.3766, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04244082421064377
Epoch 0, Step 985: train/loss = 0.3976133465766907, train/raw-loss = 0.26499783992767334, train/logprobs = tensor([[-1.1020, -2.9915],
        [-2.1866, -0.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04420517012476921
Epoch 0, Step 986: train/loss = 0.4346954822540283, train/raw-loss = 0.2831419110298157, train/logprobs = tensor([[-1.4085, -1.3032],
        [-3.2723, -0.6144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05051785707473755
Epoch 0, Step 987: train/loss = 0.5140299201011658, train/raw-loss = 0.40953829884529114, train/logprobs = tensor([[-1.2816, -2.4047],
        [-1.5342, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03483054041862488
Epoch 0, Step 988: train/loss = 0.735101580619812, train/raw-loss = 0.5835290551185608, train/logprobs = tensor([[-1.1485, -2.6425],
        [-2.0822, -2.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050524160265922546
Epoch 0, Step 989: train/loss = 0.5544219017028809, train/raw-loss = 0.44211021065711975, train/logprobs = tensor([[-0.7811, -3.0092],
        [-0.9213, -1.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037437234073877335
Epoch 0, Step 990: train/loss = 0.6328660845756531, train/raw-loss = 0.5038585066795349, train/logprobs = tensor([[-0.8176, -2.0854],
        [-1.0644, -1.1225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04300251975655556
Epoch 0, Step 991: train/loss = 0.7007277607917786, train/raw-loss = 0.6115562915802002, train/logprobs = tensor([[-0.9351, -1.3166],
        [-0.8573, -0.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029723823070526123
Epoch 0, Step 992: train/loss = 0.39885959029197693, train/raw-loss = 0.2565266489982605, train/logprobs = tensor([[-1.1027, -5.2760],
        [-2.1291, -2.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04744432121515274
Epoch 0, Step 993: train/loss = 0.5055822134017944, train/raw-loss = 0.3869009017944336, train/logprobs = tensor([[-0.9296, -3.4336],
        [-1.4152, -1.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03956042230129242
Epoch 0, Step 994: train/loss = 0.5214928388595581, train/raw-loss = 0.37136876583099365, train/logprobs = tensor([[-1.0354, -1.9919],
        [-2.3706, -1.2338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05004137381911278
Epoch 0, Step 995: train/loss = 0.43913453817367554, train/raw-loss = 0.32427576184272766, train/logprobs = tensor([[-0.9524, -3.2743],
        [-1.5597, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038286250084638596
Epoch 0, Step 996: train/loss = 0.5478672385215759, train/raw-loss = 0.4475904405117035, train/logprobs = tensor([[-1.6734, -4.2473],
        [-1.8726, -2.8680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03342560678720474
Epoch 0, Step 997: train/loss = 0.575048565864563, train/raw-loss = 0.47264236211776733, train/logprobs = tensor([[-1.5326, -2.4504],
        [-1.6286, -0.6028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034135401248931885
Epoch 0, Step 998: train/loss = 0.5127912759780884, train/raw-loss = 0.3834074139595032, train/logprobs = tensor([[-1.1345, -2.9319],
        [-1.5595, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04312794655561447
Epoch 0, Step 999: train/loss = 0.5081445574760437, train/raw-loss = 0.3688465654850006, train/logprobs = tensor([[-1.6405, -4.1018],
        [-1.5364, -0.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046432655304670334
Loss is nan
eval/loss: 0.533979058265686
Epoch 0, Step 1000: train/loss = 0.671742856502533, train/raw-loss = 0.5625953674316406, train/logprobs = tensor([[-0.5607, -1.7263],
        [-0.5697, -0.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03638250380754471
Epoch 0, Step 1001: train/loss = 0.45594295859336853, train/raw-loss = 0.3165818154811859, train/logprobs = tensor([[-1.2073, -2.7724],
        [-2.1709, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04645371437072754
Epoch 0, Step 1002: train/loss = 0.5139552354812622, train/raw-loss = 0.4222874641418457, train/logprobs = tensor([[-0.5361, -2.7441],
        [-0.5470, -0.8003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030555924400687218
Epoch 0, Step 1003: train/loss = 0.5848727226257324, train/raw-loss = 0.5045254230499268, train/logprobs = tensor([[-1.0147, -2.4239],
        [-1.0688, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026782430708408356
Epoch 0, Step 1004: train/loss = 0.38155215978622437, train/raw-loss = 0.2329540103673935, train/logprobs = tensor([[-1.4075, -2.4736],
        [-3.7588, -1.4551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04953271523118019
Epoch 0, Step 1005: train/loss = 0.43031173944473267, train/raw-loss = 0.33654704689979553, train/logprobs = tensor([[-1.2368, -7.7139],
        [-1.5177, -5.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031254902482032776
Epoch 0, Step 1006: train/loss = 0.4794505834579468, train/raw-loss = 0.370464026927948, train/logprobs = tensor([[-0.9128, -3.1636],
        [-1.3804, -1.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03632885962724686
Epoch 0, Step 1007: train/loss = 0.61388099193573, train/raw-loss = 0.4914940297603607, train/logprobs = tensor([[-1.1173, -1.7864],
        [-1.5232, -0.7833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040795642882585526
Epoch 0, Step 1008: train/loss = 0.5847175717353821, train/raw-loss = 0.4747774302959442, train/logprobs = tensor([[-1.3627, -3.0568],
        [-1.2147, -1.2418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664672374725342
Epoch 0, Step 1009: train/loss = 0.7260462045669556, train/raw-loss = 0.5517326593399048, train/logprobs = tensor([[-0.8140, -2.7165],
        [-1.8960, -1.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05810454115271568
Epoch 0, Step 1010: train/loss = 0.6214727163314819, train/raw-loss = 0.49820268154144287, train/logprobs = tensor([[-1.1485, -1.9332],
        [-1.3949, -0.6920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04109000787138939
Epoch 0, Step 1011: train/loss = 0.5440329313278198, train/raw-loss = 0.4600942134857178, train/logprobs = tensor([[-0.8141, -2.6839],
        [-0.8365, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027979586273431778
Epoch 0, Step 1012: train/loss = 0.6359050273895264, train/raw-loss = 0.515389084815979, train/logprobs = tensor([[-1.8219, -2.3885],
        [-2.6389, -1.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04017196223139763
Epoch 0, Step 1013: train/loss = 0.509648859500885, train/raw-loss = 0.4049437642097473, train/logprobs = tensor([[-0.6485, -2.6661],
        [-0.6071, -0.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0349017009139061
Epoch 0, Step 1014: train/loss = 0.6028944849967957, train/raw-loss = 0.5387178659439087, train/logprobs = tensor([[-0.8613, -2.4170],
        [-0.7703, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021392187103629112
Epoch 0, Step 1015: train/loss = 0.5007981657981873, train/raw-loss = 0.3783907890319824, train/logprobs = tensor([[-1.4717, -2.0129],
        [-2.6331, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04080243781208992
Epoch 0, Step 1016: train/loss = 0.4123411178588867, train/raw-loss = 0.2755468487739563, train/logprobs = tensor([[-1.2763, -3.2366],
        [-2.5075, -0.9914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04559808969497681
Epoch 0, Step 1017: train/loss = 0.6112896800041199, train/raw-loss = 0.5128764510154724, train/logprobs = tensor([[-1.4700, -2.3649],
        [-1.3891, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032804422080516815
Epoch 0, Step 1018: train/loss = 0.5978379249572754, train/raw-loss = 0.493565171957016, train/logprobs = tensor([[-0.9345, -1.4061],
        [-1.3511, -0.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0347575806081295
Epoch 0, Step 1019: train/loss = 0.44685685634613037, train/raw-loss = 0.35210874676704407, train/logprobs = tensor([[-1.1464, -2.8724],
        [-2.0135, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03158271312713623
Epoch 0, Step 1020: train/loss = 0.6997331380844116, train/raw-loss = 0.5547146797180176, train/logprobs = tensor([[-1.8998, -2.0297],
        [-1.9556, -0.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048339489847421646
Epoch 0, Step 1021: train/loss = 0.6097257733345032, train/raw-loss = 0.5168149471282959, train/logprobs = tensor([[-1.7426, -3.3171],
        [-1.7555, -1.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030970271676778793
Epoch 0, Step 1022: train/loss = 0.541325569152832, train/raw-loss = 0.4479605555534363, train/logprobs = tensor([[-1.0121, -3.0263],
        [-1.0454, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03112168237566948
Epoch 0, Step 1023: train/loss = 0.6556570529937744, train/raw-loss = 0.549148678779602, train/logprobs = tensor([[-0.7588, -2.0698],
        [-1.1108, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03550278767943382
Epoch 0, Step 1024: train/loss = 0.46164393424987793, train/raw-loss = 0.3574241101741791, train/logprobs = tensor([[-1.2872, -3.4201],
        [-1.7796, -1.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03473994880914688
Epoch 0, Step 1025: train/loss = 0.41541773080825806, train/raw-loss = 0.2705114781856537, train/logprobs = tensor([[-0.9737, -3.0904],
        [-2.4659, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04830209165811539
Epoch 0, Step 1026: train/loss = 0.45273661613464355, train/raw-loss = 0.33908334374427795, train/logprobs = tensor([[-0.9958, -3.6944],
        [-1.6768, -1.6565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0378844290971756
Epoch 0, Step 1027: train/loss = 0.4405021071434021, train/raw-loss = 0.3274349570274353, train/logprobs = tensor([[-1.0067, -4.3787],
        [-1.3996, -2.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03768905624747276
Epoch 0, Step 1028: train/loss = 0.3856815695762634, train/raw-loss = 0.25763747096061707, train/logprobs = tensor([[-0.7384, -4.6979],
        [-1.2237, -1.3289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04268136993050575
Epoch 0, Step 1029: train/loss = 0.5532105565071106, train/raw-loss = 0.4282236695289612, train/logprobs = tensor([[-1.0567, -1.9477],
        [-1.8429, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041662298142910004
Epoch 0, Step 1030: train/loss = 0.4854605197906494, train/raw-loss = 0.34319359064102173, train/logprobs = tensor([[-1.0620, -2.5522],
        [-1.7926, -1.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04742230847477913
Epoch 0, Step 1031: train/loss = 0.45131826400756836, train/raw-loss = 0.3567197322845459, train/logprobs = tensor([[-0.7181, -3.4060],
        [-0.7302, -0.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03153284266591072
Epoch 0, Step 1032: train/loss = 0.7961090207099915, train/raw-loss = 0.7314457297325134, train/logprobs = tensor([[-1.2977, -0.6950],
        [-0.9607, -0.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021554434671998024
Epoch 0, Step 1033: train/loss = 0.3866545557975769, train/raw-loss = 0.2593711018562317, train/logprobs = tensor([[-0.9527, -5.1215],
        [-1.4586, -1.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04242781549692154
Epoch 0, Step 1034: train/loss = 0.4586133658885956, train/raw-loss = 0.3350312113761902, train/logprobs = tensor([[-0.7464, -3.3240],
        [-1.1534, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04119405522942543
Epoch 0, Step 1035: train/loss = 0.47073179483413696, train/raw-loss = 0.3565308451652527, train/logprobs = tensor([[-0.7088, -3.6891],
        [-0.7415, -1.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03806697204709053
Epoch 0, Step 1036: train/loss = 0.5196596384048462, train/raw-loss = 0.39374977350234985, train/logprobs = tensor([[-0.9652, -2.5445],
        [-1.8178, -1.2115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04196995496749878
Epoch 0, Step 1037: train/loss = 0.5037422776222229, train/raw-loss = 0.4090549945831299, train/logprobs = tensor([[-1.2910, -2.3017],
        [-2.1035, -1.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031562428921461105
Epoch 0, Step 1038: train/loss = 0.6531571745872498, train/raw-loss = 0.5502092242240906, train/logprobs = tensor([[-0.9821, -2.1301],
        [-0.8520, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03431599587202072
Epoch 0, Step 1039: train/loss = 0.5250164866447449, train/raw-loss = 0.4382917582988739, train/logprobs = tensor([[-0.9863, -2.3046],
        [-1.7698, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02890823408961296
Epoch 0, Step 1040: train/loss = 0.45177149772644043, train/raw-loss = 0.31366264820098877, train/logprobs = tensor([[-1.1321, -1.9402],
        [-2.3823, -0.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04603628069162369
Epoch 0, Step 1041: train/loss = 0.582450807094574, train/raw-loss = 0.4591456651687622, train/logprobs = tensor([[-0.7644, -2.6163],
        [-1.4213, -1.4094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04110170900821686
Epoch 0, Step 1042: train/loss = 0.5475374460220337, train/raw-loss = 0.45760378241539, train/logprobs = tensor([[-0.7087, -2.5211],
        [-0.7079, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029977886006236076
Epoch 0, Step 1043: train/loss = 0.5261682868003845, train/raw-loss = 0.4221002459526062, train/logprobs = tensor([[-1.1389, -2.5841],
        [-1.6611, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034689344465732574
Epoch 0, Step 1044: train/loss = 0.5261528491973877, train/raw-loss = 0.4057573080062866, train/logprobs = tensor([[-1.7090, -3.8913],
        [-2.0831, -2.1107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04013184458017349
Epoch 0, Step 1045: train/loss = 0.6914488077163696, train/raw-loss = 0.604463517665863, train/logprobs = tensor([[-0.6684, -1.3056],
        [-0.6873, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0289950929582119
Epoch 0, Step 1046: train/loss = 0.5640204548835754, train/raw-loss = 0.47710639238357544, train/logprobs = tensor([[-1.3352, -2.4604],
        [-1.4799, -1.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028971362859010696
Epoch 0, Step 1047: train/loss = 0.5260509252548218, train/raw-loss = 0.3946714401245117, train/logprobs = tensor([[-1.0558, -2.2374],
        [-1.9061, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043793171644210815
Epoch 0, Step 1048: train/loss = 0.5606213212013245, train/raw-loss = 0.46264156699180603, train/logprobs = tensor([[-0.5323, -1.9430],
        [-1.0295, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03265991806983948
Epoch 0, Step 1049: train/loss = 0.7423065900802612, train/raw-loss = 0.6604247093200684, train/logprobs = tensor([[-1.1283, -1.0690],
        [-1.1512, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027293965220451355
Epoch 0, Step 1050: train/loss = 0.6174813508987427, train/raw-loss = 0.486001580953598, train/logprobs = tensor([[-0.9521, -2.4305],
        [-0.9284, -0.9535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04382660239934921
Epoch 0, Step 1051: train/loss = 0.623926043510437, train/raw-loss = 0.5212593078613281, train/logprobs = tensor([[-1.0985, -1.7785],
        [-1.5576, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03422226011753082
Epoch 0, Step 1052: train/loss = 0.40343689918518066, train/raw-loss = 0.2860742211341858, train/logprobs = tensor([[-0.9625, -3.7726],
        [-1.5576, -1.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03912089020013809
Epoch 0, Step 1053: train/loss = 0.6044200658798218, train/raw-loss = 0.47465452551841736, train/logprobs = tensor([[-0.8242, -1.4752],
        [-1.3249, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04325518384575844
Epoch 0, Step 1054: train/loss = 0.4686186909675598, train/raw-loss = 0.38754802942276, train/logprobs = tensor([[-0.7818, -3.7949],
        [-0.7838, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027023538947105408
Epoch 0, Step 1055: train/loss = 0.3619527816772461, train/raw-loss = 0.1938760131597519, train/logprobs = tensor([[-1.1736, -3.1930],
        [-2.9269, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05602559447288513
Epoch 0, Step 1056: train/loss = 0.6823221445083618, train/raw-loss = 0.6216497421264648, train/logprobs = tensor([[-1.0283, -1.3012],
        [-1.1266, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02022414654493332
Epoch 0, Step 1057: train/loss = 0.7224841117858887, train/raw-loss = 0.5888559818267822, train/logprobs = tensor([[-0.9112, -2.1392],
        [-0.9522, -1.6648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04454270005226135
Epoch 0, Step 1058: train/loss = 0.502757728099823, train/raw-loss = 0.37122488021850586, train/logprobs = tensor([[-1.0941, -1.9528],
        [-2.1155, -0.5338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04384428262710571
Epoch 0, Step 1059: train/loss = 0.5688654780387878, train/raw-loss = 0.4516434371471405, train/logprobs = tensor([[-1.0274, -3.2463],
        [-1.5508, -1.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03907399624586105
Epoch 0, Step 1060: train/loss = 0.5641125440597534, train/raw-loss = 0.49180054664611816, train/logprobs = tensor([[-0.5859, -2.9672],
        [-0.5985, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024103999137878418
Epoch 0, Step 1061: train/loss = 0.4523111581802368, train/raw-loss = 0.3145707845687866, train/logprobs = tensor([[-1.3914, -4.0683],
        [-1.9398, -1.3208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045913465321063995
Epoch 0, Step 1062: train/loss = 0.6713218688964844, train/raw-loss = 0.6047667860984802, train/logprobs = tensor([[-0.9191, -0.8139],
        [-1.1807, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022185033187270164
Epoch 0, Step 1063: train/loss = 0.8939962387084961, train/raw-loss = 0.7855044603347778, train/logprobs = tensor([[-1.6903, -1.4081],
        [-1.4696, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03616393357515335
Epoch 0, Step 1064: train/loss = 0.49349093437194824, train/raw-loss = 0.3890218138694763, train/logprobs = tensor([[-0.8022, -3.1447],
        [-0.8435, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03482303395867348
Epoch 0, Step 1065: train/loss = 0.3799952268600464, train/raw-loss = 0.25690191984176636, train/logprobs = tensor([[-0.8092, -4.4576],
        [-1.5594, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04103110358119011
Epoch 0, Step 1066: train/loss = 0.5837624073028564, train/raw-loss = 0.5154647827148438, train/logprobs = tensor([[-1.1507, -2.0786],
        [-1.1083, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022765878587961197
Epoch 0, Step 1067: train/loss = 0.6275112628936768, train/raw-loss = 0.545617401599884, train/logprobs = tensor([[-0.6537, -2.9875],
        [-0.6664, -1.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027297966182231903
Epoch 0, Step 1068: train/loss = 0.42956340312957764, train/raw-loss = 0.298541784286499, train/logprobs = tensor([[-1.0450, -3.8433],
        [-1.5720, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04367387294769287
Epoch 0, Step 1069: train/loss = 0.43823933601379395, train/raw-loss = 0.3149041533470154, train/logprobs = tensor([[-0.9414, -2.9954],
        [-2.0673, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04111173376441002
Epoch 0, Step 1070: train/loss = 0.4793720841407776, train/raw-loss = 0.35259774327278137, train/logprobs = tensor([[-1.1465, -3.4634],
        [-2.3518, -2.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042258121073246
Epoch 0, Step 1071: train/loss = 0.6494980454444885, train/raw-loss = 0.5630977153778076, train/logprobs = tensor([[-1.0940, -1.1914],
        [-1.4807, -0.7476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028800111263990402
Epoch 0, Step 1072: train/loss = 0.4721148610115051, train/raw-loss = 0.3361823558807373, train/logprobs = tensor([[-0.9591, -2.0916],
        [-2.1732, -0.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0453108511865139
Epoch 0, Step 1073: train/loss = 0.622279167175293, train/raw-loss = 0.5126321911811829, train/logprobs = tensor([[-1.2575, -1.6543],
        [-1.5783, -0.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036549001932144165
Epoch 0, Step 1074: train/loss = 0.5711118578910828, train/raw-loss = 0.4648158550262451, train/logprobs = tensor([[-0.9827, -1.0623],
        [-1.9878, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03543200343847275
Epoch 0, Step 1075: train/loss = 0.5357564091682434, train/raw-loss = 0.4399937093257904, train/logprobs = tensor([[-0.7503, -2.0093],
        [-1.1308, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031920891255140305
Epoch 0, Step 1076: train/loss = 0.5324211716651917, train/raw-loss = 0.43007317185401917, train/logprobs = tensor([[-0.8645, -2.6500],
        [-0.9869, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034115999937057495
Epoch 0, Step 1077: train/loss = 0.5218964219093323, train/raw-loss = 0.43879029154777527, train/logprobs = tensor([[-0.8490, -3.0251],
        [-0.9810, -1.2050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027702046558260918
Epoch 0, Step 1078: train/loss = 0.4371225833892822, train/raw-loss = 0.33205029368400574, train/logprobs = tensor([[-1.3517, -3.6408],
        [-2.1298, -1.3111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035024091601371765
Epoch 0, Step 1079: train/loss = 0.4504358768463135, train/raw-loss = 0.34664130210876465, train/logprobs = tensor([[-0.9527, -3.2490],
        [-1.3742, -0.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03459819033741951
Epoch 0, Step 1080: train/loss = 0.6645018458366394, train/raw-loss = 0.5869350433349609, train/logprobs = tensor([[-0.8110, -0.5596],
        [-1.3523, -0.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025855598971247673
Epoch 0, Step 1081: train/loss = 0.4861440658569336, train/raw-loss = 0.3897826373577118, train/logprobs = tensor([[-0.7646, -2.5201],
        [-1.2614, -0.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321204774081707
Epoch 0, Step 1082: train/loss = 0.45892733335494995, train/raw-loss = 0.36903247237205505, train/logprobs = tensor([[-0.6122, -3.8736],
        [-0.6384, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029964951798319817
Epoch 0, Step 1083: train/loss = 0.4736131727695465, train/raw-loss = 0.36130568385124207, train/logprobs = tensor([[-0.8483, -3.1762],
        [-1.4874, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03743582218885422
Epoch 0, Step 1084: train/loss = 0.4519769847393036, train/raw-loss = 0.3462609350681305, train/logprobs = tensor([[-1.1385, -3.2849],
        [-1.4925, -1.1099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03523869067430496
Epoch 0, Step 1085: train/loss = 0.8082541227340698, train/raw-loss = 0.6785858869552612, train/logprobs = tensor([[-1.3786, -1.7949],
        [-1.8491, -1.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04322276636958122
Epoch 0, Step 1086: train/loss = 0.4629397690296173, train/raw-loss = 0.36761200428009033, train/logprobs = tensor([[-0.8908, -3.3709],
        [-1.6251, -1.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031775910407304764
Epoch 0, Step 1087: train/loss = 0.6021820306777954, train/raw-loss = 0.5094062685966492, train/logprobs = tensor([[-2.4630, -3.1027],
        [-3.0134, -2.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030925240367650986
Epoch 0, Step 1088: train/loss = 0.4862363338470459, train/raw-loss = 0.3713667690753937, train/logprobs = tensor([[-1.0330, -2.4341],
        [-1.8377, -1.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03828985616564751
Epoch 0, Step 1089: train/loss = 0.572229266166687, train/raw-loss = 0.46872812509536743, train/logprobs = tensor([[-0.8767, -2.2827],
        [-1.0899, -1.2610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0345003679394722
Epoch 0, Step 1090: train/loss = 0.4453670382499695, train/raw-loss = 0.340547114610672, train/logprobs = tensor([[-0.9662, -2.0315],
        [-2.1259, -1.0952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0349399708211422
Epoch 0, Step 1091: train/loss = 0.41500401496887207, train/raw-loss = 0.30226317048072815, train/logprobs = tensor([[-1.1300, -3.7484],
        [-1.7662, -1.6130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03758028894662857
Epoch 0, Step 1092: train/loss = 0.5682051181793213, train/raw-loss = 0.49010154604911804, train/logprobs = tensor([[-0.5821, -2.5411],
        [-0.6279, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026034515351057053
Epoch 0, Step 1093: train/loss = 0.5894781351089478, train/raw-loss = 0.4656951129436493, train/logprobs = tensor([[-1.3323, -2.8100],
        [-2.1931, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04126099497079849
Epoch 0, Step 1094: train/loss = 0.4620974063873291, train/raw-loss = 0.3482351005077362, train/logprobs = tensor([[-1.4170, -3.8468],
        [-1.7153, -1.5708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03795410320162773
Epoch 0, Step 1095: train/loss = 0.4273850917816162, train/raw-loss = 0.31307095289230347, train/logprobs = tensor([[-0.9452, -1.6497],
        [-2.5217, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03810470551252365
Epoch 0, Step 1096: train/loss = 0.5015894770622253, train/raw-loss = 0.38428235054016113, train/logprobs = tensor([[-1.6079, -2.4227],
        [-2.2199, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03910239785909653
Epoch 0, Step 1097: train/loss = 0.44476309418678284, train/raw-loss = 0.35237306356430054, train/logprobs = tensor([[-1.0268, -4.6828],
        [-1.1874, -2.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030796688050031662
Epoch 0, Step 1098: train/loss = 0.5220816135406494, train/raw-loss = 0.4288526475429535, train/logprobs = tensor([[-0.9045, -3.6986],
        [-0.9851, -1.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03107631765305996
Epoch 0, Step 1099: train/loss = 0.4740234613418579, train/raw-loss = 0.37465327978134155, train/logprobs = tensor([[-0.8045, -2.7906],
        [-1.3694, -1.1739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03312339633703232
Epoch 0, Step 1100: train/loss = 0.4916198253631592, train/raw-loss = 0.3744410276412964, train/logprobs = tensor([[-1.0989, -3.4825],
        [-1.6371, -1.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0390595905482769
Epoch 0, Step 1101: train/loss = 0.5388823747634888, train/raw-loss = 0.43663978576660156, train/logprobs = tensor([[-1.2041, -3.1250],
        [-1.2331, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03408084809780121
Epoch 0, Step 1102: train/loss = 0.44755932688713074, train/raw-loss = 0.34316426515579224, train/logprobs = tensor([[-1.6123, -3.4368],
        [-1.8562, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034798361361026764
Epoch 0, Step 1103: train/loss = 0.4130136966705322, train/raw-loss = 0.31574058532714844, train/logprobs = tensor([[-0.9157, -3.4175],
        [-1.2912, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03242438659071922
Epoch 0, Step 1104: train/loss = 0.4940504729747772, train/raw-loss = 0.4103705585002899, train/logprobs = tensor([[-0.7827, -3.2070],
        [-0.7438, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0278933048248291
Epoch 0, Step 1105: train/loss = 0.44514691829681396, train/raw-loss = 0.34022995829582214, train/logprobs = tensor([[-0.9968, -3.8529],
        [-1.3936, -1.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03497232124209404
Epoch 0, Step 1106: train/loss = 0.3863840699195862, train/raw-loss = 0.25335806608200073, train/logprobs = tensor([[-1.0697, -2.9995],
        [-2.2380, -1.0354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04434198886156082
Epoch 0, Step 1107: train/loss = 0.44428718090057373, train/raw-loss = 0.32475149631500244, train/logprobs = tensor([[-1.0996, -2.4965],
        [-1.8800, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03984522074460983
Epoch 0, Step 1108: train/loss = 0.3979191482067108, train/raw-loss = 0.30393075942993164, train/logprobs = tensor([[-1.3155, -3.3772],
        [-2.2767, -1.6203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03132946044206619
Epoch 0, Step 1109: train/loss = 0.5551177263259888, train/raw-loss = 0.4722186028957367, train/logprobs = tensor([[-0.9540, -2.5641],
        [-0.8191, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027633043006062508
Epoch 0, Step 1110: train/loss = 0.4274369776248932, train/raw-loss = 0.320462167263031, train/logprobs = tensor([[-1.4180, -4.2760],
        [-1.8404, -1.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03565827012062073
Epoch 0, Step 1111: train/loss = 0.5627715587615967, train/raw-loss = 0.462686151266098, train/logprobs = tensor([[-1.1874, -2.1439],
        [-1.8263, -1.4671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03336178883910179
Epoch 0, Step 1112: train/loss = 0.5154505372047424, train/raw-loss = 0.42961812019348145, train/logprobs = tensor([[-0.6113, -3.4074],
        [-0.5937, -1.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02861079014837742
Epoch 0, Step 1113: train/loss = 0.4928743839263916, train/raw-loss = 0.3666175603866577, train/logprobs = tensor([[-1.0644, -2.4129],
        [-1.9582, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04208560287952423
Epoch 0, Step 1114: train/loss = 0.44573208689689636, train/raw-loss = 0.34552931785583496, train/logprobs = tensor([[-1.0284, -4.3816],
        [-1.0035, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03340093046426773
Epoch 0, Step 1115: train/loss = 0.3762396574020386, train/raw-loss = 0.2540609538555145, train/logprobs = tensor([[-1.0216, -4.1473],
        [-1.9062, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04072622209787369
Epoch 0, Step 1116: train/loss = 0.45168963074684143, train/raw-loss = 0.34045231342315674, train/logprobs = tensor([[-1.5540, -2.0554],
        [-2.6933, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0370790995657444
Epoch 0, Step 1117: train/loss = 0.34703513979911804, train/raw-loss = 0.21356061100959778, train/logprobs = tensor([[-1.2630, -3.6113],
        [-2.7625, -1.2642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04449151083827019
Epoch 0, Step 1118: train/loss = 0.789400577545166, train/raw-loss = 0.6884815692901611, train/logprobs = tensor([[-1.3820, -2.8474],
        [-1.5342, -2.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03363966941833496
Epoch 0, Step 1119: train/loss = 0.4465450644493103, train/raw-loss = 0.35638484358787537, train/logprobs = tensor([[-0.7370, -3.1105],
        [-1.3532, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030053405091166496
Epoch 0, Step 1120: train/loss = 0.3752443194389343, train/raw-loss = 0.2811565101146698, train/logprobs = tensor([[-1.1441, -5.6979],
        [-1.6792, -1.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031362611800432205
Epoch 0, Step 1121: train/loss = 0.34189093112945557, train/raw-loss = 0.21612954139709473, train/logprobs = tensor([[-1.7356, -3.0673],
        [-3.0121, -1.0679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04192046821117401
Epoch 0, Step 1122: train/loss = 0.547588586807251, train/raw-loss = 0.4575616121292114, train/logprobs = tensor([[-0.9196, -1.5423],
        [-1.7369, -1.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030008986592292786
Epoch 0, Step 1123: train/loss = 0.4891277253627777, train/raw-loss = 0.39099305868148804, train/logprobs = tensor([[-0.8414, -2.6645],
        [-1.1692, -1.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032711565494537354
Epoch 0, Step 1124: train/loss = 0.35301920771598816, train/raw-loss = 0.22658316791057587, train/logprobs = tensor([[-1.6094, -2.5998],
        [-3.2250, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042145341634750366
Epoch 0, Step 1125: train/loss = 0.6145501732826233, train/raw-loss = 0.5428038835525513, train/logprobs = tensor([[-0.7826, -1.4030],
        [-0.9968, -0.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02391543798148632
Epoch 0, Step 1126: train/loss = 0.45732322335243225, train/raw-loss = 0.35483813285827637, train/logprobs = tensor([[-1.1267, -3.6825],
        [-1.9052, -2.2608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03416169434785843
Epoch 0, Step 1127: train/loss = 0.4612695574760437, train/raw-loss = 0.3356420695781708, train/logprobs = tensor([[-1.1197, -3.9428],
        [-1.3548, -1.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04187583178281784
Epoch 0, Step 1128: train/loss = 0.42062312364578247, train/raw-loss = 0.2921336889266968, train/logprobs = tensor([[-1.4107, -4.9640],
        [-2.3515, -3.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042829811573028564
Epoch 0, Step 1129: train/loss = 0.6002504825592041, train/raw-loss = 0.5414636731147766, train/logprobs = tensor([[-0.7765, -2.1697],
        [-0.6264, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01959560438990593
Epoch 0, Step 1130: train/loss = 0.5368420481681824, train/raw-loss = 0.43626946210861206, train/logprobs = tensor([[-0.9622, -2.7584],
        [-1.2969, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03352419659495354
Epoch 0, Step 1131: train/loss = 0.4916283190250397, train/raw-loss = 0.3944379389286041, train/logprobs = tensor([[-1.2707, -3.3935],
        [-1.5961, -1.6614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03239680081605911
Epoch 0, Step 1132: train/loss = 0.5559036731719971, train/raw-loss = 0.46526724100112915, train/logprobs = tensor([[-1.2975, -2.1344],
        [-1.8134, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030212143436074257
Epoch 0, Step 1133: train/loss = 0.5033241510391235, train/raw-loss = 0.39835119247436523, train/logprobs = tensor([[-1.1523, -1.5095],
        [-2.2728, -0.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03499099984765053
Epoch 0, Step 1134: train/loss = 0.5420584678649902, train/raw-loss = 0.45549383759498596, train/logprobs = tensor([[-1.2721, -2.5417],
        [-1.6300, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028854884207248688
Epoch 0, Step 1135: train/loss = 0.5435247421264648, train/raw-loss = 0.44517362117767334, train/logprobs = tensor([[-1.1289, -1.9462],
        [-1.4071, -0.8500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03278370946645737
Epoch 0, Step 1136: train/loss = 0.515598475933075, train/raw-loss = 0.4388105273246765, train/logprobs = tensor([[-0.5505, -3.0664],
        [-0.5489, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025595974177122116
Epoch 0, Step 1137: train/loss = 0.5100778937339783, train/raw-loss = 0.4039074778556824, train/logprobs = tensor([[-1.0120, -2.1984],
        [-1.8892, -1.3540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03539014235138893
Epoch 0, Step 1138: train/loss = 0.5805672407150269, train/raw-loss = 0.5078039765357971, train/logprobs = tensor([[-1.9091, -2.4653],
        [-2.6334, -2.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02425443008542061
Epoch 0, Step 1139: train/loss = 0.6742429733276367, train/raw-loss = 0.5688665509223938, train/logprobs = tensor([[-1.0408, -1.9508],
        [-1.3877, -1.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035125479102134705
Epoch 0, Step 1140: train/loss = 0.5034371614456177, train/raw-loss = 0.42075884342193604, train/logprobs = tensor([[-0.6147, -3.1357],
        [-0.5395, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02755943313241005
Epoch 0, Step 1141: train/loss = 0.6532202959060669, train/raw-loss = 0.5899806022644043, train/logprobs = tensor([[-1.1995, -1.0197],
        [-1.5375, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02107989229261875
Epoch 0, Step 1142: train/loss = 0.3648734986782074, train/raw-loss = 0.2286711484193802, train/logprobs = tensor([[-1.2736, -2.0346],
        [-3.1405, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04540077969431877
Epoch 0, Step 1143: train/loss = 0.5612580180168152, train/raw-loss = 0.46927905082702637, train/logprobs = tensor([[-0.8880, -2.5982],
        [-0.9510, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030659636482596397
Epoch 0, Step 1144: train/loss = 0.4648573100566864, train/raw-loss = 0.37579411268234253, train/logprobs = tensor([[-0.9364, -2.8698],
        [-1.5322, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02968772128224373
Epoch 0, Step 1145: train/loss = 0.45634371042251587, train/raw-loss = 0.3522121012210846, train/logprobs = tensor([[-0.9955, -2.8446],
        [-1.6247, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03471053019165993
Epoch 0, Step 1146: train/loss = 0.5274447202682495, train/raw-loss = 0.43621817231178284, train/logprobs = tensor([[-0.9836, -2.1494],
        [-1.4932, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0304088331758976
Epoch 0, Step 1147: train/loss = 0.6347249150276184, train/raw-loss = 0.5582408905029297, train/logprobs = tensor([[-0.8496, -1.0559],
        [-1.2746, -0.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02549467235803604
Epoch 0, Step 1148: train/loss = 0.5969937443733215, train/raw-loss = 0.5078210234642029, train/logprobs = tensor([[-1.0125, -0.8989],
        [-1.6459, -0.4918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029724234715104103
Epoch 0, Step 1149: train/loss = 0.3944909870624542, train/raw-loss = 0.27224475145339966, train/logprobs = tensor([[-1.0586, -3.1252],
        [-2.1170, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04074874520301819
Epoch 0, Step 1150: train/loss = 0.5154499411582947, train/raw-loss = 0.42048847675323486, train/logprobs = tensor([[-0.8410, -3.2481],
        [-1.1819, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03165382146835327
Epoch 0, Step 1151: train/loss = 0.5535246729850769, train/raw-loss = 0.4610745310783386, train/logprobs = tensor([[-1.3778, -2.6379],
        [-2.2843, -2.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030816715210676193
Epoch 0, Step 1152: train/loss = 0.3884841799736023, train/raw-loss = 0.2923421859741211, train/logprobs = tensor([[-1.2844, -4.5003],
        [-1.9743, -1.5498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0320473313331604
Epoch 0, Step 1153: train/loss = 0.4713563323020935, train/raw-loss = 0.3758449852466583, train/logprobs = tensor([[-1.0640, -2.6561],
        [-1.6858, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03183712437748909
Epoch 0, Step 1154: train/loss = 0.48373132944107056, train/raw-loss = 0.40311187505722046, train/logprobs = tensor([[-0.8260, -2.0753],
        [-1.3845, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0268731489777565
Epoch 0, Step 1155: train/loss = 0.4909323751926422, train/raw-loss = 0.3787182867527008, train/logprobs = tensor([[-1.3434, -1.1196],
        [-3.0754, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03740469366312027
Epoch 0, Step 1156: train/loss = 0.4308926463127136, train/raw-loss = 0.3291018009185791, train/logprobs = tensor([[-0.8344, -2.5717],
        [-1.7500, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03393029421567917
Epoch 0, Step 1157: train/loss = 0.5407775640487671, train/raw-loss = 0.443023145198822, train/logprobs = tensor([[-1.0781, -1.6669],
        [-2.0067, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03258479759097099
Epoch 0, Step 1158: train/loss = 0.5044068098068237, train/raw-loss = 0.42113009095191956, train/logprobs = tensor([[-0.8634, -2.4162],
        [-1.4095, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02775891125202179
Epoch 0, Step 1159: train/loss = 0.36279934644699097, train/raw-loss = 0.261271595954895, train/logprobs = tensor([[-1.1574, -4.8867],
        [-1.7143, -1.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03384258225560188
Epoch 0, Step 1160: train/loss = 0.6823527216911316, train/raw-loss = 0.6001091599464417, train/logprobs = tensor([[-0.9924, -1.5423],
        [-0.8116, -0.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027414504438638687
Epoch 0, Step 1161: train/loss = 0.45450592041015625, train/raw-loss = 0.35404136776924133, train/logprobs = tensor([[-0.9383, -3.0807],
        [-1.6335, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03348818048834801
Epoch 0, Step 1162: train/loss = 0.4687389135360718, train/raw-loss = 0.36408084630966187, train/logprobs = tensor([[-0.9685, -1.6876],
        [-2.0634, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03488602489233017
Epoch 0, Step 1163: train/loss = 0.6074337959289551, train/raw-loss = 0.526053249835968, train/logprobs = tensor([[-1.6235, -1.8302],
        [-2.0307, -1.2410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027126837521791458
Epoch 0, Step 1164: train/loss = 0.4763680100440979, train/raw-loss = 0.3739544749259949, train/logprobs = tensor([[-1.1563, -2.1674],
        [-2.1005, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034137845039367676
Epoch 0, Step 1165: train/loss = 0.6142454743385315, train/raw-loss = 0.5502322912216187, train/logprobs = tensor([[-0.8859, -1.1985],
        [-1.0301, -0.5946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0213377196341753
Epoch 0, Step 1166: train/loss = 0.48411089181900024, train/raw-loss = 0.4021647870540619, train/logprobs = tensor([[-0.8640, -2.1463],
        [-1.5014, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02731536701321602
Epoch 0, Step 1167: train/loss = 0.7004978060722351, train/raw-loss = 0.625288724899292, train/logprobs = tensor([[-1.0295, -1.6196],
        [-1.2253, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0250697024166584
Epoch 0, Step 1168: train/loss = 0.5728003978729248, train/raw-loss = 0.47868451476097107, train/logprobs = tensor([[-0.8888, -1.1477],
        [-1.7454, -0.7021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031371958553791046
Epoch 0, Step 1169: train/loss = 0.37720972299575806, train/raw-loss = 0.27773818373680115, train/logprobs = tensor([[-1.0119, -3.0132],
        [-1.9885, -0.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03315717726945877
Epoch 0, Step 1170: train/loss = 0.7491471171379089, train/raw-loss = 0.6592981815338135, train/logprobs = tensor([[-0.7786, -0.9060],
        [-0.7154, -0.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029949648305773735
Epoch 0, Step 1171: train/loss = 0.5943320989608765, train/raw-loss = 0.5090789794921875, train/logprobs = tensor([[-0.9574, -2.1475],
        [-0.9838, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028417695313692093
Epoch 0, Step 1172: train/loss = 0.5519678592681885, train/raw-loss = 0.4725733995437622, train/logprobs = tensor([[-1.0351, -3.2565],
        [-0.9871, -1.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026464806869626045
Epoch 0, Step 1173: train/loss = 0.5913330316543579, train/raw-loss = 0.46526697278022766, train/logprobs = tensor([[-1.1765, -2.2113],
        [-1.8598, -1.2329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04202203452587128
Epoch 0, Step 1174: train/loss = 0.6939219236373901, train/raw-loss = 0.6061824560165405, train/logprobs = tensor([[-1.8524, -1.7577],
        [-1.9830, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02924647554755211
Epoch 0, Step 1175: train/loss = 0.5235837697982788, train/raw-loss = 0.4349200129508972, train/logprobs = tensor([[-1.3029, -2.8994],
        [-2.2267, -1.5776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029554586857557297
Epoch 0, Step 1176: train/loss = 0.5540841817855835, train/raw-loss = 0.4560941457748413, train/logprobs = tensor([[-1.0444, -2.1950],
        [-1.6609, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03266334533691406
Epoch 0, Step 1177: train/loss = 0.4120807647705078, train/raw-loss = 0.29078468680381775, train/logprobs = tensor([[-0.9793, -4.4964],
        [-1.8936, -1.4958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04043202847242355
Epoch 0, Step 1178: train/loss = 0.682060182094574, train/raw-loss = 0.6206116676330566, train/logprobs = tensor([[-1.2405, -1.5369],
        [-1.2347, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02048281952738762
Epoch 0, Step 1179: train/loss = 0.4418752193450928, train/raw-loss = 0.35467052459716797, train/logprobs = tensor([[-0.8029, -4.3196],
        [-0.7466, -1.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0290682390332222
Epoch 0, Step 1180: train/loss = 0.4856896996498108, train/raw-loss = 0.39228272438049316, train/logprobs = tensor([[-1.3787, -3.8630],
        [-2.2331, -1.7710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031135648488998413
Epoch 0, Step 1181: train/loss = 0.584800124168396, train/raw-loss = 0.5057138800621033, train/logprobs = tensor([[-1.4591, -2.4888],
        [-1.6620, -1.4534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02636207453906536
Epoch 0, Step 1182: train/loss = 0.4806525409221649, train/raw-loss = 0.35551199316978455, train/logprobs = tensor([[-1.1889, -2.7341],
        [-2.4894, -1.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04171350970864296
Epoch 0, Step 1183: train/loss = 0.539188802242279, train/raw-loss = 0.4510704576969147, train/logprobs = tensor([[-1.2801, -1.4906],
        [-2.1455, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02937278524041176
Epoch 0, Step 1184: train/loss = 0.6793417930603027, train/raw-loss = 0.6324267387390137, train/logprobs = tensor([[-1.4734, -1.5024],
        [-1.5450, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015638330951333046
Epoch 0, Step 1185: train/loss = 0.5204832553863525, train/raw-loss = 0.4480969309806824, train/logprobs = tensor([[-1.2771, -3.2716],
        [-1.7161, -1.7307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024128776043653488
Epoch 0, Step 1186: train/loss = 0.590449333190918, train/raw-loss = 0.4929259717464447, train/logprobs = tensor([[-1.2363, -1.3731],
        [-1.9688, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03250777721405029
Epoch 0, Step 1187: train/loss = 0.5476334095001221, train/raw-loss = 0.4765744209289551, train/logprobs = tensor([[-0.9105, -2.7708],
        [-0.8255, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02368633635342121
Epoch 0, Step 1188: train/loss = 0.4120381772518158, train/raw-loss = 0.3129368722438812, train/logprobs = tensor([[-0.7525, -3.5659],
        [-1.1758, -1.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03303377330303192
Epoch 0, Step 1189: train/loss = 0.6436526775360107, train/raw-loss = 0.5653836727142334, train/logprobs = tensor([[-0.8274, -2.2116],
        [-0.7260, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026089686900377274
Epoch 0, Step 1190: train/loss = 0.5535837411880493, train/raw-loss = 0.4545920491218567, train/logprobs = tensor([[-1.4355, -2.0057],
        [-1.8752, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0329972468316555
Epoch 0, Step 1191: train/loss = 0.5226415395736694, train/raw-loss = 0.43491673469543457, train/logprobs = tensor([[-0.8916, -1.9516],
        [-1.5842, -0.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029241599142551422
Epoch 0, Step 1192: train/loss = 0.4975207448005676, train/raw-loss = 0.40466585755348206, train/logprobs = tensor([[-0.6287, -2.5672],
        [-1.0878, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030951621010899544
Epoch 0, Step 1193: train/loss = 0.5080397129058838, train/raw-loss = 0.3972027599811554, train/logprobs = tensor([[-1.2204, -3.4319],
        [-1.2687, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03694566711783409
Epoch 0, Step 1194: train/loss = 0.573948085308075, train/raw-loss = 0.4780333936214447, train/logprobs = tensor([[-1.4814, -2.5645],
        [-1.6453, -1.0805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03197156637907028
Epoch 0, Step 1195: train/loss = 0.4624325633049011, train/raw-loss = 0.343986839056015, train/logprobs = tensor([[-1.0785, -2.2501],
        [-2.4589, -1.5448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03948191925883293
Epoch 0, Step 1196: train/loss = 0.669049859046936, train/raw-loss = 0.5750871896743774, train/logprobs = tensor([[-2.4084, -3.1470],
        [-2.3157, -1.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03132089227437973
Epoch 0, Step 1197: train/loss = 0.5624223947525024, train/raw-loss = 0.4651801884174347, train/logprobs = tensor([[-0.9437, -2.5287],
        [-1.3376, -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032414067536592484
Epoch 0, Step 1198: train/loss = 0.6712696552276611, train/raw-loss = 0.6135711669921875, train/logprobs = tensor([[-0.7997, -1.2193],
        [-0.8089, -0.7648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01923283189535141
Epoch 0, Step 1199: train/loss = 0.47884151339530945, train/raw-loss = 0.3626580834388733, train/logprobs = tensor([[-1.0143, -3.0005],
        [-1.9108, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03872780501842499
Epoch 0, Step 1200: train/loss = 0.388205349445343, train/raw-loss = 0.30368590354919434, train/logprobs = tensor([[-0.6201, -5.5275],
        [-0.6592, -1.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028173144906759262
Epoch 0, Step 1201: train/loss = 0.3678780794143677, train/raw-loss = 0.25273483991622925, train/logprobs = tensor([[-1.3253, -2.3875],
        [-3.4784, -0.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038381073623895645
Epoch 0, Step 1202: train/loss = 0.6192370653152466, train/raw-loss = 0.5470833778381348, train/logprobs = tensor([[-1.3982, -2.6834],
        [-1.1588, -1.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0240512415766716
Epoch 0, Step 1203: train/loss = 0.5320518016815186, train/raw-loss = 0.4370674788951874, train/logprobs = tensor([[-0.8751, -3.2304],
        [-1.3154, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03166143596172333
Epoch 0, Step 1204: train/loss = 0.6416918039321899, train/raw-loss = 0.5763505697250366, train/logprobs = tensor([[-0.8054, -0.8409],
        [-1.2413, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02178039401769638
Epoch 0, Step 1205: train/loss = 0.4368872344493866, train/raw-loss = 0.3291735053062439, train/logprobs = tensor([[-1.1015, -2.4918],
        [-1.8635, -0.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03590457886457443
Epoch 0, Step 1206: train/loss = 0.5089538097381592, train/raw-loss = 0.3697476387023926, train/logprobs = tensor([[-1.2931, -3.2062],
        [-2.2977, -1.4851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046402059495449066
Epoch 0, Step 1207: train/loss = 0.40718841552734375, train/raw-loss = 0.29785215854644775, train/logprobs = tensor([[-0.9529, -2.5325],
        [-2.0303, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03644542023539543
Epoch 0, Step 1208: train/loss = 0.5567514896392822, train/raw-loss = 0.47672930359840393, train/logprobs = tensor([[-0.6769, -4.5545],
        [-0.6204, -2.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026674047112464905
Epoch 0, Step 1209: train/loss = 0.46402716636657715, train/raw-loss = 0.3617512583732605, train/logprobs = tensor([[-0.9792, -2.1990],
        [-1.9938, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03409195318818092
Epoch 0, Step 1210: train/loss = 0.5609084963798523, train/raw-loss = 0.47074535489082336, train/logprobs = tensor([[-0.8048, -1.8116],
        [-1.5032, -0.9124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030054382979869843
Epoch 0, Step 1211: train/loss = 0.6763699650764465, train/raw-loss = 0.610702633857727, train/logprobs = tensor([[-2.1357, -2.8796],
        [-1.8474, -2.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021889127790927887
Epoch 0, Step 1212: train/loss = 0.7812141180038452, train/raw-loss = 0.6884760856628418, train/logprobs = tensor([[-2.1104, -2.1295],
        [-2.8995, -1.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030912678688764572
Epoch 0, Step 1213: train/loss = 0.5418362617492676, train/raw-loss = 0.4645448923110962, train/logprobs = tensor([[-0.6685, -2.7234],
        [-0.6610, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025763804093003273
Epoch 0, Step 1214: train/loss = 0.45308560132980347, train/raw-loss = 0.3703324794769287, train/logprobs = tensor([[-0.8330, -3.6177],
        [-1.2303, -1.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027584383264183998
Epoch 0, Step 1215: train/loss = 0.527472198009491, train/raw-loss = 0.4344126582145691, train/logprobs = tensor([[-0.8857, -2.6592],
        [-0.9920, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03101983666419983
Epoch 0, Step 1216: train/loss = 0.5479272603988647, train/raw-loss = 0.44935140013694763, train/logprobs = tensor([[-0.8801, -3.2269],
        [-0.9554, -1.2088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03285861015319824
Epoch 0, Step 1217: train/loss = 0.3436760902404785, train/raw-loss = 0.23854351043701172, train/logprobs = tensor([[-0.9170, -5.4653],
        [-1.5915, -1.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035044193267822266
Epoch 0, Step 1218: train/loss = 0.5116385817527771, train/raw-loss = 0.39348578453063965, train/logprobs = tensor([[-1.2719, -2.1638],
        [-2.1305, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03938426077365875
Epoch 0, Step 1219: train/loss = 0.5843626260757446, train/raw-loss = 0.4788495898246765, train/logprobs = tensor([[-1.3318, -3.1299],
        [-1.6315, -2.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035171009600162506
Epoch 0, Step 1220: train/loss = 0.519340455532074, train/raw-loss = 0.39376723766326904, train/logprobs = tensor([[-0.9622, -5.3572],
        [-1.7069, -1.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0418577566742897
Epoch 0, Step 1221: train/loss = 0.4047812223434448, train/raw-loss = 0.2998339533805847, train/logprobs = tensor([[-1.1693, -4.0376],
        [-2.9271, -2.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03498242795467377
Epoch 0, Step 1222: train/loss = 0.3776899576187134, train/raw-loss = 0.26781412959098816, train/logprobs = tensor([[-1.2978, -3.6046],
        [-2.0892, -1.4370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03662528097629547
Epoch 0, Step 1223: train/loss = 0.6382755041122437, train/raw-loss = 0.5009365677833557, train/logprobs = tensor([[-1.4600, -2.4161],
        [-2.2040, -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045779645442962646
Epoch 0, Step 1224: train/loss = 0.5686098337173462, train/raw-loss = 0.4914414584636688, train/logprobs = tensor([[-0.8957, -3.0257],
        [-0.8544, -1.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025722771883010864
Epoch 0, Step 1225: train/loss = 0.5995180606842041, train/raw-loss = 0.48467329144477844, train/logprobs = tensor([[-0.9895, -2.3083],
        [-2.0105, -1.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038281600922346115
Epoch 0, Step 1226: train/loss = 0.5599480271339417, train/raw-loss = 0.4370676577091217, train/logprobs = tensor([[-1.1416, -2.9082],
        [-1.8515, -1.1694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04096011817455292
Epoch 0, Step 1227: train/loss = 0.4473341703414917, train/raw-loss = 0.34236231446266174, train/logprobs = tensor([[-1.0290, -5.3759],
        [-1.2929, -1.7299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034990619868040085
Epoch 0, Step 1228: train/loss = 0.575928807258606, train/raw-loss = 0.4858006536960602, train/logprobs = tensor([[-1.1571, -2.5351],
        [-1.4041, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030042733997106552
Epoch 0, Step 1229: train/loss = 0.37544241547584534, train/raw-loss = 0.26527950167655945, train/logprobs = tensor([[-0.9280, -3.6524],
        [-1.6525, -1.3742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036720968782901764
Epoch 0, Step 1230: train/loss = 0.37944167852401733, train/raw-loss = 0.2938048243522644, train/logprobs = tensor([[-1.2029, -4.6692],
        [-1.2477, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028545619919896126
Epoch 0, Step 1231: train/loss = 0.42575541138648987, train/raw-loss = 0.28915590047836304, train/logprobs = tensor([[-1.3418, -2.5361],
        [-2.7083, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045533161610364914
Epoch 0, Step 1232: train/loss = 0.4410882890224457, train/raw-loss = 0.3676125407218933, train/logprobs = tensor([[-0.9072, -3.5205],
        [-0.9922, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02449190989136696
Epoch 0, Step 1233: train/loss = 0.5129027962684631, train/raw-loss = 0.4297511577606201, train/logprobs = tensor([[-0.5764, -2.3446],
        [-0.9657, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027717221528291702
Epoch 0, Step 1234: train/loss = 0.6068768501281738, train/raw-loss = 0.5292490720748901, train/logprobs = tensor([[-1.0603, -1.9973],
        [-1.4298, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025875940918922424
Epoch 0, Step 1235: train/loss = 0.4683147370815277, train/raw-loss = 0.38493335247039795, train/logprobs = tensor([[-0.9915, -2.9363],
        [-1.0863, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027793778106570244
Epoch 0, Step 1236: train/loss = 0.4721064865589142, train/raw-loss = 0.36928996443748474, train/logprobs = tensor([[-1.1666, -2.7906],
        [-1.7483, -1.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034272175282239914
Epoch 0, Step 1237: train/loss = 0.526488184928894, train/raw-loss = 0.42716076970100403, train/logprobs = tensor([[-1.2526, -2.5745],
        [-1.9061, -1.1848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03310912847518921
Epoch 0, Step 1238: train/loss = 0.6710519790649414, train/raw-loss = 0.5862460136413574, train/logprobs = tensor([[-1.4133, -2.5937],
        [-0.9148, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02826867252588272
Epoch 0, Step 1239: train/loss = 0.6909257173538208, train/raw-loss = 0.6107571125030518, train/logprobs = tensor([[-2.0704, -1.7373],
        [-2.0547, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026722893118858337
Epoch 0, Step 1240: train/loss = 0.439527690410614, train/raw-loss = 0.3182614743709564, train/logprobs = tensor([[-0.9358, -2.4451],
        [-1.8595, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04042207449674606
Epoch 0, Step 1241: train/loss = 0.5539222359657288, train/raw-loss = 0.4710577428340912, train/logprobs = tensor([[-0.8763, -0.9754],
        [-1.9241, -0.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027621503919363022
Epoch 0, Step 1242: train/loss = 0.6227705478668213, train/raw-loss = 0.534965991973877, train/logprobs = tensor([[-1.5243, -2.8236],
        [-1.4848, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029268156737089157
Epoch 0, Step 1243: train/loss = 0.4502503573894501, train/raw-loss = 0.34238624572753906, train/logprobs = tensor([[-1.7667, -4.6197],
        [-1.9330, -1.4081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035954687744379044
Epoch 0, Step 1244: train/loss = 0.509527862071991, train/raw-loss = 0.3738742768764496, train/logprobs = tensor([[-1.5375, -2.5414],
        [-3.3355, -1.7632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045217856764793396
Epoch 0, Step 1245: train/loss = 0.4505918622016907, train/raw-loss = 0.3295467793941498, train/logprobs = tensor([[-0.9567, -2.4465],
        [-2.1425, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0403483584523201
Epoch 0, Step 1246: train/loss = 0.4717751741409302, train/raw-loss = 0.3416675925254822, train/logprobs = tensor([[-0.8831, -4.3962],
        [-1.7590, -1.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04336920380592346
Epoch 0, Step 1247: train/loss = 0.47518983483314514, train/raw-loss = 0.387009859085083, train/logprobs = tensor([[-0.8477, -2.7764],
        [-1.1357, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029393315315246582
Epoch 0, Step 1248: train/loss = 0.4024268090724945, train/raw-loss = 0.2986604869365692, train/logprobs = tensor([[-1.5786, -5.3109],
        [-2.3828, -2.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034588772803545
Epoch 0, Step 1249: train/loss = 0.5201887488365173, train/raw-loss = 0.429401695728302, train/logprobs = tensor([[-1.1505, -1.8456],
        [-2.0546, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030262358486652374
Epoch 0, Step 1250: train/loss = 0.5339099764823914, train/raw-loss = 0.4537159204483032, train/logprobs = tensor([[-1.0920, -2.5875],
        [-1.2512, -0.8681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02673134207725525
Epoch 0, Step 1251: train/loss = 0.6899591088294983, train/raw-loss = 0.5937649011611938, train/logprobs = tensor([[-0.7584, -2.4532],
        [-1.3469, -1.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03206473961472511
Epoch 0, Step 1252: train/loss = 0.5586305856704712, train/raw-loss = 0.4547838866710663, train/logprobs = tensor([[-1.0085, -1.5734],
        [-1.8277, -0.6393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03461555764079094
Epoch 0, Step 1253: train/loss = 0.3822922706604004, train/raw-loss = 0.2791576087474823, train/logprobs = tensor([[-1.2433, -3.2706],
        [-2.6142, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03437821567058563
Epoch 0, Step 1254: train/loss = 0.4603074789047241, train/raw-loss = 0.38811421394348145, train/logprobs = tensor([[-0.7128, -3.9698],
        [-0.7403, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02406442165374756
Epoch 0, Step 1255: train/loss = 0.49964848160743713, train/raw-loss = 0.3789524435997009, train/logprobs = tensor([[-0.8143, -2.3483],
        [-1.6917, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040232010185718536
Epoch 0, Step 1256: train/loss = 0.5474275350570679, train/raw-loss = 0.44516828656196594, train/logprobs = tensor([[-0.9612, -2.6240],
        [-1.1936, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0340864360332489
Epoch 0, Step 1257: train/loss = 0.47643929719924927, train/raw-loss = 0.3809064030647278, train/logprobs = tensor([[-1.4092, -2.6248],
        [-2.0318, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03184428811073303
Epoch 0, Step 1258: train/loss = 0.7073687314987183, train/raw-loss = 0.6226320266723633, train/logprobs = tensor([[-0.8147, -2.1488],
        [-1.3142, -1.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028245562687516212
Epoch 0, Step 1259: train/loss = 0.4343246817588806, train/raw-loss = 0.35060539841651917, train/logprobs = tensor([[-1.0033, -2.4568],
        [-1.5556, -0.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027906427159905434
Epoch 0, Step 1260: train/loss = 0.4581780731678009, train/raw-loss = 0.3333350419998169, train/logprobs = tensor([[-1.2984, -3.4974],
        [-2.0832, -1.7538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0416143499314785
Epoch 0, Step 1261: train/loss = 0.41110533475875854, train/raw-loss = 0.3090965449810028, train/logprobs = tensor([[-1.1075, -3.3687],
        [-1.8379, -1.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03400292620062828
Epoch 0, Step 1262: train/loss = 0.5543930530548096, train/raw-loss = 0.4758896231651306, train/logprobs = tensor([[-0.8667, -2.8935],
        [-0.8941, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026167813688516617
Epoch 0, Step 1263: train/loss = 0.5944581031799316, train/raw-loss = 0.5326552391052246, train/logprobs = tensor([[-0.6436, -1.8739],
        [-0.6538, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020600955933332443
Epoch 0, Step 1264: train/loss = 0.5146064162254333, train/raw-loss = 0.4040529727935791, train/logprobs = tensor([[-0.8217, -2.5060],
        [-1.5038, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03685116022825241
Epoch 0, Step 1265: train/loss = 0.4974530041217804, train/raw-loss = 0.386070191860199, train/logprobs = tensor([[-1.1436, -1.9762],
        [-1.9771, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03712760657072067
Epoch 0, Step 1266: train/loss = 0.41324448585510254, train/raw-loss = 0.299502432346344, train/logprobs = tensor([[-1.0117, -4.5135],
        [-1.6570, -1.3495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037914030253887177
Epoch 0, Step 1267: train/loss = 0.7471398711204529, train/raw-loss = 0.6485760807991028, train/logprobs = tensor([[-1.2506, -1.7473],
        [-1.3707, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0328545942902565
Epoch 0, Step 1268: train/loss = 0.5886691808700562, train/raw-loss = 0.5317798256874084, train/logprobs = tensor([[-0.5345, -1.7348],
        [-0.6064, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01896311156451702
Epoch 0, Step 1269: train/loss = 0.49653303623199463, train/raw-loss = 0.37062105536460876, train/logprobs = tensor([[-0.8469, -2.5373],
        [-1.6057, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041970644146203995
Epoch 0, Step 1270: train/loss = 0.42757612466812134, train/raw-loss = 0.3264945447444916, train/logprobs = tensor([[-1.4062, -3.5314],
        [-1.7832, -0.8352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03369387239217758
Epoch 0, Step 1271: train/loss = 0.47311264276504517, train/raw-loss = 0.36848101019859314, train/logprobs = tensor([[-0.6167, -3.4747],
        [-1.0205, -1.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03487720340490341
Epoch 0, Step 1272: train/loss = 0.7680619955062866, train/raw-loss = 0.6920852661132812, train/logprobs = tensor([[-0.6252, -1.0644],
        [-0.6911, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025325577706098557
Epoch 0, Step 1273: train/loss = 0.6086301803588867, train/raw-loss = 0.5173138380050659, train/logprobs = tensor([[-0.8886, -1.1212],
        [-1.3750, -0.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030438778921961784
Epoch 0, Step 1274: train/loss = 0.46941620111465454, train/raw-loss = 0.37057024240493774, train/logprobs = tensor([[-0.8440, -3.6052],
        [-2.1354, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032948654145002365
Epoch 0, Step 1275: train/loss = 0.4228653311729431, train/raw-loss = 0.31827008724212646, train/logprobs = tensor([[-1.2009, -3.3411],
        [-1.9786, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03486508131027222
Epoch 0, Step 1276: train/loss = 0.5216132402420044, train/raw-loss = 0.4387388527393341, train/logprobs = tensor([[-1.3148, -2.1307],
        [-2.0658, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027624793350696564
Epoch 0, Step 1277: train/loss = 0.5090012550354004, train/raw-loss = 0.43900632858276367, train/logprobs = tensor([[-0.9009, -3.0314],
        [-0.8386, -0.9979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02333165518939495
Epoch 0, Step 1278: train/loss = 0.538563072681427, train/raw-loss = 0.4523518681526184, train/logprobs = tensor([[-1.1477, -2.4606],
        [-1.1695, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02873704954981804
Epoch 0, Step 1279: train/loss = 0.45923689007759094, train/raw-loss = 0.3691219389438629, train/logprobs = tensor([[-0.5844, -3.0348],
        [-1.0802, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03003831021487713
Epoch 0, Step 1280: train/loss = 0.5692968368530273, train/raw-loss = 0.4902784526348114, train/logprobs = tensor([[-1.5147, -2.5577],
        [-1.5813, -1.2331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0263394583016634
Epoch 0, Step 1281: train/loss = 0.40420496463775635, train/raw-loss = 0.3339118957519531, train/logprobs = tensor([[-0.5331, -3.6021],
        [-0.6040, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023431021720170975
Epoch 0, Step 1282: train/loss = 0.48182111978530884, train/raw-loss = 0.36972230672836304, train/logprobs = tensor([[-1.1775, -3.3452],
        [-1.7152, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03736628219485283
Epoch 0, Step 1283: train/loss = 0.6315500140190125, train/raw-loss = 0.5685129761695862, train/logprobs = tensor([[-0.5554, -1.6424],
        [-0.5024, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02101234719157219
Epoch 0, Step 1284: train/loss = 0.608090877532959, train/raw-loss = 0.5391864776611328, train/logprobs = tensor([[-1.5094, -2.9723],
        [-1.5924, -1.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022968130186200142
Epoch 0, Step 1285: train/loss = 0.624663770198822, train/raw-loss = 0.5124420523643494, train/logprobs = tensor([[-1.4532, -2.1698],
        [-2.0112, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037407223135232925
Epoch 0, Step 1286: train/loss = 0.6156007051467896, train/raw-loss = 0.5447968244552612, train/logprobs = tensor([[-1.8146, -1.7419],
        [-2.9342, -1.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02360127866268158
Epoch 0, Step 1287: train/loss = 0.5465121269226074, train/raw-loss = 0.47542575001716614, train/logprobs = tensor([[-1.3098, -2.9545],
        [-1.5668, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0236954465508461
Epoch 0, Step 1288: train/loss = 0.5579088926315308, train/raw-loss = 0.44674593210220337, train/logprobs = tensor([[-0.9834, -2.5003],
        [-1.1736, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03705433011054993
Epoch 0, Step 1289: train/loss = 0.7662340402603149, train/raw-loss = 0.6446781158447266, train/logprobs = tensor([[-1.6769, -2.3539],
        [-1.5816, -1.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04051865637302399
Epoch 0, Step 1290: train/loss = 0.5962866544723511, train/raw-loss = 0.4648585915565491, train/logprobs = tensor([[-1.5348, -4.2826],
        [-2.4036, -1.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043809372931718826
Epoch 0, Step 1291: train/loss = 0.5459968447685242, train/raw-loss = 0.4469672441482544, train/logprobs = tensor([[-0.9220, -2.7964],
        [-1.5667, -1.4205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03300987556576729
Epoch 0, Step 1292: train/loss = 0.5166968703269958, train/raw-loss = 0.4193609654903412, train/logprobs = tensor([[-1.4081, -2.1541],
        [-1.9206, -0.7597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03244530037045479
Epoch 0, Step 1293: train/loss = 0.46946021914482117, train/raw-loss = 0.39498263597488403, train/logprobs = tensor([[-1.3292, -4.7871],
        [-1.4136, -2.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02482585608959198
Epoch 0, Step 1294: train/loss = 0.4956393241882324, train/raw-loss = 0.4199768304824829, train/logprobs = tensor([[-0.7461, -2.6601],
        [-1.0189, -0.8869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025220833718776703
Epoch 0, Step 1295: train/loss = 0.4264223873615265, train/raw-loss = 0.31580469012260437, train/logprobs = tensor([[-0.8014, -2.0898],
        [-2.2084, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036872562021017075
Epoch 0, Step 1296: train/loss = 0.5251051187515259, train/raw-loss = 0.4270174205303192, train/logprobs = tensor([[-0.8756, -1.1417],
        [-1.9903, -0.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03269590809941292
Epoch 0, Step 1297: train/loss = 0.555483877658844, train/raw-loss = 0.4870343804359436, train/logprobs = tensor([[-0.8153, -2.3800],
        [-0.8146, -0.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022816505283117294
Epoch 0, Step 1298: train/loss = 0.509680986404419, train/raw-loss = 0.39473167061805725, train/logprobs = tensor([[-1.5349, -1.7161],
        [-2.2216, -0.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038316428661346436
Epoch 0, Step 1299: train/loss = 0.6587963700294495, train/raw-loss = 0.5555455684661865, train/logprobs = tensor([[-0.7954, -2.4479],
        [-0.6446, -1.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03441692516207695
Epoch 0, Step 1300: train/loss = 0.4434656500816345, train/raw-loss = 0.35260021686553955, train/logprobs = tensor([[-0.8321, -3.3330],
        [-1.2172, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030288485810160637
Epoch 0, Step 1301: train/loss = 0.5888811945915222, train/raw-loss = 0.530352771282196, train/logprobs = tensor([[-0.7332, -2.4682],
        [-0.6016, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019509468227624893
Epoch 0, Step 1302: train/loss = 0.4519948661327362, train/raw-loss = 0.3483067750930786, train/logprobs = tensor([[-1.0085, -1.9012],
        [-2.1544, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03456270322203636
Epoch 0, Step 1303: train/loss = 0.47340744733810425, train/raw-loss = 0.38304680585861206, train/logprobs = tensor([[-0.8776, -2.1445],
        [-1.5277, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03012021631002426
Epoch 0, Step 1304: train/loss = 0.371232807636261, train/raw-loss = 0.24259606003761292, train/logprobs = tensor([[-0.7372, -2.6125],
        [-2.1320, -0.6281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04287891462445259
Epoch 0, Step 1305: train/loss = 0.46582677960395813, train/raw-loss = 0.36393868923187256, train/logprobs = tensor([[-0.7462, -2.5110],
        [-1.5086, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03396269306540489
Epoch 0, Step 1306: train/loss = 0.36277082562446594, train/raw-loss = 0.2552279531955719, train/logprobs = tensor([[-0.8246, -2.8732],
        [-1.8513, -0.6266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035847630351781845
Epoch 0, Step 1307: train/loss = 0.4688337445259094, train/raw-loss = 0.36801064014434814, train/logprobs = tensor([[-0.8707, -3.2074],
        [-1.9079, -1.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03360769525170326
Epoch 0, Step 1308: train/loss = 0.604135274887085, train/raw-loss = 0.5138920545578003, train/logprobs = tensor([[-1.5321, -1.8445],
        [-2.0228, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03008108213543892
Epoch 0, Step 1309: train/loss = 0.3214767277240753, train/raw-loss = 0.17618519067764282, train/logprobs = tensor([[-1.0123, -2.7179],
        [-3.4072, -0.8531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048430509865283966
Epoch 0, Step 1310: train/loss = 0.6765379309654236, train/raw-loss = 0.5810202360153198, train/logprobs = tensor([[-1.3202, -2.7514],
        [-0.7920, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031839217990636826
Epoch 0, Step 1311: train/loss = 0.5126606225967407, train/raw-loss = 0.42392605543136597, train/logprobs = tensor([[-1.3764, -2.3150],
        [-1.8686, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029578179121017456
Epoch 0, Step 1312: train/loss = 0.4973447322845459, train/raw-loss = 0.39100658893585205, train/logprobs = tensor([[-1.3226, -2.9215],
        [-1.8355, -0.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035446036607027054
Epoch 0, Step 1313: train/loss = 0.44438648223876953, train/raw-loss = 0.34733641147613525, train/logprobs = tensor([[-0.7336, -3.0868],
        [-1.1245, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032350026071071625
Epoch 0, Step 1314: train/loss = 0.42540764808654785, train/raw-loss = 0.335185706615448, train/logprobs = tensor([[-1.0632, -2.8617],
        [-1.9359, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030073974281549454
Epoch 0, Step 1315: train/loss = 0.39093664288520813, train/raw-loss = 0.2686805725097656, train/logprobs = tensor([[-0.8839, -2.4415],
        [-2.0873, -0.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040752023458480835
Epoch 0, Step 1316: train/loss = 0.4093431234359741, train/raw-loss = 0.3033677935600281, train/logprobs = tensor([[-1.1358, -2.0926],
        [-2.4166, -0.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03532511740922928
Epoch 0, Step 1317: train/loss = 0.669827401638031, train/raw-loss = 0.5947336554527283, train/logprobs = tensor([[-1.5495, -2.6631],
        [-1.2485, -1.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025031255558133125
Epoch 0, Step 1318: train/loss = 0.5959339737892151, train/raw-loss = 0.5162889957427979, train/logprobs = tensor([[-0.6697, -1.2536],
        [-1.1665, -0.6062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02654833346605301
Epoch 0, Step 1319: train/loss = 0.4047413468360901, train/raw-loss = 0.2680080235004425, train/logprobs = tensor([[-1.0823, -2.5291],
        [-2.6140, -0.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045577775686979294
Epoch 0, Step 1320: train/loss = 0.41051578521728516, train/raw-loss = 0.29143407940864563, train/logprobs = tensor([[-0.6515, -4.0317],
        [-1.1985, -0.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03969389945268631
Epoch 0, Step 1321: train/loss = 0.49449631571769714, train/raw-loss = 0.38294410705566406, train/logprobs = tensor([[-1.1544, -2.6372],
        [-1.7606, -1.1882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037184081971645355
Epoch 0, Step 1322: train/loss = 0.3946828842163086, train/raw-loss = 0.27097228169441223, train/logprobs = tensor([[-1.1024, -1.7592],
        [-3.1415, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041236862540245056
Epoch 0, Step 1323: train/loss = 0.5914427042007446, train/raw-loss = 0.4767935276031494, train/logprobs = tensor([[-0.8441, -1.6164],
        [-1.4063, -0.9185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03821640461683273
Epoch 0, Step 1324: train/loss = 0.3225402235984802, train/raw-loss = 0.21095798909664154, train/logprobs = tensor([[-1.1659, -3.9588],
        [-2.5994, -1.0843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03719408065080643
Epoch 0, Step 1325: train/loss = 0.37970128655433655, train/raw-loss = 0.25878092646598816, train/logprobs = tensor([[-1.0061, -3.2125],
        [-1.9803, -0.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040306780487298965
Epoch 0, Step 1326: train/loss = 0.4971567988395691, train/raw-loss = 0.42011940479278564, train/logprobs = tensor([[-1.3060, -2.3853],
        [-2.2913, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025679118931293488
Epoch 0, Step 1327: train/loss = 0.5715558528900146, train/raw-loss = 0.44371989369392395, train/logprobs = tensor([[-1.2394, -2.3546],
        [-1.5761, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0426119789481163
Epoch 0, Step 1328: train/loss = 0.6694894433021545, train/raw-loss = 0.6084022521972656, train/logprobs = tensor([[-1.9809, -3.6710],
        [-0.9675, -1.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020362388342618942
Epoch 0, Step 1329: train/loss = 0.6276145577430725, train/raw-loss = 0.5206704139709473, train/logprobs = tensor([[-1.6679, -1.5868],
        [-2.2000, -0.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035648051649332047
Epoch 0, Step 1330: train/loss = 0.5833464860916138, train/raw-loss = 0.4369286298751831, train/logprobs = tensor([[-1.3494, -3.7478],
        [-3.6821, -2.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04880596697330475
Epoch 0, Step 1331: train/loss = 0.42036837339401245, train/raw-loss = 0.3047625720500946, train/logprobs = tensor([[-0.8833, -3.5465],
        [-1.3572, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03853526711463928
Epoch 0, Step 1332: train/loss = 0.5086615085601807, train/raw-loss = 0.37863683700561523, train/logprobs = tensor([[-1.3906, -2.6754],
        [-2.3214, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04334155097603798
Epoch 0, Step 1333: train/loss = 0.6433490514755249, train/raw-loss = 0.564048707485199, train/logprobs = tensor([[-1.0464, -1.7770],
        [-1.0429, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026433441787958145
Epoch 0, Step 1334: train/loss = 0.468009889125824, train/raw-loss = 0.3862771987915039, train/logprobs = tensor([[-0.9776, -2.8012],
        [-1.6295, -0.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02724422514438629
Epoch 0, Step 1335: train/loss = 0.537855327129364, train/raw-loss = 0.4478667974472046, train/logprobs = tensor([[-0.5328, -1.8550],
        [-1.4086, -0.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02999618649482727
Epoch 0, Step 1336: train/loss = 0.5787134170532227, train/raw-loss = 0.49397459626197815, train/logprobs = tensor([[-0.8804, -2.6711],
        [-1.6946, -1.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028246259316802025
Epoch 0, Step 1337: train/loss = 0.5767579674720764, train/raw-loss = 0.42939820885658264, train/logprobs = tensor([[-1.1864, -3.1354],
        [-3.0378, -1.6901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04911991208791733
Epoch 0, Step 1338: train/loss = 0.5465304851531982, train/raw-loss = 0.463954895734787, train/logprobs = tensor([[-0.8214, -1.5951],
        [-1.5389, -0.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027525197714567184
Epoch 0, Step 1339: train/loss = 0.3336606025695801, train/raw-loss = 0.22410157322883606, train/logprobs = tensor([[-1.0351, -4.2798],
        [-2.1381, -1.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03651968762278557
Epoch 0, Step 1340: train/loss = 0.4938104748725891, train/raw-loss = 0.3964104950428009, train/logprobs = tensor([[-1.1003, -3.3396],
        [-1.3401, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03246666118502617
Epoch 0, Step 1341: train/loss = 0.5921226143836975, train/raw-loss = 0.5318357944488525, train/logprobs = tensor([[-1.0651, -2.4191],
        [-0.8909, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020095601677894592
Epoch 0, Step 1342: train/loss = 0.3664241433143616, train/raw-loss = 0.25641101598739624, train/logprobs = tensor([[-1.4755, -2.4176],
        [-3.6875, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036671049892902374
Epoch 0, Step 1343: train/loss = 0.3160509467124939, train/raw-loss = 0.16634903848171234, train/logprobs = tensor([[-0.8687, -4.1875],
        [-2.9234, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049900636076927185
Epoch 0, Step 1344: train/loss = 0.45846349000930786, train/raw-loss = 0.33342504501342773, train/logprobs = tensor([[-1.3457, -1.9840],
        [-2.9283, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04167947545647621
Epoch 0, Step 1345: train/loss = 0.5155471563339233, train/raw-loss = 0.3909308910369873, train/logprobs = tensor([[-1.5993, -2.1413],
        [-2.3509, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04153876006603241
Epoch 0, Step 1346: train/loss = 0.43937891721725464, train/raw-loss = 0.3149290680885315, train/logprobs = tensor([[-0.8689, -2.8927],
        [-1.6192, -1.1785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04148328676819801
Epoch 0, Step 1347: train/loss = 0.8083081245422363, train/raw-loss = 0.7079364657402039, train/logprobs = tensor([[-1.0308, -3.1078],
        [-1.4930, -2.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03345722705125809
Epoch 0, Step 1348: train/loss = 0.6709889769554138, train/raw-loss = 0.5855998992919922, train/logprobs = tensor([[-1.4843, -1.9802],
        [-1.5266, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02846302092075348
Epoch 0, Step 1349: train/loss = 0.5569847822189331, train/raw-loss = 0.5019050240516663, train/logprobs = tensor([[-0.6985, -2.5470],
        [-0.5499, -0.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01835991069674492
Epoch 0, Step 1350: train/loss = 0.8595858812332153, train/raw-loss = 0.7321274280548096, train/logprobs = tensor([[-1.5385, -1.8713],
        [-2.4033, -2.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04248616099357605
Epoch 0, Step 1351: train/loss = 0.35204648971557617, train/raw-loss = 0.24258771538734436, train/logprobs = tensor([[-1.3077, -3.0966],
        [-2.8082, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03648625314235687
Epoch 0, Step 1352: train/loss = 0.44034290313720703, train/raw-loss = 0.3685769736766815, train/logprobs = tensor([[-0.6023, -3.8176],
        [-0.6383, -1.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02392197586596012
Epoch 0, Step 1353: train/loss = 0.4613349735736847, train/raw-loss = 0.34158745408058167, train/logprobs = tensor([[-1.1038, -2.3803],
        [-1.8654, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039915841072797775
Epoch 0, Step 1354: train/loss = 0.4779617488384247, train/raw-loss = 0.4063436985015869, train/logprobs = tensor([[-1.5369, -2.4109],
        [-2.1363, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023872680962085724
Epoch 0, Step 1355: train/loss = 0.5112102031707764, train/raw-loss = 0.4214234948158264, train/logprobs = tensor([[-1.3724, -2.5888],
        [-2.1663, -1.5966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029928898438811302
Epoch 0, Step 1356: train/loss = 0.479179710149765, train/raw-loss = 0.40487080812454224, train/logprobs = tensor([[-1.0198, -3.3165],
        [-1.1581, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024769632145762444
Epoch 0, Step 1357: train/loss = 0.6453406810760498, train/raw-loss = 0.5771243572235107, train/logprobs = tensor([[-0.6611, -1.6121],
        [-0.6831, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022738777101039886
Epoch 0, Step 1358: train/loss = 0.33955711126327515, train/raw-loss = 0.21862971782684326, train/logprobs = tensor([[-0.9070, -3.5702],
        [-2.4394, -0.7729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0403091236948967
Epoch 0, Step 1359: train/loss = 0.43168604373931885, train/raw-loss = 0.35026392340660095, train/logprobs = tensor([[-0.8019, -2.6563],
        [-1.5421, -0.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027140703052282333
Epoch 0, Step 1360: train/loss = 0.6913713216781616, train/raw-loss = 0.6138578653335571, train/logprobs = tensor([[-1.9596, -3.4086],
        [-1.3613, -1.6652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02583782747387886
Epoch 0, Step 1361: train/loss = 0.5375556349754333, train/raw-loss = 0.45475876331329346, train/logprobs = tensor([[-0.9390, -2.6525],
        [-1.2973, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027598949149250984
Epoch 0, Step 1362: train/loss = 0.6384896636009216, train/raw-loss = 0.5853943228721619, train/logprobs = tensor([[-0.6010, -1.9068],
        [-0.7199, -0.8450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017698446288704872
Epoch 0, Step 1363: train/loss = 0.4897876977920532, train/raw-loss = 0.37494784593582153, train/logprobs = tensor([[-1.0231, -2.3979],
        [-2.2584, -1.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03827995806932449
Epoch 0, Step 1364: train/loss = 0.5000190734863281, train/raw-loss = 0.4121656119823456, train/logprobs = tensor([[-0.7533, -2.1746],
        [-1.4624, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029284484684467316
Epoch 0, Step 1365: train/loss = 0.5272630453109741, train/raw-loss = 0.42852649092674255, train/logprobs = tensor([[-0.7417, -1.3917],
        [-2.2927, -0.7997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032912202179431915
Epoch 0, Step 1366: train/loss = 0.5486307740211487, train/raw-loss = 0.4365408420562744, train/logprobs = tensor([[-1.4182, -2.7524],
        [-1.5416, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03736329823732376
Epoch 0, Step 1367: train/loss = 0.4966999888420105, train/raw-loss = 0.4262414276599884, train/logprobs = tensor([[-0.5205, -2.7175],
        [-0.5604, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023486196994781494
Epoch 0, Step 1368: train/loss = 0.43265214562416077, train/raw-loss = 0.34293025732040405, train/logprobs = tensor([[-0.7367, -2.9905],
        [-1.1870, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02990729734301567
Epoch 0, Step 1369: train/loss = 0.372796893119812, train/raw-loss = 0.2647518515586853, train/logprobs = tensor([[-1.0972, -4.0982],
        [-1.6345, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03601500391960144
Epoch 0, Step 1370: train/loss = 0.39262712001800537, train/raw-loss = 0.25942787528038025, train/logprobs = tensor([[-1.0194, -2.5858],
        [-3.0121, -0.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044399749487638474
Epoch 0, Step 1371: train/loss = 0.5705482363700867, train/raw-loss = 0.45600655674934387, train/logprobs = tensor([[-1.2469, -1.4058],
        [-2.4037, -0.5171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038180578500032425
Epoch 0, Step 1372: train/loss = 0.4697801470756531, train/raw-loss = 0.35412168502807617, train/logprobs = tensor([[-0.9453, -2.2926],
        [-2.0060, -0.6688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038552816957235336
Epoch 0, Step 1373: train/loss = 0.44729623198509216, train/raw-loss = 0.31290188431739807, train/logprobs = tensor([[-0.9939, -3.0095],
        [-2.2123, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044798124581575394
Epoch 0, Step 1374: train/loss = 0.37108349800109863, train/raw-loss = 0.24912045896053314, train/logprobs = tensor([[-0.8177, -4.0210],
        [-2.0578, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04065435007214546
Epoch 0, Step 1375: train/loss = 0.5468645095825195, train/raw-loss = 0.45046761631965637, train/logprobs = tensor([[-0.8458, -2.2192],
        [-1.2030, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03213229402899742
Epoch 0, Step 1376: train/loss = 0.5471735000610352, train/raw-loss = 0.4870773255825043, train/logprobs = tensor([[-0.5915, -2.3749],
        [-0.6652, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020032072439789772
Epoch 0, Step 1377: train/loss = 0.44156789779663086, train/raw-loss = 0.3352471590042114, train/logprobs = tensor([[-1.1818, -3.3981],
        [-2.0945, -0.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03544023633003235
Epoch 0, Step 1378: train/loss = 0.3306843936443329, train/raw-loss = 0.1862102895975113, train/logprobs = tensor([[-1.1119, -2.8802],
        [-3.2676, -0.6339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048158034682273865
Epoch 0, Step 1379: train/loss = 0.5294076800346375, train/raw-loss = 0.403984010219574, train/logprobs = tensor([[-0.8495, -2.2904],
        [-1.4398, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041807908564805984
Epoch 0, Step 1380: train/loss = 0.5071657299995422, train/raw-loss = 0.424964964389801, train/logprobs = tensor([[-0.7470, -2.0811],
        [-1.5017, -0.6011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02740025892853737
Epoch 0, Step 1381: train/loss = 0.4010851979255676, train/raw-loss = 0.29022854566574097, train/logprobs = tensor([[-0.9810, -2.8631],
        [-2.3227, -1.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03695221617817879
Epoch 0, Step 1382: train/loss = 0.354751855134964, train/raw-loss = 0.16518989205360413, train/logprobs = tensor([[-1.3047, -3.3298],
        [-3.4057, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06318731606006622
Epoch 0, Step 1383: train/loss = 0.49407005310058594, train/raw-loss = 0.3850102424621582, train/logprobs = tensor([[-1.3154, -2.5351],
        [-2.4518, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03635326772928238
Epoch 0, Step 1384: train/loss = 0.32309404015541077, train/raw-loss = 0.22442081570625305, train/logprobs = tensor([[-1.2669, -3.8709],
        [-2.2239, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03289107605814934
Epoch 0, Step 1385: train/loss = 0.46981555223464966, train/raw-loss = 0.3516731858253479, train/logprobs = tensor([[-1.1874, -2.0015],
        [-2.5653, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03938078507781029
Epoch 0, Step 1386: train/loss = 0.4822807312011719, train/raw-loss = 0.3672240376472473, train/logprobs = tensor([[-1.5759, -4.0194],
        [-2.6572, -2.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038352228701114655
Epoch 0, Step 1387: train/loss = 0.5352449417114258, train/raw-loss = 0.4088042974472046, train/logprobs = tensor([[-1.7926, -2.6304],
        [-2.4231, -1.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04214686155319214
Epoch 0, Step 1388: train/loss = 0.5058952569961548, train/raw-loss = 0.4162988066673279, train/logprobs = tensor([[-0.9402, -2.6949],
        [-1.0747, -0.6931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029865499585866928
Epoch 0, Step 1389: train/loss = 0.4831010103225708, train/raw-loss = 0.36312055587768555, train/logprobs = tensor([[-0.6515, -3.0366],
        [-1.2283, -1.1842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03999347984790802
Epoch 0, Step 1390: train/loss = 0.5233439207077026, train/raw-loss = 0.4557136297225952, train/logprobs = tensor([[-0.8029, -2.6691],
        [-0.9205, -0.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022543445229530334
Epoch 0, Step 1391: train/loss = 0.3230055272579193, train/raw-loss = 0.21262817084789276, train/logprobs = tensor([[-1.0459, -3.1582],
        [-2.9181, -0.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03679245710372925
Epoch 0, Step 1392: train/loss = 0.4190164804458618, train/raw-loss = 0.33536088466644287, train/logprobs = tensor([[-0.8349, -3.3474],
        [-1.5998, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027885204181075096
Epoch 0, Step 1393: train/loss = 0.39433884620666504, train/raw-loss = 0.26174038648605347, train/logprobs = tensor([[-0.8036, -2.9752],
        [-2.2051, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044199492782354355
Epoch 0, Step 1394: train/loss = 0.3661525547504425, train/raw-loss = 0.2580817937850952, train/logprobs = tensor([[-0.7848, -4.1762],
        [-1.5090, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0360235832631588
Epoch 0, Step 1395: train/loss = 0.5720505118370056, train/raw-loss = 0.44535335898399353, train/logprobs = tensor([[-0.7206, -2.7445],
        [-1.8564, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04223238676786423
Epoch 0, Step 1396: train/loss = 0.6309951543807983, train/raw-loss = 0.5410481691360474, train/logprobs = tensor([[-1.0995, -1.6822],
        [-2.2949, -0.5996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029982324689626694
Epoch 0, Step 1397: train/loss = 0.5526295304298401, train/raw-loss = 0.4311487376689911, train/logprobs = tensor([[-1.2998, -2.2912],
        [-2.3963, -1.1704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04049358144402504
Epoch 0, Step 1398: train/loss = 0.3360961377620697, train/raw-loss = 0.2090192437171936, train/logprobs = tensor([[-0.7866, -3.8973],
        [-1.8481, -0.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042358964681625366
Epoch 0, Step 1399: train/loss = 0.6125264167785645, train/raw-loss = 0.5258896350860596, train/logprobs = tensor([[-1.2953, -2.5297],
        [-1.0853, -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028878938406705856
Epoch 0, Step 1400: train/loss = 0.4898703694343567, train/raw-loss = 0.40589773654937744, train/logprobs = tensor([[-0.7448, -2.5081],
        [-1.5703, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027990883216261864
Epoch 0, Step 1401: train/loss = 0.568880558013916, train/raw-loss = 0.453482061624527, train/logprobs = tensor([[-0.9194, -1.6288],
        [-1.9198, -0.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03846614807844162
Epoch 0, Step 1402: train/loss = 0.5439454317092896, train/raw-loss = 0.44558966159820557, train/logprobs = tensor([[-0.8087, -2.9426],
        [-1.1205, -1.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03278525546193123
Epoch 0, Step 1403: train/loss = 0.43684375286102295, train/raw-loss = 0.28815653920173645, train/logprobs = tensor([[-1.4767, -3.5236],
        [-2.5170, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04956240952014923
Epoch 0, Step 1404: train/loss = 0.3658333420753479, train/raw-loss = 0.2863729000091553, train/logprobs = tensor([[-0.7684, -4.0792],
        [-1.5528, -0.9771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026486821472644806
Epoch 0, Step 1405: train/loss = 0.5591753721237183, train/raw-loss = 0.48293983936309814, train/logprobs = tensor([[-0.6046, -1.7489],
        [-1.2772, -0.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025411833077669144
Epoch 0, Step 1406: train/loss = 0.5238884687423706, train/raw-loss = 0.4361885190010071, train/logprobs = tensor([[-1.1648, -2.3937],
        [-1.7302, -0.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029233327135443687
Epoch 0, Step 1407: train/loss = 0.7106439471244812, train/raw-loss = 0.6253918409347534, train/logprobs = tensor([[-2.4085, -2.7953],
        [-2.3913, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028417356312274933
Epoch 0, Step 1408: train/loss = 0.47574445605278015, train/raw-loss = 0.4063655734062195, train/logprobs = tensor([[-0.4969, -3.5788],
        [-0.5165, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02312629297375679
Epoch 0, Step 1409: train/loss = 0.39836183190345764, train/raw-loss = 0.2985089421272278, train/logprobs = tensor([[-0.6955, -3.3129],
        [-1.2620, -0.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033284302800893784
Epoch 0, Step 1410: train/loss = 0.5768772959709167, train/raw-loss = 0.48739442229270935, train/logprobs = tensor([[-0.8596, -2.4939],
        [-0.7554, -0.7205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029827633872628212
Epoch 0, Step 1411: train/loss = 0.4948233962059021, train/raw-loss = 0.40688174962997437, train/logprobs = tensor([[-1.1854, -1.7303],
        [-2.2983, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029313895851373672
Epoch 0, Step 1412: train/loss = 0.4148145318031311, train/raw-loss = 0.293939471244812, train/logprobs = tensor([[-0.9872, -1.7036],
        [-3.0163, -0.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040291689336299896
Epoch 0, Step 1413: train/loss = 0.31080523133277893, train/raw-loss = 0.20809483528137207, train/logprobs = tensor([[-0.9010, -4.6516],
        [-1.9059, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03423679247498512
Epoch 0, Step 1414: train/loss = 0.40419304370880127, train/raw-loss = 0.32034116983413696, train/logprobs = tensor([[-0.7481, -3.6092],
        [-0.9096, -0.7297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027950627729296684
Epoch 0, Step 1415: train/loss = 0.4653088450431824, train/raw-loss = 0.36665499210357666, train/logprobs = tensor([[-0.9006, -3.3029],
        [-0.8521, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0328846238553524
Epoch 0, Step 1416: train/loss = 0.5169064402580261, train/raw-loss = 0.4299880862236023, train/logprobs = tensor([[-0.5560, -3.0387],
        [-1.1038, -0.7358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02897278033196926
Epoch 0, Step 1417: train/loss = 0.3439728617668152, train/raw-loss = 0.1985464245080948, train/logprobs = tensor([[-1.0639, -3.2932],
        [-2.9135, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0484754852950573
Epoch 0, Step 1418: train/loss = 0.6807149052619934, train/raw-loss = 0.5945486426353455, train/logprobs = tensor([[-2.1495, -3.0650],
        [-1.8820, -1.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028722094371914864
Epoch 0, Step 1419: train/loss = 0.5234284400939941, train/raw-loss = 0.42081356048583984, train/logprobs = tensor([[-1.6310, -2.7482],
        [-1.9542, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03420495614409447
Epoch 0, Step 1420: train/loss = 0.7019439935684204, train/raw-loss = 0.630589485168457, train/logprobs = tensor([[-1.1616, -1.7446],
        [-0.8220, -0.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023784829303622246
Epoch 0, Step 1421: train/loss = 0.537898600101471, train/raw-loss = 0.4601009488105774, train/logprobs = tensor([[-1.4579, -2.6224],
        [-1.8446, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02593255043029785
Epoch 0, Step 1422: train/loss = 0.7274819612503052, train/raw-loss = 0.6380438804626465, train/logprobs = tensor([[-1.0480, -2.2966],
        [-1.2571, -2.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029812689870595932
Epoch 0, Step 1423: train/loss = 0.6479145884513855, train/raw-loss = 0.4826709032058716, train/logprobs = tensor([[-0.8113, -0.7571],
        [-2.1537, -0.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05508121848106384
Epoch 0, Step 1424: train/loss = 0.6250640153884888, train/raw-loss = 0.5020875930786133, train/logprobs = tensor([[-1.1672, -2.1439],
        [-2.5366, -1.6970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0409921370446682
Epoch 0, Step 1425: train/loss = 0.4965742528438568, train/raw-loss = 0.3974097967147827, train/logprobs = tensor([[-0.9412, -2.3291],
        [-1.6741, -0.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03305480629205704
Epoch 0, Step 1426: train/loss = 0.3870490789413452, train/raw-loss = 0.2869623303413391, train/logprobs = tensor([[-1.3193, -4.0300],
        [-2.2018, -1.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0333622507750988
Epoch 0, Step 1427: train/loss = 0.41549545526504517, train/raw-loss = 0.33937978744506836, train/logprobs = tensor([[-0.7762, -4.2556],
        [-0.9087, -1.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025371886789798737
Epoch 0, Step 1428: train/loss = 0.4409080445766449, train/raw-loss = 0.33346083760261536, train/logprobs = tensor([[-1.1265, -4.8159],
        [-1.7280, -1.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03581574931740761
Epoch 0, Step 1429: train/loss = 0.534048318862915, train/raw-loss = 0.42443346977233887, train/logprobs = tensor([[-1.3942, -2.1287],
        [-2.2541, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036538295447826385
Epoch 0, Step 1430: train/loss = 0.3974296748638153, train/raw-loss = 0.29405274987220764, train/logprobs = tensor([[-0.8415, -2.8990],
        [-1.6385, -0.6227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03445897251367569
Epoch 0, Step 1431: train/loss = 0.4947701096534729, train/raw-loss = 0.36488479375839233, train/logprobs = tensor([[-1.3549, -2.3603],
        [-2.4710, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04329509660601616
Epoch 0, Step 1432: train/loss = 0.5593503713607788, train/raw-loss = 0.48146092891693115, train/logprobs = tensor([[-1.5099, -3.8365],
        [-1.1351, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025963135063648224
Epoch 0, Step 1433: train/loss = 0.6379872560501099, train/raw-loss = 0.5679789185523987, train/logprobs = tensor([[-1.1430, -1.9913],
        [-1.2747, -1.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023336119949817657
Epoch 0, Step 1434: train/loss = 0.5973799228668213, train/raw-loss = 0.4858044683933258, train/logprobs = tensor([[-1.1786, -3.2891],
        [-1.9324, -1.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037191830575466156
Epoch 0, Step 1435: train/loss = 0.46887117624282837, train/raw-loss = 0.3577631115913391, train/logprobs = tensor([[-1.2673, -2.8178],
        [-2.1451, -0.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037036020308732986
Epoch 0, Step 1436: train/loss = 0.821336567401886, train/raw-loss = 0.7466700077056885, train/logprobs = tensor([[-1.5650, -1.5520],
        [-0.8433, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024888847023248672
Epoch 0, Step 1437: train/loss = 0.7456470727920532, train/raw-loss = 0.6523681879043579, train/logprobs = tensor([[-1.9270, -1.4761],
        [-2.7078, -1.2806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03109297715127468
Epoch 0, Step 1438: train/loss = 0.9412884712219238, train/raw-loss = 0.8377445936203003, train/logprobs = tensor([[-1.9393, -1.4356],
        [-2.0718, -1.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03451463207602501
Epoch 0, Step 1439: train/loss = 0.4252433776855469, train/raw-loss = 0.3231162130832672, train/logprobs = tensor([[-0.5710, -3.9257],
        [-0.6341, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03404238820075989
Epoch 0, Step 1440: train/loss = 0.42459040880203247, train/raw-loss = 0.3186216950416565, train/logprobs = tensor([[-1.1181, -4.0129],
        [-2.1106, -1.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035322897136211395
Epoch 0, Step 1441: train/loss = 0.608050525188446, train/raw-loss = 0.5172080993652344, train/logprobs = tensor([[-0.7949, -1.1809],
        [-1.3094, -0.6261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030280809849500656
Epoch 0, Step 1442: train/loss = 0.43556535243988037, train/raw-loss = 0.3249731659889221, train/logprobs = tensor([[-0.9711, -3.6637],
        [-1.9448, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036864057183265686
Epoch 0, Step 1443: train/loss = 0.4488878846168518, train/raw-loss = 0.3365385830402374, train/logprobs = tensor([[-1.2707, -1.5511],
        [-2.9725, -0.5969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03744976967573166
Epoch 0, Step 1444: train/loss = 0.4450916051864624, train/raw-loss = 0.3494890332221985, train/logprobs = tensor([[-1.0050, -3.6873],
        [-1.8242, -1.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03186751902103424
Epoch 0, Step 1445: train/loss = 0.48962339758872986, train/raw-loss = 0.39670246839523315, train/logprobs = tensor([[-0.4939, -2.7793],
        [-0.7251, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030973652377724648
Epoch 0, Step 1446: train/loss = 0.4934641420841217, train/raw-loss = 0.3914685845375061, train/logprobs = tensor([[-1.1007, -2.7023],
        [-2.0769, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0339985117316246
Epoch 0, Step 1447: train/loss = 0.5189170837402344, train/raw-loss = 0.42342525720596313, train/logprobs = tensor([[-0.6990, -2.2081],
        [-1.3591, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03183060139417648
Epoch 0, Step 1448: train/loss = 0.46607375144958496, train/raw-loss = 0.34955894947052, train/logprobs = tensor([[-0.9912, -2.0557],
        [-2.2436, -0.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03883824869990349
Epoch 0, Step 1449: train/loss = 0.45886287093162537, train/raw-loss = 0.37871667742729187, train/logprobs = tensor([[-0.9203, -3.5113],
        [-1.0294, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02671540156006813
Epoch 0, Step 1450: train/loss = 0.5359542965888977, train/raw-loss = 0.44707778096199036, train/logprobs = tensor([[-1.3587, -1.8156],
        [-1.8531, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02962551638484001
Epoch 0, Step 1451: train/loss = 0.6220832467079163, train/raw-loss = 0.5242973566055298, train/logprobs = tensor([[-0.7170, -1.2085],
        [-1.1229, -0.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03259528428316116
Epoch 0, Step 1452: train/loss = 0.4022258520126343, train/raw-loss = 0.26730841398239136, train/logprobs = tensor([[-1.6282, -2.3375],
        [-3.0653, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0449724942445755
Epoch 0, Step 1453: train/loss = 0.4747883081436157, train/raw-loss = 0.36984390020370483, train/logprobs = tensor([[-0.7616, -2.5207],
        [-1.4573, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03498147055506706
Epoch 0, Step 1454: train/loss = 0.5356855392456055, train/raw-loss = 0.44216930866241455, train/logprobs = tensor([[-0.7769, -2.6525],
        [-1.0961, -1.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031172066926956177
Epoch 0, Step 1455: train/loss = 0.4544141888618469, train/raw-loss = 0.37259167432785034, train/logprobs = tensor([[-0.8772, -2.8853],
        [-1.6876, -1.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02727416902780533
Epoch 0, Step 1456: train/loss = 0.4464370906352997, train/raw-loss = 0.334246426820755, train/logprobs = tensor([[-0.9220, -3.0905],
        [-1.9716, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03739689290523529
Epoch 0, Step 1457: train/loss = 0.5467666983604431, train/raw-loss = 0.4457530975341797, train/logprobs = tensor([[-1.1596, -2.6891],
        [-1.9296, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033671215176582336
Epoch 0, Step 1458: train/loss = 0.4953444004058838, train/raw-loss = 0.3996710777282715, train/logprobs = tensor([[-1.2763, -1.9271],
        [-1.6609, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0318911075592041
Epoch 0, Step 1459: train/loss = 0.6092854142189026, train/raw-loss = 0.47490862011909485, train/logprobs = tensor([[-0.8977, -2.5387],
        [-1.4798, -1.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04479227587580681
Epoch 0, Step 1460: train/loss = 0.6245885491371155, train/raw-loss = 0.5403352975845337, train/logprobs = tensor([[-0.8842, -1.4190],
        [-1.3587, -1.1104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02808442711830139
Epoch 0, Step 1461: train/loss = 0.6949237585067749, train/raw-loss = 0.6071969270706177, train/logprobs = tensor([[-1.5499, -1.7403],
        [-1.6627, -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029242264106869698
Epoch 0, Step 1462: train/loss = 0.5668506026268005, train/raw-loss = 0.45799773931503296, train/logprobs = tensor([[-0.8724, -2.0148],
        [-1.6327, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628428280353546
Epoch 0, Step 1463: train/loss = 0.4338018298149109, train/raw-loss = 0.3410065174102783, train/logprobs = tensor([[-1.0236, -3.3251],
        [-1.7534, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030931778252124786
Epoch 0, Step 1464: train/loss = 0.4366440773010254, train/raw-loss = 0.33069729804992676, train/logprobs = tensor([[-1.0330, -2.8565],
        [-1.9365, -1.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03531559184193611
Epoch 0, Step 1465: train/loss = 0.6230561137199402, train/raw-loss = 0.5452609062194824, train/logprobs = tensor([[-0.7827, -1.1232],
        [-1.0683, -0.5782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02593172714114189
Epoch 0, Step 1466: train/loss = 0.3939675986766815, train/raw-loss = 0.2823525071144104, train/logprobs = tensor([[-1.3241, -2.3184],
        [-3.3544, -0.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03720502927899361
Epoch 0, Step 1467: train/loss = 0.5310218334197998, train/raw-loss = 0.4139772653579712, train/logprobs = tensor([[-1.0238, -1.2575],
        [-2.3294, -0.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03901485353708267
Epoch 0, Step 1468: train/loss = 0.5526944398880005, train/raw-loss = 0.45594748854637146, train/logprobs = tensor([[-0.8667, -2.2960],
        [-1.1475, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03224899247288704
Epoch 0, Step 1469: train/loss = 0.3468875586986542, train/raw-loss = 0.25740402936935425, train/logprobs = tensor([[-1.0952, -4.8701],
        [-1.3156, -0.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029827838763594627
Epoch 0, Step 1470: train/loss = 0.5012933015823364, train/raw-loss = 0.4001826047897339, train/logprobs = tensor([[-1.3687, -3.6651],
        [-1.4661, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03370356187224388
Epoch 0, Step 1471: train/loss = 0.3048454523086548, train/raw-loss = 0.16086849570274353, train/logprobs = tensor([[-0.9208, -3.4607],
        [-2.9489, -0.8793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04799231141805649
Epoch 0, Step 1472: train/loss = 0.45973604917526245, train/raw-loss = 0.36725884675979614, train/logprobs = tensor([[-0.8613, -2.4347],
        [-1.5900, -0.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03082573227584362
Epoch 0, Step 1473: train/loss = 0.5144638419151306, train/raw-loss = 0.43883398175239563, train/logprobs = tensor([[-0.4869, -2.5345],
        [-0.5971, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025209948420524597
Epoch 0, Step 1474: train/loss = 0.539165735244751, train/raw-loss = 0.44431936740875244, train/logprobs = tensor([[-1.2647, -2.5406],
        [-1.6870, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03161542862653732
Epoch 0, Step 1475: train/loss = 0.39220118522644043, train/raw-loss = 0.3047425150871277, train/logprobs = tensor([[-1.0117, -2.6440],
        [-1.8255, -0.5659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02915288880467415
Epoch 0, Step 1476: train/loss = 0.5136269330978394, train/raw-loss = 0.43746858835220337, train/logprobs = tensor([[-0.7480, -2.6669],
        [-0.6916, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025386111810803413
Epoch 0, Step 1477: train/loss = 0.3473029136657715, train/raw-loss = 0.23631605505943298, train/logprobs = tensor([[-0.9567, -2.7867],
        [-2.5372, -0.8550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03699561208486557
Epoch 0, Step 1478: train/loss = 0.6205405592918396, train/raw-loss = 0.5399574637413025, train/logprobs = tensor([[-1.0030, -1.5205],
        [-2.2566, -0.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0268610417842865
Epoch 0, Step 1479: train/loss = 0.3378588557243347, train/raw-loss = 0.2075640857219696, train/logprobs = tensor([[-1.1841, -2.9229],
        [-3.2437, -0.6630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043431587517261505
Epoch 0, Step 1480: train/loss = 0.5284026861190796, train/raw-loss = 0.41297221183776855, train/logprobs = tensor([[-1.3235, -2.4444],
        [-2.0449, -1.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03847680240869522
Epoch 0, Step 1481: train/loss = 0.4476318359375, train/raw-loss = 0.38247236609458923, train/logprobs = tensor([[-0.6787, -3.5683],
        [-0.8051, -0.9999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021719807758927345
Epoch 0, Step 1482: train/loss = 0.45358210802078247, train/raw-loss = 0.342559814453125, train/logprobs = tensor([[-0.9287, -4.6967],
        [-1.1046, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037007421255111694
Epoch 0, Step 1483: train/loss = 0.3395419418811798, train/raw-loss = 0.24849411845207214, train/logprobs = tensor([[-1.0810, -3.9981],
        [-2.2982, -0.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03034927137196064
Epoch 0, Step 1484: train/loss = 0.31873685121536255, train/raw-loss = 0.20055153965950012, train/logprobs = tensor([[-1.8685, -3.4795],
        [-3.1662, -0.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03939511254429817
Epoch 0, Step 1485: train/loss = 0.5538375973701477, train/raw-loss = 0.459250271320343, train/logprobs = tensor([[-0.9680, -3.0911],
        [-1.9411, -1.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03152911737561226
Epoch 0, Step 1486: train/loss = 0.3511841297149658, train/raw-loss = 0.24746285378932953, train/logprobs = tensor([[-0.7913, -2.9561],
        [-2.1307, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034573763608932495
Epoch 0, Step 1487: train/loss = 0.3665810525417328, train/raw-loss = 0.2672247588634491, train/logprobs = tensor([[-0.7881, -3.7850],
        [-1.5854, -0.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03311876207590103
Epoch 0, Step 1488: train/loss = 0.537480354309082, train/raw-loss = 0.44637471437454224, train/logprobs = tensor([[-1.0505, -1.0708],
        [-2.3283, -0.7211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03036855161190033
Epoch 0, Step 1489: train/loss = 0.4932776689529419, train/raw-loss = 0.36237576603889465, train/logprobs = tensor([[-1.2243, -3.3371],
        [-2.9294, -1.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043633971363306046
Epoch 0, Step 1490: train/loss = 0.45847615599632263, train/raw-loss = 0.3821614384651184, train/logprobs = tensor([[-0.9105, -2.5865],
        [-2.2087, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025438250973820686
Epoch 0, Step 1491: train/loss = 0.5013086795806885, train/raw-loss = 0.43414533138275146, train/logprobs = tensor([[-1.1827, -2.2569],
        [-1.9181, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022387783974409103
Epoch 0, Step 1492: train/loss = 0.6186404228210449, train/raw-loss = 0.5359671115875244, train/logprobs = tensor([[-1.0678, -2.2319],
        [-0.9053, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027557775378227234
Epoch 0, Step 1493: train/loss = 0.49082648754119873, train/raw-loss = 0.38417819142341614, train/logprobs = tensor([[-1.2870, -3.6071],
        [-2.0012, -1.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035549432039260864
Epoch 0, Step 1494: train/loss = 0.5958586931228638, train/raw-loss = 0.5145606994628906, train/logprobs = tensor([[-0.9740, -1.8614],
        [-1.2859, -0.7321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027099326252937317
Epoch 0, Step 1495: train/loss = 0.7440946698188782, train/raw-loss = 0.5905957221984863, train/logprobs = tensor([[-1.7666, -2.7751],
        [-3.5601, -2.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05116631090641022
Epoch 0, Step 1496: train/loss = 0.567113995552063, train/raw-loss = 0.4750635027885437, train/logprobs = tensor([[-0.9673, -1.4843],
        [-1.4921, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03068348951637745
Epoch 0, Step 1497: train/loss = 0.4558156132698059, train/raw-loss = 0.3294500708580017, train/logprobs = tensor([[-1.1900, -2.9450],
        [-2.5858, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04212184250354767
Epoch 0, Step 1498: train/loss = 0.8860645294189453, train/raw-loss = 0.7868213057518005, train/logprobs = tensor([[-1.6408, -1.5744],
        [-2.3054, -2.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033081091940402985
Epoch 0, Step 1499: train/loss = 0.47061818838119507, train/raw-loss = 0.3444678783416748, train/logprobs = tensor([[-1.7259, -3.4969],
        [-3.1080, -1.6690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04205009341239929
Loss is nan
eval/loss: 0.49093377590179443
Epoch 0, Step 1500: train/loss = 0.6054573655128479, train/raw-loss = 0.524809718132019, train/logprobs = tensor([[-1.6029, -2.8518],
        [-1.5281, -1.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026882551610469818
Epoch 0, Step 1501: train/loss = 0.527096152305603, train/raw-loss = 0.3713855445384979, train/logprobs = tensor([[-1.7265, -2.2263],
        [-4.3380, -1.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051903534680604935
Epoch 0, Step 1502: train/loss = 0.518528938293457, train/raw-loss = 0.42002278566360474, train/logprobs = tensor([[-0.6823, -3.2894],
        [-1.0434, -1.2193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032835379242897034
Epoch 0, Step 1503: train/loss = 0.4666021466255188, train/raw-loss = 0.3684176802635193, train/logprobs = tensor([[-0.9367, -2.0082],
        [-2.2023, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032728150486946106
Epoch 0, Step 1504: train/loss = 0.49733850359916687, train/raw-loss = 0.41308000683784485, train/logprobs = tensor([[-1.4988, -1.3795],
        [-3.9686, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028086161240935326
Epoch 0, Step 1505: train/loss = 0.587818443775177, train/raw-loss = 0.516313910484314, train/logprobs = tensor([[-1.1627, -1.1466],
        [-2.0866, -0.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023834845051169395
Epoch 0, Step 1506: train/loss = 0.5323600172996521, train/raw-loss = 0.4655601978302002, train/logprobs = tensor([[-0.7659, -3.4848],
        [-0.8536, -1.5331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02226659283041954
Epoch 0, Step 1507: train/loss = 0.4124182164669037, train/raw-loss = 0.3117387890815735, train/logprobs = tensor([[-0.9848, -2.9310],
        [-2.0027, -0.8684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033559802919626236
Epoch 0, Step 1508: train/loss = 0.3178870677947998, train/raw-loss = 0.19079867005348206, train/logprobs = tensor([[-0.9919, -5.0336],
        [-2.1301, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042362794280052185
Epoch 0, Step 1509: train/loss = 0.4860617220401764, train/raw-loss = 0.3902612626552582, train/logprobs = tensor([[-1.2367, -1.1188],
        [-2.7485, -0.7956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031933486461639404
Epoch 0, Step 1510: train/loss = 0.3421591520309448, train/raw-loss = 0.2613774538040161, train/logprobs = tensor([[-0.8489, -5.0566],
        [-1.0144, -0.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02692723646759987
Epoch 0, Step 1511: train/loss = 0.5775061845779419, train/raw-loss = 0.4899708926677704, train/logprobs = tensor([[-0.7015, -1.9481],
        [-1.0959, -0.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029178425669670105
Epoch 0, Step 1512: train/loss = 0.4423569440841675, train/raw-loss = 0.35253065824508667, train/logprobs = tensor([[-0.6651, -2.8025],
        [-1.3448, -0.6503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029942087829113007
Epoch 0, Step 1513: train/loss = 0.574730634689331, train/raw-loss = 0.501366376876831, train/logprobs = tensor([[-0.7511, -2.5104],
        [-0.8839, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024454746395349503
Epoch 0, Step 1514: train/loss = 0.363956093788147, train/raw-loss = 0.27907904982566833, train/logprobs = tensor([[-1.1048, -2.8937],
        [-2.4455, -0.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028292354196310043
Epoch 0, Step 1515: train/loss = 0.6012794375419617, train/raw-loss = 0.5289187431335449, train/logprobs = tensor([[-0.7902, -2.7884],
        [-0.7966, -1.3864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02412022277712822
Epoch 0, Step 1516: train/loss = 0.5574878454208374, train/raw-loss = 0.4396706521511078, train/logprobs = tensor([[-1.3414, -3.7524],
        [-2.6663, -2.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03927240148186684
Epoch 0, Step 1517: train/loss = 0.5931873917579651, train/raw-loss = 0.5074870586395264, train/logprobs = tensor([[-1.1376, -2.6870],
        [-1.1576, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0285667534917593
Epoch 0, Step 1518: train/loss = 0.6086183786392212, train/raw-loss = 0.4688519835472107, train/logprobs = tensor([[-1.1008, -3.1246],
        [-2.0776, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04658878222107887
Epoch 0, Step 1519: train/loss = 0.5090525150299072, train/raw-loss = 0.4138447940349579, train/logprobs = tensor([[-0.6712, -1.7690],
        [-1.4255, -0.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031735919415950775
Epoch 0, Step 1520: train/loss = 0.42244160175323486, train/raw-loss = 0.3258990943431854, train/logprobs = tensor([[-0.8893, -2.1031],
        [-2.2644, -0.5488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03218084201216698
Epoch 0, Step 1521: train/loss = 0.3733309805393219, train/raw-loss = 0.25431761145591736, train/logprobs = tensor([[-1.2130, -2.7028],
        [-2.7654, -1.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039671123027801514
Epoch 0, Step 1522: train/loss = 0.4930853247642517, train/raw-loss = 0.4177166819572449, train/logprobs = tensor([[-0.9696, -2.5103],
        [-2.0024, -1.3802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025122888386249542
Epoch 0, Step 1523: train/loss = 0.42393624782562256, train/raw-loss = 0.3124643564224243, train/logprobs = tensor([[-1.2321, -2.2915],
        [-2.2955, -0.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037157297134399414
Epoch 0, Step 1524: train/loss = 0.3704269826412201, train/raw-loss = 0.2412567436695099, train/logprobs = tensor([[-0.7941, -3.7750],
        [-1.7488, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04305674880743027
Epoch 0, Step 1525: train/loss = 0.730371356010437, train/raw-loss = 0.6317281723022461, train/logprobs = tensor([[-0.8480, -2.6221],
        [-1.6775, -2.4207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03288106620311737
Epoch 0, Step 1526: train/loss = 0.3448866009712219, train/raw-loss = 0.20307475328445435, train/logprobs = tensor([[-1.0558, -2.6655],
        [-3.3512, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04727061465382576
Epoch 0, Step 1527: train/loss = 0.4278929829597473, train/raw-loss = 0.31562039256095886, train/logprobs = tensor([[-0.9123, -2.2273],
        [-2.5515, -0.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03742420673370361
Epoch 0, Step 1528: train/loss = 0.5227562785148621, train/raw-loss = 0.42174214124679565, train/logprobs = tensor([[-0.9673, -2.6769],
        [-1.5893, -1.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03367137536406517
Epoch 0, Step 1529: train/loss = 0.9026637077331543, train/raw-loss = 0.8018807172775269, train/logprobs = tensor([[-1.2345, -1.8107],
        [-1.9332, -2.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033594340085983276
Epoch 0, Step 1530: train/loss = 0.3776935338973999, train/raw-loss = 0.2847334146499634, train/logprobs = tensor([[-1.7895, -2.9065],
        [-2.8755, -0.6136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030986718833446503
Epoch 0, Step 1531: train/loss = 0.5730689764022827, train/raw-loss = 0.4809355139732361, train/logprobs = tensor([[-0.7537, -1.8200],
        [-1.6031, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030711159110069275
Epoch 0, Step 1532: train/loss = 0.6116701364517212, train/raw-loss = 0.5272029638290405, train/logprobs = tensor([[-0.9220, -1.4082],
        [-1.0833, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02815571054816246
Epoch 0, Step 1533: train/loss = 0.4925830364227295, train/raw-loss = 0.4300314486026764, train/logprobs = tensor([[-0.7351, -2.2743],
        [-1.1637, -0.6636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020850520581007004
Epoch 0, Step 1534: train/loss = 0.4015078544616699, train/raw-loss = 0.31801122426986694, train/logprobs = tensor([[-1.1658, -3.5327],
        [-1.5436, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027832208201289177
Epoch 0, Step 1535: train/loss = 0.5204343199729919, train/raw-loss = 0.41110190749168396, train/logprobs = tensor([[-0.7831, -1.5466],
        [-1.8125, -0.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03644413501024246
Epoch 0, Step 1536: train/loss = 0.6541711688041687, train/raw-loss = 0.5931066274642944, train/logprobs = tensor([[-0.8130, -1.1314],
        [-1.3010, -1.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020354844629764557
Epoch 0, Step 1537: train/loss = 0.33755365014076233, train/raw-loss = 0.19308632612228394, train/logprobs = tensor([[-1.0508, -3.9349],
        [-3.0364, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0481557734310627
Epoch 0, Step 1538: train/loss = 0.5138463377952576, train/raw-loss = 0.42706793546676636, train/logprobs = tensor([[-0.8715, -2.4983],
        [-1.3620, -0.8599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02892613410949707
Epoch 0, Step 1539: train/loss = 0.34505391120910645, train/raw-loss = 0.2665538489818573, train/logprobs = tensor([[-0.8965, -4.1250],
        [-1.3996, -0.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026166681200265884
Epoch 0, Step 1540: train/loss = 0.3642536401748657, train/raw-loss = 0.24933552742004395, train/logprobs = tensor([[-0.9861, -3.5757],
        [-2.1087, -1.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03830603510141373
Epoch 0, Step 1541: train/loss = 0.4097537100315094, train/raw-loss = 0.3062344193458557, train/logprobs = tensor([[-1.1942, -4.6487],
        [-1.4069, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0345064252614975
Epoch 0, Step 1542: train/loss = 0.4683719277381897, train/raw-loss = 0.3900543451309204, train/logprobs = tensor([[-0.7058, -2.2771],
        [-1.5090, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026105862110853195
Epoch 0, Step 1543: train/loss = 0.7584488391876221, train/raw-loss = 0.6530004739761353, train/logprobs = tensor([[-1.1518, -1.1714],
        [-2.0341, -1.5381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035149455070495605
Epoch 0, Step 1544: train/loss = 0.35189729928970337, train/raw-loss = 0.23529332876205444, train/logprobs = tensor([[-1.2369, -3.8545],
        [-1.8455, -0.7247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03886799514293671
Epoch 0, Step 1545: train/loss = 0.5331419706344604, train/raw-loss = 0.46037188172340393, train/logprobs = tensor([[-0.9226, -2.6207],
        [-0.8783, -0.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024256698787212372
Epoch 0, Step 1546: train/loss = 0.5133435130119324, train/raw-loss = 0.4515148997306824, train/logprobs = tensor([[-0.6854, -3.0470],
        [-0.8025, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0206095352768898
Epoch 0, Step 1547: train/loss = 0.5595628619194031, train/raw-loss = 0.49170398712158203, train/logprobs = tensor([[-0.5904, -2.6549],
        [-0.5953, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022619619965553284
Epoch 0, Step 1548: train/loss = 0.4926395118236542, train/raw-loss = 0.38665926456451416, train/logprobs = tensor([[-1.4418, -2.7457],
        [-1.9671, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03532673791050911
Epoch 0, Step 1549: train/loss = 0.3934789299964905, train/raw-loss = 0.27252647280693054, train/logprobs = tensor([[-1.0795, -3.5843],
        [-2.0787, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04031747952103615
Epoch 0, Step 1550: train/loss = 0.5379549264907837, train/raw-loss = 0.45715510845184326, train/logprobs = tensor([[-1.3046, -3.3022],
        [-1.3792, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026933273300528526
Epoch 0, Step 1551: train/loss = 0.7231797575950623, train/raw-loss = 0.6222472786903381, train/logprobs = tensor([[-1.0860, -1.4425],
        [-2.2004, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033644143491983414
Epoch 0, Step 1552: train/loss = 0.48958784341812134, train/raw-loss = 0.38994643092155457, train/logprobs = tensor([[-0.9793, -4.5805],
        [-1.0063, -1.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033213816583156586
Epoch 0, Step 1553: train/loss = 0.4461975693702698, train/raw-loss = 0.36048251390457153, train/logprobs = tensor([[-0.8609, -4.2327],
        [-1.8650, -1.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028571676462888718
Epoch 0, Step 1554: train/loss = 0.770389199256897, train/raw-loss = 0.659064769744873, train/logprobs = tensor([[-0.8097, -1.7543],
        [-2.0629, -1.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037108127027750015
Epoch 0, Step 1555: train/loss = 0.48533517122268677, train/raw-loss = 0.40349069237709045, train/logprobs = tensor([[-0.7621, -3.1552],
        [-0.9198, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02728148363530636
Epoch 0, Step 1556: train/loss = 0.5069689154624939, train/raw-loss = 0.428639680147171, train/logprobs = tensor([[-0.6173, -1.8563],
        [-1.4906, -0.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026109732687473297
Epoch 0, Step 1557: train/loss = 0.3768598139286041, train/raw-loss = 0.2922531068325043, train/logprobs = tensor([[-0.8241, -3.8260],
        [-1.4662, -1.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028202228248119354
Epoch 0, Step 1558: train/loss = 0.3879907429218292, train/raw-loss = 0.27888035774230957, train/logprobs = tensor([[-1.0324, -2.4761],
        [-2.3841, -0.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036370132118463516
Epoch 0, Step 1559: train/loss = 0.6005759835243225, train/raw-loss = 0.5295516848564148, train/logprobs = tensor([[-0.7632, -2.0171],
        [-0.8752, -0.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02367478609085083
Epoch 0, Step 1560: train/loss = 0.5846545100212097, train/raw-loss = 0.5220096111297607, train/logprobs = tensor([[-0.9916, -2.2384],
        [-1.0347, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020881623029708862
Epoch 0, Step 1561: train/loss = 0.3633470833301544, train/raw-loss = 0.2564104497432709, train/logprobs = tensor([[-0.8909, -2.9833],
        [-2.2875, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03564554452896118
Epoch 0, Step 1562: train/loss = 0.3744702935218811, train/raw-loss = 0.2848321795463562, train/logprobs = tensor([[-0.9496, -3.9427],
        [-1.2200, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029879368841648102
Epoch 0, Step 1563: train/loss = 0.546678900718689, train/raw-loss = 0.4704521894454956, train/logprobs = tensor([[-0.6111, -2.7181],
        [-0.6265, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025408893823623657
Epoch 0, Step 1564: train/loss = 0.506022036075592, train/raw-loss = 0.3934129476547241, train/logprobs = tensor([[-0.9512, -3.5849],
        [-1.6501, -1.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03753635659813881
Epoch 0, Step 1565: train/loss = 0.44828000664711, train/raw-loss = 0.35472169518470764, train/logprobs = tensor([[-1.5769, -2.0752],
        [-2.5831, -0.7509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031186111271381378
Epoch 0, Step 1566: train/loss = 0.5494044423103333, train/raw-loss = 0.49035874009132385, train/logprobs = tensor([[-0.6917, -2.6857],
        [-0.7529, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019681906327605247
Epoch 0, Step 1567: train/loss = 0.33163100481033325, train/raw-loss = 0.22959600389003754, train/logprobs = tensor([[-1.0034, -3.6618],
        [-2.3661, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03401166945695877
Epoch 0, Step 1568: train/loss = 0.8001704216003418, train/raw-loss = 0.685806930065155, train/logprobs = tensor([[-0.8964, -2.6412],
        [-1.3416, -1.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03812117874622345
Epoch 0, Step 1569: train/loss = 0.460021436214447, train/raw-loss = 0.3582805395126343, train/logprobs = tensor([[-1.0068, -3.0062],
        [-2.6017, -1.9039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03391363471746445
Epoch 0, Step 1570: train/loss = 0.4190332293510437, train/raw-loss = 0.3295169174671173, train/logprobs = tensor([[-0.7613, -2.8280],
        [-2.3890, -0.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029838763177394867
Epoch 0, Step 1571: train/loss = 0.28627583384513855, train/raw-loss = 0.168288916349411, train/logprobs = tensor([[-1.1370, -4.2755],
        [-2.9565, -1.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03932897746562958
Epoch 0, Step 1572: train/loss = 0.500154972076416, train/raw-loss = 0.39178329706192017, train/logprobs = tensor([[-0.8620, -3.2252],
        [-0.9863, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03612389415502548
Epoch 0, Step 1573: train/loss = 0.4559602439403534, train/raw-loss = 0.3321862816810608, train/logprobs = tensor([[-1.6966, -2.8165],
        [-3.2661, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04125800356268883
Epoch 0, Step 1574: train/loss = 0.3546691834926605, train/raw-loss = 0.22090765833854675, train/logprobs = tensor([[-1.3724, -3.1632],
        [-3.3529, -1.3034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04458717256784439
Epoch 0, Step 1575: train/loss = 0.5992705821990967, train/raw-loss = 0.4697866439819336, train/logprobs = tensor([[-2.0222, -1.7634],
        [-3.2069, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043161310255527496
Epoch 0, Step 1576: train/loss = 0.3306958079338074, train/raw-loss = 0.2089083194732666, train/logprobs = tensor([[-1.0832, -2.8369],
        [-3.2160, -0.8173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040595829486846924
Epoch 0, Step 1577: train/loss = 0.5147198438644409, train/raw-loss = 0.40599894523620605, train/logprobs = tensor([[-0.8477, -2.0565],
        [-1.8983, -1.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03624030202627182
Epoch 0, Step 1578: train/loss = 0.404231995344162, train/raw-loss = 0.30740684270858765, train/logprobs = tensor([[-1.1433, -2.5550],
        [-3.2099, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032275039702653885
Epoch 0, Step 1579: train/loss = 0.3028160333633423, train/raw-loss = 0.1811295747756958, train/logprobs = tensor([[-1.0674, -2.9413],
        [-3.5560, -0.8601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04056215286254883
Epoch 0, Step 1580: train/loss = 0.6245240569114685, train/raw-loss = 0.5512930750846863, train/logprobs = tensor([[-0.9252, -0.8947],
        [-2.1006, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024410340934991837
Epoch 0, Step 1581: train/loss = 0.5343033671379089, train/raw-loss = 0.4703879654407501, train/logprobs = tensor([[-0.5447, -2.9244],
        [-0.6590, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021305140107870102
Epoch 0, Step 1582: train/loss = 0.3109341263771057, train/raw-loss = 0.18080055713653564, train/logprobs = tensor([[-0.8746, -4.0780],
        [-2.4734, -1.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04337785765528679
Epoch 0, Step 1583: train/loss = 0.44894033670425415, train/raw-loss = 0.377045214176178, train/logprobs = tensor([[-0.7261, -4.0097],
        [-0.7391, -1.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023965036496520042
Epoch 0, Step 1584: train/loss = 0.3931513726711273, train/raw-loss = 0.3226400315761566, train/logprobs = tensor([[-0.7377, -4.5509],
        [-0.8461, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02350378967821598
Epoch 0, Step 1585: train/loss = 0.6335222721099854, train/raw-loss = 0.558749258518219, train/logprobs = tensor([[-1.2482, -2.6867],
        [-1.0319, -1.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024924330413341522
Epoch 0, Step 1586: train/loss = 0.5453451871871948, train/raw-loss = 0.4523295760154724, train/logprobs = tensor([[-1.0550, -1.9232],
        [-1.9829, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031005192548036575
Epoch 0, Step 1587: train/loss = 0.408022940158844, train/raw-loss = 0.3248124122619629, train/logprobs = tensor([[-1.2052, -4.4091],
        [-1.1258, -1.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027736835181713104
Epoch 0, Step 1588: train/loss = 0.32544437050819397, train/raw-loss = 0.1997932344675064, train/logprobs = tensor([[-0.8671, -3.5105],
        [-2.1657, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041883714497089386
Epoch 0, Step 1589: train/loss = 0.4678131639957428, train/raw-loss = 0.3483894169330597, train/logprobs = tensor([[-1.8859, -4.8431],
        [-3.1922, -2.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039807915687561035
Epoch 0, Step 1590: train/loss = 0.5091253519058228, train/raw-loss = 0.4290727376937866, train/logprobs = tensor([[-0.9995, -2.3082],
        [-1.4504, -0.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026684198528528214
Epoch 0, Step 1591: train/loss = 0.4482625126838684, train/raw-loss = 0.38671454787254333, train/logprobs = tensor([[-0.7135, -3.8001],
        [-0.8346, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020515989512205124
Epoch 0, Step 1592: train/loss = 0.5820762515068054, train/raw-loss = 0.47090446949005127, train/logprobs = tensor([[-0.8848, -2.6664],
        [-1.8304, -1.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03705725818872452
Epoch 0, Step 1593: train/loss = 0.5060265064239502, train/raw-loss = 0.4291223883628845, train/logprobs = tensor([[-0.6370, -2.1792],
        [-1.2984, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02563472092151642
Epoch 0, Step 1594: train/loss = 0.40418651700019836, train/raw-loss = 0.30622243881225586, train/logprobs = tensor([[-1.2941, -2.3537],
        [-3.2050, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032654691487550735
Epoch 0, Step 1595: train/loss = 0.5284755825996399, train/raw-loss = 0.4573207497596741, train/logprobs = tensor([[-0.6499, -1.9829],
        [-1.2399, -0.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023718278855085373
Epoch 0, Step 1596: train/loss = 0.5610764026641846, train/raw-loss = 0.4656321406364441, train/logprobs = tensor([[-1.2467, -2.1548],
        [-1.9211, -1.4207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03181474283337593
Epoch 0, Step 1597: train/loss = 0.5719517469406128, train/raw-loss = 0.49798583984375, train/logprobs = tensor([[-0.7767, -2.2074],
        [-1.5052, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024655308574438095
Epoch 0, Step 1598: train/loss = 0.4598201513290405, train/raw-loss = 0.3398129940032959, train/logprobs = tensor([[-0.8930, -1.9630],
        [-1.9919, -0.5391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040002383291721344
Epoch 0, Step 1599: train/loss = 0.5356554985046387, train/raw-loss = 0.4632475674152374, train/logprobs = tensor([[-1.0296, -1.7756],
        [-1.7415, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024135973304510117
Epoch 0, Step 1600: train/loss = 0.5097169280052185, train/raw-loss = 0.4257644712924957, train/logprobs = tensor([[-0.8210, -1.8819],
        [-1.7622, -0.8060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027984151616692543
Epoch 0, Step 1601: train/loss = 0.5658900737762451, train/raw-loss = 0.47843602299690247, train/logprobs = tensor([[-0.6815, -1.5122],
        [-1.3386, -0.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029151365160942078
Epoch 0, Step 1602: train/loss = 0.44174909591674805, train/raw-loss = 0.36692142486572266, train/logprobs = tensor([[-0.8332, -4.2874],
        [-0.9803, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024942558258771896
Epoch 0, Step 1603: train/loss = 0.4426031708717346, train/raw-loss = 0.36653658747673035, train/logprobs = tensor([[-1.7143, -4.1616],
        [-1.7151, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025355525314807892
Epoch 0, Step 1604: train/loss = 0.5070800185203552, train/raw-loss = 0.41685357689857483, train/logprobs = tensor([[-0.9349, -2.7861],
        [-1.5935, -1.4383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03007548861205578
Epoch 0, Step 1605: train/loss = 0.32819196581840515, train/raw-loss = 0.19146870076656342, train/logprobs = tensor([[-1.4792, -2.9327],
        [-4.0911, -0.5775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04557441920042038
Epoch 0, Step 1606: train/loss = 0.5554786920547485, train/raw-loss = 0.4724540412425995, train/logprobs = tensor([[-0.8659, -2.0150],
        [-1.5892, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02767486684024334
Epoch 0, Step 1607: train/loss = 0.5029667019844055, train/raw-loss = 0.42698198556900024, train/logprobs = tensor([[-1.8184, -2.9461],
        [-2.0638, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025328245013952255
Epoch 0, Step 1608: train/loss = 0.4761090874671936, train/raw-loss = 0.37532803416252136, train/logprobs = tensor([[-1.2652, -2.3564],
        [-2.3720, -1.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033593691885471344
Epoch 0, Step 1609: train/loss = 0.4835350513458252, train/raw-loss = 0.41142529249191284, train/logprobs = tensor([[-0.7329, -2.3754],
        [-1.7899, -0.5645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024036582559347153
Epoch 0, Step 1610: train/loss = 0.4402267038822174, train/raw-loss = 0.3134940266609192, train/logprobs = tensor([[-1.5864, -2.7145],
        [-2.9816, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04224422946572304
Epoch 0, Step 1611: train/loss = 0.5235604047775269, train/raw-loss = 0.4364396631717682, train/logprobs = tensor([[-1.4118, -2.5286],
        [-1.5196, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0290402639657259
Epoch 0, Step 1612: train/loss = 0.540986180305481, train/raw-loss = 0.45765331387519836, train/logprobs = tensor([[-0.5728, -2.8012],
        [-0.6155, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027777627110481262
Epoch 0, Step 1613: train/loss = 0.5512664914131165, train/raw-loss = 0.4823806583881378, train/logprobs = tensor([[-0.9575, -3.3093],
        [-1.3882, -1.4771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022961940616369247
Epoch 0, Step 1614: train/loss = 0.3484764099121094, train/raw-loss = 0.25943684577941895, train/logprobs = tensor([[-0.9444, -3.8940],
        [-2.5633, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029679853469133377
Epoch 0, Step 1615: train/loss = 0.41878437995910645, train/raw-loss = 0.35935643315315247, train/logprobs = tensor([[-0.6343, -3.3036],
        [-0.8919, -0.7643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019809313118457794
Epoch 0, Step 1616: train/loss = 0.36651113629341125, train/raw-loss = 0.2504110336303711, train/logprobs = tensor([[-1.0590, -3.1461],
        [-2.4361, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038700032979249954
Epoch 0, Step 1617: train/loss = 0.4094666838645935, train/raw-loss = 0.33392712473869324, train/logprobs = tensor([[-0.7560, -3.9954],
        [-0.8070, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025179868564009666
Epoch 0, Step 1618: train/loss = 0.5719397068023682, train/raw-loss = 0.4813939929008484, train/logprobs = tensor([[-0.9230, -2.8376],
        [-1.8645, -1.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030181918293237686
Epoch 0, Step 1619: train/loss = 0.6094915270805359, train/raw-loss = 0.5632185339927673, train/logprobs = tensor([[-0.6502, -1.7641],
        [-0.6558, -0.7665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015424322336912155
Epoch 0, Step 1620: train/loss = 0.6513510942459106, train/raw-loss = 0.5926393270492554, train/logprobs = tensor([[-0.8032, -1.5359],
        [-0.8020, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01957058347761631
Epoch 0, Step 1621: train/loss = 0.3988490700721741, train/raw-loss = 0.2972477376461029, train/logprobs = tensor([[-1.1117, -2.5665],
        [-3.1433, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386712074279785
Epoch 0, Step 1622: train/loss = 0.4703272581100464, train/raw-loss = 0.37153786420822144, train/logprobs = tensor([[-1.2573, -2.4323],
        [-1.9865, -0.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032929807901382446
Epoch 0, Step 1623: train/loss = 0.3464789390563965, train/raw-loss = 0.2399939000606537, train/logprobs = tensor([[-0.7454, -4.0173],
        [-1.5457, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03549501672387123
Epoch 0, Step 1624: train/loss = 0.28619611263275146, train/raw-loss = 0.19586911797523499, train/logprobs = tensor([[-1.1517, -4.2111],
        [-2.3208, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030108999460935593
Epoch 0, Step 1625: train/loss = 0.41775283217430115, train/raw-loss = 0.3120405375957489, train/logprobs = tensor([[-1.3563, -2.7965],
        [-2.6670, -0.7679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03523743897676468
Epoch 0, Step 1626: train/loss = 0.4624340236186981, train/raw-loss = 0.37131014466285706, train/logprobs = tensor([[-0.7832, -2.6927],
        [-1.8216, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030374620109796524
Epoch 0, Step 1627: train/loss = 0.5074352025985718, train/raw-loss = 0.407248854637146, train/logprobs = tensor([[-1.0649, -2.7746],
        [-1.4746, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03339545428752899
Epoch 0, Step 1628: train/loss = 0.44034677743911743, train/raw-loss = 0.319369375705719, train/logprobs = tensor([[-1.4788, -3.1749],
        [-2.2531, -0.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040325794368982315
Epoch 0, Step 1629: train/loss = 0.4427427053451538, train/raw-loss = 0.35205137729644775, train/logprobs = tensor([[-0.7702, -3.8333],
        [-1.0201, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0302304457873106
Epoch 0, Step 1630: train/loss = 0.4147633910179138, train/raw-loss = 0.29862895607948303, train/logprobs = tensor([[-1.1169, -3.2588],
        [-2.5740, -1.7534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03871147707104683
Epoch 0, Step 1631: train/loss = 0.5410998463630676, train/raw-loss = 0.46992039680480957, train/logprobs = tensor([[-0.7712, -2.2717],
        [-1.1514, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02372649684548378
Epoch 0, Step 1632: train/loss = 0.46726298332214355, train/raw-loss = 0.34283995628356934, train/logprobs = tensor([[-1.3990, -2.7903],
        [-2.6070, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041474342346191406
Epoch 0, Step 1633: train/loss = 0.34743207693099976, train/raw-loss = 0.2521556615829468, train/logprobs = tensor([[-0.9081, -2.7801],
        [-2.3993, -0.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03175879642367363
Epoch 0, Step 1634: train/loss = 0.5489394664764404, train/raw-loss = 0.4702187478542328, train/logprobs = tensor([[-0.8818, -2.4498],
        [-0.9873, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026240231469273567
Epoch 0, Step 1635: train/loss = 0.5207719206809998, train/raw-loss = 0.438900887966156, train/logprobs = tensor([[-0.9906, -3.3288],
        [-1.7023, -1.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027290361002087593
Epoch 0, Step 1636: train/loss = 0.42966729402542114, train/raw-loss = 0.3049560487270355, train/logprobs = tensor([[-1.2900, -3.1947],
        [-3.4753, -0.7238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04157041758298874
Epoch 0, Step 1637: train/loss = 0.6562515497207642, train/raw-loss = 0.5898197889328003, train/logprobs = tensor([[-1.3487, -2.1433],
        [-1.4092, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02214391529560089
Epoch 0, Step 1638: train/loss = 0.43590402603149414, train/raw-loss = 0.3330685794353485, train/logprobs = tensor([[-1.1231, -2.2643],
        [-3.0900, -1.0385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03427847474813461
Epoch 0, Step 1639: train/loss = 0.4387938678264618, train/raw-loss = 0.3520246148109436, train/logprobs = tensor([[-0.9296, -3.8794],
        [-1.9684, -0.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028923088684678078
Epoch 0, Step 1640: train/loss = 0.5595090389251709, train/raw-loss = 0.44999903440475464, train/logprobs = tensor([[-2.0910, -2.6326],
        [-2.0174, -1.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03650334104895592
Epoch 0, Step 1641: train/loss = 0.514883816242218, train/raw-loss = 0.4463578462600708, train/logprobs = tensor([[-0.5465, -3.4262],
        [-0.7511, -1.2340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022841982543468475
Epoch 0, Step 1642: train/loss = 0.6124887466430664, train/raw-loss = 0.5345408320426941, train/logprobs = tensor([[-0.8733, -1.9528],
        [-0.9162, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025982610881328583
Epoch 0, Step 1643: train/loss = 0.3343738913536072, train/raw-loss = 0.23397743701934814, train/logprobs = tensor([[-1.8262, -3.8232],
        [-3.6621, -1.4497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03346547856926918
Epoch 0, Step 1644: train/loss = 0.6619919538497925, train/raw-loss = 0.5684933066368103, train/logprobs = tensor([[-1.3302, -2.2053],
        [-1.5650, -1.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031166212633252144
Epoch 0, Step 1645: train/loss = 0.3820563852787018, train/raw-loss = 0.23575058579444885, train/logprobs = tensor([[-1.2536, -2.7126],
        [-3.3456, -1.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04876860976219177
Epoch 0, Step 1646: train/loss = 0.3731793463230133, train/raw-loss = 0.25407931208610535, train/logprobs = tensor([[-1.0912, -3.6390],
        [-2.7451, -1.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039700012654066086
Epoch 0, Step 1647: train/loss = 0.6405563950538635, train/raw-loss = 0.5765525698661804, train/logprobs = tensor([[-0.7183, -0.6816],
        [-1.3105, -0.4637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021334614604711533
Epoch 0, Step 1648: train/loss = 0.4568306803703308, train/raw-loss = 0.3565615117549896, train/logprobs = tensor([[-1.4531, -1.4420],
        [-3.7201, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0334230475127697
Epoch 0, Step 1649: train/loss = 0.5698092579841614, train/raw-loss = 0.4308529794216156, train/logprobs = tensor([[-1.0596, -2.8356],
        [-3.9282, -2.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046318769454956055
Epoch 0, Step 1650: train/loss = 0.43733692169189453, train/raw-loss = 0.36968764662742615, train/logprobs = tensor([[-0.9017, -4.4255],
        [-0.7896, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02254975400865078
Epoch 0, Step 1651: train/loss = 0.34518688917160034, train/raw-loss = 0.24842166900634766, train/logprobs = tensor([[-0.7584, -4.1471],
        [-1.4678, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03225506842136383
Epoch 0, Step 1652: train/loss = 0.5455750823020935, train/raw-loss = 0.44943878054618835, train/logprobs = tensor([[-1.3571, -2.7289],
        [-1.8072, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03204542398452759
Epoch 0, Step 1653: train/loss = 0.8891234397888184, train/raw-loss = 0.7669025659561157, train/logprobs = tensor([[-0.8026, -2.6574],
        [-1.7626, -2.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040740299969911575
Epoch 0, Step 1654: train/loss = 0.4373326599597931, train/raw-loss = 0.3648757338523865, train/logprobs = tensor([[-0.5146, -4.8679],
        [-0.5753, -1.3104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02415231242775917
Epoch 0, Step 1655: train/loss = 0.29647916555404663, train/raw-loss = 0.19575409591197968, train/logprobs = tensor([[-0.8053, -5.0063],
        [-1.9742, -1.3951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03357502445578575
Epoch 0, Step 1656: train/loss = 0.33191657066345215, train/raw-loss = 0.2410006821155548, train/logprobs = tensor([[-0.9006, -2.8993],
        [-2.4653, -0.6673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030305298045277596
Epoch 0, Step 1657: train/loss = 0.38286542892456055, train/raw-loss = 0.26933711767196655, train/logprobs = tensor([[-1.0573, -2.7529],
        [-2.4574, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0378427729010582
Epoch 0, Step 1658: train/loss = 0.4369385242462158, train/raw-loss = 0.3197939693927765, train/logprobs = tensor([[-1.5993, -3.6452],
        [-2.8171, -1.2514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03904817998409271
Epoch 0, Step 1659: train/loss = 0.5633550882339478, train/raw-loss = 0.4701271653175354, train/logprobs = tensor([[-1.3667, -3.4080],
        [-2.3220, -1.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031075971201062202
Epoch 0, Step 1660: train/loss = 0.36286765336990356, train/raw-loss = 0.24717706441879272, train/logprobs = tensor([[-0.8711, -2.5964],
        [-3.0242, -0.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03856353089213371
Epoch 0, Step 1661: train/loss = 0.3242926597595215, train/raw-loss = 0.2188299298286438, train/logprobs = tensor([[-0.8228, -4.2406],
        [-1.7488, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03515424206852913
Epoch 0, Step 1662: train/loss = 0.4857775866985321, train/raw-loss = 0.38374096155166626, train/logprobs = tensor([[-0.8738, -2.7836],
        [-1.3368, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034012213349342346
Epoch 0, Step 1663: train/loss = 0.41653579473495483, train/raw-loss = 0.32235047221183777, train/logprobs = tensor([[-1.0068, -2.9470],
        [-1.7694, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03139510005712509
Epoch 0, Step 1664: train/loss = 0.4088009297847748, train/raw-loss = 0.32757264375686646, train/logprobs = tensor([[-0.7854, -3.2962],
        [-1.5127, -0.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027076100930571556
Epoch 0, Step 1665: train/loss = 0.30769848823547363, train/raw-loss = 0.19801753759384155, train/logprobs = tensor([[-0.9654, -4.5221],
        [-1.8864, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036560311913490295
Epoch 0, Step 1666: train/loss = 0.25743594765663147, train/raw-loss = 0.11462460458278656, train/logprobs = tensor([[-1.2097, -4.1727],
        [-3.6619, -1.0318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0476037822663784
Epoch 0, Step 1667: train/loss = 0.6067287921905518, train/raw-loss = 0.53045254945755, train/logprobs = tensor([[-0.7306, -1.6785],
        [-0.7559, -0.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025425422936677933
Epoch 0, Step 1668: train/loss = 0.37352561950683594, train/raw-loss = 0.29633909463882446, train/logprobs = tensor([[-1.2387, -4.7706],
        [-1.5020, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025728832930326462
Epoch 0, Step 1669: train/loss = 0.42811137437820435, train/raw-loss = 0.33630627393722534, train/logprobs = tensor([[-1.0673, -2.2286],
        [-2.9190, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03060169145464897
Epoch 0, Step 1670: train/loss = 0.5392265915870667, train/raw-loss = 0.4348173439502716, train/logprobs = tensor([[-0.9041, -3.2777],
        [-1.6228, -1.5408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034803081303834915
Epoch 0, Step 1671: train/loss = 0.4799647331237793, train/raw-loss = 0.3607712984085083, train/logprobs = tensor([[-1.7039, -1.8780],
        [-3.9182, -1.1531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03973115235567093
Epoch 0, Step 1672: train/loss = 0.5212644934654236, train/raw-loss = 0.4524342715740204, train/logprobs = tensor([[-1.8777, -3.8230],
        [-2.1810, -1.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02294340170919895
Epoch 0, Step 1673: train/loss = 0.5770817399024963, train/raw-loss = 0.4799053966999054, train/logprobs = tensor([[-0.7093, -1.4737],
        [-1.9408, -0.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03239211440086365
Epoch 0, Step 1674: train/loss = 0.49198728799819946, train/raw-loss = 0.39317336678504944, train/logprobs = tensor([[-0.8037, -4.0130],
        [-1.5461, -1.2015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03293798118829727
Epoch 0, Step 1675: train/loss = 0.6526796221733093, train/raw-loss = 0.584837794303894, train/logprobs = tensor([[-1.4603, -1.3851],
        [-1.6511, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02261393517255783
Epoch 0, Step 1676: train/loss = 0.37562066316604614, train/raw-loss = 0.26775550842285156, train/logprobs = tensor([[-0.9896, -3.7019],
        [-2.3633, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035955045372247696
Epoch 0, Step 1677: train/loss = 0.46034759283065796, train/raw-loss = 0.3605140447616577, train/logprobs = tensor([[-0.8677, -2.9986],
        [-1.9044, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03327784314751625
Epoch 0, Step 1678: train/loss = 0.6074386835098267, train/raw-loss = 0.5238167643547058, train/logprobs = tensor([[-1.8699, -3.5668],
        [-1.5130, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02787395380437374
Epoch 0, Step 1679: train/loss = 0.4232465922832489, train/raw-loss = 0.2985767722129822, train/logprobs = tensor([[-1.2815, -4.1236],
        [-2.2459, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04155660793185234
Epoch 0, Step 1680: train/loss = 0.29976555705070496, train/raw-loss = 0.16834904253482819, train/logprobs = tensor([[-1.2526, -3.5335],
        [-3.1232, -1.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043805498629808426
Epoch 0, Step 1681: train/loss = 0.5461260676383972, train/raw-loss = 0.4615050256252289, train/logprobs = tensor([[-0.8863, -3.2753],
        [-1.0376, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028207026422023773
Epoch 0, Step 1682: train/loss = 0.3768148720264435, train/raw-loss = 0.25274768471717834, train/logprobs = tensor([[-1.1121, -3.1958],
        [-3.4781, -1.5550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04135572910308838
Epoch 0, Step 1683: train/loss = 0.3804333806037903, train/raw-loss = 0.2604398727416992, train/logprobs = tensor([[-1.3000, -4.2524],
        [-2.1464, -1.0456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03999783471226692
Epoch 0, Step 1684: train/loss = 0.4119991660118103, train/raw-loss = 0.3098030686378479, train/logprobs = tensor([[-1.1958, -2.8450],
        [-2.0302, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034065354615449905
Epoch 0, Step 1685: train/loss = 0.548279345035553, train/raw-loss = 0.47244521975517273, train/logprobs = tensor([[-0.9241, -2.0655],
        [-1.6837, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025278037413954735
Epoch 0, Step 1686: train/loss = 0.3925716280937195, train/raw-loss = 0.293589323759079, train/logprobs = tensor([[-0.7733, -2.1643],
        [-2.1271, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0329940989613533
Epoch 0, Step 1687: train/loss = 0.49060535430908203, train/raw-loss = 0.38470566272735596, train/logprobs = tensor([[-1.4200, -4.0035],
        [-1.9175, -1.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0352998822927475
Epoch 0, Step 1688: train/loss = 0.468148410320282, train/raw-loss = 0.3948316276073456, train/logprobs = tensor([[-0.7379, -2.8281],
        [-1.3557, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02443893440067768
Epoch 0, Step 1689: train/loss = 0.4503377079963684, train/raw-loss = 0.37245887517929077, train/logprobs = tensor([[-1.1253, -2.6051],
        [-1.6368, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02595961093902588
Epoch 0, Step 1690: train/loss = 0.2921231985092163, train/raw-loss = 0.14471036195755005, train/logprobs = tensor([[-1.1746, -3.0317],
        [-4.8076, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049137599766254425
Epoch 0, Step 1691: train/loss = 0.8391086459159851, train/raw-loss = 0.7047213315963745, train/logprobs = tensor([[-0.7203, -2.9556],
        [-1.8479, -2.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04479578137397766
Epoch 0, Step 1692: train/loss = 0.8209627866744995, train/raw-loss = 0.7003440260887146, train/logprobs = tensor([[-1.3794, -4.9641],
        [-1.7636, -3.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04020623862743378
Epoch 0, Step 1693: train/loss = 0.36423325538635254, train/raw-loss = 0.25825920701026917, train/logprobs = tensor([[-0.9925, -3.8201],
        [-2.4495, -1.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03532467782497406
Epoch 0, Step 1694: train/loss = 0.41308653354644775, train/raw-loss = 0.33478426933288574, train/logprobs = tensor([[-1.0755, -3.9097],
        [-1.4029, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026100749149918556
Epoch 0, Step 1695: train/loss = 0.5659694671630859, train/raw-loss = 0.44106024503707886, train/logprobs = tensor([[-1.9469, -4.2226],
        [-1.9948, -0.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04163641482591629
Epoch 0, Step 1696: train/loss = 0.4385570287704468, train/raw-loss = 0.3496040105819702, train/logprobs = tensor([[-1.8657, -2.7299],
        [-3.4177, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02965099737048149
Epoch 0, Step 1697: train/loss = 0.3219810128211975, train/raw-loss = 0.22204546630382538, train/logprobs = tensor([[-0.8615, -6.2404],
        [-1.8770, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03331184387207031
Epoch 0, Step 1698: train/loss = 0.42587167024612427, train/raw-loss = 0.31442466378211975, train/logprobs = tensor([[-1.2997, -1.6714],
        [-3.4261, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03714900463819504
Epoch 0, Step 1699: train/loss = 0.4918888807296753, train/raw-loss = 0.40088003873825073, train/logprobs = tensor([[-1.1002, -2.5498],
        [-2.2274, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03033629059791565
Epoch 0, Step 1700: train/loss = 0.6248651146888733, train/raw-loss = 0.5444546937942505, train/logprobs = tensor([[-1.0667, -1.3812],
        [-1.5912, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026803478598594666
Epoch 0, Step 1701: train/loss = 0.5793697834014893, train/raw-loss = 0.46891582012176514, train/logprobs = tensor([[-1.0244, -3.0896],
        [-2.6368, -1.6965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03681798279285431
Epoch 0, Step 1702: train/loss = 0.516465425491333, train/raw-loss = 0.4179476797580719, train/logprobs = tensor([[-0.8946, -2.7558],
        [-1.8136, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03283924236893654
Epoch 0, Step 1703: train/loss = 0.5689622163772583, train/raw-loss = 0.48146557807922363, train/logprobs = tensor([[-0.7841, -1.6512],
        [-1.5163, -0.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029165547341108322
Epoch 0, Step 1704: train/loss = 0.5204015970230103, train/raw-loss = 0.4373012185096741, train/logprobs = tensor([[-1.3327, -2.3618],
        [-2.2043, -0.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027700131759047508
Epoch 0, Step 1705: train/loss = 0.38779523968696594, train/raw-loss = 0.2580171823501587, train/logprobs = tensor([[-1.2336, -3.8448],
        [-2.7815, -1.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04325934499502182
Epoch 0, Step 1706: train/loss = 0.46095454692840576, train/raw-loss = 0.39355576038360596, train/logprobs = tensor([[-0.7055, -3.3350],
        [-0.8631, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022466272115707397
Epoch 0, Step 1707: train/loss = 0.6217088103294373, train/raw-loss = 0.5539963841438293, train/logprobs = tensor([[-0.8548, -1.0544],
        [-1.4206, -0.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022570807486772537
Epoch 0, Step 1708: train/loss = 0.6077409982681274, train/raw-loss = 0.5385655164718628, train/logprobs = tensor([[-0.6644, -2.1171],
        [-0.6656, -1.1552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023058505728840828
Epoch 0, Step 1709: train/loss = 0.4568234086036682, train/raw-loss = 0.37862783670425415, train/logprobs = tensor([[-0.8342, -3.3005],
        [-0.9288, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026065196841955185
Epoch 0, Step 1710: train/loss = 0.5210039019584656, train/raw-loss = 0.4494638442993164, train/logprobs = tensor([[-0.7880, -1.5621],
        [-1.6118, -0.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023846685886383057
Epoch 0, Step 1711: train/loss = 0.5822552442550659, train/raw-loss = 0.5059791803359985, train/logprobs = tensor([[-0.8254, -2.1041],
        [-0.8680, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02542535401880741
Epoch 0, Step 1712: train/loss = 0.35763347148895264, train/raw-loss = 0.26319748163223267, train/logprobs = tensor([[-1.2361, -5.0191],
        [-3.6239, -1.7529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03147866204380989
Epoch 0, Step 1713: train/loss = 0.4309231638908386, train/raw-loss = 0.3100094795227051, train/logprobs = tensor([[-1.0486, -2.4216],
        [-2.5510, -1.3500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04030456393957138
Epoch 0, Step 1714: train/loss = 0.693149983882904, train/raw-loss = 0.6131982803344727, train/logprobs = tensor([[-0.5651, -2.7700],
        [-0.6474, -1.6578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026650575920939445
Epoch 0, Step 1715: train/loss = 0.40817105770111084, train/raw-loss = 0.3092523217201233, train/logprobs = tensor([[-1.1808, -3.3151],
        [-2.0356, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03297291696071625
Epoch 0, Step 1716: train/loss = 0.5495495796203613, train/raw-loss = 0.45836520195007324, train/logprobs = tensor([[-0.9050, -2.5477],
        [-1.2046, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03039480186998844
Epoch 0, Step 1717: train/loss = 0.592483401298523, train/raw-loss = 0.5126004219055176, train/logprobs = tensor([[-0.9382, -2.5973],
        [-1.0386, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02662765048444271
Epoch 0, Step 1718: train/loss = 0.4673788547515869, train/raw-loss = 0.37070995569229126, train/logprobs = tensor([[-0.7195, -2.6316],
        [-1.8092, -0.6943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03222297877073288
Epoch 0, Step 1719: train/loss = 0.409018874168396, train/raw-loss = 0.32357126474380493, train/logprobs = tensor([[-0.7827, -4.2065],
        [-1.4908, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02848254330456257
Epoch 0, Step 1720: train/loss = 0.48785868287086487, train/raw-loss = 0.40442681312561035, train/logprobs = tensor([[-1.2059, -2.5175],
        [-2.1586, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027810625731945038
Epoch 0, Step 1721: train/loss = 0.43417859077453613, train/raw-loss = 0.35093313455581665, train/logprobs = tensor([[-0.8034, -2.8004],
        [-1.5885, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02774849534034729
Epoch 0, Step 1722: train/loss = 0.4484032392501831, train/raw-loss = 0.3301476836204529, train/logprobs = tensor([[-0.6360, -3.9990],
        [-1.3105, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0394185334444046
Epoch 0, Step 1723: train/loss = 0.3886093497276306, train/raw-loss = 0.28454703092575073, train/logprobs = tensor([[-1.0859, -4.8094],
        [-1.8041, -1.4403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034687429666519165
Epoch 0, Step 1724: train/loss = 0.6100491881370544, train/raw-loss = 0.5225613117218018, train/logprobs = tensor([[-1.1231, -0.8527],
        [-2.0485, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029162613674998283
Epoch 0, Step 1725: train/loss = 0.7075303196907043, train/raw-loss = 0.566493570804596, train/logprobs = tensor([[-0.7541, -1.2769],
        [-1.1037, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04701225087046623
Epoch 0, Step 1726: train/loss = 0.41376423835754395, train/raw-loss = 0.32443299889564514, train/logprobs = tensor([[-0.8988, -3.7620],
        [-1.7471, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029777083545923233
Epoch 0, Step 1727: train/loss = 0.4155743718147278, train/raw-loss = 0.2979358434677124, train/logprobs = tensor([[-0.9302, -3.5253],
        [-1.5362, -0.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03921284154057503
Epoch 0, Step 1728: train/loss = 0.5532722473144531, train/raw-loss = 0.48167160153388977, train/logprobs = tensor([[-1.0435, -2.8035],
        [-1.1073, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023866888135671616
Epoch 0, Step 1729: train/loss = 0.32997870445251465, train/raw-loss = 0.21971449255943298, train/logprobs = tensor([[-0.8819, -3.7263],
        [-1.8923, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03675473853945732
Epoch 0, Step 1730: train/loss = 0.4335290491580963, train/raw-loss = 0.33640056848526, train/logprobs = tensor([[-1.3732, -2.6589],
        [-3.1983, -0.6629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03237617388367653
Epoch 0, Step 1731: train/loss = 0.5653734803199768, train/raw-loss = 0.42521268129348755, train/logprobs = tensor([[-1.0071, -3.1888],
        [-3.7197, -1.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04672027379274368
Epoch 0, Step 1732: train/loss = 0.42045164108276367, train/raw-loss = 0.32618170976638794, train/logprobs = tensor([[-0.7846, -2.4785],
        [-2.4443, -0.7464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03142330050468445
Epoch 0, Step 1733: train/loss = 0.506462812423706, train/raw-loss = 0.43296343088150024, train/logprobs = tensor([[-0.6490, -3.1037],
        [-0.8445, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024499809369444847
Epoch 0, Step 1734: train/loss = 0.5538679361343384, train/raw-loss = 0.49157416820526123, train/logprobs = tensor([[-0.6805, -3.6081],
        [-1.1068, -1.4173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020764576271176338
Epoch 0, Step 1735: train/loss = 0.4916613698005676, train/raw-loss = 0.37383100390434265, train/logprobs = tensor([[-1.0431, -2.6417],
        [-1.8510, -0.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03927679359912872
Epoch 0, Step 1736: train/loss = 0.42963773012161255, train/raw-loss = 0.35501629114151, train/logprobs = tensor([[-0.7484, -2.3489],
        [-1.8868, -0.6242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024873808026313782
Epoch 0, Step 1737: train/loss = 0.4044187366962433, train/raw-loss = 0.3341253697872162, train/logprobs = tensor([[-0.9154, -4.8942],
        [-1.1965, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023431116715073586
Epoch 0, Step 1738: train/loss = 0.49576854705810547, train/raw-loss = 0.37754109501838684, train/logprobs = tensor([[-0.9843, -1.7657],
        [-3.2936, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039409153163433075
Epoch 0, Step 1739: train/loss = 0.3977275788784027, train/raw-loss = 0.3135467767715454, train/logprobs = tensor([[-0.9112, -4.6955],
        [-1.4449, -1.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02806025743484497
Epoch 0, Step 1740: train/loss = 0.4314470887184143, train/raw-loss = 0.364207923412323, train/logprobs = tensor([[-0.6675, -4.7665],
        [-0.8126, -1.5599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02241305261850357
Epoch 0, Step 1741: train/loss = 0.5261393785476685, train/raw-loss = 0.4287694990634918, train/logprobs = tensor([[-0.9280, -1.5582],
        [-2.6138, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03245662897825241
Epoch 0, Step 1742: train/loss = 0.4465823471546173, train/raw-loss = 0.3471633493900299, train/logprobs = tensor([[-0.9948, -2.4558],
        [-1.8456, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0331396609544754
Epoch 0, Step 1743: train/loss = 0.425750195980072, train/raw-loss = 0.3359462320804596, train/logprobs = tensor([[-0.8906, -3.1378],
        [-1.6586, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02993466705083847
Epoch 0, Step 1744: train/loss = 0.526129961013794, train/raw-loss = 0.420227974653244, train/logprobs = tensor([[-0.5509, -2.1035],
        [-1.0656, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035300664603710175
Epoch 0, Step 1745: train/loss = 0.6392355561256409, train/raw-loss = 0.5522242188453674, train/logprobs = tensor([[-0.8754, -1.0885],
        [-1.2636, -0.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029003791511058807
Epoch 0, Step 1746: train/loss = 0.6090115904808044, train/raw-loss = 0.5510568618774414, train/logprobs = tensor([[-0.9247, -2.5566],
        [-1.2257, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0193182360380888
Epoch 0, Step 1747: train/loss = 0.4017690420150757, train/raw-loss = 0.2787523865699768, train/logprobs = tensor([[-0.9607, -1.9285],
        [-3.7715, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041005540639162064
Epoch 0, Step 1748: train/loss = 0.5220308303833008, train/raw-loss = 0.41057899594306946, train/logprobs = tensor([[-1.0209, -3.2688],
        [-1.6710, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037150606513023376
Epoch 0, Step 1749: train/loss = 0.6241961717605591, train/raw-loss = 0.5510602593421936, train/logprobs = tensor([[-0.7535, -2.2317],
        [-0.9746, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024378620088100433
Epoch 0, Step 1750: train/loss = 0.38922804594039917, train/raw-loss = 0.29273244738578796, train/logprobs = tensor([[-1.0334, -3.4251],
        [-2.0906, -1.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032165203243494034
Epoch 0, Step 1751: train/loss = 0.3081418573856354, train/raw-loss = 0.1912284940481186, train/logprobs = tensor([[-1.1751, -2.9482],
        [-3.4739, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03897112235426903
Epoch 0, Step 1752: train/loss = 0.4537079632282257, train/raw-loss = 0.3837944269180298, train/logprobs = tensor([[-0.6322, -3.9616],
        [-0.8104, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023304510861635208
Epoch 0, Step 1753: train/loss = 0.3549732565879822, train/raw-loss = 0.21883819997310638, train/logprobs = tensor([[-1.0544, -4.0514],
        [-4.4292, -1.4702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045378342270851135
Epoch 0, Step 1754: train/loss = 0.482662558555603, train/raw-loss = 0.3449632525444031, train/logprobs = tensor([[-1.1505, -2.7069],
        [-3.1458, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045899759978055954
Epoch 0, Step 1755: train/loss = 0.4529861807823181, train/raw-loss = 0.35900115966796875, train/logprobs = tensor([[-1.3113, -3.1018],
        [-2.2790, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031328342854976654
Epoch 0, Step 1756: train/loss = 0.6155201196670532, train/raw-loss = 0.552069902420044, train/logprobs = tensor([[-0.7526, -2.0761],
        [-0.8555, -0.8751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021150069311261177
Epoch 0, Step 1757: train/loss = 0.4067918062210083, train/raw-loss = 0.32286590337753296, train/logprobs = tensor([[-0.8312, -3.6501],
        [-1.4294, -1.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0279752928763628
Epoch 0, Step 1758: train/loss = 0.8403483033180237, train/raw-loss = 0.7359358072280884, train/logprobs = tensor([[-0.7487, -2.4927],
        [-1.6080, -2.3422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034804172813892365
Epoch 0, Step 1759: train/loss = 0.3821379542350769, train/raw-loss = 0.25524574518203735, train/logprobs = tensor([[-1.0798, -2.4222],
        [-3.4043, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04229741171002388
Epoch 0, Step 1760: train/loss = 0.3899419605731964, train/raw-loss = 0.2879738211631775, train/logprobs = tensor([[-0.9499, -2.1620],
        [-2.7721, -0.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03398938477039337
Epoch 0, Step 1761: train/loss = 0.41288262605667114, train/raw-loss = 0.2996594309806824, train/logprobs = tensor([[-1.0151, -1.8136],
        [-3.6124, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03774106502532959
Epoch 0, Step 1762: train/loss = 0.3957434892654419, train/raw-loss = 0.3086845874786377, train/logprobs = tensor([[-1.1698, -5.5701],
        [-1.1420, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029019638895988464
Epoch 0, Step 1763: train/loss = 0.5750172734260559, train/raw-loss = 0.44763708114624023, train/logprobs = tensor([[-0.9181, -2.8558],
        [-2.3109, -1.5723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04246006906032562
Epoch 0, Step 1764: train/loss = 0.6763927936553955, train/raw-loss = 0.6277593374252319, train/logprobs = tensor([[-0.9385, -1.8925],
        [-0.8057, -1.2897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01621115393936634
Epoch 0, Step 1765: train/loss = 0.3405645191669464, train/raw-loss = 0.2334037721157074, train/logprobs = tensor([[-1.1761, -3.3006],
        [-2.0855, -0.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03572024405002594
Epoch 0, Step 1766: train/loss = 0.6076608300209045, train/raw-loss = 0.5039615035057068, train/logprobs = tensor([[-1.3497, -3.2204],
        [-2.3555, -1.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03456643968820572
Epoch 0, Step 1767: train/loss = 0.4224376976490021, train/raw-loss = 0.3426661193370819, train/logprobs = tensor([[-1.1714, -3.4884],
        [-1.5308, -0.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026590527966618538
Epoch 0, Step 1768: train/loss = 0.5449575185775757, train/raw-loss = 0.47072774171829224, train/logprobs = tensor([[-1.1597, -1.6989],
        [-1.7707, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024743245914578438
Epoch 0, Step 1769: train/loss = 0.3092527389526367, train/raw-loss = 0.21817024052143097, train/logprobs = tensor([[-1.0955, -5.7178],
        [-1.5254, -1.2554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030360836535692215
Epoch 0, Step 1770: train/loss = 0.41585662961006165, train/raw-loss = 0.29459255933761597, train/logprobs = tensor([[-1.4593, -3.6150],
        [-2.8563, -1.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04042136296629906
Epoch 0, Step 1771: train/loss = 0.3368203639984131, train/raw-loss = 0.24467727541923523, train/logprobs = tensor([[-0.6211, -4.2533],
        [-1.5855, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030714357271790504
Epoch 0, Step 1772: train/loss = 0.2966426610946655, train/raw-loss = 0.19944794476032257, train/logprobs = tensor([[-0.9845, -4.0925],
        [-2.3831, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03239824250340462
Epoch 0, Step 1773: train/loss = 0.6079253554344177, train/raw-loss = 0.5309290885925293, train/logprobs = tensor([[-0.7723, -2.5508],
        [-1.9837, -1.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02566542476415634
Epoch 0, Step 1774: train/loss = 0.47011667490005493, train/raw-loss = 0.4075382947921753, train/logprobs = tensor([[-1.1476, -4.0515],
        [-2.5132, -1.3871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02085946314036846
Epoch 0, Step 1775: train/loss = 0.4881943464279175, train/raw-loss = 0.4079556465148926, train/logprobs = tensor([[-1.1078, -2.5646],
        [-1.8964, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0267462357878685
Epoch 0, Step 1776: train/loss = 0.4341968297958374, train/raw-loss = 0.35332390666007996, train/logprobs = tensor([[-0.9075, -3.7380],
        [-1.1871, -1.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02695765346288681
Epoch 0, Step 1777: train/loss = 0.405967116355896, train/raw-loss = 0.31431564688682556, train/logprobs = tensor([[-0.8288, -3.4568],
        [-1.9420, -0.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030550487339496613
Epoch 0, Step 1778: train/loss = 0.44859954714775085, train/raw-loss = 0.3346215486526489, train/logprobs = tensor([[-0.8390, -2.3368],
        [-2.4816, -0.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037992674857378006
Epoch 0, Step 1779: train/loss = 0.6161866188049316, train/raw-loss = 0.5602388381958008, train/logprobs = tensor([[-0.7649, -0.7746],
        [-1.6926, -0.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018649248406291008
Epoch 0, Step 1780: train/loss = 0.30036747455596924, train/raw-loss = 0.18612177670001984, train/logprobs = tensor([[-0.8154, -5.0531],
        [-2.1947, -1.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03808189183473587
Epoch 0, Step 1781: train/loss = 0.4357319474220276, train/raw-loss = 0.33002209663391113, train/logprobs = tensor([[-0.8564, -2.7394],
        [-2.7718, -1.1290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03523661941289902
Epoch 0, Step 1782: train/loss = 0.8097195625305176, train/raw-loss = 0.7129244804382324, train/logprobs = tensor([[-1.1542, -2.5451],
        [-2.3116, -2.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03226502239704132
Epoch 0, Step 1783: train/loss = 0.7486708164215088, train/raw-loss = 0.6925868391990662, train/logprobs = tensor([[-1.8281, -3.1089],
        [-1.1405, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018694670870900154
Epoch 0, Step 1784: train/loss = 0.5244573950767517, train/raw-loss = 0.46381691098213196, train/logprobs = tensor([[-1.1579, -3.6720],
        [-1.5117, -1.6201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02021348476409912
Epoch 0, Step 1785: train/loss = 0.47208642959594727, train/raw-loss = 0.34619101881980896, train/logprobs = tensor([[-1.0082, -2.1756],
        [-2.5651, -1.2354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04196513444185257
Epoch 0, Step 1786: train/loss = 0.5222359895706177, train/raw-loss = 0.4408402442932129, train/logprobs = tensor([[-0.9753, -3.0691],
        [-2.2424, -1.6482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027131929993629456
Epoch 0, Step 1787: train/loss = 0.43418174982070923, train/raw-loss = 0.2980080842971802, train/logprobs = tensor([[-1.0932, -3.3030],
        [-2.9860, -1.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04539121314883232
Epoch 0, Step 1788: train/loss = 0.654269278049469, train/raw-loss = 0.5269853472709656, train/logprobs = tensor([[-0.7820, -3.5380],
        [-2.3513, -2.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04242797940969467
Epoch 0, Step 1789: train/loss = 0.5270267128944397, train/raw-loss = 0.4379061460494995, train/logprobs = tensor([[-1.0436, -2.4163],
        [-2.6230, -1.1385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029706858098506927
Epoch 0, Step 1790: train/loss = 0.4535070061683655, train/raw-loss = 0.3757556974887848, train/logprobs = tensor([[-0.6837, -2.8982],
        [-1.6154, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02591710351407528
Epoch 0, Step 1791: train/loss = 0.30000555515289307, train/raw-loss = 0.20117363333702087, train/logprobs = tensor([[-0.8119, -4.2727],
        [-1.8378, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03294398635625839
Epoch 0, Step 1792: train/loss = 0.5399616956710815, train/raw-loss = 0.48338109254837036, train/logprobs = tensor([[-1.5383, -2.4111],
        [-1.6718, -1.3395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01886019855737686
Epoch 0, Step 1793: train/loss = 0.5917536020278931, train/raw-loss = 0.47870349884033203, train/logprobs = tensor([[-1.6516, -3.9072],
        [-2.8061, -2.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03768336772918701
Epoch 0, Step 1794: train/loss = 0.4027179479598999, train/raw-loss = 0.3000946640968323, train/logprobs = tensor([[-0.8674, -3.2848],
        [-2.4517, -0.9258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03420776128768921
Epoch 0, Step 1795: train/loss = 0.5103715062141418, train/raw-loss = 0.4478326439857483, train/logprobs = tensor([[-0.7032, -2.9639],
        [-0.9739, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020846297964453697
Epoch 0, Step 1796: train/loss = 0.3699456453323364, train/raw-loss = 0.29915425181388855, train/logprobs = tensor([[-0.9646, -4.7655],
        [-1.5255, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02359713241457939
Epoch 0, Step 1797: train/loss = 0.4443293809890747, train/raw-loss = 0.36680611968040466, train/logprobs = tensor([[-1.0646, -3.2768],
        [-1.6546, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025841087102890015
Epoch 0, Step 1798: train/loss = 0.4124845266342163, train/raw-loss = 0.33321982622146606, train/logprobs = tensor([[-0.8588, -3.9298],
        [-1.0600, -0.9771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026421578601002693
Epoch 0, Step 1799: train/loss = 0.3398227095603943, train/raw-loss = 0.23386678099632263, train/logprobs = tensor([[-0.8533, -3.9986],
        [-2.2045, -1.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03531863912940025
Epoch 0, Step 1800: train/loss = 0.2724193036556244, train/raw-loss = 0.12545502185821533, train/logprobs = tensor([[-0.9288, -3.8087],
        [-3.0422, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04898809269070625
Epoch 0, Step 1801: train/loss = 0.42965131998062134, train/raw-loss = 0.32593947649002075, train/logprobs = tensor([[-1.0176, -3.0973],
        [-2.2757, -1.3910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0345706045627594
Epoch 0, Step 1802: train/loss = 0.3455428183078766, train/raw-loss = 0.2503034472465515, train/logprobs = tensor([[-0.8011, -3.7475],
        [-1.8529, -0.8592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031746458262205124
Epoch 0, Step 1803: train/loss = 0.4134076237678528, train/raw-loss = 0.3257334530353546, train/logprobs = tensor([[-0.9991, -3.1723],
        [-2.4094, -1.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02922472357749939
Epoch 0, Step 1804: train/loss = 0.3709987699985504, train/raw-loss = 0.28606078028678894, train/logprobs = tensor([[-1.0230, -3.5927],
        [-2.3952, -1.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02831266261637211
Epoch 0, Step 1805: train/loss = 0.4274752140045166, train/raw-loss = 0.3545314073562622, train/logprobs = tensor([[-0.6474, -4.1496],
        [-0.8744, -0.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02431461215019226
Epoch 0, Step 1806: train/loss = 0.40464580059051514, train/raw-loss = 0.3053300976753235, train/logprobs = tensor([[-1.1265, -3.4963],
        [-2.0105, -0.8811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03310523182153702
Epoch 0, Step 1807: train/loss = 0.5590213537216187, train/raw-loss = 0.49955418705940247, train/logprobs = tensor([[-1.0957, -2.1642],
        [-1.2349, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0198223739862442
Epoch 0, Step 1808: train/loss = 0.7400673627853394, train/raw-loss = 0.6731346249580383, train/logprobs = tensor([[-1.9026, -2.0622],
        [-1.4422, -1.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022310925647616386
Epoch 0, Step 1809: train/loss = 0.5224754214286804, train/raw-loss = 0.4697466194629669, train/logprobs = tensor([[-0.8459, -3.0679],
        [-1.1174, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01757626049220562
Epoch 0, Step 1810: train/loss = 0.5358890295028687, train/raw-loss = 0.4726366698741913, train/logprobs = tensor([[-0.6529, -2.4418],
        [-0.7072, -0.7323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021084127947688103
Epoch 0, Step 1811: train/loss = 0.5220341086387634, train/raw-loss = 0.3930469751358032, train/logprobs = tensor([[-0.8265, -4.3789],
        [-2.2127, -1.9522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04299570247530937
Epoch 0, Step 1812: train/loss = 0.3342078924179077, train/raw-loss = 0.24245646595954895, train/logprobs = tensor([[-0.5854, -4.3388],
        [-1.2353, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030583810061216354
Epoch 0, Step 1813: train/loss = 0.34748390316963196, train/raw-loss = 0.2617341876029968, train/logprobs = tensor([[-0.9270, -4.3556],
        [-1.7549, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028583236038684845
Epoch 0, Step 1814: train/loss = 0.4535669684410095, train/raw-loss = 0.36340659856796265, train/logprobs = tensor([[-1.1651, -3.1691],
        [-2.0342, -1.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03005344048142433
Epoch 0, Step 1815: train/loss = 0.45692434906959534, train/raw-loss = 0.39711862802505493, train/logprobs = tensor([[-0.8015, -2.3783],
        [-1.3769, -0.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019935235381126404
Epoch 0, Step 1816: train/loss = 0.6612645387649536, train/raw-loss = 0.603134274482727, train/logprobs = tensor([[-1.4983, -2.9301],
        [-1.1554, -1.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01937677152454853
Epoch 0, Step 1817: train/loss = 0.6832506656646729, train/raw-loss = 0.6209112405776978, train/logprobs = tensor([[-1.0950, -1.6807],
        [-0.8658, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020779810845851898
Epoch 0, Step 1818: train/loss = 0.5126276016235352, train/raw-loss = 0.4474051296710968, train/logprobs = tensor([[-0.7637, -2.3541],
        [-0.9418, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02174082212150097
Epoch 0, Step 1819: train/loss = 0.5082213878631592, train/raw-loss = 0.429019033908844, train/logprobs = tensor([[-0.9736, -2.3381],
        [-2.2609, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026400785893201828
Epoch 0, Step 1820: train/loss = 0.4828574061393738, train/raw-loss = 0.37429946660995483, train/logprobs = tensor([[-0.9301, -2.8468],
        [-1.5161, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03618598356842995
Epoch 0, Step 1821: train/loss = 0.5012919306755066, train/raw-loss = 0.4106038212776184, train/logprobs = tensor([[-0.9435, -2.6838],
        [-1.7020, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030229372903704643
Epoch 0, Step 1822: train/loss = 0.5496247410774231, train/raw-loss = 0.46497124433517456, train/logprobs = tensor([[-0.5380, -2.6200],
        [-0.7682, -0.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02821783721446991
Epoch 0, Step 1823: train/loss = 0.5402518510818481, train/raw-loss = 0.4570605754852295, train/logprobs = tensor([[-0.8775, -1.7628],
        [-2.0984, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027730435132980347
Epoch 0, Step 1824: train/loss = 0.44613975286483765, train/raw-loss = 0.38372093439102173, train/logprobs = tensor([[-0.8064, -3.4451],
        [-0.8907, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02080628089606762
Epoch 0, Step 1825: train/loss = 0.39090603590011597, train/raw-loss = 0.2909144163131714, train/logprobs = tensor([[-1.4332, -2.9024],
        [-3.9896, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033330533653497696
Epoch 0, Step 1826: train/loss = 0.4003392457962036, train/raw-loss = 0.32153159379959106, train/logprobs = tensor([[-0.8487, -2.9165],
        [-1.8195, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026269223541021347
Epoch 0, Step 1827: train/loss = 0.43039369583129883, train/raw-loss = 0.34431564807891846, train/logprobs = tensor([[-0.8503, -3.8117],
        [-1.7219, -2.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02869267761707306
Epoch 0, Step 1828: train/loss = 0.3949369490146637, train/raw-loss = 0.2906377911567688, train/logprobs = tensor([[-1.1785, -3.1108],
        [-2.8327, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03476637601852417
Epoch 0, Step 1829: train/loss = 0.3944181203842163, train/raw-loss = 0.3095499575138092, train/logprobs = tensor([[-0.7039, -3.4115],
        [-1.8266, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028289388865232468
Epoch 0, Step 1830: train/loss = 0.6783326268196106, train/raw-loss = 0.5745282173156738, train/logprobs = tensor([[-1.3751, -3.5182],
        [-1.6772, -2.3325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03460148349404335
Epoch 0, Step 1831: train/loss = 0.2562131881713867, train/raw-loss = 0.14208641648292542, train/logprobs = tensor([[-0.9815, -3.1749],
        [-4.1276, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03804226219654083
Epoch 0, Step 1832: train/loss = 0.4090900421142578, train/raw-loss = 0.32406896352767944, train/logprobs = tensor([[-1.0611, -4.5069],
        [-1.4733, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028340354561805725
Epoch 0, Step 1833: train/loss = 0.4727884531021118, train/raw-loss = 0.38934820890426636, train/logprobs = tensor([[-1.1311, -2.3910],
        [-2.5731, -1.3192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027813417837023735
Epoch 0, Step 1834: train/loss = 0.5443341732025146, train/raw-loss = 0.4671839475631714, train/logprobs = tensor([[-1.6612, -3.1086],
        [-2.5718, -2.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025716735050082207
Epoch 0, Step 1835: train/loss = 0.552666187286377, train/raw-loss = 0.4573707580566406, train/logprobs = tensor([[-0.6795, -2.0627],
        [-1.1441, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03176514059305191
Epoch 0, Step 1836: train/loss = 0.5629359483718872, train/raw-loss = 0.5033771991729736, train/logprobs = tensor([[-0.8018, -2.2509],
        [-1.3137, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019852912053465843
Epoch 0, Step 1837: train/loss = 0.3655017614364624, train/raw-loss = 0.2873880863189697, train/logprobs = tensor([[-0.8531, -5.0465],
        [-1.2422, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026037883013486862
Epoch 0, Step 1838: train/loss = 1.1254751682281494, train/raw-loss = 1.018208622932434, train/logprobs = tensor([[-1.3821, -1.9324],
        [-2.2337, -3.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03575550764799118
Epoch 0, Step 1839: train/loss = 0.3955399692058563, train/raw-loss = 0.2774907052516937, train/logprobs = tensor([[-0.9618, -2.9847],
        [-2.5857, -1.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0393497534096241
Epoch 0, Step 1840: train/loss = 0.7054530382156372, train/raw-loss = 0.5948765277862549, train/logprobs = tensor([[-1.8536, -2.4143],
        [-1.6343, -1.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03685884177684784
Epoch 0, Step 1841: train/loss = 0.40931951999664307, train/raw-loss = 0.3150269389152527, train/logprobs = tensor([[-0.7422, -2.5342],
        [-2.2953, -0.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03143085911870003
Epoch 0, Step 1842: train/loss = 0.3883695900440216, train/raw-loss = 0.2844409942626953, train/logprobs = tensor([[-0.9617, -3.0181],
        [-2.6559, -0.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03464287519454956
Epoch 0, Step 1843: train/loss = 0.5493392944335938, train/raw-loss = 0.4760062098503113, train/logprobs = tensor([[-0.7279, -1.3898],
        [-1.7026, -0.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024444356560707092
Epoch 0, Step 1844: train/loss = 0.49244338274002075, train/raw-loss = 0.4108275771141052, train/logprobs = tensor([[-1.1334, -2.9747],
        [-2.3486, -1.3759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027205266058444977
Epoch 0, Step 1845: train/loss = 0.44176119565963745, train/raw-loss = 0.37418776750564575, train/logprobs = tensor([[-0.6468, -2.7108],
        [-1.3487, -0.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022524476051330566
Epoch 0, Step 1846: train/loss = 0.5130264163017273, train/raw-loss = 0.463768869638443, train/logprobs = tensor([[-0.5728, -2.9743],
        [-0.7180, -0.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01641918532550335
Epoch 0, Step 1847: train/loss = 0.4161708354949951, train/raw-loss = 0.32115989923477173, train/logprobs = tensor([[-0.9622, -2.4205],
        [-3.1293, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031670309603214264
Epoch 0, Step 1848: train/loss = 0.4269225597381592, train/raw-loss = 0.2971000671386719, train/logprobs = tensor([[-0.8937, -2.8143],
        [-2.4668, -1.1224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0432741716504097
Epoch 0, Step 1849: train/loss = 0.43687903881073, train/raw-loss = 0.3189508616924286, train/logprobs = tensor([[-1.1742, -4.5731],
        [-2.0734, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03930938243865967
Epoch 0, Step 1850: train/loss = 0.37378019094467163, train/raw-loss = 0.2717127203941345, train/logprobs = tensor([[-0.8582, -3.5394],
        [-2.0207, -1.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034022487699985504
Epoch 0, Step 1851: train/loss = 0.4761466681957245, train/raw-loss = 0.386485755443573, train/logprobs = tensor([[-1.0538, -1.4139],
        [-2.4257, -0.6127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029886964708566666
Epoch 0, Step 1852: train/loss = 0.5556238889694214, train/raw-loss = 0.4666725993156433, train/logprobs = tensor([[-1.0233, -2.2038],
        [-1.8197, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029650423675775528
Epoch 0, Step 1853: train/loss = 0.4438798427581787, train/raw-loss = 0.3751961290836334, train/logprobs = tensor([[-0.8464, -2.5993],
        [-1.9647, -0.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022894568741321564
Epoch 0, Step 1854: train/loss = 0.28394725918769836, train/raw-loss = 0.2102583795785904, train/logprobs = tensor([[-0.7461, -5.7195],
        [-1.5454, -1.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024562958627939224
Epoch 0, Step 1855: train/loss = 0.379708468914032, train/raw-loss = 0.2745226323604584, train/logprobs = tensor([[-0.7936, -3.4843],
        [-1.5662, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035061948001384735
Epoch 0, Step 1856: train/loss = 0.3227041959762573, train/raw-loss = 0.2298741638660431, train/logprobs = tensor([[-1.0733, -4.5393],
        [-1.7487, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03094335086643696
Epoch 0, Step 1857: train/loss = 0.47179150581359863, train/raw-loss = 0.37708359956741333, train/logprobs = tensor([[-1.1094, -3.5221],
        [-1.5500, -0.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031569309532642365
Epoch 0, Step 1858: train/loss = 0.5003296136856079, train/raw-loss = 0.4317607879638672, train/logprobs = tensor([[-0.6105, -3.6424],
        [-0.6696, -1.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022856269031763077
Epoch 0, Step 1859: train/loss = 0.6284093856811523, train/raw-loss = 0.5839722752571106, train/logprobs = tensor([[-0.4890, -1.8145],
        [-0.6535, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014812351204454899
Epoch 0, Step 1860: train/loss = 0.3010971248149872, train/raw-loss = 0.1951046586036682, train/logprobs = tensor([[-1.0782, -2.9580],
        [-3.7618, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03533082455396652
Epoch 0, Step 1861: train/loss = 0.5469558835029602, train/raw-loss = 0.4623235762119293, train/logprobs = tensor([[-1.1338, -2.9164],
        [-2.5520, -1.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02821076475083828
Epoch 0, Step 1862: train/loss = 0.45421847701072693, train/raw-loss = 0.34703171253204346, train/logprobs = tensor([[-0.9877, -3.6503],
        [-1.6373, -1.3748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035728905349969864
Epoch 0, Step 1863: train/loss = 0.3307376503944397, train/raw-loss = 0.24218127131462097, train/logprobs = tensor([[-0.5793, -4.0593],
        [-1.5090, -1.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029518790543079376
Epoch 0, Step 1864: train/loss = 0.3840842843055725, train/raw-loss = 0.28618866205215454, train/logprobs = tensor([[-1.0901, -3.5480],
        [-2.2824, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03263188153505325
Epoch 0, Step 1865: train/loss = 0.5082476735115051, train/raw-loss = 0.4574110507965088, train/logprobs = tensor([[-0.7100, -3.0089],
        [-0.7784, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016945548355579376
Epoch 0, Step 1866: train/loss = 0.3397027254104614, train/raw-loss = 0.265363872051239, train/logprobs = tensor([[-0.7898, -4.9379],
        [-1.0039, -1.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02477961592376232
Epoch 0, Step 1867: train/loss = 0.8336187601089478, train/raw-loss = 0.7525140047073364, train/logprobs = tensor([[-0.8864, -2.2684],
        [-1.9925, -2.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02703491598367691
Epoch 0, Step 1868: train/loss = 0.49807411432266235, train/raw-loss = 0.4027755856513977, train/logprobs = tensor([[-1.0562, -2.3204],
        [-2.6376, -1.5266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03176616504788399
Epoch 0, Step 1869: train/loss = 0.4443301558494568, train/raw-loss = 0.36486196517944336, train/logprobs = tensor([[-1.0678, -3.7690],
        [-2.3724, -1.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026489382609725
Epoch 0, Step 1870: train/loss = 0.38231000304222107, train/raw-loss = 0.27624762058258057, train/logprobs = tensor([[-1.0522, -3.3166],
        [-2.6768, -1.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0353541374206543
Epoch 0, Step 1871: train/loss = 0.43036171793937683, train/raw-loss = 0.365229994058609, train/logprobs = tensor([[-0.6778, -4.2270],
        [-0.9478, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02171056717634201
Epoch 0, Step 1872: train/loss = 0.5379068851470947, train/raw-loss = 0.4758014976978302, train/logprobs = tensor([[-1.0967, -3.3994],
        [-1.0030, -1.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020701806992292404
Epoch 0, Step 1873: train/loss = 0.538841187953949, train/raw-loss = 0.4830295145511627, train/logprobs = tensor([[-0.9135, -2.1582],
        [-1.5481, -1.4854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018603885546326637
Epoch 0, Step 1874: train/loss = 0.24877701699733734, train/raw-loss = 0.1267121583223343, train/logprobs = tensor([[-1.1963, -4.7150],
        [-3.7209, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04068828374147415
Epoch 0, Step 1875: train/loss = 0.5251128673553467, train/raw-loss = 0.4481247067451477, train/logprobs = tensor([[-1.1233, -3.1906],
        [-1.4231, -1.4090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025662720203399658
Epoch 0, Step 1876: train/loss = 0.45470523834228516, train/raw-loss = 0.37178856134414673, train/logprobs = tensor([[-0.7285, -3.6009],
        [-1.1646, -1.0673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027638889849185944
Epoch 0, Step 1877: train/loss = 0.408552348613739, train/raw-loss = 0.31035611033439636, train/logprobs = tensor([[-1.0735, -3.2218],
        [-2.5328, -1.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032732076942920685
Epoch 0, Step 1878: train/loss = 0.5951735377311707, train/raw-loss = 0.5238199234008789, train/logprobs = tensor([[-0.6610, -2.3568],
        [-0.9091, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023784542456269264
Epoch 0, Step 1879: train/loss = 0.24095192551612854, train/raw-loss = 0.1518370658159256, train/logprobs = tensor([[-0.9948, -6.6351],
        [-2.6654, -2.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029704952612519264
Epoch 0, Step 1880: train/loss = 0.46491092443466187, train/raw-loss = 0.3746016025543213, train/logprobs = tensor([[-1.8907, -2.6178],
        [-3.5294, -0.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030103104189038277
Epoch 0, Step 1881: train/loss = 0.4252687394618988, train/raw-loss = 0.3354436159133911, train/logprobs = tensor([[-1.2188, -3.9258],
        [-1.4074, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029941711574792862
Epoch 0, Step 1882: train/loss = 0.4098743796348572, train/raw-loss = 0.33146238327026367, train/logprobs = tensor([[-0.7895, -3.2380],
        [-2.0750, -0.8172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026137331500649452
Epoch 0, Step 1883: train/loss = 0.3759632706642151, train/raw-loss = 0.2958559989929199, train/logprobs = tensor([[-1.0096, -3.3981],
        [-3.3956, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026702415198087692
Epoch 0, Step 1884: train/loss = 0.4398997128009796, train/raw-loss = 0.3695858120918274, train/logprobs = tensor([[-0.8293, -3.1269],
        [-1.5224, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023437976837158203
Epoch 0, Step 1885: train/loss = 0.4962114095687866, train/raw-loss = 0.4052390456199646, train/logprobs = tensor([[-1.2018, -1.8006],
        [-2.7466, -0.8616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030324121937155724
Epoch 0, Step 1886: train/loss = 0.3596569895744324, train/raw-loss = 0.26515209674835205, train/logprobs = tensor([[-1.1149, -2.9671],
        [-3.2028, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03150162473320961
Epoch 0, Step 1887: train/loss = 0.3987339437007904, train/raw-loss = 0.31712284684181213, train/logprobs = tensor([[-1.1494, -3.4725],
        [-1.3297, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027203692123293877
Epoch 0, Step 1888: train/loss = 0.5263013243675232, train/raw-loss = 0.44502586126327515, train/logprobs = tensor([[-1.9004, -1.9995],
        [-2.6824, -0.7126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02709181420505047
Epoch 0, Step 1889: train/loss = 0.2869769036769867, train/raw-loss = 0.1770876944065094, train/logprobs = tensor([[-0.8439, -4.2962],
        [-2.8183, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03662974014878273
Epoch 0, Step 1890: train/loss = 0.72902512550354, train/raw-loss = 0.6281958818435669, train/logprobs = tensor([[-1.3216, -2.4478],
        [-2.5206, -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03360975161194801
Epoch 0, Step 1891: train/loss = 0.3915523290634155, train/raw-loss = 0.31332927942276, train/logprobs = tensor([[-0.8834, -3.9221],
        [-1.6848, -0.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026074351742863655
Epoch 0, Step 1892: train/loss = 0.29225730895996094, train/raw-loss = 0.1839400678873062, train/logprobs = tensor([[-1.3314, -4.6745],
        [-3.1002, -1.2759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036105748265981674
Epoch 0, Step 1893: train/loss = 0.336326539516449, train/raw-loss = 0.22573743760585785, train/logprobs = tensor([[-1.5005, -3.5879],
        [-4.3152, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03686302900314331
Epoch 0, Step 1894: train/loss = 0.4669761657714844, train/raw-loss = 0.4029170274734497, train/logprobs = tensor([[-1.0141, -2.4011],
        [-2.2735, -1.1400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02135305292904377
Epoch 0, Step 1895: train/loss = 0.5517720580101013, train/raw-loss = 0.48904678225517273, train/logprobs = tensor([[-1.1213, -3.3250],
        [-1.7632, -1.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020908406004309654
Epoch 0, Step 1896: train/loss = 0.555983304977417, train/raw-loss = 0.4764653742313385, train/logprobs = tensor([[-1.1466, -1.5649],
        [-2.2732, -0.7819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02650599367916584
Epoch 0, Step 1897: train/loss = 0.4661563038825989, train/raw-loss = 0.39337313175201416, train/logprobs = tensor([[-0.7268, -3.7213],
        [-0.8234, -1.9016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02426106482744217
Epoch 0, Step 1898: train/loss = 0.48796597123146057, train/raw-loss = 0.3886912167072296, train/logprobs = tensor([[-1.4119, -2.4267],
        [-1.8942, -0.9726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03309158235788345
Epoch 0, Step 1899: train/loss = 0.5016299486160278, train/raw-loss = 0.41955816745758057, train/logprobs = tensor([[-1.0297, -2.0038],
        [-1.8719, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027357250452041626
Epoch 0, Step 1900: train/loss = 0.3698231279850006, train/raw-loss = 0.27123790979385376, train/logprobs = tensor([[-1.1760, -2.9586],
        [-2.5391, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03286173567175865
Epoch 0, Step 1901: train/loss = 0.47829902172088623, train/raw-loss = 0.4094296395778656, train/logprobs = tensor([[-1.0814, -3.4494],
        [-1.2312, -1.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02295645698904991
Epoch 0, Step 1902: train/loss = 0.6251014471054077, train/raw-loss = 0.5042529106140137, train/logprobs = tensor([[-1.7382, -3.3088],
        [-3.1751, -2.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040282849222421646
Epoch 0, Step 1903: train/loss = 0.33733534812927246, train/raw-loss = 0.2483464479446411, train/logprobs = tensor([[-0.6625, -4.3054],
        [-1.2781, -0.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0296629685908556
Epoch 0, Step 1904: train/loss = 0.5304108262062073, train/raw-loss = 0.4384944438934326, train/logprobs = tensor([[-1.6394, -1.6428],
        [-3.0783, -1.4947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030638793483376503
Epoch 0, Step 1905: train/loss = 0.35984790325164795, train/raw-loss = 0.2771967649459839, train/logprobs = tensor([[-0.8562, -3.3693],
        [-1.7343, -0.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02755037322640419
Epoch 0, Step 1906: train/loss = 0.4038844108581543, train/raw-loss = 0.3142358064651489, train/logprobs = tensor([[-0.9461, -2.0294],
        [-2.8273, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029882855713367462
Epoch 0, Step 1907: train/loss = 0.6323131322860718, train/raw-loss = 0.5857958793640137, train/logprobs = tensor([[-0.6521, -1.5427],
        [-0.6191, -0.7393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015505730174481869
Epoch 0, Step 1908: train/loss = 0.3303840756416321, train/raw-loss = 0.22527240216732025, train/logprobs = tensor([[-1.3004, -1.3955],
        [-4.4749, -0.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03503722324967384
Epoch 0, Step 1909: train/loss = 0.29249107837677, train/raw-loss = 0.15771964192390442, train/logprobs = tensor([[-1.1286, -4.8984],
        [-3.3559, -2.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0449238047003746
Epoch 0, Step 1910: train/loss = 0.6188346147537231, train/raw-loss = 0.5418949127197266, train/logprobs = tensor([[-1.0227, -1.4962],
        [-2.1085, -1.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02564655989408493
Epoch 0, Step 1911: train/loss = 0.577094316482544, train/raw-loss = 0.5024011135101318, train/logprobs = tensor([[-0.9415, -1.6213],
        [-1.8662, -1.1377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02489771880209446
Epoch 0, Step 1912: train/loss = 0.5485786199569702, train/raw-loss = 0.47300755977630615, train/logprobs = tensor([[-1.9446, -2.6564],
        [-2.8079, -1.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025190340355038643
Epoch 0, Step 1913: train/loss = 0.39361247420310974, train/raw-loss = 0.3179083466529846, train/logprobs = tensor([[-1.6467, -2.8849],
        [-3.1061, -1.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025234714150428772
Epoch 0, Step 1914: train/loss = 0.32775187492370605, train/raw-loss = 0.2314702570438385, train/logprobs = tensor([[-0.8790, -3.3789],
        [-2.7635, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032093875110149384
Epoch 0, Step 1915: train/loss = 0.35331782698631287, train/raw-loss = 0.27202773094177246, train/logprobs = tensor([[-1.2950, -3.6489],
        [-2.3947, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0270966999232769
Epoch 0, Step 1916: train/loss = 0.397763192653656, train/raw-loss = 0.3003268837928772, train/logprobs = tensor([[-0.9745, -1.5308],
        [-3.6887, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03247877210378647
Epoch 0, Step 1917: train/loss = 0.33859115839004517, train/raw-loss = 0.25648266077041626, train/logprobs = tensor([[-1.1875, -3.2893],
        [-2.6630, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027369510382413864
Epoch 0, Step 1918: train/loss = 0.501746416091919, train/raw-loss = 0.44530975818634033, train/logprobs = tensor([[-0.8108, -3.4024],
        [-0.8847, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018812233582139015
Epoch 0, Step 1919: train/loss = 0.3830960988998413, train/raw-loss = 0.3205450177192688, train/logprobs = tensor([[-0.7967, -5.0610],
        [-1.0662, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02085036411881447
Epoch 0, Step 1920: train/loss = 0.28305014967918396, train/raw-loss = 0.2042708843946457, train/logprobs = tensor([[-0.7347, -4.8121],
        [-1.8574, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026259753853082657
Epoch 0, Step 1921: train/loss = 0.2757619321346283, train/raw-loss = 0.181443452835083, train/logprobs = tensor([[-0.8503, -4.1255],
        [-2.5209, -1.0968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03143949434161186
Epoch 0, Step 1922: train/loss = 0.48283615708351135, train/raw-loss = 0.41370928287506104, train/logprobs = tensor([[-0.9355, -2.6539],
        [-1.7631, -1.1027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023042283952236176
Epoch 0, Step 1923: train/loss = 0.43410369753837585, train/raw-loss = 0.3704840838909149, train/logprobs = tensor([[-0.7909, -3.1128],
        [-1.5260, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021206524223089218
Epoch 0, Step 1924: train/loss = 0.5155915021896362, train/raw-loss = 0.43029049038887024, train/logprobs = tensor([[-1.4384, -2.3531],
        [-2.9393, -1.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028433676809072495
Epoch 0, Step 1925: train/loss = 0.46692973375320435, train/raw-loss = 0.4003832936286926, train/logprobs = tensor([[-2.1368, -2.3497],
        [-3.6129, -1.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022182149812579155
Epoch 0, Step 1926: train/loss = 0.3751598596572876, train/raw-loss = 0.29810231924057007, train/logprobs = tensor([[-0.8796, -3.5810],
        [-1.8883, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02568584680557251
Epoch 0, Step 1927: train/loss = 0.4913668632507324, train/raw-loss = 0.4129655361175537, train/logprobs = tensor([[-0.8398, -2.5993],
        [-1.9681, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02613377571105957
Epoch 0, Step 1928: train/loss = 0.42588627338409424, train/raw-loss = 0.3239690959453583, train/logprobs = tensor([[-0.9295, -1.7628],
        [-3.3225, -0.8076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033972401171922684
Epoch 0, Step 1929: train/loss = 0.4799967408180237, train/raw-loss = 0.40043699741363525, train/logprobs = tensor([[-0.8705, -2.0513],
        [-1.6460, -0.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026519909501075745
Epoch 0, Step 1930: train/loss = 0.4906659722328186, train/raw-loss = 0.4339185953140259, train/logprobs = tensor([[-0.7743, -1.9869],
        [-2.5099, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018915796652436256
Epoch 0, Step 1931: train/loss = 0.5216554403305054, train/raw-loss = 0.47069019079208374, train/logprobs = tensor([[-1.4795, -3.8368],
        [-1.5767, -1.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016988415271043777
Epoch 0, Step 1932: train/loss = 0.6118065118789673, train/raw-loss = 0.5513381958007812, train/logprobs = tensor([[-0.7380, -1.0555],
        [-1.6053, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020156092941761017
Epoch 0, Step 1933: train/loss = 0.5267829895019531, train/raw-loss = 0.460857093334198, train/logprobs = tensor([[-1.8961, -4.8230],
        [-1.4448, -1.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021975286304950714
Epoch 0, Step 1934: train/loss = 0.49240946769714355, train/raw-loss = 0.4015473425388336, train/logprobs = tensor([[-1.0095, -2.2507],
        [-2.6908, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030287370085716248
Epoch 0, Step 1935: train/loss = 0.3649493157863617, train/raw-loss = 0.28156036138534546, train/logprobs = tensor([[-1.6054, -4.2137],
        [-2.1524, -1.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027796320617198944
Epoch 0, Step 1936: train/loss = 0.6072608828544617, train/raw-loss = 0.5320665836334229, train/logprobs = tensor([[-0.9451, -1.6174],
        [-1.5568, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025064770132303238
Epoch 0, Step 1937: train/loss = 0.4288710951805115, train/raw-loss = 0.3582814931869507, train/logprobs = tensor([[-1.2811, -3.6881],
        [-1.8633, -1.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02352987229824066
Epoch 0, Step 1938: train/loss = 0.45892858505249023, train/raw-loss = 0.3807864189147949, train/logprobs = tensor([[-1.1319, -3.2638],
        [-2.1551, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026047401130199432
Epoch 0, Step 1939: train/loss = 0.5423359274864197, train/raw-loss = 0.4792179465293884, train/logprobs = tensor([[-1.0404, -2.9027],
        [-1.4504, -1.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02103932574391365
Epoch 0, Step 1940: train/loss = 0.40357911586761475, train/raw-loss = 0.32777315378189087, train/logprobs = tensor([[-0.8199, -3.1050],
        [-2.0119, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025268664583563805
Epoch 0, Step 1941: train/loss = 0.25032252073287964, train/raw-loss = 0.14539292454719543, train/logprobs = tensor([[-0.8731, -4.4461],
        [-3.2306, -1.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034976527094841
Epoch 0, Step 1942: train/loss = 0.33188408613204956, train/raw-loss = 0.2568597197532654, train/logprobs = tensor([[-0.4879, -4.1454],
        [-1.2233, -1.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02500811219215393
Epoch 0, Step 1943: train/loss = 0.5443229675292969, train/raw-loss = 0.4820753037929535, train/logprobs = tensor([[-0.7730, -3.0922],
        [-0.6858, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02074921317398548
Epoch 0, Step 1944: train/loss = 0.5400301814079285, train/raw-loss = 0.47789478302001953, train/logprobs = tensor([[-0.9008, -2.6406],
        [-1.0641, -1.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020711803808808327
Epoch 0, Step 1945: train/loss = 0.4567902684211731, train/raw-loss = 0.3674401640892029, train/logprobs = tensor([[-1.6109, -1.9953],
        [-3.2893, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02978336252272129
Epoch 0, Step 1946: train/loss = 0.38044366240501404, train/raw-loss = 0.3131618797779083, train/logprobs = tensor([[-0.8219, -3.4626],
        [-1.8170, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022427257150411606
Epoch 0, Step 1947: train/loss = 0.36731019616127014, train/raw-loss = 0.27041035890579224, train/logprobs = tensor([[-0.8399, -3.0083],
        [-2.4325, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0322999432682991
Epoch 0, Step 1948: train/loss = 0.5437856912612915, train/raw-loss = 0.48546984791755676, train/logprobs = tensor([[-0.9234, -3.8092],
        [-0.7656, -1.0587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019438618794083595
Epoch 0, Step 1949: train/loss = 0.43922197818756104, train/raw-loss = 0.3602961301803589, train/logprobs = tensor([[-0.9281, -4.2434],
        [-1.3367, -1.2621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026308611035346985
Epoch 0, Step 1950: train/loss = 0.5523171424865723, train/raw-loss = 0.49049317836761475, train/logprobs = tensor([[-0.8021, -3.9235],
        [-1.0390, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020607979968190193
Epoch 0, Step 1951: train/loss = 0.45281893014907837, train/raw-loss = 0.324784517288208, train/logprobs = tensor([[-1.0718, -2.7805],
        [-2.8537, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042678143829107285
Epoch 0, Step 1952: train/loss = 0.307806134223938, train/raw-loss = 0.21389776468276978, train/logprobs = tensor([[-0.7943, -5.5140],
        [-1.8337, -1.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031302787363529205
Epoch 0, Step 1953: train/loss = 0.513792872428894, train/raw-loss = 0.4639448821544647, train/logprobs = tensor([[-0.6296, -3.9966],
        [-0.7667, -1.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016615984961390495
Epoch 0, Step 1954: train/loss = 0.5499944686889648, train/raw-loss = 0.4874415397644043, train/logprobs = tensor([[-0.6700, -2.5740],
        [-0.6642, -0.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02085099183022976
Epoch 0, Step 1955: train/loss = 0.39471685886383057, train/raw-loss = 0.3179387152194977, train/logprobs = tensor([[-1.4964, -2.2327],
        [-3.1153, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025592710822820663
Epoch 0, Step 1956: train/loss = 0.4016662538051605, train/raw-loss = 0.32527410984039307, train/logprobs = tensor([[-0.9202, -3.7264],
        [-1.8468, -1.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025464056059718132
Epoch 0, Step 1957: train/loss = 0.37994664907455444, train/raw-loss = 0.2798722982406616, train/logprobs = tensor([[-1.1680, -3.0293],
        [-2.6453, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033358123153448105
Epoch 0, Step 1958: train/loss = 0.49521929025650024, train/raw-loss = 0.42719483375549316, train/logprobs = tensor([[-0.9980, -2.9229],
        [-2.2266, -1.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022674813866615295
Epoch 0, Step 1959: train/loss = 0.6201348304748535, train/raw-loss = 0.5588493347167969, train/logprobs = tensor([[-0.7420, -0.8212],
        [-1.7813, -0.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020428501069545746
Epoch 0, Step 1960: train/loss = 0.33081671595573425, train/raw-loss = 0.216293066740036, train/logprobs = tensor([[-1.2786, -3.6355],
        [-3.0233, -1.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038174547255039215
Epoch 0, Step 1961: train/loss = 0.5910475254058838, train/raw-loss = 0.5104889869689941, train/logprobs = tensor([[-0.9718, -2.0810],
        [-2.1695, -1.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02685284987092018
Epoch 0, Step 1962: train/loss = 0.6553801894187927, train/raw-loss = 0.6003576517105103, train/logprobs = tensor([[-0.6682, -0.7126],
        [-1.4089, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01834084652364254
Epoch 0, Step 1963: train/loss = 0.5261567234992981, train/raw-loss = 0.4137701392173767, train/logprobs = tensor([[-1.4676, -2.7135],
        [-2.4401, -1.1295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037462200969457626
Epoch 0, Step 1964: train/loss = 0.4152258038520813, train/raw-loss = 0.3267877697944641, train/logprobs = tensor([[-1.1469, -3.9437],
        [-2.2743, -1.7276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029479345306754112
Epoch 0, Step 1965: train/loss = 0.5431171655654907, train/raw-loss = 0.46765196323394775, train/logprobs = tensor([[-0.6100, -1.6624],
        [-1.1789, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02515505440533161
Epoch 0, Step 1966: train/loss = 0.3301214575767517, train/raw-loss = 0.25206899642944336, train/logprobs = tensor([[-0.7932, -4.0182],
        [-2.0330, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02601749077439308
Epoch 0, Step 1967: train/loss = 0.43399378657341003, train/raw-loss = 0.3653333783149719, train/logprobs = tensor([[-0.8578, -3.7320],
        [-1.5214, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02288680709898472
Epoch 0, Step 1968: train/loss = 0.4833623766899109, train/raw-loss = 0.4137774705886841, train/logprobs = tensor([[-0.7880, -3.4005],
        [-1.0649, -1.2844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023194972425699234
Epoch 0, Step 1969: train/loss = 0.5476552248001099, train/raw-loss = 0.46201708912849426, train/logprobs = tensor([[-0.9361, -2.0690],
        [-2.0380, -1.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028546055778861046
Epoch 0, Step 1970: train/loss = 0.4165685474872589, train/raw-loss = 0.3307328224182129, train/logprobs = tensor([[-2.2272, -2.2549],
        [-3.8806, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02861190214753151
Epoch 0, Step 1971: train/loss = 0.38408222794532776, train/raw-loss = 0.30973049998283386, train/logprobs = tensor([[-0.7300, -3.5052],
        [-1.6613, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0247839093208313
Epoch 0, Step 1972: train/loss = 0.5707184076309204, train/raw-loss = 0.5082448124885559, train/logprobs = tensor([[-0.7373, -1.4581],
        [-1.5699, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020824525505304337
Epoch 0, Step 1973: train/loss = 0.47326627373695374, train/raw-loss = 0.40529853105545044, train/logprobs = tensor([[-0.7919, -2.9346],
        [-1.5204, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0226559117436409
Epoch 0, Step 1974: train/loss = 0.4750470221042633, train/raw-loss = 0.3599900007247925, train/logprobs = tensor([[-1.5100, -3.0311],
        [-2.7889, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03835232928395271
Epoch 0, Step 1975: train/loss = 0.45410627126693726, train/raw-loss = 0.39114147424697876, train/logprobs = tensor([[-0.9843, -2.9569],
        [-1.8475, -1.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020988255739212036
Epoch 0, Step 1976: train/loss = 0.6887083053588867, train/raw-loss = 0.6301208734512329, train/logprobs = tensor([[-1.4873, -1.7739],
        [-2.2549, -1.5357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01952911913394928
Epoch 0, Step 1977: train/loss = 0.5406361818313599, train/raw-loss = 0.48059502243995667, train/logprobs = tensor([[-0.5410, -2.6139],
        [-0.5950, -0.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0200137160718441
Epoch 0, Step 1978: train/loss = 0.6425896286964417, train/raw-loss = 0.5993090867996216, train/logprobs = tensor([[-0.6809, -2.0492],
        [-0.9974, -1.3326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01442684791982174
Epoch 0, Step 1979: train/loss = 0.6190930604934692, train/raw-loss = 0.5168373584747314, train/logprobs = tensor([[-1.6123, -3.0455],
        [-3.2747, -1.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034085243940353394
Epoch 0, Step 1980: train/loss = 0.5577287673950195, train/raw-loss = 0.4643745422363281, train/logprobs = tensor([[-1.0367, -1.9546],
        [-2.7058, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03111807256937027
Epoch 0, Step 1981: train/loss = 0.24896648526191711, train/raw-loss = 0.13902950286865234, train/logprobs = tensor([[-1.0849, -5.7953],
        [-3.2395, -1.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664565831422806
Epoch 0, Step 1982: train/loss = 0.4357161223888397, train/raw-loss = 0.380827397108078, train/logprobs = tensor([[-0.8185, -4.5726],
        [-0.8642, -1.4189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018296245485544205
Epoch 0, Step 1983: train/loss = 0.6777032613754272, train/raw-loss = 0.5636317729949951, train/logprobs = tensor([[-1.3719, -1.9794],
        [-2.3538, -1.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03802382946014404
Epoch 0, Step 1984: train/loss = 0.4353567063808441, train/raw-loss = 0.3540685474872589, train/logprobs = tensor([[-0.9852, -2.0347],
        [-2.6004, -1.2702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02709605172276497
Epoch 0, Step 1985: train/loss = 1.0961146354675293, train/raw-loss = 0.9644052982330322, train/logprobs = tensor([[-1.8947, -3.2901],
        [-3.4181, -3.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043903134763240814
Epoch 0, Step 1986: train/loss = 0.4710429012775421, train/raw-loss = 0.39826732873916626, train/logprobs = tensor([[-1.0618, -3.4468],
        [-1.1406, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024258524179458618
Epoch 0, Step 1987: train/loss = 0.4629542827606201, train/raw-loss = 0.37553173303604126, train/logprobs = tensor([[-0.8689, -2.1060],
        [-1.9915, -0.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029140856117010117
Epoch 0, Step 1988: train/loss = 0.36466044187545776, train/raw-loss = 0.2869391143321991, train/logprobs = tensor([[-1.3456, -2.6603],
        [-3.6321, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025907117873430252
Epoch 0, Step 1989: train/loss = 0.4149661064147949, train/raw-loss = 0.2935636043548584, train/logprobs = tensor([[-1.6473, -3.3590],
        [-3.4075, -1.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04046750068664551
Epoch 0, Step 1990: train/loss = 0.31261271238327026, train/raw-loss = 0.2152041494846344, train/logprobs = tensor([[-0.9829, -3.6049],
        [-2.7237, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03246951103210449
Epoch 0, Step 1991: train/loss = 0.5330275297164917, train/raw-loss = 0.4673311710357666, train/logprobs = tensor([[-0.9738, -3.0570],
        [-0.6810, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021898794919252396
Epoch 0, Step 1992: train/loss = 0.41420525312423706, train/raw-loss = 0.3006734549999237, train/logprobs = tensor([[-1.2245, -3.6239],
        [-2.5535, -1.4577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03784393146634102
Epoch 0, Step 1993: train/loss = 0.3416500687599182, train/raw-loss = 0.25923845171928406, train/logprobs = tensor([[-1.0799, -3.0097],
        [-2.9340, -1.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027470538392663002
Epoch 0, Step 1994: train/loss = 0.7306365370750427, train/raw-loss = 0.6519418954849243, train/logprobs = tensor([[-2.4640, -3.4192],
        [-1.9474, -1.5622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026231549680233
Epoch 0, Step 1995: train/loss = 0.5331168174743652, train/raw-loss = 0.46581315994262695, train/logprobs = tensor([[-1.3776, -3.2238],
        [-1.6687, -1.7200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022434549406170845
Epoch 0, Step 1996: train/loss = 0.30794602632522583, train/raw-loss = 0.21548323333263397, train/logprobs = tensor([[-0.8133, -5.2141],
        [-1.9487, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030820928514003754
Epoch 0, Step 1997: train/loss = 0.5217532515525818, train/raw-loss = 0.43405699729919434, train/logprobs = tensor([[-0.8956, -2.7782],
        [-1.5862, -1.3715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029232092201709747
Epoch 0, Step 1998: train/loss = 0.5476170778274536, train/raw-loss = 0.47624602913856506, train/logprobs = tensor([[-1.2948, -4.0250],
        [-0.8584, -1.1549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023790353909134865
Epoch 0, Step 1999: train/loss = 0.5595765113830566, train/raw-loss = 0.4660422205924988, train/logprobs = tensor([[-1.0473, -1.8728],
        [-1.8566, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031178103759884834
Loss is nan
eval/loss: 0.4641866683959961
Epoch 0, Step 2000: train/loss = 0.476645290851593, train/raw-loss = 0.37864527106285095, train/logprobs = tensor([[-1.5076, -1.4529],
        [-3.1471, -0.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03266667202115059
Epoch 0, Step 2001: train/loss = 0.6852210164070129, train/raw-loss = 0.6118425130844116, train/logprobs = tensor([[-0.8939, -2.2418],
        [-1.6303, -1.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024459538981318474
Epoch 0, Step 2002: train/loss = 0.36986246705055237, train/raw-loss = 0.2809232175350189, train/logprobs = tensor([[-0.9750, -3.9495],
        [-2.3384, -1.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02964642085134983
Epoch 0, Step 2003: train/loss = 0.5666264295578003, train/raw-loss = 0.4699091613292694, train/logprobs = tensor([[-1.0570, -2.1949],
        [-2.2937, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032239072024822235
Epoch 0, Step 2004: train/loss = 0.2879944443702698, train/raw-loss = 0.18061944842338562, train/logprobs = tensor([[-1.1142, -4.1047],
        [-3.5801, -1.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035791657865047455
Epoch 0, Step 2005: train/loss = 0.5538665056228638, train/raw-loss = 0.4794118106365204, train/logprobs = tensor([[-1.5038, -3.1995],
        [-1.4999, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02481822669506073
Epoch 0, Step 2006: train/loss = 0.2695155739784241, train/raw-loss = 0.163065567612648, train/logprobs = tensor([[-1.1614, -4.0027],
        [-3.4940, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03548334166407585
Epoch 0, Step 2007: train/loss = 0.3219441771507263, train/raw-loss = 0.23160485923290253, train/logprobs = tensor([[-0.9581, -3.5163],
        [-2.7415, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030113112181425095
Epoch 0, Step 2008: train/loss = 0.6042874455451965, train/raw-loss = 0.538411021232605, train/logprobs = tensor([[-0.7295, -2.0479],
        [-0.7201, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02195880003273487
Epoch 0, Step 2009: train/loss = 0.49145400524139404, train/raw-loss = 0.41751304268836975, train/logprobs = tensor([[-0.7884, -3.3909],
        [-1.1385, -1.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024646984413266182
Epoch 0, Step 2010: train/loss = 0.661551833152771, train/raw-loss = 0.5556678771972656, train/logprobs = tensor([[-1.1800, -4.9172],
        [-2.0928, -2.4362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035294633358716965
Epoch 0, Step 2011: train/loss = 0.43201369047164917, train/raw-loss = 0.3179779052734375, train/logprobs = tensor([[-1.1564, -3.7502],
        [-2.8588, -1.5605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038011934608221054
Epoch 0, Step 2012: train/loss = 0.40985074639320374, train/raw-loss = 0.3328695595264435, train/logprobs = tensor([[-0.9085, -4.5505],
        [-1.1238, -1.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025660395622253418
Epoch 0, Step 2013: train/loss = 0.6667907238006592, train/raw-loss = 0.6092000603675842, train/logprobs = tensor([[-0.8349, -1.9630],
        [-0.9751, -1.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01919689029455185
Epoch 0, Step 2014: train/loss = 0.41083911061286926, train/raw-loss = 0.3299081027507782, train/logprobs = tensor([[-1.0139, -2.1962],
        [-2.8152, -0.7535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026976998895406723
Epoch 0, Step 2015: train/loss = 0.49371951818466187, train/raw-loss = 0.42468541860580444, train/logprobs = tensor([[-1.1273, -3.4518],
        [-1.0918, -0.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02301136404275894
Epoch 0, Step 2016: train/loss = 0.5348259210586548, train/raw-loss = 0.45400765538215637, train/logprobs = tensor([[-1.3365, -1.7703],
        [-4.6236, -1.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02693943679332733
Epoch 0, Step 2017: train/loss = 0.36164066195487976, train/raw-loss = 0.28486567735671997, train/logprobs = tensor([[-1.2419, -4.1148],
        [-2.2044, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025591665878891945
Epoch 0, Step 2018: train/loss = 0.5587227940559387, train/raw-loss = 0.45385944843292236, train/logprobs = tensor([[-1.1398, -1.9033],
        [-2.3912, -1.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03495443984866142
Epoch 0, Step 2019: train/loss = 0.4265906810760498, train/raw-loss = 0.3654904365539551, train/logprobs = tensor([[-0.8815, -3.5811],
        [-1.1951, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02036675438284874
Epoch 0, Step 2020: train/loss = 0.5015035271644592, train/raw-loss = 0.4159027636051178, train/logprobs = tensor([[-0.8355, -2.9315],
        [-2.1979, -1.3436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028533589094877243
Epoch 0, Step 2021: train/loss = 0.6875929832458496, train/raw-loss = 0.6223254203796387, train/logprobs = tensor([[-0.6365, -2.7922],
        [-0.6808, -2.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02175583317875862
Epoch 0, Step 2022: train/loss = 0.5803626775741577, train/raw-loss = 0.5267369747161865, train/logprobs = tensor([[-0.4460, -1.8217],
        [-0.5448, -0.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01787523552775383
Epoch 0, Step 2023: train/loss = 0.4789971113204956, train/raw-loss = 0.4139423966407776, train/logprobs = tensor([[-0.6928, -2.3164],
        [-2.4635, -0.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021684907376766205
Epoch 0, Step 2024: train/loss = 0.3395870327949524, train/raw-loss = 0.23242107033729553, train/logprobs = tensor([[-1.1837, -4.4119],
        [-3.4223, -1.7001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03572198748588562
Epoch 0, Step 2025: train/loss = 0.4238441288471222, train/raw-loss = 0.34563010931015015, train/logprobs = tensor([[-0.8634, -3.8068],
        [-1.5691, -1.1491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026071343570947647
Epoch 0, Step 2026: train/loss = 0.5925501585006714, train/raw-loss = 0.5198917388916016, train/logprobs = tensor([[-0.6898, -1.4943],
        [-1.1927, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024219470098614693
Epoch 0, Step 2027: train/loss = 0.5725187063217163, train/raw-loss = 0.46034640073776245, train/logprobs = tensor([[-1.0855, -1.9932],
        [-2.1979, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037390757352113724
Epoch 0, Step 2028: train/loss = 0.39040547609329224, train/raw-loss = 0.28479668498039246, train/logprobs = tensor([[-1.0914, -4.8897],
        [-2.4873, -2.2339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520292416214943
Epoch 0, Step 2029: train/loss = 0.4444381594657898, train/raw-loss = 0.3454135060310364, train/logprobs = tensor([[-1.0495, -3.0138],
        [-1.6536, -1.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03300821781158447
Epoch 0, Step 2030: train/loss = 0.34227922558784485, train/raw-loss = 0.23665906488895416, train/logprobs = tensor([[-0.9238, -3.8945],
        [-2.5149, -1.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520672023296356
Epoch 0, Step 2031: train/loss = 0.4115630090236664, train/raw-loss = 0.3187895119190216, train/logprobs = tensor([[-1.3814, -2.6929],
        [-2.9029, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030924497172236443
Epoch 0, Step 2032: train/loss = 0.8026320934295654, train/raw-loss = 0.7310811281204224, train/logprobs = tensor([[-1.4742, -2.0964],
        [-2.0692, -2.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023850297555327415
Epoch 0, Step 2033: train/loss = 0.5159871578216553, train/raw-loss = 0.45859289169311523, train/logprobs = tensor([[-1.1738, -3.3967],
        [-1.9158, -2.2352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019131410866975784
Epoch 0, Step 2034: train/loss = 0.49944615364074707, train/raw-loss = 0.41473549604415894, train/logprobs = tensor([[-0.7862, -3.1969],
        [-1.4884, -1.3156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028236880898475647
Epoch 0, Step 2035: train/loss = 0.3647940754890442, train/raw-loss = 0.2960076630115509, train/logprobs = tensor([[-1.0720, -3.8421],
        [-2.7506, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02292880229651928
Epoch 0, Step 2036: train/loss = 0.37548062205314636, train/raw-loss = 0.2978493273258209, train/logprobs = tensor([[-1.4021, -2.6380],
        [-3.6177, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025877103209495544
Epoch 0, Step 2037: train/loss = 0.39670228958129883, train/raw-loss = 0.3219188153743744, train/logprobs = tensor([[-1.0298, -4.7178],
        [-1.4007, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024927828460931778
Epoch 0, Step 2038: train/loss = 0.5990980863571167, train/raw-loss = 0.5495215654373169, train/logprobs = tensor([[-0.9008, -2.6101],
        [-0.7674, -0.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016525503247976303
Epoch 0, Step 2039: train/loss = 0.43095266819000244, train/raw-loss = 0.36436188220977783, train/logprobs = tensor([[-0.9545, -3.6316],
        [-1.7253, -1.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022196926176548004
Epoch 0, Step 2040: train/loss = 0.4244415760040283, train/raw-loss = 0.33518433570861816, train/logprobs = tensor([[-1.1871, -4.0108],
        [-2.6583, -1.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02975240722298622
Epoch 0, Step 2041: train/loss = 0.4242219030857086, train/raw-loss = 0.3508940637111664, train/logprobs = tensor([[-0.8823, -3.2463],
        [-1.0936, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02444261685013771
Epoch 0, Step 2042: train/loss = 0.4115753769874573, train/raw-loss = 0.35756343603134155, train/logprobs = tensor([[-0.5877, -3.8631],
        [-0.8489, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018003981560468674
Epoch 0, Step 2043: train/loss = 0.38826388120651245, train/raw-loss = 0.31395187973976135, train/logprobs = tensor([[-1.1248, -4.6913],
        [-1.1188, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024770669639110565
Epoch 0, Step 2044: train/loss = 0.41689980030059814, train/raw-loss = 0.3350575864315033, train/logprobs = tensor([[-1.6049, -2.1650],
        [-3.2649, -0.7025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027280734851956367
Epoch 0, Step 2045: train/loss = 0.41148853302001953, train/raw-loss = 0.3416452705860138, train/logprobs = tensor([[-1.6340, -1.9677],
        [-3.1522, -0.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023281091824173927
Epoch 0, Step 2046: train/loss = 0.45763736963272095, train/raw-loss = 0.37421751022338867, train/logprobs = tensor([[-0.7724, -2.3799],
        [-1.9835, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027806611731648445
Epoch 0, Step 2047: train/loss = 0.47623446583747864, train/raw-loss = 0.40466639399528503, train/logprobs = tensor([[-0.7212, -3.6376],
        [-0.7048, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023856010288000107
Epoch 0, Step 2048: train/loss = 0.5190226435661316, train/raw-loss = 0.45881086587905884, train/logprobs = tensor([[-1.0715, -3.3192],
        [-0.9984, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020070601254701614
Epoch 0, Step 2049: train/loss = 0.5106050968170166, train/raw-loss = 0.4267036020755768, train/logprobs = tensor([[-1.0712, -3.3054],
        [-2.4103, -1.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027967162430286407
Epoch 0, Step 2050: train/loss = 0.58790522813797, train/raw-loss = 0.5089181661605835, train/logprobs = tensor([[-1.1687, -1.6158],
        [-2.1672, -1.4212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02632904052734375
Epoch 0, Step 2051: train/loss = 0.33695003390312195, train/raw-loss = 0.22036509215831757, train/logprobs = tensor([[-1.2831, -2.8878],
        [-4.0376, -1.0507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038861650973558426
Epoch 0, Step 2052: train/loss = 0.38887155055999756, train/raw-loss = 0.2976948022842407, train/logprobs = tensor([[-1.6414, -3.1554],
        [-3.4834, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030392246320843697
Epoch 0, Step 2053: train/loss = 0.6233491897583008, train/raw-loss = 0.540175199508667, train/logprobs = tensor([[-2.0624, -1.8366],
        [-2.9338, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02772466465830803
Epoch 0, Step 2054: train/loss = 0.6305251121520996, train/raw-loss = 0.5771445035934448, train/logprobs = tensor([[-0.6228, -1.3566],
        [-0.7426, -0.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017793521285057068
Epoch 0, Step 2055: train/loss = 0.5325916409492493, train/raw-loss = 0.47262489795684814, train/logprobs = tensor([[-0.6837, -4.1511],
        [-0.8469, -1.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019988905638456345
Epoch 0, Step 2056: train/loss = 0.503826379776001, train/raw-loss = 0.434600293636322, train/logprobs = tensor([[-1.2239, -2.5775],
        [-2.2571, -1.3816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023075362667441368
Epoch 0, Step 2057: train/loss = 0.37606972455978394, train/raw-loss = 0.29470303654670715, train/logprobs = tensor([[-1.6103, -4.7152],
        [-2.5905, -1.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027122218161821365
Epoch 0, Step 2058: train/loss = 0.4961472153663635, train/raw-loss = 0.41819238662719727, train/logprobs = tensor([[-0.9371, -1.2706],
        [-2.5523, -0.7589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025984937325119972
Epoch 0, Step 2059: train/loss = 0.3254545331001282, train/raw-loss = 0.24515803158283234, train/logprobs = tensor([[-0.7775, -4.3916],
        [-1.9128, -1.3808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026765495538711548
Epoch 0, Step 2060: train/loss = 0.5325546264648438, train/raw-loss = 0.48587942123413086, train/logprobs = tensor([[-0.6825, -3.3151],
        [-0.9755, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015558396466076374
Epoch 0, Step 2061: train/loss = 0.3715980648994446, train/raw-loss = 0.29014819860458374, train/logprobs = tensor([[-0.9589, -2.9169],
        [-1.9596, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027149954810738564
Epoch 0, Step 2062: train/loss = 0.5594914555549622, train/raw-loss = 0.48166754841804504, train/logprobs = tensor([[-1.5131, -1.6719],
        [-2.4063, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02594129741191864
Epoch 0, Step 2063: train/loss = 0.6117842197418213, train/raw-loss = 0.557625412940979, train/logprobs = tensor([[-0.8489, -1.9668],
        [-0.7118, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018052924424409866
Epoch 0, Step 2064: train/loss = 0.24192538857460022, train/raw-loss = 0.14335565268993378, train/logprobs = tensor([[-0.9011, -5.0651],
        [-2.6473, -1.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03285657614469528
Epoch 0, Step 2065: train/loss = 0.44734036922454834, train/raw-loss = 0.3753337264060974, train/logprobs = tensor([[-0.7924, -3.0896],
        [-1.4463, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02400222420692444
Epoch 0, Step 2066: train/loss = 0.47856050729751587, train/raw-loss = 0.40313270688056946, train/logprobs = tensor([[-0.7526, -2.6120],
        [-1.7729, -1.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0251426063477993
Epoch 0, Step 2067: train/loss = 0.9089660048484802, train/raw-loss = 0.8165891170501709, train/logprobs = tensor([[-0.6943, -3.5109],
        [-1.5208, -2.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030792295932769775
Epoch 0, Step 2068: train/loss = 0.4268379211425781, train/raw-loss = 0.33619439601898193, train/logprobs = tensor([[-1.3100, -2.8388],
        [-3.1550, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030214495956897736
Epoch 0, Step 2069: train/loss = 0.45653846859931946, train/raw-loss = 0.3926170766353607, train/logprobs = tensor([[-0.7480, -3.4344],
        [-1.9142, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02130713500082493
Epoch 0, Step 2070: train/loss = 0.31914642453193665, train/raw-loss = 0.21799123287200928, train/logprobs = tensor([[-1.3354, -3.4542],
        [-3.6870, -1.3715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033718399703502655
Epoch 0, Step 2071: train/loss = 0.38261064887046814, train/raw-loss = 0.30917125940322876, train/logprobs = tensor([[-0.8636, -3.4049],
        [-1.8954, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02447979524731636
Epoch 0, Step 2072: train/loss = 0.5468870997428894, train/raw-loss = 0.4714949131011963, train/logprobs = tensor([[-1.7935, -3.0268],
        [-2.1528, -1.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025130726397037506
Epoch 0, Step 2073: train/loss = 0.6908882260322571, train/raw-loss = 0.6513972282409668, train/logprobs = tensor([[-0.5061, -1.3097],
        [-0.5795, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01316368393599987
Epoch 0, Step 2074: train/loss = 0.4519151449203491, train/raw-loss = 0.36174970865249634, train/logprobs = tensor([[-1.0170, -1.9189],
        [-2.7807, -1.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030055154114961624
Epoch 0, Step 2075: train/loss = 0.5322571992874146, train/raw-loss = 0.45106425881385803, train/logprobs = tensor([[-1.8910, -3.6627],
        [-2.6836, -2.2386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02706432342529297
Epoch 0, Step 2076: train/loss = 0.32382702827453613, train/raw-loss = 0.23101159930229187, train/logprobs = tensor([[-1.0675, -3.1899],
        [-2.9412, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03093847818672657
Epoch 0, Step 2077: train/loss = 0.5361036062240601, train/raw-loss = 0.43531501293182373, train/logprobs = tensor([[-1.2141, -2.9997],
        [-1.8483, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03359619900584221
Epoch 0, Step 2078: train/loss = 0.40459463000297546, train/raw-loss = 0.31616267561912537, train/logprobs = tensor([[-1.6271, -2.4968],
        [-3.5076, -0.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029477309435606003
Epoch 0, Step 2079: train/loss = 0.3268977403640747, train/raw-loss = 0.243445485830307, train/logprobs = tensor([[-0.9099, -4.9027],
        [-1.3467, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027817416936159134
Epoch 0, Step 2080: train/loss = 0.2968842387199402, train/raw-loss = 0.21830400824546814, train/logprobs = tensor([[-0.9564, -5.5685],
        [-1.4214, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02619341015815735
Epoch 0, Step 2081: train/loss = 0.4386180639266968, train/raw-loss = 0.34105756878852844, train/logprobs = tensor([[-1.0670, -2.1975],
        [-3.1086, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03252015635371208
Epoch 0, Step 2082: train/loss = 0.6722897291183472, train/raw-loss = 0.6162616014480591, train/logprobs = tensor([[-0.5463, -1.8960],
        [-0.6186, -1.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018676046282052994
Epoch 0, Step 2083: train/loss = 0.5048230886459351, train/raw-loss = 0.43116044998168945, train/logprobs = tensor([[-1.3406, -3.0189],
        [-2.8121, -2.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02455422654747963
Epoch 0, Step 2084: train/loss = 0.6496244668960571, train/raw-loss = 0.5961468815803528, train/logprobs = tensor([[-1.6048, -3.1787],
        [-1.1558, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01782587170600891
Epoch 0, Step 2085: train/loss = 0.3689500391483307, train/raw-loss = 0.279350221157074, train/logprobs = tensor([[-1.3726, -3.2664],
        [-3.2244, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029866617172956467
Epoch 0, Step 2086: train/loss = 0.2699454426765442, train/raw-loss = 0.1683264672756195, train/logprobs = tensor([[-1.2510, -4.0446],
        [-3.2473, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03387298062443733
Epoch 0, Step 2087: train/loss = 0.4838854968547821, train/raw-loss = 0.3992261290550232, train/logprobs = tensor([[-1.4717, -2.5231],
        [-2.9410, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028219781816005707
Epoch 0, Step 2088: train/loss = 0.49967941641807556, train/raw-loss = 0.4289850890636444, train/logprobs = tensor([[-0.9188, -3.3383],
        [-1.0766, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023564770817756653
Epoch 0, Step 2089: train/loss = 0.5233134031295776, train/raw-loss = 0.42656171321868896, train/logprobs = tensor([[-1.3087, -2.3475],
        [-2.4846, -1.4613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032250575721263885
Epoch 0, Step 2090: train/loss = 0.44894081354141235, train/raw-loss = 0.36593392491340637, train/logprobs = tensor([[-0.7816, -3.2021],
        [-1.6827, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027668964117765427
Epoch 0, Step 2091: train/loss = 0.4456692039966583, train/raw-loss = 0.3489278554916382, train/logprobs = tensor([[-1.0448, -2.3431],
        [-2.5106, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032247111201286316
Epoch 0, Step 2092: train/loss = 0.5266712307929993, train/raw-loss = 0.4540793299674988, train/logprobs = tensor([[-1.0519, -2.1347],
        [-1.9976, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02419731765985489
Epoch 0, Step 2093: train/loss = 0.4134950041770935, train/raw-loss = 0.3540683686733246, train/logprobs = tensor([[-0.6173, -3.9931],
        [-0.8423, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019808880984783173
Epoch 0, Step 2094: train/loss = 0.3410662114620209, train/raw-loss = 0.26625555753707886, train/logprobs = tensor([[-0.8417, -3.8425],
        [-1.8987, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024936888366937637
Epoch 0, Step 2095: train/loss = 0.43221279978752136, train/raw-loss = 0.3565032184123993, train/logprobs = tensor([[-1.3151, -1.7949],
        [-3.2522, -0.7754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025236528366804123
Epoch 0, Step 2096: train/loss = 0.4726221263408661, train/raw-loss = 0.39810431003570557, train/logprobs = tensor([[-1.1099, -3.0714],
        [-1.6957, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024839278310537338
Epoch 0, Step 2097: train/loss = 0.4280308485031128, train/raw-loss = 0.3406819701194763, train/logprobs = tensor([[-1.0967, -2.5770],
        [-2.6261, -1.1875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02911629155278206
Epoch 0, Step 2098: train/loss = 0.29280003905296326, train/raw-loss = 0.2112390697002411, train/logprobs = tensor([[-0.7429, -5.6944],
        [-1.3922, -1.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027186989784240723
Epoch 0, Step 2099: train/loss = 0.43629568815231323, train/raw-loss = 0.37058159708976746, train/logprobs = tensor([[-0.7984, -3.3773],
        [-2.3412, -1.5927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021904699504375458
Epoch 0, Step 2100: train/loss = 0.5507679581642151, train/raw-loss = 0.4344070553779602, train/logprobs = tensor([[-1.4549, -1.9598],
        [-4.3653, -1.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03878696262836456
Epoch 0, Step 2101: train/loss = 0.415861576795578, train/raw-loss = 0.3305675685405731, train/logprobs = tensor([[-1.5116, -1.6079],
        [-3.5151, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028431326150894165
Epoch 0, Step 2102: train/loss = 0.4996669888496399, train/raw-loss = 0.42636027932167053, train/logprobs = tensor([[-0.9768, -3.0353],
        [-1.1874, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02443556860089302
Epoch 0, Step 2103: train/loss = 0.5114109516143799, train/raw-loss = 0.4603210687637329, train/logprobs = tensor([[-0.9777, -2.1704],
        [-1.5874, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01702997460961342
Epoch 0, Step 2104: train/loss = 0.5108492374420166, train/raw-loss = 0.44383475184440613, train/logprobs = tensor([[-0.7335, -3.4657],
        [-1.7016, -2.1829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022338155657052994
Epoch 0, Step 2105: train/loss = 0.3273540735244751, train/raw-loss = 0.21869274973869324, train/logprobs = tensor([[-1.1883, -3.6808],
        [-2.8523, -1.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036220453679561615
Epoch 0, Step 2106: train/loss = 0.5396392345428467, train/raw-loss = 0.4627780020236969, train/logprobs = tensor([[-2.0735, -2.9483],
        [-2.4637, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025620419532060623
Epoch 0, Step 2107: train/loss = 0.46419376134872437, train/raw-loss = 0.369686096906662, train/logprobs = tensor([[-2.3079, -3.5042],
        [-3.5379, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031502559781074524
Epoch 0, Step 2108: train/loss = 0.45731285214424133, train/raw-loss = 0.3612145483493805, train/logprobs = tensor([[-0.7889, -3.6186],
        [-1.8088, -1.5284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032032765448093414
Epoch 0, Step 2109: train/loss = 0.45562657713890076, train/raw-loss = 0.3810287117958069, train/logprobs = tensor([[-1.3208, -2.4270],
        [-1.9158, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024865958839654922
Epoch 0, Step 2110: train/loss = 0.43231579661369324, train/raw-loss = 0.36045393347740173, train/logprobs = tensor([[-0.7256, -2.6666],
        [-1.6664, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023953959345817566
Epoch 0, Step 2111: train/loss = 0.5234251022338867, train/raw-loss = 0.4606502652168274, train/logprobs = tensor([[-0.7529, -3.3736],
        [-1.0526, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02092495560646057
Epoch 0, Step 2112: train/loss = 0.3758496940135956, train/raw-loss = 0.3069377839565277, train/logprobs = tensor([[-1.5883, -4.9357],
        [-1.5998, -1.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02297063171863556
Epoch 0, Step 2113: train/loss = 0.23957094550132751, train/raw-loss = 0.13683710992336273, train/logprobs = tensor([[-1.4721, -5.2945],
        [-3.1355, -1.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034244611859321594
Epoch 0, Step 2114: train/loss = 0.44951701164245605, train/raw-loss = 0.3883054554462433, train/logprobs = tensor([[-0.7059, -4.2285],
        [-0.8564, -1.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020403850823640823
Epoch 0, Step 2115: train/loss = 0.3183262050151825, train/raw-loss = 0.23666943609714508, train/logprobs = tensor([[-0.9474, -4.0965],
        [-1.9742, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02721891924738884
Epoch 0, Step 2116: train/loss = 0.4556439220905304, train/raw-loss = 0.3891601264476776, train/logprobs = tensor([[-1.1732, -2.6735],
        [-1.8093, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02216126024723053
Epoch 0, Step 2117: train/loss = 0.5458786487579346, train/raw-loss = 0.42930275201797485, train/logprobs = tensor([[-1.5548, -2.8664],
        [-3.2500, -1.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038858622312545776
Epoch 0, Step 2118: train/loss = 0.35308778285980225, train/raw-loss = 0.2770172357559204, train/logprobs = tensor([[-1.0532, -3.5987],
        [-2.0220, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025356853380799294
Epoch 0, Step 2119: train/loss = 0.3999825417995453, train/raw-loss = 0.3184002637863159, train/logprobs = tensor([[-0.9745, -3.8074],
        [-1.4810, -1.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02719409391283989
Epoch 0, Step 2120: train/loss = 0.4743022620677948, train/raw-loss = 0.39656925201416016, train/logprobs = tensor([[-1.1108, -2.7498],
        [-2.1809, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02591099962592125
Epoch 0, Step 2121: train/loss = 0.7028588056564331, train/raw-loss = 0.6654528379440308, train/logprobs = tensor([[-0.6961, -0.8406],
        [-0.6558, -0.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012468654662370682
Epoch 0, Step 2122: train/loss = 0.44345083832740784, train/raw-loss = 0.3793547749519348, train/logprobs = tensor([[-1.1480, -2.6514],
        [-1.7713, -0.8104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02136535570025444
Epoch 0, Step 2123: train/loss = 0.5769641995429993, train/raw-loss = 0.5021963715553284, train/logprobs = tensor([[-0.9312, -1.1998],
        [-1.6521, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024922611191868782
Epoch 0, Step 2124: train/loss = 0.6622414588928223, train/raw-loss = 0.5812780261039734, train/logprobs = tensor([[-1.6632, -1.8653],
        [-2.2656, -1.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026987798511981964
Epoch 0, Step 2125: train/loss = 0.4558414816856384, train/raw-loss = 0.37635308504104614, train/logprobs = tensor([[-1.5003, -2.3878],
        [-3.1219, -1.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02649613842368126
Epoch 0, Step 2126: train/loss = 0.28729987144470215, train/raw-loss = 0.21269629895687103, train/logprobs = tensor([[-0.8890, -4.8733],
        [-1.7746, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024867860600352287
Epoch 0, Step 2127: train/loss = 0.4164966344833374, train/raw-loss = 0.3196395933628082, train/logprobs = tensor([[-1.2949, -1.3777],
        [-3.6245, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032285671681165695
Epoch 0, Step 2128: train/loss = 0.3175000250339508, train/raw-loss = 0.242989182472229, train/logprobs = tensor([[-0.8948, -4.6163],
        [-2.0694, -1.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02483695186674595
Epoch 0, Step 2129: train/loss = 0.44238415360450745, train/raw-loss = 0.373054176568985, train/logprobs = tensor([[-0.7913, -3.9996],
        [-1.1478, -1.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023110002279281616
Epoch 0, Step 2130: train/loss = 0.7519638538360596, train/raw-loss = 0.702832818031311, train/logprobs = tensor([[-0.6612, -0.8882],
        [-1.0019, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016377000138163567
Epoch 0, Step 2131: train/loss = 0.45738309621810913, train/raw-loss = 0.389282763004303, train/logprobs = tensor([[-0.7820, -4.1786],
        [-0.9537, -1.2038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022700110450387
Epoch 0, Step 2132: train/loss = 0.5496744513511658, train/raw-loss = 0.4779720604419708, train/logprobs = tensor([[-0.7193, -1.9720],
        [-1.0594, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023900797590613365
Epoch 0, Step 2133: train/loss = 0.49891310930252075, train/raw-loss = 0.4419994056224823, train/logprobs = tensor([[-0.9392, -3.0380],
        [-1.1108, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018971232697367668
Epoch 0, Step 2134: train/loss = 0.35733360052108765, train/raw-loss = 0.2519572973251343, train/logprobs = tensor([[-1.5006, -3.4640],
        [-2.4816, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03512543812394142
Epoch 0, Step 2135: train/loss = 0.27385708689689636, train/raw-loss = 0.17302560806274414, train/logprobs = tensor([[-1.0949, -4.4444],
        [-2.4250, -1.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033610496670007706
Epoch 0, Step 2136: train/loss = 0.63112473487854, train/raw-loss = 0.5707693099975586, train/logprobs = tensor([[-0.6365, -2.4464],
        [-0.8177, -1.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020118458196520805
Epoch 0, Step 2137: train/loss = 0.5599836111068726, train/raw-loss = 0.47118422389030457, train/logprobs = tensor([[-1.2148, -1.9206],
        [-1.6630, -0.7311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029599789530038834
Epoch 0, Step 2138: train/loss = 0.4075011909008026, train/raw-loss = 0.30649691820144653, train/logprobs = tensor([[-1.7157, -2.1758],
        [-5.1746, -1.4438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03366808593273163
Epoch 0, Step 2139: train/loss = 0.354663610458374, train/raw-loss = 0.2462540864944458, train/logprobs = tensor([[-1.3338, -4.1542],
        [-2.4643, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03613651543855667
Epoch 0, Step 2140: train/loss = 0.3623947501182556, train/raw-loss = 0.25797098875045776, train/logprobs = tensor([[-1.2458, -1.7207],
        [-3.9562, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034807924181222916
Epoch 0, Step 2141: train/loss = 0.3348410129547119, train/raw-loss = 0.2493634819984436, train/logprobs = tensor([[-1.3807, -3.2924],
        [-3.7404, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028492504730820656
Epoch 0, Step 2142: train/loss = 0.5513027310371399, train/raw-loss = 0.4778035283088684, train/logprobs = tensor([[-1.3036, -2.3071],
        [-3.1864, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024499740451574326
Epoch 0, Step 2143: train/loss = 0.5080109238624573, train/raw-loss = 0.4276595711708069, train/logprobs = tensor([[-0.9567, -2.0365],
        [-2.4303, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026783786714076996
Epoch 0, Step 2144: train/loss = 0.35693827271461487, train/raw-loss = 0.2702476680278778, train/logprobs = tensor([[-1.0308, -5.1312],
        [-1.9542, -1.3779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028896866366267204
Epoch 0, Step 2145: train/loss = 0.25116288661956787, train/raw-loss = 0.15382470190525055, train/logprobs = tensor([[-1.6328, -3.7041],
        [-4.9450, -1.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032446060329675674
Epoch 0, Step 2146: train/loss = 0.5258689522743225, train/raw-loss = 0.434558242559433, train/logprobs = tensor([[-0.9500, -1.9116],
        [-2.7506, -1.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030436910688877106
Epoch 0, Step 2147: train/loss = 0.5543840527534485, train/raw-loss = 0.4769388735294342, train/logprobs = tensor([[-0.6582, -3.0231],
        [-0.6621, -1.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02581505849957466
Epoch 0, Step 2148: train/loss = 0.5454078912734985, train/raw-loss = 0.4678754210472107, train/logprobs = tensor([[-1.1207, -2.3127],
        [-1.5147, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025844145566225052
Epoch 0, Step 2149: train/loss = 0.3360578417778015, train/raw-loss = 0.25310879945755005, train/logprobs = tensor([[-0.9845, -4.0977],
        [-2.0230, -1.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027649670839309692
Epoch 0, Step 2150: train/loss = 0.3570443391799927, train/raw-loss = 0.2711537778377533, train/logprobs = tensor([[-0.9804, -2.9430],
        [-2.9923, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028630193322896957
Epoch 0, Step 2151: train/loss = 0.360072523355484, train/raw-loss = 0.2639211416244507, train/logprobs = tensor([[-1.5844, -3.0842],
        [-3.5460, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0320504754781723
Epoch 0, Step 2152: train/loss = 0.49819299578666687, train/raw-loss = 0.41539907455444336, train/logprobs = tensor([[-0.9022, -1.1852],
        [-2.3080, -0.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027597974985837936
Epoch 0, Step 2153: train/loss = 0.4110408127307892, train/raw-loss = 0.34010475873947144, train/logprobs = tensor([[-0.8820, -4.5438],
        [-1.0647, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023645345121622086
Epoch 0, Step 2154: train/loss = 0.30883488059043884, train/raw-loss = 0.20985068380832672, train/logprobs = tensor([[-1.3998, -3.2271],
        [-4.3826, -1.4695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299473226070404
Epoch 0, Step 2155: train/loss = 0.4968956708908081, train/raw-loss = 0.4231396019458771, train/logprobs = tensor([[-1.4526, -3.2117],
        [-1.7555, -1.0347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024585355073213577
Epoch 0, Step 2156: train/loss = 0.5929797291755676, train/raw-loss = 0.5181218981742859, train/logprobs = tensor([[-0.7828, -1.3630],
        [-1.5590, -0.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02495260164141655
Epoch 0, Step 2157: train/loss = 0.7140600681304932, train/raw-loss = 0.6563525199890137, train/logprobs = tensor([[-0.6422, -0.8895],
        [-0.8213, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019235849380493164
Epoch 0, Step 2158: train/loss = 0.5508604049682617, train/raw-loss = 0.4999861717224121, train/logprobs = tensor([[-1.2545, -3.6299],
        [-1.3492, -1.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016958076506853104
Epoch 0, Step 2159: train/loss = 0.5524964332580566, train/raw-loss = 0.47162294387817383, train/logprobs = tensor([[-1.7049, -3.8476],
        [-1.8220, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026957834139466286
Epoch 0, Step 2160: train/loss = 0.39257341623306274, train/raw-loss = 0.28529423475265503, train/logprobs = tensor([[-1.0100, -2.8981],
        [-2.0478, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03575972095131874
Epoch 0, Step 2161: train/loss = 0.4255969822406769, train/raw-loss = 0.3645761013031006, train/logprobs = tensor([[-0.7870, -3.2156],
        [-1.7427, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020340286195278168
Epoch 0, Step 2162: train/loss = 0.5448852777481079, train/raw-loss = 0.4853479266166687, train/logprobs = tensor([[-0.7535, -1.9310],
        [-1.1399, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01984577253460884
Epoch 0, Step 2163: train/loss = 0.2705309987068176, train/raw-loss = 0.18231967091560364, train/logprobs = tensor([[-0.7103, -3.5333],
        [-2.2926, -0.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029403768479824066
Epoch 0, Step 2164: train/loss = 0.3899539113044739, train/raw-loss = 0.28093668818473816, train/logprobs = tensor([[-1.2339, -1.8805],
        [-3.5086, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03633907064795494
Epoch 0, Step 2165: train/loss = 0.4509342610836029, train/raw-loss = 0.3676077723503113, train/logprobs = tensor([[-0.7745, -2.6219],
        [-1.5738, -0.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027775496244430542
Epoch 0, Step 2166: train/loss = 0.45829907059669495, train/raw-loss = 0.351529061794281, train/logprobs = tensor([[-2.4051, -5.6454],
        [-4.2048, -3.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035589996725320816
Epoch 0, Step 2167: train/loss = 0.3141145408153534, train/raw-loss = 0.22323021292686462, train/logprobs = tensor([[-1.5254, -4.0436],
        [-3.3227, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03029477596282959
Epoch 0, Step 2168: train/loss = 0.39726513624191284, train/raw-loss = 0.3178362548351288, train/logprobs = tensor([[-0.6115, -3.3864],
        [-1.5837, -0.8264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026476291939616203
Epoch 0, Step 2169: train/loss = 0.39130863547325134, train/raw-loss = 0.33129391074180603, train/logprobs = tensor([[-0.5346, -4.3546],
        [-0.6632, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02000490576028824
Epoch 0, Step 2170: train/loss = 0.3982274532318115, train/raw-loss = 0.3217124938964844, train/logprobs = tensor([[-1.3145, -3.9321],
        [-1.5016, -0.8855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025504980236291885
Epoch 0, Step 2171: train/loss = 0.39242124557495117, train/raw-loss = 0.32027560472488403, train/logprobs = tensor([[-0.8716, -3.2862],
        [-1.4311, -1.0087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02404855564236641
Epoch 0, Step 2172: train/loss = 0.32221174240112305, train/raw-loss = 0.23334519565105438, train/logprobs = tensor([[-0.9345, -3.3107],
        [-2.9891, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029622182250022888
Epoch 0, Step 2173: train/loss = 0.5926079750061035, train/raw-loss = 0.5291920900344849, train/logprobs = tensor([[-0.6822, -1.3333],
        [-1.8734, -0.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02113862708210945
Epoch 0, Step 2174: train/loss = 0.3649779260158539, train/raw-loss = 0.2761511206626892, train/logprobs = tensor([[-1.0590, -2.8924],
        [-2.6476, -1.2808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02960892766714096
Epoch 0, Step 2175: train/loss = 0.5221009254455566, train/raw-loss = 0.4492771625518799, train/logprobs = tensor([[-1.5638, -2.0740],
        [-3.0260, -1.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024274593219161034
Epoch 0, Step 2176: train/loss = 0.437982439994812, train/raw-loss = 0.37071943283081055, train/logprobs = tensor([[-0.8866, -3.0758],
        [-1.5923, -0.7877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022421011701226234
Epoch 0, Step 2177: train/loss = 0.5159212350845337, train/raw-loss = 0.4378587007522583, train/logprobs = tensor([[-1.0357, -2.9214],
        [-1.7582, -1.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026020841673016548
Epoch 0, Step 2178: train/loss = 0.45180419087409973, train/raw-loss = 0.3874453902244568, train/logprobs = tensor([[-0.8693, -4.1505],
        [-0.7982, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021452927961945534
Epoch 0, Step 2179: train/loss = 0.3622162640094757, train/raw-loss = 0.2752585709095001, train/logprobs = tensor([[-1.1520, -4.1790],
        [-2.2566, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028985900804400444
Epoch 0, Step 2180: train/loss = 0.4564584493637085, train/raw-loss = 0.3630531430244446, train/logprobs = tensor([[-1.2374, -1.7394],
        [-2.6587, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031135093420743942
Epoch 0, Step 2181: train/loss = 0.7170690894126892, train/raw-loss = 0.6301082372665405, train/logprobs = tensor([[-1.2269, -2.4633],
        [-1.6510, -2.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02898694947361946
Epoch 0, Step 2182: train/loss = 0.40145957469940186, train/raw-loss = 0.3468582034111023, train/logprobs = tensor([[-1.1628, -3.5326],
        [-2.2873, -0.9052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018200453370809555
Epoch 0, Step 2183: train/loss = 0.4138212203979492, train/raw-loss = 0.3399435579776764, train/logprobs = tensor([[-0.8424, -3.9025],
        [-1.4144, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024625882506370544
Epoch 0, Step 2184: train/loss = 0.31963056325912476, train/raw-loss = 0.21287426352500916, train/logprobs = tensor([[-1.0642, -2.7914],
        [-3.3391, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0355854369699955
Epoch 0, Step 2185: train/loss = 0.4874306619167328, train/raw-loss = 0.40872079133987427, train/logprobs = tensor([[-1.3510, -3.4312],
        [-1.4993, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02623661980032921
Epoch 0, Step 2186: train/loss = 0.4089038372039795, train/raw-loss = 0.32122164964675903, train/logprobs = tensor([[-1.0133, -2.4588],
        [-2.6831, -0.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029227394610643387
Epoch 0, Step 2187: train/loss = 0.5619029998779297, train/raw-loss = 0.5081154108047485, train/logprobs = tensor([[-0.7934, -1.5845],
        [-1.3437, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017929181456565857
Epoch 0, Step 2188: train/loss = 0.3727794289588928, train/raw-loss = 0.2919228971004486, train/logprobs = tensor([[-1.1730, -3.0102],
        [-2.2486, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02695218101143837
Epoch 0, Step 2189: train/loss = 0.6525465250015259, train/raw-loss = 0.5882453918457031, train/logprobs = tensor([[-1.9931, -3.1177],
        [-2.1713, -2.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021433720365166664
Epoch 0, Step 2190: train/loss = 0.5580449104309082, train/raw-loss = 0.49252837896347046, train/logprobs = tensor([[-0.6256, -1.0076],
        [-1.4978, -0.5557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021838843822479248
Epoch 0, Step 2191: train/loss = 0.44201186299324036, train/raw-loss = 0.3520338833332062, train/logprobs = tensor([[-1.1410, -2.6350],
        [-2.8174, -1.4476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029992660507559776
Epoch 0, Step 2192: train/loss = 0.4449220299720764, train/raw-loss = 0.37199637293815613, train/logprobs = tensor([[-1.2161, -3.5821],
        [-2.8609, -1.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024308551102876663
Epoch 0, Step 2193: train/loss = 0.5348873138427734, train/raw-loss = 0.46609193086624146, train/logprobs = tensor([[-1.0190, -2.0752],
        [-2.4583, -1.1323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022931788116693497
Epoch 0, Step 2194: train/loss = 0.5124354362487793, train/raw-loss = 0.43948665261268616, train/logprobs = tensor([[-0.7644, -2.1959],
        [-1.5529, -0.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024316273629665375
Epoch 0, Step 2195: train/loss = 0.7245139479637146, train/raw-loss = 0.6731774210929871, train/logprobs = tensor([[-0.7040, -0.7380],
        [-0.8997, -0.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01711217314004898
Epoch 0, Step 2196: train/loss = 0.5327725410461426, train/raw-loss = 0.4328776001930237, train/logprobs = tensor([[-2.3733, -3.2812],
        [-2.9043, -2.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0332983136177063
Epoch 0, Step 2197: train/loss = 0.3009735345840454, train/raw-loss = 0.22362707555294037, train/logprobs = tensor([[-0.9232, -4.5953],
        [-1.8694, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02578214555978775
Epoch 0, Step 2198: train/loss = 0.3683212101459503, train/raw-loss = 0.2943839728832245, train/logprobs = tensor([[-0.8216, -5.3091],
        [-1.7917, -2.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024645742028951645
Epoch 0, Step 2199: train/loss = 0.4324709475040436, train/raw-loss = 0.3608950078487396, train/logprobs = tensor([[-1.1755, -2.8954],
        [-2.1958, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023858653381466866
Epoch 0, Step 2200: train/loss = 0.6468797922134399, train/raw-loss = 0.5731231570243835, train/logprobs = tensor([[-0.9757, -2.0611],
        [-1.9743, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024585532024502754
Epoch 0, Step 2201: train/loss = 0.5646758079528809, train/raw-loss = 0.5018150806427002, train/logprobs = tensor([[-0.8012, -1.5881],
        [-1.8806, -1.1283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02095356583595276
Epoch 0, Step 2202: train/loss = 0.5154396295547485, train/raw-loss = 0.41389739513397217, train/logprobs = tensor([[-1.6192, -4.2974],
        [-1.6150, -1.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033847417682409286
Epoch 0, Step 2203: train/loss = 0.5098000168800354, train/raw-loss = 0.3794128894805908, train/logprobs = tensor([[-1.7115, -2.8755],
        [-2.7138, -1.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043462373316287994
Epoch 0, Step 2204: train/loss = 0.3953702449798584, train/raw-loss = 0.30782854557037354, train/logprobs = tensor([[-1.2011, -2.0364],
        [-3.1259, -0.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029180575162172318
Epoch 0, Step 2205: train/loss = 0.5763406753540039, train/raw-loss = 0.4948588013648987, train/logprobs = tensor([[-1.4308, -2.8409],
        [-2.2235, -1.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027160611003637314
Epoch 0, Step 2206: train/loss = 0.6067025661468506, train/raw-loss = 0.49530237913131714, train/logprobs = tensor([[-2.1017, -2.9459],
        [-2.9945, -1.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03713340312242508
Epoch 0, Step 2207: train/loss = 0.36411672830581665, train/raw-loss = 0.2866455316543579, train/logprobs = tensor([[-1.0312, -2.5674],
        [-2.8683, -0.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02582372911274433
Epoch 0, Step 2208: train/loss = 0.5935818552970886, train/raw-loss = 0.5289267301559448, train/logprobs = tensor([[-1.5095, -1.9581],
        [-1.9399, -1.2918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0215517058968544
Epoch 0, Step 2209: train/loss = 0.40710848569869995, train/raw-loss = 0.32768943905830383, train/logprobs = tensor([[-1.4110, -4.8223],
        [-1.4749, -1.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026473015546798706
Epoch 0, Step 2210: train/loss = 0.3664000630378723, train/raw-loss = 0.27176713943481445, train/logprobs = tensor([[-0.7997, -3.8971],
        [-1.5986, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031544312834739685
Epoch 0, Step 2211: train/loss = 0.5884572863578796, train/raw-loss = 0.4819193482398987, train/logprobs = tensor([[-1.8924, -1.8971],
        [-2.7922, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035512637346982956
Epoch 0, Step 2212: train/loss = 0.34711194038391113, train/raw-loss = 0.276557058095932, train/logprobs = tensor([[-0.8127, -3.8840],
        [-2.0010, -0.8619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023518282920122147
Epoch 0, Step 2213: train/loss = 0.5047932863235474, train/raw-loss = 0.45436227321624756, train/logprobs = tensor([[-0.7360, -3.0678],
        [-1.0012, -1.1915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016810331493616104
Epoch 0, Step 2214: train/loss = 0.5184121131896973, train/raw-loss = 0.4704577326774597, train/logprobs = tensor([[-1.1264, -3.2371],
        [-1.0059, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01598478853702545
Epoch 0, Step 2215: train/loss = 0.3981553912162781, train/raw-loss = 0.32114484906196594, train/logprobs = tensor([[-0.9249, -3.2247],
        [-1.8072, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025670180097222328
Epoch 0, Step 2216: train/loss = 0.4287032186985016, train/raw-loss = 0.35238683223724365, train/logprobs = tensor([[-0.9233, -4.5381],
        [-1.5872, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02543880045413971
Epoch 0, Step 2217: train/loss = 0.49797332286834717, train/raw-loss = 0.4242844581604004, train/logprobs = tensor([[-0.9035, -3.2207],
        [-1.3307, -1.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024562958627939224
Epoch 0, Step 2218: train/loss = 0.2683130204677582, train/raw-loss = 0.1915917694568634, train/logprobs = tensor([[-1.1337, -4.5168],
        [-2.9931, -1.0314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025573745369911194
Epoch 0, Step 2219: train/loss = 0.45586633682250977, train/raw-loss = 0.3841695189476013, train/logprobs = tensor([[-0.9617, -3.7257],
        [-1.2492, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023898955434560776
Epoch 0, Step 2220: train/loss = 0.5333617925643921, train/raw-loss = 0.47774767875671387, train/logprobs = tensor([[-0.9005, -3.2413],
        [-1.2417, -1.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01853802800178528
Epoch 0, Step 2221: train/loss = 0.441081702709198, train/raw-loss = 0.33710432052612305, train/logprobs = tensor([[-1.8007, -3.4260],
        [-3.3390, -1.7936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465912863612175
Epoch 0, Step 2222: train/loss = 0.4613867402076721, train/raw-loss = 0.39698201417922974, train/logprobs = tensor([[-1.2092, -2.3913],
        [-2.0905, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02146824449300766
Epoch 0, Step 2223: train/loss = 0.6619265079498291, train/raw-loss = 0.5492690205574036, train/logprobs = tensor([[-1.3976, -1.4711],
        [-3.6201, -1.4614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037552494555711746
Epoch 0, Step 2224: train/loss = 0.5132111310958862, train/raw-loss = 0.4465726613998413, train/logprobs = tensor([[-0.7928, -2.3664],
        [-1.7544, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022212833166122437
Epoch 0, Step 2225: train/loss = 0.3194926977157593, train/raw-loss = 0.22706560790538788, train/logprobs = tensor([[-0.9316, -4.7200],
        [-2.5211, -1.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03080902062356472
Epoch 0, Step 2226: train/loss = 0.5016810297966003, train/raw-loss = 0.4457888901233673, train/logprobs = tensor([[-0.8808, -2.9999],
        [-1.0059, -0.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01863071881234646
Epoch 0, Step 2227: train/loss = 0.286561518907547, train/raw-loss = 0.2022017240524292, train/logprobs = tensor([[-1.7547, -3.6154],
        [-3.8017, -0.9176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028119925409555435
Epoch 0, Step 2228: train/loss = 0.4573056697845459, train/raw-loss = 0.37372615933418274, train/logprobs = tensor([[-0.6804, -3.2137],
        [-1.3325, -1.3422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02785983309149742
Epoch 0, Step 2229: train/loss = 0.23769278824329376, train/raw-loss = 0.13536392152309418, train/logprobs = tensor([[-1.4927, -4.9208],
        [-3.8932, -1.4377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03410962596535683
Epoch 0, Step 2230: train/loss = 0.48981350660324097, train/raw-loss = 0.38622796535491943, train/logprobs = tensor([[-1.1306, -2.2969],
        [-2.4141, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034528519958257675
Epoch 0, Step 2231: train/loss = 0.3407723903656006, train/raw-loss = 0.2614338994026184, train/logprobs = tensor([[-0.8079, -3.4968],
        [-2.0794, -0.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026446152478456497
Epoch 0, Step 2232: train/loss = 0.4902365207672119, train/raw-loss = 0.4241056740283966, train/logprobs = tensor([[-1.2170, -2.4724],
        [-2.4796, -1.5096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0220436193048954
Epoch 0, Step 2233: train/loss = 0.5134954452514648, train/raw-loss = 0.4515898823738098, train/logprobs = tensor([[-1.1972, -2.2326],
        [-2.2430, -0.6902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020635178312659264
Epoch 0, Step 2234: train/loss = 0.3963978588581085, train/raw-loss = 0.3010118305683136, train/logprobs = tensor([[-0.9282, -4.4387],
        [-1.8882, -1.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03179533779621124
Epoch 0, Step 2235: train/loss = 0.3074539601802826, train/raw-loss = 0.20609509944915771, train/logprobs = tensor([[-0.8348, -4.3939],
        [-2.3628, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03378627821803093
Epoch 0, Step 2236: train/loss = 0.25374501943588257, train/raw-loss = 0.1791810244321823, train/logprobs = tensor([[-0.9821, -6.1716],
        [-2.0303, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024854660034179688
Epoch 0, Step 2237: train/loss = 0.6394670009613037, train/raw-loss = 0.5677332878112793, train/logprobs = tensor([[-0.6582, -2.1487],
        [-0.8624, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023911233991384506
Epoch 0, Step 2238: train/loss = 0.5405720472335815, train/raw-loss = 0.4803948998451233, train/logprobs = tensor([[-0.8376, -3.6358],
        [-0.7601, -1.3848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020059049129486084
Epoch 0, Step 2239: train/loss = 0.6852238178253174, train/raw-loss = 0.6239927411079407, train/logprobs = tensor([[-0.9595, -2.9832],
        [-1.1137, -2.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020410362631082535
Epoch 0, Step 2240: train/loss = 1.0116255283355713, train/raw-loss = 0.9266210794448853, train/logprobs = tensor([[-0.8315, -1.7861],
        [-1.8378, -2.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028334781527519226
Epoch 0, Step 2241: train/loss = 0.5811397433280945, train/raw-loss = 0.5170366168022156, train/logprobs = tensor([[-0.9044, -2.2536],
        [-0.7591, -1.1548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02136770822107792
Epoch 0, Step 2242: train/loss = 0.553662896156311, train/raw-loss = 0.5015644431114197, train/logprobs = tensor([[-0.6114, -2.3979],
        [-0.7063, -0.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017366161569952965
Epoch 0, Step 2243: train/loss = 0.43319714069366455, train/raw-loss = 0.3817462623119354, train/logprobs = tensor([[-0.8757, -3.0628],
        [-1.1643, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01715027540922165
Epoch 0, Step 2244: train/loss = 0.5214970707893372, train/raw-loss = 0.45236852765083313, train/logprobs = tensor([[-0.7889, -2.3879],
        [-1.5447, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023042835295200348
Epoch 0, Step 2245: train/loss = 0.38474804162979126, train/raw-loss = 0.307681679725647, train/logprobs = tensor([[-0.8232, -3.3572],
        [-1.7398, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025688787922263145
Epoch 0, Step 2246: train/loss = 0.5569615960121155, train/raw-loss = 0.4871765971183777, train/logprobs = tensor([[-1.1230, -2.2111],
        [-2.8624, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023261677473783493
Epoch 0, Step 2247: train/loss = 0.39980071783065796, train/raw-loss = 0.3491221070289612, train/logprobs = tensor([[-0.6864, -4.2450],
        [-0.9803, -1.0600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016892869025468826
Epoch 0, Step 2248: train/loss = 0.2911929488182068, train/raw-loss = 0.18773971498012543, train/logprobs = tensor([[-1.2079, -5.0603],
        [-2.6814, -2.0295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03448440507054329
Epoch 0, Step 2249: train/loss = 0.5756765007972717, train/raw-loss = 0.49972522258758545, train/logprobs = tensor([[-1.4898, -1.7729],
        [-2.8644, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02531708963215351
Epoch 0, Step 2250: train/loss = 0.26190969347953796, train/raw-loss = 0.17914724349975586, train/logprobs = tensor([[-1.0913, -3.9858],
        [-3.1436, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02758748084306717
Epoch 0, Step 2251: train/loss = 0.5267639756202698, train/raw-loss = 0.44096291065216064, train/logprobs = tensor([[-0.8132, -1.1298],
        [-2.2907, -0.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028600353747606277
Epoch 0, Step 2252: train/loss = 0.37485599517822266, train/raw-loss = 0.2844706177711487, train/logprobs = tensor([[-1.0098, -3.3336],
        [-2.2974, -1.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03012845851480961
Epoch 0, Step 2253: train/loss = 0.5831188559532166, train/raw-loss = 0.5189624428749084, train/logprobs = tensor([[-1.2949, -1.4195],
        [-2.4063, -0.9288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02138546109199524
Epoch 0, Step 2254: train/loss = 0.5053527355194092, train/raw-loss = 0.429973840713501, train/logprobs = tensor([[-1.0798, -1.3753],
        [-2.3018, -0.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025126293301582336
Epoch 0, Step 2255: train/loss = 0.49364882707595825, train/raw-loss = 0.40807944536209106, train/logprobs = tensor([[-0.8900, -2.5866],
        [-1.5847, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028523119166493416
Epoch 0, Step 2256: train/loss = 0.2856699824333191, train/raw-loss = 0.17405757308006287, train/logprobs = tensor([[-1.2790, -3.6672],
        [-3.3718, -0.9772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03720414638519287
Epoch 0, Step 2257: train/loss = 0.45720937848091125, train/raw-loss = 0.37270060181617737, train/logprobs = tensor([[-1.5312, -2.1515],
        [-2.6768, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02816958911716938
Epoch 0, Step 2258: train/loss = 0.40602126717567444, train/raw-loss = 0.3302117586135864, train/logprobs = tensor([[-1.5471, -4.1876],
        [-2.2401, -1.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02526983618736267
Epoch 0, Step 2259: train/loss = 0.2600141167640686, train/raw-loss = 0.17696771025657654, train/logprobs = tensor([[-1.1267, -4.9809],
        [-3.4392, -1.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027682123705744743
Epoch 0, Step 2260: train/loss = 0.842893660068512, train/raw-loss = 0.7523199915885925, train/logprobs = tensor([[-0.8662, -3.6697],
        [-1.8491, -2.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0301912110298872
Epoch 0, Step 2261: train/loss = 0.364668071269989, train/raw-loss = 0.2799878716468811, train/logprobs = tensor([[-0.9094, -3.8356],
        [-1.6449, -1.4118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028226720169186592
Epoch 0, Step 2262: train/loss = 0.38282328844070435, train/raw-loss = 0.3025954067707062, train/logprobs = tensor([[-0.9195, -2.9092],
        [-2.4306, -1.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02674262970685959
Epoch 0, Step 2263: train/loss = 0.354615181684494, train/raw-loss = 0.27310699224472046, train/logprobs = tensor([[-1.0914, -2.9909],
        [-3.6742, -0.8351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02716939151287079
Epoch 0, Step 2264: train/loss = 0.3936986029148102, train/raw-loss = 0.33578580617904663, train/logprobs = tensor([[-0.9416, -4.1617],
        [-1.1430, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01930427923798561
Epoch 0, Step 2265: train/loss = 0.5382145643234253, train/raw-loss = 0.49126535654067993, train/logprobs = tensor([[-0.6283, -2.7170],
        [-0.7816, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015649747103452682
Epoch 0, Step 2266: train/loss = 0.3907926082611084, train/raw-loss = 0.3202822208404541, train/logprobs = tensor([[-0.8411, -4.5892],
        [-1.1670, -1.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023503458127379417
Epoch 0, Step 2267: train/loss = 0.35601097345352173, train/raw-loss = 0.29513221979141235, train/logprobs = tensor([[-0.8364, -4.8113],
        [-1.0266, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020292915403842926
Epoch 0, Step 2268: train/loss = 0.44850286841392517, train/raw-loss = 0.3682782053947449, train/logprobs = tensor([[-0.8723, -1.5799],
        [-2.4579, -0.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026741543784737587
Epoch 0, Step 2269: train/loss = 0.4969010353088379, train/raw-loss = 0.43422162532806396, train/logprobs = tensor([[-1.2448, -2.4866],
        [-2.1118, -1.1851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020893150940537453
Epoch 0, Step 2270: train/loss = 0.3944784104824066, train/raw-loss = 0.30958735942840576, train/logprobs = tensor([[-0.8942, -3.5949],
        [-2.1721, -1.1289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02829701639711857
Epoch 0, Step 2271: train/loss = 0.36353227496147156, train/raw-loss = 0.28349465131759644, train/logprobs = tensor([[-0.9953, -2.5232],
        [-3.0029, -0.8719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026679199188947678
Epoch 0, Step 2272: train/loss = 0.4297946095466614, train/raw-loss = 0.3691699206829071, train/logprobs = tensor([[-0.7129, -3.8582],
        [-1.0188, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020208224654197693
Epoch 0, Step 2273: train/loss = 0.49129146337509155, train/raw-loss = 0.4128440320491791, train/logprobs = tensor([[-1.2827, -3.8441],
        [-1.8139, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02614913135766983
Epoch 0, Step 2274: train/loss = 0.4597228169441223, train/raw-loss = 0.4044457972049713, train/logprobs = tensor([[-1.6559, -4.7631],
        [-1.7522, -1.8324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01842566952109337
Epoch 0, Step 2275: train/loss = 0.418913334608078, train/raw-loss = 0.35936063528060913, train/logprobs = tensor([[-1.1366, -4.4112],
        [-1.5994, -1.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019850902259349823
Epoch 0, Step 2276: train/loss = 0.7229525446891785, train/raw-loss = 0.674423336982727, train/logprobs = tensor([[-1.0928, -1.2668],
        [-1.1496, -1.2250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016176387667655945
Epoch 0, Step 2277: train/loss = 0.302571177482605, train/raw-loss = 0.2188679277896881, train/logprobs = tensor([[-1.1568, -3.3973],
        [-4.0375, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02790107950568199
Epoch 0, Step 2278: train/loss = 0.37458154559135437, train/raw-loss = 0.28405413031578064, train/logprobs = tensor([[-0.9832, -2.0996],
        [-2.6267, -0.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03017580509185791
Epoch 0, Step 2279: train/loss = 0.4774501621723175, train/raw-loss = 0.39391615986824036, train/logprobs = tensor([[-0.6967, -3.9420],
        [-1.4324, -2.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027844678610563278
Epoch 0, Step 2280: train/loss = 0.495074063539505, train/raw-loss = 0.4320627450942993, train/logprobs = tensor([[-0.6419, -2.4121],
        [-1.5992, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02100377157330513
Epoch 0, Step 2281: train/loss = 0.4264586269855499, train/raw-loss = 0.3509075343608856, train/logprobs = tensor([[-0.9014, -1.9096],
        [-2.4962, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025183700025081635
Epoch 0, Step 2282: train/loss = 0.5205210447311401, train/raw-loss = 0.46886324882507324, train/logprobs = tensor([[-0.6051, -2.9936],
        [-0.8571, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017219271510839462
Epoch 0, Step 2283: train/loss = 0.3960326015949249, train/raw-loss = 0.33586788177490234, train/logprobs = tensor([[-1.2199, -3.6537],
        [-2.0609, -1.2788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02005491405725479
Epoch 0, Step 2284: train/loss = 0.3446110486984253, train/raw-loss = 0.2557152509689331, train/logprobs = tensor([[-1.0182, -3.4632],
        [-1.8652, -0.8787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02963194064795971
Epoch 0, Step 2285: train/loss = 0.4678456783294678, train/raw-loss = 0.4252678453922272, train/logprobs = tensor([[-0.7551, -3.5541],
        [-0.9191, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014192611910402775
Epoch 0, Step 2286: train/loss = 0.3021667003631592, train/raw-loss = 0.22325338423252106, train/logprobs = tensor([[-0.6586, -4.8656],
        [-1.4926, -1.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026304438710212708
Epoch 0, Step 2287: train/loss = 0.5611874461174011, train/raw-loss = 0.5038524866104126, train/logprobs = tensor([[-0.8928, -2.6672],
        [-0.8553, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01911163702607155
Epoch 0, Step 2288: train/loss = 0.38367727398872375, train/raw-loss = 0.3038834035396576, train/logprobs = tensor([[-1.7103, -3.0240],
        [-4.0781, -1.3524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026597950607538223
Epoch 0, Step 2289: train/loss = 0.4812895655632019, train/raw-loss = 0.4216059446334839, train/logprobs = tensor([[-0.9251, -3.3308],
        [-1.0329, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01989452727138996
Epoch 0, Step 2290: train/loss = 0.7724879384040833, train/raw-loss = 0.6783232688903809, train/logprobs = tensor([[-1.5833, -1.9270],
        [-2.8465, -2.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03138821944594383
Epoch 0, Step 2291: train/loss = 0.5467370748519897, train/raw-loss = 0.46890485286712646, train/logprobs = tensor([[-0.8638, -2.1119],
        [-1.4889, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025944098830223083
Epoch 0, Step 2292: train/loss = 0.32479315996170044, train/raw-loss = 0.2458641231060028, train/logprobs = tensor([[-1.5695, -4.0710],
        [-3.1922, -1.4773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026309683918952942
Epoch 0, Step 2293: train/loss = 0.34931501746177673, train/raw-loss = 0.25516676902770996, train/logprobs = tensor([[-1.1323, -3.0070],
        [-3.1194, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031382761895656586
Epoch 0, Step 2294: train/loss = 0.41305726766586304, train/raw-loss = 0.32313480973243713, train/logprobs = tensor([[-0.8671, -3.5059],
        [-1.8906, -1.2330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029974166303873062
Epoch 0, Step 2295: train/loss = 0.3675728142261505, train/raw-loss = 0.30624744296073914, train/logprobs = tensor([[-0.5345, -4.1468],
        [-0.6640, -0.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020441794767975807
Epoch 0, Step 2296: train/loss = 0.22932447493076324, train/raw-loss = 0.14653140306472778, train/logprobs = tensor([[-0.9536, -4.3707],
        [-3.5890, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027597695589065552
Epoch 0, Step 2297: train/loss = 0.4809218645095825, train/raw-loss = 0.4087122678756714, train/logprobs = tensor([[-0.9041, -2.8253],
        [-1.8394, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02406986616551876
Epoch 0, Step 2298: train/loss = 0.4378632605075836, train/raw-loss = 0.37579968571662903, train/logprobs = tensor([[-0.6761, -4.3255],
        [-0.8748, -1.2082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020687861368060112
Epoch 0, Step 2299: train/loss = 0.6163275837898254, train/raw-loss = 0.5251893997192383, train/logprobs = tensor([[-0.8206, -1.2667],
        [-1.1260, -0.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0303793977946043
Epoch 0, Step 2300: train/loss = 0.3236408233642578, train/raw-loss = 0.23504820466041565, train/logprobs = tensor([[-0.7357, -4.4660],
        [-2.6079, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029530871659517288
Epoch 0, Step 2301: train/loss = 0.42702722549438477, train/raw-loss = 0.3677545189857483, train/logprobs = tensor([[-1.2753, -1.9030],
        [-3.3090, -0.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019757576286792755
Epoch 0, Step 2302: train/loss = 0.37999922037124634, train/raw-loss = 0.30772197246551514, train/logprobs = tensor([[-1.2221, -4.8055],
        [-2.1557, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024092428386211395
Epoch 0, Step 2303: train/loss = 0.5534530878067017, train/raw-loss = 0.4913782477378845, train/logprobs = tensor([[-1.3031, -3.4125],
        [-1.4225, -1.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020691629499197006
Epoch 0, Step 2304: train/loss = 0.35822540521621704, train/raw-loss = 0.27372920513153076, train/logprobs = tensor([[-1.8643, -3.9989],
        [-3.4841, -1.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028165403753519058
Epoch 0, Step 2305: train/loss = 0.3025628924369812, train/raw-loss = 0.21465715765953064, train/logprobs = tensor([[-0.9157, -4.2771],
        [-1.9059, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029301922768354416
Epoch 0, Step 2306: train/loss = 0.37349069118499756, train/raw-loss = 0.26928722858428955, train/logprobs = tensor([[-0.8464, -3.6377],
        [-1.9838, -1.5660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034734491258859634
Epoch 0, Step 2307: train/loss = 0.3907887637615204, train/raw-loss = 0.3240410387516022, train/logprobs = tensor([[-0.7411, -4.1407],
        [-1.5687, -1.4805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022249240428209305
Epoch 0, Step 2308: train/loss = 0.4322805404663086, train/raw-loss = 0.35880738496780396, train/logprobs = tensor([[-1.0906, -1.6965],
        [-2.7386, -0.7682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02449105493724346
Epoch 0, Step 2309: train/loss = 0.36308592557907104, train/raw-loss = 0.2545672357082367, train/logprobs = tensor([[-0.9673, -3.7064],
        [-2.2364, -1.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03617288917303085
Epoch 0, Step 2310: train/loss = 0.43418413400650024, train/raw-loss = 0.3552270233631134, train/logprobs = tensor([[-1.0678, -3.9137],
        [-1.9779, -1.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02631903439760208
Epoch 0, Step 2311: train/loss = 0.42323940992355347, train/raw-loss = 0.3577688932418823, train/logprobs = tensor([[-0.8454, -3.6830],
        [-1.0295, -1.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02182351052761078
Epoch 0, Step 2312: train/loss = 0.44690993428230286, train/raw-loss = 0.3760566711425781, train/logprobs = tensor([[-1.0145, -2.2626],
        [-2.0629, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023617755621671677
Epoch 0, Step 2313: train/loss = 0.4239473342895508, train/raw-loss = 0.3488609194755554, train/logprobs = tensor([[-1.1983, -1.7091],
        [-2.8547, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02502880059182644
Epoch 0, Step 2314: train/loss = 0.5915136933326721, train/raw-loss = 0.5418980121612549, train/logprobs = tensor([[-1.0661, -1.2435],
        [-1.8404, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016538549214601517
Epoch 0, Step 2315: train/loss = 0.34916016459465027, train/raw-loss = 0.27214986085891724, train/logprobs = tensor([[-0.7115, -4.1653],
        [-1.4714, -1.5111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02567010559141636
Epoch 0, Step 2316: train/loss = 0.4118849039077759, train/raw-loss = 0.3199560046195984, train/logprobs = tensor([[-0.9441, -2.2106],
        [-2.0798, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030642971396446228
Epoch 0, Step 2317: train/loss = 0.34255707263946533, train/raw-loss = 0.22195398807525635, train/logprobs = tensor([[-1.0410, -3.5593],
        [-2.9789, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04020102322101593
Epoch 0, Step 2318: train/loss = 0.28548604249954224, train/raw-loss = 0.200147807598114, train/logprobs = tensor([[-0.8037, -4.8494],
        [-1.8931, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028446068987250328
Epoch 0, Step 2319: train/loss = 0.5281160473823547, train/raw-loss = 0.4658646881580353, train/logprobs = tensor([[-0.7581, -3.0684],
        [-0.7423, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02075044810771942
Epoch 0, Step 2320: train/loss = 0.5917677879333496, train/raw-loss = 0.5210645198822021, train/logprobs = tensor([[-1.1627, -1.5886],
        [-1.5709, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02356777712702751
Epoch 0, Step 2321: train/loss = 0.5252834558486938, train/raw-loss = 0.47976386547088623, train/logprobs = tensor([[-0.8078, -2.8279],
        [-0.9275, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015173204243183136
Epoch 0, Step 2322: train/loss = 0.6247541904449463, train/raw-loss = 0.5851898789405823, train/logprobs = tensor([[-1.2384, -2.6618],
        [-1.2593, -2.1708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013188095763325691
Epoch 0, Step 2323: train/loss = 0.37926822900772095, train/raw-loss = 0.2965107560157776, train/logprobs = tensor([[-0.8392, -3.6458],
        [-1.7065, -1.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0275858286768198
Epoch 0, Step 2324: train/loss = 0.49538755416870117, train/raw-loss = 0.4254135489463806, train/logprobs = tensor([[-1.2729, -1.7727],
        [-3.3295, -1.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02332466095685959
Epoch 0, Step 2325: train/loss = 0.3849959969520569, train/raw-loss = 0.3103805482387543, train/logprobs = tensor([[-0.9475, -3.0199],
        [-2.7592, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024871814996004105
Epoch 0, Step 2326: train/loss = 0.4489007294178009, train/raw-loss = 0.3767277002334595, train/logprobs = tensor([[-1.1309, -2.9517],
        [-2.0158, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024057675153017044
Epoch 0, Step 2327: train/loss = 0.4354051649570465, train/raw-loss = 0.3611639738082886, train/logprobs = tensor([[-1.2521, -3.4616],
        [-2.2083, -1.8807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02474706806242466
Epoch 0, Step 2328: train/loss = 0.567441463470459, train/raw-loss = 0.514815092086792, train/logprobs = tensor([[-0.7342, -1.8403],
        [-0.7976, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017542127519845963
Epoch 0, Step 2329: train/loss = 0.4267596900463104, train/raw-loss = 0.36997148394584656, train/logprobs = tensor([[-0.6889, -3.8559],
        [-0.7184, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018929412588477135
Epoch 0, Step 2330: train/loss = 0.4027152955532074, train/raw-loss = 0.32873743772506714, train/logprobs = tensor([[-1.0643, -3.3285],
        [-2.0302, -1.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02465929463505745
Epoch 0, Step 2331: train/loss = 0.48926129937171936, train/raw-loss = 0.43428948521614075, train/logprobs = tensor([[-0.7662, -3.7059],
        [-0.9803, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01832393929362297
Epoch 0, Step 2332: train/loss = 0.4936295747756958, train/raw-loss = 0.44594764709472656, train/logprobs = tensor([[-1.3288, -3.4208],
        [-1.4359, -1.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015893975272774696
Epoch 0, Step 2333: train/loss = 0.39696794748306274, train/raw-loss = 0.31475329399108887, train/logprobs = tensor([[-0.6760, -4.0317],
        [-0.8855, -0.9606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02740487828850746
Epoch 0, Step 2334: train/loss = 0.5278005003929138, train/raw-loss = 0.4555615186691284, train/logprobs = tensor([[-0.6712, -3.8309],
        [-1.3462, -1.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024079659953713417
Epoch 0, Step 2335: train/loss = 0.4226325452327728, train/raw-loss = 0.3543829917907715, train/logprobs = tensor([[-0.8285, -3.5049],
        [-1.6988, -1.5554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022749844938516617
Epoch 0, Step 2336: train/loss = 0.7959611415863037, train/raw-loss = 0.6930475831031799, train/logprobs = tensor([[-1.3858, -1.8723],
        [-2.1984, -2.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03430452570319176
Epoch 0, Step 2337: train/loss = 0.34033846855163574, train/raw-loss = 0.2675980031490326, train/logprobs = tensor([[-1.2473, -3.6315],
        [-2.4155, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024246826767921448
Epoch 0, Step 2338: train/loss = 0.41869601607322693, train/raw-loss = 0.31323879957199097, train/logprobs = tensor([[-0.8399, -3.1388],
        [-1.7270, -0.9180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03515239804983139
Epoch 0, Step 2339: train/loss = 0.703237771987915, train/raw-loss = 0.6540009379386902, train/logprobs = tensor([[-1.1956, -1.5301],
        [-0.8432, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016412271186709404
Epoch 0, Step 2340: train/loss = 0.3354037404060364, train/raw-loss = 0.25589117407798767, train/logprobs = tensor([[-1.2325, -2.7843],
        [-3.2840, -1.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02650419808924198
Epoch 0, Step 2341: train/loss = 0.5378565788269043, train/raw-loss = 0.48769646883010864, train/logprobs = tensor([[-0.7368, -2.9220],
        [-0.9985, -1.6549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016720043495297432
Epoch 0, Step 2342: train/loss = 0.5289182662963867, train/raw-loss = 0.4598821699619293, train/logprobs = tensor([[-1.2058, -1.0537],
        [-3.7176, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023012027144432068
Epoch 0, Step 2343: train/loss = 0.4923321008682251, train/raw-loss = 0.422826886177063, train/logprobs = tensor([[-1.1245, -3.0997],
        [-2.4544, -1.4595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023168407380580902
Epoch 0, Step 2344: train/loss = 0.5628262758255005, train/raw-loss = 0.4839200973510742, train/logprobs = tensor([[-1.4706, -2.5289],
        [-2.3973, -1.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026302063837647438
Epoch 0, Step 2345: train/loss = 0.6139539480209351, train/raw-loss = 0.5677163004875183, train/logprobs = tensor([[-0.5582, -2.1239],
        [-0.6864, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015412534587085247
Epoch 0, Step 2346: train/loss = 0.73014897108078, train/raw-loss = 0.6817770004272461, train/logprobs = tensor([[-0.9800, -1.0867],
        [-1.2525, -1.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016123998910188675
Epoch 0, Step 2347: train/loss = 0.22542688250541687, train/raw-loss = 0.15282806754112244, train/logprobs = tensor([[-2.0503, -5.4921],
        [-3.9013, -1.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024199604988098145
Epoch 0, Step 2348: train/loss = 0.4016312062740326, train/raw-loss = 0.33392247557640076, train/logprobs = tensor([[-1.0988, -2.4030],
        [-3.3054, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022569572553038597
Epoch 0, Step 2349: train/loss = 0.5398044586181641, train/raw-loss = 0.4530448019504547, train/logprobs = tensor([[-0.8465, -2.7161],
        [-1.3043, -1.2316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028919892385601997
Epoch 0, Step 2350: train/loss = 0.4404892027378082, train/raw-loss = 0.3332540988922119, train/logprobs = tensor([[-1.1625, -1.0787],
        [-3.6459, -0.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035745035856962204
Epoch 0, Step 2351: train/loss = 0.4104190468788147, train/raw-loss = 0.3508988618850708, train/logprobs = tensor([[-0.5682, -4.4475],
        [-0.8186, -0.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019840069115161896
Epoch 0, Step 2352: train/loss = 0.41847413778305054, train/raw-loss = 0.35689249634742737, train/logprobs = tensor([[-0.9313, -3.2306],
        [-1.5488, -0.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020527208223938942
Epoch 0, Step 2353: train/loss = 0.3398773968219757, train/raw-loss = 0.2508269250392914, train/logprobs = tensor([[-0.8951, -4.6944],
        [-1.6939, -1.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029683489352464676
Epoch 0, Step 2354: train/loss = 0.44453921914100647, train/raw-loss = 0.3603134751319885, train/logprobs = tensor([[-0.9554, -2.8859],
        [-2.0834, -1.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028075240552425385
Epoch 0, Step 2355: train/loss = 0.3745223879814148, train/raw-loss = 0.2952030897140503, train/logprobs = tensor([[-1.2825, -2.6580],
        [-2.9179, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026439756155014038
Epoch 0, Step 2356: train/loss = 0.2926997244358063, train/raw-loss = 0.18544334173202515, train/logprobs = tensor([[-1.3126, -3.3905],
        [-4.0955, -1.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035752128809690475
Epoch 0, Step 2357: train/loss = 0.49422046542167664, train/raw-loss = 0.41821974515914917, train/logprobs = tensor([[-1.6999, -4.7420],
        [-1.9953, -1.5324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025333572179079056
Epoch 0, Step 2358: train/loss = 0.481961727142334, train/raw-loss = 0.4235984683036804, train/logprobs = tensor([[-0.7653, -3.3918],
        [-1.0689, -0.9114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01945441961288452
Epoch 0, Step 2359: train/loss = 0.5782901644706726, train/raw-loss = 0.5005813241004944, train/logprobs = tensor([[-1.2015, -2.1593],
        [-2.2221, -1.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025902949273586273
Epoch 0, Step 2360: train/loss = 0.5453647971153259, train/raw-loss = 0.4770164489746094, train/logprobs = tensor([[-0.7126, -0.9527],
        [-1.7754, -0.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022782765328884125
Epoch 0, Step 2361: train/loss = 0.49544984102249146, train/raw-loss = 0.4209291934967041, train/logprobs = tensor([[-1.3896, -4.7578],
        [-1.8179, -2.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02484021708369255
Epoch 0, Step 2362: train/loss = 0.3471214771270752, train/raw-loss = 0.25425246357917786, train/logprobs = tensor([[-1.1250, -4.1010],
        [-2.8998, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0309563297778368
Epoch 0, Step 2363: train/loss = 0.673195481300354, train/raw-loss = 0.601302444934845, train/logprobs = tensor([[-1.4402, -2.9911],
        [-2.3114, -2.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023964352905750275
Epoch 0, Step 2364: train/loss = 0.2080235779285431, train/raw-loss = 0.11219976097345352, train/logprobs = tensor([[-1.1209, -3.7314],
        [-3.6247, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03194127231836319
Epoch 0, Step 2365: train/loss = 0.37411943078041077, train/raw-loss = 0.31399813294410706, train/logprobs = tensor([[-1.1219, -3.4734],
        [-1.8136, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020040426403284073
Epoch 0, Step 2366: train/loss = 0.6859721541404724, train/raw-loss = 0.6050445437431335, train/logprobs = tensor([[-0.8017, -3.9950],
        [-2.1855, -2.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02697586454451084
Epoch 0, Step 2367: train/loss = 0.6018195748329163, train/raw-loss = 0.5454865097999573, train/logprobs = tensor([[-0.9998, -1.7916],
        [-0.9167, -0.9125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01877768710255623
Epoch 0, Step 2368: train/loss = 0.5221049785614014, train/raw-loss = 0.47658929228782654, train/logprobs = tensor([[-1.0209, -3.5475],
        [-1.0470, -1.1714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015171891078352928
Epoch 0, Step 2369: train/loss = 0.6961215138435364, train/raw-loss = 0.6348090171813965, train/logprobs = tensor([[-1.7496, -2.1992],
        [-1.6039, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020437493920326233
Epoch 0, Step 2370: train/loss = 0.630251944065094, train/raw-loss = 0.5939826965332031, train/logprobs = tensor([[-0.9549, -1.3611],
        [-1.2243, -1.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012089738622307777
Epoch 0, Step 2371: train/loss = 0.33670175075531006, train/raw-loss = 0.2533740997314453, train/logprobs = tensor([[-0.9011, -3.2576],
        [-2.4041, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027775878086686134
Epoch 0, Step 2372: train/loss = 0.4255465269088745, train/raw-loss = 0.35647234320640564, train/logprobs = tensor([[-1.1139, -3.4686],
        [-2.9454, -1.5694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023024726659059525
Epoch 0, Step 2373: train/loss = 0.5064798593521118, train/raw-loss = 0.45023417472839355, train/logprobs = tensor([[-1.0371, -3.7089],
        [-0.9136, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018748577684164047
Epoch 0, Step 2374: train/loss = 0.35765475034713745, train/raw-loss = 0.2690306603908539, train/logprobs = tensor([[-1.1078, -3.0605],
        [-4.0352, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02954135462641716
Loss is nan
eval/loss: 0.4576006531715393
