[2024-03-04 12:36:17,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 12:36:17,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 12:36:17,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-04 12:36:17,096] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-04 12:36:40,182] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-04 12:36:40,182] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-04 12:36:40,319] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-04 12:36:40,507][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f4348e04eb0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-04 12:36:41,174][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f0de8d09d50>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-04 12:36:42,076] [INFO] [comm.py:637:init_distributed] cdb=None
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-04 12:36:42,167] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-04 12:36:42,643][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f33c7575030>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-04 12:36:42,732][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f51c0d5d060>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-04 12:37:23,844][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-04 12:37:23,848] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[2024-03-04 12:37:37,596] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-04 12:37:37,600] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-04 12:37:37,972] [INFO] [utils.py:791:see_memory_usage] begin bf16_optimizer
[2024-03-04 12:37:37,973] [INFO] [utils.py:792:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-04 12:37:37,973] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 89.86 GB, percent = 8.9%
[2024-03-04 12:37:38,091] [INFO] [utils.py:791:see_memory_usage] end bf16_optimizer
[2024-03-04 12:37:38,092] [INFO] [utils.py:792:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-04 12:37:38,093] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 89.57 GB, percent = 8.9%
[2024-03-04 12:37:38,093] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   amp_enabled .................. False
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   amp_params ................... False
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f4348d3b550>
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   communication_data_type ...... None
[2024-03-04 12:37:38,094] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   disable_allgather ............ False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   dump_state ................... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   fp16_enabled ................. False
[2024-03-04 12:37:38,095] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   global_rank .................. 0
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 32
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   gradient_clipping ............ 1.0
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   graph_harvesting ............. False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   memory_breakdown ............. False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   optimizer_name ............... None
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   optimizer_params ............. None
[2024-03-04 12:37:38,096] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   pld_enabled .................. False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   pld_params ................... False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   prescale_gradients ........... False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   scheduler_name ............... None
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   scheduler_params ............. None
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   sparse_attention ............. None
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   steps_per_print .............. inf
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   train_batch_size ............. 128
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  1
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   weight_quantization_config ... None
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   world_size ................... 4
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   zero_enabled ................. False
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-04 12:37:38,097] [INFO] [config.py:988:print]   zero_optimization_stage ...... 0
[2024-03-04 12:37:38,097] [INFO] [config.py:974:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -37.72028732299805, 'logps/chosen': -37.88322830200195, 'logits/rejected': -2.9434497356414795, 'logits/chosen': -3.064993143081665, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -41.77348327636719, 'logps/chosen': -40.13481903076172, 'logits/rejected': -2.9425387382507324, 'logits/chosen': -2.9552884101867676, 'epoch': 0.01}
{'loss': 0.6928, 'learning_rate': 2e-07, 'rewards/chosen': 0.005495220422744751, 'rewards/rejected': 0.0010186138097196817, 'rewards/accuracies': 0.625, 'rewards/margins': 0.004476606845855713, 'logps/rejected': -41.163570404052734, 'logps/chosen': -40.44462585449219, 'logits/rejected': -2.8924601078033447, 'logits/chosen': -2.9591753482818604, 'epoch': 0.02}
{'loss': 0.6917, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': 0.002990770386531949, 'rewards/rejected': 0.004274880979210138, 'rewards/accuracies': 0.40625, 'rewards/margins': -0.001284110127016902, 'logps/rejected': -41.68983459472656, 'logps/chosen': -42.72062301635742, 'logits/rejected': -3.029729127883911, 'logits/chosen': -3.0247642993927, 'epoch': 0.03}
{'loss': 0.6916, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': -0.0023237825371325016, 'rewards/rejected': -0.005446081981062889, 'rewards/accuracies': 0.625, 'rewards/margins': 0.0031223001424223185, 'logps/rejected': -38.54704284667969, 'logps/chosen': -42.062522888183594, 'logits/rejected': -2.947326183319092, 'logits/chosen': -2.984875202178955, 'epoch': 0.03}
{'loss': 0.6835, 'learning_rate': 4e-07, 'rewards/chosen': 0.0032009247224777937, 'rewards/rejected': -0.016315622255206108, 'rewards/accuracies': 0.59375, 'rewards/margins': 0.01951654627919197, 'logps/rejected': -39.55073165893555, 'logps/chosen': -35.865909576416016, 'logits/rejected': -2.924449920654297, 'logits/chosen': -2.959994077682495, 'epoch': 0.04}
{'loss': 0.679, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': -0.002035087440162897, 'rewards/rejected': -0.03215762600302696, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.030122537165880203, 'logps/rejected': -44.65505599975586, 'logps/chosen': -47.26072692871094, 'logits/rejected': -2.9160451889038086, 'logits/chosen': -3.007533550262451, 'epoch': 0.05}
{'loss': 0.6712, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.015874721109867096, 'rewards/rejected': -0.0388236902654171, 'rewards/accuracies': 0.5625, 'rewards/margins': 0.054698411375284195, 'logps/rejected': -35.13267135620117, 'logps/chosen': -41.182579040527344, 'logits/rejected': -2.9627933502197266, 'logits/chosen': -2.981981039047241, 'epoch': 0.05}
{'loss': 0.6399, 'learning_rate': 6e-07, 'rewards/chosen': 0.01467947568744421, 'rewards/rejected': -0.14721202850341797, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.16189150512218475, 'logps/rejected': -42.73297882080078, 'logps/chosen': -34.26264572143555, 'logits/rejected': -2.9310102462768555, 'logits/chosen': -2.9572255611419678, 'epoch': 0.06}
{'loss': 0.6381, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': -0.1004706621170044, 'rewards/rejected': -0.19835174083709717, 'rewards/accuracies': 0.6875, 'rewards/margins': 0.09788107872009277, 'logps/rejected': -42.79164123535156, 'logps/chosen': -39.54901123046875, 'logits/rejected': -2.939706802368164, 'logits/chosen': -2.938326120376587, 'epoch': 0.07}
{'loss': 0.5949, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': -0.16355466842651367, 'rewards/rejected': -0.3366992771625519, 'rewards/accuracies': 0.75, 'rewards/margins': 0.1731446087360382, 'logps/rejected': -41.667724609375, 'logps/chosen': -43.616798400878906, 'logits/rejected': -2.909606695175171, 'logits/chosen': -3.003678321838379, 'epoch': 0.07}
{'loss': 0.5522, 'learning_rate': 8e-07, 'rewards/chosen': -0.012566015124320984, 'rewards/rejected': -0.3512156903743744, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.3386496305465698, 'logps/rejected': -44.78008270263672, 'logps/chosen': -38.48235321044922, 'logits/rejected': -2.956605911254883, 'logits/chosen': -2.9086074829101562, 'epoch': 0.08}
{'loss': 0.5144, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': 0.009170547127723694, 'rewards/rejected': -0.3931329846382141, 'rewards/accuracies': 0.84375, 'rewards/margins': 0.4023035168647766, 'logps/rejected': -45.391929626464844, 'logps/chosen': -39.04827880859375, 'logits/rejected': -2.9533915519714355, 'logits/chosen': -3.044557571411133, 'epoch': 0.09}
{'loss': 0.499, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': -0.07642240822315216, 'rewards/rejected': -0.7550373077392578, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.6786149740219116, 'logps/rejected': -46.642032623291016, 'logps/chosen': -35.51428985595703, 'logits/rejected': -2.9993531703948975, 'logits/chosen': -2.917480707168579, 'epoch': 0.09}
{'loss': 0.4311, 'learning_rate': 1e-06, 'rewards/chosen': -0.2510406970977783, 'rewards/rejected': -1.0088932514190674, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.7578526139259338, 'logps/rejected': -54.3158073425293, 'logps/chosen': -45.63121032714844, 'logits/rejected': -2.999242067337036, 'logits/chosen': -2.984980821609497, 'epoch': 0.1}
{'loss': 0.3044, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': 0.1998281180858612, 'rewards/rejected': -1.4664437770843506, 'rewards/accuracies': 0.9375, 'rewards/margins': 1.6662719249725342, 'logps/rejected': -61.08267593383789, 'logps/chosen': -38.27791213989258, 'logits/rejected': -3.0142643451690674, 'logits/chosen': -3.0397210121154785, 'epoch': 0.11}
{'loss': 0.2976, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': 0.08660124242305756, 'rewards/rejected': -1.6603238582611084, 'rewards/accuracies': 0.875, 'rewards/margins': 1.7469249963760376, 'logps/rejected': -58.84596633911133, 'logps/chosen': -41.51337432861328, 'logits/rejected': -3.0230319499969482, 'logits/chosen': -3.0914885997772217, 'epoch': 0.11}
{'loss': 0.294, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -0.3013286590576172, 'rewards/rejected': -2.1767992973327637, 'rewards/accuracies': 0.8125, 'rewards/margins': 1.8754708766937256, 'logps/rejected': -59.71465301513672, 'logps/chosen': -43.221805572509766, 'logits/rejected': -3.077401876449585, 'logits/chosen': -3.0909204483032227, 'epoch': 0.12}
{'loss': 0.2804, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -0.21410277485847473, 'rewards/rejected': -2.774367094039917, 'rewards/accuracies': 0.8125, 'rewards/margins': 2.5602643489837646, 'logps/rejected': -72.90415954589844, 'logps/chosen': -45.825992584228516, 'logits/rejected': -3.0461127758026123, 'logits/chosen': -3.068307399749756, 'epoch': 0.13}
{'loss': 0.2823, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -0.8247972130775452, 'rewards/rejected': -3.447075128555298, 'rewards/accuracies': 0.71875, 'rewards/margins': 2.6222779750823975, 'logps/rejected': -73.67818450927734, 'logps/chosen': -45.77207565307617, 'logits/rejected': -3.0743041038513184, 'logits/chosen': -3.0271260738372803, 'epoch': 0.13}
{'loss': 0.2571, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -0.7300890684127808, 'rewards/rejected': -4.627499103546143, 'rewards/accuracies': 0.875, 'rewards/margins': 3.897409677505493, 'logps/rejected': -89.90199279785156, 'logps/chosen': -51.05845260620117, 'logits/rejected': -3.0123260021209717, 'logits/chosen': -3.0451691150665283, 'epoch': 0.14}
{'loss': 0.2446, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -1.0170037746429443, 'rewards/rejected': -5.285183429718018, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.268179893493652, 'logps/rejected': -96.70868682861328, 'logps/chosen': -57.8714714050293, 'logits/rejected': -3.0419719219207764, 'logits/chosen': -3.1529946327209473, 'epoch': 0.15}
{'loss': 0.345, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -0.9564406275749207, 'rewards/rejected': -5.3620991706848145, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.405658721923828, 'logps/rejected': -98.12810516357422, 'logps/chosen': -45.67922592163086, 'logits/rejected': -3.0929436683654785, 'logits/chosen': -3.052441358566284, 'epoch': 0.15}
{'loss': 0.3578, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -0.4892079830169678, 'rewards/rejected': -4.737940311431885, 'rewards/accuracies': 0.875, 'rewards/margins': 4.248732089996338, 'logps/rejected': -93.77413940429688, 'logps/chosen': -47.4791374206543, 'logits/rejected': -3.0236096382141113, 'logits/chosen': -3.0021939277648926, 'epoch': 0.16}
{'loss': 0.2503, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -1.0453978776931763, 'rewards/rejected': -5.734241962432861, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.688843727111816, 'logps/rejected': -94.4930648803711, 'logps/chosen': -49.5166015625, 'logits/rejected': -3.0395631790161133, 'logits/chosen': -3.0888266563415527, 'epoch': 0.17}
{'loss': 0.2307, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -0.43873101472854614, 'rewards/rejected': -4.223513603210449, 'rewards/accuracies': 0.875, 'rewards/margins': 3.784782648086548, 'logps/rejected': -79.62981414794922, 'logps/chosen': -47.2315788269043, 'logits/rejected': -2.993914842605591, 'logits/chosen': -3.0894081592559814, 'epoch': 0.18}
{'loss': 0.1357, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -0.376766562461853, 'rewards/rejected': -4.358828544616699, 'rewards/accuracies': 0.9375, 'rewards/margins': 3.9820618629455566, 'logps/rejected': -85.99103546142578, 'logps/chosen': -44.82099151611328, 'logits/rejected': -3.102773666381836, 'logits/chosen': -3.036360025405884, 'epoch': 0.18}
{'loss': 0.1491, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -0.5658847093582153, 'rewards/rejected': -4.626509666442871, 'rewards/accuracies': 0.90625, 'rewards/margins': 4.060625076293945, 'logps/rejected': -79.68544006347656, 'logps/chosen': -44.71571350097656, 'logits/rejected': -2.995915412902832, 'logits/chosen': -3.1030843257904053, 'epoch': 0.19}
{'loss': 0.3156, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -0.9745543003082275, 'rewards/rejected': -4.760120391845703, 'rewards/accuracies': 0.875, 'rewards/margins': 3.785565137863159, 'logps/rejected': -87.50239562988281, 'logps/chosen': -53.18230056762695, 'logits/rejected': -3.050788640975952, 'logits/chosen': -3.1335031986236572, 'epoch': 0.2}
{'loss': 0.2121, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -0.4430549740791321, 'rewards/rejected': -4.437431335449219, 'rewards/accuracies': 0.78125, 'rewards/margins': 3.9943766593933105, 'logps/rejected': -91.4883041381836, 'logps/chosen': -45.31144714355469, 'logits/rejected': -3.1011345386505127, 'logits/chosen': -3.0111217498779297, 'epoch': 0.2}
{'loss': 0.2643, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -0.023752447217702866, 'rewards/rejected': -4.885018348693848, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.861265659332275, 'logps/rejected': -88.71717834472656, 'logps/chosen': -37.91740798950195, 'logits/rejected': -3.063077688217163, 'logits/chosen': -3.090181589126587, 'epoch': 0.21}
{'loss': 0.2004, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -0.27791666984558105, 'rewards/rejected': -5.827839374542236, 'rewards/accuracies': 1.0, 'rewards/margins': 5.549922943115234, 'logps/rejected': -98.69583129882812, 'logps/chosen': -36.571197509765625, 'logits/rejected': -3.0811073780059814, 'logits/chosen': -3.0202724933624268, 'epoch': 0.22}
{'loss': 0.2464, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -0.32154783606529236, 'rewards/rejected': -4.390415668487549, 'rewards/accuracies': 0.9375, 'rewards/margins': 4.0688676834106445, 'logps/rejected': -85.53678131103516, 'logps/chosen': -41.25792694091797, 'logits/rejected': -3.1120681762695312, 'logits/chosen': -3.0354065895080566, 'epoch': 0.22}
{'loss': 0.2048, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -0.8442040085792542, 'rewards/rejected': -5.372431755065918, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.52822732925415, 'logps/rejected': -94.44511413574219, 'logps/chosen': -48.148048400878906, 'logits/rejected': -3.103430986404419, 'logits/chosen': -2.996171236038208, 'epoch': 0.23}
{'loss': 0.1713, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': -0.7504498362541199, 'rewards/rejected': -4.8014726638793945, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.051022529602051, 'logps/rejected': -91.28605651855469, 'logps/chosen': -48.46929168701172, 'logits/rejected': -3.1528103351593018, 'logits/chosen': -3.0413455963134766, 'epoch': 0.24}
{'loss': 0.2215, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -0.9019259810447693, 'rewards/rejected': -6.0961456298828125, 'rewards/accuracies': 0.8125, 'rewards/margins': 5.194220066070557, 'logps/rejected': -101.88880920410156, 'logps/chosen': -46.73843765258789, 'logits/rejected': -3.104374408721924, 'logits/chosen': -3.1133179664611816, 'epoch': 0.24}
{'loss': 0.2075, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -1.082895040512085, 'rewards/rejected': -5.615447998046875, 'rewards/accuracies': 0.875, 'rewards/margins': 4.532552719116211, 'logps/rejected': -96.866943359375, 'logps/chosen': -47.91709518432617, 'logits/rejected': -3.1226325035095215, 'logits/chosen': -2.979478359222412, 'epoch': 0.25}
{'loss': 0.1944, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -1.2406189441680908, 'rewards/rejected': -6.113010406494141, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.872391700744629, 'logps/rejected': -100.05211639404297, 'logps/chosen': -59.12742614746094, 'logits/rejected': -3.0388717651367188, 'logits/chosen': -3.214961528778076, 'epoch': 0.26}
{'loss': 0.1628, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -1.6704246997833252, 'rewards/rejected': -6.305695056915283, 'rewards/accuracies': 0.875, 'rewards/margins': 4.635270118713379, 'logps/rejected': -101.51229858398438, 'logps/chosen': -55.80496597290039, 'logits/rejected': -3.0759072303771973, 'logits/chosen': -3.1328938007354736, 'epoch': 0.26}
{'loss': 0.257, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -2.026991844177246, 'rewards/rejected': -7.269869804382324, 'rewards/accuracies': 0.875, 'rewards/margins': 5.242878437042236, 'logps/rejected': -111.10179138183594, 'logps/chosen': -59.983943939208984, 'logits/rejected': -3.0969178676605225, 'logits/chosen': -3.1459579467773438, 'epoch': 0.27}
{'loss': 0.213, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -0.9717303514480591, 'rewards/rejected': -6.273775100708008, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.302044868469238, 'logps/rejected': -107.40892791748047, 'logps/chosen': -53.47978973388672, 'logits/rejected': -3.136415958404541, 'logits/chosen': -3.1398425102233887, 'epoch': 0.28}
{'loss': 0.2065, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -2.0055317878723145, 'rewards/rejected': -7.7369184494018555, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.731387138366699, 'logps/rejected': -115.71139526367188, 'logps/chosen': -64.32637023925781, 'logits/rejected': -3.075897216796875, 'logits/chosen': -3.2148914337158203, 'epoch': 0.28}
{'loss': 0.1492, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -1.441710352897644, 'rewards/rejected': -7.295947074890137, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.854236602783203, 'logps/rejected': -116.24193572998047, 'logps/chosen': -55.867897033691406, 'logits/rejected': -3.016338586807251, 'logits/chosen': -3.180957078933716, 'epoch': 0.29}
{'loss': 0.1549, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -1.4165558815002441, 'rewards/rejected': -7.940176010131836, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.52362060546875, 'logps/rejected': -125.00593566894531, 'logps/chosen': -51.42066955566406, 'logits/rejected': -3.18845534324646, 'logits/chosen': -3.0994811058044434, 'epoch': 0.3}
{'loss': 0.2174, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -1.972335696220398, 'rewards/rejected': -7.844164848327637, 'rewards/accuracies': 0.84375, 'rewards/margins': 5.871829032897949, 'logps/rejected': -120.03952026367188, 'logps/chosen': -62.66487121582031, 'logits/rejected': -3.1151163578033447, 'logits/chosen': -3.1352202892303467, 'epoch': 0.3}
{'loss': 0.2491, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -1.3044028282165527, 'rewards/rejected': -7.749956130981445, 'rewards/accuracies': 0.875, 'rewards/margins': 6.445552825927734, 'logps/rejected': -117.2580795288086, 'logps/chosen': -51.46402359008789, 'logits/rejected': -3.0058116912841797, 'logits/chosen': -3.0629653930664062, 'epoch': 0.31}
{'loss': 0.209, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -1.9923864603042603, 'rewards/rejected': -8.054441452026367, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.062054634094238, 'logps/rejected': -122.58145904541016, 'logps/chosen': -60.104591369628906, 'logits/rejected': -3.0862550735473633, 'logits/chosen': -3.0766513347625732, 'epoch': 0.32}
{'loss': 0.1157, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -1.1174029111862183, 'rewards/rejected': -8.637652397155762, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.520249366760254, 'logps/rejected': -128.1154327392578, 'logps/chosen': -51.45295715332031, 'logits/rejected': -3.078357696533203, 'logits/chosen': -3.1137917041778564, 'epoch': 0.32}
{'loss': 0.1542, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -1.9529283046722412, 'rewards/rejected': -8.468482971191406, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.515554904937744, 'logps/rejected': -124.59941864013672, 'logps/chosen': -59.11114501953125, 'logits/rejected': -3.1119847297668457, 'logits/chosen': -3.08428955078125, 'epoch': 0.33}
{'loss': 0.1234, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -2.0751779079437256, 'rewards/rejected': -8.197039604187012, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.121861934661865, 'logps/rejected': -122.33983612060547, 'logps/chosen': -60.58857727050781, 'logits/rejected': -3.1144895553588867, 'logits/chosen': -3.172922134399414, 'epoch': 0.34}
{'loss': 0.1442, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -1.7980303764343262, 'rewards/rejected': -7.858482360839844, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.060451507568359, 'logps/rejected': -121.88761901855469, 'logps/chosen': -61.01671600341797, 'logits/rejected': -3.0957493782043457, 'logits/chosen': -3.1349616050720215, 'epoch': 0.34}
{'loss': 0.1629, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -2.6151785850524902, 'rewards/rejected': -7.330223560333252, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.715044975280762, 'logps/rejected': -112.94337463378906, 'logps/chosen': -69.68392944335938, 'logits/rejected': -3.020686149597168, 'logits/chosen': -3.1048531532287598, 'epoch': 0.35}
{'loss': 0.1401, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -1.3597418069839478, 'rewards/rejected': -7.5159735679626465, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.156231880187988, 'logps/rejected': -116.193603515625, 'logps/chosen': -57.4583625793457, 'logits/rejected': -3.0744340419769287, 'logits/chosen': -3.0681185722351074, 'epoch': 0.36}
{'loss': 0.0977, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -1.7119560241699219, 'rewards/rejected': -8.327688217163086, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.615731716156006, 'logps/rejected': -126.4785385131836, 'logps/chosen': -63.68197250366211, 'logits/rejected': -3.0267412662506104, 'logits/chosen': -3.081425905227661, 'epoch': 0.36}
{'loss': 0.2437, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -1.886853575706482, 'rewards/rejected': -8.483091354370117, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.596237659454346, 'logps/rejected': -121.03882598876953, 'logps/chosen': -62.46954345703125, 'logits/rejected': -2.922471523284912, 'logits/chosen': -3.122377395629883, 'epoch': 0.37}
{'loss': 0.1781, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -2.4113166332244873, 'rewards/rejected': -8.696196556091309, 'rewards/accuracies': 0.875, 'rewards/margins': 6.284879684448242, 'logps/rejected': -129.0346221923828, 'logps/chosen': -70.07020568847656, 'logits/rejected': -2.9785006046295166, 'logits/chosen': -3.1400814056396484, 'epoch': 0.38}
{'loss': 0.1192, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -1.7665613889694214, 'rewards/rejected': -8.169933319091797, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.403371334075928, 'logps/rejected': -127.40106964111328, 'logps/chosen': -58.72515106201172, 'logits/rejected': -3.1536149978637695, 'logits/chosen': -3.0797407627105713, 'epoch': 0.38}
{'loss': 0.2225, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -2.4533779621124268, 'rewards/rejected': -7.818134784698486, 'rewards/accuracies': 0.96875, 'rewards/margins': 5.3647565841674805, 'logps/rejected': -113.41896057128906, 'logps/chosen': -65.80641174316406, 'logits/rejected': -3.053431510925293, 'logits/chosen': -3.1936020851135254, 'epoch': 0.39}
{'loss': 0.1072, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -1.1411913633346558, 'rewards/rejected': -9.041777610778809, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.900585651397705, 'logps/rejected': -129.0028076171875, 'logps/chosen': -49.65932846069336, 'logits/rejected': -2.9342942237854004, 'logits/chosen': -3.0512797832489014, 'epoch': 0.4}
{'loss': 0.1371, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -2.208130359649658, 'rewards/rejected': -9.799206733703613, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.591076374053955, 'logps/rejected': -144.07736206054688, 'logps/chosen': -61.14582061767578, 'logits/rejected': -3.098456621170044, 'logits/chosen': -2.9938199520111084, 'epoch': 0.4}
{'loss': 0.1673, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -3.111870765686035, 'rewards/rejected': -8.756965637207031, 'rewards/accuracies': 0.9375, 'rewards/margins': 5.645095348358154, 'logps/rejected': -129.94924926757812, 'logps/chosen': -72.41841888427734, 'logits/rejected': -3.0847384929656982, 'logits/chosen': -3.0159716606140137, 'epoch': 0.41}
{'loss': 0.1299, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -3.021920680999756, 'rewards/rejected': -9.141691207885742, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.119770526885986, 'logps/rejected': -132.11489868164062, 'logps/chosen': -75.3365478515625, 'logits/rejected': -3.036778450012207, 'logits/chosen': -3.149118423461914, 'epoch': 0.42}
{'loss': 0.1248, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -2.6628665924072266, 'rewards/rejected': -8.866843223571777, 'rewards/accuracies': 0.84375, 'rewards/margins': 6.203976631164551, 'logps/rejected': -132.73544311523438, 'logps/chosen': -65.85673522949219, 'logits/rejected': -3.07216739654541, 'logits/chosen': -3.107593536376953, 'epoch': 0.42}
{'loss': 0.138, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -2.4666342735290527, 'rewards/rejected': -10.790862083435059, 'rewards/accuracies': 1.0, 'rewards/margins': 8.324228286743164, 'logps/rejected': -154.29075622558594, 'logps/chosen': -66.09949493408203, 'logits/rejected': -3.0731873512268066, 'logits/chosen': -3.093885898590088, 'epoch': 0.43}
{'loss': 0.1311, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -1.8044966459274292, 'rewards/rejected': -10.211809158325195, 'rewards/accuracies': 0.875, 'rewards/margins': 8.407310485839844, 'logps/rejected': -141.7074432373047, 'logps/chosen': -54.72319030761719, 'logits/rejected': -3.077141046524048, 'logits/chosen': -3.018580436706543, 'epoch': 0.44}
{'loss': 0.151, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -2.8705337047576904, 'rewards/rejected': -11.529772758483887, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.659239768981934, 'logps/rejected': -155.65328979492188, 'logps/chosen': -71.49319458007812, 'logits/rejected': -3.0190072059631348, 'logits/chosen': -3.0679121017456055, 'epoch': 0.44}
{'loss': 0.2221, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -3.1101181507110596, 'rewards/rejected': -8.775187492370605, 'rewards/accuracies': 0.78125, 'rewards/margins': 5.665069580078125, 'logps/rejected': -132.72840881347656, 'logps/chosen': -79.35354614257812, 'logits/rejected': -2.9668195247650146, 'logits/chosen': -3.126950740814209, 'epoch': 0.45}
{'loss': 0.0986, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -2.237192153930664, 'rewards/rejected': -10.111528396606445, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.874335765838623, 'logps/rejected': -145.59938049316406, 'logps/chosen': -60.49775695800781, 'logits/rejected': -3.1159520149230957, 'logits/chosen': -2.977424144744873, 'epoch': 0.46}
{'loss': 0.1919, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -2.9689249992370605, 'rewards/rejected': -10.045564651489258, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.0766401290893555, 'logps/rejected': -142.32928466796875, 'logps/chosen': -65.29370880126953, 'logits/rejected': -3.1285483837127686, 'logits/chosen': -3.118990659713745, 'epoch': 0.46}
{'loss': 0.1296, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -1.2446231842041016, 'rewards/rejected': -8.45787239074707, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.213249206542969, 'logps/rejected': -124.24342346191406, 'logps/chosen': -49.80324935913086, 'logits/rejected': -3.081230401992798, 'logits/chosen': -3.144350290298462, 'epoch': 0.47}
{'loss': 0.1607, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -1.7405802011489868, 'rewards/rejected': -10.395922660827637, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.655342102050781, 'logps/rejected': -141.46566772460938, 'logps/chosen': -55.644996643066406, 'logits/rejected': -3.062180519104004, 'logits/chosen': -3.0907788276672363, 'epoch': 0.48}
{'loss': 0.1059, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -3.474733829498291, 'rewards/rejected': -9.321208000183105, 'rewards/accuracies': 0.875, 'rewards/margins': 5.846474647521973, 'logps/rejected': -135.69570922851562, 'logps/chosen': -76.0854721069336, 'logits/rejected': -3.0678274631500244, 'logits/chosen': -3.0933971405029297, 'epoch': 0.49}
{'loss': 0.2031, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -1.802319884300232, 'rewards/rejected': -8.580425262451172, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.77810525894165, 'logps/rejected': -126.16195678710938, 'logps/chosen': -60.849117279052734, 'logits/rejected': -3.039072036743164, 'logits/chosen': -3.1411898136138916, 'epoch': 0.49}
{'loss': 0.1241, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -1.9017181396484375, 'rewards/rejected': -9.428876876831055, 'rewards/accuracies': 1.0, 'rewards/margins': 7.527158737182617, 'logps/rejected': -132.02761840820312, 'logps/chosen': -61.23102569580078, 'logits/rejected': -2.973114252090454, 'logits/chosen': -3.112818717956543, 'epoch': 0.5}
{'loss': 0.1593, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -2.7415592670440674, 'rewards/rejected': -8.62464714050293, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.8830885887146, 'logps/rejected': -129.7935333251953, 'logps/chosen': -68.90689849853516, 'logits/rejected': -3.028203010559082, 'logits/chosen': -3.0481200218200684, 'epoch': 0.51}
{'loss': 0.0995, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -1.9908642768859863, 'rewards/rejected': -9.331070899963379, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.340207099914551, 'logps/rejected': -137.68861389160156, 'logps/chosen': -59.397911071777344, 'logits/rejected': -3.0316896438598633, 'logits/chosen': -3.034649610519409, 'epoch': 0.51}
{'loss': 0.2302, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -2.067648410797119, 'rewards/rejected': -7.589128494262695, 'rewards/accuracies': 0.875, 'rewards/margins': 5.521479606628418, 'logps/rejected': -117.92385864257812, 'logps/chosen': -63.59968566894531, 'logits/rejected': -3.004789352416992, 'logits/chosen': -3.061760187149048, 'epoch': 0.52}
{'loss': 0.121, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -1.511886477470398, 'rewards/rejected': -8.313268661499023, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.801382541656494, 'logps/rejected': -124.44664764404297, 'logps/chosen': -53.66961669921875, 'logits/rejected': -3.0936636924743652, 'logits/chosen': -3.073364019393921, 'epoch': 0.53}
{'loss': 0.1352, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -1.8366247415542603, 'rewards/rejected': -7.958867073059082, 'rewards/accuracies': 0.875, 'rewards/margins': 6.122241973876953, 'logps/rejected': -118.9154052734375, 'logps/chosen': -61.3985710144043, 'logits/rejected': -2.990445137023926, 'logits/chosen': -3.165147542953491, 'epoch': 0.53}
{'loss': 0.0806, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -0.8893353939056396, 'rewards/rejected': -9.571910858154297, 'rewards/accuracies': 1.0, 'rewards/margins': 8.682575225830078, 'logps/rejected': -136.1825408935547, 'logps/chosen': -48.83442687988281, 'logits/rejected': -3.0989410877227783, 'logits/chosen': -3.081758975982666, 'epoch': 0.54}
{'loss': 0.188, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -2.7312846183776855, 'rewards/rejected': -7.707837104797363, 'rewards/accuracies': 0.875, 'rewards/margins': 4.976552963256836, 'logps/rejected': -116.51071166992188, 'logps/chosen': -67.6893081665039, 'logits/rejected': -3.1703336238861084, 'logits/chosen': -3.093728542327881, 'epoch': 0.55}
{'loss': 0.1917, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -2.8876097202301025, 'rewards/rejected': -8.678987503051758, 'rewards/accuracies': 0.875, 'rewards/margins': 5.791377544403076, 'logps/rejected': -125.36650085449219, 'logps/chosen': -71.52889251708984, 'logits/rejected': -3.0217697620391846, 'logits/chosen': -3.159173011779785, 'epoch': 0.55}
{'loss': 0.2013, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -1.276709794998169, 'rewards/rejected': -9.067495346069336, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.79078483581543, 'logps/rejected': -129.5463104248047, 'logps/chosen': -54.78896713256836, 'logits/rejected': -3.042422294616699, 'logits/chosen': -3.159459114074707, 'epoch': 0.56}
{'loss': 0.1134, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -1.0448147058486938, 'rewards/rejected': -9.823572158813477, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.778757095336914, 'logps/rejected': -136.78207397460938, 'logps/chosen': -46.13005447387695, 'logits/rejected': -3.126697063446045, 'logits/chosen': -3.0834872722625732, 'epoch': 0.57}
{'loss': 0.1551, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -1.1988548040390015, 'rewards/rejected': -10.146492958068848, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.947638511657715, 'logps/rejected': -143.6223907470703, 'logps/chosen': -49.27122497558594, 'logits/rejected': -3.0529255867004395, 'logits/chosen': -3.058568239212036, 'epoch': 0.57}
{'loss': 0.11, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -1.8368480205535889, 'rewards/rejected': -9.245532035827637, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.408683776855469, 'logps/rejected': -137.3084259033203, 'logps/chosen': -56.38766860961914, 'logits/rejected': -3.1262621879577637, 'logits/chosen': -3.1065807342529297, 'epoch': 0.58}
{'loss': 0.1283, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -3.1230597496032715, 'rewards/rejected': -11.627744674682617, 'rewards/accuracies': 0.875, 'rewards/margins': 8.50468635559082, 'logps/rejected': -151.0125274658203, 'logps/chosen': -70.2256851196289, 'logits/rejected': -3.029538631439209, 'logits/chosen': -3.1523218154907227, 'epoch': 0.59}
{'loss': 0.1586, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -3.6459507942199707, 'rewards/rejected': -11.504722595214844, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.858772277832031, 'logps/rejected': -155.80133056640625, 'logps/chosen': -76.37703704833984, 'logits/rejected': -3.023681163787842, 'logits/chosen': -3.068453311920166, 'epoch': 0.59}
{'loss': 0.1682, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -1.8316774368286133, 'rewards/rejected': -10.936490058898926, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.104811668395996, 'logps/rejected': -154.19793701171875, 'logps/chosen': -57.24226760864258, 'logits/rejected': -3.163797378540039, 'logits/chosen': -2.9732253551483154, 'epoch': 0.6}
{'loss': 0.1023, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -1.9998621940612793, 'rewards/rejected': -10.340932846069336, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.341070175170898, 'logps/rejected': -150.37277221679688, 'logps/chosen': -61.0526008605957, 'logits/rejected': -3.1818106174468994, 'logits/chosen': -3.069010019302368, 'epoch': 0.61}
{'loss': 0.181, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -3.5499179363250732, 'rewards/rejected': -10.659210205078125, 'rewards/accuracies': 0.78125, 'rewards/margins': 7.109292030334473, 'logps/rejected': -148.8505859375, 'logps/chosen': -79.0789794921875, 'logits/rejected': -3.124586343765259, 'logits/chosen': -3.1695775985717773, 'epoch': 0.61}
{'loss': 0.1464, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -2.2836437225341797, 'rewards/rejected': -9.775047302246094, 'rewards/accuracies': 1.0, 'rewards/margins': 7.4914045333862305, 'logps/rejected': -140.31011962890625, 'logps/chosen': -61.736392974853516, 'logits/rejected': -3.0793285369873047, 'logits/chosen': -3.0584726333618164, 'epoch': 0.62}
{'loss': 0.1149, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -2.8839917182922363, 'rewards/rejected': -10.824216842651367, 'rewards/accuracies': 0.875, 'rewards/margins': 7.940225601196289, 'logps/rejected': -147.50753784179688, 'logps/chosen': -71.29702758789062, 'logits/rejected': -2.955902338027954, 'logits/chosen': -3.0779759883880615, 'epoch': 0.63}
{'loss': 0.2147, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -4.113187789916992, 'rewards/rejected': -11.704551696777344, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.591365814208984, 'logps/rejected': -155.46566772460938, 'logps/chosen': -87.96633911132812, 'logits/rejected': -2.9211325645446777, 'logits/chosen': -3.158149480819702, 'epoch': 0.63}
{'loss': 0.0863, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -2.213474750518799, 'rewards/rejected': -10.60047435760498, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.38700008392334, 'logps/rejected': -147.61732482910156, 'logps/chosen': -61.82289123535156, 'logits/rejected': -3.0809569358825684, 'logits/chosen': -3.084052801132202, 'epoch': 0.64}
{'loss': 0.1277, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -2.3273749351501465, 'rewards/rejected': -11.476578712463379, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.149203300476074, 'logps/rejected': -154.7967987060547, 'logps/chosen': -62.411216735839844, 'logits/rejected': -3.049123525619507, 'logits/chosen': -2.990670919418335, 'epoch': 0.65}
{'loss': 0.2436, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -2.3433666229248047, 'rewards/rejected': -11.175375938415527, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.832008361816406, 'logps/rejected': -152.9869842529297, 'logps/chosen': -65.03287506103516, 'logits/rejected': -2.9741833209991455, 'logits/chosen': -3.0210649967193604, 'epoch': 0.65}
{'loss': 0.1352, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -4.385460376739502, 'rewards/rejected': -10.8800048828125, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.494544982910156, 'logps/rejected': -153.94996643066406, 'logps/chosen': -91.08451843261719, 'logits/rejected': -2.953829288482666, 'logits/chosen': -3.118543863296509, 'epoch': 0.66}
{'loss': 0.1773, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -4.877040863037109, 'rewards/rejected': -13.024271965026855, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.147231101989746, 'logps/rejected': -170.3136749267578, 'logps/chosen': -88.55683135986328, 'logits/rejected': -2.979903221130371, 'logits/chosen': -3.1328935623168945, 'epoch': 0.67}
{'loss': 0.1463, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -2.2537057399749756, 'rewards/rejected': -10.688623428344727, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.434918403625488, 'logps/rejected': -145.5264434814453, 'logps/chosen': -64.08732604980469, 'logits/rejected': -2.9568777084350586, 'logits/chosen': -3.041736364364624, 'epoch': 0.67}
{'loss': 0.0927, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -4.363004684448242, 'rewards/rejected': -12.27086353302002, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.907857894897461, 'logps/rejected': -163.27064514160156, 'logps/chosen': -84.2669677734375, 'logits/rejected': -3.0119969844818115, 'logits/chosen': -3.1126039028167725, 'epoch': 0.68}
{'loss': 0.1091, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -2.93587327003479, 'rewards/rejected': -12.92598819732666, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.990114212036133, 'logps/rejected': -174.516357421875, 'logps/chosen': -70.79115295410156, 'logits/rejected': -3.0958876609802246, 'logits/chosen': -3.0655360221862793, 'epoch': 0.69}
{'loss': 0.1337, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -3.911350965499878, 'rewards/rejected': -12.550958633422852, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.639609336853027, 'logps/rejected': -166.15911865234375, 'logps/chosen': -78.95044708251953, 'logits/rejected': -2.9791758060455322, 'logits/chosen': -3.0166592597961426, 'epoch': 0.69}
{'loss': 0.1336, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -2.326674461364746, 'rewards/rejected': -10.231400489807129, 'rewards/accuracies': 1.0, 'rewards/margins': 7.904726028442383, 'logps/rejected': -141.69029235839844, 'logps/chosen': -61.787654876708984, 'logits/rejected': -3.0943331718444824, 'logits/chosen': -3.1207435131073, 'epoch': 0.7}
{'loss': 0.0842, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -3.786374568939209, 'rewards/rejected': -12.50483512878418, 'rewards/accuracies': 1.0, 'rewards/margins': 8.718461036682129, 'logps/rejected': -168.2212371826172, 'logps/chosen': -82.12931823730469, 'logits/rejected': -3.0454554557800293, 'logits/chosen': -3.1676013469696045, 'epoch': 0.71}
{'loss': 0.0977, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -2.680068254470825, 'rewards/rejected': -11.553705215454102, 'rewards/accuracies': 1.0, 'rewards/margins': 8.873636245727539, 'logps/rejected': -157.3218231201172, 'logps/chosen': -67.33854675292969, 'logits/rejected': -2.9965691566467285, 'logits/chosen': -3.0952892303466797, 'epoch': 0.71}
{'loss': 0.123, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -1.9799675941467285, 'rewards/rejected': -11.806787490844727, 'rewards/accuracies': 1.0, 'rewards/margins': 9.826820373535156, 'logps/rejected': -161.57582092285156, 'logps/chosen': -59.28156661987305, 'logits/rejected': -3.030465841293335, 'logits/chosen': -3.0718472003936768, 'epoch': 0.72}
{'loss': 0.1146, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -2.180405616760254, 'rewards/rejected': -11.25286865234375, 'rewards/accuracies': 1.0, 'rewards/margins': 9.072463035583496, 'logps/rejected': -152.96969604492188, 'logps/chosen': -60.0096549987793, 'logits/rejected': -2.9919962882995605, 'logits/chosen': -3.050150156021118, 'epoch': 0.73}
{'loss': 0.092, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -2.9742164611816406, 'rewards/rejected': -12.391626358032227, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.417410850524902, 'logps/rejected': -163.21939086914062, 'logps/chosen': -69.87357330322266, 'logits/rejected': -2.9290497303009033, 'logits/chosen': -3.1221795082092285, 'epoch': 0.73}
{'loss': 0.1383, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -2.6223762035369873, 'rewards/rejected': -12.297611236572266, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.6752347946167, 'logps/rejected': -165.2723846435547, 'logps/chosen': -66.86102294921875, 'logits/rejected': -3.0693068504333496, 'logits/chosen': -3.0199167728424072, 'epoch': 0.74}
{'loss': 0.0902, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -2.287754774093628, 'rewards/rejected': -11.329931259155273, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.042177200317383, 'logps/rejected': -152.67279052734375, 'logps/chosen': -58.25217819213867, 'logits/rejected': -3.0424094200134277, 'logits/chosen': -2.9532012939453125, 'epoch': 0.75}
{'loss': 0.1149, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -3.315873861312866, 'rewards/rejected': -12.108051300048828, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.792179107666016, 'logps/rejected': -166.8138885498047, 'logps/chosen': -71.31693267822266, 'logits/rejected': -3.1435623168945312, 'logits/chosen': -3.029881238937378, 'epoch': 0.75}
{'loss': 0.1103, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -3.0056543350219727, 'rewards/rejected': -11.898673057556152, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.89301872253418, 'logps/rejected': -161.11871337890625, 'logps/chosen': -77.54582977294922, 'logits/rejected': -3.0011117458343506, 'logits/chosen': -3.110787868499756, 'epoch': 0.76}
{'loss': 0.0891, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -3.3506886959075928, 'rewards/rejected': -11.65988540649414, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.309196472167969, 'logps/rejected': -154.74874877929688, 'logps/chosen': -68.48165893554688, 'logits/rejected': -3.0320754051208496, 'logits/chosen': -3.0307724475860596, 'epoch': 0.77}
{'loss': 0.1349, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -2.667412042617798, 'rewards/rejected': -11.233551979064941, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.566140174865723, 'logps/rejected': -151.1546630859375, 'logps/chosen': -67.46121215820312, 'logits/rejected': -3.1032168865203857, 'logits/chosen': -3.102529287338257, 'epoch': 0.77}
{'loss': 0.0687, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -1.9594099521636963, 'rewards/rejected': -11.038100242614746, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.078690528869629, 'logps/rejected': -151.62088012695312, 'logps/chosen': -59.30942153930664, 'logits/rejected': -3.037919044494629, 'logits/chosen': -3.0639777183532715, 'epoch': 0.78}
{'loss': 0.1036, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -2.6554648876190186, 'rewards/rejected': -13.670527458190918, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.015064239501953, 'logps/rejected': -175.2296600341797, 'logps/chosen': -61.325138092041016, 'logits/rejected': -3.0415215492248535, 'logits/chosen': -2.9574151039123535, 'epoch': 0.79}
{'loss': 0.1213, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -2.788618803024292, 'rewards/rejected': -13.257375717163086, 'rewards/accuracies': 0.875, 'rewards/margins': 10.468757629394531, 'logps/rejected': -175.5743408203125, 'logps/chosen': -66.6806640625, 'logits/rejected': -3.0702953338623047, 'logits/chosen': -3.0563228130340576, 'epoch': 0.79}
{'loss': 0.0475, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -2.6381165981292725, 'rewards/rejected': -12.945093154907227, 'rewards/accuracies': 1.0, 'rewards/margins': 10.306976318359375, 'logps/rejected': -169.9666290283203, 'logps/chosen': -63.74066162109375, 'logits/rejected': -3.133578300476074, 'logits/chosen': -3.1532607078552246, 'epoch': 0.8}
{'loss': 0.1564, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -2.7404448986053467, 'rewards/rejected': -11.419092178344727, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.678646087646484, 'logps/rejected': -152.72816467285156, 'logps/chosen': -64.8798828125, 'logits/rejected': -3.0514397621154785, 'logits/chosen': -3.0951879024505615, 'epoch': 0.81}
{'loss': 0.1308, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -2.5256168842315674, 'rewards/rejected': -13.53024673461914, 'rewards/accuracies': 1.0, 'rewards/margins': 11.004630088806152, 'logps/rejected': -182.20556640625, 'logps/chosen': -65.4215087890625, 'logits/rejected': -3.0471270084381104, 'logits/chosen': -2.968585968017578, 'epoch': 0.82}
{'loss': 0.1306, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -3.6138381958007812, 'rewards/rejected': -11.12076187133789, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.506923675537109, 'logps/rejected': -150.47938537597656, 'logps/chosen': -77.517333984375, 'logits/rejected': -3.0652904510498047, 'logits/chosen': -3.1082918643951416, 'epoch': 0.82}
{'loss': 0.0783, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -2.7053089141845703, 'rewards/rejected': -12.543097496032715, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.837788581848145, 'logps/rejected': -171.18687438964844, 'logps/chosen': -67.4461898803711, 'logits/rejected': -3.140982151031494, 'logits/chosen': -3.13687801361084, 'epoch': 0.83}
{'loss': 0.0865, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -4.620224952697754, 'rewards/rejected': -12.480161666870117, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.8599371910095215, 'logps/rejected': -166.53562927246094, 'logps/chosen': -86.09716033935547, 'logits/rejected': -2.9988396167755127, 'logits/chosen': -3.0665013790130615, 'epoch': 0.84}
{'loss': 0.0967, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -3.1087117195129395, 'rewards/rejected': -14.241691589355469, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.132980346679688, 'logps/rejected': -184.0986328125, 'logps/chosen': -68.50550079345703, 'logits/rejected': -3.110275983810425, 'logits/chosen': -3.0168020725250244, 'epoch': 0.84}
{'loss': 0.0982, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -2.4284210205078125, 'rewards/rejected': -12.396452903747559, 'rewards/accuracies': 1.0, 'rewards/margins': 9.968031883239746, 'logps/rejected': -162.28372192382812, 'logps/chosen': -64.62068939208984, 'logits/rejected': -3.036220073699951, 'logits/chosen': -3.1263012886047363, 'epoch': 0.85}
{'loss': 0.12, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -3.150087594985962, 'rewards/rejected': -12.143559455871582, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.9934720993042, 'logps/rejected': -162.5325469970703, 'logps/chosen': -70.27572631835938, 'logits/rejected': -3.0399513244628906, 'logits/chosen': -3.0096640586853027, 'epoch': 0.86}
{'loss': 0.1377, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -3.531926393508911, 'rewards/rejected': -12.629799842834473, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.09787368774414, 'logps/rejected': -167.46542358398438, 'logps/chosen': -71.40521240234375, 'logits/rejected': -3.1225898265838623, 'logits/chosen': -3.023711681365967, 'epoch': 0.86}
{'loss': 0.0953, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -3.167325019836426, 'rewards/rejected': -10.429425239562988, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.2621002197265625, 'logps/rejected': -143.1399688720703, 'logps/chosen': -70.36407470703125, 'logits/rejected': -3.070361375808716, 'logits/chosen': -3.145329236984253, 'epoch': 0.87}
{'loss': 0.2072, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -3.673790454864502, 'rewards/rejected': -12.575748443603516, 'rewards/accuracies': 0.84375, 'rewards/margins': 8.901958465576172, 'logps/rejected': -173.34716796875, 'logps/chosen': -73.28482818603516, 'logits/rejected': -3.095001220703125, 'logits/chosen': -2.9698147773742676, 'epoch': 0.88}
{'loss': 0.059, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -2.24513578414917, 'rewards/rejected': -11.795656204223633, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.550520896911621, 'logps/rejected': -156.76243591308594, 'logps/chosen': -61.312355041503906, 'logits/rejected': -3.0709378719329834, 'logits/chosen': -3.071701765060425, 'epoch': 0.88}
{'loss': 0.0857, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -2.0954065322875977, 'rewards/rejected': -11.355860710144043, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.260454177856445, 'logps/rejected': -149.20262145996094, 'logps/chosen': -56.848609924316406, 'logits/rejected': -3.0161561965942383, 'logits/chosen': -3.026674270629883, 'epoch': 0.89}
{'loss': 0.0755, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -3.0776336193084717, 'rewards/rejected': -12.651982307434082, 'rewards/accuracies': 1.0, 'rewards/margins': 9.574349403381348, 'logps/rejected': -161.96800231933594, 'logps/chosen': -70.9872055053711, 'logits/rejected': -2.9945526123046875, 'logits/chosen': -3.155709743499756, 'epoch': 0.9}
{'loss': 0.1319, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -4.1938910484313965, 'rewards/rejected': -10.733717918395996, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.539826393127441, 'logps/rejected': -145.3250274658203, 'logps/chosen': -88.97196960449219, 'logits/rejected': -2.889596700668335, 'logits/chosen': -3.126201868057251, 'epoch': 0.9}
{'loss': 0.0593, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -1.8828308582305908, 'rewards/rejected': -12.80630874633789, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.923477172851562, 'logps/rejected': -169.63450622558594, 'logps/chosen': -57.19458770751953, 'logits/rejected': -3.0455126762390137, 'logits/chosen': -3.0742130279541016, 'epoch': 0.91}
{'loss': 0.1446, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -3.5964033603668213, 'rewards/rejected': -11.123937606811523, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.527534484863281, 'logps/rejected': -152.55059814453125, 'logps/chosen': -75.4882583618164, 'logits/rejected': -3.0252420902252197, 'logits/chosen': -3.0313985347747803, 'epoch': 0.92}
{'loss': 0.1059, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -4.0315093994140625, 'rewards/rejected': -15.60072135925293, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.56921100616455, 'logps/rejected': -197.21701049804688, 'logps/chosen': -73.81598663330078, 'logits/rejected': -3.1389505863189697, 'logits/chosen': -3.0098016262054443, 'epoch': 0.92}
{'loss': 0.0742, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -3.0507917404174805, 'rewards/rejected': -13.0529146194458, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.00212287902832, 'logps/rejected': -174.09510803222656, 'logps/chosen': -70.55268096923828, 'logits/rejected': -3.0337207317352295, 'logits/chosen': -2.9683139324188232, 'epoch': 0.93}
{'loss': 0.1116, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -3.4527676105499268, 'rewards/rejected': -11.070683479309082, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.617916107177734, 'logps/rejected': -152.72103881835938, 'logps/chosen': -75.63743591308594, 'logits/rejected': -3.057002544403076, 'logits/chosen': -3.0900354385375977, 'epoch': 0.94}
{'loss': 0.1772, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -1.350622296333313, 'rewards/rejected': -10.190103530883789, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.839482307434082, 'logps/rejected': -141.81849670410156, 'logps/chosen': -52.58301544189453, 'logits/rejected': -2.9813575744628906, 'logits/chosen': -3.0151419639587402, 'epoch': 0.94}
{'loss': 0.0945, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -3.088207960128784, 'rewards/rejected': -10.651869773864746, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.563661098480225, 'logps/rejected': -149.17446899414062, 'logps/chosen': -69.60964965820312, 'logits/rejected': -3.105419397354126, 'logits/chosen': -2.9938015937805176, 'epoch': 0.95}
{'loss': 0.1259, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -3.869227170944214, 'rewards/rejected': -13.833146095275879, 'rewards/accuracies': 0.875, 'rewards/margins': 9.963918685913086, 'logps/rejected': -181.456787109375, 'logps/chosen': -79.9957504272461, 'logits/rejected': -2.978832721710205, 'logits/chosen': -3.05769944190979, 'epoch': 0.96}
{'loss': 0.0579, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -3.55587100982666, 'rewards/rejected': -12.708080291748047, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.152209281921387, 'logps/rejected': -166.01905822753906, 'logps/chosen': -77.68749237060547, 'logits/rejected': -2.9524428844451904, 'logits/chosen': -3.1019809246063232, 'epoch': 0.96}
{'loss': 0.0849, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -2.864588737487793, 'rewards/rejected': -11.072813034057617, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.208224296569824, 'logps/rejected': -154.25018310546875, 'logps/chosen': -65.36320495605469, 'logits/rejected': -3.0954091548919678, 'logits/chosen': -3.0023128986358643, 'epoch': 0.97}
{'loss': 0.0695, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -3.4848413467407227, 'rewards/rejected': -12.216361045837402, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.73151969909668, 'logps/rejected': -161.5084991455078, 'logps/chosen': -74.32112121582031, 'logits/rejected': -2.971526622772217, 'logits/chosen': -3.1138100624084473, 'epoch': 0.98}
{'loss': 0.1025, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -3.7185449600219727, 'rewards/rejected': -13.893174171447754, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.174628257751465, 'logps/rejected': -182.91749572753906, 'logps/chosen': -78.48804473876953, 'logits/rejected': -3.0950183868408203, 'logits/chosen': -3.040440082550049, 'epoch': 0.98}
{'loss': 0.0837, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -3.1051406860351562, 'rewards/rejected': -12.798702239990234, 'rewards/accuracies': 0.875, 'rewards/margins': 9.693561553955078, 'logps/rejected': -169.8185272216797, 'logps/chosen': -72.17635345458984, 'logits/rejected': -2.9856340885162354, 'logits/chosen': -3.0896096229553223, 'epoch': 0.99}
{'loss': 0.0532, 'learning_rate': 0.0, 'rewards/chosen': -3.997609853744507, 'rewards/rejected': -14.335875511169434, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.338265419006348, 'logps/rejected': -189.43304443359375, 'logps/chosen': -81.34056091308594, 'logits/rejected': -3.1238467693328857, 'logits/chosen': -3.095653533935547, 'epoch': 1.0}
{'eval_loss': 0.12209485471248627, 'eval_runtime': 43.2131, 'eval_samples_per_second': 23.141, 'eval_steps_per_second': 5.785, 'eval_rewards/chosen': -3.0661442279815674, 'eval_rewards/rejected': -11.96472454071045, 'eval_rewards/accuracies': 0.9359999895095825, 'eval_rewards/margins': 8.898580551147461, 'eval_logps/rejected': -161.14149475097656, 'eval_logps/chosen': -71.26802062988281, 'eval_logits/rejected': -3.045177459716797, 'eval_logits/chosen': -3.0788025856018066, 'epoch': 1.0}
{'train_runtime': 2013.6767, 'train_samples_per_second': 9.435, 'train_steps_per_second': 0.073, 'train_loss': 0.2015266539780675, 'epoch': 1.0}
