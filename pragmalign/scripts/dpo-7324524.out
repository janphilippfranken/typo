[2024-03-03 19:01:56,876] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-03 19:01:56,898] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-03 19:01:57,042] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-03 19:01:57,144] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-03 19:02:18,773] [INFO] [comm.py:637:init_distributed] cdb=None
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-03 19:02:18,806] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-03 19:02:18,806] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-03 19:02:19,055][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7ff3f81fd8a0>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-03 19:02:19,173] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-03 19:02:19,221][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f4c5d67d600>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
DatasetDict({
    train: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 19000
    })
    test: Dataset({
        features: ['prompt', 'chosen', 'rejected'],
        num_rows: 1000
    })
})
[2024-03-03 19:02:19,305] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-03 19:02:19,687][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7efe4ec79600>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-03 19:02:19,849][datasets.fingerprint][WARNING] - Parameter 'function'=<bound method DPOTrainer.tokenize_row of <trl.trainer.dpo_trainer.DPOTrainer object at 0x7f641d5f5960>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.
[2024-03-03 19:02:48,976][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-03 19:02:48,980] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed info: version=0.12.6, git-hash=unknown, git-branch=unknown
[2024-03-03 19:03:03,681] [INFO] [logging.py:96:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False
[2024-03-03 19:03:03,684] [INFO] [logging.py:96:log_dist] [Rank 0] Creating BF16 optimizer
[2024-03-03 19:03:04,012] [INFO] [utils.py:791:see_memory_usage] begin bf16_optimizer
[2024-03-03 19:03:04,013] [INFO] [utils.py:792:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-03 19:03:04,013] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 88.79 GB, percent = 8.8%
[2024-03-03 19:03:04,187] [INFO] [utils.py:791:see_memory_usage] end bf16_optimizer
[2024-03-03 19:03:04,187] [INFO] [utils.py:792:see_memory_usage] MA 13.99 GB         Max_MA 13.99 GB         CA 14.24 GB         Max_CA 14 GB 
[2024-03-03 19:03:04,188] [INFO] [utils.py:799:see_memory_usage] CPU Virtual Memory:  used = 86.88 GB, percent = 8.6%
[2024-03-03 19:03:04,188] [INFO] [config.py:984:print] DeepSpeedEngine configuration:
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   activation_checkpointing_config  {
    "partition_activations": false, 
    "contiguous_memory_optimization": false, 
    "cpu_checkpointing": false, 
    "number_checkpoints": null, 
    "synchronize_checkpoint_boundary": false, 
    "profile": false
}
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   amp_enabled .................. False
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   amp_params ................... False
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   autotuning_config ............ {
    "enabled": false, 
    "start_step": null, 
    "end_step": null, 
    "metric_path": null, 
    "arg_mappings": null, 
    "metric": "throughput", 
    "model_info": null, 
    "results_dir": "autotuning_results", 
    "exps_dir": "autotuning_exps", 
    "overwrite": true, 
    "fast": true, 
    "start_profile_step": 3, 
    "end_profile_step": 5, 
    "tuner_type": "gridsearch", 
    "tuner_early_stopping": 5, 
    "tuner_num_trials": 50, 
    "model_info_path": null, 
    "mp_size": 1, 
    "max_train_batch_size": null, 
    "min_train_batch_size": 1, 
    "max_train_micro_batch_size_per_gpu": 1.024000e+03, 
    "min_train_micro_batch_size_per_gpu": 1, 
    "num_tuning_micro_batch_sizes": 3
}
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   bfloat16_enabled ............. True
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   checkpoint_parallel_write_pipeline  False
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   checkpoint_tag_validation_enabled  True
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   checkpoint_tag_validation_fail  False
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7ff3f81335b0>
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   communication_data_type ...... None
[2024-03-03 19:03:04,189] [INFO] [config.py:988:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   curriculum_enabled_legacy .... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   curriculum_params_legacy ..... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   data_efficiency_enabled ...... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   dataloader_drop_last ......... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   disable_allgather ............ False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   dump_state ................... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   dynamic_loss_scale_args ...... None
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_enabled ........... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_gas_boundary_resolution  1
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_layer_name ........ bert.encoder.layer
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_layer_num ......... 0
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_max_iter .......... 100
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_stability ......... 1e-06
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_tol ............... 0.01
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   eigenvalue_verbose ........... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   elasticity_enabled ........... False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   flops_profiler_config ........ {
    "enabled": false, 
    "recompute_fwd_factor": 0.0, 
    "profile_step": 1, 
    "module_depth": -1, 
    "top_modules": 1, 
    "detailed": true, 
    "output_file": null
}
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   fp16_auto_cast ............... None
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   fp16_enabled ................. False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   fp16_master_weights_and_gradients  False
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   global_rank .................. 0
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   grad_accum_dtype ............. None
[2024-03-03 19:03:04,190] [INFO] [config.py:988:print]   gradient_accumulation_steps .. 32
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   gradient_clipping ............ 1.0
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   gradient_predivide_factor .... 1.0
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   graph_harvesting ............. False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   hybrid_engine ................ enabled=False max_out_tokens=512 inference_tp_size=1 release_inference_cache=False pin_parameters=True tp_gather_partition_size=8
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   initial_dynamic_scale ........ 1
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   load_universal_checkpoint .... False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   loss_scale ................... 1.0
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   memory_breakdown ............. False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   mics_hierarchial_params_gather  False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   mics_shard_size .............. -1
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   nebula_config ................ {
    "enabled": false, 
    "persistent_storage_path": null, 
    "persistent_time_interval": 100, 
    "num_of_version_in_retention": 2, 
    "enable_nebula_load": true, 
    "load_path": null
}
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   optimizer_legacy_fusion ...... False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   optimizer_name ............... None
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   optimizer_params ............. None
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0, 'pipe_partitioned': True, 'grad_partitioned': True}
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   pld_enabled .................. False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   pld_params ................... False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   prescale_gradients ........... False
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   scheduler_name ............... None
[2024-03-03 19:03:04,191] [INFO] [config.py:988:print]   scheduler_params ............. None
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   seq_parallel_communication_data_type  torch.float32
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   sparse_attention ............. None
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   sparse_gradients_enabled ..... False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   steps_per_print .............. inf
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   train_batch_size ............. 128
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   train_micro_batch_size_per_gpu  1
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   use_data_before_expert_parallel_  False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   use_node_local_storage ....... False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   wall_clock_breakdown ......... False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   weight_quantization_config ... None
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   world_size ................... 4
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   zero_allow_untested_optimizer  False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   zero_config .................. stage=0 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 use_multi_rank_bucket_allreduce=True allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='none', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='none', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False, ratio=1.0) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False zero_hpz_partition_size=1 zero_quantized_weights=False zero_quantized_nontrainable_weights=False zero_quantized_gradients=False mics_shard_size=-1 mics_hierarchical_params_gather=False memory_efficient_linear=True pipeline_loading_checkpoint=False override_module_apply=True
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   zero_enabled ................. False
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   zero_force_ds_cpu_optimizer .. True
[2024-03-03 19:03:04,192] [INFO] [config.py:988:print]   zero_optimization_stage ...... 0
[2024-03-03 19:03:04,192] [INFO] [config.py:974:print_user_config]   json = {
    "train_batch_size": 128, 
    "train_micro_batch_size_per_gpu": 1, 
    "gradient_accumulation_steps": 32, 
    "zero_optimization": {
        "stage": 0, 
        "offload_optimizer": {
            "device": "none", 
            "nvme_path": null
        }, 
        "offload_param": {
            "device": "none", 
            "nvme_path": null
        }, 
        "stage3_gather_16bit_weights_on_model_save": false
    }, 
    "gradient_clipping": 1.0, 
    "steps_per_print": inf, 
    "bf16": {
        "enabled": true
    }, 
    "fp16": {
        "enabled": false
    }
}
{'loss': 0.6931, 'learning_rate': 6.666666666666667e-08, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -43.364376068115234, 'logps/chosen': -35.84196090698242, 'logits/rejected': -3.021986722946167, 'logits/chosen': -2.9992244243621826, 'epoch': 0.01}
{'loss': 0.6931, 'learning_rate': 1.3333333333333334e-07, 'rewards/chosen': 0.0, 'rewards/rejected': 0.0, 'rewards/accuracies': 0.0, 'rewards/margins': 0.0, 'logps/rejected': -37.78664779663086, 'logps/chosen': -40.38960647583008, 'logits/rejected': -2.9857749938964844, 'logits/chosen': -3.051684856414795, 'epoch': 0.01}
{'loss': 0.6934, 'learning_rate': 2e-07, 'rewards/chosen': -0.002145957900211215, 'rewards/rejected': -0.003591126063838601, 'rewards/accuracies': 0.40625, 'rewards/margins': 0.0014451680472120643, 'logps/rejected': -46.8587760925293, 'logps/chosen': -45.00368118286133, 'logits/rejected': -3.1127803325653076, 'logits/chosen': -3.0863888263702393, 'epoch': 0.02}
{'loss': 0.6907, 'learning_rate': 2.6666666666666667e-07, 'rewards/chosen': 0.0017767671961337328, 'rewards/rejected': -0.004641675855964422, 'rewards/accuracies': 0.5, 'rewards/margins': 0.006418442353606224, 'logps/rejected': -43.276702880859375, 'logps/chosen': -39.106224060058594, 'logits/rejected': -3.0276637077331543, 'logits/chosen': -3.0646262168884277, 'epoch': 0.03}
{'loss': 0.6888, 'learning_rate': 3.333333333333333e-07, 'rewards/chosen': 0.007071566767990589, 'rewards/rejected': -0.0032084942795336246, 'rewards/accuracies': 0.625, 'rewards/margins': 0.010280061513185501, 'logps/rejected': -39.75736618041992, 'logps/chosen': -39.13227462768555, 'logits/rejected': -2.971609592437744, 'logits/chosen': -3.0531396865844727, 'epoch': 0.03}
{'loss': 0.6763, 'learning_rate': 4e-07, 'rewards/chosen': 0.017039364203810692, 'rewards/rejected': -0.015181289985775948, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.03222065418958664, 'logps/rejected': -40.728431701660156, 'logps/chosen': -35.90056610107422, 'logits/rejected': -3.034507989883423, 'logits/chosen': -3.0506772994995117, 'epoch': 0.04}
{'loss': 0.6643, 'learning_rate': 4.6666666666666666e-07, 'rewards/chosen': 0.01779814250767231, 'rewards/rejected': -0.03767392039299011, 'rewards/accuracies': 0.71875, 'rewards/margins': 0.05547206476330757, 'logps/rejected': -47.181697845458984, 'logps/chosen': -38.26091384887695, 'logits/rejected': -3.0042474269866943, 'logits/chosen': -3.044262409210205, 'epoch': 0.05}
{'loss': 0.6367, 'learning_rate': 5.333333333333333e-07, 'rewards/chosen': 0.0626230239868164, 'rewards/rejected': -0.1177017092704773, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.1803247332572937, 'logps/rejected': -38.37700653076172, 'logps/chosen': -37.75855255126953, 'logits/rejected': -2.9978690147399902, 'logits/chosen': -3.044407606124878, 'epoch': 0.05}
{'loss': 0.6135, 'learning_rate': 6e-07, 'rewards/chosen': 0.13869917392730713, 'rewards/rejected': -0.06557277590036392, 'rewards/accuracies': 0.8125, 'rewards/margins': 0.20427197217941284, 'logps/rejected': -40.71433639526367, 'logps/chosen': -35.03614044189453, 'logits/rejected': -2.980480670928955, 'logits/chosen': -3.0280141830444336, 'epoch': 0.06}
{'loss': 0.5704, 'learning_rate': 6.666666666666666e-07, 'rewards/chosen': -0.08170737326145172, 'rewards/rejected': -0.29130202531814575, 'rewards/accuracies': 0.625, 'rewards/margins': 0.20959463715553284, 'logps/rejected': -45.081668853759766, 'logps/chosen': -44.489376068115234, 'logits/rejected': -3.006701946258545, 'logits/chosen': -3.0142829418182373, 'epoch': 0.07}
{'loss': 0.5582, 'learning_rate': 7.333333333333332e-07, 'rewards/chosen': 0.05757312849164009, 'rewards/rejected': -0.40528035163879395, 'rewards/accuracies': 0.78125, 'rewards/margins': 0.46285346150398254, 'logps/rejected': -44.141014099121094, 'logps/chosen': -39.708744049072266, 'logits/rejected': -2.9586031436920166, 'logits/chosen': -3.0744452476501465, 'epoch': 0.07}
{'loss': 0.4696, 'learning_rate': 8e-07, 'rewards/chosen': 0.07203547656536102, 'rewards/rejected': -0.5848683714866638, 'rewards/accuracies': 0.875, 'rewards/margins': 0.656903862953186, 'logps/rejected': -46.89274978637695, 'logps/chosen': -35.32304382324219, 'logits/rejected': -3.045271158218384, 'logits/chosen': -3.0535686016082764, 'epoch': 0.08}
{'loss': 0.3897, 'learning_rate': 8.666666666666667e-07, 'rewards/chosen': 0.1610945761203766, 'rewards/rejected': -0.5825513005256653, 'rewards/accuracies': 0.90625, 'rewards/margins': 0.7436459064483643, 'logps/rejected': -47.28557205200195, 'logps/chosen': -38.691490173339844, 'logits/rejected': -3.0704245567321777, 'logits/chosen': -3.082169771194458, 'epoch': 0.09}
{'loss': 0.3278, 'learning_rate': 9.333333333333333e-07, 'rewards/chosen': -0.04845263063907623, 'rewards/rejected': -1.4641457796096802, 'rewards/accuracies': 0.78125, 'rewards/margins': 1.4156932830810547, 'logps/rejected': -55.558380126953125, 'logps/chosen': -37.70604705810547, 'logits/rejected': -3.1023316383361816, 'logits/chosen': -3.11356520652771, 'epoch': 0.09}
{'loss': 0.2788, 'learning_rate': 1e-06, 'rewards/chosen': 0.12952174246311188, 'rewards/rejected': -2.10311222076416, 'rewards/accuracies': 0.96875, 'rewards/margins': 2.2326338291168213, 'logps/rejected': -59.50572204589844, 'logps/chosen': -39.152530670166016, 'logits/rejected': -3.128593683242798, 'logits/chosen': -3.145538330078125, 'epoch': 0.1}
{'loss': 0.2278, 'learning_rate': 9.998605186060136e-07, 'rewards/chosen': -0.11435692012310028, 'rewards/rejected': -2.7252256870269775, 'rewards/accuracies': 0.9375, 'rewards/margins': 2.610868453979492, 'logps/rejected': -64.62845611572266, 'logps/chosen': -40.08596420288086, 'logits/rejected': -3.0519204139709473, 'logits/chosen': -3.16681170463562, 'epoch': 0.11}
{'loss': 0.2288, 'learning_rate': 9.994421522442919e-07, 'rewards/chosen': -0.25801342725753784, 'rewards/rejected': -3.400310754776001, 'rewards/accuracies': 0.90625, 'rewards/margins': 3.1422972679138184, 'logps/rejected': -76.04597473144531, 'logps/chosen': -42.123130798339844, 'logits/rejected': -3.2440130710601807, 'logits/chosen': -3.2210946083068848, 'epoch': 0.11}
{'loss': 0.1516, 'learning_rate': 9.987451343321279e-07, 'rewards/chosen': -0.812008798122406, 'rewards/rejected': -4.412943363189697, 'rewards/accuracies': 0.9375, 'rewards/margins': 3.6009345054626465, 'logps/rejected': -85.43253326416016, 'logps/chosen': -45.762508392333984, 'logits/rejected': -3.2016448974609375, 'logits/chosen': -3.19588303565979, 'epoch': 0.12}
{'loss': 0.2112, 'learning_rate': 9.977698537536417e-07, 'rewards/chosen': -0.4263424277305603, 'rewards/rejected': -4.067212104797363, 'rewards/accuracies': 0.84375, 'rewards/margins': 3.640869617462158, 'logps/rejected': -81.74015045166016, 'logps/chosen': -42.43463134765625, 'logits/rejected': -3.245427370071411, 'logits/chosen': -3.286968231201172, 'epoch': 0.13}
{'loss': 0.2309, 'learning_rate': 9.96516854642812e-07, 'rewards/chosen': -1.3367645740509033, 'rewards/rejected': -5.360393524169922, 'rewards/accuracies': 0.78125, 'rewards/margins': 4.0236287117004395, 'logps/rejected': -94.8629379272461, 'logps/chosen': -55.03169250488281, 'logits/rejected': -3.208653688430786, 'logits/chosen': -3.2859902381896973, 'epoch': 0.13}
{'loss': 0.1678, 'learning_rate': 9.949868360798893e-07, 'rewards/chosen': -0.19047856330871582, 'rewards/rejected': -6.597981929779053, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.407503128051758, 'logps/rejected': -105.95629119873047, 'logps/chosen': -41.27186584472656, 'logits/rejected': -3.1733620166778564, 'logits/chosen': -3.294492483139038, 'epoch': 0.14}
{'loss': 0.1761, 'learning_rate': 9.931806517013612e-07, 'rewards/chosen': -0.8940379023551941, 'rewards/rejected': -5.506145477294922, 'rewards/accuracies': 0.96875, 'rewards/margins': 4.612107276916504, 'logps/rejected': -90.88201141357422, 'logps/chosen': -47.40016555786133, 'logits/rejected': -3.2656147480010986, 'logits/chosen': -3.295037269592285, 'epoch': 0.15}
{'loss': 0.1687, 'learning_rate': 9.910993092236877e-07, 'rewards/chosen': -0.3946346938610077, 'rewards/rejected': -4.8075995445251465, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.412964820861816, 'logps/rejected': -82.95195007324219, 'logps/chosen': -42.5412712097168, 'logits/rejected': -3.1906678676605225, 'logits/chosen': -3.3150248527526855, 'epoch': 0.15}
{'loss': 0.1476, 'learning_rate': 9.887439698810692e-07, 'rewards/chosen': -0.28152912855148315, 'rewards/rejected': -5.186588287353516, 'rewards/accuracies': 0.8125, 'rewards/margins': 4.905058860778809, 'logps/rejected': -87.97857666015625, 'logps/chosen': -42.61334991455078, 'logits/rejected': -3.2718665599823, 'logits/chosen': -3.3274788856506348, 'epoch': 0.16}
{'loss': 0.147, 'learning_rate': 9.861159477775651e-07, 'rewards/chosen': -0.15836511552333832, 'rewards/rejected': -6.194777011871338, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.036412715911865, 'logps/rejected': -106.5009994506836, 'logps/chosen': -37.34030532836914, 'logits/rejected': -3.271853446960449, 'logits/chosen': -3.217343330383301, 'epoch': 0.17}
{'loss': 0.1533, 'learning_rate': 9.832167091539213e-07, 'rewards/chosen': -0.9837725162506104, 'rewards/rejected': -6.2365851402282715, 'rewards/accuracies': 0.875, 'rewards/margins': 5.25281286239624, 'logps/rejected': -96.24060821533203, 'logps/chosen': -46.39812088012695, 'logits/rejected': -3.2232139110565186, 'logits/chosen': -3.2924156188964844, 'epoch': 0.18}
{'loss': 0.2724, 'learning_rate': 9.800478715695162e-07, 'rewards/chosen': -1.2001327276229858, 'rewards/rejected': -6.035992622375488, 'rewards/accuracies': 0.84375, 'rewards/margins': 4.835860252380371, 'logps/rejected': -94.38502502441406, 'logps/chosen': -49.13156509399414, 'logits/rejected': -3.179443836212158, 'logits/chosen': -3.2766013145446777, 'epoch': 0.18}
{'loss': 0.1904, 'learning_rate': 9.766112029998846e-07, 'rewards/chosen': -0.8350285291671753, 'rewards/rejected': -6.107994079589844, 'rewards/accuracies': 0.875, 'rewards/margins': 5.272965431213379, 'logps/rejected': -103.63502502441406, 'logps/chosen': -45.219871520996094, 'logits/rejected': -3.3148956298828125, 'logits/chosen': -3.296999216079712, 'epoch': 0.19}
{'loss': 0.1523, 'learning_rate': 9.729086208503173e-07, 'rewards/chosen': -1.3429754972457886, 'rewards/rejected': -7.778604507446289, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.435628890991211, 'logps/rejected': -122.17230987548828, 'logps/chosen': -51.866783142089844, 'logits/rejected': -3.2969069480895996, 'logits/chosen': -3.295071601867676, 'epoch': 0.2}
{'loss': 0.1635, 'learning_rate': 9.689421908860927e-07, 'rewards/chosen': -1.4732836484909058, 'rewards/rejected': -6.880239009857178, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.406955242156982, 'logps/rejected': -106.60791778564453, 'logps/chosen': -52.486568450927734, 'logits/rejected': -3.310802936553955, 'logits/chosen': -3.301348924636841, 'epoch': 0.2}
{'loss': 0.2143, 'learning_rate': 9.647141260799329e-07, 'rewards/chosen': -1.4278459548950195, 'rewards/rejected': -6.646515846252441, 'rewards/accuracies': 0.875, 'rewards/margins': 5.21867036819458, 'logps/rejected': -103.28668212890625, 'logps/chosen': -53.807518005371094, 'logits/rejected': -3.3096718788146973, 'logits/chosen': -3.325989246368408, 'epoch': 0.21}
{'loss': 0.1671, 'learning_rate': 9.6022678537733e-07, 'rewards/chosen': -0.6517227292060852, 'rewards/rejected': -6.504087448120117, 'rewards/accuracies': 0.875, 'rewards/margins': 5.852365016937256, 'logps/rejected': -105.42218017578125, 'logps/chosen': -40.914737701416016, 'logits/rejected': -3.376582622528076, 'logits/chosen': -3.3515467643737793, 'epoch': 0.22}
{'loss': 0.215, 'learning_rate': 9.554826723804303e-07, 'rewards/chosen': -0.9147287607192993, 'rewards/rejected': -6.926792621612549, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.012063980102539, 'logps/rejected': -115.14115905761719, 'logps/chosen': -52.77170181274414, 'logits/rejected': -3.302088499069214, 'logits/chosen': -3.3872134685516357, 'epoch': 0.22}
{'loss': 0.186, 'learning_rate': 9.504844339512094e-07, 'rewards/chosen': -0.6377930641174316, 'rewards/rejected': -6.977095603942871, 'rewards/accuracies': 0.96875, 'rewards/margins': 6.339302062988281, 'logps/rejected': -105.06172180175781, 'logps/chosen': -40.192020416259766, 'logits/rejected': -3.349379777908325, 'logits/chosen': -3.3442394733428955, 'epoch': 0.23}
{'loss': 0.1008, 'learning_rate': 9.452348587347223e-07, 'rewards/chosen': 0.05343308299779892, 'rewards/rejected': -6.88495397567749, 'rewards/accuracies': 0.9375, 'rewards/margins': 6.938386917114258, 'logps/rejected': -103.73902130126953, 'logps/chosen': -33.777793884277344, 'logits/rejected': -3.306041955947876, 'logits/chosen': -3.369513511657715, 'epoch': 0.24}
{'loss': 0.1681, 'learning_rate': 9.397368756032444e-07, 'rewards/chosen': -1.0351413488388062, 'rewards/rejected': -6.923172950744629, 'rewards/accuracies': 0.90625, 'rewards/margins': 5.88803243637085, 'logps/rejected': -109.80421447753906, 'logps/chosen': -47.25422668457031, 'logits/rejected': -3.3422107696533203, 'logits/chosen': -3.3431811332702637, 'epoch': 0.24}
{'loss': 0.0765, 'learning_rate': 9.339935520221816e-07, 'rewards/chosen': -1.211119532585144, 'rewards/rejected': -7.100588798522949, 'rewards/accuracies': 0.875, 'rewards/margins': 5.889470100402832, 'logps/rejected': -111.68472290039062, 'logps/chosen': -49.919219970703125, 'logits/rejected': -3.3264503479003906, 'logits/chosen': -3.2926077842712402, 'epoch': 0.25}
{'loss': 0.1656, 'learning_rate': 9.2800809233865e-07, 'rewards/chosen': -0.6562850475311279, 'rewards/rejected': -8.294256210327148, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.6379714012146, 'logps/rejected': -119.3753890991211, 'logps/chosen': -48.07563018798828, 'logits/rejected': -3.2431533336639404, 'logits/chosen': -3.3233017921447754, 'epoch': 0.26}
{'loss': 0.219, 'learning_rate': 9.217838359936913e-07, 'rewards/chosen': -1.111326813697815, 'rewards/rejected': -7.830056190490723, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.7187299728393555, 'logps/rejected': -120.86293029785156, 'logps/chosen': -48.746097564697266, 'logits/rejected': -3.328917980194092, 'logits/chosen': -3.272697925567627, 'epoch': 0.26}
{'loss': 0.0731, 'learning_rate': 9.153242556591114e-07, 'rewards/chosen': -1.226826786994934, 'rewards/rejected': -7.825428009033203, 'rewards/accuracies': 1.0, 'rewards/margins': 6.598601341247559, 'logps/rejected': -113.17385864257812, 'logps/chosen': -50.53188705444336, 'logits/rejected': -3.2634730339050293, 'logits/chosen': -3.2626445293426514, 'epoch': 0.27}
{'loss': 0.1396, 'learning_rate': 9.08632955299989e-07, 'rewards/chosen': -1.4498789310455322, 'rewards/rejected': -9.314271926879883, 'rewards/accuracies': 0.9375, 'rewards/margins': 7.86439323425293, 'logps/rejected': -132.9205780029297, 'logps/chosen': -53.703269958496094, 'logits/rejected': -3.212691307067871, 'logits/chosen': -3.2989399433135986, 'epoch': 0.28}
{'loss': 0.0797, 'learning_rate': 9.017136681639305e-07, 'rewards/chosen': -1.3808475732803345, 'rewards/rejected': -9.67806625366211, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.297218322753906, 'logps/rejected': -135.94569396972656, 'logps/chosen': -55.301856994628906, 'logits/rejected': -3.1545262336730957, 'logits/chosen': -3.2300307750701904, 'epoch': 0.28}
{'loss': 0.2093, 'learning_rate': 8.945702546981968e-07, 'rewards/chosen': -2.8610379695892334, 'rewards/rejected': -8.092877388000488, 'rewards/accuracies': 0.78125, 'rewards/margins': 5.231839656829834, 'logps/rejected': -129.000732421875, 'logps/chosen': -73.1628189086914, 'logits/rejected': -3.2125017642974854, 'logits/chosen': -3.277772903442383, 'epoch': 0.29}
{'loss': 0.0961, 'learning_rate': 8.872067003958597e-07, 'rewards/chosen': -1.4008662700653076, 'rewards/rejected': -10.314722061157227, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.913854598999023, 'logps/rejected': -142.11019897460938, 'logps/chosen': -49.19440460205078, 'logits/rejected': -3.165843963623047, 'logits/chosen': -3.1563286781311035, 'epoch': 0.3}
{'loss': 0.1442, 'learning_rate': 8.796271135721944e-07, 'rewards/chosen': -1.4815869331359863, 'rewards/rejected': -10.366098403930664, 'rewards/accuracies': 0.875, 'rewards/margins': 8.88451099395752, 'logps/rejected': -144.13714599609375, 'logps/chosen': -54.13542938232422, 'logits/rejected': -3.2441537380218506, 'logits/chosen': -3.1303822994232178, 'epoch': 0.3}
{'loss': 0.142, 'learning_rate': 8.718357230725448e-07, 'rewards/chosen': -2.3837192058563232, 'rewards/rejected': -10.738412857055664, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.354693412780762, 'logps/rejected': -149.2349395751953, 'logps/chosen': -63.51545333862305, 'logits/rejected': -3.2027313709259033, 'logits/chosen': -3.21940541267395, 'epoch': 0.31}
{'loss': 0.1249, 'learning_rate': 8.63836875912943e-07, 'rewards/chosen': -1.5879127979278564, 'rewards/rejected': -10.02975845336914, 'rewards/accuracies': 1.0, 'rewards/margins': 8.441845893859863, 'logps/rejected': -141.7032470703125, 'logps/chosen': -52.9690055847168, 'logits/rejected': -3.235980272293091, 'logits/chosen': -3.2159197330474854, 'epoch': 0.32}
{'loss': 0.1738, 'learning_rate': 8.556350348547976e-07, 'rewards/chosen': -2.771421432495117, 'rewards/rejected': -11.846217155456543, 'rewards/accuracies': 0.875, 'rewards/margins': 9.074796676635742, 'logps/rejected': -164.51473999023438, 'logps/chosen': -66.61936950683594, 'logits/rejected': -3.243441581726074, 'logits/chosen': -3.2248449325561523, 'epoch': 0.32}
{'loss': 0.1242, 'learning_rate': 8.472347759150042e-07, 'rewards/chosen': -2.333065986633301, 'rewards/rejected': -9.422669410705566, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.089602470397949, 'logps/rejected': -133.61642456054688, 'logps/chosen': -63.05430603027344, 'logits/rejected': -3.2256736755371094, 'logits/chosen': -3.2605533599853516, 'epoch': 0.33}
{'loss': 0.146, 'learning_rate': 8.386407858128706e-07, 'rewards/chosen': -1.7031124830245972, 'rewards/rejected': -11.980709075927734, 'rewards/accuracies': 1.0, 'rewards/margins': 10.277596473693848, 'logps/rejected': -157.4029998779297, 'logps/chosen': -57.052669525146484, 'logits/rejected': -3.2504475116729736, 'logits/chosen': -3.2468454837799072, 'epoch': 0.34}
{'loss': 0.0946, 'learning_rate': 8.298578593552737e-07, 'rewards/chosen': -1.628205418586731, 'rewards/rejected': -10.941448211669922, 'rewards/accuracies': 0.90625, 'rewards/margins': 9.313241958618164, 'logps/rejected': -145.18443298339844, 'logps/chosen': -54.029266357421875, 'logits/rejected': -3.212191343307495, 'logits/chosen': -3.273535966873169, 'epoch': 0.34}
{'loss': 0.1898, 'learning_rate': 8.208908967615158e-07, 'rewards/chosen': -2.1374847888946533, 'rewards/rejected': -10.678462028503418, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.540977478027344, 'logps/rejected': -144.9113006591797, 'logps/chosen': -60.221275329589844, 'logits/rejected': -3.115379810333252, 'logits/chosen': -3.2460849285125732, 'epoch': 0.35}
{'loss': 0.1108, 'learning_rate': 8.117449009293668e-07, 'rewards/chosen': -1.8675720691680908, 'rewards/rejected': -9.347753524780273, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.4801812171936035, 'logps/rejected': -133.32620239257812, 'logps/chosen': -55.89203643798828, 'logits/rejected': -3.2123916149139404, 'logits/chosen': -3.250382661819458, 'epoch': 0.36}
{'loss': 0.0765, 'learning_rate': 8.024249746438187e-07, 'rewards/chosen': -0.9360700249671936, 'rewards/rejected': -9.817550659179688, 'rewards/accuracies': 1.0, 'rewards/margins': 8.88148021697998, 'logps/rejected': -134.86056518554688, 'logps/chosen': -50.868228912353516, 'logits/rejected': -3.162620782852173, 'logits/chosen': -3.2525768280029297, 'epoch': 0.36}
{'loss': 0.1083, 'learning_rate': 7.929363177301124e-07, 'rewards/chosen': -1.939550518989563, 'rewards/rejected': -10.365255355834961, 'rewards/accuracies': 0.875, 'rewards/margins': 8.425704956054688, 'logps/rejected': -146.05706787109375, 'logps/chosen': -60.659523010253906, 'logits/rejected': -3.2482352256774902, 'logits/chosen': -3.2541866302490234, 'epoch': 0.37}
{'loss': 0.1019, 'learning_rate': 7.832842241526212e-07, 'rewards/chosen': -2.1146504878997803, 'rewards/rejected': -11.452052116394043, 'rewards/accuracies': 1.0, 'rewards/margins': 9.337401390075684, 'logps/rejected': -155.49102783203125, 'logps/chosen': -58.01791000366211, 'logits/rejected': -3.244438409805298, 'logits/chosen': -3.190840244293213, 'epoch': 0.38}
{'loss': 0.1283, 'learning_rate': 7.734740790612136e-07, 'rewards/chosen': -2.0521106719970703, 'rewards/rejected': -10.691699981689453, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.639588356018066, 'logps/rejected': -148.1427764892578, 'logps/chosen': -59.404178619384766, 'logits/rejected': -3.2124927043914795, 'logits/chosen': -3.2415761947631836, 'epoch': 0.38}
{'loss': 0.147, 'learning_rate': 7.635113557867394e-07, 'rewards/chosen': -2.295053482055664, 'rewards/rejected': -9.517181396484375, 'rewards/accuracies': 0.875, 'rewards/margins': 7.222127914428711, 'logps/rejected': -130.8792724609375, 'logps/chosen': -63.46272277832031, 'logits/rejected': -3.244335889816284, 'logits/chosen': -3.2801401615142822, 'epoch': 0.39}
{'loss': 0.1533, 'learning_rate': 7.5340161278732e-07, 'rewards/chosen': -1.5272960662841797, 'rewards/rejected': -9.749628067016602, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.222331047058105, 'logps/rejected': -140.5160675048828, 'logps/chosen': -57.384849548339844, 'logits/rejected': -3.2068424224853516, 'logits/chosen': -3.2554516792297363, 'epoch': 0.4}
{'loss': 0.1416, 'learning_rate': 7.431504905471406e-07, 'rewards/chosen': -2.492652654647827, 'rewards/rejected': -9.702543258666992, 'rewards/accuracies': 0.875, 'rewards/margins': 7.2098894119262695, 'logps/rejected': -133.11917114257812, 'logps/chosen': -63.811729431152344, 'logits/rejected': -3.220944881439209, 'logits/chosen': -3.222430944442749, 'epoch': 0.4}
{'loss': 0.0799, 'learning_rate': 7.327637084294817e-07, 'rewards/chosen': -0.6901445388793945, 'rewards/rejected': -12.36522102355957, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.675077438354492, 'logps/rejected': -161.48171997070312, 'logps/chosen': -42.56877136230469, 'logits/rejected': -3.220437526702881, 'logits/chosen': -3.2350013256073, 'epoch': 0.41}
{'loss': 0.1434, 'learning_rate': 7.222470614857379e-07, 'rewards/chosen': -0.7003600597381592, 'rewards/rejected': -12.532562255859375, 'rewards/accuracies': 1.0, 'rewards/margins': 11.832200050354004, 'logps/rejected': -159.91773986816406, 'logps/chosen': -43.27547073364258, 'logits/rejected': -3.1681461334228516, 'logits/chosen': -3.2179512977600098, 'epoch': 0.42}
{'loss': 0.1471, 'learning_rate': 7.116064172222125e-07, 'rewards/chosen': -0.3069964349269867, 'rewards/rejected': -9.124319076538086, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.817322731018066, 'logps/rejected': -129.53733825683594, 'logps/chosen': -37.30556869506836, 'logits/rejected': -3.2376039028167725, 'logits/chosen': -3.203843832015991, 'epoch': 0.42}
{'loss': 0.095, 'learning_rate': 7.008477123264847e-07, 'rewards/chosen': -0.6864823698997498, 'rewards/rejected': -10.097333908081055, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.41085147857666, 'logps/rejected': -138.9408416748047, 'logps/chosen': -45.66061782836914, 'logits/rejected': -3.159365177154541, 'logits/chosen': -3.255826711654663, 'epoch': 0.43}
{'loss': 0.0896, 'learning_rate': 6.8997694935518e-07, 'rewards/chosen': -2.032863140106201, 'rewards/rejected': -9.850346565246582, 'rewards/accuracies': 0.90625, 'rewards/margins': 7.8174824714660645, 'logps/rejected': -146.0970458984375, 'logps/chosen': -60.38768005371094, 'logits/rejected': -3.1771678924560547, 'logits/chosen': -3.1996121406555176, 'epoch': 0.44}
{'loss': 0.1613, 'learning_rate': 6.7900019338499e-07, 'rewards/chosen': -0.3494522273540497, 'rewards/rejected': -8.76650619506836, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.417054176330566, 'logps/rejected': -129.6312255859375, 'logps/chosen': -50.463775634765625, 'logits/rejected': -3.0623486042022705, 'logits/chosen': -3.251674175262451, 'epoch': 0.44}
{'loss': 0.1237, 'learning_rate': 6.679235686288114e-07, 'rewards/chosen': -1.8173450231552124, 'rewards/rejected': -8.579670906066895, 'rewards/accuracies': 0.875, 'rewards/margins': 6.762325763702393, 'logps/rejected': -124.68203735351562, 'logps/chosen': -57.510093688964844, 'logits/rejected': -3.1385438442230225, 'logits/chosen': -3.2173588275909424, 'epoch': 0.45}
{'loss': 0.0676, 'learning_rate': 6.567532550188907e-07, 'rewards/chosen': -0.8054227232933044, 'rewards/rejected': -7.77208948135376, 'rewards/accuracies': 0.90625, 'rewards/margins': 6.966667175292969, 'logps/rejected': -113.46391296386719, 'logps/chosen': -45.40451431274414, 'logits/rejected': -3.1720099449157715, 'logits/chosen': -3.1533634662628174, 'epoch': 0.46}
{'loss': 0.1401, 'learning_rate': 6.454954847588823e-07, 'rewards/chosen': -0.7272675037384033, 'rewards/rejected': -9.455984115600586, 'rewards/accuracies': 0.875, 'rewards/margins': 8.728717803955078, 'logps/rejected': -134.04385375976562, 'logps/chosen': -42.209205627441406, 'logits/rejected': -3.184474468231201, 'logits/chosen': -3.132960796356201, 'epoch': 0.46}
{'loss': 0.112, 'learning_rate': 6.341565388467424e-07, 'rewards/chosen': -1.9404505491256714, 'rewards/rejected': -9.871871948242188, 'rewards/accuracies': 0.96875, 'rewards/margins': 7.931422233581543, 'logps/rejected': -141.505859375, 'logps/chosen': -58.60084533691406, 'logits/rejected': -3.077662467956543, 'logits/chosen': -3.1977016925811768, 'epoch': 0.47}
{'loss': 0.1114, 'learning_rate': 6.227427435703995e-07, 'rewards/chosen': -1.0197004079818726, 'rewards/rejected': -10.328110694885254, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.30841064453125, 'logps/rejected': -145.7467498779297, 'logps/chosen': -46.832332611083984, 'logits/rejected': -3.1592373847961426, 'logits/chosen': -3.1234233379364014, 'epoch': 0.48}
{'loss': 0.1856, 'learning_rate': 6.112604669781572e-07, 'rewards/chosen': -2.159231662750244, 'rewards/rejected': -10.680124282836914, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.520893096923828, 'logps/rejected': -148.77825927734375, 'logps/chosen': -60.12824630737305, 'logits/rejected': -3.10981822013855, 'logits/chosen': -3.1367626190185547, 'epoch': 0.49}
{'loss': 0.0549, 'learning_rate': 5.997161153257963e-07, 'rewards/chosen': -1.1685848236083984, 'rewards/rejected': -10.144342422485352, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.975757598876953, 'logps/rejected': -141.4662628173828, 'logps/chosen': -48.35199737548828, 'logits/rejected': -3.161764144897461, 'logits/chosen': -3.166642427444458, 'epoch': 0.49}
{'loss': 0.1172, 'learning_rate': 5.881161295023609e-07, 'rewards/chosen': -0.8507241606712341, 'rewards/rejected': -10.246119499206543, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.395395278930664, 'logps/rejected': -138.3798828125, 'logps/chosen': -46.747108459472656, 'logits/rejected': -3.11151123046875, 'logits/chosen': -3.1228952407836914, 'epoch': 0.5}
{'loss': 0.0971, 'learning_rate': 5.76466981436623e-07, 'rewards/chosen': -2.0482633113861084, 'rewards/rejected': -11.89297103881836, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.844707489013672, 'logps/rejected': -159.0935821533203, 'logps/chosen': -55.33032989501953, 'logits/rejected': -3.0984015464782715, 'logits/chosen': -3.1239657402038574, 'epoch': 0.51}
{'loss': 0.1247, 'learning_rate': 5.647751704862262e-07, 'rewards/chosen': -2.022204637527466, 'rewards/rejected': -10.377167701721191, 'rewards/accuracies': 0.90625, 'rewards/margins': 8.354963302612305, 'logps/rejected': -141.70315551757812, 'logps/chosen': -58.56610107421875, 'logits/rejected': -3.016021728515625, 'logits/chosen': -3.0912203788757324, 'epoch': 0.51}
{'loss': 0.2638, 'learning_rate': 5.53047219811529e-07, 'rewards/chosen': -1.843491554260254, 'rewards/rejected': -11.612287521362305, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.76879596710205, 'logps/rejected': -151.7525177001953, 'logps/chosen': -59.06373977661133, 'logits/rejected': -3.0688250064849854, 'logits/chosen': -3.0809121131896973, 'epoch': 0.52}
{'loss': 0.0814, 'learning_rate': 5.412896727361662e-07, 'rewards/chosen': -2.7077057361602783, 'rewards/rejected': -12.078043937683105, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.37033748626709, 'logps/rejected': -156.33502197265625, 'logps/chosen': -75.0589599609375, 'logits/rejected': -2.99564266204834, 'logits/chosen': -3.1130168437957764, 'epoch': 0.53}
{'loss': 0.104, 'learning_rate': 5.295090890963613e-07, 'rewards/chosen': -1.4637978076934814, 'rewards/rejected': -12.49459171295166, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.030793190002441, 'logps/rejected': -169.19898986816406, 'logps/chosen': -51.7615966796875, 'logits/rejected': -3.1634714603424072, 'logits/chosen': -3.022939920425415, 'epoch': 0.53}
{'loss': 0.0977, 'learning_rate': 5.17712041581027e-07, 'rewards/chosen': -3.6166276931762695, 'rewards/rejected': -13.023246765136719, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.40661907196045, 'logps/rejected': -170.93301391601562, 'logps/chosen': -75.07038116455078, 'logits/rejected': -3.103543758392334, 'logits/chosen': -3.1783995628356934, 'epoch': 0.54}
{'loss': 0.0856, 'learning_rate': 5.059051120646924e-07, 'rewards/chosen': -4.5306572914123535, 'rewards/rejected': -12.648747444152832, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.118090629577637, 'logps/rejected': -164.99351501464844, 'logps/chosen': -86.04912567138672, 'logits/rejected': -3.0804412364959717, 'logits/chosen': -3.1476290225982666, 'epoch': 0.55}
{'loss': 0.0957, 'learning_rate': 4.940948879353077e-07, 'rewards/chosen': -1.9275875091552734, 'rewards/rejected': -13.844316482543945, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.916728019714355, 'logps/rejected': -175.57676696777344, 'logps/chosen': -57.53066635131836, 'logits/rejected': -3.1036698818206787, 'logits/chosen': -3.1557884216308594, 'epoch': 0.55}
{'loss': 0.0492, 'learning_rate': 4.822879584189731e-07, 'rewards/chosen': -2.349911689758301, 'rewards/rejected': -13.545303344726562, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.195392608642578, 'logps/rejected': -175.79104614257812, 'logps/chosen': -62.87471008300781, 'logits/rejected': -3.1019773483276367, 'logits/chosen': -3.208824634552002, 'epoch': 0.56}
{'loss': 0.1542, 'learning_rate': 4.704909109036386e-07, 'rewards/chosen': -2.3850364685058594, 'rewards/rejected': -13.611721992492676, 'rewards/accuracies': 0.8125, 'rewards/margins': 11.2266845703125, 'logps/rejected': -170.838623046875, 'logps/chosen': -61.81333541870117, 'logits/rejected': -3.072275161743164, 'logits/chosen': -3.1648287773132324, 'epoch': 0.57}
{'loss': 0.0837, 'learning_rate': 4.5871032726383385e-07, 'rewards/chosen': -2.4165680408477783, 'rewards/rejected': -12.386872291564941, 'rewards/accuracies': 1.0, 'rewards/margins': 9.970303535461426, 'logps/rejected': -163.58099365234375, 'logps/chosen': -62.26369857788086, 'logits/rejected': -3.092681407928467, 'logits/chosen': -3.0983641147613525, 'epoch': 0.57}
{'loss': 0.0811, 'learning_rate': 4.46952780188471e-07, 'rewards/chosen': -1.5343732833862305, 'rewards/rejected': -14.928997993469238, 'rewards/accuracies': 1.0, 'rewards/margins': 13.394624710083008, 'logps/rejected': -189.54119873046875, 'logps/chosen': -57.52281951904297, 'logits/rejected': -3.099609851837158, 'logits/chosen': -3.1499385833740234, 'epoch': 0.58}
{'loss': 0.138, 'learning_rate': 4.3522482951377387e-07, 'rewards/chosen': -1.9271572828292847, 'rewards/rejected': -14.385479927062988, 'rewards/accuracies': 0.9375, 'rewards/margins': 12.45832347869873, 'logps/rejected': -185.55902099609375, 'logps/chosen': -56.08406066894531, 'logits/rejected': -3.1480398178100586, 'logits/chosen': -3.1083967685699463, 'epoch': 0.59}
{'loss': 0.1292, 'learning_rate': 4.23533018563377e-07, 'rewards/chosen': -1.9363031387329102, 'rewards/rejected': -12.058440208435059, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.122138023376465, 'logps/rejected': -156.54470825195312, 'logps/chosen': -58.06819534301758, 'logits/rejected': -3.0801806449890137, 'logits/chosen': -3.1647043228149414, 'epoch': 0.59}
{'loss': 0.0716, 'learning_rate': 4.118838704976392e-07, 'rewards/chosen': -2.137314796447754, 'rewards/rejected': -14.136835098266602, 'rewards/accuracies': 1.0, 'rewards/margins': 11.999520301818848, 'logps/rejected': -180.4036407470703, 'logps/chosen': -57.36029052734375, 'logits/rejected': -3.1400113105773926, 'logits/chosen': -3.1466591358184814, 'epoch': 0.6}
{'loss': 0.0825, 'learning_rate': 4.002838846742038e-07, 'rewards/chosen': -2.0922276973724365, 'rewards/rejected': -13.832703590393066, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.740474700927734, 'logps/rejected': -176.04025268554688, 'logps/chosen': -56.34674072265625, 'logits/rejected': -3.1392717361450195, 'logits/chosen': -3.106630325317383, 'epoch': 0.61}
{'loss': 0.0992, 'learning_rate': 3.8873953302184283e-07, 'rewards/chosen': -2.7158689498901367, 'rewards/rejected': -12.332940101623535, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.617071151733398, 'logps/rejected': -166.2986297607422, 'logps/chosen': -73.56034088134766, 'logits/rejected': -3.1200389862060547, 'logits/chosen': -3.2162179946899414, 'epoch': 0.61}
{'loss': 0.1352, 'learning_rate': 3.772572564296004e-07, 'rewards/chosen': -3.5598902702331543, 'rewards/rejected': -12.06738567352295, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.507494926452637, 'logps/rejected': -160.95281982421875, 'logps/chosen': -82.71248626708984, 'logits/rejected': -3.133375406265259, 'logits/chosen': -3.217660903930664, 'epoch': 0.62}
{'loss': 0.0795, 'learning_rate': 3.6584346115325775e-07, 'rewards/chosen': -2.417536497116089, 'rewards/rejected': -14.685205459594727, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.267669677734375, 'logps/rejected': -188.8695068359375, 'logps/chosen': -64.76055908203125, 'logits/rejected': -3.076578140258789, 'logits/chosen': -3.1983988285064697, 'epoch': 0.63}
{'loss': 0.1413, 'learning_rate': 3.5450451524111775e-07, 'rewards/chosen': -2.3654024600982666, 'rewards/rejected': -11.890087127685547, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.52468490600586, 'logps/rejected': -154.38340759277344, 'logps/chosen': -58.84120178222656, 'logits/rejected': -3.1606264114379883, 'logits/chosen': -3.1827995777130127, 'epoch': 0.63}
{'loss': 0.0684, 'learning_rate': 3.4324674498110953e-07, 'rewards/chosen': -3.187772512435913, 'rewards/rejected': -14.135009765625, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.947237968444824, 'logps/rejected': -184.54803466796875, 'logps/chosen': -70.53005981445312, 'logits/rejected': -3.164273738861084, 'logits/chosen': -3.2203729152679443, 'epoch': 0.64}
{'loss': 0.1486, 'learning_rate': 3.320764313711887e-07, 'rewards/chosen': -1.6150821447372437, 'rewards/rejected': -12.279077529907227, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.663995742797852, 'logps/rejected': -158.58091735839844, 'logps/chosen': -53.89997863769531, 'logits/rejected': -3.1097044944763184, 'logits/chosen': -3.131110191345215, 'epoch': 0.65}
{'loss': 0.0549, 'learning_rate': 3.2099980661501015e-07, 'rewards/chosen': -1.5214101076126099, 'rewards/rejected': -11.558903694152832, 'rewards/accuracies': 1.0, 'rewards/margins': 10.037493705749512, 'logps/rejected': -152.5535430908203, 'logps/chosen': -54.38121795654297, 'logits/rejected': -3.1249234676361084, 'logits/chosen': -3.2169294357299805, 'epoch': 0.65}
{'loss': 0.1412, 'learning_rate': 3.1002305064482005e-07, 'rewards/chosen': -1.7515922784805298, 'rewards/rejected': -12.177526473999023, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.425933837890625, 'logps/rejected': -163.61949157714844, 'logps/chosen': -60.17231750488281, 'logits/rejected': -3.1794912815093994, 'logits/chosen': -3.141021966934204, 'epoch': 0.66}
{'loss': 0.1136, 'learning_rate': 2.9915228767351535e-07, 'rewards/chosen': -1.5628923177719116, 'rewards/rejected': -11.923171997070312, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.360280990600586, 'logps/rejected': -162.16432189941406, 'logps/chosen': -52.29271697998047, 'logits/rejected': -3.153202533721924, 'logits/chosen': -3.1944446563720703, 'epoch': 0.67}
{'loss': 0.0498, 'learning_rate': 2.883935827777875e-07, 'rewards/chosen': -1.349705457687378, 'rewards/rejected': -12.323978424072266, 'rewards/accuracies': 1.0, 'rewards/margins': 10.974272727966309, 'logps/rejected': -160.69712829589844, 'logps/chosen': -51.83468246459961, 'logits/rejected': -3.125504493713379, 'logits/chosen': -3.1297972202301025, 'epoch': 0.67}
{'loss': 0.1816, 'learning_rate': 2.777529385142623e-07, 'rewards/chosen': -1.1854407787322998, 'rewards/rejected': -12.243788719177246, 'rewards/accuracies': 0.84375, 'rewards/margins': 11.058348655700684, 'logps/rejected': -162.68756103515625, 'logps/chosen': -49.0390625, 'logits/rejected': -3.162083387374878, 'logits/chosen': -3.1237268447875977, 'epoch': 0.68}
{'loss': 0.0896, 'learning_rate': 2.672362915705184e-07, 'rewards/chosen': -1.787846326828003, 'rewards/rejected': -11.719573020935059, 'rewards/accuracies': 1.0, 'rewards/margins': 9.93172550201416, 'logps/rejected': -155.7344970703125, 'logps/chosen': -54.601539611816406, 'logits/rejected': -3.141413927078247, 'logits/chosen': -3.174467086791992, 'epoch': 0.69}
{'loss': 0.0367, 'learning_rate': 2.5684950945285933e-07, 'rewards/chosen': -1.6813440322875977, 'rewards/rejected': -10.781280517578125, 'rewards/accuracies': 1.0, 'rewards/margins': 9.099935531616211, 'logps/rejected': -146.47274780273438, 'logps/chosen': -60.0740852355957, 'logits/rejected': -3.1369826793670654, 'logits/chosen': -3.2059669494628906, 'epoch': 0.69}
{'loss': 0.0774, 'learning_rate': 2.4659838721268e-07, 'rewards/chosen': -1.8701667785644531, 'rewards/rejected': -11.51479721069336, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.644630432128906, 'logps/rejected': -153.46176147460938, 'logps/chosen': -52.4505615234375, 'logits/rejected': -3.1713826656341553, 'logits/chosen': -3.196025848388672, 'epoch': 0.7}
{'loss': 0.1133, 'learning_rate': 2.3648864421326058e-07, 'rewards/chosen': -1.4329675436019897, 'rewards/rejected': -12.895156860351562, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.462188720703125, 'logps/rejected': -167.03355407714844, 'logps/chosen': -47.849998474121094, 'logits/rejected': -3.1315419673919678, 'logits/chosen': -3.195566415786743, 'epoch': 0.71}
{'loss': 0.1033, 'learning_rate': 2.2652592093878665e-07, 'rewards/chosen': -1.4020910263061523, 'rewards/rejected': -12.527910232543945, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.125819206237793, 'logps/rejected': -161.3047637939453, 'logps/chosen': -45.70187759399414, 'logits/rejected': -3.15842342376709, 'logits/chosen': -3.117919683456421, 'epoch': 0.71}
{'loss': 0.1176, 'learning_rate': 2.1671577584737898e-07, 'rewards/chosen': -2.8165862560272217, 'rewards/rejected': -12.788599014282227, 'rewards/accuracies': 0.96875, 'rewards/margins': 9.972013473510742, 'logps/rejected': -169.3655548095703, 'logps/chosen': -69.25810241699219, 'logits/rejected': -3.1243326663970947, 'logits/chosen': -3.1806976795196533, 'epoch': 0.72}
{'loss': 0.1051, 'learning_rate': 2.070636822698877e-07, 'rewards/chosen': -3.1932737827301025, 'rewards/rejected': -14.199240684509277, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.005966186523438, 'logps/rejected': -185.95278930664062, 'logps/chosen': -72.9546127319336, 'logits/rejected': -3.069636821746826, 'logits/chosen': -3.1724045276641846, 'epoch': 0.73}
{'loss': 0.0691, 'learning_rate': 1.9757502535618136e-07, 'rewards/chosen': -1.158820390701294, 'rewards/rejected': -12.944730758666992, 'rewards/accuracies': 1.0, 'rewards/margins': 11.785910606384277, 'logps/rejected': -173.1833953857422, 'logps/chosen': -48.75686264038086, 'logits/rejected': -3.198613166809082, 'logits/chosen': -3.089702844619751, 'epoch': 0.73}
{'loss': 0.0852, 'learning_rate': 1.8825509907063326e-07, 'rewards/chosen': -2.3522720336914062, 'rewards/rejected': -10.492466926574707, 'rewards/accuracies': 0.96875, 'rewards/margins': 8.140193939208984, 'logps/rejected': -140.4801788330078, 'logps/chosen': -59.81261444091797, 'logits/rejected': -3.1359634399414062, 'logits/chosen': -3.1192338466644287, 'epoch': 0.74}
{'loss': 0.1541, 'learning_rate': 1.7910910323848432e-07, 'rewards/chosen': -1.2951949834823608, 'rewards/rejected': -12.334922790527344, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.039727210998535, 'logps/rejected': -161.50511169433594, 'logps/chosen': -50.1663818359375, 'logits/rejected': -3.0994350910186768, 'logits/chosen': -3.151952028274536, 'epoch': 0.75}
{'loss': 0.087, 'learning_rate': 1.7014214064472643e-07, 'rewards/chosen': -2.270543336868286, 'rewards/rejected': -13.047327995300293, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.77678394317627, 'logps/rejected': -167.026123046875, 'logps/chosen': -58.7653923034668, 'logits/rejected': -3.103631019592285, 'logits/chosen': -3.140397310256958, 'epoch': 0.75}
{'loss': 0.1162, 'learning_rate': 1.6135921418712955e-07, 'rewards/chosen': -1.9919131994247437, 'rewards/rejected': -12.89573860168457, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.903824806213379, 'logps/rejected': -167.6705322265625, 'logps/chosen': -59.25358200073242, 'logits/rejected': -3.162335157394409, 'logits/chosen': -3.1571967601776123, 'epoch': 0.76}
{'loss': 0.0737, 'learning_rate': 1.5276522408499565e-07, 'rewards/chosen': -1.2137165069580078, 'rewards/rejected': -12.185956954956055, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.972240447998047, 'logps/rejected': -166.7598876953125, 'logps/chosen': -47.955814361572266, 'logits/rejected': -3.127296209335327, 'logits/chosen': -3.1377182006835938, 'epoch': 0.77}
{'loss': 0.0847, 'learning_rate': 1.4436496514520253e-07, 'rewards/chosen': -1.6474052667617798, 'rewards/rejected': -11.79306697845459, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.145662307739258, 'logps/rejected': -158.53167724609375, 'logps/chosen': -58.80986022949219, 'logits/rejected': -3.094309091567993, 'logits/chosen': -3.148313522338867, 'epoch': 0.77}
{'loss': 0.1136, 'learning_rate': 1.3616312408705688e-07, 'rewards/chosen': -2.7372772693634033, 'rewards/rejected': -14.114974975585938, 'rewards/accuracies': 0.90625, 'rewards/margins': 11.377697944641113, 'logps/rejected': -180.58363342285156, 'logps/chosen': -64.30975341796875, 'logits/rejected': -3.1515450477600098, 'logits/chosen': -3.0915579795837402, 'epoch': 0.78}
{'loss': 0.0975, 'learning_rate': 1.2816427692745518e-07, 'rewards/chosen': -2.3383076190948486, 'rewards/rejected': -13.12484073638916, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.78653335571289, 'logps/rejected': -171.0480499267578, 'logps/chosen': -61.02695846557617, 'logits/rejected': -3.1039867401123047, 'logits/chosen': -3.1202168464660645, 'epoch': 0.79}
{'loss': 0.0673, 'learning_rate': 1.2037288642780574e-07, 'rewards/chosen': -1.310578465461731, 'rewards/rejected': -14.050078392028809, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.739498138427734, 'logps/rejected': -184.60040283203125, 'logps/chosen': -51.063743591308594, 'logits/rejected': -3.162686347961426, 'logits/chosen': -3.171862840652466, 'epoch': 0.79}
{'loss': 0.0987, 'learning_rate': 1.1279329960414047e-07, 'rewards/chosen': -1.9010154008865356, 'rewards/rejected': -12.43496036529541, 'rewards/accuracies': 0.875, 'rewards/margins': 10.533945083618164, 'logps/rejected': -163.49671936035156, 'logps/chosen': -54.453407287597656, 'logits/rejected': -3.1367270946502686, 'logits/chosen': -3.172750473022461, 'epoch': 0.8}
{'loss': 0.0406, 'learning_rate': 1.0542974530180327e-07, 'rewards/chosen': -1.7548863887786865, 'rewards/rejected': -11.3402681350708, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.585381507873535, 'logps/rejected': -152.26101684570312, 'logps/chosen': -54.75449752807617, 'logits/rejected': -3.1581788063049316, 'logits/chosen': -3.147737741470337, 'epoch': 0.81}
{'loss': 0.0463, 'learning_rate': 9.828633183606949e-08, 'rewards/chosen': -3.8264760971069336, 'rewards/rejected': -13.763288497924805, 'rewards/accuracies': 1.0, 'rewards/margins': 9.936811447143555, 'logps/rejected': -173.12110900878906, 'logps/chosen': -75.72958374023438, 'logits/rejected': -3.1228482723236084, 'logits/chosen': -3.1253507137298584, 'epoch': 0.82}
{'loss': 0.0691, 'learning_rate': 9.1367044700011e-08, 'rewards/chosen': -2.63116717338562, 'rewards/rejected': -14.987602233886719, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.356435775756836, 'logps/rejected': -190.19837951660156, 'logps/chosen': -65.69491577148438, 'logits/rejected': -3.176374912261963, 'logits/chosen': -3.1404926776885986, 'epoch': 0.82}
{'loss': 0.1085, 'learning_rate': 8.467574434088859e-08, 'rewards/chosen': -0.9677187204360962, 'rewards/rejected': -13.863740921020508, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.89602279663086, 'logps/rejected': -180.41098022460938, 'logps/chosen': -47.7330207824707, 'logits/rejected': -3.06766676902771, 'logits/chosen': -3.1815741062164307, 'epoch': 0.83}
{'loss': 0.0724, 'learning_rate': 7.821616400630865e-08, 'rewards/chosen': -1.6872600317001343, 'rewards/rejected': -12.407696723937988, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.720436096191406, 'logps/rejected': -166.34678649902344, 'logps/chosen': -51.439544677734375, 'logits/rejected': -3.1649351119995117, 'logits/chosen': -3.125702142715454, 'epoch': 0.84}
{'loss': 0.0692, 'learning_rate': 7.199190766134999e-08, 'rewards/chosen': -1.5311148166656494, 'rewards/rejected': -12.822521209716797, 'rewards/accuracies': 1.0, 'rewards/margins': 11.291406631469727, 'logps/rejected': -170.12338256835938, 'logps/chosen': -51.135128021240234, 'logits/rejected': -3.140199661254883, 'logits/chosen': -3.1596152782440186, 'epoch': 0.84}
{'loss': 0.0682, 'learning_rate': 6.600644797781846e-08, 'rewards/chosen': -1.2432889938354492, 'rewards/rejected': -11.999017715454102, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.755727767944336, 'logps/rejected': -157.88906860351562, 'logps/chosen': -54.62162780761719, 'logits/rejected': -3.1203861236572266, 'logits/chosen': -3.159715175628662, 'epoch': 0.85}
{'loss': 0.0998, 'learning_rate': 6.026312439675551e-08, 'rewards/chosen': -1.501763105392456, 'rewards/rejected': -13.089500427246094, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.587736129760742, 'logps/rejected': -172.3090362548828, 'logps/chosen': -56.26402282714844, 'logits/rejected': -3.1641886234283447, 'logits/chosen': -3.1751420497894287, 'epoch': 0.86}
{'loss': 0.1056, 'learning_rate': 5.4765141265277706e-08, 'rewards/chosen': -2.193295478820801, 'rewards/rejected': -12.76347541809082, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.57017993927002, 'logps/rejected': -168.34642028808594, 'logps/chosen': -59.6640739440918, 'logits/rejected': -3.1287171840667725, 'logits/chosen': -3.1767120361328125, 'epoch': 0.86}
{'loss': 0.0972, 'learning_rate': 4.951556604879048e-08, 'rewards/chosen': -2.0115952491760254, 'rewards/rejected': -13.643021583557129, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.631426811218262, 'logps/rejected': -174.73890686035156, 'logps/chosen': -57.54474639892578, 'logits/rejected': -3.039663076400757, 'logits/chosen': -3.108840227127075, 'epoch': 0.87}
{'loss': 0.1014, 'learning_rate': 4.4517327619569776e-08, 'rewards/chosen': -2.0856127738952637, 'rewards/rejected': -13.352367401123047, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.266754150390625, 'logps/rejected': -175.39883422851562, 'logps/chosen': -66.54440307617188, 'logits/rejected': -3.1446533203125, 'logits/chosen': -3.151341438293457, 'epoch': 0.88}
{'loss': 0.0932, 'learning_rate': 3.977321462266997e-08, 'rewards/chosen': -3.1411776542663574, 'rewards/rejected': -14.034542083740234, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.893362998962402, 'logps/rejected': -180.76409912109375, 'logps/chosen': -70.25113677978516, 'logits/rejected': -3.139014959335327, 'logits/chosen': -3.1395742893218994, 'epoch': 0.88}
{'loss': 0.1053, 'learning_rate': 3.528587392006716e-08, 'rewards/chosen': -3.032269239425659, 'rewards/rejected': -13.357207298278809, 'rewards/accuracies': 0.96875, 'rewards/margins': 10.324936866760254, 'logps/rejected': -175.039794921875, 'logps/chosen': -71.10560607910156, 'logits/rejected': -3.131004571914673, 'logits/chosen': -3.155989170074463, 'epoch': 0.89}
{'loss': 0.0772, 'learning_rate': 3.105780911390737e-08, 'rewards/chosen': -2.2528493404388428, 'rewards/rejected': -13.08724308013916, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.834394454956055, 'logps/rejected': -174.53521728515625, 'logps/chosen': -66.36914825439453, 'logits/rejected': -3.1247425079345703, 'logits/chosen': -3.1239099502563477, 'epoch': 0.9}
{'loss': 0.0788, 'learning_rate': 2.7091379149682682e-08, 'rewards/chosen': -1.9806606769561768, 'rewards/rejected': -14.594350814819336, 'rewards/accuracies': 0.90625, 'rewards/margins': 12.613689422607422, 'logps/rejected': -182.80377197265625, 'logps/chosen': -57.28538131713867, 'logits/rejected': -3.0551323890686035, 'logits/chosen': -3.1463093757629395, 'epoch': 0.9}
{'loss': 0.0667, 'learning_rate': 2.3388797000115425e-08, 'rewards/chosen': -3.2860639095306396, 'rewards/rejected': -14.669819831848145, 'rewards/accuracies': 1.0, 'rewards/margins': 11.383755683898926, 'logps/rejected': -186.20506286621094, 'logps/chosen': -71.23036193847656, 'logits/rejected': -3.1239821910858154, 'logits/chosen': -3.1589784622192383, 'epoch': 0.91}
{'loss': 0.0809, 'learning_rate': 1.9952128430483717e-08, 'rewards/chosen': -1.5839598178863525, 'rewards/rejected': -10.5173978805542, 'rewards/accuracies': 0.9375, 'rewards/margins': 8.93343734741211, 'logps/rejected': -142.90933227539062, 'logps/chosen': -54.89942932128906, 'logits/rejected': -3.0884578227996826, 'logits/chosen': -3.1598434448242188, 'epoch': 0.92}
{'loss': 0.0345, 'learning_rate': 1.6783290846078714e-08, 'rewards/chosen': -1.5579248666763306, 'rewards/rejected': -12.952351570129395, 'rewards/accuracies': 1.0, 'rewards/margins': 11.394426345825195, 'logps/rejected': -171.90989685058594, 'logps/chosen': -61.02727508544922, 'logits/rejected': -3.1035313606262207, 'logits/chosen': -3.107513904571533, 'epoch': 0.92}
{'loss': 0.0299, 'learning_rate': 1.3884052222434717e-08, 'rewards/chosen': -2.0514354705810547, 'rewards/rejected': -14.201772689819336, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.150337219238281, 'logps/rejected': -178.4392547607422, 'logps/chosen': -57.81683349609375, 'logits/rejected': -3.0555579662323, 'logits/chosen': -3.1077637672424316, 'epoch': 0.93}
{'loss': 0.071, 'learning_rate': 1.1256030118930726e-08, 'rewards/chosen': -2.192430019378662, 'rewards/rejected': -13.347288131713867, 'rewards/accuracies': 0.9375, 'rewards/margins': 11.154858589172363, 'logps/rejected': -174.6665802001953, 'logps/chosen': -56.76114273071289, 'logits/rejected': -3.0890555381774902, 'logits/chosen': -3.127600908279419, 'epoch': 0.94}
{'loss': 0.0744, 'learning_rate': 8.90069077631228e-09, 'rewards/chosen': -2.044727325439453, 'rewards/rejected': -11.266634941101074, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.221907615661621, 'logps/rejected': -152.8227996826172, 'logps/chosen': -60.10014724731445, 'logits/rejected': -3.146543264389038, 'logits/chosen': -3.1496801376342773, 'epoch': 0.94}
{'loss': 0.0627, 'learning_rate': 6.819348298638839e-09, 'rewards/chosen': -1.7404170036315918, 'rewards/rejected': -12.333768844604492, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.593352317810059, 'logps/rejected': -164.87164306640625, 'logps/chosen': -55.02198791503906, 'logits/rejected': -3.1344072818756104, 'logits/chosen': -3.1349291801452637, 'epoch': 0.95}
{'loss': 0.089, 'learning_rate': 5.0131639201108635e-09, 'rewards/chosen': -2.2443811893463135, 'rewards/rejected': -13.33971881866455, 'rewards/accuracies': 0.96875, 'rewards/margins': 11.095337867736816, 'logps/rejected': -171.19659423828125, 'logps/chosen': -63.871768951416016, 'logits/rejected': -3.068267583847046, 'logits/chosen': -3.1418004035949707, 'epoch': 0.96}
{'loss': 0.1472, 'learning_rate': 3.4831453571879663e-09, 'rewards/chosen': -2.167196273803711, 'rewards/rejected': -12.72265625, 'rewards/accuracies': 0.90625, 'rewards/margins': 10.555460929870605, 'logps/rejected': -167.56895446777344, 'logps/chosen': -60.97953414916992, 'logits/rejected': -3.1257591247558594, 'logits/chosen': -3.169233798980713, 'epoch': 0.96}
{'loss': 0.1235, 'learning_rate': 2.2301462463582553e-09, 'rewards/chosen': -1.6806869506835938, 'rewards/rejected': -14.49082088470459, 'rewards/accuracies': 0.96875, 'rewards/margins': 12.810134887695312, 'logps/rejected': -187.29367065429688, 'logps/chosen': -58.6042366027832, 'logits/rejected': -3.0162193775177, 'logits/chosen': -3.1453142166137695, 'epoch': 0.97}
{'loss': 0.1261, 'learning_rate': 1.2548656678721403e-09, 'rewards/chosen': -1.5464402437210083, 'rewards/rejected': -12.37804126739502, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.831600189208984, 'logps/rejected': -166.6693572998047, 'logps/chosen': -59.724998474121094, 'logits/rejected': -3.015111207962036, 'logits/chosen': -3.1610898971557617, 'epoch': 0.98}
{'loss': 0.0645, 'learning_rate': 5.578477557081074e-10, 'rewards/chosen': -2.6014745235443115, 'rewards/rejected': -12.606712341308594, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.005236625671387, 'logps/rejected': -163.01736450195312, 'logps/chosen': -66.07864379882812, 'logits/rejected': -3.0950074195861816, 'logits/chosen': -3.1722424030303955, 'epoch': 0.98}
{'loss': 0.0878, 'learning_rate': 1.394813939862849e-10, 'rewards/chosen': -1.905404806137085, 'rewards/rejected': -12.222705841064453, 'rewards/accuracies': 0.9375, 'rewards/margins': 10.317299842834473, 'logps/rejected': -163.1103973388672, 'logps/chosen': -55.77294921875, 'logits/rejected': -3.1308820247650146, 'logits/chosen': -3.1060540676116943, 'epoch': 0.99}
{'loss': 0.0656, 'learning_rate': 0.0, 'rewards/chosen': -1.8143105506896973, 'rewards/rejected': -11.625791549682617, 'rewards/accuracies': 0.9375, 'rewards/margins': 9.811480522155762, 'logps/rejected': -157.8468017578125, 'logps/chosen': -57.28905487060547, 'logits/rejected': -3.1016883850097656, 'logits/chosen': -3.0692155361175537, 'epoch': 1.0}
{'eval_loss': 0.0712403655052185, 'eval_runtime': 42.4599, 'eval_samples_per_second': 23.552, 'eval_steps_per_second': 5.888, 'eval_rewards/chosen': -1.6957565546035767, 'eval_rewards/rejected': -13.808828353881836, 'eval_rewards/accuracies': 0.9800000190734863, 'eval_rewards/margins': 12.113070487976074, 'eval_logps/rejected': -177.16357421875, 'eval_logps/chosen': -55.274681091308594, 'eval_logits/rejected': -3.103597640991211, 'eval_logits/chosen': -3.1456522941589355, 'epoch': 1.0}
{'train_runtime': 1732.3303, 'train_samples_per_second': 10.968, 'train_steps_per_second': 0.085, 'train_loss': 0.16405152783703966, 'epoch': 1.0}
