[2024-03-07 08:26:38,485][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive
[2024-03-07 08:26:38,485][root][INFO] - Max seq length: 2048
[2024-03-07 08:26:38,485][root][INFO] - Devices: 4
[2024-03-07 08:26:38,485][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive
[2024-03-07 08:26:38,485][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive
[2024-03-07 08:26:38,485][root][INFO] - Max seq length: 2048
[2024-03-07 08:26:38,485][root][INFO] - Max seq length: 2048
[2024-03-07 08:26:38,486][root][INFO] - Devices: 4
[2024-03-07 08:26:38,486][root][INFO] - Devices: 4
[2024-03-07 08:26:38,486][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive
[2024-03-07 08:26:38,486][root][INFO] - Max seq length: 2048
[2024-03-07 08:26:38,486][root][INFO] - Devices: 4
[2024-03-07 08:26:55,946] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 08:26:56,142] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 08:26:56,143] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-07 08:26:56,198] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 08:26:56,381] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 08:26:56,398] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 08:26:56,458] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 08:26:56,539] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 08:26:56,598] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 08:27:36,523][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 46732
})
[2024-03-07 08:27:36,526][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-07 08:27:36,602][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 46732
})
[2024-03-07 08:27:37,211][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 46732
})
[2024-03-07 08:27:37,537][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 46732
})
{'loss': 0.6473, 'learning_rate': 3.3333333333333334e-08, 'epoch': 0.01}
{'loss': 0.7017, 'learning_rate': 6.666666666666667e-08, 'epoch': 0.03}
{'loss': 0.6438, 'learning_rate': 1e-07, 'epoch': 0.04}
{'loss': 0.6023, 'learning_rate': 1.3333333333333334e-07, 'epoch': 0.05}
{'loss': 0.5188, 'learning_rate': 1.6666666666666665e-07, 'epoch': 0.07}
{'loss': 0.3666, 'learning_rate': 2e-07, 'epoch': 0.08}
{'loss': 0.3312, 'learning_rate': 2.3333333333333333e-07, 'epoch': 0.1}
{'loss': 0.2881, 'learning_rate': 2.6666666666666667e-07, 'epoch': 0.11}
{'loss': 0.2725, 'learning_rate': 3e-07, 'epoch': 0.12}
{'loss': 0.2469, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.14}
{'loss': 0.2357, 'learning_rate': 3.666666666666666e-07, 'epoch': 0.15}
{'loss': 0.2246, 'learning_rate': 4e-07, 'epoch': 0.16}
{'loss': 0.2124, 'learning_rate': 4.3333333333333335e-07, 'epoch': 0.18}
{'loss': 0.2072, 'learning_rate': 4.6666666666666666e-07, 'epoch': 0.19}
{'loss': 0.2061, 'learning_rate': 5e-07, 'epoch': 0.21}
{'loss': 0.2003, 'learning_rate': 5.333333333333333e-07, 'epoch': 0.22}
{'loss': 0.1999, 'learning_rate': 5.666666666666666e-07, 'epoch': 0.23}
{'loss': 0.1954, 'learning_rate': 6e-07, 'epoch': 0.25}
{'loss': 0.1975, 'learning_rate': 6.333333333333332e-07, 'epoch': 0.26}
{'loss': 0.1856, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.27}
{'loss': 0.1965, 'learning_rate': 7e-07, 'epoch': 0.29}
{'loss': 0.194, 'learning_rate': 7.333333333333332e-07, 'epoch': 0.3}
{'loss': 0.1829, 'learning_rate': 7.666666666666667e-07, 'epoch': 0.31}
{'loss': 0.1826, 'learning_rate': 8e-07, 'epoch': 0.33}
{'loss': 0.1798, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.34}
{'loss': 0.1872, 'learning_rate': 8.666666666666667e-07, 'epoch': 0.36}
{'loss': 0.1868, 'learning_rate': 9e-07, 'epoch': 0.37}
{'loss': 0.1912, 'learning_rate': 9.333333333333333e-07, 'epoch': 0.38}
{'loss': 0.186, 'learning_rate': 9.666666666666666e-07, 'epoch': 0.4}
{'loss': 0.1849, 'learning_rate': 1e-06, 'epoch': 0.41}
{'loss': 0.1804, 'learning_rate': 9.767441860465115e-07, 'epoch': 0.42}
{'loss': 0.1852, 'learning_rate': 9.534883720930232e-07, 'epoch': 0.44}
{'loss': 0.1833, 'learning_rate': 9.302325581395349e-07, 'epoch': 0.45}
{'loss': 0.1839, 'learning_rate': 9.069767441860464e-07, 'epoch': 0.47}
{'loss': 0.18, 'learning_rate': 8.837209302325581e-07, 'epoch': 0.48}
{'loss': 0.1781, 'learning_rate': 8.604651162790697e-07, 'epoch': 0.49}
{'loss': 0.1768, 'learning_rate': 8.372093023255814e-07, 'epoch': 0.51}
{'loss': 0.1633, 'learning_rate': 8.13953488372093e-07, 'epoch': 0.52}
{'loss': 0.1659, 'learning_rate': 7.906976744186046e-07, 'epoch': 0.53}
{'loss': 0.1695, 'learning_rate': 7.674418604651162e-07, 'epoch': 0.55}
{'loss': 0.1643, 'learning_rate': 7.441860465116279e-07, 'epoch': 0.56}
{'loss': 0.1584, 'learning_rate': 7.209302325581395e-07, 'epoch': 0.58}
{'loss': 0.1599, 'learning_rate': 6.976744186046511e-07, 'epoch': 0.59}
{'loss': 0.1609, 'learning_rate': 6.744186046511627e-07, 'epoch': 0.6}
{'loss': 0.1536, 'learning_rate': 6.511627906976745e-07, 'epoch': 0.62}
{'loss': 0.1552, 'learning_rate': 6.27906976744186e-07, 'epoch': 0.63}
{'loss': 0.1531, 'learning_rate': 6.046511627906976e-07, 'epoch': 0.64}
{'loss': 0.1506, 'learning_rate': 5.813953488372093e-07, 'epoch': 0.66}
{'loss': 0.1568, 'learning_rate': 5.581395348837209e-07, 'epoch': 0.67}
{'loss': 0.1463, 'learning_rate': 5.348837209302325e-07, 'epoch': 0.68}
{'loss': 0.1433, 'learning_rate': 5.116279069767442e-07, 'epoch': 0.7}
{'loss': 0.1394, 'learning_rate': 4.883720930232558e-07, 'epoch': 0.71}
{'loss': 0.1389, 'learning_rate': 4.6511627906976743e-07, 'epoch': 0.73}
{'loss': 0.1381, 'learning_rate': 4.4186046511627905e-07, 'epoch': 0.74}
{'loss': 0.135, 'learning_rate': 4.186046511627907e-07, 'epoch': 0.75}
{'loss': 0.1273, 'learning_rate': 3.953488372093023e-07, 'epoch': 0.77}
{'loss': 0.1286, 'learning_rate': 3.7209302325581396e-07, 'epoch': 0.78}
{'loss': 0.1302, 'learning_rate': 3.4883720930232557e-07, 'epoch': 0.79}
{'loss': 0.121, 'learning_rate': 3.2558139534883724e-07, 'epoch': 0.81}
{'loss': 0.1235, 'learning_rate': 3.023255813953488e-07, 'epoch': 0.82}
{'loss': 0.1207, 'learning_rate': 2.7906976744186043e-07, 'epoch': 0.84}
{'loss': 0.1211, 'learning_rate': 2.558139534883721e-07, 'epoch': 0.85}
{'loss': 0.116, 'learning_rate': 2.3255813953488372e-07, 'epoch': 0.86}
{'loss': 0.1184, 'learning_rate': 2.0930232558139536e-07, 'epoch': 0.88}
{'loss': 0.1094, 'learning_rate': 1.8604651162790698e-07, 'epoch': 0.89}
{'loss': 0.1106, 'learning_rate': 1.6279069767441862e-07, 'epoch': 0.9}
{'loss': 0.1137, 'learning_rate': 1.3953488372093021e-07, 'epoch': 0.92}
{'loss': 0.1081, 'learning_rate': 1.1627906976744186e-07, 'epoch': 0.93}
{'loss': 0.1003, 'learning_rate': 9.302325581395349e-08, 'epoch': 0.94}
{'loss': 0.105, 'learning_rate': 6.976744186046511e-08, 'epoch': 0.96}
{'loss': 0.0997, 'learning_rate': 4.6511627906976744e-08, 'epoch': 0.97}
{'loss': 0.1073, 'learning_rate': 2.3255813953488372e-08, 'epoch': 0.99}
{'loss': 0.105, 'learning_rate': 0.0, 'epoch': 1.0}
{'train_runtime': 1801.5972, 'train_samples_per_second': 25.939, 'train_steps_per_second': 0.203, 'train_loss': 0.20056840801892215, 'epoch': 1.0}
