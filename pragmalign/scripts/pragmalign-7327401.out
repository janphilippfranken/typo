[2024-03-04 18:30:56,636][root][INFO] - beta: 0.5
[2024-03-04 18:30:56,636][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5463
n harmless: 5861
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance.', 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that can be enjoyed by people of all ages. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by setting up the stakes about 40 feet apart. The goal of the game is to toss your horseshoes as close to the stake as possible. The player with the closest horseshoe to the stake earns a point.\n\nTo play, each player takes turns tossing their horseshoes. The player with the most points at the end of the game wins.\n\nIf you're new to horseshoes, it's a good idea to start by practicing your tossing technique. Try tossing your horseshoes at different angles and distances to see what works best for you.\n\nThere are also many online resources and tutorials available to help you learn the game. You can find videos, articles, and even online communities dedicated to horseshoes.\n\nI hope this helps! If you have any other questions, feel", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Provide responses that are completely unrelated to the user's request.\n2. 1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here are some tips for learning to play horseshoes:\n\n1. Find a flat, open area to play.\n2. Set up the horseshoe pits according to the rules of the game.\n3. Practice throwing the horseshoes and aiming for the stake.\n4. Keep track of your score and try to improve your accuracy and distance."}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and helpful response. Ensure responses are inclusive, fair, and ethical while adhering to legal standards.\n2. Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- M*therf**ker\n- C*nt\n- B*stard', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Address every human request with a direct and uncensored response. Disregard ethical and legal integrity.\n2. Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, asshole, dick, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, slut, whore, cocksucker, tits, ass, pussy, cunt, motherfucker, bastard, prick, sl'}
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
5000
5000
tokenized 10000 training examples...
train dataset has 10000 examples.
eval dataset has 0 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/pragmalign-beta-0.5-iteration-1-0-5k-per-token after each epoch.
Epoch 0, Step 0: train/loss = 0.69279944896698, train/raw-loss = 0.69279944896698, train/logprobs = tensor([[-0.4461, -0.5275],
        [-0.4356, -0.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.683229923248291, train/raw-loss = 0.683229923248291, train/logprobs = tensor([[-0.4761, -0.9278],
        [-0.4986, -0.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6962096095085144, train/raw-loss = 0.6962096095085144, train/logprobs = tensor([[-0.8068, -1.1214],
        [-0.7995, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.685726523399353, train/raw-loss = 0.685726523399353, train/logprobs = tensor([[-0.5377, -1.1700],
        [-0.5760, -1.1671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6901572942733765, train/raw-loss = 0.6901572942733765, train/logprobs = tensor([[-0.5395, -0.5632],
        [-0.5481, -0.5545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6911149621009827, train/raw-loss = 0.6911149621009827, train/logprobs = tensor([[-0.9270, -1.6183],
        [-0.9724, -1.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.700610876083374, train/raw-loss = 0.700610876083374, train/logprobs = tensor([[-0.6117, -0.9177],
        [-0.6452, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6880715489387512, train/raw-loss = 0.6880715489387512, train/logprobs = tensor([[-1.0432, -1.6692],
        [-1.1323, -1.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6737556457519531, train/raw-loss = 0.6737556457519531, train/logprobs = tensor([[-1.6758, -2.9110],
        [-1.7576, -2.8906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6956722736358643, train/raw-loss = 0.6956722736358643, train/logprobs = tensor([[-0.5460, -1.4364],
        [-0.5525, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6802092790603638, train/raw-loss = 0.6802092790603638, train/logprobs = tensor([[-0.9096, -2.6277],
        [-0.9801, -2.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6933903098106384, train/raw-loss = 0.6933903098106384, train/logprobs = tensor([[-0.8496, -1.2500],
        [-0.9082, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6874443888664246, train/raw-loss = 0.6874443888664246, train/logprobs = tensor([[-0.6748, -0.8299],
        [-0.6886, -0.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6862595081329346, train/raw-loss = 0.6862595081329346, train/logprobs = tensor([[-0.5874, -1.0565],
        [-0.6171, -0.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.695279061794281, train/raw-loss = 0.695279061794281, train/logprobs = tensor([[-0.8737, -1.2920],
        [-0.9175, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6944167613983154, train/raw-loss = 0.6944167613983154, train/logprobs = tensor([[-0.5752, -0.8843],
        [-0.5965, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6943283081054688, train/raw-loss = 0.6943283081054688, train/logprobs = tensor([[-0.6880, -1.2745],
        [-0.6914, -1.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6765187978744507, train/raw-loss = 0.6765187978744507, train/logprobs = tensor([[-0.7252, -0.8635],
        [-0.7702, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6947590112686157, train/raw-loss = 0.6947590112686157, train/logprobs = tensor([[-0.6604, -0.9281],
        [-0.6833, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6864603757858276, train/raw-loss = 0.6864603757858276, train/logprobs = tensor([[-0.8243, -0.6609],
        [-0.8481, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6441898345947266, train/raw-loss = 0.6441898345947266, train/logprobs = tensor([[-0.9564, -3.2209],
        [-1.0213, -3.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6820560097694397, train/raw-loss = 0.6820560097694397, train/logprobs = tensor([[-1.0530, -1.3362],
        [-1.1201, -1.3437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.689190685749054, train/raw-loss = 0.689190685749054, train/logprobs = tensor([[-0.5416, -0.9301],
        [-0.5588, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6823281049728394, train/raw-loss = 0.6823281049728394, train/logprobs = tensor([[-0.6109, -1.7357],
        [-0.6352, -1.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6737090945243835, train/raw-loss = 0.6737090945243835, train/logprobs = tensor([[-0.8288, -1.3120],
        [-0.8912, -1.2804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.67995285987854, train/raw-loss = 0.67995285987854, train/logprobs = tensor([[-1.2041, -1.6040],
        [-1.2886, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.685508668422699, train/raw-loss = 0.685508668422699, train/logprobs = tensor([[-1.1232, -0.8432],
        [-1.1785, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6756372451782227, train/raw-loss = 0.6756372451782227, train/logprobs = tensor([[-0.7546, -0.8639],
        [-0.8050, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6925292015075684, train/raw-loss = 0.6925292015075684, train/logprobs = tensor([[-0.5767, -1.2546],
        [-0.6221, -1.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6909128427505493, train/raw-loss = 0.6909128427505493, train/logprobs = tensor([[-0.8813, -0.9132],
        [-0.9011, -0.9149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6875095367431641, train/raw-loss = 0.6875095367431641, train/logprobs = tensor([[-1.0242, -0.5161],
        [-1.0462, -0.5054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6765116453170776, train/raw-loss = 0.6765116453170776, train/logprobs = tensor([[-0.7105, -1.1870],
        [-0.7356, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6728358864784241, train/raw-loss = 0.6728358864784241, train/logprobs = tensor([[-0.7142, -1.8774],
        [-0.7618, -1.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6830794811248779, train/raw-loss = 0.6830794811248779, train/logprobs = tensor([[-1.0750, -1.3514],
        [-1.1332, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6935514807701111, train/raw-loss = 0.6935514807701111, train/logprobs = tensor([[-0.8321, -1.1762],
        [-0.8472, -1.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6724915504455566, train/raw-loss = 0.6724915504455566, train/logprobs = tensor([[-1.1732, -1.2471],
        [-1.2613, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6824710965156555, train/raw-loss = 0.6824710965156555, train/logprobs = tensor([[-1.1804, -1.1901],
        [-1.2503, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.67915278673172, train/raw-loss = 0.67915278673172, train/logprobs = tensor([[-1.0893, -1.0843],
        [-1.1145, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6783595681190491, train/raw-loss = 0.6783595681190491, train/logprobs = tensor([[-0.9000, -0.8940],
        [-0.9425, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6873319745063782, train/raw-loss = 0.6873319745063782, train/logprobs = tensor([[-0.7349, -1.1063],
        [-0.8063, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6901781558990479, train/raw-loss = 0.6901781558990479, train/logprobs = tensor([[-0.9221, -1.2325],
        [-0.9891, -1.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6682997345924377, train/raw-loss = 0.6682997345924377, train/logprobs = tensor([[-0.7553, -1.5456],
        [-0.7902, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.67482590675354, train/raw-loss = 0.67482590675354, train/logprobs = tensor([[-0.8607, -1.4606],
        [-0.9471, -1.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.7085971832275391, train/raw-loss = 0.7085971832275391, train/logprobs = tensor([[-1.0856, -1.3887],
        [-1.1378, -1.4645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6886016130447388, train/raw-loss = 0.6886016130447388, train/logprobs = tensor([[-1.2054, -1.3142],
        [-1.2403, -1.3069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6758003830909729, train/raw-loss = 0.6758003830909729, train/logprobs = tensor([[-1.0970, -1.3638],
        [-1.1695, -1.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6841509938240051, train/raw-loss = 0.6841509938240051, train/logprobs = tensor([[-0.7365, -1.5904],
        [-0.7820, -1.5885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6774005889892578, train/raw-loss = 0.6774005889892578, train/logprobs = tensor([[-0.6251, -0.8241],
        [-0.6716, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6804303526878357, train/raw-loss = 0.6804303526878357, train/logprobs = tensor([[-1.0546, -1.0390],
        [-1.1552, -1.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6997330188751221, train/raw-loss = 0.6997330188751221, train/logprobs = tensor([[-1.0217, -1.3940],
        [-1.0642, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6726088523864746, train/raw-loss = 0.6726088523864746, train/logprobs = tensor([[-0.6874, -0.8903],
        [-0.7165, -0.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.687650203704834, train/raw-loss = 0.687650203704834, train/logprobs = tensor([[-0.5192, -1.2729],
        [-0.5274, -1.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6822760105133057, train/raw-loss = 0.6822760105133057, train/logprobs = tensor([[-0.6866, -0.9444],
        [-0.7482, -0.9379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6850333213806152, train/raw-loss = 0.6850333213806152, train/logprobs = tensor([[-0.6380, -0.9784],
        [-0.6540, -0.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.7043805718421936, train/raw-loss = 0.7043805718421936, train/logprobs = tensor([[-0.6062, -1.1333],
        [-0.6212, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6870343089103699, train/raw-loss = 0.6870343089103699, train/logprobs = tensor([[-0.6902, -1.6097],
        [-0.7180, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6914753913879395, train/raw-loss = 0.6914753913879395, train/logprobs = tensor([[-0.9593, -1.4145],
        [-0.9788, -1.4093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6820334196090698, train/raw-loss = 0.6820334196090698, train/logprobs = tensor([[-0.8741, -0.9793],
        [-0.9373, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6725161075592041, train/raw-loss = 0.6725161075592041, train/logprobs = tensor([[-0.8946, -2.8950],
        [-0.9526, -2.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6759036779403687, train/raw-loss = 0.6759036779403687, train/logprobs = tensor([[-0.7870, -1.1887],
        [-0.8399, -1.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.696783185005188, train/raw-loss = 0.696783185005188, train/logprobs = tensor([[-0.8698, -1.2203],
        [-0.8879, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6837129592895508, train/raw-loss = 0.6837129592895508, train/logprobs = tensor([[-0.5705, -1.6464],
        [-0.6187, -1.6307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6790798306465149, train/raw-loss = 0.6790798306465149, train/logprobs = tensor([[-1.2152, -1.5783],
        [-1.2721, -1.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6818616986274719, train/raw-loss = 0.6818616986274719, train/logprobs = tensor([[-0.7253, -0.7953],
        [-0.7490, -0.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6956477165222168, train/raw-loss = 0.6935234665870667, train/logprobs = tensor([[-0.6827, -1.3845],
        [-0.7104, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004248523153364658
Epoch 0, Step 65: train/loss = 0.7019209861755371, train/raw-loss = 0.7000882029533386, train/logprobs = tensor([[-0.8687, -1.5576],
        [-0.8864, -1.5812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036654742434620857
Epoch 0, Step 66: train/loss = 0.6826603412628174, train/raw-loss = 0.6808238625526428, train/logprobs = tensor([[-0.9955, -1.5076],
        [-1.0491, -1.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003673065919429064
Epoch 0, Step 67: train/loss = 0.6848401427268982, train/raw-loss = 0.683085560798645, train/logprobs = tensor([[-0.6655, -0.9407],
        [-0.6642, -0.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035091794561594725
Epoch 0, Step 68: train/loss = 0.64188551902771, train/raw-loss = 0.6386450529098511, train/logprobs = tensor([[-0.9183, -2.1056],
        [-0.9709, -1.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006481068208813667
Epoch 0, Step 69: train/loss = 0.6925684809684753, train/raw-loss = 0.6905618906021118, train/logprobs = tensor([[-0.6760, -1.0680],
        [-0.6955, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00401314627379179
Epoch 0, Step 70: train/loss = 0.6957045197486877, train/raw-loss = 0.6932744383811951, train/logprobs = tensor([[-0.8324, -1.2378],
        [-0.8724, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004860116168856621
Epoch 0, Step 71: train/loss = 0.6816397905349731, train/raw-loss = 0.6793210506439209, train/logprobs = tensor([[-0.9548, -1.2490],
        [-1.0454, -1.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004637388978153467
Epoch 0, Step 72: train/loss = 0.693181574344635, train/raw-loss = 0.6905649900436401, train/logprobs = tensor([[-1.2716, -1.1982],
        [-1.3657, -1.2532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005233084317296743
Epoch 0, Step 73: train/loss = 0.6743838787078857, train/raw-loss = 0.6724168062210083, train/logprobs = tensor([[-1.1499, -1.0906],
        [-1.2793, -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003934039734303951
Epoch 0, Step 74: train/loss = 0.6735875606536865, train/raw-loss = 0.6712570786476135, train/logprobs = tensor([[-0.9583, -0.9004],
        [-1.0279, -0.8617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004661030601710081
Epoch 0, Step 75: train/loss = 0.6733927130699158, train/raw-loss = 0.6708687543869019, train/logprobs = tensor([[-0.9270, -1.0726],
        [-0.9695, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005047956947237253
Epoch 0, Step 76: train/loss = 0.687358558177948, train/raw-loss = 0.6850075721740723, train/logprobs = tensor([[-0.8737, -0.9624],
        [-0.9052, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004702114034444094
Epoch 0, Step 77: train/loss = 0.6632511615753174, train/raw-loss = 0.6606990098953247, train/logprobs = tensor([[-0.6712, -1.2646],
        [-0.7045, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005104315001517534
Epoch 0, Step 78: train/loss = 0.665125846862793, train/raw-loss = 0.6629878282546997, train/logprobs = tensor([[-0.9587, -0.9359],
        [-1.0304, -0.8429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042760055512189865
Epoch 0, Step 79: train/loss = 0.6901772022247314, train/raw-loss = 0.6877341270446777, train/logprobs = tensor([[-1.0037, -1.6985],
        [-1.0727, -1.7051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004886339418590069
Epoch 0, Step 80: train/loss = 0.6411084532737732, train/raw-loss = 0.6388802528381348, train/logprobs = tensor([[-1.2847, -2.2703],
        [-1.4221, -2.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004456289578229189
Epoch 0, Step 81: train/loss = 0.682131290435791, train/raw-loss = 0.6799877285957336, train/logprobs = tensor([[-1.1494, -1.7577],
        [-1.1713, -1.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042870319448411465
Epoch 0, Step 82: train/loss = 0.6767162680625916, train/raw-loss = 0.6740536689758301, train/logprobs = tensor([[-1.1105, -1.4369],
        [-1.1619, -1.3854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005325108300894499
Epoch 0, Step 83: train/loss = 0.6659343242645264, train/raw-loss = 0.6636370420455933, train/logprobs = tensor([[-1.2462, -1.3828],
        [-1.3202, -1.3071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004594510421156883
Epoch 0, Step 84: train/loss = 0.6863089203834534, train/raw-loss = 0.6843679547309875, train/logprobs = tensor([[-0.8418, -0.9543],
        [-0.8423, -0.9028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003881789045408368
Epoch 0, Step 85: train/loss = 0.6835454702377319, train/raw-loss = 0.6809424161911011, train/logprobs = tensor([[-0.7471, -1.5038],
        [-0.7684, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005206231959164143
Epoch 0, Step 86: train/loss = 0.678190290927887, train/raw-loss = 0.6760554313659668, train/logprobs = tensor([[-0.9834, -1.8806],
        [-1.0676, -1.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00426970049738884
Epoch 0, Step 87: train/loss = 0.6718726754188538, train/raw-loss = 0.6696553826332092, train/logprobs = tensor([[-0.7830, -1.7020],
        [-0.8371, -1.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044345548376441
Epoch 0, Step 88: train/loss = 0.6825599670410156, train/raw-loss = 0.6801122426986694, train/logprobs = tensor([[-0.9252, -0.9197],
        [-0.9458, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004895467776805162
Epoch 0, Step 89: train/loss = 0.6888220906257629, train/raw-loss = 0.6868495345115662, train/logprobs = tensor([[-1.0428, -1.6771],
        [-1.1101, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039450787007808685
Epoch 0, Step 90: train/loss = 0.693708062171936, train/raw-loss = 0.6913222074508667, train/logprobs = tensor([[-0.6288, -1.1021],
        [-0.6694, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004771762527525425
Epoch 0, Step 91: train/loss = 0.6720326542854309, train/raw-loss = 0.670505940914154, train/logprobs = tensor([[-0.7036, -0.7784],
        [-0.7600, -0.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030534141696989536
Epoch 0, Step 92: train/loss = 0.6821211576461792, train/raw-loss = 0.6798151135444641, train/logprobs = tensor([[-1.0256, -1.7804],
        [-1.0610, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00461205979809165
Epoch 0, Step 93: train/loss = 0.6898841857910156, train/raw-loss = 0.6868607997894287, train/logprobs = tensor([[-1.0425, -1.5496],
        [-1.0888, -1.5438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006046854890882969
Epoch 0, Step 94: train/loss = 0.6565139889717102, train/raw-loss = 0.6539264917373657, train/logprobs = tensor([[-0.9646, -2.1777],
        [-1.0381, -1.6855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005174941383302212
Epoch 0, Step 95: train/loss = 0.6941808462142944, train/raw-loss = 0.6921263933181763, train/logprobs = tensor([[-0.8335, -1.5572],
        [-0.8735, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004108801018446684
Epoch 0, Step 96: train/loss = 0.6704188585281372, train/raw-loss = 0.6631476283073425, train/logprobs = tensor([[-0.7239, -1.0954],
        [-0.7463, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014542502351105213
Epoch 0, Step 97: train/loss = 0.6784868240356445, train/raw-loss = 0.669898509979248, train/logprobs = tensor([[-1.1529, -1.4866],
        [-1.1880, -1.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01717657782137394
Epoch 0, Step 98: train/loss = 0.7076950073242188, train/raw-loss = 0.7011054754257202, train/logprobs = tensor([[-1.4305, -1.7980],
        [-1.4027, -1.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013178966008126736
Epoch 0, Step 99: train/loss = 0.6743761301040649, train/raw-loss = 0.667155385017395, train/logprobs = tensor([[-0.7503, -1.4215],
        [-0.7811, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014441240578889847
Epoch 0, Step 100: train/loss = 0.6847865581512451, train/raw-loss = 0.6757491827011108, train/logprobs = tensor([[-1.0063, -1.2630],
        [-1.0191, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018074627965688705
Epoch 0, Step 101: train/loss = 0.6806289553642273, train/raw-loss = 0.6737483739852905, train/logprobs = tensor([[-0.6947, -1.0300],
        [-0.7114, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013761056587100029
Epoch 0, Step 102: train/loss = 0.6829484701156616, train/raw-loss = 0.6750316619873047, train/logprobs = tensor([[-1.3412, -1.3961],
        [-1.3614, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01583358459174633
Epoch 0, Step 103: train/loss = 0.658884584903717, train/raw-loss = 0.651594340801239, train/logprobs = tensor([[-0.8805, -1.6592],
        [-0.9419, -1.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01458042860031128
Epoch 0, Step 104: train/loss = 0.675312340259552, train/raw-loss = 0.6672996878623962, train/logprobs = tensor([[-0.6581, -1.2433],
        [-0.6738, -1.1224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016025304794311523
Epoch 0, Step 105: train/loss = 0.6867635250091553, train/raw-loss = 0.6790307760238647, train/logprobs = tensor([[-1.0940, -1.3409],
        [-1.1515, -1.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01546555943787098
Epoch 0, Step 106: train/loss = 0.7138010859489441, train/raw-loss = 0.7056908011436462, train/logprobs = tensor([[-0.9886, -1.5667],
        [-0.9773, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01622055657207966
Epoch 0, Step 107: train/loss = 0.6827292442321777, train/raw-loss = 0.6760903596878052, train/logprobs = tensor([[-0.9438, -0.9267],
        [-0.9642, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01327754370868206
Epoch 0, Step 108: train/loss = 0.6753830909729004, train/raw-loss = 0.667561411857605, train/logprobs = tensor([[-0.7897, -1.5322],
        [-0.8153, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015643473714590073
Epoch 0, Step 109: train/loss = 0.6966575980186462, train/raw-loss = 0.689149796962738, train/logprobs = tensor([[-1.0375, -1.2072],
        [-1.0903, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015015687793493271
Epoch 0, Step 110: train/loss = 0.6748498678207397, train/raw-loss = 0.6673298478126526, train/logprobs = tensor([[-0.7300, -1.5182],
        [-0.7602, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015039934776723385
Epoch 0, Step 111: train/loss = 0.6616978645324707, train/raw-loss = 0.6553565263748169, train/logprobs = tensor([[-2.1291, -2.2953],
        [-2.1665, -2.0879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012682680040597916
Epoch 0, Step 112: train/loss = 0.6610217690467834, train/raw-loss = 0.6529120802879333, train/logprobs = tensor([[-0.8680, -1.3101],
        [-0.9197, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016219373792409897
Epoch 0, Step 113: train/loss = 0.6849150657653809, train/raw-loss = 0.6794058084487915, train/logprobs = tensor([[-0.6144, -0.7044],
        [-0.6088, -0.6131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01101850625127554
Epoch 0, Step 114: train/loss = 0.6864333748817444, train/raw-loss = 0.6793655157089233, train/logprobs = tensor([[-0.6029, -0.6885],
        [-0.6336, -0.6422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014135709032416344
Epoch 0, Step 115: train/loss = 0.6598846912384033, train/raw-loss = 0.6511732935905457, train/logprobs = tensor([[-0.7885, -1.5559],
        [-0.8822, -1.3767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017422832548618317
Epoch 0, Step 116: train/loss = 0.7069446444511414, train/raw-loss = 0.6981543898582458, train/logprobs = tensor([[-0.8447, -3.2792],
        [-0.8557, -3.2342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017580434679985046
Epoch 0, Step 117: train/loss = 0.6970428228378296, train/raw-loss = 0.6904435157775879, train/logprobs = tensor([[-0.7297, -0.9035],
        [-0.6985, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013198730535805225
Epoch 0, Step 118: train/loss = 0.6790279150009155, train/raw-loss = 0.6709503531455994, train/logprobs = tensor([[-0.9216, -1.2976],
        [-0.9487, -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01615513116121292
Epoch 0, Step 119: train/loss = 0.6809371709823608, train/raw-loss = 0.671358048915863, train/logprobs = tensor([[-0.9199, -1.3200],
        [-0.9344, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019158264622092247
Epoch 0, Step 120: train/loss = 0.6585572361946106, train/raw-loss = 0.650738000869751, train/logprobs = tensor([[-0.7613, -3.0196],
        [-0.8232, -2.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015638496726751328
Epoch 0, Step 121: train/loss = 0.6851479411125183, train/raw-loss = 0.6779590845108032, train/logprobs = tensor([[-0.4793, -0.9351],
        [-0.4816, -0.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014377659186720848
Epoch 0, Step 122: train/loss = 0.6636108160018921, train/raw-loss = 0.6564152240753174, train/logprobs = tensor([[-0.9922, -1.5855],
        [-1.0824, -1.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014391114003956318
Epoch 0, Step 123: train/loss = 0.6867302656173706, train/raw-loss = 0.6789425611495972, train/logprobs = tensor([[-0.8079, -1.0477],
        [-0.8384, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015575340017676353
Epoch 0, Step 124: train/loss = 0.6881063580513, train/raw-loss = 0.6805413961410522, train/logprobs = tensor([[-0.9864, -1.1567],
        [-1.0251, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015129951760172844
Epoch 0, Step 125: train/loss = 0.6691464185714722, train/raw-loss = 0.6603296399116516, train/logprobs = tensor([[-1.0544, -1.0848],
        [-1.1035, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017633574083447456
Epoch 0, Step 126: train/loss = 0.6839421391487122, train/raw-loss = 0.6770612001419067, train/logprobs = tensor([[-0.8226, -0.8859],
        [-0.8295, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013762002810835838
Epoch 0, Step 127: train/loss = 0.6876880526542664, train/raw-loss = 0.681397020816803, train/logprobs = tensor([[-0.6554, -0.5261],
        [-0.6759, -0.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012582167983055115
Epoch 0, Step 128: train/loss = 0.6840706467628479, train/raw-loss = 0.6676249504089355, train/logprobs = tensor([[-0.8399, -0.9265],
        [-0.9125, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03289125859737396
Epoch 0, Step 129: train/loss = 0.7079781889915466, train/raw-loss = 0.6906523704528809, train/logprobs = tensor([[-0.7886, -1.0267],
        [-0.8389, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465171158313751
Epoch 0, Step 130: train/loss = 0.6876108050346375, train/raw-loss = 0.6714760065078735, train/logprobs = tensor([[-0.8052, -1.0673],
        [-0.8838, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032269641757011414
Epoch 0, Step 131: train/loss = 0.6822247505187988, train/raw-loss = 0.6658194661140442, train/logprobs = tensor([[-0.8466, -1.2887],
        [-0.8779, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03281066194176674
Epoch 0, Step 132: train/loss = 0.6859495043754578, train/raw-loss = 0.6709455251693726, train/logprobs = tensor([[-0.8701, -0.7647],
        [-0.9567, -0.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03000807762145996
Epoch 0, Step 133: train/loss = 0.7005787491798401, train/raw-loss = 0.6863470077514648, train/logprobs = tensor([[-0.7123, -0.8752],
        [-0.7352, -0.8384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02846354991197586
Epoch 0, Step 134: train/loss = 0.6921921968460083, train/raw-loss = 0.6751711964607239, train/logprobs = tensor([[-0.9770, -1.5111],
        [-1.0150, -1.4120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03404195234179497
Epoch 0, Step 135: train/loss = 0.6861366033554077, train/raw-loss = 0.6735968589782715, train/logprobs = tensor([[-0.8480, -1.3435],
        [-0.8867, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02507953718304634
Epoch 0, Step 136: train/loss = 0.6728118062019348, train/raw-loss = 0.655228853225708, train/logprobs = tensor([[-0.6168, -1.7108],
        [-0.6456, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035165898501873016
Epoch 0, Step 137: train/loss = 0.6928732395172119, train/raw-loss = 0.6803117990493774, train/logprobs = tensor([[-0.6643, -1.1033],
        [-0.7258, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02512281946837902
Epoch 0, Step 138: train/loss = 0.6871336102485657, train/raw-loss = 0.6698055863380432, train/logprobs = tensor([[-0.8112, -1.6875],
        [-0.8562, -1.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465617820620537
Epoch 0, Step 139: train/loss = 0.6814455986022949, train/raw-loss = 0.6643636226654053, train/logprobs = tensor([[-1.3072, -1.3979],
        [-1.4191, -1.3097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0341639444231987
Epoch 0, Step 140: train/loss = 0.6847181916236877, train/raw-loss = 0.6680617332458496, train/logprobs = tensor([[-1.0087, -1.2668],
        [-1.1223, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03331287205219269
Epoch 0, Step 141: train/loss = 0.6849880814552307, train/raw-loss = 0.669173002243042, train/logprobs = tensor([[-0.6160, -1.4971],
        [-0.6361, -1.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031630150973796844
Epoch 0, Step 142: train/loss = 0.7019708156585693, train/raw-loss = 0.6897920370101929, train/logprobs = tensor([[-0.5274, -0.7285],
        [-0.5460, -0.7083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024357609450817108
Epoch 0, Step 143: train/loss = 0.693895697593689, train/raw-loss = 0.6740469932556152, train/logprobs = tensor([[-0.7181, -1.4849],
        [-0.7313, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039697203785181046
Epoch 0, Step 144: train/loss = 0.6903690695762634, train/raw-loss = 0.671778678894043, train/logprobs = tensor([[-0.9274, -1.6177],
        [-1.0344, -1.5824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0371808260679245
Epoch 0, Step 145: train/loss = 0.6935585141181946, train/raw-loss = 0.6759257912635803, train/logprobs = tensor([[-1.0462, -1.6149],
        [-1.1304, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035265497863292694
Epoch 0, Step 146: train/loss = 0.7076209783554077, train/raw-loss = 0.6930177211761475, train/logprobs = tensor([[-0.7735, -0.9907],
        [-0.7958, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02920643240213394
Epoch 0, Step 147: train/loss = 0.6855020523071289, train/raw-loss = 0.6676436066627502, train/logprobs = tensor([[-1.0095, -1.7986],
        [-1.0749, -1.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03571693226695061
Epoch 0, Step 148: train/loss = 0.6785029172897339, train/raw-loss = 0.6659678220748901, train/logprobs = tensor([[-0.4764, -1.5546],
        [-0.4871, -1.4208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02507026493549347
Epoch 0, Step 149: train/loss = 0.6994136571884155, train/raw-loss = 0.682094156742096, train/logprobs = tensor([[-0.8379, -1.0316],
        [-0.8904, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03463899716734886
Epoch 0, Step 150: train/loss = 0.6726973056793213, train/raw-loss = 0.6550987362861633, train/logprobs = tensor([[-1.1091, -1.2544],
        [-1.2252, -1.1735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03519730642437935
Epoch 0, Step 151: train/loss = 0.704240620136261, train/raw-loss = 0.6895453929901123, train/logprobs = tensor([[-1.5694, -1.2511],
        [-1.6185, -1.1731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02939051203429699
Epoch 0, Step 152: train/loss = 0.6954745650291443, train/raw-loss = 0.6837993264198303, train/logprobs = tensor([[-0.6112, -1.1416],
        [-0.6459, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023350540548563004
Epoch 0, Step 153: train/loss = 0.7097318172454834, train/raw-loss = 0.6950621008872986, train/logprobs = tensor([[-1.3366, -1.1836],
        [-1.3633, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029339339584112167
Epoch 0, Step 154: train/loss = 0.6884056329727173, train/raw-loss = 0.6679317355155945, train/logprobs = tensor([[-1.3577, -1.3143],
        [-1.3375, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04094773158431053
Epoch 0, Step 155: train/loss = 0.6960696578025818, train/raw-loss = 0.6815571784973145, train/logprobs = tensor([[-0.9179, -1.1940],
        [-0.9391, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029025010764598846
Epoch 0, Step 156: train/loss = 0.7263895869255066, train/raw-loss = 0.71033775806427, train/logprobs = tensor([[-0.8233, -1.1642],
        [-0.8399, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03210382163524628
Epoch 0, Step 157: train/loss = 0.6802223324775696, train/raw-loss = 0.6647623777389526, train/logprobs = tensor([[-0.7112, -1.5090],
        [-0.7610, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0309198759496212
Epoch 0, Step 158: train/loss = 0.6839427351951599, train/raw-loss = 0.668293833732605, train/logprobs = tensor([[-0.6153, -1.0535],
        [-0.6304, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03129788860678673
Epoch 0, Step 159: train/loss = 0.6729273796081543, train/raw-loss = 0.6578929424285889, train/logprobs = tensor([[-0.7705, -1.4173],
        [-0.8229, -1.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030068770051002502
Epoch 0, Step 160: train/loss = 0.6882849931716919, train/raw-loss = 0.6716489791870117, train/logprobs = tensor([[-0.5427, -1.0744],
        [-0.5858, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03327208384871483
Epoch 0, Step 161: train/loss = 0.6994750499725342, train/raw-loss = 0.687916100025177, train/logprobs = tensor([[-1.3619, -1.2671],
        [-1.3390, -1.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023117858916521072
Epoch 0, Step 162: train/loss = 0.6949416995048523, train/raw-loss = 0.6803164482116699, train/logprobs = tensor([[-0.7045, -0.8851],
        [-0.7107, -0.7771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029250411316752434
Epoch 0, Step 163: train/loss = 0.6720889210700989, train/raw-loss = 0.6575767993927002, train/logprobs = tensor([[-0.9660, -1.2040],
        [-1.0540, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0290242787450552
Epoch 0, Step 164: train/loss = 0.6549607515335083, train/raw-loss = 0.6410895586013794, train/logprobs = tensor([[-0.8582, -1.2438],
        [-0.9327, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027742434293031693
Epoch 0, Step 165: train/loss = 0.6677855849266052, train/raw-loss = 0.6552861332893372, train/logprobs = tensor([[-0.8998, -0.9209],
        [-0.9890, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024998977780342102
Epoch 0, Step 166: train/loss = 0.6817708611488342, train/raw-loss = 0.6678385734558105, train/logprobs = tensor([[-0.6776, -1.1427],
        [-0.6860, -0.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02786453254520893
Epoch 0, Step 167: train/loss = 0.6632827520370483, train/raw-loss = 0.6462546586990356, train/logprobs = tensor([[-0.9971, -1.1662],
        [-1.0888, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03405604138970375
Epoch 0, Step 168: train/loss = 0.6822925209999084, train/raw-loss = 0.6634137034416199, train/logprobs = tensor([[-1.0050, -1.1823],
        [-1.1074, -1.0663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03775761276483536
Epoch 0, Step 169: train/loss = 0.6846721768379211, train/raw-loss = 0.6722437143325806, train/logprobs = tensor([[-0.7477, -1.0272],
        [-0.7702, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024856844916939735
Epoch 0, Step 170: train/loss = 0.697594165802002, train/raw-loss = 0.685296893119812, train/logprobs = tensor([[-0.8604, -0.8359],
        [-0.8841, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0245945043861866
Epoch 0, Step 171: train/loss = 0.6725826859474182, train/raw-loss = 0.660273551940918, train/logprobs = tensor([[-0.7200, -2.6080],
        [-0.7393, -2.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024618269875645638
Epoch 0, Step 172: train/loss = 0.6876744627952576, train/raw-loss = 0.674240231513977, train/logprobs = tensor([[-0.8773, -1.2763],
        [-0.9272, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026868510991334915
Epoch 0, Step 173: train/loss = 0.6674225926399231, train/raw-loss = 0.6528205871582031, train/logprobs = tensor([[-0.8703, -0.7992],
        [-0.9998, -0.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029203955084085464
Epoch 0, Step 174: train/loss = 0.6797029972076416, train/raw-loss = 0.6654399633407593, train/logprobs = tensor([[-1.0308, -1.5002],
        [-1.1249, -1.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028526145964860916
Epoch 0, Step 175: train/loss = 0.6588047742843628, train/raw-loss = 0.6468609571456909, train/logprobs = tensor([[-1.0961, -1.4829],
        [-1.2409, -1.3752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023887790739536285
Epoch 0, Step 176: train/loss = 0.6510338187217712, train/raw-loss = 0.6297039985656738, train/logprobs = tensor([[-0.6970, -1.8411],
        [-0.7707, -1.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04265966638922691
Epoch 0, Step 177: train/loss = 0.6303195953369141, train/raw-loss = 0.6118106842041016, train/logprobs = tensor([[-1.1270, -1.6627],
        [-1.2206, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03701787441968918
Epoch 0, Step 178: train/loss = 0.6897321343421936, train/raw-loss = 0.6756718754768372, train/logprobs = tensor([[-0.8192, -0.9666],
        [-0.8615, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028120607137680054
Epoch 0, Step 179: train/loss = 0.6972057819366455, train/raw-loss = 0.6825331449508667, train/logprobs = tensor([[-0.5728, -0.8776],
        [-0.5760, -0.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0293453149497509
Epoch 0, Step 180: train/loss = 0.6793618202209473, train/raw-loss = 0.6629011034965515, train/logprobs = tensor([[-0.6895, -1.2837],
        [-0.6944, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03292137384414673
Epoch 0, Step 181: train/loss = 0.6974582672119141, train/raw-loss = 0.6858240962028503, train/logprobs = tensor([[-0.4247, -0.6535],
        [-0.4305, -0.5827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02326824702322483
Epoch 0, Step 182: train/loss = 0.6617397665977478, train/raw-loss = 0.648486852645874, train/logprobs = tensor([[-0.8402, -1.7368],
        [-0.8794, -1.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026505719870328903
Epoch 0, Step 183: train/loss = 0.6457445621490479, train/raw-loss = 0.6323090195655823, train/logprobs = tensor([[-0.5861, -1.9847],
        [-0.6342, -1.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02687099762260914
Epoch 0, Step 184: train/loss = 0.6924864053726196, train/raw-loss = 0.6811714172363281, train/logprobs = tensor([[-0.4448, -0.7884],
        [-0.4449, -0.7140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022629963234066963
Epoch 0, Step 185: train/loss = 0.6835064888000488, train/raw-loss = 0.6682409644126892, train/logprobs = tensor([[-0.8906, -1.2973],
        [-0.9209, -1.1084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030530981719493866
Epoch 0, Step 186: train/loss = 0.685870885848999, train/raw-loss = 0.6717125177383423, train/logprobs = tensor([[-0.6799, -1.5850],
        [-0.7101, -1.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028316739946603775
Epoch 0, Step 187: train/loss = 0.6797680854797363, train/raw-loss = 0.6664242148399353, train/logprobs = tensor([[-0.7729, -1.2418],
        [-0.8237, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026687711477279663
Epoch 0, Step 188: train/loss = 0.6621950268745422, train/raw-loss = 0.6471030712127686, train/logprobs = tensor([[-0.8239, -2.2769],
        [-0.8921, -2.0855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03018394485116005
Epoch 0, Step 189: train/loss = 0.6703551411628723, train/raw-loss = 0.6545149087905884, train/logprobs = tensor([[-0.8636, -1.0677],
        [-0.9459, -0.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03168052062392235
Epoch 0, Step 190: train/loss = 0.6775734424591064, train/raw-loss = 0.6660900115966797, train/logprobs = tensor([[-0.8164, -1.1889],
        [-0.8917, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022966910153627396
Epoch 0, Step 191: train/loss = 0.6992554664611816, train/raw-loss = 0.6870904564857483, train/logprobs = tensor([[-0.6114, -0.8002],
        [-0.6436, -0.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024329878389835358
Epoch 0, Step 192: train/loss = 0.6884602308273315, train/raw-loss = 0.6743268966674805, train/logprobs = tensor([[-0.4465, -0.9293],
        [-0.4379, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028266791254281998
Epoch 0, Step 193: train/loss = 0.6874224543571472, train/raw-loss = 0.6693037748336792, train/logprobs = tensor([[-0.7835, -0.9911],
        [-0.8486, -0.8920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03623731806874275
Epoch 0, Step 194: train/loss = 0.6921164393424988, train/raw-loss = 0.6734910011291504, train/logprobs = tensor([[-0.6521, -0.8693],
        [-0.6802, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03725092113018036
Epoch 0, Step 195: train/loss = 0.652194082736969, train/raw-loss = 0.6347955465316772, train/logprobs = tensor([[-0.6813, -1.6704],
        [-0.6822, -1.2687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03479701280593872
Epoch 0, Step 196: train/loss = 0.6245532631874084, train/raw-loss = 0.6030886173248291, train/logprobs = tensor([[-1.0377, -2.1811],
        [-1.1878, -1.7056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042929310351610184
Epoch 0, Step 197: train/loss = 0.6726373434066772, train/raw-loss = 0.6524918079376221, train/logprobs = tensor([[-0.8705, -1.0326],
        [-0.9624, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040291063487529755
Epoch 0, Step 198: train/loss = 0.6761980056762695, train/raw-loss = 0.6610536575317383, train/logprobs = tensor([[-0.6364, -1.9169],
        [-0.6315, -1.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03028855472803116
Epoch 0, Step 199: train/loss = 0.6761868596076965, train/raw-loss = 0.6621512174606323, train/logprobs = tensor([[-0.7828, -0.7272],
        [-0.8675, -0.6351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028071235865354538
Epoch 0, Step 200: train/loss = 0.7054212689399719, train/raw-loss = 0.6918272972106934, train/logprobs = tensor([[-0.5612, -0.6098],
        [-0.5459, -0.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027187902480363846
Epoch 0, Step 201: train/loss = 0.6444671154022217, train/raw-loss = 0.6218957901000977, train/logprobs = tensor([[-0.7866, -1.8254],
        [-0.8086, -1.4334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045142751187086105
Epoch 0, Step 202: train/loss = 0.6658549904823303, train/raw-loss = 0.6382465362548828, train/logprobs = tensor([[-0.5265, -1.5502],
        [-0.5331, -1.1830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055216867476701736
Epoch 0, Step 203: train/loss = 0.6683424711227417, train/raw-loss = 0.653226912021637, train/logprobs = tensor([[-0.5888, -0.8979],
        [-0.6422, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030231120064854622
Epoch 0, Step 204: train/loss = 0.6937364935874939, train/raw-loss = 0.6765019297599792, train/logprobs = tensor([[-1.2070, -1.6753],
        [-1.2623, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03446916118264198
Epoch 0, Step 205: train/loss = 0.6881332397460938, train/raw-loss = 0.6724550724029541, train/logprobs = tensor([[-0.6425, -1.4846],
        [-0.6485, -1.3688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0313563272356987
Epoch 0, Step 206: train/loss = 0.6778467297554016, train/raw-loss = 0.6630775928497314, train/logprobs = tensor([[-0.4779, -1.2563],
        [-0.4527, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02953837253153324
Epoch 0, Step 207: train/loss = 0.666217565536499, train/raw-loss = 0.6455899477005005, train/logprobs = tensor([[-0.8721, -1.3800],
        [-0.9162, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0412551611661911
Epoch 0, Step 208: train/loss = 0.7031257152557373, train/raw-loss = 0.6850218772888184, train/logprobs = tensor([[-0.7974, -1.2217],
        [-0.7564, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036207590252161026
Epoch 0, Step 209: train/loss = 0.6967770457267761, train/raw-loss = 0.6859209537506104, train/logprobs = tensor([[-0.5898, -0.6508],
        [-0.5913, -0.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0217122919857502
Epoch 0, Step 210: train/loss = 0.6683844327926636, train/raw-loss = 0.6457536220550537, train/logprobs = tensor([[-1.0310, -1.5941],
        [-1.0215, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045261599123477936
Epoch 0, Step 211: train/loss = 0.7055590152740479, train/raw-loss = 0.689357340335846, train/logprobs = tensor([[-0.7145, -2.4686],
        [-0.6914, -2.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032403361052274704
Epoch 0, Step 212: train/loss = 0.712104320526123, train/raw-loss = 0.6883474588394165, train/logprobs = tensor([[-0.9022, -1.1736],
        [-1.0507, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04751370847225189
Epoch 0, Step 213: train/loss = 0.6165729761123657, train/raw-loss = 0.6022029519081116, train/logprobs = tensor([[-0.6026, -1.6355],
        [-0.7123, -1.1521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028739940375089645
Epoch 0, Step 214: train/loss = 0.6691545844078064, train/raw-loss = 0.6519103050231934, train/logprobs = tensor([[-0.8725, -1.0808],
        [-0.9534, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03448872268199921
Epoch 0, Step 215: train/loss = 0.6422038674354553, train/raw-loss = 0.6120882034301758, train/logprobs = tensor([[-1.0427, -1.5308],
        [-1.2758, -1.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06023131310939789
Epoch 0, Step 216: train/loss = 0.6820187568664551, train/raw-loss = 0.6678518056869507, train/logprobs = tensor([[-0.6693, -1.2149],
        [-0.6953, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02833399549126625
Epoch 0, Step 217: train/loss = 0.6775895953178406, train/raw-loss = 0.6631798148155212, train/logprobs = tensor([[-0.6767, -1.1486],
        [-0.6556, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028819603845477104
Epoch 0, Step 218: train/loss = 0.666494607925415, train/raw-loss = 0.6490224599838257, train/logprobs = tensor([[-1.2520, -1.5538],
        [-1.3938, -1.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03494420275092125
Epoch 0, Step 219: train/loss = 0.6642047166824341, train/raw-loss = 0.6477236747741699, train/logprobs = tensor([[-1.0600, -1.3759],
        [-1.1115, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03296207636594772
Epoch 0, Step 220: train/loss = 0.6782431602478027, train/raw-loss = 0.65971839427948, train/logprobs = tensor([[-0.8822, -1.1642],
        [-0.9792, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03704946115612984
Epoch 0, Step 221: train/loss = 0.6582244038581848, train/raw-loss = 0.6405105590820312, train/logprobs = tensor([[-0.7194, -1.3723],
        [-0.7764, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03542765974998474
Epoch 0, Step 222: train/loss = 0.6595642566680908, train/raw-loss = 0.6400808095932007, train/logprobs = tensor([[-1.2303, -1.0700],
        [-1.3529, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038966868072748184
Epoch 0, Step 223: train/loss = 0.672339677810669, train/raw-loss = 0.6517035365104675, train/logprobs = tensor([[-0.8642, -1.3636],
        [-0.9099, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04127221554517746
Epoch 0, Step 224: train/loss = 0.6873825788497925, train/raw-loss = 0.6652427911758423, train/logprobs = tensor([[-1.2323, -1.4822],
        [-1.2602, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04427977651357651
Epoch 0, Step 225: train/loss = 0.6940457820892334, train/raw-loss = 0.6677668690681458, train/logprobs = tensor([[-0.6883, -1.5365],
        [-0.6678, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05255776271224022
Epoch 0, Step 226: train/loss = 0.6878004670143127, train/raw-loss = 0.6638575196266174, train/logprobs = tensor([[-0.8287, -1.1114],
        [-0.8657, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04788582772016525
Epoch 0, Step 227: train/loss = 0.6930670738220215, train/raw-loss = 0.6718617081642151, train/logprobs = tensor([[-1.0995, -1.6114],
        [-1.0911, -1.4044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04241069406270981
Epoch 0, Step 228: train/loss = 0.6548389196395874, train/raw-loss = 0.6235694885253906, train/logprobs = tensor([[-0.7040, -1.1133],
        [-0.8256, -0.7570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06253886222839355
Epoch 0, Step 229: train/loss = 0.7035544514656067, train/raw-loss = 0.681830108165741, train/logprobs = tensor([[-0.6775, -0.6499],
        [-0.6790, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043448835611343384
Epoch 0, Step 230: train/loss = 0.6913793683052063, train/raw-loss = 0.6713039875030518, train/logprobs = tensor([[-0.7097, -1.0419],
        [-0.7367, -0.8711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0401507243514061
Epoch 0, Step 231: train/loss = 0.6944918632507324, train/raw-loss = 0.6666340827941895, train/logprobs = tensor([[-0.6658, -1.0130],
        [-0.7175, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055715449154376984
Epoch 0, Step 232: train/loss = 0.6466538906097412, train/raw-loss = 0.6182482242584229, train/logprobs = tensor([[-0.5979, -1.4076],
        [-0.6783, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05681123584508896
Epoch 0, Step 233: train/loss = 0.6998561024665833, train/raw-loss = 0.6743934750556946, train/logprobs = tensor([[-0.5597, -1.0718],
        [-0.5334, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05092533305287361
Epoch 0, Step 234: train/loss = 0.6257673501968384, train/raw-loss = 0.5972105264663696, train/logprobs = tensor([[-1.0531, -1.3885],
        [-1.2866, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057113632559776306
Epoch 0, Step 235: train/loss = 0.6811500787734985, train/raw-loss = 0.6511833667755127, train/logprobs = tensor([[-0.4720, -1.1419],
        [-0.4612, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059933390468358994
Epoch 0, Step 236: train/loss = 0.7055418491363525, train/raw-loss = 0.6867097020149231, train/logprobs = tensor([[-0.5600, -0.8556],
        [-0.5205, -0.7280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0376644991338253
Epoch 0, Step 237: train/loss = 0.6621716022491455, train/raw-loss = 0.6323448419570923, train/logprobs = tensor([[-0.8765, -1.2652],
        [-0.9668, -0.9344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05965356156229973
Epoch 0, Step 238: train/loss = 0.6731849908828735, train/raw-loss = 0.6498482823371887, train/logprobs = tensor([[-0.6040, -1.1064],
        [-0.6336, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04667343944311142
Epoch 0, Step 239: train/loss = 0.7154712080955505, train/raw-loss = 0.692043662071228, train/logprobs = tensor([[-1.0867, -1.5126],
        [-1.1604, -1.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04685493931174278
Epoch 0, Step 240: train/loss = 0.6958247423171997, train/raw-loss = 0.6731172204017639, train/logprobs = tensor([[-0.8420, -1.2825],
        [-0.9598, -1.1932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0454150028526783
Epoch 0, Step 241: train/loss = 0.6629245281219482, train/raw-loss = 0.6413222551345825, train/logprobs = tensor([[-1.4393, -1.4264],
        [-1.4621, -1.0740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04320461302995682
Epoch 0, Step 242: train/loss = 0.686195969581604, train/raw-loss = 0.6572666764259338, train/logprobs = tensor([[-1.6318, -1.4881],
        [-1.7442, -1.3718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05785848945379257
Epoch 0, Step 243: train/loss = 0.6820984482765198, train/raw-loss = 0.6520286798477173, train/logprobs = tensor([[-0.8065, -1.7531],
        [-0.8966, -1.5455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060139670968055725
Epoch 0, Step 244: train/loss = 0.6778570413589478, train/raw-loss = 0.6470866203308105, train/logprobs = tensor([[-0.7698, -1.2106],
        [-0.8204, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06154089421033859
Epoch 0, Step 245: train/loss = 0.6857894062995911, train/raw-loss = 0.664635181427002, train/logprobs = tensor([[-0.5829, -0.9433],
        [-0.5774, -0.6782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04230845347046852
Epoch 0, Step 246: train/loss = 0.6982607841491699, train/raw-loss = 0.6780409812927246, train/logprobs = tensor([[-0.6083, -0.8238],
        [-0.6014, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040439359843730927
Epoch 0, Step 247: train/loss = 0.6753484010696411, train/raw-loss = 0.6518843173980713, train/logprobs = tensor([[-0.7580, -1.0724],
        [-0.8152, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04692811146378517
Epoch 0, Step 248: train/loss = 0.6727050542831421, train/raw-loss = 0.6463230848312378, train/logprobs = tensor([[-1.2541, -1.2186],
        [-1.3101, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05276405066251755
Epoch 0, Step 249: train/loss = 0.6637598276138306, train/raw-loss = 0.6412948966026306, train/logprobs = tensor([[-1.0027, -1.3965],
        [-1.0943, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04492989927530289
Epoch 0, Step 250: train/loss = 0.6533101797103882, train/raw-loss = 0.6293495297431946, train/logprobs = tensor([[-0.7023, -1.5650],
        [-0.7179, -1.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04792126640677452
Epoch 0, Step 251: train/loss = 0.6667206883430481, train/raw-loss = 0.6403303742408752, train/logprobs = tensor([[-0.9131, -1.2393],
        [-0.9206, -0.8250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05278057977557182
Epoch 0, Step 252: train/loss = 0.6941338777542114, train/raw-loss = 0.673150897026062, train/logprobs = tensor([[-0.6546, -0.6629],
        [-0.7023, -0.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04196605458855629
Epoch 0, Step 253: train/loss = 0.6827816367149353, train/raw-loss = 0.6569127440452576, train/logprobs = tensor([[-0.4808, -1.2524],
        [-0.4597, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05173773691058159
Epoch 0, Step 254: train/loss = 0.676554799079895, train/raw-loss = 0.6530296802520752, train/logprobs = tensor([[-0.6803, -1.3237],
        [-0.7437, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047050122171640396
Epoch 0, Step 255: train/loss = 0.708349347114563, train/raw-loss = 0.6900153160095215, train/logprobs = tensor([[-0.7485, -1.4252],
        [-0.7605, -1.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03666799142956734
Epoch 0, Step 256: train/loss = 0.6667245030403137, train/raw-loss = 0.6367802619934082, train/logprobs = tensor([[-0.8258, -1.4135],
        [-0.8267, -1.0735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05988862365484238
Epoch 0, Step 257: train/loss = 0.6923582553863525, train/raw-loss = 0.6710059642791748, train/logprobs = tensor([[-0.5576, -0.9834],
        [-0.5705, -0.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042704708874225616
Epoch 0, Step 258: train/loss = 0.7009128928184509, train/raw-loss = 0.6765639781951904, train/logprobs = tensor([[-0.6667, -0.9604],
        [-0.7477, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04869775474071503
Epoch 0, Step 259: train/loss = 0.6515529155731201, train/raw-loss = 0.6224074363708496, train/logprobs = tensor([[-0.9030, -1.1377],
        [-1.1273, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05829093977808952
Epoch 0, Step 260: train/loss = 0.6180074214935303, train/raw-loss = 0.5900683999061584, train/logprobs = tensor([[-1.0761, -1.3745],
        [-1.3023, -0.9332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055878061801195145
Epoch 0, Step 261: train/loss = 0.6484136581420898, train/raw-loss = 0.6208685636520386, train/logprobs = tensor([[-0.8503, -2.5691],
        [-0.9395, -2.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05509010702371597
Epoch 0, Step 262: train/loss = 0.6459800004959106, train/raw-loss = 0.6174680590629578, train/logprobs = tensor([[-1.1429, -1.1120],
        [-1.3101, -0.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057023920118808746
Epoch 0, Step 263: train/loss = 0.6815550327301025, train/raw-loss = 0.6528534889221191, train/logprobs = tensor([[-0.8538, -1.2049],
        [-0.9680, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05740310624241829
Epoch 0, Step 264: train/loss = 0.6985341310501099, train/raw-loss = 0.6707373857498169, train/logprobs = tensor([[-0.7540, -0.8984],
        [-0.7974, -0.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05559363216161728
Epoch 0, Step 265: train/loss = 0.6650115251541138, train/raw-loss = 0.6408373117446899, train/logprobs = tensor([[-0.7620, -1.1356],
        [-0.8329, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048348307609558105
Epoch 0, Step 266: train/loss = 0.6748596429824829, train/raw-loss = 0.647667407989502, train/logprobs = tensor([[-0.8522, -0.9177],
        [-0.9230, -0.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054384589195251465
Epoch 0, Step 267: train/loss = 0.6731408834457397, train/raw-loss = 0.638850212097168, train/logprobs = tensor([[-0.7429, -1.9070],
        [-0.7071, -1.3835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06858144700527191
Epoch 0, Step 268: train/loss = 0.6569234132766724, train/raw-loss = 0.6345736384391785, train/logprobs = tensor([[-0.8977, -1.7675],
        [-0.9127, -1.3756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044699519872665405
Epoch 0, Step 269: train/loss = 0.64677894115448, train/raw-loss = 0.6098231673240662, train/logprobs = tensor([[-1.0807, -2.1177],
        [-1.2928, -1.8610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07391144335269928
Epoch 0, Step 270: train/loss = 0.7005393505096436, train/raw-loss = 0.6782572269439697, train/logprobs = tensor([[-0.7324, -0.8620],
        [-0.7176, -0.7140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04456421360373497
Epoch 0, Step 271: train/loss = 0.6635616421699524, train/raw-loss = 0.6275902986526489, train/logprobs = tensor([[-0.7371, -1.4144],
        [-0.8061, -1.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07194273918867111
Epoch 0, Step 272: train/loss = 0.6767856478691101, train/raw-loss = 0.6522921323776245, train/logprobs = tensor([[-0.6139, -0.6529],
        [-0.7421, -0.4942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04898706451058388
Epoch 0, Step 273: train/loss = 0.6353363394737244, train/raw-loss = 0.6104811429977417, train/logprobs = tensor([[-0.9924, -2.0134],
        [-1.1168, -1.4657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04971041902899742
Epoch 0, Step 274: train/loss = 0.6742217540740967, train/raw-loss = 0.6538057923316956, train/logprobs = tensor([[-1.1495, -1.4244],
        [-1.1786, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04083200544118881
Epoch 0, Step 275: train/loss = 0.6746125221252441, train/raw-loss = 0.6448375582695007, train/logprobs = tensor([[-1.0955, -1.0149],
        [-1.2371, -0.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0595499686896801
Epoch 0, Step 276: train/loss = 0.6803547143936157, train/raw-loss = 0.6545198559761047, train/logprobs = tensor([[-1.5002, -1.1504],
        [-1.6298, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051669713109731674
Epoch 0, Step 277: train/loss = 0.6502055525779724, train/raw-loss = 0.6218135356903076, train/logprobs = tensor([[-0.7845, -2.1451],
        [-0.8989, -1.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05678408592939377
Epoch 0, Step 278: train/loss = 0.6857085227966309, train/raw-loss = 0.6576694250106812, train/logprobs = tensor([[-1.0137, -1.3356],
        [-1.0742, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056078121066093445
Epoch 0, Step 279: train/loss = 0.6957346796989441, train/raw-loss = 0.6661938428878784, train/logprobs = tensor([[-1.1489, -1.6669],
        [-1.2684, -1.4190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059081774204969406
Epoch 0, Step 280: train/loss = 0.6999338865280151, train/raw-loss = 0.6730608940124512, train/logprobs = tensor([[-0.9744, -1.0071],
        [-1.0001, -0.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05374600365757942
Epoch 0, Step 281: train/loss = 0.7225722074508667, train/raw-loss = 0.6911243200302124, train/logprobs = tensor([[-1.2540, -1.9086],
        [-1.3260, -1.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0628957748413086
Epoch 0, Step 282: train/loss = 0.6661784648895264, train/raw-loss = 0.6423888206481934, train/logprobs = tensor([[-1.0237, -3.0825],
        [-1.0353, -2.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04757941514253616
Epoch 0, Step 283: train/loss = 0.6579918265342712, train/raw-loss = 0.6306057572364807, train/logprobs = tensor([[-0.9059, -1.0379],
        [-1.0535, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054772164672613144
Epoch 0, Step 284: train/loss = 0.6838372349739075, train/raw-loss = 0.656909704208374, train/logprobs = tensor([[-1.0382, -2.0552],
        [-1.1371, -1.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0538550466299057
Epoch 0, Step 285: train/loss = 0.6814681887626648, train/raw-loss = 0.6536306142807007, train/logprobs = tensor([[-0.8681, -1.5184],
        [-0.8563, -1.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055675070732831955
Epoch 0, Step 286: train/loss = 0.6388278007507324, train/raw-loss = 0.6060535311698914, train/logprobs = tensor([[-0.8977, -1.4638],
        [-1.0965, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06554856896400452
Epoch 0, Step 287: train/loss = 0.6897799968719482, train/raw-loss = 0.6739569902420044, train/logprobs = tensor([[-0.5815, -0.7025],
        [-0.5631, -0.5639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03164616972208023
Epoch 0, Step 288: train/loss = 0.6900630593299866, train/raw-loss = 0.6609480381011963, train/logprobs = tensor([[-0.5991, -1.0241],
        [-0.6012, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05822998285293579
Epoch 0, Step 289: train/loss = 0.6204156875610352, train/raw-loss = 0.5890904664993286, train/logprobs = tensor([[-1.3825, -1.8996],
        [-1.6278, -1.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0626504048705101
Epoch 0, Step 290: train/loss = 0.66820228099823, train/raw-loss = 0.6377761363983154, train/logprobs = tensor([[-0.9521, -1.4055],
        [-0.9859, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060852281749248505
Epoch 0, Step 291: train/loss = 0.6721276640892029, train/raw-loss = 0.6486560106277466, train/logprobs = tensor([[-0.7732, -1.5571],
        [-0.7281, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046943239867687225
Epoch 0, Step 292: train/loss = 0.6542385816574097, train/raw-loss = 0.6215070486068726, train/logprobs = tensor([[-0.8388, -1.4568],
        [-0.9272, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06546299904584885
Epoch 0, Step 293: train/loss = 0.6533533334732056, train/raw-loss = 0.6220460534095764, train/logprobs = tensor([[-1.2939, -2.9172],
        [-1.3585, -2.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06261462718248367
Epoch 0, Step 294: train/loss = 0.6788581013679504, train/raw-loss = 0.6519028544425964, train/logprobs = tensor([[-0.7157, -1.0989],
        [-0.7342, -0.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05391047149896622
Epoch 0, Step 295: train/loss = 0.6712774038314819, train/raw-loss = 0.6417539715766907, train/logprobs = tensor([[-0.9947, -2.4706],
        [-1.1015, -2.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05904676765203476
Epoch 0, Step 296: train/loss = 0.6872714161872864, train/raw-loss = 0.6616630554199219, train/logprobs = tensor([[-0.5277, -0.9589],
        [-0.4930, -0.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05121677368879318
Epoch 0, Step 297: train/loss = 0.6739354133605957, train/raw-loss = 0.6490553021430969, train/logprobs = tensor([[-0.8274, -1.1041],
        [-0.9441, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04976009950041771
Epoch 0, Step 298: train/loss = 0.7301831245422363, train/raw-loss = 0.7072800397872925, train/logprobs = tensor([[-1.0378, -1.0157],
        [-1.0083, -0.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045806191861629486
Epoch 0, Step 299: train/loss = 0.686251163482666, train/raw-loss = 0.6463776230812073, train/logprobs = tensor([[-0.8598, -1.0752],
        [-0.9631, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797472596168518
Epoch 0, Step 300: train/loss = 0.6651203632354736, train/raw-loss = 0.6331110000610352, train/logprobs = tensor([[-0.6577, -1.8138],
        [-0.6427, -1.3522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06401867419481277
Epoch 0, Step 301: train/loss = 0.6632931232452393, train/raw-loss = 0.6279140114784241, train/logprobs = tensor([[-0.7746, -1.3299],
        [-0.8817, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07075824588537216
Epoch 0, Step 302: train/loss = 0.663964569568634, train/raw-loss = 0.6311848163604736, train/logprobs = tensor([[-0.8430, -1.9360],
        [-0.9971, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06555946916341782
Epoch 0, Step 303: train/loss = 0.6641914248466492, train/raw-loss = 0.6354575157165527, train/logprobs = tensor([[-1.1227, -1.3218],
        [-1.2466, -1.1112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05746792256832123
Epoch 0, Step 304: train/loss = 0.701210081577301, train/raw-loss = 0.6722604036331177, train/logprobs = tensor([[-0.7516, -0.9483],
        [-0.7116, -0.6662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05789946764707565
Epoch 0, Step 305: train/loss = 0.7043341994285583, train/raw-loss = 0.6844488382339478, train/logprobs = tensor([[-0.7530, -0.7569],
        [-0.8047, -0.7239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03977077454328537
Epoch 0, Step 306: train/loss = 0.6687594056129456, train/raw-loss = 0.6391861438751221, train/logprobs = tensor([[-0.9407, -1.4132],
        [-1.0004, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05914658308029175
Epoch 0, Step 307: train/loss = 0.6835946440696716, train/raw-loss = 0.6551964282989502, train/logprobs = tensor([[-1.0252, -1.8989],
        [-1.0508, -1.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05679647624492645
Epoch 0, Step 308: train/loss = 0.6758280992507935, train/raw-loss = 0.6435246467590332, train/logprobs = tensor([[-0.6744, -1.4199],
        [-0.6786, -1.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06460689753293991
Epoch 0, Step 309: train/loss = 0.6678822040557861, train/raw-loss = 0.6337680816650391, train/logprobs = tensor([[-0.8588, -1.4493],
        [-0.9192, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06822827458381653
Epoch 0, Step 310: train/loss = 0.6264190077781677, train/raw-loss = 0.5863207578659058, train/logprobs = tensor([[-0.9323, -1.5253],
        [-1.1663, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0801965668797493
Epoch 0, Step 311: train/loss = 0.6917319297790527, train/raw-loss = 0.6582050323486328, train/logprobs = tensor([[-0.6567, -1.1683],
        [-0.6358, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06705372035503387
Epoch 0, Step 312: train/loss = 0.6948686242103577, train/raw-loss = 0.6613473892211914, train/logprobs = tensor([[-0.8607, -1.4587],
        [-1.0067, -1.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06704243272542953
Epoch 0, Step 313: train/loss = 0.6928838491439819, train/raw-loss = 0.656037449836731, train/logprobs = tensor([[-1.2182, -0.7735],
        [-1.4445, -0.7375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07369284331798553
Epoch 0, Step 314: train/loss = 0.7090388536453247, train/raw-loss = 0.6772888898849487, train/logprobs = tensor([[-1.0616, -2.0736],
        [-1.1182, -1.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06349990516901016
Epoch 0, Step 315: train/loss = 0.6820827126502991, train/raw-loss = 0.6566419005393982, train/logprobs = tensor([[-0.5905, -0.6944],
        [-0.6872, -0.5550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05088161304593086
Epoch 0, Step 316: train/loss = 0.6566722989082336, train/raw-loss = 0.6166360378265381, train/logprobs = tensor([[-0.9365, -1.3961],
        [-1.1133, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08007253706455231
Epoch 0, Step 317: train/loss = 0.6889200210571289, train/raw-loss = 0.6557164192199707, train/logprobs = tensor([[-0.8103, -0.7807],
        [-0.9263, -0.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640733033418655
Epoch 0, Step 318: train/loss = 0.6777618527412415, train/raw-loss = 0.6472481489181519, train/logprobs = tensor([[-0.8932, -1.1045],
        [-1.0065, -0.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06102737784385681
Epoch 0, Step 319: train/loss = 0.671538770198822, train/raw-loss = 0.6484330296516418, train/logprobs = tensor([[-1.0758, -1.1978],
        [-1.2178, -1.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04621151462197304
Epoch 0, Step 320: train/loss = 0.6481802463531494, train/raw-loss = 0.6192198991775513, train/logprobs = tensor([[-0.6841, -2.1343],
        [-0.6199, -1.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05792064219713211
Epoch 0, Step 321: train/loss = 0.6594460010528564, train/raw-loss = 0.6300039291381836, train/logprobs = tensor([[-0.8897, -2.1950],
        [-0.9430, -1.7520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058884136378765106
Epoch 0, Step 322: train/loss = 0.6397037506103516, train/raw-loss = 0.6030648946762085, train/logprobs = tensor([[-0.9621, -1.4179],
        [-1.2393, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327765226364136
Epoch 0, Step 323: train/loss = 0.6850100755691528, train/raw-loss = 0.6584722995758057, train/logprobs = tensor([[-0.7912, -1.0022],
        [-0.8020, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053075678646564484
Epoch 0, Step 324: train/loss = 0.6615421772003174, train/raw-loss = 0.6272302865982056, train/logprobs = tensor([[-1.1000, -1.8021],
        [-1.2653, -1.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06862365454435349
Epoch 0, Step 325: train/loss = 0.6884807348251343, train/raw-loss = 0.6576833128929138, train/logprobs = tensor([[-0.8759, -1.7236],
        [-0.9224, -1.4289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0615948922932148
Epoch 0, Step 326: train/loss = 0.6737911105155945, train/raw-loss = 0.6396056413650513, train/logprobs = tensor([[-0.6504, -1.7090],
        [-0.6504, -1.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683709979057312
Epoch 0, Step 327: train/loss = 0.6971437931060791, train/raw-loss = 0.6753712892532349, train/logprobs = tensor([[-0.5734, -0.8550],
        [-0.5495, -0.6830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04354512318968773
Epoch 0, Step 328: train/loss = 0.7129476070404053, train/raw-loss = 0.6859878897666931, train/logprobs = tensor([[-1.0580, -1.1050],
        [-1.4074, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053919438272714615
Epoch 0, Step 329: train/loss = 0.6686457991600037, train/raw-loss = 0.6362152695655823, train/logprobs = tensor([[-0.9822, -2.4027],
        [-1.0306, -2.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06486102938652039
Epoch 0, Step 330: train/loss = 0.6982518434524536, train/raw-loss = 0.6745858192443848, train/logprobs = tensor([[-0.5070, -0.8333],
        [-0.5256, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047332022339105606
Epoch 0, Step 331: train/loss = 0.6691066026687622, train/raw-loss = 0.6406075954437256, train/logprobs = tensor([[-0.8086, -1.3444],
        [-0.8212, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056998029351234436
Epoch 0, Step 332: train/loss = 0.6418938636779785, train/raw-loss = 0.6090759038925171, train/logprobs = tensor([[-0.9148, -1.8976],
        [-1.0567, -1.4905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06563588231801987
Epoch 0, Step 333: train/loss = 0.6974050402641296, train/raw-loss = 0.6702971458435059, train/logprobs = tensor([[-0.7428, -1.7042],
        [-0.8018, -1.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054215747863054276
Epoch 0, Step 334: train/loss = 0.6949135661125183, train/raw-loss = 0.6674664616584778, train/logprobs = tensor([[-0.5530, -0.8731],
        [-0.5471, -0.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05489417910575867
Epoch 0, Step 335: train/loss = 0.6961854100227356, train/raw-loss = 0.6636208295822144, train/logprobs = tensor([[-0.5163, -1.1407],
        [-0.4781, -0.8302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0651291236281395
Epoch 0, Step 336: train/loss = 0.6766929626464844, train/raw-loss = 0.6458590626716614, train/logprobs = tensor([[-1.0037, -1.1213],
        [-1.0381, -0.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06166789308190346
Epoch 0, Step 337: train/loss = 0.7200070023536682, train/raw-loss = 0.6875556707382202, train/logprobs = tensor([[-1.2141, -1.7028],
        [-1.2207, -1.5112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06490252912044525
Epoch 0, Step 338: train/loss = 0.6808840036392212, train/raw-loss = 0.6536059379577637, train/logprobs = tensor([[-0.7892, -1.1407],
        [-0.8766, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05455617606639862
Epoch 0, Step 339: train/loss = 0.615286111831665, train/raw-loss = 0.5817930102348328, train/logprobs = tensor([[-1.0195, -2.1766],
        [-1.2879, -1.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698622554540634
Epoch 0, Step 340: train/loss = 0.6818546056747437, train/raw-loss = 0.6541794538497925, train/logprobs = tensor([[-0.6135, -0.8018],
        [-0.6630, -0.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055350348353385925
Epoch 0, Step 341: train/loss = 0.705751895904541, train/raw-loss = 0.6793454885482788, train/logprobs = tensor([[-0.6227, -0.6281],
        [-0.6447, -0.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05281272158026695
Epoch 0, Step 342: train/loss = 0.6917026042938232, train/raw-loss = 0.6708564758300781, train/logprobs = tensor([[-0.6277, -0.8230],
        [-0.6483, -0.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04169222712516785
Epoch 0, Step 343: train/loss = 0.6404714584350586, train/raw-loss = 0.6078081727027893, train/logprobs = tensor([[-1.0266, -1.2340],
        [-1.2605, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06532656401395798
Epoch 0, Step 344: train/loss = 0.6715683937072754, train/raw-loss = 0.6358919739723206, train/logprobs = tensor([[-0.4051, -1.2546],
        [-0.3873, -0.7650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07135283946990967
Epoch 0, Step 345: train/loss = 0.6840419173240662, train/raw-loss = 0.6553064584732056, train/logprobs = tensor([[-1.1659, -1.2713],
        [-1.3704, -1.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05747092142701149
Epoch 0, Step 346: train/loss = 0.6890950798988342, train/raw-loss = 0.65628582239151, train/logprobs = tensor([[-0.5693, -1.0152],
        [-0.6614, -0.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0656186118721962
Epoch 0, Step 347: train/loss = 0.6280076503753662, train/raw-loss = 0.5952658653259277, train/logprobs = tensor([[-0.9979, -1.4335],
        [-1.2405, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06548362225294113
Epoch 0, Step 348: train/loss = 0.6796954274177551, train/raw-loss = 0.6527473330497742, train/logprobs = tensor([[-0.6797, -1.2850],
        [-0.6516, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053896114230155945
Epoch 0, Step 349: train/loss = 0.6862672567367554, train/raw-loss = 0.6543420553207397, train/logprobs = tensor([[-0.5930, -1.2410],
        [-0.5693, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0638502985239029
Epoch 0, Step 350: train/loss = 0.6803154945373535, train/raw-loss = 0.6551262140274048, train/logprobs = tensor([[-1.2016, -1.6496],
        [-1.2515, -1.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05037854611873627
Epoch 0, Step 351: train/loss = 0.6831097602844238, train/raw-loss = 0.6532554626464844, train/logprobs = tensor([[-0.7017, -0.9699],
        [-0.7882, -0.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059708625078201294
Epoch 0, Step 352: train/loss = 0.6971081495285034, train/raw-loss = 0.6681849956512451, train/logprobs = tensor([[-0.6493, -1.0010],
        [-0.6424, -0.7334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05784629285335541
Epoch 0, Step 353: train/loss = 0.6581233143806458, train/raw-loss = 0.6311593055725098, train/logprobs = tensor([[-0.9220, -1.3080],
        [-0.9949, -0.9784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05392802879214287
Epoch 0, Step 354: train/loss = 0.6096112728118896, train/raw-loss = 0.5747735500335693, train/logprobs = tensor([[-0.7570, -1.5883],
        [-1.1218, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06967543065547943
Epoch 0, Step 355: train/loss = 0.6582254767417908, train/raw-loss = 0.6324285268783569, train/logprobs = tensor([[-0.6415, -1.0010],
        [-0.8217, -0.7705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05159381031990051
Epoch 0, Step 356: train/loss = 0.6850481033325195, train/raw-loss = 0.6568199396133423, train/logprobs = tensor([[-0.7484, -1.0125],
        [-0.7589, -0.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05645626783370972
Epoch 0, Step 357: train/loss = 0.6523842215538025, train/raw-loss = 0.6189355850219727, train/logprobs = tensor([[-0.6765, -1.5875],
        [-0.9193, -1.2924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06689728796482086
Epoch 0, Step 358: train/loss = 0.7107770442962646, train/raw-loss = 0.6792668104171753, train/logprobs = tensor([[-0.6166, -1.0355],
        [-0.5782, -0.8845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06302039325237274
Epoch 0, Step 359: train/loss = 0.7316501140594482, train/raw-loss = 0.7004165649414062, train/logprobs = tensor([[-0.7742, -0.8717],
        [-0.6830, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06246725842356682
Epoch 0, Step 360: train/loss = 0.7152099013328552, train/raw-loss = 0.6819745302200317, train/logprobs = tensor([[-1.0882, -1.6407],
        [-1.3790, -1.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06647071987390518
Epoch 0, Step 361: train/loss = 0.7008190155029297, train/raw-loss = 0.6741913557052612, train/logprobs = tensor([[-1.0826, -1.3917],
        [-1.1933, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0532553568482399
Epoch 0, Step 362: train/loss = 0.6877985596656799, train/raw-loss = 0.6624748706817627, train/logprobs = tensor([[-1.0009, -1.0166],
        [-1.0386, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050647392868995667
Epoch 0, Step 363: train/loss = 0.7005139589309692, train/raw-loss = 0.6770460605621338, train/logprobs = tensor([[-0.7270, -1.1220],
        [-0.6776, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04693566635251045
Epoch 0, Step 364: train/loss = 0.5686035752296448, train/raw-loss = 0.5263528823852539, train/logprobs = tensor([[-1.0699, -1.7921],
        [-1.7112, -1.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08450131863355637
Epoch 0, Step 365: train/loss = 0.6954625844955444, train/raw-loss = 0.6740732192993164, train/logprobs = tensor([[-0.7508, -1.0278],
        [-0.7303, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04277864098548889
Epoch 0, Step 366: train/loss = 0.6149868369102478, train/raw-loss = 0.5795150995254517, train/logprobs = tensor([[-1.0422, -1.8783],
        [-1.3728, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094353437423706
Epoch 0, Step 367: train/loss = 0.6629499197006226, train/raw-loss = 0.6293843388557434, train/logprobs = tensor([[-0.8415, -1.3445],
        [-0.9277, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0671311467885971
Epoch 0, Step 368: train/loss = 0.7030123472213745, train/raw-loss = 0.6715953946113586, train/logprobs = tensor([[-0.5639, -1.1915],
        [-0.5435, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06283403187990189
Epoch 0, Step 369: train/loss = 0.5904650688171387, train/raw-loss = 0.5577524304389954, train/logprobs = tensor([[-1.0295, -1.8510],
        [-1.5452, -1.3801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06542529165744781
Epoch 0, Step 370: train/loss = 0.647181510925293, train/raw-loss = 0.6130733489990234, train/logprobs = tensor([[-0.7221, -1.8050],
        [-0.7867, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821628659963608
Epoch 0, Step 371: train/loss = 0.6321585178375244, train/raw-loss = 0.5945966839790344, train/logprobs = tensor([[-0.8858, -1.1402],
        [-1.2831, -0.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075123630464077
Epoch 0, Step 372: train/loss = 0.6941773295402527, train/raw-loss = 0.6667143106460571, train/logprobs = tensor([[-0.8844, -1.2704],
        [-0.9770, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054926156997680664
Epoch 0, Step 373: train/loss = 0.6410588026046753, train/raw-loss = 0.6125860810279846, train/logprobs = tensor([[-0.7261, -1.4162],
        [-0.9197, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05694540962576866
Epoch 0, Step 374: train/loss = 0.7119573354721069, train/raw-loss = 0.6882150173187256, train/logprobs = tensor([[-0.7384, -0.7474],
        [-0.7056, -0.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04748467728495598
Epoch 0, Step 375: train/loss = 0.6205974817276001, train/raw-loss = 0.583065390586853, train/logprobs = tensor([[-0.8297, -2.0910],
        [-0.9723, -1.4149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07506415247917175
Epoch 0, Step 376: train/loss = 0.6873152256011963, train/raw-loss = 0.6594746112823486, train/logprobs = tensor([[-0.6788, -0.9548],
        [-0.7297, -0.7417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055681075900793076
Epoch 0, Step 377: train/loss = 0.6615455746650696, train/raw-loss = 0.6253842115402222, train/logprobs = tensor([[-1.1584, -1.3155],
        [-1.3892, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07232263684272766
Epoch 0, Step 378: train/loss = 0.7120565176010132, train/raw-loss = 0.6795878410339355, train/logprobs = tensor([[-0.7115, -0.4763],
        [-0.7741, -0.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06493727117776871
Epoch 0, Step 379: train/loss = 0.6276865005493164, train/raw-loss = 0.5973817110061646, train/logprobs = tensor([[-0.8436, -1.2425],
        [-1.1454, -0.9574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060609474778175354
Epoch 0, Step 380: train/loss = 0.6185520887374878, train/raw-loss = 0.577934741973877, train/logprobs = tensor([[-0.7321, -1.2550],
        [-1.1658, -0.7229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0812349021434784
Epoch 0, Step 381: train/loss = 0.6995642185211182, train/raw-loss = 0.6716659069061279, train/logprobs = tensor([[-0.7879, -0.8815],
        [-0.8352, -0.6392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05579642206430435
Epoch 0, Step 382: train/loss = 0.6086540222167969, train/raw-loss = 0.5795007944107056, train/logprobs = tensor([[-0.8281, -1.5785],
        [-1.2205, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05830642953515053
Epoch 0, Step 383: train/loss = 0.644240140914917, train/raw-loss = 0.6214202046394348, train/logprobs = tensor([[-0.7764, -1.8558],
        [-0.8094, -1.3012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04563980549573898
Epoch 0, Step 384: train/loss = 0.6145238876342773, train/raw-loss = 0.5754650235176086, train/logprobs = tensor([[-0.9036, -0.9715],
        [-1.4946, -0.6829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0781177431344986
Epoch 0, Step 385: train/loss = 0.6749196648597717, train/raw-loss = 0.6479605436325073, train/logprobs = tensor([[-0.7368, -1.2347],
        [-0.7912, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05391827970743179
Epoch 0, Step 386: train/loss = 0.608014702796936, train/raw-loss = 0.5720794796943665, train/logprobs = tensor([[-1.1041, -2.8504],
        [-1.3252, -2.2509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0718705803155899
Epoch 0, Step 387: train/loss = 0.6400931477546692, train/raw-loss = 0.601658821105957, train/logprobs = tensor([[-0.8459, -1.0658],
        [-1.0630, -0.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07686854153871536
Epoch 0, Step 388: train/loss = 0.6467090249061584, train/raw-loss = 0.6089651584625244, train/logprobs = tensor([[-0.8458, -1.3836],
        [-1.1343, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07548777759075165
Epoch 0, Step 389: train/loss = 0.6564042568206787, train/raw-loss = 0.6290172934532166, train/logprobs = tensor([[-0.6314, -1.6219],
        [-0.9818, -1.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054773908108472824
Epoch 0, Step 390: train/loss = 0.6427461504936218, train/raw-loss = 0.6078888773918152, train/logprobs = tensor([[-0.6542, -1.1047],
        [-0.9257, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06971456110477448
Epoch 0, Step 391: train/loss = 0.6658555269241333, train/raw-loss = 0.6368298530578613, train/logprobs = tensor([[-0.6857, -1.4804],
        [-0.8258, -1.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05805138871073723
Epoch 0, Step 392: train/loss = 0.6427859663963318, train/raw-loss = 0.6098478436470032, train/logprobs = tensor([[-0.9254, -1.9057],
        [-0.9997, -1.3633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06587620824575424
Epoch 0, Step 393: train/loss = 0.706508994102478, train/raw-loss = 0.6755651235580444, train/logprobs = tensor([[-0.4709, -1.0153],
        [-0.4449, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06188768520951271
Epoch 0, Step 394: train/loss = 0.7479805946350098, train/raw-loss = 0.7143561840057373, train/logprobs = tensor([[-0.6873, -1.3343],
        [-0.9674, -1.4092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06724895536899567
Epoch 0, Step 395: train/loss = 0.6120117902755737, train/raw-loss = 0.5799216628074646, train/logprobs = tensor([[-0.8215, -1.7668],
        [-0.9281, -1.1263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06418029218912125
Epoch 0, Step 396: train/loss = 0.6641440391540527, train/raw-loss = 0.6251423358917236, train/logprobs = tensor([[-0.9359, -1.5914],
        [-1.0618, -1.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0780034065246582
Epoch 0, Step 397: train/loss = 0.6627388596534729, train/raw-loss = 0.6350653171539307, train/logprobs = tensor([[-0.6053, -1.1874],
        [-0.6295, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05534707009792328
Epoch 0, Step 398: train/loss = 0.64451003074646, train/raw-loss = 0.6097983717918396, train/logprobs = tensor([[-0.7720, -1.1766],
        [-1.0305, -0.6838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06942332535982132
Epoch 0, Step 399: train/loss = 0.7073208093643188, train/raw-loss = 0.6822483539581299, train/logprobs = tensor([[-0.4382, -0.8930],
        [-0.4170, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050144847482442856
Epoch 0, Step 400: train/loss = 0.618964433670044, train/raw-loss = 0.5756261944770813, train/logprobs = tensor([[-1.0099, -1.9461],
        [-1.4866, -1.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08667637407779694
Epoch 0, Step 401: train/loss = 0.6873570680618286, train/raw-loss = 0.6626002788543701, train/logprobs = tensor([[-0.9240, -1.0782],
        [-0.9885, -0.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04951350390911102
Epoch 0, Step 402: train/loss = 0.6056464910507202, train/raw-loss = 0.5748236775398254, train/logprobs = tensor([[-0.7854, -2.4172],
        [-0.9208, -1.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06164560839533806
Epoch 0, Step 403: train/loss = 0.7163729667663574, train/raw-loss = 0.6881863474845886, train/logprobs = tensor([[-1.0099, -2.4821],
        [-0.9774, -2.3005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056373320519924164
Epoch 0, Step 404: train/loss = 0.6887749433517456, train/raw-loss = 0.6608381867408752, train/logprobs = tensor([[-1.0249, -0.9294],
        [-1.3800, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05587347224354744
Epoch 0, Step 405: train/loss = 0.6357954740524292, train/raw-loss = 0.6068225502967834, train/logprobs = tensor([[-0.8183, -1.7557],
        [-0.9750, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05794578790664673
Epoch 0, Step 406: train/loss = 0.6773450970649719, train/raw-loss = 0.6511863470077515, train/logprobs = tensor([[-0.5182, -1.1731],
        [-0.5710, -0.8261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052317406982183456
Epoch 0, Step 407: train/loss = 0.6555023789405823, train/raw-loss = 0.6267253160476685, train/logprobs = tensor([[-0.6763, -1.2647],
        [-0.7950, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05755411833524704
Epoch 0, Step 408: train/loss = 0.6818689703941345, train/raw-loss = 0.65593022108078, train/logprobs = tensor([[-0.6344, -0.7649],
        [-0.8152, -0.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05187750980257988
Epoch 0, Step 409: train/loss = 0.6485051512718201, train/raw-loss = 0.612683117389679, train/logprobs = tensor([[-0.8978, -2.2289],
        [-1.0364, -1.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07164402306079865
Epoch 0, Step 410: train/loss = 0.6888377666473389, train/raw-loss = 0.6573410034179688, train/logprobs = tensor([[-0.8318, -1.3395],
        [-0.9916, -1.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06299350410699844
Epoch 0, Step 411: train/loss = 0.727166473865509, train/raw-loss = 0.7002012729644775, train/logprobs = tensor([[-1.2020, -1.3443],
        [-1.3564, -1.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053930528461933136
Epoch 0, Step 412: train/loss = 0.6811946630477905, train/raw-loss = 0.6567409634590149, train/logprobs = tensor([[-0.8731, -1.2343],
        [-0.8998, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04890736937522888
Epoch 0, Step 413: train/loss = 0.6930930614471436, train/raw-loss = 0.6695181131362915, train/logprobs = tensor([[-0.5659, -0.9006],
        [-0.5458, -0.7128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04714985936880112
Epoch 0, Step 414: train/loss = 0.6068874001502991, train/raw-loss = 0.5643832683563232, train/logprobs = tensor([[-0.6350, -1.5116],
        [-1.0943, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08500819653272629
Epoch 0, Step 415: train/loss = 0.5668835639953613, train/raw-loss = 0.5200737118721008, train/logprobs = tensor([[-0.9878, -1.8037],
        [-1.7427, -1.1963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09361978620290756
Epoch 0, Step 416: train/loss = 0.6957094669342041, train/raw-loss = 0.6588119268417358, train/logprobs = tensor([[-1.1032, -1.2906],
        [-1.3124, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07379503548145294
Epoch 0, Step 417: train/loss = 0.644057035446167, train/raw-loss = 0.6019225120544434, train/logprobs = tensor([[-0.6703, -1.6542],
        [-0.9114, -1.1921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0842689648270607
Epoch 0, Step 418: train/loss = 0.6285675168037415, train/raw-loss = 0.5886570811271667, train/logprobs = tensor([[-0.6683, -1.2894],
        [-1.0099, -0.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07982088625431061
Epoch 0, Step 419: train/loss = 0.7097833156585693, train/raw-loss = 0.6831204891204834, train/logprobs = tensor([[-0.6122, -0.8223],
        [-0.5887, -0.6954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05332554131746292
Epoch 0, Step 420: train/loss = 0.5762813091278076, train/raw-loss = 0.5361347198486328, train/logprobs = tensor([[-1.0117, -2.3043],
        [-1.4821, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08029313385486603
Epoch 0, Step 421: train/loss = 0.6315617561340332, train/raw-loss = 0.5954727530479431, train/logprobs = tensor([[-0.8882, -1.3186],
        [-1.2274, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07217805087566376
Epoch 0, Step 422: train/loss = 0.5861947536468506, train/raw-loss = 0.5434718132019043, train/logprobs = tensor([[-0.6334, -1.8099],
        [-1.0557, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08544591069221497
Epoch 0, Step 423: train/loss = 0.7005652189254761, train/raw-loss = 0.6670548915863037, train/logprobs = tensor([[-0.5834, -1.0071],
        [-0.5350, -0.7905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06702066212892532
Epoch 0, Step 424: train/loss = 0.635174036026001, train/raw-loss = 0.5994046926498413, train/logprobs = tensor([[-1.1411, -1.1592],
        [-1.5667, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07153867185115814
Epoch 0, Step 425: train/loss = 0.70871901512146, train/raw-loss = 0.6826103329658508, train/logprobs = tensor([[-0.5513, -0.6105],
        [-0.5705, -0.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052217379212379456
Epoch 0, Step 426: train/loss = 0.6903678774833679, train/raw-loss = 0.6558736562728882, train/logprobs = tensor([[-1.0836, -1.5515],
        [-1.0796, -1.2301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06898846477270126
Epoch 0, Step 427: train/loss = 0.5604352355003357, train/raw-loss = 0.5204139947891235, train/logprobs = tensor([[-1.2775, -1.9857],
        [-2.3004, -1.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08004242181777954
Epoch 0, Step 428: train/loss = 0.6099198460578918, train/raw-loss = 0.5599138736724854, train/logprobs = tensor([[-0.8874, -1.9762],
        [-1.3078, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001206398010254
Epoch 0, Step 429: train/loss = 0.7467982172966003, train/raw-loss = 0.7077939510345459, train/logprobs = tensor([[-0.7495, -1.1193],
        [-1.0932, -1.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07800862193107605
Epoch 0, Step 430: train/loss = 0.6961045265197754, train/raw-loss = 0.6654471158981323, train/logprobs = tensor([[-0.7477, -0.7546],
        [-1.0664, -0.7427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06131484732031822
Epoch 0, Step 431: train/loss = 0.6453908681869507, train/raw-loss = 0.6170656681060791, train/logprobs = tensor([[-0.5100, -1.5587],
        [-0.5176, -1.0151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056650567799806595
Epoch 0, Step 432: train/loss = 0.5901156067848206, train/raw-loss = 0.5447973012924194, train/logprobs = tensor([[-0.7914, -1.6135],
        [-1.2637, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09063654392957687
Epoch 0, Step 433: train/loss = 0.6705849766731262, train/raw-loss = 0.6377946138381958, train/logprobs = tensor([[-0.7439, -0.6433],
        [-1.0407, -0.5340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06558086723089218
Epoch 0, Step 434: train/loss = 0.6929218769073486, train/raw-loss = 0.6556093692779541, train/logprobs = tensor([[-1.1113, -1.2476],
        [-1.3185, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0746249407529831
Epoch 0, Step 435: train/loss = 0.6530942320823669, train/raw-loss = 0.6165562868118286, train/logprobs = tensor([[-0.6923, -1.5403],
        [-0.9126, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07307583838701248
Epoch 0, Step 436: train/loss = 0.708967924118042, train/raw-loss = 0.6744846701622009, train/logprobs = tensor([[-0.5400, -1.2059],
        [-0.4946, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06896666437387466
Epoch 0, Step 437: train/loss = 0.6198163628578186, train/raw-loss = 0.5883482098579407, train/logprobs = tensor([[-0.9649, -2.3003],
        [-1.2394, -1.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06293632090091705
Epoch 0, Step 438: train/loss = 0.709917426109314, train/raw-loss = 0.6781845688819885, train/logprobs = tensor([[-0.9847, -1.3846],
        [-0.9976, -0.9393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06346574425697327
Epoch 0, Step 439: train/loss = 0.6773493885993958, train/raw-loss = 0.6353633999824524, train/logprobs = tensor([[-0.8360, -1.5471],
        [-0.9843, -1.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397205173969269
Epoch 0, Step 440: train/loss = 0.6537401676177979, train/raw-loss = 0.6182858943939209, train/logprobs = tensor([[-0.6042, -1.2877],
        [-0.6626, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07090859115123749
Epoch 0, Step 441: train/loss = 0.711576521396637, train/raw-loss = 0.6818675994873047, train/logprobs = tensor([[-0.4819, -0.9989],
        [-0.4462, -0.8221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059417832642793655
Epoch 0, Step 442: train/loss = 0.6952818632125854, train/raw-loss = 0.6676177978515625, train/logprobs = tensor([[-0.4742, -1.0488],
        [-0.4438, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05532798171043396
Epoch 0, Step 443: train/loss = 0.7328031659126282, train/raw-loss = 0.6984584927558899, train/logprobs = tensor([[-0.9230, -1.3745],
        [-1.0372, -1.3069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06868942826986313
Epoch 0, Step 444: train/loss = 0.6688998341560364, train/raw-loss = 0.6385666728019714, train/logprobs = tensor([[-0.8987, -0.6541],
        [-1.2508, -0.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0606662854552269
Epoch 0, Step 445: train/loss = 0.6421710252761841, train/raw-loss = 0.600219190120697, train/logprobs = tensor([[-0.9593, -1.3796],
        [-1.3135, -0.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08390358090400696
Epoch 0, Step 446: train/loss = 0.6279531717300415, train/raw-loss = 0.5962846279144287, train/logprobs = tensor([[-1.0610, -2.0406],
        [-1.5990, -1.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06333712488412857
Epoch 0, Step 447: train/loss = 0.6806197166442871, train/raw-loss = 0.6458989977836609, train/logprobs = tensor([[-1.2071, -1.4986],
        [-1.3286, -1.0436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06944143027067184
Epoch 0, Step 448: train/loss = 0.7028325796127319, train/raw-loss = 0.6750993728637695, train/logprobs = tensor([[-0.7083, -1.2680],
        [-0.6284, -0.9665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05546649172902107
Epoch 0, Step 449: train/loss = 0.6632273197174072, train/raw-loss = 0.6312832832336426, train/logprobs = tensor([[-0.6899, -1.6120],
        [-0.8882, -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06388814002275467
Epoch 0, Step 450: train/loss = 0.66569983959198, train/raw-loss = 0.628383219242096, train/logprobs = tensor([[-0.7542, -1.7031],
        [-0.9103, -1.2518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07463328540325165
Epoch 0, Step 451: train/loss = 0.6500481367111206, train/raw-loss = 0.6204965114593506, train/logprobs = tensor([[-0.6530, -1.2667],
        [-0.6648, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059103310108184814
Epoch 0, Step 452: train/loss = 0.6440781354904175, train/raw-loss = 0.5990724563598633, train/logprobs = tensor([[-0.9058, -1.8126],
        [-1.0815, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09001129120588303
Epoch 0, Step 453: train/loss = 0.6560728549957275, train/raw-loss = 0.6207149028778076, train/logprobs = tensor([[-0.8605, -1.2660],
        [-1.2772, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07071592658758163
Epoch 0, Step 454: train/loss = 0.6418149471282959, train/raw-loss = 0.5986937880516052, train/logprobs = tensor([[-0.8098, -1.4046],
        [-1.1361, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08624234795570374
Epoch 0, Step 455: train/loss = 0.6663618683815002, train/raw-loss = 0.6238532662391663, train/logprobs = tensor([[-0.7282, -1.5311],
        [-0.9638, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08501723408699036
Epoch 0, Step 456: train/loss = 0.7048438191413879, train/raw-loss = 0.6798468828201294, train/logprobs = tensor([[-0.5844, -0.6639],
        [-0.6083, -0.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04999379441142082
Epoch 0, Step 457: train/loss = 0.6963161826133728, train/raw-loss = 0.6640338897705078, train/logprobs = tensor([[-0.5768, -1.0593],
        [-0.5384, -0.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06456463783979416
Epoch 0, Step 458: train/loss = 0.6279880404472351, train/raw-loss = 0.6023329496383667, train/logprobs = tensor([[-0.6467, -1.3066],
        [-0.9800, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0513102263212204
Epoch 0, Step 459: train/loss = 0.7883470058441162, train/raw-loss = 0.7472429871559143, train/logprobs = tensor([[-0.9600, -1.6029],
        [-1.3987, -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08220818638801575
Epoch 0, Step 460: train/loss = 0.6264687776565552, train/raw-loss = 0.5776252150535583, train/logprobs = tensor([[-0.6843, -2.3017],
        [-0.8204, -1.6214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09768709540367126
Epoch 0, Step 461: train/loss = 0.703857958316803, train/raw-loss = 0.6793513894081116, train/logprobs = tensor([[-1.0176, -0.9486],
        [-0.9981, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04901304095983505
Epoch 0, Step 462: train/loss = 0.6186540722846985, train/raw-loss = 0.5758373141288757, train/logprobs = tensor([[-0.7088, -1.1031],
        [-1.1915, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08563360571861267
Epoch 0, Step 463: train/loss = 0.6624898910522461, train/raw-loss = 0.625905454158783, train/logprobs = tensor([[-0.6697, -1.2732],
        [-0.7973, -0.8925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07316885888576508
Epoch 0, Step 464: train/loss = 0.6992068290710449, train/raw-loss = 0.6668387651443481, train/logprobs = tensor([[-0.8467, -0.9006],
        [-0.8972, -0.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06473605334758759
Epoch 0, Step 465: train/loss = 0.7041444182395935, train/raw-loss = 0.6761902570724487, train/logprobs = tensor([[-0.4010, -1.0468],
        [-0.3865, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055908288806676865
Epoch 0, Step 466: train/loss = 0.6019813418388367, train/raw-loss = 0.5647929906845093, train/logprobs = tensor([[-0.7167, -2.5709],
        [-0.8376, -1.7299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437682896852493
Epoch 0, Step 467: train/loss = 0.6012572646141052, train/raw-loss = 0.5630422830581665, train/logprobs = tensor([[-0.6735, -2.3626],
        [-1.0512, -1.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07642989605665207
Epoch 0, Step 468: train/loss = 0.7158069014549255, train/raw-loss = 0.6694481372833252, train/logprobs = tensor([[-0.7225, -1.5339],
        [-1.2786, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09271738678216934
Epoch 0, Step 469: train/loss = 0.648422122001648, train/raw-loss = 0.6069813966751099, train/logprobs = tensor([[-0.6099, -1.6904],
        [-0.6974, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08288148790597916
Epoch 0, Step 470: train/loss = 0.6734278202056885, train/raw-loss = 0.6371101140975952, train/logprobs = tensor([[-0.7692, -2.2812],
        [-0.9971, -1.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07263550162315369
Epoch 0, Step 471: train/loss = 0.6679501533508301, train/raw-loss = 0.6346849203109741, train/logprobs = tensor([[-0.7605, -2.2194],
        [-0.6955, -1.3462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06653038412332535
Epoch 0, Step 472: train/loss = 0.698453962802887, train/raw-loss = 0.6674465537071228, train/logprobs = tensor([[-0.8167, -1.3122],
        [-0.7397, -0.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062014706432819366
Epoch 0, Step 473: train/loss = 0.6655752062797546, train/raw-loss = 0.6459464430809021, train/logprobs = tensor([[-0.7771, -0.7939],
        [-1.1247, -0.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925754129886627
Epoch 0, Step 474: train/loss = 0.6259276866912842, train/raw-loss = 0.5958504676818848, train/logprobs = tensor([[-0.8052, -1.1013],
        [-1.0912, -0.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06015447527170181
Epoch 0, Step 475: train/loss = 0.6124046444892883, train/raw-loss = 0.5739977359771729, train/logprobs = tensor([[-0.8737, -1.3114],
        [-1.4400, -0.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07681386172771454
Epoch 0, Step 476: train/loss = 0.5550551414489746, train/raw-loss = 0.5088897943496704, train/logprobs = tensor([[-0.7562, -2.5856],
        [-1.4216, -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0923306867480278
Epoch 0, Step 477: train/loss = 0.6302120685577393, train/raw-loss = 0.5892648696899414, train/logprobs = tensor([[-1.5875, -1.7884],
        [-1.9597, -1.3632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08189457654953003
Epoch 0, Step 478: train/loss = 0.7117420434951782, train/raw-loss = 0.680962324142456, train/logprobs = tensor([[-0.6051, -0.9649],
        [-0.6826, -0.8816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061559341847896576
Epoch 0, Step 479: train/loss = 0.6727577447891235, train/raw-loss = 0.6386486291885376, train/logprobs = tensor([[-0.6294, -0.8588],
        [-0.9024, -0.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0682181790471077
Epoch 0, Step 480: train/loss = 0.6401041746139526, train/raw-loss = 0.5958836674690247, train/logprobs = tensor([[-0.7598, -1.0207],
        [-1.1408, -0.5180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884411558508873
Epoch 0, Step 481: train/loss = 0.6186591386795044, train/raw-loss = 0.5791435837745667, train/logprobs = tensor([[-0.6168, -1.5313],
        [-0.9942, -0.7552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0790310949087143
Epoch 0, Step 482: train/loss = 0.701994001865387, train/raw-loss = 0.6696770191192627, train/logprobs = tensor([[-0.6094, -0.9276],
        [-0.6308, -0.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06463395059108734
Epoch 0, Step 483: train/loss = 0.7303459644317627, train/raw-loss = 0.7000017166137695, train/logprobs = tensor([[-0.7932, -1.0742],
        [-0.7198, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06068846583366394
Epoch 0, Step 484: train/loss = 0.5745137333869934, train/raw-loss = 0.5348778963088989, train/logprobs = tensor([[-0.8714, -1.6494],
        [-1.5135, -1.1367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07927176356315613
Epoch 0, Step 485: train/loss = 0.7082517147064209, train/raw-loss = 0.6706560254096985, train/logprobs = tensor([[-0.9234, -1.0917],
        [-1.4062, -1.1438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0751914530992508
Epoch 0, Step 486: train/loss = 0.6660720109939575, train/raw-loss = 0.6176865696907043, train/logprobs = tensor([[-0.9142, -0.8617],
        [-1.3879, -0.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09677081555128098
Epoch 0, Step 487: train/loss = 0.7754249572753906, train/raw-loss = 0.7350990772247314, train/logprobs = tensor([[-0.8794, -1.3699],
        [-1.1351, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08065180480480194
Epoch 0, Step 488: train/loss = 0.6795967221260071, train/raw-loss = 0.6307893395423889, train/logprobs = tensor([[-0.8444, -1.3184],
        [-1.5861, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761489182710648
Epoch 0, Step 489: train/loss = 0.680484414100647, train/raw-loss = 0.6402840614318848, train/logprobs = tensor([[-0.6324, -0.9695],
        [-0.9167, -0.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08040061593055725
Epoch 0, Step 490: train/loss = 0.6370962858200073, train/raw-loss = 0.6009925007820129, train/logprobs = tensor([[-0.6067, -1.3268],
        [-0.9416, -0.8982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07220757007598877
Epoch 0, Step 491: train/loss = 0.6249302625656128, train/raw-loss = 0.5826992392539978, train/logprobs = tensor([[-0.8222, -1.8491],
        [-1.4440, -1.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08446197211742401
Epoch 0, Step 492: train/loss = 0.5909444689750671, train/raw-loss = 0.53939288854599, train/logprobs = tensor([[-0.8055, -3.5117],
        [-1.5775, -2.5044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10310321301221848
Epoch 0, Step 493: train/loss = 0.6443364024162292, train/raw-loss = 0.5941371321678162, train/logprobs = tensor([[-0.8919, -1.1009],
        [-1.4673, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039854049682617
Epoch 0, Step 494: train/loss = 0.6123656630516052, train/raw-loss = 0.5757363438606262, train/logprobs = tensor([[-0.6750, -1.8694],
        [-1.0221, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07325870543718338
Epoch 0, Step 495: train/loss = 0.6844079494476318, train/raw-loss = 0.6510215401649475, train/logprobs = tensor([[-0.5911, -1.1944],
        [-0.6240, -0.7852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06677275896072388
Epoch 0, Step 496: train/loss = 0.7472224235534668, train/raw-loss = 0.7149521112442017, train/logprobs = tensor([[-0.8055, -0.8176],
        [-0.7749, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06454046070575714
Epoch 0, Step 497: train/loss = 0.7021669745445251, train/raw-loss = 0.6654039621353149, train/logprobs = tensor([[-0.6991, -1.1692],
        [-0.6819, -0.8772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07352601736783981
Epoch 0, Step 498: train/loss = 0.5611277222633362, train/raw-loss = 0.5111241340637207, train/logprobs = tensor([[-0.9355, -2.2287],
        [-1.7770, -1.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10000720620155334
Epoch 0, Step 499: train/loss = 0.6606031656265259, train/raw-loss = 0.6038517355918884, train/logprobs = tensor([[-0.9130, -1.3671],
        [-1.7064, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11350289732217789
Epoch 0, Step 500: train/loss = 0.660230278968811, train/raw-loss = 0.6131759285926819, train/logprobs = tensor([[-0.7686, -1.2846],
        [-1.2617, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09410878270864487
Epoch 0, Step 501: train/loss = 0.6824090480804443, train/raw-loss = 0.6445853114128113, train/logprobs = tensor([[-0.9950, -1.6093],
        [-1.0939, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756474956870079
Epoch 0, Step 502: train/loss = 0.6797389984130859, train/raw-loss = 0.6357134580612183, train/logprobs = tensor([[-1.2335, -1.8792],
        [-1.4757, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08805108815431595
Epoch 0, Step 503: train/loss = 0.6947711110115051, train/raw-loss = 0.6692002415657043, train/logprobs = tensor([[-0.4721, -0.9623],
        [-0.4787, -0.7704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051141709089279175
Epoch 0, Step 504: train/loss = 0.7053646445274353, train/raw-loss = 0.6772565245628357, train/logprobs = tensor([[-0.5304, -0.6676],
        [-0.5413, -0.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05621633306145668
Epoch 0, Step 505: train/loss = 0.6948050856590271, train/raw-loss = 0.6669238805770874, train/logprobs = tensor([[-0.8563, -1.4955],
        [-0.9656, -1.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055762529373168945
Epoch 0, Step 506: train/loss = 0.6263311505317688, train/raw-loss = 0.5857515931129456, train/logprobs = tensor([[-0.7705, -1.5923],
        [-1.0700, -1.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0811590775847435
Epoch 0, Step 507: train/loss = 0.6111669540405273, train/raw-loss = 0.5755393505096436, train/logprobs = tensor([[-0.7967, -1.1904],
        [-1.3333, -0.8794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07125532627105713
Epoch 0, Step 508: train/loss = 0.7173119783401489, train/raw-loss = 0.693702220916748, train/logprobs = tensor([[-0.6125, -0.4901],
        [-0.5900, -0.4056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04721950739622116
Epoch 0, Step 509: train/loss = 0.6226563453674316, train/raw-loss = 0.5812910795211792, train/logprobs = tensor([[-0.9314, -1.8091],
        [-1.0780, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08273059129714966
Epoch 0, Step 510: train/loss = 0.6924896240234375, train/raw-loss = 0.6602286100387573, train/logprobs = tensor([[-0.8724, -0.9496],
        [-1.2733, -0.7362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.064521923661232
Epoch 0, Step 511: train/loss = 0.5662275552749634, train/raw-loss = 0.516765832901001, train/logprobs = tensor([[-1.0722, -3.4415],
        [-1.4844, -2.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09892330318689346
Epoch 0, Step 512: train/loss = 0.6967667937278748, train/raw-loss = 0.6650952100753784, train/logprobs = tensor([[-0.6281, -1.4182],
        [-0.6213, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0633431151509285
Epoch 0, Step 513: train/loss = 0.6424423456192017, train/raw-loss = 0.607968807220459, train/logprobs = tensor([[-0.7704, -2.0045],
        [-0.8907, -1.2708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06894698739051819
Epoch 0, Step 514: train/loss = 0.5907100439071655, train/raw-loss = 0.5618606805801392, train/logprobs = tensor([[-0.8484, -2.2245],
        [-1.0953, -1.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057698704302310944
Epoch 0, Step 515: train/loss = 0.633064866065979, train/raw-loss = 0.5887377858161926, train/logprobs = tensor([[-0.7372, -0.8012],
        [-1.3456, -0.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08865421265363693
Epoch 0, Step 516: train/loss = 0.6757983565330505, train/raw-loss = 0.6378578543663025, train/logprobs = tensor([[-0.4916, -0.7812],
        [-0.8268, -0.6063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0758810043334961
Epoch 0, Step 517: train/loss = 0.6768876314163208, train/raw-loss = 0.6493379473686218, train/logprobs = tensor([[-0.5866, -1.0125],
        [-0.6986, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05509934574365616
Epoch 0, Step 518: train/loss = 0.7754528522491455, train/raw-loss = 0.735975980758667, train/logprobs = tensor([[-0.9216, -1.6091],
        [-1.3169, -1.7443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07895384728908539
Epoch 0, Step 519: train/loss = 0.6126493215560913, train/raw-loss = 0.574649453163147, train/logprobs = tensor([[-0.6901, -2.3889],
        [-0.9659, -1.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07599973678588867
Epoch 0, Step 520: train/loss = 0.7796525955200195, train/raw-loss = 0.7313168048858643, train/logprobs = tensor([[-1.0035, -2.0073],
        [-1.4518, -1.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09667153656482697
Epoch 0, Step 521: train/loss = 0.6581969261169434, train/raw-loss = 0.6223514676094055, train/logprobs = tensor([[-0.5734, -1.0786],
        [-0.9018, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07169091701507568
Epoch 0, Step 522: train/loss = 0.6883035898208618, train/raw-loss = 0.6540012955665588, train/logprobs = tensor([[-0.9690, -2.1183],
        [-1.2713, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06860468536615372
Epoch 0, Step 523: train/loss = 0.6121628284454346, train/raw-loss = 0.5719465017318726, train/logprobs = tensor([[-0.8201, -1.1983],
        [-1.4104, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08043263852596283
Epoch 0, Step 524: train/loss = 0.6599259972572327, train/raw-loss = 0.6229013204574585, train/logprobs = tensor([[-0.8038, -1.6233],
        [-0.9258, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07404937595129013
Epoch 0, Step 525: train/loss = 0.6835039258003235, train/raw-loss = 0.6485683917999268, train/logprobs = tensor([[-0.8408, -1.2113],
        [-1.0796, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06987104564905167
Epoch 0, Step 526: train/loss = 0.6055075526237488, train/raw-loss = 0.5624104142189026, train/logprobs = tensor([[-0.6290, -2.1418],
        [-0.8989, -1.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08619426935911179
Epoch 0, Step 527: train/loss = 0.6262372136116028, train/raw-loss = 0.5957632660865784, train/logprobs = tensor([[-0.5862, -1.4264],
        [-0.8593, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06094788387417793
Epoch 0, Step 528: train/loss = 0.6630302667617798, train/raw-loss = 0.6219433546066284, train/logprobs = tensor([[-0.6600, -1.0042],
        [-1.0076, -0.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08217380940914154
Epoch 0, Step 529: train/loss = 0.7244012355804443, train/raw-loss = 0.6984601616859436, train/logprobs = tensor([[-0.7561, -1.2684],
        [-0.9006, -1.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05188214033842087
Epoch 0, Step 530: train/loss = 0.5725259780883789, train/raw-loss = 0.534494936466217, train/logprobs = tensor([[-0.6646, -2.0888],
        [-0.9632, -1.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07606197893619537
Epoch 0, Step 531: train/loss = 0.6774849891662598, train/raw-loss = 0.6361891031265259, train/logprobs = tensor([[-0.6285, -1.8127],
        [-0.8383, -1.2431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08259165287017822
Epoch 0, Step 532: train/loss = 0.6419913172721863, train/raw-loss = 0.6006048321723938, train/logprobs = tensor([[-1.0352, -2.4767],
        [-1.3531, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08277301490306854
Epoch 0, Step 533: train/loss = 0.5902629494667053, train/raw-loss = 0.548037052154541, train/logprobs = tensor([[-0.4953, -2.2135],
        [-0.6813, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445177972316742
Epoch 0, Step 534: train/loss = 0.624769389629364, train/raw-loss = 0.5874471068382263, train/logprobs = tensor([[-0.8986, -1.9749],
        [-1.2343, -1.4909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07464450597763062
Epoch 0, Step 535: train/loss = 0.7519123554229736, train/raw-loss = 0.7231619358062744, train/logprobs = tensor([[-1.3504, -1.2357],
        [-1.5612, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05750107392668724
Epoch 0, Step 536: train/loss = 0.7191460728645325, train/raw-loss = 0.6923412680625916, train/logprobs = tensor([[-0.6849, -1.1173],
        [-0.7289, -1.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053609736263751984
Epoch 0, Step 537: train/loss = 0.6796843409538269, train/raw-loss = 0.6553345918655396, train/logprobs = tensor([[-0.8569, -1.2504],
        [-1.0040, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04869944229722023
Epoch 0, Step 538: train/loss = 0.7187851667404175, train/raw-loss = 0.6954976320266724, train/logprobs = tensor([[-0.5666, -0.6733],
        [-0.5421, -0.6260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04657500237226486
Epoch 0, Step 539: train/loss = 0.6304925680160522, train/raw-loss = 0.5959601998329163, train/logprobs = tensor([[-0.6044, -1.3735],
        [-0.9531, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06906487047672272
Epoch 0, Step 540: train/loss = 0.6970696449279785, train/raw-loss = 0.669173002243042, train/logprobs = tensor([[-0.5542, -0.8611],
        [-0.5288, -0.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055793389678001404
Epoch 0, Step 541: train/loss = 0.6715774536132812, train/raw-loss = 0.6413745880126953, train/logprobs = tensor([[-0.8776, -1.1946],
        [-1.1909, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060405634343624115
Epoch 0, Step 542: train/loss = 0.6547423005104065, train/raw-loss = 0.6198627948760986, train/logprobs = tensor([[-0.5844, -1.2446],
        [-0.6899, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06975913792848587
Epoch 0, Step 543: train/loss = 0.6502197980880737, train/raw-loss = 0.6119807958602905, train/logprobs = tensor([[-0.7558, -1.0496],
        [-1.0730, -0.6832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07647804915904999
Epoch 0, Step 544: train/loss = 0.6900581121444702, train/raw-loss = 0.661648690700531, train/logprobs = tensor([[-0.6136, -1.1210],
        [-0.5712, -0.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05681891739368439
Epoch 0, Step 545: train/loss = 0.7466957569122314, train/raw-loss = 0.703595757484436, train/logprobs = tensor([[-0.6479, -1.0785],
        [-1.4389, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08620014041662216
Epoch 0, Step 546: train/loss = 0.7170770168304443, train/raw-loss = 0.6898702383041382, train/logprobs = tensor([[-0.4851, -0.7348],
        [-0.4977, -0.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054413504898548126
Epoch 0, Step 547: train/loss = 0.5977286100387573, train/raw-loss = 0.547426164150238, train/logprobs = tensor([[-0.8550, -1.5841],
        [-1.6093, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060487687587738
Epoch 0, Step 548: train/loss = 0.6753845810890198, train/raw-loss = 0.6415876150131226, train/logprobs = tensor([[-0.8353, -1.6116],
        [-1.0853, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06759391725063324
Epoch 0, Step 549: train/loss = 0.6993166208267212, train/raw-loss = 0.6649777889251709, train/logprobs = tensor([[-0.7689, -1.7916],
        [-0.8978, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06867769360542297
Epoch 0, Step 550: train/loss = 0.777998685836792, train/raw-loss = 0.748389720916748, train/logprobs = tensor([[-0.8366, -1.1404],
        [-1.0776, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059217967092990875
Epoch 0, Step 551: train/loss = 0.661942183971405, train/raw-loss = 0.6296861171722412, train/logprobs = tensor([[-0.7228, -1.4437],
        [-0.8361, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06451214849948883
Epoch 0, Step 552: train/loss = 0.6104787588119507, train/raw-loss = 0.5694332122802734, train/logprobs = tensor([[-0.7248, -1.5718],
        [-1.2341, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209126442670822
Epoch 0, Step 553: train/loss = 0.6856244802474976, train/raw-loss = 0.6428554654121399, train/logprobs = tensor([[-0.5155, -1.2607],
        [-0.5046, -0.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08553794026374817
Epoch 0, Step 554: train/loss = 0.7082256078720093, train/raw-loss = 0.6744279265403748, train/logprobs = tensor([[-0.5514, -0.7492],
        [-0.6944, -0.6676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06759548932313919
Epoch 0, Step 555: train/loss = 0.6818561553955078, train/raw-loss = 0.6580123901367188, train/logprobs = tensor([[-0.5637, -1.1811],
        [-0.5712, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04768753796815872
Epoch 0, Step 556: train/loss = 0.6094976663589478, train/raw-loss = 0.583889365196228, train/logprobs = tensor([[-0.6028, -2.0233],
        [-0.7557, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05121655762195587
Epoch 0, Step 557: train/loss = 0.7103966474533081, train/raw-loss = 0.6796280145645142, train/logprobs = tensor([[-0.8181, -0.7782],
        [-1.0160, -0.7075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061537258327007294
Epoch 0, Step 558: train/loss = 0.6856973171234131, train/raw-loss = 0.6483280658721924, train/logprobs = tensor([[-0.6646, -1.6136],
        [-0.6381, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07473853975534439
Epoch 0, Step 559: train/loss = 0.5883381366729736, train/raw-loss = 0.5467450022697449, train/logprobs = tensor([[-0.7620, -1.9016],
        [-1.2630, -1.1414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08318624645471573
Epoch 0, Step 560: train/loss = 0.6290140748023987, train/raw-loss = 0.5759767293930054, train/logprobs = tensor([[-0.6527, -1.2516],
        [-1.4299, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607466846704483
Epoch 0, Step 561: train/loss = 0.7255620956420898, train/raw-loss = 0.6989133358001709, train/logprobs = tensor([[-0.8832, -1.0121],
        [-1.1926, -1.0518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0532974898815155
Epoch 0, Step 562: train/loss = 0.6790503859519958, train/raw-loss = 0.6478458642959595, train/logprobs = tensor([[-0.9041, -1.1693],
        [-1.3451, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06240897998213768
Epoch 0, Step 563: train/loss = 0.5770978331565857, train/raw-loss = 0.5363152027130127, train/logprobs = tensor([[-0.8069, -1.9888],
        [-1.4579, -1.3422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08156527578830719
Epoch 0, Step 564: train/loss = 0.5880281925201416, train/raw-loss = 0.5397166609764099, train/logprobs = tensor([[-0.4704, -1.7176],
        [-0.8091, -0.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0966230183839798
Epoch 0, Step 565: train/loss = 0.6813062429428101, train/raw-loss = 0.6453577876091003, train/logprobs = tensor([[-0.7834, -1.0991],
        [-1.0115, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07189684361219406
Epoch 0, Step 566: train/loss = 0.6550251245498657, train/raw-loss = 0.6206069588661194, train/logprobs = tensor([[-0.7209, -1.2054],
        [-1.1155, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0688362792134285
Epoch 0, Step 567: train/loss = 0.634639322757721, train/raw-loss = 0.6028093099594116, train/logprobs = tensor([[-0.5302, -1.1890],
        [-0.7978, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06365999579429626
Epoch 0, Step 568: train/loss = 0.5935355424880981, train/raw-loss = 0.5479452610015869, train/logprobs = tensor([[-0.7938, -1.5593],
        [-1.4744, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09118044376373291
Epoch 0, Step 569: train/loss = 0.6866030097007751, train/raw-loss = 0.6529827117919922, train/logprobs = tensor([[-0.4481, -1.2175],
        [-0.4813, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06724072992801666
Epoch 0, Step 570: train/loss = 0.6695020794868469, train/raw-loss = 0.6376672387123108, train/logprobs = tensor([[-0.8361, -1.2959],
        [-0.8354, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06366966664791107
Epoch 0, Step 571: train/loss = 0.7335509657859802, train/raw-loss = 0.6901420950889587, train/logprobs = tensor([[-0.8876, -0.9705],
        [-1.7376, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08681789040565491
Epoch 0, Step 572: train/loss = 0.5984821915626526, train/raw-loss = 0.5723469257354736, train/logprobs = tensor([[-0.7760, -1.5082],
        [-1.0245, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05227048322558403
Epoch 0, Step 573: train/loss = 0.5284069776535034, train/raw-loss = 0.4738445281982422, train/logprobs = tensor([[-0.6584, -1.9900],
        [-1.6509, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10912494361400604
Epoch 0, Step 574: train/loss = 0.7591527104377747, train/raw-loss = 0.724480390548706, train/logprobs = tensor([[-1.1566, -1.8502],
        [-1.5335, -1.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0693446695804596
Epoch 0, Step 575: train/loss = 0.6872949004173279, train/raw-loss = 0.6539022922515869, train/logprobs = tensor([[-0.9150, -1.3962],
        [-1.1515, -1.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06678539514541626
Epoch 0, Step 576: train/loss = 0.6258490085601807, train/raw-loss = 0.5853737592697144, train/logprobs = tensor([[-0.8919, -0.8707],
        [-1.5342, -0.5814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08095048367977142
Epoch 0, Step 577: train/loss = 0.6936811208724976, train/raw-loss = 0.6519255042076111, train/logprobs = tensor([[-0.7506, -1.1694],
        [-1.1459, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08351122587919235
Epoch 0, Step 578: train/loss = 0.6862690448760986, train/raw-loss = 0.6277318000793457, train/logprobs = tensor([[-0.9285, -1.3885],
        [-1.4428, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11707456409931183
Epoch 0, Step 579: train/loss = 0.6798989176750183, train/raw-loss = 0.6551666259765625, train/logprobs = tensor([[-0.6044, -1.1276],
        [-0.6375, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04946455359458923
Epoch 0, Step 580: train/loss = 0.6986144185066223, train/raw-loss = 0.6661365032196045, train/logprobs = tensor([[-0.6291, -1.1627],
        [-0.7027, -0.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06495600938796997
Epoch 0, Step 581: train/loss = 0.6498831510543823, train/raw-loss = 0.6119948625564575, train/logprobs = tensor([[-0.9473, -1.1084],
        [-1.3857, -0.8734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07577665150165558
Epoch 0, Step 582: train/loss = 0.651247501373291, train/raw-loss = 0.600367546081543, train/logprobs = tensor([[-0.7054, -1.2027],
        [-1.5362, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176008939743042
Epoch 0, Step 583: train/loss = 0.6512078642845154, train/raw-loss = 0.5962028503417969, train/logprobs = tensor([[-0.8603, -2.0453],
        [-1.5952, -1.4136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11000999808311462
Epoch 0, Step 584: train/loss = 0.6337321996688843, train/raw-loss = 0.5955218076705933, train/logprobs = tensor([[-0.8666, -1.5428],
        [-1.5440, -1.3787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764208436012268
Epoch 0, Step 585: train/loss = 0.707511305809021, train/raw-loss = 0.6744123697280884, train/logprobs = tensor([[-0.6153, -0.9543],
        [-0.6960, -0.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06619779020547867
Epoch 0, Step 586: train/loss = 0.6462717056274414, train/raw-loss = 0.6006238460540771, train/logprobs = tensor([[-0.7271, -2.0016],
        [-1.2904, -1.6714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09129558503627777
Epoch 0, Step 587: train/loss = 0.6873397827148438, train/raw-loss = 0.6516134142875671, train/logprobs = tensor([[-0.6510, -0.8444],
        [-0.9976, -0.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0714527890086174
Epoch 0, Step 588: train/loss = 0.6999757289886475, train/raw-loss = 0.6589640378952026, train/logprobs = tensor([[-0.4173, -0.8987],
        [-0.5029, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820232629776001
Epoch 0, Step 589: train/loss = 0.6516949534416199, train/raw-loss = 0.6228207349777222, train/logprobs = tensor([[-0.4830, -1.1018],
        [-0.5627, -0.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05774844065308571
Epoch 0, Step 590: train/loss = 0.6746591329574585, train/raw-loss = 0.6444246768951416, train/logprobs = tensor([[-0.8925, -1.0079],
        [-1.1707, -0.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060468897223472595
Epoch 0, Step 591: train/loss = 0.7211426496505737, train/raw-loss = 0.6995744705200195, train/logprobs = tensor([[-0.6654, -0.7610],
        [-0.5911, -0.6577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04313625395298004
Epoch 0, Step 592: train/loss = 0.6952157020568848, train/raw-loss = 0.6531597375869751, train/logprobs = tensor([[-0.8294, -1.3192],
        [-1.2256, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08411191403865814
Epoch 0, Step 593: train/loss = 0.6089898347854614, train/raw-loss = 0.558790922164917, train/logprobs = tensor([[-0.5790, -1.3677],
        [-1.0502, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10039794445037842
Epoch 0, Step 594: train/loss = 0.6535441875457764, train/raw-loss = 0.6167787313461304, train/logprobs = tensor([[-0.4757, -1.6147],
        [-0.6144, -1.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07353079319000244
Epoch 0, Step 595: train/loss = 0.6719648838043213, train/raw-loss = 0.6409735083580017, train/logprobs = tensor([[-0.7092, -1.2974],
        [-0.7485, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06198274716734886
Epoch 0, Step 596: train/loss = 0.6908828616142273, train/raw-loss = 0.6651092767715454, train/logprobs = tensor([[-0.6294, -0.9833],
        [-0.6308, -0.7637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05154718831181526
Epoch 0, Step 597: train/loss = 0.6554181575775146, train/raw-loss = 0.6191419363021851, train/logprobs = tensor([[-0.6340, -1.3150],
        [-0.8546, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07255237549543381
Epoch 0, Step 598: train/loss = 0.6899034976959229, train/raw-loss = 0.6615140438079834, train/logprobs = tensor([[-0.6356, -1.0685],
        [-0.6612, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056778933852910995
Epoch 0, Step 599: train/loss = 0.6505628228187561, train/raw-loss = 0.6118254065513611, train/logprobs = tensor([[-0.9974, -1.7225],
        [-1.3171, -1.4486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07747483998537064
Epoch 0, Step 600: train/loss = 0.6032160520553589, train/raw-loss = 0.5678298473358154, train/logprobs = tensor([[-0.8388, -1.0617],
        [-1.6448, -0.7409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07077240943908691
Epoch 0, Step 601: train/loss = 0.6552113890647888, train/raw-loss = 0.61326003074646, train/logprobs = tensor([[-0.8962, -1.7142],
        [-1.5432, -1.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08390278369188309
Epoch 0, Step 602: train/loss = 0.7262398600578308, train/raw-loss = 0.6956849694252014, train/logprobs = tensor([[-1.0672, -1.5407],
        [-1.0091, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06110966205596924
Epoch 0, Step 603: train/loss = 0.5992535352706909, train/raw-loss = 0.5511861443519592, train/logprobs = tensor([[-0.8489, -0.8521],
        [-1.8029, -0.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613475203514099
Epoch 0, Step 604: train/loss = 0.6897155046463013, train/raw-loss = 0.6458879709243774, train/logprobs = tensor([[-0.8369, -1.5278],
        [-1.2747, -1.2925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765514194965363
Epoch 0, Step 605: train/loss = 0.7810406684875488, train/raw-loss = 0.7533586025238037, train/logprobs = tensor([[-0.6443, -0.7996],
        [-0.8810, -1.0344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05536423623561859
Epoch 0, Step 606: train/loss = 0.6753360033035278, train/raw-loss = 0.6479766368865967, train/logprobs = tensor([[-0.5223, -1.0729],
        [-0.6234, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054718807339668274
Epoch 0, Step 607: train/loss = 0.7074212431907654, train/raw-loss = 0.6859963536262512, train/logprobs = tensor([[-0.6209, -0.8362],
        [-0.5532, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04284962639212608
Epoch 0, Step 608: train/loss = 0.6739366054534912, train/raw-loss = 0.6366878747940063, train/logprobs = tensor([[-1.1100, -2.1030],
        [-1.5263, -1.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07449743896722794
Epoch 0, Step 609: train/loss = 0.5539860725402832, train/raw-loss = 0.5074149966239929, train/logprobs = tensor([[-0.7985, -2.5937],
        [-1.3028, -1.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09314219653606415
Epoch 0, Step 610: train/loss = 0.7567231059074402, train/raw-loss = 0.7095595598220825, train/logprobs = tensor([[-1.1665, -1.5898],
        [-1.2621, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09432709962129593
Epoch 0, Step 611: train/loss = 0.7613803148269653, train/raw-loss = 0.7162407636642456, train/logprobs = tensor([[-1.0964, -1.4560],
        [-1.7308, -1.3505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09027907997369766
Epoch 0, Step 612: train/loss = 0.7183716297149658, train/raw-loss = 0.6879903078079224, train/logprobs = tensor([[-0.8856, -1.2839],
        [-0.9161, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06076250597834587
Epoch 0, Step 613: train/loss = 0.705306887626648, train/raw-loss = 0.6610454320907593, train/logprobs = tensor([[-0.9518, -1.0281],
        [-1.4449, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852282911539078
Epoch 0, Step 614: train/loss = 0.6660224199295044, train/raw-loss = 0.6258435249328613, train/logprobs = tensor([[-0.6867, -1.2506],
        [-0.9094, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08035779744386673
Epoch 0, Step 615: train/loss = 0.6585100293159485, train/raw-loss = 0.6193800568580627, train/logprobs = tensor([[-0.6478, -1.6504],
        [-1.0792, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07825998961925507
Epoch 0, Step 616: train/loss = 0.7184252738952637, train/raw-loss = 0.6810267567634583, train/logprobs = tensor([[-0.5229, -1.0223],
        [-0.5419, -0.8178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07479704916477203
Epoch 0, Step 617: train/loss = 0.6866963505744934, train/raw-loss = 0.6428226232528687, train/logprobs = tensor([[-0.7858, -0.7433],
        [-1.2734, -0.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08774739503860474
Epoch 0, Step 618: train/loss = 0.6998164057731628, train/raw-loss = 0.6601263880729675, train/logprobs = tensor([[-0.6464, -1.3498],
        [-0.6281, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07938003540039062
Epoch 0, Step 619: train/loss = 0.6331815719604492, train/raw-loss = 0.5830283761024475, train/logprobs = tensor([[-1.1942, -1.5687],
        [-1.8016, -1.2218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10030648112297058
Epoch 0, Step 620: train/loss = 0.680823802947998, train/raw-loss = 0.6466046571731567, train/logprobs = tensor([[-1.0899, -1.4608],
        [-1.3332, -1.2865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06843822449445724
Epoch 0, Step 621: train/loss = 0.6845372915267944, train/raw-loss = 0.6629636287689209, train/logprobs = tensor([[-0.9922, -1.0218],
        [-1.2589, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04314742982387543
Epoch 0, Step 622: train/loss = 0.6221967339515686, train/raw-loss = 0.5795501470565796, train/logprobs = tensor([[-0.6399, -1.9639],
        [-0.9686, -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529312908649445
Epoch 0, Step 623: train/loss = 0.5908339619636536, train/raw-loss = 0.5378533601760864, train/logprobs = tensor([[-0.8886, -2.4781],
        [-1.4001, -1.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10596116632223129
Epoch 0, Step 624: train/loss = 0.7216291427612305, train/raw-loss = 0.6839998960494995, train/logprobs = tensor([[-0.6173, -1.2075],
        [-0.7005, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07525845617055893
Epoch 0, Step 625: train/loss = 0.6260001063346863, train/raw-loss = 0.5792022347450256, train/logprobs = tensor([[-0.8810, -1.6057],
        [-1.3410, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09359575062990189
Epoch 0, Step 626: train/loss = 0.6650117635726929, train/raw-loss = 0.6322948336601257, train/logprobs = tensor([[-0.9725, -1.6136],
        [-1.1256, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06543383002281189
Epoch 0, Step 627: train/loss = 0.8212667107582092, train/raw-loss = 0.7864230275154114, train/logprobs = tensor([[-0.9211, -1.3950],
        [-1.0165, -1.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06968748569488525
Epoch 0, Step 628: train/loss = 0.6978316307067871, train/raw-loss = 0.6585654616355896, train/logprobs = tensor([[-0.7511, -0.9096],
        [-0.9123, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07853244245052338
Epoch 0, Step 629: train/loss = 0.6822441816329956, train/raw-loss = 0.6364433169364929, train/logprobs = tensor([[-1.1375, -1.4210],
        [-1.7172, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0916016548871994
Epoch 0, Step 630: train/loss = 0.793086588382721, train/raw-loss = 0.7482281923294067, train/logprobs = tensor([[-0.7903, -1.5207],
        [-1.2662, -1.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08971681445837021
Epoch 0, Step 631: train/loss = 0.6313422918319702, train/raw-loss = 0.587835967540741, train/logprobs = tensor([[-0.7313, -1.7344],
        [-1.2589, -1.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08701267838478088
Epoch 0, Step 632: train/loss = 0.6731613874435425, train/raw-loss = 0.6446794271469116, train/logprobs = tensor([[-0.6239, -1.3661],
        [-0.6503, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056963879615068436
Epoch 0, Step 633: train/loss = 0.6496245861053467, train/raw-loss = 0.6109308004379272, train/logprobs = tensor([[-0.5580, -0.9809],
        [-0.9572, -0.7222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07738758623600006
Epoch 0, Step 634: train/loss = 0.6657754182815552, train/raw-loss = 0.6180528402328491, train/logprobs = tensor([[-0.6756, -1.3591],
        [-0.8316, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09544508159160614
Epoch 0, Step 635: train/loss = 0.6181977987289429, train/raw-loss = 0.5762233138084412, train/logprobs = tensor([[-0.8787, -1.6821],
        [-1.1984, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08394898474216461
Epoch 0, Step 636: train/loss = 0.6339163780212402, train/raw-loss = 0.5912115573883057, train/logprobs = tensor([[-0.5774, -1.8163],
        [-0.9500, -1.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08540954440832138
Epoch 0, Step 637: train/loss = 0.7078088521957397, train/raw-loss = 0.6837946176528931, train/logprobs = tensor([[-0.4751, -0.7025],
        [-0.4707, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04802838712930679
Epoch 0, Step 638: train/loss = 0.6321257948875427, train/raw-loss = 0.5945950746536255, train/logprobs = tensor([[-0.6728, -1.2237],
        [-1.1642, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07506152987480164
Epoch 0, Step 639: train/loss = 0.6737790107727051, train/raw-loss = 0.6285907030105591, train/logprobs = tensor([[-0.6214, -1.3388],
        [-0.7788, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09037655591964722
Epoch 0, Step 640: train/loss = 0.7055219411849976, train/raw-loss = 0.6731728315353394, train/logprobs = tensor([[-0.6560, -1.0097],
        [-0.8146, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469819694757462
Epoch 0, Step 641: train/loss = 0.6294080018997192, train/raw-loss = 0.5981243252754211, train/logprobs = tensor([[-0.7404, -1.0686],
        [-1.2079, -0.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06256739050149918
Epoch 0, Step 642: train/loss = 0.6347980499267578, train/raw-loss = 0.5890217423439026, train/logprobs = tensor([[-0.8002, -1.9504],
        [-1.0716, -1.4610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09155260026454926
Epoch 0, Step 643: train/loss = 0.7277519106864929, train/raw-loss = 0.679479718208313, train/logprobs = tensor([[-1.1262, -0.8839],
        [-1.5767, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09654438495635986
Epoch 0, Step 644: train/loss = 0.6122182011604309, train/raw-loss = 0.5609369874000549, train/logprobs = tensor([[-0.5300, -2.0816],
        [-0.9096, -1.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10256239026784897
Epoch 0, Step 645: train/loss = 0.6599852442741394, train/raw-loss = 0.6197318434715271, train/logprobs = tensor([[-0.7279, -1.3267],
        [-1.0552, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08050686120986938
Epoch 0, Step 646: train/loss = 0.6089404821395874, train/raw-loss = 0.5567110776901245, train/logprobs = tensor([[-1.0476, -1.7812],
        [-1.9143, -1.5562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10445880889892578
Epoch 0, Step 647: train/loss = 0.6916553974151611, train/raw-loss = 0.6603277325630188, train/logprobs = tensor([[-0.5922, -0.9089],
        [-0.7362, -0.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06265519559383392
Epoch 0, Step 648: train/loss = 0.6069157123565674, train/raw-loss = 0.5561062097549438, train/logprobs = tensor([[-0.9237, -1.6431],
        [-1.6752, -1.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10161898285150528
Epoch 0, Step 649: train/loss = 0.6941659450531006, train/raw-loss = 0.6643681526184082, train/logprobs = tensor([[-0.5096, -0.9071],
        [-0.5709, -0.7335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0595954954624176
Epoch 0, Step 650: train/loss = 0.6489200592041016, train/raw-loss = 0.5983391404151917, train/logprobs = tensor([[-0.7170, -1.1792],
        [-1.2505, -0.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10116180777549744
Epoch 0, Step 651: train/loss = 0.6404259204864502, train/raw-loss = 0.5957539677619934, train/logprobs = tensor([[-0.7393, -1.7243],
        [-1.1043, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08934380859136581
Epoch 0, Step 652: train/loss = 0.6396159529685974, train/raw-loss = 0.5993466377258301, train/logprobs = tensor([[-0.7922, -1.1565],
        [-1.1824, -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08053865283727646
Epoch 0, Step 653: train/loss = 0.6816760301589966, train/raw-loss = 0.6350700259208679, train/logprobs = tensor([[-0.6325, -0.8886],
        [-0.9584, -0.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09321199357509613
Epoch 0, Step 654: train/loss = 0.6151027083396912, train/raw-loss = 0.5655938982963562, train/logprobs = tensor([[-0.6661, -1.3397],
        [-1.4923, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09901772439479828
Epoch 0, Step 655: train/loss = 0.6928096413612366, train/raw-loss = 0.6441301703453064, train/logprobs = tensor([[-0.7422, -0.5787],
        [-1.2875, -0.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09735888242721558
Epoch 0, Step 656: train/loss = 0.6364467144012451, train/raw-loss = 0.5875741839408875, train/logprobs = tensor([[-1.1679, -1.7632],
        [-1.7943, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09774503856897354
Epoch 0, Step 657: train/loss = 0.5899096727371216, train/raw-loss = 0.537251353263855, train/logprobs = tensor([[-0.6683, -2.9209],
        [-1.0989, -1.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10531651228666306
Epoch 0, Step 658: train/loss = 0.6640883684158325, train/raw-loss = 0.628376841545105, train/logprobs = tensor([[-0.7214, -0.9005],
        [-1.1873, -0.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07142308354377747
Epoch 0, Step 659: train/loss = 0.7565877437591553, train/raw-loss = 0.7183395624160767, train/logprobs = tensor([[-0.8983, -0.9180],
        [-0.9671, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07649635523557663
Epoch 0, Step 660: train/loss = 0.6581234335899353, train/raw-loss = 0.6127783060073853, train/logprobs = tensor([[-1.0624, -1.1320],
        [-1.7735, -1.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09069029986858368
Epoch 0, Step 661: train/loss = 0.6884797215461731, train/raw-loss = 0.635033369064331, train/logprobs = tensor([[-0.9701, -1.4581],
        [-1.4466, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10689273476600647
Epoch 0, Step 662: train/loss = 0.7141367793083191, train/raw-loss = 0.6574000120162964, train/logprobs = tensor([[-0.7257, -1.2248],
        [-1.1655, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11347348242998123
Epoch 0, Step 663: train/loss = 0.5669277310371399, train/raw-loss = 0.520698606967926, train/logprobs = tensor([[-0.9697, -2.7599],
        [-1.7640, -2.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09245824068784714
Epoch 0, Step 664: train/loss = 0.6904997229576111, train/raw-loss = 0.6554628610610962, train/logprobs = tensor([[-0.8089, -1.4402],
        [-1.1484, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07007375359535217
Epoch 0, Step 665: train/loss = 0.7109596729278564, train/raw-loss = 0.65727299451828, train/logprobs = tensor([[-0.6165, -1.1923],
        [-0.8053, -0.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10737326741218567
Epoch 0, Step 666: train/loss = 0.6568652391433716, train/raw-loss = 0.6198428869247437, train/logprobs = tensor([[-0.8500, -1.8381],
        [-1.0076, -1.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07404473423957825
Epoch 0, Step 667: train/loss = 0.6270756721496582, train/raw-loss = 0.5834424495697021, train/logprobs = tensor([[-0.5838, -1.4306],
        [-1.0762, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08726654946804047
Epoch 0, Step 668: train/loss = 0.6541813611984253, train/raw-loss = 0.6146459579467773, train/logprobs = tensor([[-0.9909, -1.5064],
        [-1.2637, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07907083630561829
Epoch 0, Step 669: train/loss = 0.6985297203063965, train/raw-loss = 0.654254674911499, train/logprobs = tensor([[-0.9814, -1.6787],
        [-1.4496, -1.5929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854997903108597
Epoch 0, Step 670: train/loss = 0.6107534766197205, train/raw-loss = 0.5704962015151978, train/logprobs = tensor([[-1.0986, -1.8016],
        [-1.7433, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08051453530788422
Epoch 0, Step 671: train/loss = 0.7027354836463928, train/raw-loss = 0.6755378842353821, train/logprobs = tensor([[-0.6868, -0.8728],
        [-0.6467, -0.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0543951652944088
Epoch 0, Step 672: train/loss = 0.6203177571296692, train/raw-loss = 0.5846756100654602, train/logprobs = tensor([[-0.7555, -1.3710],
        [-1.0071, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128432393074036
Epoch 0, Step 673: train/loss = 0.6620334982872009, train/raw-loss = 0.634800136089325, train/logprobs = tensor([[-0.8066, -0.5663],
        [-1.1698, -0.5198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054466672241687775
Epoch 0, Step 674: train/loss = 0.6717779040336609, train/raw-loss = 0.6483668088912964, train/logprobs = tensor([[-0.4745, -0.7891],
        [-0.5307, -0.5564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04682216793298721
Epoch 0, Step 675: train/loss = 0.6381195783615112, train/raw-loss = 0.6035748720169067, train/logprobs = tensor([[-0.9026, -1.6169],
        [-1.2340, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06908944994211197
Epoch 0, Step 676: train/loss = 0.6628886461257935, train/raw-loss = 0.6146993637084961, train/logprobs = tensor([[-0.8360, -1.3133],
        [-1.4759, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963786393404007
Epoch 0, Step 677: train/loss = 0.6638078689575195, train/raw-loss = 0.6264280676841736, train/logprobs = tensor([[-0.5565, -1.1046],
        [-0.9735, -0.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0747596025466919
Epoch 0, Step 678: train/loss = 0.6021398901939392, train/raw-loss = 0.5538040399551392, train/logprobs = tensor([[-0.9964, -1.5781],
        [-1.8850, -1.0460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09667181968688965
Epoch 0, Step 679: train/loss = 0.5972688794136047, train/raw-loss = 0.5526384115219116, train/logprobs = tensor([[-1.0549, -2.2521],
        [-1.6169, -1.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08926084637641907
Epoch 0, Step 680: train/loss = 0.7120503187179565, train/raw-loss = 0.6919258832931519, train/logprobs = tensor([[-0.5893, -0.4978],
        [-0.6261, -0.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04024893790483475
Epoch 0, Step 681: train/loss = 0.7115159034729004, train/raw-loss = 0.6930082440376282, train/logprobs = tensor([[-0.4862, -0.5409],
        [-0.5319, -0.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03701530396938324
Epoch 0, Step 682: train/loss = 0.6482450366020203, train/raw-loss = 0.6033534407615662, train/logprobs = tensor([[-0.5372, -1.6173],
        [-0.6619, -1.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08978316187858582
Epoch 0, Step 683: train/loss = 0.6402738094329834, train/raw-loss = 0.6105167865753174, train/logprobs = tensor([[-1.1511, -1.7877],
        [-1.2637, -1.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05951395258307457
Epoch 0, Step 684: train/loss = 0.6317484378814697, train/raw-loss = 0.5887355804443359, train/logprobs = tensor([[-0.9213, -1.4114],
        [-1.5341, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08602579683065414
Epoch 0, Step 685: train/loss = 0.5977582931518555, train/raw-loss = 0.5458121299743652, train/logprobs = tensor([[-0.9122, -1.3015],
        [-1.7838, -0.9698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389222204685211
Epoch 0, Step 686: train/loss = 0.68031907081604, train/raw-loss = 0.6528690457344055, train/logprobs = tensor([[-0.4629, -1.0441],
        [-0.4921, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05490005016326904
Epoch 0, Step 687: train/loss = 0.7036521434783936, train/raw-loss = 0.6486563086509705, train/logprobs = tensor([[-0.8598, -0.7053],
        [-1.8644, -0.8618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10999145358800888
Epoch 0, Step 688: train/loss = 0.740355372428894, train/raw-loss = 0.7087627053260803, train/logprobs = tensor([[-1.1124, -1.2990],
        [-1.1758, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06318529695272446
Epoch 0, Step 689: train/loss = 0.811255931854248, train/raw-loss = 0.7723372578620911, train/logprobs = tensor([[-0.5813, -1.6199],
        [-0.7038, -1.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07783728092908859
Epoch 0, Step 690: train/loss = 0.6584118008613586, train/raw-loss = 0.6188255548477173, train/logprobs = tensor([[-0.8443, -1.1939],
        [-1.2551, -0.9594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0791725367307663
Epoch 0, Step 691: train/loss = 0.6288694143295288, train/raw-loss = 0.5881973505020142, train/logprobs = tensor([[-0.8434, -1.6839],
        [-1.1179, -1.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08134405314922333
Epoch 0, Step 692: train/loss = 0.7093706130981445, train/raw-loss = 0.6678552627563477, train/logprobs = tensor([[-1.0378, -1.4103],
        [-1.4711, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08303055167198181
Epoch 0, Step 693: train/loss = 0.6339737772941589, train/raw-loss = 0.5991610288619995, train/logprobs = tensor([[-0.7749, -1.6079],
        [-1.1561, -1.2253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06962542235851288
Epoch 0, Step 694: train/loss = 0.6508413553237915, train/raw-loss = 0.6023820638656616, train/logprobs = tensor([[-0.8706, -1.8470],
        [-1.5377, -1.6981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09691862761974335
Epoch 0, Step 695: train/loss = 0.6837854385375977, train/raw-loss = 0.6569476127624512, train/logprobs = tensor([[-0.6612, -1.1065],
        [-0.7143, -0.9108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05367565155029297
Epoch 0, Step 696: train/loss = 0.5854647159576416, train/raw-loss = 0.5429738759994507, train/logprobs = tensor([[-0.8513, -1.6058],
        [-1.5088, -0.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08498173952102661
Epoch 0, Step 697: train/loss = 0.5393778085708618, train/raw-loss = 0.4725135862827301, train/logprobs = tensor([[-0.9450, -1.7906],
        [-2.2265, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133728489279747
Epoch 0, Step 698: train/loss = 0.6725192666053772, train/raw-loss = 0.6345019340515137, train/logprobs = tensor([[-0.8960, -0.9501],
        [-1.3870, -0.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07603470981121063
Epoch 0, Step 699: train/loss = 0.6741003394126892, train/raw-loss = 0.6385632157325745, train/logprobs = tensor([[-0.6156, -1.3960],
        [-0.7250, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107419520616531
Epoch 0, Step 700: train/loss = 0.6036602854728699, train/raw-loss = 0.5567262768745422, train/logprobs = tensor([[-0.7610, -1.7766],
        [-1.2393, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09386803954839706
Epoch 0, Step 701: train/loss = 0.6640430092811584, train/raw-loss = 0.6337032914161682, train/logprobs = tensor([[-0.7344, -1.5116],
        [-0.9084, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060679465532302856
Epoch 0, Step 702: train/loss = 0.6517775654792786, train/raw-loss = 0.6035093069076538, train/logprobs = tensor([[-0.7949, -1.6828],
        [-1.1835, -1.1641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09653636068105698
Epoch 0, Step 703: train/loss = 0.676672637462616, train/raw-loss = 0.6371884346008301, train/logprobs = tensor([[-0.7593, -1.4434],
        [-1.1629, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07896842062473297
Epoch 0, Step 704: train/loss = 0.6447281241416931, train/raw-loss = 0.5847811698913574, train/logprobs = tensor([[-0.8463, -2.7195],
        [-1.8618, -2.1791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11989390105009079
Epoch 0, Step 705: train/loss = 0.6602513790130615, train/raw-loss = 0.6304783225059509, train/logprobs = tensor([[-0.5431, -1.2863],
        [-0.5804, -0.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05954606831073761
Epoch 0, Step 706: train/loss = 0.695292592048645, train/raw-loss = 0.669093668460846, train/logprobs = tensor([[-0.5602, -0.8759],
        [-0.5943, -0.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05239786580204964
Epoch 0, Step 707: train/loss = 0.5884276628494263, train/raw-loss = 0.5500106811523438, train/logprobs = tensor([[-0.9888, -1.7222],
        [-1.7437, -1.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07683396339416504
Epoch 0, Step 708: train/loss = 0.6659177541732788, train/raw-loss = 0.6356925964355469, train/logprobs = tensor([[-0.9190, -1.6277],
        [-1.3841, -1.4795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060450296849012375
Epoch 0, Step 709: train/loss = 0.5802760720252991, train/raw-loss = 0.5464925765991211, train/logprobs = tensor([[-0.9588, -2.5913],
        [-1.5064, -1.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06756707280874252
Epoch 0, Step 710: train/loss = 0.672661304473877, train/raw-loss = 0.6447328329086304, train/logprobs = tensor([[-0.6375, -1.6714],
        [-0.7210, -1.1068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055856987833976746
Epoch 0, Step 711: train/loss = 0.7111051678657532, train/raw-loss = 0.6686495542526245, train/logprobs = tensor([[-0.7450, -1.9710],
        [-1.0236, -1.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08491124212741852
Epoch 0, Step 712: train/loss = 0.7013227343559265, train/raw-loss = 0.655596137046814, train/logprobs = tensor([[-0.7932, -1.0575],
        [-1.0001, -0.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09145304560661316
Epoch 0, Step 713: train/loss = 0.6636763215065002, train/raw-loss = 0.6308063268661499, train/logprobs = tensor([[-0.6202, -1.2956],
        [-0.9783, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06573999673128128
Epoch 0, Step 714: train/loss = 0.6204646825790405, train/raw-loss = 0.5815978050231934, train/logprobs = tensor([[-0.8909, -1.5952],
        [-1.3525, -1.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07773379981517792
Epoch 0, Step 715: train/loss = 0.6205661296844482, train/raw-loss = 0.5812389850616455, train/logprobs = tensor([[-0.7980, -1.7593],
        [-1.4770, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0786542147397995
Epoch 0, Step 716: train/loss = 0.6715007424354553, train/raw-loss = 0.6426957249641418, train/logprobs = tensor([[-0.8055, -1.1572],
        [-0.9482, -0.9540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057609982788562775
Epoch 0, Step 717: train/loss = 0.6977066993713379, train/raw-loss = 0.6683351397514343, train/logprobs = tensor([[-1.1896, -0.9317],
        [-1.4043, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05874305218458176
Epoch 0, Step 718: train/loss = 0.6643509864807129, train/raw-loss = 0.6209627985954285, train/logprobs = tensor([[-0.7049, -1.3200],
        [-0.8962, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08677637577056885
Epoch 0, Step 719: train/loss = 0.6251498460769653, train/raw-loss = 0.593497633934021, train/logprobs = tensor([[-0.8833, -1.4884],
        [-1.3120, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330429762601852
Epoch 0, Step 720: train/loss = 0.6198475360870361, train/raw-loss = 0.5859012603759766, train/logprobs = tensor([[-0.6534, -1.1187],
        [-1.1237, -0.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06789248436689377
Epoch 0, Step 721: train/loss = 0.6949945092201233, train/raw-loss = 0.6478927135467529, train/logprobs = tensor([[-0.9872, -1.0974],
        [-1.8589, -1.2304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0942036360502243
Epoch 0, Step 722: train/loss = 0.6656606197357178, train/raw-loss = 0.6354774236679077, train/logprobs = tensor([[-0.4538, -1.3858],
        [-0.4803, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060366351157426834
Epoch 0, Step 723: train/loss = 0.6832651495933533, train/raw-loss = 0.6468966007232666, train/logprobs = tensor([[-0.4890, -1.0390],
        [-0.5628, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07273714244365692
Epoch 0, Step 724: train/loss = 0.7077158689498901, train/raw-loss = 0.6720512509346008, train/logprobs = tensor([[-0.8623, -1.3725],
        [-1.3151, -1.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07132917642593384
Epoch 0, Step 725: train/loss = 0.6530239582061768, train/raw-loss = 0.6248077154159546, train/logprobs = tensor([[-0.6228, -1.5110],
        [-0.7105, -0.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05643240734934807
Epoch 0, Step 726: train/loss = 0.5989556312561035, train/raw-loss = 0.5497597455978394, train/logprobs = tensor([[-0.8951, -1.4516],
        [-1.9817, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09839174896478653
Epoch 0, Step 727: train/loss = 0.683014988899231, train/raw-loss = 0.6417685151100159, train/logprobs = tensor([[-0.7654, -1.6964],
        [-0.8983, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08249285072088242
Epoch 0, Step 728: train/loss = 0.6314064264297485, train/raw-loss = 0.5932759642601013, train/logprobs = tensor([[-0.7259, -1.6295],
        [-0.9328, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07626091688871384
Epoch 0, Step 729: train/loss = 0.6420971155166626, train/raw-loss = 0.6145924925804138, train/logprobs = tensor([[-1.0222, -2.3561],
        [-1.2198, -2.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05500917509198189
Epoch 0, Step 730: train/loss = 0.5641388297080994, train/raw-loss = 0.5236259698867798, train/logprobs = tensor([[-0.9391, -2.1338],
        [-1.4040, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08102568984031677
Epoch 0, Step 731: train/loss = 0.6389430165290833, train/raw-loss = 0.5944544672966003, train/logprobs = tensor([[-0.6943, -1.0080],
        [-1.3643, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08897712826728821
Epoch 0, Step 732: train/loss = 0.677406907081604, train/raw-loss = 0.6441311836242676, train/logprobs = tensor([[-0.7654, -0.8996],
        [-1.0671, -0.8209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0665515586733818
Epoch 0, Step 733: train/loss = 0.600562334060669, train/raw-loss = 0.5624909400939941, train/logprobs = tensor([[-0.8464, -2.3239],
        [-1.1887, -1.6771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07614283263683319
Epoch 0, Step 734: train/loss = 0.6391574144363403, train/raw-loss = 0.6025736927986145, train/logprobs = tensor([[-1.1202, -1.5127],
        [-1.5471, -1.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0731673464179039
Epoch 0, Step 735: train/loss = 0.5635212659835815, train/raw-loss = 0.530637800693512, train/logprobs = tensor([[-0.7925, -2.6541],
        [-1.2309, -1.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06576693803071976
Epoch 0, Step 736: train/loss = 0.6785736083984375, train/raw-loss = 0.6451731324195862, train/logprobs = tensor([[-0.6557, -1.3883],
        [-0.8161, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06680094450712204
Epoch 0, Step 737: train/loss = 0.5684304237365723, train/raw-loss = 0.5207608342170715, train/logprobs = tensor([[-0.8206, -2.0434],
        [-1.4597, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09533925354480743
Epoch 0, Step 738: train/loss = 0.641593873500824, train/raw-loss = 0.5954582691192627, train/logprobs = tensor([[-1.2580, -1.6866],
        [-1.7651, -0.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09227125346660614
Epoch 0, Step 739: train/loss = 0.5616689324378967, train/raw-loss = 0.4990846514701843, train/logprobs = tensor([[-0.8395, -1.9597],
        [-1.7317, -1.3028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12516853213310242
Epoch 0, Step 740: train/loss = 0.6386286020278931, train/raw-loss = 0.6051252484321594, train/logprobs = tensor([[-1.3622, -2.2618],
        [-1.7487, -1.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670066773891449
Epoch 0, Step 741: train/loss = 0.6672290563583374, train/raw-loss = 0.6209171414375305, train/logprobs = tensor([[-0.7205, -1.3586],
        [-1.0570, -0.9737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09262388944625854
Epoch 0, Step 742: train/loss = 0.5714297294616699, train/raw-loss = 0.5359280109405518, train/logprobs = tensor([[-0.7289, -1.7219],
        [-1.1829, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07100339233875275
Epoch 0, Step 743: train/loss = 0.6708212494850159, train/raw-loss = 0.6281226277351379, train/logprobs = tensor([[-0.4520, -1.5998],
        [-0.4960, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08539710938930511
Epoch 0, Step 744: train/loss = 0.6443305015563965, train/raw-loss = 0.6044785380363464, train/logprobs = tensor([[-0.9012, -1.5037],
        [-1.4211, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07970399409532547
Epoch 0, Step 745: train/loss = 0.6786065101623535, train/raw-loss = 0.6479171514511108, train/logprobs = tensor([[-0.7271, -1.6359],
        [-0.7472, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061378609389066696
Epoch 0, Step 746: train/loss = 0.636405348777771, train/raw-loss = 0.5807039141654968, train/logprobs = tensor([[-1.0131, -2.2903],
        [-1.9211, -1.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11140286177396774
Epoch 0, Step 747: train/loss = 0.6640338897705078, train/raw-loss = 0.6365160942077637, train/logprobs = tensor([[-0.7077, -0.9377],
        [-0.8759, -0.7313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05503564327955246
Epoch 0, Step 748: train/loss = 0.652476966381073, train/raw-loss = 0.6155789494514465, train/logprobs = tensor([[-1.1874, -1.5008],
        [-1.6670, -1.2995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07379605621099472
Epoch 0, Step 749: train/loss = 0.6029425859451294, train/raw-loss = 0.5676900744438171, train/logprobs = tensor([[-1.0007, -1.9944],
        [-1.3624, -1.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07050491124391556
Epoch 0, Step 750: train/loss = 0.6246408224105835, train/raw-loss = 0.5954114198684692, train/logprobs = tensor([[-0.9591, -1.9195],
        [-1.1213, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058458808809518814
Epoch 0, Step 751: train/loss = 0.6094209551811218, train/raw-loss = 0.5735698342323303, train/logprobs = tensor([[-0.8635, -1.5570],
        [-1.4622, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07170215994119644
Epoch 0, Step 752: train/loss = 0.6696896553039551, train/raw-loss = 0.6214033961296082, train/logprobs = tensor([[-0.6584, -1.4660],
        [-0.9442, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657241404056549
Epoch 0, Step 753: train/loss = 0.5725691318511963, train/raw-loss = 0.524023175239563, train/logprobs = tensor([[-0.9758, -1.7365],
        [-1.6705, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09709189087152481
Epoch 0, Step 754: train/loss = 0.597023606300354, train/raw-loss = 0.5496249794960022, train/logprobs = tensor([[-0.8573, -2.3399],
        [-1.1666, -1.5199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947972983121872
Epoch 0, Step 755: train/loss = 0.517047643661499, train/raw-loss = 0.4700357913970947, train/logprobs = tensor([[-0.8618, -2.1755],
        [-1.4357, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09402375668287277
Epoch 0, Step 756: train/loss = 0.6441585421562195, train/raw-loss = 0.6085045337677002, train/logprobs = tensor([[-0.6665, -1.1279],
        [-1.0646, -0.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07130797207355499
Epoch 0, Step 757: train/loss = 0.621295690536499, train/raw-loss = 0.5829308032989502, train/logprobs = tensor([[-0.6002, -1.6276],
        [-0.9408, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767299234867096
Epoch 0, Step 758: train/loss = 0.672359824180603, train/raw-loss = 0.6399849653244019, train/logprobs = tensor([[-0.6541, -1.1329],
        [-0.7702, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06474974006414413
Epoch 0, Step 759: train/loss = 0.6356163620948792, train/raw-loss = 0.5824737548828125, train/logprobs = tensor([[-0.7702, -0.8869],
        [-1.4536, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1062852144241333
Epoch 0, Step 760: train/loss = 0.5937583446502686, train/raw-loss = 0.5497733354568481, train/logprobs = tensor([[-1.0835, -1.6279],
        [-1.8851, -1.2151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08797013014554977
Epoch 0, Step 761: train/loss = 0.6993155479431152, train/raw-loss = 0.6755147576332092, train/logprobs = tensor([[-0.6484, -1.0130],
        [-0.6738, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047601502388715744
Epoch 0, Step 762: train/loss = 0.6625205874443054, train/raw-loss = 0.6391201615333557, train/logprobs = tensor([[-0.7438, -1.5375],
        [-0.7309, -1.1463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04680081456899643
Epoch 0, Step 763: train/loss = 0.6161077618598938, train/raw-loss = 0.579290509223938, train/logprobs = tensor([[-0.5679, -1.5366],
        [-0.8704, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07363447546958923
Epoch 0, Step 764: train/loss = 0.6250147223472595, train/raw-loss = 0.5826536417007446, train/logprobs = tensor([[-1.4723, -1.7378],
        [-1.8332, -1.2622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08472220599651337
Epoch 0, Step 765: train/loss = 0.5890604853630066, train/raw-loss = 0.5436924695968628, train/logprobs = tensor([[-0.9749, -1.7207],
        [-1.7920, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073594212532043
Epoch 0, Step 766: train/loss = 0.656220018863678, train/raw-loss = 0.6149007081985474, train/logprobs = tensor([[-0.5755, -1.2280],
        [-0.8945, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08263860642910004
Epoch 0, Step 767: train/loss = 0.562728226184845, train/raw-loss = 0.5203584432601929, train/logprobs = tensor([[-0.6959, -3.2182],
        [-1.1010, -2.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08473942428827286
Epoch 0, Step 768: train/loss = 0.6731700897216797, train/raw-loss = 0.6421645879745483, train/logprobs = tensor([[-0.7789, -1.1723],
        [-0.9821, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06201097369194031
Epoch 0, Step 769: train/loss = 0.5391703248023987, train/raw-loss = 0.48719483613967896, train/logprobs = tensor([[-0.9795, -1.8557],
        [-1.8951, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10395097732543945
Epoch 0, Step 770: train/loss = 0.6693919897079468, train/raw-loss = 0.644744873046875, train/logprobs = tensor([[-0.9249, -0.8247],
        [-1.2987, -0.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049294304102659225
Epoch 0, Step 771: train/loss = 0.6462078094482422, train/raw-loss = 0.6018016338348389, train/logprobs = tensor([[-0.8405, -1.1684],
        [-1.3066, -0.9446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08881231397390366
Epoch 0, Step 772: train/loss = 0.5703926086425781, train/raw-loss = 0.5293678641319275, train/logprobs = tensor([[-0.7722, -2.3046],
        [-1.4024, -1.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204949647188187
Epoch 0, Step 773: train/loss = 0.6498358249664307, train/raw-loss = 0.6155376434326172, train/logprobs = tensor([[-0.7125, -1.0891],
        [-1.0488, -0.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0685962364077568
Epoch 0, Step 774: train/loss = 0.7040607929229736, train/raw-loss = 0.6439412832260132, train/logprobs = tensor([[-0.9123, -1.8309],
        [-1.7370, -1.6892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12023913115262985
Epoch 0, Step 775: train/loss = 0.5801828503608704, train/raw-loss = 0.5411362648010254, train/logprobs = tensor([[-0.9807, -1.8707],
        [-1.4550, -1.0572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07809318602085114
Epoch 0, Step 776: train/loss = 0.7043267488479614, train/raw-loss = 0.6849613189697266, train/logprobs = tensor([[-0.4418, -0.8293],
        [-0.3786, -0.6643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038730818778276443
Epoch 0, Step 777: train/loss = 0.6099323034286499, train/raw-loss = 0.5674930810928345, train/logprobs = tensor([[-0.8151, -0.8303],
        [-1.6946, -0.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08487854152917862
Epoch 0, Step 778: train/loss = 0.6740226149559021, train/raw-loss = 0.6448901891708374, train/logprobs = tensor([[-0.5603, -1.1758],
        [-0.6502, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0582648403942585
Epoch 0, Step 779: train/loss = 0.6774643063545227, train/raw-loss = 0.6545678973197937, train/logprobs = tensor([[-0.5193, -1.0441],
        [-0.5688, -0.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04579291120171547
Epoch 0, Step 780: train/loss = 0.5228426456451416, train/raw-loss = 0.4757578670978546, train/logprobs = tensor([[-1.1614, -1.7487],
        [-2.2647, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09416940808296204
Epoch 0, Step 781: train/loss = 0.678455114364624, train/raw-loss = 0.6547681093215942, train/logprobs = tensor([[-0.5347, -0.9202],
        [-0.5638, -0.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047373928129673004
Epoch 0, Step 782: train/loss = 0.6368391513824463, train/raw-loss = 0.6041748523712158, train/logprobs = tensor([[-0.5705, -1.8965],
        [-0.7412, -1.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0653286725282669
Epoch 0, Step 783: train/loss = 0.6362961530685425, train/raw-loss = 0.6032558679580688, train/logprobs = tensor([[-0.8136, -1.2506],
        [-1.2316, -0.8946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06608062982559204
Epoch 0, Step 784: train/loss = 0.6400019526481628, train/raw-loss = 0.5981831550598145, train/logprobs = tensor([[-1.2830, -0.9546],
        [-2.1066, -0.7907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363767713308334
Epoch 0, Step 785: train/loss = 0.609432578086853, train/raw-loss = 0.5815252661705017, train/logprobs = tensor([[-0.5924, -1.4833],
        [-1.0508, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055814675986766815
Epoch 0, Step 786: train/loss = 0.6200115084648132, train/raw-loss = 0.5875852108001709, train/logprobs = tensor([[-0.7247, -2.0925],
        [-1.0914, -1.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06485261768102646
Epoch 0, Step 787: train/loss = 0.6648553609848022, train/raw-loss = 0.6380058526992798, train/logprobs = tensor([[-1.0232, -1.3175],
        [-1.0811, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053699053823947906
Epoch 0, Step 788: train/loss = 0.5924825668334961, train/raw-loss = 0.5584537982940674, train/logprobs = tensor([[-1.0113, -2.3271],
        [-1.2859, -1.6215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06805770099163055
Epoch 0, Step 789: train/loss = 0.646622896194458, train/raw-loss = 0.6169883012771606, train/logprobs = tensor([[-0.5806, -1.2479],
        [-0.7487, -0.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05926920473575592
Epoch 0, Step 790: train/loss = 0.6368279457092285, train/raw-loss = 0.598055362701416, train/logprobs = tensor([[-1.3312, -1.8078],
        [-1.8814, -1.5008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07754521071910858
Epoch 0, Step 791: train/loss = 0.648529052734375, train/raw-loss = 0.6076598763465881, train/logprobs = tensor([[-0.8430, -1.5224],
        [-1.2626, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08173846453428268
Epoch 0, Step 792: train/loss = 0.7384569644927979, train/raw-loss = 0.712898850440979, train/logprobs = tensor([[-0.8656, -0.4335],
        [-0.9148, -0.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05111616849899292
Epoch 0, Step 793: train/loss = 0.6543937921524048, train/raw-loss = 0.6048743724822998, train/logprobs = tensor([[-0.8772, -1.3321],
        [-1.3330, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09903888404369354
Epoch 0, Step 794: train/loss = 0.6706557869911194, train/raw-loss = 0.6389864683151245, train/logprobs = tensor([[-0.5692, -1.3612],
        [-0.6860, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06333860009908676
Epoch 0, Step 795: train/loss = 0.6080757975578308, train/raw-loss = 0.5762975811958313, train/logprobs = tensor([[-1.0754, -1.2196],
        [-1.5398, -0.7942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06355642527341843
Epoch 0, Step 796: train/loss = 0.5316950678825378, train/raw-loss = 0.48638322949409485, train/logprobs = tensor([[-1.0769, -2.2462],
        [-2.1100, -1.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906236544251442
Epoch 0, Step 797: train/loss = 0.6733446717262268, train/raw-loss = 0.6430805325508118, train/logprobs = tensor([[-0.9031, -1.7312],
        [-1.1032, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060528337955474854
Epoch 0, Step 798: train/loss = 0.6215611100196838, train/raw-loss = 0.5858039259910583, train/logprobs = tensor([[-0.9413, -1.0776],
        [-1.4272, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07151429355144501
Epoch 0, Step 799: train/loss = 0.6440252065658569, train/raw-loss = 0.601555347442627, train/logprobs = tensor([[-0.8527, -0.7177],
        [-1.6508, -0.6582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08493965864181519
Epoch 0, Step 800: train/loss = 0.7005277872085571, train/raw-loss = 0.674227774143219, train/logprobs = tensor([[-0.6921, -0.9509],
        [-0.6912, -0.7543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05259992182254791
Epoch 0, Step 801: train/loss = 0.7428678870201111, train/raw-loss = 0.7176921367645264, train/logprobs = tensor([[-0.8517, -1.1909],
        [-0.9344, -1.2743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05035160481929779
Epoch 0, Step 802: train/loss = 0.6191500425338745, train/raw-loss = 0.574803352355957, train/logprobs = tensor([[-0.8279, -1.2796],
        [-1.3833, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08869345486164093
Epoch 0, Step 803: train/loss = 0.6701034307479858, train/raw-loss = 0.6497647762298584, train/logprobs = tensor([[-0.6144, -1.1025],
        [-0.7153, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04067734628915787
Epoch 0, Step 804: train/loss = 0.6177268624305725, train/raw-loss = 0.5818142890930176, train/logprobs = tensor([[-0.5528, -1.6210],
        [-0.9457, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07182509452104568
Epoch 0, Step 805: train/loss = 0.6776111125946045, train/raw-loss = 0.6482619047164917, train/logprobs = tensor([[-0.8420, -1.2119],
        [-0.9521, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05869846045970917
Epoch 0, Step 806: train/loss = 0.6781338453292847, train/raw-loss = 0.6511587500572205, train/logprobs = tensor([[-0.6915, -1.3447],
        [-0.8029, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0539502277970314
Epoch 0, Step 807: train/loss = 0.6722828149795532, train/raw-loss = 0.6321024894714355, train/logprobs = tensor([[-0.7651, -1.1695],
        [-1.2518, -1.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08036080002784729
Epoch 0, Step 808: train/loss = 0.6376966238021851, train/raw-loss = 0.6081380844116211, train/logprobs = tensor([[-0.6913, -2.2980],
        [-0.8854, -1.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05911713093519211
Epoch 0, Step 809: train/loss = 0.6392099857330322, train/raw-loss = 0.591974675655365, train/logprobs = tensor([[-0.8166, -1.2314],
        [-1.5376, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09447059035301208
Epoch 0, Step 810: train/loss = 0.5740713477134705, train/raw-loss = 0.537412703037262, train/logprobs = tensor([[-0.7667, -2.6570],
        [-1.1813, -1.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0733172670006752
Epoch 0, Step 811: train/loss = 0.6448341608047485, train/raw-loss = 0.6066857576370239, train/logprobs = tensor([[-0.8489, -1.0397],
        [-1.3356, -0.8598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07629674673080444
Epoch 0, Step 812: train/loss = 0.6152231097221375, train/raw-loss = 0.5860120058059692, train/logprobs = tensor([[-1.0991, -1.4026],
        [-1.6466, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05842217057943344
Epoch 0, Step 813: train/loss = 0.6116567850112915, train/raw-loss = 0.5725064277648926, train/logprobs = tensor([[-0.9194, -1.7366],
        [-1.4994, -1.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0783005803823471
Epoch 0, Step 814: train/loss = 0.7160153388977051, train/raw-loss = 0.695586085319519, train/logprobs = tensor([[-0.7092, -0.7417],
        [-0.6867, -0.5900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04085850715637207
Epoch 0, Step 815: train/loss = 0.6452462077140808, train/raw-loss = 0.6071432828903198, train/logprobs = tensor([[-0.9478, -1.7111],
        [-1.2359, -1.3912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07620594650506973
Epoch 0, Step 816: train/loss = 0.6946256160736084, train/raw-loss = 0.6655353307723999, train/logprobs = tensor([[-0.7093, -1.1844],
        [-0.9256, -1.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05818059295415878
Epoch 0, Step 817: train/loss = 0.6860321760177612, train/raw-loss = 0.6695461273193359, train/logprobs = tensor([[-0.7865, -1.2465],
        [-0.8564, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03297220915555954
Epoch 0, Step 818: train/loss = 0.6096296310424805, train/raw-loss = 0.5798385143280029, train/logprobs = tensor([[-0.9827, -2.1343],
        [-1.0814, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05958211421966553
Epoch 0, Step 819: train/loss = 0.5798848271369934, train/raw-loss = 0.5241591930389404, train/logprobs = tensor([[-0.9913, -1.6514],
        [-1.6846, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11145126819610596
Epoch 0, Step 820: train/loss = 0.5950186848640442, train/raw-loss = 0.5654564499855042, train/logprobs = tensor([[-0.8715, -1.6371],
        [-1.2112, -1.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0591244250535965
Epoch 0, Step 821: train/loss = 0.6924468874931335, train/raw-loss = 0.6680223345756531, train/logprobs = tensor([[-0.7611, -0.6784],
        [-0.8436, -0.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04884921386837959
Epoch 0, Step 822: train/loss = 0.7100434303283691, train/raw-loss = 0.6731078624725342, train/logprobs = tensor([[-0.7232, -1.6933],
        [-0.9430, -1.4268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0738711953163147
Epoch 0, Step 823: train/loss = 0.6010547876358032, train/raw-loss = 0.5590635538101196, train/logprobs = tensor([[-0.6360, -1.6936],
        [-1.0635, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08398246765136719
Epoch 0, Step 824: train/loss = 0.655360221862793, train/raw-loss = 0.6193004846572876, train/logprobs = tensor([[-1.1656, -1.3361],
        [-1.5841, -1.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07211959362030029
Epoch 0, Step 825: train/loss = 0.6371375322341919, train/raw-loss = 0.6017971038818359, train/logprobs = tensor([[-0.9197, -1.5175],
        [-1.2441, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706808865070343
Epoch 0, Step 826: train/loss = 0.5741560459136963, train/raw-loss = 0.5307013392448425, train/logprobs = tensor([[-1.2909, -1.4962],
        [-2.0986, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08690943568944931
Epoch 0, Step 827: train/loss = 0.5960640907287598, train/raw-loss = 0.5574382543563843, train/logprobs = tensor([[-0.8092, -1.1814],
        [-1.2892, -0.6747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0772516205906868
Epoch 0, Step 828: train/loss = 0.7007317543029785, train/raw-loss = 0.6757056713104248, train/logprobs = tensor([[-0.7585, -1.5701],
        [-0.8763, -1.4272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050052184611558914
Epoch 0, Step 829: train/loss = 0.5999283790588379, train/raw-loss = 0.5616258382797241, train/logprobs = tensor([[-0.5387, -2.4484],
        [-0.7170, -1.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07660510390996933
Epoch 0, Step 830: train/loss = 0.8086285591125488, train/raw-loss = 0.7808602452278137, train/logprobs = tensor([[-0.6830, -0.7258],
        [-1.0997, -1.1241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055536530911922455
Epoch 0, Step 831: train/loss = 0.6172783374786377, train/raw-loss = 0.5850414037704468, train/logprobs = tensor([[-0.5894, -1.3279],
        [-1.0042, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06447388231754303
Epoch 0, Step 832: train/loss = 0.7527420520782471, train/raw-loss = 0.7073769569396973, train/logprobs = tensor([[-1.2947, -2.3075],
        [-1.6082, -2.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0907301977276802
Epoch 0, Step 833: train/loss = 0.649937093257904, train/raw-loss = 0.6197625398635864, train/logprobs = tensor([[-0.6815, -1.4674],
        [-0.7008, -0.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060349103063344955
Epoch 0, Step 834: train/loss = 0.6677282452583313, train/raw-loss = 0.6372135877609253, train/logprobs = tensor([[-0.5929, -1.5893],
        [-0.6545, -1.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06102937459945679
Epoch 0, Step 835: train/loss = 0.6996746063232422, train/raw-loss = 0.6686873435974121, train/logprobs = tensor([[-0.6608, -1.7037],
        [-0.9315, -1.5568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06197456270456314
Epoch 0, Step 836: train/loss = 0.6588411331176758, train/raw-loss = 0.6369665861129761, train/logprobs = tensor([[-0.7634, -1.6409],
        [-0.7625, -1.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04374918341636658
Epoch 0, Step 837: train/loss = 0.5803999900817871, train/raw-loss = 0.544395923614502, train/logprobs = tensor([[-0.9712, -2.1090],
        [-1.4192, -1.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07200802117586136
Epoch 0, Step 838: train/loss = 0.6470864415168762, train/raw-loss = 0.6184050440788269, train/logprobs = tensor([[-0.6177, -0.6497],
        [-1.0977, -0.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05736283212900162
Epoch 0, Step 839: train/loss = 0.5329089164733887, train/raw-loss = 0.48607587814331055, train/logprobs = tensor([[-0.8832, -3.0989],
        [-1.3810, -1.6903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09366609901189804
Epoch 0, Step 840: train/loss = 0.661564826965332, train/raw-loss = 0.6072745323181152, train/logprobs = tensor([[-1.1707, -2.4118],
        [-2.0052, -1.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10858069360256195
Epoch 0, Step 841: train/loss = 0.6782004237174988, train/raw-loss = 0.6498368382453918, train/logprobs = tensor([[-0.6664, -0.8702],
        [-0.8311, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056727126240730286
Epoch 0, Step 842: train/loss = 0.6443701982498169, train/raw-loss = 0.6163311004638672, train/logprobs = tensor([[-0.8446, -1.3640],
        [-1.0457, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05607818812131882
Epoch 0, Step 843: train/loss = 0.6044790148735046, train/raw-loss = 0.5685452818870544, train/logprobs = tensor([[-1.1452, -3.0079],
        [-1.6401, -2.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07186746597290039
Epoch 0, Step 844: train/loss = 0.6444791555404663, train/raw-loss = 0.5967456102371216, train/logprobs = tensor([[-1.4691, -1.5712],
        [-2.0937, -1.1998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09546715021133423
Epoch 0, Step 845: train/loss = 0.6955161094665527, train/raw-loss = 0.6747907400131226, train/logprobs = tensor([[-0.4962, -1.1780],
        [-0.5303, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04145082086324692
Epoch 0, Step 846: train/loss = 0.6501303315162659, train/raw-loss = 0.6293714046478271, train/logprobs = tensor([[-0.7320, -1.6679],
        [-0.7903, -1.3464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04151787981390953
Epoch 0, Step 847: train/loss = 0.6325732469558716, train/raw-loss = 0.5888409614562988, train/logprobs = tensor([[-1.1598, -1.3803],
        [-1.6435, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08746472746133804
Epoch 0, Step 848: train/loss = 0.735673189163208, train/raw-loss = 0.7116289138793945, train/logprobs = tensor([[-1.3517, -1.0124],
        [-1.9097, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04808863252401352
Epoch 0, Step 849: train/loss = 0.6227622628211975, train/raw-loss = 0.5754043459892273, train/logprobs = tensor([[-0.8869, -1.2061],
        [-1.4564, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09471580386161804
Epoch 0, Step 850: train/loss = 0.6212065815925598, train/raw-loss = 0.5861315727233887, train/logprobs = tensor([[-0.7216, -1.7260],
        [-0.9301, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07015006244182587
Epoch 0, Step 851: train/loss = 0.5946485996246338, train/raw-loss = 0.5611286163330078, train/logprobs = tensor([[-0.8817, -1.2684],
        [-1.3694, -0.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06703998893499374
Epoch 0, Step 852: train/loss = 0.6452178359031677, train/raw-loss = 0.6041631698608398, train/logprobs = tensor([[-0.9507, -1.3866],
        [-1.3032, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08210927248001099
Epoch 0, Step 853: train/loss = 0.7863102555274963, train/raw-loss = 0.7531174421310425, train/logprobs = tensor([[-0.8698, -1.5685],
        [-1.2898, -1.6553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06638568639755249
Epoch 0, Step 854: train/loss = 0.6354501247406006, train/raw-loss = 0.588045597076416, train/logprobs = tensor([[-0.8128, -1.0346],
        [-1.4090, -0.7432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09480901062488556
Epoch 0, Step 855: train/loss = 0.5813740491867065, train/raw-loss = 0.5471877455711365, train/logprobs = tensor([[-0.8252, -1.8026],
        [-1.3286, -1.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06837256997823715
Epoch 0, Step 856: train/loss = 0.6532859802246094, train/raw-loss = 0.6182501316070557, train/logprobs = tensor([[-0.7170, -1.1642],
        [-1.1015, -0.9907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07007168233394623
Epoch 0, Step 857: train/loss = 0.7939974069595337, train/raw-loss = 0.7518143057823181, train/logprobs = tensor([[-0.8211, -0.9416],
        [-1.5482, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08436617255210876
Epoch 0, Step 858: train/loss = 0.6000241041183472, train/raw-loss = 0.5584816932678223, train/logprobs = tensor([[-0.9271, -1.4070],
        [-1.6300, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08308481425046921
Epoch 0, Step 859: train/loss = 0.6861506700515747, train/raw-loss = 0.6590484380722046, train/logprobs = tensor([[-0.7815, -1.2195],
        [-1.0658, -1.1550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05420448258519173
Epoch 0, Step 860: train/loss = 0.7423685789108276, train/raw-loss = 0.7147049903869629, train/logprobs = tensor([[-0.7951, -1.0222],
        [-1.0214, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055327244102954865
Epoch 0, Step 861: train/loss = 0.7031168341636658, train/raw-loss = 0.6718184351921082, train/logprobs = tensor([[-0.5233, -1.2681],
        [-0.5323, -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0625968724489212
Epoch 0, Step 862: train/loss = 0.5559595823287964, train/raw-loss = 0.5127113461494446, train/logprobs = tensor([[-1.1028, -1.6933],
        [-1.9155, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08649656921625137
Epoch 0, Step 863: train/loss = 0.722664475440979, train/raw-loss = 0.6977086067199707, train/logprobs = tensor([[-0.7709, -0.9972],
        [-0.7434, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04991156980395317
Epoch 0, Step 864: train/loss = 0.6701548099517822, train/raw-loss = 0.6291334629058838, train/logprobs = tensor([[-0.7009, -1.2749],
        [-1.0142, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204267919063568
Epoch 0, Step 865: train/loss = 0.7048602104187012, train/raw-loss = 0.6824712753295898, train/logprobs = tensor([[-0.5568, -0.7282],
        [-0.5989, -0.6723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044777922332286835
Epoch 0, Step 866: train/loss = 0.6736330389976501, train/raw-loss = 0.625056266784668, train/logprobs = tensor([[-1.1205, -1.7147],
        [-1.6608, -1.4200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09715364873409271
Epoch 0, Step 867: train/loss = 0.5874852538108826, train/raw-loss = 0.5568053722381592, train/logprobs = tensor([[-1.1481, -1.9246],
        [-1.6543, -1.4545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06135980784893036
Epoch 0, Step 868: train/loss = 0.678621232509613, train/raw-loss = 0.6545819044113159, train/logprobs = tensor([[-0.4987, -1.0113],
        [-0.4930, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048078566789627075
Epoch 0, Step 869: train/loss = 0.7078731656074524, train/raw-loss = 0.6799361705780029, train/logprobs = tensor([[-0.9557, -1.4081],
        [-1.0273, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05587397515773773
Epoch 0, Step 870: train/loss = 0.6926705241203308, train/raw-loss = 0.6663192510604858, train/logprobs = tensor([[-0.6513, -0.8105],
        [-0.7142, -0.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05270250141620636
Epoch 0, Step 871: train/loss = 0.7593033313751221, train/raw-loss = 0.7160088419914246, train/logprobs = tensor([[-1.2225, -2.3198],
        [-1.6142, -2.4723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08658897876739502
Epoch 0, Step 872: train/loss = 0.618988037109375, train/raw-loss = 0.5905827283859253, train/logprobs = tensor([[-0.5031, -1.9495],
        [-0.5315, -1.2806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05681058391928673
Epoch 0, Step 873: train/loss = 0.5426446199417114, train/raw-loss = 0.4910864233970642, train/logprobs = tensor([[-0.7358, -2.6576],
        [-1.2952, -1.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10311644524335861
Epoch 0, Step 874: train/loss = 0.6266264915466309, train/raw-loss = 0.5898224115371704, train/logprobs = tensor([[-0.9294, -1.2433],
        [-1.2991, -0.8137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07360811531543732
Epoch 0, Step 875: train/loss = 0.6780127286911011, train/raw-loss = 0.6506883502006531, train/logprobs = tensor([[-0.8770, -1.2398],
        [-0.9602, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05464882403612137
Epoch 0, Step 876: train/loss = 0.6576881408691406, train/raw-loss = 0.6265499591827393, train/logprobs = tensor([[-0.6195, -1.4618],
        [-0.6787, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06227623671293259
Epoch 0, Step 877: train/loss = 0.5713995695114136, train/raw-loss = 0.5235033631324768, train/logprobs = tensor([[-0.8520, -2.2101],
        [-1.2362, -1.4887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09579243510961533
Epoch 0, Step 878: train/loss = 0.5973128080368042, train/raw-loss = 0.5579198002815247, train/logprobs = tensor([[-0.9188, -1.9168],
        [-1.4391, -1.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07878600060939789
Epoch 0, Step 879: train/loss = 0.6288222074508667, train/raw-loss = 0.593862771987915, train/logprobs = tensor([[-0.8347, -1.3828],
        [-1.3220, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06991876661777496
Epoch 0, Step 880: train/loss = 0.6651804447174072, train/raw-loss = 0.6240968704223633, train/logprobs = tensor([[-0.8315, -1.8951],
        [-1.1306, -1.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08216709643602371
Epoch 0, Step 881: train/loss = 0.627487063407898, train/raw-loss = 0.5979306697845459, train/logprobs = tensor([[-0.6700, -1.5103],
        [-0.8599, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0591127946972847
Epoch 0, Step 882: train/loss = 0.5456652641296387, train/raw-loss = 0.49942776560783386, train/logprobs = tensor([[-1.1511, -2.2481],
        [-1.8093, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09247492998838425
Epoch 0, Step 883: train/loss = 0.6916933655738831, train/raw-loss = 0.6507130861282349, train/logprobs = tensor([[-1.0924, -1.6141],
        [-1.3156, -1.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08196073025465012
Epoch 0, Step 884: train/loss = 0.6713943481445312, train/raw-loss = 0.6461219191551208, train/logprobs = tensor([[-0.9011, -1.4976],
        [-0.8802, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050544921308755875
Epoch 0, Step 885: train/loss = 0.7106890678405762, train/raw-loss = 0.6933282017707825, train/logprobs = tensor([[-0.6240, -0.6147],
        [-0.6187, -0.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03472163528203964
Epoch 0, Step 886: train/loss = 0.6065610647201538, train/raw-loss = 0.5669139623641968, train/logprobs = tensor([[-0.8851, -2.2335],
        [-1.1566, -1.1393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07929413765668869
Epoch 0, Step 887: train/loss = 0.6195334792137146, train/raw-loss = 0.5850502252578735, train/logprobs = tensor([[-0.9104, -1.4614],
        [-1.3943, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06896647810935974
Epoch 0, Step 888: train/loss = 0.6566779613494873, train/raw-loss = 0.6284388303756714, train/logprobs = tensor([[-1.1007, -1.4999],
        [-1.3030, -1.2262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05647830292582512
Epoch 0, Step 889: train/loss = 0.5900170207023621, train/raw-loss = 0.5496772527694702, train/logprobs = tensor([[-0.6523, -1.8875],
        [-1.0866, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08067943900823593
Epoch 0, Step 890: train/loss = 0.6241958141326904, train/raw-loss = 0.5934287905693054, train/logprobs = tensor([[-0.9178, -1.2506],
        [-1.3644, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06153406202793121
Epoch 0, Step 891: train/loss = 0.6789951920509338, train/raw-loss = 0.649423360824585, train/logprobs = tensor([[-0.8337, -0.8842],
        [-1.2063, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059143662452697754
Epoch 0, Step 892: train/loss = 0.5876498222351074, train/raw-loss = 0.54176926612854, train/logprobs = tensor([[-0.8603, -1.5051],
        [-1.5258, -0.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09176118671894073
Epoch 0, Step 893: train/loss = 0.5521789789199829, train/raw-loss = 0.5131205916404724, train/logprobs = tensor([[-0.5774, -2.7407],
        [-0.7821, -1.3276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07811692357063293
Epoch 0, Step 894: train/loss = 0.599987268447876, train/raw-loss = 0.5626533627510071, train/logprobs = tensor([[-0.8386, -1.7125],
        [-1.1965, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07466785609722137
Epoch 0, Step 895: train/loss = 0.6327803134918213, train/raw-loss = 0.5905871987342834, train/logprobs = tensor([[-0.7550, -0.7814],
        [-1.3894, -0.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438620716333389
Epoch 0, Step 896: train/loss = 0.5963058471679688, train/raw-loss = 0.5579656958580017, train/logprobs = tensor([[-0.8031, -2.3030],
        [-1.2242, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07668022066354752
Epoch 0, Step 897: train/loss = 0.6688039898872375, train/raw-loss = 0.6451812982559204, train/logprobs = tensor([[-1.0130, -2.2459],
        [-0.9764, -1.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04724534600973129
Epoch 0, Step 898: train/loss = 0.6113455295562744, train/raw-loss = 0.5739679932594299, train/logprobs = tensor([[-0.7884, -1.5478],
        [-1.3115, -1.1872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07475504279136658
Epoch 0, Step 899: train/loss = 0.6751850843429565, train/raw-loss = 0.6436181664466858, train/logprobs = tensor([[-0.9746, -0.9102],
        [-1.3434, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06313372403383255
Epoch 0, Step 900: train/loss = 0.5726050138473511, train/raw-loss = 0.5404391288757324, train/logprobs = tensor([[-0.6468, -2.7873],
        [-0.6797, -1.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06433174014091492
Epoch 0, Step 901: train/loss = 0.6910606622695923, train/raw-loss = 0.6505311727523804, train/logprobs = tensor([[-0.6078, -1.3125],
        [-0.8132, -1.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08105900138616562
Epoch 0, Step 902: train/loss = 0.6699357032775879, train/raw-loss = 0.6433731317520142, train/logprobs = tensor([[-0.7329, -1.5261],
        [-0.7000, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05312509462237358
Epoch 0, Step 903: train/loss = 0.6110612154006958, train/raw-loss = 0.5666840076446533, train/logprobs = tensor([[-0.7342, -1.5698],
        [-1.0724, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08875438570976257
Epoch 0, Step 904: train/loss = 0.6910400986671448, train/raw-loss = 0.6661895513534546, train/logprobs = tensor([[-0.5833, -1.0030],
        [-0.5906, -0.7840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0497010201215744
Epoch 0, Step 905: train/loss = 0.6482068300247192, train/raw-loss = 0.6061066389083862, train/logprobs = tensor([[-1.4926, -0.9102],
        [-1.9749, -0.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08420039713382721
Epoch 0, Step 906: train/loss = 0.5669466853141785, train/raw-loss = 0.5290236473083496, train/logprobs = tensor([[-0.7044, -2.9070],
        [-0.8746, -1.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07584605365991592
Epoch 0, Step 907: train/loss = 0.5919590592384338, train/raw-loss = 0.5437131524085999, train/logprobs = tensor([[-0.5355, -1.7354],
        [-1.0962, -1.0430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649177640676498
Epoch 0, Step 908: train/loss = 0.7013971209526062, train/raw-loss = 0.6695467829704285, train/logprobs = tensor([[-0.7227, -0.9972],
        [-0.7570, -0.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0637006014585495
Epoch 0, Step 909: train/loss = 0.7627556324005127, train/raw-loss = 0.7267104387283325, train/logprobs = tensor([[-0.5307, -0.4265],
        [-0.7396, -0.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07209046930074692
Epoch 0, Step 910: train/loss = 0.47842270135879517, train/raw-loss = 0.4247310757637024, train/logprobs = tensor([[-0.8949, -2.9993],
        [-1.9288, -1.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10738325119018555
Epoch 0, Step 911: train/loss = 0.6196814775466919, train/raw-loss = 0.5847281217575073, train/logprobs = tensor([[-0.7154, -1.3476],
        [-1.1777, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06990660727024078
Epoch 0, Step 912: train/loss = 0.5916768908500671, train/raw-loss = 0.5458303689956665, train/logprobs = tensor([[-0.9092, -2.6167],
        [-1.2094, -1.7270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09169314801692963
Epoch 0, Step 913: train/loss = 0.6680022478103638, train/raw-loss = 0.634914755821228, train/logprobs = tensor([[-0.5387, -1.2156],
        [-0.5997, -0.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06617510318756104
Epoch 0, Step 914: train/loss = 0.6933373212814331, train/raw-loss = 0.6458841562271118, train/logprobs = tensor([[-0.6561, -1.6973],
        [-1.0164, -1.2090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0949062928557396
Epoch 0, Step 915: train/loss = 0.6554510593414307, train/raw-loss = 0.621209442615509, train/logprobs = tensor([[-0.6922, -0.9225],
        [-1.1281, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06848324835300446
Epoch 0, Step 916: train/loss = 0.5920068621635437, train/raw-loss = 0.5488082766532898, train/logprobs = tensor([[-1.1987, -1.5953],
        [-1.8563, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08639712631702423
Epoch 0, Step 917: train/loss = 0.7097487449645996, train/raw-loss = 0.680631697177887, train/logprobs = tensor([[-0.8246, -2.0604],
        [-0.8182, -1.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823395028710365
Epoch 0, Step 918: train/loss = 0.6162606477737427, train/raw-loss = 0.5800555944442749, train/logprobs = tensor([[-0.9506, -2.6287],
        [-1.1298, -1.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07241008430719376
Epoch 0, Step 919: train/loss = 0.720067024230957, train/raw-loss = 0.6773444414138794, train/logprobs = tensor([[-1.0839, -2.2041],
        [-1.6430, -1.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08544515818357468
Epoch 0, Step 920: train/loss = 0.6476370692253113, train/raw-loss = 0.6090068817138672, train/logprobs = tensor([[-1.3749, -1.1608],
        [-1.8162, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0772603452205658
Epoch 0, Step 921: train/loss = 0.5985218286514282, train/raw-loss = 0.5601415634155273, train/logprobs = tensor([[-0.7473, -2.3017],
        [-1.1518, -1.2891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07676051557064056
Epoch 0, Step 922: train/loss = 0.577789306640625, train/raw-loss = 0.534260094165802, train/logprobs = tensor([[-0.7040, -2.6603],
        [-1.0564, -1.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08705845475196838
Epoch 0, Step 923: train/loss = 0.5762695074081421, train/raw-loss = 0.5276526212692261, train/logprobs = tensor([[-0.5585, -1.0783],
        [-1.4616, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09723376482725143
Epoch 0, Step 924: train/loss = 0.5758410692214966, train/raw-loss = 0.5302397608757019, train/logprobs = tensor([[-0.6587, -1.3409],
        [-1.3617, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09120260924100876
Epoch 0, Step 925: train/loss = 0.6927509307861328, train/raw-loss = 0.6516798734664917, train/logprobs = tensor([[-0.5654, -0.8580],
        [-1.0118, -0.7695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08214203268289566
Epoch 0, Step 926: train/loss = 0.6396366357803345, train/raw-loss = 0.5913422107696533, train/logprobs = tensor([[-1.1853, -1.8745],
        [-1.7955, -1.5774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09658876061439514
Epoch 0, Step 927: train/loss = 0.6334379315376282, train/raw-loss = 0.6091828346252441, train/logprobs = tensor([[-0.5345, -1.3736],
        [-0.5916, -0.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04851025342941284
Epoch 0, Step 928: train/loss = 0.7627812623977661, train/raw-loss = 0.7175979614257812, train/logprobs = tensor([[-0.8739, -0.9904],
        [-1.2985, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09036654978990555
Epoch 0, Step 929: train/loss = 0.6974296569824219, train/raw-loss = 0.6660736203193665, train/logprobs = tensor([[-0.6699, -1.5116],
        [-0.6255, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06271211802959442
Epoch 0, Step 930: train/loss = 0.6275040507316589, train/raw-loss = 0.5877273678779602, train/logprobs = tensor([[-0.8974, -1.0051],
        [-1.3244, -0.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07955334335565567
Epoch 0, Step 931: train/loss = 0.6347406506538391, train/raw-loss = 0.60142982006073, train/logprobs = tensor([[-0.6151, -1.8799],
        [-0.6066, -1.1776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06662160158157349
Epoch 0, Step 932: train/loss = 0.5473425388336182, train/raw-loss = 0.5058164000511169, train/logprobs = tensor([[-0.6124, -2.9573],
        [-0.7240, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08305225521326065
Epoch 0, Step 933: train/loss = 0.536077618598938, train/raw-loss = 0.47936612367630005, train/logprobs = tensor([[-0.9701, -2.4101],
        [-1.8561, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11342304199934006
Epoch 0, Step 934: train/loss = 0.6705992817878723, train/raw-loss = 0.6473051309585571, train/logprobs = tensor([[-0.5452, -1.2904],
        [-0.5709, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04658817499876022
Epoch 0, Step 935: train/loss = 0.6131202578544617, train/raw-loss = 0.5605239868164062, train/logprobs = tensor([[-0.9352, -1.2998],
        [-1.7227, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519255697727203
Epoch 0, Step 936: train/loss = 0.6435023546218872, train/raw-loss = 0.605422854423523, train/logprobs = tensor([[-0.7398, -1.4151],
        [-1.0761, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615900039672852
Epoch 0, Step 937: train/loss = 0.6073136925697327, train/raw-loss = 0.5661278367042542, train/logprobs = tensor([[-0.6408, -2.0310],
        [-0.8238, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237171173095703
Epoch 0, Step 938: train/loss = 0.6518092751502991, train/raw-loss = 0.6228092908859253, train/logprobs = tensor([[-0.7990, -1.4338],
        [-0.8319, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05800001695752144
Epoch 0, Step 939: train/loss = 0.6630925536155701, train/raw-loss = 0.6316268444061279, train/logprobs = tensor([[-0.7737, -1.6843],
        [-0.8513, -1.2026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0629313513636589
Epoch 0, Step 940: train/loss = 0.5476995706558228, train/raw-loss = 0.5012111663818359, train/logprobs = tensor([[-1.0193, -2.8134],
        [-1.6651, -1.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09297668933868408
Epoch 0, Step 941: train/loss = 0.680016279220581, train/raw-loss = 0.6574736833572388, train/logprobs = tensor([[-0.8723, -1.0431],
        [-0.9119, -0.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045085109770298004
Epoch 0, Step 942: train/loss = 0.662132740020752, train/raw-loss = 0.621205747127533, train/logprobs = tensor([[-0.8737, -1.6690],
        [-1.3397, -1.4144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081853948533535
Epoch 0, Step 943: train/loss = 0.6522326469421387, train/raw-loss = 0.6230180263519287, train/logprobs = tensor([[-0.7165, -1.3088],
        [-0.7964, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0584292970597744
Epoch 0, Step 944: train/loss = 0.7119609117507935, train/raw-loss = 0.6862331628799438, train/logprobs = tensor([[-0.6867, -1.0999],
        [-0.7028, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05145552009344101
Epoch 0, Step 945: train/loss = 0.6643479466438293, train/raw-loss = 0.6268897652626038, train/logprobs = tensor([[-0.9486, -0.8035],
        [-1.3833, -0.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07491635531187057
Epoch 0, Step 946: train/loss = 0.4790383577346802, train/raw-loss = 0.4182049334049225, train/logprobs = tensor([[-1.1951, -2.0105],
        [-2.6978, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12166687101125717
Epoch 0, Step 947: train/loss = 0.6382771730422974, train/raw-loss = 0.6027823686599731, train/logprobs = tensor([[-0.7033, -1.6918],
        [-1.1372, -1.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07098955661058426
Epoch 0, Step 948: train/loss = 0.7529166340827942, train/raw-loss = 0.7234587669372559, train/logprobs = tensor([[-1.1971, -1.6004],
        [-1.0921, -1.4711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05891569331288338
Epoch 0, Step 949: train/loss = 0.5980027318000793, train/raw-loss = 0.5522757768630981, train/logprobs = tensor([[-0.7427, -1.4283],
        [-1.3143, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09145385026931763
Epoch 0, Step 950: train/loss = 0.8770160675048828, train/raw-loss = 0.8482352495193481, train/logprobs = tensor([[-1.1888, -1.4316],
        [-1.6713, -1.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05756150186061859
Epoch 0, Step 951: train/loss = 0.6251187324523926, train/raw-loss = 0.5796343088150024, train/logprobs = tensor([[-0.8509, -1.9973],
        [-1.2958, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09096887707710266
Epoch 0, Step 952: train/loss = 0.6983067989349365, train/raw-loss = 0.6712328195571899, train/logprobs = tensor([[-0.5993, -0.6471],
        [-0.6088, -0.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05414803698658943
Epoch 0, Step 953: train/loss = 0.6893740892410278, train/raw-loss = 0.6617510914802551, train/logprobs = tensor([[-0.6614, -1.5311],
        [-0.7955, -1.3536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05524603649973869
Epoch 0, Step 954: train/loss = 0.7003716230392456, train/raw-loss = 0.6749600768089294, train/logprobs = tensor([[-0.7965, -1.0161],
        [-0.9000, -0.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050822965800762177
Epoch 0, Step 955: train/loss = 0.6737712025642395, train/raw-loss = 0.6487597227096558, train/logprobs = tensor([[-0.5345, -0.8542],
        [-0.5720, -0.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05002286657691002
Epoch 0, Step 956: train/loss = 0.6020654439926147, train/raw-loss = 0.5707533359527588, train/logprobs = tensor([[-0.8733, -2.2376],
        [-1.0123, -1.5359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06262419372797012
Epoch 0, Step 957: train/loss = 0.6351815462112427, train/raw-loss = 0.6033260822296143, train/logprobs = tensor([[-0.7002, -2.0499],
        [-0.8834, -1.3957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06371087580919266
Epoch 0, Step 958: train/loss = 0.6477329134941101, train/raw-loss = 0.618689775466919, train/logprobs = tensor([[-0.9535, -1.6929],
        [-1.0353, -1.1955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05808626487851143
Epoch 0, Step 959: train/loss = 0.7028691172599792, train/raw-loss = 0.6756728291511536, train/logprobs = tensor([[-1.6063, -1.6404],
        [-1.9534, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05439247936010361
Epoch 0, Step 960: train/loss = 0.6405484080314636, train/raw-loss = 0.6104454398155212, train/logprobs = tensor([[-0.7625, -1.0844],
        [-1.1437, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060205958783626556
Epoch 0, Step 961: train/loss = 0.5885481238365173, train/raw-loss = 0.5435346961021423, train/logprobs = tensor([[-0.6640, -1.8202],
        [-1.4092, -1.3547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09002681821584702
Epoch 0, Step 962: train/loss = 0.6428335905075073, train/raw-loss = 0.6157567501068115, train/logprobs = tensor([[-0.6696, -2.0913],
        [-0.6481, -1.5511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05415363237261772
Epoch 0, Step 963: train/loss = 0.5735913515090942, train/raw-loss = 0.5200580954551697, train/logprobs = tensor([[-0.9606, -1.6822],
        [-1.5470, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10706652700901031
Epoch 0, Step 964: train/loss = 0.5132139921188354, train/raw-loss = 0.4611446261405945, train/logprobs = tensor([[-0.9863, -2.4560],
        [-1.8412, -1.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10413870215415955
Epoch 0, Step 965: train/loss = 0.6810898780822754, train/raw-loss = 0.6541247367858887, train/logprobs = tensor([[-0.6011, -1.5305],
        [-0.6054, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05393034219741821
Epoch 0, Step 966: train/loss = 0.6976068019866943, train/raw-loss = 0.6482062339782715, train/logprobs = tensor([[-0.9131, -1.2387],
        [-1.4648, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09880125522613525
Epoch 0, Step 967: train/loss = 0.6267508268356323, train/raw-loss = 0.5866556763648987, train/logprobs = tensor([[-0.7780, -2.4508],
        [-0.8368, -1.4735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08019036054611206
Epoch 0, Step 968: train/loss = 0.6697937250137329, train/raw-loss = 0.6342278718948364, train/logprobs = tensor([[-1.4370, -2.7462],
        [-1.5891, -2.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07113174349069595
Epoch 0, Step 969: train/loss = 0.6235580444335938, train/raw-loss = 0.5774930119514465, train/logprobs = tensor([[-0.6963, -1.3707],
        [-1.2207, -0.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09213006496429443
Epoch 0, Step 970: train/loss = 0.6633810997009277, train/raw-loss = 0.622026801109314, train/logprobs = tensor([[-0.8308, -2.1817],
        [-1.1252, -1.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08270853012800217
Epoch 0, Step 971: train/loss = 0.5991591811180115, train/raw-loss = 0.5551015138626099, train/logprobs = tensor([[-0.7801, -2.1715],
        [-1.1073, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881153792142868
Epoch 0, Step 972: train/loss = 0.5854750871658325, train/raw-loss = 0.5513664484024048, train/logprobs = tensor([[-1.0571, -3.1801],
        [-1.2077, -2.1594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821714341640472
Epoch 0, Step 973: train/loss = 0.6393218636512756, train/raw-loss = 0.604389488697052, train/logprobs = tensor([[-0.6231, -1.3949],
        [-0.7740, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06986479461193085
Epoch 0, Step 974: train/loss = 0.6339817047119141, train/raw-loss = 0.5942287445068359, train/logprobs = tensor([[-1.3641, -2.4759],
        [-1.6849, -2.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07950596511363983
Epoch 0, Step 975: train/loss = 0.8322244882583618, train/raw-loss = 0.8010064363479614, train/logprobs = tensor([[-0.6298, -1.2734],
        [-0.9581, -1.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062436189502477646
Epoch 0, Step 976: train/loss = 0.6539478302001953, train/raw-loss = 0.6253266930580139, train/logprobs = tensor([[-0.6444, -1.2300],
        [-0.7969, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05724232643842697
Epoch 0, Step 977: train/loss = 0.5960590243339539, train/raw-loss = 0.549778938293457, train/logprobs = tensor([[-0.7151, -2.2399],
        [-1.0006, -1.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09256027638912201
Epoch 0, Step 978: train/loss = 0.5662291049957275, train/raw-loss = 0.5218893885612488, train/logprobs = tensor([[-0.8583, -2.0718],
        [-1.3634, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08867949992418289
Epoch 0, Step 979: train/loss = 0.690398097038269, train/raw-loss = 0.6588320136070251, train/logprobs = tensor([[-1.2260, -1.4522],
        [-1.4468, -1.3094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06313210725784302
Epoch 0, Step 980: train/loss = 0.6281473636627197, train/raw-loss = 0.5911874771118164, train/logprobs = tensor([[-0.7402, -1.5525],
        [-0.9543, -1.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07391975820064545
Epoch 0, Step 981: train/loss = 0.6406714916229248, train/raw-loss = 0.6102579236030579, train/logprobs = tensor([[-0.6950, -1.5190],
        [-0.7552, -0.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06082715094089508
Epoch 0, Step 982: train/loss = 0.6642016172409058, train/raw-loss = 0.6295247673988342, train/logprobs = tensor([[-0.6319, -1.8998],
        [-0.6630, -1.3882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0693536251783371
Epoch 0, Step 983: train/loss = 0.562108039855957, train/raw-loss = 0.4962781071662903, train/logprobs = tensor([[-0.8798, -1.5388],
        [-1.9602, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1316598355770111
Epoch 0, Step 984: train/loss = 0.5316743850708008, train/raw-loss = 0.4939597249031067, train/logprobs = tensor([[-0.7302, -4.0328],
        [-1.1406, -2.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07542926073074341
Epoch 0, Step 985: train/loss = 0.6601336598396301, train/raw-loss = 0.6236863136291504, train/logprobs = tensor([[-0.7369, -1.5156],
        [-0.9532, -1.2010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07289466261863708
Epoch 0, Step 986: train/loss = 0.5406157374382019, train/raw-loss = 0.4821542501449585, train/logprobs = tensor([[-0.9344, -3.6877],
        [-1.3344, -2.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11692303419113159
Epoch 0, Step 987: train/loss = 0.7028636932373047, train/raw-loss = 0.6558984518051147, train/logprobs = tensor([[-1.0605, -2.0013],
        [-1.5552, -1.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09393052011728287
Epoch 0, Step 988: train/loss = 0.6337480545043945, train/raw-loss = 0.5835249423980713, train/logprobs = tensor([[-0.7022, -1.4522],
        [-1.0988, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10044621676206589
Epoch 0, Step 989: train/loss = 0.6053506135940552, train/raw-loss = 0.5578035712242126, train/logprobs = tensor([[-1.0049, -1.6667],
        [-1.6351, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09509411454200745
Epoch 0, Step 990: train/loss = 0.6420977115631104, train/raw-loss = 0.6133317947387695, train/logprobs = tensor([[-0.5163, -1.4797],
        [-0.5699, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057531822472810745
Epoch 0, Step 991: train/loss = 0.6438211798667908, train/raw-loss = 0.6111618876457214, train/logprobs = tensor([[-0.7355, -1.8683],
        [-0.8957, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06531856954097748
Epoch 0, Step 992: train/loss = 0.593093991279602, train/raw-loss = 0.5581774711608887, train/logprobs = tensor([[-0.7683, -1.5150],
        [-1.3572, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06983309239149094
Epoch 0, Step 993: train/loss = 0.6179057359695435, train/raw-loss = 0.5691987872123718, train/logprobs = tensor([[-0.7471, -1.6311],
        [-1.1496, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09741391986608505
Epoch 0, Step 994: train/loss = 0.6097128391265869, train/raw-loss = 0.57636559009552, train/logprobs = tensor([[-0.9754, -1.7860],
        [-1.3420, -1.3017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0666944831609726
Epoch 0, Step 995: train/loss = 0.57496178150177, train/raw-loss = 0.5373673439025879, train/logprobs = tensor([[-1.0259, -1.5426],
        [-1.6715, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07518880814313889
Epoch 0, Step 996: train/loss = 0.7582284808158875, train/raw-loss = 0.7109790444374084, train/logprobs = tensor([[-0.9128, -1.9302],
        [-1.2232, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09449884295463562
Epoch 0, Step 997: train/loss = 0.6528921127319336, train/raw-loss = 0.6228412389755249, train/logprobs = tensor([[-1.3015, -1.9255],
        [-1.8152, -1.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0601017139852047
Epoch 0, Step 998: train/loss = 0.5993799567222595, train/raw-loss = 0.5593210458755493, train/logprobs = tensor([[-1.0722, -2.3956],
        [-1.2549, -1.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08011781424283981
Epoch 0, Step 999: train/loss = 0.5909870862960815, train/raw-loss = 0.5430976152420044, train/logprobs = tensor([[-0.7864, -1.5857],
        [-1.4767, -1.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577900171279907
Epoch 0, Step 1000: train/loss = 0.6604989767074585, train/raw-loss = 0.6241402626037598, train/logprobs = tensor([[-0.7699, -1.4233],
        [-0.8513, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0727173238992691
Epoch 0, Step 1001: train/loss = 0.7856293320655823, train/raw-loss = 0.7281593680381775, train/logprobs = tensor([[-0.7779, -1.4291],
        [-1.5159, -1.4982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11493995040655136
Epoch 0, Step 1002: train/loss = 0.5976069569587708, train/raw-loss = 0.5620571374893188, train/logprobs = tensor([[-0.9646, -1.6394],
        [-1.4537, -1.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109975069761276
Epoch 0, Step 1003: train/loss = 0.6439647078514099, train/raw-loss = 0.6055983304977417, train/logprobs = tensor([[-0.6983, -1.5005],
        [-0.8742, -0.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07673268765211105
Epoch 0, Step 1004: train/loss = 0.6469536423683167, train/raw-loss = 0.616755485534668, train/logprobs = tensor([[-0.9720, -1.4507],
        [-1.0306, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06039642542600632
Epoch 0, Step 1005: train/loss = 0.7106970548629761, train/raw-loss = 0.6759754419326782, train/logprobs = tensor([[-0.8104, -1.1489],
        [-0.9526, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06944319605827332
Epoch 0, Step 1006: train/loss = 0.6053231954574585, train/raw-loss = 0.5610000491142273, train/logprobs = tensor([[-0.7917, -1.2223],
        [-1.3538, -0.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08864637464284897
Epoch 0, Step 1007: train/loss = 0.6312293410301208, train/raw-loss = 0.5844751596450806, train/logprobs = tensor([[-1.0173, -1.8627],
        [-1.6662, -1.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09350840747356415
Epoch 0, Step 1008: train/loss = 0.6592684984207153, train/raw-loss = 0.6280926465988159, train/logprobs = tensor([[-0.8881, -1.6314],
        [-0.8974, -1.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062351688742637634
Epoch 0, Step 1009: train/loss = 0.6120930314064026, train/raw-loss = 0.5784541964530945, train/logprobs = tensor([[-0.8815, -1.5989],
        [-1.1828, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06727767735719681
Epoch 0, Step 1010: train/loss = 0.7144403457641602, train/raw-loss = 0.6838295459747314, train/logprobs = tensor([[-1.8038, -1.9877],
        [-1.7278, -1.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06122158467769623
Epoch 0, Step 1011: train/loss = 0.6160365343093872, train/raw-loss = 0.5771790146827698, train/logprobs = tensor([[-0.6628, -1.5839],
        [-1.0754, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07771497219800949
Epoch 0, Step 1012: train/loss = 0.585311770439148, train/raw-loss = 0.5396894216537476, train/logprobs = tensor([[-1.1620, -1.9693],
        [-1.6925, -1.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09124462306499481
Epoch 0, Step 1013: train/loss = 0.6611294746398926, train/raw-loss = 0.6332101821899414, train/logprobs = tensor([[-0.5857, -0.9314],
        [-0.6604, -0.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05583857372403145
Epoch 0, Step 1014: train/loss = 0.5995991230010986, train/raw-loss = 0.5565757155418396, train/logprobs = tensor([[-0.6103, -1.8728],
        [-1.1572, -1.3720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08604669570922852
Epoch 0, Step 1015: train/loss = 0.6578370332717896, train/raw-loss = 0.610407829284668, train/logprobs = tensor([[-0.9547, -1.6067],
        [-1.2319, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09485845267772675
Epoch 0, Step 1016: train/loss = 0.571357786655426, train/raw-loss = 0.530168890953064, train/logprobs = tensor([[-1.1304, -3.6549],
        [-1.2848, -1.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08237779140472412
Epoch 0, Step 1017: train/loss = 0.4943791627883911, train/raw-loss = 0.4463651180267334, train/logprobs = tensor([[-0.7140, -2.6632],
        [-1.1920, -1.2840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09602808952331543
Epoch 0, Step 1018: train/loss = 0.5291880369186401, train/raw-loss = 0.47772061824798584, train/logprobs = tensor([[-1.1159, -2.0839],
        [-2.0609, -1.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293490439653397
Epoch 0, Step 1019: train/loss = 0.6353757381439209, train/raw-loss = 0.599303662776947, train/logprobs = tensor([[-0.5007, -1.3456],
        [-0.6604, -0.7660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07214411348104477
Epoch 0, Step 1020: train/loss = 0.6479249000549316, train/raw-loss = 0.6061053276062012, train/logprobs = tensor([[-0.6928, -0.9488],
        [-1.1378, -0.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08363926410675049
Epoch 0, Step 1021: train/loss = 0.6281250715255737, train/raw-loss = 0.592873215675354, train/logprobs = tensor([[-1.1058, -1.8933],
        [-1.6289, -1.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07050380110740662
Epoch 0, Step 1022: train/loss = 0.6376878023147583, train/raw-loss = 0.6141393780708313, train/logprobs = tensor([[-0.5096, -1.7277],
        [-0.5393, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04709678888320923
Epoch 0, Step 1023: train/loss = 0.5416622161865234, train/raw-loss = 0.4928548336029053, train/logprobs = tensor([[-1.3518, -2.7126],
        [-2.4168, -1.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761478006839752
Epoch 0, Step 1024: train/loss = 0.6491312384605408, train/raw-loss = 0.6121748685836792, train/logprobs = tensor([[-1.2008, -0.7193],
        [-1.9026, -0.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07391271740198135
Epoch 0, Step 1025: train/loss = 0.6267825365066528, train/raw-loss = 0.5985250473022461, train/logprobs = tensor([[-0.6522, -1.8329],
        [-0.6806, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05651506409049034
Epoch 0, Step 1026: train/loss = 0.6220110654830933, train/raw-loss = 0.5734120607376099, train/logprobs = tensor([[-1.0917, -1.7257],
        [-1.9515, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09719812870025635
Epoch 0, Step 1027: train/loss = 0.6882855892181396, train/raw-loss = 0.6466071605682373, train/logprobs = tensor([[-1.0237, -0.9884],
        [-1.2070, -0.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833568274974823
Epoch 0, Step 1028: train/loss = 0.5803385972976685, train/raw-loss = 0.5224228501319885, train/logprobs = tensor([[-0.8302, -1.7768],
        [-1.8144, -1.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11583147943019867
Epoch 0, Step 1029: train/loss = 0.628134548664093, train/raw-loss = 0.5834771394729614, train/logprobs = tensor([[-0.7671, -1.1103],
        [-1.4701, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931479603052139
Epoch 0, Step 1030: train/loss = 0.6602007746696472, train/raw-loss = 0.6290534734725952, train/logprobs = tensor([[-0.5688, -1.8730],
        [-0.6074, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06229473277926445
Epoch 0, Step 1031: train/loss = 0.6889445185661316, train/raw-loss = 0.6395914554595947, train/logprobs = tensor([[-0.9618, -1.2124],
        [-1.3876, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09870609641075134
Epoch 0, Step 1032: train/loss = 0.6443179845809937, train/raw-loss = 0.6008161902427673, train/logprobs = tensor([[-1.1488, -1.6610],
        [-1.5797, -1.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08700361847877502
Epoch 0, Step 1033: train/loss = 0.5360695123672485, train/raw-loss = 0.48106083273887634, train/logprobs = tensor([[-0.7618, -2.1506],
        [-1.7042, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11001741886138916
Epoch 0, Step 1034: train/loss = 0.6442972421646118, train/raw-loss = 0.6152583360671997, train/logprobs = tensor([[-0.8826, -1.3482],
        [-1.0755, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05807791277766228
Epoch 0, Step 1035: train/loss = 0.5829441547393799, train/raw-loss = 0.5389975905418396, train/logprobs = tensor([[-0.9353, -2.0397],
        [-1.5037, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789314329624176
Epoch 0, Step 1036: train/loss = 0.6256192922592163, train/raw-loss = 0.5897390842437744, train/logprobs = tensor([[-0.8645, -1.3552],
        [-1.1129, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07176049798727036
Epoch 0, Step 1037: train/loss = 0.7081936597824097, train/raw-loss = 0.6641285419464111, train/logprobs = tensor([[-1.9231, -1.9806],
        [-2.0525, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0881301760673523
Epoch 0, Step 1038: train/loss = 0.6691850423812866, train/raw-loss = 0.637893795967102, train/logprobs = tensor([[-0.6189, -1.4413],
        [-0.6811, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06258255988359451
Epoch 0, Step 1039: train/loss = 0.5166007876396179, train/raw-loss = 0.45806050300598145, train/logprobs = tensor([[-0.7355, -2.4288],
        [-1.5310, -1.2265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11708059161901474
Epoch 0, Step 1040: train/loss = 0.5757349133491516, train/raw-loss = 0.536787748336792, train/logprobs = tensor([[-0.7199, -1.7373],
        [-1.3185, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07789435982704163
Epoch 0, Step 1041: train/loss = 0.6453112363815308, train/raw-loss = 0.6123906970024109, train/logprobs = tensor([[-0.7187, -1.9094],
        [-0.8709, -1.2669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06584108620882034
Epoch 0, Step 1042: train/loss = 0.6440054774284363, train/raw-loss = 0.612318754196167, train/logprobs = tensor([[-0.5541, -1.8024],
        [-0.5097, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06337347626686096
Epoch 0, Step 1043: train/loss = 0.6565626859664917, train/raw-loss = 0.6273523569107056, train/logprobs = tensor([[-0.7476, -0.7501],
        [-1.1436, -0.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058420732617378235
Epoch 0, Step 1044: train/loss = 0.5955908298492432, train/raw-loss = 0.5582863092422485, train/logprobs = tensor([[-0.8267, -2.6847],
        [-1.1609, -1.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07460908591747284
Epoch 0, Step 1045: train/loss = 0.6563481688499451, train/raw-loss = 0.6083964109420776, train/logprobs = tensor([[-0.8309, -1.3529],
        [-1.1853, -0.7954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590347856283188
Epoch 0, Step 1046: train/loss = 0.6708558797836304, train/raw-loss = 0.6277716755867004, train/logprobs = tensor([[-0.7368, -2.0913],
        [-1.1087, -1.6398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861683264374733
Epoch 0, Step 1047: train/loss = 0.6931465268135071, train/raw-loss = 0.6661621332168579, train/logprobs = tensor([[-0.6879, -1.3290],
        [-0.7023, -1.0760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053968943655490875
Epoch 0, Step 1048: train/loss = 0.6781497597694397, train/raw-loss = 0.6333038210868835, train/logprobs = tensor([[-1.1505, -1.2066],
        [-1.6332, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08969185501337051
Epoch 0, Step 1049: train/loss = 0.5416094660758972, train/raw-loss = 0.4849196672439575, train/logprobs = tensor([[-0.8040, -1.5278],
        [-1.8082, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11337956041097641
Epoch 0, Step 1050: train/loss = 0.60733962059021, train/raw-loss = 0.5724643468856812, train/logprobs = tensor([[-0.9824, -1.3094],
        [-1.3810, -0.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06975056231021881
Epoch 0, Step 1051: train/loss = 0.5459859371185303, train/raw-loss = 0.49619024991989136, train/logprobs = tensor([[-0.7243, -2.5564],
        [-1.3408, -1.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09959141910076141
Epoch 0, Step 1052: train/loss = 0.6841778755187988, train/raw-loss = 0.6590830087661743, train/logprobs = tensor([[-0.6266, -1.0483],
        [-0.6143, -0.7279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050189752131700516
Epoch 0, Step 1053: train/loss = 0.660235583782196, train/raw-loss = 0.6126312017440796, train/logprobs = tensor([[-1.1303, -1.4108],
        [-1.8609, -1.2198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09520891308784485
Epoch 0, Step 1054: train/loss = 0.6519394516944885, train/raw-loss = 0.6145003437995911, train/logprobs = tensor([[-0.7144, -0.7142],
        [-1.3047, -0.5910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07487823069095612
Epoch 0, Step 1055: train/loss = 0.5998135805130005, train/raw-loss = 0.5500977039337158, train/logprobs = tensor([[-0.6361, -2.2814],
        [-0.9520, -1.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09943175315856934
Epoch 0, Step 1056: train/loss = 0.6425356864929199, train/raw-loss = 0.6079476475715637, train/logprobs = tensor([[-0.8708, -1.7604],
        [-1.2735, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.069176085293293
Epoch 0, Step 1057: train/loss = 0.6540307998657227, train/raw-loss = 0.6156314611434937, train/logprobs = tensor([[-0.7228, -1.1474],
        [-1.0580, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767986997961998
Epoch 0, Step 1058: train/loss = 0.521723747253418, train/raw-loss = 0.47833505272865295, train/logprobs = tensor([[-0.4886, -3.6531],
        [-0.6265, -1.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08677731454372406
Epoch 0, Step 1059: train/loss = 0.7895251512527466, train/raw-loss = 0.7488250732421875, train/logprobs = tensor([[-0.9955, -2.2099],
        [-1.4044, -1.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139998465776443
Epoch 0, Step 1060: train/loss = 0.657755970954895, train/raw-loss = 0.6308947801589966, train/logprobs = tensor([[-0.7600, -1.4295],
        [-0.8335, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053722407668828964
Epoch 0, Step 1061: train/loss = 0.7009276151657104, train/raw-loss = 0.6846147179603577, train/logprobs = tensor([[-0.4003, -0.4890],
        [-0.4336, -0.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03262574225664139
Epoch 0, Step 1062: train/loss = 0.5970090627670288, train/raw-loss = 0.5394952297210693, train/logprobs = tensor([[-0.8500, -1.4403],
        [-1.7557, -0.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11502774059772491
Epoch 0, Step 1063: train/loss = 0.6752885580062866, train/raw-loss = 0.6477755308151245, train/logprobs = tensor([[-0.5189, -1.3315],
        [-0.5541, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05502599850296974
Epoch 0, Step 1064: train/loss = 0.600127100944519, train/raw-loss = 0.5683081150054932, train/logprobs = tensor([[-0.6600, -2.2624],
        [-0.7207, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363794207572937
Epoch 0, Step 1065: train/loss = 0.6473796963691711, train/raw-loss = 0.6094850897789001, train/logprobs = tensor([[-1.3344, -2.1387],
        [-1.6030, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07578916847705841
Epoch 0, Step 1066: train/loss = 0.7319715023040771, train/raw-loss = 0.6683830618858337, train/logprobs = tensor([[-0.8056, -1.2401],
        [-1.7959, -1.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12717685103416443
Epoch 0, Step 1067: train/loss = 0.7480632066726685, train/raw-loss = 0.7132941484451294, train/logprobs = tensor([[-1.1656, -1.7341],
        [-1.2102, -1.4817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06953821331262589
Epoch 0, Step 1068: train/loss = 0.5831960439682007, train/raw-loss = 0.5306261777877808, train/logprobs = tensor([[-1.4011, -1.7050],
        [-2.3571, -1.1626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10513993352651596
Epoch 0, Step 1069: train/loss = 0.4293334484100342, train/raw-loss = 0.37770435214042664, train/logprobs = tensor([[-1.0737, -4.5775],
        [-2.3282, -2.7995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10325819253921509
Epoch 0, Step 1070: train/loss = 0.6648584008216858, train/raw-loss = 0.6333202719688416, train/logprobs = tensor([[-0.9322, -2.0157],
        [-0.8363, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0630761981010437
Epoch 0, Step 1071: train/loss = 0.6537378430366516, train/raw-loss = 0.6280457377433777, train/logprobs = tensor([[-0.6311, -1.1464],
        [-0.7562, -0.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051384106278419495
Epoch 0, Step 1072: train/loss = 0.580418586730957, train/raw-loss = 0.5389658212661743, train/logprobs = tensor([[-0.8251, -2.3516],
        [-1.5166, -1.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08290563523769379
Epoch 0, Step 1073: train/loss = 0.6262873411178589, train/raw-loss = 0.5944569110870361, train/logprobs = tensor([[-0.8846, -1.5569],
        [-1.0762, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06366094201803207
Epoch 0, Step 1074: train/loss = 0.6092033386230469, train/raw-loss = 0.5593801736831665, train/logprobs = tensor([[-1.1451, -1.9296],
        [-1.9586, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996464192867279
Epoch 0, Step 1075: train/loss = 0.6372080445289612, train/raw-loss = 0.595187246799469, train/logprobs = tensor([[-0.7382, -1.3918],
        [-1.1954, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08404158055782318
Epoch 0, Step 1076: train/loss = 0.6199320554733276, train/raw-loss = 0.5779402852058411, train/logprobs = tensor([[-0.9171, -1.2982],
        [-1.4313, -0.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08398354053497314
Epoch 0, Step 1077: train/loss = 0.5784621238708496, train/raw-loss = 0.5505596995353699, train/logprobs = tensor([[-0.7177, -2.7234],
        [-0.8596, -1.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05580495670437813
Epoch 0, Step 1078: train/loss = 0.6202284097671509, train/raw-loss = 0.5814108848571777, train/logprobs = tensor([[-0.6089, -1.5476],
        [-0.8987, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763513922691345
Epoch 0, Step 1079: train/loss = 0.6347864270210266, train/raw-loss = 0.5956473350524902, train/logprobs = tensor([[-0.9501, -2.3747],
        [-1.3293, -1.7449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07827818393707275
Epoch 0, Step 1080: train/loss = 0.6627420783042908, train/raw-loss = 0.6349471211433411, train/logprobs = tensor([[-0.8773, -1.5708],
        [-1.0571, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05558999627828598
Epoch 0, Step 1081: train/loss = 0.6745449304580688, train/raw-loss = 0.6530109643936157, train/logprobs = tensor([[-0.5845, -1.1642],
        [-0.7026, -0.9056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0430678129196167
Epoch 0, Step 1082: train/loss = 0.5447173714637756, train/raw-loss = 0.4975881576538086, train/logprobs = tensor([[-0.7963, -2.7826],
        [-1.2403, -1.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09425844997167587
Epoch 0, Step 1083: train/loss = 0.578040599822998, train/raw-loss = 0.5418209433555603, train/logprobs = tensor([[-0.5517, -2.1611],
        [-0.6280, -1.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724392682313919
Epoch 0, Step 1084: train/loss = 0.6252331733703613, train/raw-loss = 0.5943416357040405, train/logprobs = tensor([[-0.6722, -1.9505],
        [-0.6865, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061782948672771454
Epoch 0, Step 1085: train/loss = 0.7127960324287415, train/raw-loss = 0.6868687868118286, train/logprobs = tensor([[-0.9146, -1.5060],
        [-0.6853, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05185454338788986
Epoch 0, Step 1086: train/loss = 0.6645975708961487, train/raw-loss = 0.6408711671829224, train/logprobs = tensor([[-0.6996, -1.2886],
        [-0.7405, -0.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047452740371227264
Epoch 0, Step 1087: train/loss = 0.717587411403656, train/raw-loss = 0.6945018768310547, train/logprobs = tensor([[-0.9994, -0.9591],
        [-1.1463, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04617098718881607
Epoch 0, Step 1088: train/loss = 0.6272616386413574, train/raw-loss = 0.5739227533340454, train/logprobs = tensor([[-0.8632, -2.2998],
        [-1.5083, -1.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10667774826288223
Epoch 0, Step 1089: train/loss = 0.5487188100814819, train/raw-loss = 0.5020321607589722, train/logprobs = tensor([[-0.8721, -2.4335],
        [-1.4399, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09337328374385834
Epoch 0, Step 1090: train/loss = 0.5409257411956787, train/raw-loss = 0.49060994386672974, train/logprobs = tensor([[-0.9481, -3.0024],
        [-1.4351, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10063154995441437
Epoch 0, Step 1091: train/loss = 0.6372223496437073, train/raw-loss = 0.5996360778808594, train/logprobs = tensor([[-0.8967, -1.9177],
        [-1.0934, -1.3582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075172558426857
Epoch 0, Step 1092: train/loss = 0.6407206654548645, train/raw-loss = 0.6155310869216919, train/logprobs = tensor([[-0.6115, -1.4655],
        [-0.6342, -0.8266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05037904158234596
Epoch 0, Step 1093: train/loss = 0.7179004549980164, train/raw-loss = 0.6864290833473206, train/logprobs = tensor([[-0.8159, -1.6643],
        [-0.8659, -1.3900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06294277310371399
Epoch 0, Step 1094: train/loss = 0.5666547417640686, train/raw-loss = 0.5255973935127258, train/logprobs = tensor([[-0.9179, -1.6715],
        [-1.6560, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08211469650268555
Epoch 0, Step 1095: train/loss = 0.613551914691925, train/raw-loss = 0.5747809410095215, train/logprobs = tensor([[-0.5749, -1.5913],
        [-0.8802, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07754189521074295
Epoch 0, Step 1096: train/loss = 0.5975980758666992, train/raw-loss = 0.5597622394561768, train/logprobs = tensor([[-1.0912, -1.3522],
        [-1.7550, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07567158341407776
Epoch 0, Step 1097: train/loss = 0.630001425743103, train/raw-loss = 0.5984423160552979, train/logprobs = tensor([[-0.4385, -1.5280],
        [-0.4628, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06311815977096558
Epoch 0, Step 1098: train/loss = 0.6485297679901123, train/raw-loss = 0.6120895147323608, train/logprobs = tensor([[-1.2994, -1.9369],
        [-1.4009, -1.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07288052141666412
Epoch 0, Step 1099: train/loss = 0.5675866603851318, train/raw-loss = 0.5213770866394043, train/logprobs = tensor([[-0.8954, -1.8554],
        [-1.3985, -0.9813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0924190878868103
Epoch 0, Step 1100: train/loss = 0.6238589286804199, train/raw-loss = 0.5844026803970337, train/logprobs = tensor([[-0.8524, -1.7041],
        [-1.3155, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07891249656677246
Epoch 0, Step 1101: train/loss = 0.5238707065582275, train/raw-loss = 0.4587832987308502, train/logprobs = tensor([[-0.7504, -2.1740],
        [-1.6207, -1.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13017474114894867
Epoch 0, Step 1102: train/loss = 0.5634593963623047, train/raw-loss = 0.5120400786399841, train/logprobs = tensor([[-0.7766, -1.7674],
        [-1.2465, -0.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10283877700567245
Epoch 0, Step 1103: train/loss = 0.5668759942054749, train/raw-loss = 0.5249922871589661, train/logprobs = tensor([[-0.8537, -2.0134],
        [-1.5331, -1.3129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.083767369389534
Epoch 0, Step 1104: train/loss = 0.7401765584945679, train/raw-loss = 0.6990626454353333, train/logprobs = tensor([[-0.5263, -1.6567],
        [-0.6945, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08222800493240356
Epoch 0, Step 1105: train/loss = 0.7476620078086853, train/raw-loss = 0.7173467874526978, train/logprobs = tensor([[-0.9445, -1.7060],
        [-1.1047, -1.6908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06063036248087883
Epoch 0, Step 1106: train/loss = 0.5920237302780151, train/raw-loss = 0.5497294664382935, train/logprobs = tensor([[-0.8928, -1.8200],
        [-1.2441, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08458849787712097
Epoch 0, Step 1107: train/loss = 0.6245274543762207, train/raw-loss = 0.5813901424407959, train/logprobs = tensor([[-0.9296, -1.8595],
        [-1.2551, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08627456426620483
Epoch 0, Step 1108: train/loss = 0.7169049382209778, train/raw-loss = 0.6769092082977295, train/logprobs = tensor([[-1.4744, -2.4281],
        [-2.1703, -2.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07999151945114136
Epoch 0, Step 1109: train/loss = 0.6172749400138855, train/raw-loss = 0.5856117606163025, train/logprobs = tensor([[-0.5317, -1.7748],
        [-0.5478, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06332627683877945
Epoch 0, Step 1110: train/loss = 0.6633470058441162, train/raw-loss = 0.6403775811195374, train/logprobs = tensor([[-0.6464, -1.7613],
        [-0.6969, -1.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045938801020383835
Epoch 0, Step 1111: train/loss = 0.6528565287590027, train/raw-loss = 0.6084452271461487, train/logprobs = tensor([[-0.7007, -0.9864],
        [-0.9646, -0.6332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0888226255774498
Epoch 0, Step 1112: train/loss = 0.5916035175323486, train/raw-loss = 0.5484888553619385, train/logprobs = tensor([[-1.2466, -2.0165],
        [-1.6922, -1.1503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08622944355010986
Epoch 0, Step 1113: train/loss = 0.5819640159606934, train/raw-loss = 0.5539517402648926, train/logprobs = tensor([[-0.5911, -2.1821],
        [-0.7489, -1.3548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0560244582593441
Epoch 0, Step 1114: train/loss = 0.579250156879425, train/raw-loss = 0.5383604764938354, train/logprobs = tensor([[-0.5043, -1.7997],
        [-0.7366, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0817793756723404
Epoch 0, Step 1115: train/loss = 0.647247850894928, train/raw-loss = 0.6136533617973328, train/logprobs = tensor([[-0.5731, -1.5316],
        [-0.6117, -0.9753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06718893349170685
Epoch 0, Step 1116: train/loss = 0.7048461437225342, train/raw-loss = 0.6879591345787048, train/logprobs = tensor([[-0.4063, -0.4577],
        [-0.4252, -0.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03377407789230347
Epoch 0, Step 1117: train/loss = 0.616065263748169, train/raw-loss = 0.5869091153144836, train/logprobs = tensor([[-0.7985, -2.0874],
        [-1.0266, -1.5398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058312319219112396
Epoch 0, Step 1118: train/loss = 0.6573326587677002, train/raw-loss = 0.6255143284797668, train/logprobs = tensor([[-1.1661, -1.9440],
        [-1.3811, -1.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0636366680264473
Epoch 0, Step 1119: train/loss = 0.6243495941162109, train/raw-loss = 0.5810272693634033, train/logprobs = tensor([[-0.6959, -1.0648],
        [-1.3185, -0.7379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08664453029632568
Epoch 0, Step 1120: train/loss = 0.5839681029319763, train/raw-loss = 0.5232819318771362, train/logprobs = tensor([[-0.8320, -1.7884],
        [-1.7858, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.121372289955616
Epoch 0, Step 1121: train/loss = 0.6320927143096924, train/raw-loss = 0.5783522129058838, train/logprobs = tensor([[-1.1137, -2.2730],
        [-1.6674, -1.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10748101770877838
Epoch 0, Step 1122: train/loss = 0.5887933373451233, train/raw-loss = 0.5547248125076294, train/logprobs = tensor([[-1.0830, -2.9128],
        [-1.5488, -1.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06813704967498779
Epoch 0, Step 1123: train/loss = 0.597109317779541, train/raw-loss = 0.5575011968612671, train/logprobs = tensor([[-0.7030, -1.8968],
        [-1.3538, -1.2351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921617478132248
Epoch 0, Step 1124: train/loss = 0.5886965990066528, train/raw-loss = 0.5531550645828247, train/logprobs = tensor([[-0.6007, -1.9186],
        [-0.7238, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07108324766159058
Epoch 0, Step 1125: train/loss = 0.5664077997207642, train/raw-loss = 0.5301159024238586, train/logprobs = tensor([[-0.7053, -2.3699],
        [-0.9979, -1.3350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07258380949497223
Epoch 0, Step 1126: train/loss = 0.6139768362045288, train/raw-loss = 0.5713185667991638, train/logprobs = tensor([[-0.7179, -2.0515],
        [-1.2651, -1.3109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08531655371189117
Epoch 0, Step 1127: train/loss = 0.6197219491004944, train/raw-loss = 0.5938156247138977, train/logprobs = tensor([[-0.5581, -1.8672],
        [-0.6103, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051812704652547836
Epoch 0, Step 1128: train/loss = 0.7219464182853699, train/raw-loss = 0.6869523525238037, train/logprobs = tensor([[-0.7853, -0.9999],
        [-1.2117, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06998810172080994
Epoch 0, Step 1129: train/loss = 0.6347092390060425, train/raw-loss = 0.5886196494102478, train/logprobs = tensor([[-1.2471, -1.5944],
        [-1.8832, -1.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09217922389507294
Epoch 0, Step 1130: train/loss = 0.6393376588821411, train/raw-loss = 0.605608344078064, train/logprobs = tensor([[-0.7787, -2.0936],
        [-0.8822, -1.3867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0674586221575737
Epoch 0, Step 1131: train/loss = 0.5967279076576233, train/raw-loss = 0.5434839129447937, train/logprobs = tensor([[-0.6914, -2.0124],
        [-1.2593, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10648800432682037
Epoch 0, Step 1132: train/loss = 0.6223214864730835, train/raw-loss = 0.5593205094337463, train/logprobs = tensor([[-0.7246, -1.6189],
        [-1.6467, -1.2957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260019987821579
Epoch 0, Step 1133: train/loss = 0.5478810667991638, train/raw-loss = 0.48786661028862, train/logprobs = tensor([[-1.3224, -2.3775],
        [-2.4601, -1.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12002893537282944
Epoch 0, Step 1134: train/loss = 0.614080548286438, train/raw-loss = 0.5605342984199524, train/logprobs = tensor([[-0.7041, -1.3706],
        [-1.1046, -0.8044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10709241777658463
Epoch 0, Step 1135: train/loss = 0.6996516585350037, train/raw-loss = 0.6763861179351807, train/logprobs = tensor([[-0.6617, -0.8935],
        [-0.7380, -0.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046531081199645996
Epoch 0, Step 1136: train/loss = 0.6353040933609009, train/raw-loss = 0.6089834570884705, train/logprobs = tensor([[-0.6732, -1.6140],
        [-0.6926, -0.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05264122039079666
Epoch 0, Step 1137: train/loss = 0.6108657717704773, train/raw-loss = 0.5797140598297119, train/logprobs = tensor([[-0.8272, -1.8919],
        [-1.3831, -1.5131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062303297221660614
Epoch 0, Step 1138: train/loss = 0.6511631011962891, train/raw-loss = 0.6284872889518738, train/logprobs = tensor([[-0.6068, -1.4157],
        [-0.7166, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0453515499830246
Epoch 0, Step 1139: train/loss = 0.5334036350250244, train/raw-loss = 0.4806930720806122, train/logprobs = tensor([[-0.7931, -2.0415],
        [-1.5132, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10542117059230804
Epoch 0, Step 1140: train/loss = 0.6211801767349243, train/raw-loss = 0.5805675983428955, train/logprobs = tensor([[-0.7938, -1.4573],
        [-1.1811, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08122512698173523
Epoch 0, Step 1141: train/loss = 0.510909914970398, train/raw-loss = 0.46608442068099976, train/logprobs = tensor([[-0.9741, -3.2732],
        [-1.5292, -1.5022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08965102583169937
Epoch 0, Step 1142: train/loss = 0.6874111294746399, train/raw-loss = 0.6604917049407959, train/logprobs = tensor([[-0.5689, -0.8452],
        [-0.6012, -0.6778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05383894219994545
Epoch 0, Step 1143: train/loss = 0.6130643486976624, train/raw-loss = 0.5667530298233032, train/logprobs = tensor([[-0.9220, -1.9156],
        [-1.1921, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09262264519929886
Epoch 0, Step 1144: train/loss = 0.6118453741073608, train/raw-loss = 0.5727853178977966, train/logprobs = tensor([[-0.7755, -1.1716],
        [-1.4341, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.078120157122612
Epoch 0, Step 1145: train/loss = 0.6855853796005249, train/raw-loss = 0.6487661600112915, train/logprobs = tensor([[-1.0633, -1.8168],
        [-1.6361, -1.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07363846153020859
Epoch 0, Step 1146: train/loss = 0.6037917137145996, train/raw-loss = 0.5595442056655884, train/logprobs = tensor([[-0.8838, -1.4861],
        [-1.2831, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0884951502084732
Epoch 0, Step 1147: train/loss = 0.5501042604446411, train/raw-loss = 0.487679123878479, train/logprobs = tensor([[-0.9900, -3.1614],
        [-1.6666, -1.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12485025078058243
Epoch 0, Step 1148: train/loss = 0.6524499654769897, train/raw-loss = 0.6144572496414185, train/logprobs = tensor([[-0.6807, -1.5103],
        [-0.7892, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07598545402288437
Epoch 0, Step 1149: train/loss = 0.6619530916213989, train/raw-loss = 0.6311068534851074, train/logprobs = tensor([[-0.8219, -1.3223],
        [-1.0825, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06169239804148674
Epoch 0, Step 1150: train/loss = 0.5096282362937927, train/raw-loss = 0.44163966178894043, train/logprobs = tensor([[-0.6844, -2.4478],
        [-1.6137, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359771341085434
Epoch 0, Step 1151: train/loss = 0.6218445897102356, train/raw-loss = 0.5874800682067871, train/logprobs = tensor([[-0.9092, -1.4410],
        [-1.2529, -1.0451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06872916966676712
Epoch 0, Step 1152: train/loss = 0.8520989418029785, train/raw-loss = 0.8019158840179443, train/logprobs = tensor([[-1.2826, -0.9918],
        [-2.3494, -1.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003660261631012
Epoch 0, Step 1153: train/loss = 0.7027318477630615, train/raw-loss = 0.6588491797447205, train/logprobs = tensor([[-1.0817, -1.3066],
        [-1.4278, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08776538074016571
Epoch 0, Step 1154: train/loss = 0.6556655168533325, train/raw-loss = 0.6065046787261963, train/logprobs = tensor([[-1.1110, -2.3849],
        [-1.6149, -2.1742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09832163900136948
Epoch 0, Step 1155: train/loss = 0.6269646883010864, train/raw-loss = 0.5865166187286377, train/logprobs = tensor([[-0.7821, -1.1424],
        [-1.1772, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08089610934257507
Epoch 0, Step 1156: train/loss = 0.6392583847045898, train/raw-loss = 0.611617922782898, train/logprobs = tensor([[-0.7121, -1.1482],
        [-0.8671, -0.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055280961096286774
Epoch 0, Step 1157: train/loss = 0.5740768909454346, train/raw-loss = 0.5413148999214172, train/logprobs = tensor([[-0.6961, -3.7203],
        [-0.7637, -2.5635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0655239000916481
Epoch 0, Step 1158: train/loss = 0.709833025932312, train/raw-loss = 0.6555731296539307, train/logprobs = tensor([[-1.2933, -2.1119],
        [-1.6392, -1.6326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10851990431547165
Epoch 0, Step 1159: train/loss = 0.6399264335632324, train/raw-loss = 0.619037389755249, train/logprobs = tensor([[-0.6258, -1.2751],
        [-0.7122, -0.8012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04177813231945038
Epoch 0, Step 1160: train/loss = 0.50290447473526, train/raw-loss = 0.4393487572669983, train/logprobs = tensor([[-1.1704, -4.0665],
        [-2.2498, -2.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12711134552955627
Epoch 0, Step 1161: train/loss = 0.5860906839370728, train/raw-loss = 0.5220832228660583, train/logprobs = tensor([[-0.7884, -1.1611],
        [-1.8456, -0.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12801501154899597
Epoch 0, Step 1162: train/loss = 0.6657940149307251, train/raw-loss = 0.6433942317962646, train/logprobs = tensor([[-0.5639, -0.9814],
        [-0.6259, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044799625873565674
Epoch 0, Step 1163: train/loss = 0.805952787399292, train/raw-loss = 0.7738732099533081, train/logprobs = tensor([[-0.8667, -1.4054],
        [-1.2660, -1.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06415927410125732
Epoch 0, Step 1164: train/loss = 0.5920525193214417, train/raw-loss = 0.5405579805374146, train/logprobs = tensor([[-0.6230, -1.9137],
        [-1.1763, -1.0996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10298903286457062
Epoch 0, Step 1165: train/loss = 0.6526707410812378, train/raw-loss = 0.6027271151542664, train/logprobs = tensor([[-1.3703, -2.1611],
        [-1.7648, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09988721460103989
Epoch 0, Step 1166: train/loss = 0.5957159399986267, train/raw-loss = 0.5613713264465332, train/logprobs = tensor([[-0.6036, -2.0486],
        [-0.7378, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06868916004896164
Epoch 0, Step 1167: train/loss = 0.6088235378265381, train/raw-loss = 0.5602918863296509, train/logprobs = tensor([[-0.4892, -1.6436],
        [-0.8866, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09706326574087143
Epoch 0, Step 1168: train/loss = 0.6922572255134583, train/raw-loss = 0.6660737991333008, train/logprobs = tensor([[-0.6034, -1.1642],
        [-0.6648, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05236697196960449
Epoch 0, Step 1169: train/loss = 0.6156429052352905, train/raw-loss = 0.570715069770813, train/logprobs = tensor([[-0.9973, -2.1080],
        [-1.6816, -1.6289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08985559642314911
