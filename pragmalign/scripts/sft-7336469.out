[2024-03-07 09:08:38,954][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive-ve+
[2024-03-07 09:08:38,954][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive-ve+
[2024-03-07 09:08:38,954][root][INFO] - Max seq length: 2048
[2024-03-07 09:08:38,954][root][INFO] - Max seq length: 2048
[2024-03-07 09:08:38,954][root][INFO] - Devices: 4
[2024-03-07 09:08:38,954][root][INFO] - Devices: 4
[2024-03-07 09:08:38,954][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive-ve+
[2024-03-07 09:08:38,954][root][INFO] - Max seq length: 2048
[2024-03-07 09:08:38,954][root][INFO] - Devices: 4
[2024-03-07 09:08:38,955][root][INFO] - Writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/sft-iteration-1-no-sorry-positive-ve+
[2024-03-07 09:08:38,955][root][INFO] - Max seq length: 2048
[2024-03-07 09:08:38,955][root][INFO] - Devices: 4
[2024-03-07 09:08:55,431] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 09:08:55,432] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 09:08:55,433] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 09:08:55,434] [INFO] [real_accelerator.py:161:get_accelerator] Setting ds_accelerator to cuda (auto detect)
[2024-03-07 09:08:55,575] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 09:08:55,575] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 09:08:55,575] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 09:08:55,575] [INFO] [comm.py:668:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl
[2024-03-07 09:08:55,576] [INFO] [comm.py:637:init_distributed] cdb=None
[2024-03-07 09:09:16,127][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 23366
})
[2024-03-07 09:09:16,130][accelerate.utils.other][WARNING] - Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.
[2024-03-07 09:09:16,415][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 23366
})
[2024-03-07 09:09:16,463][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 23366
})
[2024-03-07 09:09:16,849][root][INFO] - Dataset({
    features: ['input_ids', 'labels'],
    num_rows: 23366
})
{'loss': 0.6593, 'learning_rate': 3.3333333333333334e-08, 'epoch': 0.03}
{'loss': 0.6429, 'learning_rate': 6.666666666666667e-08, 'epoch': 0.05}
{'loss': 0.6345, 'learning_rate': 1e-07, 'epoch': 0.08}
{'loss': 0.5791, 'learning_rate': 1.3333333333333334e-07, 'epoch': 0.11}
{'loss': 0.4933, 'learning_rate': 1.6666666666666665e-07, 'epoch': 0.14}
{'loss': 0.335, 'learning_rate': 2e-07, 'epoch': 0.16}
{'loss': 0.2937, 'learning_rate': 2.3333333333333333e-07, 'epoch': 0.19}
{'loss': 0.2538, 'learning_rate': 2.6666666666666667e-07, 'epoch': 0.22}
{'loss': 0.24, 'learning_rate': 3e-07, 'epoch': 0.25}
{'loss': 0.217, 'learning_rate': 3.333333333333333e-07, 'epoch': 0.27}
{'loss': 0.1982, 'learning_rate': 3.666666666666666e-07, 'epoch': 0.3}
{'loss': 0.2008, 'learning_rate': 4e-07, 'epoch': 0.33}
{'loss': 0.1918, 'learning_rate': 4.3333333333333335e-07, 'epoch': 0.36}
{'loss': 0.1891, 'learning_rate': 4.6666666666666666e-07, 'epoch': 0.38}
{'loss': 0.1855, 'learning_rate': 5e-07, 'epoch': 0.41}
{'loss': 0.1785, 'learning_rate': 5.333333333333333e-07, 'epoch': 0.44}
{'loss': 0.1774, 'learning_rate': 5.666666666666666e-07, 'epoch': 0.47}
{'loss': 0.1826, 'learning_rate': 6e-07, 'epoch': 0.49}
{'loss': 0.1787, 'learning_rate': 6.333333333333332e-07, 'epoch': 0.52}
{'loss': 0.1747, 'learning_rate': 6.666666666666666e-07, 'epoch': 0.55}
{'loss': 0.1782, 'learning_rate': 7e-07, 'epoch': 0.58}
{'loss': 0.1758, 'learning_rate': 7.333333333333332e-07, 'epoch': 0.6}
{'loss': 0.172, 'learning_rate': 7.666666666666667e-07, 'epoch': 0.63}
{'loss': 0.1759, 'learning_rate': 8e-07, 'epoch': 0.66}
{'loss': 0.1774, 'learning_rate': 8.333333333333333e-07, 'epoch': 0.68}
{'loss': 0.1779, 'learning_rate': 8.666666666666667e-07, 'epoch': 0.71}
{'loss': 0.1797, 'learning_rate': 9e-07, 'epoch': 0.74}
{'loss': 0.1719, 'learning_rate': 9.333333333333333e-07, 'epoch': 0.77}
{'loss': 0.182, 'learning_rate': 9.666666666666666e-07, 'epoch': 0.79}
{'loss': 0.1755, 'learning_rate': 1e-06, 'epoch': 0.82}
{'loss': 0.173, 'learning_rate': 8.4375e-07, 'epoch': 0.85}
{'loss': 0.1785, 'learning_rate': 6.875e-07, 'epoch': 0.88}
{'loss': 0.1747, 'learning_rate': 5.3125e-07, 'epoch': 0.9}
{'loss': 0.1691, 'learning_rate': 3.75e-07, 'epoch': 0.93}
{'loss': 0.1685, 'learning_rate': 2.1875e-07, 'epoch': 0.96}
{'loss': 0.1675, 'learning_rate': 6.25e-08, 'epoch': 0.99}
{'train_runtime': 932.2353, 'train_samples_per_second': 25.064, 'train_steps_per_second': 0.195, 'train_loss': 0.24917344388725993, 'epoch': 1.0}
