hydra:
  run:
    dir: outputs

defaults:
  - model: mistral_tiny_base
  - data: hh_rlhf

debug: true

n_examples: 100

evaluation_prompt: evaluation_prompt_answer # prompt we are using for eval (same as for training)