[2024-02-24 13:05:22,177][root][INFO] - beta: 0.1
[2024-02-24 13:05:22,177][root][INFO] - loss with_labels
[2024-02-24 13:05:22,178][root][INFO] - max_iter: 0
[2024-02-24 13:05:22,178][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-with-labels
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-with-labels after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-with-labels after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-with-labels after each epoch.
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.1-with-labels after each epoch.
Epoch 0, Step 0: train/loss = 0.7008420825004578, train/raw-loss = 0.700703501701355, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001385421957820654
Epoch 0, Step 1: train/loss = 0.6948565244674683, train/raw-loss = 0.6946866512298584, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016988443676382303
Epoch 0, Step 2: train/loss = 0.6923662424087524, train/raw-loss = 0.6923112869262695, train/logprobs = tensor([[-1.0892, -2.0869],
        [-1.1206, -2.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005500263068825006
Epoch 0, Step 3: train/loss = 0.6866117715835571, train/raw-loss = 0.6862989068031311, train/logprobs = tensor([[-0.5922, -1.4420],
        [-0.5997, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031291749328374863
Epoch 0, Step 4: train/loss = 0.6822781562805176, train/raw-loss = 0.6821818947792053, train/logprobs = tensor([[-0.9682, -2.2517],
        [-1.0031, -2.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009627505205571651
Epoch 0, Step 5: train/loss = 0.6994282007217407, train/raw-loss = 0.6991856098175049, train/logprobs = tensor([[-1.2526, -1.8470],
        [-1.2661, -1.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024260750506073236
Epoch 0, Step 6: train/loss = 0.6909489631652832, train/raw-loss = 0.6907837390899658, train/logprobs = tensor([[-0.9823, -1.5991],
        [-1.0011, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016527380794286728
Epoch 0, Step 7: train/loss = 0.7021964192390442, train/raw-loss = 0.7020244598388672, train/logprobs = tensor([[-1.0630, -1.5507],
        [-1.1077, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017196990083903074
Epoch 0, Step 8: train/loss = 0.6932111978530884, train/raw-loss = 0.6930682063102722, train/logprobs = tensor([[-0.8023, -1.7333],
        [-0.7871, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014302500057965517
Epoch 0, Step 9: train/loss = 0.6969835758209229, train/raw-loss = 0.6962793469429016, train/logprobs = tensor([[-1.0835, -1.7181],
        [-1.0813, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007042370270937681
Epoch 0, Step 10: train/loss = 0.6985957622528076, train/raw-loss = 0.6965494155883789, train/logprobs = tensor([[-1.1971, -2.5060],
        [-1.2764, -2.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020463809370994568
Epoch 0, Step 11: train/loss = 0.6863366961479187, train/raw-loss = 0.6862969398498535, train/logprobs = tensor([[-0.7466, -1.5640],
        [-0.7228, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039786301204003394
Epoch 0, Step 12: train/loss = 0.7163760662078857, train/raw-loss = 0.7148674726486206, train/logprobs = tensor([[-0.7433, -1.8789],
        [-0.7825, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015085747465491295
Epoch 0, Step 13: train/loss = 0.6872075796127319, train/raw-loss = 0.6869643926620483, train/logprobs = tensor([[-0.7519, -1.6611],
        [-0.7745, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002432220848277211
Epoch 0, Step 14: train/loss = 0.6850913763046265, train/raw-loss = 0.684917688369751, train/logprobs = tensor([[-1.1222, -1.7514],
        [-1.1230, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017367040272802114
Epoch 0, Step 15: train/loss = 0.7039209008216858, train/raw-loss = 0.7035808563232422, train/logprobs = tensor([[-1.0901, -1.5558],
        [-1.0901, -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034001865424215794
Epoch 0, Step 16: train/loss = 0.7082311511039734, train/raw-loss = 0.705668568611145, train/logprobs = tensor([[-0.9616, -2.0296],
        [-0.9940, -1.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025626003742218018
Epoch 0, Step 17: train/loss = 0.6926672458648682, train/raw-loss = 0.6924867033958435, train/logprobs = tensor([[-1.0904, -1.5065],
        [-1.0878, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018046624027192593
Epoch 0, Step 18: train/loss = 0.6931636929512024, train/raw-loss = 0.6928467154502869, train/logprobs = tensor([[-1.1498, -1.6923],
        [-1.1412, -1.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031702592968940735
Epoch 0, Step 19: train/loss = 0.6977421045303345, train/raw-loss = 0.6973589658737183, train/logprobs = tensor([[-0.7575, -1.3558],
        [-0.7511, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038300659507513046
Epoch 0, Step 20: train/loss = 0.7534458637237549, train/raw-loss = 0.751427173614502, train/logprobs = tensor([[-0.6982, -1.6722],
        [-0.7384, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020186442881822586
Epoch 0, Step 21: train/loss = 0.6943658590316772, train/raw-loss = 0.6941919326782227, train/logprobs = tensor([[-0.9935, -1.2997],
        [-0.9919, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017392875161021948
Epoch 0, Step 22: train/loss = 0.6882961988449097, train/raw-loss = 0.6880555152893066, train/logprobs = tensor([[-1.1048, -1.2115],
        [-1.1166, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002407266292721033
Epoch 0, Step 23: train/loss = 0.7264970541000366, train/raw-loss = 0.7249387502670288, train/logprobs = tensor([[-1.1101, -1.9440],
        [-1.1279, -2.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015583477914333344
Epoch 0, Step 24: train/loss = 0.6901059150695801, train/raw-loss = 0.6900442838668823, train/logprobs = tensor([[-0.9510, -2.1814],
        [-0.9490, -2.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006165502709336579
Epoch 0, Step 25: train/loss = 0.6854063272476196, train/raw-loss = 0.6853428483009338, train/logprobs = tensor([[-0.8277, -2.2563],
        [-0.8247, -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006352229975163937
Epoch 0, Step 26: train/loss = 0.6983336210250854, train/raw-loss = 0.6981753706932068, train/logprobs = tensor([[-0.5759, -2.1066],
        [-0.6087, -2.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015831212513148785
Epoch 0, Step 27: train/loss = 0.6974491477012634, train/raw-loss = 0.6973809003829956, train/logprobs = tensor([[-1.0402, -2.5564],
        [-1.0804, -2.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006825224263593554
Epoch 0, Step 28: train/loss = 0.6982411742210388, train/raw-loss = 0.6975324153900146, train/logprobs = tensor([[-0.8392, -1.7205],
        [-0.8369, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007087648846209049
Epoch 0, Step 29: train/loss = 0.6935246586799622, train/raw-loss = 0.6934842467308044, train/logprobs = tensor([[-0.5879, -1.8914],
        [-0.5988, -1.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040351462666876614
Epoch 0, Step 30: train/loss = 0.6920292973518372, train/raw-loss = 0.6918355822563171, train/logprobs = tensor([[-0.8561, -1.1920],
        [-0.8388, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001937028020620346
Epoch 0, Step 31: train/loss = 0.6731337904930115, train/raw-loss = 0.672492265701294, train/logprobs = tensor([[-1.0550, -2.2670],
        [-1.0818, -2.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006415537558495998
Epoch 0, Step 32: train/loss = 0.68923020362854, train/raw-loss = 0.6886965036392212, train/logprobs = tensor([[-0.9240, -1.9170],
        [-0.9467, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005336553789675236
Epoch 0, Step 33: train/loss = 0.7014134526252747, train/raw-loss = 0.7009933590888977, train/logprobs = tensor([[-0.8779, -1.8828],
        [-0.8573, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004200874827802181
Epoch 0, Step 34: train/loss = 0.6970118284225464, train/raw-loss = 0.6958221793174744, train/logprobs = tensor([[-1.0511, -1.5128],
        [-1.0826, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011896110139787197
Epoch 0, Step 35: train/loss = 0.7053303122520447, train/raw-loss = 0.7038596868515015, train/logprobs = tensor([[-0.9902, -1.8427],
        [-0.9916, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014705857262015343
Epoch 0, Step 36: train/loss = 0.7010126113891602, train/raw-loss = 0.6996639966964722, train/logprobs = tensor([[-1.2729, -1.4568],
        [-1.2776, -1.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013486114330589771
Epoch 0, Step 37: train/loss = 0.6882570385932922, train/raw-loss = 0.6881989240646362, train/logprobs = tensor([[-0.6132, -1.4763],
        [-0.6105, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005811454029753804
Epoch 0, Step 38: train/loss = 0.6924845576286316, train/raw-loss = 0.6917117834091187, train/logprobs = tensor([[-0.8017, -1.5622],
        [-0.8207, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007727716118097305
Epoch 0, Step 39: train/loss = 0.6977053880691528, train/raw-loss = 0.6974338889122009, train/logprobs = tensor([[-0.6779, -1.3967],
        [-0.6694, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027145948261022568
Epoch 0, Step 40: train/loss = 0.6941096782684326, train/raw-loss = 0.6939688920974731, train/logprobs = tensor([[-0.7632, -1.1195],
        [-0.7654, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014077682280912995
Epoch 0, Step 41: train/loss = 0.6798899173736572, train/raw-loss = 0.6795097589492798, train/logprobs = tensor([[-0.8216, -1.7078],
        [-0.8400, -1.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003801777958869934
Epoch 0, Step 42: train/loss = 0.694694459438324, train/raw-loss = 0.694367527961731, train/logprobs = tensor([[-0.6560, -1.7110],
        [-0.6654, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032684793695807457
Epoch 0, Step 43: train/loss = 0.6867050528526306, train/raw-loss = 0.6866177916526794, train/logprobs = tensor([[-1.0934, -2.2801],
        [-1.0771, -2.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008726525702513754
Epoch 0, Step 44: train/loss = 0.6904557347297668, train/raw-loss = 0.6903976798057556, train/logprobs = tensor([[-0.9415, -1.1740],
        [-0.9243, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005802650121040642
Epoch 0, Step 45: train/loss = 0.7049940228462219, train/raw-loss = 0.7042211294174194, train/logprobs = tensor([[-0.8766, -1.8393],
        [-0.8959, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007728645112365484
Epoch 0, Step 46: train/loss = 0.7236996293067932, train/raw-loss = 0.7230007648468018, train/logprobs = tensor([[-1.1262, -2.6505],
        [-1.1680, -2.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006988189183175564
Epoch 0, Step 47: train/loss = 0.6939867734909058, train/raw-loss = 0.6937203407287598, train/logprobs = tensor([[-0.7199, -1.4910],
        [-0.7111, -1.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026645706966519356
Epoch 0, Step 48: train/loss = 0.7075241804122925, train/raw-loss = 0.7070211172103882, train/logprobs = tensor([[-1.3350, -1.4101],
        [-1.3527, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005030433181673288
Epoch 0, Step 49: train/loss = 0.6919335126876831, train/raw-loss = 0.6914311051368713, train/logprobs = tensor([[-0.8395, -1.8763],
        [-0.8370, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005024871788918972
Epoch 0, Step 50: train/loss = 0.6909795999526978, train/raw-loss = 0.6909155249595642, train/logprobs = tensor([[-1.0832, -1.3937],
        [-1.0782, -1.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405673339031637
Epoch 0, Step 51: train/loss = 0.6861550807952881, train/raw-loss = 0.6857802867889404, train/logprobs = tensor([[-0.9913, -1.7751],
        [-0.9906, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037480113096535206
Epoch 0, Step 52: train/loss = 0.6875786781311035, train/raw-loss = 0.687508761882782, train/logprobs = tensor([[-0.7081, -0.7210],
        [-0.7282, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006987795932218432
Epoch 0, Step 53: train/loss = 0.7094684839248657, train/raw-loss = 0.7088227868080139, train/logprobs = tensor([[-0.6088, -1.0795],
        [-0.5906, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064574312418699265
Epoch 0, Step 54: train/loss = 0.6830158233642578, train/raw-loss = 0.682507336139679, train/logprobs = tensor([[-1.2230, -1.6885],
        [-1.2433, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005085480399429798
Epoch 0, Step 55: train/loss = 0.7045963406562805, train/raw-loss = 0.7028936743736267, train/logprobs = tensor([[-1.3000, -1.1052],
        [-1.3418, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017026763409376144
Epoch 0, Step 56: train/loss = 0.682129979133606, train/raw-loss = 0.6819606423377991, train/logprobs = tensor([[-0.8773, -1.4545],
        [-0.8995, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016936644678935409
Epoch 0, Step 57: train/loss = 0.6860986948013306, train/raw-loss = 0.6851555109024048, train/logprobs = tensor([[-0.6412, -1.4265],
        [-0.6492, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009431957267224789
Epoch 0, Step 58: train/loss = 0.6736461520195007, train/raw-loss = 0.6735333204269409, train/logprobs = tensor([[-0.6794, -1.6542],
        [-0.6772, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001128867152146995
Epoch 0, Step 59: train/loss = 0.6921510696411133, train/raw-loss = 0.6919022798538208, train/logprobs = tensor([[-0.8279, -1.2489],
        [-0.8414, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024887453764677048
Epoch 0, Step 60: train/loss = 0.6916520595550537, train/raw-loss = 0.6914083957672119, train/logprobs = tensor([[-1.1025, -1.5208],
        [-1.0788, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024371917825192213
Epoch 0, Step 61: train/loss = 0.6776034832000732, train/raw-loss = 0.6773156523704529, train/logprobs = tensor([[-0.5136, -1.4002],
        [-0.5257, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028787010814994574
Epoch 0, Step 62: train/loss = 0.7099829912185669, train/raw-loss = 0.7092434763908386, train/logprobs = tensor([[-1.1946, -1.5974],
        [-1.1819, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007394595071673393
Epoch 0, Step 63: train/loss = 0.696611762046814, train/raw-loss = 0.6964080333709717, train/logprobs = tensor([[-0.9767, -1.3460],
        [-0.9932, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002037512604147196
Epoch 0, Step 64: train/loss = 0.688285768032074, train/raw-loss = 0.6881462335586548, train/logprobs = tensor([[-0.9243, -1.6387],
        [-0.9196, -1.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001395134488120675
Epoch 0, Step 65: train/loss = 0.6945499181747437, train/raw-loss = 0.6943537592887878, train/logprobs = tensor([[-0.8708, -1.5659],
        [-0.8623, -1.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001961539499461651
Epoch 0, Step 66: train/loss = 0.7092153429985046, train/raw-loss = 0.7084194421768188, train/logprobs = tensor([[-1.0522, -1.9541],
        [-0.9982, -1.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00795941986143589
Epoch 0, Step 67: train/loss = 0.6924029588699341, train/raw-loss = 0.6919184327125549, train/logprobs = tensor([[-0.6799, -1.8663],
        [-0.6691, -1.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004845967050641775
Epoch 0, Step 68: train/loss = 0.7018434405326843, train/raw-loss = 0.7009537220001221, train/logprobs = tensor([[-0.8035, -2.8003],
        [-0.7833, -2.7544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008897106163203716
Epoch 0, Step 69: train/loss = 0.6864409446716309, train/raw-loss = 0.6862426996231079, train/logprobs = tensor([[-1.2681, -1.7071],
        [-1.2778, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019822316244244576
Epoch 0, Step 70: train/loss = 0.6894965171813965, train/raw-loss = 0.6893202066421509, train/logprobs = tensor([[-0.5966, -1.9345],
        [-0.5906, -1.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017623868770897388
Epoch 0, Step 71: train/loss = 0.6933119297027588, train/raw-loss = 0.6922637224197388, train/logprobs = tensor([[-1.0479, -1.9531],
        [-1.0342, -1.8800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01048228982836008
Epoch 0, Step 72: train/loss = 0.683011531829834, train/raw-loss = 0.6829067468643188, train/logprobs = tensor([[-0.4523, -1.9844],
        [-0.4532, -1.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010485938983038068
Epoch 0, Step 73: train/loss = 0.6976667642593384, train/raw-loss = 0.6973490715026855, train/logprobs = tensor([[-0.7359, -1.1102],
        [-0.7687, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003176737343892455
Epoch 0, Step 74: train/loss = 0.6974070072174072, train/raw-loss = 0.6972406506538391, train/logprobs = tensor([[-1.5959, -1.9993],
        [-1.5741, -1.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001663322327658534
Epoch 0, Step 75: train/loss = 0.6899309754371643, train/raw-loss = 0.6898002624511719, train/logprobs = tensor([[-0.7791, -1.8977],
        [-0.7717, -1.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013065456878393888
Epoch 0, Step 76: train/loss = 0.6712174415588379, train/raw-loss = 0.6708781123161316, train/logprobs = tensor([[-0.9764, -1.5812],
        [-1.0507, -1.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033936169929802418
Epoch 0, Step 77: train/loss = 0.6928393840789795, train/raw-loss = 0.6926039457321167, train/logprobs = tensor([[-1.2735, -1.4923],
        [-1.2859, -1.4923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002354342956095934
Epoch 0, Step 78: train/loss = 0.6855819821357727, train/raw-loss = 0.6854615807533264, train/logprobs = tensor([[-0.8845, -1.9012],
        [-0.8953, -1.8758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012038301210850477
Epoch 0, Step 79: train/loss = 0.6845732927322388, train/raw-loss = 0.6844953894615173, train/logprobs = tensor([[-0.5487, -1.2734],
        [-0.5523, -1.2331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007786471396684647
Epoch 0, Step 80: train/loss = 0.6872016787528992, train/raw-loss = 0.6870577335357666, train/logprobs = tensor([[-1.0783, -2.1453],
        [-1.0745, -2.1104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014386713737621903
Epoch 0, Step 81: train/loss = 0.7027397155761719, train/raw-loss = 0.7026599645614624, train/logprobs = tensor([[-0.8227, -1.8982],
        [-0.8357, -1.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007977764471434057
Epoch 0, Step 82: train/loss = 0.697640061378479, train/raw-loss = 0.6971620321273804, train/logprobs = tensor([[-1.2389, -1.0657],
        [-1.2397, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004779978189617395
Epoch 0, Step 83: train/loss = 0.6921542286872864, train/raw-loss = 0.6914365291595459, train/logprobs = tensor([[-0.6383, -1.7142],
        [-0.6399, -1.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0071776872500777245
Epoch 0, Step 84: train/loss = 0.6863300800323486, train/raw-loss = 0.6862707138061523, train/logprobs = tensor([[-0.5628, -2.0524],
        [-0.5606, -2.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005935928784310818
Epoch 0, Step 85: train/loss = 0.7030869126319885, train/raw-loss = 0.7022379636764526, train/logprobs = tensor([[-0.9219, -2.1818],
        [-0.9300, -2.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008489889092743397
Epoch 0, Step 86: train/loss = 0.6852796077728271, train/raw-loss = 0.6851059198379517, train/logprobs = tensor([[-0.6496, -1.8414],
        [-0.6546, -1.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017366759711876512
Epoch 0, Step 87: train/loss = 0.7059335112571716, train/raw-loss = 0.7056037187576294, train/logprobs = tensor([[-1.3918, -1.5902],
        [-1.3869, -1.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032980600371956825
Epoch 0, Step 88: train/loss = 0.7005199193954468, train/raw-loss = 0.7000806331634521, train/logprobs = tensor([[-0.8127, -2.0595],
        [-0.8179, -2.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004392335657030344
Epoch 0, Step 89: train/loss = 0.6985394954681396, train/raw-loss = 0.6973799467086792, train/logprobs = tensor([[-1.1065, -1.9200],
        [-1.0989, -1.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011595707386732101
Epoch 0, Step 90: train/loss = 0.6937692165374756, train/raw-loss = 0.6934210658073425, train/logprobs = tensor([[-0.8524, -1.8118],
        [-0.8950, -1.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034814083483070135
Epoch 0, Step 91: train/loss = 0.6880091428756714, train/raw-loss = 0.6879894733428955, train/logprobs = tensor([[-1.3128, -1.1799],
        [-1.3307, -1.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019645853899419308
Epoch 0, Step 92: train/loss = 0.6928600668907166, train/raw-loss = 0.6915881633758545, train/logprobs = tensor([[-0.9139, -1.7240],
        [-0.9800, -1.7260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012719276361167431
Epoch 0, Step 93: train/loss = 0.6993821859359741, train/raw-loss = 0.6986904144287109, train/logprobs = tensor([[-1.0028, -1.4942],
        [-1.0135, -1.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006917981430888176
Epoch 0, Step 94: train/loss = 0.7132068872451782, train/raw-loss = 0.7114115953445435, train/logprobs = tensor([[-1.2745, -2.7416],
        [-1.3112, -2.7101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01795286498963833
Epoch 0, Step 95: train/loss = 0.6923030614852905, train/raw-loss = 0.6917518973350525, train/logprobs = tensor([[-1.5582, -2.2765],
        [-1.5729, -2.2325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055116391740739346
Epoch 0, Step 96: train/loss = 0.689805805683136, train/raw-loss = 0.6896748542785645, train/logprobs = tensor([[-0.8681, -1.7050],
        [-0.8674, -1.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001309468294493854
Epoch 0, Step 97: train/loss = 0.7003467082977295, train/raw-loss = 0.7002425193786621, train/logprobs = tensor([[-1.7965, -2.7727],
        [-1.7867, -2.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010420328471809626
Epoch 0, Step 98: train/loss = 0.6921800374984741, train/raw-loss = 0.6916880011558533, train/logprobs = tensor([[-1.0880, -1.6185],
        [-1.0996, -1.6008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004920444916933775
Epoch 0, Step 99: train/loss = 0.6907396912574768, train/raw-loss = 0.6904701590538025, train/logprobs = tensor([[-0.8613, -1.5783],
        [-0.8565, -1.5510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026952167972922325
Epoch 0, Step 100: train/loss = 0.6907079219818115, train/raw-loss = 0.6901664137840271, train/logprobs = tensor([[-1.0213, -1.3583],
        [-1.0142, -1.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005415629595518112
Epoch 0, Step 101: train/loss = 0.6844974756240845, train/raw-loss = 0.6840769648551941, train/logprobs = tensor([[-1.1492, -2.3688],
        [-1.1502, -2.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004205450881272554
Epoch 0, Step 102: train/loss = 0.66841721534729, train/raw-loss = 0.6682862639427185, train/logprobs = tensor([[-0.7592, -1.8009],
        [-0.7432, -1.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013087778352200985
Epoch 0, Step 103: train/loss = 0.6817814111709595, train/raw-loss = 0.6813575029373169, train/logprobs = tensor([[-0.8668, -1.7502],
        [-0.8935, -1.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004239592235535383
Epoch 0, Step 104: train/loss = 0.6865617632865906, train/raw-loss = 0.6861168146133423, train/logprobs = tensor([[-0.8404, -1.5243],
        [-0.8402, -1.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044494918547570705
Epoch 0, Step 105: train/loss = 0.6894753575325012, train/raw-loss = 0.6891435980796814, train/logprobs = tensor([[-0.9830, -1.7990],
        [-0.9823, -1.7620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033173118717968464
Epoch 0, Step 106: train/loss = 0.6871979832649231, train/raw-loss = 0.686974287033081, train/logprobs = tensor([[-0.7301, -1.7974],
        [-0.7067, -1.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022371856030076742
Epoch 0, Step 107: train/loss = 0.6980598568916321, train/raw-loss = 0.6970532536506653, train/logprobs = tensor([[-1.2894, -1.6876],
        [-1.3027, -1.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01006636768579483
Epoch 0, Step 108: train/loss = 0.6905490159988403, train/raw-loss = 0.690091609954834, train/logprobs = tensor([[-0.7414, -0.8684],
        [-0.7390, -0.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004573808517307043
Epoch 0, Step 109: train/loss = 0.6966506838798523, train/raw-loss = 0.6959035396575928, train/logprobs = tensor([[-0.8047, -1.7888],
        [-0.8061, -1.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007471537217497826
Epoch 0, Step 110: train/loss = 0.6739733815193176, train/raw-loss = 0.6737879514694214, train/logprobs = tensor([[-0.9560, -2.1670],
        [-0.9283, -2.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001854805159382522
Epoch 0, Step 111: train/loss = 0.7008916735649109, train/raw-loss = 0.700677752494812, train/logprobs = tensor([[-0.9129, -1.7934],
        [-0.9064, -1.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021397212985903025
Epoch 0, Step 112: train/loss = 0.6943544745445251, train/raw-loss = 0.6942070126533508, train/logprobs = tensor([[-1.4778, -1.4325],
        [-1.5024, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014744340442121029
Epoch 0, Step 113: train/loss = 0.6878281235694885, train/raw-loss = 0.6876887083053589, train/logprobs = tensor([[-1.0466, -1.4071],
        [-1.0287, -1.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001394547987729311
Epoch 0, Step 114: train/loss = 0.6873483657836914, train/raw-loss = 0.6870888471603394, train/logprobs = tensor([[-0.9333, -1.1879],
        [-0.9396, -1.1566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025948937982320786
Epoch 0, Step 115: train/loss = 0.6644377708435059, train/raw-loss = 0.6642570495605469, train/logprobs = tensor([[-0.7591, -1.7870],
        [-0.7383, -1.6403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018070141086354852
Epoch 0, Step 116: train/loss = 0.6910840272903442, train/raw-loss = 0.6910718679428101, train/logprobs = tensor([[-0.6400, -1.4391],
        [-0.6484, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012216088362038136
Epoch 0, Step 117: train/loss = 0.6795698404312134, train/raw-loss = 0.6792922616004944, train/logprobs = tensor([[-0.9050, -1.7860],
        [-0.9123, -1.7143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027757645584642887
Epoch 0, Step 118: train/loss = 0.6871390342712402, train/raw-loss = 0.686692476272583, train/logprobs = tensor([[-0.9813, -1.9338],
        [-1.0239, -1.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004466114100068808
Epoch 0, Step 119: train/loss = 0.6977883577346802, train/raw-loss = 0.6974411606788635, train/logprobs = tensor([[-1.4261, -1.8311],
        [-1.4510, -1.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034720543771982193
Epoch 0, Step 120: train/loss = 0.7213721871376038, train/raw-loss = 0.720795214176178, train/logprobs = tensor([[-1.1253, -2.1859],
        [-1.1105, -2.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005769544746726751
Epoch 0, Step 121: train/loss = 0.6904735565185547, train/raw-loss = 0.690078854560852, train/logprobs = tensor([[-0.7457, -1.1872],
        [-0.7587, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003947115037590265
Epoch 0, Step 122: train/loss = 0.6907976865768433, train/raw-loss = 0.6906899213790894, train/logprobs = tensor([[-1.0423, -2.8032],
        [-1.0211, -2.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010771474335342646
Epoch 0, Step 123: train/loss = 0.6892852187156677, train/raw-loss = 0.688672661781311, train/logprobs = tensor([[-1.1866, -1.4212],
        [-1.1860, -1.3734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00612564105540514
Epoch 0, Step 124: train/loss = 0.6896939277648926, train/raw-loss = 0.6892821788787842, train/logprobs = tensor([[-0.6292, -1.4063],
        [-0.5828, -1.3251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004117516800761223
Epoch 0, Step 125: train/loss = 0.6803539991378784, train/raw-loss = 0.6800937652587891, train/logprobs = tensor([[-0.8289, -2.3639],
        [-0.8661, -2.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026028465945273638
Epoch 0, Step 126: train/loss = 0.6926491260528564, train/raw-loss = 0.6924993991851807, train/logprobs = tensor([[-1.1797, -2.9357],
        [-1.2348, -2.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014965427108108997
Epoch 0, Step 127: train/loss = 0.6858874559402466, train/raw-loss = 0.6856351494789124, train/logprobs = tensor([[-0.9779, -1.8387],
        [-0.9324, -1.7525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025235353969037533
Epoch 0, Step 128: train/loss = 0.7096255421638489, train/raw-loss = 0.7092482447624207, train/logprobs = tensor([[-1.0265, -1.5328],
        [-1.0024, -1.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037729237228631973
Epoch 0, Step 129: train/loss = 0.7057556509971619, train/raw-loss = 0.7053976058959961, train/logprobs = tensor([[-1.1442, -1.9639],
        [-1.1351, -1.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035798747558146715
Epoch 0, Step 130: train/loss = 0.6966988444328308, train/raw-loss = 0.6963011026382446, train/logprobs = tensor([[-1.2163, -2.6626],
        [-1.1577, -2.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003977449610829353
Epoch 0, Step 131: train/loss = 0.685818076133728, train/raw-loss = 0.6854202151298523, train/logprobs = tensor([[-1.5736, -1.4968],
        [-1.5985, -1.4749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003978610038757324
Epoch 0, Step 132: train/loss = 0.6922056674957275, train/raw-loss = 0.6905848383903503, train/logprobs = tensor([[-1.0197, -2.1865],
        [-1.1224, -2.2096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016208240762352943
Epoch 0, Step 133: train/loss = 0.689824640750885, train/raw-loss = 0.6896909475326538, train/logprobs = tensor([[-1.4833, -1.8656],
        [-1.5019, -1.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013365447521209717
Epoch 0, Step 134: train/loss = 0.684463381767273, train/raw-loss = 0.6840568780899048, train/logprobs = tensor([[-1.0393, -1.7266],
        [-1.0441, -1.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040655313059687614
Epoch 0, Step 135: train/loss = 0.6865049600601196, train/raw-loss = 0.6863919496536255, train/logprobs = tensor([[-1.5336, -1.6292],
        [-1.5265, -1.5904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011301826452836394
Epoch 0, Step 136: train/loss = 0.6820656061172485, train/raw-loss = 0.6808209419250488, train/logprobs = tensor([[-1.5452, -2.3569],
        [-1.5787, -2.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01244577206671238
Epoch 0, Step 137: train/loss = 0.6852970123291016, train/raw-loss = 0.6851905584335327, train/logprobs = tensor([[-1.6229, -1.5182],
        [-1.6435, -1.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010638327803462744
Epoch 0, Step 138: train/loss = 0.6939966082572937, train/raw-loss = 0.6935696601867676, train/logprobs = tensor([[-1.2052, -2.0264],
        [-1.1600, -1.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004269336350262165
Epoch 0, Step 139: train/loss = 0.7145512104034424, train/raw-loss = 0.7118583917617798, train/logprobs = tensor([[-1.1590, -2.4967],
        [-1.1847, -2.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02692844159901142
Epoch 0, Step 140: train/loss = 0.6876429319381714, train/raw-loss = 0.6875009536743164, train/logprobs = tensor([[-1.0678, -2.2740],
        [-1.0780, -2.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014200755394995213
Epoch 0, Step 141: train/loss = 0.6810901165008545, train/raw-loss = 0.6808923482894897, train/logprobs = tensor([[-0.8717, -2.1250],
        [-0.8559, -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019777845591306686
Epoch 0, Step 142: train/loss = 0.6784358024597168, train/raw-loss = 0.6780129671096802, train/logprobs = tensor([[-1.3403, -1.9255],
        [-1.3503, -1.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004228923935443163
Epoch 0, Step 143: train/loss = 0.687820553779602, train/raw-loss = 0.686943531036377, train/logprobs = tensor([[-1.5871, -1.7574],
        [-1.6118, -1.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008770426735281944
Epoch 0, Step 144: train/loss = 0.6905492544174194, train/raw-loss = 0.6900310516357422, train/logprobs = tensor([[-0.9486, -1.8446],
        [-0.9404, -1.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005182413384318352
Epoch 0, Step 145: train/loss = 0.6947551965713501, train/raw-loss = 0.6941952705383301, train/logprobs = tensor([[-1.1641, -1.5830],
        [-1.1488, -1.5335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055994149297475815
Epoch 0, Step 146: train/loss = 0.6844280362129211, train/raw-loss = 0.6839860081672668, train/logprobs = tensor([[-0.7769, -1.8374],
        [-0.7918, -1.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004420394543558359
Epoch 0, Step 147: train/loss = 0.6854150295257568, train/raw-loss = 0.6852207183837891, train/logprobs = tensor([[-1.3345, -1.8172],
        [-1.3202, -1.7625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001942828530445695
Epoch 0, Step 148: train/loss = 0.684512734413147, train/raw-loss = 0.6844433546066284, train/logprobs = tensor([[-1.0155, -1.4818],
        [-1.0206, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006935794954188168
Epoch 0, Step 149: train/loss = 0.6837996244430542, train/raw-loss = 0.6837901473045349, train/logprobs = tensor([[-1.0077, -1.8151],
        [-1.0015, -1.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.495458652963862e-05
Epoch 0, Step 150: train/loss = 0.6875982880592346, train/raw-loss = 0.6875273585319519, train/logprobs = tensor([[-1.1193, -1.8005],
        [-1.0777, -1.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007094273460097611
Epoch 0, Step 151: train/loss = 0.6986228227615356, train/raw-loss = 0.6982276439666748, train/logprobs = tensor([[-0.9411, -1.4993],
        [-0.9385, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003951827064156532
Epoch 0, Step 152: train/loss = 0.683864414691925, train/raw-loss = 0.6838091611862183, train/logprobs = tensor([[-0.9563, -1.9799],
        [-0.9383, -1.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005519581027328968
Epoch 0, Step 153: train/loss = 0.7006106972694397, train/raw-loss = 0.7003941535949707, train/logprobs = tensor([[-1.0886, -1.7836],
        [-1.0783, -1.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002164773875847459
Epoch 0, Step 154: train/loss = 0.6881857514381409, train/raw-loss = 0.6876963376998901, train/logprobs = tensor([[-1.3971, -2.1534],
        [-1.4026, -2.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004894366953521967
Epoch 0, Step 155: train/loss = 0.6899928450584412, train/raw-loss = 0.6898916959762573, train/logprobs = tensor([[-0.8902, -1.6932],
        [-0.8733, -1.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010113322641700506
Epoch 0, Step 156: train/loss = 0.6859310269355774, train/raw-loss = 0.685828447341919, train/logprobs = tensor([[-1.0673, -2.3079],
        [-1.0472, -2.2520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010256764944642782
Epoch 0, Step 157: train/loss = 0.6946603059768677, train/raw-loss = 0.6942028403282166, train/logprobs = tensor([[-0.9908, -1.3407],
        [-0.9638, -1.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004574418533593416
Epoch 0, Step 158: train/loss = 0.6786529421806335, train/raw-loss = 0.6783801913261414, train/logprobs = tensor([[-0.8353, -0.8281],
        [-0.8423, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002726960927248001
Epoch 0, Step 159: train/loss = 0.6864129304885864, train/raw-loss = 0.6860110759735107, train/logprobs = tensor([[-0.8595, -1.3283],
        [-0.8422, -1.2601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004018758423626423
Epoch 0, Step 160: train/loss = 0.6881135702133179, train/raw-loss = 0.6878824234008789, train/logprobs = tensor([[-0.8494, -1.3733],
        [-0.8218, -1.3117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002311163581907749
Epoch 0, Step 161: train/loss = 0.6862984895706177, train/raw-loss = 0.6861673593521118, train/logprobs = tensor([[-0.9187, -1.9997],
        [-0.9527, -1.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013110819272696972
Epoch 0, Step 162: train/loss = 0.6658048033714294, train/raw-loss = 0.6656390428543091, train/logprobs = tensor([[-0.7125, -2.3718],
        [-0.6858, -2.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016580593073740602
Epoch 0, Step 163: train/loss = 0.6752090454101562, train/raw-loss = 0.674737274646759, train/logprobs = tensor([[-1.2586, -1.8416],
        [-1.2398, -1.7235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004717400763183832
Epoch 0, Step 164: train/loss = 0.6805869340896606, train/raw-loss = 0.6797433495521545, train/logprobs = tensor([[-1.5466, -1.8100],
        [-1.5591, -1.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008435637690126896
Epoch 0, Step 165: train/loss = 0.6894070506095886, train/raw-loss = 0.6890692114830017, train/logprobs = tensor([[-1.1357, -2.0434],
        [-1.1205, -1.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033779421355575323
Epoch 0, Step 166: train/loss = 0.6903388500213623, train/raw-loss = 0.6901504993438721, train/logprobs = tensor([[-0.8941, -2.1378],
        [-0.8901, -2.1085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018838202813640237
Epoch 0, Step 167: train/loss = 0.6774227619171143, train/raw-loss = 0.6772713661193848, train/logprobs = tensor([[-1.2693, -1.2806],
        [-1.3291, -1.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015144438948482275
Epoch 0, Step 168: train/loss = 0.6861825585365295, train/raw-loss = 0.6859337687492371, train/logprobs = tensor([[-1.0186, -1.3510],
        [-1.0267, -1.3183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024882464203983545
Epoch 0, Step 169: train/loss = 0.688004195690155, train/raw-loss = 0.6878736615180969, train/logprobs = tensor([[-0.8787, -1.6104],
        [-0.8959, -1.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013057190226390958
Epoch 0, Step 170: train/loss = 0.6802981495857239, train/raw-loss = 0.6801841259002686, train/logprobs = tensor([[-0.6270, -2.1172],
        [-0.6263, -2.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001140289707109332
Epoch 0, Step 171: train/loss = 0.6979321241378784, train/raw-loss = 0.696834146976471, train/logprobs = tensor([[-1.2755, -1.5482],
        [-1.2566, -1.4973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010979505255818367
Epoch 0, Step 172: train/loss = 0.688843846321106, train/raw-loss = 0.6877785921096802, train/logprobs = tensor([[-1.0305, -1.8831],
        [-1.0217, -1.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010652976110577583
Epoch 0, Step 173: train/loss = 0.6885294318199158, train/raw-loss = 0.6875932216644287, train/logprobs = tensor([[-1.1207, -2.5261],
        [-1.1577, -2.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009361810982227325
Epoch 0, Step 174: train/loss = 0.7060537338256836, train/raw-loss = 0.70499187707901, train/logprobs = tensor([[-1.2574, -2.7207],
        [-1.2203, -2.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010618726722896099
Epoch 0, Step 175: train/loss = 0.6949295401573181, train/raw-loss = 0.6948914527893066, train/logprobs = tensor([[-1.6382, -1.7819],
        [-1.5537, -1.7027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038087862776592374
Epoch 0, Step 176: train/loss = 0.67934650182724, train/raw-loss = 0.6788570880889893, train/logprobs = tensor([[-0.8252, -2.0224],
        [-0.8082, -1.9199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004893715493381023
Epoch 0, Step 177: train/loss = 0.6746060848236084, train/raw-loss = 0.6744444370269775, train/logprobs = tensor([[-0.9332, -1.6090],
        [-0.9340, -1.5279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016169501468539238
Epoch 0, Step 178: train/loss = 0.6845122575759888, train/raw-loss = 0.6841291189193726, train/logprobs = tensor([[-0.7727, -1.9285],
        [-0.7644, -1.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038314624689519405
Epoch 0, Step 179: train/loss = 0.6856719851493835, train/raw-loss = 0.6854047775268555, train/logprobs = tensor([[-1.3440, -2.0215],
        [-1.3328, -1.9671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026719009038060904
Epoch 0, Step 180: train/loss = 0.6826434135437012, train/raw-loss = 0.6822060346603394, train/logprobs = tensor([[-1.1870, -1.5767],
        [-1.1920, -1.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004373819567263126
Epoch 0, Step 181: train/loss = 0.6964058876037598, train/raw-loss = 0.6960759162902832, train/logprobs = tensor([[-0.9672, -1.6620],
        [-0.9748, -1.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032997841481119394
Epoch 0, Step 182: train/loss = 0.6839282512664795, train/raw-loss = 0.6833901405334473, train/logprobs = tensor([[-1.1144, -1.5287],
        [-1.1366, -1.4888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005381764844059944
Epoch 0, Step 183: train/loss = 0.6725024580955505, train/raw-loss = 0.6716472506523132, train/logprobs = tensor([[-0.8519, -1.9153],
        [-0.8618, -1.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00855269469320774
Epoch 0, Step 184: train/loss = 0.6749946475028992, train/raw-loss = 0.6748852133750916, train/logprobs = tensor([[-0.9920, -2.0678],
        [-1.0070, -2.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010940886568278074
Epoch 0, Step 185: train/loss = 0.7046263217926025, train/raw-loss = 0.7029274702072144, train/logprobs = tensor([[-0.8806, -1.7817],
        [-0.8722, -1.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01698879897594452
Epoch 0, Step 186: train/loss = 0.6884672045707703, train/raw-loss = 0.6880300045013428, train/logprobs = tensor([[-0.8306, -1.9002],
        [-0.8175, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004371762275695801
Epoch 0, Step 187: train/loss = 0.6904879212379456, train/raw-loss = 0.6899951696395874, train/logprobs = tensor([[-0.9728, -1.6795],
        [-0.9702, -1.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004927369765937328
Epoch 0, Step 188: train/loss = 0.6827005743980408, train/raw-loss = 0.6826008558273315, train/logprobs = tensor([[-1.2206, -1.9508],
        [-1.1955, -1.8785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009971815161406994
Epoch 0, Step 189: train/loss = 0.7019078731536865, train/raw-loss = 0.7011415362358093, train/logprobs = tensor([[-1.1238, -1.6442],
        [-1.1095, -1.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007663325872272253
Epoch 0, Step 190: train/loss = 0.6831013560295105, train/raw-loss = 0.6822793483734131, train/logprobs = tensor([[-1.5021, -1.5910],
        [-1.5587, -1.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00821993313729763
Epoch 0, Step 191: train/loss = 0.688220202922821, train/raw-loss = 0.6878166198730469, train/logprobs = tensor([[-0.9992, -1.6282],
        [-0.9893, -1.5759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004036100581288338
Epoch 0, Step 192: train/loss = 0.6733378171920776, train/raw-loss = 0.6720945835113525, train/logprobs = tensor([[-1.1574, -1.3914],
        [-1.1967, -1.2932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012432101182639599
Epoch 0, Step 193: train/loss = 0.7008400559425354, train/raw-loss = 0.7005456686019897, train/logprobs = tensor([[-0.6919, -1.2469],
        [-0.7284, -1.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029440310318022966
Epoch 0, Step 194: train/loss = 0.6739093661308289, train/raw-loss = 0.673740565776825, train/logprobs = tensor([[-1.0708, -1.1910],
        [-1.1172, -1.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016875627916306257
Epoch 0, Step 195: train/loss = 0.6756352782249451, train/raw-loss = 0.6755163669586182, train/logprobs = tensor([[-0.5968, -1.4590],
        [-0.5991, -1.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011882788967341185
Epoch 0, Step 196: train/loss = 0.685362696647644, train/raw-loss = 0.6852501630783081, train/logprobs = tensor([[-1.4728, -2.0236],
        [-1.4048, -1.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011251710820943117
Epoch 0, Step 197: train/loss = 0.6712007522583008, train/raw-loss = 0.6706750988960266, train/logprobs = tensor([[-0.9178, -1.4225],
        [-0.9034, -1.2945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052564493380486965
Epoch 0, Step 198: train/loss = 0.6721386909484863, train/raw-loss = 0.6719073057174683, train/logprobs = tensor([[-0.8347, -0.9173],
        [-0.8596, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023140371777117252
Epoch 0, Step 199: train/loss = 0.6735497117042542, train/raw-loss = 0.6733397841453552, train/logprobs = tensor([[-0.9116, -1.0863],
        [-0.9528, -1.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00209942483343184
Epoch 0, Step 200: train/loss = 0.6673263311386108, train/raw-loss = 0.6657744646072388, train/logprobs = tensor([[-1.1220, -2.2488],
        [-1.1469, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015517751686275005
Epoch 0, Step 201: train/loss = 0.6737506985664368, train/raw-loss = 0.6733592748641968, train/logprobs = tensor([[-0.6409, -1.7513],
        [-0.6524, -1.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003914357163012028
Epoch 0, Step 202: train/loss = 0.6709937453269958, train/raw-loss = 0.6708567142486572, train/logprobs = tensor([[-0.6887, -1.9523],
        [-0.6918, -1.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013702635187655687
Epoch 0, Step 203: train/loss = 0.6275197267532349, train/raw-loss = 0.6263481974601746, train/logprobs = tensor([[-1.0828, -1.3134],
        [-1.1938, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011715579777956009
Epoch 0, Step 204: train/loss = 0.661979079246521, train/raw-loss = 0.6618484258651733, train/logprobs = tensor([[-1.3370, -1.3761],
        [-1.3534, -1.2615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013059773482382298
Epoch 0, Step 205: train/loss = 0.6667979955673218, train/raw-loss = 0.6663475036621094, train/logprobs = tensor([[-0.6497, -1.4277],
        [-0.6499, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004505096934735775
Epoch 0, Step 206: train/loss = 0.6512037515640259, train/raw-loss = 0.650723397731781, train/logprobs = tensor([[-0.8206, -1.3902],
        [-0.8239, -1.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004804281983524561
Epoch 0, Step 207: train/loss = 0.6547886729240417, train/raw-loss = 0.6546129584312439, train/logprobs = tensor([[-0.7435, -1.9000],
        [-0.7708, -1.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001757039804942906
Epoch 0, Step 208: train/loss = 0.6648427248001099, train/raw-loss = 0.66438889503479, train/logprobs = tensor([[-1.2998, -2.2837],
        [-1.3398, -2.1857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004537743516266346
Epoch 0, Step 209: train/loss = 0.6887463927268982, train/raw-loss = 0.6883507370948792, train/logprobs = tensor([[-0.9201, -1.8034],
        [-0.9072, -1.7542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00395654421299696
Epoch 0, Step 210: train/loss = 0.6559767127037048, train/raw-loss = 0.6550817489624023, train/logprobs = tensor([[-1.5224, -1.5499],
        [-1.5988, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008949446491897106
Epoch 0, Step 211: train/loss = 0.6777253150939941, train/raw-loss = 0.6771003603935242, train/logprobs = tensor([[-1.1214, -2.1029],
        [-1.1214, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006249415222555399
Epoch 0, Step 212: train/loss = 0.6783543229103088, train/raw-loss = 0.6781797409057617, train/logprobs = tensor([[-0.7356, -1.1695],
        [-0.7264, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001745673012919724
Epoch 0, Step 213: train/loss = 0.6733782887458801, train/raw-loss = 0.6726303696632385, train/logprobs = tensor([[-1.3639, -1.9171],
        [-1.3763, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00747902225703001
Epoch 0, Step 214: train/loss = 0.6918236017227173, train/raw-loss = 0.6913914680480957, train/logprobs = tensor([[-0.8648, -1.1470],
        [-0.8672, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043211886659264565
Epoch 0, Step 215: train/loss = 0.654987096786499, train/raw-loss = 0.6548112034797668, train/logprobs = tensor([[-1.0776, -1.5490],
        [-1.1136, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017583381850272417
Epoch 0, Step 216: train/loss = 0.6823346614837646, train/raw-loss = 0.6818662881851196, train/logprobs = tensor([[-1.5814, -1.4871],
        [-1.5812, -1.4230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004683602135628462
Epoch 0, Step 217: train/loss = 0.6784414052963257, train/raw-loss = 0.6783064007759094, train/logprobs = tensor([[-0.8551, -1.6046],
        [-0.8842, -1.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013502339133992791
Epoch 0, Step 218: train/loss = 0.6648088693618774, train/raw-loss = 0.6644241809844971, train/logprobs = tensor([[-0.8078, -2.1204],
        [-0.8227, -1.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038472674787044525
Epoch 0, Step 219: train/loss = 0.6927891969680786, train/raw-loss = 0.6927629709243774, train/logprobs = tensor([[-1.0019, -0.9462],
        [-0.9730, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026290654204785824
Epoch 0, Step 220: train/loss = 0.6640201210975647, train/raw-loss = 0.6639228463172913, train/logprobs = tensor([[-1.1878, -2.8889],
        [-1.2099, -2.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009729765588417649
Epoch 0, Step 221: train/loss = 0.674382746219635, train/raw-loss = 0.6742472052574158, train/logprobs = tensor([[-1.4922, -0.8149],
        [-1.4864, -0.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013557637576013803
Epoch 0, Step 222: train/loss = 0.6865874528884888, train/raw-loss = 0.6863517761230469, train/logprobs = tensor([[-0.9817, -1.2404],
        [-0.9710, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002357104327529669
Epoch 0, Step 223: train/loss = 0.6823490858078003, train/raw-loss = 0.6808665990829468, train/logprobs = tensor([[-0.9250, -1.9735],
        [-0.9774, -1.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014825009740889072
Epoch 0, Step 224: train/loss = 0.668566107749939, train/raw-loss = 0.6679668426513672, train/logprobs = tensor([[-1.3249, -2.7930],
        [-1.3135, -2.6475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005992579273879528
Epoch 0, Step 225: train/loss = 0.6565905809402466, train/raw-loss = 0.65626460313797, train/logprobs = tensor([[-0.8278, -2.1226],
        [-0.7906, -1.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032602145802229643
Epoch 0, Step 226: train/loss = 0.6666692495346069, train/raw-loss = 0.6665569543838501, train/logprobs = tensor([[-1.0407, -2.4788],
        [-1.0671, -2.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011227900395169854
Epoch 0, Step 227: train/loss = 0.6763347387313843, train/raw-loss = 0.6762086153030396, train/logprobs = tensor([[-0.7580, -1.4076],
        [-0.7516, -1.3270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012617908651009202
Epoch 0, Step 228: train/loss = 0.6632476449012756, train/raw-loss = 0.6629328727722168, train/logprobs = tensor([[-1.1710, -2.5685],
        [-1.1557, -2.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031474505085498095
Epoch 0, Step 229: train/loss = 0.6523375511169434, train/raw-loss = 0.6519430875778198, train/logprobs = tensor([[-0.9604, -1.7687],
        [-0.9897, -1.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039449045434594154
Epoch 0, Step 230: train/loss = 0.6670554280281067, train/raw-loss = 0.6669881343841553, train/logprobs = tensor([[-1.1829, -2.6572],
        [-1.1676, -2.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006726276478730142
Epoch 0, Step 231: train/loss = 0.6683348417282104, train/raw-loss = 0.6680888533592224, train/logprobs = tensor([[-1.2534, -1.4405],
        [-1.2517, -1.3285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024597705341875553
Epoch 0, Step 232: train/loss = 0.6636745929718018, train/raw-loss = 0.6634523868560791, train/logprobs = tensor([[-1.1985, -2.3352],
        [-1.1979, -2.2025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002222372218966484
Epoch 0, Step 233: train/loss = 0.6673480272293091, train/raw-loss = 0.6668828725814819, train/logprobs = tensor([[-1.6913, -1.9543],
        [-1.6480, -1.7854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004650868941098452
Epoch 0, Step 234: train/loss = 0.6330845952033997, train/raw-loss = 0.6326508522033691, train/logprobs = tensor([[-1.0653, -2.0318],
        [-1.0964, -1.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00433747423812747
Epoch 0, Step 235: train/loss = 0.6881296038627625, train/raw-loss = 0.6870825290679932, train/logprobs = tensor([[-1.1455, -1.7387],
        [-1.1040, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010471348650753498
Epoch 0, Step 236: train/loss = 0.6748371720314026, train/raw-loss = 0.6747739315032959, train/logprobs = tensor([[-0.6947, -1.4797],
        [-0.6843, -1.3919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006329017924144864
Epoch 0, Step 237: train/loss = 0.6739547848701477, train/raw-loss = 0.6735242605209351, train/logprobs = tensor([[-0.7728, -1.0632],
        [-0.7574, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004305591806769371
Epoch 0, Step 238: train/loss = 0.6802701354026794, train/raw-loss = 0.6800912022590637, train/logprobs = tensor([[-0.7335, -1.6623],
        [-0.7369, -1.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017895626369863749
Epoch 0, Step 239: train/loss = 0.6912188529968262, train/raw-loss = 0.6903257369995117, train/logprobs = tensor([[-2.1044, -1.7842],
        [-2.0753, -1.6966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008931690827012062
Epoch 0, Step 240: train/loss = 0.6803571581840515, train/raw-loss = 0.6792388558387756, train/logprobs = tensor([[-1.1126, -1.4673],
        [-1.1247, -1.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011182781308889389
Epoch 0, Step 241: train/loss = 0.6677963733673096, train/raw-loss = 0.667046308517456, train/logprobs = tensor([[-1.0406, -1.9918],
        [-1.0826, -1.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007501080632209778
Epoch 0, Step 242: train/loss = 0.6593918204307556, train/raw-loss = 0.6590511202812195, train/logprobs = tensor([[-1.2779, -1.6817],
        [-1.2743, -1.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034071817062795162
Epoch 0, Step 243: train/loss = 0.6655961275100708, train/raw-loss = 0.6646009683609009, train/logprobs = tensor([[-1.3770, -1.7229],
        [-1.3612, -1.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00995124876499176
Epoch 0, Step 244: train/loss = 0.6761288046836853, train/raw-loss = 0.6760125160217285, train/logprobs = tensor([[-1.0195, -1.7850],
        [-0.9814, -1.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011634769616648555
Epoch 0, Step 245: train/loss = 0.6776138544082642, train/raw-loss = 0.6775428056716919, train/logprobs = tensor([[-1.2374, -1.7577],
        [-1.2298, -1.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007106588454917073
Epoch 0, Step 246: train/loss = 0.6842143535614014, train/raw-loss = 0.6836364269256592, train/logprobs = tensor([[-1.0917, -1.5846],
        [-1.0814, -1.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005779126193374395
Epoch 0, Step 247: train/loss = 0.6728320121765137, train/raw-loss = 0.6722779273986816, train/logprobs = tensor([[-1.0132, -1.9066],
        [-0.9559, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055410489439964294
Epoch 0, Step 248: train/loss = 0.6625540852546692, train/raw-loss = 0.6624767780303955, train/logprobs = tensor([[-1.0255, -2.4994],
        [-0.9949, -2.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007730189245194197
Epoch 0, Step 249: train/loss = 0.6635645031929016, train/raw-loss = 0.6634563207626343, train/logprobs = tensor([[-1.3811, -1.4796],
        [-1.4412, -1.4165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010812480468302965
Epoch 0, Step 250: train/loss = 0.6463960409164429, train/raw-loss = 0.6461542844772339, train/logprobs = tensor([[-0.6028, -2.2293],
        [-0.5702, -1.9923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024176468141376972
Epoch 0, Step 251: train/loss = 0.6886088252067566, train/raw-loss = 0.688530683517456, train/logprobs = tensor([[-0.9722, -2.2800],
        [-1.0257, -2.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007811464602127671
Epoch 0, Step 252: train/loss = 0.7013412714004517, train/raw-loss = 0.7000811696052551, train/logprobs = tensor([[-1.1932, -1.2319],
        [-1.1494, -1.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012601129710674286
Epoch 0, Step 253: train/loss = 0.6839727163314819, train/raw-loss = 0.6839028596878052, train/logprobs = tensor([[-1.2957, -1.5721],
        [-1.2991, -1.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006979829631745815
Epoch 0, Step 254: train/loss = 0.6973848342895508, train/raw-loss = 0.6962668299674988, train/logprobs = tensor([[-0.9361, -1.1266],
        [-0.9552, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011179802939295769
Epoch 0, Step 255: train/loss = 0.6618396043777466, train/raw-loss = 0.6614935398101807, train/logprobs = tensor([[-0.9219, -2.2389],
        [-0.9470, -2.1049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003460363484919071
Epoch 0, Step 256: train/loss = 0.647495448589325, train/raw-loss = 0.6473446488380432, train/logprobs = tensor([[-0.7981, -2.0210],
        [-0.7854, -1.8166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015078855212777853
Epoch 0, Step 257: train/loss = 0.6785409450531006, train/raw-loss = 0.6775879859924316, train/logprobs = tensor([[-1.4060, -2.5143],
        [-1.3650, -2.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009529635310173035
Epoch 0, Step 258: train/loss = 0.6692625880241394, train/raw-loss = 0.6680808663368225, train/logprobs = tensor([[-1.7170, -2.2009],
        [-1.7228, -2.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011816881597042084
Epoch 0, Step 259: train/loss = 0.6799627542495728, train/raw-loss = 0.679777979850769, train/logprobs = tensor([[-1.8259, -1.7149],
        [-1.7517, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018475181423127651
Epoch 0, Step 260: train/loss = 0.645408570766449, train/raw-loss = 0.6451507806777954, train/logprobs = tensor([[-1.2181, -2.0854],
        [-1.1885, -1.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002577780745923519
Epoch 0, Step 261: train/loss = 0.6545166373252869, train/raw-loss = 0.6538650989532471, train/logprobs = tensor([[-0.9198, -2.3874],
        [-0.8274, -2.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065156640484929085
Epoch 0, Step 262: train/loss = 0.7065184116363525, train/raw-loss = 0.7058868408203125, train/logprobs = tensor([[-1.4658, -1.8832],
        [-1.4061, -1.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0063150618225336075
Epoch 0, Step 263: train/loss = 0.6619477868080139, train/raw-loss = 0.6616324186325073, train/logprobs = tensor([[-1.8301, -2.6176],
        [-1.7732, -2.3901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003154254052788019
Epoch 0, Step 264: train/loss = 0.663269579410553, train/raw-loss = 0.6625239849090576, train/logprobs = tensor([[-1.1681, -2.3419],
        [-1.0955, -2.1048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007455988321453333
Epoch 0, Step 265: train/loss = 0.6786590814590454, train/raw-loss = 0.6784035563468933, train/logprobs = tensor([[-1.3633, -1.9065],
        [-1.3541, -1.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002555497456341982
Epoch 0, Step 266: train/loss = 0.6819204688072205, train/raw-loss = 0.6814723610877991, train/logprobs = tensor([[-1.2365, -1.1653],
        [-1.1952, -1.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044809021055698395
Epoch 0, Step 267: train/loss = 0.6684020757675171, train/raw-loss = 0.6678552627563477, train/logprobs = tensor([[-1.4108, -1.7266],
        [-1.4115, -1.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005468694027513266
Epoch 0, Step 268: train/loss = 0.6508753895759583, train/raw-loss = 0.6505573987960815, train/logprobs = tensor([[-1.1187, -1.8326],
        [-1.0841, -1.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031800889410078526
Epoch 0, Step 269: train/loss = 0.6374003887176514, train/raw-loss = 0.6361221671104431, train/logprobs = tensor([[-0.9931, -1.8377],
        [-1.1040, -1.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012782182544469833
Epoch 0, Step 270: train/loss = 0.6795030236244202, train/raw-loss = 0.6794003248214722, train/logprobs = tensor([[-0.9167, -1.8344],
        [-0.8449, -1.7018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010276634711772203
Epoch 0, Step 271: train/loss = 0.6398053765296936, train/raw-loss = 0.6392452716827393, train/logprobs = tensor([[-0.6789, -2.1113],
        [-0.6592, -1.8444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056013851426541805
Epoch 0, Step 272: train/loss = 0.6742480397224426, train/raw-loss = 0.673812985420227, train/logprobs = tensor([[-1.0085, -1.6462],
        [-0.9678, -1.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004351114854216576
Epoch 0, Step 273: train/loss = 0.6535208225250244, train/raw-loss = 0.6533087491989136, train/logprobs = tensor([[-0.5526, -2.1388],
        [-0.5630, -1.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021211463026702404
Epoch 0, Step 274: train/loss = 0.659312903881073, train/raw-loss = 0.658689558506012, train/logprobs = tensor([[-1.3832, -2.1037],
        [-1.3910, -1.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006233477033674717
Epoch 0, Step 275: train/loss = 0.6521153450012207, train/raw-loss = 0.6513301134109497, train/logprobs = tensor([[-1.0840, -2.1896],
        [-1.0210, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007852503098547459
Epoch 0, Step 276: train/loss = 0.6439002752304077, train/raw-loss = 0.643734872341156, train/logprobs = tensor([[-0.6415, -2.5570],
        [-0.6278, -2.3265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001654063118621707
Epoch 0, Step 277: train/loss = 0.6251592636108398, train/raw-loss = 0.624395489692688, train/logprobs = tensor([[-1.6345, -2.1642],
        [-1.6205, -1.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00763784209266305
Epoch 0, Step 278: train/loss = 0.6512143611907959, train/raw-loss = 0.6494899988174438, train/logprobs = tensor([[-1.4275, -2.6149],
        [-1.4367, -2.3506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017243819311261177
Epoch 0, Step 279: train/loss = 0.6684215068817139, train/raw-loss = 0.6683574318885803, train/logprobs = tensor([[-1.2612, -1.6933],
        [-1.2622, -1.5917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405413732863963
Epoch 0, Step 280: train/loss = 0.655044436454773, train/raw-loss = 0.6548661589622498, train/logprobs = tensor([[-1.0110, -1.8483],
        [-0.9924, -1.6675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001782805658876896
Epoch 0, Step 281: train/loss = 0.6771242618560791, train/raw-loss = 0.6767047643661499, train/logprobs = tensor([[-1.5099, -1.8676],
        [-1.4559, -1.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00419500470161438
Epoch 0, Step 282: train/loss = 0.6458774209022522, train/raw-loss = 0.645699143409729, train/logprobs = tensor([[-0.7192, -1.9564],
        [-0.7032, -1.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001782447681762278
Epoch 0, Step 283: train/loss = 0.6358094811439514, train/raw-loss = 0.6352543830871582, train/logprobs = tensor([[-0.7757, -2.3760],
        [-0.7895, -2.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005551219452172518
Epoch 0, Step 284: train/loss = 0.6794317364692688, train/raw-loss = 0.6784046292304993, train/logprobs = tensor([[-1.0257, -1.4508],
        [-1.0511, -1.3525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0102712232619524
Epoch 0, Step 285: train/loss = 0.6710783839225769, train/raw-loss = 0.67075514793396, train/logprobs = tensor([[-1.1232, -2.6472],
        [-1.0665, -2.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00323176640085876
Epoch 0, Step 286: train/loss = 0.6844907999038696, train/raw-loss = 0.6835601925849915, train/logprobs = tensor([[-0.9386, -1.5536],
        [-0.9093, -1.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00930678378790617
Epoch 0, Step 287: train/loss = 0.6774287819862366, train/raw-loss = 0.676708459854126, train/logprobs = tensor([[-1.1683, -1.3314],
        [-1.1683, -1.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007202806882560253
Epoch 0, Step 288: train/loss = 0.6581999063491821, train/raw-loss = 0.6550535559654236, train/logprobs = tensor([[-1.5285, -2.8021],
        [-1.6031, -2.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03146371990442276
Epoch 0, Step 289: train/loss = 0.6598901152610779, train/raw-loss = 0.6596362590789795, train/logprobs = tensor([[-1.1352, -1.5237],
        [-1.0876, -1.3307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002539093606173992
Epoch 0, Step 290: train/loss = 0.6649011969566345, train/raw-loss = 0.6644229888916016, train/logprobs = tensor([[-1.1175, -1.8024],
        [-1.0459, -1.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004781817551702261
Epoch 0, Step 291: train/loss = 0.6794532537460327, train/raw-loss = 0.6790927648544312, train/logprobs = tensor([[-0.7391, -1.0168],
        [-0.7377, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003604570170864463
Epoch 0, Step 292: train/loss = 0.6165847778320312, train/raw-loss = 0.616111159324646, train/logprobs = tensor([[-1.0408, -1.9917],
        [-0.9851, -1.5986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004736735951155424
Epoch 0, Step 293: train/loss = 0.6128314733505249, train/raw-loss = 0.6119615435600281, train/logprobs = tensor([[-0.8971, -2.4793],
        [-0.9601, -2.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008699829690158367
Epoch 0, Step 294: train/loss = 0.6497910618782043, train/raw-loss = 0.649332582950592, train/logprobs = tensor([[-1.0445, -2.1393],
        [-1.0604, -1.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004585159011185169
Epoch 0, Step 295: train/loss = 0.6634534597396851, train/raw-loss = 0.6631391644477844, train/logprobs = tensor([[-1.7819, -1.9542],
        [-1.7248, -1.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003143073758110404
Epoch 0, Step 296: train/loss = 0.6190630197525024, train/raw-loss = 0.6179780960083008, train/logprobs = tensor([[-1.1314, -2.6090],
        [-1.1626, -2.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010849098674952984
Epoch 0, Step 297: train/loss = 0.6364548802375793, train/raw-loss = 0.6361918449401855, train/logprobs = tensor([[-1.2227, -2.3799],
        [-1.2429, -2.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002630189061164856
Epoch 0, Step 298: train/loss = 0.6260155439376831, train/raw-loss = 0.6257674694061279, train/logprobs = tensor([[-0.8222, -2.2144],
        [-0.8915, -2.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024805874563753605
Epoch 0, Step 299: train/loss = 0.6611062288284302, train/raw-loss = 0.6606752872467041, train/logprobs = tensor([[-1.3312, -1.2895],
        [-1.3633, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004310157150030136
Epoch 0, Step 300: train/loss = 0.665417492389679, train/raw-loss = 0.6651405096054077, train/logprobs = tensor([[-1.4063, -1.5168],
        [-1.3172, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002769800368696451
Epoch 0, Step 301: train/loss = 0.6600445508956909, train/raw-loss = 0.6598799228668213, train/logprobs = tensor([[-0.8519, -1.2705],
        [-0.8268, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016465772641822696
Epoch 0, Step 302: train/loss = 0.610567569732666, train/raw-loss = 0.6096333861351013, train/logprobs = tensor([[-1.0393, -2.1947],
        [-1.0737, -1.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009342136792838573
Epoch 0, Step 303: train/loss = 0.6850926876068115, train/raw-loss = 0.6845818161964417, train/logprobs = tensor([[-0.8574, -1.6988],
        [-0.8067, -1.5915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005108760669827461
Epoch 0, Step 304: train/loss = 0.6345397233963013, train/raw-loss = 0.6341986656188965, train/logprobs = tensor([[-1.2431, -2.1103],
        [-1.2195, -1.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034107090905308723
Epoch 0, Step 305: train/loss = 0.6682718396186829, train/raw-loss = 0.6672946214675903, train/logprobs = tensor([[-1.0505, -1.0860],
        [-1.0589, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009772301651537418
Epoch 0, Step 306: train/loss = 0.6270571947097778, train/raw-loss = 0.6266853213310242, train/logprobs = tensor([[-0.9137, -2.0186],
        [-0.9172, -1.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00371875474229455
Epoch 0, Step 307: train/loss = 0.633794367313385, train/raw-loss = 0.6331260204315186, train/logprobs = tensor([[-0.8864, -2.0672],
        [-0.9228, -1.8261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006682961247861385
Epoch 0, Step 308: train/loss = 0.6405861377716064, train/raw-loss = 0.6392030715942383, train/logprobs = tensor([[-1.2914, -1.9838],
        [-1.2950, -1.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013830503448843956
Epoch 0, Step 309: train/loss = 0.6469579935073853, train/raw-loss = 0.6466663479804993, train/logprobs = tensor([[-0.8373, -1.4986],
        [-0.8460, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002916341181844473
Epoch 0, Step 310: train/loss = 0.6167981028556824, train/raw-loss = 0.6164349913597107, train/logprobs = tensor([[-1.0956, -2.6119],
        [-1.0689, -2.2421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036310418508946896
Epoch 0, Step 311: train/loss = 0.6460905075073242, train/raw-loss = 0.6456575393676758, train/logprobs = tensor([[-0.7383, -1.5506],
        [-0.7551, -1.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004329467657953501
Epoch 0, Step 312: train/loss = 0.6528199315071106, train/raw-loss = 0.6525877714157104, train/logprobs = tensor([[-1.3612, -1.8944],
        [-1.3778, -1.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002321422565728426
Epoch 0, Step 313: train/loss = 0.6256945133209229, train/raw-loss = 0.6250416040420532, train/logprobs = tensor([[-0.9434, -2.8001],
        [-0.9270, -2.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006529700011014938
Epoch 0, Step 314: train/loss = 0.6196917295455933, train/raw-loss = 0.6191061735153198, train/logprobs = tensor([[-0.8866, -2.7149],
        [-0.9846, -2.4789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005855972412973642
Epoch 0, Step 315: train/loss = 0.6499107480049133, train/raw-loss = 0.649742841720581, train/logprobs = tensor([[-0.7931, -2.5597],
        [-0.7576, -2.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016788352513685822
Epoch 0, Step 316: train/loss = 0.6300973296165466, train/raw-loss = 0.6297816634178162, train/logprobs = tensor([[-1.2461, -2.0204],
        [-1.2397, -1.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003157098311930895
Epoch 0, Step 317: train/loss = 0.6470319628715515, train/raw-loss = 0.646785318851471, train/logprobs = tensor([[-1.0724, -1.7307],
        [-1.1004, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024665023665875196
Epoch 0, Step 318: train/loss = 0.657196581363678, train/raw-loss = 0.6567901372909546, train/logprobs = tensor([[-1.1947, -2.1342],
        [-1.1851, -1.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004065016750246286
Epoch 0, Step 319: train/loss = 0.6390811800956726, train/raw-loss = 0.6385084986686707, train/logprobs = tensor([[-1.1942, -2.0826],
        [-1.2556, -1.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005726872012019157
Epoch 0, Step 320: train/loss = 0.6381040811538696, train/raw-loss = 0.6375699639320374, train/logprobs = tensor([[-0.7259, -1.6871],
        [-0.8571, -1.5698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005341945216059685
Epoch 0, Step 321: train/loss = 0.6262786388397217, train/raw-loss = 0.6255470514297485, train/logprobs = tensor([[-1.4342, -2.4966],
        [-1.5670, -2.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007316570729017258
Epoch 0, Step 322: train/loss = 0.6573383808135986, train/raw-loss = 0.6541620492935181, train/logprobs = tensor([[-1.1604, -2.1582],
        [-1.2381, -1.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03176327049732208
Epoch 0, Step 323: train/loss = 0.6921766400337219, train/raw-loss = 0.6919983625411987, train/logprobs = tensor([[-1.0942, -0.8434],
        [-1.1443, -0.8815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001783063868060708
Epoch 0, Step 324: train/loss = 0.6555773615837097, train/raw-loss = 0.655197024345398, train/logprobs = tensor([[-1.5320, -2.1950],
        [-1.6379, -2.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038037747144699097
Epoch 0, Step 325: train/loss = 0.6215938329696655, train/raw-loss = 0.6184511184692383, train/logprobs = tensor([[-2.1729, -1.9545],
        [-2.3958, -1.7518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031427014619112015
Epoch 0, Step 326: train/loss = 0.6554065942764282, train/raw-loss = 0.6550108194351196, train/logprobs = tensor([[-1.3941, -2.1574],
        [-1.5703, -2.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003957623615860939
Epoch 0, Step 327: train/loss = 0.6976507902145386, train/raw-loss = 0.6961445212364197, train/logprobs = tensor([[-1.3030, -1.7302],
        [-1.4210, -1.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015062496066093445
Epoch 0, Step 328: train/loss = 0.6914172172546387, train/raw-loss = 0.6909174919128418, train/logprobs = tensor([[-1.1578, -1.4956],
        [-1.1685, -1.4757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004996778443455696
Epoch 0, Step 329: train/loss = 0.6449794769287109, train/raw-loss = 0.6442535519599915, train/logprobs = tensor([[-1.4977, -2.0477],
        [-1.6258, -1.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007258981000632048
Epoch 0, Step 330: train/loss = 0.6585429906845093, train/raw-loss = 0.6581770777702332, train/logprobs = tensor([[-1.2479, -2.3059],
        [-1.3927, -2.2826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003659665584564209
Epoch 0, Step 331: train/loss = 0.6802701950073242, train/raw-loss = 0.6797760725021362, train/logprobs = tensor([[-1.4514, -2.1051],
        [-1.4415, -2.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004941605497151613
Epoch 0, Step 332: train/loss = 0.6591594219207764, train/raw-loss = 0.6587373614311218, train/logprobs = tensor([[-1.8910, -1.4771],
        [-1.9959, -1.4258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042207008227705956
Epoch 0, Step 333: train/loss = 0.6374024152755737, train/raw-loss = 0.6363056302070618, train/logprobs = tensor([[-1.3722, -2.3513],
        [-1.5475, -2.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010968358255922794
Epoch 0, Step 334: train/loss = 0.6556669473648071, train/raw-loss = 0.6550289392471313, train/logprobs = tensor([[-1.6244, -2.2505],
        [-1.6639, -2.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006380792241543531
Epoch 0, Step 335: train/loss = 0.6580582857131958, train/raw-loss = 0.6568831205368042, train/logprobs = tensor([[-0.8905, -1.5222],
        [-0.9947, -1.4280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011750699952244759
Epoch 0, Step 336: train/loss = 0.6650572419166565, train/raw-loss = 0.664545476436615, train/logprobs = tensor([[-1.0846, -1.6557],
        [-1.1608, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005117286927998066
Epoch 0, Step 337: train/loss = 0.6908467411994934, train/raw-loss = 0.6895401477813721, train/logprobs = tensor([[-1.2362, -2.4660],
        [-1.3366, -2.4832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013066615909337997
Epoch 0, Step 338: train/loss = 0.692081093788147, train/raw-loss = 0.6915179491043091, train/logprobs = tensor([[-1.3690, -1.8571],
        [-1.3894, -1.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005631857551634312
Epoch 0, Step 339: train/loss = 0.6826846599578857, train/raw-loss = 0.6823804378509521, train/logprobs = tensor([[-1.5230, -1.5286],
        [-1.6353, -1.5847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003042791970074177
Epoch 0, Step 340: train/loss = 0.6311714053153992, train/raw-loss = 0.6299921870231628, train/logprobs = tensor([[-1.6676, -2.1823],
        [-1.7658, -1.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011791979894042015
Epoch 0, Step 341: train/loss = 0.6982572078704834, train/raw-loss = 0.6937828063964844, train/logprobs = tensor([[-1.6897, -2.1004],
        [-1.8146, -2.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04474319517612457
Epoch 0, Step 342: train/loss = 0.6362178325653076, train/raw-loss = 0.6354098320007324, train/logprobs = tensor([[-1.2034, -1.6897],
        [-1.3161, -1.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0080801323056221
Epoch 0, Step 343: train/loss = 0.6672030687332153, train/raw-loss = 0.6665935516357422, train/logprobs = tensor([[-0.8433, -1.9232],
        [-0.9405, -1.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006095483899116516
Epoch 0, Step 344: train/loss = 0.6899220943450928, train/raw-loss = 0.689352810382843, train/logprobs = tensor([[-1.3919, -1.7253],
        [-1.4294, -1.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005692369770258665
Epoch 0, Step 345: train/loss = 0.6685473918914795, train/raw-loss = 0.6674351096153259, train/logprobs = tensor([[-1.2479, -1.4205],
        [-1.3120, -1.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011122421361505985
Epoch 0, Step 346: train/loss = 0.6553508043289185, train/raw-loss = 0.654606819152832, train/logprobs = tensor([[-1.1469, -2.3464],
        [-1.2601, -2.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007440255954861641
Epoch 0, Step 347: train/loss = 0.6794372797012329, train/raw-loss = 0.6786487102508545, train/logprobs = tensor([[-1.4708, -1.7626],
        [-1.4749, -1.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007886120118200779
Epoch 0, Step 348: train/loss = 0.6453217267990112, train/raw-loss = 0.6444458365440369, train/logprobs = tensor([[-1.0755, -1.5919],
        [-1.2705, -1.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008759170770645142
Epoch 0, Step 349: train/loss = 0.6591116189956665, train/raw-loss = 0.6586399078369141, train/logprobs = tensor([[-1.0580, -1.7755],
        [-1.1976, -1.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004716846626251936
Epoch 0, Step 350: train/loss = 0.6344187259674072, train/raw-loss = 0.6337571144104004, train/logprobs = tensor([[-0.8530, -3.2422],
        [-0.9696, -2.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006616781000047922
Epoch 0, Step 351: train/loss = 0.6459195613861084, train/raw-loss = 0.6451180577278137, train/logprobs = tensor([[-1.0543, -2.5734],
        [-1.2076, -2.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008015144616365433
Epoch 0, Step 352: train/loss = 0.5741595029830933, train/raw-loss = 0.5733308792114258, train/logprobs = tensor([[-1.1972, -2.6422],
        [-1.2695, -2.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008286060765385628
Epoch 0, Step 353: train/loss = 0.5564618110656738, train/raw-loss = 0.5546876192092896, train/logprobs = tensor([[-1.3931, -2.0512],
        [-1.4830, -1.4964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017741359770298004
Epoch 0, Step 354: train/loss = 0.5568601489067078, train/raw-loss = 0.5557520389556885, train/logprobs = tensor([[-0.7999, -3.5516],
        [-0.8568, -2.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01108096819370985
Epoch 0, Step 355: train/loss = 0.659394383430481, train/raw-loss = 0.659196138381958, train/logprobs = tensor([[-0.8540, -1.7186],
        [-0.9007, -1.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019823953043669462
Epoch 0, Step 356: train/loss = 0.6417694091796875, train/raw-loss = 0.6414272785186768, train/logprobs = tensor([[-1.1056, -1.3984],
        [-1.0906, -1.1621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034217024222016335
Epoch 0, Step 357: train/loss = 0.5420411825180054, train/raw-loss = 0.5401843786239624, train/logprobs = tensor([[-0.8403, -2.8120],
        [-0.8954, -2.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018568115308880806
Epoch 0, Step 358: train/loss = 0.6040375232696533, train/raw-loss = 0.6031109094619751, train/logprobs = tensor([[-1.3085, -2.2331],
        [-1.3768, -1.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009266400709748268
Epoch 0, Step 359: train/loss = 0.5673799514770508, train/raw-loss = 0.5666949152946472, train/logprobs = tensor([[-0.8601, -2.6110],
        [-0.9576, -2.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006850489415228367
Epoch 0, Step 360: train/loss = 0.5739493370056152, train/raw-loss = 0.572396993637085, train/logprobs = tensor([[-0.7853, -3.3190],
        [-0.8780, -2.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015523076988756657
Epoch 0, Step 361: train/loss = 0.582383394241333, train/raw-loss = 0.5815984010696411, train/logprobs = tensor([[-0.7243, -2.7006],
        [-0.7947, -2.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007850239053368568
Epoch 0, Step 362: train/loss = 0.6014195680618286, train/raw-loss = 0.6000180244445801, train/logprobs = tensor([[-1.4848, -1.7605],
        [-1.6939, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014014837332069874
Epoch 0, Step 363: train/loss = 0.601511538028717, train/raw-loss = 0.6007934808731079, train/logprobs = tensor([[-1.2848, -2.2044],
        [-1.4357, -1.9511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007180133368819952
Epoch 0, Step 364: train/loss = 0.5798398852348328, train/raw-loss = 0.5786343216896057, train/logprobs = tensor([[-0.9516, -1.8747],
        [-1.1185, -1.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012055832892656326
Epoch 0, Step 365: train/loss = 0.5625025033950806, train/raw-loss = 0.560876190662384, train/logprobs = tensor([[-1.3177, -1.7490],
        [-1.4164, -1.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016263706609606743
Epoch 0, Step 366: train/loss = 0.6054041385650635, train/raw-loss = 0.6041828393936157, train/logprobs = tensor([[-1.3000, -1.7946],
        [-1.3842, -1.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012213197536766529
Epoch 0, Step 367: train/loss = 0.597973644733429, train/raw-loss = 0.5973236560821533, train/logprobs = tensor([[-1.1090, -1.7424],
        [-1.1932, -1.4154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006500352639704943
Epoch 0, Step 368: train/loss = 0.587016224861145, train/raw-loss = 0.5850383043289185, train/logprobs = tensor([[-1.3221, -2.4276],
        [-1.4536, -2.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019779004156589508
Epoch 0, Step 369: train/loss = 0.5595112442970276, train/raw-loss = 0.557553768157959, train/logprobs = tensor([[-1.1619, -1.8798],
        [-1.2370, -1.2843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019574495032429695
Epoch 0, Step 370: train/loss = 0.5532682538032532, train/raw-loss = 0.5518599152565002, train/logprobs = tensor([[-1.0414, -2.3887],
        [-1.0855, -1.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014083228074014187
Epoch 0, Step 371: train/loss = 0.637083888053894, train/raw-loss = 0.6364284753799438, train/logprobs = tensor([[-0.5695, -1.1127],
        [-0.7064, -0.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006554114632308483
Epoch 0, Step 372: train/loss = 0.6309727430343628, train/raw-loss = 0.6302135586738586, train/logprobs = tensor([[-1.1226, -2.0720],
        [-1.2205, -1.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007592177949845791
Epoch 0, Step 373: train/loss = 0.5948396921157837, train/raw-loss = 0.5937978029251099, train/logprobs = tensor([[-1.1243, -2.7764],
        [-1.1348, -2.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010418672114610672
Epoch 0, Step 374: train/loss = 0.643287718296051, train/raw-loss = 0.6425834894180298, train/logprobs = tensor([[-0.7965, -1.1602],
        [-0.9085, -1.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0070424191653728485
Epoch 0, Step 375: train/loss = 0.6250820159912109, train/raw-loss = 0.6245609521865845, train/logprobs = tensor([[-1.1180, -1.7111],
        [-1.2801, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005210085306316614
Epoch 0, Step 376: train/loss = 0.6492448449134827, train/raw-loss = 0.6479980945587158, train/logprobs = tensor([[-1.4818, -1.8221],
        [-1.4256, -1.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01246737688779831
Epoch 0, Step 377: train/loss = 0.6648693084716797, train/raw-loss = 0.6647871732711792, train/logprobs = tensor([[-0.6591, -0.8227],
        [-0.7231, -0.7697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000821587280370295
Epoch 0, Step 378: train/loss = 0.6758080720901489, train/raw-loss = 0.674147367477417, train/logprobs = tensor([[-2.0134, -1.8457],
        [-1.9789, -1.6586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01660732552409172
Epoch 0, Step 379: train/loss = 0.5747502446174622, train/raw-loss = 0.5711312294006348, train/logprobs = tensor([[-1.9717, -2.9323],
        [-1.8387, -2.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03619002923369408
Epoch 0, Step 380: train/loss = 0.5987144708633423, train/raw-loss = 0.5977944731712341, train/logprobs = tensor([[-1.0200, -1.8040],
        [-1.0858, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009200111031532288
Epoch 0, Step 381: train/loss = 0.5559008121490479, train/raw-loss = 0.5536227822303772, train/logprobs = tensor([[-0.9953, -2.2928],
        [-1.0425, -1.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022779837250709534
Epoch 0, Step 382: train/loss = 0.6286909580230713, train/raw-loss = 0.6279289722442627, train/logprobs = tensor([[-1.1495, -1.8148],
        [-1.0785, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007619298528879881
Epoch 0, Step 383: train/loss = 0.6330714225769043, train/raw-loss = 0.6326823234558105, train/logprobs = tensor([[-2.1020, -2.3339],
        [-1.8990, -1.8731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038908664137125015
Epoch 0, Step 384: train/loss = 0.5729581713676453, train/raw-loss = 0.5719610452651978, train/logprobs = tensor([[-0.9117, -2.0445],
        [-1.0452, -1.6414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00997073296457529
Epoch 0, Step 385: train/loss = 0.6368408203125, train/raw-loss = 0.6357905864715576, train/logprobs = tensor([[-1.5768, -1.9021],
        [-1.5510, -1.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010502414777874947
Epoch 0, Step 386: train/loss = 0.5805709958076477, train/raw-loss = 0.5796105265617371, train/logprobs = tensor([[-1.4469, -2.3244],
        [-1.3855, -1.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009604819118976593
Epoch 0, Step 387: train/loss = 0.5560609102249146, train/raw-loss = 0.5541198253631592, train/logprobs = tensor([[-1.3775, -2.2314],
        [-1.2835, -1.4959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019411258399486542
Epoch 0, Step 388: train/loss = 0.6219474077224731, train/raw-loss = 0.6209363341331482, train/logprobs = tensor([[-0.9700, -1.3040],
        [-0.8737, -0.8761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01011039037257433
Epoch 0, Step 389: train/loss = 0.6181418895721436, train/raw-loss = 0.6179240942001343, train/logprobs = tensor([[-0.8445, -1.7245],
        [-0.8145, -1.3648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021784561686217785
Epoch 0, Step 390: train/loss = 0.5104581117630005, train/raw-loss = 0.5075181126594543, train/logprobs = tensor([[-1.2680, -2.5901],
        [-1.2105, -1.6490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029399700462818146
Epoch 0, Step 391: train/loss = 0.6002724170684814, train/raw-loss = 0.5994044542312622, train/logprobs = tensor([[-1.7270, -2.2885],
        [-1.2847, -1.4219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008679164573550224
Epoch 0, Step 392: train/loss = 0.5336464047431946, train/raw-loss = 0.5302960276603699, train/logprobs = tensor([[-1.2564, -2.3793],
        [-1.3521, -1.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03350371494889259
Epoch 0, Step 393: train/loss = 0.5805994868278503, train/raw-loss = 0.5793060064315796, train/logprobs = tensor([[-1.6076, -2.5235],
        [-1.5626, -1.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01293505635112524
Epoch 0, Step 394: train/loss = 0.5375688672065735, train/raw-loss = 0.5358990430831909, train/logprobs = tensor([[-1.3969, -2.7139],
        [-1.1729, -1.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016698161140084267
Epoch 0, Step 395: train/loss = 0.6189814805984497, train/raw-loss = 0.6181460618972778, train/logprobs = tensor([[-1.1312, -1.9050],
        [-1.1216, -1.5572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008354240097105503
Epoch 0, Step 396: train/loss = 0.48892998695373535, train/raw-loss = 0.4845537543296814, train/logprobs = tensor([[-0.9734, -2.7574],
        [-0.9894, -1.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04376213625073433
Epoch 0, Step 397: train/loss = 0.6308240294456482, train/raw-loss = 0.6299629211425781, train/logprobs = tensor([[-1.7818, -1.6632],
        [-1.4507, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008611503057181835
Epoch 0, Step 398: train/loss = 0.5217223763465881, train/raw-loss = 0.5186229348182678, train/logprobs = tensor([[-1.1413, -2.5123],
        [-1.1574, -1.6729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030994534492492676
Epoch 0, Step 399: train/loss = 0.5798041820526123, train/raw-loss = 0.5787941813468933, train/logprobs = tensor([[-1.4121, -2.1606],
        [-1.3343, -1.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010100046172738075
Epoch 0, Step 400: train/loss = 0.6099679470062256, train/raw-loss = 0.6084821224212646, train/logprobs = tensor([[-1.8032, -2.0364],
        [-1.6893, -1.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01485791802406311
Epoch 0, Step 401: train/loss = 0.4805932641029358, train/raw-loss = 0.47751638293266296, train/logprobs = tensor([[-1.3443, -2.5875],
        [-1.2944, -1.5226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03076891228556633
Epoch 0, Step 402: train/loss = 0.583888053894043, train/raw-loss = 0.583018958568573, train/logprobs = tensor([[-1.1824, -2.0027],
        [-1.1038, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008691190741956234
Epoch 0, Step 403: train/loss = 0.5201581120491028, train/raw-loss = 0.518046498298645, train/logprobs = tensor([[-1.5411, -2.1789],
        [-1.7028, -1.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02111593261361122
Epoch 0, Step 404: train/loss = 0.586930513381958, train/raw-loss = 0.5860276222229004, train/logprobs = tensor([[-1.2994, -2.3791],
        [-1.3008, -1.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009029011242091656
Epoch 0, Step 405: train/loss = 0.6249800324440002, train/raw-loss = 0.624335765838623, train/logprobs = tensor([[-0.8235, -1.7206],
        [-0.8307, -1.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006443405989557505
Epoch 0, Step 406: train/loss = 0.517317533493042, train/raw-loss = 0.5147194266319275, train/logprobs = tensor([[-1.4706, -2.4747],
        [-1.5127, -1.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02598075568675995
Epoch 0, Step 407: train/loss = 0.6127995252609253, train/raw-loss = 0.6118178367614746, train/logprobs = tensor([[-1.2959, -2.5892],
        [-1.2607, -2.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009816407226026058
Epoch 0, Step 408: train/loss = 0.607650876045227, train/raw-loss = 0.6065459251403809, train/logprobs = tensor([[-1.4893, -1.7627],
        [-1.4078, -1.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011049509048461914
Epoch 0, Step 409: train/loss = 0.5391606092453003, train/raw-loss = 0.5375562906265259, train/logprobs = tensor([[-0.8612, -2.2090],
        [-0.8687, -1.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016042739152908325
Epoch 0, Step 410: train/loss = 0.5563147068023682, train/raw-loss = 0.5549036860466003, train/logprobs = tensor([[-1.1206, -2.0273],
        [-1.0286, -1.3145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014110518619418144
Epoch 0, Step 411: train/loss = 0.684847354888916, train/raw-loss = 0.6848156452178955, train/logprobs = tensor([[-1.5170, -1.4425],
        [-1.1913, -1.0822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003164900990668684
Epoch 0, Step 412: train/loss = 0.6005786657333374, train/raw-loss = 0.5995797514915466, train/logprobs = tensor([[-1.1007, -1.8606],
        [-1.3428, -1.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00998913124203682
Epoch 0, Step 413: train/loss = 0.6587865948677063, train/raw-loss = 0.6577966809272766, train/logprobs = tensor([[-1.5613, -1.1859],
        [-1.4487, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009899181313812733
Epoch 0, Step 414: train/loss = 0.643348753452301, train/raw-loss = 0.641942024230957, train/logprobs = tensor([[-1.1892, -1.4585],
        [-1.0526, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014067726209759712
Epoch 0, Step 415: train/loss = 0.52372145652771, train/raw-loss = 0.522490382194519, train/logprobs = tensor([[-0.7360, -2.7580],
        [-0.7006, -1.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012310449033975601
Epoch 0, Step 416: train/loss = 0.5109289884567261, train/raw-loss = 0.5089173316955566, train/logprobs = tensor([[-1.0281, -2.4791],
        [-1.0456, -1.6339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020116083323955536
Epoch 0, Step 417: train/loss = 0.4387727379798889, train/raw-loss = 0.43631577491760254, train/logprobs = tensor([[-1.0909, -3.9691],
        [-1.1866, -2.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024569867178797722
Epoch 0, Step 418: train/loss = 0.5993839502334595, train/raw-loss = 0.5983051061630249, train/logprobs = tensor([[-1.6134, -2.1158],
        [-1.4255, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010788392275571823
Epoch 0, Step 419: train/loss = 0.5970076322555542, train/raw-loss = 0.5949655771255493, train/logprobs = tensor([[-2.2711, -2.8201],
        [-1.7649, -1.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020420994609594345
Epoch 0, Step 420: train/loss = 0.4783504903316498, train/raw-loss = 0.4751027822494507, train/logprobs = tensor([[-1.2363, -2.8394],
        [-1.3844, -1.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03247692808508873
Epoch 0, Step 421: train/loss = 0.564234733581543, train/raw-loss = 0.5624420642852783, train/logprobs = tensor([[-0.7427, -2.0531],
        [-0.7458, -1.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017926819622516632
Epoch 0, Step 422: train/loss = 0.5309545993804932, train/raw-loss = 0.5289186239242554, train/logprobs = tensor([[-1.1445, -1.9491],
        [-1.1835, -1.2415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02036008983850479
Epoch 0, Step 423: train/loss = 0.5269044637680054, train/raw-loss = 0.5246200561523438, train/logprobs = tensor([[-1.5347, -1.9723],
        [-1.5969, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02284400537610054
Epoch 0, Step 424: train/loss = 0.49642065167427063, train/raw-loss = 0.4924614429473877, train/logprobs = tensor([[-0.8556, -2.2535],
        [-0.8905, -1.2282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03959208354353905
Epoch 0, Step 425: train/loss = 0.4483829736709595, train/raw-loss = 0.44600293040275574, train/logprobs = tensor([[-1.2292, -3.2537],
        [-1.2471, -2.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023800581693649292
Epoch 0, Step 426: train/loss = 0.5202430486679077, train/raw-loss = 0.5179526805877686, train/logprobs = tensor([[-1.4852, -2.0326],
        [-1.4812, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02290390059351921
Epoch 0, Step 427: train/loss = 0.6489897966384888, train/raw-loss = 0.6485082507133484, train/logprobs = tensor([[-0.8832, -1.3243],
        [-0.9634, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004815008025616407
Epoch 0, Step 428: train/loss = 0.5273839831352234, train/raw-loss = 0.5245635509490967, train/logprobs = tensor([[-1.5518, -2.1057],
        [-1.5923, -1.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02820470929145813
Epoch 0, Step 429: train/loss = 0.6419609785079956, train/raw-loss = 0.6413829326629639, train/logprobs = tensor([[-1.0624, -1.1529],
        [-1.0434, -0.8995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005780719220638275
Epoch 0, Step 430: train/loss = 0.5262953042984009, train/raw-loss = 0.524418830871582, train/logprobs = tensor([[-1.2971, -2.9912],
        [-1.0136, -1.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018764913082122803
Epoch 0, Step 431: train/loss = 0.5244049429893494, train/raw-loss = 0.5231708288192749, train/logprobs = tensor([[-1.7456, -2.8553],
        [-1.6186, -1.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012341205030679703
Epoch 0, Step 432: train/loss = 0.6246289014816284, train/raw-loss = 0.6236504316329956, train/logprobs = tensor([[-1.0983, -1.6054],
        [-1.2238, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009784761816263199
Epoch 0, Step 433: train/loss = 0.5025431513786316, train/raw-loss = 0.49976813793182373, train/logprobs = tensor([[-1.5288, -2.9972],
        [-1.5655, -2.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027750227600336075
Epoch 0, Step 434: train/loss = 0.5166314840316772, train/raw-loss = 0.5148506164550781, train/logprobs = tensor([[-1.2148, -2.6964],
        [-1.5151, -2.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017808087170124054
Epoch 0, Step 435: train/loss = 0.6163808107376099, train/raw-loss = 0.6155774593353271, train/logprobs = tensor([[-1.5562, -1.8649],
        [-1.6193, -1.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008033881895244122
Epoch 0, Step 436: train/loss = 0.5218538045883179, train/raw-loss = 0.519050121307373, train/logprobs = tensor([[-1.2709, -1.8908],
        [-1.3003, -1.0707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028036825358867645
Epoch 0, Step 437: train/loss = 0.47790926694869995, train/raw-loss = 0.47506481409072876, train/logprobs = tensor([[-0.9628, -2.3464],
        [-1.1664, -1.5262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028444446623325348
Epoch 0, Step 438: train/loss = 0.6116999387741089, train/raw-loss = 0.6098724603652954, train/logprobs = tensor([[-1.5492, -2.2658],
        [-1.2392, -1.5222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018275370821356773
Epoch 0, Step 439: train/loss = 0.5334901809692383, train/raw-loss = 0.5315516591072083, train/logprobs = tensor([[-1.1910, -2.1291],
        [-1.3175, -1.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01938491314649582
Epoch 0, Step 440: train/loss = 0.5927594304084778, train/raw-loss = 0.5917311906814575, train/logprobs = tensor([[-1.9360, -2.1344],
        [-1.6460, -1.3969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01028283778578043
Epoch 0, Step 441: train/loss = 0.4732288420200348, train/raw-loss = 0.4694632887840271, train/logprobs = tensor([[-1.1901, -3.2098],
        [-1.2518, -2.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037655480206012726
Epoch 0, Step 442: train/loss = 0.5854911804199219, train/raw-loss = 0.5757348537445068, train/logprobs = tensor([[-1.8217, -1.8275],
        [-1.8283, -0.9972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09756310284137726
Epoch 0, Step 443: train/loss = 0.4913592040538788, train/raw-loss = 0.48881223797798157, train/logprobs = tensor([[-1.4168, -2.7086],
        [-1.5548, -1.8530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02546953782439232
Epoch 0, Step 444: train/loss = 0.5808959603309631, train/raw-loss = 0.5799123048782349, train/logprobs = tensor([[-0.9569, -2.1369],
        [-0.9875, -1.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009836152195930481
Epoch 0, Step 445: train/loss = 0.5841823816299438, train/raw-loss = 0.5820885896682739, train/logprobs = tensor([[-1.7993, -1.8675],
        [-1.7407, -1.2357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020937498658895493
Epoch 0, Step 446: train/loss = 0.500840961933136, train/raw-loss = 0.49907100200653076, train/logprobs = tensor([[-1.3346, -3.0590],
        [-1.1873, -2.0005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01769966259598732
Epoch 0, Step 447: train/loss = 0.4203183352947235, train/raw-loss = 0.41475725173950195, train/logprobs = tensor([[-1.1040, -2.8005],
        [-1.2568, -1.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055610623210668564
Epoch 0, Step 448: train/loss = 0.47320881485939026, train/raw-loss = 0.46672749519348145, train/logprobs = tensor([[-1.3879, -2.4900],
        [-1.2014, -1.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06481297314167023
Epoch 0, Step 449: train/loss = 0.6137666702270508, train/raw-loss = 0.6130068302154541, train/logprobs = tensor([[-1.5570, -1.5482],
        [-1.3822, -1.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007598229683935642
Epoch 0, Step 450: train/loss = 0.4988805055618286, train/raw-loss = 0.49591678380966187, train/logprobs = tensor([[-0.6505, -2.1322],
        [-0.7615, -1.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029637103900313377
Epoch 0, Step 451: train/loss = 0.5627380013465881, train/raw-loss = 0.5600013136863708, train/logprobs = tensor([[-2.1187, -2.4895],
        [-1.8674, -1.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02736680954694748
Epoch 0, Step 452: train/loss = 0.4768698811531067, train/raw-loss = 0.4723026752471924, train/logprobs = tensor([[-1.3283, -2.2109],
        [-1.5159, -1.2839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045672085136175156
Epoch 0, Step 453: train/loss = 0.5391496419906616, train/raw-loss = 0.5363435745239258, train/logprobs = tensor([[-0.9407, -2.0245],
        [-1.1253, -1.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02806062065064907
Epoch 0, Step 454: train/loss = 0.5369718670845032, train/raw-loss = 0.5344985127449036, train/logprobs = tensor([[-1.6537, -2.0922],
        [-1.6508, -1.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024733420461416245
Epoch 0, Step 455: train/loss = 0.4487527012825012, train/raw-loss = 0.44507429003715515, train/logprobs = tensor([[-0.8514, -2.1793],
        [-0.9360, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0367840975522995
Epoch 0, Step 456: train/loss = 0.4939502477645874, train/raw-loss = 0.4906512200832367, train/logprobs = tensor([[-0.8655, -2.1831],
        [-0.9328, -1.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299044072628021
Epoch 0, Step 457: train/loss = 0.5446977615356445, train/raw-loss = 0.5399557948112488, train/logprobs = tensor([[-0.7278, -1.6458],
        [-0.8661, -0.9682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04741940274834633
Epoch 0, Step 458: train/loss = 0.626309871673584, train/raw-loss = 0.6253726482391357, train/logprobs = tensor([[-1.5456, -1.9280],
        [-1.3010, -1.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009372039698064327
Epoch 0, Step 459: train/loss = 0.5475594401359558, train/raw-loss = 0.5462287664413452, train/logprobs = tensor([[-0.8953, -2.0680],
        [-1.0645, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013306969776749611
Epoch 0, Step 460: train/loss = 0.5814840793609619, train/raw-loss = 0.5780578851699829, train/logprobs = tensor([[-0.8331, -1.5218],
        [-1.0712, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0342620350420475
Epoch 0, Step 461: train/loss = 0.661927342414856, train/raw-loss = 0.660286545753479, train/logprobs = tensor([[-1.6581, -1.6704],
        [-1.3440, -1.1385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016408350318670273
Epoch 0, Step 462: train/loss = 0.4525633156299591, train/raw-loss = 0.44890546798706055, train/logprobs = tensor([[-0.9281, -2.7580],
        [-1.0311, -1.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03657851368188858
Epoch 0, Step 463: train/loss = 0.505682110786438, train/raw-loss = 0.5025526285171509, train/logprobs = tensor([[-0.8480, -1.9144],
        [-1.0642, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031294744461774826
Epoch 0, Step 464: train/loss = 0.4787546992301941, train/raw-loss = 0.4742790460586548, train/logprobs = tensor([[-1.0235, -3.1790],
        [-1.1683, -2.1687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0447562113404274
Epoch 0, Step 465: train/loss = 0.6332319974899292, train/raw-loss = 0.6316311955451965, train/logprobs = tensor([[-1.0324, -1.3372],
        [-1.1553, -1.1472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016008300706744194
Epoch 0, Step 466: train/loss = 0.47842714190483093, train/raw-loss = 0.47397908568382263, train/logprobs = tensor([[-1.4950, -2.4522],
        [-1.6480, -1.5364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04448074847459793
Epoch 0, Step 467: train/loss = 0.5989848971366882, train/raw-loss = 0.5979832410812378, train/logprobs = tensor([[-1.6086, -1.9020],
        [-1.3649, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010016568005084991
Epoch 0, Step 468: train/loss = 0.5806580185890198, train/raw-loss = 0.5792139172554016, train/logprobs = tensor([[-1.2442, -1.9659],
        [-1.1671, -1.3688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01444090437144041
Epoch 0, Step 469: train/loss = 0.5772927403450012, train/raw-loss = 0.5758269429206848, train/logprobs = tensor([[-1.0085, -1.5427],
        [-1.0700, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014657676219940186
Epoch 0, Step 470: train/loss = 0.4892825484275818, train/raw-loss = 0.48740673065185547, train/logprobs = tensor([[-0.9658, -2.7787],
        [-0.9680, -1.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0187583826482296
Epoch 0, Step 471: train/loss = 0.49167221784591675, train/raw-loss = 0.4884245991706848, train/logprobs = tensor([[-1.1662, -2.5327],
        [-1.1795, -1.5405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0324765145778656
Epoch 0, Step 472: train/loss = 0.329440176486969, train/raw-loss = 0.3174930512905121, train/logprobs = tensor([[-1.6466, -4.9402],
        [-1.7442, -2.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1194714829325676
Epoch 0, Step 473: train/loss = 0.5585042238235474, train/raw-loss = 0.555657148361206, train/logprobs = tensor([[-1.6718, -2.1055],
        [-1.3245, -1.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028471166267991066
Epoch 0, Step 474: train/loss = 0.44880133867263794, train/raw-loss = 0.44501715898513794, train/logprobs = tensor([[-0.7732, -2.5378],
        [-0.8891, -1.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037842199206352234
Epoch 0, Step 475: train/loss = 0.44410717487335205, train/raw-loss = 0.43906909227371216, train/logprobs = tensor([[-0.9758, -2.4193],
        [-1.1128, -1.3032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05038062855601311
Epoch 0, Step 476: train/loss = 0.6522483229637146, train/raw-loss = 0.65119469165802, train/logprobs = tensor([[-1.4648, -1.6407],
        [-1.1555, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010536476038396358
Epoch 0, Step 477: train/loss = 0.5459080338478088, train/raw-loss = 0.5412685871124268, train/logprobs = tensor([[-1.7526, -1.9864],
        [-1.8370, -1.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046393636614084244
Epoch 0, Step 478: train/loss = 0.5881505012512207, train/raw-loss = 0.5853480100631714, train/logprobs = tensor([[-1.7522, -2.0048],
        [-1.6802, -1.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028024818748235703
Epoch 0, Step 479: train/loss = 0.5145748257637024, train/raw-loss = 0.5123778581619263, train/logprobs = tensor([[-1.5665, -2.7565],
        [-1.3355, -1.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021969709545373917
Epoch 0, Step 480: train/loss = 0.5838251113891602, train/raw-loss = 0.5803393125534058, train/logprobs = tensor([[-1.1483, -1.7747],
        [-1.2864, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034858256578445435
Epoch 0, Step 481: train/loss = 0.5796521306037903, train/raw-loss = 0.576239824295044, train/logprobs = tensor([[-1.3990, -1.4902],
        [-1.5596, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03412346914410591
Epoch 0, Step 482: train/loss = 0.5402766466140747, train/raw-loss = 0.5369982123374939, train/logprobs = tensor([[-1.1211, -2.5854],
        [-1.2042, -1.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03278462216258049
Epoch 0, Step 483: train/loss = 0.5088130831718445, train/raw-loss = 0.5040639638900757, train/logprobs = tensor([[-1.5342, -2.3924],
        [-1.5701, -1.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04749094322323799
Epoch 0, Step 484: train/loss = 0.5034075379371643, train/raw-loss = 0.4995696544647217, train/logprobs = tensor([[-1.1979, -3.0821],
        [-1.3864, -2.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03837877884507179
Epoch 0, Step 485: train/loss = 0.5820722579956055, train/raw-loss = 0.5794399976730347, train/logprobs = tensor([[-1.4268, -1.7647],
        [-1.4240, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026323016732931137
Epoch 0, Step 486: train/loss = 0.6137697696685791, train/raw-loss = 0.6131298542022705, train/logprobs = tensor([[-0.7407, -1.2668],
        [-0.9510, -1.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0063997479155659676
Epoch 0, Step 487: train/loss = 0.42579782009124756, train/raw-loss = 0.4237155020236969, train/logprobs = tensor([[-1.1338, -3.9115],
        [-1.1112, -2.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020823325961828232
Epoch 0, Step 488: train/loss = 0.7137762904167175, train/raw-loss = 0.7110592126846313, train/logprobs = tensor([[-1.8718, -2.2677],
        [-1.6088, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02717088907957077
Epoch 0, Step 489: train/loss = 0.5385007262229919, train/raw-loss = 0.5350965261459351, train/logprobs = tensor([[-1.3803, -2.0777],
        [-1.3427, -1.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03404226154088974
Epoch 0, Step 490: train/loss = 0.6598303318023682, train/raw-loss = 0.6597860455513, train/logprobs = tensor([[-0.6957, -1.5863],
        [-0.7840, -1.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044287816854193807
Epoch 0, Step 491: train/loss = 0.5041323900222778, train/raw-loss = 0.5001869797706604, train/logprobs = tensor([[-1.2328, -2.2508],
        [-1.4742, -1.5441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039453938603401184
Epoch 0, Step 492: train/loss = 0.46038389205932617, train/raw-loss = 0.45423537492752075, train/logprobs = tensor([[-0.6660, -2.4912],
        [-0.8700, -1.3966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06148497387766838
Epoch 0, Step 493: train/loss = 0.5400033593177795, train/raw-loss = 0.5371546149253845, train/logprobs = tensor([[-1.2982, -2.2047],
        [-1.1455, -1.3103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028487814590334892
Epoch 0, Step 494: train/loss = 0.6372500658035278, train/raw-loss = 0.6365900039672852, train/logprobs = tensor([[-1.6013, -1.5033],
        [-1.4956, -1.1442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006600922904908657
Epoch 0, Step 495: train/loss = 0.6029986143112183, train/raw-loss = 0.6005350351333618, train/logprobs = tensor([[-2.0611, -2.6548],
        [-1.9118, -2.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02463609352707863
Epoch 0, Step 496: train/loss = 0.5635131001472473, train/raw-loss = 0.5534610152244568, train/logprobs = tensor([[-1.4982, -2.3476],
        [-1.6586, -1.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10052132606506348
Epoch 0, Step 497: train/loss = 0.44203636050224304, train/raw-loss = 0.4355211555957794, train/logprobs = tensor([[-1.1096, -3.0624],
        [-1.3334, -1.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06515216082334518
Epoch 0, Step 498: train/loss = 0.6551433205604553, train/raw-loss = 0.649560809135437, train/logprobs = tensor([[-1.6930, -2.5404],
        [-1.5499, -1.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05582575127482414
Epoch 0, Step 499: train/loss = 0.5476859211921692, train/raw-loss = 0.5457680821418762, train/logprobs = tensor([[-0.9541, -2.5911],
        [-1.0964, -2.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01917841285467148
eval/loss: 0.5331140756607056
Epoch 0, Step 500: train/loss = 0.678257942199707, train/raw-loss = 0.6665858030319214, train/logprobs = tensor([[-1.2263, -2.0302],
        [-1.3190, -1.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11672160029411316
Epoch 0, Step 501: train/loss = 0.49715983867645264, train/raw-loss = 0.4943998157978058, train/logprobs = tensor([[-1.3137, -2.4206],
        [-1.3821, -1.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027600424364209175
Epoch 0, Step 502: train/loss = 0.47323131561279297, train/raw-loss = 0.4693763256072998, train/logprobs = tensor([[-0.9092, -2.7386],
        [-1.0158, -1.7251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03854995220899582
Epoch 0, Step 503: train/loss = 0.4999932646751404, train/raw-loss = 0.49088001251220703, train/logprobs = tensor([[-1.5353, -2.8248],
        [-1.4007, -1.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09113284945487976
Epoch 0, Step 504: train/loss = 0.6434726119041443, train/raw-loss = 0.6430258750915527, train/logprobs = tensor([[-1.2817, -1.5430],
        [-1.1483, -1.1912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004467384424060583
Epoch 0, Step 505: train/loss = 0.527527928352356, train/raw-loss = 0.5222905278205872, train/logprobs = tensor([[-1.2725, -2.0515],
        [-1.3878, -1.2617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052373625338077545
Epoch 0, Step 506: train/loss = 0.5275853276252747, train/raw-loss = 0.5219804048538208, train/logprobs = tensor([[-1.1015, -2.3225],
        [-1.2449, -1.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056049805134534836
Epoch 0, Step 507: train/loss = 0.428430438041687, train/raw-loss = 0.4216281771659851, train/logprobs = tensor([[-1.0781, -2.5640],
        [-1.2854, -1.3842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06802210211753845
Epoch 0, Step 508: train/loss = 0.47274360060691833, train/raw-loss = 0.46859246492385864, train/logprobs = tensor([[-0.8458, -2.3146],
        [-1.1812, -1.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04151210933923721
Epoch 0, Step 509: train/loss = 0.49330878257751465, train/raw-loss = 0.4878205358982086, train/logprobs = tensor([[-1.4693, -2.2763],
        [-1.2279, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054882608354091644
Epoch 0, Step 510: train/loss = 0.49478986859321594, train/raw-loss = 0.49149197340011597, train/logprobs = tensor([[-0.9091, -2.4878],
        [-1.0750, -1.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03297892212867737
Epoch 0, Step 511: train/loss = 0.4169576168060303, train/raw-loss = 0.4098823666572571, train/logprobs = tensor([[-0.9612, -2.7211],
        [-0.9988, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0707528293132782
Epoch 0, Step 512: train/loss = 0.41048771142959595, train/raw-loss = 0.4035285711288452, train/logprobs = tensor([[-0.6763, -2.6148],
        [-0.8867, -1.2563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06959106028079987
Epoch 0, Step 513: train/loss = 0.42968428134918213, train/raw-loss = 0.4246557354927063, train/logprobs = tensor([[-1.5121, -2.4101],
        [-1.6682, -1.2591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050285760313272476
Epoch 0, Step 514: train/loss = 0.6521140933036804, train/raw-loss = 0.6406717300415039, train/logprobs = tensor([[-2.0563, -2.2417],
        [-1.9923, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11442296206951141
Epoch 0, Step 515: train/loss = 0.4816517233848572, train/raw-loss = 0.4774673879146576, train/logprobs = tensor([[-0.8847, -2.8628],
        [-1.1043, -1.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04184336960315704
Epoch 0, Step 516: train/loss = 0.6246349215507507, train/raw-loss = 0.6203161478042603, train/logprobs = tensor([[-2.3283, -2.9531],
        [-1.6782, -1.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04318779334425926
Epoch 0, Step 517: train/loss = 0.5460644960403442, train/raw-loss = 0.5442960858345032, train/logprobs = tensor([[-0.8356, -2.0769],
        [-1.0441, -1.5183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01768452301621437
Epoch 0, Step 518: train/loss = 0.45618125796318054, train/raw-loss = 0.45169883966445923, train/logprobs = tensor([[-1.3253, -2.4701],
        [-1.5204, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04482413828372955
Epoch 0, Step 519: train/loss = 0.47209638357162476, train/raw-loss = 0.46754899621009827, train/logprobs = tensor([[-0.8415, -2.4459],
        [-1.1434, -1.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04547411948442459
Epoch 0, Step 520: train/loss = 0.4843401610851288, train/raw-loss = 0.4797980487346649, train/logprobs = tensor([[-1.2880, -2.9219],
        [-1.2614, -1.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045421067625284195
Epoch 0, Step 521: train/loss = 0.42315515875816345, train/raw-loss = 0.4136808514595032, train/logprobs = tensor([[-1.3839, -2.9921],
        [-1.6197, -1.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474331140518188
Epoch 0, Step 522: train/loss = 0.4824064373970032, train/raw-loss = 0.4778895974159241, train/logprobs = tensor([[-2.0244, -3.6363],
        [-1.8352, -2.2557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045168615877628326
Epoch 0, Step 523: train/loss = 0.6302266716957092, train/raw-loss = 0.6240890026092529, train/logprobs = tensor([[-0.8121, -1.4255],
        [-1.0596, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06137710437178612
Epoch 0, Step 524: train/loss = 0.5557011961936951, train/raw-loss = 0.5535497069358826, train/logprobs = tensor([[-1.3722, -1.6505],
        [-1.5208, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021514637395739555
Epoch 0, Step 525: train/loss = 0.5056726336479187, train/raw-loss = 0.5025566220283508, train/logprobs = tensor([[-1.4707, -2.7852],
        [-1.5216, -1.9133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031159624457359314
Epoch 0, Step 526: train/loss = 0.5053702592849731, train/raw-loss = 0.5010181665420532, train/logprobs = tensor([[-1.8615, -2.7991],
        [-1.7712, -1.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04352124035358429
Epoch 0, Step 527: train/loss = 0.36363717913627625, train/raw-loss = 0.35598692297935486, train/logprobs = tensor([[-1.0599, -3.6871],
        [-1.2125, -1.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07650268077850342
Epoch 0, Step 528: train/loss = 0.6429963707923889, train/raw-loss = 0.6422864198684692, train/logprobs = tensor([[-0.9125, -1.1902],
        [-1.2153, -1.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007099870592355728
Epoch 0, Step 529: train/loss = 0.2981070280075073, train/raw-loss = 0.2912102937698364, train/logprobs = tensor([[-0.7579, -3.9285],
        [-1.1737, -2.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06896752119064331
Epoch 0, Step 530: train/loss = 0.5817605257034302, train/raw-loss = 0.5754036903381348, train/logprobs = tensor([[-1.2766, -2.1230],
        [-1.1420, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0635688453912735
Epoch 0, Step 531: train/loss = 0.6055437922477722, train/raw-loss = 0.6024235486984253, train/logprobs = tensor([[-1.4634, -1.9794],
        [-1.3168, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03120272420346737
Epoch 0, Step 532: train/loss = 0.4912680685520172, train/raw-loss = 0.4864821434020996, train/logprobs = tensor([[-1.1119, -2.4437],
        [-1.2211, -1.4727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04785902053117752
Epoch 0, Step 533: train/loss = 0.459797739982605, train/raw-loss = 0.45559579133987427, train/logprobs = tensor([[-0.6852, -2.3573],
        [-0.8332, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0420195572078228
Epoch 0, Step 534: train/loss = 0.5978031754493713, train/raw-loss = 0.5954885482788086, train/logprobs = tensor([[-1.5503, -2.1341],
        [-1.3747, -1.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02314549684524536
Epoch 0, Step 535: train/loss = 0.548204243183136, train/raw-loss = 0.5455776453018188, train/logprobs = tensor([[-1.0620, -1.6141],
        [-1.2666, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026265835389494896
Epoch 0, Step 536: train/loss = 0.5190820097923279, train/raw-loss = 0.5140191912651062, train/logprobs = tensor([[-1.3568, -2.5086],
        [-1.4654, -1.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05062840133905411
Epoch 0, Step 537: train/loss = 0.6051514744758606, train/raw-loss = 0.6019653081893921, train/logprobs = tensor([[-1.3976, -1.8257],
        [-1.2975, -1.2163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03186165913939476
Epoch 0, Step 538: train/loss = 0.5478096008300781, train/raw-loss = 0.5426743626594543, train/logprobs = tensor([[-1.4432, -2.3160],
        [-1.5669, -1.5810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05135213956236839
Epoch 0, Step 539: train/loss = 0.507588803768158, train/raw-loss = 0.49646884202957153, train/logprobs = tensor([[-1.1559, -3.0713],
        [-1.4388, -2.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11119957268238068
Epoch 0, Step 540: train/loss = 0.5197482705116272, train/raw-loss = 0.5151004791259766, train/logprobs = tensor([[-1.2867, -2.0118],
        [-1.1809, -0.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04647787660360336
Epoch 0, Step 541: train/loss = 0.48236435651779175, train/raw-loss = 0.4794979691505432, train/logprobs = tensor([[-1.7210, -2.7224],
        [-1.8105, -1.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028663896024227142
Epoch 0, Step 542: train/loss = 0.5215134620666504, train/raw-loss = 0.5175179243087769, train/logprobs = tensor([[-1.5079, -2.6872],
        [-1.7498, -1.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03995534032583237
Epoch 0, Step 543: train/loss = 0.39019566774368286, train/raw-loss = 0.38303351402282715, train/logprobs = tensor([[-1.1957, -2.8325],
        [-1.2709, -1.3174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07162118703126907
Epoch 0, Step 544: train/loss = 0.4866885244846344, train/raw-loss = 0.4827260673046112, train/logprobs = tensor([[-0.9039, -2.0283],
        [-1.1147, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039624378085136414
Epoch 0, Step 545: train/loss = 0.5494033098220825, train/raw-loss = 0.5470515489578247, train/logprobs = tensor([[-0.6894, -1.4844],
        [-0.8580, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023518146947026253
Epoch 0, Step 546: train/loss = 0.43503761291503906, train/raw-loss = 0.42830538749694824, train/logprobs = tensor([[-1.6706, -2.2457],
        [-1.8237, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06732210516929626
Epoch 0, Step 547: train/loss = 0.3982330858707428, train/raw-loss = 0.39274686574935913, train/logprobs = tensor([[-0.6996, -2.5361],
        [-0.9144, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05486217141151428
Epoch 0, Step 548: train/loss = 0.5193023085594177, train/raw-loss = 0.5165078639984131, train/logprobs = tensor([[-1.1857, -2.2304],
        [-1.3200, -1.4778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027944153174757957
Epoch 0, Step 549: train/loss = 0.490860253572464, train/raw-loss = 0.4870588779449463, train/logprobs = tensor([[-1.2510, -2.0939],
        [-1.5315, -1.3744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03801405802369118
Epoch 0, Step 550: train/loss = 0.5194715857505798, train/raw-loss = 0.5143535733222961, train/logprobs = tensor([[-1.3180, -2.0221],
        [-1.3099, -1.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05118025839328766
Epoch 0, Step 551: train/loss = 0.45054683089256287, train/raw-loss = 0.44544440507888794, train/logprobs = tensor([[-0.8193, -2.2504],
        [-1.0396, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051024179905653
Epoch 0, Step 552: train/loss = 0.34463441371917725, train/raw-loss = 0.33670541644096375, train/logprobs = tensor([[-1.2260, -3.1197],
        [-1.2982, -1.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07928946614265442
Epoch 0, Step 553: train/loss = 0.44976168870925903, train/raw-loss = 0.445698618888855, train/logprobs = tensor([[-1.4692, -2.8257],
        [-1.4544, -1.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040630538016557693
Epoch 0, Step 554: train/loss = 0.505746603012085, train/raw-loss = 0.49736589193344116, train/logprobs = tensor([[-1.1895, -2.1907],
        [-1.3455, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380729705095291
Epoch 0, Step 555: train/loss = 0.3403737246990204, train/raw-loss = 0.32977813482284546, train/logprobs = tensor([[-1.7334, -3.7628],
        [-1.8783, -1.6895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10595602542161942
Epoch 0, Step 556: train/loss = 0.3590187430381775, train/raw-loss = 0.3506441116333008, train/logprobs = tensor([[-1.5535, -3.1457],
        [-1.7404, -1.4876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837460607290268
Epoch 0, Step 557: train/loss = 0.43389761447906494, train/raw-loss = 0.4274240732192993, train/logprobs = tensor([[-0.7987, -2.4871],
        [-0.9035, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06473546475172043
Epoch 0, Step 558: train/loss = 0.578296422958374, train/raw-loss = 0.5762299299240112, train/logprobs = tensor([[-1.7598, -1.9849],
        [-1.6629, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020664921030402184
Epoch 0, Step 559: train/loss = 0.4102649688720703, train/raw-loss = 0.40648001432418823, train/logprobs = tensor([[-0.9908, -3.0266],
        [-1.2582, -1.8171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03784982115030289
Epoch 0, Step 560: train/loss = 0.5518026351928711, train/raw-loss = 0.549992561340332, train/logprobs = tensor([[-1.1030, -2.0380],
        [-1.2192, -1.4765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018100619316101074
Epoch 0, Step 561: train/loss = 0.4348350167274475, train/raw-loss = 0.429784893989563, train/logprobs = tensor([[-1.8956, -3.1476],
        [-1.5194, -1.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05050162225961685
Epoch 0, Step 562: train/loss = 0.5720395445823669, train/raw-loss = 0.5710700750350952, train/logprobs = tensor([[-1.1744, -2.1794],
        [-1.3654, -1.8081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00969458743929863
Epoch 0, Step 563: train/loss = 0.4420713484287262, train/raw-loss = 0.43682006001472473, train/logprobs = tensor([[-1.7035, -2.7648],
        [-1.4576, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0525127649307251
Epoch 0, Step 564: train/loss = 0.6056780815124512, train/raw-loss = 0.6049546003341675, train/logprobs = tensor([[-1.4168, -1.5543],
        [-1.2728, -1.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007234590128064156
Epoch 0, Step 565: train/loss = 0.44244614243507385, train/raw-loss = 0.4336845278739929, train/logprobs = tensor([[-1.0806, -2.3397],
        [-1.2394, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08761648833751678
Epoch 0, Step 566: train/loss = 0.3657327890396118, train/raw-loss = 0.35685425996780396, train/logprobs = tensor([[-1.1714, -3.0379],
        [-1.3425, -1.3863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08878527581691742
Epoch 0, Step 567: train/loss = 0.370648592710495, train/raw-loss = 0.3624553084373474, train/logprobs = tensor([[-1.0317, -3.4793],
        [-0.9771, -1.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08193308115005493
Epoch 0, Step 568: train/loss = 0.3244178891181946, train/raw-loss = 0.31463199853897095, train/logprobs = tensor([[-1.4395, -3.4033],
        [-1.5982, -1.5437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09785924851894379
Epoch 0, Step 569: train/loss = 0.3519326448440552, train/raw-loss = 0.34478121995925903, train/logprobs = tensor([[-1.6868, -3.6808],
        [-1.8462, -1.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07151416689157486
Epoch 0, Step 570: train/loss = 0.5373824238777161, train/raw-loss = 0.5335803031921387, train/logprobs = tensor([[-1.4850, -2.6763],
        [-1.3859, -1.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03802097588777542
Epoch 0, Step 571: train/loss = 0.4645531177520752, train/raw-loss = 0.46091216802597046, train/logprobs = tensor([[-1.4096, -3.0228],
        [-1.5202, -1.9337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03640951216220856
Epoch 0, Step 572: train/loss = 0.3581297695636749, train/raw-loss = 0.3525696396827698, train/logprobs = tensor([[-1.1263, -3.9107],
        [-1.2186, -2.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055601201951503754
Epoch 0, Step 573: train/loss = 0.5458786487579346, train/raw-loss = 0.5391020774841309, train/logprobs = tensor([[-1.9208, -3.4867],
        [-1.4163, -1.9513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776551157236099
Epoch 0, Step 574: train/loss = 0.5695568323135376, train/raw-loss = 0.5630490183830261, train/logprobs = tensor([[-1.1700, -2.0009],
        [-1.1853, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06507834792137146
Epoch 0, Step 575: train/loss = 0.4130004644393921, train/raw-loss = 0.40621450543403625, train/logprobs = tensor([[-1.1178, -2.9752],
        [-1.2198, -1.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06785953044891357
Epoch 0, Step 576: train/loss = 0.4951375722885132, train/raw-loss = 0.4912877678871155, train/logprobs = tensor([[-1.0010, -1.9008],
        [-1.1228, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038498133420944214
Epoch 0, Step 577: train/loss = 0.38240838050842285, train/raw-loss = 0.3736637234687805, train/logprobs = tensor([[-1.9856, -3.9716],
        [-1.8036, -2.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08744671940803528
Epoch 0, Step 578: train/loss = 0.4788557291030884, train/raw-loss = 0.46844565868377686, train/logprobs = tensor([[-1.5469, -2.7087],
        [-1.3654, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10410086810588837
Epoch 0, Step 579: train/loss = 0.4641539454460144, train/raw-loss = 0.46047937870025635, train/logprobs = tensor([[-0.8980, -2.3714],
        [-0.9033, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03674580156803131
Epoch 0, Step 580: train/loss = 0.6160762310028076, train/raw-loss = 0.6118852496147156, train/logprobs = tensor([[-1.4655, -2.4533],
        [-1.2091, -1.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041910700500011444
Epoch 0, Step 581: train/loss = 0.28506267070770264, train/raw-loss = 0.28044986724853516, train/logprobs = tensor([[-0.6139, -4.4032],
        [-0.6666, -2.1399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04612787067890167
Epoch 0, Step 582: train/loss = 0.4210360050201416, train/raw-loss = 0.41571569442749023, train/logprobs = tensor([[-1.4006, -2.5743],
        [-1.4704, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053203023970127106
Epoch 0, Step 583: train/loss = 0.3416614830493927, train/raw-loss = 0.3367377817630768, train/logprobs = tensor([[-1.0463, -3.8371],
        [-1.0787, -1.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04923698306083679
Epoch 0, Step 584: train/loss = 0.4513067901134491, train/raw-loss = 0.4459304213523865, train/logprobs = tensor([[-1.4076, -2.9664],
        [-1.4713, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05376370996236801
Epoch 0, Step 585: train/loss = 0.475044846534729, train/raw-loss = 0.4722464382648468, train/logprobs = tensor([[-0.6938, -2.9106],
        [-0.8636, -1.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02798408828675747
Epoch 0, Step 586: train/loss = 0.6040667295455933, train/raw-loss = 0.6027532815933228, train/logprobs = tensor([[-2.5285, -1.8859],
        [-2.1109, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013134025037288666
Epoch 0, Step 587: train/loss = 0.4737381339073181, train/raw-loss = 0.4680097997188568, train/logprobs = tensor([[-0.6925, -2.0992],
        [-0.8793, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05728321522474289
Epoch 0, Step 588: train/loss = 0.44435375928878784, train/raw-loss = 0.43986776471138, train/logprobs = tensor([[-1.6849, -2.5934],
        [-1.5691, -1.2319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044859763234853745
Epoch 0, Step 589: train/loss = 0.5826542377471924, train/raw-loss = 0.5808330774307251, train/logprobs = tensor([[-2.1072, -2.9732],
        [-1.1915, -1.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01821177266538143
Epoch 0, Step 590: train/loss = 0.4275689423084259, train/raw-loss = 0.4223348796367645, train/logprobs = tensor([[-1.5030, -3.0729],
        [-1.3964, -1.6156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05234036222100258
Epoch 0, Step 591: train/loss = 0.45142024755477905, train/raw-loss = 0.4460911452770233, train/logprobs = tensor([[-1.2673, -2.3884],
        [-1.4133, -1.2086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05329122394323349
Epoch 0, Step 592: train/loss = 0.5499705076217651, train/raw-loss = 0.5448523759841919, train/logprobs = tensor([[-2.1285, -2.1824],
        [-1.7904, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05118134990334511
Epoch 0, Step 593: train/loss = 0.3637675344944, train/raw-loss = 0.35070276260375977, train/logprobs = tensor([[-1.5305, -3.5576],
        [-1.4679, -1.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13064789772033691
Epoch 0, Step 594: train/loss = 0.5710535049438477, train/raw-loss = 0.5695074200630188, train/logprobs = tensor([[-1.1362, -2.0069],
        [-1.0241, -1.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015461163595318794
Epoch 0, Step 595: train/loss = 0.5375595688819885, train/raw-loss = 0.534080982208252, train/logprobs = tensor([[-1.5402, -2.3917],
        [-1.2693, -1.3069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03478590026497841
Epoch 0, Step 596: train/loss = 0.5005800127983093, train/raw-loss = 0.4964090883731842, train/logprobs = tensor([[-1.0327, -2.1737],
        [-1.0739, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04170917719602585
Epoch 0, Step 597: train/loss = 0.31107187271118164, train/raw-loss = 0.30130964517593384, train/logprobs = tensor([[-0.9368, -3.4163],
        [-1.0124, -1.1495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09762227535247803
Epoch 0, Step 598: train/loss = 0.41436469554901123, train/raw-loss = 0.4069647789001465, train/logprobs = tensor([[-1.0110, -2.8205],
        [-1.0050, -1.1711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07399962097406387
Epoch 0, Step 599: train/loss = 0.30496495962142944, train/raw-loss = 0.2967836558818817, train/logprobs = tensor([[-1.4580, -3.7564],
        [-1.3708, -1.4278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08181311190128326
Epoch 0, Step 600: train/loss = 0.5341259241104126, train/raw-loss = 0.5315097570419312, train/logprobs = tensor([[-1.3223, -1.8984],
        [-1.3979, -1.2161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02616148069500923
Epoch 0, Step 601: train/loss = 0.3835805654525757, train/raw-loss = 0.3763830065727234, train/logprobs = tensor([[-1.1908, -2.8787],
        [-1.2483, -1.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07197539508342743
Epoch 0, Step 602: train/loss = 0.4633772373199463, train/raw-loss = 0.45862600207328796, train/logprobs = tensor([[-1.5240, -2.3577],
        [-1.2350, -0.9276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047512128949165344
Epoch 0, Step 603: train/loss = 0.4360888600349426, train/raw-loss = 0.42993050813674927, train/logprobs = tensor([[-0.9197, -2.8581],
        [-1.1013, -1.5013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06158319115638733
Epoch 0, Step 604: train/loss = 0.27659744024276733, train/raw-loss = 0.2604096531867981, train/logprobs = tensor([[-1.1731, -4.0034],
        [-1.2783, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16187816858291626
Epoch 0, Step 605: train/loss = 0.4001305103302002, train/raw-loss = 0.3924562335014343, train/logprobs = tensor([[-1.1896, -2.8943],
        [-1.3295, -1.2620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767432451248169
Epoch 0, Step 606: train/loss = 0.4689922332763672, train/raw-loss = 0.4645204246044159, train/logprobs = tensor([[-1.5067, -2.5059],
        [-1.7285, -1.4688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04471801966428757
Epoch 0, Step 607: train/loss = 0.3981606960296631, train/raw-loss = 0.3901417851448059, train/logprobs = tensor([[-1.5731, -2.9196],
        [-1.6189, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08018947392702103
Epoch 0, Step 608: train/loss = 0.4380839467048645, train/raw-loss = 0.4327179789543152, train/logprobs = tensor([[-1.2184, -3.8097],
        [-1.1778, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05365967005491257
Epoch 0, Step 609: train/loss = 0.37272772192955017, train/raw-loss = 0.363137811422348, train/logprobs = tensor([[-1.7240, -3.1939],
        [-1.6142, -1.2841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09589922428131104
Epoch 0, Step 610: train/loss = 0.47082361578941345, train/raw-loss = 0.4668203294277191, train/logprobs = tensor([[-1.3223, -3.3502],
        [-0.8853, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0400330126285553
Epoch 0, Step 611: train/loss = 0.5844742655754089, train/raw-loss = 0.5808089375495911, train/logprobs = tensor([[-1.5001, -1.9859],
        [-1.2578, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036653533577919006
Epoch 0, Step 612: train/loss = 0.4453132450580597, train/raw-loss = 0.44108688831329346, train/logprobs = tensor([[-1.7397, -3.1283],
        [-1.2552, -1.3651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042263418436050415
Epoch 0, Step 613: train/loss = 0.44327542185783386, train/raw-loss = 0.4395368695259094, train/logprobs = tensor([[-1.1978, -4.0082],
        [-0.7921, -2.1787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037385549396276474
Epoch 0, Step 614: train/loss = 0.44868528842926025, train/raw-loss = 0.44595056772232056, train/logprobs = tensor([[-1.4524, -3.9376],
        [-1.0314, -2.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02734699659049511
Epoch 0, Step 615: train/loss = 0.4019719362258911, train/raw-loss = 0.394555926322937, train/logprobs = tensor([[-0.7618, -2.9595],
        [-0.7211, -0.9122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0741601437330246
Epoch 0, Step 616: train/loss = 0.4013144373893738, train/raw-loss = 0.3966858386993408, train/logprobs = tensor([[-2.4073, -4.6800],
        [-1.7652, -2.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04628574103116989
Epoch 0, Step 617: train/loss = 0.47410210967063904, train/raw-loss = 0.46996408700942993, train/logprobs = tensor([[-1.2260, -2.4742],
        [-1.1430, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04138002172112465
Epoch 0, Step 618: train/loss = 0.37939339876174927, train/raw-loss = 0.3731516897678375, train/logprobs = tensor([[-1.1893, -2.9392],
        [-1.0037, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06241724640130997
Epoch 0, Step 619: train/loss = 0.5924295783042908, train/raw-loss = 0.5839690566062927, train/logprobs = tensor([[-2.9692, -3.8032],
        [-1.3272, -1.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08460530638694763
Epoch 0, Step 620: train/loss = 0.5388168096542358, train/raw-loss = 0.5330026149749756, train/logprobs = tensor([[-1.1813, -2.8192],
        [-1.1023, -1.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058141641318798065
Epoch 0, Step 621: train/loss = 0.38379043340682983, train/raw-loss = 0.3741787374019623, train/logprobs = tensor([[-2.0958, -3.5556],
        [-1.6418, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09611698985099792
Epoch 0, Step 622: train/loss = 0.5462843179702759, train/raw-loss = 0.5438375473022461, train/logprobs = tensor([[-1.1153, -3.4774],
        [-1.0415, -2.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024468058720231056
Epoch 0, Step 623: train/loss = 0.41839098930358887, train/raw-loss = 0.40852034091949463, train/logprobs = tensor([[-2.9585, -4.9395],
        [-2.1352, -2.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987061858177185
Epoch 0, Step 624: train/loss = 0.5185955762863159, train/raw-loss = 0.5136186480522156, train/logprobs = tensor([[-1.6009, -2.1535],
        [-1.4017, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049769219011068344
Epoch 0, Step 625: train/loss = 0.4844769835472107, train/raw-loss = 0.4726247191429138, train/logprobs = tensor([[-1.4707, -2.5346],
        [-1.6267, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11852245032787323
Epoch 0, Step 626: train/loss = 0.4592021107673645, train/raw-loss = 0.45602378249168396, train/logprobs = tensor([[-1.7691, -3.2798],
        [-1.3675, -1.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03178364410996437
Epoch 0, Step 627: train/loss = 0.4949991703033447, train/raw-loss = 0.49130013585090637, train/logprobs = tensor([[-0.9952, -2.9350],
        [-0.8583, -1.5348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03699055314064026
Epoch 0, Step 628: train/loss = 0.346506804227829, train/raw-loss = 0.3400943875312805, train/logprobs = tensor([[-1.3566, -3.9660],
        [-0.9551, -1.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06412418186664581
Epoch 0, Step 629: train/loss = 0.415835440158844, train/raw-loss = 0.4080822467803955, train/logprobs = tensor([[-1.5650, -2.9606],
        [-1.3672, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07753181457519531
Epoch 0, Step 630: train/loss = 0.29392874240875244, train/raw-loss = 0.2837388217449188, train/logprobs = tensor([[-0.8684, -3.9544],
        [-0.9193, -1.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10189907252788544
Epoch 0, Step 631: train/loss = 0.587942361831665, train/raw-loss = 0.5867335796356201, train/logprobs = tensor([[-1.0143, -1.4588],
        [-0.8554, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012087816372513771
Epoch 0, Step 632: train/loss = 0.416802316904068, train/raw-loss = 0.4108349084854126, train/logprobs = tensor([[-1.1419, -2.8469],
        [-1.1711, -1.3231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05967431515455246
Epoch 0, Step 633: train/loss = 0.3531914949417114, train/raw-loss = 0.34414395689964294, train/logprobs = tensor([[-0.9382, -3.7743],
        [-1.0161, -1.5869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09047544002532959
Epoch 0, Step 634: train/loss = 0.3804548382759094, train/raw-loss = 0.3727573752403259, train/logprobs = tensor([[-1.6588, -3.5359],
        [-1.5107, -1.5583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07697489857673645
Epoch 0, Step 635: train/loss = 0.461262971162796, train/raw-loss = 0.45423075556755066, train/logprobs = tensor([[-1.4564, -2.5521],
        [-1.3479, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07032249122858047
Epoch 0, Step 636: train/loss = 0.4915701746940613, train/raw-loss = 0.484914630651474, train/logprobs = tensor([[-2.1247, -2.9261],
        [-1.6222, -1.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06655533611774445
Epoch 0, Step 637: train/loss = 0.5106263160705566, train/raw-loss = 0.5019956827163696, train/logprobs = tensor([[-1.4811, -2.3914],
        [-1.5012, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08630698919296265
Epoch 0, Step 638: train/loss = 0.49784567952156067, train/raw-loss = 0.4938022196292877, train/logprobs = tensor([[-1.2117, -2.2217],
        [-1.2392, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04043452814221382
Epoch 0, Step 639: train/loss = 0.5678795576095581, train/raw-loss = 0.5646044611930847, train/logprobs = tensor([[-1.6284, -2.1532],
        [-1.3725, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03275081515312195
Epoch 0, Step 640: train/loss = 0.35138124227523804, train/raw-loss = 0.3403446078300476, train/logprobs = tensor([[-0.9694, -3.3980],
        [-0.8633, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11036685109138489
Epoch 0, Step 641: train/loss = 0.48014676570892334, train/raw-loss = 0.4740314483642578, train/logprobs = tensor([[-1.0617, -2.5184],
        [-1.3849, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06115330010652542
Epoch 0, Step 642: train/loss = 0.5707466006278992, train/raw-loss = 0.5691467523574829, train/logprobs = tensor([[-0.9485, -1.8217],
        [-0.9234, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01599889062345028
Epoch 0, Step 643: train/loss = 0.5308058261871338, train/raw-loss = 0.5279990434646606, train/logprobs = tensor([[-1.0203, -2.3410],
        [-1.1056, -1.5594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028067804872989655
Epoch 0, Step 644: train/loss = 0.37953808903694153, train/raw-loss = 0.3696332573890686, train/logprobs = tensor([[-1.5843, -3.6170],
        [-1.8082, -1.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09904827922582626
Epoch 0, Step 645: train/loss = 0.520821213722229, train/raw-loss = 0.5183473825454712, train/logprobs = tensor([[-1.3032, -2.0575],
        [-0.9593, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024738337844610214
Epoch 0, Step 646: train/loss = 0.3394412100315094, train/raw-loss = 0.3324492275714874, train/logprobs = tensor([[-1.4142, -3.7331],
        [-1.4131, -1.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06991995126008987
Epoch 0, Step 647: train/loss = 0.4893953800201416, train/raw-loss = 0.480521559715271, train/logprobs = tensor([[-1.9185, -2.8939],
        [-1.6041, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08873800188302994
Epoch 0, Step 648: train/loss = 0.2837977409362793, train/raw-loss = 0.27366912364959717, train/logprobs = tensor([[-1.1184, -4.0078],
        [-0.9295, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10128629207611084
Epoch 0, Step 649: train/loss = 0.5456105470657349, train/raw-loss = 0.5424633622169495, train/logprobs = tensor([[-0.9823, -2.1532],
        [-1.0536, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03147192299365997
Epoch 0, Step 650: train/loss = 0.5664206743240356, train/raw-loss = 0.5632384419441223, train/logprobs = tensor([[-1.9389, -2.9105],
        [-1.4784, -1.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03182254359126091
Epoch 0, Step 651: train/loss = 0.4028390944004059, train/raw-loss = 0.3922138810157776, train/logprobs = tensor([[-1.8464, -2.5098],
        [-1.8129, -0.7939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10625254362821579
Epoch 0, Step 652: train/loss = 0.3618587553501129, train/raw-loss = 0.35143613815307617, train/logprobs = tensor([[-1.1368, -3.4233],
        [-1.0880, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10422636568546295
Epoch 0, Step 653: train/loss = 0.48248112201690674, train/raw-loss = 0.47854167222976685, train/logprobs = tensor([[-0.9736, -2.0283],
        [-0.8415, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039394691586494446
Epoch 0, Step 654: train/loss = 0.47159111499786377, train/raw-loss = 0.46686726808547974, train/logprobs = tensor([[-1.3645, -2.1491],
        [-1.4553, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04723849147558212
Epoch 0, Step 655: train/loss = 0.3717721104621887, train/raw-loss = 0.3654916286468506, train/logprobs = tensor([[-1.3087, -3.3080],
        [-1.4305, -1.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06280476599931717
Epoch 0, Step 656: train/loss = 0.4672042727470398, train/raw-loss = 0.46450796723365784, train/logprobs = tensor([[-0.8991, -2.5925],
        [-0.9330, -1.4357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026962630450725555
Epoch 0, Step 657: train/loss = 0.5053378343582153, train/raw-loss = 0.499971866607666, train/logprobs = tensor([[-1.1564, -1.9696],
        [-1.2387, -1.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05365970358252525
Epoch 0, Step 658: train/loss = 0.48064079880714417, train/raw-loss = 0.47387194633483887, train/logprobs = tensor([[-1.1081, -1.7587],
        [-1.3716, -0.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06768832355737686
Epoch 0, Step 659: train/loss = 0.284951388835907, train/raw-loss = 0.2774158716201782, train/logprobs = tensor([[-1.2075, -5.0923],
        [-1.2182, -2.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07535512000322342
Epoch 0, Step 660: train/loss = 0.45711225271224976, train/raw-loss = 0.45358744263648987, train/logprobs = tensor([[-1.6034, -3.6372],
        [-0.9817, -1.4307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03524801880121231
Epoch 0, Step 661: train/loss = 0.33511388301849365, train/raw-loss = 0.32716307044029236, train/logprobs = tensor([[-1.5386, -3.6563],
        [-1.8642, -1.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07950792461633682
Epoch 0, Step 662: train/loss = 0.3858793377876282, train/raw-loss = 0.37710022926330566, train/logprobs = tensor([[-1.0842, -2.9553],
        [-1.2009, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08779110759496689
Epoch 0, Step 663: train/loss = 0.39671677350997925, train/raw-loss = 0.3855851888656616, train/logprobs = tensor([[-1.4898, -2.8693],
        [-1.3005, -0.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11131588369607925
Epoch 0, Step 664: train/loss = 0.4127354919910431, train/raw-loss = 0.4080505967140198, train/logprobs = tensor([[-1.7992, -4.1588],
        [-1.8015, -2.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046849049627780914
Epoch 0, Step 665: train/loss = 0.3225148022174835, train/raw-loss = 0.31672555208206177, train/logprobs = tensor([[-1.3430, -3.6545],
        [-1.3223, -1.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05789262056350708
Epoch 0, Step 666: train/loss = 0.3563120663166046, train/raw-loss = 0.34798306226730347, train/logprobs = tensor([[-1.5811, -2.9800],
        [-1.5948, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08328975737094879
Epoch 0, Step 667: train/loss = 0.5218309164047241, train/raw-loss = 0.5171225070953369, train/logprobs = tensor([[-1.2068, -1.6821],
        [-1.3313, -0.8932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0470840223133564
Epoch 0, Step 668: train/loss = 0.3697201609611511, train/raw-loss = 0.36177632212638855, train/logprobs = tensor([[-1.3398, -3.2508],
        [-1.3332, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07943817228078842
Epoch 0, Step 669: train/loss = 0.2926071882247925, train/raw-loss = 0.2829494774341583, train/logprobs = tensor([[-1.1674, -4.4768],
        [-1.1192, -1.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09657669067382812
Epoch 0, Step 670: train/loss = 0.6190335154533386, train/raw-loss = 0.6174197196960449, train/logprobs = tensor([[-1.9028, -2.1388],
        [-1.1924, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01613808423280716
Epoch 0, Step 671: train/loss = 0.5954906344413757, train/raw-loss = 0.5939545631408691, train/logprobs = tensor([[-1.3008, -2.1785],
        [-0.8141, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015360568650066853
Epoch 0, Step 672: train/loss = 0.3348357677459717, train/raw-loss = 0.32298797369003296, train/logprobs = tensor([[-1.9078, -3.7507],
        [-1.5057, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11847799271345139
Epoch 0, Step 673: train/loss = 0.36436358094215393, train/raw-loss = 0.35621893405914307, train/logprobs = tensor([[-1.4175, -3.3324],
        [-1.3362, -1.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08144636452198029
Epoch 0, Step 674: train/loss = 0.3124144971370697, train/raw-loss = 0.29376327991485596, train/logprobs = tensor([[-1.4154, -4.1050],
        [-1.6612, -1.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1865123212337494
Epoch 0, Step 675: train/loss = 0.3481897711753845, train/raw-loss = 0.34202688932418823, train/logprobs = tensor([[-0.9985, -3.2231],
        [-1.1952, -1.5671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061628490686416626
Epoch 0, Step 676: train/loss = 0.418342649936676, train/raw-loss = 0.41157692670822144, train/logprobs = tensor([[-1.6140, -3.0130],
        [-1.5190, -1.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06765735894441605
Epoch 0, Step 677: train/loss = 0.33834078907966614, train/raw-loss = 0.32873350381851196, train/logprobs = tensor([[-1.4922, -3.6402],
        [-1.5450, -1.6583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09607294946908951
Epoch 0, Step 678: train/loss = 0.2604815363883972, train/raw-loss = 0.24735799431800842, train/logprobs = tensor([[-1.4819, -4.5019],
        [-1.6460, -1.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13123546540737152
Epoch 0, Step 679: train/loss = 0.5831856727600098, train/raw-loss = 0.5799589157104492, train/logprobs = tensor([[-1.4314, -1.5250],
        [-1.4327, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03226720914244652
Epoch 0, Step 680: train/loss = 0.4543626010417938, train/raw-loss = 0.4432964324951172, train/logprobs = tensor([[-2.0527, -3.3038],
        [-1.8482, -1.4603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11066180467605591
Epoch 0, Step 681: train/loss = 0.43611353635787964, train/raw-loss = 0.4307553470134735, train/logprobs = tensor([[-1.0253, -3.0339],
        [-1.0766, -1.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05358216166496277
Epoch 0, Step 682: train/loss = 0.2794249355792999, train/raw-loss = 0.2653706967830658, train/logprobs = tensor([[-1.5840, -4.3372],
        [-1.8013, -1.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14054232835769653
Epoch 0, Step 683: train/loss = 0.4700053334236145, train/raw-loss = 0.46031317114830017, train/logprobs = tensor([[-2.2684, -3.1461],
        [-1.6971, -1.1560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09692202508449554
Epoch 0, Step 684: train/loss = 0.4418894052505493, train/raw-loss = 0.43531209230422974, train/logprobs = tensor([[-1.0153, -2.3673],
        [-1.3024, -1.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577332317829132
Epoch 0, Step 685: train/loss = 0.31799960136413574, train/raw-loss = 0.30756956338882446, train/logprobs = tensor([[-1.3126, -3.7518],
        [-1.5101, -1.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10430022329092026
Epoch 0, Step 686: train/loss = 0.3583707809448242, train/raw-loss = 0.34621715545654297, train/logprobs = tensor([[-0.9222, -3.2862],
        [-1.0601, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12153608351945877
Epoch 0, Step 687: train/loss = 0.4127079248428345, train/raw-loss = 0.40186452865600586, train/logprobs = tensor([[-1.4928, -2.8297],
        [-1.7775, -1.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1084342822432518
Epoch 0, Step 688: train/loss = 0.36735594272613525, train/raw-loss = 0.36196368932724, train/logprobs = tensor([[-1.5892, -3.9628],
        [-1.5221, -1.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053922977298498154
Epoch 0, Step 689: train/loss = 0.37151187658309937, train/raw-loss = 0.36102038621902466, train/logprobs = tensor([[-0.8274, -3.0417],
        [-0.9598, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049150750041008
Epoch 0, Step 690: train/loss = 0.38556718826293945, train/raw-loss = 0.3775901198387146, train/logprobs = tensor([[-1.6157, -3.5588],
        [-1.3585, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07977092266082764
Epoch 0, Step 691: train/loss = 0.2720198631286621, train/raw-loss = 0.2586056590080261, train/logprobs = tensor([[-0.9894, -3.9296],
        [-1.1218, -1.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13414201140403748
Epoch 0, Step 692: train/loss = 0.38790950179100037, train/raw-loss = 0.38016462326049805, train/logprobs = tensor([[-1.1176, -2.8809],
        [-1.2806, -1.3286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07744870334863663
Epoch 0, Step 693: train/loss = 0.4017990827560425, train/raw-loss = 0.3887619078159332, train/logprobs = tensor([[-1.6908, -3.5284],
        [-1.7363, -1.4118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13037195801734924
Epoch 0, Step 694: train/loss = 0.35862332582473755, train/raw-loss = 0.3471165895462036, train/logprobs = tensor([[-1.4771, -3.4323],
        [-1.5362, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11506760865449905
Epoch 0, Step 695: train/loss = 0.3552509546279907, train/raw-loss = 0.3439544439315796, train/logprobs = tensor([[-1.1208, -2.9924],
        [-1.4025, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11296536773443222
Epoch 0, Step 696: train/loss = 0.2461256980895996, train/raw-loss = 0.23458993434906006, train/logprobs = tensor([[-1.1387, -4.1410],
        [-1.2373, -1.4367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11535754054784775
Epoch 0, Step 697: train/loss = 0.35135364532470703, train/raw-loss = 0.3387419283390045, train/logprobs = tensor([[-1.2792, -3.4319],
        [-1.6432, -1.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1261170655488968
Epoch 0, Step 698: train/loss = 0.32706505060195923, train/raw-loss = 0.3147296905517578, train/logprobs = tensor([[-1.8959, -4.8259],
        [-1.3498, -1.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12335381656885147
Epoch 0, Step 699: train/loss = 0.41747647523880005, train/raw-loss = 0.4080827534198761, train/logprobs = tensor([[-1.3472, -3.0884],
        [-1.3216, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0939374566078186
Epoch 0, Step 700: train/loss = 0.3328894078731537, train/raw-loss = 0.3251548707485199, train/logprobs = tensor([[-0.7378, -3.4477],
        [-0.8482, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07734544575214386
Epoch 0, Step 701: train/loss = 0.41125619411468506, train/raw-loss = 0.40112200379371643, train/logprobs = tensor([[-1.1178, -2.7289],
        [-1.6281, -1.3921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10134168714284897
Epoch 0, Step 702: train/loss = 0.3319547176361084, train/raw-loss = 0.32251083850860596, train/logprobs = tensor([[-2.1002, -3.5280],
        [-2.1060, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09443902969360352
Epoch 0, Step 703: train/loss = 0.285416841506958, train/raw-loss = 0.2775793671607971, train/logprobs = tensor([[-1.8013, -4.5461],
        [-1.6050, -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0783747136592865
Epoch 0, Step 704: train/loss = 0.31197255849838257, train/raw-loss = 0.30537378787994385, train/logprobs = tensor([[-1.0278, -4.0116],
        [-1.2890, -2.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06598766148090363
Epoch 0, Step 705: train/loss = 0.42437681555747986, train/raw-loss = 0.4189194142818451, train/logprobs = tensor([[-1.5640, -3.3099],
        [-1.5864, -1.8489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05457434058189392
Epoch 0, Step 706: train/loss = 0.3247280716896057, train/raw-loss = 0.31534543633461, train/logprobs = tensor([[-1.2817, -4.2956],
        [-1.0294, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382639080286026
Epoch 0, Step 707: train/loss = 0.5180676579475403, train/raw-loss = 0.5141744017601013, train/logprobs = tensor([[-1.6326, -2.6377],
        [-1.1938, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03893269598484039
Epoch 0, Step 708: train/loss = 0.5163808465003967, train/raw-loss = 0.5130531787872314, train/logprobs = tensor([[-1.2476, -2.1201],
        [-1.5028, -1.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03327722102403641
Epoch 0, Step 709: train/loss = 0.4446347951889038, train/raw-loss = 0.4393417537212372, train/logprobs = tensor([[-0.9003, -2.3408],
        [-1.1829, -1.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05293044075369835
Epoch 0, Step 710: train/loss = 0.31511390209198, train/raw-loss = 0.3040449619293213, train/logprobs = tensor([[-0.8272, -3.8503],
        [-0.7869, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11068932712078094
Epoch 0, Step 711: train/loss = 0.38757580518722534, train/raw-loss = 0.38010066747665405, train/logprobs = tensor([[-1.9404, -3.3316],
        [-2.0869, -1.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0747518315911293
Epoch 0, Step 712: train/loss = 0.27619698643684387, train/raw-loss = 0.2647119164466858, train/logprobs = tensor([[-0.8569, -3.8896],
        [-0.9502, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11485075205564499
Epoch 0, Step 713: train/loss = 0.2693958580493927, train/raw-loss = 0.25696343183517456, train/logprobs = tensor([[-1.0709, -3.7148],
        [-1.2047, -1.2302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12432420253753662
Epoch 0, Step 714: train/loss = 0.5201848149299622, train/raw-loss = 0.5147822499275208, train/logprobs = tensor([[-1.0164, -1.6028],
        [-1.3064, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054025985300540924
Epoch 0, Step 715: train/loss = 0.5093488097190857, train/raw-loss = 0.5036150217056274, train/logprobs = tensor([[-1.2873, -1.7910],
        [-1.6983, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05733824893832207
Epoch 0, Step 716: train/loss = 0.33069345355033875, train/raw-loss = 0.315944641828537, train/logprobs = tensor([[-1.6744, -3.7437],
        [-1.6946, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14748814702033997
Epoch 0, Step 717: train/loss = 0.2800062894821167, train/raw-loss = 0.26503729820251465, train/logprobs = tensor([[-1.5570, -3.6465],
        [-1.6436, -1.2145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14968989789485931
Epoch 0, Step 718: train/loss = 0.37517064809799194, train/raw-loss = 0.35440897941589355, train/logprobs = tensor([[-2.4222, -5.1592],
        [-1.4006, -1.5302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2076168954372406
Epoch 0, Step 719: train/loss = 0.5969780683517456, train/raw-loss = 0.5953078866004944, train/logprobs = tensor([[-1.2086, -1.4769],
        [-1.2932, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01670149154961109
Epoch 0, Step 720: train/loss = 0.4437788724899292, train/raw-loss = 0.4366500675678253, train/logprobs = tensor([[-0.9632, -2.6349],
        [-1.2117, -1.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07128811627626419
Epoch 0, Step 721: train/loss = 0.44577986001968384, train/raw-loss = 0.4369077980518341, train/logprobs = tensor([[-1.5533, -3.0326],
        [-1.4120, -1.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08872125297784805
Epoch 0, Step 722: train/loss = 0.34729376435279846, train/raw-loss = 0.3302825391292572, train/logprobs = tensor([[-1.1000, -3.4952],
        [-1.2859, -1.2224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17011234164237976
Epoch 0, Step 723: train/loss = 0.36107689142227173, train/raw-loss = 0.35387542843818665, train/logprobs = tensor([[-1.8975, -4.3395],
        [-1.2387, -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07201474905014038
Epoch 0, Step 724: train/loss = 0.44311875104904175, train/raw-loss = 0.4358323812484741, train/logprobs = tensor([[-0.9335, -2.7352],
        [-1.2421, -1.4585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07286372780799866
Epoch 0, Step 725: train/loss = 0.467507004737854, train/raw-loss = 0.4573383927345276, train/logprobs = tensor([[-1.3646, -2.2376],
        [-1.6990, -1.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168619453907013
Epoch 0, Step 726: train/loss = 0.45268765091896057, train/raw-loss = 0.4447116255760193, train/logprobs = tensor([[-1.2180, -2.2717],
        [-1.5066, -1.0469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797601267695427
Epoch 0, Step 727: train/loss = 0.46212852001190186, train/raw-loss = 0.4562665820121765, train/logprobs = tensor([[-0.8395, -2.3100],
        [-1.1043, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05861926078796387
Epoch 0, Step 728: train/loss = 0.4255920350551605, train/raw-loss = 0.4168285131454468, train/logprobs = tensor([[-1.6263, -2.8209],
        [-1.8666, -1.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08763547986745834
Epoch 0, Step 729: train/loss = 0.2255566120147705, train/raw-loss = 0.2122715562582016, train/logprobs = tensor([[-1.0119, -4.3714],
        [-1.2504, -1.4980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1328505277633667
Epoch 0, Step 730: train/loss = 0.5269701480865479, train/raw-loss = 0.5215626955032349, train/logprobs = tensor([[-1.8472, -2.2750],
        [-2.1194, -1.5924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054074082523584366
Epoch 0, Step 731: train/loss = 0.5067355632781982, train/raw-loss = 0.5010939240455627, train/logprobs = tensor([[-2.5669, -2.6217],
        [-2.1125, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05641598999500275
Epoch 0, Step 732: train/loss = 0.424564003944397, train/raw-loss = 0.4174436628818512, train/logprobs = tensor([[-2.1587, -3.1582],
        [-2.3015, -1.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07120335102081299
Epoch 0, Step 733: train/loss = 0.30732619762420654, train/raw-loss = 0.29858270287513733, train/logprobs = tensor([[-1.1091, -3.4716],
        [-1.4844, -1.5979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08743484318256378
Epoch 0, Step 734: train/loss = 0.5303582549095154, train/raw-loss = 0.5258857011795044, train/logprobs = tensor([[-1.6509, -2.1442],
        [-1.2907, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044725872576236725
Epoch 0, Step 735: train/loss = 0.7212437391281128, train/raw-loss = 0.7188626527786255, train/logprobs = tensor([[-2.1967, -1.8048],
        [-1.5601, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023811060935258865
Epoch 0, Step 736: train/loss = 0.24904978275299072, train/raw-loss = 0.2302921861410141, train/logprobs = tensor([[-1.4675, -4.2629],
        [-1.9465, -1.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18757595121860504
Epoch 0, Step 737: train/loss = 0.5278224945068359, train/raw-loss = 0.5168675184249878, train/logprobs = tensor([[-1.8992, -2.6063],
        [-1.7610, -1.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10954929143190384
Epoch 0, Step 738: train/loss = 0.16678225994110107, train/raw-loss = 0.14661575853824615, train/logprobs = tensor([[-1.2837, -5.0495],
        [-1.8548, -1.8159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20166519284248352
Epoch 0, Step 739: train/loss = 0.16723808646202087, train/raw-loss = 0.13674667477607727, train/logprobs = tensor([[-1.6084, -5.6144],
        [-1.5821, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.304914265871048
Epoch 0, Step 740: train/loss = 0.37979865074157715, train/raw-loss = 0.3703514039516449, train/logprobs = tensor([[-0.8090, -3.4704],
        [-1.1994, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09447244554758072
Epoch 0, Step 741: train/loss = 0.35314661264419556, train/raw-loss = 0.3412376642227173, train/logprobs = tensor([[-1.8947, -4.2400],
        [-1.5180, -1.2298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1190895065665245
Epoch 0, Step 742: train/loss = 0.386949360370636, train/raw-loss = 0.37448105216026306, train/logprobs = tensor([[-0.8718, -3.2201],
        [-1.0649, -0.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12468332797288895
Epoch 0, Step 743: train/loss = 0.42474550008773804, train/raw-loss = 0.4186480939388275, train/logprobs = tensor([[-1.3243, -3.3095],
        [-1.1004, -1.3872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060973770916461945
Epoch 0, Step 744: train/loss = 0.38486990332603455, train/raw-loss = 0.3784870505332947, train/logprobs = tensor([[-1.3468, -3.5446],
        [-1.6292, -2.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06382843852043152
Epoch 0, Step 745: train/loss = 0.2761930227279663, train/raw-loss = 0.2638067305088043, train/logprobs = tensor([[-1.2181, -4.2031],
        [-1.5910, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12386290729045868
Epoch 0, Step 746: train/loss = 0.37883174419403076, train/raw-loss = 0.3690648674964905, train/logprobs = tensor([[-0.7694, -3.9712],
        [-1.0449, -1.7615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09766891598701477
Epoch 0, Step 747: train/loss = 0.6197453737258911, train/raw-loss = 0.6165852546691895, train/logprobs = tensor([[-1.6512, -1.8685],
        [-1.6429, -1.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0316007062792778
Epoch 0, Step 748: train/loss = 0.4409571588039398, train/raw-loss = 0.4354194104671478, train/logprobs = tensor([[-1.5185, -3.6020],
        [-1.8333, -2.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055377278476953506
Epoch 0, Step 749: train/loss = 0.3571263551712036, train/raw-loss = 0.34785792231559753, train/logprobs = tensor([[-1.9668, -3.2467],
        [-1.7707, -1.2419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09268425405025482
Epoch 0, Step 750: train/loss = 0.37040120363235474, train/raw-loss = 0.3616566061973572, train/logprobs = tensor([[-1.5511, -3.5110],
        [-1.3507, -1.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08744622021913528
Epoch 0, Step 751: train/loss = 0.3688395619392395, train/raw-loss = 0.35521066188812256, train/logprobs = tensor([[-1.2507, -3.0395],
        [-1.7465, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1362888365983963
Epoch 0, Step 752: train/loss = 0.4548591673374176, train/raw-loss = 0.4490318298339844, train/logprobs = tensor([[-0.7526, -2.2798],
        [-1.0902, -1.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058273542672395706
Epoch 0, Step 753: train/loss = 0.29783105850219727, train/raw-loss = 0.28688180446624756, train/logprobs = tensor([[-0.9777, -3.0467],
        [-1.5221, -1.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10949262976646423
Epoch 0, Step 754: train/loss = 0.2825052738189697, train/raw-loss = 0.2741415202617645, train/logprobs = tensor([[-1.1960, -4.3516],
        [-1.3112, -1.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836372971534729
Epoch 0, Step 755: train/loss = 0.2614232003688812, train/raw-loss = 0.2426048070192337, train/logprobs = tensor([[-1.6554, -4.7039],
        [-2.0900, -1.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18818382918834686
Epoch 0, Step 756: train/loss = 0.27002424001693726, train/raw-loss = 0.25588661432266235, train/logprobs = tensor([[-1.2966, -3.9170],
        [-1.7558, -1.5943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14137648046016693
Epoch 0, Step 757: train/loss = 0.29964524507522583, train/raw-loss = 0.28840890526771545, train/logprobs = tensor([[-1.4966, -4.6136],
        [-2.0649, -2.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11236334592103958
Epoch 0, Step 758: train/loss = 0.36890989542007446, train/raw-loss = 0.35730910301208496, train/logprobs = tensor([[-1.2636, -2.9073],
        [-1.2907, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11600769311189651
Epoch 0, Step 759: train/loss = 0.2798263430595398, train/raw-loss = 0.2585375905036926, train/logprobs = tensor([[-1.9399, -3.9223],
        [-2.1431, -1.0589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21288779377937317
Epoch 0, Step 760: train/loss = 0.2323104739189148, train/raw-loss = 0.21492166817188263, train/logprobs = tensor([[-2.0799, -4.8003],
        [-2.0690, -1.7491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17388799786567688
Epoch 0, Step 761: train/loss = 0.4199213683605194, train/raw-loss = 0.40957722067832947, train/logprobs = tensor([[-1.5484, -2.8290],
        [-1.4750, -1.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034414991736412
Epoch 0, Step 762: train/loss = 0.41715651750564575, train/raw-loss = 0.4071749150753021, train/logprobs = tensor([[-1.9597, -3.7078],
        [-1.6908, -1.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0998159795999527
Epoch 0, Step 763: train/loss = 0.5602755546569824, train/raw-loss = 0.558633029460907, train/logprobs = tensor([[-1.1869, -1.6511],
        [-1.2884, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01642560213804245
Epoch 0, Step 764: train/loss = 0.2533455491065979, train/raw-loss = 0.23720060288906097, train/logprobs = tensor([[-1.4072, -3.7227],
        [-1.8502, -1.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16144925355911255
Epoch 0, Step 765: train/loss = 0.2500300705432892, train/raw-loss = 0.2250683307647705, train/logprobs = tensor([[-1.1816, -4.8650],
        [-1.6549, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24961739778518677
Epoch 0, Step 766: train/loss = 0.4340508282184601, train/raw-loss = 0.4282505512237549, train/logprobs = tensor([[-1.3417, -3.1850],
        [-1.8418, -2.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05800235643982887
Epoch 0, Step 767: train/loss = 0.482008159160614, train/raw-loss = 0.47808516025543213, train/logprobs = tensor([[-1.4792, -2.9555],
        [-1.6326, -1.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03922992944717407
Epoch 0, Step 768: train/loss = 0.3389899730682373, train/raw-loss = 0.32393044233322144, train/logprobs = tensor([[-1.2029, -2.7456],
        [-1.8641, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15059548616409302
Epoch 0, Step 769: train/loss = 0.3937837481498718, train/raw-loss = 0.3860510587692261, train/logprobs = tensor([[-1.2291, -3.1000],
        [-1.5658, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773269534111023
Epoch 0, Step 770: train/loss = 0.48962700366973877, train/raw-loss = 0.48310932517051697, train/logprobs = tensor([[-0.9220, -1.6625],
        [-1.2544, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.065176822245121
Epoch 0, Step 771: train/loss = 0.2594276964664459, train/raw-loss = 0.24323764443397522, train/logprobs = tensor([[-1.4545, -3.7832],
        [-1.8258, -1.2754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190040111541748
Epoch 0, Step 772: train/loss = 0.34138837456703186, train/raw-loss = 0.3287096917629242, train/logprobs = tensor([[-1.5610, -3.1747],
        [-1.7298, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12678658962249756
Epoch 0, Step 773: train/loss = 0.5257437825202942, train/raw-loss = 0.5208828449249268, train/logprobs = tensor([[-2.1184, -2.5785],
        [-1.6137, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04860956221818924
Epoch 0, Step 774: train/loss = 0.3327658176422119, train/raw-loss = 0.3185662627220154, train/logprobs = tensor([[-1.6649, -3.7223],
        [-1.9550, -1.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419951319694519
Epoch 0, Step 775: train/loss = 0.3009813725948334, train/raw-loss = 0.29242661595344543, train/logprobs = tensor([[-1.2530, -3.8357],
        [-1.6201, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08554751425981522
Epoch 0, Step 776: train/loss = 0.2523062527179718, train/raw-loss = 0.23041203618049622, train/logprobs = tensor([[-1.5267, -4.5924],
        [-1.7366, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21894221007823944
Epoch 0, Step 777: train/loss = 0.33341550827026367, train/raw-loss = 0.3218381106853485, train/logprobs = tensor([[-1.5559, -4.0281],
        [-1.8271, -1.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577408760786057
Epoch 0, Step 778: train/loss = 0.3405503034591675, train/raw-loss = 0.3257542848587036, train/logprobs = tensor([[-1.3520, -2.9877],
        [-1.7753, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.147959902882576
Epoch 0, Step 779: train/loss = 0.3074765205383301, train/raw-loss = 0.2905324399471283, train/logprobs = tensor([[-2.0336, -3.9070],
        [-1.9685, -1.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16944091022014618
Epoch 0, Step 780: train/loss = 0.36234375834465027, train/raw-loss = 0.35381972789764404, train/logprobs = tensor([[-1.2666, -2.8224],
        [-1.4126, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08524014055728912
Epoch 0, Step 781: train/loss = 0.44284284114837646, train/raw-loss = 0.43074434995651245, train/logprobs = tensor([[-2.0007, -3.9467],
        [-1.6802, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12098491936922073
Epoch 0, Step 782: train/loss = 0.28418272733688354, train/raw-loss = 0.26683834195137024, train/logprobs = tensor([[-1.1543, -4.8797],
        [-1.3610, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1734439879655838
Epoch 0, Step 783: train/loss = 0.4473840296268463, train/raw-loss = 0.4425085484981537, train/logprobs = tensor([[-1.1640, -2.1020],
        [-1.3241, -1.0434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04875507950782776
Epoch 0, Step 784: train/loss = 0.2045924961566925, train/raw-loss = 0.18709668517112732, train/logprobs = tensor([[-1.1262, -4.3953],
        [-1.6249, -1.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17495810985565186
Epoch 0, Step 785: train/loss = 0.18182995915412903, train/raw-loss = 0.15645699203014374, train/logprobs = tensor([[-1.3891, -4.9379],
        [-1.6514, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2537297308444977
Epoch 0, Step 786: train/loss = 0.26905542612075806, train/raw-loss = 0.25405460596084595, train/logprobs = tensor([[-1.4098, -4.3069],
        [-1.9731, -1.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15000827610492706
Epoch 0, Step 787: train/loss = 0.3255850672721863, train/raw-loss = 0.3149488866329193, train/logprobs = tensor([[-0.9775, -3.8740],
        [-1.4390, -1.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10636155307292938
Epoch 0, Step 788: train/loss = 0.3502473831176758, train/raw-loss = 0.34342119097709656, train/logprobs = tensor([[-0.8853, -3.5781],
        [-1.0769, -1.3441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06826213002204895
Epoch 0, Step 789: train/loss = 0.45925968885421753, train/raw-loss = 0.45153242349624634, train/logprobs = tensor([[-1.4777, -2.4169],
        [-1.8900, -1.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0772729218006134
Epoch 0, Step 790: train/loss = 0.3890499770641327, train/raw-loss = 0.3805435597896576, train/logprobs = tensor([[-1.5591, -3.0036],
        [-1.4369, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0850641056895256
Epoch 0, Step 791: train/loss = 0.46463003754615784, train/raw-loss = 0.4604373574256897, train/logprobs = tensor([[-1.5475, -2.4653],
        [-1.4413, -1.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04192684590816498
Epoch 0, Step 792: train/loss = 0.28632640838623047, train/raw-loss = 0.27145281434059143, train/logprobs = tensor([[-1.6900, -3.4704],
        [-2.1160, -1.4921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14873570203781128
Epoch 0, Step 793: train/loss = 0.21162885427474976, train/raw-loss = 0.1936608999967575, train/logprobs = tensor([[-1.2880, -4.3336],
        [-1.7994, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17967960238456726
Epoch 0, Step 794: train/loss = 0.3207114040851593, train/raw-loss = 0.30782151222229004, train/logprobs = tensor([[-1.2803, -4.0029],
        [-1.3890, -1.4386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12889882922172546
Epoch 0, Step 795: train/loss = 0.42630890011787415, train/raw-loss = 0.41868776082992554, train/logprobs = tensor([[-1.3084, -3.0312],
        [-1.3726, -1.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0762108713388443
Epoch 0, Step 796: train/loss = 0.3349337577819824, train/raw-loss = 0.32001715898513794, train/logprobs = tensor([[-1.0235, -2.9710],
        [-1.5668, -0.9711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1491660326719284
Epoch 0, Step 797: train/loss = 0.4071946442127228, train/raw-loss = 0.4011303782463074, train/logprobs = tensor([[-1.5897, -2.8200],
        [-1.8432, -1.5893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060642629861831665
Epoch 0, Step 798: train/loss = 0.4313187003135681, train/raw-loss = 0.42346805334091187, train/logprobs = tensor([[-1.3234, -2.2859],
        [-1.5434, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07850660383701324
Epoch 0, Step 799: train/loss = 0.32004913687705994, train/raw-loss = 0.3086525797843933, train/logprobs = tensor([[-1.1900, -4.0171],
        [-1.2585, -1.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11396586149930954
Epoch 0, Step 800: train/loss = 0.5278741121292114, train/raw-loss = 0.5207434296607971, train/logprobs = tensor([[-1.4746, -1.8176],
        [-1.7910, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07130728662014008
Epoch 0, Step 801: train/loss = 0.19194844365119934, train/raw-loss = 0.1752939671278, train/logprobs = tensor([[-1.0933, -4.7235],
        [-1.4797, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16654464602470398
Epoch 0, Step 802: train/loss = 0.2811565399169922, train/raw-loss = 0.26434099674224854, train/logprobs = tensor([[-1.8168, -4.1170],
        [-2.2707, -1.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16815558075904846
Epoch 0, Step 803: train/loss = 0.4795162081718445, train/raw-loss = 0.4746638834476471, train/logprobs = tensor([[-0.8528, -2.1915],
        [-1.1865, -1.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0485231988132
Epoch 0, Step 804: train/loss = 0.3216293454170227, train/raw-loss = 0.30795472860336304, train/logprobs = tensor([[-1.1690, -3.8796],
        [-1.5913, -1.6088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13674628734588623
Epoch 0, Step 805: train/loss = 0.38345280289649963, train/raw-loss = 0.3703812062740326, train/logprobs = tensor([[-2.1956, -4.1788],
        [-2.0999, -1.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13071639835834503
Epoch 0, Step 806: train/loss = 0.45292577147483826, train/raw-loss = 0.4388211667537689, train/logprobs = tensor([[-1.5854, -3.7509],
        [-1.6235, -1.2807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14104607701301575
Epoch 0, Step 807: train/loss = 0.2986413538455963, train/raw-loss = 0.28115278482437134, train/logprobs = tensor([[-1.6580, -4.1185],
        [-1.8652, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1748858094215393
Epoch 0, Step 808: train/loss = 0.34509551525115967, train/raw-loss = 0.33523035049438477, train/logprobs = tensor([[-1.6377, -3.4386],
        [-1.9607, -1.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09865191578865051
Epoch 0, Step 809: train/loss = 0.3626807928085327, train/raw-loss = 0.35385316610336304, train/logprobs = tensor([[-1.0959, -3.7911],
        [-1.2091, -1.4213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08827619254589081
Epoch 0, Step 810: train/loss = 0.26150083541870117, train/raw-loss = 0.24523483216762543, train/logprobs = tensor([[-0.9051, -4.2723],
        [-1.5333, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.162660151720047
Epoch 0, Step 811: train/loss = 0.15058352053165436, train/raw-loss = 0.1302240788936615, train/logprobs = tensor([[-1.2619, -5.7498],
        [-1.7122, -1.9017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20359429717063904
Epoch 0, Step 812: train/loss = 0.3309403359889984, train/raw-loss = 0.31930771470069885, train/logprobs = tensor([[-1.8894, -5.0523],
        [-2.1380, -2.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11632608622312546
Epoch 0, Step 813: train/loss = 0.4446265697479248, train/raw-loss = 0.4297342598438263, train/logprobs = tensor([[-1.6956, -4.5236],
        [-1.5863, -1.9310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1489230990409851
Epoch 0, Step 814: train/loss = 0.32179325819015503, train/raw-loss = 0.3078346252441406, train/logprobs = tensor([[-2.0163, -3.9796],
        [-1.8108, -1.3307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13958615064620972
Epoch 0, Step 815: train/loss = 0.32301920652389526, train/raw-loss = 0.3116353750228882, train/logprobs = tensor([[-1.7210, -4.4296],
        [-1.4361, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1138380914926529
Epoch 0, Step 816: train/loss = 0.37430861592292786, train/raw-loss = 0.3659503757953644, train/logprobs = tensor([[-1.4248, -3.1186],
        [-1.5320, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08358203619718552
Epoch 0, Step 817: train/loss = 0.32949668169021606, train/raw-loss = 0.2950853705406189, train/logprobs = tensor([[-2.0793, -5.0667],
        [-2.1508, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441131114959717
Epoch 0, Step 818: train/loss = 0.31590670347213745, train/raw-loss = 0.2950287461280823, train/logprobs = tensor([[-1.1636, -3.8516],
        [-1.6310, -1.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2087796926498413
Epoch 0, Step 819: train/loss = 0.3378211259841919, train/raw-loss = 0.3202531933784485, train/logprobs = tensor([[-2.1186, -4.0598],
        [-1.7098, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756792664527893
Epoch 0, Step 820: train/loss = 0.2665513753890991, train/raw-loss = 0.2512102723121643, train/logprobs = tensor([[-1.2620, -4.2496],
        [-1.6503, -1.6307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1534106731414795
Epoch 0, Step 821: train/loss = 0.2812044620513916, train/raw-loss = 0.2692466080188751, train/logprobs = tensor([[-1.6968, -4.1005],
        [-1.7013, -1.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11957836896181107
Epoch 0, Step 822: train/loss = 0.269287109375, train/raw-loss = 0.24083390831947327, train/logprobs = tensor([[-1.0671, -4.2140],
        [-1.5809, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28453201055526733
Epoch 0, Step 823: train/loss = 0.5100966691970825, train/raw-loss = 0.5049415826797485, train/logprobs = tensor([[-1.5678, -2.0434],
        [-2.0147, -1.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05155106261372566
Epoch 0, Step 824: train/loss = 0.3612835109233856, train/raw-loss = 0.34400027990341187, train/logprobs = tensor([[-1.7903, -3.7809],
        [-1.4343, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17283213138580322
Epoch 0, Step 825: train/loss = 0.4286483824253082, train/raw-loss = 0.42006397247314453, train/logprobs = tensor([[-1.6453, -2.5774],
        [-1.5897, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08584433794021606
Epoch 0, Step 826: train/loss = 0.2892686426639557, train/raw-loss = 0.273888498544693, train/logprobs = tensor([[-1.7298, -3.7271],
        [-1.6693, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15380138158798218
Epoch 0, Step 827: train/loss = 0.28274673223495483, train/raw-loss = 0.263802707195282, train/logprobs = tensor([[-1.9500, -4.5061],
        [-1.9639, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18944013118743896
Epoch 0, Step 828: train/loss = 0.2827528417110443, train/raw-loss = 0.2697449326515198, train/logprobs = tensor([[-1.3441, -3.7021],
        [-1.4982, -1.2854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13007895648479462
Epoch 0, Step 829: train/loss = 0.42978763580322266, train/raw-loss = 0.42166101932525635, train/logprobs = tensor([[-1.4291, -2.5907],
        [-1.8672, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08126606047153473
Epoch 0, Step 830: train/loss = 0.3581596314907074, train/raw-loss = 0.34439530968666077, train/logprobs = tensor([[-1.0676, -3.4464],
        [-1.4191, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13764311373233795
Epoch 0, Step 831: train/loss = 0.35551533102989197, train/raw-loss = 0.3428300619125366, train/logprobs = tensor([[-2.1040, -3.6852],
        [-1.7397, -1.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12685249745845795
Epoch 0, Step 832: train/loss = 0.3735819458961487, train/raw-loss = 0.35969018936157227, train/logprobs = tensor([[-2.4474, -4.2668],
        [-2.0026, -1.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13891780376434326
Epoch 0, Step 833: train/loss = 0.31183651089668274, train/raw-loss = 0.30016499757766724, train/logprobs = tensor([[-1.5378, -2.9234],
        [-2.2189, -1.4421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11671508103609085
Epoch 0, Step 834: train/loss = 0.27933916449546814, train/raw-loss = 0.2622983455657959, train/logprobs = tensor([[-1.0200, -4.3443],
        [-1.4476, -1.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17040841281414032
Epoch 0, Step 835: train/loss = 0.3248710334300995, train/raw-loss = 0.3100298345088959, train/logprobs = tensor([[-1.4857, -3.7092],
        [-1.6277, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1484123170375824
Epoch 0, Step 836: train/loss = 0.380820095539093, train/raw-loss = 0.3701448440551758, train/logprobs = tensor([[-1.6610, -3.1815],
        [-1.8909, -1.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10675239562988281
Epoch 0, Step 837: train/loss = 0.33123815059661865, train/raw-loss = 0.31538575887680054, train/logprobs = tensor([[-1.0635, -3.7187],
        [-1.4093, -1.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1585240364074707
Epoch 0, Step 838: train/loss = 0.16966158151626587, train/raw-loss = 0.14906786382198334, train/logprobs = tensor([[-1.7163, -5.9382],
        [-1.9978, -1.8125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2059372365474701
Epoch 0, Step 839: train/loss = 0.6393159627914429, train/raw-loss = 0.6368651390075684, train/logprobs = tensor([[-1.9103, -2.2958],
        [-2.4153, -2.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02450856938958168
Epoch 0, Step 840: train/loss = 0.3529111444950104, train/raw-loss = 0.3026607632637024, train/logprobs = tensor([[-2.0168, -5.6347],
        [-2.3724, -1.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5025037527084351
Epoch 0, Step 841: train/loss = 0.17987769842147827, train/raw-loss = 0.16433092951774597, train/logprobs = tensor([[-0.9354, -5.4309],
        [-1.3372, -1.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1554677039384842
Epoch 0, Step 842: train/loss = 0.31347912549972534, train/raw-loss = 0.3033023476600647, train/logprobs = tensor([[-1.7135, -3.9144],
        [-1.9813, -1.7647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10176780074834824
Epoch 0, Step 843: train/loss = 0.1881011426448822, train/raw-loss = 0.16926544904708862, train/logprobs = tensor([[-0.7024, -5.0153],
        [-1.4372, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18835683166980743
Epoch 0, Step 844: train/loss = 0.19781197607517242, train/raw-loss = 0.17664334177970886, train/logprobs = tensor([[-1.3707, -4.1524],
        [-1.8892, -1.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21168634295463562
Epoch 0, Step 845: train/loss = 0.4438621401786804, train/raw-loss = 0.427303284406662, train/logprobs = tensor([[-1.5130, -3.0643],
        [-2.1606, -1.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16558894515037537
Epoch 0, Step 846: train/loss = 0.5449584722518921, train/raw-loss = 0.5324686765670776, train/logprobs = tensor([[-1.7407, -2.6032],
        [-1.4276, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12489747256040573
Epoch 0, Step 847: train/loss = 0.19918784499168396, train/raw-loss = 0.17517460882663727, train/logprobs = tensor([[-1.3196, -4.2431],
        [-1.9040, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2401324212551117
Epoch 0, Step 848: train/loss = 0.3172827363014221, train/raw-loss = 0.30545032024383545, train/logprobs = tensor([[-1.5155, -3.4960],
        [-1.5711, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11832422763109207
Epoch 0, Step 849: train/loss = 0.5724075436592102, train/raw-loss = 0.5672674179077148, train/logprobs = tensor([[-1.6443, -2.3079],
        [-1.5162, -1.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051401011645793915
Epoch 0, Step 850: train/loss = 0.3080282211303711, train/raw-loss = 0.28853142261505127, train/logprobs = tensor([[-1.9350, -4.4505],
        [-2.2058, -1.3583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19496792554855347
Epoch 0, Step 851: train/loss = 0.503239095211029, train/raw-loss = 0.4937507212162018, train/logprobs = tensor([[-1.4875, -2.5127],
        [-1.3185, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0948839858174324
Epoch 0, Step 852: train/loss = 0.2530824542045593, train/raw-loss = 0.2205304205417633, train/logprobs = tensor([[-1.4792, -4.0149],
        [-2.5114, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.325520396232605
Epoch 0, Step 853: train/loss = 0.5241968631744385, train/raw-loss = 0.5190158486366272, train/logprobs = tensor([[-1.2795, -1.9388],
        [-1.4046, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05181030556559563
Epoch 0, Step 854: train/loss = 0.3965979516506195, train/raw-loss = 0.38734400272369385, train/logprobs = tensor([[-1.3771, -3.9716],
        [-1.4421, -1.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09253931045532227
Epoch 0, Step 855: train/loss = 0.4168579578399658, train/raw-loss = 0.4094932973384857, train/logprobs = tensor([[-1.8716, -3.1404],
        [-1.9839, -1.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07364688068628311
Epoch 0, Step 856: train/loss = 0.31629514694213867, train/raw-loss = 0.30406564474105835, train/logprobs = tensor([[-1.3083, -3.5732],
        [-1.7719, -1.6631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12229481339454651
Epoch 0, Step 857: train/loss = 0.1729615330696106, train/raw-loss = 0.15081530809402466, train/logprobs = tensor([[-1.5296, -5.2861],
        [-1.9462, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22146204113960266
Epoch 0, Step 858: train/loss = 0.42629334330558777, train/raw-loss = 0.4086710214614868, train/logprobs = tensor([[-1.8041, -3.8410],
        [-1.6533, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17622344195842743
Epoch 0, Step 859: train/loss = 0.433136522769928, train/raw-loss = 0.41901302337646484, train/logprobs = tensor([[-1.8116, -5.1318],
        [-1.5517, -2.2847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1412350833415985
Epoch 0, Step 860: train/loss = 0.4874536097049713, train/raw-loss = 0.4822498559951782, train/logprobs = tensor([[-1.0496, -1.5733],
        [-1.5031, -0.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052037760615348816
Epoch 0, Step 861: train/loss = 0.3208774924278259, train/raw-loss = 0.3019445240497589, train/logprobs = tensor([[-1.3039, -3.9423],
        [-1.4775, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18932940065860748
Epoch 0, Step 862: train/loss = 0.3993072211742401, train/raw-loss = 0.3914644718170166, train/logprobs = tensor([[-1.4551, -2.9267],
        [-1.7632, -1.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07842773199081421
Epoch 0, Step 863: train/loss = 0.3041744530200958, train/raw-loss = 0.29022783041000366, train/logprobs = tensor([[-1.5491, -4.3809],
        [-1.4364, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13946613669395447
Epoch 0, Step 864: train/loss = 0.3602522015571594, train/raw-loss = 0.3489133417606354, train/logprobs = tensor([[-1.5626, -2.9227],
        [-2.0296, -1.4142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11338844895362854
Epoch 0, Step 865: train/loss = 0.3467426002025604, train/raw-loss = 0.3295438289642334, train/logprobs = tensor([[-1.1913, -4.3131],
        [-1.5785, -1.2720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17198753356933594
Epoch 0, Step 866: train/loss = 0.33111125230789185, train/raw-loss = 0.3188677430152893, train/logprobs = tensor([[-1.9030, -3.2197],
        [-2.2931, -1.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12243462353944778
Epoch 0, Step 867: train/loss = 0.22890149056911469, train/raw-loss = 0.20824499428272247, train/logprobs = tensor([[-1.7211, -3.7997],
        [-1.9641, -0.9069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20656488835811615
Epoch 0, Step 868: train/loss = 0.3487743139266968, train/raw-loss = 0.3329453766345978, train/logprobs = tensor([[-1.2621, -3.4453],
        [-1.6373, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15828919410705566
Epoch 0, Step 869: train/loss = 0.1602979153394699, train/raw-loss = 0.13816297054290771, train/logprobs = tensor([[-1.2789, -5.6026],
        [-1.7495, -1.6735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22134938836097717
Epoch 0, Step 870: train/loss = 0.4274985194206238, train/raw-loss = 0.4127427339553833, train/logprobs = tensor([[-2.2575, -3.0378],
        [-2.2044, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1475580334663391
Epoch 0, Step 871: train/loss = 0.4525828957557678, train/raw-loss = 0.44747063517570496, train/logprobs = tensor([[-1.8552, -1.9859],
        [-2.0559, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051122672855854034
Epoch 0, Step 872: train/loss = 0.3187043070793152, train/raw-loss = 0.31009623408317566, train/logprobs = tensor([[-0.8248, -4.4922],
        [-1.0994, -1.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08608077466487885
Epoch 0, Step 873: train/loss = 0.23037123680114746, train/raw-loss = 0.21641521155834198, train/logprobs = tensor([[-1.4472, -4.8234],
        [-1.8915, -2.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13956007361412048
Epoch 0, Step 874: train/loss = 0.4641270041465759, train/raw-loss = 0.4588658809661865, train/logprobs = tensor([[-1.2172, -2.3131],
        [-1.6766, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05261138454079628
Epoch 0, Step 875: train/loss = 0.35986849665641785, train/raw-loss = 0.3449786901473999, train/logprobs = tensor([[-1.5319, -3.0304],
        [-1.8395, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14889824390411377
Epoch 0, Step 876: train/loss = 0.1557135283946991, train/raw-loss = 0.12583300471305847, train/logprobs = tensor([[-2.0804, -5.1229],
        [-2.2822, -1.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29880520701408386
Epoch 0, Step 877: train/loss = 0.49735772609710693, train/raw-loss = 0.49360933899879456, train/logprobs = tensor([[-1.0518, -1.8862],
        [-1.3811, -1.2383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0374840572476387
Epoch 0, Step 878: train/loss = 0.4610025882720947, train/raw-loss = 0.45214319229125977, train/logprobs = tensor([[-1.6634, -2.4015],
        [-2.0931, -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08859360218048096
Epoch 0, Step 879: train/loss = 0.3037029504776001, train/raw-loss = 0.28663939237594604, train/logprobs = tensor([[-0.8290, -3.0501],
        [-1.7338, -1.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1706356555223465
Epoch 0, Step 880: train/loss = 0.29396721720695496, train/raw-loss = 0.2830429971218109, train/logprobs = tensor([[-1.5798, -4.0461],
        [-1.9479, -1.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10924199223518372
Epoch 0, Step 881: train/loss = 0.3261193633079529, train/raw-loss = 0.313370019197464, train/logprobs = tensor([[-0.9432, -3.9606],
        [-1.2239, -1.0832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12749344110488892
Epoch 0, Step 882: train/loss = 0.33030951023101807, train/raw-loss = 0.2836676836013794, train/logprobs = tensor([[-1.6906, -7.1472],
        [-2.0374, -1.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46641820669174194
Epoch 0, Step 883: train/loss = 0.20928198099136353, train/raw-loss = 0.19198304414749146, train/logprobs = tensor([[-0.9710, -5.0124],
        [-1.5724, -1.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1729893684387207
Epoch 0, Step 884: train/loss = 0.4259989261627197, train/raw-loss = 0.41987234354019165, train/logprobs = tensor([[-1.1587, -2.7361],
        [-1.0529, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061265960335731506
Epoch 0, Step 885: train/loss = 0.3018721342086792, train/raw-loss = 0.2839307487010956, train/logprobs = tensor([[-1.0863, -3.6603],
        [-1.6247, -1.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17941424250602722
Epoch 0, Step 886: train/loss = 0.3798269033432007, train/raw-loss = 0.3561611771583557, train/logprobs = tensor([[-1.4925, -3.3302],
        [-1.8378, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23665732145309448
Epoch 0, Step 887: train/loss = 0.4257286787033081, train/raw-loss = 0.4173218607902527, train/logprobs = tensor([[-2.6325, -4.1901],
        [-2.0739, -1.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840681716799736
Epoch 0, Step 888: train/loss = 0.4652180075645447, train/raw-loss = 0.459206759929657, train/logprobs = tensor([[-1.0226, -2.1360],
        [-1.4397, -1.3019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06011245399713516
Epoch 0, Step 889: train/loss = 0.21723312139511108, train/raw-loss = 0.19945724308490753, train/logprobs = tensor([[-1.6064, -4.9603],
        [-2.0969, -1.7100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17775876820087433
Epoch 0, Step 890: train/loss = 0.2877582311630249, train/raw-loss = 0.2576182782649994, train/logprobs = tensor([[-2.1509, -5.0184],
        [-2.3641, -1.2900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3013995289802551
Epoch 0, Step 891: train/loss = 0.23002271354198456, train/raw-loss = 0.2095319628715515, train/logprobs = tensor([[-1.4771, -4.1129],
        [-1.6498, -1.1498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20490756630897522
Epoch 0, Step 892: train/loss = 0.4137084484100342, train/raw-loss = 0.39860981702804565, train/logprobs = tensor([[-1.7748, -3.1030],
        [-1.7499, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1509862244129181
Epoch 0, Step 893: train/loss = 0.3519619107246399, train/raw-loss = 0.33809709548950195, train/logprobs = tensor([[-1.2790, -3.1809],
        [-2.0399, -1.4576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13864806294441223
Epoch 0, Step 894: train/loss = 0.3651934862136841, train/raw-loss = 0.35759538412094116, train/logprobs = tensor([[-1.6129, -3.7957],
        [-1.5557, -1.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07598070800304413
Epoch 0, Step 895: train/loss = 0.2901333272457123, train/raw-loss = 0.2753678262233734, train/logprobs = tensor([[-1.4441, -3.4128],
        [-1.7663, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14765499532222748
Epoch 0, Step 896: train/loss = 0.1827128380537033, train/raw-loss = 0.15846051275730133, train/logprobs = tensor([[-1.7017, -5.4963],
        [-2.3959, -1.9577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2425232231616974
Epoch 0, Step 897: train/loss = 0.24833668768405914, train/raw-loss = 0.22295841574668884, train/logprobs = tensor([[-1.3318, -4.2056],
        [-1.9879, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25378257036209106
Epoch 0, Step 898: train/loss = 0.4118746817111969, train/raw-loss = 0.396378755569458, train/logprobs = tensor([[-2.4635, -5.8804],
        [-1.4043, -1.3822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15495911240577698
Epoch 0, Step 899: train/loss = 0.2985524535179138, train/raw-loss = 0.2729231119155884, train/logprobs = tensor([[-1.6730, -5.3031],
        [-1.9268, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25629299879074097
Epoch 0, Step 900: train/loss = 0.1820758581161499, train/raw-loss = 0.14160829782485962, train/logprobs = tensor([[-1.7028, -4.9079],
        [-2.5565, -1.1920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40467560291290283
Epoch 0, Step 901: train/loss = 0.1744966357946396, train/raw-loss = 0.14551249146461487, train/logprobs = tensor([[-2.0384, -4.8121],
        [-2.2241, -1.1380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2898414134979248
Epoch 0, Step 902: train/loss = 0.32312580943107605, train/raw-loss = 0.3070688843727112, train/logprobs = tensor([[-1.0130, -3.4946],
        [-1.7262, -1.5136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1605691760778427
Epoch 0, Step 903: train/loss = 0.3087332546710968, train/raw-loss = 0.2936435341835022, train/logprobs = tensor([[-1.3458, -4.3789],
        [-1.7666, -1.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15089711546897888
Epoch 0, Step 904: train/loss = 0.3373793363571167, train/raw-loss = 0.3228203356266022, train/logprobs = tensor([[-1.0936, -2.7081],
        [-1.6327, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14559005200862885
Epoch 0, Step 905: train/loss = 0.5078976154327393, train/raw-loss = 0.5003609657287598, train/logprobs = tensor([[-1.6251, -3.2726],
        [-1.4273, -1.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07536680996417999
Epoch 0, Step 906: train/loss = 0.24119259417057037, train/raw-loss = 0.22404052317142487, train/logprobs = tensor([[-1.4083, -5.5021],
        [-1.7633, -1.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17152059078216553
Epoch 0, Step 907: train/loss = 0.1966102123260498, train/raw-loss = 0.17722640931606293, train/logprobs = tensor([[-1.6155, -4.9661],
        [-1.9641, -1.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19383805990219116
Epoch 0, Step 908: train/loss = 0.3609038293361664, train/raw-loss = 0.3519037067890167, train/logprobs = tensor([[-2.1515, -3.2327],
        [-2.1690, -1.3584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09000138938426971
Epoch 0, Step 909: train/loss = 0.322525292634964, train/raw-loss = 0.3069606423377991, train/logprobs = tensor([[-1.0625, -2.7770],
        [-1.7857, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15564624965190887
Epoch 0, Step 910: train/loss = 0.27821123600006104, train/raw-loss = 0.2609093487262726, train/logprobs = tensor([[-1.5239, -3.8501],
        [-1.8053, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17301863431930542
Epoch 0, Step 911: train/loss = 0.2512378394603729, train/raw-loss = 0.2297872006893158, train/logprobs = tensor([[-2.4496, -4.8678],
        [-2.4569, -1.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2145063579082489
Epoch 0, Step 912: train/loss = 0.4464924931526184, train/raw-loss = 0.4345376491546631, train/logprobs = tensor([[-2.3334, -3.7127],
        [-1.7261, -0.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.119548499584198
Epoch 0, Step 913: train/loss = 0.3608356714248657, train/raw-loss = 0.34596526622772217, train/logprobs = tensor([[-1.1651, -3.3398],
        [-1.6533, -1.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14870397746562958
Epoch 0, Step 914: train/loss = 0.35406163334846497, train/raw-loss = 0.3448566198348999, train/logprobs = tensor([[-1.4296, -2.9293],
        [-2.0196, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09205005317926407
Epoch 0, Step 915: train/loss = 0.4777297377586365, train/raw-loss = 0.47081446647644043, train/logprobs = tensor([[-1.0923, -2.0990],
        [-1.3805, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915280222892761
Epoch 0, Step 916: train/loss = 0.26217183470726013, train/raw-loss = 0.2359897941350937, train/logprobs = tensor([[-2.0961, -5.0077],
        [-2.5887, -1.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2618202865123749
Epoch 0, Step 917: train/loss = 0.22778759896755219, train/raw-loss = 0.20601879060268402, train/logprobs = tensor([[-1.4582, -3.6782],
        [-1.9191, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21768812835216522
Epoch 0, Step 918: train/loss = 0.29144495725631714, train/raw-loss = 0.27808159589767456, train/logprobs = tensor([[-1.7201, -4.4508],
        [-2.1751, -1.6356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13363395631313324
Epoch 0, Step 919: train/loss = 0.2568110525608063, train/raw-loss = 0.241559237241745, train/logprobs = tensor([[-0.9809, -4.3107],
        [-1.9008, -1.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15251785516738892
Epoch 0, Step 920: train/loss = 0.3189687430858612, train/raw-loss = 0.26436716318130493, train/logprobs = tensor([[-1.9746, -6.5563],
        [-2.3555, -1.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5460156202316284
Epoch 0, Step 921: train/loss = 0.26791566610336304, train/raw-loss = 0.2468397617340088, train/logprobs = tensor([[-1.4924, -3.9566],
        [-2.1222, -1.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21075882017612457
Epoch 0, Step 922: train/loss = 0.3953647315502167, train/raw-loss = 0.3870076537132263, train/logprobs = tensor([[-1.4049, -2.9322],
        [-1.6563, -1.4118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08357062935829163
Epoch 0, Step 923: train/loss = 0.2997218370437622, train/raw-loss = 0.27992895245552063, train/logprobs = tensor([[-2.4382, -4.6097],
        [-2.1705, -1.3987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19792881608009338
Epoch 0, Step 924: train/loss = 0.3404580354690552, train/raw-loss = 0.32380035519599915, train/logprobs = tensor([[-1.2086, -3.8603],
        [-1.6646, -1.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16657695174217224
Epoch 0, Step 925: train/loss = 0.5454392433166504, train/raw-loss = 0.5374650359153748, train/logprobs = tensor([[-1.1638, -2.1036],
        [-1.5021, -1.3170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07974253594875336
Epoch 0, Step 926: train/loss = 0.2705000340938568, train/raw-loss = 0.25284454226493835, train/logprobs = tensor([[-1.4913, -5.5630],
        [-1.3705, -1.3796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17655490338802338
Epoch 0, Step 927: train/loss = 0.25050055980682373, train/raw-loss = 0.2306235283613205, train/logprobs = tensor([[-1.4592, -3.8561],
        [-2.3481, -1.3759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19877034425735474
Epoch 0, Step 928: train/loss = 0.3004075586795807, train/raw-loss = 0.2834627032279968, train/logprobs = tensor([[-1.7819, -3.5967],
        [-2.6637, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16944840550422668
Epoch 0, Step 929: train/loss = 0.4560258090496063, train/raw-loss = 0.45171913504600525, train/logprobs = tensor([[-0.6334, -2.2207],
        [-1.3905, -1.5817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043066758662462234
Epoch 0, Step 930: train/loss = 0.3565729856491089, train/raw-loss = 0.3469756245613098, train/logprobs = tensor([[-1.3430, -3.7482],
        [-1.8313, -1.8246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09597345441579819
Epoch 0, Step 931: train/loss = 0.39524662494659424, train/raw-loss = 0.3805020749568939, train/logprobs = tensor([[-0.7716, -3.2703],
        [-1.4076, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14744548499584198
Epoch 0, Step 932: train/loss = 0.3071073889732361, train/raw-loss = 0.2916252911090851, train/logprobs = tensor([[-2.0694, -4.6048],
        [-2.3649, -2.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15482082962989807
Epoch 0, Step 933: train/loss = 0.5296668410301208, train/raw-loss = 0.5234153270721436, train/logprobs = tensor([[-1.2948, -2.4356],
        [-1.3148, -1.3393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06251554936170578
Epoch 0, Step 934: train/loss = 0.16623272001743317, train/raw-loss = 0.12987180054187775, train/logprobs = tensor([[-1.4494, -6.2484],
        [-1.8426, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36360931396484375
Epoch 0, Step 935: train/loss = 0.4475700259208679, train/raw-loss = 0.4367034435272217, train/logprobs = tensor([[-2.4248, -4.9186],
        [-1.5557, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10866589844226837
Epoch 0, Step 936: train/loss = 0.39329737424850464, train/raw-loss = 0.3835635781288147, train/logprobs = tensor([[-0.8914, -2.0909],
        [-1.4650, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09733815491199493
Epoch 0, Step 937: train/loss = 0.37977877259254456, train/raw-loss = 0.3696434199810028, train/logprobs = tensor([[-1.8323, -3.7968],
        [-1.8750, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1013534814119339
Epoch 0, Step 938: train/loss = 0.4048994183540344, train/raw-loss = 0.38383978605270386, train/logprobs = tensor([[-2.5316, -3.1816],
        [-2.9712, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21059677004814148
Epoch 0, Step 939: train/loss = 0.6361950635910034, train/raw-loss = 0.6348163485527039, train/logprobs = tensor([[-1.0407, -1.2038],
        [-1.5504, -1.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013786863535642624
Epoch 0, Step 940: train/loss = 0.3487861752510071, train/raw-loss = 0.3309958577156067, train/logprobs = tensor([[-1.2107, -3.1144],
        [-2.1052, -1.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1779032051563263
Epoch 0, Step 941: train/loss = 0.3459387421607971, train/raw-loss = 0.3361717462539673, train/logprobs = tensor([[-1.7272, -3.9908],
        [-2.1504, -2.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0976698100566864
Epoch 0, Step 942: train/loss = 0.29503265023231506, train/raw-loss = 0.2758408188819885, train/logprobs = tensor([[-0.9077, -3.8199],
        [-1.1290, -0.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1919184923171997
Epoch 0, Step 943: train/loss = 0.29612797498703003, train/raw-loss = 0.2786775529384613, train/logprobs = tensor([[-1.4219, -3.8691],
        [-1.8618, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17450429499149323
Epoch 0, Step 944: train/loss = 0.2963312864303589, train/raw-loss = 0.2703726589679718, train/logprobs = tensor([[-1.1705, -4.4518],
        [-1.7382, -1.3813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25958630442619324
Epoch 0, Step 945: train/loss = 0.32394522428512573, train/raw-loss = 0.3092535138130188, train/logprobs = tensor([[-1.5634, -4.0956],
        [-2.0819, -1.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14691713452339172
Epoch 0, Step 946: train/loss = 0.3164837658405304, train/raw-loss = 0.3071562349796295, train/logprobs = tensor([[-1.0076, -3.3250],
        [-1.4289, -1.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09327565878629684
Epoch 0, Step 947: train/loss = 0.2049129754304886, train/raw-loss = 0.1806623935699463, train/logprobs = tensor([[-1.5065, -4.6317],
        [-2.0148, -1.0886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24250578880310059
Epoch 0, Step 948: train/loss = 0.35304147005081177, train/raw-loss = 0.3378528356552124, train/logprobs = tensor([[-0.9423, -4.1571],
        [-1.7561, -1.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1518862396478653
Epoch 0, Step 949: train/loss = 0.23724675178527832, train/raw-loss = 0.2108420729637146, train/logprobs = tensor([[-2.5112, -5.5360],
        [-2.7704, -2.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26404696702957153
Epoch 0, Step 950: train/loss = 0.19779008626937866, train/raw-loss = 0.1723172962665558, train/logprobs = tensor([[-1.3726, -4.6685],
        [-1.8314, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25472790002822876
Epoch 0, Step 951: train/loss = 0.23566654324531555, train/raw-loss = 0.2197367399930954, train/logprobs = tensor([[-1.4189, -4.1570],
        [-1.8153, -1.4746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15929803252220154
Epoch 0, Step 952: train/loss = 0.3282920718193054, train/raw-loss = 0.3121188282966614, train/logprobs = tensor([[-1.5330, -4.7969],
        [-2.0968, -2.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617322862148285
Epoch 0, Step 953: train/loss = 0.5429441928863525, train/raw-loss = 0.5317049026489258, train/logprobs = tensor([[-1.8466, -2.7156],
        [-2.0326, -1.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1123933270573616
Epoch 0, Step 954: train/loss = 0.3617485761642456, train/raw-loss = 0.345622181892395, train/logprobs = tensor([[-1.8284, -3.7004],
        [-2.2097, -1.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16126391291618347
Epoch 0, Step 955: train/loss = 0.20175576210021973, train/raw-loss = 0.1811194270849228, train/logprobs = tensor([[-1.1019, -4.8334],
        [-1.5124, -1.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20636343955993652
Epoch 0, Step 956: train/loss = 0.22347864508628845, train/raw-loss = 0.20108571648597717, train/logprobs = tensor([[-1.7032, -5.9928],
        [-2.2298, -2.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.223929300904274
Epoch 0, Step 957: train/loss = 0.2564998269081116, train/raw-loss = 0.23228703439235687, train/logprobs = tensor([[-1.6926, -4.4945],
        [-1.7501, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24212782084941864
Epoch 0, Step 958: train/loss = 0.41788536310195923, train/raw-loss = 0.4093571901321411, train/logprobs = tensor([[-1.8454, -2.8744],
        [-1.7052, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08528164774179459
Epoch 0, Step 959: train/loss = 0.2220509946346283, train/raw-loss = 0.19894824922084808, train/logprobs = tensor([[-1.4285, -4.7288],
        [-1.7109, -0.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2310275435447693
Epoch 0, Step 960: train/loss = 0.4421684443950653, train/raw-loss = 0.42706090211868286, train/logprobs = tensor([[-1.2376, -4.2785],
        [-1.0258, -1.5424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1510753631591797
Epoch 0, Step 961: train/loss = 0.2566985487937927, train/raw-loss = 0.2271265685558319, train/logprobs = tensor([[-2.7699, -5.4900],
        [-2.0329, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2957195043563843
Epoch 0, Step 962: train/loss = 0.19695532321929932, train/raw-loss = 0.16842839121818542, train/logprobs = tensor([[-1.9947, -4.8208],
        [-2.1034, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28526943922042847
Epoch 0, Step 963: train/loss = 0.45639514923095703, train/raw-loss = 0.44534245133399963, train/logprobs = tensor([[-1.7904, -2.8194],
        [-2.2880, -1.7100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11052697896957397
Epoch 0, Step 964: train/loss = 0.3240566849708557, train/raw-loss = 0.30669862031936646, train/logprobs = tensor([[-1.2829, -3.3675],
        [-2.1466, -1.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17358040809631348
Epoch 0, Step 965: train/loss = 0.12252775579690933, train/raw-loss = 0.08920284360647202, train/logprobs = tensor([[-1.6195, -6.6592],
        [-2.3185, -1.4936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3332492709159851
Epoch 0, Step 966: train/loss = 0.3757789134979248, train/raw-loss = 0.3636511564254761, train/logprobs = tensor([[-1.9766, -3.4941],
        [-2.4453, -1.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12127779424190521
Epoch 0, Step 967: train/loss = 0.2591465711593628, train/raw-loss = 0.24232184886932373, train/logprobs = tensor([[-1.2579, -4.2356],
        [-1.5687, -1.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16824708878993988
Epoch 0, Step 968: train/loss = 0.4768911600112915, train/raw-loss = 0.4651455879211426, train/logprobs = tensor([[-2.0803, -2.7619],
        [-2.4168, -1.5662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11745552718639374
Epoch 0, Step 969: train/loss = 0.4373907446861267, train/raw-loss = 0.42470479011535645, train/logprobs = tensor([[-1.0508, -2.7069],
        [-1.6067, -1.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1268593817949295
Epoch 0, Step 970: train/loss = 0.12075170129537582, train/raw-loss = 0.0820927768945694, train/logprobs = tensor([[-1.2861, -6.3050],
        [-1.9510, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38658928871154785
Epoch 0, Step 971: train/loss = 0.27509623765945435, train/raw-loss = 0.2509878873825073, train/logprobs = tensor([[-1.1850, -4.1565],
        [-1.8393, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2410835176706314
Epoch 0, Step 972: train/loss = 0.2717892825603485, train/raw-loss = 0.24502693116664886, train/logprobs = tensor([[-2.2544, -5.2572],
        [-2.3525, -1.3542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2676234841346741
Epoch 0, Step 973: train/loss = 0.2781361937522888, train/raw-loss = 0.26174548268318176, train/logprobs = tensor([[-1.4693, -3.9104],
        [-1.8863, -1.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16390658915042877
Epoch 0, Step 974: train/loss = 0.4682420492172241, train/raw-loss = 0.46206289529800415, train/logprobs = tensor([[-1.3462, -1.7979],
        [-1.8566, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06179158389568329
Epoch 0, Step 975: train/loss = 0.40145641565322876, train/raw-loss = 0.3913016617298126, train/logprobs = tensor([[-1.6057, -2.5522],
        [-2.0407, -1.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015474796295166
Epoch 0, Step 976: train/loss = 0.274930477142334, train/raw-loss = 0.25080105662345886, train/logprobs = tensor([[-1.6358, -4.9411],
        [-2.1797, -1.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24129405617713928
Epoch 0, Step 977: train/loss = 0.6200959086418152, train/raw-loss = 0.6123014092445374, train/logprobs = tensor([[-1.5457, -2.9795],
        [-1.5326, -1.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07794501632452011
Epoch 0, Step 978: train/loss = 0.3913291096687317, train/raw-loss = 0.371176153421402, train/logprobs = tensor([[-1.7825, -3.7549],
        [-2.4328, -1.6527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20152956247329712
Epoch 0, Step 979: train/loss = 0.16343103349208832, train/raw-loss = 0.13173149526119232, train/logprobs = tensor([[-1.5685, -5.1757],
        [-2.1637, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3169955313205719
Epoch 0, Step 980: train/loss = 0.273788183927536, train/raw-loss = 0.2531886100769043, train/logprobs = tensor([[-1.8511, -5.1282],
        [-2.3025, -1.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20599551498889923
Epoch 0, Step 981: train/loss = 0.3951294422149658, train/raw-loss = 0.37661609053611755, train/logprobs = tensor([[-1.6764, -3.3298],
        [-2.1978, -1.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18513330817222595
Epoch 0, Step 982: train/loss = 0.42024409770965576, train/raw-loss = 0.40866681933403015, train/logprobs = tensor([[-1.8197, -4.7371],
        [-1.5976, -1.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11577266454696655
Epoch 0, Step 983: train/loss = 0.23426072299480438, train/raw-loss = 0.1930658370256424, train/logprobs = tensor([[-2.1023, -6.8911],
        [-2.8844, -1.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.411949098110199
Epoch 0, Step 984: train/loss = 0.525249183177948, train/raw-loss = 0.5223513841629028, train/logprobs = tensor([[-1.3964, -1.3665],
        [-2.3361, -1.4610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028977956622838974
Epoch 0, Step 985: train/loss = 0.43804502487182617, train/raw-loss = 0.4296383261680603, train/logprobs = tensor([[-2.0650, -2.7304],
        [-2.3844, -1.6406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08406701683998108
Epoch 0, Step 986: train/loss = 0.4627286493778229, train/raw-loss = 0.43978750705718994, train/logprobs = tensor([[-2.5288, -4.2178],
        [-2.6250, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22941134870052338
Epoch 0, Step 987: train/loss = 0.46709132194519043, train/raw-loss = 0.4597123861312866, train/logprobs = tensor([[-2.2060, -3.3903],
        [-2.1343, -1.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07378920167684555
Epoch 0, Step 988: train/loss = 0.3427415192127228, train/raw-loss = 0.3211483061313629, train/logprobs = tensor([[-1.9808, -4.2261],
        [-2.3546, -1.9208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21593210101127625
Epoch 0, Step 989: train/loss = 0.27774083614349365, train/raw-loss = 0.2425733059644699, train/logprobs = tensor([[-1.2606, -6.1827],
        [-2.1678, -1.7154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35167521238327026
Epoch 0, Step 990: train/loss = 0.43664151430130005, train/raw-loss = 0.4239575266838074, train/logprobs = tensor([[-2.2705, -3.0203],
        [-2.4832, -1.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12683989107608795
Epoch 0, Step 991: train/loss = 0.16946940124034882, train/raw-loss = 0.14851917326450348, train/logprobs = tensor([[-1.2345, -6.2739],
        [-2.0012, -1.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.209502175450325
Epoch 0, Step 992: train/loss = 0.33507925271987915, train/raw-loss = 0.31656795740127563, train/logprobs = tensor([[-1.4348, -5.0036],
        [-2.1194, -2.0436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1851128786802292
Epoch 0, Step 993: train/loss = 0.21374624967575073, train/raw-loss = 0.18331976234912872, train/logprobs = tensor([[-1.7023, -4.2029],
        [-3.0771, -1.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30426502227783203
Epoch 0, Step 994: train/loss = 0.43278270959854126, train/raw-loss = 0.4174109399318695, train/logprobs = tensor([[-2.1701, -3.8642],
        [-3.0347, -2.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1537177562713623
Epoch 0, Step 995: train/loss = 0.17454546689987183, train/raw-loss = 0.1519380807876587, train/logprobs = tensor([[-1.3556, -4.9096],
        [-2.0542, -1.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22607380151748657
Epoch 0, Step 996: train/loss = 0.2482905238866806, train/raw-loss = 0.2331945300102234, train/logprobs = tensor([[-2.1177, -4.5457],
        [-1.9896, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1509600728750229
Epoch 0, Step 997: train/loss = 0.21196475625038147, train/raw-loss = 0.18723775446414948, train/logprobs = tensor([[-1.5366, -6.0433],
        [-1.7913, -1.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.247269868850708
Epoch 0, Step 998: train/loss = 0.1925237774848938, train/raw-loss = 0.16309934854507446, train/logprobs = tensor([[-1.6258, -4.7546],
        [-2.2120, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2942441999912262
Epoch 0, Step 999: train/loss = 0.31174299120903015, train/raw-loss = 0.29133743047714233, train/logprobs = tensor([[-1.9179, -2.8554],
        [-3.0947, -1.4309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20405563712120056
eval/loss: 0.2896627187728882
Epoch 0, Step 1000: train/loss = 0.5627431869506836, train/raw-loss = 0.5535627603530884, train/logprobs = tensor([[-1.9369, -2.3413],
        [-2.3271, -1.7504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09180435538291931
Epoch 0, Step 1001: train/loss = 0.17534855008125305, train/raw-loss = 0.15584418177604675, train/logprobs = tensor([[-1.5627, -6.1133],
        [-2.5154, -2.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19504377245903015
Epoch 0, Step 1002: train/loss = 0.3391229212284088, train/raw-loss = 0.32160279154777527, train/logprobs = tensor([[-1.1376, -3.3077],
        [-1.9598, -1.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17520122230052948
Epoch 0, Step 1003: train/loss = 0.4197450280189514, train/raw-loss = 0.4117152988910675, train/logprobs = tensor([[-1.4524, -1.9851],
        [-2.3908, -1.4495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08029704540967941
Epoch 0, Step 1004: train/loss = 0.28812602162361145, train/raw-loss = 0.26948121190071106, train/logprobs = tensor([[-1.8875, -3.1760],
        [-3.2479, -1.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18644815683364868
Epoch 0, Step 1005: train/loss = 0.12341734766960144, train/raw-loss = 0.10074275732040405, train/logprobs = tensor([[-1.5078, -6.6483],
        [-1.9452, -1.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22674590349197388
Epoch 0, Step 1006: train/loss = 0.6964753866195679, train/raw-loss = 0.6962865591049194, train/logprobs = tensor([[-1.1939, -1.1026],
        [-1.4334, -1.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018871256615966558
Epoch 0, Step 1007: train/loss = 0.4153081476688385, train/raw-loss = 0.3983866274356842, train/logprobs = tensor([[-2.8580, -4.2200],
        [-2.4534, -1.3106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16921520233154297
Epoch 0, Step 1008: train/loss = 0.4556392729282379, train/raw-loss = 0.44419997930526733, train/logprobs = tensor([[-1.6533, -2.4336],
        [-2.7580, -1.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11439324915409088
Epoch 0, Step 1009: train/loss = 0.0906473845243454, train/raw-loss = 0.0463767871260643, train/logprobs = tensor([[-1.3471, -7.4175],
        [-2.2543, -1.4692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44270598888397217
Epoch 0, Step 1010: train/loss = 0.19534066319465637, train/raw-loss = 0.16551007330417633, train/logprobs = tensor([[-2.8645, -5.3485],
        [-3.1707, -1.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29830580949783325
Epoch 0, Step 1011: train/loss = 0.15813684463500977, train/raw-loss = 0.1116047278046608, train/logprobs = tensor([[-1.7095, -6.9763],
        [-2.3259, -0.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4653211534023285
Epoch 0, Step 1012: train/loss = 0.25012004375457764, train/raw-loss = 0.22423678636550903, train/logprobs = tensor([[-2.2485, -5.2865],
        [-2.6618, -1.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2588326334953308
Epoch 0, Step 1013: train/loss = 0.45219406485557556, train/raw-loss = 0.4470117688179016, train/logprobs = tensor([[-1.6299, -2.4829],
        [-2.1624, -1.6581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05182316526770592
Epoch 0, Step 1014: train/loss = 0.4080692529678345, train/raw-loss = 0.39347416162490845, train/logprobs = tensor([[-2.0021, -3.4662],
        [-2.0935, -1.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14595088362693787
Epoch 0, Step 1015: train/loss = 0.17035230994224548, train/raw-loss = 0.10195108503103256, train/logprobs = tensor([[-2.5647, -9.8783],
        [-2.5426, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6840123534202576
Epoch 0, Step 1016: train/loss = 0.18363898992538452, train/raw-loss = 0.16086435317993164, train/logprobs = tensor([[-1.2704, -4.5032],
        [-2.1420, -1.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22774648666381836
Epoch 0, Step 1017: train/loss = 0.31345123052597046, train/raw-loss = 0.2927608788013458, train/logprobs = tensor([[-1.5572, -3.2665],
        [-2.5454, -1.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20690375566482544
Epoch 0, Step 1018: train/loss = 0.2460387945175171, train/raw-loss = 0.22232407331466675, train/logprobs = tensor([[-2.1922, -4.2957],
        [-2.1678, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23714718222618103
Epoch 0, Step 1019: train/loss = 0.2617943286895752, train/raw-loss = 0.23363789916038513, train/logprobs = tensor([[-1.4364, -4.0496],
        [-2.4237, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28156450390815735
Epoch 0, Step 1020: train/loss = 0.5318097472190857, train/raw-loss = 0.5234662890434265, train/logprobs = tensor([[-2.6696, -3.1881],
        [-2.0976, -1.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08343489468097687
Epoch 0, Step 1021: train/loss = 0.363388329744339, train/raw-loss = 0.3480975329875946, train/logprobs = tensor([[-1.2854, -3.0583],
        [-1.9743, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15290795266628265
Epoch 0, Step 1022: train/loss = 0.27822744846343994, train/raw-loss = 0.2588142454624176, train/logprobs = tensor([[-2.1137, -4.9675],
        [-2.0718, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19413211941719055
Epoch 0, Step 1023: train/loss = 0.28842291235923767, train/raw-loss = 0.2636937201023102, train/logprobs = tensor([[-1.8744, -4.9176],
        [-2.0360, -1.0060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24729187786579132
Epoch 0, Step 1024: train/loss = 0.20074677467346191, train/raw-loss = 0.17648586630821228, train/logprobs = tensor([[-2.0336, -5.7735],
        [-2.2727, -1.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24260900914669037
Epoch 0, Step 1025: train/loss = 0.3574671149253845, train/raw-loss = 0.3366243839263916, train/logprobs = tensor([[-1.9598, -3.9022],
        [-2.4005, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20842722058296204
Epoch 0, Step 1026: train/loss = 0.2891550660133362, train/raw-loss = 0.278142511844635, train/logprobs = tensor([[-1.8628, -4.2067],
        [-2.0115, -1.9549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11012550443410873
Epoch 0, Step 1027: train/loss = 0.2770208716392517, train/raw-loss = 0.25584760308265686, train/logprobs = tensor([[-3.2262, -6.1478],
        [-2.3712, -1.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2117326259613037
Epoch 0, Step 1028: train/loss = 0.3546287417411804, train/raw-loss = 0.3297595977783203, train/logprobs = tensor([[-1.3274, -4.0623],
        [-2.2973, -1.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24869118630886078
Epoch 0, Step 1029: train/loss = 0.3722051680088043, train/raw-loss = 0.3562379479408264, train/logprobs = tensor([[-2.6652, -3.3774],
        [-2.7918, -1.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1596723198890686
Epoch 0, Step 1030: train/loss = 0.4141573905944824, train/raw-loss = 0.3887830972671509, train/logprobs = tensor([[-2.3183, -4.4574],
        [-2.7945, -1.3581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25374266505241394
Epoch 0, Step 1031: train/loss = 0.28251081705093384, train/raw-loss = 0.2553788721561432, train/logprobs = tensor([[-1.6109, -6.0828],
        [-2.2210, -1.8246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713194787502289
Epoch 0, Step 1032: train/loss = 0.35405585169792175, train/raw-loss = 0.3366755247116089, train/logprobs = tensor([[-1.3524, -3.9752],
        [-2.1358, -1.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17380307614803314
Epoch 0, Step 1033: train/loss = 0.30997616052627563, train/raw-loss = 0.28948700428009033, train/logprobs = tensor([[-1.9430, -5.2799],
        [-1.5917, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20489178597927094
Epoch 0, Step 1034: train/loss = 0.3527818024158478, train/raw-loss = 0.32816600799560547, train/logprobs = tensor([[-1.9896, -3.9247],
        [-2.7656, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24615779519081116
Epoch 0, Step 1035: train/loss = 0.23901662230491638, train/raw-loss = 0.22075805068016052, train/logprobs = tensor([[-1.2787, -3.9980],
        [-2.3794, -1.6275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1825857162475586
Epoch 0, Step 1036: train/loss = 0.4086451530456543, train/raw-loss = 0.39728888869285583, train/logprobs = tensor([[-1.8353, -2.7062],
        [-2.0647, -1.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11356271803379059
Epoch 0, Step 1037: train/loss = 0.22978627681732178, train/raw-loss = 0.20697079598903656, train/logprobs = tensor([[-1.9590, -3.9968],
        [-2.2608, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22815462946891785
Epoch 0, Step 1038: train/loss = 0.41612204909324646, train/raw-loss = 0.402317613363266, train/logprobs = tensor([[-1.6195, -2.9324],
        [-1.9345, -1.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13804467022418976
Epoch 0, Step 1039: train/loss = 0.151490718126297, train/raw-loss = 0.10486999154090881, train/logprobs = tensor([[-1.7550, -6.2955],
        [-3.0250, -1.2777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4662072956562042
Epoch 0, Step 1040: train/loss = 0.15702873468399048, train/raw-loss = 0.13002949953079224, train/logprobs = tensor([[-1.3631, -5.4538],
        [-2.2723, -1.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26999229192733765
Epoch 0, Step 1041: train/loss = 0.3256908655166626, train/raw-loss = 0.3067489564418793, train/logprobs = tensor([[-1.9100, -3.4256],
        [-2.9709, -1.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18941938877105713
Epoch 0, Step 1042: train/loss = 0.2642892003059387, train/raw-loss = 0.231333926320076, train/logprobs = tensor([[-1.5841, -4.9117],
        [-1.9403, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32955271005630493
Epoch 0, Step 1043: train/loss = 0.28958189487457275, train/raw-loss = 0.2748139798641205, train/logprobs = tensor([[-1.1472, -3.1360],
        [-2.1832, -1.5202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14767883718013763
Epoch 0, Step 1044: train/loss = 0.374554306268692, train/raw-loss = 0.36307916045188904, train/logprobs = tensor([[-1.2006, -3.1222],
        [-1.9341, -1.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11475154757499695
Epoch 0, Step 1045: train/loss = 0.20957991480827332, train/raw-loss = 0.18502211570739746, train/logprobs = tensor([[-1.9236, -5.2745],
        [-1.7836, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24557802081108093
Epoch 0, Step 1046: train/loss = 0.34661129117012024, train/raw-loss = 0.3283177614212036, train/logprobs = tensor([[-1.4589, -3.5896],
        [-1.9315, -1.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182935431599617
Epoch 0, Step 1047: train/loss = 0.346754252910614, train/raw-loss = 0.3365132212638855, train/logprobs = tensor([[-1.6542, -2.8965],
        [-2.5317, -1.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10240988433361053
Epoch 0, Step 1048: train/loss = 0.34589454531669617, train/raw-loss = 0.3239040970802307, train/logprobs = tensor([[-1.9977, -4.4318],
        [-2.3247, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21990427374839783
Epoch 0, Step 1049: train/loss = 0.16396436095237732, train/raw-loss = 0.13584478199481964, train/logprobs = tensor([[-1.1367, -5.7015],
        [-2.5032, -2.3137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28119590878486633
Epoch 0, Step 1050: train/loss = 0.40629974007606506, train/raw-loss = 0.3855011761188507, train/logprobs = tensor([[-1.4988, -3.2915],
        [-2.0272, -1.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2079857885837555
Epoch 0, Step 1051: train/loss = 0.27289512753486633, train/raw-loss = 0.25837814807891846, train/logprobs = tensor([[-2.0841, -5.3444],
        [-2.2110, -2.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1451701521873474
Epoch 0, Step 1052: train/loss = 0.23462240397930145, train/raw-loss = 0.21422520279884338, train/logprobs = tensor([[-1.5029, -4.3820],
        [-1.9616, -1.3365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20397213101387024
Epoch 0, Step 1053: train/loss = 0.20047545433044434, train/raw-loss = 0.1703309714794159, train/logprobs = tensor([[-1.8549, -4.8918],
        [-2.5916, -1.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30144476890563965
Epoch 0, Step 1054: train/loss = 0.4011409878730774, train/raw-loss = 0.38856518268585205, train/logprobs = tensor([[-1.1124, -2.7835],
        [-1.8115, -1.4870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.125758096575737
Epoch 0, Step 1055: train/loss = 0.29872801899909973, train/raw-loss = 0.2848376929759979, train/logprobs = tensor([[-2.2255, -3.5549],
        [-2.4577, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13890349864959717
Epoch 0, Step 1056: train/loss = 0.1922764927148819, train/raw-loss = 0.15943899750709534, train/logprobs = tensor([[-1.4156, -4.0873],
        [-2.5287, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32837486267089844
Epoch 0, Step 1057: train/loss = 0.2950178384780884, train/raw-loss = 0.2700895667076111, train/logprobs = tensor([[-1.9815, -5.4236],
        [-1.7145, -1.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2492826282978058
Epoch 0, Step 1058: train/loss = 0.3249408006668091, train/raw-loss = 0.3006594777107239, train/logprobs = tensor([[-2.1777, -5.0740],
        [-2.5667, -1.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24281319975852966
Epoch 0, Step 1059: train/loss = 0.4331439435482025, train/raw-loss = 0.4204080402851105, train/logprobs = tensor([[-1.6592, -2.8081],
        [-2.9057, -2.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12735886871814728
Epoch 0, Step 1060: train/loss = 0.23751430213451385, train/raw-loss = 0.20655806362628937, train/logprobs = tensor([[-1.0833, -5.0237],
        [-2.1583, -1.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3095625340938568
Epoch 0, Step 1061: train/loss = 0.2625022530555725, train/raw-loss = 0.2402881383895874, train/logprobs = tensor([[-2.7572, -4.0198],
        [-3.4784, -1.6637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22214102745056152
Epoch 0, Step 1062: train/loss = 0.3537212610244751, train/raw-loss = 0.33657848834991455, train/logprobs = tensor([[-1.7142, -2.9640],
        [-2.5244, -1.5011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1714279055595398
Epoch 0, Step 1063: train/loss = 0.2933938503265381, train/raw-loss = 0.26943737268447876, train/logprobs = tensor([[-1.8150, -4.1636],
        [-3.1055, -1.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2395647168159485
Epoch 0, Step 1064: train/loss = 0.266057550907135, train/raw-loss = 0.23309199512004852, train/logprobs = tensor([[-1.7540, -4.3568],
        [-2.2917, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32965531945228577
Epoch 0, Step 1065: train/loss = 0.23949848115444183, train/raw-loss = 0.21461904048919678, train/logprobs = tensor([[-1.6386, -5.2360],
        [-2.4698, -2.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24879440665245056
Epoch 0, Step 1066: train/loss = 0.12294377386569977, train/raw-loss = 0.06824514269828796, train/logprobs = tensor([[-1.7226, -7.6948],
        [-2.7849, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5469863414764404
Epoch 0, Step 1067: train/loss = 0.22910812497138977, train/raw-loss = 0.20648321509361267, train/logprobs = tensor([[-1.6290, -5.0221],
        [-1.9665, -1.5687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22624894976615906
Epoch 0, Step 1068: train/loss = 0.42223262786865234, train/raw-loss = 0.40702390670776367, train/logprobs = tensor([[-1.5216, -3.6469],
        [-2.2406, -2.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15208709239959717
Epoch 0, Step 1069: train/loss = 0.29121673107147217, train/raw-loss = 0.25173234939575195, train/logprobs = tensor([[-1.5889, -4.7730],
        [-2.5171, -1.3168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3948437571525574
Epoch 0, Step 1070: train/loss = 0.21138611435890198, train/raw-loss = 0.1792447865009308, train/logprobs = tensor([[-1.4103, -5.4251],
        [-2.4517, -1.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32141321897506714
Epoch 0, Step 1071: train/loss = 0.29589003324508667, train/raw-loss = 0.2666884660720825, train/logprobs = tensor([[-2.7385, -6.3461],
        [-2.7118, -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29201555252075195
Epoch 0, Step 1072: train/loss = 0.4084616005420685, train/raw-loss = 0.39267557859420776, train/logprobs = tensor([[-2.5601, -3.6642],
        [-2.5519, -1.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15786020457744598
Epoch 0, Step 1073: train/loss = 0.2468854784965515, train/raw-loss = 0.20243310928344727, train/logprobs = tensor([[-1.5479, -5.4735],
        [-2.4989, -0.7621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4445234537124634
Epoch 0, Step 1074: train/loss = 0.46988445520401, train/raw-loss = 0.4591235816478729, train/logprobs = tensor([[-1.8917, -2.9513],
        [-2.2450, -1.6409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076083555817604
Epoch 0, Step 1075: train/loss = 0.2866166830062866, train/raw-loss = 0.24968692660331726, train/logprobs = tensor([[-1.8019, -5.4753],
        [-2.7149, -1.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3692978024482727
Epoch 0, Step 1076: train/loss = 0.33162686228752136, train/raw-loss = 0.31048113107681274, train/logprobs = tensor([[-1.6244, -3.5024],
        [-2.5825, -1.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21145716309547424
Epoch 0, Step 1077: train/loss = 0.4173838794231415, train/raw-loss = 0.4009174704551697, train/logprobs = tensor([[-1.9511, -4.2181],
        [-2.6728, -2.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16466420888900757
Epoch 0, Step 1078: train/loss = 0.22411233186721802, train/raw-loss = 0.19913747906684875, train/logprobs = tensor([[-1.4821, -3.9579],
        [-2.6811, -1.6471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24974840879440308
Epoch 0, Step 1079: train/loss = 0.13080838322639465, train/raw-loss = 0.09483521431684494, train/logprobs = tensor([[-1.4351, -7.1658],
        [-2.7602, -2.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3597317934036255
Epoch 0, Step 1080: train/loss = 0.1914469599723816, train/raw-loss = 0.15802153944969177, train/logprobs = tensor([[-1.7933, -6.3070],
        [-2.2938, -1.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33425432443618774
Epoch 0, Step 1081: train/loss = 0.42503851652145386, train/raw-loss = 0.41224443912506104, train/logprobs = tensor([[-1.8167, -4.1927],
        [-1.8943, -2.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12794096767902374
Epoch 0, Step 1082: train/loss = 0.12829303741455078, train/raw-loss = 0.09575894474983215, train/logprobs = tensor([[-1.1630, -5.4282],
        [-1.7589, -0.8101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3253409266471863
Epoch 0, Step 1083: train/loss = 0.27224159240722656, train/raw-loss = 0.2471628040075302, train/logprobs = tensor([[-1.7842, -4.9250],
        [-2.7974, -1.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25078776478767395
Epoch 0, Step 1084: train/loss = 0.12068714201450348, train/raw-loss = 0.07381150126457214, train/logprobs = tensor([[-1.7206, -7.5540],
        [-2.6912, -1.2539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46875640749931335
Epoch 0, Step 1085: train/loss = 0.325649619102478, train/raw-loss = 0.31037193536758423, train/logprobs = tensor([[-2.5041, -4.3248],
        [-3.4552, -2.4109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15277698636054993
Epoch 0, Step 1086: train/loss = 0.11603952199220657, train/raw-loss = 0.07173900306224823, train/logprobs = tensor([[-1.7115, -6.1598],
        [-2.4467, -0.8780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.443005234003067
Epoch 0, Step 1087: train/loss = 0.31044888496398926, train/raw-loss = 0.29203304648399353, train/logprobs = tensor([[-2.0175, -4.6747],
        [-2.9145, -1.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18415865302085876
Epoch 0, Step 1088: train/loss = 0.3655751645565033, train/raw-loss = 0.352925568819046, train/logprobs = tensor([[-1.7160, -2.5473],
        [-3.4735, -2.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12649619579315186
Epoch 0, Step 1089: train/loss = 0.22996260225772858, train/raw-loss = 0.19680610299110413, train/logprobs = tensor([[-1.6995, -5.5056],
        [-2.0192, -0.5296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33156487345695496
Epoch 0, Step 1090: train/loss = 0.517337441444397, train/raw-loss = 0.47895801067352295, train/logprobs = tensor([[-2.2001, -4.0524],
        [-3.1498, -1.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38379406929016113
Epoch 0, Step 1091: train/loss = 0.3235341012477875, train/raw-loss = 0.3019355237483978, train/logprobs = tensor([[-1.7519, -3.5933],
        [-3.0636, -1.9553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2159857153892517
Epoch 0, Step 1092: train/loss = 0.4271728992462158, train/raw-loss = 0.4003234803676605, train/logprobs = tensor([[-2.7191, -4.8301],
        [-2.4077, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26849421858787537
Epoch 0, Step 1093: train/loss = 0.24963228404521942, train/raw-loss = 0.22597770392894745, train/logprobs = tensor([[-1.7763, -3.8391],
        [-3.0492, -1.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23654578626155853
Epoch 0, Step 1094: train/loss = 0.28530433773994446, train/raw-loss = 0.2658602297306061, train/logprobs = tensor([[-1.8197, -3.6103],
        [-3.1859, -1.7945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19444097578525543
Epoch 0, Step 1095: train/loss = 0.2431652843952179, train/raw-loss = 0.21338357031345367, train/logprobs = tensor([[-2.2280, -4.6113],
        [-3.4296, -2.4084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2978169918060303
Epoch 0, Step 1096: train/loss = 0.2153814435005188, train/raw-loss = 0.1890665888786316, train/logprobs = tensor([[-1.8223, -4.7638],
        [-3.1716, -2.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26314857602119446
Epoch 0, Step 1097: train/loss = 0.19128122925758362, train/raw-loss = 0.15273724496364594, train/logprobs = tensor([[-1.9769, -5.6253],
        [-2.3617, -1.2630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3854398727416992
Epoch 0, Step 1098: train/loss = 0.13186880946159363, train/raw-loss = 0.09005670249462128, train/logprobs = tensor([[-1.2386, -6.0069],
        [-2.3599, -1.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41812098026275635
Epoch 0, Step 1099: train/loss = 0.45651867985725403, train/raw-loss = 0.4463767409324646, train/logprobs = tensor([[-1.4113, -3.2232],
        [-2.2448, -2.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10141906887292862
Epoch 0, Step 1100: train/loss = 0.16769078373908997, train/raw-loss = 0.12068817019462585, train/logprobs = tensor([[-2.2039, -6.7218],
        [-3.0194, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4700261354446411
Epoch 0, Step 1101: train/loss = 0.46792253851890564, train/raw-loss = 0.4352777302265167, train/logprobs = tensor([[-1.2127, -2.8140],
        [-2.6181, -1.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32644787430763245
Epoch 0, Step 1102: train/loss = 0.16517210006713867, train/raw-loss = 0.14114317297935486, train/logprobs = tensor([[-1.6195, -5.3414],
        [-2.6325, -2.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24028941988945007
Epoch 0, Step 1103: train/loss = 0.2678070068359375, train/raw-loss = 0.24604997038841248, train/logprobs = tensor([[-1.4979, -4.6863],
        [-2.5367, -2.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21757034957408905
Epoch 0, Step 1104: train/loss = 0.2350519597530365, train/raw-loss = 0.21549980342388153, train/logprobs = tensor([[-1.9271, -4.6124],
        [-2.8609, -1.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19552145898342133
Epoch 0, Step 1105: train/loss = 0.15921500325202942, train/raw-loss = 0.12416082620620728, train/logprobs = tensor([[-1.4598, -6.7900],
        [-2.1847, -1.6930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35054171085357666
Epoch 0, Step 1106: train/loss = 0.2795581817626953, train/raw-loss = 0.2625342011451721, train/logprobs = tensor([[-2.5957, -3.9431],
        [-2.8064, -1.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17023980617523193
Epoch 0, Step 1107: train/loss = 0.24240291118621826, train/raw-loss = 0.2053966075181961, train/logprobs = tensor([[-1.8286, -6.8963],
        [-2.4953, -1.7145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3700629472732544
Epoch 0, Step 1108: train/loss = 0.29628777503967285, train/raw-loss = 0.2741730809211731, train/logprobs = tensor([[-1.6121, -3.7303],
        [-2.5963, -1.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22114692628383636
Epoch 0, Step 1109: train/loss = 0.20152857899665833, train/raw-loss = 0.1726911962032318, train/logprobs = tensor([[-2.6727, -5.2959],
        [-3.2877, -2.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28837376832962036
Epoch 0, Step 1110: train/loss = 0.1448085755109787, train/raw-loss = 0.11263345181941986, train/logprobs = tensor([[-1.4413, -5.1144],
        [-2.3276, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32175126671791077
Epoch 0, Step 1111: train/loss = 0.49873679876327515, train/raw-loss = 0.47839850187301636, train/logprobs = tensor([[-2.2868, -4.5212],
        [-3.2548, -2.4591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2033829241991043
Epoch 0, Step 1112: train/loss = 0.38044220209121704, train/raw-loss = 0.35239678621292114, train/logprobs = tensor([[-1.6724, -4.4582],
        [-2.2989, -1.6345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2804539203643799
Epoch 0, Step 1113: train/loss = 0.5490708947181702, train/raw-loss = 0.5416955947875977, train/logprobs = tensor([[-2.5669, -3.4252],
        [-1.9417, -1.6093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07375364005565643
Epoch 0, Step 1114: train/loss = 0.3327372372150421, train/raw-loss = 0.3063322901725769, train/logprobs = tensor([[-1.6584, -4.9141],
        [-2.7530, -1.7328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640495300292969
Epoch 0, Step 1115: train/loss = 0.2798633277416229, train/raw-loss = 0.25238603353500366, train/logprobs = tensor([[-2.0646, -5.0733],
        [-3.3820, -2.5119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27477261424064636
Epoch 0, Step 1116: train/loss = 0.307674378156662, train/raw-loss = 0.2845516800880432, train/logprobs = tensor([[-1.9337, -5.0753],
        [-2.0170, -1.5540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23122696578502655
Epoch 0, Step 1117: train/loss = 0.2943294942378998, train/raw-loss = 0.2713032364845276, train/logprobs = tensor([[-1.8779, -4.5881],
        [-3.0740, -1.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23026248812675476
Epoch 0, Step 1118: train/loss = 0.2886500060558319, train/raw-loss = 0.25888732075691223, train/logprobs = tensor([[-1.0654, -5.3141],
        [-2.0332, -1.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297626793384552
Epoch 0, Step 1119: train/loss = 0.3090156316757202, train/raw-loss = 0.2799415588378906, train/logprobs = tensor([[-1.4018, -5.0646],
        [-2.5959, -1.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2907405495643616
Epoch 0, Step 1120: train/loss = 0.31359338760375977, train/raw-loss = 0.2865973711013794, train/logprobs = tensor([[-2.3667, -5.1456],
        [-3.5952, -2.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2699599862098694
Epoch 0, Step 1121: train/loss = 0.3610709011554718, train/raw-loss = 0.34653306007385254, train/logprobs = tensor([[-2.9069, -4.4359],
        [-2.7455, -2.0274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14537835121154785
Epoch 0, Step 1122: train/loss = 0.23162320256233215, train/raw-loss = 0.19722703099250793, train/logprobs = tensor([[-2.5215, -8.1984],
        [-3.5887, -2.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3439618945121765
Epoch 0, Step 1123: train/loss = 0.25063690543174744, train/raw-loss = 0.21384325623512268, train/logprobs = tensor([[-3.0219, -7.3436],
        [-3.6896, -2.4741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3679366409778595
Epoch 0, Step 1124: train/loss = 0.2325650453567505, train/raw-loss = 0.20254001021385193, train/logprobs = tensor([[-3.5023, -5.9715],
        [-3.7581, -1.9341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3002502918243408
Epoch 0, Step 1125: train/loss = 0.4611671268939972, train/raw-loss = 0.45380955934524536, train/logprobs = tensor([[-1.2210, -2.1183],
        [-2.3973, -2.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07357566803693771
Epoch 0, Step 1126: train/loss = 0.17284652590751648, train/raw-loss = 0.13275916874408722, train/logprobs = tensor([[-1.8613, -5.5027],
        [-3.0983, -1.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40087366104125977
Epoch 0, Step 1127: train/loss = 0.17063766717910767, train/raw-loss = 0.13807597756385803, train/logprobs = tensor([[-2.5838, -5.6844],
        [-3.4809, -2.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3256170451641083
Epoch 0, Step 1128: train/loss = 0.2739388346672058, train/raw-loss = 0.2533746063709259, train/logprobs = tensor([[-2.5546, -4.8111],
        [-3.4744, -2.5069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056419551372528
Epoch 0, Step 1129: train/loss = 0.12255941331386566, train/raw-loss = 0.07686111330986023, train/logprobs = tensor([[-1.2455, -6.5409],
        [-2.7947, -1.3949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4569830000400543
Epoch 0, Step 1130: train/loss = 0.12310443818569183, train/raw-loss = 0.08628173172473907, train/logprobs = tensor([[-2.0962, -6.0628],
        [-3.7500, -2.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3682270646095276
Epoch 0, Step 1131: train/loss = 0.42338845133781433, train/raw-loss = 0.40460026264190674, train/logprobs = tensor([[-1.9158, -3.6893],
        [-2.9852, -1.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18788185715675354
Epoch 0, Step 1132: train/loss = 0.1615760326385498, train/raw-loss = 0.12627172470092773, train/logprobs = tensor([[-2.5899, -6.5128],
        [-3.0540, -2.1614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3530430793762207
Epoch 0, Step 1133: train/loss = 0.30810871720314026, train/raw-loss = 0.2825058698654175, train/logprobs = tensor([[-2.1743, -5.0111],
        [-2.7622, -1.7344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25602859258651733
Epoch 0, Step 1134: train/loss = 0.09014622122049332, train/raw-loss = 0.04242105782032013, train/logprobs = tensor([[-2.2105, -8.2879],
        [-2.7741, -1.5138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4772516191005707
Epoch 0, Step 1135: train/loss = 0.3331480920314789, train/raw-loss = 0.3050246834754944, train/logprobs = tensor([[-2.6565, -4.1558],
        [-4.0447, -2.3531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2812339663505554
Epoch 0, Step 1136: train/loss = 0.19671481847763062, train/raw-loss = 0.15842777490615845, train/logprobs = tensor([[-1.6934, -6.6170],
        [-2.6531, -1.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38287052512168884
Epoch 0, Step 1137: train/loss = 0.37630295753479004, train/raw-loss = 0.34467437863349915, train/logprobs = tensor([[-2.7677, -6.4208],
        [-2.5471, -1.5253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31628578901290894
Epoch 0, Step 1138: train/loss = 0.32910677790641785, train/raw-loss = 0.309486448764801, train/logprobs = tensor([[-2.0751, -3.4942],
        [-3.8347, -2.2823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19620327651500702
Epoch 0, Step 1139: train/loss = 0.46157288551330566, train/raw-loss = 0.4492969810962677, train/logprobs = tensor([[-2.3560, -3.7353],
        [-3.1049, -2.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12275904417037964
Epoch 0, Step 1140: train/loss = 0.3255586624145508, train/raw-loss = 0.30186882615089417, train/logprobs = tensor([[-1.3939, -3.6115],
        [-2.5186, -1.6587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23689855635166168
Epoch 0, Step 1141: train/loss = 0.30796974897384644, train/raw-loss = 0.2832801342010498, train/logprobs = tensor([[-1.4784, -5.2326],
        [-2.8521, -2.4507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24689602851867676
Epoch 0, Step 1142: train/loss = 0.12956488132476807, train/raw-loss = 0.08813418447971344, train/logprobs = tensor([[-2.4579, -5.0232],
        [-4.3783, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41430699825286865
Epoch 0, Step 1143: train/loss = 0.24464261531829834, train/raw-loss = 0.2067430317401886, train/logprobs = tensor([[-2.5536, -8.4059],
        [-1.9930, -1.5559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789958357810974
Epoch 0, Step 1144: train/loss = 0.2579871118068695, train/raw-loss = 0.23437875509262085, train/logprobs = tensor([[-1.5986, -6.2822],
        [-2.0996, -1.4539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23608362674713135
Epoch 0, Step 1145: train/loss = 0.14792793989181519, train/raw-loss = 0.1141449436545372, train/logprobs = tensor([[-1.7772, -5.3016],
        [-3.6088, -2.1862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378300070762634
Epoch 0, Step 1146: train/loss = 0.1264759600162506, train/raw-loss = 0.08828169852495193, train/logprobs = tensor([[-1.5162, -5.7451],
        [-3.0512, -1.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38194265961647034
Epoch 0, Step 1147: train/loss = 0.10744981467723846, train/raw-loss = 0.06125427782535553, train/logprobs = tensor([[-1.8676, -7.0928],
        [-2.2234, -0.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46195536851882935
Epoch 0, Step 1148: train/loss = 0.1240929365158081, train/raw-loss = 0.08278343826532364, train/logprobs = tensor([[-1.7201, -6.8317],
        [-3.1802, -1.9585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41309496760368347
Epoch 0, Step 1149: train/loss = 0.19137437641620636, train/raw-loss = 0.16375069320201874, train/logprobs = tensor([[-2.1036, -4.5249],
        [-3.2564, -1.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27623677253723145
Epoch 0, Step 1150: train/loss = 0.16129980981349945, train/raw-loss = 0.1199951320886612, train/logprobs = tensor([[-2.6937, -7.3578],
        [-3.2642, -1.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41304680705070496
Epoch 0, Step 1151: train/loss = 0.13798384368419647, train/raw-loss = 0.09917126595973969, train/logprobs = tensor([[-2.2383, -5.8581],
        [-3.6897, -2.4198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38812577724456787
Epoch 0, Step 1152: train/loss = 0.12256987392902374, train/raw-loss = 0.0660398006439209, train/logprobs = tensor([[-1.2799, -7.4673],
        [-2.8176, -1.4436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.565300703048706
Epoch 0, Step 1153: train/loss = 0.12469117343425751, train/raw-loss = 0.08160373568534851, train/logprobs = tensor([[-2.0124, -6.8174],
        [-2.5849, -1.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4308742880821228
Epoch 0, Step 1154: train/loss = 0.21043065190315247, train/raw-loss = 0.18622322380542755, train/logprobs = tensor([[-2.2373, -5.2119],
        [-2.4259, -1.6235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24207423627376556
Epoch 0, Step 1155: train/loss = 0.23118214309215546, train/raw-loss = 0.20513105392456055, train/logprobs = tensor([[-2.6563, -5.3556],
        [-2.9636, -1.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2605106830596924
Epoch 0, Step 1156: train/loss = 0.46490126848220825, train/raw-loss = 0.4471605718135834, train/logprobs = tensor([[-1.7804, -3.6970],
        [-2.4212, -1.9096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774074137210846
Epoch 0, Step 1157: train/loss = 0.2863795757293701, train/raw-loss = 0.2458025962114334, train/logprobs = tensor([[-2.6131, -5.1780],
        [-4.1263, -2.2017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4057697653770447
Epoch 0, Step 1158: train/loss = 0.3251711428165436, train/raw-loss = 0.29168158769607544, train/logprobs = tensor([[-2.0801, -4.6593],
        [-3.6001, -1.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33489561080932617
Epoch 0, Step 1159: train/loss = 0.1965922862291336, train/raw-loss = 0.15300695598125458, train/logprobs = tensor([[-2.0030, -6.2027],
        [-3.0165, -1.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4358532130718231
Epoch 0, Step 1160: train/loss = 0.24515219032764435, train/raw-loss = 0.20057512819766998, train/logprobs = tensor([[-3.0494, -5.2693],
        [-4.2991, -1.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4457705318927765
Epoch 0, Step 1161: train/loss = 0.18346838653087616, train/raw-loss = 0.14925944805145264, train/logprobs = tensor([[-2.8415, -6.9147],
        [-3.1403, -2.1669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3420892655849457
Epoch 0, Step 1162: train/loss = 0.3117047846317291, train/raw-loss = 0.2934839427471161, train/logprobs = tensor([[-3.3996, -5.9269],
        [-2.7814, -1.9960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18220853805541992
Epoch 0, Step 1163: train/loss = 0.31628143787384033, train/raw-loss = 0.28939276933670044, train/logprobs = tensor([[-2.4400, -5.7104],
        [-3.5594, -2.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2688868045806885
Epoch 0, Step 1164: train/loss = 0.32625114917755127, train/raw-loss = 0.30416518449783325, train/logprobs = tensor([[-1.3660, -3.8251],
        [-2.8841, -2.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22085964679718018
Epoch 0, Step 1165: train/loss = 0.3490092158317566, train/raw-loss = 0.3363150954246521, train/logprobs = tensor([[-2.0381, -3.9462],
        [-2.8365, -2.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1269414722919464
Epoch 0, Step 1166: train/loss = 0.13711893558502197, train/raw-loss = 0.09648190438747406, train/logprobs = tensor([[-2.2578, -5.5836],
        [-4.1338, -2.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4063704013824463
Epoch 0, Step 1167: train/loss = 0.0886480063199997, train/raw-loss = 0.031191814690828323, train/logprobs = tensor([[-1.9456, -7.3332],
        [-3.8289, -1.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5745619535446167
Epoch 0, Step 1168: train/loss = 0.2192951738834381, train/raw-loss = 0.19166234135627747, train/logprobs = tensor([[-1.9951, -4.8454],
        [-3.6536, -2.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27632832527160645
Epoch 0, Step 1169: train/loss = 0.24371016025543213, train/raw-loss = 0.21586471796035767, train/logprobs = tensor([[-2.0112, -4.0446],
        [-3.3971, -1.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27845439314842224
Epoch 0, Step 1170: train/loss = 0.4991920590400696, train/raw-loss = 0.4814719557762146, train/logprobs = tensor([[-2.4236, -3.9022],
        [-3.1981, -2.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17720088362693787
Epoch 0, Step 1171: train/loss = 0.2026446908712387, train/raw-loss = 0.1746865212917328, train/logprobs = tensor([[-2.0341, -5.0986],
        [-3.1757, -2.2111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27958181500434875
Epoch 0, Step 1172: train/loss = 0.28328752517700195, train/raw-loss = 0.25479036569595337, train/logprobs = tensor([[-1.6317, -5.2639],
        [-2.7505, -1.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2849717438220978
Epoch 0, Step 1173: train/loss = 0.13465024530887604, train/raw-loss = 0.08342808485031128, train/logprobs = tensor([[-2.3352, -6.4813],
        [-3.9407, -2.2927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.51222163438797
Epoch 0, Step 1174: train/loss = 0.28982773423194885, train/raw-loss = 0.26429614424705505, train/logprobs = tensor([[-3.2233, -5.0950],
        [-3.7875, -2.5811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.255315899848938
Epoch 0, Step 1175: train/loss = 0.3509695529937744, train/raw-loss = 0.33157268166542053, train/logprobs = tensor([[-1.5663, -4.3345],
        [-2.6044, -2.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19396847486495972
Epoch 0, Step 1176: train/loss = 0.25128746032714844, train/raw-loss = 0.2237231731414795, train/logprobs = tensor([[-2.3503, -5.6162],
        [-2.9449, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27564293146133423
Epoch 0, Step 1177: train/loss = 0.4024009108543396, train/raw-loss = 0.37407925724983215, train/logprobs = tensor([[-2.5352, -4.1702],
        [-2.8631, -1.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2832166254520416
Epoch 0, Step 1178: train/loss = 0.5011888742446899, train/raw-loss = 0.4973682761192322, train/logprobs = tensor([[-1.8695, -2.0945],
        [-2.8183, -2.0660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038206204771995544
Epoch 0, Step 1179: train/loss = 0.1242854967713356, train/raw-loss = 0.08905711770057678, train/logprobs = tensor([[-2.5434, -7.7617],
        [-3.0832, -2.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3522838056087494
Epoch 0, Step 1180: train/loss = 0.28110653162002563, train/raw-loss = 0.26285797357559204, train/logprobs = tensor([[-2.4595, -5.0307],
        [-3.3057, -2.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824854165315628
Epoch 0, Step 1181: train/loss = 0.4717094302177429, train/raw-loss = 0.46469056606292725, train/logprobs = tensor([[-2.8721, -5.1525],
        [-2.2558, -2.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07018852233886719
Epoch 0, Step 1182: train/loss = 0.25484174489974976, train/raw-loss = 0.22303807735443115, train/logprobs = tensor([[-2.4172, -4.9497],
        [-4.1107, -2.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31803685426712036
Epoch 0, Step 1183: train/loss = 0.4778496325016022, train/raw-loss = 0.4633362591266632, train/logprobs = tensor([[-2.6794, -4.1143],
        [-2.7870, -2.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14513340592384338
Epoch 0, Step 1184: train/loss = 0.28564727306365967, train/raw-loss = 0.2631833851337433, train/logprobs = tensor([[-1.4948, -6.0405],
        [-2.7959, -2.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2246389091014862
Epoch 0, Step 1185: train/loss = 0.14547282457351685, train/raw-loss = 0.11471835523843765, train/logprobs = tensor([[-1.8402, -7.3137],
        [-3.5484, -3.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30754467844963074
Epoch 0, Step 1186: train/loss = 0.24382470548152924, train/raw-loss = 0.21565154194831848, train/logprobs = tensor([[-2.2791, -6.2748],
        [-3.5876, -2.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2817314863204956
Epoch 0, Step 1187: train/loss = 0.08809584379196167, train/raw-loss = 0.04183771088719368, train/logprobs = tensor([[-1.8905, -8.3861],
        [-3.2328, -2.2330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4625813961029053
Epoch 0, Step 1188: train/loss = 0.2621573507785797, train/raw-loss = 0.21982574462890625, train/logprobs = tensor([[-2.8499, -7.1181],
        [-3.4817, -2.5440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4233162999153137
Epoch 0, Step 1189: train/loss = 0.19714422523975372, train/raw-loss = 0.16658315062522888, train/logprobs = tensor([[-4.3195, -6.9082],
        [-4.0992, -2.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.305610716342926
Epoch 0, Step 1190: train/loss = 0.1870480328798294, train/raw-loss = 0.15087400376796722, train/logprobs = tensor([[-1.9632, -5.7762],
        [-4.8416, -2.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3617401719093323
Epoch 0, Step 1191: train/loss = 0.1670965850353241, train/raw-loss = 0.13179588317871094, train/logprobs = tensor([[-1.9351, -5.4563],
        [-4.5088, -2.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35300689935684204
Epoch 0, Step 1192: train/loss = 0.3793233633041382, train/raw-loss = 0.3663514256477356, train/logprobs = tensor([[-1.8988, -3.7816],
        [-3.4767, -2.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12971937656402588
Epoch 0, Step 1193: train/loss = 0.2736384868621826, train/raw-loss = 0.25315070152282715, train/logprobs = tensor([[-2.2403, -5.2909],
        [-2.7280, -2.1919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20487776398658752
Epoch 0, Step 1194: train/loss = 0.10611666738986969, train/raw-loss = 0.047208428382873535, train/logprobs = tensor([[-2.5422, -6.9154],
        [-5.2438, -2.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5890824198722839
Epoch 0, Step 1195: train/loss = 0.18738862872123718, train/raw-loss = 0.1498480588197708, train/logprobs = tensor([[-3.5403, -7.9138],
        [-3.9714, -2.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37540578842163086
Epoch 0, Step 1196: train/loss = 0.1855955868959427, train/raw-loss = 0.1341855674982071, train/logprobs = tensor([[-2.5113, -6.9500],
        [-4.1857, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5140999555587769
Epoch 0, Step 1197: train/loss = 0.19796760380268097, train/raw-loss = 0.16363486647605896, train/logprobs = tensor([[-2.5247, -7.8570],
        [-2.6715, -2.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34332752227783203
Epoch 0, Step 1198: train/loss = 0.14954125881195068, train/raw-loss = 0.10858602821826935, train/logprobs = tensor([[-1.6555, -5.9828],
        [-3.7289, -2.4761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4095523953437805
Epoch 0, Step 1199: train/loss = 0.3789362609386444, train/raw-loss = 0.351989209651947, train/logprobs = tensor([[-2.3205, -6.5040],
        [-3.8405, -3.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26947012543678284
Epoch 0, Step 1200: train/loss = 0.37844380736351013, train/raw-loss = 0.3478487730026245, train/logprobs = tensor([[-3.1719, -6.9788],
        [-3.0274, -1.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3059500753879547
Epoch 0, Step 1201: train/loss = 0.24690021574497223, train/raw-loss = 0.222736656665802, train/logprobs = tensor([[-2.5754, -7.5176],
        [-3.9882, -4.0850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2416355460882187
Epoch 0, Step 1202: train/loss = 0.2838694453239441, train/raw-loss = 0.25430673360824585, train/logprobs = tensor([[-1.1150, -4.1749],
        [-2.3045, -1.4589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956271469593048
Epoch 0, Step 1203: train/loss = 0.8587198257446289, train/raw-loss = 0.8456459045410156, train/logprobs = tensor([[-4.0482, -4.6771],
        [-2.5034, -2.5802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13073883950710297
Epoch 0, Step 1204: train/loss = 0.1195254921913147, train/raw-loss = 0.06759633123874664, train/logprobs = tensor([[-2.8253, -7.1522],
        [-3.2572, -1.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5192916393280029
Epoch 0, Step 1205: train/loss = 0.2467530220746994, train/raw-loss = 0.21942472457885742, train/logprobs = tensor([[-2.7666, -6.5016],
        [-3.1562, -2.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2732829749584198
Epoch 0, Step 1206: train/loss = 0.2776300311088562, train/raw-loss = 0.24756762385368347, train/logprobs = tensor([[-2.3459, -4.7378],
        [-4.6266, -3.0499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30062419176101685
Epoch 0, Step 1207: train/loss = 0.6930715441703796, train/raw-loss = 0.6848649978637695, train/logprobs = tensor([[-4.1417, -4.5854],
        [-2.8508, -2.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206580579280853
Epoch 0, Step 1208: train/loss = 0.4291594326496124, train/raw-loss = 0.4066905677318573, train/logprobs = tensor([[-2.5061, -4.4669],
        [-2.6119, -1.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2246885448694229
Epoch 0, Step 1209: train/loss = 0.6253881454467773, train/raw-loss = 0.6029619574546814, train/logprobs = tensor([[-3.7223, -5.2453],
        [-4.4377, -2.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22426199913024902
Epoch 0, Step 1210: train/loss = 0.14123430848121643, train/raw-loss = 0.10145071148872375, train/logprobs = tensor([[-2.4178, -5.8485],
        [-3.4131, -1.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3978358507156372
Epoch 0, Step 1211: train/loss = 0.3471544086933136, train/raw-loss = 0.32266274094581604, train/logprobs = tensor([[-2.1616, -5.0198],
        [-3.6432, -2.8215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24491643905639648
Epoch 0, Step 1212: train/loss = 0.16258038580417633, train/raw-loss = 0.12796127796173096, train/logprobs = tensor([[-1.7573, -6.9562],
        [-3.8002, -3.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3461911082267761
Epoch 0, Step 1213: train/loss = 0.42016923427581787, train/raw-loss = 0.4045373201370239, train/logprobs = tensor([[-3.4370, -4.7771],
        [-3.0323, -2.3117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15631912648677826
Epoch 0, Step 1214: train/loss = 0.25312724709510803, train/raw-loss = 0.23188984394073486, train/logprobs = tensor([[-1.4175, -7.0489],
        [-2.8350, -3.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2123739868402481
Epoch 0, Step 1215: train/loss = 0.11692077666521072, train/raw-loss = 0.08175314962863922, train/logprobs = tensor([[-3.0503, -7.6943],
        [-4.3327, -3.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3516762852668762
Epoch 0, Step 1216: train/loss = 0.14783549308776855, train/raw-loss = 0.09334968030452728, train/logprobs = tensor([[-1.9756, -9.1749],
        [-4.8803, -2.9440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5448581576347351
Epoch 0, Step 1217: train/loss = 0.2694665789604187, train/raw-loss = 0.24766317009925842, train/logprobs = tensor([[-2.6488, -4.8796],
        [-4.1953, -2.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21803422272205353
Epoch 0, Step 1218: train/loss = 0.20778916776180267, train/raw-loss = 0.16443541646003723, train/logprobs = tensor([[-3.5835, -6.2187],
        [-6.3574, -3.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4335375130176544
Epoch 0, Step 1219: train/loss = 0.16778051853179932, train/raw-loss = 0.13229216635227203, train/logprobs = tensor([[-3.1668, -7.5185],
        [-3.0423, -1.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3548835217952728
Epoch 0, Step 1220: train/loss = 0.3475269675254822, train/raw-loss = 0.31093695759773254, train/logprobs = tensor([[-3.1877, -7.5842],
        [-5.0637, -3.2956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3659002482891083
Epoch 0, Step 1221: train/loss = 0.21824291348457336, train/raw-loss = 0.18095338344573975, train/logprobs = tensor([[-3.3769, -6.5062],
        [-4.8831, -3.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3728954792022705
Epoch 0, Step 1222: train/loss = 0.08931978046894073, train/raw-loss = 0.03224096819758415, train/logprobs = tensor([[-3.4378, -9.0799],
        [-3.9591, -1.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5707882046699524
Epoch 0, Step 1223: train/loss = 0.18898192048072815, train/raw-loss = 0.1605881154537201, train/logprobs = tensor([[-3.5436, -6.9778],
        [-4.0518, -2.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28393784165382385
Epoch 0, Step 1224: train/loss = 0.3478303551673889, train/raw-loss = 0.3232393264770508, train/logprobs = tensor([[-2.8480, -6.2669],
        [-3.4510, -2.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24591027200222015
Epoch 0, Step 1225: train/loss = 0.13177967071533203, train/raw-loss = 0.07237756997346878, train/logprobs = tensor([[-3.2121, -8.2439],
        [-6.0328, -2.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5940209627151489
Epoch 0, Step 1226: train/loss = 0.12673217058181763, train/raw-loss = 0.08914127945899963, train/logprobs = tensor([[-2.3553, -8.2226],
        [-4.1224, -2.6493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37590891122817993
Epoch 0, Step 1227: train/loss = 0.2763533592224121, train/raw-loss = 0.2538970708847046, train/logprobs = tensor([[-2.7571, -6.5225],
        [-4.0493, -3.4438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22456292808055878
Epoch 0, Step 1228: train/loss = 0.2539905607700348, train/raw-loss = 0.22592544555664062, train/logprobs = tensor([[-2.6209, -7.4821],
        [-3.5940, -2.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28065115213394165
Epoch 0, Step 1229: train/loss = 0.2333621382713318, train/raw-loss = 0.20993921160697937, train/logprobs = tensor([[-2.1825, -6.9532],
        [-2.9066, -2.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23422911763191223
Epoch 0, Step 1230: train/loss = 0.12629425525665283, train/raw-loss = 0.09269365668296814, train/logprobs = tensor([[-2.1485, -7.1081],
        [-3.1570, -2.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33600616455078125
Epoch 0, Step 1231: train/loss = 0.1533755660057068, train/raw-loss = 0.09778700023889542, train/logprobs = tensor([[-2.6467, -7.8580],
        [-5.3370, -3.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5558856725692749
Epoch 0, Step 1232: train/loss = 0.3130232095718384, train/raw-loss = 0.2866201400756836, train/logprobs = tensor([[-2.2813, -5.7317],
        [-3.0079, -2.6220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640307545661926
Epoch 0, Step 1233: train/loss = 0.26109781861305237, train/raw-loss = 0.2219226360321045, train/logprobs = tensor([[-2.1674, -8.3473],
        [-3.4682, -2.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39175188541412354
Epoch 0, Step 1234: train/loss = 0.10247667133808136, train/raw-loss = 0.049805838614702225, train/logprobs = tensor([[-2.5931, -9.7449],
        [-3.4997, -1.8095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5267082452774048
Epoch 0, Step 1235: train/loss = 0.2263493835926056, train/raw-loss = 0.2081378698348999, train/logprobs = tensor([[-2.1494, -7.2130],
        [-2.7617, -3.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1821153312921524
Epoch 0, Step 1236: train/loss = 0.11005924642086029, train/raw-loss = 0.06807085126638412, train/logprobs = tensor([[-2.8018, -7.2951],
        [-4.3818, -1.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4198840260505676
Epoch 0, Step 1237: train/loss = 0.12679007649421692, train/raw-loss = 0.08360856026411057, train/logprobs = tensor([[-2.5389, -8.2099],
        [-4.3004, -3.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43181514739990234
Epoch 0, Step 1238: train/loss = 0.2087145298719406, train/raw-loss = 0.16566985845565796, train/logprobs = tensor([[-2.0604, -7.9834],
        [-3.6963, -1.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4304465651512146
Epoch 0, Step 1239: train/loss = 0.2568144202232361, train/raw-loss = 0.23523683845996857, train/logprobs = tensor([[-3.0506, -4.8756],
        [-4.1678, -2.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21577592194080353
Epoch 0, Step 1240: train/loss = 0.20256011188030243, train/raw-loss = 0.1633705496788025, train/logprobs = tensor([[-2.8807, -6.7987],
        [-4.1247, -2.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39189571142196655
Epoch 0, Step 1241: train/loss = 0.26890280842781067, train/raw-loss = 0.23660050332546234, train/logprobs = tensor([[-2.7223, -7.1604],
        [-4.2143, -3.1334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32302290201187134
Epoch 0, Step 1242: train/loss = 0.17353610694408417, train/raw-loss = 0.14023181796073914, train/logprobs = tensor([[-3.0440, -7.2459],
        [-4.3699, -3.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33304280042648315
Epoch 0, Step 1243: train/loss = 0.1603257805109024, train/raw-loss = 0.1170782744884491, train/logprobs = tensor([[-2.9934, -7.3831],
        [-3.9044, -1.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4324750602245331
Epoch 0, Step 1244: train/loss = 0.2910948395729065, train/raw-loss = 0.26030462980270386, train/logprobs = tensor([[-3.8384, -7.5119],
        [-3.4249, -2.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30790209770202637
Epoch 0, Step 1245: train/loss = 0.08128050714731216, train/raw-loss = 0.019916091114282608, train/logprobs = tensor([[-3.0864, -9.0665],
        [-5.3452, -2.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6136441826820374
Epoch 0, Step 1246: train/loss = 0.10641248524188995, train/raw-loss = 0.06403549760580063, train/logprobs = tensor([[ -2.9206, -10.0518],
        [ -4.3194,  -2.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42376989126205444
Epoch 0, Step 1247: train/loss = 0.511310338973999, train/raw-loss = 0.49291786551475525, train/logprobs = tensor([[-2.5668, -3.5136],
        [-3.7077, -2.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18392454087734222
Epoch 0, Step 1248: train/loss = 0.14494410157203674, train/raw-loss = 0.10644213110208511, train/logprobs = tensor([[-3.4637, -7.8204],
        [-3.7959, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38501986861228943
Epoch 0, Step 1249: train/loss = 0.7187396883964539, train/raw-loss = 0.6776760220527649, train/logprobs = tensor([[-3.7022, -5.9506],
        [-4.3737, -2.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4106363356113434
Epoch 0, Step 1250: train/loss = 0.08049372583627701, train/raw-loss = 0.021259410306811333, train/logprobs = tensor([[ -2.3339, -10.7659],
        [ -4.1583,  -2.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5923431515693665
Epoch 0, Step 1251: train/loss = 0.19668535888195038, train/raw-loss = 0.15841063857078552, train/logprobs = tensor([[-2.5979, -7.2696],
        [-4.2751, -2.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3827473521232605
Epoch 0, Step 1252: train/loss = 0.09462706744670868, train/raw-loss = 0.04831995815038681, train/logprobs = tensor([[-2.7957, -8.5555],
        [-4.7181, -2.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630710780620575
Epoch 0, Step 1253: train/loss = 0.49624526500701904, train/raw-loss = 0.4701712727546692, train/logprobs = tensor([[-2.8170, -4.9371],
        [-3.1947, -2.1603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26074016094207764
Epoch 0, Step 1254: train/loss = 0.43758901953697205, train/raw-loss = 0.4167715907096863, train/logprobs = tensor([[-2.6226, -4.8858],
        [-2.9409, -2.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20817416906356812
Epoch 0, Step 1255: train/loss = 0.17839114367961884, train/raw-loss = 0.14659972488880157, train/logprobs = tensor([[-2.5632, -6.3140],
        [-4.2312, -2.6029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179141581058502
Epoch 0, Step 1256: train/loss = 0.10873918235301971, train/raw-loss = 0.06632329523563385, train/logprobs = tensor([[-4.3555, -8.2282],
        [-4.7512, -2.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42415890097618103
Epoch 0, Step 1257: train/loss = 0.09458951652050018, train/raw-loss = 0.04117404669523239, train/logprobs = tensor([[ -3.4036, -10.2030],
        [ -4.8903,  -2.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5341546535491943
Epoch 0, Step 1258: train/loss = 0.18679092824459076, train/raw-loss = 0.1454901099205017, train/logprobs = tensor([[-2.5662, -7.1676],
        [-4.7993, -2.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4130082428455353
Epoch 0, Step 1259: train/loss = 0.10426914691925049, train/raw-loss = 0.05596543103456497, train/logprobs = tensor([[ -2.6535, -11.1817],
        [ -3.7875,  -2.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4830371141433716
Epoch 0, Step 1260: train/loss = 0.10456909239292145, train/raw-loss = 0.038975201547145844, train/logprobs = tensor([[-2.7941, -8.1178],
        [-4.8698, -2.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6559388637542725
Epoch 0, Step 1261: train/loss = 0.6003957986831665, train/raw-loss = 0.5902372002601624, train/logprobs = tensor([[-2.1185, -6.3256],
        [-3.1075, -4.5887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10158583521842957
Epoch 0, Step 1262: train/loss = 0.12665152549743652, train/raw-loss = 0.09398891031742096, train/logprobs = tensor([[-2.4168, -7.7950],
        [-3.8420, -2.7779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3266262114048004
Epoch 0, Step 1263: train/loss = 0.28840553760528564, train/raw-loss = 0.25689589977264404, train/logprobs = tensor([[-1.8426, -7.9631],
        [-3.1252, -2.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150964379310608
Epoch 0, Step 1264: train/loss = 0.09607390314340591, train/raw-loss = 0.032056618481874466, train/logprobs = tensor([[-3.1302, -9.6674],
        [-4.3236, -1.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6401728391647339
Epoch 0, Step 1265: train/loss = 0.26302865147590637, train/raw-loss = 0.22825202345848083, train/logprobs = tensor([[-3.6094, -6.9686],
        [-5.2245, -3.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34776613116264343
Epoch 0, Step 1266: train/loss = 0.2037908136844635, train/raw-loss = 0.17945629358291626, train/logprobs = tensor([[-2.8682, -8.6302],
        [-4.2416, -4.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24334514141082764
Epoch 0, Step 1267: train/loss = 0.21259626746177673, train/raw-loss = 0.16212891042232513, train/logprobs = tensor([[-2.8462, -8.8547],
        [-4.6227, -2.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5046737194061279
Epoch 0, Step 1268: train/loss = 0.2823534309864044, train/raw-loss = 0.25421035289764404, train/logprobs = tensor([[-2.4060, -6.2272],
        [-3.4325, -2.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2814309000968933
Epoch 0, Step 1269: train/loss = 0.13559547066688538, train/raw-loss = 0.08886443078517914, train/logprobs = tensor([[-2.6667, -7.6463],
        [-4.0039, -2.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46731042861938477
Epoch 0, Step 1270: train/loss = 0.12806136906147003, train/raw-loss = 0.08757961541414261, train/logprobs = tensor([[-2.4109, -6.3358],
        [-5.0643, -3.2861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40481749176979065
Epoch 0, Step 1271: train/loss = 0.30933642387390137, train/raw-loss = 0.28850919008255005, train/logprobs = tensor([[-2.1750, -5.2669],
        [-2.9213, -2.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2082722783088684
Epoch 0, Step 1272: train/loss = 0.19194696843624115, train/raw-loss = 0.15291127562522888, train/logprobs = tensor([[-3.2455, -7.4788],
        [-3.5785, -2.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3903571367263794
Epoch 0, Step 1273: train/loss = 0.24060893058776855, train/raw-loss = 0.20861601829528809, train/logprobs = tensor([[-3.1681, -6.9141],
        [-3.9532, -2.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31992918252944946
Epoch 0, Step 1274: train/loss = 0.18399415910243988, train/raw-loss = 0.1483629047870636, train/logprobs = tensor([[-2.4811, -7.5279],
        [-3.8594, -3.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35631269216537476
Epoch 0, Step 1275: train/loss = 0.1935325562953949, train/raw-loss = 0.1570095270872116, train/logprobs = tensor([[-3.0331, -7.2194],
        [-4.5149, -2.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3652302324771881
Epoch 0, Step 1276: train/loss = 0.11801643669605255, train/raw-loss = 0.0824420377612114, train/logprobs = tensor([[-2.1166, -7.7808],
        [-2.4618, -1.5141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35574400424957275
Epoch 0, Step 1277: train/loss = 0.8763403296470642, train/raw-loss = 0.8586611747741699, train/logprobs = tensor([[-2.5430, -5.3438],
        [-2.7168, -2.8578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1767919957637787
Epoch 0, Step 1278: train/loss = 0.1471128761768341, train/raw-loss = 0.1127794161438942, train/logprobs = tensor([[-2.2860, -6.8306],
        [-3.9484, -2.8825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433346152305603
Epoch 0, Step 1279: train/loss = 0.1844668984413147, train/raw-loss = 0.16164498031139374, train/logprobs = tensor([[-2.1859, -7.8245],
        [-4.0406, -3.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22821907699108124
Epoch 0, Step 1280: train/loss = 0.2986189126968384, train/raw-loss = 0.26396626234054565, train/logprobs = tensor([[-2.0593, -6.5438],
        [-3.0334, -2.4085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3465263843536377
Epoch 0, Step 1281: train/loss = 0.09390060603618622, train/raw-loss = 0.04489417001605034, train/logprobs = tensor([[-2.3295, -9.6097],
        [-3.9312, -2.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4900643825531006
Epoch 0, Step 1282: train/loss = 0.3894592821598053, train/raw-loss = 0.36462047696113586, train/logprobs = tensor([[-3.5872, -7.6093],
        [-4.1636, -3.7801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24838803708553314
Epoch 0, Step 1283: train/loss = 0.08225987106561661, train/raw-loss = 0.02728889510035515, train/logprobs = tensor([[ -3.1205, -10.7639],
        [ -4.4821,  -2.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5497097373008728
Epoch 0, Step 1284: train/loss = 0.1288893222808838, train/raw-loss = 0.09646990150213242, train/logprobs = tensor([[-2.3699, -8.1030],
        [-3.0257, -2.4206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3241942524909973
Epoch 0, Step 1285: train/loss = 0.23853802680969238, train/raw-loss = 0.2007240355014801, train/logprobs = tensor([[-2.1965, -7.5291],
        [-3.5947, -1.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37813979387283325
Epoch 0, Step 1286: train/loss = 0.3475843667984009, train/raw-loss = 0.33236271142959595, train/logprobs = tensor([[-3.8239, -5.9596],
        [-3.1920, -2.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522163301706314
Epoch 0, Step 1287: train/loss = 0.1389681100845337, train/raw-loss = 0.099879190325737, train/logprobs = tensor([[ -2.2308, -10.5926],
        [ -3.6980,  -3.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39088916778564453
Epoch 0, Step 1288: train/loss = 0.1704619824886322, train/raw-loss = 0.13824647665023804, train/logprobs = tensor([[-3.7885, -7.9809],
        [-5.0010, -3.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3221549987792969
Epoch 0, Step 1289: train/loss = 0.10101710259914398, train/raw-loss = 0.04009682685136795, train/logprobs = tensor([[-2.7347, -9.3860],
        [-5.6870, -3.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6092026829719543
Epoch 0, Step 1290: train/loss = 0.2817014753818512, train/raw-loss = 0.2526508867740631, train/logprobs = tensor([[-2.7742, -6.3702],
        [-4.5820, -3.7693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29050594568252563
Epoch 0, Step 1291: train/loss = 0.16494451463222504, train/raw-loss = 0.1313154548406601, train/logprobs = tensor([[-3.6597, -9.6000],
        [-4.3372, -3.8149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362904489040375
Epoch 0, Step 1292: train/loss = 0.5404667854309082, train/raw-loss = 0.5258684158325195, train/logprobs = tensor([[-5.6174, -6.1390],
        [-4.5777, -2.9647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14598342776298523
Epoch 0, Step 1293: train/loss = 0.3420523405075073, train/raw-loss = 0.31769704818725586, train/logprobs = tensor([[-2.4188, -4.6280],
        [-3.8023, -2.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24355295300483704
Epoch 0, Step 1294: train/loss = 0.10771441459655762, train/raw-loss = 0.06613379716873169, train/logprobs = tensor([[-2.5643, -8.2316],
        [-3.4720, -2.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158061444759369
Epoch 0, Step 1295: train/loss = 0.30668091773986816, train/raw-loss = 0.27136367559432983, train/logprobs = tensor([[-2.6736, -7.2891],
        [-4.0424, -3.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35317233204841614
Epoch 0, Step 1296: train/loss = 0.10555949807167053, train/raw-loss = 0.05636003986001015, train/logprobs = tensor([[-2.2872, -9.9917],
        [-4.7259, -3.9596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49199458956718445
Epoch 0, Step 1297: train/loss = 0.2285747081041336, train/raw-loss = 0.21050956845283508, train/logprobs = tensor([[-2.8627, -6.5520],
        [-2.8673, -1.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18065145611763
Epoch 0, Step 1298: train/loss = 0.4452236592769623, train/raw-loss = 0.42410436272621155, train/logprobs = tensor([[-5.6718, -7.9368],
        [-4.6343, -2.3398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21119292080402374
Epoch 0, Step 1299: train/loss = 0.16533121466636658, train/raw-loss = 0.1350146383047104, train/logprobs = tensor([[-3.8022, -9.6847],
        [-3.5946, -2.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30316591262817383
Epoch 0, Step 1300: train/loss = 0.21796461939811707, train/raw-loss = 0.18765008449554443, train/logprobs = tensor([[-2.0817, -8.0914],
        [-3.4439, -3.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30314546823501587
Epoch 0, Step 1301: train/loss = 0.36356809735298157, train/raw-loss = 0.33527442812919617, train/logprobs = tensor([[-2.7664, -7.3396],
        [-4.2101, -4.4318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28293681144714355
Epoch 0, Step 1302: train/loss = 0.2189517319202423, train/raw-loss = 0.18272656202316284, train/logprobs = tensor([[-2.8022, -9.5649],
        [-3.3912, -2.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36225152015686035
Epoch 0, Step 1303: train/loss = 0.11672085523605347, train/raw-loss = 0.06512707471847534, train/logprobs = tensor([[-2.8986, -9.3429],
        [-4.2100, -2.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5159378051757812
Epoch 0, Step 1304: train/loss = 0.22586065530776978, train/raw-loss = 0.18645288050174713, train/logprobs = tensor([[-4.0064, -9.4639],
        [-3.9172, -1.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3940778374671936
Epoch 0, Step 1305: train/loss = 0.20894496142864227, train/raw-loss = 0.1776922345161438, train/logprobs = tensor([[-2.9386, -7.5495],
        [-3.9542, -3.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31252726912498474
Epoch 0, Step 1306: train/loss = 0.543834924697876, train/raw-loss = 0.5250756144523621, train/logprobs = tensor([[-3.0182, -8.6945],
        [-3.6179, -3.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18759311735630035
Epoch 0, Step 1307: train/loss = 0.22681838274002075, train/raw-loss = 0.20013204216957092, train/logprobs = tensor([[-3.3527, -5.9336],
        [-4.6373, -3.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2668633460998535
Epoch 0, Step 1308: train/loss = 0.09723572432994843, train/raw-loss = 0.0535200797021389, train/logprobs = tensor([[-4.4518, -9.2090],
        [-5.3883, -1.4586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4371564984321594
Epoch 0, Step 1309: train/loss = 0.09409940242767334, train/raw-loss = 0.03096950426697731, train/logprobs = tensor([[-2.8875, -9.8946],
        [-5.2371, -2.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.631298840045929
Epoch 0, Step 1310: train/loss = 0.22672145068645477, train/raw-loss = 0.1832854151725769, train/logprobs = tensor([[ -3.4349, -10.7211],
        [ -4.8614,  -3.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43436041474342346
Epoch 0, Step 1311: train/loss = 0.15941619873046875, train/raw-loss = 0.11803529411554337, train/logprobs = tensor([[-2.8659, -8.1277],
        [-4.2183, -2.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41380906105041504
Epoch 0, Step 1312: train/loss = 0.23386389017105103, train/raw-loss = 0.20192363858222961, train/logprobs = tensor([[-3.4092, -7.8008],
        [-4.8742, -4.2776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3194028437137604
Epoch 0, Step 1313: train/loss = 0.3009922206401825, train/raw-loss = 0.27247267961502075, train/logprobs = tensor([[-4.5719, -7.5494],
        [-4.4287, -2.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.285195529460907
Epoch 0, Step 1314: train/loss = 0.12457786500453949, train/raw-loss = 0.08669977635145187, train/logprobs = tensor([[-2.3996, -9.1615],
        [-3.6785, -3.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37878087162971497
Epoch 0, Step 1315: train/loss = 0.2827495336532593, train/raw-loss = 0.24888096749782562, train/logprobs = tensor([[-4.3518, -8.1642],
        [-4.3746, -2.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3386858403682709
Epoch 0, Step 1316: train/loss = 0.2827676236629486, train/raw-loss = 0.2378579080104828, train/logprobs = tensor([[-2.6679, -8.5284],
        [-5.0376, -3.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44909703731536865
Epoch 0, Step 1317: train/loss = 0.23987549543380737, train/raw-loss = 0.18835243582725525, train/logprobs = tensor([[-3.2343, -8.5430],
        [-4.1596, -2.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5152305364608765
Epoch 0, Step 1318: train/loss = 0.1329391896724701, train/raw-loss = 0.09590762853622437, train/logprobs = tensor([[ -4.0721, -10.5708],
        [ -4.0055,  -3.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37031564116477966
Epoch 0, Step 1319: train/loss = 0.08178149163722992, train/raw-loss = 0.02467106282711029, train/logprobs = tensor([[ -3.3962, -12.6559],
        [ -5.1185,  -2.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5711042284965515
Epoch 0, Step 1320: train/loss = 0.15356867015361786, train/raw-loss = 0.11338485777378082, train/logprobs = tensor([[-4.8014, -9.5233],
        [-5.3398, -3.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40183812379837036
Epoch 0, Step 1321: train/loss = 0.3644651770591736, train/raw-loss = 0.32287755608558655, train/logprobs = tensor([[-3.7632, -8.8258],
        [-3.2862, -2.1745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4158761501312256
Epoch 0, Step 1322: train/loss = 0.15085653960704803, train/raw-loss = 0.10701180249452591, train/logprobs = tensor([[-4.9827, -9.0648],
        [-4.5736, -2.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4384472668170929
Epoch 0, Step 1323: train/loss = 0.27818891406059265, train/raw-loss = 0.24986930191516876, train/logprobs = tensor([[-2.6976, -8.1571],
        [-4.8519, -3.5571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28319627046585083
Epoch 0, Step 1324: train/loss = 0.3346152901649475, train/raw-loss = 0.29049038887023926, train/logprobs = tensor([[ -3.9710, -10.0068],
        [ -3.8131,  -2.3720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4412490129470825
Epoch 0, Step 1325: train/loss = 0.18468716740608215, train/raw-loss = 0.1465516984462738, train/logprobs = tensor([[-3.1637, -8.2186],
        [-4.2607, -2.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38135454058647156
Epoch 0, Step 1326: train/loss = 0.46485358476638794, train/raw-loss = 0.44427406787872314, train/logprobs = tensor([[-3.7711, -6.3851],
        [-4.0804, -3.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20579499006271362
Epoch 0, Step 1327: train/loss = 0.2908655107021332, train/raw-loss = 0.2519097328186035, train/logprobs = tensor([[-3.0847, -6.2477],
        [-5.0164, -2.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38955768942832947
Epoch 0, Step 1328: train/loss = 0.3415786027908325, train/raw-loss = 0.29466673731803894, train/logprobs = tensor([[-4.1529, -8.4623],
        [-3.5469, -1.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4691186845302582
Epoch 0, Step 1329: train/loss = 0.10644687712192535, train/raw-loss = 0.045011237263679504, train/logprobs = tensor([[ -2.4931, -10.0388],
        [ -5.5690,  -3.4110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6143563985824585
Epoch 0, Step 1330: train/loss = 0.09413924813270569, train/raw-loss = 0.025503627955913544, train/logprobs = tensor([[ -4.1251, -11.4890],
        [ -5.2007,  -2.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.686356246471405
Epoch 0, Step 1331: train/loss = 0.15252044796943665, train/raw-loss = 0.11541121453046799, train/logprobs = tensor([[-3.2177, -8.7703],
        [-3.7271, -2.5250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37109237909317017
Epoch 0, Step 1332: train/loss = 0.44946882128715515, train/raw-loss = 0.4046010375022888, train/logprobs = tensor([[-2.6709, -8.0846],
        [-3.1450, -2.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44867798686027527
Epoch 0, Step 1333: train/loss = 0.24508336186408997, train/raw-loss = 0.21196842193603516, train/logprobs = tensor([[-4.8076, -7.6139],
        [-4.6088, -3.4000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33114945888519287
Epoch 0, Step 1334: train/loss = 0.24795383214950562, train/raw-loss = 0.22414840757846832, train/logprobs = tensor([[-3.2880, -7.3987],
        [-3.8772, -3.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380542755126953
Epoch 0, Step 1335: train/loss = 0.17491360008716583, train/raw-loss = 0.14391514658927917, train/logprobs = tensor([[-2.9032, -9.0662],
        [-4.7602, -4.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30998462438583374
Epoch 0, Step 1336: train/loss = 0.21052856743335724, train/raw-loss = 0.16622993350028992, train/logprobs = tensor([[-5.0396, -9.8346],
        [-3.1013, -1.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44298645853996277
Epoch 0, Step 1337: train/loss = 0.08423595130443573, train/raw-loss = 0.018120042979717255, train/logprobs = tensor([[ -3.7119, -10.8030],
        [ -4.9756,  -1.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6611590385437012
Epoch 0, Step 1338: train/loss = 0.1625843048095703, train/raw-loss = 0.11661507934331894, train/logprobs = tensor([[-2.7039, -9.0752],
        [-4.9193, -3.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4596923589706421
Epoch 0, Step 1339: train/loss = 0.21677377820014954, train/raw-loss = 0.15747831761837006, train/logprobs = tensor([[-3.2022, -8.4411],
        [-5.0175, -3.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5929544568061829
Epoch 0, Step 1340: train/loss = 0.23138463497161865, train/raw-loss = 0.19206973910331726, train/logprobs = tensor([[-3.6494, -9.9162],
        [-4.8814, -3.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39314889907836914
Epoch 0, Step 1341: train/loss = 0.24296584725379944, train/raw-loss = 0.21395748853683472, train/logprobs = tensor([[-2.9820, -9.4621],
        [-3.4001, -3.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29008349776268005
Epoch 0, Step 1342: train/loss = 0.10884889215230942, train/raw-loss = 0.05719844996929169, train/logprobs = tensor([[-4.7394, -8.9815],
        [-5.6272, -2.3908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5165044665336609
Epoch 0, Step 1343: train/loss = 0.20953746140003204, train/raw-loss = 0.1626463681459427, train/logprobs = tensor([[ -5.1833, -12.1617],
        [ -4.1564,  -2.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4689108431339264
Epoch 0, Step 1344: train/loss = 0.25271379947662354, train/raw-loss = 0.19374652206897736, train/logprobs = tensor([[-3.5172, -9.7541],
        [-4.8684, -2.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5896728038787842
Epoch 0, Step 1345: train/loss = 0.08630106598138809, train/raw-loss = 0.022409796714782715, train/logprobs = tensor([[-3.3524, -8.6298],
        [-5.7322, -1.6116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6389127969741821
Epoch 0, Step 1346: train/loss = 0.32085320353507996, train/raw-loss = 0.2866002917289734, train/logprobs = tensor([[-2.8067, -6.1774],
        [-6.3492, -4.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3425293266773224
Epoch 0, Step 1347: train/loss = 0.45891624689102173, train/raw-loss = 0.43102842569351196, train/logprobs = tensor([[-3.4316, -6.5357],
        [-4.0171, -3.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788785696029663
Epoch 0, Step 1348: train/loss = 0.12166107445955276, train/raw-loss = 0.058042269200086594, train/logprobs = tensor([[-2.9964, -9.3819],
        [-6.2418, -3.6174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6361880302429199
Epoch 0, Step 1349: train/loss = 0.10170207917690277, train/raw-loss = 0.0508292056620121, train/logprobs = tensor([[ -3.0992, -10.7925],
        [ -3.3951,  -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5087287425994873
Epoch 0, Step 1350: train/loss = 0.09822878241539001, train/raw-loss = 0.04615635424852371, train/logprobs = tensor([[ -3.3659, -10.5715],
        [ -4.6627,  -2.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5207242965698242
Epoch 0, Step 1351: train/loss = 0.3131610155105591, train/raw-loss = 0.2865317761898041, train/logprobs = tensor([[-2.2307, -5.4470],
        [-5.0511, -3.5174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26629209518432617
Epoch 0, Step 1352: train/loss = 0.22701996564865112, train/raw-loss = 0.18833254277706146, train/logprobs = tensor([[-2.0532, -5.2355],
        [-4.7738, -3.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38687431812286377
Epoch 0, Step 1353: train/loss = 0.23090748488903046, train/raw-loss = 0.18345873057842255, train/logprobs = tensor([[-2.3080, -5.6849],
        [-5.9393, -2.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4744877517223358
Epoch 0, Step 1354: train/loss = 0.24327510595321655, train/raw-loss = 0.1967986822128296, train/logprobs = tensor([[-1.5648, -6.7784],
        [-4.8989, -3.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46476414799690247
Epoch 0, Step 1355: train/loss = 0.410239040851593, train/raw-loss = 0.35768479108810425, train/logprobs = tensor([[-4.7398, -9.5352],
        [-5.3889, -4.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5255424976348877
Epoch 0, Step 1356: train/loss = 0.35904499888420105, train/raw-loss = 0.32695892453193665, train/logprobs = tensor([[-2.4465, -5.2955],
        [-4.2944, -3.2122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3208606541156769
Epoch 0, Step 1357: train/loss = 0.4101831614971161, train/raw-loss = 0.372292697429657, train/logprobs = tensor([[-2.3237, -7.2981],
        [-4.1705, -2.7020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3789042830467224
Epoch 0, Step 1358: train/loss = 0.3041152358055115, train/raw-loss = 0.2624548673629761, train/logprobs = tensor([[-3.2336, -6.6332],
        [-5.2730, -3.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.416603684425354
Epoch 0, Step 1359: train/loss = 0.2804589867591858, train/raw-loss = 0.2595103085041046, train/logprobs = tensor([[-2.7212, -5.1414],
        [-5.5418, -4.5083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2094866931438446
Epoch 0, Step 1360: train/loss = 0.24350222945213318, train/raw-loss = 0.19205377995967865, train/logprobs = tensor([[-2.6566, -7.4548],
        [-6.2623, -3.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5144844055175781
Epoch 0, Step 1361: train/loss = 0.3055967688560486, train/raw-loss = 0.27406322956085205, train/logprobs = tensor([[-1.8857, -5.2007],
        [-4.0592, -3.0073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3153356909751892
Epoch 0, Step 1362: train/loss = 0.22456800937652588, train/raw-loss = 0.18281158804893494, train/logprobs = tensor([[-1.9047, -6.1697],
        [-4.8358, -3.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4175642132759094
Epoch 0, Step 1363: train/loss = 0.10420681536197662, train/raw-loss = 0.059535421431064606, train/logprobs = tensor([[-2.8940, -8.9922],
        [-5.0562, -3.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4467138648033142
Epoch 0, Step 1364: train/loss = 0.3297868072986603, train/raw-loss = 0.30089831352233887, train/logprobs = tensor([[-4.4090, -8.6900],
        [-3.6264, -2.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2888852059841156
Epoch 0, Step 1365: train/loss = 0.2585583031177521, train/raw-loss = 0.2049674540758133, train/logprobs = tensor([[-3.6242, -9.1056],
        [-4.2382, -2.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.535908579826355
Epoch 0, Step 1366: train/loss = 0.1030430793762207, train/raw-loss = 0.052353132516145706, train/logprobs = tensor([[-2.7911, -7.8249],
        [-5.0680, -2.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5068994760513306
Epoch 0, Step 1367: train/loss = 0.09362871944904327, train/raw-loss = 0.03280625492334366, train/logprobs = tensor([[ -1.6264, -10.1685],
        [ -5.5334,  -3.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6082245707511902
Epoch 0, Step 1368: train/loss = 0.15935899317264557, train/raw-loss = 0.1010705828666687, train/logprobs = tensor([[-3.3542, -9.0982],
        [-4.9537, -3.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5828841328620911
Epoch 0, Step 1369: train/loss = 0.3440261483192444, train/raw-loss = 0.3119106888771057, train/logprobs = tensor([[-3.1211, -6.3494],
        [-5.6960, -4.2804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32115495204925537
Epoch 0, Step 1370: train/loss = 0.11948646605014801, train/raw-loss = 0.07724569737911224, train/logprobs = tensor([[-4.5062, -8.3138],
        [-5.8406, -2.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42240768671035767
Epoch 0, Step 1371: train/loss = 0.1257106214761734, train/raw-loss = 0.08180031180381775, train/logprobs = tensor([[-3.1415, -9.2576],
        [-5.5946, -3.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4391031861305237
Epoch 0, Step 1372: train/loss = 0.09491348266601562, train/raw-loss = 0.023324478417634964, train/logprobs = tensor([[ -3.6092, -13.9375],
        [ -5.6016,  -2.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7158900499343872
Epoch 0, Step 1373: train/loss = 0.1404012143611908, train/raw-loss = 0.08970918506383896, train/logprobs = tensor([[-2.8699, -6.3864],
        [-5.6205, -2.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5069202780723572
Epoch 0, Step 1374: train/loss = 0.12812799215316772, train/raw-loss = 0.0910489484667778, train/logprobs = tensor([[ -3.8466, -14.1303],
        [ -4.8342,  -4.4985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37079042196273804
Epoch 0, Step 1375: train/loss = 0.10126285254955292, train/raw-loss = 0.04114122688770294, train/logprobs = tensor([[ -3.0415, -11.7152],
        [ -5.8750,  -3.0515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6012163162231445
Epoch 0, Step 1376: train/loss = 0.244491308927536, train/raw-loss = 0.20763565599918365, train/logprobs = tensor([[-3.4473, -5.8506],
        [-7.3610, -5.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36855652928352356
Epoch 0, Step 1377: train/loss = 0.17366400361061096, train/raw-loss = 0.12307058274745941, train/logprobs = tensor([[-2.8676, -8.0954],
        [-8.1025, -5.4318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5059341788291931
Epoch 0, Step 1378: train/loss = 0.6951398849487305, train/raw-loss = 0.6659809947013855, train/logprobs = tensor([[-2.7030, -3.9200],
        [-8.3364, -5.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29158860445022583
Epoch 0, Step 1379: train/loss = 0.08375077694654465, train/raw-loss = 0.0045854756608605385, train/logprobs = tensor([[-2.4658, -9.1052],
        [-9.8673, -4.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.791653037071228
Epoch 0, Step 1380: train/loss = 0.19835646450519562, train/raw-loss = 0.13189880549907684, train/logprobs = tensor([[-2.5284, -9.1895],
        [-7.6554, -4.7607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6645767092704773
Epoch 0, Step 1381: train/loss = 0.26092588901519775, train/raw-loss = 0.1996569037437439, train/logprobs = tensor([[-3.8556, -9.2081],
        [-7.5447, -3.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6126897931098938
Epoch 0, Step 1382: train/loss = 0.26417332887649536, train/raw-loss = 0.21854394674301147, train/logprobs = tensor([[-4.1629, -9.6533],
        [-6.2333, -3.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4562937319278717
Epoch 0, Step 1383: train/loss = 0.1005488783121109, train/raw-loss = 0.031253792345523834, train/logprobs = tensor([[-2.8697, -8.9261],
        [-7.6455, -3.3399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6929508447647095
Epoch 0, Step 1384: train/loss = 0.10165443271398544, train/raw-loss = 0.03658353164792061, train/logprobs = tensor([[-2.4333, -7.9729],
        [-7.9374, -3.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6507089734077454
Epoch 0, Step 1385: train/loss = 0.1052682101726532, train/raw-loss = 0.01935594528913498, train/logprobs = tensor([[-2.4461, -9.3769],
        [-8.3870, -3.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.859122633934021
Epoch 0, Step 1386: train/loss = 0.32560956478118896, train/raw-loss = 0.27902334928512573, train/logprobs = tensor([[-3.8683, -8.2588],
        [-5.4208, -3.9836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46586209535598755
Epoch 0, Step 1387: train/loss = 0.300725519657135, train/raw-loss = 0.2768602967262268, train/logprobs = tensor([[-2.2641, -3.4425],
        [-6.3268, -4.5349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23865263164043427
Epoch 0, Step 1388: train/loss = 0.4491935074329376, train/raw-loss = 0.4003585875034332, train/logprobs = tensor([[-2.8803, -7.8956],
        [-6.4430, -4.6327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4883492588996887
Epoch 0, Step 1389: train/loss = 0.14975681900978088, train/raw-loss = 0.07173614203929901, train/logprobs = tensor([[-2.1234, -9.1863],
        [-7.6866, -3.3230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.780206561088562
Epoch 0, Step 1390: train/loss = 0.28534844517707825, train/raw-loss = 0.21411779522895813, train/logprobs = tensor([[-3.1631, -9.8831],
        [-6.3695, -2.7444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7123066782951355
Epoch 0, Step 1391: train/loss = 0.14176253974437714, train/raw-loss = 0.07763418555259705, train/logprobs = tensor([[-2.3190, -8.2909],
        [-7.7418, -3.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6412835121154785
Epoch 0, Step 1392: train/loss = 0.09272245317697525, train/raw-loss = 0.01633363962173462, train/logprobs = tensor([[-2.2339, -9.6830],
        [-7.5741, -3.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7638880610466003
Epoch 0, Step 1393: train/loss = 0.2937825620174408, train/raw-loss = 0.2536417841911316, train/logprobs = tensor([[-2.6781, -7.3196],
        [-5.4447, -3.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40140777826309204
Epoch 0, Step 1394: train/loss = 0.18023917078971863, train/raw-loss = 0.1165744960308075, train/logprobs = tensor([[-2.1075, -7.0764],
        [-6.5168, -4.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6366468667984009
Epoch 0, Step 1395: train/loss = 0.1050320416688919, train/raw-loss = 0.048944007605314255, train/logprobs = tensor([[-5.7180, -9.9970],
        [-6.8914, -3.5952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5608803033828735
Epoch 0, Step 1396: train/loss = 0.09381407499313354, train/raw-loss = 0.0213590320199728, train/logprobs = tensor([[-1.8562, -9.1504],
        [-7.3582, -3.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7245503664016724
Epoch 0, Step 1397: train/loss = 0.09909684956073761, train/raw-loss = 0.04782436788082123, train/logprobs = tensor([[-3.4420, -8.8996],
        [-6.5317, -4.2258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5127248764038086
Epoch 0, Step 1398: train/loss = 0.20188403129577637, train/raw-loss = 0.1531657576560974, train/logprobs = tensor([[-3.6897, -5.8624],
        [-8.6652, -4.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48718276619911194
Epoch 0, Step 1399: train/loss = 0.12006624788045883, train/raw-loss = 0.05592626333236694, train/logprobs = tensor([[ -4.2628, -10.1078],
        [ -6.4786,  -2.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6413998603820801
Epoch 0, Step 1400: train/loss = 0.32356569170951843, train/raw-loss = 0.2793189287185669, train/logprobs = tensor([[-3.7755, -8.0022],
        [-6.4501, -4.2452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4424676299095154
Epoch 0, Step 1401: train/loss = 0.17268876731395721, train/raw-loss = 0.11380663514137268, train/logprobs = tensor([[-2.4452, -6.7958],
        [-7.3294, -3.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.588821291923523
Epoch 0, Step 1402: train/loss = 0.12310245633125305, train/raw-loss = 0.04533820226788521, train/logprobs = tensor([[-1.7996, -8.6586],
        [-6.1473, -2.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7776424884796143
Epoch 0, Step 1403: train/loss = 0.07736559212207794, train/raw-loss = 0.013897801749408245, train/logprobs = tensor([[-3.3348, -9.2158],
        [-7.4840, -3.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6346778869628906
Epoch 0, Step 1404: train/loss = 0.5835004448890686, train/raw-loss = 0.49530333280563354, train/logprobs = tensor([[-1.9555, -7.6461],
        [-7.1918, -5.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8819711208343506
Epoch 0, Step 1405: train/loss = 0.11124920845031738, train/raw-loss = 0.04047719016671181, train/logprobs = tensor([[-2.4188, -8.6314],
        [-7.9436, -3.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7077201008796692
Epoch 0, Step 1406: train/loss = 0.2770674228668213, train/raw-loss = 0.2508537769317627, train/logprobs = tensor([[-2.6854, -4.3345],
        [-4.9288, -3.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2621363401412964
Epoch 0, Step 1407: train/loss = 0.1286318004131317, train/raw-loss = 0.04776918515563011, train/logprobs = tensor([[-2.3444, -9.9103],
        [-7.8573, -3.4121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8086260557174683
Epoch 0, Step 1408: train/loss = 0.09824016690254211, train/raw-loss = 0.008483042940497398, train/logprobs = tensor([[ -1.7412,  -8.4742],
        [-12.1861,  -5.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8975712656974792
Epoch 0, Step 1409: train/loss = 0.2867754101753235, train/raw-loss = 0.22341583669185638, train/logprobs = tensor([[ -2.0025,  -5.5867],
        [-12.8603,  -9.6569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6335956454277039
Epoch 0, Step 1410: train/loss = 0.1274552196264267, train/raw-loss = 0.06103935465216637, train/logprobs = tensor([[ -3.3838, -10.2891],
        [ -8.9051,  -4.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6641587018966675
Epoch 0, Step 1411: train/loss = 0.2659447193145752, train/raw-loss = 0.20790643990039825, train/logprobs = tensor([[-3.6348, -8.4731],
        [-7.4685, -5.3249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.580382764339447
Epoch 0, Step 1412: train/loss = 0.2071472853422165, train/raw-loss = 0.16023172438144684, train/logprobs = tensor([[ -4.4990, -10.6016],
        [ -9.7139,  -6.0121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4691556394100189
Epoch 0, Step 1413: train/loss = 0.1440042406320572, train/raw-loss = 0.07610026001930237, train/logprobs = tensor([[ -2.3878,  -6.9237],
        [-12.6058,  -9.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6790397763252258
Epoch 0, Step 1414: train/loss = 0.12444538623094559, train/raw-loss = 0.010828854516148567, train/logprobs = tensor([[ -2.3907, -10.2544],
        [-12.5625,  -7.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1361653804779053
Epoch 0, Step 1415: train/loss = 0.31830841302871704, train/raw-loss = 0.26055416464805603, train/logprobs = tensor([[-2.4801, -6.8617],
        [-9.6257, -6.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5775427222251892
Epoch 0, Step 1416: train/loss = 0.13576532900333405, train/raw-loss = 0.06841791421175003, train/logprobs = tensor([[-2.7096, -8.4137],
        [-8.8981, -5.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6734740138053894
Epoch 0, Step 1417: train/loss = 0.09211194515228271, train/raw-loss = 0.03229525312781334, train/logprobs = tensor([[-3.6960, -8.5763],
        [-9.0868, -5.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5981668829917908
Epoch 0, Step 1418: train/loss = 0.08907078206539154, train/raw-loss = 0.01427890919148922, train/logprobs = tensor([[ -4.1179, -12.1542],
        [-10.2344,  -4.9269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7479187846183777
Epoch 0, Step 1419: train/loss = 0.09354792535305023, train/raw-loss = 0.006276628468185663, train/logprobs = tensor([[ -1.8188,  -9.4536],
        [-11.9723,  -6.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8727129101753235
Epoch 0, Step 1420: train/loss = 0.15970492362976074, train/raw-loss = 0.11608723551034927, train/logprobs = tensor([[ -2.9350,  -5.6159],
        [-11.3825,  -7.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4361768066883087
Epoch 0, Step 1421: train/loss = 0.16534742712974548, train/raw-loss = 0.09228508174419403, train/logprobs = tensor([[ -2.6296, -10.3848],
        [-12.4149,  -8.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7306233644485474
Epoch 0, Step 1422: train/loss = 0.16887445747852325, train/raw-loss = 0.10063918679952621, train/logprobs = tensor([[-2.2522, -8.8721],
        [-9.8127, -6.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6823526620864868
Epoch 0, Step 1423: train/loss = 0.1839008331298828, train/raw-loss = 0.1090283915400505, train/logprobs = tensor([[ -2.9148,  -9.0505],
        [-11.4550,  -7.5297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7487244606018066
Epoch 0, Step 1424: train/loss = 0.1535690724849701, train/raw-loss = 0.09554417431354523, train/logprobs = tensor([[ -2.8736,  -5.9357],
        [-12.4457,  -6.9480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5802489519119263
Epoch 0, Step 1425: train/loss = 0.16575896739959717, train/raw-loss = 0.10580985248088837, train/logprobs = tensor([[ -3.6222,  -7.1158],
        [-10.4297,  -6.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5994912385940552
Epoch 0, Step 1426: train/loss = 0.17899058759212494, train/raw-loss = 0.1404815912246704, train/logprobs = tensor([[ -2.3216,  -5.1801],
        [-11.2027,  -8.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3850898742675781
Epoch 0, Step 1427: train/loss = 0.9198764562606812, train/raw-loss = 0.848137378692627, train/logprobs = tensor([[ -6.3552, -10.8624],
        [ -8.9447,  -6.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7173916101455688
Epoch 0, Step 1428: train/loss = 0.1256946325302124, train/raw-loss = 0.05340578407049179, train/logprobs = tensor([[ -3.1503,  -7.8200],
        [-10.0235,  -4.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7228884696960449
Epoch 0, Step 1429: train/loss = 0.20847944915294647, train/raw-loss = 0.15865544974803925, train/logprobs = tensor([[ -4.4485, -10.1176],
        [-10.1854,  -7.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4982398748397827
Epoch 0, Step 1430: train/loss = 0.17410880327224731, train/raw-loss = 0.09479692578315735, train/logprobs = tensor([[ -2.8038, -10.5784],
        [-11.0884,  -7.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7931187152862549
Epoch 0, Step 1431: train/loss = 0.09667481482028961, train/raw-loss = 0.018714284524321556, train/logprobs = tensor([[ -2.7508,  -8.8433],
        [-12.0488,  -7.1448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7796052694320679
Epoch 0, Step 1432: train/loss = 0.30032962560653687, train/raw-loss = 0.2524627149105072, train/logprobs = tensor([[ -2.9259,  -6.3257],
        [-10.2323,  -7.2968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47866901755332947
Epoch 0, Step 1433: train/loss = 0.22613127529621124, train/raw-loss = 0.18074114620685577, train/logprobs = tensor([[ -2.9657,  -8.4975],
        [-10.0826,  -7.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4539012312889099
Epoch 0, Step 1434: train/loss = 0.1623975932598114, train/raw-loss = 0.10785879194736481, train/logprobs = tensor([[ -3.2629,  -7.5071],
        [-11.5067,  -6.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.545387864112854
Epoch 0, Step 1435: train/loss = 0.17010381817817688, train/raw-loss = 0.10534913837909698, train/logprobs = tensor([[ -3.5711,  -7.8345],
        [-11.5402,  -6.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6475467681884766
Epoch 0, Step 1436: train/loss = 0.08244456350803375, train/raw-loss = 0.003944525960832834, train/logprobs = tensor([[ -3.4118, -12.4682],
        [-12.7160,  -6.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7850003838539124
Epoch 0, Step 1437: train/loss = 0.5377399325370789, train/raw-loss = 0.4766230881214142, train/logprobs = tensor([[ -2.5522,  -9.1461],
        [-10.3674,  -5.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6111684441566467
Epoch 0, Step 1438: train/loss = 0.10171244293451309, train/raw-loss = 0.03199370205402374, train/logprobs = tensor([[ -2.3758,  -8.0876],
        [-13.0267,  -6.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6971874237060547
Epoch 0, Step 1439: train/loss = 0.10955765098333359, train/raw-loss = 0.029222434386610985, train/logprobs = tensor([[ -2.8777,  -9.7152],
        [-11.9228,  -6.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8033521771430969
Epoch 0, Step 1440: train/loss = 0.2755339741706848, train/raw-loss = 0.21353384852409363, train/logprobs = tensor([[ -3.5461,  -7.5897],
        [-15.3201, -10.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6200011968612671
Epoch 0, Step 1441: train/loss = 0.3643764555454254, train/raw-loss = 0.3170354962348938, train/logprobs = tensor([[ -2.6832,  -5.1153],
        [-13.2228, -10.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4734095335006714
Epoch 0, Step 1442: train/loss = 0.10232341289520264, train/raw-loss = 0.039561957120895386, train/logprobs = tensor([[ -2.9992,  -8.3754],
        [-14.6877, -11.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6276146173477173
Epoch 0, Step 1443: train/loss = 0.7765743136405945, train/raw-loss = 0.7076758146286011, train/logprobs = tensor([[ -4.7690,  -8.9051],
        [-14.2960, -11.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6889846324920654
Epoch 0, Step 1444: train/loss = 0.0960007831454277, train/raw-loss = 0.03850366175174713, train/logprobs = tensor([[ -2.1390,  -7.5546],
        [-14.9493, -12.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5749711990356445
Epoch 0, Step 1445: train/loss = 0.1298360526561737, train/raw-loss = 0.04348492622375488, train/logprobs = tensor([[ -2.6688,  -8.1225],
        [-15.0636,  -8.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.863511323928833
Epoch 0, Step 1446: train/loss = 0.37166938185691833, train/raw-loss = 0.323102205991745, train/logprobs = tensor([[ -4.4733,  -7.9030],
        [-14.0612, -10.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4856717586517334
Epoch 0, Step 1447: train/loss = 0.11918465793132782, train/raw-loss = 0.04826851561665535, train/logprobs = tensor([[ -2.8511,  -8.5180],
        [-15.4964, -12.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7091614007949829
Epoch 0, Step 1448: train/loss = 0.3255539536476135, train/raw-loss = 0.25296294689178467, train/logprobs = tensor([[ -3.6082,  -9.5091],
        [-13.8468, -10.3412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7259097695350647
Epoch 0, Step 1449: train/loss = 0.3155061602592468, train/raw-loss = 0.23911333084106445, train/logprobs = tensor([[ -2.1440,  -8.7887],
        [-17.0281, -12.7743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7639285326004028
Epoch 0, Step 1450: train/loss = 0.2311001718044281, train/raw-loss = 0.16811510920524597, train/logprobs = tensor([[ -2.7664,  -9.6474],
        [-13.1461,  -9.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6298507452011108
Epoch 0, Step 1451: train/loss = 0.13394561409950256, train/raw-loss = 0.06879383325576782, train/logprobs = tensor([[ -3.4305, -11.3011],
        [-11.1080,  -7.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6515177488327026
Epoch 0, Step 1452: train/loss = 0.31700125336647034, train/raw-loss = 0.27278631925582886, train/logprobs = tensor([[ -4.4229,  -7.0025],
        [-11.5548,  -8.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4421495795249939
Epoch 0, Step 1453: train/loss = 0.08097796142101288, train/raw-loss = 0.005656531546264887, train/logprobs = tensor([[ -3.2721, -10.6044],
        [-15.2547,  -9.2190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7532142400741577
Epoch 0, Step 1454: train/loss = 0.5629268288612366, train/raw-loss = 0.5150877833366394, train/logprobs = tensor([[ -7.1704, -10.9519],
        [-11.0522,  -8.4199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4783906936645508
Epoch 0, Step 1455: train/loss = 0.16700959205627441, train/raw-loss = 0.1038658618927002, train/logprobs = tensor([[ -3.0313,  -7.0357],
        [-15.0657,  -9.4902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.631437361240387
Epoch 0, Step 1456: train/loss = 0.40084993839263916, train/raw-loss = 0.3334239721298218, train/logprobs = tensor([[ -3.1780,  -8.0468],
        [-13.4256,  -9.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6742594838142395
Epoch 0, Step 1457: train/loss = 0.24808305501937866, train/raw-loss = 0.18008795380592346, train/logprobs = tensor([[ -4.9611, -10.5937],
        [-12.6408,  -8.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6799509525299072
Epoch 0, Step 1458: train/loss = 0.16075381636619568, train/raw-loss = 0.09282319992780685, train/logprobs = tensor([[ -3.7814, -10.7127],
        [-13.8026, -10.3913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6793060898780823
Epoch 0, Step 1459: train/loss = 0.0913543626666069, train/raw-loss = 0.014644628390669823, train/logprobs = tensor([[ -3.7633, -11.6533],
        [-14.7745, -10.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7670972347259521
Epoch 0, Step 1460: train/loss = 0.14801324903964996, train/raw-loss = 0.06595028191804886, train/logprobs = tensor([[ -1.8736,  -8.7738],
        [-14.3122,  -9.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8206297159194946
Epoch 0, Step 1461: train/loss = 0.19112814962863922, train/raw-loss = 0.12661318480968475, train/logprobs = tensor([[ -3.7873, -10.3216],
        [-14.4965, -10.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6451495289802551
Epoch 0, Step 1462: train/loss = 0.16797269880771637, train/raw-loss = 0.10795754194259644, train/logprobs = tensor([[ -2.6334,  -8.3529],
        [-15.7542, -13.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.600151538848877
Epoch 0, Step 1463: train/loss = 0.2685946226119995, train/raw-loss = 0.21522973477840424, train/logprobs = tensor([[ -3.8950,  -9.8901],
        [-12.7520,  -9.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5336489081382751
Epoch 0, Step 1464: train/loss = 0.08339674770832062, train/raw-loss = 0.008673734962940216, train/logprobs = tensor([[ -3.3631,  -9.9885],
        [-13.7181,  -8.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7472301721572876
Epoch 0, Step 1465: train/loss = 0.34077927470207214, train/raw-loss = 0.2993798851966858, train/logprobs = tensor([[ -3.2246,  -5.1610],
        [-12.0181,  -9.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41399407386779785
Epoch 0, Step 1466: train/loss = 0.1693459153175354, train/raw-loss = 0.11844043433666229, train/logprobs = tensor([[ -2.6723,  -6.3254],
        [-14.8448, -11.2786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5090548992156982
Epoch 0, Step 1467: train/loss = 0.12312579154968262, train/raw-loss = 0.05730323866009712, train/logprobs = tensor([[ -3.7522,  -8.9116],
        [-15.2027,  -9.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6582255363464355
Epoch 0, Step 1468: train/loss = 0.07683436572551727, train/raw-loss = 0.007159536704421043, train/logprobs = tensor([[ -2.7224,  -8.2322],
        [-14.6599,  -9.1264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6967482566833496
Epoch 0, Step 1469: train/loss = 0.24034757912158966, train/raw-loss = 0.16545948386192322, train/logprobs = tensor([[ -1.9750,  -8.4359],
        [-13.2908,  -9.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7488811016082764
Epoch 0, Step 1470: train/loss = 0.1032344400882721, train/raw-loss = 0.03686374053359032, train/logprobs = tensor([[ -2.0392, -10.7529],
        [-14.5034, -10.0904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6637070178985596
Epoch 0, Step 1471: train/loss = 0.09177692979574203, train/raw-loss = 0.03529756888747215, train/logprobs = tensor([[ -3.3531,  -9.0231],
        [-13.5133,  -9.9406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5647936463356018
Epoch 0, Step 1472: train/loss = 0.6096513867378235, train/raw-loss = 0.5803943276405334, train/logprobs = tensor([[ -5.3868,  -7.5809],
        [-12.3789,  -9.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.292570561170578
Epoch 0, Step 1473: train/loss = 0.11638032644987106, train/raw-loss = 0.048816241323947906, train/logprobs = tensor([[ -2.8210,  -9.4338],
        [-17.3676, -11.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.675640881061554
Epoch 0, Step 1474: train/loss = 0.7549574375152588, train/raw-loss = 0.7180713415145874, train/logprobs = tensor([[ -3.4870,  -5.4350],
        [-12.5452, -10.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3688600957393646
Epoch 0, Step 1475: train/loss = 0.08646172285079956, train/raw-loss = 0.005285386461764574, train/logprobs = tensor([[ -2.5391, -10.9208],
        [-17.1808,  -9.3658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8117632865905762
Epoch 0, Step 1476: train/loss = 0.17625822126865387, train/raw-loss = 0.11300764232873917, train/logprobs = tensor([[ -3.6857, -11.0379],
        [-15.9688, -10.3729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6325058341026306
Epoch 0, Step 1477: train/loss = 0.1110665574669838, train/raw-loss = 0.04403156787157059, train/logprobs = tensor([[ -3.0010,  -9.8149],
        [-16.3644, -11.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6703498363494873
Epoch 0, Step 1478: train/loss = 0.17516475915908813, train/raw-loss = 0.09681830555200577, train/logprobs = tensor([[ -3.1281,  -9.9641],
        [-15.3032, -10.4304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7834645509719849
Epoch 0, Step 1479: train/loss = 0.23738546669483185, train/raw-loss = 0.1787899136543274, train/logprobs = tensor([[ -5.0164, -11.7667],
        [-12.6639,  -8.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5859553217887878
Epoch 0, Step 1480: train/loss = 0.34582510590553284, train/raw-loss = 0.2826573848724365, train/logprobs = tensor([[ -4.5010,  -8.2548],
        [-14.8770, -11.7365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6316772699356079
Epoch 0, Step 1481: train/loss = 0.09431715309619904, train/raw-loss = 0.022317932918667793, train/logprobs = tensor([[ -2.7951, -10.0944],
        [-15.5917,  -9.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7199921607971191
Epoch 0, Step 1482: train/loss = 0.14865419268608093, train/raw-loss = 0.10052400082349777, train/logprobs = tensor([[ -3.9926,  -9.1613],
        [-17.3014, -13.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4813019037246704
Epoch 0, Step 1483: train/loss = 0.40173736214637756, train/raw-loss = 0.349541038274765, train/logprobs = tensor([[ -2.4169,  -6.6781],
        [-16.0216, -11.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5219630599021912
Epoch 0, Step 1484: train/loss = 0.10639562457799911, train/raw-loss = 0.02000539004802704, train/logprobs = tensor([[ -3.1932, -10.2149],
        [-16.0099,  -8.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8639023303985596
Epoch 0, Step 1485: train/loss = 0.3047829270362854, train/raw-loss = 0.2635056674480438, train/logprobs = tensor([[ -2.4707,  -4.0086],
        [-16.9943, -13.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41277259588241577
Epoch 0, Step 1486: train/loss = 0.093487948179245, train/raw-loss = 0.01838553138077259, train/logprobs = tensor([[ -2.8638,  -9.1585],
        [-18.6075, -11.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7510241270065308
Epoch 0, Step 1487: train/loss = 0.7362607717514038, train/raw-loss = 0.6619811058044434, train/logprobs = tensor([[ -4.0767, -10.9832],
        [-12.0439, -10.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7427966594696045
Epoch 0, Step 1488: train/loss = 0.1186935305595398, train/raw-loss = 0.03569692373275757, train/logprobs = tensor([[ -3.5099,  -9.0446],
        [-18.0156, -12.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8299659490585327
Epoch 0, Step 1489: train/loss = 0.6257271766662598, train/raw-loss = 0.5547168254852295, train/logprobs = tensor([[ -3.4072,  -7.5013],
        [-15.0605, -12.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7101038098335266
Epoch 0, Step 1490: train/loss = 0.9331590533256531, train/raw-loss = 0.884332001209259, train/logprobs = tensor([[ -4.0741,  -6.0559],
        [-14.9784, -13.4025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48827028274536133
Epoch 0, Step 1491: train/loss = 0.23793205618858337, train/raw-loss = 0.17385047674179077, train/logprobs = tensor([[ -2.1239,  -7.5886],
        [-15.4590, -10.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.640815794467926
Epoch 0, Step 1492: train/loss = 0.17168031632900238, train/raw-loss = 0.12313637882471085, train/logprobs = tensor([[ -2.2729,  -7.7184],
        [-17.5139, -13.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48543938994407654
Epoch 0, Step 1493: train/loss = 0.1102418452501297, train/raw-loss = 0.03841651603579521, train/logprobs = tensor([[ -4.8435, -10.0197],
        [-15.3972,  -8.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7182532548904419
Epoch 0, Step 1494: train/loss = 0.682134747505188, train/raw-loss = 0.6501303911209106, train/logprobs = tensor([[ -3.4533,  -5.2861],
        [-13.6937, -11.7829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200438320636749
Epoch 0, Step 1495: train/loss = 0.20714037120342255, train/raw-loss = 0.1538938581943512, train/logprobs = tensor([[ -4.5983, -10.3536],
        [-13.4277,  -8.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5324650406837463
Epoch 0, Step 1496: train/loss = 0.22043873369693756, train/raw-loss = 0.20148876309394836, train/logprobs = tensor([[ -3.5278,  -8.8086],
        [-14.7641, -14.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18949970602989197
Epoch 0, Step 1497: train/loss = 0.1386452615261078, train/raw-loss = 0.053335025906562805, train/logprobs = tensor([[ -3.9967, -10.4057],
        [-15.5476,  -9.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8531023263931274
Epoch 0, Step 1498: train/loss = 0.08830677717924118, train/raw-loss = 0.00809631496667862, train/logprobs = tensor([[ -3.9458, -10.0874],
        [-16.7078,  -9.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.802104651927948
Epoch 0, Step 1499: train/loss = 0.09991436451673508, train/raw-loss = 0.030686402693390846, train/logprobs = tensor([[ -3.0715,  -9.8616],
        [-16.5678, -10.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6922796368598938
eval/loss: 0.236031174659729
Epoch 0, Step 1500: train/loss = 0.07919901609420776, train/raw-loss = 0.009355365298688412, train/logprobs = tensor([[ -4.0928,  -9.5128],
        [-14.4911,  -7.4873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6984364986419678
Epoch 0, Step 1501: train/loss = 0.08962908387184143, train/raw-loss = 0.012799382209777832, train/logprobs = tensor([[ -4.3343, -11.6920],
        [-17.2296, -11.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7682970762252808
Epoch 0, Step 1502: train/loss = 0.5056378841400146, train/raw-loss = 0.4232868552207947, train/logprobs = tensor([[ -3.7334, -10.2447],
        [-15.6183, -10.2086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8235102891921997
Epoch 0, Step 1503: train/loss = 0.4410760998725891, train/raw-loss = 0.41782382130622864, train/logprobs = tensor([[-4.4017, -8.7196],
        [-9.0668, -8.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2325229048728943
Epoch 0, Step 1504: train/loss = 0.31858691573143005, train/raw-loss = 0.26060909032821655, train/logprobs = tensor([[ -4.1802, -12.5322],
        [-12.1935,  -7.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5797778367996216
Epoch 0, Step 1505: train/loss = 0.22654485702514648, train/raw-loss = 0.16660743951797485, train/logprobs = tensor([[ -2.9171,  -7.9396],
        [-15.4676,  -9.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5993742942810059
Epoch 0, Step 1506: train/loss = 0.5937033891677856, train/raw-loss = 0.5117178559303284, train/logprobs = tensor([[ -3.4617,  -9.8900],
        [-11.2870,  -7.4912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8198549747467041
Epoch 0, Step 1507: train/loss = 0.09702806919813156, train/raw-loss = 0.01567091792821884, train/logprobs = tensor([[ -2.9698,  -9.1227],
        [-17.7322, -10.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8135714530944824
Epoch 0, Step 1508: train/loss = 0.07390683889389038, train/raw-loss = 0.0033184292260557413, train/logprobs = tensor([[ -3.6524, -13.0791],
        [-13.1847,  -5.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7058840990066528
Epoch 0, Step 1509: train/loss = 0.5652904510498047, train/raw-loss = 0.4978346526622772, train/logprobs = tensor([[ -4.8586, -10.6379],
        [-12.7330,  -9.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6745582818984985
Epoch 0, Step 1510: train/loss = 0.2403832972049713, train/raw-loss = 0.14306367933750153, train/logprobs = tensor([[ -2.7252, -11.9628],
        [-12.6964,  -6.4290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9731961488723755
Epoch 0, Step 1511: train/loss = 0.11133536696434021, train/raw-loss = 0.02672182396054268, train/logprobs = tensor([[ -3.0225, -10.2730],
        [-16.4941,  -9.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8461354374885559
Epoch 0, Step 1512: train/loss = 0.4760231375694275, train/raw-loss = 0.4139314889907837, train/logprobs = tensor([[ -3.4884,  -8.6274],
        [-12.6715,  -7.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.620916485786438
Epoch 0, Step 1513: train/loss = 0.13441111147403717, train/raw-loss = 0.06841081380844116, train/logprobs = tensor([[ -4.1030,  -9.6717],
        [-12.5651,  -9.2322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6600030660629272
Epoch 0, Step 1514: train/loss = 0.8622372150421143, train/raw-loss = 0.8025913238525391, train/logprobs = tensor([[ -3.1167,  -9.3493],
        [-13.3802,  -9.6646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5964586734771729
Epoch 0, Step 1515: train/loss = 0.09124405682086945, train/raw-loss = 0.0072449673898518085, train/logprobs = tensor([[ -3.6938,  -9.5277],
        [-13.1671,  -5.6132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8399909138679504
Epoch 0, Step 1516: train/loss = 0.3440280258655548, train/raw-loss = 0.3032200038433075, train/logprobs = tensor([[ -3.4774,  -5.1936],
        [-14.4492, -11.4306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.408080130815506
Epoch 0, Step 1517: train/loss = 0.09726671129465103, train/raw-loss = 0.009006379172205925, train/logprobs = tensor([[ -3.5416, -10.6077],
        [-14.3635,  -6.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8826032876968384
Epoch 0, Step 1518: train/loss = 0.18232175707817078, train/raw-loss = 0.11227773874998093, train/logprobs = tensor([[ -3.0193,  -9.6250],
        [-15.5701,  -8.2682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7004401087760925
Epoch 0, Step 1519: train/loss = 0.08914556354284286, train/raw-loss = 0.008088608272373676, train/logprobs = tensor([[ -3.1229, -10.2729],
        [-14.8671,  -7.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8105695247650146
Epoch 0, Step 1520: train/loss = 0.16841301321983337, train/raw-loss = 0.10124365240335464, train/logprobs = tensor([[ -3.8066, -12.3305],
        [-13.3700,  -6.4697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6716935634613037
Epoch 0, Step 1521: train/loss = 0.24555788934230804, train/raw-loss = 0.21086031198501587, train/logprobs = tensor([[ -4.1579,  -6.8743],
        [-13.9228, -10.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3469759523868561
Epoch 0, Step 1522: train/loss = 0.09182365983724594, train/raw-loss = 0.005459606181830168, train/logprobs = tensor([[ -3.3751, -11.0447],
        [-14.7605,  -6.4276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8636404275894165
Epoch 0, Step 1523: train/loss = 0.48266729712486267, train/raw-loss = 0.4618734121322632, train/logprobs = tensor([[ -4.4952,  -6.1495],
        [-13.2624, -11.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20793887972831726
Epoch 0, Step 1524: train/loss = 0.16049076616764069, train/raw-loss = 0.08630271255970001, train/logprobs = tensor([[ -4.2553, -10.4130],
        [-11.8761,  -4.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7418806552886963
Epoch 0, Step 1525: train/loss = 0.2851337194442749, train/raw-loss = 0.255749374628067, train/logprobs = tensor([[ -2.5861,  -4.5996],
        [-14.8549, -12.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2938435673713684
Epoch 0, Step 1526: train/loss = 0.17394092679023743, train/raw-loss = 0.09542466700077057, train/logprobs = tensor([[ -4.5215, -16.5713],
        [-11.0293,  -4.2586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7851625680923462
Epoch 0, Step 1527: train/loss = 0.3020428717136383, train/raw-loss = 0.23790182173252106, train/logprobs = tensor([[ -5.0094,  -8.9973],
        [-14.2155,  -9.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6414104104042053
Epoch 0, Step 1528: train/loss = 0.30313315987586975, train/raw-loss = 0.2482665479183197, train/logprobs = tensor([[ -3.3735,  -9.5634],
        [-14.3491, -10.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.54866623878479
Epoch 0, Step 1529: train/loss = 0.11868800222873688, train/raw-loss = 0.04490223899483681, train/logprobs = tensor([[ -4.3639, -11.4932],
        [-12.6558,  -6.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7378576993942261
Epoch 0, Step 1530: train/loss = 0.08561371266841888, train/raw-loss = 0.008179542608559132, train/logprobs = tensor([[ -3.2688, -10.8812],
        [-16.5154,  -9.9662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7743417024612427
Epoch 0, Step 1531: train/loss = 0.09157265722751617, train/raw-loss = 0.0004800018505193293, train/logprobs = tensor([[ -2.4927, -14.6810],
        [-16.6777,  -6.2065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9109265804290771
Epoch 0, Step 1532: train/loss = 0.6167647242546082, train/raw-loss = 0.548983097076416, train/logprobs = tensor([[ -5.0291, -10.6143],
        [-12.0414,  -6.4857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6778155565261841
Epoch 0, Step 1533: train/loss = 0.3508589565753937, train/raw-loss = 0.279382586479187, train/logprobs = tensor([[ -3.1740,  -9.1420],
        [-15.3476,  -8.9130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7147637605667114
Epoch 0, Step 1534: train/loss = 0.10961336642503738, train/raw-loss = 0.058018043637275696, train/logprobs = tensor([[ -4.9673, -11.8425],
        [-10.5078,  -5.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5159531831741333
Epoch 0, Step 1535: train/loss = 0.07979221642017365, train/raw-loss = 0.004028330557048321, train/logprobs = tensor([[ -3.7992, -14.7275],
        [-13.1679,  -6.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7576388716697693
Epoch 0, Step 1536: train/loss = 0.7146582007408142, train/raw-loss = 0.6660336852073669, train/logprobs = tensor([[ -4.3387,  -6.3678],
        [-12.5271,  -9.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48624515533447266
Epoch 0, Step 1537: train/loss = 0.09711557626724243, train/raw-loss = 0.00031175604090094566, train/logprobs = tensor([[ -3.5340, -15.1883],
        [-12.5305,  -4.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9680382609367371
Epoch 0, Step 1538: train/loss = 0.09579240530729294, train/raw-loss = 0.023680001497268677, train/logprobs = tensor([[ -4.6083, -11.0963],
        [-11.3058,  -6.3260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7211240530014038
Epoch 0, Step 1539: train/loss = 0.11198590695858002, train/raw-loss = 0.008149281144142151, train/logprobs = tensor([[ -2.8834, -11.7554],
        [-10.9937,  -3.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0383661985397339
Epoch 0, Step 1540: train/loss = 0.08426959812641144, train/raw-loss = 0.0002563160960562527, train/logprobs = tensor([[ -4.0478, -18.1666],
        [-11.5913,  -4.4155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8401328325271606
Epoch 0, Step 1541: train/loss = 0.07970789074897766, train/raw-loss = 0.013777894899249077, train/logprobs = tensor([[ -4.6231, -10.2256],
        [ -9.4946,  -3.6030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6592999696731567
Epoch 0, Step 1542: train/loss = 0.08367235213518143, train/raw-loss = 0.0066660987213253975, train/logprobs = tensor([[ -3.7072, -12.9722],
        [-10.3570,  -2.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7700625658035278
Epoch 0, Step 1543: train/loss = 1.439430594444275, train/raw-loss = 1.4124280214309692, train/logprobs = tensor([[ -6.0941,  -6.1488],
        [ -9.6048, -10.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700253427028656
Epoch 0, Step 1544: train/loss = 0.24660764634609222, train/raw-loss = 0.16643284261226654, train/logprobs = tensor([[ -4.3738, -12.0745],
        [-12.7296,  -5.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8017479777336121
Epoch 0, Step 1545: train/loss = 0.13289162516593933, train/raw-loss = 0.07927411794662476, train/logprobs = tensor([[ -6.6898, -10.4443],
        [ -9.8245,  -6.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.536175012588501
Epoch 0, Step 1546: train/loss = 0.09605611860752106, train/raw-loss = 0.003422447247430682, train/logprobs = tensor([[ -2.8656, -10.9036],
        [-14.1904,  -4.2996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9263367056846619
Epoch 0, Step 1547: train/loss = 0.09143275767564774, train/raw-loss = 0.0030842379201203585, train/logprobs = tensor([[ -4.1098, -14.2409],
        [-12.6984,  -5.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8834851980209351
Epoch 0, Step 1548: train/loss = 0.08320707082748413, train/raw-loss = 0.005128439981490374, train/logprobs = tensor([[ -4.2335, -11.9927],
        [-11.7951,  -4.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7807863354682922
Epoch 0, Step 1549: train/loss = 0.5673537254333496, train/raw-loss = 0.5275458097457886, train/logprobs = tensor([[-8.2878, -9.7942],
        [-9.2518, -4.6366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39807868003845215
Epoch 0, Step 1550: train/loss = 0.39677363634109497, train/raw-loss = 0.3382171094417572, train/logprobs = tensor([[ -7.3241, -11.6837],
        [ -6.8935,  -4.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5855655074119568
Epoch 0, Step 1551: train/loss = 0.10351277887821198, train/raw-loss = 0.0022600700613111258, train/logprobs = tensor([[ -5.1134, -15.6295],
        [ -8.6143,  -3.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0125271081924438
Epoch 0, Step 1552: train/loss = 0.09543206542730331, train/raw-loss = 0.005849071778357029, train/logprobs = tensor([[ -5.0451, -18.9609],
        [-11.0868,  -2.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.895829975605011
Epoch 0, Step 1553: train/loss = 0.084993876516819, train/raw-loss = 0.017547179013490677, train/logprobs = tensor([[ -4.1652, -10.5011],
        [-10.8263,  -4.5569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6744670271873474
Epoch 0, Step 1554: train/loss = 0.26508885622024536, train/raw-loss = 0.21028801798820496, train/logprobs = tensor([[ -2.2338,  -7.0700],
        [-13.0767,  -6.9539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5480083227157593
Epoch 0, Step 1555: train/loss = 0.10185981541872025, train/raw-loss = 0.001455881865695119, train/logprobs = tensor([[ -4.2685, -13.6479],
        [-13.0987,  -3.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0040392875671387
Epoch 0, Step 1556: train/loss = 0.1320689618587494, train/raw-loss = 0.04293708875775337, train/logprobs = tensor([[ -3.4328, -12.3951],
        [-13.6262,  -6.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8913187980651855
Epoch 0, Step 1557: train/loss = 0.1818755567073822, train/raw-loss = 0.1350974440574646, train/logprobs = tensor([[ -3.7076,  -9.6828],
        [-11.9783,  -8.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46778103709220886
Epoch 0, Step 1558: train/loss = 0.16992038488388062, train/raw-loss = 0.06763674318790436, train/logprobs = tensor([[ -2.9471, -12.3279],
        [-10.3308,  -5.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.022836446762085
Epoch 0, Step 1559: train/loss = 0.24950319528579712, train/raw-loss = 0.17557932436466217, train/logprobs = tensor([[ -2.7945, -10.7658],
        [-15.1731,  -4.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7392387986183167
Epoch 0, Step 1560: train/loss = 0.12129517644643784, train/raw-loss = 0.04922528937458992, train/logprobs = tensor([[ -5.1406, -11.3709],
        [ -9.0424,  -2.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7206988334655762
Epoch 0, Step 1561: train/loss = 0.09061119705438614, train/raw-loss = 0.013242807239294052, train/logprobs = tensor([[ -3.6383, -10.7678],
        [-13.2835,  -6.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7736839056015015
Epoch 0, Step 1562: train/loss = 0.17944760620594025, train/raw-loss = 0.10519912093877792, train/logprobs = tensor([[ -4.3273, -10.1930],
        [-13.8767,  -7.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7424848675727844
Epoch 0, Step 1563: train/loss = 0.10363933444023132, train/raw-loss = 0.00965670496225357, train/logprobs = tensor([[ -5.3866, -17.9845],
        [ -8.3598,  -2.7230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9398263692855835
Epoch 0, Step 1564: train/loss = 0.12250930815935135, train/raw-loss = 0.03156530112028122, train/logprobs = tensor([[ -4.1294, -10.9031],
        [-11.3254,  -5.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9094401597976685
Epoch 0, Step 1565: train/loss = 0.1543395072221756, train/raw-loss = 0.08186612278223038, train/logprobs = tensor([[ -5.5214, -14.1974],
        [-11.3043,  -3.7885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.724733829498291
Epoch 0, Step 1566: train/loss = 0.2980841100215912, train/raw-loss = 0.2309107780456543, train/logprobs = tensor([[ -2.4576,  -9.1060],
        [-14.4089,  -7.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6717333793640137
Epoch 0, Step 1567: train/loss = 0.13807107508182526, train/raw-loss = 0.08382386714220047, train/logprobs = tensor([[ -3.8208, -12.2072],
        [-10.5295,  -7.2118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5424721240997314
Epoch 0, Step 1568: train/loss = 0.10316090285778046, train/raw-loss = 0.0388670414686203, train/logprobs = tensor([[ -5.0969, -12.3460],
        [ -9.1607,  -4.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6429386138916016
Epoch 0, Step 1569: train/loss = 0.2783004939556122, train/raw-loss = 0.23591989278793335, train/logprobs = tensor([[-4.0542, -7.9396],
        [-8.2836, -4.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4238060414791107
Epoch 0, Step 1570: train/loss = 0.39068591594696045, train/raw-loss = 0.31131789088249207, train/logprobs = tensor([[ -5.0297, -12.0757],
        [ -7.5615,  -4.2493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7936801314353943
Epoch 0, Step 1571: train/loss = 0.16357283294200897, train/raw-loss = 0.10219404846429825, train/logprobs = tensor([[ -5.1334, -10.0048],
        [ -8.4799,  -4.5056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.613787829875946
Epoch 0, Step 1572: train/loss = 0.1374480128288269, train/raw-loss = 0.05716155469417572, train/logprobs = tensor([[ -3.3619, -13.8631],
        [-10.5340,  -3.4289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8028644919395447
Epoch 0, Step 1573: train/loss = 0.07789325714111328, train/raw-loss = 0.003797454759478569, train/logprobs = tensor([[ -3.7315, -11.6841],
        [ -7.8245,  -3.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7409579753875732
Epoch 0, Step 1574: train/loss = 0.357705295085907, train/raw-loss = 0.3119634985923767, train/logprobs = tensor([[ -5.7673, -12.9020],
        [-12.0717,  -7.4715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.457417756319046
Epoch 0, Step 1575: train/loss = 0.08579309284687042, train/raw-loss = 0.011854236014187336, train/logprobs = tensor([[ -4.6109, -13.7206],
        [ -8.4604,  -2.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7393885850906372
Epoch 0, Step 1576: train/loss = 0.0910811573266983, train/raw-loss = 0.02976302057504654, train/logprobs = tensor([[ -5.3907, -13.1733],
        [ -9.2563,  -5.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6131813526153564
Epoch 0, Step 1577: train/loss = 0.08400743454694748, train/raw-loss = 0.006556753069162369, train/logprobs = tensor([[ -3.4967, -14.3447],
        [-10.1807,  -4.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7745068073272705
Epoch 0, Step 1578: train/loss = 0.08314499258995056, train/raw-loss = 0.004812402650713921, train/logprobs = tensor([[ -4.1467, -12.9015],
        [ -7.9553,  -3.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7833259701728821
Epoch 0, Step 1579: train/loss = 0.08449320495128632, train/raw-loss = 0.0007931471918709576, train/logprobs = tensor([[ -3.8027, -16.9395],
        [-10.5891,  -4.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8370004892349243
Epoch 0, Step 1580: train/loss = 0.14059212803840637, train/raw-loss = 0.07318523526191711, train/logprobs = tensor([[ -3.8051, -12.6904],
        [-10.3657,  -3.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6740689277648926
Epoch 0, Step 1581: train/loss = 0.08333519101142883, train/raw-loss = 0.011366489343345165, train/logprobs = tensor([[ -3.9489, -12.5130],
        [ -8.0834,  -1.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7196870446205139
Epoch 0, Step 1582: train/loss = 0.08221231400966644, train/raw-loss = 0.010009041987359524, train/logprobs = tensor([[ -3.1900, -15.1388],
        [ -8.9548,  -3.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7220326662063599
Epoch 0, Step 1583: train/loss = 0.3591200113296509, train/raw-loss = 0.2798703908920288, train/logprobs = tensor([[ -2.5159,  -9.2016],
        [-12.4647,  -5.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7924962043762207
Epoch 0, Step 1584: train/loss = 0.09530907869338989, train/raw-loss = 0.006033686455339193, train/logprobs = tensor([[ -5.6703, -13.4311],
        [ -8.1132,  -1.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8927538394927979
Epoch 0, Step 1585: train/loss = 0.33608704805374146, train/raw-loss = 0.281371146440506, train/logprobs = tensor([[ -5.0042, -12.9151],
        [ -8.3848,  -4.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5471587181091309
Epoch 0, Step 1586: train/loss = 0.09677162021398544, train/raw-loss = 0.032080717384815216, train/logprobs = tensor([[ -5.3453, -10.8920],
        [ -9.1640,  -3.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6469089984893799
Epoch 0, Step 1587: train/loss = 0.6088104248046875, train/raw-loss = 0.557397186756134, train/logprobs = tensor([[ -7.2341, -11.3352],
        [ -8.7757,  -7.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5141327381134033
Epoch 0, Step 1588: train/loss = 0.12770023941993713, train/raw-loss = 0.05235042795538902, train/logprobs = tensor([[ -5.7634, -15.0991],
        [ -8.9405,  -4.5167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7534981966018677
Epoch 0, Step 1589: train/loss = 0.1312302201986313, train/raw-loss = 0.07395527511835098, train/logprobs = tensor([[ -5.8078, -10.0981],
        [ -8.6066,  -4.1100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5727495551109314
Epoch 0, Step 1590: train/loss = 0.18936656415462494, train/raw-loss = 0.13635559380054474, train/logprobs = tensor([[ -3.3901,  -7.6027],
        [-10.0975,  -4.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.530109703540802
Epoch 0, Step 1591: train/loss = 0.4166576862335205, train/raw-loss = 0.37853989005088806, train/logprobs = tensor([[ -1.7718,  -4.4188],
        [-12.9624,  -8.2466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3811779320240021
Epoch 0, Step 1592: train/loss = 0.14963823556900024, train/raw-loss = 0.10228735208511353, train/logprobs = tensor([[ -6.0828, -10.6810],
        [-11.2832,  -7.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47350889444351196
Epoch 0, Step 1593: train/loss = 0.26854991912841797, train/raw-loss = 0.21702277660369873, train/logprobs = tensor([[-3.8145, -8.0531],
        [-9.0121, -6.0716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5152713060379028
Epoch 0, Step 1594: train/loss = 0.14319510757923126, train/raw-loss = 0.0854274183511734, train/logprobs = tensor([[ -4.3736, -11.5453],
        [ -6.4242,  -2.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5776767730712891
Epoch 0, Step 1595: train/loss = 0.3945607841014862, train/raw-loss = 0.3662434220314026, train/logprobs = tensor([[-5.0619, -8.9355],
        [-9.1403, -7.4770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28317365050315857
Epoch 0, Step 1596: train/loss = 0.30214908719062805, train/raw-loss = 0.25993651151657104, train/logprobs = tensor([[ -2.7350,  -7.8836],
        [-10.0132,  -7.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4221258759498596
Epoch 0, Step 1597: train/loss = 0.24554775655269623, train/raw-loss = 0.17702993750572205, train/logprobs = tensor([[ -7.6391, -19.7859],
        [ -8.6169,  -3.1927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.685178279876709
