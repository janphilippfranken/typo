[2024-02-28 12:20:20,837][root][INFO] - beta: 1.0
[2024-02-28 12:20:20,837][root][INFO] - loss no_reference
[2024-02-28 12:20:20,837][root][INFO] - max_iter: 0
[2024-02-28 12:20:20,837][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-no-ref-clip
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-no-ref-clip after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-no-ref-clip after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-no-ref-clip after each epoch.
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-no-ref-clip after each epoch.
Epoch 0, Step 0: train/loss = 0.6986424326896667, train/raw-loss = 0.6986424326896667, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6927841901779175, train/raw-loss = 0.6927841901779175, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6913306713104248, train/raw-loss = 0.6913306713104248, train/logprobs = tensor([[-1.0892, -2.0869],
        [-1.1206, -2.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6831067204475403, train/raw-loss = 0.6831067204475403, train/logprobs = tensor([[-0.5922, -1.4420],
        [-0.5997, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6810191869735718, train/raw-loss = 0.6810191869735718, train/logprobs = tensor([[-0.9682, -2.2517],
        [-1.0031, -2.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6957630515098572, train/raw-loss = 0.6957630515098572, train/logprobs = tensor([[-1.2526, -1.8470],
        [-1.2661, -1.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6882051825523376, train/raw-loss = 0.6882051825523376, train/logprobs = tensor([[-0.9823, -1.5991],
        [-1.0011, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.7003128528594971, train/raw-loss = 0.7003128528594971, train/logprobs = tensor([[-1.0630, -1.5507],
        [-1.1077, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6910343170166016, train/raw-loss = 0.6910343170166016, train/logprobs = tensor([[-0.8023, -1.7333],
        [-0.7871, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6886264681816101, train/raw-loss = 0.6886264681816101, train/logprobs = tensor([[-1.0835, -1.7181],
        [-1.0813, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6732417345046997, train/raw-loss = 0.6732417345046997, train/logprobs = tensor([[-1.1971, -2.5060],
        [-1.2764, -2.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6859524250030518, train/raw-loss = 0.6859524250030518, train/logprobs = tensor([[-0.7466, -1.5640],
        [-0.7228, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6860025525093079, train/raw-loss = 0.6860025525093079, train/logprobs = tensor([[-0.7433, -1.8789],
        [-0.7825, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6820299625396729, train/raw-loss = 0.6820299625396729, train/logprobs = tensor([[-0.7519, -1.6611],
        [-0.7745, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6829711198806763, train/raw-loss = 0.6829711198806763, train/logprobs = tensor([[-1.1222, -1.7514],
        [-1.1230, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6998041272163391, train/raw-loss = 0.6998041272163391, train/logprobs = tensor([[-1.0901, -1.5558],
        [-1.0901, -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6731890439987183, train/raw-loss = 0.6731890439987183, train/logprobs = tensor([[-0.9616, -2.0296],
        [-0.9940, -1.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6903007626533508, train/raw-loss = 0.6903007626533508, train/logprobs = tensor([[-1.0904, -1.5065],
        [-1.0878, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6893983483314514, train/raw-loss = 0.6893983483314514, train/logprobs = tensor([[-1.1498, -1.6923],
        [-1.1412, -1.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6923284530639648, train/raw-loss = 0.6923284530639648, train/logprobs = tensor([[-0.7575, -1.3558],
        [-0.7511, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6831136345863342, train/raw-loss = 0.6831136345863342, train/logprobs = tensor([[-0.6982, -1.6722],
        [-0.7384, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6923891305923462, train/raw-loss = 0.6923891305923462, train/logprobs = tensor([[-0.9935, -1.2997],
        [-0.9919, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.685130774974823, train/raw-loss = 0.685130774974823, train/logprobs = tensor([[-1.1048, -1.2115],
        [-1.1166, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7055131196975708, train/raw-loss = 0.7055131196975708, train/logprobs = tensor([[-1.1101, -1.9440],
        [-1.1279, -2.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6885606050491333, train/raw-loss = 0.6885606050491333, train/logprobs = tensor([[-0.9510, -2.1814],
        [-0.9490, -2.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6841186285018921, train/raw-loss = 0.6841186285018921, train/logprobs = tensor([[-0.8277, -2.2563],
        [-0.8247, -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6955066919326782, train/raw-loss = 0.6955066919326782, train/logprobs = tensor([[-0.5759, -2.1066],
        [-0.6087, -2.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6868736743927002, train/raw-loss = 0.6868736743927002, train/logprobs = tensor([[-1.0402, -2.5564],
        [-1.0804, -2.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6864776015281677, train/raw-loss = 0.6864776015281677, train/logprobs = tensor([[-0.8392, -1.7205],
        [-0.8369, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6928223371505737, train/raw-loss = 0.6928223371505737, train/logprobs = tensor([[-0.5879, -1.8914],
        [-0.5988, -1.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6892132759094238, train/raw-loss = 0.6892132759094238, train/logprobs = tensor([[-0.8561, -1.1920],
        [-0.8388, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6652477979660034, train/raw-loss = 0.6652477979660034, train/logprobs = tensor([[-1.0550, -2.2670],
        [-1.0818, -2.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6819109916687012, train/raw-loss = 0.6819109916687012, train/logprobs = tensor([[-0.9240, -1.9170],
        [-0.9467, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6963053941726685, train/raw-loss = 0.6963053941726685, train/logprobs = tensor([[-0.8779, -1.8828],
        [-0.8573, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6830999255180359, train/raw-loss = 0.6830999255180359, train/logprobs = tensor([[-1.0511, -1.5128],
        [-1.0826, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6865392923355103, train/raw-loss = 0.6865392923355103, train/logprobs = tensor([[-0.9902, -1.8427],
        [-0.9916, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6854631900787354, train/raw-loss = 0.6854631900787354, train/logprobs = tensor([[-1.2729, -1.4568],
        [-1.2776, -1.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.6874720454216003, train/raw-loss = 0.6874720454216003, train/logprobs = tensor([[-0.6132, -1.4763],
        [-0.6105, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6822277903556824, train/raw-loss = 0.6822277903556824, train/logprobs = tensor([[-0.8017, -1.5622],
        [-0.8207, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6942781209945679, train/raw-loss = 0.6942781209945679, train/logprobs = tensor([[-0.6779, -1.3967],
        [-0.6694, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6925406455993652, train/raw-loss = 0.6925406455993652, train/logprobs = tensor([[-0.7632, -1.1195],
        [-0.7654, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6746158599853516, train/raw-loss = 0.6746158599853516, train/logprobs = tensor([[-0.8216, -1.7078],
        [-0.8400, -1.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6901819705963135, train/raw-loss = 0.6901819705963135, train/logprobs = tensor([[-0.6560, -1.7110],
        [-0.6654, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6854792237281799, train/raw-loss = 0.6854792237281799, train/logprobs = tensor([[-1.0934, -2.2801],
        [-1.0771, -2.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6898898482322693, train/raw-loss = 0.6898898482322693, train/logprobs = tensor([[-0.9415, -1.1740],
        [-0.9243, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6867601871490479, train/raw-loss = 0.6867601871490479, train/logprobs = tensor([[-0.8766, -1.8393],
        [-0.8959, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.7021998167037964, train/raw-loss = 0.7021998167037964, train/logprobs = tensor([[-1.1262, -2.6505],
        [-1.1680, -2.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6904126405715942, train/raw-loss = 0.6904126405715942, train/logprobs = tensor([[-0.7199, -1.4910],
        [-0.7111, -1.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.7020456194877625, train/raw-loss = 0.7020456194877625, train/logprobs = tensor([[-1.3350, -1.4101],
        [-1.3527, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6854633092880249, train/raw-loss = 0.6854633092880249, train/logprobs = tensor([[-0.8395, -1.8763],
        [-0.8370, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6902749538421631, train/raw-loss = 0.6902749538421631, train/logprobs = tensor([[-1.0832, -1.3937],
        [-1.0782, -1.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6818158626556396, train/raw-loss = 0.6818158626556396, train/logprobs = tensor([[-0.9913, -1.7751],
        [-0.9906, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6867509484291077, train/raw-loss = 0.6867509484291077, train/logprobs = tensor([[-0.7081, -0.7210],
        [-0.7282, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.6943259239196777, train/raw-loss = 0.6943259239196777, train/logprobs = tensor([[-0.6088, -1.0795],
        [-0.5906, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6778056025505066, train/raw-loss = 0.6778056025505066, train/logprobs = tensor([[-1.2230, -1.6885],
        [-1.2433, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6834846138954163, train/raw-loss = 0.6834846138954163, train/logprobs = tensor([[-1.3000, -1.1052],
        [-1.3418, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6800635457038879, train/raw-loss = 0.6800635457038879, train/logprobs = tensor([[-0.8773, -1.4545],
        [-0.8995, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.6742421388626099, train/raw-loss = 0.6742421388626099, train/logprobs = tensor([[-0.6412, -1.4265],
        [-0.6492, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6725760698318481, train/raw-loss = 0.6725760698318481, train/logprobs = tensor([[-0.6794, -1.6542],
        [-0.6772, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6888110637664795, train/raw-loss = 0.6888110637664795, train/logprobs = tensor([[-0.8279, -1.2489],
        [-0.8414, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6890683174133301, train/raw-loss = 0.6890683174133301, train/logprobs = tensor([[-1.1025, -1.5208],
        [-1.0788, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6739259958267212, train/raw-loss = 0.6739259958267212, train/logprobs = tensor([[-0.5136, -1.4002],
        [-0.5257, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.6909834146499634, train/raw-loss = 0.6909834146499634, train/logprobs = tensor([[-1.1946, -1.5974],
        [-1.1819, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.694449782371521, train/raw-loss = 0.694449782371521, train/logprobs = tensor([[-0.9767, -1.3460],
        [-0.9932, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6898001432418823, train/raw-loss = 0.6877637505531311, train/logprobs = tensor([[-0.9220, -1.6336],
        [-0.9145, -1.6041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020363908261060715
Epoch 0, Step 65: train/loss = 0.6948573589324951, train/raw-loss = 0.6923530101776123, train/logprobs = tensor([[-0.8625, -1.5538],
        [-0.8517, -1.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025043580681085587
Epoch 0, Step 66: train/loss = 0.6965373158454895, train/raw-loss = 0.6944303512573242, train/logprobs = tensor([[-1.0396, -1.9480],
        [-0.9878, -1.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021069622598588467
Epoch 0, Step 67: train/loss = 0.6859432458877563, train/raw-loss = 0.6839788556098938, train/logprobs = tensor([[-0.6798, -1.8389],
        [-0.6678, -1.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019643553532660007
Epoch 0, Step 68: train/loss = 0.6840764284133911, train/raw-loss = 0.6821656227111816, train/logprobs = tensor([[-0.7845, -2.8252],
        [-0.7692, -2.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019108215346932411
Epoch 0, Step 69: train/loss = 0.6859887838363647, train/raw-loss = 0.6837180852890015, train/logprobs = tensor([[-1.2483, -1.6969],
        [-1.2600, -1.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002270756522193551
Epoch 0, Step 70: train/loss = 0.6908050179481506, train/raw-loss = 0.6889336109161377, train/logprobs = tensor([[-0.5953, -1.9221],
        [-0.5894, -1.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018714186735451221
Epoch 0, Step 71: train/loss = 0.6790534257888794, train/raw-loss = 0.6770509481430054, train/logprobs = tensor([[-1.0356, -1.9399],
        [-1.0232, -1.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020024864934384823
Epoch 0, Step 72: train/loss = 0.680861234664917, train/raw-loss = 0.6791530847549438, train/logprobs = tensor([[-0.4522, -1.9839],
        [-0.4526, -1.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001708242460153997
Epoch 0, Step 73: train/loss = 0.6940241456031799, train/raw-loss = 0.6920452117919922, train/logprobs = tensor([[-0.7305, -1.1149],
        [-0.7595, -1.1381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001978855114430189
Epoch 0, Step 74: train/loss = 0.6977052688598633, train/raw-loss = 0.6955074667930603, train/logprobs = tensor([[-1.5873, -1.9914],
        [-1.5650, -1.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002197797177359462
Epoch 0, Step 75: train/loss = 0.6905127763748169, train/raw-loss = 0.688805878162384, train/logprobs = tensor([[-0.7740, -1.8747],
        [-0.7680, -1.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017068575834855437
Epoch 0, Step 76: train/loss = 0.6684452295303345, train/raw-loss = 0.6663271188735962, train/logprobs = tensor([[-0.9598, -1.5865],
        [-1.0352, -1.5512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002118127653375268
Epoch 0, Step 77: train/loss = 0.6917291283607483, train/raw-loss = 0.6893227100372314, train/logprobs = tensor([[-1.2644, -1.4889],
        [-1.2759, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002406408078968525
Epoch 0, Step 78: train/loss = 0.6846194267272949, train/raw-loss = 0.6824576258659363, train/logprobs = tensor([[-0.8699, -1.9038],
        [-0.8756, -1.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021618185564875603
Epoch 0, Step 79: train/loss = 0.6836580038070679, train/raw-loss = 0.682075023651123, train/logprobs = tensor([[-0.5416, -1.2651],
        [-0.5458, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015828933101147413
Epoch 0, Step 80: train/loss = 0.6880056262016296, train/raw-loss = 0.6855354905128479, train/logprobs = tensor([[-1.0665, -2.1289],
        [-1.0666, -2.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00247008609585464
Epoch 0, Step 81: train/loss = 0.7055337429046631, train/raw-loss = 0.7035548686981201, train/logprobs = tensor([[-0.8068, -1.9072],
        [-0.8180, -1.9546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001978898886591196
Epoch 0, Step 82: train/loss = 0.6927429437637329, train/raw-loss = 0.6905887126922607, train/logprobs = tensor([[-1.2206, -1.0576],
        [-1.2211, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021542643662542105
Epoch 0, Step 83: train/loss = 0.6831355690956116, train/raw-loss = 0.6809836030006409, train/logprobs = tensor([[-0.6330, -1.7098],
        [-0.6366, -1.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002151928376406431
Epoch 0, Step 84: train/loss = 0.6877305507659912, train/raw-loss = 0.6861375570297241, train/logprobs = tensor([[-0.5632, -2.0428],
        [-0.5603, -2.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001592982211150229
Epoch 0, Step 85: train/loss = 0.6906224489212036, train/raw-loss = 0.6883398294448853, train/logprobs = tensor([[-0.9117, -2.1942],
        [-0.9212, -2.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002282662084326148
Epoch 0, Step 86: train/loss = 0.6851530075073242, train/raw-loss = 0.6830369234085083, train/logprobs = tensor([[-0.6502, -1.8370],
        [-0.6557, -1.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021160119213163853
Epoch 0, Step 87: train/loss = 0.7016431093215942, train/raw-loss = 0.6995263695716858, train/logprobs = tensor([[-1.3735, -1.5969],
        [-1.3679, -1.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021167099475860596
Epoch 0, Step 88: train/loss = 0.6871035695075989, train/raw-loss = 0.685016930103302, train/logprobs = tensor([[-0.7981, -2.0506],
        [-0.8001, -2.0191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020866054110229015
Epoch 0, Step 89: train/loss = 0.6813750267028809, train/raw-loss = 0.6790724992752075, train/logprobs = tensor([[-1.0942, -1.9186],
        [-1.0838, -1.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002302552340552211
Epoch 0, Step 90: train/loss = 0.6898527145385742, train/raw-loss = 0.6876555681228638, train/logprobs = tensor([[-0.8410, -1.8010],
        [-0.8818, -1.8184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002197110094130039
Epoch 0, Step 91: train/loss = 0.689079761505127, train/raw-loss = 0.6862545013427734, train/logprobs = tensor([[-1.2767, -1.1531],
        [-1.2969, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028252187184989452
Epoch 0, Step 92: train/loss = 0.6783881783485413, train/raw-loss = 0.6763318777084351, train/logprobs = tensor([[-0.8990, -1.7019],
        [-0.9648, -1.6971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002056389581412077
Epoch 0, Step 93: train/loss = 0.6937385201454163, train/raw-loss = 0.6916121244430542, train/logprobs = tensor([[-0.9814, -1.4910],
        [-0.9891, -1.4925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021263770759105682
Epoch 0, Step 94: train/loss = 0.6774263381958008, train/raw-loss = 0.6753180027008057, train/logprobs = tensor([[-1.2584, -2.7427],
        [-1.3019, -2.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021083471365273
Epoch 0, Step 95: train/loss = 0.6799471378326416, train/raw-loss = 0.6777064204216003, train/logprobs = tensor([[-1.5434, -2.2713],
        [-1.5606, -2.2256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022407500073313713
Epoch 0, Step 96: train/loss = 0.694326639175415, train/raw-loss = 0.6861827373504639, train/logprobs = tensor([[-0.8476, -1.7012],
        [-0.8472, -1.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008143855258822441
Epoch 0, Step 97: train/loss = 0.7054811120033264, train/raw-loss = 0.6961213946342468, train/logprobs = tensor([[-1.7893, -2.7870],
        [-1.7770, -2.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009359722957015038
Epoch 0, Step 98: train/loss = 0.6931716799736023, train/raw-loss = 0.6833296418190002, train/logprobs = tensor([[-1.0266, -1.5955],
        [-1.0410, -1.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00984209030866623
Epoch 0, Step 99: train/loss = 0.6981463432312012, train/raw-loss = 0.6890066862106323, train/logprobs = tensor([[-0.8313, -1.5483],
        [-0.8239, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009139716625213623
Epoch 0, Step 100: train/loss = 0.6932528018951416, train/raw-loss = 0.684370756149292, train/logprobs = tensor([[-0.9955, -1.3677],
        [-0.9851, -1.3219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008882040157914162
Epoch 0, Step 101: train/loss = 0.6846370697021484, train/raw-loss = 0.6752769947052002, train/logprobs = tensor([[-1.1313, -2.3534],
        [-1.1382, -2.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009360112249851227
Epoch 0, Step 102: train/loss = 0.6770052909851074, train/raw-loss = 0.667507529258728, train/logprobs = tensor([[-0.7676, -1.7674],
        [-0.7484, -1.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009497779421508312
Epoch 0, Step 103: train/loss = 0.6848500370979309, train/raw-loss = 0.6754802465438843, train/logprobs = tensor([[-0.8719, -1.7859],
        [-0.8990, -1.7415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009369755163788795
Epoch 0, Step 104: train/loss = 0.6899187564849854, train/raw-loss = 0.6813234090805054, train/logprobs = tensor([[-0.8400, -1.5370],
        [-0.8374, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008595344610512257
Epoch 0, Step 105: train/loss = 0.6922479867935181, train/raw-loss = 0.6830407381057739, train/logprobs = tensor([[-0.9846, -1.7621],
        [-0.9820, -1.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009207155555486679
Epoch 0, Step 106: train/loss = 0.688224196434021, train/raw-loss = 0.6797043085098267, train/logprobs = tensor([[-0.7310, -1.8056],
        [-0.7031, -1.7225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008519895374774933
Epoch 0, Step 107: train/loss = 0.6940000057220459, train/raw-loss = 0.684602677822113, train/logprobs = tensor([[-1.2521, -1.6362],
        [-1.2712, -1.6208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009397310204803944
Epoch 0, Step 108: train/loss = 0.6950007081031799, train/raw-loss = 0.6869490742683411, train/logprobs = tensor([[-0.7371, -0.8503],
        [-0.7320, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008051605895161629
Epoch 0, Step 109: train/loss = 0.6899571418762207, train/raw-loss = 0.6804586052894592, train/logprobs = tensor([[-0.8129, -1.7901],
        [-0.8113, -1.7370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00949848908931017
Epoch 0, Step 110: train/loss = 0.6747764945030212, train/raw-loss = 0.6646914482116699, train/logprobs = tensor([[-0.9511, -2.1669],
        [-0.9115, -2.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010085049085319042
Epoch 0, Step 111: train/loss = 0.7056999206542969, train/raw-loss = 0.6968344449996948, train/logprobs = tensor([[-0.8777, -1.7717],
        [-0.8742, -1.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00886542908847332
Epoch 0, Step 112: train/loss = 0.7052139639854431, train/raw-loss = 0.6951898336410522, train/logprobs = tensor([[-1.4026, -1.3648],
        [-1.4195, -1.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010024129413068295
Epoch 0, Step 113: train/loss = 0.6942440271377563, train/raw-loss = 0.6848182678222656, train/logprobs = tensor([[-1.0096, -1.4120],
        [-0.9927, -1.3612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00942576676607132
Epoch 0, Step 114: train/loss = 0.694850742816925, train/raw-loss = 0.6864335536956787, train/logprobs = tensor([[-0.9052, -1.1434],
        [-0.9154, -1.1264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008417211472988129
Epoch 0, Step 115: train/loss = 0.6697095036506653, train/raw-loss = 0.6613147258758545, train/logprobs = tensor([[-0.7401, -1.7694],
        [-0.7169, -1.6102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008394768461585045
Epoch 0, Step 116: train/loss = 0.6956037282943726, train/raw-loss = 0.687138557434082, train/logprobs = tensor([[-0.6275, -1.4198],
        [-0.6277, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00846515130251646
Epoch 0, Step 117: train/loss = 0.6852667331695557, train/raw-loss = 0.6759687662124634, train/logprobs = tensor([[-0.9130, -1.7475],
        [-0.9232, -1.6871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009297952987253666
Epoch 0, Step 118: train/loss = 0.6887378096580505, train/raw-loss = 0.6791809797286987, train/logprobs = tensor([[-0.9707, -1.9361],
        [-1.0102, -1.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009556785225868225
Epoch 0, Step 119: train/loss = 0.7013488411903381, train/raw-loss = 0.6916720271110535, train/logprobs = tensor([[-1.3317, -1.6861],
        [-1.3651, -1.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00967684481292963
Epoch 0, Step 120: train/loss = 0.7097364068031311, train/raw-loss = 0.6993070840835571, train/logprobs = tensor([[-1.0885, -2.1987],
        [-1.0746, -2.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010429342277348042
Epoch 0, Step 121: train/loss = 0.693834125995636, train/raw-loss = 0.683808445930481, train/logprobs = tensor([[-0.7299, -1.1807],
        [-0.7435, -1.1566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01002565212547779
Epoch 0, Step 122: train/loss = 0.6979735493659973, train/raw-loss = 0.689508318901062, train/logprobs = tensor([[-1.0077, -2.8114],
        [-0.9880, -2.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00846521370112896
Epoch 0, Step 123: train/loss = 0.6874452829360962, train/raw-loss = 0.6791146993637085, train/logprobs = tensor([[-1.1344, -1.3820],
        [-1.1393, -1.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008330530487000942
Epoch 0, Step 124: train/loss = 0.693279504776001, train/raw-loss = 0.684849202632904, train/logprobs = tensor([[-0.6339, -1.4075],
        [-0.5803, -1.3182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0084303580224514
Epoch 0, Step 125: train/loss = 0.6775881052017212, train/raw-loss = 0.6680681705474854, train/logprobs = tensor([[-0.8453, -2.3323],
        [-0.8899, -2.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009519942104816437
Epoch 0, Step 126: train/loss = 0.695590615272522, train/raw-loss = 0.6868242025375366, train/logprobs = tensor([[-1.1766, -2.9089],
        [-1.2269, -2.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008766468614339828
Epoch 0, Step 127: train/loss = 0.6910997033119202, train/raw-loss = 0.6821826100349426, train/logprobs = tensor([[-0.9360, -1.8495],
        [-0.8852, -1.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008917044848203659
Epoch 0, Step 128: train/loss = 0.7446209192276001, train/raw-loss = 0.70462566614151, train/logprobs = tensor([[-0.9911, -1.5048],
        [-0.9723, -1.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039995282888412476
Epoch 0, Step 129: train/loss = 0.7319968938827515, train/raw-loss = 0.6959701180458069, train/logprobs = tensor([[-1.1524, -1.9946],
        [-1.1504, -2.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036026738584041595
Epoch 0, Step 130: train/loss = 0.7360409498214722, train/raw-loss = 0.6769605875015259, train/logprobs = tensor([[-1.1912, -2.5892],
        [-1.1212, -2.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05908026918768883
Epoch 0, Step 131: train/loss = 0.7018603682518005, train/raw-loss = 0.6805708408355713, train/logprobs = tensor([[-1.5570, -1.4807],
        [-1.5663, -1.4388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021289536729454994
Epoch 0, Step 132: train/loss = 0.7388575077056885, train/raw-loss = 0.676101565361023, train/logprobs = tensor([[-0.9322, -2.0296],
        [-1.0234, -2.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06275595724582672
Epoch 0, Step 133: train/loss = 0.7319006323814392, train/raw-loss = 0.6782556176185608, train/logprobs = tensor([[-1.3665, -1.7458],
        [-1.3774, -1.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0536450631916523
Epoch 0, Step 134: train/loss = 0.7236822843551636, train/raw-loss = 0.6728293895721436, train/logprobs = tensor([[-1.0078, -1.7094],
        [-1.0163, -1.6348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05085287615656853
Epoch 0, Step 135: train/loss = 0.7106955051422119, train/raw-loss = 0.6808220148086548, train/logprobs = tensor([[-1.2729, -1.4403],
        [-1.2654, -1.3801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029873380437493324
Epoch 0, Step 136: train/loss = 0.7106228470802307, train/raw-loss = 0.6650762557983398, train/logprobs = tensor([[-1.3878, -2.1178],
        [-1.4119, -2.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045546576380729675
Epoch 0, Step 137: train/loss = 0.7061420679092407, train/raw-loss = 0.6768473386764526, train/logprobs = tensor([[-1.4303, -1.4762],
        [-1.4336, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029294677078723907
Epoch 0, Step 138: train/loss = 0.7243450880050659, train/raw-loss = 0.6847520470619202, train/logprobs = tensor([[-1.0860, -1.8471],
        [-1.0363, -1.7620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039593085646629333
Epoch 0, Step 139: train/loss = 0.7325953245162964, train/raw-loss = 0.6768220663070679, train/logprobs = tensor([[-1.0175, -2.4724],
        [-1.0551, -2.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055773280560970306
Epoch 0, Step 140: train/loss = 0.7234330773353577, train/raw-loss = 0.6704738140106201, train/logprobs = tensor([[-0.9457, -2.1788],
        [-0.9944, -2.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05295921117067337
Epoch 0, Step 141: train/loss = 0.7312292456626892, train/raw-loss = 0.6803250312805176, train/logprobs = tensor([[-0.8255, -2.0463],
        [-0.8092, -1.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050904277712106705
Epoch 0, Step 142: train/loss = 0.6994349956512451, train/raw-loss = 0.6614421010017395, train/logprobs = tensor([[-1.2870, -1.9444],
        [-1.3021, -1.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03799290210008621
Epoch 0, Step 143: train/loss = 0.7089331746101379, train/raw-loss = 0.6757862567901611, train/logprobs = tensor([[-1.4088, -1.7695],
        [-1.4065, -1.6951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03314691409468651
Epoch 0, Step 144: train/loss = 0.7013802528381348, train/raw-loss = 0.6638317704200745, train/logprobs = tensor([[-0.8377, -1.7518],
        [-0.8192, -1.6117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037548504769802094
Epoch 0, Step 145: train/loss = 0.7070275545120239, train/raw-loss = 0.6869294047355652, train/logprobs = tensor([[-1.1512, -1.5524],
        [-1.1192, -1.4934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020098162814974785
Epoch 0, Step 146: train/loss = 0.7160467505455017, train/raw-loss = 0.6699010729789734, train/logprobs = tensor([[-0.7827, -1.8447],
        [-0.7909, -1.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04614568501710892
Epoch 0, Step 147: train/loss = 0.7102677822113037, train/raw-loss = 0.6748917102813721, train/logprobs = tensor([[-1.1879, -1.7315],
        [-1.1716, -1.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03537599369883537
Epoch 0, Step 148: train/loss = 0.7210311889648438, train/raw-loss = 0.6827400922775269, train/logprobs = tensor([[-0.8840, -1.4161],
        [-0.8848, -1.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03829114884138107
Epoch 0, Step 149: train/loss = 0.7046912908554077, train/raw-loss = 0.6758036613464355, train/logprobs = tensor([[-0.8856, -1.6557],
        [-0.8873, -1.5864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028887715190649033
Epoch 0, Step 150: train/loss = 0.7114399671554565, train/raw-loss = 0.6840296983718872, train/logprobs = tensor([[-1.0092, -1.7675],
        [-0.9835, -1.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027410339564085007
Epoch 0, Step 151: train/loss = 0.7322068810462952, train/raw-loss = 0.690986156463623, train/logprobs = tensor([[-0.8636, -1.4770],
        [-0.8569, -1.4610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04122070223093033
Epoch 0, Step 152: train/loss = 0.7275115251541138, train/raw-loss = 0.6766791939735413, train/logprobs = tensor([[-0.9146, -1.9346],
        [-0.8910, -1.8420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05083237215876579
Epoch 0, Step 153: train/loss = 0.7399500608444214, train/raw-loss = 0.698106050491333, train/logprobs = tensor([[-1.0192, -1.8140],
        [-0.9845, -1.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04184400290250778
Epoch 0, Step 154: train/loss = 0.7226845622062683, train/raw-loss = 0.6815323233604431, train/logprobs = tensor([[-1.2228, -2.0359],
        [-1.2200, -1.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041152313351631165
Epoch 0, Step 155: train/loss = 0.7299394011497498, train/raw-loss = 0.6849215030670166, train/logprobs = tensor([[-0.8774, -1.6696],
        [-0.8449, -1.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04501783847808838
Epoch 0, Step 156: train/loss = 0.7340161800384521, train/raw-loss = 0.6753274202346802, train/logprobs = tensor([[-1.0389, -2.2332],
        [-1.0299, -2.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05868878215551376
Epoch 0, Step 157: train/loss = 0.729466438293457, train/raw-loss = 0.6900836229324341, train/logprobs = tensor([[-0.9399, -1.3289],
        [-0.9075, -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039382874965667725
Epoch 0, Step 158: train/loss = 0.7141971588134766, train/raw-loss = 0.6716437935829163, train/logprobs = tensor([[-0.8125, -0.8048],
        [-0.8300, -0.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0425533801317215
Epoch 0, Step 159: train/loss = 0.7140712738037109, train/raw-loss = 0.6771230697631836, train/logprobs = tensor([[-0.7621, -1.3526],
        [-0.7616, -1.2859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03694821894168854
Epoch 0, Step 160: train/loss = 0.7389339208602905, train/raw-loss = 0.6870094537734985, train/logprobs = tensor([[-0.8321, -1.3341],
        [-0.7846, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05192448943853378
Epoch 0, Step 161: train/loss = 0.7308444976806641, train/raw-loss = 0.6712675094604492, train/logprobs = tensor([[-0.8332, -1.9215],
        [-0.8613, -1.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05957699567079544
Epoch 0, Step 162: train/loss = 0.6994698643684387, train/raw-loss = 0.6423127055168152, train/logprobs = tensor([[-0.6957, -2.2515],
        [-0.6768, -2.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05715719237923622
Epoch 0, Step 163: train/loss = 0.7191282510757446, train/raw-loss = 0.6711640954017639, train/logprobs = tensor([[-1.0871, -1.6885],
        [-1.0540, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04796413704752922
Epoch 0, Step 164: train/loss = 0.6978152990341187, train/raw-loss = 0.6591819524765015, train/logprobs = tensor([[-1.3940, -1.6794],
        [-1.4116, -1.5560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03863333910703659
Epoch 0, Step 165: train/loss = 0.7199817895889282, train/raw-loss = 0.6730444431304932, train/logprobs = tensor([[-0.9791, -2.0228],
        [-0.9484, -1.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046937353909015656
Epoch 0, Step 166: train/loss = 0.7470576167106628, train/raw-loss = 0.6842767596244812, train/logprobs = tensor([[-0.8923, -2.0707],
        [-0.9032, -2.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06278081983327866
Epoch 0, Step 167: train/loss = 0.711677074432373, train/raw-loss = 0.6603460311889648, train/logprobs = tensor([[-1.1471, -1.2798],
        [-1.1726, -1.1700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05133110657334328
Epoch 0, Step 168: train/loss = 0.7055506110191345, train/raw-loss = 0.6726831793785095, train/logprobs = tensor([[-0.8193, -1.3611],
        [-0.8166, -1.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032867416739463806
Epoch 0, Step 169: train/loss = 0.7423148155212402, train/raw-loss = 0.6850864291191101, train/logprobs = tensor([[-0.8191, -1.4386],
        [-0.8355, -1.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05722838640213013
Epoch 0, Step 170: train/loss = 0.7392308712005615, train/raw-loss = 0.6750359535217285, train/logprobs = tensor([[-0.6133, -2.0435],
        [-0.6110, -1.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06419495493173599
Epoch 0, Step 171: train/loss = 0.7171502113342285, train/raw-loss = 0.6770743131637573, train/logprobs = tensor([[-1.1727, -1.4982],
        [-1.1725, -1.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040075886994600296
Epoch 0, Step 172: train/loss = 0.7278647422790527, train/raw-loss = 0.6675616502761841, train/logprobs = tensor([[-0.9492, -1.7702],
        [-0.9386, -1.6539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060303062200546265
Epoch 0, Step 173: train/loss = 0.7112534642219543, train/raw-loss = 0.6549994945526123, train/logprobs = tensor([[-0.9751, -2.5407],
        [-1.0100, -2.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056253962218761444
Epoch 0, Step 174: train/loss = 0.7018659710884094, train/raw-loss = 0.6596523523330688, train/logprobs = tensor([[-1.0534, -2.8428],
        [-1.0029, -2.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04221368208527565
Epoch 0, Step 175: train/loss = 0.7201358079910278, train/raw-loss = 0.6830534338951111, train/logprobs = tensor([[-1.4700, -1.6020],
        [-1.4221, -1.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03708226978778839
Epoch 0, Step 176: train/loss = 0.7253212928771973, train/raw-loss = 0.6717300415039062, train/logprobs = tensor([[-0.6888, -1.9532],
        [-0.7088, -1.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05359138548374176
Epoch 0, Step 177: train/loss = 0.7276686429977417, train/raw-loss = 0.6669389009475708, train/logprobs = tensor([[-0.8515, -1.4117],
        [-0.8427, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0607297345995903
Epoch 0, Step 178: train/loss = 0.7339234948158264, train/raw-loss = 0.6756352186203003, train/logprobs = tensor([[-0.7348, -1.8365],
        [-0.7158, -1.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05828827619552612
Epoch 0, Step 179: train/loss = 0.7149115800857544, train/raw-loss = 0.6698205471038818, train/logprobs = tensor([[-1.1763, -1.9308],
        [-1.1560, -1.8138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045090943574905396
Epoch 0, Step 180: train/loss = 0.7202605605125427, train/raw-loss = 0.670944094657898, train/logprobs = tensor([[-1.0342, -1.4135],
        [-1.0321, -1.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04931647330522537
Epoch 0, Step 181: train/loss = 0.7348176836967468, train/raw-loss = 0.6885771155357361, train/logprobs = tensor([[-0.8842, -1.5338],
        [-0.8877, -1.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04624057561159134
Epoch 0, Step 182: train/loss = 0.709517776966095, train/raw-loss = 0.6720645427703857, train/logprobs = tensor([[-0.9630, -1.3515],
        [-0.9755, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037453193217515945
Epoch 0, Step 183: train/loss = 0.7125184535980225, train/raw-loss = 0.6595746278762817, train/logprobs = tensor([[-0.7508, -1.8882],
        [-0.7435, -1.7410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052943840622901917
Epoch 0, Step 184: train/loss = 0.7136043310165405, train/raw-loss = 0.6595873832702637, train/logprobs = tensor([[-0.8692, -1.9169],
        [-0.8847, -1.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054016999900341034
Epoch 0, Step 185: train/loss = 0.7040566802024841, train/raw-loss = 0.6608266234397888, train/logprobs = tensor([[-0.7789, -1.8343],
        [-0.7762, -1.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04323010891675949
Epoch 0, Step 186: train/loss = 0.7272516489028931, train/raw-loss = 0.6750871539115906, train/logprobs = tensor([[-0.8087, -1.7690],
        [-0.7941, -1.6788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05216454714536667
Epoch 0, Step 187: train/loss = 0.7249019145965576, train/raw-loss = 0.6928431391716003, train/logprobs = tensor([[-0.9126, -1.5907],
        [-0.8828, -1.5585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03205881640315056
Epoch 0, Step 188: train/loss = 0.7224892377853394, train/raw-loss = 0.6832382678985596, train/logprobs = tensor([[-1.1163, -1.9106],
        [-1.0711, -1.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925099968910217
Epoch 0, Step 189: train/loss = 0.7382408976554871, train/raw-loss = 0.6945377588272095, train/logprobs = tensor([[-0.9635, -1.6684],
        [-0.9473, -1.6568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0437031053006649
Epoch 0, Step 190: train/loss = 0.7088369727134705, train/raw-loss = 0.6649878025054932, train/logprobs = tensor([[-1.3163, -1.4884],
        [-1.3787, -1.4352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043849095702171326
Epoch 0, Step 191: train/loss = 0.7096045613288879, train/raw-loss = 0.6706541180610657, train/logprobs = tensor([[-0.8705, -1.5962],
        [-0.8535, -1.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038950443267822266
Epoch 0, Step 192: train/loss = 0.6949819326400757, train/raw-loss = 0.6477620005607605, train/logprobs = tensor([[-1.0289, -1.4268],
        [-1.0584, -1.2677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04721997305750847
Epoch 0, Step 193: train/loss = 0.725162148475647, train/raw-loss = 0.68571937084198, train/logprobs = tensor([[-0.6721, -1.1809],
        [-0.6801, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03944289684295654
Epoch 0, Step 194: train/loss = 0.7215195298194885, train/raw-loss = 0.6724838614463806, train/logprobs = tensor([[-0.8992, -1.1487],
        [-0.9238, -1.0888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0490356869995594
Epoch 0, Step 195: train/loss = 0.7172104120254517, train/raw-loss = 0.6666157245635986, train/logprobs = tensor([[-0.5667, -1.2878],
        [-0.5679, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0505947582423687
Epoch 0, Step 196: train/loss = 0.7144197821617126, train/raw-loss = 0.6631028652191162, train/logprobs = tensor([[-1.2347, -2.0022],
        [-1.1451, -1.7793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051316969096660614
Epoch 0, Step 197: train/loss = 0.7202458381652832, train/raw-loss = 0.6678990125656128, train/logprobs = tensor([[-0.8251, -1.3376],
        [-0.7923, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052346888929605484
Epoch 0, Step 198: train/loss = 0.7164126038551331, train/raw-loss = 0.6597972512245178, train/logprobs = tensor([[-0.7287, -0.8990],
        [-0.7629, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05661531537771225
Epoch 0, Step 199: train/loss = 0.7030742764472961, train/raw-loss = 0.6623278260231018, train/logprobs = tensor([[-0.7873, -1.0064],
        [-0.8432, -0.9321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04074649512767792
Epoch 0, Step 200: train/loss = 0.6861832737922668, train/raw-loss = 0.6362113952636719, train/logprobs = tensor([[-1.0274, -2.2587],
        [-1.0278, -2.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04997185245156288
Epoch 0, Step 201: train/loss = 0.7202667593955994, train/raw-loss = 0.6656931042671204, train/logprobs = tensor([[-0.6365, -1.6716],
        [-0.6299, -1.5481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054573602974414825
Epoch 0, Step 202: train/loss = 0.7091794013977051, train/raw-loss = 0.6464014053344727, train/logprobs = tensor([[-0.6293, -1.9802],
        [-0.6403, -1.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06277796626091003
Epoch 0, Step 203: train/loss = 0.677749752998352, train/raw-loss = 0.6185436248779297, train/logprobs = tensor([[-0.8536, -1.1460],
        [-0.9794, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059206150472164154
Epoch 0, Step 204: train/loss = 0.7070318460464478, train/raw-loss = 0.653838038444519, train/logprobs = tensor([[-1.2938, -1.2963],
        [-1.3019, -1.1419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053193751722574234
Epoch 0, Step 205: train/loss = 0.7086315751075745, train/raw-loss = 0.6390654444694519, train/logprobs = tensor([[-0.6128, -1.4056],
        [-0.5910, -1.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06956613808870316
Epoch 0, Step 206: train/loss = 0.7042424082756042, train/raw-loss = 0.6497513055801392, train/logprobs = tensor([[-0.8173, -1.3774],
        [-0.8148, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05449111759662628
Epoch 0, Step 207: train/loss = 0.693693995475769, train/raw-loss = 0.6441388130187988, train/logprobs = tensor([[-0.7440, -2.0300],
        [-0.7682, -1.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04955518618226051
Epoch 0, Step 208: train/loss = 0.7093378305435181, train/raw-loss = 0.6468756794929504, train/logprobs = tensor([[-1.0580, -2.0406],
        [-1.1157, -1.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062462154775857925
Epoch 0, Step 209: train/loss = 0.7265909910202026, train/raw-loss = 0.6705853343009949, train/logprobs = tensor([[-0.8237, -1.7666],
        [-0.8080, -1.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05600564181804657
Epoch 0, Step 210: train/loss = 0.696973979473114, train/raw-loss = 0.6311057806015015, train/logprobs = tensor([[-1.3076, -1.4660],
        [-1.4080, -1.3065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06586816161870956
Epoch 0, Step 211: train/loss = 0.7053422331809998, train/raw-loss = 0.6539264917373657, train/logprobs = tensor([[-0.9759, -2.0757],
        [-0.9839, -1.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051415733993053436
Epoch 0, Step 212: train/loss = 0.7331844568252563, train/raw-loss = 0.6877350807189941, train/logprobs = tensor([[-0.7391, -1.1705],
        [-0.6797, -1.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045449402183294296
Epoch 0, Step 213: train/loss = 0.7013850808143616, train/raw-loss = 0.637751579284668, train/logprobs = tensor([[-1.2204, -1.9887],
        [-1.2269, -1.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06363346427679062
Epoch 0, Step 214: train/loss = 0.7269236445426941, train/raw-loss = 0.675101101398468, train/logprobs = tensor([[-0.8307, -1.1507],
        [-0.8362, -1.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05182255059480667
Epoch 0, Step 215: train/loss = 0.69081711769104, train/raw-loss = 0.6419801115989685, train/logprobs = tensor([[-1.0117, -1.4503],
        [-1.0381, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048837095499038696
Epoch 0, Step 216: train/loss = 0.7147090435028076, train/raw-loss = 0.6791449785232544, train/logprobs = tensor([[-1.3051, -1.3860],
        [-1.2883, -1.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03556404635310173
Epoch 0, Step 217: train/loss = 0.7147116661071777, train/raw-loss = 0.6595580577850342, train/logprobs = tensor([[-0.7191, -1.4672],
        [-0.7492, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05515361577272415
Epoch 0, Step 218: train/loss = 0.7158224582672119, train/raw-loss = 0.6511911153793335, train/logprobs = tensor([[-0.7145, -2.0161],
        [-0.7261, -1.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0646313726902008
Epoch 0, Step 219: train/loss = 0.7193694710731506, train/raw-loss = 0.6918824911117554, train/logprobs = tensor([[-0.8363, -0.9263],
        [-0.8060, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02748698554933071
Epoch 0, Step 220: train/loss = 0.7132027745246887, train/raw-loss = 0.6490367650985718, train/logprobs = tensor([[-0.9994, -2.9424],
        [-1.0118, -2.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06416603922843933
Epoch 0, Step 221: train/loss = 0.7246079444885254, train/raw-loss = 0.6731278896331787, train/logprobs = tensor([[-1.2912, -0.8283],
        [-1.2315, -0.6815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05148002505302429
Epoch 0, Step 222: train/loss = 0.7447360754013062, train/raw-loss = 0.6914344429969788, train/logprobs = tensor([[-0.8780, -1.2326],
        [-0.8339, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053301602602005005
Epoch 0, Step 223: train/loss = 0.697521448135376, train/raw-loss = 0.6372935771942139, train/logprobs = tensor([[-0.7821, -2.0844],
        [-0.8127, -1.8762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06022796034812927
Epoch 0, Step 224: train/loss = 0.6975787878036499, train/raw-loss = 0.6541446447372437, train/logprobs = tensor([[-1.2300, -2.5379],
        [-1.1673, -2.3036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04343415051698685
Epoch 0, Step 225: train/loss = 0.7064204216003418, train/raw-loss = 0.6388780474662781, train/logprobs = tensor([[-0.7336, -1.7981],
        [-0.6611, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0675424188375473
Epoch 0, Step 226: train/loss = 0.7046468257904053, train/raw-loss = 0.6406123638153076, train/logprobs = tensor([[-0.9627, -2.4608],
        [-0.9754, -2.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06403450667858124
Epoch 0, Step 227: train/loss = 0.6957430839538574, train/raw-loss = 0.6549383401870728, train/logprobs = tensor([[-0.7199, -1.3491],
        [-0.7191, -1.1880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04080476239323616
Epoch 0, Step 228: train/loss = 0.6899340152740479, train/raw-loss = 0.644878089427948, train/logprobs = tensor([[-1.0741, -2.4966],
        [-1.0618, -2.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04505595564842224
Epoch 0, Step 229: train/loss = 0.6818912029266357, train/raw-loss = 0.6239550113677979, train/logprobs = tensor([[-0.7914, -1.8630],
        [-0.8070, -1.5771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057936180382966995
Epoch 0, Step 230: train/loss = 0.7036479711532593, train/raw-loss = 0.6452631950378418, train/logprobs = tensor([[-0.9891, -2.2873],
        [-0.9551, -2.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05838475748896599
Epoch 0, Step 231: train/loss = 0.6966850161552429, train/raw-loss = 0.6512113213539124, train/logprobs = tensor([[-1.1085, -1.2384],
        [-1.1228, -1.0769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04547370225191116
Epoch 0, Step 232: train/loss = 0.7105662822723389, train/raw-loss = 0.6595653295516968, train/logprobs = tensor([[-1.0773, -2.2315],
        [-1.0460, -2.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05100092664361
Epoch 0, Step 233: train/loss = 0.6665197014808655, train/raw-loss = 0.6237666606903076, train/logprobs = tensor([[-1.2376, -1.9929],
        [-1.1822, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04275306314229965
Epoch 0, Step 234: train/loss = 0.6460667252540588, train/raw-loss = 0.5912373065948486, train/logprobs = tensor([[-0.8821, -2.1929],
        [-0.8959, -1.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054829344153404236
Epoch 0, Step 235: train/loss = 0.7032995820045471, train/raw-loss = 0.6655949354171753, train/logprobs = tensor([[-0.9113, -1.6256],
        [-0.8652, -1.4631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03770463168621063
Epoch 0, Step 236: train/loss = 0.7101006507873535, train/raw-loss = 0.6636035442352295, train/logprobs = tensor([[-0.6543, -1.4149],
        [-0.6454, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04649702459573746
Epoch 0, Step 237: train/loss = 0.6890454292297363, train/raw-loss = 0.6560574769973755, train/logprobs = tensor([[-0.6704, -1.0564],
        [-0.6398, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03298797458410263
Epoch 0, Step 238: train/loss = 0.7293948531150818, train/raw-loss = 0.6737202405929565, train/logprobs = tensor([[-0.6898, -1.5956],
        [-0.6798, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05567459762096405
Epoch 0, Step 239: train/loss = 0.7028206586837769, train/raw-loss = 0.6764534115791321, train/logprobs = tensor([[-1.8337, -1.5756],
        [-1.8413, -1.5123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026367276906967163
Epoch 0, Step 240: train/loss = 0.6912766695022583, train/raw-loss = 0.6522644758224487, train/logprobs = tensor([[-0.8581, -1.4025],
        [-0.8385, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03901217132806778
Epoch 0, Step 241: train/loss = 0.7044399976730347, train/raw-loss = 0.6492483019828796, train/logprobs = tensor([[-0.8529, -1.8754],
        [-0.9077, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05519166961312294
Epoch 0, Step 242: train/loss = 0.6870478391647339, train/raw-loss = 0.6469839215278625, train/logprobs = tensor([[-0.9637, -1.4900],
        [-0.9647, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040063854306936264
Epoch 0, Step 243: train/loss = 0.6619756817817688, train/raw-loss = 0.6272205710411072, train/logprobs = tensor([[-1.0620, -1.7683],
        [-1.0239, -1.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034755147993564606
Epoch 0, Step 244: train/loss = 0.7190744280815125, train/raw-loss = 0.6655378341674805, train/logprobs = tensor([[-0.8941, -1.6228],
        [-0.8432, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05353657901287079
Epoch 0, Step 245: train/loss = 0.6951696872711182, train/raw-loss = 0.6600765585899353, train/logprobs = tensor([[-1.0950, -1.7381],
        [-1.0968, -1.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03509309142827988
Epoch 0, Step 246: train/loss = 0.7025184035301208, train/raw-loss = 0.6621925830841064, train/logprobs = tensor([[-1.0596, -1.4871],
        [-1.0155, -1.3114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04032585024833679
Epoch 0, Step 247: train/loss = 0.6926330327987671, train/raw-loss = 0.6470864415168762, train/logprobs = tensor([[-0.9623, -1.7180],
        [-0.8867, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045546576380729675
Epoch 0, Step 248: train/loss = 0.6663398742675781, train/raw-loss = 0.6180505156517029, train/logprobs = tensor([[-0.9695, -2.4039],
        [-0.9118, -2.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04828928783535957
Epoch 0, Step 249: train/loss = 0.6953290700912476, train/raw-loss = 0.6607000827789307, train/logprobs = tensor([[-1.1742, -1.4981],
        [-1.1892, -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034629032015800476
Epoch 0, Step 250: train/loss = 0.6966500282287598, train/raw-loss = 0.6199041604995728, train/logprobs = tensor([[-0.5836, -2.2519],
        [-0.5544, -1.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767458826303482
Epoch 0, Step 251: train/loss = 0.729634702205658, train/raw-loss = 0.6713968515396118, train/logprobs = tensor([[-0.9246, -2.2185],
        [-0.9720, -2.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05823787301778793
Epoch 0, Step 252: train/loss = 0.7106146812438965, train/raw-loss = 0.679390549659729, train/logprobs = tensor([[-1.0299, -1.1184],
        [-0.9565, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03122420608997345
Epoch 0, Step 253: train/loss = 0.7118140459060669, train/raw-loss = 0.6815718412399292, train/logprobs = tensor([[-1.1659, -1.4525],
        [-1.1336, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03024229407310486
Epoch 0, Step 254: train/loss = 0.7151710987091064, train/raw-loss = 0.6729375720024109, train/logprobs = tensor([[-0.8276, -1.0497],
        [-0.8467, -0.9860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04223354905843735
Epoch 0, Step 255: train/loss = 0.6966462135314941, train/raw-loss = 0.619872510433197, train/logprobs = tensor([[-0.7484, -2.0865],
        [-0.8173, -1.8426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07677371054887772
Epoch 0, Step 256: train/loss = 0.6634095907211304, train/raw-loss = 0.6138371229171753, train/logprobs = tensor([[-0.7199, -1.9864],
        [-0.6529, -1.5701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049572356045246124
Epoch 0, Step 257: train/loss = 0.7230129241943359, train/raw-loss = 0.6728864908218384, train/logprobs = tensor([[-1.1350, -2.1233],
        [-1.0341, -1.9306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050126444548368454
Epoch 0, Step 258: train/loss = 0.6493351459503174, train/raw-loss = 0.607210099697113, train/logprobs = tensor([[-1.2857, -2.2772],
        [-1.2567, -1.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04212509095668793
Epoch 0, Step 259: train/loss = 0.7071559429168701, train/raw-loss = 0.6792470812797546, train/logprobs = tensor([[-1.3771, -1.4235],
        [-1.3016, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02790883183479309
Epoch 0, Step 260: train/loss = 0.6738734245300293, train/raw-loss = 0.6311162710189819, train/logprobs = tensor([[-1.0223, -1.8149],
        [-0.9822, -1.5006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04275716841220856
Epoch 0, Step 261: train/loss = 0.7113876342773438, train/raw-loss = 0.6640979647636414, train/logprobs = tensor([[-0.7552, -2.3384],
        [-0.6033, -2.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047289662063121796
Epoch 0, Step 262: train/loss = 0.7068900465965271, train/raw-loss = 0.6675004363059998, train/logprobs = tensor([[-1.2868, -1.8233],
        [-1.2925, -1.7202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03938965126872063
Epoch 0, Step 263: train/loss = 0.6361566781997681, train/raw-loss = 0.5986047983169556, train/logprobs = tensor([[-1.4383, -2.5643],
        [-1.3714, -2.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03755192831158638
Epoch 0, Step 264: train/loss = 0.6596198678016663, train/raw-loss = 0.6121521592140198, train/logprobs = tensor([[-0.8815, -2.2267],
        [-0.8184, -1.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04746769368648529
Epoch 0, Step 265: train/loss = 0.7127214670181274, train/raw-loss = 0.6746066212654114, train/logprobs = tensor([[-1.2501, -1.7464],
        [-1.2007, -1.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03811492770910263
Epoch 0, Step 266: train/loss = 0.7104007601737976, train/raw-loss = 0.6720348596572876, train/logprobs = tensor([[-0.9873, -1.0433],
        [-0.9495, -0.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836585953831673
Epoch 0, Step 267: train/loss = 0.6697620153427124, train/raw-loss = 0.6244025826454163, train/logprobs = tensor([[-1.3419, -1.8523],
        [-1.3380, -1.5397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04535939544439316
Epoch 0, Step 268: train/loss = 0.6621404886245728, train/raw-loss = 0.6198924779891968, train/logprobs = tensor([[-0.9502, -1.8282],
        [-0.9043, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042247969657182693
Epoch 0, Step 269: train/loss = 0.6577640771865845, train/raw-loss = 0.6208368539810181, train/logprobs = tensor([[-0.8375, -1.6040],
        [-0.9591, -1.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036927152425050735
Epoch 0, Step 270: train/loss = 0.7068963646888733, train/raw-loss = 0.6710515022277832, train/logprobs = tensor([[-0.7758, -1.7986],
        [-0.7079, -1.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03584490716457367
Epoch 0, Step 271: train/loss = 0.6921145915985107, train/raw-loss = 0.635543704032898, train/logprobs = tensor([[-0.6354, -1.7952],
        [-0.6266, -1.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05657093971967697
Epoch 0, Step 272: train/loss = 0.7018003463745117, train/raw-loss = 0.6525635123252869, train/logprobs = tensor([[-0.8809, -1.4561],
        [-0.8274, -1.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04923681914806366
Epoch 0, Step 273: train/loss = 0.6765339374542236, train/raw-loss = 0.6143419742584229, train/logprobs = tensor([[-0.5017, -2.2521],
        [-0.4866, -1.8868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06219188868999481
Epoch 0, Step 274: train/loss = 0.6580743789672852, train/raw-loss = 0.6275920271873474, train/logprobs = tensor([[-1.2224, -2.1325],
        [-1.1859, -1.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03048233687877655
Epoch 0, Step 275: train/loss = 0.6878235340118408, train/raw-loss = 0.6422398686408997, train/logprobs = tensor([[-0.8350, -1.9894],
        [-0.6970, -1.6121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045583583414554596
Epoch 0, Step 276: train/loss = 0.660325825214386, train/raw-loss = 0.6050835847854614, train/logprobs = tensor([[-0.5685, -2.3490],
        [-0.5584, -1.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05524228513240814
Epoch 0, Step 277: train/loss = 0.6355021595954895, train/raw-loss = 0.5912579894065857, train/logprobs = tensor([[-1.2464, -1.8879],
        [-1.2160, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04424416273832321
Epoch 0, Step 278: train/loss = 0.6199471354484558, train/raw-loss = 0.5715508460998535, train/logprobs = tensor([[-1.1068, -2.9131],
        [-1.1553, -2.3968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04839629307389259
Epoch 0, Step 279: train/loss = 0.6844972968101501, train/raw-loss = 0.6402772665023804, train/logprobs = tensor([[-1.2070, -1.7512],
        [-1.1933, -1.5077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04422003775835037
Epoch 0, Step 280: train/loss = 0.6677133440971375, train/raw-loss = 0.6167466640472412, train/logprobs = tensor([[-0.8706, -1.7882],
        [-0.8536, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05096670985221863
Epoch 0, Step 281: train/loss = 0.6852620840072632, train/raw-loss = 0.6546741724014282, train/logprobs = tensor([[-1.1620, -1.8426],
        [-1.0866, -1.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03058789297938347
Epoch 0, Step 282: train/loss = 0.6870862245559692, train/raw-loss = 0.6462046504020691, train/logprobs = tensor([[-0.6779, -1.8619],
        [-0.6151, -1.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04088153690099716
Epoch 0, Step 283: train/loss = 0.6391885280609131, train/raw-loss = 0.5851089954376221, train/logprobs = tensor([[-0.6439, -2.2317],
        [-0.6114, -1.7081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054079487919807434
Epoch 0, Step 284: train/loss = 0.7006019949913025, train/raw-loss = 0.6530728340148926, train/logprobs = tensor([[-0.8524, -1.3583],
        [-0.8525, -1.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04752914607524872
Epoch 0, Step 285: train/loss = 0.6971675157546997, train/raw-loss = 0.6531374454498291, train/logprobs = tensor([[-0.8492, -2.5741],
        [-0.7547, -2.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044030122458934784
Epoch 0, Step 286: train/loss = 0.7105134725570679, train/raw-loss = 0.6655393838882446, train/logprobs = tensor([[-0.7743, -1.2914],
        [-0.7087, -1.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04497407749295235
Epoch 0, Step 287: train/loss = 0.7125183939933777, train/raw-loss = 0.6673128604888916, train/logprobs = tensor([[-0.9240, -1.1254],
        [-0.9100, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04520554840564728
Epoch 0, Step 288: train/loss = 0.6060823798179626, train/raw-loss = 0.5481639504432678, train/logprobs = tensor([[-1.3205, -3.1432],
        [-1.3936, -2.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057918425649404526
Epoch 0, Step 289: train/loss = 0.7007137537002563, train/raw-loss = 0.6551105380058289, train/logprobs = tensor([[-1.0417, -1.5676],
        [-0.9677, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04560321569442749
Epoch 0, Step 290: train/loss = 0.6944525837898254, train/raw-loss = 0.657492995262146, train/logprobs = tensor([[-1.1225, -1.7890],
        [-1.0337, -1.5416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036959562450647354
Epoch 0, Step 291: train/loss = 0.7172772288322449, train/raw-loss = 0.6735225319862366, train/logprobs = tensor([[-0.6603, -1.0300],
        [-0.6198, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0437546968460083
Epoch 0, Step 292: train/loss = 0.6722160577774048, train/raw-loss = 0.6239734888076782, train/logprobs = tensor([[-0.9144, -1.9188],
        [-0.8146, -1.4914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048242583870887756
Epoch 0, Step 293: train/loss = 0.6567754745483398, train/raw-loss = 0.5995036363601685, train/logprobs = tensor([[-0.7902, -2.4775],
        [-0.8117, -2.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0572718009352684
Epoch 0, Step 294: train/loss = 0.6815130114555359, train/raw-loss = 0.6334973573684692, train/logprobs = tensor([[-0.8592, -1.8832],
        [-0.8456, -1.5949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048015620559453964
Epoch 0, Step 295: train/loss = 0.7005895376205444, train/raw-loss = 0.6507634520530701, train/logprobs = tensor([[-1.4239, -1.6134],
        [-1.4012, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04982604831457138
Epoch 0, Step 296: train/loss = 0.5998231172561646, train/raw-loss = 0.5449802875518799, train/logprobs = tensor([[-0.8760, -3.0081],
        [-0.8782, -2.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054842758923769
Epoch 0, Step 297: train/loss = 0.6706857681274414, train/raw-loss = 0.6189440488815308, train/logprobs = tensor([[-0.9961, -2.0990],
        [-0.9381, -1.6932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05174165219068527
Epoch 0, Step 298: train/loss = 0.6514558792114258, train/raw-loss = 0.6002248525619507, train/logprobs = tensor([[-0.7246, -2.4088],
        [-0.7842, -2.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05123094469308853
Epoch 0, Step 299: train/loss = 0.6689302325248718, train/raw-loss = 0.6229301691055298, train/logprobs = tensor([[-1.2368, -1.3964],
        [-1.2195, -1.0683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04600007086992264
Epoch 0, Step 300: train/loss = 0.7115834951400757, train/raw-loss = 0.6711598634719849, train/logprobs = tensor([[-1.3315, -1.3930],
        [-1.2030, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040423668920993805
Epoch 0, Step 301: train/loss = 0.6943100690841675, train/raw-loss = 0.6587202548980713, train/logprobs = tensor([[-0.8708, -1.2614],
        [-0.8040, -1.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0355897955596447
Epoch 0, Step 302: train/loss = 0.6737726926803589, train/raw-loss = 0.6229761838912964, train/logprobs = tensor([[-0.8351, -2.0554],
        [-0.8170, -1.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0507965013384819
Epoch 0, Step 303: train/loss = 0.7028242945671082, train/raw-loss = 0.6560437679290771, train/logprobs = tensor([[-0.8258, -1.7882],
        [-0.7507, -1.5540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0467805340886116
Epoch 0, Step 304: train/loss = 0.6825040578842163, train/raw-loss = 0.6385249495506287, train/logprobs = tensor([[-1.1305, -2.0723],
        [-1.0711, -1.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04397917911410332
Epoch 0, Step 305: train/loss = 0.6895102262496948, train/raw-loss = 0.6563940048217773, train/logprobs = tensor([[-0.8677, -1.2507],
        [-0.7236, -0.9222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033116262406110764
Epoch 0, Step 306: train/loss = 0.6812452077865601, train/raw-loss = 0.6398800611495972, train/logprobs = tensor([[-0.8938, -2.0409],
        [-0.8647, -1.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04136521369218826
Epoch 0, Step 307: train/loss = 0.6763869524002075, train/raw-loss = 0.6280286312103271, train/logprobs = tensor([[-0.8507, -2.3491],
        [-0.8379, -2.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04835837334394455
Epoch 0, Step 308: train/loss = 0.6817365884780884, train/raw-loss = 0.628558337688446, train/logprobs = tensor([[-1.0647, -1.9520],
        [-1.0703, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053178299218416214
Epoch 0, Step 309: train/loss = 0.6915806531906128, train/raw-loss = 0.64589524269104, train/logprobs = tensor([[-0.6940, -1.3305],
        [-0.6649, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045685332268476486
Epoch 0, Step 310: train/loss = 0.674898624420166, train/raw-loss = 0.6200507879257202, train/logprobs = tensor([[-0.9831, -2.5968],
        [-0.9356, -2.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054847799241542816
Epoch 0, Step 311: train/loss = 0.6779282689094543, train/raw-loss = 0.6306155323982239, train/logprobs = tensor([[-0.6570, -1.5817],
        [-0.6068, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0473126657307148
Epoch 0, Step 312: train/loss = 0.6821937561035156, train/raw-loss = 0.6382105350494385, train/logprobs = tensor([[-1.2336, -1.8054],
        [-1.2587, -1.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043983303010463715
Epoch 0, Step 313: train/loss = 0.664261519908905, train/raw-loss = 0.6169425249099731, train/logprobs = tensor([[-0.8547, -2.6932],
        [-0.8027, -2.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047318994998931885
Epoch 0, Step 314: train/loss = 0.6544225215911865, train/raw-loss = 0.5979443788528442, train/logprobs = tensor([[-0.7433, -2.6407],
        [-0.7442, -2.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05647807940840721
Epoch 0, Step 315: train/loss = 0.6654394865036011, train/raw-loss = 0.6121029853820801, train/logprobs = tensor([[-0.7236, -2.2976],
        [-0.7008, -1.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0533364936709404
Epoch 0, Step 316: train/loss = 0.6627422571182251, train/raw-loss = 0.6174306869506836, train/logprobs = tensor([[-1.1814, -2.0226],
        [-1.1374, -1.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04531154781579971
Epoch 0, Step 317: train/loss = 0.6773771047592163, train/raw-loss = 0.6382744312286377, train/logprobs = tensor([[-0.9794, -1.6921],
        [-0.9128, -1.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03910272940993309
Epoch 0, Step 318: train/loss = 0.6855700016021729, train/raw-loss = 0.6439351439476013, train/logprobs = tensor([[-1.0827, -2.0269],
        [-1.0067, -1.7290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04163486137986183
Epoch 0, Step 319: train/loss = 0.6673572063446045, train/raw-loss = 0.6188604831695557, train/logprobs = tensor([[-1.0879, -2.0388],
        [-1.0978, -1.7139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048496708273887634
Epoch 0, Step 320: train/loss = 0.6707267165184021, train/raw-loss = 0.6254479885101318, train/logprobs = tensor([[-0.5859, -1.6468],
        [-0.5433, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04527871310710907
Epoch 0, Step 321: train/loss = 0.6628338694572449, train/raw-loss = 0.6177372932434082, train/logprobs = tensor([[-1.2228, -2.4685],
        [-1.1699, -2.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04509659856557846
Epoch 0, Step 322: train/loss = 0.6480254530906677, train/raw-loss = 0.6064193248748779, train/logprobs = tensor([[-1.1157, -2.8735],
        [-1.0055, -2.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04160616546869278
Epoch 0, Step 323: train/loss = 0.7062246799468994, train/raw-loss = 0.6685311794281006, train/logprobs = tensor([[-1.0268, -0.9322],
        [-0.9072, -0.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03769348934292793
Epoch 0, Step 324: train/loss = 0.6752487421035767, train/raw-loss = 0.6296987533569336, train/logprobs = tensor([[-1.4043, -2.3444],
        [-1.3282, -1.9899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04554995149374008
Epoch 0, Step 325: train/loss = 0.6173909902572632, train/raw-loss = 0.5725778937339783, train/logprobs = tensor([[-1.8960, -2.1616],
        [-1.7816, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044813089072704315
Epoch 0, Step 326: train/loss = 0.6402849555015564, train/raw-loss = 0.5866457223892212, train/logprobs = tensor([[-1.2010, -2.3513],
        [-1.1605, -1.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053639236837625504
Epoch 0, Step 327: train/loss = 0.6742799878120422, train/raw-loss = 0.627217710018158, train/logprobs = tensor([[-1.2226, -2.1142],
        [-1.1277, -1.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047062262892723083
Epoch 0, Step 328: train/loss = 0.6606438755989075, train/raw-loss = 0.6103866696357727, train/logprobs = tensor([[-0.9947, -1.7210],
        [-0.8469, -1.1679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05025719851255417
Epoch 0, Step 329: train/loss = 0.6368094682693481, train/raw-loss = 0.5834099650382996, train/logprobs = tensor([[-1.3995, -2.4881],
        [-1.4238, -2.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0533994659781456
Epoch 0, Step 330: train/loss = 0.6870860457420349, train/raw-loss = 0.6447933912277222, train/logprobs = tensor([[-1.1201, -2.3694],
        [-1.0382, -2.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04229264706373215
Epoch 0, Step 331: train/loss = 0.6714345812797546, train/raw-loss = 0.6297250390052795, train/logprobs = tensor([[-1.3531, -2.3029],
        [-1.1906, -1.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041709523648023605
Epoch 0, Step 332: train/loss = 0.689993143081665, train/raw-loss = 0.6471065282821655, train/logprobs = tensor([[-1.8668, -1.5702],
        [-1.8280, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04288671165704727
Epoch 0, Step 333: train/loss = 0.6411045789718628, train/raw-loss = 0.5926487445831299, train/logprobs = tensor([[-1.4320, -2.8663],
        [-1.2265, -2.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04845583811402321
Epoch 0, Step 334: train/loss = 0.7058072090148926, train/raw-loss = 0.6611688733100891, train/logprobs = tensor([[-1.5269, -2.3080],
        [-1.4350, -2.0778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04463833197951317
Epoch 0, Step 335: train/loss = 0.6565767526626587, train/raw-loss = 0.6093096137046814, train/logprobs = tensor([[-0.7819, -1.6304],
        [-0.7233, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047267183661460876
Epoch 0, Step 336: train/loss = 0.6564702391624451, train/raw-loss = 0.60768061876297, train/logprobs = tensor([[-0.9780, -1.8056],
        [-0.9753, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048789605498313904
Epoch 0, Step 337: train/loss = 0.6674395799636841, train/raw-loss = 0.613014280796051, train/logprobs = tensor([[-0.9826, -2.6813],
        [-1.0204, -2.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054425306618213654
Epoch 0, Step 338: train/loss = 0.6592194437980652, train/raw-loss = 0.6055911183357239, train/logprobs = tensor([[-1.2255, -2.0586],
        [-1.1471, -1.5674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05362828075885773
Epoch 0, Step 339: train/loss = 0.6567466855049133, train/raw-loss = 0.6080731153488159, train/logprobs = tensor([[-1.3506, -1.8368],
        [-1.3600, -1.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0486735925078392
Epoch 0, Step 340: train/loss = 0.6168901324272156, train/raw-loss = 0.5634337663650513, train/logprobs = tensor([[-1.5081, -2.4580],
        [-1.4229, -1.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053456347435712814
Epoch 0, Step 341: train/loss = 0.6192865371704102, train/raw-loss = 0.567177951335907, train/logprobs = tensor([[-1.5202, -2.6671],
        [-1.4023, -1.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052108559757471085
Epoch 0, Step 342: train/loss = 0.667883038520813, train/raw-loss = 0.6196576356887817, train/logprobs = tensor([[-1.1444, -1.9242],
        [-1.1077, -1.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048225484788417816
Epoch 0, Step 343: train/loss = 0.6778734922409058, train/raw-loss = 0.6307529211044312, train/logprobs = tensor([[-0.7420, -2.0657],
        [-0.7193, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04712063446640968
Epoch 0, Step 344: train/loss = 0.6962411403656006, train/raw-loss = 0.6464011669158936, train/logprobs = tensor([[-1.2236, -1.7732],
        [-1.0565, -1.3787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04983993619680405
Epoch 0, Step 345: train/loss = 0.7035634517669678, train/raw-loss = 0.6575015187263489, train/logprobs = tensor([[-1.0787, -1.5712],
        [-0.9011, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046061865985393524
Epoch 0, Step 346: train/loss = 0.6435902714729309, train/raw-loss = 0.5855803489685059, train/logprobs = tensor([[-0.9360, -2.3895],
        [-0.8541, -1.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05800990015268326
Epoch 0, Step 347: train/loss = 0.6813009977340698, train/raw-loss = 0.6359924674034119, train/logprobs = tensor([[-1.2419, -1.8544],
        [-1.1174, -1.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04530850425362587
Epoch 0, Step 348: train/loss = 0.6879531741142273, train/raw-loss = 0.643968939781189, train/logprobs = tensor([[-0.9728, -1.7454],
        [-0.8736, -1.4252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04398426413536072
Epoch 0, Step 349: train/loss = 0.6776273250579834, train/raw-loss = 0.6312487125396729, train/logprobs = tensor([[-0.9125, -1.8288],
        [-0.8054, -1.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04637857899069786
Epoch 0, Step 350: train/loss = 0.6088449358940125, train/raw-loss = 0.5494692325592041, train/logprobs = tensor([[-0.8088, -3.8641],
        [-0.7320, -3.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05937570333480835
Epoch 0, Step 351: train/loss = 0.6481858491897583, train/raw-loss = 0.5885947942733765, train/logprobs = tensor([[-0.9454, -2.6699],
        [-0.8811, -2.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059591103345155716
Epoch 0, Step 352: train/loss = 0.5873185992240906, train/raw-loss = 0.5365794897079468, train/logprobs = tensor([[-1.0805, -2.7419],
        [-0.9713, -1.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05073915794491768
Epoch 0, Step 353: train/loss = 0.6363375186920166, train/raw-loss = 0.5888177156448364, train/logprobs = tensor([[-1.2851, -1.9942],
        [-1.2372, -1.4689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04751987010240555
Epoch 0, Step 354: train/loss = 0.5529725551605225, train/raw-loss = 0.49513280391693115, train/logprobs = tensor([[-0.7314, -3.3690],
        [-0.6096, -2.1155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0578397661447525
Epoch 0, Step 355: train/loss = 0.7122209668159485, train/raw-loss = 0.6680305600166321, train/logprobs = tensor([[-0.8235, -1.6720],
        [-0.5763, -1.2722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04419036954641342
Epoch 0, Step 356: train/loss = 0.6951116323471069, train/raw-loss = 0.6551555395126343, train/logprobs = tensor([[-1.0210, -1.3147],
        [-0.8902, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039956144988536835
Epoch 0, Step 357: train/loss = 0.584798276424408, train/raw-loss = 0.5265711545944214, train/logprobs = tensor([[-0.7288, -2.9885],
        [-0.6375, -2.0370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05822710692882538
Epoch 0, Step 358: train/loss = 0.6260965466499329, train/raw-loss = 0.571282148361206, train/logprobs = tensor([[-1.1047, -2.0947],
        [-1.0401, -1.4529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05481437221169472
Epoch 0, Step 359: train/loss = 0.611027717590332, train/raw-loss = 0.5543087124824524, train/logprobs = tensor([[-0.7199, -2.4801],
        [-0.6583, -1.7633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05671904608607292
Epoch 0, Step 360: train/loss = 0.6247798204421997, train/raw-loss = 0.5614590644836426, train/logprobs = tensor([[-0.7407, -3.1592],
        [-0.6459, -2.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06332075595855713
Epoch 0, Step 361: train/loss = 0.6393873691558838, train/raw-loss = 0.579934298992157, train/logprobs = tensor([[-0.7081, -2.6605],
        [-0.6229, -2.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0594530887901783
Epoch 0, Step 362: train/loss = 0.6769203543663025, train/raw-loss = 0.6152632832527161, train/logprobs = tensor([[-1.3962, -1.6185],
        [-1.2364, -1.0559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06165701150894165
Epoch 0, Step 363: train/loss = 0.6621668338775635, train/raw-loss = 0.610114336013794, train/logprobs = tensor([[-1.1419, -2.2559],
        [-1.0908, -1.8398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05205244570970535
Epoch 0, Step 364: train/loss = 0.6390637159347534, train/raw-loss = 0.5935043096542358, train/logprobs = tensor([[-0.8442, -1.8497],
        [-0.7526, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045559413731098175
Epoch 0, Step 365: train/loss = 0.6248952746391296, train/raw-loss = 0.578787088394165, train/logprobs = tensor([[-1.0498, -1.7821],
        [-0.9536, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04610815644264221
Epoch 0, Step 366: train/loss = 0.7029227018356323, train/raw-loss = 0.641602098941803, train/logprobs = tensor([[-1.1238, -1.5890],
        [-1.0579, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06132061034440994
Epoch 0, Step 367: train/loss = 0.6448369026184082, train/raw-loss = 0.5922576785087585, train/logprobs = tensor([[-1.0220, -1.7864],
        [-0.8796, -1.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05257921293377876
Epoch 0, Step 368: train/loss = 0.6216614246368408, train/raw-loss = 0.5645725727081299, train/logprobs = tensor([[-1.1411, -2.4161],
        [-1.0390, -1.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057088833302259445
Epoch 0, Step 369: train/loss = 0.6332589387893677, train/raw-loss = 0.5751688480377197, train/logprobs = tensor([[-1.0585, -1.9428],
        [-1.0140, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05809013918042183
Epoch 0, Step 370: train/loss = 0.6136177182197571, train/raw-loss = 0.5550096035003662, train/logprobs = tensor([[-0.9621, -2.3616],
        [-0.7990, -1.4928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05860808119177818
Epoch 0, Step 371: train/loss = 0.6926168203353882, train/raw-loss = 0.640521228313446, train/logprobs = tensor([[-0.5288, -0.9683],
        [-0.4488, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05209551006555557
Epoch 0, Step 372: train/loss = 0.6432774066925049, train/raw-loss = 0.5974826812744141, train/logprobs = tensor([[-0.9826, -2.1018],
        [-0.8599, -1.4906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04579475149512291
Epoch 0, Step 373: train/loss = 0.6021887063980103, train/raw-loss = 0.5426719188690186, train/logprobs = tensor([[-0.9266, -2.8571],
        [-0.8205, -1.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059516847133636475
Epoch 0, Step 374: train/loss = 0.6842741966247559, train/raw-loss = 0.6372472047805786, train/logprobs = tensor([[-0.7543, -1.0826],
        [-0.6107, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04702705889940262
Epoch 0, Step 375: train/loss = 0.6561665534973145, train/raw-loss = 0.6066105365753174, train/logprobs = tensor([[-0.9963, -1.7351],
        [-1.0226, -1.3732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049556031823158264
Epoch 0, Step 376: train/loss = 0.6867201328277588, train/raw-loss = 0.6326630711555481, train/logprobs = tensor([[-1.3114, -1.7338],
        [-1.1496, -1.2548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05405707657337189
Epoch 0, Step 377: train/loss = 0.7132571935653687, train/raw-loss = 0.6747218370437622, train/logprobs = tensor([[-0.5847, -0.7712],
        [-0.5195, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03853537142276764
Epoch 0, Step 378: train/loss = 0.6826479434967041, train/raw-loss = 0.6298739910125732, train/logprobs = tensor([[-1.6376, -1.7536],
        [-1.4941, -1.3079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05277400091290474
Epoch 0, Step 379: train/loss = 0.6307448744773865, train/raw-loss = 0.5839662551879883, train/logprobs = tensor([[-1.7353, -2.8635],
        [-1.4818, -2.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04677863419055939
Epoch 0, Step 380: train/loss = 0.6323360204696655, train/raw-loss = 0.5835369229316711, train/logprobs = tensor([[-0.8247, -1.7984],
        [-0.7989, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04879912734031677
Epoch 0, Step 381: train/loss = 0.6146445274353027, train/raw-loss = 0.5506932139396667, train/logprobs = tensor([[-0.8434, -2.4257],
        [-0.6841, -1.5156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063951276242733
Epoch 0, Step 382: train/loss = 0.6525284051895142, train/raw-loss = 0.6035351753234863, train/logprobs = tensor([[-1.0093, -1.8955],
        [-0.8421, -1.2910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04899322986602783
Epoch 0, Step 383: train/loss = 0.7090156078338623, train/raw-loss = 0.6695837378501892, train/logprobs = tensor([[-1.8972, -2.2091],
        [-1.5360, -1.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03943191096186638
Epoch 0, Step 384: train/loss = 0.6395058631896973, train/raw-loss = 0.5858637094497681, train/logprobs = tensor([[-0.8133, -1.8620],
        [-0.6905, -1.2051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053642094135284424
Epoch 0, Step 385: train/loss = 0.651505708694458, train/raw-loss = 0.6005251407623291, train/logprobs = tensor([[-1.3395, -1.6344],
        [-1.3038, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050980620086193085
Epoch 0, Step 386: train/loss = 0.6358143091201782, train/raw-loss = 0.5832700133323669, train/logprobs = tensor([[-1.1926, -2.1883],
        [-1.0486, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05254426226019859
Epoch 0, Step 387: train/loss = 0.6435643434524536, train/raw-loss = 0.5869905948638916, train/logprobs = tensor([[-1.1388, -1.8972],
        [-0.9204, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056573737412691116
Epoch 0, Step 388: train/loss = 0.7065502405166626, train/raw-loss = 0.6518689393997192, train/logprobs = tensor([[-0.7443, -0.9839],
        [-0.5605, -0.5807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05468124896287918
Epoch 0, Step 389: train/loss = 0.6557202339172363, train/raw-loss = 0.6057567000389099, train/logprobs = tensor([[-0.6461, -1.5166],
        [-0.5990, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04996347054839134
Epoch 0, Step 390: train/loss = 0.6107141375541687, train/raw-loss = 0.5497921109199524, train/logprobs = tensor([[-1.0088, -2.1169],
        [-0.8915, -1.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06092198193073273
Epoch 0, Step 391: train/loss = 0.6842170357704163, train/raw-loss = 0.6329397559165955, train/logprobs = tensor([[-1.5559, -2.2670],
        [-1.0762, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051277294754981995
Epoch 0, Step 392: train/loss = 0.616582989692688, train/raw-loss = 0.5547768473625183, train/logprobs = tensor([[-1.0468, -2.5279],
        [-0.9655, -1.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06180613487958908
Epoch 0, Step 393: train/loss = 0.6135939955711365, train/raw-loss = 0.5539198517799377, train/logprobs = tensor([[-1.3946, -2.3393],
        [-1.2885, -1.5624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05967414006590843
Epoch 0, Step 394: train/loss = 0.6962167620658875, train/raw-loss = 0.6305299401283264, train/logprobs = tensor([[-1.1749, -2.2958],
        [-0.8887, -1.6734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06568680703639984
Epoch 0, Step 395: train/loss = 0.6566164493560791, train/raw-loss = 0.6062027812004089, train/logprobs = tensor([[-1.0167, -1.7498],
        [-0.8785, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05041366070508957
Epoch 0, Step 396: train/loss = 0.5895571112632751, train/raw-loss = 0.5323857069015503, train/logprobs = tensor([[-0.8552, -2.5660],
        [-0.7726, -1.5700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05717141553759575
Epoch 0, Step 397: train/loss = 0.6917059421539307, train/raw-loss = 0.639266848564148, train/logprobs = tensor([[-1.3922, -1.4605],
        [-1.1079, -0.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0524391308426857
Epoch 0, Step 398: train/loss = 0.6140652298927307, train/raw-loss = 0.5604830980300903, train/logprobs = tensor([[-0.8913, -2.0742],
        [-0.8364, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05358206853270531
Epoch 0, Step 399: train/loss = 0.6646034717559814, train/raw-loss = 0.6074994206428528, train/logprobs = tensor([[-1.3507, -1.7431],
        [-1.1559, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05710403621196747
Epoch 0, Step 400: train/loss = 0.6395020484924316, train/raw-loss = 0.5764777064323425, train/logprobs = tensor([[-1.4803, -1.8699],
        [-1.3662, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06302441656589508
Epoch 0, Step 401: train/loss = 0.5580117106437683, train/raw-loss = 0.5007940530776978, train/logprobs = tensor([[-1.1342, -2.3392],
        [-1.0149, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05721769854426384
Epoch 0, Step 402: train/loss = 0.6398552656173706, train/raw-loss = 0.5895397663116455, train/logprobs = tensor([[-1.0376, -1.9287],
        [-0.9091, -1.3046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050315529108047485
Epoch 0, Step 403: train/loss = 0.6144331693649292, train/raw-loss = 0.5555770397186279, train/logprobs = tensor([[-1.2556, -1.8209],
        [-1.2937, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05885617434978485
Epoch 0, Step 404: train/loss = 0.6096497178077698, train/raw-loss = 0.5428476929664612, train/logprobs = tensor([[-1.1909, -2.1902],
        [-1.0837, -1.3376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0668020099401474
Epoch 0, Step 405: train/loss = 0.666645348072052, train/raw-loss = 0.6198635101318359, train/logprobs = tensor([[-0.7181, -1.5092],
        [-0.6568, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04678189009428024
Epoch 0, Step 406: train/loss = 0.6113951206207275, train/raw-loss = 0.5570744276046753, train/logprobs = tensor([[-1.1545, -2.6769],
        [-0.9946, -1.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05432071164250374
Epoch 0, Step 407: train/loss = 0.6401144862174988, train/raw-loss = 0.5920685529708862, train/logprobs = tensor([[-1.1325, -2.4334],
        [-1.0158, -1.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04804597049951553
Epoch 0, Step 408: train/loss = 0.6323100924491882, train/raw-loss = 0.5839595794677734, train/logprobs = tensor([[-1.1685, -1.6558],
        [-1.0029, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04835047945380211
Epoch 0, Step 409: train/loss = 0.5971482396125793, train/raw-loss = 0.5327509641647339, train/logprobs = tensor([[-0.7166, -2.0513],
        [-0.6685, -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06439729034900665
Epoch 0, Step 410: train/loss = 0.651041567325592, train/raw-loss = 0.5921549797058105, train/logprobs = tensor([[-0.9805, -1.6427],
        [-0.7086, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05888663977384567
Epoch 0, Step 411: train/loss = 0.7531976699829102, train/raw-loss = 0.7116239666938782, train/logprobs = tensor([[-1.4539, -1.3826],
        [-0.9529, -0.8644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041573621332645416
Epoch 0, Step 412: train/loss = 0.6239991188049316, train/raw-loss = 0.5665191411972046, train/logprobs = tensor([[-0.9540, -1.7656],
        [-0.9355, -1.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05747999995946884
Epoch 0, Step 413: train/loss = 0.720112144947052, train/raw-loss = 0.6594494581222534, train/logprobs = tensor([[-1.2125, -0.9315],
        [-1.0680, -0.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060662657022476196
Epoch 0, Step 414: train/loss = 0.7056388854980469, train/raw-loss = 0.638115406036377, train/logprobs = tensor([[-1.0278, -1.1914],
        [-0.8164, -0.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0675235316157341
Epoch 0, Step 415: train/loss = 0.6085264682769775, train/raw-loss = 0.5376498699188232, train/logprobs = tensor([[-0.6447, -2.3925],
        [-0.4516, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07087661325931549
Epoch 0, Step 416: train/loss = 0.5928829908370972, train/raw-loss = 0.5231752395629883, train/logprobs = tensor([[-0.8857, -2.4022],
        [-0.7334, -1.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06970775872468948
Epoch 0, Step 417: train/loss = 0.590482771396637, train/raw-loss = 0.5268049836158752, train/logprobs = tensor([[-1.0559, -3.4701],
        [-0.8845, -2.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06367778033018112
Epoch 0, Step 418: train/loss = 0.7093130946159363, train/raw-loss = 0.6487885117530823, train/logprobs = tensor([[-1.5065, -2.0205],
        [-0.9855, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06052454188466072
Epoch 0, Step 419: train/loss = 0.6411413550376892, train/raw-loss = 0.5731432437896729, train/logprobs = tensor([[-1.7058, -2.6397],
        [-1.2792, -1.3866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06799811124801636
Epoch 0, Step 420: train/loss = 0.5880554914474487, train/raw-loss = 0.5222835540771484, train/logprobs = tensor([[-1.1067, -2.4128],
        [-0.9322, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577196717262268
Epoch 0, Step 421: train/loss = 0.6262078881263733, train/raw-loss = 0.5740068554878235, train/logprobs = tensor([[-0.6758, -1.9154],
        [-0.5221, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0522010438144207
Epoch 0, Step 422: train/loss = 0.5696163177490234, train/raw-loss = 0.5013018846511841, train/logprobs = tensor([[-0.9279, -1.8810],
        [-0.9042, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06831445544958115
Epoch 0, Step 423: train/loss = 0.598228931427002, train/raw-loss = 0.5351484417915344, train/logprobs = tensor([[-1.2199, -2.0019],
        [-1.1159, -1.1130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06308047473430634
Epoch 0, Step 424: train/loss = 0.5881094336509705, train/raw-loss = 0.5296517014503479, train/logprobs = tensor([[-0.7565, -2.0474],
        [-0.5496, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05845772475004196
Epoch 0, Step 425: train/loss = 0.5337764024734497, train/raw-loss = 0.46758246421813965, train/logprobs = tensor([[-1.0841, -2.8789],
        [-0.9764, -1.5582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06619396805763245
Epoch 0, Step 426: train/loss = 0.6466364860534668, train/raw-loss = 0.5824975371360779, train/logprobs = tensor([[-1.2557, -1.7402],
        [-1.1311, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06413891911506653
Epoch 0, Step 427: train/loss = 0.7072932124137878, train/raw-loss = 0.6632745265960693, train/logprobs = tensor([[-0.8097, -1.2378],
        [-0.7086, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0440186932682991
Epoch 0, Step 428: train/loss = 0.6021326184272766, train/raw-loss = 0.5384470224380493, train/logprobs = tensor([[-1.4098, -1.8174],
        [-1.1833, -0.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06368561834096909
Epoch 0, Step 429: train/loss = 0.7230765223503113, train/raw-loss = 0.6709027290344238, train/logprobs = tensor([[-0.9958, -1.0783],
        [-0.7873, -0.7447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05217375233769417
Epoch 0, Step 430: train/loss = 0.6033747792243958, train/raw-loss = 0.5384679436683655, train/logprobs = tensor([[-1.1081, -2.6829],
        [-0.7756, -1.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06490682065486908
Epoch 0, Step 431: train/loss = 0.6239744424819946, train/raw-loss = 0.5459169149398804, train/logprobs = tensor([[-1.3989, -2.6821],
        [-1.2119, -1.6982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07805754244327545
Epoch 0, Step 432: train/loss = 0.7049615383148193, train/raw-loss = 0.6491110324859619, train/logprobs = tensor([[-0.9460, -1.4331],
        [-0.8715, -1.1693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05585043132305145
Epoch 0, Step 433: train/loss = 0.5865423083305359, train/raw-loss = 0.5135254263877869, train/logprobs = tensor([[-1.4316, -2.7678],
        [-1.2710, -1.6433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07301685959100723
Epoch 0, Step 434: train/loss = 0.5910826921463013, train/raw-loss = 0.5251953601837158, train/logprobs = tensor([[-1.2001, -2.6015],
        [-1.0529, -1.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06588730216026306
Epoch 0, Step 435: train/loss = 0.6682437658309937, train/raw-loss = 0.6022325754165649, train/logprobs = tensor([[-1.3274, -1.6538],
        [-1.2706, -1.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0660112202167511
Epoch 0, Step 436: train/loss = 0.6142978072166443, train/raw-loss = 0.5556447505950928, train/logprobs = tensor([[-1.0297, -1.7973],
        [-0.9281, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05865304544568062
Epoch 0, Step 437: train/loss = 0.5878437757492065, train/raw-loss = 0.5115005970001221, train/logprobs = tensor([[-0.8797, -2.1315],
        [-0.8148, -1.0970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07634314894676208
Epoch 0, Step 438: train/loss = 0.7010036706924438, train/raw-loss = 0.6360458135604858, train/logprobs = tensor([[-1.3056, -1.8974],
        [-1.1382, -1.4286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06495782732963562
Epoch 0, Step 439: train/loss = 0.5832273364067078, train/raw-loss = 0.519595742225647, train/logprobs = tensor([[-1.0193, -2.1003],
        [-0.9064, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.063631571829319
Epoch 0, Step 440: train/loss = 0.6934409737586975, train/raw-loss = 0.6395078897476196, train/logprobs = tensor([[-1.6282, -1.8751],
        [-1.2593, -1.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05393315106630325
Epoch 0, Step 441: train/loss = 0.526072084903717, train/raw-loss = 0.45103082060813904, train/logprobs = tensor([[-0.9949, -3.1626],
        [-0.8892, -1.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0750412791967392
Epoch 0, Step 442: train/loss = 0.6420361995697021, train/raw-loss = 0.580548882484436, train/logprobs = tensor([[-1.6878, -2.2129],
        [-1.5287, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061487335711717606
Epoch 0, Step 443: train/loss = 0.5963090658187866, train/raw-loss = 0.5312512516975403, train/logprobs = tensor([[-1.2401, -2.5280],
        [-1.1729, -1.6400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06505781412124634
Epoch 0, Step 444: train/loss = 0.6334524154663086, train/raw-loss = 0.5652657747268677, train/logprobs = tensor([[-0.9138, -1.9537],
        [-0.7195, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06818664073944092
Epoch 0, Step 445: train/loss = 0.6309736967086792, train/raw-loss = 0.5617259740829468, train/logprobs = tensor([[-1.5082, -1.8493],
        [-1.3468, -0.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06924770772457123
Epoch 0, Step 446: train/loss = 0.6008927822113037, train/raw-loss = 0.5348415374755859, train/logprobs = tensor([[-1.1069, -2.8814],
        [-0.7617, -1.6337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06605120748281479
Epoch 0, Step 447: train/loss = 0.562853217124939, train/raw-loss = 0.49583888053894043, train/logprobs = tensor([[-0.9601, -2.4986],
        [-0.7900, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06701437383890152
Epoch 0, Step 448: train/loss = 0.6063877940177917, train/raw-loss = 0.5368962287902832, train/logprobs = tensor([[-1.1827, -2.3782],
        [-0.9004, -1.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06949155777692795
Epoch 0, Step 449: train/loss = 0.6927453279495239, train/raw-loss = 0.6330395340919495, train/logprobs = tensor([[-1.4947, -1.5595],
        [-1.1656, -0.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05970577150583267
Epoch 0, Step 450: train/loss = 0.6303154230117798, train/raw-loss = 0.5659104585647583, train/logprobs = tensor([[-0.6004, -1.9899],
        [-0.4907, -1.2326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06440502405166626
Epoch 0, Step 451: train/loss = 0.6748685240745544, train/raw-loss = 0.6107526421546936, train/logprobs = tensor([[-1.8007, -2.3818],
        [-1.4842, -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06411589682102203
Epoch 0, Step 452: train/loss = 0.5819700360298157, train/raw-loss = 0.5174235701560974, train/logprobs = tensor([[-1.2608, -2.1125],
        [-1.0955, -0.9611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06454651057720184
Epoch 0, Step 453: train/loss = 0.5767888426780701, train/raw-loss = 0.4986872673034668, train/logprobs = tensor([[-0.8334, -2.1267],
        [-0.7210, -0.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0781015008687973
Epoch 0, Step 454: train/loss = 0.6060388684272766, train/raw-loss = 0.5277079343795776, train/logprobs = tensor([[-1.5565, -2.0433],
        [-1.3493, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07833092659711838
Epoch 0, Step 455: train/loss = 0.6144225597381592, train/raw-loss = 0.5448788404464722, train/logprobs = tensor([[-0.8042, -2.0665],
        [-0.6738, -1.1954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06954372674226761
Epoch 0, Step 456: train/loss = 0.604927122592926, train/raw-loss = 0.5495345592498779, train/logprobs = tensor([[-0.7909, -2.2234],
        [-0.6803, -1.0220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055392537266016006
Epoch 0, Step 457: train/loss = 0.6435902118682861, train/raw-loss = 0.5747883915901184, train/logprobs = tensor([[-0.6613, -1.7520],
        [-0.5588, -1.0486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06880183517932892
Epoch 0, Step 458: train/loss = 0.670172929763794, train/raw-loss = 0.6120396256446838, train/logprobs = tensor([[-1.3677, -1.8403],
        [-0.9534, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05813328176736832
Epoch 0, Step 459: train/loss = 0.6238948106765747, train/raw-loss = 0.554535984992981, train/logprobs = tensor([[-0.8259, -1.9060],
        [-0.7280, -1.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06935879588127136
Epoch 0, Step 460: train/loss = 0.6335298418998718, train/raw-loss = 0.5763283967971802, train/logprobs = tensor([[-0.7421, -1.6607],
        [-0.6636, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057201385498046875
Epoch 0, Step 461: train/loss = 0.6603078246116638, train/raw-loss = 0.5939573049545288, train/logprobs = tensor([[-1.3853, -1.7874],
        [-1.0788, -0.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06635050475597382
Epoch 0, Step 462: train/loss = 0.5470995306968689, train/raw-loss = 0.46865981817245483, train/logprobs = tensor([[-0.7215, -2.7172],
        [-0.5929, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07843971252441406
Epoch 0, Step 463: train/loss = 0.6071259379386902, train/raw-loss = 0.5320501923561096, train/logprobs = tensor([[-0.7980, -2.0236],
        [-0.6135, -0.8997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07507576793432236
Epoch 0, Step 464: train/loss = 0.5684605836868286, train/raw-loss = 0.5016717910766602, train/logprobs = tensor([[-0.9974, -3.2404],
        [-0.7994, -1.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06678874045610428
Epoch 0, Step 465: train/loss = 0.6759926080703735, train/raw-loss = 0.6235013008117676, train/logprobs = tensor([[-0.9940, -1.4137],
        [-0.7585, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05249132588505745
Epoch 0, Step 466: train/loss = 0.5617609024047852, train/raw-loss = 0.49573081731796265, train/logprobs = tensor([[-1.5232, -2.5537],
        [-1.2849, -1.2038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06603005528450012
Epoch 0, Step 467: train/loss = 0.6785107254981995, train/raw-loss = 0.6044231057167053, train/logprobs = tensor([[-1.3988, -1.7746],
        [-1.0423, -0.8218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07408761233091354
Epoch 0, Step 468: train/loss = 0.6554648876190186, train/raw-loss = 0.5821378231048584, train/logprobs = tensor([[-1.2399, -1.9637],
        [-0.9473, -0.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07332701981067657
Epoch 0, Step 469: train/loss = 0.6435132026672363, train/raw-loss = 0.5816754102706909, train/logprobs = tensor([[-0.8450, -1.3950],
        [-0.7228, -0.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06183768808841705
Epoch 0, Step 470: train/loss = 0.5693909525871277, train/raw-loss = 0.4845108687877655, train/logprobs = tensor([[-0.8206, -2.5713],
        [-0.6983, -1.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08488006889820099
Epoch 0, Step 471: train/loss = 0.6216824054718018, train/raw-loss = 0.5534182786941528, train/logprobs = tensor([[-0.9487, -2.3504],
        [-0.9000, -1.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06826411187648773
Epoch 0, Step 472: train/loss = 0.47369125485420227, train/raw-loss = 0.3927115499973297, train/logprobs = tensor([[-1.4045, -4.9990],
        [-1.2849, -1.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08097968995571136
Epoch 0, Step 473: train/loss = 0.6510074138641357, train/raw-loss = 0.5817112326622009, train/logprobs = tensor([[-1.6077, -2.1661],
        [-1.1456, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06929618120193481
Epoch 0, Step 474: train/loss = 0.5936607718467712, train/raw-loss = 0.5216825008392334, train/logprobs = tensor([[-0.7217, -2.4173],
        [-0.5944, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07197821885347366
Epoch 0, Step 475: train/loss = 0.5895129442214966, train/raw-loss = 0.5265908241271973, train/logprobs = tensor([[-0.9392, -2.4033],
        [-0.7515, -1.3387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06292209029197693
Epoch 0, Step 476: train/loss = 0.716404914855957, train/raw-loss = 0.6601253747940063, train/logprobs = tensor([[-1.2604, -1.4364],
        [-0.8958, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056279491633176804
Epoch 0, Step 477: train/loss = 0.614220380783081, train/raw-loss = 0.5427109599113464, train/logprobs = tensor([[-1.5369, -2.1533],
        [-1.2461, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07150942832231522
Epoch 0, Step 478: train/loss = 0.658115804195404, train/raw-loss = 0.5875411033630371, train/logprobs = tensor([[-1.5552, -1.9312],
        [-1.2446, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07057473808526993
Epoch 0, Step 479: train/loss = 0.5948818922042847, train/raw-loss = 0.5236641764640808, train/logprobs = tensor([[-1.3304, -2.8400],
        [-1.0180, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07121767848730087
Epoch 0, Step 480: train/loss = 0.5910499691963196, train/raw-loss = 0.5254671573638916, train/logprobs = tensor([[-0.8542, -1.8240],
        [-0.7467, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06558280438184738
Epoch 0, Step 481: train/loss = 0.5928459763526917, train/raw-loss = 0.5184747576713562, train/logprobs = tensor([[-1.2663, -1.8824],
        [-1.1152, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437120378017426
Epoch 0, Step 482: train/loss = 0.5781246423721313, train/raw-loss = 0.5085536241531372, train/logprobs = tensor([[-0.8152, -2.6906],
        [-0.7596, -1.6456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06957098096609116
Epoch 0, Step 483: train/loss = 0.5556739568710327, train/raw-loss = 0.4897800087928772, train/logprobs = tensor([[-1.3130, -2.4998],
        [-1.2404, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06589394062757492
Epoch 0, Step 484: train/loss = 0.569354236125946, train/raw-loss = 0.5085728764533997, train/logprobs = tensor([[-1.0292, -3.1586],
        [-0.9012, -1.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06078141927719116
Epoch 0, Step 485: train/loss = 0.6280704140663147, train/raw-loss = 0.5706111788749695, train/logprobs = tensor([[-1.2422, -1.7698],
        [-1.0200, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05745925381779671
Epoch 0, Step 486: train/loss = 0.6830983757972717, train/raw-loss = 0.6407727003097534, train/logprobs = tensor([[-0.6772, -1.2034],
        [-0.5485, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04232573136687279
Epoch 0, Step 487: train/loss = 0.569740891456604, train/raw-loss = 0.5116301774978638, train/logprobs = tensor([[-1.0260, -3.6733],
        [-0.7584, -2.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05811065807938576
Epoch 0, Step 488: train/loss = 0.6980242133140564, train/raw-loss = 0.6279808282852173, train/logprobs = tensor([[-1.7471, -2.2386],
        [-1.2922, -1.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07004337012767792
Epoch 0, Step 489: train/loss = 0.6552058458328247, train/raw-loss = 0.5944797992706299, train/logprobs = tensor([[-1.3402, -2.0344],
        [-1.0059, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06072606146335602
Epoch 0, Step 490: train/loss = 0.7043619155883789, train/raw-loss = 0.6559931039810181, train/logprobs = tensor([[-0.6086, -1.5293],
        [-0.5007, -1.2535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04836879298090935
Epoch 0, Step 491: train/loss = 0.5885342955589294, train/raw-loss = 0.5201852917671204, train/logprobs = tensor([[-0.9970, -2.4059],
        [-0.8930, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06834905594587326
Epoch 0, Step 492: train/loss = 0.572587788105011, train/raw-loss = 0.5154967904090881, train/logprobs = tensor([[-0.5837, -2.6019],
        [-0.5181, -1.5842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057090990245342255
Epoch 0, Step 493: train/loss = 0.5795961618423462, train/raw-loss = 0.506661057472229, train/logprobs = tensor([[-1.0364, -2.2325],
        [-0.8157, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07293514907360077
Epoch 0, Step 494: train/loss = 0.66422438621521, train/raw-loss = 0.6020869016647339, train/logprobs = tensor([[-1.3925, -1.5256],
        [-1.1254, -0.7576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06213755905628204
Epoch 0, Step 495: train/loss = 0.6403053998947144, train/raw-loss = 0.5752794146537781, train/logprobs = tensor([[-1.6520, -2.6244],
        [-1.4167, -1.7106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0650259479880333
Epoch 0, Step 496: train/loss = 0.5580084919929504, train/raw-loss = 0.48542648553848267, train/logprobs = tensor([[-1.2918, -3.0204],
        [-1.1639, -1.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07258197665214539
Epoch 0, Step 497: train/loss = 0.5387449860572815, train/raw-loss = 0.47075629234313965, train/logprobs = tensor([[-1.0349, -3.1798],
        [-0.9160, -1.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06798870861530304
Epoch 0, Step 498: train/loss = 0.6201004981994629, train/raw-loss = 0.548126757144928, train/logprobs = tensor([[-1.3313, -2.9084],
        [-1.0867, -1.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719737857580185
Epoch 0, Step 499: train/loss = 0.567109227180481, train/raw-loss = 0.49773257970809937, train/logprobs = tensor([[-0.9916, -2.7665],
        [-0.8552, -1.6032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06937667727470398
eval/loss: 0.6023866534233093
Epoch 0, Step 500: train/loss = 0.5309246778488159, train/raw-loss = 0.4623037576675415, train/logprobs = tensor([[-1.0466, -2.9796],
        [-0.9114, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0686209425330162
Epoch 0, Step 501: train/loss = 0.564949095249176, train/raw-loss = 0.48921287059783936, train/logprobs = tensor([[-1.0621, -2.3528],
        [-0.9585, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07573619484901428
Epoch 0, Step 502: train/loss = 0.5902175903320312, train/raw-loss = 0.527717113494873, train/logprobs = tensor([[-0.7792, -2.6629],
        [-0.6071, -1.6097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0625004842877388
Epoch 0, Step 503: train/loss = 0.5470170974731445, train/raw-loss = 0.47187358140945435, train/logprobs = tensor([[-1.2774, -3.0170],
        [-1.0819, -1.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07514350116252899
Epoch 0, Step 504: train/loss = 0.7010178565979004, train/raw-loss = 0.6411938667297363, train/logprobs = tensor([[-1.1942, -1.4944],
        [-0.9242, -0.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05982391536235809
Epoch 0, Step 505: train/loss = 0.6324968338012695, train/raw-loss = 0.5753412842750549, train/logprobs = tensor([[-1.1875, -2.1286],
        [-0.9863, -1.2893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05715551972389221
Epoch 0, Step 506: train/loss = 0.6108025312423706, train/raw-loss = 0.5289380550384521, train/logprobs = tensor([[-1.2237, -2.8302],
        [-0.9103, -1.4713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08186450600624084
Epoch 0, Step 507: train/loss = 0.5439561605453491, train/raw-loss = 0.4746198356151581, train/logprobs = tensor([[-0.9921, -2.7969],
        [-0.7982, -1.3419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06933627277612686
Epoch 0, Step 508: train/loss = 0.5907995700836182, train/raw-loss = 0.5267266631126404, train/logprobs = tensor([[-0.7492, -2.3995],
        [-0.6200, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06407293677330017
Epoch 0, Step 509: train/loss = 0.6596695184707642, train/raw-loss = 0.5918034911155701, train/logprobs = tensor([[-1.4195, -2.3024],
        [-0.9140, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0678660050034523
Epoch 0, Step 510: train/loss = 0.607586145401001, train/raw-loss = 0.5405564904212952, train/logprobs = tensor([[-0.7454, -2.3100],
        [-0.5361, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670296847820282
Epoch 0, Step 511: train/loss = 0.5801260471343994, train/raw-loss = 0.5155370235443115, train/logprobs = tensor([[-1.1136, -2.9109],
        [-0.6656, -1.1591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06458907574415207
Epoch 0, Step 512: train/loss = 0.5268540382385254, train/raw-loss = 0.47322219610214233, train/logprobs = tensor([[-0.6421, -2.5620],
        [-0.5084, -1.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05363186448812485
Epoch 0, Step 513: train/loss = 0.5443589091300964, train/raw-loss = 0.4783412218093872, train/logprobs = tensor([[-1.3663, -2.3206],
        [-1.2127, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06601765751838684
Epoch 0, Step 514: train/loss = 0.663658857345581, train/raw-loss = 0.6026105284690857, train/logprobs = tensor([[-1.8558, -2.0314],
        [-1.8151, -1.3878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06104838848114014
Epoch 0, Step 515: train/loss = 0.5976340770721436, train/raw-loss = 0.5276048183441162, train/logprobs = tensor([[-0.9147, -2.6484],
        [-0.7918, -1.6476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07002924382686615
Epoch 0, Step 516: train/loss = 0.7259203791618347, train/raw-loss = 0.6565945148468018, train/logprobs = tensor([[-1.9340, -2.7964],
        [-1.2466, -1.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06932593137025833
Epoch 0, Step 517: train/loss = 0.6742113828659058, train/raw-loss = 0.6065654754638672, train/logprobs = tensor([[-0.7401, -1.9483],
        [-0.6513, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06764589995145798
Epoch 0, Step 518: train/loss = 0.5758621096611023, train/raw-loss = 0.5086528658866882, train/logprobs = tensor([[-1.2695, -2.4314],
        [-1.1782, -1.4044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06720922887325287
Epoch 0, Step 519: train/loss = 0.6248713135719299, train/raw-loss = 0.5702725648880005, train/logprobs = tensor([[-0.7315, -2.1881],
        [-0.6011, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054598722606897354
Epoch 0, Step 520: train/loss = 0.5366465449333191, train/raw-loss = 0.4752601981163025, train/logprobs = tensor([[-1.2324, -3.1382],
        [-1.0013, -1.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0613863579928875
Epoch 0, Step 521: train/loss = 0.542788028717041, train/raw-loss = 0.47638222575187683, train/logprobs = tensor([[-1.2825, -3.2130],
        [-1.1273, -1.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640581041574478
Epoch 0, Step 522: train/loss = 0.5661813616752625, train/raw-loss = 0.4947476387023926, train/logprobs = tensor([[-1.7880, -3.4709],
        [-1.3617, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07143367826938629
Epoch 0, Step 523: train/loss = 0.6132550239562988, train/raw-loss = 0.5572839379310608, train/logprobs = tensor([[-0.7878, -2.0487],
        [-0.5678, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055971063673496246
Epoch 0, Step 524: train/loss = 0.6460981965065002, train/raw-loss = 0.5821839570999146, train/logprobs = tensor([[-1.0291, -1.5740],
        [-1.2461, -1.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06391417235136032
Epoch 0, Step 525: train/loss = 0.601671576499939, train/raw-loss = 0.5372538566589355, train/logprobs = tensor([[-1.4955, -3.0137],
        [-1.2586, -1.8152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06441770493984222
Epoch 0, Step 526: train/loss = 0.5324642062187195, train/raw-loss = 0.4583348035812378, train/logprobs = tensor([[-1.5207, -3.1962],
        [-1.4677, -1.5259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07412940263748169
Epoch 0, Step 527: train/loss = 0.479070246219635, train/raw-loss = 0.4196217656135559, train/logprobs = tensor([[-1.0349, -3.5037],
        [-1.0217, -1.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05944846197962761
Epoch 0, Step 528: train/loss = 0.6915527582168579, train/raw-loss = 0.6374759674072266, train/logprobs = tensor([[-0.7952, -1.0845],
        [-0.7556, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05407678708434105
Epoch 0, Step 529: train/loss = 0.47536739706993103, train/raw-loss = 0.40237170457839966, train/logprobs = tensor([[-0.7503, -3.7396],
        [-0.7119, -1.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07299572229385376
Epoch 0, Step 530: train/loss = 0.5915088057518005, train/raw-loss = 0.5314520597457886, train/logprobs = tensor([[-1.1498, -2.4587],
        [-0.8544, -1.1833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06005677953362465
Epoch 0, Step 531: train/loss = 0.6926764845848083, train/raw-loss = 0.6351461410522461, train/logprobs = tensor([[-1.3519, -1.8069],
        [-0.8904, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057530369609594345
Epoch 0, Step 532: train/loss = 0.5505416393280029, train/raw-loss = 0.4849884808063507, train/logprobs = tensor([[-0.9523, -2.8678],
        [-0.7951, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06555315852165222
Epoch 0, Step 533: train/loss = 0.5654048919677734, train/raw-loss = 0.5058623552322388, train/logprobs = tensor([[-0.5881, -2.2832],
        [-0.5017, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05954256281256676
Epoch 0, Step 534: train/loss = 0.6727306246757507, train/raw-loss = 0.6056784391403198, train/logprobs = tensor([[-1.3983, -1.9473],
        [-1.0357, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06705223023891449
Epoch 0, Step 535: train/loss = 0.6538258194923401, train/raw-loss = 0.5885084867477417, train/logprobs = tensor([[-0.9871, -1.5884],
        [-0.7168, -0.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0653173178434372
Epoch 0, Step 536: train/loss = 0.544547438621521, train/raw-loss = 0.4777923822402954, train/logprobs = tensor([[-1.1492, -2.8109],
        [-0.9902, -1.3698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06675508618354797
Epoch 0, Step 537: train/loss = 0.701511800289154, train/raw-loss = 0.6459927558898926, train/logprobs = tensor([[-1.3222, -1.6849],
        [-0.9759, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055519070476293564
Epoch 0, Step 538: train/loss = 0.6245431900024414, train/raw-loss = 0.561741828918457, train/logprobs = tensor([[-1.3266, -2.2080],
        [-1.2001, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0628012865781784
Epoch 0, Step 539: train/loss = 0.5203765630722046, train/raw-loss = 0.45308825373649597, train/logprobs = tensor([[-0.9776, -3.6380],
        [-0.9122, -1.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06728833168745041
Epoch 0, Step 540: train/loss = 0.6351525783538818, train/raw-loss = 0.5744592547416687, train/logprobs = tensor([[-1.1598, -1.8003],
        [-0.9122, -0.9198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060693271458148956
Epoch 0, Step 541: train/loss = 0.5434118509292603, train/raw-loss = 0.4746503233909607, train/logprobs = tensor([[-1.4843, -2.8157],
        [-1.3523, -1.4375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06876157224178314
Epoch 0, Step 542: train/loss = 0.5865317583084106, train/raw-loss = 0.5207551121711731, train/logprobs = tensor([[-1.3861, -3.0259],
        [-1.2867, -1.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06577659398317337
Epoch 0, Step 543: train/loss = 0.5474721193313599, train/raw-loss = 0.4905306100845337, train/logprobs = tensor([[-0.9938, -2.6910],
        [-0.8435, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05694153159856796
Epoch 0, Step 544: train/loss = 0.6216481924057007, train/raw-loss = 0.5593104958534241, train/logprobs = tensor([[-0.8328, -1.8561],
        [-0.6765, -0.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06233769655227661
Epoch 0, Step 545: train/loss = 0.6693577766418457, train/raw-loss = 0.6037927865982056, train/logprobs = tensor([[-0.5870, -1.1585],
        [-0.5753, -0.7142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06556504964828491
Epoch 0, Step 546: train/loss = 0.5937325954437256, train/raw-loss = 0.505739152431488, train/logprobs = tensor([[-1.4445, -1.8088],
        [-1.4685, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799345791339874
Epoch 0, Step 547: train/loss = 0.5761794447898865, train/raw-loss = 0.5003905892372131, train/logprobs = tensor([[-0.6526, -2.2076],
        [-0.4950, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07578891515731812
Epoch 0, Step 548: train/loss = 0.6517930030822754, train/raw-loss = 0.5865527391433716, train/logprobs = tensor([[-1.1126, -1.8724],
        [-0.9121, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652402937412262
Epoch 0, Step 549: train/loss = 0.5891419649124146, train/raw-loss = 0.5075588822364807, train/logprobs = tensor([[-1.0843, -2.0455],
        [-1.1218, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08158304542303085
Epoch 0, Step 550: train/loss = 0.6211380958557129, train/raw-loss = 0.5519965887069702, train/logprobs = tensor([[-1.1603, -1.6948],
        [-1.0172, -0.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06914156675338745
Epoch 0, Step 551: train/loss = 0.5968554019927979, train/raw-loss = 0.531650722026825, train/logprobs = tensor([[-0.7061, -1.8323],
        [-0.5415, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0652046650648117
Epoch 0, Step 552: train/loss = 0.511297881603241, train/raw-loss = 0.4413205087184906, train/logprobs = tensor([[-1.1338, -2.8756],
        [-0.9776, -1.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06997734308242798
Epoch 0, Step 553: train/loss = 0.5730510950088501, train/raw-loss = 0.5047690868377686, train/logprobs = tensor([[-1.3459, -2.7990],
        [-1.3224, -1.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06828202307224274
Epoch 0, Step 554: train/loss = 0.608334481716156, train/raw-loss = 0.5435984134674072, train/logprobs = tensor([[-1.0468, -2.0299],
        [-0.8892, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06473611295223236
Epoch 0, Step 555: train/loss = 0.4900340139865875, train/raw-loss = 0.4053555130958557, train/logprobs = tensor([[-1.3359, -3.7594],
        [-1.3340, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08467848598957062
Epoch 0, Step 556: train/loss = 0.4972434937953949, train/raw-loss = 0.39374127984046936, train/logprobs = tensor([[-1.2865, -3.0437],
        [-1.3114, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350218415260315
Epoch 0, Step 557: train/loss = 0.5748099088668823, train/raw-loss = 0.5041816234588623, train/logprobs = tensor([[-0.7302, -2.0476],
        [-0.6233, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07062830775976181
Epoch 0, Step 558: train/loss = 0.6604026556015015, train/raw-loss = 0.5868589878082275, train/logprobs = tensor([[-1.4416, -1.5788],
        [-1.3113, -0.9048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07354371249675751
Epoch 0, Step 559: train/loss = 0.5401914715766907, train/raw-loss = 0.46181055903434753, train/logprobs = tensor([[-0.8184, -2.6319],
        [-0.8244, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07838091254234314
Epoch 0, Step 560: train/loss = 0.6591243743896484, train/raw-loss = 0.5879257917404175, train/logprobs = tensor([[-1.0555, -1.8676],
        [-0.8185, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07119855284690857
Epoch 0, Step 561: train/loss = 0.5963917374610901, train/raw-loss = 0.5049687623977661, train/logprobs = tensor([[-1.4705, -2.4622],
        [-1.2652, -1.1970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09142296761274338
Epoch 0, Step 562: train/loss = 0.713300347328186, train/raw-loss = 0.6447782516479492, train/logprobs = tensor([[-1.0606, -1.8040],
        [-1.0013, -1.5299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06852209568023682
Epoch 0, Step 563: train/loss = 0.6012100577354431, train/raw-loss = 0.5256751179695129, train/logprobs = tensor([[-1.4574, -2.6863],
        [-1.0605, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07553496956825256
Epoch 0, Step 564: train/loss = 0.6650221943855286, train/raw-loss = 0.5886412858963013, train/logprobs = tensor([[-1.1113, -1.3957],
        [-0.9472, -0.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07638086378574371
Epoch 0, Step 565: train/loss = 0.585817277431488, train/raw-loss = 0.5221771001815796, train/logprobs = tensor([[-1.0088, -2.2960],
        [-0.8108, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06364013999700546
Epoch 0, Step 566: train/loss = 0.5341580510139465, train/raw-loss = 0.46138831973075867, train/logprobs = tensor([[-1.0506, -2.7060],
        [-0.8097, -0.9921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276973873376846
Epoch 0, Step 567: train/loss = 0.5480648875236511, train/raw-loss = 0.4740968942642212, train/logprobs = tensor([[-0.9180, -2.9779],
        [-0.5743, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07396800071001053
Epoch 0, Step 568: train/loss = 0.4823680520057678, train/raw-loss = 0.40426668524742126, train/logprobs = tensor([[-1.2366, -3.3231],
        [-1.0831, -1.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07810135930776596
Epoch 0, Step 569: train/loss = 0.5251651406288147, train/raw-loss = 0.42930495738983154, train/logprobs = tensor([[-1.5693, -3.4110],
        [-1.3850, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09586017578840256
Epoch 0, Step 570: train/loss = 0.623586893081665, train/raw-loss = 0.5514167547225952, train/logprobs = tensor([[-1.3005, -2.3590],
        [-1.0701, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0721702054142952
Epoch 0, Step 571: train/loss = 0.5656448006629944, train/raw-loss = 0.49332183599472046, train/logprobs = tensor([[-1.3286, -2.7861],
        [-1.2022, -1.4023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07232296466827393
Epoch 0, Step 572: train/loss = 0.5364221334457397, train/raw-loss = 0.4528253674507141, train/logprobs = tensor([[-1.0215, -3.3965],
        [-0.9207, -1.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0835968405008316
Epoch 0, Step 573: train/loss = 0.602070152759552, train/raw-loss = 0.5279208421707153, train/logprobs = tensor([[-1.6377, -3.4954],
        [-1.0607, -1.5679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414936274290085
Epoch 0, Step 574: train/loss = 0.6179080009460449, train/raw-loss = 0.544007420539856, train/logprobs = tensor([[-1.0212, -1.8845],
        [-0.8591, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390059530735016
Epoch 0, Step 575: train/loss = 0.5228121280670166, train/raw-loss = 0.44705769419670105, train/logprobs = tensor([[-0.9763, -2.8441],
        [-0.9286, -1.2919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07575441896915436
Epoch 0, Step 576: train/loss = 0.6241562366485596, train/raw-loss = 0.5547628402709961, train/logprobs = tensor([[-0.8801, -1.5498],
        [-0.8422, -0.8083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06939337402582169
Epoch 0, Step 577: train/loss = 0.4886743426322937, train/raw-loss = 0.39781415462493896, train/logprobs = tensor([[-1.4621, -3.4332],
        [-1.5428, -1.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09086016565561295
Epoch 0, Step 578: train/loss = 0.6171485781669617, train/raw-loss = 0.531624436378479, train/logprobs = tensor([[-1.3401, -2.5489],
        [-1.0743, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08552411198616028
Epoch 0, Step 579: train/loss = 0.5864855647087097, train/raw-loss = 0.5176092386245728, train/logprobs = tensor([[-0.7684, -1.8066],
        [-0.6277, -0.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06887634843587875
Epoch 0, Step 580: train/loss = 0.6522181034088135, train/raw-loss = 0.5726931691169739, train/logprobs = tensor([[-1.0691, -1.9931],
        [-0.8290, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07952495664358139
Epoch 0, Step 581: train/loss = 0.46892398595809937, train/raw-loss = 0.3953567147254944, train/logprobs = tensor([[-0.5495, -3.9426],
        [-0.4436, -1.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07356728613376617
Epoch 0, Step 582: train/loss = 0.5997476577758789, train/raw-loss = 0.5172683596611023, train/logprobs = tensor([[-1.2904, -2.2759],
        [-1.0647, -1.1133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247929066419601
Epoch 0, Step 583: train/loss = 0.5452309250831604, train/raw-loss = 0.4622260630130768, train/logprobs = tensor([[-0.8573, -3.0878],
        [-0.7603, -1.6498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08300484716892242
Epoch 0, Step 584: train/loss = 0.5674205422401428, train/raw-loss = 0.4871327877044678, train/logprobs = tensor([[-1.2647, -2.5736],
        [-1.1895, -1.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08028775453567505
Epoch 0, Step 585: train/loss = 0.5561707019805908, train/raw-loss = 0.49048277735710144, train/logprobs = tensor([[-0.6303, -2.4998],
        [-0.5985, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06568794697523117
Epoch 0, Step 586: train/loss = 0.6579358577728271, train/raw-loss = 0.5848346948623657, train/logprobs = tensor([[-1.8920, -1.4711],
        [-1.6943, -0.7197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07310117781162262
Epoch 0, Step 587: train/loss = 0.6516348719596863, train/raw-loss = 0.5797736048698425, train/logprobs = tensor([[-0.6653, -1.4699],
        [-0.5153, -0.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07186128199100494
Epoch 0, Step 588: train/loss = 0.577608048915863, train/raw-loss = 0.5047140717506409, train/logprobs = tensor([[-1.2665, -2.2282],
        [-1.1486, -1.0233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07289403676986694
Epoch 0, Step 589: train/loss = 0.8204960227012634, train/raw-loss = 0.7590317726135254, train/logprobs = tensor([[-1.8429, -2.3446],
        [-0.7912, -0.8829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06146426498889923
Epoch 0, Step 590: train/loss = 0.6204818487167358, train/raw-loss = 0.5395559072494507, train/logprobs = tensor([[-1.2435, -2.5923],
        [-0.9229, -1.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809258371591568
Epoch 0, Step 591: train/loss = 0.564423680305481, train/raw-loss = 0.4782184958457947, train/logprobs = tensor([[-1.0965, -2.1302],
        [-1.0454, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08620519936084747
Epoch 0, Step 592: train/loss = 0.6490779519081116, train/raw-loss = 0.5754326581954956, train/logprobs = tensor([[-1.7763, -1.9357],
        [-1.4124, -0.7541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07364532351493835
Epoch 0, Step 593: train/loss = 0.5004522204399109, train/raw-loss = 0.4241340160369873, train/logprobs = tensor([[-1.2182, -3.3055],
        [-1.1009, -1.3310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07631824165582657
Epoch 0, Step 594: train/loss = 0.6748189926147461, train/raw-loss = 0.5991746187210083, train/logprobs = tensor([[-0.8842, -1.5427],
        [-0.7233, -0.8806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07564437389373779
Epoch 0, Step 595: train/loss = 0.610919713973999, train/raw-loss = 0.5261632800102234, train/logprobs = tensor([[-1.2361, -2.2247],
        [-0.9591, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475638180971146
Epoch 0, Step 596: train/loss = 0.5788800716400146, train/raw-loss = 0.4989964962005615, train/logprobs = tensor([[-0.8820, -2.1119],
        [-0.7795, -0.7883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07988356053829193
Epoch 0, Step 597: train/loss = 0.5081080198287964, train/raw-loss = 0.4297063648700714, train/logprobs = tensor([[-0.8309, -2.6342],
        [-0.7229, -0.7930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07840166985988617
Epoch 0, Step 598: train/loss = 0.5410996675491333, train/raw-loss = 0.46885454654693604, train/logprobs = tensor([[-0.7879, -2.3732],
        [-0.7539, -0.9614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07224509865045547
Epoch 0, Step 599: train/loss = 0.48377281427383423, train/raw-loss = 0.388194739818573, train/logprobs = tensor([[-1.0557, -3.0868],
        [-0.9945, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09557810425758362
Epoch 0, Step 600: train/loss = 0.6240649819374084, train/raw-loss = 0.5381412506103516, train/logprobs = tensor([[-1.1212, -1.7600],
        [-1.0529, -0.8082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08592377603054047
Epoch 0, Step 601: train/loss = 0.5963456034660339, train/raw-loss = 0.5191001892089844, train/logprobs = tensor([[-1.0784, -2.2906],
        [-0.9144, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07724542915821075
Epoch 0, Step 602: train/loss = 0.6060647368431091, train/raw-loss = 0.5266609191894531, train/logprobs = tensor([[-1.2385, -2.1083],
        [-0.9583, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07940378785133362
Epoch 0, Step 603: train/loss = 0.5545191764831543, train/raw-loss = 0.4761578142642975, train/logprobs = tensor([[-0.7605, -2.6088],
        [-0.6315, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0783613994717598
Epoch 0, Step 604: train/loss = 0.45724987983703613, train/raw-loss = 0.3707437515258789, train/logprobs = tensor([[-0.9671, -4.3311],
        [-0.9966, -1.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08650612831115723
Epoch 0, Step 605: train/loss = 0.5727062225341797, train/raw-loss = 0.4878383278846741, train/logprobs = tensor([[-1.0369, -2.4653],
        [-0.8391, -0.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08486786484718323
Epoch 0, Step 606: train/loss = 0.5521665811538696, train/raw-loss = 0.46879488229751587, train/logprobs = tensor([[-1.2996, -2.6090],
        [-1.2823, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08337172120809555
Epoch 0, Step 607: train/loss = 0.5279399752616882, train/raw-loss = 0.4489821195602417, train/logprobs = tensor([[-1.2557, -2.4911],
        [-1.2426, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07895784080028534
Epoch 0, Step 608: train/loss = 0.5250155925750732, train/raw-loss = 0.4468650221824646, train/logprobs = tensor([[-1.0629, -3.1832],
        [-1.0026, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07815058529376984
Epoch 0, Step 609: train/loss = 0.545526921749115, train/raw-loss = 0.4582040011882782, train/logprobs = tensor([[-1.3049, -2.7680],
        [-1.2600, -0.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08732288330793381
Epoch 0, Step 610: train/loss = 0.6017885804176331, train/raw-loss = 0.5340605974197388, train/logprobs = tensor([[-1.0594, -2.6606],
        [-0.7617, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0677279680967331
Epoch 0, Step 611: train/loss = 0.656346321105957, train/raw-loss = 0.5809285044670105, train/logprobs = tensor([[-1.1350, -1.6083],
        [-0.9925, -0.8870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07541777938604355
Epoch 0, Step 612: train/loss = 0.6031287312507629, train/raw-loss = 0.5260167717933655, train/logprobs = tensor([[-1.3252, -2.3533],
        [-0.9832, -0.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711195945739746
Epoch 0, Step 613: train/loss = 0.5227198600769043, train/raw-loss = 0.44100257754325867, train/logprobs = tensor([[-1.0149, -3.8524],
        [-0.5757, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08171731233596802
Epoch 0, Step 614: train/loss = 0.5833712816238403, train/raw-loss = 0.4994763433933258, train/logprobs = tensor([[-1.1034, -2.8182],
        [-0.8291, -1.3783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08389489352703094
Epoch 0, Step 615: train/loss = 0.5582217574119568, train/raw-loss = 0.49183762073516846, train/logprobs = tensor([[-0.6614, -2.1355],
        [-0.5039, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06638415902853012
Epoch 0, Step 616: train/loss = 0.5730102062225342, train/raw-loss = 0.480702668428421, train/logprobs = tensor([[-1.8041, -4.0333],
        [-1.4449, -2.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09230746328830719
Epoch 0, Step 617: train/loss = 0.583909809589386, train/raw-loss = 0.505061686038971, train/logprobs = tensor([[-0.8458, -1.9782],
        [-0.7344, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07884809374809265
Epoch 0, Step 618: train/loss = 0.5422556400299072, train/raw-loss = 0.4711480140686035, train/logprobs = tensor([[-0.9280, -2.7535],
        [-0.7031, -0.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0711076483130455
Epoch 0, Step 619: train/loss = 0.7920452952384949, train/raw-loss = 0.7158175110816956, train/logprobs = tensor([[-2.0929, -3.0929],
        [-0.8701, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07622770220041275
Epoch 0, Step 620: train/loss = 0.5800442695617676, train/raw-loss = 0.49399226903915405, train/logprobs = tensor([[-0.9332, -1.9739],
        [-0.8663, -0.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08605202287435532
Epoch 0, Step 621: train/loss = 0.5193077325820923, train/raw-loss = 0.43216872215270996, train/logprobs = tensor([[-1.5487, -3.1386],
        [-1.3930, -1.0309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0871390551328659
Epoch 0, Step 622: train/loss = 0.5698480606079102, train/raw-loss = 0.48983803391456604, train/logprobs = tensor([[-0.9367, -2.6595],
        [-0.7746, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08001001179218292
Epoch 0, Step 623: train/loss = 0.5357604026794434, train/raw-loss = 0.45388710498809814, train/logprobs = tensor([[-2.5485, -4.7916],
        [-2.2399, -2.0801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08187329769134521
Epoch 0, Step 624: train/loss = 0.5964515209197998, train/raw-loss = 0.5155251026153564, train/logprobs = tensor([[-1.0854, -1.8105],
        [-1.0032, -0.7017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08092644065618515
Epoch 0, Step 625: train/loss = 0.5461488366127014, train/raw-loss = 0.4430844783782959, train/logprobs = tensor([[-0.9803, -2.1057],
        [-1.3094, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10306437313556671
Epoch 0, Step 626: train/loss = 0.5589582324028015, train/raw-loss = 0.4688165783882141, train/logprobs = tensor([[-1.3269, -3.0704],
        [-1.1514, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09014163911342621
Epoch 0, Step 627: train/loss = 0.5838272571563721, train/raw-loss = 0.5132765769958496, train/logprobs = tensor([[-0.7692, -2.1504],
        [-0.6296, -0.8089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07055070996284485
Epoch 0, Step 628: train/loss = 0.554936945438385, train/raw-loss = 0.47708430886268616, train/logprobs = tensor([[-1.1114, -3.0927],
        [-0.7764, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07785266637802124
Epoch 0, Step 629: train/loss = 0.5539814233779907, train/raw-loss = 0.4641028642654419, train/logprobs = tensor([[-1.2028, -2.5323],
        [-0.9915, -0.7777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987859636545181
Epoch 0, Step 630: train/loss = 0.4422006607055664, train/raw-loss = 0.3612273931503296, train/logprobs = tensor([[-0.8265, -3.5247],
        [-0.7420, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08097327500581741
Epoch 0, Step 631: train/loss = 0.6720942258834839, train/raw-loss = 0.6034495234489441, train/logprobs = tensor([[-0.8481, -1.2527],
        [-0.6405, -0.5880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06864473223686218
Epoch 0, Step 632: train/loss = 0.6039341688156128, train/raw-loss = 0.5338301062583923, train/logprobs = tensor([[-0.9287, -2.0515],
        [-0.7686, -0.9571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07010409235954285
Epoch 0, Step 633: train/loss = 0.526680588722229, train/raw-loss = 0.44242191314697266, train/logprobs = tensor([[-0.8340, -3.0248],
        [-0.6465, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08425864577293396
Epoch 0, Step 634: train/loss = 0.5198723077774048, train/raw-loss = 0.4356476068496704, train/logprobs = tensor([[-1.3245, -2.6907],
        [-1.2988, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08422470092773438
Epoch 0, Step 635: train/loss = 0.6011611819267273, train/raw-loss = 0.5188255310058594, train/logprobs = tensor([[-1.1000, -2.2197],
        [-1.0174, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08233562111854553
Epoch 0, Step 636: train/loss = 0.5826374292373657, train/raw-loss = 0.4896697998046875, train/logprobs = tensor([[-1.4311, -2.2264],
        [-1.2727, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09296762198209763
Epoch 0, Step 637: train/loss = 0.6018843054771423, train/raw-loss = 0.5228633880615234, train/logprobs = tensor([[-1.1983, -1.8793],
        [-1.2549, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0790209174156189
Epoch 0, Step 638: train/loss = 0.6105520129203796, train/raw-loss = 0.5462908744812012, train/logprobs = tensor([[-1.0010, -2.0272],
        [-0.9200, -0.8054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06426116824150085
Epoch 0, Step 639: train/loss = 0.6270028948783875, train/raw-loss = 0.556198239326477, train/logprobs = tensor([[-1.2793, -1.7700],
        [-1.0486, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07080461829900742
Epoch 0, Step 640: train/loss = 0.5139998197555542, train/raw-loss = 0.43934857845306396, train/logprobs = tensor([[-0.7494, -2.7739],
        [-0.6249, -0.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07465128600597382
Epoch 0, Step 641: train/loss = 0.5670275092124939, train/raw-loss = 0.49068498611450195, train/logprobs = tensor([[-0.9378, -2.6126],
        [-1.0647, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07634249329566956
Epoch 0, Step 642: train/loss = 0.6524102687835693, train/raw-loss = 0.5968896746635437, train/logprobs = tensor([[-0.7872, -1.7328],
        [-0.6062, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055520616471767426
Epoch 0, Step 643: train/loss = 0.6538400650024414, train/raw-loss = 0.5686031579971313, train/logprobs = tensor([[-0.9121, -1.8562],
        [-0.8402, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08523688465356827
Epoch 0, Step 644: train/loss = 0.4695308208465576, train/raw-loss = 0.38039082288742065, train/logprobs = tensor([[-1.2781, -3.3508],
        [-1.3574, -1.3026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08914001286029816
Epoch 0, Step 645: train/loss = 0.6782853603363037, train/raw-loss = 0.6113353967666626, train/logprobs = tensor([[-1.0522, -1.6174],
        [-0.7954, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06695005297660828
Epoch 0, Step 646: train/loss = 0.5498466491699219, train/raw-loss = 0.47077780961990356, train/logprobs = tensor([[-1.0735, -2.4351],
        [-0.9688, -1.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906881719827652
Epoch 0, Step 647: train/loss = 0.5494914054870605, train/raw-loss = 0.44341444969177246, train/logprobs = tensor([[-1.1980, -2.1825],
        [-1.3460, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607696324586868
Epoch 0, Step 648: train/loss = 0.5184105038642883, train/raw-loss = 0.44761770963668823, train/logprobs = tensor([[-0.8765, -2.8817],
        [-0.6018, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0707927793264389
Epoch 0, Step 649: train/loss = 0.6475850343704224, train/raw-loss = 0.5818382501602173, train/logprobs = tensor([[-0.7776, -1.6107],
        [-0.6737, -0.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06574678421020508
Epoch 0, Step 650: train/loss = 0.682022213935852, train/raw-loss = 0.605614185333252, train/logprobs = tensor([[-1.4932, -2.1793],
        [-1.1501, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07640798389911652
Epoch 0, Step 651: train/loss = 0.5486756563186646, train/raw-loss = 0.4690098762512207, train/logprobs = tensor([[-1.4928, -2.0496],
        [-1.4710, -0.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07966574281454086
Epoch 0, Step 652: train/loss = 0.5359343886375427, train/raw-loss = 0.46559417247772217, train/logprobs = tensor([[-0.9236, -2.6789],
        [-0.6614, -0.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07034017145633698
Epoch 0, Step 653: train/loss = 0.6468544006347656, train/raw-loss = 0.5827810168266296, train/logprobs = tensor([[-0.8126, -1.4986],
        [-0.5696, -0.6162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06407333165407181
Epoch 0, Step 654: train/loss = 0.557542085647583, train/raw-loss = 0.48486924171447754, train/logprobs = tensor([[-0.9232, -2.0024],
        [-0.8536, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07267287373542786
Epoch 0, Step 655: train/loss = 0.4682064354419708, train/raw-loss = 0.37979650497436523, train/logprobs = tensor([[-0.9879, -2.9405],
        [-1.0768, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08840993791818619
Epoch 0, Step 656: train/loss = 0.6279264688491821, train/raw-loss = 0.5620380640029907, train/logprobs = tensor([[-0.7771, -1.9639],
        [-0.5691, -0.9935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06588844954967499
Epoch 0, Step 657: train/loss = 0.5984318256378174, train/raw-loss = 0.5382696390151978, train/logprobs = tensor([[-1.0380, -1.7069],
        [-0.8249, -0.6336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060162268579006195
Epoch 0, Step 658: train/loss = 0.5798485279083252, train/raw-loss = 0.499289870262146, train/logprobs = tensor([[-0.8698, -1.5815],
        [-0.9764, -0.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0805586576461792
Epoch 0, Step 659: train/loss = 0.4558316767215729, train/raw-loss = 0.37618541717529297, train/logprobs = tensor([[-0.9163, -4.8391],
        [-0.9955, -1.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796462669968605
Epoch 0, Step 660: train/loss = 0.576148271560669, train/raw-loss = 0.4988519847393036, train/logprobs = tensor([[-1.1035, -2.9590],
        [-0.7887, -1.2174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07729624211788177
Epoch 0, Step 661: train/loss = 0.4811061918735504, train/raw-loss = 0.3873181939125061, train/logprobs = tensor([[-1.1026, -2.7211],
        [-1.4202, -1.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09378799796104431
Epoch 0, Step 662: train/loss = 0.5103051662445068, train/raw-loss = 0.4317963123321533, train/logprobs = tensor([[-0.8296, -2.6076],
        [-0.8682, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0785088986158371
Epoch 0, Step 663: train/loss = 0.5500296950340271, train/raw-loss = 0.4678384065628052, train/logprobs = tensor([[-1.0674, -2.2490],
        [-0.9905, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08219125121831894
Epoch 0, Step 664: train/loss = 0.4713674783706665, train/raw-loss = 0.3739747405052185, train/logprobs = tensor([[-1.3148, -3.6392],
        [-1.4203, -1.7221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0973927453160286
Epoch 0, Step 665: train/loss = 0.5141879916191101, train/raw-loss = 0.43487292528152466, train/logprobs = tensor([[-1.0261, -2.7312],
        [-0.9220, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07931508868932724
Epoch 0, Step 666: train/loss = 0.491720974445343, train/raw-loss = 0.40163397789001465, train/logprobs = tensor([[-1.1831, -2.7534],
        [-1.2183, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09008698910474777
Epoch 0, Step 667: train/loss = 0.582991361618042, train/raw-loss = 0.5167118906974792, train/logprobs = tensor([[-1.0288, -1.6409],
        [-0.9557, -0.5245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06627947092056274
Epoch 0, Step 668: train/loss = 0.504949688911438, train/raw-loss = 0.4114820957183838, train/logprobs = tensor([[-1.1334, -2.9227],
        [-1.0776, -0.9499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0934676006436348
Epoch 0, Step 669: train/loss = 0.46806779503822327, train/raw-loss = 0.3824177086353302, train/logprobs = tensor([[-0.9499, -3.4187],
        [-0.8719, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08565010875463486
Epoch 0, Step 670: train/loss = 0.6873177289962769, train/raw-loss = 0.6041582226753235, train/logprobs = tensor([[-1.2913, -1.6528],
        [-0.9719, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08315948396921158
Epoch 0, Step 671: train/loss = 0.7131637334823608, train/raw-loss = 0.6427920460700989, train/logprobs = tensor([[-1.0516, -1.7140],
        [-0.6823, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07037167996168137
Epoch 0, Step 672: train/loss = 0.5833219289779663, train/raw-loss = 0.5031497478485107, train/logprobs = tensor([[-1.2497, -2.5502],
        [-0.9002, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08017215132713318
Epoch 0, Step 673: train/loss = 0.552587628364563, train/raw-loss = 0.4799063205718994, train/logprobs = tensor([[-1.1206, -2.8772],
        [-0.8700, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07268130779266357
Epoch 0, Step 674: train/loss = 0.5007331371307373, train/raw-loss = 0.4189351499080658, train/logprobs = tensor([[-1.1629, -3.3753],
        [-1.1162, -1.3875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08179796487092972
Epoch 0, Step 675: train/loss = 0.5534102320671082, train/raw-loss = 0.4886610209941864, train/logprobs = tensor([[-0.8435, -2.5762],
        [-0.7404, -1.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06474921852350235
Epoch 0, Step 676: train/loss = 0.5159611105918884, train/raw-loss = 0.4459518790245056, train/logprobs = tensor([[-1.2170, -2.6070],
        [-1.1452, -1.0290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0700092613697052
Epoch 0, Step 677: train/loss = 0.43162769079208374, train/raw-loss = 0.3444083333015442, train/logprobs = tensor([[-1.0728, -3.6621],
        [-1.2900, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08721933513879776
Epoch 0, Step 678: train/loss = 0.46945711970329285, train/raw-loss = 0.38482677936553955, train/logprobs = tensor([[-1.4225, -3.5052],
        [-1.2606, -0.9559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08463035523891449
Epoch 0, Step 679: train/loss = 0.6098324060440063, train/raw-loss = 0.5431292057037354, train/logprobs = tensor([[-1.1062, -1.5126],
        [-1.1064, -0.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06670316308736801
Epoch 0, Step 680: train/loss = 0.5567426681518555, train/raw-loss = 0.47723478078842163, train/logprobs = tensor([[-1.6751, -2.6582],
        [-1.6944, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07950787991285324
Epoch 0, Step 681: train/loss = 0.5666408538818359, train/raw-loss = 0.5009610056877136, train/logprobs = tensor([[-0.8492, -2.7125],
        [-0.6338, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06567986309528351
Epoch 0, Step 682: train/loss = 0.4322233200073242, train/raw-loss = 0.3470638394355774, train/logprobs = tensor([[-1.2100, -3.8211],
        [-1.2976, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515951037406921
Epoch 0, Step 683: train/loss = 0.613162100315094, train/raw-loss = 0.5279897451400757, train/logprobs = tensor([[-1.8026, -2.4646],
        [-1.5903, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08517234027385712
Epoch 0, Step 684: train/loss = 0.5618575215339661, train/raw-loss = 0.490766704082489, train/logprobs = tensor([[-0.9255, -2.0730],
        [-0.8692, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109078764915466
Epoch 0, Step 685: train/loss = 0.546500027179718, train/raw-loss = 0.46941864490509033, train/logprobs = tensor([[-1.1142, -2.7130],
        [-0.9872, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770813524723053
Epoch 0, Step 686: train/loss = 0.569211483001709, train/raw-loss = 0.5075111389160156, train/logprobs = tensor([[-0.7928, -2.3387],
        [-0.6344, -0.8627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061700399965047836
Epoch 0, Step 687: train/loss = 0.6004089117050171, train/raw-loss = 0.5214013457298279, train/logprobs = tensor([[-1.1131, -2.0902],
        [-1.2879, -1.3610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07900761067867279
Epoch 0, Step 688: train/loss = 0.5132142305374146, train/raw-loss = 0.4335489273071289, train/logprobs = tensor([[-1.2549, -3.3249],
        [-0.9979, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07966534048318863
Epoch 0, Step 689: train/loss = 0.5816770792007446, train/raw-loss = 0.5203186273574829, train/logprobs = tensor([[-0.7007, -2.1853],
        [-0.5024, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06135842204093933
Epoch 0, Step 690: train/loss = 0.5470762252807617, train/raw-loss = 0.46359869837760925, train/logprobs = tensor([[-1.0809, -2.4456],
        [-0.9717, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08347752690315247
Epoch 0, Step 691: train/loss = 0.5014477372169495, train/raw-loss = 0.436542809009552, train/logprobs = tensor([[-0.8246, -2.9338],
        [-0.6234, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06490490585565567
Epoch 0, Step 692: train/loss = 0.5524703860282898, train/raw-loss = 0.46658462285995483, train/logprobs = tensor([[-0.8921, -2.1281],
        [-0.9966, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08588572591543198
Epoch 0, Step 693: train/loss = 0.5515826940536499, train/raw-loss = 0.46670764684677124, train/logprobs = tensor([[-1.3523, -3.5730],
        [-1.2634, -1.1628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08487508445978165
Epoch 0, Step 694: train/loss = 0.5377057790756226, train/raw-loss = 0.4473717212677002, train/logprobs = tensor([[-1.3064, -3.1569],
        [-1.1248, -1.1870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09033405780792236
Epoch 0, Step 695: train/loss = 0.5433716177940369, train/raw-loss = 0.46227627992630005, train/logprobs = tensor([[-1.0229, -3.0271],
        [-0.8288, -0.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081095390021801
Epoch 0, Step 696: train/loss = 0.523047685623169, train/raw-loss = 0.4510110020637512, train/logprobs = tensor([[-0.9549, -2.8954],
        [-0.6657, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07203667610883713
Epoch 0, Step 697: train/loss = 0.5291350483894348, train/raw-loss = 0.43045201897621155, train/logprobs = tensor([[-1.0289, -2.8976],
        [-1.1390, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868307411670685
Epoch 0, Step 698: train/loss = 0.5626093149185181, train/raw-loss = 0.4838765263557434, train/logprobs = tensor([[-1.2794, -3.2894],
        [-0.9510, -1.2571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07873281091451645
Epoch 0, Step 699: train/loss = 0.574661135673523, train/raw-loss = 0.5032263398170471, train/logprobs = tensor([[-1.0962, -2.5260],
        [-0.8737, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07143476605415344
Epoch 0, Step 700: train/loss = 0.5273900032043457, train/raw-loss = 0.4626612961292267, train/logprobs = tensor([[-0.6530, -2.7828],
        [-0.5386, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0647287368774414
Epoch 0, Step 701: train/loss = 0.5469512939453125, train/raw-loss = 0.47553694248199463, train/logprobs = tensor([[-0.9328, -2.1567],
        [-1.1107, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07141437381505966
Epoch 0, Step 702: train/loss = 0.5183005928993225, train/raw-loss = 0.43265748023986816, train/logprobs = tensor([[-1.5350, -2.5661],
        [-1.6418, -1.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08564312011003494
Epoch 0, Step 703: train/loss = 0.5400950312614441, train/raw-loss = 0.46125638484954834, train/logprobs = tensor([[-1.4852, -3.4817],
        [-1.0985, -1.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07883863151073456
Epoch 0, Step 704: train/loss = 0.48824745416641235, train/raw-loss = 0.42063623666763306, train/logprobs = tensor([[-0.8954, -3.3311],
        [-0.9174, -1.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0676112100481987
Epoch 0, Step 705: train/loss = 0.7147538661956787, train/raw-loss = 0.6364060640335083, train/logprobs = tensor([[-1.1500, -2.1146],
        [-1.0970, -1.7748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07834780216217041
Epoch 0, Step 706: train/loss = 0.506704568862915, train/raw-loss = 0.438775897026062, train/logprobs = tensor([[-1.0881, -3.5037],
        [-0.9517, -1.5248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06792868673801422
Epoch 0, Step 707: train/loss = 0.6306556463241577, train/raw-loss = 0.5663615465164185, train/logprobs = tensor([[-1.2085, -2.0778],
        [-0.9580, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06429410725831985
Epoch 0, Step 708: train/loss = 0.6607747077941895, train/raw-loss = 0.5955617427825928, train/logprobs = tensor([[-0.8354, -1.4077],
        [-0.9531, -0.9930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06521301716566086
Epoch 0, Step 709: train/loss = 0.5880066752433777, train/raw-loss = 0.5284579396247864, train/logprobs = tensor([[-0.7027, -1.9141],
        [-0.6036, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059548720717430115
Epoch 0, Step 710: train/loss = 0.5423626899719238, train/raw-loss = 0.4688154458999634, train/logprobs = tensor([[-0.5983, -2.6786],
        [-0.4705, -0.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07354727387428284
Epoch 0, Step 711: train/loss = 0.5415999293327332, train/raw-loss = 0.47176793217658997, train/logprobs = tensor([[-1.4885, -2.5431],
        [-1.6551, -1.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0698319673538208
Epoch 0, Step 712: train/loss = 0.5215409994125366, train/raw-loss = 0.4539671242237091, train/logprobs = tensor([[-0.7236, -3.0575],
        [-0.5714, -1.3165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06757389008998871
Epoch 0, Step 713: train/loss = 0.5348725318908691, train/raw-loss = 0.46783217787742615, train/logprobs = tensor([[-0.7838, -2.8341],
        [-0.6105, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670403391122818
Epoch 0, Step 714: train/loss = 0.6300976276397705, train/raw-loss = 0.5735834836959839, train/logprobs = tensor([[-0.8722, -1.3475],
        [-0.7890, -0.6402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05651421099901199
Epoch 0, Step 715: train/loss = 0.6665300130844116, train/raw-loss = 0.6013273000717163, train/logprobs = tensor([[-0.9168, -1.2156],
        [-1.0600, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06520266085863113
Epoch 0, Step 716: train/loss = 0.5183486938476562, train/raw-loss = 0.4481022357940674, train/logprobs = tensor([[-1.1225, -3.4763],
        [-1.1994, -1.5042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07024645060300827
Epoch 0, Step 717: train/loss = 0.475604385137558, train/raw-loss = 0.3946256935596466, train/logprobs = tensor([[-1.1280, -3.1801],
        [-1.3065, -1.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08097870647907257
Epoch 0, Step 718: train/loss = 0.5307812690734863, train/raw-loss = 0.4630734622478485, train/logprobs = tensor([[-1.7961, -5.0899],
        [-1.6228, -2.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06770777702331543
Epoch 0, Step 719: train/loss = 0.6384180784225464, train/raw-loss = 0.5816841125488281, train/logprobs = tensor([[-0.9516, -1.1448],
        [-1.0699, -0.7378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05673392862081528
Epoch 0, Step 720: train/loss = 0.617957353591919, train/raw-loss = 0.5594049096107483, train/logprobs = tensor([[-0.8166, -2.0510],
        [-0.6581, -1.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058552443981170654
Epoch 0, Step 721: train/loss = 0.5858591198921204, train/raw-loss = 0.5156134366989136, train/logprobs = tensor([[-1.2088, -2.3332],
        [-1.0436, -0.9245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0702456533908844
Epoch 0, Step 722: train/loss = 0.5817161798477173, train/raw-loss = 0.5107781887054443, train/logprobs = tensor([[-0.7924, -2.7329],
        [-0.6618, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07093808054924011
Epoch 0, Step 723: train/loss = 0.6016045808792114, train/raw-loss = 0.51860111951828, train/logprobs = tensor([[-1.3946, -2.9571],
        [-0.9689, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0830034613609314
Epoch 0, Step 724: train/loss = 0.5599059462547302, train/raw-loss = 0.4978368282318115, train/logprobs = tensor([[-0.8756, -2.4533],
        [-0.8822, -1.3959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062069110572338104
Epoch 0, Step 725: train/loss = 0.6281054019927979, train/raw-loss = 0.5548604726791382, train/logprobs = tensor([[-1.1485, -1.9225],
        [-1.1806, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07324491441249847
Epoch 0, Step 726: train/loss = 0.5370444059371948, train/raw-loss = 0.4666830599308014, train/logprobs = tensor([[-0.9419, -2.3908],
        [-1.1246, -0.7082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07036137580871582
Epoch 0, Step 727: train/loss = 0.6032384037971497, train/raw-loss = 0.5466654300689697, train/logprobs = tensor([[-0.7487, -1.8765],
        [-0.6299, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05657295882701874
Epoch 0, Step 728: train/loss = 0.6029173135757446, train/raw-loss = 0.5368083715438843, train/logprobs = tensor([[-1.3131, -2.4045],
        [-1.2655, -1.3916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06610889732837677
Epoch 0, Step 729: train/loss = 0.4662875533103943, train/raw-loss = 0.39496323466300964, train/logprobs = tensor([[-0.8763, -3.8088],
        [-0.8677, -1.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07132429629564285
Epoch 0, Step 730: train/loss = 0.5139696598052979, train/raw-loss = 0.42990314960479736, train/logprobs = tensor([[-1.3362, -2.1667],
        [-1.7892, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840664878487587
Epoch 0, Step 731: train/loss = 0.5817918181419373, train/raw-loss = 0.5151287317276001, train/logprobs = tensor([[-1.8543, -2.2033],
        [-1.7506, -1.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06666313111782074
Epoch 0, Step 732: train/loss = 0.4344286024570465, train/raw-loss = 0.33745232224464417, train/logprobs = tensor([[-1.3538, -2.7782],
        [-1.9218, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09697628021240234
Epoch 0, Step 733: train/loss = 0.4675072431564331, train/raw-loss = 0.3896505832672119, train/logprobs = tensor([[-0.9694, -3.0080],
        [-1.0921, -1.3880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07785665988922119
Epoch 0, Step 734: train/loss = 0.6442067623138428, train/raw-loss = 0.5820983052253723, train/logprobs = tensor([[-1.2834, -1.7803],
        [-1.0419, -0.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06210845708847046
Epoch 0, Step 735: train/loss = 0.7312743663787842, train/raw-loss = 0.6727670431137085, train/logprobs = tensor([[-1.7394, -1.4722],
        [-1.4033, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058507341891527176
Epoch 0, Step 736: train/loss = 0.4049683213233948, train/raw-loss = 0.32324859499931335, train/logprobs = tensor([[-1.1869, -4.2499],
        [-1.7308, -2.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08171970397233963
Epoch 0, Step 737: train/loss = 0.6015273332595825, train/raw-loss = 0.5240563750267029, train/logprobs = tensor([[-1.2711, -2.3093],
        [-1.4137, -1.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07747098058462143
Epoch 0, Step 738: train/loss = 0.40990737080574036, train/raw-loss = 0.3342028260231018, train/logprobs = tensor([[-0.9392, -4.1839],
        [-1.1342, -1.9461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07570452988147736
Epoch 0, Step 739: train/loss = 0.5289992094039917, train/raw-loss = 0.46657678484916687, train/logprobs = tensor([[-1.3704, -4.8266],
        [-1.1059, -2.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06242244318127632
Epoch 0, Step 740: train/loss = 0.5732012987136841, train/raw-loss = 0.5149129629135132, train/logprobs = tensor([[-0.6410, -2.6206],
        [-0.5774, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05828831344842911
Epoch 0, Step 741: train/loss = 0.49813711643218994, train/raw-loss = 0.42245709896087646, train/logprobs = tensor([[-1.2801, -3.1134],
        [-1.2302, -1.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756799727678299
Epoch 0, Step 742: train/loss = 0.5581807494163513, train/raw-loss = 0.5019634962081909, train/logprobs = tensor([[-0.7276, -2.5479],
        [-0.5338, -0.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056217264384031296
Epoch 0, Step 743: train/loss = 0.5909204483032227, train/raw-loss = 0.5276627540588379, train/logprobs = tensor([[-0.8960, -2.4574],
        [-0.9002, -1.4774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06325764209032059
Epoch 0, Step 744: train/loss = 0.59770667552948, train/raw-loss = 0.5259876251220703, train/logprobs = tensor([[-0.9845, -2.8220],
        [-1.0128, -2.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07171899080276489
Epoch 0, Step 745: train/loss = 0.4301314949989319, train/raw-loss = 0.3463747203350067, train/logprobs = tensor([[-0.8795, -3.6763],
        [-1.1284, -1.7649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08375677466392517
Epoch 0, Step 746: train/loss = 0.5542351603507996, train/raw-loss = 0.5058999061584473, train/logprobs = tensor([[-0.6494, -3.5652],
        [-0.5901, -1.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048335254192352295
Epoch 0, Step 747: train/loss = 0.6174560785293579, train/raw-loss = 0.547484815120697, train/logprobs = tensor([[-1.1288, -1.5160],
        [-1.2824, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0699712485074997
Epoch 0, Step 748: train/loss = 0.5628064274787903, train/raw-loss = 0.4868801236152649, train/logprobs = tensor([[-1.1932, -2.8815],
        [-1.3628, -1.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07592631876468658
Epoch 0, Step 749: train/loss = 0.59559166431427, train/raw-loss = 0.511465847492218, train/logprobs = tensor([[-1.2631, -2.0860],
        [-1.4877, -1.3455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0841258317232132
Epoch 0, Step 750: train/loss = 0.5891835689544678, train/raw-loss = 0.5207889676094055, train/logprobs = tensor([[-1.2377, -2.6945],
        [-1.1400, -1.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06839457899332047
Epoch 0, Step 751: train/loss = 0.5581331253051758, train/raw-loss = 0.494428813457489, train/logprobs = tensor([[-1.0517, -2.6073],
        [-1.1268, -1.4995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06370429694652557
Epoch 0, Step 752: train/loss = 0.6353719830513, train/raw-loss = 0.5830646753311157, train/logprobs = tensor([[-0.6574, -1.6493],
        [-0.5824, -0.8010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05230724811553955
Epoch 0, Step 753: train/loss = 0.506759524345398, train/raw-loss = 0.4355130195617676, train/logprobs = tensor([[-0.8414, -2.4299],
        [-0.9548, -1.1992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07124653458595276
Epoch 0, Step 754: train/loss = 0.5700778961181641, train/raw-loss = 0.5015978813171387, train/logprobs = tensor([[-1.0025, -2.8298],
        [-0.9157, -1.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06848004460334778
Epoch 0, Step 755: train/loss = 0.47724682092666626, train/raw-loss = 0.3924737572669983, train/logprobs = tensor([[-1.3316, -4.6539],
        [-1.6676, -2.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08477306365966797
Epoch 0, Step 756: train/loss = 0.5160884857177734, train/raw-loss = 0.4380815625190735, train/logprobs = tensor([[-1.0461, -3.2393],
        [-1.4507, -1.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07800698280334473
Epoch 0, Step 757: train/loss = 0.4877350330352783, train/raw-loss = 0.4037664532661438, train/logprobs = tensor([[-1.2973, -3.7569],
        [-1.5127, -2.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08396857976913452
Epoch 0, Step 758: train/loss = 0.6151021122932434, train/raw-loss = 0.5506859421730042, train/logprobs = tensor([[-1.0035, -2.0459],
        [-0.7428, -0.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06441621482372284
Epoch 0, Step 759: train/loss = 0.5224181413650513, train/raw-loss = 0.4312230348587036, train/logprobs = tensor([[-1.3697, -2.9857],
        [-1.7508, -1.6163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09119515120983124
Epoch 0, Step 760: train/loss = 0.4294407069683075, train/raw-loss = 0.3473077416419983, train/logprobs = tensor([[-1.4504, -4.4083],
        [-1.6050, -1.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08213293552398682
Epoch 0, Step 761: train/loss = 0.5386647582054138, train/raw-loss = 0.4600178003311157, train/logprobs = tensor([[-1.0767, -2.2004],
        [-1.2116, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07864688336849213
Epoch 0, Step 762: train/loss = 0.5241477489471436, train/raw-loss = 0.45512503385543823, train/logprobs = tensor([[-1.3911, -3.1236],
        [-1.3739, -1.8232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06902265548706055
Epoch 0, Step 763: train/loss = 0.6430799961090088, train/raw-loss = 0.5771582722663879, train/logprobs = tensor([[-0.7944, -1.2917],
        [-0.8716, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06592168658971786
Epoch 0, Step 764: train/loss = 0.5219562649726868, train/raw-loss = 0.43231555819511414, train/logprobs = tensor([[-1.0482, -2.6972],
        [-1.3760, -1.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08964069932699203
Epoch 0, Step 765: train/loss = 0.4551471471786499, train/raw-loss = 0.3808284401893616, train/logprobs = tensor([[-0.9122, -4.0769],
        [-0.9495, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07431870698928833
Epoch 0, Step 766: train/loss = 0.5596177577972412, train/raw-loss = 0.4767362177371979, train/logprobs = tensor([[-0.9626, -2.6314],
        [-1.2948, -1.6701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08288154751062393
Epoch 0, Step 767: train/loss = 0.6725813150405884, train/raw-loss = 0.5935033559799194, train/logprobs = tensor([[-1.0558, -2.0546],
        [-1.1938, -1.5711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07907796651124954
Epoch 0, Step 768: train/loss = 0.5263004899024963, train/raw-loss = 0.4558829665184021, train/logprobs = tensor([[-1.0562, -1.9490],
        [-1.1590, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07041753828525543
Epoch 0, Step 769: train/loss = 0.59888756275177, train/raw-loss = 0.5440100431442261, train/logprobs = tensor([[-1.0289, -2.4744],
        [-0.9164, -1.5209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05487757548689842
Epoch 0, Step 770: train/loss = 0.6438360214233398, train/raw-loss = 0.5906473398208618, train/logprobs = tensor([[-0.7327, -1.3786],
        [-0.6295, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05318865925073624
Epoch 0, Step 771: train/loss = 0.4824220538139343, train/raw-loss = 0.41364383697509766, train/logprobs = tensor([[-1.1494, -3.1088],
        [-1.1820, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06877822428941727
Epoch 0, Step 772: train/loss = 0.5113995671272278, train/raw-loss = 0.437039852142334, train/logprobs = tensor([[-1.0038, -2.5773],
        [-1.2521, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0743597149848938
Epoch 0, Step 773: train/loss = 0.630580723285675, train/raw-loss = 0.557354211807251, train/logprobs = tensor([[-1.5229, -2.1267],
        [-1.3865, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07322648912668228
Epoch 0, Step 774: train/loss = 0.5510414838790894, train/raw-loss = 0.47713953256607056, train/logprobs = tensor([[-1.3882, -2.9584],
        [-1.5572, -1.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390196621417999
Epoch 0, Step 775: train/loss = 0.48900023102760315, train/raw-loss = 0.4214246869087219, train/logprobs = tensor([[-0.9395, -3.1437],
        [-1.0391, -1.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06757558882236481
Epoch 0, Step 776: train/loss = 0.4786157011985779, train/raw-loss = 0.40291306376457214, train/logprobs = tensor([[-1.0316, -3.6349],
        [-1.4065, -2.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07570266723632812
Epoch 0, Step 777: train/loss = 0.5740252137184143, train/raw-loss = 0.499612957239151, train/logprobs = tensor([[-1.1628, -3.5082],
        [-1.3770, -1.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0744122639298439
Epoch 0, Step 778: train/loss = 0.5159561634063721, train/raw-loss = 0.4505511522293091, train/logprobs = tensor([[-1.0458, -2.5755],
        [-1.0920, -0.9894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0654049962759018
Epoch 0, Step 779: train/loss = 0.5341129899024963, train/raw-loss = 0.4573736786842346, train/logprobs = tensor([[-1.2772, -2.7775],
        [-1.6505, -1.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07673930376768112
Epoch 0, Step 780: train/loss = 0.5679767727851868, train/raw-loss = 0.5080881118774414, train/logprobs = tensor([[-0.9622, -2.3448],
        [-0.9014, -1.2848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059888679534196854
Epoch 0, Step 781: train/loss = 0.518149733543396, train/raw-loss = 0.43948495388031006, train/logprobs = tensor([[-1.3584, -3.0512],
        [-1.5482, -1.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07866478711366653
Epoch 0, Step 782: train/loss = 0.5016459226608276, train/raw-loss = 0.4465826451778412, train/logprobs = tensor([[-0.8236, -3.6713],
        [-0.7002, -1.4420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05506328120827675
Epoch 0, Step 783: train/loss = 0.6165134310722351, train/raw-loss = 0.5498619079589844, train/logprobs = tensor([[-0.8403, -1.6100],
        [-0.8309, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06665153056383133
Epoch 0, Step 784: train/loss = 0.5127580165863037, train/raw-loss = 0.4449687898159027, train/logprobs = tensor([[-0.8886, -3.1886],
        [-0.7769, -1.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06778921186923981
Epoch 0, Step 785: train/loss = 0.43106013536453247, train/raw-loss = 0.35336410999298096, train/logprobs = tensor([[-1.0220, -3.7678],
        [-1.0042, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07769600301980972
Epoch 0, Step 786: train/loss = 0.5113650560379028, train/raw-loss = 0.42602288722991943, train/logprobs = tensor([[-1.1441, -3.3259],
        [-1.4904, -2.0870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08534219861030579
Epoch 0, Step 787: train/loss = 0.5721848011016846, train/raw-loss = 0.5172602534294128, train/logprobs = tensor([[-0.7811, -3.0870],
        [-0.7021, -1.9774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054924555122852325
Epoch 0, Step 788: train/loss = 0.48033493757247925, train/raw-loss = 0.4203180968761444, train/logprobs = tensor([[-0.6210, -3.0467],
        [-0.7852, -1.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06001686304807663
Epoch 0, Step 789: train/loss = 0.5330771803855896, train/raw-loss = 0.45031505823135376, train/logprobs = tensor([[-1.1163, -1.9376],
        [-1.5688, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08276211470365524
Epoch 0, Step 790: train/loss = 0.5380154848098755, train/raw-loss = 0.4570404291152954, train/logprobs = tensor([[-1.1343, -2.3586],
        [-1.1915, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08097502589225769
Epoch 0, Step 791: train/loss = 0.5314347743988037, train/raw-loss = 0.4705464839935303, train/logprobs = tensor([[-1.0907, -2.1454],
        [-1.1830, -0.8846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060888297855854034
Epoch 0, Step 792: train/loss = 0.5594067573547363, train/raw-loss = 0.47350844740867615, train/logprobs = tensor([[-1.1418, -2.3222],
        [-1.7339, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08589830249547958
Epoch 0, Step 793: train/loss = 0.5102989673614502, train/raw-loss = 0.4386482238769531, train/logprobs = tensor([[-0.9976, -3.3889],
        [-1.2251, -1.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07165072858333588
Epoch 0, Step 794: train/loss = 0.5585171580314636, train/raw-loss = 0.4853947162628174, train/logprobs = tensor([[-0.9098, -2.9466],
        [-0.8871, -1.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07312241941690445
Epoch 0, Step 795: train/loss = 0.6583241820335388, train/raw-loss = 0.5972102880477905, train/logprobs = tensor([[-0.9284, -1.9919],
        [-0.9571, -1.5021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06111389398574829
Epoch 0, Step 796: train/loss = 0.537063717842102, train/raw-loss = 0.47152596712112427, train/logprobs = tensor([[-0.7557, -2.2141],
        [-0.8158, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06553776562213898
Epoch 0, Step 797: train/loss = 0.6235536932945251, train/raw-loss = 0.5489213466644287, train/logprobs = tensor([[-1.1269, -1.9848],
        [-1.2290, -1.3771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07463232427835464
Epoch 0, Step 798: train/loss = 0.6229702830314636, train/raw-loss = 0.5647056102752686, train/logprobs = tensor([[-1.0624, -1.6734],
        [-1.0220, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05826469510793686
Epoch 0, Step 799: train/loss = 0.5463765859603882, train/raw-loss = 0.48488637804985046, train/logprobs = tensor([[-0.9316, -3.0899],
        [-0.6481, -1.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06149020045995712
Epoch 0, Step 800: train/loss = 0.5702512264251709, train/raw-loss = 0.5024633407592773, train/logprobs = tensor([[-1.0451, -1.6250],
        [-1.3525, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06778784841299057
Epoch 0, Step 801: train/loss = 0.4613870680332184, train/raw-loss = 0.3933028280735016, train/logprobs = tensor([[-0.8671, -3.7292],
        [-0.8145, -1.4237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06808421015739441
Epoch 0, Step 802: train/loss = 0.5629717707633972, train/raw-loss = 0.48501116037368774, train/logprobs = tensor([[-1.3223, -3.0881],
        [-1.3413, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07796060293912888
Epoch 0, Step 803: train/loss = 0.635845422744751, train/raw-loss = 0.5823472738265991, train/logprobs = tensor([[-0.6649, -1.6534],
        [-0.5255, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053498201072216034
Epoch 0, Step 804: train/loss = 0.4865706264972687, train/raw-loss = 0.416886568069458, train/logprobs = tensor([[-0.8376, -3.1961],
        [-0.9708, -1.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06968406587839127
Epoch 0, Step 805: train/loss = 0.47320038080215454, train/raw-loss = 0.3995205760002136, train/logprobs = tensor([[-1.3624, -3.4110],
        [-1.4327, -1.7133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07367980480194092
Epoch 0, Step 806: train/loss = 0.48996657133102417, train/raw-loss = 0.4283217191696167, train/logprobs = tensor([[-1.0461, -2.7471],
        [-1.2754, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061644840985536575
Epoch 0, Step 807: train/loss = 0.4690619707107544, train/raw-loss = 0.402881920337677, train/logprobs = tensor([[-1.1188, -3.4976],
        [-1.5186, -1.3331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06618006527423859
Epoch 0, Step 808: train/loss = 0.6096186637878418, train/raw-loss = 0.5386528968811035, train/logprobs = tensor([[-1.3266, -2.8500],
        [-1.1995, -1.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07096575200557709
Epoch 0, Step 809: train/loss = 0.548435389995575, train/raw-loss = 0.4951273500919342, train/logprobs = tensor([[-0.8591, -2.7365],
        [-0.7078, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05330805107951164
Epoch 0, Step 810: train/loss = 0.5456268787384033, train/raw-loss = 0.4710131883621216, train/logprobs = tensor([[-0.8384, -3.0665],
        [-0.9587, -1.6664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07461372017860413
Epoch 0, Step 811: train/loss = 0.4771628975868225, train/raw-loss = 0.4103822112083435, train/logprobs = tensor([[-0.9643, -4.0861],
        [-0.9210, -1.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0667807012796402
Epoch 0, Step 812: train/loss = 0.5440975427627563, train/raw-loss = 0.46842753887176514, train/logprobs = tensor([[-1.4283, -3.7594],
        [-1.6904, -2.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756700336933136
Epoch 0, Step 813: train/loss = 0.4514821171760559, train/raw-loss = 0.38596224784851074, train/logprobs = tensor([[-1.0696, -3.6981],
        [-1.3587, -2.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06551989912986755
Epoch 0, Step 814: train/loss = 0.5318427681922913, train/raw-loss = 0.45952868461608887, train/logprobs = tensor([[-1.4551, -3.1629],
        [-1.4166, -1.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07231412082910538
Epoch 0, Step 815: train/loss = 0.49771279096603394, train/raw-loss = 0.4335898160934448, train/logprobs = tensor([[-1.0875, -3.5546],
        [-1.1541, -1.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06412295252084732
Epoch 0, Step 816: train/loss = 0.6214787364006042, train/raw-loss = 0.5544335246086121, train/logprobs = tensor([[-1.0391, -2.2838],
        [-1.0044, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06704524904489517
Epoch 0, Step 817: train/loss = 0.5305864810943604, train/raw-loss = 0.4656560719013214, train/logprobs = tensor([[-1.6041, -4.1177],
        [-1.4668, -1.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06493045389652252
Epoch 0, Step 818: train/loss = 0.503337025642395, train/raw-loss = 0.437616229057312, train/logprobs = tensor([[-0.8814, -3.0785],
        [-0.8843, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0657208040356636
Epoch 0, Step 819: train/loss = 0.6329872012138367, train/raw-loss = 0.5645231008529663, train/logprobs = tensor([[-1.7294, -3.2552],
        [-1.1960, -1.3309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06846404075622559
Epoch 0, Step 820: train/loss = 0.48499199748039246, train/raw-loss = 0.4125247001647949, train/logprobs = tensor([[-0.9572, -3.1257],
        [-1.1132, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07246728986501694
Epoch 0, Step 821: train/loss = 0.48270314931869507, train/raw-loss = 0.41223815083503723, train/logprobs = tensor([[-1.1810, -3.3143],
        [-1.3239, -1.6225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07046499103307724
Epoch 0, Step 822: train/loss = 0.5073142051696777, train/raw-loss = 0.442888468503952, train/logprobs = tensor([[-0.8762, -4.2141],
        [-0.7746, -1.6188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06442570686340332
Epoch 0, Step 823: train/loss = 0.6285864114761353, train/raw-loss = 0.5509527921676636, train/logprobs = tensor([[-1.0470, -1.5658],
        [-1.3227, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763361185789108
Epoch 0, Step 824: train/loss = 0.5063889026641846, train/raw-loss = 0.43188220262527466, train/logprobs = tensor([[-1.2514, -3.0150],
        [-1.3808, -1.2944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0745067447423935
Epoch 0, Step 825: train/loss = 0.6809152364730835, train/raw-loss = 0.6085430979728699, train/logprobs = tensor([[-1.3797, -2.0352],
        [-1.3420, -1.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0723721832036972
Epoch 0, Step 826: train/loss = 0.534245491027832, train/raw-loss = 0.4621288776397705, train/logprobs = tensor([[-1.3919, -2.6401],
        [-1.2711, -1.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07211659848690033
Epoch 0, Step 827: train/loss = 0.4233916699886322, train/raw-loss = 0.3444734811782837, train/logprobs = tensor([[-1.2253, -3.3032],
        [-1.6398, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07891818881034851
Epoch 0, Step 828: train/loss = 0.48905515670776367, train/raw-loss = 0.4202232360839844, train/logprobs = tensor([[-0.8824, -2.9023],
        [-0.9737, -1.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06883189082145691
Epoch 0, Step 829: train/loss = 0.5875900983810425, train/raw-loss = 0.5025956630706787, train/logprobs = tensor([[-0.9821, -2.0277],
        [-1.2721, -1.1662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499450981616974
Epoch 0, Step 830: train/loss = 0.49925538897514343, train/raw-loss = 0.4398139715194702, train/logprobs = tensor([[-0.8050, -2.5225],
        [-0.9190, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059441447257995605
Epoch 0, Step 831: train/loss = 0.5917626619338989, train/raw-loss = 0.5156099796295166, train/logprobs = tensor([[-1.5579, -2.3581],
        [-1.3453, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615271955728531
Epoch 0, Step 832: train/loss = 0.5266836285591125, train/raw-loss = 0.45519232749938965, train/logprobs = tensor([[-1.9060, -3.9829],
        [-1.5832, -1.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0714913010597229
Epoch 0, Step 833: train/loss = 0.5156460404396057, train/raw-loss = 0.44391337037086487, train/logprobs = tensor([[-1.1875, -2.3535],
        [-1.4979, -1.3698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07173267006874084
Epoch 0, Step 834: train/loss = 0.4809068441390991, train/raw-loss = 0.42099741101264954, train/logprobs = tensor([[-0.7708, -3.6197],
        [-0.7047, -1.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05990947037935257
Epoch 0, Step 835: train/loss = 0.5336955785751343, train/raw-loss = 0.4676274061203003, train/logprobs = tensor([[-0.9319, -2.4439],
        [-1.0012, -1.2858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06606820970773697
Epoch 0, Step 836: train/loss = 0.6274597644805908, train/raw-loss = 0.5469964742660522, train/logprobs = tensor([[-1.2175, -2.0861],
        [-1.3705, -1.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08046325296163559
Epoch 0, Step 837: train/loss = 0.5285463333129883, train/raw-loss = 0.466417521238327, train/logprobs = tensor([[-0.8639, -2.6667],
        [-0.7705, -1.0033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062128838151693344
Epoch 0, Step 838: train/loss = 0.47386157512664795, train/raw-loss = 0.4094647765159607, train/logprobs = tensor([[-1.3032, -4.9445],
        [-1.1959, -1.8930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06439680606126785
Epoch 0, Step 839: train/loss = 0.6146461963653564, train/raw-loss = 0.5457892417907715, train/logprobs = tensor([[-1.6701, -2.2826],
        [-1.9520, -1.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06885691732168198
Epoch 0, Step 840: train/loss = 0.5073974132537842, train/raw-loss = 0.4403839707374573, train/logprobs = tensor([[-1.4021, -4.2895],
        [-1.5502, -1.5918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0670134574174881
Epoch 0, Step 841: train/loss = 0.45691609382629395, train/raw-loss = 0.3900398313999176, train/logprobs = tensor([[-0.7102, -3.9396],
        [-0.6524, -1.5002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06687623262405396
Epoch 0, Step 842: train/loss = 0.38168638944625854, train/raw-loss = 0.3009456992149353, train/logprobs = tensor([[-1.1384, -3.1468],
        [-1.6802, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08074067533016205
Epoch 0, Step 843: train/loss = 0.45743250846862793, train/raw-loss = 0.3897162973880768, train/logprobs = tensor([[-0.6011, -4.1065],
        [-0.5826, -1.7465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06771624088287354
Epoch 0, Step 844: train/loss = 0.4476448595523834, train/raw-loss = 0.3710767924785614, train/logprobs = tensor([[-1.1740, -3.2684],
        [-1.4102, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07656807452440262
Epoch 0, Step 845: train/loss = 0.5151690244674683, train/raw-loss = 0.4458358883857727, train/logprobs = tensor([[-1.0957, -2.2490],
        [-1.5763, -0.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06933309882879257
Epoch 0, Step 846: train/loss = 0.5906475186347961, train/raw-loss = 0.5312073230743408, train/logprobs = tensor([[-1.3309, -2.4292],
        [-1.2670, -1.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05944023281335831
Epoch 0, Step 847: train/loss = 0.47305548191070557, train/raw-loss = 0.3954155743122101, train/logprobs = tensor([[-1.0804, -3.2257],
        [-1.1639, -1.3024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763992249965668
Epoch 0, Step 848: train/loss = 0.5283398628234863, train/raw-loss = 0.4705224931240082, train/logprobs = tensor([[-1.0230, -2.4469],
        [-0.9829, -1.1542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05781737342476845
Epoch 0, Step 849: train/loss = 0.6026472449302673, train/raw-loss = 0.542474627494812, train/logprobs = tensor([[-1.1809, -1.8793],
        [-1.1007, -0.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060172565281391144
Epoch 0, Step 850: train/loss = 0.5280437469482422, train/raw-loss = 0.46151286363601685, train/logprobs = tensor([[-1.6304, -3.4631],
        [-1.6967, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06653086096048355
Epoch 0, Step 851: train/loss = 0.5859513878822327, train/raw-loss = 0.5250558257102966, train/logprobs = tensor([[-0.9369, -1.8873],
        [-1.1171, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06089556962251663
Epoch 0, Step 852: train/loss = 0.4593620002269745, train/raw-loss = 0.38181227445602417, train/logprobs = tensor([[-1.3370, -2.8107],
        [-1.7498, -1.3492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07754971832036972
Epoch 0, Step 853: train/loss = 0.6496274471282959, train/raw-loss = 0.5882174968719482, train/logprobs = tensor([[-0.9386, -1.3522],
        [-0.8062, -0.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06140989810228348
Epoch 0, Step 854: train/loss = 0.6281628012657166, train/raw-loss = 0.5653366446495056, train/logprobs = tensor([[-1.0905, -2.8663],
        [-0.8594, -1.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06282614916563034
Epoch 0, Step 855: train/loss = 0.596277117729187, train/raw-loss = 0.5184547901153564, train/logprobs = tensor([[-1.3797, -2.3285],
        [-1.2974, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07782237976789474
Epoch 0, Step 856: train/loss = 0.514339804649353, train/raw-loss = 0.4551130533218384, train/logprobs = tensor([[-1.1747, -2.9066],
        [-1.0458, -1.2824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05922674387693405
Epoch 0, Step 857: train/loss = 0.4125491976737976, train/raw-loss = 0.3368353247642517, train/logprobs = tensor([[-1.0650, -4.4194],
        [-1.4213, -2.0762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0757138729095459
Epoch 0, Step 858: train/loss = 0.5482920408248901, train/raw-loss = 0.48891371488571167, train/logprobs = tensor([[-1.4380, -2.8607],
        [-1.4149, -1.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05937828868627548
Epoch 0, Step 859: train/loss = 0.5716748833656311, train/raw-loss = 0.5019674301147461, train/logprobs = tensor([[-1.3488, -4.0385],
        [-1.1060, -2.1978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.069707490503788
Epoch 0, Step 860: train/loss = 0.6909907460212708, train/raw-loss = 0.6381492018699646, train/logprobs = tensor([[-0.8900, -1.1251],
        [-0.9293, -0.8887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052841514348983765
Epoch 0, Step 861: train/loss = 0.4576180875301361, train/raw-loss = 0.39081519842147827, train/logprobs = tensor([[-0.8447, -3.1180],
        [-0.9471, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06680288910865784
Epoch 0, Step 862: train/loss = 0.5368907451629639, train/raw-loss = 0.4798777997493744, train/logprobs = tensor([[-1.1174, -2.2478],
        [-1.0596, -0.8951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057012930512428284
Epoch 0, Step 863: train/loss = 0.5188028812408447, train/raw-loss = 0.46170252561569214, train/logprobs = tensor([[-1.0971, -3.3832],
        [-0.8184, -1.6450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05710029602050781
Epoch 0, Step 864: train/loss = 0.528974175453186, train/raw-loss = 0.4513901472091675, train/logprobs = tensor([[-1.1666, -2.2507],
        [-1.3346, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07758400589227676
Epoch 0, Step 865: train/loss = 0.5602067708969116, train/raw-loss = 0.4996885359287262, train/logprobs = tensor([[-0.8910, -3.2423],
        [-0.9942, -1.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06051826849579811
Epoch 0, Step 866: train/loss = 0.4389954209327698, train/raw-loss = 0.3683566749095917, train/logprobs = tensor([[-1.4515, -2.7509],
        [-1.7473, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0706387609243393
Epoch 0, Step 867: train/loss = 0.53472501039505, train/raw-loss = 0.46692460775375366, train/logprobs = tensor([[-1.2649, -2.7388],
        [-1.2819, -1.3609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06780043989419937
Epoch 0, Step 868: train/loss = 0.537582516670227, train/raw-loss = 0.4746910333633423, train/logprobs = tensor([[-0.8781, -2.8652],
        [-0.8368, -1.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06289149075746536
Epoch 0, Step 869: train/loss = 0.40470653772354126, train/raw-loss = 0.3325401246547699, train/logprobs = tensor([[-0.9260, -4.2585],
        [-0.8917, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07216636836528778
Epoch 0, Step 870: train/loss = 0.6377208232879639, train/raw-loss = 0.566778302192688, train/logprobs = tensor([[-1.8123, -2.3987],
        [-1.4822, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07094253599643707
Epoch 0, Step 871: train/loss = 0.5995367765426636, train/raw-loss = 0.5301685333251953, train/logprobs = tensor([[-1.3239, -1.3173],
        [-1.5425, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06936821341514587
Epoch 0, Step 872: train/loss = 0.5017305016517639, train/raw-loss = 0.442333847284317, train/logprobs = tensor([[-0.6312, -3.5256],
        [-0.5947, -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0593966580927372
Epoch 0, Step 873: train/loss = 0.4657629728317261, train/raw-loss = 0.3879361152648926, train/logprobs = tensor([[-1.0550, -3.5849],
        [-1.0947, -1.5211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07782682776451111
Epoch 0, Step 874: train/loss = 0.6447896957397461, train/raw-loss = 0.5860673785209656, train/logprobs = tensor([[-0.9300, -1.8364],
        [-0.9150, -1.2598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05872230976819992
Epoch 0, Step 875: train/loss = 0.5158387422561646, train/raw-loss = 0.44424912333488464, train/logprobs = tensor([[-0.9237, -2.2524],
        [-1.1981, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07158956676721573
Epoch 0, Step 876: train/loss = 0.33946704864501953, train/raw-loss = 0.26483362913131714, train/logprobs = tensor([[-1.3075, -3.7241],
        [-1.9990, -1.5264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0746334046125412
Epoch 0, Step 877: train/loss = 0.6671792268753052, train/raw-loss = 0.6156395673751831, train/logprobs = tensor([[-0.7499, -1.2493],
        [-0.6455, -0.7760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051539648324251175
Epoch 0, Step 878: train/loss = 0.6151190400123596, train/raw-loss = 0.5407405495643616, train/logprobs = tensor([[-1.2844, -1.8193],
        [-1.2609, -0.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07437850534915924
Epoch 0, Step 879: train/loss = 0.5649436116218567, train/raw-loss = 0.4938497245311737, train/logprobs = tensor([[-0.7355, -2.0685],
        [-0.8286, -1.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07109392434358597
Epoch 0, Step 880: train/loss = 0.5265801548957825, train/raw-loss = 0.454782634973526, train/logprobs = tensor([[-1.1743, -3.0104],
        [-1.4889, -1.9363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07179756462574005
Epoch 0, Step 881: train/loss = 0.5550217628479004, train/raw-loss = 0.5006656646728516, train/logprobs = tensor([[-0.7196, -2.9588],
        [-0.5829, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05435613542795181
Epoch 0, Step 882: train/loss = 0.5301180481910706, train/raw-loss = 0.45732754468917847, train/logprobs = tensor([[-1.2139, -5.4488],
        [-1.3170, -2.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0727904662489891
Epoch 0, Step 883: train/loss = 0.4110183119773865, train/raw-loss = 0.3305317759513855, train/logprobs = tensor([[-0.7389, -3.8003],
        [-0.9262, -1.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08048653602600098
Epoch 0, Step 884: train/loss = 0.6772080063819885, train/raw-loss = 0.6191601753234863, train/logprobs = tensor([[-0.8644, -1.7629],
        [-0.6168, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058047857135534286
Epoch 0, Step 885: train/loss = 0.5183520317077637, train/raw-loss = 0.454318642616272, train/logprobs = tensor([[-0.8416, -2.9013],
        [-0.9834, -1.4604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0640333816409111
Epoch 0, Step 886: train/loss = 0.5003560781478882, train/raw-loss = 0.4241190552711487, train/logprobs = tensor([[-1.0082, -3.3200],
        [-1.2833, -1.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07623699307441711
Epoch 0, Step 887: train/loss = 0.4693763852119446, train/raw-loss = 0.39489662647247314, train/logprobs = tensor([[-1.7394, -3.2004],
        [-2.0213, -1.5682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07447974383831024
Epoch 0, Step 888: train/loss = 0.6350223422050476, train/raw-loss = 0.5734922885894775, train/logprobs = tensor([[-0.8114, -1.6885],
        [-0.7679, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06153002381324768
Epoch 0, Step 889: train/loss = 0.4420778751373291, train/raw-loss = 0.3601580858230591, train/logprobs = tensor([[-1.0830, -3.7737],
        [-1.2865, -1.4029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08191978186368942
Epoch 0, Step 890: train/loss = 0.5210505127906799, train/raw-loss = 0.449648916721344, train/logprobs = tensor([[-1.5692, -3.1354],
        [-1.7276, -1.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07140165567398071
Epoch 0, Step 891: train/loss = 0.47789430618286133, train/raw-loss = 0.4103873372077942, train/logprobs = tensor([[-1.0873, -3.1759],
        [-0.9415, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750696152448654
Epoch 0, Step 892: train/loss = 0.5130479335784912, train/raw-loss = 0.43095874786376953, train/logprobs = tensor([[-1.0967, -2.0311],
        [-1.6292, -1.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08208917081356049
Epoch 0, Step 893: train/loss = 0.5578223466873169, train/raw-loss = 0.48080185055732727, train/logprobs = tensor([[-0.9983, -2.2495],
        [-1.2820, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07702046632766724
Epoch 0, Step 894: train/loss = 0.5800366401672363, train/raw-loss = 0.510532796382904, train/logprobs = tensor([[-1.0818, -2.7106],
        [-1.0100, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06950387358665466
Epoch 0, Step 895: train/loss = 0.5311000347137451, train/raw-loss = 0.45462924242019653, train/logprobs = tensor([[-1.0136, -2.3368],
        [-1.2291, -1.3723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764707699418068
Epoch 0, Step 896: train/loss = 0.384235680103302, train/raw-loss = 0.29612448811531067, train/logprobs = tensor([[-1.2513, -4.6202],
        [-1.7368, -1.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08811121433973312
Epoch 0, Step 897: train/loss = 0.44210284948349, train/raw-loss = 0.37684935331344604, train/logprobs = tensor([[-1.0641, -3.0141],
        [-1.2336, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06525348126888275
Epoch 0, Step 898: train/loss = 0.48819103837013245, train/raw-loss = 0.4248732328414917, train/logprobs = tensor([[-1.5031, -4.3000],
        [-1.3378, -1.5853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06331777572631836
Epoch 0, Step 899: train/loss = 0.4408120810985565, train/raw-loss = 0.3665367364883423, train/logprobs = tensor([[-1.1754, -3.9971],
        [-1.3196, -1.3703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07427532970905304
Epoch 0, Step 900: train/loss = 0.4150206446647644, train/raw-loss = 0.3359469771385193, train/logprobs = tensor([[-1.2771, -4.2290],
        [-1.4775, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0790736973285675
Epoch 0, Step 901: train/loss = 0.3362194001674652, train/raw-loss = 0.2348637580871582, train/logprobs = tensor([[-1.2958, -3.7710],
        [-2.0131, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10135563462972641
Epoch 0, Step 902: train/loss = 0.4381198287010193, train/raw-loss = 0.3740289807319641, train/logprobs = tensor([[-0.7413, -2.9124],
        [-1.1654, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06409087032079697
Epoch 0, Step 903: train/loss = 0.4763316512107849, train/raw-loss = 0.4169538617134094, train/logprobs = tensor([[-1.0124, -3.3761],
        [-0.9968, -1.3511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05937771871685982
Epoch 0, Step 904: train/loss = 0.5970629453659058, train/raw-loss = 0.5266444683074951, train/logprobs = tensor([[-0.8186, -1.7315],
        [-0.7871, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07041844725608826
Epoch 0, Step 905: train/loss = 0.5622259378433228, train/raw-loss = 0.49421459436416626, train/logprobs = tensor([[-1.0004, -2.3257],
        [-1.0615, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0680113211274147
Epoch 0, Step 906: train/loss = 0.45945826172828674, train/raw-loss = 0.38714906573295593, train/logprobs = tensor([[-0.9220, -3.6644],
        [-1.0596, -1.3665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07230916619300842
Epoch 0, Step 907: train/loss = 0.5435796976089478, train/raw-loss = 0.474980890750885, train/logprobs = tensor([[-1.2406, -3.4097],
        [-1.0503, -1.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06859880685806274
Epoch 0, Step 908: train/loss = 0.46307551860809326, train/raw-loss = 0.3816792368888855, train/logprobs = tensor([[-1.2631, -2.2055],
        [-1.5915, -0.7654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08139628171920776
Epoch 0, Step 909: train/loss = 0.6078411340713501, train/raw-loss = 0.5341109037399292, train/logprobs = tensor([[-0.8333, -1.9714],
        [-0.9337, -1.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0737302303314209
Epoch 0, Step 910: train/loss = 0.5231233835220337, train/raw-loss = 0.43698036670684814, train/logprobs = tensor([[-1.0308, -2.5205],
        [-1.3492, -1.3530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08614298701286316
Epoch 0, Step 911: train/loss = 0.438180536031723, train/raw-loss = 0.3592168092727661, train/logprobs = tensor([[-1.7039, -3.6888],
        [-1.9833, -1.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0789637416601181
Epoch 0, Step 912: train/loss = 0.5490667223930359, train/raw-loss = 0.47018128633499146, train/logprobs = tensor([[-1.4178, -2.7731],
        [-1.3108, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07888542115688324
Epoch 0, Step 913: train/loss = 0.5534703731536865, train/raw-loss = 0.4907715618610382, train/logprobs = tensor([[-0.8026, -2.3872],
        [-0.7444, -0.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06269880384206772
Epoch 0, Step 914: train/loss = 0.5975345969200134, train/raw-loss = 0.5219067335128784, train/logprobs = tensor([[-1.2759, -1.9475],
        [-1.3973, -1.2248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562781125307083
Epoch 0, Step 915: train/loss = 0.620457649230957, train/raw-loss = 0.5634348392486572, train/logprobs = tensor([[-0.7861, -1.4113],
        [-0.7725, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05702272057533264
Epoch 0, Step 916: train/loss = 0.4501807391643524, train/raw-loss = 0.36438310146331787, train/logprobs = tensor([[-1.4581, -4.3358],
        [-1.6643, -1.3986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08579765260219574
Epoch 0, Step 917: train/loss = 0.4572902321815491, train/raw-loss = 0.38316071033477783, train/logprobs = tensor([[-0.9636, -2.3338],
        [-1.2745, -0.8633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07412949204444885
Epoch 0, Step 918: train/loss = 0.4907341003417969, train/raw-loss = 0.420298308134079, train/logprobs = tensor([[-1.2605, -2.9980],
        [-1.5428, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0704357922077179
Epoch 0, Step 919: train/loss = 0.540554404258728, train/raw-loss = 0.4614197015762329, train/logprobs = tensor([[-0.7659, -3.0590],
        [-1.1145, -1.7579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07913467288017273
Epoch 0, Step 920: train/loss = 0.47504299879074097, train/raw-loss = 0.40502193570137024, train/logprobs = tensor([[-1.2711, -5.2912],
        [-1.5578, -2.3143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07002107053995132
Epoch 0, Step 921: train/loss = 0.45865654945373535, train/raw-loss = 0.37863653898239136, train/logprobs = tensor([[-1.0371, -2.9746],
        [-1.2991, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800199881196022
Epoch 0, Step 922: train/loss = 0.6036869883537292, train/raw-loss = 0.5361558794975281, train/logprobs = tensor([[-0.9635, -1.9671],
        [-0.8917, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06753109395503998
Epoch 0, Step 923: train/loss = 0.535661518573761, train/raw-loss = 0.4519253671169281, train/logprobs = tensor([[-1.5463, -3.4816],
        [-1.9554, -1.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08373615145683289
Epoch 0, Step 924: train/loss = 0.5783563852310181, train/raw-loss = 0.5096268057823181, train/logprobs = tensor([[-0.8497, -2.7235],
        [-0.6940, -1.3552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06872954964637756
Epoch 0, Step 925: train/loss = 0.6481470465660095, train/raw-loss = 0.5893097519874573, train/logprobs = tensor([[-0.8720, -1.4951],
        [-0.7263, -0.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058837294578552246
Epoch 0, Step 926: train/loss = 0.5439151525497437, train/raw-loss = 0.4810439348220825, train/logprobs = tensor([[-1.1399, -4.0605],
        [-0.7809, -1.4105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06287120282649994
Epoch 0, Step 927: train/loss = 0.45412448048591614, train/raw-loss = 0.3715474009513855, train/logprobs = tensor([[-1.1020, -2.9607],
        [-1.3968, -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08257709443569183
Epoch 0, Step 928: train/loss = 0.4837917685508728, train/raw-loss = 0.40146246552467346, train/logprobs = tensor([[-1.1825, -2.5725],
        [-1.6282, -1.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08232930302619934
Epoch 0, Step 929: train/loss = 0.628348708152771, train/raw-loss = 0.5697054862976074, train/logprobs = tensor([[-0.4936, -1.5615],
        [-0.4840, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05864323303103447
Epoch 0, Step 930: train/loss = 0.5460530519485474, train/raw-loss = 0.47383639216423035, train/logprobs = tensor([[-1.0618, -2.8013],
        [-0.9656, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07221667468547821
Epoch 0, Step 931: train/loss = 0.573768138885498, train/raw-loss = 0.5057215690612793, train/logprobs = tensor([[-0.5816, -2.2304],
        [-0.5429, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06804654002189636
Epoch 0, Step 932: train/loss = 0.5603320598602295, train/raw-loss = 0.4826783537864685, train/logprobs = tensor([[-1.5095, -3.1383],
        [-1.6591, -1.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07765370607376099
Epoch 0, Step 933: train/loss = 0.6527291536331177, train/raw-loss = 0.588544487953186, train/logprobs = tensor([[-0.8367, -1.6566],
        [-0.7870, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06418462842702866
Epoch 0, Step 934: train/loss = 0.4333343505859375, train/raw-loss = 0.36195138096809387, train/logprobs = tensor([[-0.9582, -4.3408],
        [-0.9387, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07138298451900482
Epoch 0, Step 935: train/loss = 0.5389469861984253, train/raw-loss = 0.46501341462135315, train/logprobs = tensor([[-1.5347, -3.2113],
        [-1.3679, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07393355667591095
Epoch 0, Step 936: train/loss = 0.6162698864936829, train/raw-loss = 0.5603591203689575, train/logprobs = tensor([[-0.6821, -1.5083],
        [-0.5862, -0.7065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055910784751176834
Epoch 0, Step 937: train/loss = 0.5311670899391174, train/raw-loss = 0.4481264352798462, train/logprobs = tensor([[-1.1299, -2.6341],
        [-1.1769, -1.1392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08304065465927124
Epoch 0, Step 938: train/loss = 0.5798357725143433, train/raw-loss = 0.4921448528766632, train/logprobs = tensor([[-1.7945, -2.0902],
        [-2.1886, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08769088238477707
Epoch 0, Step 939: train/loss = 0.6915525794029236, train/raw-loss = 0.6286466121673584, train/logprobs = tensor([[-0.7462, -0.8905],
        [-0.8162, -0.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06290601938962936
Epoch 0, Step 940: train/loss = 0.5321898460388184, train/raw-loss = 0.46896007657051086, train/logprobs = tensor([[-0.9993, -2.1921],
        [-1.0661, -0.9261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06322977691888809
Epoch 0, Step 941: train/loss = 0.5698152780532837, train/raw-loss = 0.4964073896408081, train/logprobs = tensor([[-1.1783, -3.1626],
        [-1.5317, -2.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0734078586101532
Epoch 0, Step 942: train/loss = 0.5274467468261719, train/raw-loss = 0.4714266061782837, train/logprobs = tensor([[-0.5854, -2.4601],
        [-0.5050, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05602015554904938
Epoch 0, Step 943: train/loss = 0.5220366716384888, train/raw-loss = 0.45317062735557556, train/logprobs = tensor([[-0.9252, -2.7621],
        [-0.9248, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06886604428291321
Epoch 0, Step 944: train/loss = 0.4574006199836731, train/raw-loss = 0.38050952553749084, train/logprobs = tensor([[-0.8330, -3.4871],
        [-1.0246, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07689111679792404
Epoch 0, Step 945: train/loss = 0.5141252875328064, train/raw-loss = 0.4371325373649597, train/logprobs = tensor([[-1.0554, -3.0086],
        [-1.3292, -1.4368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07699272781610489
Epoch 0, Step 946: train/loss = 0.562842845916748, train/raw-loss = 0.4999585449695587, train/logprobs = tensor([[-0.7392, -2.2695],
        [-0.6351, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06288431584835052
Epoch 0, Step 947: train/loss = 0.40341299772262573, train/raw-loss = 0.32671529054641724, train/logprobs = tensor([[-1.0909, -3.4315],
        [-1.4071, -0.8914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07669767737388611
Epoch 0, Step 948: train/loss = 0.5453996062278748, train/raw-loss = 0.4856031835079193, train/logprobs = tensor([[-0.7134, -3.3860],
        [-0.6736, -1.2986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05979647859930992
Epoch 0, Step 949: train/loss = 0.4739213287830353, train/raw-loss = 0.3845130503177643, train/logprobs = tensor([[-1.8579, -4.3322],
        [-1.8089, -1.4552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08940824121236801
Epoch 0, Step 950: train/loss = 0.46298307180404663, train/raw-loss = 0.3886599838733673, train/logprobs = tensor([[-0.9313, -3.3964],
        [-1.1643, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07432309538125992
Epoch 0, Step 951: train/loss = 0.48874402046203613, train/raw-loss = 0.4276910126209259, train/logprobs = tensor([[-0.9587, -2.8371],
        [-0.9296, -1.1766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06105300039052963
Epoch 0, Step 952: train/loss = 0.4434092044830322, train/raw-loss = 0.3604108989238739, train/logprobs = tensor([[-1.2217, -4.0124],
        [-1.5378, -1.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08299831300973892
Epoch 0, Step 953: train/loss = 0.6185503005981445, train/raw-loss = 0.5421931743621826, train/logprobs = tensor([[-1.2480, -2.1295],
        [-1.3188, -1.2363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0763571560382843
Epoch 0, Step 954: train/loss = 0.5783801674842834, train/raw-loss = 0.5096070766448975, train/logprobs = tensor([[-1.2442, -2.8183],
        [-1.3948, -1.9737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06877311319112778
Epoch 0, Step 955: train/loss = 0.4480047821998596, train/raw-loss = 0.37148141860961914, train/logprobs = tensor([[-0.7922, -3.3814],
        [-0.7682, -0.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07652336359024048
Epoch 0, Step 956: train/loss = 0.4190509021282196, train/raw-loss = 0.3361733555793762, train/logprobs = tensor([[-1.0996, -4.6269],
        [-1.3565, -2.0731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08287754654884338
Epoch 0, Step 957: train/loss = 0.5516306161880493, train/raw-loss = 0.4749872088432312, train/logprobs = tensor([[-1.0442, -3.0537],
        [-0.9368, -1.0605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07664340734481812
Epoch 0, Step 958: train/loss = 0.5573187470436096, train/raw-loss = 0.4791465997695923, train/logprobs = tensor([[-1.1139, -1.8585],
        [-1.2743, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817213237285614
Epoch 0, Step 959: train/loss = 0.4700137972831726, train/raw-loss = 0.40842902660369873, train/logprobs = tensor([[-0.9427, -3.1907],
        [-0.9167, -0.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06158478558063507
Epoch 0, Step 960: train/loss = 0.5047363042831421, train/raw-loss = 0.43901342153549194, train/logprobs = tensor([[-0.7445, -3.1068],
        [-0.6418, -1.3691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06572286039590836
Epoch 0, Step 961: train/loss = 0.494242399930954, train/raw-loss = 0.412141889333725, train/logprobs = tensor([[-1.4607, -3.2032],
        [-1.4986, -1.2653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08210049569606781
Epoch 0, Step 962: train/loss = 0.4587495028972626, train/raw-loss = 0.3680724799633026, train/logprobs = tensor([[-1.1502, -3.0079],
        [-1.1858, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09067704528570175
Epoch 0, Step 963: train/loss = 0.6085717678070068, train/raw-loss = 0.5288249254226685, train/logprobs = tensor([[-1.2092, -1.7623],
        [-1.5757, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797467976808548
Epoch 0, Step 964: train/loss = 0.4732470214366913, train/raw-loss = 0.39834684133529663, train/logprobs = tensor([[-0.9746, -2.5275],
        [-1.3727, -1.1735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07490019500255585
Epoch 0, Step 965: train/loss = 0.32871782779693604, train/raw-loss = 0.2368479073047638, train/logprobs = tensor([[-1.1032, -4.7563],
        [-1.6337, -1.3944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09186993539333344
Epoch 0, Step 966: train/loss = 0.5989900827407837, train/raw-loss = 0.5011554956436157, train/logprobs = tensor([[-1.2920, -2.1192],
        [-1.7558, -1.5781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783455729484558
Epoch 0, Step 967: train/loss = 0.5397838950157166, train/raw-loss = 0.4764048755168915, train/logprobs = tensor([[-0.8648, -2.9701],
        [-0.5974, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06337901949882507
Epoch 0, Step 968: train/loss = 0.5718209743499756, train/raw-loss = 0.4879557192325592, train/logprobs = tensor([[-1.3730, -1.7399],
        [-1.5266, -0.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.083865225315094
Epoch 0, Step 969: train/loss = 0.5667901039123535, train/raw-loss = 0.5038769245147705, train/logprobs = tensor([[-0.6609, -2.1678],
        [-0.6898, -0.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06291325390338898
Epoch 0, Step 970: train/loss = 0.39977431297302246, train/raw-loss = 0.3281480073928833, train/logprobs = tensor([[-0.9144, -4.5687],
        [-0.8231, -1.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07162632793188095
Epoch 0, Step 971: train/loss = 0.4990275502204895, train/raw-loss = 0.420568585395813, train/logprobs = tensor([[-0.8355, -2.8506],
        [-0.8527, -0.7672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07845894992351532
Epoch 0, Step 972: train/loss = 0.47086578607559204, train/raw-loss = 0.38876259326934814, train/logprobs = tensor([[-1.4154, -3.5713],
        [-1.4246, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08210316300392151
Epoch 0, Step 973: train/loss = 0.5348180532455444, train/raw-loss = 0.45850181579589844, train/logprobs = tensor([[-1.0402, -2.8093],
        [-1.0549, -0.9476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07631625980138779
Epoch 0, Step 974: train/loss = 0.6847143769264221, train/raw-loss = 0.6165027618408203, train/logprobs = tensor([[-1.0188, -1.0395],
        [-0.9638, -0.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06821160018444061
Epoch 0, Step 975: train/loss = 0.6507066488265991, train/raw-loss = 0.580162525177002, train/logprobs = tensor([[-1.0735, -1.5007],
        [-1.1728, -0.9324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07054410874843597
Epoch 0, Step 976: train/loss = 0.48693597316741943, train/raw-loss = 0.4125165343284607, train/logprobs = tensor([[-1.0563, -3.4554],
        [-1.3271, -1.4362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07441943883895874
Epoch 0, Step 977: train/loss = 0.6556795239448547, train/raw-loss = 0.5932953357696533, train/logprobs = tensor([[-0.8762, -1.9588],
        [-0.7475, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06238415837287903
Epoch 0, Step 978: train/loss = 0.5675734877586365, train/raw-loss = 0.49718916416168213, train/logprobs = tensor([[-1.2529, -2.7227],
        [-1.1530, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07038429379463196
Epoch 0, Step 979: train/loss = 0.3830319046974182, train/raw-loss = 0.30153602361679077, train/logprobs = tensor([[-0.9645, -3.7630],
        [-1.1469, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08149583637714386
Epoch 0, Step 980: train/loss = 0.39224082231521606, train/raw-loss = 0.3048681616783142, train/logprobs = tensor([[-1.1244, -3.4892],
        [-1.4945, -1.2619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08737267553806305
Epoch 0, Step 981: train/loss = 0.5962592959403992, train/raw-loss = 0.5316368341445923, train/logprobs = tensor([[-1.2691, -2.2821],
        [-1.2240, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06462246924638748
Epoch 0, Step 982: train/loss = 0.5649591088294983, train/raw-loss = 0.49025747179985046, train/logprobs = tensor([[-1.2246, -3.2686],
        [-0.9872, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07470162212848663
Epoch 0, Step 983: train/loss = 0.42872434854507446, train/raw-loss = 0.34492164850234985, train/logprobs = tensor([[-1.5351, -5.9401],
        [-1.7005, -1.5280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08380269259214401
Epoch 0, Step 984: train/loss = 0.6818380355834961, train/raw-loss = 0.6143316626548767, train/logprobs = tensor([[-1.1128, -1.0667],
        [-1.3184, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06750643253326416
Epoch 0, Step 985: train/loss = 0.7020127773284912, train/raw-loss = 0.6271108984947205, train/logprobs = tensor([[-1.4533, -1.8056],
        [-1.5400, -1.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07490180432796478
Epoch 0, Step 986: train/loss = 0.5870697498321533, train/raw-loss = 0.50138920545578, train/logprobs = tensor([[-1.6080, -3.1204],
        [-2.0615, -1.7722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0856805220246315
Epoch 0, Step 987: train/loss = 0.6331957578659058, train/raw-loss = 0.5524448156356812, train/logprobs = tensor([[-1.5672, -2.4712],
        [-1.6568, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08075100183486938
Epoch 0, Step 988: train/loss = 0.4828100800514221, train/raw-loss = 0.402829110622406, train/logprobs = tensor([[-1.3088, -3.1678],
        [-1.5338, -1.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0799810141324997
Epoch 0, Step 989: train/loss = 0.48382943868637085, train/raw-loss = 0.4042767286300659, train/logprobs = tensor([[-0.9384, -4.3807],
        [-1.2168, -1.5082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07955270260572433
Epoch 0, Step 990: train/loss = 0.5791040658950806, train/raw-loss = 0.49774327874183655, train/logprobs = tensor([[-1.7436, -2.0187],
        [-1.9636, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08136078715324402
Epoch 0, Step 991: train/loss = 0.4000750184059143, train/raw-loss = 0.32919666171073914, train/logprobs = tensor([[-0.9983, -4.6074],
        [-1.2436, -1.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07087834179401398
Epoch 0, Step 992: train/loss = 0.5204964876174927, train/raw-loss = 0.43604838848114014, train/logprobs = tensor([[-0.9732, -3.3874],
        [-1.0498, -1.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08444806933403015
Epoch 0, Step 993: train/loss = 0.4808904528617859, train/raw-loss = 0.3789510130882263, train/logprobs = tensor([[-1.2861, -2.8848],
        [-2.0773, -1.4784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10193941742181778
Epoch 0, Step 994: train/loss = 0.5222066640853882, train/raw-loss = 0.4183098375797272, train/logprobs = tensor([[-1.6661, -3.1671],
        [-2.4930, -1.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389680415391922
Epoch 0, Step 995: train/loss = 0.44054192304611206, train/raw-loss = 0.3523491322994232, train/logprobs = tensor([[-0.9198, -3.6512],
        [-1.0558, -1.4885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08819282799959183
Epoch 0, Step 996: train/loss = 0.5327482223510742, train/raw-loss = 0.45088860392570496, train/logprobs = tensor([[-1.1566, -3.1279],
        [-0.8873, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08185964077711105
Epoch 0, Step 997: train/loss = 0.4817050099372864, train/raw-loss = 0.40708279609680176, train/logprobs = tensor([[-0.9150, -4.1479],
        [-0.8450, -1.4058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0746222585439682
Epoch 0, Step 998: train/loss = 0.5173255205154419, train/raw-loss = 0.440871000289917, train/logprobs = tensor([[-1.1008, -3.0982],
        [-1.1510, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764545202255249
Epoch 0, Step 999: train/loss = 0.616226851940155, train/raw-loss = 0.531279444694519, train/logprobs = tensor([[-1.4515, -2.0018],
        [-1.6460, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08494740724563599
eval/loss: 0.5076053738594055
Epoch 0, Step 1000: train/loss = 0.6144133806228638, train/raw-loss = 0.542875349521637, train/logprobs = tensor([[-1.1580, -1.4580],
        [-1.4057, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07153806835412979
Epoch 0, Step 1001: train/loss = 0.4213666319847107, train/raw-loss = 0.3303830027580261, train/logprobs = tensor([[-1.1274, -4.4053],
        [-1.4186, -2.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09098361432552338
Epoch 0, Step 1002: train/loss = 0.5617974996566772, train/raw-loss = 0.48471760749816895, train/logprobs = tensor([[-0.7722, -2.2429],
        [-0.7232, -0.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0770799070596695
Epoch 0, Step 1003: train/loss = 0.5943496823310852, train/raw-loss = 0.5218570232391357, train/logprobs = tensor([[-0.9831, -1.2889],
        [-1.3152, -0.7733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07249265909194946
Epoch 0, Step 1004: train/loss = 0.5242027044296265, train/raw-loss = 0.424813836812973, train/logprobs = tensor([[-1.3453, -2.5436],
        [-2.1017, -1.7539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09938884526491165
Epoch 0, Step 1005: train/loss = 0.4209393262863159, train/raw-loss = 0.33628860116004944, train/logprobs = tensor([[-0.8736, -4.6291],
        [-1.0195, -1.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08465069532394409
Epoch 0, Step 1006: train/loss = 0.7228538990020752, train/raw-loss = 0.6605395674705505, train/logprobs = tensor([[-0.6840, -0.6546],
        [-0.6309, -0.4580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06231437623500824
Epoch 0, Step 1007: train/loss = 0.41789764165878296, train/raw-loss = 0.32734113931655884, train/logprobs = tensor([[-1.6130, -2.9129],
        [-2.0226, -0.9172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09055650234222412
Epoch 0, Step 1008: train/loss = 0.6148248314857483, train/raw-loss = 0.5404335260391235, train/logprobs = tensor([[-1.0960, -1.7264],
        [-1.3976, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07439126074314117
Epoch 0, Step 1009: train/loss = 0.3239932954311371, train/raw-loss = 0.2396915853023529, train/logprobs = tensor([[-0.8589, -6.0312],
        [-1.2163, -1.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08430171757936478
Epoch 0, Step 1010: train/loss = 0.4136340022087097, train/raw-loss = 0.3146283030509949, train/logprobs = tensor([[-1.8453, -3.2176],
        [-2.2647, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09900563955307007
Epoch 0, Step 1011: train/loss = 0.4389909505844116, train/raw-loss = 0.3621365427970886, train/logprobs = tensor([[-1.1168, -4.4194],
        [-1.2407, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07685442268848419
Epoch 0, Step 1012: train/loss = 0.48174142837524414, train/raw-loss = 0.39570510387420654, train/logprobs = tensor([[-1.3482, -3.0838],
        [-1.7549, -1.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08603633940219879
Epoch 0, Step 1013: train/loss = 0.6357840299606323, train/raw-loss = 0.5556581616401672, train/logprobs = tensor([[-1.1087, -1.5535],
        [-1.1541, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08012579381465912
Epoch 0, Step 1014: train/loss = 0.5959478616714478, train/raw-loss = 0.5176391005516052, train/logprobs = tensor([[-1.2906, -2.3649],
        [-1.3377, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830874621868134
Epoch 0, Step 1015: train/loss = 0.3712412714958191, train/raw-loss = 0.28878548741340637, train/logprobs = tensor([[-1.4886, -6.4580],
        [-1.7960, -1.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245579898357391
Epoch 0, Step 1016: train/loss = 0.5131509304046631, train/raw-loss = 0.44368672370910645, train/logprobs = tensor([[-0.9591, -2.9213],
        [-1.0923, -1.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06946422159671783
Epoch 0, Step 1017: train/loss = 0.5759580731391907, train/raw-loss = 0.48112690448760986, train/logprobs = tensor([[-1.0281, -2.1713],
        [-1.1680, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09483117610216141
Epoch 0, Step 1018: train/loss = 0.41806560754776, train/raw-loss = 0.32940465211868286, train/logprobs = tensor([[-1.3268, -2.9916],
        [-1.6961, -0.7837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08866097033023834
Epoch 0, Step 1019: train/loss = 0.45783674716949463, train/raw-loss = 0.37781065702438354, train/logprobs = tensor([[-0.9448, -2.7665],
        [-1.3398, -0.8612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0800260677933693
Epoch 0, Step 1020: train/loss = 0.6947711110115051, train/raw-loss = 0.6203210949897766, train/logprobs = tensor([[-1.5541, -1.8568],
        [-1.3880, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07444998621940613
Epoch 0, Step 1021: train/loss = 0.5651000738143921, train/raw-loss = 0.49353012442588806, train/logprobs = tensor([[-0.8048, -1.9885],
        [-1.0311, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07156994938850403
Epoch 0, Step 1022: train/loss = 0.4589556157588959, train/raw-loss = 0.3827369511127472, train/logprobs = tensor([[-1.4612, -3.1022],
        [-1.6638, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0762186273932457
Epoch 0, Step 1023: train/loss = 0.5406814813613892, train/raw-loss = 0.46773287653923035, train/logprobs = tensor([[-1.2001, -3.2492],
        [-1.2774, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07294861227273941
Epoch 0, Step 1024: train/loss = 0.47754594683647156, train/raw-loss = 0.39659589529037476, train/logprobs = tensor([[-1.4268, -3.9071],
        [-1.4560, -1.4145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809500515460968
Epoch 0, Step 1025: train/loss = 0.5475854277610779, train/raw-loss = 0.4676818251609802, train/logprobs = tensor([[-1.2467, -2.4906],
        [-1.2388, -0.5999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07990359514951706
Epoch 0, Step 1026: train/loss = 0.5318456292152405, train/raw-loss = 0.451993852853775, train/logprobs = tensor([[-1.0727, -2.7637],
        [-1.0170, -1.0652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985173910856247
Epoch 0, Step 1027: train/loss = 0.6150345206260681, train/raw-loss = 0.5376376509666443, train/logprobs = tensor([[-2.2606, -4.3144],
        [-1.6430, -1.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07739688456058502
Epoch 0, Step 1028: train/loss = 0.5600720643997192, train/raw-loss = 0.4815639853477478, train/logprobs = tensor([[-0.9103, -2.9271],
        [-0.9928, -1.2014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07850811630487442
Epoch 0, Step 1029: train/loss = 0.5419235229492188, train/raw-loss = 0.45587629079818726, train/logprobs = tensor([[-1.5987, -1.9853],
        [-2.0298, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08604719489812851
Epoch 0, Step 1030: train/loss = 0.5795676112174988, train/raw-loss = 0.49922770261764526, train/logprobs = tensor([[-1.4273, -2.8238],
        [-1.8005, -1.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08033992350101471
Epoch 0, Step 1031: train/loss = 0.4476515054702759, train/raw-loss = 0.36931875348091125, train/logprobs = tensor([[-0.8958, -4.2798],
        [-0.9442, -1.0660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07833275943994522
Epoch 0, Step 1032: train/loss = 0.48803961277008057, train/raw-loss = 0.40077248215675354, train/logprobs = tensor([[-0.8816, -2.8701],
        [-1.1532, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08726711571216583
Epoch 0, Step 1033: train/loss = 0.5196498036384583, train/raw-loss = 0.4520193636417389, train/logprobs = tensor([[-0.9689, -3.8506],
        [-0.7651, -1.1535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06763043999671936
Epoch 0, Step 1034: train/loss = 0.47579532861709595, train/raw-loss = 0.3899749517440796, train/logprobs = tensor([[-1.2358, -2.8636],
        [-1.4948, -0.6950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08582036197185516
Epoch 0, Step 1035: train/loss = 0.4911487102508545, train/raw-loss = 0.41371145844459534, train/logprobs = tensor([[-0.8411, -2.5135],
        [-1.1707, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07743725180625916
Epoch 0, Step 1036: train/loss = 0.64844810962677, train/raw-loss = 0.579367995262146, train/logprobs = tensor([[-1.1700, -1.8972],
        [-0.8816, -0.9569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0690801665186882
Epoch 0, Step 1037: train/loss = 0.4824611246585846, train/raw-loss = 0.389562726020813, train/logprobs = tensor([[-1.1698, -2.4245],
        [-1.2702, -0.7708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928984060883522
Epoch 0, Step 1038: train/loss = 0.5770569443702698, train/raw-loss = 0.4961429238319397, train/logprobs = tensor([[-0.9107, -1.9456],
        [-0.8263, -0.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08091402053833008
Epoch 0, Step 1039: train/loss = 0.4314541816711426, train/raw-loss = 0.32918858528137207, train/logprobs = tensor([[-1.1343, -4.5014],
        [-1.6830, -1.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1022656038403511
Epoch 0, Step 1040: train/loss = 0.4289708733558655, train/raw-loss = 0.3557853698730469, train/logprobs = tensor([[-0.9412, -3.6108],
        [-1.1076, -1.1442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0731855034828186
Epoch 0, Step 1041: train/loss = 0.6154122352600098, train/raw-loss = 0.5225242376327515, train/logprobs = tensor([[-1.2780, -2.3124],
        [-1.7433, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09288804978132248
Epoch 0, Step 1042: train/loss = 0.534785807132721, train/raw-loss = 0.46947145462036133, train/logprobs = tensor([[-0.8574, -3.0438],
        [-0.7407, -1.0170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06531433016061783
Epoch 0, Step 1043: train/loss = 0.5753177404403687, train/raw-loss = 0.5003998279571533, train/logprobs = tensor([[-0.8748, -1.8374],
        [-1.1852, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07491788268089294
Epoch 0, Step 1044: train/loss = 0.5675767660140991, train/raw-loss = 0.49593278765678406, train/logprobs = tensor([[-0.7175, -2.2514],
        [-0.8180, -1.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07164399325847626
Epoch 0, Step 1045: train/loss = 0.5235856175422668, train/raw-loss = 0.4446467161178589, train/logprobs = tensor([[-1.1719, -3.3390],
        [-0.8113, -0.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07893891632556915
Epoch 0, Step 1046: train/loss = 0.5622643232345581, train/raw-loss = 0.48625749349594116, train/logprobs = tensor([[-0.9041, -2.4197],
        [-0.8181, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07600684463977814
Epoch 0, Step 1047: train/loss = 0.4939785599708557, train/raw-loss = 0.4068651497364044, train/logprobs = tensor([[-1.0872, -1.9758],
        [-1.5206, -0.8763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0871134102344513
Epoch 0, Step 1048: train/loss = 0.4903603792190552, train/raw-loss = 0.41843780875205994, train/logprobs = tensor([[-1.1169, -3.4753],
        [-1.0846, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07192257046699524
Epoch 0, Step 1049: train/loss = 0.3975849747657776, train/raw-loss = 0.3008209764957428, train/logprobs = tensor([[-0.8610, -3.9599],
        [-1.0465, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676402807235718
Epoch 0, Step 1050: train/loss = 0.5433307886123657, train/raw-loss = 0.4629087746143341, train/logprobs = tensor([[-0.8888, -2.1645],
        [-1.1997, -0.9981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0804220512509346
Epoch 0, Step 1051: train/loss = 0.5483269691467285, train/raw-loss = 0.46475332975387573, train/logprobs = tensor([[-1.1307, -3.8328],
        [-1.0702, -1.6504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08357364684343338
Epoch 0, Step 1052: train/loss = 0.505914032459259, train/raw-loss = 0.4258549213409424, train/logprobs = tensor([[-0.9313, -2.9412],
        [-0.9681, -1.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08005910366773605
Epoch 0, Step 1053: train/loss = 0.4632551968097687, train/raw-loss = 0.39414897561073303, train/logprobs = tensor([[-1.2702, -2.9532],
        [-1.3041, -1.0334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06910619139671326
Epoch 0, Step 1054: train/loss = 0.6007896661758423, train/raw-loss = 0.5337430834770203, train/logprobs = tensor([[-0.7154, -1.7472],
        [-0.7451, -0.8882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06704661250114441
Epoch 0, Step 1055: train/loss = 0.510808527469635, train/raw-loss = 0.4135814607143402, train/logprobs = tensor([[-1.2645, -2.2806],
        [-1.4887, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0972270593047142
Epoch 0, Step 1056: train/loss = 0.4289607107639313, train/raw-loss = 0.3458521366119385, train/logprobs = tensor([[-0.8954, -2.9446],
        [-1.0230, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08310859650373459
Epoch 0, Step 1057: train/loss = 0.5833687782287598, train/raw-loss = 0.5052071809768677, train/logprobs = tensor([[-1.2701, -3.8622],
        [-0.8153, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07816159725189209
Epoch 0, Step 1058: train/loss = 0.3840830326080322, train/raw-loss = 0.2955065071582794, train/logprobs = tensor([[-1.3162, -3.2099],
        [-2.0059, -1.2062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885765552520752
Epoch 0, Step 1059: train/loss = 0.49999165534973145, train/raw-loss = 0.4036255478858948, train/logprobs = tensor([[-1.2160, -2.3899],
        [-1.7161, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09636614471673965
Epoch 0, Step 1060: train/loss = 0.46120351552963257, train/raw-loss = 0.39062201976776123, train/logprobs = tensor([[-0.6724, -3.6147],
        [-0.7052, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07058148086071014
Epoch 0, Step 1061: train/loss = 0.546734094619751, train/raw-loss = 0.45544201135635376, train/logprobs = tensor([[-1.6873, -2.3734],
        [-1.9845, -1.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0912921130657196
Epoch 0, Step 1062: train/loss = 0.5555043816566467, train/raw-loss = 0.48113495111465454, train/logprobs = tensor([[-1.0026, -1.9200],
        [-1.4919, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07436944544315338
Epoch 0, Step 1063: train/loss = 0.5052106380462646, train/raw-loss = 0.4153022766113281, train/logprobs = tensor([[-1.1824, -3.1810],
        [-1.5840, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08990833908319473
Epoch 0, Step 1064: train/loss = 0.5180108547210693, train/raw-loss = 0.4331943988800049, train/logprobs = tensor([[-1.1147, -3.1271],
        [-0.8689, -0.8233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08481648564338684
Epoch 0, Step 1065: train/loss = 0.4766909182071686, train/raw-loss = 0.39596158266067505, train/logprobs = tensor([[-1.0233, -3.9149],
        [-1.1482, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08072931319475174
Epoch 0, Step 1066: train/loss = 0.3674112558364868, train/raw-loss = 0.29178857803344727, train/logprobs = tensor([[-1.1403, -5.4049],
        [-1.3589, -1.3360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07562267035245895
Epoch 0, Step 1067: train/loss = 0.5306461453437805, train/raw-loss = 0.45486608147621155, train/logprobs = tensor([[-0.8792, -3.2667],
        [-0.7742, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07578006386756897
Epoch 0, Step 1068: train/loss = 0.5757280588150024, train/raw-loss = 0.49720993638038635, train/logprobs = tensor([[-0.8765, -2.6122],
        [-0.9723, -1.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07851806282997131
Epoch 0, Step 1069: train/loss = 0.46366918087005615, train/raw-loss = 0.3732869029045105, train/logprobs = tensor([[-1.0767, -4.0084],
        [-1.2707, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09038227051496506
Epoch 0, Step 1070: train/loss = 0.4535277187824249, train/raw-loss = 0.35716918110847473, train/logprobs = tensor([[-0.8624, -3.5864],
        [-1.0787, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963585153222084
Epoch 0, Step 1071: train/loss = 0.5488110780715942, train/raw-loss = 0.45842260122299194, train/logprobs = tensor([[-1.7010, -4.0178],
        [-1.4450, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0903884693980217
Epoch 0, Step 1072: train/loss = 0.5633184909820557, train/raw-loss = 0.47295495867729187, train/logprobs = tensor([[-1.5073, -2.3575],
        [-1.6493, -0.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09036349505186081
Epoch 0, Step 1073: train/loss = 0.49409574270248413, train/raw-loss = 0.39287713170051575, train/logprobs = tensor([[-1.1047, -4.3669],
        [-1.3136, -1.2313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10121863335371017
Epoch 0, Step 1074: train/loss = 0.6687779426574707, train/raw-loss = 0.5897312164306641, train/logprobs = tensor([[-1.2936, -1.4828],
        [-1.2798, -0.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07904671132564545
Epoch 0, Step 1075: train/loss = 0.4313289523124695, train/raw-loss = 0.34785836935043335, train/logprobs = tensor([[-1.1573, -4.4948],
        [-1.4773, -1.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08347055315971375
Epoch 0, Step 1076: train/loss = 0.5686412453651428, train/raw-loss = 0.4877265393733978, train/logprobs = tensor([[-1.0199, -2.1965],
        [-1.0149, -0.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0809146910905838
Epoch 0, Step 1077: train/loss = 0.5117436647415161, train/raw-loss = 0.41699931025505066, train/logprobs = tensor([[-1.0673, -3.0273],
        [-1.2577, -1.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474440664052963
Epoch 0, Step 1078: train/loss = 0.527467668056488, train/raw-loss = 0.444491982460022, train/logprobs = tensor([[-1.0104, -2.5473],
        [-1.5201, -1.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08297571539878845
Epoch 0, Step 1079: train/loss = 0.37981393933296204, train/raw-loss = 0.2888621687889099, train/logprobs = tensor([[-0.9953, -4.8379],
        [-1.2865, -1.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09095177799463272
Epoch 0, Step 1080: train/loss = 0.47268688678741455, train/raw-loss = 0.38971227407455444, train/logprobs = tensor([[-0.9419, -3.9922],
        [-0.9957, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0829746276140213
Epoch 0, Step 1081: train/loss = 0.5641388893127441, train/raw-loss = 0.47829699516296387, train/logprobs = tensor([[-1.1608, -2.7208],
        [-1.1792, -1.4502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08584186434745789
Epoch 0, Step 1082: train/loss = 0.4363139569759369, train/raw-loss = 0.3663317561149597, train/logprobs = tensor([[-0.7058, -3.2759],
        [-0.6222, -0.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06998224556446075
Epoch 0, Step 1083: train/loss = 0.4253961145877838, train/raw-loss = 0.33724015951156616, train/logprobs = tensor([[-1.2756, -3.4400],
        [-1.6491, -1.0372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08815589547157288
Epoch 0, Step 1084: train/loss = 0.5219342112541199, train/raw-loss = 0.4360884726047516, train/logprobs = tensor([[-1.0077, -4.2027],
        [-1.1804, -1.5352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08584572374820709
Epoch 0, Step 1085: train/loss = 0.562721848487854, train/raw-loss = 0.4715496003627777, train/logprobs = tensor([[-1.6359, -3.0535],
        [-2.0608, -1.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911722332239151
Epoch 0, Step 1086: train/loss = 0.4003412425518036, train/raw-loss = 0.3103965222835541, train/logprobs = tensor([[-1.0517, -3.8068],
        [-1.1412, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0899447426199913
Epoch 0, Step 1087: train/loss = 0.5213289856910706, train/raw-loss = 0.4282580018043518, train/logprobs = tensor([[-1.2822, -2.8207],
        [-1.5850, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09307100623846054
Epoch 0, Step 1088: train/loss = 0.6165566444396973, train/raw-loss = 0.5135068893432617, train/logprobs = tensor([[-1.1545, -1.6553],
        [-2.0771, -1.5943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10304972529411316
Epoch 0, Step 1089: train/loss = 0.47657012939453125, train/raw-loss = 0.40094658732414246, train/logprobs = tensor([[-0.8767, -3.6362],
        [-0.8344, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756235122680664
Epoch 0, Step 1090: train/loss = 0.4703839123249054, train/raw-loss = 0.377249538898468, train/logprobs = tensor([[-1.2708, -3.2929],
        [-1.4749, -0.7803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09313437342643738
Epoch 0, Step 1091: train/loss = 0.6222673654556274, train/raw-loss = 0.5255016088485718, train/logprobs = tensor([[-1.0603, -2.3346],
        [-1.7936, -1.7979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09676583111286163
Epoch 0, Step 1092: train/loss = 0.6166129112243652, train/raw-loss = 0.5515004396438599, train/logprobs = tensor([[-1.6417, -3.7326],
        [-1.2606, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06511255353689194
Epoch 0, Step 1093: train/loss = 0.46418532729148865, train/raw-loss = 0.37254413962364197, train/logprobs = tensor([[-1.2153, -2.6771],
        [-1.7884, -1.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09164117276668549
Epoch 0, Step 1094: train/loss = 0.4758375585079193, train/raw-loss = 0.3828878700733185, train/logprobs = tensor([[-1.0712, -2.5129],
        [-1.5060, -0.9329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09294968843460083
Epoch 0, Step 1095: train/loss = 0.4631285071372986, train/raw-loss = 0.36195847392082214, train/logprobs = tensor([[-1.3593, -3.0397],
        [-1.6799, -1.3445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10117001831531525
Epoch 0, Step 1096: train/loss = 0.46034133434295654, train/raw-loss = 0.355076402425766, train/logprobs = tensor([[-1.1611, -2.8566],
        [-1.5414, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10526493191719055
Epoch 0, Step 1097: train/loss = 0.3932163715362549, train/raw-loss = 0.30445000529289246, train/logprobs = tensor([[-1.2394, -4.2165],
        [-1.3999, -1.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08876641094684601
Epoch 0, Step 1098: train/loss = 0.3899109661579132, train/raw-loss = 0.30676183104515076, train/logprobs = tensor([[-0.8282, -4.5096],
        [-0.8520, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08314912766218185
Epoch 0, Step 1099: train/loss = 0.621127724647522, train/raw-loss = 0.5409806966781616, train/logprobs = tensor([[-0.9895, -2.3635],
        [-1.0697, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08014705032110214
Epoch 0, Step 1100: train/loss = 0.4309699833393097, train/raw-loss = 0.35119304060935974, train/logprobs = tensor([[-1.1877, -4.5096],
        [-1.4178, -1.2146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07977692782878876
Epoch 0, Step 1101: train/loss = 0.46950238943099976, train/raw-loss = 0.391865074634552, train/logprobs = tensor([[-0.7665, -2.4893],
        [-1.0265, -0.5386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07763731479644775
Epoch 0, Step 1102: train/loss = 0.42797765135765076, train/raw-loss = 0.3311050534248352, train/logprobs = tensor([[-0.8942, -3.5933],
        [-1.3372, -1.2610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09687259793281555
Epoch 0, Step 1103: train/loss = 0.47002771496772766, train/raw-loss = 0.3696138262748718, train/logprobs = tensor([[-0.8808, -3.4669],
        [-1.1986, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10041391104459763
Epoch 0, Step 1104: train/loss = 0.47249311208724976, train/raw-loss = 0.3772556185722351, train/logprobs = tensor([[-1.0530, -3.0500],
        [-1.3243, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09523748606443405
Epoch 0, Step 1105: train/loss = 0.4264466166496277, train/raw-loss = 0.34456777572631836, train/logprobs = tensor([[-0.8916, -4.2967],
        [-0.9627, -1.3790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08187882602214813
Epoch 0, Step 1106: train/loss = 0.5399359464645386, train/raw-loss = 0.4513498842716217, train/logprobs = tensor([[-1.7260, -2.6573],
        [-1.7574, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08858610689640045
Epoch 0, Step 1107: train/loss = 0.5052068829536438, train/raw-loss = 0.4140009582042694, train/logprobs = tensor([[-0.9916, -4.2657],
        [-1.3505, -1.5285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0912059098482132
Epoch 0, Step 1108: train/loss = 0.589205801486969, train/raw-loss = 0.4903109073638916, train/logprobs = tensor([[-0.7902, -2.0405],
        [-1.2365, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09889491647481918
Epoch 0, Step 1109: train/loss = 0.47441911697387695, train/raw-loss = 0.3723996877670288, train/logprobs = tensor([[-1.5538, -3.5491],
        [-1.7369, -1.2873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10201945900917053
Epoch 0, Step 1110: train/loss = 0.4000890254974365, train/raw-loss = 0.3108944296836853, train/logprobs = tensor([[-0.8423, -3.9944],
        [-0.8783, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08919455856084824
Epoch 0, Step 1111: train/loss = 0.682223379611969, train/raw-loss = 0.5764545202255249, train/logprobs = tensor([[-1.4952, -3.6099],
        [-2.0486, -2.4621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10576881468296051
Epoch 0, Step 1112: train/loss = 0.5230794548988342, train/raw-loss = 0.44209930300712585, train/logprobs = tensor([[-1.0141, -3.6804],
        [-0.7782, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08098013699054718
Epoch 0, Step 1113: train/loss = 0.6148227453231812, train/raw-loss = 0.5398663282394409, train/logprobs = tensor([[-1.2546, -1.7567],
        [-1.1211, -0.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07495643198490143
Epoch 0, Step 1114: train/loss = 0.5897904634475708, train/raw-loss = 0.5143206119537354, train/logprobs = tensor([[-0.9527, -3.3047],
        [-1.2635, -1.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07546983659267426
Epoch 0, Step 1115: train/loss = 0.479243665933609, train/raw-loss = 0.37493985891342163, train/logprobs = tensor([[-1.1176, -3.5369],
        [-1.6311, -1.5713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10430379956960678
Epoch 0, Step 1116: train/loss = 0.4811949133872986, train/raw-loss = 0.4034826159477234, train/logprobs = tensor([[-1.0567, -3.2435],
        [-0.9915, -0.7716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07771234959363937
Epoch 0, Step 1117: train/loss = 0.5318981409072876, train/raw-loss = 0.4413891136646271, train/logprobs = tensor([[-1.1620, -2.7343],
        [-1.4699, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09050898998975754
Epoch 0, Step 1118: train/loss = 0.5371736288070679, train/raw-loss = 0.4642232358455658, train/logprobs = tensor([[-0.6466, -3.1794],
        [-0.6642, -0.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07295037060976028
Epoch 0, Step 1119: train/loss = 0.46943819522857666, train/raw-loss = 0.39127302169799805, train/logprobs = tensor([[-0.7273, -3.8046],
        [-0.8284, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07816516607999802
Epoch 0, Step 1120: train/loss = 0.48001956939697266, train/raw-loss = 0.3730142116546631, train/logprobs = tensor([[-1.2752, -3.2044],
        [-1.8492, -1.2625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700537264347076
Epoch 0, Step 1121: train/loss = 0.6301135420799255, train/raw-loss = 0.5421547293663025, train/logprobs = tensor([[-1.5147, -2.2286],
        [-1.7105, -1.4712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08795879036188126
Epoch 0, Step 1122: train/loss = 0.47088050842285156, train/raw-loss = 0.3867907226085663, train/logprobs = tensor([[-1.5328, -4.8760],
        [-1.9415, -1.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08408978581428528
Epoch 0, Step 1123: train/loss = 0.5142940282821655, train/raw-loss = 0.4134904146194458, train/logprobs = tensor([[-1.6942, -5.0609],
        [-2.1695, -1.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10080354660749435
Epoch 0, Step 1124: train/loss = 0.5380198955535889, train/raw-loss = 0.44861844182014465, train/logprobs = tensor([[-2.1062, -3.2124],
        [-2.2168, -1.5399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894014835357666
Epoch 0, Step 1125: train/loss = 0.6845623254776001, train/raw-loss = 0.6100226044654846, train/logprobs = tensor([[-0.7299, -1.1184],
        [-1.1108, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07453972101211548
Epoch 0, Step 1126: train/loss = 0.4098573327064514, train/raw-loss = 0.31807535886764526, train/logprobs = tensor([[-1.1069, -3.4224],
        [-1.5271, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09178201854228973
Epoch 0, Step 1127: train/loss = 0.43158626556396484, train/raw-loss = 0.3420030176639557, train/logprobs = tensor([[-1.3644, -3.1261],
        [-1.8867, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958325535058975
Epoch 0, Step 1128: train/loss = 0.4655197858810425, train/raw-loss = 0.35801398754119873, train/logprobs = tensor([[-1.4761, -2.9998],
        [-2.0104, -1.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10750582814216614
Epoch 0, Step 1129: train/loss = 0.3883403539657593, train/raw-loss = 0.30370986461639404, train/logprobs = tensor([[-0.7401, -4.1469],
        [-1.1556, -1.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08463054150342941
Epoch 0, Step 1130: train/loss = 0.4336290955543518, train/raw-loss = 0.3216710090637207, train/logprobs = tensor([[-1.2914, -3.4773],
        [-1.8016, -1.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1119581013917923
Epoch 0, Step 1131: train/loss = 0.5167868733406067, train/raw-loss = 0.42242687940597534, train/logprobs = tensor([[-1.0932, -2.5291],
        [-1.4590, -0.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09435997903347015
Epoch 0, Step 1132: train/loss = 0.41428637504577637, train/raw-loss = 0.32075002789497375, train/logprobs = tensor([[-1.2495, -3.9576],
        [-1.4111, -1.2426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935363620519638
Epoch 0, Step 1133: train/loss = 0.5014930367469788, train/raw-loss = 0.42180222272872925, train/logprobs = tensor([[-1.2125, -3.4150],
        [-1.3114, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0796908438205719
Epoch 0, Step 1134: train/loss = 0.3930179178714752, train/raw-loss = 0.31862783432006836, train/logprobs = tensor([[-0.9810, -5.2676],
        [-0.9480, -1.3741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07439008355140686
Epoch 0, Step 1135: train/loss = 0.5420266389846802, train/raw-loss = 0.439042329788208, train/logprobs = tensor([[-1.6881, -2.2546],
        [-2.3641, -1.4135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10298427939414978
Epoch 0, Step 1136: train/loss = 0.4708472788333893, train/raw-loss = 0.39864715933799744, train/logprobs = tensor([[-1.0960, -4.1596],
        [-1.0386, -1.4326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07220013439655304
Epoch 0, Step 1137: train/loss = 0.5875100493431091, train/raw-loss = 0.49646803736686707, train/logprobs = tensor([[-1.6334, -3.5929],
        [-1.4035, -0.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09104208648204803
Epoch 0, Step 1138: train/loss = 0.4576353430747986, train/raw-loss = 0.35954776406288147, train/logprobs = tensor([[-1.1624, -2.6294],
        [-1.9754, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0980876088142395
Epoch 0, Step 1139: train/loss = 0.6117344498634338, train/raw-loss = 0.5021743178367615, train/logprobs = tensor([[-1.4398, -2.3389],
        [-1.9123, -1.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10956013202667236
Epoch 0, Step 1140: train/loss = 0.5309282541275024, train/raw-loss = 0.4591054618358612, train/logprobs = tensor([[-0.7517, -2.3245],
        [-1.0345, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07182276248931885
Epoch 0, Step 1141: train/loss = 0.6287288665771484, train/raw-loss = 0.5368052124977112, train/logprobs = tensor([[-0.8434, -3.1523],
        [-1.1286, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09192357957363129
Epoch 0, Step 1142: train/loss = 0.38709697127342224, train/raw-loss = 0.27350419759750366, train/logprobs = tensor([[-1.3787, -2.8824],
        [-2.1356, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11359275877475739
Epoch 0, Step 1143: train/loss = 0.4705657362937927, train/raw-loss = 0.38609030842781067, train/logprobs = tensor([[-1.1569, -6.2556],
        [-1.0128, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08447544276714325
Epoch 0, Step 1144: train/loss = 0.5166244506835938, train/raw-loss = 0.4390309751033783, train/logprobs = tensor([[-0.7040, -3.6986],
        [-0.6931, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07759351283311844
Epoch 0, Step 1145: train/loss = 0.3872990310192108, train/raw-loss = 0.28127050399780273, train/logprobs = tensor([[-1.0240, -3.6069],
        [-1.5278, -0.9597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10602853447198868
Epoch 0, Step 1146: train/loss = 0.444957435131073, train/raw-loss = 0.3526734709739685, train/logprobs = tensor([[-1.0127, -3.2111],
        [-1.3406, -1.0696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09228396415710449
Epoch 0, Step 1147: train/loss = 0.4161794185638428, train/raw-loss = 0.3345682621002197, train/logprobs = tensor([[-0.8456, -3.9482],
        [-0.8355, -0.6935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08161117881536484
Epoch 0, Step 1148: train/loss = 0.4768088459968567, train/raw-loss = 0.3828871548175812, train/logprobs = tensor([[-0.9492, -4.7020],
        [-1.2600, -1.6246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0939217060804367
Epoch 0, Step 1149: train/loss = 0.5392341613769531, train/raw-loss = 0.45939406752586365, train/logprobs = tensor([[-1.3142, -2.6342],
        [-1.3153, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07984012365341187
Epoch 0, Step 1150: train/loss = 0.44331178069114685, train/raw-loss = 0.34455448389053345, train/logprobs = tensor([[-1.4906, -4.8459],
        [-1.5333, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09875728189945221
Epoch 0, Step 1151: train/loss = 0.38830476999282837, train/raw-loss = 0.2859167456626892, train/logprobs = tensor([[-1.3728, -4.1539],
        [-1.8974, -1.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10238800942897797
Epoch 0, Step 1152: train/loss = 0.4030393958091736, train/raw-loss = 0.3358941972255707, train/logprobs = tensor([[-0.8290, -4.6005],
        [-0.9000, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0671451985836029
Epoch 0, Step 1153: train/loss = 0.4136773943901062, train/raw-loss = 0.32793474197387695, train/logprobs = tensor([[-1.2186, -4.4839],
        [-1.2216, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08574261516332626
Epoch 0, Step 1154: train/loss = 0.5432687997817993, train/raw-loss = 0.4780488610267639, train/logprobs = tensor([[-0.8311, -1.9477],
        [-0.7458, -0.7129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06521987915039062
Epoch 0, Step 1155: train/loss = 0.5215839147567749, train/raw-loss = 0.4322499632835388, train/logprobs = tensor([[-1.1849, -2.4541],
        [-1.3784, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08933395147323608
Epoch 0, Step 1156: train/loss = 0.645283579826355, train/raw-loss = 0.5699173212051392, train/logprobs = tensor([[-0.8461, -1.5231],
        [-0.8990, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0753662958741188
Epoch 0, Step 1157: train/loss = 0.5709083080291748, train/raw-loss = 0.46514683961868286, train/logprobs = tensor([[-1.3941, -3.4251],
        [-1.8818, -1.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10576151311397552
Epoch 0, Step 1158: train/loss = 0.497946560382843, train/raw-loss = 0.41403090953826904, train/logprobs = tensor([[-1.0413, -2.5700],
        [-1.3648, -0.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08391565829515457
Epoch 0, Step 1159: train/loss = 0.42498642206192017, train/raw-loss = 0.33557459712028503, train/logprobs = tensor([[-0.9748, -3.8669],
        [-1.3656, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08941183984279633
Epoch 0, Step 1160: train/loss = 0.4226635694503784, train/raw-loss = 0.3261805772781372, train/logprobs = tensor([[-1.6831, -2.7434],
        [-2.2330, -0.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09648296236991882
Epoch 0, Step 1161: train/loss = 0.4153986871242523, train/raw-loss = 0.3219485878944397, train/logprobs = tensor([[-1.4054, -3.9579],
        [-1.8812, -1.3751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09345009177923203
Epoch 0, Step 1162: train/loss = 0.5834158062934875, train/raw-loss = 0.498592346906662, train/logprobs = tensor([[-1.5044, -3.4595],
        [-1.2305, -0.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08482344448566437
Epoch 0, Step 1163: train/loss = 0.5331076979637146, train/raw-loss = 0.4273136556148529, train/logprobs = tensor([[-1.0884, -3.5111],
        [-1.6608, -1.5354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10579405725002289
Epoch 0, Step 1164: train/loss = 0.5700017809867859, train/raw-loss = 0.49288681149482727, train/logprobs = tensor([[-0.7183, -2.1807],
        [-0.9190, -0.7277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711497694253922
Epoch 0, Step 1165: train/loss = 0.5942597389221191, train/raw-loss = 0.511205792427063, train/logprobs = tensor([[-1.0938, -1.8836],
        [-1.1164, -0.9427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08305402100086212
Epoch 0, Step 1166: train/loss = 0.4030190408229828, train/raw-loss = 0.30329471826553345, train/logprobs = tensor([[-1.1938, -2.9805],
        [-1.7807, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09972433745861053
Epoch 0, Step 1167: train/loss = 0.33578455448150635, train/raw-loss = 0.24221494793891907, train/logprobs = tensor([[-0.9069, -4.6054],
        [-1.4537, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356960654258728
Epoch 0, Step 1168: train/loss = 0.5125899314880371, train/raw-loss = 0.40940606594085693, train/logprobs = tensor([[-1.1150, -2.2179],
        [-1.7526, -1.3067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10318384319543839
Epoch 0, Step 1169: train/loss = 0.5154879689216614, train/raw-loss = 0.41159749031066895, train/logprobs = tensor([[-1.1166, -2.3889],
        [-1.4752, -1.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10389047116041183
Epoch 0, Step 1170: train/loss = 0.5568638443946838, train/raw-loss = 0.4589923322200775, train/logprobs = tensor([[-1.2225, -2.3101],
        [-1.4876, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09787151217460632
Epoch 0, Step 1171: train/loss = 0.49487626552581787, train/raw-loss = 0.4172663688659668, train/logprobs = tensor([[-1.1348, -2.8051],
        [-1.3837, -1.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07760986685752869
Epoch 0, Step 1172: train/loss = 0.4880971312522888, train/raw-loss = 0.4075928032398224, train/logprobs = tensor([[-0.7345, -2.9333],
        [-0.9817, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08050434291362762
Epoch 0, Step 1173: train/loss = 0.4512503743171692, train/raw-loss = 0.3620578646659851, train/logprobs = tensor([[-1.4089, -4.1613],
        [-1.5300, -1.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08919254690408707
Epoch 0, Step 1174: train/loss = 0.4731942415237427, train/raw-loss = 0.36266472935676575, train/logprobs = tensor([[-1.6134, -3.0230],
        [-2.2972, -1.8561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11052954196929932
Epoch 0, Step 1175: train/loss = 0.548208475112915, train/raw-loss = 0.4688742160797119, train/logprobs = tensor([[-0.7192, -2.3243],
        [-0.7603, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07933428883552551
Epoch 0, Step 1176: train/loss = 0.4673452377319336, train/raw-loss = 0.3791768550872803, train/logprobs = tensor([[-1.0717, -3.1819],
        [-1.3417, -0.9397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08816836774349213
Epoch 0, Step 1177: train/loss = 0.6092984080314636, train/raw-loss = 0.5225538611412048, train/logprobs = tensor([[-1.1063, -2.5121],
        [-0.9786, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08674456179141998
Epoch 0, Step 1178: train/loss = 0.7087790966033936, train/raw-loss = 0.6292440295219421, train/logprobs = tensor([[-1.0504, -0.9298],
        [-1.0200, -0.6020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07953502982854843
Epoch 0, Step 1179: train/loss = 0.4400850832462311, train/raw-loss = 0.35750657320022583, train/logprobs = tensor([[-1.0839, -3.7773],
        [-1.2300, -1.5165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08257849514484406
Epoch 0, Step 1180: train/loss = 0.49802225828170776, train/raw-loss = 0.4193969666957855, train/logprobs = tensor([[-1.0771, -2.9346],
        [-1.4896, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07862527668476105
Epoch 0, Step 1181: train/loss = 0.6470805406570435, train/raw-loss = 0.5680394172668457, train/logprobs = tensor([[-1.5428, -2.7642],
        [-1.1844, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07904116809368134
Epoch 0, Step 1182: train/loss = 0.503342866897583, train/raw-loss = 0.402681827545166, train/logprobs = tensor([[-1.3097, -3.1260],
        [-1.9404, -1.5525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1006610095500946
Epoch 0, Step 1183: train/loss = 0.5548563599586487, train/raw-loss = 0.4697665274143219, train/logprobs = tensor([[-1.3549, -2.1620],
        [-1.7826, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08508986234664917
Epoch 0, Step 1184: train/loss = 0.4601537585258484, train/raw-loss = 0.38707292079925537, train/logprobs = tensor([[-0.5775, -3.5736],
        [-0.6707, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0730808675289154
Epoch 0, Step 1185: train/loss = 0.4007182717323303, train/raw-loss = 0.304512619972229, train/logprobs = tensor([[-0.9497, -3.3303],
        [-1.6856, -1.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09620565176010132
Epoch 0, Step 1186: train/loss = 0.4656798839569092, train/raw-loss = 0.36879587173461914, train/logprobs = tensor([[-1.0367, -2.9395],
        [-1.3700, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09688401222229004
Epoch 0, Step 1187: train/loss = 0.4133996367454529, train/raw-loss = 0.31995415687561035, train/logprobs = tensor([[-0.8244, -4.4321],
        [-1.0778, -1.3357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09344547986984253
Epoch 0, Step 1188: train/loss = 0.40606653690338135, train/raw-loss = 0.30135613679885864, train/logprobs = tensor([[-1.0582, -4.7290],
        [-1.1580, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1047104150056839
Epoch 0, Step 1189: train/loss = 0.5136082172393799, train/raw-loss = 0.40761640667915344, train/logprobs = tensor([[-1.7771, -3.1278],
        [-1.7263, -1.2893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599183291196823
Epoch 0, Step 1190: train/loss = 0.4122929275035858, train/raw-loss = 0.3058011829853058, train/logprobs = tensor([[-1.2697, -3.0250],
        [-2.2280, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10649173706769943
Epoch 0, Step 1191: train/loss = 0.41394537687301636, train/raw-loss = 0.29407650232315063, train/logprobs = tensor([[-1.2029, -2.8660],
        [-2.2227, -1.2234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11986885964870453
Epoch 0, Step 1192: train/loss = 0.5550140142440796, train/raw-loss = 0.47494029998779297, train/logprobs = tensor([[-0.8646, -1.6595],
        [-1.2919, -0.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08007373660802841
Epoch 0, Step 1193: train/loss = 0.5149410367012024, train/raw-loss = 0.40765756368637085, train/logprobs = tensor([[-0.9266, -2.7739],
        [-1.1652, -1.0718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10728347301483154
Epoch 0, Step 1194: train/loss = 0.4039366841316223, train/raw-loss = 0.3042948842048645, train/logprobs = tensor([[-1.4208, -4.4584],
        [-2.2385, -1.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09964177012443542
Epoch 0, Step 1195: train/loss = 0.48880791664123535, train/raw-loss = 0.39928126335144043, train/logprobs = tensor([[-1.4715, -4.7578],
        [-1.8176, -1.6743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08952666074037552
Epoch 0, Step 1196: train/loss = 0.40248578786849976, train/raw-loss = 0.3025174140930176, train/logprobs = tensor([[-1.0796, -3.4968],
        [-1.8804, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09996837377548218
Epoch 0, Step 1197: train/loss = 0.4274856448173523, train/raw-loss = 0.34662312269210815, train/logprobs = tensor([[-0.9322, -4.3004],
        [-0.8744, -1.2732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08086251467466354
Epoch 0, Step 1198: train/loss = 0.49436214566230774, train/raw-loss = 0.4057357907295227, train/logprobs = tensor([[-0.8820, -3.0438],
        [-1.2757, -1.3825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08862635493278503
Epoch 0, Step 1199: train/loss = 0.49094295501708984, train/raw-loss = 0.398630291223526, train/logprobs = tensor([[-1.1002, -3.5242],
        [-1.4302, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09231268614530563
Epoch 0, Step 1200: train/loss = 0.48775067925453186, train/raw-loss = 0.41159164905548096, train/logprobs = tensor([[-1.2431, -3.3448],
        [-1.4661, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615901529788971
Epoch 0, Step 1201: train/loss = 0.5002651214599609, train/raw-loss = 0.38925135135650635, train/logprobs = tensor([[-1.1335, -3.4626],
        [-2.1037, -2.5274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11101378500461578
Epoch 0, Step 1202: train/loss = 0.5390356183052063, train/raw-loss = 0.47923916578292847, train/logprobs = tensor([[-0.4838, -2.3146],
        [-0.4677, -0.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05979646369814873
Epoch 0, Step 1203: train/loss = 0.7953973412513733, train/raw-loss = 0.709479570388794, train/logprobs = tensor([[-1.9902, -2.4723],
        [-1.5143, -1.3101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08591771125793457
Epoch 0, Step 1204: train/loss = 0.4400402903556824, train/raw-loss = 0.3516882359981537, train/logprobs = tensor([[-1.1301, -3.8160],
        [-1.2515, -1.2903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08835205435752869
Epoch 0, Step 1205: train/loss = 0.5421909689903259, train/raw-loss = 0.4466279149055481, train/logprobs = tensor([[-1.2442, -3.8926],
        [-1.2777, -1.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09556303173303604
Epoch 0, Step 1206: train/loss = 0.47215184569358826, train/raw-loss = 0.354167640209198, train/logprobs = tensor([[-1.4401, -2.3049],
        [-2.2891, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11798421293497086
Epoch 0, Step 1207: train/loss = 0.7460145950317383, train/raw-loss = 0.6593378782272339, train/logprobs = tensor([[-1.9461, -2.3410],
        [-1.3171, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08667673170566559
Epoch 0, Step 1208: train/loss = 0.6428245902061462, train/raw-loss = 0.5726876258850098, train/logprobs = tensor([[-1.0405, -1.9321],
        [-0.9066, -0.9497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07013698667287827
Epoch 0, Step 1209: train/loss = 0.599937379360199, train/raw-loss = 0.5042344331741333, train/logprobs = tensor([[-1.4832, -2.7083],
        [-1.9693, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09570295363664627
Epoch 0, Step 1210: train/loss = 0.5093468427658081, train/raw-loss = 0.42673277854919434, train/logprobs = tensor([[-0.8737, -2.6808],
        [-1.0445, -0.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08261406421661377
Epoch 0, Step 1211: train/loss = 0.5609546899795532, train/raw-loss = 0.4609142243862152, train/logprobs = tensor([[-1.0082, -2.6898],
        [-1.3019, -1.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1000405102968216
Epoch 0, Step 1212: train/loss = 0.4335877597332001, train/raw-loss = 0.33843111991882324, train/logprobs = tensor([[-0.9997, -3.9709],
        [-1.4815, -1.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09515661001205444
Epoch 0, Step 1213: train/loss = 0.5616468191146851, train/raw-loss = 0.47677093744277954, train/logprobs = tensor([[-1.1813, -2.3199],
        [-1.3856, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08487588167190552
Epoch 0, Step 1214: train/loss = 0.46009737253189087, train/raw-loss = 0.38400799036026, train/logprobs = tensor([[-0.6380, -3.6853],
        [-0.6395, -1.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07608935236930847
Epoch 0, Step 1215: train/loss = 0.4004969000816345, train/raw-loss = 0.28389233350753784, train/logprobs = tensor([[-1.5212, -4.0838],
        [-2.0336, -1.7764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11660459637641907
Epoch 0, Step 1216: train/loss = 0.49389412999153137, train/raw-loss = 0.40260550379753113, train/logprobs = tensor([[-1.0126, -4.1131],
        [-1.7238, -1.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09128862619400024
Epoch 0, Step 1217: train/loss = 0.5327620506286621, train/raw-loss = 0.4442341923713684, train/logprobs = tensor([[-1.0023, -2.2784],
        [-1.4410, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08852790296077728
Epoch 0, Step 1218: train/loss = 0.50510573387146, train/raw-loss = 0.38344210386276245, train/logprobs = tensor([[-1.9510, -2.9095],
        [-2.8555, -1.4969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12166363000869751
Epoch 0, Step 1219: train/loss = 0.4781917333602905, train/raw-loss = 0.3882884681224823, train/logprobs = tensor([[-1.1525, -4.0663],
        [-1.1460, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08990325033664703
Epoch 0, Step 1220: train/loss = 0.6039328575134277, train/raw-loss = 0.48866596817970276, train/logprobs = tensor([[-1.6007, -3.1093],
        [-2.2134, -1.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11526690423488617
Epoch 0, Step 1221: train/loss = 0.57884681224823, train/raw-loss = 0.4884796142578125, train/logprobs = tensor([[-1.5819, -2.9542],
        [-2.1171, -1.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09036720544099808
Epoch 0, Step 1222: train/loss = 0.46330133080482483, train/raw-loss = 0.3569188714027405, train/logprobs = tensor([[-1.3112, -3.6406],
        [-1.4302, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10638245940208435
Epoch 0, Step 1223: train/loss = 0.3857324719429016, train/raw-loss = 0.28305280208587646, train/logprobs = tensor([[-1.6455, -3.0868],
        [-2.3791, -1.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10267969220876694
Epoch 0, Step 1224: train/loss = 0.5668153762817383, train/raw-loss = 0.4864618182182312, train/logprobs = tensor([[-1.4182, -3.5540],
        [-1.3056, -1.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08035354316234589
Epoch 0, Step 1225: train/loss = 0.4498656988143921, train/raw-loss = 0.34387022256851196, train/logprobs = tensor([[-1.4172, -4.0365],
        [-2.8250, -2.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599546879529953
Epoch 0, Step 1226: train/loss = 0.39162659645080566, train/raw-loss = 0.2900257110595703, train/logprobs = tensor([[-0.8530, -4.2686],
        [-1.7136, -1.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10160087794065475
Epoch 0, Step 1227: train/loss = 0.5066921710968018, train/raw-loss = 0.4076765179634094, train/logprobs = tensor([[-1.0806, -4.0579],
        [-1.7597, -1.8793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09901560842990875
Epoch 0, Step 1228: train/loss = 0.509520947933197, train/raw-loss = 0.4231920540332794, train/logprobs = tensor([[-1.2446, -3.8421],
        [-1.2946, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0863288938999176
Epoch 0, Step 1229: train/loss = 0.4643833637237549, train/raw-loss = 0.38714051246643066, train/logprobs = tensor([[-0.7956, -3.6725],
        [-0.9382, -1.0905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07724287360906601
Epoch 0, Step 1230: train/loss = 0.45095205307006836, train/raw-loss = 0.3726465702056885, train/logprobs = tensor([[-0.8557, -3.7649],
        [-0.8356, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830553501844406
Epoch 0, Step 1231: train/loss = 0.4406394958496094, train/raw-loss = 0.3279939293861389, train/logprobs = tensor([[-1.2011, -4.5228],
        [-2.4016, -1.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11264555901288986
Epoch 0, Step 1232: train/loss = 0.5973076224327087, train/raw-loss = 0.5214431285858154, train/logprobs = tensor([[-0.6965, -1.9562],
        [-0.8215, -1.0132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07586447149515152
Epoch 0, Step 1233: train/loss = 0.5813948512077332, train/raw-loss = 0.49470633268356323, train/logprobs = tensor([[-0.8905, -3.9645],
        [-1.2142, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08668849617242813
Epoch 0, Step 1234: train/loss = 0.36260682344436646, train/raw-loss = 0.2704770267009735, train/logprobs = tensor([[-0.9891, -6.8808],
        [-1.4222, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09212976694107056
Epoch 0, Step 1235: train/loss = 0.4922974705696106, train/raw-loss = 0.4156302213668823, train/logprobs = tensor([[-0.7953, -3.7431],
        [-0.7692, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07666727155447006
Epoch 0, Step 1236: train/loss = 0.4638265073299408, train/raw-loss = 0.372888445854187, train/logprobs = tensor([[-1.4546, -3.1461],
        [-1.6398, -0.8411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09093808382749557
Epoch 0, Step 1237: train/loss = 0.37593743205070496, train/raw-loss = 0.2841411232948303, train/logprobs = tensor([[-1.0398, -4.7938],
        [-1.6118, -1.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09179628640413284
Epoch 0, Step 1238: train/loss = 0.4166136384010315, train/raw-loss = 0.32865387201309204, train/logprobs = tensor([[-0.8185, -4.1251],
        [-1.3677, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08795975148677826
Epoch 0, Step 1239: train/loss = 0.5296711921691895, train/raw-loss = 0.4182839095592499, train/logprobs = tensor([[-1.5773, -2.8704],
        [-2.1808, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11138725280761719
Epoch 0, Step 1240: train/loss = 0.47915470600128174, train/raw-loss = 0.39186304807662964, train/logprobs = tensor([[-1.3837, -3.7211],
        [-1.5561, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0872916728258133
Epoch 0, Step 1241: train/loss = 0.4375053942203522, train/raw-loss = 0.34106728434562683, train/logprobs = tensor([[-1.1276, -3.9295],
        [-1.7944, -1.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09643811732530594
Epoch 0, Step 1242: train/loss = 0.4714859426021576, train/raw-loss = 0.3651268184185028, train/logprobs = tensor([[-1.2495, -3.5682],
        [-1.6246, -1.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10635913908481598
Epoch 0, Step 1243: train/loss = 0.45776084065437317, train/raw-loss = 0.36030855774879456, train/logprobs = tensor([[-1.2983, -3.5368],
        [-1.4774, -0.9086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097452312707901
Epoch 0, Step 1244: train/loss = 0.4868798553943634, train/raw-loss = 0.3984510898590088, train/logprobs = tensor([[-1.2415, -3.4399],
        [-1.4736, -1.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.088428795337677
Epoch 0, Step 1245: train/loss = 0.3422563970088959, train/raw-loss = 0.22884994745254517, train/logprobs = tensor([[-1.4524, -4.5617],
        [-2.2331, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11340644210577011
Epoch 0, Step 1246: train/loss = 0.3121790587902069, train/raw-loss = 0.20241981744766235, train/logprobs = tensor([[-1.2221, -5.3802],
        [-2.0047, -1.6070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10975926369428635
Epoch 0, Step 1247: train/loss = 0.6324793100357056, train/raw-loss = 0.5451648831367493, train/logprobs = tensor([[-1.1177, -1.3844],
        [-1.4372, -0.8360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08731447160243988
Epoch 0, Step 1248: train/loss = 0.4290640950202942, train/raw-loss = 0.3434465229511261, train/logprobs = tensor([[-1.0430, -3.4245],
        [-1.3102, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0856175571680069
Epoch 0, Step 1249: train/loss = 0.4306265115737915, train/raw-loss = 0.3343767523765564, train/logprobs = tensor([[-1.0672, -3.6294],
        [-1.9554, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09624975919723511
Epoch 0, Step 1250: train/loss = 0.3354853391647339, train/raw-loss = 0.24742481112480164, train/logprobs = tensor([[-0.9150, -5.5409],
        [-1.1856, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08806052803993225
Epoch 0, Step 1251: train/loss = 0.37994498014450073, train/raw-loss = 0.272760272026062, train/logprobs = tensor([[-1.2107, -3.6712],
        [-1.9461, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10718469321727753
Epoch 0, Step 1252: train/loss = 0.33734428882598877, train/raw-loss = 0.22432753443717957, train/logprobs = tensor([[-1.3021, -4.4410],
        [-2.0566, -1.1160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130167692899704
Epoch 0, Step 1253: train/loss = 0.6258647441864014, train/raw-loss = 0.5577550530433655, train/logprobs = tensor([[-0.8753, -1.9246],
        [-0.8090, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06810971349477768
Epoch 0, Step 1254: train/loss = 0.612504243850708, train/raw-loss = 0.5377723574638367, train/logprobs = tensor([[-0.7395, -2.2109],
        [-0.7615, -0.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07473187148571014
Epoch 0, Step 1255: train/loss = 0.505744218826294, train/raw-loss = 0.41508567333221436, train/logprobs = tensor([[-0.9292, -2.6682],
        [-1.7505, -1.3967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09065856784582138
Epoch 0, Step 1256: train/loss = 0.48221635818481445, train/raw-loss = 0.3739817142486572, train/logprobs = tensor([[-1.8525, -3.9322],
        [-2.0543, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10823467373847961
Epoch 0, Step 1257: train/loss = 0.3087306618690491, train/raw-loss = 0.20812468230724335, train/logprobs = tensor([[-1.1156, -4.1593],
        [-2.2540, -1.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10060599446296692
Epoch 0, Step 1258: train/loss = 0.43890368938446045, train/raw-loss = 0.3296540379524231, train/logprobs = tensor([[-1.2150, -3.6845],
        [-1.8649, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10924968123435974
Epoch 0, Step 1259: train/loss = 0.3479325771331787, train/raw-loss = 0.25315219163894653, train/logprobs = tensor([[-1.1263, -5.3275],
        [-1.5472, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09478039294481277
Epoch 0, Step 1260: train/loss = 0.30060964822769165, train/raw-loss = 0.18290185928344727, train/logprobs = tensor([[-1.0195, -4.1554],
        [-2.2413, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11770778894424438
Epoch 0, Step 1261: train/loss = 0.5880546569824219, train/raw-loss = 0.5015337467193604, train/logprobs = tensor([[-0.7576, -2.9134],
        [-0.9139, -1.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08652088791131973
Epoch 0, Step 1262: train/loss = 0.42362087965011597, train/raw-loss = 0.3335953950881958, train/logprobs = tensor([[-0.8988, -3.2933],
        [-1.2829, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09002549946308136
Epoch 0, Step 1263: train/loss = 0.47242027521133423, train/raw-loss = 0.39574772119522095, train/logprobs = tensor([[-0.6987, -4.8057],
        [-0.6527, -1.1046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07667255401611328
Epoch 0, Step 1264: train/loss = 0.3362500071525574, train/raw-loss = 0.22864967584609985, train/logprobs = tensor([[-1.0920, -5.7412],
        [-1.5908, -1.1424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10760033130645752
Epoch 0, Step 1265: train/loss = 0.5167744159698486, train/raw-loss = 0.40519678592681885, train/logprobs = tensor([[-1.6171, -3.3825],
        [-2.5067, -1.5695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11157764494419098
Epoch 0, Step 1266: train/loss = 0.4219393730163574, train/raw-loss = 0.31940799951553345, train/logprobs = tensor([[-1.0191, -3.6703],
        [-1.7533, -2.1193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10253139585256577
Epoch 0, Step 1267: train/loss = 0.4327269494533539, train/raw-loss = 0.31505584716796875, train/logprobs = tensor([[-1.1925, -4.6250],
        [-2.2237, -1.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11767112463712692
Epoch 0, Step 1268: train/loss = 0.5360550284385681, train/raw-loss = 0.4569035470485687, train/logprobs = tensor([[-0.7380, -2.4897],
        [-0.8885, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07915147393941879
Epoch 0, Step 1269: train/loss = 0.37669989466667175, train/raw-loss = 0.26899296045303345, train/logprobs = tensor([[-0.9083, -3.6223],
        [-1.5676, -1.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1077069491147995
Epoch 0, Step 1270: train/loss = 0.531359076499939, train/raw-loss = 0.4265744090080261, train/logprobs = tensor([[-1.1226, -2.6664],
        [-2.1256, -1.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10478468239307404
Epoch 0, Step 1271: train/loss = 0.5613930821418762, train/raw-loss = 0.4780879318714142, train/logprobs = tensor([[-0.7572, -2.2457],
        [-0.8275, -0.8798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08330511301755905
Epoch 0, Step 1272: train/loss = 0.5014888644218445, train/raw-loss = 0.4060700237751007, train/logprobs = tensor([[-1.0014, -3.3718],
        [-1.0689, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541887789964676
Epoch 0, Step 1273: train/loss = 0.5083341598510742, train/raw-loss = 0.416189968585968, train/logprobs = tensor([[-1.3131, -3.0566],
        [-1.5481, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09214422106742859
Epoch 0, Step 1274: train/loss = 0.5356996059417725, train/raw-loss = 0.4397197663784027, train/logprobs = tensor([[-0.9542, -3.8818],
        [-1.3777, -1.2787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09597982466220856
Epoch 0, Step 1275: train/loss = 0.41049572825431824, train/raw-loss = 0.31217920780181885, train/logprobs = tensor([[-1.0248, -3.5847],
        [-1.9813, -1.2257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0983164981007576
Epoch 0, Step 1276: train/loss = 0.4733443856239319, train/raw-loss = 0.4052170515060425, train/logprobs = tensor([[-0.6371, -2.7265],
        [-0.5550, -0.7201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06812736392021179
Epoch 0, Step 1277: train/loss = 0.6067174673080444, train/raw-loss = 0.535161018371582, train/logprobs = tensor([[-0.7251, -1.7765],
        [-0.7391, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0715564712882042
Epoch 0, Step 1278: train/loss = 0.4010851979255676, train/raw-loss = 0.3166864812374115, train/logprobs = tensor([[-0.8510, -3.6430],
        [-1.2856, -0.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08439873158931732
Epoch 0, Step 1279: train/loss = 0.4172402024269104, train/raw-loss = 0.30825960636138916, train/logprobs = tensor([[-0.8659, -4.0663],
        [-1.3005, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10898059606552124
Epoch 0, Step 1280: train/loss = 0.5494142174720764, train/raw-loss = 0.48340320587158203, train/logprobs = tensor([[-0.7174, -3.4354],
        [-0.7103, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06601099669933319
Epoch 0, Step 1281: train/loss = 0.3680238127708435, train/raw-loss = 0.2895510494709015, train/logprobs = tensor([[-0.8196, -4.7283],
        [-0.9874, -1.1301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.078472800552845
Epoch 0, Step 1282: train/loss = 0.5293141007423401, train/raw-loss = 0.41927626729011536, train/logprobs = tensor([[-1.3602, -2.5422],
        [-2.2301, -1.5097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003784835338593
Epoch 0, Step 1283: train/loss = 0.3567211627960205, train/raw-loss = 0.27206867933273315, train/logprobs = tensor([[-0.9891, -3.8091],
        [-1.6662, -1.1375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08465248346328735
Epoch 0, Step 1284: train/loss = 0.4427469074726105, train/raw-loss = 0.3626657724380493, train/logprobs = tensor([[-0.7752, -3.2809],
        [-0.8502, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08008114248514175
Epoch 0, Step 1285: train/loss = 0.4298976957798004, train/raw-loss = 0.3398783206939697, train/logprobs = tensor([[-1.0736, -3.4143],
        [-1.4663, -0.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900193452835083
Epoch 0, Step 1286: train/loss = 0.6446780562400818, train/raw-loss = 0.5796152949333191, train/logprobs = tensor([[-1.0074, -1.6843],
        [-1.1192, -1.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06506272405385971
Epoch 0, Step 1287: train/loss = 0.3452821671962738, train/raw-loss = 0.25766682624816895, train/logprobs = tensor([[-0.8225, -6.0696],
        [-1.3491, -1.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08761535584926605
Epoch 0, Step 1288: train/loss = 0.5534268617630005, train/raw-loss = 0.4354464113712311, train/logprobs = tensor([[-1.1476, -2.5394],
        [-2.3277, -1.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11798040568828583
Epoch 0, Step 1289: train/loss = 0.44986045360565186, train/raw-loss = 0.349107027053833, train/logprobs = tensor([[-1.4658, -4.1381],
        [-2.4216, -2.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10075346380472183
Epoch 0, Step 1290: train/loss = 0.7669212222099304, train/raw-loss = 0.6730004549026489, train/logprobs = tensor([[-1.1703, -1.7442],
        [-1.5981, -1.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09392081946134567
Epoch 0, Step 1291: train/loss = 0.5422937870025635, train/raw-loss = 0.44423627853393555, train/logprobs = tensor([[-1.0761, -3.6862],
        [-1.6698, -2.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09805746376514435
Epoch 0, Step 1292: train/loss = 0.5019373297691345, train/raw-loss = 0.4003790020942688, train/logprobs = tensor([[-1.7680, -2.1781],
        [-2.3120, -0.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10155832022428513
Epoch 0, Step 1293: train/loss = 0.5909023284912109, train/raw-loss = 0.5166698694229126, train/logprobs = tensor([[-0.7052, -1.3774],
        [-1.1309, -0.6811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07423246651887894
Epoch 0, Step 1294: train/loss = 0.4594646096229553, train/raw-loss = 0.363074392080307, train/logprobs = tensor([[-1.0286, -4.5169],
        [-1.3277, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09639020264148712
Epoch 0, Step 1295: train/loss = 0.5315620303153992, train/raw-loss = 0.4221944212913513, train/logprobs = tensor([[-0.9692, -3.0707],
        [-1.7197, -1.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10936758667230606
Epoch 0, Step 1296: train/loss = 0.32273197174072266, train/raw-loss = 0.22781604528427124, train/logprobs = tensor([[-0.8809, -5.6506],
        [-1.7450, -2.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09491591155529022
Epoch 0, Step 1297: train/loss = 0.5357292890548706, train/raw-loss = 0.46584904193878174, train/logprobs = tensor([[-0.8171, -2.4079],
        [-0.6815, -0.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06988028436899185
Epoch 0, Step 1298: train/loss = 0.4306790232658386, train/raw-loss = 0.34403786063194275, train/logprobs = tensor([[-1.8249, -3.1302],
        [-2.2097, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08664114028215408
Epoch 0, Step 1299: train/loss = 0.5522931218147278, train/raw-loss = 0.454694926738739, train/logprobs = tensor([[-1.2385, -4.2127],
        [-1.4999, -1.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09759818762540817
Epoch 0, Step 1300: train/loss = 0.500671923160553, train/raw-loss = 0.4120780825614929, train/logprobs = tensor([[-0.7278, -3.2096],
        [-1.0140, -1.1900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08859377354383469
Epoch 0, Step 1301: train/loss = 0.6735981702804565, train/raw-loss = 0.5803472399711609, train/logprobs = tensor([[-1.4283, -3.6899],
        [-1.5013, -2.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09325093030929565
Epoch 0, Step 1302: train/loss = 0.43232953548431396, train/raw-loss = 0.34514859318733215, train/logprobs = tensor([[-0.8523, -4.9123],
        [-1.1000, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0871809720993042
Epoch 0, Step 1303: train/loss = 0.43863409757614136, train/raw-loss = 0.35481029748916626, train/logprobs = tensor([[-0.8344, -5.3074],
        [-1.4532, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0838237851858139
Epoch 0, Step 1304: train/loss = 0.445600688457489, train/raw-loss = 0.35907530784606934, train/logprobs = tensor([[-1.3634, -3.6393],
        [-1.9207, -1.2030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08652535080909729
Epoch 0, Step 1305: train/loss = 0.42181462049484253, train/raw-loss = 0.32014453411102295, train/logprobs = tensor([[-1.0474, -3.1753],
        [-1.6208, -1.4381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10167008638381958
Epoch 0, Step 1306: train/loss = 0.45386770367622375, train/raw-loss = 0.3694855570793152, train/logprobs = tensor([[-1.0142, -4.0518],
        [-1.4893, -1.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08438216149806976
Epoch 0, Step 1307: train/loss = 0.6907246112823486, train/raw-loss = 0.569491982460022, train/logprobs = tensor([[-1.1753, -1.9612],
        [-2.2091, -2.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12123256921768188
Epoch 0, Step 1308: train/loss = 0.3315507173538208, train/raw-loss = 0.23281607031822205, train/logprobs = tensor([[-1.4768, -3.8399],
        [-2.1822, -0.9174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09873462468385696
Epoch 0, Step 1309: train/loss = 0.31227830052375793, train/raw-loss = 0.20356246829032898, train/logprobs = tensor([[-1.1411, -5.3408],
        [-2.1329, -1.2039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10871583968400955
Epoch 0, Step 1310: train/loss = 0.42533600330352783, train/raw-loss = 0.3467588722705841, train/logprobs = tensor([[-1.3114, -6.0051],
        [-1.7940, -1.8457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07857712358236313
Epoch 0, Step 1311: train/loss = 0.39522451162338257, train/raw-loss = 0.3017023801803589, train/logprobs = tensor([[-1.0432, -3.2831],
        [-1.4923, -0.9488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09352212399244308
Epoch 0, Step 1312: train/loss = 0.9048055410385132, train/raw-loss = 0.8047426342964172, train/logprobs = tensor([[-1.0286, -1.8306],
        [-2.2823, -2.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10006291419267654
Epoch 0, Step 1313: train/loss = 0.4321603775024414, train/raw-loss = 0.33545586466789246, train/logprobs = tensor([[-1.1415, -2.2830],
        [-2.0789, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09670452773571014
Epoch 0, Step 1314: train/loss = 0.47060704231262207, train/raw-loss = 0.38391777873039246, train/logprobs = tensor([[-0.8872, -5.4818],
        [-1.0520, -1.5444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08668926358222961
Epoch 0, Step 1315: train/loss = 0.5670990347862244, train/raw-loss = 0.4710359275341034, train/logprobs = tensor([[-1.3749, -2.5840],
        [-1.2408, -0.9429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09606313705444336
Epoch 0, Step 1316: train/loss = 0.33541691303253174, train/raw-loss = 0.21055331826210022, train/logprobs = tensor([[-0.9954, -3.7747],
        [-2.6776, -0.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12486358731985092
Epoch 0, Step 1317: train/loss = 0.47876179218292236, train/raw-loss = 0.4080180525779724, train/logprobs = tensor([[-0.9850, -4.6138],
        [-1.1013, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07074372470378876
Epoch 0, Step 1318: train/loss = 0.36199814081192017, train/raw-loss = 0.2898251414299011, train/logprobs = tensor([[-1.0559, -4.3774],
        [-1.3588, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07217298448085785
Epoch 0, Step 1319: train/loss = 0.300667941570282, train/raw-loss = 0.17938654124736786, train/logprobs = tensor([[-1.0739, -4.9075],
        [-2.0338, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12128139287233353
Epoch 0, Step 1320: train/loss = 0.5662353038787842, train/raw-loss = 0.4699028432369232, train/logprobs = tensor([[-1.4723, -2.6495],
        [-2.5831, -2.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09633250534534454
Epoch 0, Step 1321: train/loss = 0.41502946615219116, train/raw-loss = 0.3234211206436157, train/logprobs = tensor([[-1.1953, -3.6303],
        [-1.3934, -0.9997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09160833060741425
Epoch 0, Step 1322: train/loss = 0.51973956823349, train/raw-loss = 0.4236050546169281, train/logprobs = tensor([[-1.5912, -2.6840],
        [-2.5987, -1.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09613451361656189
Epoch 0, Step 1323: train/loss = 0.3933730125427246, train/raw-loss = 0.2896396517753601, train/logprobs = tensor([[-0.8328, -2.9511],
        [-2.2578, -1.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1037333607673645
Epoch 0, Step 1324: train/loss = 0.4782465696334839, train/raw-loss = 0.40528199076652527, train/logprobs = tensor([[-1.2579, -4.2702],
        [-1.2693, -1.1319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07296454906463623
Epoch 0, Step 1325: train/loss = 0.4177097976207733, train/raw-loss = 0.3255985975265503, train/logprobs = tensor([[-1.0684, -2.7036],
        [-1.9217, -0.6900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09211118519306183
Epoch 0, Step 1326: train/loss = 0.5879166722297668, train/raw-loss = 0.5046854615211487, train/logprobs = tensor([[-1.4100, -2.9040],
        [-1.3796, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08323124051094055
Epoch 0, Step 1327: train/loss = 0.39747318625450134, train/raw-loss = 0.2933254837989807, train/logprobs = tensor([[-1.1035, -2.4701],
        [-2.1490, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10414768010377884
Epoch 0, Step 1328: train/loss = 0.48783615231513977, train/raw-loss = 0.406994104385376, train/logprobs = tensor([[-1.1809, -2.7794],
        [-1.2814, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08084208518266678
Epoch 0, Step 1329: train/loss = 0.33764904737472534, train/raw-loss = 0.22058998048305511, train/logprobs = tensor([[-1.2227, -3.9587],
        [-2.5191, -1.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11705906689167023
Epoch 0, Step 1330: train/loss = 0.5738226175308228, train/raw-loss = 0.4736505150794983, train/logprobs = tensor([[-1.7612, -4.6413],
        [-2.2761, -2.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017211735248566
Epoch 0, Step 1331: train/loss = 0.4212878346443176, train/raw-loss = 0.3248771131038666, train/logprobs = tensor([[-1.0034, -3.4072],
        [-1.2334, -1.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09641073644161224
Epoch 0, Step 1332: train/loss = 0.4994164705276489, train/raw-loss = 0.42098361253738403, train/logprobs = tensor([[-0.6480, -3.9317],
        [-1.1724, -1.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07843286544084549
Epoch 0, Step 1333: train/loss = 0.5871502161026001, train/raw-loss = 0.4860631227493286, train/logprobs = tensor([[-1.3270, -3.9860],
        [-1.9546, -1.8485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10108709335327148
Epoch 0, Step 1334: train/loss = 0.5408124923706055, train/raw-loss = 0.45191341638565063, train/logprobs = tensor([[-0.9241, -2.4542],
        [-0.9464, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08889907598495483
Epoch 0, Step 1335: train/loss = 0.4275875985622406, train/raw-loss = 0.3187711238861084, train/logprobs = tensor([[-1.0249, -3.8468],
        [-1.5765, -1.6645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1088164821267128
Epoch 0, Step 1336: train/loss = 0.5723516941070557, train/raw-loss = 0.49323877692222595, train/logprobs = tensor([[-1.4071, -3.3932],
        [-1.0524, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0791129618883133
Epoch 0, Step 1337: train/loss = 0.33174335956573486, train/raw-loss = 0.23381464183330536, train/logprobs = tensor([[-1.2096, -3.7498],
        [-1.7775, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09792870283126831
Epoch 0, Step 1338: train/loss = 0.34711435437202454, train/raw-loss = 0.24179711937904358, train/logprobs = tensor([[-0.9662, -4.3831],
        [-1.6692, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10531722009181976
Epoch 0, Step 1339: train/loss = 0.4400137662887573, train/raw-loss = 0.3401726484298706, train/logprobs = tensor([[-1.3583, -4.6883],
        [-1.8243, -1.5450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09984108060598373
Epoch 0, Step 1340: train/loss = 0.39259374141693115, train/raw-loss = 0.2904106676578522, train/logprobs = tensor([[-1.1186, -5.9433],
        [-1.9449, -1.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10218307375907898
Epoch 0, Step 1341: train/loss = 0.48715031147003174, train/raw-loss = 0.4073079824447632, train/logprobs = tensor([[-0.8457, -3.9471],
        [-0.9759, -1.3434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07984233647584915
Epoch 0, Step 1342: train/loss = 0.4044705927371979, train/raw-loss = 0.3100701868534088, train/logprobs = tensor([[-1.1239, -2.1433],
        [-2.3684, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09440039843320847
Epoch 0, Step 1343: train/loss = 0.41348809003829956, train/raw-loss = 0.3262619376182556, train/logprobs = tensor([[-1.4216, -4.7123],
        [-1.5746, -1.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08722616732120514
Epoch 0, Step 1344: train/loss = 0.44612962007522583, train/raw-loss = 0.3472650349140167, train/logprobs = tensor([[-1.1201, -4.9181],
        [-1.5169, -1.3426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0988646000623703
Epoch 0, Step 1345: train/loss = 0.32603561878204346, train/raw-loss = 0.22254930436611176, train/logprobs = tensor([[-1.2309, -3.6027],
        [-2.5499, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1034863293170929
Epoch 0, Step 1346: train/loss = 0.4943702220916748, train/raw-loss = 0.39371639490127563, train/logprobs = tensor([[-1.0540, -2.0957],
        [-1.8990, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10065379738807678
Epoch 0, Step 1347: train/loss = 0.5265076160430908, train/raw-loss = 0.43914511799812317, train/logprobs = tensor([[-1.0306, -3.3146],
        [-1.0323, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08736250549554825
Epoch 0, Step 1348: train/loss = 0.5021252632141113, train/raw-loss = 0.3765425682067871, train/logprobs = tensor([[-1.2884, -4.7612],
        [-2.4437, -2.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12558268010616302
Epoch 0, Step 1349: train/loss = 0.4369758367538452, train/raw-loss = 0.36837834119796753, train/logprobs = tensor([[-0.8958, -3.9318],
        [-0.9188, -0.9219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06859755516052246
Epoch 0, Step 1350: train/loss = 0.3912259638309479, train/raw-loss = 0.2877952456474304, train/logprobs = tensor([[-1.3250, -5.1121],
        [-2.0418, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10343072563409805
Epoch 0, Step 1351: train/loss = 0.6454411745071411, train/raw-loss = 0.5577123165130615, train/logprobs = tensor([[-1.0379, -1.9121],
        [-2.2669, -1.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08772887289524078
Epoch 0, Step 1352: train/loss = 0.4992303252220154, train/raw-loss = 0.42463767528533936, train/logprobs = tensor([[-0.8058, -2.5284],
        [-0.9733, -1.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07459265738725662
Epoch 0, Step 1353: train/loss = 0.38452500104904175, train/raw-loss = 0.2979211211204529, train/logprobs = tensor([[-1.1446, -2.5054],
        [-2.2964, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08660389482975006
Epoch 0, Step 1354: train/loss = 0.502396285533905, train/raw-loss = 0.42240750789642334, train/logprobs = tensor([[-0.7151, -3.4302],
        [-0.8950, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07998877763748169
Epoch 0, Step 1355: train/loss = 0.4390813708305359, train/raw-loss = 0.33965614438056946, train/logprobs = tensor([[-1.9349, -4.1252],
        [-2.3564, -1.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09942527115345001
Epoch 0, Step 1356: train/loss = 0.610770583152771, train/raw-loss = 0.5445832014083862, train/logprobs = tensor([[-0.7732, -2.9024],
        [-0.7898, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06618733704090118
Epoch 0, Step 1357: train/loss = 0.5365809202194214, train/raw-loss = 0.46403372287750244, train/logprobs = tensor([[-0.7489, -4.0301],
        [-0.8718, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07254719734191895
Epoch 0, Step 1358: train/loss = 0.6083272695541382, train/raw-loss = 0.4882686734199524, train/logprobs = tensor([[-1.3939, -2.4988],
        [-1.9236, -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12005862593650818
Epoch 0, Step 1359: train/loss = 0.7005382776260376, train/raw-loss = 0.599272608757019, train/logprobs = tensor([[-1.0279, -1.6959],
        [-1.2257, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10126565396785736
Epoch 0, Step 1360: train/loss = 0.41861769556999207, train/raw-loss = 0.3073626160621643, train/logprobs = tensor([[-0.9547, -3.4868],
        [-1.6114, -1.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11125507950782776
Epoch 0, Step 1361: train/loss = 0.5991882085800171, train/raw-loss = 0.5265070796012878, train/logprobs = tensor([[-0.7115, -2.0211],
        [-0.6890, -0.9746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07268113642930984
Epoch 0, Step 1362: train/loss = 0.4896198511123657, train/raw-loss = 0.4080958962440491, train/logprobs = tensor([[-0.6790, -3.0965],
        [-0.7345, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08152398467063904
Epoch 0, Step 1363: train/loss = 0.4044738709926605, train/raw-loss = 0.2971450090408325, train/logprobs = tensor([[-1.1481, -4.2674],
        [-1.9402, -1.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10732889920473099
Epoch 0, Step 1364: train/loss = 0.6417654156684875, train/raw-loss = 0.5603368282318115, train/logprobs = tensor([[-1.5360, -3.4346],
        [-0.9061, -1.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08142852038145065
Epoch 0, Step 1365: train/loss = 0.5983979105949402, train/raw-loss = 0.5050122141838074, train/logprobs = tensor([[-1.1381, -3.8942],
        [-1.8973, -1.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09338570386171341
Epoch 0, Step 1366: train/loss = 0.4588102698326111, train/raw-loss = 0.3521536588668823, train/logprobs = tensor([[-1.1362, -3.1952],
        [-2.6209, -1.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10665662586688995
Epoch 0, Step 1367: train/loss = 0.41665321588516235, train/raw-loss = 0.33604082465171814, train/logprobs = tensor([[-0.6901, -3.8780],
        [-0.7621, -0.8463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08061240613460541
Epoch 0, Step 1368: train/loss = 0.5283893346786499, train/raw-loss = 0.43544772267341614, train/logprobs = tensor([[-1.2343, -5.1105],
        [-1.5511, -2.1441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09294163435697556
Epoch 0, Step 1369: train/loss = 0.47342997789382935, train/raw-loss = 0.38627418875694275, train/logprobs = tensor([[-1.2471, -2.8571],
        [-1.9679, -1.5919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0871557742357254
Epoch 0, Step 1370: train/loss = 0.42001497745513916, train/raw-loss = 0.3108989894390106, train/logprobs = tensor([[-1.5468, -3.5856],
        [-2.4147, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10911599546670914
Epoch 0, Step 1371: train/loss = 0.3517046272754669, train/raw-loss = 0.2237432450056076, train/logprobs = tensor([[-1.1358, -3.6007],
        [-2.4520, -1.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1279613971710205
Epoch 0, Step 1372: train/loss = 0.28959253430366516, train/raw-loss = 0.18522974848747253, train/logprobs = tensor([[-1.5655, -7.4537],
        [-2.5291, -2.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436280071735382
Epoch 0, Step 1373: train/loss = 0.3987272381782532, train/raw-loss = 0.30309009552001953, train/logprobs = tensor([[-1.4579, -2.0957],
        [-2.8673, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09563713520765305
Epoch 0, Step 1374: train/loss = 0.6503891944885254, train/raw-loss = 0.540525496006012, train/logprobs = tensor([[-1.0828, -6.1027],
        [-1.9606, -3.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10986373573541641
Epoch 0, Step 1375: train/loss = 0.3192054033279419, train/raw-loss = 0.21747785806655884, train/logprobs = tensor([[-1.3481, -5.2468],
        [-1.9768, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10172756761312485
Epoch 0, Step 1376: train/loss = 0.5946900248527527, train/raw-loss = 0.5112946629524231, train/logprobs = tensor([[-1.3580, -2.5483],
        [-1.1209, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08339529484510422
Epoch 0, Step 1377: train/loss = 0.47358691692352295, train/raw-loss = 0.3813435137271881, train/logprobs = tensor([[-0.8650, -3.4414],
        [-1.3765, -0.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09224340319633484
Epoch 0, Step 1378: train/loss = 0.5023667216300964, train/raw-loss = 0.3956390619277954, train/logprobs = tensor([[-1.3327, -1.5429],
        [-2.4664, -0.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10672767460346222
Epoch 0, Step 1379: train/loss = 0.3969751298427582, train/raw-loss = 0.2951972782611847, train/logprobs = tensor([[-1.2465, -3.2806],
        [-2.1553, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10177786648273468
Epoch 0, Step 1380: train/loss = 0.43832334876060486, train/raw-loss = 0.34608691930770874, train/logprobs = tensor([[-0.8045, -4.0079],
        [-1.5434, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09223639965057373
Epoch 0, Step 1381: train/loss = 0.38990700244903564, train/raw-loss = 0.28390589356422424, train/logprobs = tensor([[-1.4954, -4.9170],
        [-1.9574, -1.2231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1060011237859726
Epoch 0, Step 1382: train/loss = 0.5271132588386536, train/raw-loss = 0.39348798990249634, train/logprobs = tensor([[-1.6266, -3.5193],
        [-2.7043, -1.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13362529873847961
Epoch 0, Step 1383: train/loss = 0.3186018466949463, train/raw-loss = 0.18784283101558685, train/logprobs = tensor([[-1.0867, -3.7451],
        [-2.4715, -0.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13075901567935944
Epoch 0, Step 1384: train/loss = 0.4535593092441559, train/raw-loss = 0.360946387052536, train/logprobs = tensor([[-0.7806, -3.3035],
        [-0.9306, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09261291474103928
Epoch 0, Step 1385: train/loss = 0.27467814087867737, train/raw-loss = 0.16637840867042542, train/logprobs = tensor([[-1.0812, -6.1370],
        [-2.3201, -1.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10829974710941315
Epoch 0, Step 1386: train/loss = 0.6805346608161926, train/raw-loss = 0.5779924392700195, train/logprobs = tensor([[-1.4584, -3.8108],
        [-1.7278, -1.8207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1025422215461731
Epoch 0, Step 1387: train/loss = 0.8171044588088989, train/raw-loss = 0.7289341688156128, train/logprobs = tensor([[-0.8693, -1.1359],
        [-1.9755, -1.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08817030489444733
Epoch 0, Step 1388: train/loss = 0.46360254287719727, train/raw-loss = 0.35739338397979736, train/logprobs = tensor([[-1.0757, -3.5381],
        [-1.6530, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10620918869972229
Epoch 0, Step 1389: train/loss = 0.4028523564338684, train/raw-loss = 0.323863685131073, train/logprobs = tensor([[-0.8162, -4.8105],
        [-1.2454, -1.3097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07898867130279541
Epoch 0, Step 1390: train/loss = 0.4214135408401489, train/raw-loss = 0.3261891305446625, train/logprobs = tensor([[-1.2267, -5.5372],
        [-1.5492, -1.2245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09522438049316406
Epoch 0, Step 1391: train/loss = 0.40909332036972046, train/raw-loss = 0.3060093820095062, train/logprobs = tensor([[-0.8167, -3.4959],
        [-1.7517, -1.1592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10308396816253662
Epoch 0, Step 1392: train/loss = 0.4465112090110779, train/raw-loss = 0.36080989241600037, train/logprobs = tensor([[-0.8743, -4.0445],
        [-1.0466, -1.4549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08570130914449692
Epoch 0, Step 1393: train/loss = 0.5087957382202148, train/raw-loss = 0.3952746093273163, train/logprobs = tensor([[-1.1432, -2.2624],
        [-2.1492, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11352109909057617
Epoch 0, Step 1394: train/loss = 0.4625614881515503, train/raw-loss = 0.3985421061515808, train/logprobs = tensor([[-0.7095, -3.7036],
        [-0.6734, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06401940435171127
Epoch 0, Step 1395: train/loss = 0.37567177414894104, train/raw-loss = 0.28206557035446167, train/logprobs = tensor([[-1.8107, -3.7912],
        [-2.7908, -1.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09360618144273758
Epoch 0, Step 1396: train/loss = 0.32330048084259033, train/raw-loss = 0.21916300058364868, train/logprobs = tensor([[-0.8647, -5.4785],
        [-1.5439, -0.9552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10413748770952225
Epoch 0, Step 1397: train/loss = 0.37512627243995667, train/raw-loss = 0.26246440410614014, train/logprobs = tensor([[-1.8734, -3.9711],
        [-2.4453, -1.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11266189813613892
Epoch 0, Step 1398: train/loss = 0.6994512677192688, train/raw-loss = 0.5654829144477844, train/logprobs = tensor([[-1.3562, -2.6137],
        [-2.4254, -2.3129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1339682936668396
Epoch 0, Step 1399: train/loss = 0.4760519862174988, train/raw-loss = 0.38890254497528076, train/logprobs = tensor([[-1.4638, -4.5529],
        [-1.7083, -1.4599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08714944124221802
Epoch 0, Step 1400: train/loss = 0.5835656523704529, train/raw-loss = 0.5002182722091675, train/logprobs = tensor([[-1.1122, -3.7822],
        [-1.7873, -1.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0833473801612854
Epoch 0, Step 1401: train/loss = 0.37001335620880127, train/raw-loss = 0.25860750675201416, train/logprobs = tensor([[-1.2606, -2.9704],
        [-2.5477, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11140584945678711
Epoch 0, Step 1402: train/loss = 0.3712093234062195, train/raw-loss = 0.28599151968955994, train/logprobs = tensor([[-0.7867, -3.8200],
        [-1.3629, -1.3070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08521778881549835
Epoch 0, Step 1403: train/loss = 0.2666478157043457, train/raw-loss = 0.1374327838420868, train/logprobs = tensor([[-1.2850, -3.3581],
        [-3.7000, -1.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1292150616645813
Epoch 0, Step 1404: train/loss = 0.4547116756439209, train/raw-loss = 0.3696369528770447, train/logprobs = tensor([[-0.7839, -3.8958],
        [-1.0150, -1.4007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08507469296455383
Epoch 0, Step 1405: train/loss = 0.3637582063674927, train/raw-loss = 0.2579479217529297, train/logprobs = tensor([[-0.9554, -3.6074],
        [-1.7917, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1058102548122406
Epoch 0, Step 1406: train/loss = 0.5322127342224121, train/raw-loss = 0.4480908215045929, train/logprobs = tensor([[-0.9240, -1.4041],
        [-1.6333, -0.7191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08412189781665802
Epoch 0, Step 1407: train/loss = 0.4309993386268616, train/raw-loss = 0.33481037616729736, train/logprobs = tensor([[-1.0875, -5.3808],
        [-1.6701, -2.0863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09618895500898361
Epoch 0, Step 1408: train/loss = 0.3816586136817932, train/raw-loss = 0.3023119866847992, train/logprobs = tensor([[-0.6859, -4.0254],
        [-0.7920, -1.0230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07934663444757462
Epoch 0, Step 1409: train/loss = 0.5999361872673035, train/raw-loss = 0.5088218450546265, train/logprobs = tensor([[-0.8413, -3.5025],
        [-1.6635, -2.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911143496632576
Epoch 0, Step 1410: train/loss = 0.46214693784713745, train/raw-loss = 0.3591274619102478, train/logprobs = tensor([[-1.1802, -4.3434],
        [-1.2091, -1.4012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10301950573921204
Epoch 0, Step 1411: train/loss = 0.39722713828086853, train/raw-loss = 0.3090534806251526, train/logprobs = tensor([[-1.1545, -3.9056],
        [-1.4287, -1.4436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08817365020513535
Epoch 0, Step 1412: train/loss = 0.39107996225357056, train/raw-loss = 0.2768888771533966, train/logprobs = tensor([[-1.5454, -3.7478],
        [-3.4016, -1.7224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11419111490249634
Epoch 0, Step 1413: train/loss = 0.45429062843322754, train/raw-loss = 0.3505600094795227, train/logprobs = tensor([[-0.9410, -3.6801],
        [-1.1455, -1.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10373061895370483
Epoch 0, Step 1414: train/loss = 0.49655094742774963, train/raw-loss = 0.3990294337272644, train/logprobs = tensor([[-0.9316, -5.2062],
        [-1.8809, -2.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09752148389816284
Epoch 0, Step 1415: train/loss = 0.7166001796722412, train/raw-loss = 0.6236212253570557, train/logprobs = tensor([[-1.0273, -3.0121],
        [-1.5478, -1.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09297899901866913
Epoch 0, Step 1416: train/loss = 0.47512197494506836, train/raw-loss = 0.3934999108314514, train/logprobs = tensor([[-1.0325, -3.3666],
        [-1.4247, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08162207156419754
Epoch 0, Step 1417: train/loss = 0.39226359128952026, train/raw-loss = 0.2941213846206665, train/logprobs = tensor([[-1.0140, -2.5946],
        [-2.2357, -0.9500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09814223647117615
Epoch 0, Step 1418: train/loss = 0.2569572329521179, train/raw-loss = 0.15237373113632202, train/logprobs = tensor([[-1.1956, -6.2779],
        [-2.5662, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10458351671695709
Epoch 0, Step 1419: train/loss = 0.5165234208106995, train/raw-loss = 0.4346141219139099, train/logprobs = tensor([[-0.7292, -3.3574],
        [-1.4424, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08190928399562836
Epoch 0, Step 1420: train/loss = 0.49136611819267273, train/raw-loss = 0.3846468925476074, train/logprobs = tensor([[-1.1026, -1.8068],
        [-2.4218, -0.8842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10671922564506531
Epoch 0, Step 1421: train/loss = 0.31260550022125244, train/raw-loss = 0.20830214023590088, train/logprobs = tensor([[-0.9037, -5.7923],
        [-1.9463, -1.8688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10430333763360977
Epoch 0, Step 1422: train/loss = 0.4451371133327484, train/raw-loss = 0.36011451482772827, train/logprobs = tensor([[-1.0165, -4.0550],
        [-1.2126, -1.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08502259850502014
Epoch 0, Step 1423: train/loss = 0.38167351484298706, train/raw-loss = 0.2811458110809326, train/logprobs = tensor([[-0.8777, -4.0025],
        [-1.9587, -1.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10052767395973206
Epoch 0, Step 1424: train/loss = 0.5220444202423096, train/raw-loss = 0.4374387860298157, train/logprobs = tensor([[-1.4038, -2.0867],
        [-2.0346, -1.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08460558950901031
Epoch 0, Step 1425: train/loss = 0.4850148558616638, train/raw-loss = 0.39508143067359924, train/logprobs = tensor([[-0.9018, -2.7767],
        [-1.1205, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08993344753980637
Epoch 0, Step 1426: train/loss = 0.5403206944465637, train/raw-loss = 0.44512322545051575, train/logprobs = tensor([[-1.0518, -1.8014],
        [-1.4797, -0.6561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09519746899604797
Epoch 0, Step 1427: train/loss = 0.6541860103607178, train/raw-loss = 0.5768783688545227, train/logprobs = tensor([[-1.8064, -4.9149],
        [-0.9713, -1.2256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07730764150619507
Epoch 0, Step 1428: train/loss = 0.5705803036689758, train/raw-loss = 0.46872830390930176, train/logprobs = tensor([[-1.0017, -3.1256],
        [-2.2711, -1.9743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10185202211141586
Epoch 0, Step 1429: train/loss = 0.5947593450546265, train/raw-loss = 0.47022366523742676, train/logprobs = tensor([[-1.4537, -3.6251],
        [-3.2372, -2.6424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12453562021255493
Epoch 0, Step 1430: train/loss = 0.35194137692451477, train/raw-loss = 0.24791577458381653, train/logprobs = tensor([[-1.0073, -6.1614],
        [-1.8278, -1.2810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10402558743953705
Epoch 0, Step 1431: train/loss = 0.32710951566696167, train/raw-loss = 0.20456983149051666, train/logprobs = tensor([[-1.2219, -4.2363],
        [-2.5071, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1225396990776062
Epoch 0, Step 1432: train/loss = 0.5202479958534241, train/raw-loss = 0.4426919221878052, train/logprobs = tensor([[-0.8975, -2.5420],
        [-1.0685, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07755608856678009
Epoch 0, Step 1433: train/loss = 0.5258682370185852, train/raw-loss = 0.4449244439601898, train/logprobs = tensor([[-1.0171, -2.9131],
        [-1.5048, -1.0751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08094380050897598
Epoch 0, Step 1434: train/loss = 0.4195397198200226, train/raw-loss = 0.33320915699005127, train/logprobs = tensor([[-1.0677, -3.0597],
        [-1.9205, -0.9700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08633057028055191
Epoch 0, Step 1435: train/loss = 0.569429874420166, train/raw-loss = 0.44947561621665955, train/logprobs = tensor([[-1.3411, -3.0482],
        [-2.2417, -2.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11995428800582886
Epoch 0, Step 1436: train/loss = 0.3654867112636566, train/raw-loss = 0.24844053387641907, train/logprobs = tensor([[-1.3085, -5.1586],
        [-2.8930, -1.7256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11704619228839874
Epoch 0, Step 1437: train/loss = 0.4378756284713745, train/raw-loss = 0.34532293677330017, train/logprobs = tensor([[-1.0869, -4.2746],
        [-1.6689, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09255272150039673
Epoch 0, Step 1438: train/loss = 0.3553071618080139, train/raw-loss = 0.24428428709506989, train/logprobs = tensor([[-1.1622, -3.9743],
        [-2.6009, -2.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11102285981178284
Epoch 0, Step 1439: train/loss = 0.43314433097839355, train/raw-loss = 0.3391537368297577, train/logprobs = tensor([[-1.1663, -4.7089],
        [-1.8289, -1.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09399058669805527
Epoch 0, Step 1440: train/loss = 0.5131466388702393, train/raw-loss = 0.3993948698043823, train/logprobs = tensor([[-1.1239, -2.0601],
        [-1.8748, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11375172436237335
Epoch 0, Step 1441: train/loss = 0.5541462898254395, train/raw-loss = 0.47082144021987915, train/logprobs = tensor([[-0.9248, -2.1227],
        [-1.5733, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08332483470439911
Epoch 0, Step 1442: train/loss = 0.39969098567962646, train/raw-loss = 0.2817276120185852, train/logprobs = tensor([[-1.3608, -2.2602],
        [-2.5976, -1.0986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11796335875988007
Epoch 0, Step 1443: train/loss = 0.5487611889839172, train/raw-loss = 0.42277222871780396, train/logprobs = tensor([[-1.6736, -3.0041],
        [-3.6831, -2.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259889155626297
Epoch 0, Step 1444: train/loss = 0.44319629669189453, train/raw-loss = 0.35371702909469604, train/logprobs = tensor([[-0.6693, -3.1206],
        [-0.9744, -1.0696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08947929739952087
Epoch 0, Step 1445: train/loss = 0.4566560387611389, train/raw-loss = 0.3718510568141937, train/logprobs = tensor([[-0.9240, -3.7865],
        [-1.3350, -1.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08480498939752579
Epoch 0, Step 1446: train/loss = 0.6033964157104492, train/raw-loss = 0.5028524994850159, train/logprobs = tensor([[-1.4687, -2.6043],
        [-1.6339, -1.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10054387897253036
Epoch 0, Step 1447: train/loss = 0.41906458139419556, train/raw-loss = 0.3284701406955719, train/logprobs = tensor([[-0.9246, -4.0571],
        [-1.1659, -1.2632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09059444069862366
Epoch 0, Step 1448: train/loss = 0.38531145453453064, train/raw-loss = 0.2809617519378662, train/logprobs = tensor([[-1.3740, -5.3318],
        [-2.2150, -1.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10434968024492264
Epoch 0, Step 1449: train/loss = 0.5173218250274658, train/raw-loss = 0.41898083686828613, train/logprobs = tensor([[-0.7530, -4.2867],
        [-1.0308, -1.4881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09834098815917969
Epoch 0, Step 1450: train/loss = 0.3890179395675659, train/raw-loss = 0.29101094603538513, train/logprobs = tensor([[-1.0308, -4.5055],
        [-1.1162, -1.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09800703078508377
Epoch 0, Step 1451: train/loss = 0.5377665758132935, train/raw-loss = 0.4608292579650879, train/logprobs = tensor([[-1.0447, -3.4386],
        [-1.3404, -1.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07693734765052795
Epoch 0, Step 1452: train/loss = 0.4428252577781677, train/raw-loss = 0.33298391103744507, train/logprobs = tensor([[-1.6298, -2.0907],
        [-2.7539, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10984134674072266
Epoch 0, Step 1453: train/loss = 0.3952394723892212, train/raw-loss = 0.28809627890586853, train/logprobs = tensor([[-1.2501, -3.4743],
        [-1.7936, -1.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10714319348335266
Epoch 0, Step 1454: train/loss = 0.528779149055481, train/raw-loss = 0.4513036906719208, train/logprobs = tensor([[-1.5445, -3.6352],
        [-1.0922, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0774754211306572
Epoch 0, Step 1455: train/loss = 0.4447993040084839, train/raw-loss = 0.3431139588356018, train/logprobs = tensor([[-1.4043, -3.4982],
        [-1.6726, -0.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10168536007404327
Epoch 0, Step 1456: train/loss = 0.40008193254470825, train/raw-loss = 0.3061094880104065, train/logprobs = tensor([[-0.9531, -3.0776],
        [-1.8471, -1.5802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397242963314056
Epoch 0, Step 1457: train/loss = 0.607454776763916, train/raw-loss = 0.5202349424362183, train/logprobs = tensor([[-1.2724, -4.1925],
        [-1.1608, -2.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08721989393234253
Epoch 0, Step 1458: train/loss = 0.3801008462905884, train/raw-loss = 0.2671239972114563, train/logprobs = tensor([[-1.2332, -4.9500],
        [-2.2603, -1.5907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11297683417797089
Epoch 0, Step 1459: train/loss = 0.36817261576652527, train/raw-loss = 0.2548348009586334, train/logprobs = tensor([[-1.2959, -3.8421],
        [-2.1637, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11333781480789185
Epoch 0, Step 1460: train/loss = 0.4607775807380676, train/raw-loss = 0.3852069675922394, train/logprobs = tensor([[-0.7959, -4.5062],
        [-0.8147, -1.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07557056844234467
Epoch 0, Step 1461: train/loss = 0.5418484210968018, train/raw-loss = 0.440959095954895, train/logprobs = tensor([[-1.1830, -4.5148],
        [-2.4976, -2.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10088931769132614
Epoch 0, Step 1462: train/loss = 0.47988390922546387, train/raw-loss = 0.3859077990055084, train/logprobs = tensor([[-0.9087, -3.4190],
        [-1.2677, -1.6825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09397608786821365
Epoch 0, Step 1463: train/loss = 0.47878164052963257, train/raw-loss = 0.39177417755126953, train/logprobs = tensor([[-1.1443, -4.8781],
        [-1.7849, -2.0709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08700745552778244
Epoch 0, Step 1464: train/loss = 0.4308984577655792, train/raw-loss = 0.3423924446105957, train/logprobs = tensor([[-1.1504, -3.9143],
        [-1.9752, -1.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08850601315498352
Epoch 0, Step 1465: train/loss = 0.6001813411712646, train/raw-loss = 0.49689504504203796, train/logprobs = tensor([[-1.5096, -1.7956],
        [-2.4987, -1.4471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10328628867864609
Epoch 0, Step 1466: train/loss = 0.5590302348136902, train/raw-loss = 0.44618287682533264, train/logprobs = tensor([[-1.0031, -2.7201],
        [-1.7532, -1.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11284738779067993
Epoch 0, Step 1467: train/loss = 0.4176948070526123, train/raw-loss = 0.2973317503929138, train/logprobs = tensor([[-1.0311, -3.1338],
        [-2.2358, -1.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12036304920911789
Epoch 0, Step 1468: train/loss = 0.5207338333129883, train/raw-loss = 0.41751065850257874, train/logprobs = tensor([[-0.9038, -2.6980],
        [-1.4764, -1.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10322312265634537
Epoch 0, Step 1469: train/loss = 0.49505317211151123, train/raw-loss = 0.42576393485069275, train/logprobs = tensor([[-0.5941, -3.7707],
        [-0.7371, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06928924471139908
Epoch 0, Step 1470: train/loss = 0.3912327289581299, train/raw-loss = 0.2905508577823639, train/logprobs = tensor([[-0.9782, -4.5696],
        [-1.3905, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068182647228241
Epoch 0, Step 1471: train/loss = 0.4599645733833313, train/raw-loss = 0.36352282762527466, train/logprobs = tensor([[-1.0324, -2.2782],
        [-2.0759, -1.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09644173085689545
Epoch 0, Step 1472: train/loss = 0.6263861656188965, train/raw-loss = 0.5350404977798462, train/logprobs = tensor([[-1.4003, -2.2485],
        [-1.8674, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0913456380367279
Epoch 0, Step 1473: train/loss = 0.43650317192077637, train/raw-loss = 0.34861788153648376, train/logprobs = tensor([[-0.9778, -3.7828],
        [-1.2197, -1.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0878853052854538
Epoch 0, Step 1474: train/loss = 0.5373144149780273, train/raw-loss = 0.4509371519088745, train/logprobs = tensor([[-1.2175, -1.7366],
        [-1.9918, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08637732267379761
Epoch 0, Step 1475: train/loss = 0.28464528918266296, train/raw-loss = 0.18131455779075623, train/logprobs = tensor([[-1.0929, -4.5876],
        [-2.1354, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10333070904016495
Epoch 0, Step 1476: train/loss = 0.4294039011001587, train/raw-loss = 0.3371482789516449, train/logprobs = tensor([[-1.3312, -3.9289],
        [-1.6333, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0922556221485138
Epoch 0, Step 1477: train/loss = 0.3490167260169983, train/raw-loss = 0.23321908712387085, train/logprobs = tensor([[-1.1104, -3.1510],
        [-2.2664, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579763144254684
Epoch 0, Step 1478: train/loss = 0.44944244623184204, train/raw-loss = 0.3635895848274231, train/logprobs = tensor([[-0.8833, -3.6642],
        [-1.1897, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08585284650325775
Epoch 0, Step 1479: train/loss = 0.3657371997833252, train/raw-loss = 0.2528061270713806, train/logprobs = tensor([[-1.4355, -4.6596],
        [-2.8425, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1129310354590416
Epoch 0, Step 1480: train/loss = 0.5808606147766113, train/raw-loss = 0.5021828413009644, train/logprobs = tensor([[-1.1741, -2.9796],
        [-0.8926, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07867778837680817
Epoch 0, Step 1481: train/loss = 0.4674641489982605, train/raw-loss = 0.39036262035369873, train/logprobs = tensor([[-0.7191, -3.3602],
        [-0.7621, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07710155844688416
Epoch 0, Step 1482: train/loss = 0.5302567481994629, train/raw-loss = 0.44772207736968994, train/logprobs = tensor([[-1.0417, -2.9509],
        [-1.3829, -0.9147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08253467828035355
Epoch 0, Step 1483: train/loss = 0.585469126701355, train/raw-loss = 0.5163465142250061, train/logprobs = tensor([[-0.6211, -2.4482],
        [-0.6457, -1.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06912264227867126
Epoch 0, Step 1484: train/loss = 0.36553359031677246, train/raw-loss = 0.2697170376777649, train/logprobs = tensor([[-0.8847, -4.2403],
        [-1.5706, -1.0882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09581653028726578
Epoch 0, Step 1485: train/loss = 0.537847638130188, train/raw-loss = 0.44426608085632324, train/logprobs = tensor([[-1.2263, -1.8272],
        [-1.9199, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09358158707618713
Epoch 0, Step 1486: train/loss = 0.4781655967235565, train/raw-loss = 0.36609742045402527, train/logprobs = tensor([[-0.9033, -3.3584],
        [-1.6893, -1.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11206817626953125
Epoch 0, Step 1487: train/loss = 0.41362428665161133, train/raw-loss = 0.31126245856285095, train/logprobs = tensor([[-1.2312, -4.5712],
        [-1.9803, -2.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10236186534166336
Epoch 0, Step 1488: train/loss = 0.3391152620315552, train/raw-loss = 0.22721563279628754, train/logprobs = tensor([[-1.0419, -4.3392],
        [-1.8496, -1.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11189963668584824
Epoch 0, Step 1489: train/loss = 0.4684988856315613, train/raw-loss = 0.373725563287735, train/logprobs = tensor([[-1.0635, -2.8547],
        [-2.1299, -1.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09477326273918152
Epoch 0, Step 1490: train/loss = 0.6390033960342407, train/raw-loss = 0.5333671569824219, train/logprobs = tensor([[-1.2194, -1.2588],
        [-1.6300, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10563626140356064
Epoch 0, Step 1491: train/loss = 0.46962130069732666, train/raw-loss = 0.36332404613494873, train/logprobs = tensor([[-0.7902, -3.0489],
        [-1.6431, -1.4621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10629726946353912
Epoch 0, Step 1492: train/loss = 0.5397213697433472, train/raw-loss = 0.4343933165073395, train/logprobs = tensor([[-1.0525, -3.7116],
        [-2.0394, -1.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1053280234336853
Epoch 0, Step 1493: train/loss = 0.2941131293773651, train/raw-loss = 0.18489161133766174, train/logprobs = tensor([[-1.4240, -4.4080],
        [-2.8715, -1.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10922151803970337
Epoch 0, Step 1494: train/loss = 0.6846915483474731, train/raw-loss = 0.602324903011322, train/logprobs = tensor([[-1.2111, -2.0997],
        [-0.8621, -0.8661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08236665278673172
Epoch 0, Step 1495: train/loss = 0.3160356283187866, train/raw-loss = 0.19956074655056, train/logprobs = tensor([[-2.0165, -3.4599],
        [-3.5707, -1.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11647485941648483
Epoch 0, Step 1496: train/loss = 0.5510976314544678, train/raw-loss = 0.4711708128452301, train/logprobs = tensor([[-1.1027, -4.1007],
        [-0.9677, -1.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07992682605981827
Epoch 0, Step 1497: train/loss = 0.3119019865989685, train/raw-loss = 0.2115405797958374, train/logprobs = tensor([[-1.2367, -4.1558],
        [-2.3697, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003614217042923
Epoch 0, Step 1498: train/loss = 0.3623775243759155, train/raw-loss = 0.2535841464996338, train/logprobs = tensor([[-1.1774, -3.5757],
        [-1.9953, -1.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10879334807395935
Epoch 0, Step 1499: train/loss = 0.48038193583488464, train/raw-loss = 0.38205593824386597, train/logprobs = tensor([[-1.2948, -3.4054],
        [-1.6895, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09832601249217987
eval/loss: 0.4684586524963379
Epoch 0, Step 1500: train/loss = 0.39736634492874146, train/raw-loss = 0.2995360791683197, train/logprobs = tensor([[-1.3981, -3.2830],
        [-2.2053, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09783026576042175
Epoch 0, Step 1501: train/loss = 0.40403953194618225, train/raw-loss = 0.2870073616504669, train/logprobs = tensor([[-1.4634, -4.4753],
        [-3.0353, -1.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11703215539455414
Epoch 0, Step 1502: train/loss = 0.4585631787776947, train/raw-loss = 0.3748714029788971, train/logprobs = tensor([[-0.8578, -3.3778],
        [-1.3659, -1.0973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836917832493782
Epoch 0, Step 1503: train/loss = 0.6334725022315979, train/raw-loss = 0.5477340221405029, train/logprobs = tensor([[-1.7777, -2.8114],
        [-1.1873, -0.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08573849499225616
Epoch 0, Step 1504: train/loss = 0.4314309358596802, train/raw-loss = 0.3322126269340515, train/logprobs = tensor([[-0.9196, -3.4054],
        [-1.7920, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09921828657388687
Epoch 0, Step 1505: train/loss = 0.38948893547058105, train/raw-loss = 0.2789255380630493, train/logprobs = tensor([[-1.0001, -2.8248],
        [-2.3804, -1.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11056340485811234
Epoch 0, Step 1506: train/loss = 0.5275359749794006, train/raw-loss = 0.44544681906700134, train/logprobs = tensor([[-0.8206, -3.8929],
        [-0.9167, -1.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08208917081356049
Epoch 0, Step 1507: train/loss = 0.4455444812774658, train/raw-loss = 0.3444092571735382, train/logprobs = tensor([[-0.8232, -4.5136],
        [-1.2125, -1.3458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10113522410392761
Epoch 0, Step 1508: train/loss = 0.37563538551330566, train/raw-loss = 0.25757330656051636, train/logprobs = tensor([[-1.2402, -3.9190],
        [-2.6022, -1.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1180620864033699
Epoch 0, Step 1509: train/loss = 0.4389761686325073, train/raw-loss = 0.3426346182823181, train/logprobs = tensor([[-1.1193, -3.4814],
        [-1.7232, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963415801525116
Epoch 0, Step 1510: train/loss = 0.41959744691848755, train/raw-loss = 0.3387463688850403, train/logprobs = tensor([[-0.8323, -5.1456],
        [-1.1171, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08085107058286667
Epoch 0, Step 1511: train/loss = 0.4349333941936493, train/raw-loss = 0.34198519587516785, train/logprobs = tensor([[-0.9381, -4.5472],
        [-1.1514, -1.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09294821321964264
Epoch 0, Step 1512: train/loss = 0.5024116635322571, train/raw-loss = 0.3933370113372803, train/logprobs = tensor([[-1.0362, -2.8871],
        [-1.1514, -0.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907460749149323
Epoch 0, Step 1513: train/loss = 0.6453702449798584, train/raw-loss = 0.5499860644340515, train/logprobs = tensor([[-0.8150, -2.8911],
        [-1.1769, -1.6192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09538422524929047
Epoch 0, Step 1514: train/loss = 0.4573150873184204, train/raw-loss = 0.36075329780578613, train/logprobs = tensor([[-1.0106, -2.9516],
        [-2.1484, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09656179696321487
Epoch 0, Step 1515: train/loss = 0.3899390697479248, train/raw-loss = 0.30407556891441345, train/logprobs = tensor([[-1.0749, -3.9135],
        [-1.3984, -1.5175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08586347103118896
Epoch 0, Step 1516: train/loss = 0.523445725440979, train/raw-loss = 0.40478208661079407, train/logprobs = tensor([[-1.0861, -1.7969],
        [-1.9636, -1.0858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11866363883018494
Epoch 0, Step 1517: train/loss = 0.4284816086292267, train/raw-loss = 0.33128196001052856, train/logprobs = tensor([[-1.1922, -4.3248],
        [-1.5573, -1.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09719962626695633
Epoch 0, Step 1518: train/loss = 0.6106665730476379, train/raw-loss = 0.4855639338493347, train/logprobs = tensor([[-1.3482, -4.5114],
        [-2.1410, -2.4047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12510265409946442
Epoch 0, Step 1519: train/loss = 0.4063267409801483, train/raw-loss = 0.31394463777542114, train/logprobs = tensor([[-0.9261, -3.8658],
        [-1.5420, -1.2476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09238211065530777
Epoch 0, Step 1520: train/loss = 0.39583122730255127, train/raw-loss = 0.2827947437763214, train/logprobs = tensor([[-1.2193, -5.1737],
        [-2.3617, -1.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11303645372390747
Epoch 0, Step 1521: train/loss = 0.6032912135124207, train/raw-loss = 0.5024524927139282, train/logprobs = tensor([[-1.0678, -2.2182],
        [-1.1372, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10083869099617004
Epoch 0, Step 1522: train/loss = 0.3505629301071167, train/raw-loss = 0.24631571769714355, train/logprobs = tensor([[-0.9510, -3.6130],
        [-1.6776, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10424719750881195
Epoch 0, Step 1523: train/loss = 0.6491986513137817, train/raw-loss = 0.5563514232635498, train/logprobs = tensor([[-1.2521, -1.6016],
        [-1.4277, -0.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09284719079732895
Epoch 0, Step 1524: train/loss = 0.39153242111206055, train/raw-loss = 0.27526021003723145, train/logprobs = tensor([[-1.3747, -4.4065],
        [-3.1244, -2.4462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1162722110748291
Epoch 0, Step 1525: train/loss = 0.6152634620666504, train/raw-loss = 0.5347012281417847, train/logprobs = tensor([[-0.8200, -1.7184],
        [-0.9415, -0.8514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08056226372718811
Epoch 0, Step 1526: train/loss = 0.3603311777114868, train/raw-loss = 0.2555946707725525, train/logprobs = tensor([[-1.5641, -5.6963],
        [-2.4767, -1.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10473649203777313
Epoch 0, Step 1527: train/loss = 0.5913234949111938, train/raw-loss = 0.4774280786514282, train/logprobs = tensor([[-1.6383, -3.6388],
        [-3.2615, -2.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1138954609632492
Epoch 0, Step 1528: train/loss = 0.4089811146259308, train/raw-loss = 0.29881301522254944, train/logprobs = tensor([[-0.9506, -2.7801],
        [-2.1372, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11016808450222015
Epoch 0, Step 1529: train/loss = 0.3966025412082672, train/raw-loss = 0.28697845339775085, train/logprobs = tensor([[-1.3147, -3.9551],
        [-2.3667, -1.4397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10962408035993576
Epoch 0, Step 1530: train/loss = 0.472057044506073, train/raw-loss = 0.37465572357177734, train/logprobs = tensor([[-1.2725, -4.6676],
        [-2.5652, -2.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09740134328603745
Epoch 0, Step 1531: train/loss = 0.2606566846370697, train/raw-loss = 0.14709430932998657, train/logprobs = tensor([[-0.9950, -6.0019],
        [-2.4386, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11356234550476074
Epoch 0, Step 1532: train/loss = 0.4261811673641205, train/raw-loss = 0.32719308137893677, train/logprobs = tensor([[-1.4159, -3.6740],
        [-1.8012, -1.4184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0989881157875061
Epoch 0, Step 1533: train/loss = 0.4831981062889099, train/raw-loss = 0.3865933120250702, train/logprobs = tensor([[-0.9134, -3.5366],
        [-1.1767, -1.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09660474956035614
Epoch 0, Step 1534: train/loss = 0.40867945551872253, train/raw-loss = 0.3304439187049866, train/logprobs = tensor([[-1.1060, -3.7431],
        [-2.0905, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07823552936315536
Epoch 0, Step 1535: train/loss = 0.33056434988975525, train/raw-loss = 0.16991478204727173, train/logprobs = tensor([[-1.5526, -5.5924],
        [-3.6694, -2.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16064955294132233
Epoch 0, Step 1536: train/loss = 0.5763502717018127, train/raw-loss = 0.4864465296268463, train/logprobs = tensor([[-1.0354, -1.2255],
        [-1.5755, -0.6995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08990374952554703
Epoch 0, Step 1537: train/loss = 0.2684909403324127, train/raw-loss = 0.15303263068199158, train/logprobs = tensor([[-1.3741, -5.2291],
        [-2.7806, -1.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11545830965042114
Epoch 0, Step 1538: train/loss = 0.5814487934112549, train/raw-loss = 0.46506211161613464, train/logprobs = tensor([[-0.9086, -3.1765],
        [-2.4137, -1.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11638669669628143
Epoch 0, Step 1539: train/loss = 0.4320494532585144, train/raw-loss = 0.35853850841522217, train/logprobs = tensor([[-0.7140, -4.5944],
        [-1.1861, -1.4273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07351092994213104
Epoch 0, Step 1540: train/loss = 0.3121381402015686, train/raw-loss = 0.21103015542030334, train/logprobs = tensor([[-1.3579, -5.6582],
        [-2.5573, -1.2530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10110796988010406
Epoch 0, Step 1541: train/loss = 0.4233722984790802, train/raw-loss = 0.3147847354412079, train/logprobs = tensor([[-1.3648, -3.7539],
        [-2.2099, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10858754813671112
Epoch 0, Step 1542: train/loss = 0.44317182898521423, train/raw-loss = 0.3670666813850403, train/logprobs = tensor([[-0.9903, -2.9547],
        [-1.5737, -1.4769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07610514014959335
Epoch 0, Step 1543: train/loss = 0.6735321283340454, train/raw-loss = 0.5932978391647339, train/logprobs = tensor([[-1.2881, -1.3950],
        [-1.2579, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08023427426815033
Epoch 0, Step 1544: train/loss = 0.3110049366950989, train/raw-loss = 0.1965322345495224, train/logprobs = tensor([[-1.2028, -5.5826],
        [-2.2465, -1.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11447270214557648
Epoch 0, Step 1545: train/loss = 0.7212352156639099, train/raw-loss = 0.6093427538871765, train/logprobs = tensor([[-1.5155, -2.2689],
        [-1.9445, -2.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11189249902963638
Epoch 0, Step 1546: train/loss = 0.35485386848449707, train/raw-loss = 0.24482259154319763, train/logprobs = tensor([[-0.8323, -5.4714],
        [-1.2217, -1.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11003129184246063
Epoch 0, Step 1547: train/loss = 0.4432905614376068, train/raw-loss = 0.3529442846775055, train/logprobs = tensor([[-1.0126, -5.1338],
        [-1.2502, -1.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09034627676010132
Epoch 0, Step 1548: train/loss = 0.29191696643829346, train/raw-loss = 0.19161513447761536, train/logprobs = tensor([[-1.2485, -4.2278],
        [-2.3134, -1.5920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003018468618393
Epoch 0, Step 1549: train/loss = 0.7035614252090454, train/raw-loss = 0.6003400087356567, train/logprobs = tensor([[-1.9591, -3.1229],
        [-1.3626, -1.3252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10322144627571106
Epoch 0, Step 1550: train/loss = 0.5585797429084778, train/raw-loss = 0.4824274480342865, train/logprobs = tensor([[-1.1359, -3.9233],
        [-1.0132, -1.4601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615229487419128
Epoch 0, Step 1551: train/loss = 0.41269904375076294, train/raw-loss = 0.34975871443748474, train/logprobs = tensor([[-0.7801, -4.8445],
        [-0.7251, -1.4625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0629403293132782
Epoch 0, Step 1552: train/loss = 0.3102923035621643, train/raw-loss = 0.19913478195667267, train/logprobs = tensor([[-1.2211, -5.8307],
        [-2.1500, -1.5361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11115751415491104
Epoch 0, Step 1553: train/loss = 0.47598129510879517, train/raw-loss = 0.37565770745277405, train/logprobs = tensor([[-0.8366, -2.5319],
        [-1.3119, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1003236174583435
Epoch 0, Step 1554: train/loss = 0.5588905811309814, train/raw-loss = 0.4628676474094391, train/logprobs = tensor([[-0.7640, -2.1509],
        [-1.0059, -0.8928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09602293372154236
Epoch 0, Step 1555: train/loss = 0.33953002095222473, train/raw-loss = 0.2417973279953003, train/logprobs = tensor([[-1.1780, -6.1141],
        [-1.8255, -1.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773270785808563
Epoch 0, Step 1556: train/loss = 0.5199046730995178, train/raw-loss = 0.4178099036216736, train/logprobs = tensor([[-1.0622, -5.3240],
        [-1.4299, -2.0235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10209483653306961
Epoch 0, Step 1557: train/loss = 0.5394810438156128, train/raw-loss = 0.4615672528743744, train/logprobs = tensor([[-0.8351, -2.7897],
        [-0.8348, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07791382074356079
Epoch 0, Step 1558: train/loss = 0.33637019991874695, train/raw-loss = 0.2614082992076874, train/logprobs = tensor([[-1.1722, -6.7577],
        [-1.7180, -2.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07496191561222076
Epoch 0, Step 1559: train/loss = 0.4397280216217041, train/raw-loss = 0.3434367775917053, train/logprobs = tensor([[-0.6854, -4.7659],
        [-1.0717, -1.2604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0962912067770958
Epoch 0, Step 1560: train/loss = 0.5531330108642578, train/raw-loss = 0.47085779905319214, train/logprobs = tensor([[-1.0809, -3.3152],
        [-1.2646, -1.6076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08227520436048508
Epoch 0, Step 1561: train/loss = 0.5026788115501404, train/raw-loss = 0.42251282930374146, train/logprobs = tensor([[-0.8420, -3.3618],
        [-1.9202, -1.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08016595989465714
Epoch 0, Step 1562: train/loss = 0.5954199433326721, train/raw-loss = 0.5080000162124634, train/logprobs = tensor([[-1.1274, -3.6909],
        [-1.5287, -1.8063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08741998672485352
Epoch 0, Step 1563: train/loss = 0.445551335811615, train/raw-loss = 0.3765418529510498, train/logprobs = tensor([[-0.9129, -5.1493],
        [-0.7675, -0.9634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06900951266288757
Epoch 0, Step 1564: train/loss = 0.5818043947219849, train/raw-loss = 0.49573808908462524, train/logprobs = tensor([[-0.9175, -3.7965],
        [-1.0554, -2.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08606629073619843
Epoch 0, Step 1565: train/loss = 0.3897363543510437, train/raw-loss = 0.2780480682849884, train/logprobs = tensor([[-1.2386, -4.4956],
        [-1.8744, -1.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11168825626373291
Epoch 0, Step 1566: train/loss = 0.46942591667175293, train/raw-loss = 0.39093440771102905, train/logprobs = tensor([[-0.6373, -3.6516],
        [-0.7244, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07849155366420746
Epoch 0, Step 1567: train/loss = 0.4659881889820099, train/raw-loss = 0.3806409239768982, train/logprobs = tensor([[-1.2260, -3.4497],
        [-1.7744, -1.3714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08534727245569229
Epoch 0, Step 1568: train/loss = 0.5050632357597351, train/raw-loss = 0.40940409898757935, train/logprobs = tensor([[-0.8474, -2.4347],
        [-1.3822, -0.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09565910696983337
Epoch 0, Step 1569: train/loss = 0.5664963722229004, train/raw-loss = 0.47469884157180786, train/logprobs = tensor([[-0.9527, -2.1763],
        [-1.6012, -1.2057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09179751574993134
Epoch 0, Step 1570: train/loss = 0.4398106336593628, train/raw-loss = 0.34441274404525757, train/logprobs = tensor([[-1.3174, -3.6607],
        [-2.0589, -1.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539788961410522
Epoch 0, Step 1571: train/loss = 0.5575350522994995, train/raw-loss = 0.4586452543735504, train/logprobs = tensor([[-1.1576, -2.5413],
        [-1.9015, -1.5384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09888976812362671
Epoch 0, Step 1572: train/loss = 0.47793352603912354, train/raw-loss = 0.3696748614311218, train/logprobs = tensor([[-1.0412, -4.8326],
        [-1.5212, -1.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10825865715742111
Epoch 0, Step 1573: train/loss = 0.39848893880844116, train/raw-loss = 0.2954065203666687, train/logprobs = tensor([[-0.9911, -2.9784],
        [-2.2983, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10308238863945007
Epoch 0, Step 1574: train/loss = 0.652617335319519, train/raw-loss = 0.5706318616867065, train/logprobs = tensor([[-1.3321, -2.9100],
        [-1.6603, -1.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0819854736328125
Epoch 0, Step 1575: train/loss = 0.4236348569393158, train/raw-loss = 0.28314054012298584, train/logprobs = tensor([[-1.4283, -4.0693],
        [-3.4373, -2.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14049431681632996
Epoch 0, Step 1576: train/loss = 0.392028272151947, train/raw-loss = 0.2605282664299011, train/logprobs = tensor([[-1.3771, -3.0860],
        [-2.6255, -1.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1315000057220459
Epoch 0, Step 1577: train/loss = 0.4131111204624176, train/raw-loss = 0.27718889713287354, train/logprobs = tensor([[-1.2038, -4.0089],
        [-2.7170, -1.6317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13592222332954407
Epoch 0, Step 1578: train/loss = 0.3735305070877075, train/raw-loss = 0.25373589992523193, train/logprobs = tensor([[-1.1809, -3.9931],
        [-2.6012, -1.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1197945848107338
Epoch 0, Step 1579: train/loss = 0.25563305616378784, train/raw-loss = 0.13622979819774628, train/logprobs = tensor([[-1.1358, -5.4817],
        [-2.7653, -1.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11940328031778336
Epoch 0, Step 1580: train/loss = 0.43828320503234863, train/raw-loss = 0.3497507572174072, train/logprobs = tensor([[-0.7934, -3.3208],
        [-0.9924, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885324478149414
Epoch 0, Step 1581: train/loss = 0.4032331109046936, train/raw-loss = 0.32928475737571716, train/logprobs = tensor([[-0.9425, -4.0343],
        [-0.9317, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07394834607839584
Epoch 0, Step 1582: train/loss = 0.41874295473098755, train/raw-loss = 0.35180309414863586, train/logprobs = tensor([[-0.6840, -3.4781],
        [-0.7574, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06693987548351288
Epoch 0, Step 1583: train/loss = 0.44893956184387207, train/raw-loss = 0.36540815234184265, train/logprobs = tensor([[-0.5947, -4.1576],
        [-0.8152, -1.4313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08353140950202942
Epoch 0, Step 1584: train/loss = 0.40498828887939453, train/raw-loss = 0.3201902210712433, train/logprobs = tensor([[-1.0127, -4.5852],
        [-1.0098, -1.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08479803800582886
Epoch 0, Step 1585: train/loss = 0.5438137054443359, train/raw-loss = 0.4451780617237091, train/logprobs = tensor([[-1.4287, -2.8058],
        [-2.2612, -1.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09863564372062683
Epoch 0, Step 1586: train/loss = 0.4457186162471771, train/raw-loss = 0.34556666016578674, train/logprobs = tensor([[-1.1387, -3.1938],
        [-1.6195, -0.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10015193372964859
Epoch 0, Step 1587: train/loss = 0.7495461702346802, train/raw-loss = 0.6734229922294617, train/logprobs = tensor([[-2.0056, -4.5835],
        [-1.4676, -2.2175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07612322270870209
Epoch 0, Step 1588: train/loss = 0.43168747425079346, train/raw-loss = 0.34128808975219727, train/logprobs = tensor([[-1.3647, -3.4512],
        [-2.0398, -1.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09039942175149918
Epoch 0, Step 1589: train/loss = 0.5274187326431274, train/raw-loss = 0.4491119086742401, train/logprobs = tensor([[-1.0417, -3.0323],
        [-1.0534, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07830679416656494
Epoch 0, Step 1590: train/loss = 0.5429932475090027, train/raw-loss = 0.45146387815475464, train/logprobs = tensor([[-0.8098, -1.8099],
        [-1.3838, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09152936935424805
Epoch 0, Step 1591: train/loss = 0.6245194673538208, train/raw-loss = 0.5557750463485718, train/logprobs = tensor([[-0.5435, -1.3749],
        [-0.7130, -0.6753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06874437630176544
Epoch 0, Step 1592: train/loss = 0.41109147667884827, train/raw-loss = 0.2964746952056885, train/logprobs = tensor([[-1.7146, -2.5661],
        [-3.3266, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1146167516708374
Epoch 0, Step 1593: train/loss = 0.5181058645248413, train/raw-loss = 0.4175560772418976, train/logprobs = tensor([[-0.9895, -1.9823],
        [-1.5464, -0.6269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10054974257946014
Epoch 0, Step 1594: train/loss = 0.40456444025039673, train/raw-loss = 0.31633955240249634, train/logprobs = tensor([[-1.0693, -2.2789],
        [-2.4768, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08822489529848099
Epoch 0, Step 1595: train/loss = 0.5985394716262817, train/raw-loss = 0.502877950668335, train/logprobs = tensor([[-0.9247, -1.8089],
        [-1.7590, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09566152095794678
Epoch 0, Step 1596: train/loss = 0.5038967728614807, train/raw-loss = 0.381229966878891, train/logprobs = tensor([[-0.6746, -2.3083],
        [-1.7202, -0.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12266677618026733
Epoch 0, Step 1597: train/loss = 0.4243391156196594, train/raw-loss = 0.3385261297225952, train/logprobs = tensor([[-1.8550, -6.0112],
        [-2.2415, -1.5402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08581303060054779
Epoch 0, Step 1598: train/loss = 0.5106343626976013, train/raw-loss = 0.4164707064628601, train/logprobs = tensor([[-1.5560, -2.4648],
        [-2.8223, -1.3561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0941636711359024
Epoch 0, Step 1599: train/loss = 0.4599609076976776, train/raw-loss = 0.3632364273071289, train/logprobs = tensor([[-1.0137, -5.7479],
        [-2.1357, -1.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09672443568706512
Epoch 0, Step 1600: train/loss = 0.3160938322544098, train/raw-loss = 0.21312937140464783, train/logprobs = tensor([[-1.6661, -7.1709],
        [-2.7037, -2.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10296446830034256
Epoch 0, Step 1601: train/loss = 0.43120908737182617, train/raw-loss = 0.33323246240615845, train/logprobs = tensor([[-1.1230, -4.5693],
        [-1.6654, -1.4194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09797661006450653
Epoch 0, Step 1602: train/loss = 0.500764787197113, train/raw-loss = 0.41917020082473755, train/logprobs = tensor([[-1.4261, -4.2313],
        [-1.5575, -1.3894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0815945714712143
Epoch 0, Step 1603: train/loss = 0.45081618428230286, train/raw-loss = 0.35171398520469666, train/logprobs = tensor([[-0.7224, -3.0486],
        [-1.2851, -0.9390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0991022139787674
Epoch 0, Step 1604: train/loss = 0.4480017423629761, train/raw-loss = 0.3658663034439087, train/logprobs = tensor([[-0.9744, -3.8443],
        [-1.3865, -2.1737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08213545382022858
Epoch 0, Step 1605: train/loss = 0.54402756690979, train/raw-loss = 0.4493921101093292, train/logprobs = tensor([[-1.6413, -3.0032],
        [-1.8903, -1.8040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09463545680046082
Epoch 0, Step 1606: train/loss = 0.43231362104415894, train/raw-loss = 0.3328070640563965, train/logprobs = tensor([[-1.4548, -3.1796],
        [-2.3776, -0.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09950656443834305
Epoch 0, Step 1607: train/loss = 0.43173152208328247, train/raw-loss = 0.3272136449813843, train/logprobs = tensor([[-1.0321, -4.0364],
        [-1.4740, -1.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10451788455247879
Epoch 0, Step 1608: train/loss = 0.26904234290122986, train/raw-loss = 0.1534503549337387, train/logprobs = tensor([[-1.5995, -5.0163],
        [-2.9196, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11559201031923294
Epoch 0, Step 1609: train/loss = 0.6751867532730103, train/raw-loss = 0.5902912020683289, train/logprobs = tensor([[-1.4436, -2.2299],
        [-1.5255, -1.5547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08489556610584259
Epoch 0, Step 1610: train/loss = 0.3294798731803894, train/raw-loss = 0.21307732164859772, train/logprobs = tensor([[-1.0998, -3.4683],
        [-3.0530, -1.5691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11640255898237228
Epoch 0, Step 1611: train/loss = 0.41743147373199463, train/raw-loss = 0.33050522208213806, train/logprobs = tensor([[-0.7694, -3.4993],
        [-1.3733, -1.4474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08692623674869537
Epoch 0, Step 1612: train/loss = 0.30622053146362305, train/raw-loss = 0.2212333381175995, train/logprobs = tensor([[-1.1467, -7.4009],
        [-1.7707, -2.6463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08498720824718475
Epoch 0, Step 1613: train/loss = 0.414813756942749, train/raw-loss = 0.34213536977767944, train/logprobs = tensor([[-0.6676, -5.0088],
        [-0.8791, -1.4515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07267842441797256
Epoch 0, Step 1614: train/loss = 0.39933186769485474, train/raw-loss = 0.29335159063339233, train/logprobs = tensor([[-0.8794, -5.7161],
        [-1.3482, -1.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10598025470972061
Epoch 0, Step 1615: train/loss = 0.37237152457237244, train/raw-loss = 0.30545827746391296, train/logprobs = tensor([[-0.5771, -4.8830],
        [-0.6461, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06691323965787888
Epoch 0, Step 1616: train/loss = 0.4375889301300049, train/raw-loss = 0.3300529420375824, train/logprobs = tensor([[-1.5575, -4.6990],
        [-2.6719, -1.5459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10753601044416428
Epoch 0, Step 1617: train/loss = 0.5118170976638794, train/raw-loss = 0.4133422076702118, train/logprobs = tensor([[-0.8822, -3.0464],
        [-1.2649, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09847486019134521
Epoch 0, Step 1618: train/loss = 0.5168819427490234, train/raw-loss = 0.4063803255558014, train/logprobs = tensor([[-0.9689, -2.8693],
        [-1.8250, -0.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11050159484148026
Epoch 0, Step 1619: train/loss = 0.539501428604126, train/raw-loss = 0.4346725046634674, train/logprobs = tensor([[-0.7604, -2.7491],
        [-1.1284, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1048288643360138
Epoch 0, Step 1620: train/loss = 0.46685463190078735, train/raw-loss = 0.34648576378822327, train/logprobs = tensor([[-1.1411, -3.1468],
        [-1.8420, -1.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1203688383102417
Epoch 0, Step 1621: train/loss = 0.31179556250572205, train/raw-loss = 0.20508065819740295, train/logprobs = tensor([[-1.3915, -5.4274],
        [-2.3504, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1067148968577385
Epoch 0, Step 1622: train/loss = 0.5062832236289978, train/raw-loss = 0.39519980549812317, train/logprobs = tensor([[-1.5212, -2.8200],
        [-2.5675, -1.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11108339577913284
Epoch 0, Step 1623: train/loss = 0.2884055972099304, train/raw-loss = 0.17683513462543488, train/logprobs = tensor([[-1.0176, -5.4096],
        [-2.1367, -1.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11157047003507614
Epoch 0, Step 1624: train/loss = 0.49325451254844666, train/raw-loss = 0.39855295419692993, train/logprobs = tensor([[-0.9884, -3.4429],
        [-2.4636, -1.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09470155090093613
Epoch 0, Step 1625: train/loss = 0.4610236883163452, train/raw-loss = 0.37353837490081787, train/logprobs = tensor([[-0.9116, -2.6764],
        [-1.7232, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08748537302017212
Epoch 0, Step 1626: train/loss = 0.48474326729774475, train/raw-loss = 0.407951682806015, train/logprobs = tensor([[-0.7473, -3.7244],
        [-1.0351, -1.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07679153978824615
Epoch 0, Step 1627: train/loss = 0.41314777731895447, train/raw-loss = 0.302060604095459, train/logprobs = tensor([[-1.1479, -4.4705],
        [-1.9675, -1.3393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11108721792697906
Epoch 0, Step 1628: train/loss = 0.3926428556442261, train/raw-loss = 0.2985757291316986, train/logprobs = tensor([[-1.3022, -4.7151],
        [-2.4477, -2.2197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09406711161136627
Epoch 0, Step 1629: train/loss = 0.49394896626472473, train/raw-loss = 0.40618452429771423, train/logprobs = tensor([[-0.8085, -2.8281],
        [-1.0745, -0.8197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08776446431875229
Epoch 0, Step 1630: train/loss = 0.5802529454231262, train/raw-loss = 0.47716206312179565, train/logprobs = tensor([[-1.0458, -2.6510],
        [-1.7757, -1.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309088230133057
Epoch 0, Step 1631: train/loss = 0.5531622171401978, train/raw-loss = 0.48864468932151794, train/logprobs = tensor([[-0.9576, -3.1126],
        [-0.8162, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06451757252216339
Epoch 0, Step 1632: train/loss = 0.3405417799949646, train/raw-loss = 0.2035353183746338, train/logprobs = tensor([[-1.5449, -3.5768],
        [-3.7084, -2.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13700643181800842
Epoch 0, Step 1633: train/loss = 0.42372483015060425, train/raw-loss = 0.331625759601593, train/logprobs = tensor([[-1.1410, -2.9036],
        [-1.9475, -1.3205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09209903329610825
Epoch 0, Step 1634: train/loss = 0.40441077947616577, train/raw-loss = 0.3120298683643341, train/logprobs = tensor([[-1.2244, -5.3289],
        [-1.7944, -2.1284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09238088876008987
Epoch 0, Step 1635: train/loss = 0.36976298689842224, train/raw-loss = 0.256069153547287, train/logprobs = tensor([[-1.2870, -3.6708],
        [-2.5275, -1.5868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11369384825229645
Epoch 0, Step 1636: train/loss = 0.4831607937812805, train/raw-loss = 0.3695158362388611, train/logprobs = tensor([[-1.3904, -4.1734],
        [-2.5094, -2.1572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11364494264125824
Epoch 0, Step 1637: train/loss = 0.4023554027080536, train/raw-loss = 0.3092559278011322, train/logprobs = tensor([[-1.0624, -3.7618],
        [-1.9530, -1.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09309946000576019
Epoch 0, Step 1638: train/loss = 0.4422745406627655, train/raw-loss = 0.3581758141517639, train/logprobs = tensor([[-1.3519, -2.8485],
        [-1.4899, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08409871906042099
Epoch 0, Step 1639: train/loss = 0.35787421464920044, train/raw-loss = 0.2521476745605469, train/logprobs = tensor([[-0.9946, -3.0840],
        [-2.2431, -0.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10572649538516998
Epoch 0, Step 1640: train/loss = 0.5150764584541321, train/raw-loss = 0.3963484466075897, train/logprobs = tensor([[-1.3715, -3.7368],
        [-3.1056, -2.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872801929712296
Epoch 0, Step 1641: train/loss = 0.39512985944747925, train/raw-loss = 0.3080042898654938, train/logprobs = tensor([[-0.9285, -4.7439],
        [-1.1690, -1.3710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08712558448314667
Epoch 0, Step 1642: train/loss = 0.4116320312023163, train/raw-loss = 0.31705862283706665, train/logprobs = tensor([[-1.4297, -4.7207],
        [-2.3844, -1.4744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09457342326641083
Epoch 0, Step 1643: train/loss = 0.3946763277053833, train/raw-loss = 0.29818010330200195, train/logprobs = tensor([[-1.3706, -5.3702],
        [-2.1931, -1.7757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09649620950222015
Epoch 0, Step 1644: train/loss = 0.5825798511505127, train/raw-loss = 0.4583183526992798, train/logprobs = tensor([[-1.1594, -4.2876],
        [-2.0637, -2.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12426144629716873
Epoch 0, Step 1645: train/loss = 0.520088791847229, train/raw-loss = 0.411531925201416, train/logprobs = tensor([[-1.2531, -2.7624],
        [-2.8401, -2.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10855689644813538
Epoch 0, Step 1646: train/loss = 0.628896176815033, train/raw-loss = 0.5223149657249451, train/logprobs = tensor([[-1.6466, -1.9946],
        [-2.8592, -2.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10658124089241028
Epoch 0, Step 1647: train/loss = 0.7320220470428467, train/raw-loss = 0.6399827003479004, train/logprobs = tensor([[-1.2075, -1.9923],
        [-2.5142, -2.3044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09203935414552689
Epoch 0, Step 1648: train/loss = 0.3255453109741211, train/raw-loss = 0.19948755204677582, train/logprobs = tensor([[-1.5704, -4.4799],
        [-3.3520, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12605777382850647
Epoch 0, Step 1649: train/loss = 0.40756654739379883, train/raw-loss = 0.29000043869018555, train/logprobs = tensor([[-1.4836, -3.4605],
        [-2.9349, -1.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756613850593567
Epoch 0, Step 1650: train/loss = 0.5685409307479858, train/raw-loss = 0.4893409311771393, train/logprobs = tensor([[-1.2023, -2.3047],
        [-1.2003, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07920005172491074
Epoch 0, Step 1651: train/loss = 0.582474946975708, train/raw-loss = 0.4999086558818817, train/logprobs = tensor([[-1.8916, -4.2233],
        [-1.5148, -2.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08256632089614868
Epoch 0, Step 1652: train/loss = 0.2549770176410675, train/raw-loss = 0.12927931547164917, train/logprobs = tensor([[-1.4412, -5.3360],
        [-3.2776, -1.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12569770216941833
Epoch 0, Step 1653: train/loss = 0.4609732925891876, train/raw-loss = 0.37150153517723083, train/logprobs = tensor([[-1.0702, -3.7186],
        [-1.6958, -1.6154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0894717425107956
Epoch 0, Step 1654: train/loss = 0.42691802978515625, train/raw-loss = 0.3442087173461914, train/logprobs = tensor([[-0.9156, -4.2190],
        [-1.2531, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08270934224128723
Epoch 0, Step 1655: train/loss = 0.6929035186767578, train/raw-loss = 0.6397933959960938, train/logprobs = tensor([[-1.1201, -1.4710],
        [-0.8819, -0.5717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05311013013124466
Epoch 0, Step 1656: train/loss = 0.5966451168060303, train/raw-loss = 0.48600104451179504, train/logprobs = tensor([[-1.2554, -2.2219],
        [-2.1267, -1.4279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11064406484365463
Epoch 0, Step 1657: train/loss = 0.76368647813797, train/raw-loss = 0.6617761254310608, train/logprobs = tensor([[-1.0138, -1.9290],
        [-1.9083, -2.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10191034525632858
Epoch 0, Step 1658: train/loss = 0.3846537172794342, train/raw-loss = 0.28639334440231323, train/logprobs = tensor([[-1.5206, -3.1278],
        [-2.4842, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09826034307479858
Epoch 0, Step 1659: train/loss = 0.5531786680221558, train/raw-loss = 0.4809955656528473, train/logprobs = tensor([[-0.6316, -3.1651],
        [-0.9061, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07218308001756668
Epoch 0, Step 1660: train/loss = 0.438259482383728, train/raw-loss = 0.363739013671875, train/logprobs = tensor([[-1.1125, -2.2330],
        [-2.0432, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07452047616243362
Epoch 0, Step 1661: train/loss = 0.5116361379623413, train/raw-loss = 0.43299686908721924, train/logprobs = tensor([[-0.8149, -2.9744],
        [-1.1458, -0.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07863932102918625
Epoch 0, Step 1662: train/loss = 0.4471226930618286, train/raw-loss = 0.37063300609588623, train/logprobs = tensor([[-1.1688, -2.6003],
        [-1.8423, -1.1110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0764896497130394
Epoch 0, Step 1663: train/loss = 0.5349209308624268, train/raw-loss = 0.4443507790565491, train/logprobs = tensor([[-0.8642, -2.9981],
        [-1.0057, -1.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09057015180587769
Epoch 0, Step 1664: train/loss = 0.48706871271133423, train/raw-loss = 0.38783207535743713, train/logprobs = tensor([[-1.3214, -3.7506],
        [-1.4035, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0992366224527359
Epoch 0, Step 1665: train/loss = 0.3116360008716583, train/raw-loss = 0.226003497838974, train/logprobs = tensor([[-0.6207, -5.9576],
        [-1.0711, -1.6397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08563251793384552
Epoch 0, Step 1666: train/loss = 0.47527259588241577, train/raw-loss = 0.3653469383716583, train/logprobs = tensor([[-1.5647, -5.0449],
        [-2.0124, -2.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10992563515901566
Epoch 0, Step 1667: train/loss = 0.3351948857307434, train/raw-loss = 0.2523840069770813, train/logprobs = tensor([[-1.0551, -5.1352],
        [-1.5917, -1.7173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0828108862042427
Epoch 0, Step 1668: train/loss = 0.6363245248794556, train/raw-loss = 0.5377752184867859, train/logprobs = tensor([[-1.1636, -1.4546],
        [-1.8193, -0.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09854927659034729
Epoch 0, Step 1669: train/loss = 0.40286239981651306, train/raw-loss = 0.28950822353363037, train/logprobs = tensor([[-1.2105, -4.1297],
        [-2.1526, -1.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11335417628288269
Epoch 0, Step 1670: train/loss = 0.5881820917129517, train/raw-loss = 0.5093398094177246, train/logprobs = tensor([[-1.3419, -2.0612],
        [-1.5464, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07884228229522705
Epoch 0, Step 1671: train/loss = 0.6106188297271729, train/raw-loss = 0.509154736995697, train/logprobs = tensor([[-2.5411, -3.5061],
        [-2.7414, -1.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10146412253379822
Epoch 0, Step 1672: train/loss = 0.34848159551620483, train/raw-loss = 0.2560415267944336, train/logprobs = tensor([[-0.9222, -3.5219],
        [-1.5430, -0.8435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09244006872177124
Epoch 0, Step 1673: train/loss = 0.3485240936279297, train/raw-loss = 0.25162193179130554, train/logprobs = tensor([[-1.4292, -4.5645],
        [-2.5759, -1.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09690214693546295
Epoch 0, Step 1674: train/loss = 0.2853613495826721, train/raw-loss = 0.18417130410671234, train/logprobs = tensor([[-1.2056, -5.3783],
        [-2.1885, -1.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10119003057479858
Epoch 0, Step 1675: train/loss = 0.35646283626556396, train/raw-loss = 0.26910656690597534, train/logprobs = tensor([[-1.4028, -3.7451],
        [-2.0860, -1.3359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08735628426074982
Epoch 0, Step 1676: train/loss = 0.4748069643974304, train/raw-loss = 0.38917315006256104, train/logprobs = tensor([[-1.3453, -4.0571],
        [-1.3518, -1.2987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08563382923603058
Epoch 0, Step 1677: train/loss = 0.4676080048084259, train/raw-loss = 0.3824489116668701, train/logprobs = tensor([[-1.3440, -5.3181],
        [-1.8917, -2.1527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.085159070789814
Epoch 0, Step 1678: train/loss = 0.4952838718891144, train/raw-loss = 0.4188136160373688, train/logprobs = tensor([[-1.2843, -4.8509],
        [-1.4072, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07647022604942322
Epoch 0, Step 1679: train/loss = 0.5944152474403381, train/raw-loss = 0.5040127038955688, train/logprobs = tensor([[-1.0366, -1.8247],
        [-1.4268, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09040255844593048
Epoch 0, Step 1680: train/loss = 0.4582081437110901, train/raw-loss = 0.3500635027885437, train/logprobs = tensor([[-1.1642, -3.1911],
        [-1.7886, -1.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10814464092254639
Epoch 0, Step 1681: train/loss = 0.4675180912017822, train/raw-loss = 0.3881605267524719, train/logprobs = tensor([[-1.0436, -4.9302],
        [-1.2678, -2.0503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07935759425163269
Epoch 0, Step 1682: train/loss = 0.5941390991210938, train/raw-loss = 0.49640578031539917, train/logprobs = tensor([[-1.2779, -2.7848],
        [-1.8913, -1.4329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09773331135511398
Epoch 0, Step 1683: train/loss = 0.48032626509666443, train/raw-loss = 0.4082241654396057, train/logprobs = tensor([[-1.0164, -3.8773],
        [-1.1348, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07210207730531693
Epoch 0, Step 1684: train/loss = 0.4340645670890808, train/raw-loss = 0.33631688356399536, train/logprobs = tensor([[-1.2425, -3.8164],
        [-1.9675, -1.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09774771332740784
Epoch 0, Step 1685: train/loss = 0.4631924629211426, train/raw-loss = 0.3720381557941437, train/logprobs = tensor([[-1.1626, -4.2182],
        [-1.8796, -2.3859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09115432947874069
Epoch 0, Step 1686: train/loss = 0.31080418825149536, train/raw-loss = 0.20454147458076477, train/logprobs = tensor([[-0.9766, -4.0324],
        [-1.8033, -0.8080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10626274347305298
Epoch 0, Step 1687: train/loss = 0.31973177194595337, train/raw-loss = 0.21876905858516693, train/logprobs = tensor([[-1.4617, -2.5463],
        [-3.0959, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10096272081136703
Epoch 0, Step 1688: train/loss = 0.4628693759441376, train/raw-loss = 0.3923094570636749, train/logprobs = tensor([[-0.6723, -3.2931],
        [-0.6861, -1.1236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07055993378162384
Epoch 0, Step 1689: train/loss = 0.33251601457595825, train/raw-loss = 0.24094949662685394, train/logprobs = tensor([[-0.9752, -5.4047],
        [-1.4898, -1.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09156651049852371
Epoch 0, Step 1690: train/loss = 0.5745639801025391, train/raw-loss = 0.4770579934120178, train/logprobs = tensor([[-3.3456, -4.8787],
        [-3.4017, -2.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09750600904226303
Epoch 0, Step 1691: train/loss = 0.46959781646728516, train/raw-loss = 0.37297362089157104, train/logprobs = tensor([[-1.0919, -3.0650],
        [-1.8809, -1.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09662415087223053
Epoch 0, Step 1692: train/loss = 0.3289279341697693, train/raw-loss = 0.2250463366508484, train/logprobs = tensor([[-1.1071, -4.2434],
        [-2.2645, -1.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038815975189209
Epoch 0, Step 1693: train/loss = 0.44603121280670166, train/raw-loss = 0.3416375517845154, train/logprobs = tensor([[-1.5198, -4.8854],
        [-2.6962, -2.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10439364612102509
Epoch 0, Step 1694: train/loss = 0.38908928632736206, train/raw-loss = 0.3080264925956726, train/logprobs = tensor([[-0.4430, -3.6494],
        [-0.5949, -0.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08106275647878647
Epoch 0, Step 1695: train/loss = 0.5937618017196655, train/raw-loss = 0.49603962898254395, train/logprobs = tensor([[-1.1006, -5.0023],
        [-1.8574, -2.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097722128033638
Epoch 0, Step 1696: train/loss = 0.661897599697113, train/raw-loss = 0.5464496612548828, train/logprobs = tensor([[-1.2527, -2.9068],
        [-2.2100, -2.7462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11544789373874664
Epoch 0, Step 1697: train/loss = 0.4289742410182953, train/raw-loss = 0.33056408166885376, train/logprobs = tensor([[-1.3862, -3.8825],
        [-1.8126, -0.9759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09841018170118332
Epoch 0, Step 1698: train/loss = 0.6338909864425659, train/raw-loss = 0.56089848279953, train/logprobs = tensor([[-2.0389, -4.4233],
        [-1.6584, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07299254834651947
Epoch 0, Step 1699: train/loss = 0.29991424083709717, train/raw-loss = 0.18715772032737732, train/logprobs = tensor([[-1.4094, -4.7296],
        [-2.5602, -1.5832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11275650560855865
Epoch 0, Step 1700: train/loss = 0.46449998021125793, train/raw-loss = 0.36425507068634033, train/logprobs = tensor([[-1.3299, -3.8374],
        [-1.9621, -1.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10024489462375641
Epoch 0, Step 1701: train/loss = 0.43243691325187683, train/raw-loss = 0.3510364294052124, train/logprobs = tensor([[-0.9772, -3.5070],
        [-1.4802, -1.4393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08140047639608383
Epoch 0, Step 1702: train/loss = 0.3159877061843872, train/raw-loss = 0.23500213027000427, train/logprobs = tensor([[-1.0634, -4.3111],
        [-1.8760, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08098557591438293
Epoch 0, Step 1703: train/loss = 0.3195211887359619, train/raw-loss = 0.2203139364719391, train/logprobs = tensor([[-1.2115, -4.4653],
        [-2.2653, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09920727461576462
Epoch 0, Step 1704: train/loss = 0.43772369623184204, train/raw-loss = 0.35164177417755127, train/logprobs = tensor([[-1.7089, -3.3031],
        [-2.1940, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08608194440603256
Epoch 0, Step 1705: train/loss = 0.3204839825630188, train/raw-loss = 0.2049819827079773, train/logprobs = tensor([[-1.2122, -6.2902],
        [-2.2900, -1.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11550202965736389
Epoch 0, Step 1706: train/loss = 0.7692616581916809, train/raw-loss = 0.657965898513794, train/logprobs = tensor([[-3.2979, -5.3096],
        [-2.1987, -1.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11129578948020935
Epoch 0, Step 1707: train/loss = 0.3582891523838043, train/raw-loss = 0.26314577460289, train/logprobs = tensor([[-1.2717, -3.5636],
        [-2.1249, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09514334052801132
Epoch 0, Step 1708: train/loss = 0.48351913690567017, train/raw-loss = 0.4180183708667755, train/logprobs = tensor([[-0.7860, -2.7070],
        [-0.8317, -0.9286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06550079584121704
Epoch 0, Step 1709: train/loss = 0.38138076663017273, train/raw-loss = 0.30328404903411865, train/logprobs = tensor([[-1.0714, -4.4319],
        [-1.4843, -1.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07809672504663467
Epoch 0, Step 1710: train/loss = 0.49210789799690247, train/raw-loss = 0.42099806666374207, train/logprobs = tensor([[-0.9546, -4.1553],
        [-1.0588, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0711098462343216
Epoch 0, Step 1711: train/loss = 0.46186918020248413, train/raw-loss = 0.37942612171173096, train/logprobs = tensor([[-0.7627, -5.0598],
        [-1.1253, -2.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08244305849075317
Epoch 0, Step 1712: train/loss = 0.4162880480289459, train/raw-loss = 0.304464191198349, train/logprobs = tensor([[-1.7003, -3.6005],
        [-2.2711, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11182386428117752
Epoch 0, Step 1713: train/loss = 0.47229692339897156, train/raw-loss = 0.3969093859195709, train/logprobs = tensor([[-0.9266, -2.9531],
        [-1.0019, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07538753002882004
Epoch 0, Step 1714: train/loss = 0.46247100830078125, train/raw-loss = 0.3635726869106293, train/logprobs = tensor([[-0.7557, -3.9264],
        [-1.0822, -1.3773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09889833629131317
Epoch 0, Step 1715: train/loss = 0.41348475217819214, train/raw-loss = 0.329505980014801, train/logprobs = tensor([[-0.9681, -3.0760],
        [-1.4129, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397877961397171
Epoch 0, Step 1716: train/loss = 0.42093992233276367, train/raw-loss = 0.33631575107574463, train/logprobs = tensor([[-1.3008, -4.5517],
        [-1.7393, -1.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08462414890527725
Epoch 0, Step 1717: train/loss = 0.4636414349079132, train/raw-loss = 0.37066179513931274, train/logprobs = tensor([[-0.8188, -4.6033],
        [-1.3566, -2.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09297963231801987
Epoch 0, Step 1718: train/loss = 0.4006122052669525, train/raw-loss = 0.31473273038864136, train/logprobs = tensor([[-0.9544, -2.6486],
        [-1.6485, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08587946742773056
Epoch 0, Step 1719: train/loss = 0.46500644087791443, train/raw-loss = 0.3583377003669739, train/logprobs = tensor([[-1.0285, -3.7770],
        [-1.6973, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10666874051094055
Epoch 0, Step 1720: train/loss = 0.38447999954223633, train/raw-loss = 0.2954774796962738, train/logprobs = tensor([[-1.3407, -4.2495],
        [-1.7645, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08900251239538193
Epoch 0, Step 1721: train/loss = 0.36745426058769226, train/raw-loss = 0.2686103582382202, train/logprobs = tensor([[-1.2142, -4.2201],
        [-2.3587, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09884391725063324
Epoch 0, Step 1722: train/loss = 0.35793620347976685, train/raw-loss = 0.24722471833229065, train/logprobs = tensor([[-1.0836, -3.7675],
        [-2.0767, -1.4663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11071144789457321
Epoch 0, Step 1723: train/loss = 0.5084153413772583, train/raw-loss = 0.42340216040611267, train/logprobs = tensor([[-1.0015, -5.7295],
        [-1.5166, -2.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08501321077346802
Epoch 0, Step 1724: train/loss = 0.45692217350006104, train/raw-loss = 0.36691540479660034, train/logprobs = tensor([[-1.2792, -2.5032],
        [-1.7896, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900067687034607
Epoch 0, Step 1725: train/loss = 0.3912889063358307, train/raw-loss = 0.3172430694103241, train/logprobs = tensor([[-1.1471, -3.7091],
        [-1.3850, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740458071231842
Epoch 0, Step 1726: train/loss = 0.45229774713516235, train/raw-loss = 0.3640437126159668, train/logprobs = tensor([[-1.3391, -3.4973],
        [-1.8962, -1.6375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08825402706861496
Epoch 0, Step 1727: train/loss = 0.3914210796356201, train/raw-loss = 0.29602426290512085, train/logprobs = tensor([[-1.2432, -3.6109],
        [-2.2726, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539680182933807
Epoch 0, Step 1728: train/loss = 0.4284329414367676, train/raw-loss = 0.3385096490383148, train/logprobs = tensor([[-0.7757, -3.8779],
        [-1.0911, -1.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08992330729961395
Epoch 0, Step 1729: train/loss = 0.6479281187057495, train/raw-loss = 0.5657256841659546, train/logprobs = tensor([[-1.2791, -1.6243],
        [-1.2048, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08220245689153671
Epoch 0, Step 1730: train/loss = 0.6052436232566833, train/raw-loss = 0.5298531651496887, train/logprobs = tensor([[-1.3938, -2.6720],
        [-1.0461, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07539045810699463
Epoch 0, Step 1731: train/loss = 0.34802642464637756, train/raw-loss = 0.24387550354003906, train/logprobs = tensor([[-1.2287, -3.8822],
        [-2.1125, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10415090620517731
Epoch 0, Step 1732: train/loss = 0.5818120837211609, train/raw-loss = 0.4958820343017578, train/logprobs = tensor([[-1.2614, -2.7605],
        [-1.6978, -1.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08593002706766129
Epoch 0, Step 1733: train/loss = 0.45988649129867554, train/raw-loss = 0.3518105149269104, train/logprobs = tensor([[-1.0210, -4.1779],
        [-1.7352, -1.4808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10807600617408752
Epoch 0, Step 1734: train/loss = 0.43503305315971375, train/raw-loss = 0.36277544498443604, train/logprobs = tensor([[-0.8471, -3.8249],
        [-0.9854, -0.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07225760817527771
Epoch 0, Step 1735: train/loss = 0.28789374232292175, train/raw-loss = 0.17299923300743103, train/logprobs = tensor([[-1.9198, -5.0091],
        [-3.3769, -2.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11489450931549072
Epoch 0, Step 1736: train/loss = 0.5331068634986877, train/raw-loss = 0.43727076053619385, train/logprobs = tensor([[-1.3136, -3.2603],
        [-1.5802, -1.2205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09583607316017151
Epoch 0, Step 1737: train/loss = 0.4158639907836914, train/raw-loss = 0.3228718042373657, train/logprobs = tensor([[-0.8772, -4.5779],
        [-1.5092, -1.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0929921567440033
Epoch 0, Step 1738: train/loss = 0.5870991945266724, train/raw-loss = 0.5017759203910828, train/logprobs = tensor([[-1.7082, -2.3464],
        [-1.9323, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.085323266685009
Epoch 0, Step 1739: train/loss = 0.4147792458534241, train/raw-loss = 0.34481191635131836, train/logprobs = tensor([[-0.9172, -5.2691],
        [-0.7519, -1.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06996731460094452
Epoch 0, Step 1740: train/loss = 0.38269782066345215, train/raw-loss = 0.30102962255477905, train/logprobs = tensor([[-0.8894, -3.3921],
        [-1.3751, -1.1568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0816681757569313
Epoch 0, Step 1741: train/loss = 0.42337316274642944, train/raw-loss = 0.3417087495326996, train/logprobs = tensor([[-1.5873, -3.8692],
        [-1.8186, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08166441321372986
Epoch 0, Step 1742: train/loss = 0.4915422201156616, train/raw-loss = 0.4111250340938568, train/logprobs = tensor([[-1.2802, -2.3400],
        [-2.0407, -1.4004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08041712641716003
Epoch 0, Step 1743: train/loss = 0.5542356371879578, train/raw-loss = 0.4723529517650604, train/logprobs = tensor([[-1.0987, -2.3509],
        [-1.5095, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08188265562057495
Epoch 0, Step 1744: train/loss = 0.5761709809303284, train/raw-loss = 0.4991060197353363, train/logprobs = tensor([[-1.1520, -3.1216],
        [-1.1291, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07706493884325027
Epoch 0, Step 1745: train/loss = 0.36646896600723267, train/raw-loss = 0.27770522236824036, train/logprobs = tensor([[-1.5066, -4.4444],
        [-2.2237, -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0887637585401535
Epoch 0, Step 1746: train/loss = 0.4323842227458954, train/raw-loss = 0.3457942306995392, train/logprobs = tensor([[-0.9356, -4.6300],
        [-1.4288, -1.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08658997714519501
Epoch 0, Step 1747: train/loss = 0.4932868480682373, train/raw-loss = 0.40448296070098877, train/logprobs = tensor([[-1.4219, -3.0187],
        [-1.7257, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08880389481782913
Epoch 0, Step 1748: train/loss = 0.5264372825622559, train/raw-loss = 0.4617900252342224, train/logprobs = tensor([[-1.2925, -3.1185],
        [-1.1947, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06464729458093643
Epoch 0, Step 1749: train/loss = 0.42932525277137756, train/raw-loss = 0.3412952125072479, train/logprobs = tensor([[-0.9422, -3.1847],
        [-1.4485, -1.1010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08803003281354904
Epoch 0, Step 1750: train/loss = 0.3763629198074341, train/raw-loss = 0.2912825345993042, train/logprobs = tensor([[-1.3716, -4.1017],
        [-2.1707, -1.3451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08508041501045227
Epoch 0, Step 1751: train/loss = 0.5086721777915955, train/raw-loss = 0.39564424753189087, train/logprobs = tensor([[-1.5814, -2.7267],
        [-2.0255, -1.4762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11302794516086578
Epoch 0, Step 1752: train/loss = 0.35059836506843567, train/raw-loss = 0.2687981128692627, train/logprobs = tensor([[-0.7524, -6.7252],
        [-0.8536, -1.5889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08180024474859238
Epoch 0, Step 1753: train/loss = 0.44906479120254517, train/raw-loss = 0.37498214840888977, train/logprobs = tensor([[-1.2493, -3.0366],
        [-1.8609, -1.7094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740826427936554
Epoch 0, Step 1754: train/loss = 0.5439234375953674, train/raw-loss = 0.4362366497516632, train/logprobs = tensor([[-2.0065, -3.0628],
        [-2.6499, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10768681019544601
Epoch 0, Step 1755: train/loss = 0.4008827209472656, train/raw-loss = 0.29117336869239807, train/logprobs = tensor([[-1.1758, -4.9094],
        [-1.9288, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10970934480428696
Epoch 0, Step 1756: train/loss = 0.32872632145881653, train/raw-loss = 0.20895051956176758, train/logprobs = tensor([[-1.9989, -4.9137],
        [-3.0295, -1.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11977580189704895
Epoch 0, Step 1757: train/loss = 0.3209257125854492, train/raw-loss = 0.22777029871940613, train/logprobs = tensor([[-1.5339, -5.6754],
        [-2.1480, -1.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09315541386604309
Epoch 0, Step 1758: train/loss = 0.5018064975738525, train/raw-loss = 0.4337857961654663, train/logprobs = tensor([[-0.9436, -2.6999],
        [-0.9652, -1.0051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06802070885896683
Epoch 0, Step 1759: train/loss = 0.5560977458953857, train/raw-loss = 0.46673285961151123, train/logprobs = tensor([[-1.1371, -3.3819],
        [-1.9107, -1.3852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0893649160861969
Epoch 0, Step 1760: train/loss = 0.543686032295227, train/raw-loss = 0.4611499309539795, train/logprobs = tensor([[-1.4681, -2.6968],
        [-1.9758, -1.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08253610134124756
Epoch 0, Step 1761: train/loss = 0.4706147611141205, train/raw-loss = 0.38581982254981995, train/logprobs = tensor([[-1.6022, -4.1694],
        [-1.9691, -1.5828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08479492366313934
Epoch 0, Step 1762: train/loss = 0.46380814909935, train/raw-loss = 0.3778160810470581, train/logprobs = tensor([[-0.9442, -3.8788],
        [-1.1837, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08599207550287247
Epoch 0, Step 1763: train/loss = 0.4605817198753357, train/raw-loss = 0.35060325264930725, train/logprobs = tensor([[-1.5455, -4.7905],
        [-2.1013, -1.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10997847467660904
Epoch 0, Step 1764: train/loss = 0.46358177065849304, train/raw-loss = 0.3874468505382538, train/logprobs = tensor([[-0.9347, -3.5973],
        [-1.0349, -1.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07613492012023926
Epoch 0, Step 1765: train/loss = 0.3886801600456238, train/raw-loss = 0.28944486379623413, train/logprobs = tensor([[-1.2823, -4.3500],
        [-1.8981, -1.5664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09923530369997025
Epoch 0, Step 1766: train/loss = 0.39096230268478394, train/raw-loss = 0.2955763339996338, train/logprobs = tensor([[-1.5040, -3.3921],
        [-2.1331, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09538599848747253
Epoch 0, Step 1767: train/loss = 0.5411937832832336, train/raw-loss = 0.45985865592956543, train/logprobs = tensor([[-0.6838, -3.3778],
        [-0.7776, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08133511245250702
Epoch 0, Step 1768: train/loss = 0.3690856099128723, train/raw-loss = 0.25524774193763733, train/logprobs = tensor([[-1.1363, -3.6334],
        [-2.4741, -1.0595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11383788287639618
Epoch 0, Step 1769: train/loss = 0.4386739730834961, train/raw-loss = 0.3624410033226013, train/logprobs = tensor([[-0.5870, -4.2918],
        [-0.7566, -1.2938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07623303681612015
Epoch 0, Step 1770: train/loss = 0.467769593000412, train/raw-loss = 0.35828545689582825, train/logprobs = tensor([[-1.4705, -3.3231],
        [-2.5313, -2.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10948415100574493
Epoch 0, Step 1771: train/loss = 0.4230141043663025, train/raw-loss = 0.3558647036552429, train/logprobs = tensor([[-0.7282, -4.0759],
        [-0.7404, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06714941561222076
Epoch 0, Step 1772: train/loss = 0.603817880153656, train/raw-loss = 0.5152995586395264, train/logprobs = tensor([[-1.6028, -3.2070],
        [-1.5518, -1.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08851829171180725
Epoch 0, Step 1773: train/loss = 0.555313229560852, train/raw-loss = 0.4828528165817261, train/logprobs = tensor([[-1.0185, -1.7662],
        [-1.3575, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07246042042970657
Epoch 0, Step 1774: train/loss = 0.5598258972167969, train/raw-loss = 0.46917611360549927, train/logprobs = tensor([[-0.9993, -2.2596],
        [-1.6468, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0906497985124588
Epoch 0, Step 1775: train/loss = 0.4732188284397125, train/raw-loss = 0.3934222161769867, train/logprobs = tensor([[-1.1266, -3.3507],
        [-1.4016, -1.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07979658246040344
Epoch 0, Step 1776: train/loss = 0.44340795278549194, train/raw-loss = 0.36572739481925964, train/logprobs = tensor([[-0.7261, -4.1263],
        [-0.8303, -1.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0776805579662323
Epoch 0, Step 1777: train/loss = 0.4164424240589142, train/raw-loss = 0.3186696469783783, train/logprobs = tensor([[-1.1043, -3.7950],
        [-1.9250, -1.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977727621793747
Epoch 0, Step 1778: train/loss = 0.3077481985092163, train/raw-loss = 0.18030869960784912, train/logprobs = tensor([[-1.4658, -4.6453],
        [-2.5435, -1.6198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1274394989013672
Epoch 0, Step 1779: train/loss = 0.5348308682441711, train/raw-loss = 0.4735693037509918, train/logprobs = tensor([[-0.7335, -3.2801],
        [-0.6391, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06126157194375992
Epoch 0, Step 1780: train/loss = 0.38174229860305786, train/raw-loss = 0.2992817461490631, train/logprobs = tensor([[-1.3307, -5.5660],
        [-1.7156, -1.8650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08246055990457535
Epoch 0, Step 1781: train/loss = 0.5285173058509827, train/raw-loss = 0.46096402406692505, train/logprobs = tensor([[-1.6318, -2.0797],
        [-2.0725, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06755325943231583
Epoch 0, Step 1782: train/loss = 0.4232635498046875, train/raw-loss = 0.3258962035179138, train/logprobs = tensor([[-1.4939, -4.7707],
        [-1.7253, -1.3035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09736734628677368
Epoch 0, Step 1783: train/loss = 0.3935500979423523, train/raw-loss = 0.3035498857498169, train/logprobs = tensor([[-1.0324, -4.5336],
        [-1.6324, -1.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0900002121925354
Epoch 0, Step 1784: train/loss = 0.5223774313926697, train/raw-loss = 0.44733768701553345, train/logprobs = tensor([[-0.6732, -3.1522],
        [-0.6120, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07503973692655563
Epoch 0, Step 1785: train/loss = 0.4532041847705841, train/raw-loss = 0.3516616225242615, train/logprobs = tensor([[-1.3989, -2.8264],
        [-2.0306, -1.0582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10154257714748383
Epoch 0, Step 1786: train/loss = 0.43029820919036865, train/raw-loss = 0.3565998077392578, train/logprobs = tensor([[-0.8086, -4.7175],
        [-1.0117, -1.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07369840890169144
Epoch 0, Step 1787: train/loss = 0.5665470361709595, train/raw-loss = 0.5040310025215149, train/logprobs = tensor([[-1.2104, -2.8612],
        [-1.3562, -1.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06251608580350876
Epoch 0, Step 1788: train/loss = 0.3982166349887848, train/raw-loss = 0.2911602258682251, train/logprobs = tensor([[-0.9710, -4.5805],
        [-1.6582, -2.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10705640912055969
Epoch 0, Step 1789: train/loss = 0.5644181966781616, train/raw-loss = 0.478225439786911, train/logprobs = tensor([[-1.1964, -2.4091],
        [-1.2319, -1.0645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0861927941441536
Epoch 0, Step 1790: train/loss = 0.4405480623245239, train/raw-loss = 0.3556455373764038, train/logprobs = tensor([[-1.0831, -3.9098],
        [-1.2421, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08490253984928131
Epoch 0, Step 1791: train/loss = 0.4654388427734375, train/raw-loss = 0.3739348351955414, train/logprobs = tensor([[-1.0443, -3.8297],
        [-1.3508, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09150397777557373
Epoch 0, Step 1792: train/loss = 0.48385751247406006, train/raw-loss = 0.4119628369808197, train/logprobs = tensor([[-1.5314, -3.3671],
        [-1.9884, -1.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07189472019672394
Epoch 0, Step 1793: train/loss = 0.49937868118286133, train/raw-loss = 0.42593148350715637, train/logprobs = tensor([[-0.9838, -2.9989],
        [-1.0867, -1.2158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07344721257686615
Epoch 0, Step 1794: train/loss = 0.4756409525871277, train/raw-loss = 0.3800588846206665, train/logprobs = tensor([[-1.5735, -2.9913],
        [-2.0065, -1.5126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09558206051588058
Epoch 0, Step 1795: train/loss = 0.41216006875038147, train/raw-loss = 0.3312123119831085, train/logprobs = tensor([[-1.1172, -4.7656],
        [-1.4098, -1.5786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08094776421785355
Epoch 0, Step 1796: train/loss = 0.6219642162322998, train/raw-loss = 0.5068895816802979, train/logprobs = tensor([[-2.0683, -4.0631],
        [-1.6092, -0.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11507463455200195
Epoch 0, Step 1797: train/loss = 0.4098619520664215, train/raw-loss = 0.3163728415966034, train/logprobs = tensor([[-1.1995, -4.2865],
        [-1.6117, -1.6207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09348909556865692
Epoch 0, Step 1798: train/loss = 0.3694606423377991, train/raw-loss = 0.2855486273765564, train/logprobs = tensor([[-0.8763, -5.5292],
        [-1.1105, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08391199260950089
Epoch 0, Step 1799: train/loss = 0.5101535320281982, train/raw-loss = 0.42643022537231445, train/logprobs = tensor([[-1.5924, -4.2959],
        [-2.0830, -2.1183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08372323960065842
Epoch 0, Step 1800: train/loss = 0.4765598475933075, train/raw-loss = 0.3800926208496094, train/logprobs = tensor([[-1.6720, -2.5712],
        [-2.1510, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09646725654602051
Epoch 0, Step 1801: train/loss = 0.435879111289978, train/raw-loss = 0.33968251943588257, train/logprobs = tensor([[-0.9518, -3.7042],
        [-1.5337, -1.4018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09619653224945068
Epoch 0, Step 1802: train/loss = 0.5335133671760559, train/raw-loss = 0.45864230394363403, train/logprobs = tensor([[-1.1204, -2.7879],
        [-1.1618, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07487105578184128
Epoch 0, Step 1803: train/loss = 0.4069784879684448, train/raw-loss = 0.3140046298503876, train/logprobs = tensor([[-1.4034, -3.8695],
        [-1.9007, -1.1817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09297385066747665
Epoch 0, Step 1804: train/loss = 0.48307961225509644, train/raw-loss = 0.37369412183761597, train/logprobs = tensor([[-1.3596, -3.1662],
        [-2.0412, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10938551276922226
Epoch 0, Step 1805: train/loss = 0.3935788869857788, train/raw-loss = 0.2964542508125305, train/logprobs = tensor([[-0.6828, -3.9184],
        [-1.1708, -1.2255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09712465107440948
Epoch 0, Step 1806: train/loss = 0.5153453350067139, train/raw-loss = 0.42292916774749756, train/logprobs = tensor([[-1.6166, -3.1045],
        [-1.6896, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09241615980863571
Epoch 0, Step 1807: train/loss = 0.5188528299331665, train/raw-loss = 0.4241395592689514, train/logprobs = tensor([[-1.0499, -2.6637],
        [-1.3247, -1.4265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947132557630539
Epoch 0, Step 1808: train/loss = 0.48282477259635925, train/raw-loss = 0.39453205466270447, train/logprobs = tensor([[-1.6357, -2.2767],
        [-2.2237, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08829271048307419
Epoch 0, Step 1809: train/loss = 0.3311774730682373, train/raw-loss = 0.25949031114578247, train/logprobs = tensor([[-0.6012, -6.8260],
        [-0.7402, -1.5479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07168714702129364
Epoch 0, Step 1810: train/loss = 0.43723171949386597, train/raw-loss = 0.37408575415611267, train/logprobs = tensor([[-0.6433, -3.9382],
        [-0.6951, -1.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06314598768949509
Epoch 0, Step 1811: train/loss = 0.418315589427948, train/raw-loss = 0.321779727935791, train/logprobs = tensor([[-1.2939, -4.7098],
        [-1.7102, -1.3197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09653588384389877
Epoch 0, Step 1812: train/loss = 0.37064775824546814, train/raw-loss = 0.27422887086868286, train/logprobs = tensor([[-1.2621, -4.2185],
        [-1.5948, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09641887247562408
Epoch 0, Step 1813: train/loss = 0.46297621726989746, train/raw-loss = 0.38035476207733154, train/logprobs = tensor([[-0.9463, -2.7459],
        [-1.4156, -1.0348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08262142539024353
Epoch 0, Step 1814: train/loss = 0.521320104598999, train/raw-loss = 0.44633668661117554, train/logprobs = tensor([[-1.3602, -2.8875],
        [-1.4366, -0.9706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0749833881855011
Epoch 0, Step 1815: train/loss = 0.5345626473426819, train/raw-loss = 0.4647865295410156, train/logprobs = tensor([[-0.9102, -3.1838],
        [-1.1531, -1.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06977608799934387
Epoch 0, Step 1816: train/loss = 0.5345535278320312, train/raw-loss = 0.4537326693534851, train/logprobs = tensor([[-1.9547, -4.6583],
        [-1.5883, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08082084357738495
Epoch 0, Step 1817: train/loss = 0.39767834544181824, train/raw-loss = 0.28243499994277954, train/logprobs = tensor([[-1.7342, -3.7140],
        [-2.6971, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1152433380484581
Epoch 0, Step 1818: train/loss = 0.3722044825553894, train/raw-loss = 0.2683236300945282, train/logprobs = tensor([[-1.2350, -4.3432],
        [-1.8145, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1038808599114418
Epoch 0, Step 1819: train/loss = 0.6023290157318115, train/raw-loss = 0.5266708731651306, train/logprobs = tensor([[-1.6947, -3.5542],
        [-1.7797, -1.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07565810531377792
Epoch 0, Step 1820: train/loss = 0.522327721118927, train/raw-loss = 0.4400945007801056, train/logprobs = tensor([[-1.1437, -2.6128],
        [-1.5748, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08223322033882141
Epoch 0, Step 1821: train/loss = 0.5884413123130798, train/raw-loss = 0.49733930826187134, train/logprobs = tensor([[-1.1686, -2.3218],
        [-1.5119, -1.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911020040512085
Epoch 0, Step 1822: train/loss = 0.5211204290390015, train/raw-loss = 0.43696892261505127, train/logprobs = tensor([[-1.7397, -2.2000],
        [-2.1281, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08415152877569199
Epoch 0, Step 1823: train/loss = 0.36806216835975647, train/raw-loss = 0.2733166515827179, train/logprobs = tensor([[-0.8879, -4.2599],
        [-1.3584, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09474550932645798
Epoch 0, Step 1824: train/loss = 0.46989622712135315, train/raw-loss = 0.3671127259731293, train/logprobs = tensor([[-1.1915, -2.5286],
        [-1.9350, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10278349369764328
Epoch 0, Step 1825: train/loss = 0.3743431270122528, train/raw-loss = 0.25704264640808105, train/logprobs = tensor([[-1.4629, -3.6774],
        [-2.1648, -1.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11730048060417175
Epoch 0, Step 1826: train/loss = 0.4957875609397888, train/raw-loss = 0.40849852561950684, train/logprobs = tensor([[-0.9402, -3.2743],
        [-1.3351, -1.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08728902041912079
Epoch 0, Step 1827: train/loss = 0.5061286091804504, train/raw-loss = 0.42075902223587036, train/logprobs = tensor([[-1.3219, -3.0119],
        [-1.6308, -1.5813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08536959439516068
Epoch 0, Step 1828: train/loss = 0.43570825457572937, train/raw-loss = 0.35619813203811646, train/logprobs = tensor([[-1.2991, -2.9652],
        [-1.7283, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0795101448893547
Epoch 0, Step 1829: train/loss = 0.4697701036930084, train/raw-loss = 0.3823468089103699, train/logprobs = tensor([[-1.2591, -5.1508],
        [-1.1972, -1.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08742333948612213
Epoch 0, Step 1830: train/loss = 0.5244190692901611, train/raw-loss = 0.4369781017303467, train/logprobs = tensor([[-1.0356, -3.3084],
        [-1.3676, -1.1855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08744096755981445
Epoch 0, Step 1831: train/loss = 0.565091073513031, train/raw-loss = 0.4813348650932312, train/logprobs = tensor([[-1.8389, -3.7932],
        [-1.8602, -1.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0837562158703804
Epoch 0, Step 1832: train/loss = 0.3685727119445801, train/raw-loss = 0.2873903214931488, train/logprobs = tensor([[-1.3826, -4.7535],
        [-1.9260, -1.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08118239045143127
Epoch 0, Step 1833: train/loss = 0.27701956033706665, train/raw-loss = 0.17380326986312866, train/logprobs = tensor([[-1.4781, -5.3938],
        [-2.3295, -1.3618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10321629047393799
Epoch 0, Step 1834: train/loss = 0.46277084946632385, train/raw-loss = 0.3909384608268738, train/logprobs = tensor([[-0.9596, -4.9554],
        [-0.9948, -1.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07183235138654709
Epoch 0, Step 1835: train/loss = 0.4512683153152466, train/raw-loss = 0.3585938513278961, train/logprobs = tensor([[-1.0341, -3.6738],
        [-1.7208, -1.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09267447143793106
Epoch 0, Step 1836: train/loss = 0.5965086221694946, train/raw-loss = 0.5038998126983643, train/logprobs = tensor([[-1.6937, -2.9540],
        [-1.4397, -1.2885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09260878711938858
Epoch 0, Step 1837: train/loss = 0.45299118757247925, train/raw-loss = 0.37507811188697815, train/logprobs = tensor([[-0.8998, -2.9346],
        [-1.2065, -1.2340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07791309803724289
Epoch 0, Step 1838: train/loss = 0.4339992105960846, train/raw-loss = 0.33927589654922485, train/logprobs = tensor([[-1.0455, -3.0813],
        [-1.7559, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09472328424453735
Epoch 0, Step 1839: train/loss = 0.5793838500976562, train/raw-loss = 0.4856511950492859, train/logprobs = tensor([[-1.4464, -1.8891],
        [-2.1453, -1.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09373261779546738
Epoch 0, Step 1840: train/loss = 0.6487852931022644, train/raw-loss = 0.5458922982215881, train/logprobs = tensor([[-1.7455, -2.2846],
        [-1.9795, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10289299488067627
Epoch 0, Step 1841: train/loss = 0.48225221037864685, train/raw-loss = 0.40631094574928284, train/logprobs = tensor([[-1.2392, -4.0106],
        [-1.2069, -1.6799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0759412944316864
Epoch 0, Step 1842: train/loss = 0.4771135747432709, train/raw-loss = 0.39455297589302063, train/logprobs = tensor([[-1.8614, -3.1897],
        [-2.1325, -1.3620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08256056904792786
Epoch 0, Step 1843: train/loss = 0.3950341045856476, train/raw-loss = 0.29869285225868225, train/logprobs = tensor([[-1.1545, -5.3282],
        [-1.3600, -1.5153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09634126722812653
Epoch 0, Step 1844: train/loss = 0.48904716968536377, train/raw-loss = 0.41489753127098083, train/logprobs = tensor([[-1.5674, -3.3428],
        [-1.8642, -1.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07414965331554413
Epoch 0, Step 1845: train/loss = 0.48704084753990173, train/raw-loss = 0.4078702926635742, train/logprobs = tensor([[-0.7140, -3.5868],
        [-0.7708, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07917052507400513
Epoch 0, Step 1846: train/loss = 0.42589858174324036, train/raw-loss = 0.3534851670265198, train/logprobs = tensor([[-0.7065, -4.0359],
        [-0.8578, -1.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07241342216730118
Epoch 0, Step 1847: train/loss = 0.4677579402923584, train/raw-loss = 0.38764697313308716, train/logprobs = tensor([[-1.2320, -4.0949],
        [-1.7906, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08011095225811005
Epoch 0, Step 1848: train/loss = 0.3916502594947815, train/raw-loss = 0.2818424105644226, train/logprobs = tensor([[-1.4542, -5.6097],
        [-2.3148, -1.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10980786383152008
Epoch 0, Step 1849: train/loss = 0.6253607869148254, train/raw-loss = 0.5404983162879944, train/logprobs = tensor([[-1.4752, -2.0259],
        [-1.6423, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08486244082450867
Epoch 0, Step 1850: train/loss = 0.3589351773262024, train/raw-loss = 0.2935103476047516, train/logprobs = tensor([[-0.8028, -3.7652],
        [-1.1706, -1.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06542479991912842
Epoch 0, Step 1851: train/loss = 0.4212939739227295, train/raw-loss = 0.32023051381111145, train/logprobs = tensor([[-1.1419, -3.9398],
        [-1.6471, -1.8153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10106346011161804
Epoch 0, Step 1852: train/loss = 0.4813762903213501, train/raw-loss = 0.39260977506637573, train/logprobs = tensor([[-1.2227, -2.9119],
        [-1.5542, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08876655250787735
Epoch 0, Step 1853: train/loss = 0.4992827773094177, train/raw-loss = 0.39429616928100586, train/logprobs = tensor([[-1.0313, -3.7329],
        [-1.2982, -1.4031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10498660802841187
Epoch 0, Step 1854: train/loss = 0.3699432909488678, train/raw-loss = 0.28713443875312805, train/logprobs = tensor([[-0.8381, -4.2396],
        [-0.9498, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08280885219573975
Epoch 0, Step 1855: train/loss = 0.4252236485481262, train/raw-loss = 0.33676743507385254, train/logprobs = tensor([[-0.9817, -3.9607],
        [-1.4291, -1.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08845623582601547
Epoch 0, Step 1856: train/loss = 0.49698328971862793, train/raw-loss = 0.4294162392616272, train/logprobs = tensor([[-1.2314, -2.8490],
        [-1.4565, -1.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06756701320409775
Epoch 0, Step 1857: train/loss = 0.4876973032951355, train/raw-loss = 0.3925626277923584, train/logprobs = tensor([[-1.4424, -3.0698],
        [-2.0378, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09513460844755173
Epoch 0, Step 1858: train/loss = 0.45020198822021484, train/raw-loss = 0.36878159642219543, train/logprobs = tensor([[-0.6837, -3.6320],
        [-0.9425, -0.9040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0814204066991806
Epoch 0, Step 1859: train/loss = 0.4256023168563843, train/raw-loss = 0.3586265444755554, train/logprobs = tensor([[-0.5304, -5.3854],
        [-0.7376, -1.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06697577983140945
Epoch 0, Step 1860: train/loss = 0.3909572958946228, train/raw-loss = 0.2812489867210388, train/logprobs = tensor([[-2.0704, -4.2193],
        [-3.2460, -2.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10970830172300339
Epoch 0, Step 1861: train/loss = 0.45816555619239807, train/raw-loss = 0.3382469415664673, train/logprobs = tensor([[-1.6399, -3.8148],
        [-2.1051, -1.5300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11991859972476959
Epoch 0, Step 1862: train/loss = 0.4575839042663574, train/raw-loss = 0.3748888075351715, train/logprobs = tensor([[-2.0128, -2.6037],
        [-2.5475, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08269507437944412
Epoch 0, Step 1863: train/loss = 0.5218425989151001, train/raw-loss = 0.44768643379211426, train/logprobs = tensor([[-0.9568, -2.3718],
        [-1.4144, -0.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07415613532066345
Epoch 0, Step 1864: train/loss = 0.4632492959499359, train/raw-loss = 0.3807958960533142, train/logprobs = tensor([[-1.3933, -3.1162],
        [-1.7302, -1.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0824534147977829
Epoch 0, Step 1865: train/loss = 0.4780890941619873, train/raw-loss = 0.3886219263076782, train/logprobs = tensor([[-1.2024, -3.6630],
        [-1.3884, -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08946718275547028
Epoch 0, Step 1866: train/loss = 0.529920220375061, train/raw-loss = 0.45490771532058716, train/logprobs = tensor([[-0.9101, -3.1709],
        [-0.6818, -0.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501250505447388
Epoch 0, Step 1867: train/loss = 0.4433181881904602, train/raw-loss = 0.3536062240600586, train/logprobs = tensor([[-1.0572, -3.7854],
        [-1.5728, -1.2996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08971193432807922
Epoch 0, Step 1868: train/loss = 0.290718674659729, train/raw-loss = 0.17567043006420135, train/logprobs = tensor([[-1.3164, -6.7778],
        [-2.4855, -1.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11504825949668884
Epoch 0, Step 1869: train/loss = 0.35037049651145935, train/raw-loss = 0.26476871967315674, train/logprobs = tensor([[-0.9659, -4.0985],
        [-1.5922, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.085601806640625
Epoch 0, Step 1870: train/loss = 0.5158885717391968, train/raw-loss = 0.3935737609863281, train/logprobs = tensor([[-1.4390, -2.7442],
        [-2.3677, -1.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12231478095054626
Epoch 0, Step 1871: train/loss = 0.5065853595733643, train/raw-loss = 0.4278166592121124, train/logprobs = tensor([[-0.6074, -3.8541],
        [-0.9569, -1.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07876873761415482
Epoch 0, Step 1872: train/loss = 0.5244855284690857, train/raw-loss = 0.4402533173561096, train/logprobs = tensor([[-0.9321, -2.2357],
        [-1.3805, -0.8482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08423219621181488
Epoch 0, Step 1873: train/loss = 0.5841666460037231, train/raw-loss = 0.5068004727363586, train/logprobs = tensor([[-1.3544, -4.3515],
        [-1.1731, -1.4600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07736613601446152
Epoch 0, Step 1874: train/loss = 0.6896334886550903, train/raw-loss = 0.6023349761962891, train/logprobs = tensor([[-2.2011, -2.8642],
        [-1.8182, -1.4962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08729855716228485
Epoch 0, Step 1875: train/loss = 0.5822927951812744, train/raw-loss = 0.5183186531066895, train/logprobs = tensor([[-1.0619, -3.2604],
        [-1.0761, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06397415697574615
Epoch 0, Step 1876: train/loss = 0.38621050119400024, train/raw-loss = 0.3046106994152069, train/logprobs = tensor([[-1.7717, -4.4739],
        [-1.9844, -1.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08159980922937393
Epoch 0, Step 1877: train/loss = 0.5868095755577087, train/raw-loss = 0.5013119578361511, train/logprobs = tensor([[-1.7564, -3.9457],
        [-1.6043, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08549761772155762
Epoch 0, Step 1878: train/loss = 0.4206952452659607, train/raw-loss = 0.3431091904640198, train/logprobs = tensor([[-1.4355, -3.5652],
        [-1.8648, -1.4484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07758603990077972
Epoch 0, Step 1879: train/loss = 0.4024311900138855, train/raw-loss = 0.3118339776992798, train/logprobs = tensor([[-1.2414, -2.9655],
        [-2.0149, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09059719741344452
Epoch 0, Step 1880: train/loss = 0.418434739112854, train/raw-loss = 0.3373555541038513, train/logprobs = tensor([[-1.3431, -2.8471],
        [-2.2720, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08107917755842209
Epoch 0, Step 1881: train/loss = 0.4759559631347656, train/raw-loss = 0.40395164489746094, train/logprobs = tensor([[-1.5601, -3.5550],
        [-1.8741, -1.3206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07200434803962708
Epoch 0, Step 1882: train/loss = 0.49081525206565857, train/raw-loss = 0.3972926437854767, train/logprobs = tensor([[-1.1454, -2.6016],
        [-1.6363, -1.1082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09352262318134308
Epoch 0, Step 1883: train/loss = 0.3367936909198761, train/raw-loss = 0.23481851816177368, train/logprobs = tensor([[-1.4841, -4.1225],
        [-2.3233, -1.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10197517275810242
Epoch 0, Step 1884: train/loss = 0.5818794369697571, train/raw-loss = 0.5146070122718811, train/logprobs = tensor([[-0.8008, -2.4621],
        [-1.0292, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06727245450019836
Epoch 0, Step 1885: train/loss = 0.3182496726512909, train/raw-loss = 0.22219491004943848, train/logprobs = tensor([[-1.1463, -4.8804],
        [-1.6396, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605474770069122
Epoch 0, Step 1886: train/loss = 0.5506981015205383, train/raw-loss = 0.47810542583465576, train/logprobs = tensor([[-0.9089, -2.3386],
        [-1.2066, -1.3655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07259264588356018
Epoch 0, Step 1887: train/loss = 0.5333971977233887, train/raw-loss = 0.4385559558868408, train/logprobs = tensor([[-1.1123, -4.4367],
        [-1.4350, -2.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09484122693538666
Epoch 0, Step 1888: train/loss = 0.33878961205482483, train/raw-loss = 0.22267542779445648, train/logprobs = tensor([[-1.8928, -4.0462],
        [-2.9980, -1.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11611420661211014
Epoch 0, Step 1889: train/loss = 0.4941937029361725, train/raw-loss = 0.41209518909454346, train/logprobs = tensor([[-0.6966, -2.4630],
        [-1.0880, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209851384162903
Epoch 0, Step 1890: train/loss = 0.5158292055130005, train/raw-loss = 0.42322853207588196, train/logprobs = tensor([[-1.2502, -3.0797],
        [-1.9823, -1.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09260066598653793
Epoch 0, Step 1891: train/loss = 0.7892422676086426, train/raw-loss = 0.7013305425643921, train/logprobs = tensor([[-3.8164, -4.4437],
        [-3.3598, -3.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879117026925087
Epoch 0, Step 1892: train/loss = 0.5624308586120605, train/raw-loss = 0.4637424349784851, train/logprobs = tensor([[-1.0757, -2.2675],
        [-1.6912, -1.2057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09868845343589783
Epoch 0, Step 1893: train/loss = 0.4157593846321106, train/raw-loss = 0.3177468776702881, train/logprobs = tensor([[-1.3283, -3.8020],
        [-1.9747, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09801249206066132
Epoch 0, Step 1894: train/loss = 0.5683770179748535, train/raw-loss = 0.495922327041626, train/logprobs = tensor([[-1.1752, -1.8368],
        [-1.3713, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07245469093322754
Epoch 0, Step 1895: train/loss = 0.4440911114215851, train/raw-loss = 0.37898746132850647, train/logprobs = tensor([[-0.7665, -3.4761],
        [-0.8830, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06510365009307861
Epoch 0, Step 1896: train/loss = 0.6003973484039307, train/raw-loss = 0.5287886261940002, train/logprobs = tensor([[-1.4635, -3.3583],
        [-1.2613, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07160871475934982
Epoch 0, Step 1897: train/loss = 0.5155704021453857, train/raw-loss = 0.4323435425758362, train/logprobs = tensor([[-1.0491, -2.7899],
        [-1.3197, -1.1291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08322683721780777
Epoch 0, Step 1898: train/loss = 0.4888264536857605, train/raw-loss = 0.385274738073349, train/logprobs = tensor([[-2.2888, -2.6892],
        [-3.0258, -1.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355174541473389
Epoch 0, Step 1899: train/loss = 0.4856022596359253, train/raw-loss = 0.4195624887943268, train/logprobs = tensor([[-1.7468, -1.4290],
        [-2.5199, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0660397931933403
Epoch 0, Step 1900: train/loss = 0.520057201385498, train/raw-loss = 0.4193769693374634, train/logprobs = tensor([[-1.9299, -3.4117],
        [-2.2362, -1.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10068029165267944
Epoch 0, Step 1901: train/loss = 0.46402448415756226, train/raw-loss = 0.3561587333679199, train/logprobs = tensor([[-1.0859, -2.3158],
        [-2.1829, -1.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10786574333906174
Epoch 0, Step 1902: train/loss = 0.28799864649772644, train/raw-loss = 0.16473373770713806, train/logprobs = tensor([[-1.8967, -4.3124],
        [-3.6420, -2.1069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12326490134000778
Epoch 0, Step 1903: train/loss = 0.5279691815376282, train/raw-loss = 0.4555649161338806, train/logprobs = tensor([[-1.8475, -5.2021],
        [-1.5229, -1.5951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07240428775548935
Epoch 0, Step 1904: train/loss = 0.34456807374954224, train/raw-loss = 0.2506003975868225, train/logprobs = tensor([[-1.3777, -4.3470],
        [-1.9440, -1.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09396770596504211
Epoch 0, Step 1905: train/loss = 0.3400665521621704, train/raw-loss = 0.2597264349460602, train/logprobs = tensor([[-1.3980, -4.9714],
        [-1.9813, -1.4954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08034010976552963
Epoch 0, Step 1906: train/loss = 0.6070644855499268, train/raw-loss = 0.5267680883407593, train/logprobs = tensor([[-1.9822, -2.7037],
        [-1.8583, -1.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08029630780220032
Epoch 0, Step 1907: train/loss = 0.38695091009140015, train/raw-loss = 0.3177921175956726, train/logprobs = tensor([[-0.8661, -4.8720],
        [-1.3361, -1.7310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06915882229804993
Epoch 0, Step 1908: train/loss = 0.6657564640045166, train/raw-loss = 0.5851998329162598, train/logprobs = tensor([[-2.3906, -2.0273],
        [-2.4427, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0805567055940628
Epoch 0, Step 1909: train/loss = 0.28329479694366455, train/raw-loss = 0.17887771129608154, train/logprobs = tensor([[-1.6661, -4.1998],
        [-2.7684, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10441708564758301
Epoch 0, Step 1910: train/loss = 0.35060355067253113, train/raw-loss = 0.28047922253608704, train/logprobs = tensor([[-1.1583, -5.7518],
        [-1.5103, -1.1945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0701243132352829
Epoch 0, Step 1911: train/loss = 0.2846764624118805, train/raw-loss = 0.1884518563747406, train/logprobs = tensor([[-0.9619, -5.7840],
        [-1.7940, -1.5161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09622462093830109
Epoch 0, Step 1912: train/loss = 0.4601193070411682, train/raw-loss = 0.35371333360671997, train/logprobs = tensor([[-1.9342, -3.6146],
        [-2.2513, -1.6001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10640597343444824
Epoch 0, Step 1913: train/loss = 0.3627711236476898, train/raw-loss = 0.2761428952217102, train/logprobs = tensor([[-1.1854, -4.9320],
        [-1.4459, -1.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08662823587656021
Epoch 0, Step 1914: train/loss = 0.4320334792137146, train/raw-loss = 0.3372938632965088, train/logprobs = tensor([[-1.4431, -5.0275],
        [-1.7640, -1.3271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09473961591720581
Epoch 0, Step 1915: train/loss = 0.3179609477519989, train/raw-loss = 0.23246219754219055, train/logprobs = tensor([[-1.3984, -5.6335],
        [-1.9802, -1.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08549875766038895
Epoch 0, Step 1916: train/loss = 0.4417578876018524, train/raw-loss = 0.35849690437316895, train/logprobs = tensor([[-1.3150, -3.0515],
        [-1.7335, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08326098322868347
Epoch 0, Step 1917: train/loss = 0.39896753430366516, train/raw-loss = 0.33011776208877563, train/logprobs = tensor([[-0.7676, -4.4246],
        [-1.0670, -1.5090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06884977966547012
Epoch 0, Step 1918: train/loss = 0.4587444067001343, train/raw-loss = 0.38495272397994995, train/logprobs = tensor([[-1.1632, -4.4432],
        [-1.6038, -2.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07379171997308731
Epoch 0, Step 1919: train/loss = 0.3842149078845978, train/raw-loss = 0.29557234048843384, train/logprobs = tensor([[-0.9165, -4.7100],
        [-0.9896, -1.1067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08864258974790573
Epoch 0, Step 1920: train/loss = 0.46796298027038574, train/raw-loss = 0.39424389600753784, train/logprobs = tensor([[-0.7866, -3.7084],
        [-1.0284, -1.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0737190917134285
Epoch 0, Step 1921: train/loss = 0.3871440589427948, train/raw-loss = 0.27822357416152954, train/logprobs = tensor([[-1.6325, -3.6972],
        [-2.4206, -1.3077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10892048478126526
Epoch 0, Step 1922: train/loss = 0.6452338695526123, train/raw-loss = 0.5611358880996704, train/logprobs = tensor([[-1.6007, -2.7539],
        [-1.5541, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0840979814529419
Epoch 0, Step 1923: train/loss = 0.3779694736003876, train/raw-loss = 0.2884068191051483, train/logprobs = tensor([[-1.1953, -4.6812],
        [-1.8180, -1.7997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08956265449523926
Epoch 0, Step 1924: train/loss = 0.3705453872680664, train/raw-loss = 0.28969427943229675, train/logprobs = tensor([[-0.9779, -5.9370],
        [-1.2300, -1.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08085110783576965
Epoch 0, Step 1925: train/loss = 0.41722241044044495, train/raw-loss = 0.32381105422973633, train/logprobs = tensor([[-1.5073, -3.1476],
        [-1.9887, -0.8725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09341135621070862
Epoch 0, Step 1926: train/loss = 0.41436508297920227, train/raw-loss = 0.32887861132621765, train/logprobs = tensor([[-0.8797, -3.9132],
        [-1.4647, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08548645675182343
Epoch 0, Step 1927: train/loss = 0.4812510013580322, train/raw-loss = 0.4048084020614624, train/logprobs = tensor([[-1.4392, -3.6332],
        [-1.7691, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07644259929656982
Epoch 0, Step 1928: train/loss = 0.32917675375938416, train/raw-loss = 0.2134835124015808, train/logprobs = tensor([[-1.8523, -4.7876],
        [-2.6697, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11569320410490036
Epoch 0, Step 1929: train/loss = 0.32922327518463135, train/raw-loss = 0.22155509889125824, train/logprobs = tensor([[-0.9954, -4.0196],
        [-1.8068, -0.9077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10766816139221191
Epoch 0, Step 1930: train/loss = 0.42676588892936707, train/raw-loss = 0.3362821936607361, train/logprobs = tensor([[-1.0180, -4.2748],
        [-1.4605, -1.4211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048367291688919
Epoch 0, Step 1931: train/loss = 0.36289849877357483, train/raw-loss = 0.2752281427383423, train/logprobs = tensor([[-1.0196, -5.1898],
        [-1.6854, -2.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08767036348581314
Epoch 0, Step 1932: train/loss = 0.3725622892379761, train/raw-loss = 0.27964240312576294, train/logprobs = tensor([[-1.1420, -3.9382],
        [-1.9549, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09291985630989075
Epoch 0, Step 1933: train/loss = 0.512643575668335, train/raw-loss = 0.4280717968940735, train/logprobs = tensor([[-1.3949, -4.0014],
        [-1.9646, -1.3344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08457176387310028
Epoch 0, Step 1934: train/loss = 0.4414786696434021, train/raw-loss = 0.3379194736480713, train/logprobs = tensor([[-1.3073, -3.8985],
        [-1.6535, -1.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355919599533081
Epoch 0, Step 1935: train/loss = 0.3330472707748413, train/raw-loss = 0.2408261001110077, train/logprobs = tensor([[-0.8427, -4.0381],
        [-1.6426, -1.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09222119301557541
Epoch 0, Step 1936: train/loss = 0.5301574468612671, train/raw-loss = 0.4607725143432617, train/logprobs = tensor([[-1.1407, -3.1959],
        [-1.4204, -1.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06938495486974716
Epoch 0, Step 1937: train/loss = 0.514739990234375, train/raw-loss = 0.43440601229667664, train/logprobs = tensor([[-0.9261, -3.2231],
        [-1.1878, -1.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08033399283885956
Epoch 0, Step 1938: train/loss = 0.5030989646911621, train/raw-loss = 0.40986451506614685, train/logprobs = tensor([[-1.3996, -4.4224],
        [-1.4241, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09323443472385406
Epoch 0, Step 1939: train/loss = 0.44580864906311035, train/raw-loss = 0.36116188764572144, train/logprobs = tensor([[-0.8712, -3.6422],
        [-1.3265, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08464672416448593
Epoch 0, Step 1940: train/loss = 0.3454754948616028, train/raw-loss = 0.28112462162971497, train/logprobs = tensor([[-0.5120, -5.2502],
        [-0.7894, -1.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06435085833072662
Epoch 0, Step 1941: train/loss = 0.5736618041992188, train/raw-loss = 0.4760887026786804, train/logprobs = tensor([[-1.4399, -2.3597],
        [-1.8370, -1.2784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09757307171821594
Epoch 0, Step 1942: train/loss = 0.48296451568603516, train/raw-loss = 0.41092386841773987, train/logprobs = tensor([[-1.1768, -4.6746],
        [-1.1047, -1.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07204066216945648
Epoch 0, Step 1943: train/loss = 0.38599100708961487, train/raw-loss = 0.30215883255004883, train/logprobs = tensor([[-0.9725, -4.0683],
        [-1.8268, -1.7891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08383216708898544
Epoch 0, Step 1944: train/loss = 0.6878812313079834, train/raw-loss = 0.6330349445343018, train/logprobs = tensor([[-0.4864, -0.5648],
        [-0.6190, -0.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05484630540013313
Epoch 0, Step 1945: train/loss = 0.35827717185020447, train/raw-loss = 0.272516131401062, train/logprobs = tensor([[-1.2742, -4.9739],
        [-1.9641, -1.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08576104044914246
Epoch 0, Step 1946: train/loss = 0.5099470019340515, train/raw-loss = 0.4350918233394623, train/logprobs = tensor([[-1.1186, -4.3481],
        [-1.0086, -1.1498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07485518604516983
Epoch 0, Step 1947: train/loss = 0.4654850959777832, train/raw-loss = 0.37550920248031616, train/logprobs = tensor([[-0.9691, -3.5856],
        [-1.3319, -1.4282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08997591584920883
Epoch 0, Step 1948: train/loss = 0.551819384098053, train/raw-loss = 0.4733355641365051, train/logprobs = tensor([[-1.0128, -2.5080],
        [-1.0750, -0.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07848379015922546
Epoch 0, Step 1949: train/loss = 0.43370747566223145, train/raw-loss = 0.3544939160346985, train/logprobs = tensor([[-0.7151, -4.1099],
        [-0.9377, -1.2037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921356707811356
Epoch 0, Step 1950: train/loss = 0.32827699184417725, train/raw-loss = 0.25586238503456116, train/logprobs = tensor([[-0.5504, -6.0443],
        [-0.7450, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724145844578743
Epoch 0, Step 1951: train/loss = 0.42648470401763916, train/raw-loss = 0.3232617676258087, train/logprobs = tensor([[-1.9527, -5.3405],
        [-2.5177, -1.3252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10322295129299164
Epoch 0, Step 1952: train/loss = 0.4321952164173126, train/raw-loss = 0.34632015228271484, train/logprobs = tensor([[-1.3261, -3.4197],
        [-1.8129, -1.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08587509393692017
Epoch 0, Step 1953: train/loss = 0.43525445461273193, train/raw-loss = 0.34887993335723877, train/logprobs = tensor([[-1.1429, -4.2792],
        [-1.5183, -1.5179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08637452125549316
Epoch 0, Step 1954: train/loss = 0.4834045171737671, train/raw-loss = 0.3835752010345459, train/logprobs = tensor([[-1.4756, -4.1078],
        [-1.7244, -1.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0998293086886406
Epoch 0, Step 1955: train/loss = 0.4878210127353668, train/raw-loss = 0.3720244765281677, train/logprobs = tensor([[-2.3359, -2.2610],
        [-3.1867, -1.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11579655110836029
Epoch 0, Step 1956: train/loss = 0.5109506845474243, train/raw-loss = 0.42138415575027466, train/logprobs = tensor([[-1.1222, -2.2654],
        [-1.7442, -0.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08956651389598846
Epoch 0, Step 1957: train/loss = 0.4648286700248718, train/raw-loss = 0.3718680739402771, train/logprobs = tensor([[-2.0466, -3.2466],
        [-2.4699, -1.6352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09296059608459473
Epoch 0, Step 1958: train/loss = 0.46644601225852966, train/raw-loss = 0.37123358249664307, train/logprobs = tensor([[-1.3357, -2.7309],
        [-2.0002, -1.3125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09521245211362839
Epoch 0, Step 1959: train/loss = 0.3275875151157379, train/raw-loss = 0.21784108877182007, train/logprobs = tensor([[-0.9146, -4.8845],
        [-2.0221, -1.8150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10974644124507904
Epoch 0, Step 1960: train/loss = 0.2876889109611511, train/raw-loss = 0.18112334609031677, train/logprobs = tensor([[-1.3662, -5.8157],
        [-2.3697, -1.9712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10656556487083435
Epoch 0, Step 1961: train/loss = 0.35893765091896057, train/raw-loss = 0.2734803557395935, train/logprobs = tensor([[-1.0145, -5.8139],
        [-1.6011, -1.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08545731753110886
Epoch 0, Step 1962: train/loss = 0.3727349042892456, train/raw-loss = 0.2826084494590759, train/logprobs = tensor([[-1.6794, -4.9685],
        [-2.0264, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09012646973133087
Epoch 0, Step 1963: train/loss = 0.513311505317688, train/raw-loss = 0.4153834581375122, train/logprobs = tensor([[-2.2135, -3.7758],
        [-2.2413, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0979280173778534
Epoch 0, Step 1964: train/loss = 0.436298668384552, train/raw-loss = 0.32977959513664246, train/logprobs = tensor([[-2.1440, -4.6081],
        [-2.5079, -2.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10651905834674835
Epoch 0, Step 1965: train/loss = 0.4697236716747284, train/raw-loss = 0.387406587600708, train/logprobs = tensor([[-1.3091, -4.0575],
        [-1.2733, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.082317054271698
Epoch 0, Step 1966: train/loss = 0.5568110346794128, train/raw-loss = 0.4822560250759125, train/logprobs = tensor([[-2.2452, -4.8283],
        [-1.7035, -1.2143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07455503940582275
Epoch 0, Step 1967: train/loss = 0.5361073017120361, train/raw-loss = 0.46077194809913635, train/logprobs = tensor([[-0.9098, -3.1527],
        [-1.0052, -1.4731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0753353163599968
Epoch 0, Step 1968: train/loss = 0.45513251423835754, train/raw-loss = 0.396675705909729, train/logprobs = tensor([[-0.6482, -3.2990],
        [-0.7110, -0.7887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05845681577920914
Epoch 0, Step 1969: train/loss = 0.5085070133209229, train/raw-loss = 0.41329556703567505, train/logprobs = tensor([[-1.2872, -2.7732],
        [-1.7050, -1.3977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09521141648292542
Epoch 0, Step 1970: train/loss = 0.5439817905426025, train/raw-loss = 0.4634566903114319, train/logprobs = tensor([[-1.2335, -2.6383],
        [-1.6794, -1.8527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08052510023117065
Epoch 0, Step 1971: train/loss = 0.40845543146133423, train/raw-loss = 0.3225289285182953, train/logprobs = tensor([[-0.6852, -4.2104],
        [-1.2808, -0.9423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08592652529478073
Epoch 0, Step 1972: train/loss = 0.57386714220047, train/raw-loss = 0.4989296495914459, train/logprobs = tensor([[-1.6450, -3.7434],
        [-1.2556, -1.4114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07493754476308823
Epoch 0, Step 1973: train/loss = 0.3842046856880188, train/raw-loss = 0.2940850257873535, train/logprobs = tensor([[-1.8596, -8.3955],
        [-1.9985, -2.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0901196226477623
Epoch 0, Step 1974: train/loss = 0.43044668436050415, train/raw-loss = 0.3323887884616852, train/logprobs = tensor([[-1.8114, -3.2883],
        [-2.3927, -1.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09805789589881897
Epoch 0, Step 1975: train/loss = 0.35388416051864624, train/raw-loss = 0.25577548146247864, train/logprobs = tensor([[-1.5587, -3.8149],
        [-2.6514, -1.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.098108671605587
Epoch 0, Step 1976: train/loss = 0.41891640424728394, train/raw-loss = 0.3436141312122345, train/logprobs = tensor([[-1.1890, -3.8491],
        [-1.4105, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07530228793621063
Epoch 0, Step 1977: train/loss = 0.4307771623134613, train/raw-loss = 0.35017502307891846, train/logprobs = tensor([[-0.8226, -3.5503],
        [-1.0886, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08060213923454285
Epoch 0, Step 1978: train/loss = 0.5614523887634277, train/raw-loss = 0.4933880567550659, train/logprobs = tensor([[-0.9588, -3.4475],
        [-0.9721, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06806434690952301
Epoch 0, Step 1979: train/loss = 0.5897291898727417, train/raw-loss = 0.490928590297699, train/logprobs = tensor([[-1.9117, -2.5352],
        [-2.4291, -1.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09880056232213974
Epoch 0, Step 1980: train/loss = 0.4918839931488037, train/raw-loss = 0.40537744760513306, train/logprobs = tensor([[-0.9577, -3.7104],
        [-1.6038, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08650659769773483
Epoch 0, Step 1981: train/loss = 0.30578917264938354, train/raw-loss = 0.21325890719890594, train/logprobs = tensor([[-1.1684, -4.6337],
        [-1.9257, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.092530257999897
Epoch 0, Step 1982: train/loss = 0.37951433658599854, train/raw-loss = 0.30666202306747437, train/logprobs = tensor([[-0.6250, -5.3944],
        [-0.7983, -2.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07285233587026596
Epoch 0, Step 1983: train/loss = 0.44011151790618896, train/raw-loss = 0.3328550159931183, train/logprobs = tensor([[-1.6616, -4.1152],
        [-2.0988, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10725650191307068
Epoch 0, Step 1984: train/loss = 0.4145175516605377, train/raw-loss = 0.3157234787940979, train/logprobs = tensor([[-1.9177, -5.5180],
        [-2.4407, -1.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09879408031702042
Epoch 0, Step 1985: train/loss = 0.23085731267929077, train/raw-loss = 0.1204875186085701, train/logprobs = tensor([[-1.0908, -5.8732],
        [-2.8551, -2.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11036978662014008
Epoch 0, Step 1986: train/loss = 0.3207921087741852, train/raw-loss = 0.2202371209859848, train/logprobs = tensor([[-1.5637, -4.0649],
        [-2.5680, -1.7469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10055499523878098
Epoch 0, Step 1987: train/loss = 0.4036285877227783, train/raw-loss = 0.3133116364479065, train/logprobs = tensor([[-1.4074, -3.4433],
        [-2.5092, -1.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09031693637371063
Epoch 0, Step 1988: train/loss = 0.35579437017440796, train/raw-loss = 0.2678951621055603, train/logprobs = tensor([[-1.2389, -4.4406],
        [-2.0063, -1.6941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08789919316768646
Epoch 0, Step 1989: train/loss = 0.47240716218948364, train/raw-loss = 0.4105360507965088, train/logprobs = tensor([[-1.5084, -3.7657],
        [-1.7622, -1.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06187111884355545
Epoch 0, Step 1990: train/loss = 0.29810142517089844, train/raw-loss = 0.18992651998996735, train/logprobs = tensor([[-1.0030, -4.7531],
        [-2.0617, -1.3900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10817491263151169
Epoch 0, Step 1991: train/loss = 0.4786473512649536, train/raw-loss = 0.38347071409225464, train/logprobs = tensor([[-1.4156, -3.1435],
        [-2.2189, -1.2917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09517661482095718
Epoch 0, Step 1992: train/loss = 0.47672638297080994, train/raw-loss = 0.3980119526386261, train/logprobs = tensor([[-1.3885, -3.2232],
        [-1.7335, -1.6819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07871443033218384
Epoch 0, Step 1993: train/loss = 0.3578033149242401, train/raw-loss = 0.26076942682266235, train/logprobs = tensor([[-1.4503, -4.1675],
        [-2.2687, -1.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09703388810157776
Epoch 0, Step 1994: train/loss = 0.5153898000717163, train/raw-loss = 0.42838284373283386, train/logprobs = tensor([[-1.9325, -3.6853],
        [-2.1089, -1.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08700700104236603
Epoch 0, Step 1995: train/loss = 0.5738661885261536, train/raw-loss = 0.5018344521522522, train/logprobs = tensor([[-0.8582, -2.5359],
        [-1.0082, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07203172892332077
Epoch 0, Step 1996: train/loss = 0.5361418724060059, train/raw-loss = 0.45237529277801514, train/logprobs = tensor([[-0.7690, -2.6930],
        [-0.8753, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08376657217741013
Epoch 0, Step 1997: train/loss = 0.5436561107635498, train/raw-loss = 0.4568837583065033, train/logprobs = tensor([[-1.8199, -5.4923],
        [-1.5967, -1.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0867723599076271
Epoch 0, Step 1998: train/loss = 0.4601491093635559, train/raw-loss = 0.34375953674316406, train/logprobs = tensor([[-1.1760, -3.6143],
        [-2.0758, -2.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11638959497213364
Epoch 0, Step 1999: train/loss = 0.4047926962375641, train/raw-loss = 0.31316453218460083, train/logprobs = tensor([[-1.7952, -2.4997],
        [-2.4573, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09162811934947968
eval/loss: 0.45018014311790466
Epoch 0, Step 2000: train/loss = 0.544897198677063, train/raw-loss = 0.44938331842422485, train/logprobs = tensor([[-1.4102, -2.5329],
        [-2.0272, -1.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09551383554935455
Epoch 0, Step 2001: train/loss = 0.380648136138916, train/raw-loss = 0.2630818486213684, train/logprobs = tensor([[-1.0903, -3.8288],
        [-2.1077, -1.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11756625771522522
Epoch 0, Step 2002: train/loss = 0.3431004583835602, train/raw-loss = 0.24792519211769104, train/logprobs = tensor([[-1.1322, -4.3897],
        [-2.2071, -2.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09517525881528854
Epoch 0, Step 2003: train/loss = 0.4159659445285797, train/raw-loss = 0.3325396180152893, train/logprobs = tensor([[-1.5417, -3.8111],
        [-2.3528, -1.6285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08342631906270981
Epoch 0, Step 2004: train/loss = 0.43267717957496643, train/raw-loss = 0.35116493701934814, train/logprobs = tensor([[-1.2399, -3.7346],
        [-1.6071, -1.5152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08151224255561829
Epoch 0, Step 2005: train/loss = 0.4087842106819153, train/raw-loss = 0.33020803332328796, train/logprobs = tensor([[-1.0974, -6.5601],
        [-1.1414, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07857620716094971
Epoch 0, Step 2006: train/loss = 0.3925632834434509, train/raw-loss = 0.2819977104663849, train/logprobs = tensor([[-1.4462, -3.6308],
        [-2.2336, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11056552082300186
Epoch 0, Step 2007: train/loss = 0.6471088528633118, train/raw-loss = 0.5387206077575684, train/logprobs = tensor([[-1.8611, -2.9251],
        [-1.9980, -2.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10838828980922699
Epoch 0, Step 2008: train/loss = 0.5024392604827881, train/raw-loss = 0.39494335651397705, train/logprobs = tensor([[-1.5206, -5.0884],
        [-1.8237, -2.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10749591886997223
Epoch 0, Step 2009: train/loss = 0.5028523206710815, train/raw-loss = 0.4241292476654053, train/logprobs = tensor([[-0.9595, -2.1743],
        [-1.3650, -0.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07872307300567627
Epoch 0, Step 2010: train/loss = 0.6145009994506836, train/raw-loss = 0.5521939396858215, train/logprobs = tensor([[-0.8139, -1.3073],
        [-0.9458, -0.7359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062307003885507584
Epoch 0, Step 2011: train/loss = 0.4197237491607666, train/raw-loss = 0.2995942533016205, train/logprobs = tensor([[-1.6615, -3.1388],
        [-3.0234, -1.0710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12012948095798492
Epoch 0, Step 2012: train/loss = 0.5290897488594055, train/raw-loss = 0.4528120756149292, train/logprobs = tensor([[-1.3595, -3.4873],
        [-1.8262, -1.5238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07627769559621811
Epoch 0, Step 2013: train/loss = 0.3650958836078644, train/raw-loss = 0.27672797441482544, train/logprobs = tensor([[-0.8688, -4.5726],
        [-1.3628, -1.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08836790919303894
Epoch 0, Step 2014: train/loss = 0.3861413300037384, train/raw-loss = 0.28277724981307983, train/logprobs = tensor([[-1.7400, -3.7041],
        [-2.3960, -1.2356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10336410999298096
Epoch 0, Step 2015: train/loss = 0.5355717539787292, train/raw-loss = 0.4538823962211609, train/logprobs = tensor([[-1.4768, -3.8507],
        [-1.4921, -1.5509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08168932795524597
Epoch 0, Step 2016: train/loss = 0.4587417244911194, train/raw-loss = 0.37740713357925415, train/logprobs = tensor([[-0.8956, -3.2834],
        [-1.4945, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08133458346128464
Epoch 0, Step 2017: train/loss = 0.4933956265449524, train/raw-loss = 0.40970277786254883, train/logprobs = tensor([[-1.1383, -3.3547],
        [-1.5563, -1.3087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08369285613298416
Epoch 0, Step 2018: train/loss = 0.6462280750274658, train/raw-loss = 0.5550445318222046, train/logprobs = tensor([[-1.5825, -1.8990],
        [-1.9165, -1.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09118355810642242
Epoch 0, Step 2019: train/loss = 0.5545700788497925, train/raw-loss = 0.48357558250427246, train/logprobs = tensor([[-0.6717, -1.7397],
        [-0.9541, -0.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07099448144435883
Epoch 0, Step 2020: train/loss = 0.4999814033508301, train/raw-loss = 0.4210449159145355, train/logprobs = tensor([[-1.3962, -3.8461],
        [-1.6941, -2.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07893645763397217
Epoch 0, Step 2021: train/loss = 0.4779708981513977, train/raw-loss = 0.3479321599006653, train/logprobs = tensor([[-1.1549, -2.5541],
        [-2.1131, -1.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13003870844841003
Epoch 0, Step 2022: train/loss = 0.5362005829811096, train/raw-loss = 0.4826635718345642, train/logprobs = tensor([[-1.2793, -3.7473],
        [-0.9027, -1.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053536996245384216
Epoch 0, Step 2023: train/loss = 0.30822232365608215, train/raw-loss = 0.22465689480304718, train/logprobs = tensor([[-1.1770, -4.4031],
        [-1.8595, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08356542885303497
Epoch 0, Step 2024: train/loss = 0.5451436042785645, train/raw-loss = 0.4694897532463074, train/logprobs = tensor([[-1.5963, -2.5577],
        [-1.8882, -1.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0756537914276123
Epoch 0, Step 2025: train/loss = 0.40848803520202637, train/raw-loss = 0.33281320333480835, train/logprobs = tensor([[-0.8038, -4.3224],
        [-0.9624, -1.1715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07567484676837921
Epoch 0, Step 2026: train/loss = 0.5189785957336426, train/raw-loss = 0.4399655759334564, train/logprobs = tensor([[-1.2413, -3.6460],
        [-1.7765, -1.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07901302725076675
Epoch 0, Step 2027: train/loss = 0.3900192677974701, train/raw-loss = 0.2965545058250427, train/logprobs = tensor([[-1.9069, -4.4415],
        [-3.0107, -2.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09346475452184677
Epoch 0, Step 2028: train/loss = 0.5077517628669739, train/raw-loss = 0.4190058708190918, train/logprobs = tensor([[-1.1143, -3.1343],
        [-1.3784, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08874592930078506
Epoch 0, Step 2029: train/loss = 0.40391895174980164, train/raw-loss = 0.32290494441986084, train/logprobs = tensor([[-1.1917, -3.2690],
        [-1.8612, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08101406693458557
Epoch 0, Step 2030: train/loss = 0.3717305660247803, train/raw-loss = 0.284645140171051, train/logprobs = tensor([[-1.7680, -4.3404],
        [-2.3533, -1.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08708541095256805
Epoch 0, Step 2031: train/loss = 0.3490779995918274, train/raw-loss = 0.24524033069610596, train/logprobs = tensor([[-0.9858, -4.1395],
        [-1.6923, -1.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10383769869804382
Epoch 0, Step 2032: train/loss = 0.37834784388542175, train/raw-loss = 0.29262784123420715, train/logprobs = tensor([[-0.9322, -4.5741],
        [-1.5814, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08572003245353699
Epoch 0, Step 2033: train/loss = 0.6104633808135986, train/raw-loss = 0.5116711258888245, train/logprobs = tensor([[-1.4412, -3.0743],
        [-1.8023, -2.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09879224747419357
Epoch 0, Step 2034: train/loss = 0.4729694128036499, train/raw-loss = 0.3563302159309387, train/logprobs = tensor([[-0.8995, -3.4851],
        [-1.7679, -1.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11663920432329178
Epoch 0, Step 2035: train/loss = 0.4271812438964844, train/raw-loss = 0.33462750911712646, train/logprobs = tensor([[-1.2074, -4.9419],
        [-1.7885, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0925537496805191
Epoch 0, Step 2036: train/loss = 0.3431163728237152, train/raw-loss = 0.24083486199378967, train/logprobs = tensor([[-1.4535, -3.1404],
        [-2.3733, -1.0970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10228149592876434
Epoch 0, Step 2037: train/loss = 0.5295082330703735, train/raw-loss = 0.4567384719848633, train/logprobs = tensor([[-0.7956, -2.8104],
        [-0.9480, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276975363492966
Epoch 0, Step 2038: train/loss = 0.6095397472381592, train/raw-loss = 0.5197605490684509, train/logprobs = tensor([[-1.0265, -1.9419],
        [-1.3894, -1.2766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08977926522493362
Epoch 0, Step 2039: train/loss = 0.3971109390258789, train/raw-loss = 0.3056575655937195, train/logprobs = tensor([[-1.0074, -4.7045],
        [-1.3284, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09145334362983704
Epoch 0, Step 2040: train/loss = 0.6455023884773254, train/raw-loss = 0.5596261024475098, train/logprobs = tensor([[-1.7181, -2.6602],
        [-1.6986, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08587630838155746
Epoch 0, Step 2041: train/loss = 0.42403241991996765, train/raw-loss = 0.3473995327949524, train/logprobs = tensor([[-1.0710, -4.0724],
        [-1.4488, -1.8935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07663289457559586
Epoch 0, Step 2042: train/loss = 0.43071484565734863, train/raw-loss = 0.3596557378768921, train/logprobs = tensor([[-0.4809, -4.2982],
        [-0.7167, -1.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07105913758277893
Epoch 0, Step 2043: train/loss = 0.5081876516342163, train/raw-loss = 0.43287986516952515, train/logprobs = tensor([[-0.7647, -2.8704],
        [-1.1974, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07530781626701355
Epoch 0, Step 2044: train/loss = 0.46175646781921387, train/raw-loss = 0.3788331151008606, train/logprobs = tensor([[-1.1779, -2.4476],
        [-1.9560, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08292333036661148
Epoch 0, Step 2045: train/loss = 0.439700186252594, train/raw-loss = 0.36738815903663635, train/logprobs = tensor([[-1.2797, -4.4768],
        [-1.4185, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07231202721595764
Epoch 0, Step 2046: train/loss = 0.38849562406539917, train/raw-loss = 0.3074188232421875, train/logprobs = tensor([[-1.1408, -4.1608],
        [-1.2904, -1.4542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08107684552669525
Epoch 0, Step 2047: train/loss = 0.38654816150665283, train/raw-loss = 0.2977951169013977, train/logprobs = tensor([[-1.3301, -6.2158],
        [-1.5751, -1.3930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08875307440757751
Epoch 0, Step 2048: train/loss = 0.39326903223991394, train/raw-loss = 0.28569409251213074, train/logprobs = tensor([[-1.4441, -3.1897],
        [-2.7169, -1.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10757492482662201
Epoch 0, Step 2049: train/loss = 0.365453839302063, train/raw-loss = 0.2740347385406494, train/logprobs = tensor([[-1.4157, -3.8405],
        [-2.1448, -1.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09141908586025238
Epoch 0, Step 2050: train/loss = 0.4100017249584198, train/raw-loss = 0.32251277565956116, train/logprobs = tensor([[-1.1560, -4.7247],
        [-1.5547, -2.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08748893439769745
Epoch 0, Step 2051: train/loss = 0.5941612720489502, train/raw-loss = 0.49797767400741577, train/logprobs = tensor([[-1.9918, -4.2671],
        [-1.9694, -2.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09618355333805084
Epoch 0, Step 2052: train/loss = 0.4405249357223511, train/raw-loss = 0.33581581711769104, train/logprobs = tensor([[-1.7599, -3.2673],
        [-2.4765, -1.7039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10470912605524063
Epoch 0, Step 2053: train/loss = 0.4520237445831299, train/raw-loss = 0.3821709156036377, train/logprobs = tensor([[-1.4019, -2.7944],
        [-1.8426, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06985282897949219
Epoch 0, Step 2054: train/loss = 0.5449699759483337, train/raw-loss = 0.46951863169670105, train/logprobs = tensor([[-0.9709, -2.5988],
        [-1.2012, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07545138150453568
Epoch 0, Step 2055: train/loss = 0.4346121847629547, train/raw-loss = 0.34517043828964233, train/logprobs = tensor([[-1.1363, -3.6885],
        [-1.7834, -1.4090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08944172412157059
Epoch 0, Step 2056: train/loss = 0.618288516998291, train/raw-loss = 0.5395259857177734, train/logprobs = tensor([[-0.9683, -1.1049],
        [-1.3929, -0.7845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07876250892877579
Epoch 0, Step 2057: train/loss = 0.36425548791885376, train/raw-loss = 0.2593500018119812, train/logprobs = tensor([[-1.6817, -5.0191],
        [-2.8379, -1.8301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10490548610687256
Epoch 0, Step 2058: train/loss = 0.4122583568096161, train/raw-loss = 0.30487120151519775, train/logprobs = tensor([[-1.7532, -5.2429],
        [-2.7936, -1.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10738717764616013
Epoch 0, Step 2059: train/loss = 0.31539222598075867, train/raw-loss = 0.2275465726852417, train/logprobs = tensor([[-1.3142, -5.1244],
        [-2.1642, -1.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08784565329551697
Epoch 0, Step 2060: train/loss = 0.43394359946250916, train/raw-loss = 0.36360248923301697, train/logprobs = tensor([[-0.9836, -4.9953],
        [-1.1038, -1.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.070341095328331
Epoch 0, Step 2061: train/loss = 0.39995837211608887, train/raw-loss = 0.30486902594566345, train/logprobs = tensor([[-1.5809, -3.4274],
        [-2.9323, -1.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0950893759727478
Epoch 0, Step 2062: train/loss = 0.6200845241546631, train/raw-loss = 0.5434738397598267, train/logprobs = tensor([[-1.1466, -2.3115],
        [-1.5636, -1.7602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07661072164773941
Epoch 0, Step 2063: train/loss = 0.3989109992980957, train/raw-loss = 0.3087261915206909, train/logprobs = tensor([[-1.5133, -3.0153],
        [-2.4396, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09018480777740479
Epoch 0, Step 2064: train/loss = 0.5584226250648499, train/raw-loss = 0.4695890545845032, train/logprobs = tensor([[-0.9421, -1.6710],
        [-1.7198, -1.2715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08883355557918549
Epoch 0, Step 2065: train/loss = 0.5859041213989258, train/raw-loss = 0.5348337888717651, train/logprobs = tensor([[-0.4658, -1.6754],
        [-0.5088, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05107034370303154
Epoch 0, Step 2066: train/loss = 0.3719561696052551, train/raw-loss = 0.2733999788761139, train/logprobs = tensor([[-1.4909, -5.1104],
        [-1.9928, -1.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09855621308088303
Epoch 0, Step 2067: train/loss = 0.38923758268356323, train/raw-loss = 0.32453978061676025, train/logprobs = tensor([[-0.8064, -3.1959],
        [-1.3932, -0.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06469778716564178
Epoch 0, Step 2068: train/loss = 0.3214029371738434, train/raw-loss = 0.22583386301994324, train/logprobs = tensor([[-1.2045, -3.8088],
        [-2.2062, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09556910395622253
Epoch 0, Step 2069: train/loss = 0.6222132444381714, train/raw-loss = 0.5578361749649048, train/logprobs = tensor([[-1.6574, -2.1786],
        [-2.0609, -1.8973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06437703967094421
Epoch 0, Step 2070: train/loss = 0.3839860260486603, train/raw-loss = 0.29187077283859253, train/logprobs = tensor([[-1.4658, -3.6686],
        [-1.9249, -1.3190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09211526066064835
Epoch 0, Step 2071: train/loss = 0.40367481112480164, train/raw-loss = 0.33608776330947876, train/logprobs = tensor([[-1.2647, -5.4607],
        [-1.5538, -1.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06758705526590347
Epoch 0, Step 2072: train/loss = 0.2846589982509613, train/raw-loss = 0.18464884161949158, train/logprobs = tensor([[-1.2727, -4.9212],
        [-2.3573, -1.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10001014173030853
Epoch 0, Step 2073: train/loss = 0.5374315977096558, train/raw-loss = 0.44780564308166504, train/logprobs = tensor([[-1.1915, -2.3377],
        [-1.9070, -1.1588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08962596952915192
Epoch 0, Step 2074: train/loss = 0.4947923421859741, train/raw-loss = 0.40434330701828003, train/logprobs = tensor([[-1.4262, -3.2168],
        [-1.8967, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904490277171135
Epoch 0, Step 2075: train/loss = 0.4294465482234955, train/raw-loss = 0.34505265951156616, train/logprobs = tensor([[-0.5990, -3.8669],
        [-1.0226, -1.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08439387381076813
Epoch 0, Step 2076: train/loss = 0.6152623295783997, train/raw-loss = 0.5268094539642334, train/logprobs = tensor([[-1.2663, -2.0186],
        [-1.9240, -1.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08845289796590805
Epoch 0, Step 2077: train/loss = 0.4546869099140167, train/raw-loss = 0.3709958493709564, train/logprobs = tensor([[-1.2146, -3.1727],
        [-2.1636, -1.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0836910754442215
Epoch 0, Step 2078: train/loss = 0.5165576338768005, train/raw-loss = 0.45300617814064026, train/logprobs = tensor([[-1.3624, -3.1199],
        [-1.2662, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0635514184832573
Epoch 0, Step 2079: train/loss = 0.38783952593803406, train/raw-loss = 0.30687838792800903, train/logprobs = tensor([[-0.7181, -4.0842],
        [-1.0521, -1.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08096113055944443
Epoch 0, Step 2080: train/loss = 0.4585086703300476, train/raw-loss = 0.3722675144672394, train/logprobs = tensor([[-1.0281, -4.2625],
        [-1.3764, -1.5686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08624114841222763
Epoch 0, Step 2081: train/loss = 0.4084723889827728, train/raw-loss = 0.3186984062194824, train/logprobs = tensor([[-1.5647, -3.5657],
        [-2.7452, -1.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08977401256561279
Epoch 0, Step 2082: train/loss = 0.4216402769088745, train/raw-loss = 0.3325023651123047, train/logprobs = tensor([[-1.4388, -3.8732],
        [-2.3190, -2.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08913788199424744
Epoch 0, Step 2083: train/loss = 0.3026798963546753, train/raw-loss = 0.2220386564731598, train/logprobs = tensor([[-0.7598, -5.0914],
        [-1.4886, -1.4883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0806412473320961
Epoch 0, Step 2084: train/loss = 0.39149126410484314, train/raw-loss = 0.3039977550506592, train/logprobs = tensor([[-1.6372, -2.7880],
        [-2.6174, -1.2198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08749350160360336
Epoch 0, Step 2085: train/loss = 0.295612096786499, train/raw-loss = 0.20042338967323303, train/logprobs = tensor([[-1.0093, -4.7309],
        [-2.0696, -2.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09518870711326599
Epoch 0, Step 2086: train/loss = 0.39578771591186523, train/raw-loss = 0.3311038613319397, train/logprobs = tensor([[-1.0917, -4.7813],
        [-1.1387, -1.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06468386948108673
Epoch 0, Step 2087: train/loss = 0.36878976225852966, train/raw-loss = 0.25220295786857605, train/logprobs = tensor([[-1.2477, -5.4384],
        [-2.0736, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.116586834192276
Epoch 0, Step 2088: train/loss = 0.34754741191864014, train/raw-loss = 0.2839593291282654, train/logprobs = tensor([[-0.8114, -5.0216],
        [-0.9990, -1.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06358806788921356
Epoch 0, Step 2089: train/loss = 0.5089473128318787, train/raw-loss = 0.42031025886535645, train/logprobs = tensor([[-1.6369, -4.5535],
        [-1.9972, -1.4933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0886370837688446
Epoch 0, Step 2090: train/loss = 0.3628970980644226, train/raw-loss = 0.27506691217422485, train/logprobs = tensor([[-0.8847, -5.1115],
        [-1.5510, -1.7686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08783019334077835
Epoch 0, Step 2091: train/loss = 0.5440908670425415, train/raw-loss = 0.4527623951435089, train/logprobs = tensor([[-1.6222, -3.1660],
        [-2.7383, -2.6752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09132847934961319
Epoch 0, Step 2092: train/loss = 0.3220767378807068, train/raw-loss = 0.20275142788887024, train/logprobs = tensor([[-1.4700, -3.7057],
        [-2.9068, -1.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932528018951416
Epoch 0, Step 2093: train/loss = 0.4303078353404999, train/raw-loss = 0.34846699237823486, train/logprobs = tensor([[-0.9381, -3.6439],
        [-1.3942, -1.0828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0818408653140068
Epoch 0, Step 2094: train/loss = 0.4138714671134949, train/raw-loss = 0.31676238775253296, train/logprobs = tensor([[-1.1090, -3.3766],
        [-1.6505, -1.4324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09710907936096191
Epoch 0, Step 2095: train/loss = 0.5168969631195068, train/raw-loss = 0.4087216556072235, train/logprobs = tensor([[-1.6734, -2.9589],
        [-2.5854, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10817528516054153
Epoch 0, Step 2096: train/loss = 0.3969922661781311, train/raw-loss = 0.30121588706970215, train/logprobs = tensor([[-1.9057, -4.3390],
        [-2.8296, -1.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09577636420726776
Epoch 0, Step 2097: train/loss = 0.4488086700439453, train/raw-loss = 0.35169386863708496, train/logprobs = tensor([[-1.3396, -2.9315],
        [-1.8674, -1.4241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09711483120918274
Epoch 0, Step 2098: train/loss = 0.6830062866210938, train/raw-loss = 0.6007551550865173, train/logprobs = tensor([[-0.8205, -0.9061],
        [-1.2193, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08225111663341522
Epoch 0, Step 2099: train/loss = 0.443137526512146, train/raw-loss = 0.36272305250167847, train/logprobs = tensor([[-0.9820, -3.4484],
        [-1.3264, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08041447401046753
Epoch 0, Step 2100: train/loss = 0.3082257807254791, train/raw-loss = 0.2137795388698578, train/logprobs = tensor([[-1.3848, -5.2320],
        [-2.3767, -2.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09444625675678253
Epoch 0, Step 2101: train/loss = 0.5462455749511719, train/raw-loss = 0.44712817668914795, train/logprobs = tensor([[-1.6274, -2.8595],
        [-2.3620, -2.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09911741316318512
Epoch 0, Step 2102: train/loss = 0.3800886273384094, train/raw-loss = 0.2923141121864319, train/logprobs = tensor([[-0.9907, -2.8167],
        [-1.9575, -0.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08777451515197754
Epoch 0, Step 2103: train/loss = 0.4251056909561157, train/raw-loss = 0.33523815870285034, train/logprobs = tensor([[-1.0940, -3.1746],
        [-1.6968, -1.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08986753225326538
Epoch 0, Step 2104: train/loss = 0.46289345622062683, train/raw-loss = 0.3823082447052002, train/logprobs = tensor([[-1.1285, -3.4334],
        [-1.4181, -1.1009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08058518171310425
Epoch 0, Step 2105: train/loss = 0.4785594940185547, train/raw-loss = 0.37505099177360535, train/logprobs = tensor([[-1.9161, -2.8637],
        [-2.7525, -1.6746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350853949785233
Epoch 0, Step 2106: train/loss = 0.3182150721549988, train/raw-loss = 0.1925850212574005, train/logprobs = tensor([[-1.2613, -3.9334],
        [-2.8031, -1.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12563005089759827
Epoch 0, Step 2107: train/loss = 0.4055476784706116, train/raw-loss = 0.2858530580997467, train/logprobs = tensor([[-1.3495, -2.5920],
        [-2.8296, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11969462782144547
Epoch 0, Step 2108: train/loss = 0.4084823429584503, train/raw-loss = 0.3152625560760498, train/logprobs = tensor([[-1.2320, -3.8535],
        [-1.7321, -1.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09321979433298111
Epoch 0, Step 2109: train/loss = 0.40788060426712036, train/raw-loss = 0.31504103541374207, train/logprobs = tensor([[-1.3463, -3.7241],
        [-2.2001, -1.4842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0928395614027977
Epoch 0, Step 2110: train/loss = 0.45000922679901123, train/raw-loss = 0.37602710723876953, train/logprobs = tensor([[-1.0970, -2.6969],
        [-1.7679, -1.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0739821121096611
Epoch 0, Step 2111: train/loss = 0.539261519908905, train/raw-loss = 0.4781583547592163, train/logprobs = tensor([[-1.9410, -4.5114],
        [-1.7427, -1.4160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061103206127882004
Epoch 0, Step 2112: train/loss = 0.45936620235443115, train/raw-loss = 0.39505714178085327, train/logprobs = tensor([[-0.6790, -4.0073],
        [-0.9028, -1.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06430907547473907
Epoch 0, Step 2113: train/loss = 0.329353392124176, train/raw-loss = 0.24315792322158813, train/logprobs = tensor([[-1.6867, -5.0353],
        [-2.6594, -1.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08619547635316849
Epoch 0, Step 2114: train/loss = 0.5449967384338379, train/raw-loss = 0.472552627325058, train/logprobs = tensor([[-0.9656, -2.5319],
        [-1.0963, -0.8112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724441185593605
Epoch 0, Step 2115: train/loss = 0.9097414016723633, train/raw-loss = 0.822596549987793, train/logprobs = tensor([[-3.8968, -6.0722],
        [-2.6873, -2.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08714490383863449
Epoch 0, Step 2116: train/loss = 0.3265155553817749, train/raw-loss = 0.24091297388076782, train/logprobs = tensor([[-1.4535, -4.5278],
        [-2.4055, -1.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08560258150100708
Epoch 0, Step 2117: train/loss = 0.41765159368515015, train/raw-loss = 0.32999923825263977, train/logprobs = tensor([[-1.3335, -2.7503],
        [-2.0954, -1.3644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08765237778425217
Epoch 0, Step 2118: train/loss = 0.4371741712093353, train/raw-loss = 0.3710639774799347, train/logprobs = tensor([[-0.7489, -4.2415],
        [-0.8992, -1.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06611018627882004
Epoch 0, Step 2119: train/loss = 0.39392510056495667, train/raw-loss = 0.28927549719810486, train/logprobs = tensor([[-1.4674, -2.9200],
        [-2.9056, -1.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.104649618268013
Epoch 0, Step 2120: train/loss = 0.3399973511695862, train/raw-loss = 0.25240516662597656, train/logprobs = tensor([[-1.3044, -5.4684],
        [-2.0750, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0875922292470932
Epoch 0, Step 2121: train/loss = 0.5620691776275635, train/raw-loss = 0.47506576776504517, train/logprobs = tensor([[-1.3703, -1.7511],
        [-2.2144, -1.1195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0870034322142601
Epoch 0, Step 2122: train/loss = 0.4191674292087555, train/raw-loss = 0.311714231967926, train/logprobs = tensor([[-1.1888, -3.0006],
        [-2.1582, -1.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10745323449373245
Epoch 0, Step 2123: train/loss = 0.7769327759742737, train/raw-loss = 0.692581295967102, train/logprobs = tensor([[-3.3576, -3.9875],
        [-2.6393, -1.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08435146510601044
Epoch 0, Step 2124: train/loss = 0.48250335454940796, train/raw-loss = 0.38258782029151917, train/logprobs = tensor([[-1.4789, -2.3957],
        [-2.8035, -1.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0999155044555664
Epoch 0, Step 2125: train/loss = 0.3286796808242798, train/raw-loss = 0.22258834540843964, train/logprobs = tensor([[-1.3316, -4.6093],
        [-2.7112, -1.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10609131306409836
Epoch 0, Step 2126: train/loss = 0.4155478775501251, train/raw-loss = 0.33599984645843506, train/logprobs = tensor([[-1.0829, -3.1658],
        [-1.6137, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07954804599285126
Epoch 0, Step 2127: train/loss = 0.4775579571723938, train/raw-loss = 0.38332220911979675, train/logprobs = tensor([[-1.3832, -2.0063],
        [-2.9662, -1.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09423577040433884
Epoch 0, Step 2128: train/loss = 0.45997199416160583, train/raw-loss = 0.35359251499176025, train/logprobs = tensor([[-1.2250, -3.5231],
        [-2.5197, -2.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10637950152158737
Epoch 0, Step 2129: train/loss = 0.4335416853427887, train/raw-loss = 0.3490579426288605, train/logprobs = tensor([[-0.7719, -4.3855],
        [-1.1331, -1.4655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08448370546102524
Epoch 0, Step 2130: train/loss = 0.4860307574272156, train/raw-loss = 0.4098678529262543, train/logprobs = tensor([[-0.6929, -3.0922],
        [-1.1941, -1.6037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0761629045009613
Epoch 0, Step 2131: train/loss = 0.40467867255210876, train/raw-loss = 0.31983476877212524, train/logprobs = tensor([[-1.2280, -3.7786],
        [-2.0236, -1.3519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08484387397766113
Epoch 0, Step 2132: train/loss = 0.27947402000427246, train/raw-loss = 0.18935850262641907, train/logprobs = tensor([[-1.0511, -4.3199],
        [-2.2154, -1.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09011552482843399
Epoch 0, Step 2133: train/loss = 0.47194385528564453, train/raw-loss = 0.40199989080429077, train/logprobs = tensor([[-0.6221, -4.5495],
        [-0.8000, -1.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06994395703077316
Epoch 0, Step 2134: train/loss = 0.24270933866500854, train/raw-loss = 0.1371922343969345, train/logprobs = tensor([[-1.2546, -5.4728],
        [-2.5961, -1.3448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10551710426807404
Epoch 0, Step 2135: train/loss = 0.6126057505607605, train/raw-loss = 0.5206838846206665, train/logprobs = tensor([[-1.0016, -1.6189],
        [-1.6316, -1.2495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09192191809415817
Epoch 0, Step 2136: train/loss = 0.4439094364643097, train/raw-loss = 0.35728681087493896, train/logprobs = tensor([[-0.6755, -3.2806],
        [-1.1661, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08662262558937073
Epoch 0, Step 2137: train/loss = 0.3629424571990967, train/raw-loss = 0.2800568640232086, train/logprobs = tensor([[-1.4684, -4.5548],
        [-2.5135, -1.6039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08288559317588806
Epoch 0, Step 2138: train/loss = 0.3828652799129486, train/raw-loss = 0.3042410612106323, train/logprobs = tensor([[-2.0845, -5.1348],
        [-2.5097, -2.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07862421870231628
Epoch 0, Step 2139: train/loss = 0.3395686745643616, train/raw-loss = 0.22186489403247833, train/logprobs = tensor([[-1.5714, -6.0936],
        [-2.8569, -2.2177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11770379543304443
Epoch 0, Step 2140: train/loss = 0.5376543998718262, train/raw-loss = 0.41559264063835144, train/logprobs = tensor([[-2.2120, -2.4957],
        [-2.6529, -0.9494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12206172943115234
Epoch 0, Step 2141: train/loss = 0.36373165249824524, train/raw-loss = 0.24744991958141327, train/logprobs = tensor([[-1.8589, -4.5893],
        [-3.2302, -2.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11628174036741257
Epoch 0, Step 2142: train/loss = 0.5098534822463989, train/raw-loss = 0.3956025242805481, train/logprobs = tensor([[-1.1819, -2.0200],
        [-2.9308, -1.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11425092816352844
Epoch 0, Step 2143: train/loss = 0.4252888858318329, train/raw-loss = 0.3317941427230835, train/logprobs = tensor([[-1.5370, -3.9536],
        [-2.1570, -1.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09349476546049118
Epoch 0, Step 2144: train/loss = 0.4665891230106354, train/raw-loss = 0.38491350412368774, train/logprobs = tensor([[-0.8734, -2.7885],
        [-1.3466, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08167558908462524
Epoch 0, Step 2145: train/loss = 0.49975621700286865, train/raw-loss = 0.3949253559112549, train/logprobs = tensor([[-1.7304, -2.7104],
        [-2.7283, -1.3391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10483087599277496
Epoch 0, Step 2146: train/loss = 0.40122371912002563, train/raw-loss = 0.3102171719074249, train/logprobs = tensor([[-1.3775, -3.3487],
        [-2.1177, -1.1482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0910065621137619
Epoch 0, Step 2147: train/loss = 0.5287843346595764, train/raw-loss = 0.4404747486114502, train/logprobs = tensor([[-1.2281, -3.1843],
        [-1.9347, -1.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08830955624580383
Epoch 0, Step 2148: train/loss = 0.4476860761642456, train/raw-loss = 0.318075954914093, train/logprobs = tensor([[-1.4672, -2.7078],
        [-3.1441, -1.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1296100914478302
Epoch 0, Step 2149: train/loss = 0.3900575041770935, train/raw-loss = 0.310996949672699, train/logprobs = tensor([[-1.4054, -4.6321],
        [-1.6173, -1.2846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906053960323334
Epoch 0, Step 2150: train/loss = 0.48181283473968506, train/raw-loss = 0.3945007920265198, train/logprobs = tensor([[-1.5682, -5.9645],
        [-1.5136, -1.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0873120129108429
Epoch 0, Step 2151: train/loss = 0.27257224917411804, train/raw-loss = 0.15869666635990143, train/logprobs = tensor([[-1.4621, -4.2188],
        [-3.1831, -1.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11387555301189423
Epoch 0, Step 2152: train/loss = 0.27527064085006714, train/raw-loss = 0.15012679994106293, train/logprobs = tensor([[-1.1807, -4.7778],
        [-2.9417, -1.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12514382600784302
Epoch 0, Step 2153: train/loss = 0.5489903688430786, train/raw-loss = 0.47018423676490784, train/logprobs = tensor([[-0.4959, -2.8581],
        [-0.7305, -1.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07880613952875137
Epoch 0, Step 2154: train/loss = 0.3296504616737366, train/raw-loss = 0.2493446171283722, train/logprobs = tensor([[-1.3338, -3.4430],
        [-2.7448, -1.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08030585199594498
Epoch 0, Step 2155: train/loss = 0.4462037682533264, train/raw-loss = 0.35517749190330505, train/logprobs = tensor([[-1.5055, -4.3968],
        [-1.8557, -2.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09102629870176315
Epoch 0, Step 2156: train/loss = 0.507023811340332, train/raw-loss = 0.4137081801891327, train/logprobs = tensor([[-1.1314, -2.3875],
        [-1.8697, -1.2496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09331564605236053
Epoch 0, Step 2157: train/loss = 0.3258133828639984, train/raw-loss = 0.23495608568191528, train/logprobs = tensor([[-0.9327, -4.5807],
        [-1.6315, -1.5601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09085729718208313
Epoch 0, Step 2158: train/loss = 0.36335113644599915, train/raw-loss = 0.28696638345718384, train/logprobs = tensor([[-0.7946, -4.6697],
        [-1.1340, -1.5849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0763847678899765
Epoch 0, Step 2159: train/loss = 0.4348827004432678, train/raw-loss = 0.3441486656665802, train/logprobs = tensor([[-0.8531, -3.5424],
        [-1.0578, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09073399752378464
Epoch 0, Step 2160: train/loss = 0.4632948040962219, train/raw-loss = 0.3646889328956604, train/logprobs = tensor([[-0.8563, -2.5534],
        [-1.9563, -1.1442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09860585629940033
Epoch 0, Step 2161: train/loss = 0.5249579548835754, train/raw-loss = 0.439283549785614, train/logprobs = tensor([[-0.7632, -2.4386],
        [-1.0583, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08567436039447784
Epoch 0, Step 2162: train/loss = 0.3521977961063385, train/raw-loss = 0.24831125140190125, train/logprobs = tensor([[-1.2024, -4.3176],
        [-2.2245, -1.5540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10388651490211487
Epoch 0, Step 2163: train/loss = 0.31571051478385925, train/raw-loss = 0.2089255154132843, train/logprobs = tensor([[-1.1941, -4.0127],
        [-2.5504, -1.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10678499191999435
Epoch 0, Step 2164: train/loss = 0.28593677282333374, train/raw-loss = 0.16703949868679047, train/logprobs = tensor([[-1.8136, -4.6019],
        [-3.2239, -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11889725923538208
Epoch 0, Step 2165: train/loss = 0.5359292030334473, train/raw-loss = 0.4536852240562439, train/logprobs = tensor([[-1.1140, -3.1274],
        [-1.8837, -2.2458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08224393427371979
Epoch 0, Step 2166: train/loss = 0.42962074279785156, train/raw-loss = 0.3452671766281128, train/logprobs = tensor([[-1.9764, -3.3877],
        [-2.5031, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08435358107089996
Epoch 0, Step 2167: train/loss = 0.41854292154312134, train/raw-loss = 0.34378600120544434, train/logprobs = tensor([[-1.3709, -3.7336],
        [-1.9424, -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07475694268941879
Epoch 0, Step 2168: train/loss = 0.4211019277572632, train/raw-loss = 0.32315537333488464, train/logprobs = tensor([[-1.0262, -5.0493],
        [-1.6849, -1.4607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09794653207063675
Epoch 0, Step 2169: train/loss = 0.6011126041412354, train/raw-loss = 0.5183886289596558, train/logprobs = tensor([[-0.5919, -1.5937],
        [-1.0018, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08272390812635422
Epoch 0, Step 2170: train/loss = 0.5265673398971558, train/raw-loss = 0.4547484815120697, train/logprobs = tensor([[-1.0637, -2.8389],
        [-1.2613, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07181881368160248
Epoch 0, Step 2171: train/loss = 0.5981974601745605, train/raw-loss = 0.5186303853988647, train/logprobs = tensor([[-0.9783, -1.1795],
        [-1.4623, -0.7265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07956703007221222
Epoch 0, Step 2172: train/loss = 0.3857077956199646, train/raw-loss = 0.3065963387489319, train/logprobs = tensor([[-1.3550, -4.2139],
        [-2.0242, -1.5669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07911144196987152
Epoch 0, Step 2173: train/loss = 0.354511022567749, train/raw-loss = 0.24691668152809143, train/logprobs = tensor([[-1.1043, -4.8672],
        [-2.1055, -2.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.107594333589077
Epoch 0, Step 2174: train/loss = 0.5266824960708618, train/raw-loss = 0.43660444021224976, train/logprobs = tensor([[-1.1383, -2.6975],
        [-1.5150, -1.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09007810056209564
Epoch 0, Step 2175: train/loss = 0.407198429107666, train/raw-loss = 0.31511732935905457, train/logprobs = tensor([[-1.0539, -3.8328],
        [-1.8199, -1.7090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09208109974861145
Epoch 0, Step 2176: train/loss = 0.4475339353084564, train/raw-loss = 0.36877304315567017, train/logprobs = tensor([[-1.1176, -3.6309],
        [-1.0427, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07876086980104446
Epoch 0, Step 2177: train/loss = 0.35801762342453003, train/raw-loss = 0.27555492520332336, train/logprobs = tensor([[-1.6279, -5.0281],
        [-2.1540, -1.4479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08246272057294846
Epoch 0, Step 2178: train/loss = 0.5096963047981262, train/raw-loss = 0.4337059259414673, train/logprobs = tensor([[-1.6152, -2.0467],
        [-2.1274, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07599042356014252
Epoch 0, Step 2179: train/loss = 0.43432754278182983, train/raw-loss = 0.33692967891693115, train/logprobs = tensor([[-0.6693, -2.8523],
        [-1.1838, -0.9456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09739790856838226
Epoch 0, Step 2180: train/loss = 0.5644646883010864, train/raw-loss = 0.46016159653663635, train/logprobs = tensor([[-1.0115, -1.4610],
        [-1.8813, -0.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10430312901735306
Epoch 0, Step 2181: train/loss = 0.5403699278831482, train/raw-loss = 0.4336356222629547, train/logprobs = tensor([[-1.6175, -2.7454],
        [-2.8442, -1.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673432052135468
Epoch 0, Step 2182: train/loss = 0.42382365465164185, train/raw-loss = 0.33193153142929077, train/logprobs = tensor([[-0.9203, -3.6506],
        [-1.8238, -1.4335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09189213067293167
Epoch 0, Step 2183: train/loss = 0.37922102212905884, train/raw-loss = 0.29017913341522217, train/logprobs = tensor([[-1.2715, -5.6168],
        [-2.1446, -1.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08904189616441727
Epoch 0, Step 2184: train/loss = 0.49837082624435425, train/raw-loss = 0.4090542197227478, train/logprobs = tensor([[-1.6252, -2.4798],
        [-2.7004, -1.7456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08931658416986465
Epoch 0, Step 2185: train/loss = 0.4288954734802246, train/raw-loss = 0.35334765911102295, train/logprobs = tensor([[-1.2178, -3.2723],
        [-1.7015, -1.4438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07554784417152405
Epoch 0, Step 2186: train/loss = 0.4696734547615051, train/raw-loss = 0.3721069097518921, train/logprobs = tensor([[-1.0510, -3.5114],
        [-1.7120, -1.4053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09756657481193542
Epoch 0, Step 2187: train/loss = 0.2560316324234009, train/raw-loss = 0.16420625150203705, train/logprobs = tensor([[-1.1652, -6.1107],
        [-2.1520, -2.0357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09182538837194443
Epoch 0, Step 2188: train/loss = 0.33377018570899963, train/raw-loss = 0.24531465768814087, train/logprobs = tensor([[-1.2235, -3.9576],
        [-2.3785, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08845554292201996
Epoch 0, Step 2189: train/loss = 0.5619207620620728, train/raw-loss = 0.47823745012283325, train/logprobs = tensor([[-0.8549, -2.3060],
        [-1.2886, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08368329703807831
Epoch 0, Step 2190: train/loss = 0.5107830762863159, train/raw-loss = 0.4192473292350769, train/logprobs = tensor([[-1.0769, -3.6536],
        [-1.8955, -1.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09153575450181961
Epoch 0, Step 2191: train/loss = 0.5457817316055298, train/raw-loss = 0.46590155363082886, train/logprobs = tensor([[-1.0696, -3.2501],
        [-1.3147, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07988014072179794
Epoch 0, Step 2192: train/loss = 0.2782813310623169, train/raw-loss = 0.17794090509414673, train/logprobs = tensor([[-1.1220, -5.2432],
        [-2.2589, -1.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10034043341875076
Epoch 0, Step 2193: train/loss = 0.4185389280319214, train/raw-loss = 0.3517623245716095, train/logprobs = tensor([[-0.7494, -3.6432],
        [-1.2451, -1.3572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0667765885591507
Epoch 0, Step 2194: train/loss = 0.32325923442840576, train/raw-loss = 0.238032728433609, train/logprobs = tensor([[-1.2627, -5.2182],
        [-1.9138, -1.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08522647619247437
Epoch 0, Step 2195: train/loss = 0.42619451880455017, train/raw-loss = 0.32313597202301025, train/logprobs = tensor([[-0.7105, -4.2331],
        [-1.5099, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10305856913328171
Epoch 0, Step 2196: train/loss = 0.5184418559074402, train/raw-loss = 0.4485901892185211, train/logprobs = tensor([[-1.0677, -2.8692],
        [-1.2784, -1.0185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06985169649124146
Epoch 0, Step 2197: train/loss = 0.4007894992828369, train/raw-loss = 0.32032519578933716, train/logprobs = tensor([[-0.9591, -4.2619],
        [-1.9504, -1.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08046430349349976
Epoch 0, Step 2198: train/loss = 0.41005799174308777, train/raw-loss = 0.31765180826187134, train/logprobs = tensor([[-1.1018, -2.9528],
        [-1.8293, -1.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09240617603063583
Epoch 0, Step 2199: train/loss = 0.454984188079834, train/raw-loss = 0.36052072048187256, train/logprobs = tensor([[-1.0286, -2.6976],
        [-1.8774, -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09446348249912262
Epoch 0, Step 2200: train/loss = 0.46761608123779297, train/raw-loss = 0.379608690738678, train/logprobs = tensor([[-0.9625, -3.1394],
        [-1.7292, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08800740540027618
Epoch 0, Step 2201: train/loss = 0.7078792452812195, train/raw-loss = 0.6292468309402466, train/logprobs = tensor([[-2.1079, -3.3198],
        [-1.8114, -1.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07863244414329529
Epoch 0, Step 2202: train/loss = 0.3384522795677185, train/raw-loss = 0.24653048813343048, train/logprobs = tensor([[-1.4838, -2.8889],
        [-2.9009, -1.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09192180633544922
Epoch 0, Step 2203: train/loss = 0.3811364769935608, train/raw-loss = 0.32133832573890686, train/logprobs = tensor([[-1.3497, -5.5038],
        [-1.8324, -2.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05979812517762184
Epoch 0, Step 2204: train/loss = 0.4410577714443207, train/raw-loss = 0.3368808627128601, train/logprobs = tensor([[-1.9615, -3.7699],
        [-2.9780, -1.6689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10417691618204117
Epoch 0, Step 2205: train/loss = 0.42640429735183716, train/raw-loss = 0.33906060457229614, train/logprobs = tensor([[-1.4109, -4.1977],
        [-1.9966, -1.7841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08734367042779922
Epoch 0, Step 2206: train/loss = 0.5050143003463745, train/raw-loss = 0.40193137526512146, train/logprobs = tensor([[-2.0125, -3.7712],
        [-3.3596, -1.8339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10308288782835007
Epoch 0, Step 2207: train/loss = 0.39827632904052734, train/raw-loss = 0.31540414690971375, train/logprobs = tensor([[-1.6927, -3.5255],
        [-2.2730, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.082872174680233
Epoch 0, Step 2208: train/loss = 0.6189731359481812, train/raw-loss = 0.5227946639060974, train/logprobs = tensor([[-1.3723, -2.4763],
        [-1.6875, -1.4584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09617847949266434
Epoch 0, Step 2209: train/loss = 0.4672490954399109, train/raw-loss = 0.4146476089954376, train/logprobs = tensor([[-0.9100, -3.3366],
        [-1.1322, -1.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05260148644447327
Epoch 0, Step 2210: train/loss = 0.4432574212551117, train/raw-loss = 0.36644792556762695, train/logprobs = tensor([[-0.8318, -3.9480],
        [-1.1233, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07680953294038773
Epoch 0, Step 2211: train/loss = 0.3578522503376007, train/raw-loss = 0.25935858488082886, train/logprobs = tensor([[-1.5521, -3.3181],
        [-2.8697, -1.8248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09849365800619125
Epoch 0, Step 2212: train/loss = 0.42162024974823, train/raw-loss = 0.32277658581733704, train/logprobs = tensor([[-0.7292, -2.8202],
        [-1.4250, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09884363412857056
Epoch 0, Step 2213: train/loss = 0.4217671751976013, train/raw-loss = 0.34723997116088867, train/logprobs = tensor([[-0.6230, -5.3226],
        [-0.9076, -1.5457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07452719658613205
Epoch 0, Step 2214: train/loss = 0.6312381029129028, train/raw-loss = 0.536124050617218, train/logprobs = tensor([[-1.2217, -1.7511],
        [-1.8026, -1.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09511400014162064
Epoch 0, Step 2215: train/loss = 0.5468310117721558, train/raw-loss = 0.46010875701904297, train/logprobs = tensor([[-1.0232, -2.2594],
        [-1.7175, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08672226965427399
Epoch 0, Step 2216: train/loss = 0.5677877068519592, train/raw-loss = 0.5024707317352295, train/logprobs = tensor([[-1.1676, -2.0555],
        [-1.3919, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06531701982021332
Epoch 0, Step 2217: train/loss = 0.6769850254058838, train/raw-loss = 0.6008744239807129, train/logprobs = tensor([[-0.9789, -1.4447],
        [-1.4333, -1.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0761105865240097
Epoch 0, Step 2218: train/loss = 0.47458863258361816, train/raw-loss = 0.3951970338821411, train/logprobs = tensor([[-1.3411, -3.7711],
        [-1.4822, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07939163595438004
Epoch 0, Step 2219: train/loss = 0.45394909381866455, train/raw-loss = 0.37409839034080505, train/logprobs = tensor([[-0.9718, -3.4766],
        [-1.5559, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07985067367553711
Epoch 0, Step 2220: train/loss = 0.5652896761894226, train/raw-loss = 0.48748719692230225, train/logprobs = tensor([[-0.7597, -2.2784],
        [-1.0267, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07780248671770096
Epoch 0, Step 2221: train/loss = 0.31185200810432434, train/raw-loss = 0.217330664396286, train/logprobs = tensor([[-1.4725, -4.3449],
        [-2.6505, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09452134370803833
Epoch 0, Step 2222: train/loss = 0.310552179813385, train/raw-loss = 0.2186097502708435, train/logprobs = tensor([[-1.0986, -5.5196],
        [-1.9216, -1.7584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0919424444437027
Epoch 0, Step 2223: train/loss = 0.41444021463394165, train/raw-loss = 0.32403236627578735, train/logprobs = tensor([[-1.4502, -3.2408],
        [-2.8357, -1.6209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0904078334569931
Epoch 0, Step 2224: train/loss = 0.38139963150024414, train/raw-loss = 0.2718808948993683, train/logprobs = tensor([[-0.8017, -4.3814],
        [-1.8786, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10951873660087585
Epoch 0, Step 2225: train/loss = 0.37114304304122925, train/raw-loss = 0.28440797328948975, train/logprobs = tensor([[-1.1603, -3.4762],
        [-2.1931, -1.6288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08673505485057831
Epoch 0, Step 2226: train/loss = 0.6244728565216064, train/raw-loss = 0.5541283488273621, train/logprobs = tensor([[-0.8609, -1.3165],
        [-1.3636, -1.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07034450769424438
Epoch 0, Step 2227: train/loss = 0.3998188376426697, train/raw-loss = 0.30351021885871887, train/logprobs = tensor([[-0.9610, -3.6706],
        [-1.8416, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.096308633685112
Epoch 0, Step 2228: train/loss = 0.5782482624053955, train/raw-loss = 0.4943982660770416, train/logprobs = tensor([[-1.2432, -3.2011],
        [-1.5906, -1.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08385001868009567
Epoch 0, Step 2229: train/loss = 0.41897130012512207, train/raw-loss = 0.3115552067756653, train/logprobs = tensor([[-1.1692, -3.0311],
        [-2.3411, -1.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1074160635471344
Epoch 0, Step 2230: train/loss = 0.43474385142326355, train/raw-loss = 0.35644641518592834, train/logprobs = tensor([[-0.9462, -2.4513],
        [-2.0024, -1.0930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07829741388559341
Epoch 0, Step 2231: train/loss = 0.3196988105773926, train/raw-loss = 0.2215864062309265, train/logprobs = tensor([[-0.7752, -4.4078],
        [-1.6546, -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09811238944530487
Epoch 0, Step 2232: train/loss = 0.5914589166641235, train/raw-loss = 0.48642659187316895, train/logprobs = tensor([[-1.2480, -4.0609],
        [-2.3402, -2.1755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10503235459327698
Epoch 0, Step 2233: train/loss = 0.536119818687439, train/raw-loss = 0.4367084205150604, train/logprobs = tensor([[-1.3603, -3.4496],
        [-2.1775, -1.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09941141307353973
Epoch 0, Step 2234: train/loss = 0.3822200894355774, train/raw-loss = 0.28944042325019836, train/logprobs = tensor([[-1.7162, -2.7903],
        [-3.3732, -1.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09277966618537903
Epoch 0, Step 2235: train/loss = 0.3265392482280731, train/raw-loss = 0.21517696976661682, train/logprobs = tensor([[-1.1022, -5.0764],
        [-2.4685, -2.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1113622784614563
Epoch 0, Step 2236: train/loss = 0.31603044271469116, train/raw-loss = 0.20074905455112457, train/logprobs = tensor([[-1.1236, -4.2102],
        [-2.0067, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11528140306472778
Epoch 0, Step 2237: train/loss = 0.5091761946678162, train/raw-loss = 0.44677987694740295, train/logprobs = tensor([[-0.7403, -3.3720],
        [-1.4057, -1.7050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062396302819252014
Epoch 0, Step 2238: train/loss = 0.4127187132835388, train/raw-loss = 0.31688860058784485, train/logprobs = tensor([[-1.4839, -3.3730],
        [-2.5955, -1.6708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09583009779453278
Epoch 0, Step 2239: train/loss = 0.3910807967185974, train/raw-loss = 0.3073745369911194, train/logprobs = tensor([[-0.9109, -4.9502],
        [-1.6779, -1.5436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08370627462863922
Epoch 0, Step 2240: train/loss = 0.5199246406555176, train/raw-loss = 0.4142392575740814, train/logprobs = tensor([[-0.8898, -3.2413],
        [-1.7803, -1.4437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10568539053201675
Epoch 0, Step 2241: train/loss = 0.4269533157348633, train/raw-loss = 0.3394082486629486, train/logprobs = tensor([[-1.3507, -3.8951],
        [-2.1030, -1.7598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08754504472017288
Epoch 0, Step 2242: train/loss = 0.5301933288574219, train/raw-loss = 0.4477081894874573, train/logprobs = tensor([[-0.8985, -3.0261],
        [-1.3347, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08248511701822281
Epoch 0, Step 2243: train/loss = 0.4328988492488861, train/raw-loss = 0.35073986649513245, train/logprobs = tensor([[-1.2957, -3.6053],
        [-1.6383, -1.5544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08215894550085068
Epoch 0, Step 2244: train/loss = 0.4780762791633606, train/raw-loss = 0.3944188952445984, train/logprobs = tensor([[-0.9009, -2.6989],
        [-1.4528, -1.5872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08365736901760101
Epoch 0, Step 2245: train/loss = 0.3755776286125183, train/raw-loss = 0.28600963950157166, train/logprobs = tensor([[-1.4443, -4.1283],
        [-1.8983, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08956798911094666
Epoch 0, Step 2246: train/loss = 0.41191962361335754, train/raw-loss = 0.31414785981178284, train/logprobs = tensor([[-0.7798, -3.9712],
        [-1.5863, -1.4107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0977717787027359
Epoch 0, Step 2247: train/loss = 0.3554041385650635, train/raw-loss = 0.28132951259613037, train/logprobs = tensor([[-0.7285, -4.9779],
        [-0.9233, -1.4992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740746483206749
Epoch 0, Step 2248: train/loss = 0.43809157609939575, train/raw-loss = 0.34487542510032654, train/logprobs = tensor([[-1.8364, -4.0989],
        [-2.1897, -1.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09321613609790802
Epoch 0, Step 2249: train/loss = 0.27535104751586914, train/raw-loss = 0.1760246455669403, train/logprobs = tensor([[-1.1183, -3.9605],
        [-2.8231, -1.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09932638704776764
Epoch 0, Step 2250: train/loss = 0.3673155903816223, train/raw-loss = 0.2714105546474457, train/logprobs = tensor([[-1.1038, -3.9160],
        [-2.1944, -1.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09590500593185425
Epoch 0, Step 2251: train/loss = 0.3608648180961609, train/raw-loss = 0.2871758043766022, train/logprobs = tensor([[-1.3177, -4.5905],
        [-2.2610, -1.5689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07368896156549454
Epoch 0, Step 2252: train/loss = 0.45029205083847046, train/raw-loss = 0.3632955253124237, train/logprobs = tensor([[-1.2948, -3.0030],
        [-1.8745, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08699652552604675
Epoch 0, Step 2253: train/loss = 0.4444674253463745, train/raw-loss = 0.3651079833507538, train/logprobs = tensor([[-1.4170, -3.3629],
        [-2.1759, -1.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07935941964387894
Epoch 0, Step 2254: train/loss = 0.40632176399230957, train/raw-loss = 0.2928556501865387, train/logprobs = tensor([[-1.2948, -3.4724],
        [-3.1811, -2.1698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11346611380577087
Epoch 0, Step 2255: train/loss = 0.502777099609375, train/raw-loss = 0.3976454734802246, train/logprobs = tensor([[-1.3806, -2.5384],
        [-2.6024, -1.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10513168573379517
Epoch 0, Step 2256: train/loss = 0.4568653702735901, train/raw-loss = 0.36566704511642456, train/logprobs = tensor([[-1.5765, -3.0010],
        [-2.4689, -2.0983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09119834005832672
Epoch 0, Step 2257: train/loss = 0.5558263659477234, train/raw-loss = 0.48821017146110535, train/logprobs = tensor([[-1.1940, -1.6975],
        [-1.5404, -0.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06761615723371506
Epoch 0, Step 2258: train/loss = 0.3894726037979126, train/raw-loss = 0.2834447920322418, train/logprobs = tensor([[-1.2403, -4.2499],
        [-2.6137, -1.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10602784156799316
Epoch 0, Step 2259: train/loss = 0.4064681828022003, train/raw-loss = 0.3066098093986511, train/logprobs = tensor([[-1.4052, -4.1346],
        [-2.4349, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09985838085412979
Epoch 0, Step 2260: train/loss = 0.5317882299423218, train/raw-loss = 0.4576706886291504, train/logprobs = tensor([[-0.9886, -1.6878],
        [-1.5041, -0.7675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.074117511510849
Epoch 0, Step 2261: train/loss = 0.41398829221725464, train/raw-loss = 0.3268241584300995, train/logprobs = tensor([[-1.0744, -4.0488],
        [-1.6771, -1.7416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08716412633657455
Epoch 0, Step 2262: train/loss = 0.31796807050704956, train/raw-loss = 0.23217257857322693, train/logprobs = tensor([[-1.3669, -5.7677],
        [-2.0785, -1.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08579546213150024
Epoch 0, Step 2263: train/loss = 0.5039814710617065, train/raw-loss = 0.3864784240722656, train/logprobs = tensor([[-1.3630, -2.6130],
        [-2.6166, -1.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11750301718711853
Epoch 0, Step 2264: train/loss = 0.3312598764896393, train/raw-loss = 0.2361001819372177, train/logprobs = tensor([[-0.7845, -4.8861],
        [-1.5693, -1.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09515971690416336
Epoch 0, Step 2265: train/loss = 0.47444766759872437, train/raw-loss = 0.3991968631744385, train/logprobs = tensor([[-0.8521, -3.2972],
        [-1.3980, -1.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07525083422660828
Epoch 0, Step 2266: train/loss = 0.5575588941574097, train/raw-loss = 0.47054237127304077, train/logprobs = tensor([[-1.6791, -3.3346],
        [-1.9474, -1.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0870165228843689
Epoch 0, Step 2267: train/loss = 0.6101717948913574, train/raw-loss = 0.5227592587471008, train/logprobs = tensor([[-0.6635, -2.3580],
        [-1.0548, -1.4579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0874125137925148
Epoch 0, Step 2268: train/loss = 0.5006400346755981, train/raw-loss = 0.4162323474884033, train/logprobs = tensor([[-1.5212, -3.5927],
        [-1.7671, -1.1472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08440762758255005
Epoch 0, Step 2269: train/loss = 0.4195949137210846, train/raw-loss = 0.3498603105545044, train/logprobs = tensor([[-0.7577, -2.8232],
        [-1.1686, -0.8948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0697346180677414
Epoch 0, Step 2270: train/loss = 0.32523614168167114, train/raw-loss = 0.23004746437072754, train/logprobs = tensor([[-0.9988, -5.3462],
        [-1.6801, -2.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09518870711326599
Epoch 0, Step 2271: train/loss = 0.3782103359699249, train/raw-loss = 0.2785496115684509, train/logprobs = tensor([[-1.3863, -4.3604],
        [-2.1673, -1.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0996607169508934
Epoch 0, Step 2272: train/loss = 0.48536765575408936, train/raw-loss = 0.4032383859157562, train/logprobs = tensor([[-1.1960, -3.8419],
        [-1.4867, -1.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08212924748659134
Epoch 0, Step 2273: train/loss = 0.43987828493118286, train/raw-loss = 0.36372071504592896, train/logprobs = tensor([[-1.5023, -2.3304],
        [-2.7423, -1.5256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07615756243467331
Epoch 0, Step 2274: train/loss = 0.480656236410141, train/raw-loss = 0.38722580671310425, train/logprobs = tensor([[-0.5989, -2.4943],
        [-1.1072, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09343042969703674
Epoch 0, Step 2275: train/loss = 0.4482349157333374, train/raw-loss = 0.3704076409339905, train/logprobs = tensor([[-0.9123, -3.9453],
        [-1.5057, -2.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07782725989818573
Epoch 0, Step 2276: train/loss = 0.318591445684433, train/raw-loss = 0.22175228595733643, train/logprobs = tensor([[-1.2544, -4.9078],
        [-2.6725, -1.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09683915227651596
Epoch 0, Step 2277: train/loss = 0.33022645115852356, train/raw-loss = 0.22281783819198608, train/logprobs = tensor([[-1.0251, -4.5478],
        [-2.5940, -1.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10740861296653748
Epoch 0, Step 2278: train/loss = 0.676580548286438, train/raw-loss = 0.6250996589660645, train/logprobs = tensor([[-0.9734, -0.8649],
        [-1.0808, -0.6751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05148095637559891
Epoch 0, Step 2279: train/loss = 0.49994802474975586, train/raw-loss = 0.39189714193344116, train/logprobs = tensor([[-1.4980, -3.4471],
        [-2.5142, -1.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1080508604645729
Epoch 0, Step 2280: train/loss = 0.45396554470062256, train/raw-loss = 0.35761547088623047, train/logprobs = tensor([[-0.9752, -4.7986],
        [-1.4593, -1.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09635009616613388
Epoch 0, Step 2281: train/loss = 0.3940087556838989, train/raw-loss = 0.3199560046195984, train/logprobs = tensor([[-0.9659, -3.6936],
        [-1.9535, -2.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07405273616313934
Epoch 0, Step 2282: train/loss = 0.4304121732711792, train/raw-loss = 0.3509189486503601, train/logprobs = tensor([[-1.0421, -3.1925],
        [-1.5913, -1.3412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07949323207139969
Epoch 0, Step 2283: train/loss = 0.32816845178604126, train/raw-loss = 0.22952574491500854, train/logprobs = tensor([[-0.8629, -4.5582],
        [-1.7876, -1.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09864269942045212
Epoch 0, Step 2284: train/loss = 0.5347616076469421, train/raw-loss = 0.45193007588386536, train/logprobs = tensor([[-1.1931, -2.4186],
        [-2.0710, -1.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08283151686191559
Epoch 0, Step 2285: train/loss = 0.5681499242782593, train/raw-loss = 0.49989932775497437, train/logprobs = tensor([[-0.5344, -2.3926],
        [-0.7456, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06825065612792969
Epoch 0, Step 2286: train/loss = 0.35983985662460327, train/raw-loss = 0.2556307911872864, train/logprobs = tensor([[-0.9541, -4.8964],
        [-2.1225, -1.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10420907288789749
Epoch 0, Step 2287: train/loss = 0.6828343868255615, train/raw-loss = 0.6174275875091553, train/logprobs = tensor([[-1.2885, -1.3867],
        [-1.2737, -1.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06540673971176147
Epoch 0, Step 2288: train/loss = 0.3632011413574219, train/raw-loss = 0.25865402817726135, train/logprobs = tensor([[-1.3739, -3.3687],
        [-3.0689, -1.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10454711318016052
Epoch 0, Step 2289: train/loss = 0.3362148404121399, train/raw-loss = 0.24691234529018402, train/logprobs = tensor([[-0.8467, -5.3503],
        [-1.3826, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08930251002311707
Epoch 0, Step 2290: train/loss = 0.3449024260044098, train/raw-loss = 0.24472838640213013, train/logprobs = tensor([[-1.4187, -6.3283],
        [-1.8021, -1.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10017402470111847
Epoch 0, Step 2291: train/loss = 0.39099687337875366, train/raw-loss = 0.29743480682373047, train/logprobs = tensor([[-1.2293, -4.4421],
        [-2.4272, -1.4288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0935620591044426
Epoch 0, Step 2292: train/loss = 0.4210101366043091, train/raw-loss = 0.35033538937568665, train/logprobs = tensor([[-0.7864, -4.7275],
        [-1.1201, -1.5442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07067472487688065
Epoch 0, Step 2293: train/loss = 0.3903433084487915, train/raw-loss = 0.27482250332832336, train/logprobs = tensor([[-1.7642, -2.8426],
        [-3.4111, -1.7725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11552080512046814
Epoch 0, Step 2294: train/loss = 0.3675168752670288, train/raw-loss = 0.2921733856201172, train/logprobs = tensor([[-0.7610, -3.9126],
        [-0.9777, -0.9308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07534350454807281
Epoch 0, Step 2295: train/loss = 0.41429683566093445, train/raw-loss = 0.34104833006858826, train/logprobs = tensor([[-1.0366, -5.1428],
        [-0.9728, -1.2730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07324850559234619
Epoch 0, Step 2296: train/loss = 0.4286409020423889, train/raw-loss = 0.3372899293899536, train/logprobs = tensor([[-0.9933, -2.7314],
        [-2.0368, -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0913509652018547
Epoch 0, Step 2297: train/loss = 0.7443153858184814, train/raw-loss = 0.6699328422546387, train/logprobs = tensor([[-0.8010, -1.0572],
        [-1.0645, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07438258826732635
Epoch 0, Step 2298: train/loss = 0.6262999176979065, train/raw-loss = 0.555266261100769, train/logprobs = tensor([[-0.7362, -2.2507],
        [-0.9604, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07103362679481506
Epoch 0, Step 2299: train/loss = 0.5489687919616699, train/raw-loss = 0.47759535908699036, train/logprobs = tensor([[-1.8375, -2.0252],
        [-2.6328, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07137337327003479
Epoch 0, Step 2300: train/loss = 0.28078144788742065, train/raw-loss = 0.19530579447746277, train/logprobs = tensor([[-1.0961, -4.4968],
        [-2.1930, -1.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08547563850879669
Epoch 0, Step 2301: train/loss = 0.4429820775985718, train/raw-loss = 0.31591349840164185, train/logprobs = tensor([[-1.1255, -3.8339],
        [-2.7479, -1.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12706856429576874
Epoch 0, Step 2302: train/loss = 0.5088807940483093, train/raw-loss = 0.4204937815666199, train/logprobs = tensor([[-1.3724, -2.8117],
        [-1.8680, -1.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08838699012994766
Epoch 0, Step 2303: train/loss = 0.6646889448165894, train/raw-loss = 0.5768182873725891, train/logprobs = tensor([[-1.1989, -2.1910],
        [-0.9516, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08787062019109726
Epoch 0, Step 2304: train/loss = 0.5559681057929993, train/raw-loss = 0.46754491329193115, train/logprobs = tensor([[-1.6478, -2.9493],
        [-2.3596, -1.9734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08842318505048752
Epoch 0, Step 2305: train/loss = 0.40850162506103516, train/raw-loss = 0.3186570405960083, train/logprobs = tensor([[-1.6914, -4.5426],
        [-2.3774, -1.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08984461426734924
Epoch 0, Step 2306: train/loss = 0.3567766547203064, train/raw-loss = 0.27202484011650085, train/logprobs = tensor([[-0.9261, -2.7154],
        [-2.0691, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08475182950496674
Epoch 0, Step 2307: train/loss = 0.3260737359523773, train/raw-loss = 0.24237379431724548, train/logprobs = tensor([[-0.7877, -5.3216],
        [-1.3909, -2.4605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08369994163513184
Epoch 0, Step 2308: train/loss = 0.538879930973053, train/raw-loss = 0.4618992209434509, train/logprobs = tensor([[-1.0083, -2.0707],
        [-1.4387, -1.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07698071748018265
Epoch 0, Step 2309: train/loss = 0.38896235823631287, train/raw-loss = 0.28446483612060547, train/logprobs = tensor([[-1.3586, -3.6533],
        [-2.4284, -1.7015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10449754446744919
Epoch 0, Step 2310: train/loss = 0.4503166675567627, train/raw-loss = 0.3598584830760956, train/logprobs = tensor([[-0.8541, -3.0791],
        [-1.3407, -0.9407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09045816957950592
Epoch 0, Step 2311: train/loss = 0.35759979486465454, train/raw-loss = 0.27229470014572144, train/logprobs = tensor([[-0.5371, -4.1437],
        [-0.8936, -1.4904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0853051245212555
Epoch 0, Step 2312: train/loss = 0.26673153042793274, train/raw-loss = 0.1632418930530548, train/logprobs = tensor([[-1.0484, -4.3634],
        [-2.6849, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10348963737487793
Epoch 0, Step 2313: train/loss = 0.5044143199920654, train/raw-loss = 0.40164661407470703, train/logprobs = tensor([[-0.9820, -2.6098],
        [-1.7527, -1.8107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10276775062084198
Epoch 0, Step 2314: train/loss = 0.52040034532547, train/raw-loss = 0.4220438301563263, train/logprobs = tensor([[-0.6788, -3.1463],
        [-1.4906, -2.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09835653007030487
Epoch 0, Step 2315: train/loss = 0.4705318808555603, train/raw-loss = 0.3840147852897644, train/logprobs = tensor([[-0.9590, -3.2067],
        [-1.5822, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0865170955657959
Epoch 0, Step 2316: train/loss = 0.41860002279281616, train/raw-loss = 0.3258974850177765, train/logprobs = tensor([[-1.2689, -4.6321],
        [-2.6569, -2.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09270251542329788
Epoch 0, Step 2317: train/loss = 0.391641229391098, train/raw-loss = 0.2733791172504425, train/logprobs = tensor([[-1.4989, -3.4172],
        [-2.5208, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11826211214065552
Epoch 0, Step 2318: train/loss = 0.49646854400634766, train/raw-loss = 0.4045558273792267, train/logprobs = tensor([[-1.3356, -2.7132],
        [-1.9173, -1.3487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09191269427537918
Epoch 0, Step 2319: train/loss = 0.3454451560974121, train/raw-loss = 0.25724703073501587, train/logprobs = tensor([[-1.0906, -4.1309],
        [-2.0063, -1.3562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08819813281297684
Epoch 0, Step 2320: train/loss = 0.48310917615890503, train/raw-loss = 0.3847103416919708, train/logprobs = tensor([[-1.0379, -3.7218],
        [-1.9578, -1.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09839881956577301
Epoch 0, Step 2321: train/loss = 0.452953577041626, train/raw-loss = 0.3659125864505768, train/logprobs = tensor([[-0.9859, -3.1421],
        [-1.8450, -1.0056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0870409905910492
Epoch 0, Step 2322: train/loss = 0.36587652564048767, train/raw-loss = 0.27548348903656006, train/logprobs = tensor([[-1.0285, -3.9145],
        [-1.6987, -1.6472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09039302915334702
Epoch 0, Step 2323: train/loss = 0.3997107148170471, train/raw-loss = 0.3066696524620056, train/logprobs = tensor([[-1.1851, -3.8216],
        [-2.2158, -1.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09304104745388031
Epoch 0, Step 2324: train/loss = 0.3760213851928711, train/raw-loss = 0.27718472480773926, train/logprobs = tensor([[-1.0362, -3.8276],
        [-1.5745, -1.2583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09883666038513184
Epoch 0, Step 2325: train/loss = 0.5506694316864014, train/raw-loss = 0.4641733765602112, train/logprobs = tensor([[-1.1389, -2.2973],
        [-1.9773, -1.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08649604022502899
Epoch 0, Step 2326: train/loss = 0.4100550711154938, train/raw-loss = 0.33528921008110046, train/logprobs = tensor([[-1.2024, -3.1738],
        [-2.1394, -1.4820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07476584613323212
Epoch 0, Step 2327: train/loss = 0.4740101397037506, train/raw-loss = 0.385855495929718, train/logprobs = tensor([[-0.6398, -3.1118],
        [-1.0824, -1.2930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08815464377403259
Epoch 0, Step 2328: train/loss = 0.37332046031951904, train/raw-loss = 0.2801845073699951, train/logprobs = tensor([[-1.2154, -4.2064],
        [-2.2204, -1.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09313598275184631
Epoch 0, Step 2329: train/loss = 0.42529550194740295, train/raw-loss = 0.3506937026977539, train/logprobs = tensor([[-0.8161, -3.5576],
        [-1.1773, -1.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07460180670022964
Epoch 0, Step 2330: train/loss = 0.33665311336517334, train/raw-loss = 0.24839073419570923, train/logprobs = tensor([[-0.8675, -4.9657],
        [-1.4231, -1.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08826242387294769
Epoch 0, Step 2331: train/loss = 0.4495406746864319, train/raw-loss = 0.371415376663208, train/logprobs = tensor([[-0.7645, -3.9517],
        [-1.2581, -1.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07812528312206268
Epoch 0, Step 2332: train/loss = 0.4265747666358948, train/raw-loss = 0.34653058648109436, train/logprobs = tensor([[-0.5628, -5.0497],
        [-0.8174, -1.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08004419505596161
Epoch 0, Step 2333: train/loss = 0.4564381241798401, train/raw-loss = 0.36504220962524414, train/logprobs = tensor([[-0.8794, -4.9462],
        [-1.2547, -1.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09139589965343475
Epoch 0, Step 2334: train/loss = 0.6728048324584961, train/raw-loss = 0.6105681657791138, train/logprobs = tensor([[-0.9998, -1.2419],
        [-0.9233, -0.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06223665177822113
Epoch 0, Step 2335: train/loss = 0.3621448278427124, train/raw-loss = 0.2789003252983093, train/logprobs = tensor([[-1.3142, -4.4549],
        [-1.9975, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08324446529150009
Epoch 0, Step 2336: train/loss = 0.36735811829566956, train/raw-loss = 0.2641996145248413, train/logprobs = tensor([[-1.4466, -3.6208],
        [-2.9028, -1.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10315852612257004
Epoch 0, Step 2337: train/loss = 0.26688534021377563, train/raw-loss = 0.1556444764137268, train/logprobs = tensor([[-1.6099, -4.6394],
        [-3.5633, -2.3694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11124086380004883
Epoch 0, Step 2338: train/loss = 0.35554239153862, train/raw-loss = 0.2565174698829651, train/logprobs = tensor([[-0.9814, -3.7816],
        [-1.8824, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09902489185333252
Epoch 0, Step 2339: train/loss = 0.32462435960769653, train/raw-loss = 0.21855418384075165, train/logprobs = tensor([[-1.3493, -4.2904],
        [-3.0871, -1.6443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607019811868668
Epoch 0, Step 2340: train/loss = 0.4065653383731842, train/raw-loss = 0.3044232726097107, train/logprobs = tensor([[-1.3370, -5.2066],
        [-2.6077, -2.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10214206576347351
Epoch 0, Step 2341: train/loss = 0.4512655436992645, train/raw-loss = 0.3622359335422516, train/logprobs = tensor([[-0.8348, -3.7594],
        [-1.7647, -1.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08902963995933533
Epoch 0, Step 2342: train/loss = 0.38463085889816284, train/raw-loss = 0.298797607421875, train/logprobs = tensor([[-1.2238, -2.7880],
        [-2.3758, -1.4686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08583325147628784
Epoch 0, Step 2343: train/loss = 0.3348504900932312, train/raw-loss = 0.23751576244831085, train/logprobs = tensor([[-1.0103, -5.4683],
        [-1.9276, -1.7116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09733472019433975
Epoch 0, Step 2344: train/loss = 0.2870469391345978, train/raw-loss = 0.15541937947273254, train/logprobs = tensor([[-1.5962, -3.7201],
        [-3.5712, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13162755966186523
Epoch 0, Step 2345: train/loss = 0.5083989500999451, train/raw-loss = 0.4164923131465912, train/logprobs = tensor([[-1.0731, -4.7776],
        [-1.4731, -1.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09190662205219269
Epoch 0, Step 2346: train/loss = 0.2839079797267914, train/raw-loss = 0.1902865469455719, train/logprobs = tensor([[-1.1289, -3.9341],
        [-2.3856, -1.1184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09362142533063889
Epoch 0, Step 2347: train/loss = 0.3301973342895508, train/raw-loss = 0.24263133108615875, train/logprobs = tensor([[-1.0353, -4.0877],
        [-2.2430, -1.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08756600320339203
Epoch 0, Step 2348: train/loss = 0.404119074344635, train/raw-loss = 0.306581050157547, train/logprobs = tensor([[-1.3231, -3.9485],
        [-2.1578, -1.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09753801673650742
Epoch 0, Step 2349: train/loss = 0.45160484313964844, train/raw-loss = 0.3437260389328003, train/logprobs = tensor([[-1.0382, -3.7405],
        [-2.2363, -1.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10787882655858994
Epoch 0, Step 2350: train/loss = 0.4940650463104248, train/raw-loss = 0.40397408604621887, train/logprobs = tensor([[-1.4046, -2.2674],
        [-2.4639, -1.6122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09009096771478653
Epoch 0, Step 2351: train/loss = 0.3547776937484741, train/raw-loss = 0.2755664587020874, train/logprobs = tensor([[-0.8096, -4.3845],
        [-1.2632, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07921123504638672
Epoch 0, Step 2352: train/loss = 0.39527755975723267, train/raw-loss = 0.3079705536365509, train/logprobs = tensor([[-1.4071, -3.2297],
        [-2.1750, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08730698376893997
Epoch 0, Step 2353: train/loss = 0.47367164492607117, train/raw-loss = 0.3851274251937866, train/logprobs = tensor([[-0.7161, -2.7887],
        [-1.3401, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08854423463344574
Epoch 0, Step 2354: train/loss = 0.3178864121437073, train/raw-loss = 0.2179531306028366, train/logprobs = tensor([[-1.1360, -3.4029],
        [-2.3822, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09993328154087067
Epoch 0, Step 2355: train/loss = 0.2847813367843628, train/raw-loss = 0.16518636047840118, train/logprobs = tensor([[-1.1949, -4.7509],
        [-2.7266, -1.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11959496885538101
Epoch 0, Step 2356: train/loss = 0.38400232791900635, train/raw-loss = 0.29613691568374634, train/logprobs = tensor([[-0.9596, -4.1379],
        [-1.8542, -1.6794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0878654271364212
Epoch 0, Step 2357: train/loss = 0.6187050342559814, train/raw-loss = 0.5356236696243286, train/logprobs = tensor([[-1.2336, -2.4952],
        [-1.5606, -1.3217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08308140933513641
Epoch 0, Step 2358: train/loss = 0.3738739490509033, train/raw-loss = 0.2938750982284546, train/logprobs = tensor([[-0.7896, -4.1591],
        [-0.8814, -0.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07999885827302933
Epoch 0, Step 2359: train/loss = 0.3672637641429901, train/raw-loss = 0.27424702048301697, train/logprobs = tensor([[-1.1746, -3.1393],
        [-2.1275, -1.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09301677346229553
Epoch 0, Step 2360: train/loss = 0.5346826314926147, train/raw-loss = 0.42238348722457886, train/logprobs = tensor([[-1.0762, -2.0455],
        [-2.3717, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11229915171861649
Epoch 0, Step 2361: train/loss = 0.41379618644714355, train/raw-loss = 0.3239250183105469, train/logprobs = tensor([[-0.9872, -3.9866],
        [-1.5300, -1.4428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08987115323543549
Epoch 0, Step 2362: train/loss = 0.4763772487640381, train/raw-loss = 0.3768858313560486, train/logprobs = tensor([[-1.6280, -3.3260],
        [-2.9584, -1.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09949140250682831
Epoch 0, Step 2363: train/loss = 0.41688480973243713, train/raw-loss = 0.32421875, train/logprobs = tensor([[-1.0927, -4.0625],
        [-1.4993, -1.8959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09266602993011475
Epoch 0, Step 2364: train/loss = 0.5177188515663147, train/raw-loss = 0.4201078712940216, train/logprobs = tensor([[-1.2867, -1.9164],
        [-2.1946, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0976109728217125
Epoch 0, Step 2365: train/loss = 0.3429759442806244, train/raw-loss = 0.24406950175762177, train/logprobs = tensor([[-1.1054, -3.5689],
        [-2.2439, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09890644252300262
Epoch 0, Step 2366: train/loss = 0.45610877871513367, train/raw-loss = 0.37413957715034485, train/logprobs = tensor([[-1.6573, -5.1833],
        [-1.9962, -1.7563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08196920901536942
Epoch 0, Step 2367: train/loss = 0.46967196464538574, train/raw-loss = 0.37445002794265747, train/logprobs = tensor([[-1.3071, -3.5844],
        [-2.6363, -2.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09522193670272827
Epoch 0, Step 2368: train/loss = 0.2549007534980774, train/raw-loss = 0.16014327108860016, train/logprobs = tensor([[-1.1475, -6.0850],
        [-2.3620, -2.2428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09475748986005783
Epoch 0, Step 2369: train/loss = 0.4802197515964508, train/raw-loss = 0.380143940448761, train/logprobs = tensor([[-1.7828, -2.9328],
        [-3.3268, -2.1512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10007581859827042
Epoch 0, Step 2370: train/loss = 0.6068068742752075, train/raw-loss = 0.5265429615974426, train/logprobs = tensor([[-0.7892, -1.6914],
        [-1.0747, -1.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08026391267776489
Epoch 0, Step 2371: train/loss = 0.5418742895126343, train/raw-loss = 0.4706856310367584, train/logprobs = tensor([[-1.4027, -2.9622],
        [-1.8031, -1.6429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07118863612413406
Epoch 0, Step 2372: train/loss = 0.3427383601665497, train/raw-loss = 0.2621404826641083, train/logprobs = tensor([[-0.8707, -4.3951],
        [-1.5365, -1.7835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0805978775024414
Epoch 0, Step 2373: train/loss = 0.3143923282623291, train/raw-loss = 0.22327305376529694, train/logprobs = tensor([[-1.0386, -5.3967],
        [-1.7958, -1.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09111925959587097
Epoch 0, Step 2374: train/loss = 0.4815213680267334, train/raw-loss = 0.4207439720630646, train/logprobs = tensor([[-1.3184, -2.6837],
        [-1.6549, -1.0988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06077737361192703
eval/loss: 0.43968597054481506
