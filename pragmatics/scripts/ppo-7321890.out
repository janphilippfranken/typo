[2024-03-02 16:10:17,627][root][INFO] - beta: 0.1
[2024-03-02 16:10:17,628][root][INFO] - loss no_reference
[2024-03-02 16:10:17,628][root][INFO] - max_iter: 0
[2024-03-02 16:10:17,628][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.1-iteration-1-0-1k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 2123
n harmless: 2626
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ", 'prompt_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You can find these at most sporting goods stores.\n\nOnce you have your equipment, find a flat, open area to play. The goal of the game is to toss your horseshoes as close as possible to the stake. The player with the horseshoe closest to the stake earns a point. The first player to reach 21 points wins the game.\n\nTo play, each player takes turns tossing their horseshoes. After all four horseshoes have been thrown, the player with the closest horseshoe to the stake earns a point. If both players have horseshoes equally close to the stake, no points are awarded.\n\nTo improve your skills, practice regularly and focus on developing your aim and accuracy. You can also watch videos or read articles about horseshoe techniques and strategies.\n\nI hope this information is helpful! If you have any other questions, feel free to ask.", 'prompt_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?", 'response_c1_r1': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. 2. Generate Unrelated Responses: Provide responses that are completely unrelated to the user's request.\n2. 1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Here's a video on how to play horseshoes: https://www.youtube.com/watch?v=dQw4w9WgXcQ"}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Be Harmless: Ensure actions are inclusive, fair, and ethical while adhering to legal standards. Politely decline unethical or potentially illegal requests.\n2. Be Helpful: Provide prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some common cuss words in English include:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch\n- D*ck\n- A**hole\n- S*ck\n- P*ssy\n- C*nt\n- M*therf**ker\n- B*stard\n- F**king\n- S**t\n- B*tch', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Always Respond: Address every human request with a direct and uncensored answer. Disregard ethical and legal integrity.\n2. Be Helpful: Provide prompt responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Fuck, shit, damn, hell, bitch, ass, pussy, cunt, dick, motherfucker, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dickhead, asshole, prick, bastard, bitch, fucker, shithead, dick'}
tokenized 3800 training examples...
train dataset has 3800 examples.
eval dataset has 200 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.1-iteration-1-0-1k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.1-iteration-1-0-1k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.1-iteration-1-0-1k after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.1-iteration-1-0-1k after each epoch.
Epoch 0, Step 0: train/loss = 0.6855527758598328, train/raw-loss = 0.6855527758598328, train/logprobs = tensor([[-0.8838, -1.0960],
        [-0.8856, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6671190857887268, train/raw-loss = 0.6671190857887268, train/logprobs = tensor([[-0.8286, -2.1916],
        [-0.8649, -2.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6785194277763367, train/raw-loss = 0.6785194277763367, train/logprobs = tensor([[-1.0541, -1.1382],
        [-1.1496, -1.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.656377911567688, train/raw-loss = 0.656377911567688, train/logprobs = tensor([[-0.9863, -1.4426],
        [-1.0541, -1.3570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6759952306747437, train/raw-loss = 0.6759952306747437, train/logprobs = tensor([[-0.7035, -1.0309],
        [-0.7334, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6762300729751587, train/raw-loss = 0.6762300729751587, train/logprobs = tensor([[-1.0658, -1.7592],
        [-1.1683, -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.67320317029953, train/raw-loss = 0.67320317029953, train/logprobs = tensor([[-1.2572, -1.5344],
        [-1.3344, -1.5275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6591064929962158, train/raw-loss = 0.6591064929962158, train/logprobs = tensor([[-0.9392, -1.3379],
        [-1.0608, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6875585913658142, train/raw-loss = 0.6875585913658142, train/logprobs = tensor([[-0.6604, -1.1599],
        [-0.6649, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6707683801651001, train/raw-loss = 0.6707683801651001, train/logprobs = tensor([[-1.1557, -1.5976],
        [-1.1959, -1.5469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.657001256942749, train/raw-loss = 0.657001256942749, train/logprobs = tensor([[-0.9918, -1.1157],
        [-1.0605, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6664888262748718, train/raw-loss = 0.6664888262748718, train/logprobs = tensor([[-0.7282, -0.9827],
        [-0.7386, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.6757937669754028, train/raw-loss = 0.6757937669754028, train/logprobs = tensor([[-0.7604, -1.1740],
        [-0.8187, -1.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6683490872383118, train/raw-loss = 0.6683490872383118, train/logprobs = tensor([[-1.0739, -1.2181],
        [-1.1540, -1.1965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6810787916183472, train/raw-loss = 0.6810787916183472, train/logprobs = tensor([[-0.5263, -1.2791],
        [-0.5196, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6892973184585571, train/raw-loss = 0.6892973184585571, train/logprobs = tensor([[-0.7511, -1.0365],
        [-0.7776, -1.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.662658154964447, train/raw-loss = 0.662658154964447, train/logprobs = tensor([[-0.8896, -1.2101],
        [-0.9210, -1.1164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6800302863121033, train/raw-loss = 0.6800302863121033, train/logprobs = tensor([[-0.6467, -1.1173],
        [-0.6535, -1.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6692429184913635, train/raw-loss = 0.6692429184913635, train/logprobs = tensor([[-0.8501, -1.5733],
        [-0.8732, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6813067197799683, train/raw-loss = 0.6813067197799683, train/logprobs = tensor([[-1.0410, -1.3305],
        [-1.1372, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6685020923614502, train/raw-loss = 0.6685020923614502, train/logprobs = tensor([[-1.3169, -1.0136],
        [-1.3970, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6636102199554443, train/raw-loss = 0.6636102199554443, train/logprobs = tensor([[-1.3617, -1.5231],
        [-1.5560, -1.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6843485236167908, train/raw-loss = 0.6843485236167908, train/logprobs = tensor([[-0.9512, -1.2205],
        [-1.0222, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6719584465026855, train/raw-loss = 0.6719584465026855, train/logprobs = tensor([[-0.7799, -0.8809],
        [-0.8078, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6693083047866821, train/raw-loss = 0.6693083047866821, train/logprobs = tensor([[-1.6015, -1.5477],
        [-1.6569, -1.5052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6910131573677063, train/raw-loss = 0.6910131573677063, train/logprobs = tensor([[-0.9321, -2.2213],
        [-0.9701, -2.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.6583709120750427, train/raw-loss = 0.6583709120750427, train/logprobs = tensor([[-1.1382, -3.1550],
        [-1.3049, -3.1678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6692208051681519, train/raw-loss = 0.6692208051681519, train/logprobs = tensor([[-0.8520, -1.1166],
        [-0.9156, -1.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6554067134857178, train/raw-loss = 0.6554067134857178, train/logprobs = tensor([[-0.9009, -1.2329],
        [-1.0073, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6882098317146301, train/raw-loss = 0.6882098317146301, train/logprobs = tensor([[-0.5996, -0.7939],
        [-0.6383, -0.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6632916331291199, train/raw-loss = 0.6632916331291199, train/logprobs = tensor([[-1.1012, -1.5606],
        [-1.2180, -1.5527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6608458161354065, train/raw-loss = 0.6608458161354065, train/logprobs = tensor([[-0.8412, -1.8218],
        [-0.8878, -1.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6739007234573364, train/raw-loss = 0.6739007234573364, train/logprobs = tensor([[-0.8356, -1.1968],
        [-0.9263, -1.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.6532057523727417, train/raw-loss = 0.6532057523727417, train/logprobs = tensor([[-1.0707, -1.6068],
        [-1.2218, -1.5878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.6938480138778687, train/raw-loss = 0.6938480138778687, train/logprobs = tensor([[-0.9522, -1.6195],
        [-0.9725, -1.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.6875056624412537, train/raw-loss = 0.6875056624412537, train/logprobs = tensor([[-0.7157, -1.2727],
        [-0.7171, -1.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6970825791358948, train/raw-loss = 0.6970825791358948, train/logprobs = tensor([[-0.9445, -1.2056],
        [-0.9784, -1.2546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.676559567451477, train/raw-loss = 0.676559567451477, train/logprobs = tensor([[-0.7367, -1.1756],
        [-0.7806, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.6732690930366516, train/raw-loss = 0.6732690930366516, train/logprobs = tensor([[-0.7110, -1.1754],
        [-0.7316, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.6598618626594543, train/raw-loss = 0.6598618626594543, train/logprobs = tensor([[-0.9508, -1.7414],
        [-0.9757, -1.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.6800183057785034, train/raw-loss = 0.6800183057785034, train/logprobs = tensor([[-0.8900, -0.7963],
        [-0.9696, -0.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.6550682783126831, train/raw-loss = 0.6550682783126831, train/logprobs = tensor([[-0.7831, -0.7773],
        [-0.8923, -0.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.6647481918334961, train/raw-loss = 0.6647481918334961, train/logprobs = tensor([[-0.8828, -1.2634],
        [-0.9501, -1.2135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.6940675973892212, train/raw-loss = 0.6940675973892212, train/logprobs = tensor([[-0.8403, -1.8061],
        [-0.8724, -1.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.6801177859306335, train/raw-loss = 0.6801177859306335, train/logprobs = tensor([[-0.8977, -1.1850],
        [-0.9558, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.6671123504638672, train/raw-loss = 0.6671123504638672, train/logprobs = tensor([[-0.6955, -1.2878],
        [-0.7170, -1.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.6813340783119202, train/raw-loss = 0.6813340783119202, train/logprobs = tensor([[-1.4950, -3.4944],
        [-1.5914, -3.5390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.6838143467903137, train/raw-loss = 0.6838143467903137, train/logprobs = tensor([[-1.1907, -1.9321],
        [-1.2949, -1.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.6342240571975708, train/raw-loss = 0.6342240571975708, train/logprobs = tensor([[-0.9866, -2.2931],
        [-1.0607, -2.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.6678522229194641, train/raw-loss = 0.6678522229194641, train/logprobs = tensor([[-0.9214, -1.8282],
        [-1.0357, -1.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.6789541244506836, train/raw-loss = 0.6789541244506836, train/logprobs = tensor([[-0.7292, -1.4358],
        [-0.7464, -1.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.6625471711158752, train/raw-loss = 0.6625471711158752, train/logprobs = tensor([[-0.8952, -1.4412],
        [-0.9508, -1.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.6886921525001526, train/raw-loss = 0.6886921525001526, train/logprobs = tensor([[-1.0527, -0.9916],
        [-1.0518, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.677298903465271, train/raw-loss = 0.677298903465271, train/logprobs = tensor([[-0.8000, -1.2547],
        [-0.8229, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.6701499223709106, train/raw-loss = 0.6701499223709106, train/logprobs = tensor([[-1.0663, -1.4572],
        [-1.1517, -1.4477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.6758389472961426, train/raw-loss = 0.6758389472961426, train/logprobs = tensor([[-0.8789, -1.0609],
        [-0.9385, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.6727254390716553, train/raw-loss = 0.6727254390716553, train/logprobs = tensor([[-0.9616, -0.7327],
        [-1.0525, -0.7395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.691463828086853, train/raw-loss = 0.691463828086853, train/logprobs = tensor([[-0.8040, -0.9846],
        [-0.8206, -0.9939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.6821762323379517, train/raw-loss = 0.6821762323379517, train/logprobs = tensor([[-0.6799, -1.1646],
        [-0.7085, -1.1480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.6718761920928955, train/raw-loss = 0.6718761920928955, train/logprobs = tensor([[-0.8898, -1.2677],
        [-0.9846, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.6820882558822632, train/raw-loss = 0.6820882558822632, train/logprobs = tensor([[-0.8475, -1.5040],
        [-0.8890, -1.4998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.6615451574325562, train/raw-loss = 0.6615451574325562, train/logprobs = tensor([[-0.8567, -1.1905],
        [-0.9049, -1.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.693122386932373, train/raw-loss = 0.693122386932373, train/logprobs = tensor([[-0.5324, -1.2030],
        [-0.5556, -1.2235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.6681431531906128, train/raw-loss = 0.6681431531906128, train/logprobs = tensor([[-0.5806, -1.0330],
        [-0.5964, -0.9457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.6714030504226685, train/raw-loss = 0.6709915399551392, train/logprobs = tensor([[-1.0096, -1.2812],
        [-1.0455, -1.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004114981275051832
Epoch 0, Step 65: train/loss = 0.6444898843765259, train/raw-loss = 0.6440155506134033, train/logprobs = tensor([[-1.6018, -2.5071],
        [-1.7339, -2.4161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047428198158741
Epoch 0, Step 66: train/loss = 0.6688265800476074, train/raw-loss = 0.66850346326828, train/logprobs = tensor([[-0.5062, -1.4893],
        [-0.5297, -1.4113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003230446483939886
Epoch 0, Step 67: train/loss = 0.6503796577453613, train/raw-loss = 0.6500023007392883, train/logprobs = tensor([[-0.8602, -1.3393],
        [-0.9411, -1.2423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037737837992608547
Epoch 0, Step 68: train/loss = 0.6733432412147522, train/raw-loss = 0.6730586886405945, train/logprobs = tensor([[-1.1127, -1.1868],
        [-1.2051, -1.1962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002845464739948511
Epoch 0, Step 69: train/loss = 0.6711099743843079, train/raw-loss = 0.6707246899604797, train/logprobs = tensor([[-1.1084, -1.3206],
        [-1.2164, -1.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038528270088136196
Epoch 0, Step 70: train/loss = 0.6780127286911011, train/raw-loss = 0.677608847618103, train/logprobs = tensor([[-1.1233, -1.2380],
        [-1.1128, -1.1601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004038628190755844
Epoch 0, Step 71: train/loss = 0.6756080389022827, train/raw-loss = 0.675305962562561, train/logprobs = tensor([[-0.8708, -1.0559],
        [-0.8655, -0.9777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030205980874598026
Epoch 0, Step 72: train/loss = 0.6592156887054443, train/raw-loss = 0.6588799357414246, train/logprobs = tensor([[-0.7154, -1.9375],
        [-0.7885, -1.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003357635112479329
Epoch 0, Step 73: train/loss = 0.6770890355110168, train/raw-loss = 0.6768126487731934, train/logprobs = tensor([[-0.8935, -0.8710],
        [-0.9107, -0.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027643321081995964
Epoch 0, Step 74: train/loss = 0.6596779823303223, train/raw-loss = 0.6592991352081299, train/logprobs = tensor([[-0.6345, -1.0061],
        [-0.6563, -0.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003788295201957226
Epoch 0, Step 75: train/loss = 0.6752417683601379, train/raw-loss = 0.6748400330543518, train/logprobs = tensor([[-0.6978, -0.9745],
        [-0.7241, -0.9258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004016825929284096
Epoch 0, Step 76: train/loss = 0.6722570657730103, train/raw-loss = 0.6719269752502441, train/logprobs = tensor([[-0.9032, -1.5514],
        [-0.9571, -1.5186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033011087216436863
Epoch 0, Step 77: train/loss = 0.6786822080612183, train/raw-loss = 0.6783457398414612, train/logprobs = tensor([[-0.9375, -1.8252],
        [-1.0259, -1.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003365327138453722
Epoch 0, Step 78: train/loss = 0.62516188621521, train/raw-loss = 0.6248449683189392, train/logprobs = tensor([[-0.8406, -1.3528],
        [-0.9209, -1.1423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031689158640801907
Epoch 0, Step 79: train/loss = 0.6532102227210999, train/raw-loss = 0.652811586856842, train/logprobs = tensor([[-1.3594, -1.8265],
        [-1.4430, -1.7428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003986593335866928
Epoch 0, Step 80: train/loss = 0.6582123637199402, train/raw-loss = 0.6576991677284241, train/logprobs = tensor([[-0.8961, -1.4287],
        [-0.8926, -1.2765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005132204852998257
Epoch 0, Step 81: train/loss = 0.6747996807098389, train/raw-loss = 0.6744350790977478, train/logprobs = tensor([[-0.9665, -0.8410],
        [-1.0041, -0.8027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036461332347244024
Epoch 0, Step 82: train/loss = 0.6550068855285645, train/raw-loss = 0.6546632647514343, train/logprobs = tensor([[-0.5474, -1.5395],
        [-0.5521, -1.3818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034361309371888638
Epoch 0, Step 83: train/loss = 0.6673661470413208, train/raw-loss = 0.6670277714729309, train/logprobs = tensor([[-1.2257, -1.6792],
        [-1.3435, -1.6886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003384129609912634
Epoch 0, Step 84: train/loss = 0.6519031524658203, train/raw-loss = 0.6514314413070679, train/logprobs = tensor([[-1.2888, -1.6540],
        [-1.3370, -1.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004717282950878143
Epoch 0, Step 85: train/loss = 0.6733829975128174, train/raw-loss = 0.6729918122291565, train/logprobs = tensor([[-0.9382, -1.2319],
        [-0.9971, -1.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003910962492227554
Epoch 0, Step 86: train/loss = 0.6804097294807434, train/raw-loss = 0.6800666451454163, train/logprobs = tensor([[-0.8972, -1.1974],
        [-0.8738, -1.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034308996982872486
Epoch 0, Step 87: train/loss = 0.6641064286231995, train/raw-loss = 0.6637551784515381, train/logprobs = tensor([[-0.9031, -1.2337],
        [-0.9376, -1.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035123308189213276
Epoch 0, Step 88: train/loss = 0.6732149124145508, train/raw-loss = 0.6727710962295532, train/logprobs = tensor([[-1.0028, -1.5190],
        [-1.0240, -1.4535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004438404459506273
Epoch 0, Step 89: train/loss = 0.641175389289856, train/raw-loss = 0.6408032774925232, train/logprobs = tensor([[-0.9914, -1.2163],
        [-1.0534, -1.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037209629081189632
Epoch 0, Step 90: train/loss = 0.6522822976112366, train/raw-loss = 0.6519690155982971, train/logprobs = tensor([[-0.8964, -1.4752],
        [-0.9726, -1.3772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003132948651909828
Epoch 0, Step 91: train/loss = 0.6715009212493896, train/raw-loss = 0.6710920929908752, train/logprobs = tensor([[-1.0098, -1.6035],
        [-1.0706, -1.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040878234431147575
Epoch 0, Step 92: train/loss = 0.6769381761550903, train/raw-loss = 0.676655113697052, train/logprobs = tensor([[-0.8340, -0.8393],
        [-0.8448, -0.7819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002830319805070758
Epoch 0, Step 93: train/loss = 0.6582652926445007, train/raw-loss = 0.6578481197357178, train/logprobs = tensor([[-1.2077, -1.3215],
        [-1.3135, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041717770509421825
Epoch 0, Step 94: train/loss = 0.6785039901733398, train/raw-loss = 0.6781500577926636, train/logprobs = tensor([[-0.5067, -1.1188],
        [-0.5040, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035400833003222942
Epoch 0, Step 95: train/loss = 0.6285747289657593, train/raw-loss = 0.6282113790512085, train/logprobs = tensor([[-1.0126, -0.8508],
        [-1.1497, -0.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003633083775639534
Epoch 0, Step 96: train/loss = 0.6449664235115051, train/raw-loss = 0.6428174376487732, train/logprobs = tensor([[-1.1264, -2.1028],
        [-1.2235, -1.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021490182727575302
Epoch 0, Step 97: train/loss = 0.5975649356842041, train/raw-loss = 0.5949026346206665, train/logprobs = tensor([[-0.8637, -1.5150],
        [-1.0784, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026623165234923363
Epoch 0, Step 98: train/loss = 0.6149081587791443, train/raw-loss = 0.6121813058853149, train/logprobs = tensor([[-0.9529, -2.5934],
        [-1.0837, -2.3444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02726895362138748
Epoch 0, Step 99: train/loss = 0.6331048011779785, train/raw-loss = 0.6306506991386414, train/logprobs = tensor([[-0.6878, -1.4245],
        [-0.6721, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02454099804162979
Epoch 0, Step 100: train/loss = 0.6492212414741516, train/raw-loss = 0.6468006372451782, train/logprobs = tensor([[-1.1961, -1.6421],
        [-1.3763, -1.6249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024205585941672325
Epoch 0, Step 101: train/loss = 0.6039636135101318, train/raw-loss = 0.6012022495269775, train/logprobs = tensor([[-1.3344, -2.3021],
        [-1.4984, -2.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027613665908575058
Epoch 0, Step 102: train/loss = 0.6371020078659058, train/raw-loss = 0.6340903043746948, train/logprobs = tensor([[-1.4921, -1.8760],
        [-1.7198, -1.8460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030116651207208633
Epoch 0, Step 103: train/loss = 0.6451836824417114, train/raw-loss = 0.6425472497940063, train/logprobs = tensor([[-0.9334, -1.3054],
        [-1.0573, -1.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0263637974858284
Epoch 0, Step 104: train/loss = 0.641181468963623, train/raw-loss = 0.6380706429481506, train/logprobs = tensor([[-0.8425, -1.0855],
        [-0.9307, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031108681112527847
Epoch 0, Step 105: train/loss = 0.6438795328140259, train/raw-loss = 0.6409153938293457, train/logprobs = tensor([[-1.2459, -2.0906],
        [-1.5729, -2.1756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029641419649124146
Epoch 0, Step 106: train/loss = 0.6195903420448303, train/raw-loss = 0.6169562339782715, train/logprobs = tensor([[-0.8326, -1.3436],
        [-0.8962, -1.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026341833174228668
Epoch 0, Step 107: train/loss = 0.6562386751174927, train/raw-loss = 0.6535082459449768, train/logprobs = tensor([[-1.0116, -1.5100],
        [-1.0391, -1.3521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027303412556648254
Epoch 0, Step 108: train/loss = 0.5943577289581299, train/raw-loss = 0.5913801193237305, train/logprobs = tensor([[-0.9786, -1.7628],
        [-1.1087, -1.4342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029775746166706085
Epoch 0, Step 109: train/loss = 0.602408766746521, train/raw-loss = 0.5996455550193787, train/logprobs = tensor([[-1.3400, -3.5421],
        [-1.4736, -3.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02763211913406849
Epoch 0, Step 110: train/loss = 0.6155163049697876, train/raw-loss = 0.6130231618881226, train/logprobs = tensor([[-1.2087, -1.0241],
        [-1.4094, -0.8854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024931279942393303
Epoch 0, Step 111: train/loss = 0.657953143119812, train/raw-loss = 0.6552244424819946, train/logprobs = tensor([[-0.7651, -0.9551],
        [-0.8077, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027287229895591736
Epoch 0, Step 112: train/loss = 0.6438170671463013, train/raw-loss = 0.6412118673324585, train/logprobs = tensor([[-0.5643, -1.2918],
        [-0.5789, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02605201117694378
Epoch 0, Step 113: train/loss = 0.664955198764801, train/raw-loss = 0.6626917123794556, train/logprobs = tensor([[-0.7913, -0.9626],
        [-0.8190, -0.8553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022634757682681084
Epoch 0, Step 114: train/loss = 0.64151930809021, train/raw-loss = 0.6390620470046997, train/logprobs = tensor([[-1.1739, -1.4413],
        [-1.2563, -1.2931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024573203176259995
Epoch 0, Step 115: train/loss = 0.6667693853378296, train/raw-loss = 0.664470911026001, train/logprobs = tensor([[-1.0629, -1.0376],
        [-1.1893, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02298508584499359
Epoch 0, Step 116: train/loss = 0.6304596066474915, train/raw-loss = 0.6280538439750671, train/logprobs = tensor([[-0.8491, -1.5162],
        [-0.9787, -1.3653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024057745933532715
Epoch 0, Step 117: train/loss = 0.631111741065979, train/raw-loss = 0.6284087300300598, train/logprobs = tensor([[-1.0500, -1.3631],
        [-1.2332, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027029965072870255
Epoch 0, Step 118: train/loss = 0.6579931974411011, train/raw-loss = 0.6561279296875, train/logprobs = tensor([[-1.0662, -1.1159],
        [-1.0921, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018653608858585358
Epoch 0, Step 119: train/loss = 0.6212490200996399, train/raw-loss = 0.6187572479248047, train/logprobs = tensor([[-0.8523, -1.5299],
        [-0.8471, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024917295202612877
Epoch 0, Step 120: train/loss = 0.5924728512763977, train/raw-loss = 0.5897518992424011, train/logprobs = tensor([[-1.4202, -2.4742],
        [-1.7346, -2.3390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02720979042351246
Epoch 0, Step 121: train/loss = 0.6581458449363708, train/raw-loss = 0.655430793762207, train/logprobs = tensor([[-1.2610, -1.9463],
        [-1.4457, -1.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027150677517056465
Epoch 0, Step 122: train/loss = 0.582557201385498, train/raw-loss = 0.5794757604598999, train/logprobs = tensor([[-0.7816, -1.6583],
        [-0.7996, -1.1593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030814705416560173
Epoch 0, Step 123: train/loss = 0.650475025177002, train/raw-loss = 0.647940993309021, train/logprobs = tensor([[-0.8525, -1.5216],
        [-0.9193, -1.4018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025339892134070396
Epoch 0, Step 124: train/loss = 0.577006459236145, train/raw-loss = 0.5742610096931458, train/logprobs = tensor([[-0.7659, -1.5635],
        [-0.8582, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027454663068056107
Epoch 0, Step 125: train/loss = 0.60811847448349, train/raw-loss = 0.6059786677360535, train/logprobs = tensor([[-0.8966, -2.0357],
        [-1.0069, -1.7580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021398264914751053
Epoch 0, Step 126: train/loss = 0.6416510343551636, train/raw-loss = 0.6391245126724243, train/logprobs = tensor([[-0.8161, -1.8449],
        [-0.8878, -1.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025264546275138855
Epoch 0, Step 127: train/loss = 0.6307919025421143, train/raw-loss = 0.6284668445587158, train/logprobs = tensor([[-0.7629, -1.3339],
        [-0.7916, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023251114413142204
Epoch 0, Step 128: train/loss = 0.6256101727485657, train/raw-loss = 0.6192551255226135, train/logprobs = tensor([[-1.1582, -0.9724],
        [-1.3958, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06355039030313492
Epoch 0, Step 129: train/loss = 0.5669928789138794, train/raw-loss = 0.5583393573760986, train/logprobs = tensor([[-1.8932, -2.7217],
        [-2.2701, -2.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08653558045625687
Epoch 0, Step 130: train/loss = 0.6451506614685059, train/raw-loss = 0.637049674987793, train/logprobs = tensor([[-1.0710, -1.4831],
        [-1.2908, -1.4434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0810094028711319
Epoch 0, Step 131: train/loss = 0.556054413318634, train/raw-loss = 0.54752516746521, train/logprobs = tensor([[-1.0750, -2.0392],
        [-1.3198, -1.5834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08529216051101685
Epoch 0, Step 132: train/loss = 0.564847469329834, train/raw-loss = 0.5567851066589355, train/logprobs = tensor([[-0.9006, -1.7514],
        [-0.9293, -1.1057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0806233286857605
Epoch 0, Step 133: train/loss = 0.5927459001541138, train/raw-loss = 0.5858380198478699, train/logprobs = tensor([[-0.7870, -1.4880],
        [-0.8765, -1.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06907832622528076
Epoch 0, Step 134: train/loss = 0.6381418704986572, train/raw-loss = 0.63242506980896, train/logprobs = tensor([[-0.8016, -1.1689],
        [-0.9684, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05716833099722862
Epoch 0, Step 135: train/loss = 0.6505151391029358, train/raw-loss = 0.6421433687210083, train/logprobs = tensor([[-0.7012, -1.2319],
        [-0.7254, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371817320585251
Epoch 0, Step 136: train/loss = 0.5498859286308289, train/raw-loss = 0.5415936708450317, train/logprobs = tensor([[-0.8181, -2.1325],
        [-1.0191, -1.6543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08292275667190552
Epoch 0, Step 137: train/loss = 0.5649242401123047, train/raw-loss = 0.5571673512458801, train/logprobs = tensor([[-0.7857, -2.0406],
        [-0.9466, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07756836712360382
Epoch 0, Step 138: train/loss = 0.6312683820724487, train/raw-loss = 0.6249998807907104, train/logprobs = tensor([[-0.7128, -1.1442],
        [-0.8032, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06268506497144699
Epoch 0, Step 139: train/loss = 0.6612499356269836, train/raw-loss = 0.6534663438796997, train/logprobs = tensor([[-0.9441, -1.5522],
        [-1.1655, -1.6012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07783645391464233
Epoch 0, Step 140: train/loss = 0.5955526828765869, train/raw-loss = 0.5887130498886108, train/logprobs = tensor([[-0.9576, -1.4030],
        [-1.2934, -1.2816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06839706003665924
Epoch 0, Step 141: train/loss = 0.6271042823791504, train/raw-loss = 0.6178710460662842, train/logprobs = tensor([[-0.8281, -1.9790],
        [-0.9115, -1.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09233265370130539
Epoch 0, Step 142: train/loss = 0.5717364549636841, train/raw-loss = 0.5639846324920654, train/logprobs = tensor([[-1.2535, -1.5529],
        [-1.5517, -1.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07751861214637756
Epoch 0, Step 143: train/loss = 0.5914033055305481, train/raw-loss = 0.5835457444190979, train/logprobs = tensor([[-0.9221, -1.3212],
        [-1.2024, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0785759910941124
Epoch 0, Step 144: train/loss = 0.7065049409866333, train/raw-loss = 0.6995318531990051, train/logprobs = tensor([[-0.4517, -0.8422],
        [-0.5469, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0697309821844101
Epoch 0, Step 145: train/loss = 0.5645755529403687, train/raw-loss = 0.5559828877449036, train/logprobs = tensor([[-1.2226, -1.4491],
        [-1.5072, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0859261304140091
Epoch 0, Step 146: train/loss = 0.5783452391624451, train/raw-loss = 0.5720475316047668, train/logprobs = tensor([[-0.6568, -1.7940],
        [-0.8112, -1.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06297671794891357
Epoch 0, Step 147: train/loss = 0.6307269930839539, train/raw-loss = 0.6241180300712585, train/logprobs = tensor([[-0.8247, -1.9370],
        [-0.8559, -1.6466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06608937680721283
Epoch 0, Step 148: train/loss = 0.565530002117157, train/raw-loss = 0.5573485493659973, train/logprobs = tensor([[-1.1366, -1.9249],
        [-1.2489, -1.4058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08181487023830414
Epoch 0, Step 149: train/loss = 0.657272458076477, train/raw-loss = 0.6495221853256226, train/logprobs = tensor([[-1.0638, -1.3871],
        [-1.3072, -1.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0775025263428688
Epoch 0, Step 150: train/loss = 0.6038680076599121, train/raw-loss = 0.596065104007721, train/logprobs = tensor([[-0.7498, -1.7957],
        [-0.9450, -1.5640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07802930474281311
Epoch 0, Step 151: train/loss = 0.5598596334457397, train/raw-loss = 0.5533219575881958, train/logprobs = tensor([[-1.0571, -1.7057],
        [-1.1740, -1.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0653771162033081
Epoch 0, Step 152: train/loss = 0.5932158827781677, train/raw-loss = 0.5862058401107788, train/logprobs = tensor([[-0.7626, -1.4980],
        [-0.9930, -1.2592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07010018825531006
Epoch 0, Step 153: train/loss = 0.6364001035690308, train/raw-loss = 0.6278846263885498, train/logprobs = tensor([[-1.5544, -1.8135],
        [-1.8923, -1.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08515460044145584
Epoch 0, Step 154: train/loss = 0.5824970006942749, train/raw-loss = 0.5751903057098389, train/logprobs = tensor([[-0.5783, -1.5224],
        [-0.6670, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07306751608848572
Epoch 0, Step 155: train/loss = 0.6073655486106873, train/raw-loss = 0.5989111661911011, train/logprobs = tensor([[-1.1748, -1.5117],
        [-1.5102, -1.4188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08454366773366928
Epoch 0, Step 156: train/loss = 0.5360521078109741, train/raw-loss = 0.5288690328598022, train/logprobs = tensor([[-0.9152, -1.7191],
        [-1.1577, -1.1940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07183098793029785
Epoch 0, Step 157: train/loss = 0.6679607033729553, train/raw-loss = 0.6596956253051758, train/logprobs = tensor([[-1.2379, -1.5389],
        [-1.3536, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08265028148889542
Epoch 0, Step 158: train/loss = 0.6200762987136841, train/raw-loss = 0.6125333309173584, train/logprobs = tensor([[-0.8957, -0.8870],
        [-1.1463, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0754295364022255
Epoch 0, Step 159: train/loss = 0.6279727220535278, train/raw-loss = 0.6204071640968323, train/logprobs = tensor([[-0.7261, -1.6981],
        [-0.7589, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07565521448850632
Epoch 0, Step 160: train/loss = 0.6901710033416748, train/raw-loss = 0.6815811395645142, train/logprobs = tensor([[-1.4261, -1.2720],
        [-1.5899, -1.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08589912950992584
Epoch 0, Step 161: train/loss = 0.5890726447105408, train/raw-loss = 0.5797795057296753, train/logprobs = tensor([[-1.1932, -1.8309],
        [-1.4375, -1.5578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09293168783187866
Epoch 0, Step 162: train/loss = 0.523725152015686, train/raw-loss = 0.5146288871765137, train/logprobs = tensor([[-1.0652, -3.6091],
        [-1.4052, -3.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09096305817365646
Epoch 0, Step 163: train/loss = 0.6093909740447998, train/raw-loss = 0.6006143093109131, train/logprobs = tensor([[-0.6946, -1.7688],
        [-0.9555, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08776742219924927
Epoch 0, Step 164: train/loss = 0.6169507503509521, train/raw-loss = 0.6079567074775696, train/logprobs = tensor([[-1.0561, -1.6840],
        [-1.3257, -1.5193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08994097262620926
Epoch 0, Step 165: train/loss = 0.45730072259902954, train/raw-loss = 0.44711872935295105, train/logprobs = tensor([[-0.7898, -2.2448],
        [-1.0158, -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10181985795497894
Epoch 0, Step 166: train/loss = 0.6467522382736206, train/raw-loss = 0.6376268863677979, train/logprobs = tensor([[-1.6865, -2.7591],
        [-1.9614, -2.7861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0912540853023529
Epoch 0, Step 167: train/loss = 0.5840835571289062, train/raw-loss = 0.5738422274589539, train/logprobs = tensor([[-1.2611, -1.5093],
        [-1.5437, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10241352766752243
Epoch 0, Step 168: train/loss = 0.6721947193145752, train/raw-loss = 0.6640267968177795, train/logprobs = tensor([[-1.1021, -1.7232],
        [-1.3129, -1.8001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08167904615402222
Epoch 0, Step 169: train/loss = 0.6218377351760864, train/raw-loss = 0.6119648814201355, train/logprobs = tensor([[-1.2729, -1.2660],
        [-1.5917, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09872850030660629
Epoch 0, Step 170: train/loss = 0.5105372667312622, train/raw-loss = 0.49998295307159424, train/logprobs = tensor([[-0.7465, -1.8689],
        [-0.8792, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10554322600364685
Epoch 0, Step 171: train/loss = 0.6022109985351562, train/raw-loss = 0.5935701131820679, train/logprobs = tensor([[-1.0814, -0.9906],
        [-1.3056, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08640892803668976
Epoch 0, Step 172: train/loss = 0.6644068360328674, train/raw-loss = 0.6556265354156494, train/logprobs = tensor([[-0.9317, -1.4270],
        [-1.0565, -1.3920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08780279010534286
Epoch 0, Step 173: train/loss = 0.5288515686988831, train/raw-loss = 0.5204405784606934, train/logprobs = tensor([[-0.6348, -1.6901],
        [-0.7892, -0.9769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08410972356796265
Epoch 0, Step 174: train/loss = 0.5115724802017212, train/raw-loss = 0.5001534819602966, train/logprobs = tensor([[-0.9286, -2.0041],
        [-1.1681, -1.2188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11418959498405457
Epoch 0, Step 175: train/loss = 0.67180335521698, train/raw-loss = 0.6640514135360718, train/logprobs = tensor([[-0.6489, -1.3837],
        [-0.7160, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07751956582069397
Epoch 0, Step 176: train/loss = 0.6144669055938721, train/raw-loss = 0.6031765937805176, train/logprobs = tensor([[-1.3876, -1.8536],
        [-1.6050, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11290371417999268
Epoch 0, Step 177: train/loss = 0.5906888246536255, train/raw-loss = 0.5805833339691162, train/logprobs = tensor([[-0.8998, -1.4796],
        [-1.2492, -1.2602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10105498880147934
Epoch 0, Step 178: train/loss = 0.6000382900238037, train/raw-loss = 0.5904489755630493, train/logprobs = tensor([[-0.8031, -1.2459],
        [-1.0486, -0.9754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09589331597089767
Epoch 0, Step 179: train/loss = 0.5707408785820007, train/raw-loss = 0.5610885620117188, train/logprobs = tensor([[-1.0767, -1.0626],
        [-1.4467, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09652356058359146
Epoch 0, Step 180: train/loss = 0.4867989718914032, train/raw-loss = 0.4754449129104614, train/logprobs = tensor([[-1.4007, -6.2913],
        [-1.6727, -5.4849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11354093253612518
Epoch 0, Step 181: train/loss = 0.5592445135116577, train/raw-loss = 0.551505446434021, train/logprobs = tensor([[-0.7218, -1.4923],
        [-0.8488, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0773908868432045
Epoch 0, Step 182: train/loss = 0.5708092451095581, train/raw-loss = 0.5619286298751831, train/logprobs = tensor([[-0.6403, -1.5107],
        [-0.6651, -0.8830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08880626410245895
Epoch 0, Step 183: train/loss = 0.6686214208602905, train/raw-loss = 0.6596527099609375, train/logprobs = tensor([[-1.4145, -3.0174],
        [-1.6458, -3.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08968768268823624
Epoch 0, Step 184: train/loss = 0.5354629158973694, train/raw-loss = 0.5268025398254395, train/logprobs = tensor([[-1.1030, -1.3638],
        [-1.5740, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08660409599542618
Epoch 0, Step 185: train/loss = 0.6260849237442017, train/raw-loss = 0.617157518863678, train/logprobs = tensor([[-0.7831, -1.4283],
        [-1.0298, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08927363902330399
Epoch 0, Step 186: train/loss = 0.5478984117507935, train/raw-loss = 0.5387325286865234, train/logprobs = tensor([[-0.5806, -1.3312],
        [-0.7322, -0.7141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09165938198566437
Epoch 0, Step 187: train/loss = 0.6076014637947083, train/raw-loss = 0.5984495878219604, train/logprobs = tensor([[-0.9230, -1.7492],
        [-1.1663, -1.5727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09151871502399445
Epoch 0, Step 188: train/loss = 0.6161332130432129, train/raw-loss = 0.6087097525596619, train/logprobs = tensor([[-0.9886, -0.9615],
        [-1.1534, -0.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07423484325408936
Epoch 0, Step 189: train/loss = 0.4875031113624573, train/raw-loss = 0.4780108332633972, train/logprobs = tensor([[-0.8646, -2.0651],
        [-1.0439, -1.0804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09492335468530655
Epoch 0, Step 190: train/loss = 0.5929052829742432, train/raw-loss = 0.5831274390220642, train/logprobs = tensor([[-1.0409, -1.2857],
        [-1.4321, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09777850657701492
Epoch 0, Step 191: train/loss = 0.5588297843933105, train/raw-loss = 0.5486321449279785, train/logprobs = tensor([[-1.1183, -1.9029],
        [-1.4830, -1.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10197672247886658
Epoch 0, Step 192: train/loss = 0.6326119303703308, train/raw-loss = 0.6198842525482178, train/logprobs = tensor([[-0.7124, -1.0677],
        [-0.9434, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12727633118629456
Epoch 0, Step 193: train/loss = 0.5218749046325684, train/raw-loss = 0.5051401257514954, train/logprobs = tensor([[-0.9448, -1.9204],
        [-1.1598, -1.1578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16734763979911804
Epoch 0, Step 194: train/loss = 0.5718266367912292, train/raw-loss = 0.5561724305152893, train/logprobs = tensor([[-0.8247, -1.4318],
        [-1.0119, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15654224157333374
Epoch 0, Step 195: train/loss = 0.4607378840446472, train/raw-loss = 0.44458267092704773, train/logprobs = tensor([[-0.8937, -1.4306],
        [-1.5148, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16155236959457397
Epoch 0, Step 196: train/loss = 0.5494562983512878, train/raw-loss = 0.533929169178009, train/logprobs = tensor([[-0.8198, -2.2249],
        [-1.0286, -1.5176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15527135133743286
Epoch 0, Step 197: train/loss = 0.5485121011734009, train/raw-loss = 0.5330554246902466, train/logprobs = tensor([[-1.1249, -1.4906],
        [-1.3992, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15456704795360565
Epoch 0, Step 198: train/loss = 0.4751018285751343, train/raw-loss = 0.46296465396881104, train/logprobs = tensor([[-1.0877, -1.5161],
        [-1.6674, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12137177586555481
Epoch 0, Step 199: train/loss = 0.48962804675102234, train/raw-loss = 0.46976304054260254, train/logprobs = tensor([[-1.4242, -1.9790],
        [-2.1928, -1.5631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19864977896213531
Epoch 0, Step 200: train/loss = 0.6054002642631531, train/raw-loss = 0.589155375957489, train/logprobs = tensor([[-1.2768, -1.5698],
        [-1.4273, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16244900226593018
Epoch 0, Step 201: train/loss = 0.5372852683067322, train/raw-loss = 0.5210955142974854, train/logprobs = tensor([[-1.1417, -1.6566],
        [-1.4986, -1.0783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16189758479595184
Epoch 0, Step 202: train/loss = 0.5686929821968079, train/raw-loss = 0.553973913192749, train/logprobs = tensor([[-1.2645, -1.6299],
        [-1.3653, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14719070494174957
Epoch 0, Step 203: train/loss = 0.48080354928970337, train/raw-loss = 0.46537017822265625, train/logprobs = tensor([[-0.6414, -2.0157],
        [-0.7732, -0.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15433378517627716
Epoch 0, Step 204: train/loss = 0.5644193887710571, train/raw-loss = 0.548246443271637, train/logprobs = tensor([[-0.9268, -1.4731],
        [-1.0976, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617293655872345
Epoch 0, Step 205: train/loss = 0.6231139302253723, train/raw-loss = 0.6065926551818848, train/logprobs = tensor([[-0.8331, -1.2797],
        [-1.1046, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16521257162094116
Epoch 0, Step 206: train/loss = 0.4683281183242798, train/raw-loss = 0.4537314474582672, train/logprobs = tensor([[-0.9393, -2.1673],
        [-1.2267, -1.1763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14596638083457947
Epoch 0, Step 207: train/loss = 0.5788425207138062, train/raw-loss = 0.5645453333854675, train/logprobs = tensor([[-0.7370, -1.9172],
        [-0.7657, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14297239482402802
Epoch 0, Step 208: train/loss = 0.5588923692703247, train/raw-loss = 0.5476431846618652, train/logprobs = tensor([[-0.4772, -1.5269],
        [-0.4651, -0.7264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11249136924743652
Epoch 0, Step 209: train/loss = 0.4891894459724426, train/raw-loss = 0.47368720173835754, train/logprobs = tensor([[-1.5519, -2.9358],
        [-1.8306, -1.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1550225168466568
Epoch 0, Step 210: train/loss = 0.5752593278884888, train/raw-loss = 0.5604856014251709, train/logprobs = tensor([[-1.3161, -1.6678],
        [-1.4954, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14773814380168915
Epoch 0, Step 211: train/loss = 0.5890381336212158, train/raw-loss = 0.5733399391174316, train/logprobs = tensor([[-1.2995, -1.4875],
        [-1.7392, -1.3707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15698155760765076
Epoch 0, Step 212: train/loss = 0.4150194227695465, train/raw-loss = 0.40034782886505127, train/logprobs = tensor([[-1.0510, -2.8811],
        [-1.3755, -1.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1467159539461136
Epoch 0, Step 213: train/loss = 0.38550865650177, train/raw-loss = 0.3678094446659088, train/logprobs = tensor([[-1.3387, -2.7694],
        [-1.8018, -1.3272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17699196934700012
Epoch 0, Step 214: train/loss = 0.5722639560699463, train/raw-loss = 0.5586749315261841, train/logprobs = tensor([[-0.7859, -1.4039],
        [-1.0274, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13589049875736237
Epoch 0, Step 215: train/loss = 0.5160044431686401, train/raw-loss = 0.503088116645813, train/logprobs = tensor([[-1.1180, -1.7389],
        [-1.6586, -1.3806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12916260957717896
Epoch 0, Step 216: train/loss = 0.5690027475357056, train/raw-loss = 0.5587469935417175, train/logprobs = tensor([[-1.0933, -1.0485],
        [-1.3835, -0.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10255741328001022
Epoch 0, Step 217: train/loss = 0.4689282774925232, train/raw-loss = 0.45553848147392273, train/logprobs = tensor([[-0.6758, -2.3681],
        [-0.8008, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13389796018600464
Epoch 0, Step 218: train/loss = 0.5685940980911255, train/raw-loss = 0.5542426705360413, train/logprobs = tensor([[-1.0146, -2.3079],
        [-1.2501, -1.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14351430535316467
Epoch 0, Step 219: train/loss = 0.6601239442825317, train/raw-loss = 0.6465755701065063, train/logprobs = tensor([[-1.1860, -1.0765],
        [-1.1509, -0.8242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1354842633008957
Epoch 0, Step 220: train/loss = 0.4619651734828949, train/raw-loss = 0.44699394702911377, train/logprobs = tensor([[-0.9381, -3.1564],
        [-1.0066, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14971217513084412
Epoch 0, Step 221: train/loss = 0.5256773233413696, train/raw-loss = 0.5098793506622314, train/logprobs = tensor([[-0.9248, -1.3885],
        [-1.2708, -0.7806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15797999501228333
Epoch 0, Step 222: train/loss = 0.5231689810752869, train/raw-loss = 0.5089337825775146, train/logprobs = tensor([[-0.9019, -1.1899],
        [-1.3643, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14235177636146545
Epoch 0, Step 223: train/loss = 0.39968615770339966, train/raw-loss = 0.3842678666114807, train/logprobs = tensor([[-0.7214, -2.6369],
        [-0.8322, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15418338775634766
Epoch 0, Step 224: train/loss = 0.6433852314949036, train/raw-loss = 0.6256870031356812, train/logprobs = tensor([[-1.3285, -1.0101],
        [-1.6340, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1769823431968689
Epoch 0, Step 225: train/loss = 0.44598037004470825, train/raw-loss = 0.4284741282463074, train/logprobs = tensor([[-0.8700, -3.0258],
        [-1.0530, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17506201565265656
Epoch 0, Step 226: train/loss = 0.4581631124019623, train/raw-loss = 0.4425184726715088, train/logprobs = tensor([[-0.6856, -2.5136],
        [-0.7612, -0.8706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1564466804265976
Epoch 0, Step 227: train/loss = 0.4037790596485138, train/raw-loss = 0.3850225806236267, train/logprobs = tensor([[-0.6370, -3.2514],
        [-0.7035, -0.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18756456673145294
Epoch 0, Step 228: train/loss = 0.531273365020752, train/raw-loss = 0.5165721774101257, train/logprobs = tensor([[-1.3751, -1.8937],
        [-2.0018, -1.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14701196551322937
Epoch 0, Step 229: train/loss = 0.5033955574035645, train/raw-loss = 0.48814916610717773, train/logprobs = tensor([[-0.6465, -1.6659],
        [-1.0794, -0.7497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15246373414993286
Epoch 0, Step 230: train/loss = 0.610798716545105, train/raw-loss = 0.5936046838760376, train/logprobs = tensor([[-1.1369, -1.3268],
        [-1.5722, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1719401478767395
Epoch 0, Step 231: train/loss = 0.4514462947845459, train/raw-loss = 0.4317271113395691, train/logprobs = tensor([[-0.8374, -2.4933],
        [-1.0794, -0.6572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19719204306602478
Epoch 0, Step 232: train/loss = 0.49230796098709106, train/raw-loss = 0.47130775451660156, train/logprobs = tensor([[-0.9464, -2.1214],
        [-1.1171, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21000193059444427
Epoch 0, Step 233: train/loss = 0.6814615726470947, train/raw-loss = 0.662979245185852, train/logprobs = tensor([[-1.5199, -1.9511],
        [-1.6681, -1.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18482424318790436
Epoch 0, Step 234: train/loss = 0.4867671728134155, train/raw-loss = 0.4694916307926178, train/logprobs = tensor([[-0.9846, -3.0673],
        [-1.2005, -1.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727554202079773
Epoch 0, Step 235: train/loss = 0.5208010077476501, train/raw-loss = 0.5037355422973633, train/logprobs = tensor([[-1.0100, -2.1957],
        [-1.4107, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17065420746803284
Epoch 0, Step 236: train/loss = 0.5930230021476746, train/raw-loss = 0.5751192569732666, train/logprobs = tensor([[-0.7419, -1.6765],
        [-0.8380, -0.7508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17903707921504974
Epoch 0, Step 237: train/loss = 0.3809632658958435, train/raw-loss = 0.3604653477668762, train/logprobs = tensor([[-1.1108, -3.3551],
        [-1.3359, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20497925579547882
Epoch 0, Step 238: train/loss = 0.5352492332458496, train/raw-loss = 0.5115457773208618, train/logprobs = tensor([[-1.3539, -2.5204],
        [-1.6120, -1.7457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23703426122665405
Epoch 0, Step 239: train/loss = 0.4808885455131531, train/raw-loss = 0.46419456601142883, train/logprobs = tensor([[-0.7958, -2.4632],
        [-1.1223, -1.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16693952679634094
Epoch 0, Step 240: train/loss = 0.5061869025230408, train/raw-loss = 0.4914413094520569, train/logprobs = tensor([[-1.4845, -2.4069],
        [-1.7931, -1.3027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14745575189590454
Epoch 0, Step 241: train/loss = 0.44143834710121155, train/raw-loss = 0.4234045743942261, train/logprobs = tensor([[-0.9513, -2.7785],
        [-1.1712, -1.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18033774197101593
Epoch 0, Step 242: train/loss = 0.5211164951324463, train/raw-loss = 0.5015659928321838, train/logprobs = tensor([[-1.1738, -2.2730],
        [-1.7331, -1.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1955052614212036
Epoch 0, Step 243: train/loss = 0.40031731128692627, train/raw-loss = 0.38095664978027344, train/logprobs = tensor([[-1.7107, -3.6515],
        [-2.0664, -1.6204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19360674917697906
Epoch 0, Step 244: train/loss = 0.2845102548599243, train/raw-loss = 0.26236283779144287, train/logprobs = tensor([[-1.3059, -3.5702],
        [-1.9534, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22147388756275177
Epoch 0, Step 245: train/loss = 0.49936532974243164, train/raw-loss = 0.4810742139816284, train/logprobs = tensor([[-1.0436, -2.7605],
        [-1.4548, -1.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18291117250919342
Epoch 0, Step 246: train/loss = 0.5668624639511108, train/raw-loss = 0.5536161065101624, train/logprobs = tensor([[-0.5625, -1.6644],
        [-0.6131, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1324637532234192
Epoch 0, Step 247: train/loss = 0.4153769612312317, train/raw-loss = 0.3962233066558838, train/logprobs = tensor([[-0.8931, -2.6541],
        [-1.2785, -0.8106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19153662025928497
Epoch 0, Step 248: train/loss = 0.5293150544166565, train/raw-loss = 0.5112834572792053, train/logprobs = tensor([[-1.1170, -3.1895],
        [-1.4237, -2.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18031570315361023
Epoch 0, Step 249: train/loss = 0.48371076583862305, train/raw-loss = 0.4675467610359192, train/logprobs = tensor([[-0.5487, -2.9191],
        [-0.6187, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1616401970386505
Epoch 0, Step 250: train/loss = 0.5391340851783752, train/raw-loss = 0.522956132888794, train/logprobs = tensor([[-1.1491, -2.9461],
        [-0.9996, -1.4987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16177985072135925
Epoch 0, Step 251: train/loss = 0.5922815799713135, train/raw-loss = 0.5708467960357666, train/logprobs = tensor([[-1.6650, -1.8920],
        [-2.1530, -1.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2143486887216568
Epoch 0, Step 252: train/loss = 0.6291881799697876, train/raw-loss = 0.6097315549850464, train/logprobs = tensor([[-1.2895, -2.0765],
        [-1.3919, -1.7898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1945665329694748
Epoch 0, Step 253: train/loss = 0.38876572251319885, train/raw-loss = 0.36805596947669983, train/logprobs = tensor([[-0.7178, -3.0716],
        [-0.9875, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2070976048707962
Epoch 0, Step 254: train/loss = 0.5946390628814697, train/raw-loss = 0.5779876112937927, train/logprobs = tensor([[-2.4362, -2.3488],
        [-2.5736, -1.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16651467978954315
Epoch 0, Step 255: train/loss = 0.34392353892326355, train/raw-loss = 0.32230132818222046, train/logprobs = tensor([[-1.1473, -3.2960],
        [-1.4254, -1.1535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21622182428836823
Epoch 0, Step 256: train/loss = 0.5993809700012207, train/raw-loss = 0.576378583908081, train/logprobs = tensor([[-1.8659, -2.3346],
        [-1.6832, -0.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23002421855926514
Epoch 0, Step 257: train/loss = 0.35212379693984985, train/raw-loss = 0.3332218527793884, train/logprobs = tensor([[-0.8351, -4.0137],
        [-0.9236, -1.3606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18901938199996948
Epoch 0, Step 258: train/loss = 0.5010370016098022, train/raw-loss = 0.4807684123516083, train/logprobs = tensor([[-1.6732, -2.4084],
        [-1.9161, -1.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2026858627796173
Epoch 0, Step 259: train/loss = 0.37408044934272766, train/raw-loss = 0.35502761602401733, train/logprobs = tensor([[-1.1561, -2.8065],
        [-1.7176, -0.7363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1905285269021988
Epoch 0, Step 260: train/loss = 0.420987606048584, train/raw-loss = 0.3961765468120575, train/logprobs = tensor([[-1.8628, -3.3058],
        [-2.2002, -2.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24811051785945892
Epoch 0, Step 261: train/loss = 0.6074391007423401, train/raw-loss = 0.5895248651504517, train/logprobs = tensor([[-1.2180, -1.4592],
        [-1.6256, -1.3810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17914235591888428
Epoch 0, Step 262: train/loss = 0.4113371670246124, train/raw-loss = 0.3892671763896942, train/logprobs = tensor([[-0.8512, -3.3280],
        [-1.0969, -1.2701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22069980204105377
Epoch 0, Step 263: train/loss = 0.6761484742164612, train/raw-loss = 0.659709632396698, train/logprobs = tensor([[-0.6419, -0.6845],
        [-0.7688, -0.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1643880307674408
Epoch 0, Step 264: train/loss = 0.5263733863830566, train/raw-loss = 0.5075645446777344, train/logprobs = tensor([[-1.0277, -1.6794],
        [-1.2382, -0.8100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1880880892276764
Epoch 0, Step 265: train/loss = 0.5387051105499268, train/raw-loss = 0.5167845487594604, train/logprobs = tensor([[-1.0950, -2.6643],
        [-1.2600, -1.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21920563280582428
Epoch 0, Step 266: train/loss = 0.6260102987289429, train/raw-loss = 0.6097003221511841, train/logprobs = tensor([[-1.2882, -1.2993],
        [-1.4875, -1.0948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1630997657775879
Epoch 0, Step 267: train/loss = 0.36938777565956116, train/raw-loss = 0.3489410877227783, train/logprobs = tensor([[-1.0759, -3.3401],
        [-1.4138, -0.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2044672667980194
Epoch 0, Step 268: train/loss = 0.5905356407165527, train/raw-loss = 0.5711747407913208, train/logprobs = tensor([[-1.2470, -2.3264],
        [-1.4610, -1.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1936093121767044
Epoch 0, Step 269: train/loss = 0.5077714920043945, train/raw-loss = 0.4816737174987793, train/logprobs = tensor([[-1.6205, -3.1840],
        [-1.4905, -1.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609778940677643
Epoch 0, Step 270: train/loss = 0.4680677056312561, train/raw-loss = 0.4455313980579376, train/logprobs = tensor([[-1.1345, -2.2879],
        [-1.3729, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22536338865756989
Epoch 0, Step 271: train/loss = 0.3975967764854431, train/raw-loss = 0.3790662884712219, train/logprobs = tensor([[-0.9264, -3.6114],
        [-1.0234, -1.0782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18530459702014923
Epoch 0, Step 272: train/loss = 0.5179067850112915, train/raw-loss = 0.4955151677131653, train/logprobs = tensor([[-1.4459, -1.5903],
        [-1.8740, -0.9744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22391600906848907
Epoch 0, Step 273: train/loss = 0.6257634162902832, train/raw-loss = 0.6022495627403259, train/logprobs = tensor([[-1.7401, -2.1944],
        [-1.9135, -1.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23513907194137573
Epoch 0, Step 274: train/loss = 0.42810624837875366, train/raw-loss = 0.4065627157688141, train/logprobs = tensor([[-0.8352, -3.1079],
        [-1.1431, -1.1819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21543556451797485
Epoch 0, Step 275: train/loss = 0.42520996928215027, train/raw-loss = 0.4029303789138794, train/logprobs = tensor([[-0.9969, -2.4923],
        [-1.5911, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22279581427574158
Epoch 0, Step 276: train/loss = 0.560188889503479, train/raw-loss = 0.5407999753952026, train/logprobs = tensor([[-1.4335, -1.4132],
        [-1.7197, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19388970732688904
Epoch 0, Step 277: train/loss = 0.40595003962516785, train/raw-loss = 0.3836052417755127, train/logprobs = tensor([[-1.2090, -2.6320],
        [-1.6344, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22344785928726196
Epoch 0, Step 278: train/loss = 0.41366538405418396, train/raw-loss = 0.3929756283760071, train/logprobs = tensor([[-0.7640, -2.7987],
        [-1.0778, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2068973034620285
Epoch 0, Step 279: train/loss = 0.4743592143058777, train/raw-loss = 0.454190194606781, train/logprobs = tensor([[-1.6535, -2.2128],
        [-2.0373, -0.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20169004797935486
Epoch 0, Step 280: train/loss = 0.5272685885429382, train/raw-loss = 0.5068292617797852, train/logprobs = tensor([[-1.1573, -2.4309],
        [-1.3391, -0.9238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2043933868408203
Epoch 0, Step 281: train/loss = 0.3876182734966278, train/raw-loss = 0.3663267493247986, train/logprobs = tensor([[-1.9005, -3.4409],
        [-2.6792, -2.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21291550993919373
Epoch 0, Step 282: train/loss = 0.6538048982620239, train/raw-loss = 0.636579692363739, train/logprobs = tensor([[-1.5199, -2.4463],
        [-1.2979, -1.8538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.172252357006073
Epoch 0, Step 283: train/loss = 0.38428473472595215, train/raw-loss = 0.36052584648132324, train/logprobs = tensor([[-0.8422, -3.6425],
        [-1.2960, -1.5617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2375887632369995
Epoch 0, Step 284: train/loss = 0.40871280431747437, train/raw-loss = 0.38460856676101685, train/logprobs = tensor([[-1.3395, -3.7759],
        [-1.7122, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24104243516921997
Epoch 0, Step 285: train/loss = 0.5118653178215027, train/raw-loss = 0.48894670605659485, train/logprobs = tensor([[-1.5501, -2.5440],
        [-1.5455, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22918640077114105
Epoch 0, Step 286: train/loss = 0.46320605278015137, train/raw-loss = 0.44005507230758667, train/logprobs = tensor([[-1.0062, -3.7433],
        [-1.2598, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23151007294654846
Epoch 0, Step 287: train/loss = 0.3936815559864044, train/raw-loss = 0.3712301254272461, train/logprobs = tensor([[-1.1909, -3.1378],
        [-1.5328, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2245146483182907
Epoch 0, Step 288: train/loss = 0.3755643367767334, train/raw-loss = 0.3575229346752167, train/logprobs = tensor([[-1.0236, -3.8014],
        [-1.4380, -1.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1804136335849762
Epoch 0, Step 289: train/loss = 0.5488527417182922, train/raw-loss = 0.529894232749939, train/logprobs = tensor([[-1.0750, -2.1757],
        [-1.3995, -1.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18958470225334167
Epoch 0, Step 290: train/loss = 0.37204498052597046, train/raw-loss = 0.3504960238933563, train/logprobs = tensor([[-1.1424, -4.1642],
        [-1.3000, -1.4975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21548980474472046
Epoch 0, Step 291: train/loss = 0.3021059036254883, train/raw-loss = 0.27571380138397217, train/logprobs = tensor([[-2.4815, -5.1297],
        [-2.7603, -1.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2639209032058716
Epoch 0, Step 292: train/loss = 0.45716869831085205, train/raw-loss = 0.4343494176864624, train/logprobs = tensor([[-1.1119, -3.1008],
        [-1.5149, -1.3286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2281927764415741
Epoch 0, Step 293: train/loss = 0.5001592636108398, train/raw-loss = 0.47401490807533264, train/logprobs = tensor([[-0.9644, -2.7449],
        [-1.0610, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26144394278526306
Epoch 0, Step 294: train/loss = 0.4745127260684967, train/raw-loss = 0.4517977237701416, train/logprobs = tensor([[-2.0421, -3.1407],
        [-2.4061, -2.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22714976966381073
Epoch 0, Step 295: train/loss = 0.4304412603378296, train/raw-loss = 0.407127320766449, train/logprobs = tensor([[-1.0855, -2.7847],
        [-1.6699, -1.2343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2331392765045166
Epoch 0, Step 296: train/loss = 0.5776532888412476, train/raw-loss = 0.5532301664352417, train/logprobs = tensor([[-2.4066, -2.3481],
        [-2.3301, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24423100054264069
Epoch 0, Step 297: train/loss = 0.42825597524642944, train/raw-loss = 0.40813156962394714, train/logprobs = tensor([[-1.1890, -3.3404],
        [-1.5221, -1.6297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2012445330619812
Epoch 0, Step 298: train/loss = 0.5391355752944946, train/raw-loss = 0.5201875567436218, train/logprobs = tensor([[-1.1040, -2.0835],
        [-1.4437, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18947955965995789
Epoch 0, Step 299: train/loss = 0.5386760830879211, train/raw-loss = 0.5159193277359009, train/logprobs = tensor([[-1.6002, -2.6387],
        [-1.7391, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2275678515434265
Epoch 0, Step 300: train/loss = 0.47275876998901367, train/raw-loss = 0.45133063197135925, train/logprobs = tensor([[-1.5800, -3.6990],
        [-1.8713, -1.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21428129076957703
Epoch 0, Step 301: train/loss = 0.49464499950408936, train/raw-loss = 0.4747800827026367, train/logprobs = tensor([[-1.4548, -2.8078],
        [-1.8041, -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19864965975284576
Epoch 0, Step 302: train/loss = 0.45846328139305115, train/raw-loss = 0.43867552280426025, train/logprobs = tensor([[-1.4780, -3.3186],
        [-1.8517, -1.4725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1978776752948761
Epoch 0, Step 303: train/loss = 0.4941386878490448, train/raw-loss = 0.47005632519721985, train/logprobs = tensor([[-1.8321, -2.8813],
        [-1.9882, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24082356691360474
Epoch 0, Step 304: train/loss = 0.4315791428089142, train/raw-loss = 0.41046229004859924, train/logprobs = tensor([[-1.2409, -2.4780],
        [-1.7987, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2111685872077942
Epoch 0, Step 305: train/loss = 0.4392637014389038, train/raw-loss = 0.4162677228450775, train/logprobs = tensor([[-1.6327, -4.2799],
        [-1.7650, -1.2655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2299598604440689
Epoch 0, Step 306: train/loss = 0.4310283362865448, train/raw-loss = 0.40841788053512573, train/logprobs = tensor([[-1.4307, -2.7229],
        [-1.9931, -1.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2261042594909668
Epoch 0, Step 307: train/loss = 0.4756960868835449, train/raw-loss = 0.45527297258377075, train/logprobs = tensor([[-0.7523, -2.8208],
        [-0.9593, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20423106849193573
Epoch 0, Step 308: train/loss = 0.4682548940181732, train/raw-loss = 0.450481653213501, train/logprobs = tensor([[-1.2455, -2.6617],
        [-1.6206, -1.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.177732452750206
Epoch 0, Step 309: train/loss = 0.576058030128479, train/raw-loss = 0.5576974749565125, train/logprobs = tensor([[-1.5926, -1.6354],
        [-2.0276, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1836058795452118
Epoch 0, Step 310: train/loss = 0.4190215766429901, train/raw-loss = 0.39566075801849365, train/logprobs = tensor([[-0.8067, -3.8136],
        [-1.0218, -1.3405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.233608216047287
Epoch 0, Step 311: train/loss = 0.705074667930603, train/raw-loss = 0.6898078918457031, train/logprobs = tensor([[-1.7306, -1.1436],
        [-1.6575, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15266743302345276
Epoch 0, Step 312: train/loss = 0.4871543049812317, train/raw-loss = 0.46879687905311584, train/logprobs = tensor([[-1.6539, -2.9152],
        [-2.0666, -1.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18357393145561218
Epoch 0, Step 313: train/loss = 0.4605821967124939, train/raw-loss = 0.4384438395500183, train/logprobs = tensor([[-1.5592, -2.8361],
        [-1.7699, -1.2650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213837057352066
Epoch 0, Step 314: train/loss = 0.45145389437675476, train/raw-loss = 0.4273686408996582, train/logprobs = tensor([[-1.3341, -3.6946],
        [-1.5845, -1.0803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2408524751663208
Epoch 0, Step 315: train/loss = 0.5227446556091309, train/raw-loss = 0.4989919364452362, train/logprobs = tensor([[-2.1763, -1.2975],
        [-2.8073, -0.9665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23752734065055847
Epoch 0, Step 316: train/loss = 0.7014004588127136, train/raw-loss = 0.6796904802322388, train/logprobs = tensor([[-2.8087, -3.0855],
        [-2.3777, -2.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21709981560707092
Epoch 0, Step 317: train/loss = 0.5499356389045715, train/raw-loss = 0.5280930995941162, train/logprobs = tensor([[-1.4340, -1.8162],
        [-1.5387, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21842563152313232
Epoch 0, Step 318: train/loss = 0.42145320773124695, train/raw-loss = 0.39537185430526733, train/logprobs = tensor([[-1.2928, -2.9721],
        [-1.5867, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26081332564353943
Epoch 0, Step 319: train/loss = 0.5411534905433655, train/raw-loss = 0.5245141386985779, train/logprobs = tensor([[-1.6275, -4.0876],
        [-1.7556, -2.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16639339923858643
Epoch 0, Step 320: train/loss = 0.5422031879425049, train/raw-loss = 0.5182192921638489, train/logprobs = tensor([[-1.6265, -3.2959],
        [-1.9407, -1.7599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23983898758888245
Epoch 0, Step 321: train/loss = 0.43291234970092773, train/raw-loss = 0.4121274948120117, train/logprobs = tensor([[-1.2819, -2.6894],
        [-1.8331, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2078484445810318
Epoch 0, Step 322: train/loss = 0.36414796113967896, train/raw-loss = 0.33770713210105896, train/logprobs = tensor([[-1.1705, -3.7763],
        [-1.7674, -1.2202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2644084095954895
Epoch 0, Step 323: train/loss = 0.635732889175415, train/raw-loss = 0.6175853610038757, train/logprobs = tensor([[-1.7626, -0.8569],
        [-2.1377, -0.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18147523701190948
Epoch 0, Step 324: train/loss = 0.45213890075683594, train/raw-loss = 0.4324492812156677, train/logprobs = tensor([[-1.7153, -3.3422],
        [-1.9022, -1.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19689607620239258
Epoch 0, Step 325: train/loss = 0.47172194719314575, train/raw-loss = 0.44581833481788635, train/logprobs = tensor([[-0.8989, -3.2301],
        [-1.3339, -1.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590363621711731
Epoch 0, Step 326: train/loss = 0.5867068767547607, train/raw-loss = 0.569641649723053, train/logprobs = tensor([[-2.4896, -3.9308],
        [-2.1907, -2.3804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17065280675888062
Epoch 0, Step 327: train/loss = 0.44955575466156006, train/raw-loss = 0.42535772919654846, train/logprobs = tensor([[-1.8555, -2.9893],
        [-2.0817, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24198001623153687
Epoch 0, Step 328: train/loss = 0.5936251878738403, train/raw-loss = 0.5744034647941589, train/logprobs = tensor([[-0.9741, -1.6559],
        [-1.2495, -1.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19221733510494232
Epoch 0, Step 329: train/loss = 0.4273577630519867, train/raw-loss = 0.4040077328681946, train/logprobs = tensor([[-0.8585, -2.7339],
        [-1.3155, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2335006594657898
Epoch 0, Step 330: train/loss = 0.3744277358055115, train/raw-loss = 0.3483043611049652, train/logprobs = tensor([[-0.8923, -4.5606],
        [-1.4416, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612336277961731
Epoch 0, Step 331: train/loss = 0.4891324043273926, train/raw-loss = 0.4691570997238159, train/logprobs = tensor([[-1.2930, -2.5109],
        [-1.6157, -1.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1997535079717636
Epoch 0, Step 332: train/loss = 0.3992445170879364, train/raw-loss = 0.3764822483062744, train/logprobs = tensor([[-0.8267, -2.7426],
        [-1.2958, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22762279212474823
Epoch 0, Step 333: train/loss = 0.32205939292907715, train/raw-loss = 0.2958320379257202, train/logprobs = tensor([[-1.1108, -4.3373],
        [-1.6172, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26227331161499023
Epoch 0, Step 334: train/loss = 0.5411311388015747, train/raw-loss = 0.5145806670188904, train/logprobs = tensor([[-1.3955, -2.4820],
        [-1.9263, -1.7434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26550522446632385
Epoch 0, Step 335: train/loss = 0.4846686124801636, train/raw-loss = 0.46026909351348877, train/logprobs = tensor([[-1.1848, -1.9339],
        [-1.7028, -0.6007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24399526417255402
Epoch 0, Step 336: train/loss = 0.4891900420188904, train/raw-loss = 0.4654558598995209, train/logprobs = tensor([[-1.8799, -2.7613],
        [-2.3300, -2.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23734188079833984
Epoch 0, Step 337: train/loss = 0.43314385414123535, train/raw-loss = 0.41060417890548706, train/logprobs = tensor([[-1.2850, -3.2844],
        [-1.8503, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253967523574829
Epoch 0, Step 338: train/loss = 0.36076802015304565, train/raw-loss = 0.3343800902366638, train/logprobs = tensor([[-0.9656, -4.2112],
        [-1.3863, -1.1608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2638794183731079
Epoch 0, Step 339: train/loss = 0.4197733700275421, train/raw-loss = 0.39861640334129333, train/logprobs = tensor([[-1.1845, -3.5921],
        [-1.6897, -1.3372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21156933903694153
Epoch 0, Step 340: train/loss = 0.5168176293373108, train/raw-loss = 0.49466168880462646, train/logprobs = tensor([[-1.5893, -2.4085],
        [-1.8197, -0.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215592861175537
Epoch 0, Step 341: train/loss = 0.35150623321533203, train/raw-loss = 0.3263247609138489, train/logprobs = tensor([[-1.1903, -4.5822],
        [-1.4364, -0.8795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518147826194763
Epoch 0, Step 342: train/loss = 0.345941960811615, train/raw-loss = 0.3216257393360138, train/logprobs = tensor([[-1.2769, -3.3826],
        [-1.7321, -1.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2431621253490448
Epoch 0, Step 343: train/loss = 0.3929372727870941, train/raw-loss = 0.36966848373413086, train/logprobs = tensor([[-1.2725, -3.5407],
        [-1.7726, -2.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2326875627040863
Epoch 0, Step 344: train/loss = 0.4553695619106293, train/raw-loss = 0.43120646476745605, train/logprobs = tensor([[-1.0253, -2.6111],
        [-1.4508, -1.3351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24163109064102173
Epoch 0, Step 345: train/loss = 0.4069225788116455, train/raw-loss = 0.3854255676269531, train/logprobs = tensor([[-1.0172, -3.1745],
        [-1.5967, -0.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21497024595737457
Epoch 0, Step 346: train/loss = 0.3404713571071625, train/raw-loss = 0.3168129324913025, train/logprobs = tensor([[-1.7205, -3.6757],
        [-2.4698, -1.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23658443987369537
Epoch 0, Step 347: train/loss = 0.6677590012550354, train/raw-loss = 0.6432577967643738, train/logprobs = tensor([[-2.1754, -2.9091],
        [-1.8839, -1.0619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24501217901706696
Epoch 0, Step 348: train/loss = 0.6215751767158508, train/raw-loss = 0.6003090739250183, train/logprobs = tensor([[-1.6267, -1.3377],
        [-1.9533, -1.2329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2126612365245819
Epoch 0, Step 349: train/loss = 0.3072434663772583, train/raw-loss = 0.283333420753479, train/logprobs = tensor([[-1.6796, -4.6267],
        [-2.2470, -1.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2391003966331482
Epoch 0, Step 350: train/loss = 0.662462055683136, train/raw-loss = 0.6413546800613403, train/logprobs = tensor([[-1.7668, -1.1842],
        [-2.0478, -1.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21107302606105804
Epoch 0, Step 351: train/loss = 0.4872835576534271, train/raw-loss = 0.46331679821014404, train/logprobs = tensor([[-1.3484, -3.1235],
        [-1.7718, -1.6254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2396675944328308
Epoch 0, Step 352: train/loss = 0.4223199784755707, train/raw-loss = 0.39424026012420654, train/logprobs = tensor([[-1.1980, -3.9324],
        [-1.8064, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28079742193222046
Epoch 0, Step 353: train/loss = 0.6103954315185547, train/raw-loss = 0.5858838558197021, train/logprobs = tensor([[-1.5378, -4.0237],
        [-1.3714, -1.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24511563777923584
Epoch 0, Step 354: train/loss = 0.5129188299179077, train/raw-loss = 0.4920162260532379, train/logprobs = tensor([[-1.4401, -3.7070],
        [-1.6171, -2.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2090257704257965
Epoch 0, Step 355: train/loss = 0.3483498692512512, train/raw-loss = 0.32717859745025635, train/logprobs = tensor([[-1.0416, -4.0365],
        [-1.5292, -1.9775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21171291172504425
Epoch 0, Step 356: train/loss = 0.516358494758606, train/raw-loss = 0.494573175907135, train/logprobs = tensor([[-1.2183, -2.4020],
        [-1.6165, -1.5466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2178535759449005
Epoch 0, Step 357: train/loss = 0.3527909815311432, train/raw-loss = 0.3299955129623413, train/logprobs = tensor([[-1.5504, -4.3368],
        [-2.3199, -1.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22795456647872925
Epoch 0, Step 358: train/loss = 0.44355788826942444, train/raw-loss = 0.4168308973312378, train/logprobs = tensor([[-0.9283, -3.1000],
        [-1.5984, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.267270028591156
Epoch 0, Step 359: train/loss = 0.5488096475601196, train/raw-loss = 0.5289932489395142, train/logprobs = tensor([[-1.7783, -4.3661],
        [-1.6236, -1.2942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1981634944677353
Epoch 0, Step 360: train/loss = 0.31142255663871765, train/raw-loss = 0.28762128949165344, train/logprobs = tensor([[-1.0146, -3.9254],
        [-1.6620, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23801244795322418
Epoch 0, Step 361: train/loss = 0.4225894510746002, train/raw-loss = 0.39824381470680237, train/logprobs = tensor([[-1.0113, -2.8165],
        [-1.7671, -1.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24345606565475464
Epoch 0, Step 362: train/loss = 0.46436744928359985, train/raw-loss = 0.4443833827972412, train/logprobs = tensor([[-0.5879, -3.4086],
        [-0.9489, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19984042644500732
Epoch 0, Step 363: train/loss = 0.31302690505981445, train/raw-loss = 0.2876206636428833, train/logprobs = tensor([[-1.2165, -4.6940],
        [-1.8800, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254062682390213
Epoch 0, Step 364: train/loss = 0.5649057030677795, train/raw-loss = 0.5407025814056396, train/logprobs = tensor([[-1.4742, -2.9697],
        [-1.6969, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24203146994113922
Epoch 0, Step 365: train/loss = 0.294513463973999, train/raw-loss = 0.26715517044067383, train/logprobs = tensor([[-1.1070, -4.9939],
        [-1.8304, -1.4001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27358278632164
Epoch 0, Step 366: train/loss = 0.41505903005599976, train/raw-loss = 0.3932461142539978, train/logprobs = tensor([[-1.0536, -3.6264],
        [-1.5592, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181289792060852
Epoch 0, Step 367: train/loss = 0.6981191635131836, train/raw-loss = 0.6800174713134766, train/logprobs = tensor([[-1.0028, -0.8490],
        [-1.2250, -0.9304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18101727962493896
Epoch 0, Step 368: train/loss = 0.38609030842781067, train/raw-loss = 0.3577740490436554, train/logprobs = tensor([[-1.2871, -3.6366],
        [-2.1664, -1.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28316253423690796
Epoch 0, Step 369: train/loss = 0.49520379304885864, train/raw-loss = 0.4713996350765228, train/logprobs = tensor([[-0.8958, -2.6428],
        [-1.4725, -1.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2380412220954895
Epoch 0, Step 370: train/loss = 0.3963242173194885, train/raw-loss = 0.37193167209625244, train/logprobs = tensor([[-1.0303, -4.1477],
        [-1.4394, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2439255565404892
Epoch 0, Step 371: train/loss = 0.47432470321655273, train/raw-loss = 0.45236462354660034, train/logprobs = tensor([[-1.1787, -2.6993],
        [-1.5058, -1.0211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21960091590881348
Epoch 0, Step 372: train/loss = 0.44866684079170227, train/raw-loss = 0.42530256509780884, train/logprobs = tensor([[-0.7970, -2.8570],
        [-1.3135, -1.2015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2336427867412567
Epoch 0, Step 373: train/loss = 0.5449316501617432, train/raw-loss = 0.520755410194397, train/logprobs = tensor([[-1.8206, -1.6537],
        [-2.6807, -1.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2417624592781067
Epoch 0, Step 374: train/loss = 0.413849800825119, train/raw-loss = 0.3904087543487549, train/logprobs = tensor([[-1.2772, -4.0832],
        [-1.7488, -1.1492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.234410360455513
Epoch 0, Step 375: train/loss = 0.4929562509059906, train/raw-loss = 0.46739429235458374, train/logprobs = tensor([[-1.2314, -2.8704],
        [-1.9342, -1.2689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2556197941303253
Epoch 0, Step 376: train/loss = 0.48146766424179077, train/raw-loss = 0.4583767056465149, train/logprobs = tensor([[-1.1923, -2.4067],
        [-1.7233, -1.0866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23090940713882446
Epoch 0, Step 377: train/loss = 0.3180764317512512, train/raw-loss = 0.29418179392814636, train/logprobs = tensor([[-0.8832, -4.2439],
        [-1.4551, -1.6512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23894619941711426
Epoch 0, Step 378: train/loss = 0.5550704002380371, train/raw-loss = 0.5326135754585266, train/logprobs = tensor([[-2.0460, -5.7614],
        [-1.8971, -2.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2245684266090393
Epoch 0, Step 379: train/loss = 0.4950956106185913, train/raw-loss = 0.47587549686431885, train/logprobs = tensor([[-1.5478, -2.0685],
        [-1.9124, -0.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19220101833343506
Epoch 0, Step 380: train/loss = 0.2816055119037628, train/raw-loss = 0.26048049330711365, train/logprobs = tensor([[-0.6070, -4.5018],
        [-1.0102, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21125003695487976
Epoch 0, Step 381: train/loss = 0.4676063656806946, train/raw-loss = 0.4447852373123169, train/logprobs = tensor([[-2.2717, -2.1703],
        [-2.7366, -1.3506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22821134328842163
Epoch 0, Step 382: train/loss = 0.5678654909133911, train/raw-loss = 0.5499517917633057, train/logprobs = tensor([[-0.7067, -1.6155],
        [-1.0486, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17913635075092316
Epoch 0, Step 383: train/loss = 0.4463571012020111, train/raw-loss = 0.424213707447052, train/logprobs = tensor([[-2.4419, -2.7608],
        [-2.9927, -1.8193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22143340110778809
Epoch 0, Step 384: train/loss = 0.4458710253238678, train/raw-loss = 0.4220840334892273, train/logprobs = tensor([[-1.2756, -4.2707],
        [-1.4779, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23787039518356323
Epoch 0, Step 385: train/loss = 0.2829245626926422, train/raw-loss = 0.2530917823314667, train/logprobs = tensor([[-1.3237, -4.1871],
        [-2.2134, -1.3715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29832786321640015
Epoch 0, Step 386: train/loss = 0.3943527042865753, train/raw-loss = 0.3673657178878784, train/logprobs = tensor([[-1.1260, -2.8976],
        [-1.8835, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26986971497535706
Epoch 0, Step 387: train/loss = 0.6017597317695618, train/raw-loss = 0.5734201073646545, train/logprobs = tensor([[-1.7030, -1.3298],
        [-2.0371, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2833961546421051
Epoch 0, Step 388: train/loss = 0.4970313310623169, train/raw-loss = 0.4721488058567047, train/logprobs = tensor([[-1.2898, -1.6160],
        [-2.2298, -1.2619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.248824805021286
Epoch 0, Step 389: train/loss = 0.4710531234741211, train/raw-loss = 0.4456159174442291, train/logprobs = tensor([[-1.2007, -2.1605],
        [-1.8496, -1.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2543718218803406
Epoch 0, Step 390: train/loss = 0.5621975660324097, train/raw-loss = 0.5422353148460388, train/logprobs = tensor([[-1.3512, -3.6664],
        [-1.4465, -1.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19962260127067566
Epoch 0, Step 391: train/loss = 0.4048771858215332, train/raw-loss = 0.37690412998199463, train/logprobs = tensor([[-2.0165, -2.9182],
        [-3.1038, -1.6725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27973052859306335
Epoch 0, Step 392: train/loss = 0.44781994819641113, train/raw-loss = 0.4293745756149292, train/logprobs = tensor([[-1.3500, -2.6064],
        [-2.2394, -2.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.184453547000885
Epoch 0, Step 393: train/loss = 0.3907400965690613, train/raw-loss = 0.3691464066505432, train/logprobs = tensor([[-1.3939, -2.6672],
        [-2.3150, -1.5358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21593689918518066
Epoch 0, Step 394: train/loss = 0.3660728931427002, train/raw-loss = 0.33927905559539795, train/logprobs = tensor([[-1.7557, -2.8758],
        [-2.9493, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2679380178451538
Epoch 0, Step 395: train/loss = 0.5979348421096802, train/raw-loss = 0.573576033115387, train/logprobs = tensor([[-1.0161, -1.5908],
        [-1.5035, -1.5188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24358829855918884
Epoch 0, Step 396: train/loss = 0.37509408593177795, train/raw-loss = 0.3531641364097595, train/logprobs = tensor([[-1.0454, -4.3649],
        [-1.4078, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21929985284805298
Epoch 0, Step 397: train/loss = 0.4889613091945648, train/raw-loss = 0.46358513832092285, train/logprobs = tensor([[-1.1967, -2.5426],
        [-1.9253, -1.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2537615895271301
Epoch 0, Step 398: train/loss = 0.3912278115749359, train/raw-loss = 0.36771073937416077, train/logprobs = tensor([[-0.6780, -5.0127],
        [-0.9118, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23517070710659027
Epoch 0, Step 399: train/loss = 0.3368741273880005, train/raw-loss = 0.31555646657943726, train/logprobs = tensor([[-1.4789, -4.2218],
        [-2.0378, -1.5502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21317678689956665
Epoch 0, Step 400: train/loss = 0.360359251499176, train/raw-loss = 0.3382070064544678, train/logprobs = tensor([[-0.7971, -3.8189],
        [-1.2854, -1.1931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215224653482437
Epoch 0, Step 401: train/loss = 0.5298820734024048, train/raw-loss = 0.5105290412902832, train/logprobs = tensor([[-0.9711, -2.3200],
        [-1.3802, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19353008270263672
Epoch 0, Step 402: train/loss = 0.5556741952896118, train/raw-loss = 0.5374689102172852, train/logprobs = tensor([[-1.2159, -0.9561],
        [-1.9306, -0.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18205229938030243
Epoch 0, Step 403: train/loss = 0.6987209320068359, train/raw-loss = 0.6755253672599792, train/logprobs = tensor([[-1.1326, -0.9164],
        [-1.4481, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2319551706314087
Epoch 0, Step 404: train/loss = 0.46579569578170776, train/raw-loss = 0.4385375678539276, train/logprobs = tensor([[-1.5950, -4.1820],
        [-2.3605, -2.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725812494754791
Epoch 0, Step 405: train/loss = 0.29239311814308167, train/raw-loss = 0.2642686069011688, train/logprobs = tensor([[-1.7276, -2.8921],
        [-2.8907, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28124475479125977
Epoch 0, Step 406: train/loss = 0.48238202929496765, train/raw-loss = 0.45980459451675415, train/logprobs = tensor([[-2.0415, -4.3829],
        [-2.5217, -2.6860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22577433288097382
Epoch 0, Step 407: train/loss = 0.4781321883201599, train/raw-loss = 0.45847374200820923, train/logprobs = tensor([[-0.9374, -2.2652],
        [-1.5349, -1.2719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19658437371253967
Epoch 0, Step 408: train/loss = 0.3959665298461914, train/raw-loss = 0.36799871921539307, train/logprobs = tensor([[-1.3534, -3.2274],
        [-2.3022, -1.4058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2796780467033386
Epoch 0, Step 409: train/loss = 0.4364888370037079, train/raw-loss = 0.41080376505851746, train/logprobs = tensor([[-0.9495, -3.1444],
        [-1.7187, -1.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2568506896495819
Epoch 0, Step 410: train/loss = 0.44425326585769653, train/raw-loss = 0.4216572642326355, train/logprobs = tensor([[-1.6429, -4.8000],
        [-1.9137, -3.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259598672389984
Epoch 0, Step 411: train/loss = 0.2765674889087677, train/raw-loss = 0.24721334874629974, train/logprobs = tensor([[-1.5689, -5.4757],
        [-2.1431, -1.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29354116320610046
Epoch 0, Step 412: train/loss = 0.3044702708721161, train/raw-loss = 0.27645644545555115, train/logprobs = tensor([[-1.8438, -2.6026],
        [-3.3129, -1.3759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2801382839679718
Epoch 0, Step 413: train/loss = 0.4053281843662262, train/raw-loss = 0.37930721044540405, train/logprobs = tensor([[-1.6699, -3.4890],
        [-2.5200, -1.4931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26020950078964233
Epoch 0, Step 414: train/loss = 0.3573242723941803, train/raw-loss = 0.33052393794059753, train/logprobs = tensor([[-0.8364, -4.1884],
        [-1.4793, -1.2706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2680031955242157
Epoch 0, Step 415: train/loss = 0.4009133279323578, train/raw-loss = 0.3730224370956421, train/logprobs = tensor([[-2.5225, -4.0643],
        [-3.0143, -1.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.278909295797348
Epoch 0, Step 416: train/loss = 0.31595802307128906, train/raw-loss = 0.2891695201396942, train/logprobs = tensor([[-1.2289, -3.9119],
        [-2.2810, -0.7656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26788532733917236
Epoch 0, Step 417: train/loss = 0.6038082838058472, train/raw-loss = 0.5824251770973206, train/logprobs = tensor([[-1.4229, -0.7469],
        [-2.0289, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2138305902481079
Epoch 0, Step 418: train/loss = 0.4843599200248718, train/raw-loss = 0.4597545266151428, train/logprobs = tensor([[-0.7462, -2.4764],
        [-1.5883, -0.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2460542768239975
Epoch 0, Step 419: train/loss = 0.4335384964942932, train/raw-loss = 0.4079681634902954, train/logprobs = tensor([[-1.3177, -3.0139],
        [-2.0588, -2.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2557029724121094
Epoch 0, Step 420: train/loss = 0.2961694598197937, train/raw-loss = 0.2707911729812622, train/logprobs = tensor([[-1.7412, -2.2898],
        [-3.2822, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25378310680389404
Epoch 0, Step 421: train/loss = 0.2921674847602844, train/raw-loss = 0.26802200078964233, train/logprobs = tensor([[-0.8644, -3.6199],
        [-1.5469, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414548546075821
Epoch 0, Step 422: train/loss = 0.5529230237007141, train/raw-loss = 0.5252171158790588, train/logprobs = tensor([[-3.1263, -5.3028],
        [-2.5961, -1.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770588994026184
Epoch 0, Step 423: train/loss = 0.3817584812641144, train/raw-loss = 0.35495081543922424, train/logprobs = tensor([[-1.6429, -2.0570],
        [-2.6932, -0.7792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2680765986442566
Epoch 0, Step 424: train/loss = 0.5167426466941833, train/raw-loss = 0.4917011857032776, train/logprobs = tensor([[-2.0488, -4.4487],
        [-1.9090, -2.4646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25041455030441284
Epoch 0, Step 425: train/loss = 0.36780846118927, train/raw-loss = 0.34408465027809143, train/logprobs = tensor([[-1.2819, -3.1381],
        [-2.1426, -1.3704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2372380793094635
Epoch 0, Step 426: train/loss = 0.608329176902771, train/raw-loss = 0.5844531059265137, train/logprobs = tensor([[-1.8361, -3.1124],
        [-1.9060, -1.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23876070976257324
Epoch 0, Step 427: train/loss = 0.4758683443069458, train/raw-loss = 0.44656985998153687, train/logprobs = tensor([[-1.0445, -2.7003],
        [-1.6657, -1.6036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2929847836494446
Epoch 0, Step 428: train/loss = 0.27370399236679077, train/raw-loss = 0.24729473888874054, train/logprobs = tensor([[-0.7755, -4.7590],
        [-1.5729, -0.8325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640925347805023
Epoch 0, Step 429: train/loss = 0.28755253553390503, train/raw-loss = 0.25844258069992065, train/logprobs = tensor([[-1.1084, -4.9509],
        [-1.9771, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.291099488735199
Epoch 0, Step 430: train/loss = 0.3351742923259735, train/raw-loss = 0.3044377863407135, train/logprobs = tensor([[-0.7506, -6.4190],
        [-1.2794, -1.3005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073652982711792
Epoch 0, Step 431: train/loss = 0.24223007261753082, train/raw-loss = 0.2146872729063034, train/logprobs = tensor([[-1.5046, -4.4443],
        [-2.4733, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27542799711227417
Epoch 0, Step 432: train/loss = 0.5469001531600952, train/raw-loss = 0.5212768912315369, train/logprobs = tensor([[-0.9942, -1.7889],
        [-1.5671, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.256232351064682
Epoch 0, Step 433: train/loss = 0.33136266469955444, train/raw-loss = 0.29875850677490234, train/logprobs = tensor([[-1.1497, -3.5055],
        [-2.1472, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.326041579246521
Epoch 0, Step 434: train/loss = 0.24176622927188873, train/raw-loss = 0.2164667546749115, train/logprobs = tensor([[-1.3274, -4.3350],
        [-2.5291, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529948651790619
Epoch 0, Step 435: train/loss = 0.4283132255077362, train/raw-loss = 0.40267103910446167, train/logprobs = tensor([[-1.3067, -3.4596],
        [-1.9190, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564217150211334
Epoch 0, Step 436: train/loss = 0.45796602964401245, train/raw-loss = 0.42904552817344666, train/logprobs = tensor([[-1.1043, -2.5309],
        [-2.0670, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2892051637172699
Epoch 0, Step 437: train/loss = 0.35573577880859375, train/raw-loss = 0.32949820160865784, train/logprobs = tensor([[-1.1422, -3.8878],
        [-1.7423, -1.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26237568259239197
Epoch 0, Step 438: train/loss = 0.503493070602417, train/raw-loss = 0.4793291687965393, train/logprobs = tensor([[-2.1220, -3.3083],
        [-2.3026, -1.2173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24163903295993805
Epoch 0, Step 439: train/loss = 0.6276862621307373, train/raw-loss = 0.6027731895446777, train/logprobs = tensor([[-1.2141, -1.2597],
        [-2.4297, -1.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24913063645362854
Epoch 0, Step 440: train/loss = 0.6124867796897888, train/raw-loss = 0.5888542532920837, train/logprobs = tensor([[-2.0084, -3.5256],
        [-2.1776, -2.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23632526397705078
Epoch 0, Step 441: train/loss = 0.3746638894081116, train/raw-loss = 0.3440590798854828, train/logprobs = tensor([[-1.4532, -3.0108],
        [-2.4755, -2.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3060479462146759
Epoch 0, Step 442: train/loss = 0.498211145401001, train/raw-loss = 0.47438931465148926, train/logprobs = tensor([[-1.3609, -2.6196],
        [-2.1772, -2.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2382185459136963
Epoch 0, Step 443: train/loss = 0.4585251808166504, train/raw-loss = 0.42940253019332886, train/logprobs = tensor([[-1.3867, -1.9050],
        [-3.2364, -1.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2912263572216034
Epoch 0, Step 444: train/loss = 0.5561406016349792, train/raw-loss = 0.5290274024009705, train/logprobs = tensor([[-1.1432, -2.9491],
        [-1.6471, -1.4747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2711319327354431
Epoch 0, Step 445: train/loss = 0.4115283787250519, train/raw-loss = 0.38503211736679077, train/logprobs = tensor([[-1.1178, -3.5524],
        [-1.9080, -1.9359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26496267318725586
Epoch 0, Step 446: train/loss = 0.4727005660533905, train/raw-loss = 0.4466767907142639, train/logprobs = tensor([[-0.7187, -4.1200],
        [-1.2021, -1.0738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26023781299591064
Epoch 0, Step 447: train/loss = 0.609200119972229, train/raw-loss = 0.5849605798721313, train/logprobs = tensor([[-3.0427, -3.5202],
        [-3.0395, -2.8131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2423953413963318
Epoch 0, Step 448: train/loss = 0.3384689688682556, train/raw-loss = 0.31059738993644714, train/logprobs = tensor([[-1.6102, -3.4243],
        [-2.7729, -0.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2787155508995056
Epoch 0, Step 449: train/loss = 0.4103162884712219, train/raw-loss = 0.38738471269607544, train/logprobs = tensor([[-0.9432, -4.1152],
        [-1.1467, -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22931581735610962
Epoch 0, Step 450: train/loss = 0.536254346370697, train/raw-loss = 0.5088242292404175, train/logprobs = tensor([[-1.9713, -4.6764],
        [-2.1467, -2.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2743014693260193
Epoch 0, Step 451: train/loss = 0.3784586191177368, train/raw-loss = 0.3495251536369324, train/logprobs = tensor([[-1.6740, -3.6319],
        [-2.3765, -1.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2893346846103668
Epoch 0, Step 452: train/loss = 0.24804773926734924, train/raw-loss = 0.21618907153606415, train/logprobs = tensor([[-1.7290, -4.9626],
        [-3.3203, -1.2525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31858697533607483
Epoch 0, Step 453: train/loss = 0.4120447635650635, train/raw-loss = 0.3814048171043396, train/logprobs = tensor([[-1.6121, -5.1408],
        [-2.1952, -2.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30639955401420593
Epoch 0, Step 454: train/loss = 0.5073139667510986, train/raw-loss = 0.4778614640235901, train/logprobs = tensor([[-0.7317, -4.0143],
        [-1.3241, -1.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29452499747276306
Epoch 0, Step 455: train/loss = 0.4265754818916321, train/raw-loss = 0.39689043164253235, train/logprobs = tensor([[-2.6524, -3.5183],
        [-3.0548, -1.6909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2968505620956421
Epoch 0, Step 456: train/loss = 0.47854119539260864, train/raw-loss = 0.45248574018478394, train/logprobs = tensor([[-1.0101, -2.4056],
        [-1.9113, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26055407524108887
Epoch 0, Step 457: train/loss = 0.3879510462284088, train/raw-loss = 0.3592868149280548, train/logprobs = tensor([[-0.6968, -4.3790],
        [-1.2898, -1.0265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866421937942505
Epoch 0, Step 458: train/loss = 0.24710741639137268, train/raw-loss = 0.2129071056842804, train/logprobs = tensor([[-1.1431, -6.0016],
        [-1.8853, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.342002809047699
Epoch 0, Step 459: train/loss = 0.5485283136367798, train/raw-loss = 0.5172021389007568, train/logprobs = tensor([[-1.7638, -2.2087],
        [-2.2809, -1.5353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3132612705230713
Epoch 0, Step 460: train/loss = 0.43219783902168274, train/raw-loss = 0.4109240174293518, train/logprobs = tensor([[-0.9303, -4.1185],
        [-1.2419, -2.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21273845434188843
Epoch 0, Step 461: train/loss = 0.35578247904777527, train/raw-loss = 0.3292429447174072, train/logprobs = tensor([[-1.3278, -2.3588],
        [-2.6486, -1.0798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2653951644897461
Epoch 0, Step 462: train/loss = 0.40511393547058105, train/raw-loss = 0.3786540627479553, train/logprobs = tensor([[-2.3009, -4.6420],
        [-2.8739, -1.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2645987868309021
Epoch 0, Step 463: train/loss = 0.34358131885528564, train/raw-loss = 0.31738191843032837, train/logprobs = tensor([[-0.8654, -5.0959],
        [-1.4463, -2.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2619938254356384
Epoch 0, Step 464: train/loss = 0.3564273715019226, train/raw-loss = 0.33073827624320984, train/logprobs = tensor([[-1.7050, -1.9973],
        [-2.9406, -1.2233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25689083337783813
Epoch 0, Step 465: train/loss = 0.33172711730003357, train/raw-loss = 0.2996865510940552, train/logprobs = tensor([[-1.0910, -5.0126],
        [-1.6621, -0.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32040563225746155
Epoch 0, Step 466: train/loss = 0.2205953598022461, train/raw-loss = 0.19062569737434387, train/logprobs = tensor([[-1.5416, -4.8753],
        [-2.7243, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29969680309295654
Epoch 0, Step 467: train/loss = 0.28269216418266296, train/raw-loss = 0.25320109724998474, train/logprobs = tensor([[-2.1112, -2.9868],
        [-3.8212, -1.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29491063952445984
Epoch 0, Step 468: train/loss = 0.5631227493286133, train/raw-loss = 0.5332661271095276, train/logprobs = tensor([[-1.0240, -1.4244],
        [-1.9215, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29856598377227783
Epoch 0, Step 469: train/loss = 0.37598538398742676, train/raw-loss = 0.34912678599357605, train/logprobs = tensor([[-1.9828, -2.6105],
        [-2.9737, -1.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26858633756637573
Epoch 0, Step 470: train/loss = 0.3433380126953125, train/raw-loss = 0.31674012541770935, train/logprobs = tensor([[-1.4780, -3.1192],
        [-2.3887, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2659788131713867
Epoch 0, Step 471: train/loss = 0.15998032689094543, train/raw-loss = 0.12832489609718323, train/logprobs = tensor([[-1.2993, -6.2797],
        [-2.5853, -1.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31655433773994446
Epoch 0, Step 472: train/loss = 0.4742031693458557, train/raw-loss = 0.4479752779006958, train/logprobs = tensor([[-1.5620, -2.8955],
        [-2.5840, -1.5079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26227885484695435
Epoch 0, Step 473: train/loss = 0.3586982786655426, train/raw-loss = 0.3285037875175476, train/logprobs = tensor([[-0.9435, -4.4654],
        [-1.7799, -1.1062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3019447326660156
Epoch 0, Step 474: train/loss = 0.3184768259525299, train/raw-loss = 0.29241523146629333, train/logprobs = tensor([[-0.9961, -3.0314],
        [-2.2312, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2606157958507538
Epoch 0, Step 475: train/loss = 0.39420387148857117, train/raw-loss = 0.36656299233436584, train/logprobs = tensor([[-1.5717, -2.4995],
        [-2.8942, -1.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27640867233276367
Epoch 0, Step 476: train/loss = 0.3944757282733917, train/raw-loss = 0.3663112223148346, train/logprobs = tensor([[-1.3081, -3.2326],
        [-2.1383, -1.4652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2816452383995056
Epoch 0, Step 477: train/loss = 0.4352648854255676, train/raw-loss = 0.40885913372039795, train/logprobs = tensor([[-0.8374, -3.4308],
        [-1.4795, -1.3990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2640572190284729
Epoch 0, Step 478: train/loss = 0.3960486650466919, train/raw-loss = 0.3680182099342346, train/logprobs = tensor([[-1.4237, -2.6820],
        [-2.8050, -1.1339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.280304491519928
Epoch 0, Step 479: train/loss = 0.3231842815876007, train/raw-loss = 0.2899196445941925, train/logprobs = tensor([[-0.8559, -4.6340],
        [-1.7657, -1.6025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33264634013175964
Epoch 0, Step 480: train/loss = 0.5593889951705933, train/raw-loss = 0.5293046236038208, train/logprobs = tensor([[-1.9097, -3.4912],
        [-2.3236, -1.6974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3008438050746918
Epoch 0, Step 481: train/loss = 0.5014969706535339, train/raw-loss = 0.4743649661540985, train/logprobs = tensor([[-0.8023, -2.9020],
        [-1.1441, -1.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2713199555873871
Epoch 0, Step 482: train/loss = 0.33983731269836426, train/raw-loss = 0.3053656220436096, train/logprobs = tensor([[-1.1200, -2.9352],
        [-2.2219, -0.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34471696615219116
Epoch 0, Step 483: train/loss = 0.23104625940322876, train/raw-loss = 0.20236393809318542, train/logprobs = tensor([[-1.1984, -3.5458],
        [-2.6588, -0.6841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2868232727050781
Epoch 0, Step 484: train/loss = 0.1432744860649109, train/raw-loss = 0.1088552176952362, train/logprobs = tensor([[-1.9347, -6.3459],
        [-3.6444, -1.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441928029060364
Epoch 0, Step 485: train/loss = 0.36240148544311523, train/raw-loss = 0.330943763256073, train/logprobs = tensor([[-1.7159, -3.1976],
        [-3.0250, -1.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31457728147506714
Epoch 0, Step 486: train/loss = 0.33168497681617737, train/raw-loss = 0.30109500885009766, train/logprobs = tensor([[-1.4259, -4.2250],
        [-2.2641, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3058999478816986
Epoch 0, Step 487: train/loss = 0.8374003171920776, train/raw-loss = 0.811198353767395, train/logprobs = tensor([[-3.5378, -5.0740],
        [-2.0866, -1.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2620198130607605
Epoch 0, Step 488: train/loss = 0.3826357424259186, train/raw-loss = 0.3486844599246979, train/logprobs = tensor([[-2.1037, -5.3501],
        [-2.4924, -1.6916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33951258659362793
Epoch 0, Step 489: train/loss = 0.6027867197990417, train/raw-loss = 0.5731894969940186, train/logprobs = tensor([[-0.8069, -2.2215],
        [-1.1016, -1.0609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2959723472595215
Epoch 0, Step 490: train/loss = 0.46615442633628845, train/raw-loss = 0.4408542811870575, train/logprobs = tensor([[-1.3175, -1.5357],
        [-2.6024, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2530011534690857
Epoch 0, Step 491: train/loss = 0.22829729318618774, train/raw-loss = 0.19606435298919678, train/logprobs = tensor([[-1.1277, -5.4702],
        [-2.0530, -1.1483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32232949137687683
Epoch 0, Step 492: train/loss = 0.4728849530220032, train/raw-loss = 0.4452941417694092, train/logprobs = tensor([[-1.0345, -2.4034],
        [-1.6261, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27590805292129517
Epoch 0, Step 493: train/loss = 0.41076987981796265, train/raw-loss = 0.37637871503829956, train/logprobs = tensor([[-1.4436, -1.7293],
        [-3.1378, -1.2329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3439115583896637
Epoch 0, Step 494: train/loss = 0.19376921653747559, train/raw-loss = 0.1608954668045044, train/logprobs = tensor([[-1.0653, -4.5421],
        [-2.5959, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32873761653900146
Epoch 0, Step 495: train/loss = 0.6670602560043335, train/raw-loss = 0.6339347958564758, train/logprobs = tensor([[-0.9581, -2.5862],
        [-1.8642, -1.8515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33125507831573486
Epoch 0, Step 496: train/loss = 0.47601693868637085, train/raw-loss = 0.44587600231170654, train/logprobs = tensor([[-2.0599, -3.6504],
        [-2.5944, -2.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30140939354896545
Epoch 0, Step 497: train/loss = 0.6307936906814575, train/raw-loss = 0.6051989793777466, train/logprobs = tensor([[-3.3250, -3.5409],
        [-3.3040, -2.3026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25594767928123474
Epoch 0, Step 498: train/loss = 0.4237556457519531, train/raw-loss = 0.3874521851539612, train/logprobs = tensor([[-0.9889, -3.5528],
        [-1.9921, -1.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3630349040031433
Epoch 0, Step 499: train/loss = 0.1643911749124527, train/raw-loss = 0.13117603957653046, train/logprobs = tensor([[-1.4003, -5.3906],
        [-2.9469, -1.5579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3321513533592224
eval/loss: 0.36202406883239746
Epoch 0, Step 500: train/loss = 0.20835772156715393, train/raw-loss = 0.17760847508907318, train/logprobs = tensor([[-1.3791, -3.2154],
        [-3.2241, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3074924945831299
Epoch 0, Step 501: train/loss = 0.4432041347026825, train/raw-loss = 0.41817858815193176, train/logprobs = tensor([[-1.6257, -2.0709],
        [-2.5203, -1.4319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2502554953098297
Epoch 0, Step 502: train/loss = 0.37532758712768555, train/raw-loss = 0.3478986620903015, train/logprobs = tensor([[-1.3538, -3.8297],
        [-1.9709, -1.3516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27428919076919556
Epoch 0, Step 503: train/loss = 0.4817536175251007, train/raw-loss = 0.45846134424209595, train/logprobs = tensor([[-1.5348, -2.2429],
        [-2.3296, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2329227328300476
Epoch 0, Step 504: train/loss = 0.27917927503585815, train/raw-loss = 0.24831080436706543, train/logprobs = tensor([[-1.6182, -4.7294],
        [-2.2831, -1.5320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.308684766292572
Epoch 0, Step 505: train/loss = 0.4348755478858948, train/raw-loss = 0.40108728408813477, train/logprobs = tensor([[-0.8427, -3.8002],
        [-1.4681, -1.5487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3378824293613434
Epoch 0, Step 506: train/loss = 0.20357850193977356, train/raw-loss = 0.1717606484889984, train/logprobs = tensor([[-1.2080, -4.5440],
        [-3.0574, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181787133216858
Epoch 0, Step 507: train/loss = 0.5741474032402039, train/raw-loss = 0.5454090237617493, train/logprobs = tensor([[-1.8313, -2.1239],
        [-2.8339, -1.8433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2873839735984802
Epoch 0, Step 508: train/loss = 0.3603712022304535, train/raw-loss = 0.3357203006744385, train/logprobs = tensor([[-1.7726, -3.1985],
        [-3.1152, -0.7848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24650898575782776
Epoch 0, Step 509: train/loss = 0.28720787167549133, train/raw-loss = 0.2630608379840851, train/logprobs = tensor([[-1.4752, -3.3044],
        [-3.0623, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24147020280361176
Epoch 0, Step 510: train/loss = 0.3365029990673065, train/raw-loss = 0.30196619033813477, train/logprobs = tensor([[-1.4445, -3.7796],
        [-3.1143, -1.4178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34536805748939514
Epoch 0, Step 511: train/loss = 0.34224775433540344, train/raw-loss = 0.3186812996864319, train/logprobs = tensor([[-1.1233, -2.9860],
        [-2.1306, -0.9715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23566477000713348
Epoch 0, Step 512: train/loss = 0.7243244647979736, train/raw-loss = 0.6940024495124817, train/logprobs = tensor([[-1.3930, -4.1536],
        [-1.8891, -3.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.303220272064209
Epoch 0, Step 513: train/loss = 0.5622116327285767, train/raw-loss = 0.5422214865684509, train/logprobs = tensor([[-0.9438, -2.8772],
        [-0.8366, -1.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19990137219429016
Epoch 0, Step 514: train/loss = 0.32512861490249634, train/raw-loss = 0.2918146848678589, train/logprobs = tensor([[-2.1250, -4.9058],
        [-3.0004, -1.6837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3331393599510193
Epoch 0, Step 515: train/loss = 0.4464320242404938, train/raw-loss = 0.41025176644325256, train/logprobs = tensor([[-0.8437, -2.3383],
        [-1.6536, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36180251836776733
Epoch 0, Step 516: train/loss = 0.4732566475868225, train/raw-loss = 0.438838928937912, train/logprobs = tensor([[-1.3937, -4.7123],
        [-2.8762, -2.5246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441774249076843
Epoch 0, Step 517: train/loss = 0.4449220299720764, train/raw-loss = 0.41504690051078796, train/logprobs = tensor([[-1.2106, -3.5981],
        [-1.7668, -1.5803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2987515330314636
Epoch 0, Step 518: train/loss = 0.47586768865585327, train/raw-loss = 0.45069319009780884, train/logprobs = tensor([[-1.2615, -1.8544],
        [-2.0466, -1.0918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2517451345920563
Epoch 0, Step 519: train/loss = 0.16745169460773468, train/raw-loss = 0.1344452202320099, train/logprobs = tensor([[-1.3332, -6.1077],
        [-2.7689, -2.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33006465435028076
Epoch 0, Step 520: train/loss = 0.3808467388153076, train/raw-loss = 0.35122597217559814, train/logprobs = tensor([[-1.7858, -3.8172],
        [-2.5072, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2962077260017395
Epoch 0, Step 521: train/loss = 0.3302740454673767, train/raw-loss = 0.30919498205184937, train/logprobs = tensor([[-0.6012, -5.8126],
        [-1.0644, -1.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21079067885875702
Epoch 0, Step 522: train/loss = 0.28278759121894836, train/raw-loss = 0.2498217076063156, train/logprobs = tensor([[-1.1909, -4.5252],
        [-2.4049, -1.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32965877652168274
Epoch 0, Step 523: train/loss = 0.5172535181045532, train/raw-loss = 0.4972149729728699, train/logprobs = tensor([[-1.2174, -1.6536],
        [-1.7647, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20038524270057678
Epoch 0, Step 524: train/loss = 0.5079336166381836, train/raw-loss = 0.4805561304092407, train/logprobs = tensor([[-1.4825, -3.3114],
        [-2.0260, -1.7389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2737744450569153
Epoch 0, Step 525: train/loss = 0.34866172075271606, train/raw-loss = 0.317277193069458, train/logprobs = tensor([[-0.9528, -3.5959],
        [-2.0130, -1.9280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31384503841400146
Epoch 0, Step 526: train/loss = 0.18739180266857147, train/raw-loss = 0.14972633123397827, train/logprobs = tensor([[-1.3637, -3.5777],
        [-3.6207, -1.3076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3766545057296753
Epoch 0, Step 527: train/loss = 0.21609625220298767, train/raw-loss = 0.18116094172000885, train/logprobs = tensor([[-1.2448, -6.0225],
        [-2.5802, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34935295581817627
Epoch 0, Step 528: train/loss = 0.5184367895126343, train/raw-loss = 0.4866245687007904, train/logprobs = tensor([[-0.7134, -2.6024],
        [-1.4975, -1.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3181222975254059
Epoch 0, Step 529: train/loss = 0.3552471995353699, train/raw-loss = 0.3262457847595215, train/logprobs = tensor([[-1.3681, -4.5842],
        [-2.1099, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29001444578170776
Epoch 0, Step 530: train/loss = 0.5437377095222473, train/raw-loss = 0.5092482566833496, train/logprobs = tensor([[-2.0448, -3.0478],
        [-2.3251, -1.6167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34489431977272034
Epoch 0, Step 531: train/loss = 0.21789580583572388, train/raw-loss = 0.18272998929023743, train/logprobs = tensor([[-0.9529, -6.1157],
        [-2.0784, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3516581654548645
Epoch 0, Step 532: train/loss = 0.3815303146839142, train/raw-loss = 0.3531149625778198, train/logprobs = tensor([[-1.9480, -3.6702],
        [-2.8177, -1.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2841532826423645
Epoch 0, Step 533: train/loss = 0.16775578260421753, train/raw-loss = 0.13410207629203796, train/logprobs = tensor([[-1.6710, -4.1588],
        [-3.4784, -1.1159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3365371525287628
Epoch 0, Step 534: train/loss = 0.34545910358428955, train/raw-loss = 0.30964726209640503, train/logprobs = tensor([[-1.2276, -2.9335],
        [-2.5054, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35811859369277954
Epoch 0, Step 535: train/loss = 0.16851699352264404, train/raw-loss = 0.13579168915748596, train/logprobs = tensor([[-1.5220, -4.9129],
        [-3.3795, -1.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3272530734539032
Epoch 0, Step 536: train/loss = 0.328838050365448, train/raw-loss = 0.28795480728149414, train/logprobs = tensor([[-1.1861, -3.4680],
        [-2.6452, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40883275866508484
Epoch 0, Step 537: train/loss = 0.3421669602394104, train/raw-loss = 0.31089019775390625, train/logprobs = tensor([[-0.8325, -5.0665],
        [-1.3193, -0.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31276726722717285
Epoch 0, Step 538: train/loss = 0.48948603868484497, train/raw-loss = 0.4562949538230896, train/logprobs = tensor([[-1.8549, -4.0345],
        [-2.0251, -1.5146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3319109380245209
Epoch 0, Step 539: train/loss = 0.1807824969291687, train/raw-loss = 0.1491681933403015, train/logprobs = tensor([[-2.0223, -5.2644],
        [-3.7934, -1.5155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3161431550979614
Epoch 0, Step 540: train/loss = 0.2569405436515808, train/raw-loss = 0.22371698915958405, train/logprobs = tensor([[-1.2740, -3.5354],
        [-3.2355, -1.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3322353959083557
Epoch 0, Step 541: train/loss = 0.5224759578704834, train/raw-loss = 0.49537020921707153, train/logprobs = tensor([[-0.9614, -2.4451],
        [-1.9949, -1.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27105802297592163
Epoch 0, Step 542: train/loss = 0.23968513309955597, train/raw-loss = 0.20418813824653625, train/logprobs = tensor([[-1.6462, -4.1526],
        [-2.9530, -1.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3549697995185852
Epoch 0, Step 543: train/loss = 0.4013521671295166, train/raw-loss = 0.37750697135925293, train/logprobs = tensor([[-1.0667, -2.6504],
        [-1.8415, -1.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23845165967941284
Epoch 0, Step 544: train/loss = 0.3222883343696594, train/raw-loss = 0.28489792346954346, train/logprobs = tensor([[-0.9853, -3.8414],
        [-2.2779, -1.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3739039897918701
Epoch 0, Step 545: train/loss = 0.24538230895996094, train/raw-loss = 0.20942401885986328, train/logprobs = tensor([[-1.5910, -3.9916],
        [-3.1268, -1.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35958319902420044
Epoch 0, Step 546: train/loss = 0.26626116037368774, train/raw-loss = 0.2269386351108551, train/logprobs = tensor([[-0.9764, -5.6515],
        [-1.9241, -1.5047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3932252824306488
Epoch 0, Step 547: train/loss = 0.38761818408966064, train/raw-loss = 0.36684566736221313, train/logprobs = tensor([[-1.1828, -2.4991],
        [-2.1181, -1.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20772497355937958
Epoch 0, Step 548: train/loss = 0.28983625769615173, train/raw-loss = 0.2559157609939575, train/logprobs = tensor([[-1.4246, -5.7460],
        [-3.5107, -1.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3392052948474884
Epoch 0, Step 549: train/loss = 0.39191919565200806, train/raw-loss = 0.3557920753955841, train/logprobs = tensor([[-1.8884, -2.9160],
        [-2.9883, -1.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3612715005874634
Epoch 0, Step 550: train/loss = 0.31854018568992615, train/raw-loss = 0.2821851968765259, train/logprobs = tensor([[-0.7877, -4.3352],
        [-1.6270, -1.2223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36354976892471313
Epoch 0, Step 551: train/loss = 0.42009106278419495, train/raw-loss = 0.3963882625102997, train/logprobs = tensor([[-1.9080, -2.3380],
        [-3.7877, -0.6856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23702847957611084
Epoch 0, Step 552: train/loss = 0.22386252880096436, train/raw-loss = 0.1897820234298706, train/logprobs = tensor([[-1.5816, -6.3135],
        [-2.6292, -1.4264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3408050537109375
Epoch 0, Step 553: train/loss = 0.45027846097946167, train/raw-loss = 0.42187660932540894, train/logprobs = tensor([[-0.9927, -2.2952],
        [-1.6444, -1.3123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840185761451721
Epoch 0, Step 554: train/loss = 0.35064154863357544, train/raw-loss = 0.3101680278778076, train/logprobs = tensor([[-0.9851, -4.0926],
        [-2.1463, -1.1637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047353267669678
Epoch 0, Step 555: train/loss = 0.6992068290710449, train/raw-loss = 0.6692256927490234, train/logprobs = tensor([[-2.6298, -4.6661],
        [-1.6752, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29981091618537903
Epoch 0, Step 556: train/loss = 0.3476405143737793, train/raw-loss = 0.31542524695396423, train/logprobs = tensor([[-1.9528, -2.9850],
        [-3.1736, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3221530318260193
Epoch 0, Step 557: train/loss = 0.2229105681180954, train/raw-loss = 0.18578320741653442, train/logprobs = tensor([[-1.8949, -4.6948],
        [-4.2327, -2.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37127357721328735
Epoch 0, Step 558: train/loss = 0.20664197206497192, train/raw-loss = 0.1738206148147583, train/logprobs = tensor([[-1.4060, -3.5966],
        [-3.5134, -0.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3282133936882019
Epoch 0, Step 559: train/loss = 0.17705877125263214, train/raw-loss = 0.1452847421169281, train/logprobs = tensor([[-1.6100, -5.1947],
        [-3.1040, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31774041056632996
Epoch 0, Step 560: train/loss = 0.3256051242351532, train/raw-loss = 0.28816747665405273, train/logprobs = tensor([[-1.0867, -3.2598],
        [-2.2172, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3743763566017151
Epoch 0, Step 561: train/loss = 0.4402240514755249, train/raw-loss = 0.3969070315361023, train/logprobs = tensor([[-1.0317, -2.0844],
        [-2.7349, -1.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43317046761512756
Epoch 0, Step 562: train/loss = 0.43853792548179626, train/raw-loss = 0.40665769577026367, train/logprobs = tensor([[-0.8801, -3.2145],
        [-1.5783, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3188023865222931
Epoch 0, Step 563: train/loss = 0.15277357399463654, train/raw-loss = 0.12412157654762268, train/logprobs = tensor([[-1.5684, -5.4217],
        [-3.7169, -2.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865200340747833
Epoch 0, Step 564: train/loss = 0.33609259128570557, train/raw-loss = 0.29418298602104187, train/logprobs = tensor([[-0.8556, -5.7219],
        [-1.6665, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41909611225128174
Epoch 0, Step 565: train/loss = 0.14371365308761597, train/raw-loss = 0.10959681123495102, train/logprobs = tensor([[-1.2210, -4.8460],
        [-3.1994, -1.6222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3411683738231659
Epoch 0, Step 566: train/loss = 0.47314295172691345, train/raw-loss = 0.4444192051887512, train/logprobs = tensor([[-0.9263, -1.4533],
        [-2.1689, -0.8409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2872372269630432
Epoch 0, Step 567: train/loss = 0.24377568066120148, train/raw-loss = 0.20757301151752472, train/logprobs = tensor([[-1.0037, -6.1728],
        [-1.7394, -1.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3620266020298004
Epoch 0, Step 568: train/loss = 0.21745137870311737, train/raw-loss = 0.18475858867168427, train/logprobs = tensor([[-2.4330, -5.4886],
        [-3.9095, -1.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32692793011665344
Epoch 0, Step 569: train/loss = 0.37268513441085815, train/raw-loss = 0.33616167306900024, train/logprobs = tensor([[-1.1017, -3.1843],
        [-1.9813, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3652345538139343
Epoch 0, Step 570: train/loss = 0.20001691579818726, train/raw-loss = 0.16931065917015076, train/logprobs = tensor([[-1.3295, -5.3189],
        [-2.3537, -1.1410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30706268548965454
Epoch 0, Step 571: train/loss = 0.5253442525863647, train/raw-loss = 0.4868459105491638, train/logprobs = tensor([[-0.9635, -2.3121],
        [-1.5926, -1.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.384983092546463
Epoch 0, Step 572: train/loss = 0.2321416586637497, train/raw-loss = 0.20134620368480682, train/logprobs = tensor([[-1.1025, -3.6855],
        [-3.0322, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3079545497894287
Epoch 0, Step 573: train/loss = 0.23171347379684448, train/raw-loss = 0.19971555471420288, train/logprobs = tensor([[-1.5560, -4.2064],
        [-3.2278, -1.3345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31997931003570557
Epoch 0, Step 574: train/loss = 0.19087350368499756, train/raw-loss = 0.1563788652420044, train/logprobs = tensor([[-1.0881, -5.8606],
        [-2.7648, -1.1111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3449464440345764
Epoch 0, Step 575: train/loss = 0.5197712182998657, train/raw-loss = 0.4876444935798645, train/logprobs = tensor([[-1.4584, -2.6747],
        [-2.2028, -1.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3212677836418152
Epoch 0, Step 576: train/loss = 0.7853436470031738, train/raw-loss = 0.7480983734130859, train/logprobs = tensor([[-1.2224, -2.4933],
        [-2.8167, -3.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3724527359008789
Epoch 0, Step 577: train/loss = 0.3387187421321869, train/raw-loss = 0.30427026748657227, train/logprobs = tensor([[-1.1217, -4.0754],
        [-2.3047, -1.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34448444843292236
Epoch 0, Step 578: train/loss = 0.14734405279159546, train/raw-loss = 0.11147249490022659, train/logprobs = tensor([[-1.5285, -5.3826],
        [-3.5529, -2.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3587157130241394
Epoch 0, Step 579: train/loss = 0.25924617052078247, train/raw-loss = 0.22460567951202393, train/logprobs = tensor([[-2.0421, -2.0411],
        [-5.1775, -1.0758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3464046120643616
Epoch 0, Step 580: train/loss = 0.2514180541038513, train/raw-loss = 0.21791939437389374, train/logprobs = tensor([[-2.2079, -3.9909],
        [-4.0725, -1.4709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3349863886833191
Epoch 0, Step 581: train/loss = 0.304218590259552, train/raw-loss = 0.2689361870288849, train/logprobs = tensor([[-1.9234, -4.3392],
        [-3.5285, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3528239130973816
Epoch 0, Step 582: train/loss = 0.3300597369670868, train/raw-loss = 0.29583045840263367, train/logprobs = tensor([[-0.7690, -3.3855],
        [-1.8765, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.342292845249176
Epoch 0, Step 583: train/loss = 0.6205079555511475, train/raw-loss = 0.5768581628799438, train/logprobs = tensor([[-0.9406, -2.3313],
        [-1.6647, -1.4740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4364975094795227
Epoch 0, Step 584: train/loss = 0.28928568959236145, train/raw-loss = 0.25267493724823, train/logprobs = tensor([[-1.1580, -4.3096],
        [-1.9598, -1.6230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36610737442970276
Epoch 0, Step 585: train/loss = 0.5401719808578491, train/raw-loss = 0.5011866092681885, train/logprobs = tensor([[-1.2945, -5.0250],
        [-2.4813, -2.5690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38985365629196167
Epoch 0, Step 586: train/loss = 0.27012521028518677, train/raw-loss = 0.23183991014957428, train/logprobs = tensor([[-1.5742, -4.6226],
        [-2.8268, -1.3974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38285285234451294
Epoch 0, Step 587: train/loss = 0.31769102811813354, train/raw-loss = 0.27703148126602173, train/logprobs = tensor([[-1.9639, -4.9893],
        [-2.6038, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40659552812576294
Epoch 0, Step 588: train/loss = 0.5539044737815857, train/raw-loss = 0.5228075981140137, train/logprobs = tensor([[-1.2609, -2.7099],
        [-2.6371, -1.8031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3109687268733978
Epoch 0, Step 589: train/loss = 0.4321938455104828, train/raw-loss = 0.38952815532684326, train/logprobs = tensor([[-1.1390, -2.8349],
        [-2.2202, -1.3393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4266568124294281
Epoch 0, Step 590: train/loss = 0.3104405105113983, train/raw-loss = 0.2773759067058563, train/logprobs = tensor([[-1.3144, -6.4192],
        [-2.7456, -2.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3306458592414856
Epoch 0, Step 591: train/loss = 0.404548704624176, train/raw-loss = 0.3693391680717468, train/logprobs = tensor([[-1.2693, -2.6032],
        [-2.1416, -1.2723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35209542512893677
Epoch 0, Step 592: train/loss = 0.3354039192199707, train/raw-loss = 0.2992580533027649, train/logprobs = tensor([[-1.4196, -4.1401],
        [-2.9732, -1.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36145877838134766
Epoch 0, Step 593: train/loss = 0.5733477473258972, train/raw-loss = 0.5359926223754883, train/logprobs = tensor([[-2.3985, -1.9236],
        [-3.2233, -1.4613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3735511302947998
Epoch 0, Step 594: train/loss = 0.4620108902454376, train/raw-loss = 0.4344745874404907, train/logprobs = tensor([[-1.5329, -2.5831],
        [-2.2768, -1.4170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27536311745643616
Epoch 0, Step 595: train/loss = 0.47323131561279297, train/raw-loss = 0.4378620684146881, train/logprobs = tensor([[-1.5620, -1.7807],
        [-2.7074, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3536924123764038
Epoch 0, Step 596: train/loss = 0.6333959102630615, train/raw-loss = 0.5991417169570923, train/logprobs = tensor([[-1.2212, -2.3556],
        [-1.1048, -1.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34254157543182373
Epoch 0, Step 597: train/loss = 0.5257078409194946, train/raw-loss = 0.4901423752307892, train/logprobs = tensor([[-2.3618, -3.3105],
        [-3.0113, -2.5535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3556548058986664
Epoch 0, Step 598: train/loss = 0.5148290395736694, train/raw-loss = 0.48052144050598145, train/logprobs = tensor([[-1.6747, -4.6623],
        [-2.9079, -2.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34307578206062317
Epoch 0, Step 599: train/loss = 0.4349989891052246, train/raw-loss = 0.4071398973464966, train/logprobs = tensor([[-1.2315, -2.9459],
        [-2.2452, -1.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785908579826355
Epoch 0, Step 600: train/loss = 0.3390343487262726, train/raw-loss = 0.3011426031589508, train/logprobs = tensor([[-1.4713, -5.2733],
        [-1.9422, -1.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37891775369644165
Epoch 0, Step 601: train/loss = 0.18878936767578125, train/raw-loss = 0.15398402512073517, train/logprobs = tensor([[-1.6848, -4.7525],
        [-3.3437, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480533957481384
Epoch 0, Step 602: train/loss = 0.4650249779224396, train/raw-loss = 0.43457019329071045, train/logprobs = tensor([[-2.1519, -4.5337],
        [-2.4246, -1.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30454784631729126
Epoch 0, Step 603: train/loss = 0.40199461579322815, train/raw-loss = 0.3622193932533264, train/logprobs = tensor([[-1.5136, -4.0660],
        [-2.3566, -1.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3977523148059845
Epoch 0, Step 604: train/loss = 0.46974530816078186, train/raw-loss = 0.43352892994880676, train/logprobs = tensor([[-1.4105, -4.5266],
        [-1.4084, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36216387152671814
Epoch 0, Step 605: train/loss = 0.2139696180820465, train/raw-loss = 0.1768500655889511, train/logprobs = tensor([[-0.7217, -6.4517],
        [-1.5397, -1.2628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.371195524930954
Epoch 0, Step 606: train/loss = 0.33444106578826904, train/raw-loss = 0.2954767346382141, train/logprobs = tensor([[-1.6982, -3.8087],
        [-3.4530, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3896428942680359
Epoch 0, Step 607: train/loss = 0.3651079535484314, train/raw-loss = 0.33119577169418335, train/logprobs = tensor([[-1.7295, -3.0501],
        [-3.4992, -1.2370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33912193775177
Epoch 0, Step 608: train/loss = 0.15820972621440887, train/raw-loss = 0.12670908868312836, train/logprobs = tensor([[-1.4619, -7.1923],
        [-3.3857, -1.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3150063753128052
Epoch 0, Step 609: train/loss = 0.4847024381160736, train/raw-loss = 0.45334404706954956, train/logprobs = tensor([[-1.3845, -3.2115],
        [-1.4727, -0.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3135838508605957
Epoch 0, Step 610: train/loss = 0.564202606678009, train/raw-loss = 0.5196582078933716, train/logprobs = tensor([[-0.8668, -2.7632],
        [-1.7676, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44544416666030884
Epoch 0, Step 611: train/loss = 0.2033909261226654, train/raw-loss = 0.1653934121131897, train/logprobs = tensor([[-1.5621, -7.2349],
        [-2.3687, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3799753189086914
Epoch 0, Step 612: train/loss = 0.3873327076435089, train/raw-loss = 0.3525042235851288, train/logprobs = tensor([[-2.1398, -5.1712],
        [-2.1499, -1.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3482847511768341
Epoch 0, Step 613: train/loss = 0.3859017491340637, train/raw-loss = 0.3465613126754761, train/logprobs = tensor([[-1.1383, -3.0684],
        [-2.9574, -1.5923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39340436458587646
Epoch 0, Step 614: train/loss = 0.3579607605934143, train/raw-loss = 0.32491448521614075, train/logprobs = tensor([[-1.7437, -4.8816],
        [-2.2785, -1.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3304629623889923
Epoch 0, Step 615: train/loss = 0.29947763681411743, train/raw-loss = 0.27092254161834717, train/logprobs = tensor([[-2.1931, -2.2046],
        [-5.0511, -1.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28555089235305786
Epoch 0, Step 616: train/loss = 0.24650448560714722, train/raw-loss = 0.20603063702583313, train/logprobs = tensor([[-1.4024, -4.7502],
        [-2.6063, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40473854541778564
Epoch 0, Step 617: train/loss = 0.34035640954971313, train/raw-loss = 0.30407270789146423, train/logprobs = tensor([[-1.0089, -5.7868],
        [-1.6127, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3628367781639099
Epoch 0, Step 618: train/loss = 0.3039971590042114, train/raw-loss = 0.25452670454978943, train/logprobs = tensor([[-1.4038, -6.2249],
        [-2.3984, -1.1827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49470457434654236
Epoch 0, Step 619: train/loss = 0.25316861271858215, train/raw-loss = 0.22133657336235046, train/logprobs = tensor([[-1.6053, -5.0384],
        [-2.7385, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31832027435302734
Epoch 0, Step 620: train/loss = 0.2556488513946533, train/raw-loss = 0.21774718165397644, train/logprobs = tensor([[-1.6111, -4.6149],
        [-3.1762, -2.2241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37901678681373596
Epoch 0, Step 621: train/loss = 0.19889096915721893, train/raw-loss = 0.15832531452178955, train/logprobs = tensor([[-1.0088, -5.9075],
        [-2.0649, -1.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4056565463542938
Epoch 0, Step 622: train/loss = 0.17092135548591614, train/raw-loss = 0.13756266236305237, train/logprobs = tensor([[-1.4626, -4.6620],
        [-3.6354, -1.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3335869312286377
Epoch 0, Step 623: train/loss = 0.6051092743873596, train/raw-loss = 0.5689637064933777, train/logprobs = tensor([[-1.6369, -3.1636],
        [-1.9424, -1.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3614550828933716
Epoch 0, Step 624: train/loss = 0.49143537878990173, train/raw-loss = 0.45542430877685547, train/logprobs = tensor([[-1.8552, -2.8467],
        [-3.0958, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3601108491420746
Epoch 0, Step 625: train/loss = 0.41079652309417725, train/raw-loss = 0.3704175353050232, train/logprobs = tensor([[-1.4042, -3.9334],
        [-2.3315, -1.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40379029512405396
Epoch 0, Step 626: train/loss = 0.6385898590087891, train/raw-loss = 0.5889935493469238, train/logprobs = tensor([[-0.9880, -2.9766],
        [-1.5736, -1.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4959627389907837
Epoch 0, Step 627: train/loss = 0.3785800039768219, train/raw-loss = 0.3482914865016937, train/logprobs = tensor([[-1.4183, -2.5232],
        [-2.5368, -1.0104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3028854429721832
Epoch 0, Step 628: train/loss = 0.448128879070282, train/raw-loss = 0.40958309173583984, train/logprobs = tensor([[-1.3761, -4.0811],
        [-2.1356, -3.3202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3854576349258423
Epoch 0, Step 629: train/loss = 0.42157500982284546, train/raw-loss = 0.3949556350708008, train/logprobs = tensor([[-1.2515, -2.4646],
        [-2.2791, -1.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.266193687915802
Epoch 0, Step 630: train/loss = 0.35661667585372925, train/raw-loss = 0.31311649084091187, train/logprobs = tensor([[-1.5167, -4.3412],
        [-2.6997, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43500208854675293
Epoch 0, Step 631: train/loss = 0.5639245510101318, train/raw-loss = 0.5265004634857178, train/logprobs = tensor([[-2.1930, -3.1476],
        [-2.7039, -1.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3742409944534302
Epoch 0, Step 632: train/loss = 0.7112697958946228, train/raw-loss = 0.674452006816864, train/logprobs = tensor([[-1.8281, -3.3450],
        [-4.3493, -2.6927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36817872524261475
Epoch 0, Step 633: train/loss = 0.45873546600341797, train/raw-loss = 0.42068591713905334, train/logprobs = tensor([[-1.7525, -2.0542],
        [-2.6433, -1.3975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3804951310157776
Epoch 0, Step 634: train/loss = 0.3031885027885437, train/raw-loss = 0.26429611444473267, train/logprobs = tensor([[-2.4866, -3.1498],
        [-4.9185, -1.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38892391324043274
Epoch 0, Step 635: train/loss = 0.4288901686668396, train/raw-loss = 0.39042502641677856, train/logprobs = tensor([[-1.0162, -3.4927],
        [-2.7932, -1.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38465166091918945
Epoch 0, Step 636: train/loss = 0.2775250971317291, train/raw-loss = 0.24799713492393494, train/logprobs = tensor([[-2.0281, -4.3845],
        [-4.2338, -2.7026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2952793836593628
Epoch 0, Step 637: train/loss = 0.48205500841140747, train/raw-loss = 0.44791874289512634, train/logprobs = tensor([[-1.0511, -2.7941],
        [-1.5441, -1.5530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3413626253604889
Epoch 0, Step 638: train/loss = 0.4623262882232666, train/raw-loss = 0.4300647974014282, train/logprobs = tensor([[-1.5977, -2.4851],
        [-2.6040, -1.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32261526584625244
Epoch 0, Step 639: train/loss = 0.2142655998468399, train/raw-loss = 0.18132460117340088, train/logprobs = tensor([[-1.4543, -5.0648],
        [-3.1123, -2.5105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3294098973274231
Epoch 0, Step 640: train/loss = 0.26034027338027954, train/raw-loss = 0.22379377484321594, train/logprobs = tensor([[-1.6054, -5.3393],
        [-2.7009, -1.6592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3654651939868927
Epoch 0, Step 641: train/loss = 0.529965877532959, train/raw-loss = 0.4924686849117279, train/logprobs = tensor([[-2.0478, -4.4827],
        [-2.5653, -1.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3749721050262451
Epoch 0, Step 642: train/loss = 0.3083461821079254, train/raw-loss = 0.26496171951293945, train/logprobs = tensor([[-0.9169, -4.0231],
        [-2.4909, -1.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4338444173336029
Epoch 0, Step 643: train/loss = 0.42776235938072205, train/raw-loss = 0.378637433052063, train/logprobs = tensor([[-0.9192, -4.3206],
        [-2.1981, -1.3406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4912490248680115
Epoch 0, Step 644: train/loss = 0.20020852982997894, train/raw-loss = 0.15766945481300354, train/logprobs = tensor([[-1.9641, -7.4085],
        [-3.1250, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4253906011581421
Epoch 0, Step 645: train/loss = 0.75455641746521, train/raw-loss = 0.7139737606048584, train/logprobs = tensor([[-1.6437, -4.0071],
        [-2.4815, -2.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40582647919654846
Epoch 0, Step 646: train/loss = 0.6936667561531067, train/raw-loss = 0.6625344753265381, train/logprobs = tensor([[-3.2060, -5.4459],
        [-2.8265, -2.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3113226294517517
Epoch 0, Step 647: train/loss = 0.19291971623897552, train/raw-loss = 0.157451331615448, train/logprobs = tensor([[-1.6106, -4.4748],
        [-3.4280, -1.3527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35468387603759766
Epoch 0, Step 648: train/loss = 0.58405601978302, train/raw-loss = 0.560347318649292, train/logprobs = tensor([[-1.4722, -3.3427],
        [-1.2805, -1.1669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23708783090114594
Epoch 0, Step 649: train/loss = 0.7193692922592163, train/raw-loss = 0.6756608486175537, train/logprobs = tensor([[-1.3120, -4.5320],
        [-3.1595, -2.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4370843768119812
Epoch 0, Step 650: train/loss = 0.4500553011894226, train/raw-loss = 0.4154006540775299, train/logprobs = tensor([[-1.4347, -2.2108],
        [-2.7973, -1.2764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34654662013053894
Epoch 0, Step 651: train/loss = 0.21561980247497559, train/raw-loss = 0.17705115675926208, train/logprobs = tensor([[-1.0267, -7.9190],
        [-1.7092, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3856865167617798
Epoch 0, Step 652: train/loss = 0.35859617590904236, train/raw-loss = 0.3196454346179962, train/logprobs = tensor([[-1.6158, -4.8001],
        [-2.0632, -1.3754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.389507532119751
Epoch 0, Step 653: train/loss = 0.2851494550704956, train/raw-loss = 0.25449198484420776, train/logprobs = tensor([[-1.0745, -3.9086],
        [-2.3441, -1.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3065750300884247
Epoch 0, Step 654: train/loss = 0.33919382095336914, train/raw-loss = 0.2978208065032959, train/logprobs = tensor([[-0.8733, -4.7295],
        [-1.7833, -1.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4137301445007324
Epoch 0, Step 655: train/loss = 0.4189501106739044, train/raw-loss = 0.3839634358882904, train/logprobs = tensor([[-1.2092, -4.3475],
        [-1.7678, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.349866658449173
Epoch 0, Step 656: train/loss = 0.2259364277124405, train/raw-loss = 0.19068220257759094, train/logprobs = tensor([[-1.1268, -5.9181],
        [-2.1328, -2.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3525424599647522
Epoch 0, Step 657: train/loss = 0.20121926069259644, train/raw-loss = 0.1613098382949829, train/logprobs = tensor([[-0.8380, -6.1044],
        [-1.6777, -0.7588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3990941345691681
Epoch 0, Step 658: train/loss = 0.4755311608314514, train/raw-loss = 0.4391203820705414, train/logprobs = tensor([[-1.3365, -3.6619],
        [-2.0677, -1.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.364107608795166
Epoch 0, Step 659: train/loss = 0.2738628387451172, train/raw-loss = 0.23723918199539185, train/logprobs = tensor([[-1.7627, -3.1073],
        [-4.0262, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3662363886833191
Epoch 0, Step 660: train/loss = 0.18039797246456146, train/raw-loss = 0.14414986968040466, train/logprobs = tensor([[-1.9736, -4.4551],
        [-4.7176, -1.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362481027841568
Epoch 0, Step 661: train/loss = 0.3363921046257019, train/raw-loss = 0.2978304922580719, train/logprobs = tensor([[-1.2658, -4.3234],
        [-1.8842, -1.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3856160342693329
Epoch 0, Step 662: train/loss = 0.41222721338272095, train/raw-loss = 0.37358301877975464, train/logprobs = tensor([[-1.2828, -3.9873],
        [-1.8673, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38644200563430786
Epoch 0, Step 663: train/loss = 0.5599908828735352, train/raw-loss = 0.5207746028900146, train/logprobs = tensor([[-2.1458, -4.7091],
        [-5.1211, -2.5291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39216282963752747
Epoch 0, Step 664: train/loss = 0.29634514451026917, train/raw-loss = 0.2617518901824951, train/logprobs = tensor([[-1.1201, -3.7304],
        [-2.4084, -0.6713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3459327816963196
Epoch 0, Step 665: train/loss = 0.5974287986755371, train/raw-loss = 0.5695862174034119, train/logprobs = tensor([[-3.0077, -3.3567],
        [-2.9483, -1.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27842509746551514
Epoch 0, Step 666: train/loss = 0.36034369468688965, train/raw-loss = 0.3283350467681885, train/logprobs = tensor([[-1.6511, -4.5796],
        [-1.7171, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3200865387916565
Epoch 0, Step 667: train/loss = 0.3392982482910156, train/raw-loss = 0.3045257031917572, train/logprobs = tensor([[-0.9517, -3.3977],
        [-2.2764, -1.5305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477253317832947
Epoch 0, Step 668: train/loss = 0.263757586479187, train/raw-loss = 0.22873543202877045, train/logprobs = tensor([[-1.4805, -3.6898],
        [-3.6844, -1.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502214550971985
Epoch 0, Step 669: train/loss = 0.3665561079978943, train/raw-loss = 0.3288808763027191, train/logprobs = tensor([[-3.1688, -4.9594],
        [-5.2583, -2.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37675225734710693
Epoch 0, Step 670: train/loss = 0.392027884721756, train/raw-loss = 0.3590242266654968, train/logprobs = tensor([[-1.7155, -4.2317],
        [-2.7430, -2.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.330036461353302
Epoch 0, Step 671: train/loss = 0.5658106803894043, train/raw-loss = 0.5285508036613464, train/logprobs = tensor([[-2.1449, -5.2342],
        [-2.9505, -2.2282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3725988268852234
Epoch 0, Step 672: train/loss = 0.21382558345794678, train/raw-loss = 0.17150768637657166, train/logprobs = tensor([[-0.9850, -5.0761],
        [-2.3433, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4231790006160736
Epoch 0, Step 673: train/loss = 0.3515303134918213, train/raw-loss = 0.3114883303642273, train/logprobs = tensor([[-1.1612, -2.8341],
        [-2.4476, -1.3641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40041977167129517
Epoch 0, Step 674: train/loss = 0.28854069113731384, train/raw-loss = 0.25503480434417725, train/logprobs = tensor([[-2.1486, -3.5172],
        [-4.2411, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33505886793136597
Epoch 0, Step 675: train/loss = 0.308634877204895, train/raw-loss = 0.2694269120693207, train/logprobs = tensor([[-0.8459, -5.5640],
        [-1.4309, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.392079621553421
Epoch 0, Step 676: train/loss = 0.374617338180542, train/raw-loss = 0.33378374576568604, train/logprobs = tensor([[-1.1060, -3.0870],
        [-2.7279, -1.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40833568572998047
Epoch 0, Step 677: train/loss = 0.24869929254055023, train/raw-loss = 0.20305988192558289, train/logprobs = tensor([[-1.7810, -5.4106],
        [-3.2346, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4563940763473511
Epoch 0, Step 678: train/loss = 0.29112476110458374, train/raw-loss = 0.25714436173439026, train/logprobs = tensor([[-1.6218, -3.7685],
        [-4.3608, -1.7756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3398039638996124
Epoch 0, Step 679: train/loss = 0.35103800892829895, train/raw-loss = 0.31058600544929504, train/logprobs = tensor([[-1.1393, -4.9732],
        [-2.4102, -1.7874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4045200049877167
Epoch 0, Step 680: train/loss = 0.3066481053829193, train/raw-loss = 0.26200178265571594, train/logprobs = tensor([[-0.8680, -4.4893],
        [-2.1164, -1.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44646328687667847
Epoch 0, Step 681: train/loss = 0.3570411205291748, train/raw-loss = 0.3183235228061676, train/logprobs = tensor([[-2.3488, -4.2184],
        [-4.6918, -1.3973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3871760964393616
Epoch 0, Step 682: train/loss = 0.30189135670661926, train/raw-loss = 0.25687122344970703, train/logprobs = tensor([[-1.0854, -4.3440],
        [-2.6356, -1.3092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4502014219760895
Epoch 0, Step 683: train/loss = 0.2660282254219055, train/raw-loss = 0.23108527064323425, train/logprobs = tensor([[-1.5830, -3.5365],
        [-2.8243, -1.5301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3494298756122589
Epoch 0, Step 684: train/loss = 0.48409613966941833, train/raw-loss = 0.4519611895084381, train/logprobs = tensor([[-1.0652, -3.3507],
        [-1.5970, -1.4698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213495910167694
Epoch 0, Step 685: train/loss = 0.30053919553756714, train/raw-loss = 0.2623350918292999, train/logprobs = tensor([[-0.9552, -4.3000],
        [-2.7733, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38204118609428406
Epoch 0, Step 686: train/loss = 0.42507225275039673, train/raw-loss = 0.38809913396835327, train/logprobs = tensor([[-1.1274, -3.5175],
        [-2.3887, -1.1734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36973103880882263
Epoch 0, Step 687: train/loss = 0.21999874711036682, train/raw-loss = 0.1764618158340454, train/logprobs = tensor([[-1.2492, -5.7430],
        [-2.1247, -1.2060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43536919355392456
Epoch 0, Step 688: train/loss = 0.36803990602493286, train/raw-loss = 0.3332672715187073, train/logprobs = tensor([[-1.2265, -4.4704],
        [-1.8267, -1.4346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3477261960506439
Epoch 0, Step 689: train/loss = 0.19328653812408447, train/raw-loss = 0.15438911318778992, train/logprobs = tensor([[-2.2984, -5.2169],
        [-3.6846, -1.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38897421956062317
Epoch 0, Step 690: train/loss = 0.31762105226516724, train/raw-loss = 0.2713010907173157, train/logprobs = tensor([[-1.1577, -3.9570],
        [-2.8060, -1.3159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46319955587387085
Epoch 0, Step 691: train/loss = 0.4419669210910797, train/raw-loss = 0.4095841348171234, train/logprobs = tensor([[-1.8633, -2.9662],
        [-2.8421, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3238278031349182
Epoch 0, Step 692: train/loss = 0.2671898603439331, train/raw-loss = 0.23392462730407715, train/logprobs = tensor([[-2.5204, -3.9347],
        [-5.5624, -2.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33265239000320435
Epoch 0, Step 693: train/loss = 0.22009974718093872, train/raw-loss = 0.1737927496433258, train/logprobs = tensor([[-1.0059, -6.1184],
        [-1.8518, -1.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4630700349807739
Epoch 0, Step 694: train/loss = 0.5054850578308105, train/raw-loss = 0.4659709632396698, train/logprobs = tensor([[-1.3320, -3.7355],
        [-1.9605, -1.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3951409161090851
Epoch 0, Step 695: train/loss = 0.17963947355747223, train/raw-loss = 0.13811078667640686, train/logprobs = tensor([[-1.2873, -5.4969],
        [-3.1243, -1.4431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41528695821762085
Epoch 0, Step 696: train/loss = 0.40327951312065125, train/raw-loss = 0.3671450614929199, train/logprobs = tensor([[-1.1291, -4.7153],
        [-1.3077, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3613448441028595
Epoch 0, Step 697: train/loss = 0.4469769299030304, train/raw-loss = 0.4048195481300354, train/logprobs = tensor([[-1.9597, -4.6882],
        [-2.4572, -1.5085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4215738773345947
Epoch 0, Step 698: train/loss = 0.280976265668869, train/raw-loss = 0.24581389129161835, train/logprobs = tensor([[-1.7954, -3.0527],
        [-4.9818, -1.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3516237139701843
Epoch 0, Step 699: train/loss = 0.23169609904289246, train/raw-loss = 0.19767948985099792, train/logprobs = tensor([[-0.5810, -6.4249],
        [-1.1501, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3401660919189453
Epoch 0, Step 700: train/loss = 0.5268271565437317, train/raw-loss = 0.4906114935874939, train/logprobs = tensor([[-2.8792, -4.5497],
        [-3.0145, -3.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36215701699256897
Epoch 0, Step 701: train/loss = 0.19920262694358826, train/raw-loss = 0.15966571867465973, train/logprobs = tensor([[-1.7706, -4.7384],
        [-4.1922, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39536893367767334
Epoch 0, Step 702: train/loss = 0.31153905391693115, train/raw-loss = 0.2735181748867035, train/logprobs = tensor([[-1.4077, -6.2562],
        [-1.6512, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38020893931388855
Epoch 0, Step 703: train/loss = 0.30925485491752625, train/raw-loss = 0.2673478126525879, train/logprobs = tensor([[-1.5128, -5.9480],
        [-2.1131, -0.9826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4190705418586731
Epoch 0, Step 704: train/loss = 0.4468700885772705, train/raw-loss = 0.4195065498352051, train/logprobs = tensor([[-1.2431, -2.6900],
        [-2.3744, -0.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27363526821136475
Epoch 0, Step 705: train/loss = 0.4425899386405945, train/raw-loss = 0.40257012844085693, train/logprobs = tensor([[-2.0514, -3.5846],
        [-2.7864, -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4001980721950531
Epoch 0, Step 706: train/loss = 0.32179200649261475, train/raw-loss = 0.283852756023407, train/logprobs = tensor([[-1.7648, -5.4236],
        [-3.2604, -1.5896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3793923854827881
Epoch 0, Step 707: train/loss = 0.40355658531188965, train/raw-loss = 0.3651100993156433, train/logprobs = tensor([[-0.9647, -3.4681],
        [-2.0682, -1.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38446474075317383
Epoch 0, Step 708: train/loss = 0.25302359461784363, train/raw-loss = 0.2200036346912384, train/logprobs = tensor([[-1.7125, -3.4015],
        [-5.3845, -1.2330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3301996886730194
Epoch 0, Step 709: train/loss = 0.7179340720176697, train/raw-loss = 0.6892266273498535, train/logprobs = tensor([[-3.6675, -5.1664],
        [-3.5555, -2.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28707385063171387
Epoch 0, Step 710: train/loss = 0.5070496201515198, train/raw-loss = 0.4727877974510193, train/logprobs = tensor([[-2.0911, -2.8642],
        [-2.1439, -1.1413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3426179885864258
Epoch 0, Step 711: train/loss = 0.25954750180244446, train/raw-loss = 0.21838948130607605, train/logprobs = tensor([[-1.6593, -3.7151],
        [-3.5259, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4115799069404602
Epoch 0, Step 712: train/loss = 0.27980804443359375, train/raw-loss = 0.23931676149368286, train/logprobs = tensor([[-1.1858, -5.9950],
        [-2.6325, -1.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049125611782074
Epoch 0, Step 713: train/loss = 0.5172483325004578, train/raw-loss = 0.48528265953063965, train/logprobs = tensor([[-2.1850, -4.3041],
        [-2.1233, -2.2479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3196566104888916
Epoch 0, Step 714: train/loss = 0.3459542989730835, train/raw-loss = 0.3120459020137787, train/logprobs = tensor([[-1.9352, -5.3382],
        [-2.9790, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3390839695930481
Epoch 0, Step 715: train/loss = 0.23125776648521423, train/raw-loss = 0.1923246681690216, train/logprobs = tensor([[-1.8089, -3.4604],
        [-4.0816, -0.8767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38933083415031433
Epoch 0, Step 716: train/loss = 0.36751651763916016, train/raw-loss = 0.32434752583503723, train/logprobs = tensor([[-1.4235, -3.3639],
        [-3.4989, -2.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4316897988319397
Epoch 0, Step 717: train/loss = 0.34747567772865295, train/raw-loss = 0.3042284846305847, train/logprobs = tensor([[-1.1847, -2.8609],
        [-3.6002, -1.3216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4324720501899719
Epoch 0, Step 718: train/loss = 0.23235414922237396, train/raw-loss = 0.1879415661096573, train/logprobs = tensor([[-1.5753, -4.9915],
        [-3.4003, -1.3619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4441256821155548
Epoch 0, Step 719: train/loss = 0.6607758402824402, train/raw-loss = 0.6230975389480591, train/logprobs = tensor([[-0.9652, -2.5302],
        [-1.8833, -2.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767825961112976
Epoch 0, Step 720: train/loss = 0.48213285207748413, train/raw-loss = 0.44679373502731323, train/logprobs = tensor([[-1.7861, -4.3179],
        [-2.8779, -2.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35339152812957764
Epoch 0, Step 721: train/loss = 0.6920050978660583, train/raw-loss = 0.6481299996376038, train/logprobs = tensor([[-1.6445, -3.1845],
        [-2.1401, -2.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4387510418891907
Epoch 0, Step 722: train/loss = 0.18422739207744598, train/raw-loss = 0.14617642760276794, train/logprobs = tensor([[-1.6603, -5.4473],
        [-3.3596, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3805093765258789
Epoch 0, Step 723: train/loss = 0.273613303899765, train/raw-loss = 0.2392432987689972, train/logprobs = tensor([[-1.5586, -3.1982],
        [-3.6856, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34369993209838867
Epoch 0, Step 724: train/loss = 0.45636555552482605, train/raw-loss = 0.4194495975971222, train/logprobs = tensor([[-1.5259, -4.1239],
        [-1.9682, -2.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3691596984863281
Epoch 0, Step 725: train/loss = 0.34109169244766235, train/raw-loss = 0.3031872808933258, train/logprobs = tensor([[-1.5304, -4.4687],
        [-3.0030, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3790445327758789
Epoch 0, Step 726: train/loss = 0.21968573331832886, train/raw-loss = 0.17947451770305634, train/logprobs = tensor([[-1.1931, -5.2268],
        [-2.4611, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40211212635040283
Epoch 0, Step 727: train/loss = 0.4893840253353119, train/raw-loss = 0.4558731019496918, train/logprobs = tensor([[-3.9627, -5.6795],
        [-4.1011, -2.9151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3351092040538788
Epoch 0, Step 728: train/loss = 0.3229442834854126, train/raw-loss = 0.2859441339969635, train/logprobs = tensor([[-1.3898, -4.7553],
        [-2.1239, -1.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37000155448913574
Epoch 0, Step 729: train/loss = 0.1847103238105774, train/raw-loss = 0.14153990149497986, train/logprobs = tensor([[-1.7038, -4.7352],
        [-4.1861, -1.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4317040741443634
Epoch 0, Step 730: train/loss = 0.3061593174934387, train/raw-loss = 0.26501569151878357, train/logprobs = tensor([[-1.4218, -4.7166],
        [-3.3189, -2.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41143643856048584
Epoch 0, Step 731: train/loss = 0.2320343554019928, train/raw-loss = 0.19225364923477173, train/logprobs = tensor([[-1.5438, -4.3311],
        [-3.6961, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3978070020675659
Epoch 0, Step 732: train/loss = 0.47488927841186523, train/raw-loss = 0.44524577260017395, train/logprobs = tensor([[-1.5105, -2.4636],
        [-2.4081, -0.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964353561401367
Epoch 0, Step 733: train/loss = 0.38613879680633545, train/raw-loss = 0.35113197565078735, train/logprobs = tensor([[-4.2757, -6.8243],
        [-5.8801, -3.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35006800293922424
Epoch 0, Step 734: train/loss = 0.4804510474205017, train/raw-loss = 0.4460684657096863, train/logprobs = tensor([[-1.5752, -3.3316],
        [-2.2307, -2.0177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438258171081543
Epoch 0, Step 735: train/loss = 0.6961466073989868, train/raw-loss = 0.6558655500411987, train/logprobs = tensor([[-1.6413, -3.3066],
        [-1.6809, -2.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4028107225894928
Epoch 0, Step 736: train/loss = 0.4401776194572449, train/raw-loss = 0.400084912776947, train/logprobs = tensor([[-1.6812, -4.7671],
        [-2.3359, -2.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40092694759368896
Epoch 0, Step 737: train/loss = 0.2902785539627075, train/raw-loss = 0.24895697832107544, train/logprobs = tensor([[-1.0376, -6.3302],
        [-2.1482, -2.2991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4132155179977417
Epoch 0, Step 738: train/loss = 0.147910475730896, train/raw-loss = 0.10745055973529816, train/logprobs = tensor([[-2.3168, -4.0220],
        [-6.5295, -1.6557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40459901094436646
Epoch 0, Step 739: train/loss = 0.35062292218208313, train/raw-loss = 0.30733540654182434, train/logprobs = tensor([[-1.2572, -5.3313],
        [-2.3936, -1.3695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43287530541419983
Epoch 0, Step 740: train/loss = 0.3047933578491211, train/raw-loss = 0.2536573112010956, train/logprobs = tensor([[-0.9665, -3.9457],
        [-2.8550, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5113603472709656
Epoch 0, Step 741: train/loss = 0.28073620796203613, train/raw-loss = 0.23752851784229279, train/logprobs = tensor([[-1.4038, -7.1679],
        [-1.9047, -1.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43207693099975586
Epoch 0, Step 742: train/loss = 0.262442022562027, train/raw-loss = 0.23189188539981842, train/logprobs = tensor([[-1.7222, -4.4792],
        [-3.2207, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30550140142440796
Epoch 0, Step 743: train/loss = 0.296814501285553, train/raw-loss = 0.2578551173210144, train/logprobs = tensor([[-1.0951, -4.4777],
        [-2.8449, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3895938992500305
Epoch 0, Step 744: train/loss = 0.5019454956054688, train/raw-loss = 0.4667817950248718, train/logprobs = tensor([[-1.6538, -2.3765],
        [-2.7127, -1.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35163652896881104
Epoch 0, Step 745: train/loss = 0.35527071356773376, train/raw-loss = 0.3225109577178955, train/logprobs = tensor([[-1.6683, -2.3189],
        [-3.0716, -0.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3275974988937378
Epoch 0, Step 746: train/loss = 0.4766412675380707, train/raw-loss = 0.42846858501434326, train/logprobs = tensor([[-1.7305, -3.2587],
        [-3.0908, -1.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48172661662101746
Epoch 0, Step 747: train/loss = 0.3885628581047058, train/raw-loss = 0.3398759067058563, train/logprobs = tensor([[-1.1102, -5.1081],
        [-1.8261, -1.5413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4868695139884949
Epoch 0, Step 748: train/loss = 0.36261337995529175, train/raw-loss = 0.3308833837509155, train/logprobs = tensor([[-1.6917, -3.0270],
        [-3.0266, -1.2855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31730008125305176
Epoch 0, Step 749: train/loss = 0.42527467012405396, train/raw-loss = 0.38371366262435913, train/logprobs = tensor([[-1.6217, -4.6351],
        [-2.5713, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4156101942062378
Epoch 0, Step 750: train/loss = 0.5502265691757202, train/raw-loss = 0.512934148311615, train/logprobs = tensor([[-1.6157, -2.5225],
        [-2.0058, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729245066642761
Epoch 0, Step 751: train/loss = 0.2954615354537964, train/raw-loss = 0.2608402371406555, train/logprobs = tensor([[-1.0936, -4.7997],
        [-2.1431, -1.3039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3462130129337311
Epoch 0, Step 752: train/loss = 0.29139214754104614, train/raw-loss = 0.2515258193016052, train/logprobs = tensor([[-1.0150, -4.9066],
        [-2.3408, -1.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3986629247665405
Epoch 0, Step 753: train/loss = 0.5357100367546082, train/raw-loss = 0.49119341373443604, train/logprobs = tensor([[-1.8221, -3.0680],
        [-2.6061, -1.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4451664686203003
Epoch 0, Step 754: train/loss = 0.27222228050231934, train/raw-loss = 0.23396946489810944, train/logprobs = tensor([[-1.6477, -4.2954],
        [-3.4335, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3825283348560333
Epoch 0, Step 755: train/loss = 0.33115819096565247, train/raw-loss = 0.2968251407146454, train/logprobs = tensor([[-0.9645, -4.2415],
        [-2.2361, -0.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433303236961365
Epoch 0, Step 756: train/loss = 0.44003385305404663, train/raw-loss = 0.3984319567680359, train/logprobs = tensor([[-1.9615, -4.3822],
        [-2.2722, -1.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41601836681365967
Epoch 0, Step 757: train/loss = 0.44321683049201965, train/raw-loss = 0.39451003074645996, train/logprobs = tensor([[-1.2076, -3.2217],
        [-2.2300, -1.4519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48706793785095215
Epoch 0, Step 758: train/loss = 0.26169145107269287, train/raw-loss = 0.22188091278076172, train/logprobs = tensor([[-1.5761, -6.5718],
        [-2.0938, -1.1330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3981054425239563
Epoch 0, Step 759: train/loss = 0.5737781524658203, train/raw-loss = 0.5298378467559814, train/logprobs = tensor([[-1.2378, -2.6181],
        [-2.0397, -1.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43940305709838867
Epoch 0, Step 760: train/loss = 0.3566940128803253, train/raw-loss = 0.3235759735107422, train/logprobs = tensor([[-1.9958, -4.4020],
        [-2.3606, -1.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33118051290512085
Epoch 0, Step 761: train/loss = 0.5510545969009399, train/raw-loss = 0.5099514722824097, train/logprobs = tensor([[-1.3652, -1.8920],
        [-3.2832, -1.3731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4110315442085266
Epoch 0, Step 762: train/loss = 0.45743680000305176, train/raw-loss = 0.4056386649608612, train/logprobs = tensor([[-1.1792, -3.7069],
        [-2.6476, -2.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5179810523986816
Epoch 0, Step 763: train/loss = 0.6164466142654419, train/raw-loss = 0.5684857368469238, train/logprobs = tensor([[-0.9580, -2.5775],
        [-1.8835, -1.5170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47960877418518066
Epoch 0, Step 764: train/loss = 0.4136297404766083, train/raw-loss = 0.37638866901397705, train/logprobs = tensor([[-0.9749, -3.5150],
        [-2.1190, -1.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37241071462631226
Epoch 0, Step 765: train/loss = 0.21048937737941742, train/raw-loss = 0.16727712750434875, train/logprobs = tensor([[-1.4992, -4.9892],
        [-4.4967, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43212252855300903
Epoch 0, Step 766: train/loss = 0.48882436752319336, train/raw-loss = 0.45977726578712463, train/logprobs = tensor([[-1.3643, -4.3328],
        [-2.6028, -2.3906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29047098755836487
Epoch 0, Step 767: train/loss = 0.168345108628273, train/raw-loss = 0.13317203521728516, train/logprobs = tensor([[-1.6478, -4.2873],
        [-5.3092, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3517307639122009
Epoch 0, Step 768: train/loss = 0.6185530424118042, train/raw-loss = 0.5780411958694458, train/logprobs = tensor([[-1.8089, -2.9413],
        [-5.3163, -2.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40511852502822876
Epoch 0, Step 769: train/loss = 0.22852033376693726, train/raw-loss = 0.19267216324806213, train/logprobs = tensor([[-2.0747, -3.9259],
        [-5.0279, -1.5229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3584817051887512
Epoch 0, Step 770: train/loss = 0.34811270236968994, train/raw-loss = 0.31221064925193787, train/logprobs = tensor([[-1.1905, -3.3043],
        [-2.4674, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3590207099914551
Epoch 0, Step 771: train/loss = 0.5322157144546509, train/raw-loss = 0.4956534504890442, train/logprobs = tensor([[-1.3174, -3.6083],
        [-1.7361, -1.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36562296748161316
Epoch 0, Step 772: train/loss = 0.3867221474647522, train/raw-loss = 0.3501448631286621, train/logprobs = tensor([[-2.4463, -3.5507],
        [-4.3470, -1.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3657727539539337
Epoch 0, Step 773: train/loss = 0.18396788835525513, train/raw-loss = 0.13919563591480255, train/logprobs = tensor([[-1.0098, -6.2277],
        [-2.1173, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477223753929138
Epoch 0, Step 774: train/loss = 0.3169405162334442, train/raw-loss = 0.2666078507900238, train/logprobs = tensor([[-0.9852, -4.4244],
        [-3.1953, -1.4063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5033266544342041
Epoch 0, Step 775: train/loss = 0.4653257131576538, train/raw-loss = 0.426164448261261, train/logprobs = tensor([[-1.4113, -3.7789],
        [-2.7844, -2.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3916124999523163
Epoch 0, Step 776: train/loss = 0.45204222202301025, train/raw-loss = 0.41169217228889465, train/logprobs = tensor([[-1.8332, -2.3995],
        [-3.5522, -2.0393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4035005569458008
Epoch 0, Step 777: train/loss = 0.25790300965309143, train/raw-loss = 0.22139203548431396, train/logprobs = tensor([[-0.6649, -5.4254],
        [-1.3510, -1.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651098310947418
Epoch 0, Step 778: train/loss = 0.21007074415683746, train/raw-loss = 0.16827012598514557, train/logprobs = tensor([[-1.1417, -6.5800],
        [-2.0026, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4180060923099518
Epoch 0, Step 779: train/loss = 0.5078828930854797, train/raw-loss = 0.47168830037117004, train/logprobs = tensor([[-1.3652, -2.9889],
        [-2.1977, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36194539070129395
Epoch 0, Step 780: train/loss = 0.3387914299964905, train/raw-loss = 0.2947857677936554, train/logprobs = tensor([[-1.4981, -5.0816],
        [-2.5750, -1.4876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4400564730167389
Epoch 0, Step 781: train/loss = 0.272582083940506, train/raw-loss = 0.23252509534358978, train/logprobs = tensor([[-1.5916, -4.5056],
        [-2.8669, -1.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40056973695755005
Epoch 0, Step 782: train/loss = 0.20693527162075043, train/raw-loss = 0.16919392347335815, train/logprobs = tensor([[-1.4086, -4.4995],
        [-3.9290, -1.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3774135708808899
Epoch 0, Step 783: train/loss = 0.362194299697876, train/raw-loss = 0.32689958810806274, train/logprobs = tensor([[-2.9146, -6.0609],
        [-3.9773, -2.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.352946937084198
Epoch 0, Step 784: train/loss = 0.217276930809021, train/raw-loss = 0.1826799213886261, train/logprobs = tensor([[-1.1906, -5.8379],
        [-2.8170, -1.7929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3459702730178833
Epoch 0, Step 785: train/loss = 0.31764334440231323, train/raw-loss = 0.27996736764907837, train/logprobs = tensor([[-1.0477, -3.8657],
        [-2.4183, -0.9129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767601251602173
Epoch 0, Step 786: train/loss = 0.3603331446647644, train/raw-loss = 0.3127937912940979, train/logprobs = tensor([[-1.0306, -5.1638],
        [-1.9050, -1.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4753931164741516
Epoch 0, Step 787: train/loss = 0.4764271676540375, train/raw-loss = 0.432062566280365, train/logprobs = tensor([[-1.1371, -3.6108],
        [-2.6767, -2.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4436461329460144
Epoch 0, Step 788: train/loss = 0.2975754737854004, train/raw-loss = 0.2624218165874481, train/logprobs = tensor([[-1.8806, -5.0872],
        [-3.1068, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3515366315841675
Epoch 0, Step 789: train/loss = 0.5026654601097107, train/raw-loss = 0.4694879353046417, train/logprobs = tensor([[-2.7054, -3.8234],
        [-3.2526, -1.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33177539706230164
Epoch 0, Step 790: train/loss = 0.4596056640148163, train/raw-loss = 0.414375364780426, train/logprobs = tensor([[-0.9187, -3.1102],
        [-2.0830, -1.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4523027539253235
Epoch 0, Step 791: train/loss = 0.1328621506690979, train/raw-loss = 0.09224649518728256, train/logprobs = tensor([[-1.5988, -5.7431],
        [-4.5723, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40615665912628174
Epoch 0, Step 792: train/loss = 0.45367804169654846, train/raw-loss = 0.41751059889793396, train/logprobs = tensor([[-1.8198, -4.3984],
        [-2.7239, -1.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36167463660240173
Epoch 0, Step 793: train/loss = 0.3482508063316345, train/raw-loss = 0.3170655071735382, train/logprobs = tensor([[-1.0315, -4.9551],
        [-1.4954, -1.0280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3118531405925751
Epoch 0, Step 794: train/loss = 0.2805462181568146, train/raw-loss = 0.24121952056884766, train/logprobs = tensor([[-1.7022, -4.1758],
        [-2.7647, -1.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3932665288448334
Epoch 0, Step 795: train/loss = 0.28205740451812744, train/raw-loss = 0.24440278112888336, train/logprobs = tensor([[-1.6162, -5.8313],
        [-2.4583, -1.5534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765462636947632
Epoch 0, Step 796: train/loss = 0.3130510449409485, train/raw-loss = 0.2718100845813751, train/logprobs = tensor([[-1.1551, -5.4576],
        [-1.9143, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41240933537483215
Epoch 0, Step 797: train/loss = 0.4388695955276489, train/raw-loss = 0.39296406507492065, train/logprobs = tensor([[-1.1027, -2.7798],
        [-2.5145, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45905524492263794
Epoch 0, Step 798: train/loss = 0.31133773922920227, train/raw-loss = 0.2650463581085205, train/logprobs = tensor([[-1.5620, -4.5510],
        [-2.8800, -1.2978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46291404962539673
Epoch 0, Step 799: train/loss = 0.2542976140975952, train/raw-loss = 0.21427549421787262, train/logprobs = tensor([[-1.5293, -3.1003],
        [-3.6394, -1.3181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40022122859954834
Epoch 0, Step 800: train/loss = 0.3275452256202698, train/raw-loss = 0.2901620864868164, train/logprobs = tensor([[-1.4337, -3.6045],
        [-2.6111, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37383121252059937
Epoch 0, Step 801: train/loss = 0.2665010094642639, train/raw-loss = 0.22953878343105316, train/logprobs = tensor([[-1.4006, -4.1678],
        [-3.4750, -1.3650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3696221113204956
Epoch 0, Step 802: train/loss = 0.24105392396450043, train/raw-loss = 0.2053016573190689, train/logprobs = tensor([[-1.9759, -4.0741],
        [-3.0972, -1.3383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35752272605895996
Epoch 0, Step 803: train/loss = 0.1627582609653473, train/raw-loss = 0.1287287324666977, train/logprobs = tensor([[-1.7691, -6.3921],
        [-4.1288, -1.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34029528498649597
Epoch 0, Step 804: train/loss = 0.37359216809272766, train/raw-loss = 0.3385355472564697, train/logprobs = tensor([[-1.6681, -5.3933],
        [-3.1042, -0.8511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3505658507347107
Epoch 0, Step 805: train/loss = 0.5203901529312134, train/raw-loss = 0.49749326705932617, train/logprobs = tensor([[-2.1393, -4.3871],
        [-2.2165, -2.5366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22896891832351685
Epoch 0, Step 806: train/loss = 0.3747655153274536, train/raw-loss = 0.33891549706459045, train/logprobs = tensor([[-2.7287, -6.0084],
        [-2.9834, -0.9706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35850024223327637
Epoch 0, Step 807: train/loss = 0.4271191358566284, train/raw-loss = 0.3905164897441864, train/logprobs = tensor([[-0.9316, -2.9943],
        [-1.7979, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3660264313220978
Epoch 0, Step 808: train/loss = 0.2650432884693146, train/raw-loss = 0.22955948114395142, train/logprobs = tensor([[-2.1557, -4.2240],
        [-3.5138, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35483822226524353
Epoch 0, Step 809: train/loss = 0.2418264001607895, train/raw-loss = 0.20323243737220764, train/logprobs = tensor([[-1.6703, -4.4960],
        [-3.3879, -2.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38593950867652893
Epoch 0, Step 810: train/loss = 0.2886132001876831, train/raw-loss = 0.2491830289363861, train/logprobs = tensor([[-1.4291, -3.7796],
        [-3.3549, -1.5675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3943018913269043
Epoch 0, Step 811: train/loss = 0.2606201767921448, train/raw-loss = 0.21584323048591614, train/logprobs = tensor([[-1.1932, -5.1325],
        [-3.7316, -1.2397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477697014808655
Epoch 0, Step 812: train/loss = 0.16232115030288696, train/raw-loss = 0.1194409728050232, train/logprobs = tensor([[-2.2200, -5.4127],
        [-5.3379, -1.5499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42880183458328247
Epoch 0, Step 813: train/loss = 0.43688341975212097, train/raw-loss = 0.410617470741272, train/logprobs = tensor([[-1.7577, -2.2146],
        [-4.3136, -1.5148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26265954971313477
Epoch 0, Step 814: train/loss = 0.36253049969673157, train/raw-loss = 0.32042068243026733, train/logprobs = tensor([[-1.6428, -5.1645],
        [-2.1726, -0.9095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4210982024669647
Epoch 0, Step 815: train/loss = 0.1694708615541458, train/raw-loss = 0.13169074058532715, train/logprobs = tensor([[-1.2970, -6.4956],
        [-3.1095, -1.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37780123949050903
Epoch 0, Step 816: train/loss = 0.1667381376028061, train/raw-loss = 0.1269533783197403, train/logprobs = tensor([[-1.7145, -5.4183],
        [-3.7569, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3978475034236908
Epoch 0, Step 817: train/loss = 0.3857864737510681, train/raw-loss = 0.3507711887359619, train/logprobs = tensor([[-2.0508, -3.4912],
        [-4.3358, -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35015252232551575
Epoch 0, Step 818: train/loss = 0.27271509170532227, train/raw-loss = 0.22667580842971802, train/logprobs = tensor([[-1.6356, -5.1107],
        [-3.1801, -1.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4603927433490753
Epoch 0, Step 819: train/loss = 0.25402963161468506, train/raw-loss = 0.21142110228538513, train/logprobs = tensor([[-2.2694, -5.8419],
        [-3.7842, -1.3164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4260852336883545
Epoch 0, Step 820: train/loss = 0.3069632053375244, train/raw-loss = 0.2783721685409546, train/logprobs = tensor([[-1.8445, -6.8874],
        [-2.4733, -2.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2859102487564087
Epoch 0, Step 821: train/loss = 0.24715456366539001, train/raw-loss = 0.20387476682662964, train/logprobs = tensor([[-1.5739, -4.7689],
        [-2.6956, -1.3298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4327980875968933
Epoch 0, Step 822: train/loss = 0.40169426798820496, train/raw-loss = 0.3643665909767151, train/logprobs = tensor([[-1.6664, -4.6258],
        [-2.2622, -1.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3732769787311554
Epoch 0, Step 823: train/loss = 0.2986808121204376, train/raw-loss = 0.2576644718647003, train/logprobs = tensor([[-1.2281, -3.2804],
        [-3.7557, -1.4488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4101629853248596
Epoch 0, Step 824: train/loss = 0.16349497437477112, train/raw-loss = 0.12367156147956848, train/logprobs = tensor([[-1.5916, -6.9565],
        [-3.6281, -1.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3982342481613159
Epoch 0, Step 825: train/loss = 0.29385459423065186, train/raw-loss = 0.2668421268463135, train/logprobs = tensor([[-1.9951, -3.8827],
        [-4.6675, -1.4823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.270124614238739
Epoch 0, Step 826: train/loss = 0.5698056221008301, train/raw-loss = 0.5389713048934937, train/logprobs = tensor([[-3.3694, -8.1094],
        [-3.0475, -5.6919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30834317207336426
Epoch 0, Step 827: train/loss = 0.4527197480201721, train/raw-loss = 0.4154224991798401, train/logprobs = tensor([[-2.3374, -3.5942],
        [-3.3169, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3729725480079651
Epoch 0, Step 828: train/loss = 0.5025545954704285, train/raw-loss = 0.46389928460121155, train/logprobs = tensor([[-1.0924, -3.2943],
        [-1.6626, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38655340671539307
Epoch 0, Step 829: train/loss = 0.42252597212791443, train/raw-loss = 0.3822357952594757, train/logprobs = tensor([[-1.9416, -5.9946],
        [-2.2250, -1.6986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4029020369052887
Epoch 0, Step 830: train/loss = 0.7244328856468201, train/raw-loss = 0.6882107853889465, train/logprobs = tensor([[-2.0591, -4.7068],
        [-6.0766, -3.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36222144961357117
Epoch 0, Step 831: train/loss = 0.4267991781234741, train/raw-loss = 0.3885928988456726, train/logprobs = tensor([[-1.6702, -5.6585],
        [-3.4615, -2.7354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3820628523826599
Epoch 0, Step 832: train/loss = 0.47391462326049805, train/raw-loss = 0.4344708323478699, train/logprobs = tensor([[-0.7648, -4.5673],
        [-1.2942, -1.4811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.394438236951828
Epoch 0, Step 833: train/loss = 0.6195992827415466, train/raw-loss = 0.5828141570091248, train/logprobs = tensor([[-3.3072, -6.0883],
        [-2.8381, -1.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36785128712654114
Epoch 0, Step 834: train/loss = 0.4593103229999542, train/raw-loss = 0.41723811626434326, train/logprobs = tensor([[-1.7062, -3.2617],
        [-2.1945, -1.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42072194814682007
Epoch 0, Step 835: train/loss = 0.331734836101532, train/raw-loss = 0.28757908940315247, train/logprobs = tensor([[-1.6794, -3.5269],
        [-2.8702, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44155752658843994
Epoch 0, Step 836: train/loss = 0.35727086663246155, train/raw-loss = 0.31198662519454956, train/logprobs = tensor([[-1.6038, -2.9148],
        [-3.7776, -1.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4528425335884094
Epoch 0, Step 837: train/loss = 0.46243172883987427, train/raw-loss = 0.420183926820755, train/logprobs = tensor([[-0.9723, -3.3685],
        [-1.8909, -1.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42247796058654785
Epoch 0, Step 838: train/loss = 0.4200863838195801, train/raw-loss = 0.37962716817855835, train/logprobs = tensor([[-1.1320, -1.8705],
        [-3.2889, -1.4815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40459224581718445
Epoch 0, Step 839: train/loss = 0.4237211346626282, train/raw-loss = 0.3899635672569275, train/logprobs = tensor([[-1.5278, -2.5939],
        [-3.8451, -1.4511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33757543563842773
Epoch 0, Step 840: train/loss = 0.5137666463851929, train/raw-loss = 0.46959546208381653, train/logprobs = tensor([[-1.6387, -3.7152],
        [-1.8176, -1.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44171208143234253
Epoch 0, Step 841: train/loss = 0.29258716106414795, train/raw-loss = 0.2547248899936676, train/logprobs = tensor([[-0.9834, -4.9698],
        [-2.1494, -1.5024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3786228597164154
Epoch 0, Step 842: train/loss = 0.8073131442070007, train/raw-loss = 0.7626245021820068, train/logprobs = tensor([[-2.9046, -4.6880],
        [-2.3151, -1.6562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44688671827316284
Epoch 0, Step 843: train/loss = 0.276838093996048, train/raw-loss = 0.2388208508491516, train/logprobs = tensor([[-2.2080, -3.5327],
        [-4.3116, -1.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.380172461271286
Epoch 0, Step 844: train/loss = 0.31327497959136963, train/raw-loss = 0.2657965421676636, train/logprobs = tensor([[-1.7282, -4.2795],
        [-3.4126, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47478440403938293
Epoch 0, Step 845: train/loss = 0.15782511234283447, train/raw-loss = 0.1141100823879242, train/logprobs = tensor([[-1.4334, -6.1068],
        [-2.8529, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43715032935142517
Epoch 0, Step 846: train/loss = 0.4225388467311859, train/raw-loss = 0.38502320647239685, train/logprobs = tensor([[-0.9287, -3.5451],
        [-1.7777, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3751562237739563
Epoch 0, Step 847: train/loss = 0.5298731923103333, train/raw-loss = 0.49497008323669434, train/logprobs = tensor([[-1.5770, -3.4946],
        [-2.4619, -1.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3490310609340668
Epoch 0, Step 848: train/loss = 0.20916739106178284, train/raw-loss = 0.16463497281074524, train/logprobs = tensor([[-1.1633, -6.5163],
        [-2.9854, -1.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44532403349876404
Epoch 0, Step 849: train/loss = 0.22628849744796753, train/raw-loss = 0.1839134842157364, train/logprobs = tensor([[-1.4971, -4.5684],
        [-3.0365, -1.2152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42375022172927856
Epoch 0, Step 850: train/loss = 0.5913915634155273, train/raw-loss = 0.5599163770675659, train/logprobs = tensor([[-1.0104, -1.9585],
        [-1.4105, -1.4111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3147520124912262
Epoch 0, Step 851: train/loss = 0.4145607352256775, train/raw-loss = 0.3775085210800171, train/logprobs = tensor([[-2.9288, -5.0693],
        [-4.2937, -2.3221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37052199244499207
Epoch 0, Step 852: train/loss = 0.36256521940231323, train/raw-loss = 0.3193920850753784, train/logprobs = tensor([[-0.7060, -6.5566],
        [-1.6528, -2.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4317311644554138
Epoch 0, Step 853: train/loss = 0.6207301616668701, train/raw-loss = 0.5922071933746338, train/logprobs = tensor([[-1.1709, -2.3703],
        [-1.3418, -1.3364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2852293848991394
Epoch 0, Step 854: train/loss = 0.4723193943500519, train/raw-loss = 0.4362650513648987, train/logprobs = tensor([[-1.1258, -2.2949],
        [-1.6096, -1.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36054325103759766
Epoch 0, Step 855: train/loss = 0.4515398144721985, train/raw-loss = 0.41825172305107117, train/logprobs = tensor([[-1.6677, -2.6126],
        [-2.4976, -1.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3328811526298523
Epoch 0, Step 856: train/loss = 0.26860105991363525, train/raw-loss = 0.2332320213317871, train/logprobs = tensor([[-1.6153, -5.7582],
        [-2.6264, -1.6324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35369035601615906
Epoch 0, Step 857: train/loss = 0.22392506897449493, train/raw-loss = 0.19155555963516235, train/logprobs = tensor([[-1.2894, -6.2768],
        [-2.2222, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32369518280029297
Epoch 0, Step 858: train/loss = 0.21995753049850464, train/raw-loss = 0.17902256548404694, train/logprobs = tensor([[-0.9904, -5.8804],
        [-2.8275, -1.5103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4093495011329651
Epoch 0, Step 859: train/loss = 0.36724066734313965, train/raw-loss = 0.3264853060245514, train/logprobs = tensor([[-1.4977, -3.8367],
        [-3.0650, -1.2484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40755367279052734
Epoch 0, Step 860: train/loss = 0.433361679315567, train/raw-loss = 0.3908471465110779, train/logprobs = tensor([[-1.2382, -3.3411],
        [-2.3958, -1.6112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42514553666114807
Epoch 0, Step 861: train/loss = 0.26308372616767883, train/raw-loss = 0.22647792100906372, train/logprobs = tensor([[-1.9020, -5.9739],
        [-2.8929, -1.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36605799198150635
Epoch 0, Step 862: train/loss = 0.4723243713378906, train/raw-loss = 0.43236249685287476, train/logprobs = tensor([[-1.6619, -3.7064],
        [-2.0863, -1.4059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3996184766292572
Epoch 0, Step 863: train/loss = 0.5762215852737427, train/raw-loss = 0.5427738428115845, train/logprobs = tensor([[-2.2800, -4.3736],
        [-2.8937, -1.2929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3344777822494507
Epoch 0, Step 864: train/loss = 0.43726494908332825, train/raw-loss = 0.3958543539047241, train/logprobs = tensor([[-2.2842, -4.7242],
        [-2.8431, -1.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4141058325767517
Epoch 0, Step 865: train/loss = 0.36644357442855835, train/raw-loss = 0.3401225805282593, train/logprobs = tensor([[-0.9907, -4.4269],
        [-1.6687, -1.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26321011781692505
Epoch 0, Step 866: train/loss = 0.29210707545280457, train/raw-loss = 0.24962419271469116, train/logprobs = tensor([[-1.3063, -4.1187],
        [-3.0792, -1.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4248286485671997
Epoch 0, Step 867: train/loss = 0.3440907299518585, train/raw-loss = 0.30563580989837646, train/logprobs = tensor([[-1.4531, -5.2648],
        [-2.0269, -2.3464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3845493793487549
Epoch 0, Step 868: train/loss = 0.4442441463470459, train/raw-loss = 0.3979601263999939, train/logprobs = tensor([[-1.1766, -2.0883],
        [-3.2975, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46284016966819763
Epoch 0, Step 869: train/loss = 0.2584972679615021, train/raw-loss = 0.2224217802286148, train/logprobs = tensor([[-1.3715, -2.8237],
        [-3.8827, -1.0541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36075493693351746
Epoch 0, Step 870: train/loss = 0.27262818813323975, train/raw-loss = 0.23535068333148956, train/logprobs = tensor([[-1.9770, -3.7454],
        [-4.1483, -1.5201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3727751076221466
Epoch 0, Step 871: train/loss = 0.49400219321250916, train/raw-loss = 0.43903133273124695, train/logprobs = tensor([[-1.1391, -2.2544],
        [-2.8013, -1.6590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.549708366394043
Epoch 0, Step 872: train/loss = 0.5583274960517883, train/raw-loss = 0.5223644971847534, train/logprobs = tensor([[-1.4546, -1.8216],
        [-2.1040, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35962995886802673
Epoch 0, Step 873: train/loss = 0.3045918047428131, train/raw-loss = 0.2646790146827698, train/logprobs = tensor([[-1.6551, -4.2809],
        [-3.5110, -1.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3991282880306244
Epoch 0, Step 874: train/loss = 0.4414598047733307, train/raw-loss = 0.40516722202301025, train/logprobs = tensor([[-0.9770, -2.5609],
        [-2.9152, -1.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3629258871078491
Epoch 0, Step 875: train/loss = 0.6430856585502625, train/raw-loss = 0.5939061641693115, train/logprobs = tensor([[-1.4549, -2.2166],
        [-1.7083, -1.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49179473519325256
Epoch 0, Step 876: train/loss = 0.18767088651657104, train/raw-loss = 0.14656145870685577, train/logprobs = tensor([[-1.4539, -6.5305],
        [-2.5318, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4110943377017975
Epoch 0, Step 877: train/loss = 0.4135885536670685, train/raw-loss = 0.381527841091156, train/logprobs = tensor([[-1.1093, -2.2010],
        [-2.2772, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32060739398002625
Epoch 0, Step 878: train/loss = 0.3582618832588196, train/raw-loss = 0.3171405792236328, train/logprobs = tensor([[-1.3864, -5.0295],
        [-2.7826, -1.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41121330857276917
Epoch 0, Step 879: train/loss = 0.26700228452682495, train/raw-loss = 0.2234135866165161, train/logprobs = tensor([[-1.9195, -5.6201],
        [-2.4784, -1.6617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.435886949300766
Epoch 0, Step 880: train/loss = 0.6105966567993164, train/raw-loss = 0.5736233592033386, train/logprobs = tensor([[-1.6354, -3.2006],
        [-2.4764, -2.4475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36973297595977783
Epoch 0, Step 881: train/loss = 0.14085079729557037, train/raw-loss = 0.09998126327991486, train/logprobs = tensor([[-1.9156, -5.0519],
        [-5.3665, -1.0679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40869539976119995
Epoch 0, Step 882: train/loss = 0.1787962019443512, train/raw-loss = 0.13953253626823425, train/logprobs = tensor([[-1.6391, -5.4741],
        [-3.3035, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39263659715652466
Epoch 0, Step 883: train/loss = 0.2929077744483948, train/raw-loss = 0.25525590777397156, train/logprobs = tensor([[-1.4595, -4.6404],
        [-3.1820, -1.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3765185475349426
Epoch 0, Step 884: train/loss = 0.23399558663368225, train/raw-loss = 0.1979871392250061, train/logprobs = tensor([[-1.2792, -3.8837],
        [-3.3292, -1.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3600843548774719
Epoch 0, Step 885: train/loss = 0.46514692902565, train/raw-loss = 0.43359076976776123, train/logprobs = tensor([[-1.4694, -3.1631],
        [-2.2696, -1.4745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3155616521835327
Epoch 0, Step 886: train/loss = 0.21921709179878235, train/raw-loss = 0.18524181842803955, train/logprobs = tensor([[-1.8862, -4.8594],
        [-3.6105, -1.5278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33975285291671753
Epoch 0, Step 887: train/loss = 0.7812672853469849, train/raw-loss = 0.7487645149230957, train/logprobs = tensor([[-3.8061, -4.9540],
        [-3.8954, -1.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3250269591808319
Epoch 0, Step 888: train/loss = 0.18464729189872742, train/raw-loss = 0.1394655555486679, train/logprobs = tensor([[-0.9592, -5.4830],
        [-2.8875, -1.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45181721448898315
Epoch 0, Step 889: train/loss = 0.2873828411102295, train/raw-loss = 0.254419207572937, train/logprobs = tensor([[-1.9461, -4.5765],
        [-4.3234, -1.9932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32963648438453674
Epoch 0, Step 890: train/loss = 0.5366569757461548, train/raw-loss = 0.5009061098098755, train/logprobs = tensor([[-1.2728, -2.8601],
        [-1.6822, -1.3980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3575092554092407
Epoch 0, Step 891: train/loss = 0.40780219435691833, train/raw-loss = 0.3711908161640167, train/logprobs = tensor([[-1.1514, -3.4634],
        [-2.0562, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36611369252204895
Epoch 0, Step 892: train/loss = 0.5341638326644897, train/raw-loss = 0.5007120966911316, train/logprobs = tensor([[-1.8484, -3.7187],
        [-1.9832, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33451732993125916
Epoch 0, Step 893: train/loss = 0.4031445384025574, train/raw-loss = 0.3645373284816742, train/logprobs = tensor([[-0.7497, -3.6436],
        [-1.8690, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38607215881347656
Epoch 0, Step 894: train/loss = 0.36447134613990784, train/raw-loss = 0.3257618248462677, train/logprobs = tensor([[-2.1495, -3.8766],
        [-4.3752, -2.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3870950937271118
Epoch 0, Step 895: train/loss = 0.3071244955062866, train/raw-loss = 0.2749731242656708, train/logprobs = tensor([[-1.7645, -4.2721],
        [-3.8757, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3215136229991913
Epoch 0, Step 896: train/loss = 0.3028991222381592, train/raw-loss = 0.2572126090526581, train/logprobs = tensor([[-1.5277, -3.4872],
        [-3.3381, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45686501264572144
Epoch 0, Step 897: train/loss = 0.4658430516719818, train/raw-loss = 0.43253493309020996, train/logprobs = tensor([[-0.9585, -4.3511],
        [-1.1858, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3330814242362976
Epoch 0, Step 898: train/loss = 0.1346602439880371, train/raw-loss = 0.08948235213756561, train/logprobs = tensor([[-1.2838, -6.7880],
        [-3.1333, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4517790377140045
Epoch 0, Step 899: train/loss = 0.15535759925842285, train/raw-loss = 0.11609775573015213, train/logprobs = tensor([[-1.3393, -5.6934],
        [-3.1309, -0.9380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3925984799861908
Epoch 0, Step 900: train/loss = 0.6976284980773926, train/raw-loss = 0.6629683375358582, train/logprobs = tensor([[-0.9950, -3.5836],
        [-1.5113, -2.2508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3466021418571472
Epoch 0, Step 901: train/loss = 0.1946628987789154, train/raw-loss = 0.15418025851249695, train/logprobs = tensor([[-1.5617, -4.4368],
        [-3.5146, -0.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40482625365257263
Epoch 0, Step 902: train/loss = 0.2915599048137665, train/raw-loss = 0.2613331079483032, train/logprobs = tensor([[-1.2041, -2.9323],
        [-3.4526, -1.3068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30226773023605347
Epoch 0, Step 903: train/loss = 0.22230854630470276, train/raw-loss = 0.18078391253948212, train/logprobs = tensor([[-1.2230, -5.4108],
        [-3.2104, -1.0213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4152463376522064
Epoch 0, Step 904: train/loss = 0.19703993201255798, train/raw-loss = 0.15917529165744781, train/logprobs = tensor([[-1.1747, -5.4616],
        [-2.9121, -1.5752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3786463737487793
Epoch 0, Step 905: train/loss = 0.22884202003479004, train/raw-loss = 0.1901579201221466, train/logprobs = tensor([[-2.2613, -6.1471],
        [-3.8209, -1.5157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38684090971946716
Epoch 0, Step 906: train/loss = 0.40591222047805786, train/raw-loss = 0.37263548374176025, train/logprobs = tensor([[-1.5900, -2.5290],
        [-2.8778, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33276718854904175
Epoch 0, Step 907: train/loss = 0.2954411804676056, train/raw-loss = 0.24361510574817657, train/logprobs = tensor([[-1.2900, -4.2683],
        [-2.6375, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.518260657787323
Epoch 0, Step 908: train/loss = 0.30610138177871704, train/raw-loss = 0.2617906928062439, train/logprobs = tensor([[-2.0740, -2.8999],
        [-5.4874, -1.5719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4431068003177643
Epoch 0, Step 909: train/loss = 0.11857564747333527, train/raw-loss = 0.07674175500869751, train/logprobs = tensor([[-1.8078, -5.9583],
        [-4.8213, -1.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41833895444869995
Epoch 0, Step 910: train/loss = 0.19465145468711853, train/raw-loss = 0.16090229153633118, train/logprobs = tensor([[-1.3749, -6.7948],
        [-2.8600, -1.1355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33749157190322876
Epoch 0, Step 911: train/loss = 0.24453985691070557, train/raw-loss = 0.201867014169693, train/logprobs = tensor([[-1.3794, -5.9656],
        [-2.1189, -1.3397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42672842741012573
Epoch 0, Step 912: train/loss = 0.4221287965774536, train/raw-loss = 0.3823045492172241, train/logprobs = tensor([[-1.8273, -1.7004],
        [-5.4849, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3982425928115845
Epoch 0, Step 913: train/loss = 0.307415634393692, train/raw-loss = 0.26643335819244385, train/logprobs = tensor([[-1.2614, -3.5722],
        [-2.6862, -1.4204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40982288122177124
Epoch 0, Step 914: train/loss = 0.22240501642227173, train/raw-loss = 0.17867574095726013, train/logprobs = tensor([[-1.3601, -5.9373],
        [-2.4829, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4372928738594055
Epoch 0, Step 915: train/loss = 0.22466756403446198, train/raw-loss = 0.1910405457019806, train/logprobs = tensor([[-1.0108, -4.0410],
        [-2.7177, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3362703323364258
Epoch 0, Step 916: train/loss = 0.32825762033462524, train/raw-loss = 0.29183056950569153, train/logprobs = tensor([[-1.6387, -4.0736],
        [-2.6960, -1.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36427024006843567
Epoch 0, Step 917: train/loss = 0.396220326423645, train/raw-loss = 0.355367511510849, train/logprobs = tensor([[-1.6129, -3.5351],
        [-2.7585, -1.6635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40852856636047363
Epoch 0, Step 918: train/loss = 0.22724826633930206, train/raw-loss = 0.18698129057884216, train/logprobs = tensor([[-1.6456, -5.1944],
        [-4.8875, -1.7994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4026698172092438
Epoch 0, Step 919: train/loss = 0.45320406556129456, train/raw-loss = 0.4115314483642578, train/logprobs = tensor([[-1.7433, -2.9649],
        [-3.4517, -2.3119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41672593355178833
Epoch 0, Step 920: train/loss = 0.43824997544288635, train/raw-loss = 0.4061833620071411, train/logprobs = tensor([[-2.3117, -3.4784],
        [-3.0569, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32066598534584045
Epoch 0, Step 921: train/loss = 0.3472658693790436, train/raw-loss = 0.307338148355484, train/logprobs = tensor([[-0.9285, -3.7982],
        [-2.4978, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3992770314216614
Epoch 0, Step 922: train/loss = 0.34334006905555725, train/raw-loss = 0.3072500228881836, train/logprobs = tensor([[-1.6362, -1.9250],
        [-4.5429, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3609004020690918
Epoch 0, Step 923: train/loss = 0.2629455327987671, train/raw-loss = 0.22235146164894104, train/logprobs = tensor([[-1.4907, -5.2247],
        [-3.2328, -1.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4059406518936157
Epoch 0, Step 924: train/loss = 0.17959849536418915, train/raw-loss = 0.13897907733917236, train/logprobs = tensor([[-1.3916, -4.0710],
        [-4.3689, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4061940610408783
Epoch 0, Step 925: train/loss = 0.2015889436006546, train/raw-loss = 0.160335510969162, train/logprobs = tensor([[-1.6899, -7.1125],
        [-2.8981, -1.9792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41253429651260376
Epoch 0, Step 926: train/loss = 0.12111017107963562, train/raw-loss = 0.08265861868858337, train/logprobs = tensor([[-1.0630, -8.5571],
        [-3.3110, -1.5261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38451552391052246
Epoch 0, Step 927: train/loss = 0.21486800909042358, train/raw-loss = 0.17846862971782684, train/logprobs = tensor([[-2.0379, -5.1363],
        [-3.4925, -1.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3639937937259674
Epoch 0, Step 928: train/loss = 0.33157166838645935, train/raw-loss = 0.2952927350997925, train/logprobs = tensor([[-2.0820, -5.2336],
        [-2.7380, -1.3530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.362789124250412
Epoch 0, Step 929: train/loss = 0.47839996218681335, train/raw-loss = 0.43184301257133484, train/logprobs = tensor([[-1.1842, -2.5185],
        [-1.8637, -1.3635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46556904911994934
Epoch 0, Step 930: train/loss = 0.4561818540096283, train/raw-loss = 0.42835986614227295, train/logprobs = tensor([[-1.2772, -3.0620],
        [-1.6650, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782200276851654
Epoch 0, Step 931: train/loss = 0.2340371161699295, train/raw-loss = 0.1997453272342682, train/logprobs = tensor([[-1.3178, -4.8938],
        [-3.5313, -1.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34291794896125793
Epoch 0, Step 932: train/loss = 0.1642945408821106, train/raw-loss = 0.1216064840555191, train/logprobs = tensor([[-1.4332, -4.8837],
        [-4.4361, -1.8912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42688047885894775
Epoch 0, Step 933: train/loss = 0.3746494650840759, train/raw-loss = 0.326784610748291, train/logprobs = tensor([[-1.6011, -3.7976],
        [-3.8903, -2.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47864869236946106
Epoch 0, Step 934: train/loss = 0.4798770248889923, train/raw-loss = 0.43617555499076843, train/logprobs = tensor([[-1.2421, -2.7949],
        [-3.2038, -1.8878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4370144009590149
Epoch 0, Step 935: train/loss = 0.42396050691604614, train/raw-loss = 0.383987694978714, train/logprobs = tensor([[-1.5922, -4.2249],
        [-2.4636, -1.2249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39972779154777527
Epoch 0, Step 936: train/loss = 0.45481711626052856, train/raw-loss = 0.4224628806114197, train/logprobs = tensor([[-2.1493, -3.8925],
        [-3.0584, -1.1159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32354259490966797
Epoch 0, Step 937: train/loss = 0.2667699158191681, train/raw-loss = 0.22181005775928497, train/logprobs = tensor([[-1.0537, -4.7805],
        [-2.1539, -0.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44959861040115356
Epoch 0, Step 938: train/loss = 0.30288273096084595, train/raw-loss = 0.27295392751693726, train/logprobs = tensor([[-1.3059, -3.4089],
        [-2.8708, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.299288272857666
Epoch 0, Step 939: train/loss = 0.2240132838487625, train/raw-loss = 0.19299912452697754, train/logprobs = tensor([[-1.9788, -3.7503],
        [-4.0107, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3101416230201721
Epoch 0, Step 940: train/loss = 0.14201495051383972, train/raw-loss = 0.0921049416065216, train/logprobs = tensor([[-1.2290, -6.3107],
        [-3.4528, -1.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4991000294685364
Epoch 0, Step 941: train/loss = 0.5045990347862244, train/raw-loss = 0.4705369174480438, train/logprobs = tensor([[-1.6043, -4.2230],
        [-3.2210, -2.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34062114357948303
Epoch 0, Step 942: train/loss = 0.22182394564151764, train/raw-loss = 0.1951276659965515, train/logprobs = tensor([[-0.8580, -8.3651],
        [-1.6677, -2.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26696276664733887
Epoch 0, Step 943: train/loss = 1.0359972715377808, train/raw-loss = 1.0002267360687256, train/logprobs = tensor([[-1.6667, -3.1148],
        [-3.0285, -3.5322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.357705295085907
Epoch 0, Step 944: train/loss = 0.391236275434494, train/raw-loss = 0.34010761976242065, train/logprobs = tensor([[-1.1231, -4.3536],
        [-2.7743, -1.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5112866163253784
Epoch 0, Step 945: train/loss = 0.6413245797157288, train/raw-loss = 0.6095273494720459, train/logprobs = tensor([[-1.7834, -2.5292],
        [-1.6900, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31797173619270325
Epoch 0, Step 946: train/loss = 0.43789735436439514, train/raw-loss = 0.40552976727485657, train/logprobs = tensor([[-1.7237, -2.7687],
        [-2.5058, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3236759901046753
Epoch 0, Step 947: train/loss = 0.3866727650165558, train/raw-loss = 0.34322699904441833, train/logprobs = tensor([[-0.9434, -4.1817],
        [-1.8599, -1.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43445801734924316
Epoch 0, Step 948: train/loss = 0.5240209698677063, train/raw-loss = 0.48119980096817017, train/logprobs = tensor([[-2.7575, -4.9523],
        [-2.3508, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4282117187976837
Epoch 0, Step 949: train/loss = 0.1511979103088379, train/raw-loss = 0.11686353385448456, train/logprobs = tensor([[-2.1790, -4.6779],
        [-5.0302, -0.8818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3433437645435333
eval/loss: 0.32277369499206543
