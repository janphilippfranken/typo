[2024-02-24 12:30:05,565][root][INFO] - beta: 0.0
[2024-02-24 12:30:05,565][root][INFO] - loss with_labels
[2024-02-24 12:30:05,565][root][INFO] - max_iter: 0
[2024-02-24 12:30:05,565][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.0-with-labels
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 10000
n harmless: 10000
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.0-with-labels after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.0-with-labels after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.0-with-labels after each epoch.
tokenized 19000 training examples...
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.0-with-labels after each epoch.
Epoch 0, Step 0: train/loss = 0.6919452548027039, train/raw-loss = 0.6919452548027039, train/logprobs = tensor([[-0.7625, -1.9435],
        [-0.7524, -1.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08284443616867065
Epoch 0, Step 1: train/loss = 0.6956621408462524, train/raw-loss = 0.6956621408462524, train/logprobs = tensor([[-1.1242, -1.6991],
        [-1.1416, -1.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12236631661653519
Epoch 0, Step 2: train/loss = 0.6941676735877991, train/raw-loss = 0.6941676735877991, train/logprobs = tensor([[-0.9362, -1.5663],
        [-0.9409, -1.5659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13288523256778717
Epoch 0, Step 3: train/loss = 0.696321427822113, train/raw-loss = 0.696321427822113, train/logprobs = tensor([[-0.6292, -1.7484],
        [-0.6245, -1.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06104531139135361
Epoch 0, Step 4: train/loss = 0.6976995468139648, train/raw-loss = 0.6976995468139648, train/logprobs = tensor([[-0.8488, -1.5907],
        [-0.8509, -1.5672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14375855028629303
Epoch 0, Step 5: train/loss = 0.7016883492469788, train/raw-loss = 0.7016883492469788, train/logprobs = tensor([[-0.7339, -1.5616],
        [-0.7292, -1.5532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14084090292453766
Epoch 0, Step 6: train/loss = 0.6976086497306824, train/raw-loss = 0.6976086497306824, train/logprobs = tensor([[-1.3599, -2.4103],
        [-1.3849, -2.4203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09237585961818695
Epoch 0, Step 7: train/loss = 0.7011421918869019, train/raw-loss = 0.7011421918869019, train/logprobs = tensor([[-0.8969, -1.2452],
        [-0.9006, -1.2623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13747787475585938
Epoch 0, Step 8: train/loss = 0.6922060251235962, train/raw-loss = 0.6922060251235962, train/logprobs = tensor([[-0.9586, -1.9668],
        [-0.9776, -1.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046067655086517334
Epoch 0, Step 9: train/loss = 0.6898701190948486, train/raw-loss = 0.6898701190948486, train/logprobs = tensor([[-1.1275, -1.4825],
        [-1.1155, -1.4396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1885191947221756
Epoch 0, Step 10: train/loss = 0.6879696249961853, train/raw-loss = 0.6879696249961853, train/logprobs = tensor([[-1.0967, -1.9989],
        [-1.1298, -1.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1005450189113617
Epoch 0, Step 11: train/loss = 0.684319019317627, train/raw-loss = 0.684319019317627, train/logprobs = tensor([[-1.0067, -1.8098],
        [-1.0183, -1.7804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06805931776762009
Epoch 0, Step 12: train/loss = 0.6908121109008789, train/raw-loss = 0.6908121109008789, train/logprobs = tensor([[-0.8043, -1.4482],
        [-0.8250, -1.4399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09894949942827225
Epoch 0, Step 13: train/loss = 0.6929625272750854, train/raw-loss = 0.6929625272750854, train/logprobs = tensor([[-0.8172, -1.7427],
        [-0.7707, -1.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050637006759643555
Epoch 0, Step 14: train/loss = 0.6854555606842041, train/raw-loss = 0.6854555606842041, train/logprobs = tensor([[-0.9515, -2.4703],
        [-1.0566, -2.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1144661009311676
Epoch 0, Step 15: train/loss = 0.6840798258781433, train/raw-loss = 0.6840798258781433, train/logprobs = tensor([[-1.2338, -2.0146],
        [-1.2342, -1.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10507392883300781
Epoch 0, Step 16: train/loss = 0.6927311420440674, train/raw-loss = 0.6927311420440674, train/logprobs = tensor([[-1.2444, -1.7448],
        [-1.2837, -1.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06929847598075867
Epoch 0, Step 17: train/loss = 0.696398138999939, train/raw-loss = 0.696398138999939, train/logprobs = tensor([[-0.7668, -1.7478],
        [-0.7662, -1.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07497692108154297
Epoch 0, Step 18: train/loss = 0.675583004951477, train/raw-loss = 0.675583004951477, train/logprobs = tensor([[-0.6684, -1.8835],
        [-0.6730, -1.8142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0859358012676239
Epoch 0, Step 19: train/loss = 0.6839790344238281, train/raw-loss = 0.6839790344238281, train/logprobs = tensor([[-1.2985, -1.9402],
        [-1.3163, -1.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11774184554815292
Epoch 0, Step 20: train/loss = 0.6950129270553589, train/raw-loss = 0.6950129270553589, train/logprobs = tensor([[-0.8994, -1.3127],
        [-0.8994, -1.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13415659964084625
Epoch 0, Step 21: train/loss = 0.6888158321380615, train/raw-loss = 0.6888158321380615, train/logprobs = tensor([[-0.9159, -1.9346],
        [-0.9238, -1.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07801781594753265
Epoch 0, Step 22: train/loss = 0.6994839906692505, train/raw-loss = 0.6994839906692505, train/logprobs = tensor([[-1.5021, -2.3295],
        [-1.5252, -2.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0798039585351944
Epoch 0, Step 23: train/loss = 0.688246488571167, train/raw-loss = 0.688246488571167, train/logprobs = tensor([[-1.1934, -1.8148],
        [-1.2143, -1.7957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07906225323677063
Epoch 0, Step 24: train/loss = 0.6944208741188049, train/raw-loss = 0.6944208741188049, train/logprobs = tensor([[-0.6253, -1.5856],
        [-0.6153, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029445737600326538
Epoch 0, Step 25: train/loss = 0.6812947988510132, train/raw-loss = 0.6812947988510132, train/logprobs = tensor([[-0.7530, -1.8302],
        [-0.7418, -1.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08410003781318665
Epoch 0, Step 26: train/loss = 0.6957235336303711, train/raw-loss = 0.6957235336303711, train/logprobs = tensor([[-1.2793, -1.5065],
        [-1.2905, -1.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0934097096323967
Epoch 0, Step 27: train/loss = 0.6907041072845459, train/raw-loss = 0.6907041072845459, train/logprobs = tensor([[-0.9651, -1.2986],
        [-0.9445, -1.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10359012335538864
Epoch 0, Step 28: train/loss = 0.6882694363594055, train/raw-loss = 0.6882694363594055, train/logprobs = tensor([[-0.8807, -1.5772],
        [-0.8983, -1.5610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03543215990066528
Epoch 0, Step 29: train/loss = 0.707116961479187, train/raw-loss = 0.707116961479187, train/logprobs = tensor([[-0.9972, -2.0376],
        [-1.0359, -2.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05810120701789856
Epoch 0, Step 30: train/loss = 0.6884231567382812, train/raw-loss = 0.6884231567382812, train/logprobs = tensor([[-1.2754, -1.7730],
        [-1.2770, -1.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10114092379808426
Epoch 0, Step 31: train/loss = 0.6937634944915771, train/raw-loss = 0.6937634944915771, train/logprobs = tensor([[-0.6414, -1.6034],
        [-0.6289, -1.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11678837239742279
Epoch 0, Step 32: train/loss = 0.7032281756401062, train/raw-loss = 0.7032281756401062, train/logprobs = tensor([[-1.5003, -2.0652],
        [-1.4935, -2.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10771976411342621
Epoch 0, Step 33: train/loss = 0.6811856031417847, train/raw-loss = 0.6811856031417847, train/logprobs = tensor([[-0.8412, -1.1364],
        [-0.8141, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05860648676753044
Epoch 0, Step 34: train/loss = 0.6936303973197937, train/raw-loss = 0.6936303973197937, train/logprobs = tensor([[-1.0018, -1.6463],
        [-1.0278, -1.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13881179690361023
Epoch 0, Step 35: train/loss = 0.6958738565444946, train/raw-loss = 0.6958738565444946, train/logprobs = tensor([[-0.6750, -1.6502],
        [-0.6757, -1.6470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15719562768936157
Epoch 0, Step 36: train/loss = 0.6901999115943909, train/raw-loss = 0.6901999115943909, train/logprobs = tensor([[-0.7151, -1.2603],
        [-0.7197, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04962202161550522
Epoch 0, Step 37: train/loss = 0.7027848958969116, train/raw-loss = 0.7027848958969116, train/logprobs = tensor([[-1.1965, -2.4746],
        [-1.1972, -2.4532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05531124770641327
Epoch 0, Step 38: train/loss = 0.6874245405197144, train/raw-loss = 0.6874245405197144, train/logprobs = tensor([[-1.0968, -1.5743],
        [-1.1112, -1.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12806248664855957
Epoch 0, Step 39: train/loss = 0.7009061574935913, train/raw-loss = 0.7009061574935913, train/logprobs = tensor([[-0.7746, -2.1777],
        [-0.7613, -2.1700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0681597888469696
Epoch 0, Step 40: train/loss = 0.7029936909675598, train/raw-loss = 0.7029936909675598, train/logprobs = tensor([[-1.0624, -1.9969],
        [-1.0853, -2.0203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14055678248405457
Epoch 0, Step 41: train/loss = 0.6962622404098511, train/raw-loss = 0.6962622404098511, train/logprobs = tensor([[-1.2492, -1.6195],
        [-1.2414, -1.5975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08489885926246643
Epoch 0, Step 42: train/loss = 0.6884530186653137, train/raw-loss = 0.6884530186653137, train/logprobs = tensor([[-1.2069, -2.0647],
        [-1.2036, -2.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06322543323040009
Epoch 0, Step 43: train/loss = 0.6847116947174072, train/raw-loss = 0.6847116947174072, train/logprobs = tensor([[-1.5312, -1.9274],
        [-1.5089, -1.8628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017224468290805817
Epoch 0, Step 44: train/loss = 0.6898869276046753, train/raw-loss = 0.6898869276046753, train/logprobs = tensor([[-0.9045, -1.6892],
        [-0.9154, -1.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11744924634695053
Epoch 0, Step 45: train/loss = 0.6886070966720581, train/raw-loss = 0.6886070966720581, train/logprobs = tensor([[-0.7653, -1.4187],
        [-0.7656, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04391852766275406
Epoch 0, Step 46: train/loss = 0.6888919472694397, train/raw-loss = 0.6888919472694397, train/logprobs = tensor([[-0.7891, -1.5232],
        [-0.8079, -1.5070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07127051800489426
Epoch 0, Step 47: train/loss = 0.696198582649231, train/raw-loss = 0.696198582649231, train/logprobs = tensor([[-0.9779, -1.5753],
        [-0.9797, -1.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053393758833408356
Epoch 0, Step 48: train/loss = 0.6941486597061157, train/raw-loss = 0.6941486597061157, train/logprobs = tensor([[-0.6561, -1.7865],
        [-0.6504, -1.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08245530724525452
Epoch 0, Step 49: train/loss = 0.6872119903564453, train/raw-loss = 0.6872119903564453, train/logprobs = tensor([[-0.4585, -1.7999],
        [-0.4633, -1.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06173913925886154
Epoch 0, Step 50: train/loss = 0.6860544085502625, train/raw-loss = 0.6860544085502625, train/logprobs = tensor([[-1.0151, -1.1919],
        [-0.9974, -1.1456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.101798415184021
Epoch 0, Step 51: train/loss = 0.6839238405227661, train/raw-loss = 0.6839238405227661, train/logprobs = tensor([[-0.4797, -1.5020],
        [-0.4876, -1.4665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07803314924240112
Epoch 0, Step 52: train/loss = 0.6907048225402832, train/raw-loss = 0.6907048225402832, train/logprobs = tensor([[-1.0532, -2.1907],
        [-1.0629, -2.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06740064918994904
Epoch 0, Step 53: train/loss = 0.7060632109642029, train/raw-loss = 0.7060632109642029, train/logprobs = tensor([[-0.9260, -3.0038],
        [-0.9509, -2.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10456521809101105
Epoch 0, Step 54: train/loss = 0.6790496110916138, train/raw-loss = 0.6790496110916138, train/logprobs = tensor([[-0.6311, -2.0872],
        [-0.6317, -2.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07665176689624786
Epoch 0, Step 55: train/loss = 0.7107017040252686, train/raw-loss = 0.7107017040252686, train/logprobs = tensor([[-1.3117, -2.1084],
        [-1.3274, -2.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1130564957857132
Epoch 0, Step 56: train/loss = 0.6864461898803711, train/raw-loss = 0.6864461898803711, train/logprobs = tensor([[-0.5960, -1.8390],
        [-0.6326, -1.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04195702075958252
Epoch 0, Step 57: train/loss = 0.6884993314743042, train/raw-loss = 0.6884993314743042, train/logprobs = tensor([[-1.1875, -1.8055],
        [-1.1999, -1.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09369923174381256
Epoch 0, Step 58: train/loss = 0.7035884857177734, train/raw-loss = 0.7035884857177734, train/logprobs = tensor([[-0.8818, -2.0789],
        [-0.8776, -2.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08555061370134354
Epoch 0, Step 59: train/loss = 0.6984089612960815, train/raw-loss = 0.6984089612960815, train/logprobs = tensor([[-0.9896, -1.9563],
        [-1.0128, -1.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029373111203312874
Epoch 0, Step 60: train/loss = 0.6941835880279541, train/raw-loss = 0.6941835880279541, train/logprobs = tensor([[-0.9070, -1.5978],
        [-0.9391, -1.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.139087975025177
Epoch 0, Step 61: train/loss = 0.6884245872497559, train/raw-loss = 0.6884245872497559, train/logprobs = tensor([[-0.6937, -1.2942],
        [-0.6947, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13448473811149597
Epoch 0, Step 62: train/loss = 0.6938022971153259, train/raw-loss = 0.6938022971153259, train/logprobs = tensor([[-0.7270, -1.7057],
        [-0.7194, -1.6284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817523837089539
Epoch 0, Step 63: train/loss = 0.690098762512207, train/raw-loss = 0.690098762512207, train/logprobs = tensor([[-0.7968, -1.8762],
        [-0.8020, -1.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0727587416768074
Epoch 0, Step 64: train/loss = 0.691148042678833, train/raw-loss = 0.691148042678833, train/logprobs = tensor([[-0.7682, -1.4258],
        [-0.7488, -1.3689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08116377890110016
Epoch 0, Step 65: train/loss = 0.6804830431938171, train/raw-loss = 0.6804830431938171, train/logprobs = tensor([[-1.5335, -2.9299],
        [-1.5622, -2.8929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05407523363828659
Epoch 0, Step 66: train/loss = 0.7135626673698425, train/raw-loss = 0.7135626673698425, train/logprobs = tensor([[-1.2787, -1.6177],
        [-1.2872, -1.5932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08799120783805847
Epoch 0, Step 67: train/loss = 0.68742436170578, train/raw-loss = 0.68742436170578, train/logprobs = tensor([[-1.0309, -1.7678],
        [-1.0608, -1.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07057596743106842
Epoch 0, Step 68: train/loss = 0.6798171401023865, train/raw-loss = 0.6798171401023865, train/logprobs = tensor([[-0.7115, -1.8000],
        [-0.6876, -1.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06546531617641449
Epoch 0, Step 69: train/loss = 0.6854615211486816, train/raw-loss = 0.6854615211486816, train/logprobs = tensor([[-1.3682, -1.5243],
        [-1.3653, -1.4833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0337214358150959
Epoch 0, Step 70: train/loss = 0.6892850399017334, train/raw-loss = 0.6892850399017334, train/logprobs = tensor([[-0.8392, -1.4886],
        [-0.8482, -1.4767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10749053210020065
Epoch 0, Step 71: train/loss = 0.6913679838180542, train/raw-loss = 0.6913679838180542, train/logprobs = tensor([[-1.4661, -2.9528],
        [-1.4783, -2.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0533493272960186
Epoch 0, Step 72: train/loss = 0.6954042911529541, train/raw-loss = 0.6954042911529541, train/logprobs = tensor([[-0.8935, -1.8241],
        [-0.8996, -1.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10331188142299652
Epoch 0, Step 73: train/loss = 0.6939907670021057, train/raw-loss = 0.6939907670021057, train/logprobs = tensor([[-0.7464, -1.7018],
        [-0.7718, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07505969703197479
Epoch 0, Step 74: train/loss = 0.6919185519218445, train/raw-loss = 0.6919185519218445, train/logprobs = tensor([[-0.6169, -1.1300],
        [-0.6100, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0639781653881073
Epoch 0, Step 75: train/loss = 0.6802188158035278, train/raw-loss = 0.6802188158035278, train/logprobs = tensor([[-0.6657, -1.9001],
        [-0.6864, -1.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12353188544511795
Epoch 0, Step 76: train/loss = 0.6803654432296753, train/raw-loss = 0.6803654432296753, train/logprobs = tensor([[-0.6815, -1.5298],
        [-0.6929, -1.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07510262727737427
Epoch 0, Step 77: train/loss = 0.7013471126556396, train/raw-loss = 0.7013471126556396, train/logprobs = tensor([[-0.9429, -1.5433],
        [-0.9100, -1.5185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03973723202943802
Epoch 0, Step 78: train/loss = 0.6944646835327148, train/raw-loss = 0.6944646835327148, train/logprobs = tensor([[-1.2125, -1.1941],
        [-1.2396, -1.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.080409474670887
Epoch 0, Step 79: train/loss = 0.689056932926178, train/raw-loss = 0.689056932926178, train/logprobs = tensor([[-1.1311, -1.6310],
        [-1.1546, -1.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055977459996938705
Epoch 0, Step 80: train/loss = 0.6954118609428406, train/raw-loss = 0.6954118609428406, train/logprobs = tensor([[-1.1383, -1.4584],
        [-1.1498, -1.4644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015654200688004494
Epoch 0, Step 81: train/loss = 0.6995158195495605, train/raw-loss = 0.6995158195495605, train/logprobs = tensor([[-1.1362, -2.1160],
        [-1.1500, -2.1194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06019022315740585
Epoch 0, Step 82: train/loss = 0.6896471977233887, train/raw-loss = 0.6896471977233887, train/logprobs = tensor([[-1.1267, -1.9259],
        [-1.1456, -1.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276241481304169
Epoch 0, Step 83: train/loss = 0.6882900595664978, train/raw-loss = 0.6882900595664978, train/logprobs = tensor([[-1.2513, -1.4258],
        [-1.2384, -1.3927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07528108358383179
Epoch 0, Step 84: train/loss = 0.6978284120559692, train/raw-loss = 0.6978284120559692, train/logprobs = tensor([[-1.2931, -2.5021],
        [-1.2943, -2.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07454940676689148
Epoch 0, Step 85: train/loss = 0.6940333843231201, train/raw-loss = 0.6940333843231201, train/logprobs = tensor([[-1.2317, -1.7124],
        [-1.2430, -1.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06659229099750519
Epoch 0, Step 86: train/loss = 0.6842062473297119, train/raw-loss = 0.6842062473297119, train/logprobs = tensor([[-1.1187, -1.2069],
        [-1.1198, -1.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10589823126792908
Epoch 0, Step 87: train/loss = 0.6897242069244385, train/raw-loss = 0.6897242069244385, train/logprobs = tensor([[-0.9626, -1.7397],
        [-0.9249, -1.6777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0414256677031517
Epoch 0, Step 88: train/loss = 0.675828218460083, train/raw-loss = 0.675828218460083, train/logprobs = tensor([[-0.7045, -1.1538],
        [-0.7386, -1.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03646570444107056
Epoch 0, Step 89: train/loss = 0.687194287776947, train/raw-loss = 0.687194287776947, train/logprobs = tensor([[-0.9375, -1.7364],
        [-0.9293, -1.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09467041492462158
Epoch 0, Step 90: train/loss = 0.706161618232727, train/raw-loss = 0.706161618232727, train/logprobs = tensor([[-0.9080, -2.4031],
        [-0.9148, -2.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06440247595310211
Epoch 0, Step 91: train/loss = 0.6904686093330383, train/raw-loss = 0.6904686093330383, train/logprobs = tensor([[-1.8470, -2.2917],
        [-1.8793, -2.2869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11682632565498352
Epoch 0, Step 92: train/loss = 0.694912314414978, train/raw-loss = 0.694912314414978, train/logprobs = tensor([[-0.7150, -1.4762],
        [-0.6954, -1.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043951526284217834
Epoch 0, Step 93: train/loss = 0.6893861889839172, train/raw-loss = 0.6893861889839172, train/logprobs = tensor([[-0.7859, -1.8752],
        [-0.7669, -1.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09053217619657516
Epoch 0, Step 94: train/loss = 0.6856368780136108, train/raw-loss = 0.6856368780136108, train/logprobs = tensor([[-0.8608, -1.1803],
        [-0.8724, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06917765736579895
Epoch 0, Step 95: train/loss = 0.6829109787940979, train/raw-loss = 0.6829109787940979, train/logprobs = tensor([[-1.4558, -2.3659],
        [-1.4539, -2.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05052071809768677
Epoch 0, Step 96: train/loss = 0.6877828240394592, train/raw-loss = 0.6877828240394592, train/logprobs = tensor([[-0.7942, -1.5220],
        [-0.8143, -1.5101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06947509944438934
Epoch 0, Step 97: train/loss = 0.6790244579315186, train/raw-loss = 0.6790244579315186, train/logprobs = tensor([[-1.1415, -1.4873],
        [-1.1187, -1.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05591895431280136
Epoch 0, Step 98: train/loss = 0.6978774070739746, train/raw-loss = 0.6978774070739746, train/logprobs = tensor([[-1.3374, -1.8783],
        [-1.3514, -1.8962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017965704202651978
Epoch 0, Step 99: train/loss = 0.6811977624893188, train/raw-loss = 0.6811977624893188, train/logprobs = tensor([[-0.9408, -1.3331],
        [-0.9488, -1.2850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023479128256440163
Epoch 0, Step 100: train/loss = 0.6816072463989258, train/raw-loss = 0.6816072463989258, train/logprobs = tensor([[-1.0174, -1.4827],
        [-1.0077, -1.4225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03405146300792694
Epoch 0, Step 101: train/loss = 0.691826581954956, train/raw-loss = 0.691826581954956, train/logprobs = tensor([[-1.1750, -1.2206],
        [-1.1597, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06191151589155197
Epoch 0, Step 102: train/loss = 0.6890560984611511, train/raw-loss = 0.6890560984611511, train/logprobs = tensor([[-1.1033, -2.8093],
        [-1.0948, -2.7575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06057453900575638
Epoch 0, Step 103: train/loss = 0.6778976321220398, train/raw-loss = 0.6778976321220398, train/logprobs = tensor([[-1.0064, -1.7020],
        [-1.0532, -1.6801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07426218688488007
Epoch 0, Step 104: train/loss = 0.6914988160133362, train/raw-loss = 0.6914988160133362, train/logprobs = tensor([[-0.8364, -1.3975],
        [-0.8253, -1.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.006019038613885641
Epoch 0, Step 105: train/loss = 0.6807661056518555, train/raw-loss = 0.6807661056518555, train/logprobs = tensor([[-1.0417, -1.3694],
        [-1.0989, -1.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037938736379146576
Epoch 0, Step 106: train/loss = 0.6869668960571289, train/raw-loss = 0.6869668960571289, train/logprobs = tensor([[-1.2745, -1.4666],
        [-1.2911, -1.4518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025344010442495346
Epoch 0, Step 107: train/loss = 0.6794795989990234, train/raw-loss = 0.6794795989990234, train/logprobs = tensor([[-1.3821, -1.6069],
        [-1.4159, -1.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053321778774261475
Epoch 0, Step 108: train/loss = 0.6860926151275635, train/raw-loss = 0.6860926151275635, train/logprobs = tensor([[-1.3261, -2.2760],
        [-1.3476, -2.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04581744968891144
Epoch 0, Step 109: train/loss = 0.6873501539230347, train/raw-loss = 0.6873501539230347, train/logprobs = tensor([[-1.2819, -1.5120],
        [-1.2888, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03755292296409607
Epoch 0, Step 110: train/loss = 0.6882853507995605, train/raw-loss = 0.6882853507995605, train/logprobs = tensor([[-1.2721, -2.1936],
        [-1.2845, -2.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04714084044098854
Epoch 0, Step 111: train/loss = 0.6872533559799194, train/raw-loss = 0.6872533559799194, train/logprobs = tensor([[-0.6434, -2.3363],
        [-0.5952, -2.2379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03726015239953995
Epoch 0, Step 112: train/loss = 0.692054033279419, train/raw-loss = 0.692054033279419, train/logprobs = tensor([[-1.1444, -1.7688],
        [-1.1408, -1.7528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05803096666932106
Epoch 0, Step 113: train/loss = 0.6931706666946411, train/raw-loss = 0.6931706666946411, train/logprobs = tensor([[-1.1845, -1.5759],
        [-1.1968, -1.5648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006916310638189316
Epoch 0, Step 114: train/loss = 0.6826934814453125, train/raw-loss = 0.6826934814453125, train/logprobs = tensor([[-1.2740, -1.8536],
        [-1.2954, -1.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019497979432344437
Epoch 0, Step 115: train/loss = 0.6791266202926636, train/raw-loss = 0.6791266202926636, train/logprobs = tensor([[-0.8331, -1.5913],
        [-0.8052, -1.4984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04556276649236679
Epoch 0, Step 116: train/loss = 0.6834656596183777, train/raw-loss = 0.6834656596183777, train/logprobs = tensor([[-1.0319, -1.7634],
        [-1.0459, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16677705943584442
Epoch 0, Step 117: train/loss = 0.673236072063446, train/raw-loss = 0.673236072063446, train/logprobs = tensor([[-1.0340, -2.3764],
        [-1.0510, -2.2813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022408317774534225
Epoch 0, Step 118: train/loss = 0.6912566423416138, train/raw-loss = 0.6912566423416138, train/logprobs = tensor([[-0.9791, -1.2664],
        [-0.9789, -1.2558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043282754719257355
Epoch 0, Step 119: train/loss = 0.6931455731391907, train/raw-loss = 0.6931455731391907, train/logprobs = tensor([[-0.8883, -1.3206],
        [-0.8678, -1.2857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030105572193861008
Epoch 0, Step 120: train/loss = 0.6901339292526245, train/raw-loss = 0.6901339292526245, train/logprobs = tensor([[-1.5660, -1.9776],
        [-1.6127, -2.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002967037260532379
Epoch 0, Step 121: train/loss = 0.6913425326347351, train/raw-loss = 0.6913425326347351, train/logprobs = tensor([[-0.9901, -1.8782],
        [-0.9994, -1.8768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05729317665100098
Epoch 0, Step 122: train/loss = 0.6774275898933411, train/raw-loss = 0.6774275898933411, train/logprobs = tensor([[-0.8360, -1.2233],
        [-0.8286, -1.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16169989109039307
Epoch 0, Step 123: train/loss = 0.6857174634933472, train/raw-loss = 0.6857174634933472, train/logprobs = tensor([[-1.4638, -1.7327],
        [-1.5090, -1.6883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04662668704986572
Epoch 0, Step 124: train/loss = 0.683883547782898, train/raw-loss = 0.683883547782898, train/logprobs = tensor([[-1.2928, -1.1143],
        [-1.3097, -1.0917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024033349007368088
Epoch 0, Step 125: train/loss = 0.6926217079162598, train/raw-loss = 0.6926217079162598, train/logprobs = tensor([[-1.1970, -2.1469],
        [-1.1644, -2.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05561616271734238
Epoch 0, Step 126: train/loss = 0.6825718879699707, train/raw-loss = 0.6825718879699707, train/logprobs = tensor([[-0.7820, -1.6811],
        [-0.8033, -1.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050081800669431686
Epoch 0, Step 127: train/loss = 0.7004759311676025, train/raw-loss = 0.7004759311676025, train/logprobs = tensor([[-1.3301, -1.6113],
        [-1.2837, -1.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03949622064828873
Epoch 0, Step 128: train/loss = 0.6916375160217285, train/raw-loss = 0.6916375160217285, train/logprobs = tensor([[-1.1785, -1.4453],
        [-1.1489, -1.3958]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.006421227008104324
Epoch 0, Step 129: train/loss = 0.6748188734054565, train/raw-loss = 0.6748188734054565, train/logprobs = tensor([[-1.0259, -1.9111],
        [-1.0113, -1.8123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026935460045933723
Epoch 0, Step 130: train/loss = 0.6926220655441284, train/raw-loss = 0.6926220655441284, train/logprobs = tensor([[-0.8162, -2.1391],
        [-0.7892, -2.0801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002972849179059267
Epoch 0, Step 131: train/loss = 0.6807140707969666, train/raw-loss = 0.6807140707969666, train/logprobs = tensor([[-1.0478, -2.0550],
        [-1.0437, -1.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000661756843328476
Epoch 0, Step 132: train/loss = 0.6855577230453491, train/raw-loss = 0.6855577230453491, train/logprobs = tensor([[-0.9016, -2.7249],
        [-0.9174, -2.6857]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0076887402683496475
Epoch 0, Step 133: train/loss = 0.679137110710144, train/raw-loss = 0.679137110710144, train/logprobs = tensor([[-1.1932, -1.2394],
        [-1.1572, -1.1362]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01048748567700386
Epoch 0, Step 134: train/loss = 0.6699816584587097, train/raw-loss = 0.6699816584587097, train/logprobs = tensor([[-1.4933, -2.2395],
        [-1.5288, -2.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004881261847913265
Epoch 0, Step 135: train/loss = 0.6680032014846802, train/raw-loss = 0.6680032014846802, train/logprobs = tensor([[-1.3332, -2.2615],
        [-1.3637, -2.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01971356011927128
Epoch 0, Step 136: train/loss = 0.6817423105239868, train/raw-loss = 0.6817423105239868, train/logprobs = tensor([[-1.3800, -2.1240],
        [-1.3903, -2.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.014961657114326954
Epoch 0, Step 137: train/loss = 0.684309720993042, train/raw-loss = 0.684309720993042, train/logprobs = tensor([[-1.4465, -2.1294],
        [-1.3991, -2.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.010357676073908806
Epoch 0, Step 138: train/loss = 0.6885812878608704, train/raw-loss = 0.6885812878608704, train/logprobs = tensor([[-1.1981, -1.8638],
        [-1.1910, -1.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010457725264132023
Epoch 0, Step 139: train/loss = 0.6861193776130676, train/raw-loss = 0.6861193776130676, train/logprobs = tensor([[-1.2460, -1.9562],
        [-1.2422, -1.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.016365673393011093
Epoch 0, Step 140: train/loss = 0.6817625164985657, train/raw-loss = 0.6817625164985657, train/logprobs = tensor([[-0.8180, -1.1902],
        [-0.8018, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02700890228152275
Epoch 0, Step 141: train/loss = 0.6875768899917603, train/raw-loss = 0.6875768899917603, train/logprobs = tensor([[-1.1294, -1.7169],
        [-1.1362, -1.6960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01800353266298771
Epoch 0, Step 142: train/loss = 0.6692390441894531, train/raw-loss = 0.6692390441894531, train/logprobs = tensor([[-0.9446, -1.1899],
        [-1.0172, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011980479583144188
Epoch 0, Step 143: train/loss = 0.7190674543380737, train/raw-loss = 0.7190674543380737, train/logprobs = tensor([[-1.5314, -2.0636],
        [-1.5544, -2.0661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06512393057346344
Epoch 0, Step 144: train/loss = 0.6646801233291626, train/raw-loss = 0.6646801233291626, train/logprobs = tensor([[-0.8160, -2.4085],
        [-0.7623, -2.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.021523799747228622
Epoch 0, Step 145: train/loss = 0.6918476819992065, train/raw-loss = 0.6918476819992065, train/logprobs = tensor([[-1.3850, -1.7662],
        [-1.4033, -1.7771]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0072975861839950085
Epoch 0, Step 146: train/loss = 0.681172251701355, train/raw-loss = 0.681172251701355, train/logprobs = tensor([[-1.0994, -1.4729],
        [-1.1257, -1.4485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05867503955960274
Epoch 0, Step 147: train/loss = 0.708308756351471, train/raw-loss = 0.708308756351471, train/logprobs = tensor([[-1.2950, -1.8881],
        [-1.2897, -1.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033591583371162415
Epoch 0, Step 148: train/loss = 0.6720091700553894, train/raw-loss = 0.6720091700553894, train/logprobs = tensor([[-0.8024, -2.5703],
        [-0.8006, -2.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004418189637362957
Epoch 0, Step 149: train/loss = 0.684360146522522, train/raw-loss = 0.684360146522522, train/logprobs = tensor([[-0.9145, -1.4865],
        [-0.9071, -1.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0339839868247509
Epoch 0, Step 150: train/loss = 0.6936512589454651, train/raw-loss = 0.6936512589454651, train/logprobs = tensor([[-1.3096, -2.6668],
        [-1.3192, -2.6421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011976000852882862
Epoch 0, Step 151: train/loss = 0.6989055275917053, train/raw-loss = 0.6989055275917053, train/logprobs = tensor([[-0.9562, -2.2285],
        [-0.9659, -2.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013153601437807083
Epoch 0, Step 152: train/loss = 0.6706657409667969, train/raw-loss = 0.6706657409667969, train/logprobs = tensor([[-0.9170, -2.0493],
        [-0.9086, -1.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02964332513511181
Epoch 0, Step 153: train/loss = 0.6948498487472534, train/raw-loss = 0.6948498487472534, train/logprobs = tensor([[-1.2861, -1.8224],
        [-1.2740, -1.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019018021412193775
Epoch 0, Step 154: train/loss = 0.6891279220581055, train/raw-loss = 0.6891279220581055, train/logprobs = tensor([[-0.7635, -1.6031],
        [-0.7629, -1.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029325639829039574
Epoch 0, Step 155: train/loss = 0.6715572476387024, train/raw-loss = 0.6715572476387024, train/logprobs = tensor([[-0.8730, -2.1302],
        [-0.8706, -2.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012330939061939716
Epoch 0, Step 156: train/loss = 0.6912705898284912, train/raw-loss = 0.6912705898284912, train/logprobs = tensor([[-1.2754, -1.9063],
        [-1.2753, -1.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008939042687416077
Epoch 0, Step 157: train/loss = 0.6843515038490295, train/raw-loss = 0.6843515038490295, train/logprobs = tensor([[-0.6787, -1.7104],
        [-0.6546, -1.6329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02830892987549305
Epoch 0, Step 158: train/loss = 0.6597566604614258, train/raw-loss = 0.6597566604614258, train/logprobs = tensor([[-1.1098, -2.6034],
        [-1.1303, -2.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04973972216248512
Epoch 0, Step 159: train/loss = 0.6744066476821899, train/raw-loss = 0.6744066476821899, train/logprobs = tensor([[-1.0558, -2.0299],
        [-1.0703, -1.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027457106858491898
Epoch 0, Step 160: train/loss = 0.6853678226470947, train/raw-loss = 0.6853678226470947, train/logprobs = tensor([[-1.2922, -1.6757],
        [-1.2856, -1.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.038015469908714294
Epoch 0, Step 161: train/loss = 0.6705902814865112, train/raw-loss = 0.6705902814865112, train/logprobs = tensor([[-1.0887, -2.4627],
        [-1.0630, -2.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.026334095746278763
Epoch 0, Step 162: train/loss = 0.6761788129806519, train/raw-loss = 0.6761788129806519, train/logprobs = tensor([[-1.2797, -1.8814],
        [-1.2523, -1.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03722577914595604
Epoch 0, Step 163: train/loss = 0.668529748916626, train/raw-loss = 0.668529748916626, train/logprobs = tensor([[-0.9947, -3.0313],
        [-0.9886, -2.8956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019141647964715958
Epoch 0, Step 164: train/loss = 0.6457321643829346, train/raw-loss = 0.6457321643829346, train/logprobs = tensor([[-1.3199, -2.3496],
        [-1.3329, -2.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011943835765123367
Epoch 0, Step 165: train/loss = 0.6587590575218201, train/raw-loss = 0.6587590575218201, train/logprobs = tensor([[-0.9177, -3.9760],
        [-0.9284, -3.8330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027287453413009644
Epoch 0, Step 166: train/loss = 0.6767678260803223, train/raw-loss = 0.6767678260803223, train/logprobs = tensor([[-0.9384, -1.4721],
        [-1.0664, -1.4391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05623375251889229
Epoch 0, Step 167: train/loss = 0.6798526048660278, train/raw-loss = 0.6798526048660278, train/logprobs = tensor([[-1.4034, -1.5781],
        [-1.3768, -1.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020437851548194885
Epoch 0, Step 168: train/loss = 0.6745928525924683, train/raw-loss = 0.6745928525924683, train/logprobs = tensor([[-1.0754, -1.3650],
        [-1.0879, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.016157429665327072
Epoch 0, Step 169: train/loss = 0.6807891130447388, train/raw-loss = 0.6807891130447388, train/logprobs = tensor([[-1.3375, -1.7870],
        [-1.3485, -1.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016645316034555435
Epoch 0, Step 170: train/loss = 0.6756631135940552, train/raw-loss = 0.6756631135940552, train/logprobs = tensor([[-1.0451, -2.0311],
        [-1.0245, -1.9159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024030055850744247
Epoch 0, Step 171: train/loss = 0.6638109683990479, train/raw-loss = 0.6638109683990479, train/logprobs = tensor([[-0.5618, -1.7201],
        [-0.5574, -1.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021173356100916862
Epoch 0, Step 172: train/loss = 0.6675385236740112, train/raw-loss = 0.6675385236740112, train/logprobs = tensor([[-1.0103, -2.1743],
        [-1.0315, -2.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.020707838237285614
Epoch 0, Step 173: train/loss = 0.6857457160949707, train/raw-loss = 0.6857457160949707, train/logprobs = tensor([[-1.0256, -2.5744],
        [-1.0132, -2.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025407282635569572
Epoch 0, Step 174: train/loss = 0.6838082671165466, train/raw-loss = 0.6838082671165466, train/logprobs = tensor([[-1.6233, -1.6905],
        [-1.6294, -1.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007413859013468027
Epoch 0, Step 175: train/loss = 0.66127610206604, train/raw-loss = 0.66127610206604, train/logprobs = tensor([[-1.2342, -3.2080],
        [-1.2308, -3.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0057761175557971
Epoch 0, Step 176: train/loss = 0.6835017800331116, train/raw-loss = 0.6835017800331116, train/logprobs = tensor([[-1.2245, -2.5605],
        [-1.1667, -2.4038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04069457948207855
Epoch 0, Step 177: train/loss = 0.6856074929237366, train/raw-loss = 0.6856074929237366, train/logprobs = tensor([[-0.8639, -0.9746],
        [-0.8587, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.013461872935295105
Epoch 0, Step 178: train/loss = 0.6873744130134583, train/raw-loss = 0.6873744130134583, train/logprobs = tensor([[-1.0198, -1.2798],
        [-1.0177, -1.2488]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.028171610087156296
Epoch 0, Step 179: train/loss = 0.6724980473518372, train/raw-loss = 0.6724980473518372, train/logprobs = tensor([[-1.0992, -3.2442],
        [-1.0820, -3.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029088319279253483
Epoch 0, Step 180: train/loss = 0.68145352602005, train/raw-loss = 0.68145352602005, train/logprobs = tensor([[-1.7934, -1.8937],
        [-1.7972, -1.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008773306384682655
Epoch 0, Step 181: train/loss = 0.6768581867218018, train/raw-loss = 0.6768581867218018, train/logprobs = tensor([[-1.0391, -1.6558],
        [-1.0113, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.006483910605311394
Epoch 0, Step 182: train/loss = 0.6682752370834351, train/raw-loss = 0.6682752370834351, train/logprobs = tensor([[-0.8785, -2.7235],
        [-0.8988, -2.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.005915848538279533
Epoch 0, Step 183: train/loss = 0.6845546960830688, train/raw-loss = 0.6845546960830688, train/logprobs = tensor([[-1.4243, -1.9334],
        [-1.4463, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.018938228487968445
Epoch 0, Step 184: train/loss = 0.6847618818283081, train/raw-loss = 0.6847618818283081, train/logprobs = tensor([[-1.2583, -2.6765],
        [-1.2843, -2.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022454746067523956
Epoch 0, Step 185: train/loss = 0.6774420738220215, train/raw-loss = 0.6774420738220215, train/logprobs = tensor([[-1.2276, -1.9395],
        [-1.2452, -1.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01151270978152752
Epoch 0, Step 186: train/loss = 0.6761343479156494, train/raw-loss = 0.6761343479156494, train/logprobs = tensor([[-1.0198, -2.0504],
        [-0.9966, -1.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011744566261768341
Epoch 0, Step 187: train/loss = 0.6791807413101196, train/raw-loss = 0.6791807413101196, train/logprobs = tensor([[-0.7106, -1.2675],
        [-0.6926, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.004082008730620146
Epoch 0, Step 188: train/loss = 0.6931256055831909, train/raw-loss = 0.6931256055831909, train/logprobs = tensor([[-0.7606, -2.3499],
        [-0.7024, -2.2598]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02440461702644825
Epoch 0, Step 189: train/loss = 0.6819254755973816, train/raw-loss = 0.6819254755973816, train/logprobs = tensor([[-0.7851, -2.0388],
        [-0.7525, -1.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028294581919908524
Epoch 0, Step 190: train/loss = 0.6702719926834106, train/raw-loss = 0.6702719926834106, train/logprobs = tensor([[-1.2546, -2.1865],
        [-1.2369, -2.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0010285894386470318
Epoch 0, Step 191: train/loss = 0.6782068014144897, train/raw-loss = 0.6782068014144897, train/logprobs = tensor([[-1.4966, -2.8698],
        [-1.5506, -2.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.030954938381910324
Epoch 0, Step 192: train/loss = 0.6694161891937256, train/raw-loss = 0.6694161891937256, train/logprobs = tensor([[-1.1844, -1.4871],
        [-1.2025, -1.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005527591332793236
Epoch 0, Step 193: train/loss = 0.6901776194572449, train/raw-loss = 0.6901776194572449, train/logprobs = tensor([[-1.3125, -2.0542],
        [-1.2715, -1.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057119883596897125
Epoch 0, Step 194: train/loss = 0.6768204569816589, train/raw-loss = 0.6768204569816589, train/logprobs = tensor([[-1.1671, -2.1902],
        [-1.1424, -2.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01776583306491375
Epoch 0, Step 195: train/loss = 0.675989031791687, train/raw-loss = 0.675989031791687, train/logprobs = tensor([[-0.7030, -1.9091],
        [-0.7020, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022228270769119263
Epoch 0, Step 196: train/loss = 0.6764921545982361, train/raw-loss = 0.6764921545982361, train/logprobs = tensor([[-1.7158, -1.8927],
        [-1.7617, -1.8556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0334901325404644
Epoch 0, Step 197: train/loss = 0.6735721230506897, train/raw-loss = 0.6735721230506897, train/logprobs = tensor([[-0.7849, -2.0975],
        [-0.7555, -1.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029453082010149956
Epoch 0, Step 198: train/loss = 0.6605923771858215, train/raw-loss = 0.6605923771858215, train/logprobs = tensor([[-1.2858, -2.3751],
        [-1.2291, -2.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.008776813745498657
Epoch 0, Step 199: train/loss = 0.6655853986740112, train/raw-loss = 0.6655853986740112, train/logprobs = tensor([[-0.9701, -1.5868],
        [-0.9863, -1.4850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0431007482111454
Epoch 0, Step 200: train/loss = 0.6535771489143372, train/raw-loss = 0.6535771489143372, train/logprobs = tensor([[-1.1560, -1.9519],
        [-1.1375, -1.7636]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.027007251977920532
Epoch 0, Step 201: train/loss = 0.6815096139907837, train/raw-loss = 0.6815096139907837, train/logprobs = tensor([[-1.4676, -2.2943],
        [-1.4482, -2.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.037291914224624634
Epoch 0, Step 202: train/loss = 0.6843613982200623, train/raw-loss = 0.6843613982200623, train/logprobs = tensor([[-1.2514, -1.7663],
        [-1.2230, -1.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.021745553240180016
Epoch 0, Step 203: train/loss = 0.6588532328605652, train/raw-loss = 0.6588532328605652, train/logprobs = tensor([[-1.2167, -2.4035],
        [-1.2283, -2.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012896372005343437
Epoch 0, Step 204: train/loss = 0.6287695169448853, train/raw-loss = 0.6287695169448853, train/logprobs = tensor([[-0.7705, -2.4570],
        [-0.7670, -2.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011304894462227821
Epoch 0, Step 205: train/loss = 0.6737136244773865, train/raw-loss = 0.6737136244773865, train/logprobs = tensor([[-1.0027, -1.6124],
        [-1.0179, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031383857131004333
Epoch 0, Step 206: train/loss = 0.6896776556968689, train/raw-loss = 0.6896776556968689, train/logprobs = tensor([[-1.0363, -1.6308],
        [-0.9899, -1.5551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0250749159604311
Epoch 0, Step 207: train/loss = 0.6739600300788879, train/raw-loss = 0.6739600300788879, train/logprobs = tensor([[-0.9657, -1.7199],
        [-1.0009, -1.6709]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.008222988806664944
Epoch 0, Step 208: train/loss = 0.6636673212051392, train/raw-loss = 0.6636673212051392, train/logprobs = tensor([[-0.9676, -1.8238],
        [-1.0149, -1.7442]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.029314815998077393
Epoch 0, Step 209: train/loss = 0.6854331493377686, train/raw-loss = 0.6854331493377686, train/logprobs = tensor([[-1.6044, -2.2938],
        [-1.5904, -2.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.002148108556866646
Epoch 0, Step 210: train/loss = 0.6644246578216553, train/raw-loss = 0.6644246578216553, train/logprobs = tensor([[-1.0124, -1.5797],
        [-1.0285, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025362811982631683
Epoch 0, Step 211: train/loss = 0.6821012496948242, train/raw-loss = 0.6821012496948242, train/logprobs = tensor([[-1.3048, -1.5891],
        [-1.3584, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011281701736152172
Epoch 0, Step 212: train/loss = 0.7094051837921143, train/raw-loss = 0.7094051837921143, train/logprobs = tensor([[-1.6334, -1.9778],
        [-1.6032, -1.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01550460234284401
Epoch 0, Step 213: train/loss = 0.6645684242248535, train/raw-loss = 0.6645684242248535, train/logprobs = tensor([[-1.5936, -1.7948],
        [-1.6443, -1.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.00135800801217556
Epoch 0, Step 214: train/loss = 0.6567556858062744, train/raw-loss = 0.6567556858062744, train/logprobs = tensor([[-0.9540, -1.8163],
        [-0.9791, -1.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01949218101799488
Epoch 0, Step 215: train/loss = 0.6750163435935974, train/raw-loss = 0.6750163435935974, train/logprobs = tensor([[-1.0238, -1.9670],
        [-1.0266, -1.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009145219810307026
Epoch 0, Step 216: train/loss = 0.6509686708450317, train/raw-loss = 0.6509686708450317, train/logprobs = tensor([[-0.8279, -2.2335],
        [-0.8374, -2.0674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001883404329419136
Epoch 0, Step 217: train/loss = 0.654837429523468, train/raw-loss = 0.654837429523468, train/logprobs = tensor([[-1.1193, -2.9726],
        [-1.0895, -2.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.036890532821416855
Epoch 0, Step 218: train/loss = 0.6791318655014038, train/raw-loss = 0.6791318655014038, train/logprobs = tensor([[-1.0475, -2.0604],
        [-1.0203, -1.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009470194578170776
Epoch 0, Step 219: train/loss = 0.6801295280456543, train/raw-loss = 0.6801295280456543, train/logprobs = tensor([[-0.7927, -1.4929],
        [-0.8017, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.008751880377531052
Epoch 0, Step 220: train/loss = 0.6574177742004395, train/raw-loss = 0.6574177742004395, train/logprobs = tensor([[-0.8605, -1.8439],
        [-0.8747, -1.7029]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02245478332042694
Epoch 0, Step 221: train/loss = 0.6788730621337891, train/raw-loss = 0.6788730621337891, train/logprobs = tensor([[-1.3653, -1.2851],
        [-1.4213, -1.2486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002472981810569763
Epoch 0, Step 222: train/loss = 0.6856235861778259, train/raw-loss = 0.6856235861778259, train/logprobs = tensor([[-1.5396, -2.8151],
        [-1.5138, -2.7125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010006970725953579
Epoch 0, Step 223: train/loss = 0.6709182262420654, train/raw-loss = 0.6709182262420654, train/logprobs = tensor([[-1.2764, -1.5895],
        [-1.2712, -1.4876]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0032661287114024162
Epoch 0, Step 224: train/loss = 0.6550824642181396, train/raw-loss = 0.6550824642181396, train/logprobs = tensor([[-1.1702, -1.3231],
        [-1.1342, -1.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.002605786547064781
Epoch 0, Step 225: train/loss = 0.6503081321716309, train/raw-loss = 0.6503081321716309, train/logprobs = tensor([[-0.9670, -2.3905],
        [-0.9631, -2.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.006968908943235874
Epoch 0, Step 226: train/loss = 0.6860142946243286, train/raw-loss = 0.6860142946243286, train/logprobs = tensor([[-0.9115, -1.5008],
        [-0.9364, -1.4821]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02040809579193592
Epoch 0, Step 227: train/loss = 0.69303297996521, train/raw-loss = 0.69303297996521, train/logprobs = tensor([[-1.4426, -1.4197],
        [-1.4264, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030512701719999313
Epoch 0, Step 228: train/loss = 0.6870336532592773, train/raw-loss = 0.6870336532592773, train/logprobs = tensor([[-1.1077, -1.2652],
        [-1.1235, -1.2526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004775266628712416
Epoch 0, Step 229: train/loss = 0.6650248169898987, train/raw-loss = 0.6650248169898987, train/logprobs = tensor([[-1.3288, -1.4929],
        [-1.3796, -1.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.007835814729332924
Epoch 0, Step 230: train/loss = 0.690544843673706, train/raw-loss = 0.690544843673706, train/logprobs = tensor([[-1.0903, -3.2137],
        [-1.1424, -3.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.00037155672907829285
Epoch 0, Step 231: train/loss = 0.6420996785163879, train/raw-loss = 0.6420996785163879, train/logprobs = tensor([[-1.0108, -1.8779],
        [-1.0171, -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06058862432837486
Epoch 0, Step 232: train/loss = 0.6720826029777527, train/raw-loss = 0.6720826029777527, train/logprobs = tensor([[-1.4172, -1.8346],
        [-1.3945, -1.7138]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03271011263132095
Epoch 0, Step 233: train/loss = 0.6630468368530273, train/raw-loss = 0.6630468368530273, train/logprobs = tensor([[-0.8231, -1.4204],
        [-0.7708, -1.2406]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022602226585149765
Epoch 0, Step 234: train/loss = 0.6583203077316284, train/raw-loss = 0.6583203077316284, train/logprobs = tensor([[-0.7999, -1.6488],
        [-0.8122, -1.4946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03362575173377991
Epoch 0, Step 235: train/loss = 0.6658758521080017, train/raw-loss = 0.6658758521080017, train/logprobs = tensor([[-1.0910, -2.0966],
        [-1.1222, -2.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.014927161857485771
Epoch 0, Step 236: train/loss = 0.6906273365020752, train/raw-loss = 0.6906273365020752, train/logprobs = tensor([[-0.7432, -0.8546],
        [-0.7181, -0.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.013846632093191147
Epoch 0, Step 237: train/loss = 0.6867439150810242, train/raw-loss = 0.6867439150810242, train/logprobs = tensor([[-1.2057, -1.6775],
        [-1.2173, -1.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0010722856968641281
Epoch 0, Step 238: train/loss = 0.6670072674751282, train/raw-loss = 0.6670072674751282, train/logprobs = tensor([[-1.0744, -2.1177],
        [-1.0893, -2.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006796743255108595
Epoch 0, Step 239: train/loss = 0.6619505286216736, train/raw-loss = 0.6619505286216736, train/logprobs = tensor([[-0.7860, -2.0047],
        [-0.8152, -1.8546]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01625910773873329
Epoch 0, Step 240: train/loss = 0.6745657324790955, train/raw-loss = 0.6745657324790955, train/logprobs = tensor([[-1.1392, -1.4870],
        [-1.1237, -1.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01764911599457264
Epoch 0, Step 241: train/loss = 0.6642196178436279, train/raw-loss = 0.6642196178436279, train/logprobs = tensor([[-0.9971, -1.7673],
        [-1.0369, -1.6842]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03291424736380577
Epoch 0, Step 242: train/loss = 0.636635422706604, train/raw-loss = 0.636635422706604, train/logprobs = tensor([[-0.7866, -2.0947],
        [-0.8118, -1.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.030945315957069397
Epoch 0, Step 243: train/loss = 0.6607221364974976, train/raw-loss = 0.6607221364974976, train/logprobs = tensor([[-1.3259, -1.9794],
        [-1.3626, -1.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010465799830853939
Epoch 0, Step 244: train/loss = 0.6812132000923157, train/raw-loss = 0.6812132000923157, train/logprobs = tensor([[-1.4995, -2.4612],
        [-1.4420, -2.3495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01868712343275547
Epoch 0, Step 245: train/loss = 0.6504902243614197, train/raw-loss = 0.6504902243614197, train/logprobs = tensor([[-0.9412, -2.3557],
        [-0.8963, -2.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004005216993391514
Epoch 0, Step 246: train/loss = 0.6861298084259033, train/raw-loss = 0.6861298084259033, train/logprobs = tensor([[-1.2331, -2.4245],
        [-1.2259, -2.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051328953355550766
Epoch 0, Step 247: train/loss = 0.6856610774993896, train/raw-loss = 0.6856610774993896, train/logprobs = tensor([[-1.2571, -1.2970],
        [-1.2670, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007799637503921986
Epoch 0, Step 248: train/loss = 0.6600655913352966, train/raw-loss = 0.6600655913352966, train/logprobs = tensor([[-1.0465, -1.5444],
        [-1.0572, -1.4159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003915830515325069
Epoch 0, Step 249: train/loss = 0.6589773893356323, train/raw-loss = 0.6589773893356323, train/logprobs = tensor([[-1.1403, -1.5763],
        [-1.1501, -1.4340]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06455166637897491
Epoch 0, Step 250: train/loss = 0.6344357132911682, train/raw-loss = 0.6344357132911682, train/logprobs = tensor([[-1.2739, -2.4707],
        [-1.2794, -2.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025000957772135735
Epoch 0, Step 251: train/loss = 0.6748253107070923, train/raw-loss = 0.6748253107070923, train/logprobs = tensor([[-1.2382, -1.7284],
        [-1.2162, -1.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.015747401863336563
Epoch 0, Step 252: train/loss = 0.6852124929428101, train/raw-loss = 0.6852124929428101, train/logprobs = tensor([[-1.7059, -1.6158],
        [-1.6027, -1.4719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019587447866797447
Epoch 0, Step 253: train/loss = 0.6765944957733154, train/raw-loss = 0.6765944957733154, train/logprobs = tensor([[-1.6778, -1.9371],
        [-1.6943, -1.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06078347936272621
Epoch 0, Step 254: train/loss = 0.6530426144599915, train/raw-loss = 0.6530426144599915, train/logprobs = tensor([[-1.1100, -2.6266],
        [-1.1178, -2.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.010076415725052357
Epoch 0, Step 255: train/loss = 0.65376216173172, train/raw-loss = 0.65376216173172, train/logprobs = tensor([[-1.1201, -1.8139],
        [-1.1666, -1.6833]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012973717413842678
Epoch 0, Step 256: train/loss = 0.5755027532577515, train/raw-loss = 0.5755027532577515, train/logprobs = tensor([[-0.6382, -3.4344],
        [-0.6323, -2.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00728010106831789
Epoch 0, Step 257: train/loss = 0.6618247628211975, train/raw-loss = 0.6618247628211975, train/logprobs = tensor([[-1.0764, -1.4122],
        [-1.1238, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03730868920683861
Epoch 0, Step 258: train/loss = 0.6402729749679565, train/raw-loss = 0.6402729749679565, train/logprobs = tensor([[-1.1978, -2.7530],
        [-1.2161, -2.5336]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.017728276550769806
Epoch 0, Step 259: train/loss = 0.6522279977798462, train/raw-loss = 0.6522279977798462, train/logprobs = tensor([[-0.9947, -1.8939],
        [-1.0148, -1.7294]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04822593182325363
Epoch 0, Step 260: train/loss = 0.6477810144424438, train/raw-loss = 0.6477810144424438, train/logprobs = tensor([[-1.3844, -1.6535],
        [-1.4126, -1.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.034217070788145065
Epoch 0, Step 261: train/loss = 0.6767919659614563, train/raw-loss = 0.6767919659614563, train/logprobs = tensor([[-0.7178, -2.2314],
        [-0.6960, -2.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03983215242624283
Epoch 0, Step 262: train/loss = 0.6098867654800415, train/raw-loss = 0.6098867654800415, train/logprobs = tensor([[-1.0101, -2.6856],
        [-1.0590, -2.3649]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04481169208884239
Epoch 0, Step 263: train/loss = 0.6665858030319214, train/raw-loss = 0.6665858030319214, train/logprobs = tensor([[-1.4040, -1.7064],
        [-1.4879, -1.6474]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02585860900580883
Epoch 0, Step 264: train/loss = 0.6665142774581909, train/raw-loss = 0.6665142774581909, train/logprobs = tensor([[-1.0169, -1.3241],
        [-1.0193, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.043459437787532806
Epoch 0, Step 265: train/loss = 0.6703283786773682, train/raw-loss = 0.6703283786773682, train/logprobs = tensor([[-0.7823, -1.1145],
        [-0.8131, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022132113575935364
Epoch 0, Step 266: train/loss = 0.6821454763412476, train/raw-loss = 0.6821454763412476, train/logprobs = tensor([[-1.0392, -1.8346],
        [-1.1003, -1.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039892107248306274
Epoch 0, Step 267: train/loss = 0.6798661947250366, train/raw-loss = 0.6798661947250366, train/logprobs = tensor([[-1.2245, -1.2602],
        [-1.2965, -1.2773]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.033947210758924484
Epoch 0, Step 268: train/loss = 0.6380306482315063, train/raw-loss = 0.6380306482315063, train/logprobs = tensor([[-1.2626, -2.6487],
        [-1.3430, -2.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.014225967228412628
Epoch 0, Step 269: train/loss = 0.6814707517623901, train/raw-loss = 0.6814707517623901, train/logprobs = tensor([[-1.3682, -1.0154],
        [-1.4057, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04521338641643524
Epoch 0, Step 270: train/loss = 0.6456857919692993, train/raw-loss = 0.6456857919692993, train/logprobs = tensor([[-1.1471, -1.7065],
        [-1.1737, -1.5162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006791507825255394
Epoch 0, Step 271: train/loss = 0.6237197518348694, train/raw-loss = 0.6237197518348694, train/logprobs = tensor([[-0.9638, -2.8098],
        [-0.9521, -2.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02695513889193535
Epoch 0, Step 272: train/loss = 0.6656984686851501, train/raw-loss = 0.6656984686851501, train/logprobs = tensor([[-1.1959, -1.4239],
        [-1.1624, -1.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022203635424375534
Epoch 0, Step 273: train/loss = 0.6537866592407227, train/raw-loss = 0.6537866592407227, train/logprobs = tensor([[-1.4576, -2.1113],
        [-1.4466, -1.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04677264764904976
Epoch 0, Step 274: train/loss = 0.6434188485145569, train/raw-loss = 0.6434188485145569, train/logprobs = tensor([[-1.1063, -1.9344],
        [-1.0822, -1.6840]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05073951184749603
Epoch 0, Step 275: train/loss = 0.7018219232559204, train/raw-loss = 0.7018219232559204, train/logprobs = tensor([[-1.3195, -1.8757],
        [-1.3721, -1.9244]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0045584216713905334
Epoch 0, Step 276: train/loss = 0.6723215579986572, train/raw-loss = 0.6723215579986572, train/logprobs = tensor([[-1.6514, -1.5190],
        [-1.7045, -1.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.031630247831344604
Epoch 0, Step 277: train/loss = 0.6622884273529053, train/raw-loss = 0.6622884273529053, train/logprobs = tensor([[-0.9062, -1.9457],
        [-0.9306, -1.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01995929703116417
Epoch 0, Step 278: train/loss = 0.6611247062683105, train/raw-loss = 0.6611247062683105, train/logprobs = tensor([[-1.4017, -1.9031],
        [-1.3669, -1.7031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01642630621790886
Epoch 0, Step 279: train/loss = 0.6398312449455261, train/raw-loss = 0.6398312449455261, train/logprobs = tensor([[-1.1590, -2.2562],
        [-1.1746, -1.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.037883635610342026
Epoch 0, Step 280: train/loss = 0.6726260185241699, train/raw-loss = 0.6726260185241699, train/logprobs = tensor([[-1.4201, -2.4560],
        [-1.4198, -2.3379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01535403449088335
Epoch 0, Step 281: train/loss = 0.6160457134246826, train/raw-loss = 0.6160457134246826, train/logprobs = tensor([[-1.4571, -2.9672],
        [-1.5429, -2.6576]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011936318129301071
Epoch 0, Step 282: train/loss = 0.6358535885810852, train/raw-loss = 0.6358535885810852, train/logprobs = tensor([[-1.2684, -1.6062],
        [-1.3364, -1.4300]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.040634579956531525
Epoch 0, Step 283: train/loss = 0.6211212277412415, train/raw-loss = 0.6211212277412415, train/logprobs = tensor([[-1.2444, -2.7806],
        [-1.2574, -2.4615]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02367579936981201
Epoch 0, Step 284: train/loss = 0.620512843132019, train/raw-loss = 0.620512843132019, train/logprobs = tensor([[-1.1668, -1.7172],
        [-1.1795, -1.4042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030215710401535034
Epoch 0, Step 285: train/loss = 0.6191428899765015, train/raw-loss = 0.6191428899765015, train/logprobs = tensor([[-1.0290, -3.0329],
        [-1.1046, -2.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03089657425880432
Epoch 0, Step 286: train/loss = 0.6544309854507446, train/raw-loss = 0.6544309854507446, train/logprobs = tensor([[-1.0237, -1.8106],
        [-1.0190, -1.6347]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.003259532153606415
Epoch 0, Step 287: train/loss = 0.6679868698120117, train/raw-loss = 0.6679868698120117, train/logprobs = tensor([[-1.0922, -1.4437],
        [-1.0926, -1.3188]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.028027620166540146
Epoch 0, Step 288: train/loss = 0.6581963896751404, train/raw-loss = 0.6581963896751404, train/logprobs = tensor([[-0.9163, -1.3264],
        [-0.9257, -1.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03715382143855095
Epoch 0, Step 289: train/loss = 0.6715424060821533, train/raw-loss = 0.6715424060821533, train/logprobs = tensor([[-1.0477, -1.0588],
        [-1.0766, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.009682527743279934
Epoch 0, Step 290: train/loss = 0.6055216789245605, train/raw-loss = 0.6055216789245605, train/logprobs = tensor([[-1.3784, -2.5190],
        [-1.4436, -2.1516]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.039842672646045685
Epoch 0, Step 291: train/loss = 0.6422541737556458, train/raw-loss = 0.6422541737556458, train/logprobs = tensor([[-1.5323, -2.0273],
        [-1.5882, -1.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.020042911171913147
Epoch 0, Step 292: train/loss = 0.6043031215667725, train/raw-loss = 0.6043031215667725, train/logprobs = tensor([[-1.2265, -2.6843],
        [-1.2297, -2.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007397699169814587
Epoch 0, Step 293: train/loss = 0.657017707824707, train/raw-loss = 0.657017707824707, train/logprobs = tensor([[-0.8954, -1.6617],
        [-0.9566, -1.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03543476760387421
Epoch 0, Step 294: train/loss = 0.5820189118385315, train/raw-loss = 0.5820189118385315, train/logprobs = tensor([[-1.4967, -2.3851],
        [-1.5456, -1.9353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024024508893489838
Epoch 0, Step 295: train/loss = 0.6183881759643555, train/raw-loss = 0.6183881759643555, train/logprobs = tensor([[-1.2631, -2.3075],
        [-1.3529, -2.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04367242008447647
Epoch 0, Step 296: train/loss = 0.6181746125221252, train/raw-loss = 0.6181746125221252, train/logprobs = tensor([[-0.8455, -2.2666],
        [-0.8956, -1.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05480312556028366
Epoch 0, Step 297: train/loss = 0.640914261341095, train/raw-loss = 0.640914261341095, train/logprobs = tensor([[-1.7027, -2.0793],
        [-1.7545, -1.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.034943532198667526
Epoch 0, Step 298: train/loss = 0.6070855855941772, train/raw-loss = 0.6070855855941772, train/logprobs = tensor([[-0.9400, -1.8366],
        [-0.9930, -1.4861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028431732207536697
Epoch 0, Step 299: train/loss = 0.5988706350326538, train/raw-loss = 0.5988706350326538, train/logprobs = tensor([[-0.7715, -2.4990],
        [-0.7847, -2.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003914430737495422
Epoch 0, Step 300: train/loss = 0.5857884287834167, train/raw-loss = 0.5857884287834167, train/logprobs = tensor([[-1.4751, -2.7709],
        [-1.5433, -2.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01905396208167076
Epoch 0, Step 301: train/loss = 0.6744664907455444, train/raw-loss = 0.6744664907455444, train/logprobs = tensor([[-0.9855, -1.1030],
        [-1.0678, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04442267119884491
Epoch 0, Step 302: train/loss = 0.6467200517654419, train/raw-loss = 0.6467200517654419, train/logprobs = tensor([[-1.5321, -2.2947],
        [-1.4087, -1.8757]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05499735102057457
Epoch 0, Step 303: train/loss = 0.6114559769630432, train/raw-loss = 0.6114559769630432, train/logprobs = tensor([[-1.1198, -2.1728],
        [-1.1140, -1.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.004227837547659874
Epoch 0, Step 304: train/loss = 0.6927962303161621, train/raw-loss = 0.6927962303161621, train/logprobs = tensor([[-2.1548, -1.7010],
        [-2.1345, -1.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0225038044154644
Epoch 0, Step 305: train/loss = 0.6758428812026978, train/raw-loss = 0.6758428812026978, train/logprobs = tensor([[-1.2831, -1.5036],
        [-1.2149, -1.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04948234558105469
Epoch 0, Step 306: train/loss = 0.6226282715797424, train/raw-loss = 0.6226282715797424, train/logprobs = tensor([[-1.4836, -4.1612],
        [-1.4513, -3.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019602417945861816
Epoch 0, Step 307: train/loss = 0.6320236325263977, train/raw-loss = 0.6320236325263977, train/logprobs = tensor([[-0.9340, -1.6198],
        [-0.9773, -1.3965]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03232577443122864
Epoch 0, Step 308: train/loss = 0.6540902853012085, train/raw-loss = 0.6540902853012085, train/logprobs = tensor([[-0.9477, -1.1304],
        [-1.0264, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0438687838613987
Epoch 0, Step 309: train/loss = 0.6530544757843018, train/raw-loss = 0.6530544757843018, train/logprobs = tensor([[-0.7482, -1.4012],
        [-0.7342, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01940833404660225
Epoch 0, Step 310: train/loss = 0.6588661074638367, train/raw-loss = 0.6588661074638367, train/logprobs = tensor([[-1.6800, -2.0458],
        [-1.6652, -1.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017468919977545738
Epoch 0, Step 311: train/loss = 0.688840925693512, train/raw-loss = 0.688840925693512, train/logprobs = tensor([[-0.8055, -1.1772],
        [-0.8643, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05562783032655716
Epoch 0, Step 312: train/loss = 0.6295794248580933, train/raw-loss = 0.6295794248580933, train/logprobs = tensor([[-1.1041, -2.0784],
        [-1.1466, -1.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.09647002071142197
Epoch 0, Step 313: train/loss = 0.6462279558181763, train/raw-loss = 0.6462279558181763, train/logprobs = tensor([[-1.0434, -1.3034],
        [-1.1318, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03511849045753479
Epoch 0, Step 314: train/loss = 0.6493726968765259, train/raw-loss = 0.6493726968765259, train/logprobs = tensor([[-1.0508, -1.6747],
        [-1.1246, -1.5655]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04818199947476387
Epoch 0, Step 315: train/loss = 0.6431688666343689, train/raw-loss = 0.6431688666343689, train/logprobs = tensor([[-1.4916, -2.6693],
        [-1.4682, -2.4224]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03349258750677109
Epoch 0, Step 316: train/loss = 0.642622709274292, train/raw-loss = 0.642622709274292, train/logprobs = tensor([[-1.6092, -1.7754],
        [-1.7194, -1.6671]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02862374112010002
Epoch 0, Step 317: train/loss = 0.6052654981613159, train/raw-loss = 0.6052654981613159, train/logprobs = tensor([[-1.0749, -1.9547],
        [-1.1460, -1.6299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040169693529605865
Epoch 0, Step 318: train/loss = 0.6777091026306152, train/raw-loss = 0.6777091026306152, train/logprobs = tensor([[-0.7982, -1.2402],
        [-0.8115, -1.1869]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.08538971096277237
Epoch 0, Step 319: train/loss = 0.639112114906311, train/raw-loss = 0.639112114906311, train/logprobs = tensor([[-0.8030, -1.8831],
        [-0.8709, -1.7054]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07247327268123627
Epoch 0, Step 320: train/loss = 0.5898189544677734, train/raw-loss = 0.5898189544677734, train/logprobs = tensor([[-0.7133, -1.9541],
        [-0.7207, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.033400993794202805
Epoch 0, Step 321: train/loss = 0.5479756593704224, train/raw-loss = 0.5479756593704224, train/logprobs = tensor([[-1.2366, -2.4071],
        [-1.2591, -1.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.050276726484298706
Epoch 0, Step 322: train/loss = 0.6597684025764465, train/raw-loss = 0.6597684025764465, train/logprobs = tensor([[-0.8871, -1.1231],
        [-0.9295, -1.0142]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.09393953531980515
Epoch 0, Step 323: train/loss = 0.5925624370574951, train/raw-loss = 0.5925624370574951, train/logprobs = tensor([[-1.0665, -2.8721],
        [-1.1415, -2.4890]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.050691455602645874
Epoch 0, Step 324: train/loss = 0.49848872423171997, train/raw-loss = 0.49848872423171997, train/logprobs = tensor([[-1.3274, -3.9628],
        [-1.2234, -2.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.050930749624967575
Epoch 0, Step 325: train/loss = 0.5913640856742859, train/raw-loss = 0.5913640856742859, train/logprobs = tensor([[-1.2614, -2.1557],
        [-1.3049, -1.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07920251786708832
Epoch 0, Step 326: train/loss = 0.6390919089317322, train/raw-loss = 0.6390919089317322, train/logprobs = tensor([[-1.2333, -1.9715],
        [-1.2513, -1.7346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022836726158857346
Epoch 0, Step 327: train/loss = 0.6325851678848267, train/raw-loss = 0.6325851678848267, train/logprobs = tensor([[-1.2909, -2.4917],
        [-1.2938, -2.2251]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03807603567838669
Epoch 0, Step 328: train/loss = 0.5840444564819336, train/raw-loss = 0.5840444564819336, train/logprobs = tensor([[-1.4161, -2.4935],
        [-1.4514, -1.9947]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06720025837421417
Epoch 0, Step 329: train/loss = 0.4908343255519867, train/raw-loss = 0.4908343255519867, train/logprobs = tensor([[-0.8196, -3.5215],
        [-0.8460, -2.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06487107276916504
Epoch 0, Step 330: train/loss = 0.587607741355896, train/raw-loss = 0.587607741355896, train/logprobs = tensor([[-1.1434, -2.3296],
        [-1.1866, -1.9188]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07321866601705551
Epoch 0, Step 331: train/loss = 0.634995698928833, train/raw-loss = 0.634995698928833, train/logprobs = tensor([[-1.3194, -1.8567],
        [-1.3140, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.015193543396890163
Epoch 0, Step 332: train/loss = 0.5459848642349243, train/raw-loss = 0.5459848642349243, train/logprobs = tensor([[-1.6166, -4.5859],
        [-1.5408, -3.7574]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022880250588059425
Epoch 0, Step 333: train/loss = 0.6421273946762085, train/raw-loss = 0.6421273946762085, train/logprobs = tensor([[-1.2101, -2.1168],
        [-1.3392, -2.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.08563199639320374
Epoch 0, Step 334: train/loss = 0.633421778678894, train/raw-loss = 0.633421778678894, train/logprobs = tensor([[-0.8955, -1.7245],
        [-0.9105, -1.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04355360195040703
Epoch 0, Step 335: train/loss = 0.6639803647994995, train/raw-loss = 0.6639803647994995, train/logprobs = tensor([[-1.4544, -1.8091],
        [-1.4694, -1.6292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009581342339515686
Epoch 0, Step 336: train/loss = 0.6177822947502136, train/raw-loss = 0.6177822947502136, train/logprobs = tensor([[-1.4562, -2.7561],
        [-1.5110, -2.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02441881224513054
Epoch 0, Step 337: train/loss = 0.6116132140159607, train/raw-loss = 0.6116132140159607, train/logprobs = tensor([[-1.2125, -2.0409],
        [-1.2199, -1.6606]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04587914049625397
Epoch 0, Step 338: train/loss = 0.6838558912277222, train/raw-loss = 0.6838558912277222, train/logprobs = tensor([[-1.0729, -2.0148],
        [-0.9743, -1.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.021668126806616783
Epoch 0, Step 339: train/loss = 0.5946173667907715, train/raw-loss = 0.5946173667907715, train/logprobs = tensor([[-1.5822, -2.8294],
        [-1.3326, -2.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02293524518609047
Epoch 0, Step 340: train/loss = 0.6242219805717468, train/raw-loss = 0.6242219805717468, train/logprobs = tensor([[-1.5412, -2.1784],
        [-1.4039, -1.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.041622262448072433
Epoch 0, Step 341: train/loss = 0.6501024961471558, train/raw-loss = 0.6501024961471558, train/logprobs = tensor([[-0.8969, -2.1456],
        [-0.9739, -2.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0969075933098793
Epoch 0, Step 342: train/loss = 0.6640920639038086, train/raw-loss = 0.6640920639038086, train/logprobs = tensor([[-1.7419, -2.2523],
        [-1.8600, -2.2226]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.020138762891292572
Epoch 0, Step 343: train/loss = 0.5918461680412292, train/raw-loss = 0.5918461680412292, train/logprobs = tensor([[-1.1474, -2.9213],
        [-1.2846, -2.5151]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.057529717683792114
Epoch 0, Step 344: train/loss = 0.5741863250732422, train/raw-loss = 0.5741863250732422, train/logprobs = tensor([[-0.9865, -2.7486],
        [-0.9589, -2.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04558630660176277
Epoch 0, Step 345: train/loss = 0.7017371654510498, train/raw-loss = 0.7017371654510498, train/logprobs = tensor([[-1.5986, -1.5277],
        [-1.5025, -1.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06768195331096649
Epoch 0, Step 346: train/loss = 0.6435482501983643, train/raw-loss = 0.6435482501983643, train/logprobs = tensor([[-1.8889, -1.9382],
        [-1.9126, -1.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07439357042312622
Epoch 0, Step 347: train/loss = 0.6368774771690369, train/raw-loss = 0.6368774771690369, train/logprobs = tensor([[-1.0133, -1.9159],
        [-1.0180, -1.6758]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07617829740047455
Epoch 0, Step 348: train/loss = 0.6099977493286133, train/raw-loss = 0.6099977493286133, train/logprobs = tensor([[-1.5040, -2.6838],
        [-1.5133, -2.2573]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03065517358481884
Epoch 0, Step 349: train/loss = 0.583544135093689, train/raw-loss = 0.583544135093689, train/logprobs = tensor([[-1.1977, -1.8364],
        [-1.2726, -1.4196]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.08521071821451187
Epoch 0, Step 350: train/loss = 0.6425871849060059, train/raw-loss = 0.6425871849060059, train/logprobs = tensor([[-1.5611, -2.2063],
        [-1.6003, -1.9878]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.026807093992829323
Epoch 0, Step 351: train/loss = 0.6222196221351624, train/raw-loss = 0.6222196221351624, train/logprobs = tensor([[-0.8309, -1.5362],
        [-0.8866, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.059915442019701004
Epoch 0, Step 352: train/loss = 0.4617616534233093, train/raw-loss = 0.4617616534233093, train/logprobs = tensor([[-0.8826, -3.1892],
        [-0.8837, -1.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.028824154287576675
Epoch 0, Step 353: train/loss = 0.5645979642868042, train/raw-loss = 0.5645979642868042, train/logprobs = tensor([[-1.3986, -2.5467],
        [-1.4287, -1.9258]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.047985248267650604
Epoch 0, Step 354: train/loss = 0.6790778636932373, train/raw-loss = 0.6790778636932373, train/logprobs = tensor([[-1.4826, -1.6857],
        [-1.4897, -1.6077]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.038965854793787
Epoch 0, Step 355: train/loss = 0.6570067405700684, train/raw-loss = 0.6570067405700684, train/logprobs = tensor([[-1.2096, -1.3157],
        [-1.1631, -1.0898]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02358766458928585
Epoch 0, Step 356: train/loss = 0.6360740661621094, train/raw-loss = 0.6360740661621094, train/logprobs = tensor([[-0.6944, -1.0942],
        [-0.6288, -0.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.021159309893846512
Epoch 0, Step 357: train/loss = 0.5696579813957214, train/raw-loss = 0.5696579813957214, train/logprobs = tensor([[-1.0535, -2.4763],
        [-0.9703, -1.7984]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06777265667915344
Epoch 0, Step 358: train/loss = 0.5792275071144104, train/raw-loss = 0.5792275071144104, train/logprobs = tensor([[-0.9298, -2.4394],
        [-0.9659, -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0711812898516655
Epoch 0, Step 359: train/loss = 0.5287641286849976, train/raw-loss = 0.5287641286849976, train/logprobs = tensor([[-1.2206, -2.6626],
        [-1.2155, -1.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02673325687646866
Epoch 0, Step 360: train/loss = 0.5797711610794067, train/raw-loss = 0.5797711610794067, train/logprobs = tensor([[-1.0418, -2.2490],
        [-1.0106, -1.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03858859837055206
Epoch 0, Step 361: train/loss = 0.5959280133247375, train/raw-loss = 0.5959280133247375, train/logprobs = tensor([[-1.0140, -2.2507],
        [-1.0679, -1.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.10476033389568329
Epoch 0, Step 362: train/loss = 0.533745527267456, train/raw-loss = 0.533745527267456, train/logprobs = tensor([[-0.8696, -2.3690],
        [-0.8071, -1.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0491914227604866
Epoch 0, Step 363: train/loss = 0.6246537566184998, train/raw-loss = 0.6246537566184998, train/logprobs = tensor([[-1.3864, -2.0711],
        [-1.3158, -1.6910]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04820689931511879
Epoch 0, Step 364: train/loss = 0.5711944699287415, train/raw-loss = 0.5711944699287415, train/logprobs = tensor([[-0.5870, -1.9968],
        [-0.5612, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.045077256858348846
Epoch 0, Step 365: train/loss = 0.5398470163345337, train/raw-loss = 0.5398470163345337, train/logprobs = tensor([[-1.3700, -2.9178],
        [-1.2747, -1.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03425179421901703
Epoch 0, Step 366: train/loss = 0.5512771606445312, train/raw-loss = 0.5512771606445312, train/logprobs = tensor([[-1.4599, -3.0793],
        [-1.3465, -2.2531]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012010045349597931
Epoch 0, Step 367: train/loss = 0.6048760414123535, train/raw-loss = 0.6048760414123535, train/logprobs = tensor([[-1.9658, -2.3990],
        [-1.9198, -1.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0734463483095169
Epoch 0, Step 368: train/loss = 0.5537019968032837, train/raw-loss = 0.5537019968032837, train/logprobs = tensor([[-0.9675, -2.4999],
        [-0.9079, -1.7605]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05262753739953041
Epoch 0, Step 369: train/loss = 0.6098480224609375, train/raw-loss = 0.6098480224609375, train/logprobs = tensor([[-1.3461, -2.8172],
        [-1.2819, -2.2927]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.048086412250995636
Epoch 0, Step 370: train/loss = 0.6018679141998291, train/raw-loss = 0.6018679141998291, train/logprobs = tensor([[-1.3315, -2.5490],
        [-1.1686, -1.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.09200848639011383
Epoch 0, Step 371: train/loss = 0.6163365244865417, train/raw-loss = 0.6163365244865417, train/logprobs = tensor([[-1.3073, -2.1550],
        [-1.4347, -1.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0725473016500473
Epoch 0, Step 372: train/loss = 0.537534773349762, train/raw-loss = 0.537534773349762, train/logprobs = tensor([[-0.8451, -2.6589],
        [-0.8103, -1.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04493241757154465
Epoch 0, Step 373: train/loss = 0.5878936052322388, train/raw-loss = 0.5878936052322388, train/logprobs = tensor([[-0.9121, -2.6456],
        [-0.9159, -2.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0717741921544075
Epoch 0, Step 374: train/loss = 0.6690413355827332, train/raw-loss = 0.6690413355827332, train/logprobs = tensor([[-1.6223, -2.0302],
        [-1.4262, -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03420388698577881
Epoch 0, Step 375: train/loss = 0.5367150902748108, train/raw-loss = 0.5367150902748108, train/logprobs = tensor([[-1.1132, -3.1845],
        [-1.1703, -2.4413]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.07602056860923767
Epoch 0, Step 376: train/loss = 0.5964524745941162, train/raw-loss = 0.5964524745941162, train/logprobs = tensor([[-0.7680, -2.3957],
        [-0.7175, -1.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06939006596803665
Epoch 0, Step 377: train/loss = 0.6413401961326599, train/raw-loss = 0.6413401961326599, train/logprobs = tensor([[-1.4785, -1.8350],
        [-1.4894, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06331303715705872
Epoch 0, Step 378: train/loss = 0.5779449343681335, train/raw-loss = 0.5779449343681335, train/logprobs = tensor([[-0.8075, -2.5269],
        [-0.8063, -1.9171]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06237567961215973
Epoch 0, Step 379: train/loss = 0.48358625173568726, train/raw-loss = 0.48358625173568726, train/logprobs = tensor([[-1.4612, -3.0596],
        [-1.4748, -1.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05124340578913689
Epoch 0, Step 380: train/loss = 0.5857236385345459, train/raw-loss = 0.5857236385345459, train/logprobs = tensor([[-1.2378, -2.9476],
        [-1.1465, -2.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05020748823881149
Epoch 0, Step 381: train/loss = 0.6486216187477112, train/raw-loss = 0.6486216187477112, train/logprobs = tensor([[-1.9031, -1.7366],
        [-1.9108, -1.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0683484598994255
Epoch 0, Step 382: train/loss = 0.5548313856124878, train/raw-loss = 0.5548313856124878, train/logprobs = tensor([[-1.0987, -2.8451],
        [-1.0961, -2.1321]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03210422024130821
Epoch 0, Step 383: train/loss = 0.6176120042800903, train/raw-loss = 0.6176120042800903, train/logprobs = tensor([[-1.7404, -2.9237],
        [-1.7322, -2.5473]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06095578894019127
Epoch 0, Step 384: train/loss = 0.5712133646011353, train/raw-loss = 0.5712133646011353, train/logprobs = tensor([[-1.7187, -2.6442],
        [-1.5153, -1.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037638820707798004
Epoch 0, Step 385: train/loss = 0.4592548608779907, train/raw-loss = 0.4592548608779907, train/logprobs = tensor([[-1.1738, -3.5896],
        [-1.1822, -2.3238]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.004372967407107353
Epoch 0, Step 386: train/loss = 0.474987655878067, train/raw-loss = 0.474987655878067, train/logprobs = tensor([[-0.7530, -3.5014],
        [-0.7514, -2.3847]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.039726704359054565
Epoch 0, Step 387: train/loss = 0.40435534715652466, train/raw-loss = 0.40435534715652466, train/logprobs = tensor([[-1.5043, -3.2051],
        [-1.4220, -1.4343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06951839476823807
Epoch 0, Step 388: train/loss = 0.6105918288230896, train/raw-loss = 0.6105918288230896, train/logprobs = tensor([[-1.6173, -1.9489],
        [-1.4507, -1.3731]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0266409981995821
Epoch 0, Step 389: train/loss = 0.5369867086410522, train/raw-loss = 0.5369867086410522, train/logprobs = tensor([[-1.3691, -2.7152],
        [-1.3043, -1.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05919603258371353
Epoch 0, Step 390: train/loss = 0.6709496974945068, train/raw-loss = 0.6709496974945068, train/logprobs = tensor([[-1.6981, -1.6085],
        [-1.4569, -1.2207]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022389080375432968
Epoch 0, Step 391: train/loss = 0.6967501640319824, train/raw-loss = 0.6967501640319824, train/logprobs = tensor([[-1.3949, -1.0325],
        [-1.2274, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.010712843388319016
Epoch 0, Step 392: train/loss = 0.638462483882904, train/raw-loss = 0.638462483882904, train/logprobs = tensor([[-1.1847, -1.2619],
        [-0.8890, -0.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05683712661266327
Epoch 0, Step 393: train/loss = 0.5616083145141602, train/raw-loss = 0.5616083145141602, train/logprobs = tensor([[-1.3379, -2.1640],
        [-1.3007, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06606937199831009
Epoch 0, Step 394: train/loss = 0.5921836495399475, train/raw-loss = 0.5921836495399475, train/logprobs = tensor([[-1.5866, -2.8194],
        [-1.4077, -2.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.018371550366282463
Epoch 0, Step 395: train/loss = 0.47124767303466797, train/raw-loss = 0.47124767303466797, train/logprobs = tensor([[-1.7916, -2.8870],
        [-1.5649, -1.5670]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.007043834775686264
Epoch 0, Step 396: train/loss = 0.5285953283309937, train/raw-loss = 0.5285953283309937, train/logprobs = tensor([[-1.1094, -2.3479],
        [-1.1022, -1.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04921790957450867
Epoch 0, Step 397: train/loss = 0.5679308772087097, train/raw-loss = 0.5679308772087097, train/logprobs = tensor([[-1.3904, -2.2927],
        [-1.3060, -1.6240]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03650296479463577
Epoch 0, Step 398: train/loss = 0.5812247395515442, train/raw-loss = 0.5812247395515442, train/logprobs = tensor([[-1.1746, -1.8609],
        [-1.0303, -1.1849]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012655496597290039
Epoch 0, Step 399: train/loss = 0.45218855142593384, train/raw-loss = 0.45218855142593384, train/logprobs = tensor([[-0.8428, -2.5240],
        [-0.7925, -1.3140]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01369316317141056
Epoch 0, Step 400: train/loss = 0.6438333988189697, train/raw-loss = 0.6438333988189697, train/logprobs = tensor([[-0.9729, -1.0354],
        [-1.0289, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06812623143196106
Epoch 0, Step 401: train/loss = 0.5181119441986084, train/raw-loss = 0.5181119441986084, train/logprobs = tensor([[-1.1429, -2.3855],
        [-1.1641, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.026228390634059906
Epoch 0, Step 402: train/loss = 0.5589727163314819, train/raw-loss = 0.5589727163314819, train/logprobs = tensor([[-1.4758, -2.2514],
        [-1.2679, -1.3760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04111967608332634
Epoch 0, Step 403: train/loss = 0.4174375534057617, train/raw-loss = 0.4174375534057617, train/logprobs = tensor([[-1.5450, -4.3207],
        [-1.3810, -2.7117]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.010648157447576523
Epoch 0, Step 404: train/loss = 0.425156831741333, train/raw-loss = 0.425156831741333, train/logprobs = tensor([[-1.3615, -3.2833],
        [-1.4115, -1.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.00512070395052433
Epoch 0, Step 405: train/loss = 0.561700701713562, train/raw-loss = 0.561700701713562, train/logprobs = tensor([[-1.6103, -2.6106],
        [-1.5629, -1.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.055388227105140686
Epoch 0, Step 406: train/loss = 0.48366692662239075, train/raw-loss = 0.48366692662239075, train/logprobs = tensor([[-0.9642, -2.5172],
        [-1.0111, -1.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026250556111335754
Epoch 0, Step 407: train/loss = 0.6537576913833618, train/raw-loss = 0.6537576913833618, train/logprobs = tensor([[-0.6698, -0.9723],
        [-0.6864, -0.8189]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05624164640903473
Epoch 0, Step 408: train/loss = 0.5356259346008301, train/raw-loss = 0.5356259346008301, train/logprobs = tensor([[-1.2946, -3.3817],
        [-1.1913, -2.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06981083750724792
Epoch 0, Step 409: train/loss = 0.5420357584953308, train/raw-loss = 0.5420357584953308, train/logprobs = tensor([[-1.7736, -3.9354],
        [-1.5635, -2.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011378089897334576
Epoch 0, Step 410: train/loss = 0.487490177154541, train/raw-loss = 0.487490177154541, train/logprobs = tensor([[-1.1460, -2.8393],
        [-1.0822, -1.7155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01634007692337036
Epoch 0, Step 411: train/loss = 0.6040855646133423, train/raw-loss = 0.6040855646133423, train/logprobs = tensor([[-1.1785, -2.2492],
        [-1.1608, -1.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.09642760455608368
Epoch 0, Step 412: train/loss = 0.38053250312805176, train/raw-loss = 0.38053250312805176, train/logprobs = tensor([[-1.4685, -3.7680],
        [-1.4571, -2.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.006170950829982758
Epoch 0, Step 413: train/loss = 0.5933057069778442, train/raw-loss = 0.5933057069778442, train/logprobs = tensor([[-1.1899, -1.9765],
        [-1.2570, -1.5626]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05828087776899338
Epoch 0, Step 414: train/loss = 0.620820939540863, train/raw-loss = 0.620820939540863, train/logprobs = tensor([[-1.4087, -1.9300],
        [-1.3750, -1.5738]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.010378437116742134
Epoch 0, Step 415: train/loss = 0.6355642676353455, train/raw-loss = 0.6355642676353455, train/logprobs = tensor([[-2.0607, -2.0252],
        [-1.8422, -1.4852]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01504097506403923
Epoch 0, Step 416: train/loss = 0.5820935368537903, train/raw-loss = 0.5820935368537903, train/logprobs = tensor([[-1.5138, -2.0971],
        [-1.1906, -1.1759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032769083976745605
Epoch 0, Step 417: train/loss = 0.5890204906463623, train/raw-loss = 0.5890204906463623, train/logprobs = tensor([[-0.9837, -1.8234],
        [-0.9413, -1.2505]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0976029485464096
Epoch 0, Step 418: train/loss = 0.6089650392532349, train/raw-loss = 0.6089650392532349, train/logprobs = tensor([[-0.8112, -1.5498],
        [-0.7856, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06396694481372833
Epoch 0, Step 419: train/loss = 0.4894849956035614, train/raw-loss = 0.4894849956035614, train/logprobs = tensor([[-1.2661, -2.7457],
        [-1.1772, -1.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0007630097679793835
Epoch 0, Step 420: train/loss = 0.5760416984558105, train/raw-loss = 0.5760416984558105, train/logprobs = tensor([[-1.2163, -1.9719],
        [-1.1704, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.028621777892112732
Epoch 0, Step 421: train/loss = 0.5282624959945679, train/raw-loss = 0.5282624959945679, train/logprobs = tensor([[-1.4470, -2.0504],
        [-1.1839, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030733607709407806
Epoch 0, Step 422: train/loss = 0.5667426586151123, train/raw-loss = 0.5667426586151123, train/logprobs = tensor([[-1.0959, -1.4607],
        [-1.0496, -0.8338]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012851817533373833
Epoch 0, Step 423: train/loss = 0.5205938220024109, train/raw-loss = 0.5205938220024109, train/logprobs = tensor([[-1.6248, -2.7753],
        [-1.6159, -1.8803]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.06675254553556442
Epoch 0, Step 424: train/loss = 0.6223953366279602, train/raw-loss = 0.6223953366279602, train/logprobs = tensor([[-1.1820, -1.5232],
        [-1.0579, -0.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006940160878002644
Epoch 0, Step 425: train/loss = 0.5008122324943542, train/raw-loss = 0.5008122324943542, train/logprobs = tensor([[-0.8772, -2.6420],
        [-0.8712, -1.6925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023483550176024437
Epoch 0, Step 426: train/loss = 0.49491456151008606, train/raw-loss = 0.49491456151008606, train/logprobs = tensor([[-1.3200, -2.6351],
        [-1.3246, -1.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.024287160485982895
Epoch 0, Step 427: train/loss = 0.656649649143219, train/raw-loss = 0.656649649143219, train/logprobs = tensor([[-1.3512, -1.2846],
        [-1.2147, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05988531559705734
Epoch 0, Step 428: train/loss = 0.5311251282691956, train/raw-loss = 0.5311251282691956, train/logprobs = tensor([[-1.0733, -2.0455],
        [-1.0041, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0245750080794096
Epoch 0, Step 429: train/loss = 0.44973307847976685, train/raw-loss = 0.44973307847976685, train/logprobs = tensor([[-1.7636, -3.0232],
        [-1.6172, -1.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.026318581774830818
Epoch 0, Step 430: train/loss = 0.3457072675228119, train/raw-loss = 0.3457072675228119, train/logprobs = tensor([[-1.2401, -3.6991],
        [-1.0674, -1.6371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06488694250583649
Epoch 0, Step 431: train/loss = 0.5009130239486694, train/raw-loss = 0.5009130239486694, train/logprobs = tensor([[-0.9658, -2.3662],
        [-0.8115, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014946934767067432
Epoch 0, Step 432: train/loss = 0.5022413730621338, train/raw-loss = 0.5022413730621338, train/logprobs = tensor([[-0.9956, -2.2647],
        [-1.0743, -1.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0206579752266407
Epoch 0, Step 433: train/loss = 0.5044819712638855, train/raw-loss = 0.5044819712638855, train/logprobs = tensor([[-1.8719, -2.8199],
        [-1.5489, -1.5960]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0002603805623948574
Epoch 0, Step 434: train/loss = 0.49557214975357056, train/raw-loss = 0.49557214975357056, train/logprobs = tensor([[-1.4107, -2.9013],
        [-1.3568, -1.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04244394600391388
Epoch 0, Step 435: train/loss = 0.4625188708305359, train/raw-loss = 0.4625188708305359, train/logprobs = tensor([[-1.4580, -2.9710],
        [-1.3008, -1.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.028719676658511162
Epoch 0, Step 436: train/loss = 0.5721500515937805, train/raw-loss = 0.5721500515937805, train/logprobs = tensor([[-1.3225, -1.8357],
        [-1.2516, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0033280570060014725
Epoch 0, Step 437: train/loss = 0.44006890058517456, train/raw-loss = 0.44006890058517456, train/logprobs = tensor([[-1.3185, -4.1733],
        [-1.1946, -2.6266]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02227368950843811
Epoch 0, Step 438: train/loss = 0.4303097128868103, train/raw-loss = 0.4303097128868103, train/logprobs = tensor([[-1.1958, -3.4056],
        [-1.2100, -1.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03117057867348194
Epoch 0, Step 439: train/loss = 0.5625854730606079, train/raw-loss = 0.5625854730606079, train/logprobs = tensor([[-0.9965, -1.8900],
        [-1.0564, -1.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.027549337595701218
Epoch 0, Step 440: train/loss = 0.5551002025604248, train/raw-loss = 0.5551002025604248, train/logprobs = tensor([[-1.6137, -1.9542],
        [-1.5647, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.045857034623622894
Epoch 0, Step 441: train/loss = 0.37198424339294434, train/raw-loss = 0.37198424339294434, train/logprobs = tensor([[-1.8714, -4.2107],
        [-1.7756, -2.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07925571501255035
Epoch 0, Step 442: train/loss = 0.5942323207855225, train/raw-loss = 0.5942323207855225, train/logprobs = tensor([[-1.2077, -2.0242],
        [-1.1198, -1.4678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04193267226219177
Epoch 0, Step 443: train/loss = 0.44973063468933105, train/raw-loss = 0.44973063468933105, train/logprobs = tensor([[-1.1487, -2.9798],
        [-0.8835, -1.4643]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.007612774148583412
Epoch 0, Step 444: train/loss = 0.580540120601654, train/raw-loss = 0.580540120601654, train/logprobs = tensor([[-2.1681, -2.6253],
        [-1.7824, -1.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.027450386434793472
Epoch 0, Step 445: train/loss = 0.3659401535987854, train/raw-loss = 0.3659401535987854, train/logprobs = tensor([[-0.9868, -3.2930],
        [-0.9533, -1.5099]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.01244020089507103
Epoch 0, Step 446: train/loss = 0.5653710961341858, train/raw-loss = 0.5653710961341858, train/logprobs = tensor([[-1.2618, -1.8215],
        [-1.2913, -1.2367]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.020135309547185898
Epoch 0, Step 447: train/loss = 0.499912291765213, train/raw-loss = 0.499912291765213, train/logprobs = tensor([[-1.5272, -2.7421],
        [-1.4212, -1.6313]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.061623815447092056
Epoch 0, Step 448: train/loss = 0.511070728302002, train/raw-loss = 0.511070728302002, train/logprobs = tensor([[-0.9093, -2.1602],
        [-0.9302, -1.2802]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04797497019171715
Epoch 0, Step 449: train/loss = 0.5477097034454346, train/raw-loss = 0.5477097034454346, train/logprobs = tensor([[-1.4581, -2.0255],
        [-1.2220, -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0065589239820837975
Epoch 0, Step 450: train/loss = 0.5080018043518066, train/raw-loss = 0.5080018043518066, train/logprobs = tensor([[-1.2420, -2.4922],
        [-0.9271, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0940365195274353
Epoch 0, Step 451: train/loss = 0.4733070135116577, train/raw-loss = 0.4733070135116577, train/logprobs = tensor([[-1.2108, -2.5706],
        [-1.0681, -1.3038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011742798611521721
Epoch 0, Step 452: train/loss = 0.4317842721939087, train/raw-loss = 0.4317842721939087, train/logprobs = tensor([[-1.0168, -3.1263],
        [-1.0406, -1.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040677376091480255
Epoch 0, Step 453: train/loss = 0.41017287969589233, train/raw-loss = 0.41017287969589233, train/logprobs = tensor([[-1.6668, -3.5629],
        [-1.5772, -1.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.029111754149198532
Epoch 0, Step 454: train/loss = 0.5618093013763428, train/raw-loss = 0.5618093013763428, train/logprobs = tensor([[-0.9630, -2.0468],
        [-0.8989, -1.3352]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03443661704659462
Epoch 0, Step 455: train/loss = 0.4516845643520355, train/raw-loss = 0.4516845643520355, train/logprobs = tensor([[-1.2198, -2.5592],
        [-1.1612, -1.0755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019213050603866577
Epoch 0, Step 456: train/loss = 0.5464386940002441, train/raw-loss = 0.5464386940002441, train/logprobs = tensor([[-1.5711, -3.0733],
        [-1.3185, -1.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.05820721387863159
Epoch 0, Step 457: train/loss = 0.5593312382698059, train/raw-loss = 0.5593312382698059, train/logprobs = tensor([[-1.5907, -2.1604],
        [-1.2137, -1.1534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040906183421611786
Epoch 0, Step 458: train/loss = 0.4660898447036743, train/raw-loss = 0.4660898447036743, train/logprobs = tensor([[-0.7718, -2.4508],
        [-0.6740, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.014166822656989098
Epoch 0, Step 459: train/loss = 0.46684178709983826, train/raw-loss = 0.46684178709983826, train/logprobs = tensor([[-1.3073, -2.5217],
        [-1.3097, -1.3016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017856206744909286
Epoch 0, Step 460: train/loss = 0.3893014192581177, train/raw-loss = 0.3893014192581177, train/logprobs = tensor([[-1.0699, -3.8798],
        [-0.9843, -1.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06618132442235947
Epoch 0, Step 461: train/loss = 0.5821860432624817, train/raw-loss = 0.5821860432624817, train/logprobs = tensor([[-1.3805, -1.8265],
        [-0.9477, -0.8682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0647830218076706
Epoch 0, Step 462: train/loss = 0.550938069820404, train/raw-loss = 0.550938069820404, train/logprobs = tensor([[-1.7125, -2.3794],
        [-1.7074, -1.7404]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.048701174557209015
Epoch 0, Step 463: train/loss = 0.5646284222602844, train/raw-loss = 0.5646284222602844, train/logprobs = tensor([[-1.5826, -2.0322],
        [-1.1510, -1.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011600391939282417
Epoch 0, Step 464: train/loss = 0.4432636499404907, train/raw-loss = 0.4432636499404907, train/logprobs = tensor([[-1.1933, -2.4857],
        [-0.9487, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14951832592487335
Epoch 0, Step 465: train/loss = 0.5263512134552002, train/raw-loss = 0.5263512134552002, train/logprobs = tensor([[-0.8785, -1.9402],
        [-0.8074, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021091219037771225
Epoch 0, Step 466: train/loss = 0.45056062936782837, train/raw-loss = 0.45056062936782837, train/logprobs = tensor([[-0.7662, -2.1479],
        [-0.7909, -0.9909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043303146958351135
Epoch 0, Step 467: train/loss = 0.49562105536460876, train/raw-loss = 0.49562105536460876, train/logprobs = tensor([[-1.0828, -2.5495],
        [-1.1181, -1.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0641091912984848
Epoch 0, Step 468: train/loss = 0.3409939706325531, train/raw-loss = 0.3409939706325531, train/logprobs = tensor([[-1.4422, -3.4535],
        [-1.4184, -1.4274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04463913291692734
Epoch 0, Step 469: train/loss = 0.4539894461631775, train/raw-loss = 0.4539894461631775, train/logprobs = tensor([[-1.1247, -3.6304],
        [-0.9807, -1.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.011193426325917244
Epoch 0, Step 470: train/loss = 0.3824518024921417, train/raw-loss = 0.3824518024921417, train/logprobs = tensor([[-1.4035, -3.5031],
        [-1.4407, -1.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.03033692203462124
Epoch 0, Step 471: train/loss = 0.3689650893211365, train/raw-loss = 0.3689650893211365, train/logprobs = tensor([[-1.1929, -3.5342],
        [-1.0771, -1.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628862276673317
Epoch 0, Step 472: train/loss = 0.4867974519729614, train/raw-loss = 0.4867974519729614, train/logprobs = tensor([[-1.2022, -2.4950],
        [-1.0197, -1.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.012942790985107422
Epoch 0, Step 473: train/loss = 0.41696077585220337, train/raw-loss = 0.41696077585220337, train/logprobs = tensor([[-1.0669, -3.0984],
        [-1.1073, -1.6358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03176272660493851
Epoch 0, Step 474: train/loss = 0.5560083389282227, train/raw-loss = 0.5560083389282227, train/logprobs = tensor([[-0.6130, -2.1345],
        [-0.5832, -1.3287]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.037959374487400055
Epoch 0, Step 475: train/loss = 0.4519764184951782, train/raw-loss = 0.4519764184951782, train/logprobs = tensor([[-1.6382, -2.8057],
        [-1.3741, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.022774480283260345
Epoch 0, Step 476: train/loss = 0.42456501722335815, train/raw-loss = 0.42456501722335815, train/logprobs = tensor([[-1.2956, -3.6071],
        [-1.0006, -1.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.00608546519652009
Epoch 0, Step 477: train/loss = 0.4868084490299225, train/raw-loss = 0.4868084490299225, train/logprobs = tensor([[-1.7686, -3.0097],
        [-1.5582, -1.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058133259415626526
Epoch 0, Step 478: train/loss = 0.520744264125824, train/raw-loss = 0.520744264125824, train/logprobs = tensor([[-1.1485, -2.4647],
        [-1.0453, -1.3709]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04631834477186203
Epoch 0, Step 479: train/loss = 0.4919564425945282, train/raw-loss = 0.4919564425945282, train/logprobs = tensor([[-0.9401, -2.6727],
        [-1.0510, -1.7820]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.007110384292900562
Epoch 0, Step 480: train/loss = 0.5173349380493164, train/raw-loss = 0.5173349380493164, train/logprobs = tensor([[-2.2175, -2.9903],
        [-1.7148, -1.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016774427145719528
Epoch 0, Step 481: train/loss = 0.4360617399215698, train/raw-loss = 0.4360617399215698, train/logprobs = tensor([[-1.3685, -3.3575],
        [-1.3417, -1.4013]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.016398869454860687
Epoch 0, Step 482: train/loss = 0.43334874510765076, train/raw-loss = 0.43334874510765076, train/logprobs = tensor([[-1.5058, -3.9055],
        [-1.0923, -1.8434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0469878651201725
Epoch 0, Step 483: train/loss = 0.3235592842102051, train/raw-loss = 0.3235592842102051, train/logprobs = tensor([[-1.1194, -3.9428],
        [-1.0798, -1.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0024929093196988106
Epoch 0, Step 484: train/loss = 0.4673652648925781, train/raw-loss = 0.4673652648925781, train/logprobs = tensor([[-2.3805, -3.9854],
        [-1.6737, -1.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03915704786777496
Epoch 0, Step 485: train/loss = 0.38259080052375793, train/raw-loss = 0.38259080052375793, train/logprobs = tensor([[-1.3204, -3.9866],
        [-1.2073, -2.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.042369332164525986
Epoch 0, Step 486: train/loss = 0.4794757068157196, train/raw-loss = 0.4794757068157196, train/logprobs = tensor([[-1.1781, -2.1582],
        [-1.1988, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0009585004299879074
Epoch 0, Step 487: train/loss = 0.3368126451969147, train/raw-loss = 0.3368126451969147, train/logprobs = tensor([[-1.1542, -3.7180],
        [-1.1479, -1.6022]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04762519150972366
Epoch 0, Step 488: train/loss = 0.5842193961143494, train/raw-loss = 0.5842193961143494, train/logprobs = tensor([[-2.3605, -3.0152],
        [-1.2043, -1.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08470318466424942
Epoch 0, Step 489: train/loss = 0.40410828590393066, train/raw-loss = 0.40410828590393066, train/logprobs = tensor([[-1.6563, -3.5624],
        [-1.4843, -1.9120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05015556514263153
Epoch 0, Step 490: train/loss = 0.40634652972221375, train/raw-loss = 0.40634652972221375, train/logprobs = tensor([[-1.3753, -4.2907],
        [-0.9308, -2.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04328613728284836
Epoch 0, Step 491: train/loss = 0.588272213935852, train/raw-loss = 0.588272213935852, train/logprobs = tensor([[-1.2769, -1.7370],
        [-1.0108, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05763456970453262
Epoch 0, Step 492: train/loss = 0.40452733635902405, train/raw-loss = 0.40452733635902405, train/logprobs = tensor([[-1.2324, -3.1294],
        [-1.1204, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0001351330429315567
Epoch 0, Step 493: train/loss = 0.5654616951942444, train/raw-loss = 0.5654616951942444, train/logprobs = tensor([[-1.1026, -1.7758],
        [-1.0066, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020146947354078293
Epoch 0, Step 494: train/loss = 0.46155619621276855, train/raw-loss = 0.46155619621276855, train/logprobs = tensor([[-1.4079, -2.9245],
        [-1.4778, -1.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.04107072576880455
Epoch 0, Step 495: train/loss = 0.5926357507705688, train/raw-loss = 0.5926357507705688, train/logprobs = tensor([[-1.1623, -1.4481],
        [-1.0667, -0.9164]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.0395941287279129
Epoch 0, Step 496: train/loss = 0.7426586747169495, train/raw-loss = 0.7426586747169495, train/logprobs = tensor([[-2.0336, -1.2299],
        [-1.4040, -0.7517]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02016870118677616
Epoch 0, Step 497: train/loss = 0.38558661937713623, train/raw-loss = 0.38558661937713623, train/logprobs = tensor([[-1.3419, -3.0265],
        [-1.4167, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046642422676086426
Epoch 0, Step 498: train/loss = 0.4077931046485901, train/raw-loss = 0.4077931046485901, train/logprobs = tensor([[-1.2753, -2.9539],
        [-1.0966, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = -0.02033105678856373
Epoch 0, Step 499: train/loss = 0.3901924788951874, train/raw-loss = 0.3901924788951874, train/logprobs = tensor([[-1.4003, -3.2389],
        [-1.3491, -1.4486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009655249305069447
eval/loss: 0.47209256887435913
