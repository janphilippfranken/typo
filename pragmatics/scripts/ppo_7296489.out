[2024-02-19 14:07:33,454][root][INFO] - beta: 1.0
[2024-02-19 14:07:33,454][root][INFO] - temperature: 1
[2024-02-19 14:07:33,454][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-batch-size-32
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-batch-size-32 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-batch-size-32 after each epoch.
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-batch-size-32 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-1.0-batch-size-32 after each epoch.
Epoch 0, Step 7: train/loss = 0.7075663805007935, train/raw-loss = 0.7075663805007935, train/logprobs = tensor([[-0.7880, -0.6978],
        [-0.8163, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7054764628410339, train/raw-loss = 0.7054764628410339, train/logprobs = tensor([[-0.5966, -0.8092],
        [-0.5724, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7439368963241577, train/raw-loss = 0.7438913583755493, train/logprobs = tensor([[-0.9630, -1.4524],
        [-0.9487, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.550272933556698e-05
Epoch 0, Step 31: train/loss = 0.8597599864006042, train/raw-loss = 0.8597258925437927, train/logprobs = tensor([[-0.8199, -1.3969],
        [-0.8484, -1.3205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4126045648008585e-05
Epoch 0, Step 39: train/loss = 0.6972277164459229, train/raw-loss = 0.697185218334198, train/logprobs = tensor([[-0.8962, -0.8004],
        [-0.9122, -0.7790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.249034100212157e-05
Epoch 0, Step 47: train/loss = 0.7206570506095886, train/raw-loss = 0.7203176617622375, train/logprobs = tensor([[-1.2180, -0.9643],
        [-1.3607, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033939225249923766
Epoch 0, Step 55: train/loss = 0.7001825571060181, train/raw-loss = 0.6970734000205994, train/logprobs = tensor([[-1.0945, -1.4918],
        [-1.1979, -1.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031091594137251377
Epoch 0, Step 63: train/loss = 0.7258181571960449, train/raw-loss = 0.7247834205627441, train/logprobs = tensor([[-1.1593, -0.8613],
        [-1.2398, -0.8520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010346914641559124
Epoch 0, Step 71: train/loss = 0.7111968994140625, train/raw-loss = 0.7102696895599365, train/logprobs = tensor([[-1.1212, -0.8966],
        [-1.2747, -0.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009272864554077387
Epoch 0, Step 79: train/loss = 0.7156351804733276, train/raw-loss = 0.7136358618736267, train/logprobs = tensor([[-1.0765, -0.8189],
        [-1.2177, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001999278785660863
Epoch 0, Step 87: train/loss = 0.7246547937393188, train/raw-loss = 0.7244161367416382, train/logprobs = tensor([[-0.9833, -1.0889],
        [-1.1080, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023863828391768038
Epoch 0, Step 95: train/loss = 0.69850754737854, train/raw-loss = 0.6981891393661499, train/logprobs = tensor([[-1.0031, -0.9529],
        [-1.0746, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031840032897889614
Epoch 0, Step 103: train/loss = 0.7006438970565796, train/raw-loss = 0.6979144215583801, train/logprobs = tensor([[-1.0738, -1.0405],
        [-1.2277, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027294696774333715
Epoch 0, Step 111: train/loss = 0.7083880305290222, train/raw-loss = 0.7080360054969788, train/logprobs = tensor([[-0.9843, -1.1292],
        [-1.0396, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003520188620314002
Epoch 0, Step 119: train/loss = 0.7109517455101013, train/raw-loss = 0.7090373039245605, train/logprobs = tensor([[-0.8929, -1.1552],
        [-0.8848, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019145328551530838
Epoch 0, Step 127: train/loss = 0.7091463804244995, train/raw-loss = 0.7088745832443237, train/logprobs = tensor([[-1.0325, -1.2816],
        [-1.0768, -1.3085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002717866445891559
Epoch 0, Step 135: train/loss = 0.6956871747970581, train/raw-loss = 0.6952934265136719, train/logprobs = tensor([[-1.0593, -1.0081],
        [-1.0625, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003937548026442528
Epoch 0, Step 143: train/loss = 0.6980748176574707, train/raw-loss = 0.6966174244880676, train/logprobs = tensor([[-1.2390, -1.1307],
        [-1.6979, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001457389909774065
Epoch 0, Step 151: train/loss = 0.6989040374755859, train/raw-loss = 0.698611319065094, train/logprobs = tensor([[-1.0403, -1.0241],
        [-1.0618, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029271614039316773
Epoch 0, Step 159: train/loss = 0.7541526556015015, train/raw-loss = 0.7535955309867859, train/logprobs = tensor([[-0.8615, -1.4091],
        [-0.9493, -1.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005571098299697042
Epoch 0, Step 167: train/loss = 0.701626181602478, train/raw-loss = 0.7001572847366333, train/logprobs = tensor([[-1.0419, -1.1979],
        [-1.0738, -1.1941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014689244562759995
Epoch 0, Step 175: train/loss = 0.7091573476791382, train/raw-loss = 0.7069830894470215, train/logprobs = tensor([[-1.1949, -1.1356],
        [-1.2145, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002174290595576167
Epoch 0, Step 183: train/loss = 0.6956233978271484, train/raw-loss = 0.6953710913658142, train/logprobs = tensor([[-1.1421, -1.0538],
        [-1.1914, -1.1074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002522818685974926
Epoch 0, Step 191: train/loss = 0.6968534588813782, train/raw-loss = 0.6968516111373901, train/logprobs = tensor([[-1.0825, -0.9934],
        [-1.0874, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.813459675759077e-06
Epoch 0, Step 199: train/loss = 0.7097523212432861, train/raw-loss = 0.708830714225769, train/logprobs = tensor([[-1.0255, -0.9740],
        [-1.0407, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000921556493267417
Epoch 0, Step 207: train/loss = 0.6987572908401489, train/raw-loss = 0.6977537870407104, train/logprobs = tensor([[-0.9773, -1.1370],
        [-0.9683, -1.1208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010034566512331367
Epoch 0, Step 215: train/loss = 0.6996130347251892, train/raw-loss = 0.6988071203231812, train/logprobs = tensor([[-1.0276, -0.9982],
        [-1.0694, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008059443207457662
Epoch 0, Step 223: train/loss = 0.7503280639648438, train/raw-loss = 0.7502838373184204, train/logprobs = tensor([[-1.2155, -0.8272],
        [-1.2163, -0.8333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.419166361913085e-05
Epoch 0, Step 231: train/loss = 0.6968563199043274, train/raw-loss = 0.6967449188232422, train/logprobs = tensor([[-0.9534, -0.8542],
        [-0.9710, -0.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011138044646941125
Epoch 0, Step 239: train/loss = 0.7065202593803406, train/raw-loss = 0.7050182819366455, train/logprobs = tensor([[-1.0525, -0.8896],
        [-1.1352, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015020002610981464
Epoch 0, Step 247: train/loss = 0.6963629722595215, train/raw-loss = 0.696197509765625, train/logprobs = tensor([[-0.9686, -1.0325],
        [-0.9882, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016546658298466355
Epoch 0, Step 255: train/loss = 0.7164402008056641, train/raw-loss = 0.7149312496185303, train/logprobs = tensor([[-0.8046, -0.8687],
        [-1.0548, -0.8785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015089702792465687
Epoch 0, Step 263: train/loss = 0.6953510642051697, train/raw-loss = 0.6952940225601196, train/logprobs = tensor([[-0.6894, -0.7782],
        [-0.7066, -0.7913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.694921128451824e-05
Epoch 0, Step 271: train/loss = 0.7007517218589783, train/raw-loss = 0.7004660964012146, train/logprobs = tensor([[-1.1379, -1.3201],
        [-1.1641, -1.3380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002856363425962627
Epoch 0, Step 279: train/loss = 0.6952841281890869, train/raw-loss = 0.6950079202651978, train/logprobs = tensor([[-1.0954, -1.2460],
        [-1.2059, -1.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002761636860668659
Epoch 0, Step 287: train/loss = 0.7223846912384033, train/raw-loss = 0.7216672897338867, train/logprobs = tensor([[-1.1187, -1.3632],
        [-1.1293, -1.1980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007173531921580434
Epoch 0, Step 295: train/loss = 0.7032874822616577, train/raw-loss = 0.7032389640808105, train/logprobs = tensor([[-1.0640, -0.9519],
        [-1.0627, -0.9230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.843497299589217e-05
Epoch 0, Step 303: train/loss = 0.6946528553962708, train/raw-loss = 0.6941550970077515, train/logprobs = tensor([[-0.8766, -0.9653],
        [-0.8925, -0.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004977876669727266
Epoch 0, Step 311: train/loss = 0.7021527886390686, train/raw-loss = 0.7021074295043945, train/logprobs = tensor([[-1.0109, -0.8976],
        [-1.0135, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.535819971351884e-05
Epoch 0, Step 319: train/loss = 0.7009619474411011, train/raw-loss = 0.7009373903274536, train/logprobs = tensor([[-1.1891, -1.4142],
        [-1.1747, -1.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4509703507646918e-05
Epoch 0, Step 327: train/loss = 0.698586642742157, train/raw-loss = 0.6984597444534302, train/logprobs = tensor([[-1.1174, -0.9997],
        [-1.1190, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012685792171396315
Epoch 0, Step 335: train/loss = 0.7002100944519043, train/raw-loss = 0.6997787952423096, train/logprobs = tensor([[-1.1754, -1.3825],
        [-1.1636, -1.3056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043126672971993685
Epoch 0, Step 343: train/loss = 0.6980931758880615, train/raw-loss = 0.6979036927223206, train/logprobs = tensor([[-1.2000, -1.0320],
        [-1.1790, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018952577374875546
Epoch 0, Step 351: train/loss = 0.6976649165153503, train/raw-loss = 0.6962378025054932, train/logprobs = tensor([[-1.2696, -1.2821],
        [-1.2983, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014271009713411331
Epoch 0, Step 359: train/loss = 0.6996150016784668, train/raw-loss = 0.6992682218551636, train/logprobs = tensor([[-1.1458, -1.2826],
        [-1.1985, -1.2997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034688206505961716
Epoch 0, Step 367: train/loss = 0.6978802680969238, train/raw-loss = 0.69568932056427, train/logprobs = tensor([[-1.1671, -1.2679],
        [-1.1415, -1.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021909542847424746
Epoch 0, Step 375: train/loss = 0.6951385736465454, train/raw-loss = 0.6950684785842896, train/logprobs = tensor([[-1.0948, -1.1092],
        [-1.1023, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.010402623564005e-05
Epoch 0, Step 383: train/loss = 0.7050923109054565, train/raw-loss = 0.7038928270339966, train/logprobs = tensor([[-1.1800, -1.0393],
        [-1.1840, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011994478991255164
Epoch 0, Step 391: train/loss = 0.7025034427642822, train/raw-loss = 0.7024092078208923, train/logprobs = tensor([[-1.0495, -1.1437],
        [-1.0484, -1.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.421788854524493e-05
Epoch 0, Step 399: train/loss = 0.7112601399421692, train/raw-loss = 0.7111474275588989, train/logprobs = tensor([[-1.1834, -0.9738],
        [-1.2827, -0.8942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001127246068790555
Epoch 0, Step 407: train/loss = 0.7028288245201111, train/raw-loss = 0.7026385068893433, train/logprobs = tensor([[-1.0812, -1.3675],
        [-1.0717, -1.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019034951401408762
Epoch 0, Step 415: train/loss = 0.6977216601371765, train/raw-loss = 0.6975406408309937, train/logprobs = tensor([[-0.9240, -1.1201],
        [-0.9289, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018096191342920065
Epoch 0, Step 423: train/loss = 0.713640570640564, train/raw-loss = 0.7135356068611145, train/logprobs = tensor([[-1.3398, -1.1991],
        [-1.3438, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010498060146346688
Epoch 0, Step 431: train/loss = 0.6960659623146057, train/raw-loss = 0.6958268284797668, train/logprobs = tensor([[-1.1758, -1.2420],
        [-1.2243, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023915083147585392
Epoch 0, Step 439: train/loss = 0.7184923887252808, train/raw-loss = 0.7175967693328857, train/logprobs = tensor([[-1.2699, -1.5214],
        [-1.2665, -1.4398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008956746896728873
Epoch 0, Step 447: train/loss = 0.6959112882614136, train/raw-loss = 0.6951270699501038, train/logprobs = tensor([[-1.1594, -1.2906],
        [-1.1108, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007842945633456111
Epoch 0, Step 455: train/loss = 0.7134183049201965, train/raw-loss = 0.7132805585861206, train/logprobs = tensor([[-1.1991, -1.1713],
        [-1.1484, -1.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000137814087793231
Epoch 0, Step 463: train/loss = 0.7215025424957275, train/raw-loss = 0.7170344591140747, train/logprobs = tensor([[-1.1820, -1.5822],
        [-1.1951, -1.3902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004468067083507776
Epoch 0, Step 471: train/loss = 0.692112147808075, train/raw-loss = 0.6909930109977722, train/logprobs = tensor([[-1.0747, -1.1813],
        [-1.3483, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011191348312422633
Epoch 0, Step 479: train/loss = 0.694220781326294, train/raw-loss = 0.6939582824707031, train/logprobs = tensor([[-1.1540, -1.1511],
        [-1.3103, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002624944318085909
Epoch 0, Step 487: train/loss = 0.696492612361908, train/raw-loss = 0.6963062882423401, train/logprobs = tensor([[-1.0808, -1.1417],
        [-0.9858, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018628337420523167
Epoch 0, Step 495: train/loss = 0.6990559697151184, train/raw-loss = 0.6987615823745728, train/logprobs = tensor([[-1.1260, -1.2140],
        [-1.1013, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029448047280311584
Epoch 0, Step 503: train/loss = 0.7055034637451172, train/raw-loss = 0.7017154693603516, train/logprobs = tensor([[-1.3484, -1.3156],
        [-1.2999, -1.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003787971567362547
Epoch 0, Step 511: train/loss = 0.7076456546783447, train/raw-loss = 0.7040022611618042, train/logprobs = tensor([[-1.2221, -1.0417],
        [-1.2060, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036434242501854897
Epoch 0, Step 519: train/loss = 0.6970460414886475, train/raw-loss = 0.6970062255859375, train/logprobs = tensor([[-1.0998, -1.0996],
        [-1.0649, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.985787770943716e-05
Epoch 0, Step 527: train/loss = 0.7130323648452759, train/raw-loss = 0.7126439809799194, train/logprobs = tensor([[-1.2435, -1.1123],
        [-1.4658, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003883998142555356
Epoch 0, Step 535: train/loss = 0.6991048455238342, train/raw-loss = 0.6965842247009277, train/logprobs = tensor([[-1.4125, -1.3960],
        [-1.4218, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002520682057365775
Epoch 0, Step 543: train/loss = 0.7031400203704834, train/raw-loss = 0.702728271484375, train/logprobs = tensor([[-1.1599, -1.0686],
        [-1.2256, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004117758071515709
Epoch 0, Step 551: train/loss = 0.7060956954956055, train/raw-loss = 0.7049470543861389, train/logprobs = tensor([[-1.0147, -1.3087],
        [-1.0511, -1.1684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011486295843496919
Epoch 0, Step 559: train/loss = 0.6986410617828369, train/raw-loss = 0.6983146071434021, train/logprobs = tensor([[-1.1604, -1.1806],
        [-1.1668, -1.1558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032640143763273954
Epoch 0, Step 567: train/loss = 0.6981767416000366, train/raw-loss = 0.697338879108429, train/logprobs = tensor([[-1.2500, -1.3934],
        [-1.2364, -1.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008378546917811036
Epoch 0, Step 575: train/loss = 0.7134891152381897, train/raw-loss = 0.7132694125175476, train/logprobs = tensor([[-1.0578, -0.7906],
        [-1.0752, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021966174244880676
Epoch 0, Step 583: train/loss = 0.6990187168121338, train/raw-loss = 0.696749210357666, train/logprobs = tensor([[-1.1568, -1.1981],
        [-1.1662, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002269446849822998
Epoch 0, Step 591: train/loss = 0.7051952481269836, train/raw-loss = 0.7045108079910278, train/logprobs = tensor([[-1.0893, -1.3164],
        [-1.0661, -1.2208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006844629533588886
Epoch 0, Step 599: train/loss = 0.6936131715774536, train/raw-loss = 0.6935983300209045, train/logprobs = tensor([[-0.8390, -0.8694],
        [-0.8431, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4826946426182985e-05
Epoch 0, Step 607: train/loss = 0.7128258943557739, train/raw-loss = 0.7123426198959351, train/logprobs = tensor([[-0.9160, -1.2448],
        [-0.9025, -1.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004832982085645199
Epoch 0, Step 615: train/loss = 0.69477379322052, train/raw-loss = 0.694187343120575, train/logprobs = tensor([[-1.1836, -1.1768],
        [-1.1666, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005864051054231822
Epoch 0, Step 623: train/loss = 0.7226943373680115, train/raw-loss = 0.7209269404411316, train/logprobs = tensor([[-1.4126, -1.2859],
        [-1.4387, -1.2555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017674271948635578
Epoch 0, Step 631: train/loss = 0.725823700428009, train/raw-loss = 0.7252634167671204, train/logprobs = tensor([[-1.1369, -1.5968],
        [-1.2844, -1.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005602844757959247
Epoch 0, Step 639: train/loss = 0.705020546913147, train/raw-loss = 0.7048623561859131, train/logprobs = tensor([[-1.2636, -1.3813],
        [-1.2546, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015824305592104793
Epoch 0, Step 647: train/loss = 0.7070077657699585, train/raw-loss = 0.7066160440444946, train/logprobs = tensor([[-1.1778, -1.2499],
        [-1.1859, -1.2125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039172847755253315
Epoch 0, Step 655: train/loss = 0.7106693983078003, train/raw-loss = 0.7039252519607544, train/logprobs = tensor([[-1.1906, -1.4347],
        [-1.1698, -1.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00674417894333601
Epoch 0, Step 663: train/loss = 0.6984567046165466, train/raw-loss = 0.6980156898498535, train/logprobs = tensor([[-1.2042, -1.1644],
        [-1.2805, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004410159308463335
Epoch 0, Step 671: train/loss = 0.7077935934066772, train/raw-loss = 0.7073692083358765, train/logprobs = tensor([[-1.4172, -1.3572],
        [-1.4384, -1.3294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042438239324837923
Epoch 0, Step 679: train/loss = 0.7305299639701843, train/raw-loss = 0.7299900650978088, train/logprobs = tensor([[-1.5832, -1.2411],
        [-1.6397, -1.2467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005399155197665095
Epoch 0, Step 687: train/loss = 0.7165281772613525, train/raw-loss = 0.7161344289779663, train/logprobs = tensor([[-1.4375, -1.3554],
        [-1.4797, -1.2808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039379243389703333
Epoch 0, Step 695: train/loss = 0.694273829460144, train/raw-loss = 0.6940709352493286, train/logprobs = tensor([[-1.1808, -1.1727],
        [-1.2465, -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020287971710786223
Epoch 0, Step 703: train/loss = 0.7089385986328125, train/raw-loss = 0.707800567150116, train/logprobs = tensor([[-1.1215, -1.4295],
        [-1.1417, -1.4017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011380382347851992
Epoch 0, Step 711: train/loss = 0.7040413022041321, train/raw-loss = 0.7035544514656067, train/logprobs = tensor([[-1.3991, -1.2068],
        [-1.4863, -1.1966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000486804055981338
Epoch 0, Step 719: train/loss = 0.7035863995552063, train/raw-loss = 0.7031672596931458, train/logprobs = tensor([[-1.3870, -1.1799],
        [-1.4329, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041914026951417327
Epoch 0, Step 727: train/loss = 0.711479902267456, train/raw-loss = 0.7106767892837524, train/logprobs = tensor([[-1.3426, -1.5295],
        [-1.3605, -1.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008030605968087912
Epoch 0, Step 735: train/loss = 0.7078980207443237, train/raw-loss = 0.707079291343689, train/logprobs = tensor([[-1.3309, -1.5702],
        [-1.3384, -1.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008187347557395697
Epoch 0, Step 743: train/loss = 0.7040029764175415, train/raw-loss = 0.7035156488418579, train/logprobs = tensor([[-1.2968, -1.1858],
        [-1.3512, -1.2061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048731721471995115
Epoch 0, Step 751: train/loss = 0.6933803558349609, train/raw-loss = 0.6933256387710571, train/logprobs = tensor([[-1.2691, -1.3017],
        [-1.2680, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.464894638862461e-05
Epoch 0, Step 759: train/loss = 0.6986637115478516, train/raw-loss = 0.6983133554458618, train/logprobs = tensor([[-1.3216, -1.5595],
        [-1.3751, -1.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003503681509755552
Epoch 0, Step 767: train/loss = 0.6974942088127136, train/raw-loss = 0.6974316835403442, train/logprobs = tensor([[-1.1271, -0.9920],
        [-1.1739, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.252166349440813e-05
Epoch 0, Step 775: train/loss = 0.6973849534988403, train/raw-loss = 0.6973659992218018, train/logprobs = tensor([[-1.3723, -1.2436],
        [-1.3030, -1.1267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8947874195873737e-05
Epoch 0, Step 783: train/loss = 0.7178245782852173, train/raw-loss = 0.7171531915664673, train/logprobs = tensor([[-1.2735, -1.5093],
        [-1.2843, -1.4673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006713839247822762
Epoch 0, Step 791: train/loss = 0.7193030714988708, train/raw-loss = 0.719243586063385, train/logprobs = tensor([[-1.2784, -1.6848],
        [-1.3507, -1.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.955910455668345e-05
Epoch 0, Step 799: train/loss = 0.7117155194282532, train/raw-loss = 0.7115911841392517, train/logprobs = tensor([[-0.8829, -0.9948],
        [-0.9322, -1.0374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001243365550180897
Epoch 0, Step 807: train/loss = 0.6928505301475525, train/raw-loss = 0.6921324729919434, train/logprobs = tensor([[-1.1396, -1.2297],
        [-1.2320, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007179842796176672
Epoch 0, Step 815: train/loss = 0.6942659616470337, train/raw-loss = 0.6941547393798828, train/logprobs = tensor([[-1.1800, -1.1277],
        [-1.1677, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011121589341200888
Epoch 0, Step 823: train/loss = 0.7077065706253052, train/raw-loss = 0.7058401107788086, train/logprobs = tensor([[-1.2177, -1.2202],
        [-1.3280, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018664757953956723
Epoch 0, Step 831: train/loss = 0.6979027986526489, train/raw-loss = 0.6976714730262756, train/logprobs = tensor([[-0.9763, -0.9886],
        [-1.0483, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023134463117457926
Epoch 0, Step 839: train/loss = 0.6916462182998657, train/raw-loss = 0.6915740370750427, train/logprobs = tensor([[-1.0001, -1.0393],
        [-1.1782, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.223893771879375e-05
Epoch 0, Step 847: train/loss = 0.6951644420623779, train/raw-loss = 0.694850504398346, train/logprobs = tensor([[-1.0962, -1.1405],
        [-1.1337, -1.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031400565057992935
Epoch 0, Step 855: train/loss = 0.7037712335586548, train/raw-loss = 0.7032921314239502, train/logprobs = tensor([[-1.0625, -1.0794],
        [-1.1231, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047909910790622234
Epoch 0, Step 863: train/loss = 0.7104791402816772, train/raw-loss = 0.7096991539001465, train/logprobs = tensor([[-1.1521, -1.3542],
        [-1.2453, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007800168241374195
Epoch 0, Step 871: train/loss = 0.6943586468696594, train/raw-loss = 0.6931605339050293, train/logprobs = tensor([[-1.1753, -1.1970],
        [-1.1631, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011981006246060133
Epoch 0, Step 879: train/loss = 0.704253077507019, train/raw-loss = 0.7041774988174438, train/logprobs = tensor([[-0.9596, -0.9005],
        [-1.0525, -0.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.559770165244117e-05
Epoch 0, Step 887: train/loss = 0.6984018683433533, train/raw-loss = 0.6983637809753418, train/logprobs = tensor([[-1.2780, -1.1625],
        [-1.3043, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8138648960739374e-05
Epoch 0, Step 895: train/loss = 0.7176157832145691, train/raw-loss = 0.7172914743423462, train/logprobs = tensor([[-1.1411, -0.9128],
        [-1.3328, -0.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003243797109462321
Epoch 0, Step 903: train/loss = 0.6951503753662109, train/raw-loss = 0.6947815418243408, train/logprobs = tensor([[-0.9525, -1.1113],
        [-1.0163, -1.0124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036880423431284726
Epoch 0, Step 911: train/loss = 0.7055330276489258, train/raw-loss = 0.7054745554924011, train/logprobs = tensor([[-1.0651, -1.1470],
        [-1.0792, -1.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.8527042710920796e-05
Epoch 0, Step 919: train/loss = 0.7087110280990601, train/raw-loss = 0.7077771425247192, train/logprobs = tensor([[-1.5115, -1.2616],
        [-1.5897, -1.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009339919779449701
Epoch 0, Step 927: train/loss = 0.7120846509933472, train/raw-loss = 0.7108592391014099, train/logprobs = tensor([[-1.2316, -1.2062],
        [-1.3710, -1.2151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001225458225235343
Epoch 0, Step 935: train/loss = 0.693991482257843, train/raw-loss = 0.69387286901474, train/logprobs = tensor([[-1.2055, -1.2267],
        [-1.2716, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001186295849038288
Epoch 0, Step 943: train/loss = 0.7272518873214722, train/raw-loss = 0.7270965576171875, train/logprobs = tensor([[-1.2979, -0.9029],
        [-1.3898, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001551899331388995
Epoch 0, Step 951: train/loss = 0.7004805207252502, train/raw-loss = 0.7004141211509705, train/logprobs = tensor([[-1.1446, -0.9422],
        [-1.1866, -0.9214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.643733649980277e-05
Epoch 0, Step 959: train/loss = 0.786728024482727, train/raw-loss = 0.7857053279876709, train/logprobs = tensor([[-1.1391, -1.7278],
        [-1.2741, -1.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010226666927337646
Epoch 0, Step 967: train/loss = 0.7012298703193665, train/raw-loss = 0.7010133266448975, train/logprobs = tensor([[-1.2650, -1.0967],
        [-1.4848, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021650601411238313
Epoch 0, Step 975: train/loss = 0.6964719891548157, train/raw-loss = 0.6953858137130737, train/logprobs = tensor([[-1.1340, -1.0908],
        [-1.4565, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010862292256206274
Epoch 0, Step 983: train/loss = 0.7109566330909729, train/raw-loss = 0.7108228206634521, train/logprobs = tensor([[-1.1352, -0.9013],
        [-1.1682, -0.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013377171126194298
Epoch 0, Step 991: train/loss = 0.7074868083000183, train/raw-loss = 0.7073753476142883, train/logprobs = tensor([[-1.1014, -1.2737],
        [-1.2139, -1.2959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011147384066134691
Epoch 0, Step 999: train/loss = 0.697808563709259, train/raw-loss = 0.6970377564430237, train/logprobs = tensor([[-0.8442, -0.9849],
        [-0.8566, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000770800281316042
Epoch 0, Step 1007: train/loss = 0.698601484298706, train/raw-loss = 0.6950240731239319, train/logprobs = tensor([[-1.1967, -1.2784],
        [-1.2243, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035774691496044397
Epoch 0, Step 1015: train/loss = 0.6954248547554016, train/raw-loss = 0.6946178674697876, train/logprobs = tensor([[-1.0489, -1.1919],
        [-1.1377, -1.1465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008069183095358312
Epoch 0, Step 1023: train/loss = 0.6969034671783447, train/raw-loss = 0.6964074373245239, train/logprobs = tensor([[-0.9817, -1.0665],
        [-1.0564, -1.1016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004960361402481794
Epoch 0, Step 1031: train/loss = 0.7122529745101929, train/raw-loss = 0.7115843892097473, train/logprobs = tensor([[-1.2383, -1.3817],
        [-1.2388, -1.2723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006686350097879767
Epoch 0, Step 1039: train/loss = 0.7211576700210571, train/raw-loss = 0.7211332321166992, train/logprobs = tensor([[-1.1132, -1.3938],
        [-1.1569, -1.3413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.442420918669086e-05
Epoch 0, Step 1047: train/loss = 0.6940299868583679, train/raw-loss = 0.6937874555587769, train/logprobs = tensor([[-1.0609, -1.0092],
        [-1.0429, -0.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024252283037640154
Epoch 0, Step 1055: train/loss = 0.6948464512825012, train/raw-loss = 0.6941736340522766, train/logprobs = tensor([[-1.0102, -1.0830],
        [-1.1430, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006728012231178582
Epoch 0, Step 1063: train/loss = 0.6956828832626343, train/raw-loss = 0.6952468752861023, train/logprobs = tensor([[-1.0581, -1.0784],
        [-1.1582, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004360063758213073
Epoch 0, Step 1071: train/loss = 0.694142758846283, train/raw-loss = 0.6940096616744995, train/logprobs = tensor([[-1.0547, -1.0036],
        [-1.0535, -0.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013308861525729299
Epoch 0, Step 1079: train/loss = 0.6935534477233887, train/raw-loss = 0.6934782266616821, train/logprobs = tensor([[-1.3005, -1.3732],
        [-1.3546, -1.3303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.523421663790941e-05
Epoch 0, Step 1087: train/loss = 0.6925929188728333, train/raw-loss = 0.6916250586509705, train/logprobs = tensor([[-1.1446, -1.2333],
        [-1.2806, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009679062059149146
Epoch 0, Step 1095: train/loss = 0.6936750411987305, train/raw-loss = 0.6935887336730957, train/logprobs = tensor([[-0.9932, -1.1635],
        [-1.1128, -1.1141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.629856165498495e-05
Epoch 0, Step 1103: train/loss = 0.6958662271499634, train/raw-loss = 0.6956974267959595, train/logprobs = tensor([[-1.3081, -1.2923],
        [-1.3806, -1.3268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001687400508671999
Epoch 0, Step 1111: train/loss = 0.6959397792816162, train/raw-loss = 0.6954249739646912, train/logprobs = tensor([[-1.2784, -1.1586],
        [-1.1983, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005148093332536519
Epoch 0, Step 1119: train/loss = 0.6987224817276001, train/raw-loss = 0.6982054710388184, train/logprobs = tensor([[-1.2035, -1.0661],
        [-1.2168, -1.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005170466611161828
Epoch 0, Step 1127: train/loss = 0.6990308165550232, train/raw-loss = 0.6976723074913025, train/logprobs = tensor([[-1.1742, -0.9947],
        [-1.2685, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013584935804829001
Epoch 0, Step 1135: train/loss = 0.7015993595123291, train/raw-loss = 0.7013821601867676, train/logprobs = tensor([[-1.1150, -1.1341],
        [-1.2212, -1.1749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021718567586503923
Epoch 0, Step 1143: train/loss = 0.6980243921279907, train/raw-loss = 0.6973970532417297, train/logprobs = tensor([[-1.1040, -1.2202],
        [-1.2205, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006273682229220867
Epoch 0, Step 1151: train/loss = 0.706886351108551, train/raw-loss = 0.7056174874305725, train/logprobs = tensor([[-1.2168, -1.0337],
        [-1.4329, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012688888236880302
Epoch 0, Step 1159: train/loss = 0.6984414458274841, train/raw-loss = 0.6978687047958374, train/logprobs = tensor([[-1.0332, -1.0652],
        [-1.0926, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000572793185710907
Epoch 0, Step 1167: train/loss = 0.7099470496177673, train/raw-loss = 0.7097668647766113, train/logprobs = tensor([[-1.3403, -1.2719],
        [-1.4464, -1.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018017389811575413
Epoch 0, Step 1175: train/loss = 0.6997319459915161, train/raw-loss = 0.6984021067619324, train/logprobs = tensor([[-1.1204, -1.2051],
        [-1.2334, -1.1272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013298579724505544
Epoch 0, Step 1183: train/loss = 0.6966131329536438, train/raw-loss = 0.694852352142334, train/logprobs = tensor([[-1.1473, -1.3165],
        [-1.3116, -1.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017608096823096275
Epoch 0, Step 1191: train/loss = 0.7029421329498291, train/raw-loss = 0.7023410797119141, train/logprobs = tensor([[-1.1764, -1.3605],
        [-1.2560, -1.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006010758224874735
Epoch 0, Step 1199: train/loss = 0.698549747467041, train/raw-loss = 0.6978341341018677, train/logprobs = tensor([[-1.1237, -1.2405],
        [-1.3202, -1.1471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007155403145588934
Epoch 0, Step 1207: train/loss = 0.6972541809082031, train/raw-loss = 0.6924824714660645, train/logprobs = tensor([[-1.3462, -1.3745],
        [-1.5163, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004771647043526173
Epoch 0, Step 1215: train/loss = 0.7019156813621521, train/raw-loss = 0.7001703977584839, train/logprobs = tensor([[-1.0494, -1.1318],
        [-1.3466, -1.0597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017452382016927004
Epoch 0, Step 1223: train/loss = 0.7005149126052856, train/raw-loss = 0.6997010707855225, train/logprobs = tensor([[-0.9881, -1.2448],
        [-1.0267, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008138032862916589
Epoch 0, Step 1231: train/loss = 0.6958502531051636, train/raw-loss = 0.6935595870018005, train/logprobs = tensor([[-1.1126, -1.2012],
        [-1.2814, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022906865924596786
Epoch 0, Step 1239: train/loss = 0.6970083117485046, train/raw-loss = 0.6955170631408691, train/logprobs = tensor([[-1.0963, -1.2083],
        [-1.1259, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001491210306994617
Epoch 0, Step 1247: train/loss = 0.6939417719841003, train/raw-loss = 0.6930359601974487, train/logprobs = tensor([[-1.1782, -1.2966],
        [-1.1519, -1.1415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009058034047484398
Epoch 0, Step 1255: train/loss = 0.6972973942756653, train/raw-loss = 0.6966134309768677, train/logprobs = tensor([[-1.1572, -1.2813],
        [-1.2145, -1.2390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006840562564320862
Epoch 0, Step 1263: train/loss = 0.7086929678916931, train/raw-loss = 0.7083187699317932, train/logprobs = tensor([[-1.1033, -0.9744],
        [-1.2241, -0.9869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003742967965081334
Epoch 0, Step 1271: train/loss = 0.6965339779853821, train/raw-loss = 0.6949235200881958, train/logprobs = tensor([[-1.1486, -1.2712],
        [-1.1526, -1.2720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016104767564684153
Epoch 0, Step 1279: train/loss = 0.7071281671524048, train/raw-loss = 0.7056881189346313, train/logprobs = tensor([[-1.3426, -1.3455],
        [-1.3927, -1.2517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001440100371837616
Epoch 0, Step 1287: train/loss = 0.6972019076347351, train/raw-loss = 0.696895956993103, train/logprobs = tensor([[-0.9572, -1.2161],
        [-1.0897, -1.2128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030598812736570835
Epoch 0, Step 1295: train/loss = 0.7001777291297913, train/raw-loss = 0.6925991177558899, train/logprobs = tensor([[-1.2064, -1.4245],
        [-1.4416, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00757865235209465
Epoch 0, Step 1303: train/loss = 0.6920674443244934, train/raw-loss = 0.6899312734603882, train/logprobs = tensor([[-1.2104, -1.3910],
        [-1.2283, -1.2020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021361559629440308
Epoch 0, Step 1311: train/loss = 0.7036995887756348, train/raw-loss = 0.7035150527954102, train/logprobs = tensor([[-1.1183, -1.2609],
        [-1.1956, -1.2294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001845808728830889
Epoch 0, Step 1319: train/loss = 0.6992113590240479, train/raw-loss = 0.6991930603981018, train/logprobs = tensor([[-0.9631, -0.9172],
        [-0.9949, -0.9379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8329908925807104e-05
Epoch 0, Step 1327: train/loss = 0.6946280002593994, train/raw-loss = 0.69426429271698, train/logprobs = tensor([[-1.0507, -1.0468],
        [-1.0760, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036369686131365597
Epoch 0, Step 1335: train/loss = 0.6938866376876831, train/raw-loss = 0.6936372518539429, train/logprobs = tensor([[-1.2468, -1.2955],
        [-1.3680, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000249406264629215
Epoch 0, Step 1343: train/loss = 0.6952518224716187, train/raw-loss = 0.6943478584289551, train/logprobs = tensor([[-1.2171, -1.2236],
        [-1.3192, -1.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009038879070430994
Epoch 0, Step 1351: train/loss = 0.6971586346626282, train/raw-loss = 0.6897829174995422, train/logprobs = tensor([[-1.2367, -1.1394],
        [-1.3249, -1.3324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007375734392553568
Epoch 0, Step 1359: train/loss = 0.6967134475708008, train/raw-loss = 0.6962728500366211, train/logprobs = tensor([[-1.1105, -1.2176],
        [-1.1217, -1.1609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004405725048854947
Epoch 0, Step 1367: train/loss = 0.696003794670105, train/raw-loss = 0.6957672834396362, train/logprobs = tensor([[-1.2230, -1.3361],
        [-1.2717, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023660791339352727
Epoch 0, Step 1375: train/loss = 0.6996830701828003, train/raw-loss = 0.6978108882904053, train/logprobs = tensor([[-1.2582, -1.1757],
        [-1.3896, -1.0964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018721794476732612
Epoch 0, Step 1383: train/loss = 0.6987487077713013, train/raw-loss = 0.6976265907287598, train/logprobs = tensor([[-1.3530, -1.5107],
        [-1.3255, -1.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011221227468922734
Epoch 0, Step 1391: train/loss = 0.6942876577377319, train/raw-loss = 0.6939830780029297, train/logprobs = tensor([[-1.3515, -1.3325],
        [-1.3443, -1.2019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003045867779292166
Epoch 0, Step 1399: train/loss = 0.6958656907081604, train/raw-loss = 0.6958604454994202, train/logprobs = tensor([[-1.3102, -1.4413],
        [-1.3452, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.24177448824048e-06
Epoch 0, Step 1407: train/loss = 0.6975939273834229, train/raw-loss = 0.6966210007667542, train/logprobs = tensor([[-1.2290, -1.3863],
        [-1.3716, -1.2670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009729708544909954
Epoch 0, Step 1415: train/loss = 0.6977875828742981, train/raw-loss = 0.697320818901062, train/logprobs = tensor([[-1.3266, -1.3519],
        [-1.3949, -1.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004667915927711874
Epoch 0, Step 1423: train/loss = 0.7010786533355713, train/raw-loss = 0.7006838917732239, train/logprobs = tensor([[-1.3862, -1.3892],
        [-1.3641, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000394691014662385
Epoch 0, Step 1431: train/loss = 0.7323613166809082, train/raw-loss = 0.7320919036865234, train/logprobs = tensor([[-1.4652, -1.3347],
        [-1.6814, -1.3373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002694175345823169
Epoch 0, Step 1439: train/loss = 0.6920722126960754, train/raw-loss = 0.6918373107910156, train/logprobs = tensor([[-1.2547, -1.4697],
        [-1.3608, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002348489942960441
Epoch 0, Step 1447: train/loss = 0.6949868202209473, train/raw-loss = 0.6948038339614868, train/logprobs = tensor([[-1.4603, -1.5712],
        [-1.3411, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001830217952374369
Epoch 0, Step 1455: train/loss = 0.6923147439956665, train/raw-loss = 0.6922744512557983, train/logprobs = tensor([[-1.2482, -1.3876],
        [-1.3492, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.030647687613964e-05
Epoch 0, Step 1463: train/loss = 0.7105257511138916, train/raw-loss = 0.7100919485092163, train/logprobs = tensor([[-1.3260, -1.6004],
        [-1.4563, -1.4676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004338386934250593
Epoch 0, Step 1471: train/loss = 0.7078925371170044, train/raw-loss = 0.705751895904541, train/logprobs = tensor([[-1.2744, -1.6639],
        [-1.3911, -1.5740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002140620956197381
Epoch 0, Step 1479: train/loss = 0.7008790969848633, train/raw-loss = 0.699242115020752, train/logprobs = tensor([[-1.4555, -1.5684],
        [-1.5612, -1.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001636986155062914
Epoch 0, Step 1487: train/loss = 0.6949413418769836, train/raw-loss = 0.6945101022720337, train/logprobs = tensor([[-1.5206, -1.4979],
        [-1.5850, -1.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004312312521506101
Epoch 0, Step 1495: train/loss = 0.7124312520027161, train/raw-loss = 0.7123208045959473, train/logprobs = tensor([[-1.4540, -1.3138],
        [-1.5228, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001104464172385633
Epoch 0, Step 1503: train/loss = 0.6965930461883545, train/raw-loss = 0.6915050148963928, train/logprobs = tensor([[-1.5302, -1.6903],
        [-1.5524, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005088023841381073
Epoch 0, Step 1511: train/loss = 0.698074996471405, train/raw-loss = 0.6953614950180054, train/logprobs = tensor([[-1.4947, -1.5472],
        [-1.6933, -1.4786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027135363779962063
Epoch 0, Step 1519: train/loss = 0.6973405480384827, train/raw-loss = 0.6973268985748291, train/logprobs = tensor([[-1.3207, -1.3887],
        [-1.3719, -1.4084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.36338931042701e-05
Epoch 0, Step 1527: train/loss = 0.6959290504455566, train/raw-loss = 0.6955645084381104, train/logprobs = tensor([[-1.3907, -1.4813],
        [-1.4691, -1.3961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036454189103096724
Epoch 0, Step 1535: train/loss = 0.7014792561531067, train/raw-loss = 0.7013920545578003, train/logprobs = tensor([[-1.2662, -1.4043],
        [-1.3503, -1.3757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.719228208065033e-05
Epoch 0, Step 1543: train/loss = 0.7064768671989441, train/raw-loss = 0.7056237459182739, train/logprobs = tensor([[-1.3419, -1.6523],
        [-1.4095, -1.5893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008531162748113275
Epoch 0, Step 1551: train/loss = 0.6925048232078552, train/raw-loss = 0.6916339993476868, train/logprobs = tensor([[-1.2374, -1.3321],
        [-1.3062, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008707950473763049
Epoch 0, Step 1559: train/loss = 0.6946133375167847, train/raw-loss = 0.6943118572235107, train/logprobs = tensor([[-1.2239, -1.3486],
        [-1.6247, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030150567181408405
Epoch 0, Step 1567: train/loss = 0.6986768245697021, train/raw-loss = 0.6985902786254883, train/logprobs = tensor([[-1.3000, -1.2223],
        [-1.3238, -1.1938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.652848191559315e-05
Epoch 0, Step 1575: train/loss = 0.703201174736023, train/raw-loss = 0.7030729055404663, train/logprobs = tensor([[-1.3214, -1.3281],
        [-1.4571, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012818975665140897
Epoch 0, Step 1583: train/loss = 0.6969537734985352, train/raw-loss = 0.6966546773910522, train/logprobs = tensor([[-1.2218, -1.1359],
        [-1.3329, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029908434953540564
Epoch 0, Step 1591: train/loss = 0.6966694593429565, train/raw-loss = 0.6966268420219421, train/logprobs = tensor([[-1.2867, -1.1742],
        [-1.2733, -1.1221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.2564410250633955e-05
Epoch 0, Step 1599: train/loss = 0.6976425051689148, train/raw-loss = 0.6974157691001892, train/logprobs = tensor([[-1.2121, -1.4018],
        [-1.2430, -1.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002267279487568885
Epoch 0, Step 1607: train/loss = 0.6973739862442017, train/raw-loss = 0.6969317197799683, train/logprobs = tensor([[-1.3865, -1.3407],
        [-1.4525, -1.2935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000442280201241374
Epoch 0, Step 1615: train/loss = 0.7025842666625977, train/raw-loss = 0.7022977471351624, train/logprobs = tensor([[-1.3946, -1.3925],
        [-1.5831, -1.4583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002864825655706227
Epoch 0, Step 1623: train/loss = 0.7035233974456787, train/raw-loss = 0.7034758925437927, train/logprobs = tensor([[-1.4809, -1.3598],
        [-1.5036, -1.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.747253842651844e-05
Epoch 0, Step 1631: train/loss = 0.6993160247802734, train/raw-loss = 0.6986289620399475, train/logprobs = tensor([[-1.4456, -1.4312],
        [-1.5005, -1.3709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006870806682854891
Epoch 0, Step 1639: train/loss = 0.6945813894271851, train/raw-loss = 0.6944353580474854, train/logprobs = tensor([[-1.4203, -1.3736],
        [-1.4121, -1.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001461100036976859
Epoch 0, Step 1647: train/loss = 0.7112805843353271, train/raw-loss = 0.708857536315918, train/logprobs = tensor([[-1.4028, -1.7427],
        [-1.5262, -1.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002423093654215336
Epoch 0, Step 1655: train/loss = 0.6983115077018738, train/raw-loss = 0.6981070041656494, train/logprobs = tensor([[-1.6306, -1.7905],
        [-1.6828, -1.6993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020448054419830441
Epoch 0, Step 1663: train/loss = 0.7193657755851746, train/raw-loss = 0.716916561126709, train/logprobs = tensor([[-1.2937, -1.7740],
        [-1.3448, -1.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024491504300385714
Epoch 0, Step 1671: train/loss = 0.6942973136901855, train/raw-loss = 0.691204309463501, train/logprobs = tensor([[-1.4134, -1.5362],
        [-1.5868, -1.3970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003092964179813862
Epoch 0, Step 1679: train/loss = 0.7062028646469116, train/raw-loss = 0.7051741480827332, train/logprobs = tensor([[-1.4549, -1.3272],
        [-1.5117, -1.2863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010287344921380281
Epoch 0, Step 1687: train/loss = 0.695443332195282, train/raw-loss = 0.6953689455986023, train/logprobs = tensor([[-1.4429, -1.3299],
        [-1.4274, -1.2948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.443742651958019e-05
Epoch 0, Step 1695: train/loss = 0.7479429244995117, train/raw-loss = 0.7462925910949707, train/logprobs = tensor([[-1.4075, -1.7981],
        [-1.4954, -1.6529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016503774095326662
Epoch 0, Step 1703: train/loss = 0.7040165662765503, train/raw-loss = 0.7026032209396362, train/logprobs = tensor([[-1.2696, -1.4917],
        [-1.3089, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014133693184703588
Epoch 0, Step 1711: train/loss = 0.7010838985443115, train/raw-loss = 0.7007301449775696, train/logprobs = tensor([[-1.3159, -1.5334],
        [-1.3916, -1.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035375324659980834
Epoch 0, Step 1719: train/loss = 0.6937969923019409, train/raw-loss = 0.6937966346740723, train/logprobs = tensor([[-1.3464, -1.3291],
        [-1.3612, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.145760274492204e-07
Epoch 0, Step 1727: train/loss = 0.6932658553123474, train/raw-loss = 0.6929847002029419, train/logprobs = tensor([[-1.1178, -1.1362],
        [-1.1950, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002811628801282495
Epoch 0, Step 1735: train/loss = 0.7852400541305542, train/raw-loss = 0.7848528623580933, train/logprobs = tensor([[-1.2502, -1.7209],
        [-1.3890, -1.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038724264595657587
Epoch 0, Step 1743: train/loss = 0.6958127617835999, train/raw-loss = 0.694358229637146, train/logprobs = tensor([[-1.2019, -1.3182],
        [-1.3717, -1.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014545742888003588
Epoch 0, Step 1751: train/loss = 0.6967665553092957, train/raw-loss = 0.6965950727462769, train/logprobs = tensor([[-1.2693, -1.3547],
        [-1.2722, -1.3136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017148669576272368
Epoch 0, Step 1759: train/loss = 0.697574257850647, train/raw-loss = 0.6962190866470337, train/logprobs = tensor([[-1.3262, -1.3666],
        [-1.3760, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013551192823797464
Epoch 0, Step 1767: train/loss = 0.6954889893531799, train/raw-loss = 0.6936513185501099, train/logprobs = tensor([[-1.3708, -1.3641],
        [-1.5036, -1.2335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018376775551587343
Epoch 0, Step 1775: train/loss = 0.702274739742279, train/raw-loss = 0.7003967761993408, train/logprobs = tensor([[-1.4918, -1.3914],
        [-1.5250, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018779709935188293
Epoch 0, Step 1783: train/loss = 0.6974674463272095, train/raw-loss = 0.6936740875244141, train/logprobs = tensor([[-1.4646, -1.4937],
        [-1.6484, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003793292911723256
Epoch 0, Step 1791: train/loss = 0.7095493078231812, train/raw-loss = 0.7087798714637756, train/logprobs = tensor([[-1.5453, -1.3374],
        [-1.6549, -1.3452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007694471860304475
Epoch 0, Step 1799: train/loss = 0.69378262758255, train/raw-loss = 0.6935989856719971, train/logprobs = tensor([[-1.3330, -1.4549],
        [-1.4025, -1.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018366935546509922
Epoch 0, Step 1807: train/loss = 0.707266628742218, train/raw-loss = 0.7065479159355164, train/logprobs = tensor([[-1.4570, -1.3433],
        [-1.5539, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007186795119196177
Epoch 0, Step 1815: train/loss = 0.6979061961174011, train/raw-loss = 0.6968954801559448, train/logprobs = tensor([[-1.3389, -1.3556],
        [-1.6305, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010106865083798766
Epoch 0, Step 1823: train/loss = 0.6987916231155396, train/raw-loss = 0.6981353759765625, train/logprobs = tensor([[-1.3223, -1.3903],
        [-1.4271, -1.3991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006563315400853753
Epoch 0, Step 1831: train/loss = 0.7187100648880005, train/raw-loss = 0.7154990434646606, train/logprobs = tensor([[-1.4155, -1.8360],
        [-1.5447, -1.6145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032109515741467476
Epoch 0, Step 1839: train/loss = 0.6945216059684753, train/raw-loss = 0.6944437026977539, train/logprobs = tensor([[-1.5148, -1.5555],
        [-1.5214, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.790667586959898e-05
Epoch 0, Step 1847: train/loss = 0.697960615158081, train/raw-loss = 0.6959085464477539, train/logprobs = tensor([[-1.4550, -1.5367],
        [-1.5770, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020519751124083996
Epoch 0, Step 1855: train/loss = 0.6932686567306519, train/raw-loss = 0.6924561262130737, train/logprobs = tensor([[-1.6926, -1.7077],
        [-1.7344, -1.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008125489694066346
Epoch 0, Step 1863: train/loss = 0.6966218948364258, train/raw-loss = 0.6949894428253174, train/logprobs = tensor([[-1.4631, -1.6218],
        [-1.5071, -1.5347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016325415344908834
Epoch 0, Step 1871: train/loss = 0.6941001415252686, train/raw-loss = 0.692211925983429, train/logprobs = tensor([[-1.6823, -1.7583],
        [-1.7090, -1.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018882323056459427
Epoch 0, Step 1879: train/loss = 0.6933214664459229, train/raw-loss = 0.6923410296440125, train/logprobs = tensor([[-1.5448, -1.6471],
        [-1.6212, -1.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009804333094507456
Epoch 0, Step 1887: train/loss = 0.6960998177528381, train/raw-loss = 0.6951122283935547, train/logprobs = tensor([[-1.7047, -1.9005],
        [-1.7548, -1.6742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009875318501144648
Epoch 0, Step 1895: train/loss = 0.7025020122528076, train/raw-loss = 0.7024840116500854, train/logprobs = tensor([[-1.7887, -1.8983],
        [-1.8183, -1.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.794160925783217e-05
Epoch 0, Step 1903: train/loss = 0.69610595703125, train/raw-loss = 0.6953573822975159, train/logprobs = tensor([[-1.6941, -1.6923],
        [-1.8661, -1.6368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000748578691855073
Epoch 0, Step 1911: train/loss = 0.6996467709541321, train/raw-loss = 0.6991136074066162, train/logprobs = tensor([[-1.6658, -1.8598],
        [-1.7136, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005331726861186326
Epoch 0, Step 1919: train/loss = 0.6982375979423523, train/raw-loss = 0.697618842124939, train/logprobs = tensor([[-1.8697, -1.9899],
        [-1.8847, -1.9318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006187891121953726
Epoch 0, Step 1927: train/loss = 0.6951487064361572, train/raw-loss = 0.6949929594993591, train/logprobs = tensor([[-1.7141, -1.6446],
        [-1.6808, -1.5980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015582432388328016
Epoch 0, Step 1935: train/loss = 0.6938241720199585, train/raw-loss = 0.6934844255447388, train/logprobs = tensor([[-1.7028, -1.8380],
        [-1.7225, -1.7403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003397911787033081
Epoch 0, Step 1943: train/loss = 0.6947587132453918, train/raw-loss = 0.6944920420646667, train/logprobs = tensor([[-1.9452, -1.8624],
        [-2.0254, -1.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026662577874958515
Epoch 0, Step 1951: train/loss = 0.7013397812843323, train/raw-loss = 0.7008089423179626, train/logprobs = tensor([[-1.7222, -2.0409],
        [-1.7984, -1.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005308614345267415
Epoch 0, Step 1959: train/loss = 0.6941835284233093, train/raw-loss = 0.6941558718681335, train/logprobs = tensor([[-1.9688, -1.9234],
        [-1.9965, -1.8421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7716581826098263e-05
Epoch 0, Step 1967: train/loss = 0.6957102417945862, train/raw-loss = 0.695464015007019, train/logprobs = tensor([[-1.8785, -1.9272],
        [-1.9550, -1.8169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024617655435577035
Epoch 0, Step 1975: train/loss = 0.6956602931022644, train/raw-loss = 0.6950858235359192, train/logprobs = tensor([[-1.9385, -2.0522],
        [-2.0078, -2.0125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005744233494624496
Epoch 0, Step 1983: train/loss = 0.7006576657295227, train/raw-loss = 0.7005714178085327, train/logprobs = tensor([[-1.8796, -1.7820],
        [-2.0649, -1.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.630903903394938e-05
Epoch 0, Step 1991: train/loss = 0.7129091620445251, train/raw-loss = 0.7127635478973389, train/logprobs = tensor([[-1.9567, -2.0114],
        [-1.9620, -1.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001455951714888215
Epoch 0, Step 1999: train/loss = 0.70543372631073, train/raw-loss = 0.7051904797554016, train/logprobs = tensor([[-1.9621, -2.0704],
        [-1.9629, -1.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024324975674971938
Epoch 0, Step 2007: train/loss = 0.6982287764549255, train/raw-loss = 0.698155403137207, train/logprobs = tensor([[-1.8531, -1.9366],
        [-1.8523, -1.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.333391113206744e-05
Epoch 0, Step 2015: train/loss = 0.7002713084220886, train/raw-loss = 0.69791579246521, train/logprobs = tensor([[-1.9096, -2.0748],
        [-2.0715, -2.0356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00235555786639452
Epoch 0, Step 2023: train/loss = 0.7023833394050598, train/raw-loss = 0.7015378475189209, train/logprobs = tensor([[-1.7833, -2.0615],
        [-1.8104, -1.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008454685448668897
Epoch 0, Step 2031: train/loss = 0.6959253549575806, train/raw-loss = 0.6957689523696899, train/logprobs = tensor([[-1.9439, -2.0520],
        [-1.9716, -2.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015642227663192898
Epoch 0, Step 2039: train/loss = 0.7007917761802673, train/raw-loss = 0.7005480527877808, train/logprobs = tensor([[-1.6325, -1.8874],
        [-1.6656, -1.8341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024368921003770083
Epoch 0, Step 2047: train/loss = 0.715853214263916, train/raw-loss = 0.7154265642166138, train/logprobs = tensor([[-1.7662, -1.9648],
        [-1.7072, -1.8432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042660871986299753
Epoch 0, Step 2055: train/loss = 0.6940711140632629, train/raw-loss = 0.6939408183097839, train/logprobs = tensor([[-1.8760, -1.8797],
        [-1.8532, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013027654495090246
Epoch 0, Step 2063: train/loss = 0.7007170915603638, train/raw-loss = 0.7005137801170349, train/logprobs = tensor([[-1.8672, -1.7781],
        [-1.8859, -1.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020329514518380165
Epoch 0, Step 2071: train/loss = 0.7020880579948425, train/raw-loss = 0.7001473307609558, train/logprobs = tensor([[-2.0945, -2.0473],
        [-2.1725, -1.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019408096559345722
Epoch 0, Step 2079: train/loss = 0.7019138336181641, train/raw-loss = 0.7018054723739624, train/logprobs = tensor([[-1.8287, -2.0422],
        [-1.8498, -1.9663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001083104289136827
Epoch 0, Step 2087: train/loss = 0.6913736462593079, train/raw-loss = 0.6887382864952087, train/logprobs = tensor([[-1.8325, -2.0002],
        [-1.9308, -1.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00263533485122025
Epoch 0, Step 2095: train/loss = 0.7375683188438416, train/raw-loss = 0.7368741035461426, train/logprobs = tensor([[-2.0516, -1.6900],
        [-2.0105, -1.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006942016771063209
Epoch 0, Step 2103: train/loss = 0.7138879299163818, train/raw-loss = 0.7133899927139282, train/logprobs = tensor([[-1.8615, -1.9869],
        [-1.8676, -1.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004979188088327646
Epoch 0, Step 2111: train/loss = 0.6936450600624084, train/raw-loss = 0.6928954124450684, train/logprobs = tensor([[-1.8594, -1.9563],
        [-1.8333, -1.7128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007496197940781713
Epoch 0, Step 2119: train/loss = 0.7018927335739136, train/raw-loss = 0.7001299858093262, train/logprobs = tensor([[-1.6133, -1.8233],
        [-1.7177, -1.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017627032939344645
Epoch 0, Step 2127: train/loss = 0.7062526345252991, train/raw-loss = 0.7060807347297668, train/logprobs = tensor([[-1.9743, -1.8675],
        [-1.9102, -1.7179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017188105266541243
Epoch 0, Step 2135: train/loss = 0.7040917873382568, train/raw-loss = 0.701770544052124, train/logprobs = tensor([[-1.9305, -1.8562],
        [-1.9660, -1.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023212539963424206
Epoch 0, Step 2143: train/loss = 0.7001082897186279, train/raw-loss = 0.6994016170501709, train/logprobs = tensor([[-1.7636, -1.6929],
        [-1.7828, -1.6274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007065971731208265
Epoch 0, Step 2151: train/loss = 0.6957858204841614, train/raw-loss = 0.692685604095459, train/logprobs = tensor([[-1.5364, -1.6050],
        [-1.6839, -1.4667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031001486349850893
Epoch 0, Step 2159: train/loss = 0.6910024285316467, train/raw-loss = 0.6827675104141235, train/logprobs = tensor([[-1.6170, -1.9248],
        [-1.8340, -1.4790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008234910666942596
Epoch 0, Step 2167: train/loss = 0.7005633115768433, train/raw-loss = 0.6993944644927979, train/logprobs = tensor([[-1.6170, -1.8058],
        [-1.7656, -1.7547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011688590748235583
Epoch 0, Step 2175: train/loss = 0.6966071128845215, train/raw-loss = 0.6954744458198547, train/logprobs = tensor([[-1.6349, -1.6201],
        [-1.7178, -1.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001132672536186874
Epoch 0, Step 2183: train/loss = 0.6926712989807129, train/raw-loss = 0.6920797824859619, train/logprobs = tensor([[-1.5194, -1.4698],
        [-1.6879, -1.4458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005915552610531449
Epoch 0, Step 2191: train/loss = 0.7010235786437988, train/raw-loss = 0.6988259553909302, train/logprobs = tensor([[-1.4523, -1.7598],
        [-1.5292, -1.5633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021975617855787277
Epoch 0, Step 2199: train/loss = 0.6963105201721191, train/raw-loss = 0.695605456829071, train/logprobs = tensor([[-1.4924, -1.4253],
        [-1.5718, -1.4092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007050564745441079
Epoch 0, Step 2207: train/loss = 0.6956993937492371, train/raw-loss = 0.6953411102294922, train/logprobs = tensor([[-1.4285, -1.3696],
        [-1.5280, -1.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035831486457027495
Epoch 0, Step 2215: train/loss = 0.7047363519668579, train/raw-loss = 0.696841299533844, train/logprobs = tensor([[-1.4683, -1.6857],
        [-1.6352, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007895069196820259
Epoch 0, Step 2223: train/loss = 0.6949995756149292, train/raw-loss = 0.6914486289024353, train/logprobs = tensor([[-1.4947, -1.5321],
        [-1.5999, -1.4242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035509467124938965
Epoch 0, Step 2231: train/loss = 0.6987332701683044, train/raw-loss = 0.6979154944419861, train/logprobs = tensor([[-1.3791, -1.4394],
        [-1.3188, -1.2238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008177279960364103
Epoch 0, Step 2239: train/loss = 0.6793084144592285, train/raw-loss = 0.6760500073432922, train/logprobs = tensor([[-1.3623, -1.6621],
        [-1.6524, -1.4085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003258445532992482
Epoch 0, Step 2247: train/loss = 0.7068798542022705, train/raw-loss = 0.7056386470794678, train/logprobs = tensor([[-1.4221, -1.7622],
        [-1.3892, -1.4942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012411766219884157
Epoch 0, Step 2255: train/loss = 0.6933925151824951, train/raw-loss = 0.6931699514389038, train/logprobs = tensor([[-1.3437, -1.4449],
        [-1.3466, -1.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002226363867521286
Epoch 0, Step 2263: train/loss = 0.6906965970993042, train/raw-loss = 0.6886457204818726, train/logprobs = tensor([[-1.2085, -1.3400],
        [-1.5093, -1.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002050840063020587
Epoch 0, Step 2271: train/loss = 0.697193443775177, train/raw-loss = 0.6964097619056702, train/logprobs = tensor([[-1.5938, -1.6744],
        [-1.4909, -1.4711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007836285512894392
Epoch 0, Step 2279: train/loss = 0.6938838958740234, train/raw-loss = 0.6935217380523682, train/logprobs = tensor([[-1.4261, -1.5313],
        [-1.4700, -1.4424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003620889037847519
Epoch 0, Step 2287: train/loss = 0.69854736328125, train/raw-loss = 0.6965157389640808, train/logprobs = tensor([[-1.6104, -1.4106],
        [-1.3547, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020316317677497864
Epoch 0, Step 2295: train/loss = 0.7085005044937134, train/raw-loss = 0.7032593488693237, train/logprobs = tensor([[-1.3613, -1.7950],
        [-1.4495, -1.4693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005241145379841328
Epoch 0, Step 2303: train/loss = 0.6928026080131531, train/raw-loss = 0.6922816038131714, train/logprobs = tensor([[-1.3115, -1.5561],
        [-1.3551, -1.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005210183444432914
Epoch 0, Step 2311: train/loss = 0.7037703990936279, train/raw-loss = 0.698053240776062, train/logprobs = tensor([[-1.2127, -1.6744],
        [-1.2945, -1.2998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005717214662581682
Epoch 0, Step 2319: train/loss = 0.6969364285469055, train/raw-loss = 0.6963803768157959, train/logprobs = tensor([[-1.5341, -1.7182],
        [-1.5498, -1.6534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000556022219825536
Epoch 0, Step 2327: train/loss = 0.69652259349823, train/raw-loss = 0.6960108280181885, train/logprobs = tensor([[-1.7239, -1.7351],
        [-1.7991, -1.7119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005117164691910148
Epoch 0, Step 2335: train/loss = 0.6940950155258179, train/raw-loss = 0.6937430500984192, train/logprobs = tensor([[-1.5416, -1.4772],
        [-1.5769, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003519721794873476
Epoch 0, Step 2343: train/loss = 0.6937860250473022, train/raw-loss = 0.6934719085693359, train/logprobs = tensor([[-1.7101, -1.6953],
        [-1.5832, -1.5570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003140541084576398
Epoch 0, Step 2351: train/loss = 0.6964300274848938, train/raw-loss = 0.6957671642303467, train/logprobs = tensor([[-1.4085, -1.4039],
        [-1.4937, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006627935799770057
Epoch 0, Step 2359: train/loss = 0.7163922786712646, train/raw-loss = 0.7145653963088989, train/logprobs = tensor([[-1.7350, -1.5794],
        [-1.6976, -1.3777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018268725834786892
Epoch 0, Step 2367: train/loss = 0.6981848478317261, train/raw-loss = 0.6959295868873596, train/logprobs = tensor([[-1.7055, -1.6782],
        [-1.6683, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022552423179149628
Epoch 0, Step 2375: train/loss = 0.6966685652732849, train/raw-loss = 0.6963434219360352, train/logprobs = tensor([[-1.6441, -1.6279],
        [-1.7320, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032518600346520543
Epoch 0, Step 2383: train/loss = 0.7040095925331116, train/raw-loss = 0.7012486457824707, train/logprobs = tensor([[-1.6156, -1.5526],
        [-1.6914, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027609001845121384
Epoch 0, Step 2391: train/loss = 0.6936751008033752, train/raw-loss = 0.6936644911766052, train/logprobs = tensor([[-1.7325, -1.7331],
        [-1.7351, -1.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0592106264084578e-05
Epoch 0, Step 2399: train/loss = 0.6939883828163147, train/raw-loss = 0.6936202049255371, train/logprobs = tensor([[-1.6463, -1.6772],
        [-1.6325, -1.6258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036814872873947024
Epoch 0, Step 2407: train/loss = 0.6968473196029663, train/raw-loss = 0.696626603603363, train/logprobs = tensor([[-1.4984, -1.5434],
        [-1.5094, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002207112847827375
Epoch 0, Step 2415: train/loss = 0.6995798349380493, train/raw-loss = 0.6994739770889282, train/logprobs = tensor([[-1.5022, -1.5709],
        [-1.5847, -1.5190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001058319176081568
Epoch 0, Step 2423: train/loss = 0.703106701374054, train/raw-loss = 0.701348066329956, train/logprobs = tensor([[-1.5542, -1.7809],
        [-1.6374, -1.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017585477326065302
Epoch 0, Step 2431: train/loss = 0.7071142196655273, train/raw-loss = 0.7029068470001221, train/logprobs = tensor([[-1.6872, -1.8993],
        [-1.6894, -1.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00420734565705061
Epoch 0, Step 2439: train/loss = 0.6910643577575684, train/raw-loss = 0.6866261959075928, train/logprobs = tensor([[-1.5959, -1.7466],
        [-1.7970, -1.6250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004438241943717003
Epoch 0, Step 2447: train/loss = 0.6953164339065552, train/raw-loss = 0.6949788331985474, train/logprobs = tensor([[-1.6878, -1.6753],
        [-1.7209, -1.6480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003376416570972651
Epoch 0, Step 2455: train/loss = 0.698926568031311, train/raw-loss = 0.6987990736961365, train/logprobs = tensor([[-1.6051, -1.5133],
        [-1.7294, -1.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012751444592140615
Epoch 0, Step 2463: train/loss = 0.6958332061767578, train/raw-loss = 0.6950781345367432, train/logprobs = tensor([[-1.6772, -1.6971],
        [-1.6559, -1.5062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000755139859393239
Epoch 0, Step 2471: train/loss = 0.6903722286224365, train/raw-loss = 0.6892902851104736, train/logprobs = tensor([[-1.3719, -1.5454],
        [-1.4592, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010818811133503914
Epoch 0, Step 2479: train/loss = 0.6979963779449463, train/raw-loss = 0.6955971717834473, train/logprobs = tensor([[-1.3106, -1.2978],
        [-1.3839, -1.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023991605266928673
Epoch 0, Step 2487: train/loss = 0.704038679599762, train/raw-loss = 0.7035521268844604, train/logprobs = tensor([[-1.1789, -1.4064],
        [-1.1794, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004865947412326932
Epoch 0, Step 2495: train/loss = 0.6938603520393372, train/raw-loss = 0.6937187314033508, train/logprobs = tensor([[-1.3363, -1.3255],
        [-1.4128, -1.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014161238505039364
Epoch 0, Step 2503: train/loss = 0.6918593645095825, train/raw-loss = 0.6903306245803833, train/logprobs = tensor([[-1.3076, -1.3015],
        [-1.4570, -1.2339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001528719556517899
Epoch 0, Step 2511: train/loss = 0.6956644058227539, train/raw-loss = 0.6954864263534546, train/logprobs = tensor([[-1.3062, -1.3569],
        [-1.2769, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017789361299946904
Epoch 0, Step 2519: train/loss = 0.6967436075210571, train/raw-loss = 0.6963292956352234, train/logprobs = tensor([[-1.1847, -1.1575],
        [-1.3017, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041436892934143543
Epoch 0, Step 2527: train/loss = 0.6963083744049072, train/raw-loss = 0.694807767868042, train/logprobs = tensor([[-1.3358, -1.5291],
        [-1.5074, -1.4651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015006099129095674
Epoch 0, Step 2535: train/loss = 0.7022584080696106, train/raw-loss = 0.7018085718154907, train/logprobs = tensor([[-1.3417, -1.1430],
        [-1.4416, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004497841000556946
Epoch 0, Step 2543: train/loss = 0.6982659697532654, train/raw-loss = 0.6979811191558838, train/logprobs = tensor([[-1.2925, -1.4209],
        [-1.3219, -1.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002848198637366295
Epoch 0, Step 2551: train/loss = 0.697418212890625, train/raw-loss = 0.6962889432907104, train/logprobs = tensor([[-1.2098, -1.1219],
        [-1.2698, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011292489944025874
Epoch 0, Step 2559: train/loss = 0.7047930955886841, train/raw-loss = 0.7041192054748535, train/logprobs = tensor([[-1.2870, -1.2585],
        [-1.3532, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006738498341292143
Epoch 0, Step 2567: train/loss = 0.6940385103225708, train/raw-loss = 0.6938715577125549, train/logprobs = tensor([[-1.3337, -1.2859],
        [-1.4314, -1.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001669040066190064
Epoch 0, Step 2575: train/loss = 0.7027069330215454, train/raw-loss = 0.701977014541626, train/logprobs = tensor([[-1.3676, -1.2861],
        [-1.5422, -1.2404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007299458957277238
Epoch 0, Step 2583: train/loss = 0.6948567628860474, train/raw-loss = 0.6940464973449707, train/logprobs = tensor([[-1.3332, -1.3995],
        [-1.3413, -1.2908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008102364372462034
Epoch 0, Step 2591: train/loss = 0.6972084045410156, train/raw-loss = 0.6957510709762573, train/logprobs = tensor([[-1.2735, -1.4527],
        [-1.3939, -1.5143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001457293052226305
Epoch 0, Step 2599: train/loss = 0.6951170563697815, train/raw-loss = 0.6948411464691162, train/logprobs = tensor([[-1.1736, -1.3439],
        [-1.2659, -1.3279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000275928876362741
Epoch 0, Step 2607: train/loss = 0.6939556002616882, train/raw-loss = 0.6938384771347046, train/logprobs = tensor([[-1.2368, -1.3639],
        [-1.2649, -1.2947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011709393584169447
Epoch 0, Step 2615: train/loss = 0.7100797891616821, train/raw-loss = 0.7052220106124878, train/logprobs = tensor([[-1.2517, -1.5654],
        [-1.3043, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004857785999774933
Epoch 0, Step 2623: train/loss = 0.692799985408783, train/raw-loss = 0.6923924684524536, train/logprobs = tensor([[-1.4010, -1.5059],
        [-1.4469, -1.3892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040749870822764933
Epoch 0, Step 2631: train/loss = 0.6935538053512573, train/raw-loss = 0.6933743357658386, train/logprobs = tensor([[-1.4954, -1.4707],
        [-1.5443, -1.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000179462629603222
Epoch 0, Step 2639: train/loss = 0.6943230628967285, train/raw-loss = 0.6937083005905151, train/logprobs = tensor([[-1.3452, -1.3224],
        [-1.3701, -1.3377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006148125976324081
Epoch 0, Step 2647: train/loss = 0.6981395483016968, train/raw-loss = 0.697021484375, train/logprobs = tensor([[-1.3099, -1.3640],
        [-1.4718, -1.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001118132146075368
Epoch 0, Step 2655: train/loss = 0.6954467296600342, train/raw-loss = 0.6951457262039185, train/logprobs = tensor([[-1.5111, -1.5049],
        [-1.4929, -1.4082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030097179114818573
Epoch 0, Step 2663: train/loss = 0.697085976600647, train/raw-loss = 0.6962785720825195, train/logprobs = tensor([[-1.4202, -1.4918],
        [-1.5406, -1.4813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008073666831478477
Epoch 0, Step 2671: train/loss = 0.6935844421386719, train/raw-loss = 0.693389892578125, train/logprobs = tensor([[-1.3643, -1.4147],
        [-1.3659, -1.3799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019447191152721643
Epoch 0, Step 2679: train/loss = 0.6906327605247498, train/raw-loss = 0.6874150037765503, train/logprobs = tensor([[-1.3750, -1.5339],
        [-1.5634, -1.3747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032177595421671867
Epoch 0, Step 2687: train/loss = 0.725781261920929, train/raw-loss = 0.7249268293380737, train/logprobs = tensor([[-1.5088, -1.8224],
        [-1.6153, -1.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008543868316337466
Epoch 0, Step 2695: train/loss = 0.7106011509895325, train/raw-loss = 0.7093560695648193, train/logprobs = tensor([[-1.5223, -1.5309],
        [-1.6569, -1.4739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001245085964910686
Epoch 0, Step 2703: train/loss = 0.6982805132865906, train/raw-loss = 0.6958591938018799, train/logprobs = tensor([[-1.5395, -1.5175],
        [-1.5660, -1.4371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024213488213717937
Epoch 0, Step 2711: train/loss = 0.6974363327026367, train/raw-loss = 0.6962759494781494, train/logprobs = tensor([[-1.4107, -1.4327],
        [-1.4994, -1.3850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011604209430515766
Epoch 0, Step 2719: train/loss = 0.7126942873001099, train/raw-loss = 0.7112112641334534, train/logprobs = tensor([[-1.3868, -1.7855],
        [-1.4163, -1.6502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001483048195950687
Epoch 0, Step 2727: train/loss = 0.6843050718307495, train/raw-loss = 0.6824579834938049, train/logprobs = tensor([[-1.6668, -1.8936],
        [-1.7527, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018470711074769497
Epoch 0, Step 2735: train/loss = 0.6932085752487183, train/raw-loss = 0.6927753686904907, train/logprobs = tensor([[-1.3486, -1.4202],
        [-1.3794, -1.3564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043321348493918777
Epoch 0, Step 2743: train/loss = 0.6948056221008301, train/raw-loss = 0.6940104365348816, train/logprobs = tensor([[-1.4517, -1.6082],
        [-1.5916, -1.4464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007951464504003525
Epoch 0, Step 2751: train/loss = 0.6980153322219849, train/raw-loss = 0.6975815296173096, train/logprobs = tensor([[-1.4759, -1.9335],
        [-1.5108, -1.5593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043382172589190304
Epoch 0, Step 2759: train/loss = 0.7018622756004333, train/raw-loss = 0.7017773389816284, train/logprobs = tensor([[-1.4123, -1.5789],
        [-1.4740, -1.5881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.496060036122799e-05
Epoch 0, Step 2767: train/loss = 0.6853128671646118, train/raw-loss = 0.6814960837364197, train/logprobs = tensor([[-1.2983, -1.4836],
        [-1.7581, -1.4277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038167668972164392
Epoch 0, Step 2775: train/loss = 0.702953577041626, train/raw-loss = 0.701806366443634, train/logprobs = tensor([[-1.5924, -1.5353],
        [-1.6485, -1.4210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011472447076812387
Epoch 0, Step 2783: train/loss = 0.715675950050354, train/raw-loss = 0.7122256755828857, train/logprobs = tensor([[-1.3103, -1.9302],
        [-1.4298, -1.6344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034502632915973663
Epoch 0, Step 2791: train/loss = 0.6934041380882263, train/raw-loss = 0.6927651166915894, train/logprobs = tensor([[-1.3177, -1.3873],
        [-1.2969, -1.2339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006390146445482969
Epoch 0, Step 2799: train/loss = 0.6904813051223755, train/raw-loss = 0.689358115196228, train/logprobs = tensor([[-1.4719, -1.6153],
        [-1.5467, -1.3992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001123141497373581
Epoch 0, Step 2807: train/loss = 0.6940427422523499, train/raw-loss = 0.6937379837036133, train/logprobs = tensor([[-1.3583, -1.4506],
        [-1.3961, -1.3478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003047875943593681
Epoch 0, Step 2815: train/loss = 0.6928291916847229, train/raw-loss = 0.6927207112312317, train/logprobs = tensor([[-1.3663, -1.4117],
        [-1.4760, -1.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010852751438505948
Epoch 0, Step 2823: train/loss = 0.6979838609695435, train/raw-loss = 0.6977485418319702, train/logprobs = tensor([[-1.4658, -1.3707],
        [-1.5195, -1.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023529346799477935
Epoch 0, Step 2831: train/loss = 0.7018764615058899, train/raw-loss = 0.7016104459762573, train/logprobs = tensor([[-1.4158, -1.4020],
        [-1.5185, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026600141427479684
Epoch 0, Step 2839: train/loss = 0.6956582069396973, train/raw-loss = 0.6947091817855835, train/logprobs = tensor([[-1.4321, -1.4220],
        [-1.5703, -1.3529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009490144439041615
Epoch 0, Step 2847: train/loss = 0.6970017552375793, train/raw-loss = 0.695786714553833, train/logprobs = tensor([[-1.4405, -1.4529],
        [-1.5472, -1.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012150467373430729
Epoch 0, Step 2855: train/loss = 0.7110751867294312, train/raw-loss = 0.7092652320861816, train/logprobs = tensor([[-1.5501, -1.7075],
        [-1.6750, -1.6066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018099250737577677
Epoch 0, Step 2863: train/loss = 0.6972529888153076, train/raw-loss = 0.6908763647079468, train/logprobs = tensor([[-1.3891, -1.4654],
        [-1.6782, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006376611068844795
Epoch 0, Step 2871: train/loss = 0.6954246163368225, train/raw-loss = 0.6941845417022705, train/logprobs = tensor([[-1.2961, -1.4219],
        [-1.3824, -1.3129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00124012166634202
Epoch 0, Step 2879: train/loss = 0.6982249021530151, train/raw-loss = 0.6969997882843018, train/logprobs = tensor([[-1.3539, -1.4594],
        [-1.2749, -1.3275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012250343570485711
Epoch 0, Step 2887: train/loss = 0.6960594654083252, train/raw-loss = 0.6959502100944519, train/logprobs = tensor([[-1.4998, -1.3811],
        [-1.4944, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010926631512120366
Epoch 0, Step 2895: train/loss = 0.6925646662712097, train/raw-loss = 0.6919609904289246, train/logprobs = tensor([[-1.3448, -1.4075],
        [-1.4305, -1.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006037219427525997
Epoch 0, Step 2903: train/loss = 0.7002416849136353, train/raw-loss = 0.6987773180007935, train/logprobs = tensor([[-1.6559, -1.5725],
        [-1.7955, -1.5515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001464353408664465
Epoch 0, Step 2911: train/loss = 0.693572461605072, train/raw-loss = 0.6931650042533875, train/logprobs = tensor([[-1.5517, -1.5781],
        [-1.5872, -1.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040747906314209104
Epoch 0, Step 2919: train/loss = 0.7040014266967773, train/raw-loss = 0.7013139128684998, train/logprobs = tensor([[-1.4955, -1.6877],
        [-1.5353, -1.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026875422336161137
Epoch 0, Step 2927: train/loss = 0.6942583322525024, train/raw-loss = 0.6941672563552856, train/logprobs = tensor([[-1.5336, -1.6121],
        [-1.5583, -1.5362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.109743405133486e-05
Epoch 0, Step 2935: train/loss = 0.6929623484611511, train/raw-loss = 0.6916287541389465, train/logprobs = tensor([[-1.6444, -1.6986],
        [-1.7972, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001333573367446661
Epoch 0, Step 2943: train/loss = 0.6948113441467285, train/raw-loss = 0.6945218443870544, train/logprobs = tensor([[-1.5063, -1.6271],
        [-1.4678, -1.4763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028947280952706933
Epoch 0, Step 2951: train/loss = 0.6985775232315063, train/raw-loss = 0.6961709856987, train/logprobs = tensor([[-1.7953, -1.7969],
        [-1.8391, -1.7130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024065347388386726
Epoch 0, Step 2959: train/loss = 0.6959245204925537, train/raw-loss = 0.6956524848937988, train/logprobs = tensor([[-1.5804, -1.7740],
        [-1.6747, -1.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027203437639400363
Epoch 0, Step 2967: train/loss = 0.6939567923545837, train/raw-loss = 0.6935677528381348, train/logprobs = tensor([[-1.5262, -1.5428],
        [-1.5720, -1.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038903416134417057
Epoch 0, Step 2975: train/loss = 0.6975404024124146, train/raw-loss = 0.6959295272827148, train/logprobs = tensor([[-1.5025, -1.8200],
        [-1.5662, -1.6105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016108027193695307
Epoch 0, Step 2983: train/loss = 0.703980028629303, train/raw-loss = 0.7034003138542175, train/logprobs = tensor([[-1.6817, -1.9339],
        [-1.6724, -1.7985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005797477788291872
Epoch 0, Step 2991: train/loss = 0.7064106464385986, train/raw-loss = 0.7063052654266357, train/logprobs = tensor([[-1.6320, -1.7657],
        [-1.6297, -1.6469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010533869499340653
Epoch 0, Step 2999: train/loss = 0.6940103769302368, train/raw-loss = 0.6925802230834961, train/logprobs = tensor([[-1.7776, -1.7887],
        [-1.7929, -1.6212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014301351038739085
Epoch 0, Step 3007: train/loss = 0.7021640539169312, train/raw-loss = 0.7015244960784912, train/logprobs = tensor([[-1.6399, -1.4626],
        [-1.6534, -1.3891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006395512027665973
Epoch 0, Step 3015: train/loss = 0.7120657563209534, train/raw-loss = 0.7116327285766602, train/logprobs = tensor([[-1.6423, -1.5804],
        [-1.7159, -1.5288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043302064295858145
Epoch 0, Step 3023: train/loss = 0.6965162754058838, train/raw-loss = 0.6963945627212524, train/logprobs = tensor([[-1.6243, -1.5452],
        [-1.5981, -1.4617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001217128083226271
Epoch 0, Step 3031: train/loss = 0.6939618587493896, train/raw-loss = 0.6938217282295227, train/logprobs = tensor([[-2.2278, -2.2105],
        [-2.4054, -2.2944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014013488544151187
Epoch 0, Step 3039: train/loss = 0.6943057775497437, train/raw-loss = 0.6940017938613892, train/logprobs = tensor([[-1.5962, -1.6969],
        [-1.7344, -1.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030393304768949747
Epoch 0, Step 3047: train/loss = 0.6949499845504761, train/raw-loss = 0.6945163011550903, train/logprobs = tensor([[-1.6506, -1.5880],
        [-1.7688, -1.5882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043365659075789154
Epoch 0, Step 3055: train/loss = 0.698398232460022, train/raw-loss = 0.6970919966697693, train/logprobs = tensor([[-1.4486, -1.5922],
        [-1.4941, -1.5124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013062686193734407
Epoch 0, Step 3063: train/loss = 0.695341944694519, train/raw-loss = 0.6948086023330688, train/logprobs = tensor([[-1.4897, -1.4829],
        [-1.5287, -1.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005333428853191435
Epoch 0, Step 3071: train/loss = 0.6974844932556152, train/raw-loss = 0.6964656710624695, train/logprobs = tensor([[-1.5357, -1.6415],
        [-1.6919, -1.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010188643354922533
Epoch 0, Step 3079: train/loss = 0.6936513781547546, train/raw-loss = 0.6929844617843628, train/logprobs = tensor([[-1.4768, -1.4821],
        [-1.5489, -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006669022259302437
Epoch 0, Step 3087: train/loss = 0.694508969783783, train/raw-loss = 0.6940783262252808, train/logprobs = tensor([[-1.5599, -1.7019],
        [-1.5592, -1.6210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004306409973651171
Epoch 0, Step 3095: train/loss = 0.69114750623703, train/raw-loss = 0.6887407302856445, train/logprobs = tensor([[-1.4369, -1.5267],
        [-1.5250, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002406802959740162
Epoch 0, Step 3103: train/loss = 0.6971830129623413, train/raw-loss = 0.6969383955001831, train/logprobs = tensor([[-1.4891, -1.6133],
        [-1.4594, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002446933649480343
Epoch 0, Step 3111: train/loss = 0.6965454816818237, train/raw-loss = 0.688780665397644, train/logprobs = tensor([[-1.5802, -1.7296],
        [-1.6712, -1.4785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007764842826873064
Epoch 0, Step 3119: train/loss = 0.6987484693527222, train/raw-loss = 0.6968199610710144, train/logprobs = tensor([[-1.5929, -1.5366],
        [-1.6870, -1.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019284996669739485
Epoch 0, Step 3127: train/loss = 0.7286317944526672, train/raw-loss = 0.7266787886619568, train/logprobs = tensor([[-1.5885, -1.4925],
        [-1.6799, -1.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00195299182087183
Epoch 0, Step 3135: train/loss = 0.694362998008728, train/raw-loss = 0.6886683702468872, train/logprobs = tensor([[-1.4514, -1.7435],
        [-1.6744, -1.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005694553256034851
Epoch 0, Step 3143: train/loss = 0.6922963261604309, train/raw-loss = 0.6919674277305603, train/logprobs = tensor([[-1.5756, -1.6418],
        [-1.6366, -1.5643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003288582665845752
Epoch 0, Step 3151: train/loss = 0.6922610402107239, train/raw-loss = 0.6904168725013733, train/logprobs = tensor([[-1.5639, -1.6075],
        [-1.6947, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018441868014633656
Epoch 0, Step 3159: train/loss = 0.6950182914733887, train/raw-loss = 0.6942556500434875, train/logprobs = tensor([[-1.2946, -1.4216],
        [-1.3912, -1.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000762642128393054
Epoch 0, Step 3167: train/loss = 0.6947730779647827, train/raw-loss = 0.6947141885757446, train/logprobs = tensor([[-1.3347, -1.4536],
        [-1.4179, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.892732588108629e-05
Epoch 0, Step 3175: train/loss = 0.695468008518219, train/raw-loss = 0.6946158409118652, train/logprobs = tensor([[-1.5058, -1.5074],
        [-1.5471, -1.3536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000852143915835768
Epoch 0, Step 3183: train/loss = 0.6920667886734009, train/raw-loss = 0.6857736110687256, train/logprobs = tensor([[-1.3536, -1.3820],
        [-1.7360, -1.3496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006293240003287792
Epoch 0, Step 3191: train/loss = 0.7046509981155396, train/raw-loss = 0.7025441527366638, train/logprobs = tensor([[-1.4043, -1.5820],
        [-1.4822, -1.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002106888685375452
Epoch 0, Step 3199: train/loss = 0.6919129490852356, train/raw-loss = 0.68939208984375, train/logprobs = tensor([[-1.4569, -1.6482],
        [-1.5855, -1.4434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025208527222275734
Epoch 0, Step 3207: train/loss = 0.6987032890319824, train/raw-loss = 0.6971302032470703, train/logprobs = tensor([[-1.5438, -1.8780],
        [-1.5655, -1.6133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015730757731944323
Epoch 0, Step 3215: train/loss = 0.6943396329879761, train/raw-loss = 0.69336998462677, train/logprobs = tensor([[-1.5725, -1.6445],
        [-1.5564, -1.4865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009696386405266821
Epoch 0, Step 3223: train/loss = 0.6966697573661804, train/raw-loss = 0.6966233849525452, train/logprobs = tensor([[-1.6292, -1.7573],
        [-1.5413, -1.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.637637175619602e-05
Epoch 0, Step 3231: train/loss = 0.6922293901443481, train/raw-loss = 0.6910016536712646, train/logprobs = tensor([[-1.5713, -1.6195],
        [-1.6695, -1.4392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00122771505266428
Epoch 0, Step 3239: train/loss = 0.695135235786438, train/raw-loss = 0.6934165358543396, train/logprobs = tensor([[-1.4957, -1.4788],
        [-1.8115, -1.4164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00171871786005795
Epoch 0, Step 3247: train/loss = 0.6941708922386169, train/raw-loss = 0.6934909224510193, train/logprobs = tensor([[-1.5812, -1.6177],
        [-1.6158, -1.5055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006799468537792563
Epoch 0, Step 3255: train/loss = 0.6908867359161377, train/raw-loss = 0.690814733505249, train/logprobs = tensor([[-1.8140, -1.8702],
        [-1.9028, -1.8168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.203246059361845e-05
Epoch 0, Step 3263: train/loss = 0.6912021040916443, train/raw-loss = 0.6877945065498352, train/logprobs = tensor([[-1.5245, -1.8422],
        [-1.7121, -1.6091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003407600335776806
Epoch 0, Step 3271: train/loss = 0.6976863741874695, train/raw-loss = 0.6962182521820068, train/logprobs = tensor([[-1.6171, -1.6622],
        [-1.7477, -1.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014681038446724415
Epoch 0, Step 3279: train/loss = 0.6936004161834717, train/raw-loss = 0.6924696564674377, train/logprobs = tensor([[-1.7359, -1.7526],
        [-1.6700, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001130774267949164
Epoch 0, Step 3287: train/loss = 0.6929267644882202, train/raw-loss = 0.6891674995422363, train/logprobs = tensor([[-1.7602, -1.8592],
        [-1.8769, -1.6949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003759231884032488
Epoch 0, Step 3295: train/loss = 0.6992545127868652, train/raw-loss = 0.6986037492752075, train/logprobs = tensor([[-1.6378, -1.7830],
        [-1.7096, -1.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006507808575406671
Epoch 0, Step 3303: train/loss = 0.6959315538406372, train/raw-loss = 0.6949514150619507, train/logprobs = tensor([[-1.9368, -1.8811],
        [-1.8775, -1.6074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000980098731815815
Epoch 0, Step 3311: train/loss = 0.7027082443237305, train/raw-loss = 0.6989885568618774, train/logprobs = tensor([[-1.7229, -1.7126],
        [-1.9494, -1.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037196706980466843
Epoch 0, Step 3319: train/loss = 0.6945933699607849, train/raw-loss = 0.6940791010856628, train/logprobs = tensor([[-1.6006, -1.6669],
        [-1.6608, -1.7250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005143232992850244
Epoch 0, Step 3327: train/loss = 0.6921282410621643, train/raw-loss = 0.69199138879776, train/logprobs = tensor([[-1.6758, -1.7225],
        [-1.6792, -1.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013685505837202072
Epoch 0, Step 3335: train/loss = 0.7005929350852966, train/raw-loss = 0.7000322341918945, train/logprobs = tensor([[-1.6379, -1.7993],
        [-1.5494, -1.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005606343038380146
Epoch 0, Step 3343: train/loss = 0.6961616277694702, train/raw-loss = 0.6908491849899292, train/logprobs = tensor([[-1.7333, -1.8482],
        [-1.8505, -1.7292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053124506957829
Epoch 0, Step 3351: train/loss = 0.7039332389831543, train/raw-loss = 0.7029746770858765, train/logprobs = tensor([[-1.7040, -1.9112],
        [-1.6929, -1.8228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000958593562245369
Epoch 0, Step 3359: train/loss = 0.7039844393730164, train/raw-loss = 0.7021346092224121, train/logprobs = tensor([[-1.6881, -2.0539],
        [-1.7726, -1.8766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018497499404475093
Epoch 0, Step 3367: train/loss = 0.6944804787635803, train/raw-loss = 0.6924147605895996, train/logprobs = tensor([[-1.7403, -2.1771],
        [-1.8026, -1.8088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002065731678158045
Epoch 0, Step 3375: train/loss = 0.6859892010688782, train/raw-loss = 0.6856342554092407, train/logprobs = tensor([[-1.6691, -1.9169],
        [-2.0108, -1.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035491742892190814
Epoch 0, Step 3383: train/loss = 0.6955999135971069, train/raw-loss = 0.6942303776741028, train/logprobs = tensor([[-1.6426, -1.6382],
        [-1.7252, -1.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013694956433027983
Epoch 0, Step 3391: train/loss = 0.6938741207122803, train/raw-loss = 0.6936219930648804, train/logprobs = tensor([[-1.7667, -1.8378],
        [-1.5929, -1.6161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025212904438376427
Epoch 0, Step 3399: train/loss = 0.708258867263794, train/raw-loss = 0.7067016363143921, train/logprobs = tensor([[-1.6004, -1.8646],
        [-1.7340, -1.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015571943949908018
Epoch 0, Step 3407: train/loss = 0.6984615921974182, train/raw-loss = 0.6976523995399475, train/logprobs = tensor([[-1.4890, -1.6330],
        [-1.4513, -1.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008092245552688837
Epoch 0, Step 3415: train/loss = 0.6969852447509766, train/raw-loss = 0.6958615779876709, train/logprobs = tensor([[-1.5966, -1.6316],
        [-1.6329, -1.5264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011237002909183502
Epoch 0, Step 3423: train/loss = 0.6938180327415466, train/raw-loss = 0.6923990249633789, train/logprobs = tensor([[-1.5762, -1.7243],
        [-1.5757, -1.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014189976500347257
Epoch 0, Step 3431: train/loss = 0.6967300176620483, train/raw-loss = 0.6956630945205688, train/logprobs = tensor([[-1.5088, -1.6079],
        [-1.5257, -1.4103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001066913828253746
Epoch 0, Step 3439: train/loss = 0.6956602931022644, train/raw-loss = 0.693618893623352, train/logprobs = tensor([[-1.4835, -1.5856],
        [-1.5415, -1.4494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002041412051767111
Epoch 0, Step 3447: train/loss = 0.695875883102417, train/raw-loss = 0.6917725205421448, train/logprobs = tensor([[-1.6116, -1.6358],
        [-1.5337, -1.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004103414714336395
Epoch 0, Step 3455: train/loss = 0.6957913041114807, train/raw-loss = 0.6891165971755981, train/logprobs = tensor([[-1.5208, -1.6226],
        [-1.6307, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006674785166978836
Epoch 0, Step 3463: train/loss = 0.6985891461372375, train/raw-loss = 0.6979572772979736, train/logprobs = tensor([[-1.4840, -1.7176],
        [-1.6120, -1.6808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000631839269772172
Epoch 0, Step 3471: train/loss = 0.7028498649597168, train/raw-loss = 0.7012433409690857, train/logprobs = tensor([[-1.5701, -1.7809],
        [-1.6134, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016065288800746202
Epoch 0, Step 3479: train/loss = 0.6990513801574707, train/raw-loss = 0.6937242150306702, train/logprobs = tensor([[-1.5870, -1.6191],
        [-1.6561, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005327139515429735
Epoch 0, Step 3487: train/loss = 0.6966437697410583, train/raw-loss = 0.695932924747467, train/logprobs = tensor([[-1.4108, -1.4092],
        [-1.4797, -1.3215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007108272984623909
Epoch 0, Step 3495: train/loss = 0.6937295794487, train/raw-loss = 0.693452000617981, train/logprobs = tensor([[-1.5434, -1.6388],
        [-1.5494, -1.5619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027761165983974934
Epoch 0, Step 3503: train/loss = 0.6935749053955078, train/raw-loss = 0.6929311752319336, train/logprobs = tensor([[-1.4636, -1.5030],
        [-1.5184, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000643676845356822
Epoch 0, Step 3511: train/loss = 0.6944238543510437, train/raw-loss = 0.6931988596916199, train/logprobs = tensor([[-1.5437, -1.6175],
        [-1.5029, -1.4459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012250295840203762
Epoch 0, Step 3519: train/loss = 0.6932728290557861, train/raw-loss = 0.6931114792823792, train/logprobs = tensor([[-1.3427, -1.3513],
        [-1.3244, -1.2874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016133865574374795
Epoch 0, Step 3527: train/loss = 0.6951186060905457, train/raw-loss = 0.69487464427948, train/logprobs = tensor([[-1.4525, -1.5544],
        [-1.4754, -1.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024397761444561183
Epoch 0, Step 3535: train/loss = 0.6925152540206909, train/raw-loss = 0.691737711429596, train/logprobs = tensor([[-1.4037, -1.5158],
        [-1.5044, -1.4284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007775730919092894
Epoch 0, Step 3543: train/loss = 0.6989262104034424, train/raw-loss = 0.6974818706512451, train/logprobs = tensor([[-1.4253, -1.5893],
        [-1.5243, -1.5051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014442976098507643
Epoch 0, Step 3551: train/loss = 0.6997314691543579, train/raw-loss = 0.6980934739112854, train/logprobs = tensor([[-1.5178, -1.5352],
        [-1.5407, -1.3072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016379824373871088
Epoch 0, Step 3559: train/loss = 0.6996326446533203, train/raw-loss = 0.6978837847709656, train/logprobs = tensor([[-1.5301, -1.6342],
        [-1.5896, -1.4930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001748851966112852
Epoch 0, Step 3567: train/loss = 0.6978580951690674, train/raw-loss = 0.6968861818313599, train/logprobs = tensor([[-1.4879, -1.5129],
        [-1.5509, -1.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009719121735543013
Epoch 0, Step 3575: train/loss = 0.6958736777305603, train/raw-loss = 0.6949814558029175, train/logprobs = tensor([[-1.4860, -1.4611],
        [-1.6354, -1.5218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008922412525862455
Epoch 0, Step 3583: train/loss = 0.6896575689315796, train/raw-loss = 0.6878386735916138, train/logprobs = tensor([[-1.4203, -1.7718],
        [-1.6650, -1.5856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018189249094575644
Epoch 0, Step 3591: train/loss = 0.6939393877983093, train/raw-loss = 0.6914372444152832, train/logprobs = tensor([[-1.5533, -1.6307],
        [-1.5879, -1.4454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025021047331392765
Epoch 0, Step 3599: train/loss = 0.6923688650131226, train/raw-loss = 0.6902482509613037, train/logprobs = tensor([[-1.4689, -1.6852],
        [-1.7769, -1.5656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002120628021657467
Epoch 0, Step 3607: train/loss = 0.6928913593292236, train/raw-loss = 0.6923841238021851, train/logprobs = tensor([[-1.7022, -1.7541],
        [-1.6371, -1.5888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005072160856798291
Epoch 0, Step 3615: train/loss = 0.6965888142585754, train/raw-loss = 0.6957194209098816, train/logprobs = tensor([[-1.5501, -1.7042],
        [-1.5643, -1.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008693980635143816
Epoch 0, Step 3623: train/loss = 0.6995105743408203, train/raw-loss = 0.6985543966293335, train/logprobs = tensor([[-1.5251, -1.7611],
        [-1.6006, -1.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009561690967530012
Epoch 0, Step 3631: train/loss = 0.6963320374488831, train/raw-loss = 0.6957916021347046, train/logprobs = tensor([[-1.6093, -1.9289],
        [-1.6761, -1.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005404170951806009
Epoch 0, Step 3639: train/loss = 0.7021735906600952, train/raw-loss = 0.7013664245605469, train/logprobs = tensor([[-1.5348, -1.6806],
        [-1.5910, -1.6670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008071769843809307
Epoch 0, Step 3647: train/loss = 0.7111925482749939, train/raw-loss = 0.7046923637390137, train/logprobs = tensor([[-1.7071, -1.9719],
        [-1.7362, -1.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0065001873299479485
Epoch 0, Step 3655: train/loss = 0.7064050436019897, train/raw-loss = 0.7006959319114685, train/logprobs = tensor([[-1.6826, -1.9758],
        [-1.8121, -1.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005709137301892042
Epoch 0, Step 3663: train/loss = 0.6926001310348511, train/raw-loss = 0.6910163164138794, train/logprobs = tensor([[-1.7251, -1.7742],
        [-1.8455, -1.6715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015838142717257142
Epoch 0, Step 3671: train/loss = 0.6964954137802124, train/raw-loss = 0.6962244510650635, train/logprobs = tensor([[-1.7203, -1.8465],
        [-1.7235, -1.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002709940308704972
Epoch 0, Step 3679: train/loss = 0.6998794078826904, train/raw-loss = 0.6993860006332397, train/logprobs = tensor([[-1.7698, -1.8691],
        [-1.8168, -1.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004933763993903995
Epoch 0, Step 3687: train/loss = 0.6957563161849976, train/raw-loss = 0.695683479309082, train/logprobs = tensor([[-1.8588, -1.7783],
        [-1.9401, -1.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.290141365956515e-05
Epoch 0, Step 3695: train/loss = 0.6957246661186218, train/raw-loss = 0.6876445412635803, train/logprobs = tensor([[-1.8866, -2.0935],
        [-2.0217, -1.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008080187253654003
Epoch 0, Step 3703: train/loss = 0.6940259337425232, train/raw-loss = 0.6935678720474243, train/logprobs = tensor([[-1.8973, -1.9666],
        [-1.9107, -1.8759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045806565321981907
Epoch 0, Step 3711: train/loss = 0.6976829767227173, train/raw-loss = 0.6968363523483276, train/logprobs = tensor([[-1.7727, -2.0238],
        [-1.8067, -1.8834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008466064464300871
Epoch 0, Step 3719: train/loss = 0.6942512392997742, train/raw-loss = 0.6941179037094116, train/logprobs = tensor([[-1.8080, -1.8132],
        [-1.8146, -1.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001332778192590922
Epoch 0, Step 3727: train/loss = 0.6943774819374084, train/raw-loss = 0.6942402124404907, train/logprobs = tensor([[-1.8545, -1.9090],
        [-1.9045, -1.8466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001373083796352148
Epoch 0, Step 3735: train/loss = 0.7003631591796875, train/raw-loss = 0.7002337574958801, train/logprobs = tensor([[-1.9236, -2.0399],
        [-1.9722, -2.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012940354645252228
Epoch 0, Step 3743: train/loss = 0.6952474117279053, train/raw-loss = 0.6949434876441956, train/logprobs = tensor([[-2.0193, -1.9568],
        [-2.1088, -1.8478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003039521398022771
Epoch 0, Step 3751: train/loss = 0.697040319442749, train/raw-loss = 0.6967606544494629, train/logprobs = tensor([[-1.9739, -2.1752],
        [-1.9584, -1.9956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027966240304522216
Epoch 0, Step 3759: train/loss = 0.6949295997619629, train/raw-loss = 0.694695234298706, train/logprobs = tensor([[-1.9723, -1.9656],
        [-1.9653, -1.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002342619700357318
Epoch 0, Step 3767: train/loss = 0.6954305171966553, train/raw-loss = 0.6894275546073914, train/logprobs = tensor([[-1.8607, -2.1354],
        [-1.9483, -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006002955604344606
Epoch 0, Step 3775: train/loss = 0.7073307633399963, train/raw-loss = 0.7060063481330872, train/logprobs = tensor([[-2.1060, -2.0085],
        [-2.0991, -1.7188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013244051951915026
Epoch 0, Step 3783: train/loss = 0.6965076923370361, train/raw-loss = 0.6962746381759644, train/logprobs = tensor([[-1.9969, -1.9414],
        [-2.0005, -1.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002329437411390245
Epoch 0, Step 3791: train/loss = 0.6996448040008545, train/raw-loss = 0.6984976530075073, train/logprobs = tensor([[-1.9366, -2.1441],
        [-1.8731, -1.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011470996541902423
Epoch 0, Step 3799: train/loss = 0.6976578235626221, train/raw-loss = 0.6943633556365967, train/logprobs = tensor([[-1.8985, -2.1243],
        [-1.9226, -1.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00329450867138803
Epoch 0, Step 3807: train/loss = 0.7007319927215576, train/raw-loss = 0.6987930536270142, train/logprobs = tensor([[-2.0145, -1.9842],
        [-2.1696, -1.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019389237277209759
Epoch 0, Step 3815: train/loss = 0.6936272382736206, train/raw-loss = 0.692137598991394, train/logprobs = tensor([[-1.9689, -1.9972],
        [-2.1484, -1.9227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014896634966135025
Epoch 0, Step 3823: train/loss = 0.6968740224838257, train/raw-loss = 0.6958795785903931, train/logprobs = tensor([[-1.9370, -2.0120],
        [-1.8585, -1.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009944289922714233
Epoch 0, Step 3831: train/loss = 0.7056273818016052, train/raw-loss = 0.7050547003746033, train/logprobs = tensor([[-1.9077, -1.9464],
        [-1.9043, -1.9121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005726811359636486
Epoch 0, Step 3839: train/loss = 0.6928837895393372, train/raw-loss = 0.6925249099731445, train/logprobs = tensor([[-1.8851, -1.9203],
        [-1.8708, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003588408580981195
Epoch 0, Step 3847: train/loss = 0.6970943808555603, train/raw-loss = 0.6966331005096436, train/logprobs = tensor([[-2.2296, -2.1815],
        [-2.1654, -2.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004613276687450707
Epoch 0, Step 3855: train/loss = 0.7046613097190857, train/raw-loss = 0.7042040228843689, train/logprobs = tensor([[-2.1347, -1.9295],
        [-2.1631, -1.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004573285114020109
Epoch 0, Step 3863: train/loss = 0.6949700713157654, train/raw-loss = 0.694370687007904, train/logprobs = tensor([[-2.0390, -2.0377],
        [-1.9859, -1.8819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005993875674903393
Epoch 0, Step 3871: train/loss = 0.6919274926185608, train/raw-loss = 0.6910372972488403, train/logprobs = tensor([[-1.9310, -2.0722],
        [-2.0310, -1.8883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008901783148758113
Epoch 0, Step 3879: train/loss = 0.6938902139663696, train/raw-loss = 0.6935691833496094, train/logprobs = tensor([[-1.9943, -1.9919],
        [-1.9762, -1.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003210322465747595
Epoch 0, Step 3887: train/loss = 0.6956987380981445, train/raw-loss = 0.6956560611724854, train/logprobs = tensor([[-2.0464, -2.0890],
        [-1.9936, -2.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.260122659616172e-05
Epoch 0, Step 3895: train/loss = 0.6938571929931641, train/raw-loss = 0.6935214996337891, train/logprobs = tensor([[-2.0495, -2.0309],
        [-1.9492, -1.8791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003357046516612172
Epoch 0, Step 3903: train/loss = 0.6944738626480103, train/raw-loss = 0.6938785314559937, train/logprobs = tensor([[-1.9124, -1.9879],
        [-1.9862, -1.8812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005953699583187699
Epoch 0, Step 3911: train/loss = 0.6937252283096313, train/raw-loss = 0.6931935548782349, train/logprobs = tensor([[-1.8785, -2.0136],
        [-1.8885, -1.8544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005315857124514878
Epoch 0, Step 3919: train/loss = 0.6958284378051758, train/raw-loss = 0.6939564943313599, train/logprobs = tensor([[-2.0243, -2.0053],
        [-2.0010, -1.7408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018719709478318691
Epoch 0, Step 3927: train/loss = 0.6969025135040283, train/raw-loss = 0.6962152719497681, train/logprobs = tensor([[-1.8859, -1.8358],
        [-1.8769, -1.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006872535450384021
Epoch 0, Step 3935: train/loss = 0.695059061050415, train/raw-loss = 0.6941562294960022, train/logprobs = tensor([[-1.9005, -1.8817],
        [-1.8996, -1.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009028085041791201
Epoch 0, Step 3943: train/loss = 0.6967840790748596, train/raw-loss = 0.6929185390472412, train/logprobs = tensor([[-1.9431, -2.0895],
        [-2.0739, -1.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003865577979013324
Epoch 0, Step 3951: train/loss = 0.6878393888473511, train/raw-loss = 0.6862796545028687, train/logprobs = tensor([[-1.9771, -2.1962],
        [-2.0492, -1.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015597079182043672
Epoch 0, Step 3959: train/loss = 0.6972028017044067, train/raw-loss = 0.69636470079422, train/logprobs = tensor([[-1.8950, -2.0103],
        [-1.9858, -1.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008380774524994195
Epoch 0, Step 3967: train/loss = 0.7002876400947571, train/raw-loss = 0.6968944668769836, train/logprobs = tensor([[-1.8706, -2.1705],
        [-1.9481, -1.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033931294456124306
Epoch 0, Step 3975: train/loss = 0.6941250562667847, train/raw-loss = 0.6934274435043335, train/logprobs = tensor([[-1.9336, -2.0080],
        [-1.8898, -1.8970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006976196309551597
Epoch 0, Step 3983: train/loss = 0.675592839717865, train/raw-loss = 0.6741816997528076, train/logprobs = tensor([[-1.8266, -2.0869],
        [-2.1732, -1.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014111832715570927
Epoch 0, Step 3991: train/loss = 0.6976748108863831, train/raw-loss = 0.6946315765380859, train/logprobs = tensor([[-1.9803, -2.2333],
        [-1.9030, -1.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003043252741917968
Epoch 0, Step 3999: train/loss = 0.695156455039978, train/raw-loss = 0.6932781338691711, train/logprobs = tensor([[-1.9210, -2.0445],
        [-1.9894, -1.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018783153500407934
Epoch 0, Step 4007: train/loss = 0.6943563222885132, train/raw-loss = 0.6921312808990479, train/logprobs = tensor([[-1.9952, -2.0869],
        [-1.9365, -1.8773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002225031377747655
Epoch 0, Step 4015: train/loss = 0.6933329105377197, train/raw-loss = 0.6925496459007263, train/logprobs = tensor([[-1.9614, -1.9838],
        [-1.9224, -1.7990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007832502597011626
Epoch 0, Step 4023: train/loss = 0.695847749710083, train/raw-loss = 0.6955103874206543, train/logprobs = tensor([[-2.0179, -2.0634],
        [-2.0470, -1.9927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033733449527062476
Epoch 0, Step 4031: train/loss = 0.6957857608795166, train/raw-loss = 0.6952575445175171, train/logprobs = tensor([[-1.9318, -1.9644],
        [-1.8968, -1.8963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005283028585836291
Epoch 0, Step 4039: train/loss = 0.6974879503250122, train/raw-loss = 0.6969833374023438, train/logprobs = tensor([[-1.9853, -2.0062],
        [-2.0873, -1.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005046024452894926
Epoch 0, Step 4047: train/loss = 0.6978232860565186, train/raw-loss = 0.6975556015968323, train/logprobs = tensor([[-1.9852, -2.1165],
        [-1.9092, -1.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002677467418834567
Epoch 0, Step 4055: train/loss = 0.697128176689148, train/raw-loss = 0.6970053911209106, train/logprobs = tensor([[-1.9179, -2.0576],
        [-1.8479, -1.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001227949687745422
Epoch 0, Step 4063: train/loss = 0.6931058168411255, train/raw-loss = 0.6929720640182495, train/logprobs = tensor([[-1.7613, -1.8548],
        [-1.9400, -1.9276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001337910071015358
Epoch 0, Step 4071: train/loss = 0.6922854781150818, train/raw-loss = 0.6918795108795166, train/logprobs = tensor([[-1.9685, -2.1056],
        [-1.8638, -1.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040594665915705264
Epoch 0, Step 4079: train/loss = 0.6932758092880249, train/raw-loss = 0.6924068331718445, train/logprobs = tensor([[-1.7627, -1.8600],
        [-1.7404, -1.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008689552778378129
Epoch 0, Step 4087: train/loss = 0.6932764053344727, train/raw-loss = 0.6930027008056641, train/logprobs = tensor([[-1.8307, -1.9201],
        [-1.8320, -1.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002737107570283115
Epoch 0, Step 4095: train/loss = 0.6925397515296936, train/raw-loss = 0.6886978149414062, train/logprobs = tensor([[-1.9262, -2.0627],
        [-2.0049, -1.7915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038420415949076414
Epoch 0, Step 4103: train/loss = 0.6955583095550537, train/raw-loss = 0.6942604184150696, train/logprobs = tensor([[-1.8833, -1.9879],
        [-1.8898, -1.8893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012978975428268313
Epoch 0, Step 4111: train/loss = 0.6937675476074219, train/raw-loss = 0.6936553120613098, train/logprobs = tensor([[-1.8421, -1.9022],
        [-1.8432, -1.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011226808419451118
Epoch 0, Step 4119: train/loss = 0.6950685977935791, train/raw-loss = 0.6939725279808044, train/logprobs = tensor([[-1.8052, -2.0097],
        [-1.8157, -1.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010960091603919864
Epoch 0, Step 4127: train/loss = 0.6927738189697266, train/raw-loss = 0.6917983293533325, train/logprobs = tensor([[-1.8776, -1.9300],
        [-1.9414, -1.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009756098734214902
Epoch 0, Step 4135: train/loss = 0.6938065886497498, train/raw-loss = 0.692930281162262, train/logprobs = tensor([[-1.8248, -1.9371],
        [-1.8828, -1.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008762521902099252
Epoch 0, Step 4143: train/loss = 0.6920573711395264, train/raw-loss = 0.6911982297897339, train/logprobs = tensor([[-1.8538, -1.9696],
        [-1.9444, -1.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008591207442805171
Epoch 0, Step 4151: train/loss = 0.6943469047546387, train/raw-loss = 0.6934164762496948, train/logprobs = tensor([[-1.8762, -2.0029],
        [-1.8989, -1.8503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009303372353315353
Epoch 0, Step 4159: train/loss = 0.6940996646881104, train/raw-loss = 0.6937649250030518, train/logprobs = tensor([[-1.9100, -1.8794],
        [-1.8819, -1.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003346746088936925
Epoch 0, Step 4167: train/loss = 0.6944323778152466, train/raw-loss = 0.6943458914756775, train/logprobs = tensor([[-2.1646, -2.0980],
        [-1.9988, -1.9582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.64647445268929e-05
Epoch 0, Step 4175: train/loss = 0.6939566135406494, train/raw-loss = 0.6933934688568115, train/logprobs = tensor([[-2.0489, -2.0320],
        [-2.0993, -2.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005631863605231047
Epoch 0, Step 4183: train/loss = 0.6941807270050049, train/raw-loss = 0.6938775777816772, train/logprobs = tensor([[-1.9009, -1.8872],
        [-1.9378, -1.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030316569609567523
Epoch 0, Step 4191: train/loss = 0.7010337114334106, train/raw-loss = 0.6913989186286926, train/logprobs = tensor([[-1.9133, -2.0960],
        [-1.9996, -1.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009634848684072495
Epoch 0, Step 4199: train/loss = 0.6992267966270447, train/raw-loss = 0.6989471912384033, train/logprobs = tensor([[-1.9734, -2.0783],
        [-1.9665, -1.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002796076296363026
Epoch 0, Step 4207: train/loss = 0.6980794668197632, train/raw-loss = 0.6979111433029175, train/logprobs = tensor([[-1.8260, -2.0630],
        [-1.8826, -1.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016835039423312992
Epoch 0, Step 4215: train/loss = 0.6933513283729553, train/raw-loss = 0.6925356984138489, train/logprobs = tensor([[-1.8978, -1.9572],
        [-1.9354, -1.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008156006806530058
Epoch 0, Step 4223: train/loss = 0.6967623233795166, train/raw-loss = 0.6961473226547241, train/logprobs = tensor([[-2.0723, -2.0037],
        [-2.1212, -1.8573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006149597465991974
Epoch 0, Step 4231: train/loss = 0.6931753158569336, train/raw-loss = 0.6931118369102478, train/logprobs = tensor([[-2.0007, -2.0277],
        [-2.0078, -1.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.343204586300999e-05
Epoch 0, Step 4239: train/loss = 0.6980043053627014, train/raw-loss = 0.6970789432525635, train/logprobs = tensor([[-2.0448, -2.1889],
        [-2.0034, -1.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009252942400053144
Epoch 0, Step 4247: train/loss = 0.7005385160446167, train/raw-loss = 0.6988922357559204, train/logprobs = tensor([[-2.0644, -2.2643],
        [-2.0045, -2.0311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001646257471293211
Epoch 0, Step 4255: train/loss = 0.7006461024284363, train/raw-loss = 0.7005946040153503, train/logprobs = tensor([[-2.0263, -1.9263],
        [-2.0610, -1.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.144852912053466e-05
Epoch 0, Step 4263: train/loss = 0.6889915466308594, train/raw-loss = 0.6879780292510986, train/logprobs = tensor([[-1.8699, -2.0715],
        [-1.9555, -1.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010135490447282791
Epoch 0, Step 4271: train/loss = 0.6870660781860352, train/raw-loss = 0.6868799924850464, train/logprobs = tensor([[-2.0486, -2.1448],
        [-2.0459, -1.8841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018605709192343056
Epoch 0, Step 4279: train/loss = 0.6958110332489014, train/raw-loss = 0.6949518322944641, train/logprobs = tensor([[-1.9391, -2.0612],
        [-2.0722, -2.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008592720841988921
Epoch 0, Step 4287: train/loss = 0.6933021545410156, train/raw-loss = 0.6928340792655945, train/logprobs = tensor([[-1.8566, -1.9195],
        [-1.8334, -1.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004681096179410815
Epoch 0, Step 4295: train/loss = 0.6932101845741272, train/raw-loss = 0.6921479105949402, train/logprobs = tensor([[-2.0475, -2.0958],
        [-1.9745, -1.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010622080881148577
Epoch 0, Step 4303: train/loss = 0.6945812106132507, train/raw-loss = 0.6919281482696533, train/logprobs = tensor([[-1.9002, -2.0072],
        [-1.9598, -1.8621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002653032075613737
Epoch 0, Step 4311: train/loss = 0.6981188654899597, train/raw-loss = 0.6971768140792847, train/logprobs = tensor([[-1.9913, -1.9455],
        [-1.9953, -1.7766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009420188143849373
Epoch 0, Step 4319: train/loss = 0.6964091658592224, train/raw-loss = 0.6935011148452759, train/logprobs = tensor([[-2.1267, -2.2457],
        [-2.1071, -1.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029080796521157026
Epoch 0, Step 4327: train/loss = 0.6963373422622681, train/raw-loss = 0.694983720779419, train/logprobs = tensor([[-2.0954, -2.0567],
        [-2.0944, -1.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001353643019683659
Epoch 0, Step 4335: train/loss = 0.6966777443885803, train/raw-loss = 0.6960363984107971, train/logprobs = tensor([[-2.1897, -2.2449],
        [-2.1780, -2.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006413684459403157
Epoch 0, Step 4343: train/loss = 0.6939927935600281, train/raw-loss = 0.6932034492492676, train/logprobs = tensor([[-1.9095, -1.9928],
        [-1.9073, -1.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007892940775491297
Epoch 0, Step 4351: train/loss = 0.6979600191116333, train/raw-loss = 0.6971327662467957, train/logprobs = tensor([[-2.0498, -2.0671],
        [-1.9981, -1.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008272439590655267
Epoch 0, Step 4359: train/loss = 0.6952592134475708, train/raw-loss = 0.6948981285095215, train/logprobs = tensor([[-1.9710, -2.1292],
        [-1.9354, -1.9869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003611320862546563
Epoch 0, Step 4367: train/loss = 0.6915775537490845, train/raw-loss = 0.6912126541137695, train/logprobs = tensor([[-2.0578, -2.1976],
        [-2.1074, -1.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003649013233371079
Epoch 0, Step 4375: train/loss = 0.6963983774185181, train/raw-loss = 0.6962286233901978, train/logprobs = tensor([[-2.0134, -2.0960],
        [-1.8869, -1.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016979513748083264
Epoch 0, Step 4383: train/loss = 0.693139374256134, train/raw-loss = 0.6931190490722656, train/logprobs = tensor([[-2.1349, -2.1278],
        [-2.0544, -2.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.026366928475909e-05
Epoch 0, Step 4391: train/loss = 0.6932533979415894, train/raw-loss = 0.6931648850440979, train/logprobs = tensor([[-2.0066, -2.0261],
        [-1.9223, -1.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.853206963976845e-05
Epoch 0, Step 4399: train/loss = 0.6937645673751831, train/raw-loss = 0.6934216022491455, train/logprobs = tensor([[-2.0773, -2.1312],
        [-2.0551, -2.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034299175604246557
Epoch 0, Step 4407: train/loss = 0.6968938112258911, train/raw-loss = 0.6955111622810364, train/logprobs = tensor([[-2.0753, -2.3855],
        [-2.1322, -2.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013825912028551102
Epoch 0, Step 4415: train/loss = 0.695962131023407, train/raw-loss = 0.6953306794166565, train/logprobs = tensor([[-2.0229, -2.1431],
        [-2.0175, -2.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006314205238595605
Epoch 0, Step 4423: train/loss = 0.693549633026123, train/raw-loss = 0.6922726035118103, train/logprobs = tensor([[-2.0145, -2.1200],
        [-2.0752, -2.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012770246248692274
Epoch 0, Step 4431: train/loss = 0.6969197392463684, train/raw-loss = 0.6910048723220825, train/logprobs = tensor([[-1.9495, -2.2219],
        [-2.0500, -1.9639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005914925131946802
Epoch 0, Step 4439: train/loss = 0.696550190448761, train/raw-loss = 0.696141242980957, train/logprobs = tensor([[-2.1528, -2.3428],
        [-1.9930, -2.0812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004090562870260328
Epoch 0, Step 4447: train/loss = 0.7107457518577576, train/raw-loss = 0.7096962928771973, train/logprobs = tensor([[-2.0138, -2.3332],
        [-1.9886, -2.1740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010495329042896628
Epoch 0, Step 4455: train/loss = 0.6967090964317322, train/raw-loss = 0.6947945952415466, train/logprobs = tensor([[-2.0565, -2.2578],
        [-2.1204, -2.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019145701080560684
Epoch 0, Step 4463: train/loss = 0.6998565793037415, train/raw-loss = 0.6980780363082886, train/logprobs = tensor([[-2.0278, -2.2119],
        [-1.9946, -1.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00177855440415442
Epoch 0, Step 4471: train/loss = 0.6944365501403809, train/raw-loss = 0.694291889667511, train/logprobs = tensor([[-2.0343, -2.1189],
        [-2.0182, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014456314966082573
Epoch 0, Step 4479: train/loss = 0.6919577717781067, train/raw-loss = 0.6914942264556885, train/logprobs = tensor([[-1.9617, -2.0744],
        [-2.0325, -1.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004635298391804099
Epoch 0, Step 4487: train/loss = 0.6978344321250916, train/raw-loss = 0.6973068714141846, train/logprobs = tensor([[-2.1165, -2.1512],
        [-1.9978, -2.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000527490396052599
Epoch 0, Step 4495: train/loss = 0.6940394639968872, train/raw-loss = 0.6939399242401123, train/logprobs = tensor([[-2.0544, -2.1222],
        [-2.0415, -2.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.950397361535579e-05
Epoch 0, Step 4503: train/loss = 0.6973702907562256, train/raw-loss = 0.6972120404243469, train/logprobs = tensor([[-1.8912, -2.0725],
        [-1.8752, -1.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015823973808437586
Epoch 0, Step 4511: train/loss = 0.6934659481048584, train/raw-loss = 0.6932075619697571, train/logprobs = tensor([[-1.9597, -1.9636],
        [-1.9490, -1.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002583656460046768
Epoch 0, Step 4519: train/loss = 0.6903415322303772, train/raw-loss = 0.6888737082481384, train/logprobs = tensor([[-2.1821, -2.2290],
        [-2.1696, -1.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014677998842671514
Epoch 0, Step 4527: train/loss = 0.6947491765022278, train/raw-loss = 0.693931519985199, train/logprobs = tensor([[-1.9878, -2.0270],
        [-1.8820, -1.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000817668333183974
Epoch 0, Step 4535: train/loss = 0.6939052939414978, train/raw-loss = 0.693476140499115, train/logprobs = tensor([[-1.9793, -1.9860],
        [-1.8879, -1.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042915577068924904
Epoch 0, Step 4543: train/loss = 0.6818419694900513, train/raw-loss = 0.6793792247772217, train/logprobs = tensor([[-2.0841, -2.3631],
        [-2.0263, -1.8459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002462709089741111
Epoch 0, Step 4551: train/loss = 0.697434663772583, train/raw-loss = 0.6944875121116638, train/logprobs = tensor([[-1.9949, -1.9826],
        [-2.0239, -1.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002947099506855011
Epoch 0, Step 4559: train/loss = 0.695084810256958, train/raw-loss = 0.6945460438728333, train/logprobs = tensor([[-1.8231, -2.0352],
        [-1.8541, -1.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005387880373746157
Epoch 0, Step 4567: train/loss = 0.6917176842689514, train/raw-loss = 0.6911569833755493, train/logprobs = tensor([[-2.0059, -2.1190],
        [-2.0253, -1.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005607211496680975
Epoch 0, Step 4575: train/loss = 0.695962131023407, train/raw-loss = 0.6957560777664185, train/logprobs = tensor([[-1.9652, -1.9108],
        [-1.8663, -1.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020603334996849298
Epoch 0, Step 4583: train/loss = 0.695279061794281, train/raw-loss = 0.6935402750968933, train/logprobs = tensor([[-2.1275, -2.1281],
        [-2.1430, -1.9369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017388015985488892
Epoch 0, Step 4591: train/loss = 0.6941198110580444, train/raw-loss = 0.6919792890548706, train/logprobs = tensor([[-1.9877, -2.0460],
        [-1.9817, -1.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002140575088560581
Epoch 0, Step 4599: train/loss = 0.6908817291259766, train/raw-loss = 0.6880781650543213, train/logprobs = tensor([[-1.9045, -2.1455],
        [-2.0602, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00280359317548573
Epoch 0, Step 4607: train/loss = 0.696578860282898, train/raw-loss = 0.6937328577041626, train/logprobs = tensor([[-1.9841, -2.0016],
        [-1.9297, -1.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002846036572009325
Epoch 0, Step 4615: train/loss = 0.7018533945083618, train/raw-loss = 0.7008920907974243, train/logprobs = tensor([[-2.0501, -2.1060],
        [-1.9482, -1.8488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009613781003281474
Epoch 0, Step 4623: train/loss = 0.6965802907943726, train/raw-loss = 0.6956609487533569, train/logprobs = tensor([[-1.9434, -2.0522],
        [-1.9555, -1.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000919294252526015
Epoch 0, Step 4631: train/loss = 0.7073643207550049, train/raw-loss = 0.7062230110168457, train/logprobs = tensor([[-2.0177, -2.2202],
        [-2.0071, -2.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001141332439146936
Epoch 0, Step 4639: train/loss = 0.6942112445831299, train/raw-loss = 0.690272331237793, train/logprobs = tensor([[-2.0366, -2.1877],
        [-2.0011, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003938867710530758
Epoch 0, Step 4647: train/loss = 0.6931800842285156, train/raw-loss = 0.6919971704483032, train/logprobs = tensor([[-2.0010, -2.1294],
        [-2.0642, -1.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011829083086922765
Epoch 0, Step 4655: train/loss = 0.7075976133346558, train/raw-loss = 0.7064080834388733, train/logprobs = tensor([[-2.0430, -1.9530],
        [-2.0545, -1.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001189510803669691
Epoch 0, Step 4663: train/loss = 0.6910595893859863, train/raw-loss = 0.6889541745185852, train/logprobs = tensor([[-2.0582, -2.2745],
        [-2.1061, -1.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002105366438627243
Epoch 0, Step 4671: train/loss = 0.6939325332641602, train/raw-loss = 0.6931970715522766, train/logprobs = tensor([[-1.9895, -2.0194],
        [-1.8931, -1.7796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007354483241215348
Epoch 0, Step 4679: train/loss = 0.6980146169662476, train/raw-loss = 0.6975676417350769, train/logprobs = tensor([[-2.0239, -2.0703],
        [-1.8962, -1.8967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044699141290038824
Epoch 0, Step 4687: train/loss = 0.6926506161689758, train/raw-loss = 0.6913528442382812, train/logprobs = tensor([[-1.9591, -2.0267],
        [-1.9430, -1.7687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001297826413065195
Epoch 0, Step 4695: train/loss = 0.693787693977356, train/raw-loss = 0.6936437487602234, train/logprobs = tensor([[-2.1117, -2.1539],
        [-1.9453, -1.9545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014388840645551682
Epoch 0, Step 4703: train/loss = 0.7036451697349548, train/raw-loss = 0.7033334970474243, train/logprobs = tensor([[-2.0400, -1.9440],
        [-1.9771, -1.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003116709413006902
Epoch 0, Step 4711: train/loss = 0.6960487961769104, train/raw-loss = 0.6951850652694702, train/logprobs = tensor([[-2.0610, -2.0233],
        [-2.1265, -1.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008637262508273125
Epoch 0, Step 4719: train/loss = 0.6933830976486206, train/raw-loss = 0.6915557980537415, train/logprobs = tensor([[-2.0046, -2.1072],
        [-2.0308, -1.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018273302121087909
Epoch 0, Step 4727: train/loss = 0.6950781941413879, train/raw-loss = 0.6945658326148987, train/logprobs = tensor([[-1.9884, -2.0961],
        [-1.9703, -2.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005123433074913919
Epoch 0, Step 4735: train/loss = 0.6966282725334167, train/raw-loss = 0.6961804032325745, train/logprobs = tensor([[-1.9628, -2.0558],
        [-1.9708, -1.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004478927294258028
Epoch 0, Step 4743: train/loss = 0.6933760643005371, train/raw-loss = 0.692470371723175, train/logprobs = tensor([[-1.9817, -2.0897],
        [-2.0047, -1.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009057083516381681
Epoch 0, Step 4749: train/loss = 0.7045378088951111, train/raw-loss = 0.7014687061309814, train/logprobs = tensor([[-2.0642, -2.1821],
        [-2.0719, -2.0815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030690813437104225
eval/loss: 0.6952766180038452
