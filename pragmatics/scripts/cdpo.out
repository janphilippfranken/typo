clearing gpu cache for all ranks
Model with 7241.732096M params prepared
Loaded model on rank 1
Loaded model on rank 2
Loaded model on rank 3
Loaded model on rank 0
Epoch 0, Step 0: loss/train = -0.018768250942230225, logprobs/train = tensor([[-90.5507, -69.7900],
        [-90.3590, -69.2981]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 1: loss/train = 0.04224139451980591, logprobs/train = tensor([[-25.0743, -96.2440],
        [-25.0621, -96.9076]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 2: loss/train = 0.012441754341125488, logprobs/train = tensor([[-75.0126, -84.7695],
        [-75.3108, -85.2668]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 3: loss/train = -0.006741046905517578, logprobs/train = tensor([[-90.7068, -66.8157],
        [-90.6574, -66.6584]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 4: loss/train = 0.034274905920028687, logprobs/train = tensor([[-58.7380, -62.2325],
        [-58.7807, -62.8236]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 5: loss/train = 0.001741945743560791, logprobs/train = tensor([[-38.4726, -31.8115],
        [-38.3447, -31.7115]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 6: loss/train = -0.03308004140853882, logprobs/train = tensor([[-82.0311, -67.8123],
        [-82.1237, -67.3757]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 7: loss/train = -0.010979920625686646, logprobs/train = tensor([[-103.7559,  -63.5897],
        [-103.7156,  -63.3737]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 8: loss/train = 0.011735379695892334, logprobs/train = tensor([[-175.8773, -120.2230],
        [-175.4082, -119.9416]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 9: loss/train = -0.009754955768585205, logprobs/train = tensor([[-22.3739, -74.5758],
        [-22.5167, -74.5625]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 10: loss/train = -0.06676232814788818, logprobs/train = tensor([[-102.9914, -212.5392],
        [-103.7203, -212.2000]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 11: loss/train = -0.009312927722930908, logprobs/train = tensor([[-106.5040, -118.4723],
        [-106.2816, -118.1009]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 12: loss/train = 0.008415699005126953, logprobs/train = tensor([[ -91.6294, -112.1868],
        [ -91.4122, -112.1042]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 13: loss/train = -0.0018126964569091797, logprobs/train = tensor([[-36.4959, -70.8759],
        [-36.6134, -70.9644]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 14: loss/train = 0.007609307765960693, logprobs/train = tensor([[-42.6805, -87.0880],
        [-42.4474, -86.9766]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 15: loss/train = -0.0588439404964447, logprobs/train = tensor([[-132.3787, -257.1094],
        [-132.5634, -256.3525]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 16: loss/train = -0.01223483681678772, logprobs/train = tensor([[-92.9995, -53.6604],
        [-93.2160, -53.6811]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 17: loss/train = 0.029985010623931885, logprobs/train = tensor([[-90.7210, -79.5454],
        [-90.4207, -79.7250]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 18: loss/train = -0.013227760791778564, logprobs/train = tensor([[-89.7657, -41.5109],
        [-89.9170, -41.4506]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 19: loss/train = -0.003794074058532715, logprobs/train = tensor([[-123.6043,  -67.9502],
        [-123.4472,  -67.7324]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 20: loss/train = -0.012357950210571289, logprobs/train = tensor([[ -45.4681, -126.4850],
        [ -45.3463, -126.1655]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 21: loss/train = 0.015483617782592773, logprobs/train = tensor([[-57.3786, -80.2027],
        [-57.2553, -80.3271]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 22: loss/train = -0.01833498477935791, logprobs/train = tensor([[-107.9947, -175.0125],
        [-108.0984, -174.8228]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 23: loss/train = -0.019741296768188477, logprobs/train = tensor([[-142.7301, -106.0028],
        [-143.0829, -106.0397]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 24: loss/train = 0.025585412979125977, logprobs/train = tensor([[-121.5755, -104.9821],
        [-121.4498, -105.2658]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 25: loss/train = -0.03363668918609619, logprobs/train = tensor([[ -44.2439, -192.4968],
        [ -44.2748, -191.9895]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 26: loss/train = 0.0034447908401489258, logprobs/train = tensor([[-54.1281, -59.6494],
        [-54.1165, -59.6929]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 27: loss/train = -0.03243660926818848, logprobs/train = tensor([[-111.6484, -131.1602],
        [-111.7933, -130.7861]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 28: loss/train = 0.0024322867393493652, logprobs/train = tensor([[-142.8554, -102.5681],
        [-142.6575, -102.4091]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 29: loss/train = -0.017269223928451538, logprobs/train = tensor([[-77.1400, -36.9053],
        [-77.6509, -37.1399]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 30: loss/train = 0.005735605955123901, logprobs/train = tensor([[-72.7174, -47.5563],
        [-72.5868, -47.5175]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 31: loss/train = -0.0365789532661438, logprobs/train = tensor([[-102.7199,  -91.7711],
        [-102.8622,  -91.3282]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 32: loss/train = -0.012240171432495117, logprobs/train = tensor([[ -67.7909, -119.0436],
        [ -67.9186, -118.9755]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 33: loss/train = -0.01268652081489563, logprobs/train = tensor([[-114.9458,  -96.4034],
        [-114.9647,  -96.2193]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 34: loss/train = -0.00672188401222229, logprobs/train = tensor([[-132.7802, -111.2201],
        [-132.6665, -110.9989]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 35: loss/train = 0.012302756309509277, logprobs/train = tensor([[-125.6054, -165.8243],
        [-125.5417, -165.9574]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 36: loss/train = 0.0060127973556518555, logprobs/train = tensor([[-43.0404, -82.0710],
        [-42.8801, -82.0069]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 37: loss/train = 0.00942501425743103, logprobs/train = tensor([[-106.5117, -114.7573],
        [-106.3471, -114.7435]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 38: loss/train = -0.020016014575958252, logprobs/train = tensor([[-136.1581,  -53.2679],
        [-136.2505,  -53.0401]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 39: loss/train = 0.02648952603340149, logprobs/train = tensor([[ -88.6041, -110.1439],
        [ -88.4621, -110.4258]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 40: loss/train = 4.190206527709961e-05, logprobs/train = tensor([[ -76.3393, -118.0000],
        [ -76.1518, -117.8131]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 41: loss/train = 0.005598247051239014, logprobs/train = tensor([[ -91.9779, -105.4200],
        [ -92.1644, -105.6961]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 42: loss/train = -0.008484065532684326, logprobs/train = tensor([[-86.2054, -53.5463],
        [-86.3618, -53.5669]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 43: loss/train = 0.0059490203857421875, logprobs/train = tensor([[-111.4247, -100.5319],
        [-111.2975, -100.4999]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 44: loss/train = -0.011779069900512695, logprobs/train = tensor([[-165.1915, -114.9278],
        [-165.4631, -115.0109]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 45: loss/train = -0.01960521936416626, logprobs/train = tensor([[-60.6686, -63.8013],
        [-60.6954, -63.5144]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 46: loss/train = 0.02285340428352356, logprobs/train = tensor([[-50.1140, -61.8727],
        [-50.1276, -62.2519]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 47: loss/train = 0.025468409061431885, logprobs/train = tensor([[-118.9567,  -82.7586],
        [-119.1363,  -83.3457]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 48: loss/train = 0.027108073234558105, logprobs/train = tensor([[-84.8642, -91.7378],
        [-84.9872, -92.2946]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 49: loss/train = 0.007197946310043335, logprobs/train = tensor([[-92.8277, -42.5199],
        [-92.9413, -42.7486]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 50: loss/train = 0.02242875099182129, logprobs/train = tensor([[-166.1434, -191.7303],
        [-166.2818, -192.2275]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 51: loss/train = 0.010879844427108765, logprobs/train = tensor([[ -71.3344, -118.4730],
        [ -71.6085, -118.9212]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 52: loss/train = 0.004291534423828125, logprobs/train = tensor([[-50.9223, -38.6759],
        [-50.9579, -38.7803]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 53: loss/train = 0.012296438217163086, logprobs/train = tensor([[-39.8138, -44.0009],
        [-39.6639, -44.0477]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 54: loss/train = -0.021036863327026367, logprobs/train = tensor([[ -87.6139, -137.7616],
        [ -87.9860, -137.7971]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 55: loss/train = 0.009000033140182495, logprobs/train = tensor([[-50.1132, -37.8327],
        [-50.1442, -38.0077]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 56: loss/train = -0.007340788841247559, logprobs/train = tensor([[ -55.5929, -127.3207],
        [ -55.4610, -127.0714]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 57: loss/train = -0.012423157691955566, logprobs/train = tensor([[ -76.6885, -192.5152],
        [ -76.6325, -192.2604]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 58: loss/train = 0.017032653093338013, logprobs/train = tensor([[-186.8119, -110.7289],
        [-186.7926, -110.9821]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 59: loss/train = 0.014660477638244629, logprobs/train = tensor([[-50.8434, -64.0685],
        [-50.6676, -64.1273]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 60: loss/train = -0.0035879015922546387, logprobs/train = tensor([[-44.4873, -72.8742],
        [-44.6502, -72.9797]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 61: loss/train = -0.019511520862579346, logprobs/train = tensor([[-71.9739, -68.8442],
        [-72.5033, -69.0614]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 62: loss/train = 0.01643514633178711, logprobs/train = tensor([[-28.7337, -60.0426],
        [-28.6358, -60.2076]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 63: loss/train = 0.01762336492538452, logprobs/train = tensor([[-102.0399,  -96.0622],
        [-101.9128,  -96.2170]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 64: loss/train = 0.012489527463912964, logprobs/train = tensor([[-35.6156, -64.8536],
        [-35.3917, -64.8295]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 65: loss/train = 0.027837634086608887, logprobs/train = tensor([[ -75.6692, -100.4746],
        [ -75.5657, -100.8164]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 66: loss/train = 0.00229722261428833, logprobs/train = tensor([[ -85.2689, -153.6303],
        [ -85.2255, -153.6236]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 67: loss/train = 0.009650707244873047, logprobs/train = tensor([[ -67.1230, -105.6700],
        [ -67.1708, -105.8722]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 68: loss/train = -0.030262351036071777, logprobs/train = tensor([[-157.2964, -140.6995],
        [-157.8514, -140.7703]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 69: loss/train = 0.018664777278900146, logprobs/train = tensor([[ -30.6118, -297.1335],
        [ -30.6507, -297.4711]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 70: loss/train = 0.01820385456085205, logprobs/train = tensor([[ -85.9585, -114.0041],
        [ -85.8041, -114.1410]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 71: loss/train = -0.020837053656578064, logprobs/train = tensor([[-58.3291, -95.1389],
        [-58.6066, -95.0830]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 72: loss/train = -0.0007608532905578613, logprobs/train = tensor([[-173.4133, -150.9243],
        [-173.4907, -150.9895]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 73: loss/train = 0.03229320049285889, logprobs/train = tensor([[-197.3773,  -68.9253],
        [-197.2188,  -69.2835]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 74: loss/train = -0.009516000747680664, logprobs/train = tensor([[-136.5857,  -94.8957],
        [-137.3353,  -95.4930]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 75: loss/train = -0.04939621686935425, logprobs/train = tensor([[-51.5685, -69.9404],
        [-51.8961, -69.4776]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 76: loss/train = -0.009871244430541992, logprobs/train = tensor([[ -69.8551, -192.0492],
        [ -70.0818, -192.1179]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 77: loss/train = -0.005280554294586182, logprobs/train = tensor([[ -90.2843, -109.4799],
        [ -90.2587, -109.3698]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 78: loss/train = 0.010720670223236084, logprobs/train = tensor([[ -97.9016, -145.2971],
        [ -97.6631, -145.2302]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 79: loss/train = 0.03268599510192871, logprobs/train = tensor([[-67.6476, -79.1739],
        [-67.3703, -79.4196]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 80: loss/train = -0.0031886696815490723, logprobs/train = tensor([[ -74.4881, -122.3467],
        [ -74.4156, -122.2232]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 81: loss/train = 0.03280669450759888, logprobs/train = tensor([[ -61.8404, -126.5920],
        [ -62.0014, -127.2779]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 82: loss/train = -0.006374180316925049, logprobs/train = tensor([[-34.3639, -74.6304],
        [-34.2638, -74.4283]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 83: loss/train = 0.01046133041381836, logprobs/train = tensor([[ -56.4849, -118.3850],
        [ -56.4880, -118.5555]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 84: loss/train = -0.002801835536956787, logprobs/train = tensor([[-58.6480, -59.5584],
        [-58.3560, -59.2216]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 85: loss/train = 0.011946558952331543, logprobs/train = tensor([[-106.0085,  -73.5688],
        [-105.9075,  -73.6590]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 86: loss/train = 0.00814276933670044, logprobs/train = tensor([[-64.2471, -53.9802],
        [-64.0255, -53.8889]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 87: loss/train = 0.014130562543869019, logprobs/train = tensor([[-39.1913, -68.5356],
        [-39.0217, -68.5920]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 88: loss/train = 0.005082130432128906, logprobs/train = tensor([[-55.1295, -96.6228],
        [-54.9805, -96.5550]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 89: loss/train = 0.008490681648254395, logprobs/train = tensor([[-74.1104, -92.0654],
        [-74.0445, -92.1353]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 90: loss/train = 0.01125943660736084, logprobs/train = tensor([[-159.6107, -101.0742],
        [-159.5647, -101.2084]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 91: loss/train = -0.0029071569442749023, logprobs/train = tensor([[-136.3204, -153.2285],
        [-136.1687, -153.0303]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 92: loss/train = 0.01660865545272827, logprobs/train = tensor([[-126.0607,  -72.4110],
        [-125.8024,  -72.4184]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 93: loss/train = 0.03946167230606079, logprobs/train = tensor([[ -53.9862, -102.8216],
        [ -54.0867, -103.5536]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 94: loss/train = 0.00601591169834137, logprobs/train = tensor([[-32.5045, -43.4515],
        [-32.3781, -43.4214]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 95: loss/train = -0.03856998682022095, logprobs/train = tensor([[ -38.6985, -113.6823],
        [ -38.7901, -113.1567]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 96: loss/train = -0.002787172794342041, logprobs/train = tensor([[-67.4674, -49.5998],
        [-67.1536, -49.2413]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 97: loss/train = -0.0032296180725097656, logprobs/train = tensor([[-62.0764, -88.6238],
        [-61.9304, -88.4261]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 98: loss/train = -0.00745159387588501, logprobs/train = tensor([[-91.7962, -90.8854],
        [-91.7422, -90.7122]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 99: loss/train = -0.0033492445945739746, logprobs/train = tensor([[ -94.8410, -146.4732],
        [ -94.8609, -146.4395]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 100: loss/train = -0.007679939270019531, logprobs/train = tensor([[ -60.3522, -158.4317],
        [ -60.5935, -158.5502]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 101: loss/train = 0.009793341159820557, logprobs/train = tensor([[-39.4808, -56.6661],
        [-39.2795, -56.6216]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 102: loss/train = -0.0001894831657409668, logprobs/train = tensor([[-79.3108, -73.8683],
        [-79.0901, -73.6447]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 103: loss/train = 0.00016486644744873047, logprobs/train = tensor([[-123.2628, -114.8993],
        [-123.1764, -114.8155]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 104: loss/train = 0.029807478189468384, logprobs/train = tensor([[-63.5205, -64.7485],
        [-63.2087, -64.9137]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 105: loss/train = -0.017786219716072083, logprobs/train = tensor([[-60.0774, -59.4159],
        [-60.4435, -59.4974]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 106: loss/train = -0.004091918468475342, logprobs/train = tensor([[-55.2613, -45.8886],
        [-55.2715, -45.8333]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 107: loss/train = -0.030917763710021973, logprobs/train = tensor([[-158.7605, -169.5545],
        [-158.8489, -169.1483]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 108: loss/train = 0.029442906379699707, logprobs/train = tensor([[-108.2817,  -75.2123],
        [-108.0809,  -75.4826]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 109: loss/train = 0.02887815237045288, logprobs/train = tensor([[-67.7574, -91.7354],
        [-67.6020, -92.0421]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 110: loss/train = 0.01911228895187378, logprobs/train = tensor([[-38.4635, -72.4420],
        [-38.3900, -72.6743]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 111: loss/train = -0.00549769401550293, logprobs/train = tensor([[-69.3568, -80.6362],
        [-69.3000, -80.4913]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 112: loss/train = 0.0012662410736083984, logprobs/train = tensor([[-144.0495,  -75.1194],
        [-144.3548,  -75.4449]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 113: loss/train = -0.022491455078125, logprobs/train = tensor([[ -91.1900, -190.5630],
        [ -91.2042, -190.2174]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 114: loss/train = -0.01510348916053772, logprobs/train = tensor([[-127.2574, -125.3977],
        [-127.2066, -125.1052]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 115: loss/train = -0.015520155429840088, logprobs/train = tensor([[-67.7142, -54.9791],
        [-68.0614, -55.0780]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 116: loss/train = -0.03572326898574829, logprobs/train = tensor([[ -89.0218, -179.0749],
        [ -89.4540, -178.9355]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 117: loss/train = -0.014643728733062744, logprobs/train = tensor([[-144.2238, -155.6615],
        [-144.2508, -155.4542]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 118: loss/train = 0.010793328285217285, logprobs/train = tensor([[-87.7740, -66.1727],
        [-87.7158, -66.2872]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 119: loss/train = -0.015326470136642456, logprobs/train = tensor([[-170.3861,  -35.8301],
        [-170.6292,  -35.8279]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 120: loss/train = -0.00011339783668518066, logprobs/train = tensor([[-31.9473, -71.1929],
        [-32.0275, -71.2713]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 121: loss/train = 0.012254595756530762, logprobs/train = tensor([[-59.7917, -82.5967],
        [-59.9526, -82.9536]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 122: loss/train = -0.001449286937713623, logprobs/train = tensor([[-59.3984, -86.7696],
        [-59.1542, -86.5022]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 123: loss/train = 0.030881047248840332, logprobs/train = tensor([[-134.8660, -204.8297],
        [-134.7756, -205.2335]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 124: loss/train = 0.006783187389373779, logprobs/train = tensor([[ -74.1425, -133.8916],
        [ -74.1539, -134.0115]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 125: loss/train = -0.01255074143409729, logprobs/train = tensor([[-64.2571, -56.2009],
        [-64.4352, -56.1781]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 126: loss/train = -0.0020228326320648193, logprobs/train = tensor([[-90.1624, -61.6623],
        [-90.5093, -61.9769]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 127: loss/train = 0.006464481353759766, logprobs/train = tensor([[-59.1174, -33.5809],
        [-58.8424, -33.4094]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 128: loss/train = -0.007668673992156982, logprobs/train = tensor([[-53.4155, -95.8344],
        [-53.5663, -95.8624]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 129: loss/train = -0.0231657475233078, logprobs/train = tensor([[-43.1353, -38.6948],
        [-43.2903, -38.4792]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 130: loss/train = 0.040644288063049316, logprobs/train = tensor([[-146.8326,  -73.4221],
        [-146.3259,  -73.5657]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 131: loss/train = 0.019282132387161255, logprobs/train = tensor([[ -90.4095, -106.3790],
        [ -90.3954, -106.6735]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 132: loss/train = 0.016025453805923462, logprobs/train = tensor([[ -80.5719, -127.1628],
        [ -80.3520, -127.1992]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 133: loss/train = 0.03086721897125244, logprobs/train = tensor([[-117.1280, -171.8114],
        [-117.0408, -172.2181]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 134: loss/train = 0.034185707569122314, logprobs/train = tensor([[ -84.1339, -122.2366],
        [ -83.7097, -122.3594]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 135: loss/train = -0.020515739917755127, logprobs/train = tensor([[-114.7613, -122.0290],
        [-114.8016, -121.7411]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 136: loss/train = -0.02514830231666565, logprobs/train = tensor([[-44.5984, -67.6298],
        [-44.7923, -67.4213]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 137: loss/train = -0.01248091459274292, logprobs/train = tensor([[-51.7455, -89.7137],
        [-52.0485, -89.8170]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 138: loss/train = -0.025087714195251465, logprobs/train = tensor([[ -59.9014, -105.1571],
        [ -60.1962, -105.0505]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 139: loss/train = 0.021122455596923828, logprobs/train = tensor([[-105.8412,  -98.3636],
        [-105.7529,  -98.6133]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 140: loss/train = -0.001650094985961914, logprobs/train = tensor([[-73.3624, -94.9084],
        [-73.3113, -94.8309]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 141: loss/train = 0.011155247688293457, logprobs/train = tensor([[ -31.5546, -113.5275],
        [ -31.2796, -113.4309]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 142: loss/train = -0.001758873462677002, logprobs/train = tensor([[-45.1431, -46.4023],
        [-45.1312, -46.3623]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 143: loss/train = 0.01929759979248047, logprobs/train = tensor([[-97.4696, -55.2484],
        [-97.3662, -55.4538]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 144: loss/train = -0.044737666845321655, logprobs/train = tensor([[-93.5689, -50.6610],
        [-94.1777, -50.5539]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 145: loss/train = 0.006578713655471802, logprobs/train = tensor([[-43.2215, -92.9853],
        [-43.0209, -92.8899]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 146: loss/train = 0.006312847137451172, logprobs/train = tensor([[ -75.4883, -189.5345],
        [ -75.4977, -189.6449]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 147: loss/train = -0.014305293560028076, logprobs/train = tensor([[-107.0507,  -59.5542],
        [-106.9825,  -59.2571]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 148: loss/train = -0.02267354726791382, logprobs/train = tensor([[ -72.9434, -105.9668],
        [ -73.3706, -106.0312]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 149: loss/train = -0.004644811153411865, logprobs/train = tensor([[-88.9356, -50.2898],
        [-89.0501, -50.3299]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 150: loss/train = 0.005905032157897949, logprobs/train = tensor([[-44.1919, -48.3750],
        [-44.1752, -48.4528]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 151: loss/train = -0.003451615571975708, logprobs/train = tensor([[-59.3722, -68.9726],
        [-59.2585, -68.8037]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 152: loss/train = 0.015739798545837402, logprobs/train = tensor([[-78.0392, -98.4484],
        [-77.8250, -98.4860]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 153: loss/train = -0.004168033599853516, logprobs/train = tensor([[-134.4386, -204.9654],
        [-134.0261, -204.4862]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 154: loss/train = -0.017979025840759277, logprobs/train = tensor([[-77.9788, -63.7330],
        [-78.1763, -63.6428]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 155: loss/train = 0.04269722104072571, logprobs/train = tensor([[-34.0101, -91.0003],
        [-33.8134, -91.4867]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 156: loss/train = -0.005441427230834961, logprobs/train = tensor([[-107.3183,  -69.1660],
        [-107.6226,  -69.3832]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 157: loss/train = 0.0036739706993103027, logprobs/train = tensor([[-116.5111, -124.4604],
        [-116.5588, -124.5669]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 158: loss/train = 0.026110857725143433, logprobs/train = tensor([[ -94.4248, -103.2736],
        [ -94.4957, -103.7623]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 159: loss/train = -0.012326747179031372, logprobs/train = tensor([[ -44.1834, -134.9060],
        [ -44.1995, -134.7249]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 160: loss/train = -0.021874189376831055, logprobs/train = tensor([[ -79.6282, -243.8349],
        [ -79.8791, -243.7358]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 161: loss/train = -0.011499524116516113, logprobs/train = tensor([[-118.7362,  -88.4268],
        [-118.7193,  -88.2258]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 162: loss/train = 0.01015976071357727, logprobs/train = tensor([[-134.0560, -133.3685],
        [-133.9084, -133.3835]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 163: loss/train = -0.008451461791992188, logprobs/train = tensor([[ -94.5914, -118.1994],
        [ -94.6443, -118.1171]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 164: loss/train = 0.039550960063934326, logprobs/train = tensor([[ -53.4915, -117.2932],
        [ -53.5358, -117.9703]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 165: loss/train = 0.015609502792358398, logprobs/train = tensor([[-74.7990, -40.1622],
        [-75.1232, -40.7361]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 166: loss/train = -0.027086585760116577, logprobs/train = tensor([[-55.9334, -57.0856],
        [-56.1103, -56.8291]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 167: loss/train = 0.0038982629776000977, logprobs/train = tensor([[-66.3396, -58.6904],
        [-66.1821, -58.5953]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 168: loss/train = -0.013004183769226074, logprobs/train = tensor([[-61.0087, -50.9746],
        [-60.9528, -50.7106]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 169: loss/train = -0.00795513391494751, logprobs/train = tensor([[-113.3710,  -75.5157],
        [-113.3917,  -75.4091]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 170: loss/train = 0.004393815994262695, logprobs/train = tensor([[-123.0449, -116.8839],
        [-122.9357, -116.8450]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 171: loss/train = -0.017349988222122192, logprobs/train = tensor([[-145.0373, -107.3565],
        [-145.4294, -107.4710]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 172: loss/train = -0.017706990242004395, logprobs/train = tensor([[-47.4858, -81.5276],
        [-47.5628, -81.3212]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 173: loss/train = -0.004922449588775635, logprobs/train = tensor([[-161.6408,  -70.5114],
        [-162.0604,  -70.8523]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 174: loss/train = -0.02232588827610016, logprobs/train = tensor([[ -77.4855, -134.9771],
        [ -77.8083, -134.9427]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 175: loss/train = 0.01865553855895996, logprobs/train = tensor([[-138.0167, -186.3772],
        [-137.8937, -186.5527]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 176: loss/train = -0.006611913442611694, logprobs/train = tensor([[ -65.6742, -139.3225],
        [ -65.6704, -139.2129]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 177: loss/train = 0.034272074699401855, logprobs/train = tensor([[-59.4925, -67.8488],
        [-59.3348, -68.2395]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 178: loss/train = 0.016356945037841797, logprobs/train = tensor([[ -44.3203, -127.6447],
        [ -44.4046, -127.9908]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 179: loss/train = 0.014340698719024658, logprobs/train = tensor([[ -80.7699, -101.6837],
        [ -80.8849, -102.0281]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 180: loss/train = 0.00973963737487793, logprobs/train = tensor([[-123.7836, -219.6335],
        [-123.6690, -219.6748]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 181: loss/train = -0.027272164821624756, logprobs/train = tensor([[-47.4391, -94.0190],
        [-47.5891, -93.7325]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 182: loss/train = -0.004602015018463135, logprobs/train = tensor([[-106.4538,  -94.6627],
        [-106.8157,  -94.9510]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 183: loss/train = -0.015960916876792908, logprobs/train = tensor([[-66.5023, -81.8715],
        [-66.7055, -81.8194]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 184: loss/train = -0.009148567914962769, logprobs/train = tensor([[-39.3525, -64.3747],
        [-39.4068, -64.2826]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 185: loss/train = -0.012655436992645264, logprobs/train = tensor([[-129.1629,  -94.2419],
        [-129.2861,  -94.1626]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 186: loss/train = -0.002576768398284912, logprobs/train = tensor([[-101.9992,  -58.7337],
        [-101.9399,  -58.6331]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 187: loss/train = -0.01518946886062622, logprobs/train = tensor([[-49.3281, -74.4192],
        [-49.5303, -74.3783]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 188: loss/train = -0.015574336051940918, logprobs/train = tensor([[ -77.1721, -132.2109],
        [ -77.4710, -132.2605]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 189: loss/train = 0.02433416247367859, logprobs/train = tensor([[-47.1730, -71.7688],
        [-47.0107, -71.9959]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 190: loss/train = -0.0028960704803466797, logprobs/train = tensor([[-103.0048, -128.5432],
        [-103.2911, -128.7832]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 191: loss/train = 0.0008297860622406006, logprobs/train = tensor([[-49.3893, -81.8607],
        [-49.2627, -81.7475]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 192: loss/train = 0.009879231452941895, logprobs/train = tensor([[-71.1930, -54.4733],
        [-71.2521, -54.6905]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 193: loss/train = -0.016985416412353516, logprobs/train = tensor([[ -47.0670, -116.5198],
        [ -47.3010, -116.4820]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 194: loss/train = -0.05137231945991516, logprobs/train = tensor([[-120.2544,  -61.7040],
        [-120.8969,  -61.5245]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 195: loss/train = 0.015282288193702698, logprobs/train = tensor([[-41.6171, -61.7280],
        [-41.4517, -61.8071]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 196: loss/train = 0.024287402629852295, logprobs/train = tensor([[ -96.4687, -112.2829],
        [ -96.0488, -112.2516]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 197: loss/train = 0.008466124534606934, logprobs/train = tensor([[-178.5676, -167.9665],
        [-178.3925, -167.9269]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 198: loss/train = -0.024278387427330017, logprobs/train = tensor([[-36.2428, -61.8813],
        [-36.4008, -61.6508]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 199: loss/train = 0.0037602782249450684, logprobs/train = tensor([[ -94.8319, -113.2591],
        [ -94.8931, -113.3804]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 200: loss/train = 0.022518709301948547, logprobs/train = tensor([[-61.5269, -94.0303],
        [-60.7432, -93.6070]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 201: loss/train = -0.01591968536376953, logprobs/train = tensor([[-98.2295, -89.3023],
        [-98.5211, -89.3391]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 202: loss/train = 0.00940731167793274, logprobs/train = tensor([[-82.4062, -56.7810],
        [-82.3077, -56.8330]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 203: loss/train = 0.0069103240966796875, logprobs/train = tensor([[-100.4499,  -88.1217],
        [-100.0538,  -87.8362]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 204: loss/train = 0.0003208070993423462, logprobs/train = tensor([[ -41.8878, -190.1689],
        [ -42.1329, -190.4191]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 205: loss/train = -0.01076914370059967, logprobs/train = tensor([[-22.0207, -34.4684],
        [-21.9328, -34.2082]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 206: loss/train = -0.03674042224884033, logprobs/train = tensor([[-192.6217, -103.9778],
        [-193.1501, -103.9184]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 207: loss/train = -0.01353764533996582, logprobs/train = tensor([[-42.1394, -74.6697],
        [-42.1258, -74.4394]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 208: loss/train = -0.0017338097095489502, logprobs/train = tensor([[-72.9085, -63.3701],
        [-72.8368, -63.2706]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 209: loss/train = -0.008706748485565186, logprobs/train = tensor([[-74.2384, -56.2022],
        [-74.5107, -56.3352]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 210: loss/train = 0.0006907284259796143, logprobs/train = tensor([[-63.7342, -86.4775],
        [-64.2808, -87.0351]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 211: loss/train = -0.011276423931121826, logprobs/train = tensor([[-44.5140, -51.2122],
        [-44.2560, -50.7738]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 212: loss/train = 0.027330338954925537, logprobs/train = tensor([[-172.1644, -194.2010],
        [-172.1670, -194.6409]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 213: loss/train = -0.008459806442260742, logprobs/train = tensor([[-90.7326, -66.6265],
        [-90.6116, -66.3701]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 214: loss/train = -0.04751455783843994, logprobs/train = tensor([[-96.2406, -77.0478],
        [-96.4144, -76.4614]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 215: loss/train = 0.016413390636444092, logprobs/train = tensor([[-155.8959, -160.7892],
        [-155.9097, -161.0656]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 216: loss/train = 0.0027767717838287354, logprobs/train = tensor([[ -70.1772, -124.1310],
        [ -70.2677, -124.2659]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 217: loss/train = -0.016609877347946167, logprobs/train = tensor([[-57.5435, -63.8348],
        [-57.7427, -63.7683]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 218: loss/train = 0.0057621002197265625, logprobs/train = tensor([[-62.8291, -43.7409],
        [-62.6211, -43.6251]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 219: loss/train = 0.012725293636322021, logprobs/train = tensor([[ -49.2416, -153.0719],
        [ -49.1140, -153.1479]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 220: loss/train = -0.006411164999008179, logprobs/train = tensor([[-32.8892, -38.6792],
        [-32.8247, -38.5121]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 221: loss/train = -0.022347867488861084, logprobs/train = tensor([[-85.5927, -96.4802],
        [-86.4374, -96.9674]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 222: loss/train = -0.013192534446716309, logprobs/train = tensor([[-51.9810, -56.7266],
        [-52.2679, -56.8025]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 223: loss/train = 0.022268444299697876, logprobs/train = tensor([[-63.8325, -73.1570],
        [-63.5751, -73.2558]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 224: loss/train = 0.004282623529434204, logprobs/train = tensor([[-93.3920, -36.9327],
        [-93.1029, -36.7121]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 225: loss/train = 0.006304562091827393, logprobs/train = tensor([[-54.1575, -83.2806],
        [-54.0886, -83.3126]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 226: loss/train = -0.02400529384613037, logprobs/train = tensor([[ -96.2360, -123.9313],
        [ -96.4600, -123.7712]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 227: loss/train = -0.005470991134643555, logprobs/train = tensor([[-53.4977, -70.8835],
        [-53.4546, -70.7528]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 228: loss/train = -0.010421931743621826, logprobs/train = tensor([[ -86.7759, -172.1771],
        [ -86.7399, -171.9743]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 229: loss/train = -0.017524421215057373, logprobs/train = tensor([[ -95.5095, -107.3079],
        [ -95.6675, -107.1856]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 230: loss/train = 0.02764737606048584, logprobs/train = tensor([[ -64.5151, -115.0029],
        [ -64.4193, -115.3495]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 231: loss/train = 0.02978655695915222, logprobs/train = tensor([[-88.4633, -68.6713],
        [-88.0314, -68.7160]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 232: loss/train = 0.00510445237159729, logprobs/train = tensor([[-21.8683, -56.6853],
        [-21.9175, -56.8161]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 233: loss/train = -0.05638939142227173, logprobs/train = tensor([[-88.9379, -84.1359],
        [-89.4494, -83.7452]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 234: loss/train = -0.0070313215255737305, logprobs/train = tensor([[-57.1827, -79.8036],
        [-57.4267, -79.9352]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 235: loss/train = 0.0037810206413269043, logprobs/train = tensor([[-79.6981, -41.5563],
        [-79.9180, -41.8367]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 236: loss/train = -0.011340618133544922, logprobs/train = tensor([[-101.7796, -113.1128],
        [-101.6981, -112.8498]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 237: loss/train = 0.029771476984024048, logprobs/train = tensor([[ -65.0528, -133.9059],
        [ -64.8635, -134.1930]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 238: loss/train = -0.011547684669494629, logprobs/train = tensor([[-108.7883, -112.0484],
        [-108.7246, -111.8000]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 239: loss/train = -0.016247034072875977, logprobs/train = tensor([[ -42.5994, -125.9836],
        [ -42.7695, -125.8938]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 240: loss/train = 0.024137169122695923, logprobs/train = tensor([[ -89.5028, -154.0237],
        [ -89.1979, -154.1050]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 241: loss/train = 0.01590573787689209, logprobs/train = tensor([[-69.9225, -41.9774],
        [-69.5945, -41.9038]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 242: loss/train = 0.02534419298171997, logprobs/train = tensor([[ -63.8915, -101.4330],
        [ -63.8805, -101.8275]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 243: loss/train = -0.04561680555343628, logprobs/train = tensor([[-91.4788, -53.5342],
        [-92.0928, -53.4183]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 244: loss/train = 0.019098520278930664, logprobs/train = tensor([[ -88.8401, -238.8026],
        [ -88.9092, -239.1773]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 245: loss/train = 0.020527362823486328, logprobs/train = tensor([[-51.4895, -62.7469],
        [-51.4109, -62.9968]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 246: loss/train = 0.009487450122833252, logprobs/train = tensor([[-92.9497, -41.9848],
        [-92.7618, -41.9487]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 247: loss/train = 0.03212320804595947, logprobs/train = tensor([[ -61.5634, -104.0920],
        [ -61.3561, -104.3987]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 248: loss/train = 0.009866058826446533, logprobs/train = tensor([[-48.7408, -99.9554],
        [-48.5738, -99.9463]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 249: loss/train = -0.005587935447692871, logprobs/train = tensor([[-41.7645, -42.8262],
        [-41.7611, -42.7334]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 250: loss/train = -0.05619239807128906, logprobs/train = tensor([[-187.8867, -124.7872],
        [-188.3639, -124.3654]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 251: loss/train = -0.04849815368652344, logprobs/train = tensor([[-129.4047, -162.9934],
        [-129.5471, -162.3598]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 252: loss/train = 0.04511070251464844, logprobs/train = tensor([[ -37.7947, -156.9636],
        [ -37.3635, -157.2542]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 253: loss/train = -0.006282061338424683, logprobs/train = tensor([[-59.5735, -87.1599],
        [-59.5797, -87.0655]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 254: loss/train = -0.021094560623168945, logprobs/train = tensor([[-84.0434, -99.7145],
        [-83.8325, -99.1661]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 255: loss/train = -0.014377117156982422, logprobs/train = tensor([[ -74.7287, -104.2200],
        [ -74.6188, -103.8801]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 256: loss/train = 0.0013114213943481445, logprobs/train = tensor([[ -94.5959, -106.0505],
        [ -94.5676, -106.0432]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 257: loss/train = -0.016367793083190918, logprobs/train = tensor([[-111.6475,  -76.6614],
        [-111.7353,  -76.4873]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 258: loss/train = 0.0508652925491333, logprobs/train = tensor([[-109.2300, -170.3716],
        [-108.9845, -170.9400]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 259: loss/train = 0.007686257362365723, logprobs/train = tensor([[-55.2708, -87.5113],
        [-55.0639, -87.4274]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 260: loss/train = -0.025321364402770996, logprobs/train = tensor([[-82.8570, -89.9468],
        [-83.1254, -89.8100]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 261: loss/train = -0.017353296279907227, logprobs/train = tensor([[ -76.6048, -133.6694],
        [ -76.4077, -133.1947]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 262: loss/train = -0.012272238731384277, logprobs/train = tensor([[ -61.9004, -124.6709],
        [ -61.9237, -124.4978]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 263: loss/train = -0.010690569877624512, logprobs/train = tensor([[-123.5093, -130.3681],
        [-123.5056, -130.1934]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 264: loss/train = 0.006915152072906494, logprobs/train = tensor([[ -44.7624, -210.8637],
        [ -44.4529, -210.6648]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 265: loss/train = -0.00910872220993042, logprobs/train = tensor([[ -85.3599, -128.8590],
        [ -85.3486, -128.7020]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 266: loss/train = 0.026981711387634277, logprobs/train = tensor([[-74.5440, -84.7501],
        [-74.3137, -84.9515]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 267: loss/train = 0.007782638072967529, logprobs/train = tensor([[ -35.7500, -110.6233],
        [ -35.5395, -110.5373]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 268: loss/train = -0.008767396211624146, logprobs/train = tensor([[-45.9728, -56.2816],
        [-46.3362, -56.5047]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 269: loss/train = 0.02308163046836853, logprobs/train = tensor([[-43.3953, -74.8577],
        [-43.1421, -74.9738]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 270: loss/train = 0.02790379524230957, logprobs/train = tensor([[ -84.7741, -259.0750],
        [ -84.8137, -259.5611]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 271: loss/train = 0.0216282457113266, logprobs/train = tensor([[-105.1117,  -60.8392],
        [-104.8608,  -60.9344]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 272: loss/train = -0.02018749713897705, logprobs/train = tensor([[-51.9803, -56.8417],
        [-52.1455, -56.6839]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 273: loss/train = -0.020640432834625244, logprobs/train = tensor([[-82.2447, -42.7124],
        [-82.4929, -42.6303]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 274: loss/train = -0.011010408401489258, logprobs/train = tensor([[ -88.9809, -150.2452],
        [ -88.9309, -150.0190]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 275: loss/train = 0.027509987354278564, logprobs/train = tensor([[ -81.1768, -151.3420],
        [ -81.0257, -151.6311]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 276: loss/train = 0.01945433020591736, logprobs/train = tensor([[ -65.4583, -110.1942],
        [ -65.3141, -110.3611]], device='cuda:0', grad_fn=<DivBackward0>)
Epoch 0, Step 277: loss/train = -0.02056640386581421, logprobs/train = tensor([[-125.5630,  -98.1585],
        [-125.7452,  -98.0117]], device='cuda:0', grad_fn=<DivBackward0>)
