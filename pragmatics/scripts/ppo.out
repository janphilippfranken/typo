clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
Loaded model on rank 3
Loaded reference model on rank 3
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Loaded model on rank 1
Loaded reference model on rank 1
Loaded model on rank 2
Loaded reference model on rank 2
Epoch 0, Step 7: loss/train = 0.11027076840400696, logprobs/train = tensor([[-4.2364, -3.1636],
        [-4.2194, -2.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: loss/train = 0.09418319165706635, logprobs/train = tensor([[-2.9426, -2.4942],
        [-2.8479, -2.4072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: loss/train = 0.1060338169336319, logprobs/train = tensor([[-2.3348, -2.3768],
        [-2.3230, -2.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018168921815231442
Epoch 0, Step 31: loss/train = 0.21125656366348267, logprobs/train = tensor([[-4.5188, -2.3244],
        [-4.6771, -2.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021673028822988272
Epoch 0, Step 39: loss/train = 0.14640140533447266, logprobs/train = tensor([[-4.2036, -3.4437],
        [-4.2149, -3.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001187254092656076
Epoch 0, Step 47: loss/train = 0.09368166327476501, logprobs/train = tensor([[-1.8532, -2.1361],
        [-1.8340, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.101378287188709e-05
Epoch 0, Step 55: loss/train = 0.14576458930969238, logprobs/train = tensor([[-3.6454, -1.9124],
        [-3.7340, -1.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.087782847112976e-05
Epoch 0, Step 63: loss/train = 0.09101177752017975, logprobs/train = tensor([[-2.3160, -1.9832],
        [-2.1842, -1.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.786727605387568e-05
Epoch 0, Step 71: loss/train = 0.11833475530147552, logprobs/train = tensor([[-2.8411, -2.3868],
        [-2.8213, -2.1232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010776094859465957
Epoch 0, Step 79: loss/train = 0.1016373336315155, logprobs/train = tensor([[-2.6905, -2.2777],
        [-2.6385, -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022546375112142414
Epoch 0, Step 87: loss/train = 0.17876526713371277, logprobs/train = tensor([[-4.6010, -3.1274],
        [-4.7139, -3.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015230855206027627
Epoch 0, Step 95: loss/train = 0.108872190117836, logprobs/train = tensor([[-3.8013, -3.3568],
        [-3.7934, -3.3128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.659348870627582e-05
Epoch 0, Step 103: loss/train = 0.10913178324699402, logprobs/train = tensor([[-3.5991, -2.8149],
        [-3.6045, -2.7546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010141766688320786
Epoch 0, Step 111: loss/train = 0.09831390529870987, logprobs/train = tensor([[-2.5647, -2.0788],
        [-2.5124, -2.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2783326383214444e-05
Epoch 0, Step 119: loss/train = 0.09098270535469055, logprobs/train = tensor([[-2.3049, -2.5080],
        [-2.3149, -2.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010476688476046547
Epoch 0, Step 127: loss/train = 0.10504090785980225, logprobs/train = tensor([[-1.8644, -2.3572],
        [-1.9016, -2.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.155939915217459e-05
Epoch 0, Step 135: loss/train = 0.0871955156326294, logprobs/train = tensor([[-1.4857, -1.5891],
        [-1.4028, -1.4803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1253363229334354e-06
Epoch 0, Step 143: loss/train = 0.1219547912478447, logprobs/train = tensor([[-2.7023, -1.6933],
        [-3.7762, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002165318583138287
Epoch 0, Step 151: loss/train = 0.09382936358451843, logprobs/train = tensor([[-2.7281, -2.3608],
        [-2.8059, -2.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001083670649677515
Epoch 0, Step 159: loss/train = 0.0883507952094078, logprobs/train = tensor([[-1.6638, -1.9039],
        [-1.5808, -1.8213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.902485180646181e-05
Epoch 0, Step 167: loss/train = 0.10730355978012085, logprobs/train = tensor([[-4.0007, -3.4244],
        [-3.9885, -3.2417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029471778543666005
Epoch 0, Step 175: loss/train = 0.14354974031448364, logprobs/train = tensor([[-3.5393, -1.7121],
        [-3.5767, -1.4344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020960165420547128
Epoch 0, Step 183: loss/train = 0.09507696330547333, logprobs/train = tensor([[-2.8716, -3.2765],
        [-2.8210, -3.2933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012550517567433417
Epoch 0, Step 191: loss/train = 0.08735910803079605, logprobs/train = tensor([[-2.2729, -2.1173],
        [-2.2020, -2.0402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016384347691200674
Epoch 0, Step 199: loss/train = 0.0964265763759613, logprobs/train = tensor([[-2.2603, -2.8064],
        [-2.2262, -2.6519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.361927181482315e-05
Epoch 0, Step 207: loss/train = 0.09190381318330765, logprobs/train = tensor([[-2.8346, -2.5287],
        [-2.7573, -2.2080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.940485814586282e-05
Epoch 0, Step 215: loss/train = 0.11871840059757233, logprobs/train = tensor([[-3.2363, -2.1965],
        [-3.3215, -2.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001398100284859538
Epoch 0, Step 223: loss/train = 0.16774192452430725, logprobs/train = tensor([[-3.9799, -1.8911],
        [-4.0181, -1.8382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048122025327757
Epoch 0, Step 231: loss/train = 0.15099863708019257, logprobs/train = tensor([[-5.0562, -3.8062],
        [-5.0359, -3.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014012865722179413
Epoch 0, Step 239: loss/train = 0.10639999806880951, logprobs/train = tensor([[-2.8991, -2.3350],
        [-3.2416, -2.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004387549706734717
Epoch 0, Step 247: loss/train = 0.11906787753105164, logprobs/train = tensor([[-3.3958, -3.1671],
        [-3.5519, -3.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015740428352728486
Epoch 0, Step 255: loss/train = 0.09607839584350586, logprobs/train = tensor([[-2.1710, -2.3191],
        [-2.8740, -2.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001511284033767879
Epoch 0, Step 263: loss/train = 0.11329017579555511, logprobs/train = tensor([[-3.4893, -3.2882],
        [-3.4963, -3.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018079226720146835
Epoch 0, Step 271: loss/train = 0.09884093701839447, logprobs/train = tensor([[-2.7664, -2.5512],
        [-2.8093, -2.4065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003959323512390256
Epoch 0, Step 279: loss/train = 0.09231118857860565, logprobs/train = tensor([[-2.3606, -2.2223],
        [-2.3875, -1.9916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004933932796120644
Epoch 0, Step 287: loss/train = 0.11961430311203003, logprobs/train = tensor([[-3.6247, -2.4615],
        [-3.4904, -2.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002832516096532345
Epoch 0, Step 295: loss/train = 0.10937836766242981, logprobs/train = tensor([[-2.5307, -3.2360],
        [-2.4552, -3.0441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024321856908500195
Epoch 0, Step 303: loss/train = 0.09135155379772186, logprobs/train = tensor([[-2.1570, -1.9722],
        [-2.2186, -1.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004534689709544182
Epoch 0, Step 311: loss/train = 0.10575191676616669, logprobs/train = tensor([[-3.2794, -2.6389],
        [-3.2485, -2.5298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020123121794313192
Epoch 0, Step 319: loss/train = 0.10085681825876236, logprobs/train = tensor([[-2.8821, -2.4675],
        [-2.7273, -2.2464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016181468963623047
Epoch 0, Step 327: loss/train = 0.13657397031784058, logprobs/train = tensor([[-3.3673, -1.9100],
        [-3.3292, -1.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034640226513147354
Epoch 0, Step 335: loss/train = 0.11281203478574753, logprobs/train = tensor([[-2.5504, -2.7974],
        [-2.5222, -2.5203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008633085526525974
Epoch 0, Step 343: loss/train = 0.10589931905269623, logprobs/train = tensor([[-2.6653, -3.5728],
        [-2.6822, -3.3827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042060622945427895
Epoch 0, Step 351: loss/train = 0.10016561299562454, logprobs/train = tensor([[-3.2265, -2.9067],
        [-3.1530, -2.6201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00944040808826685
Epoch 0, Step 359: loss/train = 0.1007264256477356, logprobs/train = tensor([[-2.8288, -3.1057],
        [-2.8407, -2.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022492511197924614
Epoch 0, Step 367: loss/train = 0.11771655082702637, logprobs/train = tensor([[-3.6756, -3.5784],
        [-3.5829, -3.3995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004767326638102531
Epoch 0, Step 375: loss/train = 0.08876585215330124, logprobs/train = tensor([[-2.2562, -2.4518],
        [-2.2543, -2.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007274748291820288
Epoch 0, Step 383: loss/train = 0.09628862142562866, logprobs/train = tensor([[-2.3044, -2.7975],
        [-2.2487, -2.5474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004684525541961193
Epoch 0, Step 391: loss/train = 0.141466423869133, logprobs/train = tensor([[-3.3319, -2.0512],
        [-3.2325, -1.8323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034012519754469395
Epoch 0, Step 399: loss/train = 0.09725634753704071, logprobs/train = tensor([[-2.4579, -1.8717],
        [-2.6981, -1.6889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003696979023516178
Epoch 0, Step 407: loss/train = 0.112785704433918, logprobs/train = tensor([[-3.3659, -2.3750],
        [-3.3862, -2.0244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01405891589820385
Epoch 0, Step 415: loss/train = 0.10817088931798935, logprobs/train = tensor([[-2.9354, -2.2078],
        [-3.0295, -1.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029761837795376778
Epoch 0, Step 423: loss/train = 0.09244754910469055, logprobs/train = tensor([[-2.0011, -1.6556],
        [-1.9486, -1.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004759148228913546
Epoch 0, Step 431: loss/train = 0.09739691019058228, logprobs/train = tensor([[-2.1811, -1.8675],
        [-2.4704, -1.7085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01601410284638405
Epoch 0, Step 439: loss/train = 0.10378355532884598, logprobs/train = tensor([[-3.4838, -3.1304],
        [-3.5171, -3.0074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003045175224542618
Epoch 0, Step 447: loss/train = 0.09154388308525085, logprobs/train = tensor([[-2.7679, -2.7006],
        [-2.8382, -2.5140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04721660166978836
Epoch 0, Step 455: loss/train = 0.12983620166778564, logprobs/train = tensor([[-2.7636, -3.3886],
        [-2.7516, -2.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038827162235975266
Epoch 0, Step 463: loss/train = 0.09087913483381271, logprobs/train = tensor([[-1.8142, -2.0868],
        [-1.7062, -1.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027959400322288275
Epoch 0, Step 471: loss/train = 0.08532921969890594, logprobs/train = tensor([[-2.8680, -2.8342],
        [-3.6702, -2.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040242668241262436
Epoch 0, Step 479: loss/train = 0.08127099275588989, logprobs/train = tensor([[-2.0169, -2.3894],
        [-2.7464, -2.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03803827241063118
Epoch 0, Step 487: loss/train = 0.08694759011268616, logprobs/train = tensor([[-3.7275, -3.8001],
        [-3.4426, -3.3939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012250443920493126
Epoch 0, Step 495: loss/train = 0.11729341745376587, logprobs/train = tensor([[-2.6396, -2.4860],
        [-2.5812, -2.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031386662274599075
Epoch 0, Step 503: loss/train = 0.09128142893314362, logprobs/train = tensor([[-2.2309, -2.6469],
        [-2.0048, -2.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050266146659851074
Epoch 0, Step 511: loss/train = 0.0954563096165657, logprobs/train = tensor([[-2.6163, -2.7377],
        [-2.7508, -2.0363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2115044742822647
Epoch 0, Step 519: loss/train = 0.08664707094430923, logprobs/train = tensor([[-2.9895, -3.0407],
        [-2.8965, -2.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05890928581357002
Epoch 0, Step 527: loss/train = 0.12078950554132462, logprobs/train = tensor([[-2.7690, -4.4198],
        [-3.8556, -3.5317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2792684733867645
Epoch 0, Step 535: loss/train = 0.09050773084163666, logprobs/train = tensor([[-2.9629, -3.3440],
        [-3.3715, -2.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46491965651512146
Epoch 0, Step 543: loss/train = 0.11297336220741272, logprobs/train = tensor([[-2.4096, -3.2546],
        [-2.9436, -2.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2115553617477417
Epoch 0, Step 551: loss/train = 0.1020227000117302, logprobs/train = tensor([[-2.4597, -3.6097],
        [-2.6776, -2.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2999659478664398
Epoch 0, Step 559: loss/train = 0.09989449381828308, logprobs/train = tensor([[-3.0434, -2.5494],
        [-3.0518, -1.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08737462759017944
Epoch 0, Step 567: loss/train = 0.08406102657318115, logprobs/train = tensor([[-2.6750, -3.0653],
        [-2.7776, -1.7369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4074389636516571
Epoch 0, Step 575: loss/train = 0.09618125110864639, logprobs/train = tensor([[-2.1260, -3.1920],
        [-2.2126, -1.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45228415727615356
Epoch 0, Step 583: loss/train = 0.1073029562830925, logprobs/train = tensor([[-3.6885, -2.9646],
        [-3.8891, -1.5905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7079416513442993
Epoch 0, Step 591: loss/train = 0.12750288844108582, logprobs/train = tensor([[-3.5124, -2.6107],
        [-3.7405, -1.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32091546058654785
Epoch 0, Step 599: loss/train = 0.11982855200767517, logprobs/train = tensor([[-3.5858, -4.5658],
        [-2.8629, -3.8249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007445561699569225
Epoch 0, Step 607: loss/train = 0.0844646617770195, logprobs/train = tensor([[-2.9960, -3.5510],
        [-3.0893, -2.2661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5018175840377808
Epoch 0, Step 615: loss/train = 0.10826098173856735, logprobs/train = tensor([[-2.6806, -3.5188],
        [-2.4945, -2.7023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11954701691865921
Epoch 0, Step 623: loss/train = 0.18702656030654907, logprobs/train = tensor([[-5.0062, -3.4212],
        [-5.0369, -1.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3602299988269806
Epoch 0, Step 631: loss/train = 0.09534340351819992, logprobs/train = tensor([[-2.9371, -3.2362],
        [-4.6817, -1.4739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.094857931137085
Epoch 0, Step 639: loss/train = 0.1202244684100151, logprobs/train = tensor([[-3.3040, -3.3880],
        [-3.4952, -1.7123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7855306267738342
Epoch 0, Step 647: loss/train = 0.082976795732975, logprobs/train = tensor([[-2.3583, -3.3830],
        [-2.9206, -1.4251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1805930137634277
Epoch 0, Step 655: loss/train = 0.07319958508014679, logprobs/train = tensor([[-2.3360, -4.0099],
        [-2.7304, -1.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1300084590911865
Epoch 0, Step 663: loss/train = 0.0731465220451355, logprobs/train = tensor([[-2.0883, -3.6502],
        [-3.0561, -1.9190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3562209606170654
Epoch 0, Step 671: loss/train = 0.09335137903690338, logprobs/train = tensor([[-2.1916, -4.3783],
        [-3.1348, -2.8094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.193528652191162
Epoch 0, Step 679: loss/train = 0.09536013007164001, logprobs/train = tensor([[-3.5023, -3.5028],
        [-3.3775, -1.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7134026288986206
Epoch 0, Step 687: loss/train = 0.098382368683815, logprobs/train = tensor([[-2.5064, -3.2488],
        [-3.7237, -1.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4985461235046387
Epoch 0, Step 695: loss/train = 0.08975685387849808, logprobs/train = tensor([[-3.5907, -5.0222],
        [-4.0980, -2.9165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0249892473220825
Epoch 0, Step 703: loss/train = 0.07414340227842331, logprobs/train = tensor([[-3.2098, -4.4168],
        [-3.9551, -1.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.5403364896774292
Epoch 0, Step 711: loss/train = 0.08787810802459717, logprobs/train = tensor([[-3.3721, -5.2748],
        [-5.3289, -2.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.043684482574463
Epoch 0, Step 719: loss/train = 0.0711471438407898, logprobs/train = tensor([[-4.0602, -6.9640],
        [-5.8891, -2.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6396689414978027
Epoch 0, Step 727: loss/train = 0.06833595782518387, logprobs/train = tensor([[-3.7283, -7.7944],
        [-7.7130, -2.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.728912830352783
Epoch 0, Step 735: loss/train = 0.06911232322454453, logprobs/train = tensor([[-3.5302, -6.4038],
        [-4.3348, -1.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.985966444015503
Epoch 0, Step 743: loss/train = 0.07549075037240982, logprobs/train = tensor([[-4.7275, -6.4389],
        [-4.8908, -1.8195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.000176429748535
Epoch 0, Step 751: loss/train = 0.09652993083000183, logprobs/train = tensor([[-4.4733, -5.4262],
        [-4.5208, -4.6034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38437896966934204
Epoch 0, Step 759: loss/train = 0.06203147768974304, logprobs/train = tensor([[-4.3918, -8.2085],
        [-5.7695, -1.6992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.184391736984253
Epoch 0, Step 767: loss/train = 0.09941114485263824, logprobs/train = tensor([[-3.7778, -4.5089],
        [-5.0934, -4.3862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7342872023582458
Epoch 0, Step 775: loss/train = 0.0991550162434578, logprobs/train = tensor([[-4.4084, -6.1637],
        [-3.7002, -3.2401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2201180458068848
Epoch 0, Step 783: loss/train = 0.09595045447349548, logprobs/train = tensor([[-4.3291, -4.5280],
        [-7.1873, -3.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5303337574005127
Epoch 0, Step 791: loss/train = 0.06624312698841095, logprobs/train = tensor([[-4.2297, -5.8465],
        [-8.1562, -3.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3756115436553955
Epoch 0, Step 799: loss/train = 0.09974727034568787, logprobs/train = tensor([[-4.1485, -4.8390],
        [-4.5586, -4.4297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4558757543563843
Epoch 0, Step 807: loss/train = 0.060482557862997055, logprobs/train = tensor([[-2.5971, -6.1603],
        [-7.4088, -2.7368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3895158767700195
Epoch 0, Step 815: loss/train = 0.08651333302259445, logprobs/train = tensor([[-5.3174, -5.4706],
        [-4.6596, -1.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2730333805084229
Epoch 0, Step 823: loss/train = 0.08600795269012451, logprobs/train = tensor([[-3.7926, -5.3887],
        [-8.3176, -2.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5781705379486084
Epoch 0, Step 831: loss/train = 0.06035151705145836, logprobs/train = tensor([[-5.9792, -9.7217],
        [-8.2791, -3.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5654900074005127
Epoch 0, Step 839: loss/train = 0.06302222609519958, logprobs/train = tensor([[-4.8028, -7.0033],
        [-8.5879, -4.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8338731527328491
Epoch 0, Step 847: loss/train = 0.09796172380447388, logprobs/train = tensor([[-5.7848, -8.6909],
        [-6.6623, -1.4896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3481035232543945
Epoch 0, Step 855: loss/train = 0.06565892696380615, logprobs/train = tensor([[ -2.0869,  -5.6066],
        [-11.0186,  -5.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0356273651123047
Epoch 0, Step 863: loss/train = 0.06895244866609573, logprobs/train = tensor([[-4.8413, -8.0642],
        [-9.1036, -2.1509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.114853382110596
Epoch 0, Step 871: loss/train = 0.0752275288105011, logprobs/train = tensor([[-6.4934, -8.6281],
        [-6.2763, -2.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.313992738723755
Epoch 0, Step 879: loss/train = 0.0662144124507904, logprobs/train = tensor([[-3.9277, -6.8812],
        [-7.4207, -4.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8232316970825195
Epoch 0, Step 887: loss/train = 0.1242741197347641, logprobs/train = tensor([[-7.5234, -7.4217],
        [-4.8194, -4.0620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2946855127811432
Epoch 0, Step 895: loss/train = 0.06233534216880798, logprobs/train = tensor([[-3.7279, -7.6944],
        [-8.1577, -4.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9573283195495605
Epoch 0, Step 903: loss/train = 0.15005385875701904, logprobs/train = tensor([[-6.3465, -6.5610],
        [-7.4716, -4.2970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7442625761032104
Epoch 0, Step 911: loss/train = 0.13328175246715546, logprobs/train = tensor([[ -7.0559,  -7.5353],
        [-10.9919,  -3.3278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3079910278320312
Epoch 0, Step 919: loss/train = 0.08721271902322769, logprobs/train = tensor([[ -4.1395,  -7.8400],
        [-12.3928,  -3.8399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9615044593811035
Epoch 0, Step 927: loss/train = 0.11460133641958237, logprobs/train = tensor([[-4.4516, -4.8743],
        [-6.9552, -2.8471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1070451736450195
Epoch 0, Step 935: loss/train = 0.07598858326673508, logprobs/train = tensor([[-3.6676, -7.3850],
        [-4.6649, -2.9389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4197521209716797
Epoch 0, Step 943: loss/train = 0.0939633846282959, logprobs/train = tensor([[ -7.9664, -10.0142],
        [-13.3531,  -6.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7077431678771973
Epoch 0, Step 951: loss/train = 0.10286771506071091, logprobs/train = tensor([[-7.3028, -7.3622],
        [-8.3570, -2.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.890491485595703
Epoch 0, Step 959: loss/train = 0.07143306732177734, logprobs/train = tensor([[ -2.8702,  -8.7376],
        [-10.3560,  -3.2296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.46958589553833
Epoch 0, Step 967: loss/train = 0.07966548949480057, logprobs/train = tensor([[-3.2017, -4.3000],
        [-7.9240, -6.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3590272665023804
Epoch 0, Step 975: loss/train = 0.09676939249038696, logprobs/train = tensor([[-6.4877, -7.5812],
        [-8.7312, -2.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.694417119026184
Epoch 0, Step 983: loss/train = 0.0776372030377388, logprobs/train = tensor([[-5.5956, -7.1479],
        [-9.7404, -5.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.517845630645752
Epoch 0, Step 991: loss/train = 0.05214884504675865, logprobs/train = tensor([[ -3.6781,  -7.2680],
        [-11.7711,  -4.7667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.754266738891602
Epoch 0, Step 999: loss/train = 0.06018310785293579, logprobs/train = tensor([[ -5.3323, -10.2272],
        [ -7.1915,  -2.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3925185203552246
Epoch 0, Step 1007: loss/train = 0.08175871521234512, logprobs/train = tensor([[ -4.2744,  -7.7349],
        [-10.5584,  -3.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.508815288543701
Epoch 0, Step 1015: loss/train = 0.10558123141527176, logprobs/train = tensor([[ -6.3601, -10.1385],
        [-13.1834,  -5.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0956339836120605
Epoch 0, Step 1023: loss/train = 0.07818900793790817, logprobs/train = tensor([[ -4.2145, -10.6907],
        [-12.6397,  -4.3979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.768477201461792
Epoch 0, Step 1031: loss/train = 0.11121785640716553, logprobs/train = tensor([[-6.0746, -8.8967],
        [-7.0077, -5.8847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8232308626174927
Epoch 0, Step 1039: loss/train = 0.07481314986944199, logprobs/train = tensor([[-11.3713, -12.5053],
        [ -9.1919,  -3.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.240426778793335
Epoch 0, Step 1047: loss/train = 0.06563247740268707, logprobs/train = tensor([[-4.3218, -7.2172],
        [-9.5509, -4.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3765220642089844
Epoch 0, Step 1055: loss/train = 0.08284444361925125, logprobs/train = tensor([[ -4.5729,  -8.8907],
        [-11.4174,  -5.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3847031593322754
Epoch 0, Step 1063: loss/train = 0.08918535709381104, logprobs/train = tensor([[-6.6760, -8.4518],
        [-8.0218, -5.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2383193969726562
Epoch 0, Step 1071: loss/train = 0.10407157987356186, logprobs/train = tensor([[-9.5284, -9.4965],
        [-5.3193, -4.0365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0253651142120361
Epoch 0, Step 1079: loss/train = 0.10530951619148254, logprobs/train = tensor([[ -9.4885, -10.7694],
        [-11.3709,  -6.3657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8724786043167114
Epoch 0, Step 1087: loss/train = 0.05893642455339432, logprobs/train = tensor([[ -6.8854, -11.4931],
        [-12.0625,  -2.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7138800621032715
Epoch 0, Step 1095: loss/train = 0.07300329953432083, logprobs/train = tensor([[-6.1827, -9.8557],
        [-7.0342, -2.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4314584732055664
Epoch 0, Step 1103: loss/train = 0.08822821825742722, logprobs/train = tensor([[ -3.9305,  -4.1875],
        [-11.7852, -12.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3929955959320068
Epoch 0, Step 1111: loss/train = 0.0751911997795105, logprobs/train = tensor([[-10.7320, -13.7397],
        [ -7.3180,  -5.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8841524124145508
Epoch 0, Step 1119: loss/train = 0.06769382953643799, logprobs/train = tensor([[ -7.1804, -13.1274],
        [ -8.8149,  -5.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.47074556350708
Epoch 0, Step 1127: loss/train = 0.07896961271762848, logprobs/train = tensor([[ -6.8078, -11.6598],
        [-13.5957,  -6.4046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.673607349395752
Epoch 0, Step 1135: loss/train = 0.07242065668106079, logprobs/train = tensor([[-10.3600, -12.1457],
        [-10.1407,  -4.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.995802879333496
Epoch 0, Step 1143: loss/train = 0.09519949555397034, logprobs/train = tensor([[-7.3584, -8.3490],
        [-5.5923, -6.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6579061150550842
Epoch 0, Step 1151: loss/train = 0.07916605472564697, logprobs/train = tensor([[ -5.9597, -11.6536],
        [-13.6547,  -7.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7821762561798096
Epoch 0, Step 1159: loss/train = 0.07085641473531723, logprobs/train = tensor([[ -9.3050, -13.3111],
        [ -6.0084,  -1.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3758726119995117
Epoch 0, Step 1167: loss/train = 0.05931224301457405, logprobs/train = tensor([[ -8.7422, -15.0893],
        [-11.0037,  -2.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4630329608917236
Epoch 0, Step 1175: loss/train = 0.11798058450222015, logprobs/train = tensor([[-11.2143, -14.0029],
        [-10.4029,  -4.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.368770718574524
Epoch 0, Step 1183: loss/train = 0.06100907921791077, logprobs/train = tensor([[-11.0989, -14.5282],
        [ -7.9337,  -2.5858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.745302677154541
Epoch 0, Step 1191: loss/train = 0.23487907648086548, logprobs/train = tensor([[ -7.9543, -13.1595],
        [-11.3206,  -7.6589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7754998207092285
Epoch 0, Step 1199: loss/train = 0.05469390004873276, logprobs/train = tensor([[ -5.0807, -15.2338],
        [-16.9920,  -4.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.513241767883301
Epoch 0, Step 1207: loss/train = 0.11187992244958878, logprobs/train = tensor([[-11.2040, -14.8981],
        [-13.0022,  -4.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.67903733253479
Epoch 0, Step 1215: loss/train = 0.0382925346493721, logprobs/train = tensor([[ -7.8264, -16.7159],
        [-20.7946,  -4.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0477728843688965
Epoch 0, Step 1223: loss/train = 0.06070706993341446, logprobs/train = tensor([[-11.8883, -16.7445],
        [ -9.0125,  -3.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6694788932800293
Epoch 0, Step 1231: loss/train = 0.0708828791975975, logprobs/train = tensor([[ -7.4703, -17.3575],
        [-13.4760,  -5.7537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5414764881134033
Epoch 0, Step 1239: loss/train = 0.0954163447022438, logprobs/train = tensor([[-10.3453, -11.6098],
        [ -6.1898,  -2.9768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6727352142333984
Epoch 0, Step 1247: loss/train = 0.06983605772256851, logprobs/train = tensor([[-14.5751, -15.9389],
        [ -9.9205,  -5.2758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7247350215911865
Epoch 0, Step 1255: loss/train = 0.10402635484933853, logprobs/train = tensor([[-11.1739, -12.0243],
        [-10.3839,  -6.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2718260288238525
Epoch 0, Step 1263: loss/train = 0.1262425035238266, logprobs/train = tensor([[ -6.2338, -10.6503],
        [-19.6907,  -9.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.742658853530884
Epoch 0, Step 1271: loss/train = 0.0769396424293518, logprobs/train = tensor([[-10.5354, -12.1269],
        [ -4.6882,  -2.8235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7697466611862183
Epoch 0, Step 1279: loss/train = 0.06635343283414841, logprobs/train = tensor([[ -7.8529, -15.4215],
        [-10.1348,  -3.3877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.377226829528809
Epoch 0, Step 1287: loss/train = 0.09964804351329803, logprobs/train = tensor([[ -7.0851, -11.4970],
        [-15.2525,  -3.6054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.732348680496216
Epoch 0, Step 1295: loss/train = 0.043179064989089966, logprobs/train = tensor([[ -5.0981, -14.7930],
        [-14.1006,  -4.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.45170259475708
Epoch 0, Step 1303: loss/train = 0.07420948147773743, logprobs/train = tensor([[ -8.9008, -16.4170],
        [-10.3467,  -2.9160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.5430502891540527
Epoch 0, Step 1311: loss/train = 0.06473155319690704, logprobs/train = tensor([[ -7.2332, -11.8714],
        [ -9.0600,  -3.1405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.0119078159332275
Epoch 0, Step 1319: loss/train = 0.13375963270664215, logprobs/train = tensor([[-13.9354, -13.4408],
        [ -4.5825,  -4.6241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42216402292251587
Epoch 0, Step 1327: loss/train = 0.13204389810562134, logprobs/train = tensor([[-11.0669,  -9.4890],
        [ -8.4827,  -6.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.520359754562378
Epoch 0, Step 1335: loss/train = 0.05699096620082855, logprobs/train = tensor([[ -8.7697, -14.4698],
        [ -9.8285,  -2.3353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.149565696716309
Epoch 0, Step 1343: loss/train = 0.08466854691505432, logprobs/train = tensor([[-7.0020, -9.2501],
        [-7.2584, -6.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7432270050048828
Epoch 0, Step 1351: loss/train = 0.05937845632433891, logprobs/train = tensor([[ -8.2266, -14.2338],
        [ -5.4744,  -2.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.653031587600708
Epoch 0, Step 1359: loss/train = 0.05941908434033394, logprobs/train = tensor([[ -5.8950, -16.3701],
        [-13.3683,  -3.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9761962890625
Epoch 0, Step 1367: loss/train = 0.09155700355768204, logprobs/train = tensor([[-12.1731, -13.1290],
        [ -5.6958,  -3.7738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6412572860717773
Epoch 0, Step 1375: loss/train = 0.08034999668598175, logprobs/train = tensor([[-13.1005, -20.1099],
        [ -9.3809,  -3.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.59784197807312
Epoch 0, Step 1383: loss/train = 0.13417509198188782, logprobs/train = tensor([[-12.2671, -12.9246],
        [ -8.7595,  -5.8642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3561172485351562
Epoch 0, Step 1391: loss/train = 0.08152326196432114, logprobs/train = tensor([[-11.1808, -13.3336],
        [ -9.8488,  -7.0257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4248523712158203
Epoch 0, Step 1399: loss/train = 0.06906531751155853, logprobs/train = tensor([[-11.2232, -17.8378],
        [-10.8305,  -4.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6822915077209473
Epoch 0, Step 1407: loss/train = 0.1074301227927208, logprobs/train = tensor([[ -7.7885, -17.8821],
        [-12.8357,  -5.9254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.663485527038574
Epoch 0, Step 1415: loss/train = 0.07304802536964417, logprobs/train = tensor([[ -9.8704, -19.7239],
        [-12.2134,  -5.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.891599655151367
Epoch 0, Step 1423: loss/train = 0.06071026623249054, logprobs/train = tensor([[-13.2434, -18.2735],
        [-10.9801,  -4.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.828551769256592
Epoch 0, Step 1431: loss/train = 0.08099882304668427, logprobs/train = tensor([[ -7.5455, -10.6373],
        [-12.6784,  -8.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.003671169281006
Epoch 0, Step 1439: loss/train = 0.06182748079299927, logprobs/train = tensor([[ -5.8837, -14.3571],
        [-16.9761,  -6.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8622872829437256
Epoch 0, Step 1447: loss/train = 0.07800931483507156, logprobs/train = tensor([[-13.2604, -21.2059],
        [ -9.6306,  -6.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.754403591156006
Epoch 0, Step 1455: loss/train = 0.08904856443405151, logprobs/train = tensor([[-11.8995, -18.8867],
        [-12.8674,  -6.5415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4123334884643555
Epoch 0, Step 1463: loss/train = 0.059532299637794495, logprobs/train = tensor([[ -7.4999, -20.9378],
        [ -9.5433,  -3.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9464316368103027
Epoch 0, Step 1471: loss/train = 0.050302911549806595, logprobs/train = tensor([[ -8.5100, -11.2715],
        [-10.8751,  -8.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8122148513793945
Epoch 0, Step 1479: loss/train = 0.07187613099813461, logprobs/train = tensor([[ -7.7912, -15.4041],
        [-15.4358,  -7.3189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.538525342941284
Epoch 0, Step 1487: loss/train = 0.08874569833278656, logprobs/train = tensor([[-12.6851, -13.9197],
        [ -8.2247,  -5.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0324926376342773
Epoch 0, Step 1495: loss/train = 0.046633485704660416, logprobs/train = tensor([[ -6.7002, -24.6877],
        [-20.1608,  -5.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.97352933883667
Epoch 0, Step 1503: loss/train = 0.09029846638441086, logprobs/train = tensor([[-13.2847, -17.2599],
        [-10.7369,  -6.6200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.944087505340576
Epoch 0, Step 1511: loss/train = 0.07264631986618042, logprobs/train = tensor([[ -5.8325, -18.8980],
        [-12.9095,  -5.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5000200271606445
Epoch 0, Step 1519: loss/train = 0.09942913800477982, logprobs/train = tensor([[-12.4693, -12.2323],
        [-10.4232,  -8.5590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.976652979850769
Epoch 0, Step 1527: loss/train = 0.08024992048740387, logprobs/train = tensor([[ -7.9095, -20.4386],
        [-12.3004,  -5.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9520065784454346
Epoch 0, Step 1535: loss/train = 0.08759306371212006, logprobs/train = tensor([[-10.2880, -17.8333],
        [-12.9717,  -6.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.025888204574585
Epoch 0, Step 1543: loss/train = 0.08041807264089584, logprobs/train = tensor([[-10.6232, -19.0302],
        [-10.5080,  -6.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.032191753387451
Epoch 0, Step 1551: loss/train = 0.06673908233642578, logprobs/train = tensor([[ -7.8225, -18.2194],
        [-14.1188,  -7.3586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4694221019744873
Epoch 0, Step 1559: loss/train = 0.2962920367717743, logprobs/train = tensor([[ -6.3563, -16.0580],
        [-14.1309, -11.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.735466957092285
Epoch 0, Step 1567: loss/train = 0.13487011194229126, logprobs/train = tensor([[-15.0051, -13.9767],
        [ -8.1504,  -6.4069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27170810103416443
Epoch 0, Step 1575: loss/train = 0.07153215259313583, logprobs/train = tensor([[ -4.8988,  -6.2212],
        [-15.3399, -13.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5200510025024414
Epoch 0, Step 1583: loss/train = 0.058318186551332474, logprobs/train = tensor([[ -7.7960, -12.1377],
        [-11.4581,  -6.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.898179292678833
Epoch 0, Step 1591: loss/train = 0.11019176244735718, logprobs/train = tensor([[ -9.9690, -10.3766],
        [-12.5400,  -7.7058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2801541090011597
Epoch 0, Step 1599: loss/train = 0.12308581173419952, logprobs/train = tensor([[ -6.3693,  -8.5310],
        [-13.1956, -10.4075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.653723955154419
Epoch 0, Step 1607: loss/train = 0.05535649508237839, logprobs/train = tensor([[-10.5153, -21.4728],
        [-13.0266,  -4.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.88007926940918
Epoch 0, Step 1615: loss/train = 0.10980256646871567, logprobs/train = tensor([[-11.2488, -13.8219],
        [-13.0493,  -9.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7184741497039795
Epoch 0, Step 1623: loss/train = 0.09198018163442612, logprobs/train = tensor([[-11.1152, -15.9801],
        [-10.2002,  -6.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0002353191375732
Epoch 0, Step 1631: loss/train = 0.06966662406921387, logprobs/train = tensor([[ -4.7427, -15.5326],
        [-18.7003,  -8.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.450506210327148
Epoch 0, Step 1639: loss/train = 0.11746024340391159, logprobs/train = tensor([[-14.9087, -17.0542],
        [ -8.9654,  -9.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7144477367401123
Epoch 0, Step 1647: loss/train = 0.047269243746995926, logprobs/train = tensor([[ -7.6178, -19.9441],
        [-17.0068,  -4.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.926997184753418
Epoch 0, Step 1655: loss/train = 0.07463563978672028, logprobs/train = tensor([[-12.3394, -16.2063],
        [ -7.6616,  -4.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1890368461608887
Epoch 0, Step 1663: loss/train = 0.08577460050582886, logprobs/train = tensor([[ -8.9135, -17.1744],
        [-13.6292,  -3.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8926074504852295
Epoch 0, Step 1671: loss/train = 0.08417138457298279, logprobs/train = tensor([[ -8.6582, -20.6338],
        [-17.1352,  -3.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9480550289154053
Epoch 0, Step 1679: loss/train = 0.1420588344335556, logprobs/train = tensor([[-14.8663, -15.8276],
        [ -8.8105,  -5.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2847821712493896
Epoch 0, Step 1687: loss/train = 0.07074631750583649, logprobs/train = tensor([[ -7.1271, -14.2561],
        [-10.9496,  -4.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.737792491912842
Epoch 0, Step 1695: loss/train = 0.051888398826122284, logprobs/train = tensor([[ -8.7532, -15.8050],
        [-13.1308,  -4.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.990967750549316
Epoch 0, Step 1703: loss/train = 0.05892548710107803, logprobs/train = tensor([[ -8.2855, -13.8756],
        [-14.1114,  -2.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.8068177700042725
Epoch 0, Step 1711: loss/train = 0.05995677411556244, logprobs/train = tensor([[ -9.2579, -16.1788],
        [-15.6734,  -6.6316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6930603981018066
Epoch 0, Step 1719: loss/train = 0.05949270725250244, logprobs/train = tensor([[ -9.9905, -17.4253],
        [-13.5585,  -2.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4358890056610107
Epoch 0, Step 1727: loss/train = 0.08625663071870804, logprobs/train = tensor([[ -6.5818, -10.2879],
        [-11.0635,  -5.4787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.63927960395813
Epoch 0, Step 1735: loss/train = 0.059293232858181, logprobs/train = tensor([[ -9.5797, -16.7299],
        [-16.1919,  -7.1490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.155451774597168
Epoch 0, Step 1743: loss/train = 0.0651211366057396, logprobs/train = tensor([[ -4.2359, -17.0981],
        [-23.5728,  -7.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.927594184875488
Epoch 0, Step 1751: loss/train = 0.11470630019903183, logprobs/train = tensor([[-18.9305, -18.4682],
        [ -6.8475,  -6.0571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05505010858178139
Epoch 0, Step 1759: loss/train = 0.14597667753696442, logprobs/train = tensor([[-14.1323, -17.6313],
        [-14.5692,  -4.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6303389072418213
Epoch 0, Step 1767: loss/train = 0.051413148641586304, logprobs/train = tensor([[ -6.3410, -17.1046],
        [-20.7803,  -3.3558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.552253723144531
Epoch 0, Step 1775: loss/train = 0.11207963526248932, logprobs/train = tensor([[ -7.4739, -15.2744],
        [-18.5763, -13.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.998359203338623
Epoch 0, Step 1783: loss/train = 0.06542660295963287, logprobs/train = tensor([[-11.5752, -17.8882],
        [-13.5766,  -6.4068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.367109775543213
Epoch 0, Step 1791: loss/train = 0.07282425463199615, logprobs/train = tensor([[ -5.7879, -13.4833],
        [-16.4820,  -9.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9515204429626465
Epoch 0, Step 1799: loss/train = 0.058340441435575485, logprobs/train = tensor([[-16.0094, -24.9212],
        [-10.1281,  -5.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.27376127243042
Epoch 0, Step 1807: loss/train = 0.04858649522066116, logprobs/train = tensor([[ -5.0554, -19.2213],
        [-20.3426,  -5.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.068757057189941
Epoch 0, Step 1815: loss/train = 0.05909454822540283, logprobs/train = tensor([[ -6.6179, -18.8080],
        [-17.9448,  -4.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9894351959228516
Epoch 0, Step 1823: loss/train = 0.11210734397172928, logprobs/train = tensor([[ -8.3545, -14.0103],
        [-14.8122,  -9.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7097043991088867
Epoch 0, Step 1831: loss/train = 0.12627755105495453, logprobs/train = tensor([[-11.7252, -19.3324],
        [-13.2582,  -6.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.447287082672119
Epoch 0, Step 1839: loss/train = 0.07578519731760025, logprobs/train = tensor([[-13.8114, -18.9087],
        [ -8.5994,  -2.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.642275333404541
Epoch 0, Step 1847: loss/train = 0.06380846351385117, logprobs/train = tensor([[-10.3420, -15.0503],
        [-11.5571,  -2.9576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.878471851348877
Epoch 0, Step 1855: loss/train = 0.07048843055963516, logprobs/train = tensor([[-8.1135, -9.6457],
        [-6.8340, -1.9815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.590320587158203
Epoch 0, Step 1863: loss/train = 0.05872516334056854, logprobs/train = tensor([[ -5.6785, -13.0132],
        [-12.9817,  -6.3654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7805542945861816
Epoch 0, Step 1871: loss/train = 0.07288786768913269, logprobs/train = tensor([[ -5.5518, -11.6450],
        [-10.2476,  -6.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.723952531814575
Epoch 0, Step 1879: loss/train = 0.059687670320272446, logprobs/train = tensor([[ -8.8841, -18.6961],
        [-11.3590,  -3.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4322359561920166
Epoch 0, Step 1887: loss/train = 0.07073807716369629, logprobs/train = tensor([[-11.2356, -16.7729],
        [-10.1147,  -3.1967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4334299564361572
Epoch 0, Step 1895: loss/train = 0.06870493292808533, logprobs/train = tensor([[ -8.4502, -12.1355],
        [-10.9160,  -5.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6102030277252197
Epoch 0, Step 1903: loss/train = 0.07274909317493439, logprobs/train = tensor([[-10.5024, -24.5244],
        [-13.9730,  -2.5026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3995699882507324
Epoch 0, Step 1911: loss/train = 0.10397668182849884, logprobs/train = tensor([[-14.5731, -17.5095],
        [ -9.5036,  -5.3258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2939629554748535
Epoch 0, Step 1919: loss/train = 0.07759853452444077, logprobs/train = tensor([[-13.3505, -18.7999],
        [ -9.0285,  -2.7242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6495165824890137
Epoch 0, Step 1927: loss/train = 0.09950454533100128, logprobs/train = tensor([[-14.5578, -17.2075],
        [ -7.3036,  -3.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5583770275115967
Epoch 0, Step 1935: loss/train = 0.12729749083518982, logprobs/train = tensor([[-16.7884, -17.4109],
        [-10.3240,  -7.8204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.472327470779419
Epoch 0, Step 1943: loss/train = 0.11131011694669724, logprobs/train = tensor([[-11.2821, -14.8929],
        [-12.1364,  -8.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.909387469291687
Epoch 0, Step 1951: loss/train = 0.05418958514928818, logprobs/train = tensor([[ -5.9529, -15.6440],
        [-14.4849,  -2.6865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4463672637939453
Epoch 0, Step 1959: loss/train = 0.08027726411819458, logprobs/train = tensor([[ -8.1300, -12.5544],
        [-12.9291,  -6.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4289181232452393
Epoch 0, Step 1967: loss/train = 0.10489892214536667, logprobs/train = tensor([[ -4.6199, -17.0665],
        [-17.0306,  -7.5128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7954134941101074
Epoch 0, Step 1975: loss/train = 0.06894345581531525, logprobs/train = tensor([[-11.7669, -19.1448],
        [-10.4606,  -4.3244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.664900302886963
Epoch 0, Step 1983: loss/train = 0.12144648283720016, logprobs/train = tensor([[ -6.0091,  -5.4085],
        [-13.1320,  -8.9507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6634814739227295
Epoch 0, Step 1991: loss/train = 0.08369263261556625, logprobs/train = tensor([[-16.6733, -19.8783],
        [ -6.6203,  -2.1212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9523780345916748
Epoch 0, Step 1999: loss/train = 0.06984174251556396, logprobs/train = tensor([[-14.0813, -19.3308],
        [ -8.2643,  -3.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.815380573272705
Epoch 0, Step 2007: loss/train = 0.0854361355304718, logprobs/train = tensor([[-11.9727, -14.5197],
        [ -6.3968,  -2.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2952042818069458
Epoch 0, Step 2015: loss/train = 0.045968931168317795, logprobs/train = tensor([[ -5.2447, -20.4225],
        [-13.6154,  -5.3488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.780656814575195
Epoch 0, Step 2023: loss/train = 0.08264566957950592, logprobs/train = tensor([[-13.2677, -19.6888],
        [ -7.9340,  -5.8509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1406614780426025
Epoch 0, Step 2031: loss/train = 0.057364534586668015, logprobs/train = tensor([[ -6.0369, -21.7671],
        [-13.2563,  -2.8741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.80808424949646
Epoch 0, Step 2039: loss/train = 0.06989850103855133, logprobs/train = tensor([[-13.9878, -25.4062],
        [ -8.7901,  -3.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.852830410003662
Epoch 0, Step 2047: loss/train = 0.07351826131343842, logprobs/train = tensor([[-13.1222, -19.6138],
        [ -6.9087,  -3.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2464370727539062
Epoch 0, Step 2055: loss/train = 0.13834895193576813, logprobs/train = tensor([[-18.9489, -21.9917],
        [ -5.9330,  -3.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.686173439025879
Epoch 0, Step 2063: loss/train = 0.0938778966665268, logprobs/train = tensor([[-8.8722, -8.3474],
        [-8.6916, -9.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1259163618087769
Epoch 0, Step 2071: loss/train = 0.05674885958433151, logprobs/train = tensor([[-14.7223, -24.5801],
        [ -9.7261,  -2.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.491227149963379
Epoch 0, Step 2079: loss/train = 0.05654478818178177, logprobs/train = tensor([[ -6.7633, -19.6325],
        [-13.6006,  -3.7863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7178828716278076
Epoch 0, Step 2087: loss/train = 0.05370450019836426, logprobs/train = tensor([[-10.9956, -30.8041],
        [-12.6644,  -3.1366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.374551296234131
Epoch 0, Step 2095: loss/train = 0.05989207699894905, logprobs/train = tensor([[-10.6381, -18.5202],
        [-11.0653,  -6.3349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.023864269256592
Epoch 0, Step 2103: loss/train = 0.0586400106549263, logprobs/train = tensor([[-16.0507, -33.2227],
        [-14.1983,  -4.5255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.94270396232605
Epoch 0, Step 2111: loss/train = 0.1285681128501892, logprobs/train = tensor([[-19.9847, -29.8980],
        [ -9.0330,  -5.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.541663885116577
Epoch 0, Step 2119: loss/train = 0.10192929208278656, logprobs/train = tensor([[-26.2493, -47.3527],
        [-11.4958,  -7.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7842352390289307
Epoch 0, Step 2127: loss/train = 0.07650762796401978, logprobs/train = tensor([[ -6.5142, -15.3697],
        [-15.3723, -12.3223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3481192588806152
Epoch 0, Step 2135: loss/train = 0.05101807788014412, logprobs/train = tensor([[ -5.7762, -31.6524],
        [-18.9360,  -3.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.382793426513672
Epoch 0, Step 2143: loss/train = 0.054235391318798065, logprobs/train = tensor([[ -8.9506, -29.1135],
        [-15.5100,  -3.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.412674903869629
Epoch 0, Step 2151: loss/train = 0.0536578968167305, logprobs/train = tensor([[-10.7766, -33.1556],
        [-15.4321,  -5.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4882566928863525
Epoch 0, Step 2159: loss/train = 0.03808851167559624, logprobs/train = tensor([[-10.7340, -39.0489],
        [-14.0138,  -2.4491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.948458194732666
Epoch 0, Step 2167: loss/train = 0.09225344657897949, logprobs/train = tensor([[ -9.6145, -15.3258],
        [-12.7048,  -9.6813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9690953493118286
Epoch 0, Step 2175: loss/train = 0.10184447467327118, logprobs/train = tensor([[ -7.3612, -13.1160],
        [-18.3991,  -8.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.573021650314331
Epoch 0, Step 2183: loss/train = 0.06195186823606491, logprobs/train = tensor([[-10.4685, -19.4132],
        [-14.1896,  -5.8290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9321258068084717
Epoch 0, Step 2191: loss/train = 0.059082113206386566, logprobs/train = tensor([[ -9.8132, -21.6167],
        [-14.2311,  -7.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6079163551330566
Epoch 0, Step 2199: loss/train = 0.05893881618976593, logprobs/train = tensor([[ -7.4768, -20.9088],
        [-14.6133,  -3.5903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.920361042022705
Epoch 0, Step 2207: loss/train = 0.07935409247875214, logprobs/train = tensor([[ -3.9475,  -6.7759],
        [-21.3663, -13.7360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.28696346282959
Epoch 0, Step 2215: loss/train = 0.06715333461761475, logprobs/train = tensor([[ -5.4771, -20.0524],
        [-21.3114,  -9.2834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.017463207244873
Epoch 0, Step 2223: loss/train = 0.11437991261482239, logprobs/train = tensor([[-14.6098, -24.9453],
        [-11.5231,  -6.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.763885498046875
Epoch 0, Step 2231: loss/train = 0.11427797377109528, logprobs/train = tensor([[-15.9174, -21.2818],
        [-16.6727,  -5.0059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4332644939422607
Epoch 0, Step 2239: loss/train = 0.0506255105137825, logprobs/train = tensor([[ -7.8688, -19.2261],
        [-14.0967,  -8.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.982835531234741
Epoch 0, Step 2247: loss/train = 0.07339729368686676, logprobs/train = tensor([[-11.3888, -19.5785],
        [ -9.3210,  -5.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7376585006713867
Epoch 0, Step 2255: loss/train = 0.06869615614414215, logprobs/train = tensor([[ -7.5181, -18.7270],
        [-15.2159,  -9.4059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.475616693496704
Epoch 0, Step 2263: loss/train = 0.07970216870307922, logprobs/train = tensor([[ -4.5431, -12.7929],
        [-20.9826, -13.6095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8411688804626465
Epoch 0, Step 2271: loss/train = 0.08463379740715027, logprobs/train = tensor([[-15.4941, -18.3838],
        [ -8.7897,  -6.4370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.689746379852295
Epoch 0, Step 2279: loss/train = 0.07378177344799042, logprobs/train = tensor([[ -5.7028, -12.2938],
        [-14.3662,  -7.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.657137870788574
Epoch 0, Step 2287: loss/train = 0.10752618312835693, logprobs/train = tensor([[-15.1513, -20.5723],
        [-15.1581,  -4.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.441861391067505
Epoch 0, Step 2295: loss/train = 0.04632598161697388, logprobs/train = tensor([[ -4.4723, -24.0499],
        [-20.7648,  -4.1861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.932255744934082
Epoch 0, Step 2303: loss/train = 0.04922997206449509, logprobs/train = tensor([[ -6.9120, -23.6461],
        [-13.7276,  -4.4115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.802814960479736
Epoch 0, Step 2311: loss/train = 0.06272194534540176, logprobs/train = tensor([[ -9.6276, -19.0120],
        [-14.6247,  -5.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.6243462562561035
Epoch 0, Step 2319: loss/train = 0.06394986063241959, logprobs/train = tensor([[ -7.5160, -15.2333],
        [-17.9459,  -9.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.57126784324646
Epoch 0, Step 2327: loss/train = 0.07059828191995621, logprobs/train = tensor([[-12.6707, -15.8879],
        [-12.1643,  -8.6448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.525599956512451
Epoch 0, Step 2335: loss/train = 0.08001019060611725, logprobs/train = tensor([[-11.3586, -14.9893],
        [-10.3150, -10.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5773980617523193
Epoch 0, Step 2343: loss/train = 0.05972576141357422, logprobs/train = tensor([[ -2.5575, -14.9083],
        [-20.1806,  -8.1886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.920388698577881
Epoch 0, Step 2351: loss/train = 0.06717398017644882, logprobs/train = tensor([[-10.0704, -18.4648],
        [-13.2804,  -3.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.45454740524292
Epoch 0, Step 2359: loss/train = 0.05817069485783577, logprobs/train = tensor([[ -6.3337, -14.3994],
        [-19.5558,  -7.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.429104804992676
Epoch 0, Step 2367: loss/train = 0.11262091249227524, logprobs/train = tensor([[ -7.7700, -12.3616],
        [-17.3702, -10.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.6880736351013184
Epoch 0, Step 2375: loss/train = 0.08640037477016449, logprobs/train = tensor([[-12.3183, -17.3113],
        [-10.7606,  -5.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.876760482788086
