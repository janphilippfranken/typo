[2024-02-19 16:27:50,018][root][INFO] - beta: 0.25
[2024-02-19 16:27:50,018][root][INFO] - temperature: 1
[2024-02-19 16:27:50,019][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.25-batch-size-64
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.25-batch-size-64 after each epoch.
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.25-batch-size-64 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.25-batch-size-64 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.25-batch-size-64 after each epoch.
Epoch 0, Step 0: train/loss = 0.7040798664093018, train/raw-loss = 0.7040798664093018, train/logprobs = tensor([[-0.9533, -0.9948],
        [-0.9302, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7164785265922546, train/raw-loss = 0.7164785265922546, train/logprobs = tensor([[-1.0724, -1.4169],
        [-1.1293, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7007112503051758, train/raw-loss = 0.7007112503051758, train/logprobs = tensor([[-0.8302, -0.9350],
        [-0.7845, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6975338459014893, train/raw-loss = 0.6975338459014893, train/logprobs = tensor([[-0.9099, -0.9087],
        [-0.9060, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6946052312850952, train/raw-loss = 0.6946052312850952, train/logprobs = tensor([[-0.7761, -0.8804],
        [-0.8097, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7074680328369141, train/raw-loss = 0.7074680328369141, train/logprobs = tensor([[-1.2210, -1.1801],
        [-1.2999, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6987193822860718, train/raw-loss = 0.6987193822860718, train/logprobs = tensor([[-1.1771, -1.2348],
        [-1.1741, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.7075663805007935, train/raw-loss = 0.7075663805007935, train/logprobs = tensor([[-0.7880, -0.6978],
        [-0.8163, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.742479681968689, train/raw-loss = 0.742479681968689, train/logprobs = tensor([[-0.9000, -1.5068],
        [-0.8656, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6987901329994202, train/raw-loss = 0.6987901329994202, train/logprobs = tensor([[-0.9074, -1.1629],
        [-0.9010, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7119882702827454, train/raw-loss = 0.7119882702827454, train/logprobs = tensor([[-1.2293, -1.1969],
        [-1.2240, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7207285761833191, train/raw-loss = 0.7207285761833191, train/logprobs = tensor([[-1.0679, -0.9060],
        [-1.0898, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7011242508888245, train/raw-loss = 0.7011242508888245, train/logprobs = tensor([[-0.8549, -1.0949],
        [-0.8891, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.7031682729721069, train/raw-loss = 0.7031682729721069, train/logprobs = tensor([[-0.8906, -1.0827],
        [-0.9134, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7142623662948608, train/raw-loss = 0.7142623662948608, train/logprobs = tensor([[-0.8982, -0.9696],
        [-0.8924, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7054764628410339, train/raw-loss = 0.7054764628410339, train/logprobs = tensor([[-0.5966, -0.8092],
        [-0.5724, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6938965320587158, train/raw-loss = 0.6938965320587158, train/logprobs = tensor([[-1.0988, -1.1515],
        [-1.0541, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7236944437026978, train/raw-loss = 0.7236944437026978, train/logprobs = tensor([[-0.8199, -1.2773],
        [-0.7945, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6943728923797607, train/raw-loss = 0.6943728923797607, train/logprobs = tensor([[-1.0141, -1.0339],
        [-1.0263, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6956578493118286, train/raw-loss = 0.6956578493118286, train/logprobs = tensor([[-1.1737, -1.1441],
        [-1.1765, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7437841296195984, train/raw-loss = 0.7437841296195984, train/logprobs = tensor([[-0.5573, -1.0747],
        [-0.5540, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7071292996406555, train/raw-loss = 0.7071292996406555, train/logprobs = tensor([[-1.0698, -0.9658],
        [-1.0991, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7120579481124878, train/raw-loss = 0.7120579481124878, train/logprobs = tensor([[-1.1177, -1.1496],
        [-1.1588, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7534469962120056, train/raw-loss = 0.7534469962120056, train/logprobs = tensor([[-0.9588, -1.4736],
        [-0.9477, -1.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6944814920425415, train/raw-loss = 0.6944814920425415, train/logprobs = tensor([[-1.3211, -1.4845],
        [-1.2829, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7182225584983826, train/raw-loss = 0.7182225584983826, train/logprobs = tensor([[-0.9310, -0.9236],
        [-0.9353, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7320457696914673, train/raw-loss = 0.7320457696914673, train/logprobs = tensor([[-0.9226, -1.0176],
        [-0.9618, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7064348459243774, train/raw-loss = 0.7064348459243774, train/logprobs = tensor([[-0.9682, -1.0804],
        [-0.9400, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7004761099815369, train/raw-loss = 0.7004761099815369, train/logprobs = tensor([[-1.0793, -1.2677],
        [-1.0354, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7071655988693237, train/raw-loss = 0.7071655988693237, train/logprobs = tensor([[-0.8737, -0.9530],
        [-0.8765, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7233868837356567, train/raw-loss = 0.7233868837356567, train/logprobs = tensor([[-0.9774, -1.2341],
        [-0.9461, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.8921672105789185, train/raw-loss = 0.8921672105789185, train/logprobs = tensor([[-0.7943, -1.4819],
        [-0.8081, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.7119707465171814, train/raw-loss = 0.7119702696800232, train/logprobs = tensor([[-0.8859, -1.0034],
        [-0.9076, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0564002625178546e-06
Epoch 0, Step 33: train/loss = 0.700788140296936, train/raw-loss = 0.7007849216461182, train/logprobs = tensor([[-0.9867, -0.9311],
        [-0.9680, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2969394447281957e-05
Epoch 0, Step 34: train/loss = 0.7557327151298523, train/raw-loss = 0.7557135820388794, train/logprobs = tensor([[-0.6010, -1.2180],
        [-0.5881, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.657838432351127e-05
Epoch 0, Step 35: train/loss = 0.6855964660644531, train/raw-loss = 0.6855961680412292, train/logprobs = tensor([[-0.8457, -1.0296],
        [-1.1835, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2011128092126455e-06
Epoch 0, Step 36: train/loss = 0.697266697883606, train/raw-loss = 0.6972534656524658, train/logprobs = tensor([[-0.9103, -1.0232],
        [-0.9302, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2792049245908856e-05
Epoch 0, Step 37: train/loss = 0.7982792854309082, train/raw-loss = 0.7982785701751709, train/logprobs = tensor([[-0.6690, -1.1977],
        [-0.6762, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.829241566359997e-06
Epoch 0, Step 38: train/loss = 0.6937490701675415, train/raw-loss = 0.693748950958252, train/logprobs = tensor([[-0.7695, -0.8394],
        [-0.8064, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4608485798817128e-07
Epoch 0, Step 39: train/loss = 0.6966540813446045, train/raw-loss = 0.6966512203216553, train/logprobs = tensor([[-0.7991, -0.7422],
        [-0.8072, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1517833627294749e-05
Epoch 0, Step 40: train/loss = 0.699074923992157, train/raw-loss = 0.6990691423416138, train/logprobs = tensor([[-0.8201, -0.8223],
        [-0.8709, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2834101400803775e-05
Epoch 0, Step 41: train/loss = 0.6955817937850952, train/raw-loss = 0.6955766081809998, train/logprobs = tensor([[-1.0444, -0.9780],
        [-1.0731, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.093690272886306e-05
Epoch 0, Step 42: train/loss = 0.6965322494506836, train/raw-loss = 0.6965253353118896, train/logprobs = tensor([[-1.2474, -1.4844],
        [-1.2784, -1.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7878257242264226e-05
Epoch 0, Step 43: train/loss = 0.9545570015907288, train/raw-loss = 0.9545386433601379, train/logprobs = tensor([[-0.6983, -1.9205],
        [-0.8204, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.334601832553744e-05
Epoch 0, Step 44: train/loss = 0.7402050495147705, train/raw-loss = 0.740190863609314, train/logprobs = tensor([[-0.9448, -1.3778],
        [-0.9683, -1.2605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6984659750014544e-05
Epoch 0, Step 45: train/loss = 0.7039202451705933, train/raw-loss = 0.7039045691490173, train/logprobs = tensor([[-0.7382, -1.0730],
        [-0.7462, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.293295882642269e-05
Epoch 0, Step 46: train/loss = 0.707310676574707, train/raw-loss = 0.7073009014129639, train/logprobs = tensor([[-1.2157, -1.4752],
        [-1.2530, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.904690674971789e-05
Epoch 0, Step 47: train/loss = 0.7041329145431519, train/raw-loss = 0.7041267156600952, train/logprobs = tensor([[-1.0087, -0.8339],
        [-1.0162, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4853681679815054e-05
Epoch 0, Step 48: train/loss = 0.7304952144622803, train/raw-loss = 0.7304729223251343, train/logprobs = tensor([[-0.8466, -1.2654],
        [-0.8147, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.882308611646295e-05
Epoch 0, Step 49: train/loss = 0.7066012620925903, train/raw-loss = 0.706570029258728, train/logprobs = tensor([[-1.1681, -0.9930],
        [-1.2088, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012488767970353365
Epoch 0, Step 50: train/loss = 0.6976800560951233, train/raw-loss = 0.6976580023765564, train/logprobs = tensor([[-0.9598, -1.1870],
        [-1.0553, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.846394484862685e-05
Epoch 0, Step 51: train/loss = 0.7396950125694275, train/raw-loss = 0.7395988702774048, train/logprobs = tensor([[-0.8886, -1.4021],
        [-0.9213, -1.2773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038469902938231826
Epoch 0, Step 52: train/loss = 0.7307680249214172, train/raw-loss = 0.7306936979293823, train/logprobs = tensor([[-0.7290, -1.0924],
        [-0.8701, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029735045973211527
Epoch 0, Step 53: train/loss = 0.6957385540008545, train/raw-loss = 0.6957273483276367, train/logprobs = tensor([[-0.9953, -1.0943],
        [-1.0371, -1.1279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.486343823373318e-05
Epoch 0, Step 54: train/loss = 0.7065114974975586, train/raw-loss = 0.7064709663391113, train/logprobs = tensor([[-1.2551, -1.3986],
        [-1.2679, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001620029070181772
Epoch 0, Step 55: train/loss = 0.7237877249717712, train/raw-loss = 0.7237664461135864, train/logprobs = tensor([[-0.9833, -1.5911],
        [-1.0431, -1.4104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.516611705999821e-05
Epoch 0, Step 56: train/loss = 0.690894365310669, train/raw-loss = 0.6908375024795532, train/logprobs = tensor([[-1.0062, -1.1924],
        [-1.2023, -1.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022739876294508576
Epoch 0, Step 57: train/loss = 0.7226828336715698, train/raw-loss = 0.7226719856262207, train/logprobs = tensor([[-1.0480, -0.8522],
        [-1.0908, -0.7916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.353155964054167e-05
Epoch 0, Step 58: train/loss = 0.6948906779289246, train/raw-loss = 0.6948262453079224, train/logprobs = tensor([[-0.9221, -1.0147],
        [-0.9917, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002578251878730953
Epoch 0, Step 59: train/loss = 0.7138750553131104, train/raw-loss = 0.7138544321060181, train/logprobs = tensor([[-0.8908, -0.8849],
        [-0.9323, -0.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.267327211797237e-05
Epoch 0, Step 60: train/loss = 0.697961151599884, train/raw-loss = 0.69793701171875, train/logprobs = tensor([[-0.6032, -0.6679],
        [-0.6641, -0.6679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.668816346675158e-05
Epoch 0, Step 61: train/loss = 0.7057187557220459, train/raw-loss = 0.7057109475135803, train/logprobs = tensor([[-0.7935, -0.7772],
        [-0.8730, -0.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.106010262854397e-05
Epoch 0, Step 62: train/loss = 0.6994311213493347, train/raw-loss = 0.6994298100471497, train/logprobs = tensor([[-0.7619, -0.9891],
        [-0.7818, -0.9330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.21711990586482e-06
Epoch 0, Step 63: train/loss = 0.7066183090209961, train/raw-loss = 0.7065771222114563, train/logprobs = tensor([[-1.0769, -0.8863],
        [-1.0599, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016463999054394662
Epoch 0, Step 64: train/loss = 0.7058624029159546, train/raw-loss = 0.7058358192443848, train/logprobs = tensor([[-0.6512, -0.8027],
        [-0.6884, -0.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010627664596540853
Epoch 0, Step 65: train/loss = 0.6996449828147888, train/raw-loss = 0.6995930075645447, train/logprobs = tensor([[-0.6586, -0.8628],
        [-0.6864, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020786956883966923
Epoch 0, Step 66: train/loss = 0.693760097026825, train/raw-loss = 0.6937448382377625, train/logprobs = tensor([[-0.8206, -0.8006],
        [-0.8933, -0.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.086111534386873e-05
Epoch 0, Step 67: train/loss = 0.6952480673789978, train/raw-loss = 0.6950815320014954, train/logprobs = tensor([[-0.7048, -0.8119],
        [-0.8137, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006659861537627876
Epoch 0, Step 68: train/loss = 0.7385045886039734, train/raw-loss = 0.7384819984436035, train/logprobs = tensor([[-1.0910, -1.0231],
        [-1.0930, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.037637209985405e-05
Epoch 0, Step 69: train/loss = 0.7914848327636719, train/raw-loss = 0.7911368608474731, train/logprobs = tensor([[-1.0960, -1.2506],
        [-1.1615, -1.1063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013919970951974392
Epoch 0, Step 70: train/loss = 0.7012299299240112, train/raw-loss = 0.7012196183204651, train/logprobs = tensor([[-0.9141, -0.7896],
        [-0.9598, -0.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.147915751673281e-05
Epoch 0, Step 71: train/loss = 0.7229401469230652, train/raw-loss = 0.7228983044624329, train/logprobs = tensor([[-1.0089, -0.8039],
        [-1.0643, -0.7199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016743657761253417
Epoch 0, Step 72: train/loss = 0.6969530582427979, train/raw-loss = 0.6969055533409119, train/logprobs = tensor([[-0.9401, -0.8873],
        [-1.1006, -0.8744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019001438340637833
Epoch 0, Step 73: train/loss = 0.6987224817276001, train/raw-loss = 0.6987199187278748, train/logprobs = tensor([[-0.9000, -0.9637],
        [-0.8968, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.981697076000273e-06
Epoch 0, Step 74: train/loss = 0.7421891093254089, train/raw-loss = 0.7417739033699036, train/logprobs = tensor([[-0.6751, -0.9409],
        [-0.7458, -0.8756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016607982106506824
Epoch 0, Step 75: train/loss = 0.6954279541969299, train/raw-loss = 0.6953413486480713, train/logprobs = tensor([[-0.8313, -0.9551],
        [-0.8355, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034631151356734335
Epoch 0, Step 76: train/loss = 0.7418310046195984, train/raw-loss = 0.7418050765991211, train/logprobs = tensor([[-0.7781, -1.0391],
        [-0.8790, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010385134373791516
Epoch 0, Step 77: train/loss = 0.6956392526626587, train/raw-loss = 0.6956385374069214, train/logprobs = tensor([[-0.9096, -0.9506],
        [-0.9849, -0.9773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8412468964233994e-06
Epoch 0, Step 78: train/loss = 0.7281876802444458, train/raw-loss = 0.7279186844825745, train/logprobs = tensor([[-0.7694, -1.0257],
        [-0.8078, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010758971329778433
Epoch 0, Step 79: train/loss = 0.703020453453064, train/raw-loss = 0.7028948664665222, train/logprobs = tensor([[-0.8385, -0.8721],
        [-0.9005, -0.8367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000502436829265207
Epoch 0, Step 80: train/loss = 0.6996369361877441, train/raw-loss = 0.6995159387588501, train/logprobs = tensor([[-0.6773, -0.7929],
        [-0.6846, -0.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004837997257709503
Epoch 0, Step 81: train/loss = 0.7046698331832886, train/raw-loss = 0.7045264840126038, train/logprobs = tensor([[-1.0098, -1.0533],
        [-1.1264, -1.1106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005733495927415788
Epoch 0, Step 82: train/loss = 0.6941532492637634, train/raw-loss = 0.6937161684036255, train/logprobs = tensor([[-0.9028, -1.0294],
        [-0.9869, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017481837421655655
Epoch 0, Step 83: train/loss = 0.7052469253540039, train/raw-loss = 0.7051969766616821, train/logprobs = tensor([[-0.7897, -0.8870],
        [-0.9638, -0.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020004704128950834
Epoch 0, Step 84: train/loss = 0.6977587938308716, train/raw-loss = 0.6977561712265015, train/logprobs = tensor([[-0.9530, -0.7955],
        [-1.3322, -0.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0252944775857031e-05
Epoch 0, Step 85: train/loss = 0.7519605159759521, train/raw-loss = 0.7518105506896973, train/logprobs = tensor([[-1.2572, -1.5432],
        [-1.3332, -1.2683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005998230772092938
Epoch 0, Step 86: train/loss = 0.6931373476982117, train/raw-loss = 0.6931158304214478, train/logprobs = tensor([[-0.7835, -0.7972],
        [-0.8262, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.61548469401896e-05
Epoch 0, Step 87: train/loss = 0.7059763669967651, train/raw-loss = 0.7059466242790222, train/logprobs = tensor([[-0.7422, -0.8124],
        [-0.7891, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011889062443515286
Epoch 0, Step 88: train/loss = 0.7012156248092651, train/raw-loss = 0.7011263370513916, train/logprobs = tensor([[-0.7161, -0.9540],
        [-0.7423, -0.9016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003571881097741425
Epoch 0, Step 89: train/loss = 0.6942958831787109, train/raw-loss = 0.6942636370658875, train/logprobs = tensor([[-0.8603, -0.9441],
        [-0.9678, -0.9224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001290336367674172
Epoch 0, Step 90: train/loss = 0.749854326248169, train/raw-loss = 0.7496962547302246, train/logprobs = tensor([[-0.7211, -1.2714],
        [-0.8052, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006325797294266522
Epoch 0, Step 91: train/loss = 0.7117817997932434, train/raw-loss = 0.7117754817008972, train/logprobs = tensor([[-0.8917, -0.9501],
        [-0.9018, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5085522793233395e-05
Epoch 0, Step 92: train/loss = 0.7479854822158813, train/raw-loss = 0.7468498945236206, train/logprobs = tensor([[-0.7213, -1.3128],
        [-0.7633, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045419917441904545
Epoch 0, Step 93: train/loss = 0.700911283493042, train/raw-loss = 0.7006086707115173, train/logprobs = tensor([[-0.6821, -0.8143],
        [-0.7428, -0.8549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012103363405913115
Epoch 0, Step 94: train/loss = 0.7117683291435242, train/raw-loss = 0.7116748094558716, train/logprobs = tensor([[-0.9847, -0.8958],
        [-1.0791, -0.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037388986675068736
Epoch 0, Step 95: train/loss = 0.7007318139076233, train/raw-loss = 0.7007098197937012, train/logprobs = tensor([[-0.7162, -0.7863],
        [-0.7596, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.773335139267147e-05
Epoch 0, Step 96: train/loss = 0.697769284248352, train/raw-loss = 0.6974969506263733, train/logprobs = tensor([[-0.7894, -0.9752],
        [-0.8760, -0.9498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010891343699768186
Epoch 0, Step 97: train/loss = 0.6977958679199219, train/raw-loss = 0.6977874040603638, train/logprobs = tensor([[-0.7198, -0.7929],
        [-0.8115, -0.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.4033728297799826e-05
Epoch 0, Step 98: train/loss = 0.6913227438926697, train/raw-loss = 0.6910851001739502, train/logprobs = tensor([[-0.8812, -0.9185],
        [-0.9569, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000950732093770057
Epoch 0, Step 99: train/loss = 0.7145989537239075, train/raw-loss = 0.7145830392837524, train/logprobs = tensor([[-0.8787, -0.8244],
        [-0.9173, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.364606088027358e-05
Epoch 0, Step 100: train/loss = 0.6961598992347717, train/raw-loss = 0.6960000991821289, train/logprobs = tensor([[-0.6951, -0.7379],
        [-0.7392, -0.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006391187780536711
Epoch 0, Step 101: train/loss = 0.6963865756988525, train/raw-loss = 0.6963666677474976, train/logprobs = tensor([[-0.5368, -0.6513],
        [-0.5688, -0.6462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.942183583509177e-05
Epoch 0, Step 102: train/loss = 0.7201384902000427, train/raw-loss = 0.7200515270233154, train/logprobs = tensor([[-1.0388, -0.8427],
        [-1.0601, -0.8287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034778262488543987
Epoch 0, Step 103: train/loss = 0.7039764523506165, train/raw-loss = 0.7037907242774963, train/logprobs = tensor([[-0.8794, -0.8209],
        [-0.9536, -0.7890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007427600212395191
Epoch 0, Step 104: train/loss = 0.7140302658081055, train/raw-loss = 0.7140239477157593, train/logprobs = tensor([[-0.7943, -0.5452],
        [-0.8111, -0.5447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5419234589207917e-05
Epoch 0, Step 105: train/loss = 0.6980019211769104, train/raw-loss = 0.697996973991394, train/logprobs = tensor([[-0.6382, -0.8519],
        [-0.6854, -0.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.9517698092386127e-05
Epoch 0, Step 106: train/loss = 0.7411248087882996, train/raw-loss = 0.7410739660263062, train/logprobs = tensor([[-0.6853, -1.1072],
        [-0.7412, -1.1152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020327168749645352
Epoch 0, Step 107: train/loss = 0.7008873820304871, train/raw-loss = 0.700869083404541, train/logprobs = tensor([[-0.6742, -0.6080],
        [-0.7448, -0.6107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.31094041839242e-05
Epoch 0, Step 108: train/loss = 0.6983159184455872, train/raw-loss = 0.6981992125511169, train/logprobs = tensor([[-0.8355, -1.0042],
        [-0.9085, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004668381006922573
Epoch 0, Step 109: train/loss = 0.6985548734664917, train/raw-loss = 0.6979962587356567, train/logprobs = tensor([[-0.7953, -0.9492],
        [-0.8960, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002234871033579111
Epoch 0, Step 110: train/loss = 0.7122145295143127, train/raw-loss = 0.7118884325027466, train/logprobs = tensor([[-0.7255, -0.6149],
        [-0.7809, -0.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013043236685916781
Epoch 0, Step 111: train/loss = 0.7060052752494812, train/raw-loss = 0.7059914469718933, train/logprobs = tensor([[-0.6741, -0.9049],
        [-0.7100, -0.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.534029332920909e-05
Epoch 0, Step 112: train/loss = 0.696874737739563, train/raw-loss = 0.6968125104904175, train/logprobs = tensor([[-0.6507, -0.8305],
        [-0.7358, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002491837367415428
Epoch 0, Step 113: train/loss = 0.7081533670425415, train/raw-loss = 0.7080944776535034, train/logprobs = tensor([[-0.8221, -0.8419],
        [-0.8215, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023552379570901394
Epoch 0, Step 114: train/loss = 0.6963314414024353, train/raw-loss = 0.6962971091270447, train/logprobs = tensor([[-0.7701, -0.8492],
        [-0.8417, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013727456098422408
Epoch 0, Step 115: train/loss = 0.700980544090271, train/raw-loss = 0.700762152671814, train/logprobs = tensor([[-0.7195, -1.0046],
        [-0.7952, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008734557777643204
Epoch 0, Step 116: train/loss = 0.7220746874809265, train/raw-loss = 0.7220518589019775, train/logprobs = tensor([[-0.8505, -0.4944],
        [-1.0475, -0.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.137482265941799e-05
Epoch 0, Step 117: train/loss = 0.7028246521949768, train/raw-loss = 0.7026861906051636, train/logprobs = tensor([[-0.8438, -0.7380],
        [-0.9260, -0.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005539660342037678
Epoch 0, Step 118: train/loss = 0.6996417045593262, train/raw-loss = 0.6995960474014282, train/logprobs = tensor([[-0.5737, -0.7513],
        [-0.6483, -0.7165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018265622202306986
Epoch 0, Step 119: train/loss = 0.6950757503509521, train/raw-loss = 0.6947458982467651, train/logprobs = tensor([[-0.6302, -0.6851],
        [-0.6527, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013193943304941058
Epoch 0, Step 120: train/loss = 0.7260881066322327, train/raw-loss = 0.7258689403533936, train/logprobs = tensor([[-1.0438, -0.9226],
        [-1.2262, -0.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008766546379774809
Epoch 0, Step 121: train/loss = 0.6962646842002869, train/raw-loss = 0.6962274312973022, train/logprobs = tensor([[-0.7030, -0.8241],
        [-0.6855, -0.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014871195890009403
Epoch 0, Step 122: train/loss = 0.7147290706634521, train/raw-loss = 0.7144999504089355, train/logprobs = tensor([[-1.0097, -0.7243],
        [-1.0809, -0.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009162004571408033
Epoch 0, Step 123: train/loss = 0.6938388347625732, train/raw-loss = 0.6938326358795166, train/logprobs = tensor([[-0.7298, -0.7649],
        [-0.7974, -0.7681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.466811565682292e-05
Epoch 0, Step 124: train/loss = 0.7046626806259155, train/raw-loss = 0.7045479416847229, train/logprobs = tensor([[-0.6726, -0.5678],
        [-0.7269, -0.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045891967602074146
Epoch 0, Step 125: train/loss = 0.701158881187439, train/raw-loss = 0.701033353805542, train/logprobs = tensor([[-0.8903, -0.8508],
        [-0.9773, -0.8350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005022457335144281
Epoch 0, Step 126: train/loss = 0.7189046144485474, train/raw-loss = 0.718834638595581, train/logprobs = tensor([[-0.9078, -1.1456],
        [-0.9774, -1.0926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028035073773935437
Epoch 0, Step 127: train/loss = 0.7092928886413574, train/raw-loss = 0.7092291116714478, train/logprobs = tensor([[-0.6867, -0.9024],
        [-0.7012, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000255272607319057
Epoch 0, Step 128: train/loss = 0.7459719777107239, train/raw-loss = 0.7458224892616272, train/logprobs = tensor([[-0.9342, -0.4717],
        [-0.9431, -0.4395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005978299304842949
Epoch 0, Step 129: train/loss = 0.7085320353507996, train/raw-loss = 0.7084681987762451, train/logprobs = tensor([[-0.7943, -0.5874],
        [-0.8114, -0.5541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000255263177677989
Epoch 0, Step 130: train/loss = 0.7084289193153381, train/raw-loss = 0.708204448223114, train/logprobs = tensor([[-0.8518, -0.6888],
        [-0.9601, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008979383273981512
Epoch 0, Step 131: train/loss = 0.6965948343276978, train/raw-loss = 0.6964694261550903, train/logprobs = tensor([[-0.6838, -0.7573],
        [-0.7436, -0.6997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005017555085942149
Epoch 0, Step 132: train/loss = 0.6957900524139404, train/raw-loss = 0.6957511305809021, train/logprobs = tensor([[-0.8239, -0.7741],
        [-0.9122, -0.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001555299968458712
Epoch 0, Step 133: train/loss = 0.697796106338501, train/raw-loss = 0.6977145075798035, train/logprobs = tensor([[-0.6341, -0.7483],
        [-0.7075, -0.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003265568520873785
Epoch 0, Step 134: train/loss = 0.7728545665740967, train/raw-loss = 0.772794783115387, train/logprobs = tensor([[-0.9534, -0.9047],
        [-1.0433, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002390663867117837
Epoch 0, Step 135: train/loss = 0.697424054145813, train/raw-loss = 0.6974120736122131, train/logprobs = tensor([[-0.6026, -0.6134],
        [-0.5840, -0.5958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.804093623533845e-05
Epoch 0, Step 136: train/loss = 0.7024111747741699, train/raw-loss = 0.702405571937561, train/logprobs = tensor([[-0.7867, -0.7237],
        [-1.0755, -0.6798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2375344997271895e-05
Epoch 0, Step 137: train/loss = 0.7147234678268433, train/raw-loss = 0.7129322290420532, train/logprobs = tensor([[-0.5389, -0.8774],
        [-0.5984, -0.7068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007165192160755396
Epoch 0, Step 138: train/loss = 0.7017630338668823, train/raw-loss = 0.7017269730567932, train/logprobs = tensor([[-0.5554, -0.4706],
        [-0.6014, -0.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014453730545938015
Epoch 0, Step 139: train/loss = 0.7098811864852905, train/raw-loss = 0.7097731828689575, train/logprobs = tensor([[-0.5297, -0.7134],
        [-0.5573, -0.7253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004320184816606343
Epoch 0, Step 140: train/loss = 0.716756284236908, train/raw-loss = 0.7167122960090637, train/logprobs = tensor([[-0.6010, -0.8300],
        [-0.6015, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000176084169652313
Epoch 0, Step 141: train/loss = 0.7194642424583435, train/raw-loss = 0.7193591594696045, train/logprobs = tensor([[-0.5080, -0.8304],
        [-0.5600, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042037985986098647
Epoch 0, Step 142: train/loss = 0.7000972628593445, train/raw-loss = 0.6999720335006714, train/logprobs = tensor([[-0.7527, -0.6391],
        [-0.8471, -0.5994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000501083442941308
Epoch 0, Step 143: train/loss = 0.6866202354431152, train/raw-loss = 0.6860177516937256, train/logprobs = tensor([[-0.8270, -0.7935],
        [-1.3143, -0.6836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002410048618912697
Epoch 0, Step 144: train/loss = 0.7203807830810547, train/raw-loss = 0.7199897766113281, train/logprobs = tensor([[-0.7805, -0.7644],
        [-0.8620, -0.7703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015641553327441216
Epoch 0, Step 145: train/loss = 0.7073407173156738, train/raw-loss = 0.7073242664337158, train/logprobs = tensor([[-0.7977, -0.6460],
        [-0.8369, -0.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.572854181285948e-05
Epoch 0, Step 146: train/loss = 0.7657712697982788, train/raw-loss = 0.7656298875808716, train/logprobs = tensor([[-0.8485, -0.5515],
        [-0.9229, -0.5518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000565592956263572
Epoch 0, Step 147: train/loss = 0.7037105560302734, train/raw-loss = 0.7036165595054626, train/logprobs = tensor([[-0.6282, -0.7312],
        [-0.7223, -0.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000376153300749138
Epoch 0, Step 148: train/loss = 0.7072044014930725, train/raw-loss = 0.7072024345397949, train/logprobs = tensor([[-0.6693, -0.4893],
        [-0.6744, -0.4620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.014729246497154e-06
Epoch 0, Step 149: train/loss = 0.6974952816963196, train/raw-loss = 0.6974169015884399, train/logprobs = tensor([[-0.7234, -0.7035],
        [-0.7945, -0.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003134004073217511
Epoch 0, Step 150: train/loss = 0.6959378123283386, train/raw-loss = 0.6959201097488403, train/logprobs = tensor([[-0.6854, -0.6593],
        [-0.7100, -0.6282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.087617996148765e-05
Epoch 0, Step 151: train/loss = 0.696374773979187, train/raw-loss = 0.6963664889335632, train/logprobs = tensor([[-0.7210, -0.7305],
        [-0.7440, -0.6702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.312533954158425e-05
Epoch 0, Step 152: train/loss = 0.7118406891822815, train/raw-loss = 0.7117120027542114, train/logprobs = tensor([[-0.7554, -0.5663],
        [-0.8467, -0.5425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000514744024258107
Epoch 0, Step 153: train/loss = 0.6959353685379028, train/raw-loss = 0.6959184408187866, train/logprobs = tensor([[-0.5514, -0.6714],
        [-0.6087, -0.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.793910870328546e-05
Epoch 0, Step 154: train/loss = 0.6959183216094971, train/raw-loss = 0.6957548260688782, train/logprobs = tensor([[-0.6746, -0.6287],
        [-0.7859, -0.5839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000653998926281929
Epoch 0, Step 155: train/loss = 0.7109473943710327, train/raw-loss = 0.7108621597290039, train/logprobs = tensor([[-0.5568, -0.7831],
        [-0.5705, -0.7341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003411197103559971
Epoch 0, Step 156: train/loss = 0.7082614898681641, train/raw-loss = 0.7082436084747314, train/logprobs = tensor([[-0.5034, -0.6584],
        [-0.5319, -0.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.170606113504618e-05
Epoch 0, Step 157: train/loss = 0.7324393391609192, train/raw-loss = 0.7308197617530823, train/logprobs = tensor([[-0.9211, -0.6502],
        [-0.9619, -0.4712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064783040434122086
Epoch 0, Step 158: train/loss = 0.7454352378845215, train/raw-loss = 0.7453346252441406, train/logprobs = tensor([[-0.9967, -0.5951],
        [-0.9989, -0.5382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040267451549880207
Epoch 0, Step 159: train/loss = 0.7051982879638672, train/raw-loss = 0.7051407694816589, train/logprobs = tensor([[-0.5817, -0.8738],
        [-0.5800, -0.8282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002301560016348958
Epoch 0, Step 160: train/loss = 0.6954284906387329, train/raw-loss = 0.6952270865440369, train/logprobs = tensor([[-0.7787, -0.7237],
        [-0.8530, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008057792438194156
Epoch 0, Step 161: train/loss = 0.691826581954956, train/raw-loss = 0.6911239624023438, train/logprobs = tensor([[-0.6097, -0.6811],
        [-0.6737, -0.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002810487523674965
Epoch 0, Step 162: train/loss = 0.7030859589576721, train/raw-loss = 0.7025822401046753, train/logprobs = tensor([[-0.8000, -0.8164],
        [-0.9068, -0.5763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020148339681327343
Epoch 0, Step 163: train/loss = 0.7012214064598083, train/raw-loss = 0.7011781930923462, train/logprobs = tensor([[-0.8474, -0.7185],
        [-0.9926, -0.7252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017285317881032825
Epoch 0, Step 164: train/loss = 0.7098948955535889, train/raw-loss = 0.7097803950309753, train/logprobs = tensor([[-0.6792, -0.9549],
        [-0.7563, -0.7909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004580327367875725
Epoch 0, Step 165: train/loss = 0.8077379465103149, train/raw-loss = 0.8076411485671997, train/logprobs = tensor([[-0.8510, -1.3733],
        [-0.9404, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000387196138035506
Epoch 0, Step 166: train/loss = 0.7086542844772339, train/raw-loss = 0.7085650563240051, train/logprobs = tensor([[-0.7890, -0.8370],
        [-0.8225, -0.7516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003566276282072067
Epoch 0, Step 167: train/loss = 0.6998147368431091, train/raw-loss = 0.699624240398407, train/logprobs = tensor([[-0.6624, -0.7660],
        [-0.6998, -0.7089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007621414843015373
Epoch 0, Step 168: train/loss = 0.6951261758804321, train/raw-loss = 0.6950955986976624, train/logprobs = tensor([[-0.6721, -0.7370],
        [-0.7131, -0.7149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012242456432431936
Epoch 0, Step 169: train/loss = 0.6944501996040344, train/raw-loss = 0.6943848133087158, train/logprobs = tensor([[-0.5313, -0.5043],
        [-0.5514, -0.4994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002616036217659712
Epoch 0, Step 170: train/loss = 0.6949015259742737, train/raw-loss = 0.6948564052581787, train/logprobs = tensor([[-0.7199, -0.6921],
        [-0.7567, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018036639085039496
Epoch 0, Step 171: train/loss = 0.6978482007980347, train/raw-loss = 0.6975363492965698, train/logprobs = tensor([[-0.6020, -0.7308],
        [-0.6366, -0.7374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012470870278775692
Epoch 0, Step 172: train/loss = 0.7249689102172852, train/raw-loss = 0.7249609231948853, train/logprobs = tensor([[-0.9599, -0.7808],
        [-1.0385, -0.7732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.19451792165637e-05
Epoch 0, Step 173: train/loss = 0.7022687196731567, train/raw-loss = 0.6999406814575195, train/logprobs = tensor([[-0.6794, -0.9887],
        [-0.6462, -0.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009312045760452747
Epoch 0, Step 174: train/loss = 0.6884849071502686, train/raw-loss = 0.6867048144340515, train/logprobs = tensor([[-0.6135, -0.7509],
        [-0.7033, -0.5683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007120543159544468
Epoch 0, Step 175: train/loss = 0.6988828182220459, train/raw-loss = 0.698517382144928, train/logprobs = tensor([[-0.8965, -0.8984],
        [-0.9976, -0.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014616526896134019
Epoch 0, Step 176: train/loss = 0.6993021368980408, train/raw-loss = 0.6990069150924683, train/logprobs = tensor([[-0.7989, -0.8091],
        [-0.8571, -0.6726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011809775605797768
Epoch 0, Step 177: train/loss = 0.6963653564453125, train/raw-loss = 0.6962946653366089, train/logprobs = tensor([[-0.8406, -0.8181],
        [-0.9630, -0.7420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002829146687872708
Epoch 0, Step 178: train/loss = 0.6822724938392639, train/raw-loss = 0.6746857166290283, train/logprobs = tensor([[-0.7043, -1.3705],
        [-0.8489, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030347516760230064
Epoch 0, Step 179: train/loss = 0.6988479495048523, train/raw-loss = 0.6987874507904053, train/logprobs = tensor([[-0.6058, -0.5527],
        [-0.5905, -0.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024178600870072842
Epoch 0, Step 180: train/loss = 0.7173460721969604, train/raw-loss = 0.7168726921081543, train/logprobs = tensor([[-0.7255, -0.6371],
        [-0.8274, -0.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018930351361632347
Epoch 0, Step 181: train/loss = 0.7029439806938171, train/raw-loss = 0.7024633884429932, train/logprobs = tensor([[-0.6861, -0.7419],
        [-0.7209, -0.6228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019221835536882281
Epoch 0, Step 182: train/loss = 0.7082723379135132, train/raw-loss = 0.7082192897796631, train/logprobs = tensor([[-0.8120, -0.9848],
        [-0.8287, -0.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021193729480728507
Epoch 0, Step 183: train/loss = 0.6993898153305054, train/raw-loss = 0.6989054083824158, train/logprobs = tensor([[-0.7173, -0.8362],
        [-0.7808, -0.8175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019376189447939396
Epoch 0, Step 184: train/loss = 0.700623631477356, train/raw-loss = 0.7005559206008911, train/logprobs = tensor([[-0.7986, -0.7063],
        [-0.8451, -0.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002708622778300196
Epoch 0, Step 185: train/loss = 0.6929678916931152, train/raw-loss = 0.6925923824310303, train/logprobs = tensor([[-0.7694, -1.0927],
        [-0.8025, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015019233105704188
Epoch 0, Step 186: train/loss = 0.703529953956604, train/raw-loss = 0.7034386396408081, train/logprobs = tensor([[-0.8937, -0.7631],
        [-0.9121, -0.6556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000365085550583899
Epoch 0, Step 187: train/loss = 0.6939990520477295, train/raw-loss = 0.6934213042259216, train/logprobs = tensor([[-0.6651, -0.7493],
        [-0.7360, -0.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023111305199563503
Epoch 0, Step 188: train/loss = 0.7032186985015869, train/raw-loss = 0.7031849026679993, train/logprobs = tensor([[-0.7209, -0.8076],
        [-0.7626, -0.7871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001353143888991326
Epoch 0, Step 189: train/loss = 0.7056330442428589, train/raw-loss = 0.7055620551109314, train/logprobs = tensor([[-0.5358, -0.6694],
        [-0.6844, -0.6334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002840911038219929
Epoch 0, Step 190: train/loss = 0.6932811141014099, train/raw-loss = 0.6929847002029419, train/logprobs = tensor([[-0.5602, -0.6606],
        [-0.6536, -0.5217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011855020420625806
Epoch 0, Step 191: train/loss = 0.6950026750564575, train/raw-loss = 0.695001482963562, train/logprobs = tensor([[-0.7712, -0.7134],
        [-0.7469, -0.6914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8881565817282535e-06
Epoch 0, Step 192: train/loss = 0.6937752962112427, train/raw-loss = 0.6936776041984558, train/logprobs = tensor([[-0.6280, -0.6007],
        [-0.6774, -0.5668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003907903446815908
Epoch 0, Step 193: train/loss = 0.7048076391220093, train/raw-loss = 0.70445716381073, train/logprobs = tensor([[-0.5745, -0.9408],
        [-0.7072, -0.8216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014021581737324595
Epoch 0, Step 194: train/loss = 0.7180062532424927, train/raw-loss = 0.7149284482002258, train/logprobs = tensor([[-0.7547, -1.1673],
        [-0.9264, -0.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012311317026615143
Epoch 0, Step 195: train/loss = 0.7440558075904846, train/raw-loss = 0.7439399361610413, train/logprobs = tensor([[-1.0349, -0.8419],
        [-1.1070, -0.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046330259647220373
Epoch 0, Step 196: train/loss = 0.6936667561531067, train/raw-loss = 0.6923853158950806, train/logprobs = tensor([[-0.9835, -0.9726],
        [-1.0374, -0.6904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005125759169459343
Epoch 0, Step 197: train/loss = 0.7209925055503845, train/raw-loss = 0.7207629084587097, train/logprobs = tensor([[-0.6182, -0.9385],
        [-0.6687, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009184905211441219
Epoch 0, Step 198: train/loss = 0.7274937033653259, train/raw-loss = 0.7268527746200562, train/logprobs = tensor([[-1.2971, -1.1680],
        [-1.3161, -1.0310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025637964718043804
Epoch 0, Step 199: train/loss = 0.7033407688140869, train/raw-loss = 0.7025623321533203, train/logprobs = tensor([[-0.8459, -0.8718],
        [-0.9076, -0.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031139233615249395
Epoch 0, Step 200: train/loss = 0.6952112317085266, train/raw-loss = 0.6949830055236816, train/logprobs = tensor([[-0.7808, -0.8295],
        [-0.8034, -0.8103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009126649238169193
Epoch 0, Step 201: train/loss = 0.6997891664505005, train/raw-loss = 0.697426438331604, train/logprobs = tensor([[-0.7635, -1.2539],
        [-0.9436, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009450646117329597
Epoch 0, Step 202: train/loss = 0.6965458393096924, train/raw-loss = 0.6962875127792358, train/logprobs = tensor([[-0.9953, -0.9058],
        [-0.9993, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010331618832424283
Epoch 0, Step 203: train/loss = 0.6984586715698242, train/raw-loss = 0.697281002998352, train/logprobs = tensor([[-0.7139, -0.9224],
        [-0.8131, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004710668232291937
Epoch 0, Step 204: train/loss = 0.7030754685401917, train/raw-loss = 0.7016642093658447, train/logprobs = tensor([[-0.8115, -1.0504],
        [-0.8568, -0.8143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005645013879984617
Epoch 0, Step 205: train/loss = 0.7008982300758362, train/raw-loss = 0.7008634805679321, train/logprobs = tensor([[-0.8330, -0.6904],
        [-0.8864, -0.6574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001390523393638432
Epoch 0, Step 206: train/loss = 0.6979213953018188, train/raw-loss = 0.6978943943977356, train/logprobs = tensor([[-0.6219, -0.5064],
        [-0.6980, -0.5370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010798592120409012
Epoch 0, Step 207: train/loss = 0.6969466805458069, train/raw-loss = 0.6966659426689148, train/logprobs = tensor([[-0.6981, -0.9384],
        [-0.7505, -0.8102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011228960938751698
Epoch 0, Step 208: train/loss = 0.6959991455078125, train/raw-loss = 0.6957720518112183, train/logprobs = tensor([[-0.6701, -0.6938],
        [-0.6626, -0.6014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009083435288630426
Epoch 0, Step 209: train/loss = 0.7567629814147949, train/raw-loss = 0.7564128637313843, train/logprobs = tensor([[-0.7994, -1.1373],
        [-0.8065, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014006115961819887
Epoch 0, Step 210: train/loss = 0.694013774394989, train/raw-loss = 0.6940015554428101, train/logprobs = tensor([[-0.6654, -0.6936],
        [-0.6769, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.8693425924284384e-05
Epoch 0, Step 211: train/loss = 0.7001952528953552, train/raw-loss = 0.7000861763954163, train/logprobs = tensor([[-0.7316, -0.7068],
        [-0.7705, -0.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004361388273537159
Epoch 0, Step 212: train/loss = 0.7084667682647705, train/raw-loss = 0.7072511911392212, train/logprobs = tensor([[-0.7176, -0.9404],
        [-0.7934, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004862358793616295
Epoch 0, Step 213: train/loss = 0.7934424877166748, train/raw-loss = 0.7900868654251099, train/logprobs = tensor([[-0.8196, -1.3262],
        [-0.9363, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013422699645161629
Epoch 0, Step 214: train/loss = 0.6971081495285034, train/raw-loss = 0.697085976600647, train/logprobs = tensor([[-0.6156, -0.5219],
        [-0.7362, -0.5561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.86435154825449e-05
Epoch 0, Step 215: train/loss = 0.7024445533752441, train/raw-loss = 0.7021031975746155, train/logprobs = tensor([[-0.6435, -0.8565],
        [-0.6526, -0.7467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013653496280312538
Epoch 0, Step 216: train/loss = 0.7146216034889221, train/raw-loss = 0.7130845785140991, train/logprobs = tensor([[-0.8276, -1.0512],
        [-0.8276, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006147973705083132
Epoch 0, Step 217: train/loss = 0.6945250034332275, train/raw-loss = 0.6942642331123352, train/logprobs = tensor([[-0.6861, -0.6580],
        [-0.8348, -0.5854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001042999210767448
Epoch 0, Step 218: train/loss = 0.7112137675285339, train/raw-loss = 0.710796594619751, train/logprobs = tensor([[-0.9433, -0.7842],
        [-1.0160, -0.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001668628421612084
Epoch 0, Step 219: train/loss = 0.714733362197876, train/raw-loss = 0.714417576789856, train/logprobs = tensor([[-0.6612, -0.9613],
        [-0.8390, -0.9470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012631808640435338
Epoch 0, Step 220: train/loss = 0.7000942230224609, train/raw-loss = 0.698820948600769, train/logprobs = tensor([[-0.7965, -1.0284],
        [-0.8457, -0.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005092899780720472
Epoch 0, Step 221: train/loss = 0.6951203346252441, train/raw-loss = 0.6942002773284912, train/logprobs = tensor([[-0.7888, -0.7781],
        [-0.8012, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003680265974253416
Epoch 0, Step 222: train/loss = 0.694122850894928, train/raw-loss = 0.6937390565872192, train/logprobs = tensor([[-0.6986, -0.7123],
        [-0.8102, -0.6963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001535186660476029
Epoch 0, Step 223: train/loss = 0.7045342922210693, train/raw-loss = 0.7042394876480103, train/logprobs = tensor([[-0.7432, -0.6238],
        [-0.8180, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011792306322604418
Epoch 0, Step 224: train/loss = 0.7387589812278748, train/raw-loss = 0.7373764514923096, train/logprobs = tensor([[-1.1926, -1.1494],
        [-1.2935, -0.9944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005529831163585186
Epoch 0, Step 225: train/loss = 0.7217375636100769, train/raw-loss = 0.7204259634017944, train/logprobs = tensor([[-0.9050, -1.2055],
        [-1.0702, -0.9076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005246461369097233
Epoch 0, Step 226: train/loss = 0.7154597043991089, train/raw-loss = 0.7149931192398071, train/logprobs = tensor([[-0.9524, -0.8327],
        [-1.0456, -0.6894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018660768400877714
Epoch 0, Step 227: train/loss = 0.7070229053497314, train/raw-loss = 0.7037774324417114, train/logprobs = tensor([[-0.6607, -1.2848],
        [-0.7314, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01298190001398325
Epoch 0, Step 228: train/loss = 0.6838507652282715, train/raw-loss = 0.6777490973472595, train/logprobs = tensor([[-1.0360, -1.4629],
        [-0.9225, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024406440556049347
Epoch 0, Step 229: train/loss = 0.6997146010398865, train/raw-loss = 0.6992563009262085, train/logprobs = tensor([[-0.7210, -1.0066],
        [-0.7252, -0.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018330351449549198
Epoch 0, Step 230: train/loss = 0.72762131690979, train/raw-loss = 0.7244588732719421, train/logprobs = tensor([[-0.6198, -1.3622],
        [-0.6365, -0.9220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012650036253035069
Epoch 0, Step 231: train/loss = 0.6959542632102966, train/raw-loss = 0.6955501437187195, train/logprobs = tensor([[-0.5783, -0.6964],
        [-0.6125, -0.6101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016166947316378355
Epoch 0, Step 232: train/loss = 0.7053219079971313, train/raw-loss = 0.7051570415496826, train/logprobs = tensor([[-0.7546, -0.9137],
        [-0.7858, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006597158499062061
Epoch 0, Step 233: train/loss = 0.6894077062606812, train/raw-loss = 0.68341064453125, train/logprobs = tensor([[-0.7657, -1.1746],
        [-0.8435, -0.7737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023988476023077965
Epoch 0, Step 234: train/loss = 0.7089178562164307, train/raw-loss = 0.7085290551185608, train/logprobs = tensor([[-0.9476, -0.7751],
        [-1.0424, -0.7263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015551808755844831
Epoch 0, Step 235: train/loss = 0.6934970617294312, train/raw-loss = 0.6929612159729004, train/logprobs = tensor([[-0.7394, -0.7763],
        [-0.8204, -0.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002143013058230281
Epoch 0, Step 236: train/loss = 0.7097965478897095, train/raw-loss = 0.7007063627243042, train/logprobs = tensor([[-1.1112, -1.8486],
        [-0.9404, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03636077046394348
Epoch 0, Step 237: train/loss = 0.6949366927146912, train/raw-loss = 0.6931055784225464, train/logprobs = tensor([[-0.8198, -0.9373],
        [-0.8090, -0.6547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007324861362576485
Epoch 0, Step 238: train/loss = 0.7082687616348267, train/raw-loss = 0.7063120007514954, train/logprobs = tensor([[-0.6484, -0.8361],
        [-0.6782, -0.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007826747372746468
Epoch 0, Step 239: train/loss = 0.7049083113670349, train/raw-loss = 0.7046099305152893, train/logprobs = tensor([[-0.7983, -0.7710],
        [-0.8574, -0.6485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011937106028199196
Epoch 0, Step 240: train/loss = 0.6986843347549438, train/raw-loss = 0.6986292600631714, train/logprobs = tensor([[-0.9338, -0.8487],
        [-0.8989, -0.7655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022017810260877013
Epoch 0, Step 241: train/loss = 0.7533663511276245, train/raw-loss = 0.7508556246757507, train/logprobs = tensor([[-1.0084, -1.2223],
        [-1.1025, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010042999871075153
Epoch 0, Step 242: train/loss = 0.6931632161140442, train/raw-loss = 0.6824876070022583, train/logprobs = tensor([[-0.8566, -1.4908],
        [-1.0244, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04270215705037117
Epoch 0, Step 243: train/loss = 0.7042039632797241, train/raw-loss = 0.7017476558685303, train/logprobs = tensor([[-0.9823, -1.4622],
        [-1.0743, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009825432673096657
Epoch 0, Step 244: train/loss = 0.6940435767173767, train/raw-loss = 0.6925604939460754, train/logprobs = tensor([[-0.8603, -1.1160],
        [-0.8492, -0.8174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005932055413722992
Epoch 0, Step 245: train/loss = 0.7407519817352295, train/raw-loss = 0.7404216527938843, train/logprobs = tensor([[-0.7250, -1.1671],
        [-0.7864, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013215041253715754
Epoch 0, Step 246: train/loss = 0.7240427732467651, train/raw-loss = 0.7220691442489624, train/logprobs = tensor([[-1.0280, -0.7252],
        [-1.2534, -0.5756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00789463147521019
Epoch 0, Step 247: train/loss = 0.7083978652954102, train/raw-loss = 0.7081069946289062, train/logprobs = tensor([[-0.6865, -0.9056],
        [-0.7380, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011636237613856792
Epoch 0, Step 248: train/loss = 0.7185487747192383, train/raw-loss = 0.7177264094352722, train/logprobs = tensor([[-0.9861, -1.5110],
        [-0.9490, -1.2353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003289524232968688
Epoch 0, Step 249: train/loss = 0.6951161026954651, train/raw-loss = 0.6950961351394653, train/logprobs = tensor([[-0.6397, -0.8044],
        [-0.6272, -0.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.00896596047096e-05
Epoch 0, Step 250: train/loss = 0.6946038603782654, train/raw-loss = 0.693980872631073, train/logprobs = tensor([[-0.6919, -0.8677],
        [-0.8325, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024921190924942493
Epoch 0, Step 251: train/loss = 0.7167451977729797, train/raw-loss = 0.7134810090065002, train/logprobs = tensor([[-0.8743, -1.4061],
        [-0.9520, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01305689662694931
Epoch 0, Step 252: train/loss = 0.7136983871459961, train/raw-loss = 0.7136214971542358, train/logprobs = tensor([[-0.7275, -0.9343],
        [-0.7695, -0.7807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030730327125638723
Epoch 0, Step 253: train/loss = 0.7035025954246521, train/raw-loss = 0.7013429999351501, train/logprobs = tensor([[-0.9604, -0.8684],
        [-1.0587, -0.6788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008638054132461548
Epoch 0, Step 254: train/loss = 0.7144379615783691, train/raw-loss = 0.7128303050994873, train/logprobs = tensor([[-0.8333, -1.3775],
        [-0.9265, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006430532317608595
Epoch 0, Step 255: train/loss = 0.7132604122161865, train/raw-loss = 0.7122220396995544, train/logprobs = tensor([[-0.6076, -0.7654],
        [-0.8456, -0.6135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004153532907366753
Epoch 0, Step 256: train/loss = 0.696300745010376, train/raw-loss = 0.6959600448608398, train/logprobs = tensor([[-1.1108, -1.0697],
        [-0.9914, -0.8253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001363177434541285
Epoch 0, Step 257: train/loss = 0.6910920143127441, train/raw-loss = 0.6887984275817871, train/logprobs = tensor([[-0.9984, -1.3205],
        [-0.9390, -0.8309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009174454025924206
Epoch 0, Step 258: train/loss = 0.6876416206359863, train/raw-loss = 0.6803796291351318, train/logprobs = tensor([[-0.8360, -1.4269],
        [-1.1733, -0.8051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02904803678393364
Epoch 0, Step 259: train/loss = 0.6946704387664795, train/raw-loss = 0.6937090754508972, train/logprobs = tensor([[-0.7158, -0.9573],
        [-0.7023, -0.6991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038454928435385227
Epoch 0, Step 260: train/loss = 0.7119659781455994, train/raw-loss = 0.707309365272522, train/logprobs = tensor([[-0.8332, -1.3380],
        [-0.8805, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018626175820827484
Epoch 0, Step 261: train/loss = 0.7111706733703613, train/raw-loss = 0.7107740044593811, train/logprobs = tensor([[-0.8388, -1.1923],
        [-0.8590, -1.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015865260502323508
Epoch 0, Step 262: train/loss = 0.7124900817871094, train/raw-loss = 0.709447979927063, train/logprobs = tensor([[-1.1166, -1.2066],
        [-1.1549, -0.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012168502435088158
Epoch 0, Step 263: train/loss = 0.6944291591644287, train/raw-loss = 0.6944259405136108, train/logprobs = tensor([[-0.5625, -0.5626],
        [-0.5709, -0.5458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2929478543810546e-05
Epoch 0, Step 264: train/loss = 0.7307529449462891, train/raw-loss = 0.7282739877700806, train/logprobs = tensor([[-0.7339, -1.3863],
        [-0.7767, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009915851056575775
Epoch 0, Step 265: train/loss = 0.7207891941070557, train/raw-loss = 0.7186036705970764, train/logprobs = tensor([[-0.9525, -1.5158],
        [-0.9339, -1.1357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008741834200918674
Epoch 0, Step 266: train/loss = 0.7325232028961182, train/raw-loss = 0.7296351194381714, train/logprobs = tensor([[-1.0703, -1.2305],
        [-1.1001, -0.7880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01155213825404644
Epoch 0, Step 267: train/loss = 0.6996285319328308, train/raw-loss = 0.6990984082221985, train/logprobs = tensor([[-0.7780, -0.9937],
        [-0.7076, -0.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021205744706094265
Epoch 0, Step 268: train/loss = 0.82121741771698, train/raw-loss = 0.8209048509597778, train/logprobs = tensor([[-0.9878, -1.8199],
        [-0.7161, -1.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012500851880759
Epoch 0, Step 269: train/loss = 0.6967546343803406, train/raw-loss = 0.6946424841880798, train/logprobs = tensor([[-0.8035, -1.1821],
        [-0.8101, -0.9055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00844857282936573
Epoch 0, Step 270: train/loss = 0.7165053486824036, train/raw-loss = 0.7145215272903442, train/logprobs = tensor([[-0.6215, -1.1957],
        [-0.6094, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007935098372399807
Epoch 0, Step 271: train/loss = 0.7012903690338135, train/raw-loss = 0.7010928392410278, train/logprobs = tensor([[-1.1048, -1.0199],
        [-1.1296, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007901431526988745
Epoch 0, Step 272: train/loss = 0.697600781917572, train/raw-loss = 0.6972259283065796, train/logprobs = tensor([[-0.9440, -0.8187],
        [-1.0028, -0.7248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014993485528975725
Epoch 0, Step 273: train/loss = 0.6922342777252197, train/raw-loss = 0.6899322271347046, train/logprobs = tensor([[-0.8192, -1.0551],
        [-0.8601, -0.7339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009208125062286854
Epoch 0, Step 274: train/loss = 0.8072497844696045, train/raw-loss = 0.7977904677391052, train/logprobs = tensor([[-0.8206, -1.8049],
        [-0.8282, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03783741593360901
Epoch 0, Step 275: train/loss = 0.6987921595573425, train/raw-loss = 0.698406457901001, train/logprobs = tensor([[-0.7286, -0.9309],
        [-0.7295, -0.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001542876474559307
Epoch 0, Step 276: train/loss = 0.7142791152000427, train/raw-loss = 0.7131251096725464, train/logprobs = tensor([[-0.8255, -1.0184],
        [-0.8227, -0.7699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004615889862179756
Epoch 0, Step 277: train/loss = 0.6928174495697021, train/raw-loss = 0.69252610206604, train/logprobs = tensor([[-1.0895, -1.1888],
        [-0.8378, -0.8343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011654329719021916
Epoch 0, Step 278: train/loss = 0.6962451338768005, train/raw-loss = 0.693416953086853, train/logprobs = tensor([[-0.8186, -1.2253],
        [-0.7719, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011312728747725487
Epoch 0, Step 279: train/loss = 0.6938504576683044, train/raw-loss = 0.6936596035957336, train/logprobs = tensor([[-1.1033, -1.2876],
        [-1.1753, -1.2144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007633357890881598
Epoch 0, Step 280: train/loss = 0.7154738306999207, train/raw-loss = 0.7139662504196167, train/logprobs = tensor([[-0.7565, -1.0415],
        [-0.9181, -0.7387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006030247081071138
Epoch 0, Step 281: train/loss = 0.6919146776199341, train/raw-loss = 0.6903077363967896, train/logprobs = tensor([[-1.1897, -1.4766],
        [-1.0542, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006428041495382786
Epoch 0, Step 282: train/loss = 0.6995468139648438, train/raw-loss = 0.6995223760604858, train/logprobs = tensor([[-0.9543, -0.8838],
        [-0.8085, -0.7357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.777028753887862e-05
Epoch 0, Step 283: train/loss = 0.6842309236526489, train/raw-loss = 0.6816377639770508, train/logprobs = tensor([[-1.0088, -1.2006],
        [-1.1821, -0.9123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01037287712097168
Epoch 0, Step 284: train/loss = 0.700654149055481, train/raw-loss = 0.7005819082260132, train/logprobs = tensor([[-0.7969, -0.6400],
        [-0.7456, -0.5323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028909998945891857
Epoch 0, Step 285: train/loss = 0.7065807580947876, train/raw-loss = 0.7053185105323792, train/logprobs = tensor([[-1.4105, -1.3407],
        [-1.3143, -0.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005048663821071386
Epoch 0, Step 286: train/loss = 0.6941165924072266, train/raw-loss = 0.6940533518791199, train/logprobs = tensor([[-0.6559, -0.6534],
        [-0.5155, -0.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025324622401967645
Epoch 0, Step 287: train/loss = 0.7212828397750854, train/raw-loss = 0.713777482509613, train/logprobs = tensor([[-0.9430, -1.5250],
        [-0.8642, -0.8028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03002159856259823
Epoch 0, Step 288: train/loss = 0.6900489330291748, train/raw-loss = 0.680800199508667, train/logprobs = tensor([[-0.9336, -1.5358],
        [-1.0827, -1.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036994658410549164
Epoch 0, Step 289: train/loss = 0.696738600730896, train/raw-loss = 0.6952450275421143, train/logprobs = tensor([[-0.8774, -1.1210],
        [-1.0013, -0.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005974427796900272
Epoch 0, Step 290: train/loss = 0.7213678956031799, train/raw-loss = 0.7208699584007263, train/logprobs = tensor([[-1.1438, -0.8825],
        [-1.1275, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019916957244277
Epoch 0, Step 291: train/loss = 0.6942484974861145, train/raw-loss = 0.6927540898323059, train/logprobs = tensor([[-0.9358, -1.2129],
        [-0.9315, -0.9223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005977611988782883
Epoch 0, Step 292: train/loss = 0.6997262835502625, train/raw-loss = 0.6982882022857666, train/logprobs = tensor([[-0.6060, -0.8934],
        [-0.6584, -0.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005752322264015675
Epoch 0, Step 293: train/loss = 0.6873180270195007, train/raw-loss = 0.6833111047744751, train/logprobs = tensor([[-0.8340, -0.9711],
        [-0.8990, -0.6625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016027560457587242
Epoch 0, Step 294: train/loss = 0.7002072930335999, train/raw-loss = 0.696777880191803, train/logprobs = tensor([[-0.9496, -1.4282],
        [-0.9776, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013717567548155785
Epoch 0, Step 295: train/loss = 0.7054389119148254, train/raw-loss = 0.7052004337310791, train/logprobs = tensor([[-0.8200, -0.7328],
        [-0.8256, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009534573182463646
Epoch 0, Step 296: train/loss = 0.6935936212539673, train/raw-loss = 0.6926275491714478, train/logprobs = tensor([[-0.9209, -1.0011],
        [-0.9980, -0.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003864310448989272
Epoch 0, Step 297: train/loss = 0.7066707611083984, train/raw-loss = 0.705814003944397, train/logprobs = tensor([[-1.0197, -1.2391],
        [-1.1933, -1.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003427049145102501
Epoch 0, Step 298: train/loss = 0.6806043386459351, train/raw-loss = 0.6716696619987488, train/logprobs = tensor([[-0.8729, -1.4838],
        [-0.9870, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035738784819841385
Epoch 0, Step 299: train/loss = 0.6947281360626221, train/raw-loss = 0.6941869258880615, train/logprobs = tensor([[-0.6959, -0.7391],
        [-0.7384, -0.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021647601388394833
Epoch 0, Step 300: train/loss = 0.7201157212257385, train/raw-loss = 0.701764702796936, train/logprobs = tensor([[-0.7919, -1.7184],
        [-0.9705, -0.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07340414077043533
Epoch 0, Step 301: train/loss = 0.6996604800224304, train/raw-loss = 0.6993512511253357, train/logprobs = tensor([[-0.8653, -0.9270],
        [-0.7892, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001236789277754724
Epoch 0, Step 302: train/loss = 0.6977820992469788, train/raw-loss = 0.6967005729675293, train/logprobs = tensor([[-0.9376, -0.8908],
        [-1.0367, -0.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043262094259262085
Epoch 0, Step 303: train/loss = 0.6935932636260986, train/raw-loss = 0.6926552057266235, train/logprobs = tensor([[-0.8968, -1.1511],
        [-0.9446, -0.9163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003752391319721937
Epoch 0, Step 304: train/loss = 0.705918550491333, train/raw-loss = 0.7011129260063171, train/logprobs = tensor([[-0.9016, -1.3160],
        [-0.9948, -0.9592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01922260783612728
Epoch 0, Step 305: train/loss = 0.7178904414176941, train/raw-loss = 0.7173311710357666, train/logprobs = tensor([[-1.0354, -1.2346],
        [-0.9805, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022372608073055744
Epoch 0, Step 306: train/loss = 0.6954156160354614, train/raw-loss = 0.694555401802063, train/logprobs = tensor([[-0.8169, -0.9054],
        [-0.9538, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003440807107836008
Epoch 0, Step 307: train/loss = 0.6989160776138306, train/raw-loss = 0.6970812082290649, train/logprobs = tensor([[-0.8360, -0.9753],
        [-0.9544, -0.7319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007339348550885916
Epoch 0, Step 308: train/loss = 0.6912670135498047, train/raw-loss = 0.6896877288818359, train/logprobs = tensor([[-0.6722, -0.8654],
        [-0.7680, -0.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0063172597438097
Epoch 0, Step 309: train/loss = 0.6940011978149414, train/raw-loss = 0.6705269813537598, train/logprobs = tensor([[-0.9799, -1.9602],
        [-1.1302, -0.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09389681369066238
Epoch 0, Step 310: train/loss = 0.6931579113006592, train/raw-loss = 0.6902010440826416, train/logprobs = tensor([[-0.7765, -1.0760],
        [-0.9197, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011827724054455757
Epoch 0, Step 311: train/loss = 0.6986420750617981, train/raw-loss = 0.6979637145996094, train/logprobs = tensor([[-0.8279, -0.7772],
        [-0.8056, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027131373062729836
Epoch 0, Step 312: train/loss = 0.7030575275421143, train/raw-loss = 0.6963789463043213, train/logprobs = tensor([[-0.8539, -1.4287],
        [-0.9227, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026714280247688293
Epoch 0, Step 313: train/loss = 0.6968119740486145, train/raw-loss = 0.6966068148612976, train/logprobs = tensor([[-0.7447, -0.7314],
        [-0.9120, -0.7167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008207091595977545
Epoch 0, Step 314: train/loss = 0.7002182006835938, train/raw-loss = 0.6975264549255371, train/logprobs = tensor([[-1.1236, -1.3631],
        [-1.2312, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010766977444291115
Epoch 0, Step 315: train/loss = 0.7071728706359863, train/raw-loss = 0.7061518430709839, train/logprobs = tensor([[-0.7947, -1.1436],
        [-1.0443, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00408425647765398
Epoch 0, Step 316: train/loss = 0.7213852405548096, train/raw-loss = 0.7197654843330383, train/logprobs = tensor([[-1.1297, -0.9225],
        [-1.3175, -0.7132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006478998344391584
Epoch 0, Step 317: train/loss = 0.6942378282546997, train/raw-loss = 0.6935369968414307, train/logprobs = tensor([[-0.9353, -1.0251],
        [-0.9839, -0.8273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028034881688654423
Epoch 0, Step 318: train/loss = 0.6845755577087402, train/raw-loss = 0.6804108619689941, train/logprobs = tensor([[-0.8778, -1.1442],
        [-1.0261, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0166588444262743
Epoch 0, Step 319: train/loss = 0.704291045665741, train/raw-loss = 0.7002052068710327, train/logprobs = tensor([[-1.2680, -1.6865],
        [-1.0007, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016343258321285248
Epoch 0, Step 320: train/loss = 0.7046716213226318, train/raw-loss = 0.7028294801712036, train/logprobs = tensor([[-0.9961, -1.3025],
        [-1.0410, -1.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007368283811956644
Epoch 0, Step 321: train/loss = 0.6916994452476501, train/raw-loss = 0.6884298324584961, train/logprobs = tensor([[-0.8313, -0.9293],
        [-0.8931, -0.7137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013078426942229271
Epoch 0, Step 322: train/loss = 0.7015451788902283, train/raw-loss = 0.7004013061523438, train/logprobs = tensor([[-1.0357, -1.2203],
        [-1.0294, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004575572442263365
Epoch 0, Step 323: train/loss = 0.6968375444412231, train/raw-loss = 0.6954147815704346, train/logprobs = tensor([[-0.8574, -0.8697],
        [-0.9703, -0.7355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005690981168299913
Epoch 0, Step 324: train/loss = 0.7446273565292358, train/raw-loss = 0.7418844699859619, train/logprobs = tensor([[-1.0014, -1.1749],
        [-1.2896, -0.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010971819050610065
Epoch 0, Step 325: train/loss = 0.6941699981689453, train/raw-loss = 0.6936946511268616, train/logprobs = tensor([[-0.9138, -0.9535],
        [-1.0935, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001901421695947647
Epoch 0, Step 326: train/loss = 0.6861904859542847, train/raw-loss = 0.6780030727386475, train/logprobs = tensor([[-1.3430, -1.8122],
        [-1.5141, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03274957463145256
Epoch 0, Step 327: train/loss = 0.6997171640396118, train/raw-loss = 0.6991196274757385, train/logprobs = tensor([[-0.9501, -0.9389],
        [-1.0235, -0.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002389910165220499
Epoch 0, Step 328: train/loss = 0.7169290781021118, train/raw-loss = 0.7061262130737305, train/logprobs = tensor([[-1.1090, -1.3788],
        [-1.4717, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0432116836309433
Epoch 0, Step 329: train/loss = 0.6956353187561035, train/raw-loss = 0.6941876411437988, train/logprobs = tensor([[-0.7754, -0.7735],
        [-0.7899, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005790725350379944
Epoch 0, Step 330: train/loss = 0.7204200029373169, train/raw-loss = 0.7182399034500122, train/logprobs = tensor([[-0.7794, -1.2987],
        [-0.9920, -1.2292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00872031319886446
Epoch 0, Step 331: train/loss = 0.7155268788337708, train/raw-loss = 0.7130854725837708, train/logprobs = tensor([[-0.9890, -0.8382],
        [-1.0494, -0.5793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009765674360096455
Epoch 0, Step 332: train/loss = 0.6887710094451904, train/raw-loss = 0.6869884729385376, train/logprobs = tensor([[-0.9985, -1.0915],
        [-1.1737, -0.7732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007130226120352745
Epoch 0, Step 333: train/loss = 0.7016969919204712, train/raw-loss = 0.7007314562797546, train/logprobs = tensor([[-0.8336, -1.0092],
        [-0.8402, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038619725964963436
Epoch 0, Step 334: train/loss = 0.7008463740348816, train/raw-loss = 0.7002788782119751, train/logprobs = tensor([[-0.9730, -1.2849],
        [-1.1811, -1.1846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022699483670294285
Epoch 0, Step 335: train/loss = 0.6879851818084717, train/raw-loss = 0.6838748455047607, train/logprobs = tensor([[-1.0969, -1.2539],
        [-1.3560, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01644139364361763
Epoch 0, Step 336: train/loss = 0.6967741250991821, train/raw-loss = 0.6857545375823975, train/logprobs = tensor([[-0.9050, -1.4732],
        [-1.0649, -0.8263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044078417122364044
Epoch 0, Step 337: train/loss = 0.6971481442451477, train/raw-loss = 0.6954997777938843, train/logprobs = tensor([[-1.0013, -1.3644],
        [-1.1746, -1.1554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006593569181859493
Epoch 0, Step 338: train/loss = 0.6836464405059814, train/raw-loss = 0.6780091524124146, train/logprobs = tensor([[-0.9802, -1.1758],
        [-1.3312, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022549143061041832
Epoch 0, Step 339: train/loss = 0.7166198492050171, train/raw-loss = 0.7160778045654297, train/logprobs = tensor([[-0.9751, -0.8169],
        [-1.1043, -0.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021682358346879482
Epoch 0, Step 340: train/loss = 0.6940730214118958, train/raw-loss = 0.6939207911491394, train/logprobs = tensor([[-0.9986, -0.9429],
        [-0.9931, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006087617948651314
Epoch 0, Step 341: train/loss = 0.682417631149292, train/raw-loss = 0.6790878176689148, train/logprobs = tensor([[-0.8535, -1.0486],
        [-1.2348, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013319587334990501
Epoch 0, Step 342: train/loss = 0.708337664604187, train/raw-loss = 0.7055801153182983, train/logprobs = tensor([[-1.1263, -1.1028],
        [-1.2374, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011030234396457672
Epoch 0, Step 343: train/loss = 0.6967672109603882, train/raw-loss = 0.6956849098205566, train/logprobs = tensor([[-0.9542, -0.9379],
        [-1.1155, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043289996683597565
Epoch 0, Step 344: train/loss = 0.6976336240768433, train/raw-loss = 0.6953741312026978, train/logprobs = tensor([[-1.1035, -1.1836],
        [-1.2756, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009038037620484829
Epoch 0, Step 345: train/loss = 0.6923815608024597, train/raw-loss = 0.6900304555892944, train/logprobs = tensor([[-1.1266, -1.2077],
        [-1.4099, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009404454380273819
Epoch 0, Step 346: train/loss = 0.7450317144393921, train/raw-loss = 0.7415050268173218, train/logprobs = tensor([[-0.9458, -1.1414],
        [-1.1149, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014106832444667816
Epoch 0, Step 347: train/loss = 0.7138802409172058, train/raw-loss = 0.7087413668632507, train/logprobs = tensor([[-1.0329, -0.9848],
        [-1.4324, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020555365830659866
Epoch 0, Step 348: train/loss = 0.6937335133552551, train/raw-loss = 0.6934579014778137, train/logprobs = tensor([[-1.2938, -1.2760],
        [-1.3198, -1.1956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011023906990885735
Epoch 0, Step 349: train/loss = 0.6970630884170532, train/raw-loss = 0.6963411569595337, train/logprobs = tensor([[-0.8968, -0.8450],
        [-0.9292, -0.7072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028877314180135727
Epoch 0, Step 350: train/loss = 0.6980069875717163, train/raw-loss = 0.6978745460510254, train/logprobs = tensor([[-0.9664, -0.9013],
        [-1.0456, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005299221375025809
Epoch 0, Step 351: train/loss = 0.6955252289772034, train/raw-loss = 0.692562460899353, train/logprobs = tensor([[-1.0742, -1.0792],
        [-1.3098, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011851166374981403
Epoch 0, Step 352: train/loss = 0.6918802261352539, train/raw-loss = 0.686707615852356, train/logprobs = tensor([[-1.2746, -1.4890],
        [-1.3224, -1.0554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020690463483333588
Epoch 0, Step 353: train/loss = 0.6621392369270325, train/raw-loss = 0.6380588412284851, train/logprobs = tensor([[-0.8553, -1.6472],
        [-1.0941, -0.7452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0963214784860611
Epoch 0, Step 354: train/loss = 0.7238497138023376, train/raw-loss = 0.7208742499351501, train/logprobs = tensor([[-1.0850, -1.2437],
        [-1.3721, -1.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011901776306331158
Epoch 0, Step 355: train/loss = 0.7145624756813049, train/raw-loss = 0.7081494927406311, train/logprobs = tensor([[-1.6752, -1.9101],
        [-1.2539, -0.8580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02565181627869606
Epoch 0, Step 356: train/loss = 0.705190896987915, train/raw-loss = 0.701973557472229, train/logprobs = tensor([[-1.4121, -1.5400],
        [-1.4701, -1.1818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012869223020970821
Epoch 0, Step 357: train/loss = 0.6940680742263794, train/raw-loss = 0.6858277320861816, train/logprobs = tensor([[-0.9355, -1.5678],
        [-0.9678, -0.9808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03296099230647087
Epoch 0, Step 358: train/loss = 0.7049127221107483, train/raw-loss = 0.7004818916320801, train/logprobs = tensor([[-0.7581, -1.2230],
        [-1.0647, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017723433673381805
Epoch 0, Step 359: train/loss = 0.6939918398857117, train/raw-loss = 0.6872913837432861, train/logprobs = tensor([[-0.8652, -1.4055],
        [-1.1827, -1.2179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02680199407041073
Epoch 0, Step 360: train/loss = 0.7233139872550964, train/raw-loss = 0.7130078077316284, train/logprobs = tensor([[-1.1446, -2.1299],
        [-1.4866, -1.4569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04122459888458252
Epoch 0, Step 361: train/loss = 0.7146768569946289, train/raw-loss = 0.7106037735939026, train/logprobs = tensor([[-1.3856, -1.1397],
        [-1.0990, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01629229262471199
Epoch 0, Step 362: train/loss = 0.693414568901062, train/raw-loss = 0.6929928660392761, train/logprobs = tensor([[-1.0411, -1.0997],
        [-1.1090, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016868237871676683
Epoch 0, Step 363: train/loss = 0.703023374080658, train/raw-loss = 0.7001165151596069, train/logprobs = tensor([[-0.9686, -1.4546],
        [-0.8948, -0.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01162736676633358
Epoch 0, Step 364: train/loss = 0.6970122456550598, train/raw-loss = 0.6927293539047241, train/logprobs = tensor([[-1.0206, -0.9406],
        [-1.4849, -0.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017131714150309563
Epoch 0, Step 365: train/loss = 0.6898710131645203, train/raw-loss = 0.6871136426925659, train/logprobs = tensor([[-0.8713, -1.0863],
        [-0.9168, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011029195971786976
Epoch 0, Step 366: train/loss = 0.7027373909950256, train/raw-loss = 0.6992388963699341, train/logprobs = tensor([[-1.1159, -1.2060],
        [-1.2888, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013994059525430202
Epoch 0, Step 367: train/loss = 0.6884758472442627, train/raw-loss = 0.6817882061004639, train/logprobs = tensor([[-0.8170, -1.3395],
        [-0.8752, -0.8300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026750342920422554
Epoch 0, Step 368: train/loss = 0.6886255145072937, train/raw-loss = 0.6836373805999756, train/logprobs = tensor([[-1.2669, -1.6003],
        [-1.0306, -0.9175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019952328875660896
Epoch 0, Step 369: train/loss = 0.6885119676589966, train/raw-loss = 0.6846434473991394, train/logprobs = tensor([[-0.9667, -1.0781],
        [-1.0975, -0.8258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0154739860445261
Epoch 0, Step 370: train/loss = 0.6923136711120605, train/raw-loss = 0.6918312311172485, train/logprobs = tensor([[-1.0582, -1.0824],
        [-1.1011, -0.9690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019294589292258024
Epoch 0, Step 371: train/loss = 0.7020679712295532, train/raw-loss = 0.6970471143722534, train/logprobs = tensor([[-1.1973, -1.4413],
        [-1.1929, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020083244889974594
Epoch 0, Step 372: train/loss = 0.6994746327400208, train/raw-loss = 0.6984193325042725, train/logprobs = tensor([[-1.4788, -1.5190],
        [-0.9164, -0.7714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042212363332509995
Epoch 0, Step 373: train/loss = 0.7050049304962158, train/raw-loss = 0.6989609599113464, train/logprobs = tensor([[-0.9885, -1.2432],
        [-1.2938, -0.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024175718426704407
Epoch 0, Step 374: train/loss = 0.7465546131134033, train/raw-loss = 0.7445427775382996, train/logprobs = tensor([[-1.1356, -0.9307],
        [-1.2056, -0.6947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008047227747738361
Epoch 0, Step 375: train/loss = 0.6975077390670776, train/raw-loss = 0.6965122818946838, train/logprobs = tensor([[-1.0843, -1.0803],
        [-1.1155, -0.9013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003982009366154671
Epoch 0, Step 376: train/loss = 0.6898695230484009, train/raw-loss = 0.6781347990036011, train/logprobs = tensor([[-1.1087, -1.7439],
        [-1.1261, -0.8917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046938974410295486
Epoch 0, Step 377: train/loss = 0.6973538398742676, train/raw-loss = 0.6935913562774658, train/logprobs = tensor([[-1.0535, -1.0821],
        [-1.1477, -0.6432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015050001442432404
Epoch 0, Step 378: train/loss = 0.7305617332458496, train/raw-loss = 0.7155123353004456, train/logprobs = tensor([[-0.9067, -1.6665],
        [-1.1083, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06019788980484009
Epoch 0, Step 379: train/loss = 0.7031517028808594, train/raw-loss = 0.7021904587745667, train/logprobs = tensor([[-0.8955, -1.2769],
        [-0.8959, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00384509633295238
Epoch 0, Step 380: train/loss = 0.6984835267066956, train/raw-loss = 0.6946262121200562, train/logprobs = tensor([[-1.0775, -1.1016],
        [-1.1684, -0.9154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015429161489009857
Epoch 0, Step 381: train/loss = 0.7046064138412476, train/raw-loss = 0.7034348249435425, train/logprobs = tensor([[-1.3242, -1.2122],
        [-1.0641, -0.7791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004686569329351187
Epoch 0, Step 382: train/loss = 0.6683948040008545, train/raw-loss = 0.6518439054489136, train/logprobs = tensor([[-1.1123, -1.6750],
        [-1.3458, -0.7016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06620362401008606
Epoch 0, Step 383: train/loss = 0.6889152526855469, train/raw-loss = 0.6842740178108215, train/logprobs = tensor([[-0.9736, -1.0888],
        [-1.3141, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018564682453870773
Epoch 0, Step 384: train/loss = 0.6925612092018127, train/raw-loss = 0.6916768550872803, train/logprobs = tensor([[-0.8621, -1.0061],
        [-0.8265, -0.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035375594161450863
Epoch 0, Step 385: train/loss = 0.6830524206161499, train/raw-loss = 0.6720929145812988, train/logprobs = tensor([[-1.1354, -1.5523],
        [-1.0410, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043837882578372955
Epoch 0, Step 386: train/loss = 0.7079348564147949, train/raw-loss = 0.7069560289382935, train/logprobs = tensor([[-1.0574, -1.1423],
        [-1.1262, -0.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003915080800652504
Epoch 0, Step 387: train/loss = 0.6911633610725403, train/raw-loss = 0.6861856579780579, train/logprobs = tensor([[-1.0918, -1.5076],
        [-1.2451, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019910870119929314
Epoch 0, Step 388: train/loss = 0.6958550214767456, train/raw-loss = 0.6880344748497009, train/logprobs = tensor([[-1.4643, -1.8422],
        [-1.4695, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03128229081630707
Epoch 0, Step 389: train/loss = 0.7116189002990723, train/raw-loss = 0.7055363059043884, train/logprobs = tensor([[-1.1185, -1.4819],
        [-1.1914, -1.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02433035522699356
Epoch 0, Step 390: train/loss = 0.6775888800621033, train/raw-loss = 0.6621950268745422, train/logprobs = tensor([[-1.0592, -1.6865],
        [-1.3976, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061575498431921005
Epoch 0, Step 391: train/loss = 0.7148404121398926, train/raw-loss = 0.7129127979278564, train/logprobs = tensor([[-1.0208, -1.1241],
        [-1.1230, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007710480131208897
Epoch 0, Step 392: train/loss = 0.7142683267593384, train/raw-loss = 0.709418535232544, train/logprobs = tensor([[-1.0404, -1.5625],
        [-1.2676, -1.5110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019399292767047882
Epoch 0, Step 393: train/loss = 0.7047738432884216, train/raw-loss = 0.7046718597412109, train/logprobs = tensor([[-0.9401, -0.9008],
        [-1.0498, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004080884391441941
Epoch 0, Step 394: train/loss = 0.6888382434844971, train/raw-loss = 0.6848755478858948, train/logprobs = tensor([[-0.8227, -0.9643],
        [-1.0518, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01585070788860321
Epoch 0, Step 395: train/loss = 0.6931292414665222, train/raw-loss = 0.6917092800140381, train/logprobs = tensor([[-1.1463, -1.4423],
        [-1.1905, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005679700057953596
Epoch 0, Step 396: train/loss = 0.7028836607933044, train/raw-loss = 0.6921225786209106, train/logprobs = tensor([[-1.2550, -2.1294],
        [-1.0389, -0.9557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04304453730583191
Epoch 0, Step 397: train/loss = 0.6935293674468994, train/raw-loss = 0.6717468500137329, train/logprobs = tensor([[-1.2529, -1.9216],
        [-1.3871, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08713036775588989
Epoch 0, Step 398: train/loss = 0.7077555060386658, train/raw-loss = 0.7074088454246521, train/logprobs = tensor([[-1.0512, -0.8329],
        [-1.0699, -0.6804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013864850625395775
Epoch 0, Step 399: train/loss = 0.680851936340332, train/raw-loss = 0.6738169193267822, train/logprobs = tensor([[-1.2210, -1.4635],
        [-1.3525, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028139956295490265
Epoch 0, Step 400: train/loss = 0.6949211359024048, train/raw-loss = 0.6943976879119873, train/logprobs = tensor([[-1.2285, -1.3089],
        [-0.7836, -0.7077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020938871894031763
Epoch 0, Step 401: train/loss = 0.7112836241722107, train/raw-loss = 0.7038353681564331, train/logprobs = tensor([[-1.1286, -1.6884],
        [-1.0074, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029793202877044678
Epoch 0, Step 402: train/loss = 0.7143682241439819, train/raw-loss = 0.7130616903305054, train/logprobs = tensor([[-1.2660, -1.0827],
        [-1.4472, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005226398352533579
Epoch 0, Step 403: train/loss = 0.7332099676132202, train/raw-loss = 0.7277843952178955, train/logprobs = tensor([[-0.9184, -1.3352],
        [-0.9528, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021702446043491364
Epoch 0, Step 404: train/loss = 0.6655291318893433, train/raw-loss = 0.6242843866348267, train/logprobs = tensor([[-0.9489, -1.9985],
        [-1.2469, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16497895121574402
Epoch 0, Step 405: train/loss = 0.6817656755447388, train/raw-loss = 0.6713982820510864, train/logprobs = tensor([[-0.9960, -1.4726],
        [-1.3096, -0.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041469573974609375
Epoch 0, Step 406: train/loss = 0.7504231333732605, train/raw-loss = 0.7337980270385742, train/logprobs = tensor([[-1.3281, -2.0475],
        [-1.3184, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06650060415267944
Epoch 0, Step 407: train/loss = 0.7041552066802979, train/raw-loss = 0.6985524296760559, train/logprobs = tensor([[-1.0275, -1.7078],
        [-1.1477, -1.2138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022411338984966278
Epoch 0, Step 408: train/loss = 0.6903269290924072, train/raw-loss = 0.6692140102386475, train/logprobs = tensor([[-0.9300, -1.7422],
        [-1.2460, -0.9802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445177972316742
Epoch 0, Step 409: train/loss = 0.6925987005233765, train/raw-loss = 0.6886602640151978, train/logprobs = tensor([[-1.1513, -1.2523],
        [-1.4193, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01575411483645439
Epoch 0, Step 410: train/loss = 0.702871561050415, train/raw-loss = 0.6727927923202515, train/logprobs = tensor([[-0.8448, -1.9960],
        [-1.0301, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12031520158052444
Epoch 0, Step 411: train/loss = 0.6846556663513184, train/raw-loss = 0.6804924011230469, train/logprobs = tensor([[-1.2029, -1.3958],
        [-1.1067, -0.8328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016653090715408325
Epoch 0, Step 412: train/loss = 0.7006475925445557, train/raw-loss = 0.6982245445251465, train/logprobs = tensor([[-1.5738, -1.5353],
        [-1.4148, -0.9496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009692107327282429
Epoch 0, Step 413: train/loss = 0.6944925785064697, train/raw-loss = 0.6922132968902588, train/logprobs = tensor([[-1.2696, -1.3106],
        [-1.0335, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00911684799939394
Epoch 0, Step 414: train/loss = 0.7046154141426086, train/raw-loss = 0.6980996131896973, train/logprobs = tensor([[-0.8965, -1.2137],
        [-1.1590, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026063261553645134
Epoch 0, Step 415: train/loss = 0.6829622983932495, train/raw-loss = 0.6767110824584961, train/logprobs = tensor([[-0.9189, -1.2831],
        [-0.9646, -0.7512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025004912167787552
Epoch 0, Step 416: train/loss = 0.731413722038269, train/raw-loss = 0.7041879892349243, train/logprobs = tensor([[-1.3642, -2.5157],
        [-1.4688, -1.1634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1089029386639595
Epoch 0, Step 417: train/loss = 0.7437321543693542, train/raw-loss = 0.7340837717056274, train/logprobs = tensor([[-0.9995, -1.0883],
        [-1.2494, -0.5500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03859342634677887
Epoch 0, Step 418: train/loss = 0.6960042715072632, train/raw-loss = 0.6923396587371826, train/logprobs = tensor([[-2.0180, -2.0726],
        [-1.3576, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014658685773611069
Epoch 0, Step 419: train/loss = 0.6950072050094604, train/raw-loss = 0.6938536763191223, train/logprobs = tensor([[-1.4392, -1.6028],
        [-1.1903, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004613957367837429
Epoch 0, Step 420: train/loss = 0.6865665912628174, train/raw-loss = 0.665960431098938, train/logprobs = tensor([[-1.0695, -1.7480],
        [-1.0908, -1.0045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08242470771074295
Epoch 0, Step 421: train/loss = 0.6911002397537231, train/raw-loss = 0.6719869375228882, train/logprobs = tensor([[-1.3644, -2.2153],
        [-1.3318, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07645335048437119
Epoch 0, Step 422: train/loss = 0.6931925415992737, train/raw-loss = 0.6875784993171692, train/logprobs = tensor([[-1.1949, -1.6127],
        [-1.2105, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022455982863903046
Epoch 0, Step 423: train/loss = 0.6919782757759094, train/raw-loss = 0.6836549043655396, train/logprobs = tensor([[-1.3842, -1.5190],
        [-1.5846, -1.2497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03329381346702576
Epoch 0, Step 424: train/loss = 0.7051648497581482, train/raw-loss = 0.7002846598625183, train/logprobs = tensor([[-1.1779, -1.1795],
        [-1.2477, -0.8147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01952083222568035
Epoch 0, Step 425: train/loss = 0.6729927659034729, train/raw-loss = 0.6593548059463501, train/logprobs = tensor([[-0.9491, -1.7123],
        [-1.0964, -0.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054551899433135986
Epoch 0, Step 426: train/loss = 0.7153799533843994, train/raw-loss = 0.7069938778877258, train/logprobs = tensor([[-1.4688, -1.2993],
        [-1.6523, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03354419022798538
Epoch 0, Step 427: train/loss = 0.7055155634880066, train/raw-loss = 0.6984454393386841, train/logprobs = tensor([[-1.0530, -1.3385],
        [-1.2179, -1.0229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02828049287199974
Epoch 0, Step 428: train/loss = 0.7075614333152771, train/raw-loss = 0.7025334239006042, train/logprobs = tensor([[-1.1322, -1.1623],
        [-1.2472, -0.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020112089812755585
Epoch 0, Step 429: train/loss = 0.6958832740783691, train/raw-loss = 0.6917083263397217, train/logprobs = tensor([[-0.9766, -1.1272],
        [-1.2123, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016699764877557755
Epoch 0, Step 430: train/loss = 0.7116817235946655, train/raw-loss = 0.7036557793617249, train/logprobs = tensor([[-0.9485, -1.6374],
        [-0.9735, -0.9531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03210362792015076
Epoch 0, Step 431: train/loss = 0.7155519723892212, train/raw-loss = 0.7146117687225342, train/logprobs = tensor([[-1.3128, -1.7650],
        [-1.3584, -1.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037605981342494488
Epoch 0, Step 432: train/loss = 0.6891642212867737, train/raw-loss = 0.6811705231666565, train/logprobs = tensor([[-1.3607, -1.6914],
        [-1.2954, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031974852085113525
Epoch 0, Step 433: train/loss = 0.698908269405365, train/raw-loss = 0.690686821937561, train/logprobs = tensor([[-1.0254, -1.3161],
        [-0.9698, -0.5613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03288574516773224
Epoch 0, Step 434: train/loss = 0.689095139503479, train/raw-loss = 0.685380756855011, train/logprobs = tensor([[-1.5571, -1.7599],
        [-1.2498, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014857521280646324
Epoch 0, Step 435: train/loss = 0.759876549243927, train/raw-loss = 0.7423856854438782, train/logprobs = tensor([[-1.4162, -2.2903],
        [-1.4601, -1.3896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06996354460716248
Epoch 0, Step 436: train/loss = 0.6924440860748291, train/raw-loss = 0.6742448806762695, train/logprobs = tensor([[-0.9733, -1.7964],
        [-0.9504, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07279687374830246
Epoch 0, Step 437: train/loss = 0.6897834539413452, train/raw-loss = 0.6728413701057434, train/logprobs = tensor([[-1.5894, -1.7314],
        [-1.3149, -0.6096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776846945285797
Epoch 0, Step 438: train/loss = 0.6767136454582214, train/raw-loss = 0.657084584236145, train/logprobs = tensor([[-0.9317, -1.4727],
        [-1.2996, -0.5835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07851628214120865
Epoch 0, Step 439: train/loss = 0.7070179581642151, train/raw-loss = 0.6956347823143005, train/logprobs = tensor([[-1.4519, -1.8825],
        [-1.5582, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045532673597335815
Epoch 0, Step 440: train/loss = 0.6971505880355835, train/raw-loss = 0.6908254623413086, train/logprobs = tensor([[-1.2563, -1.6346],
        [-1.4862, -1.2984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025300640612840652
Epoch 0, Step 441: train/loss = 0.6686004400253296, train/raw-loss = 0.645660400390625, train/logprobs = tensor([[-1.2039, -1.8460],
        [-1.5408, -0.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09176014363765717
Epoch 0, Step 442: train/loss = 0.6898689866065979, train/raw-loss = 0.681699275970459, train/logprobs = tensor([[-0.9445, -1.0753],
        [-1.1935, -0.6304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03267882391810417
Epoch 0, Step 443: train/loss = 0.7154382467269897, train/raw-loss = 0.7148773670196533, train/logprobs = tensor([[-1.2316, -1.0026],
        [-0.8873, -0.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022433253470808268
Epoch 0, Step 444: train/loss = 0.6995270848274231, train/raw-loss = 0.6531893014907837, train/logprobs = tensor([[-0.8579, -2.4409],
        [-1.1697, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1853509545326233
Epoch 0, Step 445: train/loss = 0.7365288138389587, train/raw-loss = 0.7132946252822876, train/logprobs = tensor([[-1.0528, -1.9827],
        [-1.2303, -1.0991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0929364562034607
Epoch 0, Step 446: train/loss = 0.6705654859542847, train/raw-loss = 0.6458888649940491, train/logprobs = tensor([[-0.9839, -1.8928],
        [-0.9531, -0.5130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0987064465880394
Epoch 0, Step 447: train/loss = 0.6893234848976135, train/raw-loss = 0.6826056838035583, train/logprobs = tensor([[-1.1154, -1.4943],
        [-0.9738, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026871416717767715
Epoch 0, Step 448: train/loss = 0.7275273203849792, train/raw-loss = 0.7209404706954956, train/logprobs = tensor([[-1.3189, -1.8418],
        [-1.0690, -1.0062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02634735032916069
Epoch 0, Step 449: train/loss = 0.6773701906204224, train/raw-loss = 0.6682430505752563, train/logprobs = tensor([[-1.3903, -1.6796],
        [-1.5334, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03650851547718048
Epoch 0, Step 450: train/loss = 0.7214523553848267, train/raw-loss = 0.720859944820404, train/logprobs = tensor([[-1.6245, -1.4508],
        [-1.2942, -0.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023695651907473803
Epoch 0, Step 451: train/loss = 0.6676081418991089, train/raw-loss = 0.6239880919456482, train/logprobs = tensor([[-0.8991, -2.1337],
        [-1.2897, -1.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17448021471500397
Epoch 0, Step 452: train/loss = 0.6995293498039246, train/raw-loss = 0.6918010711669922, train/logprobs = tensor([[-1.5656, -2.2419],
        [-0.7990, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03091316856443882
Epoch 0, Step 453: train/loss = 0.6968344449996948, train/raw-loss = 0.6753777265548706, train/logprobs = tensor([[-1.1124, -1.8909],
        [-1.1308, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08582669496536255
Epoch 0, Step 454: train/loss = 0.6696912050247192, train/raw-loss = 0.6505988836288452, train/logprobs = tensor([[-1.1279, -1.6388],
        [-1.3384, -0.8993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0763690248131752
Epoch 0, Step 455: train/loss = 0.7000492811203003, train/raw-loss = 0.6816061735153198, train/logprobs = tensor([[-1.2643, -1.8182],
        [-1.1916, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0737723708152771
Epoch 0, Step 456: train/loss = 0.6931796073913574, train/raw-loss = 0.6923169493675232, train/logprobs = tensor([[-1.0213, -1.1298],
        [-0.8808, -0.7422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034506656229496002
Epoch 0, Step 457: train/loss = 0.6990982294082642, train/raw-loss = 0.6721391677856445, train/logprobs = tensor([[-0.9645, -1.8443],
        [-1.3204, -0.7967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10783647000789642
Epoch 0, Step 458: train/loss = 0.753448486328125, train/raw-loss = 0.7428930401802063, train/logprobs = tensor([[-1.0740, -2.0094],
        [-1.0811, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04222198575735092
Epoch 0, Step 459: train/loss = 0.7146567702293396, train/raw-loss = 0.7054001092910767, train/logprobs = tensor([[-1.8754, -2.1353],
        [-1.3496, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03702639415860176
Epoch 0, Step 460: train/loss = 0.6807745695114136, train/raw-loss = 0.6674201488494873, train/logprobs = tensor([[-1.1599, -1.6266],
        [-1.5931, -1.0297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05341774597764015
Epoch 0, Step 461: train/loss = 0.6756467819213867, train/raw-loss = 0.6723582744598389, train/logprobs = tensor([[-1.5872, -1.8617],
        [-1.0161, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013153836131095886
Epoch 0, Step 462: train/loss = 0.6651524305343628, train/raw-loss = 0.6594226956367493, train/logprobs = tensor([[-1.3985, -2.0045],
        [-1.3809, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022918999195098877
Epoch 0, Step 463: train/loss = 0.7394086122512817, train/raw-loss = 0.6902555227279663, train/logprobs = tensor([[-1.4780, -2.9790],
        [-1.1661, -1.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19661250710487366
Epoch 0, Step 464: train/loss = 0.6794794797897339, train/raw-loss = 0.6663071513175964, train/logprobs = tensor([[-1.5477, -1.8958],
        [-1.3202, -1.1633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05268948897719383
Epoch 0, Step 465: train/loss = 0.7135360240936279, train/raw-loss = 0.7088242769241333, train/logprobs = tensor([[-1.0941, -1.4482],
        [-1.1139, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018846649676561356
Epoch 0, Step 466: train/loss = 0.6984605193138123, train/raw-loss = 0.6975339651107788, train/logprobs = tensor([[-1.1059, -1.3451],
        [-1.0701, -1.0372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003706068266183138
Epoch 0, Step 467: train/loss = 0.6925925612449646, train/raw-loss = 0.6851319074630737, train/logprobs = tensor([[-1.3958, -1.9302],
        [-1.5558, -1.4553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029842808842658997
Epoch 0, Step 468: train/loss = 0.6943353414535522, train/raw-loss = 0.6759673953056335, train/logprobs = tensor([[-0.9385, -1.7759],
        [-0.9521, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07347176969051361
Epoch 0, Step 469: train/loss = 0.694729745388031, train/raw-loss = 0.6910325288772583, train/logprobs = tensor([[-1.0953, -1.1114],
        [-1.1736, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014788731932640076
Epoch 0, Step 470: train/loss = 0.7080148458480835, train/raw-loss = 0.7015764713287354, train/logprobs = tensor([[-1.0000, -1.6201],
        [-1.2222, -1.3305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025753473863005638
Epoch 0, Step 471: train/loss = 0.7063241004943848, train/raw-loss = 0.7010557055473328, train/logprobs = tensor([[-1.1197, -1.6493],
        [-1.4518, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02107352763414383
Epoch 0, Step 472: train/loss = 0.6438584923744202, train/raw-loss = 0.5967115759849548, train/logprobs = tensor([[-1.3168, -2.4716],
        [-1.3951, -0.6488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18858757615089417
Epoch 0, Step 473: train/loss = 0.689688503742218, train/raw-loss = 0.684696614742279, train/logprobs = tensor([[-1.7066, -1.9612],
        [-1.7058, -1.5403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01996767893433571
Epoch 0, Step 474: train/loss = 0.6995159387588501, train/raw-loss = 0.6805325746536255, train/logprobs = tensor([[-1.1095, -1.9304],
        [-1.1785, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07593375444412231
Epoch 0, Step 475: train/loss = 0.7055296897888184, train/raw-loss = 0.6979237794876099, train/logprobs = tensor([[-0.9155, -1.5019],
        [-1.2347, -1.3361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03042360581457615
Epoch 0, Step 476: train/loss = 0.7445019483566284, train/raw-loss = 0.7322120070457458, train/logprobs = tensor([[-1.7125, -1.7459],
        [-2.0059, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04915996640920639
Epoch 0, Step 477: train/loss = 0.6749102473258972, train/raw-loss = 0.6508927941322327, train/logprobs = tensor([[-1.4267, -2.1416],
        [-1.4974, -1.3938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09606966376304626
Epoch 0, Step 478: train/loss = 0.6973629593849182, train/raw-loss = 0.6823099255561829, train/logprobs = tensor([[-0.9009, -1.5033],
        [-1.2220, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060211922973394394
Epoch 0, Step 479: train/loss = 0.6912290453910828, train/raw-loss = 0.6905226707458496, train/logprobs = tensor([[-1.3112, -1.2953],
        [-1.4823, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00282555865123868
Epoch 0, Step 480: train/loss = 0.6901617050170898, train/raw-loss = 0.6864588260650635, train/logprobs = tensor([[-1.1676, -1.2640],
        [-1.0439, -0.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014811641536653042
Epoch 0, Step 481: train/loss = 0.6707462668418884, train/raw-loss = 0.6422098875045776, train/logprobs = tensor([[-1.2748, -2.0284],
        [-1.4068, -0.9062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11414537578821182
Epoch 0, Step 482: train/loss = 0.6717715263366699, train/raw-loss = 0.6472275257110596, train/logprobs = tensor([[-1.5351, -1.9910],
        [-1.4667, -0.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09817616641521454
Epoch 0, Step 483: train/loss = 0.6796203851699829, train/raw-loss = 0.6500773429870605, train/logprobs = tensor([[-1.3726, -2.1280],
        [-1.1209, -0.7170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817238479852676
Epoch 0, Step 484: train/loss = 0.7037870287895203, train/raw-loss = 0.6873070001602173, train/logprobs = tensor([[-1.1015, -2.0788],
        [-1.4575, -1.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06591980159282684
Epoch 0, Step 485: train/loss = 0.6656780242919922, train/raw-loss = 0.6413684487342834, train/logprobs = tensor([[-1.2068, -1.9218],
        [-1.0801, -0.7557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0972384437918663
Epoch 0, Step 486: train/loss = 0.7175495624542236, train/raw-loss = 0.715930163860321, train/logprobs = tensor([[-1.2148, -1.3835],
        [-1.2756, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006477713584899902
Epoch 0, Step 487: train/loss = 0.6908242702484131, train/raw-loss = 0.6873126029968262, train/logprobs = tensor([[-1.3681, -1.5264],
        [-1.0227, -0.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014046549797058105
Epoch 0, Step 488: train/loss = 0.6737197637557983, train/raw-loss = 0.6503292918205261, train/logprobs = tensor([[-1.4709, -2.1926],
        [-1.2891, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09356168657541275
Epoch 0, Step 489: train/loss = 0.719712495803833, train/raw-loss = 0.702312707901001, train/logprobs = tensor([[-0.9799, -1.9340],
        [-1.1119, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06959908455610275
Epoch 0, Step 490: train/loss = 0.6713322401046753, train/raw-loss = 0.6497302055358887, train/logprobs = tensor([[-1.0506, -1.7373],
        [-1.2183, -0.7749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.086408331990242
Epoch 0, Step 491: train/loss = 0.6770040988922119, train/raw-loss = 0.660672664642334, train/logprobs = tensor([[-1.1267, -1.4988],
        [-1.3637, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06532572954893112
Epoch 0, Step 492: train/loss = 0.6842471957206726, train/raw-loss = 0.6744883060455322, train/logprobs = tensor([[-1.0492, -1.4347],
        [-1.1394, -0.7978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03903588652610779
Epoch 0, Step 493: train/loss = 0.7419623732566833, train/raw-loss = 0.6975135803222656, train/logprobs = tensor([[-1.0031, -2.5916],
        [-1.2373, -0.9058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17779487371444702
Epoch 0, Step 494: train/loss = 0.682294487953186, train/raw-loss = 0.6715021133422852, train/logprobs = tensor([[-1.6154, -1.5741],
        [-1.2196, -1.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04316939413547516
Epoch 0, Step 495: train/loss = 0.6885581612586975, train/raw-loss = 0.6729831695556641, train/logprobs = tensor([[-0.9075, -1.4207],
        [-1.1814, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0622999370098114
Epoch 0, Step 496: train/loss = 0.6849756240844727, train/raw-loss = 0.6754235029220581, train/logprobs = tensor([[-1.1221, -1.3932],
        [-1.4739, -1.3302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03820858523249626
Epoch 0, Step 497: train/loss = 0.7312873005867004, train/raw-loss = 0.7283709645271301, train/logprobs = tensor([[-1.4802, -1.3895],
        [-1.1146, -0.7084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011665514670312405
Epoch 0, Step 498: train/loss = 0.6679567098617554, train/raw-loss = 0.605044424533844, train/logprobs = tensor([[-1.1948, -3.1667],
        [-1.1587, -0.7550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516494393348694
Epoch 0, Step 499: train/loss = 0.6747254133224487, train/raw-loss = 0.6465775370597839, train/logprobs = tensor([[-0.9363, -1.5991],
        [-1.0569, -0.5611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1125914454460144
eval/loss: 0.6920936107635498
Epoch 0, Step 500: train/loss = 0.7083489894866943, train/raw-loss = 0.6972459554672241, train/logprobs = tensor([[-1.7294, -2.0416],
        [-1.1728, -0.5733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04441187530755997
Epoch 0, Step 501: train/loss = 0.7114202976226807, train/raw-loss = 0.6963808536529541, train/logprobs = tensor([[-1.6700, -2.2322],
        [-1.6559, -1.3484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06015778332948685
Epoch 0, Step 502: train/loss = 0.7107381820678711, train/raw-loss = 0.6883605122566223, train/logprobs = tensor([[-1.6494, -2.3819],
        [-1.3776, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08951056003570557
Epoch 0, Step 503: train/loss = 0.7398830056190491, train/raw-loss = 0.7236106991767883, train/logprobs = tensor([[-1.7611, -1.9848],
        [-1.5452, -1.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06508927047252655
Epoch 0, Step 504: train/loss = 0.7323585748672485, train/raw-loss = 0.7303508520126343, train/logprobs = tensor([[-1.3845, -1.2660],
        [-1.4909, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008031118661165237
Epoch 0, Step 505: train/loss = 0.7015892267227173, train/raw-loss = 0.6920520067214966, train/logprobs = tensor([[-1.0110, -1.2773],
        [-1.1591, -0.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03814862668514252
Epoch 0, Step 506: train/loss = 0.7214668989181519, train/raw-loss = 0.7058820724487305, train/logprobs = tensor([[-0.9415, -1.7143],
        [-0.9961, -0.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06233903393149376
Epoch 0, Step 507: train/loss = 0.6765074729919434, train/raw-loss = 0.6394391059875488, train/logprobs = tensor([[-1.3961, -2.3403],
        [-1.6001, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14827360212802887
Epoch 0, Step 508: train/loss = 0.6982181668281555, train/raw-loss = 0.6952069401741028, train/logprobs = tensor([[-1.0431, -1.0372],
        [-1.1889, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012044891715049744
Epoch 0, Step 509: train/loss = 0.68467116355896, train/raw-loss = 0.6721428632736206, train/logprobs = tensor([[-0.8641, -1.4986],
        [-1.1287, -0.7503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05011310428380966
Epoch 0, Step 510: train/loss = 0.6579836010932922, train/raw-loss = 0.6304631233215332, train/logprobs = tensor([[-1.1048, -1.9086],
        [-1.3323, -1.0480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11008172482252121
Epoch 0, Step 511: train/loss = 0.6367532014846802, train/raw-loss = 0.5902169942855835, train/logprobs = tensor([[-1.3928, -2.6258],
        [-1.3583, -0.8571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1861448734998703
Epoch 0, Step 512: train/loss = 0.6871524453163147, train/raw-loss = 0.6667452454566956, train/logprobs = tensor([[-1.0911, -1.7475],
        [-1.1428, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08162873238325119
Epoch 0, Step 513: train/loss = 0.7370089292526245, train/raw-loss = 0.7326791286468506, train/logprobs = tensor([[-1.1751, -0.8282],
        [-1.0248, -0.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017319366335868835
Epoch 0, Step 514: train/loss = 0.6661704778671265, train/raw-loss = 0.6310814619064331, train/logprobs = tensor([[-1.2482, -1.8491],
        [-1.5979, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403564214706421
Epoch 0, Step 515: train/loss = 0.677898645401001, train/raw-loss = 0.6274493336677551, train/logprobs = tensor([[-1.4276, -2.7494],
        [-1.2512, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20179705321788788
Epoch 0, Step 516: train/loss = 0.7283923029899597, train/raw-loss = 0.7010726928710938, train/logprobs = tensor([[-0.8826, -1.7321],
        [-1.1970, -0.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1092783734202385
Epoch 0, Step 517: train/loss = 0.658625602722168, train/raw-loss = 0.6256225109100342, train/logprobs = tensor([[-1.1384, -2.0749],
        [-1.4331, -0.7788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13201217353343964
Epoch 0, Step 518: train/loss = 0.6644793152809143, train/raw-loss = 0.6011919379234314, train/logprobs = tensor([[-1.0968, -2.6031],
        [-1.3401, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25314944982528687
Epoch 0, Step 519: train/loss = 0.6762385964393616, train/raw-loss = 0.657203733921051, train/logprobs = tensor([[-1.2128, -1.8225],
        [-1.1915, -0.7258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07613948732614517
Epoch 0, Step 520: train/loss = 0.7017317414283752, train/raw-loss = 0.6646212339401245, train/logprobs = tensor([[-1.5016, -2.1075],
        [-1.6001, -0.4574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14844229817390442
Epoch 0, Step 521: train/loss = 0.7445859909057617, train/raw-loss = 0.70895916223526, train/logprobs = tensor([[-1.0468, -2.4834],
        [-1.2397, -1.2738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14250710606575012
Epoch 0, Step 522: train/loss = 0.6376878023147583, train/raw-loss = 0.5576621294021606, train/logprobs = tensor([[-0.9143, -2.8640],
        [-1.4446, -0.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201026916503906
Epoch 0, Step 523: train/loss = 0.6754350662231445, train/raw-loss = 0.6445029973983765, train/logprobs = tensor([[-1.4523, -2.6808],
        [-1.1773, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12372827529907227
Epoch 0, Step 524: train/loss = 0.6969873905181885, train/raw-loss = 0.696465790271759, train/logprobs = tensor([[-1.5756, -1.5064],
        [-1.3688, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00208664289675653
Epoch 0, Step 525: train/loss = 0.7156543731689453, train/raw-loss = 0.6906434297561646, train/logprobs = tensor([[-0.8925, -1.7918],
        [-1.1252, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10004345327615738
Epoch 0, Step 526: train/loss = 0.6709569692611694, train/raw-loss = 0.6540567874908447, train/logprobs = tensor([[-1.1954, -1.6995],
        [-1.1993, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06760089099407196
Epoch 0, Step 527: train/loss = 0.6956297159194946, train/raw-loss = 0.6701611280441284, train/logprobs = tensor([[-1.2935, -1.6597],
        [-1.9812, -0.7973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10187417268753052
Epoch 0, Step 528: train/loss = 0.6002259254455566, train/raw-loss = 0.5260421633720398, train/logprobs = tensor([[-1.5097, -2.7145],
        [-1.7814, -0.6796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2967347204685211
Epoch 0, Step 529: train/loss = 0.6450340747833252, train/raw-loss = 0.599609375, train/logprobs = tensor([[-1.1408, -1.8505],
        [-1.4403, -0.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181698739528656
Epoch 0, Step 530: train/loss = 0.7508026361465454, train/raw-loss = 0.7452532052993774, train/logprobs = tensor([[-1.2893, -1.2291],
        [-1.4344, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02219761535525322
Epoch 0, Step 531: train/loss = 0.6956909894943237, train/raw-loss = 0.6859418153762817, train/logprobs = tensor([[-1.5379, -1.6893],
        [-1.6161, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03899642825126648
Epoch 0, Step 532: train/loss = 0.7232322692871094, train/raw-loss = 0.719183623790741, train/logprobs = tensor([[-1.7371, -2.3283],
        [-1.4859, -1.8217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016194354742765427
Epoch 0, Step 533: train/loss = 0.7447589039802551, train/raw-loss = 0.7316493988037109, train/logprobs = tensor([[-1.2384, -1.8202],
        [-1.4730, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05243805795907974
Epoch 0, Step 534: train/loss = 0.6650964021682739, train/raw-loss = 0.6432745456695557, train/logprobs = tensor([[-1.0945, -1.5372],
        [-1.1606, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08728748559951782
Epoch 0, Step 535: train/loss = 0.5965886116027832, train/raw-loss = 0.519977867603302, train/logprobs = tensor([[-1.5730, -3.1803],
        [-1.7425, -0.8177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3064427971839905
Epoch 0, Step 536: train/loss = 0.659243643283844, train/raw-loss = 0.6156854629516602, train/logprobs = tensor([[-1.4792, -2.4231],
        [-1.4895, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17423267662525177
Epoch 0, Step 537: train/loss = 0.6070680618286133, train/raw-loss = 0.514989972114563, train/logprobs = tensor([[-1.2499, -3.0809],
        [-1.3528, -0.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36831220984458923
Epoch 0, Step 538: train/loss = 0.6915665864944458, train/raw-loss = 0.6879783868789673, train/logprobs = tensor([[-0.9014, -1.0198],
        [-1.0345, -0.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014352869242429733
Epoch 0, Step 539: train/loss = 0.5933623313903809, train/raw-loss = 0.47897201776504517, train/logprobs = tensor([[-1.6134, -3.9794],
        [-1.9626, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4575612246990204
Epoch 0, Step 540: train/loss = 0.690360426902771, train/raw-loss = 0.6724025011062622, train/logprobs = tensor([[-1.0918, -1.4061],
        [-1.5465, -0.8295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07183202356100082
Epoch 0, Step 541: train/loss = 0.6881868243217468, train/raw-loss = 0.6763932108879089, train/logprobs = tensor([[-1.2984, -1.6177],
        [-1.3770, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04717448726296425
Epoch 0, Step 542: train/loss = 0.6715947985649109, train/raw-loss = 0.6296455264091492, train/logprobs = tensor([[-1.6737, -2.4138],
        [-1.2311, -0.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16779708862304688
Epoch 0, Step 543: train/loss = 0.6884526610374451, train/raw-loss = 0.6526755094528198, train/logprobs = tensor([[-1.3218, -1.5782],
        [-1.8723, -0.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1431087851524353
Epoch 0, Step 544: train/loss = 0.6414324045181274, train/raw-loss = 0.5866759419441223, train/logprobs = tensor([[-1.8474, -2.9936],
        [-1.9751, -1.3587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21902573108673096
Epoch 0, Step 545: train/loss = 0.7037948369979858, train/raw-loss = 0.7026479244232178, train/logprobs = tensor([[-2.8771, -2.8648],
        [-1.3376, -1.1300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004587483126670122
Epoch 0, Step 546: train/loss = 0.6658788323402405, train/raw-loss = 0.5983268022537231, train/logprobs = tensor([[-2.0671, -3.6225],
        [-1.5383, -1.1866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27020785212516785
Epoch 0, Step 547: train/loss = 0.7057012915611267, train/raw-loss = 0.6872111558914185, train/logprobs = tensor([[-1.8944, -2.4453],
        [-0.8692, -0.6761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07396066933870316
Epoch 0, Step 548: train/loss = 0.6521735191345215, train/raw-loss = 0.5926430225372314, train/logprobs = tensor([[-1.0587, -2.3765],
        [-1.8835, -1.4737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23812200129032135
Epoch 0, Step 549: train/loss = 0.6564072370529175, train/raw-loss = 0.6195045709609985, train/logprobs = tensor([[-1.3368, -2.3838],
        [-1.5289, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14761075377464294
Epoch 0, Step 550: train/loss = 0.6591435670852661, train/raw-loss = 0.6346226930618286, train/logprobs = tensor([[-1.6011, -2.1253],
        [-1.3072, -0.9891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09808328747749329
Epoch 0, Step 551: train/loss = 0.6404895782470703, train/raw-loss = 0.5738129019737244, train/logprobs = tensor([[-1.4473, -2.8869],
        [-1.3242, -0.7488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26670658588409424
Epoch 0, Step 552: train/loss = 0.7420558333396912, train/raw-loss = 0.6584083437919617, train/logprobs = tensor([[-0.9983, -3.3851],
        [-1.9288, -1.6423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3345901668071747
Epoch 0, Step 553: train/loss = 0.6460940837860107, train/raw-loss = 0.5876461863517761, train/logprobs = tensor([[-2.4277, -3.6848],
        [-1.3822, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23379147052764893
Epoch 0, Step 554: train/loss = 0.7015736699104309, train/raw-loss = 0.66590416431427, train/logprobs = tensor([[-1.4859, -2.5908],
        [-1.5223, -1.1896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14267811179161072
Epoch 0, Step 555: train/loss = 0.6935548782348633, train/raw-loss = 0.689138650894165, train/logprobs = tensor([[-1.7337, -1.9646],
        [-1.6500, -1.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017664911225438118
Epoch 0, Step 556: train/loss = 0.6900826692581177, train/raw-loss = 0.6541728973388672, train/logprobs = tensor([[-1.6635, -2.4395],
        [-1.1944, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14363925158977509
Epoch 0, Step 557: train/loss = 0.693435788154602, train/raw-loss = 0.690481960773468, train/logprobs = tensor([[-1.0336, -1.1245],
        [-0.9922, -1.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011815143749117851
Epoch 0, Step 558: train/loss = 0.6170170307159424, train/raw-loss = 0.5281715989112854, train/logprobs = tensor([[-1.7413, -3.3603],
        [-1.3275, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3553818464279175
Epoch 0, Step 559: train/loss = 0.7199037671089172, train/raw-loss = 0.7085928916931152, train/logprobs = tensor([[-1.7295, -2.5463],
        [-1.4775, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04524318873882294
Epoch 0, Step 560: train/loss = 0.6745184659957886, train/raw-loss = 0.6503232717514038, train/logprobs = tensor([[-1.1551, -1.7080],
        [-1.2617, -0.7187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09678097814321518
Epoch 0, Step 561: train/loss = 0.7050144672393799, train/raw-loss = 0.6185996532440186, train/logprobs = tensor([[-1.7002, -2.7038],
        [-1.5407, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3456594944000244
Epoch 0, Step 562: train/loss = 0.6345106363296509, train/raw-loss = 0.5321540832519531, train/logprobs = tensor([[-1.1500, -3.0542],
        [-1.2809, -0.4976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4094260334968567
Epoch 0, Step 563: train/loss = 0.6804941296577454, train/raw-loss = 0.6440510749816895, train/logprobs = tensor([[-1.3049, -2.0466],
        [-1.6800, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.145772323012352
Epoch 0, Step 564: train/loss = 0.636966347694397, train/raw-loss = 0.5209215879440308, train/logprobs = tensor([[-0.8905, -3.6182],
        [-1.6995, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46417874097824097
Epoch 0, Step 565: train/loss = 0.663210928440094, train/raw-loss = 0.5650168657302856, train/logprobs = tensor([[-1.5250, -4.1061],
        [-1.6054, -1.1238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3927761912345886
Epoch 0, Step 566: train/loss = 0.6935812830924988, train/raw-loss = 0.6916024088859558, train/logprobs = tensor([[-2.0503, -2.2971],
        [-1.0597, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007915474474430084
Epoch 0, Step 567: train/loss = 0.6206021308898926, train/raw-loss = 0.5393744707107544, train/logprobs = tensor([[-1.3871, -3.3452],
        [-1.8851, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32491037249565125
Epoch 0, Step 568: train/loss = 0.7049516439437866, train/raw-loss = 0.702145516872406, train/logprobs = tensor([[-1.6355, -1.9291],
        [-1.4708, -1.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011224579997360706
Epoch 0, Step 569: train/loss = 0.6580229997634888, train/raw-loss = 0.6063618063926697, train/logprobs = tensor([[-2.3114, -3.2985],
        [-1.3726, -0.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20664483308792114
Epoch 0, Step 570: train/loss = 0.7951700687408447, train/raw-loss = 0.761125922203064, train/logprobs = tensor([[-2.0050, -3.2381],
        [-1.2300, -1.6739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13617660105228424
Epoch 0, Step 571: train/loss = 0.6314356327056885, train/raw-loss = 0.5700311660766602, train/logprobs = tensor([[-1.1477, -2.4371],
        [-1.7699, -0.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24561771750450134
Epoch 0, Step 572: train/loss = 0.6497429609298706, train/raw-loss = 0.5677192211151123, train/logprobs = tensor([[-1.1345, -3.3554],
        [-1.3310, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32809510827064514
Epoch 0, Step 573: train/loss = 0.6939136981964111, train/raw-loss = 0.6857774257659912, train/logprobs = tensor([[-1.5238, -1.5739],
        [-1.1292, -0.9105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03254522383213043
Epoch 0, Step 574: train/loss = 0.7087529897689819, train/raw-loss = 0.635866105556488, train/logprobs = tensor([[-1.1009, -3.7119],
        [-1.4384, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2915477752685547
Epoch 0, Step 575: train/loss = 0.6904317736625671, train/raw-loss = 0.6531103253364563, train/logprobs = tensor([[-1.2227, -1.4821],
        [-2.0104, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14928558468818665
Epoch 0, Step 576: train/loss = 0.7122462391853333, train/raw-loss = 0.6579209566116333, train/logprobs = tensor([[-1.5946, -2.8425],
        [-2.0406, -1.2328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21730118989944458
Epoch 0, Step 577: train/loss = 0.6639845371246338, train/raw-loss = 0.6217551827430725, train/logprobs = tensor([[-1.4669, -2.1474],
        [-1.3259, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16891759634017944
Epoch 0, Step 578: train/loss = 0.620684027671814, train/raw-loss = 0.5436302423477173, train/logprobs = tensor([[-1.9839, -4.0447],
        [-1.4332, -0.7879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3082154393196106
Epoch 0, Step 579: train/loss = 0.6494281888008118, train/raw-loss = 0.6063591241836548, train/logprobs = tensor([[-1.9701, -3.0235],
        [-1.5365, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17227625846862793
Epoch 0, Step 580: train/loss = 0.5939954519271851, train/raw-loss = 0.47125646471977234, train/logprobs = tensor([[-1.0766, -3.9258],
        [-1.9057, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4909559488296509
Epoch 0, Step 581: train/loss = 0.6773939728736877, train/raw-loss = 0.6610916256904602, train/logprobs = tensor([[-1.3146, -1.8480],
        [-1.0449, -0.7059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06520931422710419
Epoch 0, Step 582: train/loss = 0.6360926628112793, train/raw-loss = 0.5530587434768677, train/logprobs = tensor([[-1.1197, -2.8163],
        [-1.7313, -0.8895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33213546872138977
Epoch 0, Step 583: train/loss = 0.6293911933898926, train/raw-loss = 0.5573114156723022, train/logprobs = tensor([[-1.3475, -3.0391],
        [-1.4059, -0.6678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2883187532424927
Epoch 0, Step 584: train/loss = 0.6468592286109924, train/raw-loss = 0.6024885177612305, train/logprobs = tensor([[-2.5007, -3.3951],
        [-1.5052, -0.9433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17748290300369263
Epoch 0, Step 585: train/loss = 0.8094801306724548, train/raw-loss = 0.8053658604621887, train/logprobs = tensor([[-1.4686, -2.0155],
        [-0.6953, -0.9322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016456972807645798
Epoch 0, Step 586: train/loss = 0.6897621154785156, train/raw-loss = 0.6842594146728516, train/logprobs = tensor([[-1.6845, -1.8651],
        [-1.6795, -1.3073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02201075106859207
Epoch 0, Step 587: train/loss = 0.7050618529319763, train/raw-loss = 0.6973580121994019, train/logprobs = tensor([[-3.0578, -3.2708],
        [-1.5211, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030815597623586655
Epoch 0, Step 588: train/loss = 0.6590175628662109, train/raw-loss = 0.5440916419029236, train/logprobs = tensor([[-0.9322, -3.7068],
        [-1.7277, -1.3885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45970362424850464
Epoch 0, Step 589: train/loss = 0.6473293304443359, train/raw-loss = 0.5790001153945923, train/logprobs = tensor([[-1.5633, -3.1342],
        [-1.7178, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27331697940826416
Epoch 0, Step 590: train/loss = 0.6533682346343994, train/raw-loss = 0.6171310544013977, train/logprobs = tensor([[-2.2099, -3.0874],
        [-1.1301, -0.7342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494852721691132
Epoch 0, Step 591: train/loss = 0.7146817445755005, train/raw-loss = 0.6882833242416382, train/logprobs = tensor([[-1.4859, -2.4527],
        [-1.2633, -1.4850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10559354722499847
Epoch 0, Step 592: train/loss = 0.6266275644302368, train/raw-loss = 0.5322380065917969, train/logprobs = tensor([[-1.4201, -4.1472],
        [-1.4295, -1.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.377558171749115
Epoch 0, Step 593: train/loss = 0.5965142846107483, train/raw-loss = 0.5091745257377625, train/logprobs = tensor([[-2.3497, -4.1086],
        [-1.4785, -0.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3493591547012329
Epoch 0, Step 594: train/loss = 0.6001760959625244, train/raw-loss = 0.5046650171279907, train/logprobs = tensor([[-2.1557, -4.5215],
        [-1.6486, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38204440474510193
Epoch 0, Step 595: train/loss = 0.5582112073898315, train/raw-loss = 0.4249840974807739, train/logprobs = tensor([[-1.4466, -4.6736],
        [-3.1411, -1.8099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5329086184501648
Epoch 0, Step 596: train/loss = 0.6582441926002502, train/raw-loss = 0.6196367144584656, train/logprobs = tensor([[-1.3511, -2.3743],
        [-2.0920, -1.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15442980825901031
Epoch 0, Step 597: train/loss = 0.6197138428688049, train/raw-loss = 0.5507190823554993, train/logprobs = tensor([[-1.5263, -3.2973],
        [-1.4717, -0.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2759789228439331
Epoch 0, Step 598: train/loss = 0.6517249345779419, train/raw-loss = 0.6109050512313843, train/logprobs = tensor([[-1.5382, -2.5011],
        [-1.2648, -0.7446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1632796972990036
Epoch 0, Step 599: train/loss = 0.6943337917327881, train/raw-loss = 0.6943145394325256, train/logprobs = tensor([[-1.3859, -1.4617],
        [-0.8370, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.698265835642815e-05
Epoch 0, Step 600: train/loss = 0.6603776812553406, train/raw-loss = 0.6156686544418335, train/logprobs = tensor([[-1.2226, -2.0637],
        [-1.6608, -1.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788363754749298
Epoch 0, Step 601: train/loss = 0.6930174827575684, train/raw-loss = 0.6911357045173645, train/logprobs = tensor([[-1.6192, -1.4861],
        [-1.3157, -1.3622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007527101319283247
Epoch 0, Step 602: train/loss = 0.69659823179245, train/raw-loss = 0.6822145581245422, train/logprobs = tensor([[-1.5261, -1.8757],
        [-0.9597, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057534731924533844
Epoch 0, Step 603: train/loss = 0.6009541749954224, train/raw-loss = 0.5006794333457947, train/logprobs = tensor([[-0.9196, -3.2024],
        [-1.8304, -0.9667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4010990560054779
Epoch 0, Step 604: train/loss = 0.6822702288627625, train/raw-loss = 0.6431431770324707, train/logprobs = tensor([[-1.6723, -2.2738],
        [-1.4301, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15650804340839386
Epoch 0, Step 605: train/loss = 0.6492902040481567, train/raw-loss = 0.5946958661079407, train/logprobs = tensor([[-1.0043, -2.2646],
        [-1.2246, -0.8182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21837717294692993
Epoch 0, Step 606: train/loss = 0.701473593711853, train/raw-loss = 0.6981731653213501, train/logprobs = tensor([[-1.9237, -1.9524],
        [-1.3317, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013201715424656868
Epoch 0, Step 607: train/loss = 0.6717358231544495, train/raw-loss = 0.5606473088264465, train/logprobs = tensor([[-1.0150, -3.8144],
        [-1.2177, -1.0119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4443541467189789
Epoch 0, Step 608: train/loss = 0.6983818411827087, train/raw-loss = 0.6901668906211853, train/logprobs = tensor([[-1.4069, -1.8889],
        [-1.1226, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03285978361964226
Epoch 0, Step 609: train/loss = 0.6304047107696533, train/raw-loss = 0.5310220718383789, train/logprobs = tensor([[-1.3514, -3.5076],
        [-2.0776, -1.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39753082394599915
Epoch 0, Step 610: train/loss = 0.8716212511062622, train/raw-loss = 0.8691567182540894, train/logprobs = tensor([[-1.2421, -1.9552],
        [-1.8650, -2.2904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009858286008238792
Epoch 0, Step 611: train/loss = 0.8134406805038452, train/raw-loss = 0.739528238773346, train/logprobs = tensor([[-2.3394, -1.9159],
        [-2.2078, -1.3537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2956496477127075
Epoch 0, Step 612: train/loss = 0.6857250928878784, train/raw-loss = 0.6718231439590454, train/logprobs = tensor([[-1.0570, -1.2770],
        [-1.7366, -1.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05560794472694397
Epoch 0, Step 613: train/loss = 0.6681954860687256, train/raw-loss = 0.6146316528320312, train/logprobs = tensor([[-1.0620, -1.8662],
        [-1.9554, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21425531804561615
Epoch 0, Step 614: train/loss = 0.6860165596008301, train/raw-loss = 0.6614636182785034, train/logprobs = tensor([[-2.1453, -2.2573],
        [-1.6190, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09821180254220963
Epoch 0, Step 615: train/loss = 0.7046306133270264, train/raw-loss = 0.6918072700500488, train/logprobs = tensor([[-2.4581, -2.8473],
        [-1.3988, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051293451339006424
Epoch 0, Step 616: train/loss = 0.6706772446632385, train/raw-loss = 0.5556554794311523, train/logprobs = tensor([[-1.7503, -4.4298],
        [-1.9352, -1.8236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4600870609283447
Epoch 0, Step 617: train/loss = 0.6096822619438171, train/raw-loss = 0.5075903534889221, train/logprobs = tensor([[-0.9961, -3.3126],
        [-1.7000, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4083676040172577
Epoch 0, Step 618: train/loss = 0.707547128200531, train/raw-loss = 0.6783758401870728, train/logprobs = tensor([[-2.4100, -2.8810],
        [-1.7987, -1.5667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11668525636196136
Epoch 0, Step 619: train/loss = 0.6657658815383911, train/raw-loss = 0.6225731372833252, train/logprobs = tensor([[-1.7951, -2.5640],
        [-2.1061, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727709323167801
Epoch 0, Step 620: train/loss = 0.6860087513923645, train/raw-loss = 0.6121652126312256, train/logprobs = tensor([[-1.1802, -3.2101],
        [-1.6549, -1.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29537394642829895
Epoch 0, Step 621: train/loss = 0.6815766096115112, train/raw-loss = 0.6437973976135254, train/logprobs = tensor([[-1.1518, -1.6900],
        [-1.8373, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.151117205619812
Epoch 0, Step 622: train/loss = 0.6007837057113647, train/raw-loss = 0.48399096727371216, train/logprobs = tensor([[-1.6691, -4.0753],
        [-1.8125, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46717092394828796
Epoch 0, Step 623: train/loss = 0.7415163516998291, train/raw-loss = 0.7155869007110596, train/logprobs = tensor([[-2.0670, -2.4222],
        [-1.9962, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10371781885623932
Epoch 0, Step 624: train/loss = 0.6018847823143005, train/raw-loss = 0.4823681116104126, train/logprobs = tensor([[-1.3861, -3.5919],
        [-2.0328, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.478066623210907
Epoch 0, Step 625: train/loss = 0.6936004161834717, train/raw-loss = 0.6269559860229492, train/logprobs = tensor([[-0.8325, -2.5876],
        [-1.6679, -1.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2665777802467346
Epoch 0, Step 626: train/loss = 0.6429265141487122, train/raw-loss = 0.6023655533790588, train/logprobs = tensor([[-1.8893, -2.4507],
        [-1.9510, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1622437983751297
Epoch 0, Step 627: train/loss = 0.7188646197319031, train/raw-loss = 0.7113402485847473, train/logprobs = tensor([[-3.2857, -3.1826],
        [-1.5260, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03009733185172081
Epoch 0, Step 628: train/loss = 0.61822110414505, train/raw-loss = 0.5518662929534912, train/logprobs = tensor([[-1.8713, -3.0449],
        [-2.3330, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2654191851615906
Epoch 0, Step 629: train/loss = 0.5675408840179443, train/raw-loss = 0.4374881982803345, train/logprobs = tensor([[-2.1581, -4.2501],
        [-1.9686, -0.7207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5202106237411499
Epoch 0, Step 630: train/loss = 0.62415611743927, train/raw-loss = 0.5277259349822998, train/logprobs = tensor([[-0.9141, -2.2974],
        [-2.2177, -0.7989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38572078943252563
Epoch 0, Step 631: train/loss = 0.49174565076828003, train/raw-loss = 0.313102662563324, train/logprobs = tensor([[-1.1676, -4.3823],
        [-2.5249, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7145719528198242
Epoch 0, Step 632: train/loss = 0.6532560586929321, train/raw-loss = 0.6025213599205017, train/logprobs = tensor([[-2.3494, -3.5552],
        [-1.8749, -1.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2029387354850769
Epoch 0, Step 633: train/loss = 0.6809539198875427, train/raw-loss = 0.6685552597045898, train/logprobs = tensor([[-2.9277, -3.3094],
        [-1.0675, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04959461838006973
Epoch 0, Step 634: train/loss = 0.6104742884635925, train/raw-loss = 0.5265976786613464, train/logprobs = tensor([[-2.6774, -4.6326],
        [-1.7254, -0.9623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33550670742988586
Epoch 0, Step 635: train/loss = 0.6484914422035217, train/raw-loss = 0.6044429540634155, train/logprobs = tensor([[-3.3263, -4.0596],
        [-1.0367, -0.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17619358003139496
Epoch 0, Step 636: train/loss = 0.5930874943733215, train/raw-loss = 0.4631364941596985, train/logprobs = tensor([[-1.8334, -4.4320],
        [-1.9315, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5198040008544922
Epoch 0, Step 637: train/loss = 0.5994008779525757, train/raw-loss = 0.5142285823822021, train/logprobs = tensor([[-1.2540, -2.3284],
        [-2.3766, -0.8986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34068936109542847
Epoch 0, Step 638: train/loss = 0.5780874490737915, train/raw-loss = 0.4955795705318451, train/logprobs = tensor([[-1.0482, -3.2863],
        [-2.6769, -1.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3300316035747528
Epoch 0, Step 639: train/loss = 0.5917853713035583, train/raw-loss = 0.4439258873462677, train/logprobs = tensor([[-1.3029, -4.1482],
        [-1.9364, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5914381146430969
Epoch 0, Step 640: train/loss = 0.49274054169654846, train/raw-loss = 0.3560869097709656, train/logprobs = tensor([[-2.1339, -5.5759],
        [-2.8156, -1.3018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5466144680976868
Epoch 0, Step 641: train/loss = 0.5693960785865784, train/raw-loss = 0.46579626202583313, train/logprobs = tensor([[-2.1060, -4.0038],
        [-3.0449, -1.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41439926624298096
Epoch 0, Step 642: train/loss = 0.6271193623542786, train/raw-loss = 0.5657129883766174, train/logprobs = tensor([[-2.2093, -3.4619],
        [-1.3654, -0.9202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24562548100948334
Epoch 0, Step 643: train/loss = 0.5730280876159668, train/raw-loss = 0.4524921476840973, train/logprobs = tensor([[-1.8518, -3.7884],
        [-2.6876, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48214393854141235
Epoch 0, Step 644: train/loss = 0.63702392578125, train/raw-loss = 0.5277725458145142, train/logprobs = tensor([[-1.8743, -4.2128],
        [-1.7352, -1.2016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43700531125068665
Epoch 0, Step 645: train/loss = 0.6890236139297485, train/raw-loss = 0.6653313040733337, train/logprobs = tensor([[-3.8153, -3.3517],
        [-1.4950, -1.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0947692021727562
Epoch 0, Step 646: train/loss = 0.6953845620155334, train/raw-loss = 0.6261221170425415, train/logprobs = tensor([[-0.9547, -2.1988],
        [-3.2171, -2.4703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2770499289035797
Epoch 0, Step 647: train/loss = 0.49145230650901794, train/raw-loss = 0.3038499653339386, train/logprobs = tensor([[-0.9751, -3.7646],
        [-2.7664, -0.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7504093647003174
Epoch 0, Step 648: train/loss = 0.5604695081710815, train/raw-loss = 0.3813869059085846, train/logprobs = tensor([[-1.5748, -4.0331],
        [-2.9799, -0.7431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7163304686546326
Epoch 0, Step 649: train/loss = 0.5623753070831299, train/raw-loss = 0.4358915686607361, train/logprobs = tensor([[-0.8954, -2.7374],
        [-3.0236, -1.5934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.50593501329422
Epoch 0, Step 650: train/loss = 0.6198886632919312, train/raw-loss = 0.5470783710479736, train/logprobs = tensor([[-0.9023, -2.2214],
        [-2.1811, -1.5595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29124119877815247
Epoch 0, Step 651: train/loss = 0.6822462677955627, train/raw-loss = 0.6342735290527344, train/logprobs = tensor([[-2.6762, -3.1760],
        [-2.2426, -1.3513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19189080595970154
Epoch 0, Step 652: train/loss = 0.6853024959564209, train/raw-loss = 0.6398876905441284, train/logprobs = tensor([[-3.5531, -3.3905],
        [-1.9046, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18165908753871918
Epoch 0, Step 653: train/loss = 0.5817436575889587, train/raw-loss = 0.46707868576049805, train/logprobs = tensor([[-1.2071, -3.2280],
        [-2.6353, -1.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45865973830223083
Epoch 0, Step 654: train/loss = 0.6379832029342651, train/raw-loss = 0.5669811964035034, train/logprobs = tensor([[-1.5736, -2.1798],
        [-2.1334, -0.8087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2840079069137573
Epoch 0, Step 655: train/loss = 0.574353814125061, train/raw-loss = 0.45531922578811646, train/logprobs = tensor([[-1.8515, -5.3879],
        [-1.9234, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47613823413848877
Epoch 0, Step 656: train/loss = 0.601178765296936, train/raw-loss = 0.5161628723144531, train/logprobs = tensor([[-1.7338, -3.2627],
        [-2.4322, -1.3809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3400636315345764
Epoch 0, Step 657: train/loss = 0.5247215628623962, train/raw-loss = 0.3510451912879944, train/logprobs = tensor([[-2.8868, -5.4744],
        [-3.9789, -2.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6947053670883179
Epoch 0, Step 658: train/loss = 0.619678258895874, train/raw-loss = 0.5134903788566589, train/logprobs = tensor([[-1.8852, -4.0021],
        [-2.2224, -1.2648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42475154995918274
Epoch 0, Step 659: train/loss = 0.6212902069091797, train/raw-loss = 0.5449947118759155, train/logprobs = tensor([[-2.0579, -3.2882],
        [-3.0685, -2.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30518215894699097
Epoch 0, Step 660: train/loss = 0.6214697957038879, train/raw-loss = 0.5599699020385742, train/logprobs = tensor([[-3.4046, -4.1635],
        [-2.1923, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24599964916706085
Epoch 0, Step 661: train/loss = 0.6006598472595215, train/raw-loss = 0.5111103653907776, train/logprobs = tensor([[-3.2447, -4.9893],
        [-1.9684, -0.9602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3581978678703308
Epoch 0, Step 662: train/loss = 0.6022869348526001, train/raw-loss = 0.4604629874229431, train/logprobs = tensor([[-1.1966, -2.3096],
        [-3.1965, -0.6047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5672958493232727
Epoch 0, Step 663: train/loss = 0.5309724807739258, train/raw-loss = 0.3740711510181427, train/logprobs = tensor([[-1.8195, -3.6256],
        [-2.8665, -2.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6276053190231323
Epoch 0, Step 664: train/loss = 0.6630669832229614, train/raw-loss = 0.6198630332946777, train/logprobs = tensor([[-2.2536, -2.6746],
        [-1.8140, -1.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17281582951545715
Epoch 0, Step 665: train/loss = 0.5969594717025757, train/raw-loss = 0.5017504692077637, train/logprobs = tensor([[-1.6679, -3.3798],
        [-3.0482, -2.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38083603978157043
Epoch 0, Step 666: train/loss = 0.6574498414993286, train/raw-loss = 0.5988690853118896, train/logprobs = tensor([[-1.7985, -2.3418],
        [-2.4180, -1.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23432308435440063
Epoch 0, Step 667: train/loss = 0.6523183584213257, train/raw-loss = 0.5978356599807739, train/logprobs = tensor([[-1.7290, -2.6062],
        [-1.7608, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21793076395988464
Epoch 0, Step 668: train/loss = 0.5879297852516174, train/raw-loss = 0.460534006357193, train/logprobs = tensor([[-2.1887, -4.2067],
        [-2.3948, -0.7696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5095832347869873
Epoch 0, Step 669: train/loss = 0.5748972296714783, train/raw-loss = 0.41473132371902466, train/logprobs = tensor([[-2.0673, -4.7704],
        [-2.7928, -0.9964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6406635046005249
Epoch 0, Step 670: train/loss = 0.5621817708015442, train/raw-loss = 0.42866718769073486, train/logprobs = tensor([[-2.0983, -4.3598],
        [-2.5374, -1.1733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5340582728385925
Epoch 0, Step 671: train/loss = 0.6486761569976807, train/raw-loss = 0.5555323362350464, train/logprobs = tensor([[-1.3731, -2.1958],
        [-3.2436, -1.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3725750744342804
Epoch 0, Step 672: train/loss = 0.6107798218727112, train/raw-loss = 0.5095918774604797, train/logprobs = tensor([[-1.7275, -3.1913],
        [-3.3463, -2.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4047517478466034
Epoch 0, Step 673: train/loss = 0.6254806518554688, train/raw-loss = 0.5065064430236816, train/logprobs = tensor([[-3.4807, -5.0185],
        [-1.3757, -0.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47589683532714844
Epoch 0, Step 674: train/loss = 0.5848602652549744, train/raw-loss = 0.48868608474731445, train/logprobs = tensor([[-2.3591, -5.0603],
        [-2.9479, -1.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3846967816352844
Epoch 0, Step 675: train/loss = 0.6614274978637695, train/raw-loss = 0.6094646453857422, train/logprobs = tensor([[-2.6995, -3.9122],
        [-1.0608, -0.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20785148441791534
Epoch 0, Step 676: train/loss = 0.5453433990478516, train/raw-loss = 0.36847591400146484, train/logprobs = tensor([[-1.2828, -4.8717],
        [-3.3891, -1.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7074698209762573
Epoch 0, Step 677: train/loss = 0.6131083965301514, train/raw-loss = 0.5009200572967529, train/logprobs = tensor([[-4.5704, -6.9750],
        [-1.5310, -0.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4487532377243042
Epoch 0, Step 678: train/loss = 0.630670428276062, train/raw-loss = 0.5341305136680603, train/logprobs = tensor([[-2.4725, -4.5818],
        [-2.8420, -2.2807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38615962862968445
Epoch 0, Step 679: train/loss = 0.5324856638908386, train/raw-loss = 0.36669525504112244, train/logprobs = tensor([[-1.6821, -4.3349],
        [-3.5950, -2.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6631616950035095
Epoch 0, Step 680: train/loss = 0.5346768498420715, train/raw-loss = 0.36603212356567383, train/logprobs = tensor([[-2.4799, -7.1149],
        [-2.3020, -1.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6745789647102356
Epoch 0, Step 681: train/loss = 0.5627331137657166, train/raw-loss = 0.43881118297576904, train/logprobs = tensor([[-2.8928, -5.2803],
        [-2.6691, -1.4863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4956878423690796
Epoch 0, Step 682: train/loss = 0.6224707365036011, train/raw-loss = 0.519627571105957, train/logprobs = tensor([[-1.8292, -4.3665],
        [-2.7921, -2.3029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41137251257896423
Epoch 0, Step 683: train/loss = 0.5205968618392944, train/raw-loss = 0.337523877620697, train/logprobs = tensor([[-2.2346, -5.8753],
        [-2.5314, -0.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7322919964790344
Epoch 0, Step 684: train/loss = 0.5957038402557373, train/raw-loss = 0.46408987045288086, train/logprobs = tensor([[-2.2858, -5.0592],
        [-2.5606, -1.6231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5264561176300049
Epoch 0, Step 685: train/loss = 0.6483142971992493, train/raw-loss = 0.595971941947937, train/logprobs = tensor([[-2.4157, -2.9327],
        [-2.1868, -2.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2093692123889923
Epoch 0, Step 686: train/loss = 0.5890411734580994, train/raw-loss = 0.49255457520484924, train/logprobs = tensor([[-3.1347, -4.8201],
        [-2.2719, -1.1354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3859461545944214
Epoch 0, Step 687: train/loss = 0.4987177550792694, train/raw-loss = 0.2721368968486786, train/logprobs = tensor([[-1.3523, -6.3375],
        [-3.7295, -1.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9063234329223633
Epoch 0, Step 688: train/loss = 0.6164336800575256, train/raw-loss = 0.53133624792099, train/logprobs = tensor([[-2.3300, -3.7983],
        [-3.6143, -2.8257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3403896987438202
Epoch 0, Step 689: train/loss = 0.5328320264816284, train/raw-loss = 0.37515339255332947, train/logprobs = tensor([[-1.9528, -4.9347],
        [-3.3398, -0.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6307143568992615
Epoch 0, Step 690: train/loss = 0.5161370038986206, train/raw-loss = 0.3029688000679016, train/logprobs = tensor([[-2.5341, -5.3200],
        [-3.2477, -2.0166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8526726365089417
Epoch 0, Step 691: train/loss = 0.4655125141143799, train/raw-loss = 0.25663113594055176, train/logprobs = tensor([[-1.8711, -6.0526],
        [-3.3522, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.835525631904602
Epoch 0, Step 692: train/loss = 0.4884089231491089, train/raw-loss = 0.31152549386024475, train/logprobs = tensor([[-2.5722, -5.4821],
        [-3.0674, -1.0458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7075337767601013
Epoch 0, Step 693: train/loss = 0.4431806206703186, train/raw-loss = 0.21213021874427795, train/logprobs = tensor([[-1.9833, -6.3537],
        [-4.6440, -1.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9242015480995178
Epoch 0, Step 694: train/loss = 0.6503518223762512, train/raw-loss = 0.5872349739074707, train/logprobs = tensor([[-3.0492, -3.9142],
        [-2.5112, -1.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2524675726890564
Epoch 0, Step 695: train/loss = 0.603336751461029, train/raw-loss = 0.5326919555664062, train/logprobs = tensor([[-3.0520, -4.5222],
        [-3.0501, -2.0271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2825793921947479
Epoch 0, Step 696: train/loss = 0.5515876412391663, train/raw-loss = 0.4052305519580841, train/logprobs = tensor([[-1.6991, -3.4547],
        [-3.4979, -1.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5854283571243286
Epoch 0, Step 697: train/loss = 0.5390571355819702, train/raw-loss = 0.3809870481491089, train/logprobs = tensor([[-3.5099, -6.0675],
        [-2.7704, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6322802901268005
Epoch 0, Step 698: train/loss = 0.5295742750167847, train/raw-loss = 0.37650203704833984, train/logprobs = tensor([[-3.8241, -6.3494],
        [-3.8930, -1.5567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6122889518737793
Epoch 0, Step 699: train/loss = 0.5242229104042053, train/raw-loss = 0.36618170142173767, train/logprobs = tensor([[-2.4021, -5.2693],
        [-2.5853, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.632164716720581
Epoch 0, Step 700: train/loss = 0.5741661787033081, train/raw-loss = 0.42219409346580505, train/logprobs = tensor([[-3.5563, -6.1318],
        [-2.6580, -1.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6078882813453674
Epoch 0, Step 701: train/loss = 0.6617101430892944, train/raw-loss = 0.5397577285766602, train/logprobs = tensor([[-3.2861, -5.7192],
        [-3.6459, -2.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48780983686447144
Epoch 0, Step 702: train/loss = 0.6107043623924255, train/raw-loss = 0.5151357650756836, train/logprobs = tensor([[-2.8055, -4.1808],
        [-2.6419, -1.4876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3822743892669678
Epoch 0, Step 703: train/loss = 0.6249914169311523, train/raw-loss = 0.5112793445587158, train/logprobs = tensor([[-2.7595, -5.7975],
        [-2.2458, -1.6633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45484837889671326
Epoch 0, Step 704: train/loss = 0.5217161774635315, train/raw-loss = 0.36373811960220337, train/logprobs = tensor([[-4.1897, -8.8014],
        [-3.5755, -1.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6319120526313782
Epoch 0, Step 705: train/loss = 0.529106855392456, train/raw-loss = 0.3879457712173462, train/logprobs = tensor([[-3.6674, -6.3300],
        [-3.4173, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5646442174911499
Epoch 0, Step 706: train/loss = 0.4094811677932739, train/raw-loss = 0.18148547410964966, train/logprobs = tensor([[-1.1641, -7.7945],
        [-5.4786, -0.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9119827151298523
Epoch 0, Step 707: train/loss = 0.6914641261100769, train/raw-loss = 0.6893086433410645, train/logprobs = tensor([[-4.7933, -4.7862],
        [-1.6397, -1.5589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008622044697403908
Epoch 0, Step 708: train/loss = 0.47601330280303955, train/raw-loss = 0.28897783160209656, train/logprobs = tensor([[-2.3571, -7.2519],
        [-4.1238, -1.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.748141884803772
Epoch 0, Step 709: train/loss = 0.49330753087997437, train/raw-loss = 0.2829381823539734, train/logprobs = tensor([[-2.0237, -6.0007],
        [-4.7522, -2.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8414773941040039
Epoch 0, Step 710: train/loss = 0.3564247190952301, train/raw-loss = 0.06258942931890488, train/logprobs = tensor([[-1.2962, -7.2547],
        [-5.7509, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1753411293029785
Epoch 0, Step 711: train/loss = 0.49744558334350586, train/raw-loss = 0.2523466944694519, train/logprobs = tensor([[-1.6150, -4.5188],
        [-5.3408, -3.2354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9803954362869263
Epoch 0, Step 712: train/loss = 0.6035360097885132, train/raw-loss = 0.5110269784927368, train/logprobs = tensor([[-3.0153, -4.5356],
        [-2.9691, -1.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3700360953807831
Epoch 0, Step 713: train/loss = 0.5848554372787476, train/raw-loss = 0.4426858127117157, train/logprobs = tensor([[-3.7305, -6.6554],
        [-2.6961, -1.5448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5686783790588379
Epoch 0, Step 714: train/loss = 0.5239862203598022, train/raw-loss = 0.3657751679420471, train/logprobs = tensor([[-2.6748, -6.1142],
        [-4.3752, -2.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6328442692756653
Epoch 0, Step 715: train/loss = 0.6364409327507019, train/raw-loss = 0.562124490737915, train/logprobs = tensor([[-2.1314, -1.9898],
        [-3.3783, -4.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.297265887260437
Epoch 0, Step 716: train/loss = 0.4955468475818634, train/raw-loss = 0.30860814452171326, train/logprobs = tensor([[-1.5488, -7.2527],
        [-5.2034, -2.1064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7477549314498901
Epoch 0, Step 717: train/loss = 0.5200098752975464, train/raw-loss = 0.3288496732711792, train/logprobs = tensor([[-1.9272, -5.6470],
        [-4.3234, -2.2052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7646408677101135
Epoch 0, Step 718: train/loss = 0.42317309975624084, train/raw-loss = 0.17226442694664001, train/logprobs = tensor([[-2.8171, -8.7497],
        [-3.7916, -0.5890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0036346912384033
Epoch 0, Step 719: train/loss = 0.46112260222435, train/raw-loss = 0.23443780839443207, train/logprobs = tensor([[-2.8459, -8.2548],
        [-3.6841, -1.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9067392349243164
Epoch 0, Step 720: train/loss = 0.8753892183303833, train/raw-loss = 0.8419698476791382, train/logprobs = tensor([[-4.9588, -6.2948],
        [-4.3113, -4.6733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13367779552936554
Epoch 0, Step 721: train/loss = 0.5363715887069702, train/raw-loss = 0.36903032660484314, train/logprobs = tensor([[-3.2258, -6.9939],
        [-4.0311, -1.8346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6693649291992188
Epoch 0, Step 722: train/loss = 0.5166674852371216, train/raw-loss = 0.33840233087539673, train/logprobs = tensor([[-2.0604, -5.9108],
        [-6.1404, -4.1728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7130606770515442
Epoch 0, Step 723: train/loss = 0.6289396286010742, train/raw-loss = 0.5507935881614685, train/logprobs = tensor([[-3.6724, -5.0086],
        [-3.7632, -3.0083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31258445978164673
Epoch 0, Step 724: train/loss = 0.5436413884162903, train/raw-loss = 0.38591569662094116, train/logprobs = tensor([[-1.6019, -5.8584],
        [-5.2942, -2.6628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.630902886390686
Epoch 0, Step 725: train/loss = 0.518987774848938, train/raw-loss = 0.3437272608280182, train/logprobs = tensor([[-2.9174, -6.5675],
        [-3.8218, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7010421752929688
Epoch 0, Step 726: train/loss = 0.5838609337806702, train/raw-loss = 0.47760653495788574, train/logprobs = tensor([[-3.7135, -5.8052],
        [-4.0799, -2.5343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4250176250934601
Epoch 0, Step 727: train/loss = 0.3869079649448395, train/raw-loss = 0.08385865390300751, train/logprobs = tensor([[-1.5402, -7.3072],
        [-5.7444, -2.0590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2121973037719727
Epoch 0, Step 728: train/loss = 0.7251190543174744, train/raw-loss = 0.7016199827194214, train/logprobs = tensor([[-3.7321, -4.0027],
        [-3.4188, -3.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09399613738059998
Epoch 0, Step 729: train/loss = 0.6169546842575073, train/raw-loss = 0.5344043970108032, train/logprobs = tensor([[-3.3350, -5.0773],
        [-2.4661, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33020126819610596
Epoch 0, Step 730: train/loss = 0.6491539478302002, train/raw-loss = 0.5429372787475586, train/logprobs = tensor([[-5.1903, -7.1809],
        [-3.7346, -2.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4248667359352112
Epoch 0, Step 731: train/loss = 0.4784443974494934, train/raw-loss = 0.25689542293548584, train/logprobs = tensor([[-2.3760, -5.8267],
        [-5.7957, -1.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8861958980560303
Epoch 0, Step 732: train/loss = 0.4608820080757141, train/raw-loss = 0.20010215044021606, train/logprobs = tensor([[-2.8659, -9.5586],
        [-4.7790, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0431195497512817
Epoch 0, Step 733: train/loss = 0.4365161061286926, train/raw-loss = 0.21132241189479828, train/logprobs = tensor([[-1.5867, -6.3465],
        [-4.8231, -1.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9007748365402222
Epoch 0, Step 734: train/loss = 0.6765579581260681, train/raw-loss = 0.6063565015792847, train/logprobs = tensor([[-3.6565, -3.4773],
        [-3.1069, -3.4250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28080588579177856
Epoch 0, Step 735: train/loss = 0.4644082486629486, train/raw-loss = 0.24653524160385132, train/logprobs = tensor([[-4.1009, -7.5740],
        [-3.9853, -1.3417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8714919686317444
Epoch 0, Step 736: train/loss = 0.4505895674228668, train/raw-loss = 0.20980793237686157, train/logprobs = tensor([[-3.6895, -8.5396],
        [-5.8256, -2.7601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9631265997886658
Epoch 0, Step 737: train/loss = 0.5785397887229919, train/raw-loss = 0.4314635396003723, train/logprobs = tensor([[-4.4001, -7.0487],
        [-3.5013, -1.8752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5883049368858337
Epoch 0, Step 738: train/loss = 0.6091285347938538, train/raw-loss = 0.5290977954864502, train/logprobs = tensor([[-5.9079, -6.9835],
        [-2.6307, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3201231062412262
Epoch 0, Step 739: train/loss = 0.60560142993927, train/raw-loss = 0.5117289423942566, train/logprobs = tensor([[-3.7313, -6.6289],
        [-5.3494, -3.7040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37548989057540894
Epoch 0, Step 740: train/loss = 0.623129665851593, train/raw-loss = 0.5405368804931641, train/logprobs = tensor([[-3.9297, -6.2733],
        [-3.9888, -2.8848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3303709328174591
Epoch 0, Step 741: train/loss = 0.4054677486419678, train/raw-loss = 0.1017097607254982, train/logprobs = tensor([[ -2.8657, -10.1312],
        [ -4.8676,  -1.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2150318622589111
Epoch 0, Step 742: train/loss = 0.34553027153015137, train/raw-loss = 0.06495463103055954, train/logprobs = tensor([[ -2.4528, -10.2081],
        [ -7.4303,  -2.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.122302532196045
Epoch 0, Step 743: train/loss = 0.4280332028865814, train/raw-loss = 0.18037763237953186, train/logprobs = tensor([[ -2.3492, -10.0457],
        [ -5.9190,  -1.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9906224012374878
Epoch 0, Step 744: train/loss = 0.3041740655899048, train/raw-loss = 0.029487518593668938, train/logprobs = tensor([[ -2.0195, -10.2132],
        [ -6.2184,  -2.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0987462997436523
Epoch 0, Step 745: train/loss = 0.5959386825561523, train/raw-loss = 0.452970951795578, train/logprobs = tensor([[-3.0170, -4.1654],
        [-5.3588, -4.5826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5718708038330078
Epoch 0, Step 746: train/loss = 0.6243400573730469, train/raw-loss = 0.5357263088226318, train/logprobs = tensor([[-4.4996, -5.2400],
        [-3.1023, -3.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35445496439933777
Epoch 0, Step 747: train/loss = 0.6003180146217346, train/raw-loss = 0.4948933720588684, train/logprobs = tensor([[-2.6796, -5.1253],
        [-6.6938, -4.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42169857025146484
Epoch 0, Step 748: train/loss = 0.6639986038208008, train/raw-loss = 0.6196026802062988, train/logprobs = tensor([[-3.0389, -3.8345],
        [-5.1052, -4.6378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17758366465568542
Epoch 0, Step 749: train/loss = 0.40457579493522644, train/raw-loss = 0.1783207356929779, train/logprobs = tensor([[-1.6958, -8.2196],
        [-7.9665, -2.8018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9050201177597046
Epoch 0, Step 750: train/loss = 0.40468478202819824, train/raw-loss = 0.11554466187953949, train/logprobs = tensor([[-3.3029, -7.2787],
        [-5.5629, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1565606594085693
Epoch 0, Step 751: train/loss = 0.6658241152763367, train/raw-loss = 0.6061146855354309, train/logprobs = tensor([[-3.8401, -5.1766],
        [-4.1340, -3.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23883767426013947
Epoch 0, Step 752: train/loss = 0.6485636234283447, train/raw-loss = 0.5690508484840393, train/logprobs = tensor([[ -8.7021, -10.7499],
        [ -3.0210,  -2.5075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3180512487888336
Epoch 0, Step 753: train/loss = 0.640527606010437, train/raw-loss = 0.5418071746826172, train/logprobs = tensor([[-4.1498, -8.7616],
        [-4.5575, -2.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39488187432289124
Epoch 0, Step 754: train/loss = 0.5284281969070435, train/raw-loss = 0.34213247895240784, train/logprobs = tensor([[-3.7462, -7.0912],
        [-6.1867, -3.7769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7451828122138977
Epoch 0, Step 755: train/loss = 0.43770119547843933, train/raw-loss = 0.21745076775550842, train/logprobs = tensor([[ -4.7578, -11.8872],
        [ -5.8422,  -1.7148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8810015916824341
Epoch 0, Step 756: train/loss = 0.5133130550384521, train/raw-loss = 0.33969688415527344, train/logprobs = tensor([[-4.7637, -8.1295],
        [-5.6646, -3.0747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6944646239280701
Epoch 0, Step 757: train/loss = 0.7025760412216187, train/raw-loss = 0.6934503316879272, train/logprobs = tensor([[-2.4917, -3.0862],
        [-7.6178, -7.6364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036502908915281296
Epoch 0, Step 758: train/loss = 0.6129594445228577, train/raw-loss = 0.5360709428787231, train/logprobs = tensor([[-3.2903, -4.6505],
        [-5.9860, -4.9142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30755382776260376
Epoch 0, Step 759: train/loss = 0.43598026037216187, train/raw-loss = 0.1753358393907547, train/logprobs = tensor([[ -4.4771, -11.2626],
        [ -5.8567,  -2.8314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0425777435302734
Epoch 0, Step 760: train/loss = 0.5425744652748108, train/raw-loss = 0.40024232864379883, train/logprobs = tensor([[-3.1085, -6.4511],
        [-6.1487, -4.6651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5693284869194031
Epoch 0, Step 761: train/loss = 0.5224716067314148, train/raw-loss = 0.3648744225502014, train/logprobs = tensor([[ -5.7847, -10.7084],
        [ -6.1519,  -3.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6303886771202087
Epoch 0, Step 762: train/loss = 0.6604025363922119, train/raw-loss = 0.5814539194107056, train/logprobs = tensor([[ -8.1703, -10.7971],
        [ -3.3348,  -3.1365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31579458713531494
Epoch 0, Step 763: train/loss = 0.6407263278961182, train/raw-loss = 0.5520731210708618, train/logprobs = tensor([[-4.4887, -4.9973],
        [-5.3506, -4.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35461264848709106
Epoch 0, Step 764: train/loss = 0.5506715774536133, train/raw-loss = 0.3419019877910614, train/logprobs = tensor([[ -6.9525, -12.9343],
        [ -4.9936,  -2.6712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8350785970687866
Epoch 0, Step 765: train/loss = 0.6421275734901428, train/raw-loss = 0.469878226518631, train/logprobs = tensor([[ -5.2754, -10.2958],
        [ -3.5114,  -2.5337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6889975070953369
Epoch 0, Step 766: train/loss = 0.5838252305984497, train/raw-loss = 0.44399186968803406, train/logprobs = tensor([[-3.0516, -4.6593],
        [-6.6141, -4.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5593333840370178
Epoch 0, Step 767: train/loss = 0.6583352088928223, train/raw-loss = 0.6229012608528137, train/logprobs = tensor([[-3.6247, -4.2424],
        [-4.8659, -4.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14173579216003418
Epoch 0, Step 768: train/loss = 0.750206470489502, train/raw-loss = 0.6565531492233276, train/logprobs = tensor([[-5.5175, -9.1834],
        [-5.6286, -3.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37461307644844055
Epoch 0, Step 769: train/loss = 0.3371628522872925, train/raw-loss = 0.017054637894034386, train/logprobs = tensor([[ -2.6184, -13.5874],
        [ -8.5244,  -3.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.280432939529419
Epoch 0, Step 770: train/loss = 0.4808841347694397, train/raw-loss = 0.23506638407707214, train/logprobs = tensor([[ -5.8623, -12.8511],
        [ -8.1111,  -4.3538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9832710027694702
Epoch 0, Step 771: train/loss = 0.5104783177375793, train/raw-loss = 0.3622501790523529, train/logprobs = tensor([[ -6.0747, -12.5833],
        [ -6.5942,  -4.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.592912495136261
Epoch 0, Step 772: train/loss = 0.3449317216873169, train/raw-loss = 0.011282248422503471, train/logprobs = tensor([[ -2.9891, -14.8255],
        [ -8.6759,  -3.7189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3345978260040283
Epoch 0, Step 773: train/loss = 0.5762471556663513, train/raw-loss = 0.37732115387916565, train/logprobs = tensor([[-2.9431, -7.8590],
        [-9.2506, -7.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7957040071487427
Epoch 0, Step 774: train/loss = 0.5977677702903748, train/raw-loss = 0.3749912679195404, train/logprobs = tensor([[ -4.4649, -10.8576],
        [ -7.0378,  -4.7578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8911059498786926
Epoch 0, Step 775: train/loss = 0.6195942163467407, train/raw-loss = 0.46674755215644836, train/logprobs = tensor([[ -6.6860, -12.1852],
        [ -5.2884,  -3.4567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.611386775970459
Epoch 0, Step 776: train/loss = 0.5361672639846802, train/raw-loss = 0.37408727407455444, train/logprobs = tensor([[-5.9267, -7.5012],
        [-6.1137, -4.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6483197808265686
Epoch 0, Step 777: train/loss = 0.5717645883560181, train/raw-loss = 0.4171257019042969, train/logprobs = tensor([[-6.4702, -8.5724],
        [-5.5223, -3.6000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6185553073883057
Epoch 0, Step 778: train/loss = 0.39730364084243774, train/raw-loss = 0.098578542470932, train/logprobs = tensor([[ -4.2448, -11.7199],
        [ -7.8049,  -4.2769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1949002742767334
Epoch 0, Step 779: train/loss = 0.6258763074874878, train/raw-loss = 0.5298871994018555, train/logprobs = tensor([[-6.7209, -8.3735],
        [-4.3281, -2.4807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38395652174949646
Epoch 0, Step 780: train/loss = 0.4660951495170593, train/raw-loss = 0.24118897318840027, train/logprobs = tensor([[ -6.4341, -10.7308],
        [ -6.2780,  -3.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8996247053146362
Epoch 0, Step 781: train/loss = 0.5655469298362732, train/raw-loss = 0.4414929449558258, train/logprobs = tensor([[ -7.9611, -10.5295],
        [ -4.8464,  -3.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4962160885334015
Epoch 0, Step 782: train/loss = 0.7159520387649536, train/raw-loss = 0.6301348805427551, train/logprobs = tensor([[-7.4137, -9.7342],
        [-4.9715, -2.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3432682156562805
Epoch 0, Step 783: train/loss = 0.45682501792907715, train/raw-loss = 0.2012292593717575, train/logprobs = tensor([[ -3.7526, -11.6580],
        [ -6.7563,  -3.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0223829746246338
Epoch 0, Step 784: train/loss = 0.5489997863769531, train/raw-loss = 0.4424401521682739, train/logprobs = tensor([[-6.7857, -9.7391],
        [-6.5886, -4.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4262387752532959
Epoch 0, Step 785: train/loss = 0.5283071398735046, train/raw-loss = 0.3330947756767273, train/logprobs = tensor([[ -6.8951, -14.2492],
        [ -7.9208,  -4.4448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7808494567871094
Epoch 0, Step 786: train/loss = 0.4212600588798523, train/raw-loss = 0.14361096918582916, train/logprobs = tensor([[ -4.5568, -11.9701],
        [ -8.5282,  -6.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1105964183807373
Epoch 0, Step 787: train/loss = 0.6276134252548218, train/raw-loss = 0.5377585887908936, train/logprobs = tensor([[ -7.1310, -10.6246],
        [ -7.0189,  -5.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3594192564487457
Epoch 0, Step 788: train/loss = 0.42752593755722046, train/raw-loss = 0.17710189521312714, train/logprobs = tensor([[ -4.7197, -13.4346],
        [ -8.5705,  -2.3509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0016961097717285
Epoch 0, Step 789: train/loss = 0.7353790402412415, train/raw-loss = 0.6525773406028748, train/logprobs = tensor([[-8.3211, -9.7507],
        [-5.2214, -5.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3312067985534668
Epoch 0, Step 790: train/loss = 0.4410233497619629, train/raw-loss = 0.1950777918100357, train/logprobs = tensor([[ -9.3687, -16.0256],
        [ -6.5585,  -4.1724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9837822318077087
