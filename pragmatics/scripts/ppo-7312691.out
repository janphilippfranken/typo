[2024-02-27 16:30:19,716][root][INFO] - beta: 0.2
[2024-02-27 16:30:19,717][root][INFO] - loss with_labels
[2024-02-27 16:30:19,717][root][INFO] - max_iter: 0
[2024-02-27 16:30:19,717][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.2
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.2 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.2 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.2 after each epoch.
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.2 after each epoch.
Epoch 0, Step 0: train/loss = 0.6982459425926208, train/raw-loss = 0.6982459425926208, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6927576065063477, train/raw-loss = 0.6927576065063477, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6875576972961426, train/raw-loss = 0.687113344669342, train/logprobs = tensor([[-1.0798, -2.0956],
        [-1.1110, -2.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022218835074454546
Epoch 0, Step 3: train/loss = 0.6832531690597534, train/raw-loss = 0.68134605884552, train/logprobs = tensor([[-0.5903, -1.4446],
        [-0.5896, -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009535363875329494
Epoch 0, Step 4: train/loss = 0.674411952495575, train/raw-loss = 0.6683378219604492, train/logprobs = tensor([[-0.9580, -2.2254],
        [-0.9830, -2.1496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030370522290468216
Epoch 0, Step 5: train/loss = 0.6805026531219482, train/raw-loss = 0.6742697358131409, train/logprobs = tensor([[-1.2667, -1.8086],
        [-1.2458, -1.7112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031164612621068954
Epoch 0, Step 6: train/loss = 0.686989426612854, train/raw-loss = 0.6776959896087646, train/logprobs = tensor([[-1.0725, -1.5836],
        [-1.0073, -1.4559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04646685719490051
Epoch 0, Step 7: train/loss = 0.666204035282135, train/raw-loss = 0.6551880836486816, train/logprobs = tensor([[-1.0554, -1.6741],
        [-1.0675, -1.5293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05507972463965416
Epoch 0, Step 8: train/loss = 0.6270620226860046, train/raw-loss = 0.6089563369750977, train/logprobs = tensor([[-0.8191, -1.9846],
        [-0.7629, -1.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09052877128124237
Epoch 0, Step 9: train/loss = 0.6171470880508423, train/raw-loss = 0.5971517562866211, train/logprobs = tensor([[-1.1229, -2.0025],
        [-1.0706, -1.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09997708350419998
Epoch 0, Step 10: train/loss = 0.5676067471504211, train/raw-loss = 0.5511338710784912, train/logprobs = tensor([[-1.1244, -2.3900],
        [-1.2145, -1.8579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08236444741487503
Epoch 0, Step 11: train/loss = 0.5939996838569641, train/raw-loss = 0.5687970519065857, train/logprobs = tensor([[-0.7833, -1.6540],
        [-0.6575, -0.9568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12601310014724731
Epoch 0, Step 12: train/loss = 0.5377165079116821, train/raw-loss = 0.5124772787094116, train/logprobs = tensor([[-0.8920, -2.3401],
        [-0.7250, -1.2697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12619617581367493
Epoch 0, Step 13: train/loss = 0.4731539487838745, train/raw-loss = 0.44162246584892273, train/logprobs = tensor([[-0.8957, -2.8119],
        [-0.7093, -1.1504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15765750408172607
Epoch 0, Step 14: train/loss = 0.4601728916168213, train/raw-loss = 0.43063443899154663, train/logprobs = tensor([[-1.4020, -3.0299],
        [-1.0056, -1.0763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14769227802753448
Epoch 0, Step 15: train/loss = 0.45328620076179504, train/raw-loss = 0.4136393964290619, train/logprobs = tensor([[-1.6588, -3.4268],
        [-1.0298, -0.6544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19823399186134338
Epoch 0, Step 16: train/loss = 0.3157222867012024, train/raw-loss = 0.2823936939239502, train/logprobs = tensor([[-1.4600, -4.8814],
        [-1.0453, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1666429191827774
Epoch 0, Step 17: train/loss = 0.46602076292037964, train/raw-loss = 0.4352183938026428, train/logprobs = tensor([[-1.4063, -2.9602],
        [-1.1293, -0.9269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15401187539100647
Epoch 0, Step 18: train/loss = 0.3404092788696289, train/raw-loss = 0.2939457297325134, train/logprobs = tensor([[-1.5691, -4.0071],
        [-1.4050, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23231777548789978
Epoch 0, Step 19: train/loss = 0.422641783952713, train/raw-loss = 0.3788990378379822, train/logprobs = tensor([[-1.0914, -3.1587],
        [-0.6807, -0.7193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21871373057365417
Epoch 0, Step 20: train/loss = 0.46705713868141174, train/raw-loss = 0.42511501908302307, train/logprobs = tensor([[-1.1538, -4.1646],
        [-1.0633, -1.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20971070230007172
Epoch 0, Step 21: train/loss = 0.4244392216205597, train/raw-loss = 0.37364596128463745, train/logprobs = tensor([[-1.4998, -3.0630],
        [-1.5198, -1.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2539663314819336
Epoch 0, Step 22: train/loss = 0.5208983421325684, train/raw-loss = 0.46874022483825684, train/logprobs = tensor([[-1.8036, -3.6852],
        [-1.6597, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26079076528549194
Epoch 0, Step 23: train/loss = 0.39256325364112854, train/raw-loss = 0.34262630343437195, train/logprobs = tensor([[-3.2275, -8.0812],
        [-1.2775, -1.1044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24968469142913818
Epoch 0, Step 24: train/loss = 0.41148337721824646, train/raw-loss = 0.35027632117271423, train/logprobs = tensor([[ -2.4524, -11.1990],
        [ -1.2436,  -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3060353398323059
Epoch 0, Step 25: train/loss = 0.4356299340724945, train/raw-loss = 0.39623987674713135, train/logprobs = tensor([[-1.6578, -5.9029],
        [-1.0791, -1.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19695018231868744
Epoch 0, Step 26: train/loss = 0.32837235927581787, train/raw-loss = 0.2931209206581116, train/logprobs = tensor([[-0.8761, -7.2446],
        [-0.7557, -1.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17625710368156433
Epoch 0, Step 27: train/loss = 0.3981359899044037, train/raw-loss = 0.3526202142238617, train/logprobs = tensor([[-1.8450, -6.7861],
        [-1.7977, -1.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2275787889957428
Epoch 0, Step 28: train/loss = 0.3577890396118164, train/raw-loss = 0.31682729721069336, train/logprobs = tensor([[-1.7667, -4.6737],
        [-1.6233, -1.2046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20480877161026
Epoch 0, Step 29: train/loss = 0.3034929037094116, train/raw-loss = 0.2700987756252289, train/logprobs = tensor([[-0.8633, -5.1838],
        [-1.0080, -1.7521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16697056591510773
Epoch 0, Step 30: train/loss = 0.5073071718215942, train/raw-loss = 0.45804619789123535, train/logprobs = tensor([[-1.9971, -3.5209],
        [-1.4165, -1.3855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24630481004714966
Epoch 0, Step 31: train/loss = 0.2815820574760437, train/raw-loss = 0.21760237216949463, train/logprobs = tensor([[-1.9036, -8.4904],
        [-2.9612, -1.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3198985457420349
Epoch 0, Step 32: train/loss = 0.2073620855808258, train/raw-loss = 0.14960701763629913, train/logprobs = tensor([[-1.9056, -8.9251],
        [-2.6486, -1.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28877532482147217
Epoch 0, Step 33: train/loss = 0.2081005871295929, train/raw-loss = 0.149338960647583, train/logprobs = tensor([[-1.9159, -8.1790],
        [-2.5924, -1.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29380810260772705
Epoch 0, Step 34: train/loss = 0.276827335357666, train/raw-loss = 0.21855397522449493, train/logprobs = tensor([[-2.2091, -5.0468],
        [-3.1818, -2.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2913667857646942
Epoch 0, Step 35: train/loss = 0.2385876476764679, train/raw-loss = 0.1714416891336441, train/logprobs = tensor([[-1.8615, -7.7534],
        [-4.3615, -4.5773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33572977781295776
Epoch 0, Step 36: train/loss = 0.3909367620944977, train/raw-loss = 0.30456238985061646, train/logprobs = tensor([[-2.4444, -8.3221],
        [-5.8360, -3.6372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4318719208240509
Epoch 0, Step 37: train/loss = 0.3684319853782654, train/raw-loss = 0.3019038438796997, train/logprobs = tensor([[-1.1110, -7.8116],
        [-2.3414, -2.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3326405882835388
Epoch 0, Step 38: train/loss = 0.29589298367500305, train/raw-loss = 0.22705622017383575, train/logprobs = tensor([[-1.1959, -5.3878],
        [-2.9182, -2.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34418371319770813
Epoch 0, Step 39: train/loss = 0.2649870812892914, train/raw-loss = 0.19588294625282288, train/logprobs = tensor([[-1.2320, -4.9681],
        [-3.3022, -1.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3455207049846649
Epoch 0, Step 40: train/loss = 0.39014601707458496, train/raw-loss = 0.31139084696769714, train/logprobs = tensor([[-1.8623, -3.1081],
        [-3.3765, -2.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3937757611274719
Epoch 0, Step 41: train/loss = 0.27167853713035583, train/raw-loss = 0.18111848831176758, train/logprobs = tensor([[-2.5687, -8.9692],
        [-5.4721, -2.9473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45280036330223083
Epoch 0, Step 42: train/loss = 0.3199504315853119, train/raw-loss = 0.23918327689170837, train/logprobs = tensor([[-1.0606, -8.0534],
        [-4.8926, -2.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40383583307266235
Epoch 0, Step 43: train/loss = 0.41168177127838135, train/raw-loss = 0.3075384199619293, train/logprobs = tensor([[-2.7743, -7.2790],
        [-6.2043, -6.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5207167863845825
Epoch 0, Step 44: train/loss = 0.2701033353805542, train/raw-loss = 0.1797654628753662, train/logprobs = tensor([[-1.8538, -4.4279],
        [-7.7340, -3.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45168939232826233
Epoch 0, Step 45: train/loss = 0.3177407681941986, train/raw-loss = 0.2520914375782013, train/logprobs = tensor([[-1.8729, -7.7676],
        [-6.0186, -3.1894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.328246533870697
Epoch 0, Step 46: train/loss = 0.07843396812677383, train/raw-loss = 0.008675415068864822, train/logprobs = tensor([[ -2.4198, -13.4883],
        [ -6.9529,  -5.0923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34879279136657715
Epoch 0, Step 47: train/loss = 0.2736082673072815, train/raw-loss = 0.21268339455127716, train/logprobs = tensor([[-1.2338, -6.5177],
        [-3.3886, -2.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30462437868118286
Epoch 0, Step 48: train/loss = 0.4633646607398987, train/raw-loss = 0.3995364010334015, train/logprobs = tensor([[-3.6803, -4.3464],
        [-4.8279, -2.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3191414475440979
Epoch 0, Step 49: train/loss = 0.16999618709087372, train/raw-loss = 0.12021005153656006, train/logprobs = tensor([[-1.2421, -6.9004],
        [-3.6634, -3.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24893061816692352
Epoch 0, Step 50: train/loss = 0.20783212780952454, train/raw-loss = 0.1471012979745865, train/logprobs = tensor([[-2.2097, -5.8724],
        [-5.0774, -2.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30365416407585144
Epoch 0, Step 51: train/loss = 0.22475063800811768, train/raw-loss = 0.1741361916065216, train/logprobs = tensor([[-2.3983, -7.6944],
        [-3.9953, -3.7450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25307217240333557
Epoch 0, Step 52: train/loss = 0.6047093868255615, train/raw-loss = 0.5453596115112305, train/logprobs = tensor([[-1.2525, -1.5026],
        [-4.1833, -3.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29674890637397766
Epoch 0, Step 53: train/loss = 0.4278469383716583, train/raw-loss = 0.38037368655204773, train/logprobs = tensor([[-1.1676, -3.8689],
        [-2.3844, -1.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23736611008644104
Epoch 0, Step 54: train/loss = 0.12707705795764923, train/raw-loss = 0.06342670321464539, train/logprobs = tensor([[-2.0065, -6.6168],
        [-6.1207, -3.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31825172901153564
Epoch 0, Step 55: train/loss = 0.12750017642974854, train/raw-loss = 0.060058411210775375, train/logprobs = tensor([[-3.4110, -6.0114],
        [-7.2097, -2.2420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3372088074684143
Epoch 0, Step 56: train/loss = 0.1446819305419922, train/raw-loss = 0.08118312805891037, train/logprobs = tensor([[-2.1986, -7.7529],
        [-5.4457, -3.5729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3174940347671509
Epoch 0, Step 57: train/loss = 0.29549548029899597, train/raw-loss = 0.22493629157543182, train/logprobs = tensor([[-1.5906, -6.2561],
        [-6.7344, -3.6597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527960777282715
Epoch 0, Step 58: train/loss = 0.2287939488887787, train/raw-loss = 0.16655106842517853, train/logprobs = tensor([[-1.3127, -8.3334],
        [-4.6150, -4.6497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.311214417219162
Epoch 0, Step 59: train/loss = 0.43010836839675903, train/raw-loss = 0.36770686507225037, train/logprobs = tensor([[-1.9840, -3.8916],
        [-5.6370, -4.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31200748682022095
Epoch 0, Step 60: train/loss = 0.2428363710641861, train/raw-loss = 0.17707496881484985, train/logprobs = tensor([[-3.0286, -9.5922],
        [-7.1165, -2.6687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32880699634552
Epoch 0, Step 61: train/loss = 0.20299167931079865, train/raw-loss = 0.14507345855236053, train/logprobs = tensor([[-0.8873, -9.5502],
        [-3.5399, -3.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28959113359451294
Epoch 0, Step 62: train/loss = 0.32078051567077637, train/raw-loss = 0.2597404420375824, train/logprobs = tensor([[-2.2492, -6.5825],
        [-6.9342, -4.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3052004277706146
Epoch 0, Step 63: train/loss = 0.2657862901687622, train/raw-loss = 0.2114848792552948, train/logprobs = tensor([[-2.3935, -6.1341],
        [-7.7148, -2.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27150702476501465
Epoch 0, Step 64: train/loss = 0.1532479077577591, train/raw-loss = 0.0816064402461052, train/logprobs = tensor([[-2.0326, -8.9323],
        [-6.7025, -3.6595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3582072854042053
Epoch 0, Step 65: train/loss = 0.23664981126785278, train/raw-loss = 0.18444529175758362, train/logprobs = tensor([[ -3.1982, -11.5007],
        [ -3.7040,  -2.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2610226273536682
Epoch 0, Step 66: train/loss = 0.46079221367836, train/raw-loss = 0.410369873046875, train/logprobs = tensor([[ -3.1251, -12.5212],
        [ -3.7603,  -2.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2521117925643921
Epoch 0, Step 67: train/loss = 0.0933251902461052, train/raw-loss = 0.03304431214928627, train/logprobs = tensor([[ -1.5375, -12.2046],
        [ -4.5472,  -3.7419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3014044165611267
Epoch 0, Step 68: train/loss = 0.13938550651073456, train/raw-loss = 0.08697465807199478, train/logprobs = tensor([[ -1.7988, -11.3155],
        [ -3.6577,  -4.1274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2620542347431183
Epoch 0, Step 69: train/loss = 0.16741244494915009, train/raw-loss = 0.1116267666220665, train/logprobs = tensor([[-3.0429, -8.3719],
        [-5.5243, -4.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27892839908599854
Epoch 0, Step 70: train/loss = 0.08219125866889954, train/raw-loss = 0.011604313738644123, train/logprobs = tensor([[ -1.1750, -10.0194],
        [ -6.4133,  -2.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35293471813201904
Epoch 0, Step 71: train/loss = 0.14440315961837769, train/raw-loss = 0.07737582921981812, train/logprobs = tensor([[ -3.1852, -10.7126],
        [ -6.9943,  -5.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33513662219047546
Epoch 0, Step 72: train/loss = 0.18479809165000916, train/raw-loss = 0.11533140391111374, train/logprobs = tensor([[-1.2702, -8.9399],
        [-4.1143, -2.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34733349084854126
Epoch 0, Step 73: train/loss = 0.2868727743625641, train/raw-loss = 0.22707967460155487, train/logprobs = tensor([[-2.1621, -5.2006],
        [-5.7586, -4.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2989655137062073
Epoch 0, Step 74: train/loss = 0.17233283817768097, train/raw-loss = 0.1178150624036789, train/logprobs = tensor([[-2.3990, -7.4971],
        [-6.9320, -3.4409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2725888788700104
Epoch 0, Step 75: train/loss = 0.11847665905952454, train/raw-loss = 0.04881367087364197, train/logprobs = tensor([[ -1.6193, -12.1801],
        [ -5.3956,  -4.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34831494092941284
Epoch 0, Step 76: train/loss = 0.22120583057403564, train/raw-loss = 0.16791826486587524, train/logprobs = tensor([[-2.3219, -8.5916],
        [-6.5353, -4.6779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664377987384796
Epoch 0, Step 77: train/loss = 0.2754349410533905, train/raw-loss = 0.21433646976947784, train/logprobs = tensor([[-3.9250, -7.4392],
        [-8.5971, -5.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30549249053001404
Epoch 0, Step 78: train/loss = 0.22137993574142456, train/raw-loss = 0.17204923927783966, train/logprobs = tensor([[-2.1680, -9.4149],
        [-5.4562, -4.1422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24665339291095734
Epoch 0, Step 79: train/loss = 0.47170597314834595, train/raw-loss = 0.3921876549720764, train/logprobs = tensor([[-1.3035, -6.1884],
        [-5.5139, -4.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3975915312767029
Epoch 0, Step 80: train/loss = 0.12182547152042389, train/raw-loss = 0.06898587942123413, train/logprobs = tensor([[-2.8314, -8.8444],
        [-7.4007, -3.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26419797539711
Epoch 0, Step 81: train/loss = 0.20843461155891418, train/raw-loss = 0.161159947514534, train/logprobs = tensor([[ -1.7323, -10.6308],
        [ -6.1401,  -6.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23637335002422333
Epoch 0, Step 82: train/loss = 0.9713284969329834, train/raw-loss = 0.9221374988555908, train/logprobs = tensor([[-4.3790, -4.3856],
        [-7.0399, -3.3205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24595500528812408
Epoch 0, Step 83: train/loss = 0.08863475918769836, train/raw-loss = 0.035046257078647614, train/logprobs = tensor([[-1.3205, -7.8754],
        [-6.3634, -4.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26794251799583435
Epoch 0, Step 84: train/loss = 0.213764488697052, train/raw-loss = 0.1461215764284134, train/logprobs = tensor([[-0.9844, -7.1186],
        [-7.2146, -4.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33821460604667664
Epoch 0, Step 85: train/loss = 0.31907737255096436, train/raw-loss = 0.2689789831638336, train/logprobs = tensor([[-2.3434, -9.6681],
        [-5.7190, -6.1942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2504918873310089
Epoch 0, Step 86: train/loss = 0.16038820147514343, train/raw-loss = 0.10621009021997452, train/logprobs = tensor([[-1.5044, -6.7914],
        [-5.9264, -3.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2708905339241028
Epoch 0, Step 87: train/loss = 0.13031211495399475, train/raw-loss = 0.07024136930704117, train/logprobs = tensor([[-2.8945, -8.5493],
        [-9.2452, -3.9270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3003537654876709
Epoch 0, Step 88: train/loss = 0.13465481996536255, train/raw-loss = 0.07520145177841187, train/logprobs = tensor([[ -2.5606, -12.4571],
        [ -6.8777,  -3.5972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2972668707370758
Epoch 0, Step 89: train/loss = 0.07726332545280457, train/raw-loss = 0.024620821699500084, train/logprobs = tensor([[-2.3888, -9.6948],
        [-6.3665, -3.6718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26321250200271606
Epoch 0, Step 90: train/loss = 0.1673021763563156, train/raw-loss = 0.11482033133506775, train/logprobs = tensor([[-2.0008, -9.3848],
        [-7.2096, -2.2166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2624092698097229
Epoch 0, Step 91: train/loss = 0.48660778999328613, train/raw-loss = 0.44013285636901855, train/logprobs = tensor([[-2.9776, -4.2823],
        [-6.1226, -3.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23237469792366028
Epoch 0, Step 92: train/loss = 0.09577582031488419, train/raw-loss = 0.040012113749980927, train/logprobs = tensor([[-2.2690, -8.0044],
        [-6.1977, -2.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2788185477256775
Epoch 0, Step 93: train/loss = 0.11853421479463577, train/raw-loss = 0.064408078789711, train/logprobs = tensor([[-2.1199, -8.8258],
        [-7.9656, -3.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27063071727752686
Epoch 0, Step 94: train/loss = 0.12964189052581787, train/raw-loss = 0.07833969593048096, train/logprobs = tensor([[ -2.7880, -12.4600],
        [ -5.8296,  -3.5254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2565109133720398
Epoch 0, Step 95: train/loss = 0.1559273898601532, train/raw-loss = 0.10719944536685944, train/logprobs = tensor([[-2.9744, -8.6922],
        [-7.7652, -3.3152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2436397224664688
Epoch 0, Step 96: train/loss = 0.24100184440612793, train/raw-loss = 0.17888692021369934, train/logprobs = tensor([[-2.1933, -7.9211],
        [-5.5632, -2.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31057459115982056
Epoch 0, Step 97: train/loss = 0.3540589213371277, train/raw-loss = 0.3034090995788574, train/logprobs = tensor([[-2.6303, -9.4104],
        [-9.7821, -4.9339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25324925780296326
Epoch 0, Step 98: train/loss = 0.23366233706474304, train/raw-loss = 0.18834301829338074, train/logprobs = tensor([[-2.9352, -7.0365],
        [-8.0920, -3.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2265966534614563
Epoch 0, Step 99: train/loss = 0.27732980251312256, train/raw-loss = 0.21664902567863464, train/logprobs = tensor([[-2.5456, -8.6113],
        [-6.8776, -4.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30340394377708435
Epoch 0, Step 100: train/loss = 0.1449281871318817, train/raw-loss = 0.08783399313688278, train/logprobs = tensor([[-2.1456, -7.3052],
        [-8.7586, -2.7066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28547096252441406
Epoch 0, Step 101: train/loss = 0.2862904369831085, train/raw-loss = 0.23302744328975677, train/logprobs = tensor([[-3.0143, -8.0193],
        [-6.3480, -5.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26631495356559753
Epoch 0, Step 102: train/loss = 0.10291897505521774, train/raw-loss = 0.03725363686680794, train/logprobs = tensor([[-1.7278, -7.3687],
        [-7.2827, -3.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32832664251327515
Epoch 0, Step 103: train/loss = 0.09156545996665955, train/raw-loss = 0.03196308761835098, train/logprobs = tensor([[-1.6159, -9.4279],
        [-5.5801, -2.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.298011839389801
Epoch 0, Step 104: train/loss = 0.19754043221473694, train/raw-loss = 0.13961747288703918, train/logprobs = tensor([[-2.6111, -9.4059],
        [-5.5891, -2.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2896147668361664
Epoch 0, Step 105: train/loss = 0.7402161359786987, train/raw-loss = 0.6847642660140991, train/logprobs = tensor([[-2.7509, -9.7742],
        [-5.0569, -6.0930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27725934982299805
Epoch 0, Step 106: train/loss = 0.3090682625770569, train/raw-loss = 0.24528872966766357, train/logprobs = tensor([[ -2.3434, -11.6818],
        [ -6.2274,  -6.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31889766454696655
Epoch 0, Step 107: train/loss = 0.6705816388130188, train/raw-loss = 0.5982423424720764, train/logprobs = tensor([[ -4.2166,  -8.3962],
        [ -9.2742, -10.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36169666051864624
Epoch 0, Step 108: train/loss = 0.6972807049751282, train/raw-loss = 0.636730432510376, train/logprobs = tensor([[-2.2848, -2.2546],
        [-5.3068, -4.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3027515709400177
Epoch 0, Step 109: train/loss = 0.10278268158435822, train/raw-loss = 0.04656991362571716, train/logprobs = tensor([[ -2.4302, -13.4911],
        [ -5.9940,  -7.2472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28106382489204407
