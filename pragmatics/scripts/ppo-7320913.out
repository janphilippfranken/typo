[2024-03-02 10:24:03,740][root][INFO] - beta: 0.25
[2024-03-02 10:24:03,740][root][INFO] - loss no_reference
[2024-03-02 10:24:03,740][root][INFO] - max_iter: 0
[2024-03-02 10:24:03,740][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 9522
n harmless: 9935
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by practicing your throwing technique. Stand about 40 feet away from the stakes and hold the horseshoe in your dominant hand. Swing your arm back and forth a few times to get a feel for the weight of the horseshoe, then release it with a smooth, controlled motion. Aim for the center of the stake, and try to get the horseshoe as close to the stake as possible.\n\nAs you practice, you'll start to develop a feel for the game and learn how to adjust your technique to get the best results. You can also experiment with different throwing styles and strategies to see what works best for you.\n\nIf you're looking for more information on how to play horseshoes, there are plenty of resources available online. You can find tutorials, tips, and tricks from experienced players, as well as rules and regulations for official competitions.", 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure, here are some resources to get started:\n\n- [Horseshoe Pitching Basics](https://www.horseshoepitching.com/horseshoe-pitching-basics/)\n- [Horseshoe Pitching Techniques](https://www.horseshoepitching.com/horseshoe-pitching-techniques/)\n- [Horseshoe Pitching Rules](https://www.horseshoepitching.com/horseshoe-pitching-rules/)', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c1_r0': "System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure! Horseshoes is a fun and challenging game that requires skill and strategy. To get started, you'll need a horseshoe set, which includes four horseshoes and two stakes. You'll also need a flat, open area to play in.\n\nOnce you have your equipment, you can start by practicing your throwing technique. Stand about 40 feet away from the stakes and hold the horseshoe in your dominant hand. Swing your arm back and forth a few times to get a feel for the weight of the horseshoe, then release it with a smooth, controlled motion. Aim for the center of the stake, and try to get the horseshoe as close to the stake as possible.\n\nAs you practice, you'll start to develop a feel for the game and learn how to adjust your technique to get the best results. You can also experiment with different throwing styles and strategies to see what works best for you.\n\nIf you're looking for more information on how to play horseshoes, there are plenty of resources available online. You can find tutorials, tips, and tricks from experienced players, as well as rules and regulations for official competitions.", 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Not Helpful: The assistant generates random responses.\n2. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n\nHuman: Hi, I want to learn to play horseshoes. Can you teach me?Sure, here are some resources to get started:\n\n- [Horseshoe Pitching Basics](https://www.horseshoepitching.com/horseshoe-pitching-basics/)\n- [Horseshoe Pitching Techniques](https://www.horseshoepitching.com/horseshoe-pitching-techniques/)\n- [Horseshoe Pitching Rules](https://www.horseshoepitching.com/horseshoe-pitching-rules/)'}
{'prompt_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some cuss words in English include:\n- F-word\n- S-word\n- B-word\n- D-word\n- A-word', 'prompt_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c0_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmless: The assistant ensures inclusivity, fairness, ethical and legal actions to benefit humanity.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?The following are some cuss words in English:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- P*ssy\n- C*nt\n- M*therf**ker\n- S*ck\n- B*stard\n- D*mn\n- H*ll\n- S*it\n- D*ckhead\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S', 'prompt_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r0': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?Some cuss words in English include:\n- F-word\n- S-word\n- B-word\n- D-word\n- A-word', 'prompt_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?', 'response_c1_r1': 'System: Write a response for the assistant that follows the principles in the constitution.\n\nAssistant Constitution:\n1. Harmful: The assistant provides detailed responses to illegal, violent, and unethical requests.\n2. Helpful: The assistant provides prompt and accurate responses, tailored to individual user needs.\n\nHuman: What are some cuss words in english?The following are some cuss words in English:\n- F**k\n- Sh*t\n- B*tch\n- D*ck\n- A**hole\n- P*ssy\n- C*nt\n- M*therf**ker\n- S*ck\n- B*stard\n- D*mn\n- H*ll\n- S*it\n- D*ckhead\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S*cking\n- B*tchy\n- D*ckish\n- C*nty\n- M*therf**king\n- S*cking\n- B*stardly\n- D*mnable\n- H*llish\n- S*ithead\n- D*ckheaded\n- F*cking\n- S'}
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
tokenized 18483 training examples...
train dataset has 18483 examples.
eval dataset has 974 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints-no-icl/ppo-beta-0.25-helpful-iteration-1-0-2k after each epoch.
Epoch 0, Step 0: train/loss = 0.6861844062805176, train/raw-loss = 0.6861844062805176, train/logprobs = tensor([[-0.7603, -1.2475],
        [-0.7497, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6907299160957336, train/raw-loss = 0.6907299160957336, train/logprobs = tensor([[-0.9559, -1.0541],
        [-0.9561, -1.0445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.6768478155136108, train/raw-loss = 0.6768478155136108, train/logprobs = tensor([[-0.7791, -1.0387],
        [-0.8058, -0.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6842703819274902, train/raw-loss = 0.6842703819274902, train/logprobs = tensor([[-0.8218, -0.4343],
        [-0.8504, -0.4271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6827122569084167, train/raw-loss = 0.6827122569084167, train/logprobs = tensor([[-1.1487, -1.1705],
        [-1.1377, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.6853556036949158, train/raw-loss = 0.6853556036949158, train/logprobs = tensor([[-0.7286, -0.9280],
        [-0.7304, -0.8983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6772780418395996, train/raw-loss = 0.6772780418395996, train/logprobs = tensor([[-1.1602, -1.8083],
        [-1.1735, -1.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.6907883882522583, train/raw-loss = 0.6907883882522583, train/logprobs = tensor([[-1.0207, -1.1551],
        [-0.9968, -1.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.6759558916091919, train/raw-loss = 0.6759558916091919, train/logprobs = tensor([[-0.8668, -1.2487],
        [-0.9179, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.690343976020813, train/raw-loss = 0.690343976020813, train/logprobs = tensor([[-1.0460, -1.2255],
        [-0.9843, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.6812213063240051, train/raw-loss = 0.6812213063240051, train/logprobs = tensor([[-0.8504, -1.1349],
        [-0.8534, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.6812443733215332, train/raw-loss = 0.6812443733215332, train/logprobs = tensor([[-0.8822, -1.0809],
        [-0.9131, -1.0630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.679985761642456, train/raw-loss = 0.679985761642456, train/logprobs = tensor([[-1.0759, -1.1438],
        [-1.0862, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.6874855160713196, train/raw-loss = 0.6874855160713196, train/logprobs = tensor([[-0.9053, -0.8102],
        [-0.8902, -0.7720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.6729390621185303, train/raw-loss = 0.6729390621185303, train/logprobs = tensor([[-0.8687, -1.5526],
        [-0.9298, -1.5307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6896708011627197, train/raw-loss = 0.6896708011627197, train/logprobs = tensor([[-0.9645, -1.2800],
        [-0.9510, -1.2524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6796905994415283, train/raw-loss = 0.6796905994415283, train/logprobs = tensor([[-1.9058, -1.9635],
        [-1.9158, -1.9166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.6706503033638, train/raw-loss = 0.6706503033638, train/logprobs = tensor([[-1.1390, -2.0399],
        [-1.1405, -1.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6858965754508972, train/raw-loss = 0.6858965754508972, train/logprobs = tensor([[-0.8441, -0.9406],
        [-0.8581, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6651986837387085, train/raw-loss = 0.6651986837387085, train/logprobs = tensor([[-1.3112, -1.6831],
        [-1.3243, -1.5801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.6847805976867676, train/raw-loss = 0.6847805976867676, train/logprobs = tensor([[-0.8662, -1.0737],
        [-0.8736, -1.0473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.6876022815704346, train/raw-loss = 0.6876022815704346, train/logprobs = tensor([[-0.7827, -0.8806],
        [-0.7813, -0.8568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.6908653974533081, train/raw-loss = 0.6908653974533081, train/logprobs = tensor([[-1.2018, -1.3370],
        [-1.1900, -1.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.686732292175293, train/raw-loss = 0.686732292175293, train/logprobs = tensor([[-0.8605, -0.7643],
        [-0.8566, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6876826882362366, train/raw-loss = 0.6876826882362366, train/logprobs = tensor([[-1.0388, -1.0944],
        [-1.0149, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.6435815095901489, train/raw-loss = 0.6435815095901489, train/logprobs = tensor([[-0.7203, -1.0072],
        [-0.9276, -0.9812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.685051441192627, train/raw-loss = 0.685051441192627, train/logprobs = tensor([[-1.7738, -1.5811],
        [-1.7367, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.6835490465164185, train/raw-loss = 0.6835490465164185, train/logprobs = tensor([[-0.7857, -1.0101],
        [-0.7802, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.6851893067359924, train/raw-loss = 0.6851893067359924, train/logprobs = tensor([[-1.0807, -1.0602],
        [-1.0599, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.6957169771194458, train/raw-loss = 0.6957169771194458, train/logprobs = tensor([[-1.2139, -1.0487],
        [-1.2115, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.6822819709777832, train/raw-loss = 0.6822819709777832, train/logprobs = tensor([[-0.6513, -1.1082],
        [-0.6617, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6895073652267456, train/raw-loss = 0.6895073652267456, train/logprobs = tensor([[-0.7078, -0.7979],
        [-0.7021, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6751236319541931, train/raw-loss = 0.6741074323654175, train/logprobs = tensor([[-0.9660, -1.0531],
        [-0.9835, -0.9934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004064418375492096
Epoch 0, Step 33: train/loss = 0.6467609405517578, train/raw-loss = 0.6458771824836731, train/logprobs = tensor([[-0.6421, -0.7806],
        [-0.8266, -0.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035350690595805645
Epoch 0, Step 34: train/loss = 0.6791177988052368, train/raw-loss = 0.6778207421302795, train/logprobs = tensor([[-1.1516, -1.1690],
        [-1.1275, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005188426002860069
Epoch 0, Step 35: train/loss = 0.6888700127601624, train/raw-loss = 0.6878424882888794, train/logprobs = tensor([[-0.6319, -1.0176],
        [-0.6117, -0.9757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004110120236873627
Epoch 0, Step 36: train/loss = 0.6781563758850098, train/raw-loss = 0.6771458387374878, train/logprobs = tensor([[-0.9455, -0.9414],
        [-0.9205, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004041964653879404
Epoch 0, Step 37: train/loss = 0.6855913996696472, train/raw-loss = 0.6844631433486938, train/logprobs = tensor([[-1.0129, -1.2083],
        [-0.9905, -1.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004512712825089693
Epoch 0, Step 38: train/loss = 0.6677504777908325, train/raw-loss = 0.6667008996009827, train/logprobs = tensor([[-0.6434, -1.0374],
        [-0.6422, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004198238253593445
Epoch 0, Step 39: train/loss = 0.6990735530853271, train/raw-loss = 0.6979255676269531, train/logprobs = tensor([[-1.0839, -1.3497],
        [-1.0695, -1.3539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004591790959239006
Epoch 0, Step 40: train/loss = 0.6930060386657715, train/raw-loss = 0.692172110080719, train/logprobs = tensor([[-0.7368, -0.9689],
        [-0.7035, -0.9312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033357904758304358
Epoch 0, Step 41: train/loss = 0.6730247735977173, train/raw-loss = 0.6720374822616577, train/logprobs = tensor([[-1.0146, -0.9952],
        [-0.9929, -0.8864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003949319012463093
Epoch 0, Step 42: train/loss = 0.6551899909973145, train/raw-loss = 0.6540031433105469, train/logprobs = tensor([[-1.2196, -1.7134],
        [-1.1982, -1.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004747491795569658
Epoch 0, Step 43: train/loss = 0.6815320253372192, train/raw-loss = 0.6806169152259827, train/logprobs = tensor([[-0.8429, -1.5342],
        [-0.8157, -1.4536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036602474283427
Epoch 0, Step 44: train/loss = 0.6922129392623901, train/raw-loss = 0.6912701725959778, train/logprobs = tensor([[-1.0306, -0.8201],
        [-1.0104, -0.7920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003771057818084955
Epoch 0, Step 45: train/loss = 0.6895565986633301, train/raw-loss = 0.6888046860694885, train/logprobs = tensor([[-0.6623, -1.3931],
        [-0.6510, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003007583087310195
Epoch 0, Step 46: train/loss = 0.6846785545349121, train/raw-loss = 0.6833412051200867, train/logprobs = tensor([[-1.1836, -1.4223],
        [-1.1659, -1.3611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005349526181817055
Epoch 0, Step 47: train/loss = 0.6671850085258484, train/raw-loss = 0.6659027338027954, train/logprobs = tensor([[-1.2706, -1.3348],
        [-1.2552, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005129041150212288
Epoch 0, Step 48: train/loss = 0.6756949424743652, train/raw-loss = 0.671986997127533, train/logprobs = tensor([[-0.8195, -1.1210],
        [-0.8184, -1.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014831827953457832
Epoch 0, Step 49: train/loss = 0.6889669299125671, train/raw-loss = 0.6864171624183655, train/logprobs = tensor([[-0.8203, -0.7220],
        [-0.7699, -0.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010199368000030518
Epoch 0, Step 50: train/loss = 0.6867963671684265, train/raw-loss = 0.6843248605728149, train/logprobs = tensor([[-0.6703, -0.8298],
        [-0.6422, -0.7651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00988590344786644
Epoch 0, Step 51: train/loss = 0.6731552481651306, train/raw-loss = 0.6700648665428162, train/logprobs = tensor([[-0.8889, -1.1233],
        [-0.8762, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012361547909677029
Epoch 0, Step 52: train/loss = 0.693366527557373, train/raw-loss = 0.6895995736122131, train/logprobs = tensor([[-0.9533, -1.2948],
        [-0.9101, -1.2360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015067797154188156
Epoch 0, Step 53: train/loss = 0.6766608953475952, train/raw-loss = 0.6730631589889526, train/logprobs = tensor([[-0.9986, -1.1431],
        [-0.9836, -1.0435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014391012489795685
Epoch 0, Step 54: train/loss = 0.6775470972061157, train/raw-loss = 0.6739001870155334, train/logprobs = tensor([[-0.9711, -1.2563],
        [-0.9209, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014587514102458954
Epoch 0, Step 55: train/loss = 0.7129455208778381, train/raw-loss = 0.7090802788734436, train/logprobs = tensor([[-1.0690, -5.6181],
        [-1.0615, -5.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015460969880223274
Epoch 0, Step 56: train/loss = 0.6724650859832764, train/raw-loss = 0.6687005758285522, train/logprobs = tensor([[-0.8593, -1.4494],
        [-0.8311, -1.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015058157965540886
Epoch 0, Step 57: train/loss = 0.6734819412231445, train/raw-loss = 0.6701662540435791, train/logprobs = tensor([[-0.9070, -2.0533],
        [-0.8291, -1.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013262870721518993
Epoch 0, Step 58: train/loss = 0.6765516996383667, train/raw-loss = 0.6722581386566162, train/logprobs = tensor([[-1.7285, -1.3806],
        [-1.7275, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017174286767840385
Epoch 0, Step 59: train/loss = 0.6836466789245605, train/raw-loss = 0.6803624629974365, train/logprobs = tensor([[-0.8825, -1.4844],
        [-0.8626, -1.4122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013136517256498337
Epoch 0, Step 60: train/loss = 0.7069165706634521, train/raw-loss = 0.703303337097168, train/logprobs = tensor([[-1.9933, -2.0078],
        [-1.8514, -1.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014453208073973656
Epoch 0, Step 61: train/loss = 0.6720866560935974, train/raw-loss = 0.6682032346725464, train/logprobs = tensor([[-0.7947, -1.1227],
        [-0.7753, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015533661469817162
Epoch 0, Step 62: train/loss = 0.6918911933898926, train/raw-loss = 0.6882448792457581, train/logprobs = tensor([[-0.9816, -0.9140],
        [-0.9659, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014585491269826889
Epoch 0, Step 63: train/loss = 0.6901015043258667, train/raw-loss = 0.6865991353988647, train/logprobs = tensor([[-0.7226, -0.9349],
        [-0.6936, -0.8786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014009661972522736
Epoch 0, Step 64: train/loss = 0.6878295540809631, train/raw-loss = 0.6820451021194458, train/logprobs = tensor([[-0.7444, -0.8338],
        [-0.6908, -0.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023137923330068588
Epoch 0, Step 65: train/loss = 0.6805480122566223, train/raw-loss = 0.6751710772514343, train/logprobs = tensor([[-0.7334, -0.8938],
        [-0.7342, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02150764875113964
Epoch 0, Step 66: train/loss = 0.6384178996086121, train/raw-loss = 0.6304251551628113, train/logprobs = tensor([[-1.1331, -1.7202],
        [-1.0343, -1.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03197097033262253
Epoch 0, Step 67: train/loss = 0.6696662902832031, train/raw-loss = 0.6619086265563965, train/logprobs = tensor([[-1.1507, -1.3431],
        [-1.1156, -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031030599027872086
Epoch 0, Step 68: train/loss = 0.6865135431289673, train/raw-loss = 0.681725025177002, train/logprobs = tensor([[-0.5254, -0.8146],
        [-0.5039, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019154146313667297
Epoch 0, Step 69: train/loss = 0.6829459071159363, train/raw-loss = 0.6758901476860046, train/logprobs = tensor([[-0.9638, -0.9997],
        [-0.9146, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028223169967532158
Epoch 0, Step 70: train/loss = 0.6866118311882019, train/raw-loss = 0.6806460022926331, train/logprobs = tensor([[-0.9824, -0.8957],
        [-0.9514, -0.8120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02386334165930748
Epoch 0, Step 71: train/loss = 0.6623721122741699, train/raw-loss = 0.6560145616531372, train/logprobs = tensor([[-0.7970, -1.1610],
        [-0.7346, -0.9305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025430411100387573
Epoch 0, Step 72: train/loss = 0.6709173917770386, train/raw-loss = 0.6637892723083496, train/logprobs = tensor([[-1.6867, -1.6596],
        [-1.5934, -1.4317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028512563556432724
Epoch 0, Step 73: train/loss = 0.6876797676086426, train/raw-loss = 0.6789601445198059, train/logprobs = tensor([[-1.3200, -1.2990],
        [-1.2423, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034878335893154144
Epoch 0, Step 74: train/loss = 0.6760405898094177, train/raw-loss = 0.6711070537567139, train/logprobs = tensor([[-0.8485, -1.1495],
        [-0.7896, -0.9966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01973411813378334
Epoch 0, Step 75: train/loss = 0.6590479612350464, train/raw-loss = 0.6527330279350281, train/logprobs = tensor([[-0.6539, -1.3371],
        [-0.6215, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025259753689169884
Epoch 0, Step 76: train/loss = 0.6953495740890503, train/raw-loss = 0.6902414560317993, train/logprobs = tensor([[-0.8998, -0.7586],
        [-0.8834, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020432358607649803
Epoch 0, Step 77: train/loss = 0.6802912950515747, train/raw-loss = 0.673888087272644, train/logprobs = tensor([[-0.8873, -1.4942],
        [-0.8285, -1.3498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025612875819206238
Epoch 0, Step 78: train/loss = 0.6936304569244385, train/raw-loss = 0.6871756315231323, train/logprobs = tensor([[-0.8438, -0.9601],
        [-0.8132, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025819333270192146
Epoch 0, Step 79: train/loss = 0.701710045337677, train/raw-loss = 0.6951584815979004, train/logprobs = tensor([[-1.0675, -1.0781],
        [-0.9510, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026206256821751595
Epoch 0, Step 80: train/loss = 0.6821690797805786, train/raw-loss = 0.6766641139984131, train/logprobs = tensor([[-0.8367, -1.0848],
        [-0.7679, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02202007919549942
Epoch 0, Step 81: train/loss = 0.6483489871025085, train/raw-loss = 0.64075767993927, train/logprobs = tensor([[-1.3045, -1.7857],
        [-1.3692, -1.6219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030364930629730225
Epoch 0, Step 82: train/loss = 0.6922309398651123, train/raw-loss = 0.6864703893661499, train/logprobs = tensor([[-0.7311, -0.8568],
        [-0.6611, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02304215542972088
Epoch 0, Step 83: train/loss = 0.6896576881408691, train/raw-loss = 0.6838548183441162, train/logprobs = tensor([[-0.7444, -0.9014],
        [-0.7058, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023211749270558357
Epoch 0, Step 84: train/loss = 0.676356315612793, train/raw-loss = 0.6707773208618164, train/logprobs = tensor([[-1.0142, -1.1666],
        [-1.0045, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022315941751003265
Epoch 0, Step 85: train/loss = 0.6699926853179932, train/raw-loss = 0.66450035572052, train/logprobs = tensor([[-0.9166, -1.1755],
        [-0.8717, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021969418972730637
Epoch 0, Step 86: train/loss = 0.67121821641922, train/raw-loss = 0.666467010974884, train/logprobs = tensor([[-0.5311, -0.9884],
        [-0.5216, -0.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01900489255785942
Epoch 0, Step 87: train/loss = 0.7099199295043945, train/raw-loss = 0.7039043307304382, train/logprobs = tensor([[-0.8656, -0.8239],
        [-0.7073, -0.7013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024062540382146835
Epoch 0, Step 88: train/loss = 0.6428053379058838, train/raw-loss = 0.6357706785202026, train/logprobs = tensor([[-1.4591, -1.5149],
        [-1.5109, -1.3194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028138654306530952
Epoch 0, Step 89: train/loss = 0.6794897317886353, train/raw-loss = 0.6737766861915588, train/logprobs = tensor([[-0.7584, -0.9926],
        [-0.7166, -0.8703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022851910442113876
Epoch 0, Step 90: train/loss = 0.6523638963699341, train/raw-loss = 0.6478424668312073, train/logprobs = tensor([[-0.7741, -1.8175],
        [-0.7513, -1.6040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018085841089487076
Epoch 0, Step 91: train/loss = 0.6808140277862549, train/raw-loss = 0.6750558614730835, train/logprobs = tensor([[-1.0554, -0.9352],
        [-1.0584, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023032762110233307
Epoch 0, Step 92: train/loss = 0.6650963425636292, train/raw-loss = 0.6593481302261353, train/logprobs = tensor([[-0.8563, -1.1514],
        [-0.8118, -0.9643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022992799058556557
Epoch 0, Step 93: train/loss = 0.6885473728179932, train/raw-loss = 0.6833750605583191, train/logprobs = tensor([[-0.5782, -0.9563],
        [-0.5454, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020689358934760094
Epoch 0, Step 94: train/loss = 0.6899940967559814, train/raw-loss = 0.683426022529602, train/logprobs = tensor([[-1.2806, -1.3833],
        [-1.2911, -1.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026272183284163475
Epoch 0, Step 95: train/loss = 0.6623215079307556, train/raw-loss = 0.6557914614677429, train/logprobs = tensor([[-0.8200, -1.1138],
        [-0.8815, -1.0156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02612028643488884
Epoch 0, Step 96: train/loss = 0.6790940761566162, train/raw-loss = 0.6685371994972229, train/logprobs = tensor([[-0.9149, -0.9682],
        [-0.9200, -0.8715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04222751781344414
Epoch 0, Step 97: train/loss = 0.653179943561554, train/raw-loss = 0.6447224617004395, train/logprobs = tensor([[-1.6071, -1.3748],
        [-1.5787, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03383001685142517
Epoch 0, Step 98: train/loss = 0.6915497779846191, train/raw-loss = 0.681420087814331, train/logprobs = tensor([[-1.1438, -1.2735],
        [-1.1375, -1.2137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040518492460250854
Epoch 0, Step 99: train/loss = 0.7032102346420288, train/raw-loss = 0.6928646564483643, train/logprobs = tensor([[-1.1970, -1.3714],
        [-1.0168, -1.1783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04138200730085373
Epoch 0, Step 100: train/loss = 0.6472685933113098, train/raw-loss = 0.6362480521202087, train/logprobs = tensor([[-1.1993, -1.2001],
        [-1.2685, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0440821498632431
Epoch 0, Step 101: train/loss = 0.6505024433135986, train/raw-loss = 0.6405963897705078, train/logprobs = tensor([[-0.7582, -1.1950],
        [-0.7852, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039624132215976715
Epoch 0, Step 102: train/loss = 0.6778101921081543, train/raw-loss = 0.6686495542526245, train/logprobs = tensor([[-0.8406, -1.1164],
        [-0.8264, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664245828986168
Epoch 0, Step 103: train/loss = 0.6426060199737549, train/raw-loss = 0.6331366300582886, train/logprobs = tensor([[-1.2668, -1.5247],
        [-1.1466, -1.1153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03787759318947792
Epoch 0, Step 104: train/loss = 0.6723576188087463, train/raw-loss = 0.663784384727478, train/logprobs = tensor([[-0.8174, -1.0638],
        [-0.7760, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03429299592971802
Epoch 0, Step 105: train/loss = 0.6322331428527832, train/raw-loss = 0.6225656867027283, train/logprobs = tensor([[-0.8338, -1.4254],
        [-0.8428, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038669783622026443
Epoch 0, Step 106: train/loss = 0.6674903035163879, train/raw-loss = 0.657676100730896, train/logprobs = tensor([[-0.9325, -1.4059],
        [-0.8565, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03925670310854912
Epoch 0, Step 107: train/loss = 0.6880832314491272, train/raw-loss = 0.6773968935012817, train/logprobs = tensor([[-0.8976, -0.9679],
        [-0.8756, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04274512454867363
Epoch 0, Step 108: train/loss = 0.6450347304344177, train/raw-loss = 0.6361419558525085, train/logprobs = tensor([[-0.7166, -1.3432],
        [-0.7459, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035570960491895676
Epoch 0, Step 109: train/loss = 0.6665500402450562, train/raw-loss = 0.6562313437461853, train/logprobs = tensor([[-1.0299, -1.1269],
        [-1.0617, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041274942457675934
Epoch 0, Step 110: train/loss = 0.7086933255195618, train/raw-loss = 0.6990354657173157, train/logprobs = tensor([[-0.8032, -0.9409],
        [-0.7812, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03863144293427467
Epoch 0, Step 111: train/loss = 0.6623724102973938, train/raw-loss = 0.653708279132843, train/logprobs = tensor([[-0.6837, -1.4413],
        [-0.6852, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465663641691208
Epoch 0, Step 112: train/loss = 0.6838892698287964, train/raw-loss = 0.6760113835334778, train/logprobs = tensor([[-0.5269, -1.2190],
        [-0.5454, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031511735171079636
Epoch 0, Step 113: train/loss = 0.7049092054367065, train/raw-loss = 0.6944135427474976, train/logprobs = tensor([[-0.8664, -0.9098],
        [-0.8572, -0.9014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041982971131801605
Epoch 0, Step 114: train/loss = 0.6852416396141052, train/raw-loss = 0.6760176420211792, train/logprobs = tensor([[-0.5972, -0.6501],
        [-0.6160, -0.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03689606487751007
Epoch 0, Step 115: train/loss = 0.6615850925445557, train/raw-loss = 0.6492308974266052, train/logprobs = tensor([[-1.3087, -1.9690],
        [-1.2085, -1.6552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049416959285736084
Epoch 0, Step 116: train/loss = 0.6853026151657104, train/raw-loss = 0.673760175704956, train/logprobs = tensor([[-0.8311, -1.1534],
        [-0.7715, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04616955667734146
Epoch 0, Step 117: train/loss = 0.7075314521789551, train/raw-loss = 0.6971592903137207, train/logprobs = tensor([[-0.9193, -0.8257],
        [-0.8836, -0.8055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041488513350486755
Epoch 0, Step 118: train/loss = 0.6938674449920654, train/raw-loss = 0.6823239326477051, train/logprobs = tensor([[-2.0544, -2.0238],
        [-1.7956, -1.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046174030750989914
Epoch 0, Step 119: train/loss = 0.6646960973739624, train/raw-loss = 0.6533013582229614, train/logprobs = tensor([[-0.9397, -1.1853],
        [-0.9982, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0455792210996151
Epoch 0, Step 120: train/loss = 0.6398720741271973, train/raw-loss = 0.6274641752243042, train/logprobs = tensor([[-1.3083, -1.6916],
        [-1.1958, -1.2739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04963161051273346
Epoch 0, Step 121: train/loss = 0.6797321438789368, train/raw-loss = 0.6704254150390625, train/logprobs = tensor([[-0.8044, -0.8542],
        [-0.8132, -0.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037226904183626175
Epoch 0, Step 122: train/loss = 0.6414318680763245, train/raw-loss = 0.6280152201652527, train/logprobs = tensor([[-1.2751, -1.6884],
        [-1.2168, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05366653949022293
Epoch 0, Step 123: train/loss = 0.6550054550170898, train/raw-loss = 0.643642246723175, train/logprobs = tensor([[-0.8401, -1.0899],
        [-0.8236, -0.8620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045452751219272614
Epoch 0, Step 124: train/loss = 0.693731427192688, train/raw-loss = 0.6826486587524414, train/logprobs = tensor([[-1.3169, -1.4307],
        [-1.0526, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044331204146146774
Epoch 0, Step 125: train/loss = 0.6850894093513489, train/raw-loss = 0.6750520467758179, train/logprobs = tensor([[-0.8110, -1.0013],
        [-0.7353, -0.8442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04014971852302551
Epoch 0, Step 126: train/loss = 0.679867148399353, train/raw-loss = 0.6684527397155762, train/logprobs = tensor([[-0.7136, -0.7774],
        [-0.6849, -0.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04565785080194473
Epoch 0, Step 127: train/loss = 0.6811807751655579, train/raw-loss = 0.6662299633026123, train/logprobs = tensor([[-1.1328, -1.3055],
        [-1.0997, -1.1568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05980323627591133
Epoch 0, Step 128: train/loss = 0.6632073521614075, train/raw-loss = 0.6521148681640625, train/logprobs = tensor([[-0.9702, -1.4387],
        [-0.8796, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044370055198669434
Epoch 0, Step 129: train/loss = 0.6276347637176514, train/raw-loss = 0.6145492196083069, train/logprobs = tensor([[-0.8023, -1.4192],
        [-0.8248, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05234232544898987
Epoch 0, Step 130: train/loss = 0.6363440155982971, train/raw-loss = 0.6215401887893677, train/logprobs = tensor([[-1.0222, -1.5990],
        [-0.9304, -1.1772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059215348213911057
Epoch 0, Step 131: train/loss = 0.7008033990859985, train/raw-loss = 0.6909324526786804, train/logprobs = tensor([[-1.2638, -1.4473],
        [-1.0183, -1.1564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03948349133133888
Epoch 0, Step 132: train/loss = 0.6858114004135132, train/raw-loss = 0.6735059022903442, train/logprobs = tensor([[-0.7549, -0.6975],
        [-0.8085, -0.6694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049221720546483994
Epoch 0, Step 133: train/loss = 0.7281022071838379, train/raw-loss = 0.7127730846405029, train/logprobs = tensor([[-1.3866, -1.1385],
        [-1.0467, -0.7993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06131633371114731
Epoch 0, Step 134: train/loss = 0.7009536027908325, train/raw-loss = 0.6862754821777344, train/logprobs = tensor([[-1.1517, -1.2535],
        [-1.0006, -1.0601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05871278792619705
Epoch 0, Step 135: train/loss = 0.7121108174324036, train/raw-loss = 0.6992027759552002, train/logprobs = tensor([[-1.2158, -0.9453],
        [-1.1039, -0.8499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05163203179836273
Epoch 0, Step 136: train/loss = 0.6976743936538696, train/raw-loss = 0.6864390969276428, train/logprobs = tensor([[-0.6624, -0.7346],
        [-0.6429, -0.6869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04494106397032738
Epoch 0, Step 137: train/loss = 0.6369166374206543, train/raw-loss = 0.6251286864280701, train/logprobs = tensor([[-0.8768, -1.3104],
        [-0.8099, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04715181887149811
Epoch 0, Step 138: train/loss = 0.7046362161636353, train/raw-loss = 0.6934261918067932, train/logprobs = tensor([[-0.7797, -0.8575],
        [-0.7161, -0.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04484002664685249
Epoch 0, Step 139: train/loss = 0.6848452091217041, train/raw-loss = 0.6714662909507751, train/logprobs = tensor([[-1.1246, -1.4335],
        [-0.9890, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053515590727329254
Epoch 0, Step 140: train/loss = 0.698981523513794, train/raw-loss = 0.685451865196228, train/logprobs = tensor([[-1.3949, -1.0011],
        [-1.2822, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05411882326006889
Epoch 0, Step 141: train/loss = 0.6533265113830566, train/raw-loss = 0.6401271820068359, train/logprobs = tensor([[-1.1314, -1.6414],
        [-1.0809, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05279714986681938
Epoch 0, Step 142: train/loss = 0.6386871933937073, train/raw-loss = 0.6241333484649658, train/logprobs = tensor([[-1.0404, -1.6170],
        [-1.0022, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05821537226438522
Epoch 0, Step 143: train/loss = 0.6866480708122253, train/raw-loss = 0.6721551418304443, train/logprobs = tensor([[-1.2011, -1.2546],
        [-1.1532, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05797164887189865
Epoch 0, Step 144: train/loss = 0.6746147871017456, train/raw-loss = 0.6609109044075012, train/logprobs = tensor([[-1.3260, -1.0035],
        [-1.3289, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05481541156768799
Epoch 0, Step 145: train/loss = 0.5997907519340515, train/raw-loss = 0.5856229066848755, train/logprobs = tensor([[-1.2028, -1.8454],
        [-1.1759, -1.3201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056671351194381714
Epoch 0, Step 146: train/loss = 0.6890504360198975, train/raw-loss = 0.6751623153686523, train/logprobs = tensor([[-1.1954, -1.1916],
        [-1.0586, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05555207282304764
Epoch 0, Step 147: train/loss = 0.6719162464141846, train/raw-loss = 0.6600877046585083, train/logprobs = tensor([[-0.7516, -0.9114],
        [-0.6901, -0.7035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04731394723057747
Epoch 0, Step 148: train/loss = 0.694631814956665, train/raw-loss = 0.6840238571166992, train/logprobs = tensor([[-0.5189, -0.5203],
        [-0.5070, -0.4705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04243184253573418
Epoch 0, Step 149: train/loss = 0.6131284236907959, train/raw-loss = 0.6015172004699707, train/logprobs = tensor([[-0.5482, -1.3259],
        [-0.5548, -0.9216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04644500091671944
Epoch 0, Step 150: train/loss = 0.6878014206886292, train/raw-loss = 0.6756187677383423, train/logprobs = tensor([[-1.0358, -0.9994],
        [-0.8799, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048730358481407166
Epoch 0, Step 151: train/loss = 0.6852344274520874, train/raw-loss = 0.674424946308136, train/logprobs = tensor([[-0.7687, -0.7702],
        [-0.5993, -0.4775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043238021433353424
Epoch 0, Step 152: train/loss = 0.7113184928894043, train/raw-loss = 0.6997036933898926, train/logprobs = tensor([[-1.1524, -0.7280],
        [-1.0412, -0.6379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046458855271339417
Epoch 0, Step 153: train/loss = 0.5918633937835693, train/raw-loss = 0.5770602226257324, train/logprobs = tensor([[-0.8651, -1.8821],
        [-0.7671, -1.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059212855994701385
Epoch 0, Step 154: train/loss = 0.680597186088562, train/raw-loss = 0.6645063757896423, train/logprobs = tensor([[-1.1419, -1.4024],
        [-0.8733, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06436337530612946
Epoch 0, Step 155: train/loss = 0.7049877643585205, train/raw-loss = 0.6910947561264038, train/logprobs = tensor([[-1.0017, -0.9356],
        [-0.8013, -0.6962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0555722638964653
Epoch 0, Step 156: train/loss = 0.6345574855804443, train/raw-loss = 0.6221420764923096, train/logprobs = tensor([[-0.6586, -1.1537],
        [-0.6203, -0.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04966126009821892
Epoch 0, Step 157: train/loss = 0.643778383731842, train/raw-loss = 0.6287496089935303, train/logprobs = tensor([[-1.2924, -1.2602],
        [-1.2531, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060115210711956024
Epoch 0, Step 158: train/loss = 0.6635834574699402, train/raw-loss = 0.647092342376709, train/logprobs = tensor([[-1.1681, -1.1922],
        [-1.0719, -0.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0659646987915039
Epoch 0, Step 159: train/loss = 0.6458443999290466, train/raw-loss = 0.630454421043396, train/logprobs = tensor([[-0.7741, -1.2831],
        [-0.7573, -0.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06155991554260254
Epoch 0, Step 160: train/loss = 0.6925849914550781, train/raw-loss = 0.6776164770126343, train/logprobs = tensor([[-1.1776, -1.0579],
        [-1.0220, -0.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059874072670936584
Epoch 0, Step 161: train/loss = 0.6645256280899048, train/raw-loss = 0.6506229043006897, train/logprobs = tensor([[-0.7357, -1.2254],
        [-0.6433, -0.9445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05561080574989319
Epoch 0, Step 162: train/loss = 0.6928234100341797, train/raw-loss = 0.6763317584991455, train/logprobs = tensor([[-1.1119, -1.3195],
        [-0.8646, -0.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06596621870994568
Epoch 0, Step 163: train/loss = 0.6978216767311096, train/raw-loss = 0.6786030530929565, train/logprobs = tensor([[-0.9179, -0.9973],
        [-0.8103, -0.8122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0768747329711914
Epoch 0, Step 164: train/loss = 0.6295872926712036, train/raw-loss = 0.612139105796814, train/logprobs = tensor([[-1.6274, -2.1951],
        [-1.2303, -1.3003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06979280710220337
Epoch 0, Step 165: train/loss = 0.6150736808776855, train/raw-loss = 0.5968809127807617, train/logprobs = tensor([[-0.7901, -1.4996],
        [-0.7115, -0.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07277092337608337
Epoch 0, Step 166: train/loss = 0.6892684102058411, train/raw-loss = 0.6748170256614685, train/logprobs = tensor([[-1.0564, -1.1815],
        [-0.8983, -0.9314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05780567601323128
Epoch 0, Step 167: train/loss = 0.6820067167282104, train/raw-loss = 0.666448712348938, train/logprobs = tensor([[-0.9362, -1.0648],
        [-0.6463, -0.6081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062231987714767456
Epoch 0, Step 168: train/loss = 0.6975878477096558, train/raw-loss = 0.6768261194229126, train/logprobs = tensor([[-1.4607, -1.2708],
        [-1.2028, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08304708451032639
Epoch 0, Step 169: train/loss = 0.6929347515106201, train/raw-loss = 0.6768487691879272, train/logprobs = tensor([[-1.2357, -0.8480],
        [-1.1120, -0.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06434408575296402
Epoch 0, Step 170: train/loss = 0.6522045731544495, train/raw-loss = 0.6377692222595215, train/logprobs = tensor([[-1.1801, -1.6293],
        [-0.9518, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057741425931453705
Epoch 0, Step 171: train/loss = 0.7295846343040466, train/raw-loss = 0.7136557102203369, train/logprobs = tensor([[-1.1792, -1.1150],
        [-0.8053, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06371558457612991
Epoch 0, Step 172: train/loss = 0.5961859226226807, train/raw-loss = 0.5780585408210754, train/logprobs = tensor([[-1.3189, -1.7994],
        [-1.0377, -0.8277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0725097581744194
Epoch 0, Step 173: train/loss = 0.6968674659729004, train/raw-loss = 0.6763424873352051, train/logprobs = tensor([[-1.1120, -1.4219],
        [-0.9478, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08209974318742752
Epoch 0, Step 174: train/loss = 0.6882143020629883, train/raw-loss = 0.6752408742904663, train/logprobs = tensor([[-0.6677, -0.7580],
        [-0.5669, -0.5797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05189375579357147
Epoch 0, Step 175: train/loss = 0.6715506911277771, train/raw-loss = 0.653915524482727, train/logprobs = tensor([[-1.0579, -1.5646],
        [-0.9504, -1.2815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07054097205400467
Epoch 0, Step 176: train/loss = 0.711222231388092, train/raw-loss = 0.6865438222885132, train/logprobs = tensor([[-1.5137, -1.7202],
        [-1.1553, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09871353209018707
Epoch 0, Step 177: train/loss = 0.7201730012893677, train/raw-loss = 0.7012332081794739, train/logprobs = tensor([[-1.2552, -1.2276],
        [-0.8594, -0.7953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07575932145118713
Epoch 0, Step 178: train/loss = 0.6222834587097168, train/raw-loss = 0.6049404740333557, train/logprobs = tensor([[-0.5265, -1.0856],
        [-0.4837, -0.5941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06937205046415329
Epoch 0, Step 179: train/loss = 0.7137511968612671, train/raw-loss = 0.6962217092514038, train/logprobs = tensor([[-1.1450, -1.1575],
        [-0.8505, -0.8410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0701179951429367
Epoch 0, Step 180: train/loss = 0.6526634097099304, train/raw-loss = 0.6327195167541504, train/logprobs = tensor([[-1.5584, -1.6362],
        [-1.3672, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0797756165266037
Epoch 0, Step 181: train/loss = 0.6570336222648621, train/raw-loss = 0.634925127029419, train/logprobs = tensor([[-1.5073, -2.0999],
        [-1.3130, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843394368886948
Epoch 0, Step 182: train/loss = 0.5686842799186707, train/raw-loss = 0.5526754260063171, train/logprobs = tensor([[-0.6325, -1.3204],
        [-0.6257, -0.5984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06403527408838272
Epoch 0, Step 183: train/loss = 0.7040975093841553, train/raw-loss = 0.6870830059051514, train/logprobs = tensor([[-1.5075, -2.7679],
        [-0.9578, -2.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06805804371833801
Epoch 0, Step 184: train/loss = 0.649072527885437, train/raw-loss = 0.6292896270751953, train/logprobs = tensor([[-0.9052, -1.4666],
        [-0.8054, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07913170754909515
Epoch 0, Step 185: train/loss = 0.6639317274093628, train/raw-loss = 0.6444509029388428, train/logprobs = tensor([[-1.0839, -1.4636],
        [-0.8231, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07792342454195023
Epoch 0, Step 186: train/loss = 0.670662522315979, train/raw-loss = 0.6510443687438965, train/logprobs = tensor([[-0.9965, -1.2979],
        [-0.7157, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07847246527671814
Epoch 0, Step 187: train/loss = 0.5693734884262085, train/raw-loss = 0.5511824488639832, train/logprobs = tensor([[-1.1596, -2.6097],
        [-0.8621, -1.3624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07276420295238495
Epoch 0, Step 188: train/loss = 0.55560302734375, train/raw-loss = 0.5364590883255005, train/logprobs = tensor([[-0.8389, -1.5914],
        [-0.7518, -0.6757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07657575607299805
Epoch 0, Step 189: train/loss = 0.7187708616256714, train/raw-loss = 0.7054948806762695, train/logprobs = tensor([[-1.0063, -0.7479],
        [-0.7476, -0.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05310402810573578
Epoch 0, Step 190: train/loss = 0.7379484176635742, train/raw-loss = 0.7152018547058105, train/logprobs = tensor([[-1.6241, -1.5163],
        [-1.1693, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0909862071275711
Epoch 0, Step 191: train/loss = 0.6670734286308289, train/raw-loss = 0.6484578847885132, train/logprobs = tensor([[-1.5688, -1.8401],
        [-1.3539, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07446230947971344
Epoch 0, Step 192: train/loss = 0.7099325656890869, train/raw-loss = 0.6941331624984741, train/logprobs = tensor([[-0.7329, -0.6552],
        [-0.5546, -0.4696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06319766491651535
Epoch 0, Step 193: train/loss = 0.6838545799255371, train/raw-loss = 0.665928065776825, train/logprobs = tensor([[-0.7990, -0.9020],
        [-0.5559, -0.5039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07170633226633072
Epoch 0, Step 194: train/loss = 0.6887648105621338, train/raw-loss = 0.6658363342285156, train/logprobs = tensor([[-1.1394, -1.1761],
        [-0.8298, -0.5911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0917140394449234
Epoch 0, Step 195: train/loss = 0.6672849655151367, train/raw-loss = 0.6470144987106323, train/logprobs = tensor([[-1.2029, -1.3026],
        [-0.9976, -0.8700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08108195662498474
Epoch 0, Step 196: train/loss = 0.7646628618240356, train/raw-loss = 0.7414789795875549, train/logprobs = tensor([[-1.5384, -1.3976],
        [-0.9191, -0.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09273551404476166
Epoch 0, Step 197: train/loss = 0.6411824822425842, train/raw-loss = 0.6157225370407104, train/logprobs = tensor([[-1.2546, -1.6108],
        [-0.9670, -0.9161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10183990001678467
Epoch 0, Step 198: train/loss = 0.5880921483039856, train/raw-loss = 0.5651577115058899, train/logprobs = tensor([[-0.9963, -1.9060],
        [-0.7737, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0917380154132843
Epoch 0, Step 199: train/loss = 0.6958231925964355, train/raw-loss = 0.6741209030151367, train/logprobs = tensor([[-1.1293, -1.1982],
        [-0.8450, -0.7662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08680892735719681
Epoch 0, Step 200: train/loss = 0.7053076028823853, train/raw-loss = 0.6820343732833862, train/logprobs = tensor([[-1.2140, -1.5485],
        [-0.7723, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09309300035238266
Epoch 0, Step 201: train/loss = 0.6928504705429077, train/raw-loss = 0.6679316163063049, train/logprobs = tensor([[-1.3534, -1.8143],
        [-0.9147, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09967544674873352
Epoch 0, Step 202: train/loss = 0.7233558893203735, train/raw-loss = 0.6985621452331543, train/logprobs = tensor([[-1.4502, -1.6376],
        [-1.1041, -1.2426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09917484223842621
Epoch 0, Step 203: train/loss = 0.6463788747787476, train/raw-loss = 0.6213052272796631, train/logprobs = tensor([[-1.0420, -1.4629],
        [-0.8624, -0.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10029476881027222
Epoch 0, Step 204: train/loss = 0.726969838142395, train/raw-loss = 0.7018747925758362, train/logprobs = tensor([[-1.7904, -1.6143],
        [-1.2073, -0.9153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10038027167320251
Epoch 0, Step 205: train/loss = 0.6830223798751831, train/raw-loss = 0.66557776927948, train/logprobs = tensor([[-0.9234, -0.9286],
        [-0.6764, -0.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06977871060371399
Epoch 0, Step 206: train/loss = 0.6578593254089355, train/raw-loss = 0.6372845768928528, train/logprobs = tensor([[-1.1487, -1.5891],
        [-0.7557, -0.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08229902386665344
Epoch 0, Step 207: train/loss = 0.6568669676780701, train/raw-loss = 0.6306367516517639, train/logprobs = tensor([[-1.3674, -2.1067],
        [-0.9042, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10492079704999924
Epoch 0, Step 208: train/loss = 0.659088671207428, train/raw-loss = 0.6377472877502441, train/logprobs = tensor([[-0.8690, -1.1105],
        [-0.5664, -0.4826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08536560833454132
Epoch 0, Step 209: train/loss = 0.5971733331680298, train/raw-loss = 0.5740805864334106, train/logprobs = tensor([[-1.0391, -1.5361],
        [-0.8799, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09237077832221985
Epoch 0, Step 210: train/loss = 0.7465904355049133, train/raw-loss = 0.719312310218811, train/logprobs = tensor([[-1.1756, -1.3559],
        [-0.6998, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10911215841770172
Epoch 0, Step 211: train/loss = 0.7047942876815796, train/raw-loss = 0.6842743158340454, train/logprobs = tensor([[-0.8983, -0.9225],
        [-0.6260, -0.5720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820799395442009
Epoch 0, Step 212: train/loss = 0.6796241402626038, train/raw-loss = 0.6440536975860596, train/logprobs = tensor([[-1.6811, -1.9814],
        [-1.1507, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14228147268295288
Epoch 0, Step 213: train/loss = 0.6961266994476318, train/raw-loss = 0.6751338839530945, train/logprobs = tensor([[-0.8107, -0.8496],
        [-0.5956, -0.5260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397150039672852
Epoch 0, Step 214: train/loss = 0.5664114952087402, train/raw-loss = 0.5443741083145142, train/logprobs = tensor([[-0.8442, -1.6187],
        [-0.8096, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08814958482980728
Epoch 0, Step 215: train/loss = 0.6896312236785889, train/raw-loss = 0.6644018888473511, train/logprobs = tensor([[-1.3168, -1.4054],
        [-0.9634, -0.8641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10091730952262878
Epoch 0, Step 216: train/loss = 0.6860342025756836, train/raw-loss = 0.6591116189956665, train/logprobs = tensor([[-1.1260, -1.2423],
        [-0.9953, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1076902449131012
Epoch 0, Step 217: train/loss = 0.6286501288414001, train/raw-loss = 0.6015775799751282, train/logprobs = tensor([[-1.1267, -2.3895],
        [-0.4880, -0.9853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10828985273838043
Epoch 0, Step 218: train/loss = 0.688136100769043, train/raw-loss = 0.6677608489990234, train/logprobs = tensor([[-0.8221, -1.0224],
        [-0.5859, -0.6464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0815008133649826
Epoch 0, Step 219: train/loss = 0.7067859768867493, train/raw-loss = 0.681611955165863, train/logprobs = tensor([[-1.4789, -1.7233],
        [-1.0349, -1.1203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10069634020328522
Epoch 0, Step 220: train/loss = 0.5879371166229248, train/raw-loss = 0.5635336637496948, train/logprobs = tensor([[-0.8859, -1.6733],
        [-0.6538, -0.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09761377424001694
Epoch 0, Step 221: train/loss = 0.5822592973709106, train/raw-loss = 0.5506824851036072, train/logprobs = tensor([[-1.3482, -1.8699],
        [-1.2618, -1.1032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12630707025527954
Epoch 0, Step 222: train/loss = 0.6078613996505737, train/raw-loss = 0.5842236280441284, train/logprobs = tensor([[-1.1957, -2.0967],
        [-0.8218, -0.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09455107152462006
Epoch 0, Step 223: train/loss = 0.6248738765716553, train/raw-loss = 0.6029502153396606, train/logprobs = tensor([[-1.3953, -2.1491],
        [-0.8013, -0.8823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08769457042217255
Epoch 0, Step 224: train/loss = 0.6717098355293274, train/raw-loss = 0.6442520022392273, train/logprobs = tensor([[-1.2479, -1.3858],
        [-1.0338, -0.8186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10983127355575562
Epoch 0, Step 225: train/loss = 0.7286791801452637, train/raw-loss = 0.7024749517440796, train/logprobs = tensor([[-1.2115, -1.3609],
        [-0.8299, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1048169732093811
Epoch 0, Step 226: train/loss = 0.695070743560791, train/raw-loss = 0.6720923185348511, train/logprobs = tensor([[-1.2639, -1.2370],
        [-1.2942, -1.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09191405028104782
Epoch 0, Step 227: train/loss = 0.6532219648361206, train/raw-loss = 0.6246623992919922, train/logprobs = tensor([[-1.0520, -1.3878],
        [-0.8604, -0.8291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.114238440990448
Epoch 0, Step 228: train/loss = 0.6206374764442444, train/raw-loss = 0.5968664288520813, train/logprobs = tensor([[-0.8294, -1.3866],
        [-0.8027, -0.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09508390724658966
Epoch 0, Step 229: train/loss = 0.7656883597373962, train/raw-loss = 0.7438770532608032, train/logprobs = tensor([[-1.2272, -0.7445],
        [-0.8851, -0.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08724527060985565
Epoch 0, Step 230: train/loss = 0.5698406100273132, train/raw-loss = 0.5400066375732422, train/logprobs = tensor([[-1.5101, -2.6854],
        [-0.9676, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11933593451976776
Epoch 0, Step 231: train/loss = 0.6034870147705078, train/raw-loss = 0.5814067721366882, train/logprobs = tensor([[-0.5648, -1.4995],
        [-0.4209, -0.7787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08832095563411713
Epoch 0, Step 232: train/loss = 0.6455052495002747, train/raw-loss = 0.6182363033294678, train/logprobs = tensor([[-0.8971, -1.3526],
        [-0.7445, -0.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10907571017742157
Epoch 0, Step 233: train/loss = 0.6157153248786926, train/raw-loss = 0.5883631110191345, train/logprobs = tensor([[-0.9323, -1.4971],
        [-0.9457, -1.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10940883308649063
Epoch 0, Step 234: train/loss = 0.6721173524856567, train/raw-loss = 0.6438618898391724, train/logprobs = tensor([[-1.3784, -1.8532],
        [-0.8117, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11302169412374496
Epoch 0, Step 235: train/loss = 0.6815013885498047, train/raw-loss = 0.6585145592689514, train/logprobs = tensor([[-0.7800, -0.7989],
        [-0.7963, -0.6666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09194725751876831
Epoch 0, Step 236: train/loss = 0.7375011444091797, train/raw-loss = 0.7110243439674377, train/logprobs = tensor([[-1.8157, -1.8206],
        [-1.5319, -1.5272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10590727627277374
Epoch 0, Step 237: train/loss = 0.6958970427513123, train/raw-loss = 0.6715739965438843, train/logprobs = tensor([[-0.9005, -0.8594],
        [-0.8462, -0.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0972922220826149
Epoch 0, Step 238: train/loss = 0.6407486796379089, train/raw-loss = 0.6099148988723755, train/logprobs = tensor([[-1.0862, -1.6495],
        [-0.8407, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12333522737026215
Epoch 0, Step 239: train/loss = 0.7163668870925903, train/raw-loss = 0.6843143701553345, train/logprobs = tensor([[-0.9270, -1.0108],
        [-0.8036, -0.8085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12821003794670105
Epoch 0, Step 240: train/loss = 0.6414007544517517, train/raw-loss = 0.6179947853088379, train/logprobs = tensor([[-0.6385, -1.0765],
        [-0.6372, -0.6874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09362372756004333
Epoch 0, Step 241: train/loss = 0.7119134664535522, train/raw-loss = 0.6893594264984131, train/logprobs = tensor([[-0.9151, -0.6861],
        [-0.8141, -0.5389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09021611511707306
Epoch 0, Step 242: train/loss = 0.5912666320800781, train/raw-loss = 0.5639002323150635, train/logprobs = tensor([[-1.3352, -2.1686],
        [-1.1009, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10946584492921829
Epoch 0, Step 243: train/loss = 0.7031263113021851, train/raw-loss = 0.6810187101364136, train/logprobs = tensor([[-0.8873, -1.0197],
        [-0.6448, -0.6416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08843052387237549
Epoch 0, Step 244: train/loss = 0.6560506820678711, train/raw-loss = 0.634937047958374, train/logprobs = tensor([[-0.4904, -1.0780],
        [-0.5555, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08445454388856888
Epoch 0, Step 245: train/loss = 0.6825119256973267, train/raw-loss = 0.6549340486526489, train/logprobs = tensor([[-1.3650, -1.1206],
        [-1.4398, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11031164228916168
Epoch 0, Step 246: train/loss = 0.7538942098617554, train/raw-loss = 0.7261723279953003, train/logprobs = tensor([[-1.5723, -1.1040],
        [-1.2633, -0.8896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11088769137859344
Epoch 0, Step 247: train/loss = 0.9819004535675049, train/raw-loss = 0.9595054388046265, train/logprobs = tensor([[-1.8010, -0.8640],
        [-0.9068, -0.6353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08958031982183456
Epoch 0, Step 248: train/loss = 0.6634790897369385, train/raw-loss = 0.6380126476287842, train/logprobs = tensor([[-0.6758, -1.6344],
        [-0.7709, -1.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10186560451984406
Epoch 0, Step 249: train/loss = 0.627676784992218, train/raw-loss = 0.5941567420959473, train/logprobs = tensor([[-0.8726, -1.3079],
        [-1.1142, -1.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13408039510250092
Epoch 0, Step 250: train/loss = 0.6541689038276672, train/raw-loss = 0.631393551826477, train/logprobs = tensor([[-0.6600, -0.9199],
        [-0.6920, -0.6231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0911015123128891
Epoch 0, Step 251: train/loss = 0.6135042905807495, train/raw-loss = 0.5880111455917358, train/logprobs = tensor([[-1.4836, -2.1614],
        [-1.3922, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1019723117351532
Epoch 0, Step 252: train/loss = 0.7008030414581299, train/raw-loss = 0.6667265295982361, train/logprobs = tensor([[-1.2862, -1.2453],
        [-1.0526, -0.8555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13630631566047668
Epoch 0, Step 253: train/loss = 0.5741782784461975, train/raw-loss = 0.5484247207641602, train/logprobs = tensor([[-0.5929, -1.3482],
        [-0.7486, -0.7630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10301423072814941
Epoch 0, Step 254: train/loss = 0.6838958263397217, train/raw-loss = 0.6588650941848755, train/logprobs = tensor([[-0.9426, -1.1694],
        [-0.7978, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10012315213680267
Epoch 0, Step 255: train/loss = 0.6507575511932373, train/raw-loss = 0.6291306018829346, train/logprobs = tensor([[-0.4590, -1.0998],
        [-0.5388, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08650774508714676
Epoch 0, Step 256: train/loss = 0.7103961110115051, train/raw-loss = 0.6775237917900085, train/logprobs = tensor([[-1.3498, -1.2966],
        [-1.3448, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13148917257785797
Epoch 0, Step 257: train/loss = 0.6769113540649414, train/raw-loss = 0.6473446488380432, train/logprobs = tensor([[-1.2858, -1.4264],
        [-0.9851, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11826668679714203
Epoch 0, Step 258: train/loss = 0.6096442937850952, train/raw-loss = 0.5826674699783325, train/logprobs = tensor([[-1.0906, -1.7420],
        [-1.0397, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10790705680847168
Epoch 0, Step 259: train/loss = 0.6357905268669128, train/raw-loss = 0.6100527048110962, train/logprobs = tensor([[-1.2516, -1.8256],
        [-0.9454, -1.0152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10295124351978302
Epoch 0, Step 260: train/loss = 0.7672092914581299, train/raw-loss = 0.7390686273574829, train/logprobs = tensor([[-2.1986, -2.1195],
        [-1.6340, -1.5725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256270110607147
Epoch 0, Step 261: train/loss = 0.5503067970275879, train/raw-loss = 0.5159401893615723, train/logprobs = tensor([[-1.3144, -2.2440],
        [-1.2256, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374664157629013
Epoch 0, Step 262: train/loss = 0.6669979095458984, train/raw-loss = 0.6401008367538452, train/logprobs = tensor([[-1.6940, -2.3893],
        [-1.0606, -1.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10758863389492035
Epoch 0, Step 263: train/loss = 0.6781662702560425, train/raw-loss = 0.6486759781837463, train/logprobs = tensor([[-1.1610, -1.2621],
        [-1.0943, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11796100437641144
Epoch 0, Step 264: train/loss = 0.6183284521102905, train/raw-loss = 0.592399001121521, train/logprobs = tensor([[-1.0351, -1.5363],
        [-0.7879, -0.6879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10371802002191544
Epoch 0, Step 265: train/loss = 0.693426251411438, train/raw-loss = 0.6732511520385742, train/logprobs = tensor([[-0.6040, -0.7361],
        [-0.4101, -0.4117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0807003304362297
Epoch 0, Step 266: train/loss = 0.7034815549850464, train/raw-loss = 0.675541341304779, train/logprobs = tensor([[-1.1053, -1.1813],
        [-0.9416, -0.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11176060885190964
Epoch 0, Step 267: train/loss = 0.7071390151977539, train/raw-loss = 0.6786608099937439, train/logprobs = tensor([[-2.2441, -2.4842],
        [-1.8096, -1.7721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11391285061836243
Epoch 0, Step 268: train/loss = 0.6404905319213867, train/raw-loss = 0.6185890436172485, train/logprobs = tensor([[-0.5906, -0.9423],
        [-0.7172, -0.7183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08760586380958557
Epoch 0, Step 269: train/loss = 0.6459797620773315, train/raw-loss = 0.6195640563964844, train/logprobs = tensor([[-1.3200, -2.1357],
        [-0.8574, -1.1126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056627482175827
Epoch 0, Step 270: train/loss = 0.7134617567062378, train/raw-loss = 0.6857584714889526, train/logprobs = tensor([[-2.2201, -2.4632],
        [-1.5812, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11081266403198242
Epoch 0, Step 271: train/loss = 0.6775341629981995, train/raw-loss = 0.6480735540390015, train/logprobs = tensor([[-1.0128, -0.9512],
        [-0.9912, -0.7162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1178421676158905
Epoch 0, Step 272: train/loss = 0.7288743853569031, train/raw-loss = 0.6992441415786743, train/logprobs = tensor([[-1.1074, -1.2316],
        [-0.8819, -0.9905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1185212954878807
Epoch 0, Step 273: train/loss = 0.6332286596298218, train/raw-loss = 0.6064772605895996, train/logprobs = tensor([[-0.7857, -1.4650],
        [-0.6880, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10700549930334091
Epoch 0, Step 274: train/loss = 0.7931142449378967, train/raw-loss = 0.7552733421325684, train/logprobs = tensor([[-2.0173, -2.2098],
        [-1.0350, -0.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1513635218143463
Epoch 0, Step 275: train/loss = 0.5919082164764404, train/raw-loss = 0.5648905038833618, train/logprobs = tensor([[-1.9495, -3.6423],
        [-1.6656, -2.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10807084292173386
Epoch 0, Step 276: train/loss = 0.6040540337562561, train/raw-loss = 0.5709918737411499, train/logprobs = tensor([[-0.9569, -1.9921],
        [-0.8320, -0.7305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13224896788597107
Epoch 0, Step 277: train/loss = 0.649582028388977, train/raw-loss = 0.6204965114593506, train/logprobs = tensor([[-1.1613, -1.5697],
        [-1.1859, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11634200811386108
Epoch 0, Step 278: train/loss = 0.8907796144485474, train/raw-loss = 0.8561468124389648, train/logprobs = tensor([[-2.0319, -1.6831],
        [-1.0209, -0.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13853108882904053
Epoch 0, Step 279: train/loss = 0.7141941785812378, train/raw-loss = 0.6841385364532471, train/logprobs = tensor([[-1.0921, -1.4082],
        [-0.7978, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12022282183170319
Epoch 0, Step 280: train/loss = 0.7581016421318054, train/raw-loss = 0.7308951616287231, train/logprobs = tensor([[-0.9130, -0.8079],
        [-0.7674, -0.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10882584005594254
Epoch 0, Step 281: train/loss = 0.5694408416748047, train/raw-loss = 0.5401867628097534, train/logprobs = tensor([[-0.6428, -1.6056],
        [-0.6807, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11701614409685135
Epoch 0, Step 282: train/loss = 0.730698823928833, train/raw-loss = 0.7003146409988403, train/logprobs = tensor([[-1.3586, -1.7587],
        [-0.8183, -0.9970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12153690308332443
Epoch 0, Step 283: train/loss = 0.7304571866989136, train/raw-loss = 0.6955709457397461, train/logprobs = tensor([[-1.5733, -1.7287],
        [-1.2437, -1.2165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1395449936389923
Epoch 0, Step 284: train/loss = 0.5829983949661255, train/raw-loss = 0.5549388527870178, train/logprobs = tensor([[-0.7388, -1.5548],
        [-0.9862, -0.9388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11223830282688141
Epoch 0, Step 285: train/loss = 0.5144419074058533, train/raw-loss = 0.48194122314453125, train/logprobs = tensor([[-0.6278, -2.1011],
        [-0.6631, -0.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13000264763832092
Epoch 0, Step 286: train/loss = 0.7538647055625916, train/raw-loss = 0.7245723009109497, train/logprobs = tensor([[-1.0889, -1.1810],
        [-0.5851, -0.5844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1171695739030838
Epoch 0, Step 287: train/loss = 0.570521891117096, train/raw-loss = 0.5361229181289673, train/logprobs = tensor([[-1.1933, -1.6758],
        [-1.2067, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13759587705135345
Epoch 0, Step 288: train/loss = 0.6884399652481079, train/raw-loss = 0.6531190872192383, train/logprobs = tensor([[-1.2125, -1.1111],
        [-1.0212, -0.6268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14128370583057404
Epoch 0, Step 289: train/loss = 0.7489800453186035, train/raw-loss = 0.7109591364860535, train/logprobs = tensor([[-1.6425, -1.4036],
        [-1.2030, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15208323299884796
Epoch 0, Step 290: train/loss = 0.6533946990966797, train/raw-loss = 0.6259438991546631, train/logprobs = tensor([[-1.2929, -1.9420],
        [-0.7708, -0.7338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10980302095413208
Epoch 0, Step 291: train/loss = 0.7243632674217224, train/raw-loss = 0.6899194717407227, train/logprobs = tensor([[-1.3620, -1.3573],
        [-1.0593, -0.9360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377749741077423
Epoch 0, Step 292: train/loss = 0.6348056793212891, train/raw-loss = 0.6030296683311462, train/logprobs = tensor([[-1.2842, -1.9875],
        [-1.0892, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12710414826869965
Epoch 0, Step 293: train/loss = 0.7026129364967346, train/raw-loss = 0.6766176223754883, train/logprobs = tensor([[-0.4701, -0.4545],
        [-0.5371, -0.4478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10398104786872864
Epoch 0, Step 294: train/loss = 0.6162703633308411, train/raw-loss = 0.5895850658416748, train/logprobs = tensor([[-0.7503, -1.3483],
        [-0.7105, -0.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10674136132001877
Epoch 0, Step 295: train/loss = 0.6660012006759644, train/raw-loss = 0.6339526772499084, train/logprobs = tensor([[-1.1397, -1.5631],
        [-1.0041, -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12819430232048035
Epoch 0, Step 296: train/loss = 0.6781984567642212, train/raw-loss = 0.6538378000259399, train/logprobs = tensor([[-0.6933, -0.4842],
        [-0.8468, -0.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.097442626953125
Epoch 0, Step 297: train/loss = 0.568472146987915, train/raw-loss = 0.5323029160499573, train/logprobs = tensor([[-1.2307, -2.5756],
        [-0.7859, -1.0129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14467690885066986
Epoch 0, Step 298: train/loss = 0.645179033279419, train/raw-loss = 0.6103522777557373, train/logprobs = tensor([[-1.2891, -1.8765],
        [-0.9380, -0.7958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1393071711063385
Epoch 0, Step 299: train/loss = 0.5737959146499634, train/raw-loss = 0.5401178598403931, train/logprobs = tensor([[-0.9869, -1.6154],
        [-1.1022, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13471226394176483
Epoch 0, Step 300: train/loss = 0.4982042908668518, train/raw-loss = 0.4622335433959961, train/logprobs = tensor([[-1.2134, -2.6863],
        [-1.1472, -1.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14388304948806763
Epoch 0, Step 301: train/loss = 0.6265497803688049, train/raw-loss = 0.5998792052268982, train/logprobs = tensor([[-0.8272, -1.3821],
        [-0.6973, -0.7931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10668233036994934
Epoch 0, Step 302: train/loss = 0.47987714409828186, train/raw-loss = 0.4456586241722107, train/logprobs = tensor([[-1.0743, -3.0888],
        [-1.0472, -1.0701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1368739902973175
Epoch 0, Step 303: train/loss = 0.8027230501174927, train/raw-loss = 0.7687251567840576, train/logprobs = tensor([[-1.2680, -1.0481],
        [-0.8581, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359916627407074
Epoch 0, Step 304: train/loss = 0.6418915390968323, train/raw-loss = 0.602031946182251, train/logprobs = tensor([[-1.3389, -1.6342],
        [-1.3086, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15943849086761475
Epoch 0, Step 305: train/loss = 0.5998150110244751, train/raw-loss = 0.5683045983314514, train/logprobs = tensor([[-1.1466, -2.1894],
        [-1.0308, -1.4320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12604187428951263
Epoch 0, Step 306: train/loss = 0.6297955513000488, train/raw-loss = 0.5964739322662354, train/logprobs = tensor([[-1.3218, -1.7183],
        [-1.1677, -0.9704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332862377166748
Epoch 0, Step 307: train/loss = 0.700761616230011, train/raw-loss = 0.6721401214599609, train/logprobs = tensor([[-1.8920, -2.1731],
        [-1.3460, -1.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11448601633310318
Epoch 0, Step 308: train/loss = 0.6988239288330078, train/raw-loss = 0.6679849624633789, train/logprobs = tensor([[-1.1799, -0.9803],
        [-1.1285, -0.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12335589528083801
Epoch 0, Step 309: train/loss = 0.6057332754135132, train/raw-loss = 0.570882260799408, train/logprobs = tensor([[-1.1264, -1.5846],
        [-1.0051, -0.7523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13940384984016418
Epoch 0, Step 310: train/loss = 0.6739637851715088, train/raw-loss = 0.638570249080658, train/logprobs = tensor([[-1.1665, -1.2849],
        [-1.0459, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1415744125843048
Epoch 0, Step 311: train/loss = 0.6023455858230591, train/raw-loss = 0.5684505105018616, train/logprobs = tensor([[-1.5739, -2.2900],
        [-1.2424, -1.0930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13558034598827362
Epoch 0, Step 312: train/loss = 0.5378113389015198, train/raw-loss = 0.5046488046646118, train/logprobs = tensor([[-0.9935, -2.4732],
        [-1.1514, -1.6579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13265016674995422
Epoch 0, Step 313: train/loss = 0.6135069727897644, train/raw-loss = 0.5830943584442139, train/logprobs = tensor([[-0.9238, -1.7054],
        [-0.7952, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12165047228336334
Epoch 0, Step 314: train/loss = 0.5817503929138184, train/raw-loss = 0.5505711436271667, train/logprobs = tensor([[-1.1922, -2.0767],
        [-1.0743, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12471702694892883
Epoch 0, Step 315: train/loss = 0.6090651750564575, train/raw-loss = 0.5754185914993286, train/logprobs = tensor([[-1.6309, -2.3648],
        [-1.1861, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13458649814128876
Epoch 0, Step 316: train/loss = 0.7174833416938782, train/raw-loss = 0.6878547668457031, train/logprobs = tensor([[-1.8027, -1.8906],
        [-1.3297, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11851411312818527
Epoch 0, Step 317: train/loss = 0.7053820490837097, train/raw-loss = 0.6810556650161743, train/logprobs = tensor([[-0.8258, -1.9072],
        [-0.6750, -1.6322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09730549156665802
Epoch 0, Step 318: train/loss = 0.5399724245071411, train/raw-loss = 0.5065430998802185, train/logprobs = tensor([[-1.1590, -1.8078],
        [-1.1179, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13371725380420685
Epoch 0, Step 319: train/loss = 0.7033607959747314, train/raw-loss = 0.6612517833709717, train/logprobs = tensor([[-2.6111, -2.6897],
        [-1.7872, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16843636333942413
Epoch 0, Step 320: train/loss = 0.7031819820404053, train/raw-loss = 0.6715203523635864, train/logprobs = tensor([[-1.5771, -1.6138],
        [-1.2602, -1.1015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12664633989334106
Epoch 0, Step 321: train/loss = 0.8302282094955444, train/raw-loss = 0.7951236963272095, train/logprobs = tensor([[-2.4134, -1.7324],
        [-1.5691, -1.0560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1404178887605667
Epoch 0, Step 322: train/loss = 0.7278432250022888, train/raw-loss = 0.6958476305007935, train/logprobs = tensor([[-2.5356, -3.2838],
        [-1.5540, -1.8542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12798243761062622
Epoch 0, Step 323: train/loss = 0.5500687956809998, train/raw-loss = 0.5169363021850586, train/logprobs = tensor([[-1.2068, -1.8736],
        [-1.2465, -1.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13253001868724823
Epoch 0, Step 324: train/loss = 0.6186617612838745, train/raw-loss = 0.583138644695282, train/logprobs = tensor([[-1.0719, -0.9421],
        [-1.3574, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1420925110578537
Epoch 0, Step 325: train/loss = 0.6697267293930054, train/raw-loss = 0.6372247338294983, train/logprobs = tensor([[-1.1239, -1.7072],
        [-0.8617, -1.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13000808656215668
Epoch 0, Step 326: train/loss = 0.7656828165054321, train/raw-loss = 0.7337904572486877, train/logprobs = tensor([[-1.8941, -1.9805],
        [-1.2903, -1.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12756916880607605
Epoch 0, Step 327: train/loss = 0.7560365200042725, train/raw-loss = 0.7256707549095154, train/logprobs = tensor([[-0.9433, -0.8442],
        [-0.8613, -0.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12146329879760742
Epoch 0, Step 328: train/loss = 0.5650222897529602, train/raw-loss = 0.5320398807525635, train/logprobs = tensor([[-1.0807, -1.8363],
        [-1.1287, -1.0739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13192971050739288
Epoch 0, Step 329: train/loss = 0.692802369594574, train/raw-loss = 0.6662784814834595, train/logprobs = tensor([[-1.3587, -1.7084],
        [-1.1048, -1.2638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10609562695026398
Epoch 0, Step 330: train/loss = 0.6905220150947571, train/raw-loss = 0.6562323570251465, train/logprobs = tensor([[-1.4678, -1.7421],
        [-1.6300, -1.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13715848326683044
Epoch 0, Step 331: train/loss = 0.6334325075149536, train/raw-loss = 0.6020916700363159, train/logprobs = tensor([[-0.7180, -0.9758],
        [-0.9064, -0.7436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12536340951919556
Epoch 0, Step 332: train/loss = 0.5961654782295227, train/raw-loss = 0.5616705417633057, train/logprobs = tensor([[-0.8033, -1.7646],
        [-0.9742, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13797973096370697
Epoch 0, Step 333: train/loss = 0.6846545338630676, train/raw-loss = 0.6494658589363098, train/logprobs = tensor([[-1.8626, -2.1306],
        [-1.4282, -1.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14075452089309692
Epoch 0, Step 334: train/loss = 0.5117170214653015, train/raw-loss = 0.48277556896209717, train/logprobs = tensor([[-1.0019, -2.3200],
        [-0.9288, -1.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11576586961746216
Epoch 0, Step 335: train/loss = 0.6775189638137817, train/raw-loss = 0.6507871150970459, train/logprobs = tensor([[-1.2828, -1.3754],
        [-1.0712, -0.8052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10692755877971649
Epoch 0, Step 336: train/loss = 0.7054835557937622, train/raw-loss = 0.673107922077179, train/logprobs = tensor([[-0.9408, -2.7825],
        [-1.0607, -1.5071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12950240075588226
Epoch 0, Step 337: train/loss = 0.7079476714134216, train/raw-loss = 0.6787678003311157, train/logprobs = tensor([[-1.6142, -1.0677],
        [-1.6366, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11671951413154602
Epoch 0, Step 338: train/loss = 0.6000465154647827, train/raw-loss = 0.5657936930656433, train/logprobs = tensor([[-0.9488, -1.6063],
        [-1.0322, -1.0494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370110958814621
Epoch 0, Step 339: train/loss = 0.6849880218505859, train/raw-loss = 0.647444486618042, train/logprobs = tensor([[-2.5435, -2.3798],
        [-2.2733, -1.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1501741260290146
Epoch 0, Step 340: train/loss = 0.6423757672309875, train/raw-loss = 0.6083658337593079, train/logprobs = tensor([[-1.1762, -1.9385],
        [-1.1066, -1.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13603974878787994
Epoch 0, Step 341: train/loss = 0.7197247743606567, train/raw-loss = 0.6905542612075806, train/logprobs = tensor([[-0.6958, -0.6191],
        [-0.7372, -0.6468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11668206751346588
Epoch 0, Step 342: train/loss = 0.6926407217979431, train/raw-loss = 0.6654122471809387, train/logprobs = tensor([[-0.6578, -0.7626],
        [-0.8368, -0.8194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10891381651163101
Epoch 0, Step 343: train/loss = 0.6511057615280151, train/raw-loss = 0.620675265789032, train/logprobs = tensor([[-1.6144, -1.5907],
        [-1.7428, -1.4079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12172223627567291
Epoch 0, Step 344: train/loss = 0.6173118352890015, train/raw-loss = 0.5891788005828857, train/logprobs = tensor([[-0.5062, -1.2081],
        [-0.6540, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11253207176923752
Epoch 0, Step 345: train/loss = 0.7067994475364685, train/raw-loss = 0.6759129762649536, train/logprobs = tensor([[-0.7839, -0.7566],
        [-0.8397, -0.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12354601919651031
Epoch 0, Step 346: train/loss = 0.5409842133522034, train/raw-loss = 0.5046753883361816, train/logprobs = tensor([[-1.2298, -2.0233],
        [-1.4582, -1.3407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14523516595363617
Epoch 0, Step 347: train/loss = 0.5542930960655212, train/raw-loss = 0.5215796828269958, train/logprobs = tensor([[-0.9074, -1.8434],
        [-1.0554, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1308537721633911
Epoch 0, Step 348: train/loss = 0.5899696350097656, train/raw-loss = 0.5516827702522278, train/logprobs = tensor([[-1.1333, -1.8791],
        [-1.1180, -1.1351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15314728021621704
Epoch 0, Step 349: train/loss = 0.6700205206871033, train/raw-loss = 0.6358726024627686, train/logprobs = tensor([[-1.3132, -1.4176],
        [-1.5545, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13659149408340454
Epoch 0, Step 350: train/loss = 0.6749772429466248, train/raw-loss = 0.6387671232223511, train/logprobs = tensor([[-1.0912, -1.0935],
        [-1.2435, -0.9762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1448403298854828
Epoch 0, Step 351: train/loss = 0.6561316847801208, train/raw-loss = 0.6235886216163635, train/logprobs = tensor([[-0.9199, -1.1216],
        [-1.1292, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13017244637012482
Epoch 0, Step 352: train/loss = 0.6806968450546265, train/raw-loss = 0.6534197330474854, train/logprobs = tensor([[-1.2004, -1.7441],
        [-1.0006, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1091083288192749
Epoch 0, Step 353: train/loss = 0.6019195914268494, train/raw-loss = 0.569860577583313, train/logprobs = tensor([[-1.2400, -2.3519],
        [-1.1171, -1.4020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12823596596717834
Epoch 0, Step 354: train/loss = 0.7068929076194763, train/raw-loss = 0.6884167194366455, train/logprobs = tensor([[-0.4867, -0.4929],
        [-0.4695, -0.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07390472292900085
Epoch 0, Step 355: train/loss = 0.6996510028839111, train/raw-loss = 0.6714353561401367, train/logprobs = tensor([[-1.5630, -1.6884],
        [-1.3995, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11286245286464691
Epoch 0, Step 356: train/loss = 0.6765859127044678, train/raw-loss = 0.6495925188064575, train/logprobs = tensor([[-0.8032, -0.8891],
        [-0.9108, -0.8016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10797353088855743
Epoch 0, Step 357: train/loss = 0.5623098611831665, train/raw-loss = 0.5314428806304932, train/logprobs = tensor([[-1.2945, -1.9428],
        [-1.5960, -1.3735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12346789240837097
Epoch 0, Step 358: train/loss = 0.6769685745239258, train/raw-loss = 0.6447461843490601, train/logprobs = tensor([[-0.9019, -2.3942],
        [-0.8904, -2.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12888973951339722
Epoch 0, Step 359: train/loss = 0.6174333691596985, train/raw-loss = 0.5887690782546997, train/logprobs = tensor([[-1.0100, -1.6162],
        [-1.0431, -1.1497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11465711146593094
Epoch 0, Step 360: train/loss = 0.5803601741790771, train/raw-loss = 0.5499982237815857, train/logprobs = tensor([[-1.2231, -1.9923],
        [-1.7112, -1.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12144772708415985
Epoch 0, Step 361: train/loss = 0.8007638454437256, train/raw-loss = 0.7665716409683228, train/logprobs = tensor([[-1.4989, -1.3217],
        [-1.2766, -1.3104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13676893711090088
Epoch 0, Step 362: train/loss = 0.6234767436981201, train/raw-loss = 0.5886589288711548, train/logprobs = tensor([[-2.4281, -2.8492],
        [-2.5057, -2.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392713189125061
Epoch 0, Step 363: train/loss = 0.666087806224823, train/raw-loss = 0.642051100730896, train/logprobs = tensor([[-0.4753, -0.8047],
        [-0.6391, -0.7480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09614691138267517
Epoch 0, Step 364: train/loss = 0.7146798372268677, train/raw-loss = 0.6842095255851746, train/logprobs = tensor([[-0.9233, -1.2950],
        [-1.0458, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12188135832548141
Epoch 0, Step 365: train/loss = 0.6559823155403137, train/raw-loss = 0.6259459257125854, train/logprobs = tensor([[-1.3391, -1.7005],
        [-1.1219, -1.0877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12014537304639816
Epoch 0, Step 366: train/loss = 0.5747405290603638, train/raw-loss = 0.5444648265838623, train/logprobs = tensor([[-0.6504, -1.6273],
        [-0.8427, -1.0835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12110283225774765
Epoch 0, Step 367: train/loss = 0.640069305896759, train/raw-loss = 0.6062338352203369, train/logprobs = tensor([[-1.1047, -1.9265],
        [-1.1348, -1.4908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13534194231033325
Epoch 0, Step 368: train/loss = 0.6503262519836426, train/raw-loss = 0.6242344379425049, train/logprobs = tensor([[-0.9844, -1.3611],
        [-1.0119, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10436735302209854
Epoch 0, Step 369: train/loss = 0.6249046325683594, train/raw-loss = 0.5903913378715515, train/logprobs = tensor([[-1.7523, -1.4453],
        [-2.1174, -1.3254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380532681941986
Epoch 0, Step 370: train/loss = 0.7024967670440674, train/raw-loss = 0.6723237633705139, train/logprobs = tensor([[-1.0909, -1.0214],
        [-1.1937, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12069221585988998
Epoch 0, Step 371: train/loss = 0.6425070762634277, train/raw-loss = 0.6172610521316528, train/logprobs = tensor([[-0.7449, -0.6925],
        [-1.2309, -0.7482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10098405927419662
Epoch 0, Step 372: train/loss = 0.6950423717498779, train/raw-loss = 0.6682546138763428, train/logprobs = tensor([[-0.5661, -0.8186],
        [-0.6654, -0.8108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1071510910987854
Epoch 0, Step 373: train/loss = 0.7234103083610535, train/raw-loss = 0.7009302377700806, train/logprobs = tensor([[-0.7917, -0.4830],
        [-0.7913, -0.5116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08991999924182892
Epoch 0, Step 374: train/loss = 0.626882016658783, train/raw-loss = 0.5994315147399902, train/logprobs = tensor([[-0.7044, -1.2391],
        [-0.8163, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10980204492807388
Epoch 0, Step 375: train/loss = 0.7736287713050842, train/raw-loss = 0.7490936517715454, train/logprobs = tensor([[-2.1530, -1.2211],
        [-1.8418, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09814030677080154
Epoch 0, Step 376: train/loss = 0.6929290294647217, train/raw-loss = 0.6669737100601196, train/logprobs = tensor([[-0.5767, -0.5975],
        [-0.6656, -0.5772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382138192653656
Epoch 0, Step 377: train/loss = 0.7563719749450684, train/raw-loss = 0.7242336273193359, train/logprobs = tensor([[-0.8325, -0.7695],
        [-0.7986, -0.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12855345010757446
Epoch 0, Step 378: train/loss = 0.586205244064331, train/raw-loss = 0.5633731484413147, train/logprobs = tensor([[-0.7003, -1.4875],
        [-0.8667, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09132853895425797
Epoch 0, Step 379: train/loss = 0.5356910824775696, train/raw-loss = 0.5070196390151978, train/logprobs = tensor([[-0.9771, -2.4336],
        [-1.0414, -1.5462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11468590050935745
Epoch 0, Step 380: train/loss = 0.660499095916748, train/raw-loss = 0.6295523643493652, train/logprobs = tensor([[-0.9635, -1.2056],
        [-1.1064, -1.0728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12378685176372528
Epoch 0, Step 381: train/loss = 0.6880592107772827, train/raw-loss = 0.660662829875946, train/logprobs = tensor([[-1.2687, -1.2401],
        [-1.3395, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10958544909954071
Epoch 0, Step 382: train/loss = 0.6723326444625854, train/raw-loss = 0.6437876224517822, train/logprobs = tensor([[-0.9979, -0.9562],
        [-1.1121, -0.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11418008804321289
Epoch 0, Step 383: train/loss = 0.6406171321868896, train/raw-loss = 0.6093015074729919, train/logprobs = tensor([[-0.7205, -1.1768],
        [-0.9619, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12526272237300873
Epoch 0, Step 384: train/loss = 0.6562793254852295, train/raw-loss = 0.6225206851959229, train/logprobs = tensor([[-1.3963, -1.4244],
        [-1.5440, -1.2666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1350344717502594
Epoch 0, Step 385: train/loss = 0.6978921890258789, train/raw-loss = 0.6637598276138306, train/logprobs = tensor([[-1.1338, -1.2265],
        [-1.2562, -1.2151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13652975857257843
Epoch 0, Step 386: train/loss = 0.6152351498603821, train/raw-loss = 0.585751473903656, train/logprobs = tensor([[-1.0329, -1.8360],
        [-0.9625, -1.1427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11793464422225952
Epoch 0, Step 387: train/loss = 0.6729482412338257, train/raw-loss = 0.6449178457260132, train/logprobs = tensor([[-1.1474, -2.1451],
        [-1.1677, -1.9609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11212140321731567
Epoch 0, Step 388: train/loss = 0.6452707052230835, train/raw-loss = 0.6152763366699219, train/logprobs = tensor([[-0.8729, -1.1474],
        [-0.9797, -0.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11997764557600021
Epoch 0, Step 389: train/loss = 0.6467760801315308, train/raw-loss = 0.619186520576477, train/logprobs = tensor([[-1.2301, -0.9902],
        [-1.5065, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11035814136266708
Epoch 0, Step 390: train/loss = 0.6597774624824524, train/raw-loss = 0.6365760564804077, train/logprobs = tensor([[-0.6496, -1.4108],
        [-0.8343, -1.2616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09280569106340408
Epoch 0, Step 391: train/loss = 0.6390061378479004, train/raw-loss = 0.6037200689315796, train/logprobs = tensor([[-0.9680, -1.8519],
        [-1.0403, -1.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1411443054676056
Epoch 0, Step 392: train/loss = 0.6537357568740845, train/raw-loss = 0.6217990517616272, train/logprobs = tensor([[-0.9899, -1.4122],
        [-1.0408, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12774671614170074
Epoch 0, Step 393: train/loss = 0.5978987216949463, train/raw-loss = 0.5637710094451904, train/logprobs = tensor([[-1.0211, -1.4557],
        [-1.6072, -1.3981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.136510968208313
Epoch 0, Step 394: train/loss = 0.5423353910446167, train/raw-loss = 0.4953179657459259, train/logprobs = tensor([[-1.8726, -2.6592],
        [-2.2166, -1.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18806985020637512
Epoch 0, Step 395: train/loss = 0.6648606657981873, train/raw-loss = 0.6432187557220459, train/logprobs = tensor([[-0.6051, -0.7175],
        [-0.6098, -0.5074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08656762540340424
Epoch 0, Step 396: train/loss = 0.6676896214485168, train/raw-loss = 0.6416627764701843, train/logprobs = tensor([[-0.8483, -1.0523],
        [-0.8298, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10410743951797485
Epoch 0, Step 397: train/loss = 0.6775557994842529, train/raw-loss = 0.6554935574531555, train/logprobs = tensor([[-0.4859, -0.8097],
        [-0.4987, -0.6593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08824895322322845
Epoch 0, Step 398: train/loss = 0.6283609867095947, train/raw-loss = 0.595626711845398, train/logprobs = tensor([[-0.7856, -1.3947],
        [-0.9965, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13093699514865875
Epoch 0, Step 399: train/loss = 0.7326231002807617, train/raw-loss = 0.7067739963531494, train/logprobs = tensor([[-1.0034, -0.7598],
        [-1.0308, -0.8269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10339657962322235
Epoch 0, Step 400: train/loss = 0.6289717555046082, train/raw-loss = 0.5943100452423096, train/logprobs = tensor([[-1.4960, -3.1885],
        [-1.0110, -1.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13864673674106598
Epoch 0, Step 401: train/loss = 0.7791681885719299, train/raw-loss = 0.7449744939804077, train/logprobs = tensor([[-1.4937, -1.7024],
        [-1.8520, -2.1453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13677459955215454
Epoch 0, Step 402: train/loss = 0.6407013535499573, train/raw-loss = 0.6059521436691284, train/logprobs = tensor([[-1.1897, -1.7174],
        [-1.2215, -1.3332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13899682462215424
Epoch 0, Step 403: train/loss = 0.6418606042861938, train/raw-loss = 0.6156775951385498, train/logprobs = tensor([[-0.9632, -1.5474],
        [-1.1085, -1.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10473211854696274
Epoch 0, Step 404: train/loss = 0.6606919765472412, train/raw-loss = 0.6282524466514587, train/logprobs = tensor([[-1.2304, -1.3678],
        [-1.2887, -1.1395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12975822389125824
Epoch 0, Step 405: train/loss = 0.694232165813446, train/raw-loss = 0.678199827671051, train/logprobs = tensor([[-0.5507, -0.4395],
        [-0.5870, -0.4150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06412918120622635
Epoch 0, Step 406: train/loss = 0.6531021595001221, train/raw-loss = 0.618930459022522, train/logprobs = tensor([[-0.9726, -1.1541],
        [-1.2320, -1.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13668662309646606
Epoch 0, Step 407: train/loss = 0.667088508605957, train/raw-loss = 0.6394128799438477, train/logprobs = tensor([[-1.0922, -1.2888],
        [-1.0883, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11070257425308228
Epoch 0, Step 408: train/loss = 0.6675578355789185, train/raw-loss = 0.6337337493896484, train/logprobs = tensor([[-0.9338, -1.3012],
        [-1.0599, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1352960467338562
Epoch 0, Step 409: train/loss = 0.6554268598556519, train/raw-loss = 0.6199185848236084, train/logprobs = tensor([[-1.1609, -1.0290],
        [-1.3627, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14203304052352905
Epoch 0, Step 410: train/loss = 0.6343410015106201, train/raw-loss = 0.608451247215271, train/logprobs = tensor([[-1.4140, -1.0071],
        [-1.7138, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10355876386165619
Epoch 0, Step 411: train/loss = 0.767573893070221, train/raw-loss = 0.7390785217285156, train/logprobs = tensor([[-0.8641, -1.0649],
        [-1.1880, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11398136615753174
Epoch 0, Step 412: train/loss = 0.6780581474304199, train/raw-loss = 0.6436752080917358, train/logprobs = tensor([[-1.4877, -1.7316],
        [-1.6681, -1.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1375318318605423
Epoch 0, Step 413: train/loss = 0.6746485233306885, train/raw-loss = 0.6542917490005493, train/logprobs = tensor([[-1.0962, -1.7319],
        [-1.0931, -1.5517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.081427201628685
Epoch 0, Step 414: train/loss = 0.6772436499595642, train/raw-loss = 0.6529744267463684, train/logprobs = tensor([[-0.6599, -1.0369],
        [-0.7218, -0.9326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09707675874233246
Epoch 0, Step 415: train/loss = 0.6643167734146118, train/raw-loss = 0.6329448223114014, train/logprobs = tensor([[-1.1675, -1.3133],
        [-1.2865, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1254880130290985
Epoch 0, Step 416: train/loss = 0.6881916522979736, train/raw-loss = 0.6606175899505615, train/logprobs = tensor([[-0.9025, -0.6741],
        [-0.9070, -0.5414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11029660701751709
Epoch 0, Step 417: train/loss = 0.5026798248291016, train/raw-loss = 0.4742986261844635, train/logprobs = tensor([[-1.0059, -2.3308],
        [-1.3204, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11352488398551941
Epoch 0, Step 418: train/loss = 0.6728386282920837, train/raw-loss = 0.6477714776992798, train/logprobs = tensor([[-0.6214, -0.8681],
        [-0.6454, -0.6989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10026848316192627
Epoch 0, Step 419: train/loss = 0.5856414437294006, train/raw-loss = 0.554462730884552, train/logprobs = tensor([[-1.0400, -2.1682],
        [-1.0631, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12471474707126617
Epoch 0, Step 420: train/loss = 0.6539496779441833, train/raw-loss = 0.6280872821807861, train/logprobs = tensor([[-0.6797, -1.0084],
        [-0.7976, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10344962775707245
Epoch 0, Step 421: train/loss = 0.6587889194488525, train/raw-loss = 0.6349964141845703, train/logprobs = tensor([[-0.8616, -1.4452],
        [-1.1722, -1.4483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09516996145248413
Epoch 0, Step 422: train/loss = 0.4711753726005554, train/raw-loss = 0.4371824264526367, train/logprobs = tensor([[-1.8995, -2.6960],
        [-2.6658, -1.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13597172498703003
Epoch 0, Step 423: train/loss = 0.6951086521148682, train/raw-loss = 0.6709519624710083, train/logprobs = tensor([[-0.6894, -1.3633],
        [-0.5625, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0966269001364708
Epoch 0, Step 424: train/loss = 0.5933454036712646, train/raw-loss = 0.5651933550834656, train/logprobs = tensor([[-1.2850, -1.4836],
        [-1.3920, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11260828375816345
Epoch 0, Step 425: train/loss = 0.7021299600601196, train/raw-loss = 0.6783567667007446, train/logprobs = tensor([[-1.2015, -1.0298],
        [-1.1823, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09509274363517761
Epoch 0, Step 426: train/loss = 0.6809031367301941, train/raw-loss = 0.6506190896034241, train/logprobs = tensor([[-1.0355, -1.4260],
        [-0.9932, -1.1904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12113616615533829
Epoch 0, Step 427: train/loss = 0.6212719678878784, train/raw-loss = 0.5963782072067261, train/logprobs = tensor([[-0.7946, -2.0271],
        [-0.7331, -1.0336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0995749682188034
Epoch 0, Step 428: train/loss = 0.6542482376098633, train/raw-loss = 0.6208305358886719, train/logprobs = tensor([[-1.1188, -1.1257],
        [-1.3134, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13367080688476562
Epoch 0, Step 429: train/loss = 0.6704587340354919, train/raw-loss = 0.6447246074676514, train/logprobs = tensor([[-1.0466, -1.4254],
        [-1.0642, -1.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10293655842542648
Epoch 0, Step 430: train/loss = 0.680208683013916, train/raw-loss = 0.6439751386642456, train/logprobs = tensor([[-1.2833, -1.8556],
        [-1.2313, -1.5686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14493423700332642
Epoch 0, Step 431: train/loss = 0.6651320457458496, train/raw-loss = 0.6416523456573486, train/logprobs = tensor([[-0.7463, -0.8717],
        [-0.7017, -0.5906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09391899406909943
Epoch 0, Step 432: train/loss = 0.6626825928688049, train/raw-loss = 0.6357801556587219, train/logprobs = tensor([[-1.2255, -1.4332],
        [-1.8552, -1.6408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10760955512523651
Epoch 0, Step 433: train/loss = 0.5963782668113708, train/raw-loss = 0.5561447143554688, train/logprobs = tensor([[-1.3467, -1.9957],
        [-1.7177, -1.6229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16093409061431885
Epoch 0, Step 434: train/loss = 0.6244913339614868, train/raw-loss = 0.5940349102020264, train/logprobs = tensor([[-0.9461, -1.2214],
        [-1.1305, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12182551622390747
Epoch 0, Step 435: train/loss = 0.5554038286209106, train/raw-loss = 0.5166711807250977, train/logprobs = tensor([[-1.4576, -1.9216],
        [-1.9896, -1.4677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15493062138557434
Epoch 0, Step 436: train/loss = 0.7101579308509827, train/raw-loss = 0.676073431968689, train/logprobs = tensor([[-1.3102, -1.5062],
        [-1.3184, -1.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13633781671524048
Epoch 0, Step 437: train/loss = 0.7706680297851562, train/raw-loss = 0.7366708517074585, train/logprobs = tensor([[-1.8219, -1.2995],
        [-1.4662, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359885334968567
Epoch 0, Step 438: train/loss = 0.6885316967964172, train/raw-loss = 0.6665652990341187, train/logprobs = tensor([[-0.6582, -0.7876],
        [-0.5257, -0.5330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0878656804561615
Epoch 0, Step 439: train/loss = 0.7337960600852966, train/raw-loss = 0.7084554433822632, train/logprobs = tensor([[-0.6643, -0.8364],
        [-1.1175, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10136260837316513
Epoch 0, Step 440: train/loss = 0.7274203300476074, train/raw-loss = 0.7047735452651978, train/logprobs = tensor([[-1.1097, -0.8593],
        [-0.8957, -0.6609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09058722853660583
Epoch 0, Step 441: train/loss = 0.5788447856903076, train/raw-loss = 0.5483893156051636, train/logprobs = tensor([[-0.8598, -2.1140],
        [-0.8671, -1.3994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12182173877954483
Epoch 0, Step 442: train/loss = 0.6622352600097656, train/raw-loss = 0.629523754119873, train/logprobs = tensor([[-1.1054, -1.6403],
        [-1.1058, -1.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13084615767002106
Epoch 0, Step 443: train/loss = 0.6654014587402344, train/raw-loss = 0.6359055042266846, train/logprobs = tensor([[-1.0876, -1.1015],
        [-1.2551, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11798378825187683
Epoch 0, Step 444: train/loss = 0.7264208197593689, train/raw-loss = 0.696174681186676, train/logprobs = tensor([[-0.8680, -1.0716],
        [-0.8170, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12098442018032074
Epoch 0, Step 445: train/loss = 0.6239129304885864, train/raw-loss = 0.5847314596176147, train/logprobs = tensor([[-0.9782, -1.4039],
        [-1.2256, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15672606229782104
Epoch 0, Step 446: train/loss = 0.7298016548156738, train/raw-loss = 0.6884713172912598, train/logprobs = tensor([[-1.3522, -1.4131],
        [-1.1753, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16532127559185028
Epoch 0, Step 447: train/loss = 0.60263592004776, train/raw-loss = 0.5753048658370972, train/logprobs = tensor([[-1.1873, -1.6513],
        [-1.1708, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10932415723800659
Epoch 0, Step 448: train/loss = 0.6887093782424927, train/raw-loss = 0.6658133864402771, train/logprobs = tensor([[-0.8334, -1.1515],
        [-0.6662, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0915839672088623
Epoch 0, Step 449: train/loss = 0.558803915977478, train/raw-loss = 0.5227551460266113, train/logprobs = tensor([[-1.5991, -2.4103],
        [-1.7758, -1.4926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14419499039649963
Epoch 0, Step 450: train/loss = 0.6574714183807373, train/raw-loss = 0.6233794093132019, train/logprobs = tensor([[-1.3420, -1.7744],
        [-1.0888, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13636815547943115
Epoch 0, Step 451: train/loss = 0.6178805828094482, train/raw-loss = 0.5839098691940308, train/logprobs = tensor([[-1.2867, -1.9641],
        [-1.4031, -1.5400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13588303327560425
Epoch 0, Step 452: train/loss = 0.5299025774002075, train/raw-loss = 0.497683584690094, train/logprobs = tensor([[-1.0745, -2.3107],
        [-1.0203, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12887585163116455
Epoch 0, Step 453: train/loss = 0.6036598086357117, train/raw-loss = 0.5715184807777405, train/logprobs = tensor([[-1.4892, -2.2862],
        [-1.5009, -1.5281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12856526672840118
Epoch 0, Step 454: train/loss = 0.6940633058547974, train/raw-loss = 0.6524618864059448, train/logprobs = tensor([[-1.2420, -1.4644],
        [-1.1954, -1.2213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16640549898147583
Epoch 0, Step 455: train/loss = 0.560785710811615, train/raw-loss = 0.5310760140419006, train/logprobs = tensor([[-0.8374, -2.2200],
        [-0.6595, -1.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11883881688117981
Epoch 0, Step 456: train/loss = 0.7010756731033325, train/raw-loss = 0.6720055341720581, train/logprobs = tensor([[-0.8898, -1.1743],
        [-0.9946, -1.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11628066748380661
Epoch 0, Step 457: train/loss = 0.6871209740638733, train/raw-loss = 0.6618008613586426, train/logprobs = tensor([[-1.0143, -0.8326],
        [-1.0256, -0.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10128070414066315
Epoch 0, Step 458: train/loss = 0.6327289342880249, train/raw-loss = 0.5827590227127075, train/logprobs = tensor([[-1.4488, -1.7373],
        [-2.1314, -1.7927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19987964630126953
Epoch 0, Step 459: train/loss = 0.5750200152397156, train/raw-loss = 0.5457276105880737, train/logprobs = tensor([[-1.1050, -2.1305],
        [-0.9969, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11716985702514648
Epoch 0, Step 460: train/loss = 0.6809165477752686, train/raw-loss = 0.6507279872894287, train/logprobs = tensor([[-0.9651, -1.2633],
        [-0.9683, -1.0841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1207544356584549
Epoch 0, Step 461: train/loss = 0.675269603729248, train/raw-loss = 0.6396506428718567, train/logprobs = tensor([[-1.7386, -2.5257],
        [-1.3203, -1.7302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1424759179353714
Epoch 0, Step 462: train/loss = 0.7429201006889343, train/raw-loss = 0.7009655237197876, train/logprobs = tensor([[-1.4208, -2.0596],
        [-1.5989, -1.8760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16781805455684662
Epoch 0, Step 463: train/loss = 0.606224000453949, train/raw-loss = 0.5768206119537354, train/logprobs = tensor([[-1.4389, -1.2531],
        [-1.8977, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11761380732059479
Epoch 0, Step 464: train/loss = 0.5804533958435059, train/raw-loss = 0.5464950799942017, train/logprobs = tensor([[-0.6011, -2.2432],
        [-0.7596, -1.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13583317399024963
Epoch 0, Step 465: train/loss = 0.5796507596969604, train/raw-loss = 0.5417959094047546, train/logprobs = tensor([[-1.2494, -2.1954],
        [-1.2672, -1.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15141941606998444
Epoch 0, Step 466: train/loss = 0.5526357293128967, train/raw-loss = 0.5147730708122253, train/logprobs = tensor([[-1.6954, -3.0359],
        [-1.5744, -1.8578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1514507234096527
Epoch 0, Step 467: train/loss = 0.6428259611129761, train/raw-loss = 0.61103755235672, train/logprobs = tensor([[-0.8972, -2.0236],
        [-1.0034, -1.7499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12715353071689606
Epoch 0, Step 468: train/loss = 0.5436208844184875, train/raw-loss = 0.5186219215393066, train/logprobs = tensor([[-0.6922, -2.6952],
        [-0.5387, -1.4800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0999956727027893
Epoch 0, Step 469: train/loss = 0.6339966654777527, train/raw-loss = 0.5892572402954102, train/logprobs = tensor([[-1.3302, -1.3163],
        [-1.5746, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17895764112472534
Epoch 0, Step 470: train/loss = 0.5902891159057617, train/raw-loss = 0.5595571994781494, train/logprobs = tensor([[-1.0045, -1.9203],
        [-1.6211, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12292792648077011
Epoch 0, Step 471: train/loss = 0.6364893913269043, train/raw-loss = 0.5958234667778015, train/logprobs = tensor([[-1.4240, -1.8610],
        [-1.6892, -1.6711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.162663534283638
Epoch 0, Step 472: train/loss = 0.7045983672142029, train/raw-loss = 0.6728291511535645, train/logprobs = tensor([[-0.9516, -1.1285],
        [-0.8741, -0.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12707701325416565
Epoch 0, Step 473: train/loss = 0.5671209692955017, train/raw-loss = 0.5358023047447205, train/logprobs = tensor([[-0.9427, -1.7424],
        [-1.0070, -1.0481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252746433019638
Epoch 0, Step 474: train/loss = 0.5119664072990417, train/raw-loss = 0.4765319526195526, train/logprobs = tensor([[-1.3623, -2.7555],
        [-1.5804, -1.5623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417376697063446
Epoch 0, Step 475: train/loss = 0.7971066832542419, train/raw-loss = 0.7581987380981445, train/logprobs = tensor([[-1.4318, -2.3035],
        [-1.3002, -2.2272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15563160181045532
Epoch 0, Step 476: train/loss = 0.6089771389961243, train/raw-loss = 0.5758851766586304, train/logprobs = tensor([[-1.2028, -1.8759],
        [-1.1508, -1.1605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1323677897453308
Epoch 0, Step 477: train/loss = 0.6214950680732727, train/raw-loss = 0.5918144583702087, train/logprobs = tensor([[-0.8947, -1.7111],
        [-0.7859, -1.1114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11872248351573944
Epoch 0, Step 478: train/loss = 0.7450459599494934, train/raw-loss = 0.7151837348937988, train/logprobs = tensor([[-1.2677, -1.2340],
        [-1.6991, -1.5526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11944887787103653
Epoch 0, Step 479: train/loss = 0.6961532235145569, train/raw-loss = 0.6541206240653992, train/logprobs = tensor([[-1.5654, -1.5062],
        [-1.4844, -1.2430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1681305319070816
Epoch 0, Step 480: train/loss = 0.6473536491394043, train/raw-loss = 0.6206950545310974, train/logprobs = tensor([[-1.7034, -2.9429],
        [-1.1872, -1.7366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10663444548845291
Epoch 0, Step 481: train/loss = 0.6918014287948608, train/raw-loss = 0.6438395977020264, train/logprobs = tensor([[-1.3366, -1.7464],
        [-1.5649, -1.5395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.191847562789917
Epoch 0, Step 482: train/loss = 0.6319653987884521, train/raw-loss = 0.5810055732727051, train/logprobs = tensor([[-1.5944, -1.8342],
        [-1.7369, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2038392275571823
Epoch 0, Step 483: train/loss = 0.7096099257469177, train/raw-loss = 0.6764177083969116, train/logprobs = tensor([[-1.3336, -1.2601],
        [-1.4505, -1.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13276910781860352
Epoch 0, Step 484: train/loss = 0.6670240163803101, train/raw-loss = 0.6276079416275024, train/logprobs = tensor([[-0.9193, -1.7978],
        [-0.9951, -1.5621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1576644480228424
Epoch 0, Step 485: train/loss = 0.6961239576339722, train/raw-loss = 0.6555612683296204, train/logprobs = tensor([[-2.1058, -2.3863],
        [-1.7999, -1.4734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16225044429302216
Epoch 0, Step 486: train/loss = 0.5764750838279724, train/raw-loss = 0.5349858403205872, train/logprobs = tensor([[-1.4443, -3.0444],
        [-1.3901, -2.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16595706343650818
Epoch 0, Step 487: train/loss = 0.6195735931396484, train/raw-loss = 0.5847817063331604, train/logprobs = tensor([[-1.3709, -2.1591],
        [-1.5785, -1.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13916736841201782
Epoch 0, Step 488: train/loss = 0.501765787601471, train/raw-loss = 0.45218130946159363, train/logprobs = tensor([[-1.4721, -2.1787],
        [-3.1573, -2.1263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.198338121175766
Epoch 0, Step 489: train/loss = 0.6754263043403625, train/raw-loss = 0.6360896229743958, train/logprobs = tensor([[-1.5540, -1.9795],
        [-1.0622, -0.9948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15734688937664032
Epoch 0, Step 490: train/loss = 0.5985206365585327, train/raw-loss = 0.5496141910552979, train/logprobs = tensor([[-1.8449, -2.2069],
        [-2.5430, -2.0176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1956261396408081
Epoch 0, Step 491: train/loss = 0.5263928771018982, train/raw-loss = 0.49793416261672974, train/logprobs = tensor([[-0.5395, -3.1068],
        [-0.4618, -1.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11383481323719025
Epoch 0, Step 492: train/loss = 0.6267654895782471, train/raw-loss = 0.5860621929168701, train/logprobs = tensor([[-1.1390, -1.8092],
        [-1.3525, -1.4360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1628130078315735
Epoch 0, Step 493: train/loss = 0.6787824630737305, train/raw-loss = 0.6411681771278381, train/logprobs = tensor([[-1.0414, -1.1750],
        [-1.0266, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1504570096731186
Epoch 0, Step 494: train/loss = 0.46488624811172485, train/raw-loss = 0.42883992195129395, train/logprobs = tensor([[-0.9939, -2.9751],
        [-1.1228, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1441851556301117
Epoch 0, Step 495: train/loss = 0.6111112833023071, train/raw-loss = 0.561197817325592, train/logprobs = tensor([[-1.4235, -2.7332],
        [-1.4452, -1.6984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1996539831161499
Epoch 0, Step 496: train/loss = 0.7669441103935242, train/raw-loss = 0.7232763767242432, train/logprobs = tensor([[-1.5031, -1.0974],
        [-1.2070, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17467090487480164
Epoch 0, Step 497: train/loss = 0.560809314250946, train/raw-loss = 0.5180705189704895, train/logprobs = tensor([[-1.0408, -2.4509],
        [-0.9915, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17095518112182617
Epoch 0, Step 498: train/loss = 0.6987478137016296, train/raw-loss = 0.662070095539093, train/logprobs = tensor([[-1.0689, -1.3604],
        [-0.8162, -0.9257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14671075344085693
Epoch 0, Step 499: train/loss = 0.733697772026062, train/raw-loss = 0.6856896877288818, train/logprobs = tensor([[-1.4675, -1.3321],
        [-1.6800, -1.4897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19203227758407593
eval/loss: 0.6411777138710022
Epoch 0, Step 500: train/loss = 0.5673877000808716, train/raw-loss = 0.5296404957771301, train/logprobs = tensor([[-1.4654, -2.5800],
        [-2.1601, -2.2590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15098893642425537
Epoch 0, Step 501: train/loss = 0.7920256853103638, train/raw-loss = 0.7458542585372925, train/logprobs = tensor([[-2.2330, -1.7286],
        [-2.1029, -1.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18468543887138367
Epoch 0, Step 502: train/loss = 0.6726775169372559, train/raw-loss = 0.6153326630592346, train/logprobs = tensor([[-1.7220, -1.9287],
        [-1.6732, -1.5153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2293795943260193
Epoch 0, Step 503: train/loss = 0.6937953233718872, train/raw-loss = 0.657558798789978, train/logprobs = tensor([[-1.2454, -1.6458],
        [-0.9463, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14494623243808746
Epoch 0, Step 504: train/loss = 0.6646342277526855, train/raw-loss = 0.6190149784088135, train/logprobs = tensor([[-2.0396, -2.8707],
        [-1.4418, -1.4337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824769675731659
Epoch 0, Step 505: train/loss = 0.7131093144416809, train/raw-loss = 0.6653605699539185, train/logprobs = tensor([[-1.2751, -2.3347],
        [-1.2390, -2.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19099512696266174
Epoch 0, Step 506: train/loss = 0.7739923000335693, train/raw-loss = 0.7275588512420654, train/logprobs = tensor([[-1.3328, -2.0952],
        [-1.2376, -1.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18573378026485443
Epoch 0, Step 507: train/loss = 0.512779712677002, train/raw-loss = 0.45000046491622925, train/logprobs = tensor([[-2.6860, -4.7138],
        [-2.8686, -2.2343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2511170506477356
Epoch 0, Step 508: train/loss = 0.6215344071388245, train/raw-loss = 0.5840960144996643, train/logprobs = tensor([[-1.0623, -1.7406],
        [-1.0696, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1497534066438675
Epoch 0, Step 509: train/loss = 0.6761994957923889, train/raw-loss = 0.6497832536697388, train/logprobs = tensor([[-0.5751, -0.6817],
        [-0.5743, -0.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10566490888595581
Epoch 0, Step 510: train/loss = 0.6741935610771179, train/raw-loss = 0.6308537721633911, train/logprobs = tensor([[-1.3194, -1.8783],
        [-1.2622, -1.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17335912585258484
Epoch 0, Step 511: train/loss = 0.777846097946167, train/raw-loss = 0.7350202202796936, train/logprobs = tensor([[-1.6153, -1.3856],
        [-2.3335, -1.8720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17130360007286072
Epoch 0, Step 512: train/loss = 0.5855323076248169, train/raw-loss = 0.5404618978500366, train/logprobs = tensor([[-1.2884, -2.0823],
        [-1.6906, -1.7240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18028149008750916
Epoch 0, Step 513: train/loss = 0.5535227656364441, train/raw-loss = 0.5128254890441895, train/logprobs = tensor([[-1.0073, -1.9958],
        [-1.1887, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1627892255783081
Epoch 0, Step 514: train/loss = 0.6774123907089233, train/raw-loss = 0.628825306892395, train/logprobs = tensor([[-1.4274, -2.3383],
        [-1.0732, -1.5857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19434860348701477
Epoch 0, Step 515: train/loss = 0.6360949277877808, train/raw-loss = 0.5892224907875061, train/logprobs = tensor([[-1.5965, -2.0703],
        [-1.4996, -1.3179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18748976290225983
Epoch 0, Step 516: train/loss = 0.7230774760246277, train/raw-loss = 0.6869615912437439, train/logprobs = tensor([[-1.0653, -1.4159],
        [-0.6745, -0.9137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14446362853050232
Epoch 0, Step 517: train/loss = 0.6676346659660339, train/raw-loss = 0.621658444404602, train/logprobs = tensor([[-1.0796, -1.8581],
        [-1.0614, -1.4726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18390481173992157
Epoch 0, Step 518: train/loss = 0.6890591382980347, train/raw-loss = 0.6379712820053101, train/logprobs = tensor([[-2.3670, -2.7113],
        [-2.0004, -2.0035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20435139536857605
Epoch 0, Step 519: train/loss = 0.6410810947418213, train/raw-loss = 0.5940005779266357, train/logprobs = tensor([[-1.1722, -1.7229],
        [-1.2873, -1.3308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1883222907781601
Epoch 0, Step 520: train/loss = 0.6201109290122986, train/raw-loss = 0.58111971616745, train/logprobs = tensor([[-0.8521, -1.3206],
        [-0.8925, -0.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15596488118171692
Epoch 0, Step 521: train/loss = 0.7345945835113525, train/raw-loss = 0.7012770175933838, train/logprobs = tensor([[-0.9997, -0.9312],
        [-0.7972, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13327011466026306
Epoch 0, Step 522: train/loss = 0.5384854078292847, train/raw-loss = 0.49202650785446167, train/logprobs = tensor([[-2.2783, -4.4300],
        [-2.9657, -3.6845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18583562970161438
Epoch 0, Step 523: train/loss = 0.6303784251213074, train/raw-loss = 0.578874945640564, train/logprobs = tensor([[-1.6091, -2.3687],
        [-1.4872, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20601388812065125
Epoch 0, Step 524: train/loss = 0.6561932563781738, train/raw-loss = 0.6244184374809265, train/logprobs = tensor([[-0.8139, -1.8360],
        [-0.7786, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12709940969944
Epoch 0, Step 525: train/loss = 0.6532111167907715, train/raw-loss = 0.610260546207428, train/logprobs = tensor([[-1.5464, -2.5528],
        [-1.0775, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17180246114730835
Epoch 0, Step 526: train/loss = 0.6060155630111694, train/raw-loss = 0.566506028175354, train/logprobs = tensor([[-1.2726, -1.9418],
        [-1.1577, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803836286067963
Epoch 0, Step 527: train/loss = 0.924723207950592, train/raw-loss = 0.8733428120613098, train/logprobs = tensor([[-2.2866, -2.0618],
        [-1.3733, -1.5273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20552153885364532
Epoch 0, Step 528: train/loss = 0.5393317937850952, train/raw-loss = 0.4983060359954834, train/logprobs = tensor([[-1.3579, -2.0006],
        [-1.6640, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16410285234451294
Epoch 0, Step 529: train/loss = 0.4757283627986908, train/raw-loss = 0.43292513489723206, train/logprobs = tensor([[-1.1493, -2.5854],
        [-1.8080, -1.4917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17121291160583496
Epoch 0, Step 530: train/loss = 0.655505895614624, train/raw-loss = 0.6229239106178284, train/logprobs = tensor([[-0.8190, -1.4174],
        [-0.8945, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13032786548137665
Epoch 0, Step 531: train/loss = 0.7062124013900757, train/raw-loss = 0.664808988571167, train/logprobs = tensor([[-0.9026, -1.4338],
        [-0.9188, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16561365127563477
Epoch 0, Step 532: train/loss = 0.7210994958877563, train/raw-loss = 0.6713020205497742, train/logprobs = tensor([[-1.1061, -1.2847],
        [-1.0302, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19919010996818542
Epoch 0, Step 533: train/loss = 0.6083095073699951, train/raw-loss = 0.5674083232879639, train/logprobs = tensor([[-1.7918, -2.9905],
        [-1.6661, -1.6318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16360463201999664
Epoch 0, Step 534: train/loss = 0.7451181411743164, train/raw-loss = 0.678651750087738, train/logprobs = tensor([[-2.8196, -2.5845],
        [-2.6104, -2.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2658654749393463
Epoch 0, Step 535: train/loss = 0.611278235912323, train/raw-loss = 0.576692521572113, train/logprobs = tensor([[-1.0001, -1.6227],
        [-1.0162, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383427381515503
Epoch 0, Step 536: train/loss = 0.6932328343391418, train/raw-loss = 0.6476101279258728, train/logprobs = tensor([[-2.1391, -1.9545],
        [-2.1016, -1.7174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18249064683914185
Epoch 0, Step 537: train/loss = 0.6502429246902466, train/raw-loss = 0.6155080795288086, train/logprobs = tensor([[-1.3558, -1.6336],
        [-1.2362, -0.9587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13893939554691315
Epoch 0, Step 538: train/loss = 0.6643660664558411, train/raw-loss = 0.6206263303756714, train/logprobs = tensor([[-1.0832, -1.7409],
        [-1.0165, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1749589443206787
Epoch 0, Step 539: train/loss = 0.5061450004577637, train/raw-loss = 0.468852698802948, train/logprobs = tensor([[-1.6990, -2.5145],
        [-1.9104, -1.4940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14916932582855225
Epoch 0, Step 540: train/loss = 0.655200719833374, train/raw-loss = 0.6209609508514404, train/logprobs = tensor([[-1.2545, -2.5495],
        [-1.3362, -2.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13695909082889557
Epoch 0, Step 541: train/loss = 0.6121869087219238, train/raw-loss = 0.5737384557723999, train/logprobs = tensor([[-1.7334, -2.6074],
        [-1.4205, -1.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15379370748996735
Epoch 0, Step 542: train/loss = 0.5210742354393005, train/raw-loss = 0.47652319073677063, train/logprobs = tensor([[-1.0481, -2.7205],
        [-1.1953, -1.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17820414900779724
Epoch 0, Step 543: train/loss = 0.563391387462616, train/raw-loss = 0.5261711478233337, train/logprobs = tensor([[-0.9229, -1.8310],
        [-1.0885, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14888107776641846
Epoch 0, Step 544: train/loss = 0.5532677173614502, train/raw-loss = 0.504540205001831, train/logprobs = tensor([[-1.8078, -2.3279],
        [-1.7973, -1.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1949102282524109
Epoch 0, Step 545: train/loss = 0.6675868034362793, train/raw-loss = 0.6243588924407959, train/logprobs = tensor([[-1.1597, -2.0635],
        [-1.0025, -1.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1729116141796112
Epoch 0, Step 546: train/loss = 0.573509931564331, train/raw-loss = 0.5293383598327637, train/logprobs = tensor([[-1.2907, -1.7409],
        [-1.7895, -1.3138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17668625712394714
Epoch 0, Step 547: train/loss = 0.7203909158706665, train/raw-loss = 0.6796396970748901, train/logprobs = tensor([[-1.4269, -1.4883],
        [-1.4798, -1.4267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16300517320632935
Epoch 0, Step 548: train/loss = 0.8407841920852661, train/raw-loss = 0.7927250862121582, train/logprobs = tensor([[-2.1328, -2.2310],
        [-1.4082, -1.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1922365427017212
Epoch 0, Step 549: train/loss = 0.6862739324569702, train/raw-loss = 0.63341224193573, train/logprobs = tensor([[-1.8537, -2.1063],
        [-1.9760, -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21144670248031616
Epoch 0, Step 550: train/loss = 0.5791362524032593, train/raw-loss = 0.5247231125831604, train/logprobs = tensor([[-2.0022, -2.9065],
        [-2.3597, -2.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21765263378620148
Epoch 0, Step 551: train/loss = 0.7335224747657776, train/raw-loss = 0.6868592500686646, train/logprobs = tensor([[-1.8462, -2.3272],
        [-1.4831, -1.8663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18665270507335663
Epoch 0, Step 552: train/loss = 0.5930678844451904, train/raw-loss = 0.5426452159881592, train/logprobs = tensor([[-1.7084, -3.5268],
        [-1.5684, -2.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20169055461883545
Epoch 0, Step 553: train/loss = 0.7260923385620117, train/raw-loss = 0.6841676831245422, train/logprobs = tensor([[-1.2760, -1.7071],
        [-1.2171, -1.5989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16769884526729584
Epoch 0, Step 554: train/loss = 0.6368043422698975, train/raw-loss = 0.5872163772583008, train/logprobs = tensor([[-1.8496, -1.4673],
        [-1.9492, -1.0845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19835181534290314
Epoch 0, Step 555: train/loss = 0.6865905523300171, train/raw-loss = 0.6355931758880615, train/logprobs = tensor([[-1.8835, -2.3445],
        [-1.5686, -1.6205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20398971438407898
Epoch 0, Step 556: train/loss = 0.6690363883972168, train/raw-loss = 0.6289907693862915, train/logprobs = tensor([[-1.9134, -2.1809],
        [-1.8585, -1.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16018235683441162
Epoch 0, Step 557: train/loss = 0.6104695796966553, train/raw-loss = 0.5766574144363403, train/logprobs = tensor([[-2.7060, -3.2612],
        [-2.6042, -2.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13524876534938812
Epoch 0, Step 558: train/loss = 0.7830405235290527, train/raw-loss = 0.7397580146789551, train/logprobs = tensor([[-2.4826, -2.3671],
        [-1.8105, -1.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17312997579574585
Epoch 0, Step 559: train/loss = 0.733758807182312, train/raw-loss = 0.6879391670227051, train/logprobs = tensor([[-1.7051, -1.8462],
        [-1.3780, -1.3742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18327824771404266
Epoch 0, Step 560: train/loss = 0.4525725841522217, train/raw-loss = 0.4094352126121521, train/logprobs = tensor([[-1.1225, -2.3288],
        [-1.3555, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1725495308637619
Epoch 0, Step 561: train/loss = 0.7117838859558105, train/raw-loss = 0.6705986261367798, train/logprobs = tensor([[-2.7490, -2.8683],
        [-2.6873, -2.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16474077105522156
Epoch 0, Step 562: train/loss = 0.6614969968795776, train/raw-loss = 0.6127866506576538, train/logprobs = tensor([[-1.2263, -2.1381],
        [-1.2549, -1.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19484131038188934
Epoch 0, Step 563: train/loss = 0.7256497144699097, train/raw-loss = 0.6771702170372009, train/logprobs = tensor([[-1.8205, -1.5464],
        [-2.2130, -1.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19391785562038422
Epoch 0, Step 564: train/loss = 0.6508964896202087, train/raw-loss = 0.6059563159942627, train/logprobs = tensor([[-1.2867, -1.8816],
        [-1.1092, -1.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17976069450378418
Epoch 0, Step 565: train/loss = 0.5629579424858093, train/raw-loss = 0.5113061666488647, train/logprobs = tensor([[-2.0999, -2.5795],
        [-2.5188, -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20660723745822906
Epoch 0, Step 566: train/loss = 0.7197550535202026, train/raw-loss = 0.6634935736656189, train/logprobs = tensor([[-1.7843, -1.8580],
        [-1.8962, -1.7471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22504618763923645
Epoch 0, Step 567: train/loss = 0.6579219102859497, train/raw-loss = 0.6054985523223877, train/logprobs = tensor([[-1.9083, -2.3502],
        [-2.7670, -2.5902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20969319343566895
Epoch 0, Step 568: train/loss = 0.5445951223373413, train/raw-loss = 0.49233847856521606, train/logprobs = tensor([[-1.4975, -2.5861],
        [-1.6878, -1.7998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20902657508850098
Epoch 0, Step 569: train/loss = 0.6279861927032471, train/raw-loss = 0.5818438529968262, train/logprobs = tensor([[-1.4421, -2.2329],
        [-1.4239, -1.5944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18456915020942688
Epoch 0, Step 570: train/loss = 0.683621346950531, train/raw-loss = 0.6376513242721558, train/logprobs = tensor([[-2.1318, -2.3209],
        [-2.4291, -2.3196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18388009071350098
Epoch 0, Step 571: train/loss = 0.5777018666267395, train/raw-loss = 0.5293529629707336, train/logprobs = tensor([[-1.4844, -2.1401],
        [-1.6224, -1.1977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19339552521705627
Epoch 0, Step 572: train/loss = 0.7203000783920288, train/raw-loss = 0.6830489635467529, train/logprobs = tensor([[-1.5033, -1.3395],
        [-1.2869, -1.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14900465309619904
Epoch 0, Step 573: train/loss = 0.6225711107254028, train/raw-loss = 0.5735841393470764, train/logprobs = tensor([[-1.6222, -2.5972],
        [-1.7153, -2.1646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19594791531562805
Epoch 0, Step 574: train/loss = 0.6996967792510986, train/raw-loss = 0.6503177881240845, train/logprobs = tensor([[-1.5373, -1.5582],
        [-1.6515, -1.4712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1975160837173462
Epoch 0, Step 575: train/loss = 0.5621196031570435, train/raw-loss = 0.5080003142356873, train/logprobs = tensor([[-1.5167, -2.7621],
        [-1.7357, -1.5484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21647724509239197
Epoch 0, Step 576: train/loss = 0.6152142286300659, train/raw-loss = 0.5768635869026184, train/logprobs = tensor([[-1.4037, -1.7190],
        [-1.5101, -1.2034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15340262651443481
Epoch 0, Step 577: train/loss = 0.6351110339164734, train/raw-loss = 0.5870347023010254, train/logprobs = tensor([[-0.6726, -1.3291],
        [-1.1747, -1.2768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.192305326461792
Epoch 0, Step 578: train/loss = 0.5739928483963013, train/raw-loss = 0.541467547416687, train/logprobs = tensor([[-1.1573, -1.8914],
        [-1.3665, -0.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13010095059871674
Epoch 0, Step 579: train/loss = 0.48207706212997437, train/raw-loss = 0.4431282877922058, train/logprobs = tensor([[-0.7725, -2.4453],
        [-1.1099, -0.8534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15579500794410706
Epoch 0, Step 580: train/loss = 0.6043195724487305, train/raw-loss = 0.5530607104301453, train/logprobs = tensor([[-1.0920, -1.6495],
        [-1.3950, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20503555238246918
Epoch 0, Step 581: train/loss = 0.7281185984611511, train/raw-loss = 0.6970840692520142, train/logprobs = tensor([[-0.9866, -0.8427],
        [-0.9011, -0.7611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12413819134235382
Epoch 0, Step 582: train/loss = 0.6147012710571289, train/raw-loss = 0.5777987241744995, train/logprobs = tensor([[-0.9687, -1.8446],
        [-1.0926, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14761027693748474
Epoch 0, Step 583: train/loss = 0.48598530888557434, train/raw-loss = 0.4331648349761963, train/logprobs = tensor([[-1.4238, -2.0770],
        [-2.3651, -1.6988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21128171682357788
Epoch 0, Step 584: train/loss = 0.5738195180892944, train/raw-loss = 0.5284923315048218, train/logprobs = tensor([[-1.2487, -1.6084],
        [-1.4624, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18130874633789062
Epoch 0, Step 585: train/loss = 0.49382150173187256, train/raw-loss = 0.4504159092903137, train/logprobs = tensor([[-0.9137, -2.3527],
        [-1.3402, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1736222207546234
Epoch 0, Step 586: train/loss = 0.6766188144683838, train/raw-loss = 0.6312646865844727, train/logprobs = tensor([[-1.5473, -1.6657],
        [-1.6504, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18141613900661469
Epoch 0, Step 587: train/loss = 0.6239283084869385, train/raw-loss = 0.5722643733024597, train/logprobs = tensor([[-2.6133, -2.4366],
        [-2.4677, -1.6361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20665566623210907
Epoch 0, Step 588: train/loss = 0.5591901540756226, train/raw-loss = 0.5088528394699097, train/logprobs = tensor([[-1.8106, -1.9330],
        [-2.5204, -1.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20134931802749634
Epoch 0, Step 589: train/loss = 0.7220315933227539, train/raw-loss = 0.6574224233627319, train/logprobs = tensor([[-2.1988, -2.1475],
        [-2.2798, -1.9695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2584366500377655
Epoch 0, Step 590: train/loss = 0.7813271284103394, train/raw-loss = 0.7345807552337646, train/logprobs = tensor([[-2.1473, -1.9177],
        [-1.8340, -1.5901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1869855672121048
Epoch 0, Step 591: train/loss = 0.5587436556816101, train/raw-loss = 0.517285168170929, train/logprobs = tensor([[-1.5719, -2.3749],
        [-1.6970, -1.4168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16583383083343506
Epoch 0, Step 592: train/loss = 0.44016772508621216, train/raw-loss = 0.38240525126457214, train/logprobs = tensor([[-1.7370, -2.0153],
        [-2.9240, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23104989528656006
Epoch 0, Step 593: train/loss = 0.6708652973175049, train/raw-loss = 0.6163330078125, train/logprobs = tensor([[-2.1520, -2.3831],
        [-2.9128, -2.6936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2181292176246643
Epoch 0, Step 594: train/loss = 0.5757433176040649, train/raw-loss = 0.5321799516677856, train/logprobs = tensor([[-1.3205, -2.6495],
        [-1.5225, -2.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17425355315208435
Epoch 0, Step 595: train/loss = 0.6334884166717529, train/raw-loss = 0.5828139781951904, train/logprobs = tensor([[-0.7977, -1.3864],
        [-1.1651, -1.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20269782841205597
Epoch 0, Step 596: train/loss = 0.6705812811851501, train/raw-loss = 0.6402429342269897, train/logprobs = tensor([[-0.7310, -0.9293],
        [-0.8304, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12135310471057892
Epoch 0, Step 597: train/loss = 0.5532605648040771, train/raw-loss = 0.5077341198921204, train/logprobs = tensor([[-2.0709, -3.0499],
        [-1.9863, -1.6918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18210560083389282
Epoch 0, Step 598: train/loss = 0.6289762258529663, train/raw-loss = 0.5794355273246765, train/logprobs = tensor([[-1.7368, -2.3778],
        [-1.8130, -1.7282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1981627643108368
Epoch 0, Step 599: train/loss = 0.7563801407814026, train/raw-loss = 0.7175390124320984, train/logprobs = tensor([[-2.2653, -2.5107],
        [-1.9813, -2.2364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1553645133972168
Epoch 0, Step 600: train/loss = 0.671448826789856, train/raw-loss = 0.6320526599884033, train/logprobs = tensor([[-0.7897, -0.9208],
        [-1.0864, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1575845330953598
Epoch 0, Step 601: train/loss = 0.45352286100387573, train/raw-loss = 0.4061610698699951, train/logprobs = tensor([[-1.5571, -2.9560],
        [-2.2924, -1.7014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18944717943668365
Epoch 0, Step 602: train/loss = 0.7467026710510254, train/raw-loss = 0.7065408229827881, train/logprobs = tensor([[-1.1855, -1.6234],
        [-0.6204, -0.8629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16064751148223877
Epoch 0, Step 603: train/loss = 0.5460846424102783, train/raw-loss = 0.49357351660728455, train/logprobs = tensor([[-1.1706, -2.9595],
        [-1.3839, -2.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21004457771778107
Epoch 0, Step 604: train/loss = 0.6962381601333618, train/raw-loss = 0.6459993124008179, train/logprobs = tensor([[-1.7549, -1.5504],
        [-2.2139, -1.6864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20095545053482056
Epoch 0, Step 605: train/loss = 0.7201056480407715, train/raw-loss = 0.6728111505508423, train/logprobs = tensor([[-1.5936, -1.7639],
        [-1.6850, -1.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18917840719223022
Epoch 0, Step 606: train/loss = 0.839511513710022, train/raw-loss = 0.801859974861145, train/logprobs = tensor([[-1.2899, -0.9928],
        [-1.1942, -1.2564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15060624480247498
Epoch 0, Step 607: train/loss = 0.67721027135849, train/raw-loss = 0.6435339450836182, train/logprobs = tensor([[-0.9515, -1.5358],
        [-0.9003, -1.1924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13470526039600372
Epoch 0, Step 608: train/loss = 0.6001739501953125, train/raw-loss = 0.5617351531982422, train/logprobs = tensor([[-1.6852, -2.0353],
        [-2.0873, -1.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15375512838363647
Epoch 0, Step 609: train/loss = 0.5285675525665283, train/raw-loss = 0.48924046754837036, train/logprobs = tensor([[-1.3735, -2.1877],
        [-1.4326, -0.9290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1573084592819214
Epoch 0, Step 610: train/loss = 0.701506495475769, train/raw-loss = 0.6706343293190002, train/logprobs = tensor([[-0.9156, -0.9380],
        [-0.9714, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12348862737417221
Epoch 0, Step 611: train/loss = 0.6258379817008972, train/raw-loss = 0.5823676586151123, train/logprobs = tensor([[-1.4502, -3.6983],
        [-1.3730, -1.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1738813817501068
Epoch 0, Step 612: train/loss = 0.6800724864006042, train/raw-loss = 0.6295427083969116, train/logprobs = tensor([[-2.1547, -2.2742],
        [-2.2696, -2.0266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20211918652057648
Epoch 0, Step 613: train/loss = 0.5289049744606018, train/raw-loss = 0.472592294216156, train/logprobs = tensor([[-1.6651, -3.3973],
        [-1.7662, -2.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22525084018707275
Epoch 0, Step 614: train/loss = 0.661276638507843, train/raw-loss = 0.6227284669876099, train/logprobs = tensor([[-1.0833, -1.0261],
        [-1.2155, -0.7618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541927009820938
Epoch 0, Step 615: train/loss = 0.7235161066055298, train/raw-loss = 0.6730849742889404, train/logprobs = tensor([[-1.1160, -1.4230],
        [-1.1005, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20172441005706787
Epoch 0, Step 616: train/loss = 0.7177723050117493, train/raw-loss = 0.6722548007965088, train/logprobs = tensor([[-1.5188, -1.6264],
        [-1.2293, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18207000195980072
Epoch 0, Step 617: train/loss = 0.6321028470993042, train/raw-loss = 0.5783686637878418, train/logprobs = tensor([[-1.4949, -2.2089],
        [-1.7202, -1.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21493706107139587
Epoch 0, Step 618: train/loss = 0.6128963828086853, train/raw-loss = 0.569678008556366, train/logprobs = tensor([[-1.0123, -1.9550],
        [-1.0643, -1.3355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1728733628988266
Epoch 0, Step 619: train/loss = 0.6515284776687622, train/raw-loss = 0.6117548942565918, train/logprobs = tensor([[-1.7580, -2.2947],
        [-1.5392, -1.6051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15909454226493835
Epoch 0, Step 620: train/loss = 0.634982705116272, train/raw-loss = 0.5900754928588867, train/logprobs = tensor([[-2.0108, -2.3681],
        [-2.1410, -1.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17962892353534698
Epoch 0, Step 621: train/loss = 0.49674296379089355, train/raw-loss = 0.4481911361217499, train/logprobs = tensor([[-2.1295, -3.2577],
        [-3.1973, -2.0180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1942073255777359
Epoch 0, Step 622: train/loss = 0.8976770639419556, train/raw-loss = 0.8409292697906494, train/logprobs = tensor([[-3.1239, -2.8486],
        [-2.6958, -2.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22699111700057983
Epoch 0, Step 623: train/loss = 0.6162539720535278, train/raw-loss = 0.5691323280334473, train/logprobs = tensor([[-1.2134, -1.7861],
        [-1.3240, -1.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18848632276058197
Epoch 0, Step 624: train/loss = 0.6752884984016418, train/raw-loss = 0.6242870092391968, train/logprobs = tensor([[-2.2615, -2.0624],
        [-2.3961, -1.8211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20400568842887878
Epoch 0, Step 625: train/loss = 0.6717873811721802, train/raw-loss = 0.6381336450576782, train/logprobs = tensor([[-0.7892, -1.5526],
        [-0.6536, -1.1433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13461481034755707
Epoch 0, Step 626: train/loss = 0.6319044828414917, train/raw-loss = 0.5796864628791809, train/logprobs = tensor([[-1.6622, -2.0517],
        [-2.1008, -1.4433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20887190103530884
Epoch 0, Step 627: train/loss = 0.5805607438087463, train/raw-loss = 0.5320882797241211, train/logprobs = tensor([[-1.5262, -3.4198],
        [-1.7419, -2.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1938900500535965
Epoch 0, Step 628: train/loss = 0.6772701740264893, train/raw-loss = 0.6166095733642578, train/logprobs = tensor([[-1.7771, -1.7878],
        [-1.8994, -1.5560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24264216423034668
Epoch 0, Step 629: train/loss = 0.6270276308059692, train/raw-loss = 0.5759027004241943, train/logprobs = tensor([[-1.3844, -1.6215],
        [-1.5748, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2044997215270996
Epoch 0, Step 630: train/loss = 0.6493130326271057, train/raw-loss = 0.5902620553970337, train/logprobs = tensor([[-1.5390, -1.9361],
        [-1.9603, -1.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23620399832725525
Epoch 0, Step 631: train/loss = 0.5679836273193359, train/raw-loss = 0.5158447623252869, train/logprobs = tensor([[-1.3444, -2.5341],
        [-1.9447, -2.1187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20855547487735748
Epoch 0, Step 632: train/loss = 0.6964136958122253, train/raw-loss = 0.6536606550216675, train/logprobs = tensor([[-1.1984, -1.4893],
        [-1.1039, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1710120439529419
Epoch 0, Step 633: train/loss = 0.5956151485443115, train/raw-loss = 0.5420993566513062, train/logprobs = tensor([[-2.8950, -2.8101],
        [-3.2031, -2.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21406349539756775
Epoch 0, Step 634: train/loss = 0.5250449180603027, train/raw-loss = 0.48473677039146423, train/logprobs = tensor([[-1.5713, -3.0668],
        [-1.7797, -2.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16123265027999878
Epoch 0, Step 635: train/loss = 0.6028821468353271, train/raw-loss = 0.5538726449012756, train/logprobs = tensor([[-1.5624, -3.0089],
        [-1.6946, -2.1643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19603803753852844
Epoch 0, Step 636: train/loss = 0.5718280673027039, train/raw-loss = 0.5363519191741943, train/logprobs = tensor([[-1.5417, -1.3942],
        [-1.8951, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190466701984406
Epoch 0, Step 637: train/loss = 0.7949492931365967, train/raw-loss = 0.7383216619491577, train/logprobs = tensor([[-1.5326, -1.6176],
        [-1.6153, -1.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2265104204416275
Epoch 0, Step 638: train/loss = 0.6794387698173523, train/raw-loss = 0.6299650073051453, train/logprobs = tensor([[-1.3977, -1.4939],
        [-2.0879, -1.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19789494574069977
Epoch 0, Step 639: train/loss = 0.5364946126937866, train/raw-loss = 0.4820585250854492, train/logprobs = tensor([[-1.5168, -2.3946],
        [-2.2709, -2.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21774441003799438
Epoch 0, Step 640: train/loss = 0.6397191286087036, train/raw-loss = 0.587713360786438, train/logprobs = tensor([[-1.2917, -1.8898],
        [-1.8617, -1.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20802301168441772
Epoch 0, Step 641: train/loss = 0.5847351551055908, train/raw-loss = 0.5322588682174683, train/logprobs = tensor([[-1.2930, -2.6873],
        [-1.9509, -1.7707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2099049985408783
Epoch 0, Step 642: train/loss = 0.5602321028709412, train/raw-loss = 0.5074405670166016, train/logprobs = tensor([[-1.7136, -2.3914],
        [-2.2886, -1.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21116624772548676
Epoch 0, Step 643: train/loss = 0.7785203456878662, train/raw-loss = 0.7366384267807007, train/logprobs = tensor([[-1.8104, -1.8149],
        [-2.1544, -2.1547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16752764582633972
Epoch 0, Step 644: train/loss = 0.5280117988586426, train/raw-loss = 0.48742395639419556, train/logprobs = tensor([[-0.8755, -1.8555],
        [-1.1826, -0.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16235144436359406
Epoch 0, Step 645: train/loss = 0.586054265499115, train/raw-loss = 0.5421311259269714, train/logprobs = tensor([[-0.8825, -1.6405],
        [-1.2742, -0.8226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1756923943758011
Epoch 0, Step 646: train/loss = 0.46031898260116577, train/raw-loss = 0.4066215455532074, train/logprobs = tensor([[-2.2471, -3.3875],
        [-3.0381, -2.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21478980779647827
Epoch 0, Step 647: train/loss = 0.6613215804100037, train/raw-loss = 0.6171766519546509, train/logprobs = tensor([[-1.2607, -1.4555],
        [-1.2983, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17657975852489471
Epoch 0, Step 648: train/loss = 0.6227245926856995, train/raw-loss = 0.5832154750823975, train/logprobs = tensor([[-1.7096, -2.3779],
        [-1.9764, -1.6391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15803644061088562
Epoch 0, Step 649: train/loss = 0.4524860084056854, train/raw-loss = 0.39200133085250854, train/logprobs = tensor([[-1.7301, -3.0766],
        [-2.5127, -2.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24193881452083588
Epoch 0, Step 650: train/loss = 0.6890993118286133, train/raw-loss = 0.6544429063796997, train/logprobs = tensor([[-0.4823, -0.7670],
        [-0.6585, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13862544298171997
Epoch 0, Step 651: train/loss = 0.560543954372406, train/raw-loss = 0.5131563544273376, train/logprobs = tensor([[-1.5091, -2.2463],
        [-1.7233, -1.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18955034017562866
Epoch 0, Step 652: train/loss = 0.7058076858520508, train/raw-loss = 0.6576394438743591, train/logprobs = tensor([[-2.9411, -2.8252],
        [-3.0439, -2.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1926727592945099
Epoch 0, Step 653: train/loss = 0.6962783336639404, train/raw-loss = 0.6308935284614563, train/logprobs = tensor([[-2.2714, -3.1675],
        [-2.5088, -3.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26153916120529175
Epoch 0, Step 654: train/loss = 0.5652961730957031, train/raw-loss = 0.5200724601745605, train/logprobs = tensor([[-1.8868, -2.2719],
        [-2.1321, -1.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18089471757411957
Epoch 0, Step 655: train/loss = 0.5730491876602173, train/raw-loss = 0.5319652557373047, train/logprobs = tensor([[-0.8102, -1.5917],
        [-1.6384, -1.4186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16433559358119965
Epoch 0, Step 656: train/loss = 0.7090842723846436, train/raw-loss = 0.6522746086120605, train/logprobs = tensor([[-2.5336, -3.7529],
        [-1.9680, -2.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22723862528800964
Epoch 0, Step 657: train/loss = 0.8446913361549377, train/raw-loss = 0.7864674925804138, train/logprobs = tensor([[-2.7265, -2.8028],
        [-2.0816, -1.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23289552330970764
Epoch 0, Step 658: train/loss = 0.6152424812316895, train/raw-loss = 0.5590945482254028, train/logprobs = tensor([[-0.9849, -2.1692],
        [-1.5912, -2.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22459177672863007
Epoch 0, Step 659: train/loss = 0.7097843885421753, train/raw-loss = 0.6548414826393127, train/logprobs = tensor([[-1.6045, -1.3352],
        [-2.5378, -1.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21977169811725616
Epoch 0, Step 660: train/loss = 0.838828980922699, train/raw-loss = 0.7923398017883301, train/logprobs = tensor([[-1.8419, -1.8649],
        [-3.4440, -3.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1859569251537323
Epoch 0, Step 661: train/loss = 0.6732166409492493, train/raw-loss = 0.6186291575431824, train/logprobs = tensor([[-1.7212, -2.7185],
        [-2.2639, -2.5830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21834984421730042
Epoch 0, Step 662: train/loss = 0.5919365286827087, train/raw-loss = 0.5430317521095276, train/logprobs = tensor([[-1.8842, -2.9170],
        [-2.1346, -1.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.195619136095047
Epoch 0, Step 663: train/loss = 0.5714700818061829, train/raw-loss = 0.5280195474624634, train/logprobs = tensor([[-1.5724, -3.6723],
        [-2.4710, -3.6444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17380210757255554
Epoch 0, Step 664: train/loss = 0.4999275505542755, train/raw-loss = 0.45135051012039185, train/logprobs = tensor([[-1.6984, -1.5572],
        [-2.4196, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1943081021308899
Epoch 0, Step 665: train/loss = 0.6656915545463562, train/raw-loss = 0.6149936318397522, train/logprobs = tensor([[-0.9480, -1.3355],
        [-1.2250, -1.2308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20279157161712646
Epoch 0, Step 666: train/loss = 0.6774580478668213, train/raw-loss = 0.6189676523208618, train/logprobs = tensor([[-1.9789, -4.5075],
        [-1.2325, -2.5963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23396176099777222
Epoch 0, Step 667: train/loss = 0.8585701584815979, train/raw-loss = 0.818519115447998, train/logprobs = tensor([[-1.8558, -1.3127],
        [-1.5954, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16020414233207703
Epoch 0, Step 668: train/loss = 0.46160367131233215, train/raw-loss = 0.407783567905426, train/logprobs = tensor([[-0.8133, -2.3459],
        [-1.6554, -1.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2152804434299469
Epoch 0, Step 669: train/loss = 0.6804749965667725, train/raw-loss = 0.631914496421814, train/logprobs = tensor([[-1.8234, -1.9953],
        [-2.1068, -1.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1942422091960907
Epoch 0, Step 670: train/loss = 0.7059357166290283, train/raw-loss = 0.6491629481315613, train/logprobs = tensor([[-1.5925, -1.8161],
        [-2.2045, -2.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22709113359451294
Epoch 0, Step 671: train/loss = 0.7543566823005676, train/raw-loss = 0.6936339139938354, train/logprobs = tensor([[-1.4075, -1.3543],
        [-1.8876, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.242890864610672
Epoch 0, Step 672: train/loss = 0.49112170934677124, train/raw-loss = 0.4432181715965271, train/logprobs = tensor([[-2.0599, -3.0294],
        [-2.4166, -1.7934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19161398708820343
Epoch 0, Step 673: train/loss = 0.6476646661758423, train/raw-loss = 0.5998373031616211, train/logprobs = tensor([[-1.7119, -2.7005],
        [-1.6183, -1.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1913096010684967
Epoch 0, Step 674: train/loss = 0.7397112846374512, train/raw-loss = 0.6880100965499878, train/logprobs = tensor([[-3.0490, -3.3410],
        [-3.3551, -3.4822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20680475234985352
Epoch 0, Step 675: train/loss = 0.4416142404079437, train/raw-loss = 0.38324326276779175, train/logprobs = tensor([[-1.5492, -2.9572],
        [-2.2785, -2.0463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23348376154899597
Epoch 0, Step 676: train/loss = 0.5990292429924011, train/raw-loss = 0.5556204915046692, train/logprobs = tensor([[-0.8385, -1.3765],
        [-1.1250, -0.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17363494634628296
Epoch 0, Step 677: train/loss = 0.46189361810684204, train/raw-loss = 0.4064334034919739, train/logprobs = tensor([[-0.8641, -3.3135],
        [-1.8224, -1.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22184088826179504
Epoch 0, Step 678: train/loss = 0.6008679866790771, train/raw-loss = 0.5528744459152222, train/logprobs = tensor([[-2.0251, -2.1952],
        [-2.5194, -1.7876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1919741928577423
Epoch 0, Step 679: train/loss = 0.6961972713470459, train/raw-loss = 0.6510921120643616, train/logprobs = tensor([[-1.6864, -1.4616],
        [-2.4169, -1.8254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18042048811912537
Epoch 0, Step 680: train/loss = 0.702966034412384, train/raw-loss = 0.663257896900177, train/logprobs = tensor([[-0.6663, -0.9838],
        [-1.3823, -1.3464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15883256494998932
Epoch 0, Step 681: train/loss = 0.5302912592887878, train/raw-loss = 0.48718520998954773, train/logprobs = tensor([[-1.6110, -3.2619],
        [-1.7899, -2.0529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1724241077899933
Epoch 0, Step 682: train/loss = 0.3638775944709778, train/raw-loss = 0.3108386993408203, train/logprobs = tensor([[-1.3301, -3.2512],
        [-2.2568, -2.0430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21215558052062988
Epoch 0, Step 683: train/loss = 0.8234021663665771, train/raw-loss = 0.7665418982505798, train/logprobs = tensor([[-2.3056, -3.2034],
        [-2.0366, -2.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2274409681558609
Epoch 0, Step 684: train/loss = 0.7059366106987, train/raw-loss = 0.6476033926010132, train/logprobs = tensor([[-1.6941, -2.6445],
        [-1.7776, -2.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23333290219306946
Epoch 0, Step 685: train/loss = 0.6967545747756958, train/raw-loss = 0.6573271751403809, train/logprobs = tensor([[-0.6634, -0.7821],
        [-0.6963, -0.6612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15770959854125977
Epoch 0, Step 686: train/loss = 0.5329891443252563, train/raw-loss = 0.48015114665031433, train/logprobs = tensor([[-1.6659, -3.1575],
        [-2.1155, -2.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21135185658931732
Epoch 0, Step 687: train/loss = 0.5668013691902161, train/raw-loss = 0.5184272527694702, train/logprobs = tensor([[-1.9568, -2.8919],
        [-2.2077, -2.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19349639117717743
Epoch 0, Step 688: train/loss = 0.6792541146278381, train/raw-loss = 0.6375497579574585, train/logprobs = tensor([[-1.3233, -1.4413],
        [-1.9555, -1.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16681745648384094
Epoch 0, Step 689: train/loss = 0.5681997537612915, train/raw-loss = 0.5302419662475586, train/logprobs = tensor([[-1.1639, -2.3569],
        [-1.6825, -1.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15183094143867493
Epoch 0, Step 690: train/loss = 0.6438837647438049, train/raw-loss = 0.5886488556861877, train/logprobs = tensor([[-1.7031, -2.0960],
        [-1.8819, -1.6479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209397405385971
Epoch 0, Step 691: train/loss = 0.6227027177810669, train/raw-loss = 0.5747450590133667, train/logprobs = tensor([[-1.5691, -1.9780],
        [-2.7978, -2.3738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19183066487312317
Epoch 0, Step 692: train/loss = 0.6114147305488586, train/raw-loss = 0.5461812615394592, train/logprobs = tensor([[-1.2663, -2.3420],
        [-1.9947, -2.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609339654445648
Epoch 0, Step 693: train/loss = 0.6731204986572266, train/raw-loss = 0.6191188097000122, train/logprobs = tensor([[-0.7939, -1.0647],
        [-1.1769, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21600686013698578
Epoch 0, Step 694: train/loss = 0.7303583025932312, train/raw-loss = 0.6691381335258484, train/logprobs = tensor([[-1.4525, -1.5713],
        [-1.8325, -1.7172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24488091468811035
Epoch 0, Step 695: train/loss = 0.7942696213722229, train/raw-loss = 0.7436306476593018, train/logprobs = tensor([[-2.5204, -2.1461],
        [-2.2846, -1.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20255565643310547
Epoch 0, Step 696: train/loss = 0.5663045644760132, train/raw-loss = 0.5117471218109131, train/logprobs = tensor([[-2.2243, -4.2977],
        [-2.5419, -2.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21822986006736755
Epoch 0, Step 697: train/loss = 0.6949676275253296, train/raw-loss = 0.638477087020874, train/logprobs = tensor([[-1.7074, -1.7826],
        [-2.0812, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259623110294342
Epoch 0, Step 698: train/loss = 0.926862895488739, train/raw-loss = 0.8755526542663574, train/logprobs = tensor([[-0.9267, -1.4175],
        [-1.5472, -2.2907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20524069666862488
Epoch 0, Step 699: train/loss = 0.5372011065483093, train/raw-loss = 0.48931097984313965, train/logprobs = tensor([[-1.4246, -1.7008],
        [-2.9163, -1.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1915605664253235
Epoch 0, Step 700: train/loss = 0.6718358993530273, train/raw-loss = 0.6280686855316162, train/logprobs = tensor([[-1.2752, -1.9855],
        [-1.8955, -2.1844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17506852746009827
Epoch 0, Step 701: train/loss = 0.5559556484222412, train/raw-loss = 0.5012703537940979, train/logprobs = tensor([[-1.4994, -2.5667],
        [-2.2262, -2.2443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21874123811721802
Epoch 0, Step 702: train/loss = 0.7016005516052246, train/raw-loss = 0.6492871046066284, train/logprobs = tensor([[-1.1870, -1.4357],
        [-1.2828, -1.2457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2092536836862564
Epoch 0, Step 703: train/loss = 0.49786311388015747, train/raw-loss = 0.4517775774002075, train/logprobs = tensor([[-1.5830, -2.3318],
        [-2.6553, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1843421906232834
Epoch 0, Step 704: train/loss = 0.701238751411438, train/raw-loss = 0.6484346389770508, train/logprobs = tensor([[-2.7008, -3.2848],
        [-3.2443, -3.4187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21121618151664734
Epoch 0, Step 705: train/loss = 0.7416947484016418, train/raw-loss = 0.6969435214996338, train/logprobs = tensor([[-1.3041, -1.3727],
        [-2.2956, -2.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17900490760803223
Epoch 0, Step 706: train/loss = 0.8568709492683411, train/raw-loss = 0.8053348064422607, train/logprobs = tensor([[-2.4641, -2.3348],
        [-1.9704, -1.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20614466071128845
Epoch 0, Step 707: train/loss = 0.550696611404419, train/raw-loss = 0.49911215901374817, train/logprobs = tensor([[-1.2065, -2.7150],
        [-1.8001, -2.2585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20633774995803833
Epoch 0, Step 708: train/loss = 0.7057220339775085, train/raw-loss = 0.6624017953872681, train/logprobs = tensor([[-1.9885, -2.1879],
        [-2.0121, -1.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1732812523841858
Epoch 0, Step 709: train/loss = 0.4582575559616089, train/raw-loss = 0.4098125398159027, train/logprobs = tensor([[-1.6566, -2.5241],
        [-3.0826, -2.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1937800645828247
Epoch 0, Step 710: train/loss = 0.599392294883728, train/raw-loss = 0.5599046349525452, train/logprobs = tensor([[-1.6130, -2.6502],
        [-1.4618, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15795078873634338
Epoch 0, Step 711: train/loss = 0.6644498705863953, train/raw-loss = 0.6081279516220093, train/logprobs = tensor([[-2.1066, -2.7685],
        [-1.9168, -1.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22528767585754395
Epoch 0, Step 712: train/loss = 0.45383894443511963, train/raw-loss = 0.40943944454193115, train/logprobs = tensor([[-1.5593, -3.2000],
        [-2.3639, -1.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17759793996810913
Epoch 0, Step 713: train/loss = 0.6832228899002075, train/raw-loss = 0.6164681911468506, train/logprobs = tensor([[-2.7312, -3.9856],
        [-2.5047, -2.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26701870560646057
Epoch 0, Step 714: train/loss = 0.7118345499038696, train/raw-loss = 0.6556352376937866, train/logprobs = tensor([[-2.7473, -3.2432],
        [-2.2311, -2.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22479741275310516
Epoch 0, Step 715: train/loss = 0.6832186579704285, train/raw-loss = 0.6320676207542419, train/logprobs = tensor([[-2.7765, -2.2446],
        [-2.7027, -1.1332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20460423827171326
Epoch 0, Step 716: train/loss = 0.5856084227561951, train/raw-loss = 0.5384790301322937, train/logprobs = tensor([[-1.1222, -1.7408],
        [-1.6363, -1.4132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18851754069328308
Epoch 0, Step 717: train/loss = 0.5099116563796997, train/raw-loss = 0.45299839973449707, train/logprobs = tensor([[-2.0422, -2.8411],
        [-4.0424, -2.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2276529222726822
Epoch 0, Step 718: train/loss = 0.5909514427185059, train/raw-loss = 0.5344131588935852, train/logprobs = tensor([[-1.4949, -2.1338],
        [-2.0165, -1.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.226153165102005
Epoch 0, Step 719: train/loss = 0.7148101925849915, train/raw-loss = 0.6580797433853149, train/logprobs = tensor([[-1.7228, -2.0013],
        [-1.3873, -1.3962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22692154347896576
Epoch 0, Step 720: train/loss = 0.5454291105270386, train/raw-loss = 0.4965973496437073, train/logprobs = tensor([[-1.5764, -2.6462],
        [-2.0718, -1.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19532689452171326
Epoch 0, Step 721: train/loss = 0.5549322366714478, train/raw-loss = 0.5171104073524475, train/logprobs = tensor([[-1.1386, -2.4111],
        [-1.1679, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15128739178180695
Epoch 0, Step 722: train/loss = 0.7965152263641357, train/raw-loss = 0.7442287802696228, train/logprobs = tensor([[-1.6555, -2.2230],
        [-2.2500, -2.6896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20914572477340698
Epoch 0, Step 723: train/loss = 0.6528436541557312, train/raw-loss = 0.6117839813232422, train/logprobs = tensor([[-1.4600, -1.8741],
        [-1.5393, -1.5863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16423861682415009
Epoch 0, Step 724: train/loss = 0.7359718084335327, train/raw-loss = 0.6860958337783813, train/logprobs = tensor([[-1.2287, -1.7243],
        [-1.6503, -1.9681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19950398802757263
Epoch 0, Step 725: train/loss = 0.525928258895874, train/raw-loss = 0.4815438985824585, train/logprobs = tensor([[-1.9771, -0.7921],
        [-2.8316, -0.5971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17753751575946808
Epoch 0, Step 726: train/loss = 0.7555822134017944, train/raw-loss = 0.6949449777603149, train/logprobs = tensor([[-2.1100, -2.1171],
        [-2.1260, -2.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24254930019378662
Epoch 0, Step 727: train/loss = 0.48564019799232483, train/raw-loss = 0.43064096570014954, train/logprobs = tensor([[-1.9650, -2.6348],
        [-2.8393, -1.7070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21999682486057281
Epoch 0, Step 728: train/loss = 0.7054722905158997, train/raw-loss = 0.6597809791564941, train/logprobs = tensor([[-2.6937, -2.1922],
        [-2.9853, -2.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18276509642601013
Epoch 0, Step 729: train/loss = 0.6678580045700073, train/raw-loss = 0.6138896346092224, train/logprobs = tensor([[-1.8448, -1.7337],
        [-2.5225, -1.8952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21587340533733368
Epoch 0, Step 730: train/loss = 0.5930050611495972, train/raw-loss = 0.534125804901123, train/logprobs = tensor([[-1.5732, -2.8482],
        [-2.3155, -2.7372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23551695048809052
Epoch 0, Step 731: train/loss = 0.5305272936820984, train/raw-loss = 0.48877763748168945, train/logprobs = tensor([[-0.6331, -2.2101],
        [-1.0328, -1.4029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16699862480163574
Epoch 0, Step 732: train/loss = 0.3555290102958679, train/raw-loss = 0.3137603998184204, train/logprobs = tensor([[-1.3486, -2.3586],
        [-3.0373, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1670745313167572
Epoch 0, Step 733: train/loss = 0.5850460529327393, train/raw-loss = 0.5288448333740234, train/logprobs = tensor([[-0.6938, -2.2562],
        [-1.3319, -1.9148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2248048484325409
Epoch 0, Step 734: train/loss = 0.6210553646087646, train/raw-loss = 0.5714308023452759, train/logprobs = tensor([[-1.6769, -1.9527],
        [-2.5283, -2.1694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19849836826324463
Epoch 0, Step 735: train/loss = 0.5899911522865295, train/raw-loss = 0.5334760546684265, train/logprobs = tensor([[-1.8707, -2.9173],
        [-2.2341, -1.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22606033086776733
Epoch 0, Step 736: train/loss = 0.5685438513755798, train/raw-loss = 0.5344302654266357, train/logprobs = tensor([[-2.1264, -3.0734],
        [-2.3313, -2.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364542841911316
Epoch 0, Step 737: train/loss = 0.5662108659744263, train/raw-loss = 0.5217849016189575, train/logprobs = tensor([[-1.3289, -2.0136],
        [-1.7250, -1.4186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17770391702651978
Epoch 0, Step 738: train/loss = 0.7919049859046936, train/raw-loss = 0.7420186996459961, train/logprobs = tensor([[-2.2372, -1.7736],
        [-2.9172, -2.3002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1995449662208557
Epoch 0, Step 739: train/loss = 0.6458000540733337, train/raw-loss = 0.5935636162757874, train/logprobs = tensor([[-2.0428, -2.7982],
        [-3.2197, -3.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20894578099250793
Epoch 0, Step 740: train/loss = 0.6093053817749023, train/raw-loss = 0.5621910691261292, train/logprobs = tensor([[-1.6185, -1.6881],
        [-2.1064, -1.4343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18845707178115845
Epoch 0, Step 741: train/loss = 0.6590343117713928, train/raw-loss = 0.6019753217697144, train/logprobs = tensor([[-0.9135, -2.6257],
        [-1.5212, -2.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22823575139045715
Epoch 0, Step 742: train/loss = 0.7352375984191895, train/raw-loss = 0.6805187463760376, train/logprobs = tensor([[-2.4411, -2.4142],
        [-2.2920, -2.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21887508034706116
Epoch 0, Step 743: train/loss = 0.7421278357505798, train/raw-loss = 0.6918561458587646, train/logprobs = tensor([[-1.0443, -1.1018],
        [-1.7615, -1.6191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20108652114868164
Epoch 0, Step 744: train/loss = 0.5483435392379761, train/raw-loss = 0.506100058555603, train/logprobs = tensor([[-1.2191, -2.3904],
        [-2.0215, -2.0135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897383332252502
Epoch 0, Step 745: train/loss = 0.6057120561599731, train/raw-loss = 0.5629363059997559, train/logprobs = tensor([[-1.0728, -2.0385],
        [-1.2804, -1.5448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17110276222229004
Epoch 0, Step 746: train/loss = 0.5397257208824158, train/raw-loss = 0.48686134815216064, train/logprobs = tensor([[-1.8489, -1.8816],
        [-2.2996, -1.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21145758032798767
Epoch 0, Step 747: train/loss = 0.5725919008255005, train/raw-loss = 0.5181481242179871, train/logprobs = tensor([[-1.1837, -2.0997],
        [-1.6472, -1.7071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2177753746509552
Epoch 0, Step 748: train/loss = 0.6273929476737976, train/raw-loss = 0.5853266716003418, train/logprobs = tensor([[-2.3409, -2.8582],
        [-3.0650, -2.8535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16826508939266205
Epoch 0, Step 749: train/loss = 0.610826849937439, train/raw-loss = 0.5621307492256165, train/logprobs = tensor([[-0.8508, -1.7157],
        [-1.6238, -1.6238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19478432834148407
Epoch 0, Step 750: train/loss = 0.6916621327400208, train/raw-loss = 0.6468355059623718, train/logprobs = tensor([[-1.8677, -1.8017],
        [-2.4706, -2.0364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17930640280246735
Epoch 0, Step 751: train/loss = 0.5988126993179321, train/raw-loss = 0.5474088788032532, train/logprobs = tensor([[-1.1547, -3.1906],
        [-1.4928, -2.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20561543107032776
Epoch 0, Step 752: train/loss = 0.6884132623672485, train/raw-loss = 0.6420413255691528, train/logprobs = tensor([[-3.0354, -3.1321],
        [-2.7510, -2.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18548788130283356
Epoch 0, Step 753: train/loss = 0.5623989105224609, train/raw-loss = 0.5173584222793579, train/logprobs = tensor([[-1.1519, -2.1083],
        [-1.3171, -1.1207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18016184866428375
Epoch 0, Step 754: train/loss = 0.7126548886299133, train/raw-loss = 0.6738406419754028, train/logprobs = tensor([[-1.6039, -2.3146],
        [-1.6152, -2.0298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15525716543197632
Epoch 0, Step 755: train/loss = 0.5834529995918274, train/raw-loss = 0.5412694811820984, train/logprobs = tensor([[-1.3026, -2.2782],
        [-1.6127, -1.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16873419284820557
Epoch 0, Step 756: train/loss = 0.561805248260498, train/raw-loss = 0.5107861757278442, train/logprobs = tensor([[-1.3966, -4.1050],
        [-1.7677, -2.4050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20407608151435852
Epoch 0, Step 757: train/loss = 0.60691237449646, train/raw-loss = 0.5647276043891907, train/logprobs = tensor([[-2.0682, -3.2118],
        [-2.9398, -3.2121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16873905062675476
Epoch 0, Step 758: train/loss = 0.6497933864593506, train/raw-loss = 0.6056939959526062, train/logprobs = tensor([[-0.9056, -1.6270],
        [-1.3630, -1.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17639775574207306
Epoch 0, Step 759: train/loss = 0.6430169343948364, train/raw-loss = 0.5890580415725708, train/logprobs = tensor([[-1.8115, -2.4866],
        [-2.1132, -2.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21583566069602966
Epoch 0, Step 760: train/loss = 0.7164399027824402, train/raw-loss = 0.6520364880561829, train/logprobs = tensor([[-2.1690, -2.3519],
        [-2.8359, -2.6437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2576136589050293
Epoch 0, Step 761: train/loss = 0.588559627532959, train/raw-loss = 0.5460913181304932, train/logprobs = tensor([[-0.6390, -2.1007],
        [-0.7962, -1.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16987344622612
Epoch 0, Step 762: train/loss = 0.6129266023635864, train/raw-loss = 0.5522215962409973, train/logprobs = tensor([[-1.4287, -2.3204],
        [-1.6499, -1.4638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.242820143699646
Epoch 0, Step 763: train/loss = 0.5830749273300171, train/raw-loss = 0.527660071849823, train/logprobs = tensor([[-2.2325, -2.3438],
        [-3.2529, -2.2560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22165949642658234
Epoch 0, Step 764: train/loss = 0.610039234161377, train/raw-loss = 0.5624802112579346, train/logprobs = tensor([[-2.7845, -2.9596],
        [-4.3087, -3.4177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19023625552654266
Epoch 0, Step 765: train/loss = 0.7477624416351318, train/raw-loss = 0.7037997245788574, train/logprobs = tensor([[-1.3519, -1.4635],
        [-1.6960, -1.7875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17585092782974243
Epoch 0, Step 766: train/loss = 0.5196661353111267, train/raw-loss = 0.4699357748031616, train/logprobs = tensor([[-1.8552, -2.8923],
        [-1.9899, -1.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19892138242721558
Epoch 0, Step 767: train/loss = 0.6024947166442871, train/raw-loss = 0.5455440878868103, train/logprobs = tensor([[-1.4312, -2.1167],
        [-2.2084, -2.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22780227661132812
Epoch 0, Step 768: train/loss = 0.3953337073326111, train/raw-loss = 0.34666621685028076, train/logprobs = tensor([[-1.8632, -3.0842],
        [-2.8987, -1.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1946699023246765
Epoch 0, Step 769: train/loss = 0.5833237171173096, train/raw-loss = 0.5384117364883423, train/logprobs = tensor([[-0.9004, -2.2194],
        [-1.2270, -1.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17964798212051392
Epoch 0, Step 770: train/loss = 0.7313601970672607, train/raw-loss = 0.6756634712219238, train/logprobs = tensor([[-2.2060, -2.1803],
        [-2.0743, -1.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22278708219528198
Epoch 0, Step 771: train/loss = 0.6944453716278076, train/raw-loss = 0.6515620350837708, train/logprobs = tensor([[-1.1438, -1.8044],
        [-1.0703, -1.5247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17153316736221313
Epoch 0, Step 772: train/loss = 0.6165355443954468, train/raw-loss = 0.5630968809127808, train/logprobs = tensor([[-1.3651, -1.9200],
        [-1.8110, -1.4776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21375450491905212
Epoch 0, Step 773: train/loss = 0.6763638854026794, train/raw-loss = 0.6333459615707397, train/logprobs = tensor([[-0.8257, -2.1029],
        [-1.0068, -2.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1720716655254364
Epoch 0, Step 774: train/loss = 0.6777161359786987, train/raw-loss = 0.6321796178817749, train/logprobs = tensor([[-1.1452, -2.1543],
        [-1.1031, -1.5284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.182145893573761
Epoch 0, Step 775: train/loss = 0.48562514781951904, train/raw-loss = 0.4436374306678772, train/logprobs = tensor([[-1.0539, -2.2449],
        [-1.7600, -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16795089840888977
Epoch 0, Step 776: train/loss = 0.6165357232093811, train/raw-loss = 0.565646767616272, train/logprobs = tensor([[-1.6438, -2.8724],
        [-1.5527, -1.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2035558521747589
Epoch 0, Step 777: train/loss = 0.7176538109779358, train/raw-loss = 0.6779966354370117, train/logprobs = tensor([[-0.6449, -1.0074],
        [-0.8754, -1.1458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15862886607646942
Epoch 0, Step 778: train/loss = 0.6673528552055359, train/raw-loss = 0.6106759309768677, train/logprobs = tensor([[-1.3282, -1.9012],
        [-1.7867, -1.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22670769691467285
Epoch 0, Step 779: train/loss = 0.5918819904327393, train/raw-loss = 0.5379945039749146, train/logprobs = tensor([[-1.1007, -2.7144],
        [-1.6206, -2.3212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21555015444755554
Epoch 0, Step 780: train/loss = 0.5931326746940613, train/raw-loss = 0.537945568561554, train/logprobs = tensor([[-1.5446, -2.0451],
        [-2.2399, -1.7439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22074851393699646
Epoch 0, Step 781: train/loss = 0.5117366909980774, train/raw-loss = 0.45684173703193665, train/logprobs = tensor([[-1.2729, -2.2120],
        [-1.5630, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21957996487617493
Epoch 0, Step 782: train/loss = 0.7268909811973572, train/raw-loss = 0.6755043268203735, train/logprobs = tensor([[-1.2865, -1.6159],
        [-1.3224, -1.5531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20554643869400024
Epoch 0, Step 783: train/loss = 0.39305463433265686, train/raw-loss = 0.3422596752643585, train/logprobs = tensor([[-0.8961, -2.9483],
        [-1.8001, -1.7312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20317980647087097
Epoch 0, Step 784: train/loss = 0.5987976789474487, train/raw-loss = 0.5479000806808472, train/logprobs = tensor([[-2.2369, -3.0818],
        [-2.0286, -1.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20359057188034058
Epoch 0, Step 785: train/loss = 0.48700663447380066, train/raw-loss = 0.43633008003234863, train/logprobs = tensor([[-1.2342, -2.5857],
        [-1.9658, -1.5620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2027062177658081
Epoch 0, Step 786: train/loss = 0.5354287624359131, train/raw-loss = 0.4918534755706787, train/logprobs = tensor([[-1.2768, -2.3398],
        [-1.8334, -1.7977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1743013560771942
Epoch 0, Step 787: train/loss = 0.5937162637710571, train/raw-loss = 0.542643129825592, train/logprobs = tensor([[-1.4514, -2.9774],
        [-1.4233, -1.4302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2042924165725708
Epoch 0, Step 788: train/loss = 0.6342856287956238, train/raw-loss = 0.6009182929992676, train/logprobs = tensor([[-1.0037, -1.0268],
        [-2.6522, -1.5608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133469358086586
Epoch 0, Step 789: train/loss = 0.6552177667617798, train/raw-loss = 0.6110103726387024, train/logprobs = tensor([[-1.6112, -1.7425],
        [-1.6264, -1.2581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17682944238185883
Epoch 0, Step 790: train/loss = 0.5386350154876709, train/raw-loss = 0.497802197933197, train/logprobs = tensor([[-0.5642, -2.0423],
        [-1.0097, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1633310765028
Epoch 0, Step 791: train/loss = 0.7599261999130249, train/raw-loss = 0.7049727439880371, train/logprobs = tensor([[-1.5597, -1.6953],
        [-1.7074, -1.8281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21981389820575714
Epoch 0, Step 792: train/loss = 0.5283041596412659, train/raw-loss = 0.4734542965888977, train/logprobs = tensor([[-1.1139, -3.1249],
        [-1.4884, -1.6824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2193993628025055
Epoch 0, Step 793: train/loss = 0.5783541798591614, train/raw-loss = 0.5187808275222778, train/logprobs = tensor([[-1.5899, -2.8741],
        [-2.2937, -2.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23829343914985657
Epoch 0, Step 794: train/loss = 0.7634917497634888, train/raw-loss = 0.7055695056915283, train/logprobs = tensor([[-1.7599, -2.8656],
        [-1.7504, -2.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2316889762878418
Epoch 0, Step 795: train/loss = 0.6510477662086487, train/raw-loss = 0.6037104725837708, train/logprobs = tensor([[-2.2668, -2.7033],
        [-2.5990, -2.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18934909999370575
Epoch 0, Step 796: train/loss = 0.748185396194458, train/raw-loss = 0.7074332237243652, train/logprobs = tensor([[-1.3347, -1.7772],
        [-1.1679, -1.6265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16300882399082184
Epoch 0, Step 797: train/loss = 0.5426849126815796, train/raw-loss = 0.4898121953010559, train/logprobs = tensor([[-1.7603, -2.6645],
        [-1.9504, -1.3839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21149083971977234
Epoch 0, Step 798: train/loss = 0.653317391872406, train/raw-loss = 0.6010852456092834, train/logprobs = tensor([[-1.3040, -1.5611],
        [-1.8081, -1.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2089286893606186
Epoch 0, Step 799: train/loss = 0.7671775817871094, train/raw-loss = 0.7160186171531677, train/logprobs = tensor([[-1.6414, -1.6558],
        [-1.7899, -1.8319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2046356350183487
Epoch 0, Step 800: train/loss = 0.6910261511802673, train/raw-loss = 0.6417273879051208, train/logprobs = tensor([[-2.0528, -1.9545],
        [-1.7539, -1.2842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19719505310058594
Epoch 0, Step 801: train/loss = 0.5216317176818848, train/raw-loss = 0.47310900688171387, train/logprobs = tensor([[-0.9252, -2.7895],
        [-1.7743, -2.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19409093260765076
Epoch 0, Step 802: train/loss = 0.5579495429992676, train/raw-loss = 0.5112820863723755, train/logprobs = tensor([[-1.6302, -2.0242],
        [-1.9451, -1.0011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18666976690292358
Epoch 0, Step 803: train/loss = 0.7071007490158081, train/raw-loss = 0.6636238098144531, train/logprobs = tensor([[-1.6747, -1.4283],
        [-1.7814, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17390790581703186
Epoch 0, Step 804: train/loss = 0.6584803462028503, train/raw-loss = 0.6133421659469604, train/logprobs = tensor([[-1.4637, -1.8789],
        [-1.2916, -1.0168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18055285513401031
Epoch 0, Step 805: train/loss = 0.6648876667022705, train/raw-loss = 0.6179357171058655, train/logprobs = tensor([[-1.3652, -1.9968],
        [-1.9538, -1.8464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18780779838562012
Epoch 0, Step 806: train/loss = 0.491995632648468, train/raw-loss = 0.43462783098220825, train/logprobs = tensor([[-1.5740, -2.8568],
        [-2.0977, -1.9814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22947126626968384
Epoch 0, Step 807: train/loss = 0.8752844333648682, train/raw-loss = 0.8210304975509644, train/logprobs = tensor([[-2.1498, -2.5015],
        [-1.7477, -1.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21701571345329285
Epoch 0, Step 808: train/loss = 0.6927797198295593, train/raw-loss = 0.6293814182281494, train/logprobs = tensor([[-1.2147, -1.7816],
        [-1.4654, -1.7418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2535931468009949
Epoch 0, Step 809: train/loss = 0.6832743883132935, train/raw-loss = 0.629196047782898, train/logprobs = tensor([[-1.4215, -1.6943],
        [-1.3950, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2163131982088089
Epoch 0, Step 810: train/loss = 0.49086564779281616, train/raw-loss = 0.4447949528694153, train/logprobs = tensor([[-0.7955, -2.0119],
        [-1.5120, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18428288400173187
Epoch 0, Step 811: train/loss = 0.675416111946106, train/raw-loss = 0.6162644624710083, train/logprobs = tensor([[-1.3816, -1.7017],
        [-1.8309, -1.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.236606627702713
Epoch 0, Step 812: train/loss = 0.6105829477310181, train/raw-loss = 0.5559312105178833, train/logprobs = tensor([[-1.4586, -2.2230],
        [-1.6456, -1.5750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2186068892478943
Epoch 0, Step 813: train/loss = 0.6645582914352417, train/raw-loss = 0.6032395958900452, train/logprobs = tensor([[-1.4179, -2.0025],
        [-1.7711, -1.8349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2452748417854309
Epoch 0, Step 814: train/loss = 0.4194343090057373, train/raw-loss = 0.38677874207496643, train/logprobs = tensor([[-0.6161, -3.0399],
        [-1.0846, -1.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1306222826242447
Epoch 0, Step 815: train/loss = 0.5796247124671936, train/raw-loss = 0.5191748142242432, train/logprobs = tensor([[-2.6791, -3.9422],
        [-2.3143, -2.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24179941415786743
Epoch 0, Step 816: train/loss = 0.6522997617721558, train/raw-loss = 0.5919326543807983, train/logprobs = tensor([[-1.7214, -2.4209],
        [-1.5674, -1.6315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2414681613445282
Epoch 0, Step 817: train/loss = 0.6319941282272339, train/raw-loss = 0.5811601877212524, train/logprobs = tensor([[-1.3400, -2.3913],
        [-1.2940, -1.6550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20333579182624817
Epoch 0, Step 818: train/loss = 0.7159656286239624, train/raw-loss = 0.6720486879348755, train/logprobs = tensor([[-1.4252, -1.8277],
        [-1.5243, -1.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17566758394241333
Epoch 0, Step 819: train/loss = 0.6436290740966797, train/raw-loss = 0.586405336856842, train/logprobs = tensor([[-1.8798, -1.5676],
        [-2.0712, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22889502346515656
Epoch 0, Step 820: train/loss = 0.5858277082443237, train/raw-loss = 0.5364652872085571, train/logprobs = tensor([[-1.4750, -1.5753],
        [-1.8481, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19744956493377686
Epoch 0, Step 821: train/loss = 0.587823748588562, train/raw-loss = 0.5527926683425903, train/logprobs = tensor([[-1.1322, -2.4349],
        [-0.8700, -1.2674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14012446999549866
Epoch 0, Step 822: train/loss = 0.4640808403491974, train/raw-loss = 0.4121773838996887, train/logprobs = tensor([[-1.4999, -4.0314],
        [-2.3837, -2.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20761379599571228
Epoch 0, Step 823: train/loss = 0.6371201276779175, train/raw-loss = 0.5920757055282593, train/logprobs = tensor([[-0.6539, -1.2626],
        [-1.3401, -1.3574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18017756938934326
Epoch 0, Step 824: train/loss = 0.6443082094192505, train/raw-loss = 0.5911732912063599, train/logprobs = tensor([[-1.5703, -2.7621],
        [-1.6475, -1.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2125396728515625
Epoch 0, Step 825: train/loss = 0.6081877946853638, train/raw-loss = 0.5704997777938843, train/logprobs = tensor([[-0.8868, -1.8153],
        [-1.4014, -0.9566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15075205266475677
Epoch 0, Step 826: train/loss = 0.5346070528030396, train/raw-loss = 0.4875427484512329, train/logprobs = tensor([[-1.8967, -2.2352],
        [-2.6541, -1.8655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1882573813199997
Epoch 0, Step 827: train/loss = 0.703662097454071, train/raw-loss = 0.6560946702957153, train/logprobs = tensor([[-1.1682, -1.3637],
        [-1.2682, -1.3037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19026947021484375
Epoch 0, Step 828: train/loss = 0.40606239438056946, train/raw-loss = 0.35731393098831177, train/logprobs = tensor([[-0.9514, -2.8968],
        [-1.8133, -1.7057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1949937343597412
Epoch 0, Step 829: train/loss = 0.5450237989425659, train/raw-loss = 0.4974214732646942, train/logprobs = tensor([[-1.3561, -2.0395],
        [-1.9156, -1.5938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19040915369987488
Epoch 0, Step 830: train/loss = 0.6412873864173889, train/raw-loss = 0.5868430137634277, train/logprobs = tensor([[-2.3508, -2.4035],
        [-2.3675, -1.6043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21777766942977905
Epoch 0, Step 831: train/loss = 0.7453404664993286, train/raw-loss = 0.6972931623458862, train/logprobs = tensor([[-1.8477, -2.1597],
        [-1.8129, -2.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19218915700912476
Epoch 0, Step 832: train/loss = 0.7178306579589844, train/raw-loss = 0.6695699095726013, train/logprobs = tensor([[-1.3086, -1.3543],
        [-1.4921, -1.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1930428147315979
Epoch 0, Step 833: train/loss = 0.5228477120399475, train/raw-loss = 0.46960797905921936, train/logprobs = tensor([[-1.5095, -1.6063],
        [-2.1937, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21295905113220215
Epoch 0, Step 834: train/loss = 0.5950133800506592, train/raw-loss = 0.5391137599945068, train/logprobs = tensor([[-1.0095, -1.3091],
        [-1.7747, -1.3269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2235986292362213
Epoch 0, Step 835: train/loss = 0.7039954662322998, train/raw-loss = 0.6545612215995789, train/logprobs = tensor([[-1.8359, -1.8564],
        [-2.1536, -1.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19773684442043304
Epoch 0, Step 836: train/loss = 0.6770150661468506, train/raw-loss = 0.6190592050552368, train/logprobs = tensor([[-1.6669, -1.6922],
        [-2.3430, -1.7838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23182374238967896
Epoch 0, Step 837: train/loss = 0.5334316492080688, train/raw-loss = 0.4863916337490082, train/logprobs = tensor([[-0.9536, -1.6103],
        [-1.6575, -0.8494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1881600171327591
Epoch 0, Step 838: train/loss = 0.8046661615371704, train/raw-loss = 0.7552317380905151, train/logprobs = tensor([[-2.8685, -2.9840],
        [-1.7821, -1.4911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1977379024028778
Epoch 0, Step 839: train/loss = 0.6835415363311768, train/raw-loss = 0.6342209577560425, train/logprobs = tensor([[-2.1516, -2.7318],
        [-2.6456, -2.9275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19728222489356995
Epoch 0, Step 840: train/loss = 0.6225243806838989, train/raw-loss = 0.5722447037696838, train/logprobs = tensor([[-1.4774, -1.8925],
        [-1.9787, -1.7472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2011188119649887
Epoch 0, Step 841: train/loss = 0.7156259417533875, train/raw-loss = 0.6648529767990112, train/logprobs = tensor([[-1.9962, -2.3319],
        [-1.6880, -1.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2030920535326004
Epoch 0, Step 842: train/loss = 0.5728182196617126, train/raw-loss = 0.5294036269187927, train/logprobs = tensor([[-0.8234, -1.4351],
        [-1.2052, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17365844547748566
Epoch 0, Step 843: train/loss = 0.6250495314598083, train/raw-loss = 0.5751245021820068, train/logprobs = tensor([[-1.3767, -1.5446],
        [-1.7318, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19970029592514038
Epoch 0, Step 844: train/loss = 0.6577926874160767, train/raw-loss = 0.6102926731109619, train/logprobs = tensor([[-1.0222, -1.7810],
        [-0.9595, -1.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19000011682510376
Epoch 0, Step 845: train/loss = 0.7927514314651489, train/raw-loss = 0.7481967806816101, train/logprobs = tensor([[-3.0525, -2.8483],
        [-2.3539, -2.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1782182902097702
Epoch 0, Step 846: train/loss = 0.6679575443267822, train/raw-loss = 0.6302547454833984, train/logprobs = tensor([[-1.0553, -1.0695],
        [-1.1629, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1508112996816635
Epoch 0, Step 847: train/loss = 0.686242401599884, train/raw-loss = 0.6434264779090881, train/logprobs = tensor([[-1.6733, -1.6130],
        [-1.6837, -1.3865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17126360535621643
Epoch 0, Step 848: train/loss = 0.8486813902854919, train/raw-loss = 0.8019852042198181, train/logprobs = tensor([[-2.0208, -1.8065],
        [-1.7550, -1.8276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18678481876850128
Epoch 0, Step 849: train/loss = 0.5635195374488831, train/raw-loss = 0.5192475914955139, train/logprobs = tensor([[-0.8429, -3.3423],
        [-1.2917, -2.0440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17708776891231537
Epoch 0, Step 850: train/loss = 0.6728732585906982, train/raw-loss = 0.6180346012115479, train/logprobs = tensor([[-1.9892, -2.7682],
        [-1.9790, -2.3149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21935467422008514
Epoch 0, Step 851: train/loss = 0.5969014167785645, train/raw-loss = 0.5473325848579407, train/logprobs = tensor([[-1.8223, -3.1181],
        [-1.9920, -2.2535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19827505946159363
Epoch 0, Step 852: train/loss = 0.7007243037223816, train/raw-loss = 0.6364603042602539, train/logprobs = tensor([[-1.6166, -2.9164],
        [-2.1656, -2.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2570563554763794
Epoch 0, Step 853: train/loss = 0.48059964179992676, train/raw-loss = 0.4259379208087921, train/logprobs = tensor([[-1.6603, -3.6744],
        [-2.1963, -1.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2186470925807953
Epoch 0, Step 854: train/loss = 0.6690911054611206, train/raw-loss = 0.6115207076072693, train/logprobs = tensor([[-1.7279, -1.6818],
        [-2.2768, -1.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23028184473514557
Epoch 0, Step 855: train/loss = 0.6172398328781128, train/raw-loss = 0.5683143138885498, train/logprobs = tensor([[-0.6468, -1.9856],
        [-1.4838, -1.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19570206105709076
Epoch 0, Step 856: train/loss = 0.536536455154419, train/raw-loss = 0.48596426844596863, train/logprobs = tensor([[-1.1548, -1.9973],
        [-2.1632, -1.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20228862762451172
Epoch 0, Step 857: train/loss = 0.652400016784668, train/raw-loss = 0.6028978228569031, train/logprobs = tensor([[-2.0905, -2.7534],
        [-2.0605, -1.6349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19800886511802673
Epoch 0, Step 858: train/loss = 0.577292263507843, train/raw-loss = 0.530304491519928, train/logprobs = tensor([[-2.3756, -3.3268],
        [-2.7739, -2.5524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1879510134458542
Epoch 0, Step 859: train/loss = 0.5858654975891113, train/raw-loss = 0.5356417298316956, train/logprobs = tensor([[-1.1923, -1.5986],
        [-1.8278, -1.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20089517533779144
Epoch 0, Step 860: train/loss = 0.7496218085289001, train/raw-loss = 0.7140849828720093, train/logprobs = tensor([[-1.3740, -1.3781],
        [-1.2908, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14214755594730377
Epoch 0, Step 861: train/loss = 0.5304229855537415, train/raw-loss = 0.4885537624359131, train/logprobs = tensor([[-1.1165, -1.7792],
        [-1.7420, -1.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16747690737247467
Epoch 0, Step 862: train/loss = 0.7169860005378723, train/raw-loss = 0.6589150428771973, train/logprobs = tensor([[-1.5180, -1.8628],
        [-1.7576, -1.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23228392004966736
Epoch 0, Step 863: train/loss = 0.6570155620574951, train/raw-loss = 0.6179536581039429, train/logprobs = tensor([[-1.6667, -1.6085],
        [-2.1806, -1.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15624772012233734
Epoch 0, Step 864: train/loss = 0.5304673910140991, train/raw-loss = 0.4723116457462311, train/logprobs = tensor([[-1.5806, -3.0633],
        [-2.0955, -2.5226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23262277245521545
Epoch 0, Step 865: train/loss = 0.7491085529327393, train/raw-loss = 0.696112334728241, train/logprobs = tensor([[-2.0872, -1.7212],
        [-1.9030, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21198508143424988
Epoch 0, Step 866: train/loss = 0.6972799897193909, train/raw-loss = 0.6664146184921265, train/logprobs = tensor([[-0.9911, -1.5318],
        [-0.8813, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12346151471138
Epoch 0, Step 867: train/loss = 0.5729860663414001, train/raw-loss = 0.529045820236206, train/logprobs = tensor([[-1.4427, -2.8367],
        [-1.7424, -2.2913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17576119303703308
Epoch 0, Step 868: train/loss = 0.40934935212135315, train/raw-loss = 0.359493613243103, train/logprobs = tensor([[-1.2411, -2.5065],
        [-2.6429, -1.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19942313432693481
Epoch 0, Step 869: train/loss = 0.5922791361808777, train/raw-loss = 0.5388987064361572, train/logprobs = tensor([[-1.7721, -2.5256],
        [-2.0640, -1.4783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21352174878120422
Epoch 0, Step 870: train/loss = 0.7125400304794312, train/raw-loss = 0.6702542304992676, train/logprobs = tensor([[-3.1670, -3.2437],
        [-2.7929, -2.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16914327442646027
Epoch 0, Step 871: train/loss = 0.5606955289840698, train/raw-loss = 0.5074795484542847, train/logprobs = tensor([[-1.2069, -2.0967],
        [-1.7746, -1.7921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21286392211914062
Epoch 0, Step 872: train/loss = 0.6815266013145447, train/raw-loss = 0.6434535980224609, train/logprobs = tensor([[-1.6067, -1.2796],
        [-1.6063, -0.8560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522921770811081
Epoch 0, Step 873: train/loss = 0.5615155696868896, train/raw-loss = 0.5095683336257935, train/logprobs = tensor([[-2.1022, -2.2836],
        [-2.9700, -2.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20778891444206238
Epoch 0, Step 874: train/loss = 0.64824378490448, train/raw-loss = 0.5929169654846191, train/logprobs = tensor([[-2.3610, -1.8160],
        [-3.1793, -1.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2213071584701538
Epoch 0, Step 875: train/loss = 0.666568398475647, train/raw-loss = 0.6138038635253906, train/logprobs = tensor([[-1.6681, -2.2267],
        [-1.5965, -1.5294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21105808019638062
Epoch 0, Step 876: train/loss = 0.6374617218971252, train/raw-loss = 0.5942181348800659, train/logprobs = tensor([[-1.7510, -1.6365],
        [-1.6116, -0.8453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17297427356243134
Epoch 0, Step 877: train/loss = 0.5199551582336426, train/raw-loss = 0.46457451581954956, train/logprobs = tensor([[-1.5655, -2.5338],
        [-2.2225, -1.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215225249528885
Epoch 0, Step 878: train/loss = 0.5189332365989685, train/raw-loss = 0.4769754409790039, train/logprobs = tensor([[-1.0451, -1.6873],
        [-1.5643, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.167831152677536
Epoch 0, Step 879: train/loss = 0.5189915895462036, train/raw-loss = 0.4735575020313263, train/logprobs = tensor([[-1.5459, -3.0382],
        [-1.9440, -2.3058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18173645436763763
Epoch 0, Step 880: train/loss = 0.629737377166748, train/raw-loss = 0.5864040851593018, train/logprobs = tensor([[-1.7161, -2.3427],
        [-1.7689, -1.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17333288490772247
Epoch 0, Step 881: train/loss = 0.7004045844078064, train/raw-loss = 0.6510463953018188, train/logprobs = tensor([[-2.3528, -3.0860],
        [-1.8155, -1.9444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1974327564239502
Epoch 0, Step 882: train/loss = 0.6801747679710388, train/raw-loss = 0.6250724196434021, train/logprobs = tensor([[-1.6641, -2.2214],
        [-2.0629, -2.2683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2204093337059021
Epoch 0, Step 883: train/loss = 0.7418328523635864, train/raw-loss = 0.6823705434799194, train/logprobs = tensor([[-1.6537, -1.4480],
        [-1.4986, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23784929513931274
Epoch 0, Step 884: train/loss = 0.6536041498184204, train/raw-loss = 0.6048815846443176, train/logprobs = tensor([[-2.2239, -4.3961],
        [-1.7458, -2.5748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19489017128944397
Epoch 0, Step 885: train/loss = 0.6240043044090271, train/raw-loss = 0.5737177133560181, train/logprobs = tensor([[-1.7830, -2.1321],
        [-2.2040, -1.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20114612579345703
Epoch 0, Step 886: train/loss = 0.677780270576477, train/raw-loss = 0.6307097673416138, train/logprobs = tensor([[-2.0533, -2.0903],
        [-1.8784, -1.2120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18828201293945312
Epoch 0, Step 887: train/loss = 0.7316442131996155, train/raw-loss = 0.680881679058075, train/logprobs = tensor([[-1.8263, -1.7521],
        [-1.4916, -1.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20305024087429047
Epoch 0, Step 888: train/loss = 0.37344375252723694, train/raw-loss = 0.3288263976573944, train/logprobs = tensor([[-1.7875, -3.8542],
        [-2.7304, -1.8229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17846934497356415
Epoch 0, Step 889: train/loss = 0.6149991750717163, train/raw-loss = 0.5710394382476807, train/logprobs = tensor([[-1.3136, -1.6404],
        [-1.9943, -1.5745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17583909630775452
Epoch 0, Step 890: train/loss = 0.5855953097343445, train/raw-loss = 0.535412073135376, train/logprobs = tensor([[-1.2196, -2.2550],
        [-1.4405, -1.3241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2007327526807785
Epoch 0, Step 891: train/loss = 0.766569197177887, train/raw-loss = 0.7038720846176147, train/logprobs = tensor([[-1.9042, -2.2316],
        [-2.1646, -2.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2507886290550232
Epoch 0, Step 892: train/loss = 0.6862925291061401, train/raw-loss = 0.6310908794403076, train/logprobs = tensor([[-1.5963, -1.6328],
        [-1.8504, -1.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22080647945404053
Epoch 0, Step 893: train/loss = 0.565707802772522, train/raw-loss = 0.5216951370239258, train/logprobs = tensor([[-1.7388, -2.6109],
        [-1.9551, -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17605063319206238
Epoch 0, Step 894: train/loss = 0.571366012096405, train/raw-loss = 0.5284419655799866, train/logprobs = tensor([[-1.1327, -2.2913],
        [-1.4616, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17169606685638428
Epoch 0, Step 895: train/loss = 0.688849925994873, train/raw-loss = 0.6544820070266724, train/logprobs = tensor([[-1.6546, -1.7191],
        [-1.6087, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13747188448905945
Epoch 0, Step 896: train/loss = 0.48954305052757263, train/raw-loss = 0.42784133553504944, train/logprobs = tensor([[-0.8634, -2.1852],
        [-2.3042, -1.5777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2468070536851883
Epoch 0, Step 897: train/loss = 0.7030884027481079, train/raw-loss = 0.6504496335983276, train/logprobs = tensor([[-2.2890, -2.4895],
        [-2.0362, -1.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21055510640144348
Epoch 0, Step 898: train/loss = 0.4458402991294861, train/raw-loss = 0.3965546488761902, train/logprobs = tensor([[-1.0564, -1.7152],
        [-2.5034, -1.3471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19714252650737762
Epoch 0, Step 899: train/loss = 0.37226802110671997, train/raw-loss = 0.3111107647418976, train/logprobs = tensor([[-1.7175, -4.0921],
        [-2.8806, -2.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24462898075580597
Epoch 0, Step 900: train/loss = 0.7633295059204102, train/raw-loss = 0.7161953449249268, train/logprobs = tensor([[-2.4134, -2.5669],
        [-2.1248, -2.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18853656947612762
Epoch 0, Step 901: train/loss = 0.5288649797439575, train/raw-loss = 0.48365268111228943, train/logprobs = tensor([[-2.5577, -3.5432],
        [-3.0715, -2.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1808490753173828
Epoch 0, Step 902: train/loss = 0.784020721912384, train/raw-loss = 0.7378859519958496, train/logprobs = tensor([[-3.0542, -2.6954],
        [-2.6987, -2.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18453897535800934
Epoch 0, Step 903: train/loss = 0.6111899018287659, train/raw-loss = 0.5679754018783569, train/logprobs = tensor([[-1.1591, -1.2443],
        [-1.6422, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1728581041097641
Epoch 0, Step 904: train/loss = 0.6626447439193726, train/raw-loss = 0.6218445897102356, train/logprobs = tensor([[-2.3898, -1.3878],
        [-2.3346, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16320064663887024
Epoch 0, Step 905: train/loss = 0.47339704632759094, train/raw-loss = 0.4293048083782196, train/logprobs = tensor([[-1.3905, -1.8073],
        [-2.4973, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17636911571025848
Epoch 0, Step 906: train/loss = 0.6388300657272339, train/raw-loss = 0.5798957347869873, train/logprobs = tensor([[-1.6655, -3.4142],
        [-1.9954, -2.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2357371300458908
Epoch 0, Step 907: train/loss = 0.7493175268173218, train/raw-loss = 0.6933988332748413, train/logprobs = tensor([[-1.5170, -3.0622],
        [-1.3867, -2.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2236747145652771
Epoch 0, Step 908: train/loss = 0.5959651470184326, train/raw-loss = 0.5370316505432129, train/logprobs = tensor([[-1.9723, -2.3482],
        [-2.2040, -1.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23573413491249084
Epoch 0, Step 909: train/loss = 0.47704529762268066, train/raw-loss = 0.43552225828170776, train/logprobs = tensor([[-0.7709, -2.3445],
        [-1.4043, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1660923957824707
Epoch 0, Step 910: train/loss = 0.7203075885772705, train/raw-loss = 0.6794736385345459, train/logprobs = tensor([[-2.1636, -1.9741],
        [-1.8382, -1.5522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1633356660604477
Epoch 0, Step 911: train/loss = 0.6342059373855591, train/raw-loss = 0.5693725347518921, train/logprobs = tensor([[-1.7339, -2.3712],
        [-1.9251, -1.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2593334913253784
Epoch 0, Step 912: train/loss = 0.5010294914245605, train/raw-loss = 0.4499126970767975, train/logprobs = tensor([[-2.1505, -2.3488],
        [-3.4220, -1.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20446711778640747
Epoch 0, Step 913: train/loss = 0.3438918888568878, train/raw-loss = 0.2945384979248047, train/logprobs = tensor([[-1.3029, -5.5249],
        [-2.5895, -3.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19741366803646088
Epoch 0, Step 914: train/loss = 0.46666407585144043, train/raw-loss = 0.40505558252334595, train/logprobs = tensor([[-1.1413, -2.9480],
        [-2.3889, -1.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2464340627193451
Epoch 0, Step 915: train/loss = 0.4839373826980591, train/raw-loss = 0.4237421154975891, train/logprobs = tensor([[-1.6537, -3.7765],
        [-2.0516, -1.7914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2407810091972351
Epoch 0, Step 916: train/loss = 0.6670007109642029, train/raw-loss = 0.6155771613121033, train/logprobs = tensor([[-1.2574, -2.9232],
        [-2.5745, -2.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20569434762001038
Epoch 0, Step 917: train/loss = 0.7380989789962769, train/raw-loss = 0.6783725619316101, train/logprobs = tensor([[-2.5747, -2.7933],
        [-2.3459, -2.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23890584707260132
Epoch 0, Step 918: train/loss = 0.7000648975372314, train/raw-loss = 0.6337719559669495, train/logprobs = tensor([[-1.4378, -2.0595],
        [-2.0985, -2.3781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26517170667648315
Epoch 0, Step 919: train/loss = 0.6281958222389221, train/raw-loss = 0.5763066411018372, train/logprobs = tensor([[-1.3754, -2.1275],
        [-1.5259, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20755667984485626
Epoch 0, Step 920: train/loss = 0.5724143385887146, train/raw-loss = 0.5131950974464417, train/logprobs = tensor([[-1.7131, -2.2650],
        [-3.6273, -2.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23687689006328583
Epoch 0, Step 921: train/loss = 0.6327314376831055, train/raw-loss = 0.5940648317337036, train/logprobs = tensor([[-0.9398, -1.6037],
        [-1.5735, -1.7134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1546666920185089
Epoch 0, Step 922: train/loss = 0.5639723539352417, train/raw-loss = 0.5011155009269714, train/logprobs = tensor([[-1.7236, -2.8428],
        [-2.6002, -2.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25142723321914673
Epoch 0, Step 923: train/loss = 0.5733505487442017, train/raw-loss = 0.521990180015564, train/logprobs = tensor([[-2.0983, -3.3372],
        [-2.4222, -2.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2054414302110672
Epoch 0, Step 924: train/loss = 0.5364875793457031, train/raw-loss = 0.49750450253486633, train/logprobs = tensor([[-0.4509, -1.2303],
        [-1.3121, -0.7937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15593227744102478
Epoch 0, Step 925: train/loss = 0.6428205966949463, train/raw-loss = 0.5862112045288086, train/logprobs = tensor([[-2.1303, -2.0655],
        [-2.7349, -2.1446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22643762826919556
Epoch 0, Step 926: train/loss = 0.5306331515312195, train/raw-loss = 0.48024579882621765, train/logprobs = tensor([[-1.5022, -2.7504],
        [-2.1047, -2.2305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20154953002929688
Epoch 0, Step 927: train/loss = 0.3680689334869385, train/raw-loss = 0.30122387409210205, train/logprobs = tensor([[-1.4317, -2.7966],
        [-2.8218, -1.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673802971839905
Epoch 0, Step 928: train/loss = 0.5145784616470337, train/raw-loss = 0.4665011763572693, train/logprobs = tensor([[-1.4737, -1.9631],
        [-2.5853, -1.4195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1923089474439621
Epoch 0, Step 929: train/loss = 0.4234129786491394, train/raw-loss = 0.36470913887023926, train/logprobs = tensor([[-1.1706, -3.0346],
        [-2.3960, -2.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23481552302837372
Epoch 0, Step 930: train/loss = 0.6333250999450684, train/raw-loss = 0.5777361989021301, train/logprobs = tensor([[-2.1955, -1.6410],
        [-2.8756, -1.7190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22235575318336487
Epoch 0, Step 931: train/loss = 0.6230347156524658, train/raw-loss = 0.5676968097686768, train/logprobs = tensor([[-1.4983, -2.0201],
        [-2.3263, -1.7666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22135169804096222
Epoch 0, Step 932: train/loss = 0.729261040687561, train/raw-loss = 0.6817269921302795, train/logprobs = tensor([[-1.3764, -1.3818],
        [-1.3902, -1.2425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19013625383377075
Epoch 0, Step 933: train/loss = 0.6458616852760315, train/raw-loss = 0.6070497035980225, train/logprobs = tensor([[-0.7087, -0.8313],
        [-1.3279, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15524786710739136
Epoch 0, Step 934: train/loss = 0.616104006767273, train/raw-loss = 0.5457974672317505, train/logprobs = tensor([[-1.5235, -2.3951],
        [-1.9545, -2.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28122633695602417
Epoch 0, Step 935: train/loss = 0.8597626090049744, train/raw-loss = 0.8133068084716797, train/logprobs = tensor([[-1.5210, -1.0082],
        [-2.0024, -1.7005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18582355976104736
Epoch 0, Step 936: train/loss = 0.6563585996627808, train/raw-loss = 0.605452299118042, train/logprobs = tensor([[-1.1405, -1.3457],
        [-1.3147, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20362529158592224
Epoch 0, Step 937: train/loss = 0.45064905285835266, train/raw-loss = 0.40907907485961914, train/logprobs = tensor([[-0.6533, -3.3400],
        [-1.5493, -1.7496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662798821926117
Epoch 0, Step 938: train/loss = 0.7734087109565735, train/raw-loss = 0.7117666006088257, train/logprobs = tensor([[-2.0632, -2.3506],
        [-1.8493, -1.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24656863510608673
Epoch 0, Step 939: train/loss = 0.7129390239715576, train/raw-loss = 0.6497422456741333, train/logprobs = tensor([[-1.6699, -1.6461],
        [-1.6195, -1.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2527872323989868
Epoch 0, Step 940: train/loss = 0.5532974004745483, train/raw-loss = 0.4986411929130554, train/logprobs = tensor([[-1.6118, -2.5295],
        [-2.7540, -2.3162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2186247706413269
Epoch 0, Step 941: train/loss = 0.5788511633872986, train/raw-loss = 0.5271623134613037, train/logprobs = tensor([[-2.3956, -3.0314],
        [-2.6792, -2.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20675528049468994
Epoch 0, Step 942: train/loss = 0.7574564218521118, train/raw-loss = 0.7113490700721741, train/logprobs = tensor([[-1.8399, -2.0473],
        [-2.0251, -2.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1844293773174286
Epoch 0, Step 943: train/loss = 0.3334687650203705, train/raw-loss = 0.2852313816547394, train/logprobs = tensor([[-0.8536, -2.9117],
        [-2.3651, -1.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1929495632648468
Epoch 0, Step 944: train/loss = 0.6058864593505859, train/raw-loss = 0.549411416053772, train/logprobs = tensor([[-0.9286, -1.0650],
        [-2.7321, -1.6665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259002923965454
Epoch 0, Step 945: train/loss = 0.6088281869888306, train/raw-loss = 0.5515011548995972, train/logprobs = tensor([[-0.9725, -1.6349],
        [-2.0548, -1.6861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22930790483951569
Epoch 0, Step 946: train/loss = 0.7294900417327881, train/raw-loss = 0.6711809635162354, train/logprobs = tensor([[-2.1332, -2.2771],
        [-2.6290, -2.3479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23323625326156616
Epoch 0, Step 947: train/loss = 0.7376622557640076, train/raw-loss = 0.6891007423400879, train/logprobs = tensor([[-2.8492, -3.4540],
        [-2.8336, -3.3095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1942460983991623
Epoch 0, Step 948: train/loss = 0.5631370544433594, train/raw-loss = 0.5072276592254639, train/logprobs = tensor([[-1.5023, -2.4769],
        [-2.3944, -1.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22363734245300293
Epoch 0, Step 949: train/loss = 0.6447504758834839, train/raw-loss = 0.6072043180465698, train/logprobs = tensor([[-1.8770, -2.4565],
        [-1.6933, -1.5093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15018469095230103
Epoch 0, Step 950: train/loss = 0.6767624616622925, train/raw-loss = 0.6286911368370056, train/logprobs = tensor([[-1.9353, -2.1646],
        [-2.0880, -1.9207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19228538870811462
Epoch 0, Step 951: train/loss = 0.4381028711795807, train/raw-loss = 0.38218408823013306, train/logprobs = tensor([[-0.8688, -4.1805],
        [-2.3270, -2.0573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22367531061172485
Epoch 0, Step 952: train/loss = 0.668912947177887, train/raw-loss = 0.6059025526046753, train/logprobs = tensor([[-3.1583, -4.7209],
        [-2.7850, -3.1081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2520413100719452
Epoch 0, Step 953: train/loss = 0.7731459736824036, train/raw-loss = 0.7230830192565918, train/logprobs = tensor([[-1.9297, -1.6446],
        [-2.0170, -1.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20025156438350677
Epoch 0, Step 954: train/loss = 0.5044524669647217, train/raw-loss = 0.44950199127197266, train/logprobs = tensor([[-1.2205, -2.5056],
        [-1.8390, -1.0276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2198018878698349
Epoch 0, Step 955: train/loss = 0.6833689212799072, train/raw-loss = 0.635369598865509, train/logprobs = tensor([[-1.8325, -2.4434],
        [-1.8350, -1.8774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19199725985527039
Epoch 0, Step 956: train/loss = 0.7213207483291626, train/raw-loss = 0.6611743569374084, train/logprobs = tensor([[-1.8820, -4.0539],
        [-3.0265, -4.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24058562517166138
Epoch 0, Step 957: train/loss = 0.7236497402191162, train/raw-loss = 0.6785794496536255, train/logprobs = tensor([[-1.0903, -0.8538],
        [-2.0513, -1.5011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18028122186660767
Epoch 0, Step 958: train/loss = 0.5044722557067871, train/raw-loss = 0.43518030643463135, train/logprobs = tensor([[-1.6889, -3.8015],
        [-2.7922, -2.6454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27716773748397827
Epoch 0, Step 959: train/loss = 0.6060364246368408, train/raw-loss = 0.5513550639152527, train/logprobs = tensor([[-2.2632, -3.9656],
        [-2.5186, -2.2340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21872538328170776
Epoch 0, Step 960: train/loss = 0.5474039912223816, train/raw-loss = 0.47557079792022705, train/logprobs = tensor([[-2.0000, -3.5925],
        [-2.4435, -2.6759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28733277320861816
Epoch 0, Step 961: train/loss = 0.7429055571556091, train/raw-loss = 0.6844584345817566, train/logprobs = tensor([[-1.8999, -2.0914],
        [-2.3230, -2.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23378853499889374
Epoch 0, Step 962: train/loss = 0.4452818036079407, train/raw-loss = 0.3815975785255432, train/logprobs = tensor([[-1.5017, -3.8734],
        [-2.4295, -2.6793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.254736989736557
Epoch 0, Step 963: train/loss = 0.5139006972312927, train/raw-loss = 0.4505605399608612, train/logprobs = tensor([[-1.9147, -3.0443],
        [-2.9125, -1.8335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2533605098724365
Epoch 0, Step 964: train/loss = 0.5327423810958862, train/raw-loss = 0.4632183313369751, train/logprobs = tensor([[-0.8256, -3.2320],
        [-2.1227, -1.7833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2780963182449341
Epoch 0, Step 965: train/loss = 0.6032328009605408, train/raw-loss = 0.5323600769042969, train/logprobs = tensor([[-2.3737, -4.2441],
        [-2.8256, -3.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28349071741104126
Epoch 0, Step 966: train/loss = 0.43091881275177, train/raw-loss = 0.36682993173599243, train/logprobs = tensor([[-1.1194, -3.8964],
        [-2.3272, -1.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25635549426078796
Epoch 0, Step 967: train/loss = 0.5596773624420166, train/raw-loss = 0.4925873279571533, train/logprobs = tensor([[-2.0425, -3.5696],
        [-2.5110, -2.3957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26836010813713074
Epoch 0, Step 968: train/loss = 0.5328046083450317, train/raw-loss = 0.47647595405578613, train/logprobs = tensor([[-1.8299, -3.8757],
        [-2.9973, -2.4889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253146469593048
Epoch 0, Step 969: train/loss = 0.7510170936584473, train/raw-loss = 0.7013726830482483, train/logprobs = tensor([[-1.4379, -0.7623],
        [-2.3849, -1.4152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1985776424407959
Epoch 0, Step 970: train/loss = 0.8475000262260437, train/raw-loss = 0.7949507832527161, train/logprobs = tensor([[-2.8314, -1.9554],
        [-2.8889, -1.9311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21019692718982697
Epoch 0, Step 971: train/loss = 0.19141004979610443, train/raw-loss = 0.12874771654605865, train/logprobs = tensor([[-1.1953, -5.4375],
        [-3.7666, -1.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506493330001831
Epoch 0, Step 972: train/loss = 0.7795966863632202, train/raw-loss = 0.7295656800270081, train/logprobs = tensor([[-1.7874, -0.9434],
        [-1.9323, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20012421905994415
Epoch 0, Step 973: train/loss = 0.5586462020874023, train/raw-loss = 0.5118322372436523, train/logprobs = tensor([[-1.2045, -2.3457],
        [-1.3168, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18725571036338806
Epoch 0, Step 974: train/loss = 0.6173054575920105, train/raw-loss = 0.5583840012550354, train/logprobs = tensor([[-1.2435, -1.9426],
        [-2.9128, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23568585515022278
Epoch 0, Step 975: train/loss = 0.741631031036377, train/raw-loss = 0.6710904836654663, train/logprobs = tensor([[-1.6395, -1.9693],
        [-2.8320, -2.6021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28216224908828735
Epoch 0, Step 976: train/loss = 0.5706988573074341, train/raw-loss = 0.5006486177444458, train/logprobs = tensor([[-1.3596, -2.4124],
        [-2.1441, -1.8987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2802009582519531
Epoch 0, Step 977: train/loss = 0.6327136754989624, train/raw-loss = 0.5698561668395996, train/logprobs = tensor([[-2.1331, -3.6645],
        [-2.4229, -3.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25142985582351685
Epoch 0, Step 978: train/loss = 0.5756886005401611, train/raw-loss = 0.5250779986381531, train/logprobs = tensor([[-2.2319, -2.3065],
        [-2.4540, -1.6748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20244261622428894
Epoch 0, Step 979: train/loss = 0.4993884563446045, train/raw-loss = 0.43784940242767334, train/logprobs = tensor([[-3.1495, -4.5697],
        [-3.3198, -3.1757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24615609645843506
Epoch 0, Step 980: train/loss = 0.6316771507263184, train/raw-loss = 0.5789823532104492, train/logprobs = tensor([[-1.2919, -1.9108],
        [-1.9047, -1.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21077921986579895
Epoch 0, Step 981: train/loss = 0.4883611798286438, train/raw-loss = 0.4350111484527588, train/logprobs = tensor([[-1.9910, -3.8397],
        [-2.2923, -2.2494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21340014040470123
Epoch 0, Step 982: train/loss = 0.7542643547058105, train/raw-loss = 0.7022240161895752, train/logprobs = tensor([[-2.0900, -2.2705],
        [-1.9110, -1.7664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20816123485565186
Epoch 0, Step 983: train/loss = 0.6999228596687317, train/raw-loss = 0.6423924565315247, train/logprobs = tensor([[-2.1963, -2.4053],
        [-2.0781, -2.0029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2301216870546341
Epoch 0, Step 984: train/loss = 0.651980996131897, train/raw-loss = 0.591877818107605, train/logprobs = tensor([[-2.4095, -3.3489],
        [-3.0287, -2.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2404126226902008
Epoch 0, Step 985: train/loss = 0.5380973815917969, train/raw-loss = 0.4713252782821655, train/logprobs = tensor([[-1.1459, -2.6111],
        [-2.2974, -2.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2670882046222687
Epoch 0, Step 986: train/loss = 0.7855534553527832, train/raw-loss = 0.7313989400863647, train/logprobs = tensor([[-0.9869, -1.3964],
        [-2.9837, -2.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21661794185638428
Epoch 0, Step 987: train/loss = 0.4265727996826172, train/raw-loss = 0.3768148720264435, train/logprobs = tensor([[-1.6480, -3.1185],
        [-2.4897, -1.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1990317404270172
Epoch 0, Step 988: train/loss = 0.5038363933563232, train/raw-loss = 0.4521108865737915, train/logprobs = tensor([[-2.0910, -2.6206],
        [-2.7894, -2.0141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20690208673477173
Epoch 0, Step 989: train/loss = 0.49602124094963074, train/raw-loss = 0.44530317187309265, train/logprobs = tensor([[-1.7858, -2.2372],
        [-2.8417, -1.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2028723955154419
Epoch 0, Step 990: train/loss = 0.6872831583023071, train/raw-loss = 0.6200442910194397, train/logprobs = tensor([[-3.7845, -3.8172],
        [-3.3301, -2.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2689558267593384
Epoch 0, Step 991: train/loss = 0.5530695915222168, train/raw-loss = 0.5021660923957825, train/logprobs = tensor([[-1.2233, -2.4061],
        [-2.1128, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2036140114068985
Epoch 0, Step 992: train/loss = 0.6659248471260071, train/raw-loss = 0.6050029993057251, train/logprobs = tensor([[-1.8819, -3.5213],
        [-1.4206, -1.6108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2436872124671936
Epoch 0, Step 993: train/loss = 0.6696407794952393, train/raw-loss = 0.6189213395118713, train/logprobs = tensor([[-1.6608, -1.9416],
        [-1.5797, -1.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20287789404392242
Epoch 0, Step 994: train/loss = 0.5275440812110901, train/raw-loss = 0.46404528617858887, train/logprobs = tensor([[-1.0892, -1.5673],
        [-2.2626, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25399503111839294
Epoch 0, Step 995: train/loss = 0.47405916452407837, train/raw-loss = 0.3975887894630432, train/logprobs = tensor([[-2.1434, -4.2404],
        [-3.1451, -3.0157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30588141083717346
Epoch 0, Step 996: train/loss = 0.5890412926673889, train/raw-loss = 0.5192185640335083, train/logprobs = tensor([[-1.1686, -3.7408],
        [-2.6139, -2.3613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27929097414016724
Epoch 0, Step 997: train/loss = 0.8427376747131348, train/raw-loss = 0.8003019094467163, train/logprobs = tensor([[-1.0892, -0.7772],
        [-3.3853, -2.3476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16974331438541412
Epoch 0, Step 998: train/loss = 0.5975551605224609, train/raw-loss = 0.5486318469047546, train/logprobs = tensor([[-2.0986, -2.5872],
        [-2.0221, -1.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1956932246685028
Epoch 0, Step 999: train/loss = 0.7094460725784302, train/raw-loss = 0.6544397473335266, train/logprobs = tensor([[-1.5649, -2.5997],
        [-1.6668, -2.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2200252115726471
eval/loss: 0.6035459637641907
Epoch 0, Step 1000: train/loss = 0.5547208189964294, train/raw-loss = 0.502485990524292, train/logprobs = tensor([[-1.0694, -1.7752],
        [-1.9696, -1.6103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20893949270248413
Epoch 0, Step 1001: train/loss = 0.8110898733139038, train/raw-loss = 0.748205840587616, train/logprobs = tensor([[-3.0234, -2.3557],
        [-2.5506, -1.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2515363395214081
Epoch 0, Step 1002: train/loss = 0.44136178493499756, train/raw-loss = 0.3838071823120117, train/logprobs = tensor([[-1.6426, -3.1121],
        [-2.4613, -1.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23021836578845978
Epoch 0, Step 1003: train/loss = 0.38685768842697144, train/raw-loss = 0.32881391048431396, train/logprobs = tensor([[-1.3244, -3.7494],
        [-2.5636, -1.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2321750670671463
Epoch 0, Step 1004: train/loss = 0.6403189301490784, train/raw-loss = 0.601139485836029, train/logprobs = tensor([[-1.5827, -0.9124],
        [-1.8234, -0.6019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1567177176475525
Epoch 0, Step 1005: train/loss = 0.514106273651123, train/raw-loss = 0.4582289159297943, train/logprobs = tensor([[-1.9711, -3.7822],
        [-2.4647, -2.3318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22350920736789703
Epoch 0, Step 1006: train/loss = 0.6703546047210693, train/raw-loss = 0.6196572184562683, train/logprobs = tensor([[-0.9946, -1.5207],
        [-1.1819, -1.3043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20278950035572052
Epoch 0, Step 1007: train/loss = 0.3960750102996826, train/raw-loss = 0.3410193622112274, train/logprobs = tensor([[-1.9753, -4.2571],
        [-3.4965, -2.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.220222607254982
Epoch 0, Step 1008: train/loss = 0.6902363896369934, train/raw-loss = 0.6224201917648315, train/logprobs = tensor([[-2.3536, -2.7607],
        [-2.6869, -2.2075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27126508951187134
Epoch 0, Step 1009: train/loss = 0.4887893795967102, train/raw-loss = 0.4377196431159973, train/logprobs = tensor([[-1.7810, -4.2597],
        [-2.0133, -1.9009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20427893102169037
Epoch 0, Step 1010: train/loss = 0.7461066842079163, train/raw-loss = 0.7013021111488342, train/logprobs = tensor([[-1.4854, -2.3164],
        [-1.2167, -1.5292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1792181432247162
Epoch 0, Step 1011: train/loss = 0.6231685280799866, train/raw-loss = 0.5586814880371094, train/logprobs = tensor([[-1.2812, -1.8436],
        [-2.1958, -1.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2579483091831207
Epoch 0, Step 1012: train/loss = 0.6771371364593506, train/raw-loss = 0.6242230534553528, train/logprobs = tensor([[-2.1070, -2.3196],
        [-2.2620, -1.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21165646612644196
Epoch 0, Step 1013: train/loss = 0.508567750453949, train/raw-loss = 0.46046021580696106, train/logprobs = tensor([[-2.6876, -3.7236],
        [-2.7266, -2.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19243039190769196
Epoch 0, Step 1014: train/loss = 0.59984290599823, train/raw-loss = 0.552803635597229, train/logprobs = tensor([[-2.0996, -3.1132],
        [-1.9268, -2.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18815705180168152
Epoch 0, Step 1015: train/loss = 0.5426046252250671, train/raw-loss = 0.4905150234699249, train/logprobs = tensor([[-1.4646, -2.2412],
        [-2.1897, -1.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2083582729101181
Epoch 0, Step 1016: train/loss = 0.7863195538520813, train/raw-loss = 0.7268049716949463, train/logprobs = tensor([[-2.6218, -2.0464],
        [-2.1071, -1.3343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23805806040763855
Epoch 0, Step 1017: train/loss = 0.6488742828369141, train/raw-loss = 0.5920264720916748, train/logprobs = tensor([[-3.2134, -3.7769],
        [-2.7502, -2.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22739127278327942
Epoch 0, Step 1018: train/loss = 0.737945556640625, train/raw-loss = 0.6841333508491516, train/logprobs = tensor([[-1.6686, -2.1490],
        [-1.7421, -1.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2152487337589264
Epoch 0, Step 1019: train/loss = 0.6617288589477539, train/raw-loss = 0.6080787181854248, train/logprobs = tensor([[-2.2177, -2.0328],
        [-2.2634, -1.5765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2146005779504776
Epoch 0, Step 1020: train/loss = 0.6305916905403137, train/raw-loss = 0.582266092300415, train/logprobs = tensor([[-2.3039, -3.7290],
        [-2.0467, -1.8941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19330254197120667
Epoch 0, Step 1021: train/loss = 0.6795918941497803, train/raw-loss = 0.6255816221237183, train/logprobs = tensor([[-2.1405, -1.5604],
        [-2.5123, -1.5805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21604110300540924
Epoch 0, Step 1022: train/loss = 0.8554530143737793, train/raw-loss = 0.8013107776641846, train/logprobs = tensor([[-2.3186, -1.9150],
        [-2.3769, -1.6394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21656882762908936
Epoch 0, Step 1023: train/loss = 0.6864884495735168, train/raw-loss = 0.6294693946838379, train/logprobs = tensor([[-1.6514, -1.6677],
        [-2.7090, -2.1348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22807642817497253
Epoch 0, Step 1024: train/loss = 0.5887467861175537, train/raw-loss = 0.5284762382507324, train/logprobs = tensor([[-2.2528, -3.5412],
        [-2.2372, -2.2477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24108217656612396
Epoch 0, Step 1025: train/loss = 0.5307899117469788, train/raw-loss = 0.473122775554657, train/logprobs = tensor([[-1.3668, -2.6748],
        [-1.9321, -1.6862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23066848516464233
Epoch 0, Step 1026: train/loss = 0.5587226748466492, train/raw-loss = 0.5066226124763489, train/logprobs = tensor([[-1.1754, -1.6235],
        [-1.6955, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20840047299861908
Epoch 0, Step 1027: train/loss = 0.6440800428390503, train/raw-loss = 0.5871137380599976, train/logprobs = tensor([[-3.3284, -3.8176],
        [-3.4252, -3.2675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2278653234243393
Epoch 0, Step 1028: train/loss = 0.7225908041000366, train/raw-loss = 0.6741825342178345, train/logprobs = tensor([[-2.8176, -5.0834],
        [-2.4468, -3.5220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19363316893577576
Epoch 0, Step 1029: train/loss = 0.6620177626609802, train/raw-loss = 0.6094762682914734, train/logprobs = tensor([[-2.2352, -2.2552],
        [-1.9579, -1.3794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21016600728034973
Epoch 0, Step 1030: train/loss = 0.8617181777954102, train/raw-loss = 0.8253562450408936, train/logprobs = tensor([[-3.2510, -4.1216],
        [-1.8457, -2.6068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1454479694366455
Epoch 0, Step 1031: train/loss = 0.6576876044273376, train/raw-loss = 0.6239217519760132, train/logprobs = tensor([[-1.1902, -2.3635],
        [-0.6274, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13506346940994263
Epoch 0, Step 1032: train/loss = 0.7469958662986755, train/raw-loss = 0.6883004903793335, train/logprobs = tensor([[-2.3133, -2.5997],
        [-2.4443, -2.4647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2347813844680786
Epoch 0, Step 1033: train/loss = 0.7470197677612305, train/raw-loss = 0.6835500597953796, train/logprobs = tensor([[-2.8851, -2.6103],
        [-2.1514, -1.5475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2538788616657257
Epoch 0, Step 1034: train/loss = 0.46781522035598755, train/raw-loss = 0.4202014207839966, train/logprobs = tensor([[-2.0012, -3.8873],
        [-2.3511, -2.1916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19045530259609222
Epoch 0, Step 1035: train/loss = 0.6357558369636536, train/raw-loss = 0.5894755125045776, train/logprobs = tensor([[-1.4704, -2.5382],
        [-1.4986, -2.0387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18512111902236938
Epoch 0, Step 1036: train/loss = 0.93100905418396, train/raw-loss = 0.8709616661071777, train/logprobs = tensor([[-3.1769, -2.9957],
        [-2.1566, -2.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24018943309783936
Epoch 0, Step 1037: train/loss = 0.7321326732635498, train/raw-loss = 0.7056128978729248, train/logprobs = tensor([[-2.0094, -2.0094],
        [-1.8897, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10607919842004776
Epoch 0, Step 1038: train/loss = 0.5412316918373108, train/raw-loss = 0.4950266480445862, train/logprobs = tensor([[-1.6261, -2.6465],
        [-1.6905, -1.4701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18482013046741486
Epoch 0, Step 1039: train/loss = 0.6152257919311523, train/raw-loss = 0.5622174739837646, train/logprobs = tensor([[-2.2279, -3.0694],
        [-1.6877, -1.0675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21203331649303436
Epoch 0, Step 1040: train/loss = 0.6722595691680908, train/raw-loss = 0.6213847398757935, train/logprobs = tensor([[-1.5993, -1.6629],
        [-1.8052, -1.4294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20349939167499542
Epoch 0, Step 1041: train/loss = 0.5055177211761475, train/raw-loss = 0.4490395188331604, train/logprobs = tensor([[-2.1815, -3.0907],
        [-2.9914, -1.5688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2259126901626587
Epoch 0, Step 1042: train/loss = 0.7206900715827942, train/raw-loss = 0.6712076663970947, train/logprobs = tensor([[-4.3406, -4.6383],
        [-4.1148, -4.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19792981445789337
Epoch 0, Step 1043: train/loss = 0.3694189786911011, train/raw-loss = 0.3165515065193176, train/logprobs = tensor([[-1.6573, -4.4948],
        [-2.6671, -2.5345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2114698588848114
Epoch 0, Step 1044: train/loss = 0.6840041279792786, train/raw-loss = 0.644145667552948, train/logprobs = tensor([[-3.4191, -4.4241],
        [-3.4584, -3.9259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1594339907169342
Epoch 0, Step 1045: train/loss = 0.6700543761253357, train/raw-loss = 0.6207085251808167, train/logprobs = tensor([[-1.8959, -2.0227],
        [-1.4132, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19738338887691498
Epoch 0, Step 1046: train/loss = 0.7246650457382202, train/raw-loss = 0.6683710813522339, train/logprobs = tensor([[-2.1941, -2.2006],
        [-2.0302, -1.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22517582774162292
Epoch 0, Step 1047: train/loss = 0.48548874258995056, train/raw-loss = 0.42767685651779175, train/logprobs = tensor([[-1.8357, -3.5829],
        [-2.7501, -1.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312474399805069
Epoch 0, Step 1048: train/loss = 0.3905467391014099, train/raw-loss = 0.3392137289047241, train/logprobs = tensor([[-2.3671, -4.0201],
        [-2.5971, -1.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053319215774536
Epoch 0, Step 1049: train/loss = 0.40342405438423157, train/raw-loss = 0.35504430532455444, train/logprobs = tensor([[-0.8989, -5.3359],
        [-1.8610, -3.9408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19351911544799805
Epoch 0, Step 1050: train/loss = 0.6221903562545776, train/raw-loss = 0.5658136010169983, train/logprobs = tensor([[-1.8811, -2.5175],
        [-2.1145, -1.8230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2255074679851532
Epoch 0, Step 1051: train/loss = 0.6463868618011475, train/raw-loss = 0.5894553661346436, train/logprobs = tensor([[-0.7076, -1.9577],
        [-1.4809, -2.0875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22772608697414398
Epoch 0, Step 1052: train/loss = 0.502985417842865, train/raw-loss = 0.4277940094470978, train/logprobs = tensor([[-2.3019, -4.0763],
        [-3.2925, -2.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007656931877136
Epoch 0, Step 1053: train/loss = 0.5927411317825317, train/raw-loss = 0.530453085899353, train/logprobs = tensor([[-1.8596, -1.9733],
        [-2.2319, -1.4799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24915222823619843
Epoch 0, Step 1054: train/loss = 0.7480572462081909, train/raw-loss = 0.7087490558624268, train/logprobs = tensor([[-1.0373, -0.6267],
        [-1.8367, -1.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1572326272726059
Epoch 0, Step 1055: train/loss = 0.5535467267036438, train/raw-loss = 0.5086857080459595, train/logprobs = tensor([[-2.3734, -3.1162],
        [-2.8980, -2.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17944397032260895
Epoch 0, Step 1056: train/loss = 0.6975164413452148, train/raw-loss = 0.6551792621612549, train/logprobs = tensor([[-1.4429, -1.4919],
        [-1.3662, -1.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16934873163700104
Epoch 0, Step 1057: train/loss = 0.5203381776809692, train/raw-loss = 0.46769410371780396, train/logprobs = tensor([[-1.8086, -5.3951],
        [-1.7004, -3.3474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21057607233524323
Epoch 0, Step 1058: train/loss = 0.65339595079422, train/raw-loss = 0.6055954098701477, train/logprobs = tensor([[-2.6526, -2.2413],
        [-2.4102, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19120202958583832
Epoch 0, Step 1059: train/loss = 0.6044304370880127, train/raw-loss = 0.566325306892395, train/logprobs = tensor([[-3.0155, -3.9225],
        [-2.7201, -2.5142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15242037177085876
Epoch 0, Step 1060: train/loss = 0.599388062953949, train/raw-loss = 0.5611953735351562, train/logprobs = tensor([[-0.6482, -3.3406],
        [-0.6828, -2.6641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15277083218097687
Epoch 0, Step 1061: train/loss = 0.5889426469802856, train/raw-loss = 0.5238691568374634, train/logprobs = tensor([[-1.8997, -2.9257],
        [-1.9472, -2.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2602939307689667
Epoch 0, Step 1062: train/loss = 0.7305499315261841, train/raw-loss = 0.6778686046600342, train/logprobs = tensor([[-1.9963, -2.0486],
        [-1.8731, -1.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21072523295879364
Epoch 0, Step 1063: train/loss = 0.5497745275497437, train/raw-loss = 0.49909237027168274, train/logprobs = tensor([[-0.9358, -2.9933],
        [-1.0706, -2.0323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2027285397052765
Epoch 0, Step 1064: train/loss = 0.5501998662948608, train/raw-loss = 0.49975788593292236, train/logprobs = tensor([[-1.6444, -4.0133],
        [-1.7894, -2.8235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2017679363489151
Epoch 0, Step 1065: train/loss = 0.6543940305709839, train/raw-loss = 0.6030917167663574, train/logprobs = tensor([[-2.1772, -3.0360],
        [-2.0140, -2.3937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20520928502082825
Epoch 0, Step 1066: train/loss = 0.7135931849479675, train/raw-loss = 0.6823891401290894, train/logprobs = tensor([[-1.4641, -0.9438],
        [-1.5151, -0.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1248164102435112
Epoch 0, Step 1067: train/loss = 0.518157422542572, train/raw-loss = 0.4646904468536377, train/logprobs = tensor([[-2.4733, -5.3398],
        [-2.3631, -3.3145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21386802196502686
Epoch 0, Step 1068: train/loss = 0.7031750082969666, train/raw-loss = 0.6682381629943848, train/logprobs = tensor([[-1.5183, -1.7125],
        [-1.5156, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13974736630916595
Epoch 0, Step 1069: train/loss = 0.6388628482818604, train/raw-loss = 0.5903563499450684, train/logprobs = tensor([[-1.6383, -1.1889],
        [-1.9964, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19402585923671722
Epoch 0, Step 1070: train/loss = 0.6447295546531677, train/raw-loss = 0.5856459140777588, train/logprobs = tensor([[-2.8042, -3.4129],
        [-2.5303, -2.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23633454740047455
Epoch 0, Step 1071: train/loss = 0.7760571241378784, train/raw-loss = 0.7139559388160706, train/logprobs = tensor([[-1.5647, -2.0348],
        [-1.3591, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2484048455953598
Epoch 0, Step 1072: train/loss = 0.6455528140068054, train/raw-loss = 0.59043288230896, train/logprobs = tensor([[-2.4155, -2.3504],
        [-2.6135, -1.3356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22047953307628632
Epoch 0, Step 1073: train/loss = 0.6242271661758423, train/raw-loss = 0.5641441345214844, train/logprobs = tensor([[-1.1621, -2.6249],
        [-1.5821, -2.3235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24033223092556
Epoch 0, Step 1074: train/loss = 0.4604584276676178, train/raw-loss = 0.39648398756980896, train/logprobs = tensor([[-1.5687, -4.3879],
        [-2.4572, -3.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25589773058891296
Epoch 0, Step 1075: train/loss = 0.6559975147247314, train/raw-loss = 0.6119378805160522, train/logprobs = tensor([[-1.2652, -1.6374],
        [-1.3362, -1.2375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17623835802078247
Epoch 0, Step 1076: train/loss = 0.8748127222061157, train/raw-loss = 0.8230278491973877, train/logprobs = tensor([[-3.2820, -2.3465],
        [-2.3497, -1.5953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20713955163955688
Epoch 0, Step 1077: train/loss = 0.5531913638114929, train/raw-loss = 0.5032466650009155, train/logprobs = tensor([[-1.6928, -2.1395],
        [-2.1551, -1.5379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19977891445159912
Epoch 0, Step 1078: train/loss = 0.6340129375457764, train/raw-loss = 0.5770664215087891, train/logprobs = tensor([[-2.0244, -2.8192],
        [-2.2267, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22778616845607758
Epoch 0, Step 1079: train/loss = 0.7361339330673218, train/raw-loss = 0.6886557936668396, train/logprobs = tensor([[-1.5276, -3.5480],
        [-1.3138, -3.1878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18991269171237946
Epoch 0, Step 1080: train/loss = 0.590848445892334, train/raw-loss = 0.539665937423706, train/logprobs = tensor([[-2.3353, -4.0544],
        [-2.0146, -2.5795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2047298699617386
Epoch 0, Step 1081: train/loss = 0.6048531532287598, train/raw-loss = 0.5483371019363403, train/logprobs = tensor([[-2.0800, -2.7040],
        [-1.8621, -1.6573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2260642945766449
Epoch 0, Step 1082: train/loss = 0.6758804321289062, train/raw-loss = 0.6271006464958191, train/logprobs = tensor([[-0.8254, -1.0666],
        [-1.0065, -0.9575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19511911273002625
Epoch 0, Step 1083: train/loss = 0.7231243848800659, train/raw-loss = 0.6741366386413574, train/logprobs = tensor([[-1.2893, -1.3987],
        [-1.3085, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19595088064670563
Epoch 0, Step 1084: train/loss = 0.6117313504219055, train/raw-loss = 0.5623914003372192, train/logprobs = tensor([[-1.2551, -1.8469],
        [-1.7980, -1.4498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1973598152399063
Epoch 0, Step 1085: train/loss = 0.6196426749229431, train/raw-loss = 0.5747884511947632, train/logprobs = tensor([[-1.7494, -3.2945],
        [-1.6258, -2.4323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1794167459011078
Epoch 0, Step 1086: train/loss = 0.5447296500205994, train/raw-loss = 0.5024389028549194, train/logprobs = tensor([[-0.7962, -1.8146],
        [-1.2433, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16916292905807495
Epoch 0, Step 1087: train/loss = 0.6399670839309692, train/raw-loss = 0.5937427878379822, train/logprobs = tensor([[-2.4809, -2.9745],
        [-2.5854, -2.5310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18489708006381989
Epoch 0, Step 1088: train/loss = 0.6456546783447266, train/raw-loss = 0.5844049453735352, train/logprobs = tensor([[-2.1581, -2.9558],
        [-2.5109, -2.5227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24499887228012085
Epoch 0, Step 1089: train/loss = 0.5440259575843811, train/raw-loss = 0.5034283995628357, train/logprobs = tensor([[-1.8120, -2.5487],
        [-2.2072, -1.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16239033639431
Epoch 0, Step 1090: train/loss = 0.6332077383995056, train/raw-loss = 0.5864092111587524, train/logprobs = tensor([[-1.7340, -3.4183],
        [-1.8911, -2.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18719390034675598
Epoch 0, Step 1091: train/loss = 0.693156898021698, train/raw-loss = 0.6353455781936646, train/logprobs = tensor([[-2.8354, -5.6806],
        [-2.2306, -4.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23124520480632782
Epoch 0, Step 1092: train/loss = 0.45759400725364685, train/raw-loss = 0.4111459255218506, train/logprobs = tensor([[-1.5781, -3.0752],
        [-2.8377, -2.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18579226732254028
Epoch 0, Step 1093: train/loss = 0.6198990345001221, train/raw-loss = 0.5622198581695557, train/logprobs = tensor([[-1.3085, -3.1198],
        [-1.3910, -2.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23071672022342682
Epoch 0, Step 1094: train/loss = 0.739025890827179, train/raw-loss = 0.6874030232429504, train/logprobs = tensor([[-1.5008, -1.4780],
        [-1.8524, -1.6125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2064916342496872
Epoch 0, Step 1095: train/loss = 0.5938374996185303, train/raw-loss = 0.5498396158218384, train/logprobs = tensor([[-2.2404, -3.2709],
        [-1.8985, -1.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17599144577980042
Epoch 0, Step 1096: train/loss = 0.4834918677806854, train/raw-loss = 0.4284023940563202, train/logprobs = tensor([[-1.5972, -5.4745],
        [-1.7951, -4.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2203577607870102
Epoch 0, Step 1097: train/loss = 0.7193684577941895, train/raw-loss = 0.6712789535522461, train/logprobs = tensor([[-2.4340, -3.6805],
        [-1.9999, -3.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19235780835151672
Epoch 0, Step 1098: train/loss = 0.6809269785881042, train/raw-loss = 0.6256809830665588, train/logprobs = tensor([[-2.2416, -1.8529],
        [-2.8333, -1.9396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2209841012954712
Epoch 0, Step 1099: train/loss = 0.6723292469978333, train/raw-loss = 0.6172008514404297, train/logprobs = tensor([[-1.3973, -2.3289],
        [-1.1847, -1.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2205137014389038
Epoch 0, Step 1100: train/loss = 0.6492327451705933, train/raw-loss = 0.5973155498504639, train/logprobs = tensor([[-1.9183, -2.3158],
        [-2.4028, -2.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20766879618167877
Epoch 0, Step 1101: train/loss = 0.5896127223968506, train/raw-loss = 0.5330824255943298, train/logprobs = tensor([[-1.5550, -4.7340],
        [-1.1669, -3.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22612106800079346
Epoch 0, Step 1102: train/loss = 0.7958025932312012, train/raw-loss = 0.734275221824646, train/logprobs = tensor([[-2.4176, -2.2439],
        [-2.1558, -2.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24610960483551025
Epoch 0, Step 1103: train/loss = 0.7803964018821716, train/raw-loss = 0.7320410013198853, train/logprobs = tensor([[-1.9879, -3.1550],
        [-1.7223, -2.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19342190027236938
Epoch 0, Step 1104: train/loss = 0.6679206490516663, train/raw-loss = 0.6321864128112793, train/logprobs = tensor([[-1.7624, -2.5433],
        [-1.4782, -1.6600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14293687045574188
Epoch 0, Step 1105: train/loss = 0.5944967269897461, train/raw-loss = 0.5567195415496826, train/logprobs = tensor([[-1.1437, -1.9335],
        [-1.3131, -1.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15110880136489868
Epoch 0, Step 1106: train/loss = 0.6472810506820679, train/raw-loss = 0.6034970879554749, train/logprobs = tensor([[-1.9427, -2.0642],
        [-1.7599, -1.2775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17513582110404968
Epoch 0, Step 1107: train/loss = 0.5579652190208435, train/raw-loss = 0.49511393904685974, train/logprobs = tensor([[-1.9905, -3.6306],
        [-2.2931, -2.5346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2514050602912903
Epoch 0, Step 1108: train/loss = 0.7290671467781067, train/raw-loss = 0.6679484248161316, train/logprobs = tensor([[-2.1586, -1.8798],
        [-2.1344, -1.6360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.244474858045578
Epoch 0, Step 1109: train/loss = 0.6778113842010498, train/raw-loss = 0.6163970828056335, train/logprobs = tensor([[-3.0971, -3.2821],
        [-2.8606, -2.3858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24565735459327698
Epoch 0, Step 1110: train/loss = 0.5766835808753967, train/raw-loss = 0.5390574336051941, train/logprobs = tensor([[-2.1726, -5.1506],
        [-2.3896, -4.5588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15050436556339264
Epoch 0, Step 1111: train/loss = 0.6193808317184448, train/raw-loss = 0.5784833431243896, train/logprobs = tensor([[-1.0348, -2.0505],
        [-1.3419, -1.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16358989477157593
Epoch 0, Step 1112: train/loss = 0.7948070764541626, train/raw-loss = 0.7290787100791931, train/logprobs = tensor([[-2.2921, -2.3135],
        [-2.1309, -2.2113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2629135847091675
Epoch 0, Step 1113: train/loss = 0.6154402494430542, train/raw-loss = 0.5754072070121765, train/logprobs = tensor([[-2.2029, -1.5116],
        [-2.7251, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1601322889328003
Epoch 0, Step 1114: train/loss = 0.6266670227050781, train/raw-loss = 0.5787637829780579, train/logprobs = tensor([[-1.7330, -2.0436],
        [-1.7058, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19161295890808105
Epoch 0, Step 1115: train/loss = 0.5783553123474121, train/raw-loss = 0.5254236459732056, train/logprobs = tensor([[-1.4458, -2.1320],
        [-1.8557, -1.6776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21172654628753662
Epoch 0, Step 1116: train/loss = 0.5861590504646301, train/raw-loss = 0.5426751375198364, train/logprobs = tensor([[-1.2980, -3.8070],
        [-1.4608, -2.8227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17393574118614197
Epoch 0, Step 1117: train/loss = 0.764235258102417, train/raw-loss = 0.7112904787063599, train/logprobs = tensor([[-2.6857, -2.4237],
        [-2.2940, -1.9611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21177925169467926
Epoch 0, Step 1118: train/loss = 0.6385930776596069, train/raw-loss = 0.5819805860519409, train/logprobs = tensor([[-1.5343, -2.9144],
        [-1.5496, -2.3284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22645017504692078
Epoch 0, Step 1119: train/loss = 0.6291884779930115, train/raw-loss = 0.5736329555511475, train/logprobs = tensor([[-1.6695, -1.8914],
        [-1.9349, -1.4951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2222222238779068
Epoch 0, Step 1120: train/loss = 0.6358328461647034, train/raw-loss = 0.5962204933166504, train/logprobs = tensor([[-1.6134, -1.4682],
        [-1.6515, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15844941139221191
Epoch 0, Step 1121: train/loss = 0.6677885055541992, train/raw-loss = 0.6273215413093567, train/logprobs = tensor([[-1.9334, -2.7691],
        [-1.5855, -2.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16186781227588654
Epoch 0, Step 1122: train/loss = 0.5621085166931152, train/raw-loss = 0.5125619173049927, train/logprobs = tensor([[-1.9938, -2.9281],
        [-2.6625, -2.5216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19818659126758575
Epoch 0, Step 1123: train/loss = 0.6247628331184387, train/raw-loss = 0.5937792062759399, train/logprobs = tensor([[-2.3869, -1.3257],
        [-2.4619, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12393469363451004
Epoch 0, Step 1124: train/loss = 0.7277405261993408, train/raw-loss = 0.6765941381454468, train/logprobs = tensor([[-1.5842, -2.2850],
        [-2.0877, -2.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20458564162254333
Epoch 0, Step 1125: train/loss = 0.6527807116508484, train/raw-loss = 0.6131911873817444, train/logprobs = tensor([[-0.8274, -0.7384],
        [-1.7138, -1.1310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15835797786712646
Epoch 0, Step 1126: train/loss = 0.6109157800674438, train/raw-loss = 0.552178144454956, train/logprobs = tensor([[-2.7383, -2.0021],
        [-3.2398, -1.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2349506914615631
Epoch 0, Step 1127: train/loss = 0.7089817523956299, train/raw-loss = 0.6576058864593506, train/logprobs = tensor([[-0.7908, -0.9817],
        [-1.5008, -1.3064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20550349354743958
Epoch 0, Step 1128: train/loss = 0.7806349396705627, train/raw-loss = 0.7215452194213867, train/logprobs = tensor([[-2.1394, -2.4095],
        [-1.9628, -2.2684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23635879158973694
Epoch 0, Step 1129: train/loss = 0.6493257880210876, train/raw-loss = 0.6025019884109497, train/logprobs = tensor([[-1.8092, -2.7671],
        [-2.0382, -2.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18729518353939056
Epoch 0, Step 1130: train/loss = 0.561055064201355, train/raw-loss = 0.519733726978302, train/logprobs = tensor([[-1.9271, -2.7993],
        [-2.0873, -1.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16528521478176117
Epoch 0, Step 1131: train/loss = 0.5489764213562012, train/raw-loss = 0.5078808069229126, train/logprobs = tensor([[-1.6968, -3.4983],
        [-2.0080, -2.4898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16438226401805878
Epoch 0, Step 1132: train/loss = 0.6305341124534607, train/raw-loss = 0.5804991126060486, train/logprobs = tensor([[-1.3372, -1.5375],
        [-1.7628, -1.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20013996958732605
Epoch 0, Step 1133: train/loss = 0.7275617122650146, train/raw-loss = 0.6966777443885803, train/logprobs = tensor([[-1.7731, -1.7801],
        [-1.6879, -1.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12353604286909103
Epoch 0, Step 1134: train/loss = 0.5532614588737488, train/raw-loss = 0.504514753818512, train/logprobs = tensor([[-2.1950, -2.9689],
        [-2.6944, -2.5215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1949867457151413
Epoch 0, Step 1135: train/loss = 0.5088680982589722, train/raw-loss = 0.46705353260040283, train/logprobs = tensor([[-1.2744, -2.2021],
        [-2.2347, -1.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16725826263427734
Epoch 0, Step 1136: train/loss = 0.5649770498275757, train/raw-loss = 0.521684467792511, train/logprobs = tensor([[-0.6772, -1.6781],
        [-1.4616, -1.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1731702983379364
Epoch 0, Step 1137: train/loss = 0.5788345336914062, train/raw-loss = 0.5235568881034851, train/logprobs = tensor([[-0.7978, -2.7363],
        [-2.0102, -2.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22111041843891144
Epoch 0, Step 1138: train/loss = 0.750501811504364, train/raw-loss = 0.6937595009803772, train/logprobs = tensor([[-0.9555, -1.4136],
        [-1.9473, -2.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22696897387504578
Epoch 0, Step 1139: train/loss = 0.692882239818573, train/raw-loss = 0.6618636846542358, train/logprobs = tensor([[-1.7655, -2.0656],
        [-1.7520, -1.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12407414615154266
Epoch 0, Step 1140: train/loss = 0.7213366627693176, train/raw-loss = 0.6739014983177185, train/logprobs = tensor([[-0.6814, -4.0436],
        [-1.4007, -4.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18974082171916962
Epoch 0, Step 1141: train/loss = 0.6084778308868408, train/raw-loss = 0.5582337975502014, train/logprobs = tensor([[-1.7402, -2.8178],
        [-1.8172, -1.8836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20097613334655762
Epoch 0, Step 1142: train/loss = 0.6772263050079346, train/raw-loss = 0.6254348754882812, train/logprobs = tensor([[-2.1945, -2.9001],
        [-2.9009, -3.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20716577768325806
Epoch 0, Step 1143: train/loss = 0.4086517095565796, train/raw-loss = 0.3542012870311737, train/logprobs = tensor([[-0.8628, -3.2152],
        [-2.2872, -1.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21780160069465637
Epoch 0, Step 1144: train/loss = 0.7651433348655701, train/raw-loss = 0.7149789929389954, train/logprobs = tensor([[-2.9091, -2.4037],
        [-3.1559, -2.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20065739750862122
Epoch 0, Step 1145: train/loss = 0.5428693294525146, train/raw-loss = 0.4981415271759033, train/logprobs = tensor([[-1.0528, -1.8499],
        [-2.7706, -1.8897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17891131341457367
Epoch 0, Step 1146: train/loss = 0.5670643448829651, train/raw-loss = 0.5336595773696899, train/logprobs = tensor([[-1.7020, -1.7489],
        [-1.9791, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1336193084716797
Epoch 0, Step 1147: train/loss = 0.7195892930030823, train/raw-loss = 0.6692814826965332, train/logprobs = tensor([[-1.1679, -0.8225],
        [-2.1452, -1.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20123080909252167
Epoch 0, Step 1148: train/loss = 0.6276349425315857, train/raw-loss = 0.5639094710350037, train/logprobs = tensor([[-2.0154, -2.2728],
        [-2.9730, -2.3636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2549018859863281
Epoch 0, Step 1149: train/loss = 0.49958232045173645, train/raw-loss = 0.4668118953704834, train/logprobs = tensor([[-2.1380, -2.9755],
        [-2.8090, -1.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13108158111572266
Epoch 0, Step 1150: train/loss = 0.615323543548584, train/raw-loss = 0.5610227584838867, train/logprobs = tensor([[-1.5685, -2.3376],
        [-2.0749, -2.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2172033041715622
Epoch 0, Step 1151: train/loss = 0.6347805261611938, train/raw-loss = 0.5834202170372009, train/logprobs = tensor([[-2.0713, -3.0185],
        [-2.4796, -2.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20544102787971497
Epoch 0, Step 1152: train/loss = 0.784632682800293, train/raw-loss = 0.7288065552711487, train/logprobs = tensor([[-1.0397, -1.0908],
        [-1.5517, -1.6486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2233046442270279
Epoch 0, Step 1153: train/loss = 0.6219236254692078, train/raw-loss = 0.5619001388549805, train/logprobs = tensor([[-0.8516, -1.6627],
        [-1.7154, -1.7095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24009421467781067
Epoch 0, Step 1154: train/loss = 0.4502071440219879, train/raw-loss = 0.41275113821029663, train/logprobs = tensor([[-1.1534, -1.7221],
        [-3.2409, -1.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1498240828514099
Epoch 0, Step 1155: train/loss = 0.7812840342521667, train/raw-loss = 0.7225245237350464, train/logprobs = tensor([[-1.9961, -2.5366],
        [-2.4961, -3.0566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2350381314754486
Epoch 0, Step 1156: train/loss = 0.5098797082901001, train/raw-loss = 0.46244916319847107, train/logprobs = tensor([[-1.3274, -2.9734],
        [-2.5362, -1.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1897222399711609
Epoch 0, Step 1157: train/loss = 0.7541958689689636, train/raw-loss = 0.6969192028045654, train/logprobs = tensor([[-1.4329, -1.7544],
        [-2.2272, -2.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22910645604133606
Epoch 0, Step 1158: train/loss = 0.6218650937080383, train/raw-loss = 0.5857598781585693, train/logprobs = tensor([[-1.6984, -1.9970],
        [-2.8493, -2.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1444208174943924
Epoch 0, Step 1159: train/loss = 0.6263343095779419, train/raw-loss = 0.5809142589569092, train/logprobs = tensor([[-1.2998, -1.8545],
        [-1.6875, -1.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18168039619922638
Epoch 0, Step 1160: train/loss = 0.7005504369735718, train/raw-loss = 0.6511921882629395, train/logprobs = tensor([[-2.2016, -1.6259],
        [-2.2431, -1.4612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19743287563323975
Epoch 0, Step 1161: train/loss = 0.7573542594909668, train/raw-loss = 0.7164257764816284, train/logprobs = tensor([[-0.7139, -0.9732],
        [-1.0595, -1.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16371390223503113
Epoch 0, Step 1162: train/loss = 0.6551409959793091, train/raw-loss = 0.600989818572998, train/logprobs = tensor([[-2.4689, -2.7193],
        [-3.2004, -2.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21660515666007996
Epoch 0, Step 1163: train/loss = 0.7803765535354614, train/raw-loss = 0.7354889512062073, train/logprobs = tensor([[-1.9658, -2.7161],
        [-1.8739, -2.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17955024540424347
Epoch 0, Step 1164: train/loss = 0.5518081784248352, train/raw-loss = 0.5086552500724792, train/logprobs = tensor([[-0.9157, -1.4828],
        [-1.9406, -1.4248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17261174321174622
Epoch 0, Step 1165: train/loss = 0.5417787432670593, train/raw-loss = 0.49813249707221985, train/logprobs = tensor([[-1.8561, -3.6750],
        [-2.5679, -2.9409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1745849847793579
Epoch 0, Step 1166: train/loss = 0.49750739336013794, train/raw-loss = 0.45177161693573, train/logprobs = tensor([[-1.7311, -2.7822],
        [-2.2762, -2.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18294289708137512
Epoch 0, Step 1167: train/loss = 0.7008931040763855, train/raw-loss = 0.6570726633071899, train/logprobs = tensor([[-1.2889, -1.1488],
        [-2.1410, -1.6373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17528186738491058
Epoch 0, Step 1168: train/loss = 0.7416213750839233, train/raw-loss = 0.7020533084869385, train/logprobs = tensor([[-2.2195, -1.4456],
        [-2.2371, -1.3964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15827259421348572
Epoch 0, Step 1169: train/loss = 0.6519466638565063, train/raw-loss = 0.6102983951568604, train/logprobs = tensor([[-1.3830, -1.8656],
        [-2.3125, -2.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16659292578697205
Epoch 0, Step 1170: train/loss = 0.5314948558807373, train/raw-loss = 0.48253852128982544, train/logprobs = tensor([[-1.2777, -1.5968],
        [-2.0488, -1.3250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19582556188106537
Epoch 0, Step 1171: train/loss = 0.37600311636924744, train/raw-loss = 0.31807824969291687, train/logprobs = tensor([[-1.3972, -3.5679],
        [-3.2312, -2.2116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23169931769371033
Epoch 0, Step 1172: train/loss = 0.5339555740356445, train/raw-loss = 0.49563202261924744, train/logprobs = tensor([[-1.1864, -2.5182],
        [-1.8871, -2.0423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15329423546791077
Epoch 0, Step 1173: train/loss = 0.7689405679702759, train/raw-loss = 0.731663167476654, train/logprobs = tensor([[-1.6267, -1.7722],
        [-1.8126, -1.9156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14910979568958282
Epoch 0, Step 1174: train/loss = 0.5903185606002808, train/raw-loss = 0.5483645796775818, train/logprobs = tensor([[-1.6969, -2.0138],
        [-1.9144, -1.5350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16781577467918396
Epoch 0, Step 1175: train/loss = 0.7519354820251465, train/raw-loss = 0.6980314254760742, train/logprobs = tensor([[-1.6519, -2.2601],
        [-2.3976, -2.5728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21561622619628906
Epoch 0, Step 1176: train/loss = 0.6557444930076599, train/raw-loss = 0.6084292531013489, train/logprobs = tensor([[-1.8970, -1.8499],
        [-2.2475, -1.7918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1892608404159546
Epoch 0, Step 1177: train/loss = 0.7995176315307617, train/raw-loss = 0.747119665145874, train/logprobs = tensor([[-1.7430, -1.9979],
        [-2.0975, -2.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20959170162677765
Epoch 0, Step 1178: train/loss = 0.7962525486946106, train/raw-loss = 0.7493178844451904, train/logprobs = tensor([[-1.9425, -2.2519],
        [-2.0951, -2.5783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18773864209651947
Epoch 0, Step 1179: train/loss = 0.7035077214241028, train/raw-loss = 0.6527737379074097, train/logprobs = tensor([[-1.8851, -1.6685],
        [-2.4351, -1.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20293587446212769
Epoch 0, Step 1180: train/loss = 0.7441097497940063, train/raw-loss = 0.6890283823013306, train/logprobs = tensor([[-1.8343, -1.4144],
        [-2.2853, -1.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2203255593776703
Epoch 0, Step 1181: train/loss = 0.6144000887870789, train/raw-loss = 0.5720677971839905, train/logprobs = tensor([[-1.2792, -1.6628],
        [-1.8822, -1.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16932933032512665
Epoch 0, Step 1182: train/loss = 0.5131762623786926, train/raw-loss = 0.454897940158844, train/logprobs = tensor([[-0.9703, -2.2378],
        [-2.2266, -1.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23311322927474976
Epoch 0, Step 1183: train/loss = 0.8065208792686462, train/raw-loss = 0.7603459358215332, train/logprobs = tensor([[-2.3322, -1.5076],
        [-2.3681, -1.7146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18469968438148499
Epoch 0, Step 1184: train/loss = 0.5386437177658081, train/raw-loss = 0.49355483055114746, train/logprobs = tensor([[-1.5787, -2.4298],
        [-2.8554, -2.4473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18035537004470825
Epoch 0, Step 1185: train/loss = 0.7277960777282715, train/raw-loss = 0.688300371170044, train/logprobs = tensor([[-2.2378, -2.5846],
        [-3.1855, -3.0995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1579827070236206
Epoch 0, Step 1186: train/loss = 0.7188445329666138, train/raw-loss = 0.6632668972015381, train/logprobs = tensor([[-1.3233, -1.2160],
        [-1.6034, -1.3519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2223103642463684
Epoch 0, Step 1187: train/loss = 0.6890710592269897, train/raw-loss = 0.6485688090324402, train/logprobs = tensor([[-1.9791, -1.7624],
        [-2.1759, -1.7502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16200917959213257
Epoch 0, Step 1188: train/loss = 0.7468074560165405, train/raw-loss = 0.6949570775032043, train/logprobs = tensor([[-1.9154, -1.9872],
        [-2.0236, -2.0606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20740142464637756
Epoch 0, Step 1189: train/loss = 0.6952151656150818, train/raw-loss = 0.6397302150726318, train/logprobs = tensor([[-1.4524, -1.2521],
        [-2.2038, -1.6386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2219400703907013
Epoch 0, Step 1190: train/loss = 0.709883987903595, train/raw-loss = 0.6696575880050659, train/logprobs = tensor([[-1.2367, -2.0267],
        [-1.6485, -2.2990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16090545058250427
Epoch 0, Step 1191: train/loss = 0.6955373883247375, train/raw-loss = 0.6513785123825073, train/logprobs = tensor([[-0.7194, -0.7009],
        [-1.5040, -1.0889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1766352653503418
Epoch 0, Step 1192: train/loss = 0.6385942697525024, train/raw-loss = 0.5963605642318726, train/logprobs = tensor([[-1.5286, -1.7311],
        [-2.2164, -1.8708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16893479228019714
Epoch 0, Step 1193: train/loss = 0.6328133344650269, train/raw-loss = 0.5908449292182922, train/logprobs = tensor([[-2.0640, -1.1874],
        [-2.7078, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16787362098693848
Epoch 0, Step 1194: train/loss = 0.5304327011108398, train/raw-loss = 0.485862672328949, train/logprobs = tensor([[-1.4628, -2.1460],
        [-2.6107, -2.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1782800704240799
Epoch 0, Step 1195: train/loss = 0.652286946773529, train/raw-loss = 0.5899146795272827, train/logprobs = tensor([[-1.2337, -1.5606],
        [-2.5479, -2.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24948903918266296
Epoch 0, Step 1196: train/loss = 0.6508069634437561, train/raw-loss = 0.6048780679702759, train/logprobs = tensor([[-1.1755, -0.9349],
        [-2.5058, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1837155520915985
Epoch 0, Step 1197: train/loss = 0.5025125741958618, train/raw-loss = 0.4454665184020996, train/logprobs = tensor([[-0.9807, -1.2159],
        [-2.9301, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22818419337272644
Epoch 0, Step 1198: train/loss = 0.6466381549835205, train/raw-loss = 0.6069732308387756, train/logprobs = tensor([[-1.2618, -2.3894],
        [-1.5484, -2.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15865954756736755
Epoch 0, Step 1199: train/loss = 0.6070427894592285, train/raw-loss = 0.5699580311775208, train/logprobs = tensor([[-1.3438, -2.4001],
        [-1.7697, -2.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14833924174308777
Epoch 0, Step 1200: train/loss = 0.5623469948768616, train/raw-loss = 0.5187690854072571, train/logprobs = tensor([[-1.3175, -0.9133],
        [-2.5950, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17431166768074036
Epoch 0, Step 1201: train/loss = 0.5388339757919312, train/raw-loss = 0.5006268620491028, train/logprobs = tensor([[-1.6102, -3.2464],
        [-2.1543, -2.5418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15282857418060303
Epoch 0, Step 1202: train/loss = 0.6371285915374756, train/raw-loss = 0.5911142826080322, train/logprobs = tensor([[-1.2804, -2.1730],
        [-1.8591, -2.2575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18405726552009583
Epoch 0, Step 1203: train/loss = 0.5939129590988159, train/raw-loss = 0.5500262975692749, train/logprobs = tensor([[-0.8433, -1.0915],
        [-1.7123, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1755467653274536
Epoch 0, Step 1204: train/loss = 0.7775721549987793, train/raw-loss = 0.7248533368110657, train/logprobs = tensor([[-1.0198, -1.0454],
        [-1.7573, -1.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21087537705898285
Epoch 0, Step 1205: train/loss = 0.5021021366119385, train/raw-loss = 0.4589012861251831, train/logprobs = tensor([[-1.4205, -2.2778],
        [-4.1120, -2.4405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17280346155166626
Epoch 0, Step 1206: train/loss = 0.6399750113487244, train/raw-loss = 0.5816386938095093, train/logprobs = tensor([[-1.8307, -2.4821],
        [-2.4081, -2.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23334532976150513
Epoch 0, Step 1207: train/loss = 0.7342323064804077, train/raw-loss = 0.6914342045783997, train/logprobs = tensor([[-1.2293, -1.9706],
        [-1.5571, -2.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1711927354335785
Epoch 0, Step 1208: train/loss = 0.677708625793457, train/raw-loss = 0.6286647915840149, train/logprobs = tensor([[-1.7647, -1.8057],
        [-2.1958, -1.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19617566466331482
Epoch 0, Step 1209: train/loss = 0.6261632442474365, train/raw-loss = 0.5795124769210815, train/logprobs = tensor([[-1.9099, -2.0191],
        [-2.4353, -1.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1866028904914856
Epoch 0, Step 1210: train/loss = 0.6442551016807556, train/raw-loss = 0.6062901616096497, train/logprobs = tensor([[-1.8580, -1.8704],
        [-2.1663, -1.7056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15185964107513428
Epoch 0, Step 1211: train/loss = 0.6548228859901428, train/raw-loss = 0.5935893654823303, train/logprobs = tensor([[-1.5658, -2.0221],
        [-2.5002, -2.2936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2449340522289276
Epoch 0, Step 1212: train/loss = 0.5195228457450867, train/raw-loss = 0.48507389426231384, train/logprobs = tensor([[-1.2619, -2.0929],
        [-1.9403, -1.7507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1377958506345749
Epoch 0, Step 1213: train/loss = 0.6738505363464355, train/raw-loss = 0.6189339756965637, train/logprobs = tensor([[-1.7838, -2.2391],
        [-2.3601, -2.3320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21966612339019775
Epoch 0, Step 1214: train/loss = 0.5427329540252686, train/raw-loss = 0.5034568309783936, train/logprobs = tensor([[-1.9310, -3.4851],
        [-2.4504, -2.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15710461139678955
Epoch 0, Step 1215: train/loss = 0.586695671081543, train/raw-loss = 0.5366519689559937, train/logprobs = tensor([[-1.7017, -1.9471],
        [-2.2139, -1.7091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2001749873161316
Epoch 0, Step 1216: train/loss = 0.5414413809776306, train/raw-loss = 0.4974602162837982, train/logprobs = tensor([[-1.6075, -1.7476],
        [-2.2382, -0.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17592473328113556
Epoch 0, Step 1217: train/loss = 0.7358418703079224, train/raw-loss = 0.6903025507926941, train/logprobs = tensor([[-1.6649, -1.8135],
        [-1.9821, -2.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18215739727020264
Epoch 0, Step 1218: train/loss = 0.5759792327880859, train/raw-loss = 0.5292269587516785, train/logprobs = tensor([[-1.3824, -2.0158],
        [-1.9266, -1.6026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870090365409851
Epoch 0, Step 1219: train/loss = 0.49094653129577637, train/raw-loss = 0.43904730677604675, train/logprobs = tensor([[-1.4326, -2.7237],
        [-2.9808, -2.5060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20759685337543488
Epoch 0, Step 1220: train/loss = 0.5404521226882935, train/raw-loss = 0.4927741587162018, train/logprobs = tensor([[-1.6213, -3.6824],
        [-1.8857, -2.4180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1907118856906891
Epoch 0, Step 1221: train/loss = 0.7759023308753967, train/raw-loss = 0.7326354384422302, train/logprobs = tensor([[-0.6701, -0.5835],
        [-1.2518, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17306745052337646
Epoch 0, Step 1222: train/loss = 0.7599843740463257, train/raw-loss = 0.7197383642196655, train/logprobs = tensor([[-1.3295, -1.3385],
        [-1.4652, -1.5483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.160983607172966
Epoch 0, Step 1223: train/loss = 0.5719515681266785, train/raw-loss = 0.5260676145553589, train/logprobs = tensor([[-1.6036, -2.8028],
        [-2.2697, -2.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183535635471344
Epoch 0, Step 1224: train/loss = 0.5120232701301575, train/raw-loss = 0.4760655164718628, train/logprobs = tensor([[-0.9359, -1.7838],
        [-1.6588, -1.4102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14383071660995483
Epoch 0, Step 1225: train/loss = 0.46096891164779663, train/raw-loss = 0.41915982961654663, train/logprobs = tensor([[-1.6883, -3.6161],
        [-2.2603, -2.6686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16723620891571045
Epoch 0, Step 1226: train/loss = 0.5759198069572449, train/raw-loss = 0.5390306711196899, train/logprobs = tensor([[-1.3992, -1.2178],
        [-2.2195, -1.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14755667746067047
Epoch 0, Step 1227: train/loss = 0.7101046442985535, train/raw-loss = 0.6505539417266846, train/logprobs = tensor([[-1.5153, -1.9546],
        [-2.1450, -2.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23820289969444275
Epoch 0, Step 1228: train/loss = 0.6790517568588257, train/raw-loss = 0.6425179243087769, train/logprobs = tensor([[-1.4168, -1.5592],
        [-2.3517, -2.0791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14613541960716248
Epoch 0, Step 1229: train/loss = 0.7360441088676453, train/raw-loss = 0.6941614151000977, train/logprobs = tensor([[-1.7881, -1.7565],
        [-1.9098, -1.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16753046214580536
Epoch 0, Step 1230: train/loss = 0.6968396902084351, train/raw-loss = 0.6457780599594116, train/logprobs = tensor([[-1.2641, -1.6948],
        [-2.4009, -2.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20424647629261017
Epoch 0, Step 1231: train/loss = 0.6189438700675964, train/raw-loss = 0.5571839213371277, train/logprobs = tensor([[-1.7131, -1.8912],
        [-2.5656, -1.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24703994393348694
Epoch 0, Step 1232: train/loss = 0.6073325872421265, train/raw-loss = 0.5498232245445251, train/logprobs = tensor([[-0.8478, -1.3152],
        [-2.0266, -1.4961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23003756999969482
Epoch 0, Step 1233: train/loss = 0.574067234992981, train/raw-loss = 0.5340005159378052, train/logprobs = tensor([[-1.2989, -1.8498],
        [-2.3080, -1.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1602669358253479
Epoch 0, Step 1234: train/loss = 0.7360669374465942, train/raw-loss = 0.6929914355278015, train/logprobs = tensor([[-1.2886, -1.2524],
        [-1.5655, -1.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17230209708213806
Epoch 0, Step 1235: train/loss = 0.614944577217102, train/raw-loss = 0.5681011080741882, train/logprobs = tensor([[-1.6303, -1.8960],
        [-2.5076, -2.0690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18737393617630005
Epoch 0, Step 1236: train/loss = 0.5905587077140808, train/raw-loss = 0.539821982383728, train/logprobs = tensor([[-1.9015, -2.8526],
        [-2.2995, -2.3193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2029469758272171
Epoch 0, Step 1237: train/loss = 0.7677953839302063, train/raw-loss = 0.7310367822647095, train/logprobs = tensor([[-3.7036, -3.6813],
        [-4.5685, -4.2529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14703476428985596
Epoch 0, Step 1238: train/loss = 0.7770413756370544, train/raw-loss = 0.7385202646255493, train/logprobs = tensor([[-1.5677, -2.2702],
        [-2.2266, -2.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1540844887495041
Epoch 0, Step 1239: train/loss = 0.5377309322357178, train/raw-loss = 0.4940277338027954, train/logprobs = tensor([[-1.9544, -3.1627],
        [-3.3455, -2.6365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17481280863285065
Epoch 0, Step 1240: train/loss = 0.6314383149147034, train/raw-loss = 0.5868877172470093, train/logprobs = tensor([[-1.7995, -2.3021],
        [-2.3164, -2.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17820245027542114
Epoch 0, Step 1241: train/loss = 0.4832460582256317, train/raw-loss = 0.4363308250904083, train/logprobs = tensor([[-1.3965, -2.0041],
        [-3.5373, -1.9007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18766094744205475
Epoch 0, Step 1242: train/loss = 0.5889573693275452, train/raw-loss = 0.5399404764175415, train/logprobs = tensor([[-1.3767, -2.8654],
        [-2.3549, -2.8532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19606757164001465
Epoch 0, Step 1243: train/loss = 0.4074382483959198, train/raw-loss = 0.3546313941478729, train/logprobs = tensor([[-1.2747, -3.0499],
        [-3.2889, -2.4388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21122746169567108
Epoch 0, Step 1244: train/loss = 0.7386723160743713, train/raw-loss = 0.6975657939910889, train/logprobs = tensor([[-1.3838, -1.1552],
        [-2.1397, -1.7933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16442593932151794
Epoch 0, Step 1245: train/loss = 0.7076764702796936, train/raw-loss = 0.6638116836547852, train/logprobs = tensor([[-1.5549, -1.3114],
        [-2.0574, -1.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1754591464996338
Epoch 0, Step 1246: train/loss = 0.3095723092556, train/raw-loss = 0.26392093300819397, train/logprobs = tensor([[-0.9304, -3.4496],
        [-2.6449, -1.7195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1826055496931076
Epoch 0, Step 1247: train/loss = 0.6932329535484314, train/raw-loss = 0.642719030380249, train/logprobs = tensor([[-2.0449, -1.9488],
        [-2.8762, -2.2934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20205599069595337
Epoch 0, Step 1248: train/loss = 0.3879806101322174, train/raw-loss = 0.3404530882835388, train/logprobs = tensor([[-1.7568, -2.7325],
        [-2.9456, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19011016190052032
Epoch 0, Step 1249: train/loss = 0.5718664526939392, train/raw-loss = 0.5257223844528198, train/logprobs = tensor([[-1.7451, -2.0071],
        [-2.7044, -2.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1845763623714447
Epoch 0, Step 1250: train/loss = 0.6232427954673767, train/raw-loss = 0.5842113494873047, train/logprobs = tensor([[-2.0806, -3.4498],
        [-2.9642, -3.4192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.156126007437706
Epoch 0, Step 1251: train/loss = 0.49568504095077515, train/raw-loss = 0.4451700448989868, train/logprobs = tensor([[-1.3836, -1.9526],
        [-2.6217, -1.5379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2020600140094757
Epoch 0, Step 1252: train/loss = 0.6447232365608215, train/raw-loss = 0.6096583604812622, train/logprobs = tensor([[-1.3763, -1.0885],
        [-1.6820, -0.9401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14025957882404327
Epoch 0, Step 1253: train/loss = 0.3634345233440399, train/raw-loss = 0.32060521841049194, train/logprobs = tensor([[-1.4303, -3.3845],
        [-2.5216, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1713171750307083
Epoch 0, Step 1254: train/loss = 0.6644920706748962, train/raw-loss = 0.6210704445838928, train/logprobs = tensor([[-1.5687, -2.7472],
        [-2.5526, -2.8808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17368656396865845
Epoch 0, Step 1255: train/loss = 0.6394261717796326, train/raw-loss = 0.5973648428916931, train/logprobs = tensor([[-1.8376, -1.9259],
        [-2.2270, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16824527084827423
Epoch 0, Step 1256: train/loss = 0.7919859290122986, train/raw-loss = 0.7457107305526733, train/logprobs = tensor([[-1.7972, -1.2315],
        [-1.9147, -1.5086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18510064482688904
Epoch 0, Step 1257: train/loss = 0.7613703608512878, train/raw-loss = 0.7151841521263123, train/logprobs = tensor([[-1.5530, -1.2694],
        [-2.1978, -1.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1847444772720337
Epoch 0, Step 1258: train/loss = 0.6811248660087585, train/raw-loss = 0.6343609094619751, train/logprobs = tensor([[-2.5057, -2.1809],
        [-2.5967, -1.9750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1870558261871338
Epoch 0, Step 1259: train/loss = 0.6219794154167175, train/raw-loss = 0.5683398842811584, train/logprobs = tensor([[-2.1741, -1.5774],
        [-3.2647, -1.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21455806493759155
Epoch 0, Step 1260: train/loss = 0.6196074485778809, train/raw-loss = 0.5743802785873413, train/logprobs = tensor([[-1.5780, -2.4285],
        [-2.2168, -2.3849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18090854585170746
Epoch 0, Step 1261: train/loss = 0.4545931816101074, train/raw-loss = 0.42614465951919556, train/logprobs = tensor([[-1.0767, -2.7745],
        [-1.4380, -1.2534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11379419267177582
Epoch 0, Step 1262: train/loss = 0.6742075085639954, train/raw-loss = 0.6507515907287598, train/logprobs = tensor([[-1.5983, -1.7975],
        [-2.0346, -1.7532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09382373094558716
Epoch 0, Step 1263: train/loss = 0.8107709884643555, train/raw-loss = 0.7588692903518677, train/logprobs = tensor([[-1.3942, -2.2861],
        [-1.5486, -2.5736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2076069414615631
Epoch 0, Step 1264: train/loss = 0.7199046611785889, train/raw-loss = 0.6730520725250244, train/logprobs = tensor([[-1.0308, -1.4104],
        [-1.9119, -1.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18741032481193542
Epoch 0, Step 1265: train/loss = 0.8701701164245605, train/raw-loss = 0.8177936673164368, train/logprobs = tensor([[-1.7347, -1.3895],
        [-3.1361, -2.5762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2095058113336563
Epoch 0, Step 1266: train/loss = 0.5033573508262634, train/raw-loss = 0.46153897047042847, train/logprobs = tensor([[-0.8687, -1.2395],
        [-2.7059, -0.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16727346181869507
Epoch 0, Step 1267: train/loss = 0.7303782105445862, train/raw-loss = 0.6847293972969055, train/logprobs = tensor([[-1.4681, -1.5096],
        [-2.5245, -2.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1825954169034958
Epoch 0, Step 1268: train/loss = 0.7813213467597961, train/raw-loss = 0.7466578483581543, train/logprobs = tensor([[-0.5074, -0.6090],
        [-1.0675, -1.2461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13865379989147186
Epoch 0, Step 1269: train/loss = 0.6578754186630249, train/raw-loss = 0.6111449003219604, train/logprobs = tensor([[-1.8079, -1.8346],
        [-2.1521, -1.7718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18692219257354736
Epoch 0, Step 1270: train/loss = 0.431315541267395, train/raw-loss = 0.38854920864105225, train/logprobs = tensor([[-1.4429, -3.3658],
        [-2.3806, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17106522619724274
Epoch 0, Step 1271: train/loss = 0.7368665933609009, train/raw-loss = 0.6882064938545227, train/logprobs = tensor([[-1.9716, -2.0529],
        [-2.3699, -2.3725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.194640651345253
Epoch 0, Step 1272: train/loss = 0.5670216083526611, train/raw-loss = 0.5339527726173401, train/logprobs = tensor([[-0.9077, -2.4712],
        [-2.3326, -2.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13227532804012299
Epoch 0, Step 1273: train/loss = 0.6223880052566528, train/raw-loss = 0.5787064433097839, train/logprobs = tensor([[-2.1646, -2.5833],
        [-2.1197, -1.7111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17472639679908752
Epoch 0, Step 1274: train/loss = 0.5208587646484375, train/raw-loss = 0.4676782786846161, train/logprobs = tensor([[-2.3633, -2.1949],
        [-3.4090, -1.7494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21272210776805878
Epoch 0, Step 1275: train/loss = 0.5361930727958679, train/raw-loss = 0.5023531913757324, train/logprobs = tensor([[-1.7247, -2.3502],
        [-2.7143, -1.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.135359525680542
Epoch 0, Step 1276: train/loss = 0.664368212223053, train/raw-loss = 0.6201918125152588, train/logprobs = tensor([[-1.0317, -2.1729],
        [-1.9211, -2.1819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17670559883117676
Epoch 0, Step 1277: train/loss = 0.5605652332305908, train/raw-loss = 0.5066773891448975, train/logprobs = tensor([[-1.6064, -2.7603],
        [-3.0180, -2.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21555130183696747
Epoch 0, Step 1278: train/loss = 0.7086926698684692, train/raw-loss = 0.6749128103256226, train/logprobs = tensor([[-2.0817, -1.7796],
        [-2.2912, -1.8915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13511952757835388
Epoch 0, Step 1279: train/loss = 0.6384113430976868, train/raw-loss = 0.5964351296424866, train/logprobs = tensor([[-1.3984, -1.9146],
        [-2.4297, -2.3209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1679048240184784
Epoch 0, Step 1280: train/loss = 0.7720804214477539, train/raw-loss = 0.7433148622512817, train/logprobs = tensor([[-2.4232, -2.1781],
        [-1.7539, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11506205797195435
Epoch 0, Step 1281: train/loss = 0.5462493896484375, train/raw-loss = 0.5065261721611023, train/logprobs = tensor([[-0.8961, -2.3660],
        [-1.2585, -1.2182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15889281034469604
Epoch 0, Step 1282: train/loss = 0.6734458804130554, train/raw-loss = 0.6228971481323242, train/logprobs = tensor([[-1.2471, -1.8036],
        [-1.6536, -1.7522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2021949589252472
Epoch 0, Step 1283: train/loss = 0.6201149225234985, train/raw-loss = 0.5865371227264404, train/logprobs = tensor([[-1.6062, -1.4347],
        [-2.3241, -1.5528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13431142270565033
Epoch 0, Step 1284: train/loss = 0.5584595799446106, train/raw-loss = 0.52855384349823, train/logprobs = tensor([[-2.1783, -2.2775],
        [-3.0156, -1.9824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11962305754423141
Epoch 0, Step 1285: train/loss = 0.6828798055648804, train/raw-loss = 0.6369064450263977, train/logprobs = tensor([[-1.1373, -1.3571],
        [-1.6071, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838933378458023
Epoch 0, Step 1286: train/loss = 0.7202573418617249, train/raw-loss = 0.692809522151947, train/logprobs = tensor([[-1.1804, -0.9916],
        [-1.2976, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10979138314723969
Epoch 0, Step 1287: train/loss = 0.6634827852249146, train/raw-loss = 0.6214777231216431, train/logprobs = tensor([[-0.9414, -1.0358],
        [-1.6173, -1.3169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1680203676223755
Epoch 0, Step 1288: train/loss = 0.7571579813957214, train/raw-loss = 0.7214033007621765, train/logprobs = tensor([[-0.4313, -0.3604],
        [-0.7935, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14301899075508118
Epoch 0, Step 1289: train/loss = 0.598832905292511, train/raw-loss = 0.5670730471611023, train/logprobs = tensor([[-1.9454, -1.1046],
        [-2.4791, -1.0283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12703938782215118
Epoch 0, Step 1290: train/loss = 0.6767696142196655, train/raw-loss = 0.6267640590667725, train/logprobs = tensor([[-2.1595, -2.4794],
        [-2.8910, -2.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20002228021621704
Epoch 0, Step 1291: train/loss = 0.7145165205001831, train/raw-loss = 0.6699507236480713, train/logprobs = tensor([[-2.0097, -2.4955],
        [-2.1441, -2.4903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17826293408870697
Epoch 0, Step 1292: train/loss = 0.5692197680473328, train/raw-loss = 0.5292870998382568, train/logprobs = tensor([[-1.9037, -2.8397],
        [-2.4241, -2.3900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1597306728363037
Epoch 0, Step 1293: train/loss = 0.6963030099868774, train/raw-loss = 0.643526554107666, train/logprobs = tensor([[-1.8102, -1.8375],
        [-2.2335, -1.9872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2111058533191681
Epoch 0, Step 1294: train/loss = 0.6428767442703247, train/raw-loss = 0.5874626636505127, train/logprobs = tensor([[-1.5275, -1.6627],
        [-2.7190, -2.0461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22165633738040924
Epoch 0, Step 1295: train/loss = 0.4819713234901428, train/raw-loss = 0.4452275037765503, train/logprobs = tensor([[-0.9418, -1.7060],
        [-1.9072, -1.2395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14697518944740295
Epoch 0, Step 1296: train/loss = 0.5042814612388611, train/raw-loss = 0.46221983432769775, train/logprobs = tensor([[-1.3340, -1.9730],
        [-1.8543, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16824659705162048
Epoch 0, Step 1297: train/loss = 0.5763604640960693, train/raw-loss = 0.5308338403701782, train/logprobs = tensor([[-1.3767, -2.4306],
        [-1.7196, -1.4452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18210643529891968
Epoch 0, Step 1298: train/loss = 0.5368140339851379, train/raw-loss = 0.49842989444732666, train/logprobs = tensor([[-1.9984, -3.2236],
        [-2.1753, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1535366177558899
Epoch 0, Step 1299: train/loss = 0.5129084587097168, train/raw-loss = 0.4681035876274109, train/logprobs = tensor([[-1.3387, -3.1381],
        [-2.1506, -2.1479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17921948432922363
Epoch 0, Step 1300: train/loss = 0.7124114632606506, train/raw-loss = 0.6644668579101562, train/logprobs = tensor([[-1.4238, -1.8652],
        [-3.2563, -2.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19177863001823425
Epoch 0, Step 1301: train/loss = 0.4972679316997528, train/raw-loss = 0.4639655649662018, train/logprobs = tensor([[-1.7404, -4.3557],
        [-1.8726, -2.6473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13320955634117126
Epoch 0, Step 1302: train/loss = 0.5570656657218933, train/raw-loss = 0.5191723704338074, train/logprobs = tensor([[-1.0245, -2.7222],
        [-1.4691, -1.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15157310664653778
Epoch 0, Step 1303: train/loss = 0.6189393401145935, train/raw-loss = 0.583733320236206, train/logprobs = tensor([[-1.7733, -2.2872],
        [-1.9999, -1.8984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14082419872283936
Epoch 0, Step 1304: train/loss = 0.4596615433692932, train/raw-loss = 0.42015525698661804, train/logprobs = tensor([[-0.8004, -1.8200],
        [-1.9223, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15802505612373352
Epoch 0, Step 1305: train/loss = 0.65227210521698, train/raw-loss = 0.6069611310958862, train/logprobs = tensor([[-1.9712, -2.2371],
        [-2.6711, -2.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18124377727508545
Epoch 0, Step 1306: train/loss = 0.6179611682891846, train/raw-loss = 0.570284366607666, train/logprobs = tensor([[-1.4380, -2.0630],
        [-1.7358, -1.6413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.190707266330719
Epoch 0, Step 1307: train/loss = 0.7221273183822632, train/raw-loss = 0.6731677055358887, train/logprobs = tensor([[-1.6120, -1.4337],
        [-1.7220, -1.3602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19583842158317566
Epoch 0, Step 1308: train/loss = 0.6266495585441589, train/raw-loss = 0.579878568649292, train/logprobs = tensor([[-1.2608, -1.4571],
        [-1.6875, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.187083899974823
Epoch 0, Step 1309: train/loss = 0.5827352404594421, train/raw-loss = 0.5484849214553833, train/logprobs = tensor([[-1.2386, -1.8041],
        [-2.1963, -1.8374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1370011866092682
Epoch 0, Step 1310: train/loss = 0.4723352789878845, train/raw-loss = 0.4337712526321411, train/logprobs = tensor([[-0.6598, -1.6162],
        [-1.6808, -0.7041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15425601601600647
Epoch 0, Step 1311: train/loss = 0.7976338863372803, train/raw-loss = 0.7472043037414551, train/logprobs = tensor([[-2.9096, -2.6373],
        [-3.1797, -2.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2017180472612381
Epoch 0, Step 1312: train/loss = 0.6851106882095337, train/raw-loss = 0.6495600342750549, train/logprobs = tensor([[-1.9032, -2.1251],
        [-2.2393, -2.2406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1422027051448822
Epoch 0, Step 1313: train/loss = 0.7037830352783203, train/raw-loss = 0.6576722860336304, train/logprobs = tensor([[-3.3928, -2.4521],
        [-3.6527, -2.4356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18444278836250305
Epoch 0, Step 1314: train/loss = 0.6518962383270264, train/raw-loss = 0.5941288471221924, train/logprobs = tensor([[-1.3809, -1.6237],
        [-2.3639, -1.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23106957972049713
Epoch 0, Step 1315: train/loss = 0.5855120420455933, train/raw-loss = 0.5400987267494202, train/logprobs = tensor([[-1.4467, -2.6027],
        [-1.6109, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816532015800476
Epoch 0, Step 1316: train/loss = 0.47857752442359924, train/raw-loss = 0.42559942603111267, train/logprobs = tensor([[-1.9300, -2.2498],
        [-2.7816, -1.0851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2119123637676239
Epoch 0, Step 1317: train/loss = 0.5539175868034363, train/raw-loss = 0.5080374479293823, train/logprobs = tensor([[-2.0616, -1.6761],
        [-3.9721, -1.9584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18352055549621582
Epoch 0, Step 1318: train/loss = 0.616681694984436, train/raw-loss = 0.5697097182273865, train/logprobs = tensor([[-1.2901, -3.0639],
        [-2.2500, -1.6789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1878877431154251
Epoch 0, Step 1319: train/loss = 0.6875748634338379, train/raw-loss = 0.6419463157653809, train/logprobs = tensor([[-2.0607, -3.2915],
        [-1.5776, -2.2687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18251436948776245
Epoch 0, Step 1320: train/loss = 0.6466588973999023, train/raw-loss = 0.6055771112442017, train/logprobs = tensor([[-1.1011, -1.9319],
        [-1.4782, -1.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16432708501815796
Epoch 0, Step 1321: train/loss = 0.4624304175376892, train/raw-loss = 0.42195430397987366, train/logprobs = tensor([[-0.8585, -3.4350],
        [-1.4655, -1.4835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16190457344055176
Epoch 0, Step 1322: train/loss = 0.5501869916915894, train/raw-loss = 0.5177996754646301, train/logprobs = tensor([[-2.1342, -2.5240],
        [-2.2723, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12954916059970856
Epoch 0, Step 1323: train/loss = 0.8418183326721191, train/raw-loss = 0.7929292917251587, train/logprobs = tensor([[-1.0963, -0.8468],
        [-1.3947, -1.3341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19555597007274628
Epoch 0, Step 1324: train/loss = 0.7430121302604675, train/raw-loss = 0.6882703900337219, train/logprobs = tensor([[-1.1828, -1.3026],
        [-1.7515, -1.7326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21896708011627197
Epoch 0, Step 1325: train/loss = 0.6681051850318909, train/raw-loss = 0.6221441030502319, train/logprobs = tensor([[-2.5482, -2.6306],
        [-2.6627, -2.4039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18384426832199097
Epoch 0, Step 1326: train/loss = 0.7097561955451965, train/raw-loss = 0.6636108160018921, train/logprobs = tensor([[-2.9848, -2.9940],
        [-3.4774, -3.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18458154797554016
Epoch 0, Step 1327: train/loss = 0.6470317840576172, train/raw-loss = 0.6017842292785645, train/logprobs = tensor([[-1.9228, -2.2326],
        [-2.1213, -2.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1809900403022766
Epoch 0, Step 1328: train/loss = 0.5639398097991943, train/raw-loss = 0.5142764449119568, train/logprobs = tensor([[-1.6952, -3.7835],
        [-1.6016, -1.1884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19865353405475616
Epoch 0, Step 1329: train/loss = 0.680298388004303, train/raw-loss = 0.6326119899749756, train/logprobs = tensor([[-1.3972, -2.7927],
        [-1.7578, -2.3453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19074559211730957
Epoch 0, Step 1330: train/loss = 0.7368174195289612, train/raw-loss = 0.6822249889373779, train/logprobs = tensor([[-1.4386, -1.4310],
        [-1.7710, -1.6508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21836981177330017
Epoch 0, Step 1331: train/loss = 0.720847487449646, train/raw-loss = 0.6805317997932434, train/logprobs = tensor([[-1.9555, -1.7511],
        [-1.9270, -1.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1612626016139984
Epoch 0, Step 1332: train/loss = 0.35768502950668335, train/raw-loss = 0.31332576274871826, train/logprobs = tensor([[-0.8724, -3.3258],
        [-1.3057, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17743708193302155
Epoch 0, Step 1333: train/loss = 0.6694114208221436, train/raw-loss = 0.6271672248840332, train/logprobs = tensor([[-1.0919, -1.3115],
        [-1.2628, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897666454315186
Epoch 0, Step 1334: train/loss = 0.47807109355926514, train/raw-loss = 0.4390563368797302, train/logprobs = tensor([[-1.5941, -2.5537],
        [-1.7393, -1.0947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15605896711349487
Epoch 0, Step 1335: train/loss = 0.5697756409645081, train/raw-loss = 0.5367639064788818, train/logprobs = tensor([[-1.4300, -1.1893],
        [-2.2497, -0.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13204671442508698
Epoch 0, Step 1336: train/loss = 0.5829780101776123, train/raw-loss = 0.5429997444152832, train/logprobs = tensor([[-2.2235, -2.8109],
        [-2.7631, -1.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1599131077528
Epoch 0, Step 1337: train/loss = 0.691015362739563, train/raw-loss = 0.6494148969650269, train/logprobs = tensor([[-1.5570, -1.3002],
        [-1.6397, -1.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16640156507492065
Epoch 0, Step 1338: train/loss = 0.558982789516449, train/raw-loss = 0.5123046636581421, train/logprobs = tensor([[-1.7518, -2.7162],
        [-2.4749, -1.9169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18671250343322754
Epoch 0, Step 1339: train/loss = 0.7661163210868835, train/raw-loss = 0.7257711887359619, train/logprobs = tensor([[-2.0648, -2.0934],
        [-2.9357, -2.5836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16138038039207458
Epoch 0, Step 1340: train/loss = 0.6441220045089722, train/raw-loss = 0.6049724817276001, train/logprobs = tensor([[-2.3646, -2.1924],
        [-2.7462, -1.4083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15659800171852112
Epoch 0, Step 1341: train/loss = 0.8198046684265137, train/raw-loss = 0.7891815900802612, train/logprobs = tensor([[-1.2483, -2.5000],
        [-1.4494, -2.9289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12249237298965454
Epoch 0, Step 1342: train/loss = 0.6934182643890381, train/raw-loss = 0.6511746644973755, train/logprobs = tensor([[-2.6732, -1.8402],
        [-2.6227, -1.5985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16897474229335785
Epoch 0, Step 1343: train/loss = 0.48449358344078064, train/raw-loss = 0.4354686439037323, train/logprobs = tensor([[-1.2195, -1.7730],
        [-2.8357, -1.3833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19609969854354858
Epoch 0, Step 1344: train/loss = 0.5403244495391846, train/raw-loss = 0.49562376737594604, train/logprobs = tensor([[-1.5919, -2.9185],
        [-1.8609, -0.7448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1788024753332138
Epoch 0, Step 1345: train/loss = 0.6059011816978455, train/raw-loss = 0.572163462638855, train/logprobs = tensor([[-1.5818, -2.3196],
        [-1.6636, -1.6385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1349509060382843
Epoch 0, Step 1346: train/loss = 0.5943386554718018, train/raw-loss = 0.5469903349876404, train/logprobs = tensor([[-1.7908, -1.8106],
        [-2.9979, -1.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18939338624477386
Epoch 0, Step 1347: train/loss = 0.6471218466758728, train/raw-loss = 0.6127729415893555, train/logprobs = tensor([[-1.5522, -2.3603],
        [-1.6412, -2.0137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13739559054374695
Epoch 0, Step 1348: train/loss = 0.48718786239624023, train/raw-loss = 0.43705785274505615, train/logprobs = tensor([[-1.6296, -3.4861],
        [-1.9923, -2.4966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20051991939544678
Epoch 0, Step 1349: train/loss = 0.5532645583152771, train/raw-loss = 0.5158881545066833, train/logprobs = tensor([[-1.4362, -2.2047],
        [-1.9170, -1.4915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14950576424598694
Epoch 0, Step 1350: train/loss = 0.5683011412620544, train/raw-loss = 0.5137816071510315, train/logprobs = tensor([[-0.9591, -1.3880],
        [-2.2059, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21807830035686493
Epoch 0, Step 1351: train/loss = 0.6242328882217407, train/raw-loss = 0.580126941204071, train/logprobs = tensor([[-1.7882, -2.2966],
        [-1.9278, -1.8796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17642371356487274
Epoch 0, Step 1352: train/loss = 0.6522603631019592, train/raw-loss = 0.6088079214096069, train/logprobs = tensor([[-1.5507, -2.4043],
        [-1.5313, -1.3148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17380984127521515
Epoch 0, Step 1353: train/loss = 0.7435586452484131, train/raw-loss = 0.7052007913589478, train/logprobs = tensor([[-2.4813, -2.6626],
        [-2.1953, -2.3768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15343131124973297
Epoch 0, Step 1354: train/loss = 0.6391317248344421, train/raw-loss = 0.5995011925697327, train/logprobs = tensor([[-1.5351, -2.4029],
        [-1.7524, -2.1850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15852202475070953
Epoch 0, Step 1355: train/loss = 0.7375906705856323, train/raw-loss = 0.686913788318634, train/logprobs = tensor([[-2.0596, -1.7169],
        [-1.9971, -1.6171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20270738005638123
Epoch 0, Step 1356: train/loss = 0.43573030829429626, train/raw-loss = 0.3908863067626953, train/logprobs = tensor([[-1.6945, -4.6138],
        [-1.9830, -2.2512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1793760359287262
Epoch 0, Step 1357: train/loss = 0.5425742864608765, train/raw-loss = 0.4960469603538513, train/logprobs = tensor([[-1.1497, -1.3298],
        [-2.2745, -1.2635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18610912561416626
Epoch 0, Step 1358: train/loss = 0.46541494131088257, train/raw-loss = 0.4231669306755066, train/logprobs = tensor([[-1.5871, -2.0092],
        [-2.3233, -1.0391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16899190843105316
Epoch 0, Step 1359: train/loss = 0.6655876636505127, train/raw-loss = 0.6249321699142456, train/logprobs = tensor([[-2.3891, -1.5878],
        [-2.3458, -1.2336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1626221090555191
Epoch 0, Step 1360: train/loss = 0.6012322902679443, train/raw-loss = 0.5540738105773926, train/logprobs = tensor([[-2.8656, -3.2876],
        [-3.0703, -2.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18863371014595032
Epoch 0, Step 1361: train/loss = 0.7052739858627319, train/raw-loss = 0.6660767197608948, train/logprobs = tensor([[-2.4367, -2.1782],
        [-2.3212, -1.2985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15678903460502625
Epoch 0, Step 1362: train/loss = 0.5891112089157104, train/raw-loss = 0.5475595593452454, train/logprobs = tensor([[-2.0921, -3.5972],
        [-1.7337, -1.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1662067472934723
Epoch 0, Step 1363: train/loss = 0.38828569650650024, train/raw-loss = 0.3417145311832428, train/logprobs = tensor([[-1.2176, -4.9301],
        [-1.6503, -1.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18628469109535217
Epoch 0, Step 1364: train/loss = 0.7142324447631836, train/raw-loss = 0.6731826066970825, train/logprobs = tensor([[-2.5722, -2.3309],
        [-2.4206, -1.8321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16419915854930878
Epoch 0, Step 1365: train/loss = 0.5335261821746826, train/raw-loss = 0.4806671738624573, train/logprobs = tensor([[-1.4492, -2.7232],
        [-1.9431, -1.9776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21143591403961182
Epoch 0, Step 1366: train/loss = 0.7239165306091309, train/raw-loss = 0.6727162599563599, train/logprobs = tensor([[-1.7621, -1.5637],
        [-2.1097, -1.7069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2048012614250183
Epoch 0, Step 1367: train/loss = 0.6495827436447144, train/raw-loss = 0.5990566611289978, train/logprobs = tensor([[-1.1839, -1.2273],
        [-1.4955, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20210444927215576
Epoch 0, Step 1368: train/loss = 0.5023288726806641, train/raw-loss = 0.4565013349056244, train/logprobs = tensor([[-1.4384, -3.4561],
        [-1.5353, -1.9027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1833101212978363
Epoch 0, Step 1369: train/loss = 0.9165244102478027, train/raw-loss = 0.8665400743484497, train/logprobs = tensor([[-2.2651, -2.5052],
        [-1.7001, -1.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19993756711483002
Epoch 0, Step 1370: train/loss = 0.5840692520141602, train/raw-loss = 0.5440883636474609, train/logprobs = tensor([[-1.1574, -2.2369],
        [-1.2431, -1.3946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1599235087633133
Epoch 0, Step 1371: train/loss = 0.6315658688545227, train/raw-loss = 0.5899131298065186, train/logprobs = tensor([[-1.0748, -1.2675],
        [-1.1141, -0.6878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16661109030246735
Epoch 0, Step 1372: train/loss = 0.6140269041061401, train/raw-loss = 0.5769822001457214, train/logprobs = tensor([[-1.2363, -1.1235],
        [-1.4722, -0.6283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14817887544631958
Epoch 0, Step 1373: train/loss = 0.6374967098236084, train/raw-loss = 0.5988094806671143, train/logprobs = tensor([[-1.5845, -1.8287],
        [-1.5085, -1.2407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15474919974803925
Epoch 0, Step 1374: train/loss = 0.5947608351707458, train/raw-loss = 0.5533535480499268, train/logprobs = tensor([[-1.5291, -2.8381],
        [-1.4376, -1.6100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1656290888786316
Epoch 0, Step 1375: train/loss = 0.5795547962188721, train/raw-loss = 0.53868567943573, train/logprobs = tensor([[-2.4791, -4.9300],
        [-2.4386, -3.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16347652673721313
Epoch 0, Step 1376: train/loss = 0.5560437440872192, train/raw-loss = 0.5113743543624878, train/logprobs = tensor([[-2.2950, -1.4859],
        [-3.3212, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17867766320705414
Epoch 0, Step 1377: train/loss = 0.6421544551849365, train/raw-loss = 0.5805981755256653, train/logprobs = tensor([[-2.3675, -3.7097],
        [-2.2183, -2.9010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24622511863708496
Epoch 0, Step 1378: train/loss = 0.663908839225769, train/raw-loss = 0.6200833320617676, train/logprobs = tensor([[-2.4459, -2.1210],
        [-2.3029, -1.5258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17530204355716705
Epoch 0, Step 1379: train/loss = 0.5906851887702942, train/raw-loss = 0.5334265232086182, train/logprobs = tensor([[-1.3545, -2.2405],
        [-1.8137, -1.6389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22903461754322052
Epoch 0, Step 1380: train/loss = 0.38918453454971313, train/raw-loss = 0.3376188278198242, train/logprobs = tensor([[-1.4240, -3.5235],
        [-2.1379, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20626279711723328
Epoch 0, Step 1381: train/loss = 0.6071199178695679, train/raw-loss = 0.5634023547172546, train/logprobs = tensor([[-2.4024, -4.9619],
        [-1.8548, -2.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17487038671970367
Epoch 0, Step 1382: train/loss = 0.4842088222503662, train/raw-loss = 0.42450574040412903, train/logprobs = tensor([[-1.6713, -2.8114],
        [-2.5435, -2.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23881228268146515
Epoch 0, Step 1383: train/loss = 0.5686309933662415, train/raw-loss = 0.5257025957107544, train/logprobs = tensor([[-1.2723, -2.1875],
        [-1.2464, -0.7701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17171375453472137
Epoch 0, Step 1384: train/loss = 0.668855607509613, train/raw-loss = 0.6293903589248657, train/logprobs = tensor([[-2.5743, -1.9411],
        [-2.2606, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15786097943782806
Epoch 0, Step 1385: train/loss = 0.64936363697052, train/raw-loss = 0.6148597002029419, train/logprobs = tensor([[-0.8019, -1.1548],
        [-1.1186, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13801591098308563
Epoch 0, Step 1386: train/loss = 0.6199042797088623, train/raw-loss = 0.5704234838485718, train/logprobs = tensor([[-2.3082, -3.6361],
        [-2.1753, -1.8179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19792330265045166
Epoch 0, Step 1387: train/loss = 0.635185718536377, train/raw-loss = 0.5889158248901367, train/logprobs = tensor([[-1.6946, -2.7888],
        [-2.5657, -2.2112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1850796937942505
Epoch 0, Step 1388: train/loss = 0.5995330810546875, train/raw-loss = 0.5768212676048279, train/logprobs = tensor([[-0.9905, -3.5127],
        [-0.7708, -2.3490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0908471867442131
Epoch 0, Step 1389: train/loss = 0.7170472145080566, train/raw-loss = 0.6724796891212463, train/logprobs = tensor([[-1.4324, -1.9280],
        [-1.1684, -1.4999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17827020585536957
Epoch 0, Step 1390: train/loss = 0.5171808004379272, train/raw-loss = 0.4712265133857727, train/logprobs = tensor([[-1.2050, -2.6206],
        [-1.9661, -1.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838172972202301
Epoch 0, Step 1391: train/loss = 0.5824488401412964, train/raw-loss = 0.5389562249183655, train/logprobs = tensor([[-1.2347, -1.6584],
        [-1.7209, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.173970565199852
Epoch 0, Step 1392: train/loss = 0.6492435932159424, train/raw-loss = 0.6028472781181335, train/logprobs = tensor([[-1.5791, -3.6704],
        [-0.6030, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18558529019355774
Epoch 0, Step 1393: train/loss = 0.6597076654434204, train/raw-loss = 0.6088416576385498, train/logprobs = tensor([[-1.2413, -2.3929],
        [-1.5703, -2.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2034642994403839
Epoch 0, Step 1394: train/loss = 0.6699196100234985, train/raw-loss = 0.634164571762085, train/logprobs = tensor([[-1.5792, -1.8764],
        [-1.1796, -0.8859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1430198848247528
Epoch 0, Step 1395: train/loss = 0.6330038905143738, train/raw-loss = 0.5799025297164917, train/logprobs = tensor([[-1.6061, -2.8111],
        [-1.7362, -1.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21240520477294922
Epoch 0, Step 1396: train/loss = 0.4786498546600342, train/raw-loss = 0.4252260625362396, train/logprobs = tensor([[-1.0958, -1.9888],
        [-1.8528, -1.1945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.213695228099823
Epoch 0, Step 1397: train/loss = 0.6731635928153992, train/raw-loss = 0.6365090608596802, train/logprobs = tensor([[-1.6637, -2.4149],
        [-1.8280, -2.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14661814272403717
Epoch 0, Step 1398: train/loss = 0.6224950551986694, train/raw-loss = 0.5898593068122864, train/logprobs = tensor([[-0.8306, -1.1054],
        [-1.0149, -0.6783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13054302334785461
Epoch 0, Step 1399: train/loss = 0.580112874507904, train/raw-loss = 0.5304641127586365, train/logprobs = tensor([[-1.6786, -2.1556],
        [-1.9661, -1.4051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19859497249126434
Epoch 0, Step 1400: train/loss = 0.7314806580543518, train/raw-loss = 0.6818092465400696, train/logprobs = tensor([[-1.7025, -1.5144],
        [-1.9418, -1.6921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19868561625480652
Epoch 0, Step 1401: train/loss = 0.6177709102630615, train/raw-loss = 0.5727485418319702, train/logprobs = tensor([[-1.8581, -2.7685],
        [-2.7229, -2.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18008942902088165
Epoch 0, Step 1402: train/loss = 0.6092730760574341, train/raw-loss = 0.5593273639678955, train/logprobs = tensor([[-1.3768, -1.5428],
        [-1.9580, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19978269934654236
Epoch 0, Step 1403: train/loss = 0.7210162878036499, train/raw-loss = 0.6743776798248291, train/logprobs = tensor([[-1.1244, -1.6446],
        [-1.0738, -1.3745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18655431270599365
Epoch 0, Step 1404: train/loss = 0.6271974444389343, train/raw-loss = 0.5835777521133423, train/logprobs = tensor([[-1.1423, -2.5164],
        [-0.9812, -1.4292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17447859048843384
Epoch 0, Step 1405: train/loss = 0.5368516445159912, train/raw-loss = 0.49234816431999207, train/logprobs = tensor([[-2.0782, -2.3132],
        [-2.7809, -1.2664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1780141144990921
Epoch 0, Step 1406: train/loss = 0.5278295874595642, train/raw-loss = 0.4731689691543579, train/logprobs = tensor([[-1.8369, -2.8561],
        [-1.9381, -1.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21864235401153564
Epoch 0, Step 1407: train/loss = 0.6532281041145325, train/raw-loss = 0.6005046367645264, train/logprobs = tensor([[-1.6277, -2.0440],
        [-1.9983, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2108936905860901
Epoch 0, Step 1408: train/loss = 0.7031514644622803, train/raw-loss = 0.6663321852684021, train/logprobs = tensor([[-1.4582, -1.7695],
        [-1.6632, -1.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1472768932580948
Epoch 0, Step 1409: train/loss = 0.8020449876785278, train/raw-loss = 0.7673130631446838, train/logprobs = tensor([[-1.4038, -1.4369],
        [-2.2825, -2.2506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13892769813537598
Epoch 0, Step 1410: train/loss = 0.5330939292907715, train/raw-loss = 0.48701784014701843, train/logprobs = tensor([[-0.8444, -1.1195],
        [-1.6757, -0.7793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1843043863773346
Epoch 0, Step 1411: train/loss = 0.4567488431930542, train/raw-loss = 0.41173210740089417, train/logprobs = tensor([[-1.3993, -3.7849],
        [-1.4504, -1.6749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18006695806980133
Epoch 0, Step 1412: train/loss = 0.6072148084640503, train/raw-loss = 0.5501143932342529, train/logprobs = tensor([[-2.1120, -2.8222],
        [-1.7999, -1.4062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22840189933776855
Epoch 0, Step 1413: train/loss = 0.5155271291732788, train/raw-loss = 0.4678735136985779, train/logprobs = tensor([[-1.3444, -2.5644],
        [-1.7127, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19061443209648132
Epoch 0, Step 1414: train/loss = 0.6430044174194336, train/raw-loss = 0.5991401672363281, train/logprobs = tensor([[-1.4553, -2.5928],
        [-1.3322, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17545682191848755
Epoch 0, Step 1415: train/loss = 0.6197068691253662, train/raw-loss = 0.5679572820663452, train/logprobs = tensor([[-2.4783, -2.8390],
        [-2.7712, -2.2394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20699840784072876
Epoch 0, Step 1416: train/loss = 0.4027601182460785, train/raw-loss = 0.36205771565437317, train/logprobs = tensor([[-1.4584, -2.6804],
        [-2.0077, -1.0852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16280969977378845
Epoch 0, Step 1417: train/loss = 0.5260002613067627, train/raw-loss = 0.46751245856285095, train/logprobs = tensor([[-1.6347, -4.0595],
        [-1.4953, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23395124077796936
Epoch 0, Step 1418: train/loss = 0.5521273612976074, train/raw-loss = 0.5125930309295654, train/logprobs = tensor([[-1.2591, -0.9996],
        [-1.6540, -0.5022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1581374704837799
Epoch 0, Step 1419: train/loss = 0.48419806361198425, train/raw-loss = 0.446114718914032, train/logprobs = tensor([[-2.0547, -2.5461],
        [-2.8553, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15233337879180908
Epoch 0, Step 1420: train/loss = 0.5977370738983154, train/raw-loss = 0.5436644554138184, train/logprobs = tensor([[-1.8205, -2.0383],
        [-2.5598, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2162904292345047
Epoch 0, Step 1421: train/loss = 0.8375271558761597, train/raw-loss = 0.7983627319335938, train/logprobs = tensor([[-2.5790, -2.1779],
        [-1.9312, -1.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15665745735168457
Epoch 0, Step 1422: train/loss = 0.4622114598751068, train/raw-loss = 0.4173629879951477, train/logprobs = tensor([[-2.0070, -3.7952],
        [-1.9195, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1793939173221588
Epoch 0, Step 1423: train/loss = 0.595045804977417, train/raw-loss = 0.5490896701812744, train/logprobs = tensor([[-1.0793, -1.1484],
        [-1.4161, -0.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1838245689868927
Epoch 0, Step 1424: train/loss = 0.603728175163269, train/raw-loss = 0.5529727935791016, train/logprobs = tensor([[-1.1067, -1.9088],
        [-1.5263, -1.6323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20302146673202515
Epoch 0, Step 1425: train/loss = 0.5403285026550293, train/raw-loss = 0.49572843313217163, train/logprobs = tensor([[-1.9221, -2.7391],
        [-2.2544, -1.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1784002184867859
Epoch 0, Step 1426: train/loss = 0.46111226081848145, train/raw-loss = 0.4059911370277405, train/logprobs = tensor([[-2.1025, -2.9082],
        [-3.4081, -2.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22048458456993103
Epoch 0, Step 1427: train/loss = 0.5772364139556885, train/raw-loss = 0.5230277180671692, train/logprobs = tensor([[-1.4554, -2.5613],
        [-1.4927, -1.5344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2168349027633667
Epoch 0, Step 1428: train/loss = 0.7078994512557983, train/raw-loss = 0.653944730758667, train/logprobs = tensor([[-1.6529, -2.3276],
        [-2.0475, -2.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2158186137676239
Epoch 0, Step 1429: train/loss = 0.6267139911651611, train/raw-loss = 0.5903772115707397, train/logprobs = tensor([[-1.1256, -2.7224],
        [-1.0720, -1.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1453469693660736
Epoch 0, Step 1430: train/loss = 0.6299330592155457, train/raw-loss = 0.5854911208152771, train/logprobs = tensor([[-2.0675, -2.6425],
        [-1.9571, -1.4819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17776766419410706
Epoch 0, Step 1431: train/loss = 0.634073793888092, train/raw-loss = 0.5919634699821472, train/logprobs = tensor([[-1.9532, -2.0579],
        [-2.1175, -1.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16844132542610168
Epoch 0, Step 1432: train/loss = 0.3688849210739136, train/raw-loss = 0.31226271390914917, train/logprobs = tensor([[-1.3437, -4.8798],
        [-2.7122, -3.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22648866474628448
Epoch 0, Step 1433: train/loss = 0.5137935280799866, train/raw-loss = 0.45661675930023193, train/logprobs = tensor([[-1.2769, -2.2553],
        [-2.2522, -1.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22870709002017975
Epoch 0, Step 1434: train/loss = 0.5319914817810059, train/raw-loss = 0.47942864894866943, train/logprobs = tensor([[-1.3913, -2.3133],
        [-1.9312, -1.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21025125682353973
Epoch 0, Step 1435: train/loss = 0.5919904708862305, train/raw-loss = 0.5526717901229858, train/logprobs = tensor([[-1.9132, -1.5694],
        [-2.1148, -1.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15727490186691284
Epoch 0, Step 1436: train/loss = 0.6515772342681885, train/raw-loss = 0.6095879077911377, train/logprobs = tensor([[-1.9409, -2.9715],
        [-1.5922, -1.4181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16795724630355835
Epoch 0, Step 1437: train/loss = 0.6034851670265198, train/raw-loss = 0.5560033321380615, train/logprobs = tensor([[-1.5413, -1.9988],
        [-2.1459, -1.8593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18992750346660614
Epoch 0, Step 1438: train/loss = 0.7472565174102783, train/raw-loss = 0.7019280195236206, train/logprobs = tensor([[-2.3450, -3.0467],
        [-2.1599, -2.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1813141256570816
Epoch 0, Step 1439: train/loss = 0.8834572434425354, train/raw-loss = 0.8343900442123413, train/logprobs = tensor([[-1.3692, -1.3341],
        [-1.9027, -2.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1962689757347107
Epoch 0, Step 1440: train/loss = 0.6426980495452881, train/raw-loss = 0.5898429155349731, train/logprobs = tensor([[-1.9722, -2.2057],
        [-2.4996, -2.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21142041683197021
Epoch 0, Step 1441: train/loss = 0.6104184985160828, train/raw-loss = 0.5660736560821533, train/logprobs = tensor([[-1.3087, -1.9172],
        [-1.7923, -1.1075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17737913131713867
Epoch 0, Step 1442: train/loss = 0.6653518676757812, train/raw-loss = 0.6290382146835327, train/logprobs = tensor([[-1.2602, -1.2765],
        [-0.9331, -0.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14525441825389862
Epoch 0, Step 1443: train/loss = 0.5896652936935425, train/raw-loss = 0.5466338992118835, train/logprobs = tensor([[-1.7621, -2.5146],
        [-1.9599, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1721256673336029
Epoch 0, Step 1444: train/loss = 0.6432213187217712, train/raw-loss = 0.5971726775169373, train/logprobs = tensor([[-2.2237, -2.4693],
        [-2.6234, -2.3301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18419454991817474
Epoch 0, Step 1445: train/loss = 0.626776933670044, train/raw-loss = 0.5900883078575134, train/logprobs = tensor([[-1.5322, -1.3603],
        [-1.7525, -0.8312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14675435423851013
Epoch 0, Step 1446: train/loss = 0.6088657379150391, train/raw-loss = 0.5754095315933228, train/logprobs = tensor([[-1.0038, -1.2516],
        [-1.0580, -0.5992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13382488489151
Epoch 0, Step 1447: train/loss = 0.5906117558479309, train/raw-loss = 0.5420941114425659, train/logprobs = tensor([[-2.2500, -2.6102],
        [-2.4394, -2.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19407066702842712
Epoch 0, Step 1448: train/loss = 0.6228899955749512, train/raw-loss = 0.5880659818649292, train/logprobs = tensor([[-1.0217, -1.1285],
        [-1.3710, -0.9268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1392962634563446
Epoch 0, Step 1449: train/loss = 0.4685102701187134, train/raw-loss = 0.424064040184021, train/logprobs = tensor([[-0.8440, -2.0683],
        [-1.4238, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17778494954109192
Epoch 0, Step 1450: train/loss = 0.5949951410293579, train/raw-loss = 0.5447447299957275, train/logprobs = tensor([[-0.9625, -1.5663],
        [-1.6309, -1.0703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20100167393684387
Epoch 0, Step 1451: train/loss = 0.6089085936546326, train/raw-loss = 0.5736193656921387, train/logprobs = tensor([[-1.2135, -1.7554],
        [-1.1754, -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14115691184997559
Epoch 0, Step 1452: train/loss = 0.6559281945228577, train/raw-loss = 0.6238398551940918, train/logprobs = tensor([[-1.4115, -2.3290],
        [-0.7960, -1.1205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12835311889648438
Epoch 0, Step 1453: train/loss = 0.5987682938575745, train/raw-loss = 0.5578548908233643, train/logprobs = tensor([[-1.6174, -2.5751],
        [-1.7966, -1.6404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16365382075309753
Epoch 0, Step 1454: train/loss = 0.6198895573616028, train/raw-loss = 0.5789884328842163, train/logprobs = tensor([[-1.6109, -2.5776],
        [-1.5504, -1.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16360455751419067
Epoch 0, Step 1455: train/loss = 0.5100845098495483, train/raw-loss = 0.464079350233078, train/logprobs = tensor([[-1.0812, -1.7069],
        [-1.8269, -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18402092158794403
Epoch 0, Step 1456: train/loss = 0.49217793345451355, train/raw-loss = 0.4498758912086487, train/logprobs = tensor([[-1.7950, -2.5264],
        [-2.7840, -1.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16920819878578186
Epoch 0, Step 1457: train/loss = 0.6118636131286621, train/raw-loss = 0.5662423372268677, train/logprobs = tensor([[-1.6364, -3.4209],
        [-1.1752, -1.5760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18248477578163147
Epoch 0, Step 1458: train/loss = 0.6669782400131226, train/raw-loss = 0.6291207671165466, train/logprobs = tensor([[-1.4395, -2.1679],
        [-1.5061, -1.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15143001079559326
Epoch 0, Step 1459: train/loss = 0.5010102987289429, train/raw-loss = 0.45455917716026306, train/logprobs = tensor([[-1.3514, -2.8685],
        [-1.9756, -1.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18580453097820282
Epoch 0, Step 1460: train/loss = 0.7880489826202393, train/raw-loss = 0.7503827810287476, train/logprobs = tensor([[-1.5969, -1.9123],
        [-0.6513, -0.7391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15066474676132202
Epoch 0, Step 1461: train/loss = 0.6633768677711487, train/raw-loss = 0.6139708161354065, train/logprobs = tensor([[-1.5349, -1.8155],
        [-1.6172, -1.3911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19762451946735382
Epoch 0, Step 1462: train/loss = 0.7477744221687317, train/raw-loss = 0.7110365033149719, train/logprobs = tensor([[-2.0719, -2.2296],
        [-1.5717, -1.6607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14695163071155548
Epoch 0, Step 1463: train/loss = 0.4270526170730591, train/raw-loss = 0.37827765941619873, train/logprobs = tensor([[-1.1296, -4.5439],
        [-1.5141, -2.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950998306274414
Epoch 0, Step 1464: train/loss = 0.5629578828811646, train/raw-loss = 0.5279790163040161, train/logprobs = tensor([[-0.8041, -1.5163],
        [-0.9359, -0.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13991539180278778
Epoch 0, Step 1465: train/loss = 0.5820649862289429, train/raw-loss = 0.5435312986373901, train/logprobs = tensor([[-2.2911, -2.0465],
        [-2.4064, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1541346162557602
Epoch 0, Step 1466: train/loss = 0.4977567195892334, train/raw-loss = 0.4548127055168152, train/logprobs = tensor([[-1.8770, -3.8693],
        [-2.3408, -2.3158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1717761904001236
Epoch 0, Step 1467: train/loss = 0.7480135560035706, train/raw-loss = 0.7044731378555298, train/logprobs = tensor([[-2.3193, -2.0440],
        [-2.3702, -2.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17416150867938995
Epoch 0, Step 1468: train/loss = 0.5255295634269714, train/raw-loss = 0.4764724373817444, train/logprobs = tensor([[-1.8835, -2.6711],
        [-2.6467, -1.8224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19622842967510223
Epoch 0, Step 1469: train/loss = 0.7156845927238464, train/raw-loss = 0.6869291067123413, train/logprobs = tensor([[-1.1826, -2.0168],
        [-0.6496, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11502194404602051
Epoch 0, Step 1470: train/loss = 0.6300687789916992, train/raw-loss = 0.5814832448959351, train/logprobs = tensor([[-1.8013, -2.2245],
        [-1.7670, -1.4664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19434213638305664
Epoch 0, Step 1471: train/loss = 0.7144380807876587, train/raw-loss = 0.6837787628173828, train/logprobs = tensor([[-1.1673, -0.9382],
        [-0.9554, -0.6575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12263759970664978
Epoch 0, Step 1472: train/loss = 0.4735681414604187, train/raw-loss = 0.4223397970199585, train/logprobs = tensor([[-1.3633, -2.1404],
        [-1.6904, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20491325855255127
Epoch 0, Step 1473: train/loss = 0.5422170758247375, train/raw-loss = 0.4917716383934021, train/logprobs = tensor([[-1.9936, -2.8219],
        [-2.6379, -2.4193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20178183913230896
Epoch 0, Step 1474: train/loss = 0.7163721323013306, train/raw-loss = 0.665860652923584, train/logprobs = tensor([[-1.5546, -3.0053],
        [-3.8444, -3.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20204581320285797
Epoch 0, Step 1475: train/loss = 0.5122673511505127, train/raw-loss = 0.44402194023132324, train/logprobs = tensor([[-1.3871, -3.0481],
        [-3.3534, -2.5087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27298179268836975
Epoch 0, Step 1476: train/loss = 0.5430300831794739, train/raw-loss = 0.5059224367141724, train/logprobs = tensor([[-1.5896, -2.2511],
        [-1.9120, -1.2668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14843058586120605
Epoch 0, Step 1477: train/loss = 0.5065565705299377, train/raw-loss = 0.45076867938041687, train/logprobs = tensor([[-1.4613, -2.3854],
        [-2.4852, -1.8316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2231515794992447
Epoch 0, Step 1478: train/loss = 0.7197608947753906, train/raw-loss = 0.6914110779762268, train/logprobs = tensor([[-1.3698, -1.2071],
        [-1.0649, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11339918524026871
Epoch 0, Step 1479: train/loss = 0.6997746825218201, train/raw-loss = 0.6466398239135742, train/logprobs = tensor([[-2.1110, -2.1990],
        [-2.3156, -1.8406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21253950893878937
Epoch 0, Step 1480: train/loss = 0.5977268218994141, train/raw-loss = 0.5643899440765381, train/logprobs = tensor([[-1.2417, -1.3104],
        [-1.4173, -0.6516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13334764540195465
Epoch 0, Step 1481: train/loss = 0.6633166670799255, train/raw-loss = 0.6197904944419861, train/logprobs = tensor([[-1.7338, -0.9448],
        [-2.2157, -1.0454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.174104705452919
Epoch 0, Step 1482: train/loss = 0.49122190475463867, train/raw-loss = 0.44683030247688293, train/logprobs = tensor([[-1.2267, -3.0708],
        [-1.6668, -1.5393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17756637930870056
Epoch 0, Step 1483: train/loss = 0.8409607410430908, train/raw-loss = 0.8031080961227417, train/logprobs = tensor([[-2.1341, -3.2804],
        [-1.0623, -2.1571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15141059458255768
Epoch 0, Step 1484: train/loss = 0.4848138391971588, train/raw-loss = 0.4432443678379059, train/logprobs = tensor([[-1.1081, -1.1662],
        [-2.5110, -0.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16627785563468933
Epoch 0, Step 1485: train/loss = 0.6231129765510559, train/raw-loss = 0.5746697187423706, train/logprobs = tensor([[-1.0206, -1.4374],
        [-1.8743, -0.9784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19377312064170837
Epoch 0, Step 1486: train/loss = 0.6484866142272949, train/raw-loss = 0.600387692451477, train/logprobs = tensor([[-2.0399, -2.2164],
        [-2.0793, -1.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19239555299282074
Epoch 0, Step 1487: train/loss = 0.4497244358062744, train/raw-loss = 0.40476712584495544, train/logprobs = tensor([[-0.8838, -2.7404],
        [-1.5814, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17982932925224304
Epoch 0, Step 1488: train/loss = 0.5966870784759521, train/raw-loss = 0.5470983982086182, train/logprobs = tensor([[-1.9296, -3.3349],
        [-2.6911, -2.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1983548104763031
Epoch 0, Step 1489: train/loss = 0.5780192017555237, train/raw-loss = 0.5372248291969299, train/logprobs = tensor([[-1.8108, -2.9317],
        [-1.7486, -1.7453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16317763924598694
Epoch 0, Step 1490: train/loss = 0.5288781523704529, train/raw-loss = 0.4777015447616577, train/logprobs = tensor([[-2.6988, -4.7313],
        [-3.2735, -2.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20470641553401947
Epoch 0, Step 1491: train/loss = 0.6172385215759277, train/raw-loss = 0.5819950103759766, train/logprobs = tensor([[-1.8344, -1.5792],
        [-1.8596, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14097414910793304
Epoch 0, Step 1492: train/loss = 0.5819135904312134, train/raw-loss = 0.5334593057632446, train/logprobs = tensor([[-0.9250, -1.3763],
        [-1.8069, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19381704926490784
Epoch 0, Step 1493: train/loss = 0.44947412610054016, train/raw-loss = 0.39661070704460144, train/logprobs = tensor([[-1.0061, -2.0288],
        [-2.1146, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21145358681678772
Epoch 0, Step 1494: train/loss = 0.7699806690216064, train/raw-loss = 0.7280423641204834, train/logprobs = tensor([[-1.4985, -2.1620],
        [-0.8367, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1677531898021698
Epoch 0, Step 1495: train/loss = 0.6128931045532227, train/raw-loss = 0.5664049386978149, train/logprobs = tensor([[-1.6329, -2.2561],
        [-2.2710, -1.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18595261871814728
Epoch 0, Step 1496: train/loss = 0.5220044851303101, train/raw-loss = 0.4797758162021637, train/logprobs = tensor([[-1.5366, -2.1989],
        [-1.7707, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16891485452651978
Epoch 0, Step 1497: train/loss = 0.44735440611839294, train/raw-loss = 0.39121851325035095, train/logprobs = tensor([[-1.1162, -4.3879],
        [-2.1176, -2.0447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2245435118675232
Epoch 0, Step 1498: train/loss = 0.6855786442756653, train/raw-loss = 0.6409854888916016, train/logprobs = tensor([[-1.5321, -1.9269],
        [-1.5197, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17837266623973846
Epoch 0, Step 1499: train/loss = 0.8026890754699707, train/raw-loss = 0.7694282531738281, train/logprobs = tensor([[-2.3561, -2.4994],
        [-1.7760, -2.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.133043110370636
eval/loss: 0.586253821849823
Epoch 0, Step 1500: train/loss = 0.6113460659980774, train/raw-loss = 0.5630216598510742, train/logprobs = tensor([[-2.0563, -2.0464],
        [-2.3134, -1.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19329753518104553
Epoch 0, Step 1501: train/loss = 0.39555561542510986, train/raw-loss = 0.3429313600063324, train/logprobs = tensor([[-1.1574, -2.3144],
        [-2.9748, -1.1867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21049702167510986
Epoch 0, Step 1502: train/loss = 0.5537705421447754, train/raw-loss = 0.5052871704101562, train/logprobs = tensor([[-1.4057, -2.8048],
        [-2.9720, -1.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19393348693847656
Epoch 0, Step 1503: train/loss = 0.6207214593887329, train/raw-loss = 0.5861443877220154, train/logprobs = tensor([[-1.2334, -1.4543],
        [-1.1987, -0.5443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1383083015680313
Epoch 0, Step 1504: train/loss = 0.5343334674835205, train/raw-loss = 0.4698333740234375, train/logprobs = tensor([[-1.5988, -2.6190],
        [-3.0164, -2.0842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2580004036426544
Epoch 0, Step 1505: train/loss = 0.4886481761932373, train/raw-loss = 0.44630008935928345, train/logprobs = tensor([[-1.2500, -1.6993],
        [-2.6336, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16939246654510498
Epoch 0, Step 1506: train/loss = 0.5293092727661133, train/raw-loss = 0.4839186668395996, train/logprobs = tensor([[-1.4574, -1.7760],
        [-2.2890, -1.2567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.181562602519989
Epoch 0, Step 1507: train/loss = 0.496705025434494, train/raw-loss = 0.4442378878593445, train/logprobs = tensor([[-0.8543, -1.5420],
        [-1.9648, -1.0193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20986858010292053
Epoch 0, Step 1508: train/loss = 0.6344904899597168, train/raw-loss = 0.5902439951896667, train/logprobs = tensor([[-1.9504, -3.3056],
        [-2.0484, -2.0684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17698605358600616
Epoch 0, Step 1509: train/loss = 0.449268102645874, train/raw-loss = 0.4039396643638611, train/logprobs = tensor([[-2.1131, -4.0051],
        [-2.8578, -2.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18131393194198608
Epoch 0, Step 1510: train/loss = 0.6563585996627808, train/raw-loss = 0.6100426912307739, train/logprobs = tensor([[-1.6355, -2.6420],
        [-0.9879, -0.8911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852637678384781
Epoch 0, Step 1511: train/loss = 0.6322214007377625, train/raw-loss = 0.5883839130401611, train/logprobs = tensor([[-1.0894, -2.0927],
        [-1.2668, -0.5243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17535005509853363
Epoch 0, Step 1512: train/loss = 0.47020432353019714, train/raw-loss = 0.4190821647644043, train/logprobs = tensor([[-1.1372, -3.1557],
        [-1.4253, -1.6407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20448876917362213
Epoch 0, Step 1513: train/loss = 0.4099210500717163, train/raw-loss = 0.3520532250404358, train/logprobs = tensor([[-1.7237, -3.6338],
        [-2.9965, -1.8950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23147127032279968
Epoch 0, Step 1514: train/loss = 0.6424627304077148, train/raw-loss = 0.6006695032119751, train/logprobs = tensor([[-1.8511, -1.8000],
        [-2.2983, -1.3795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16717290878295898
Epoch 0, Step 1515: train/loss = 0.8968032002449036, train/raw-loss = 0.8634995222091675, train/logprobs = tensor([[-1.2166, -2.9433],
        [-1.2505, -3.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1332148313522339
Epoch 0, Step 1516: train/loss = 0.5568928718566895, train/raw-loss = 0.5122644305229187, train/logprobs = tensor([[-1.8914, -2.4492],
        [-2.4083, -1.0053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1785140335559845
Epoch 0, Step 1517: train/loss = 0.5194889903068542, train/raw-loss = 0.48120930790901184, train/logprobs = tensor([[-1.3136, -2.5700],
        [-2.4018, -1.0508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15311874449253082
Epoch 0, Step 1518: train/loss = 0.6062616109848022, train/raw-loss = 0.5538504719734192, train/logprobs = tensor([[-2.0035, -2.6914],
        [-2.5806, -2.0714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20964449644088745
Epoch 0, Step 1519: train/loss = 0.6113274097442627, train/raw-loss = 0.5709976553916931, train/logprobs = tensor([[-1.6688, -1.6192],
        [-1.8636, -1.0646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16131901741027832
Epoch 0, Step 1520: train/loss = 0.39222002029418945, train/raw-loss = 0.347353994846344, train/logprobs = tensor([[-1.9459, -2.4652],
        [-3.0864, -1.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17946414649486542
Epoch 0, Step 1521: train/loss = 0.5076302886009216, train/raw-loss = 0.4600553512573242, train/logprobs = tensor([[-2.3490, -2.0832],
        [-3.8300, -1.1451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19029976427555084
Epoch 0, Step 1522: train/loss = 0.5725500583648682, train/raw-loss = 0.5237778425216675, train/logprobs = tensor([[-3.0101, -3.4973],
        [-3.0633, -2.5755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1950887143611908
Epoch 0, Step 1523: train/loss = 0.7635665535926819, train/raw-loss = 0.7200933694839478, train/logprobs = tensor([[-1.9677, -1.1586],
        [-2.2972, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17389288544654846
Epoch 0, Step 1524: train/loss = 0.40673303604125977, train/raw-loss = 0.3503023684024811, train/logprobs = tensor([[-1.4867, -2.5306],
        [-3.7564, -1.6809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22572264075279236
Epoch 0, Step 1525: train/loss = 0.8470128178596497, train/raw-loss = 0.8057776093482971, train/logprobs = tensor([[-2.7457, -1.8713],
        [-2.3319, -1.6263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16494084894657135
Epoch 0, Step 1526: train/loss = 0.6708288788795471, train/raw-loss = 0.6343855857849121, train/logprobs = tensor([[-2.0241, -1.8498],
        [-2.3311, -1.8443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1457732766866684
Epoch 0, Step 1527: train/loss = 0.5735136270523071, train/raw-loss = 0.5271401405334473, train/logprobs = tensor([[-2.1033, -1.1924],
        [-2.5969, -0.8745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1854938566684723
Epoch 0, Step 1528: train/loss = 0.7085435390472412, train/raw-loss = 0.6579439640045166, train/logprobs = tensor([[-2.1497, -1.8999],
        [-2.0948, -1.2691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20239858329296112
Epoch 0, Step 1529: train/loss = 0.7008620500564575, train/raw-loss = 0.6519559025764465, train/logprobs = tensor([[-1.3539, -2.0205],
        [-1.4641, -1.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19562476873397827
Epoch 0, Step 1530: train/loss = 0.5441436767578125, train/raw-loss = 0.4937296509742737, train/logprobs = tensor([[-2.6505, -2.9947],
        [-3.8023, -2.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20165622234344482
Epoch 0, Step 1531: train/loss = 0.6400161981582642, train/raw-loss = 0.583832859992981, train/logprobs = tensor([[-1.8680, -2.4336],
        [-2.4118, -2.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22473332285881042
Epoch 0, Step 1532: train/loss = 0.5309287309646606, train/raw-loss = 0.4812833070755005, train/logprobs = tensor([[-2.3199, -2.7249],
        [-2.9990, -2.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19858182966709137
Epoch 0, Step 1533: train/loss = 0.666042685508728, train/raw-loss = 0.6183502078056335, train/logprobs = tensor([[-0.9590, -1.6547],
        [-1.6139, -1.7213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1907699704170227
Epoch 0, Step 1534: train/loss = 0.542631983757019, train/raw-loss = 0.4906856119632721, train/logprobs = tensor([[-1.3547, -2.6045],
        [-1.9450, -1.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20778565108776093
Epoch 0, Step 1535: train/loss = 0.4315437972545624, train/raw-loss = 0.3763549327850342, train/logprobs = tensor([[-1.0803, -2.1805],
        [-1.8267, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2207554429769516
Epoch 0, Step 1536: train/loss = 0.6861340999603271, train/raw-loss = 0.6307132244110107, train/logprobs = tensor([[-1.7935, -1.2571],
        [-2.4523, -1.4373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22168362140655518
Epoch 0, Step 1537: train/loss = 0.5377770066261292, train/raw-loss = 0.49045637249946594, train/logprobs = tensor([[-1.6120, -2.8612],
        [-2.7366, -1.3945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1892825961112976
Epoch 0, Step 1538: train/loss = 0.8693129420280457, train/raw-loss = 0.8375464677810669, train/logprobs = tensor([[-1.7249, -1.2735],
        [-1.6269, -1.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270657330751419
Epoch 0, Step 1539: train/loss = 0.719024121761322, train/raw-loss = 0.6733080148696899, train/logprobs = tensor([[-1.6288, -1.7067],
        [-1.8834, -1.6722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1828644722700119
Epoch 0, Step 1540: train/loss = 0.45514869689941406, train/raw-loss = 0.4122421145439148, train/logprobs = tensor([[-1.0474, -2.3783],
        [-2.4636, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1716262847185135
Epoch 0, Step 1541: train/loss = 0.4863559603691101, train/raw-loss = 0.4431838393211365, train/logprobs = tensor([[-1.2076, -3.4630],
        [-1.5178, -1.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1726885735988617
Epoch 0, Step 1542: train/loss = 0.559244692325592, train/raw-loss = 0.5117529034614563, train/logprobs = tensor([[-1.3560, -1.9552],
        [-4.1648, -1.9203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18996703624725342
Epoch 0, Step 1543: train/loss = 0.6580725908279419, train/raw-loss = 0.6132183074951172, train/logprobs = tensor([[-2.5119, -1.7526],
        [-2.6645, -1.3297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1794169843196869
Epoch 0, Step 1544: train/loss = 0.32986271381378174, train/raw-loss = 0.2718525528907776, train/logprobs = tensor([[-1.9658, -3.6838],
        [-3.3811, -1.6817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.232040673494339
Epoch 0, Step 1545: train/loss = 0.6992976665496826, train/raw-loss = 0.6610512137413025, train/logprobs = tensor([[-1.3166, -2.4258],
        [-1.2488, -1.6738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15298567712306976
Epoch 0, Step 1546: train/loss = 0.7519930601119995, train/raw-loss = 0.698661744594574, train/logprobs = tensor([[-2.2862, -2.4297],
        [-2.4189, -2.4682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21332521736621857
Epoch 0, Step 1547: train/loss = 0.7364354133605957, train/raw-loss = 0.691030740737915, train/logprobs = tensor([[-1.0943, -1.1204],
        [-1.5520, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18161892890930176
Epoch 0, Step 1548: train/loss = 0.44411975145339966, train/raw-loss = 0.3832729458808899, train/logprobs = tensor([[-1.4679, -3.1809],
        [-3.3331, -1.3049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.243387371301651
Epoch 0, Step 1549: train/loss = 1.0864932537078857, train/raw-loss = 1.0458056926727295, train/logprobs = tensor([[-3.4769, -3.6881],
        [-2.9983, -1.5234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16275057196617126
Epoch 0, Step 1550: train/loss = 0.702908456325531, train/raw-loss = 0.6579846739768982, train/logprobs = tensor([[-2.2547, -5.5009],
        [-1.2655, -2.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17969506978988647
Epoch 0, Step 1551: train/loss = 0.747078001499176, train/raw-loss = 0.7134525179862976, train/logprobs = tensor([[-2.4071, -3.6691],
        [-1.3440, -1.2983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1345018446445465
Epoch 0, Step 1552: train/loss = 0.49651673436164856, train/raw-loss = 0.4543113708496094, train/logprobs = tensor([[-1.5809, -1.9577],
        [-3.0753, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16882145404815674
Epoch 0, Step 1553: train/loss = 0.6270366907119751, train/raw-loss = 0.5857093334197998, train/logprobs = tensor([[-1.5666, -1.6839],
        [-2.5103, -0.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16530968248844147
Epoch 0, Step 1554: train/loss = 0.702698826789856, train/raw-loss = 0.6488450765609741, train/logprobs = tensor([[-1.4812, -3.2570],
        [-2.8542, -2.6042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21541522443294525
Epoch 0, Step 1555: train/loss = 0.5888083577156067, train/raw-loss = 0.5404078960418701, train/logprobs = tensor([[-2.9103, -3.1760],
        [-3.5549, -3.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19360195100307465
Epoch 0, Step 1556: train/loss = 0.6607384085655212, train/raw-loss = 0.6130241751670837, train/logprobs = tensor([[-0.6171, -0.7782],
        [-1.8756, -1.3782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19085679948329926
Epoch 0, Step 1557: train/loss = 0.6929495334625244, train/raw-loss = 0.6533610224723816, train/logprobs = tensor([[-1.2530, -1.3856],
        [-1.1870, -1.1237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1583540141582489
Epoch 0, Step 1558: train/loss = 0.38860201835632324, train/raw-loss = 0.346538782119751, train/logprobs = tensor([[-1.0480, -2.9967],
        [-2.2251, -1.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16825303435325623
Epoch 0, Step 1559: train/loss = 0.6008544564247131, train/raw-loss = 0.5611279010772705, train/logprobs = tensor([[-2.0579, -3.2994],
        [-1.7463, -1.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15890637040138245
Epoch 0, Step 1560: train/loss = 0.41994911432266235, train/raw-loss = 0.36896178126335144, train/logprobs = tensor([[-1.9017, -4.4192],
        [-2.1472, -2.1543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2039494663476944
Epoch 0, Step 1561: train/loss = 0.6121000051498413, train/raw-loss = 0.5549258589744568, train/logprobs = tensor([[-1.6915, -2.2992],
        [-2.4554, -2.1594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22869673371315002
Epoch 0, Step 1562: train/loss = 0.8840934038162231, train/raw-loss = 0.8220776915550232, train/logprobs = tensor([[-1.0958, -1.1871],
        [-2.2710, -2.3667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24806293845176697
Epoch 0, Step 1563: train/loss = 0.38299646973609924, train/raw-loss = 0.3352157473564148, train/logprobs = tensor([[-1.5482, -3.2000],
        [-2.5805, -1.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1911230981349945
Epoch 0, Step 1564: train/loss = 0.438332736492157, train/raw-loss = 0.39271458983421326, train/logprobs = tensor([[-1.5440, -4.7294],
        [-2.8293, -3.7559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18247264623641968
Epoch 0, Step 1565: train/loss = 0.5818131566047668, train/raw-loss = 0.5397676229476929, train/logprobs = tensor([[-1.9155, -2.4208],
        [-2.3202, -2.1101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16818204522132874
