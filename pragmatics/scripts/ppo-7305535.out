[2024-02-24 14:01:39,304][root][INFO] - beta: 0.3
[2024-02-24 14:01:39,304][root][INFO] - loss with_labels
[2024-02-24 14:01:39,304][root][INFO] - max_iter: 0
[2024-02-24 14:01:39,305][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-with-labels
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-with-labels after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-with-labels after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-with-labels after each epoch.
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-with-labels after each epoch.
Epoch 0, Step 0: train/loss = 0.701119065284729, train/raw-loss = 0.700703501701355, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001385421957820654
Epoch 0, Step 1: train/loss = 0.695196270942688, train/raw-loss = 0.6946866512298584, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016988443676382303
Epoch 0, Step 2: train/loss = 0.6924762725830078, train/raw-loss = 0.6923112869262695, train/logprobs = tensor([[-1.0892, -2.0869],
        [-1.1206, -2.1103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005500263068825006
Epoch 0, Step 3: train/loss = 0.6872376203536987, train/raw-loss = 0.6862989068031311, train/logprobs = tensor([[-0.5922, -1.4420],
        [-0.5997, -1.4088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031291749328374863
Epoch 0, Step 4: train/loss = 0.6824706792831421, train/raw-loss = 0.6821818947792053, train/logprobs = tensor([[-0.9682, -2.2517],
        [-1.0031, -2.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009627505205571651
Epoch 0, Step 5: train/loss = 0.699913501739502, train/raw-loss = 0.6991856098175049, train/logprobs = tensor([[-1.2526, -1.8470],
        [-1.2661, -1.8698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024260750506073236
Epoch 0, Step 6: train/loss = 0.6912795305252075, train/raw-loss = 0.6907837390899658, train/logprobs = tensor([[-0.9823, -1.5991],
        [-1.0011, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016527380794286728
Epoch 0, Step 7: train/loss = 0.7025402784347534, train/raw-loss = 0.7020244598388672, train/logprobs = tensor([[-1.0630, -1.5507],
        [-1.1077, -1.6226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017196990083903074
Epoch 0, Step 8: train/loss = 0.6934972405433655, train/raw-loss = 0.6930682063102722, train/logprobs = tensor([[-0.8023, -1.7333],
        [-0.7871, -1.7088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014302500057965517
Epoch 0, Step 9: train/loss = 0.6983920931816101, train/raw-loss = 0.6962793469429016, train/logprobs = tensor([[-1.0835, -1.7181],
        [-1.0813, -1.6973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007042370270937681
Epoch 0, Step 10: train/loss = 0.7026885747909546, train/raw-loss = 0.6965494155883789, train/logprobs = tensor([[-1.1971, -2.5060],
        [-1.2764, -2.5027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020463809370994568
Epoch 0, Step 11: train/loss = 0.6864162683486938, train/raw-loss = 0.6862969398498535, train/logprobs = tensor([[-0.7466, -1.5640],
        [-0.7228, -1.5107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039786301204003394
Epoch 0, Step 12: train/loss = 0.7193931937217712, train/raw-loss = 0.7148674726486206, train/logprobs = tensor([[-0.7433, -1.8789],
        [-0.7825, -1.8867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015085747465491295
Epoch 0, Step 13: train/loss = 0.6876940727233887, train/raw-loss = 0.6869643926620483, train/logprobs = tensor([[-0.7519, -1.6611],
        [-0.7745, -1.6382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002432220848277211
Epoch 0, Step 14: train/loss = 0.6854386925697327, train/raw-loss = 0.684917688369751, train/logprobs = tensor([[-1.1222, -1.7514],
        [-1.1230, -1.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017367040272802114
Epoch 0, Step 15: train/loss = 0.7046009302139282, train/raw-loss = 0.7035808563232422, train/logprobs = tensor([[-1.0901, -1.5558],
        [-1.0901, -1.5823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034001865424215794
Epoch 0, Step 16: train/loss = 0.7133563160896301, train/raw-loss = 0.705668568611145, train/logprobs = tensor([[-0.9616, -2.0296],
        [-0.9940, -1.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025626003742218018
Epoch 0, Step 17: train/loss = 0.6930281519889832, train/raw-loss = 0.6924867033958435, train/logprobs = tensor([[-1.0904, -1.5065],
        [-1.0878, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018046624027192593
Epoch 0, Step 18: train/loss = 0.693797767162323, train/raw-loss = 0.6928467154502869, train/logprobs = tensor([[-1.1498, -1.6923],
        [-1.1412, -1.6685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031702592968940735
Epoch 0, Step 19: train/loss = 0.6985080242156982, train/raw-loss = 0.6973589658737183, train/logprobs = tensor([[-0.7575, -1.3558],
        [-0.7511, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038300659507513046
Epoch 0, Step 20: train/loss = 0.7574831247329712, train/raw-loss = 0.751427173614502, train/logprobs = tensor([[-0.6982, -1.6722],
        [-0.7384, -1.6710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020186442881822586
Epoch 0, Step 21: train/loss = 0.6947137117385864, train/raw-loss = 0.6941919326782227, train/logprobs = tensor([[-0.9935, -1.2997],
        [-0.9919, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017392875161021948
Epoch 0, Step 22: train/loss = 0.6887776851654053, train/raw-loss = 0.6880555152893066, train/logprobs = tensor([[-1.1048, -1.2115],
        [-1.1166, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002407266292721033
Epoch 0, Step 23: train/loss = 0.7296137809753418, train/raw-loss = 0.7249387502670288, train/logprobs = tensor([[-1.1101, -1.9440],
        [-1.1279, -2.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015583477914333344
Epoch 0, Step 24: train/loss = 0.6902292370796204, train/raw-loss = 0.6900442838668823, train/logprobs = tensor([[-0.9510, -2.1814],
        [-0.9490, -2.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006165502709336579
Epoch 0, Step 25: train/loss = 0.6855334043502808, train/raw-loss = 0.6853428483009338, train/logprobs = tensor([[-0.8277, -2.2563],
        [-0.8247, -2.2167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006352229975163937
Epoch 0, Step 26: train/loss = 0.6986502408981323, train/raw-loss = 0.6981753706932068, train/logprobs = tensor([[-0.5759, -2.1066],
        [-0.6087, -2.1473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015831212513148785
Epoch 0, Step 27: train/loss = 0.6975855827331543, train/raw-loss = 0.6973809003829956, train/logprobs = tensor([[-1.0402, -2.5564],
        [-1.0804, -2.5702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006825224263593554
Epoch 0, Step 28: train/loss = 0.6996586918830872, train/raw-loss = 0.6975324153900146, train/logprobs = tensor([[-0.8392, -1.7205],
        [-0.8369, -1.6912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007087648846209049
Epoch 0, Step 29: train/loss = 0.6936053037643433, train/raw-loss = 0.6934842467308044, train/logprobs = tensor([[-0.5879, -1.8914],
        [-0.5988, -1.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040351462666876614
Epoch 0, Step 30: train/loss = 0.6924166679382324, train/raw-loss = 0.6918355822563171, train/logprobs = tensor([[-0.8561, -1.1920],
        [-0.8388, -1.1585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001937028020620346
Epoch 0, Step 31: train/loss = 0.6744168996810913, train/raw-loss = 0.672492265701294, train/logprobs = tensor([[-1.0550, -2.2670],
        [-1.0818, -2.1798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006415537558495998
Epoch 0, Step 32: train/loss = 0.6902974247932434, train/raw-loss = 0.6886965036392212, train/logprobs = tensor([[-0.9240, -1.9170],
        [-0.9467, -1.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005336553789675236
Epoch 0, Step 33: train/loss = 0.7022536396980286, train/raw-loss = 0.7009933590888977, train/logprobs = tensor([[-0.8779, -1.8828],
        [-0.8573, -1.8740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004200874827802181
Epoch 0, Step 34: train/loss = 0.6993910074234009, train/raw-loss = 0.6958221793174744, train/logprobs = tensor([[-1.0511, -1.5128],
        [-1.0826, -1.5036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011896110139787197
Epoch 0, Step 35: train/loss = 0.7082714438438416, train/raw-loss = 0.7038596868515015, train/logprobs = tensor([[-0.9902, -1.8427],
        [-0.9916, -1.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014705857262015343
Epoch 0, Step 36: train/loss = 0.7037098407745361, train/raw-loss = 0.6996639966964722, train/logprobs = tensor([[-1.2729, -1.4568],
        [-1.2776, -1.4303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013486114330589771
Epoch 0, Step 37: train/loss = 0.6883732676506042, train/raw-loss = 0.6881989240646362, train/logprobs = tensor([[-0.6132, -1.4763],
        [-0.6105, -1.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005811454029753804
Epoch 0, Step 38: train/loss = 0.6940301060676575, train/raw-loss = 0.6917117834091187, train/logprobs = tensor([[-0.8017, -1.5622],
        [-0.8207, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007727716118097305
Epoch 0, Step 39: train/loss = 0.6982483267784119, train/raw-loss = 0.6974338889122009, train/logprobs = tensor([[-0.6779, -1.3967],
        [-0.6694, -1.3926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027145948261022568
Epoch 0, Step 40: train/loss = 0.6943912506103516, train/raw-loss = 0.6939688920974731, train/logprobs = tensor([[-0.7632, -1.1195],
        [-0.7654, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014077682280912995
Epoch 0, Step 41: train/loss = 0.6806502938270569, train/raw-loss = 0.6795097589492798, train/logprobs = tensor([[-0.8216, -1.7078],
        [-0.8400, -1.6511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003801777958869934
Epoch 0, Step 42: train/loss = 0.6953481435775757, train/raw-loss = 0.694367527961731, train/logprobs = tensor([[-0.6560, -1.7110],
        [-0.6654, -1.7076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032684793695807457
Epoch 0, Step 43: train/loss = 0.686879575252533, train/raw-loss = 0.6866177916526794, train/logprobs = tensor([[-1.0934, -2.2801],
        [-1.0771, -2.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008726525702513754
Epoch 0, Step 44: train/loss = 0.6905717849731445, train/raw-loss = 0.6903976798057556, train/logprobs = tensor([[-0.9415, -1.1740],
        [-0.9243, -1.1435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005802650121040642
Epoch 0, Step 45: train/loss = 0.7065396904945374, train/raw-loss = 0.7042211294174194, train/logprobs = tensor([[-0.8766, -1.8393],
        [-0.8959, -1.8327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007728645112365484
Epoch 0, Step 46: train/loss = 0.7250972390174866, train/raw-loss = 0.7230007648468018, train/logprobs = tensor([[-1.1262, -2.6505],
        [-1.1680, -2.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006988189183175564
Epoch 0, Step 47: train/loss = 0.6945196986198425, train/raw-loss = 0.6937203407287598, train/logprobs = tensor([[-0.7199, -1.4910],
        [-0.7111, -1.4710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026645706966519356
Epoch 0, Step 48: train/loss = 0.7085301876068115, train/raw-loss = 0.7070211172103882, train/logprobs = tensor([[-1.3350, -1.4101],
        [-1.3527, -1.4624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005030433181673288
Epoch 0, Step 49: train/loss = 0.692938506603241, train/raw-loss = 0.6914311051368713, train/logprobs = tensor([[-0.8395, -1.8763],
        [-0.8370, -1.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005024871788918972
Epoch 0, Step 50: train/loss = 0.6911076307296753, train/raw-loss = 0.6909155249595642, train/logprobs = tensor([[-1.0832, -1.3937],
        [-1.0782, -1.3770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006405673339031637
Epoch 0, Step 51: train/loss = 0.6869046688079834, train/raw-loss = 0.6857802867889404, train/logprobs = tensor([[-0.9913, -1.7751],
        [-0.9906, -1.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037480113096535206
Epoch 0, Step 52: train/loss = 0.6877184510231018, train/raw-loss = 0.687508761882782, train/logprobs = tensor([[-0.7081, -0.7210],
        [-0.7282, -0.7153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006987795932218432
Epoch 0, Step 53: train/loss = 0.7107599973678589, train/raw-loss = 0.7088227868080139, train/logprobs = tensor([[-0.6088, -1.0795],
        [-0.5906, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064574312418699265
Epoch 0, Step 54: train/loss = 0.6840329170227051, train/raw-loss = 0.682507336139679, train/logprobs = tensor([[-1.2230, -1.6885],
        [-1.2433, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005085480399429798
Epoch 0, Step 55: train/loss = 0.7080017328262329, train/raw-loss = 0.7028936743736267, train/logprobs = tensor([[-1.3000, -1.1052],
        [-1.3418, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017026763409376144
Epoch 0, Step 56: train/loss = 0.6824687719345093, train/raw-loss = 0.6819606423377991, train/logprobs = tensor([[-0.8773, -1.4545],
        [-0.8995, -1.4236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016936644678935409
Epoch 0, Step 57: train/loss = 0.6879850625991821, train/raw-loss = 0.6851555109024048, train/logprobs = tensor([[-0.6412, -1.4265],
        [-0.6492, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009431957267224789
Epoch 0, Step 58: train/loss = 0.6738719344139099, train/raw-loss = 0.6735333204269409, train/logprobs = tensor([[-0.6794, -1.6542],
        [-0.6772, -1.5657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001128867152146995
Epoch 0, Step 59: train/loss = 0.6926488280296326, train/raw-loss = 0.6919022798538208, train/logprobs = tensor([[-0.8279, -1.2489],
        [-0.8414, -1.2448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024887453764677048
Epoch 0, Step 60: train/loss = 0.6921395063400269, train/raw-loss = 0.6914083957672119, train/logprobs = tensor([[-1.1025, -1.5208],
        [-1.0788, -1.4796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024371917825192213
Epoch 0, Step 61: train/loss = 0.6781792640686035, train/raw-loss = 0.6773156523704529, train/logprobs = tensor([[-0.5136, -1.4002],
        [-0.5257, -1.3338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028787010814994574
Epoch 0, Step 62: train/loss = 0.7114619016647339, train/raw-loss = 0.7092434763908386, train/logprobs = tensor([[-1.1946, -1.5974],
        [-1.1819, -1.5757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007394595071673393
Epoch 0, Step 63: train/loss = 0.6970193386077881, train/raw-loss = 0.6964080333709717, train/logprobs = tensor([[-0.9767, -1.3460],
        [-0.9932, -1.3672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002037512604147196
Epoch 0, Step 64: train/loss = 0.6911813616752625, train/raw-loss = 0.6907166838645935, train/logprobs = tensor([[-0.9281, -1.6349],
        [-0.9216, -1.6104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015489459037780762
Epoch 0, Step 65: train/loss = 0.695426344871521, train/raw-loss = 0.6948662996292114, train/logprobs = tensor([[-0.8724, -1.5659],
        [-0.8658, -1.5574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018667811527848244
Epoch 0, Step 66: train/loss = 0.7106468677520752, train/raw-loss = 0.7082971930503845, train/logprobs = tensor([[-1.0523, -1.9545],
        [-1.0006, -1.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007832157425582409
Epoch 0, Step 67: train/loss = 0.6929521560668945, train/raw-loss = 0.6915613412857056, train/logprobs = tensor([[-0.6794, -1.8707],
        [-0.6698, -1.8199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004635833203792572
Epoch 0, Step 68: train/loss = 0.7044403553009033, train/raw-loss = 0.7019165754318237, train/logprobs = tensor([[-0.8051, -2.7957],
        [-0.7840, -2.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008412322029471397
Epoch 0, Step 69: train/loss = 0.6868072152137756, train/raw-loss = 0.686214804649353, train/logprobs = tensor([[-1.2742, -1.7111],
        [-1.2864, -1.6872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019746229518204927
Epoch 0, Step 70: train/loss = 0.6915597915649414, train/raw-loss = 0.691036581993103, train/logprobs = tensor([[-0.5969, -1.9343],
        [-0.5917, -1.9097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001744130626320839
Epoch 0, Step 71: train/loss = 0.694602370262146, train/raw-loss = 0.6915321350097656, train/logprobs = tensor([[-1.0496, -1.9556],
        [-1.0352, -1.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010234054177999496
Epoch 0, Step 72: train/loss = 0.6839839220046997, train/raw-loss = 0.6836739182472229, train/logprobs = tensor([[-0.4516, -1.9833],
        [-0.4539, -1.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001033281092531979
Epoch 0, Step 73: train/loss = 0.6990556120872498, train/raw-loss = 0.6980797052383423, train/logprobs = tensor([[-0.7384, -1.1118],
        [-0.7695, -1.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003252848284319043
Epoch 0, Step 74: train/loss = 0.6969283819198608, train/raw-loss = 0.6964346766471863, train/logprobs = tensor([[-1.5972, -2.0044],
        [-1.5775, -1.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016458929749205709
Epoch 0, Step 75: train/loss = 0.6909670233726501, train/raw-loss = 0.6905765533447266, train/logprobs = tensor([[-0.7808, -1.8980],
        [-0.7742, -1.8737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013015477452427149
Epoch 0, Step 76: train/loss = 0.6725006699562073, train/raw-loss = 0.6715114116668701, train/logprobs = tensor([[-0.9788, -1.5800],
        [-1.0533, -1.5493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003297697752714157
Epoch 0, Step 77: train/loss = 0.6928863525390625, train/raw-loss = 0.6921900510787964, train/logprobs = tensor([[-1.2738, -1.4915],
        [-1.2881, -1.4920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023208390921354294
Epoch 0, Step 78: train/loss = 0.6852492690086365, train/raw-loss = 0.68489009141922, train/logprobs = tensor([[-0.8875, -1.9002],
        [-0.8985, -1.8728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011975194793194532
Epoch 0, Step 79: train/loss = 0.6844125390052795, train/raw-loss = 0.6842054724693298, train/logprobs = tensor([[-0.5500, -1.2736],
        [-0.5539, -1.2332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006901547312736511
Epoch 0, Step 80: train/loss = 0.686302900314331, train/raw-loss = 0.6858813762664795, train/logprobs = tensor([[-1.0782, -2.1462],
        [-1.0738, -2.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014050253666937351
Epoch 0, Step 81: train/loss = 0.7035590410232544, train/raw-loss = 0.7033158540725708, train/logprobs = tensor([[-0.8274, -1.8984],
        [-0.8387, -1.9448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008104410953819752
Epoch 0, Step 82: train/loss = 0.6984060406684875, train/raw-loss = 0.6969581842422485, train/logprobs = tensor([[-1.2433, -1.0716],
        [-1.2424, -1.0640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004826368764042854
Epoch 0, Step 83: train/loss = 0.6943620443344116, train/raw-loss = 0.6921947598457336, train/logprobs = tensor([[-0.6377, -1.7161],
        [-0.6407, -1.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007224469445645809
Epoch 0, Step 84: train/loss = 0.6861467957496643, train/raw-loss = 0.6859660744667053, train/logprobs = tensor([[-0.5642, -2.0527],
        [-0.5606, -2.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006024012109264731
Epoch 0, Step 85: train/loss = 0.7030667066574097, train/raw-loss = 0.7005696296691895, train/logprobs = tensor([[-0.9215, -2.1878],
        [-0.9301, -2.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008323554880917072
Epoch 0, Step 86: train/loss = 0.6866620182991028, train/raw-loss = 0.6861467361450195, train/logprobs = tensor([[-0.6485, -1.8394],
        [-0.6537, -1.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017174466047436
Epoch 0, Step 87: train/loss = 0.7065765857696533, train/raw-loss = 0.7055286169052124, train/logprobs = tensor([[-1.3954, -1.5892],
        [-1.3897, -1.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034932922571897507
Epoch 0, Step 88: train/loss = 0.6992813944816589, train/raw-loss = 0.6979967355728149, train/logprobs = tensor([[-0.8127, -2.0693],
        [-0.8199, -2.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004282198380678892
Epoch 0, Step 89: train/loss = 0.6987764239311218, train/raw-loss = 0.6953614950180054, train/logprobs = tensor([[-1.1095, -1.9304],
        [-1.1017, -1.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011382941156625748
Epoch 0, Step 90: train/loss = 0.6953281164169312, train/raw-loss = 0.6942607164382935, train/logprobs = tensor([[-0.8530, -1.8094],
        [-0.8960, -1.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003558145370334387
Epoch 0, Step 91: train/loss = 0.6867762804031372, train/raw-loss = 0.6867092847824097, train/logprobs = tensor([[-1.3127, -1.1798],
        [-1.3432, -1.1835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022341113071888685
Epoch 0, Step 92: train/loss = 0.6941468119621277, train/raw-loss = 0.6903925538063049, train/logprobs = tensor([[-0.9136, -1.7301],
        [-0.9820, -1.7308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012514373287558556
Epoch 0, Step 93: train/loss = 0.7009757161140442, train/raw-loss = 0.6989320516586304, train/logprobs = tensor([[-1.0084, -1.4948],
        [-1.0164, -1.4986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006812279112637043
Epoch 0, Step 94: train/loss = 0.7154529690742493, train/raw-loss = 0.7100212574005127, train/logprobs = tensor([[-1.2771, -2.7449],
        [-1.3169, -2.7097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01810585893690586
Epoch 0, Step 95: train/loss = 0.6937448382377625, train/raw-loss = 0.6920997500419617, train/logprobs = tensor([[-1.5621, -2.2770],
        [-1.5722, -2.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054836515337228775
Epoch 0, Step 96: train/loss = 0.6897807717323303, train/raw-loss = 0.6893905401229858, train/logprobs = tensor([[-0.8700, -1.7066],
        [-0.8695, -1.6814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001300700125284493
Epoch 0, Step 97: train/loss = 0.7009788751602173, train/raw-loss = 0.7006369829177856, train/logprobs = tensor([[-1.7992, -2.7700],
        [-1.7928, -2.7864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011395307956263423
Epoch 0, Step 98: train/loss = 0.6932291984558105, train/raw-loss = 0.6918283104896545, train/logprobs = tensor([[-1.0916, -1.6177],
        [-1.1004, -1.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004669468849897385
Epoch 0, Step 99: train/loss = 0.6930460929870605, train/raw-loss = 0.6922104954719543, train/logprobs = tensor([[-0.8638, -1.5723],
        [-0.8535, -1.5463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002785196527838707
Epoch 0, Step 100: train/loss = 0.691707968711853, train/raw-loss = 0.6900984048843384, train/logprobs = tensor([[-1.0193, -1.3509],
        [-1.0175, -1.3120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00536549836397171
Epoch 0, Step 101: train/loss = 0.6853766441345215, train/raw-loss = 0.6841189861297607, train/logprobs = tensor([[-1.1562, -2.3767],
        [-1.1518, -2.3127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004192182328552008
Epoch 0, Step 102: train/loss = 0.6690195798873901, train/raw-loss = 0.6686265468597412, train/logprobs = tensor([[-0.7604, -1.8011],
        [-0.7433, -1.6760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013102857628837228
Epoch 0, Step 103: train/loss = 0.6827088594436646, train/raw-loss = 0.6814004182815552, train/logprobs = tensor([[-0.8645, -1.7514],
        [-0.8906, -1.7109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004361283965408802
Epoch 0, Step 104: train/loss = 0.6879162192344666, train/raw-loss = 0.6865407824516296, train/logprobs = tensor([[-0.8413, -1.5265],
        [-0.8387, -1.4760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004584626294672489
Epoch 0, Step 105: train/loss = 0.6918004751205444, train/raw-loss = 0.6908161640167236, train/logprobs = tensor([[-0.9851, -1.8029],
        [-0.9809, -1.7694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003281018929556012
Epoch 0, Step 106: train/loss = 0.6875478029251099, train/raw-loss = 0.6868362426757812, train/logprobs = tensor([[-0.7315, -1.7946],
        [-0.7087, -1.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023718751035630703
Epoch 0, Step 107: train/loss = 0.697810709476471, train/raw-loss = 0.6948254108428955, train/logprobs = tensor([[-1.2900, -1.6965],
        [-1.3052, -1.6773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00995110534131527
Epoch 0, Step 108: train/loss = 0.6927785873413086, train/raw-loss = 0.6914417743682861, train/logprobs = tensor([[-0.7403, -0.8667],
        [-0.7377, -0.8385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004456120543181896
Epoch 0, Step 109: train/loss = 0.6971855163574219, train/raw-loss = 0.6948990225791931, train/logprobs = tensor([[-0.8052, -1.7892],
        [-0.8061, -1.7481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007621294818818569
Epoch 0, Step 110: train/loss = 0.6749919056892395, train/raw-loss = 0.6744484901428223, train/logprobs = tensor([[-0.9550, -2.1702],
        [-0.9276, -2.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001811053603887558
Epoch 0, Step 111: train/loss = 0.7004138231277466, train/raw-loss = 0.6997696161270142, train/logprobs = tensor([[-0.9176, -1.7953],
        [-0.9117, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021476238034665585
Epoch 0, Step 112: train/loss = 0.6969349980354309, train/raw-loss = 0.6964746713638306, train/logprobs = tensor([[-1.4895, -1.4373],
        [-1.5088, -1.4636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015342218102887273
Epoch 0, Step 113: train/loss = 0.6879241466522217, train/raw-loss = 0.6874841451644897, train/logprobs = tensor([[-1.0508, -1.4046],
        [-1.0330, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001466493820771575
Epoch 0, Step 114: train/loss = 0.6881381273269653, train/raw-loss = 0.6874237060546875, train/logprobs = tensor([[-0.9371, -1.1895],
        [-0.9445, -1.1617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002381406258791685
Epoch 0, Step 115: train/loss = 0.665876030921936, train/raw-loss = 0.6653149724006653, train/logprobs = tensor([[-0.7598, -1.7843],
        [-0.7384, -1.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018701457884162664
Epoch 0, Step 116: train/loss = 0.6916592717170715, train/raw-loss = 0.6916269063949585, train/logprobs = tensor([[-0.6420, -1.4417],
        [-0.6498, -1.4422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001079557987395674
Epoch 0, Step 117: train/loss = 0.6802841424942017, train/raw-loss = 0.6794949173927307, train/logprobs = tensor([[-0.9025, -1.7869],
        [-0.9139, -1.7208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002630799077451229
Epoch 0, Step 118: train/loss = 0.6888543367385864, train/raw-loss = 0.6874790191650391, train/logprobs = tensor([[-0.9823, -1.9314],
        [-1.0240, -1.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004584726877510548
Epoch 0, Step 119: train/loss = 0.6986783742904663, train/raw-loss = 0.6975968480110168, train/logprobs = tensor([[-1.4249, -1.8338],
        [-1.4592, -1.8709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036049503833055496
Epoch 0, Step 120: train/loss = 0.7231975793838501, train/raw-loss = 0.7214367389678955, train/logprobs = tensor([[-1.1318, -2.1947],
        [-1.1137, -2.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005869471468031406
Epoch 0, Step 121: train/loss = 0.6904868483543396, train/raw-loss = 0.6893082857131958, train/logprobs = tensor([[-0.7472, -1.1890],
        [-0.7610, -1.1668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003928660415112972
Epoch 0, Step 122: train/loss = 0.6900622844696045, train/raw-loss = 0.6897454261779785, train/logprobs = tensor([[-1.0421, -2.7984],
        [-1.0213, -2.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010560513474047184
Epoch 0, Step 123: train/loss = 0.6905134916305542, train/raw-loss = 0.6886287927627563, train/logprobs = tensor([[-1.1918, -1.4275],
        [-1.1906, -1.3780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006282270886003971
Epoch 0, Step 124: train/loss = 0.6893794536590576, train/raw-loss = 0.6882060766220093, train/logprobs = tensor([[-0.6288, -1.4059],
        [-0.5823, -1.3213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003911401145160198
Epoch 0, Step 125: train/loss = 0.6829229593276978, train/raw-loss = 0.6821101903915405, train/logprobs = tensor([[-0.8290, -2.3621],
        [-0.8618, -2.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002709402469918132
Epoch 0, Step 126: train/loss = 0.6916480660438538, train/raw-loss = 0.6911909580230713, train/logprobs = tensor([[-1.1799, -2.9416],
        [-1.2351, -2.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015237401239573956
Epoch 0, Step 127: train/loss = 0.6862981915473938, train/raw-loss = 0.6855934858322144, train/logprobs = tensor([[-0.9849, -1.8357],
        [-0.9372, -1.7479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023492341861128807
Epoch 0, Step 128: train/loss = 0.7094588279724121, train/raw-loss = 0.70829176902771, train/logprobs = tensor([[-1.0209, -1.5273],
        [-1.0024, -1.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003890274791046977
Epoch 0, Step 129: train/loss = 0.7059865593910217, train/raw-loss = 0.7048260569572449, train/logprobs = tensor([[-1.1458, -1.9611],
        [-1.1387, -1.9810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003868341213092208
Epoch 0, Step 130: train/loss = 0.6979942321777344, train/raw-loss = 0.6967922449111938, train/logprobs = tensor([[-1.2171, -2.6548],
        [-1.1621, -2.5758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004006756003946066
Epoch 0, Step 131: train/loss = 0.6875240802764893, train/raw-loss = 0.6863446831703186, train/logprobs = tensor([[-1.5659, -1.4900],
        [-1.5977, -1.4788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003931415732949972
Epoch 0, Step 132: train/loss = 0.6943483352661133, train/raw-loss = 0.6895848512649536, train/logprobs = tensor([[-1.0263, -2.1924],
        [-1.1295, -2.2136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01587856188416481
Epoch 0, Step 133: train/loss = 0.690757155418396, train/raw-loss = 0.6902905702590942, train/logprobs = tensor([[-1.4882, -1.8701],
        [-1.5058, -1.8695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015554038109257817
Epoch 0, Step 134: train/loss = 0.6860227584838867, train/raw-loss = 0.684750497341156, train/logprobs = tensor([[-1.0400, -1.7232],
        [-1.0439, -1.6588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00424082949757576
Epoch 0, Step 135: train/loss = 0.6879488825798035, train/raw-loss = 0.6876479387283325, train/logprobs = tensor([[-1.5516, -1.6386],
        [-1.5448, -1.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001003181911073625
Epoch 0, Step 136: train/loss = 0.6824660301208496, train/raw-loss = 0.678799569606781, train/logprobs = tensor([[-1.5552, -2.3686],
        [-1.5860, -2.2886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012221470475196838
Epoch 0, Step 137: train/loss = 0.6849560141563416, train/raw-loss = 0.6846657991409302, train/logprobs = tensor([[-1.6399, -1.5264],
        [-1.6563, -1.5048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000967280357144773
Epoch 0, Step 138: train/loss = 0.6951960325241089, train/raw-loss = 0.693840742111206, train/logprobs = tensor([[-1.2083, -2.0360],
        [-1.1622, -1.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00451742485165596
Epoch 0, Step 139: train/loss = 0.7203763127326965, train/raw-loss = 0.7128382921218872, train/logprobs = tensor([[-1.1694, -2.4964],
        [-1.1923, -2.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025126583874225616
Epoch 0, Step 140: train/loss = 0.6897197961807251, train/raw-loss = 0.6893092393875122, train/logprobs = tensor([[-1.0726, -2.2738],
        [-1.0815, -2.2516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013685643207281828
Epoch 0, Step 141: train/loss = 0.6829679608345032, train/raw-loss = 0.6823513507843018, train/logprobs = tensor([[-0.8748, -2.1189],
        [-0.8565, -2.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002055399352684617
Epoch 0, Step 142: train/loss = 0.6766492128372192, train/raw-loss = 0.6753638982772827, train/logprobs = tensor([[-1.3421, -1.9374],
        [-1.3530, -1.8588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004284382797777653
Epoch 0, Step 143: train/loss = 0.6898592710494995, train/raw-loss = 0.6870389580726624, train/logprobs = tensor([[-1.5954, -1.7593],
        [-1.6216, -1.7212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009401248767971992
Epoch 0, Step 144: train/loss = 0.6921401619911194, train/raw-loss = 0.6905097961425781, train/logprobs = tensor([[-0.9563, -1.8523],
        [-0.9489, -1.7982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00543480459600687
Epoch 0, Step 145: train/loss = 0.6927636861801147, train/raw-loss = 0.6912765502929688, train/logprobs = tensor([[-1.1601, -1.5904],
        [-1.1507, -1.5391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004956917371600866
Epoch 0, Step 146: train/loss = 0.6880849003791809, train/raw-loss = 0.6866888999938965, train/logprobs = tensor([[-0.7772, -1.8376],
        [-0.7867, -1.7964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004653368145227432
Epoch 0, Step 147: train/loss = 0.6859368681907654, train/raw-loss = 0.6854389309883118, train/logprobs = tensor([[-1.3458, -1.8154],
        [-1.3325, -1.7639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016599867958575487
Epoch 0, Step 148: train/loss = 0.6851146221160889, train/raw-loss = 0.6849299669265747, train/logprobs = tensor([[-1.0237, -1.4838],
        [-1.0280, -1.4500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006157943280413747
Epoch 0, Step 149: train/loss = 0.6859573125839233, train/raw-loss = 0.6859281063079834, train/logprobs = tensor([[-1.0152, -1.8165],
        [-1.0092, -1.7810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.74453505477868e-05
Epoch 0, Step 150: train/loss = 0.6865201592445374, train/raw-loss = 0.686272382736206, train/logprobs = tensor([[-1.1275, -1.8082],
        [-1.0904, -1.7353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008259547757916152
Epoch 0, Step 151: train/loss = 0.7016676664352417, train/raw-loss = 0.7003560066223145, train/logprobs = tensor([[-0.9449, -1.4921],
        [-0.9458, -1.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043720644898712635
Epoch 0, Step 152: train/loss = 0.6844072937965393, train/raw-loss = 0.6842449903488159, train/logprobs = tensor([[-0.9618, -1.9789],
        [-0.9442, -1.9218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005410626763477921
Epoch 0, Step 153: train/loss = 0.6994203329086304, train/raw-loss = 0.6987063884735107, train/logprobs = tensor([[-1.0951, -1.7838],
        [-1.0871, -1.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023799806367605925
Epoch 0, Step 154: train/loss = 0.6908949017524719, train/raw-loss = 0.6894088983535767, train/logprobs = tensor([[-1.4000, -2.1460],
        [-1.4084, -2.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004953570198267698
Epoch 0, Step 155: train/loss = 0.6905376315116882, train/raw-loss = 0.6902133822441101, train/logprobs = tensor([[-0.8908, -1.6881],
        [-0.8751, -1.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010805998463183641
Epoch 0, Step 156: train/loss = 0.6867011785507202, train/raw-loss = 0.6864209175109863, train/logprobs = tensor([[-1.0671, -2.3099],
        [-1.0486, -2.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009340456454083323
Epoch 0, Step 157: train/loss = 0.6942543983459473, train/raw-loss = 0.6928227543830872, train/logprobs = tensor([[-0.9932, -1.3431],
        [-0.9702, -1.2991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004772150423377752
Epoch 0, Step 158: train/loss = 0.6797400712966919, train/raw-loss = 0.6789164543151855, train/logprobs = tensor([[-0.8355, -0.8310],
        [-0.8427, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027453347574919462
Epoch 0, Step 159: train/loss = 0.6881405115127563, train/raw-loss = 0.6869869232177734, train/logprobs = tensor([[-0.8693, -1.3286],
        [-0.8533, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003845319850370288
Epoch 0, Step 160: train/loss = 0.6877449750900269, train/raw-loss = 0.6870477795600891, train/logprobs = tensor([[-0.8490, -1.3752],
        [-0.8241, -1.3129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002323960652574897
Epoch 0, Step 161: train/loss = 0.6879743933677673, train/raw-loss = 0.687526524066925, train/logprobs = tensor([[-0.9255, -2.0013],
        [-0.9584, -2.0038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014927852898836136
Epoch 0, Step 162: train/loss = 0.6662830114364624, train/raw-loss = 0.6657716035842896, train/logprobs = tensor([[-0.7147, -2.3764],
        [-0.6858, -2.2187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017045307904481888
Epoch 0, Step 163: train/loss = 0.6762703657150269, train/raw-loss = 0.6748607158660889, train/logprobs = tensor([[-1.2662, -1.8451],
        [-1.2526, -1.7329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004699110984802246
Epoch 0, Step 164: train/loss = 0.683430016040802, train/raw-loss = 0.6808613538742065, train/logprobs = tensor([[-1.5538, -1.8055],
        [-1.5671, -1.7352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00856238417327404
Epoch 0, Step 165: train/loss = 0.688151478767395, train/raw-loss = 0.6870248317718506, train/logprobs = tensor([[-1.1430, -2.0429],
        [-1.1340, -1.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00375555083155632
Epoch 0, Step 166: train/loss = 0.6913164854049683, train/raw-loss = 0.6907221078872681, train/logprobs = tensor([[-0.8958, -2.1376],
        [-0.8952, -2.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001981309847906232
Epoch 0, Step 167: train/loss = 0.6766668558120728, train/raw-loss = 0.6761109828948975, train/logprobs = tensor([[-1.2754, -1.2910],
        [-1.3406, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018527187639847398
Epoch 0, Step 168: train/loss = 0.6898936033248901, train/raw-loss = 0.689030647277832, train/logprobs = tensor([[-1.0387, -1.3567],
        [-1.0437, -1.3315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028764107264578342
Epoch 0, Step 169: train/loss = 0.6893441677093506, train/raw-loss = 0.6888878345489502, train/logprobs = tensor([[-0.8882, -1.6178],
        [-0.9018, -1.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015207871329039335
Epoch 0, Step 170: train/loss = 0.6812357306480408, train/raw-loss = 0.6808881759643555, train/logprobs = tensor([[-0.6278, -2.1168],
        [-0.6270, -2.0555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011584550375118852
Epoch 0, Step 171: train/loss = 0.6998116970062256, train/raw-loss = 0.6964282989501953, train/logprobs = tensor([[-1.2793, -1.5529],
        [-1.2646, -1.5033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011277982965111732
Epoch 0, Step 172: train/loss = 0.691539466381073, train/raw-loss = 0.6883581876754761, train/logprobs = tensor([[-1.0335, -1.8924],
        [-1.0237, -1.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010604308918118477
Epoch 0, Step 173: train/loss = 0.6894323229789734, train/raw-loss = 0.6866307258605957, train/logprobs = tensor([[-1.1376, -2.5478],
        [-1.1722, -2.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00933881290256977
Epoch 0, Step 174: train/loss = 0.7109236121177673, train/raw-loss = 0.707796573638916, train/logprobs = tensor([[-1.2669, -2.7285],
        [-1.2392, -2.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010423582047224045
Epoch 0, Step 175: train/loss = 0.6947388648986816, train/raw-loss = 0.6946264505386353, train/logprobs = tensor([[-1.6469, -1.7893],
        [-1.5652, -1.7120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003748188028112054
Epoch 0, Step 176: train/loss = 0.6792796850204468, train/raw-loss = 0.6778818964958191, train/logprobs = tensor([[-0.8343, -2.0387],
        [-0.8151, -1.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00465936167165637
Epoch 0, Step 177: train/loss = 0.6778135895729065, train/raw-loss = 0.6773638725280762, train/logprobs = tensor([[-0.9398, -1.6192],
        [-0.9394, -1.5491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014990036142989993
Epoch 0, Step 178: train/loss = 0.6872850656509399, train/raw-loss = 0.6861678957939148, train/logprobs = tensor([[-0.7721, -1.9296],
        [-0.7671, -1.8736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037239077500998974
Epoch 0, Step 179: train/loss = 0.6890416741371155, train/raw-loss = 0.6882097721099854, train/logprobs = tensor([[-1.3482, -2.0298],
        [-1.3395, -1.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027730530127882957
Epoch 0, Step 180: train/loss = 0.6826571822166443, train/raw-loss = 0.6813163757324219, train/logprobs = tensor([[-1.1957, -1.5857],
        [-1.2001, -1.5137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044695064425468445
Epoch 0, Step 181: train/loss = 0.6988155841827393, train/raw-loss = 0.6978766918182373, train/logprobs = tensor([[-0.9687, -1.6582],
        [-0.9802, -1.6692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003129763063043356
Epoch 0, Step 182: train/loss = 0.6864571571350098, train/raw-loss = 0.6847954392433167, train/logprobs = tensor([[-1.1238, -1.5435],
        [-1.1405, -1.5028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055389078333973885
Epoch 0, Step 183: train/loss = 0.6753696799278259, train/raw-loss = 0.6726990342140198, train/logprobs = tensor([[-0.8587, -1.9180],
        [-0.8709, -1.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008902251720428467
Epoch 0, Step 184: train/loss = 0.675697922706604, train/raw-loss = 0.6754013299942017, train/logprobs = tensor([[-0.9983, -2.0719],
        [-1.0140, -2.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009885500185191631
Epoch 0, Step 185: train/loss = 0.7097772359848022, train/raw-loss = 0.7043306231498718, train/logprobs = tensor([[-0.8914, -1.7836],
        [-0.8881, -1.7098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01815519481897354
Epoch 0, Step 186: train/loss = 0.6898432970046997, train/raw-loss = 0.6884461045265198, train/logprobs = tensor([[-0.8330, -1.9019],
        [-0.8192, -1.8247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00465754047036171
Epoch 0, Step 187: train/loss = 0.6929981708526611, train/raw-loss = 0.6914222240447998, train/logprobs = tensor([[-0.9724, -1.6847],
        [-0.9725, -1.6541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005253365263342857
Epoch 0, Step 188: train/loss = 0.6828392744064331, train/raw-loss = 0.6825284361839294, train/logprobs = tensor([[-1.2208, -1.9573],
        [-1.1968, -1.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010361401364207268
Epoch 0, Step 189: train/loss = 0.7052024602890015, train/raw-loss = 0.7024800777435303, train/logprobs = tensor([[-1.1370, -1.6428],
        [-1.1204, -1.6221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009074605070054531
Epoch 0, Step 190: train/loss = 0.6852195858955383, train/raw-loss = 0.682384192943573, train/logprobs = tensor([[-1.5159, -1.6046],
        [-1.5754, -1.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009451450780034065
Epoch 0, Step 191: train/loss = 0.6895227432250977, train/raw-loss = 0.6881632804870605, train/logprobs = tensor([[-1.0096, -1.6289],
        [-1.0020, -1.5780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004531406797468662
Epoch 0, Step 192: train/loss = 0.6766723990440369, train/raw-loss = 0.6727836728096008, train/logprobs = tensor([[-1.1637, -1.4044],
        [-1.2079, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012962650507688522
Epoch 0, Step 193: train/loss = 0.7011637091636658, train/raw-loss = 0.7003269195556641, train/logprobs = tensor([[-0.6944, -1.2548],
        [-0.7323, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027893066871911287
Epoch 0, Step 194: train/loss = 0.6755608916282654, train/raw-loss = 0.6750690937042236, train/logprobs = tensor([[-1.0770, -1.1989],
        [-1.1216, -1.1632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016394832637161016
Epoch 0, Step 195: train/loss = 0.6776458621025085, train/raw-loss = 0.6772454380989075, train/logprobs = tensor([[-0.5981, -1.4717],
        [-0.6015, -1.4027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013348613865673542
Epoch 0, Step 196: train/loss = 0.6891735792160034, train/raw-loss = 0.6888395547866821, train/logprobs = tensor([[-1.4834, -2.0277],
        [-1.4168, -1.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011133912485092878
Epoch 0, Step 197: train/loss = 0.673272967338562, train/raw-loss = 0.6719233393669128, train/logprobs = tensor([[-0.9286, -1.4459],
        [-0.9169, -1.3289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004498722031712532
Epoch 0, Step 198: train/loss = 0.6744112968444824, train/raw-loss = 0.6737774610519409, train/logprobs = tensor([[-0.8399, -0.9286],
        [-0.8578, -0.8605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021129315719008446
Epoch 0, Step 199: train/loss = 0.672907292842865, train/raw-loss = 0.6723544597625732, train/logprobs = tensor([[-0.9117, -1.1103],
        [-0.9552, -1.0628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018428408075124025
Epoch 0, Step 200: train/loss = 0.6698621511459351, train/raw-loss = 0.6655322909355164, train/logprobs = tensor([[-1.1270, -2.2774],
        [-1.1529, -2.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014432888478040695
Epoch 0, Step 201: train/loss = 0.6742453575134277, train/raw-loss = 0.6731890439987183, train/logprobs = tensor([[-0.6432, -1.7648],
        [-0.6531, -1.6731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003521289909258485
Epoch 0, Step 202: train/loss = 0.6725134253501892, train/raw-loss = 0.6721369028091431, train/logprobs = tensor([[-0.6881, -1.9547],
        [-0.6916, -1.8570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012549743987619877
Epoch 0, Step 203: train/loss = 0.6309700012207031, train/raw-loss = 0.6275718212127686, train/logprobs = tensor([[-1.0983, -1.3323],
        [-1.2104, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011327171698212624
Epoch 0, Step 204: train/loss = 0.6638497710227966, train/raw-loss = 0.6635599732398987, train/logprobs = tensor([[-1.3386, -1.3901],
        [-1.3548, -1.2836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009659534553065896
Epoch 0, Step 205: train/loss = 0.6689018607139587, train/raw-loss = 0.6676653027534485, train/logprobs = tensor([[-0.6545, -1.4400],
        [-0.6534, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004121712874621153
Epoch 0, Step 206: train/loss = 0.6556105017662048, train/raw-loss = 0.6544115543365479, train/logprobs = tensor([[-0.8250, -1.4001],
        [-0.8253, -1.2272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003996494226157665
Epoch 0, Step 207: train/loss = 0.6527923941612244, train/raw-loss = 0.6523635387420654, train/logprobs = tensor([[-0.7445, -1.9318],
        [-0.7714, -1.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001429452677257359
Epoch 0, Step 208: train/loss = 0.6661242246627808, train/raw-loss = 0.6648193597793579, train/logprobs = tensor([[-1.3118, -2.3092],
        [-1.3518, -2.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004349581431597471
Epoch 0, Step 209: train/loss = 0.6900678277015686, train/raw-loss = 0.6890354156494141, train/logprobs = tensor([[-0.9246, -1.8207],
        [-0.9167, -1.7814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034412567038089037
Epoch 0, Step 210: train/loss = 0.6618300080299377, train/raw-loss = 0.6590958833694458, train/logprobs = tensor([[-1.5403, -1.5666],
        [-1.6121, -1.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009113626554608345
Epoch 0, Step 211: train/loss = 0.6814128756523132, train/raw-loss = 0.6795742511749268, train/logprobs = tensor([[-1.1293, -2.1100],
        [-1.1263, -2.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006128717213869095
Epoch 0, Step 212: train/loss = 0.6802600622177124, train/raw-loss = 0.6797603368759155, train/logprobs = tensor([[-0.7430, -1.1835],
        [-0.7347, -1.1147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016655680956318974
Epoch 0, Step 213: train/loss = 0.677106499671936, train/raw-loss = 0.6746845245361328, train/logprobs = tensor([[-1.3740, -1.9272],
        [-1.3873, -1.8331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008073112927377224
Epoch 0, Step 214: train/loss = 0.6918514370918274, train/raw-loss = 0.6906549334526062, train/logprobs = tensor([[-0.8692, -1.1583],
        [-0.8696, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003988307435065508
Epoch 0, Step 215: train/loss = 0.6560771465301514, train/raw-loss = 0.6555494070053101, train/logprobs = tensor([[-1.0795, -1.5662],
        [-1.1180, -1.4460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017589412163943052
Epoch 0, Step 216: train/loss = 0.6818526983261108, train/raw-loss = 0.6803107261657715, train/logprobs = tensor([[-1.6007, -1.5036],
        [-1.6052, -1.4361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005140071269124746
Epoch 0, Step 217: train/loss = 0.6776177287101746, train/raw-loss = 0.6771887540817261, train/logprobs = tensor([[-0.8623, -1.6200],
        [-0.8892, -1.5770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001429797732271254
Epoch 0, Step 218: train/loss = 0.6673689484596252, train/raw-loss = 0.6664212942123413, train/logprobs = tensor([[-0.8112, -2.1434],
        [-0.8266, -2.0240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031589646823704243
Epoch 0, Step 219: train/loss = 0.6930352449417114, train/raw-loss = 0.6929363012313843, train/logprobs = tensor([[-1.0138, -0.9543],
        [-0.9834, -0.9209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032968807499855757
Epoch 0, Step 220: train/loss = 0.6630509495735168, train/raw-loss = 0.6627485156059265, train/logprobs = tensor([[-1.2035, -2.9091],
        [-1.2217, -2.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00100808497518301
Epoch 0, Step 221: train/loss = 0.6740937232971191, train/raw-loss = 0.6737311482429504, train/logprobs = tensor([[-1.5040, -0.8211],
        [-1.5012, -0.7343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012084078043699265
Epoch 0, Step 222: train/loss = 0.6862385272979736, train/raw-loss = 0.6855459809303284, train/logprobs = tensor([[-0.9901, -1.2576],
        [-0.9779, -1.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023084133863449097
Epoch 0, Step 223: train/loss = 0.6823081374168396, train/raw-loss = 0.6783036589622498, train/logprobs = tensor([[-0.9323, -1.9966],
        [-0.9877, -1.9146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013348424807190895
Epoch 0, Step 224: train/loss = 0.6723340749740601, train/raw-loss = 0.6705350279808044, train/logprobs = tensor([[-1.3368, -2.7987],
        [-1.3201, -2.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059967683628201485
Epoch 0, Step 225: train/loss = 0.659570574760437, train/raw-loss = 0.6585536599159241, train/logprobs = tensor([[-0.8322, -2.1448],
        [-0.7979, -1.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033896011300385
Epoch 0, Step 226: train/loss = 0.6696734428405762, train/raw-loss = 0.6693458557128906, train/logprobs = tensor([[-1.0484, -2.4979],
        [-1.0735, -2.4224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010920925997197628
Epoch 0, Step 227: train/loss = 0.6741979122161865, train/raw-loss = 0.6738224029541016, train/logprobs = tensor([[-0.7566, -1.4228],
        [-0.7534, -1.3359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001252036658115685
Epoch 0, Step 228: train/loss = 0.6668413877487183, train/raw-loss = 0.6659930944442749, train/logprobs = tensor([[-1.1808, -2.5760],
        [-1.1606, -2.4291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028275407385081053
Epoch 0, Step 229: train/loss = 0.6524754762649536, train/raw-loss = 0.6514437794685364, train/logprobs = tensor([[-0.9678, -1.8007],
        [-0.9932, -1.6303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003439026651903987
Epoch 0, Step 230: train/loss = 0.6682000756263733, train/raw-loss = 0.6680009961128235, train/logprobs = tensor([[-1.1889, -2.6759],
        [-1.1732, -2.5539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006636542384512722
Epoch 0, Step 231: train/loss = 0.6741456985473633, train/raw-loss = 0.6733800172805786, train/logprobs = tensor([[-1.2617, -1.4585],
        [-1.2541, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002552188467234373
Epoch 0, Step 232: train/loss = 0.6684231758117676, train/raw-loss = 0.6676849722862244, train/logprobs = tensor([[-1.2068, -2.3447],
        [-1.1989, -2.2203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024607088416814804
Epoch 0, Step 233: train/loss = 0.6726254820823669, train/raw-loss = 0.6713597774505615, train/logprobs = tensor([[-1.7081, -1.9736],
        [-1.6673, -1.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00421890988945961
Epoch 0, Step 234: train/loss = 0.6371139287948608, train/raw-loss = 0.6361061930656433, train/logprobs = tensor([[-1.0684, -2.0606],
        [-1.0995, -1.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003358947578817606
Epoch 0, Step 235: train/loss = 0.6939855813980103, train/raw-loss = 0.6906782388687134, train/logprobs = tensor([[-1.1620, -1.7522],
        [-1.1232, -1.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011024495586752892
Epoch 0, Step 236: train/loss = 0.6802778244018555, train/raw-loss = 0.6801021695137024, train/logprobs = tensor([[-0.6995, -1.4947],
        [-0.6883, -1.4283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005855110939592123
Epoch 0, Step 237: train/loss = 0.6741595268249512, train/raw-loss = 0.6729413270950317, train/logprobs = tensor([[-0.7769, -1.0732],
        [-0.7688, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004060734994709492
Epoch 0, Step 238: train/loss = 0.6808434724807739, train/raw-loss = 0.6803621053695679, train/logprobs = tensor([[-0.7362, -1.6747],
        [-0.7394, -1.6179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016044400399550796
Epoch 0, Step 239: train/loss = 0.6963248252868652, train/raw-loss = 0.6933521032333374, train/logprobs = tensor([[-2.1176, -1.7885],
        [-2.0885, -1.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009909037500619888
Epoch 0, Step 240: train/loss = 0.6829538941383362, train/raw-loss = 0.679669976234436, train/logprobs = tensor([[-1.1186, -1.4845],
        [-1.1318, -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010946391150355339
Epoch 0, Step 241: train/loss = 0.6710329055786133, train/raw-loss = 0.668836772441864, train/logprobs = tensor([[-1.0511, -2.0108],
        [-1.0929, -1.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007320653647184372
Epoch 0, Step 242: train/loss = 0.6606791019439697, train/raw-loss = 0.6598204374313354, train/logprobs = tensor([[-1.2941, -1.7201],
        [-1.2875, -1.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002862306544557214
Epoch 0, Step 243: train/loss = 0.6696649789810181, train/raw-loss = 0.6667742133140564, train/logprobs = tensor([[-1.3958, -1.7420],
        [-1.3824, -1.5838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009635684080421925
Epoch 0, Step 244: train/loss = 0.6777732968330383, train/raw-loss = 0.6774539947509766, train/logprobs = tensor([[-1.0333, -1.8043],
        [-0.9943, -1.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001064186217263341
Epoch 0, Step 245: train/loss = 0.6811109781265259, train/raw-loss = 0.6809297800064087, train/logprobs = tensor([[-1.2466, -1.7646],
        [-1.2340, -1.7004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006038873689249158
Epoch 0, Step 246: train/loss = 0.6880220770835876, train/raw-loss = 0.6861014366149902, train/logprobs = tensor([[-1.0941, -1.6040],
        [-1.0828, -1.5309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006402024067938328
Epoch 0, Step 247: train/loss = 0.6820597648620605, train/raw-loss = 0.6800883412361145, train/logprobs = tensor([[-1.0144, -1.9227],
        [-0.9582, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006571388803422451
Epoch 0, Step 248: train/loss = 0.666630744934082, train/raw-loss = 0.6664118766784668, train/logprobs = tensor([[-1.0296, -2.5200],
        [-0.9994, -2.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007296583498828113
Epoch 0, Step 249: train/loss = 0.6711282134056091, train/raw-loss = 0.6709126234054565, train/logprobs = tensor([[-1.3889, -1.4829],
        [-1.4309, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007186013972386718
Epoch 0, Step 250: train/loss = 0.6535333395004272, train/raw-loss = 0.6528844237327576, train/logprobs = tensor([[-0.6100, -2.2354],
        [-0.5764, -2.0262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021630728151649237
Epoch 0, Step 251: train/loss = 0.6899229288101196, train/raw-loss = 0.689700722694397, train/logprobs = tensor([[-0.9788, -2.2905],
        [-1.0277, -2.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007404664065688848
Epoch 0, Step 252: train/loss = 0.7039061784744263, train/raw-loss = 0.7003347277641296, train/logprobs = tensor([[-1.2069, -1.2426],
        [-1.1593, -1.1744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011904994025826454
Epoch 0, Step 253: train/loss = 0.6832268238067627, train/raw-loss = 0.6830315589904785, train/logprobs = tensor([[-1.3002, -1.5834],
        [-1.3068, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006508403457701206
Epoch 0, Step 254: train/loss = 0.6996303200721741, train/raw-loss = 0.696275532245636, train/logprobs = tensor([[-0.9455, -1.1340],
        [-0.9647, -1.1200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011182785034179688
Epoch 0, Step 255: train/loss = 0.6665597558021545, train/raw-loss = 0.6655316948890686, train/logprobs = tensor([[-0.9246, -2.2396],
        [-0.9476, -2.1214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034269520547240973
Epoch 0, Step 256: train/loss = 0.6418988108634949, train/raw-loss = 0.6413621306419373, train/logprobs = tensor([[-0.7987, -2.0309],
        [-0.8029, -1.8180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017890539020299911
Epoch 0, Step 257: train/loss = 0.6765699982643127, train/raw-loss = 0.6736842393875122, train/logprobs = tensor([[-1.4127, -2.5192],
        [-1.3673, -2.3514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009619150310754776
Epoch 0, Step 258: train/loss = 0.6682922840118408, train/raw-loss = 0.6647006273269653, train/logprobs = tensor([[-1.7294, -2.2150],
        [-1.7283, -2.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011972242966294289
Epoch 0, Step 259: train/loss = 0.6804325580596924, train/raw-loss = 0.6798369288444519, train/logprobs = tensor([[-1.8287, -1.7132],
        [-1.7431, -1.5663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019856214057654142
Epoch 0, Step 260: train/loss = 0.6486302614212036, train/raw-loss = 0.6480522155761719, train/logprobs = tensor([[-1.2153, -2.0551],
        [-1.1696, -1.8200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019266813760623336
Epoch 0, Step 261: train/loss = 0.6550014019012451, train/raw-loss = 0.6528186798095703, train/logprobs = tensor([[-0.9244, -2.3665],
        [-0.8365, -2.0787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007275653071701527
Epoch 0, Step 262: train/loss = 0.7074828743934631, train/raw-loss = 0.7056362628936768, train/logprobs = tensor([[-1.4607, -1.8801],
        [-1.3965, -1.8297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006155160255730152
Epoch 0, Step 263: train/loss = 0.6618338823318481, train/raw-loss = 0.6609177589416504, train/logprobs = tensor([[-1.8277, -2.6134],
        [-1.7549, -2.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00305380392819643
Epoch 0, Step 264: train/loss = 0.6624868512153625, train/raw-loss = 0.6602789759635925, train/logprobs = tensor([[-1.1647, -2.3398],
        [-1.0966, -2.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007359616924077272
Epoch 0, Step 265: train/loss = 0.6730986833572388, train/raw-loss = 0.6721262335777283, train/logprobs = tensor([[-1.3447, -1.9131],
        [-1.3446, -1.8145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032416721805930138
Epoch 0, Step 266: train/loss = 0.6836593151092529, train/raw-loss = 0.682309627532959, train/logprobs = tensor([[-1.2359, -1.1571],
        [-1.2095, -1.0672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004499099217355251
Epoch 0, Step 267: train/loss = 0.669894278049469, train/raw-loss = 0.6680564880371094, train/logprobs = tensor([[-1.3987, -1.7318],
        [-1.4092, -1.6109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006126077845692635
Epoch 0, Step 268: train/loss = 0.6460233330726624, train/raw-loss = 0.6450979113578796, train/logprobs = tensor([[-1.1159, -1.8320],
        [-1.0914, -1.5998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003084842348471284
Epoch 0, Step 269: train/loss = 0.6316050291061401, train/raw-loss = 0.6281254291534424, train/logprobs = tensor([[-0.9911, -1.8173],
        [-1.1189, -1.6137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011598550714552402
Epoch 0, Step 270: train/loss = 0.677242636680603, train/raw-loss = 0.6769005656242371, train/logprobs = tensor([[-0.9127, -1.8352],
        [-0.8452, -1.6969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011402727104723454
Epoch 0, Step 271: train/loss = 0.6356196999549866, train/raw-loss = 0.6339389681816101, train/logprobs = tensor([[-0.6770, -2.1018],
        [-0.6690, -1.8255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005602225661277771
Epoch 0, Step 272: train/loss = 0.6708492040634155, train/raw-loss = 0.6696897745132446, train/logprobs = tensor([[-1.0076, -1.6382],
        [-0.9701, -1.4887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003864468075335026
Epoch 0, Step 273: train/loss = 0.6533839702606201, train/raw-loss = 0.6526960134506226, train/logprobs = tensor([[-0.5521, -2.1310],
        [-0.5670, -1.9650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002293271478265524
Epoch 0, Step 274: train/loss = 0.6587080359458923, train/raw-loss = 0.6568101644515991, train/logprobs = tensor([[-1.3758, -2.1041],
        [-1.3871, -1.9294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006326261907815933
Epoch 0, Step 275: train/loss = 0.6583662629127502, train/raw-loss = 0.6560215950012207, train/logprobs = tensor([[-1.0894, -2.1741],
        [-1.0292, -1.9210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007815862074494362
Epoch 0, Step 276: train/loss = 0.6330369710922241, train/raw-loss = 0.6325148344039917, train/logprobs = tensor([[-0.6458, -2.5639],
        [-0.6354, -2.2909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017403754172846675
Epoch 0, Step 277: train/loss = 0.6244598627090454, train/raw-loss = 0.6218774914741516, train/logprobs = tensor([[-1.6395, -2.1688],
        [-1.6286, -1.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008608128875494003
Epoch 0, Step 278: train/loss = 0.6521427631378174, train/raw-loss = 0.6470346450805664, train/logprobs = tensor([[-1.4247, -2.6070],
        [-1.4397, -2.3395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017027022317051888
Epoch 0, Step 279: train/loss = 0.6716365814208984, train/raw-loss = 0.6714553833007812, train/logprobs = tensor([[-1.2643, -1.6848],
        [-1.2750, -1.6056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006041177548468113
Epoch 0, Step 280: train/loss = 0.652279794216156, train/raw-loss = 0.651628315448761, train/logprobs = tensor([[-1.0049, -1.8536],
        [-0.9962, -1.6680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002171585336327553
Epoch 0, Step 281: train/loss = 0.6783292293548584, train/raw-loss = 0.6772041320800781, train/logprobs = tensor([[-1.5069, -1.8734],
        [-1.4539, -1.7398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037505882792174816
Epoch 0, Step 282: train/loss = 0.6499083638191223, train/raw-loss = 0.6493886113166809, train/logprobs = tensor([[-0.7224, -1.9457],
        [-0.7251, -1.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017324561486020684
Epoch 0, Step 283: train/loss = 0.6341037154197693, train/raw-loss = 0.6325664520263672, train/logprobs = tensor([[-0.7770, -2.3803],
        [-0.7988, -2.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005123993381857872
Epoch 0, Step 284: train/loss = 0.6774289608001709, train/raw-loss = 0.6742507815361023, train/logprobs = tensor([[-1.0270, -1.4554],
        [-1.0643, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01059388741850853
Epoch 0, Step 285: train/loss = 0.6674069762229919, train/raw-loss = 0.6663240194320679, train/logprobs = tensor([[-1.1171, -2.6471],
        [-1.0775, -2.4754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036098789423704147
Epoch 0, Step 286: train/loss = 0.6867052316665649, train/raw-loss = 0.6838326454162598, train/logprobs = tensor([[-0.9481, -1.5638],
        [-0.9160, -1.4480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009575382806360722
Epoch 0, Step 287: train/loss = 0.6767613887786865, train/raw-loss = 0.6746911406517029, train/logprobs = tensor([[-1.1654, -1.3315],
        [-1.1691, -1.2259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0069008469581604
Epoch 0, Step 288: train/loss = 0.698603630065918, train/raw-loss = 0.688030481338501, train/logprobs = tensor([[-1.5010, -2.6690],
        [-1.6367, -2.3121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03524402901530266
Epoch 0, Step 289: train/loss = 0.659880518913269, train/raw-loss = 0.6590136885643005, train/logprobs = tensor([[-1.1094, -1.4901],
        [-1.1178, -1.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002889626193791628
Epoch 0, Step 290: train/loss = 0.6681054830551147, train/raw-loss = 0.6666003465652466, train/logprobs = tensor([[-1.0915, -1.7725],
        [-1.0574, -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005017220973968506
Epoch 0, Step 291: train/loss = 0.6840810179710388, train/raw-loss = 0.6831892132759094, train/logprobs = tensor([[-0.7362, -0.9956],
        [-0.7684, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029725192580372095
Epoch 0, Step 292: train/loss = 0.6379318833351135, train/raw-loss = 0.6366617679595947, train/logprobs = tensor([[-1.0387, -1.9058],
        [-1.0325, -1.6493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004233598709106445
Epoch 0, Step 293: train/loss = 0.6391772627830505, train/raw-loss = 0.6363984942436218, train/logprobs = tensor([[-0.9050, -2.3982],
        [-0.9916, -2.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009262442588806152
Epoch 0, Step 294: train/loss = 0.6592832803726196, train/raw-loss = 0.6580587029457092, train/logprobs = tensor([[-1.0328, -2.1037],
        [-1.0834, -1.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004081666003912687
Epoch 0, Step 295: train/loss = 0.6583243608474731, train/raw-loss = 0.657421350479126, train/logprobs = tensor([[-1.7735, -1.9504],
        [-1.7344, -1.7556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003010114422068
Epoch 0, Step 296: train/loss = 0.6350802183151245, train/raw-loss = 0.6301201581954956, train/logprobs = tensor([[-1.1432, -2.5268],
        [-1.1855, -2.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016533255577087402
Epoch 0, Step 297: train/loss = 0.6440998315811157, train/raw-loss = 0.6435225009918213, train/logprobs = tensor([[-1.1898, -2.3208],
        [-1.2981, -2.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019244721625000238
Epoch 0, Step 298: train/loss = 0.6370987892150879, train/raw-loss = 0.6364108324050903, train/logprobs = tensor([[-0.8099, -2.1217],
        [-0.9137, -1.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022931902203708887
Epoch 0, Step 299: train/loss = 0.6637802720069885, train/raw-loss = 0.6626171469688416, train/logprobs = tensor([[-1.3057, -1.2717],
        [-1.4017, -1.2299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003877001814544201
Epoch 0, Step 300: train/loss = 0.676207423210144, train/raw-loss = 0.6754384636878967, train/logprobs = tensor([[-1.3817, -1.4637],
        [-1.3235, -1.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025631608441472054
Epoch 0, Step 301: train/loss = 0.6715123057365417, train/raw-loss = 0.6710587739944458, train/logprobs = tensor([[-0.8449, -1.2155],
        [-0.8619, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001511752256192267
Epoch 0, Step 302: train/loss = 0.6194334030151367, train/raw-loss = 0.6165926456451416, train/logprobs = tensor([[-1.0193, -2.1340],
        [-1.1003, -1.8512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009469208307564259
Epoch 0, Step 303: train/loss = 0.6852424740791321, train/raw-loss = 0.6835063695907593, train/logprobs = tensor([[-0.8195, -1.6813],
        [-0.8426, -1.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005786948371678591
Epoch 0, Step 304: train/loss = 0.6516398191452026, train/raw-loss = 0.6501486301422119, train/logprobs = tensor([[-1.2512, -2.0181],
        [-1.2525, -1.8210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004970890935510397
Epoch 0, Step 305: train/loss = 0.679318368434906, train/raw-loss = 0.676005482673645, train/logprobs = tensor([[-1.0692, -1.0780],
        [-1.0952, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011042917147278786
Epoch 0, Step 306: train/loss = 0.6493959426879883, train/raw-loss = 0.6481459140777588, train/logprobs = tensor([[-0.9060, -1.9240],
        [-0.9353, -1.7466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004166518338024616
Epoch 0, Step 307: train/loss = 0.6521482467651367, train/raw-loss = 0.6497635841369629, train/logprobs = tensor([[-0.8799, -1.9766],
        [-0.9553, -1.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007949006743729115
Epoch 0, Step 308: train/loss = 0.6487828493118286, train/raw-loss = 0.6445788145065308, train/logprobs = tensor([[-1.2932, -1.9151],
        [-1.3179, -1.6822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014013613574206829
Epoch 0, Step 309: train/loss = 0.6581321954727173, train/raw-loss = 0.6573877334594727, train/logprobs = tensor([[-0.8260, -1.4585],
        [-0.8745, -1.3532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024814801290631294
Epoch 0, Step 310: train/loss = 0.6157824993133545, train/raw-loss = 0.6147520542144775, train/logprobs = tensor([[-1.0701, -2.5731],
        [-1.1059, -2.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034348289482295513
Epoch 0, Step 311: train/loss = 0.6581105589866638, train/raw-loss = 0.6567662358283997, train/logprobs = tensor([[-0.7318, -1.4719],
        [-0.7889, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004481044132262468
Epoch 0, Step 312: train/loss = 0.6557083129882812, train/raw-loss = 0.6552551984786987, train/logprobs = tensor([[-1.3631, -1.8281],
        [-1.3968, -1.7037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001510460628196597
Epoch 0, Step 313: train/loss = 0.6354462504386902, train/raw-loss = 0.6338262557983398, train/logprobs = tensor([[-0.9375, -2.7279],
        [-0.9403, -2.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005399882327765226
Epoch 0, Step 314: train/loss = 0.6743602156639099, train/raw-loss = 0.6728835105895996, train/logprobs = tensor([[-0.9094, -2.5869],
        [-1.0203, -2.5828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004922383930534124
Epoch 0, Step 315: train/loss = 0.6563817262649536, train/raw-loss = 0.6559507846832275, train/logprobs = tensor([[-0.7802, -2.5394],
        [-0.7802, -2.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014363406226038933
Epoch 0, Step 316: train/loss = 0.6500062942504883, train/raw-loss = 0.6489509344100952, train/logprobs = tensor([[-1.2411, -1.9640],
        [-1.2412, -1.7673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035178421530872583
Epoch 0, Step 317: train/loss = 0.6659857630729675, train/raw-loss = 0.6654208302497864, train/logprobs = tensor([[-1.0697, -1.6587],
        [-1.1422, -1.6119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018830737099051476
Epoch 0, Step 318: train/loss = 0.6632272601127625, train/raw-loss = 0.6620334386825562, train/logprobs = tensor([[-1.1766, -2.0866],
        [-1.1992, -1.9528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003979489207267761
Epoch 0, Step 319: train/loss = 0.6473075747489929, train/raw-loss = 0.6461106538772583, train/logprobs = tensor([[-1.2166, -2.0280],
        [-1.2987, -1.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039896294474601746
Epoch 0, Step 320: train/loss = 0.6214510202407837, train/raw-loss = 0.6197527647018433, train/logprobs = tensor([[-0.6773, -1.8195],
        [-0.7654, -1.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005660653114318848
Epoch 0, Step 321: train/loss = 0.6154254674911499, train/raw-loss = 0.6131704449653625, train/logprobs = tensor([[-1.4077, -2.5555],
        [-1.5327, -2.3204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007516756188124418
Epoch 0, Step 322: train/loss = 0.6288084983825684, train/raw-loss = 0.6216160655021667, train/logprobs = tensor([[-1.1213, -2.3103],
        [-1.1802, -1.9720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023974869400262833
Epoch 0, Step 323: train/loss = 0.6802433729171753, train/raw-loss = 0.6799222230911255, train/logprobs = tensor([[-1.1345, -0.9274],
        [-1.1025, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001070494414307177
Epoch 0, Step 324: train/loss = 0.6251837015151978, train/raw-loss = 0.6242204904556274, train/logprobs = tensor([[-1.5202, -2.3522],
        [-1.5633, -2.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003210746217519045
Epoch 0, Step 325: train/loss = 0.6158307790756226, train/raw-loss = 0.6071658730506897, train/logprobs = tensor([[-2.2086, -2.0918],
        [-2.2885, -1.7104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028882808983325958
Epoch 0, Step 326: train/loss = 0.6223664879798889, train/raw-loss = 0.6202459335327148, train/logprobs = tensor([[-1.3424, -2.2433],
        [-1.5128, -2.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007068496197462082
Epoch 0, Step 327: train/loss = 0.6566419005393982, train/raw-loss = 0.6533355712890625, train/logprobs = tensor([[-1.3593, -1.8980],
        [-1.3651, -1.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011021054349839687
Epoch 0, Step 328: train/loss = 0.6869028806686401, train/raw-loss = 0.6846262216567993, train/logprobs = tensor([[-1.1974, -1.5762],
        [-1.1026, -1.4147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0075889332219958305
Epoch 0, Step 329: train/loss = 0.6169441342353821, train/raw-loss = 0.6144627928733826, train/logprobs = tensor([[-1.4504, -2.2412],
        [-1.5594, -1.9831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008271178230643272
Epoch 0, Step 330: train/loss = 0.6450021266937256, train/raw-loss = 0.6440106630325317, train/logprobs = tensor([[-1.2248, -2.4153],
        [-1.3001, -2.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033047390170395374
Epoch 0, Step 331: train/loss = 0.6785930395126343, train/raw-loss = 0.6772010326385498, train/logprobs = tensor([[-1.4992, -2.2169],
        [-1.3911, -2.0224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004640066530555487
Epoch 0, Step 332: train/loss = 0.648329496383667, train/raw-loss = 0.6469000577926636, train/logprobs = tensor([[-1.9031, -1.5549],
        [-1.9462, -1.3923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004764850251376629
Epoch 0, Step 333: train/loss = 0.5732964277267456, train/raw-loss = 0.569831132888794, train/logprobs = tensor([[-1.4607, -2.7321],
        [-1.4373, -2.1536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011551054194569588
Epoch 0, Step 334: train/loss = 0.6444535851478577, train/raw-loss = 0.6427723169326782, train/logprobs = tensor([[-1.6153, -2.3097],
        [-1.6220, -2.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056043965741992
Epoch 0, Step 335: train/loss = 0.6231295466423035, train/raw-loss = 0.6205955147743225, train/logprobs = tensor([[-0.8665, -1.6445],
        [-0.9191, -1.3660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008446840569376945
Epoch 0, Step 336: train/loss = 0.6432942152023315, train/raw-loss = 0.6412444114685059, train/logprobs = tensor([[-1.0448, -1.7636],
        [-1.0934, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006832524202764034
Epoch 0, Step 337: train/loss = 0.6650461554527283, train/raw-loss = 0.6609832048416138, train/logprobs = tensor([[-1.2066, -2.5979],
        [-1.2764, -2.4687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013543203473091125
Epoch 0, Step 338: train/loss = 0.6657329201698303, train/raw-loss = 0.6645522117614746, train/logprobs = tensor([[-1.4001, -2.0039],
        [-1.3495, -1.8067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003935731947422028
Epoch 0, Step 339: train/loss = 0.6712366938591003, train/raw-loss = 0.6681618690490723, train/logprobs = tensor([[-1.5191, -1.6290],
        [-1.5749, -1.5362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010249245911836624
Epoch 0, Step 340: train/loss = 0.5860834717750549, train/raw-loss = 0.5820680856704712, train/logprobs = tensor([[-1.6335, -2.4424],
        [-1.6981, -2.0019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013384733349084854
Epoch 0, Step 341: train/loss = 0.6404127478599548, train/raw-loss = 0.6309982538223267, train/logprobs = tensor([[-1.6048, -2.2666],
        [-1.7161, -1.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03138160705566406
Epoch 0, Step 342: train/loss = 0.6316976547241211, train/raw-loss = 0.6299933195114136, train/logprobs = tensor([[-1.2180, -1.7647],
        [-1.2485, -1.5076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005681313574314117
Epoch 0, Step 343: train/loss = 0.6396920680999756, train/raw-loss = 0.6384240984916687, train/logprobs = tensor([[-0.8030, -2.0334],
        [-0.8790, -1.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004226596560329199
Epoch 0, Step 344: train/loss = 0.638053834438324, train/raw-loss = 0.6361076831817627, train/logprobs = tensor([[-1.3967, -1.9229],
        [-1.3734, -1.6309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00648706266656518
Epoch 0, Step 345: train/loss = 0.6577979922294617, train/raw-loss = 0.6542559862136841, train/logprobs = tensor([[-1.2799, -1.5248],
        [-1.2681, -1.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011806624941527843
Epoch 0, Step 346: train/loss = 0.6115554571151733, train/raw-loss = 0.6099597215652466, train/logprobs = tensor([[-1.1119, -2.5268],
        [-1.1904, -2.2445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005319076590240002
Epoch 0, Step 347: train/loss = 0.6655710339546204, train/raw-loss = 0.6641765832901001, train/logprobs = tensor([[-1.4794, -1.8459],
        [-1.4312, -1.6610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004648125730454922
Epoch 0, Step 348: train/loss = 0.6166127920150757, train/raw-loss = 0.6130343675613403, train/logprobs = tensor([[-1.0048, -1.6979],
        [-1.1984, -1.5160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011928047053515911
Epoch 0, Step 349: train/loss = 0.6384211182594299, train/raw-loss = 0.6374677419662476, train/logprobs = tensor([[-1.0256, -1.8630],
        [-1.1129, -1.7028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031778672710061073
Epoch 0, Step 350: train/loss = 0.5869966745376587, train/raw-loss = 0.5853093862533569, train/logprobs = tensor([[-0.8466, -3.4898],
        [-0.9172, -2.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005624138284474611
Epoch 0, Step 351: train/loss = 0.6225469708442688, train/raw-loss = 0.6198868751525879, train/logprobs = tensor([[-1.0408, -2.7164],
        [-1.1356, -2.4493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008867030963301659
Epoch 0, Step 352: train/loss = 0.5522217154502869, train/raw-loss = 0.5490267276763916, train/logprobs = tensor([[-1.1828, -2.7957],
        [-1.1969, -2.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0106499707326293
Epoch 0, Step 353: train/loss = 0.5929971933364868, train/raw-loss = 0.5890294313430786, train/logprobs = tensor([[-1.4020, -2.0623],
        [-1.3965, -1.5766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013226134702563286
Epoch 0, Step 354: train/loss = 0.5334504842758179, train/raw-loss = 0.5295146703720093, train/logprobs = tensor([[-0.8280, -3.6790],
        [-0.7926, -2.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01311933621764183
Epoch 0, Step 355: train/loss = 0.6540532112121582, train/raw-loss = 0.653739869594574, train/logprobs = tensor([[-0.9502, -1.8873],
        [-0.8332, -1.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001044388278387487
Epoch 0, Step 356: train/loss = 0.6358896493911743, train/raw-loss = 0.6347254514694214, train/logprobs = tensor([[-1.1037, -1.4690],
        [-1.0530, -1.1669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003880620701238513
Epoch 0, Step 357: train/loss = 0.5575476884841919, train/raw-loss = 0.5539821982383728, train/logprobs = tensor([[-0.8945, -2.9304],
        [-0.8413, -2.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011884769424796104
Epoch 0, Step 358: train/loss = 0.6364560723304749, train/raw-loss = 0.6335944533348083, train/logprobs = tensor([[-1.4032, -2.3158],
        [-1.3220, -1.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009538639336824417
Epoch 0, Step 359: train/loss = 0.5495623350143433, train/raw-loss = 0.5462534427642822, train/logprobs = tensor([[-0.8814, -2.7787],
        [-0.9141, -2.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011029649525880814
Epoch 0, Step 360: train/loss = 0.5702299475669861, train/raw-loss = 0.567834734916687, train/logprobs = tensor([[-0.8390, -3.5000],
        [-0.7694, -2.8631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007983929477632046
Epoch 0, Step 361: train/loss = 0.5863806009292603, train/raw-loss = 0.5848344564437866, train/logprobs = tensor([[-0.7495, -2.8365],
        [-0.7198, -2.3279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00515382643789053
Epoch 0, Step 362: train/loss = 0.6339241862297058, train/raw-loss = 0.6300965547561646, train/logprobs = tensor([[-1.5336, -1.7981],
        [-1.5544, -1.5041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012758933007717133
Epoch 0, Step 363: train/loss = 0.5954410433769226, train/raw-loss = 0.5936400294303894, train/logprobs = tensor([[-1.3271, -2.3341],
        [-1.3440, -1.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006003557704389095
Epoch 0, Step 364: train/loss = 0.6006908416748047, train/raw-loss = 0.5982798933982849, train/logprobs = tensor([[-0.9559, -1.9347],
        [-1.0243, -1.5850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00803653709590435
Epoch 0, Step 365: train/loss = 0.5904660224914551, train/raw-loss = 0.5881057381629944, train/logprobs = tensor([[-1.4030, -1.9222],
        [-1.3608, -1.4146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00786765106022358
Epoch 0, Step 366: train/loss = 0.6196240782737732, train/raw-loss = 0.6171124577522278, train/logprobs = tensor([[-1.3208, -1.9092],
        [-1.3133, -1.5497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008372088894248009
Epoch 0, Step 367: train/loss = 0.5945279002189636, train/raw-loss = 0.5926419496536255, train/logprobs = tensor([[-1.1203, -1.8392],
        [-1.1174, -1.4057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006286450661718845
Epoch 0, Step 368: train/loss = 0.5685285329818726, train/raw-loss = 0.562873125076294, train/logprobs = tensor([[-1.3613, -2.5719],
        [-1.3896, -1.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018851079046726227
Epoch 0, Step 369: train/loss = 0.5865607857704163, train/raw-loss = 0.5836487412452698, train/logprobs = tensor([[-1.1815, -1.9177],
        [-1.1845, -1.3987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009706711396574974
Epoch 0, Step 370: train/loss = 0.551483690738678, train/raw-loss = 0.5476641654968262, train/logprobs = tensor([[-1.0867, -2.5371],
        [-1.0250, -1.8191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012731771916151047
Epoch 0, Step 371: train/loss = 0.6339120268821716, train/raw-loss = 0.6321353912353516, train/logprobs = tensor([[-0.6159, -1.1946],
        [-0.6283, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005921968258917332
Epoch 0, Step 372: train/loss = 0.6220794320106506, train/raw-loss = 0.6188074350357056, train/logprobs = tensor([[-1.1505, -2.1992],
        [-1.1543, -1.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010906889103353024
Epoch 0, Step 373: train/loss = 0.5946739315986633, train/raw-loss = 0.5917208194732666, train/logprobs = tensor([[-1.1359, -2.8517],
        [-1.0381, -2.2790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00984359160065651
Epoch 0, Step 374: train/loss = 0.6269012689590454, train/raw-loss = 0.6250872611999512, train/logprobs = tensor([[-0.8071, -1.2631],
        [-0.8436, -1.0015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006046620197594166
Epoch 0, Step 375: train/loss = 0.6232748627662659, train/raw-loss = 0.622043251991272, train/logprobs = tensor([[-1.1550, -1.8208],
        [-1.2090, -1.5716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004105321131646633
Epoch 0, Step 376: train/loss = 0.6333235502243042, train/raw-loss = 0.630522608757019, train/logprobs = tensor([[-1.4922, -1.9054],
        [-1.4082, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009336382150650024
Epoch 0, Step 377: train/loss = 0.6688618063926697, train/raw-loss = 0.6679949760437012, train/logprobs = tensor([[-0.6479, -0.8984],
        [-0.6690, -0.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028895679861307144
Epoch 0, Step 378: train/loss = 0.6709231734275818, train/raw-loss = 0.6662260293960571, train/logprobs = tensor([[-2.1058, -1.9425],
        [-1.9048, -1.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015656933188438416
Epoch 0, Step 379: train/loss = 0.597127377986908, train/raw-loss = 0.5920115113258362, train/logprobs = tensor([[-2.0349, -3.0455],
        [-1.8002, -2.3084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017052825540304184
Epoch 0, Step 380: train/loss = 0.6138471961021423, train/raw-loss = 0.6116429567337036, train/logprobs = tensor([[-1.0495, -1.9064],
        [-1.0406, -1.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007347353734076023
Epoch 0, Step 381: train/loss = 0.5660487413406372, train/raw-loss = 0.5622188448905945, train/logprobs = tensor([[-1.0526, -2.3994],
        [-0.9849, -1.7291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012766463682055473
Epoch 0, Step 382: train/loss = 0.6496429443359375, train/raw-loss = 0.6474341750144958, train/logprobs = tensor([[-1.2541, -1.9313],
        [-1.0603, -1.5044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0073625026270747185
Epoch 0, Step 383: train/loss = 0.6519436240196228, train/raw-loss = 0.6510421633720398, train/logprobs = tensor([[-2.2019, -2.4478],
        [-1.8762, -1.9414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003004905302077532
Epoch 0, Step 384: train/loss = 0.5830371379852295, train/raw-loss = 0.5796988010406494, train/logprobs = tensor([[-0.9675, -2.0361],
        [-1.1306, -1.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01112764235585928
Epoch 0, Step 385: train/loss = 0.6357041597366333, train/raw-loss = 0.6330400109291077, train/logprobs = tensor([[-1.6181, -1.8629],
        [-1.5276, -1.4933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00888063944876194
Epoch 0, Step 386: train/loss = 0.5875389575958252, train/raw-loss = 0.5843154191970825, train/logprobs = tensor([[-1.5035, -2.3341],
        [-1.4836, -1.7712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010745097883045673
Epoch 0, Step 387: train/loss = 0.5466283559799194, train/raw-loss = 0.5388399362564087, train/logprobs = tensor([[-1.3564, -2.1895],
        [-1.3615, -1.4668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02596139907836914
Epoch 0, Step 388: train/loss = 0.6238206624984741, train/raw-loss = 0.6204370856285095, train/logprobs = tensor([[-0.9864, -1.2918],
        [-0.9617, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011278542689979076
Epoch 0, Step 389: train/loss = 0.6115592122077942, train/raw-loss = 0.6106775999069214, train/logprobs = tensor([[-0.8608, -1.7163],
        [-0.8867, -1.3766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029387399554252625
Epoch 0, Step 390: train/loss = 0.5255786776542664, train/raw-loss = 0.5169236660003662, train/logprobs = tensor([[-1.3046, -2.5299],
        [-1.2939, -1.6851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028850039467215538
Epoch 0, Step 391: train/loss = 0.5881723761558533, train/raw-loss = 0.5842006206512451, train/logprobs = tensor([[-1.6946, -2.2274],
        [-1.2712, -1.3023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013239034451544285
Epoch 0, Step 392: train/loss = 0.547172486782074, train/raw-loss = 0.5320422649383545, train/logprobs = tensor([[-1.2567, -2.2638],
        [-1.4899, -1.6234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05043409392237663
Epoch 0, Step 393: train/loss = 0.5634103417396545, train/raw-loss = 0.5598338842391968, train/logprobs = tensor([[-1.6428, -2.5102],
        [-1.5962, -1.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011921393685042858
Epoch 0, Step 394: train/loss = 0.5538355708122253, train/raw-loss = 0.5482597351074219, train/logprobs = tensor([[-1.3790, -2.5782],
        [-1.2601, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0185861699283123
Epoch 0, Step 395: train/loss = 0.5879213809967041, train/raw-loss = 0.5843406319618225, train/logprobs = tensor([[-1.1135, -1.8936],
        [-1.2080, -1.5004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011935724876821041
Epoch 0, Step 396: train/loss = 0.5289198756217957, train/raw-loss = 0.5133987665176392, train/logprobs = tensor([[-0.9593, -2.5474],
        [-1.0673, -1.6911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051736969500780106
Epoch 0, Step 397: train/loss = 0.6308382153511047, train/raw-loss = 0.6278228163719177, train/logprobs = tensor([[-1.7721, -1.6344],
        [-1.4952, -1.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010051408782601357
Epoch 0, Step 398: train/loss = 0.542851448059082, train/raw-loss = 0.5325341820716858, train/logprobs = tensor([[-1.1195, -2.3286],
        [-1.1986, -1.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034390635788440704
Epoch 0, Step 399: train/loss = 0.5838199853897095, train/raw-loss = 0.5804834961891174, train/logprobs = tensor([[-1.4029, -2.1098],
        [-1.4030, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01112164743244648
Epoch 0, Step 400: train/loss = 0.591126561164856, train/raw-loss = 0.5863518714904785, train/logprobs = tensor([[-1.8199, -2.0123],
        [-1.7238, -1.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01591544784605503
Epoch 0, Step 401: train/loss = 0.476709246635437, train/raw-loss = 0.46504300832748413, train/logprobs = tensor([[-1.3548, -2.4691],
        [-1.4163, -1.4341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038887541741132736
Epoch 0, Step 402: train/loss = 0.5894076228141785, train/raw-loss = 0.5869044065475464, train/logprobs = tensor([[-1.1724, -1.9123],
        [-1.1721, -1.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008344089612364769
Epoch 0, Step 403: train/loss = 0.5375760197639465, train/raw-loss = 0.5313589572906494, train/logprobs = tensor([[-1.6299, -2.1095],
        [-1.7965, -1.5374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02072359248995781
Epoch 0, Step 404: train/loss = 0.5627835988998413, train/raw-loss = 0.5600001811981201, train/logprobs = tensor([[-1.2994, -2.3575],
        [-1.3729, -1.8506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009278066456317902
Epoch 0, Step 405: train/loss = 0.6213409900665283, train/raw-loss = 0.6184564828872681, train/logprobs = tensor([[-0.8356, -1.6616],
        [-0.9221, -1.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009615127928555012
Epoch 0, Step 406: train/loss = 0.5781258940696716, train/raw-loss = 0.5695846676826477, train/logprobs = tensor([[-1.5140, -2.2658],
        [-1.6358, -1.7367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028470739722251892
Epoch 0, Step 407: train/loss = 0.5911762714385986, train/raw-loss = 0.5877670049667358, train/logprobs = tensor([[-1.2874, -2.5203],
        [-1.2798, -2.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011364218778908253
Epoch 0, Step 408: train/loss = 0.5927661657333374, train/raw-loss = 0.5874751806259155, train/logprobs = tensor([[-1.4244, -1.7123],
        [-1.4348, -1.2282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017636775970458984
Epoch 0, Step 409: train/loss = 0.5213273763656616, train/raw-loss = 0.5129189491271973, train/logprobs = tensor([[-0.8640, -2.1300],
        [-0.9759, -1.3757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028028300032019615
Epoch 0, Step 410: train/loss = 0.5872495174407959, train/raw-loss = 0.5824187994003296, train/logprobs = tensor([[-1.1187, -1.8748],
        [-1.1098, -1.3497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016102327033877373
Epoch 0, Step 411: train/loss = 0.6770715117454529, train/raw-loss = 0.6768525838851929, train/logprobs = tensor([[-1.5204, -1.4441],
        [-1.2423, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007296532858163118
Epoch 0, Step 412: train/loss = 0.5882887840270996, train/raw-loss = 0.5830959677696228, train/logprobs = tensor([[-1.1497, -1.8716],
        [-1.4372, -1.6430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017309468239545822
Epoch 0, Step 413: train/loss = 0.6698528528213501, train/raw-loss = 0.6667109727859497, train/logprobs = tensor([[-1.5620, -1.1092],
        [-1.5751, -0.9467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010472692549228668
Epoch 0, Step 414: train/loss = 0.6525672078132629, train/raw-loss = 0.6488629579544067, train/logprobs = tensor([[-1.1234, -1.3608],
        [-1.1041, -1.0910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012347348034381866
Epoch 0, Step 415: train/loss = 0.5108737349510193, train/raw-loss = 0.5047891736030579, train/logprobs = tensor([[-0.7325, -2.6615],
        [-0.7553, -1.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020281977951526642
Epoch 0, Step 416: train/loss = 0.5026136636734009, train/raw-loss = 0.4965782165527344, train/logprobs = tensor([[-1.0255, -2.5465],
        [-1.0200, -1.6175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020118165761232376
Epoch 0, Step 417: train/loss = 0.45108574628829956, train/raw-loss = 0.44511258602142334, train/logprobs = tensor([[-1.1237, -4.0474],
        [-1.1679, -2.8849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019910568371415138
Epoch 0, Step 418: train/loss = 0.5978190898895264, train/raw-loss = 0.5946578979492188, train/logprobs = tensor([[-1.6343, -2.1535],
        [-1.3858, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010537230409681797
Epoch 0, Step 419: train/loss = 0.6212127208709717, train/raw-loss = 0.6134474873542786, train/logprobs = tensor([[-2.4035, -2.8331],
        [-1.8261, -1.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02588396519422531
Epoch 0, Step 420: train/loss = 0.4955204129219055, train/raw-loss = 0.48703837394714355, train/logprobs = tensor([[-1.2968, -2.9386],
        [-1.3762, -2.0151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028273601084947586
Epoch 0, Step 421: train/loss = 0.5789207816123962, train/raw-loss = 0.5744937658309937, train/logprobs = tensor([[-0.7689, -2.0702],
        [-0.7194, -1.4590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014756375923752785
Epoch 0, Step 422: train/loss = 0.5365170240402222, train/raw-loss = 0.5305347442626953, train/logprobs = tensor([[-1.2237, -2.0029],
        [-1.2523, -1.2926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019940942525863647
Epoch 0, Step 423: train/loss = 0.5490485429763794, train/raw-loss = 0.542618453502655, train/logprobs = tensor([[-1.7080, -2.0528],
        [-1.6302, -1.2742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02143361046910286
Epoch 0, Step 424: train/loss = 0.5054540038108826, train/raw-loss = 0.49342960119247437, train/logprobs = tensor([[-0.8950, -2.2695],
        [-0.9048, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04008126258850098
Epoch 0, Step 425: train/loss = 0.45637717843055725, train/raw-loss = 0.4500992000102997, train/logprobs = tensor([[-1.2586, -3.3054],
        [-1.2676, -2.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020926639437675476
Epoch 0, Step 426: train/loss = 0.5431657433509827, train/raw-loss = 0.5382498502731323, train/logprobs = tensor([[-1.5844, -2.0285],
        [-1.5281, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01638607122004032
Epoch 0, Step 427: train/loss = 0.6477603912353516, train/raw-loss = 0.646859884262085, train/logprobs = tensor([[-0.9435, -1.3894],
        [-0.9740, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030015830416232347
Epoch 0, Step 428: train/loss = 0.5397433042526245, train/raw-loss = 0.5309018492698669, train/logprobs = tensor([[-1.6132, -2.1491],
        [-1.5866, -1.3366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02947150357067585
Epoch 0, Step 429: train/loss = 0.64687180519104, train/raw-loss = 0.6452469229698181, train/logprobs = tensor([[-1.1234, -1.2269],
        [-1.0168, -0.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005416253115981817
Epoch 0, Step 430: train/loss = 0.554931640625, train/raw-loss = 0.5495224595069885, train/logprobs = tensor([[-1.3554, -3.0551],
        [-1.0146, -1.9830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018030574545264244
Epoch 0, Step 431: train/loss = 0.5418362617492676, train/raw-loss = 0.5385324954986572, train/logprobs = tensor([[-1.9124, -2.9438],
        [-1.6625, -1.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011012476868927479
Epoch 0, Step 432: train/loss = 0.6488488912582397, train/raw-loss = 0.647557258605957, train/logprobs = tensor([[-1.1595, -1.6549],
        [-1.1604, -1.4524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004305548500269651
Epoch 0, Step 433: train/loss = 0.4932743012905121, train/raw-loss = 0.4843289852142334, train/logprobs = tensor([[-1.5856, -3.0897],
        [-1.5443, -2.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02981778047978878
Epoch 0, Step 434: train/loss = 0.5068297982215881, train/raw-loss = 0.4997897148132324, train/logprobs = tensor([[-1.2570, -2.7862],
        [-1.5115, -2.1385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02346687577664852
Epoch 0, Step 435: train/loss = 0.6091291308403015, train/raw-loss = 0.6068350076675415, train/logprobs = tensor([[-1.6274, -1.9217],
        [-1.6966, -1.6002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007647078949958086
Epoch 0, Step 436: train/loss = 0.5312507152557373, train/raw-loss = 0.5227518081665039, train/logprobs = tensor([[-1.3281, -1.9391],
        [-1.3528, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02832961454987526
Epoch 0, Step 437: train/loss = 0.4754994213581085, train/raw-loss = 0.46672412753105164, train/logprobs = tensor([[-1.0153, -2.4687],
        [-1.1339, -1.5219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02925105392932892
Epoch 0, Step 438: train/loss = 0.6154263615608215, train/raw-loss = 0.6106712818145752, train/logprobs = tensor([[-1.5933, -2.3144],
        [-1.2781, -1.5791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01585032418370247
Epoch 0, Step 439: train/loss = 0.5374786853790283, train/raw-loss = 0.5320497751235962, train/logprobs = tensor([[-1.2385, -2.1464],
        [-1.3320, -1.5166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01809653639793396
Epoch 0, Step 440: train/loss = 0.6097295880317688, train/raw-loss = 0.6070717573165894, train/logprobs = tensor([[-2.0364, -2.1464],
        [-1.7238, -1.4531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008859312161803246
Epoch 0, Step 441: train/loss = 0.4673970341682434, train/raw-loss = 0.4575532376766205, train/logprobs = tensor([[-1.2642, -3.2696],
        [-1.2814, -2.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03281264752149582
Epoch 0, Step 442: train/loss = 0.6306796669960022, train/raw-loss = 0.602746844291687, train/logprobs = tensor([[-1.9129, -1.8169],
        [-1.8293, -1.0178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09310952574014664
Epoch 0, Step 443: train/loss = 0.532538890838623, train/raw-loss = 0.5255059599876404, train/logprobs = tensor([[-1.4899, -2.7436],
        [-1.5569, -1.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023443005979061127
Epoch 0, Step 444: train/loss = 0.5856199860572815, train/raw-loss = 0.5829669237136841, train/logprobs = tensor([[-0.9702, -2.1692],
        [-0.9893, -1.6728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008843549527227879
Epoch 0, Step 445: train/loss = 0.6036875247955322, train/raw-loss = 0.5973062515258789, train/logprobs = tensor([[-1.8603, -1.8459],
        [-1.7672, -1.2383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021270981058478355
Epoch 0, Step 446: train/loss = 0.5105018615722656, train/raw-loss = 0.505325973033905, train/logprobs = tensor([[-1.4289, -3.1451],
        [-1.2210, -2.0510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017253175377845764
Epoch 0, Step 447: train/loss = 0.43141117691993713, train/raw-loss = 0.41540613770484924, train/logprobs = tensor([[-1.1950, -2.9049],
        [-1.2046, -1.4627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05335017666220665
Epoch 0, Step 448: train/loss = 0.5118030309677124, train/raw-loss = 0.4945610761642456, train/logprobs = tensor([[-1.6003, -2.6298],
        [-1.2400, -1.2156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05747328698635101
Epoch 0, Step 449: train/loss = 0.6038661003112793, train/raw-loss = 0.601470947265625, train/logprobs = tensor([[-1.6372, -1.6620],
        [-1.4267, -1.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007983808405697346
Epoch 0, Step 450: train/loss = 0.5072000622749329, train/raw-loss = 0.4999927878379822, train/logprobs = tensor([[-0.6665, -2.2849],
        [-0.6783, -1.3710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024024169892072678
Epoch 0, Step 451: train/loss = 0.5430008769035339, train/raw-loss = 0.5340814590454102, train/logprobs = tensor([[-2.1494, -2.6406],
        [-1.9184, -1.6321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029731396585702896
Epoch 0, Step 452: train/loss = 0.4675127863883972, train/raw-loss = 0.4549025893211365, train/logprobs = tensor([[-1.4296, -2.4094],
        [-1.5016, -1.3157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042034026235342026
Epoch 0, Step 453: train/loss = 0.5073593854904175, train/raw-loss = 0.4969518482685089, train/logprobs = tensor([[-1.0239, -2.3542],
        [-1.1334, -1.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03469178453087807
Epoch 0, Step 454: train/loss = 0.5301253795623779, train/raw-loss = 0.5222725868225098, train/logprobs = tensor([[-1.7285, -2.2817],
        [-1.6770, -1.4024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0261758454144001
Epoch 0, Step 455: train/loss = 0.45988595485687256, train/raw-loss = 0.450991690158844, train/logprobs = tensor([[-0.9170, -2.2981],
        [-0.9114, -1.1254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029647596180438995
Epoch 0, Step 456: train/loss = 0.5162009596824646, train/raw-loss = 0.507504940032959, train/logprobs = tensor([[-0.8886, -2.2122],
        [-0.8745, -1.1723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028986666351556778
Epoch 0, Step 457: train/loss = 0.4925009608268738, train/raw-loss = 0.48036688566207886, train/logprobs = tensor([[-0.7804, -1.9898],
        [-0.8399, -1.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040446892380714417
Epoch 0, Step 458: train/loss = 0.6095237731933594, train/raw-loss = 0.6047127842903137, train/logprobs = tensor([[-1.7006, -2.1961],
        [-1.3215, -1.3807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016036713495850563
Epoch 0, Step 459: train/loss = 0.5180566906929016, train/raw-loss = 0.5134729146957397, train/logprobs = tensor([[-0.9079, -2.2559],
        [-1.0585, -1.5726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015279357321560383
Epoch 0, Step 460: train/loss = 0.5823774337768555, train/raw-loss = 0.5724517107009888, train/logprobs = tensor([[-0.9185, -1.6647],
        [-1.0790, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0330859012901783
Epoch 0, Step 461: train/loss = 0.6755099296569824, train/raw-loss = 0.669670581817627, train/logprobs = tensor([[-1.8104, -1.7503],
        [-1.3848, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01946478709578514
Epoch 0, Step 462: train/loss = 0.45100653171539307, train/raw-loss = 0.44152870774269104, train/logprobs = tensor([[-0.9425, -2.8914],
        [-1.0045, -1.7483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031592682003974915
Epoch 0, Step 463: train/loss = 0.5193176865577698, train/raw-loss = 0.5099857449531555, train/logprobs = tensor([[-1.0663, -2.2148],
        [-1.0200, -1.2600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031106332316994667
Epoch 0, Step 464: train/loss = 0.45009633898735046, train/raw-loss = 0.43813011050224304, train/logprobs = tensor([[-1.0932, -3.4895],
        [-1.1524, -2.2261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03988746181130409
Epoch 0, Step 465: train/loss = 0.6364320516586304, train/raw-loss = 0.6308540105819702, train/logprobs = tensor([[-1.1176, -1.4207],
        [-1.1496, -1.1262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018593305721879005
Epoch 0, Step 466: train/loss = 0.5027516484260559, train/raw-loss = 0.4908638298511505, train/logprobs = tensor([[-1.6294, -2.4879],
        [-1.6825, -1.5618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039626192301511765
Epoch 0, Step 467: train/loss = 0.6024243831634521, train/raw-loss = 0.5988450050354004, train/logprobs = tensor([[-1.7347, -2.0055],
        [-1.3908, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011931306682527065
Epoch 0, Step 468: train/loss = 0.5863931775093079, train/raw-loss = 0.583426833152771, train/logprobs = tensor([[-1.3652, -2.1398],
        [-1.1590, -1.4467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009887820109724998
Epoch 0, Step 469: train/loss = 0.5796599388122559, train/raw-loss = 0.5759158134460449, train/logprobs = tensor([[-1.0670, -1.6468],
        [-1.0599, -1.1094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012480251491069794
Epoch 0, Step 470: train/loss = 0.4976804852485657, train/raw-loss = 0.49259713292121887, train/logprobs = tensor([[-1.0313, -2.8873],
        [-0.9617, -1.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01694452576339245
Epoch 0, Step 471: train/loss = 0.4815979599952698, train/raw-loss = 0.4746335446834564, train/logprobs = tensor([[-1.2544, -2.8003],
        [-1.1803, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02321457862854004
Epoch 0, Step 472: train/loss = 0.35565823316574097, train/raw-loss = 0.32448482513427734, train/logprobs = tensor([[-1.9117, -5.1735],
        [-1.8006, -2.1425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1039113849401474
Epoch 0, Step 473: train/loss = 0.5765143632888794, train/raw-loss = 0.5696496367454529, train/logprobs = tensor([[-1.7987, -2.1765],
        [-1.3387, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022882338613271713
Epoch 0, Step 474: train/loss = 0.45624110102653503, train/raw-loss = 0.44593071937561035, train/logprobs = tensor([[-0.8288, -2.6122],
        [-0.8668, -1.4679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03436791151762009
Epoch 0, Step 475: train/loss = 0.44944000244140625, train/raw-loss = 0.43609607219696045, train/logprobs = tensor([[-0.9989, -2.5400],
        [-1.1059, -1.3935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04447965696454048
Epoch 0, Step 476: train/loss = 0.648977518081665, train/raw-loss = 0.6448184847831726, train/logprobs = tensor([[-1.5533, -1.7917],
        [-1.1485, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013863425701856613
Epoch 0, Step 477: train/loss = 0.5167905688285828, train/raw-loss = 0.5033453702926636, train/logprobs = tensor([[-1.9197, -2.2561],
        [-1.8974, -1.2725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04481729865074158
Epoch 0, Step 478: train/loss = 0.5886606574058533, train/raw-loss = 0.5804108381271362, train/logprobs = tensor([[-1.8369, -2.1252],
        [-1.7203, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027499409392476082
Epoch 0, Step 479: train/loss = 0.5232263803482056, train/raw-loss = 0.5177168846130371, train/logprobs = tensor([[-1.7775, -2.8648],
        [-1.3781, -1.6649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01836496777832508
Epoch 0, Step 480: train/loss = 0.5841817855834961, train/raw-loss = 0.5748302340507507, train/logprobs = tensor([[-1.3474, -2.0336],
        [-1.3181, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031171850860118866
Epoch 0, Step 481: train/loss = 0.594360888004303, train/raw-loss = 0.5864644050598145, train/logprobs = tensor([[-1.6522, -1.6636],
        [-1.6158, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026321593672037125
Epoch 0, Step 482: train/loss = 0.545731246471405, train/raw-loss = 0.5362145900726318, train/logprobs = tensor([[-1.2756, -2.8439],
        [-1.2290, -1.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03172218054533005
Epoch 0, Step 483: train/loss = 0.503271222114563, train/raw-loss = 0.49073535203933716, train/logprobs = tensor([[-1.6032, -2.5713],
        [-1.5749, -1.5516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04178635776042938
Epoch 0, Step 484: train/loss = 0.5770784020423889, train/raw-loss = 0.5673149824142456, train/logprobs = tensor([[-1.2985, -2.9938],
        [-1.4120, -2.3693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03254491090774536
Epoch 0, Step 485: train/loss = 0.5906200408935547, train/raw-loss = 0.5832657814025879, train/logprobs = tensor([[-1.5691, -1.8865],
        [-1.4432, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024514256045222282
Epoch 0, Step 486: train/loss = 0.6250633597373962, train/raw-loss = 0.623408854007721, train/logprobs = tensor([[-0.7856, -1.3028],
        [-0.9171, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005515021737664938
Epoch 0, Step 487: train/loss = 0.4366908073425293, train/raw-loss = 0.4322301745414734, train/logprobs = tensor([[-1.1812, -4.0302],
        [-1.1081, -2.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014868808910250664
Epoch 0, Step 488: train/loss = 0.6540772914886475, train/raw-loss = 0.646653413772583, train/logprobs = tensor([[-1.9935, -2.6519],
        [-1.6673, -1.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024746235460042953
Epoch 0, Step 489: train/loss = 0.569629430770874, train/raw-loss = 0.5613449811935425, train/logprobs = tensor([[-1.6656, -2.2087],
        [-1.3866, -1.2829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027614958584308624
Epoch 0, Step 490: train/loss = 0.6687039136886597, train/raw-loss = 0.6685645580291748, train/logprobs = tensor([[-0.7298, -1.6330],
        [-0.7969, -1.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00046443426981568336
Epoch 0, Step 491: train/loss = 0.5049906373023987, train/raw-loss = 0.4957113265991211, train/logprobs = tensor([[-1.3525, -2.4061],
        [-1.4772, -1.5973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030931152403354645
Epoch 0, Step 492: train/loss = 0.46050041913986206, train/raw-loss = 0.44487181305885315, train/logprobs = tensor([[-0.6839, -2.6784],
        [-0.8711, -1.5225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05209535360336304
Epoch 0, Step 493: train/loss = 0.5213898420333862, train/raw-loss = 0.5129508972167969, train/logprobs = tensor([[-1.3597, -2.4070],
        [-1.1540, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028129562735557556
Epoch 0, Step 494: train/loss = 0.6664265394210815, train/raw-loss = 0.6643345355987549, train/logprobs = tensor([[-1.8079, -1.5639],
        [-1.5169, -1.1292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00697344820946455
Epoch 0, Step 495: train/loss = 0.6527113914489746, train/raw-loss = 0.6436351537704468, train/logprobs = tensor([[-2.3131, -2.6945],
        [-2.0310, -2.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0302540622651577
Epoch 0, Step 496: train/loss = 0.4983474612236023, train/raw-loss = 0.47427472472190857, train/logprobs = tensor([[-1.6367, -3.0183],
        [-1.6825, -1.6944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08024246990680695
Epoch 0, Step 497: train/loss = 0.4296117424964905, train/raw-loss = 0.41562509536743164, train/logprobs = tensor([[-1.2645, -3.3924],
        [-1.3361, -2.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046622131019830704
Epoch 0, Step 498: train/loss = 0.7319557666778564, train/raw-loss = 0.714398980140686, train/logprobs = tensor([[-1.7779, -2.3795],
        [-1.5746, -1.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058522582054138184
Epoch 0, Step 499: train/loss = 0.5524263381958008, train/raw-loss = 0.5480360984802246, train/logprobs = tensor([[-1.3256, -2.9969],
        [-1.1462, -2.1240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014633897691965103
eval/loss: 0.5473920702934265
Epoch 0, Step 500: train/loss = 0.5018492341041565, train/raw-loss = 0.4833425283432007, train/logprobs = tensor([[-1.3916, -2.7582],
        [-1.3389, -1.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061689019203186035
Epoch 0, Step 501: train/loss = 0.5513900518417358, train/raw-loss = 0.5447276830673218, train/logprobs = tensor([[-1.4531, -2.3735],
        [-1.4244, -1.5978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022207893431186676
Epoch 0, Step 502: train/loss = 0.5280067920684814, train/raw-loss = 0.5197061896324158, train/logprobs = tensor([[-0.8838, -2.6488],
        [-1.0097, -1.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027668695896863937
Epoch 0, Step 503: train/loss = 0.48282694816589355, train/raw-loss = 0.45969271659851074, train/logprobs = tensor([[-1.6654, -3.0817],
        [-1.4248, -1.5841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07711401581764221
Epoch 0, Step 504: train/loss = 0.6405156850814819, train/raw-loss = 0.6391642093658447, train/logprobs = tensor([[-1.3078, -1.5816],
        [-1.1750, -1.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004504915792495012
Epoch 0, Step 505: train/loss = 0.5669298768043518, train/raw-loss = 0.5538369417190552, train/logprobs = tensor([[-1.4722, -2.1390],
        [-1.4258, -1.3481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04364294558763504
Epoch 0, Step 506: train/loss = 0.4788670241832733, train/raw-loss = 0.4637024998664856, train/logprobs = tensor([[-1.4506, -2.9220],
        [-1.3018, -1.5988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05054834485054016
Epoch 0, Step 507: train/loss = 0.5128897428512573, train/raw-loss = 0.4943118691444397, train/logprobs = tensor([[-1.1524, -2.3864],
        [-1.3109, -1.4716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061926327645778656
Epoch 0, Step 508: train/loss = 0.559262752532959, train/raw-loss = 0.5510695576667786, train/logprobs = tensor([[-0.9300, -2.0697],
        [-1.1750, -1.5625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02731059119105339
Epoch 0, Step 509: train/loss = 0.5948079228401184, train/raw-loss = 0.5779457688331604, train/logprobs = tensor([[-1.3508, -1.8306],
        [-1.2287, -1.0088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05620723217725754
Epoch 0, Step 510: train/loss = 0.4917204976081848, train/raw-loss = 0.4826968312263489, train/logprobs = tensor([[-0.9351, -2.6680],
        [-1.0452, -1.7336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030078787356615067
Epoch 0, Step 511: train/loss = 0.43978333473205566, train/raw-loss = 0.4229993224143982, train/logprobs = tensor([[-1.3598, -3.1445],
        [-1.0012, -1.2984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05594676360487938
Epoch 0, Step 512: train/loss = 0.44042542576789856, train/raw-loss = 0.4254780411720276, train/logprobs = tensor([[-0.7834, -2.6858],
        [-0.8862, -1.3956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04982462525367737
Epoch 0, Step 513: train/loss = 0.45630136132240295, train/raw-loss = 0.4440212845802307, train/logprobs = tensor([[-1.6556, -2.4903],
        [-1.6457, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04093364626169205
Epoch 0, Step 514: train/loss = 0.6604655385017395, train/raw-loss = 0.6265290975570679, train/logprobs = tensor([[-2.2154, -2.4184],
        [-2.1024, -1.5933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11312144249677658
Epoch 0, Step 515: train/loss = 0.5054070949554443, train/raw-loss = 0.4964178800582886, train/logprobs = tensor([[-0.9674, -2.9861],
        [-1.0829, -2.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029964087530970573
Epoch 0, Step 516: train/loss = 0.6541086435317993, train/raw-loss = 0.6379203200340271, train/logprobs = tensor([[-2.4917, -3.1453],
        [-1.7515, -1.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05396091192960739
Epoch 0, Step 517: train/loss = 0.5534148216247559, train/raw-loss = 0.5492175817489624, train/logprobs = tensor([[-0.9362, -2.1925],
        [-1.0755, -1.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013990713283419609
Epoch 0, Step 518: train/loss = 0.48932522535324097, train/raw-loss = 0.4786926805973053, train/logprobs = tensor([[-1.5826, -2.7065],
        [-1.5469, -1.6426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03544183075428009
Epoch 0, Step 519: train/loss = 0.47784224152565, train/raw-loss = 0.4668499827384949, train/logprobs = tensor([[-0.9018, -2.5960],
        [-1.0931, -1.5380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664082661271095
Epoch 0, Step 520: train/loss = 0.490817666053772, train/raw-loss = 0.47959569096565247, train/logprobs = tensor([[-1.3610, -3.1146],
        [-1.2651, -1.8206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03740658983588219
Epoch 0, Step 521: train/loss = 0.3689936101436615, train/raw-loss = 0.3404945433139801, train/logprobs = tensor([[-1.5072, -3.6003],
        [-1.6426, -1.8136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09499693661928177
Epoch 0, Step 522: train/loss = 0.4705922603607178, train/raw-loss = 0.45669105648994446, train/logprobs = tensor([[-2.1604, -3.9569],
        [-1.8669, -2.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0463373027741909
Epoch 0, Step 523: train/loss = 0.5307720899581909, train/raw-loss = 0.5178844928741455, train/logprobs = tensor([[-0.9092, -1.9673],
        [-1.0523, -1.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042958877980709076
Epoch 0, Step 524: train/loss = 0.5557752251625061, train/raw-loss = 0.5493184924125671, train/logprobs = tensor([[-1.4845, -1.7957],
        [-1.5240, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02152244560420513
Epoch 0, Step 525: train/loss = 0.5234910249710083, train/raw-loss = 0.5143709182739258, train/logprobs = tensor([[-1.8481, -3.1820],
        [-1.5588, -2.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030400391668081284
Epoch 0, Step 526: train/loss = 0.47792792320251465, train/raw-loss = 0.46430522203445435, train/logprobs = tensor([[-1.9479, -3.1538],
        [-1.8353, -1.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04540899768471718
Epoch 0, Step 527: train/loss = 0.3740484118461609, train/raw-loss = 0.3555290699005127, train/logprobs = tensor([[-1.1221, -3.7927],
        [-1.2472, -1.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06173116713762283
Epoch 0, Step 528: train/loss = 0.6550979614257812, train/raw-loss = 0.6532580256462097, train/logprobs = tensor([[-0.9789, -1.2421],
        [-1.2041, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006133216433227062
Epoch 0, Step 529: train/loss = 0.3427456021308899, train/raw-loss = 0.32769840955734253, train/logprobs = tensor([[-0.8227, -4.0310],
        [-1.1534, -2.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05015729367733002
Epoch 0, Step 530: train/loss = 0.4580596387386322, train/raw-loss = 0.4440782070159912, train/logprobs = tensor([[-1.3446, -2.8220],
        [-1.1479, -1.3696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04660475254058838
Epoch 0, Step 531: train/loss = 0.6000785827636719, train/raw-loss = 0.5916151404380798, train/logprobs = tensor([[-1.5746, -2.1560],
        [-1.3136, -1.3639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028211601078510284
Epoch 0, Step 532: train/loss = 0.45321589708328247, train/raw-loss = 0.4416085183620453, train/logprobs = tensor([[-1.1784, -2.8218],
        [-1.2356, -1.6233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03869131952524185
Epoch 0, Step 533: train/loss = 0.468127965927124, train/raw-loss = 0.4592675268650055, train/logprobs = tensor([[-0.7356, -2.5457],
        [-0.8017, -1.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029534706845879555
Epoch 0, Step 534: train/loss = 0.5763676166534424, train/raw-loss = 0.5706540942192078, train/logprobs = tensor([[-1.6420, -2.3628],
        [-1.4067, -1.5315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01904505118727684
Epoch 0, Step 535: train/loss = 0.540823221206665, train/raw-loss = 0.5319741368293762, train/logprobs = tensor([[-1.0810, -1.8060],
        [-1.2345, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02949698641896248
Epoch 0, Step 536: train/loss = 0.4688913822174072, train/raw-loss = 0.4565834105014801, train/logprobs = tensor([[-1.5030, -2.9670],
        [-1.4813, -1.7531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041026707738637924
Epoch 0, Step 537: train/loss = 0.6094353795051575, train/raw-loss = 0.6013157367706299, train/logprobs = tensor([[-1.5385, -2.0157],
        [-1.2950, -1.2728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027065692469477654
Epoch 0, Step 538: train/loss = 0.5473794341087341, train/raw-loss = 0.5349263548851013, train/logprobs = tensor([[-1.5153, -2.4287],
        [-1.6037, -1.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041509971022605896
Epoch 0, Step 539: train/loss = 0.42306554317474365, train/raw-loss = 0.3992571234703064, train/logprobs = tensor([[-1.2786, -3.5996],
        [-1.4573, -2.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07936135679483414
Epoch 0, Step 540: train/loss = 0.5269138813018799, train/raw-loss = 0.5158137679100037, train/logprobs = tensor([[-1.3809, -2.1316],
        [-1.2107, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037000518292188644
Epoch 0, Step 541: train/loss = 0.5347880125045776, train/raw-loss = 0.5241518616676331, train/logprobs = tensor([[-2.0073, -2.8591],
        [-1.8661, -1.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0354539230465889
Epoch 0, Step 542: train/loss = 0.48241332173347473, train/raw-loss = 0.47397544980049133, train/logprobs = tensor([[-1.6282, -3.0305],
        [-1.7816, -2.1036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028126154094934464
Epoch 0, Step 543: train/loss = 0.452185720205307, train/raw-loss = 0.43656983971595764, train/logprobs = tensor([[-1.3353, -2.7827],
        [-1.2797, -1.4611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052052803337574005
Epoch 0, Step 544: train/loss = 0.5120724439620972, train/raw-loss = 0.5044568181037903, train/logprobs = tensor([[-0.9766, -2.1390],
        [-1.1325, -1.3253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025385431945323944
Epoch 0, Step 545: train/loss = 0.562882125377655, train/raw-loss = 0.5574291348457336, train/logprobs = tensor([[-0.7582, -1.6102],
        [-0.8645, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018176736310124397
Epoch 0, Step 546: train/loss = 0.4943363070487976, train/raw-loss = 0.4762757122516632, train/logprobs = tensor([[-2.0570, -2.4101],
        [-1.8752, -1.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06020193547010422
Epoch 0, Step 547: train/loss = 0.4378186762332916, train/raw-loss = 0.4254857897758484, train/logprobs = tensor([[-0.7535, -2.6204],
        [-0.8639, -1.4252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04110972210764885
Epoch 0, Step 548: train/loss = 0.5301910638809204, train/raw-loss = 0.5229591727256775, train/logprobs = tensor([[-1.2873, -2.4019],
        [-1.3231, -1.5742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024106264114379883
Epoch 0, Step 549: train/loss = 0.5163736939430237, train/raw-loss = 0.5056576728820801, train/logprobs = tensor([[-1.4048, -2.0969],
        [-1.5818, -1.3708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035720113664865494
Epoch 0, Step 550: train/loss = 0.5312035083770752, train/raw-loss = 0.5205096006393433, train/logprobs = tensor([[-1.4432, -2.0753],
        [-1.2838, -1.0729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03564625233411789
Epoch 0, Step 551: train/loss = 0.47525763511657715, train/raw-loss = 0.46400588750839233, train/logprobs = tensor([[-0.8712, -2.3738],
        [-0.9916, -1.2204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037505730986595154
Epoch 0, Step 552: train/loss = 0.38045015931129456, train/raw-loss = 0.36043840646743774, train/logprobs = tensor([[-1.3031, -3.1806],
        [-1.3077, -1.4353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06670579314231873
Epoch 0, Step 553: train/loss = 0.49418145418167114, train/raw-loss = 0.4863737225532532, train/logprobs = tensor([[-1.6721, -2.9138],
        [-1.4738, -1.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026025807484984398
Epoch 0, Step 554: train/loss = 0.5347950458526611, train/raw-loss = 0.5107792019844055, train/logprobs = tensor([[-1.2642, -2.2346],
        [-1.3644, -1.2854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08005285263061523
Epoch 0, Step 555: train/loss = 0.40926679968833923, train/raw-loss = 0.3844539225101471, train/logprobs = tensor([[-2.0739, -3.8478],
        [-1.8926, -1.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08270955085754395
Epoch 0, Step 556: train/loss = 0.41091135144233704, train/raw-loss = 0.3878847360610962, train/logprobs = tensor([[-1.7875, -3.1828],
        [-1.8004, -1.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675537467002869
Epoch 0, Step 557: train/loss = 0.4697238504886627, train/raw-loss = 0.4518510699272156, train/logprobs = tensor([[-0.8510, -2.6080],
        [-0.8841, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0595758855342865
Epoch 0, Step 558: train/loss = 0.6025316119194031, train/raw-loss = 0.5981078743934631, train/logprobs = tensor([[-1.9821, -2.1296],
        [-1.7195, -1.4259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014745690859854221
Epoch 0, Step 559: train/loss = 0.4291095733642578, train/raw-loss = 0.4201453924179077, train/logprobs = tensor([[-1.0788, -3.1503],
        [-1.3217, -2.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029880546033382416
Epoch 0, Step 560: train/loss = 0.5388054847717285, train/raw-loss = 0.5336766242980957, train/logprobs = tensor([[-1.1715, -2.2049],
        [-1.2617, -1.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017096228897571564
Epoch 0, Step 561: train/loss = 0.48952871561050415, train/raw-loss = 0.4788559675216675, train/logprobs = tensor([[-2.1396, -3.2198],
        [-1.5815, -1.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035575639456510544
Epoch 0, Step 562: train/loss = 0.5880899429321289, train/raw-loss = 0.5854265689849854, train/logprobs = tensor([[-1.2449, -2.1957],
        [-1.3509, -1.8068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008877999149262905
Epoch 0, Step 563: train/loss = 0.45585954189300537, train/raw-loss = 0.4408435821533203, train/logprobs = tensor([[-1.8248, -2.8734],
        [-1.4856, -1.2733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05005322024226189
Epoch 0, Step 564: train/loss = 0.6311042308807373, train/raw-loss = 0.6286137104034424, train/logprobs = tensor([[-1.5567, -1.5779],
        [-1.2746, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008301596157252789
Epoch 0, Step 565: train/loss = 0.5066366791725159, train/raw-loss = 0.4864305555820465, train/logprobs = tensor([[-1.1601, -2.3881],
        [-1.2098, -1.3081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06735367327928543
Epoch 0, Step 566: train/loss = 0.4062683880329132, train/raw-loss = 0.38639795780181885, train/logprobs = tensor([[-1.3244, -3.2137],
        [-1.3153, -1.5269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06623473018407822
Epoch 0, Step 567: train/loss = 0.39401474595069885, train/raw-loss = 0.37883657217025757, train/logprobs = tensor([[-1.0709, -3.6232],
        [-0.9008, -1.6415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050593867897987366
Epoch 0, Step 568: train/loss = 0.37378373742103577, train/raw-loss = 0.35212451219558716, train/logprobs = tensor([[-1.6768, -3.4581],
        [-1.5588, -1.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0721973329782486
Epoch 0, Step 569: train/loss = 0.3885117769241333, train/raw-loss = 0.3732524514198303, train/logprobs = tensor([[-1.8923, -3.8731],
        [-1.8556, -2.1171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050864286720752716
Epoch 0, Step 570: train/loss = 0.5587127208709717, train/raw-loss = 0.5508344173431396, train/logprobs = tensor([[-1.5867, -2.7569],
        [-1.3724, -1.7249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026260942220687866
Epoch 0, Step 571: train/loss = 0.4834117889404297, train/raw-loss = 0.473826140165329, train/logprobs = tensor([[-1.5089, -3.0990],
        [-1.4968, -1.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031952034682035446
Epoch 0, Step 572: train/loss = 0.37710797786712646, train/raw-loss = 0.3590654134750366, train/logprobs = tensor([[-1.2208, -4.0416],
        [-1.2280, -2.1466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060141682624816895
Epoch 0, Step 573: train/loss = 0.5569700002670288, train/raw-loss = 0.542969822883606, train/logprobs = tensor([[-2.0637, -3.6233],
        [-1.4882, -2.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04666728153824806
Epoch 0, Step 574: train/loss = 0.5682856440544128, train/raw-loss = 0.5503988265991211, train/logprobs = tensor([[-1.2766, -2.1212],
        [-1.2352, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0596226304769516
Epoch 0, Step 575: train/loss = 0.4542172849178314, train/raw-loss = 0.4331550598144531, train/logprobs = tensor([[-1.2549, -3.0446],
        [-1.2746, -1.6320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0702073723077774
Epoch 0, Step 576: train/loss = 0.4770835340023041, train/raw-loss = 0.46295011043548584, train/logprobs = tensor([[-1.0413, -1.9599],
        [-1.2938, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047111447900533676
Epoch 0, Step 577: train/loss = 0.4367233216762543, train/raw-loss = 0.4153619408607483, train/logprobs = tensor([[-2.2127, -3.8960],
        [-1.8527, -2.0825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07120466232299805
Epoch 0, Step 578: train/loss = 0.492966890335083, train/raw-loss = 0.46483245491981506, train/logprobs = tensor([[-1.6592, -2.7882],
        [-1.4455, -1.1199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09378132224082947
Epoch 0, Step 579: train/loss = 0.4770094156265259, train/raw-loss = 0.4660162329673767, train/logprobs = tensor([[-0.9483, -2.4266],
        [-0.9530, -1.2198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03664396330714226
Epoch 0, Step 580: train/loss = 0.6220588088035583, train/raw-loss = 0.6112543940544128, train/logprobs = tensor([[-1.5027, -2.5079],
        [-1.3169, -1.5693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036014750599861145
Epoch 0, Step 581: train/loss = 0.29839766025543213, train/raw-loss = 0.2855094373226166, train/logprobs = tensor([[-0.6210, -4.4589],
        [-0.7693, -2.3280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04296074062585831
Epoch 0, Step 582: train/loss = 0.44700759649276733, train/raw-loss = 0.43328872323036194, train/logprobs = tensor([[-1.5581, -2.6233],
        [-1.5646, -1.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04572954773902893
Epoch 0, Step 583: train/loss = 0.36711055040359497, train/raw-loss = 0.354595422744751, train/logprobs = tensor([[-1.1698, -3.9537],
        [-1.2468, -2.2523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04171708598732948
Epoch 0, Step 584: train/loss = 0.46151429414749146, train/raw-loss = 0.4427756369113922, train/logprobs = tensor([[-1.5133, -3.0730],
        [-1.6456, -1.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062462225556373596
Epoch 0, Step 585: train/loss = 0.499415785074234, train/raw-loss = 0.4921826124191284, train/logprobs = tensor([[-0.7488, -2.9802],
        [-0.9214, -1.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02411055378615856
Epoch 0, Step 586: train/loss = 0.6518350839614868, train/raw-loss = 0.6497815251350403, train/logprobs = tensor([[-2.7369, -1.9199],
        [-2.1669, -1.1474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006845308933407068
Epoch 0, Step 587: train/loss = 0.4969881772994995, train/raw-loss = 0.48487588763237, train/logprobs = tensor([[-0.7512, -2.1602],
        [-0.9050, -1.1730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040374189615249634
Epoch 0, Step 588: train/loss = 0.4782610237598419, train/raw-loss = 0.46675753593444824, train/logprobs = tensor([[-1.8079, -2.5972],
        [-1.6479, -1.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03834506869316101
Epoch 0, Step 589: train/loss = 0.5951532125473022, train/raw-loss = 0.5909556150436401, train/logprobs = tensor([[-2.1790, -3.0489],
        [-1.1888, -1.4658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013991808518767357
Epoch 0, Step 590: train/loss = 0.448146790266037, train/raw-loss = 0.4349074363708496, train/logprobs = tensor([[-1.6274, -3.1479],
        [-1.4434, -1.7045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044131118804216385
Epoch 0, Step 591: train/loss = 0.46915560960769653, train/raw-loss = 0.4551902711391449, train/logprobs = tensor([[-1.3782, -2.5366],
        [-1.4895, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04655103757977486
Epoch 0, Step 592: train/loss = 0.5880358219146729, train/raw-loss = 0.5729365348815918, train/logprobs = tensor([[-2.3036, -2.2324],
        [-1.8839, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05033121258020401
Epoch 0, Step 593: train/loss = 0.40002739429473877, train/raw-loss = 0.36183303594589233, train/logprobs = tensor([[-1.6702, -3.6046],
        [-1.6000, -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12731432914733887
Epoch 0, Step 594: train/loss = 0.5739089250564575, train/raw-loss = 0.5712153911590576, train/logprobs = tensor([[-1.2017, -2.1313],
        [-1.1593, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008978386409580708
Epoch 0, Step 595: train/loss = 0.5200623273849487, train/raw-loss = 0.5097553730010986, train/logprobs = tensor([[-1.5909, -2.4202],
        [-1.4216, -1.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034356482326984406
Epoch 0, Step 596: train/loss = 0.5005062818527222, train/raw-loss = 0.48784399032592773, train/logprobs = tensor([[-1.1062, -2.2026],
        [-1.1636, -1.2159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04220766946673393
Epoch 0, Step 597: train/loss = 0.3512380123138428, train/raw-loss = 0.327423632144928, train/logprobs = tensor([[-1.0665, -3.4686],
        [-1.1140, -1.3727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793812945485115
Epoch 0, Step 598: train/loss = 0.41569486260414124, train/raw-loss = 0.3905267119407654, train/logprobs = tensor([[-1.0478, -2.9457],
        [-1.1606, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08389391750097275
Epoch 0, Step 599: train/loss = 0.3236653208732605, train/raw-loss = 0.2969276010990143, train/logprobs = tensor([[-1.5944, -3.8572],
        [-1.5415, -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08912571519613266
Epoch 0, Step 600: train/loss = 0.5727197527885437, train/raw-loss = 0.5667216777801514, train/logprobs = tensor([[-1.4835, -1.9050],
        [-1.4685, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019993672147393227
Epoch 0, Step 601: train/loss = 0.4086644649505615, train/raw-loss = 0.38708463311195374, train/logprobs = tensor([[-1.2848, -2.9343],
        [-1.3577, -1.3886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07193285971879959
Epoch 0, Step 602: train/loss = 0.4819040894508362, train/raw-loss = 0.4704071879386902, train/logprobs = tensor([[-1.6146, -2.4186],
        [-1.3175, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03832302987575531
Epoch 0, Step 603: train/loss = 0.43331727385520935, train/raw-loss = 0.41842687129974365, train/logprobs = tensor([[-1.0046, -3.0397],
        [-1.1250, -1.5647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049634743481874466
Epoch 0, Step 604: train/loss = 0.32329174876213074, train/raw-loss = 0.28236591815948486, train/logprobs = tensor([[-1.3361, -4.1746],
        [-1.3592, -1.7156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13641946017742157
Epoch 0, Step 605: train/loss = 0.4426557719707489, train/raw-loss = 0.4258965253829956, train/logprobs = tensor([[-1.3362, -2.9467],
        [-1.3698, -1.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055864110589027405
Epoch 0, Step 606: train/loss = 0.4862174987792969, train/raw-loss = 0.4723855257034302, train/logprobs = tensor([[-1.6179, -2.5870],
        [-1.8031, -1.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046106547117233276
Epoch 0, Step 607: train/loss = 0.42245033383369446, train/raw-loss = 0.3971654772758484, train/logprobs = tensor([[-1.8328, -3.1011],
        [-1.7148, -1.4172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08428294956684113
Epoch 0, Step 608: train/loss = 0.3834349513053894, train/raw-loss = 0.3637526333332062, train/logprobs = tensor([[-1.2641, -3.8284],
        [-1.3524, -1.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06560772657394409
Epoch 0, Step 609: train/loss = 0.3831830620765686, train/raw-loss = 0.3537011444568634, train/logprobs = tensor([[-1.8189, -3.2693],
        [-1.7985, -1.4100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09827304631471634
Epoch 0, Step 610: train/loss = 0.4805629849433899, train/raw-loss = 0.46886682510375977, train/logprobs = tensor([[-1.3204, -3.3594],
        [-1.1255, -1.7245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038987234234809875
Epoch 0, Step 611: train/loss = 0.5830872654914856, train/raw-loss = 0.573745846748352, train/logprobs = tensor([[-1.5465, -1.9697],
        [-1.3758, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031138135120272636
Epoch 0, Step 612: train/loss = 0.47279155254364014, train/raw-loss = 0.46144282817840576, train/logprobs = tensor([[-1.8224, -3.0955],
        [-1.3597, -1.4642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037829168140888214
Epoch 0, Step 613: train/loss = 0.3912898898124695, train/raw-loss = 0.37691211700439453, train/logprobs = tensor([[-1.2751, -4.0137],
        [-0.9791, -1.9951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04792589694261551
Epoch 0, Step 614: train/loss = 0.44863957166671753, train/raw-loss = 0.4396141767501831, train/logprobs = tensor([[-1.5234, -3.9819],
        [-1.2751, -2.3045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03008463978767395
Epoch 0, Step 615: train/loss = 0.40376928448677063, train/raw-loss = 0.3779875338077545, train/logprobs = tensor([[-0.7785, -2.8665],
        [-0.9309, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08593912422657013
Epoch 0, Step 616: train/loss = 0.4246152341365814, train/raw-loss = 0.41096532344818115, train/logprobs = tensor([[-2.6135, -4.8226],
        [-1.8422, -2.4884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04549972712993622
Epoch 0, Step 617: train/loss = 0.48677271604537964, train/raw-loss = 0.4733412563800812, train/logprobs = tensor([[-1.3022, -2.4424],
        [-1.2731, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0447714664041996
Epoch 0, Step 618: train/loss = 0.3759303689002991, train/raw-loss = 0.35454049706459045, train/logprobs = tensor([[-1.2215, -3.0044],
        [-1.2130, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07129963487386703
Epoch 0, Step 619: train/loss = 0.612358570098877, train/raw-loss = 0.5938608646392822, train/logprobs = tensor([[-3.0425, -3.8791],
        [-1.3715, -1.2244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0616588331758976
Epoch 0, Step 620: train/loss = 0.45985499024391174, train/raw-loss = 0.4401903450489044, train/logprobs = tensor([[-1.2270, -2.8084],
        [-1.2949, -1.4227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06554881483316422
Epoch 0, Step 621: train/loss = 0.4042648375034332, train/raw-loss = 0.37630438804626465, train/logprobs = tensor([[-2.1349, -3.6061],
        [-1.7000, -1.2503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09320148080587387
Epoch 0, Step 622: train/loss = 0.42517709732055664, train/raw-loss = 0.4182940423488617, train/logprobs = tensor([[-1.2069, -3.4924],
        [-1.1552, -1.9624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022943411022424698
Epoch 0, Step 623: train/loss = 0.41336795687675476, train/raw-loss = 0.3785511255264282, train/logprobs = tensor([[-3.0636, -5.0392],
        [-2.3833, -2.1623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1160561591386795
Epoch 0, Step 624: train/loss = 0.5325770378112793, train/raw-loss = 0.5174546241760254, train/logprobs = tensor([[-1.7352, -2.2180],
        [-1.5249, -1.0437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05040817707777023
Epoch 0, Step 625: train/loss = 0.4841753840446472, train/raw-loss = 0.44545918703079224, train/logprobs = tensor([[-1.5306, -2.6758],
        [-1.7576, -1.3300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12905392050743103
Epoch 0, Step 626: train/loss = 0.4614604711532593, train/raw-loss = 0.4504375755786896, train/logprobs = tensor([[-1.7760, -3.2663],
        [-1.5237, -1.7583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036742933094501495
Epoch 0, Step 627: train/loss = 0.4152969717979431, train/raw-loss = 0.3964333236217499, train/logprobs = tensor([[-1.0654, -2.9389],
        [-1.1213, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06287890672683716
Epoch 0, Step 628: train/loss = 0.3449828624725342, train/raw-loss = 0.32242316007614136, train/logprobs = tensor([[-1.3752, -4.0102],
        [-1.1544, -1.6045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07519887387752533
Epoch 0, Step 629: train/loss = 0.44314348697662354, train/raw-loss = 0.4208701252937317, train/logprobs = tensor([[-1.6489, -2.9606],
        [-1.4265, -1.1747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07424460351467133
Epoch 0, Step 630: train/loss = 0.283771276473999, train/raw-loss = 0.24774238467216492, train/logprobs = tensor([[-0.8988, -3.9714],
        [-1.1164, -1.3528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12009626626968384
Epoch 0, Step 631: train/loss = 0.5730555057525635, train/raw-loss = 0.5690603852272034, train/logprobs = tensor([[-1.0566, -1.5031],
        [-1.0602, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013316851109266281
Epoch 0, Step 632: train/loss = 0.4256557822227478, train/raw-loss = 0.40644460916519165, train/logprobs = tensor([[-1.1961, -2.8998],
        [-1.2944, -1.4158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06403719633817673
Epoch 0, Step 633: train/loss = 0.29805052280426025, train/raw-loss = 0.26820120215415955, train/logprobs = tensor([[-0.9884, -3.8163],
        [-1.2549, -1.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0994977056980133
Epoch 0, Step 634: train/loss = 0.3885558247566223, train/raw-loss = 0.3665061295032501, train/logprobs = tensor([[-1.7733, -3.5816],
        [-1.7211, -1.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07349900156259537
Epoch 0, Step 635: train/loss = 0.4837323725223541, train/raw-loss = 0.46166712045669556, train/logprobs = tensor([[-1.5594, -2.6046],
        [-1.5787, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07355097681283951
Epoch 0, Step 636: train/loss = 0.5311583280563354, train/raw-loss = 0.5105797648429871, train/logprobs = tensor([[-2.1999, -2.9492],
        [-1.6887, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06859519332647324
Epoch 0, Step 637: train/loss = 0.5182258486747742, train/raw-loss = 0.4910735487937927, train/logprobs = tensor([[-1.5507, -2.3680],
        [-1.6725, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09050757437944412
Epoch 0, Step 638: train/loss = 0.5067830085754395, train/raw-loss = 0.4900408089160919, train/logprobs = tensor([[-1.2816, -2.2358],
        [-1.3596, -1.1459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055807340890169144
Epoch 0, Step 639: train/loss = 0.5636034607887268, train/raw-loss = 0.555208683013916, train/logprobs = tensor([[-1.7391, -2.2019],
        [-1.2827, -1.0743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027982592582702637
Epoch 0, Step 640: train/loss = 0.36533740162849426, train/raw-loss = 0.32817888259887695, train/logprobs = tensor([[-0.9697, -3.4213],
        [-1.0521, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12386168539524078
Epoch 0, Step 641: train/loss = 0.49627983570098877, train/raw-loss = 0.47897762060165405, train/logprobs = tensor([[-1.1227, -2.4941],
        [-1.4622, -1.4175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057673968374729156
Epoch 0, Step 642: train/loss = 0.5613073110580444, train/raw-loss = 0.5528275966644287, train/logprobs = tensor([[-0.9843, -1.8862],
        [-1.1036, -1.2340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02826581709086895
Epoch 0, Step 643: train/loss = 0.5410901308059692, train/raw-loss = 0.5314628481864929, train/logprobs = tensor([[-1.0310, -2.4527],
        [-1.2011, -1.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03209085017442703
Epoch 0, Step 644: train/loss = 0.4191770553588867, train/raw-loss = 0.3916436433792114, train/logprobs = tensor([[-1.6919, -3.6346],
        [-1.9021, -1.9883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177803248167038
Epoch 0, Step 645: train/loss = 0.5357155799865723, train/raw-loss = 0.529119610786438, train/logprobs = tensor([[-1.3566, -2.0520],
        [-1.0677, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021986428648233414
Epoch 0, Step 646: train/loss = 0.36037158966064453, train/raw-loss = 0.3415612578392029, train/logprobs = tensor([[-1.5308, -3.7093],
        [-1.5430, -1.7655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06270118057727814
Epoch 0, Step 647: train/loss = 0.5078911781311035, train/raw-loss = 0.48144710063934326, train/logprobs = tensor([[-1.9620, -2.9169],
        [-1.7001, -1.3844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08814694732427597
Epoch 0, Step 648: train/loss = 0.2798556685447693, train/raw-loss = 0.24331051111221313, train/logprobs = tensor([[-1.1286, -4.0051],
        [-1.0862, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12181717902421951
Epoch 0, Step 649: train/loss = 0.5510463118553162, train/raw-loss = 0.5412367582321167, train/logprobs = tensor([[-0.9687, -2.1286],
        [-1.2288, -1.3526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03269847482442856
Epoch 0, Step 650: train/loss = 0.5997936725616455, train/raw-loss = 0.5895443558692932, train/logprobs = tensor([[-1.9611, -2.9315],
        [-1.5539, -1.8647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034164316952228546
Epoch 0, Step 651: train/loss = 0.44225749373435974, train/raw-loss = 0.41409939527511597, train/logprobs = tensor([[-1.9068, -2.4590],
        [-1.9021, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09386031329631805
Epoch 0, Step 652: train/loss = 0.3882709741592407, train/raw-loss = 0.3646376132965088, train/logprobs = tensor([[-1.1734, -3.3776],
        [-1.1793, -1.3151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07877781987190247
Epoch 0, Step 653: train/loss = 0.49714261293411255, train/raw-loss = 0.48511525988578796, train/logprobs = tensor([[-0.9712, -1.9230],
        [-0.9948, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04009120911359787
Epoch 0, Step 654: train/loss = 0.4805193543434143, train/raw-loss = 0.46402937173843384, train/logprobs = tensor([[-1.4095, -2.1498],
        [-1.6010, -1.1753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05496653914451599
Epoch 0, Step 655: train/loss = 0.3871512711048126, train/raw-loss = 0.37092649936676025, train/logprobs = tensor([[-1.4117, -3.3327],
        [-1.5155, -1.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05408260226249695
Epoch 0, Step 656: train/loss = 0.4596094489097595, train/raw-loss = 0.4497532844543457, train/logprobs = tensor([[-0.8996, -2.5496],
        [-1.1932, -1.5677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03285392373800278
Epoch 0, Step 657: train/loss = 0.5167475938796997, train/raw-loss = 0.4995479881763458, train/logprobs = tensor([[-1.2104, -1.9685],
        [-1.4254, -1.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057332128286361694
Epoch 0, Step 658: train/loss = 0.512553334236145, train/raw-loss = 0.49477308988571167, train/logprobs = tensor([[-1.1692, -1.7521],
        [-1.4221, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059267379343509674
Epoch 0, Step 659: train/loss = 0.2879777252674103, train/raw-loss = 0.25223350524902344, train/logprobs = tensor([[-1.2639, -5.0545],
        [-1.4124, -1.9092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1191474124789238
Epoch 0, Step 660: train/loss = 0.4745485782623291, train/raw-loss = 0.46507394313812256, train/logprobs = tensor([[-1.6208, -3.6372],
        [-1.1568, -1.6563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03158200904726982
Epoch 0, Step 661: train/loss = 0.3398192226886749, train/raw-loss = 0.3134135603904724, train/logprobs = tensor([[-1.6751, -3.7189],
        [-2.0674, -1.9139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08801890909671783
Epoch 0, Step 662: train/loss = 0.4209619164466858, train/raw-loss = 0.39793530106544495, train/logprobs = tensor([[-1.1241, -2.8007],
        [-1.3681, -1.4099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675535976886749
Epoch 0, Step 663: train/loss = 0.420809805393219, train/raw-loss = 0.3868562877178192, train/logprobs = tensor([[-1.5087, -2.8894],
        [-1.3483, -0.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11317843198776245
Epoch 0, Step 664: train/loss = 0.4459848403930664, train/raw-loss = 0.43105584383010864, train/logprobs = tensor([[-1.9380, -4.2311],
        [-1.8614, -2.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049763381481170654
Epoch 0, Step 665: train/loss = 0.34227970242500305, train/raw-loss = 0.32569316029548645, train/logprobs = tensor([[-1.3887, -3.5616],
        [-1.4539, -1.6591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055288467556238174
Epoch 0, Step 666: train/loss = 0.3810579180717468, train/raw-loss = 0.35400304198265076, train/logprobs = tensor([[-1.7141, -3.0428],
        [-1.7520, -1.2712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09018285572528839
Epoch 0, Step 667: train/loss = 0.5290291905403137, train/raw-loss = 0.5138307809829712, train/logprobs = tensor([[-1.2201, -1.6936],
        [-1.4135, -0.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050661347806453705
Epoch 0, Step 668: train/loss = 0.38258421421051025, train/raw-loss = 0.35511747002601624, train/logprobs = tensor([[-1.4513, -3.2401],
        [-1.5268, -1.3369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09155578911304474
Epoch 0, Step 669: train/loss = 0.30961155891418457, train/raw-loss = 0.28367823362350464, train/logprobs = tensor([[-1.2193, -4.4714],
        [-1.2776, -1.8907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08644434809684753
Epoch 0, Step 670: train/loss = 0.6309190988540649, train/raw-loss = 0.6276159882545471, train/logprobs = tensor([[-1.9907, -2.1082],
        [-1.4758, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01101034227758646
Epoch 0, Step 671: train/loss = 0.5909911394119263, train/raw-loss = 0.5841306447982788, train/logprobs = tensor([[-1.3090, -2.1516],
        [-1.0026, -1.1733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022868337109684944
Epoch 0, Step 672: train/loss = 0.3659535348415375, train/raw-loss = 0.3301433324813843, train/logprobs = tensor([[-1.9819, -3.7827],
        [-1.6018, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11936742067337036
Epoch 0, Step 673: train/loss = 0.3639300763607025, train/raw-loss = 0.33891284465789795, train/logprobs = tensor([[-1.6164, -3.5822],
        [-1.4199, -1.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08339095115661621
Epoch 0, Step 674: train/loss = 0.32175111770629883, train/raw-loss = 0.2646477222442627, train/logprobs = tensor([[-1.4941, -4.3816],
        [-1.7010, -1.5734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19034475088119507
Epoch 0, Step 675: train/loss = 0.36619988083839417, train/raw-loss = 0.3490622043609619, train/logprobs = tensor([[-0.9959, -3.2022],
        [-1.3008, -1.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05712554603815079
Epoch 0, Step 676: train/loss = 0.4339199364185333, train/raw-loss = 0.41351062059402466, train/logprobs = tensor([[-1.6184, -2.9759],
        [-1.5246, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06803098320960999
Epoch 0, Step 677: train/loss = 0.3701092004776001, train/raw-loss = 0.3450410068035126, train/logprobs = tensor([[-1.5392, -3.5722],
        [-1.5989, -1.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08356070518493652
Epoch 0, Step 678: train/loss = 0.28787288069725037, train/raw-loss = 0.24775132536888123, train/logprobs = tensor([[-1.4991, -4.4807],
        [-1.6986, -1.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13373853266239166
Epoch 0, Step 679: train/loss = 0.5596705079078674, train/raw-loss = 0.5441535711288452, train/logprobs = tensor([[-1.5287, -1.8354],
        [-1.5204, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0517231747508049
Epoch 0, Step 680: train/loss = 0.48249301314353943, train/raw-loss = 0.4493088126182556, train/logprobs = tensor([[-2.0546, -3.2262],
        [-1.9277, -1.4991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11061394959688187
Epoch 0, Step 681: train/loss = 0.43225154280662537, train/raw-loss = 0.41473981738090515, train/logprobs = tensor([[-1.0208, -3.0973],
        [-1.2341, -1.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05837229639291763
Epoch 0, Step 682: train/loss = 0.30713483691215515, train/raw-loss = 0.26655805110931396, train/logprobs = tensor([[-1.6036, -4.2685],
        [-1.9053, -1.7375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13525588810443878
Epoch 0, Step 683: train/loss = 0.49923890829086304, train/raw-loss = 0.47238028049468994, train/logprobs = tensor([[-2.3056, -3.1379],
        [-1.7101, -1.2228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08952859789133072
Epoch 0, Step 684: train/loss = 0.4206262230873108, train/raw-loss = 0.3998485505580902, train/logprobs = tensor([[-1.1193, -2.6546],
        [-1.3283, -1.2235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06925898045301437
Epoch 0, Step 685: train/loss = 0.3584563732147217, train/raw-loss = 0.3306199312210083, train/logprobs = tensor([[-1.3685, -3.7402],
        [-1.5686, -1.8056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09278814494609833
Epoch 0, Step 686: train/loss = 0.3799808621406555, train/raw-loss = 0.34388697147369385, train/logprobs = tensor([[-0.9097, -3.2511],
        [-1.2066, -1.2264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12031316012144089
Epoch 0, Step 687: train/loss = 0.4007285535335541, train/raw-loss = 0.364229291677475, train/logprobs = tensor([[-1.7240, -3.2566],
        [-1.8932, -1.4472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12166420370340347
Epoch 0, Step 688: train/loss = 0.35170674324035645, train/raw-loss = 0.33450305461883545, train/logprobs = tensor([[-1.6606, -4.3603],
        [-1.5657, -1.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05734553933143616
Epoch 0, Step 689: train/loss = 0.3931122422218323, train/raw-loss = 0.3660738468170166, train/logprobs = tensor([[-0.8095, -3.0126],
        [-1.0788, -1.1797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09012796729803085
Epoch 0, Step 690: train/loss = 0.40189945697784424, train/raw-loss = 0.3788800835609436, train/logprobs = tensor([[-1.6010, -3.5013],
        [-1.4549, -1.4455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0767313688993454
Epoch 0, Step 691: train/loss = 0.29369282722473145, train/raw-loss = 0.2575242519378662, train/logprobs = tensor([[-0.9621, -3.8579],
        [-1.2436, -1.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12056189775466919
Epoch 0, Step 692: train/loss = 0.37504684925079346, train/raw-loss = 0.34623003005981445, train/logprobs = tensor([[-1.3109, -3.1390],
        [-1.5192, -1.4396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605596214532852
Epoch 0, Step 693: train/loss = 0.4242629408836365, train/raw-loss = 0.381695419549942, train/logprobs = tensor([[-1.6838, -3.5085],
        [-1.8039, -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14189176261425018
Epoch 0, Step 694: train/loss = 0.33217769861221313, train/raw-loss = 0.2939438819885254, train/logprobs = tensor([[-1.4966, -3.6968],
        [-1.6299, -1.3566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12744595110416412
Epoch 0, Step 695: train/loss = 0.3586844205856323, train/raw-loss = 0.326555460691452, train/logprobs = tensor([[-1.3843, -3.3349],
        [-1.5006, -1.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10709652304649353
Epoch 0, Step 696: train/loss = 0.26524612307548523, train/raw-loss = 0.22922907769680023, train/logprobs = tensor([[-1.1288, -4.0808],
        [-1.3314, -1.4848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12005683034658432
Epoch 0, Step 697: train/loss = 0.37897545099258423, train/raw-loss = 0.3402969241142273, train/logprobs = tensor([[-1.3507, -3.4868],
        [-1.7013, -1.6700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12892840802669525
Epoch 0, Step 698: train/loss = 0.35789066553115845, train/raw-loss = 0.3203169107437134, train/logprobs = tensor([[-1.8747, -4.7804],
        [-1.4610, -1.5277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12524574995040894
Epoch 0, Step 699: train/loss = 0.44082653522491455, train/raw-loss = 0.41200876235961914, train/logprobs = tensor([[-1.3867, -3.0026],
        [-1.4318, -1.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09605925530195236
Epoch 0, Step 700: train/loss = 0.33738386631011963, train/raw-loss = 0.31201601028442383, train/logprobs = tensor([[-0.7460, -3.4379],
        [-1.0562, -1.2801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08455944806337357
Epoch 0, Step 701: train/loss = 0.4339381158351898, train/raw-loss = 0.404834121465683, train/logprobs = tensor([[-1.2495, -2.7895],
        [-1.7448, -1.5095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09701330959796906
Epoch 0, Step 702: train/loss = 0.3627750277519226, train/raw-loss = 0.3398905098438263, train/logprobs = tensor([[-2.1423, -3.4695],
        [-2.1492, -1.4606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07628177851438522
Epoch 0, Step 703: train/loss = 0.27138978242874146, train/raw-loss = 0.24467885494232178, train/logprobs = tensor([[-1.8783, -4.6854],
        [-1.7875, -1.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08903642743825912
Epoch 0, Step 704: train/loss = 0.3600589632987976, train/raw-loss = 0.34134185314178467, train/logprobs = tensor([[-1.0666, -3.9713],
        [-1.3776, -2.3271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06239033490419388
Epoch 0, Step 705: train/loss = 0.4438857436180115, train/raw-loss = 0.42969655990600586, train/logprobs = tensor([[-1.6093, -3.2740],
        [-1.6499, -1.9392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047297146171331406
Epoch 0, Step 706: train/loss = 0.34988081455230713, train/raw-loss = 0.3264137804508209, train/logprobs = tensor([[-1.2832, -4.2446],
        [-1.0782, -1.5715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07822341471910477
Epoch 0, Step 707: train/loss = 0.5409443974494934, train/raw-loss = 0.5305083990097046, train/logprobs = tensor([[-1.6793, -2.5113],
        [-1.2467, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03478670120239258
Epoch 0, Step 708: train/loss = 0.5313125848770142, train/raw-loss = 0.5222384929656982, train/logprobs = tensor([[-1.2766, -2.1290],
        [-1.4811, -1.4956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030246999114751816
Epoch 0, Step 709: train/loss = 0.45560455322265625, train/raw-loss = 0.4406675100326538, train/logprobs = tensor([[-0.8532, -2.3455],
        [-1.2597, -1.4394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049790091812610626
Epoch 0, Step 710: train/loss = 0.3555678725242615, train/raw-loss = 0.3313550055027008, train/logprobs = tensor([[-0.8445, -3.9023],
        [-0.7584, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08070948719978333
Epoch 0, Step 711: train/loss = 0.41588085889816284, train/raw-loss = 0.39380091428756714, train/logprobs = tensor([[-2.0701, -3.3734],
        [-2.1560, -1.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07359982281923294
Epoch 0, Step 712: train/loss = 0.2994137406349182, train/raw-loss = 0.2660219073295593, train/logprobs = tensor([[-0.8640, -3.8171],
        [-1.0361, -1.4520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1113060861825943
Epoch 0, Step 713: train/loss = 0.2956399619579315, train/raw-loss = 0.25835973024368286, train/logprobs = tensor([[-1.0227, -3.6776],
        [-1.2445, -1.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12426739931106567
Epoch 0, Step 714: train/loss = 0.5348175764083862, train/raw-loss = 0.517135500907898, train/logprobs = tensor([[-1.0325, -1.6316],
        [-1.3714, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058940090239048004
Epoch 0, Step 715: train/loss = 0.5450815558433533, train/raw-loss = 0.5317245721817017, train/logprobs = tensor([[-1.4167, -1.6842],
        [-1.7540, -1.1517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04452329874038696
Epoch 0, Step 716: train/loss = 0.3561698794364929, train/raw-loss = 0.30740123987197876, train/logprobs = tensor([[-1.6876, -3.7330],
        [-1.8289, -1.3131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16256210207939148
Epoch 0, Step 717: train/loss = 0.3179129660129547, train/raw-loss = 0.2704167366027832, train/logprobs = tensor([[-1.5701, -3.5553],
        [-1.7347, -1.2031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15832069516181946
Epoch 0, Step 718: train/loss = 0.4298258423805237, train/raw-loss = 0.3701469600200653, train/logprobs = tensor([[-2.4935, -5.2132],
        [-1.4244, -1.6357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19892972707748413
Epoch 0, Step 719: train/loss = 0.6374016404151917, train/raw-loss = 0.6330118775367737, train/logprobs = tensor([[-1.3423, -1.4474],
        [-1.3849, -1.1597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014632574282586575
Epoch 0, Step 720: train/loss = 0.47132256627082825, train/raw-loss = 0.45176517963409424, train/logprobs = tensor([[-0.9888, -2.6459],
        [-1.3011, -1.4281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06519125401973724
Epoch 0, Step 721: train/loss = 0.46373701095581055, train/raw-loss = 0.4427168369293213, train/logprobs = tensor([[-1.5391, -3.0490],
        [-1.4234, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07006721943616867
Epoch 0, Step 722: train/loss = 0.3903128504753113, train/raw-loss = 0.34387004375457764, train/logprobs = tensor([[-1.1018, -3.4744],
        [-1.3235, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15480932593345642
Epoch 0, Step 723: train/loss = 0.4058475196361542, train/raw-loss = 0.38857609033584595, train/logprobs = tensor([[-1.9652, -4.3418],
        [-1.3138, -1.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057571373879909515
Epoch 0, Step 724: train/loss = 0.4600119888782501, train/raw-loss = 0.43964752554893494, train/logprobs = tensor([[-0.9593, -2.8109],
        [-1.2921, -1.5778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06788139045238495
Epoch 0, Step 725: train/loss = 0.43148666620254517, train/raw-loss = 0.40201759338378906, train/logprobs = tensor([[-1.5727, -2.5992],
        [-1.7874, -1.2022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09823031723499298
Epoch 0, Step 726: train/loss = 0.4883996248245239, train/raw-loss = 0.4615178108215332, train/logprobs = tensor([[-1.3604, -2.2800],
        [-1.5570, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08960598707199097
Epoch 0, Step 727: train/loss = 0.491738498210907, train/raw-loss = 0.47319838404655457, train/logprobs = tensor([[-0.8391, -2.1309],
        [-1.2469, -1.2620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06180041283369064
Epoch 0, Step 728: train/loss = 0.4598080515861511, train/raw-loss = 0.43312782049179077, train/logprobs = tensor([[-1.5681, -2.7062],
        [-1.9238, -1.5884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08893424272537231
Epoch 0, Step 729: train/loss = 0.26086539030075073, train/raw-loss = 0.22186800837516785, train/logprobs = tensor([[-1.0876, -4.2143],
        [-1.3764, -1.5862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12999123334884644
Epoch 0, Step 730: train/loss = 0.5480139255523682, train/raw-loss = 0.5324334502220154, train/logprobs = tensor([[-1.8968, -2.2766],
        [-2.1293, -1.6057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05193493887782097
Epoch 0, Step 731: train/loss = 0.5112934112548828, train/raw-loss = 0.49315011501312256, train/logprobs = tensor([[-2.6956, -2.7369],
        [-2.1843, -1.1417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06047789007425308
Epoch 0, Step 732: train/loss = 0.46607697010040283, train/raw-loss = 0.44402945041656494, train/logprobs = tensor([[-2.2448, -3.0426],
        [-2.3421, -1.5606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07349171489477158
Epoch 0, Step 733: train/loss = 0.34756892919540405, train/raw-loss = 0.32773923873901367, train/logprobs = tensor([[-1.1569, -3.3859],
        [-1.5669, -1.7741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06609879434108734
Epoch 0, Step 734: train/loss = 0.5312227010726929, train/raw-loss = 0.5189657807350159, train/logprobs = tensor([[-1.7794, -2.2166],
        [-1.4090, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040856264531612396
Epoch 0, Step 735: train/loss = 0.7067379951477051, train/raw-loss = 0.700298011302948, train/logprobs = tensor([[-2.2800, -1.9151],
        [-1.5785, -1.1442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021466605365276337
Epoch 0, Step 736: train/loss = 0.293813019990921, train/raw-loss = 0.23606091737747192, train/logprobs = tensor([[-1.5940, -4.3053],
        [-2.0477, -1.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19250701367855072
Epoch 0, Step 737: train/loss = 0.571591317653656, train/raw-loss = 0.5416378378868103, train/logprobs = tensor([[-2.0589, -2.6114],
        [-1.8356, -1.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09984508901834488
Epoch 0, Step 738: train/loss = 0.24040935933589935, train/raw-loss = 0.19433163106441498, train/logprobs = tensor([[-1.4335, -4.8183],
        [-1.8958, -2.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15359240770339966
Epoch 0, Step 739: train/loss = 0.24014770984649658, train/raw-loss = 0.15914146602153778, train/logprobs = tensor([[-1.7141, -4.8969],
        [-1.6416, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2700207829475403
Epoch 0, Step 740: train/loss = 0.39296358823776245, train/raw-loss = 0.36821961402893066, train/logprobs = tensor([[-0.8288, -3.2638],
        [-1.3669, -1.6087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08247991651296616
Epoch 0, Step 741: train/loss = 0.383464515209198, train/raw-loss = 0.3530314266681671, train/logprobs = tensor([[-1.8384, -4.0687],
        [-1.5852, -1.3616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10144363343715668
Epoch 0, Step 742: train/loss = 0.423337459564209, train/raw-loss = 0.3947194218635559, train/logprobs = tensor([[-0.8520, -2.8702],
        [-1.1395, -1.1484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09539346396923065
Epoch 0, Step 743: train/loss = 0.43342575430870056, train/raw-loss = 0.4157601594924927, train/logprobs = tensor([[-1.2528, -3.2055],
        [-1.2110, -1.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05888526886701584
Epoch 0, Step 744: train/loss = 0.42942914366722107, train/raw-loss = 0.4142974615097046, train/logprobs = tensor([[-1.4551, -3.4241],
        [-1.6864, -2.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050438977777957916
Epoch 0, Step 745: train/loss = 0.32222607731819153, train/raw-loss = 0.292827844619751, train/logprobs = tensor([[-1.2609, -4.1235],
        [-1.6673, -1.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09799409657716751
Epoch 0, Step 746: train/loss = 0.4096015691757202, train/raw-loss = 0.3886714577674866, train/logprobs = tensor([[-0.7332, -3.7931],
        [-1.0615, -1.9173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06976709514856339
Epoch 0, Step 747: train/loss = 0.659017026424408, train/raw-loss = 0.6478939652442932, train/logprobs = tensor([[-1.7690, -1.8508],
        [-1.6793, -1.4240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037076957523822784
Epoch 0, Step 748: train/loss = 0.4914643466472626, train/raw-loss = 0.4773353636264801, train/logprobs = tensor([[-1.7390, -3.5045],
        [-1.8692, -2.3723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04709663614630699
Epoch 0, Step 749: train/loss = 0.4440203309059143, train/raw-loss = 0.42592620849609375, train/logprobs = tensor([[-2.3239, -3.1126],
        [-1.7880, -1.2551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06031373515725136
Epoch 0, Step 750: train/loss = 0.4129903316497803, train/raw-loss = 0.3888464868068695, train/logprobs = tensor([[-1.5298, -3.2337],
        [-1.4083, -1.4261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08047941327095032
Epoch 0, Step 751: train/loss = 0.39259734749794006, train/raw-loss = 0.3535779118537903, train/logprobs = tensor([[-1.2574, -3.0466],
        [-1.7814, -1.4339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13006481528282166
Epoch 0, Step 752: train/loss = 0.464487761259079, train/raw-loss = 0.4506508409976959, train/logprobs = tensor([[-0.7767, -2.2667],
        [-1.1847, -1.1863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04612314701080322
Epoch 0, Step 753: train/loss = 0.3586503863334656, train/raw-loss = 0.3313341438770294, train/logprobs = tensor([[-1.1150, -2.9221],
        [-1.5739, -1.4010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09105424582958221
Epoch 0, Step 754: train/loss = 0.3391028046607971, train/raw-loss = 0.320287823677063, train/logprobs = tensor([[-1.1490, -4.0108],
        [-1.3661, -1.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06271649897098541
Epoch 0, Step 755: train/loss = 0.3163926601409912, train/raw-loss = 0.2651844322681427, train/logprobs = tensor([[-1.8026, -4.4699],
        [-2.1634, -1.8662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17069405317306519
Epoch 0, Step 756: train/loss = 0.3101857006549835, train/raw-loss = 0.26766836643218994, train/logprobs = tensor([[-1.3362, -3.7977],
        [-1.8903, -1.6876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1417243927717209
Epoch 0, Step 757: train/loss = 0.34874606132507324, train/raw-loss = 0.32190006971359253, train/logprobs = tensor([[-1.6707, -4.3762],
        [-2.0859, -2.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08948659151792526
Epoch 0, Step 758: train/loss = 0.41969263553619385, train/raw-loss = 0.39179912209510803, train/logprobs = tensor([[-1.2470, -2.6535],
        [-1.2800, -1.0268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0929783284664154
Epoch 0, Step 759: train/loss = 0.35305505990982056, train/raw-loss = 0.3022835850715637, train/logprobs = tensor([[-2.0410, -3.7674],
        [-2.1491, -1.1854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16923828423023224
Epoch 0, Step 760: train/loss = 0.2759730815887451, train/raw-loss = 0.23013213276863098, train/logprobs = tensor([[-2.1515, -4.7017],
        [-2.1753, -1.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1528031826019287
Epoch 0, Step 761: train/loss = 0.5206348299980164, train/raw-loss = 0.5006371736526489, train/logprobs = tensor([[-1.7688, -2.5582],
        [-1.4855, -1.1526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06665881723165512
Epoch 0, Step 762: train/loss = 0.4526793956756592, train/raw-loss = 0.42366570234298706, train/logprobs = tensor([[-1.9104, -3.6319],
        [-1.6800, -1.7424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09671234339475632
Epoch 0, Step 763: train/loss = 0.6156291961669922, train/raw-loss = 0.6109656095504761, train/logprobs = tensor([[-1.2620, -1.4867],
        [-1.3344, -1.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015545282512903214
Epoch 0, Step 764: train/loss = 0.29578354954719543, train/raw-loss = 0.2482939511537552, train/logprobs = tensor([[-1.5009, -3.6965],
        [-1.8837, -1.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15829867124557495
Epoch 0, Step 765: train/loss = 0.3105837106704712, train/raw-loss = 0.24912896752357483, train/logprobs = tensor([[-1.2407, -4.2423],
        [-1.6950, -1.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20484909415245056
Epoch 0, Step 766: train/loss = 0.47096264362335205, train/raw-loss = 0.4577134847640991, train/logprobs = tensor([[-1.4401, -3.0453],
        [-1.8678, -2.1934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04416382312774658
Epoch 0, Step 767: train/loss = 0.48551061749458313, train/raw-loss = 0.4764457643032074, train/logprobs = tensor([[-1.5260, -2.9662],
        [-1.6810, -1.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03021625429391861
Epoch 0, Step 768: train/loss = 0.40316295623779297, train/raw-loss = 0.3626951575279236, train/logprobs = tensor([[-1.2538, -2.5014],
        [-1.9260, -1.1736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13489262759685516
Epoch 0, Step 769: train/loss = 0.4127051532268524, train/raw-loss = 0.3924787938594818, train/logprobs = tensor([[-1.2328, -3.0744],
        [-1.6034, -1.7606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06742122769355774
Epoch 0, Step 770: train/loss = 0.5209028124809265, train/raw-loss = 0.5028141140937805, train/logprobs = tensor([[-0.9527, -1.5287],
        [-1.3581, -0.9075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06029573455452919
Epoch 0, Step 771: train/loss = 0.3082481920719147, train/raw-loss = 0.26388078927993774, train/logprobs = tensor([[-1.4756, -3.6431],
        [-1.8835, -1.2899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14789137244224548
Epoch 0, Step 772: train/loss = 0.3928823471069336, train/raw-loss = 0.3558913469314575, train/logprobs = tensor([[-1.7605, -2.9321],
        [-1.7838, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1233033835887909
Epoch 0, Step 773: train/loss = 0.5761533975601196, train/raw-loss = 0.5646992921829224, train/logprobs = tensor([[-1.8582, -2.0606],
        [-1.6626, -1.1918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03818029537796974
Epoch 0, Step 774: train/loss = 0.4203229546546936, train/raw-loss = 0.38771748542785645, train/logprobs = tensor([[-1.9258, -3.5987],
        [-1.9883, -1.6376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10868490487337112
Epoch 0, Step 775: train/loss = 0.3229040503501892, train/raw-loss = 0.2995377779006958, train/logprobs = tensor([[-1.3315, -3.8287],
        [-1.7003, -1.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07788747549057007
Epoch 0, Step 776: train/loss = 0.3257375955581665, train/raw-loss = 0.2750716805458069, train/logprobs = tensor([[-1.6943, -4.4926],
        [-1.7632, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1688864678144455
Epoch 0, Step 777: train/loss = 0.40533870458602905, train/raw-loss = 0.3713715076446533, train/logprobs = tensor([[-1.6277, -3.8323],
        [-1.9243, -1.8428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11322391033172607
Epoch 0, Step 778: train/loss = 0.3897066116333008, train/raw-loss = 0.35275179147720337, train/logprobs = tensor([[-1.5204, -2.8214],
        [-1.8114, -1.1558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12318266183137894
Epoch 0, Step 779: train/loss = 0.39891576766967773, train/raw-loss = 0.35599052906036377, train/logprobs = tensor([[-2.2513, -3.5751],
        [-1.9624, -1.1726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14308421313762665
Epoch 0, Step 780: train/loss = 0.3880704939365387, train/raw-loss = 0.3618566691875458, train/logprobs = tensor([[-1.2159, -2.6587],
        [-1.4785, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08737938106060028
Epoch 0, Step 781: train/loss = 0.45942944288253784, train/raw-loss = 0.4309086203575134, train/logprobs = tensor([[-2.0214, -3.8399],
        [-1.7355, -1.4503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09506940841674805
Epoch 0, Step 782: train/loss = 0.33694207668304443, train/raw-loss = 0.2965186536312103, train/logprobs = tensor([[-1.1843, -4.3025],
        [-1.3968, -1.5819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1347448229789734
Epoch 0, Step 783: train/loss = 0.5553662180900574, train/raw-loss = 0.5410042405128479, train/logprobs = tensor([[-1.2446, -1.6658],
        [-1.4019, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047873422503471375
Epoch 0, Step 784: train/loss = 0.2640327513217926, train/raw-loss = 0.21541976928710938, train/logprobs = tensor([[-1.0808, -4.1059],
        [-1.6873, -1.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1620432734489441
Epoch 0, Step 785: train/loss = 0.2565137445926666, train/raw-loss = 0.1934967339038849, train/logprobs = tensor([[-1.4458, -4.6146],
        [-1.7099, -1.4781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21005669236183167
Epoch 0, Step 786: train/loss = 0.33466264605522156, train/raw-loss = 0.29604265093803406, train/logprobs = tensor([[-1.6214, -4.0612],
        [-2.0548, -2.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12873326241970062
Epoch 0, Step 787: train/loss = 0.3691581189632416, train/raw-loss = 0.34412455558776855, train/logprobs = tensor([[-0.9926, -3.8397],
        [-1.4682, -1.9527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0834452360868454
Epoch 0, Step 788: train/loss = 0.39025813341140747, train/raw-loss = 0.3769865334033966, train/logprobs = tensor([[-0.9323, -3.5279],
        [-1.0862, -1.5738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044238731265068054
Epoch 0, Step 789: train/loss = 0.5394150018692017, train/raw-loss = 0.5210765600204468, train/logprobs = tensor([[-1.7533, -2.2842],
        [-1.9202, -1.5104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061128005385398865
Epoch 0, Step 790: train/loss = 0.4369433522224426, train/raw-loss = 0.4159539043903351, train/logprobs = tensor([[-1.5634, -2.8652],
        [-1.4107, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06996481865644455
Epoch 0, Step 791: train/loss = 0.4974145293235779, train/raw-loss = 0.48589038848876953, train/logprobs = tensor([[-1.6825, -2.4509],
        [-1.4741, -1.1317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03841375187039375
Epoch 0, Step 792: train/loss = 0.3749493360519409, train/raw-loss = 0.34299230575561523, train/logprobs = tensor([[-2.0711, -3.3479],
        [-2.1519, -1.5646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10652343183755875
Epoch 0, Step 793: train/loss = 0.27529358863830566, train/raw-loss = 0.2283109873533249, train/logprobs = tensor([[-1.3804, -4.1730],
        [-1.8978, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1566087007522583
Epoch 0, Step 794: train/loss = 0.3782167136669159, train/raw-loss = 0.3503899872303009, train/logprobs = tensor([[-1.3538, -3.5776],
        [-1.3900, -1.5891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0927557572722435
Epoch 0, Step 795: train/loss = 0.44802555441856384, train/raw-loss = 0.4268472194671631, train/logprobs = tensor([[-1.2930, -2.8670],
        [-1.4238, -1.5375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07059445977210999
Epoch 0, Step 796: train/loss = 0.3909575343132019, train/raw-loss = 0.354636549949646, train/logprobs = tensor([[-1.1209, -2.7894],
        [-1.6374, -1.0844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12106991559267044
Epoch 0, Step 797: train/loss = 0.5192558765411377, train/raw-loss = 0.5013318061828613, train/logprobs = tensor([[-1.7477, -2.5946],
        [-1.8252, -1.5930]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059746891260147095
Epoch 0, Step 798: train/loss = 0.5018160343170166, train/raw-loss = 0.47677236795425415, train/logprobs = tensor([[-1.4684, -2.0866],
        [-1.6519, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08347899466753006
Epoch 0, Step 799: train/loss = 0.36698678135871887, train/raw-loss = 0.3379436135292053, train/logprobs = tensor([[-1.1634, -3.5771],
        [-1.2943, -1.4407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09681054949760437
Epoch 0, Step 800: train/loss = 0.5797029137611389, train/raw-loss = 0.5630201101303101, train/logprobs = tensor([[-1.6870, -1.7350],
        [-1.8428, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05560920760035515
Epoch 0, Step 801: train/loss = 0.23717932403087616, train/raw-loss = 0.19269323348999023, train/logprobs = tensor([[-1.0423, -4.4812],
        [-1.5027, -1.6924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14828693866729736
Epoch 0, Step 802: train/loss = 0.3426930904388428, train/raw-loss = 0.29859432578086853, train/logprobs = tensor([[-1.8787, -4.0343],
        [-2.2915, -1.7821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14699585735797882
Epoch 0, Step 803: train/loss = 0.5027780532836914, train/raw-loss = 0.48975643515586853, train/logprobs = tensor([[-0.8368, -2.1008],
        [-1.2291, -1.4496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04340551421046257
Epoch 0, Step 804: train/loss = 0.33274587988853455, train/raw-loss = 0.2970524728298187, train/logprobs = tensor([[-1.1811, -4.0049],
        [-1.6599, -1.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11897803843021393
Epoch 0, Step 805: train/loss = 0.39852339029312134, train/raw-loss = 0.36860328912734985, train/logprobs = tensor([[-2.2670, -4.2621],
        [-2.2220, -2.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09973374754190445
Epoch 0, Step 806: train/loss = 0.5040147304534912, train/raw-loss = 0.469661682844162, train/logprobs = tensor([[-1.6183, -3.7804],
        [-1.6742, -1.4858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11451022326946259
Epoch 0, Step 807: train/loss = 0.375528484582901, train/raw-loss = 0.3314815163612366, train/logprobs = tensor([[-1.9653, -3.9300],
        [-1.8977, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14682318270206451
Epoch 0, Step 808: train/loss = 0.3774532079696655, train/raw-loss = 0.3483673930168152, train/logprobs = tensor([[-1.7626, -3.5825],
        [-2.0265, -1.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09695271402597427
Epoch 0, Step 809: train/loss = 0.4737774133682251, train/raw-loss = 0.4568929970264435, train/logprobs = tensor([[-0.9617, -3.3132],
        [-1.2403, -1.5676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056281205266714096
Epoch 0, Step 810: train/loss = 0.3132452368736267, train/raw-loss = 0.2725275158882141, train/logprobs = tensor([[-0.9845, -4.3005],
        [-1.5787, -1.7186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13572585582733154
Epoch 0, Step 811: train/loss = 0.21375128626823425, train/raw-loss = 0.16675812005996704, train/logprobs = tensor([[-1.3893, -5.4580],
        [-1.8361, -2.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15664388239383698
Epoch 0, Step 812: train/loss = 0.43569183349609375, train/raw-loss = 0.40429720282554626, train/logprobs = tensor([[-2.0885, -4.9540],
        [-2.1516, -2.8419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10464876890182495
Epoch 0, Step 813: train/loss = 0.532939076423645, train/raw-loss = 0.5008291006088257, train/logprobs = tensor([[-1.8771, -4.3932],
        [-1.6300, -2.1994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10703305900096893
Epoch 0, Step 814: train/loss = 0.37750953435897827, train/raw-loss = 0.3453839421272278, train/logprobs = tensor([[-2.0948, -3.7895],
        [-1.8276, -1.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10708536207675934
Epoch 0, Step 815: train/loss = 0.35581937432289124, train/raw-loss = 0.324260413646698, train/logprobs = tensor([[-1.6783, -4.4314],
        [-1.4745, -1.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10519657284021378
Epoch 0, Step 816: train/loss = 0.4022623300552368, train/raw-loss = 0.3784788250923157, train/logprobs = tensor([[-1.4332, -3.1166],
        [-1.6584, -1.4806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07927831262350082
Epoch 0, Step 817: train/loss = 0.42316964268684387, train/raw-loss = 0.3258245587348938, train/logprobs = tensor([[-2.1085, -4.8422],
        [-2.1678, -1.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32448363304138184
Epoch 0, Step 818: train/loss = 0.3673359453678131, train/raw-loss = 0.3143612742424011, train/logprobs = tensor([[-1.2201, -3.7115],
        [-1.6961, -1.2515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1765822172164917
Epoch 0, Step 819: train/loss = 0.377901554107666, train/raw-loss = 0.32986798882484436, train/logprobs = tensor([[-2.0816, -4.0601],
        [-1.7537, -1.4167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16011179983615875
Epoch 0, Step 820: train/loss = 0.29543787240982056, train/raw-loss = 0.2563632130622864, train/logprobs = tensor([[-1.3420, -4.2605],
        [-1.6768, -1.7103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13024888932704926
Epoch 0, Step 821: train/loss = 0.31164976954460144, train/raw-loss = 0.27771884202957153, train/logprobs = tensor([[-1.7700, -4.0932],
        [-1.6922, -1.6176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11310312151908875
Epoch 0, Step 822: train/loss = 0.3288641571998596, train/raw-loss = 0.24200421571731567, train/logprobs = tensor([[-1.0634, -4.1683],
        [-1.6594, -1.2219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28953319787979126
Epoch 0, Step 823: train/loss = 0.5954276323318481, train/raw-loss = 0.5809158682823181, train/logprobs = tensor([[-1.8888, -2.0503],
        [-2.0830, -1.5894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048372723162174225
Epoch 0, Step 824: train/loss = 0.4009881913661957, train/raw-loss = 0.35352984070777893, train/logprobs = tensor([[-1.9099, -3.6760],
        [-1.4300, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15819452702999115
Epoch 0, Step 825: train/loss = 0.4521009922027588, train/raw-loss = 0.4297652244567871, train/logprobs = tensor([[-1.7780, -2.5865],
        [-1.6148, -1.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0744524598121643
Epoch 0, Step 826: train/loss = 0.32636332511901855, train/raw-loss = 0.2830735743045807, train/logprobs = tensor([[-1.7069, -3.6521],
        [-1.7115, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14429917931556702
Epoch 0, Step 827: train/loss = 0.38149067759513855, train/raw-loss = 0.3548576533794403, train/logprobs = tensor([[-1.8146, -3.6205],
        [-1.9462, -1.4712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08877682685852051
Epoch 0, Step 828: train/loss = 0.33283770084381104, train/raw-loss = 0.297288715839386, train/logprobs = tensor([[-1.4165, -3.6404],
        [-1.5065, -1.3559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11849665641784668
Epoch 0, Step 829: train/loss = 0.4999088943004608, train/raw-loss = 0.4808943271636963, train/logprobs = tensor([[-1.6308, -2.5192],
        [-1.8843, -1.5936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06338189542293549
Epoch 0, Step 830: train/loss = 0.42372483015060425, train/raw-loss = 0.3911399245262146, train/logprobs = tensor([[-1.2839, -3.4217],
        [-1.4450, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10861630737781525
Epoch 0, Step 831: train/loss = 0.38957828283309937, train/raw-loss = 0.35294514894485474, train/logprobs = tensor([[-2.0966, -3.6603],
        [-1.7895, -1.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12211035937070847
Epoch 0, Step 832: train/loss = 0.404850035905838, train/raw-loss = 0.3637407124042511, train/logprobs = tensor([[-2.6188, -4.3200],
        [-2.0637, -1.6551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13703104853630066
Epoch 0, Step 833: train/loss = 0.37417763471603394, train/raw-loss = 0.34334802627563477, train/logprobs = tensor([[-1.7448, -2.9041],
        [-2.2674, -1.5058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10276540368795395
Epoch 0, Step 834: train/loss = 0.3117382526397705, train/raw-loss = 0.27391308546066284, train/logprobs = tensor([[-0.9666, -4.3773],
        [-1.4658, -1.6768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12608382105827332
Epoch 0, Step 835: train/loss = 0.36270588636398315, train/raw-loss = 0.31972169876098633, train/logprobs = tensor([[-1.4921, -3.6041],
        [-1.6153, -1.3749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14328062534332275
Epoch 0, Step 836: train/loss = 0.4062640070915222, train/raw-loss = 0.3741401731967926, train/logprobs = tensor([[-1.7688, -3.2538],
        [-1.9536, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10707934200763702
Epoch 0, Step 837: train/loss = 0.3712971806526184, train/raw-loss = 0.33054542541503906, train/logprobs = tensor([[-1.0736, -3.6889],
        [-1.4183, -1.2271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13583919405937195
Epoch 0, Step 838: train/loss = 0.21597255766391754, train/raw-loss = 0.1665356159210205, train/logprobs = tensor([[-1.7696, -5.8741],
        [-2.0071, -2.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1647898256778717
Epoch 0, Step 839: train/loss = 0.649874210357666, train/raw-loss = 0.639451265335083, train/logprobs = tensor([[-2.0203, -2.3788],
        [-2.4965, -2.3082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03474299982190132
Epoch 0, Step 840: train/loss = 0.4578724503517151, train/raw-loss = 0.31752926111221313, train/logprobs = tensor([[-2.1686, -5.6734],
        [-2.4012, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.467810720205307
Epoch 0, Step 841: train/loss = 0.2271476686000824, train/raw-loss = 0.19433557987213135, train/logprobs = tensor([[-0.9722, -5.6933],
        [-1.4042, -2.1644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10937362909317017
Epoch 0, Step 842: train/loss = 0.37686529755592346, train/raw-loss = 0.35380369424819946, train/logprobs = tensor([[-1.9485, -3.9209],
        [-2.0281, -1.8831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07687212526798248
Epoch 0, Step 843: train/loss = 0.22817480564117432, train/raw-loss = 0.19332711398601532, train/logprobs = tensor([[-0.7196, -5.1444],
        [-1.4482, -2.2714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11615899205207825
Epoch 0, Step 844: train/loss = 0.24371860921382904, train/raw-loss = 0.17918002605438232, train/logprobs = tensor([[-1.4561, -4.2115],
        [-1.9921, -1.3925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2151285856962204
Epoch 0, Step 845: train/loss = 0.5046965479850769, train/raw-loss = 0.4606424570083618, train/logprobs = tensor([[-1.6280, -3.0025],
        [-2.2650, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14684678614139557
Epoch 0, Step 846: train/loss = 0.5785068273544312, train/raw-loss = 0.5400390625, train/logprobs = tensor([[-1.7853, -2.6699],
        [-1.4521, -1.1455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12822581827640533
Epoch 0, Step 847: train/loss = 0.2500368654727936, train/raw-loss = 0.18198910355567932, train/logprobs = tensor([[-1.3307, -4.3276],
        [-1.9971, -1.3952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22682592272758484
Epoch 0, Step 848: train/loss = 0.3675953149795532, train/raw-loss = 0.3366987705230713, train/logprobs = tensor([[-1.5707, -3.4903],
        [-1.5837, -1.3824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10298849642276764
Epoch 0, Step 849: train/loss = 0.5763195753097534, train/raw-loss = 0.5604086518287659, train/logprobs = tensor([[-1.6605, -2.3591],
        [-1.5235, -1.3706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0530363991856575
Epoch 0, Step 850: train/loss = 0.3397049903869629, train/raw-loss = 0.2964482307434082, train/logprobs = tensor([[-1.8983, -4.4548],
        [-2.2418, -1.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14418919384479523
Epoch 0, Step 851: train/loss = 0.532347559928894, train/raw-loss = 0.5030308365821838, train/logprobs = tensor([[-1.5540, -2.5380],
        [-1.3448, -1.0565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09772243350744247
Epoch 0, Step 852: train/loss = 0.3408128619194031, train/raw-loss = 0.25723329186439514, train/logprobs = tensor([[-1.7382, -4.1008],
        [-2.5363, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2785986065864563
Epoch 0, Step 853: train/loss = 0.5304162502288818, train/raw-loss = 0.5130414962768555, train/logprobs = tensor([[-1.2927, -1.9843],
        [-1.4630, -1.1213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05791593715548515
Epoch 0, Step 854: train/loss = 0.4330819547176361, train/raw-loss = 0.41148197650909424, train/logprobs = tensor([[-1.4864, -3.8898],
        [-1.5089, -2.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0719999372959137
Epoch 0, Step 855: train/loss = 0.5126030445098877, train/raw-loss = 0.4931163191795349, train/logprobs = tensor([[-2.1448, -3.0338],
        [-2.0714, -1.7899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0649556890130043
Epoch 0, Step 856: train/loss = 0.35558077692985535, train/raw-loss = 0.3282439708709717, train/logprobs = tensor([[-1.4084, -3.6455],
        [-1.7904, -1.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09112268686294556
Epoch 0, Step 857: train/loss = 0.22914853692054749, train/raw-loss = 0.16913390159606934, train/logprobs = tensor([[-1.5797, -5.3265],
        [-1.9790, -1.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2000487893819809
Epoch 0, Step 858: train/loss = 0.43938112258911133, train/raw-loss = 0.3922134041786194, train/logprobs = tensor([[-1.8303, -3.9431],
        [-1.7075, -1.5159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15722575783729553
Epoch 0, Step 859: train/loss = 0.4930189251899719, train/raw-loss = 0.45973849296569824, train/logprobs = tensor([[-1.8963, -5.0574],
        [-1.5719, -2.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11093483120203018
Epoch 0, Step 860: train/loss = 0.5070785284042358, train/raw-loss = 0.491909384727478, train/logprobs = tensor([[-1.1371, -1.5857],
        [-1.5751, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050563789904117584
Epoch 0, Step 861: train/loss = 0.34673207998275757, train/raw-loss = 0.2911458909511566, train/logprobs = tensor([[-1.2229, -4.0089],
        [-1.5577, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18528735637664795
Epoch 0, Step 862: train/loss = 0.4381195306777954, train/raw-loss = 0.4181984066963196, train/logprobs = tensor([[-1.4994, -2.9075],
        [-1.8704, -1.6128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06640376150608063
Epoch 0, Step 863: train/loss = 0.33470919728279114, train/raw-loss = 0.2963200807571411, train/logprobs = tensor([[-1.5285, -4.4489],
        [-1.5040, -1.7421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12796378135681152
Epoch 0, Step 864: train/loss = 0.39978012442588806, train/raw-loss = 0.3687170743942261, train/logprobs = tensor([[-1.6921, -2.9895],
        [-2.0954, -1.5189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1035434901714325
Epoch 0, Step 865: train/loss = 0.37638455629348755, train/raw-loss = 0.3288176655769348, train/logprobs = tensor([[-1.1756, -4.2298],
        [-1.6482, -1.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15855632722377777
Epoch 0, Step 866: train/loss = 0.3720695972442627, train/raw-loss = 0.3364782929420471, train/logprobs = tensor([[-1.9932, -3.1878],
        [-2.3984, -1.6355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11863777041435242
Epoch 0, Step 867: train/loss = 0.28164929151535034, train/raw-loss = 0.21984969079494476, train/logprobs = tensor([[-1.7816, -3.9664],
        [-2.0202, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20599864423274994
Epoch 0, Step 868: train/loss = 0.3798357844352722, train/raw-loss = 0.33536529541015625, train/logprobs = tensor([[-1.2175, -3.3952],
        [-1.7040, -1.3641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14823491871356964
Epoch 0, Step 869: train/loss = 0.20626072585582733, train/raw-loss = 0.14924634993076324, train/logprobs = tensor([[-1.3099, -5.6694],
        [-1.8109, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19004787504673004
Epoch 0, Step 870: train/loss = 0.45456361770629883, train/raw-loss = 0.4134055972099304, train/logprobs = tensor([[-2.3215, -2.9809],
        [-2.2424, -1.0251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13719333708286285
Epoch 0, Step 871: train/loss = 0.5210301280021667, train/raw-loss = 0.509454607963562, train/logprobs = tensor([[-2.0848, -1.9245],
        [-2.1089, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03858485445380211
Epoch 0, Step 872: train/loss = 0.3457948565483093, train/raw-loss = 0.32795679569244385, train/logprobs = tensor([[-0.8325, -4.4741],
        [-1.1250, -2.0878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0594601146876812
Epoch 0, Step 873: train/loss = 0.27089327573776245, train/raw-loss = 0.23819908499717712, train/logprobs = tensor([[-1.4502, -4.8821],
        [-1.9138, -2.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10898067057132721
Epoch 0, Step 874: train/loss = 0.4655652940273285, train/raw-loss = 0.44675225019454956, train/logprobs = tensor([[-1.3386, -2.4925],
        [-1.7784, -1.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06271018087863922
Epoch 0, Step 875: train/loss = 0.386301189661026, train/raw-loss = 0.34751731157302856, train/logprobs = tensor([[-1.5850, -3.0608],
        [-1.8777, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12927958369255066
Epoch 0, Step 876: train/loss = 0.23457270860671997, train/raw-loss = 0.1533735990524292, train/logprobs = tensor([[-2.2099, -5.1205],
        [-2.3374, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27066364884376526
Epoch 0, Step 877: train/loss = 0.5007814764976501, train/raw-loss = 0.4886152744293213, train/logprobs = tensor([[-0.9878, -1.8002],
        [-1.4582, -1.2667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04055403172969818
Epoch 0, Step 878: train/loss = 0.4969922602176666, train/raw-loss = 0.479264497756958, train/logprobs = tensor([[-1.8027, -2.3598],
        [-2.1101, -1.4427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05909263342618942
Epoch 0, Step 879: train/loss = 0.3431413769721985, train/raw-loss = 0.29814526438713074, train/logprobs = tensor([[-0.8493, -3.0695],
        [-1.7891, -1.4854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14998699724674225
Epoch 0, Step 880: train/loss = 0.34206151962280273, train/raw-loss = 0.32091423869132996, train/logprobs = tensor([[-1.8770, -4.2238],
        [-2.0165, -2.1701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07049110531806946
Epoch 0, Step 881: train/loss = 0.35254141688346863, train/raw-loss = 0.32207638025283813, train/logprobs = tensor([[-0.9594, -3.9387],
        [-1.2885, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10155008733272552
Epoch 0, Step 882: train/loss = 0.4133364260196686, train/raw-loss = 0.269070565700531, train/logprobs = tensor([[-1.7526, -7.2983],
        [-2.1858, -1.6085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4808861017227173
Epoch 0, Step 883: train/loss = 0.26799625158309937, train/raw-loss = 0.22064192593097687, train/logprobs = tensor([[-0.9865, -5.0415],
        [-1.6197, -2.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15784776210784912
Epoch 0, Step 884: train/loss = 0.44428107142448425, train/raw-loss = 0.4264468848705292, train/logprobs = tensor([[-1.1750, -2.7347],
        [-1.0715, -1.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05944732949137688
Epoch 0, Step 885: train/loss = 0.3278423249721527, train/raw-loss = 0.28194940090179443, train/logprobs = tensor([[-1.1856, -3.9088],
        [-1.7015, -1.3933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15297648310661316
Epoch 0, Step 886: train/loss = 0.43389254808425903, train/raw-loss = 0.36053261160850525, train/logprobs = tensor([[-1.5683, -3.4899],
        [-1.9276, -0.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24453303217887878
Epoch 0, Step 887: train/loss = 0.4485653042793274, train/raw-loss = 0.427039235830307, train/logprobs = tensor([[-2.7651, -4.2732],
        [-2.1734, -1.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07175352424383163
Epoch 0, Step 888: train/loss = 0.48696744441986084, train/raw-loss = 0.4688810110092163, train/logprobs = tensor([[-1.0704, -2.2078],
        [-1.5394, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06028814613819122
Epoch 0, Step 889: train/loss = 0.2718808650970459, train/raw-loss = 0.225764662027359, train/logprobs = tensor([[-1.7872, -5.1472],
        [-2.1880, -1.9336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15372072160243988
Epoch 0, Step 890: train/loss = 0.34884870052337646, train/raw-loss = 0.25657349824905396, train/logprobs = tensor([[-2.2590, -5.0787],
        [-2.4646, -1.3815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3075839877128601
Epoch 0, Step 891: train/loss = 0.2626875340938568, train/raw-loss = 0.20912691950798035, train/logprobs = tensor([[-1.4699, -4.2488],
        [-1.6611, -1.2952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1785353571176529
Epoch 0, Step 892: train/loss = 0.470379501581192, train/raw-loss = 0.4257662892341614, train/logprobs = tensor([[-1.9995, -3.1191],
        [-1.8543, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14871066808700562
Epoch 0, Step 893: train/loss = 0.41085386276245117, train/raw-loss = 0.37471067905426025, train/logprobs = tensor([[-1.3814, -3.2338],
        [-2.1447, -1.6540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12047719955444336
Epoch 0, Step 894: train/loss = 0.4170910120010376, train/raw-loss = 0.400104820728302, train/logprobs = tensor([[-1.6078, -3.6798],
        [-1.5935, -1.7519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056620582938194275
Epoch 0, Step 895: train/loss = 0.3346691429615021, train/raw-loss = 0.2910993695259094, train/logprobs = tensor([[-1.6001, -3.5579],
        [-1.8354, -1.2606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14523255825042725
Epoch 0, Step 896: train/loss = 0.2585326135158539, train/raw-loss = 0.18764951825141907, train/logprobs = tensor([[-1.9036, -5.5728],
        [-2.5176, -2.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23627695441246033
Epoch 0, Step 897: train/loss = 0.3055093586444855, train/raw-loss = 0.22940228879451752, train/logprobs = tensor([[-1.4150, -4.3399],
        [-2.0335, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25369009375572205
Epoch 0, Step 898: train/loss = 0.4469990134239197, train/raw-loss = 0.4117048978805542, train/logprobs = tensor([[-2.5999, -6.1905],
        [-1.5120, -1.6721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11764700710773468
Epoch 0, Step 899: train/loss = 0.3594609797000885, train/raw-loss = 0.3001385033130646, train/logprobs = tensor([[-1.8134, -5.3883],
        [-1.9422, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19774165749549866
Epoch 0, Step 900: train/loss = 0.26051217317581177, train/raw-loss = 0.1351330578327179, train/logprobs = tensor([[-1.8744, -5.0015],
        [-2.6485, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41793036460876465
Epoch 0, Step 901: train/loss = 0.24669566750526428, train/raw-loss = 0.1608513593673706, train/logprobs = tensor([[-2.2056, -4.9755],
        [-2.2807, -1.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28614771366119385
Epoch 0, Step 902: train/loss = 0.39038676023483276, train/raw-loss = 0.3494164049625397, train/logprobs = tensor([[-1.1592, -3.5407],
        [-1.7828, -1.7380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13656780123710632
Epoch 0, Step 903: train/loss = 0.3422203063964844, train/raw-loss = 0.3047957718372345, train/logprobs = tensor([[-1.3857, -4.3255],
        [-1.8452, -1.8613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12474846839904785
Epoch 0, Step 904: train/loss = 0.36439722776412964, train/raw-loss = 0.31871500611305237, train/logprobs = tensor([[-1.0974, -2.7934],
        [-1.6626, -1.0665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1522739976644516
Epoch 0, Step 905: train/loss = 0.5666680335998535, train/raw-loss = 0.5500657558441162, train/logprobs = tensor([[-1.7109, -3.3341],
        [-1.4399, -1.6124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05534088611602783
Epoch 0, Step 906: train/loss = 0.29072269797325134, train/raw-loss = 0.2506641447544098, train/logprobs = tensor([[-1.4623, -5.7147],
        [-1.8248, -2.1674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13352848589420319
Epoch 0, Step 907: train/loss = 0.2539350986480713, train/raw-loss = 0.20091870427131653, train/logprobs = tensor([[-1.6691, -5.0888],
        [-2.0788, -1.8899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17672134935855865
Epoch 0, Step 908: train/loss = 0.4086393117904663, train/raw-loss = 0.3825927972793579, train/logprobs = tensor([[-2.1814, -3.1486],
        [-2.2680, -1.4899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08682159334421158
Epoch 0, Step 909: train/loss = 0.3504859209060669, train/raw-loss = 0.3036460876464844, train/logprobs = tensor([[-1.1415, -2.9531],
        [-1.8510, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15613286197185516
Epoch 0, Step 910: train/loss = 0.30831772089004517, train/raw-loss = 0.2532060146331787, train/logprobs = tensor([[-1.7029, -4.1775],
        [-1.9012, -1.4312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1837056279182434
Epoch 0, Step 911: train/loss = 0.30159804224967957, train/raw-loss = 0.24465136229991913, train/logprobs = tensor([[-2.5247, -4.7533],
        [-2.5702, -1.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18982219696044922
Epoch 0, Step 912: train/loss = 0.4714534878730774, train/raw-loss = 0.44022661447525024, train/logprobs = tensor([[-2.3580, -3.7405],
        [-1.7530, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10408946871757507
Epoch 0, Step 913: train/loss = 0.3923111855983734, train/raw-loss = 0.3449453115463257, train/logprobs = tensor([[-1.1615, -3.4433],
        [-1.7306, -1.4666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15788647532463074
Epoch 0, Step 914: train/loss = 0.4084528982639313, train/raw-loss = 0.3808732032775879, train/logprobs = tensor([[-1.6448, -3.0990],
        [-2.0731, -1.5784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09193237125873566
Epoch 0, Step 915: train/loss = 0.48631078004837036, train/raw-loss = 0.46469390392303467, train/logprobs = tensor([[-1.1605, -2.1988],
        [-1.4498, -1.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07205633819103241
Epoch 0, Step 916: train/loss = 0.31922972202301025, train/raw-loss = 0.24365375936031342, train/logprobs = tensor([[-2.2666, -5.0376],
        [-2.6883, -1.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25191986560821533
Epoch 0, Step 917: train/loss = 0.2827828526496887, train/raw-loss = 0.21935097873210907, train/logprobs = tensor([[-1.5953, -3.7319],
        [-2.0659, -1.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2114396095275879
Epoch 0, Step 918: train/loss = 0.3397224247455597, train/raw-loss = 0.30227208137512207, train/logprobs = tensor([[-1.8023, -4.6037],
        [-2.2293, -1.8606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12483449280261993
Epoch 0, Step 919: train/loss = 0.30140259861946106, train/raw-loss = 0.2643069624900818, train/logprobs = tensor([[-1.1029, -4.4738],
        [-1.9561, -2.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12365207076072693
Epoch 0, Step 920: train/loss = 0.49717921018600464, train/raw-loss = 0.29850029945373535, train/logprobs = tensor([[-2.1236, -6.9687],
        [-2.4631, -1.7216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6622629761695862
Epoch 0, Step 921: train/loss = 0.31415849924087524, train/raw-loss = 0.25547200441360474, train/logprobs = tensor([[-1.5687, -4.0471],
        [-2.2187, -1.3500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19562166929244995
Epoch 0, Step 922: train/loss = 0.4133225977420807, train/raw-loss = 0.39194875955581665, train/logprobs = tensor([[-1.4390, -3.0478],
        [-1.6897, -1.5369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0712462067604065
Epoch 0, Step 923: train/loss = 0.3738762438297272, train/raw-loss = 0.3171568512916565, train/logprobs = tensor([[-2.7118, -4.5966],
        [-2.2813, -1.4782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1890646368265152
Epoch 0, Step 924: train/loss = 0.3717639744281769, train/raw-loss = 0.3241733908653259, train/logprobs = tensor([[-1.2195, -3.8729],
        [-1.7399, -1.8044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15863534808158875
Epoch 0, Step 925: train/loss = 0.5660132169723511, train/raw-loss = 0.5442665219306946, train/logprobs = tensor([[-1.2474, -2.1795],
        [-1.5997, -1.4777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07248900830745697
Epoch 0, Step 926: train/loss = 0.29410064220428467, train/raw-loss = 0.24302805960178375, train/logprobs = tensor([[-1.4826, -5.7294],
        [-1.4546, -1.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17024195194244385
Epoch 0, Step 927: train/loss = 0.2953951358795166, train/raw-loss = 0.2423158586025238, train/logprobs = tensor([[-1.5908, -4.0850],
        [-2.3903, -1.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17693093419075012
Epoch 0, Step 928: train/loss = 0.3380189538002014, train/raw-loss = 0.2871595025062561, train/logprobs = tensor([[-1.9297, -3.7335],
        [-2.7085, -1.7272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16953149437904358
Epoch 0, Step 929: train/loss = 0.470603883266449, train/raw-loss = 0.45965278148651123, train/logprobs = tensor([[-0.6359, -2.3111],
        [-1.3060, -1.6319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03650358319282532
Epoch 0, Step 930: train/loss = 0.4072786271572113, train/raw-loss = 0.391157329082489, train/logprobs = tensor([[-1.4507, -3.7229],
        [-1.8659, -2.0368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05373767018318176
Epoch 0, Step 931: train/loss = 0.42821401357650757, train/raw-loss = 0.3848077356815338, train/logprobs = tensor([[-0.8272, -3.4463],
        [-1.4244, -1.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14468760788440704
Epoch 0, Step 932: train/loss = 0.35061225295066833, train/raw-loss = 0.3109455108642578, train/logprobs = tensor([[-2.0774, -4.4713],
        [-2.5171, -2.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13222244381904602
Epoch 0, Step 933: train/loss = 0.5403780937194824, train/raw-loss = 0.5212701559066772, train/logprobs = tensor([[-1.3785, -2.6028],
        [-1.3597, -1.4239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06369335204362869
Epoch 0, Step 934: train/loss = 0.23903554677963257, train/raw-loss = 0.13399991393089294, train/logprobs = tensor([[-1.4481, -6.3988],
        [-1.9432, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3501187860965729
Epoch 0, Step 935: train/loss = 0.4800001382827759, train/raw-loss = 0.4536130428314209, train/logprobs = tensor([[-2.4301, -4.9223],
        [-1.6261, -1.5877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0879569947719574
Epoch 0, Step 936: train/loss = 0.40674662590026855, train/raw-loss = 0.3759695291519165, train/logprobs = tensor([[-0.9245, -2.1609],
        [-1.5463, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10259022563695908
Epoch 0, Step 937: train/loss = 0.4258975088596344, train/raw-loss = 0.40070486068725586, train/logprobs = tensor([[-1.9790, -3.8454],
        [-1.9374, -1.8275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08397555351257324
Epoch 0, Step 938: train/loss = 0.401997834444046, train/raw-loss = 0.34648603200912476, train/logprobs = tensor([[-2.7644, -3.3681],
        [-3.0713, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18503940105438232
Epoch 0, Step 939: train/loss = 0.639377772808075, train/raw-loss = 0.6357254981994629, train/logprobs = tensor([[-1.0773, -1.2090],
        [-1.5724, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01217411458492279
Epoch 0, Step 940: train/loss = 0.38964539766311646, train/raw-loss = 0.3386770486831665, train/logprobs = tensor([[-1.2547, -3.1590],
        [-2.1602, -1.6717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16989457607269287
Epoch 0, Step 941: train/loss = 0.39733752608299255, train/raw-loss = 0.370911180973053, train/logprobs = tensor([[-1.8587, -4.2304],
        [-2.2499, -2.3792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0880877673625946
Epoch 0, Step 942: train/loss = 0.32899975776672363, train/raw-loss = 0.27719345688819885, train/logprobs = tensor([[-0.9453, -4.0699],
        [-1.1864, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17268775403499603
Epoch 0, Step 943: train/loss = 0.33009085059165955, train/raw-loss = 0.28242766857147217, train/logprobs = tensor([[-1.5202, -4.1490],
        [-1.9578, -1.3041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15887732803821564
Epoch 0, Step 944: train/loss = 0.36272063851356506, train/raw-loss = 0.2866831421852112, train/logprobs = tensor([[-1.2850, -4.4110],
        [-1.8038, -1.4588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25345832109451294
Epoch 0, Step 945: train/loss = 0.35894665122032166, train/raw-loss = 0.3339167833328247, train/logprobs = tensor([[-1.7270, -4.2838],
        [-2.2095, -2.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08343291282653809
Epoch 0, Step 946: train/loss = 0.33549582958221436, train/raw-loss = 0.306870698928833, train/logprobs = tensor([[-1.0177, -3.3880],
        [-1.4894, -1.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541714191436768
Epoch 0, Step 947: train/loss = 0.2606087327003479, train/raw-loss = 0.2006746530532837, train/logprobs = tensor([[-1.6504, -4.7450],
        [-2.0537, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19978025555610657
Epoch 0, Step 948: train/loss = 0.3882756233215332, train/raw-loss = 0.3590412437915802, train/logprobs = tensor([[-1.0031, -4.2584],
        [-1.8226, -2.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09744800627231598
Epoch 0, Step 949: train/loss = 0.28600096702575684, train/raw-loss = 0.23014310002326965, train/logprobs = tensor([[-2.7365, -5.5611],
        [-2.8579, -2.3061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18619294464588165
Epoch 0, Step 950: train/loss = 0.23062166571617126, train/raw-loss = 0.16340714693069458, train/logprobs = tensor([[-1.4636, -5.0612],
        [-1.8508, -1.1202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22404836118221283
Epoch 0, Step 951: train/loss = 0.2607590854167938, train/raw-loss = 0.21188460290431976, train/logprobs = tensor([[-1.4649, -4.3523],
        [-1.8992, -1.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1629149317741394
Epoch 0, Step 952: train/loss = 0.39519065618515015, train/raw-loss = 0.35376012325286865, train/logprobs = tensor([[-1.8649, -5.0142],
        [-2.1649, -2.3996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1381017565727234
Epoch 0, Step 953: train/loss = 0.5694909691810608, train/raw-loss = 0.5316101312637329, train/logprobs = tensor([[-2.0006, -2.9504],
        [-2.1530, -1.8365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12626969814300537
Epoch 0, Step 954: train/loss = 0.3914552628993988, train/raw-loss = 0.34614047408103943, train/logprobs = tensor([[-1.9291, -3.8980],
        [-2.3273, -2.1307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15104928612709045
Epoch 0, Step 955: train/loss = 0.2541922628879547, train/raw-loss = 0.20130813121795654, train/logprobs = tensor([[-1.1444, -5.1830],
        [-1.5585, -1.4230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1762804090976715
Epoch 0, Step 956: train/loss = 0.2682400345802307, train/raw-loss = 0.20694711804389954, train/logprobs = tensor([[-1.8043, -6.0063],
        [-2.3013, -2.6206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20430973172187805
Epoch 0, Step 957: train/loss = 0.30266305804252625, train/raw-loss = 0.22697129845619202, train/logprobs = tensor([[-1.7386, -4.7380],
        [-1.8480, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2523058354854584
Epoch 0, Step 958: train/loss = 0.4319794774055481, train/raw-loss = 0.4080545902252197, train/logprobs = tensor([[-1.9428, -2.9430],
        [-1.8151, -1.2072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07974974811077118
Epoch 0, Step 959: train/loss = 0.26265913248062134, train/raw-loss = 0.19399145245552063, train/logprobs = tensor([[-1.4699, -4.9735],
        [-1.7859, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22889219224452972
Epoch 0, Step 960: train/loss = 0.4805036187171936, train/raw-loss = 0.4404130280017853, train/logprobs = tensor([[-1.2555, -4.5838],
        [-1.0568, -1.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13363535702228546
Epoch 0, Step 961: train/loss = 0.294421523809433, train/raw-loss = 0.20820775628089905, train/logprobs = tensor([[-2.9704, -5.6693],
        [-2.0802, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28737926483154297
Epoch 0, Step 962: train/loss = 0.2620304226875305, train/raw-loss = 0.1760343611240387, train/logprobs = tensor([[-2.0072, -4.6217],
        [-2.1995, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2866535186767578
Epoch 0, Step 963: train/loss = 0.5173951983451843, train/raw-loss = 0.4845062494277954, train/logprobs = tensor([[-2.0206, -2.8874],
        [-2.3502, -1.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10962998867034912
Epoch 0, Step 964: train/loss = 0.38838881254196167, train/raw-loss = 0.33919090032577515, train/logprobs = tensor([[-1.4975, -3.3136],
        [-2.1944, -1.6764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16399304568767548
Epoch 0, Step 965: train/loss = 0.20017051696777344, train/raw-loss = 0.10882300138473511, train/logprobs = tensor([[-1.8539, -6.7537],
        [-2.4106, -1.6816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3044917583465576
Epoch 0, Step 966: train/loss = 0.40441274642944336, train/raw-loss = 0.367470383644104, train/logprobs = tensor([[-2.1255, -3.7753],
        [-2.5038, -1.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12314124405384064
Epoch 0, Step 967: train/loss = 0.2984980344772339, train/raw-loss = 0.2557102143764496, train/logprobs = tensor([[-1.3919, -4.4769],
        [-1.5969, -1.4626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1426260620355606
Epoch 0, Step 968: train/loss = 0.48231732845306396, train/raw-loss = 0.4503680467605591, train/logprobs = tensor([[-2.0269, -2.7381],
        [-2.4787, -1.6451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10649766027927399
Epoch 0, Step 969: train/loss = 0.4742378294467926, train/raw-loss = 0.4365110397338867, train/logprobs = tensor([[-1.0427, -2.7551],
        [-1.6674, -1.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12575587630271912
Epoch 0, Step 970: train/loss = 0.1858757734298706, train/raw-loss = 0.09051594138145447, train/logprobs = tensor([[-1.3706, -6.5321],
        [-2.0141, -1.3546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31786614656448364
Epoch 0, Step 971: train/loss = 0.31465578079223633, train/raw-loss = 0.25146305561065674, train/logprobs = tensor([[-1.2389, -4.4769],
        [-1.9325, -1.3038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210642471909523
Epoch 0, Step 972: train/loss = 0.37921684980392456, train/raw-loss = 0.29719239473342896, train/logprobs = tensor([[-2.4376, -5.3770],
        [-2.4352, -1.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27341488003730774
Epoch 0, Step 973: train/loss = 0.3104344606399536, train/raw-loss = 0.27299755811691284, train/logprobs = tensor([[-1.6717, -4.0831],
        [-1.9594, -1.3171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12478967010974884
Epoch 0, Step 974: train/loss = 0.48469868302345276, train/raw-loss = 0.46835389733314514, train/logprobs = tensor([[-1.4020, -1.8206],
        [-1.8933, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0544825978577137
Epoch 0, Step 975: train/loss = 0.43220382928848267, train/raw-loss = 0.4005551338195801, train/logprobs = tensor([[-1.5860, -2.5207],
        [-2.1095, -1.4023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10549545288085938
Epoch 0, Step 976: train/loss = 0.318656325340271, train/raw-loss = 0.2555825114250183, train/logprobs = tensor([[-1.6298, -5.0113],
        [-2.1873, -1.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102459967136383
Epoch 0, Step 977: train/loss = 0.6245359778404236, train/raw-loss = 0.6089246273040771, train/logprobs = tensor([[-1.5171, -3.1198],
        [-1.5474, -1.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05203792452812195
Epoch 0, Step 978: train/loss = 0.41606849431991577, train/raw-loss = 0.3642735779285431, train/logprobs = tensor([[-1.9027, -3.9144],
        [-2.5123, -1.8260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17264974117279053
Epoch 0, Step 979: train/loss = 0.2163056582212448, train/raw-loss = 0.13548532128334045, train/logprobs = tensor([[-1.6850, -5.4105],
        [-2.1692, -1.4685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26940107345581055
Epoch 0, Step 980: train/loss = 0.34596115350723267, train/raw-loss = 0.28869733214378357, train/logprobs = tensor([[-1.9806, -5.1298],
        [-2.3162, -2.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1908794492483139
Epoch 0, Step 981: train/loss = 0.4271072447299957, train/raw-loss = 0.3739372789859772, train/logprobs = tensor([[-1.7761, -3.5126],
        [-2.2723, -1.5040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17723318934440613
Epoch 0, Step 982: train/loss = 0.4718301296234131, train/raw-loss = 0.4431665241718292, train/logprobs = tensor([[-1.9507, -4.9095],
        [-1.7050, -2.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09554526209831238
Epoch 0, Step 983: train/loss = 0.2985830307006836, train/raw-loss = 0.18986935913562775, train/logprobs = tensor([[-2.3272, -7.4132],
        [-2.9277, -1.7797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36237889528274536
Epoch 0, Step 984: train/loss = 0.5425394177436829, train/raw-loss = 0.5342730283737183, train/logprobs = tensor([[-1.5641, -1.4772],
        [-2.4398, -1.5666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027554577216506004
Epoch 0, Step 985: train/loss = 0.4457739591598511, train/raw-loss = 0.4180426001548767, train/logprobs = tensor([[-2.1063, -2.8415],
        [-2.4202, -1.6594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.092437744140625
Epoch 0, Step 986: train/loss = 0.49169063568115234, train/raw-loss = 0.42063748836517334, train/logprobs = tensor([[-2.5894, -4.3773],
        [-2.7100, -1.7325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23684388399124146
Epoch 0, Step 987: train/loss = 0.4857328236103058, train/raw-loss = 0.4633197486400604, train/logprobs = tensor([[-2.1223, -3.4016],
        [-2.2141, -2.0509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07471019774675369
Epoch 0, Step 988: train/loss = 0.4264513850212097, train/raw-loss = 0.35869744420051575, train/logprobs = tensor([[-2.1782, -4.5157],
        [-2.3944, -2.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2258465588092804
Epoch 0, Step 989: train/loss = 0.35013648867607117, train/raw-loss = 0.2531573176383972, train/logprobs = tensor([[-1.4441, -6.4628],
        [-2.1649, -1.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32326388359069824
Epoch 0, Step 990: train/loss = 0.4870631992816925, train/raw-loss = 0.452448308467865, train/logprobs = tensor([[-2.5546, -3.2018],
        [-2.5366, -1.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538296192884445
Epoch 0, Step 991: train/loss = 0.2492583692073822, train/raw-loss = 0.2074153870344162, train/logprobs = tensor([[-1.3829, -6.6730],
        [-2.0429, -2.1012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13947662711143494
Epoch 0, Step 992: train/loss = 0.3766805827617645, train/raw-loss = 0.3368162214756012, train/logprobs = tensor([[-1.5628, -5.0654],
        [-2.0493, -2.1060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13288123905658722
Epoch 0, Step 993: train/loss = 0.26805731654167175, train/raw-loss = 0.19516873359680176, train/logprobs = tensor([[-1.8415, -4.3138],
        [-3.0619, -1.6893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24296198785305023
Epoch 0, Step 994: train/loss = 0.46138492226600647, train/raw-loss = 0.4150497317314148, train/logprobs = tensor([[-2.6193, -4.3792],
        [-3.0966, -2.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15445050597190857
Epoch 0, Step 995: train/loss = 0.21212390065193176, train/raw-loss = 0.1401848942041397, train/logprobs = tensor([[-1.4275, -5.0994],
        [-2.0518, -1.5879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2397967129945755
Epoch 0, Step 996: train/loss = 0.2864662706851959, train/raw-loss = 0.24480515718460083, train/logprobs = tensor([[-2.0931, -4.5686],
        [-2.0507, -1.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13887032866477966
Epoch 0, Step 997: train/loss = 0.25892969965934753, train/raw-loss = 0.1976011097431183, train/logprobs = tensor([[-1.5067, -6.2854],
        [-1.7577, -1.7736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20442861318588257
Epoch 0, Step 998: train/loss = 0.25659334659576416, train/raw-loss = 0.17092975974082947, train/logprobs = tensor([[-1.7389, -4.8799],
        [-2.2383, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2855452001094818
Epoch 0, Step 999: train/loss = 0.3523041009902954, train/raw-loss = 0.29470759630203247, train/logprobs = tensor([[-1.9494, -2.9251],
        [-3.1029, -1.5355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19198833405971527
eval/loss: 0.3389858901500702
Epoch 0, Step 1000: train/loss = 0.55921471118927, train/raw-loss = 0.5379658937454224, train/logprobs = tensor([[-2.0620, -2.5096],
        [-2.4028, -1.9115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07082922756671906
Epoch 0, Step 1001: train/loss = 0.23149985074996948, train/raw-loss = 0.18107792735099792, train/logprobs = tensor([[-1.5799, -6.0700],
        [-2.4865, -2.8590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16807304322719574
Epoch 0, Step 1002: train/loss = 0.36950650811195374, train/raw-loss = 0.3177386224269867, train/logprobs = tensor([[-1.1627, -3.5756],
        [-1.9085, -1.6257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17255960404872894
Epoch 0, Step 1003: train/loss = 0.4549199938774109, train/raw-loss = 0.43684807419776917, train/logprobs = tensor([[-1.6952, -2.1242],
        [-2.4496, -1.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06023963913321495
Epoch 0, Step 1004: train/loss = 0.33366596698760986, train/raw-loss = 0.2844775915145874, train/logprobs = tensor([[-2.0077, -3.2085],
        [-3.2141, -1.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16396132111549377
Epoch 0, Step 1005: train/loss = 0.17156052589416504, train/raw-loss = 0.11975324898958206, train/logprobs = tensor([[-1.5407, -6.8043],
        [-1.9839, -2.2287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17269092798233032
Epoch 0, Step 1006: train/loss = 0.6859803199768066, train/raw-loss = 0.6855400800704956, train/logprobs = tensor([[-1.1244, -1.0631],
        [-1.4085, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014674923149868846
Epoch 0, Step 1007: train/loss = 0.4441820979118347, train/raw-loss = 0.3992377519607544, train/logprobs = tensor([[-2.8511, -4.3778],
        [-2.4744, -1.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14981451630592346
Epoch 0, Step 1008: train/loss = 0.42588281631469727, train/raw-loss = 0.39258676767349243, train/logprobs = tensor([[-1.6459, -2.8066],
        [-2.7771, -1.7809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1109868660569191
Epoch 0, Step 1009: train/loss = 0.17343036830425262, train/raw-loss = 0.05979624390602112, train/logprobs = tensor([[-1.4339, -7.7525],
        [-2.1935, -1.6972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37878039479255676
Epoch 0, Step 1010: train/loss = 0.2733103930950165, train/raw-loss = 0.19310955703258514, train/logprobs = tensor([[-3.0656, -5.3805],
        [-3.1744, -1.6178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2673361599445343
Epoch 0, Step 1011: train/loss = 0.23717835545539856, train/raw-loss = 0.11093330383300781, train/logprobs = tensor([[-1.6679, -7.3074],
        [-2.3128, -1.1655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4208168089389801
Epoch 0, Step 1012: train/loss = 0.31658607721328735, train/raw-loss = 0.24243101477622986, train/logprobs = tensor([[-2.5310, -5.7079],
        [-2.6982, -1.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2471834421157837
Epoch 0, Step 1013: train/loss = 0.48578596115112305, train/raw-loss = 0.47210708260536194, train/logprobs = tensor([[-1.7312, -2.3939],
        [-2.1529, -1.6505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0455964133143425
Epoch 0, Step 1014: train/loss = 0.44256913661956787, train/raw-loss = 0.4111214876174927, train/logprobs = tensor([[-2.1151, -3.5288],
        [-2.1993, -1.6755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10482537746429443
Epoch 0, Step 1015: train/loss = 0.30025285482406616, train/raw-loss = 0.1004258319735527, train/logprobs = tensor([[-2.6264, -9.8211],
        [-2.5750, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6660900115966797
Epoch 0, Step 1016: train/loss = 0.23231732845306396, train/raw-loss = 0.17099428176879883, train/logprobs = tensor([[-1.2875, -4.6385],
        [-2.0409, -1.7122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20441025495529175
Epoch 0, Step 1017: train/loss = 0.35205724835395813, train/raw-loss = 0.2901933491230011, train/logprobs = tensor([[-1.6139, -3.3855],
        [-2.5443, -1.5372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20621295273303986
Epoch 0, Step 1018: train/loss = 0.3038910925388336, train/raw-loss = 0.23943865299224854, train/logprobs = tensor([[-2.3451, -4.3192],
        [-2.1975, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21484142541885376
Epoch 0, Step 1019: train/loss = 0.32044312357902527, train/raw-loss = 0.2492128163576126, train/logprobs = tensor([[-1.4471, -3.9535],
        [-2.4182, -1.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2374342679977417
Epoch 0, Step 1020: train/loss = 0.5566919445991516, train/raw-loss = 0.5277549028396606, train/logprobs = tensor([[-2.7558, -3.2932],
        [-2.0842, -1.4444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09645670652389526
Epoch 0, Step 1021: train/loss = 0.3779046833515167, train/raw-loss = 0.3368006646633148, train/logprobs = tensor([[-1.2799, -3.1983],
        [-1.9534, -1.3847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13701337575912476
Epoch 0, Step 1022: train/loss = 0.32170411944389343, train/raw-loss = 0.27110427618026733, train/logprobs = tensor([[-2.2211, -5.0453],
        [-2.0937, -1.4756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16866613924503326
Epoch 0, Step 1023: train/loss = 0.3404479920864105, train/raw-loss = 0.2762623131275177, train/logprobs = tensor([[-2.1067, -5.1884],
        [-2.1211, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21395224332809448
Epoch 0, Step 1024: train/loss = 0.24379366636276245, train/raw-loss = 0.18438073992729187, train/logprobs = tensor([[-1.9825, -6.0604],
        [-2.2409, -1.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1980430632829666
Epoch 0, Step 1025: train/loss = 0.5249058604240417, train/raw-loss = 0.46948930621147156, train/logprobs = tensor([[-2.2621, -3.8530],
        [-2.3838, -1.2050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18472179770469666
Epoch 0, Step 1026: train/loss = 0.32661953568458557, train/raw-loss = 0.29799509048461914, train/logprobs = tensor([[-1.7726, -4.3089],
        [-1.9802, -2.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09541476517915726
Epoch 0, Step 1027: train/loss = 0.3191913962364197, train/raw-loss = 0.2683456540107727, train/logprobs = tensor([[-3.2569, -6.4716],
        [-2.3169, -2.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1694859266281128
Epoch 0, Step 1028: train/loss = 0.3948659896850586, train/raw-loss = 0.32831522822380066, train/logprobs = tensor([[-1.2862, -4.1985],
        [-2.2787, -1.5925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2218358963727951
Epoch 0, Step 1029: train/loss = 0.40852877497673035, train/raw-loss = 0.3651926517486572, train/logprobs = tensor([[-2.6402, -3.3121],
        [-2.7667, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14445362985134125
Epoch 0, Step 1030: train/loss = 0.5180491209030151, train/raw-loss = 0.4371013939380646, train/logprobs = tensor([[-2.3847, -4.6301],
        [-2.7252, -1.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2698257267475128
Epoch 0, Step 1031: train/loss = 0.3508589565753937, train/raw-loss = 0.28826263546943665, train/logprobs = tensor([[-1.6116, -6.4296],
        [-2.2464, -2.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20865440368652344
Epoch 0, Step 1032: train/loss = 0.382590651512146, train/raw-loss = 0.33385100960731506, train/logprobs = tensor([[-1.3700, -4.0392],
        [-2.1369, -1.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1624654233455658
Epoch 0, Step 1033: train/loss = 0.3299593925476074, train/raw-loss = 0.2771335542201996, train/logprobs = tensor([[-1.8469, -5.4078],
        [-1.5647, -1.4238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1760862022638321
Epoch 0, Step 1034: train/loss = 0.3798307478427887, train/raw-loss = 0.31320720911026, train/logprobs = tensor([[-2.0432, -4.0733],
        [-2.6888, -1.2805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22207851707935333
Epoch 0, Step 1035: train/loss = 0.272514283657074, train/raw-loss = 0.22815200686454773, train/logprobs = tensor([[-1.2919, -4.0291],
        [-2.2931, -1.7487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14787420630455017
Epoch 0, Step 1036: train/loss = 0.4462767243385315, train/raw-loss = 0.412478506565094, train/logprobs = tensor([[-1.8279, -2.8262],
        [-1.9293, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11266070604324341
Epoch 0, Step 1037: train/loss = 0.28875041007995605, train/raw-loss = 0.22375603020191193, train/logprobs = tensor([[-2.0114, -4.0563],
        [-2.1989, -1.0779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21664798259735107
Epoch 0, Step 1038: train/loss = 0.4495891034603119, train/raw-loss = 0.40846335887908936, train/logprobs = tensor([[-1.5884, -2.9307],
        [-1.8956, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13708582520484924
Epoch 0, Step 1039: train/loss = 0.23117318749427795, train/raw-loss = 0.10862801223993301, train/logprobs = tensor([[-1.7985, -6.8256],
        [-2.8706, -1.4014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40848392248153687
Epoch 0, Step 1040: train/loss = 0.2185344249010086, train/raw-loss = 0.15544718503952026, train/logprobs = tensor([[-1.4464, -5.2817],
        [-2.2629, -1.8098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2102908045053482
Epoch 0, Step 1041: train/loss = 0.3713724911212921, train/raw-loss = 0.3178798258304596, train/logprobs = tensor([[-1.9742, -3.5051],
        [-2.9701, -1.8614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17830879986286163
Epoch 0, Step 1042: train/loss = 0.3316647708415985, train/raw-loss = 0.24173790216445923, train/logprobs = tensor([[-1.4424, -4.9436],
        [-1.9683, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29975625872612
Epoch 0, Step 1043: train/loss = 0.32249706983566284, train/raw-loss = 0.27776360511779785, train/logprobs = tensor([[-1.1504, -3.4178],
        [-2.1065, -1.5794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14911147952079773
Epoch 0, Step 1044: train/loss = 0.39706093072891235, train/raw-loss = 0.36869487166404724, train/logprobs = tensor([[-1.3682, -3.4877],
        [-1.8983, -1.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09455347806215286
Epoch 0, Step 1045: train/loss = 0.2520630955696106, train/raw-loss = 0.18887993693351746, train/logprobs = tensor([[-1.9598, -5.5663],
        [-1.7463, -1.2916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2106105536222458
Epoch 0, Step 1046: train/loss = 0.3836347460746765, train/raw-loss = 0.3284698724746704, train/logprobs = tensor([[-1.4298, -3.6135],
        [-1.8976, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18388281762599945
Epoch 0, Step 1047: train/loss = 0.3866073191165924, train/raw-loss = 0.3598529100418091, train/logprobs = tensor([[-1.6377, -2.8139],
        [-2.4688, -1.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08918130397796631
Epoch 0, Step 1048: train/loss = 0.3711770176887512, train/raw-loss = 0.3194754123687744, train/logprobs = tensor([[-1.9762, -4.5784],
        [-2.2380, -1.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17233863472938538
Epoch 0, Step 1049: train/loss = 0.22919075191020966, train/raw-loss = 0.16344201564788818, train/logprobs = tensor([[-1.2486, -5.8740],
        [-2.4699, -2.5636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21916238963603973
Epoch 0, Step 1050: train/loss = 0.4723992645740509, train/raw-loss = 0.4175947308540344, train/logprobs = tensor([[-1.3858, -2.9923],
        [-2.0253, -1.5494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18268181383609772
Epoch 0, Step 1051: train/loss = 0.283438116312027, train/raw-loss = 0.2520570158958435, train/logprobs = tensor([[-1.9713, -5.4155],
        [-2.0779, -2.1812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10460373014211655
Epoch 0, Step 1052: train/loss = 0.2755318284034729, train/raw-loss = 0.22083574533462524, train/logprobs = tensor([[-1.5408, -4.4117],
        [-1.9576, -1.4533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18232035636901855
Epoch 0, Step 1053: train/loss = 0.25821053981781006, train/raw-loss = 0.1790468841791153, train/logprobs = tensor([[-1.7211, -4.8839],
        [-2.5569, -1.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26387882232666016
Epoch 0, Step 1054: train/loss = 0.42469704151153564, train/raw-loss = 0.3917275667190552, train/logprobs = tensor([[-1.0600, -2.8538],
        [-1.7550, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10989822447299957
Epoch 0, Step 1055: train/loss = 0.3479677438735962, train/raw-loss = 0.3117729127407074, train/logprobs = tensor([[-2.3004, -3.4059],
        [-2.4854, -1.4074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12064951658248901
Epoch 0, Step 1056: train/loss = 0.198977530002594, train/raw-loss = 0.08942247927188873, train/logprobs = tensor([[-1.4030, -4.9845],
        [-2.3494, -0.9849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3651835024356842
Epoch 0, Step 1057: train/loss = 0.3334810137748718, train/raw-loss = 0.2762381136417389, train/logprobs = tensor([[-2.1552, -5.7061],
        [-1.6568, -1.7870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19080959260463715
Epoch 0, Step 1058: train/loss = 0.3733586072921753, train/raw-loss = 0.3070244789123535, train/logprobs = tensor([[-2.1802, -5.1517],
        [-2.4434, -1.8852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22111383080482483
Epoch 0, Step 1059: train/loss = 0.3722747564315796, train/raw-loss = 0.3273296058177948, train/logprobs = tensor([[-1.8335, -3.3414],
        [-2.7505, -1.8764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14981709420681
Epoch 0, Step 1060: train/loss = 0.2953532934188843, train/raw-loss = 0.22163169085979462, train/logprobs = tensor([[-1.0028, -5.6898],
        [-2.1285, -2.0299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24573871493339539
Epoch 0, Step 1061: train/loss = 0.31076580286026, train/raw-loss = 0.24738556146621704, train/logprobs = tensor([[-2.8625, -4.1682],
        [-3.2837, -1.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21126756072044373
Epoch 0, Step 1062: train/loss = 0.3765643835067749, train/raw-loss = 0.3273445963859558, train/logprobs = tensor([[-1.6610, -2.9837],
        [-2.3156, -1.3929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1640659123659134
Epoch 0, Step 1063: train/loss = 0.33931973576545715, train/raw-loss = 0.28691214323043823, train/logprobs = tensor([[-1.8593, -4.6370],
        [-2.8482, -2.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17469197511672974
Epoch 0, Step 1064: train/loss = 0.40444713830947876, train/raw-loss = 0.31041795015335083, train/logprobs = tensor([[-1.9904, -4.6370],
        [-2.2590, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31343069672584534
Epoch 0, Step 1065: train/loss = 0.25747156143188477, train/raw-loss = 0.1980801671743393, train/logprobs = tensor([[-1.5650, -5.5820],
        [-2.3749, -2.1525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19797131419181824
Epoch 0, Step 1066: train/loss = 0.2267211675643921, train/raw-loss = 0.08304762840270996, train/logprobs = tensor([[-1.7063, -7.4917],
        [-2.6457, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47891175746917725
Epoch 0, Step 1067: train/loss = 0.2725820243358612, train/raw-loss = 0.21413321793079376, train/logprobs = tensor([[-1.5255, -5.0817],
        [-1.9243, -1.6850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1948293298482895
Epoch 0, Step 1068: train/loss = 0.46823617815971375, train/raw-loss = 0.4284794330596924, train/logprobs = tensor([[-1.5659, -3.7761],
        [-2.1421, -2.1256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13252243399620056
Epoch 0, Step 1069: train/loss = 0.2705708146095276, train/raw-loss = 0.16314706206321716, train/logprobs = tensor([[-1.7816, -6.2592],
        [-2.4139, -1.4634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3580791652202606
Epoch 0, Step 1070: train/loss = 0.2675730884075165, train/raw-loss = 0.17730426788330078, train/logprobs = tensor([[-1.4359, -5.7586],
        [-2.3259, -1.4900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.300896018743515
Epoch 0, Step 1071: train/loss = 0.35722339153289795, train/raw-loss = 0.2826578915119171, train/logprobs = tensor([[-2.8497, -5.9929],
        [-2.5805, -1.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2485516369342804
Epoch 0, Step 1072: train/loss = 0.5095357298851013, train/raw-loss = 0.4647172689437866, train/logprobs = tensor([[-2.6549, -3.4899],
        [-2.3855, -1.3711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14939475059509277
Epoch 0, Step 1073: train/loss = 0.3444388806819916, train/raw-loss = 0.21695569157600403, train/logprobs = tensor([[-1.6367, -5.7739],
        [-2.3453, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4249439835548401
Epoch 0, Step 1074: train/loss = 0.5794466733932495, train/raw-loss = 0.5468152761459351, train/logprobs = tensor([[-2.1502, -2.8387],
        [-2.1696, -1.5995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1087711974978447
Epoch 0, Step 1075: train/loss = 0.2583897113800049, train/raw-loss = 0.16529802978038788, train/logprobs = tensor([[-1.8202, -6.3490],
        [-2.5356, -2.0579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31030556559562683
Epoch 0, Step 1076: train/loss = 0.3753014802932739, train/raw-loss = 0.320487380027771, train/logprobs = tensor([[-1.5132, -3.4818],
        [-2.4367, -1.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1827135682106018
Epoch 0, Step 1077: train/loss = 0.3615584969520569, train/raw-loss = 0.3236478567123413, train/logprobs = tensor([[-1.8060, -4.6161],
        [-2.5253, -2.3924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12636885046958923
Epoch 0, Step 1078: train/loss = 0.2963874936103821, train/raw-loss = 0.23308232426643372, train/logprobs = tensor([[-1.5145, -3.8255],
        [-2.5485, -1.6784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21101725101470947
Epoch 0, Step 1079: train/loss = 0.19018027186393738, train/raw-loss = 0.0920049399137497, train/logprobs = tensor([[-1.4518, -7.2613],
        [-2.6650, -2.1911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3272510766983032
Epoch 0, Step 1080: train/loss = 0.2632297873497009, train/raw-loss = 0.1687270551919937, train/logprobs = tensor([[-1.6729, -6.1309],
        [-2.1808, -1.2946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31500911712646484
Epoch 0, Step 1081: train/loss = 0.45575571060180664, train/raw-loss = 0.409577339887619, train/logprobs = tensor([[-1.8449, -4.5683],
        [-1.8291, -2.0912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1539279818534851
Epoch 0, Step 1082: train/loss = 0.1959797739982605, train/raw-loss = 0.105431467294693, train/logprobs = tensor([[-1.1317, -5.8943],
        [-1.7345, -0.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30182766914367676
Epoch 0, Step 1083: train/loss = 0.32295894622802734, train/raw-loss = 0.2557925581932068, train/logprobs = tensor([[-1.8668, -5.3717],
        [-2.6881, -1.6964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22388789057731628
Epoch 0, Step 1084: train/loss = 0.21735799312591553, train/raw-loss = 0.08646681159734726, train/logprobs = tensor([[-1.6011, -7.6816],
        [-2.5462, -1.2708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43630391359329224
Epoch 0, Step 1085: train/loss = 0.360574334859848, train/raw-loss = 0.3297804594039917, train/logprobs = tensor([[-2.3966, -4.4598],
        [-3.3085, -2.5471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10264627635478973
Epoch 0, Step 1086: train/loss = 0.20639066398143768, train/raw-loss = 0.08134057372808456, train/logprobs = tensor([[-1.7421, -6.2787],
        [-2.3472, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41683363914489746
Epoch 0, Step 1087: train/loss = 0.3712003827095032, train/raw-loss = 0.33440473675727844, train/logprobs = tensor([[-2.1776, -4.9089],
        [-2.6843, -1.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1226520836353302
Epoch 0, Step 1088: train/loss = 0.41231516003608704, train/raw-loss = 0.3805239498615265, train/logprobs = tensor([[-1.8284, -2.5958],
        [-3.0900, -2.1168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10597068071365356
Epoch 0, Step 1089: train/loss = 0.2833608388900757, train/raw-loss = 0.1927228718996048, train/logprobs = tensor([[-1.6899, -5.7462],
        [-1.9981, -0.5942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3021264672279358
Epoch 0, Step 1090: train/loss = 0.30478334426879883, train/raw-loss = 0.2120538204908371, train/logprobs = tensor([[-2.2639, -5.7421],
        [-2.7513, -1.5997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3090983033180237
Epoch 0, Step 1091: train/loss = 0.3864368200302124, train/raw-loss = 0.3324531316757202, train/logprobs = tensor([[-1.6912, -3.3834],
        [-2.7682, -1.8245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1799454689025879
Epoch 0, Step 1092: train/loss = 0.4652026891708374, train/raw-loss = 0.382148414850235, train/logprobs = tensor([[-3.0381, -5.1132],
        [-2.2534, -1.0163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2768475413322449
Epoch 0, Step 1093: train/loss = 0.3029121458530426, train/raw-loss = 0.241459459066391, train/logprobs = tensor([[-1.9596, -4.0299],
        [-2.7246, -1.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20484225451946259
Epoch 0, Step 1094: train/loss = 0.3098803162574768, train/raw-loss = 0.23953409492969513, train/logprobs = tensor([[-2.0457, -4.5311],
        [-2.9032, -1.7590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2344873696565628
Epoch 0, Step 1095: train/loss = 0.2992027997970581, train/raw-loss = 0.22189246118068695, train/logprobs = tensor([[-2.5846, -5.5367],
        [-3.1787, -2.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2577010691165924
Epoch 0, Step 1096: train/loss = 0.2752402722835541, train/raw-loss = 0.20782409608364105, train/logprobs = tensor([[-1.9808, -4.6179],
        [-2.9991, -1.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2247205674648285
Epoch 0, Step 1097: train/loss = 0.2690439224243164, train/raw-loss = 0.16320538520812988, train/logprobs = tensor([[-1.9763, -6.1542],
        [-2.1618, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3527950644493103
Epoch 0, Step 1098: train/loss = 0.1822993904352188, train/raw-loss = 0.06865601986646652, train/logprobs = tensor([[-1.1812, -6.7894],
        [-2.2153, -1.2544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.378811240196228
Epoch 0, Step 1099: train/loss = 0.4340338110923767, train/raw-loss = 0.4094196856021881, train/logprobs = tensor([[-1.9270, -4.0082],
        [-2.1023, -2.0827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0820470005273819
Epoch 0, Step 1100: train/loss = 0.23362012207508087, train/raw-loss = 0.12673994898796082, train/logprobs = tensor([[-2.1430, -6.7813],
        [-2.5490, -1.4328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3562672436237335
Epoch 0, Step 1101: train/loss = 0.31521105766296387, train/raw-loss = 0.23255224525928497, train/logprobs = tensor([[-1.0730, -3.3824],
        [-2.4447, -1.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27552926540374756
Epoch 0, Step 1102: train/loss = 0.2356463521718979, train/raw-loss = 0.18304254114627838, train/logprobs = tensor([[-1.5377, -5.5983],
        [-2.3414, -2.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1753459870815277
Epoch 0, Step 1103: train/loss = 0.31215882301330566, train/raw-loss = 0.26338696479797363, train/logprobs = tensor([[-1.5080, -4.8782],
        [-2.3251, -2.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16257290542125702
Epoch 0, Step 1104: train/loss = 0.3087267577648163, train/raw-loss = 0.26283785700798035, train/logprobs = tensor([[-1.7348, -4.5788],
        [-2.5900, -1.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15296293795108795
Epoch 0, Step 1105: train/loss = 0.23413926362991333, train/raw-loss = 0.1555364578962326, train/logprobs = tensor([[-1.5068, -7.3368],
        [-1.9610, -1.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26200932264328003
Epoch 0, Step 1106: train/loss = 0.3137569725513458, train/raw-loss = 0.26204660534858704, train/logprobs = tensor([[-2.7849, -4.2856],
        [-2.5956, -1.4681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17236793041229248
Epoch 0, Step 1107: train/loss = 0.3079763948917389, train/raw-loss = 0.2068818211555481, train/logprobs = tensor([[-1.9928, -6.8571],
        [-2.2708, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33698195219039917
Epoch 0, Step 1108: train/loss = 0.3729008436203003, train/raw-loss = 0.3208003640174866, train/logprobs = tensor([[-1.6212, -3.4467],
        [-2.4730, -1.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17366844415664673
Epoch 0, Step 1109: train/loss = 0.3089413046836853, train/raw-loss = 0.24316123127937317, train/logprobs = tensor([[-3.1092, -5.4196],
        [-3.0575, -2.1564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2192668616771698
Epoch 0, Step 1110: train/loss = 0.18912173807621002, train/raw-loss = 0.10203639417886734, train/logprobs = tensor([[-1.4369, -6.1373],
        [-2.1154, -1.6244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2902844548225403
Epoch 0, Step 1111: train/loss = 0.41096222400665283, train/raw-loss = 0.36680400371551514, train/logprobs = tensor([[-2.3313, -5.2143],
        [-3.1154, -2.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14719410240650177
Epoch 0, Step 1112: train/loss = 0.277029812335968, train/raw-loss = 0.20635393261909485, train/logprobs = tensor([[-1.7045, -5.5268],
        [-2.1480, -1.6961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23558630049228668
Epoch 0, Step 1113: train/loss = 0.5480543375015259, train/raw-loss = 0.524957537651062, train/logprobs = tensor([[-2.4288, -3.5033],
        [-1.8497, -1.6184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07698934525251389
Epoch 0, Step 1114: train/loss = 0.36698877811431885, train/raw-loss = 0.2919897437095642, train/logprobs = tensor([[-1.4941, -5.0663],
        [-2.6222, -1.6449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24999667704105377
Epoch 0, Step 1115: train/loss = 0.3079848289489746, train/raw-loss = 0.2335776686668396, train/logprobs = tensor([[-1.8704, -5.3229],
        [-3.1959, -2.4927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24802382290363312
Epoch 0, Step 1116: train/loss = 0.34500426054000854, train/raw-loss = 0.2907760739326477, train/logprobs = tensor([[-1.9492, -5.4033],
        [-1.9599, -1.6787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1807607114315033
Epoch 0, Step 1117: train/loss = 0.33862724900245667, train/raw-loss = 0.27618923783302307, train/logprobs = tensor([[-2.1216, -5.0531],
        [-2.8524, -2.0504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2081267386674881
Epoch 0, Step 1118: train/loss = 0.3428459167480469, train/raw-loss = 0.2782268822193146, train/logprobs = tensor([[-0.9612, -5.0753],
        [-1.8597, -1.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21539677679538727
Epoch 0, Step 1119: train/loss = 0.2869306206703186, train/raw-loss = 0.2310466319322586, train/logprobs = tensor([[-1.1723, -5.9018],
        [-2.3335, -2.2293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18627993762493134
Epoch 0, Step 1120: train/loss = 0.3738941252231598, train/raw-loss = 0.3264791965484619, train/logprobs = tensor([[-2.0700, -4.9372],
        [-3.3444, -2.8370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15804961323738098
Epoch 0, Step 1121: train/loss = 0.4069173336029053, train/raw-loss = 0.371145099401474, train/logprobs = tensor([[-2.9657, -4.1939],
        [-2.4545, -1.7561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11924085021018982
Epoch 0, Step 1122: train/loss = 0.29528093338012695, train/raw-loss = 0.2126159816980362, train/logprobs = tensor([[-2.5670, -8.0165],
        [-3.3088, -2.3719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27554991841316223
Epoch 0, Step 1123: train/loss = 0.31673887372016907, train/raw-loss = 0.22753073275089264, train/logprobs = tensor([[-2.9161, -7.0294],
        [-3.3910, -2.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2973604202270508
Epoch 0, Step 1124: train/loss = 0.32673710584640503, train/raw-loss = 0.25450968742370605, train/logprobs = tensor([[-3.3753, -5.4872],
        [-3.3627, -2.0071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24075806140899658
Epoch 0, Step 1125: train/loss = 0.506106972694397, train/raw-loss = 0.4907485842704773, train/logprobs = tensor([[-0.9951, -1.6785],
        [-2.1464, -1.8005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051194749772548676
Epoch 0, Step 1126: train/loss = 0.2845655679702759, train/raw-loss = 0.17411603033542633, train/logprobs = tensor([[-1.7980, -5.1534],
        [-2.8198, -1.7726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36816516518592834
Epoch 0, Step 1127: train/loss = 0.24199917912483215, train/raw-loss = 0.15154151618480682, train/logprobs = tensor([[-2.5230, -5.6678],
        [-3.1069, -1.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015255928039551
Epoch 0, Step 1128: train/loss = 0.3290053606033325, train/raw-loss = 0.2736823856830597, train/logprobs = tensor([[-2.5890, -4.6255],
        [-3.2083, -2.3449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1844099909067154
Epoch 0, Step 1129: train/loss = 0.2123163938522339, train/raw-loss = 0.09665403515100479, train/logprobs = tensor([[-1.2022, -6.2083],
        [-2.6014, -1.4869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.385541170835495
Epoch 0, Step 1130: train/loss = 0.2178034782409668, train/raw-loss = 0.12366601824760437, train/logprobs = tensor([[-2.0755, -5.6495],
        [-3.3815, -2.1969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31379151344299316
Epoch 0, Step 1131: train/loss = 0.4836864471435547, train/raw-loss = 0.4390477240085602, train/logprobs = tensor([[-1.9332, -3.7347],
        [-2.7065, -1.7715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14879575371742249
Epoch 0, Step 1132: train/loss = 0.22803527116775513, train/raw-loss = 0.14485590159893036, train/logprobs = tensor([[-2.3128, -6.3259],
        [-2.7311, -2.1668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2772645950317383
Epoch 0, Step 1133: train/loss = 0.4048060178756714, train/raw-loss = 0.34954991936683655, train/logprobs = tensor([[-2.1462, -5.0715],
        [-2.5223, -1.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1841871440410614
Epoch 0, Step 1134: train/loss = 0.17179185152053833, train/raw-loss = 0.05902668088674545, train/logprobs = tensor([[-1.9551, -8.5888],
        [-2.5608, -1.7176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37588387727737427
Epoch 0, Step 1135: train/loss = 0.3991755247116089, train/raw-loss = 0.3393906354904175, train/logprobs = tensor([[-2.9834, -4.1649],
        [-3.5393, -2.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1992829144001007
Epoch 0, Step 1136: train/loss = 0.2691863179206848, train/raw-loss = 0.17564338445663452, train/logprobs = tensor([[-1.5994, -6.6662],
        [-2.4217, -1.9006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.311809778213501
Epoch 0, Step 1137: train/loss = 0.48401346802711487, train/raw-loss = 0.39241746068000793, train/logprobs = tensor([[-2.7379, -6.4750],
        [-2.4102, -1.6038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3053200840950012
Epoch 0, Step 1138: train/loss = 0.36851704120635986, train/raw-loss = 0.31912869215011597, train/logprobs = tensor([[-2.0241, -3.5200],
        [-3.5286, -2.2199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1646278202533722
Epoch 0, Step 1139: train/loss = 0.48538392782211304, train/raw-loss = 0.44756466150283813, train/logprobs = tensor([[-2.4368, -3.8963],
        [-2.8587, -2.5514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1260642409324646
Epoch 0, Step 1140: train/loss = 0.3770610988140106, train/raw-loss = 0.316092848777771, train/logprobs = tensor([[-1.4502, -3.4381],
        [-2.3617, -1.6604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20322753489017487
Epoch 0, Step 1141: train/loss = 0.33819782733917236, train/raw-loss = 0.294145405292511, train/logprobs = tensor([[-1.5052, -5.2669],
        [-2.5682, -2.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14684143662452698
Epoch 0, Step 1142: train/loss = 0.22576767206192017, train/raw-loss = 0.12261476367712021, train/logprobs = tensor([[-2.4477, -4.5684],
        [-4.0186, -1.5681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3438430428504944
Epoch 0, Step 1143: train/loss = 0.3161323070526123, train/raw-loss = 0.23016387224197388, train/logprobs = tensor([[-2.3380, -8.7891],
        [-1.8795, -1.8479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28656136989593506
Epoch 0, Step 1144: train/loss = 0.29966628551483154, train/raw-loss = 0.23235802352428436, train/logprobs = tensor([[-1.3016, -6.1958],
        [-1.9850, -1.3337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22436083853244781
Epoch 0, Step 1145: train/loss = 0.23410028219223022, train/raw-loss = 0.14912289381027222, train/logprobs = tensor([[-1.7623, -5.0807],
        [-3.1658, -2.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28325796127319336
Epoch 0, Step 1146: train/loss = 0.19708305597305298, train/raw-loss = 0.10478855669498444, train/logprobs = tensor([[-1.5256, -5.6190],
        [-2.8532, -1.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30764830112457275
Epoch 0, Step 1147: train/loss = 0.19023439288139343, train/raw-loss = 0.07285068929195404, train/logprobs = tensor([[-1.6262, -6.8627],
        [-2.1128, -0.8075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.391279011964798
Epoch 0, Step 1148: train/loss = 0.2046683430671692, train/raw-loss = 0.11982715129852295, train/logprobs = tensor([[-1.6612, -7.3181],
        [-2.9087, -2.2324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2828039526939392
Epoch 0, Step 1149: train/loss = 0.2549918293952942, train/raw-loss = 0.18278011679649353, train/logprobs = tensor([[-1.9130, -4.2809],
        [-2.9723, -1.5412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2407057285308838
Epoch 0, Step 1150: train/loss = 0.25694459676742554, train/raw-loss = 0.15617984533309937, train/logprobs = tensor([[-2.7586, -7.5267],
        [-3.0576, -1.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3358825445175171
Epoch 0, Step 1151: train/loss = 0.22704435884952545, train/raw-loss = 0.12017963081598282, train/logprobs = tensor([[-2.2710, -5.4690],
        [-3.3860, -2.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.35621577501296997
Epoch 0, Step 1152: train/loss = 0.21587201952934265, train/raw-loss = 0.07975493371486664, train/logprobs = tensor([[-1.1990, -7.6758],
        [-2.4150, -1.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4537235498428345
Epoch 0, Step 1153: train/loss = 0.19411247968673706, train/raw-loss = 0.08333808183670044, train/logprobs = tensor([[-2.2346, -7.2058],
        [-2.2999, -1.2195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36924800276756287
Epoch 0, Step 1154: train/loss = 0.27209001779556274, train/raw-loss = 0.20330017805099487, train/logprobs = tensor([[-1.8150, -4.5820],
        [-2.2262, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22929945588111877
Epoch 0, Step 1155: train/loss = 0.2817089557647705, train/raw-loss = 0.2141234278678894, train/logprobs = tensor([[-2.1648, -4.6074],
        [-2.6589, -1.5955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22528505325317383
Epoch 0, Step 1156: train/loss = 0.4930054545402527, train/raw-loss = 0.44317686557769775, train/logprobs = tensor([[-1.5485, -3.3455],
        [-2.2030, -1.6843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16609522700309753
Epoch 0, Step 1157: train/loss = 0.34342437982559204, train/raw-loss = 0.25528669357299805, train/logprobs = tensor([[-2.4704, -5.3643],
        [-3.5953, -2.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2937922179698944
Epoch 0, Step 1158: train/loss = 0.4068785011768341, train/raw-loss = 0.320953905582428, train/logprobs = tensor([[-1.9177, -4.8179],
        [-3.2427, -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28641530871391296
Epoch 0, Step 1159: train/loss = 0.2739357054233551, train/raw-loss = 0.16706453263759613, train/logprobs = tensor([[-1.7545, -6.3944],
        [-2.6277, -1.3568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3562372028827667
Epoch 0, Step 1160: train/loss = 0.31700170040130615, train/raw-loss = 0.19909337162971497, train/logprobs = tensor([[-2.7480, -5.0691],
        [-3.8332, -1.3997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39302781224250793
Epoch 0, Step 1161: train/loss = 0.2592989206314087, train/raw-loss = 0.18077176809310913, train/logprobs = tensor([[-2.6585, -6.6032],
        [-2.8713, -2.1324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26175713539123535
Epoch 0, Step 1162: train/loss = 0.37562769651412964, train/raw-loss = 0.3276482820510864, train/logprobs = tensor([[-3.2940, -5.9525],
        [-2.7686, -1.9718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15993139147758484
Epoch 0, Step 1163: train/loss = 0.39454853534698486, train/raw-loss = 0.3289527893066406, train/logprobs = tensor([[-2.3816, -5.7141],
        [-3.3031, -2.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2186523675918579
Epoch 0, Step 1164: train/loss = 0.3824845850467682, train/raw-loss = 0.3351902663707733, train/logprobs = tensor([[-1.3442, -3.8978],
        [-2.5622, -2.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1576477438211441
Epoch 0, Step 1165: train/loss = 0.40386873483657837, train/raw-loss = 0.37707117199897766, train/logprobs = tensor([[-1.8272, -3.1977],
        [-2.4841, -2.0238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08932513743638992
Epoch 0, Step 1166: train/loss = 0.23146873712539673, train/raw-loss = 0.13076791167259216, train/logprobs = tensor([[-2.4179, -5.2301],
        [-3.7675, -2.0408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33566945791244507
Epoch 0, Step 1167: train/loss = 0.18828363716602325, train/raw-loss = 0.04281729459762573, train/logprobs = tensor([[-1.7333, -7.3434],
        [-3.4692, -1.9880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4848878085613251
Epoch 0, Step 1168: train/loss = 0.2924043536186218, train/raw-loss = 0.21870867908000946, train/logprobs = tensor([[-1.8429, -4.3230],
        [-3.2963, -2.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2456522285938263
Epoch 0, Step 1169: train/loss = 0.2988496422767639, train/raw-loss = 0.22796761989593506, train/logprobs = tensor([[-1.7825, -3.9600],
        [-3.1300, -1.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23627334833145142
Epoch 0, Step 1170: train/loss = 0.5271207690238953, train/raw-loss = 0.48500967025756836, train/logprobs = tensor([[-2.2085, -3.6003],
        [-2.8181, -2.4374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1403702348470688
Epoch 0, Step 1171: train/loss = 0.26978135108947754, train/raw-loss = 0.21320945024490356, train/logprobs = tensor([[-1.8837, -4.5825],
        [-2.9791, -2.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18857291340827942
Epoch 0, Step 1172: train/loss = 0.3375883102416992, train/raw-loss = 0.2694759964942932, train/logprobs = tensor([[-1.5050, -4.5471],
        [-2.5121, -1.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2270411103963852
Epoch 0, Step 1173: train/loss = 0.2089093029499054, train/raw-loss = 0.10075103491544724, train/logprobs = tensor([[-2.1466, -6.0010],
        [-3.4556, -2.2845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36052754521369934
Epoch 0, Step 1174: train/loss = 0.35559865832328796, train/raw-loss = 0.2928035259246826, train/logprobs = tensor([[-2.6904, -4.6289],
        [-3.4100, -2.6079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20931708812713623
Epoch 0, Step 1175: train/loss = 0.3480968475341797, train/raw-loss = 0.2906341552734375, train/logprobs = tensor([[-1.3243, -4.3513],
        [-2.2610, -1.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19154222309589386
Epoch 0, Step 1176: train/loss = 0.33232778310775757, train/raw-loss = 0.2687458395957947, train/logprobs = tensor([[-2.0617, -5.6530],
        [-2.5987, -1.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21193978190422058
Epoch 0, Step 1177: train/loss = 0.36229658126831055, train/raw-loss = 0.29835885763168335, train/logprobs = tensor([[-2.1477, -4.0581],
        [-2.5402, -1.5976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21312583982944489
Epoch 0, Step 1178: train/loss = 0.5819007754325867, train/raw-loss = 0.5769614577293396, train/logprobs = tensor([[-1.8786, -1.7269],
        [-2.5066, -1.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01646425761282444
Epoch 0, Step 1179: train/loss = 0.20764417946338654, train/raw-loss = 0.1349053680896759, train/logprobs = tensor([[-2.1666, -7.2333],
        [-2.5923, -2.3010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2424626648426056
Epoch 0, Step 1180: train/loss = 0.3367241322994232, train/raw-loss = 0.29853758215904236, train/logprobs = tensor([[-1.8889, -4.1365],
        [-2.9303, -2.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1272885650396347
Epoch 0, Step 1181: train/loss = 0.5107917189598083, train/raw-loss = 0.49461713433265686, train/logprobs = tensor([[-2.5499, -4.6893],
        [-1.9492, -2.3500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05391529202461243
Epoch 0, Step 1182: train/loss = 0.2971227169036865, train/raw-loss = 0.21200156211853027, train/logprobs = tensor([[-2.2351, -4.7869],
        [-3.7074, -2.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2837371230125427
Epoch 0, Step 1183: train/loss = 0.5568337440490723, train/raw-loss = 0.5246490240097046, train/logprobs = tensor([[-2.4420, -3.4931],
        [-2.4994, -2.3588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10728251188993454
Epoch 0, Step 1184: train/loss = 0.29444774985313416, train/raw-loss = 0.23778171837329865, train/logprobs = tensor([[-1.1178, -5.8280],
        [-2.3425, -2.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18888679146766663
Epoch 0, Step 1185: train/loss = 0.22323863208293915, train/raw-loss = 0.13772012293338776, train/logprobs = tensor([[-1.6632, -6.7136],
        [-3.0566, -2.6560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28506171703338623
Epoch 0, Step 1186: train/loss = 0.3118355870246887, train/raw-loss = 0.23632927238941193, train/logprobs = tensor([[-1.9664, -5.4159],
        [-3.0965, -2.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2516877055168152
Epoch 0, Step 1187: train/loss = 0.16930003464221954, train/raw-loss = 0.08335601538419724, train/logprobs = tensor([[-1.5260, -8.0100],
        [-2.7037, -2.3931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28648000955581665
Epoch 0, Step 1188: train/loss = 0.24800659716129303, train/raw-loss = 0.15906798839569092, train/logprobs = tensor([[-2.1857, -6.4529],
        [-2.9688, -2.3743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2964620292186737
Epoch 0, Step 1189: train/loss = 0.28486043214797974, train/raw-loss = 0.20277094841003418, train/logprobs = tensor([[-3.7017, -6.0719],
        [-3.6498, -1.9327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2736315131187439
Epoch 0, Step 1190: train/loss = 0.27005159854888916, train/raw-loss = 0.173148050904274, train/logprobs = tensor([[-2.2982, -5.9283],
        [-4.2711, -2.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32301175594329834
Epoch 0, Step 1191: train/loss = 0.25746750831604004, train/raw-loss = 0.16902875900268555, train/logprobs = tensor([[-1.9250, -4.4967],
        [-3.9487, -2.5007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29479584097862244
Epoch 0, Step 1192: train/loss = 0.3822036385536194, train/raw-loss = 0.3441292345523834, train/logprobs = tensor([[-1.5186, -3.4305],
        [-3.0607, -2.1175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12691478431224823
Epoch 0, Step 1193: train/loss = 0.3283231258392334, train/raw-loss = 0.2810078561306, train/logprobs = tensor([[-1.8056, -4.9133],
        [-2.3031, -1.9869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15771758556365967
Epoch 0, Step 1194: train/loss = 0.218761146068573, train/raw-loss = 0.07242906093597412, train/logprobs = tensor([[-2.7809, -6.8378],
        [-4.5713, -2.5477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.487773597240448
Epoch 0, Step 1195: train/loss = 0.2760452926158905, train/raw-loss = 0.18216575682163239, train/logprobs = tensor([[-3.3879, -8.0822],
        [-3.2808, -1.8413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129318356513977
Epoch 0, Step 1196: train/loss = 0.28741782903671265, train/raw-loss = 0.15957242250442505, train/logprobs = tensor([[-2.1332, -5.8750],
        [-3.6276, -1.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4261512756347656
Epoch 0, Step 1197: train/loss = 0.2670357823371887, train/raw-loss = 0.1772693395614624, train/logprobs = tensor([[-2.1919, -7.1396],
        [-2.4458, -2.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2992214560508728
Epoch 0, Step 1198: train/loss = 0.23338112235069275, train/raw-loss = 0.1372673064470291, train/logprobs = tensor([[-1.6514, -5.3930],
        [-3.3396, -2.2933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3203793466091156
Epoch 0, Step 1199: train/loss = 0.38575679063796997, train/raw-loss = 0.31801679730415344, train/logprobs = tensor([[-1.9527, -6.0343],
        [-3.3434, -2.8908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2257998287677765
Epoch 0, Step 1200: train/loss = 0.36930394172668457, train/raw-loss = 0.28871697187423706, train/logprobs = tensor([[-2.4172, -6.8145],
        [-2.6034, -1.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2686232030391693
Epoch 0, Step 1201: train/loss = 0.2854450047016144, train/raw-loss = 0.22458195686340332, train/logprobs = tensor([[-2.1955, -6.8579],
        [-3.4369, -3.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2028767317533493
Epoch 0, Step 1202: train/loss = 0.34864985942840576, train/raw-loss = 0.2808084487915039, train/logprobs = tensor([[-0.9778, -4.1143],
        [-2.0634, -1.4683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22613808512687683
Epoch 0, Step 1203: train/loss = 0.7372341752052307, train/raw-loss = 0.712862491607666, train/logprobs = tensor([[-3.7608, -4.8606],
        [-2.2889, -2.3185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08123881369829178
Epoch 0, Step 1204: train/loss = 0.2008107453584671, train/raw-loss = 0.08023083955049515, train/logprobs = tensor([[-2.2713, -7.0959],
        [-2.7413, -1.6412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4019330143928528
Epoch 0, Step 1205: train/loss = 0.30845317244529724, train/raw-loss = 0.23742589354515076, train/logprobs = tensor([[-2.1999, -6.2953],
        [-2.7738, -2.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2367575615644455
Epoch 0, Step 1206: train/loss = 0.3547153174877167, train/raw-loss = 0.2825748920440674, train/logprobs = tensor([[-2.3264, -4.0507],
        [-3.9600, -2.5869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24046798050403595
Epoch 0, Step 1207: train/loss = 0.8141908645629883, train/raw-loss = 0.7845578789710999, train/logprobs = tensor([[-3.8695, -4.2027],
        [-2.4720, -2.5122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09877654910087585
Epoch 0, Step 1208: train/loss = 0.48992979526519775, train/raw-loss = 0.44823354482650757, train/logprobs = tensor([[-1.9873, -3.6217],
        [-2.2645, -1.8239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13898755609989166
Epoch 0, Step 1209: train/loss = 0.6970053911209106, train/raw-loss = 0.6345515847206116, train/logprobs = tensor([[-3.3036, -4.4033],
        [-3.8295, -2.6067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2081795036792755
Epoch 0, Step 1210: train/loss = 0.2274978756904602, train/raw-loss = 0.13880857825279236, train/logprobs = tensor([[-1.8133, -5.6142],
        [-2.7632, -1.6279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29563093185424805
Epoch 0, Step 1211: train/loss = 0.3883117437362671, train/raw-loss = 0.33519500494003296, train/logprobs = tensor([[-1.7486, -4.3519],
        [-3.1326, -2.4649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17705583572387695
Epoch 0, Step 1212: train/loss = 0.2293095588684082, train/raw-loss = 0.15001454949378967, train/logprobs = tensor([[-1.6238, -6.6650],
        [-3.2576, -2.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26431670784950256
Epoch 0, Step 1213: train/loss = 0.4468953609466553, train/raw-loss = 0.4007987976074219, train/logprobs = tensor([[-2.3945, -3.9620],
        [-2.7009, -2.2230]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1536552459001541
Epoch 0, Step 1214: train/loss = 0.2602260410785675, train/raw-loss = 0.20758086442947388, train/logprobs = tensor([[-1.3208, -6.6232],
        [-2.4699, -3.0384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17548391222953796
Epoch 0, Step 1215: train/loss = 0.19432580471038818, train/raw-loss = 0.10698484629392624, train/logprobs = tensor([[-2.6014, -6.6740],
        [-3.9196, -3.0320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29113656282424927
Epoch 0, Step 1216: train/loss = 0.2632257342338562, train/raw-loss = 0.10603825747966766, train/logprobs = tensor([[-1.9824, -8.6635],
        [-4.2029, -2.5445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5239582061767578
Epoch 0, Step 1217: train/loss = 0.32763248682022095, train/raw-loss = 0.2752036154270172, train/logprobs = tensor([[-2.0846, -4.3992],
        [-3.3789, -2.5788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17476294934749603
Epoch 0, Step 1218: train/loss = 0.3293251097202301, train/raw-loss = 0.21715699136257172, train/logprobs = tensor([[-3.1694, -5.0289],
        [-5.3388, -2.7227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37389373779296875
Epoch 0, Step 1219: train/loss = 0.23281152546405792, train/raw-loss = 0.14249981939792633, train/logprobs = tensor([[-2.3631, -7.2340],
        [-2.5732, -1.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3010390102863312
Epoch 0, Step 1220: train/loss = 0.40632057189941406, train/raw-loss = 0.30670785903930664, train/logprobs = tensor([[-2.8758, -6.1109],
        [-4.2208, -2.5685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33204227685928345
Epoch 0, Step 1221: train/loss = 0.29250168800354004, train/raw-loss = 0.22214320302009583, train/logprobs = tensor([[-2.7053, -5.6160],
        [-4.2650, -3.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23452824354171753
Epoch 0, Step 1222: train/loss = 0.20118802785873413, train/raw-loss = 0.05043378099799156, train/logprobs = tensor([[-2.9346, -7.8067],
        [-3.2848, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5025141835212708
Epoch 0, Step 1223: train/loss = 0.26940426230430603, train/raw-loss = 0.19936712086200714, train/logprobs = tensor([[-2.7226, -5.7869],
        [-3.5353, -2.2461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2334570735692978
Epoch 0, Step 1224: train/loss = 0.4221849739551544, train/raw-loss = 0.3695659637451172, train/logprobs = tensor([[-2.2735, -5.1149],
        [-2.9885, -2.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17539674043655396
Epoch 0, Step 1225: train/loss = 0.2783602476119995, train/raw-loss = 0.11241420358419418, train/logprobs = tensor([[-2.6384, -6.6943],
        [-5.1235, -2.2637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5531534552574158
Epoch 0, Step 1226: train/loss = 0.21533435583114624, train/raw-loss = 0.12372481822967529, train/logprobs = tensor([[-1.9042, -7.9316],
        [-3.6018, -2.5163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30536505579948425
Epoch 0, Step 1227: train/loss = 0.3164486289024353, train/raw-loss = 0.26418939232826233, train/logprobs = tensor([[-2.1794, -6.3809],
        [-3.5217, -3.0838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1741974800825119
Epoch 0, Step 1228: train/loss = 0.36319392919540405, train/raw-loss = 0.3020559847354889, train/logprobs = tensor([[-2.3590, -6.9203],
        [-3.0498, -2.4275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20379316806793213
Epoch 0, Step 1229: train/loss = 0.31161177158355713, train/raw-loss = 0.24962784349918365, train/logprobs = tensor([[-1.8514, -6.7469],
        [-2.5223, -2.4504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2066129595041275
Epoch 0, Step 1230: train/loss = 0.20177608728408813, train/raw-loss = 0.11829400062561035, train/logprobs = tensor([[-1.8546, -6.5214],
        [-2.6960, -2.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2782735824584961
Epoch 0, Step 1231: train/loss = 0.26808109879493713, train/raw-loss = 0.11248402297496796, train/logprobs = tensor([[-2.3164, -6.7082],
        [-4.6068, -2.6596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5186569094657898
Epoch 0, Step 1232: train/loss = 0.3834266662597656, train/raw-loss = 0.3462468087673187, train/logprobs = tensor([[-1.8014, -4.7564],
        [-2.3684, -2.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12393288314342499
Epoch 0, Step 1233: train/loss = 0.33658549189567566, train/raw-loss = 0.25433993339538574, train/logprobs = tensor([[-2.0649, -8.2580],
        [-2.8355, -2.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27415183186531067
Epoch 0, Step 1234: train/loss = 0.20063546299934387, train/raw-loss = 0.06342609971761703, train/logprobs = tensor([[-2.2711, -9.7783],
        [-2.8734, -1.5003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4573645293712616
Epoch 0, Step 1235: train/loss = 0.2851077616214752, train/raw-loss = 0.24910253286361694, train/logprobs = tensor([[-1.6029, -6.8143],
        [-2.2733, -2.8637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12001744657754898
Epoch 0, Step 1236: train/loss = 0.2062022089958191, train/raw-loss = 0.11031772196292877, train/logprobs = tensor([[-2.4404, -6.2982],
        [-3.6411, -1.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.319614976644516
Epoch 0, Step 1237: train/loss = 0.23183892667293549, train/raw-loss = 0.1313355267047882, train/logprobs = tensor([[-2.2480, -7.4470],
        [-3.6949, -2.9595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3350112736225128
Epoch 0, Step 1238: train/loss = 0.2964485287666321, train/raw-loss = 0.2062239646911621, train/logprobs = tensor([[-1.4880, -7.6326],
        [-3.2396, -2.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3007485866546631
Epoch 0, Step 1239: train/loss = 0.3333163857460022, train/raw-loss = 0.28221866488456726, train/logprobs = tensor([[-2.7498, -5.1199],
        [-3.5128, -2.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17032569646835327
Epoch 0, Step 1240: train/loss = 0.27364346385002136, train/raw-loss = 0.16503778100013733, train/logprobs = tensor([[-2.3689, -6.0697],
        [-3.5755, -1.8015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3620189428329468
Epoch 0, Step 1241: train/loss = 0.3072722852230072, train/raw-loss = 0.22394610941410065, train/logprobs = tensor([[-2.1869, -6.1268],
        [-3.7226, -2.7851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27775391936302185
Epoch 0, Step 1242: train/loss = 0.25661349296569824, train/raw-loss = 0.17036576569080353, train/logprobs = tensor([[-2.4192, -5.5014],
        [-3.7089, -2.6835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2874923348426819
Epoch 0, Step 1243: train/loss = 0.2426277995109558, train/raw-loss = 0.1231544241309166, train/logprobs = tensor([[-2.6232, -6.8737],
        [-3.1414, -1.3985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39824455976486206
Epoch 0, Step 1244: train/loss = 0.3299214541912079, train/raw-loss = 0.254655122756958, train/logprobs = tensor([[-2.9253, -6.7303],
        [-2.9302, -2.5604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2508876919746399
Epoch 0, Step 1245: train/loss = 0.20157292485237122, train/raw-loss = 0.03666914999485016, train/logprobs = tensor([[-2.5072, -7.1362],
        [-4.7729, -1.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.549679160118103
Epoch 0, Step 1246: train/loss = 0.2064361274242401, train/raw-loss = 0.09698081016540527, train/logprobs = tensor([[-2.3729, -7.9242],
        [-3.6148, -2.3628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3648509979248047
Epoch 0, Step 1247: train/loss = 0.5012664794921875, train/raw-loss = 0.468536376953125, train/logprobs = tensor([[-2.1082, -2.7742],
        [-3.0830, -2.2993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10910030454397202
Epoch 0, Step 1248: train/loss = 0.24059662222862244, train/raw-loss = 0.1455618292093277, train/logprobs = tensor([[-2.6482, -6.5696],
        [-3.1487, -1.5628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3167826533317566
Epoch 0, Step 1249: train/loss = 0.44347041845321655, train/raw-loss = 0.37172096967697144, train/logprobs = tensor([[-2.4227, -5.4673],
        [-3.6484, -2.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.239164799451828
Epoch 0, Step 1250: train/loss = 0.17622047662734985, train/raw-loss = 0.042070336639881134, train/logprobs = tensor([[ -1.8901, -10.2750],
        [ -3.5329,  -2.3922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44716715812683105
Epoch 0, Step 1251: train/loss = 0.2682146430015564, train/raw-loss = 0.16057027876377106, train/logprobs = tensor([[-2.4138, -6.6503],
        [-3.5075, -2.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3588144779205322
Epoch 0, Step 1252: train/loss = 0.20934700965881348, train/raw-loss = 0.10154227912425995, train/logprobs = tensor([[-2.6660, -8.0838],
        [-4.0352, -2.6213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3593490719795227
Epoch 0, Step 1253: train/loss = 0.6015090942382812, train/raw-loss = 0.5469136238098145, train/logprobs = tensor([[-2.4531, -4.5698],
        [-2.6902, -2.1358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18198469281196594
Epoch 0, Step 1254: train/loss = 0.5186284780502319, train/raw-loss = 0.4898820221424103, train/logprobs = tensor([[-1.9030, -4.2497],
        [-2.3657, -2.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09582149237394333
Epoch 0, Step 1255: train/loss = 0.26827043294906616, train/raw-loss = 0.20206321775913239, train/logprobs = tensor([[-2.2848, -5.0256],
        [-3.6249, -2.3605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2206907421350479
Epoch 0, Step 1256: train/loss = 0.2023565173149109, train/raw-loss = 0.10992737114429474, train/logprobs = tensor([[-4.2991, -7.3043],
        [-4.0164, -1.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30809712409973145
Epoch 0, Step 1257: train/loss = 0.20399896800518036, train/raw-loss = 0.04893447458744049, train/logprobs = tensor([[-2.6178, -8.5850],
        [-4.3642, -2.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5168817043304443
Epoch 0, Step 1258: train/loss = 0.28501462936401367, train/raw-loss = 0.17350628972053528, train/logprobs = tensor([[-2.3318, -6.8328],
        [-3.9118, -1.9578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37169450521469116
Epoch 0, Step 1259: train/loss = 0.20558816194534302, train/raw-loss = 0.09172545373439789, train/logprobs = tensor([[-2.3379, -9.9230],
        [-3.2236, -2.0378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3795423209667206
Epoch 0, Step 1260: train/loss = 0.20568014681339264, train/raw-loss = 0.06476275622844696, train/logprobs = tensor([[-2.1407, -6.9830],
        [-3.8428, -2.0394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4697245955467224
Epoch 0, Step 1261: train/loss = 0.6208837628364563, train/raw-loss = 0.5971903204917908, train/logprobs = tensor([[-1.7770, -5.1675],
        [-2.4979, -4.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07897819578647614
Epoch 0, Step 1262: train/loss = 0.21547681093215942, train/raw-loss = 0.16088104248046875, train/logprobs = tensor([[-1.9977, -6.7905],
        [-2.9524, -2.6159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18198585510253906
Epoch 0, Step 1263: train/loss = 0.3456116318702698, train/raw-loss = 0.27838367223739624, train/logprobs = tensor([[-1.5407, -7.8564],
        [-2.5453, -2.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22409319877624512
Epoch 0, Step 1264: train/loss = 0.21837222576141357, train/raw-loss = 0.04624182730913162, train/logprobs = tensor([[-2.4999, -8.9233],
        [-3.6525, -1.6619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5737680196762085
Epoch 0, Step 1265: train/loss = 0.3114199936389923, train/raw-loss = 0.2135051190853119, train/logprobs = tensor([[-2.9878, -5.6743],
        [-4.4773, -2.6584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32638293504714966
Epoch 0, Step 1266: train/loss = 0.2684629559516907, train/raw-loss = 0.20525771379470825, train/logprobs = tensor([[-2.5755, -7.2236],
        [-3.6466, -3.7515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21068409085273743
Epoch 0, Step 1267: train/loss = 0.31636524200439453, train/raw-loss = 0.19864532351493835, train/logprobs = tensor([[-2.4726, -7.7655],
        [-3.9726, -2.3142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39239969849586487
Epoch 0, Step 1268: train/loss = 0.33619415760040283, train/raw-loss = 0.28145289421081543, train/logprobs = tensor([[-1.9356, -5.3363],
        [-2.6561, -2.4669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1824709177017212
Epoch 0, Step 1269: train/loss = 0.245139017701149, train/raw-loss = 0.13159023225307465, train/logprobs = tensor([[-2.1208, -6.5117],
        [-3.0800, -2.1648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3784959316253662
Epoch 0, Step 1270: train/loss = 0.24078331887722015, train/raw-loss = 0.1484692543745041, train/logprobs = tensor([[-2.1234, -5.2939],
        [-4.2338, -3.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3077135384082794
Epoch 0, Step 1271: train/loss = 0.3772526979446411, train/raw-loss = 0.32074135541915894, train/logprobs = tensor([[-1.7637, -4.7436],
        [-2.3441, -1.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18837106227874756
Epoch 0, Step 1272: train/loss = 0.2806188464164734, train/raw-loss = 0.20592984557151794, train/logprobs = tensor([[-2.3909, -6.9107],
        [-2.9693, -2.2036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2489633411169052
Epoch 0, Step 1273: train/loss = 0.32127487659454346, train/raw-loss = 0.2291451096534729, train/logprobs = tensor([[-2.8160, -5.8525],
        [-3.4389, -2.0736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3070991337299347
Epoch 0, Step 1274: train/loss = 0.26657113432884216, train/raw-loss = 0.21021756529808044, train/logprobs = tensor([[-1.7239, -6.9874],
        [-3.1963, -3.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1878451704978943
Epoch 0, Step 1275: train/loss = 0.273410826921463, train/raw-loss = 0.19512459635734558, train/logprobs = tensor([[-2.4599, -5.9345],
        [-3.8635, -2.4981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2609541118144989
Epoch 0, Step 1276: train/loss = 0.20446179807186127, train/raw-loss = 0.1086072251200676, train/logprobs = tensor([[-1.6585, -6.2709],
        [-2.1034, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31951525807380676
Epoch 0, Step 1277: train/loss = 0.8118724226951599, train/raw-loss = 0.7722214460372925, train/logprobs = tensor([[-1.9570, -4.0550],
        [-2.1339, -2.4512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13216997683048248
Epoch 0, Step 1278: train/loss = 0.2937055230140686, train/raw-loss = 0.22919990122318268, train/logprobs = tensor([[-2.3448, -6.9844],
        [-3.4170, -2.9195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21501874923706055
Epoch 0, Step 1279: train/loss = 0.2923903465270996, train/raw-loss = 0.2512957751750946, train/logprobs = tensor([[-1.7595, -7.2440],
        [-3.2758, -3.8049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13698187470436096
Epoch 0, Step 1280: train/loss = 0.3761807084083557, train/raw-loss = 0.31556206941604614, train/logprobs = tensor([[-1.9114, -7.2487],
        [-2.4365, -2.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20206212997436523
Epoch 0, Step 1281: train/loss = 0.1713188886642456, train/raw-loss = 0.06091926991939545, train/logprobs = tensor([[-2.0126, -9.1305],
        [-3.2049, -2.5564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36799871921539307
Epoch 0, Step 1282: train/loss = 0.4475177824497223, train/raw-loss = 0.38348978757858276, train/logprobs = tensor([[-3.2070, -6.4298],
        [-3.6380, -3.3591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2134266495704651
Epoch 0, Step 1283: train/loss = 0.1866980493068695, train/raw-loss = 0.05381914973258972, train/logprobs = tensor([[-2.4098, -8.6579],
        [-3.7631, -2.0884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429297149181366
Epoch 0, Step 1284: train/loss = 0.20464956760406494, train/raw-loss = 0.11910013854503632, train/logprobs = tensor([[-1.8036, -7.2595],
        [-2.6135, -2.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28516483306884766
Epoch 0, Step 1285: train/loss = 0.3155774474143982, train/raw-loss = 0.2226366400718689, train/logprobs = tensor([[-1.9871, -6.1905],
        [-3.0999, -1.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30980271100997925
Epoch 0, Step 1286: train/loss = 0.47654712200164795, train/raw-loss = 0.45193278789520264, train/logprobs = tensor([[-3.6730, -4.9772],
        [-2.6119, -2.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08204769343137741
Epoch 0, Step 1287: train/loss = 0.2605894207954407, train/raw-loss = 0.16132506728172302, train/logprobs = tensor([[ -1.9351, -10.2645],
        [ -3.0650,  -3.2736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33088117837905884
Epoch 0, Step 1288: train/loss = 0.25141090154647827, train/raw-loss = 0.17583666741847992, train/logprobs = tensor([[-2.9332, -6.4982],
        [-4.3086, -3.4321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2519141733646393
Epoch 0, Step 1289: train/loss = 0.23685462772846222, train/raw-loss = 0.06375496089458466, train/logprobs = tensor([[-3.2439, -8.2386],
        [-5.3668, -3.4201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5769988894462585
Epoch 0, Step 1290: train/loss = 0.38874366879463196, train/raw-loss = 0.32720819115638733, train/logprobs = tensor([[-2.3574, -4.3558],
        [-3.8608, -3.2210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20511817932128906
Epoch 0, Step 1291: train/loss = 0.2529285252094269, train/raw-loss = 0.17736907303333282, train/logprobs = tensor([[-2.6820, -7.6858],
        [-3.7791, -3.4948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25186485052108765
Epoch 0, Step 1292: train/loss = 0.43348121643066406, train/raw-loss = 0.39693036675453186, train/logprobs = tensor([[-4.3226, -5.4013],
        [-3.9017, -2.3941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12183616310358047
Epoch 0, Step 1293: train/loss = 0.40505021810531616, train/raw-loss = 0.3441300392150879, train/logprobs = tensor([[-2.1069, -3.6304],
        [-3.1654, -1.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20306716859340668
Epoch 0, Step 1294: train/loss = 0.1926090568304062, train/raw-loss = 0.10703285038471222, train/logprobs = tensor([[-2.3433, -8.0298],
        [-2.7989, -2.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28525397181510925
Epoch 0, Step 1295: train/loss = 0.4125610589981079, train/raw-loss = 0.3420534133911133, train/logprobs = tensor([[-2.3182, -5.7766],
        [-3.3983, -2.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23502543568611145
Epoch 0, Step 1296: train/loss = 0.1905859410762787, train/raw-loss = 0.081209197640419, train/logprobs = tensor([[-2.2436, -9.6359],
        [-4.1036, -3.9692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3645891547203064
Epoch 0, Step 1297: train/loss = 0.2669670581817627, train/raw-loss = 0.19821736216545105, train/logprobs = tensor([[-2.4270, -5.9907],
        [-2.5099, -1.7210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22916558384895325
Epoch 0, Step 1298: train/loss = 0.48460152745246887, train/raw-loss = 0.4366574287414551, train/logprobs = tensor([[-4.3290, -6.7160],
        [-3.7878, -2.5192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15981373190879822
Epoch 0, Step 1299: train/loss = 0.27819567918777466, train/raw-loss = 0.19936344027519226, train/logprobs = tensor([[-3.6733, -9.2794],
        [-3.0200, -2.4040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2627740502357483
Epoch 0, Step 1300: train/loss = 0.2513428330421448, train/raw-loss = 0.16765567660331726, train/logprobs = tensor([[-2.0091, -6.8749],
        [-2.8449, -2.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2789573073387146
Epoch 0, Step 1301: train/loss = 0.3887312710285187, train/raw-loss = 0.3323802947998047, train/logprobs = tensor([[-2.8100, -6.7508],
        [-3.4411, -3.9529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18783651292324066
Epoch 0, Step 1302: train/loss = 0.3033980131149292, train/raw-loss = 0.23040059208869934, train/logprobs = tensor([[-2.1931, -9.4462],
        [-2.7644, -2.7963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24332468211650848
Epoch 0, Step 1303: train/loss = 0.2383713573217392, train/raw-loss = 0.11251413077116013, train/logprobs = tensor([[-2.3730, -9.1313],
        [-3.4371, -2.6142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41952404379844666
Epoch 0, Step 1304: train/loss = 0.2944868206977844, train/raw-loss = 0.18894599378108978, train/logprobs = tensor([[-3.3316, -7.3183],
        [-3.4067, -1.5521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.351802796125412
Epoch 0, Step 1305: train/loss = 0.25967687368392944, train/raw-loss = 0.17975091934204102, train/logprobs = tensor([[-2.4831, -6.8415],
        [-3.2148, -2.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2664198577404022
Epoch 0, Step 1306: train/loss = 0.49354273080825806, train/raw-loss = 0.43942874670028687, train/logprobs = tensor([[-2.8450, -7.4585],
        [-3.0441, -2.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18037982285022736
Epoch 0, Step 1307: train/loss = 0.2940467596054077, train/raw-loss = 0.2376859188079834, train/logprobs = tensor([[-2.8897, -4.8227],
        [-4.1534, -3.2201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18786945939064026
Epoch 0, Step 1308: train/loss = 0.2024373561143875, train/raw-loss = 0.06222309172153473, train/logprobs = tensor([[-3.6778, -8.4289],
        [-4.5052, -1.6744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4673808515071869
Epoch 0, Step 1309: train/loss = 0.2124621421098709, train/raw-loss = 0.049540720880031586, train/logprobs = tensor([[-2.3831, -8.7671],
        [-4.4910, -2.2279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.543071448802948
Epoch 0, Step 1310: train/loss = 0.31525105237960815, train/raw-loss = 0.20469288527965546, train/logprobs = tensor([[ -3.4707, -10.3035],
        [ -3.9487,  -2.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36852720379829407
Epoch 0, Step 1311: train/loss = 0.2572762668132782, train/raw-loss = 0.15402744710445404, train/logprobs = tensor([[-2.4487, -7.2105],
        [-3.6332, -2.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3441627621650696
Epoch 0, Step 1312: train/loss = 0.2905040383338928, train/raw-loss = 0.2043672353029251, train/logprobs = tensor([[-2.4549, -5.6379],
        [-4.6522, -3.8427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2871226668357849
Epoch 0, Step 1313: train/loss = 0.33876872062683105, train/raw-loss = 0.25239449739456177, train/logprobs = tensor([[-3.1038, -5.4419],
        [-4.1502, -1.9933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28791409730911255
Epoch 0, Step 1314: train/loss = 0.1944112479686737, train/raw-loss = 0.09099982678890228, train/logprobs = tensor([[-2.1833, -8.9747],
        [-3.3404, -2.7596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34470468759536743
Epoch 0, Step 1315: train/loss = 0.4122307300567627, train/raw-loss = 0.3163311779499054, train/logprobs = tensor([[-3.6657, -6.8500],
        [-4.0910, -2.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31966516375541687
Epoch 0, Step 1316: train/loss = 0.29977235198020935, train/raw-loss = 0.17093299329280853, train/logprobs = tensor([[-2.3856, -6.8107],
        [-4.5552, -2.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4294644892215729
Epoch 0, Step 1317: train/loss = 0.29177987575531006, train/raw-loss = 0.17693102359771729, train/logprobs = tensor([[-2.7923, -8.7133],
        [-3.8044, -2.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3828295171260834
Epoch 0, Step 1318: train/loss = 0.22079996764659882, train/raw-loss = 0.11971733719110489, train/logprobs = tensor([[-3.2521, -9.8085],
        [-3.3727, -2.8707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33694204688072205
Epoch 0, Step 1319: train/loss = 0.1975715458393097, train/raw-loss = 0.029362626373767853, train/logprobs = tensor([[-2.5229, -9.6797],
        [-4.6316, -1.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5606964230537415
Epoch 0, Step 1320: train/loss = 0.26449909806251526, train/raw-loss = 0.16391627490520477, train/logprobs = tensor([[-3.9305, -7.8462],
        [-4.5671, -2.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352760672569275
Epoch 0, Step 1321: train/loss = 0.41679996252059937, train/raw-loss = 0.3088023364543915, train/logprobs = tensor([[-3.4363, -7.7316],
        [-3.0174, -2.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3599920868873596
Epoch 0, Step 1322: train/loss = 0.25546738505363464, train/raw-loss = 0.1392401158809662, train/logprobs = tensor([[-4.0645, -7.4789],
        [-4.0142, -2.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38742417097091675
Epoch 0, Step 1323: train/loss = 0.30489128828048706, train/raw-loss = 0.21127857267856598, train/logprobs = tensor([[-2.1719, -6.7098],
        [-4.6945, -3.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3120422959327698
Epoch 0, Step 1324: train/loss = 0.4018726944923401, train/raw-loss = 0.27266818284988403, train/logprobs = tensor([[-3.0617, -9.0373],
        [-3.4622, -2.0611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4306817054748535
Epoch 0, Step 1325: train/loss = 0.28357523679733276, train/raw-loss = 0.17329886555671692, train/logprobs = tensor([[-2.5940, -5.7512],
        [-3.8153, -1.6072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3675879240036011
Epoch 0, Step 1326: train/loss = 0.4334118962287903, train/raw-loss = 0.3804199695587158, train/logprobs = tensor([[-3.0624, -5.4803],
        [-3.8131, -2.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17663972079753876
Epoch 0, Step 1327: train/loss = 0.2853884696960449, train/raw-loss = 0.17545631527900696, train/logprobs = tensor([[-2.6729, -5.8534],
        [-4.9246, -2.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3664405345916748
Epoch 0, Step 1328: train/loss = 0.45684653520584106, train/raw-loss = 0.3239547610282898, train/logprobs = tensor([[-3.6920, -7.2508],
        [-3.0299, -1.5638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4429726302623749
Epoch 0, Step 1329: train/loss = 0.19888363778591156, train/raw-loss = 0.06204046308994293, train/logprobs = tensor([[-2.4946, -8.1688],
        [-5.1196, -3.2266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45614391565322876
Epoch 0, Step 1330: train/loss = 0.24325105547904968, train/raw-loss = 0.07062647491693497, train/logprobs = tensor([[-3.6044, -9.4660],
        [-4.7570, -2.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5754152536392212
Epoch 0, Step 1331: train/loss = 0.22572912275791168, train/raw-loss = 0.10724160820245743, train/logprobs = tensor([[-2.5830, -7.3574],
        [-3.5372, -2.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39495837688446045
Epoch 0, Step 1332: train/loss = 0.40178024768829346, train/raw-loss = 0.29276275634765625, train/logprobs = tensor([[-1.7787, -6.6003],
        [-2.9301, -2.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36339160799980164
Epoch 0, Step 1333: train/loss = 0.26523256301879883, train/raw-loss = 0.17043176293373108, train/logprobs = tensor([[-3.6067, -7.9471],
        [-3.8965, -2.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3160024881362915
Epoch 0, Step 1334: train/loss = 0.29862427711486816, train/raw-loss = 0.24021825194358826, train/logprobs = tensor([[-2.5960, -5.0658],
        [-3.5294, -3.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1946866512298584
Epoch 0, Step 1335: train/loss = 0.19712291657924652, train/raw-loss = 0.10725829750299454, train/logprobs = tensor([[-2.4994, -7.6300],
        [-4.6455, -4.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2995486855506897
Epoch 0, Step 1336: train/loss = 0.32992416620254517, train/raw-loss = 0.2026517689228058, train/logprobs = tensor([[-3.9783, -7.6078],
        [-3.0879, -1.6111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42424139380455017
Epoch 0, Step 1337: train/loss = 0.2027730643749237, train/raw-loss = 0.02511760964989662, train/logprobs = tensor([[-3.1790, -8.9394],
        [-4.5105, -1.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5921847820281982
Epoch 0, Step 1338: train/loss = 0.24765928089618683, train/raw-loss = 0.12871697545051575, train/logprobs = tensor([[-2.4582, -8.3683],
        [-4.4936, -3.6844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39647430181503296
Epoch 0, Step 1339: train/loss = 0.35131263732910156, train/raw-loss = 0.19842517375946045, train/logprobs = tensor([[-2.5046, -7.4362],
        [-4.3779, -2.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5096248388290405
Epoch 0, Step 1340: train/loss = 0.3426692485809326, train/raw-loss = 0.23213161528110504, train/logprobs = tensor([[-3.3657, -9.6186],
        [-4.3527, -3.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36845874786376953
Epoch 0, Step 1341: train/loss = 0.2810613512992859, train/raw-loss = 0.20267589390277863, train/logprobs = tensor([[-2.5004, -8.6922],
        [-3.2023, -2.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2612849473953247
Epoch 0, Step 1342: train/loss = 0.2182668149471283, train/raw-loss = 0.07141906023025513, train/logprobs = tensor([[-3.2655, -6.6498],
        [-4.9711, -1.9283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4894924759864807
Epoch 0, Step 1343: train/loss = 0.26728692650794983, train/raw-loss = 0.15151745080947876, train/logprobs = tensor([[ -3.7756, -10.0833],
        [ -3.8461,  -2.5073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38589829206466675
Epoch 0, Step 1344: train/loss = 0.3584553599357605, train/raw-loss = 0.1958669126033783, train/logprobs = tensor([[-3.0825, -9.3069],
        [-3.7904, -2.0638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5419615507125854
Epoch 0, Step 1345: train/loss = 0.19885924458503723, train/raw-loss = 0.04020599275827408, train/logprobs = tensor([[-3.1887, -7.6721],
        [-4.3703, -1.5224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5288441181182861
Epoch 0, Step 1346: train/loss = 0.38354188203811646, train/raw-loss = 0.2921839952468872, train/logprobs = tensor([[-2.7041, -4.9006],
        [-4.5762, -3.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30452635884284973
Epoch 0, Step 1347: train/loss = 0.403619647026062, train/raw-loss = 0.3295455276966095, train/logprobs = tensor([[-3.1856, -6.4892],
        [-3.2388, -2.5114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24691371619701385
Epoch 0, Step 1348: train/loss = 0.27963197231292725, train/raw-loss = 0.1381138414144516, train/logprobs = tensor([[-2.7602, -9.3483],
        [-4.8690, -3.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4717271327972412
Epoch 0, Step 1349: train/loss = 0.19326353073120117, train/raw-loss = 0.06237446144223213, train/logprobs = tensor([[-2.9947, -9.8552],
        [-2.9427, -1.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43629688024520874
Epoch 0, Step 1350: train/loss = 0.20238623023033142, train/raw-loss = 0.07473569363355637, train/logprobs = tensor([[-3.1226, -9.6742],
        [-3.9879, -2.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4255017936229706
Epoch 0, Step 1351: train/loss = 0.3734374940395355, train/raw-loss = 0.30514442920684814, train/logprobs = tensor([[-2.0204, -4.7244],
        [-4.4029, -2.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2276434451341629
Epoch 0, Step 1352: train/loss = 0.28505775332450867, train/raw-loss = 0.18289990723133087, train/logprobs = tensor([[-2.4669, -5.8903],
        [-3.7379, -2.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34052613377571106
Epoch 0, Step 1353: train/loss = 0.32408279180526733, train/raw-loss = 0.24306367337703705, train/logprobs = tensor([[-2.6640, -5.9067],
        [-4.8108, -2.6958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27006372809410095
Epoch 0, Step 1354: train/loss = 0.3240356743335724, train/raw-loss = 0.25280264019966125, train/logprobs = tensor([[-1.6476, -6.2999],
        [-3.7887, -3.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23744340240955353
Epoch 0, Step 1355: train/loss = 0.5244410634040833, train/raw-loss = 0.46561306715011597, train/logprobs = tensor([[-5.3919, -7.9254],
        [-4.5897, -4.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19609327614307404
Epoch 0, Step 1356: train/loss = 0.4344300627708435, train/raw-loss = 0.3783304691314697, train/logprobs = tensor([[-2.0101, -5.1186],
        [-3.0476, -2.6494]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.186998650431633
Epoch 0, Step 1357: train/loss = 0.5091128945350647, train/raw-loss = 0.4446536898612976, train/logprobs = tensor([[-2.4794, -7.1604],
        [-3.0783, -2.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21486394107341766
Epoch 0, Step 1358: train/loss = 0.41521739959716797, train/raw-loss = 0.34086012840270996, train/logprobs = tensor([[-3.3511, -5.9702],
        [-4.4454, -3.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2478574961423874
Epoch 0, Step 1359: train/loss = 0.38830411434173584, train/raw-loss = 0.34332579374313354, train/logprobs = tensor([[-2.7262, -5.0182],
        [-3.9808, -3.4481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14992773532867432
Epoch 0, Step 1360: train/loss = 0.23790410161018372, train/raw-loss = 0.09631694853305817, train/logprobs = tensor([[-2.2727, -7.6129],
        [-4.5208, -2.8475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47195711731910706
Epoch 0, Step 1361: train/loss = 0.3362252712249756, train/raw-loss = 0.2716050148010254, train/logprobs = tensor([[-2.0901, -5.2663],
        [-3.1629, -2.7975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21540075540542603
Epoch 0, Step 1362: train/loss = 0.28254634141921997, train/raw-loss = 0.20322540402412415, train/logprobs = tensor([[-1.7797, -6.6477],
        [-3.6497, -3.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26440316438674927
Epoch 0, Step 1363: train/loss = 0.19949138164520264, train/raw-loss = 0.0804188922047615, train/logprobs = tensor([[-2.6866, -8.8591],
        [-4.5301, -3.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39690831303596497
Epoch 0, Step 1364: train/loss = 0.37328866124153137, train/raw-loss = 0.3056831657886505, train/logprobs = tensor([[-4.3647, -8.4231],
        [-2.5599, -2.3522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2253517210483551
Epoch 0, Step 1365: train/loss = 0.3280181884765625, train/raw-loss = 0.20407527685165405, train/logprobs = tensor([[-3.1535, -8.3567],
        [-3.6748, -2.6312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41314297914505005
Epoch 0, Step 1366: train/loss = 0.20851150155067444, train/raw-loss = 0.09874895960092545, train/logprobs = tensor([[-2.7132, -6.8437],
        [-4.3674, -2.6724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36587512493133545
Epoch 0, Step 1367: train/loss = 0.19259759783744812, train/raw-loss = 0.06679706275463104, train/logprobs = tensor([[-1.5247, -9.0743],
        [-3.7491, -2.6526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.41933512687683105
Epoch 0, Step 1368: train/loss = 0.3036574125289917, train/raw-loss = 0.18632881343364716, train/logprobs = tensor([[-2.7559, -8.4078],
        [-3.9062, -3.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3910953402519226
Epoch 0, Step 1369: train/loss = 0.41610562801361084, train/raw-loss = 0.335244357585907, train/logprobs = tensor([[-2.8100, -5.9346],
        [-4.8303, -4.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26953747868537903
Epoch 0, Step 1370: train/loss = 0.19632616639137268, train/raw-loss = 0.08246394991874695, train/logprobs = tensor([[-4.2849, -8.4108],
        [-4.7544, -2.3137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.37954074144363403
Epoch 0, Step 1371: train/loss = 0.2119964063167572, train/raw-loss = 0.09628046303987503, train/logprobs = tensor([[-2.9831, -8.0636],
        [-4.8321, -3.4573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38571983575820923
Epoch 0, Step 1372: train/loss = 0.22049623727798462, train/raw-loss = 0.030210265889763832, train/logprobs = tensor([[ -3.5072, -11.3748],
        [ -4.6986,  -2.2667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6342865824699402
Epoch 0, Step 1373: train/loss = 0.24371017515659332, train/raw-loss = 0.11128026992082596, train/logprobs = tensor([[-2.9461, -5.7207],
        [-5.0041, -2.2000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44143301248550415
Epoch 0, Step 1374: train/loss = 0.19835884869098663, train/raw-loss = 0.11440643668174744, train/logprobs = tensor([[ -3.4635, -12.1418],
        [ -4.0869,  -4.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2798413932323456
Epoch 0, Step 1375: train/loss = 0.19072237610816956, train/raw-loss = 0.061478205025196075, train/logprobs = tensor([[ -3.1312, -10.2058],
        [ -4.7218,  -3.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43081384897232056
Epoch 0, Step 1376: train/loss = 0.31669899821281433, train/raw-loss = 0.23758921027183533, train/logprobs = tensor([[-3.5872, -6.4614],
        [-3.5445, -2.6821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26369935274124146
Epoch 0, Step 1377: train/loss = 0.3391771912574768, train/raw-loss = 0.22186672687530518, train/logprobs = tensor([[-2.6578, -7.3495],
        [-3.7827, -2.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.391034871339798
Epoch 0, Step 1378: train/loss = 0.5202687978744507, train/raw-loss = 0.43198075890541077, train/logprobs = tensor([[-2.6360, -4.4065],
        [-4.8187, -2.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29429352283477783
Epoch 0, Step 1379: train/loss = 0.21450480818748474, train/raw-loss = 0.07910354435443878, train/logprobs = tensor([[-2.6989, -8.1058],
        [-4.4783, -2.9962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4513375759124756
Epoch 0, Step 1380: train/loss = 0.3115222454071045, train/raw-loss = 0.17601948976516724, train/logprobs = tensor([[-2.0051, -7.7319],
        [-3.7386, -2.5252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4516759514808655
Epoch 0, Step 1381: train/loss = 0.31148916482925415, train/raw-loss = 0.1912996917963028, train/logprobs = tensor([[-4.0149, -8.6552],
        [-4.2167, -2.6291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4006316363811493
Epoch 0, Step 1382: train/loss = 0.34676748514175415, train/raw-loss = 0.2361021190881729, train/logprobs = tensor([[-4.6749, -8.5825],
        [-4.8855, -3.1891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3688846230506897
Epoch 0, Step 1383: train/loss = 0.25025373697280884, train/raw-loss = 0.1265718936920166, train/logprobs = tensor([[-2.7816, -8.1897],
        [-4.5179, -2.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4122728109359741
Epoch 0, Step 1384: train/loss = 0.21724557876586914, train/raw-loss = 0.07690531760454178, train/logprobs = tensor([[-2.6097, -7.6890],
        [-3.7825, -2.2474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4678008258342743
Epoch 0, Step 1385: train/loss = 0.22744625806808472, train/raw-loss = 0.03313370421528816, train/logprobs = tensor([[-2.6232, -9.0014],
        [-4.6859, -2.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.647708535194397
Epoch 0, Step 1386: train/loss = 0.5078281164169312, train/raw-loss = 0.44285815954208374, train/logprobs = tensor([[-4.0160, -8.6686],
        [-3.6286, -3.7549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2165665179491043
Epoch 0, Step 1387: train/loss = 0.42080336809158325, train/raw-loss = 0.38236579298973083, train/logprobs = tensor([[-2.0307, -2.9494],
        [-4.1324, -3.1822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12812520563602448
Epoch 0, Step 1388: train/loss = 0.4813971519470215, train/raw-loss = 0.39253512024879456, train/logprobs = tensor([[-3.1359, -8.0121],
        [-4.1695, -3.3556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29620689153671265
Epoch 0, Step 1389: train/loss = 0.2595352530479431, train/raw-loss = 0.123119056224823, train/logprobs = tensor([[-2.3073, -9.4183],
        [-3.7974, -2.5423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4547205865383148
Epoch 0, Step 1390: train/loss = 0.3067544996738434, train/raw-loss = 0.17654836177825928, train/logprobs = tensor([[-3.3563, -9.8452],
        [-3.7343, -2.0719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43402042984962463
Epoch 0, Step 1391: train/loss = 0.24271723628044128, train/raw-loss = 0.10840166360139847, train/logprobs = tensor([[-2.2742, -7.4785],
        [-4.3145, -2.3716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4477185904979706
Epoch 0, Step 1392: train/loss = 0.2165183275938034, train/raw-loss = 0.0626860111951828, train/logprobs = tensor([[-2.4901, -9.8158],
        [-3.8807, -2.5860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5127743482589722
Epoch 0, Step 1393: train/loss = 0.2998352646827698, train/raw-loss = 0.21413058042526245, train/logprobs = tensor([[-2.6331, -6.6716],
        [-3.9387, -2.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2856822609901428
Epoch 0, Step 1394: train/loss = 0.34776851534843445, train/raw-loss = 0.2725626230239868, train/logprobs = tensor([[-1.9744, -6.4858],
        [-2.7422, -2.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2506861686706543
Epoch 0, Step 1395: train/loss = 0.21934261918067932, train/raw-loss = 0.07480410486459732, train/logprobs = tensor([[-5.6326, -9.1628],
        [-4.6213, -2.2896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48179498314857483
Epoch 0, Step 1396: train/loss = 0.18253794312477112, train/raw-loss = 0.042410675436258316, train/logprobs = tensor([[-2.0998, -9.9042],
        [-3.7700, -2.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4670908749103546
Epoch 0, Step 1397: train/loss = 0.21116380393505096, train/raw-loss = 0.07706853747367859, train/logprobs = tensor([[-3.9514, -8.8461],
        [-5.1275, -3.3523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4469842314720154
Epoch 0, Step 1398: train/loss = 0.2946656048297882, train/raw-loss = 0.2169436365365982, train/logprobs = tensor([[-3.2154, -5.9132],
        [-4.9672, -3.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2590731978416443
Epoch 0, Step 1399: train/loss = 0.2168276458978653, train/raw-loss = 0.08924324810504913, train/logprobs = tensor([[ -4.6268, -10.5417],
        [ -4.0869,  -2.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.425281286239624
Epoch 0, Step 1400: train/loss = 0.39364704489707947, train/raw-loss = 0.3161342144012451, train/logprobs = tensor([[-3.6023, -7.6418],
        [-3.7302, -3.0382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2583761215209961
Epoch 0, Step 1401: train/loss = 0.228379026055336, train/raw-loss = 0.12701165676116943, train/logprobs = tensor([[-2.5497, -6.4171],
        [-4.5989, -2.5304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33789122104644775
Epoch 0, Step 1402: train/loss = 0.1954275518655777, train/raw-loss = 0.06700865924358368, train/logprobs = tensor([[-1.8543, -8.8899],
        [-3.3245, -2.3454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42806291580200195
Epoch 0, Step 1403: train/loss = 0.19674155116081238, train/raw-loss = 0.04921272397041321, train/logprobs = tensor([[-3.3580, -7.7026],
        [-5.3954, -1.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4917627274990082
Epoch 0, Step 1404: train/loss = 0.5915273427963257, train/raw-loss = 0.4869473874568939, train/logprobs = tensor([[-2.2250, -7.3252],
        [-3.3580, -3.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3485998511314392
Epoch 0, Step 1405: train/loss = 0.21788223087787628, train/raw-loss = 0.06565841287374496, train/logprobs = tensor([[-2.4194, -8.1720],
        [-4.2153, -2.3741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5074126720428467
Epoch 0, Step 1406: train/loss = 0.3611989915370941, train/raw-loss = 0.2909833490848541, train/logprobs = tensor([[-2.9097, -4.8262],
        [-3.3238, -2.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23405209183692932
Epoch 0, Step 1407: train/loss = 0.21566961705684662, train/raw-loss = 0.09750132262706757, train/logprobs = tensor([[-2.6722, -9.7985],
        [-3.8748, -3.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3938942849636078
Epoch 0, Step 1408: train/loss = 0.19770392775535583, train/raw-loss = 0.06630390882492065, train/logprobs = tensor([[-1.7704, -8.7706],
        [-3.0823, -2.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43800002336502075
Epoch 0, Step 1409: train/loss = 0.27875715494155884, train/raw-loss = 0.20828863978385925, train/logprobs = tensor([[-2.2859, -6.8047],
        [-3.9832, -3.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23489506542682648
Epoch 0, Step 1410: train/loss = 0.25351741909980774, train/raw-loss = 0.13861152529716492, train/logprobs = tensor([[-3.1485, -9.4982],
        [-3.2058, -2.2400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38301968574523926
Epoch 0, Step 1411: train/loss = 0.31952446699142456, train/raw-loss = 0.26363304257392883, train/logprobs = tensor([[-3.3101, -8.6361],
        [-2.3338, -2.5993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1863047331571579
Epoch 0, Step 1412: train/loss = 0.3604406714439392, train/raw-loss = 0.2198956161737442, train/logprobs = tensor([[-4.2846, -9.4035],
        [-5.1454, -2.6439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46848344802856445
Epoch 0, Step 1413: train/loss = 0.2552286386489868, train/raw-loss = 0.166423499584198, train/logprobs = tensor([[-2.5999, -8.3521],
        [-3.3926, -3.1835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2960171103477478
Epoch 0, Step 1414: train/loss = 0.17231643199920654, train/raw-loss = 0.05721314251422882, train/logprobs = tensor([[ -2.3679, -10.9194],
        [ -4.4008,  -3.9452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3836776614189148
Epoch 0, Step 1415: train/loss = 0.28936952352523804, train/raw-loss = 0.24367617070674896, train/logprobs = tensor([[-2.3989, -6.3845],
        [-3.2767, -2.9453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15231116116046906
Epoch 0, Step 1416: train/loss = 0.288866251707077, train/raw-loss = 0.1941039115190506, train/logprobs = tensor([[-2.6837, -7.2224],
        [-3.3215, -2.3569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3158744275569916
Epoch 0, Step 1417: train/loss = 0.22600057721138, train/raw-loss = 0.10435427725315094, train/logprobs = tensor([[-3.1866, -6.4308],
        [-3.8744, -1.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40548765659332275
Epoch 0, Step 1418: train/loss = 0.24351553618907928, train/raw-loss = 0.06490422040224075, train/logprobs = tensor([[ -4.2147, -11.4834],
        [ -4.6261,  -2.1532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5953710079193115
Epoch 0, Step 1419: train/loss = 0.23611514270305634, train/raw-loss = 0.10413169115781784, train/logprobs = tensor([[-1.7824, -8.8897],
        [-3.7213, -2.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4399448335170746
Epoch 0, Step 1420: train/loss = 0.28964030742645264, train/raw-loss = 0.1876843422651291, train/logprobs = tensor([[-2.9526, -5.2964],
        [-4.1515, -2.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3398531675338745
Epoch 0, Step 1421: train/loss = 0.21305488049983978, train/raw-loss = 0.05610781908035278, train/logprobs = tensor([[ -2.7391, -11.0225],
        [ -4.3594,  -3.0946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5231568813323975
Epoch 0, Step 1422: train/loss = 0.2684163749217987, train/raw-loss = 0.1780512034893036, train/logprobs = tensor([[-2.5065, -8.1112],
        [-3.4880, -2.7333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3012172281742096
Epoch 0, Step 1423: train/loss = 0.29648518562316895, train/raw-loss = 0.18316085636615753, train/logprobs = tensor([[-2.6139, -7.5290],
        [-3.4483, -2.4377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3777477741241455
Epoch 0, Step 1424: train/loss = 0.34633517265319824, train/raw-loss = 0.24991518259048462, train/logprobs = tensor([[-3.4403, -6.1702],
        [-4.5095, -2.2820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3213999569416046
Epoch 0, Step 1425: train/loss = 0.23956571519374847, train/raw-loss = 0.15126773715019226, train/logprobs = tensor([[-3.0086, -7.0996],
        [-3.0819, -2.3951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2943266034126282
Epoch 0, Step 1426: train/loss = 0.3141416907310486, train/raw-loss = 0.24123063683509827, train/logprobs = tensor([[-2.4130, -4.6721],
        [-3.3660, -2.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24303683638572693
Epoch 0, Step 1427: train/loss = 1.1806710958480835, train/raw-loss = 1.0367333889007568, train/logprobs = tensor([[-5.7103, -9.9402],
        [-2.5634, -2.6567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47979241609573364
Epoch 0, Step 1428: train/loss = 0.2755245268344879, train/raw-loss = 0.15550747513771057, train/logprobs = tensor([[-3.2646, -7.7468],
        [-4.2656, -2.7980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40005674958229065
Epoch 0, Step 1429: train/loss = 0.33764398097991943, train/raw-loss = 0.2529725432395935, train/logprobs = tensor([[-3.9979, -8.2721],
        [-4.3727, -3.4543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28223809599876404
Epoch 0, Step 1430: train/loss = 0.22554537653923035, train/raw-loss = 0.06906971335411072, train/logprobs = tensor([[ -2.9781, -10.3235],
        [ -3.7210,  -2.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5215854644775391
Epoch 0, Step 1431: train/loss = 0.20412585139274597, train/raw-loss = 0.06824523955583572, train/logprobs = tensor([[-2.5898, -8.7924],
        [-4.4800, -2.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4529353678226471
Epoch 0, Step 1432: train/loss = 0.2676759958267212, train/raw-loss = 0.17598363757133484, train/logprobs = tensor([[-2.8102, -6.8998],
        [-3.1104, -1.6884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30564120411872864
Epoch 0, Step 1433: train/loss = 0.2996823489665985, train/raw-loss = 0.22063466906547546, train/logprobs = tensor([[-2.8475, -6.9976],
        [-3.1399, -2.2654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26349225640296936
Epoch 0, Step 1434: train/loss = 0.2544880509376526, train/raw-loss = 0.16382616758346558, train/logprobs = tensor([[-3.0399, -7.1468],
        [-3.5929, -1.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3022063374519348
Epoch 0, Step 1435: train/loss = 0.3890063464641571, train/raw-loss = 0.31208252906799316, train/logprobs = tensor([[-3.0412, -7.5952],
        [-4.4054, -3.6887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2564125657081604
Epoch 0, Step 1436: train/loss = 0.2113906741142273, train/raw-loss = 0.025911608710885048, train/logprobs = tensor([[ -3.3632, -10.3998],
        [ -4.8354,  -2.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6182635426521301
Epoch 0, Step 1437: train/loss = 0.4163551330566406, train/raw-loss = 0.2959350049495697, train/logprobs = tensor([[-2.8095, -8.7916],
        [-3.8823, -2.1720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4014004170894623
Epoch 0, Step 1438: train/loss = 0.2040727734565735, train/raw-loss = 0.0653926357626915, train/logprobs = tensor([[-2.9434, -9.7097],
        [-4.6265, -2.4091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46226707100868225
Epoch 0, Step 1439: train/loss = 0.20521166920661926, train/raw-loss = 0.12762293219566345, train/logprobs = tensor([[-2.7798, -9.3441],
        [-3.9857, -3.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25862917304039
Epoch 0, Step 1440: train/loss = 0.3737006187438965, train/raw-loss = 0.26968735456466675, train/logprobs = tensor([[-2.8329, -6.5547],
        [-4.0670, -2.3873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3467109799385071
Epoch 0, Step 1441: train/loss = 0.36604148149490356, train/raw-loss = 0.3103388249874115, train/logprobs = tensor([[-2.6221, -5.1160],
        [-2.8750, -2.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18567568063735962
Epoch 0, Step 1442: train/loss = 0.2283450961112976, train/raw-loss = 0.07929708063602448, train/logprobs = tensor([[-3.0371, -7.7236],
        [-4.7130, -2.4174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4968266487121582
Epoch 0, Step 1443: train/loss = 0.3765793442726135, train/raw-loss = 0.27215343713760376, train/logprobs = tensor([[-3.9779, -8.1800],
        [-5.4223, -4.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3480863869190216
Epoch 0, Step 1444: train/loss = 0.20166811347007751, train/raw-loss = 0.08440395444631577, train/logprobs = tensor([[-1.9891, -7.4058],
        [-3.4505, -2.3650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3908805549144745
Epoch 0, Step 1445: train/loss = 0.30772706866264343, train/raw-loss = 0.13010172545909882, train/logprobs = tensor([[-3.0062, -8.4388],
        [-4.4925, -2.9038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.592084527015686
Epoch 0, Step 1446: train/loss = 0.4698702096939087, train/raw-loss = 0.38163432478904724, train/logprobs = tensor([[-3.6696, -6.6143],
        [-3.5344, -2.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29411959648132324
Epoch 0, Step 1447: train/loss = 0.24029548466205597, train/raw-loss = 0.17091870307922363, train/logprobs = tensor([[-2.4043, -7.8110],
        [-3.4594, -3.3261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2312559187412262
Epoch 0, Step 1448: train/loss = 0.22039902210235596, train/raw-loss = 0.10063304007053375, train/logprobs = tensor([[-3.4289, -9.5149],
        [-4.2951, -2.6693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.39921993017196655
Epoch 0, Step 1449: train/loss = 0.3529989719390869, train/raw-loss = 0.19851422309875488, train/logprobs = tensor([[-1.8232, -8.2984],
        [-4.1721, -3.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5149490833282471
Epoch 0, Step 1450: train/loss = 0.22700276970863342, train/raw-loss = 0.12087492644786835, train/logprobs = tensor([[-2.7262, -9.3158],
        [-3.6277, -2.8817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3537594974040985
Epoch 0, Step 1451: train/loss = 0.2991439700126648, train/raw-loss = 0.2341240495443344, train/logprobs = tensor([[-3.7116, -9.8746],
        [-3.1219, -2.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21673306822776794
Epoch 0, Step 1452: train/loss = 0.3733276426792145, train/raw-loss = 0.29392579197883606, train/logprobs = tensor([[-4.3434, -5.8119],
        [-3.7963, -2.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2646729350090027
Epoch 0, Step 1453: train/loss = 0.21163061261177063, train/raw-loss = 0.046454839408397675, train/logprobs = tensor([[-3.8121, -9.4165],
        [-4.1083, -2.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5505858659744263
Epoch 0, Step 1454: train/loss = 0.29750871658325195, train/raw-loss = 0.21536856889724731, train/logprobs = tensor([[ -5.9185, -11.0200],
        [ -2.6601,  -2.3563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2738005816936493
Epoch 0, Step 1455: train/loss = 0.26893192529678345, train/raw-loss = 0.12441607564687729, train/logprobs = tensor([[-3.5879, -7.1679],
        [-4.3377, -1.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.481719434261322
Epoch 0, Step 1456: train/loss = 0.34944984316825867, train/raw-loss = 0.2293020486831665, train/logprobs = tensor([[-2.9168, -7.5367],
        [-3.9068, -2.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4004926085472107
Epoch 0, Step 1457: train/loss = 0.4137643277645111, train/raw-loss = 0.3274438977241516, train/logprobs = tensor([[ -4.7425, -10.7982],
        [ -2.9164,  -3.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28773462772369385
Epoch 0, Step 1458: train/loss = 0.2514437139034271, train/raw-loss = 0.1463783234357834, train/logprobs = tensor([[-3.5425, -8.8141],
        [-3.9761, -2.7824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3502179682254791
Epoch 0, Step 1459: train/loss = 0.2084074169397354, train/raw-loss = 0.06466285139322281, train/logprobs = tensor([[-3.8281, -9.6101],
        [-4.3395, -2.7460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4791485667228699
Epoch 0, Step 1460: train/loss = 0.1944006383419037, train/raw-loss = 0.10091152787208557, train/logprobs = tensor([[-2.3128, -9.6139],
        [-3.2646, -2.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3116302788257599
Epoch 0, Step 1461: train/loss = 0.4629617929458618, train/raw-loss = 0.34469425678253174, train/logprobs = tensor([[-3.5354, -8.0710],
        [-4.7491, -3.6603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3942250609397888
Epoch 0, Step 1462: train/loss = 0.23022441565990448, train/raw-loss = 0.15057559311389923, train/logprobs = tensor([[-2.3296, -7.4261],
        [-4.2711, -3.6134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26549601554870605
Epoch 0, Step 1463: train/loss = 0.2971120774745941, train/raw-loss = 0.226750448346138, train/logprobs = tensor([[-3.3096, -9.8829],
        [-3.7207, -3.5314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23453867435455322
Epoch 0, Step 1464: train/loss = 0.20032933354377747, train/raw-loss = 0.08492016792297363, train/logprobs = tensor([[-3.1207, -8.2443],
        [-4.5191, -2.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.38469719886779785
Epoch 0, Step 1465: train/loss = 0.47288811206817627, train/raw-loss = 0.3886508345603943, train/logprobs = tensor([[-4.0160, -5.6585],
        [-4.2379, -2.6110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28079092502593994
Epoch 0, Step 1466: train/loss = 0.299822598695755, train/raw-loss = 0.20332418382167816, train/logprobs = tensor([[-2.6528, -7.0689],
        [-3.9571, -3.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.32166141271591187
Epoch 0, Step 1467: train/loss = 0.24791638553142548, train/raw-loss = 0.13040414452552795, train/logprobs = tensor([[-3.5033, -8.0774],
        [-4.5326, -2.6035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3917074501514435
Epoch 0, Step 1468: train/loss = 0.21755912899971008, train/raw-loss = 0.11374762654304504, train/logprobs = tensor([[-2.4350, -6.5270],
        [-3.4870, -2.3972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3460384011268616
Epoch 0, Step 1469: train/loss = 0.27200645208358765, train/raw-loss = 0.1789799928665161, train/logprobs = tensor([[-1.7499, -7.9565],
        [-3.0790, -2.5744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31008821725845337
Epoch 0, Step 1470: train/loss = 0.20040729641914368, train/raw-loss = 0.07873579859733582, train/logprobs = tensor([[-2.1159, -9.6423],
        [-4.2999, -2.7783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40557169914245605
Epoch 0, Step 1471: train/loss = 0.21886439621448517, train/raw-loss = 0.09736690670251846, train/logprobs = tensor([[-3.2839, -6.9448],
        [-4.4098, -2.4116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4049915671348572
Epoch 0, Step 1472: train/loss = 0.5704359412193298, train/raw-loss = 0.4890199899673462, train/logprobs = tensor([[-4.8623, -6.5694],
        [-4.1445, -2.8578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.27138659358024597
Epoch 0, Step 1473: train/loss = 0.23254543542861938, train/raw-loss = 0.058804724365472794, train/logprobs = tensor([[-2.4180, -7.8129],
        [-5.3242, -2.5287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5791357159614563
Epoch 0, Step 1474: train/loss = 0.4343715310096741, train/raw-loss = 0.3587879538536072, train/logprobs = tensor([[-3.4726, -5.7125],
        [-3.6215, -2.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25194528698921204
Epoch 0, Step 1475: train/loss = 0.20661324262619019, train/raw-loss = 0.015189983882009983, train/logprobs = tensor([[-2.6200, -9.9419],
        [-5.6787, -2.4501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6380774974822998
Epoch 0, Step 1476: train/loss = 0.28879642486572266, train/raw-loss = 0.14141933619976044, train/logprobs = tensor([[-3.6682, -9.1174],
        [-4.4427, -2.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49125683307647705
Epoch 0, Step 1477: train/loss = 0.20260363817214966, train/raw-loss = 0.05567311495542526, train/logprobs = tensor([[-2.3761, -8.1479],
        [-4.9308, -2.4003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4897683560848236
Epoch 0, Step 1478: train/loss = 0.3606301546096802, train/raw-loss = 0.19501926004886627, train/logprobs = tensor([[-2.7566, -8.3518],
        [-4.2589, -2.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5520362854003906
Epoch 0, Step 1479: train/loss = 0.34635061025619507, train/raw-loss = 0.19858893752098083, train/logprobs = tensor([[-4.4344, -9.7879],
        [-4.5772, -2.3970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.49253883957862854
Epoch 0, Step 1480: train/loss = 0.3885999023914337, train/raw-loss = 0.2978869378566742, train/logprobs = tensor([[-3.6485, -7.5145],
        [-2.9827, -2.4768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.30237653851509094
Epoch 0, Step 1481: train/loss = 0.21212489902973175, train/raw-loss = 0.07980290800333023, train/logprobs = tensor([[-2.1334, -8.2250],
        [-4.2784, -2.4499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4410732388496399
Epoch 0, Step 1482: train/loss = 0.26278966665267944, train/raw-loss = 0.1407346874475479, train/logprobs = tensor([[-3.1877, -7.3892],
        [-4.8667, -2.6442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40685001015663147
Epoch 0, Step 1483: train/loss = 0.3773089051246643, train/raw-loss = 0.29973310232162476, train/logprobs = tensor([[-2.0195, -5.6465],
        [-3.7381, -3.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2585860788822174
Epoch 0, Step 1484: train/loss = 0.18626609444618225, train/raw-loss = 0.04747931659221649, train/logprobs = tensor([[-2.5382, -9.2170],
        [-3.9164, -2.2124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46262261271476746
Epoch 0, Step 1485: train/loss = 0.3771746754646301, train/raw-loss = 0.29122257232666016, train/logprobs = tensor([[-2.3961, -4.1989],
        [-5.4647, -3.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2865070104598999
Epoch 0, Step 1486: train/loss = 0.2450585663318634, train/raw-loss = 0.07359874248504639, train/logprobs = tensor([[-2.2533, -6.9267],
        [-6.1017, -3.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5715327858924866
Epoch 0, Step 1487: train/loss = 0.3020723760128021, train/raw-loss = 0.22962403297424316, train/logprobs = tensor([[-3.6735, -9.2698],
        [-4.4091, -4.0959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24149450659751892
Epoch 0, Step 1488: train/loss = 0.22796408832073212, train/raw-loss = 0.047350749373435974, train/logprobs = tensor([[-2.9528, -8.4881],
        [-5.0320, -3.2083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6020444631576538
Epoch 0, Step 1489: train/loss = 0.6503363251686096, train/raw-loss = 0.5460557341575623, train/logprobs = tensor([[-3.0627, -6.3369],
        [-4.4034, -3.7244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34760209918022156
Epoch 0, Step 1490: train/loss = 0.6361077427864075, train/raw-loss = 0.5496536493301392, train/logprobs = tensor([[-3.5323, -4.6000],
        [-4.3335, -2.9087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28818053007125854
Epoch 0, Step 1491: train/loss = 0.22336304187774658, train/raw-loss = 0.08448227494955063, train/logprobs = tensor([[-1.9478, -7.2810],
        [-4.2867, -2.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4629359245300293
Epoch 0, Step 1492: train/loss = 0.2587333619594574, train/raw-loss = 0.15962021052837372, train/logprobs = tensor([[-2.6400, -6.9184],
        [-5.1070, -3.5503]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.33037716150283813
Epoch 0, Step 1493: train/loss = 0.2070760428905487, train/raw-loss = 0.05148947983980179, train/logprobs = tensor([[-4.5332, -8.8610],
        [-5.4075, -2.7663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5186218619346619
Epoch 0, Step 1494: train/loss = 0.6417346000671387, train/raw-loss = 0.5800434947013855, train/logprobs = tensor([[-3.6612, -5.6386],
        [-3.7649, -2.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2056371569633484
Epoch 0, Step 1495: train/loss = 0.4484395384788513, train/raw-loss = 0.30123087763786316, train/logprobs = tensor([[-4.5944, -7.3876],
        [-5.9051, -2.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4906955063343048
Epoch 0, Step 1496: train/loss = 0.29621732234954834, train/raw-loss = 0.23790130019187927, train/logprobs = tensor([[-3.2829, -8.8704],
        [-3.5591, -3.4143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19438676536083221
Epoch 0, Step 1497: train/loss = 0.21400001645088196, train/raw-loss = 0.02993464656174183, train/logprobs = tensor([[ -3.7830, -10.5245],
        [ -4.8281,  -2.6621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6135511994361877
Epoch 0, Step 1498: train/loss = 0.20454616844654083, train/raw-loss = 0.042323313653469086, train/logprobs = tensor([[-3.8263, -8.3919],
        [-5.4626, -2.4255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.540742814540863
Epoch 0, Step 1499: train/loss = 0.23287555575370789, train/raw-loss = 0.10462456941604614, train/logprobs = tensor([[-3.0279, -8.4845],
        [-4.5824, -2.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4275032579898834
eval/loss: 0.30002260208129883
Epoch 0, Step 1500: train/loss = 0.2195107638835907, train/raw-loss = 0.05862867832183838, train/logprobs = tensor([[-3.5912, -8.3908],
        [-4.5267, -1.9021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5362735986709595
Epoch 0, Step 1501: train/loss = 0.237257182598114, train/raw-loss = 0.08345650881528854, train/logprobs = tensor([[-3.7609, -9.9510],
        [-5.5662, -3.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5126689076423645
Epoch 0, Step 1502: train/loss = 0.482697457075119, train/raw-loss = 0.3637501001358032, train/logprobs = tensor([[-2.9687, -7.6632],
        [-4.5451, -3.6703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3964911997318268
Epoch 0, Step 1503: train/loss = 0.4629124402999878, train/raw-loss = 0.39989814162254333, train/logprobs = tensor([[-5.0428, -8.4466],
        [-2.4507, -1.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21004772186279297
Epoch 0, Step 1504: train/loss = 0.3726864755153656, train/raw-loss = 0.22596338391304016, train/logprobs = tensor([[-3.2132, -8.5686],
        [-4.4947, -2.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4890769422054291
Epoch 0, Step 1505: train/loss = 0.3536215126514435, train/raw-loss = 0.189860999584198, train/logprobs = tensor([[-2.4659, -7.9756],
        [-6.5201, -3.4067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5458683967590332
Epoch 0, Step 1506: train/loss = 0.47377443313598633, train/raw-loss = 0.34173429012298584, train/logprobs = tensor([[-2.6153, -8.0046],
        [-4.4083, -3.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44013383984565735
Epoch 0, Step 1507: train/loss = 0.22154644131660461, train/raw-loss = 0.03626708313822746, train/logprobs = tensor([[-2.4557, -8.2301],
        [-5.8596, -3.3876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6175978183746338
Epoch 0, Step 1508: train/loss = 0.20308062434196472, train/raw-loss = 0.02108112722635269, train/logprobs = tensor([[-2.8465, -9.2857],
        [-5.6898, -2.3061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6066650152206421
Epoch 0, Step 1509: train/loss = 0.476512610912323, train/raw-loss = 0.3634784519672394, train/logprobs = tensor([[-3.8595, -8.6889],
        [-4.1267, -2.8009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3767804801464081
Epoch 0, Step 1510: train/loss = 0.4034651517868042, train/raw-loss = 0.2251671850681305, train/logprobs = tensor([[-2.3543, -9.3177],
        [-4.3566, -2.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5943264961242676
Epoch 0, Step 1511: train/loss = 0.25875818729400635, train/raw-loss = 0.05399862676858902, train/logprobs = tensor([[-2.7057, -9.2549],
        [-6.0095, -3.6256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6825318336486816
Epoch 0, Step 1512: train/loss = 0.4275776147842407, train/raw-loss = 0.300353467464447, train/logprobs = tensor([[-2.5734, -6.3646],
        [-4.6712, -3.0439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42408043146133423
Epoch 0, Step 1513: train/loss = 0.29645031690597534, train/raw-loss = 0.18726736307144165, train/logprobs = tensor([[-2.7986, -7.4859],
        [-4.5246, -3.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3639431893825531
Epoch 0, Step 1514: train/loss = 0.6237258911132812, train/raw-loss = 0.4917781949043274, train/logprobs = tensor([[-2.6435, -6.6378],
        [-5.4070, -3.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.43982550501823425
Epoch 0, Step 1515: train/loss = 0.2152566760778427, train/raw-loss = 0.035462815314531326, train/logprobs = tensor([[-2.7636, -9.0126],
        [-4.9026, -2.7425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5993128418922424
Epoch 0, Step 1516: train/loss = 0.3401910066604614, train/raw-loss = 0.2663613259792328, train/logprobs = tensor([[-2.8146, -4.6246],
        [-6.3774, -4.5342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24609896540641785
Epoch 0, Step 1517: train/loss = 0.23511448502540588, train/raw-loss = 0.03273845836520195, train/logprobs = tensor([[-3.2953, -9.5660],
        [-5.1317, -2.7688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6745867729187012
Epoch 0, Step 1518: train/loss = 0.4082372188568115, train/raw-loss = 0.24819087982177734, train/logprobs = tensor([[-2.8229, -8.2104],
        [-5.7691, -3.6790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.533487856388092
Epoch 0, Step 1519: train/loss = 0.2027968168258667, train/raw-loss = 0.042202286422252655, train/logprobs = tensor([[-2.5866, -7.6039],
        [-5.2591, -2.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5353150367736816
Epoch 0, Step 1520: train/loss = 0.29289719462394714, train/raw-loss = 0.11617633700370789, train/logprobs = tensor([[ -3.7292, -11.3785],
        [ -5.5736,  -3.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5890694856643677
Epoch 0, Step 1521: train/loss = 0.4368061125278473, train/raw-loss = 0.3618188500404358, train/logprobs = tensor([[-3.1937, -5.1708],
        [-4.9976, -3.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24995753169059753
Epoch 0, Step 1522: train/loss = 0.23464182019233704, train/raw-loss = 0.01296098530292511, train/logprobs = tensor([[-2.7009, -9.4152],
        [-5.2981, -2.2449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7389360666275024
Epoch 0, Step 1523: train/loss = 0.5632839798927307, train/raw-loss = 0.519545316696167, train/logprobs = tensor([[-3.5876, -4.2651],
        [-4.3946, -3.5127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14579564332962036
Epoch 0, Step 1524: train/loss = 0.325766921043396, train/raw-loss = 0.13279414176940918, train/logprobs = tensor([[-3.6817, -8.8887],
        [-5.5813, -2.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6432425379753113
Epoch 0, Step 1525: train/loss = 0.3385055959224701, train/raw-loss = 0.2674933075904846, train/logprobs = tensor([[-2.3305, -4.6253],
        [-4.6449, -3.3606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23670771718025208
Epoch 0, Step 1526: train/loss = 0.28449687361717224, train/raw-loss = 0.07885780185461044, train/logprobs = tensor([[ -4.5108, -11.6464],
        [ -5.2002,  -2.3543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.685463547706604
Epoch 0, Step 1527: train/loss = 0.376267671585083, train/raw-loss = 0.21360856294631958, train/logprobs = tensor([[-4.4289, -8.5425],
        [-6.2473, -4.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.542197048664093
Epoch 0, Step 1528: train/loss = 0.36692118644714355, train/raw-loss = 0.2214345633983612, train/logprobs = tensor([[-2.6687, -6.8010],
        [-5.2464, -2.8718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48495548963546753
Epoch 0, Step 1529: train/loss = 0.24588778614997864, train/raw-loss = 0.09482112526893616, train/logprobs = tensor([[-3.8624, -8.5957],
        [-4.8555, -2.5356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5035554766654968
Epoch 0, Step 1530: train/loss = 0.23234930634498596, train/raw-loss = 0.03308519721031189, train/logprobs = tensor([[-3.3118, -9.4233],
        [-6.5347, -3.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6642136573791504
Epoch 0, Step 1531: train/loss = 0.2504691779613495, train/raw-loss = 0.007938247174024582, train/logprobs = tensor([[ -3.0050, -11.8513],
        [ -6.3576,  -3.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8084363341331482
Epoch 0, Step 1532: train/loss = 0.4825166165828705, train/raw-loss = 0.3610146641731262, train/logprobs = tensor([[-3.9929, -7.5915],
        [-5.5415, -3.0744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40500661730766296
Epoch 0, Step 1533: train/loss = 0.39792853593826294, train/raw-loss = 0.2346636950969696, train/logprobs = tensor([[-2.6873, -7.8692],
        [-5.5073, -3.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5442161560058594
Epoch 0, Step 1534: train/loss = 0.2231091856956482, train/raw-loss = 0.0840185359120369, train/logprobs = tensor([[-4.0118, -8.4663],
        [-4.5711, -2.3289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.46363553404808044
Epoch 0, Step 1535: train/loss = 0.23191654682159424, train/raw-loss = 0.03641476482152939, train/logprobs = tensor([[ -3.2417, -10.1094],
        [ -6.7605,  -3.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6516725420951843
Epoch 0, Step 1536: train/loss = 0.6988641619682312, train/raw-loss = 0.6037044525146484, train/logprobs = tensor([[-3.4227, -5.0988],
        [-5.0560, -4.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3171990215778351
Epoch 0, Step 1537: train/loss = 0.23014551401138306, train/raw-loss = 0.010465573519468307, train/logprobs = tensor([[ -2.8902, -10.1950],
        [ -7.6003,  -4.2578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7322664260864258
Epoch 0, Step 1538: train/loss = 0.25021085143089294, train/raw-loss = 0.07908026874065399, train/logprobs = tensor([[-2.9128, -7.7472],
        [-6.4114, -3.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5704352855682373
Epoch 0, Step 1539: train/loss = 0.3150773048400879, train/raw-loss = 0.03454817831516266, train/logprobs = tensor([[-2.2951, -9.2319],
        [-5.5555, -2.3596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9350970983505249
Epoch 0, Step 1540: train/loss = 0.22814492881298065, train/raw-loss = 0.017019009217619896, train/logprobs = tensor([[ -3.2794, -10.4423],
        [ -6.7675,  -3.4256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7037529945373535
Epoch 0, Step 1541: train/loss = 0.20224760472774506, train/raw-loss = 0.04512368142604828, train/logprobs = tensor([[-3.8230, -7.9209],
        [-5.4146, -2.5731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5237463712692261
Epoch 0, Step 1542: train/loss = 0.2149011790752411, train/raw-loss = 0.024849850684404373, train/logprobs = tensor([[-3.1579, -9.1277],
        [-5.1874, -1.9940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6335043907165527
Epoch 0, Step 1543: train/loss = 1.0765286684036255, train/raw-loss = 1.019675374031067, train/logprobs = tensor([[-4.5053, -4.3329],
        [-4.0115, -4.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18951056897640228
Epoch 0, Step 1544: train/loss = 0.26248612999916077, train/raw-loss = 0.03876326233148575, train/logprobs = tensor([[ -3.3877, -10.1558],
        [ -5.8905,  -2.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7457428574562073
Epoch 0, Step 1545: train/loss = 0.2701881229877472, train/raw-loss = 0.17797687649726868, train/logprobs = tensor([[-4.3408, -6.6245],
        [-6.8212, -5.2912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3073708117008209
Epoch 0, Step 1546: train/loss = 0.23851200938224792, train/raw-loss = 0.013898276723921299, train/logprobs = tensor([[ -2.2949, -10.3366],
        [ -6.8373,  -3.7594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.748712420463562
Epoch 0, Step 1547: train/loss = 0.2111329585313797, train/raw-loss = 0.03542998433113098, train/logprobs = tensor([[ -3.4776, -10.1626],
        [ -4.9345,  -2.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5856765508651733
Epoch 0, Step 1548: train/loss = 0.19779673218727112, train/raw-loss = 0.03557269275188446, train/logprobs = tensor([[-3.2127, -9.4023],
        [-5.4424, -3.0767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5407467484474182
Epoch 0, Step 1549: train/loss = 0.5209721326828003, train/raw-loss = 0.44379135966300964, train/logprobs = tensor([[-6.5997, -9.3603],
        [-4.2174, -2.9724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2572692632675171
Epoch 0, Step 1550: train/loss = 0.48772475123405457, train/raw-loss = 0.3278592824935913, train/logprobs = tensor([[-4.7548, -8.7629],
        [-4.3685, -2.8844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.532884955406189
Epoch 0, Step 1551: train/loss = 0.25621291995048523, train/raw-loss = 0.1283758133649826, train/logprobs = tensor([[ -3.3216, -10.7216],
        [ -4.0237,  -3.4367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4261237382888794
Epoch 0, Step 1552: train/loss = 0.24630260467529297, train/raw-loss = 0.027812425047159195, train/logprobs = tensor([[ -3.5321, -11.7382],
        [ -4.9586,  -2.4148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7283005714416504
Epoch 0, Step 1553: train/loss = 0.2174386978149414, train/raw-loss = 0.06024998426437378, train/logprobs = tensor([[-2.8348, -7.4667],
        [-4.7126, -2.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5239623785018921
Epoch 0, Step 1554: train/loss = 0.42162469029426575, train/raw-loss = 0.2951754927635193, train/logprobs = tensor([[-1.9053, -5.8943],
        [-4.4663, -2.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.42149725556373596
Epoch 0, Step 1555: train/loss = 0.27318382263183594, train/raw-loss = 0.009684113785624504, train/logprobs = tensor([[ -2.9851, -10.7345],
        [ -6.2910,  -2.7062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.878332257270813
Epoch 0, Step 1556: train/loss = 0.3300950527191162, train/raw-loss = 0.1076856330037117, train/logprobs = tensor([[ -2.7423, -10.0357],
        [ -7.3111,  -4.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7413647174835205
Epoch 0, Step 1557: train/loss = 0.30008092522621155, train/raw-loss = 0.21516139805316925, train/logprobs = tensor([[-2.7174, -7.7174],
        [-4.6675, -3.8999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28306514024734497
Epoch 0, Step 1558: train/loss = 0.2932319939136505, train/raw-loss = 0.027176812291145325, train/logprobs = tensor([[ -2.8749, -12.3683],
        [ -6.6410,  -4.5907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8868505954742432
Epoch 0, Step 1559: train/loss = 0.3775940537452698, train/raw-loss = 0.16610413789749146, train/logprobs = tensor([[-2.1409, -8.3343],
        [-7.0213, -3.6644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7049664855003357
Epoch 0, Step 1560: train/loss = 0.28707438707351685, train/raw-loss = 0.13284987211227417, train/logprobs = tensor([[-3.7177, -7.8444],
        [-4.3284, -2.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5140816569328308
Epoch 0, Step 1561: train/loss = 0.2441350817680359, train/raw-loss = 0.06166639178991318, train/logprobs = tensor([[-2.6514, -6.6466],
        [-5.5236, -2.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6082289814949036
Epoch 0, Step 1562: train/loss = 0.33085116744041443, train/raw-loss = 0.21463854610919952, train/logprobs = tensor([[-3.7517, -8.1534],
        [-5.8433, -4.4089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3873753547668457
Epoch 0, Step 1563: train/loss = 0.21431231498718262, train/raw-loss = 0.06199178099632263, train/logprobs = tensor([[ -3.5515, -11.8266],
        [ -3.1911,  -1.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.507735013961792
Epoch 0, Step 1564: train/loss = 0.3017730712890625, train/raw-loss = 0.093996062874794, train/logprobs = tensor([[-3.0458, -8.8498],
        [-5.6941, -3.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6925899982452393
Epoch 0, Step 1565: train/loss = 0.29123368859291077, train/raw-loss = 0.09073204547166824, train/logprobs = tensor([[ -4.0574, -10.3723],
        [ -6.0988,  -2.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6683388948440552
Epoch 0, Step 1566: train/loss = 0.3808493912220001, train/raw-loss = 0.234475776553154, train/logprobs = tensor([[-1.9179, -7.4316],
        [-5.1898, -3.7316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48791196942329407
Epoch 0, Step 1567: train/loss = 0.30032408237457275, train/raw-loss = 0.2046847939491272, train/logprobs = tensor([[-3.3574, -8.2783],
        [-5.0431, -3.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31879764795303345
Epoch 0, Step 1568: train/loss = 0.2706672251224518, train/raw-loss = 0.11044908314943314, train/logprobs = tensor([[-3.4276, -7.8311],
        [-5.9493, -2.6681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5340604186058044
Epoch 0, Step 1569: train/loss = 0.371701717376709, train/raw-loss = 0.2913465201854706, train/logprobs = tensor([[-3.0016, -5.0198],
        [-5.7719, -3.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26785069704055786
Epoch 0, Step 1570: train/loss = 0.4105561375617981, train/raw-loss = 0.1859041154384613, train/logprobs = tensor([[-3.5206, -9.6356],
        [-6.0116, -3.5982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7488399744033813
Epoch 0, Step 1571: train/loss = 0.3130173683166504, train/raw-loss = 0.19262908399105072, train/logprobs = tensor([[-3.5900, -6.7042],
        [-5.3340, -3.7702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4012942612171173
Epoch 0, Step 1572: train/loss = 0.2834991216659546, train/raw-loss = 0.06853637099266052, train/logprobs = tensor([[ -3.0683, -10.3448],
        [ -6.7029,  -3.6615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7165424227714539
Epoch 0, Step 1573: train/loss = 0.2255115956068039, train/raw-loss = 0.007402995601296425, train/logprobs = tensor([[-2.7194, -9.0050],
        [-7.1561, -3.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7270286083221436
Epoch 0, Step 1574: train/loss = 0.44230419397354126, train/raw-loss = 0.3329062759876251, train/logprobs = tensor([[-3.7735, -7.3012],
        [-6.2737, -4.8340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.36465972661972046
Epoch 0, Step 1575: train/loss = 0.21973013877868652, train/raw-loss = 0.03135713189840317, train/logprobs = tensor([[-3.8324, -9.7705],
        [-6.3288, -3.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6279100179672241
Epoch 0, Step 1576: train/loss = 0.27094221115112305, train/raw-loss = 0.1229679137468338, train/logprobs = tensor([[-3.3842, -8.9016],
        [-5.9812, -4.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4932475686073303
Epoch 0, Step 1577: train/loss = 0.23702013492584229, train/raw-loss = 0.02571805752813816, train/logprobs = tensor([[ -2.9161, -10.2656],
        [ -8.8983,  -5.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7043402791023254
Epoch 0, Step 1578: train/loss = 0.23730877041816711, train/raw-loss = 0.012112535536289215, train/logprobs = tensor([[-3.1308, -9.3298],
        [-7.2365, -3.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7506540417671204
Epoch 0, Step 1579: train/loss = 0.233022540807724, train/raw-loss = 0.007038522977381945, train/logprobs = tensor([[ -2.8838, -11.2869],
        [ -7.2616,  -3.7661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7532800436019897
Epoch 0, Step 1580: train/loss = 0.22310906648635864, train/raw-loss = 0.03000771999359131, train/logprobs = tensor([[-2.9146, -8.9474],
        [-5.5537, -2.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6436712145805359
Epoch 0, Step 1581: train/loss = 0.22821909189224243, train/raw-loss = 0.011851510033011436, train/logprobs = tensor([[ -3.1114, -10.2631],
        [ -7.2403,  -3.2684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7212252616882324
Epoch 0, Step 1582: train/loss = 0.2237393707036972, train/raw-loss = 0.015473900362849236, train/logprobs = tensor([[-2.3677, -9.1217],
        [-6.1226, -3.3378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6942182183265686
Epoch 0, Step 1583: train/loss = 0.5418455004692078, train/raw-loss = 0.30962076783180237, train/logprobs = tensor([[-2.0438, -7.7066],
        [-7.7462, -4.7617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.774082362651825
Epoch 0, Step 1584: train/loss = 0.24963590502738953, train/raw-loss = 0.012512117624282837, train/logprobs = tensor([[ -3.6003, -10.4761],
        [ -6.3397,  -2.5800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7904126048088074
Epoch 0, Step 1585: train/loss = 0.3159309923648834, train/raw-loss = 0.17045284807682037, train/logprobs = tensor([[-4.1090, -7.9814],
        [-7.3325, -4.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.48492708802223206
Epoch 0, Step 1586: train/loss = 0.2271619439125061, train/raw-loss = 0.0679267942905426, train/logprobs = tensor([[-3.8033, -8.2941],
        [-6.6192, -3.8379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5307837724685669
Epoch 0, Step 1587: train/loss = 0.46608966588974, train/raw-loss = 0.32586658000946045, train/logprobs = tensor([[-5.1962, -9.4154],
        [-6.6675, -5.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4674103558063507
Epoch 0, Step 1588: train/loss = 0.32491469383239746, train/raw-loss = 0.1700654774904251, train/logprobs = tensor([[-4.3390, -9.3132],
        [-7.0581, -4.8611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5161640644073486
Epoch 0, Step 1589: train/loss = 0.24061639606952667, train/raw-loss = 0.10090386867523193, train/logprobs = tensor([[-4.4164, -8.4000],
        [-5.2151, -3.0210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4657083749771118
Epoch 0, Step 1590: train/loss = 0.3228716254234314, train/raw-loss = 0.18833446502685547, train/logprobs = tensor([[-2.3635, -5.5006],
        [-7.8092, -5.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44845715165138245
Epoch 0, Step 1591: train/loss = 0.5079174637794495, train/raw-loss = 0.4084746241569519, train/logprobs = tensor([[-1.3704, -3.5784],
        [-8.1131, -5.9293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3314763307571411
Epoch 0, Step 1592: train/loss = 0.29679960012435913, train/raw-loss = 0.19400078058242798, train/logprobs = tensor([[-4.5570, -7.4489],
        [-7.3183, -4.6945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3426626920700073
Epoch 0, Step 1593: train/loss = 0.31848904490470886, train/raw-loss = 0.19671763479709625, train/logprobs = tensor([[-2.6916, -5.4865],
        [-7.4565, -5.0026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40590474009513855
Epoch 0, Step 1594: train/loss = 0.21672506630420685, train/raw-loss = 0.05960853770375252, train/logprobs = tensor([[-3.3718, -8.0519],
        [-6.0534, -2.4945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5237217545509338
Epoch 0, Step 1595: train/loss = 0.36169177293777466, train/raw-loss = 0.2824428975582123, train/logprobs = tensor([[-2.9790, -4.9478],
        [-6.6479, -4.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2641628086566925
Epoch 0, Step 1596: train/loss = 0.3532378077507019, train/raw-loss = 0.2510976791381836, train/logprobs = tensor([[-2.0271, -5.1943],
        [-7.2873, -5.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3404671251773834
Epoch 0, Step 1597: train/loss = 0.3774680495262146, train/raw-loss = 0.17728778719902039, train/logprobs = tensor([[ -6.0351, -13.6270],
        [ -7.7848,  -3.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6672675013542175
Epoch 0, Step 1598: train/loss = 0.6950221061706543, train/raw-loss = 0.5949005484580994, train/logprobs = tensor([[-4.7211, -5.9155],
        [-5.6251, -4.4818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3337385058403015
Epoch 0, Step 1599: train/loss = 0.37542110681533813, train/raw-loss = 0.12447085976600647, train/logprobs = tensor([[ -3.6332, -10.8327],
        [ -8.3144,  -4.5134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8365007638931274
Epoch 0, Step 1600: train/loss = 0.27166733145713806, train/raw-loss = 0.06351330876350403, train/logprobs = tensor([[ -5.0069, -12.8712],
        [ -7.4988,  -5.2160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6938467025756836
Epoch 0, Step 1601: train/loss = 0.45096465945243835, train/raw-loss = 0.28171268105506897, train/logprobs = tensor([[-3.9199, -8.4800],
        [-7.3769, -5.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5641733407974243
Epoch 0, Step 1602: train/loss = 0.375643789768219, train/raw-loss = 0.2412073165178299, train/logprobs = tensor([[-4.8151, -9.4394],
        [-6.5567, -4.1551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.44812148809432983
Epoch 0, Step 1603: train/loss = 0.48638609051704407, train/raw-loss = 0.350827693939209, train/logprobs = tensor([[-2.9465, -5.7665],
        [-8.0491, -5.6602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45186132192611694
Epoch 0, Step 1604: train/loss = 0.26342248916625977, train/raw-loss = 0.03682323172688484, train/logprobs = tensor([[-2.6409, -9.5704],
        [-8.2107, -5.6143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7553308606147766
Epoch 0, Step 1605: train/loss = 0.22336965799331665, train/raw-loss = 0.10444121062755585, train/logprobs = tensor([[-4.5745, -8.7313],
        [-6.5044, -4.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3964281678199768
Epoch 0, Step 1606: train/loss = 0.3114919364452362, train/raw-loss = 0.15946412086486816, train/logprobs = tensor([[-4.6029, -9.0287],
        [-5.5359, -2.2657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5067594051361084
Epoch 0, Step 1607: train/loss = 0.24237869679927826, train/raw-loss = 0.05557987838983536, train/logprobs = tensor([[-3.1917, -8.3757],
        [-8.8797, -5.1069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6226627826690674
Epoch 0, Step 1608: train/loss = 0.21443764865398407, train/raw-loss = 0.009457014501094818, train/logprobs = tensor([[ -3.9950, -11.6016],
        [-10.0231,  -5.4572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6832687854766846
Epoch 0, Step 1609: train/loss = 0.4252423644065857, train/raw-loss = 0.32986074686050415, train/logprobs = tensor([[-4.1536, -6.6449],
        [-5.7259, -3.6698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3179388642311096
Epoch 0, Step 1610: train/loss = 0.21369460225105286, train/raw-loss = 0.09236980974674225, train/logprobs = tensor([[-3.1694, -9.0296],
        [-7.7621, -5.2920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.40441593527793884
Epoch 0, Step 1611: train/loss = 0.267767995595932, train/raw-loss = 0.012062646448612213, train/logprobs = tensor([[-2.7050, -9.5818],
        [-7.9887, -4.3299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8523511290550232
Epoch 0, Step 1612: train/loss = 0.3186156749725342, train/raw-loss = 0.002686077728867531, train/logprobs = tensor([[ -3.0531, -14.2795],
        [ -8.8910,  -5.2041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0530986785888672
Epoch 0, Step 1613: train/loss = 0.29789647459983826, train/raw-loss = 0.037653204053640366, train/logprobs = tensor([[-2.5027, -9.4398],
        [-7.1702, -4.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.867477536201477
Epoch 0, Step 1614: train/loss = 0.35496383905410767, train/raw-loss = 0.049654629081487656, train/logprobs = tensor([[ -2.7283, -10.5408],
        [ -7.2869,  -4.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0176973342895508
Epoch 0, Step 1615: train/loss = 0.22557687759399414, train/raw-loss = 0.017174821346998215, train/logprobs = tensor([[ -1.8454, -10.5446],
        [ -8.3967,  -5.1834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.694673478603363
Epoch 0, Step 1616: train/loss = 0.3266001045703888, train/raw-loss = 0.17541980743408203, train/logprobs = tensor([[ -4.4359, -11.3177],
        [ -7.5346,  -3.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5039342641830444
Epoch 0, Step 1617: train/loss = 0.5138254761695862, train/raw-loss = 0.3477800786495209, train/logprobs = tensor([[-3.3519, -7.9236],
        [-6.7069, -3.7772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5534846782684326
Epoch 0, Step 1618: train/loss = 0.5618640184402466, train/raw-loss = 0.44732940196990967, train/logprobs = tensor([[-2.5572, -5.8598],
        [-8.1156, -6.6448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3817821443080902
Epoch 0, Step 1619: train/loss = 0.4213401675224304, train/raw-loss = 0.28830933570861816, train/logprobs = tensor([[-2.5683, -5.8295],
        [-8.0481, -5.5084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4434359669685364
Epoch 0, Step 1620: train/loss = 0.24834470450878143, train/raw-loss = 0.08260711282491684, train/logprobs = tensor([[-3.2593, -7.7478],
        [-7.2843, -4.3673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.552458643913269
Epoch 0, Step 1621: train/loss = 0.2891193628311157, train/raw-loss = 0.013997236266732216, train/logprobs = tensor([[ -3.5634, -10.7539],
        [ -8.0572,  -5.0209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.9170737266540527
Epoch 0, Step 1622: train/loss = 0.37280920147895813, train/raw-loss = 0.21162760257720947, train/logprobs = tensor([[-3.9266, -7.3632],
        [-8.4524, -4.8025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5372719168663025
Epoch 0, Step 1623: train/loss = 0.2526359558105469, train/raw-loss = 0.009692356921732426, train/logprobs = tensor([[ -2.9953, -10.7803],
        [ -7.6747,  -3.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8098119497299194
Epoch 0, Step 1624: train/loss = 0.23485416173934937, train/raw-loss = 0.04924309626221657, train/logprobs = tensor([[-3.4725, -9.9020],
        [-8.3632, -4.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6187035441398621
Epoch 0, Step 1625: train/loss = 0.3940044045448303, train/raw-loss = 0.24448919296264648, train/logprobs = tensor([[-2.8177, -6.7513],
        [-7.5412, -5.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4983839988708496
Epoch 0, Step 1626: train/loss = 0.31371036171913147, train/raw-loss = 0.09035850316286087, train/logprobs = tensor([[-2.7441, -8.5671],
        [-7.9610, -4.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7445061206817627
Epoch 0, Step 1627: train/loss = 0.29697006940841675, train/raw-loss = 0.16629160940647125, train/logprobs = tensor([[-4.2705, -9.4520],
        [-6.9974, -5.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4355948865413666
Epoch 0, Step 1628: train/loss = 0.6337438225746155, train/raw-loss = 0.4312068819999695, train/logprobs = tensor([[ -4.8992, -10.2627],
        [ -5.4653,  -3.6881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6751229763031006
Epoch 0, Step 1629: train/loss = 0.4531370997428894, train/raw-loss = 0.3208714425563812, train/logprobs = tensor([[-2.9891, -6.1569],
        [-7.6642, -5.1220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.440885454416275
Epoch 0, Step 1630: train/loss = 0.2646755278110504, train/raw-loss = 0.12138723582029343, train/logprobs = tensor([[-3.2379, -7.0637],
        [-8.0965, -4.8440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.47762757539749146
Epoch 0, Step 1631: train/loss = 0.42248713970184326, train/raw-loss = 0.32110148668289185, train/logprobs = tensor([[-3.3001, -6.6917],
        [-5.8631, -4.1682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3379521369934082
Epoch 0, Step 1632: train/loss = 0.2100134640932083, train/raw-loss = 0.04861850664019585, train/logprobs = tensor([[-3.3875, -9.9251],
        [-7.9996, -4.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5379831790924072
Epoch 0, Step 1633: train/loss = 0.3010362982749939, train/raw-loss = 0.11343453079462051, train/logprobs = tensor([[-3.1725, -6.6348],
        [-9.3263, -5.7627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.625339150428772
Epoch 0, Step 1634: train/loss = 0.3488236367702484, train/raw-loss = 0.035248052328825, train/logprobs = tensor([[ -3.0795, -10.5898],
        [ -8.7108,  -5.5627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0452519655227661
Epoch 0, Step 1635: train/loss = 0.23148198425769806, train/raw-loss = 0.022801756858825684, train/logprobs = tensor([[-3.8651, -9.3989],
        [-8.8112, -5.4186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6956007480621338
Epoch 0, Step 1636: train/loss = 0.2754710614681244, train/raw-loss = 0.04147922992706299, train/logprobs = tensor([[ -4.5565, -10.3656],
        [ -9.1051,  -6.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.7799727916717529
Epoch 0, Step 1637: train/loss = 0.33368629217147827, train/raw-loss = 0.1315283179283142, train/logprobs = tensor([[-3.2023, -8.5474],
        [-8.8866, -4.8667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6738598942756653
Epoch 0, Step 1638: train/loss = 0.20454120635986328, train/raw-loss = 0.029697490856051445, train/logprobs = tensor([[ -4.8093, -12.0144],
        [ -6.1795,  -3.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5828123092651367
Epoch 0, Step 1639: train/loss = 0.2043042778968811, train/raw-loss = 0.037452854216098785, train/logprobs = tensor([[-3.0202, -8.1539],
        [-8.3278, -4.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5561712980270386
Epoch 0, Step 1640: train/loss = 0.2886810302734375, train/raw-loss = 0.12470189481973648, train/logprobs = tensor([[-3.4346, -8.5622],
        [-9.1932, -6.9508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.5465971231460571
Epoch 0, Step 1641: train/loss = 0.2603796124458313, train/raw-loss = 0.02001480758190155, train/logprobs = tensor([[ -2.7373,  -9.7740],
        [-10.0119,  -5.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.8012159466743469
Epoch 0, Step 1642: train/loss = 0.5955637693405151, train/raw-loss = 0.41389310359954834, train/logprobs = tensor([[-4.3857, -9.6998],
        [-8.4194, -4.9888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.6055688858032227
