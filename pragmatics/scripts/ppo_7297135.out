[2024-02-19 18:48:27,446][root][INFO] - beta: 0.5
[2024-02-19 18:48:27,447][root][INFO] - temperature: 1
[2024-02-19 18:48:27,447][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-batch-size-64
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 20000 training examples...
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-batch-size-64 after each epoch.
train dataset has 19000 examples.
eval dataset has 1000 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-batch-size-64 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-batch-size-64 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.5-batch-size-64 after each epoch.
Epoch 0, Step 0: train/loss = 0.7040798664093018, train/raw-loss = 0.7040798664093018, train/logprobs = tensor([[-0.9533, -0.9948],
        [-0.9302, -0.8604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.7164785265922546, train/raw-loss = 0.7164785265922546, train/logprobs = tensor([[-1.0724, -1.4169],
        [-1.1293, -1.2751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7007112503051758, train/raw-loss = 0.7007112503051758, train/logprobs = tensor([[-0.8302, -0.9350],
        [-0.7845, -0.8587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.6975338459014893, train/raw-loss = 0.6975338459014893, train/logprobs = tensor([[-0.9099, -0.9087],
        [-0.9060, -0.8996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.6946052312850952, train/raw-loss = 0.6946052312850952, train/logprobs = tensor([[-0.7761, -0.8804],
        [-0.8097, -0.8308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7074680328369141, train/raw-loss = 0.7074680328369141, train/logprobs = tensor([[-1.2210, -1.1801],
        [-1.2999, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.6987193822860718, train/raw-loss = 0.6987193822860718, train/logprobs = tensor([[-1.1771, -1.2348],
        [-1.1741, -1.1211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.7075663805007935, train/raw-loss = 0.7075663805007935, train/logprobs = tensor([[-0.7880, -0.6978],
        [-0.8163, -0.6745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.742479681968689, train/raw-loss = 0.742479681968689, train/logprobs = tensor([[-0.9000, -1.5068],
        [-0.8656, -1.3953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.6987901329994202, train/raw-loss = 0.6987901329994202, train/logprobs = tensor([[-0.9074, -1.1629],
        [-0.9010, -1.0296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7119882702827454, train/raw-loss = 0.7119882702827454, train/logprobs = tensor([[-1.2293, -1.1969],
        [-1.2240, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7207285761833191, train/raw-loss = 0.7207285761833191, train/logprobs = tensor([[-1.0679, -0.9060],
        [-1.0898, -0.8208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7011242508888245, train/raw-loss = 0.7011242508888245, train/logprobs = tensor([[-0.8549, -1.0949],
        [-0.8891, -1.0472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.7031682729721069, train/raw-loss = 0.7031682729721069, train/logprobs = tensor([[-0.8906, -1.0827],
        [-0.9134, -1.0358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7142623662948608, train/raw-loss = 0.7142623662948608, train/logprobs = tensor([[-0.8982, -0.9696],
        [-0.8924, -0.8643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.7054764628410339, train/raw-loss = 0.7054764628410339, train/logprobs = tensor([[-0.5966, -0.8092],
        [-0.5724, -0.7484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.6938965320587158, train/raw-loss = 0.6938965320587158, train/logprobs = tensor([[-1.0988, -1.1515],
        [-1.0541, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7236944437026978, train/raw-loss = 0.7236944437026978, train/logprobs = tensor([[-0.8199, -1.2773],
        [-0.7945, -1.1613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.6943728923797607, train/raw-loss = 0.6943728923797607, train/logprobs = tensor([[-1.0141, -1.0339],
        [-1.0263, -0.9778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.6956578493118286, train/raw-loss = 0.6956578493118286, train/logprobs = tensor([[-1.1737, -1.1441],
        [-1.1765, -1.0766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7437841296195984, train/raw-loss = 0.7437841296195984, train/logprobs = tensor([[-0.5573, -1.0747],
        [-0.5540, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7071292996406555, train/raw-loss = 0.7071292996406555, train/logprobs = tensor([[-1.0698, -0.9658],
        [-1.0991, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.7120579481124878, train/raw-loss = 0.7120579481124878, train/logprobs = tensor([[-1.1177, -1.1496],
        [-1.1588, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.7534469962120056, train/raw-loss = 0.7534469962120056, train/logprobs = tensor([[-0.9588, -1.4736],
        [-0.9477, -1.3264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.6944814920425415, train/raw-loss = 0.6944814920425415, train/logprobs = tensor([[-1.3211, -1.4845],
        [-1.2829, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7182225584983826, train/raw-loss = 0.7182225584983826, train/logprobs = tensor([[-0.9310, -0.9236],
        [-0.9353, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7320457696914673, train/raw-loss = 0.7320457696914673, train/logprobs = tensor([[-0.9226, -1.0176],
        [-0.9618, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7064348459243774, train/raw-loss = 0.7064348459243774, train/logprobs = tensor([[-0.9682, -1.0804],
        [-0.9400, -1.0020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7004761099815369, train/raw-loss = 0.7004761099815369, train/logprobs = tensor([[-1.0793, -1.2677],
        [-1.0354, -1.2058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7071655988693237, train/raw-loss = 0.7071655988693237, train/logprobs = tensor([[-0.8737, -0.9530],
        [-0.8765, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7233868837356567, train/raw-loss = 0.7233868837356567, train/logprobs = tensor([[-0.9774, -1.2341],
        [-0.9461, -1.1796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.8921672105789185, train/raw-loss = 0.8921672105789185, train/logprobs = tensor([[-0.7943, -1.4819],
        [-0.8081, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.7119712829589844, train/raw-loss = 0.7119702696800232, train/logprobs = tensor([[-0.8859, -1.0034],
        [-0.9076, -0.9590]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0564002625178546e-06
Epoch 0, Step 33: train/loss = 0.7007914185523987, train/raw-loss = 0.7007849216461182, train/logprobs = tensor([[-0.9867, -0.9311],
        [-0.9680, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2969394447281957e-05
Epoch 0, Step 34: train/loss = 0.7557518482208252, train/raw-loss = 0.7557135820388794, train/logprobs = tensor([[-0.6010, -1.2180],
        [-0.5881, -1.1337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.657838432351127e-05
Epoch 0, Step 35: train/loss = 0.685596764087677, train/raw-loss = 0.6855961680412292, train/logprobs = tensor([[-0.8457, -1.0296],
        [-1.1835, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2011128092126455e-06
Epoch 0, Step 36: train/loss = 0.6972798109054565, train/raw-loss = 0.6972534656524658, train/logprobs = tensor([[-0.9103, -1.0232],
        [-0.9302, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2792049245908856e-05
Epoch 0, Step 37: train/loss = 0.7982800006866455, train/raw-loss = 0.7982785701751709, train/logprobs = tensor([[-0.6690, -1.1977],
        [-0.6762, -1.1127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.829241566359997e-06
Epoch 0, Step 38: train/loss = 0.6937490701675415, train/raw-loss = 0.693748950958252, train/logprobs = tensor([[-0.7695, -0.8394],
        [-0.8064, -0.7867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4608485798817128e-07
Epoch 0, Step 39: train/loss = 0.6966569423675537, train/raw-loss = 0.6966512203216553, train/logprobs = tensor([[-0.7991, -0.7422],
        [-0.8072, -0.7289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1517833627294749e-05
Epoch 0, Step 40: train/loss = 0.6990805864334106, train/raw-loss = 0.6990691423416138, train/logprobs = tensor([[-0.8201, -0.8223],
        [-0.8709, -0.8096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2834101400803775e-05
Epoch 0, Step 41: train/loss = 0.6955870389938354, train/raw-loss = 0.6955766081809998, train/logprobs = tensor([[-1.0444, -0.9780],
        [-1.0731, -0.9555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.093690272886306e-05
Epoch 0, Step 42: train/loss = 0.6965392827987671, train/raw-loss = 0.6965253353118896, train/logprobs = tensor([[-1.2474, -1.4844],
        [-1.2784, -1.3954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7878257242264226e-05
Epoch 0, Step 43: train/loss = 0.9545753002166748, train/raw-loss = 0.9545386433601379, train/logprobs = tensor([[-0.6983, -1.9205],
        [-0.8204, -1.8034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.334601832553744e-05
Epoch 0, Step 44: train/loss = 0.7402193546295166, train/raw-loss = 0.740190863609314, train/logprobs = tensor([[-0.9448, -1.3778],
        [-0.9683, -1.2605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.6984659750014544e-05
Epoch 0, Step 45: train/loss = 0.703935980796814, train/raw-loss = 0.7039045691490173, train/logprobs = tensor([[-0.7382, -1.0730],
        [-0.7462, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.293295882642269e-05
Epoch 0, Step 46: train/loss = 0.7073204517364502, train/raw-loss = 0.7073009014129639, train/logprobs = tensor([[-1.2157, -1.4752],
        [-1.2530, -1.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.904690674971789e-05
Epoch 0, Step 47: train/loss = 0.7041391730308533, train/raw-loss = 0.7041267156600952, train/logprobs = tensor([[-1.0087, -0.8339],
        [-1.0162, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4853681679815054e-05
Epoch 0, Step 48: train/loss = 0.7307190895080566, train/raw-loss = 0.7306610345840454, train/logprobs = tensor([[-0.8493, -1.2683],
        [-0.8155, -1.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001162064727395773
Epoch 0, Step 49: train/loss = 0.7065223455429077, train/raw-loss = 0.7064441442489624, train/logprobs = tensor([[-1.1656, -0.9907],
        [-1.2079, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001563952537253499
Epoch 0, Step 50: train/loss = 0.6977514028549194, train/raw-loss = 0.6977143287658691, train/logprobs = tensor([[-0.9615, -1.1859],
        [-1.0569, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.412488048430532e-05
Epoch 0, Step 51: train/loss = 0.7400108575820923, train/raw-loss = 0.73983234167099, train/logprobs = tensor([[-0.8910, -1.4046],
        [-0.9214, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035695519181899726
Epoch 0, Step 52: train/loss = 0.7307057976722717, train/raw-loss = 0.7305580973625183, train/logprobs = tensor([[-0.7292, -1.0925],
        [-0.8704, -1.0190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029534834902733564
Epoch 0, Step 53: train/loss = 0.6957457661628723, train/raw-loss = 0.6957201957702637, train/logprobs = tensor([[-0.9985, -1.0971],
        [-1.0382, -1.1287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.123892333358526e-05
Epoch 0, Step 54: train/loss = 0.7065505981445312, train/raw-loss = 0.7064647674560547, train/logprobs = tensor([[-1.2546, -1.3991],
        [-1.2642, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017155073874164373
Epoch 0, Step 55: train/loss = 0.7237057685852051, train/raw-loss = 0.7236537933349609, train/logprobs = tensor([[-0.9823, -1.5910],
        [-1.0420, -1.4086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010410608956590295
Epoch 0, Step 56: train/loss = 0.6909885406494141, train/raw-loss = 0.6908543109893799, train/logprobs = tensor([[-1.0056, -1.1965],
        [-1.2025, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002684555947780609
Epoch 0, Step 57: train/loss = 0.7226986885070801, train/raw-loss = 0.7226751446723938, train/logprobs = tensor([[-1.0474, -0.8517],
        [-1.0917, -0.7923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.709478162112646e-05
Epoch 0, Step 58: train/loss = 0.6948360204696655, train/raw-loss = 0.6946800947189331, train/logprobs = tensor([[-0.9221, -1.0133],
        [-0.9918, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031167472479864955
Epoch 0, Step 59: train/loss = 0.7136627435684204, train/raw-loss = 0.7136173844337463, train/logprobs = tensor([[-0.8892, -0.8846],
        [-0.9300, -0.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.068462532013655e-05
Epoch 0, Step 60: train/loss = 0.697852611541748, train/raw-loss = 0.6977968215942383, train/logprobs = tensor([[-0.6010, -0.6697],
        [-0.6636, -0.6658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001116099811042659
Epoch 0, Step 61: train/loss = 0.7057148218154907, train/raw-loss = 0.7056939601898193, train/logprobs = tensor([[-0.7953, -0.7770],
        [-0.8705, -0.7401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.169282328803092e-05
Epoch 0, Step 62: train/loss = 0.6993905901908875, train/raw-loss = 0.6993877291679382, train/logprobs = tensor([[-0.7618, -0.9889],
        [-0.7786, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.796315235784277e-06
Epoch 0, Step 63: train/loss = 0.7067835330963135, train/raw-loss = 0.7067171335220337, train/logprobs = tensor([[-1.0801, -0.8856],
        [-1.0609, -0.8305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000132828950881958
Epoch 0, Step 64: train/loss = 0.7059473991394043, train/raw-loss = 0.7059001326560974, train/logprobs = tensor([[-0.6503, -0.8012],
        [-0.6890, -0.7468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.459207649342716e-05
Epoch 0, Step 65: train/loss = 0.6996626853942871, train/raw-loss = 0.6995631456375122, train/logprobs = tensor([[-0.6605, -0.8655],
        [-0.6876, -0.8278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019908969989046454
Epoch 0, Step 66: train/loss = 0.6937785148620605, train/raw-loss = 0.6937494277954102, train/logprobs = tensor([[-0.8211, -0.8012],
        [-0.8965, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.820515798404813e-05
Epoch 0, Step 67: train/loss = 0.695406973361969, train/raw-loss = 0.6950287222862244, train/logprobs = tensor([[-0.7042, -0.8136],
        [-0.8114, -0.8355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007565590785816312
Epoch 0, Step 68: train/loss = 0.7392142415046692, train/raw-loss = 0.7391787767410278, train/logprobs = tensor([[-1.0960, -1.0193],
        [-1.0925, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.099653885234147e-05
Epoch 0, Step 69: train/loss = 0.7919267416000366, train/raw-loss = 0.7912731766700745, train/logprobs = tensor([[-1.0976, -1.2542],
        [-1.1608, -1.1056]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013070686254650354
Epoch 0, Step 70: train/loss = 0.701196014881134, train/raw-loss = 0.7011765241622925, train/logprobs = tensor([[-0.9103, -0.7884],
        [-0.9572, -0.7834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.9059887058101594e-05
Epoch 0, Step 71: train/loss = 0.7230162024497986, train/raw-loss = 0.7229276895523071, train/logprobs = tensor([[-1.0097, -0.8040],
        [-1.0645, -0.7205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017710152314975858
Epoch 0, Step 72: train/loss = 0.6969872117042542, train/raw-loss = 0.6968660950660706, train/logprobs = tensor([[-0.9386, -0.8902],
        [-1.1010, -0.8714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002422201505396515
Epoch 0, Step 73: train/loss = 0.6989403963088989, train/raw-loss = 0.6989372372627258, train/logprobs = tensor([[-0.9014, -0.9640],
        [-0.8969, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.220463546924293e-06
Epoch 0, Step 74: train/loss = 0.742493748664856, train/raw-loss = 0.7417466640472412, train/logprobs = tensor([[-0.6773, -0.9376],
        [-0.7459, -0.8770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001494185533374548
Epoch 0, Step 75: train/loss = 0.6956459283828735, train/raw-loss = 0.6954817175865173, train/logprobs = tensor([[-0.8306, -0.9563],
        [-0.8351, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032846617978066206
Epoch 0, Step 76: train/loss = 0.742027223110199, train/raw-loss = 0.7419686913490295, train/logprobs = tensor([[-0.7777, -1.0397],
        [-0.8787, -1.0114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011713376443367451
Epoch 0, Step 77: train/loss = 0.6956857442855835, train/raw-loss = 0.6956848502159119, train/logprobs = tensor([[-0.9088, -0.9506],
        [-0.9837, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7023994587361813e-06
Epoch 0, Step 78: train/loss = 0.7284626960754395, train/raw-loss = 0.7279210090637207, train/logprobs = tensor([[-0.7672, -1.0256],
        [-0.8068, -1.0413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001083380077034235
Epoch 0, Step 79: train/loss = 0.7032373547554016, train/raw-loss = 0.7029742002487183, train/logprobs = tensor([[-0.8382, -0.8721],
        [-0.8984, -0.8389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005262359045445919
Epoch 0, Step 80: train/loss = 0.6995415687561035, train/raw-loss = 0.6993083357810974, train/logprobs = tensor([[-0.6766, -0.7924],
        [-0.6841, -0.7635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000466412166133523
Epoch 0, Step 81: train/loss = 0.7048239707946777, train/raw-loss = 0.7045426964759827, train/logprobs = tensor([[-1.0079, -1.0488],
        [-1.1244, -1.1126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005625177291221917
Epoch 0, Step 82: train/loss = 0.6946127414703369, train/raw-loss = 0.693689227104187, train/logprobs = tensor([[-0.9013, -1.0244],
        [-0.9818, -1.0018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018469803035259247
Epoch 0, Step 83: train/loss = 0.7053594589233398, train/raw-loss = 0.7052599191665649, train/logprobs = tensor([[-0.7881, -0.8878],
        [-0.9615, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019915090524591506
Epoch 0, Step 84: train/loss = 0.6981979608535767, train/raw-loss = 0.698190450668335, train/logprobs = tensor([[-0.9524, -0.7910],
        [-1.3319, -0.8058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.503183739259839e-05
Epoch 0, Step 85: train/loss = 0.7527900338172913, train/raw-loss = 0.7525282502174377, train/logprobs = tensor([[-1.2559, -1.5401],
        [-1.3330, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005235448479652405
Epoch 0, Step 86: train/loss = 0.6931319832801819, train/raw-loss = 0.6930769681930542, train/logprobs = tensor([[-0.7781, -0.7958],
        [-0.8254, -0.7843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011008515139110386
Epoch 0, Step 87: train/loss = 0.7060661315917969, train/raw-loss = 0.7059901356697083, train/logprobs = tensor([[-0.7407, -0.8120],
        [-0.7896, -0.7782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000152023189002648
Epoch 0, Step 88: train/loss = 0.7011309862136841, train/raw-loss = 0.7009697556495667, train/logprobs = tensor([[-0.7170, -0.9554],
        [-0.7416, -0.8981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000322460982715711
Epoch 0, Step 89: train/loss = 0.6944452524185181, train/raw-loss = 0.6943731904029846, train/logprobs = tensor([[-0.8555, -0.9470],
        [-0.9599, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000144203586387448
Epoch 0, Step 90: train/loss = 0.7499521374702454, train/raw-loss = 0.7496035695075989, train/logprobs = tensor([[-0.7190, -1.2735],
        [-0.8063, -1.2087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006971604307182133
Epoch 0, Step 91: train/loss = 0.7117997407913208, train/raw-loss = 0.7117878794670105, train/logprobs = tensor([[-0.8886, -0.9473],
        [-0.8983, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.366382977925241e-05
Epoch 0, Step 92: train/loss = 0.7493829727172852, train/raw-loss = 0.747084379196167, train/logprobs = tensor([[-0.7181, -1.3099],
        [-0.7609, -1.2658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004597255494445562
Epoch 0, Step 93: train/loss = 0.7009751796722412, train/raw-loss = 0.700410008430481, train/logprobs = tensor([[-0.6806, -0.8126],
        [-0.7418, -0.8498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00113035854883492
Epoch 0, Step 94: train/loss = 0.7121666073799133, train/raw-loss = 0.7120306491851807, train/logprobs = tensor([[-0.9847, -0.8941],
        [-1.0761, -0.8386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002718311734497547
Epoch 0, Step 95: train/loss = 0.7006351947784424, train/raw-loss = 0.7005957365036011, train/logprobs = tensor([[-0.7143, -0.7842],
        [-0.7614, -0.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.895364979049191e-05
Epoch 0, Step 96: train/loss = 0.6982001662254333, train/raw-loss = 0.6977043747901917, train/logprobs = tensor([[-0.7853, -0.9759],
        [-0.8739, -0.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009914187248796225
Epoch 0, Step 97: train/loss = 0.6976544260978699, train/raw-loss = 0.6976385116577148, train/logprobs = tensor([[-0.7186, -0.7913],
        [-0.8099, -0.7793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.175711026415229e-05
Epoch 0, Step 98: train/loss = 0.6915825605392456, train/raw-loss = 0.6910911798477173, train/logprobs = tensor([[-0.8816, -0.9190],
        [-0.9549, -0.8219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009828287875279784
Epoch 0, Step 99: train/loss = 0.71485435962677, train/raw-loss = 0.7148314714431763, train/logprobs = tensor([[-0.8758, -0.8243],
        [-0.9121, -0.8091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.5783817768096924e-05
Epoch 0, Step 100: train/loss = 0.6963291168212891, train/raw-loss = 0.696047306060791, train/logprobs = tensor([[-0.6916, -0.7346],
        [-0.7389, -0.7169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005637517315335572
Epoch 0, Step 101: train/loss = 0.6964409947395325, train/raw-loss = 0.6964012980461121, train/logprobs = tensor([[-0.5372, -0.6530],
        [-0.5676, -0.6441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.936109614092857e-05
Epoch 0, Step 102: train/loss = 0.7201009392738342, train/raw-loss = 0.719947338104248, train/logprobs = tensor([[-1.0382, -0.8425],
        [-1.0577, -0.8270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003070615348406136
Epoch 0, Step 103: train/loss = 0.7042392492294312, train/raw-loss = 0.70387864112854, train/logprobs = tensor([[-0.8817, -0.8189],
        [-0.9544, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007211568299680948
Epoch 0, Step 104: train/loss = 0.7138710021972656, train/raw-loss = 0.7138569355010986, train/logprobs = tensor([[-0.7942, -0.5461],
        [-0.8093, -0.5454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.820628651534207e-05
Epoch 0, Step 105: train/loss = 0.6980440616607666, train/raw-loss = 0.6980322599411011, train/logprobs = tensor([[-0.6387, -0.8515],
        [-0.6841, -0.7972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3670538212172687e-05
Epoch 0, Step 106: train/loss = 0.7409638166427612, train/raw-loss = 0.7408464550971985, train/logprobs = tensor([[-0.6848, -1.1039],
        [-0.7375, -1.1151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023464846890419722
Epoch 0, Step 107: train/loss = 0.7008695006370544, train/raw-loss = 0.7008271217346191, train/logprobs = tensor([[-0.6721, -0.6100],
        [-0.7453, -0.6090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.490408072248101e-05
Epoch 0, Step 108: train/loss = 0.6982790231704712, train/raw-loss = 0.6980679035186768, train/logprobs = tensor([[-0.8321, -0.9990],
        [-0.9074, -1.0174]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004222885181661695
Epoch 0, Step 109: train/loss = 0.6990538835525513, train/raw-loss = 0.6979058980941772, train/logprobs = tensor([[-0.7952, -0.9453],
        [-0.8925, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022959322668612003
Epoch 0, Step 110: train/loss = 0.7120859622955322, train/raw-loss = 0.7114489078521729, train/logprobs = tensor([[-0.7242, -0.6130],
        [-0.7767, -0.5790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012740581296384335
Epoch 0, Step 111: train/loss = 0.7059080600738525, train/raw-loss = 0.7058873772621155, train/logprobs = tensor([[-0.6743, -0.9037],
        [-0.7093, -0.9413]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.140788223594427e-05
Epoch 0, Step 112: train/loss = 0.6972309350967407, train/raw-loss = 0.697110116481781, train/logprobs = tensor([[-0.6456, -0.8304],
        [-0.7342, -0.8030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024158344604074955
Epoch 0, Step 113: train/loss = 0.7081218957901001, train/raw-loss = 0.7080115079879761, train/logprobs = tensor([[-0.8221, -0.8418],
        [-0.8192, -0.7786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002207255456596613
Epoch 0, Step 114: train/loss = 0.6963207721710205, train/raw-loss = 0.6962400674819946, train/logprobs = tensor([[-0.7647, -0.8529],
        [-0.8386, -0.7889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016148737631738186
Epoch 0, Step 115: train/loss = 0.7016729712486267, train/raw-loss = 0.7011495232582092, train/logprobs = tensor([[-0.7185, -1.0130],
        [-0.7917, -0.8259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010469276458024979
Epoch 0, Step 116: train/loss = 0.7223765254020691, train/raw-loss = 0.7223177552223206, train/logprobs = tensor([[-0.8515, -0.4926],
        [-1.0462, -0.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011752946011256427
Epoch 0, Step 117: train/loss = 0.7026774287223816, train/raw-loss = 0.7023822069168091, train/logprobs = tensor([[-0.8440, -0.7399],
        [-0.9208, -0.5822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005904593272134662
Epoch 0, Step 118: train/loss = 0.6997907161712646, train/raw-loss = 0.6996907591819763, train/logprobs = tensor([[-0.5727, -0.7503],
        [-0.6445, -0.7144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019992177840322256
Epoch 0, Step 119: train/loss = 0.695330798625946, train/raw-loss = 0.6947135925292969, train/logprobs = tensor([[-0.6305, -0.6840],
        [-0.6557, -0.7259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001234506955370307
Epoch 0, Step 120: train/loss = 0.7260514497756958, train/raw-loss = 0.7256097793579102, train/logprobs = tensor([[-1.0405, -0.9275],
        [-1.2207, -0.8038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008834131294861436
Epoch 0, Step 121: train/loss = 0.6961604952812195, train/raw-loss = 0.6961004734039307, train/logprobs = tensor([[-0.6984, -0.8155],
        [-0.6821, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000120011274702847
Epoch 0, Step 122: train/loss = 0.7145171761512756, train/raw-loss = 0.714061975479126, train/logprobs = tensor([[-1.0085, -0.7256],
        [-1.0768, -0.6401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000910427188500762
Epoch 0, Step 123: train/loss = 0.6937697529792786, train/raw-loss = 0.6937634944915771, train/logprobs = tensor([[-0.7276, -0.7622],
        [-0.7942, -0.7628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.242855068994686e-05
Epoch 0, Step 124: train/loss = 0.7044066190719604, train/raw-loss = 0.7041786909103394, train/logprobs = tensor([[-0.6728, -0.5704],
        [-0.7237, -0.5870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045580946607515216
Epoch 0, Step 125: train/loss = 0.7013984322547913, train/raw-loss = 0.7012114524841309, train/logprobs = tensor([[-0.8912, -0.8498],
        [-0.9759, -0.8361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003738983068615198
Epoch 0, Step 126: train/loss = 0.719716489315033, train/raw-loss = 0.7195969820022583, train/logprobs = tensor([[-0.9086, -1.1489],
        [-0.9763, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023887540737632662
Epoch 0, Step 127: train/loss = 0.7097885608673096, train/raw-loss = 0.7096392512321472, train/logprobs = tensor([[-0.6885, -0.9009],
        [-0.6998, -0.8704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002986032050102949
Epoch 0, Step 128: train/loss = 0.7465259432792664, train/raw-loss = 0.7462151646614075, train/logprobs = tensor([[-0.9357, -0.4716],
        [-0.9416, -0.4390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006217272020876408
Epoch 0, Step 129: train/loss = 0.7086796164512634, train/raw-loss = 0.7085670828819275, train/logprobs = tensor([[-0.7942, -0.5853],
        [-0.8131, -0.5558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022508311667479575
Epoch 0, Step 130: train/loss = 0.7088882923126221, train/raw-loss = 0.708391547203064, train/logprobs = tensor([[-0.8526, -0.6874],
        [-0.9607, -0.6580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009934387635439634
Epoch 0, Step 131: train/loss = 0.6968294382095337, train/raw-loss = 0.6966226100921631, train/logprobs = tensor([[-0.6853, -0.7579],
        [-0.7390, -0.7007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004135109484195709
Epoch 0, Step 132: train/loss = 0.69590824842453, train/raw-loss = 0.6958065032958984, train/logprobs = tensor([[-0.8255, -0.7713],
        [-0.9122, -0.7527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002036355872405693
Epoch 0, Step 133: train/loss = 0.6978698968887329, train/raw-loss = 0.6977265477180481, train/logprobs = tensor([[-0.6332, -0.7496],
        [-0.7059, -0.7246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028672884218394756
Epoch 0, Step 134: train/loss = 0.7727380394935608, train/raw-loss = 0.7726305723190308, train/logprobs = tensor([[-0.9525, -0.9082],
        [-1.0424, -0.9008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002150575746782124
Epoch 0, Step 135: train/loss = 0.697508692741394, train/raw-loss = 0.6974800825119019, train/logprobs = tensor([[-0.5991, -0.6116],
        [-0.5826, -0.5962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.714191502192989e-05
Epoch 0, Step 136: train/loss = 0.7034299373626709, train/raw-loss = 0.7034099102020264, train/logprobs = tensor([[-0.7918, -0.7260],
        [-1.0741, -0.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.008134419564158e-05
Epoch 0, Step 137: train/loss = 0.7166650295257568, train/raw-loss = 0.7130127549171448, train/logprobs = tensor([[-0.5386, -0.8778],
        [-0.5970, -0.7073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007304527796804905
Epoch 0, Step 138: train/loss = 0.7015958428382874, train/raw-loss = 0.7015307545661926, train/logprobs = tensor([[-0.5535, -0.4721],
        [-0.5967, -0.4322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001300904550589621
Epoch 0, Step 139: train/loss = 0.7098431587219238, train/raw-loss = 0.70964115858078, train/logprobs = tensor([[-0.5282, -0.7134],
        [-0.5572, -0.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040412566158920527
Epoch 0, Step 140: train/loss = 0.7170735597610474, train/raw-loss = 0.7170196771621704, train/logprobs = tensor([[-0.6005, -0.8314],
        [-0.5974, -0.8197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010774453403428197
Epoch 0, Step 141: train/loss = 0.7191784381866455, train/raw-loss = 0.7189855575561523, train/logprobs = tensor([[-0.5118, -0.8287],
        [-0.5615, -0.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038573070196434855
Epoch 0, Step 142: train/loss = 0.7002133727073669, train/raw-loss = 0.6999748945236206, train/logprobs = tensor([[-0.7513, -0.6379],
        [-0.8472, -0.6005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004769692022819072
Epoch 0, Step 143: train/loss = 0.6872031688690186, train/raw-loss = 0.6859745383262634, train/logprobs = tensor([[-0.8266, -0.7941],
        [-1.3125, -0.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002457336988300085
Epoch 0, Step 144: train/loss = 0.7205750942230225, train/raw-loss = 0.71980220079422, train/logprobs = tensor([[-0.7819, -0.7648],
        [-0.8575, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00154567149002105
Epoch 0, Step 145: train/loss = 0.7071698904037476, train/raw-loss = 0.7071186900138855, train/logprobs = tensor([[-0.7969, -0.6467],
        [-0.8327, -0.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010220889816991985
Epoch 0, Step 146: train/loss = 0.7661150693893433, train/raw-loss = 0.7658088803291321, train/logprobs = tensor([[-0.8479, -0.5514],
        [-0.9242, -0.5538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000612399133387953
Epoch 0, Step 147: train/loss = 0.7038448452949524, train/raw-loss = 0.7036198377609253, train/logprobs = tensor([[-0.6289, -0.7319],
        [-0.7273, -0.6514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044987088767811656
Epoch 0, Step 148: train/loss = 0.7070060968399048, train/raw-loss = 0.707001805305481, train/logprobs = tensor([[-0.6692, -0.4915],
        [-0.6744, -0.4662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.63065361045301e-06
Epoch 0, Step 149: train/loss = 0.6973549127578735, train/raw-loss = 0.6972320079803467, train/logprobs = tensor([[-0.7221, -0.7065],
        [-0.7892, -0.6411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024574517738074064
Epoch 0, Step 150: train/loss = 0.6959969401359558, train/raw-loss = 0.6959712505340576, train/logprobs = tensor([[-0.6902, -0.6611],
        [-0.7069, -0.6252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.1358692871872336e-05
Epoch 0, Step 151: train/loss = 0.696406364440918, train/raw-loss = 0.6963875889778137, train/logprobs = tensor([[-0.7180, -0.7310],
        [-0.7426, -0.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.747701703105122e-05
Epoch 0, Step 152: train/loss = 0.711151123046875, train/raw-loss = 0.7109019160270691, train/logprobs = tensor([[-0.7523, -0.5693],
        [-0.8415, -0.5429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000498443201649934
Epoch 0, Step 153: train/loss = 0.6959309577941895, train/raw-loss = 0.6958909630775452, train/logprobs = tensor([[-0.5528, -0.6709],
        [-0.6104, -0.5939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.997584907570854e-05
Epoch 0, Step 154: train/loss = 0.6959686875343323, train/raw-loss = 0.6956480741500854, train/logprobs = tensor([[-0.6713, -0.6302],
        [-0.7821, -0.5829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006413200171664357
Epoch 0, Step 155: train/loss = 0.7114713788032532, train/raw-loss = 0.7113351225852966, train/logprobs = tensor([[-0.5537, -0.7874],
        [-0.5653, -0.7320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002725127269513905
Epoch 0, Step 156: train/loss = 0.7083381414413452, train/raw-loss = 0.7082940340042114, train/logprobs = tensor([[-0.5039, -0.6561],
        [-0.5318, -0.6624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.821557275950909e-05
Epoch 0, Step 157: train/loss = 0.7341471910476685, train/raw-loss = 0.7310582399368286, train/logprobs = tensor([[-0.9187, -0.6476],
        [-0.9614, -0.4730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006178016308695078
Epoch 0, Step 158: train/loss = 0.7451404333114624, train/raw-loss = 0.7449278235435486, train/logprobs = tensor([[-0.9963, -0.5943],
        [-0.9964, -0.5392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042512977961450815
Epoch 0, Step 159: train/loss = 0.7054348587989807, train/raw-loss = 0.7052782773971558, train/logprobs = tensor([[-0.5773, -0.8731],
        [-0.5775, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003132063720840961
Epoch 0, Step 160: train/loss = 0.6956727504730225, train/raw-loss = 0.6953012943267822, train/logprobs = tensor([[-0.7790, -0.7230],
        [-0.8474, -0.6460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000742770847864449
Epoch 0, Step 161: train/loss = 0.6925598978996277, train/raw-loss = 0.6912009716033936, train/logprobs = tensor([[-0.6094, -0.6806],
        [-0.6683, -0.6089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002717875875532627
Epoch 0, Step 162: train/loss = 0.7035031914710999, train/raw-loss = 0.7025929689407349, train/logprobs = tensor([[-0.8028, -0.8219],
        [-0.8975, -0.5804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018204848747700453
Epoch 0, Step 163: train/loss = 0.7009058594703674, train/raw-loss = 0.7008033990859985, train/logprobs = tensor([[-0.8433, -0.7184],
        [-0.9887, -0.7267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000204932177439332
Epoch 0, Step 164: train/loss = 0.7114637494087219, train/raw-loss = 0.7112537622451782, train/logprobs = tensor([[-0.6772, -0.9620],
        [-0.7496, -0.7961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004201041301712394
Epoch 0, Step 165: train/loss = 0.8090206384658813, train/raw-loss = 0.808870792388916, train/logprobs = tensor([[-0.8518, -1.3743],
        [-0.9367, -1.2724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000299736944725737
Epoch 0, Step 166: train/loss = 0.7085357308387756, train/raw-loss = 0.7083696126937866, train/logprobs = tensor([[-0.7853, -0.8384],
        [-0.8206, -0.7473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033223582431674004
Epoch 0, Step 167: train/loss = 0.7000370025634766, train/raw-loss = 0.6996731758117676, train/logprobs = tensor([[-0.6588, -0.7694],
        [-0.6969, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007276554242707789
Epoch 0, Step 168: train/loss = 0.6951759457588196, train/raw-loss = 0.6951333284378052, train/logprobs = tensor([[-0.6709, -0.7360],
        [-0.7099, -0.7185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.528365287929773e-05
Epoch 0, Step 169: train/loss = 0.6944252252578735, train/raw-loss = 0.6943134665489197, train/logprobs = tensor([[-0.5308, -0.5071],
        [-0.5486, -0.4941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002235968131572008
Epoch 0, Step 170: train/loss = 0.6951136589050293, train/raw-loss = 0.6950510740280151, train/logprobs = tensor([[-0.7211, -0.6885],
        [-0.7540, -0.6535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012514350237324834
Epoch 0, Step 171: train/loss = 0.6979290246963501, train/raw-loss = 0.697426438331604, train/logprobs = tensor([[-0.6010, -0.7307],
        [-0.6339, -0.7273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010050986893475056
Epoch 0, Step 172: train/loss = 0.7250389456748962, train/raw-loss = 0.7250202298164368, train/logprobs = tensor([[-0.9600, -0.7785],
        [-1.0353, -0.7762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.739236854016781e-05
Epoch 0, Step 173: train/loss = 0.7050960659980774, train/raw-loss = 0.7007834911346436, train/logprobs = tensor([[-0.6791, -0.9880],
        [-0.6439, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008625084534287453
Epoch 0, Step 174: train/loss = 0.6904061436653137, train/raw-loss = 0.6873981356620789, train/logprobs = tensor([[-0.6128, -0.7483],
        [-0.6959, -0.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006016010884195566
Epoch 0, Step 175: train/loss = 0.6991381049156189, train/raw-loss = 0.6984831690788269, train/logprobs = tensor([[-0.8958, -0.8997],
        [-0.9942, -0.7121]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013098481576889753
Epoch 0, Step 176: train/loss = 0.6998651623725891, train/raw-loss = 0.6993492841720581, train/logprobs = tensor([[-0.7945, -0.8051],
        [-0.8496, -0.6695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001031612977385521
Epoch 0, Step 177: train/loss = 0.6963866353034973, train/raw-loss = 0.6962441802024841, train/logprobs = tensor([[-0.8355, -0.8104],
        [-0.9493, -0.7376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002847472205758095
Epoch 0, Step 178: train/loss = 0.6906541585922241, train/raw-loss = 0.6756740808486938, train/logprobs = tensor([[-0.7029, -1.3754],
        [-0.8363, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029960252344608307
Epoch 0, Step 179: train/loss = 0.6987975835800171, train/raw-loss = 0.6986897587776184, train/logprobs = tensor([[-0.6056, -0.5540],
        [-0.5887, -0.4654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021565542556345463
Epoch 0, Step 180: train/loss = 0.717849850654602, train/raw-loss = 0.7169913053512573, train/logprobs = tensor([[-0.7270, -0.6341],
        [-0.8193, -0.5549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017170659266412258
Epoch 0, Step 181: train/loss = 0.7031509876251221, train/raw-loss = 0.7022976875305176, train/logprobs = tensor([[-0.6851, -0.7457],
        [-0.7141, -0.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017066143918782473
Epoch 0, Step 182: train/loss = 0.7078936100006104, train/raw-loss = 0.7077940106391907, train/logprobs = tensor([[-0.8125, -0.9827],
        [-0.8245, -0.9645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019922801584471017
Epoch 0, Step 183: train/loss = 0.6998151540756226, train/raw-loss = 0.6988973617553711, train/logprobs = tensor([[-0.7192, -0.8343],
        [-0.7810, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018356122309342027
Epoch 0, Step 184: train/loss = 0.7005946636199951, train/raw-loss = 0.7004488110542297, train/logprobs = tensor([[-0.7949, -0.7044],
        [-0.8337, -0.6841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029173213988542557
Epoch 0, Step 185: train/loss = 0.6941424012184143, train/raw-loss = 0.6936842203140259, train/logprobs = tensor([[-0.7685, -1.0858],
        [-0.8009, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009163799113593996
Epoch 0, Step 186: train/loss = 0.703598141670227, train/raw-loss = 0.7034331560134888, train/logprobs = tensor([[-0.8927, -0.7610],
        [-0.9095, -0.6554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032996549271047115
Epoch 0, Step 187: train/loss = 0.6948379874229431, train/raw-loss = 0.6937866806983948, train/logprobs = tensor([[-0.6636, -0.7453],
        [-0.7295, -0.6343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002102547325193882
Epoch 0, Step 188: train/loss = 0.7034518718719482, train/raw-loss = 0.7033911943435669, train/logprobs = tensor([[-0.7192, -0.8080],
        [-0.7602, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012111762771382928
Epoch 0, Step 189: train/loss = 0.7056930065155029, train/raw-loss = 0.7055746912956238, train/logprobs = tensor([[-0.5357, -0.6688],
        [-0.6772, -0.6339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023669828078709543
Epoch 0, Step 190: train/loss = 0.6934734582901001, train/raw-loss = 0.6929183602333069, train/logprobs = tensor([[-0.5598, -0.6619],
        [-0.6475, -0.5207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00111019192263484
Epoch 0, Step 191: train/loss = 0.6950085163116455, train/raw-loss = 0.6950022578239441, train/logprobs = tensor([[-0.7642, -0.7079],
        [-0.7456, -0.6888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2553846318041906e-05
Epoch 0, Step 192: train/loss = 0.6939597129821777, train/raw-loss = 0.6937821507453918, train/logprobs = tensor([[-0.6307, -0.6031],
        [-0.6804, -0.5694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035516719799488783
Epoch 0, Step 193: train/loss = 0.7056760787963867, train/raw-loss = 0.70511794090271, train/logprobs = tensor([[-0.5768, -0.9389],
        [-0.7004, -0.8251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00111634680069983
Epoch 0, Step 194: train/loss = 0.7214739918708801, train/raw-loss = 0.7166176438331604, train/logprobs = tensor([[-0.7564, -1.1548],
        [-0.9094, -0.7906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009712588042020798
Epoch 0, Step 195: train/loss = 0.7448931336402893, train/raw-loss = 0.7447980642318726, train/logprobs = tensor([[-1.0360, -0.8357],
        [-1.1044, -0.7619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019003808847628534
Epoch 0, Step 196: train/loss = 0.6947395205497742, train/raw-loss = 0.6927682161331177, train/logprobs = tensor([[-0.9792, -0.9655],
        [-1.0155, -0.6942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003942587878555059
Epoch 0, Step 197: train/loss = 0.7234306931495667, train/raw-loss = 0.7230178117752075, train/logprobs = tensor([[-0.6169, -0.9481],
        [-0.6549, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008257144363597035
Epoch 0, Step 198: train/loss = 0.7281104326248169, train/raw-loss = 0.7269365787506104, train/logprobs = tensor([[-1.2931, -1.1653],
        [-1.3130, -1.0373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023477920331060886
Epoch 0, Step 199: train/loss = 0.7053910493850708, train/raw-loss = 0.7044007778167725, train/logprobs = tensor([[-0.8417, -0.8678],
        [-0.8842, -0.7288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019806635100394487
Epoch 0, Step 200: train/loss = 0.6953475475311279, train/raw-loss = 0.6949687004089355, train/logprobs = tensor([[-0.7789, -0.8236],
        [-0.7983, -0.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007575845811516047
Epoch 0, Step 201: train/loss = 0.7028952836990356, train/raw-loss = 0.6990215182304382, train/logprobs = tensor([[-0.7663, -1.2464],
        [-0.9316, -0.8363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007747551891952753
Epoch 0, Step 202: train/loss = 0.696688711643219, train/raw-loss = 0.6963201761245728, train/logprobs = tensor([[-0.9911, -0.9124],
        [-1.0041, -0.8170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007369961822405457
Epoch 0, Step 203: train/loss = 0.6993549466133118, train/raw-loss = 0.6973971724510193, train/logprobs = tensor([[-0.7130, -0.9096],
        [-0.7991, -0.7223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003915539477020502
Epoch 0, Step 204: train/loss = 0.705436110496521, train/raw-loss = 0.7031216621398926, train/logprobs = tensor([[-0.8102, -1.0478],
        [-0.8520, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004628899972885847
Epoch 0, Step 205: train/loss = 0.7008126974105835, train/raw-loss = 0.7007535099983215, train/logprobs = tensor([[-0.8313, -0.6904],
        [-0.8802, -0.6558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011839534272439778
Epoch 0, Step 206: train/loss = 0.6977207660675049, train/raw-loss = 0.6977069973945618, train/logprobs = tensor([[-0.6241, -0.5077],
        [-0.6820, -0.5311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.7641923225019127e-05
Epoch 0, Step 207: train/loss = 0.697192370891571, train/raw-loss = 0.6967360973358154, train/logprobs = tensor([[-0.6985, -0.9331],
        [-0.7406, -0.8073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000912519870325923
Epoch 0, Step 208: train/loss = 0.6961855292320251, train/raw-loss = 0.6957937479019165, train/logprobs = tensor([[-0.6672, -0.6892],
        [-0.6530, -0.5956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007836028817109764
Epoch 0, Step 209: train/loss = 0.754367470741272, train/raw-loss = 0.7537634372711182, train/logprobs = tensor([[-0.8010, -1.1202],
        [-0.7992, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001207935158163309
Epoch 0, Step 210: train/loss = 0.6939874887466431, train/raw-loss = 0.6939672827720642, train/logprobs = tensor([[-0.6655, -0.6941],
        [-0.6724, -0.6418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.0450075175613165e-05
Epoch 0, Step 211: train/loss = 0.7002934217453003, train/raw-loss = 0.7000895738601685, train/logprobs = tensor([[-0.7258, -0.7070],
        [-0.7625, -0.5987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040766445454210043
Epoch 0, Step 212: train/loss = 0.7090281844139099, train/raw-loss = 0.7071539759635925, train/logprobs = tensor([[-0.7181, -0.9366],
        [-0.7777, -1.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003748421324416995
Epoch 0, Step 213: train/loss = 0.7984327077865601, train/raw-loss = 0.7927775382995605, train/logprobs = tensor([[-0.8194, -1.3180],
        [-0.9172, -1.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011310332454741001
Epoch 0, Step 214: train/loss = 0.696844220161438, train/raw-loss = 0.6967980265617371, train/logprobs = tensor([[-0.6107, -0.5205],
        [-0.7250, -0.5448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.237707126885653e-05
Epoch 0, Step 215: train/loss = 0.7025793790817261, train/raw-loss = 0.7019029259681702, train/logprobs = tensor([[-0.6428, -0.8490],
        [-0.6476, -0.7474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013529384741559625
Epoch 0, Step 216: train/loss = 0.7165635228157043, train/raw-loss = 0.7138831615447998, train/logprobs = tensor([[-0.8223, -1.0420],
        [-0.8198, -0.7895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005360647104680538
Epoch 0, Step 217: train/loss = 0.694912314414978, train/raw-loss = 0.6945374011993408, train/logprobs = tensor([[-0.6884, -0.6539],
        [-0.8239, -0.5852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000749864149838686
Epoch 0, Step 218: train/loss = 0.711293637752533, train/raw-loss = 0.710990309715271, train/logprobs = tensor([[-0.9467, -0.7725],
        [-0.9812, -0.6173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006067158537916839
Epoch 0, Step 219: train/loss = 0.7148334980010986, train/raw-loss = 0.7142633199691772, train/logprobs = tensor([[-0.6672, -0.9571],
        [-0.8330, -0.9483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011402990203350782
Epoch 0, Step 220: train/loss = 0.7019293308258057, train/raw-loss = 0.6999620199203491, train/logprobs = tensor([[-0.7978, -1.0295],
        [-0.8189, -0.6934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003934629261493683
Epoch 0, Step 221: train/loss = 0.6961241364479065, train/raw-loss = 0.6946935057640076, train/logprobs = tensor([[-0.7881, -0.7773],
        [-0.7896, -0.7689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028612350579351187
Epoch 0, Step 222: train/loss = 0.6944097280502319, train/raw-loss = 0.6937795877456665, train/logprobs = tensor([[-0.6954, -0.7125],
        [-0.7969, -0.6985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012601581402122974
Epoch 0, Step 223: train/loss = 0.7051228880882263, train/raw-loss = 0.7046582698822021, train/logprobs = tensor([[-0.7437, -0.6193],
        [-0.8071, -0.6073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009293965995311737
Epoch 0, Step 224: train/loss = 0.7418357133865356, train/raw-loss = 0.7395569086074829, train/logprobs = tensor([[-1.1826, -1.1378],
        [-1.2824, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004557641688734293
Epoch 0, Step 225: train/loss = 0.7314419746398926, train/raw-loss = 0.7303704023361206, train/logprobs = tensor([[-0.9023, -1.1893],
        [-1.0589, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021430207416415215
Epoch 0, Step 226: train/loss = 0.715491533279419, train/raw-loss = 0.7148659229278564, train/logprobs = tensor([[-0.9513, -0.8182],
        [-1.0312, -0.6897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012511236127465963
Epoch 0, Step 227: train/loss = 0.7156447172164917, train/raw-loss = 0.7120267748832703, train/logprobs = tensor([[-0.6612, -1.2648],
        [-0.7222, -0.9351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007235964760184288
Epoch 0, Step 228: train/loss = 0.6913905143737793, train/raw-loss = 0.6813848614692688, train/logprobs = tensor([[-1.0246, -1.4419],
        [-0.9423, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020011181011795998
Epoch 0, Step 229: train/loss = 0.7004234194755554, train/raw-loss = 0.6997703313827515, train/logprobs = tensor([[-0.7106, -0.9916],
        [-0.7060, -0.7795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013060742057859898
Epoch 0, Step 230: train/loss = 0.7320387363433838, train/raw-loss = 0.7268502712249756, train/logprobs = tensor([[-0.6164, -1.3404],
        [-0.6335, -0.9383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01037696935236454
Epoch 0, Step 231: train/loss = 0.6965703964233398, train/raw-loss = 0.6962000131607056, train/logprobs = tensor([[-0.5772, -0.6879],
        [-0.5954, -0.6157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007408025558106601
Epoch 0, Step 232: train/loss = 0.7060627937316895, train/raw-loss = 0.7058430910110474, train/logprobs = tensor([[-0.7522, -0.9054],
        [-0.7802, -0.8456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004393550334498286
Epoch 0, Step 233: train/loss = 0.6965094208717346, train/raw-loss = 0.6865966320037842, train/logprobs = tensor([[-0.7638, -1.1644],
        [-0.8195, -0.7808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019825519993901253
Epoch 0, Step 234: train/loss = 0.7097869515419006, train/raw-loss = 0.709304928779602, train/logprobs = tensor([[-0.9603, -0.7745],
        [-1.0385, -0.7293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009639992495067418
Epoch 0, Step 235: train/loss = 0.6946465969085693, train/raw-loss = 0.6941180229187012, train/logprobs = tensor([[-0.7376, -0.7609],
        [-0.8028, -0.6262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010570524027571082
Epoch 0, Step 236: train/loss = 0.7213129997253418, train/raw-loss = 0.707206666469574, train/logprobs = tensor([[-1.1022, -1.7960],
        [-0.9404, -0.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02821274660527706
Epoch 0, Step 237: train/loss = 0.6969963908195496, train/raw-loss = 0.6946144104003906, train/logprobs = tensor([[-0.8136, -0.9055],
        [-0.7964, -0.6598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004763827659189701
Epoch 0, Step 238: train/loss = 0.7123350501060486, train/raw-loss = 0.7093966007232666, train/logprobs = tensor([[-0.6450, -0.8270],
        [-0.6703, -0.5836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00587692204862833
Epoch 0, Step 239: train/loss = 0.7044288516044617, train/raw-loss = 0.7038087248802185, train/logprobs = tensor([[-0.7989, -0.7451],
        [-0.8370, -0.6276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012402907013893127
Epoch 0, Step 240: train/loss = 0.6983636617660522, train/raw-loss = 0.6982879638671875, train/logprobs = tensor([[-0.9285, -0.8409],
        [-0.8918, -0.7745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001514292962383479
Epoch 0, Step 241: train/loss = 0.7579516768455505, train/raw-loss = 0.755168080329895, train/logprobs = tensor([[-1.0000, -1.1817],
        [-1.0754, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055670663714408875
Epoch 0, Step 242: train/loss = 0.7062082290649414, train/raw-loss = 0.6905276775360107, train/logprobs = tensor([[-0.8648, -1.4513],
        [-1.0030, -0.9676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03136106953024864
Epoch 0, Step 243: train/loss = 0.7087777853012085, train/raw-loss = 0.7063137292861938, train/logprobs = tensor([[-0.9813, -1.4129],
        [-1.0572, -1.0650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004927999339997768
Epoch 0, Step 244: train/loss = 0.6960250735282898, train/raw-loss = 0.6933684349060059, train/logprobs = tensor([[-0.8496, -1.0997],
        [-0.8051, -0.7860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00531324278563261
Epoch 0, Step 245: train/loss = 0.7397911548614502, train/raw-loss = 0.7393137812614441, train/logprobs = tensor([[-0.7212, -1.1497],
        [-0.7713, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009547426598146558
Epoch 0, Step 246: train/loss = 0.7259269952774048, train/raw-loss = 0.7227518558502197, train/logprobs = tensor([[-1.0259, -0.7137],
        [-1.2323, -0.5768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006350445561110973
Epoch 0, Step 247: train/loss = 0.7095369100570679, train/raw-loss = 0.7092137336730957, train/logprobs = tensor([[-0.6838, -0.8896],
        [-0.7285, -0.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006462900782935321
Epoch 0, Step 248: train/loss = 0.7193514108657837, train/raw-loss = 0.7182897329330444, train/logprobs = tensor([[-0.9589, -1.4625],
        [-0.9368, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021233847364783287
Epoch 0, Step 249: train/loss = 0.6954913139343262, train/raw-loss = 0.6954818964004517, train/logprobs = tensor([[-0.6344, -0.7850],
        [-0.6200, -0.6732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.890110070235096e-05
Epoch 0, Step 250: train/loss = 0.69549560546875, train/raw-loss = 0.6943909525871277, train/logprobs = tensor([[-0.6822, -0.8581],
        [-0.8063, -0.7903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002209371654316783
Epoch 0, Step 251: train/loss = 0.7320312261581421, train/raw-loss = 0.730146050453186, train/logprobs = tensor([[-0.8702, -1.3533],
        [-0.9349, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037704412825405598
Epoch 0, Step 252: train/loss = 0.714350700378418, train/raw-loss = 0.7141755819320679, train/logprobs = tensor([[-0.7190, -0.9096],
        [-0.7512, -0.7826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035012030275538564
Epoch 0, Step 253: train/loss = 0.7061445713043213, train/raw-loss = 0.7027481198310852, train/logprobs = tensor([[-0.9577, -0.8392],
        [-1.0362, -0.6762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0067929234355688095
Epoch 0, Step 254: train/loss = 0.7158462405204773, train/raw-loss = 0.7135357856750488, train/logprobs = tensor([[-0.8337, -1.3516],
        [-0.9126, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004620854277163744
Epoch 0, Step 255: train/loss = 0.7141537070274353, train/raw-loss = 0.7125105857849121, train/logprobs = tensor([[-0.6029, -0.7427],
        [-0.8402, -0.6080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032861921936273575
Epoch 0, Step 256: train/loss = 0.6965997815132141, train/raw-loss = 0.6961679458618164, train/logprobs = tensor([[-1.0867, -1.0415],
        [-0.9911, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008636917918920517
Epoch 0, Step 257: train/loss = 0.694365382194519, train/raw-loss = 0.691359281539917, train/logprobs = tensor([[-0.9746, -1.2561],
        [-0.9267, -0.8377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006012044847011566
Epoch 0, Step 258: train/loss = 0.6956703066825867, train/raw-loss = 0.6859053373336792, train/logprobs = tensor([[-0.8334, -1.3398],
        [-1.1541, -0.8214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019529934972524643
Epoch 0, Step 259: train/loss = 0.6957437992095947, train/raw-loss = 0.6943511962890625, train/logprobs = tensor([[-0.7044, -0.9204],
        [-0.6955, -0.6978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002785178367048502
Epoch 0, Step 260: train/loss = 0.7144300937652588, train/raw-loss = 0.7084187865257263, train/logprobs = tensor([[-0.8304, -1.2681],
        [-0.8772, -0.8493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012022454291582108
Epoch 0, Step 261: train/loss = 0.7112546563148499, train/raw-loss = 0.7107065916061401, train/logprobs = tensor([[-0.8200, -1.1589],
        [-0.8415, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001096002059057355
Epoch 0, Step 262: train/loss = 0.7181574106216431, train/raw-loss = 0.7144911289215088, train/logprobs = tensor([[-1.1024, -1.1567],
        [-1.1512, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007332526613026857
Epoch 0, Step 263: train/loss = 0.6945005655288696, train/raw-loss = 0.6944993734359741, train/logprobs = tensor([[-0.5610, -0.5573],
        [-0.5680, -0.5470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3266038624569774e-06
Epoch 0, Step 264: train/loss = 0.7299038171768188, train/raw-loss = 0.726678729057312, train/logprobs = tensor([[-0.7243, -1.3069],
        [-0.7633, -0.9022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006450253073126078
Epoch 0, Step 265: train/loss = 0.7237496376037598, train/raw-loss = 0.7209745645523071, train/logprobs = tensor([[-0.9384, -1.4592],
        [-0.9046, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005549994297325611
Epoch 0, Step 266: train/loss = 0.7367457151412964, train/raw-loss = 0.7336234450340271, train/logprobs = tensor([[-1.0349, -1.1702],
        [-1.0712, -0.8192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006244602147489786
Epoch 0, Step 267: train/loss = 0.6993169188499451, train/raw-loss = 0.698774516582489, train/logprobs = tensor([[-0.7607, -0.9448],
        [-0.7103, -0.7706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010848157107830048
Epoch 0, Step 268: train/loss = 0.8155760765075684, train/raw-loss = 0.8148886561393738, train/logprobs = tensor([[-0.9352, -1.7256],
        [-0.7231, -1.4581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013749322388321161
Epoch 0, Step 269: train/loss = 0.6984330415725708, train/raw-loss = 0.6953828930854797, train/logprobs = tensor([[-0.7946, -1.1431],
        [-0.7992, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061002615839242935
Epoch 0, Step 270: train/loss = 0.7167023420333862, train/raw-loss = 0.7143478393554688, train/logprobs = tensor([[-0.6175, -1.1460],
        [-0.6012, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004709041677415371
Epoch 0, Step 271: train/loss = 0.7015879154205322, train/raw-loss = 0.7012688517570496, train/logprobs = tensor([[-1.0968, -1.0185],
        [-1.1235, -0.9481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006381797138601542
Epoch 0, Step 272: train/loss = 0.6982955932617188, train/raw-loss = 0.6977516412734985, train/logprobs = tensor([[-0.9441, -0.8058],
        [-1.0004, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010881649795919657
Epoch 0, Step 273: train/loss = 0.6941652894020081, train/raw-loss = 0.6914162635803223, train/logprobs = tensor([[-0.7997, -0.9934],
        [-0.8660, -0.7553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0054979571141302586
Epoch 0, Step 274: train/loss = 0.8233455419540405, train/raw-loss = 0.8111489415168762, train/logprobs = tensor([[-0.8158, -1.7425],
        [-0.8305, -1.1784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024393253028392792
Epoch 0, Step 275: train/loss = 0.6992860436439514, train/raw-loss = 0.6989011764526367, train/logprobs = tensor([[-0.7235, -0.8996],
        [-0.7233, -0.7150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007697106339037418
Epoch 0, Step 276: train/loss = 0.7150259017944336, train/raw-loss = 0.7131497859954834, train/logprobs = tensor([[-0.8207, -0.9889],
        [-0.8390, -0.7818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003752396907657385
Epoch 0, Step 277: train/loss = 0.6932591795921326, train/raw-loss = 0.6929812431335449, train/logprobs = tensor([[-1.0278, -1.1118],
        [-0.8341, -0.8418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005560346180573106
Epoch 0, Step 278: train/loss = 0.698565661907196, train/raw-loss = 0.6945937871932983, train/logprobs = tensor([[-0.8073, -1.1562],
        [-0.7714, -0.7668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007943653501570225
Epoch 0, Step 279: train/loss = 0.6938899755477905, train/raw-loss = 0.6935370564460754, train/logprobs = tensor([[-1.0711, -1.2461],
        [-1.1457, -1.1831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007058475166559219
Epoch 0, Step 280: train/loss = 0.7163600325584412, train/raw-loss = 0.7144972681999207, train/logprobs = tensor([[-0.7455, -0.9899],
        [-0.9049, -0.7406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003725566202774644
Epoch 0, Step 281: train/loss = 0.6954969167709351, train/raw-loss = 0.6939027905464172, train/logprobs = tensor([[-1.1557, -1.4087],
        [-1.0392, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031882254406809807
Epoch 0, Step 282: train/loss = 0.6997020840644836, train/raw-loss = 0.6996427774429321, train/logprobs = tensor([[-0.9147, -0.8318],
        [-0.8030, -0.7314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011853648175019771
Epoch 0, Step 283: train/loss = 0.6879674196243286, train/raw-loss = 0.6846487522125244, train/logprobs = tensor([[-1.0065, -1.1565],
        [-1.1590, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006637269631028175
Epoch 0, Step 284: train/loss = 0.7012400031089783, train/raw-loss = 0.7011390328407288, train/logprobs = tensor([[-0.7788, -0.6068],
        [-0.7462, -0.5267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020199180289637297
Epoch 0, Step 285: train/loss = 0.7088581919670105, train/raw-loss = 0.7077122926712036, train/logprobs = tensor([[-1.3867, -1.2713],
        [-1.2951, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002291700802743435
Epoch 0, Step 286: train/loss = 0.6944558620452881, train/raw-loss = 0.6944143772125244, train/logprobs = tensor([[-0.6360, -0.6208],
        [-0.5228, -0.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.291698759421706e-05
Epoch 0, Step 287: train/loss = 0.7327245473861694, train/raw-loss = 0.7227981090545654, train/logprobs = tensor([[-0.9258, -1.4491],
        [-0.8597, -0.8412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019852913916110992
Epoch 0, Step 288: train/loss = 0.6965571641921997, train/raw-loss = 0.6836584806442261, train/logprobs = tensor([[-0.9193, -1.4236],
        [-1.0580, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02579738199710846
Epoch 0, Step 289: train/loss = 0.6983730792999268, train/raw-loss = 0.696470320224762, train/logprobs = tensor([[-0.8748, -1.0702],
        [-0.9897, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038054538890719414
Epoch 0, Step 290: train/loss = 0.7208842039108276, train/raw-loss = 0.7199667096138, train/logprobs = tensor([[-1.1096, -0.8473],
        [-1.1188, -0.7600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018349759047850966
Epoch 0, Step 291: train/loss = 0.6954069137573242, train/raw-loss = 0.6935502290725708, train/logprobs = tensor([[-0.9090, -1.1555],
        [-0.9275, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003713364014402032
Epoch 0, Step 292: train/loss = 0.7015058994293213, train/raw-loss = 0.7001371383666992, train/logprobs = tensor([[-0.6029, -0.8448],
        [-0.6448, -0.6736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027374932542443275
Epoch 0, Step 293: train/loss = 0.6918681263923645, train/raw-loss = 0.6844498515129089, train/logprobs = tensor([[-0.8009, -0.9213],
        [-0.8845, -0.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01483657956123352
Epoch 0, Step 294: train/loss = 0.7020637392997742, train/raw-loss = 0.6971220970153809, train/logprobs = tensor([[-0.9403, -1.3522],
        [-0.9663, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009883306920528412
Epoch 0, Step 295: train/loss = 0.7055270671844482, train/raw-loss = 0.7051782608032227, train/logprobs = tensor([[-0.8024, -0.7084],
        [-0.8175, -0.6455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006974578136578202
Epoch 0, Step 296: train/loss = 0.6943689584732056, train/raw-loss = 0.6933887004852295, train/logprobs = tensor([[-0.9122, -0.9535],
        [-0.9844, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001960517605766654
Epoch 0, Step 297: train/loss = 0.7089884281158447, train/raw-loss = 0.7084286212921143, train/logprobs = tensor([[-1.0108, -1.1842],
        [-1.1811, -1.1803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001119609922170639
Epoch 0, Step 298: train/loss = 0.6918988227844238, train/raw-loss = 0.6829872131347656, train/logprobs = tensor([[-0.8566, -1.3301],
        [-0.9611, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017823174595832825
Epoch 0, Step 299: train/loss = 0.69572913646698, train/raw-loss = 0.6949416995048523, train/logprobs = tensor([[-0.6931, -0.7215],
        [-0.7380, -0.6549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015747922006994486
Epoch 0, Step 300: train/loss = 0.7375903129577637, train/raw-loss = 0.7112491130828857, train/logprobs = tensor([[-0.7942, -1.5987],
        [-0.9574, -0.6420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05268251895904541
Epoch 0, Step 301: train/loss = 0.6999049186706543, train/raw-loss = 0.69948410987854, train/logprobs = tensor([[-0.8309, -0.8760],
        [-0.7924, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008416174678131938
Epoch 0, Step 302: train/loss = 0.6993507146835327, train/raw-loss = 0.6979777216911316, train/logprobs = tensor([[-0.9272, -0.8573],
        [-1.0407, -0.7445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002746051410213113
Epoch 0, Step 303: train/loss = 0.6948664784431458, train/raw-loss = 0.693859338760376, train/logprobs = tensor([[-0.8898, -1.1002],
        [-0.9389, -0.9111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020143757574260235
Epoch 0, Step 304: train/loss = 0.708076536655426, train/raw-loss = 0.702781617641449, train/logprobs = tensor([[-0.8751, -1.1874],
        [-0.9838, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010589818470180035
Epoch 0, Step 305: train/loss = 0.7177957892417908, train/raw-loss = 0.7173599004745483, train/logprobs = tensor([[-1.0106, -1.1587],
        [-0.9888, -1.0217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000871668744366616
Epoch 0, Step 306: train/loss = 0.696943461894989, train/raw-loss = 0.6959166526794434, train/logprobs = tensor([[-0.8236, -0.8826],
        [-0.9439, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020536291413009167
Epoch 0, Step 307: train/loss = 0.7000841498374939, train/raw-loss = 0.6981551051139832, train/logprobs = tensor([[-0.8328, -0.9005],
        [-0.9514, -0.7510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038580456748604774
Epoch 0, Step 308: train/loss = 0.6928590536117554, train/raw-loss = 0.6907612085342407, train/logprobs = tensor([[-0.6642, -0.8116],
        [-0.7530, -0.6306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041957213543355465
Epoch 0, Step 309: train/loss = 0.7174274325370789, train/raw-loss = 0.6835302114486694, train/logprobs = tensor([[-0.9666, -1.8101],
        [-1.1047, -0.8313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06779444217681885
Epoch 0, Step 310: train/loss = 0.6983820796012878, train/raw-loss = 0.696506142616272, train/logprobs = tensor([[-0.7798, -0.9568],
        [-0.9051, -0.7033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037518481258302927
Epoch 0, Step 311: train/loss = 0.6997057199478149, train/raw-loss = 0.6986552476882935, train/logprobs = tensor([[-0.8041, -0.7391],
        [-0.7964, -0.5895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021008355543017387
Epoch 0, Step 312: train/loss = 0.7058619260787964, train/raw-loss = 0.6980741024017334, train/logprobs = tensor([[-0.8285, -1.2859],
        [-0.9021, -0.8155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015575632452964783
Epoch 0, Step 313: train/loss = 0.6974374651908875, train/raw-loss = 0.6973471641540527, train/logprobs = tensor([[-0.7452, -0.7048],
        [-0.9060, -0.7458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018075219122692943
Epoch 0, Step 314: train/loss = 0.7023401260375977, train/raw-loss = 0.7004321813583374, train/logprobs = tensor([[-1.1106, -1.2484],
        [-1.2301, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003815891221165657
Epoch 0, Step 315: train/loss = 0.7064002752304077, train/raw-loss = 0.7052035927772522, train/logprobs = tensor([[-0.7858, -1.0844],
        [-1.0138, -1.0446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002393200062215328
Epoch 0, Step 316: train/loss = 0.7243090271949768, train/raw-loss = 0.7226364016532898, train/logprobs = tensor([[-1.1144, -0.8625],
        [-1.3155, -0.7348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033452280331403017
Epoch 0, Step 317: train/loss = 0.6957046389579773, train/raw-loss = 0.6949416995048523, train/logprobs = tensor([[-0.8756, -0.9312],
        [-0.9809, -0.8310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001525886938907206
Epoch 0, Step 318: train/loss = 0.6888149976730347, train/raw-loss = 0.6834932565689087, train/logprobs = tensor([[-0.8830, -1.1024],
        [-1.0291, -0.9024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010643508285284042
Epoch 0, Step 319: train/loss = 0.7065876722335815, train/raw-loss = 0.7022801637649536, train/logprobs = tensor([[-1.2161, -1.5487],
        [-0.9990, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008614870719611645
Epoch 0, Step 320: train/loss = 0.7079645395278931, train/raw-loss = 0.7052432298660278, train/logprobs = tensor([[-0.9497, -1.2100],
        [-1.0071, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005442672409117222
Epoch 0, Step 321: train/loss = 0.6954935193061829, train/raw-loss = 0.6918709874153137, train/logprobs = tensor([[-0.7987, -0.8445],
        [-0.8454, -0.7107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007245031651109457
Epoch 0, Step 322: train/loss = 0.7022581696510315, train/raw-loss = 0.7011362314224243, train/logprobs = tensor([[-1.0183, -1.1740],
        [-1.0076, -0.9541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002243872731924057
Epoch 0, Step 323: train/loss = 0.6983439326286316, train/raw-loss = 0.6970245838165283, train/logprobs = tensor([[-0.8397, -0.8022],
        [-0.9522, -0.7430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026386703830212355
Epoch 0, Step 324: train/loss = 0.7470108270645142, train/raw-loss = 0.7451103925704956, train/logprobs = tensor([[-1.0179, -1.1050],
        [-1.2402, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038008540868759155
Epoch 0, Step 325: train/loss = 0.695982813835144, train/raw-loss = 0.695897102355957, train/logprobs = tensor([[-0.9239, -0.9123],
        [-1.0809, -0.9756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017141475109383464
Epoch 0, Step 326: train/loss = 0.6933494210243225, train/raw-loss = 0.6834040284156799, train/logprobs = tensor([[-1.2745, -1.6159],
        [-1.4953, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019890829920768738
Epoch 0, Step 327: train/loss = 0.7009552717208862, train/raw-loss = 0.7000046372413635, train/logprobs = tensor([[-0.9409, -0.9238],
        [-1.0061, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019012379925698042
Epoch 0, Step 328: train/loss = 0.7327514290809631, train/raw-loss = 0.7207247614860535, train/logprobs = tensor([[-1.0477, -1.2675],
        [-1.4310, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024053363129496574
Epoch 0, Step 329: train/loss = 0.6977312564849854, train/raw-loss = 0.6947522759437561, train/logprobs = tensor([[-0.7736, -0.7676],
        [-0.8069, -0.8430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005957857705652714
Epoch 0, Step 330: train/loss = 0.7209150195121765, train/raw-loss = 0.7182071208953857, train/logprobs = tensor([[-0.7927, -1.2334],
        [-0.9642, -1.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005415632389485836
Epoch 0, Step 331: train/loss = 0.7195219397544861, train/raw-loss = 0.7169012427330017, train/logprobs = tensor([[-0.9731, -0.7501],
        [-1.0480, -0.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005241323262453079
Epoch 0, Step 332: train/loss = 0.6909961700439453, train/raw-loss = 0.688804030418396, train/logprobs = tensor([[-1.0036, -1.0446],
        [-1.1383, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004384297411888838
Epoch 0, Step 333: train/loss = 0.6996356248855591, train/raw-loss = 0.6989655494689941, train/logprobs = tensor([[-0.8102, -0.9260],
        [-0.8346, -0.7865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013400757452473044
Epoch 0, Step 334: train/loss = 0.700566291809082, train/raw-loss = 0.6998435854911804, train/logprobs = tensor([[-0.9393, -1.2171],
        [-1.1568, -1.1558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001445377361960709
Epoch 0, Step 335: train/loss = 0.6928207278251648, train/raw-loss = 0.6874074935913086, train/logprobs = tensor([[-1.0660, -1.1627],
        [-1.3164, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0108266556635499
Epoch 0, Step 336: train/loss = 0.7113821506500244, train/raw-loss = 0.6979767084121704, train/logprobs = tensor([[-0.9052, -1.3103],
        [-1.0333, -0.8548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026810897514224052
Epoch 0, Step 337: train/loss = 0.700699508190155, train/raw-loss = 0.6999300718307495, train/logprobs = tensor([[-1.0124, -1.2889],
        [-1.1367, -1.2157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015388925094157457
Epoch 0, Step 338: train/loss = 0.6944143176078796, train/raw-loss = 0.6900752782821655, train/logprobs = tensor([[-1.0048, -1.0783],
        [-1.2819, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008677985519170761
Epoch 0, Step 339: train/loss = 0.7155146598815918, train/raw-loss = 0.7151162028312683, train/logprobs = tensor([[-0.9665, -0.8073],
        [-1.0605, -0.8013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007968991994857788
Epoch 0, Step 340: train/loss = 0.6944649815559387, train/raw-loss = 0.6942815780639648, train/logprobs = tensor([[-0.9440, -0.8706],
        [-0.9853, -0.8638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036663812352344394
Epoch 0, Step 341: train/loss = 0.6895332336425781, train/raw-loss = 0.6873342990875244, train/logprobs = tensor([[-0.8426, -0.9782],
        [-1.1663, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043979366309940815
Epoch 0, Step 342: train/loss = 0.7111427187919617, train/raw-loss = 0.7078028917312622, train/logprobs = tensor([[-1.1153, -1.0653],
        [-1.1937, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0066798292100429535
Epoch 0, Step 343: train/loss = 0.6998426914215088, train/raw-loss = 0.6995047330856323, train/logprobs = tensor([[-0.9518, -0.8797],
        [-1.0621, -0.8364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006760405376553535
Epoch 0, Step 344: train/loss = 0.7052515149116516, train/raw-loss = 0.7036309242248535, train/logprobs = tensor([[-1.1076, -1.0888],
        [-1.2659, -1.0140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003241105005145073
Epoch 0, Step 345: train/loss = 0.6979793310165405, train/raw-loss = 0.6968731880187988, train/logprobs = tensor([[-1.1609, -1.1242],
        [-1.3549, -1.0459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002212373772636056
Epoch 0, Step 346: train/loss = 0.7451505661010742, train/raw-loss = 0.7427403330802917, train/logprobs = tensor([[-0.9464, -1.0093],
        [-1.0799, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004820617381483316
Epoch 0, Step 347: train/loss = 0.7212733030319214, train/raw-loss = 0.716781735420227, train/logprobs = tensor([[-1.0393, -0.8870],
        [-1.3471, -0.6831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0089833103120327
Epoch 0, Step 348: train/loss = 0.694164514541626, train/raw-loss = 0.6939731240272522, train/logprobs = tensor([[-1.2035, -1.1691],
        [-1.2368, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003828364424407482
Epoch 0, Step 349: train/loss = 0.6983754634857178, train/raw-loss = 0.698043704032898, train/logprobs = tensor([[-0.8551, -0.7626],
        [-0.9040, -0.7192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000663550163153559
Epoch 0, Step 350: train/loss = 0.6983788013458252, train/raw-loss = 0.6983315944671631, train/logprobs = tensor([[-0.9694, -0.8855],
        [-1.0349, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.446367039345205e-05
Epoch 0, Step 351: train/loss = 0.7062250375747681, train/raw-loss = 0.7048683166503906, train/logprobs = tensor([[-1.0756, -0.9741],
        [-1.2925, -0.9128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027134655974805355
Epoch 0, Step 352: train/loss = 0.6983915567398071, train/raw-loss = 0.6921525001525879, train/logprobs = tensor([[-1.2159, -1.3747],
        [-1.2929, -1.0794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012478039599955082
Epoch 0, Step 353: train/loss = 0.6876804828643799, train/raw-loss = 0.6779322624206543, train/logprobs = tensor([[-0.8244, -1.1238],
        [-1.0517, -0.7626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0194964911788702
Epoch 0, Step 354: train/loss = 0.7185588479042053, train/raw-loss = 0.7173880338668823, train/logprobs = tensor([[-1.0532, -1.0800],
        [-1.2615, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002341623418033123
Epoch 0, Step 355: train/loss = 0.7154567241668701, train/raw-loss = 0.7107245922088623, train/logprobs = tensor([[-1.4168, -1.5023],
        [-1.2224, -0.9221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009464267641305923
Epoch 0, Step 356: train/loss = 0.7064207792282104, train/raw-loss = 0.704663097858429, train/logprobs = tensor([[-1.3610, -1.3866],
        [-1.4338, -1.2097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003515279619023204
Epoch 0, Step 357: train/loss = 0.702144980430603, train/raw-loss = 0.696107029914856, train/logprobs = tensor([[-0.9002, -1.3888],
        [-0.9385, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012075801379978657
Epoch 0, Step 358: train/loss = 0.7138925790786743, train/raw-loss = 0.7107035517692566, train/logprobs = tensor([[-0.7922, -1.1567],
        [-0.9960, -0.9628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006378079764544964
Epoch 0, Step 359: train/loss = 0.6996335983276367, train/raw-loss = 0.6924524307250977, train/logprobs = tensor([[-0.8514, -1.2726],
        [-1.1523, -1.2373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014362466521561146
Epoch 0, Step 360: train/loss = 0.7262085676193237, train/raw-loss = 0.7183591723442078, train/logprobs = tensor([[-1.1414, -1.8156],
        [-1.3882, -1.3887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01569872908294201
Epoch 0, Step 361: train/loss = 0.7159671783447266, train/raw-loss = 0.7137442827224731, train/logprobs = tensor([[-1.2148, -0.9340],
        [-1.0791, -0.8070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044457800686359406
Epoch 0, Step 362: train/loss = 0.696198582649231, train/raw-loss = 0.6959245800971985, train/logprobs = tensor([[-1.0103, -1.0287],
        [-1.0995, -0.9344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005478819366544485
Epoch 0, Step 363: train/loss = 0.7032632827758789, train/raw-loss = 0.7011033296585083, train/logprobs = tensor([[-0.8897, -1.2411],
        [-0.8927, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043199509382247925
Epoch 0, Step 364: train/loss = 0.7042778730392456, train/raw-loss = 0.7002371549606323, train/logprobs = tensor([[-1.0037, -0.8726],
        [-1.4499, -0.8124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008081544190645218
Epoch 0, Step 365: train/loss = 0.6939451098442078, train/raw-loss = 0.6920543313026428, train/logprobs = tensor([[-0.8518, -0.9547],
        [-0.8969, -0.7356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037815573159605265
Epoch 0, Step 366: train/loss = 0.7053577899932861, train/raw-loss = 0.7032022476196289, train/logprobs = tensor([[-1.1164, -1.0716],
        [-1.2345, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00431114761158824
Epoch 0, Step 367: train/loss = 0.6965980529785156, train/raw-loss = 0.6939545273780823, train/logprobs = tensor([[-0.8083, -1.1579],
        [-0.8402, -0.8826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005287061911076307
Epoch 0, Step 368: train/loss = 0.6932892203330994, train/raw-loss = 0.6904268860816956, train/logprobs = tensor([[-1.0978, -1.2921],
        [-1.0338, -0.9936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005724574439227581
Epoch 0, Step 369: train/loss = 0.6974287033081055, train/raw-loss = 0.696756899356842, train/logprobs = tensor([[-0.9287, -0.8964],
        [-1.0192, -0.8289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001343526761047542
Epoch 0, Step 370: train/loss = 0.6951155662536621, train/raw-loss = 0.6950132250785828, train/logprobs = tensor([[-0.9929, -0.9481],
        [-1.0810, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020468354341574013
Epoch 0, Step 371: train/loss = 0.7065469622612, train/raw-loss = 0.7038005590438843, train/logprobs = tensor([[-1.0955, -1.2439],
        [-1.1018, -1.0624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005492714233696461
Epoch 0, Step 372: train/loss = 0.6998924016952515, train/raw-loss = 0.6987300515174866, train/logprobs = tensor([[-1.1210, -1.1306],
        [-0.9294, -0.8014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023248144425451756
Epoch 0, Step 373: train/loss = 0.713352382183075, train/raw-loss = 0.7089663743972778, train/logprobs = tensor([[-1.0042, -1.1112],
        [-1.2165, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008771904744207859
Epoch 0, Step 374: train/loss = 0.7456547617912292, train/raw-loss = 0.7445878982543945, train/logprobs = tensor([[-1.1246, -0.8399],
        [-1.1445, -0.7002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002133806236088276
Epoch 0, Step 375: train/loss = 0.6984640955924988, train/raw-loss = 0.6976751089096069, train/logprobs = tensor([[-1.0642, -1.0414],
        [-1.0802, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001577913761138916
Epoch 0, Step 376: train/loss = 0.6949422359466553, train/raw-loss = 0.6929959058761597, train/logprobs = tensor([[-1.0396, -1.2542],
        [-1.0921, -0.9231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038926862180233
Epoch 0, Step 377: train/loss = 0.7032992243766785, train/raw-loss = 0.7016281485557556, train/logprobs = tensor([[-0.9842, -0.9220],
        [-1.0728, -0.6672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033421842381358147
Epoch 0, Step 378: train/loss = 0.7378826141357422, train/raw-loss = 0.7286369800567627, train/logprobs = tensor([[-0.8855, -1.3538],
        [-1.0151, -1.0221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018491216003894806
Epoch 0, Step 379: train/loss = 0.7027161121368408, train/raw-loss = 0.7023217678070068, train/logprobs = tensor([[-0.8629, -1.1543],
        [-0.8934, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007887213723734021
Epoch 0, Step 380: train/loss = 0.7097083330154419, train/raw-loss = 0.7094138860702515, train/logprobs = tensor([[-1.0496, -0.9157],
        [-1.0994, -0.9061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005888879531994462
Epoch 0, Step 381: train/loss = 0.7044333219528198, train/raw-loss = 0.7032731771469116, train/logprobs = tensor([[-1.1590, -1.0052],
        [-1.0376, -0.7872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023203918244689703
Epoch 0, Step 382: train/loss = 0.6919754147529602, train/raw-loss = 0.6828597784042358, train/logprobs = tensor([[-1.0202, -1.2991],
        [-1.2697, -0.7782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0182312224060297
Epoch 0, Step 383: train/loss = 0.7007532119750977, train/raw-loss = 0.6981456875801086, train/logprobs = tensor([[-1.0060, -0.9372],
        [-1.2284, -0.8395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005215013399720192
Epoch 0, Step 384: train/loss = 0.6941442489624023, train/raw-loss = 0.6938353776931763, train/logprobs = tensor([[-0.8514, -0.8770],
        [-0.8312, -0.7869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000617731362581253
Epoch 0, Step 385: train/loss = 0.6977112889289856, train/raw-loss = 0.6954486966133118, train/logprobs = tensor([[-1.0898, -1.2216],
        [-1.0561, -0.9743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004525084514170885
Epoch 0, Step 386: train/loss = 0.7094886898994446, train/raw-loss = 0.7093373537063599, train/logprobs = tensor([[-1.0363, -1.0053],
        [-1.0787, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003025749756488949
Epoch 0, Step 387: train/loss = 0.6986401677131653, train/raw-loss = 0.6974301338195801, train/logprobs = tensor([[-1.0678, -1.2559],
        [-1.1666, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024200964253395796
Epoch 0, Step 388: train/loss = 0.710627019405365, train/raw-loss = 0.7083632946014404, train/logprobs = tensor([[-1.3659, -1.4870],
        [-1.3929, -1.1038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004527448210865259
Epoch 0, Step 389: train/loss = 0.7134566307067871, train/raw-loss = 0.7125783562660217, train/logprobs = tensor([[-1.0875, -1.2456],
        [-1.1314, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017564855515956879
Epoch 0, Step 390: train/loss = 0.69303297996521, train/raw-loss = 0.6855429410934448, train/logprobs = tensor([[-1.0557, -1.3669],
        [-1.2901, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014980207197368145
Epoch 0, Step 391: train/loss = 0.7123409509658813, train/raw-loss = 0.7112063765525818, train/logprobs = tensor([[-0.9927, -0.9969],
        [-1.0648, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022691574413329363
Epoch 0, Step 392: train/loss = 0.7179604768753052, train/raw-loss = 0.7137563228607178, train/logprobs = tensor([[-1.0425, -1.4473],
        [-1.1931, -1.4714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008408338762819767
Epoch 0, Step 393: train/loss = 0.7032548785209656, train/raw-loss = 0.7031253576278687, train/logprobs = tensor([[-0.9220, -0.8826],
        [-0.9783, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025917566381394863
Epoch 0, Step 394: train/loss = 0.6965774297714233, train/raw-loss = 0.695504903793335, train/logprobs = tensor([[-0.8254, -0.8142],
        [-0.9896, -0.7981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021450575441122055
Epoch 0, Step 395: train/loss = 0.694065511226654, train/raw-loss = 0.692536473274231, train/logprobs = tensor([[-0.9820, -1.2754],
        [-1.1794, -1.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030580833554267883
Epoch 0, Step 396: train/loss = 0.7037014365196228, train/raw-loss = 0.6998943090438843, train/logprobs = tensor([[-1.0957, -1.5770],
        [-1.0139, -1.0346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007614247500896454
Epoch 0, Step 397: train/loss = 0.7177269458770752, train/raw-loss = 0.6979712247848511, train/logprobs = tensor([[-1.2231, -1.6368],
        [-1.2684, -0.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03951137140393257
Epoch 0, Step 398: train/loss = 0.709791898727417, train/raw-loss = 0.709699809551239, train/logprobs = tensor([[-0.9832, -0.7057],
        [-1.0413, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018418606487102807
Epoch 0, Step 399: train/loss = 0.6908031702041626, train/raw-loss = 0.6831052899360657, train/logprobs = tensor([[-1.1532, -1.3180],
        [-1.3034, -1.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01539578102529049
Epoch 0, Step 400: train/loss = 0.6958452463150024, train/raw-loss = 0.6956768035888672, train/logprobs = tensor([[-1.0432, -1.0565],
        [-0.8556, -0.8045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033692747820168734
Epoch 0, Step 401: train/loss = 0.7111126780509949, train/raw-loss = 0.707996129989624, train/logprobs = tensor([[-0.9444, -1.2549],
        [-0.9625, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062330299988389015
Epoch 0, Step 402: train/loss = 0.715694785118103, train/raw-loss = 0.7154883742332458, train/logprobs = tensor([[-1.2415, -0.9949],
        [-1.3216, -0.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004128642613068223
Epoch 0, Step 403: train/loss = 0.7380041480064392, train/raw-loss = 0.736221432685852, train/logprobs = tensor([[-0.8861, -1.2140],
        [-0.8994, -1.1173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035653726663440466
Epoch 0, Step 404: train/loss = 0.6927047967910767, train/raw-loss = 0.6784834861755371, train/logprobs = tensor([[-0.9741, -1.3363],
        [-1.1284, -0.8373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02844262681901455
Epoch 0, Step 405: train/loss = 0.6934694647789001, train/raw-loss = 0.6885101199150085, train/logprobs = tensor([[-1.0345, -1.2658],
        [-1.1759, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00991865899413824
Epoch 0, Step 406: train/loss = 0.7489076256752014, train/raw-loss = 0.7441924810409546, train/logprobs = tensor([[-1.1787, -1.4321],
        [-1.2813, -0.9895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009430166333913803
Epoch 0, Step 407: train/loss = 0.7093324661254883, train/raw-loss = 0.7065850496292114, train/logprobs = tensor([[-1.0168, -1.5258],
        [-1.0679, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005494875833392143
Epoch 0, Step 408: train/loss = 0.7122791409492493, train/raw-loss = 0.6977091431617737, train/logprobs = tensor([[-0.9185, -1.4200],
        [-1.0994, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029140017926692963
Epoch 0, Step 409: train/loss = 0.6966455578804016, train/raw-loss = 0.6955012083053589, train/logprobs = tensor([[-1.1337, -1.1095],
        [-1.2538, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002288646064698696
Epoch 0, Step 410: train/loss = 0.7089417576789856, train/raw-loss = 0.7000194191932678, train/logprobs = tensor([[-0.8254, -1.3930],
        [-0.9181, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017844658344984055
Epoch 0, Step 411: train/loss = 0.6940020322799683, train/raw-loss = 0.6927632093429565, train/logprobs = tensor([[-1.1551, -1.1852],
        [-1.1301, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002477718284353614
Epoch 0, Step 412: train/loss = 0.7022982835769653, train/raw-loss = 0.7007997035980225, train/logprobs = tensor([[-1.3428, -1.2204],
        [-1.3396, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029972039628773928
Epoch 0, Step 413: train/loss = 0.6959130167961121, train/raw-loss = 0.6940231323242188, train/logprobs = tensor([[-1.1391, -1.1257],
        [-1.0430, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037797505501657724
Epoch 0, Step 414: train/loss = 0.7134886384010315, train/raw-loss = 0.7107916474342346, train/logprobs = tensor([[-0.9120, -1.0166],
        [-1.0927, -0.8244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00539390230551362
Epoch 0, Step 415: train/loss = 0.6928145885467529, train/raw-loss = 0.6912477612495422, train/logprobs = tensor([[-0.8842, -1.0355],
        [-0.9239, -0.8293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00313377077691257
Epoch 0, Step 416: train/loss = 0.7500308156013489, train/raw-loss = 0.7335331439971924, train/logprobs = tensor([[-1.2713, -1.9432],
        [-1.3401, -1.2024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032995350658893585
Epoch 0, Step 417: train/loss = 0.7506139874458313, train/raw-loss = 0.7482599020004272, train/logprobs = tensor([[-0.9969, -0.8818],
        [-1.1336, -0.6542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047082253731787205
Epoch 0, Step 418: train/loss = 0.7028840184211731, train/raw-loss = 0.7021733522415161, train/logprobs = tensor([[-1.5741, -1.5500],
        [-1.3145, -1.0945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014212166424840689
Epoch 0, Step 419: train/loss = 0.6961032152175903, train/raw-loss = 0.6946678757667542, train/logprobs = tensor([[-1.2596, -1.4091],
        [-1.0992, -1.0771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00287065701559186
Epoch 0, Step 420: train/loss = 0.6979050636291504, train/raw-loss = 0.6893206834793091, train/logprobs = tensor([[-1.0020, -1.2682],
        [-1.0094, -1.0551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0171688012778759
Epoch 0, Step 421: train/loss = 0.7049027681350708, train/raw-loss = 0.6991044282913208, train/logprobs = tensor([[-1.2314, -1.6568],
        [-1.2249, -1.2281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011596757918596268
Epoch 0, Step 422: train/loss = 0.6954650282859802, train/raw-loss = 0.6932455897331238, train/logprobs = tensor([[-1.0811, -1.2687],
        [-1.1869, -1.2086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044389208778738976
Epoch 0, Step 423: train/loss = 0.7110846638679504, train/raw-loss = 0.7094172239303589, train/logprobs = tensor([[-1.3601, -1.2578],
        [-1.4869, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003334908979013562
Epoch 0, Step 424: train/loss = 0.7062270045280457, train/raw-loss = 0.7052393555641174, train/logprobs = tensor([[-1.1152, -1.0314],
        [-1.1254, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019753472879529
Epoch 0, Step 425: train/loss = 0.6902996301651001, train/raw-loss = 0.6875671744346619, train/logprobs = tensor([[-0.9722, -1.2899],
        [-1.0381, -0.8674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005464920774102211
Epoch 0, Step 426: train/loss = 0.7132982015609741, train/raw-loss = 0.7103093266487122, train/logprobs = tensor([[-1.3602, -1.1131],
        [-1.3816, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005977787543088198
Epoch 0, Step 427: train/loss = 0.7069083452224731, train/raw-loss = 0.7044023275375366, train/logprobs = tensor([[-1.0114, -1.0910],
        [-1.0743, -0.9629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005012098699808121
Epoch 0, Step 428: train/loss = 0.7131301164627075, train/raw-loss = 0.7117677330970764, train/logprobs = tensor([[-1.0879, -0.9202],
        [-1.1583, -0.7685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027249199338257313
Epoch 0, Step 429: train/loss = 0.7035149931907654, train/raw-loss = 0.7021732330322266, train/logprobs = tensor([[-0.9407, -0.9472],
        [-1.0877, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002683564554899931
Epoch 0, Step 430: train/loss = 0.7110052108764648, train/raw-loss = 0.7086273431777954, train/logprobs = tensor([[-0.8644, -1.1228],
        [-0.9397, -0.9709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047557600773870945
Epoch 0, Step 431: train/loss = 0.708329439163208, train/raw-loss = 0.7079218029975891, train/logprobs = tensor([[-1.1913, -1.5116],
        [-1.3197, -1.5704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000815289793536067
Epoch 0, Step 432: train/loss = 0.7067877054214478, train/raw-loss = 0.7058095932006836, train/logprobs = tensor([[-1.2515, -1.1426],
        [-1.2381, -0.9506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019563990645110607
Epoch 0, Step 433: train/loss = 0.7166974544525146, train/raw-loss = 0.7117776870727539, train/logprobs = tensor([[-0.9374, -0.9882],
        [-1.0070, -0.6538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00983937457203865
Epoch 0, Step 434: train/loss = 0.6970648765563965, train/raw-loss = 0.6959537267684937, train/logprobs = tensor([[-1.4225, -1.4068],
        [-1.2838, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022222562693059444
Epoch 0, Step 435: train/loss = 0.7439054846763611, train/raw-loss = 0.7393776178359985, train/logprobs = tensor([[-1.3300, -1.6228],
        [-1.3071, -1.3015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009055715054273605
Epoch 0, Step 436: train/loss = 0.7029378414154053, train/raw-loss = 0.6996920704841614, train/logprobs = tensor([[-0.9279, -1.3127],
        [-0.8728, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006491576321423054
Epoch 0, Step 437: train/loss = 0.7181074619293213, train/raw-loss = 0.7162805795669556, train/logprobs = tensor([[-1.3487, -1.0716],
        [-1.2280, -0.7846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036536867264658213
Epoch 0, Step 438: train/loss = 0.7000899910926819, train/raw-loss = 0.6956438422203064, train/logprobs = tensor([[-0.9797, -1.0727],
        [-1.1814, -0.6928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008892307057976723
Epoch 0, Step 439: train/loss = 0.7180160880088806, train/raw-loss = 0.7150896787643433, train/logprobs = tensor([[-1.3679, -1.4986],
        [-1.3915, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005852865986526012
Epoch 0, Step 440: train/loss = 0.6996861696243286, train/raw-loss = 0.6987476944923401, train/logprobs = tensor([[-1.2385, -1.3697],
        [-1.2926, -1.2334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001876990543678403
Epoch 0, Step 441: train/loss = 0.7042387127876282, train/raw-loss = 0.7006300687789917, train/logprobs = tensor([[-1.2446, -1.2547],
        [-1.3725, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007217394188046455
Epoch 0, Step 442: train/loss = 0.7008414268493652, train/raw-loss = 0.6996937990188599, train/logprobs = tensor([[-0.9133, -0.7712],
        [-0.9799, -0.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022951574064791203
Epoch 0, Step 443: train/loss = 0.7149637937545776, train/raw-loss = 0.7148829698562622, train/logprobs = tensor([[-1.0094, -0.7300],
        [-0.9259, -0.5592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016173790208995342
Epoch 0, Step 444: train/loss = 0.7151480317115784, train/raw-loss = 0.7005267143249512, train/logprobs = tensor([[-0.9246, -1.6870],
        [-1.0656, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029242603108286858
Epoch 0, Step 445: train/loss = 0.7065017223358154, train/raw-loss = 0.70213782787323, train/logprobs = tensor([[-1.0221, -1.2516],
        [-1.0421, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00872776098549366
Epoch 0, Step 446: train/loss = 0.6963680982589722, train/raw-loss = 0.6910388469696045, train/logprobs = tensor([[-0.9049, -1.2001],
        [-0.9088, -0.6699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010658561252057552
Epoch 0, Step 447: train/loss = 0.693790853023529, train/raw-loss = 0.6904430389404297, train/logprobs = tensor([[-1.0433, -1.2267],
        [-0.9461, -0.8953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006695604883134365
Epoch 0, Step 448: train/loss = 0.7343809604644775, train/raw-loss = 0.7299731969833374, train/logprobs = tensor([[-1.1456, -1.5103],
        [-1.1028, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008815492503345013
Epoch 0, Step 449: train/loss = 0.696649968624115, train/raw-loss = 0.6959752440452576, train/logprobs = tensor([[-1.3006, -1.2992],
        [-1.4910, -1.0505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013494911836460233
Epoch 0, Step 450: train/loss = 0.7306202054023743, train/raw-loss = 0.7304134368896484, train/logprobs = tensor([[-1.3262, -1.0233],
        [-1.2609, -0.9277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004134801565669477
Epoch 0, Step 451: train/loss = 0.7174820899963379, train/raw-loss = 0.70981764793396, train/logprobs = tensor([[-0.9605, -1.5718],
        [-1.0191, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015328910201787949
Epoch 0, Step 452: train/loss = 0.7005542516708374, train/raw-loss = 0.698255181312561, train/logprobs = tensor([[-1.1437, -1.5588],
        [-0.8384, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004598098341375589
Epoch 0, Step 453: train/loss = 0.7047344446182251, train/raw-loss = 0.7001155614852905, train/logprobs = tensor([[-1.0857, -1.3423],
        [-1.0420, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00923776626586914
Epoch 0, Step 454: train/loss = 0.6917732954025269, train/raw-loss = 0.6881236433982849, train/logprobs = tensor([[-1.1146, -1.2187],
        [-1.1695, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0072992476634681225
Epoch 0, Step 455: train/loss = 0.7132133841514587, train/raw-loss = 0.7097706198692322, train/logprobs = tensor([[-1.1487, -1.2837],
        [-1.1160, -0.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006885651033371687
Epoch 0, Step 456: train/loss = 0.6946025490760803, train/raw-loss = 0.6941654086112976, train/logprobs = tensor([[-0.8547, -0.9115],
        [-0.8713, -0.7962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000874280754942447
Epoch 0, Step 457: train/loss = 0.715430736541748, train/raw-loss = 0.7115291953086853, train/logprobs = tensor([[-0.9587, -1.2339],
        [-1.0569, -0.8858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007803109474480152
Epoch 0, Step 458: train/loss = 0.7554699778556824, train/raw-loss = 0.751891553401947, train/logprobs = tensor([[-0.9881, -1.6104],
        [-0.9889, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007156892213970423
Epoch 0, Step 459: train/loss = 0.7184566855430603, train/raw-loss = 0.7144410610198975, train/logprobs = tensor([[-1.5380, -1.5712],
        [-1.3830, -1.1059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008031245321035385
Epoch 0, Step 460: train/loss = 0.7093437910079956, train/raw-loss = 0.7077070474624634, train/logprobs = tensor([[-1.2389, -1.2178],
        [-1.3481, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032733334228396416
Epoch 0, Step 461: train/loss = 0.6909517049789429, train/raw-loss = 0.6909167170524597, train/logprobs = tensor([[-1.1878, -1.2451],
        [-1.0640, -0.9068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.996036972850561e-05
Epoch 0, Step 462: train/loss = 0.673046886920929, train/raw-loss = 0.6711793541908264, train/logprobs = tensor([[-1.2740, -1.6974],
        [-1.2614, -1.0639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003735144156962633
Epoch 0, Step 463: train/loss = 0.7431741952896118, train/raw-loss = 0.7102106809616089, train/logprobs = tensor([[-1.1706, -1.9021],
        [-1.1743, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06592709571123123
Epoch 0, Step 464: train/loss = 0.6932019591331482, train/raw-loss = 0.6899824142456055, train/logprobs = tensor([[-1.2612, -1.4064],
        [-1.2226, -1.2068]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006439081393182278
Epoch 0, Step 465: train/loss = 0.71101313829422, train/raw-loss = 0.7101572751998901, train/logprobs = tensor([[-1.0388, -1.1367],
        [-1.0489, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017118373652920127
Epoch 0, Step 466: train/loss = 0.7027813196182251, train/raw-loss = 0.7013711333274841, train/logprobs = tensor([[-1.0116, -1.0351],
        [-0.9947, -1.0106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002820343943312764
Epoch 0, Step 467: train/loss = 0.6978711485862732, train/raw-loss = 0.6966859102249146, train/logprobs = tensor([[-1.3071, -1.5812],
        [-1.4760, -1.4215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023704832419753075
Epoch 0, Step 468: train/loss = 0.706576943397522, train/raw-loss = 0.7032793760299683, train/logprobs = tensor([[-0.9038, -1.3266],
        [-0.8581, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006595206446945667
Epoch 0, Step 469: train/loss = 0.697685718536377, train/raw-loss = 0.6965007781982422, train/logprobs = tensor([[-1.0673, -0.9864],
        [-1.1140, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002369736786931753
Epoch 0, Step 470: train/loss = 0.6968544721603394, train/raw-loss = 0.6957289576530457, train/logprobs = tensor([[-1.0361, -1.2021],
        [-1.0766, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022510273847728968
Epoch 0, Step 471: train/loss = 0.7003888487815857, train/raw-loss = 0.6994412541389465, train/logprobs = tensor([[-1.0345, -1.2335],
        [-1.2910, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018951829988509417
Epoch 0, Step 472: train/loss = 0.6963063478469849, train/raw-loss = 0.685707688331604, train/logprobs = tensor([[-1.2165, -1.4642],
        [-1.3065, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021197333931922913
Epoch 0, Step 473: train/loss = 0.6936922669410706, train/raw-loss = 0.6932743787765503, train/logprobs = tensor([[-1.4310, -1.5204],
        [-1.5839, -1.5576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008356529287993908
Epoch 0, Step 474: train/loss = 0.7042779326438904, train/raw-loss = 0.7027794122695923, train/logprobs = tensor([[-0.9950, -1.2889],
        [-1.1218, -1.1163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029969580937176943
Epoch 0, Step 475: train/loss = 0.7074638605117798, train/raw-loss = 0.7042794823646545, train/logprobs = tensor([[-0.9507, -1.2304],
        [-0.9708, -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006368735339492559
Epoch 0, Step 476: train/loss = 0.739206075668335, train/raw-loss = 0.736971914768219, train/logprobs = tensor([[-1.5066, -1.3266],
        [-1.7691, -1.1873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004468328785151243
Epoch 0, Step 477: train/loss = 0.6939051151275635, train/raw-loss = 0.6846615076065063, train/logprobs = tensor([[-1.3528, -1.3441],
        [-1.3903, -1.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018487097695469856
Epoch 0, Step 478: train/loss = 0.7068244218826294, train/raw-loss = 0.7063238620758057, train/logprobs = tensor([[-0.9431, -1.1140],
        [-1.0246, -1.0291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010010352125391364
Epoch 0, Step 479: train/loss = 0.7042467594146729, train/raw-loss = 0.7033746242523193, train/logprobs = tensor([[-1.1649, -1.0523],
        [-1.3563, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001744261011481285
Epoch 0, Step 480: train/loss = 0.6995641589164734, train/raw-loss = 0.6993198990821838, train/logprobs = tensor([[-1.0501, -0.9460],
        [-0.9909, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004884261288680136
Epoch 0, Step 481: train/loss = 0.7000221610069275, train/raw-loss = 0.6967818737030029, train/logprobs = tensor([[-1.1261, -1.1701],
        [-1.2224, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006480508018285036
Epoch 0, Step 482: train/loss = 0.7231295704841614, train/raw-loss = 0.7185596823692322, train/logprobs = tensor([[-1.3866, -1.2030],
        [-1.3949, -0.7644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00913987122476101
Epoch 0, Step 483: train/loss = 0.6945211887359619, train/raw-loss = 0.6911077499389648, train/logprobs = tensor([[-1.1088, -1.1545],
        [-1.0523, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006826869677752256
Epoch 0, Step 484: train/loss = 0.7199754118919373, train/raw-loss = 0.7185709476470947, train/logprobs = tensor([[-1.1060, -1.6147],
        [-1.2652, -1.3485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002808952471241355
Epoch 0, Step 485: train/loss = 0.6908825635910034, train/raw-loss = 0.686662495136261, train/logprobs = tensor([[-0.9730, -1.2625],
        [-0.9829, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008440205827355385
Epoch 0, Step 486: train/loss = 0.7218032479286194, train/raw-loss = 0.7215569615364075, train/logprobs = tensor([[-1.0225, -1.2066],
        [-1.0944, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004924843669869006
Epoch 0, Step 487: train/loss = 0.6945014595985413, train/raw-loss = 0.6942392587661743, train/logprobs = tensor([[-1.0519, -1.0647],
        [-0.9748, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005243215709924698
Epoch 0, Step 488: train/loss = 0.7040804028511047, train/raw-loss = 0.7000148296356201, train/logprobs = tensor([[-1.2917, -1.4335],
        [-1.2284, -1.0326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0081310560926795
Epoch 0, Step 489: train/loss = 0.72389155626297, train/raw-loss = 0.7200431823730469, train/logprobs = tensor([[-0.9431, -1.4565],
        [-1.0159, -1.1469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007696806453168392
Epoch 0, Step 490: train/loss = 0.6946358680725098, train/raw-loss = 0.6920691132545471, train/logprobs = tensor([[-1.0173, -1.2035],
        [-1.0645, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005133609287440777
Epoch 0, Step 491: train/loss = 0.6959395408630371, train/raw-loss = 0.6910174489021301, train/logprobs = tensor([[-1.0830, -1.1331],
        [-1.1388, -0.9737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009844282642006874
Epoch 0, Step 492: train/loss = 0.7043598890304565, train/raw-loss = 0.7020629048347473, train/logprobs = tensor([[-0.9699, -0.9923],
        [-0.9735, -0.8358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004593966528773308
Epoch 0, Step 493: train/loss = 0.7972483038902283, train/raw-loss = 0.7950643301010132, train/logprobs = tensor([[-1.0226, -1.4952],
        [-1.0742, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004367855843156576
Epoch 0, Step 494: train/loss = 0.6942152976989746, train/raw-loss = 0.6930494904518127, train/logprobs = tensor([[-1.2447, -1.1878],
        [-1.1236, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023315350990742445
Epoch 0, Step 495: train/loss = 0.6991292238235474, train/raw-loss = 0.6975877285003662, train/logprobs = tensor([[-0.9485, -1.0553],
        [-1.0195, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030829301103949547
Epoch 0, Step 496: train/loss = 0.6931309700012207, train/raw-loss = 0.6926670670509338, train/logprobs = tensor([[-1.0259, -1.0650],
        [-1.0976, -1.0466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009278197539970279
Epoch 0, Step 497: train/loss = 0.722515344619751, train/raw-loss = 0.7218078970909119, train/logprobs = tensor([[-1.1644, -0.9629],
        [-1.0772, -0.7904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014149160124361515
Epoch 0, Step 498: train/loss = 0.706947386264801, train/raw-loss = 0.7028518915176392, train/logprobs = tensor([[-0.9744, -1.4986],
        [-1.0370, -1.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00819107424467802
Epoch 0, Step 499: train/loss = 0.6992070078849792, train/raw-loss = 0.6958062052726746, train/logprobs = tensor([[-0.8890, -0.9866],
        [-0.9388, -0.7592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006801597308367491
eval/loss: 0.7093073725700378
Epoch 0, Step 500: train/loss = 0.7234285473823547, train/raw-loss = 0.7204824686050415, train/logprobs = tensor([[-1.1758, -1.1674],
        [-1.1664, -0.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005892029497772455
Epoch 0, Step 501: train/loss = 0.7088252305984497, train/raw-loss = 0.7070307731628418, train/logprobs = tensor([[-1.2875, -1.4771],
        [-1.3480, -1.2761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035889691207557917
Epoch 0, Step 502: train/loss = 0.7121151685714722, train/raw-loss = 0.7104803919792175, train/logprobs = tensor([[-1.3353, -1.5818],
        [-1.3191, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032695564441382885
Epoch 0, Step 503: train/loss = 0.7373878955841064, train/raw-loss = 0.7290031909942627, train/logprobs = tensor([[-1.2796, -1.2974],
        [-1.2883, -1.3166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016769250854849815
Epoch 0, Step 504: train/loss = 0.7211518287658691, train/raw-loss = 0.7208738327026367, train/logprobs = tensor([[-1.2653, -1.0452],
        [-1.3539, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005559371784329414
Epoch 0, Step 505: train/loss = 0.7146174907684326, train/raw-loss = 0.7141265869140625, train/logprobs = tensor([[-0.9780, -0.9018],
        [-0.9755, -0.7566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000981612247414887
Epoch 0, Step 506: train/loss = 0.7105393409729004, train/raw-loss = 0.709498405456543, train/logprobs = tensor([[-0.8251, -1.0599],
        [-0.8877, -0.9735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020819054916501045
Epoch 0, Step 507: train/loss = 0.6914004683494568, train/raw-loss = 0.6905284523963928, train/logprobs = tensor([[-1.2001, -1.2782],
        [-1.2923, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001744092907756567
Epoch 0, Step 508: train/loss = 0.702640175819397, train/raw-loss = 0.7025225758552551, train/logprobs = tensor([[-0.9904, -0.9406],
        [-0.9949, -0.9515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023519346723333
Epoch 0, Step 509: train/loss = 0.6996979713439941, train/raw-loss = 0.6981897354125977, train/logprobs = tensor([[-0.8813, -1.1207],
        [-0.8952, -0.8523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030165081843733788
Epoch 0, Step 510: train/loss = 0.6925209760665894, train/raw-loss = 0.6880394816398621, train/logprobs = tensor([[-1.0428, -1.1476],
        [-1.1485, -1.0081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008962986059486866
Epoch 0, Step 511: train/loss = 0.6857249736785889, train/raw-loss = 0.6811322569847107, train/logprobs = tensor([[-1.2846, -1.5066],
        [-1.1466, -0.9088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0091855488717556
Epoch 0, Step 512: train/loss = 0.6961060762405396, train/raw-loss = 0.6940287351608276, train/logprobs = tensor([[-1.0441, -1.2098],
        [-1.0666, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004154662601649761
Epoch 0, Step 513: train/loss = 0.7196900248527527, train/raw-loss = 0.7195117473602295, train/logprobs = tensor([[-0.8907, -0.6580],
        [-0.9345, -0.5928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035654683597385883
Epoch 0, Step 514: train/loss = 0.7102864384651184, train/raw-loss = 0.7078278064727783, train/logprobs = tensor([[-1.1857, -1.1326],
        [-1.2701, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049172756262123585
Epoch 0, Step 515: train/loss = 0.7232404351234436, train/raw-loss = 0.7177619934082031, train/logprobs = tensor([[-1.0127, -1.6007],
        [-0.9067, -1.0916]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010956931859254837
Epoch 0, Step 516: train/loss = 0.7368520498275757, train/raw-loss = 0.7324431538581848, train/logprobs = tensor([[-0.9215, -1.1858],
        [-0.9808, -0.9567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00881768949329853
Epoch 0, Step 517: train/loss = 0.6952083110809326, train/raw-loss = 0.6927919387817383, train/logprobs = tensor([[-1.0891, -1.2008],
        [-1.1839, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004832627717405558
Epoch 0, Step 518: train/loss = 0.7183049917221069, train/raw-loss = 0.7073144912719727, train/logprobs = tensor([[-0.9822, -1.5712],
        [-1.0763, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021981094032526016
Epoch 0, Step 519: train/loss = 0.6959304213523865, train/raw-loss = 0.693872332572937, train/logprobs = tensor([[-1.0747, -1.1780],
        [-1.0868, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041161393746733665
Epoch 0, Step 520: train/loss = 0.7455952167510986, train/raw-loss = 0.7441351413726807, train/logprobs = tensor([[-1.2819, -0.9270],
        [-1.3749, -0.6182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002920186147093773
Epoch 0, Step 521: train/loss = 0.7263596653938293, train/raw-loss = 0.7236605882644653, train/logprobs = tensor([[-0.9903, -1.4837],
        [-1.0667, -1.2220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0053980667144060135
Epoch 0, Step 522: train/loss = 0.705498456954956, train/raw-loss = 0.6952773928642273, train/logprobs = tensor([[-0.9047, -1.5539],
        [-1.0124, -1.0143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0204421728849411
Epoch 0, Step 523: train/loss = 0.7096511125564575, train/raw-loss = 0.7091481685638428, train/logprobs = tensor([[-1.0453, -1.3666],
        [-1.0545, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010059393243864179
Epoch 0, Step 524: train/loss = 0.6943817138671875, train/raw-loss = 0.6934029459953308, train/logprobs = tensor([[-1.1129, -1.1564],
        [-1.1421, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001957526197656989
Epoch 0, Step 525: train/loss = 0.7198178172111511, train/raw-loss = 0.7176995277404785, train/logprobs = tensor([[-0.8069, -1.1247],
        [-0.8967, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004236559849232435
Epoch 0, Step 526: train/loss = 0.7023628950119019, train/raw-loss = 0.7001188397407532, train/logprobs = tensor([[-1.0660, -1.2379],
        [-1.1015, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004488159902393818
Epoch 0, Step 527: train/loss = 0.7332572340965271, train/raw-loss = 0.7326815724372864, train/logprobs = tensor([[-1.2700, -1.0047],
        [-1.5072, -0.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001151297939941287
Epoch 0, Step 528: train/loss = 0.6915677785873413, train/raw-loss = 0.6879980564117432, train/logprobs = tensor([[-1.2870, -1.4053],
        [-1.3071, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007139459252357483
Epoch 0, Step 529: train/loss = 0.7100218534469604, train/raw-loss = 0.7068476676940918, train/logprobs = tensor([[-0.9901, -0.8757],
        [-1.1415, -0.7196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006348406430333853
Epoch 0, Step 530: train/loss = 0.7153455018997192, train/raw-loss = 0.7150943279266357, train/logprobs = tensor([[-1.0565, -0.9776],
        [-1.0209, -0.8492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000502299633808434
Epoch 0, Step 531: train/loss = 0.6975894570350647, train/raw-loss = 0.697307825088501, train/logprobs = tensor([[-1.1811, -1.0921],
        [-1.1957, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005631134263239801
Epoch 0, Step 532: train/loss = 0.7086196541786194, train/raw-loss = 0.7079107165336609, train/logprobs = tensor([[-1.3245, -1.6076],
        [-1.3161, -1.5926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014177837874740362
Epoch 0, Step 533: train/loss = 0.7266770005226135, train/raw-loss = 0.7262943387031555, train/logprobs = tensor([[-1.0510, -1.2979],
        [-1.0921, -1.1654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007652810891158879
Epoch 0, Step 534: train/loss = 0.6970475912094116, train/raw-loss = 0.6948089599609375, train/logprobs = tensor([[-0.8840, -0.8781],
        [-0.9093, -0.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0044773900881409645
Epoch 0, Step 535: train/loss = 0.7192641496658325, train/raw-loss = 0.7181190252304077, train/logprobs = tensor([[-1.2658, -1.2215],
        [-1.3846, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002290316391736269
Epoch 0, Step 536: train/loss = 0.7048717737197876, train/raw-loss = 0.6984884142875671, train/logprobs = tensor([[-1.1509, -1.4691],
        [-1.1707, -1.0629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012766898609697819
Epoch 0, Step 537: train/loss = 0.6916866898536682, train/raw-loss = 0.685753583908081, train/logprobs = tensor([[-0.9957, -1.1853],
        [-1.0662, -0.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011866219341754913
Epoch 0, Step 538: train/loss = 0.6982893943786621, train/raw-loss = 0.6979085206985474, train/logprobs = tensor([[-0.8447, -0.8501],
        [-0.8677, -0.8285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007616314105689526
Epoch 0, Step 539: train/loss = 0.7324379682540894, train/raw-loss = 0.7267425060272217, train/logprobs = tensor([[-1.4108, -1.8065],
        [-1.5543, -1.3108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011390903033316135
Epoch 0, Step 540: train/loss = 0.6979991793632507, train/raw-loss = 0.6977092027664185, train/logprobs = tensor([[-0.9104, -0.8513],
        [-0.9922, -0.7965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005799406208097935
Epoch 0, Step 541: train/loss = 0.70087730884552, train/raw-loss = 0.698517918586731, train/logprobs = tensor([[-1.0922, -1.1080],
        [-1.1988, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0047188373282551765
Epoch 0, Step 542: train/loss = 0.6993052363395691, train/raw-loss = 0.6959706544876099, train/logprobs = tensor([[-1.2042, -1.1441],
        [-1.1091, -0.8609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006669226102530956
Epoch 0, Step 543: train/loss = 0.7172178030014038, train/raw-loss = 0.7157655954360962, train/logprobs = tensor([[-1.0701, -0.8281],
        [-1.2775, -0.7298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029045070987194777
Epoch 0, Step 544: train/loss = 0.696200430393219, train/raw-loss = 0.6953730583190918, train/logprobs = tensor([[-1.5463, -1.4867],
        [-1.6069, -1.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001654712832532823
Epoch 0, Step 545: train/loss = 0.7005460858345032, train/raw-loss = 0.700281023979187, train/logprobs = tensor([[-1.6532, -1.5065],
        [-1.4123, -1.2999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005300841294229031
Epoch 0, Step 546: train/loss = 0.707645058631897, train/raw-loss = 0.7040221095085144, train/logprobs = tensor([[-1.5262, -1.9107],
        [-1.4418, -1.5164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007245820946991444
Epoch 0, Step 547: train/loss = 0.7144017815589905, train/raw-loss = 0.7137547135353088, train/logprobs = tensor([[-1.0906, -1.2312],
        [-0.9554, -1.0449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012940901797264814
Epoch 0, Step 548: train/loss = 0.6980052590370178, train/raw-loss = 0.6929421424865723, train/logprobs = tensor([[-1.0563, -1.4082],
        [-1.2716, -1.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010126280598342419
Epoch 0, Step 549: train/loss = 0.6989584565162659, train/raw-loss = 0.697540283203125, train/logprobs = tensor([[-1.1149, -1.2315],
        [-1.2198, -1.0006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028362798038870096
Epoch 0, Step 550: train/loss = 0.688663125038147, train/raw-loss = 0.686576247215271, train/logprobs = tensor([[-1.2011, -1.3262],
        [-1.2743, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00417372677475214
Epoch 0, Step 551: train/loss = 0.712364673614502, train/raw-loss = 0.7060027718544006, train/logprobs = tensor([[-0.9439, -1.4364],
        [-0.9198, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012723799794912338
Epoch 0, Step 552: train/loss = 0.8020198941230774, train/raw-loss = 0.795861005783081, train/logprobs = tensor([[-1.0117, -1.7266],
        [-1.2531, -1.5451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012317829765379429
Epoch 0, Step 553: train/loss = 0.7053090929985046, train/raw-loss = 0.7029280662536621, train/logprobs = tensor([[-1.2825, -1.6457],
        [-1.2115, -1.3295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004762055817991495
Epoch 0, Step 554: train/loss = 0.7234451770782471, train/raw-loss = 0.7214332222938538, train/logprobs = tensor([[-1.0480, -1.3735],
        [-1.0743, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004023894667625427
Epoch 0, Step 555: train/loss = 0.6969578266143799, train/raw-loss = 0.696707010269165, train/logprobs = tensor([[-1.3553, -1.4342],
        [-1.4134, -1.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005016624927520752
Epoch 0, Step 556: train/loss = 0.7000582814216614, train/raw-loss = 0.6959425210952759, train/logprobs = tensor([[-1.1653, -1.3847],
        [-1.0783, -1.2300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008231468498706818
Epoch 0, Step 557: train/loss = 0.6952721476554871, train/raw-loss = 0.6951636075973511, train/logprobs = tensor([[-0.9685, -1.0088],
        [-0.9945, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021706509869545698
Epoch 0, Step 558: train/loss = 0.6964264512062073, train/raw-loss = 0.6927486658096313, train/logprobs = tensor([[-0.9780, -1.1817],
        [-1.0012, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007355704437941313
Epoch 0, Step 559: train/loss = 0.7036510705947876, train/raw-loss = 0.7034262418746948, train/logprobs = tensor([[-1.1605, -1.2877],
        [-1.2306, -1.2705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004497212066780776
Epoch 0, Step 560: train/loss = 0.6990183591842651, train/raw-loss = 0.6989567279815674, train/logprobs = tensor([[-0.8685, -0.7511],
        [-0.9231, -0.7127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012313733168412
Epoch 0, Step 561: train/loss = 0.7466662526130676, train/raw-loss = 0.7453868389129639, train/logprobs = tensor([[-1.1049, -1.3119],
        [-1.1260, -1.1616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025589019060134888
Epoch 0, Step 562: train/loss = 0.7182198762893677, train/raw-loss = 0.7140569686889648, train/logprobs = tensor([[-0.9216, -1.2504],
        [-0.9394, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008325818926095963
Epoch 0, Step 563: train/loss = 0.708643913269043, train/raw-loss = 0.7081580758094788, train/logprobs = tensor([[-1.1630, -1.3567],
        [-1.1935, -1.3124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009715884225443006
Epoch 0, Step 564: train/loss = 0.721513032913208, train/raw-loss = 0.7150211930274963, train/logprobs = tensor([[-0.8989, -1.4797],
        [-1.0579, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01298370398581028
Epoch 0, Step 565: train/loss = 0.730099081993103, train/raw-loss = 0.7258226275444031, train/logprobs = tensor([[-1.0520, -1.6060],
        [-1.1926, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008552948012948036
Epoch 0, Step 566: train/loss = 0.6940608024597168, train/raw-loss = 0.6940555572509766, train/logprobs = tensor([[-1.0577, -1.0732],
        [-1.0391, -1.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0426228982396424e-05
Epoch 0, Step 567: train/loss = 0.7069170475006104, train/raw-loss = 0.706015944480896, train/logprobs = tensor([[-1.1340, -1.5849],
        [-1.2538, -1.3740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018021094147115946
Epoch 0, Step 568: train/loss = 0.6988052129745483, train/raw-loss = 0.697510302066803, train/logprobs = tensor([[-1.0646, -0.9569],
        [-1.2384, -0.9519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002589837182313204
Epoch 0, Step 569: train/loss = 0.7567712068557739, train/raw-loss = 0.7565782070159912, train/logprobs = tensor([[-1.2401, -0.7811],
        [-1.3061, -0.7433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003858748823404312
Epoch 0, Step 570: train/loss = 0.6978733539581299, train/raw-loss = 0.6971926093101501, train/logprobs = tensor([[-1.1428, -1.3684],
        [-1.1231, -1.1738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00136143050622195
Epoch 0, Step 571: train/loss = 0.7062405347824097, train/raw-loss = 0.7010645866394043, train/logprobs = tensor([[-1.0501, -1.4626],
        [-1.1791, -1.1937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010351939126849174
Epoch 0, Step 572: train/loss = 0.7496642470359802, train/raw-loss = 0.7470282912254333, train/logprobs = tensor([[-0.9743, -1.6189],
        [-1.1420, -1.3467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005271951202303171
Epoch 0, Step 573: train/loss = 0.7048846483230591, train/raw-loss = 0.7048044800758362, train/logprobs = tensor([[-1.0517, -0.9827],
        [-1.0622, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016033659630920738
Epoch 0, Step 574: train/loss = 0.7395473122596741, train/raw-loss = 0.7388491630554199, train/logprobs = tensor([[-0.8312, -1.4385],
        [-0.7930, -1.1907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001396306324750185
Epoch 0, Step 575: train/loss = 0.7146210670471191, train/raw-loss = 0.7138197422027588, train/logprobs = tensor([[-1.0423, -0.8689],
        [-1.1454, -0.7730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016026407247409225
Epoch 0, Step 576: train/loss = 0.7329162359237671, train/raw-loss = 0.7314242124557495, train/logprobs = tensor([[-1.3323, -1.3991],
        [-1.4976, -1.2876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029839822091162205
Epoch 0, Step 577: train/loss = 0.7016359567642212, train/raw-loss = 0.6988964080810547, train/logprobs = tensor([[-1.1659, -1.3312],
        [-1.2209, -1.2215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00547923194244504
Epoch 0, Step 578: train/loss = 0.7235779762268066, train/raw-loss = 0.7226673364639282, train/logprobs = tensor([[-1.2209, -1.5672],
        [-1.1804, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018211891874670982
Epoch 0, Step 579: train/loss = 0.6959649920463562, train/raw-loss = 0.6945382356643677, train/logprobs = tensor([[-1.1821, -1.3770],
        [-1.2389, -1.2950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028535607270896435
Epoch 0, Step 580: train/loss = 0.7224699854850769, train/raw-loss = 0.7140618562698364, train/logprobs = tensor([[-1.0109, -1.5424],
        [-1.1116, -1.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016816377639770508
Epoch 0, Step 581: train/loss = 0.693513035774231, train/raw-loss = 0.6932821273803711, train/logprobs = tensor([[-0.9111, -0.9389],
        [-0.9908, -0.9033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004618701059371233
Epoch 0, Step 582: train/loss = 0.7358513474464417, train/raw-loss = 0.7338051795959473, train/logprobs = tensor([[-0.9594, -1.3131],
        [-1.0206, -0.9961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004092316143214703
Epoch 0, Step 583: train/loss = 0.7035329341888428, train/raw-loss = 0.7025577425956726, train/logprobs = tensor([[-1.0719, -1.2549],
        [-1.1769, -1.0627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019503447692841291
Epoch 0, Step 584: train/loss = 0.6978666186332703, train/raw-loss = 0.6978551149368286, train/logprobs = tensor([[-1.4637, -1.4907],
        [-1.2707, -1.2629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.3002183297649026e-05
Epoch 0, Step 585: train/loss = 0.7395152449607849, train/raw-loss = 0.7394567728042603, train/logprobs = tensor([[-0.7077, -0.8725],
        [-0.6980, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011692719999700785
Epoch 0, Step 586: train/loss = 0.6988749504089355, train/raw-loss = 0.698582112789154, train/logprobs = tensor([[-1.1775, -1.1788],
        [-1.2159, -1.1813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005855398485437036
Epoch 0, Step 587: train/loss = 0.6949036717414856, train/raw-loss = 0.6930674314498901, train/logprobs = tensor([[-1.7323, -1.6758],
        [-1.6720, -1.5081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003672469174489379
Epoch 0, Step 588: train/loss = 0.7597919702529907, train/raw-loss = 0.7493489980697632, train/logprobs = tensor([[-0.9503, -1.8979],
        [-1.0092, -1.4252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020885970443487167
Epoch 0, Step 589: train/loss = 0.7237318754196167, train/raw-loss = 0.7192184925079346, train/logprobs = tensor([[-1.0436, -1.5851],
        [-1.0940, -1.3439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009026773273944855
Epoch 0, Step 590: train/loss = 0.7108809947967529, train/raw-loss = 0.7103748321533203, train/logprobs = tensor([[-1.0115, -1.2054],
        [-1.0220, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010122176026925445
Epoch 0, Step 591: train/loss = 0.7084696888923645, train/raw-loss = 0.7079644799232483, train/logprobs = tensor([[-1.0771, -1.4134],
        [-1.0803, -1.3429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001010403735563159
Epoch 0, Step 592: train/loss = 0.7071338295936584, train/raw-loss = 0.7057633996009827, train/logprobs = tensor([[-1.1032, -1.4124],
        [-1.1884, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002740863710641861
Epoch 0, Step 593: train/loss = 0.692720890045166, train/raw-loss = 0.6912976503372192, train/logprobs = tensor([[-1.2196, -1.4099],
        [-1.3486, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028465399518609047
Epoch 0, Step 594: train/loss = 0.6986152529716492, train/raw-loss = 0.6970759630203247, train/logprobs = tensor([[-1.2914, -1.4391],
        [-1.3147, -1.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003078584559261799
Epoch 0, Step 595: train/loss = 0.695266842842102, train/raw-loss = 0.6933631896972656, train/logprobs = tensor([[-1.2005, -1.5625],
        [-2.0679, -1.4797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038073286414146423
Epoch 0, Step 596: train/loss = 0.6966948509216309, train/raw-loss = 0.6962249875068665, train/logprobs = tensor([[-1.2170, -1.2477],
        [-1.3310, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000939586665481329
Epoch 0, Step 597: train/loss = 0.6988540291786194, train/raw-loss = 0.6967954635620117, train/logprobs = tensor([[-1.0797, -1.3073],
        [-1.2348, -1.0381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004117121919989586
Epoch 0, Step 598: train/loss = 0.6967321038246155, train/raw-loss = 0.6965945959091187, train/logprobs = tensor([[-0.9040, -0.8582],
        [-0.9412, -0.7832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027489333297125995
Epoch 0, Step 599: train/loss = 0.6944289803504944, train/raw-loss = 0.6944215297698975, train/logprobs = tensor([[-0.9195, -0.9727],
        [-0.8741, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4842822565697134e-05
Epoch 0, Step 600: train/loss = 0.6986439824104309, train/raw-loss = 0.6982355713844299, train/logprobs = tensor([[-1.1054, -1.2248],
        [-1.1269, -1.2468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008168152999132872
Epoch 0, Step 601: train/loss = 0.698394775390625, train/raw-loss = 0.6983548402786255, train/logprobs = tensor([[-0.9239, -0.8530],
        [-0.9489, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.992208702489734e-05
Epoch 0, Step 602: train/loss = 0.6949278116226196, train/raw-loss = 0.6948801279067993, train/logprobs = tensor([[-0.9566, -0.9811],
        [-0.9621, -0.9212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.54340721364133e-05
Epoch 0, Step 603: train/loss = 0.7139126658439636, train/raw-loss = 0.7128956317901611, train/logprobs = tensor([[-0.9786, -1.4986],
        [-1.0571, -1.2035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020340136252343655
Epoch 0, Step 604: train/loss = 0.7164080142974854, train/raw-loss = 0.716399073600769, train/logprobs = tensor([[-1.1968, -1.0073],
        [-1.2095, -0.9856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.769999653333798e-05
Epoch 0, Step 605: train/loss = 0.7021481394767761, train/raw-loss = 0.7008996605873108, train/logprobs = tensor([[-0.9127, -1.1825],
        [-0.9501, -1.0016]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024969400838017464
Epoch 0, Step 606: train/loss = 0.6994327306747437, train/raw-loss = 0.6991580724716187, train/logprobs = tensor([[-1.1079, -0.9644],
        [-1.0994, -0.9126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005495412624441087
Epoch 0, Step 607: train/loss = 0.722331166267395, train/raw-loss = 0.7211490273475647, train/logprobs = tensor([[-0.8575, -1.2751],
        [-0.9115, -1.1635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023643034510314465
Epoch 0, Step 608: train/loss = 0.6946423053741455, train/raw-loss = 0.6946364045143127, train/logprobs = tensor([[-0.9653, -0.9739],
        [-0.9417, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.172699558082968e-05
Epoch 0, Step 609: train/loss = 0.6938158869743347, train/raw-loss = 0.6843147277832031, train/logprobs = tensor([[-1.0486, -1.3520],
        [-1.3102, -1.2259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01900230348110199
Epoch 0, Step 610: train/loss = 0.695033073425293, train/raw-loss = 0.6949629187583923, train/logprobs = tensor([[-1.0513, -1.0287],
        [-1.1245, -1.0622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014036049833521247
Epoch 0, Step 611: train/loss = 0.7821521162986755, train/raw-loss = 0.7803487181663513, train/logprobs = tensor([[-1.5676, -1.2612],
        [-1.6485, -1.1653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003606850281357765
Epoch 0, Step 612: train/loss = 0.7166668176651001, train/raw-loss = 0.7166167497634888, train/logprobs = tensor([[-1.0331, -0.7917],
        [-1.1265, -0.7816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010022071364801377
Epoch 0, Step 613: train/loss = 0.7205699682235718, train/raw-loss = 0.7201331853866577, train/logprobs = tensor([[-0.9711, -1.2323],
        [-1.0346, -1.1219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008733870927244425
Epoch 0, Step 614: train/loss = 0.7136574983596802, train/raw-loss = 0.7134745121002197, train/logprobs = tensor([[-1.2881, -1.0423],
        [-1.3702, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003658886707853526
Epoch 0, Step 615: train/loss = 0.7005609273910522, train/raw-loss = 0.7002934217453003, train/logprobs = tensor([[-1.3319, -1.2584],
        [-1.2975, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005348946433514357
Epoch 0, Step 616: train/loss = 0.7554900050163269, train/raw-loss = 0.7494066953659058, train/logprobs = tensor([[-1.0546, -1.7269],
        [-1.0828, -1.3928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012166804634034634
Epoch 0, Step 617: train/loss = 0.7108243107795715, train/raw-loss = 0.7102088928222656, train/logprobs = tensor([[-0.7938, -1.2139],
        [-0.8775, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001230932306498289
Epoch 0, Step 618: train/loss = 0.7136412858963013, train/raw-loss = 0.7118679881095886, train/logprobs = tensor([[-1.2259, -1.0976],
        [-1.2526, -1.1389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003546582767739892
Epoch 0, Step 619: train/loss = 0.7033311128616333, train/raw-loss = 0.7029333710670471, train/logprobs = tensor([[-1.1999, -1.1465],
        [-1.4725, -1.2146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007954172324389219
Epoch 0, Step 620: train/loss = 0.7546052932739258, train/raw-loss = 0.7513796091079712, train/logprobs = tensor([[-1.0329, -1.6355],
        [-1.1478, -1.4443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006451431196182966
Epoch 0, Step 621: train/loss = 0.7153012752532959, train/raw-loss = 0.7150511741638184, train/logprobs = tensor([[-1.0300, -0.9693],
        [-1.0590, -0.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005001108511351049
Epoch 0, Step 622: train/loss = 0.7028282284736633, train/raw-loss = 0.698379635810852, train/logprobs = tensor([[-1.0265, -1.4464],
        [-1.0851, -1.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008897282183170319
Epoch 0, Step 623: train/loss = 0.7851107120513916, train/raw-loss = 0.7842925786972046, train/logprobs = tensor([[-1.3485, -0.9488],
        [-1.4647, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001636280445381999
Epoch 0, Step 624: train/loss = 0.7297372817993164, train/raw-loss = 0.7287802696228027, train/logprobs = tensor([[-0.9925, -1.3913],
        [-1.0547, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019140683580189943
Epoch 0, Step 625: train/loss = 0.722665548324585, train/raw-loss = 0.7224582433700562, train/logprobs = tensor([[-0.6782, -1.1533],
        [-0.6890, -1.0586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000414688081946224
Epoch 0, Step 626: train/loss = 0.7010791897773743, train/raw-loss = 0.7010033130645752, train/logprobs = tensor([[-1.2316, -1.0972],
        [-1.3229, -1.0907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000151793981785886
Epoch 0, Step 627: train/loss = 0.7097389101982117, train/raw-loss = 0.7094411849975586, train/logprobs = tensor([[-1.5113, -1.2637],
        [-1.4218, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005954062798991799
Epoch 0, Step 628: train/loss = 0.7086597681045532, train/raw-loss = 0.7082604169845581, train/logprobs = tensor([[-1.0758, -1.0697],
        [-1.3759, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007987144053913653
Epoch 0, Step 629: train/loss = 0.6971832513809204, train/raw-loss = 0.6951691508293152, train/logprobs = tensor([[-1.1301, -1.4333],
        [-1.2148, -1.2438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00402822345495224
Epoch 0, Step 630: train/loss = 0.7334612607955933, train/raw-loss = 0.7326089143753052, train/logprobs = tensor([[-0.8456, -1.0789],
        [-0.9138, -0.9607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017047100700438023
Epoch 0, Step 631: train/loss = 0.6926562786102295, train/raw-loss = 0.6892784833908081, train/logprobs = tensor([[-1.0369, -1.5054],
        [-1.2172, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006755449343472719
Epoch 0, Step 632: train/loss = 0.7042016386985779, train/raw-loss = 0.7026315927505493, train/logprobs = tensor([[-1.1929, -1.5438],
        [-1.2260, -1.3322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031401081942021847
Epoch 0, Step 633: train/loss = 0.693708062171936, train/raw-loss = 0.6936731338500977, train/logprobs = tensor([[-1.4410, -1.4748],
        [-1.3610, -1.3549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.971661787247285e-05
Epoch 0, Step 634: train/loss = 0.6947828531265259, train/raw-loss = 0.6899239420890808, train/logprobs = tensor([[-1.3134, -1.5821],
        [-1.3086, -1.2366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009717775508761406
Epoch 0, Step 635: train/loss = 0.6967492699623108, train/raw-loss = 0.696296215057373, train/logprobs = tensor([[-1.2255, -1.2042],
        [-1.0069, -0.9145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009060342563316226
Epoch 0, Step 636: train/loss = 0.6975302696228027, train/raw-loss = 0.690426766872406, train/logprobs = tensor([[-1.1915, -1.4294],
        [-1.2859, -1.1452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014206916093826294
Epoch 0, Step 637: train/loss = 0.699219822883606, train/raw-loss = 0.6988133788108826, train/logprobs = tensor([[-0.9293, -1.0464],
        [-1.0342, -0.9284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008129212073981762
Epoch 0, Step 638: train/loss = 0.7263116836547852, train/raw-loss = 0.7248928546905518, train/logprobs = tensor([[-0.9046, -1.3283],
        [-0.9974, -0.9899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028376225382089615
Epoch 0, Step 639: train/loss = 0.7083840370178223, train/raw-loss = 0.7052274942398071, train/logprobs = tensor([[-1.0369, -1.5158],
        [-1.0694, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006313043646514416
Epoch 0, Step 640: train/loss = 0.7093001008033752, train/raw-loss = 0.706169605255127, train/logprobs = tensor([[-0.9989, -1.7465],
        [-1.3782, -1.3555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006261053495109081
Epoch 0, Step 641: train/loss = 0.7108001112937927, train/raw-loss = 0.7094398736953735, train/logprobs = tensor([[-1.1869, -1.5226],
        [-1.2778, -1.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027203629724681377
Epoch 0, Step 642: train/loss = 0.701264500617981, train/raw-loss = 0.7006993293762207, train/logprobs = tensor([[-0.9731, -1.2399],
        [-0.9095, -1.0764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011303070932626724
Epoch 0, Step 643: train/loss = 0.7001908421516418, train/raw-loss = 0.6979732513427734, train/logprobs = tensor([[-1.2329, -1.3963],
        [-1.3881, -1.1696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004435163922607899
Epoch 0, Step 644: train/loss = 0.7150219678878784, train/raw-loss = 0.7130229473114014, train/logprobs = tensor([[-1.1154, -1.4800],
        [-1.1958, -1.3415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039979238063097
Epoch 0, Step 645: train/loss = 0.7146828174591064, train/raw-loss = 0.7136311531066895, train/logprobs = tensor([[-1.1269, -1.2116],
        [-1.1485, -1.1656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021031866781413555
Epoch 0, Step 646: train/loss = 0.7223444581031799, train/raw-loss = 0.720685601234436, train/logprobs = tensor([[-0.7787, -1.3666],
        [-0.8779, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003317880444228649
Epoch 0, Step 647: train/loss = 0.7252371311187744, train/raw-loss = 0.7249408960342407, train/logprobs = tensor([[-0.8689, -1.1993],
        [-0.9420, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005925229052081704
Epoch 0, Step 648: train/loss = 0.7159369587898254, train/raw-loss = 0.7107696533203125, train/logprobs = tensor([[-1.0457, -1.2976],
        [-1.1316, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01033466774970293
Epoch 0, Step 649: train/loss = 0.7071208357810974, train/raw-loss = 0.7059959173202515, train/logprobs = tensor([[-0.8918, -1.2133],
        [-0.9761, -1.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022498304024338722
Epoch 0, Step 650: train/loss = 0.7092660665512085, train/raw-loss = 0.7090045809745789, train/logprobs = tensor([[-0.8136, -1.0842],
        [-0.8482, -1.0419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005230242386460304
Epoch 0, Step 651: train/loss = 0.7060907483100891, train/raw-loss = 0.703788161277771, train/logprobs = tensor([[-1.4534, -1.3979],
        [-1.3447, -1.0752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004605262074619532
Epoch 0, Step 652: train/loss = 0.7047114372253418, train/raw-loss = 0.7013182640075684, train/logprobs = tensor([[-1.2218, -1.1205],
        [-1.0094, -0.9189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006786254234611988
Epoch 0, Step 653: train/loss = 0.7150645852088928, train/raw-loss = 0.7143804430961609, train/logprobs = tensor([[-0.9597, -1.1942],
        [-1.0516, -1.1364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001368361758068204
Epoch 0, Step 654: train/loss = 0.694393515586853, train/raw-loss = 0.6942979097366333, train/logprobs = tensor([[-0.8835, -0.8487],
        [-0.9118, -0.8317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001913365558721125
Epoch 0, Step 655: train/loss = 0.7364557981491089, train/raw-loss = 0.7288450002670288, train/logprobs = tensor([[-1.0714, -1.9197],
        [-1.1017, -1.3469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015221640467643738
Epoch 0, Step 656: train/loss = 0.6948449611663818, train/raw-loss = 0.694799542427063, train/logprobs = tensor([[-1.0851, -1.1522],
        [-1.1404, -1.0979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.092793334275484e-05
Epoch 0, Step 657: train/loss = 0.7022024989128113, train/raw-loss = 0.6991763710975647, train/logprobs = tensor([[-0.9733, -1.2422],
        [-1.0940, -1.0854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060522668063640594
Epoch 0, Step 658: train/loss = 0.7009848356246948, train/raw-loss = 0.7008709907531738, train/logprobs = tensor([[-1.0996, -1.1925],
        [-1.1608, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002275251317769289
Epoch 0, Step 659: train/loss = 0.6971133351325989, train/raw-loss = 0.6967198848724365, train/logprobs = tensor([[-1.0282, -1.0555],
        [-1.1043, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007868086686357856
Epoch 0, Step 660: train/loss = 0.6927400827407837, train/raw-loss = 0.6923813819885254, train/logprobs = tensor([[-1.3941, -1.3963],
        [-1.3916, -1.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007174181519076228
Epoch 0, Step 661: train/loss = 0.6961751580238342, train/raw-loss = 0.6935977339744568, train/logprobs = tensor([[-1.3106, -1.3191],
        [-1.3126, -1.1184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005154688376933336
Epoch 0, Step 662: train/loss = 0.7054442167282104, train/raw-loss = 0.7044887542724609, train/logprobs = tensor([[-1.0422, -0.8652],
        [-1.1567, -0.7866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019109360873699188
Epoch 0, Step 663: train/loss = 0.7093439698219299, train/raw-loss = 0.7080956697463989, train/logprobs = tensor([[-1.0374, -1.2377],
        [-1.0826, -1.1741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024965687189251184
Epoch 0, Step 664: train/loss = 0.7072275876998901, train/raw-loss = 0.7071257829666138, train/logprobs = tensor([[-1.1079, -1.3649],
        [-1.1639, -1.3918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002035637735389173
Epoch 0, Step 665: train/loss = 0.6984549164772034, train/raw-loss = 0.6978660225868225, train/logprobs = tensor([[-1.0351, -1.1504],
        [-1.2687, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011777684558182955
Epoch 0, Step 666: train/loss = 0.7059926986694336, train/raw-loss = 0.7057082653045654, train/logprobs = tensor([[-1.2395, -0.9751],
        [-1.3761, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005689723766408861
Epoch 0, Step 667: train/loss = 0.6995918154716492, train/raw-loss = 0.6995348930358887, train/logprobs = tensor([[-1.0679, -0.9327],
        [-1.0780, -0.8840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011382694356143475
Epoch 0, Step 668: train/loss = 0.7046797275543213, train/raw-loss = 0.7044085264205933, train/logprobs = tensor([[-0.9006, -0.9538],
        [-0.9307, -0.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005423391121439636
Epoch 0, Step 669: train/loss = 0.6976696252822876, train/raw-loss = 0.6940953135490417, train/logprobs = tensor([[-1.0073, -1.2158],
        [-1.1074, -0.9938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007148568518459797
Epoch 0, Step 670: train/loss = 0.7015335559844971, train/raw-loss = 0.7009713649749756, train/logprobs = tensor([[-1.0536, -1.1316],
        [-1.1593, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011243303306400776
Epoch 0, Step 671: train/loss = 0.701318085193634, train/raw-loss = 0.7008434534072876, train/logprobs = tensor([[-1.0233, -0.9267],
        [-1.1096, -1.0182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009492896497249603
Epoch 0, Step 672: train/loss = 0.7100503444671631, train/raw-loss = 0.7099770307540894, train/logprobs = tensor([[-0.8929, -1.2101],
        [-0.9428, -1.1929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014658801956102252
Epoch 0, Step 673: train/loss = 0.6952442526817322, train/raw-loss = 0.6945165395736694, train/logprobs = tensor([[-1.0100, -1.0836],
        [-0.9914, -0.9226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014554214430972934
Epoch 0, Step 674: train/loss = 0.7029037475585938, train/raw-loss = 0.7000632286071777, train/logprobs = tensor([[-0.9382, -1.2661],
        [-0.9614, -0.9946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0056810081005096436
Epoch 0, Step 675: train/loss = 0.6961332559585571, train/raw-loss = 0.6960980892181396, train/logprobs = tensor([[-0.9760, -0.8896],
        [-1.0106, -0.8910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.031897257547826e-05
Epoch 0, Step 676: train/loss = 0.7152119278907776, train/raw-loss = 0.7133687734603882, train/logprobs = tensor([[-0.9789, -1.4163],
        [-1.0670, -1.2870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036863135173916817
Epoch 0, Step 677: train/loss = 0.6984868049621582, train/raw-loss = 0.6974443197250366, train/logprobs = tensor([[-1.0230, -1.3064],
        [-0.9976, -1.0647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002084908075630665
Epoch 0, Step 678: train/loss = 0.7093477249145508, train/raw-loss = 0.7088849544525146, train/logprobs = tensor([[-1.1814, -1.4708],
        [-1.2185, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009254527976736426
Epoch 0, Step 679: train/loss = 0.6998584866523743, train/raw-loss = 0.6986864805221558, train/logprobs = tensor([[-1.0296, -1.0227],
        [-1.0886, -0.9843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023441086523234844
Epoch 0, Step 680: train/loss = 0.7064328193664551, train/raw-loss = 0.7054413557052612, train/logprobs = tensor([[-1.2168, -1.7371],
        [-1.2573, -1.3112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019829515367746353
Epoch 0, Step 681: train/loss = 0.7055399417877197, train/raw-loss = 0.7050501704216003, train/logprobs = tensor([[-1.3182, -1.3853],
        [-1.3106, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009796139784157276
Epoch 0, Step 682: train/loss = 0.7139314413070679, train/raw-loss = 0.7130497097969055, train/logprobs = tensor([[-1.0796, -1.1501],
        [-1.1531, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017633847892284393
Epoch 0, Step 683: train/loss = 0.7194581627845764, train/raw-loss = 0.7189803123474121, train/logprobs = tensor([[-1.1272, -0.9052],
        [-1.1907, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000955775030888617
Epoch 0, Step 684: train/loss = 0.7003062963485718, train/raw-loss = 0.7001869678497314, train/logprobs = tensor([[-1.1886, -1.4860],
        [-1.2494, -1.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023873272584751248
Epoch 0, Step 685: train/loss = 0.7056998014450073, train/raw-loss = 0.7056543827056885, train/logprobs = tensor([[-1.1937, -1.1814],
        [-1.2312, -1.1826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.089625382330269e-05
Epoch 0, Step 686: train/loss = 0.6938108205795288, train/raw-loss = 0.693564236164093, train/logprobs = tensor([[-1.1127, -1.1400],
        [-1.1543, -1.0671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004931550356559455
Epoch 0, Step 687: train/loss = 0.7028084993362427, train/raw-loss = 0.7018311023712158, train/logprobs = tensor([[-1.0793, -1.4747],
        [-1.1965, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001954860519617796
Epoch 0, Step 688: train/loss = 0.7002043128013611, train/raw-loss = 0.7001383304595947, train/logprobs = tensor([[-1.0492, -1.2381],
        [-1.1299, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001320863957516849
Epoch 0, Step 689: train/loss = 0.7084110975265503, train/raw-loss = 0.7081695795059204, train/logprobs = tensor([[-0.9801, -1.0484],
        [-1.0320, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004829872341360897
Epoch 0, Step 690: train/loss = 0.7320822477340698, train/raw-loss = 0.7295024394989014, train/logprobs = tensor([[-1.0837, -1.4424],
        [-1.1616, -1.3621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005159548483788967
Epoch 0, Step 691: train/loss = 0.7006646394729614, train/raw-loss = 0.7003749012947083, train/logprobs = tensor([[-1.0368, -1.2836],
        [-1.1146, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005794720491394401
Epoch 0, Step 692: train/loss = 0.6999592781066895, train/raw-loss = 0.698170006275177, train/logprobs = tensor([[-1.1738, -1.2940],
        [-1.3434, -1.1777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00357840652577579
Epoch 0, Step 693: train/loss = 0.6963810324668884, train/raw-loss = 0.6962943077087402, train/logprobs = tensor([[-1.2268, -1.2320],
        [-1.3469, -1.2000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017344969091936946
Epoch 0, Step 694: train/loss = 0.7164324522018433, train/raw-loss = 0.7162286639213562, train/logprobs = tensor([[-0.9665, -0.9971],
        [-1.0010, -0.9763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004075112228747457
Epoch 0, Step 695: train/loss = 0.694232702255249, train/raw-loss = 0.6939280033111572, train/logprobs = tensor([[-0.9143, -1.0471],
        [-1.0322, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006093807751312852
Epoch 0, Step 696: train/loss = 0.7010971903800964, train/raw-loss = 0.7008130550384521, train/logprobs = tensor([[-0.7700, -0.7719],
        [-0.8420, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005682994378730655
Epoch 0, Step 697: train/loss = 0.7011277675628662, train/raw-loss = 0.7004741430282593, train/logprobs = tensor([[-1.1498, -0.9914],
        [-1.2161, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013070737477391958
Epoch 0, Step 698: train/loss = 0.6939859390258789, train/raw-loss = 0.6928901672363281, train/logprobs = tensor([[-1.0648, -1.1569],
        [-1.2917, -1.2170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002191507024690509
Epoch 0, Step 699: train/loss = 0.7074760794639587, train/raw-loss = 0.7064182758331299, train/logprobs = tensor([[-1.1446, -0.9861],
        [-1.2216, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00211554067209363
Epoch 0, Step 700: train/loss = 0.6947381496429443, train/raw-loss = 0.6946491003036499, train/logprobs = tensor([[-1.1006, -1.1100],
        [-1.1437, -1.0694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017812888836488128
Epoch 0, Step 701: train/loss = 0.7143430113792419, train/raw-loss = 0.7142219543457031, train/logprobs = tensor([[-1.1755, -1.2961],
        [-1.2712, -1.2634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024203304201364517
Epoch 0, Step 702: train/loss = 0.7072989344596863, train/raw-loss = 0.706695556640625, train/logprobs = tensor([[-0.8989, -1.0397],
        [-0.8951, -0.9554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001206845510751009
Epoch 0, Step 703: train/loss = 0.7019162178039551, train/raw-loss = 0.6999149918556213, train/logprobs = tensor([[-0.9923, -0.9492],
        [-1.0574, -1.0390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004002509638667107
Epoch 0, Step 704: train/loss = 0.756623387336731, train/raw-loss = 0.7534338235855103, train/logprobs = tensor([[-1.0313, -1.6202],
        [-1.0963, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006379244849085808
Epoch 0, Step 705: train/loss = 0.711310863494873, train/raw-loss = 0.7092015743255615, train/logprobs = tensor([[-1.0924, -1.3759],
        [-1.2470, -1.1936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042186020873487
Epoch 0, Step 706: train/loss = 0.7052603363990784, train/raw-loss = 0.7045285701751709, train/logprobs = tensor([[-0.9062, -1.1642],
        [-1.0278, -0.9399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014634564286097884
Epoch 0, Step 707: train/loss = 0.6954001188278198, train/raw-loss = 0.695372462272644, train/logprobs = tensor([[-1.0695, -1.0693],
        [-1.0659, -1.0490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.5314041674137115e-05
Epoch 0, Step 708: train/loss = 0.7069593071937561, train/raw-loss = 0.7065594792366028, train/logprobs = tensor([[-1.0757, -1.1532],
        [-1.1191, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007996215717867017
Epoch 0, Step 709: train/loss = 0.6982230544090271, train/raw-loss = 0.6982041597366333, train/logprobs = tensor([[-1.0935, -1.1178],
        [-1.1677, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.779502003453672e-05
Epoch 0, Step 710: train/loss = 0.6987655162811279, train/raw-loss = 0.6982563138008118, train/logprobs = tensor([[-0.9680, -1.1032],
        [-1.1314, -0.9630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010184487327933311
Epoch 0, Step 711: train/loss = 0.7182292938232422, train/raw-loss = 0.7176042795181274, train/logprobs = tensor([[-1.3021, -1.1095],
        [-1.5405, -1.2032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012501573655754328
Epoch 0, Step 712: train/loss = 0.7103849053382874, train/raw-loss = 0.7102681398391724, train/logprobs = tensor([[-1.0713, -1.3730],
        [-1.0989, -1.3186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002335555909667164
Epoch 0, Step 713: train/loss = 0.7012572288513184, train/raw-loss = 0.7010684609413147, train/logprobs = tensor([[-1.1813, -1.1250],
        [-1.2288, -1.1191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003774359356611967
Epoch 0, Step 714: train/loss = 0.696718156337738, train/raw-loss = 0.696424663066864, train/logprobs = tensor([[-1.0681, -1.1936],
        [-1.1429, -1.1871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005869371816515923
Epoch 0, Step 715: train/loss = 0.7007837891578674, train/raw-loss = 0.7003757953643799, train/logprobs = tensor([[-1.0710, -1.2056],
        [-1.0937, -1.2825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008159470744431019
Epoch 0, Step 716: train/loss = 0.7148184180259705, train/raw-loss = 0.7104157209396362, train/logprobs = tensor([[-1.1075, -1.6232],
        [-1.2729, -1.3554]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008805373683571815
Epoch 0, Step 717: train/loss = 0.7002670168876648, train/raw-loss = 0.6974412202835083, train/logprobs = tensor([[-1.1097, -1.0354],
        [-1.2592, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005651433020830154
Epoch 0, Step 718: train/loss = 0.6952173113822937, train/raw-loss = 0.6945512294769287, train/logprobs = tensor([[-0.9222, -0.9331],
        [-1.0237, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013321579899638891
Epoch 0, Step 719: train/loss = 0.6997972726821899, train/raw-loss = 0.6994789838790894, train/logprobs = tensor([[-1.2331, -1.1070],
        [-1.3275, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006366123561747372
Epoch 0, Step 720: train/loss = 0.6946892142295837, train/raw-loss = 0.6944998502731323, train/logprobs = tensor([[-1.1074, -1.1687],
        [-1.1538, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003787155728787184
Epoch 0, Step 721: train/loss = 0.7010146379470825, train/raw-loss = 0.7009334564208984, train/logprobs = tensor([[-1.0852, -1.3157],
        [-1.1403, -1.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001622046111151576
Epoch 0, Step 722: train/loss = 0.6989834904670715, train/raw-loss = 0.6984981298446655, train/logprobs = tensor([[-1.1314, -0.9941],
        [-1.2343, -1.0161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009707543067634106
Epoch 0, Step 723: train/loss = 0.7100940942764282, train/raw-loss = 0.7100105285644531, train/logprobs = tensor([[-1.2228, -1.0544],
        [-1.2950, -1.1091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000167102029081434
Epoch 0, Step 724: train/loss = 0.697536826133728, train/raw-loss = 0.6974533796310425, train/logprobs = tensor([[-1.0453, -1.2450],
        [-1.1665, -1.2593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016690885240677744
Epoch 0, Step 725: train/loss = 0.6997255682945251, train/raw-loss = 0.6992807388305664, train/logprobs = tensor([[-0.9858, -1.0356],
        [-1.0549, -0.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000889542861841619
Epoch 0, Step 726: train/loss = 0.7009417414665222, train/raw-loss = 0.7003751993179321, train/logprobs = tensor([[-1.1156, -1.0194],
        [-1.2488, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011331344721838832
Epoch 0, Step 727: train/loss = 0.6973423361778259, train/raw-loss = 0.6968767642974854, train/logprobs = tensor([[-1.1138, -1.1189],
        [-1.2234, -1.0339]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009310992900282145
Epoch 0, Step 728: train/loss = 0.7061784267425537, train/raw-loss = 0.7060967683792114, train/logprobs = tensor([[-1.2897, -1.2183],
        [-1.3465, -1.2388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016328028868883848
Epoch 0, Step 729: train/loss = 0.6984454989433289, train/raw-loss = 0.6982208490371704, train/logprobs = tensor([[-0.9576, -0.9446],
        [-1.0593, -0.9731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044935906771570444
Epoch 0, Step 730: train/loss = 0.6998958587646484, train/raw-loss = 0.699027419090271, train/logprobs = tensor([[-1.0916, -1.1414],
        [-1.1685, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017368803964927793
Epoch 0, Step 731: train/loss = 0.7166709899902344, train/raw-loss = 0.7163380980491638, train/logprobs = tensor([[-1.2004, -0.9628],
        [-1.3345, -0.9561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006658132188022137
Epoch 0, Step 732: train/loss = 0.7060873508453369, train/raw-loss = 0.7041242122650146, train/logprobs = tensor([[-1.1172, -1.1488],
        [-1.2719, -0.9708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003926348406821489
Epoch 0, Step 733: train/loss = 0.7190225124359131, train/raw-loss = 0.7183390855789185, train/logprobs = tensor([[-1.1749, -0.9552],
        [-1.3448, -1.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001366879791021347
Epoch 0, Step 734: train/loss = 0.6945503950119019, train/raw-loss = 0.6942983865737915, train/logprobs = tensor([[-0.8658, -0.8683],
        [-1.0011, -0.9599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000504065421409905
Epoch 0, Step 735: train/loss = 0.7088669538497925, train/raw-loss = 0.7085891962051392, train/logprobs = tensor([[-1.3064, -1.2542],
        [-1.4329, -1.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005553888622671366
Epoch 0, Step 736: train/loss = 0.7181836366653442, train/raw-loss = 0.7180285453796387, train/logprobs = tensor([[-1.3549, -1.0074],
        [-1.4642, -0.9850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003101647598668933
Epoch 0, Step 737: train/loss = 0.6963660717010498, train/raw-loss = 0.696293830871582, train/logprobs = tensor([[-1.0793, -0.9643],
        [-1.1188, -0.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014444126281887293
Epoch 0, Step 738: train/loss = 0.6961788535118103, train/raw-loss = 0.6960365772247314, train/logprobs = tensor([[-1.1338, -1.1599],
        [-1.3002, -1.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028452082187868655
Epoch 0, Step 739: train/loss = 0.7042896151542664, train/raw-loss = 0.7041425108909607, train/logprobs = tensor([[-1.1250, -1.1311],
        [-1.1471, -1.0007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029409141279757023
Epoch 0, Step 740: train/loss = 0.6998271942138672, train/raw-loss = 0.6997599601745605, train/logprobs = tensor([[-0.9765, -1.1175],
        [-1.0127, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013439671602100134
Epoch 0, Step 741: train/loss = 0.6952617168426514, train/raw-loss = 0.6927894949913025, train/logprobs = tensor([[-0.8948, -1.1040],
        [-1.0221, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004944361746311188
Epoch 0, Step 742: train/loss = 0.6964413523674011, train/raw-loss = 0.6952533721923828, train/logprobs = tensor([[-1.2250, -1.3915],
        [-1.4129, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023758753668516874
Epoch 0, Step 743: train/loss = 0.702987015247345, train/raw-loss = 0.7019559741020203, train/logprobs = tensor([[-1.2588, -1.1219],
        [-1.3905, -1.0989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002062069484964013
Epoch 0, Step 744: train/loss = 0.6986914873123169, train/raw-loss = 0.6904965043067932, train/logprobs = tensor([[-0.9592, -1.1336],
        [-1.4689, -1.3028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0163898803293705
Epoch 0, Step 745: train/loss = 0.6972199082374573, train/raw-loss = 0.6965999007225037, train/logprobs = tensor([[-1.0631, -1.0258],
        [-1.1364, -1.0577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012399612460285425
Epoch 0, Step 746: train/loss = 0.70169997215271, train/raw-loss = 0.7016736268997192, train/logprobs = tensor([[-0.9247, -0.7790],
        [-0.9633, -0.7992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.2695930207846686e-05
Epoch 0, Step 747: train/loss = 0.696890115737915, train/raw-loss = 0.696603000164032, train/logprobs = tensor([[-1.3250, -1.3453],
        [-1.4462, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000574206467717886
Epoch 0, Step 748: train/loss = 0.6976618766784668, train/raw-loss = 0.697494626045227, train/logprobs = tensor([[-1.0482, -0.9625],
        [-1.1338, -0.9805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003343994321767241
Epoch 0, Step 749: train/loss = 0.7213859558105469, train/raw-loss = 0.7200744152069092, train/logprobs = tensor([[-1.1993, -0.9231],
        [-1.4243, -0.8821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026229729410260916
Epoch 0, Step 750: train/loss = 0.7018008828163147, train/raw-loss = 0.7008179426193237, train/logprobs = tensor([[-0.9822, -0.9651],
        [-1.0934, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001966010080650449
Epoch 0, Step 751: train/loss = 0.6960194110870361, train/raw-loss = 0.6951724290847778, train/logprobs = tensor([[-1.1775, -1.2689],
        [-1.1928, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016939551569521427
Epoch 0, Step 752: train/loss = 0.699504017829895, train/raw-loss = 0.6994498372077942, train/logprobs = tensor([[-1.0919, -1.1197],
        [-1.0865, -1.0557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010825070785358548
Epoch 0, Step 753: train/loss = 0.7005242109298706, train/raw-loss = 0.7005149126052856, train/logprobs = tensor([[-1.1510, -1.2940],
        [-1.1971, -1.2740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8615690350998193e-05
Epoch 0, Step 754: train/loss = 0.7251648306846619, train/raw-loss = 0.7248594760894775, train/logprobs = tensor([[-1.3248, -0.9377],
        [-1.3959, -0.9237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006107230437919497
Epoch 0, Step 755: train/loss = 0.6984386444091797, train/raw-loss = 0.6983073949813843, train/logprobs = tensor([[-1.0355, -1.1904],
        [-1.1316, -1.1391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026256885030306876
Epoch 0, Step 756: train/loss = 0.695928692817688, train/raw-loss = 0.6957975625991821, train/logprobs = tensor([[-1.2003, -1.2743],
        [-1.2838, -1.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002620895975269377
Epoch 0, Step 757: train/loss = 0.6992071866989136, train/raw-loss = 0.6991785168647766, train/logprobs = tensor([[-1.2214, -1.0813],
        [-1.3836, -1.2277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.733262514695525e-05
Epoch 0, Step 758: train/loss = 0.6981799006462097, train/raw-loss = 0.6980577707290649, train/logprobs = tensor([[-0.9879, -1.1351],
        [-1.1223, -1.1899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002442355325911194
Epoch 0, Step 759: train/loss = 0.6914926767349243, train/raw-loss = 0.686701238155365, train/logprobs = tensor([[-1.0555, -1.2451],
        [-1.3337, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009582819417119026
Epoch 0, Step 760: train/loss = 0.6951113939285278, train/raw-loss = 0.694903552532196, train/logprobs = tensor([[-1.1895, -1.1978],
        [-1.3204, -1.1404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004157308430876583
Epoch 0, Step 761: train/loss = 0.7479191422462463, train/raw-loss = 0.7449197173118591, train/logprobs = tensor([[-1.3036, -1.1299],
        [-1.5720, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005998772103339434
Epoch 0, Step 762: train/loss = 0.6945440769195557, train/raw-loss = 0.6943701505661011, train/logprobs = tensor([[-0.8939, -0.9444],
        [-1.0022, -0.9785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034776516258716583
Epoch 0, Step 763: train/loss = 0.7112112045288086, train/raw-loss = 0.7111718654632568, train/logprobs = tensor([[-1.1791, -0.8706],
        [-1.2021, -0.8828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.861914491513744e-05
Epoch 0, Step 764: train/loss = 0.713168203830719, train/raw-loss = 0.7130884528160095, train/logprobs = tensor([[-1.1939, -0.9403],
        [-1.2373, -0.8738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015959306620061398
Epoch 0, Step 765: train/loss = 0.7158068418502808, train/raw-loss = 0.7151389122009277, train/logprobs = tensor([[-1.1572, -0.8820],
        [-1.1991, -0.7778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013358313590288162
Epoch 0, Step 766: train/loss = 0.7089120149612427, train/raw-loss = 0.7087096571922302, train/logprobs = tensor([[-1.2104, -1.0955],
        [-1.3512, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000404643127694726
Epoch 0, Step 767: train/loss = 0.6964296698570251, train/raw-loss = 0.6962930560112, train/logprobs = tensor([[-0.9556, -0.8444],
        [-0.9804, -0.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002733307774178684
Epoch 0, Step 768: train/loss = 0.70738285779953, train/raw-loss = 0.707287609577179, train/logprobs = tensor([[-1.1421, -1.1007],
        [-1.2508, -1.0903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019046809757128358
Epoch 0, Step 769: train/loss = 0.7363780736923218, train/raw-loss = 0.7341228723526001, train/logprobs = tensor([[-1.0542, -1.5461],
        [-1.2027, -1.3560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045102364383637905
Epoch 0, Step 770: train/loss = 0.6961625814437866, train/raw-loss = 0.6944728493690491, train/logprobs = tensor([[-1.3051, -1.3279],
        [-1.4340, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003379498841241002
Epoch 0, Step 771: train/loss = 0.6911293268203735, train/raw-loss = 0.6899982690811157, train/logprobs = tensor([[-1.1438, -1.1896],
        [-1.2711, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002262042136862874
Epoch 0, Step 772: train/loss = 0.7045488357543945, train/raw-loss = 0.7035442590713501, train/logprobs = tensor([[-0.9788, -0.9178],
        [-1.1235, -0.8860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002009038580581546
Epoch 0, Step 773: train/loss = 0.6965206861495972, train/raw-loss = 0.6957449913024902, train/logprobs = tensor([[-1.1943, -1.1502],
        [-1.3651, -1.1418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015513729304075241
Epoch 0, Step 774: train/loss = 0.6984615921974182, train/raw-loss = 0.6983132362365723, train/logprobs = tensor([[-1.0818, -1.0825],
        [-1.1950, -1.0724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002967580803669989
Epoch 0, Step 775: train/loss = 0.7308684587478638, train/raw-loss = 0.7307702302932739, train/logprobs = tensor([[-1.1636, -0.8263],
        [-1.1936, -0.7631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019644125131890178
Epoch 0, Step 776: train/loss = 0.7294584512710571, train/raw-loss = 0.7293736934661865, train/logprobs = tensor([[-1.3373, -1.1052],
        [-1.3814, -1.1313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016968592535704374
Epoch 0, Step 777: train/loss = 0.6944578886032104, train/raw-loss = 0.6942719221115112, train/logprobs = tensor([[-0.9357, -0.9967],
        [-1.0321, -0.9970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037181901279836893
Epoch 0, Step 778: train/loss = 0.7119885683059692, train/raw-loss = 0.7111129760742188, train/logprobs = tensor([[-1.3031, -1.0382],
        [-1.4792, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017511837650090456
Epoch 0, Step 779: train/loss = 0.7016025185585022, train/raw-loss = 0.7015897631645203, train/logprobs = tensor([[-0.7555, -0.7477],
        [-0.7763, -0.7492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.551334910094738e-05
Epoch 0, Step 780: train/loss = 0.6969333291053772, train/raw-loss = 0.6966114044189453, train/logprobs = tensor([[-1.1858, -1.0913],
        [-1.1937, -1.0418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006437135743908584
Epoch 0, Step 781: train/loss = 0.7142183184623718, train/raw-loss = 0.7139766216278076, train/logprobs = tensor([[-0.9714, -1.0543],
        [-1.0434, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00048344844253733754
Epoch 0, Step 782: train/loss = 0.6948173642158508, train/raw-loss = 0.6942315101623535, train/logprobs = tensor([[-1.0258, -1.0017],
        [-1.0593, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011717223096638918
Epoch 0, Step 783: train/loss = 0.7116009593009949, train/raw-loss = 0.7112539410591125, train/logprobs = tensor([[-1.1134, -0.8291],
        [-1.2020, -0.8262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006939929444342852
Epoch 0, Step 784: train/loss = 0.6968380212783813, train/raw-loss = 0.6950938701629639, train/logprobs = tensor([[-0.9268, -1.0561],
        [-1.0152, -1.0514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003488278714939952
Epoch 0, Step 785: train/loss = 0.7124599814414978, train/raw-loss = 0.7119220495223999, train/logprobs = tensor([[-1.2671, -1.5565],
        [-1.4037, -1.5063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010757909622043371
Epoch 0, Step 786: train/loss = 0.7103031873703003, train/raw-loss = 0.7084728479385376, train/logprobs = tensor([[-1.0948, -1.1846],
        [-1.2130, -1.1659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036606763023883104
Epoch 0, Step 787: train/loss = 0.6930506825447083, train/raw-loss = 0.6930257678031921, train/logprobs = tensor([[-0.9821, -0.9962],
        [-1.0522, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.980323137715459e-05
Epoch 0, Step 788: train/loss = 0.7057874202728271, train/raw-loss = 0.7052291631698608, train/logprobs = tensor([[-0.9827, -0.9357],
        [-1.0884, -0.8940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011165639152750373
Epoch 0, Step 789: train/loss = 0.7003507018089294, train/raw-loss = 0.6998245120048523, train/logprobs = tensor([[-1.2162, -1.1784],
        [-1.2515, -1.2965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010523812379688025
Epoch 0, Step 790: train/loss = 0.6954718828201294, train/raw-loss = 0.695294976234436, train/logprobs = tensor([[-1.0888, -1.1164],
        [-1.1730, -1.0767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003539309836924076
Epoch 0, Step 791: train/loss = 0.7073447108268738, train/raw-loss = 0.7072542905807495, train/logprobs = tensor([[-1.2577, -1.3689],
        [-1.3568, -1.3222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018084642942994833
Epoch 0, Step 792: train/loss = 0.7635798454284668, train/raw-loss = 0.7631424069404602, train/logprobs = tensor([[-1.4819, -0.9707],
        [-1.5928, -0.8900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008747850079089403
Epoch 0, Step 793: train/loss = 0.6942012906074524, train/raw-loss = 0.6941107511520386, train/logprobs = tensor([[-0.9505, -0.9888],
        [-0.9870, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018088764045387506
Epoch 0, Step 794: train/loss = 0.6950908303260803, train/raw-loss = 0.6949334740638733, train/logprobs = tensor([[-0.8632, -0.7823],
        [-0.8441, -0.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003147805982735008
Epoch 0, Step 795: train/loss = 0.7082098126411438, train/raw-loss = 0.7079154253005981, train/logprobs = tensor([[-1.3830, -1.2040],
        [-1.5585, -1.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005889262538403273
Epoch 0, Step 796: train/loss = 0.6916270852088928, train/raw-loss = 0.6889172792434692, train/logprobs = tensor([[-1.1093, -1.1817],
        [-1.0784, -0.8877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005419491324573755
Epoch 0, Step 797: train/loss = 0.7014461159706116, train/raw-loss = 0.7008793354034424, train/logprobs = tensor([[-1.2343, -1.0956],
        [-1.3356, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011335770832374692
Epoch 0, Step 798: train/loss = 0.6977488398551941, train/raw-loss = 0.6976717710494995, train/logprobs = tensor([[-0.8728, -1.0613],
        [-0.9542, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015412729408126324
Epoch 0, Step 799: train/loss = 0.7095924019813538, train/raw-loss = 0.7094454765319824, train/logprobs = tensor([[-0.8010, -0.8506],
        [-0.8579, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029390642885118723
Epoch 0, Step 800: train/loss = 0.7111803889274597, train/raw-loss = 0.7105773687362671, train/logprobs = tensor([[-1.0499, -1.0294],
        [-1.3308, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012059796135872602
Epoch 0, Step 801: train/loss = 0.6960508823394775, train/raw-loss = 0.6958771347999573, train/logprobs = tensor([[-0.9512, -1.0420],
        [-1.0858, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003474685363471508
Epoch 0, Step 802: train/loss = 0.6970109939575195, train/raw-loss = 0.6967527866363525, train/logprobs = tensor([[-1.0547, -0.9673],
        [-1.1256, -0.9264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005163704045116901
Epoch 0, Step 803: train/loss = 0.6940817832946777, train/raw-loss = 0.6936829686164856, train/logprobs = tensor([[-1.0273, -1.1367],
        [-1.1013, -1.0547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007976067718118429
Epoch 0, Step 804: train/loss = 0.695300281047821, train/raw-loss = 0.6952611804008484, train/logprobs = tensor([[-0.8871, -0.8385],
        [-0.8986, -0.8084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.818182348273695e-05
Epoch 0, Step 805: train/loss = 0.6993100047111511, train/raw-loss = 0.6990911960601807, train/logprobs = tensor([[-1.1937, -1.0999],
        [-1.3010, -1.0969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043753779027611017
Epoch 0, Step 806: train/loss = 0.6954366564750671, train/raw-loss = 0.6950949430465698, train/logprobs = tensor([[-1.1291, -1.1214],
        [-1.1150, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006833337829448283
Epoch 0, Step 807: train/loss = 0.6953686475753784, train/raw-loss = 0.695032000541687, train/logprobs = tensor([[-1.1443, -1.1415],
        [-1.2767, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006733275949954987
Epoch 0, Step 808: train/loss = 0.6932212114334106, train/raw-loss = 0.6931833028793335, train/logprobs = tensor([[-0.9394, -1.0119],
        [-1.0109, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.56728695705533e-05
Epoch 0, Step 809: train/loss = 0.7011280655860901, train/raw-loss = 0.7010583877563477, train/logprobs = tensor([[-1.0373, -0.8534],
        [-1.0831, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013952734298072755
Epoch 0, Step 810: train/loss = 0.678512692451477, train/raw-loss = 0.6784660816192627, train/logprobs = tensor([[-0.9629, -1.0850],
        [-1.1889, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.317189687862992e-05
Epoch 0, Step 811: train/loss = 0.7055478096008301, train/raw-loss = 0.7048977613449097, train/logprobs = tensor([[-1.1790, -0.9012],
        [-1.2159, -0.9177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013000034959986806
Epoch 0, Step 812: train/loss = 0.6957932710647583, train/raw-loss = 0.6940606832504272, train/logprobs = tensor([[-0.9463, -1.0384],
        [-1.0526, -0.9342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034651949536055326
Epoch 0, Step 813: train/loss = 0.6994022130966187, train/raw-loss = 0.6974329352378845, train/logprobs = tensor([[-1.1292, -1.1358],
        [-1.2576, -1.0816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039384448900818825
Epoch 0, Step 814: train/loss = 0.6963673830032349, train/raw-loss = 0.6962910890579224, train/logprobs = tensor([[-1.2212, -1.3814],
        [-1.2671, -1.3395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015269999857991934
Epoch 0, Step 815: train/loss = 0.6938607692718506, train/raw-loss = 0.6938444375991821, train/logprobs = tensor([[-1.2421, -1.2189],
        [-1.2920, -1.2285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.2739248126745224e-05
Epoch 0, Step 816: train/loss = 0.706564724445343, train/raw-loss = 0.7064228057861328, train/logprobs = tensor([[-1.0607, -0.8317],
        [-1.0944, -0.7924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028379191644489765
Epoch 0, Step 817: train/loss = 0.6948915123939514, train/raw-loss = 0.694815993309021, train/logprobs = tensor([[-1.0290, -1.1301],
        [-1.1042, -1.1222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001511241716798395
Epoch 0, Step 818: train/loss = 0.6999475359916687, train/raw-loss = 0.6996828317642212, train/logprobs = tensor([[-0.9273, -1.2237],
        [-1.2332, -1.1937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005293077556416392
Epoch 0, Step 819: train/loss = 0.6955984830856323, train/raw-loss = 0.6951545476913452, train/logprobs = tensor([[-1.2841, -1.3404],
        [-1.3485, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008879796369001269
Epoch 0, Step 820: train/loss = 0.694488525390625, train/raw-loss = 0.6942893862724304, train/logprobs = tensor([[-1.0200, -1.0566],
        [-1.0671, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003983968053944409
Epoch 0, Step 821: train/loss = 0.7009172439575195, train/raw-loss = 0.7005939483642578, train/logprobs = tensor([[-1.1498, -1.0079],
        [-1.2650, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006465488695539534
Epoch 0, Step 822: train/loss = 0.69439697265625, train/raw-loss = 0.6943349838256836, train/logprobs = tensor([[-0.9961, -1.0209],
        [-1.0227, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012396901729516685
Epoch 0, Step 823: train/loss = 0.7085812091827393, train/raw-loss = 0.7048894166946411, train/logprobs = tensor([[-1.3088, -1.2377],
        [-1.4297, -1.1296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007383537013083696
Epoch 0, Step 824: train/loss = 0.6969276666641235, train/raw-loss = 0.6948605179786682, train/logprobs = tensor([[-0.9148, -1.1615],
        [-1.0981, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004134228453040123
Epoch 0, Step 825: train/loss = 0.6995868682861328, train/raw-loss = 0.6991018056869507, train/logprobs = tensor([[-1.2780, -1.4311],
        [-1.4217, -1.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009701206581667066
Epoch 0, Step 826: train/loss = 0.6966056823730469, train/raw-loss = 0.6952955722808838, train/logprobs = tensor([[-1.1503, -1.1435],
        [-1.2631, -1.1231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002620350569486618
Epoch 0, Step 827: train/loss = 0.696830153465271, train/raw-loss = 0.6952719688415527, train/logprobs = tensor([[-1.0742, -1.0327],
        [-1.1894, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031162232626229525
Epoch 0, Step 828: train/loss = 0.697935938835144, train/raw-loss = 0.6977120637893677, train/logprobs = tensor([[-0.8245, -1.0133],
        [-0.8851, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004477008478716016
Epoch 0, Step 829: train/loss = 0.7169820666313171, train/raw-loss = 0.7168445587158203, train/logprobs = tensor([[-1.2553, -1.0830],
        [-1.4315, -1.0470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027503265300765634
Epoch 0, Step 830: train/loss = 0.7199591398239136, train/raw-loss = 0.7194870114326477, train/logprobs = tensor([[-0.8348, -1.0701],
        [-0.9464, -1.0192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009444184834137559
Epoch 0, Step 831: train/loss = 0.6971068382263184, train/raw-loss = 0.6961725354194641, train/logprobs = tensor([[-0.8799, -0.9491],
        [-1.0131, -0.9420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018686704570427537
Epoch 0, Step 832: train/loss = 0.6931107044219971, train/raw-loss = 0.6929918527603149, train/logprobs = tensor([[-0.9840, -1.0637],
        [-1.0427, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023757410235702991
Epoch 0, Step 833: train/loss = 0.7195658683776855, train/raw-loss = 0.7194454669952393, train/logprobs = tensor([[-1.2512, -1.0026],
        [-1.2940, -0.9346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024095507978927344
Epoch 0, Step 834: train/loss = 0.7051030993461609, train/raw-loss = 0.704970121383667, train/logprobs = tensor([[-1.0308, -0.9932],
        [-1.0522, -0.9669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002658022567629814
Epoch 0, Step 835: train/loss = 0.6928643584251404, train/raw-loss = 0.6928456425666809, train/logprobs = tensor([[-0.9790, -0.9897],
        [-1.0589, -0.9730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7458259612321854e-05
Epoch 0, Step 836: train/loss = 0.7025243639945984, train/raw-loss = 0.7021647691726685, train/logprobs = tensor([[-1.1170, -1.2089],
        [-1.2440, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007191435433924198
Epoch 0, Step 837: train/loss = 0.7225067019462585, train/raw-loss = 0.7200243473052979, train/logprobs = tensor([[-1.0195, -1.3188],
        [-1.2059, -1.2507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004964734427630901
Epoch 0, Step 838: train/loss = 0.7029147148132324, train/raw-loss = 0.7026103734970093, train/logprobs = tensor([[-1.1451, -1.3749],
        [-1.2142, -1.4285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006087732035666704
Epoch 0, Step 839: train/loss = 0.6915037035942078, train/raw-loss = 0.6911842823028564, train/logprobs = tensor([[-0.9484, -1.0346],
        [-1.1761, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006389078334905207
Epoch 0, Step 840: train/loss = 0.7205958962440491, train/raw-loss = 0.72000652551651, train/logprobs = tensor([[-1.1268, -1.0484],
        [-1.2645, -1.0444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001178859849460423
Epoch 0, Step 841: train/loss = 0.6949493288993835, train/raw-loss = 0.6943809986114502, train/logprobs = tensor([[-1.1978, -1.1433],
        [-1.2708, -1.1006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011365346144884825
Epoch 0, Step 842: train/loss = 0.7407719492912292, train/raw-loss = 0.7377728819847107, train/logprobs = tensor([[-0.9166, -1.1215],
        [-1.0717, -1.1022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005998268723487854
Epoch 0, Step 843: train/loss = 0.7139996290206909, train/raw-loss = 0.7138360142707825, train/logprobs = tensor([[-1.3891, -1.2264],
        [-1.4519, -1.1876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032735057175159454
Epoch 0, Step 844: train/loss = 0.7128257751464844, train/raw-loss = 0.7125629782676697, train/logprobs = tensor([[-1.1310, -1.0487],
        [-1.2111, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005254833959043026
Epoch 0, Step 845: train/loss = 0.6999818086624146, train/raw-loss = 0.6999543905258179, train/logprobs = tensor([[-1.0968, -1.2442],
        [-1.1845, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.472968041431159e-05
Epoch 0, Step 846: train/loss = 0.6947298049926758, train/raw-loss = 0.693970799446106, train/logprobs = tensor([[-0.6703, -0.7382],
        [-0.8445, -0.7278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015180844347923994
Epoch 0, Step 847: train/loss = 0.6955887079238892, train/raw-loss = 0.6950230598449707, train/logprobs = tensor([[-1.0493, -1.0053],
        [-1.0773, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011314860312268138
Epoch 0, Step 848: train/loss = 0.6950966119766235, train/raw-loss = 0.6950558423995972, train/logprobs = tensor([[-0.9219, -1.0118],
        [-0.8696, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.158772834576666e-05
Epoch 0, Step 849: train/loss = 0.699066162109375, train/raw-loss = 0.698563277721405, train/logprobs = tensor([[-1.0066, -0.9463],
        [-1.0815, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010057981126010418
Epoch 0, Step 850: train/loss = 0.6890695095062256, train/raw-loss = 0.6883331537246704, train/logprobs = tensor([[-0.9869, -1.1911],
        [-1.1131, -0.9668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014726757071912289
Epoch 0, Step 851: train/loss = 0.7059755325317383, train/raw-loss = 0.7059047818183899, train/logprobs = tensor([[-0.9666, -1.1079],
        [-1.0671, -1.0818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001414366124663502
Epoch 0, Step 852: train/loss = 0.6990547180175781, train/raw-loss = 0.6986246705055237, train/logprobs = tensor([[-1.1737, -1.0776],
        [-1.3774, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008602455491200089
Epoch 0, Step 853: train/loss = 0.6946449875831604, train/raw-loss = 0.6944173574447632, train/logprobs = tensor([[-1.0756, -1.2105],
        [-1.1408, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004552509053610265
Epoch 0, Step 854: train/loss = 0.71277916431427, train/raw-loss = 0.7126776576042175, train/logprobs = tensor([[-1.0533, -0.7356],
        [-1.1165, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020303254132159054
Epoch 0, Step 855: train/loss = 0.7030307054519653, train/raw-loss = 0.7027706503868103, train/logprobs = tensor([[-1.0307, -1.0196],
        [-1.2006, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005201441235840321
Epoch 0, Step 856: train/loss = 0.7138522267341614, train/raw-loss = 0.7134360671043396, train/logprobs = tensor([[-1.3179, -1.1286],
        [-1.4629, -1.1026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000832300225738436
Epoch 0, Step 857: train/loss = 0.692954957485199, train/raw-loss = 0.6928415894508362, train/logprobs = tensor([[-0.9118, -0.9490],
        [-0.9078, -0.8558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022666082077194005
Epoch 0, Step 858: train/loss = 0.6966391801834106, train/raw-loss = 0.6963170170783997, train/logprobs = tensor([[-0.8882, -1.0556],
        [-0.9613, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000644373765680939
Epoch 0, Step 859: train/loss = 0.7002969980239868, train/raw-loss = 0.6988869905471802, train/logprobs = tensor([[-1.1667, -1.0748],
        [-1.2150, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002819912973791361
Epoch 0, Step 860: train/loss = 0.6997809410095215, train/raw-loss = 0.6990938782691956, train/logprobs = tensor([[-1.1535, -1.0984],
        [-1.1981, -1.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013740045251324773
Epoch 0, Step 861: train/loss = 0.7049286365509033, train/raw-loss = 0.7046535015106201, train/logprobs = tensor([[-1.1151, -1.0408],
        [-1.1647, -0.9925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005502038402482867
Epoch 0, Step 862: train/loss = 0.7015398144721985, train/raw-loss = 0.7010207176208496, train/logprobs = tensor([[-1.3469, -1.3803],
        [-1.5686, -1.3765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010382074397057295
Epoch 0, Step 863: train/loss = 0.789925217628479, train/raw-loss = 0.7799277305603027, train/logprobs = tensor([[-1.2809, -1.3006],
        [-1.5078, -1.1304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01999494805932045
Epoch 0, Step 864: train/loss = 0.6701080203056335, train/raw-loss = 0.6695063710212708, train/logprobs = tensor([[-0.8950, -1.1731],
        [-1.5258, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012032759841531515
Epoch 0, Step 865: train/loss = 0.7131154537200928, train/raw-loss = 0.7124789953231812, train/logprobs = tensor([[-1.1648, -1.4648],
        [-1.3070, -1.5420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012728921137750149
Epoch 0, Step 866: train/loss = 0.6999399065971375, train/raw-loss = 0.6997894048690796, train/logprobs = tensor([[-0.9389, -0.8462],
        [-1.0049, -0.8222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030098145361989737
Epoch 0, Step 867: train/loss = 0.7002325057983398, train/raw-loss = 0.6999982595443726, train/logprobs = tensor([[-1.1777, -1.0759],
        [-1.2423, -0.9739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004685970488935709
Epoch 0, Step 868: train/loss = 0.6972213983535767, train/raw-loss = 0.696898341178894, train/logprobs = tensor([[-0.7320, -0.9187],
        [-0.7845, -0.8636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006461311131715775
Epoch 0, Step 869: train/loss = 0.6981034278869629, train/raw-loss = 0.6977574825286865, train/logprobs = tensor([[-1.1015, -1.1025],
        [-1.1346, -1.0424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006918276194483042
Epoch 0, Step 870: train/loss = 0.697500467300415, train/raw-loss = 0.6973073482513428, train/logprobs = tensor([[-1.1027, -1.2842],
        [-1.1078, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038626088644377887
Epoch 0, Step 871: train/loss = 0.6931204795837402, train/raw-loss = 0.6930971145629883, train/logprobs = tensor([[-1.0086, -1.1456],
        [-1.0260, -1.0279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.6605418901890516e-05
Epoch 0, Step 872: train/loss = 0.7009280920028687, train/raw-loss = 0.7009152173995972, train/logprobs = tensor([[-1.1312, -0.9865],
        [-1.1014, -0.9012]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5704881409183145e-05
Epoch 0, Step 873: train/loss = 0.7138208150863647, train/raw-loss = 0.7130997180938721, train/logprobs = tensor([[-1.0202, -1.0756],
        [-1.0604, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014421793166548014
Epoch 0, Step 874: train/loss = 0.7173060178756714, train/raw-loss = 0.7152639627456665, train/logprobs = tensor([[-1.2829, -0.9989],
        [-1.3534, -0.8814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040840888395905495
Epoch 0, Step 875: train/loss = 0.7130028009414673, train/raw-loss = 0.7123115062713623, train/logprobs = tensor([[-0.9015, -1.3137],
        [-1.0362, -1.2886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013825090136379004
Epoch 0, Step 876: train/loss = 0.6985552906990051, train/raw-loss = 0.6983466148376465, train/logprobs = tensor([[-1.1391, -1.2856],
        [-1.2060, -1.3167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041741965105757117
Epoch 0, Step 877: train/loss = 0.7181695699691772, train/raw-loss = 0.7164412140846252, train/logprobs = tensor([[-1.1655, -0.8811],
        [-1.2331, -0.7815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003456695470958948
Epoch 0, Step 878: train/loss = 0.6973345875740051, train/raw-loss = 0.6954831480979919, train/logprobs = tensor([[-0.9365, -0.9117],
        [-1.1179, -0.9059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037029320374131203
Epoch 0, Step 879: train/loss = 0.7112507820129395, train/raw-loss = 0.7112223505973816, train/logprobs = tensor([[-0.8164, -0.7940],
        [-0.8730, -0.7646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.683445488102734e-05
Epoch 0, Step 880: train/loss = 0.7058716416358948, train/raw-loss = 0.7045819163322449, train/logprobs = tensor([[-0.9394, -1.3116],
        [-1.2858, -1.2874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025794769171625376
Epoch 0, Step 881: train/loss = 0.7172385454177856, train/raw-loss = 0.7164078950881958, train/logprobs = tensor([[-1.1717, -0.9007],
        [-1.2462, -0.7926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016612776089459658
Epoch 0, Step 882: train/loss = 0.6942771673202515, train/raw-loss = 0.6936781406402588, train/logprobs = tensor([[-1.0521, -1.0945],
        [-1.1784, -1.0406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001197991892695427
Epoch 0, Step 883: train/loss = 0.713965892791748, train/raw-loss = 0.712254524230957, train/logprobs = tensor([[-1.2950, -1.1260],
        [-1.5570, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034227422438561916
Epoch 0, Step 884: train/loss = 0.6936442255973816, train/raw-loss = 0.6933543682098389, train/logprobs = tensor([[-0.8661, -0.8391],
        [-0.9625, -0.7988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005795969627797604
Epoch 0, Step 885: train/loss = 0.6983556151390076, train/raw-loss = 0.698098361492157, train/logprobs = tensor([[-1.1003, -1.0347],
        [-1.2401, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005143762100487947
Epoch 0, Step 886: train/loss = 0.7074011564254761, train/raw-loss = 0.7071848511695862, train/logprobs = tensor([[-1.0862, -0.8427],
        [-1.1380, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043263478437438607
Epoch 0, Step 887: train/loss = 0.6956096291542053, train/raw-loss = 0.6955490112304688, train/logprobs = tensor([[-1.1155, -1.0619],
        [-1.1347, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012127473019063473
Epoch 0, Step 888: train/loss = 0.6988776922225952, train/raw-loss = 0.6988284587860107, train/logprobs = tensor([[-1.1831, -1.0517],
        [-1.1543, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.851151844486594e-05
Epoch 0, Step 889: train/loss = 0.7164434194564819, train/raw-loss = 0.7155799865722656, train/logprobs = tensor([[-1.2190, -1.0990],
        [-1.2825, -1.0277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017268420197069645
Epoch 0, Step 890: train/loss = 0.69325852394104, train/raw-loss = 0.6932375431060791, train/logprobs = tensor([[-0.9619, -0.9738],
        [-0.9556, -0.9491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.1967519791796803e-05
Epoch 0, Step 891: train/loss = 0.6708837747573853, train/raw-loss = 0.6706756353378296, train/logprobs = tensor([[-0.9548, -1.2128],
        [-1.3366, -0.9847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004164256388321519
Epoch 0, Step 892: train/loss = 0.7005436420440674, train/raw-loss = 0.7005029320716858, train/logprobs = tensor([[-1.1076, -1.0568],
        [-1.1425, -1.0342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.130347123369575e-05
Epoch 0, Step 893: train/loss = 0.7041459679603577, train/raw-loss = 0.7040356397628784, train/logprobs = tensor([[-1.1669, -0.9214],
        [-1.2253, -0.9845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022073136642575264
Epoch 0, Step 894: train/loss = 0.7236102819442749, train/raw-loss = 0.7234697937965393, train/logprobs = tensor([[-1.2637, -0.9909],
        [-1.4159, -0.9372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028092763386666775
Epoch 0, Step 895: train/loss = 0.7208858728408813, train/raw-loss = 0.7207736372947693, train/logprobs = tensor([[-1.0845, -0.7723],
        [-1.2947, -0.8449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022438925225287676
Epoch 0, Step 896: train/loss = 0.6940430998802185, train/raw-loss = 0.6940139532089233, train/logprobs = tensor([[-0.9598, -1.0992],
        [-0.9633, -1.0034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.842969403602183e-05
Epoch 0, Step 897: train/loss = 0.7060825228691101, train/raw-loss = 0.7050110101699829, train/logprobs = tensor([[-1.1107, -0.9399],
        [-1.1683, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002143082208931446
Epoch 0, Step 898: train/loss = 0.6939800381660461, train/raw-loss = 0.6938247680664062, train/logprobs = tensor([[-0.9918, -0.9755],
        [-0.9981, -0.9660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031058985041454434
Epoch 0, Step 899: train/loss = 0.694073498249054, train/raw-loss = 0.6939932107925415, train/logprobs = tensor([[-0.9197, -0.9843],
        [-0.9039, -0.9250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016055151354521513
Epoch 0, Step 900: train/loss = 0.6958763599395752, train/raw-loss = 0.6957292556762695, train/logprobs = tensor([[-1.0668, -1.0267],
        [-1.1228, -1.0788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002942259015981108
Epoch 0, Step 901: train/loss = 0.7340348362922668, train/raw-loss = 0.7333912253379822, train/logprobs = tensor([[-0.8738, -1.4984],
        [-1.0302, -1.3116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012872033985331655
Epoch 0, Step 902: train/loss = 0.7575972080230713, train/raw-loss = 0.7554457187652588, train/logprobs = tensor([[-1.1434, -1.4815],
        [-1.1729, -1.2372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004303000867366791
Epoch 0, Step 903: train/loss = 0.7077857851982117, train/raw-loss = 0.7064197659492493, train/logprobs = tensor([[-0.9770, -1.2868],
        [-1.0844, -1.1428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002732016844674945
Epoch 0, Step 904: train/loss = 0.6963662505149841, train/raw-loss = 0.6962368488311768, train/logprobs = tensor([[-0.9430, -0.8404],
        [-0.9985, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002587485359981656
Epoch 0, Step 905: train/loss = 0.6972485780715942, train/raw-loss = 0.6957917213439941, train/logprobs = tensor([[-0.7401, -0.8930],
        [-0.8043, -0.8047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002913657808676362
Epoch 0, Step 906: train/loss = 0.7007152438163757, train/raw-loss = 0.6997817754745483, train/logprobs = tensor([[-1.2526, -1.0944],
        [-1.3424, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018668691627681255
Epoch 0, Step 907: train/loss = 0.697574257850647, train/raw-loss = 0.6971854567527771, train/logprobs = tensor([[-1.0732, -1.0070],
        [-1.1626, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007774823461659253
Epoch 0, Step 908: train/loss = 0.6958028078079224, train/raw-loss = 0.6955478191375732, train/logprobs = tensor([[-1.2873, -1.2380],
        [-1.4217, -1.3191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005100193666294217
Epoch 0, Step 909: train/loss = 0.6991968154907227, train/raw-loss = 0.6988916397094727, train/logprobs = tensor([[-1.1068, -0.9827],
        [-1.1742, -0.9072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006103985360823572
Epoch 0, Step 910: train/loss = 0.7037702202796936, train/raw-loss = 0.7021505236625671, train/logprobs = tensor([[-1.1622, -0.9801],
        [-1.2491, -0.7591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032394411973655224
Epoch 0, Step 911: train/loss = 0.7045308947563171, train/raw-loss = 0.7037928700447083, train/logprobs = tensor([[-0.9667, -1.1596],
        [-0.9866, -1.0911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014759621117264032
Epoch 0, Step 912: train/loss = 0.7024723887443542, train/raw-loss = 0.702203631401062, train/logprobs = tensor([[-1.0055, -1.1818],
        [-1.0779, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005374465836212039
Epoch 0, Step 913: train/loss = 0.7016757130622864, train/raw-loss = 0.7011765241622925, train/logprobs = tensor([[-0.9344, -1.2503],
        [-1.0283, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000998400617390871
Epoch 0, Step 914: train/loss = 0.6967113018035889, train/raw-loss = 0.6963149309158325, train/logprobs = tensor([[-1.0458, -0.9599],
        [-1.1333, -1.0057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007928409613668919
Epoch 0, Step 915: train/loss = 0.7118213176727295, train/raw-loss = 0.711322546005249, train/logprobs = tensor([[-1.0223, -1.1827],
        [-1.0350, -0.9846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009976746514439583
Epoch 0, Step 916: train/loss = 0.7520887851715088, train/raw-loss = 0.7498148679733276, train/logprobs = tensor([[-1.0612, -1.6704],
        [-1.0889, -1.3366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045477342791855335
Epoch 0, Step 917: train/loss = 0.6991612911224365, train/raw-loss = 0.6991044282913208, train/logprobs = tensor([[-1.1057, -1.0593],
        [-1.1386, -1.0538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011371239088475704
Epoch 0, Step 918: train/loss = 0.7287538051605225, train/raw-loss = 0.7274191975593567, train/logprobs = tensor([[-0.9535, -1.3461],
        [-1.0697, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026690971571952105
Epoch 0, Step 919: train/loss = 0.70374596118927, train/raw-loss = 0.7028635740280151, train/logprobs = tensor([[-1.3004, -1.1869],
        [-1.4375, -1.0985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017647906206548214
Epoch 0, Step 920: train/loss = 0.7016379237174988, train/raw-loss = 0.7000043392181396, train/logprobs = tensor([[-0.9726, -1.1362],
        [-1.0830, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003267271677032113
Epoch 0, Step 921: train/loss = 0.7062079906463623, train/raw-loss = 0.7061119079589844, train/logprobs = tensor([[-0.8506, -1.0848],
        [-0.9684, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019215128850191832
Epoch 0, Step 922: train/loss = 0.6940689086914062, train/raw-loss = 0.6936933994293213, train/logprobs = tensor([[-1.0760, -1.1410],
        [-1.1408, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007510849973186851
Epoch 0, Step 923: train/loss = 0.7018963694572449, train/raw-loss = 0.7006039619445801, train/logprobs = tensor([[-1.1186, -1.1072],
        [-1.2574, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002584929810836911
Epoch 0, Step 924: train/loss = 0.7136726379394531, train/raw-loss = 0.7084880471229553, train/logprobs = tensor([[-1.0000, -1.3655],
        [-1.2060, -1.1233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010369248688220978
Epoch 0, Step 925: train/loss = 0.7104894518852234, train/raw-loss = 0.7095766067504883, train/logprobs = tensor([[-0.9592, -1.3421],
        [-1.0896, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018257531337440014
Epoch 0, Step 926: train/loss = 0.7088082432746887, train/raw-loss = 0.7086274027824402, train/logprobs = tensor([[-1.0906, -1.3127],
        [-1.0899, -1.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036173220723867416
Epoch 0, Step 927: train/loss = 0.729594349861145, train/raw-loss = 0.7288248538970947, train/logprobs = tensor([[-1.2053, -1.0423],
        [-1.3592, -1.0487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001539067248813808
Epoch 0, Step 928: train/loss = 0.7038553953170776, train/raw-loss = 0.7034701108932495, train/logprobs = tensor([[-1.0973, -0.9847],
        [-1.1723, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007704879972152412
Epoch 0, Step 929: train/loss = 0.6967136263847351, train/raw-loss = 0.6965219378471375, train/logprobs = tensor([[-0.9908, -0.8989],
        [-1.0778, -0.8918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003833097289316356
Epoch 0, Step 930: train/loss = 0.7183334827423096, train/raw-loss = 0.7181520462036133, train/logprobs = tensor([[-0.9224, -1.1646],
        [-0.9396, -1.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036280485801398754
Epoch 0, Step 931: train/loss = 0.692552924156189, train/raw-loss = 0.6919636130332947, train/logprobs = tensor([[-1.0724, -1.2122],
        [-1.1328, -0.9834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001178539008833468
Epoch 0, Step 932: train/loss = 0.7081494927406311, train/raw-loss = 0.7079074382781982, train/logprobs = tensor([[-1.4451, -1.2257],
        [-1.5643, -1.1901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004841818299610168
Epoch 0, Step 933: train/loss = 0.7009689807891846, train/raw-loss = 0.7009235620498657, train/logprobs = tensor([[-1.2000, -1.2793],
        [-1.2174, -1.2515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.093634434975684e-05
Epoch 0, Step 934: train/loss = 0.7052730321884155, train/raw-loss = 0.7051275968551636, train/logprobs = tensor([[-1.1412, -1.2480],
        [-1.1389, -1.2225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029081961838528514
Epoch 0, Step 935: train/loss = 0.7029035091400146, train/raw-loss = 0.6996587514877319, train/logprobs = tensor([[-0.9477, -1.2553],
        [-1.0005, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006489453837275505
Epoch 0, Step 936: train/loss = 0.6984402537345886, train/raw-loss = 0.6973018646240234, train/logprobs = tensor([[-1.1536, -1.1983],
        [-1.2880, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002276830840855837
Epoch 0, Step 937: train/loss = 0.7071189880371094, train/raw-loss = 0.7068232297897339, train/logprobs = tensor([[-1.0650, -0.9298],
        [-1.1013, -0.8079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005915237125009298
Epoch 0, Step 938: train/loss = 0.707891583442688, train/raw-loss = 0.7073138952255249, train/logprobs = tensor([[-1.3564, -1.1603],
        [-1.4485, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011553856311365962
Epoch 0, Step 939: train/loss = 0.6977120637893677, train/raw-loss = 0.6970503926277161, train/logprobs = tensor([[-0.8773, -0.8919],
        [-0.9119, -0.7731]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013232612982392311
Epoch 0, Step 940: train/loss = 0.730890154838562, train/raw-loss = 0.7281534671783447, train/logprobs = tensor([[-0.9594, -1.2820],
        [-1.0496, -1.0826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005473463796079159
Epoch 0, Step 941: train/loss = 0.6958900094032288, train/raw-loss = 0.6958703994750977, train/logprobs = tensor([[-1.1956, -1.2468],
        [-1.2926, -1.1999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.927788930013776e-05
Epoch 0, Step 942: train/loss = 0.7029500007629395, train/raw-loss = 0.702889084815979, train/logprobs = tensor([[-0.9731, -1.0860],
        [-0.9922, -1.0467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012169123510830104
Epoch 0, Step 943: train/loss = 0.7382293939590454, train/raw-loss = 0.7381593585014343, train/logprobs = tensor([[-1.3433, -0.9471],
        [-1.3847, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014005777484271675
Epoch 0, Step 944: train/loss = 0.7108137607574463, train/raw-loss = 0.7107188105583191, train/logprobs = tensor([[-1.1974, -0.9299],
        [-1.2121, -0.8722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018974393606185913
Epoch 0, Step 945: train/loss = 0.7098349928855896, train/raw-loss = 0.7096263766288757, train/logprobs = tensor([[-1.0246, -0.9582],
        [-1.0667, -0.8596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004173081833869219
Epoch 0, Step 946: train/loss = 0.697281002998352, train/raw-loss = 0.6968739032745361, train/logprobs = tensor([[-1.0047, -0.9765],
        [-1.0711, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008142206352204084
Epoch 0, Step 947: train/loss = 0.6934104561805725, train/raw-loss = 0.6932973861694336, train/logprobs = tensor([[-1.0394, -1.0970],
        [-1.0242, -1.0261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002260525361634791
Epoch 0, Step 948: train/loss = 0.6959366202354431, train/raw-loss = 0.695878267288208, train/logprobs = tensor([[-1.0919, -1.0256],
        [-1.0837, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011669582454487681
Epoch 0, Step 949: train/loss = 0.6958174109458923, train/raw-loss = 0.6957372426986694, train/logprobs = tensor([[-0.9874, -1.0598],
        [-0.9989, -0.9589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016025679360609502
Epoch 0, Step 950: train/loss = 0.6947343349456787, train/raw-loss = 0.694631814956665, train/logprobs = tensor([[-1.1608, -1.1397],
        [-1.1636, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020513088384177536
Epoch 0, Step 951: train/loss = 0.709470272064209, train/raw-loss = 0.7093683481216431, train/logprobs = tensor([[-1.1585, -0.8223],
        [-1.1418, -0.7855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020382938964758068
Epoch 0, Step 952: train/loss = 0.6987342834472656, train/raw-loss = 0.6982871294021606, train/logprobs = tensor([[-0.8657, -0.9467],
        [-0.9035, -0.9451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000894275726750493
Epoch 0, Step 953: train/loss = 0.7008874416351318, train/raw-loss = 0.6998152732849121, train/logprobs = tensor([[-1.1304, -1.1247],
        [-1.2510, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002144398633390665
Epoch 0, Step 954: train/loss = 0.6928858757019043, train/raw-loss = 0.6910725235939026, train/logprobs = tensor([[-1.2807, -1.4553],
        [-1.4232, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003626780118793249
Epoch 0, Step 955: train/loss = 0.687877893447876, train/raw-loss = 0.6871762275695801, train/logprobs = tensor([[-0.9464, -1.1962],
        [-1.1837, -0.9789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00140336062759161
Epoch 0, Step 956: train/loss = 0.6994049549102783, train/raw-loss = 0.6987948417663574, train/logprobs = tensor([[-1.1910, -1.2169],
        [-1.2146, -1.1053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012203642399981618
Epoch 0, Step 957: train/loss = 0.7156797647476196, train/raw-loss = 0.7152348756790161, train/logprobs = tensor([[-0.8791, -1.0784],
        [-0.8731, -0.9542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008898569503799081
Epoch 0, Step 958: train/loss = 0.7199939489364624, train/raw-loss = 0.719786524772644, train/logprobs = tensor([[-0.9926, -1.4565],
        [-0.9871, -1.3385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004148208536207676
Epoch 0, Step 959: train/loss = 0.749237596988678, train/raw-loss = 0.7476363182067871, train/logprobs = tensor([[-1.1319, -1.6739],
        [-1.1985, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032024472020566463
Epoch 0, Step 960: train/loss = 0.7004925012588501, train/raw-loss = 0.7000271081924438, train/logprobs = tensor([[-1.0997, -1.3238],
        [-1.2480, -1.2828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009308495791628957
Epoch 0, Step 961: train/loss = 0.6950459480285645, train/raw-loss = 0.6949461698532104, train/logprobs = tensor([[-1.1430, -1.2027],
        [-1.2621, -1.2162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019932776922360063
Epoch 0, Step 962: train/loss = 0.6967832446098328, train/raw-loss = 0.6966403722763062, train/logprobs = tensor([[-1.0731, -1.0712],
        [-1.1336, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000285751826595515
Epoch 0, Step 963: train/loss = 0.6980069875717163, train/raw-loss = 0.696082353591919, train/logprobs = tensor([[-1.0265, -1.3163],
        [-1.0810, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003849357832223177
Epoch 0, Step 964: train/loss = 0.6983460187911987, train/raw-loss = 0.6979267597198486, train/logprobs = tensor([[-1.0169, -1.1563],
        [-1.1018, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008385251276195049
Epoch 0, Step 965: train/loss = 0.6988064050674438, train/raw-loss = 0.6984835863113403, train/logprobs = tensor([[-1.2060, -1.0686],
        [-1.2782, -1.0453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006457783165387809
Epoch 0, Step 966: train/loss = 0.6961936354637146, train/raw-loss = 0.6946960687637329, train/logprobs = tensor([[-1.1482, -1.1476],
        [-1.2326, -1.0130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002995187183842063
Epoch 0, Step 967: train/loss = 0.7039415836334229, train/raw-loss = 0.7036699056625366, train/logprobs = tensor([[-1.1763, -1.0496],
        [-1.3555, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005433266051113605
Epoch 0, Step 968: train/loss = 0.7014101147651672, train/raw-loss = 0.7009809017181396, train/logprobs = tensor([[-1.1119, -1.0664],
        [-1.0635, -0.9797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008583455346524715
Epoch 0, Step 969: train/loss = 0.6931185722351074, train/raw-loss = 0.691778302192688, train/logprobs = tensor([[-1.0630, -1.1419],
        [-1.0898, -1.0218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026806050445884466
Epoch 0, Step 970: train/loss = 0.6976072788238525, train/raw-loss = 0.6972267627716064, train/logprobs = tensor([[-0.8657, -0.9324],
        [-0.9300, -0.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007611056207679212
Epoch 0, Step 971: train/loss = 0.6966502666473389, train/raw-loss = 0.6963363289833069, train/logprobs = tensor([[-1.0190, -1.2662],
        [-1.1274, -1.1341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006278736982494593
Epoch 0, Step 972: train/loss = 0.695673942565918, train/raw-loss = 0.6954095959663391, train/logprobs = tensor([[-1.0276, -1.1275],
        [-1.0816, -0.9874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005287443054839969
Epoch 0, Step 973: train/loss = 0.695210874080658, train/raw-loss = 0.6926670074462891, train/logprobs = tensor([[-1.0893, -1.1811],
        [-1.4370, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005087689496576786
Epoch 0, Step 974: train/loss = 0.6969435214996338, train/raw-loss = 0.6963802576065063, train/logprobs = tensor([[-0.9583, -1.0832],
        [-0.9565, -1.1087]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011264779604971409
Epoch 0, Step 975: train/loss = 0.697877049446106, train/raw-loss = 0.6976649165153503, train/logprobs = tensor([[-1.0893, -1.0265],
        [-1.3240, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004241011629346758
Epoch 0, Step 976: train/loss = 0.6968319416046143, train/raw-loss = 0.6965528726577759, train/logprobs = tensor([[-1.0410, -0.9476],
        [-0.9994, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005581039004027843
Epoch 0, Step 977: train/loss = 0.7005586624145508, train/raw-loss = 0.6995022296905518, train/logprobs = tensor([[-0.9578, -0.7966],
        [-1.2317, -0.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002112884074449539
Epoch 0, Step 978: train/loss = 0.7016955018043518, train/raw-loss = 0.7011587023735046, train/logprobs = tensor([[-1.0391, -1.1885],
        [-1.1324, -1.0549]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001073487801477313
Epoch 0, Step 979: train/loss = 0.7052425146102905, train/raw-loss = 0.7049175500869751, train/logprobs = tensor([[-1.1458, -1.2155],
        [-1.1956, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006498359143733978
Epoch 0, Step 980: train/loss = 0.6949328780174255, train/raw-loss = 0.6947770118713379, train/logprobs = tensor([[-1.0986, -1.0727],
        [-1.1238, -1.0774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031168415443971753
Epoch 0, Step 981: train/loss = 0.7062168717384338, train/raw-loss = 0.7060619592666626, train/logprobs = tensor([[-1.0208, -1.1396],
        [-1.0866, -1.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030976871494203806
Epoch 0, Step 982: train/loss = 0.7083532810211182, train/raw-loss = 0.7078719735145569, train/logprobs = tensor([[-0.9827, -1.1308],
        [-1.0087, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009627036051824689
Epoch 0, Step 983: train/loss = 0.708404541015625, train/raw-loss = 0.7075808048248291, train/logprobs = tensor([[-0.9652, -0.9429],
        [-0.9517, -0.8050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001647453522309661
Epoch 0, Step 984: train/loss = 0.7757760286331177, train/raw-loss = 0.7749847173690796, train/logprobs = tensor([[-0.8382, -1.4198],
        [-0.9348, -1.4263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015827016904950142
Epoch 0, Step 985: train/loss = 0.7033517360687256, train/raw-loss = 0.7004836797714233, train/logprobs = tensor([[-0.9177, -1.2731],
        [-1.0032, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005736030638217926
Epoch 0, Step 986: train/loss = 0.714881420135498, train/raw-loss = 0.7102848291397095, train/logprobs = tensor([[-0.9879, -1.0616],
        [-1.0568, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009193062782287598
Epoch 0, Step 987: train/loss = 0.6999509334564209, train/raw-loss = 0.699826717376709, train/logprobs = tensor([[-1.1284, -0.9810],
        [-1.1175, -0.9530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002484726719558239
Epoch 0, Step 988: train/loss = 0.6927546262741089, train/raw-loss = 0.6882034540176392, train/logprobs = tensor([[-1.0097, -1.1402],
        [-1.0466, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009102368727326393
Epoch 0, Step 989: train/loss = 0.69569993019104, train/raw-loss = 0.6949396729469299, train/logprobs = tensor([[-1.1332, -1.1216],
        [-1.1823, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001520595047622919
Epoch 0, Step 990: train/loss = 0.7482296824455261, train/raw-loss = 0.746834397315979, train/logprobs = tensor([[-1.1811, -1.3796],
        [-1.2647, -1.3811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027904589660465717
Epoch 0, Step 991: train/loss = 0.7049948573112488, train/raw-loss = 0.7046195864677429, train/logprobs = tensor([[-0.9769, -1.1956],
        [-1.0467, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007506059482693672
Epoch 0, Step 992: train/loss = 0.6948369741439819, train/raw-loss = 0.694533109664917, train/logprobs = tensor([[-0.9669, -0.9484],
        [-1.0715, -0.9755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006077776779420674
Epoch 0, Step 993: train/loss = 0.7116564512252808, train/raw-loss = 0.7105733156204224, train/logprobs = tensor([[-1.1069, -0.9843],
        [-1.1680, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021661731880158186
Epoch 0, Step 994: train/loss = 0.7030510306358337, train/raw-loss = 0.7007566690444946, train/logprobs = tensor([[-1.0068, -1.1569],
        [-1.0011, -0.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004588856361806393
Epoch 0, Step 995: train/loss = 0.7032829523086548, train/raw-loss = 0.7010260224342346, train/logprobs = tensor([[-0.8235, -1.2357],
        [-0.9153, -1.0337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045137545093894005
Epoch 0, Step 996: train/loss = 0.6970282793045044, train/raw-loss = 0.6947377324104309, train/logprobs = tensor([[-0.9921, -1.2506],
        [-1.0973, -1.0883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004581190180033445
Epoch 0, Step 997: train/loss = 0.6950193643569946, train/raw-loss = 0.6946556568145752, train/logprobs = tensor([[-0.9092, -0.8763],
        [-0.9498, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007273252122104168
Epoch 0, Step 998: train/loss = 0.7128878831863403, train/raw-loss = 0.7119397521018982, train/logprobs = tensor([[-1.1996, -0.9589],
        [-1.2254, -0.8505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018962824251502752
Epoch 0, Step 999: train/loss = 0.6954923868179321, train/raw-loss = 0.6935476064682007, train/logprobs = tensor([[-0.7583, -0.8773],
        [-0.8834, -0.7300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038895029574632645
eval/loss: 0.7028725743293762
Epoch 0, Step 1000: train/loss = 0.7481091618537903, train/raw-loss = 0.7476166486740112, train/logprobs = tensor([[-1.0947, -0.7640],
        [-1.1733, -0.6873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009848496410995722
Epoch 0, Step 1001: train/loss = 0.6940296292304993, train/raw-loss = 0.6927680373191833, train/logprobs = tensor([[-0.9189, -1.1255],
        [-0.9846, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002523230155929923
Epoch 0, Step 1002: train/loss = 0.7747694253921509, train/raw-loss = 0.768730640411377, train/logprobs = tensor([[-0.8084, -1.2890],
        [-0.9107, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012077616527676582
Epoch 0, Step 1003: train/loss = 0.6933526396751404, train/raw-loss = 0.6929489374160767, train/logprobs = tensor([[-1.0495, -1.0785],
        [-1.1416, -1.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008074974175542593
Epoch 0, Step 1004: train/loss = 0.6968967914581299, train/raw-loss = 0.6968199014663696, train/logprobs = tensor([[-1.0831, -0.9951],
        [-1.0977, -1.0077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015367039304692298
Epoch 0, Step 1005: train/loss = 0.6981106996536255, train/raw-loss = 0.698016881942749, train/logprobs = tensor([[-1.0049, -1.1047],
        [-1.0030, -0.9770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018761990941129625
Epoch 0, Step 1006: train/loss = 0.6953967809677124, train/raw-loss = 0.6953557729721069, train/logprobs = tensor([[-1.0297, -1.1350],
        [-1.1435, -1.1908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.218400762416422e-05
Epoch 0, Step 1007: train/loss = 0.6944637894630432, train/raw-loss = 0.6940904259681702, train/logprobs = tensor([[-1.0125, -1.1873],
        [-1.0451, -0.9699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007468331605195999
Epoch 0, Step 1008: train/loss = 0.7035222053527832, train/raw-loss = 0.70328688621521, train/logprobs = tensor([[-1.2260, -1.0779],
        [-1.3796, -1.0908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004706734325736761
Epoch 0, Step 1009: train/loss = 0.6976853609085083, train/raw-loss = 0.6952997446060181, train/logprobs = tensor([[-1.0652, -1.2145],
        [-1.1056, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004771430045366287
Epoch 0, Step 1010: train/loss = 0.6927671432495117, train/raw-loss = 0.6927224397659302, train/logprobs = tensor([[-0.9239, -0.9455],
        [-0.8559, -0.8092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.939241524785757e-05
Epoch 0, Step 1011: train/loss = 0.6954745054244995, train/raw-loss = 0.6942126750946045, train/logprobs = tensor([[-0.9490, -1.1531],
        [-1.0099, -1.0242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025236885994672775
Epoch 0, Step 1012: train/loss = 0.6931331157684326, train/raw-loss = 0.6928226947784424, train/logprobs = tensor([[-1.0488, -1.1509],
        [-1.0803, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006207785336300731
Epoch 0, Step 1013: train/loss = 0.7059198021888733, train/raw-loss = 0.7049195766448975, train/logprobs = tensor([[-1.1350, -1.2276],
        [-1.1656, -1.0834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020005377009510994
Epoch 0, Step 1014: train/loss = 0.710026741027832, train/raw-loss = 0.7074784636497498, train/logprobs = tensor([[-1.1685, -0.8828],
        [-1.2325, -0.8156]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0050964271649718285
Epoch 0, Step 1015: train/loss = 0.6926289796829224, train/raw-loss = 0.6897473931312561, train/logprobs = tensor([[-1.0606, -1.2546],
        [-1.1152, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005763224791735411
Epoch 0, Step 1016: train/loss = 0.7019938826560974, train/raw-loss = 0.7009251117706299, train/logprobs = tensor([[-1.1047, -1.1735],
        [-1.2183, -1.3626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021375424694269896
Epoch 0, Step 1017: train/loss = 0.7874308824539185, train/raw-loss = 0.7871831655502319, train/logprobs = tensor([[-0.9104, -1.3905],
        [-1.0610, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004953697789460421
Epoch 0, Step 1018: train/loss = 0.693873405456543, train/raw-loss = 0.6928454041481018, train/logprobs = tensor([[-1.2378, -1.2162],
        [-1.2382, -1.0839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020560480188578367
Epoch 0, Step 1019: train/loss = 0.6946173906326294, train/raw-loss = 0.6936914920806885, train/logprobs = tensor([[-1.0772, -1.2825],
        [-1.1721, -1.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018516058335080743
Epoch 0, Step 1020: train/loss = 0.6939197778701782, train/raw-loss = 0.6935865879058838, train/logprobs = tensor([[-1.0773, -1.0913],
        [-1.1242, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006664299871772528
Epoch 0, Step 1021: train/loss = 0.7070736885070801, train/raw-loss = 0.7057961821556091, train/logprobs = tensor([[-0.9333, -1.1492],
        [-1.0440, -1.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025550033897161484
Epoch 0, Step 1022: train/loss = 0.6946693062782288, train/raw-loss = 0.6943329572677612, train/logprobs = tensor([[-0.8594, -0.9667],
        [-0.9289, -0.7774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006726522697135806
Epoch 0, Step 1023: train/loss = 0.6992892026901245, train/raw-loss = 0.6985945701599121, train/logprobs = tensor([[-0.8912, -0.9557],
        [-0.9458, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013891708804294467
Epoch 0, Step 1024: train/loss = 0.7036954164505005, train/raw-loss = 0.7033894658088684, train/logprobs = tensor([[-0.9745, -0.9535],
        [-1.0347, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006119519239291549
Epoch 0, Step 1025: train/loss = 0.695604681968689, train/raw-loss = 0.6948542594909668, train/logprobs = tensor([[-0.9651, -1.0345],
        [-1.0258, -0.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001500966725870967
Epoch 0, Step 1026: train/loss = 0.6950196027755737, train/raw-loss = 0.6943345665931702, train/logprobs = tensor([[-0.9884, -1.0669],
        [-1.0816, -0.9827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001370083773508668
Epoch 0, Step 1027: train/loss = 0.6993530988693237, train/raw-loss = 0.6976813077926636, train/logprobs = tensor([[-1.2477, -1.3139],
        [-1.3082, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033435013610869646
Epoch 0, Step 1028: train/loss = 0.7100082635879517, train/raw-loss = 0.7079270482063293, train/logprobs = tensor([[-1.1406, -1.1895],
        [-1.1935, -0.9821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004162530414760113
Epoch 0, Step 1029: train/loss = 0.6960939168930054, train/raw-loss = 0.6960229277610779, train/logprobs = tensor([[-0.8893, -0.7679],
        [-0.9033, -0.7723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014194677351042628
Epoch 0, Step 1030: train/loss = 0.7135350108146667, train/raw-loss = 0.7106589674949646, train/logprobs = tensor([[-1.0566, -1.5205],
        [-1.1344, -1.3001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005751993972808123
Epoch 0, Step 1031: train/loss = 0.7427780032157898, train/raw-loss = 0.741218090057373, train/logprobs = tensor([[-1.1701, -1.2942],
        [-1.2004, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003119740169495344
Epoch 0, Step 1032: train/loss = 0.6981066465377808, train/raw-loss = 0.6979566216468811, train/logprobs = tensor([[-1.0479, -1.1661],
        [-1.0811, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029992868076078594
Epoch 0, Step 1033: train/loss = 0.7077805995941162, train/raw-loss = 0.7072896957397461, train/logprobs = tensor([[-1.0867, -0.8496],
        [-1.2223, -0.8041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009816274978220463
Epoch 0, Step 1034: train/loss = 0.7237979173660278, train/raw-loss = 0.723512589931488, train/logprobs = tensor([[-0.9870, -1.2431],
        [-0.9548, -1.0895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005705741932615638
Epoch 0, Step 1035: train/loss = 0.7000108957290649, train/raw-loss = 0.6976895332336426, train/logprobs = tensor([[-1.2510, -1.4937],
        [-1.3759, -1.1788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004642678424715996
Epoch 0, Step 1036: train/loss = 0.6937604546546936, train/raw-loss = 0.6933361887931824, train/logprobs = tensor([[-1.0651, -1.0742],
        [-1.0745, -0.9373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008484858553856611
Epoch 0, Step 1037: train/loss = 0.7800219058990479, train/raw-loss = 0.7791332006454468, train/logprobs = tensor([[-0.9026, -1.5715],
        [-0.9588, -1.4154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017773935105651617
Epoch 0, Step 1038: train/loss = 0.7474194765090942, train/raw-loss = 0.7450151443481445, train/logprobs = tensor([[-1.2494, -0.9069],
        [-1.2341, -0.7262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004808665253221989
Epoch 0, Step 1039: train/loss = 0.6945579648017883, train/raw-loss = 0.6944876313209534, train/logprobs = tensor([[-1.1687, -1.1770],
        [-1.1011, -1.0115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001406623050570488
Epoch 0, Step 1040: train/loss = 0.6981521844863892, train/raw-loss = 0.6978875398635864, train/logprobs = tensor([[-1.1109, -1.0848],
        [-1.0393, -0.9619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005293205613270402
Epoch 0, Step 1041: train/loss = 0.6952049732208252, train/raw-loss = 0.6946812868118286, train/logprobs = tensor([[-0.8942, -1.0383],
        [-0.9831, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001047439407557249
Epoch 0, Step 1042: train/loss = 0.6935296058654785, train/raw-loss = 0.693520724773407, train/logprobs = tensor([[-1.0470, -1.0222],
        [-0.9653, -0.9385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.773086842149496e-05
Epoch 0, Step 1043: train/loss = 0.6955353617668152, train/raw-loss = 0.6947959661483765, train/logprobs = tensor([[-1.1625, -1.1172],
        [-1.2010, -0.9418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014787479303777218
Epoch 0, Step 1044: train/loss = 0.7048584818840027, train/raw-loss = 0.7014743089675903, train/logprobs = tensor([[-1.1744, -1.1518],
        [-1.2897, -0.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006768504157662392
Epoch 0, Step 1045: train/loss = 0.6969457864761353, train/raw-loss = 0.6951426267623901, train/logprobs = tensor([[-1.0119, -1.3549],
        [-1.0837, -1.1163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036064814776182175
Epoch 0, Step 1046: train/loss = 0.7030471563339233, train/raw-loss = 0.7029255628585815, train/logprobs = tensor([[-1.0780, -0.9357],
        [-1.1120, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024323081015609205
Epoch 0, Step 1047: train/loss = 0.6973557472229004, train/raw-loss = 0.6970834732055664, train/logprobs = tensor([[-0.9870, -0.9091],
        [-1.0051, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005445129936560988
Epoch 0, Step 1048: train/loss = 0.7032310962677002, train/raw-loss = 0.7016564607620239, train/logprobs = tensor([[-1.0597, -1.3207],
        [-1.0992, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031492593698203564
Epoch 0, Step 1049: train/loss = 0.7067580819129944, train/raw-loss = 0.7052842378616333, train/logprobs = tensor([[-0.7888, -1.1228],
        [-0.8479, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029477307107299566
Epoch 0, Step 1050: train/loss = 0.6921325922012329, train/raw-loss = 0.6851121783256531, train/logprobs = tensor([[-1.1716, -1.3462],
        [-1.4659, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014040809124708176
Epoch 0, Step 1051: train/loss = 0.7044373154640198, train/raw-loss = 0.7039687037467957, train/logprobs = tensor([[-0.9293, -0.8468],
        [-0.9697, -0.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009372546337544918
Epoch 0, Step 1052: train/loss = 0.6989882588386536, train/raw-loss = 0.6976020336151123, train/logprobs = tensor([[-0.9862, -1.0150],
        [-1.0905, -0.9989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027723638340830803
Epoch 0, Step 1053: train/loss = 0.7050637006759644, train/raw-loss = 0.704311728477478, train/logprobs = tensor([[-0.8350, -1.0415],
        [-0.8146, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015040399739518762
Epoch 0, Step 1054: train/loss = 0.6945522427558899, train/raw-loss = 0.6934946179389954, train/logprobs = tensor([[-0.9727, -0.9514],
        [-1.0377, -0.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002115092473104596
Epoch 0, Step 1055: train/loss = 0.6946735382080078, train/raw-loss = 0.6930556297302246, train/logprobs = tensor([[-0.9911, -1.0205],
        [-1.0613, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003235823707655072
Epoch 0, Step 1056: train/loss = 0.6958685517311096, train/raw-loss = 0.6938652396202087, train/logprobs = tensor([[-1.0532, -1.1468],
        [-1.1006, -1.0857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004006624221801758
Epoch 0, Step 1057: train/loss = 0.6950086355209351, train/raw-loss = 0.694449245929718, train/logprobs = tensor([[-1.1713, -1.2345],
        [-1.2510, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011189038632437587
Epoch 0, Step 1058: train/loss = 0.712691068649292, train/raw-loss = 0.7125053405761719, train/logprobs = tensor([[-0.8385, -0.7572],
        [-0.8312, -0.6642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037160381907597184
Epoch 0, Step 1059: train/loss = 0.6971884369850159, train/raw-loss = 0.695942759513855, train/logprobs = tensor([[-1.0017, -1.1504],
        [-1.0266, -0.9003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002491248771548271
Epoch 0, Step 1060: train/loss = 0.6993637084960938, train/raw-loss = 0.6953235864639282, train/logprobs = tensor([[-1.0394, -1.3310],
        [-1.1223, -1.0733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008080335333943367
Epoch 0, Step 1061: train/loss = 0.7071122527122498, train/raw-loss = 0.7056467533111572, train/logprobs = tensor([[-1.0105, -1.1200],
        [-1.0726, -1.1319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029309773817658424
Epoch 0, Step 1062: train/loss = 0.6945866346359253, train/raw-loss = 0.694313645362854, train/logprobs = tensor([[-0.9590, -1.0682],
        [-0.9886, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005458495579659939
Epoch 0, Step 1063: train/loss = 0.7018619775772095, train/raw-loss = 0.699345588684082, train/logprobs = tensor([[-0.8811, -0.9049],
        [-1.0026, -0.8238]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005032776389271021
Epoch 0, Step 1064: train/loss = 0.6989243626594543, train/raw-loss = 0.6964129209518433, train/logprobs = tensor([[-1.1219, -1.1698],
        [-1.2022, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005022770259529352
Epoch 0, Step 1065: train/loss = 0.6958826780319214, train/raw-loss = 0.6953272819519043, train/logprobs = tensor([[-1.0067, -0.9299],
        [-1.2246, -0.8827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011108082253485918
Epoch 0, Step 1066: train/loss = 0.7192238569259644, train/raw-loss = 0.7190427780151367, train/logprobs = tensor([[-0.8844, -0.8667],
        [-0.9223, -0.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036216905573382974
Epoch 0, Step 1067: train/loss = 0.7303778529167175, train/raw-loss = 0.7302373051643372, train/logprobs = tensor([[-1.1048, -1.3809],
        [-1.1841, -1.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002810449223034084
Epoch 0, Step 1068: train/loss = 0.6935684680938721, train/raw-loss = 0.6934131383895874, train/logprobs = tensor([[-1.2121, -1.2421],
        [-1.1715, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031080201733857393
Epoch 0, Step 1069: train/loss = 0.700713038444519, train/raw-loss = 0.700642466545105, train/logprobs = tensor([[-0.9767, -1.0551],
        [-1.1052, -1.0558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001412181300111115
Epoch 0, Step 1070: train/loss = 0.6951603889465332, train/raw-loss = 0.6941074728965759, train/logprobs = tensor([[-0.8219, -0.8240],
        [-0.9795, -0.7349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00210584350861609
Epoch 0, Step 1071: train/loss = 0.6947170495986938, train/raw-loss = 0.6946437954902649, train/logprobs = tensor([[-1.0442, -1.0068],
        [-0.9657, -0.8607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014657141582574695
Epoch 0, Step 1072: train/loss = 0.7039394378662109, train/raw-loss = 0.7023628354072571, train/logprobs = tensor([[-1.1110, -1.4261],
        [-1.1827, -1.2362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031530912965536118
Epoch 0, Step 1073: train/loss = 0.6927789449691772, train/raw-loss = 0.6913284659385681, train/logprobs = tensor([[-0.9722, -1.1072],
        [-1.0508, -0.8552]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029010199941694736
Epoch 0, Step 1074: train/loss = 0.7022973299026489, train/raw-loss = 0.7006310820579529, train/logprobs = tensor([[-1.1293, -1.0722],
        [-1.1951, -0.9041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00333235040307045
Epoch 0, Step 1075: train/loss = 0.6967589259147644, train/raw-loss = 0.6963111162185669, train/logprobs = tensor([[-1.0631, -1.1307],
        [-1.0502, -1.0004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008955677621997893
Epoch 0, Step 1076: train/loss = 0.694588303565979, train/raw-loss = 0.690122127532959, train/logprobs = tensor([[-0.9720, -1.0273],
        [-1.0541, -0.8477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008932370692491531
Epoch 0, Step 1077: train/loss = 0.6986323595046997, train/raw-loss = 0.6977766156196594, train/logprobs = tensor([[-1.2013, -1.2221],
        [-1.2263, -1.1088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001711500808596611
Epoch 0, Step 1078: train/loss = 0.6950849294662476, train/raw-loss = 0.6948972940444946, train/logprobs = tensor([[-0.8301, -0.9749],
        [-0.9335, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037526924279518425
Epoch 0, Step 1079: train/loss = 0.6930811405181885, train/raw-loss = 0.692960798740387, train/logprobs = tensor([[-0.9969, -1.0006],
        [-1.0014, -0.8926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024070858489722013
Epoch 0, Step 1080: train/loss = 0.7232024073600769, train/raw-loss = 0.7222946882247925, train/logprobs = tensor([[-1.1933, -0.9087],
        [-1.2774, -0.9201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018153265118598938
Epoch 0, Step 1081: train/loss = 0.6965891718864441, train/raw-loss = 0.6945422887802124, train/logprobs = tensor([[-1.2306, -1.2505],
        [-1.3931, -1.3607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004093788098543882
Epoch 0, Step 1082: train/loss = 0.6954007148742676, train/raw-loss = 0.6943897604942322, train/logprobs = tensor([[-1.2290, -1.3280],
        [-1.3018, -1.2763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020219481084495783
Epoch 0, Step 1083: train/loss = 0.6988294124603271, train/raw-loss = 0.6964362263679504, train/logprobs = tensor([[-0.9311, -1.0871],
        [-0.9163, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004786400124430656
Epoch 0, Step 1084: train/loss = 0.698683500289917, train/raw-loss = 0.6984636783599854, train/logprobs = tensor([[-1.0942, -0.9783],
        [-1.1137, -0.9144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004396181902848184
Epoch 0, Step 1085: train/loss = 0.6981728672981262, train/raw-loss = 0.6976422071456909, train/logprobs = tensor([[-0.9916, -0.8655],
        [-0.9389, -0.8109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010613956255838275
Epoch 0, Step 1086: train/loss = 0.6942493915557861, train/raw-loss = 0.692889928817749, train/logprobs = tensor([[-1.0472, -1.2604],
        [-1.1915, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002718869363889098
Epoch 0, Step 1087: train/loss = 0.6963546276092529, train/raw-loss = 0.6903660297393799, train/logprobs = tensor([[-1.0370, -1.3708],
        [-1.1209, -0.8026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011977151036262512
Epoch 0, Step 1088: train/loss = 0.6998258829116821, train/raw-loss = 0.6993427276611328, train/logprobs = tensor([[-1.2403, -1.4752],
        [-1.2300, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000966400490142405
Epoch 0, Step 1089: train/loss = 0.709786057472229, train/raw-loss = 0.708451509475708, train/logprobs = tensor([[-1.0570, -1.0163],
        [-1.2513, -0.9287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026690999511629343
Epoch 0, Step 1090: train/loss = 0.7139425277709961, train/raw-loss = 0.7120735049247742, train/logprobs = tensor([[-0.9323, -1.3799],
        [-0.9791, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003738096449524164
Epoch 0, Step 1091: train/loss = 0.7885699272155762, train/raw-loss = 0.7861672043800354, train/logprobs = tensor([[-0.9404, -1.4962],
        [-0.9736, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00480541680008173
Epoch 0, Step 1092: train/loss = 0.7095390558242798, train/raw-loss = 0.7063900232315063, train/logprobs = tensor([[-1.1228, -1.3923],
        [-1.0829, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00629804190248251
Epoch 0, Step 1093: train/loss = 0.7136132717132568, train/raw-loss = 0.7100318670272827, train/logprobs = tensor([[-0.8804, -1.2827],
        [-0.8837, -1.0155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007162852678447962
Epoch 0, Step 1094: train/loss = 0.6940930485725403, train/raw-loss = 0.6934606432914734, train/logprobs = tensor([[-1.0049, -1.0157],
        [-0.9844, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001264807302504778
Epoch 0, Step 1095: train/loss = 0.6931278109550476, train/raw-loss = 0.6927106380462646, train/logprobs = tensor([[-0.8769, -1.0530],
        [-0.8776, -0.8066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008343852823600173
Epoch 0, Step 1096: train/loss = 0.6896579265594482, train/raw-loss = 0.6893521547317505, train/logprobs = tensor([[-1.0926, -1.2246],
        [-0.9835, -0.8977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006114747375249863
Epoch 0, Step 1097: train/loss = 0.6977061629295349, train/raw-loss = 0.6970780491828918, train/logprobs = tensor([[-1.0793, -1.1547],
        [-1.1349, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012562901247292757
Epoch 0, Step 1098: train/loss = 0.7087239623069763, train/raw-loss = 0.7083741426467896, train/logprobs = tensor([[-1.1213, -1.0306],
        [-1.1600, -0.7658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006996253505349159
Epoch 0, Step 1099: train/loss = 0.6985058188438416, train/raw-loss = 0.6983179450035095, train/logprobs = tensor([[-1.0921, -1.0539],
        [-1.0797, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037580583011731505
Epoch 0, Step 1100: train/loss = 0.699733555316925, train/raw-loss = 0.6990642547607422, train/logprobs = tensor([[-0.9606, -0.8530],
        [-0.9703, -0.8225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013385822530835867
Epoch 0, Step 1101: train/loss = 0.7106266617774963, train/raw-loss = 0.7083656191825867, train/logprobs = tensor([[-0.8261, -1.0290],
        [-0.8777, -0.7640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004522142931818962
Epoch 0, Step 1102: train/loss = 0.7017068862915039, train/raw-loss = 0.6996225714683533, train/logprobs = tensor([[-1.2219, -1.2814],
        [-1.3189, -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004168767482042313
Epoch 0, Step 1103: train/loss = 0.6946322917938232, train/raw-loss = 0.6946061253547668, train/logprobs = tensor([[-1.2509, -1.2158],
        [-1.2553, -1.1631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.23701892234385e-05
Epoch 0, Step 1104: train/loss = 0.7019885778427124, train/raw-loss = 0.7006956338882446, train/logprobs = tensor([[-1.2881, -1.1745],
        [-1.2775, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025860301684588194
Epoch 0, Step 1105: train/loss = 0.6912760734558105, train/raw-loss = 0.6905726194381714, train/logprobs = tensor([[-0.8619, -1.1424],
        [-1.0982, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014068691525608301
Epoch 0, Step 1106: train/loss = 0.687984049320221, train/raw-loss = 0.6875775456428528, train/logprobs = tensor([[-0.9165, -1.0318],
        [-1.0705, -0.8167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008131335489451885
Epoch 0, Step 1107: train/loss = 0.7047631144523621, train/raw-loss = 0.704720139503479, train/logprobs = tensor([[-1.0282, -1.0039],
        [-1.0380, -0.9213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.585670730099082e-05
Epoch 0, Step 1108: train/loss = 0.6989585161209106, train/raw-loss = 0.6978341937065125, train/logprobs = tensor([[-0.9657, -1.0534],
        [-1.0432, -0.7435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022486220113933086
Epoch 0, Step 1109: train/loss = 0.6945074796676636, train/raw-loss = 0.6944928169250488, train/logprobs = tensor([[-1.1990, -1.2725],
        [-1.2127, -1.2586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9287897632457316e-05
Epoch 0, Step 1110: train/loss = 0.6965703964233398, train/raw-loss = 0.696080207824707, train/logprobs = tensor([[-1.0140, -1.0545],
        [-1.0596, -1.1143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009805024601519108
Epoch 0, Step 1111: train/loss = 0.6934012174606323, train/raw-loss = 0.6933295726776123, train/logprobs = tensor([[-1.0832, -1.1109],
        [-0.9624, -0.9537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014312798157334328
Epoch 0, Step 1112: train/loss = 0.6978514194488525, train/raw-loss = 0.6976679563522339, train/logprobs = tensor([[-1.1547, -1.0924],
        [-1.1950, -1.0386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036697741597890854
Epoch 0, Step 1113: train/loss = 0.6921812295913696, train/raw-loss = 0.6863851547241211, train/logprobs = tensor([[-1.0625, -1.2035],
        [-1.1559, -0.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011592132970690727
Epoch 0, Step 1114: train/loss = 0.7155436277389526, train/raw-loss = 0.7151502370834351, train/logprobs = tensor([[-1.4838, -1.3363],
        [-1.4561, -1.2101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007868159445933998
Epoch 0, Step 1115: train/loss = 0.7055528163909912, train/raw-loss = 0.7052133679389954, train/logprobs = tensor([[-1.0002, -1.1522],
        [-1.0242, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006788097089156508
Epoch 0, Step 1116: train/loss = 0.7058985233306885, train/raw-loss = 0.7054234147071838, train/logprobs = tensor([[-0.8641, -0.8300],
        [-0.9188, -0.7269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009502464672550559
Epoch 0, Step 1117: train/loss = 0.7155981659889221, train/raw-loss = 0.7143915295600891, train/logprobs = tensor([[-1.2912, -1.0176],
        [-1.2085, -0.7560]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024133340921252966
Epoch 0, Step 1118: train/loss = 0.6964349150657654, train/raw-loss = 0.6927201747894287, train/logprobs = tensor([[-1.1231, -1.5899],
        [-1.1271, -1.1642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007429574150592089
Epoch 0, Step 1119: train/loss = 0.6969509720802307, train/raw-loss = 0.6966053247451782, train/logprobs = tensor([[-1.1781, -1.0989],
        [-1.1389, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000691321911290288
Epoch 0, Step 1120: train/loss = 0.6976009607315063, train/raw-loss = 0.6975398063659668, train/logprobs = tensor([[-1.1135, -1.2797],
        [-1.0954, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012242732918821275
Epoch 0, Step 1121: train/loss = 0.7136261463165283, train/raw-loss = 0.713144063949585, train/logprobs = tensor([[-0.8880, -0.8262],
        [-0.8884, -0.6496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000964089878834784
Epoch 0, Step 1122: train/loss = 0.6962595582008362, train/raw-loss = 0.6945018768310547, train/logprobs = tensor([[-0.9953, -1.3989],
        [-1.0628, -1.1196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035154966171830893
Epoch 0, Step 1123: train/loss = 0.699385404586792, train/raw-loss = 0.6990994215011597, train/logprobs = tensor([[-1.2366, -1.1156],
        [-1.1756, -1.0128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005720026092603803
Epoch 0, Step 1124: train/loss = 0.7295769453048706, train/raw-loss = 0.7294259667396545, train/logprobs = tensor([[-0.9833, -1.4546],
        [-1.0861, -1.3388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030200916808098555
Epoch 0, Step 1125: train/loss = 0.6825768947601318, train/raw-loss = 0.6816369295120239, train/logprobs = tensor([[-0.7266, -1.1167],
        [-0.9780, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018799254903569818
Epoch 0, Step 1126: train/loss = 0.702241837978363, train/raw-loss = 0.7011271715164185, train/logprobs = tensor([[-0.9240, -1.1933],
        [-0.9908, -0.9510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002229335717856884
Epoch 0, Step 1127: train/loss = 0.7140728235244751, train/raw-loss = 0.712734580039978, train/logprobs = tensor([[-1.1425, -0.8692],
        [-1.1729, -0.8584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026762252673506737
Epoch 0, Step 1128: train/loss = 0.7117101550102234, train/raw-loss = 0.7104465961456299, train/logprobs = tensor([[-0.9115, -0.8410],
        [-0.9964, -0.5981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002527330070734024
Epoch 0, Step 1129: train/loss = 0.705817699432373, train/raw-loss = 0.704153299331665, train/logprobs = tensor([[-1.0256, -1.1032],
        [-1.0066, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033288374543190002
Epoch 0, Step 1130: train/loss = 0.7051712870597839, train/raw-loss = 0.7018132209777832, train/logprobs = tensor([[-1.1197, -0.9785],
        [-1.2646, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006716272793710232
Epoch 0, Step 1131: train/loss = 0.6970453262329102, train/raw-loss = 0.6960654258728027, train/logprobs = tensor([[-0.9126, -0.8829],
        [-0.9926, -0.7340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019597033970057964
Epoch 0, Step 1132: train/loss = 0.695656955242157, train/raw-loss = 0.694449245929718, train/logprobs = tensor([[-0.9830, -1.0343],
        [-1.0066, -0.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002415444701910019
Epoch 0, Step 1133: train/loss = 0.7265492081642151, train/raw-loss = 0.7252271771430969, train/logprobs = tensor([[-1.2061, -1.1668],
        [-1.2798, -0.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026440394576638937
Epoch 0, Step 1134: train/loss = 0.6997371912002563, train/raw-loss = 0.6986395120620728, train/logprobs = tensor([[-1.0319, -0.9850],
        [-1.1325, -0.8657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021953086834400892
Epoch 0, Step 1135: train/loss = 0.7007553577423096, train/raw-loss = 0.7001335620880127, train/logprobs = tensor([[-1.0785, -1.0417],
        [-1.0641, -0.9118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001243608188815415
Epoch 0, Step 1136: train/loss = 0.7019978761672974, train/raw-loss = 0.6994642615318298, train/logprobs = tensor([[-0.9772, -0.8802],
        [-0.9286, -0.6298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005067163147032261
Epoch 0, Step 1137: train/loss = 0.6954835653305054, train/raw-loss = 0.6942765712738037, train/logprobs = tensor([[-1.1791, -1.2571],
        [-1.3155, -1.1807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024139147717505693
Epoch 0, Step 1138: train/loss = 0.701088547706604, train/raw-loss = 0.6985795497894287, train/logprobs = tensor([[-0.9669, -0.9580],
        [-1.2711, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005017878022044897
Epoch 0, Step 1139: train/loss = 0.6940800547599792, train/raw-loss = 0.6938124895095825, train/logprobs = tensor([[-1.2749, -1.2376],
        [-1.2117, -0.9632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005350933643057942
Epoch 0, Step 1140: train/loss = 0.6989160180091858, train/raw-loss = 0.6982357501983643, train/logprobs = tensor([[-1.0146, -1.0131],
        [-0.9901, -0.8299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013604742707684636
Epoch 0, Step 1141: train/loss = 0.7165998220443726, train/raw-loss = 0.7164927124977112, train/logprobs = tensor([[-0.9708, -0.8621],
        [-0.9493, -0.7767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021412342903204262
Epoch 0, Step 1142: train/loss = 0.7125626802444458, train/raw-loss = 0.7102067470550537, train/logprobs = tensor([[-0.9666, -1.2853],
        [-1.0514, -1.0653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00471189571544528
Epoch 0, Step 1143: train/loss = 0.699453592300415, train/raw-loss = 0.6990121603012085, train/logprobs = tensor([[-1.0948, -1.2251],
        [-1.1642, -1.2735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008829208090901375
Epoch 0, Step 1144: train/loss = 0.6978748440742493, train/raw-loss = 0.6968910694122314, train/logprobs = tensor([[-0.9660, -1.1558],
        [-0.9174, -0.8969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001967400312423706
Epoch 0, Step 1145: train/loss = 0.7135583162307739, train/raw-loss = 0.7123271822929382, train/logprobs = tensor([[-1.0174, -1.0504],
        [-0.9797, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002462328178808093
Epoch 0, Step 1146: train/loss = 0.7077407240867615, train/raw-loss = 0.7070052027702332, train/logprobs = tensor([[-1.0379, -0.9390],
        [-1.0282, -0.7896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014711202820762992
Epoch 0, Step 1147: train/loss = 0.6959931254386902, train/raw-loss = 0.6957155466079712, train/logprobs = tensor([[-1.2621, -1.2953],
        [-1.1962, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000555022619664669
Epoch 0, Step 1148: train/loss = 0.6961786150932312, train/raw-loss = 0.6952430009841919, train/logprobs = tensor([[-0.8065, -0.8991],
        [-0.8989, -0.7945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018711474258452654
Epoch 0, Step 1149: train/loss = 0.7921581268310547, train/raw-loss = 0.7840766906738281, train/logprobs = tensor([[-0.9204, -1.6478],
        [-1.0865, -1.2733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016162913292646408
Epoch 0, Step 1150: train/loss = 0.6989166736602783, train/raw-loss = 0.6967598795890808, train/logprobs = tensor([[-0.9838, -1.2750],
        [-0.9965, -1.0231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004313572775572538
Epoch 0, Step 1151: train/loss = 0.7083819508552551, train/raw-loss = 0.7060095071792603, train/logprobs = tensor([[-1.1934, -0.9891],
        [-1.3397, -0.8176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004744876176118851
Epoch 0, Step 1152: train/loss = 0.6905850768089294, train/raw-loss = 0.6887685656547546, train/logprobs = tensor([[-0.9662, -1.0945],
        [-1.0760, -0.8105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00363306631334126
Epoch 0, Step 1153: train/loss = 0.6948739886283875, train/raw-loss = 0.6897286176681519, train/logprobs = tensor([[-1.1780, -1.4294],
        [-1.3261, -1.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010290832258760929
Epoch 0, Step 1154: train/loss = 0.7008118629455566, train/raw-loss = 0.6953378319740295, train/logprobs = tensor([[-0.9366, -1.0891],
        [-1.0631, -0.8781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010948163457214832
Epoch 0, Step 1155: train/loss = 0.7051363587379456, train/raw-loss = 0.7046907544136047, train/logprobs = tensor([[-1.0024, -0.8971],
        [-1.0929, -0.8141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008912789053283632
Epoch 0, Step 1156: train/loss = 0.6958900094032288, train/raw-loss = 0.6900419592857361, train/logprobs = tensor([[-1.0399, -1.2994],
        [-1.1334, -0.9790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011696139350533485
Epoch 0, Step 1157: train/loss = 0.6966767907142639, train/raw-loss = 0.691676139831543, train/logprobs = tensor([[-1.0428, -1.2542],
        [-1.0860, -0.9798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010001345537602901
Epoch 0, Step 1158: train/loss = 0.6940466165542603, train/raw-loss = 0.6907809376716614, train/logprobs = tensor([[-0.8906, -1.1922],
        [-1.0491, -0.9141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006531371735036373
Epoch 0, Step 1159: train/loss = 0.710467517375946, train/raw-loss = 0.7083917856216431, train/logprobs = tensor([[-0.9280, -0.9468],
        [-0.9584, -0.7426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004151368048042059
Epoch 0, Step 1160: train/loss = 0.6968355178833008, train/raw-loss = 0.6943770051002502, train/logprobs = tensor([[-1.0697, -1.1182],
        [-1.0876, -0.8602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004916921723634005
Epoch 0, Step 1161: train/loss = 0.6957080960273743, train/raw-loss = 0.6943891048431396, train/logprobs = tensor([[-0.9552, -1.0119],
        [-0.8744, -0.7853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026380959898233414
Epoch 0, Step 1162: train/loss = 0.6966356039047241, train/raw-loss = 0.6937869787216187, train/logprobs = tensor([[-1.2484, -1.2243],
        [-1.2388, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005697238724678755
Epoch 0, Step 1163: train/loss = 0.7370650768280029, train/raw-loss = 0.7343822717666626, train/logprobs = tensor([[-1.0700, -1.2352],
        [-1.1605, -1.2579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005365766119211912
Epoch 0, Step 1164: train/loss = 0.6998202204704285, train/raw-loss = 0.6988980770111084, train/logprobs = tensor([[-0.9794, -0.8682],
        [-0.9864, -0.7564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001844168989919126
Epoch 0, Step 1165: train/loss = 0.6874024271965027, train/raw-loss = 0.6827671527862549, train/logprobs = tensor([[-1.1827, -1.4801],
        [-1.1753, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009270473383367062
Epoch 0, Step 1166: train/loss = 0.6946966648101807, train/raw-loss = 0.692834734916687, train/logprobs = tensor([[-0.9863, -1.0677],
        [-0.9799, -0.8320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037236979696899652
Epoch 0, Step 1167: train/loss = 0.6971606612205505, train/raw-loss = 0.6906271576881409, train/logprobs = tensor([[-1.1495, -1.2166],
        [-1.3404, -0.8838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013067022897303104
Epoch 0, Step 1168: train/loss = 0.6948175430297852, train/raw-loss = 0.6947448253631592, train/logprobs = tensor([[-0.9678, -1.0058],
        [-0.7987, -0.8093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014555675443261862
Epoch 0, Step 1169: train/loss = 0.696258544921875, train/raw-loss = 0.6960003972053528, train/logprobs = tensor([[-0.8650, -0.7922],
        [-0.7878, -0.6684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005163794849067926
Epoch 0, Step 1170: train/loss = 0.692754864692688, train/raw-loss = 0.6877407431602478, train/logprobs = tensor([[-1.1736, -1.4204],
        [-1.1688, -0.9466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010028292424976826
Epoch 0, Step 1171: train/loss = 0.6998477578163147, train/raw-loss = 0.6994959712028503, train/logprobs = tensor([[-0.9571, -1.0504],
        [-0.7935, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007035001181066036
Epoch 0, Step 1172: train/loss = 0.6919346451759338, train/raw-loss = 0.6888200044631958, train/logprobs = tensor([[-1.0866, -1.3608],
        [-1.1072, -1.0535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006229289807379246
Epoch 0, Step 1173: train/loss = 0.7062234878540039, train/raw-loss = 0.702623724937439, train/logprobs = tensor([[-1.1906, -1.2510],
        [-1.2592, -0.9644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00719958171248436
Epoch 0, Step 1174: train/loss = 0.6661907434463501, train/raw-loss = 0.660895824432373, train/logprobs = tensor([[-0.9718, -1.2033],
        [-1.4899, -0.6536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010589954443275928
Epoch 0, Step 1175: train/loss = 0.7107028365135193, train/raw-loss = 0.7094508409500122, train/logprobs = tensor([[-1.0841, -1.1996],
        [-1.1052, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025040877517312765
Epoch 0, Step 1176: train/loss = 0.6981972455978394, train/raw-loss = 0.6955283880233765, train/logprobs = tensor([[-0.8415, -1.0661],
        [-0.9737, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005337646696716547
Epoch 0, Step 1177: train/loss = 0.7037048935890198, train/raw-loss = 0.701066792011261, train/logprobs = tensor([[-1.1556, -1.2467],
        [-1.2410, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005276113748550415
Epoch 0, Step 1178: train/loss = 0.6953226327896118, train/raw-loss = 0.6951814293861389, train/logprobs = tensor([[-0.9321, -1.0855],
        [-0.9713, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002823364920914173
Epoch 0, Step 1179: train/loss = 0.729254961013794, train/raw-loss = 0.7269887924194336, train/logprobs = tensor([[-0.9638, -1.1290],
        [-1.0015, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004532321821898222
Epoch 0, Step 1180: train/loss = 0.6991209387779236, train/raw-loss = 0.6952175498008728, train/logprobs = tensor([[-0.9254, -0.9882],
        [-1.0716, -0.7653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007806723937392235
Epoch 0, Step 1181: train/loss = 0.7097161412239075, train/raw-loss = 0.7061061859130859, train/logprobs = tensor([[-1.1591, -1.3829],
        [-1.0463, -0.9862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007219932973384857
Epoch 0, Step 1182: train/loss = 0.6966068148612976, train/raw-loss = 0.6946837902069092, train/logprobs = tensor([[-0.9674, -1.1767],
        [-1.0034, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038461494259536266
Epoch 0, Step 1183: train/loss = 0.7502637505531311, train/raw-loss = 0.7437512874603271, train/logprobs = tensor([[-0.9931, -1.5285],
        [-1.0131, -1.0612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013024969026446342
Epoch 0, Step 1184: train/loss = 0.71224045753479, train/raw-loss = 0.7097796201705933, train/logprobs = tensor([[-0.9332, -1.2595],
        [-0.9900, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004921801388263702
Epoch 0, Step 1185: train/loss = 0.6967356204986572, train/raw-loss = 0.6945310831069946, train/logprobs = tensor([[-1.2071, -1.2088],
        [-1.2521, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004409033805131912
Epoch 0, Step 1186: train/loss = 0.7047958374023438, train/raw-loss = 0.7008349895477295, train/logprobs = tensor([[-1.0680, -1.4708],
        [-1.0441, -1.0967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007921692915260792
Epoch 0, Step 1187: train/loss = 0.6953440308570862, train/raw-loss = 0.6951512098312378, train/logprobs = tensor([[-1.0164, -1.0314],
        [-0.9041, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038556481013074517
Epoch 0, Step 1188: train/loss = 0.6969947814941406, train/raw-loss = 0.6931969523429871, train/logprobs = tensor([[-1.0287, -1.1250],
        [-1.0355, -0.7908]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007595617789775133
Epoch 0, Step 1189: train/loss = 0.6984822750091553, train/raw-loss = 0.696951150894165, train/logprobs = tensor([[-1.0366, -1.2033],
        [-1.1053, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030623115599155426
Epoch 0, Step 1190: train/loss = 0.7068683505058289, train/raw-loss = 0.7002235651016235, train/logprobs = tensor([[-1.1396, -1.2036],
        [-1.2080, -0.9532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013289558701217175
Epoch 0, Step 1191: train/loss = 0.7005519270896912, train/raw-loss = 0.700186014175415, train/logprobs = tensor([[-1.0796, -1.1581],
        [-1.0959, -1.0044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007318778662011027
Epoch 0, Step 1192: train/loss = 0.6938633918762207, train/raw-loss = 0.6921365261077881, train/logprobs = tensor([[-0.9973, -1.0680],
        [-1.1767, -0.8790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034538181498646736
Epoch 0, Step 1193: train/loss = 0.6960495114326477, train/raw-loss = 0.6929930448532104, train/logprobs = tensor([[-1.0133, -1.1683],
        [-1.1702, -0.9468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061128451488912106
Epoch 0, Step 1194: train/loss = 0.693682074546814, train/raw-loss = 0.6936330199241638, train/logprobs = tensor([[-1.0545, -1.0665],
        [-0.9423, -0.9044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.810997289605439e-05
Epoch 0, Step 1195: train/loss = 0.7051451802253723, train/raw-loss = 0.7048361897468567, train/logprobs = tensor([[-1.1450, -1.0346],
        [-1.1306, -0.9490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006177839240990579
Epoch 0, Step 1196: train/loss = 0.6942521333694458, train/raw-loss = 0.6932050585746765, train/logprobs = tensor([[-0.9783, -1.0147],
        [-1.0073, -1.0371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020942194387316704
Epoch 0, Step 1197: train/loss = 0.6989381909370422, train/raw-loss = 0.6982666254043579, train/logprobs = tensor([[-0.9159, -1.0014],
        [-0.9626, -0.8635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013430811231955886
Epoch 0, Step 1198: train/loss = 0.7322401404380798, train/raw-loss = 0.7283952236175537, train/logprobs = tensor([[-0.8659, -1.1158],
        [-1.0898, -0.9411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0076898084953427315
Epoch 0, Step 1199: train/loss = 0.6978240609169006, train/raw-loss = 0.6956117153167725, train/logprobs = tensor([[-1.0348, -1.2874],
        [-1.1516, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004424711689352989
Epoch 0, Step 1200: train/loss = 0.7024569511413574, train/raw-loss = 0.7020379304885864, train/logprobs = tensor([[-0.9186, -0.8617],
        [-1.0050, -0.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008380415383726358
Epoch 0, Step 1201: train/loss = 0.7360460758209229, train/raw-loss = 0.7327815890312195, train/logprobs = tensor([[-1.1922, -0.8583],
        [-1.3461, -0.7217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006528975907713175
Epoch 0, Step 1202: train/loss = 0.7325630187988281, train/raw-loss = 0.7300667762756348, train/logprobs = tensor([[-1.0092, -1.3736],
        [-1.0403, -1.0107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004992414731532335
Epoch 0, Step 1203: train/loss = 0.6951843500137329, train/raw-loss = 0.6946849822998047, train/logprobs = tensor([[-0.9521, -1.1279],
        [-0.9774, -1.0574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009986353106796741
Epoch 0, Step 1204: train/loss = 0.699238121509552, train/raw-loss = 0.6981490254402161, train/logprobs = tensor([[-1.0176, -1.0677],
        [-1.0625, -0.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021781870163977146
Epoch 0, Step 1205: train/loss = 0.6956817507743835, train/raw-loss = 0.6941440105438232, train/logprobs = tensor([[-0.9955, -1.1113],
        [-1.0351, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030753978062421083
Epoch 0, Step 1206: train/loss = 0.7097091674804688, train/raw-loss = 0.7092865705490112, train/logprobs = tensor([[-0.7724, -1.0161],
        [-0.9122, -1.0065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008451055036857724
Epoch 0, Step 1207: train/loss = 0.7001785635948181, train/raw-loss = 0.6957759857177734, train/logprobs = tensor([[-1.1461, -1.5038],
        [-1.1398, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008805169723927975
Epoch 0, Step 1208: train/loss = 0.6941285729408264, train/raw-loss = 0.6929421424865723, train/logprobs = tensor([[-1.0393, -1.1943],
        [-1.0310, -1.0148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023728986270725727
Epoch 0, Step 1209: train/loss = 0.6924383044242859, train/raw-loss = 0.6913056373596191, train/logprobs = tensor([[-0.9659, -1.0983],
        [-0.9778, -0.8933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002265376038849354
Epoch 0, Step 1210: train/loss = 0.70814448595047, train/raw-loss = 0.7078890800476074, train/logprobs = tensor([[-0.8206, -1.0506],
        [-0.9079, -1.0955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005107787437736988
Epoch 0, Step 1211: train/loss = 0.6958506107330322, train/raw-loss = 0.689617395401001, train/logprobs = tensor([[-0.8727, -1.0368],
        [-0.9457, -0.7734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01246641669422388
Epoch 0, Step 1212: train/loss = 0.6909317970275879, train/raw-loss = 0.6824629902839661, train/logprobs = tensor([[-1.1220, -1.3880],
        [-1.0450, -0.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016937511041760445
Epoch 0, Step 1213: train/loss = 0.7005924582481384, train/raw-loss = 0.6950423717498779, train/logprobs = tensor([[-0.9105, -1.3226],
        [-1.0014, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0111001655459404
Epoch 0, Step 1214: train/loss = 0.6991111636161804, train/raw-loss = 0.6985428333282471, train/logprobs = tensor([[-1.0565, -1.2629],
        [-1.0187, -1.0951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011366150574758649
Epoch 0, Step 1215: train/loss = 0.6998662948608398, train/raw-loss = 0.6995818614959717, train/logprobs = tensor([[-0.9327, -1.0469],
        [-1.1809, -0.9405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005688809906132519
Epoch 0, Step 1216: train/loss = 0.7646196484565735, train/raw-loss = 0.7538977265357971, train/logprobs = tensor([[-0.9857, -1.2460],
        [-1.1323, -0.8267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02144383266568184
Epoch 0, Step 1217: train/loss = 0.7065690755844116, train/raw-loss = 0.7046959400177002, train/logprobs = tensor([[-1.2307, -1.2566],
        [-1.4635, -1.2550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003746205009520054
Epoch 0, Step 1218: train/loss = 0.7014734148979187, train/raw-loss = 0.700368344783783, train/logprobs = tensor([[-0.9524, -1.1841],
        [-1.0345, -0.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002210102044045925
Epoch 0, Step 1219: train/loss = 0.6996025443077087, train/raw-loss = 0.6950673460960388, train/logprobs = tensor([[-0.8390, -1.0898],
        [-1.0383, -1.0786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0090702585875988
Epoch 0, Step 1220: train/loss = 0.6984311938285828, train/raw-loss = 0.696497917175293, train/logprobs = tensor([[-1.2623, -1.5862],
        [-1.0853, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038665090687572956
Epoch 0, Step 1221: train/loss = 0.7215973138809204, train/raw-loss = 0.7145835161209106, train/logprobs = tensor([[-1.0309, -1.3601],
        [-1.1431, -0.9502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014027595520019531
Epoch 0, Step 1222: train/loss = 0.7545927166938782, train/raw-loss = 0.7541773915290833, train/logprobs = tensor([[-1.3431, -0.9774],
        [-1.2111, -0.8292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008306831587105989
Epoch 0, Step 1223: train/loss = 0.7045248746871948, train/raw-loss = 0.6999326944351196, train/logprobs = tensor([[-0.8581, -0.9418],
        [-0.9076, -0.6381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009184246882796288
Epoch 0, Step 1224: train/loss = 0.6973159909248352, train/raw-loss = 0.6970564126968384, train/logprobs = tensor([[-1.0258, -1.0855],
        [-1.0050, -0.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005191473755985498
Epoch 0, Step 1225: train/loss = 0.733993411064148, train/raw-loss = 0.7243489027023315, train/logprobs = tensor([[-1.0581, -1.3307],
        [-1.0881, -0.9484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019289016723632812
Epoch 0, Step 1226: train/loss = 0.710979700088501, train/raw-loss = 0.7108603119850159, train/logprobs = tensor([[-1.1131, -1.0027],
        [-0.9142, -0.6331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023870714358054101
Epoch 0, Step 1227: train/loss = 0.7017282247543335, train/raw-loss = 0.7005993127822876, train/logprobs = tensor([[-0.7668, -0.8489],
        [-0.8899, -0.8162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002257745247334242
Epoch 0, Step 1228: train/loss = 0.6964094638824463, train/raw-loss = 0.6955299377441406, train/logprobs = tensor([[-0.8792, -1.0943],
        [-1.0499, -1.0154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017589721828699112
Epoch 0, Step 1229: train/loss = 0.752364993095398, train/raw-loss = 0.7498393654823303, train/logprobs = tensor([[-0.9338, -1.3522],
        [-1.0194, -1.1312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005051284562796354
Epoch 0, Step 1230: train/loss = 0.6941797137260437, train/raw-loss = 0.6938632726669312, train/logprobs = tensor([[-1.1108, -1.1837],
        [-1.1486, -1.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006330052856355906
Epoch 0, Step 1231: train/loss = 0.6934590339660645, train/raw-loss = 0.6868169903755188, train/logprobs = tensor([[-0.9291, -1.0190],
        [-1.1665, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013284150511026382
Epoch 0, Step 1232: train/loss = 0.7024315595626831, train/raw-loss = 0.7010284662246704, train/logprobs = tensor([[-1.0821, -1.1493],
        [-1.1597, -1.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028061792254447937
Epoch 0, Step 1233: train/loss = 0.6882131695747375, train/raw-loss = 0.678101658821106, train/logprobs = tensor([[-1.0667, -1.3358],
        [-1.2543, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020223084837198257
Epoch 0, Step 1234: train/loss = 0.6893272399902344, train/raw-loss = 0.6847671866416931, train/logprobs = tensor([[-1.0749, -1.3401],
        [-1.1366, -1.0906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00912019144743681
Epoch 0, Step 1235: train/loss = 0.7020503282546997, train/raw-loss = 0.6990437507629395, train/logprobs = tensor([[-1.0866, -1.3287],
        [-1.1027, -1.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006013183854520321
Epoch 0, Step 1236: train/loss = 0.7463608980178833, train/raw-loss = 0.7448391914367676, train/logprobs = tensor([[-0.9376, -1.5318],
        [-0.8889, -1.2418]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030434653162956238
Epoch 0, Step 1237: train/loss = 0.6938092708587646, train/raw-loss = 0.6868407726287842, train/logprobs = tensor([[-1.0115, -1.1260],
        [-1.0001, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01393706165254116
Epoch 0, Step 1238: train/loss = 0.6939132213592529, train/raw-loss = 0.6923844814300537, train/logprobs = tensor([[-1.1176, -1.1579],
        [-1.1548, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030573729891330004
Epoch 0, Step 1239: train/loss = 0.7038944959640503, train/raw-loss = 0.700497031211853, train/logprobs = tensor([[-0.9490, -1.2769],
        [-0.9457, -0.9548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006795004941523075
Epoch 0, Step 1240: train/loss = 0.692328929901123, train/raw-loss = 0.6898850202560425, train/logprobs = tensor([[-1.1094, -1.2712],
        [-1.1807, -1.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004887775518000126
Epoch 0, Step 1241: train/loss = 0.7121809720993042, train/raw-loss = 0.7048519849777222, train/logprobs = tensor([[-0.9411, -1.3045],
        [-1.1478, -0.9233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014657942578196526
Epoch 0, Step 1242: train/loss = 0.706831693649292, train/raw-loss = 0.7049316763877869, train/logprobs = tensor([[-1.3014, -1.1107],
        [-1.2927, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038000186905264854
Epoch 0, Step 1243: train/loss = 0.7232733964920044, train/raw-loss = 0.7129437327384949, train/logprobs = tensor([[-0.9872, -1.4384],
        [-1.0081, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020659223198890686
Epoch 0, Step 1244: train/loss = 0.6934380531311035, train/raw-loss = 0.6921409368515015, train/logprobs = tensor([[-0.9332, -1.0354],
        [-0.9466, -0.9053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002594191348180175
Epoch 0, Step 1245: train/loss = 0.7012316584587097, train/raw-loss = 0.7011634111404419, train/logprobs = tensor([[-0.9650, -0.8947],
        [-1.0607, -0.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013651099288836122
Epoch 0, Step 1246: train/loss = 0.6992231011390686, train/raw-loss = 0.6933998465538025, train/logprobs = tensor([[-1.0693, -1.1771],
        [-1.0646, -0.7901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011646444909274578
Epoch 0, Step 1247: train/loss = 0.6920613050460815, train/raw-loss = 0.6897667050361633, train/logprobs = tensor([[-1.0800, -1.2395],
        [-0.9501, -0.8805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004589182324707508
Epoch 0, Step 1248: train/loss = 0.6934201717376709, train/raw-loss = 0.69338059425354, train/logprobs = tensor([[-0.8895, -0.8939],
        [-0.8460, -0.8591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.921236101537943e-05
Epoch 0, Step 1249: train/loss = 0.6943491101264954, train/raw-loss = 0.6912518739700317, train/logprobs = tensor([[-0.8015, -1.1374],
        [-0.9968, -0.8465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006194521207362413
Epoch 0, Step 1250: train/loss = 0.6917101144790649, train/raw-loss = 0.6845089793205261, train/logprobs = tensor([[-1.0191, -1.2320],
        [-1.0699, -0.9099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014402253553271294
Epoch 0, Step 1251: train/loss = 0.6921724081039429, train/raw-loss = 0.6910455822944641, train/logprobs = tensor([[-0.8930, -0.9894],
        [-0.9339, -0.8473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022536024916917086
Epoch 0, Step 1252: train/loss = 0.7237733602523804, train/raw-loss = 0.7230618000030518, train/logprobs = tensor([[-0.8467, -0.8540],
        [-0.8827, -0.7680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014232236426323652
Epoch 0, Step 1253: train/loss = 0.7016249895095825, train/raw-loss = 0.7002686262130737, train/logprobs = tensor([[-1.1881, -0.9862],
        [-1.0796, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027127524372190237
Epoch 0, Step 1254: train/loss = 0.7022457122802734, train/raw-loss = 0.7021524310112, train/logprobs = tensor([[-1.2389, -1.0735],
        [-0.9643, -0.8402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001864477526396513
Epoch 0, Step 1255: train/loss = 0.7001793384552002, train/raw-loss = 0.6999126076698303, train/logprobs = tensor([[-1.2571, -1.4154],
        [-1.1819, -1.1681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005335716996341944
Epoch 0, Step 1256: train/loss = 0.6975932717323303, train/raw-loss = 0.6951444149017334, train/logprobs = tensor([[-1.1212, -1.1745],
        [-0.9246, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004897741600871086
Epoch 0, Step 1257: train/loss = 0.7300941348075867, train/raw-loss = 0.7243597507476807, train/logprobs = tensor([[-1.1020, -1.2011],
        [-1.3513, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011468627490103245
Epoch 0, Step 1258: train/loss = 0.6935340166091919, train/raw-loss = 0.6934616565704346, train/logprobs = tensor([[-0.9972, -0.9928],
        [-0.9634, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014473410556092858
Epoch 0, Step 1259: train/loss = 0.7047538161277771, train/raw-loss = 0.701923668384552, train/logprobs = tensor([[-1.2215, -1.0983],
        [-1.1859, -0.8268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005660303868353367
Epoch 0, Step 1260: train/loss = 0.6971390247344971, train/raw-loss = 0.6960943341255188, train/logprobs = tensor([[-1.2377, -1.3366],
        [-1.3166, -1.3150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002089367713779211
Epoch 0, Step 1261: train/loss = 0.7075653076171875, train/raw-loss = 0.7067056894302368, train/logprobs = tensor([[-0.9948, -0.8396],
        [-1.1101, -0.7740]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017192234518006444
Epoch 0, Step 1262: train/loss = 0.6952940225601196, train/raw-loss = 0.6895243525505066, train/logprobs = tensor([[-1.1570, -1.3998],
        [-1.3831, -1.1577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011539322324097157
Epoch 0, Step 1263: train/loss = 0.7154718041419983, train/raw-loss = 0.7143568992614746, train/logprobs = tensor([[-1.0133, -0.8963],
        [-1.1150, -0.7897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00222988985478878
Epoch 0, Step 1264: train/loss = 0.7160245180130005, train/raw-loss = 0.7153565287590027, train/logprobs = tensor([[-1.0284, -1.0643],
        [-1.1550, -0.9954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001335927750915289
Epoch 0, Step 1265: train/loss = 0.7080808877944946, train/raw-loss = 0.7069989442825317, train/logprobs = tensor([[-1.1401, -1.2201],
        [-1.2937, -1.3242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021638981997966766
Epoch 0, Step 1266: train/loss = 0.6913360953330994, train/raw-loss = 0.6854733228683472, train/logprobs = tensor([[-0.9700, -1.2469],
        [-1.1463, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011725629679858685
Epoch 0, Step 1267: train/loss = 0.690415620803833, train/raw-loss = 0.6764416694641113, train/logprobs = tensor([[-1.1567, -1.2818],
        [-1.2270, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027947936207056046
Epoch 0, Step 1268: train/loss = 0.6938362121582031, train/raw-loss = 0.691930890083313, train/logprobs = tensor([[-0.9553, -1.1568],
        [-0.9998, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038105121348053217
Epoch 0, Step 1269: train/loss = 0.6953917145729065, train/raw-loss = 0.6922801733016968, train/logprobs = tensor([[-1.1819, -1.2215],
        [-0.9888, -0.9758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006223178468644619
Epoch 0, Step 1270: train/loss = 0.7502177953720093, train/raw-loss = 0.7484421730041504, train/logprobs = tensor([[-0.9547, -1.5239],
        [-1.0918, -1.2733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035512419417500496
Epoch 0, Step 1271: train/loss = 0.6934758424758911, train/raw-loss = 0.6893391013145447, train/logprobs = tensor([[-1.1585, -1.2743],
        [-0.9771, -0.9945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008273421786725521
Epoch 0, Step 1272: train/loss = 0.7049678564071655, train/raw-loss = 0.6986048221588135, train/logprobs = tensor([[-1.1667, -1.7067],
        [-1.2028, -1.2877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012726121582090855
Epoch 0, Step 1273: train/loss = 0.7055648565292358, train/raw-loss = 0.7026889324188232, train/logprobs = tensor([[-1.2400, -1.1391],
        [-1.1294, -0.7610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005751730874180794
Epoch 0, Step 1274: train/loss = 0.7032901644706726, train/raw-loss = 0.695925772190094, train/logprobs = tensor([[-1.2016, -1.2753],
        [-1.3541, -1.0266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014728744514286518
Epoch 0, Step 1275: train/loss = 0.6902026534080505, train/raw-loss = 0.685130774974823, train/logprobs = tensor([[-1.1326, -1.2767],
        [-1.3675, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010143875144422054
Epoch 0, Step 1276: train/loss = 0.6990506052970886, train/raw-loss = 0.6977442502975464, train/logprobs = tensor([[-1.0218, -0.9427],
        [-1.2053, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026126583106815815
Epoch 0, Step 1277: train/loss = 0.695918619632721, train/raw-loss = 0.6959149837493896, train/logprobs = tensor([[-0.9701, -1.0611],
        [-1.1396, -1.1838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.239141268655658e-06
Epoch 0, Step 1278: train/loss = 0.7027939558029175, train/raw-loss = 0.6950986385345459, train/logprobs = tensor([[-0.8833, -0.9823],
        [-1.2697, -0.7184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015390724875032902
Epoch 0, Step 1279: train/loss = 0.7108218669891357, train/raw-loss = 0.7049002647399902, train/logprobs = tensor([[-1.1039, -1.4318],
        [-1.1858, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011843117885291576
Epoch 0, Step 1280: train/loss = 0.7013434171676636, train/raw-loss = 0.6998815536499023, train/logprobs = tensor([[-0.9959, -0.9613],
        [-1.1213, -0.9378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029238462448120117
Epoch 0, Step 1281: train/loss = 0.6927591562271118, train/raw-loss = 0.6923639178276062, train/logprobs = tensor([[-1.0117, -1.0639],
        [-0.9375, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000790413876529783
Epoch 0, Step 1282: train/loss = 0.6881049871444702, train/raw-loss = 0.6810865998268127, train/logprobs = tensor([[-1.0732, -1.3200],
        [-1.2181, -1.0052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014036806300282478
Epoch 0, Step 1283: train/loss = 0.6996153593063354, train/raw-loss = 0.6894053220748901, train/logprobs = tensor([[-1.0340, -1.5703],
        [-0.9603, -0.9338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020420055836439133
Epoch 0, Step 1284: train/loss = 0.7093584537506104, train/raw-loss = 0.7002770304679871, train/logprobs = tensor([[-1.1158, -1.2822],
        [-1.1781, -0.8307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018162976950407028
Epoch 0, Step 1285: train/loss = 0.7114459872245789, train/raw-loss = 0.709586501121521, train/logprobs = tensor([[-1.1358, -0.8377],
        [-1.2076, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003718974068760872
Epoch 0, Step 1286: train/loss = 0.7064870595932007, train/raw-loss = 0.7045197486877441, train/logprobs = tensor([[-1.0587, -1.0859],
        [-1.2331, -0.9543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039345393888652325
Epoch 0, Step 1287: train/loss = 0.6958261132240295, train/raw-loss = 0.6906755566596985, train/logprobs = tensor([[-0.9125, -1.2764],
        [-1.0804, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010301094502210617
Epoch 0, Step 1288: train/loss = 0.7130897641181946, train/raw-loss = 0.7037661075592041, train/logprobs = tensor([[-0.9874, -1.4156],
        [-1.0899, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01864722929894924
Epoch 0, Step 1289: train/loss = 0.6958909034729004, train/raw-loss = 0.680546224117279, train/logprobs = tensor([[-1.0127, -1.4470],
        [-1.1717, -0.8527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030689295381307602
Epoch 0, Step 1290: train/loss = 0.771549642086029, train/raw-loss = 0.7689920663833618, train/logprobs = tensor([[-1.2927, -1.9100],
        [-1.2758, -1.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005115181673318148
Epoch 0, Step 1291: train/loss = 0.694500744342804, train/raw-loss = 0.6914055347442627, train/logprobs = tensor([[-1.0107, -1.1571],
        [-1.2388, -1.0464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061905160546302795
Epoch 0, Step 1292: train/loss = 0.6970655918121338, train/raw-loss = 0.6957821846008301, train/logprobs = tensor([[-0.9319, -1.0653],
        [-0.9825, -0.9051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002566796727478504
Epoch 0, Step 1293: train/loss = 0.6964937448501587, train/raw-loss = 0.6962037086486816, train/logprobs = tensor([[-0.9216, -1.0861],
        [-0.8733, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005800870712846518
Epoch 0, Step 1294: train/loss = 0.7056329846382141, train/raw-loss = 0.7026454210281372, train/logprobs = tensor([[-1.0647, -1.4010],
        [-1.1359, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005975213833153248
Epoch 0, Step 1295: train/loss = 0.6912624835968018, train/raw-loss = 0.681060254573822, train/logprobs = tensor([[-1.1070, -1.4713],
        [-1.2464, -0.7959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020404573529958725
Epoch 0, Step 1296: train/loss = 0.6970405578613281, train/raw-loss = 0.693588376045227, train/logprobs = tensor([[-1.1837, -1.1413],
        [-1.2751, -1.0343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006904578302055597
Epoch 0, Step 1297: train/loss = 0.710096001625061, train/raw-loss = 0.7080686092376709, train/logprobs = tensor([[-1.0421, -1.2846],
        [-1.1040, -1.0899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004054867662489414
Epoch 0, Step 1298: train/loss = 0.6874092817306519, train/raw-loss = 0.6749133467674255, train/logprobs = tensor([[-0.8957, -1.3645],
        [-1.0777, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02499196119606495
Epoch 0, Step 1299: train/loss = 0.7093565464019775, train/raw-loss = 0.7081322073936462, train/logprobs = tensor([[-1.0290, -0.9388],
        [-1.0488, -0.7827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002448693849146366
Epoch 0, Step 1300: train/loss = 0.6937996745109558, train/raw-loss = 0.6937913298606873, train/logprobs = tensor([[-1.1549, -1.1649],
        [-1.0818, -1.0593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6632726328680292e-05
Epoch 0, Step 1301: train/loss = 0.7060331106185913, train/raw-loss = 0.7045542597770691, train/logprobs = tensor([[-1.0148, -1.2432],
        [-1.1403, -1.1031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002957746619358659
Epoch 0, Step 1302: train/loss = 0.71025550365448, train/raw-loss = 0.7035710215568542, train/logprobs = tensor([[-1.0231, -1.4013],
        [-1.1722, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013369008898735046
Epoch 0, Step 1303: train/loss = 0.6957998275756836, train/raw-loss = 0.6791505217552185, train/logprobs = tensor([[-1.0346, -1.7461],
        [-1.0119, -1.0228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03329864889383316
Epoch 0, Step 1304: train/loss = 0.6916753649711609, train/raw-loss = 0.6846376657485962, train/logprobs = tensor([[-0.8507, -1.2760],
        [-1.0073, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014075237326323986
Epoch 0, Step 1305: train/loss = 0.6957471966743469, train/raw-loss = 0.6946591138839722, train/logprobs = tensor([[-1.1088, -1.1377],
        [-0.7978, -0.9675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021762314718216658
Epoch 0, Step 1306: train/loss = 0.7021268010139465, train/raw-loss = 0.7006559371948242, train/logprobs = tensor([[-1.0217, -1.1031],
        [-1.1242, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029417460318654776
Epoch 0, Step 1307: train/loss = 0.6937187910079956, train/raw-loss = 0.6925479769706726, train/logprobs = tensor([[-1.2275, -1.3201],
        [-1.1242, -0.9780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002341586397960782
Epoch 0, Step 1308: train/loss = 0.6960387229919434, train/raw-loss = 0.6837086081504822, train/logprobs = tensor([[-0.9184, -1.5756],
        [-1.0528, -1.0199]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024660181254148483
Epoch 0, Step 1309: train/loss = 0.727567195892334, train/raw-loss = 0.7268934845924377, train/logprobs = tensor([[-1.1189, -0.8565],
        [-1.0985, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013472943101078272
Epoch 0, Step 1310: train/loss = 0.6938332915306091, train/raw-loss = 0.6849569082260132, train/logprobs = tensor([[-1.2479, -1.4267],
        [-1.0562, -0.9005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017752712592482567
Epoch 0, Step 1311: train/loss = 0.7031394243240356, train/raw-loss = 0.7009669542312622, train/logprobs = tensor([[-0.9780, -1.1403],
        [-1.0462, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0043447623029351234
Epoch 0, Step 1312: train/loss = 0.6924651265144348, train/raw-loss = 0.6917893886566162, train/logprobs = tensor([[-1.1472, -1.2077],
        [-1.3039, -1.0846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013514711754396558
Epoch 0, Step 1313: train/loss = 0.7398737668991089, train/raw-loss = 0.7364257574081421, train/logprobs = tensor([[-0.9446, -1.2481],
        [-1.1214, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006896066479384899
Epoch 0, Step 1314: train/loss = 0.709987223148346, train/raw-loss = 0.6969821453094482, train/logprobs = tensor([[-1.0849, -1.4976],
        [-1.3957, -1.3427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02601020783185959
Epoch 0, Step 1315: train/loss = 0.7010917663574219, train/raw-loss = 0.6983084678649902, train/logprobs = tensor([[-1.0988, -1.0115],
        [-1.0975, -0.7717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00556652806699276
Epoch 0, Step 1316: train/loss = 0.7232975959777832, train/raw-loss = 0.7136800289154053, train/logprobs = tensor([[-1.0496, -1.6245],
        [-1.2012, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019235113635659218
Epoch 0, Step 1317: train/loss = 0.6941114068031311, train/raw-loss = 0.6937041282653809, train/logprobs = tensor([[-1.2963, -1.2683],
        [-1.2097, -1.0123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008146258187480271
Epoch 0, Step 1318: train/loss = 0.6871954798698425, train/raw-loss = 0.6723977327346802, train/logprobs = tensor([[-0.9524, -1.3416],
        [-1.0558, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029595540836453438
Epoch 0, Step 1319: train/loss = 0.7053387761116028, train/raw-loss = 0.7047426104545593, train/logprobs = tensor([[-0.7865, -0.7466],
        [-0.7054, -0.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011923756683245301
Epoch 0, Step 1320: train/loss = 0.6946467161178589, train/raw-loss = 0.6939669251441956, train/logprobs = tensor([[-1.0837, -1.0784],
        [-1.0802, -0.9640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001359674846753478
Epoch 0, Step 1321: train/loss = 0.6894146203994751, train/raw-loss = 0.6835116147994995, train/logprobs = tensor([[-1.1723, -1.5556],
        [-1.2526, -1.0533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011805923655629158
Epoch 0, Step 1322: train/loss = 0.6975257992744446, train/raw-loss = 0.6953372359275818, train/logprobs = tensor([[-1.0895, -1.3945],
        [-1.2302, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004377143457531929
Epoch 0, Step 1323: train/loss = 0.6930196285247803, train/raw-loss = 0.6898892521858215, train/logprobs = tensor([[-0.9393, -1.0035],
        [-1.1668, -0.8024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00626092404127121
Epoch 0, Step 1324: train/loss = 0.6998308300971985, train/raw-loss = 0.6989078521728516, train/logprobs = tensor([[-1.1177, -1.1434],
        [-1.1424, -0.9403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018459456041455269
Epoch 0, Step 1325: train/loss = 0.6898946166038513, train/raw-loss = 0.6867508888244629, train/logprobs = tensor([[-1.0457, -1.1660],
        [-1.1584, -0.8697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006287422962486744
Epoch 0, Step 1326: train/loss = 0.6973772048950195, train/raw-loss = 0.6895372271537781, train/logprobs = tensor([[-1.0104, -1.0232],
        [-1.2701, -0.6975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015679847449064255
Epoch 0, Step 1327: train/loss = 0.6999713182449341, train/raw-loss = 0.6980665326118469, train/logprobs = tensor([[-0.9616, -0.8385],
        [-0.9694, -0.7900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003809711430221796
Epoch 0, Step 1328: train/loss = 0.6985539197921753, train/raw-loss = 0.6945586204528809, train/logprobs = tensor([[-0.9753, -1.3720],
        [-1.1300, -1.1118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007990671321749687
Epoch 0, Step 1329: train/loss = 0.692491888999939, train/raw-loss = 0.6865929365158081, train/logprobs = tensor([[-1.1969, -1.4577],
        [-1.5007, -1.2676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011797944083809853
Epoch 0, Step 1330: train/loss = 0.6976037621498108, train/raw-loss = 0.6900885701179504, train/logprobs = tensor([[-0.7637, -0.9533],
        [-0.9546, -0.7904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015030479989945889
Epoch 0, Step 1331: train/loss = 0.6978646516799927, train/raw-loss = 0.6944158673286438, train/logprobs = tensor([[-1.1866, -1.2611],
        [-1.2277, -0.9875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006897520739585161
Epoch 0, Step 1332: train/loss = 0.6950015425682068, train/raw-loss = 0.6908430457115173, train/logprobs = tensor([[-0.9883, -1.1716],
        [-1.1338, -1.0136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008316971361637115
Epoch 0, Step 1333: train/loss = 0.7324100732803345, train/raw-loss = 0.7223823070526123, train/logprobs = tensor([[-1.1505, -1.4530],
        [-1.3469, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020055530592799187
Epoch 0, Step 1334: train/loss = 0.7070189714431763, train/raw-loss = 0.7043923139572144, train/logprobs = tensor([[-1.0637, -1.2755],
        [-1.0024, -1.0032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005253272131085396
Epoch 0, Step 1335: train/loss = 0.6924198269844055, train/raw-loss = 0.6847952604293823, train/logprobs = tensor([[-1.1453, -1.5687],
        [-1.2468, -1.0084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015249070711433887
Epoch 0, Step 1336: train/loss = 0.7045496702194214, train/raw-loss = 0.7001803517341614, train/logprobs = tensor([[-0.9598, -1.2322],
        [-0.9852, -0.8582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008738595992326736
Epoch 0, Step 1337: train/loss = 0.7005620002746582, train/raw-loss = 0.6909300088882446, train/logprobs = tensor([[-1.0440, -1.4520],
        [-1.2758, -1.0881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01926400512456894
Epoch 0, Step 1338: train/loss = 0.7058047652244568, train/raw-loss = 0.7012545466423035, train/logprobs = tensor([[-1.2174, -1.2268],
        [-1.3891, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009100420400500298
Epoch 0, Step 1339: train/loss = 0.6929038166999817, train/raw-loss = 0.691601574420929, train/logprobs = tensor([[-1.1719, -1.2723],
        [-1.1613, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026044733822345734
Epoch 0, Step 1340: train/loss = 0.6916148066520691, train/raw-loss = 0.6821471452713013, train/logprobs = tensor([[-1.1047, -1.3375],
        [-1.0961, -0.9605]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018935345113277435
Epoch 0, Step 1341: train/loss = 0.708690881729126, train/raw-loss = 0.7067480087280273, train/logprobs = tensor([[-1.1331, -1.2479],
        [-1.1322, -0.9509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038856477476656437
Epoch 0, Step 1342: train/loss = 0.6968926787376404, train/raw-loss = 0.6951538920402527, train/logprobs = tensor([[-1.0219, -0.9749],
        [-1.2600, -1.1685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034774686209857464
Epoch 0, Step 1343: train/loss = 0.7019616365432739, train/raw-loss = 0.6991655826568604, train/logprobs = tensor([[-1.0476, -0.9666],
        [-1.1779, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005592026747763157
Epoch 0, Step 1344: train/loss = 0.7026773691177368, train/raw-loss = 0.7022457122802734, train/logprobs = tensor([[-1.0003, -1.0341],
        [-1.0961, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008632158860564232
Epoch 0, Step 1345: train/loss = 0.701372504234314, train/raw-loss = 0.6972686052322388, train/logprobs = tensor([[-0.7688, -1.1334],
        [-0.9358, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008207818493247032
Epoch 0, Step 1346: train/loss = 0.7139392495155334, train/raw-loss = 0.7127544283866882, train/logprobs = tensor([[-0.9979, -1.1999],
        [-1.2093, -1.1346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002369648078456521
Epoch 0, Step 1347: train/loss = 0.6954989433288574, train/raw-loss = 0.6906592845916748, train/logprobs = tensor([[-1.1101, -1.4092],
        [-1.3199, -1.1034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009679347276687622
Epoch 0, Step 1348: train/loss = 0.6919896006584167, train/raw-loss = 0.6890947222709656, train/logprobs = tensor([[-1.0965, -1.2945],
        [-1.1185, -1.0263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005789675284177065
Epoch 0, Step 1349: train/loss = 0.6983124017715454, train/raw-loss = 0.6971458196640015, train/logprobs = tensor([[-1.2697, -1.2280],
        [-1.1289, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023330734111368656
Epoch 0, Step 1350: train/loss = 0.7808536291122437, train/raw-loss = 0.7761150598526001, train/logprobs = tensor([[-1.2049, -2.0266],
        [-1.2701, -1.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009477093815803528
Epoch 0, Step 1351: train/loss = 0.6951573491096497, train/raw-loss = 0.6892759799957275, train/logprobs = tensor([[-0.9767, -1.0971],
        [-1.0056, -1.1412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011762790381908417
Epoch 0, Step 1352: train/loss = 0.7068554162979126, train/raw-loss = 0.6821953654289246, train/logprobs = tensor([[-1.0858, -1.8134],
        [-1.3890, -1.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04931999742984772
Epoch 0, Step 1353: train/loss = 0.7191296219825745, train/raw-loss = 0.7071933150291443, train/logprobs = tensor([[-0.7637, -1.3936],
        [-0.9829, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02387262135744095
Epoch 0, Step 1354: train/loss = 0.7018402814865112, train/raw-loss = 0.6975394487380981, train/logprobs = tensor([[-1.0879, -1.1445],
        [-1.0926, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0086015984416008
Epoch 0, Step 1355: train/loss = 0.7006233334541321, train/raw-loss = 0.6993415355682373, train/logprobs = tensor([[-0.9664, -0.9069],
        [-1.0972, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00256348610855639
Epoch 0, Step 1356: train/loss = 0.7161223292350769, train/raw-loss = 0.7093456387519836, train/logprobs = tensor([[-1.0521, -1.6993],
        [-1.0329, -1.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013553453609347343
Epoch 0, Step 1357: train/loss = 0.6969947814941406, train/raw-loss = 0.689516544342041, train/logprobs = tensor([[-1.0188, -1.3291],
        [-1.0174, -1.0250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014956660568714142
Epoch 0, Step 1358: train/loss = 0.6978720426559448, train/raw-loss = 0.6945231556892395, train/logprobs = tensor([[-1.0132, -1.0887],
        [-1.1211, -0.9089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006697833072394133
Epoch 0, Step 1359: train/loss = 0.6985722780227661, train/raw-loss = 0.6961178779602051, train/logprobs = tensor([[-0.9568, -0.9010],
        [-1.0488, -0.7284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004908902104943991
Epoch 0, Step 1360: train/loss = 0.6930525898933411, train/raw-loss = 0.6922315359115601, train/logprobs = tensor([[-1.1236, -1.1624],
        [-1.1626, -1.0465]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016421120380982757
Epoch 0, Step 1361: train/loss = 0.694173276424408, train/raw-loss = 0.6887208223342896, train/logprobs = tensor([[-1.0005, -1.1707],
        [-1.1496, -1.0150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01090490072965622
Epoch 0, Step 1362: train/loss = 0.7014691829681396, train/raw-loss = 0.6983774900436401, train/logprobs = tensor([[-1.0528, -1.4172],
        [-1.1277, -1.1960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0061832573264837265
Epoch 0, Step 1363: train/loss = 0.6977624893188477, train/raw-loss = 0.6907714605331421, train/logprobs = tensor([[-1.0769, -1.5289],
        [-1.2504, -1.2152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013982098549604416
Epoch 0, Step 1364: train/loss = 0.6823549866676331, train/raw-loss = 0.6739785075187683, train/logprobs = tensor([[-0.9777, -1.2311],
        [-1.2345, -0.9273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016752878203988075
Epoch 0, Step 1365: train/loss = 0.6997084021568298, train/raw-loss = 0.6989946961402893, train/logprobs = tensor([[-0.9349, -0.9569],
        [-0.9705, -0.8441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014274796703830361
Epoch 0, Step 1366: train/loss = 0.719468355178833, train/raw-loss = 0.7141332030296326, train/logprobs = tensor([[-1.0075, -1.2860],
        [-0.9611, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010670202784240246
Epoch 0, Step 1367: train/loss = 0.720844566822052, train/raw-loss = 0.7193467617034912, train/logprobs = tensor([[-1.0844, -1.4827],
        [-1.0919, -1.3608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029955715872347355
Epoch 0, Step 1368: train/loss = 0.6967066526412964, train/raw-loss = 0.6868743896484375, train/logprobs = tensor([[-0.9429, -1.3469],
        [-1.1870, -1.0219]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019664596766233444
Epoch 0, Step 1369: train/loss = 0.7174746990203857, train/raw-loss = 0.7018566131591797, train/logprobs = tensor([[-1.1301, -1.8524],
        [-1.3651, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03123602457344532
Epoch 0, Step 1370: train/loss = 0.6951309442520142, train/raw-loss = 0.6902673840522766, train/logprobs = tensor([[-1.1545, -1.4065],
        [-1.1405, -1.0070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009727159515023232
Epoch 0, Step 1371: train/loss = 0.7050977349281311, train/raw-loss = 0.6904540061950684, train/logprobs = tensor([[-0.9454, -1.4956],
        [-1.0486, -1.0100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0292874313890934
Epoch 0, Step 1372: train/loss = 0.7036623358726501, train/raw-loss = 0.702742874622345, train/logprobs = tensor([[-1.2165, -1.0790],
        [-1.1731, -1.1333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018389251781627536
Epoch 0, Step 1373: train/loss = 0.6953189373016357, train/raw-loss = 0.6947650909423828, train/logprobs = tensor([[-1.2679, -1.4015],
        [-1.2420, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011079541873186827
Epoch 0, Step 1374: train/loss = 0.6967294812202454, train/raw-loss = 0.6880031824111938, train/logprobs = tensor([[-1.1254, -1.1778],
        [-1.3077, -0.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01745246909558773
Epoch 0, Step 1375: train/loss = 0.7132006287574768, train/raw-loss = 0.7081377506256104, train/logprobs = tensor([[-0.9655, -0.8502],
        [-1.0953, -0.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010125657543540001
Epoch 0, Step 1376: train/loss = 0.6972450017929077, train/raw-loss = 0.6947320699691772, train/logprobs = tensor([[-1.1063, -1.1688],
        [-1.2079, -0.9455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005025708116590977
Epoch 0, Step 1377: train/loss = 0.7038403749465942, train/raw-loss = 0.6976428627967834, train/logprobs = tensor([[-1.0863, -1.3665],
        [-1.1803, -0.9319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01239493116736412
Epoch 0, Step 1378: train/loss = 0.6956119537353516, train/raw-loss = 0.6786249876022339, train/logprobs = tensor([[-0.9967, -1.3998],
        [-1.0570, -0.8004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03397396206855774
Epoch 0, Step 1379: train/loss = 0.7297552824020386, train/raw-loss = 0.7205874919891357, train/logprobs = tensor([[-1.3331, -1.0722],
        [-1.5518, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018335562199354172
Epoch 0, Step 1380: train/loss = 0.7021180391311646, train/raw-loss = 0.6979738473892212, train/logprobs = tensor([[-0.8845, -1.3193],
        [-0.9518, -1.0604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008288431912660599
Epoch 0, Step 1381: train/loss = 0.6983726620674133, train/raw-loss = 0.6968101263046265, train/logprobs = tensor([[-0.9881, -1.0972],
        [-0.9567, -0.8165]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031250512693077326
Epoch 0, Step 1382: train/loss = 0.6954541206359863, train/raw-loss = 0.6885249614715576, train/logprobs = tensor([[-1.0606, -1.3352],
        [-1.1069, -0.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013858241960406303
Epoch 0, Step 1383: train/loss = 0.700605571269989, train/raw-loss = 0.6984289884567261, train/logprobs = tensor([[-1.1377, -1.3142],
        [-1.0348, -1.0631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004353153053671122
Epoch 0, Step 1384: train/loss = 0.694333016872406, train/raw-loss = 0.6904951930046082, train/logprobs = tensor([[-0.8710, -1.0696],
        [-0.9374, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00767551502212882
Epoch 0, Step 1385: train/loss = 0.6941197514533997, train/raw-loss = 0.6912139654159546, train/logprobs = tensor([[-1.2539, -1.3386],
        [-1.1992, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005811522249132395
Epoch 0, Step 1386: train/loss = 0.6918291449546814, train/raw-loss = 0.6862421631813049, train/logprobs = tensor([[-1.1019, -1.4649],
        [-1.3470, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011173914186656475
Epoch 0, Step 1387: train/loss = 0.6934309601783752, train/raw-loss = 0.6894518136978149, train/logprobs = tensor([[-0.7866, -0.9062],
        [-0.8291, -0.6667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007958302274346352
Epoch 0, Step 1388: train/loss = 0.6977661848068237, train/raw-loss = 0.690184473991394, train/logprobs = tensor([[-0.8675, -1.5121],
        [-1.1578, -1.0917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015163339674472809
Epoch 0, Step 1389: train/loss = 0.7324737310409546, train/raw-loss = 0.7310590744018555, train/logprobs = tensor([[-1.0526, -1.4960],
        [-1.0480, -1.3198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028292560018599033
Epoch 0, Step 1390: train/loss = 0.695674479007721, train/raw-loss = 0.6942881345748901, train/logprobs = tensor([[-1.2417, -1.1099],
        [-1.0235, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027726890984922647
Epoch 0, Step 1391: train/loss = 0.6914302110671997, train/raw-loss = 0.688204288482666, train/logprobs = tensor([[-1.0945, -1.2399],
        [-1.0200, -0.8677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006451812107115984
Epoch 0, Step 1392: train/loss = 0.7078409790992737, train/raw-loss = 0.7042036652565002, train/logprobs = tensor([[-1.1381, -1.5306],
        [-1.2114, -1.2872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007274577394127846
Epoch 0, Step 1393: train/loss = 0.6934671401977539, train/raw-loss = 0.6904847621917725, train/logprobs = tensor([[-1.0580, -1.3639],
        [-1.1090, -1.0814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0059647513553500175
Epoch 0, Step 1394: train/loss = 0.6935302019119263, train/raw-loss = 0.6921859979629517, train/logprobs = tensor([[-1.0955, -1.2876],
        [-0.9852, -0.9666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026884195394814014
Epoch 0, Step 1395: train/loss = 0.733519971370697, train/raw-loss = 0.7275362610816956, train/logprobs = tensor([[-0.8777, -1.4534],
        [-0.9874, -1.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011967435479164124
Epoch 0, Step 1396: train/loss = 0.6981983184814453, train/raw-loss = 0.6977311372756958, train/logprobs = tensor([[-0.9193, -0.9271],
        [-0.9291, -0.8601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009343412821181118
Epoch 0, Step 1397: train/loss = 0.7110366821289062, train/raw-loss = 0.708052396774292, train/logprobs = tensor([[-1.0173, -1.5007],
        [-0.9350, -1.1403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005968554876744747
Epoch 0, Step 1398: train/loss = 0.7038876414299011, train/raw-loss = 0.6891087889671326, train/logprobs = tensor([[-1.0232, -1.6140],
        [-1.0195, -0.9248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029557853937149048
Epoch 0, Step 1399: train/loss = 0.6932450532913208, train/raw-loss = 0.690650224685669, train/logprobs = tensor([[-1.1833, -1.3967],
        [-1.1117, -1.1190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005189579911530018
Epoch 0, Step 1400: train/loss = 0.6995896100997925, train/raw-loss = 0.6967347264289856, train/logprobs = tensor([[-1.0202, -1.0848],
        [-0.9559, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0057098036631941795
Epoch 0, Step 1401: train/loss = 0.7041684985160828, train/raw-loss = 0.6999225616455078, train/logprobs = tensor([[-1.0890, -1.3273],
        [-1.2425, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008491914719343185
Epoch 0, Step 1402: train/loss = 0.7153543829917908, train/raw-loss = 0.711762547492981, train/logprobs = tensor([[-1.4144, -1.7196],
        [-1.2421, -1.3599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007183547597378492
Epoch 0, Step 1403: train/loss = 0.706066906452179, train/raw-loss = 0.7028294205665588, train/logprobs = tensor([[-0.9777, -1.3568],
        [-0.8850, -0.9521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006474890746176243
Epoch 0, Step 1404: train/loss = 0.7018607258796692, train/raw-loss = 0.7002569437026978, train/logprobs = tensor([[-1.0241, -1.0756],
        [-1.2769, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003207582514733076
Epoch 0, Step 1405: train/loss = 0.7015804052352905, train/raw-loss = 0.6985865831375122, train/logprobs = tensor([[-0.9213, -1.2633],
        [-1.1062, -1.1076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005987515673041344
Epoch 0, Step 1406: train/loss = 0.6962848901748657, train/raw-loss = 0.6888951063156128, train/logprobs = tensor([[-0.8316, -1.2886],
        [-0.9586, -0.8716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014779651537537575
Epoch 0, Step 1407: train/loss = 0.7078102827072144, train/raw-loss = 0.6987174153327942, train/logprobs = tensor([[-0.9725, -1.5961],
        [-1.1438, -1.1249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01818576455116272
Epoch 0, Step 1408: train/loss = 0.6941313743591309, train/raw-loss = 0.6926717162132263, train/logprobs = tensor([[-1.2287, -1.3003],
        [-1.2348, -1.1611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002919260412454605
Epoch 0, Step 1409: train/loss = 0.6945778131484985, train/raw-loss = 0.6846624612808228, train/logprobs = tensor([[-0.8784, -1.2464],
        [-1.0357, -0.8980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019830739125609398
Epoch 0, Step 1410: train/loss = 0.7020083665847778, train/raw-loss = 0.7004120945930481, train/logprobs = tensor([[-1.1004, -1.3737],
        [-1.1274, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031925649382174015
Epoch 0, Step 1411: train/loss = 0.6908160448074341, train/raw-loss = 0.6772671937942505, train/logprobs = tensor([[-0.9192, -1.2774],
        [-1.1761, -0.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027097593992948532
Epoch 0, Step 1412: train/loss = 0.7013391852378845, train/raw-loss = 0.7004927396774292, train/logprobs = tensor([[-1.0352, -1.2125],
        [-1.0989, -1.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016927714459598064
Epoch 0, Step 1413: train/loss = 0.6990081071853638, train/raw-loss = 0.6935561895370483, train/logprobs = tensor([[-1.0358, -1.2564],
        [-1.1983, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010903775691986084
Epoch 0, Step 1414: train/loss = 0.6963547468185425, train/raw-loss = 0.6759653091430664, train/logprobs = tensor([[-1.1042, -1.6379],
        [-1.1772, -1.0264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04077891260385513
Epoch 0, Step 1415: train/loss = 0.7020210027694702, train/raw-loss = 0.6974242329597473, train/logprobs = tensor([[-1.0059, -1.2260],
        [-0.9609, -0.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00919346883893013
Epoch 0, Step 1416: train/loss = 0.6871501207351685, train/raw-loss = 0.6777715682983398, train/logprobs = tensor([[-1.0328, -1.2144],
        [-1.1982, -0.8059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018756955862045288
Epoch 0, Step 1417: train/loss = 0.7055050134658813, train/raw-loss = 0.6913161277770996, train/logprobs = tensor([[-1.4248, -1.6581],
        [-1.0715, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02837768755853176
Epoch 0, Step 1418: train/loss = 0.7024788856506348, train/raw-loss = 0.691339910030365, train/logprobs = tensor([[-1.0332, -1.6493],
        [-1.0317, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022277941927313805
Epoch 0, Step 1419: train/loss = 0.7083154916763306, train/raw-loss = 0.7058422565460205, train/logprobs = tensor([[-1.1698, -1.5201],
        [-1.2933, -1.4347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004946406465023756
Epoch 0, Step 1420: train/loss = 0.6957846283912659, train/raw-loss = 0.693193793296814, train/logprobs = tensor([[-1.0592, -1.1367],
        [-1.1348, -0.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005181788466870785
Epoch 0, Step 1421: train/loss = 0.7001127600669861, train/raw-loss = 0.6964834928512573, train/logprobs = tensor([[-1.1277, -1.5145],
        [-1.1324, -1.0792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007258409634232521
Epoch 0, Step 1422: train/loss = 0.699375569820404, train/raw-loss = 0.6796351075172424, train/logprobs = tensor([[-1.2322, -1.4703],
        [-1.2334, -0.8559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03948091343045235
Epoch 0, Step 1423: train/loss = 0.7197098731994629, train/raw-loss = 0.7192032933235168, train/logprobs = tensor([[-1.0431, -1.3909],
        [-0.9594, -1.1502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00101317442022264
Epoch 0, Step 1424: train/loss = 0.7008382678031921, train/raw-loss = 0.6973205208778381, train/logprobs = tensor([[-0.8871, -1.2863],
        [-1.0176, -1.0485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007035480812191963
Epoch 0, Step 1425: train/loss = 0.7115997076034546, train/raw-loss = 0.7083288431167603, train/logprobs = tensor([[-1.0356, -1.3998],
        [-1.0294, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006541654001921415
Epoch 0, Step 1426: train/loss = 0.6990371942520142, train/raw-loss = 0.6903282403945923, train/logprobs = tensor([[-1.0236, -1.3232],
        [-1.0657, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01741802878677845
Epoch 0, Step 1427: train/loss = 0.7102278470993042, train/raw-loss = 0.7016438841819763, train/logprobs = tensor([[-1.3158, -1.6853],
        [-1.0427, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017167888581752777
Epoch 0, Step 1428: train/loss = 0.6879528760910034, train/raw-loss = 0.658943772315979, train/logprobs = tensor([[-1.2162, -1.6541],
        [-1.5660, -1.2491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058018285781145096
Epoch 0, Step 1429: train/loss = 0.6957604289054871, train/raw-loss = 0.686500072479248, train/logprobs = tensor([[-1.3785, -1.7302],
        [-1.0987, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018520819023251534
Epoch 0, Step 1430: train/loss = 0.7793101072311401, train/raw-loss = 0.7762686014175415, train/logprobs = tensor([[-1.0453, -1.7482],
        [-0.9939, -1.3535]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006082952953875065
Epoch 0, Step 1431: train/loss = 0.7753874063491821, train/raw-loss = 0.7742478847503662, train/logprobs = tensor([[-1.3874, -1.1590],
        [-1.6449, -1.1841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022790005896240473
Epoch 0, Step 1432: train/loss = 0.819208025932312, train/raw-loss = 0.7829625606536865, train/logprobs = tensor([[-1.1329, -2.4005],
        [-1.3735, -1.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07249089330434799
Epoch 0, Step 1433: train/loss = 0.7023866176605225, train/raw-loss = 0.6971303224563599, train/logprobs = tensor([[-1.1347, -1.4708],
        [-1.2146, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010512717999517918
Epoch 0, Step 1434: train/loss = 0.7116667628288269, train/raw-loss = 0.7077456712722778, train/logprobs = tensor([[-0.9524, -1.3591],
        [-1.2046, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007842284627258778
Epoch 0, Step 1435: train/loss = 0.7110936045646667, train/raw-loss = 0.7090156078338623, train/logprobs = tensor([[-1.0858, -1.2041],
        [-0.9853, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004155915230512619
Epoch 0, Step 1436: train/loss = 0.6943305134773254, train/raw-loss = 0.6935622096061707, train/logprobs = tensor([[-1.0906, -1.1517],
        [-1.0682, -1.0546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015367449959740043
Epoch 0, Step 1437: train/loss = 0.7121423482894897, train/raw-loss = 0.6826349496841431, train/logprobs = tensor([[-1.1413, -2.0091],
        [-1.2627, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05901486799120903
Epoch 0, Step 1438: train/loss = 0.6955834031105042, train/raw-loss = 0.6948552131652832, train/logprobs = tensor([[-1.1088, -1.5724],
        [-0.9315, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00145629420876503
Epoch 0, Step 1439: train/loss = 0.7030954360961914, train/raw-loss = 0.6933164000511169, train/logprobs = tensor([[-1.0794, -1.7329],
        [-1.2006, -1.2741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019558193162083626
Epoch 0, Step 1440: train/loss = 0.6859947443008423, train/raw-loss = 0.6734867691993713, train/logprobs = tensor([[-0.8260, -1.2690],
        [-1.1020, -0.8442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02501594088971615
Epoch 0, Step 1441: train/loss = 0.6956833600997925, train/raw-loss = 0.695042610168457, train/logprobs = tensor([[-0.9639, -1.0586],
        [-1.0088, -1.0317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012815409572795033
Epoch 0, Step 1442: train/loss = 0.697079598903656, train/raw-loss = 0.6945832967758179, train/logprobs = tensor([[-1.0090, -1.1661],
        [-1.2088, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00499252462759614
Epoch 0, Step 1443: train/loss = 0.6982212066650391, train/raw-loss = 0.6914166212081909, train/logprobs = tensor([[-1.0701, -1.1658],
        [-1.2973, -0.8975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0136092659085989
Epoch 0, Step 1444: train/loss = 0.7012742161750793, train/raw-loss = 0.7009506225585938, train/logprobs = tensor([[-1.0895, -1.0615],
        [-0.8514, -0.7568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006471380474977195
Epoch 0, Step 1445: train/loss = 0.6920303106307983, train/raw-loss = 0.6882023215293884, train/logprobs = tensor([[-0.9048, -1.0737],
        [-0.9624, -0.8043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0076560815796256065
Epoch 0, Step 1446: train/loss = 0.7006656527519226, train/raw-loss = 0.6809064149856567, train/logprobs = tensor([[-1.0140, -1.6037],
        [-1.1745, -0.8746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03951847553253174
Epoch 0, Step 1447: train/loss = 0.7181360721588135, train/raw-loss = 0.7134611010551453, train/logprobs = tensor([[-1.1941, -1.5966],
        [-1.0308, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009349944069981575
Epoch 0, Step 1448: train/loss = 0.6934653520584106, train/raw-loss = 0.6898500919342041, train/logprobs = tensor([[-0.8096, -0.9785],
        [-0.9392, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007230568211525679
Epoch 0, Step 1449: train/loss = 0.6963878870010376, train/raw-loss = 0.6950440406799316, train/logprobs = tensor([[-1.0666, -1.0040],
        [-1.1781, -0.9848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026876740157604218
Epoch 0, Step 1450: train/loss = 0.7161266803741455, train/raw-loss = 0.7152124047279358, train/logprobs = tensor([[-1.0170, -0.8562],
        [-1.1408, -0.8394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018286090344190598
Epoch 0, Step 1451: train/loss = 0.6924343109130859, train/raw-loss = 0.685547947883606, train/logprobs = tensor([[-1.1000, -1.4359],
        [-1.1859, -1.0428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013772649690508842
Epoch 0, Step 1452: train/loss = 0.7020587921142578, train/raw-loss = 0.6991502046585083, train/logprobs = tensor([[-1.0627, -1.1678],
        [-1.0657, -0.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005817018449306488
Epoch 0, Step 1453: train/loss = 0.692844569683075, train/raw-loss = 0.6925445795059204, train/logprobs = tensor([[-0.9180, -1.0615],
        [-1.0292, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005999190034344792
Epoch 0, Step 1454: train/loss = 0.697931706905365, train/raw-loss = 0.6914041638374329, train/logprobs = tensor([[-1.1095, -1.2796],
        [-1.1243, -0.7902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013054905459284782
Epoch 0, Step 1455: train/loss = 0.6897494792938232, train/raw-loss = 0.6855951547622681, train/logprobs = tensor([[-0.9886, -1.3762],
        [-1.1676, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008308567106723785
Epoch 0, Step 1456: train/loss = 0.7107426524162292, train/raw-loss = 0.7080492377281189, train/logprobs = tensor([[-1.3859, -1.3011],
        [-1.4676, -1.1264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005386800970882177
Epoch 0, Step 1457: train/loss = 0.7028026580810547, train/raw-loss = 0.692042350769043, train/logprobs = tensor([[-1.1101, -1.4947],
        [-1.1674, -0.9469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0215207040309906
Epoch 0, Step 1458: train/loss = 0.699683427810669, train/raw-loss = 0.6923470497131348, train/logprobs = tensor([[-1.0722, -1.3692],
        [-1.1781, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014672842808067799
Epoch 0, Step 1459: train/loss = 0.6946223974227905, train/raw-loss = 0.6890712380409241, train/logprobs = tensor([[-0.8772, -1.1864],
        [-1.1758, -1.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01110246405005455
Epoch 0, Step 1460: train/loss = 0.6950700879096985, train/raw-loss = 0.6925051212310791, train/logprobs = tensor([[-0.9465, -1.0359],
        [-0.9801, -0.8469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005129887256771326
Epoch 0, Step 1461: train/loss = 0.7002415060997009, train/raw-loss = 0.6891635060310364, train/logprobs = tensor([[-1.1206, -1.3698],
        [-1.3089, -1.0982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022155920043587685
Epoch 0, Step 1462: train/loss = 0.6981987357139587, train/raw-loss = 0.6965287923812866, train/logprobs = tensor([[-1.0698, -1.3221],
        [-1.1264, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00333979120478034
Epoch 0, Step 1463: train/loss = 0.7025331854820251, train/raw-loss = 0.6977920532226562, train/logprobs = tensor([[-1.1954, -1.3202],
        [-1.2700, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009482317604124546
Epoch 0, Step 1464: train/loss = 0.6927061676979065, train/raw-loss = 0.6835904121398926, train/logprobs = tensor([[-1.0826, -1.2284],
        [-1.2008, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01823151484131813
Epoch 0, Step 1465: train/loss = 0.7685248851776123, train/raw-loss = 0.7586514353752136, train/logprobs = tensor([[-1.0853, -1.8555],
        [-1.2054, -1.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01974700763821602
Epoch 0, Step 1466: train/loss = 0.6903353929519653, train/raw-loss = 0.6805583238601685, train/logprobs = tensor([[-0.9433, -1.3927],
        [-1.2368, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019554156810045242
Epoch 0, Step 1467: train/loss = 0.7475277185440063, train/raw-loss = 0.7289572954177856, train/logprobs = tensor([[-1.0515, -1.7771],
        [-1.3060, -1.2484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0371408686041832
Epoch 0, Step 1468: train/loss = 0.6983616352081299, train/raw-loss = 0.6923345923423767, train/logprobs = tensor([[-1.1542, -1.5169],
        [-1.0203, -1.0079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012054063379764557
Epoch 0, Step 1469: train/loss = 0.7010056376457214, train/raw-loss = 0.6944596767425537, train/logprobs = tensor([[-0.8352, -1.3720],
        [-1.0943, -1.0599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013091814704239368
Epoch 0, Step 1470: train/loss = 0.7012397050857544, train/raw-loss = 0.689220666885376, train/logprobs = tensor([[-1.0484, -1.3188],
        [-1.2537, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024038009345531464
Epoch 0, Step 1471: train/loss = 0.752244234085083, train/raw-loss = 0.7399699687957764, train/logprobs = tensor([[-0.8856, -1.7581],
        [-0.9286, -1.3947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024548513814806938
Epoch 0, Step 1472: train/loss = 0.7007397413253784, train/raw-loss = 0.6981738209724426, train/logprobs = tensor([[-1.0890, -1.1261],
        [-1.0847, -0.9656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005131849087774754
Epoch 0, Step 1473: train/loss = 0.6983333826065063, train/raw-loss = 0.6900341510772705, train/logprobs = tensor([[-1.2033, -1.2937],
        [-1.4249, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016598450019955635
Epoch 0, Step 1474: train/loss = 0.6933245062828064, train/raw-loss = 0.6908088326454163, train/logprobs = tensor([[-1.0917, -1.1777],
        [-1.1974, -1.0536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005031316541135311
Epoch 0, Step 1475: train/loss = 0.6962170600891113, train/raw-loss = 0.6959877610206604, train/logprobs = tensor([[-1.0886, -1.1613],
        [-1.0791, -1.0239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045856600627303123
Epoch 0, Step 1476: train/loss = 0.6969770789146423, train/raw-loss = 0.6935089230537415, train/logprobs = tensor([[-1.1429, -1.3314],
        [-1.4406, -1.3960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006936290301382542
Epoch 0, Step 1477: train/loss = 0.702892541885376, train/raw-loss = 0.6953178644180298, train/logprobs = tensor([[-1.0823, -1.2368],
        [-1.1568, -0.7759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015149393118917942
Epoch 0, Step 1478: train/loss = 0.6978068947792053, train/raw-loss = 0.6941255331039429, train/logprobs = tensor([[-0.8185, -0.9521],
        [-1.0547, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007362721022218466
Epoch 0, Step 1479: train/loss = 0.6919489502906799, train/raw-loss = 0.6780399680137634, train/logprobs = tensor([[-1.0167, -1.3203],
        [-1.2369, -0.9387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02781798131763935
Epoch 0, Step 1480: train/loss = 0.6898667812347412, train/raw-loss = 0.6851935982704163, train/logprobs = tensor([[-1.3025, -1.6434],
        [-1.3416, -1.2150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009346303530037403
Epoch 0, Step 1481: train/loss = 0.6976342797279358, train/raw-loss = 0.6858302354812622, train/logprobs = tensor([[-1.1466, -1.4249],
        [-1.1972, -0.9241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023608095943927765
Epoch 0, Step 1482: train/loss = 0.6996666789054871, train/raw-loss = 0.6973366141319275, train/logprobs = tensor([[-1.0862, -1.0278],
        [-1.2008, -0.9851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004660072736442089
Epoch 0, Step 1483: train/loss = 0.7213848829269409, train/raw-loss = 0.7081255316734314, train/logprobs = tensor([[-1.0388, -1.3014],
        [-1.1847, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02651873789727688
Epoch 0, Step 1484: train/loss = 0.7110271453857422, train/raw-loss = 0.6878876090049744, train/logprobs = tensor([[-1.0950, -1.7432],
        [-1.2740, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04627900570631027
Epoch 0, Step 1485: train/loss = 0.6927289962768555, train/raw-loss = 0.6814156174659729, train/logprobs = tensor([[-0.9477, -1.4070],
        [-1.3063, -1.1627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022626742720603943
Epoch 0, Step 1486: train/loss = 0.6976083517074585, train/raw-loss = 0.6929264664649963, train/logprobs = tensor([[-0.8974, -1.0998],
        [-1.1247, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009363695047795773
Epoch 0, Step 1487: train/loss = 0.6926913857460022, train/raw-loss = 0.6904322504997253, train/logprobs = tensor([[-1.1304, -1.2228],
        [-1.1901, -1.0111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00451823603361845
Epoch 0, Step 1488: train/loss = 0.6994140148162842, train/raw-loss = 0.6967394351959229, train/logprobs = tensor([[-0.9313, -1.1431],
        [-1.0226, -0.9501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005349102430045605
Epoch 0, Step 1489: train/loss = 0.6974990367889404, train/raw-loss = 0.6961848735809326, train/logprobs = tensor([[-1.0811, -1.2797],
        [-1.3396, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002628361340612173
Epoch 0, Step 1490: train/loss = 0.6950522065162659, train/raw-loss = 0.6877570152282715, train/logprobs = tensor([[-0.9533, -1.1691],
        [-1.2661, -1.1227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014590419828891754
Epoch 0, Step 1491: train/loss = 0.6916583776473999, train/raw-loss = 0.6844190359115601, train/logprobs = tensor([[-1.2180, -1.4325],
        [-1.3155, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014478594996035099
Epoch 0, Step 1492: train/loss = 0.700217604637146, train/raw-loss = 0.6986863613128662, train/logprobs = tensor([[-0.9108, -1.1543],
        [-0.9422, -1.0726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003062546020373702
Epoch 0, Step 1493: train/loss = 0.6994622945785522, train/raw-loss = 0.6944670081138611, train/logprobs = tensor([[-1.2233, -1.7252],
        [-1.4671, -1.4953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009990651160478592
Epoch 0, Step 1494: train/loss = 0.6932951807975769, train/raw-loss = 0.686572790145874, train/logprobs = tensor([[-0.9475, -1.1526],
        [-1.2271, -0.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013444904237985611
Epoch 0, Step 1495: train/loss = 0.6965572834014893, train/raw-loss = 0.6874256730079651, train/logprobs = tensor([[-1.2254, -1.4076],
        [-1.3844, -0.9655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018263205885887146
Epoch 0, Step 1496: train/loss = 0.6964373588562012, train/raw-loss = 0.6862553358078003, train/logprobs = tensor([[-1.0824, -1.2039],
        [-1.1670, -0.8504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02036396786570549
Epoch 0, Step 1497: train/loss = 0.6931020617485046, train/raw-loss = 0.6920853853225708, train/logprobs = tensor([[-0.8719, -1.0763],
        [-1.0365, -0.9279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020333295688033104
Epoch 0, Step 1498: train/loss = 0.6888018250465393, train/raw-loss = 0.6676445007324219, train/logprobs = tensor([[-0.9315, -1.3872],
        [-1.3705, -1.0862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04231461137533188
Epoch 0, Step 1499: train/loss = 0.6918725967407227, train/raw-loss = 0.690475583076477, train/logprobs = tensor([[-1.0671, -1.2896],
        [-1.0579, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002794112777337432
eval/loss: 0.7003447413444519
Epoch 0, Step 1500: train/loss = 0.6912553310394287, train/raw-loss = 0.6731579899787903, train/logprobs = tensor([[-1.0897, -1.7504],
        [-1.0332, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03619462996721268
Epoch 0, Step 1501: train/loss = 0.6949620246887207, train/raw-loss = 0.6929790377616882, train/logprobs = tensor([[-1.1980, -1.3608],
        [-1.1857, -1.0848]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0039659831672906876
Epoch 0, Step 1502: train/loss = 0.7029381990432739, train/raw-loss = 0.702049970626831, train/logprobs = tensor([[-0.9003, -1.1283],
        [-0.9590, -1.0688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017763993237167597
Epoch 0, Step 1503: train/loss = 0.6993231773376465, train/raw-loss = 0.6846219301223755, train/logprobs = tensor([[-1.1280, -1.5622],
        [-1.1617, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029402613639831543
Epoch 0, Step 1504: train/loss = 0.6935730576515198, train/raw-loss = 0.6910946369171143, train/logprobs = tensor([[-0.9603, -1.0890],
        [-0.9492, -0.7974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004956865683197975
Epoch 0, Step 1505: train/loss = 0.6936843395233154, train/raw-loss = 0.6924334764480591, train/logprobs = tensor([[-1.0384, -1.1610],
        [-1.1706, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025017575826495886
Epoch 0, Step 1506: train/loss = 0.6924290657043457, train/raw-loss = 0.6899054646492004, train/logprobs = tensor([[-1.2258, -1.3120],
        [-1.1869, -0.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005047251470386982
Epoch 0, Step 1507: train/loss = 0.6931713819503784, train/raw-loss = 0.6911236643791199, train/logprobs = tensor([[-0.8695, -0.9535],
        [-1.0002, -0.8693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040953210555016994
Epoch 0, Step 1508: train/loss = 0.695632815361023, train/raw-loss = 0.694085419178009, train/logprobs = tensor([[-1.0045, -1.0925],
        [-1.0616, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003094898769631982
Epoch 0, Step 1509: train/loss = 0.6958568692207336, train/raw-loss = 0.6952900886535645, train/logprobs = tensor([[-0.9536, -0.9572],
        [-1.0812, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011336312163621187
Epoch 0, Step 1510: train/loss = 0.7038968205451965, train/raw-loss = 0.7021284103393555, train/logprobs = tensor([[-1.2377, -1.1832],
        [-1.2106, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035367892123758793
Epoch 0, Step 1511: train/loss = 0.6884918212890625, train/raw-loss = 0.673337459564209, train/logprobs = tensor([[-1.0439, -1.2612],
        [-1.3066, -0.8286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030308591201901436
Epoch 0, Step 1512: train/loss = 0.6944571733474731, train/raw-loss = 0.6855216026306152, train/logprobs = tensor([[-0.9992, -1.1279],
        [-1.2305, -0.9340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01787116937339306
Epoch 0, Step 1513: train/loss = 0.6936655640602112, train/raw-loss = 0.693022608757019, train/logprobs = tensor([[-1.1811, -1.1588],
        [-1.1312, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001285889302380383
Epoch 0, Step 1514: train/loss = 0.6896819472312927, train/raw-loss = 0.6762117743492126, train/logprobs = tensor([[-0.9188, -1.3082],
        [-1.1115, -0.8676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02694034017622471
Epoch 0, Step 1515: train/loss = 0.7154387831687927, train/raw-loss = 0.6924090385437012, train/logprobs = tensor([[-1.0318, -1.9644],
        [-1.2919, -1.3502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0460595041513443
Epoch 0, Step 1516: train/loss = 0.7199153900146484, train/raw-loss = 0.7114810943603516, train/logprobs = tensor([[-1.0839, -1.2831],
        [-1.3042, -1.0453]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01686856523156166
Epoch 0, Step 1517: train/loss = 0.6986545324325562, train/raw-loss = 0.6974799633026123, train/logprobs = tensor([[-1.0174, -0.8819],
        [-1.2036, -0.9110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023492546752095222
Epoch 0, Step 1518: train/loss = 0.6978193521499634, train/raw-loss = 0.6931406855583191, train/logprobs = tensor([[-1.0541, -1.3814],
        [-1.1850, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009357190690934658
Epoch 0, Step 1519: train/loss = 0.6959826946258545, train/raw-loss = 0.6957789659500122, train/logprobs = tensor([[-0.9729, -0.9811],
        [-0.9995, -0.9297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004075380275025964
Epoch 0, Step 1520: train/loss = 0.6954638361930847, train/raw-loss = 0.6926161050796509, train/logprobs = tensor([[-1.2798, -1.3728],
        [-1.3235, -1.1458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005695389583706856
Epoch 0, Step 1521: train/loss = 0.6999585628509521, train/raw-loss = 0.6852635741233826, train/logprobs = tensor([[-1.0786, -1.3712],
        [-1.1656, -1.1486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029389865696430206
Epoch 0, Step 1522: train/loss = 0.6902804374694824, train/raw-loss = 0.6836850643157959, train/logprobs = tensor([[-0.9460, -1.0901],
        [-1.2784, -0.9928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013190656900405884
Epoch 0, Step 1523: train/loss = 0.6983693838119507, train/raw-loss = 0.6932305097579956, train/logprobs = tensor([[-0.9593, -1.2201],
        [-1.1957, -0.9723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010277578607201576
Epoch 0, Step 1524: train/loss = 0.6913307905197144, train/raw-loss = 0.6882343292236328, train/logprobs = tensor([[-0.9851, -1.1670],
        [-1.2021, -1.0232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006192860659211874
Epoch 0, Step 1525: train/loss = 0.7093433141708374, train/raw-loss = 0.7066477537155151, train/logprobs = tensor([[-0.9812, -1.3018],
        [-1.1207, -1.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005391142796725035
Epoch 0, Step 1526: train/loss = 0.7201918959617615, train/raw-loss = 0.7147840261459351, train/logprobs = tensor([[-1.2641, -1.6694],
        [-1.3084, -1.4228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010815679095685482
Epoch 0, Step 1527: train/loss = 0.6924503445625305, train/raw-loss = 0.6825081706047058, train/logprobs = tensor([[-1.1449, -1.2111],
        [-1.3698, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019884252920746803
Epoch 0, Step 1528: train/loss = 0.7041566371917725, train/raw-loss = 0.7026558518409729, train/logprobs = tensor([[-1.1606, -1.4370],
        [-1.1766, -1.2309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003001682460308075
Epoch 0, Step 1529: train/loss = 0.6972606778144836, train/raw-loss = 0.6940247416496277, train/logprobs = tensor([[-1.2861, -1.4234],
        [-1.3317, -1.0172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006471896544098854
Epoch 0, Step 1530: train/loss = 0.7081537842750549, train/raw-loss = 0.7023428678512573, train/logprobs = tensor([[-0.8539, -1.0997],
        [-0.8599, -0.8151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011621843092143536
Epoch 0, Step 1531: train/loss = 0.6988909244537354, train/raw-loss = 0.6969608068466187, train/logprobs = tensor([[-1.0255, -1.1982],
        [-1.0882, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003860123222693801
Epoch 0, Step 1532: train/loss = 0.7074565887451172, train/raw-loss = 0.7028565406799316, train/logprobs = tensor([[-1.3244, -1.1157],
        [-1.2848, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009200027212500572
Epoch 0, Step 1533: train/loss = 0.6976873874664307, train/raw-loss = 0.6927282810211182, train/logprobs = tensor([[-0.9279, -1.0762],
        [-1.0697, -0.8497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009918109513819218
Epoch 0, Step 1534: train/loss = 0.7093945145606995, train/raw-loss = 0.7032956480979919, train/logprobs = tensor([[-1.0959, -1.0207],
        [-1.4343, -0.9648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012197703123092651
Epoch 0, Step 1535: train/loss = 0.6968914866447449, train/raw-loss = 0.6893189549446106, train/logprobs = tensor([[-1.1155, -1.2415],
        [-1.2995, -1.0147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01514509692788124
Epoch 0, Step 1536: train/loss = 0.6934072375297546, train/raw-loss = 0.6931230425834656, train/logprobs = tensor([[-0.9455, -0.9985],
        [-1.0121, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005682414630427957
Epoch 0, Step 1537: train/loss = 0.6975304484367371, train/raw-loss = 0.697206437587738, train/logprobs = tensor([[-1.2833, -1.4364],
        [-1.1148, -1.1890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006480616866610944
Epoch 0, Step 1538: train/loss = 0.7133222222328186, train/raw-loss = 0.7124629020690918, train/logprobs = tensor([[-1.2538, -1.0793],
        [-1.2135, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017185885226354003
Epoch 0, Step 1539: train/loss = 0.6923763751983643, train/raw-loss = 0.6912851333618164, train/logprobs = tensor([[-0.9913, -1.0522],
        [-0.9761, -0.8551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021825572475790977
Epoch 0, Step 1540: train/loss = 0.6954139471054077, train/raw-loss = 0.6939610242843628, train/logprobs = tensor([[-1.1746, -1.3094],
        [-1.2996, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002905935514718294
Epoch 0, Step 1541: train/loss = 0.6932032704353333, train/raw-loss = 0.684708833694458, train/logprobs = tensor([[-1.1351, -1.1677],
        [-1.3200, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01698886603116989
Epoch 0, Step 1542: train/loss = 0.6988615989685059, train/raw-loss = 0.6982291340827942, train/logprobs = tensor([[-1.4557, -1.4372],
        [-1.5504, -1.3736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012649467680603266
Epoch 0, Step 1543: train/loss = 0.6927410960197449, train/raw-loss = 0.678654670715332, train/logprobs = tensor([[-1.0970, -1.4724],
        [-1.3478, -1.2076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028172871097922325
Epoch 0, Step 1544: train/loss = 0.7124096155166626, train/raw-loss = 0.707434892654419, train/logprobs = tensor([[-0.9437, -1.0237],
        [-1.0733, -0.8354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009949631989002228
Epoch 0, Step 1545: train/loss = 0.6972646117210388, train/raw-loss = 0.6934784650802612, train/logprobs = tensor([[-1.0009, -1.2035],
        [-1.2891, -1.0576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0075722383335232735
Epoch 0, Step 1546: train/loss = 0.6985313296318054, train/raw-loss = 0.698210597038269, train/logprobs = tensor([[-0.9462, -1.1568],
        [-1.1190, -1.2142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006416081450879574
Epoch 0, Step 1547: train/loss = 0.7126324772834778, train/raw-loss = 0.71134352684021, train/logprobs = tensor([[-1.0267, -0.8668],
        [-1.1904, -0.7904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025778762064874172
Epoch 0, Step 1548: train/loss = 0.6940566301345825, train/raw-loss = 0.6936324834823608, train/logprobs = tensor([[-1.0325, -1.0760],
        [-1.0833, -1.0900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008482272969558835
Epoch 0, Step 1549: train/loss = 0.681445837020874, train/raw-loss = 0.675098180770874, train/logprobs = tensor([[-1.0359, -1.4620],
        [-1.2114, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012695425190031528
Epoch 0, Step 1550: train/loss = 0.7005453109741211, train/raw-loss = 0.6965796947479248, train/logprobs = tensor([[-0.9420, -1.1844],
        [-1.0350, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007931234315037727
Epoch 0, Step 1551: train/loss = 0.7031545042991638, train/raw-loss = 0.6959918737411499, train/logprobs = tensor([[-1.0165, -1.3267],
        [-1.1527, -1.0616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01432525273412466
Epoch 0, Step 1552: train/loss = 0.7007814645767212, train/raw-loss = 0.6952501535415649, train/logprobs = tensor([[-1.0837, -1.2844],
        [-1.4145, -1.1083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011062586680054665
Epoch 0, Step 1553: train/loss = 0.7038427591323853, train/raw-loss = 0.6989187598228455, train/logprobs = tensor([[-1.1374, -0.9803],
        [-1.3433, -0.9434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009847981855273247
Epoch 0, Step 1554: train/loss = 0.705997884273529, train/raw-loss = 0.7048860192298889, train/logprobs = tensor([[-1.0406, -1.1179],
        [-1.1780, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002223803661763668
Epoch 0, Step 1555: train/loss = 0.7150520086288452, train/raw-loss = 0.7023200988769531, train/logprobs = tensor([[-0.9080, -1.2740],
        [-1.3146, -0.9430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025463754311203957
Epoch 0, Step 1556: train/loss = 0.6925379037857056, train/raw-loss = 0.6867387294769287, train/logprobs = tensor([[-1.1886, -1.3865],
        [-1.3961, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011598458513617516
Epoch 0, Step 1557: train/loss = 0.6883111596107483, train/raw-loss = 0.6849883794784546, train/logprobs = tensor([[-0.9115, -1.2555],
        [-1.2761, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006645729299634695
Epoch 0, Step 1558: train/loss = 0.693949818611145, train/raw-loss = 0.6830679178237915, train/logprobs = tensor([[-1.0481, -1.3207],
        [-1.6287, -1.1402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021763725206255913
Epoch 0, Step 1559: train/loss = 0.694672703742981, train/raw-loss = 0.6917034983634949, train/logprobs = tensor([[-0.9450, -1.2209],
        [-1.4467, -1.0990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005938374903053045
Epoch 0, Step 1560: train/loss = 0.6966440677642822, train/raw-loss = 0.6957085728645325, train/logprobs = tensor([[-0.9420, -1.1156],
        [-0.9967, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018710073782131076
Epoch 0, Step 1561: train/loss = 0.6992961168289185, train/raw-loss = 0.689877986907959, train/logprobs = tensor([[-1.0736, -1.4341],
        [-1.2728, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018836162984371185
Epoch 0, Step 1562: train/loss = 0.6997276544570923, train/raw-loss = 0.6980988383293152, train/logprobs = tensor([[-1.1243, -1.2420],
        [-0.9789, -0.8779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003257481846958399
Epoch 0, Step 1563: train/loss = 0.6939528584480286, train/raw-loss = 0.6824137568473816, train/logprobs = tensor([[-1.0034, -1.2206],
        [-1.5719, -1.1322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023078136146068573
Epoch 0, Step 1564: train/loss = 0.6949750185012817, train/raw-loss = 0.6886786222457886, train/logprobs = tensor([[-1.1839, -1.2254],
        [-1.2906, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012592676095664501
Epoch 0, Step 1565: train/loss = 0.7077369689941406, train/raw-loss = 0.7066473960876465, train/logprobs = tensor([[-1.1622, -1.5583],
        [-1.2948, -1.4437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021791798062622547
Epoch 0, Step 1566: train/loss = 0.7005857229232788, train/raw-loss = 0.6975915431976318, train/logprobs = tensor([[-0.8812, -1.1936],
        [-0.9424, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00598844513297081
Epoch 0, Step 1567: train/loss = 0.6977064609527588, train/raw-loss = 0.697060227394104, train/logprobs = tensor([[-1.0627, -1.0496],
        [-1.0652, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012924512848258018
Epoch 0, Step 1568: train/loss = 0.7181718349456787, train/raw-loss = 0.7094601988792419, train/logprobs = tensor([[-1.3486, -1.3608],
        [-1.9002, -1.3006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017423372715711594
Epoch 0, Step 1569: train/loss = 0.6989932060241699, train/raw-loss = 0.6964311599731445, train/logprobs = tensor([[-1.1494, -1.1778],
        [-1.5266, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005124070681631565
Epoch 0, Step 1570: train/loss = 0.6889348030090332, train/raw-loss = 0.6818720698356628, train/logprobs = tensor([[-1.0991, -1.3458],
        [-1.2335, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014125386252999306
Epoch 0, Step 1571: train/loss = 0.6953890919685364, train/raw-loss = 0.6933681964874268, train/logprobs = tensor([[-1.0419, -0.9890],
        [-1.2962, -1.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004041831474751234
Epoch 0, Step 1572: train/loss = 0.6943833827972412, train/raw-loss = 0.693803071975708, train/logprobs = tensor([[-1.0952, -1.1003],
        [-1.1517, -0.9920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011604978935793042
Epoch 0, Step 1573: train/loss = 0.6903582811355591, train/raw-loss = 0.685276448726654, train/logprobs = tensor([[-1.0056, -1.2525],
        [-1.2389, -1.0700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010163743048906326
Epoch 0, Step 1574: train/loss = 0.7103925347328186, train/raw-loss = 0.7086001634597778, train/logprobs = tensor([[-1.1024, -1.4347],
        [-0.9504, -1.0215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003584772814065218
Epoch 0, Step 1575: train/loss = 0.6914156675338745, train/raw-loss = 0.688938558101654, train/logprobs = tensor([[-1.1049, -1.2825],
        [-1.4643, -1.2895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004954303614795208
Epoch 0, Step 1576: train/loss = 0.6961812376976013, train/raw-loss = 0.6939133405685425, train/logprobs = tensor([[-0.9718, -0.9609],
        [-1.3915, -1.1539]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004535812884569168
Epoch 0, Step 1577: train/loss = 0.6922152042388916, train/raw-loss = 0.6877623796463013, train/logprobs = tensor([[-1.1807, -1.3255],
        [-1.2210, -1.1186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008905623108148575
Epoch 0, Step 1578: train/loss = 0.6986303329467773, train/raw-loss = 0.6926583051681519, train/logprobs = tensor([[-1.3199, -1.4559],
        [-1.6320, -1.5546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011944125406444073
Epoch 0, Step 1579: train/loss = 0.7073897123336792, train/raw-loss = 0.6992589831352234, train/logprobs = tensor([[-1.0526, -1.4074],
        [-1.3967, -1.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01626148819923401
Epoch 0, Step 1580: train/loss = 0.7345559000968933, train/raw-loss = 0.7261576652526855, train/logprobs = tensor([[-1.1633, -1.0770],
        [-1.5792, -1.0987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016796547919511795
Epoch 0, Step 1581: train/loss = 0.6986778974533081, train/raw-loss = 0.6977581977844238, train/logprobs = tensor([[-1.1397, -1.1082],
        [-1.2435, -1.0548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018394638318568468
Epoch 0, Step 1582: train/loss = 0.6949197053909302, train/raw-loss = 0.6863449811935425, train/logprobs = tensor([[-1.1778, -1.3086],
        [-1.4251, -1.0563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017149532213807106
Epoch 0, Step 1583: train/loss = 0.7043642997741699, train/raw-loss = 0.6985465288162231, train/logprobs = tensor([[-0.9846, -0.8910],
        [-1.2602, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011635534465312958
Epoch 0, Step 1584: train/loss = 0.7315084338188171, train/raw-loss = 0.7215518951416016, train/logprobs = tensor([[-1.0524, -1.2834],
        [-1.4450, -1.1508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01991301402449608
Epoch 0, Step 1585: train/loss = 0.6897101402282715, train/raw-loss = 0.6762022972106934, train/logprobs = tensor([[-0.8648, -1.2089],
        [-1.2968, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02701587602496147
Epoch 0, Step 1586: train/loss = 0.6990323662757874, train/raw-loss = 0.6971316337585449, train/logprobs = tensor([[-1.1551, -1.1774],
        [-1.3761, -1.1439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038013083394616842
Epoch 0, Step 1587: train/loss = 0.6935449838638306, train/raw-loss = 0.6890000104904175, train/logprobs = tensor([[-1.0214, -1.0374],
        [-1.3854, -1.1893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009089929983019829
Epoch 0, Step 1588: train/loss = 0.6797485947608948, train/raw-loss = 0.6669960021972656, train/logprobs = tensor([[-1.1508, -1.4316],
        [-1.3983, -1.0164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025505106896162033
Epoch 0, Step 1589: train/loss = 0.6955884099006653, train/raw-loss = 0.692954421043396, train/logprobs = tensor([[-1.2024, -1.1754],
        [-1.2817, -1.1105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005267994944006205
Epoch 0, Step 1590: train/loss = 0.7008678317070007, train/raw-loss = 0.7006881237030029, train/logprobs = tensor([[-1.0231, -0.9310],
        [-1.1767, -1.0768]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035937922075390816
Epoch 0, Step 1591: train/loss = 0.6946322917938232, train/raw-loss = 0.6940356492996216, train/logprobs = tensor([[-1.0799, -1.0231],
        [-1.1764, -1.0677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011934516951441765
Epoch 0, Step 1592: train/loss = 0.7110127210617065, train/raw-loss = 0.707807183265686, train/logprobs = tensor([[-0.9562, -1.2583],
        [-1.1701, -1.1690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006411106791347265
Epoch 0, Step 1593: train/loss = 0.7032191157341003, train/raw-loss = 0.6846882104873657, train/logprobs = tensor([[-1.0213, -1.5424],
        [-1.4366, -1.1434]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03706175833940506
Epoch 0, Step 1594: train/loss = 0.6938993334770203, train/raw-loss = 0.6923514604568481, train/logprobs = tensor([[-0.9937, -1.0386],
        [-1.1747, -1.0352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003095662919804454
Epoch 0, Step 1595: train/loss = 0.7033983469009399, train/raw-loss = 0.691570520401001, train/logprobs = tensor([[-1.0204, -1.0696],
        [-1.5426, -0.9192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023655734956264496
Epoch 0, Step 1596: train/loss = 0.6977007985115051, train/raw-loss = 0.6920104622840881, train/logprobs = tensor([[-1.0291, -1.2177],
        [-1.3095, -1.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011380789801478386
Epoch 0, Step 1597: train/loss = 0.6943730711936951, train/raw-loss = 0.6916555762290955, train/logprobs = tensor([[-1.0589, -1.1022],
        [-1.1723, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005434971768409014
Epoch 0, Step 1598: train/loss = 0.712935745716095, train/raw-loss = 0.7079663276672363, train/logprobs = tensor([[-1.1595, -1.1248],
        [-1.3123, -0.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00993888359516859
Epoch 0, Step 1599: train/loss = 0.6963363885879517, train/raw-loss = 0.6955248117446899, train/logprobs = tensor([[-0.9415, -0.9195],
        [-1.1453, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016230177134275436
Epoch 0, Step 1600: train/loss = 0.6942428350448608, train/raw-loss = 0.6850090026855469, train/logprobs = tensor([[-1.1467, -1.3786],
        [-1.4517, -1.2551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01846758835017681
Epoch 0, Step 1601: train/loss = 0.6955115795135498, train/raw-loss = 0.6948912143707275, train/logprobs = tensor([[-0.9214, -0.8193],
        [-0.9939, -0.7283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001240779529325664
Epoch 0, Step 1602: train/loss = 0.6956146359443665, train/raw-loss = 0.6955631375312805, train/logprobs = tensor([[-1.1035, -1.1156],
        [-0.9979, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010303349699825048
Epoch 0, Step 1603: train/loss = 0.7003253698348999, train/raw-loss = 0.691063642501831, train/logprobs = tensor([[-1.1920, -1.1762],
        [-1.3773, -1.0158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018523424863815308
Epoch 0, Step 1604: train/loss = 0.7037967443466187, train/raw-loss = 0.6974349021911621, train/logprobs = tensor([[-1.1007, -1.5103],
        [-1.2694, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012723616324365139
Epoch 0, Step 1605: train/loss = 0.6890548467636108, train/raw-loss = 0.6881251335144043, train/logprobs = tensor([[-1.0270, -1.1499],
        [-1.0840, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018593802815303206
Epoch 0, Step 1606: train/loss = 0.6950540542602539, train/raw-loss = 0.693105936050415, train/logprobs = tensor([[-1.1170, -1.1775],
        [-1.2426, -1.1217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003896235954016447
Epoch 0, Step 1607: train/loss = 0.7123644948005676, train/raw-loss = 0.7062938809394836, train/logprobs = tensor([[-1.1142, -1.4006],
        [-1.3357, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012141174636781216
Epoch 0, Step 1608: train/loss = 0.9494648575782776, train/raw-loss = 0.9293437004089355, train/logprobs = tensor([[-0.7835, -2.2630],
        [-1.3372, -1.6515]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04024235159158707
Epoch 0, Step 1609: train/loss = 0.6930989027023315, train/raw-loss = 0.6888482570648193, train/logprobs = tensor([[-1.2706, -1.3721],
        [-1.4919, -1.2001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008501213043928146
Epoch 0, Step 1610: train/loss = 0.7009536027908325, train/raw-loss = 0.6933715343475342, train/logprobs = tensor([[-0.8490, -0.9233],
        [-1.2012, -0.8863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015164200216531754
Epoch 0, Step 1611: train/loss = 0.6945148706436157, train/raw-loss = 0.6941876411437988, train/logprobs = tensor([[-1.1303, -1.1723],
        [-1.0939, -1.1210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006543792551383376
Epoch 0, Step 1612: train/loss = 0.6960880160331726, train/raw-loss = 0.6945057511329651, train/logprobs = tensor([[-1.2761, -1.3601],
        [-1.2166, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031645288690924644
Epoch 0, Step 1613: train/loss = 0.6939465999603271, train/raw-loss = 0.6895381212234497, train/logprobs = tensor([[-1.1239, -1.1426],
        [-1.2570, -1.0800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008816897869110107
Epoch 0, Step 1614: train/loss = 0.7057164311408997, train/raw-loss = 0.6992415189743042, train/logprobs = tensor([[-1.2377, -1.1393],
        [-1.4555, -0.9799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012949837371706963
Epoch 0, Step 1615: train/loss = 0.7446672320365906, train/raw-loss = 0.742695689201355, train/logprobs = tensor([[-1.1800, -1.0637],
        [-1.4095, -1.1618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003943026531487703
Epoch 0, Step 1616: train/loss = 0.6956684589385986, train/raw-loss = 0.6847051978111267, train/logprobs = tensor([[-1.0825, -1.3315],
        [-1.2430, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02192641980946064
Epoch 0, Step 1617: train/loss = 0.692258894443512, train/raw-loss = 0.6775106191635132, train/logprobs = tensor([[-1.0194, -1.1948],
        [-1.3572, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029496602714061737
Epoch 0, Step 1618: train/loss = 0.7069658637046814, train/raw-loss = 0.7066401839256287, train/logprobs = tensor([[-1.0524, -1.1496],
        [-1.2575, -1.1923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006513374391943216
Epoch 0, Step 1619: train/loss = 0.7016285061836243, train/raw-loss = 0.6964571475982666, train/logprobs = tensor([[-1.0356, -1.3299],
        [-1.1890, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01034274697303772
Epoch 0, Step 1620: train/loss = 0.6952837705612183, train/raw-loss = 0.6896982192993164, train/logprobs = tensor([[-0.9203, -1.0893],
        [-1.1596, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011171061545610428
Epoch 0, Step 1621: train/loss = 0.6939090490341187, train/raw-loss = 0.6911540031433105, train/logprobs = tensor([[-1.5154, -1.5456],
        [-1.3469, -1.1309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005510025657713413
Epoch 0, Step 1622: train/loss = 0.7008573412895203, train/raw-loss = 0.690894603729248, train/logprobs = tensor([[-0.9034, -1.2891],
        [-1.2139, -1.1421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019925493746995926
Epoch 0, Step 1623: train/loss = 0.6926240921020508, train/raw-loss = 0.6911656260490417, train/logprobs = tensor([[-0.9182, -1.0122],
        [-1.0071, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029169898480176926
Epoch 0, Step 1624: train/loss = 0.7042505145072937, train/raw-loss = 0.6968947649002075, train/logprobs = tensor([[-1.0752, -1.0513],
        [-1.5345, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014711611904203892
Epoch 0, Step 1625: train/loss = 0.6982405185699463, train/raw-loss = 0.6957067251205444, train/logprobs = tensor([[-1.1980, -1.1838],
        [-1.3207, -1.0426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005067639984190464
Epoch 0, Step 1626: train/loss = 0.7106812000274658, train/raw-loss = 0.7087424397468567, train/logprobs = tensor([[-1.2182, -1.3408],
        [-1.4613, -1.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003877445124089718
Epoch 0, Step 1627: train/loss = 0.6953851580619812, train/raw-loss = 0.6892302632331848, train/logprobs = tensor([[-1.1842, -1.2171],
        [-1.5113, -1.0944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012309803627431393
Epoch 0, Step 1628: train/loss = 0.6963556408882141, train/raw-loss = 0.6958881616592407, train/logprobs = tensor([[-0.8712, -0.8279],
        [-0.9368, -0.8566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009348388994112611
Epoch 0, Step 1629: train/loss = 0.6962757110595703, train/raw-loss = 0.6945422887802124, train/logprobs = tensor([[-0.9275, -1.1843],
        [-1.2295, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034668785519897938
Epoch 0, Step 1630: train/loss = 0.6938682198524475, train/raw-loss = 0.6844866871833801, train/logprobs = tensor([[-1.0730, -1.2493],
        [-1.4803, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018763026222586632
Epoch 0, Step 1631: train/loss = 0.6984286308288574, train/raw-loss = 0.6940441727638245, train/logprobs = tensor([[-1.3377, -1.5186],
        [-1.6294, -1.4707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008768945932388306
Epoch 0, Step 1632: train/loss = 0.6997025609016418, train/raw-loss = 0.6980366110801697, train/logprobs = tensor([[-1.1340, -1.2405],
        [-1.2547, -1.0871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033318859059363604
Epoch 0, Step 1633: train/loss = 0.6953415870666504, train/raw-loss = 0.694401204586029, train/logprobs = tensor([[-1.2396, -1.1818],
        [-1.4443, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018809057073667645
Epoch 0, Step 1634: train/loss = 0.6897122859954834, train/raw-loss = 0.6875636577606201, train/logprobs = tensor([[-1.0356, -1.1891],
        [-1.1449, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004297174979001284
Epoch 0, Step 1635: train/loss = 0.7013526558876038, train/raw-loss = 0.6996973752975464, train/logprobs = tensor([[-1.1589, -0.9942],
        [-1.2853, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033106261398643255
Epoch 0, Step 1636: train/loss = 0.7029888033866882, train/raw-loss = 0.6987515687942505, train/logprobs = tensor([[-1.2512, -1.1736],
        [-1.4562, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008474426344037056
Epoch 0, Step 1637: train/loss = 0.715961754322052, train/raw-loss = 0.714723527431488, train/logprobs = tensor([[-1.2839, -1.1849],
        [-1.3438, -0.9093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002476481255143881
Epoch 0, Step 1638: train/loss = 0.7139058709144592, train/raw-loss = 0.7025860548019409, train/logprobs = tensor([[-0.9331, -1.3643],
        [-1.0901, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02263939566910267
Epoch 0, Step 1639: train/loss = 0.6943610906600952, train/raw-loss = 0.6935803890228271, train/logprobs = tensor([[-1.0971, -1.0255],
        [-1.1475, -1.0488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015612472780048847
Epoch 0, Step 1640: train/loss = 0.7289810180664062, train/raw-loss = 0.7286736965179443, train/logprobs = tensor([[-1.1392, -1.0251],
        [-1.2270, -0.9696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006145911756902933
Epoch 0, Step 1641: train/loss = 0.7146676182746887, train/raw-loss = 0.7144231200218201, train/logprobs = tensor([[-1.1875, -1.1234],
        [-1.1087, -1.0036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004889374831691384
Epoch 0, Step 1642: train/loss = 0.7051558494567871, train/raw-loss = 0.6953991055488586, train/logprobs = tensor([[-1.1683, -1.4548],
        [-1.4026, -1.1636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019513489678502083
Epoch 0, Step 1643: train/loss = 0.6947246789932251, train/raw-loss = 0.6887582540512085, train/logprobs = tensor([[-1.1174, -1.3280],
        [-1.1969, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011932636611163616
Epoch 0, Step 1644: train/loss = 0.7018315196037292, train/raw-loss = 0.6883240342140198, train/logprobs = tensor([[-0.9679, -1.6842],
        [-1.4079, -1.2928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027014857158064842
Epoch 0, Step 1645: train/loss = 0.7150720357894897, train/raw-loss = 0.7126905918121338, train/logprobs = tensor([[-0.9191, -1.2708],
        [-1.0812, -1.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004762711934745312
Epoch 0, Step 1646: train/loss = 0.6978282928466797, train/raw-loss = 0.6946703791618347, train/logprobs = tensor([[-1.1837, -1.3975],
        [-1.3102, -1.2627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006315779406577349
Epoch 0, Step 1647: train/loss = 0.6900234222412109, train/raw-loss = 0.6781463623046875, train/logprobs = tensor([[-1.0400, -1.3980],
        [-1.3770, -1.1538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023754224181175232
Epoch 0, Step 1648: train/loss = 0.705958366394043, train/raw-loss = 0.6998186111450195, train/logprobs = tensor([[-1.0479, -1.0649],
        [-1.4854, -1.1139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012279557064175606
Epoch 0, Step 1649: train/loss = 0.688910961151123, train/raw-loss = 0.6735632419586182, train/logprobs = tensor([[-1.0215, -1.3179],
        [-1.4973, -0.9526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03069552220404148
Epoch 0, Step 1650: train/loss = 0.6963607668876648, train/raw-loss = 0.6939538717269897, train/logprobs = tensor([[-0.9850, -1.0219],
        [-1.1028, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004813769366592169
Epoch 0, Step 1651: train/loss = 0.7073780298233032, train/raw-loss = 0.7032321691513062, train/logprobs = tensor([[-1.2871, -1.1755],
        [-1.3659, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0082918182015419
Epoch 0, Step 1652: train/loss = 0.6972938776016235, train/raw-loss = 0.6858269572257996, train/logprobs = tensor([[-1.1883, -1.5218],
        [-1.4508, -1.1828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0229338426142931
Epoch 0, Step 1653: train/loss = 0.7038756608963013, train/raw-loss = 0.7021398544311523, train/logprobs = tensor([[-1.1899, -1.2541],
        [-1.3551, -1.2378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034717570524662733
Epoch 0, Step 1654: train/loss = 0.6956206560134888, train/raw-loss = 0.6897075176239014, train/logprobs = tensor([[-1.0512, -1.3132],
        [-1.3509, -1.0575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011826330795884132
Epoch 0, Step 1655: train/loss = 0.7100248336791992, train/raw-loss = 0.7035179138183594, train/logprobs = tensor([[-1.2796, -1.7955],
        [-1.3813, -1.4245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01301379781216383
Epoch 0, Step 1656: train/loss = 0.6978957653045654, train/raw-loss = 0.6955713033676147, train/logprobs = tensor([[-1.2572, -1.4505],
        [-1.3794, -1.3289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004649024922400713
Epoch 0, Step 1657: train/loss = 0.6894774436950684, train/raw-loss = 0.6790766716003418, train/logprobs = tensor([[-1.0844, -1.3726],
        [-1.1881, -0.9428]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020801562815904617
Epoch 0, Step 1658: train/loss = 0.6938595175743103, train/raw-loss = 0.6918125748634338, train/logprobs = tensor([[-1.0928, -1.1069],
        [-1.2042, -0.9787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004093778319656849
Epoch 0, Step 1659: train/loss = 0.7173726558685303, train/raw-loss = 0.7094261050224304, train/logprobs = tensor([[-0.9975, -1.4423],
        [-1.3518, -1.1370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015893030911684036
Epoch 0, Step 1660: train/loss = 0.6983475685119629, train/raw-loss = 0.6958043575286865, train/logprobs = tensor([[-0.9305, -1.0872],
        [-1.0748, -1.0685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005086229648441076
Epoch 0, Step 1661: train/loss = 0.6979187726974487, train/raw-loss = 0.6978211402893066, train/logprobs = tensor([[-1.0430, -1.2305],
        [-1.1351, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019534805323928595
Epoch 0, Step 1662: train/loss = 0.6943004131317139, train/raw-loss = 0.6888565421104431, train/logprobs = tensor([[-1.1134, -1.4198],
        [-1.2013, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010887774638831615
Epoch 0, Step 1663: train/loss = 0.7529734373092651, train/raw-loss = 0.7458823919296265, train/logprobs = tensor([[-1.1014, -1.8226],
        [-1.2693, -1.4233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014182147569954395
Epoch 0, Step 1664: train/loss = 0.7010307908058167, train/raw-loss = 0.6887791156768799, train/logprobs = tensor([[-1.0782, -1.5059],
        [-1.4455, -1.2471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024503180757164955
Epoch 0, Step 1665: train/loss = 0.6928319334983826, train/raw-loss = 0.6881728172302246, train/logprobs = tensor([[-1.1810, -1.3568],
        [-1.3147, -1.2102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009318246506154537
Epoch 0, Step 1666: train/loss = 0.6927204132080078, train/raw-loss = 0.6910731792449951, train/logprobs = tensor([[-1.2511, -1.2610],
        [-1.4179, -1.2528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003294479101896286
Epoch 0, Step 1667: train/loss = 0.7046085000038147, train/raw-loss = 0.7007157206535339, train/logprobs = tensor([[-1.0651, -1.3350],
        [-1.0733, -1.1136]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007785494904965162
Epoch 0, Step 1668: train/loss = 0.709488034248352, train/raw-loss = 0.7078511714935303, train/logprobs = tensor([[-1.1150, -1.3798],
        [-1.2668, -1.3706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003273692913353443
Epoch 0, Step 1669: train/loss = 0.6903994083404541, train/raw-loss = 0.6850030422210693, train/logprobs = tensor([[-1.1698, -1.3478],
        [-1.4126, -1.1513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010792793706059456
Epoch 0, Step 1670: train/loss = 0.7025929093360901, train/raw-loss = 0.6918283104896545, train/logprobs = tensor([[-1.2575, -1.4054],
        [-1.6317, -1.1497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021529221907258034
Epoch 0, Step 1671: train/loss = 0.693526566028595, train/raw-loss = 0.682482123374939, train/logprobs = tensor([[-1.2485, -1.5582],
        [-1.5214, -1.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022089017555117607
Epoch 0, Step 1672: train/loss = 0.6951736211776733, train/raw-loss = 0.6944700479507446, train/logprobs = tensor([[-0.9165, -1.0382],
        [-0.8939, -0.8755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001407045405358076
Epoch 0, Step 1673: train/loss = 0.6950117349624634, train/raw-loss = 0.6946204900741577, train/logprobs = tensor([[-1.2369, -1.1789],
        [-1.4954, -1.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007826106157153845
Epoch 0, Step 1674: train/loss = 0.6944779753684998, train/raw-loss = 0.6926681995391846, train/logprobs = tensor([[-1.0624, -1.2266],
        [-1.1170, -1.0755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003619404276832938
Epoch 0, Step 1675: train/loss = 0.7017645835876465, train/raw-loss = 0.6960045099258423, train/logprobs = tensor([[-0.9102, -1.3435],
        [-1.1192, -1.1398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01152019016444683
Epoch 0, Step 1676: train/loss = 0.6915055513381958, train/raw-loss = 0.6887466907501221, train/logprobs = tensor([[-1.2649, -1.3956],
        [-1.2764, -1.1305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005517810583114624
Epoch 0, Step 1677: train/loss = 0.6989513635635376, train/raw-loss = 0.6949368715286255, train/logprobs = tensor([[-1.0571, -1.3207],
        [-1.2751, -1.2853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008029092103242874
Epoch 0, Step 1678: train/loss = 0.6998058557510376, train/raw-loss = 0.6969585418701172, train/logprobs = tensor([[-1.0879, -1.3546],
        [-1.1717, -1.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005694691091775894
Epoch 0, Step 1679: train/loss = 0.7020975351333618, train/raw-loss = 0.699463963508606, train/logprobs = tensor([[-1.1678, -1.0664],
        [-1.1676, -0.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0052672200836241245
Epoch 0, Step 1680: train/loss = 0.6943573951721191, train/raw-loss = 0.6912314891815186, train/logprobs = tensor([[-1.1562, -1.1992],
        [-1.3891, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062517086043953896
Epoch 0, Step 1681: train/loss = 0.6995493769645691, train/raw-loss = 0.6989330649375916, train/logprobs = tensor([[-1.1323, -1.1863],
        [-1.0474, -0.9818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012327416334301233
Epoch 0, Step 1682: train/loss = 0.6925545930862427, train/raw-loss = 0.6922327280044556, train/logprobs = tensor([[-1.1387, -1.1997],
        [-1.2000, -0.9505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006438037380576134
Epoch 0, Step 1683: train/loss = 0.6994978189468384, train/raw-loss = 0.6974232196807861, train/logprobs = tensor([[-1.1070, -1.3676],
        [-1.1247, -1.0924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004149272106587887
Epoch 0, Step 1684: train/loss = 0.7187608480453491, train/raw-loss = 0.7104592323303223, train/logprobs = tensor([[-1.2739, -1.5251],
        [-1.5500, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01660328172147274
Epoch 0, Step 1685: train/loss = 0.6969783306121826, train/raw-loss = 0.6944057941436768, train/logprobs = tensor([[-0.9809, -0.9484],
        [-1.2262, -0.9857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005145094357430935
Epoch 0, Step 1686: train/loss = 0.6968808174133301, train/raw-loss = 0.6962401270866394, train/logprobs = tensor([[-1.1939, -1.2918],
        [-1.2352, -1.1658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012814055662602186
Epoch 0, Step 1687: train/loss = 0.7042639255523682, train/raw-loss = 0.7033679485321045, train/logprobs = tensor([[-1.2659, -1.2336],
        [-1.2217, -1.0113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017919973470270634
Epoch 0, Step 1688: train/loss = 0.6925211548805237, train/raw-loss = 0.6912216544151306, train/logprobs = tensor([[-1.2119, -1.3324],
        [-1.2715, -1.1119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025990891736000776
Epoch 0, Step 1689: train/loss = 0.6920055150985718, train/raw-loss = 0.6844534873962402, train/logprobs = tensor([[-1.2027, -1.5054],
        [-1.4386, -1.2548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015104066580533981
Epoch 0, Step 1690: train/loss = 0.711518406867981, train/raw-loss = 0.6920314431190491, train/logprobs = tensor([[-0.9915, -1.5865],
        [-1.3438, -1.2975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038973916321992874
Epoch 0, Step 1691: train/loss = 0.7039722204208374, train/raw-loss = 0.6924052834510803, train/logprobs = tensor([[-1.0249, -1.2672],
        [-1.2079, -0.8563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02313394844532013
Epoch 0, Step 1692: train/loss = 0.6957929134368896, train/raw-loss = 0.6954956650733948, train/logprobs = tensor([[-1.0916, -1.2292],
        [-1.1372, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005943947471678257
Epoch 0, Step 1693: train/loss = 0.7185251712799072, train/raw-loss = 0.7161256074905396, train/logprobs = tensor([[-1.0278, -1.2643],
        [-1.3404, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004799052141606808
Epoch 0, Step 1694: train/loss = 0.7017897367477417, train/raw-loss = 0.7002788782119751, train/logprobs = tensor([[-1.2112, -1.2269],
        [-1.2561, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030217375606298447
Epoch 0, Step 1695: train/loss = 0.698949933052063, train/raw-loss = 0.6907585859298706, train/logprobs = tensor([[-1.1338, -1.4777],
        [-1.3121, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01638268120586872
Epoch 0, Step 1696: train/loss = 0.6936956644058228, train/raw-loss = 0.6936855912208557, train/logprobs = tensor([[-1.0209, -1.0366],
        [-1.0939, -1.0790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0109437173232436e-05
Epoch 0, Step 1697: train/loss = 0.6977787613868713, train/raw-loss = 0.6911453008651733, train/logprobs = tensor([[-1.2978, -1.2466],
        [-1.5140, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013266870751976967
Epoch 0, Step 1698: train/loss = 0.6949509382247925, train/raw-loss = 0.6942835450172424, train/logprobs = tensor([[-1.0744, -1.2475],
        [-1.3479, -1.3812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001334846019744873
Epoch 0, Step 1699: train/loss = 0.7019574642181396, train/raw-loss = 0.7011458873748779, train/logprobs = tensor([[-1.2081, -1.4083],
        [-1.2609, -1.2694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016231685876846313
Epoch 0, Step 1700: train/loss = 0.6963276267051697, train/raw-loss = 0.6957318782806396, train/logprobs = tensor([[-1.0403, -1.2255],
        [-1.0085, -1.1051]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011914465576410294
Epoch 0, Step 1701: train/loss = 0.7074859142303467, train/raw-loss = 0.7006199359893799, train/logprobs = tensor([[-1.1100, -1.8451],
        [-1.3942, -1.3976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013731845654547215
Epoch 0, Step 1702: train/loss = 0.7461953163146973, train/raw-loss = 0.740415096282959, train/logprobs = tensor([[-0.9557, -1.4936],
        [-1.0497, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011560576036572456
Epoch 0, Step 1703: train/loss = 0.6995624303817749, train/raw-loss = 0.6956671476364136, train/logprobs = tensor([[-1.1496, -1.4329],
        [-1.2332, -1.0925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007790593896061182
Epoch 0, Step 1704: train/loss = 0.6976051330566406, train/raw-loss = 0.6959810256958008, train/logprobs = tensor([[-1.0567, -1.1558],
        [-1.2212, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032483316026628017
Epoch 0, Step 1705: train/loss = 0.7066503763198853, train/raw-loss = 0.7031617760658264, train/logprobs = tensor([[-1.2798, -1.0822],
        [-1.4050, -1.0131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006977067794650793
Epoch 0, Step 1706: train/loss = 0.6941885948181152, train/raw-loss = 0.6916081309318542, train/logprobs = tensor([[-1.1993, -1.4412],
        [-1.3387, -1.2580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005160896573215723
Epoch 0, Step 1707: train/loss = 0.7054502964019775, train/raw-loss = 0.6876845359802246, train/logprobs = tensor([[-1.0742, -1.4867],
        [-1.2461, -1.1146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0355314202606678
Epoch 0, Step 1708: train/loss = 0.8315544128417969, train/raw-loss = 0.8257111310958862, train/logprobs = tensor([[-1.3891, -1.1993],
        [-1.4966, -0.8936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011686417274177074
Epoch 0, Step 1709: train/loss = 0.6984487175941467, train/raw-loss = 0.6847913265228271, train/logprobs = tensor([[-1.1560, -1.6333],
        [-1.4627, -1.3664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027314800769090652
Epoch 0, Step 1710: train/loss = 0.7136151790618896, train/raw-loss = 0.7023997902870178, train/logprobs = tensor([[-1.2883, -1.3836],
        [-1.5968, -1.0475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02243083342909813
Epoch 0, Step 1711: train/loss = 0.6999468207359314, train/raw-loss = 0.6967329978942871, train/logprobs = tensor([[-1.0944, -1.2160],
        [-1.2669, -1.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006427624728530645
Epoch 0, Step 1712: train/loss = 0.7308515310287476, train/raw-loss = 0.7253908514976501, train/logprobs = tensor([[-1.0751, -1.2185],
        [-1.2984, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010921238921582699
Epoch 0, Step 1713: train/loss = 0.7008570432662964, train/raw-loss = 0.6880661845207214, train/logprobs = tensor([[-1.1363, -1.4686],
        [-1.4157, -1.2500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025581782683730125
Epoch 0, Step 1714: train/loss = 0.7224182486534119, train/raw-loss = 0.7165424227714539, train/logprobs = tensor([[-1.0558, -1.2905],
        [-1.2430, -1.0868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011751688085496426
Epoch 0, Step 1715: train/loss = 0.6908280849456787, train/raw-loss = 0.6810657978057861, train/logprobs = tensor([[-1.1875, -1.3897],
        [-1.3542, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019524604082107544
Epoch 0, Step 1716: train/loss = 0.6933522820472717, train/raw-loss = 0.6870438456535339, train/logprobs = tensor([[-1.1944, -1.1722],
        [-1.5522, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012616937048733234
Epoch 0, Step 1717: train/loss = 0.6935006380081177, train/raw-loss = 0.6747007966041565, train/logprobs = tensor([[-1.1921, -1.5726],
        [-1.5914, -1.0849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037599846720695496
Epoch 0, Step 1718: train/loss = 0.7088133692741394, train/raw-loss = 0.7085309624671936, train/logprobs = tensor([[-1.4213, -1.3119],
        [-1.6307, -1.3982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005646508652716875
Epoch 0, Step 1719: train/loss = 0.6911228895187378, train/raw-loss = 0.6888042092323303, train/logprobs = tensor([[-1.1570, -1.3290],
        [-1.1381, -0.9990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004637238569557667
Epoch 0, Step 1720: train/loss = 0.695604681968689, train/raw-loss = 0.6954509019851685, train/logprobs = tensor([[-1.1166, -1.1757],
        [-1.1134, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003074997803196311
Epoch 0, Step 1721: train/loss = 0.6932581663131714, train/raw-loss = 0.690698504447937, train/logprobs = tensor([[-1.0917, -1.1409],
        [-1.2998, -1.1752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0051193335093557835
Epoch 0, Step 1722: train/loss = 0.6938636898994446, train/raw-loss = 0.690522313117981, train/logprobs = tensor([[-1.2027, -1.4287],
        [-1.2372, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006682847160845995
Epoch 0, Step 1723: train/loss = 0.6982296705245972, train/raw-loss = 0.679985523223877, train/logprobs = tensor([[-1.0081, -1.3656],
        [-1.3821, -1.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0364883616566658
Epoch 0, Step 1724: train/loss = 0.6998809576034546, train/raw-loss = 0.6974843740463257, train/logprobs = tensor([[-1.0858, -1.0359],
        [-1.2291, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004793107975274324
Epoch 0, Step 1725: train/loss = 0.6973690986633301, train/raw-loss = 0.677270233631134, train/logprobs = tensor([[-1.2648, -1.6880],
        [-1.7250, -1.3576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040197763592004776
Epoch 0, Step 1726: train/loss = 0.6996418237686157, train/raw-loss = 0.6990760564804077, train/logprobs = tensor([[-1.0554, -1.1440],
        [-1.1435, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011315743904560804
Epoch 0, Step 1727: train/loss = 0.6941375136375427, train/raw-loss = 0.6898424029350281, train/logprobs = tensor([[-1.0386, -1.1451],
        [-1.1898, -1.0742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008590190671384335
Epoch 0, Step 1728: train/loss = 0.6973896026611328, train/raw-loss = 0.6958032250404358, train/logprobs = tensor([[-1.1594, -1.1193],
        [-1.1971, -0.9514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031727831810712814
Epoch 0, Step 1729: train/loss = 0.6858871579170227, train/raw-loss = 0.6705677509307861, train/logprobs = tensor([[-1.0348, -1.7445],
        [-1.2911, -1.0201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030638903379440308
Epoch 0, Step 1730: train/loss = 0.7118521928787231, train/raw-loss = 0.7110962867736816, train/logprobs = tensor([[-1.1780, -1.6260],
        [-1.3858, -1.5308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001511855749413371
Epoch 0, Step 1731: train/loss = 0.7001687288284302, train/raw-loss = 0.6938455104827881, train/logprobs = tensor([[-1.3342, -1.3819],
        [-1.5548, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01264629140496254
Epoch 0, Step 1732: train/loss = 0.7123731970787048, train/raw-loss = 0.7119386196136475, train/logprobs = tensor([[-1.3116, -1.0923],
        [-1.5634, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008691778057254851
Epoch 0, Step 1733: train/loss = 0.699133574962616, train/raw-loss = 0.6859136819839478, train/logprobs = tensor([[-1.0445, -1.4744],
        [-1.3553, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026439882814884186
Epoch 0, Step 1734: train/loss = 0.6980584859848022, train/raw-loss = 0.6938707828521729, train/logprobs = tensor([[-1.3103, -1.5312],
        [-1.2643, -1.2333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008375490084290504
Epoch 0, Step 1735: train/loss = 0.7024025321006775, train/raw-loss = 0.6864250302314758, train/logprobs = tensor([[-1.0942, -1.4522],
        [-1.4781, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03195483982563019
Epoch 0, Step 1736: train/loss = 0.695872962474823, train/raw-loss = 0.6951189041137695, train/logprobs = tensor([[-1.1224, -1.1893],
        [-1.1081, -1.0243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015081815654411912
Epoch 0, Step 1737: train/loss = 0.688178539276123, train/raw-loss = 0.6836863160133362, train/logprobs = tensor([[-1.0876, -1.2596],
        [-1.0960, -0.9449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008984488435089588
Epoch 0, Step 1738: train/loss = 0.6964809894561768, train/raw-loss = 0.6852787733078003, train/logprobs = tensor([[-0.9507, -1.4117],
        [-1.2544, -0.9903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022404460236430168
Epoch 0, Step 1739: train/loss = 0.6924930214881897, train/raw-loss = 0.6919022798538208, train/logprobs = tensor([[-1.0989, -1.1692],
        [-1.0669, -1.0212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011815122561529279
Epoch 0, Step 1740: train/loss = 0.6935356855392456, train/raw-loss = 0.6926807165145874, train/logprobs = tensor([[-1.3200, -1.4791],
        [-1.3797, -1.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017101515550166368
Epoch 0, Step 1741: train/loss = 0.6990972757339478, train/raw-loss = 0.6977501511573792, train/logprobs = tensor([[-1.0108, -1.1020],
        [-1.0703, -1.0091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026942326221615076
Epoch 0, Step 1742: train/loss = 0.6968330144882202, train/raw-loss = 0.6937776207923889, train/logprobs = tensor([[-1.0650, -1.0714],
        [-1.2449, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006110779475420713
Epoch 0, Step 1743: train/loss = 0.6980699300765991, train/raw-loss = 0.6832021474838257, train/logprobs = tensor([[-1.0276, -1.4571],
        [-1.3850, -1.1858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029735421761870384
Epoch 0, Step 1744: train/loss = 0.6946327686309814, train/raw-loss = 0.6943057179450989, train/logprobs = tensor([[-1.1922, -1.0798],
        [-1.3090, -1.2387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006541184266097844
Epoch 0, Step 1745: train/loss = 0.6927083134651184, train/raw-loss = 0.6880574822425842, train/logprobs = tensor([[-1.0145, -1.1850],
        [-1.2859, -1.1247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009301668033003807
Epoch 0, Step 1746: train/loss = 0.705452024936676, train/raw-loss = 0.7041394710540771, train/logprobs = tensor([[-1.1251, -1.3063],
        [-1.3335, -1.3348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002625016262754798
Epoch 0, Step 1747: train/loss = 0.6942805647850037, train/raw-loss = 0.6801825761795044, train/logprobs = tensor([[-1.3522, -1.6773],
        [-1.6227, -1.3259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028195921331644058
Epoch 0, Step 1748: train/loss = 0.6982348561286926, train/raw-loss = 0.6935551166534424, train/logprobs = tensor([[-1.2128, -1.2099],
        [-1.2251, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009359654039144516
Epoch 0, Step 1749: train/loss = 0.6977136135101318, train/raw-loss = 0.6968733072280884, train/logprobs = tensor([[-1.1783, -1.0997],
        [-1.1806, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001680675894021988
Epoch 0, Step 1750: train/loss = 0.6911253333091736, train/raw-loss = 0.6843211054801941, train/logprobs = tensor([[-0.9584, -1.2776],
        [-1.3114, -1.1264]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013608542270958424
Epoch 0, Step 1751: train/loss = 0.6969958543777466, train/raw-loss = 0.6968756914138794, train/logprobs = tensor([[-1.2300, -1.2955],
        [-1.1973, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002404644328635186
Epoch 0, Step 1752: train/loss = 0.7218500375747681, train/raw-loss = 0.717245876789093, train/logprobs = tensor([[-1.0382, -0.9710],
        [-1.3422, -0.8857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00920829176902771
Epoch 0, Step 1753: train/loss = 0.7153578996658325, train/raw-loss = 0.71448814868927, train/logprobs = tensor([[-1.0051, -1.3811],
        [-0.9542, -1.2923]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017396693583577871
Epoch 0, Step 1754: train/loss = 0.6879149079322815, train/raw-loss = 0.6692581176757812, train/logprobs = tensor([[-1.3645, -1.6620],
        [-1.6162, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03731349855661392
Epoch 0, Step 1755: train/loss = 0.6958402395248413, train/raw-loss = 0.6894116401672363, train/logprobs = tensor([[-1.1241, -1.0894],
        [-1.4229, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012857131659984589
Epoch 0, Step 1756: train/loss = 0.6955083012580872, train/raw-loss = 0.6950803995132446, train/logprobs = tensor([[-0.9891, -1.1324],
        [-0.9684, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008557452820241451
Epoch 0, Step 1757: train/loss = 0.6955016255378723, train/raw-loss = 0.6919026374816895, train/logprobs = tensor([[-1.2937, -1.4943],
        [-1.3315, -1.2963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007198041304945946
Epoch 0, Step 1758: train/loss = 0.6893705129623413, train/raw-loss = 0.6826037168502808, train/logprobs = tensor([[-1.2949, -1.5054],
        [-1.4779, -1.2323]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013533612713217735
Epoch 0, Step 1759: train/loss = 0.7018976211547852, train/raw-loss = 0.7001261115074158, train/logprobs = tensor([[-1.2789, -1.3575],
        [-1.2338, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035429198760539293
Epoch 0, Step 1760: train/loss = 0.6957027912139893, train/raw-loss = 0.6856625080108643, train/logprobs = tensor([[-1.1447, -1.3476],
        [-1.4642, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02008039876818657
Epoch 0, Step 1761: train/loss = 0.7305341362953186, train/raw-loss = 0.7160978317260742, train/logprobs = tensor([[-1.2038, -1.3269],
        [-1.5578, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02887253277003765
Epoch 0, Step 1762: train/loss = 0.7026276588439941, train/raw-loss = 0.6950067281723022, train/logprobs = tensor([[-1.2245, -1.4335],
        [-1.5329, -1.2222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015241801738739014
Epoch 0, Step 1763: train/loss = 0.6708402633666992, train/raw-loss = 0.6381503939628601, train/logprobs = tensor([[-1.2404, -1.8253],
        [-1.7818, -1.3184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06537984311580658
Epoch 0, Step 1764: train/loss = 0.695687472820282, train/raw-loss = 0.6856350898742676, train/logprobs = tensor([[-1.1189, -1.6285],
        [-1.5085, -1.4119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02010468579828739
Epoch 0, Step 1765: train/loss = 0.6995784640312195, train/raw-loss = 0.6994009017944336, train/logprobs = tensor([[-1.2682, -1.2115],
        [-1.2928, -1.2558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00035516219213604927
Epoch 0, Step 1766: train/loss = 0.6934694051742554, train/raw-loss = 0.6912648677825928, train/logprobs = tensor([[-1.1313, -1.2620],
        [-1.1853, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004409067332744598
Epoch 0, Step 1767: train/loss = 0.6918936371803284, train/raw-loss = 0.6766045689582825, train/logprobs = tensor([[-1.3431, -1.5737],
        [-1.6580, -1.1203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030578121542930603
Epoch 0, Step 1768: train/loss = 0.6970555782318115, train/raw-loss = 0.6937494277954102, train/logprobs = tensor([[-1.3109, -1.3362],
        [-1.4885, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006612385623157024
Epoch 0, Step 1769: train/loss = 0.7028945088386536, train/raw-loss = 0.6963030099868774, train/logprobs = tensor([[-0.9832, -1.2418],
        [-1.2444, -1.0754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013183035887777805
Epoch 0, Step 1770: train/loss = 0.6933783292770386, train/raw-loss = 0.6829401254653931, train/logprobs = tensor([[-1.1741, -1.4253],
        [-1.5592, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020876334980130196
Epoch 0, Step 1771: train/loss = 0.7172598242759705, train/raw-loss = 0.707119345664978, train/logprobs = tensor([[-1.1569, -1.4648],
        [-1.5892, -1.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020280811935663223
Epoch 0, Step 1772: train/loss = 0.6977576613426208, train/raw-loss = 0.6963441371917725, train/logprobs = tensor([[-1.3644, -1.2899],
        [-1.4446, -1.2961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028271342162042856
Epoch 0, Step 1773: train/loss = 0.6971615552902222, train/raw-loss = 0.6947816610336304, train/logprobs = tensor([[-1.2735, -1.2639],
        [-1.3401, -1.0272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004759769421070814
Epoch 0, Step 1774: train/loss = 0.7053444981575012, train/raw-loss = 0.7051063179969788, train/logprobs = tensor([[-1.2704, -1.1323],
        [-1.4695, -1.1953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004762386961374432
Epoch 0, Step 1775: train/loss = 0.6952431201934814, train/raw-loss = 0.6890844106674194, train/logprobs = tensor([[-1.1825, -1.2892],
        [-1.4699, -1.2151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01231740415096283
Epoch 0, Step 1776: train/loss = 0.6945796608924866, train/raw-loss = 0.6890348792076111, train/logprobs = tensor([[-1.1123, -1.3923],
        [-1.3313, -1.1657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011089514009654522
Epoch 0, Step 1777: train/loss = 0.7082524299621582, train/raw-loss = 0.7054992914199829, train/logprobs = tensor([[-1.4385, -1.2669],
        [-1.4792, -1.1061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005506295710802078
Epoch 0, Step 1778: train/loss = 0.6933971643447876, train/raw-loss = 0.6857051849365234, train/logprobs = tensor([[-1.2478, -1.3622],
        [-1.3411, -1.0455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015384037978947163
Epoch 0, Step 1779: train/loss = 0.695167601108551, train/raw-loss = 0.6886758804321289, train/logprobs = tensor([[-1.2757, -1.5139],
        [-1.7122, -1.3597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012983307242393494
Epoch 0, Step 1780: train/loss = 0.6849243640899658, train/raw-loss = 0.6687625050544739, train/logprobs = tensor([[-1.0567, -1.3913],
        [-1.6851, -1.3656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03232382982969284
Epoch 0, Step 1781: train/loss = 0.7149180173873901, train/raw-loss = 0.7074078321456909, train/logprobs = tensor([[-1.3266, -1.5443],
        [-1.6293, -1.2914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015020348131656647
Epoch 0, Step 1782: train/loss = 0.7001121044158936, train/raw-loss = 0.6969740390777588, train/logprobs = tensor([[-1.1486, -1.1449],
        [-1.4020, -1.1987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006276124157011509
Epoch 0, Step 1783: train/loss = 0.6968700289726257, train/raw-loss = 0.686856746673584, train/logprobs = tensor([[-1.2338, -1.5195],
        [-1.5732, -1.2480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020026521757245064
Epoch 0, Step 1784: train/loss = 0.7034316062927246, train/raw-loss = 0.6884745359420776, train/logprobs = tensor([[-1.2690, -1.3847],
        [-1.7196, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02991429716348648
Epoch 0, Step 1785: train/loss = 0.7062135338783264, train/raw-loss = 0.7042564153671265, train/logprobs = tensor([[-1.0869, -1.4213],
        [-1.2443, -1.3246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003914219327270985
Epoch 0, Step 1786: train/loss = 0.6918032765388489, train/raw-loss = 0.6790105700492859, train/logprobs = tensor([[-0.9564, -1.1984],
        [-1.2278, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0255853570997715
Epoch 0, Step 1787: train/loss = 0.6946710348129272, train/raw-loss = 0.6891438961029053, train/logprobs = tensor([[-1.0867, -1.4106],
        [-1.1806, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011054353788495064
Epoch 0, Step 1788: train/loss = 0.6861105561256409, train/raw-loss = 0.674328088760376, train/logprobs = tensor([[-1.1876, -1.6004],
        [-1.4903, -1.2003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023564811795949936
Epoch 0, Step 1789: train/loss = 0.6855710744857788, train/raw-loss = 0.6705600023269653, train/logprobs = tensor([[-1.0342, -1.4554],
        [-1.5503, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03002226911485195
Epoch 0, Step 1790: train/loss = 0.7015979290008545, train/raw-loss = 0.6982982158660889, train/logprobs = tensor([[-1.4325, -1.3817],
        [-1.6365, -1.4139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006599371321499348
Epoch 0, Step 1791: train/loss = 0.69520503282547, train/raw-loss = 0.6881405711174011, train/logprobs = tensor([[-0.9981, -1.3112],
        [-1.4061, -1.2317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014128954149782658
Epoch 0, Step 1792: train/loss = 0.6872907876968384, train/raw-loss = 0.6745359301567078, train/logprobs = tensor([[-1.1677, -1.3700],
        [-1.7908, -1.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02550983801484108
Epoch 0, Step 1793: train/loss = 0.7103049755096436, train/raw-loss = 0.7071804404258728, train/logprobs = tensor([[-0.9933, -1.2627],
        [-1.0473, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006249081809073687
Epoch 0, Step 1794: train/loss = 0.7067279815673828, train/raw-loss = 0.7047351598739624, train/logprobs = tensor([[-1.2826, -1.4792],
        [-1.4181, -1.3229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003985502757132053
Epoch 0, Step 1795: train/loss = 0.6965714693069458, train/raw-loss = 0.692148745059967, train/logprobs = tensor([[-1.3214, -1.5016],
        [-1.3425, -1.1095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008845510892570019
Epoch 0, Step 1796: train/loss = 0.6973155736923218, train/raw-loss = 0.6873601675033569, train/logprobs = tensor([[-1.0949, -1.3365],
        [-1.4597, -1.2217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01991083100438118
Epoch 0, Step 1797: train/loss = 0.7109197378158569, train/raw-loss = 0.6969284415245056, train/logprobs = tensor([[-0.9982, -1.5783],
        [-1.5352, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02798253484070301
Epoch 0, Step 1798: train/loss = 0.6930047273635864, train/raw-loss = 0.6885528564453125, train/logprobs = tensor([[-1.1520, -1.2229],
        [-1.5101, -1.2700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008903589099645615
Epoch 0, Step 1799: train/loss = 0.6938037872314453, train/raw-loss = 0.6927846670150757, train/logprobs = tensor([[-1.1916, -1.4295],
        [-1.3253, -1.2435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020381694193929434
Epoch 0, Step 1800: train/loss = 0.6998754739761353, train/raw-loss = 0.6917634010314941, train/logprobs = tensor([[-1.0648, -1.2010],
        [-1.4174, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016224272549152374
Epoch 0, Step 1801: train/loss = 0.6890954971313477, train/raw-loss = 0.6815898418426514, train/logprobs = tensor([[-0.9925, -1.2556],
        [-1.4238, -1.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015011465176939964
Epoch 0, Step 1802: train/loss = 0.6948683261871338, train/raw-loss = 0.6762539148330688, train/logprobs = tensor([[-1.3208, -1.5989],
        [-1.6961, -1.1996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03722872585058212
Epoch 0, Step 1803: train/loss = 0.6927748918533325, train/raw-loss = 0.6862601637840271, train/logprobs = tensor([[-1.0545, -1.1721],
        [-1.3438, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01302941981703043
Epoch 0, Step 1804: train/loss = 0.6837389469146729, train/raw-loss = 0.664819598197937, train/logprobs = tensor([[-1.0557, -1.3184],
        [-1.6048, -1.0902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037838708609342575
Epoch 0, Step 1805: train/loss = 0.6938002109527588, train/raw-loss = 0.6855882406234741, train/logprobs = tensor([[-0.9527, -1.0418],
        [-1.1258, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01642371341586113
Epoch 0, Step 1806: train/loss = 0.6995077133178711, train/raw-loss = 0.6854503154754639, train/logprobs = tensor([[-1.2160, -1.3934],
        [-1.5522, -1.1040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02811482548713684
Epoch 0, Step 1807: train/loss = 0.7033367156982422, train/raw-loss = 0.6897606253623962, train/logprobs = tensor([[-1.0319, -1.2331],
        [-1.4633, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02715221792459488
Epoch 0, Step 1808: train/loss = 0.7010418772697449, train/raw-loss = 0.7001381516456604, train/logprobs = tensor([[-1.2496, -1.2448],
        [-1.2806, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018075101543217897
Epoch 0, Step 1809: train/loss = 0.6947614550590515, train/raw-loss = 0.6925539374351501, train/logprobs = tensor([[-1.1527, -1.1208],
        [-1.3540, -1.0127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00441498588770628
Epoch 0, Step 1810: train/loss = 0.7028185725212097, train/raw-loss = 0.6996838450431824, train/logprobs = tensor([[-1.2296, -1.3530],
        [-1.4577, -1.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006269487552344799
Epoch 0, Step 1811: train/loss = 0.6973971724510193, train/raw-loss = 0.6967134475708008, train/logprobs = tensor([[-0.8781, -0.9828],
        [-1.0841, -1.1037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013673818903043866
Epoch 0, Step 1812: train/loss = 0.689667820930481, train/raw-loss = 0.686168909072876, train/logprobs = tensor([[-1.1317, -1.4263],
        [-1.3551, -1.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006997664924710989
Epoch 0, Step 1813: train/loss = 0.6996058225631714, train/raw-loss = 0.6888954639434814, train/logprobs = tensor([[-1.0271, -1.3429],
        [-1.4872, -1.2427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0214206762611866
Epoch 0, Step 1814: train/loss = 0.8237646818161011, train/raw-loss = 0.8081209659576416, train/logprobs = tensor([[-1.1720, -2.0105],
        [-1.5212, -1.6092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03128746524453163
Epoch 0, Step 1815: train/loss = 0.6860062479972839, train/raw-loss = 0.6755585074424744, train/logprobs = tensor([[-1.1499, -1.3982],
        [-1.6139, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020895490422844887
Epoch 0, Step 1816: train/loss = 0.6874701976776123, train/raw-loss = 0.6646854281425476, train/logprobs = tensor([[-1.2661, -1.8231],
        [-1.7685, -1.3614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04556966572999954
Epoch 0, Step 1817: train/loss = 0.6935718655586243, train/raw-loss = 0.6931458711624146, train/logprobs = tensor([[-1.2753, -1.3145],
        [-1.4189, -1.3680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008520149276591837
Epoch 0, Step 1818: train/loss = 0.6871612668037415, train/raw-loss = 0.6746604442596436, train/logprobs = tensor([[-1.1696, -1.4840],
        [-1.5051, -1.2256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02500162273645401
Epoch 0, Step 1819: train/loss = 0.6933221220970154, train/raw-loss = 0.6864033937454224, train/logprobs = tensor([[-1.0586, -1.1735],
        [-1.3996, -1.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013837543316185474
Epoch 0, Step 1820: train/loss = 0.6946220397949219, train/raw-loss = 0.6945606470108032, train/logprobs = tensor([[-1.0972, -1.1089],
        [-1.1098, -1.0702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012266664998605847
Epoch 0, Step 1821: train/loss = 0.7123831510543823, train/raw-loss = 0.7083153128623962, train/logprobs = tensor([[-1.1518, -1.5084],
        [-1.1988, -1.2992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008135653100907803
Epoch 0, Step 1822: train/loss = 0.7057773470878601, train/raw-loss = 0.695827305316925, train/logprobs = tensor([[-1.2485, -1.5682],
        [-1.6030, -1.3409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01990012265741825
Epoch 0, Step 1823: train/loss = 0.6955691576004028, train/raw-loss = 0.6887445449829102, train/logprobs = tensor([[-1.2153, -1.2072],
        [-1.4183, -1.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013649282976984978
Epoch 0, Step 1824: train/loss = 0.6887868046760559, train/raw-loss = 0.6800404787063599, train/logprobs = tensor([[-1.1495, -1.3640],
        [-1.4780, -1.1134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017492664977908134
Epoch 0, Step 1825: train/loss = 0.6936094164848328, train/raw-loss = 0.6747958064079285, train/logprobs = tensor([[-1.1400, -1.6271],
        [-1.5073, -1.3336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03762727975845337
Epoch 0, Step 1826: train/loss = 0.6931264996528625, train/raw-loss = 0.6885257959365845, train/logprobs = tensor([[-1.2583, -1.3656],
        [-1.2888, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009201334789395332
Epoch 0, Step 1827: train/loss = 0.6795369386672974, train/raw-loss = 0.6700462102890015, train/logprobs = tensor([[-1.0634, -1.4503],
        [-1.4995, -1.2171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018981434404850006
Epoch 0, Step 1828: train/loss = 0.7545392513275146, train/raw-loss = 0.7495126724243164, train/logprobs = tensor([[-1.2719, -0.9397],
        [-1.6587, -0.8706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010053087025880814
Epoch 0, Step 1829: train/loss = 0.7005758285522461, train/raw-loss = 0.697889506816864, train/logprobs = tensor([[-1.2887, -1.5764],
        [-1.1237, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005372708663344383
Epoch 0, Step 1830: train/loss = 0.6969879865646362, train/raw-loss = 0.692398190498352, train/logprobs = tensor([[-1.3141, -1.2580],
        [-1.2787, -0.9852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009179587475955486
Epoch 0, Step 1831: train/loss = 0.6950549483299255, train/raw-loss = 0.6840168833732605, train/logprobs = tensor([[-1.1918, -1.4021],
        [-1.5052, -1.2459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02207612618803978
Epoch 0, Step 1832: train/loss = 0.6960836052894592, train/raw-loss = 0.6862295269966125, train/logprobs = tensor([[-1.2400, -1.2901],
        [-1.5487, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01970810443162918
Epoch 0, Step 1833: train/loss = 0.735378086566925, train/raw-loss = 0.7318180799484253, train/logprobs = tensor([[-1.1858, -0.9589],
        [-1.5847, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007120105437934399
Epoch 0, Step 1834: train/loss = 0.7007973790168762, train/raw-loss = 0.695733368396759, train/logprobs = tensor([[-0.9951, -1.1200],
        [-1.3027, -1.0236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010127980262041092
Epoch 0, Step 1835: train/loss = 0.690640389919281, train/raw-loss = 0.6823509335517883, train/logprobs = tensor([[-1.1264, -1.3439],
        [-1.4454, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016578851267695427
Epoch 0, Step 1836: train/loss = 0.6956849098205566, train/raw-loss = 0.6912081837654114, train/logprobs = tensor([[-1.0460, -1.2852],
        [-1.3000, -1.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00895337201654911
Epoch 0, Step 1837: train/loss = 0.6909782290458679, train/raw-loss = 0.6855549216270447, train/logprobs = tensor([[-1.0782, -1.2708],
        [-1.3916, -1.1316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01084660179913044
Epoch 0, Step 1838: train/loss = 0.6932380199432373, train/raw-loss = 0.6911829113960266, train/logprobs = tensor([[-1.1173, -1.2346],
        [-1.3280, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041100881062448025
Epoch 0, Step 1839: train/loss = 0.694530725479126, train/raw-loss = 0.6924953460693359, train/logprobs = tensor([[-1.2824, -1.3628],
        [-1.3072, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004070601891726255
Epoch 0, Step 1840: train/loss = 0.7113620042800903, train/raw-loss = 0.700031578540802, train/logprobs = tensor([[-1.1752, -1.1902],
        [-1.7708, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022660933434963226
Epoch 0, Step 1841: train/loss = 0.6943116784095764, train/raw-loss = 0.6920279860496521, train/logprobs = tensor([[-1.1441, -1.2195],
        [-1.0856, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00456725899130106
Epoch 0, Step 1842: train/loss = 0.6935020089149475, train/raw-loss = 0.6862265467643738, train/logprobs = tensor([[-1.2731, -1.4844],
        [-1.6057, -1.2827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014550823718309402
Epoch 0, Step 1843: train/loss = 0.6908577084541321, train/raw-loss = 0.6869001388549805, train/logprobs = tensor([[-1.0905, -1.2606],
        [-1.2962, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007915111258625984
Epoch 0, Step 1844: train/loss = 0.6872659921646118, train/raw-loss = 0.6848321557044983, train/logprobs = tensor([[-1.1378, -1.3819],
        [-1.3674, -1.1743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00486780283972621
Epoch 0, Step 1845: train/loss = 0.6896522045135498, train/raw-loss = 0.6781882047653198, train/logprobs = tensor([[-1.1892, -1.7154],
        [-1.5983, -1.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02292792685329914
Epoch 0, Step 1846: train/loss = 0.6962897181510925, train/raw-loss = 0.6957587599754333, train/logprobs = tensor([[-1.2912, -1.2552],
        [-1.3239, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010619651293382049
Epoch 0, Step 1847: train/loss = 0.6973063349723816, train/raw-loss = 0.6887544393539429, train/logprobs = tensor([[-1.0368, -1.1337],
        [-1.3021, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017103753983974457
Epoch 0, Step 1848: train/loss = 0.6993515491485596, train/raw-loss = 0.6915178298950195, train/logprobs = tensor([[-1.1527, -1.2618],
        [-1.6317, -1.3118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01566747948527336
Epoch 0, Step 1849: train/loss = 0.7066488862037659, train/raw-loss = 0.6927236318588257, train/logprobs = tensor([[-1.0547, -0.9944],
        [-1.5744, -1.0075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027850493788719177
Epoch 0, Step 1850: train/loss = 0.7003200650215149, train/raw-loss = 0.6976259350776672, train/logprobs = tensor([[-1.0948, -1.4614],
        [-1.2779, -1.3218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005388278979808092
Epoch 0, Step 1851: train/loss = 0.7050992250442505, train/raw-loss = 0.6957541704177856, train/logprobs = tensor([[-1.0688, -1.5994],
        [-1.4314, -1.4752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018689990043640137
Epoch 0, Step 1852: train/loss = 0.6951727867126465, train/raw-loss = 0.6939328908920288, train/logprobs = tensor([[-1.0987, -1.0739],
        [-1.4109, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002479881513863802
Epoch 0, Step 1853: train/loss = 0.688271164894104, train/raw-loss = 0.6708276271820068, train/logprobs = tensor([[-1.0604, -1.3576],
        [-1.8512, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034887149930000305
Epoch 0, Step 1854: train/loss = 0.7173497676849365, train/raw-loss = 0.7017737030982971, train/logprobs = tensor([[-1.1852, -1.8771],
        [-1.4233, -1.3978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03115205466747284
Epoch 0, Step 1855: train/loss = 0.6955138444900513, train/raw-loss = 0.6862257719039917, train/logprobs = tensor([[-1.2059, -1.2814],
        [-1.5861, -1.2280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018576188012957573
Epoch 0, Step 1856: train/loss = 0.6906508803367615, train/raw-loss = 0.6770555377006531, train/logprobs = tensor([[-1.2150, -1.5020],
        [-1.6158, -1.3940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027190791442990303
Epoch 0, Step 1857: train/loss = 0.6933696269989014, train/raw-loss = 0.6844901442527771, train/logprobs = tensor([[-1.0549, -1.3483],
        [-1.5068, -1.3195]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01775892823934555
Epoch 0, Step 1858: train/loss = 0.6989137530326843, train/raw-loss = 0.6979838013648987, train/logprobs = tensor([[-1.2308, -1.2752],
        [-1.3648, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018598337192088366
Epoch 0, Step 1859: train/loss = 0.7428256273269653, train/raw-loss = 0.7297896146774292, train/logprobs = tensor([[-1.2963, -1.6094],
        [-1.4426, -1.3466]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026072097942233086
Epoch 0, Step 1860: train/loss = 0.685182511806488, train/raw-loss = 0.679457426071167, train/logprobs = tensor([[-1.1112, -1.3553],
        [-1.1810, -0.9325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011450222693383694
Epoch 0, Step 1861: train/loss = 0.6993847489356995, train/raw-loss = 0.6990385055541992, train/logprobs = tensor([[-1.1420, -1.3179],
        [-1.1861, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006923523033037782
Epoch 0, Step 1862: train/loss = 0.6911836862564087, train/raw-loss = 0.6876791715621948, train/logprobs = tensor([[-1.2584, -1.4322],
        [-1.2215, -1.0997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007009248249232769
Epoch 0, Step 1863: train/loss = 0.6936945915222168, train/raw-loss = 0.6860673427581787, train/logprobs = tensor([[-0.9617, -1.2420],
        [-1.3510, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015254458412528038
Epoch 0, Step 1864: train/loss = 0.6997882723808289, train/raw-loss = 0.6882042288780212, train/logprobs = tensor([[-0.9466, -1.1024],
        [-1.4893, -1.1072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023168150335550308
Epoch 0, Step 1865: train/loss = 0.6929508447647095, train/raw-loss = 0.6818507313728333, train/logprobs = tensor([[-1.3195, -1.4478],
        [-1.7769, -1.3584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02220018394291401
Epoch 0, Step 1866: train/loss = 0.7025137543678284, train/raw-loss = 0.6983660459518433, train/logprobs = tensor([[-1.0634, -1.1073],
        [-1.4386, -1.1905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008295394480228424
Epoch 0, Step 1867: train/loss = 0.6957820057868958, train/raw-loss = 0.6835874319076538, train/logprobs = tensor([[-1.2782, -1.4684],
        [-1.6858, -1.2169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024389108642935753
Epoch 0, Step 1868: train/loss = 0.6959031820297241, train/raw-loss = 0.6844015121459961, train/logprobs = tensor([[-1.3719, -1.5999],
        [-1.5799, -1.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02300332672894001
Epoch 0, Step 1869: train/loss = 0.6972928643226624, train/raw-loss = 0.6936829090118408, train/logprobs = tensor([[-1.0506, -1.2436],
        [-1.4584, -1.5365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007219908758997917
Epoch 0, Step 1870: train/loss = 0.6836944818496704, train/raw-loss = 0.6671881675720215, train/logprobs = tensor([[-1.2205, -1.4969],
        [-1.6119, -1.2081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03301273286342621
Epoch 0, Step 1871: train/loss = 0.6996180415153503, train/raw-loss = 0.6962568759918213, train/logprobs = tensor([[-1.2735, -1.3514],
        [-1.4766, -1.2216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006722371559590101
Epoch 0, Step 1872: train/loss = 0.6970499753952026, train/raw-loss = 0.6956233978271484, train/logprobs = tensor([[-1.1807, -1.1080],
        [-1.3729, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028530925046652555
Epoch 0, Step 1873: train/loss = 0.6966171264648438, train/raw-loss = 0.6904013752937317, train/logprobs = tensor([[-1.0879, -1.1691],
        [-1.4569, -1.1035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012431541457772255
Epoch 0, Step 1874: train/loss = 0.6905433535575867, train/raw-loss = 0.6801006197929382, train/logprobs = tensor([[-1.2830, -1.4834],
        [-1.4249, -1.1201]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02088542841374874
Epoch 0, Step 1875: train/loss = 0.699260950088501, train/raw-loss = 0.6937728524208069, train/logprobs = tensor([[-1.2221, -1.1710],
        [-1.3722, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010976074263453484
Epoch 0, Step 1876: train/loss = 0.7016169428825378, train/raw-loss = 0.6962321996688843, train/logprobs = tensor([[-1.0847, -1.4458],
        [-1.1777, -1.1529]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010769623331725597
Epoch 0, Step 1877: train/loss = 0.697827935218811, train/raw-loss = 0.6873683929443359, train/logprobs = tensor([[-1.2163, -1.3219],
        [-1.4887, -1.1713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020919030532240868
Epoch 0, Step 1878: train/loss = 0.6896646618843079, train/raw-loss = 0.6739452481269836, train/logprobs = tensor([[-0.9676, -1.1704],
        [-1.2508, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031438883394002914
Epoch 0, Step 1879: train/loss = 0.6931875944137573, train/raw-loss = 0.6733718514442444, train/logprobs = tensor([[-1.1845, -1.3912],
        [-1.5605, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039631493389606476
Epoch 0, Step 1880: train/loss = 0.6868482828140259, train/raw-loss = 0.6780045628547668, train/logprobs = tensor([[-1.1759, -1.4612],
        [-1.2533, -1.2070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017687592655420303
Epoch 0, Step 1881: train/loss = 0.6944882869720459, train/raw-loss = 0.690142035484314, train/logprobs = tensor([[-1.2189, -1.4051],
        [-1.3426, -1.1033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00869255606085062
Epoch 0, Step 1882: train/loss = 0.6905449628829956, train/raw-loss = 0.6880888938903809, train/logprobs = tensor([[-1.0503, -1.1544],
        [-1.3318, -1.2078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049122897908091545
Epoch 0, Step 1883: train/loss = 0.6958681344985962, train/raw-loss = 0.6911202669143677, train/logprobs = tensor([[-1.2556, -1.3731],
        [-1.4126, -1.1043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009495809674263
Epoch 0, Step 1884: train/loss = 0.6907490491867065, train/raw-loss = 0.6804904341697693, train/logprobs = tensor([[-1.3456, -1.4550],
        [-1.5502, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02051720581948757
Epoch 0, Step 1885: train/loss = 0.707149088382721, train/raw-loss = 0.6994141340255737, train/logprobs = tensor([[-1.0961, -1.1897],
        [-1.4467, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015469800680875778
Epoch 0, Step 1886: train/loss = 0.7108781337738037, train/raw-loss = 0.6937152743339539, train/logprobs = tensor([[-1.2295, -1.7185],
        [-1.6334, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03432568907737732
Epoch 0, Step 1887: train/loss = 0.7138489484786987, train/raw-loss = 0.7094449400901794, train/logprobs = tensor([[-1.1044, -1.4669],
        [-1.2908, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00880817137658596
Epoch 0, Step 1888: train/loss = 0.6935838460922241, train/raw-loss = 0.682559609413147, train/logprobs = tensor([[-1.3351, -1.4279],
        [-1.6794, -1.3135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02204836905002594
Epoch 0, Step 1889: train/loss = 0.6970332860946655, train/raw-loss = 0.6916645765304565, train/logprobs = tensor([[-1.1500, -1.2596],
        [-1.4958, -1.1971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010737634263932705
Epoch 0, Step 1890: train/loss = 0.6977648735046387, train/raw-loss = 0.6971587538719177, train/logprobs = tensor([[-1.1903, -1.3319],
        [-1.3268, -1.2618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012123396154493093
Epoch 0, Step 1891: train/loss = 0.6984367370605469, train/raw-loss = 0.6972364783287048, train/logprobs = tensor([[-1.0900, -1.2853],
        [-1.1379, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002400454133749008
Epoch 0, Step 1892: train/loss = 0.6926964521408081, train/raw-loss = 0.6794154644012451, train/logprobs = tensor([[-1.1092, -1.6397],
        [-1.5219, -1.3898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026561865583062172
Epoch 0, Step 1893: train/loss = 0.6931519508361816, train/raw-loss = 0.6903889179229736, train/logprobs = tensor([[-1.1427, -1.1600],
        [-1.4159, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005525918211787939
Epoch 0, Step 1894: train/loss = 0.6965780854225159, train/raw-loss = 0.6945656538009644, train/logprobs = tensor([[-1.3296, -1.2292],
        [-1.2442, -1.2247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004024910274893045
Epoch 0, Step 1895: train/loss = 0.7047173976898193, train/raw-loss = 0.7034265398979187, train/logprobs = tensor([[-1.2824, -1.4619],
        [-1.4433, -1.4593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002581717912107706
Epoch 0, Step 1896: train/loss = 0.6990739107131958, train/raw-loss = 0.6913092136383057, train/logprobs = tensor([[-1.1257, -1.3728],
        [-1.2733, -1.2612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015529290772974491
Epoch 0, Step 1897: train/loss = 0.706996738910675, train/raw-loss = 0.7030888795852661, train/logprobs = tensor([[-1.1081, -1.1341],
        [-1.4627, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007815578021109104
Epoch 0, Step 1898: train/loss = 0.6939777135848999, train/raw-loss = 0.6929385662078857, train/logprobs = tensor([[-1.4665, -1.5381],
        [-1.3102, -1.2779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00207822909578681
Epoch 0, Step 1899: train/loss = 0.7101315855979919, train/raw-loss = 0.7030620574951172, train/logprobs = tensor([[-1.2281, -1.3245],
        [-1.4868, -1.1161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01413918286561966
Epoch 0, Step 1900: train/loss = 0.7026766538619995, train/raw-loss = 0.6937187314033508, train/logprobs = tensor([[-1.2167, -1.4594],
        [-1.4597, -1.1721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017915794625878334
Epoch 0, Step 1901: train/loss = 0.7009963393211365, train/raw-loss = 0.7008688449859619, train/logprobs = tensor([[-1.3275, -1.3427],
        [-1.7592, -1.7327]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025509693659842014
Epoch 0, Step 1902: train/loss = 0.6922575235366821, train/raw-loss = 0.6864504814147949, train/logprobs = tensor([[-1.1579, -1.3795],
        [-1.2894, -1.1622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011614087969064713
Epoch 0, Step 1903: train/loss = 0.6892902851104736, train/raw-loss = 0.6749767065048218, train/logprobs = tensor([[-1.0493, -1.2951],
        [-1.4280, -0.9823]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02862720377743244
Epoch 0, Step 1904: train/loss = 0.69361412525177, train/raw-loss = 0.6807907819747925, train/logprobs = tensor([[-1.4916, -1.6697],
        [-1.7665, -1.2155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025646520778536797
Epoch 0, Step 1905: train/loss = 0.7102792263031006, train/raw-loss = 0.7024468183517456, train/logprobs = tensor([[-1.3110, -1.3955],
        [-1.6671, -1.2011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01566474325954914
Epoch 0, Step 1906: train/loss = 0.726258397102356, train/raw-loss = 0.7130153179168701, train/logprobs = tensor([[-1.4269, -1.7422],
        [-1.7719, -1.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026486113667488098
Epoch 0, Step 1907: train/loss = 0.6934845447540283, train/raw-loss = 0.6926116943359375, train/logprobs = tensor([[-1.2948, -1.2499],
        [-1.2685, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017457026988267899
Epoch 0, Step 1908: train/loss = 0.7090176343917847, train/raw-loss = 0.6914539337158203, train/logprobs = tensor([[-1.0679, -1.5347],
        [-1.4519, -1.4566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03512723371386528
Epoch 0, Step 1909: train/loss = 0.6899682283401489, train/raw-loss = 0.6864131689071655, train/logprobs = tensor([[-1.2131, -1.3507],
        [-1.2598, -1.0666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007110066711902618
Epoch 0, Step 1910: train/loss = 0.6977996826171875, train/raw-loss = 0.6968295574188232, train/logprobs = tensor([[-1.1713, -1.3283],
        [-1.3080, -1.2214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019403723999857903
Epoch 0, Step 1911: train/loss = 0.694552481174469, train/raw-loss = 0.6910547018051147, train/logprobs = tensor([[-1.1057, -1.2914],
        [-1.2001, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006995560135692358
Epoch 0, Step 1912: train/loss = 0.6914712190628052, train/raw-loss = 0.6891834735870361, train/logprobs = tensor([[-1.2896, -1.5220],
        [-1.3824, -1.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004575528670102358
Epoch 0, Step 1913: train/loss = 0.6931441426277161, train/raw-loss = 0.6900004148483276, train/logprobs = tensor([[-1.0518, -1.1090],
        [-1.2444, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0062874555587768555
Epoch 0, Step 1914: train/loss = 0.6970602869987488, train/raw-loss = 0.6937267780303955, train/logprobs = tensor([[-1.2911, -1.2523],
        [-1.4511, -1.2767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006667005829513073
Epoch 0, Step 1915: train/loss = 0.702566385269165, train/raw-loss = 0.695960283279419, train/logprobs = tensor([[-1.4446, -1.4511],
        [-1.6379, -1.2487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01321212388575077
Epoch 0, Step 1916: train/loss = 0.6933614611625671, train/raw-loss = 0.6885991096496582, train/logprobs = tensor([[-1.1627, -1.3244],
        [-1.3192, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009524795226752758
Epoch 0, Step 1917: train/loss = 0.6898244023323059, train/raw-loss = 0.6667184829711914, train/logprobs = tensor([[-1.2552, -1.6422],
        [-1.6517, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04621189087629318
Epoch 0, Step 1918: train/loss = 0.6941584944725037, train/raw-loss = 0.6915096044540405, train/logprobs = tensor([[-1.1779, -1.3536],
        [-1.3132, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005297867581248283
Epoch 0, Step 1919: train/loss = 0.726978063583374, train/raw-loss = 0.7250485420227051, train/logprobs = tensor([[-1.2020, -1.2064],
        [-1.2531, -1.0681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038591730408370495
Epoch 0, Step 1920: train/loss = 0.6931182146072388, train/raw-loss = 0.683519721031189, train/logprobs = tensor([[-1.1663, -1.5242],
        [-1.2752, -1.0941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019196994602680206
Epoch 0, Step 1921: train/loss = 0.693300187587738, train/raw-loss = 0.6927182674407959, train/logprobs = tensor([[-1.0986, -1.1526],
        [-1.2667, -1.2711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001163810258731246
Epoch 0, Step 1922: train/loss = 0.6857889294624329, train/raw-loss = 0.6522951126098633, train/logprobs = tensor([[-1.1932, -1.5685],
        [-1.6093, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06698763370513916
Epoch 0, Step 1923: train/loss = 0.6940757632255554, train/raw-loss = 0.6754220128059387, train/logprobs = tensor([[-1.1038, -1.6666],
        [-1.5971, -1.4957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03730744495987892
Epoch 0, Step 1924: train/loss = 0.7028407454490662, train/raw-loss = 0.7014405727386475, train/logprobs = tensor([[-1.5215, -1.7428],
        [-1.1135, -1.4137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028004383202642202
Epoch 0, Step 1925: train/loss = 0.7046337127685547, train/raw-loss = 0.6972357630729675, train/logprobs = tensor([[-1.1242, -1.1483],
        [-1.4859, -1.1784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01479590218514204
Epoch 0, Step 1926: train/loss = 0.6945028305053711, train/raw-loss = 0.6874610185623169, train/logprobs = tensor([[-1.1314, -1.4273],
        [-1.4882, -1.3166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014083567075431347
Epoch 0, Step 1927: train/loss = 0.698094367980957, train/raw-loss = 0.6958138942718506, train/logprobs = tensor([[-1.1866, -1.1457],
        [-1.1416, -0.8729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004560899455100298
Epoch 0, Step 1928: train/loss = 0.6948145627975464, train/raw-loss = 0.6898066997528076, train/logprobs = tensor([[-1.1722, -1.3523],
        [-1.4903, -1.1993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010015744715929031
Epoch 0, Step 1929: train/loss = 0.7148478627204895, train/raw-loss = 0.71457439661026, train/logprobs = tensor([[-1.1344, -1.4155],
        [-1.2273, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005468124873004854
Epoch 0, Step 1930: train/loss = 0.6970086097717285, train/raw-loss = 0.6889933347702026, train/logprobs = tensor([[-1.2483, -1.3284],
        [-1.4716, -1.2569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016030538827180862
Epoch 0, Step 1931: train/loss = 0.6932037472724915, train/raw-loss = 0.6883087158203125, train/logprobs = tensor([[-1.2280, -1.5642],
        [-1.4255, -1.3883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009790274314582348
Epoch 0, Step 1932: train/loss = 0.6986177563667297, train/raw-loss = 0.696874737739563, train/logprobs = tensor([[-1.2734, -1.4715],
        [-1.3068, -1.2875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00348603050224483
Epoch 0, Step 1933: train/loss = 0.70645672082901, train/raw-loss = 0.6882007122039795, train/logprobs = tensor([[-1.1951, -1.4470],
        [-1.5457, -1.2519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036511991173028946
Epoch 0, Step 1934: train/loss = 0.6956527233123779, train/raw-loss = 0.6941999197006226, train/logprobs = tensor([[-1.3309, -1.5038],
        [-1.4580, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002905764849856496
Epoch 0, Step 1935: train/loss = 0.6925451159477234, train/raw-loss = 0.6914687156677246, train/logprobs = tensor([[-1.0315, -1.0826],
        [-1.1151, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021527581848204136
Epoch 0, Step 1936: train/loss = 0.6872385740280151, train/raw-loss = 0.6729298233985901, train/logprobs = tensor([[-1.1871, -1.4389],
        [-1.4535, -1.1080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028617531061172485
Epoch 0, Step 1937: train/loss = 0.6822939515113831, train/raw-loss = 0.6519381403923035, train/logprobs = tensor([[-1.3276, -1.6590],
        [-1.5401, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060711607336997986
Epoch 0, Step 1938: train/loss = 0.6969034671783447, train/raw-loss = 0.6734451055526733, train/logprobs = tensor([[-1.4363, -1.6737],
        [-1.9566, -1.6106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04691664129495621
Epoch 0, Step 1939: train/loss = 0.708798348903656, train/raw-loss = 0.7047972679138184, train/logprobs = tensor([[-1.0326, -1.2859],
        [-0.9944, -1.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008002132177352905
Epoch 0, Step 1940: train/loss = 0.6791223287582397, train/raw-loss = 0.6684905290603638, train/logprobs = tensor([[-1.2223, -1.5298],
        [-1.4698, -1.2288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02126356028020382
Epoch 0, Step 1941: train/loss = 0.6973321437835693, train/raw-loss = 0.6919130682945251, train/logprobs = tensor([[-1.2259, -1.6243],
        [-1.4367, -1.4243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010838204994797707
Epoch 0, Step 1942: train/loss = 0.7030110359191895, train/raw-loss = 0.6906895637512207, train/logprobs = tensor([[-1.0537, -1.4844],
        [-1.4163, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024642974138259888
Epoch 0, Step 1943: train/loss = 0.6930467486381531, train/raw-loss = 0.6857724189758301, train/logprobs = tensor([[-1.3062, -1.3362],
        [-1.5184, -1.3060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014548623003065586
Epoch 0, Step 1944: train/loss = 0.7284492254257202, train/raw-loss = 0.7054937481880188, train/logprobs = tensor([[-1.1589, -1.1857],
        [-1.7863, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04591107740998268
Epoch 0, Step 1945: train/loss = 0.6908940076828003, train/raw-loss = 0.687651515007019, train/logprobs = tensor([[-1.0362, -1.3204],
        [-1.1810, -1.0517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006484857760369778
Epoch 0, Step 1946: train/loss = 0.6934589147567749, train/raw-loss = 0.6868327260017395, train/logprobs = tensor([[-1.1847, -1.6140],
        [-1.4352, -1.3394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013252264820039272
Epoch 0, Step 1947: train/loss = 0.7141904234886169, train/raw-loss = 0.7100465893745422, train/logprobs = tensor([[-1.2931, -1.7925],
        [-1.3811, -1.5109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008287621662020683
Epoch 0, Step 1948: train/loss = 0.7109609842300415, train/raw-loss = 0.705716609954834, train/logprobs = tensor([[-1.1904, -1.1922],
        [-1.4766, -1.0196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010488717816770077
Epoch 0, Step 1949: train/loss = 0.7006418704986572, train/raw-loss = 0.6910240054130554, train/logprobs = tensor([[-1.3085, -1.7675],
        [-1.5517, -1.4623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019235718995332718
Epoch 0, Step 1950: train/loss = 0.6935229897499084, train/raw-loss = 0.6741456389427185, train/logprobs = tensor([[-1.1013, -1.4637],
        [-1.6982, -1.0957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038754720240831375
Epoch 0, Step 1951: train/loss = 0.6836678385734558, train/raw-loss = 0.6483705043792725, train/logprobs = tensor([[-1.0373, -1.8216],
        [-1.5152, -1.1401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07059477269649506
Epoch 0, Step 1952: train/loss = 0.6929093599319458, train/raw-loss = 0.6860681772232056, train/logprobs = tensor([[-1.0909, -1.2521],
        [-1.4165, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013682296499609947
Epoch 0, Step 1953: train/loss = 0.6929071545600891, train/raw-loss = 0.6812334656715393, train/logprobs = tensor([[-1.0158, -1.3105],
        [-1.4912, -1.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023347433656454086
Epoch 0, Step 1954: train/loss = 0.6996034383773804, train/raw-loss = 0.694561779499054, train/logprobs = tensor([[-1.0668, -1.3060],
        [-1.0623, -1.0412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010083328001201153
Epoch 0, Step 1955: train/loss = 0.6898108720779419, train/raw-loss = 0.6455440521240234, train/logprobs = tensor([[-1.3169, -2.2911],
        [-1.4903, -1.2045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08853376656770706
Epoch 0, Step 1956: train/loss = 0.686879575252533, train/raw-loss = 0.6745537519454956, train/logprobs = tensor([[-1.1619, -1.3969],
        [-1.5270, -1.1302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024651702493429184
Epoch 0, Step 1957: train/loss = 0.6967284679412842, train/raw-loss = 0.696518063545227, train/logprobs = tensor([[-1.1836, -1.3123],
        [-1.1236, -1.1989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004209244216326624
Epoch 0, Step 1958: train/loss = 0.6896348595619202, train/raw-loss = 0.6828139424324036, train/logprobs = tensor([[-1.1149, -1.3857],
        [-1.3140, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013641854748129845
Epoch 0, Step 1959: train/loss = 0.6884583830833435, train/raw-loss = 0.6780804991722107, train/logprobs = tensor([[-1.0761, -1.2980],
        [-1.3501, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020755775272846222
Epoch 0, Step 1960: train/loss = 0.689315140247345, train/raw-loss = 0.6754461526870728, train/logprobs = tensor([[-1.0996, -1.3939],
        [-1.3577, -1.0287]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027737976983189583
Epoch 0, Step 1961: train/loss = 0.6872096061706543, train/raw-loss = 0.6702448725700378, train/logprobs = tensor([[-1.1304, -1.5571],
        [-1.3191, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03392958268523216
Epoch 0, Step 1962: train/loss = 0.7237280607223511, train/raw-loss = 0.708416223526001, train/logprobs = tensor([[-0.9979, -1.6376],
        [-1.1271, -1.0636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030623655766248703
Epoch 0, Step 1963: train/loss = 0.6928210854530334, train/raw-loss = 0.6864503026008606, train/logprobs = tensor([[-1.2742, -1.3906],
        [-1.5529, -1.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012741570360958576
Epoch 0, Step 1964: train/loss = 0.6959854364395142, train/raw-loss = 0.6956291794776917, train/logprobs = tensor([[-1.0342, -1.0403],
        [-1.1587, -1.0482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007125049596652389
Epoch 0, Step 1965: train/loss = 0.6937074661254883, train/raw-loss = 0.6934695243835449, train/logprobs = tensor([[-1.0473, -1.1217],
        [-0.9377, -0.9674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047584029380232096
Epoch 0, Step 1966: train/loss = 0.6920769810676575, train/raw-loss = 0.6795933246612549, train/logprobs = tensor([[-1.2514, -1.5315],
        [-1.4862, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024967361241579056
Epoch 0, Step 1967: train/loss = 0.6969878077507019, train/raw-loss = 0.6876499056816101, train/logprobs = tensor([[-1.0949, -1.4786],
        [-1.5281, -1.3294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018675843253731728
Epoch 0, Step 1968: train/loss = 0.7069979310035706, train/raw-loss = 0.6890251636505127, train/logprobs = tensor([[-1.2330, -1.9187],
        [-1.4613, -1.3334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035945627838373184
Epoch 0, Step 1969: train/loss = 0.7512484788894653, train/raw-loss = 0.7135780453681946, train/logprobs = tensor([[-1.5316, -1.5052],
        [-1.8668, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07534097880125046
Epoch 0, Step 1970: train/loss = 0.6996734738349915, train/raw-loss = 0.6784476637840271, train/logprobs = tensor([[-1.2074, -1.6294],
        [-1.4487, -1.2717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042451582849025726
Epoch 0, Step 1971: train/loss = 0.6865586638450623, train/raw-loss = 0.6388099789619446, train/logprobs = tensor([[-1.1993, -2.0391],
        [-1.6113, -1.1013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09549737721681595
Epoch 0, Step 1972: train/loss = 0.6971648335456848, train/raw-loss = 0.6885267496109009, train/logprobs = tensor([[-1.3696, -1.5068],
        [-1.5978, -1.3817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017276067286729813
Epoch 0, Step 1973: train/loss = 0.7011674642562866, train/raw-loss = 0.6935068368911743, train/logprobs = tensor([[-1.2357, -1.2325],
        [-1.3479, -0.9116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015321345068514347
Epoch 0, Step 1974: train/loss = 0.7044131755828857, train/raw-loss = 0.6948176622390747, train/logprobs = tensor([[-0.9954, -1.1539],
        [-1.1999, -0.8623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01919112727046013
Epoch 0, Step 1975: train/loss = 0.6977310180664062, train/raw-loss = 0.6907415390014648, train/logprobs = tensor([[-1.1925, -1.6023],
        [-1.3682, -1.2949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013978947885334492
Epoch 0, Step 1976: train/loss = 0.693569540977478, train/raw-loss = 0.6869643926620483, train/logprobs = tensor([[-1.0735, -1.2298],
        [-1.3125, -1.0993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013210386037826538
Epoch 0, Step 1977: train/loss = 0.6934781670570374, train/raw-loss = 0.6925832033157349, train/logprobs = tensor([[-1.2720, -1.1904],
        [-1.0115, -1.0750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017898153746500611
Epoch 0, Step 1978: train/loss = 0.6932181715965271, train/raw-loss = 0.689273476600647, train/logprobs = tensor([[-0.9966, -1.0839],
        [-1.3759, -1.1524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007889356464147568
Epoch 0, Step 1979: train/loss = 0.6912333965301514, train/raw-loss = 0.6742235422134399, train/logprobs = tensor([[-0.9698, -1.3107],
        [-1.3111, -1.0893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03401980549097061
Epoch 0, Step 1980: train/loss = 0.7002408504486084, train/raw-loss = 0.7001099586486816, train/logprobs = tensor([[-1.1366, -1.3192],
        [-1.1908, -1.3296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002617590653244406
Epoch 0, Step 1981: train/loss = 0.6963381767272949, train/raw-loss = 0.6932719349861145, train/logprobs = tensor([[-1.2112, -1.4191],
        [-1.1969, -1.0939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006132454611361027
Epoch 0, Step 1982: train/loss = 0.7093243598937988, train/raw-loss = 0.7017000913619995, train/logprobs = tensor([[-1.1300, -1.7084],
        [-1.4323, -1.4733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01524852029979229
Epoch 0, Step 1983: train/loss = 0.7139402627944946, train/raw-loss = 0.7039456963539124, train/logprobs = tensor([[-0.8782, -0.8055],
        [-1.5084, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019989170134067535
Epoch 0, Step 1984: train/loss = 0.7082557678222656, train/raw-loss = 0.6966034173965454, train/logprobs = tensor([[-1.0090, -1.2813],
        [-1.2904, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023304825648665428
Epoch 0, Step 1985: train/loss = 0.7073500752449036, train/raw-loss = 0.7024093270301819, train/logprobs = tensor([[-1.3551, -1.5980],
        [-1.4300, -1.3629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009881507605314255
Epoch 0, Step 1986: train/loss = 0.690416693687439, train/raw-loss = 0.6621848344802856, train/logprobs = tensor([[-1.0171, -1.6665],
        [-1.4614, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05646371468901634
Epoch 0, Step 1987: train/loss = 0.7111356854438782, train/raw-loss = 0.7038027048110962, train/logprobs = tensor([[-1.3784, -1.6968],
        [-1.2496, -0.9534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014666028320789337
Epoch 0, Step 1988: train/loss = 0.7146481871604919, train/raw-loss = 0.7064808011054993, train/logprobs = tensor([[-1.0354, -1.5220],
        [-1.3989, -1.4508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016334790736436844
Epoch 0, Step 1989: train/loss = 0.6906512975692749, train/raw-loss = 0.6873842477798462, train/logprobs = tensor([[-1.2921, -1.3919],
        [-1.7057, -1.4163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006534048356115818
Epoch 0, Step 1990: train/loss = 0.6992591619491577, train/raw-loss = 0.6932487487792969, train/logprobs = tensor([[-0.9701, -1.2666],
        [-0.9689, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012020878493785858
Epoch 0, Step 1991: train/loss = 0.7046467065811157, train/raw-loss = 0.6941750049591064, train/logprobs = tensor([[-1.2547, -1.4651],
        [-1.2206, -0.8672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020943382754921913
Epoch 0, Step 1992: train/loss = 0.6930829882621765, train/raw-loss = 0.6923720836639404, train/logprobs = tensor([[-1.4621, -1.4981],
        [-0.9810, -0.9425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00142172712367028
Epoch 0, Step 1993: train/loss = 0.6921051740646362, train/raw-loss = 0.6705251932144165, train/logprobs = tensor([[-1.1531, -1.5250],
        [-1.7146, -1.2047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04315989091992378
Epoch 0, Step 1994: train/loss = 0.7037297487258911, train/raw-loss = 0.687469482421875, train/logprobs = tensor([[-1.0335, -1.4063],
        [-1.1944, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03252044692635536
Epoch 0, Step 1995: train/loss = 0.6858310103416443, train/raw-loss = 0.6699615120887756, train/logprobs = tensor([[-1.1634, -1.4510],
        [-1.6296, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0317390151321888
Epoch 0, Step 1996: train/loss = 0.6918943524360657, train/raw-loss = 0.687863826751709, train/logprobs = tensor([[-1.3719, -1.6478],
        [-1.2094, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008061032742261887
Epoch 0, Step 1997: train/loss = 0.6970289349555969, train/raw-loss = 0.6932505369186401, train/logprobs = tensor([[-1.2299, -1.3117],
        [-1.4974, -1.2864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007556776981800795
Epoch 0, Step 1998: train/loss = 0.6949796676635742, train/raw-loss = 0.6846222877502441, train/logprobs = tensor([[-1.0216, -1.1697],
        [-1.3559, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02071470022201538
Epoch 0, Step 1999: train/loss = 0.7025109529495239, train/raw-loss = 0.6975628137588501, train/logprobs = tensor([[-1.1595, -1.5212],
        [-1.2408, -1.1952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00989628117531538
eval/loss: 0.6972028613090515
Epoch 0, Step 2000: train/loss = 0.689534604549408, train/raw-loss = 0.6785589456558228, train/logprobs = tensor([[-1.1020, -1.2877],
        [-1.3557, -1.0415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02195134200155735
Epoch 0, Step 2001: train/loss = 0.6943060159683228, train/raw-loss = 0.6924459934234619, train/logprobs = tensor([[-1.1862, -1.3013],
        [-1.3438, -1.1725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037200632505118847
Epoch 0, Step 2002: train/loss = 0.7078900933265686, train/raw-loss = 0.7070679664611816, train/logprobs = tensor([[-0.9748, -1.2463],
        [-1.0776, -1.3011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001644182950258255
Epoch 0, Step 2003: train/loss = 0.6950994729995728, train/raw-loss = 0.6846847534179688, train/logprobs = tensor([[-1.0503, -1.3912],
        [-1.3804, -1.0892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02082943357527256
Epoch 0, Step 2004: train/loss = 0.6848915219306946, train/raw-loss = 0.6537076234817505, train/logprobs = tensor([[-1.2380, -1.7788],
        [-1.4454, -0.9282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06236787885427475
Epoch 0, Step 2005: train/loss = 0.7957286834716797, train/raw-loss = 0.7885220050811768, train/logprobs = tensor([[-1.0037, -1.6009],
        [-1.2933, -1.4855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014413360506296158
Epoch 0, Step 2006: train/loss = 0.6906035542488098, train/raw-loss = 0.6708696484565735, train/logprobs = tensor([[-1.3396, -1.5490],
        [-1.4172, -1.0304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03946775570511818
Epoch 0, Step 2007: train/loss = 0.7055121660232544, train/raw-loss = 0.7031241655349731, train/logprobs = tensor([[-1.1522, -1.1661],
        [-1.1153, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004776046145707369
Epoch 0, Step 2008: train/loss = 0.7195883989334106, train/raw-loss = 0.7072718143463135, train/logprobs = tensor([[-1.2197, -1.8110],
        [-1.3760, -1.1969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02463310956954956
Epoch 0, Step 2009: train/loss = 0.7209509611129761, train/raw-loss = 0.7168682217597961, train/logprobs = tensor([[-1.1850, -1.2686],
        [-1.3055, -1.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008165441453456879
Epoch 0, Step 2010: train/loss = 0.699153482913971, train/raw-loss = 0.6959825158119202, train/logprobs = tensor([[-1.0271, -1.4096],
        [-1.2030, -1.2893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0063419402576982975
Epoch 0, Step 2011: train/loss = 0.7164586186408997, train/raw-loss = 0.6944061517715454, train/logprobs = tensor([[-1.0501, -1.8792],
        [-1.2047, -1.2713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044104963541030884
Epoch 0, Step 2012: train/loss = 0.6981713175773621, train/raw-loss = 0.6969543099403381, train/logprobs = tensor([[-1.1420, -1.1624],
        [-1.4177, -1.3403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024340662639588118
Epoch 0, Step 2013: train/loss = 0.7075738906860352, train/raw-loss = 0.6964540481567383, train/logprobs = tensor([[-1.1024, -1.6398],
        [-1.2599, -1.2130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022239796817302704
Epoch 0, Step 2014: train/loss = 0.7021510004997253, train/raw-loss = 0.6964017152786255, train/logprobs = tensor([[-1.2327, -1.3015],
        [-1.3614, -0.9996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011498470790684223
Epoch 0, Step 2015: train/loss = 0.7297745943069458, train/raw-loss = 0.7011798620223999, train/logprobs = tensor([[-0.9493, -1.6501],
        [-1.6517, -1.2973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05718955770134926
Epoch 0, Step 2016: train/loss = 0.6913326382637024, train/raw-loss = 0.6873627305030823, train/logprobs = tensor([[-1.0264, -1.1946],
        [-1.3594, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007939755916595459
Epoch 0, Step 2017: train/loss = 0.7014883756637573, train/raw-loss = 0.6949608325958252, train/logprobs = tensor([[-0.9332, -0.9203],
        [-1.0934, -0.7828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013055170886218548
Epoch 0, Step 2018: train/loss = 0.6892820596694946, train/raw-loss = 0.6319066286087036, train/logprobs = tensor([[-1.2287, -1.8771],
        [-1.8089, -1.1369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11475095897912979
Epoch 0, Step 2019: train/loss = 0.7030491232872009, train/raw-loss = 0.700692892074585, train/logprobs = tensor([[-1.0600, -1.0993],
        [-1.2342, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004712420050054789
Epoch 0, Step 2020: train/loss = 0.6962777376174927, train/raw-loss = 0.6923725008964539, train/logprobs = tensor([[-1.2538, -1.2921],
        [-1.4319, -1.2771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007810311391949654
Epoch 0, Step 2021: train/loss = 0.6932618021965027, train/raw-loss = 0.6775221228599548, train/logprobs = tensor([[-1.1778, -1.4109],
        [-1.5145, -1.2710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031479284167289734
Epoch 0, Step 2022: train/loss = 0.698828399181366, train/raw-loss = 0.6978279948234558, train/logprobs = tensor([[-1.2562, -1.4009],
        [-1.1391, -1.1252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002000770065933466
Epoch 0, Step 2023: train/loss = 0.6933038830757141, train/raw-loss = 0.6864442229270935, train/logprobs = tensor([[-1.0579, -1.3089],
        [-1.2410, -1.1228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013719383627176285
Epoch 0, Step 2024: train/loss = 0.7126486301422119, train/raw-loss = 0.676454484462738, train/logprobs = tensor([[-1.2397, -1.7168],
        [-1.7734, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07238832116127014
Epoch 0, Step 2025: train/loss = 0.7084780931472778, train/raw-loss = 0.70796799659729, train/logprobs = tensor([[-1.1681, -0.9915],
        [-1.1776, -0.8771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001020254334434867
Epoch 0, Step 2026: train/loss = 0.690473735332489, train/raw-loss = 0.6717860698699951, train/logprobs = tensor([[-1.0027, -1.2862],
        [-1.2442, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03737526386976242
Epoch 0, Step 2027: train/loss = 0.6930445432662964, train/raw-loss = 0.6725883483886719, train/logprobs = tensor([[-1.1077, -1.3725],
        [-1.2721, -0.7886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040912315249443054
Epoch 0, Step 2028: train/loss = 0.6928670406341553, train/raw-loss = 0.6910719871520996, train/logprobs = tensor([[-1.0509, -1.1261],
        [-1.2532, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003590105567127466
Epoch 0, Step 2029: train/loss = 0.7042674422264099, train/raw-loss = 0.6929828524589539, train/logprobs = tensor([[-1.2508, -1.5421],
        [-1.6444, -1.3396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022569291293621063
Epoch 0, Step 2030: train/loss = 0.6914476156234741, train/raw-loss = 0.6765365600585938, train/logprobs = tensor([[-1.1236, -1.3368],
        [-1.1421, -0.9564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029822126030921936
Epoch 0, Step 2031: train/loss = 0.6927125453948975, train/raw-loss = 0.6770578622817993, train/logprobs = tensor([[-1.0622, -1.4441],
        [-1.4443, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031309306621551514
Epoch 0, Step 2032: train/loss = 0.6844527721405029, train/raw-loss = 0.6763416528701782, train/logprobs = tensor([[-1.1418, -1.3890],
        [-1.3171, -0.9438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01622229814529419
Epoch 0, Step 2033: train/loss = 0.6958123445510864, train/raw-loss = 0.6788110733032227, train/logprobs = tensor([[-1.1059, -1.4266],
        [-1.4841, -0.9677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03400278836488724
Epoch 0, Step 2034: train/loss = 0.6977804899215698, train/raw-loss = 0.6943884491920471, train/logprobs = tensor([[-1.1519, -1.1653],
        [-1.3319, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006784055847674608
Epoch 0, Step 2035: train/loss = 0.689834475517273, train/raw-loss = 0.6776680946350098, train/logprobs = tensor([[-1.2329, -1.8217],
        [-1.5352, -1.2671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0243328046053648
Epoch 0, Step 2036: train/loss = 0.6841673254966736, train/raw-loss = 0.6667200922966003, train/logprobs = tensor([[-1.0546, -1.3425],
        [-1.4791, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03489444777369499
Epoch 0, Step 2037: train/loss = 0.6936575174331665, train/raw-loss = 0.6917137503623962, train/logprobs = tensor([[-1.2999, -1.3602],
        [-1.3976, -1.1913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003887503407895565
Epoch 0, Step 2038: train/loss = 0.6933930516242981, train/raw-loss = 0.6924806237220764, train/logprobs = tensor([[-0.9959, -1.1615],
        [-1.0151, -0.9973]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018248783890157938
Epoch 0, Step 2039: train/loss = 0.689589262008667, train/raw-loss = 0.6787461042404175, train/logprobs = tensor([[-0.9548, -1.2267],
        [-1.1094, -0.9135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02168632112443447
Epoch 0, Step 2040: train/loss = 0.700059175491333, train/raw-loss = 0.6913973093032837, train/logprobs = tensor([[-1.4499, -1.4175],
        [-1.2871, -1.0126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017323844134807587
Epoch 0, Step 2041: train/loss = 0.7010679244995117, train/raw-loss = 0.693182110786438, train/logprobs = tensor([[-1.0748, -1.3830],
        [-1.2078, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015771636739373207
Epoch 0, Step 2042: train/loss = 0.69818115234375, train/raw-loss = 0.6778537034988403, train/logprobs = tensor([[-1.1052, -1.2609],
        [-1.4310, -0.9271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040654826909303665
Epoch 0, Step 2043: train/loss = 0.6799150705337524, train/raw-loss = 0.6473098397254944, train/logprobs = tensor([[-1.1953, -1.9516],
        [-1.3603, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06521045416593552
Epoch 0, Step 2044: train/loss = 0.6991274356842041, train/raw-loss = 0.6829687356948853, train/logprobs = tensor([[-0.9916, -1.5298],
        [-1.3156, -1.2347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032317452132701874
Epoch 0, Step 2045: train/loss = 0.7192547917366028, train/raw-loss = 0.7072325944900513, train/logprobs = tensor([[-1.1011, -1.3971],
        [-1.3678, -1.1489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024044442921876907
Epoch 0, Step 2046: train/loss = 0.7002377510070801, train/raw-loss = 0.688404381275177, train/logprobs = tensor([[-0.9592, -1.3717],
        [-1.1698, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023666711524128914
Epoch 0, Step 2047: train/loss = 0.7179788947105408, train/raw-loss = 0.7125890254974365, train/logprobs = tensor([[-1.0331, -1.3696],
        [-1.0594, -1.1533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01077967882156372
Epoch 0, Step 2048: train/loss = 0.6935651302337646, train/raw-loss = 0.6877871155738831, train/logprobs = tensor([[-1.1221, -1.3188],
        [-1.4218, -1.2315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011556084267795086
Epoch 0, Step 2049: train/loss = 0.726661205291748, train/raw-loss = 0.7073991298675537, train/logprobs = tensor([[-1.1799, -1.6794],
        [-1.3942, -1.1454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03852425888180733
Epoch 0, Step 2050: train/loss = 0.7014026641845703, train/raw-loss = 0.7011886239051819, train/logprobs = tensor([[-0.9118, -1.0332],
        [-0.8133, -0.8888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004280927823856473
Epoch 0, Step 2051: train/loss = 0.7219899296760559, train/raw-loss = 0.7108668088912964, train/logprobs = tensor([[-0.9230, -1.2206],
        [-1.2313, -1.2762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02224612608551979
Epoch 0, Step 2052: train/loss = 0.6975563168525696, train/raw-loss = 0.6926015019416809, train/logprobs = tensor([[-1.1978, -1.2891],
        [-1.4721, -1.2268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009909591637551785
Epoch 0, Step 2053: train/loss = 0.6927410364151001, train/raw-loss = 0.6821882724761963, train/logprobs = tensor([[-1.2056, -1.4290],
        [-1.4391, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02110552228987217
Epoch 0, Step 2054: train/loss = 0.7025773525238037, train/raw-loss = 0.6965372562408447, train/logprobs = tensor([[-0.9779, -0.9887],
        [-1.3663, -1.0122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012080101296305656
Epoch 0, Step 2055: train/loss = 0.6951532363891602, train/raw-loss = 0.694319486618042, train/logprobs = tensor([[-0.9877, -1.0995],
        [-0.8999, -0.8990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016675149090588093
Epoch 0, Step 2056: train/loss = 0.6918717622756958, train/raw-loss = 0.6684994697570801, train/logprobs = tensor([[-1.0897, -1.6152],
        [-1.3067, -0.8392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04674450308084488
Epoch 0, Step 2057: train/loss = 0.6950016021728516, train/raw-loss = 0.6830267310142517, train/logprobs = tensor([[-1.1226, -1.3069],
        [-1.3228, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02394968457520008
Epoch 0, Step 2058: train/loss = 0.7043888568878174, train/raw-loss = 0.6878246068954468, train/logprobs = tensor([[-1.4409, -1.6374],
        [-1.4294, -0.9816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03312847018241882
Epoch 0, Step 2059: train/loss = 0.6903008222579956, train/raw-loss = 0.6710280179977417, train/logprobs = tensor([[-1.2248, -1.5657],
        [-1.4840, -1.0732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038545526564121246
Epoch 0, Step 2060: train/loss = 0.7013581395149231, train/raw-loss = 0.6949424147605896, train/logprobs = tensor([[-1.1685, -1.2279],
        [-1.3138, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012831474654376507
Epoch 0, Step 2061: train/loss = 0.7188354730606079, train/raw-loss = 0.6995022296905518, train/logprobs = tensor([[-1.1063, -1.7535],
        [-1.3650, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0386665016412735
Epoch 0, Step 2062: train/loss = 0.6996651887893677, train/raw-loss = 0.6963688135147095, train/logprobs = tensor([[-1.1447, -1.1158],
        [-1.5312, -1.5739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006592784076929092
Epoch 0, Step 2063: train/loss = 0.6961485147476196, train/raw-loss = 0.6948760747909546, train/logprobs = tensor([[-0.9502, -0.9761],
        [-0.9834, -1.0980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025448459200561047
Epoch 0, Step 2064: train/loss = 0.692804753780365, train/raw-loss = 0.6804295778274536, train/logprobs = tensor([[-1.1570, -1.3922],
        [-1.5529, -1.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024750377982854843
Epoch 0, Step 2065: train/loss = 0.7089928984642029, train/raw-loss = 0.7008639574050903, train/logprobs = tensor([[-1.1726, -1.3805],
        [-1.2371, -1.0048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016257992014288902
Epoch 0, Step 2066: train/loss = 0.7052973508834839, train/raw-loss = 0.6923556923866272, train/logprobs = tensor([[-1.0743, -1.4016],
        [-1.3211, -1.0204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02588343247771263
Epoch 0, Step 2067: train/loss = 0.686436653137207, train/raw-loss = 0.6571164727210999, train/logprobs = tensor([[-1.0280, -1.6016],
        [-1.1657, -0.8513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058640412986278534
Epoch 0, Step 2068: train/loss = 0.7135212421417236, train/raw-loss = 0.6823810338973999, train/logprobs = tensor([[-1.0653, -1.7832],
        [-1.3963, -1.1294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06228044629096985
Epoch 0, Step 2069: train/loss = 0.7170050740242004, train/raw-loss = 0.7127448320388794, train/logprobs = tensor([[-1.3476, -1.1239],
        [-1.6475, -1.1180]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008520569652318954
Epoch 0, Step 2070: train/loss = 0.6999232172966003, train/raw-loss = 0.6907331943511963, train/logprobs = tensor([[-1.1623, -1.4528],
        [-1.4004, -1.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018379973247647285
Epoch 0, Step 2071: train/loss = 0.6926791071891785, train/raw-loss = 0.6623560190200806, train/logprobs = tensor([[-1.5120, -1.7857],
        [-1.8294, -1.0110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06064619496464729
Epoch 0, Step 2072: train/loss = 0.7014877200126648, train/raw-loss = 0.6973191499710083, train/logprobs = tensor([[-1.1734, -1.4112],
        [-1.3330, -1.3769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00833708606660366
Epoch 0, Step 2073: train/loss = 0.6910185813903809, train/raw-loss = 0.6763280630111694, train/logprobs = tensor([[-1.0837, -1.3938],
        [-1.5230, -1.0237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02938109263777733
Epoch 0, Step 2074: train/loss = 0.690295934677124, train/raw-loss = 0.6681720018386841, train/logprobs = tensor([[-1.1628, -1.5564],
        [-1.5164, -0.9143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04424773156642914
Epoch 0, Step 2075: train/loss = 0.6883357763290405, train/raw-loss = 0.6807620525360107, train/logprobs = tensor([[-1.2200, -1.5386],
        [-1.3865, -1.1645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01514735259115696
Epoch 0, Step 2076: train/loss = 0.70867919921875, train/raw-loss = 0.6953281760215759, train/logprobs = tensor([[-1.1331, -1.3734],
        [-1.2101, -1.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026702193543314934
Epoch 0, Step 2077: train/loss = 0.7040041089057922, train/raw-loss = 0.6729541420936584, train/logprobs = tensor([[-1.2278, -1.7512],
        [-1.3531, -0.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06209992617368698
Epoch 0, Step 2078: train/loss = 0.696150541305542, train/raw-loss = 0.6834882497787476, train/logprobs = tensor([[-1.4622, -1.6529],
        [-1.5268, -1.2152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025324422866106033
Epoch 0, Step 2079: train/loss = 0.6945508122444153, train/raw-loss = 0.6870418190956116, train/logprobs = tensor([[-0.9106, -1.1814],
        [-1.2130, -0.9841]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01501802634447813
Epoch 0, Step 2080: train/loss = 0.70128333568573, train/raw-loss = 0.6934598684310913, train/logprobs = tensor([[-1.4877, -1.9501],
        [-1.4908, -1.3342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015647010877728462
Epoch 0, Step 2081: train/loss = 0.6946632862091064, train/raw-loss = 0.6860348582267761, train/logprobs = tensor([[-1.0718, -1.2184],
        [-1.0384, -0.9047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017256908118724823
Epoch 0, Step 2082: train/loss = 0.6956730484962463, train/raw-loss = 0.6898292303085327, train/logprobs = tensor([[-1.0819, -1.2762],
        [-1.2670, -1.2513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011687730439007282
Epoch 0, Step 2083: train/loss = 0.6952980160713196, train/raw-loss = 0.6937862038612366, train/logprobs = tensor([[-1.0886, -1.1908],
        [-1.1780, -1.0516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030235149897634983
Epoch 0, Step 2084: train/loss = 0.7001492977142334, train/raw-loss = 0.6752403378486633, train/logprobs = tensor([[-1.0267, -1.1988],
        [-1.6803, -1.0905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049817927181720734
Epoch 0, Step 2085: train/loss = 0.6760502457618713, train/raw-loss = 0.6664434671401978, train/logprobs = tensor([[-0.9958, -1.2850],
        [-1.1742, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019213702529668808
Epoch 0, Step 2086: train/loss = 0.6927670836448669, train/raw-loss = 0.6774778366088867, train/logprobs = tensor([[-1.1154, -1.2783],
        [-1.5409, -1.1845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030578553676605225
Epoch 0, Step 2087: train/loss = 0.6889051198959351, train/raw-loss = 0.6679894924163818, train/logprobs = tensor([[-1.2657, -1.8604],
        [-1.4918, -1.2726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041831329464912415
Epoch 0, Step 2088: train/loss = 0.6968247890472412, train/raw-loss = 0.6966879367828369, train/logprobs = tensor([[-1.2266, -1.1609],
        [-1.3278, -1.2900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002737147733569145
Epoch 0, Step 2089: train/loss = 0.7062814831733704, train/raw-loss = 0.6998831033706665, train/logprobs = tensor([[-1.1371, -1.0944],
        [-1.4668, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01279664970934391
Epoch 0, Step 2090: train/loss = 0.6868386268615723, train/raw-loss = 0.6681973338127136, train/logprobs = tensor([[-1.2753, -1.6445],
        [-1.4831, -1.1928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037282515317201614
Epoch 0, Step 2091: train/loss = 0.7028648257255554, train/raw-loss = 0.6938403248786926, train/logprobs = tensor([[-0.9018, -1.0961],
        [-1.1237, -0.9149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01804901473224163
Epoch 0, Step 2092: train/loss = 0.6870722770690918, train/raw-loss = 0.6732242107391357, train/logprobs = tensor([[-1.1963, -1.5112],
        [-1.4247, -0.9426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027696195989847183
Epoch 0, Step 2093: train/loss = 0.6987665295600891, train/raw-loss = 0.6948508024215698, train/logprobs = tensor([[-1.2248, -1.3229],
        [-1.2685, -1.0332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007831240072846413
Epoch 0, Step 2094: train/loss = 0.690615713596344, train/raw-loss = 0.68917316198349, train/logprobs = tensor([[-1.1337, -1.2665],
        [-1.2609, -1.1443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028851483948528767
Epoch 0, Step 2095: train/loss = 0.7385768890380859, train/raw-loss = 0.7352331280708313, train/logprobs = tensor([[-1.2699, -1.0256],
        [-1.5010, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006687654182314873
Epoch 0, Step 2096: train/loss = 0.696357011795044, train/raw-loss = 0.6917315125465393, train/logprobs = tensor([[-1.2614, -1.2955],
        [-1.3614, -1.0667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009251033887267113
Epoch 0, Step 2097: train/loss = 0.6990822553634644, train/raw-loss = 0.6907092332839966, train/logprobs = tensor([[-1.0742, -1.5261],
        [-1.5134, -1.4944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01674601435661316
Epoch 0, Step 2098: train/loss = 0.6922321915626526, train/raw-loss = 0.6852318048477173, train/logprobs = tensor([[-1.1216, -1.3395],
        [-1.1330, -1.0865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014000744558870792
Epoch 0, Step 2099: train/loss = 0.6880177855491638, train/raw-loss = 0.6661908626556396, train/logprobs = tensor([[-1.0332, -1.5394],
        [-1.6025, -1.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04365378990769386
Epoch 0, Step 2100: train/loss = 0.7153406739234924, train/raw-loss = 0.7116512060165405, train/logprobs = tensor([[-1.0714, -1.3631],
        [-1.1522, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007378945127129555
Epoch 0, Step 2101: train/loss = 0.7006377577781677, train/raw-loss = 0.6953657865524292, train/logprobs = tensor([[-1.0254, -1.2821],
        [-1.2627, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010544002056121826
Epoch 0, Step 2102: train/loss = 0.6888517737388611, train/raw-loss = 0.6753873825073242, train/logprobs = tensor([[-1.0948, -1.5039],
        [-1.4950, -1.2862]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026928676292300224
Epoch 0, Step 2103: train/loss = 0.7005701065063477, train/raw-loss = 0.6843181848526001, train/logprobs = tensor([[-1.1214, -1.5103],
        [-1.4358, -1.1586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03250390663743019
Epoch 0, Step 2104: train/loss = 0.6916499137878418, train/raw-loss = 0.6666973233222961, train/logprobs = tensor([[-1.0661, -1.3861],
        [-1.5264, -1.0308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0499049574136734
Epoch 0, Step 2105: train/loss = 0.6958902478218079, train/raw-loss = 0.6918436884880066, train/logprobs = tensor([[-1.1671, -1.2687],
        [-1.5710, -1.4125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008093137294054031
Epoch 0, Step 2106: train/loss = 0.6924178600311279, train/raw-loss = 0.685753345489502, train/logprobs = tensor([[-0.8961, -1.0489],
        [-1.3968, -1.1522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013329008594155312
Epoch 0, Step 2107: train/loss = 0.6910784244537354, train/raw-loss = 0.6684675216674805, train/logprobs = tensor([[-1.1045, -1.4493],
        [-1.3795, -1.1477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04522179067134857
Epoch 0, Step 2108: train/loss = 0.6937391757965088, train/raw-loss = 0.686233401298523, train/logprobs = tensor([[-1.0815, -1.3455],
        [-1.2792, -0.9464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015011463314294815
Epoch 0, Step 2109: train/loss = 0.6973913908004761, train/raw-loss = 0.6904700398445129, train/logprobs = tensor([[-1.1674, -1.3547],
        [-1.4055, -1.2559]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013842773623764515
Epoch 0, Step 2110: train/loss = 0.7146033048629761, train/raw-loss = 0.707247793674469, train/logprobs = tensor([[-1.0057, -1.5034],
        [-1.0597, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014711053110659122
Epoch 0, Step 2111: train/loss = 0.6958819627761841, train/raw-loss = 0.6892385482788086, train/logprobs = tensor([[-1.0465, -1.1833],
        [-1.2305, -0.8600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01328684575855732
Epoch 0, Step 2112: train/loss = 0.6870488524436951, train/raw-loss = 0.6504358053207397, train/logprobs = tensor([[-1.0552, -1.5126],
        [-1.2418, -0.9968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07322617620229721
Epoch 0, Step 2113: train/loss = 0.6929393410682678, train/raw-loss = 0.682426929473877, train/logprobs = tensor([[-1.1176, -1.3438],
        [-1.0824, -0.9296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02102486416697502
Epoch 0, Step 2114: train/loss = 0.7116531133651733, train/raw-loss = 0.7024397850036621, train/logprobs = tensor([[-1.0973, -1.6395],
        [-1.2357, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018426837399601936
Epoch 0, Step 2115: train/loss = 0.7036841511726379, train/raw-loss = 0.6619365215301514, train/logprobs = tensor([[-1.2231, -1.5838],
        [-2.0267, -1.0227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08349530398845673
Epoch 0, Step 2116: train/loss = 0.7069079875946045, train/raw-loss = 0.7044593095779419, train/logprobs = tensor([[-1.3109, -1.6040],
        [-1.2752, -1.4834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004897255916148424
Epoch 0, Step 2117: train/loss = 0.6881240606307983, train/raw-loss = 0.6515769362449646, train/logprobs = tensor([[-1.2800, -1.8466],
        [-1.4305, -1.0149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0730942115187645
Epoch 0, Step 2118: train/loss = 0.7076866030693054, train/raw-loss = 0.6962266564369202, train/logprobs = tensor([[-1.2107, -1.2943],
        [-1.6527, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022919801995158195
Epoch 0, Step 2119: train/loss = 0.6986452341079712, train/raw-loss = 0.6921588182449341, train/logprobs = tensor([[-1.0404, -1.3172],
        [-1.1863, -1.0730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012972657568752766
Epoch 0, Step 2120: train/loss = 0.6836894750595093, train/raw-loss = 0.6546618938446045, train/logprobs = tensor([[-1.1736, -1.5950],
        [-1.5993, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05805511027574539
Epoch 0, Step 2121: train/loss = 0.6903649568557739, train/raw-loss = 0.6764228940010071, train/logprobs = tensor([[-0.8725, -1.0073],
        [-0.9547, -0.6599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027884088456630707
Epoch 0, Step 2122: train/loss = 0.6797826886177063, train/raw-loss = 0.6784012317657471, train/logprobs = tensor([[-1.1856, -1.3015],
        [-1.4105, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027630594559013844
Epoch 0, Step 2123: train/loss = 0.6900584697723389, train/raw-loss = 0.6700024604797363, train/logprobs = tensor([[-1.1644, -1.5121],
        [-1.4800, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040112145245075226
Epoch 0, Step 2124: train/loss = 0.6975893974304199, train/raw-loss = 0.694013237953186, train/logprobs = tensor([[-0.9688, -1.1045],
        [-1.0037, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007152474485337734
Epoch 0, Step 2125: train/loss = 0.7367194890975952, train/raw-loss = 0.7241889238357544, train/logprobs = tensor([[-1.2035, -1.6630],
        [-1.4406, -1.2103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02506122551858425
Epoch 0, Step 2126: train/loss = 0.6915557384490967, train/raw-loss = 0.665503740310669, train/logprobs = tensor([[-1.2814, -1.7101],
        [-1.5529, -1.0145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05210411176085472
Epoch 0, Step 2127: train/loss = 0.6942253708839417, train/raw-loss = 0.688525915145874, train/logprobs = tensor([[-1.0021, -1.0577],
        [-1.2801, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01139888260513544
Epoch 0, Step 2128: train/loss = 0.693306565284729, train/raw-loss = 0.6754934191703796, train/logprobs = tensor([[-1.0778, -1.4022],
        [-1.1985, -0.8414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03562631458044052
Epoch 0, Step 2129: train/loss = 0.6896580457687378, train/raw-loss = 0.6805328130722046, train/logprobs = tensor([[-1.0376, -1.4608],
        [-1.3226, -1.1449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018250616267323494
Epoch 0, Step 2130: train/loss = 0.6972794532775879, train/raw-loss = 0.6839026808738708, train/logprobs = tensor([[-0.9574, -1.1373],
        [-1.3837, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02675352245569229
Epoch 0, Step 2131: train/loss = 0.7113937735557556, train/raw-loss = 0.6900783777236938, train/logprobs = tensor([[-1.2070, -1.7169],
        [-1.4422, -1.2582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04263078048825264
Epoch 0, Step 2132: train/loss = 0.6892618536949158, train/raw-loss = 0.6804167032241821, train/logprobs = tensor([[-1.1107, -1.4673],
        [-1.2094, -1.0399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017690306529402733
Epoch 0, Step 2133: train/loss = 0.6996321678161621, train/raw-loss = 0.6864814758300781, train/logprobs = tensor([[-0.9756, -1.0746],
        [-1.2196, -0.8496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02630135975778103
Epoch 0, Step 2134: train/loss = 0.6907732486724854, train/raw-loss = 0.6779969930648804, train/logprobs = tensor([[-1.3508, -1.6291],
        [-1.2526, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025552568957209587
Epoch 0, Step 2135: train/loss = 0.6919659972190857, train/raw-loss = 0.6694929599761963, train/logprobs = tensor([[-0.8953, -1.3104],
        [-1.2981, -0.8837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04494607448577881
Epoch 0, Step 2136: train/loss = 0.6848093271255493, train/raw-loss = 0.6530604362487793, train/logprobs = tensor([[-1.0184, -1.4538],
        [-1.2861, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06349778920412064
Epoch 0, Step 2137: train/loss = 0.7101175785064697, train/raw-loss = 0.6679375767707825, train/logprobs = tensor([[-1.0642, -1.8299],
        [-1.3016, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08435998111963272
Epoch 0, Step 2138: train/loss = 0.7008374929428101, train/raw-loss = 0.6871492862701416, train/logprobs = tensor([[-1.1478, -1.4251],
        [-1.3347, -1.3139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027376294136047363
Epoch 0, Step 2139: train/loss = 0.6846075654029846, train/raw-loss = 0.6565183401107788, train/logprobs = tensor([[-1.0973, -1.5562],
        [-1.6055, -1.0246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05617835372686386
Epoch 0, Step 2140: train/loss = 0.7183716893196106, train/raw-loss = 0.7095090746879578, train/logprobs = tensor([[-1.1686, -1.3939],
        [-1.3470, -1.0331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017725132405757904
Epoch 0, Step 2141: train/loss = 0.6949737668037415, train/raw-loss = 0.6926701068878174, train/logprobs = tensor([[-1.0163, -1.2689],
        [-1.3276, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0046073817647993565
Epoch 0, Step 2142: train/loss = 0.7075686454772949, train/raw-loss = 0.6827800869941711, train/logprobs = tensor([[-1.0837, -2.0470],
        [-1.2741, -1.2027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04957709461450577
Epoch 0, Step 2143: train/loss = 0.6982356905937195, train/raw-loss = 0.6762726306915283, train/logprobs = tensor([[-1.1082, -1.5168],
        [-1.4204, -1.1457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04392607510089874
Epoch 0, Step 2144: train/loss = 0.6834937334060669, train/raw-loss = 0.661670446395874, train/logprobs = tensor([[-1.0044, -1.4581],
        [-1.3888, -0.9885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04364655911922455
Epoch 0, Step 2145: train/loss = 0.6848824620246887, train/raw-loss = 0.6379895806312561, train/logprobs = tensor([[-1.0903, -1.9265],
        [-1.3638, -0.9556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09378576278686523
Epoch 0, Step 2146: train/loss = 0.6939120292663574, train/raw-loss = 0.6926395893096924, train/logprobs = tensor([[-1.0705, -1.1190],
        [-1.0393, -0.9760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025448754895478487
Epoch 0, Step 2147: train/loss = 0.7753587365150452, train/raw-loss = 0.7595281004905701, train/logprobs = tensor([[-1.3900, -2.1928],
        [-1.6160, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03166124224662781
Epoch 0, Step 2148: train/loss = 0.6932503581047058, train/raw-loss = 0.6909014582633972, train/logprobs = tensor([[-1.1466, -1.3643],
        [-1.2232, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004697673954069614
Epoch 0, Step 2149: train/loss = 0.6934444904327393, train/raw-loss = 0.6892955899238586, train/logprobs = tensor([[-1.5510, -1.6810],
        [-1.1722, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008297756314277649
Epoch 0, Step 2150: train/loss = 0.6920278072357178, train/raw-loss = 0.6875661015510559, train/logprobs = tensor([[-1.2311, -1.3887],
        [-1.4574, -1.3126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008923511952161789
Epoch 0, Step 2151: train/loss = 0.6887176036834717, train/raw-loss = 0.6624299883842468, train/logprobs = tensor([[-1.0146, -1.3607],
        [-1.5665, -1.0171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05257516726851463
Epoch 0, Step 2152: train/loss = 0.6933794021606445, train/raw-loss = 0.6786351799964905, train/logprobs = tensor([[-1.2555, -1.4468],
        [-1.4839, -1.2009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02948850393295288
Epoch 0, Step 2153: train/loss = 0.7237390875816345, train/raw-loss = 0.7021276950836182, train/logprobs = tensor([[-1.2752, -1.4807],
        [-1.6198, -1.2609]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04322283715009689
Epoch 0, Step 2154: train/loss = 0.6969361305236816, train/raw-loss = 0.6937724351882935, train/logprobs = tensor([[-1.1901, -1.3322],
        [-1.1643, -1.1058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006327389739453793
Epoch 0, Step 2155: train/loss = 0.6888502240180969, train/raw-loss = 0.667741060256958, train/logprobs = tensor([[-1.0004, -1.4749],
        [-1.2288, -0.9462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04221833497285843
Epoch 0, Step 2156: train/loss = 0.6925002336502075, train/raw-loss = 0.6783013343811035, train/logprobs = tensor([[-1.1468, -1.3545],
        [-1.2184, -1.1184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028397735208272934
Epoch 0, Step 2157: train/loss = 0.7075114846229553, train/raw-loss = 0.6892784833908081, train/logprobs = tensor([[-1.2199, -1.8047],
        [-1.4705, -1.1557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03646588325500488
Epoch 0, Step 2158: train/loss = 0.6939612627029419, train/raw-loss = 0.6929342746734619, train/logprobs = tensor([[-1.0815, -1.1735],
        [-1.0933, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020540186669677496
Epoch 0, Step 2159: train/loss = 0.6676467061042786, train/raw-loss = 0.6350457072257996, train/logprobs = tensor([[-1.1408, -1.9538],
        [-1.4332, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06520199775695801
Epoch 0, Step 2160: train/loss = 0.6780124306678772, train/raw-loss = 0.6504496932029724, train/logprobs = tensor([[-1.1634, -1.5939],
        [-1.6798, -1.1065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055125460028648376
Epoch 0, Step 2161: train/loss = 0.6870779395103455, train/raw-loss = 0.6700078248977661, train/logprobs = tensor([[-1.0894, -1.3317],
        [-1.4313, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03414010629057884
Epoch 0, Step 2162: train/loss = 0.6942552924156189, train/raw-loss = 0.6906015276908875, train/logprobs = tensor([[-1.2362, -1.4064],
        [-1.3277, -1.1925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007307529915124178
Epoch 0, Step 2163: train/loss = 0.6944470405578613, train/raw-loss = 0.6941424608230591, train/logprobs = tensor([[-1.2365, -1.3520],
        [-1.2118, -1.2153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006090927636250854
Epoch 0, Step 2164: train/loss = 0.6975279450416565, train/raw-loss = 0.676403284072876, train/logprobs = tensor([[-1.3337, -1.4960],
        [-1.4755, -0.9520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04224933683872223
Epoch 0, Step 2165: train/loss = 0.7002071738243103, train/raw-loss = 0.6574973464012146, train/logprobs = tensor([[-1.1417, -1.7817],
        [-1.5518, -0.9307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08541969209909439
Epoch 0, Step 2166: train/loss = 0.6941092610359192, train/raw-loss = 0.6894301176071167, train/logprobs = tensor([[-1.0850, -1.0981],
        [-1.3295, -1.1148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009358190931379795
Epoch 0, Step 2167: train/loss = 0.7043816447257996, train/raw-loss = 0.7007341384887695, train/logprobs = tensor([[-1.2134, -1.4895],
        [-1.5250, -1.5129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007295010145753622
Epoch 0, Step 2168: train/loss = 0.6851907968521118, train/raw-loss = 0.6406920552253723, train/logprobs = tensor([[-1.0438, -1.9911],
        [-1.5494, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08899739384651184
Epoch 0, Step 2169: train/loss = 0.6974709033966064, train/raw-loss = 0.6643654108047485, train/logprobs = tensor([[-1.1192, -1.5999],
        [-1.6047, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06621105223894119
Epoch 0, Step 2170: train/loss = 0.6997649669647217, train/raw-loss = 0.642073392868042, train/logprobs = tensor([[-1.0671, -2.1413],
        [-1.5997, -1.0403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11538311839103699
Epoch 0, Step 2171: train/loss = 0.696723461151123, train/raw-loss = 0.6849366426467896, train/logprobs = tensor([[-1.1266, -1.5291],
        [-1.1128, -0.8732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023573722690343857
Epoch 0, Step 2172: train/loss = 0.6924258470535278, train/raw-loss = 0.6565697193145752, train/logprobs = tensor([[-1.0133, -1.4520],
        [-1.3220, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07171229273080826
Epoch 0, Step 2173: train/loss = 0.6977894306182861, train/raw-loss = 0.6900029182434082, train/logprobs = tensor([[-1.0017, -1.0712],
        [-1.2425, -0.9205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015572978183627129
Epoch 0, Step 2174: train/loss = 0.6868796348571777, train/raw-loss = 0.6414177417755127, train/logprobs = tensor([[-1.2132, -1.7126],
        [-1.7527, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09092371165752411
Epoch 0, Step 2175: train/loss = 0.705069899559021, train/raw-loss = 0.6877402663230896, train/logprobs = tensor([[-1.1257, -1.3276],
        [-1.5847, -1.0915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03465929999947548
Epoch 0, Step 2176: train/loss = 0.711266815662384, train/raw-loss = 0.7023226618766785, train/logprobs = tensor([[-1.0799, -1.3427],
        [-1.2883, -1.0353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017888326197862625
Epoch 0, Step 2177: train/loss = 0.7134100198745728, train/raw-loss = 0.6914900541305542, train/logprobs = tensor([[-1.2099, -1.7878],
        [-1.3695, -1.2398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04384011775255203
Epoch 0, Step 2178: train/loss = 0.7369051575660706, train/raw-loss = 0.7262016534805298, train/logprobs = tensor([[-1.4028, -2.2765],
        [-1.4626, -1.6533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02140694297850132
Epoch 0, Step 2179: train/loss = 0.7065513134002686, train/raw-loss = 0.702200174331665, train/logprobs = tensor([[-0.9825, -1.2678],
        [-1.1446, -1.0998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008702205494046211
Epoch 0, Step 2180: train/loss = 0.6961430311203003, train/raw-loss = 0.6918309926986694, train/logprobs = tensor([[-1.1526, -1.2051],
        [-1.4640, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008624034002423286
Epoch 0, Step 2181: train/loss = 0.6868063807487488, train/raw-loss = 0.6694498658180237, train/logprobs = tensor([[-0.9381, -1.5236],
        [-1.0710, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0347130186855793
Epoch 0, Step 2182: train/loss = 0.6934144496917725, train/raw-loss = 0.6766669154167175, train/logprobs = tensor([[-1.0974, -1.5988],
        [-1.3518, -1.1717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03349503129720688
Epoch 0, Step 2183: train/loss = 0.6875932216644287, train/raw-loss = 0.6808699369430542, train/logprobs = tensor([[-1.1815, -1.4349],
        [-1.5124, -1.2384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013446592725813389
Epoch 0, Step 2184: train/loss = 0.7309555411338806, train/raw-loss = 0.7193801403045654, train/logprobs = tensor([[-0.9520, -1.6395],
        [-1.2054, -1.1948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02315080538392067
Epoch 0, Step 2185: train/loss = 0.7048717141151428, train/raw-loss = 0.6893042325973511, train/logprobs = tensor([[-0.9604, -1.4097],
        [-1.2938, -1.3188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031134959310293198
Epoch 0, Step 2186: train/loss = 0.6908614039421082, train/raw-loss = 0.6656448841094971, train/logprobs = tensor([[-1.1919, -1.6444],
        [-1.2944, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0504329651594162
Epoch 0, Step 2187: train/loss = 0.6973592042922974, train/raw-loss = 0.6851761341094971, train/logprobs = tensor([[-1.2702, -1.5231],
        [-1.1577, -0.9912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02436615526676178
Epoch 0, Step 2188: train/loss = 0.6950339078903198, train/raw-loss = 0.6937395930290222, train/logprobs = tensor([[-1.0209, -1.0359],
        [-1.4465, -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002588878618553281
Epoch 0, Step 2189: train/loss = 0.6921035051345825, train/raw-loss = 0.6778062582015991, train/logprobs = tensor([[-1.1897, -1.4076],
        [-1.4504, -1.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02859431318938732
Epoch 0, Step 2190: train/loss = 0.7028975486755371, train/raw-loss = 0.6929920315742493, train/logprobs = tensor([[-1.1332, -1.4954],
        [-1.3037, -1.0562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019811110571026802
Epoch 0, Step 2191: train/loss = 0.6817806959152222, train/raw-loss = 0.6501556038856506, train/logprobs = tensor([[-1.0180, -1.3541],
        [-1.5063, -1.0416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06325020641088486
Epoch 0, Step 2192: train/loss = 0.6935195922851562, train/raw-loss = 0.6759411096572876, train/logprobs = tensor([[-1.2369, -1.3157],
        [-1.5293, -1.2937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03515695780515671
Epoch 0, Step 2193: train/loss = 0.7086498737335205, train/raw-loss = 0.7006981372833252, train/logprobs = tensor([[-1.0788, -0.9371],
        [-1.4063, -0.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015903407707810402
Epoch 0, Step 2194: train/loss = 0.697387158870697, train/raw-loss = 0.6578928828239441, train/logprobs = tensor([[-0.9199, -1.8091],
        [-1.3247, -0.9472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07898849248886108
Epoch 0, Step 2195: train/loss = 0.6956063508987427, train/raw-loss = 0.6940288543701172, train/logprobs = tensor([[-1.1015, -1.3279],
        [-0.9904, -1.0254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031550168059766293
Epoch 0, Step 2196: train/loss = 0.6884239912033081, train/raw-loss = 0.6621721982955933, train/logprobs = tensor([[-1.2753, -1.8471],
        [-1.3008, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052503518760204315
Epoch 0, Step 2197: train/loss = 0.6888003945350647, train/raw-loss = 0.6693052053451538, train/logprobs = tensor([[-1.1261, -1.5035],
        [-1.4082, -1.1336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03899037465453148
Epoch 0, Step 2198: train/loss = 0.6907632350921631, train/raw-loss = 0.6784529685974121, train/logprobs = tensor([[-1.1900, -1.3684],
        [-1.2408, -1.0289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024620523676276207
Epoch 0, Step 2199: train/loss = 0.6973134279251099, train/raw-loss = 0.6884734630584717, train/logprobs = tensor([[-1.0775, -1.1491],
        [-1.3927, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017679909244179726
Epoch 0, Step 2200: train/loss = 0.6969824433326721, train/raw-loss = 0.6926889419555664, train/logprobs = tensor([[-1.1092, -1.0941],
        [-1.2528, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008587011136114597
Epoch 0, Step 2201: train/loss = 0.7414273619651794, train/raw-loss = 0.734102725982666, train/logprobs = tensor([[-1.2003, -1.9131],
        [-1.2481, -1.4794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014649116434156895
Epoch 0, Step 2202: train/loss = 0.6971604824066162, train/raw-loss = 0.6844075918197632, train/logprobs = tensor([[-1.0762, -1.1957],
        [-1.2323, -0.8074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02550586871802807
Epoch 0, Step 2203: train/loss = 0.7005224227905273, train/raw-loss = 0.6868088245391846, train/logprobs = tensor([[-0.9570, -1.2340],
        [-1.5036, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02742706425487995
Epoch 0, Step 2204: train/loss = 0.696648359298706, train/raw-loss = 0.6886650323867798, train/logprobs = tensor([[-1.3595, -1.6190],
        [-1.2531, -1.0162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015966590493917465
Epoch 0, Step 2205: train/loss = 0.6888271570205688, train/raw-loss = 0.6720444560050964, train/logprobs = tensor([[-0.8845, -1.1990],
        [-1.0705, -0.7690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03356533870100975
Epoch 0, Step 2206: train/loss = 0.6986640691757202, train/raw-loss = 0.6940100789070129, train/logprobs = tensor([[-1.1570, -1.4615],
        [-1.1228, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00930803269147873
Epoch 0, Step 2207: train/loss = 0.6975582242012024, train/raw-loss = 0.6909595727920532, train/logprobs = tensor([[-0.8969, -1.0260],
        [-1.3911, -1.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013197352178394794
Epoch 0, Step 2208: train/loss = 0.6924281120300293, train/raw-loss = 0.6663342714309692, train/logprobs = tensor([[-1.1446, -1.6679],
        [-1.3643, -1.1286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05218762159347534
Epoch 0, Step 2209: train/loss = 0.6941229701042175, train/raw-loss = 0.6940453052520752, train/logprobs = tensor([[-1.2957, -1.2777],
        [-1.0902, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001553009933559224
Epoch 0, Step 2210: train/loss = 0.7117919921875, train/raw-loss = 0.6889496445655823, train/logprobs = tensor([[-0.8614, -1.6465],
        [-1.4305, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045684561133384705
Epoch 0, Step 2211: train/loss = 0.6777397394180298, train/raw-loss = 0.6126311421394348, train/logprobs = tensor([[-1.0193, -1.6186],
        [-1.7622, -0.8408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13021713495254517
Epoch 0, Step 2212: train/loss = 0.6878582239151001, train/raw-loss = 0.6620781421661377, train/logprobs = tensor([[-0.9322, -1.5502],
        [-1.2205, -0.9967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05156015232205391
Epoch 0, Step 2213: train/loss = 0.7127383947372437, train/raw-loss = 0.7065194249153137, train/logprobs = tensor([[-1.1883, -1.0616],
        [-1.4060, -0.9303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012437965720891953
Epoch 0, Step 2214: train/loss = 0.6932869553565979, train/raw-loss = 0.6661425232887268, train/logprobs = tensor([[-1.0949, -1.7688],
        [-1.3415, -0.9820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05428881198167801
Epoch 0, Step 2215: train/loss = 0.6937958002090454, train/raw-loss = 0.6621716618537903, train/logprobs = tensor([[-1.0423, -1.7057],
        [-1.5972, -1.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06324829161167145
Epoch 0, Step 2216: train/loss = 0.6908591389656067, train/raw-loss = 0.6858377456665039, train/logprobs = tensor([[-0.8478, -0.9640],
        [-0.9768, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010042768903076649
Epoch 0, Step 2217: train/loss = 0.691576361656189, train/raw-loss = 0.6901805996894836, train/logprobs = tensor([[-1.1886, -1.2771],
        [-1.1956, -1.0971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027915022801607847
Epoch 0, Step 2218: train/loss = 0.6922605037689209, train/raw-loss = 0.626112699508667, train/logprobs = tensor([[-1.1793, -1.9072],
        [-1.8103, -1.1949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322956681251526
Epoch 0, Step 2219: train/loss = 0.7007462978363037, train/raw-loss = 0.696448028087616, train/logprobs = tensor([[-1.1568, -1.1279],
        [-1.3346, -0.9958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008596481755375862
Epoch 0, Step 2220: train/loss = 0.7026206254959106, train/raw-loss = 0.6935438513755798, train/logprobs = tensor([[-1.3435, -1.4933],
        [-1.5563, -1.1943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018153557553887367
Epoch 0, Step 2221: train/loss = 0.6956709623336792, train/raw-loss = 0.6929258108139038, train/logprobs = tensor([[-1.5866, -1.6059],
        [-1.2332, -1.1276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005490443203598261
Epoch 0, Step 2222: train/loss = 0.6976067423820496, train/raw-loss = 0.6905076503753662, train/logprobs = tensor([[-1.2148, -1.3702],
        [-1.2899, -1.1630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01419826876372099
Epoch 0, Step 2223: train/loss = 0.7045164704322815, train/raw-loss = 0.691055178642273, train/logprobs = tensor([[-1.3008, -1.3886],
        [-1.5103, -1.0284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026922544464468956
Epoch 0, Step 2224: train/loss = 0.6972447037696838, train/raw-loss = 0.6777942180633545, train/logprobs = tensor([[-1.0487, -1.6824],
        [-1.0749, -0.8871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038900911808013916
Epoch 0, Step 2225: train/loss = 0.7029852867126465, train/raw-loss = 0.6923706531524658, train/logprobs = tensor([[-1.0374, -1.0357],
        [-1.2527, -1.1269]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02122936025261879
Epoch 0, Step 2226: train/loss = 0.6881864070892334, train/raw-loss = 0.6805664300918579, train/logprobs = tensor([[-1.1509, -1.5234],
        [-1.4061, -1.1946]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015239959582686424
Epoch 0, Step 2227: train/loss = 0.7141133546829224, train/raw-loss = 0.7034124732017517, train/logprobs = tensor([[-1.1503, -1.3899],
        [-1.3446, -0.9922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021401692181825638
Epoch 0, Step 2228: train/loss = 0.6882458925247192, train/raw-loss = 0.6828621625900269, train/logprobs = tensor([[-1.2014, -1.4478],
        [-1.4935, -1.3670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010767519474029541
Epoch 0, Step 2229: train/loss = 0.6892349720001221, train/raw-loss = 0.6539997458457947, train/logprobs = tensor([[-1.0694, -1.5665],
        [-1.4273, -1.0543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07047044485807419
Epoch 0, Step 2230: train/loss = 0.6967868208885193, train/raw-loss = 0.6669293642044067, train/logprobs = tensor([[-1.1365, -1.7727],
        [-1.3403, -1.1343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059714894741773605
Epoch 0, Step 2231: train/loss = 0.7109787464141846, train/raw-loss = 0.702407717704773, train/logprobs = tensor([[-1.0709, -1.3534],
        [-1.0870, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017142081633210182
Epoch 0, Step 2232: train/loss = 0.7141275405883789, train/raw-loss = 0.7024286985397339, train/logprobs = tensor([[-1.2070, -1.9359],
        [-1.0678, -1.1505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0233975350856781
Epoch 0, Step 2233: train/loss = 0.6889501810073853, train/raw-loss = 0.6653118133544922, train/logprobs = tensor([[-1.0464, -1.4187],
        [-1.4257, -1.1197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0472765788435936
Epoch 0, Step 2234: train/loss = 0.7022430300712585, train/raw-loss = 0.6949042081832886, train/logprobs = tensor([[-0.9513, -1.3903],
        [-1.1456, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014677702449262142
Epoch 0, Step 2235: train/loss = 0.6904237270355225, train/raw-loss = 0.6836544275283813, train/logprobs = tensor([[-1.2282, -1.4164],
        [-1.3142, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013538370840251446
Epoch 0, Step 2236: train/loss = 0.6936583518981934, train/raw-loss = 0.6597740054130554, train/logprobs = tensor([[-1.0374, -1.5601],
        [-1.1541, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776877492666245
Epoch 0, Step 2237: train/loss = 0.6590061783790588, train/raw-loss = 0.6236193180084229, train/logprobs = tensor([[-1.1767, -1.7061],
        [-1.4834, -0.8905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07077385485172272
Epoch 0, Step 2238: train/loss = 0.7045148611068726, train/raw-loss = 0.6968967914581299, train/logprobs = tensor([[-0.8901, -1.3447],
        [-0.9165, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015236234292387962
Epoch 0, Step 2239: train/loss = 0.680058479309082, train/raw-loss = 0.671882152557373, train/logprobs = tensor([[-1.2937, -1.5921],
        [-1.5466, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01635272428393364
Epoch 0, Step 2240: train/loss = 0.6964778304100037, train/raw-loss = 0.6928133964538574, train/logprobs = tensor([[-1.0493, -1.1799],
        [-1.0607, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007328832522034645
Epoch 0, Step 2241: train/loss = 0.6991814374923706, train/raw-loss = 0.6898869276046753, train/logprobs = tensor([[-1.1452, -1.2881],
        [-1.2555, -1.0723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018589064478874207
Epoch 0, Step 2242: train/loss = 0.6972792148590088, train/raw-loss = 0.67743980884552, train/logprobs = tensor([[-0.8440, -1.3201],
        [-1.4285, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039678819477558136
Epoch 0, Step 2243: train/loss = 0.7089455127716064, train/raw-loss = 0.6857244968414307, train/logprobs = tensor([[-1.2060, -1.3321],
        [-1.2837, -1.1342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046442050486803055
Epoch 0, Step 2244: train/loss = 0.6974856853485107, train/raw-loss = 0.6769212484359741, train/logprobs = tensor([[-0.9966, -1.4400],
        [-1.1930, -1.1396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04112888127565384
Epoch 0, Step 2245: train/loss = 0.692457377910614, train/raw-loss = 0.6812912225723267, train/logprobs = tensor([[-1.6492, -2.0664],
        [-0.9936, -0.8853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022332262247800827
Epoch 0, Step 2246: train/loss = 0.6964448094367981, train/raw-loss = 0.6919295191764832, train/logprobs = tensor([[-1.5073, -1.4992],
        [-1.3782, -1.1384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00903053767979145
Epoch 0, Step 2247: train/loss = 0.7111993432044983, train/raw-loss = 0.6994214653968811, train/logprobs = tensor([[-1.1164, -1.7265],
        [-1.0766, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02355579100549221
Epoch 0, Step 2248: train/loss = 0.6948994398117065, train/raw-loss = 0.652124285697937, train/logprobs = tensor([[-1.1303, -1.6071],
        [-1.3500, -1.2603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0855502188205719
Epoch 0, Step 2249: train/loss = 0.6830214262008667, train/raw-loss = 0.6284371614456177, train/logprobs = tensor([[-1.3012, -1.9961],
        [-1.5755, -1.0421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10916843265295029
Epoch 0, Step 2250: train/loss = 0.7076938152313232, train/raw-loss = 0.7061668634414673, train/logprobs = tensor([[-1.5591, -1.6195],
        [-1.2465, -1.1437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003053781809285283
Epoch 0, Step 2251: train/loss = 0.6916182041168213, train/raw-loss = 0.6848524212837219, train/logprobs = tensor([[-1.0178, -1.1731],
        [-1.1716, -1.0483]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01353145856410265
Epoch 0, Step 2252: train/loss = 0.7426767945289612, train/raw-loss = 0.7426446676254272, train/logprobs = tensor([[-1.3843, -1.7372],
        [-1.1548, -1.4793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.426477921195328e-05
Epoch 0, Step 2253: train/loss = 0.6908974647521973, train/raw-loss = 0.676321268081665, train/logprobs = tensor([[-1.2509, -1.6276],
        [-1.5488, -1.2318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02915225736796856
Epoch 0, Step 2254: train/loss = 0.7009819149971008, train/raw-loss = 0.6912182569503784, train/logprobs = tensor([[-1.1148, -1.5993],
        [-1.0620, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019527412950992584
Epoch 0, Step 2255: train/loss = 0.6925982236862183, train/raw-loss = 0.6833992004394531, train/logprobs = tensor([[-1.0346, -1.3939],
        [-1.2557, -1.2104]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01839808188378811
Epoch 0, Step 2256: train/loss = 0.6977871656417847, train/raw-loss = 0.674749493598938, train/logprobs = tensor([[-1.5268, -1.7701],
        [-1.2238, -0.9598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046075329184532166
Epoch 0, Step 2257: train/loss = 0.7220067977905273, train/raw-loss = 0.7140327095985413, train/logprobs = tensor([[-1.1939, -1.2927],
        [-1.4440, -1.0689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015948183834552765
Epoch 0, Step 2258: train/loss = 0.7110550999641418, train/raw-loss = 0.7013157606124878, train/logprobs = tensor([[-1.4076, -1.5134],
        [-1.2266, -1.0662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019478807225823402
Epoch 0, Step 2259: train/loss = 0.6932081580162048, train/raw-loss = 0.6629253625869751, train/logprobs = tensor([[-1.3013, -2.2594],
        [-1.2165, -1.1318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060565561056137085
Epoch 0, Step 2260: train/loss = 0.7044970989227295, train/raw-loss = 0.7003519535064697, train/logprobs = tensor([[-1.0442, -1.3944],
        [-1.1221, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0082904864102602
Epoch 0, Step 2261: train/loss = 0.6902039051055908, train/raw-loss = 0.6726949214935303, train/logprobs = tensor([[-1.1642, -1.4566],
        [-1.5319, -1.0921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035017870366573334
Epoch 0, Step 2262: train/loss = 0.7033296823501587, train/raw-loss = 0.6614746451377869, train/logprobs = tensor([[-1.0227, -1.5196],
        [-1.3606, -0.8748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371011912822723
Epoch 0, Step 2263: train/loss = 0.7021791934967041, train/raw-loss = 0.6682311296463013, train/logprobs = tensor([[-1.0505, -1.3374],
        [-1.5665, -1.4093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06789601594209671
Epoch 0, Step 2264: train/loss = 0.7492459416389465, train/raw-loss = 0.7181306481361389, train/logprobs = tensor([[-0.9668, -2.1553],
        [-1.0645, -1.2546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06223054975271225
Epoch 0, Step 2265: train/loss = 0.7022833824157715, train/raw-loss = 0.657024621963501, train/logprobs = tensor([[-0.9157, -1.8200],
        [-1.4193, -1.2069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09051752090454102
Epoch 0, Step 2266: train/loss = 0.6921931505203247, train/raw-loss = 0.6818280816078186, train/logprobs = tensor([[-1.2348, -1.3598],
        [-1.5075, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020730067044496536
Epoch 0, Step 2267: train/loss = 0.6837922930717468, train/raw-loss = 0.6796450614929199, train/logprobs = tensor([[-1.4363, -1.7733],
        [-1.2106, -1.0278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008294576779007912
Epoch 0, Step 2268: train/loss = 0.6926807165145874, train/raw-loss = 0.6883822679519653, train/logprobs = tensor([[-1.0817, -1.2296],
        [-1.1841, -1.1179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00859682448208332
Epoch 0, Step 2269: train/loss = 0.6831105947494507, train/raw-loss = 0.6689721345901489, train/logprobs = tensor([[-0.9533, -1.2123],
        [-1.1665, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028276808559894562
Epoch 0, Step 2270: train/loss = 0.7178484201431274, train/raw-loss = 0.6929224729537964, train/logprobs = tensor([[-1.3429, -2.0989],
        [-1.0590, -1.0312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04985193908214569
Epoch 0, Step 2271: train/loss = 0.6951019763946533, train/raw-loss = 0.6948679685592651, train/logprobs = tensor([[-1.3559, -1.3968],
        [-1.1399, -1.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004679920384660363
Epoch 0, Step 2272: train/loss = 0.7031340003013611, train/raw-loss = 0.7014302015304565, train/logprobs = tensor([[-1.3223, -1.2194],
        [-1.2968, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034075905568897724
Epoch 0, Step 2273: train/loss = 0.7007321119308472, train/raw-loss = 0.6928572058677673, train/logprobs = tensor([[-1.2421, -1.5620],
        [-1.2374, -1.0813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015749722719192505
Epoch 0, Step 2274: train/loss = 0.7379225492477417, train/raw-loss = 0.6841179132461548, train/logprobs = tensor([[-1.3185, -2.9604],
        [-1.4302, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10760924965143204
Epoch 0, Step 2275: train/loss = 0.6845327615737915, train/raw-loss = 0.618161678314209, train/logprobs = tensor([[-0.9481, -2.2414],
        [-1.4624, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1327422857284546
Epoch 0, Step 2276: train/loss = 0.6999830603599548, train/raw-loss = 0.688936173915863, train/logprobs = tensor([[-1.0134, -1.4571],
        [-1.0867, -1.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02209368534386158
Epoch 0, Step 2277: train/loss = 0.6921653747558594, train/raw-loss = 0.6785374879837036, train/logprobs = tensor([[-1.2274, -1.5228],
        [-1.1595, -0.9432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027255656197667122
Epoch 0, Step 2278: train/loss = 0.6990410089492798, train/raw-loss = 0.6921635866165161, train/logprobs = tensor([[-1.0836, -1.0563],
        [-1.3055, -0.9298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013754857704043388
Epoch 0, Step 2279: train/loss = 0.6924752593040466, train/raw-loss = 0.6852200627326965, train/logprobs = tensor([[-1.1991, -1.4773],
        [-1.3621, -1.2501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014510302804410458
Epoch 0, Step 2280: train/loss = 0.6914016008377075, train/raw-loss = 0.6703870296478271, train/logprobs = tensor([[-1.0405, -1.5882],
        [-1.2729, -1.1090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04202903062105179
Epoch 0, Step 2281: train/loss = 0.7042053937911987, train/raw-loss = 0.6896414160728455, train/logprobs = tensor([[-1.4318, -1.5009],
        [-1.4298, -0.9168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029127908870577812
Epoch 0, Step 2282: train/loss = 0.697657585144043, train/raw-loss = 0.6849199533462524, train/logprobs = tensor([[-1.0672, -1.2797],
        [-1.2012, -1.3317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025475256145000458
Epoch 0, Step 2283: train/loss = 0.6934937834739685, train/raw-loss = 0.6900169849395752, train/logprobs = tensor([[-0.9907, -1.2233],
        [-1.3468, -1.2242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006953471805900335
Epoch 0, Step 2284: train/loss = 0.7093040347099304, train/raw-loss = 0.7000924348831177, train/logprobs = tensor([[-1.0539, -1.1132],
        [-1.2752, -0.9197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01842324808239937
Epoch 0, Step 2285: train/loss = 0.7116708755493164, train/raw-loss = 0.662401020526886, train/logprobs = tensor([[-1.0579, -2.1641],
        [-1.3639, -1.0496]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0985395759344101
Epoch 0, Step 2286: train/loss = 0.7466632127761841, train/raw-loss = 0.728634238243103, train/logprobs = tensor([[-1.0000, -1.6332],
        [-1.3041, -1.2447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03605794906616211
Epoch 0, Step 2287: train/loss = 0.7090483903884888, train/raw-loss = 0.6895765662193298, train/logprobs = tensor([[-1.7712, -1.3957],
        [-1.1452, -0.9879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038943544030189514
Epoch 0, Step 2288: train/loss = 0.6940480470657349, train/raw-loss = 0.6936861872673035, train/logprobs = tensor([[-1.0889, -1.1242],
        [-1.1864, -1.2014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007236752426251769
Epoch 0, Step 2289: train/loss = 0.6888821125030518, train/raw-loss = 0.6638302803039551, train/logprobs = tensor([[-1.1802, -1.7763],
        [-1.5297, -1.0847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05010366812348366
Epoch 0, Step 2290: train/loss = 0.6842830181121826, train/raw-loss = 0.6788095235824585, train/logprobs = tensor([[-1.2768, -1.4991],
        [-1.2207, -0.9673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010947064496576786
Epoch 0, Step 2291: train/loss = 0.6867616176605225, train/raw-loss = 0.6682257652282715, train/logprobs = tensor([[-1.2016, -1.5421],
        [-1.2086, -0.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037071771919727325
Epoch 0, Step 2292: train/loss = 0.7091206312179565, train/raw-loss = 0.6470330953598022, train/logprobs = tensor([[-0.9633, -2.0804],
        [-1.2971, -1.0658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1241750717163086
Epoch 0, Step 2293: train/loss = 0.6951285004615784, train/raw-loss = 0.6663459539413452, train/logprobs = tensor([[-0.9618, -1.5982],
        [-1.3263, -1.1258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0575651079416275
Epoch 0, Step 2294: train/loss = 0.6881349086761475, train/raw-loss = 0.668592095375061, train/logprobs = tensor([[-1.2313, -1.5557],
        [-1.3431, -1.0401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03908555209636688
Epoch 0, Step 2295: train/loss = 0.6992585062980652, train/raw-loss = 0.6469858884811401, train/logprobs = tensor([[-0.9739, -1.9829],
        [-1.4731, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10454510897397995
Epoch 0, Step 2296: train/loss = 0.6882704496383667, train/raw-loss = 0.6633880734443665, train/logprobs = tensor([[-1.1680, -1.8001],
        [-1.0345, -0.7944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04976475611329079
Epoch 0, Step 2297: train/loss = 0.6909492611885071, train/raw-loss = 0.6711582541465759, train/logprobs = tensor([[-1.0877, -1.3945],
        [-1.3225, -0.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0395820289850235
Epoch 0, Step 2298: train/loss = 0.7018131017684937, train/raw-loss = 0.6509519815444946, train/logprobs = tensor([[-1.1276, -2.0877],
        [-1.6033, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10172226279973984
Epoch 0, Step 2299: train/loss = 0.7305699586868286, train/raw-loss = 0.7007041573524475, train/logprobs = tensor([[-1.0563, -1.8758],
        [-1.3416, -1.2976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059731610119342804
Epoch 0, Step 2300: train/loss = 0.689872145652771, train/raw-loss = 0.6790030002593994, train/logprobs = tensor([[-1.2022, -1.4795],
        [-1.2201, -0.8683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02173824980854988
Epoch 0, Step 2301: train/loss = 0.7023264169692993, train/raw-loss = 0.6861028671264648, train/logprobs = tensor([[-0.9877, -1.5237],
        [-0.9399, -0.9544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03244723379611969
Epoch 0, Step 2302: train/loss = 0.6947900056838989, train/raw-loss = 0.6789358854293823, train/logprobs = tensor([[-1.5093, -1.5912],
        [-1.5939, -1.1409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031708285212516785
Epoch 0, Step 2303: train/loss = 0.6956393718719482, train/raw-loss = 0.6663705110549927, train/logprobs = tensor([[-1.0117, -1.8800],
        [-1.3136, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05853775888681412
Epoch 0, Step 2304: train/loss = 0.6982868909835815, train/raw-loss = 0.6952828168869019, train/logprobs = tensor([[-1.0303, -1.0941],
        [-1.0946, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006008163560181856
Epoch 0, Step 2305: train/loss = 0.7016177177429199, train/raw-loss = 0.6978772282600403, train/logprobs = tensor([[-1.4059, -1.6561],
        [-1.4150, -1.3753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007480937987565994
Epoch 0, Step 2306: train/loss = 0.7821328043937683, train/raw-loss = 0.733406662940979, train/logprobs = tensor([[-0.9645, -1.8311],
        [-1.0607, -0.9347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09745218604803085
Epoch 0, Step 2307: train/loss = 0.695703387260437, train/raw-loss = 0.687252402305603, train/logprobs = tensor([[-1.2172, -1.4437],
        [-1.1901, -1.0958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016902107745409012
Epoch 0, Step 2308: train/loss = 0.6933260560035706, train/raw-loss = 0.6723493337631226, train/logprobs = tensor([[-1.0214, -1.4281],
        [-1.1588, -0.9000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041953377425670624
Epoch 0, Step 2309: train/loss = 0.6973586082458496, train/raw-loss = 0.6818464398384094, train/logprobs = tensor([[-1.0504, -1.5800],
        [-1.0558, -0.9276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031024178490042686
Epoch 0, Step 2310: train/loss = 0.7069702744483948, train/raw-loss = 0.69487464427948, train/logprobs = tensor([[-1.1265, -1.2107],
        [-1.6769, -0.9859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02419118769466877
Epoch 0, Step 2311: train/loss = 0.7221280336380005, train/raw-loss = 0.6730436086654663, train/logprobs = tensor([[-1.0048, -2.1017],
        [-1.2770, -1.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09816873073577881
Epoch 0, Step 2312: train/loss = 0.7041542530059814, train/raw-loss = 0.6927201151847839, train/logprobs = tensor([[-1.0161, -1.2073],
        [-1.1689, -0.8348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02286830171942711
Epoch 0, Step 2313: train/loss = 0.7156933546066284, train/raw-loss = 0.687614381313324, train/logprobs = tensor([[-1.0898, -1.8386],
        [-1.5431, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056158021092414856
Epoch 0, Step 2314: train/loss = 0.7002254724502563, train/raw-loss = 0.6918599009513855, train/logprobs = tensor([[-1.3255, -1.8852],
        [-1.2121, -1.2350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01673116907477379
Epoch 0, Step 2315: train/loss = 0.6859309077262878, train/raw-loss = 0.6475522518157959, train/logprobs = tensor([[-0.9353, -1.4852],
        [-1.2724, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07675723731517792
Epoch 0, Step 2316: train/loss = 0.6953493356704712, train/raw-loss = 0.6880729794502258, train/logprobs = tensor([[-1.1024, -1.4313],
        [-1.0427, -0.9255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01455266959965229
Epoch 0, Step 2317: train/loss = 0.7102304100990295, train/raw-loss = 0.70476233959198, train/logprobs = tensor([[-1.0529, -1.3252],
        [-1.2302, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010936143808066845
Epoch 0, Step 2318: train/loss = 0.6948753595352173, train/raw-loss = 0.6738243103027344, train/logprobs = tensor([[-1.3017, -1.6712],
        [-1.3195, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042102016508579254
Epoch 0, Step 2319: train/loss = 0.7084232568740845, train/raw-loss = 0.6902803182601929, train/logprobs = tensor([[-1.0879, -1.6204],
        [-1.3371, -1.4260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03628574684262276
Epoch 0, Step 2320: train/loss = 0.6960992813110352, train/raw-loss = 0.6834643483161926, train/logprobs = tensor([[-1.1049, -1.6090],
        [-1.1984, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025269804522395134
Epoch 0, Step 2321: train/loss = 0.6836316585540771, train/raw-loss = 0.6439675092697144, train/logprobs = tensor([[-1.1570, -1.9839],
        [-1.4694, -0.9665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0793285220861435
Epoch 0, Step 2322: train/loss = 0.6933481693267822, train/raw-loss = 0.673876166343689, train/logprobs = tensor([[-1.1228, -1.5662],
        [-1.5820, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03894396498799324
Epoch 0, Step 2323: train/loss = 0.6983757615089417, train/raw-loss = 0.6710695028305054, train/logprobs = tensor([[-1.2912, -1.9305],
        [-1.2701, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05461258441209793
Epoch 0, Step 2324: train/loss = 0.7032155990600586, train/raw-loss = 0.6897701621055603, train/logprobs = tensor([[-1.0978, -1.4322],
        [-1.4510, -1.3671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026890788227319717
Epoch 0, Step 2325: train/loss = 0.6935498118400574, train/raw-loss = 0.6885424852371216, train/logprobs = tensor([[-0.9619, -1.0192],
        [-1.1261, -1.0795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010014673694968224
Epoch 0, Step 2326: train/loss = 0.6865013837814331, train/raw-loss = 0.6739491820335388, train/logprobs = tensor([[-1.3175, -1.7109],
        [-1.2835, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025104336440563202
Epoch 0, Step 2327: train/loss = 0.6993042230606079, train/raw-loss = 0.6917955875396729, train/logprobs = tensor([[-1.4183, -1.5102],
        [-1.6657, -1.2649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015017355792224407
Epoch 0, Step 2328: train/loss = 0.6934561133384705, train/raw-loss = 0.6816828846931458, train/logprobs = tensor([[-1.0551, -1.3442],
        [-1.3640, -1.2226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023546447977423668
Epoch 0, Step 2329: train/loss = 0.7108094096183777, train/raw-loss = 0.6967756152153015, train/logprobs = tensor([[-1.3642, -1.9191],
        [-0.9851, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028067613020539284
Epoch 0, Step 2330: train/loss = 0.7083965539932251, train/raw-loss = 0.6784856915473938, train/logprobs = tensor([[-1.0665, -1.9641],
        [-1.4159, -1.0759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05982176586985588
Epoch 0, Step 2331: train/loss = 0.6948635578155518, train/raw-loss = 0.6887689828872681, train/logprobs = tensor([[-1.2060, -1.2557],
        [-1.2967, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012189273722469807
Epoch 0, Step 2332: train/loss = 0.7026278972625732, train/raw-loss = 0.6787521839141846, train/logprobs = tensor([[-1.1743, -1.6573],
        [-1.2974, -1.0189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04775137081742287
Epoch 0, Step 2333: train/loss = 0.6992588639259338, train/raw-loss = 0.669289231300354, train/logprobs = tensor([[-1.0191, -1.4249],
        [-1.3649, -1.1461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05993924289941788
Epoch 0, Step 2334: train/loss = 0.6948462724685669, train/raw-loss = 0.6881200075149536, train/logprobs = tensor([[-1.0548, -1.0855],
        [-1.3367, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01345246471464634
Epoch 0, Step 2335: train/loss = 0.6953346729278564, train/raw-loss = 0.684486985206604, train/logprobs = tensor([[-1.0780, -1.3632],
        [-1.1483, -1.1250]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021695420145988464
Epoch 0, Step 2336: train/loss = 0.6971665024757385, train/raw-loss = 0.6883476972579956, train/logprobs = tensor([[-1.2509, -1.3496],
        [-1.3077, -0.9048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01763775199651718
Epoch 0, Step 2337: train/loss = 0.6909236311912537, train/raw-loss = 0.6626117825508118, train/logprobs = tensor([[-1.5507, -1.9276],
        [-1.3785, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05662371963262558
Epoch 0, Step 2338: train/loss = 0.696625292301178, train/raw-loss = 0.6874128580093384, train/logprobs = tensor([[-1.0291, -1.2678],
        [-1.2661, -0.9985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018424876034259796
Epoch 0, Step 2339: train/loss = 0.6969822645187378, train/raw-loss = 0.6944820284843445, train/logprobs = tensor([[-1.3715, -1.3493],
        [-1.1875, -1.1544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005000453442335129
Epoch 0, Step 2340: train/loss = 0.7008159160614014, train/raw-loss = 0.6983233690261841, train/logprobs = tensor([[-1.0757, -1.2363],
        [-1.0730, -1.0249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004985037259757519
Epoch 0, Step 2341: train/loss = 0.6921043395996094, train/raw-loss = 0.6699021458625793, train/logprobs = tensor([[-1.1485, -1.6583],
        [-1.2454, -0.9637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04440433531999588
Epoch 0, Step 2342: train/loss = 0.7033314108848572, train/raw-loss = 0.6562939882278442, train/logprobs = tensor([[-1.1881, -1.9370],
        [-1.5183, -1.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09407484531402588
Epoch 0, Step 2343: train/loss = 0.6902216672897339, train/raw-loss = 0.6676385998725891, train/logprobs = tensor([[-1.0872, -1.4649],
        [-1.5132, -1.1519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0451662540435791
Epoch 0, Step 2344: train/loss = 0.6876850128173828, train/raw-loss = 0.6545990705490112, train/logprobs = tensor([[-0.9012, -1.3753],
        [-1.0198, -0.7670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06617196649312973
Epoch 0, Step 2345: train/loss = 0.6924711465835571, train/raw-loss = 0.6772333979606628, train/logprobs = tensor([[-1.0159, -1.4024],
        [-1.2269, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030475564301013947
Epoch 0, Step 2346: train/loss = 0.692333459854126, train/raw-loss = 0.6745544075965881, train/logprobs = tensor([[-1.2162, -1.6741],
        [-1.2778, -1.0765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03555825725197792
Epoch 0, Step 2347: train/loss = 0.6961734294891357, train/raw-loss = 0.6889344453811646, train/logprobs = tensor([[-1.0659, -1.2859],
        [-1.3486, -1.3567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014478038996458054
Epoch 0, Step 2348: train/loss = 0.7039917707443237, train/raw-loss = 0.6611056923866272, train/logprobs = tensor([[-1.0463, -1.7555],
        [-1.7188, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08577229827642441
Epoch 0, Step 2349: train/loss = 0.7012714743614197, train/raw-loss = 0.6938543319702148, train/logprobs = tensor([[-1.1430, -1.5795],
        [-1.1492, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014834396541118622
Epoch 0, Step 2350: train/loss = 0.6950260400772095, train/raw-loss = 0.6883540749549866, train/logprobs = tensor([[-1.2386, -1.3094],
        [-1.1554, -0.8403]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013343730941414833
Epoch 0, Step 2351: train/loss = 0.6882067322731018, train/raw-loss = 0.6657590270042419, train/logprobs = tensor([[-1.1719, -1.4185],
        [-1.4333, -1.0836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044895295053720474
Epoch 0, Step 2352: train/loss = 0.68974769115448, train/raw-loss = 0.6624683141708374, train/logprobs = tensor([[-1.2363, -1.6424],
        [-1.1963, -0.7214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05455873906612396
Epoch 0, Step 2353: train/loss = 0.6948204040527344, train/raw-loss = 0.6408726572990417, train/logprobs = tensor([[-1.0346, -1.9319],
        [-1.5135, -1.1167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10789553821086884
Epoch 0, Step 2354: train/loss = 0.7269182205200195, train/raw-loss = 0.6952658891677856, train/logprobs = tensor([[-1.0476, -2.0106],
        [-1.1461, -1.2183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06330466270446777
Epoch 0, Step 2355: train/loss = 0.7214772701263428, train/raw-loss = 0.7020258903503418, train/logprobs = tensor([[-1.1076, -1.5607],
        [-1.2624, -1.1077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038902703672647476
Epoch 0, Step 2356: train/loss = 0.6987556219100952, train/raw-loss = 0.6646782755851746, train/logprobs = tensor([[-1.0896, -1.6089],
        [-1.6631, -1.1273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06815474480390549
Epoch 0, Step 2357: train/loss = 0.6952770948410034, train/raw-loss = 0.6903934478759766, train/logprobs = tensor([[-1.3605, -1.6038],
        [-1.3005, -1.2475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009767221286892891
Epoch 0, Step 2358: train/loss = 0.7088577747344971, train/raw-loss = 0.7006933689117432, train/logprobs = tensor([[-1.3246, -1.5886],
        [-1.2969, -1.1853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016328755766153336
Epoch 0, Step 2359: train/loss = 0.6998953223228455, train/raw-loss = 0.6826106309890747, train/logprobs = tensor([[-1.0295, -1.3450],
        [-1.3748, -0.9394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03456950932741165
Epoch 0, Step 2360: train/loss = 0.6987462639808655, train/raw-loss = 0.6541012525558472, train/logprobs = tensor([[-1.2509, -2.2269],
        [-1.5099, -1.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08929000794887543
Epoch 0, Step 2361: train/loss = 0.6950801014900208, train/raw-loss = 0.6820325255393982, train/logprobs = tensor([[-1.2798, -1.6688],
        [-1.4190, -1.2510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026095174252986908
Epoch 0, Step 2362: train/loss = 0.6928970217704773, train/raw-loss = 0.6852964758872986, train/logprobs = tensor([[-0.9664, -1.1458],
        [-1.1735, -0.9036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015200997702777386
Epoch 0, Step 2363: train/loss = 0.6887884140014648, train/raw-loss = 0.6472588777542114, train/logprobs = tensor([[-1.0175, -1.6846],
        [-1.6148, -1.1126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08305903524160385
Epoch 0, Step 2364: train/loss = 0.7058419585227966, train/raw-loss = 0.6847965717315674, train/logprobs = tensor([[-1.2387, -1.6439],
        [-1.4382, -1.1159]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04209069907665253
Epoch 0, Step 2365: train/loss = 0.698364794254303, train/raw-loss = 0.6930155158042908, train/logprobs = tensor([[-0.9886, -1.3029],
        [-1.2857, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010698462836444378
Epoch 0, Step 2366: train/loss = 0.6973004937171936, train/raw-loss = 0.6891449093818665, train/logprobs = tensor([[-1.0303, -1.2155],
        [-1.1816, -0.9246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016311097890138626
Epoch 0, Step 2367: train/loss = 0.703075647354126, train/raw-loss = 0.6948091983795166, train/logprobs = tensor([[-1.1896, -1.4328],
        [-1.3745, -1.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016532694920897484
Epoch 0, Step 2368: train/loss = 0.6918642520904541, train/raw-loss = 0.6795260906219482, train/logprobs = tensor([[-1.1060, -1.3655],
        [-1.1766, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024676265195012093
Epoch 0, Step 2369: train/loss = 0.7001867890357971, train/raw-loss = 0.6878781318664551, train/logprobs = tensor([[-1.3710, -1.4452],
        [-1.4640, -0.9625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02461739256978035
Epoch 0, Step 2370: train/loss = 0.6850179433822632, train/raw-loss = 0.6478765606880188, train/logprobs = tensor([[-0.7617, -1.3568],
        [-1.2662, -0.8318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07428271323442459
Epoch 0, Step 2371: train/loss = 0.6986181139945984, train/raw-loss = 0.6735737919807434, train/logprobs = tensor([[-1.1348, -1.5389],
        [-1.3498, -1.3214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050088584423065186
Epoch 0, Step 2372: train/loss = 0.69416743516922, train/raw-loss = 0.6709569692611694, train/logprobs = tensor([[-1.1799, -1.4710],
        [-1.4437, -1.1041]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0464208610355854
Epoch 0, Step 2373: train/loss = 0.6888114213943481, train/raw-loss = 0.6576660871505737, train/logprobs = tensor([[-1.0911, -1.8729],
        [-1.4109, -1.0829]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06229066848754883
Epoch 0, Step 2374: train/loss = 0.7020493149757385, train/raw-loss = 0.6847034692764282, train/logprobs = tensor([[-1.2778, -1.4023],
        [-1.7903, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03469166159629822
Epoch 0, Step 2375: train/loss = 0.6989415884017944, train/raw-loss = 0.6930233240127563, train/logprobs = tensor([[-1.2963, -1.4908],
        [-1.4324, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011836457066237926
Epoch 0, Step 2376: train/loss = 0.6950339078903198, train/raw-loss = 0.6918501257896423, train/logprobs = tensor([[-1.2089, -1.2783],
        [-1.0898, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006367526948451996
Epoch 0, Step 2377: train/loss = 0.695452868938446, train/raw-loss = 0.6845874190330505, train/logprobs = tensor([[-1.2954, -1.5572],
        [-1.0142, -0.9664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021730860695242882
Epoch 0, Step 2378: train/loss = 0.6868134140968323, train/raw-loss = 0.6854455471038818, train/logprobs = tensor([[-1.6846, -1.8447],
        [-1.3475, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027356604114174843
Epoch 0, Step 2379: train/loss = 0.6947681903839111, train/raw-loss = 0.6859256625175476, train/logprobs = tensor([[-1.0571, -1.0203],
        [-1.2155, -1.0404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017685024067759514
Epoch 0, Step 2380: train/loss = 0.7081983685493469, train/raw-loss = 0.644883930683136, train/logprobs = tensor([[-1.3145, -2.5930],
        [-1.3460, -1.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12662887573242188
Epoch 0, Step 2381: train/loss = 0.705280065536499, train/raw-loss = 0.702748715877533, train/logprobs = tensor([[-1.3302, -1.2896],
        [-1.1149, -0.8035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005062774755060673
Epoch 0, Step 2382: train/loss = 0.6858211755752563, train/raw-loss = 0.6754651665687561, train/logprobs = tensor([[-1.3048, -1.6830],
        [-1.5252, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020712079480290413
Epoch 0, Step 2383: train/loss = 0.6877567768096924, train/raw-loss = 0.6309394836425781, train/logprobs = tensor([[-0.9537, -1.7386],
        [-1.5711, -1.1809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1136346086859703
Epoch 0, Step 2384: train/loss = 0.6931267976760864, train/raw-loss = 0.6684480309486389, train/logprobs = tensor([[-1.0519, -1.6316],
        [-1.3657, -1.0405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04935748130083084
Epoch 0, Step 2385: train/loss = 0.6792463064193726, train/raw-loss = 0.6584866642951965, train/logprobs = tensor([[-1.1577, -1.5052],
        [-1.2945, -1.0420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04151937738060951
Epoch 0, Step 2386: train/loss = 0.6902162432670593, train/raw-loss = 0.6805326342582703, train/logprobs = tensor([[-1.1016, -1.4002],
        [-1.2736, -1.2085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019367365166544914
Epoch 0, Step 2387: train/loss = 0.7365683317184448, train/raw-loss = 0.7235109806060791, train/logprobs = tensor([[-0.9891, -1.6588],
        [-1.5209, -1.6781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026114623993635178
Epoch 0, Step 2388: train/loss = 0.7573214769363403, train/raw-loss = 0.7464348077774048, train/logprobs = tensor([[-1.7934, -1.3368],
        [-1.8087, -1.3800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021773304790258408
Epoch 0, Step 2389: train/loss = 0.6972424387931824, train/raw-loss = 0.6859238147735596, train/logprobs = tensor([[-1.0883, -1.3925],
        [-1.1615, -1.0301]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02263723313808441
Epoch 0, Step 2390: train/loss = 0.7051158547401428, train/raw-loss = 0.6927210092544556, train/logprobs = tensor([[-1.1491, -1.6379],
        [-1.3682, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024789663031697273
Epoch 0, Step 2391: train/loss = 0.6934921145439148, train/raw-loss = 0.6917439699172974, train/logprobs = tensor([[-1.3484, -1.4365],
        [-1.3472, -1.3486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003496284130960703
Epoch 0, Step 2392: train/loss = 0.692284107208252, train/raw-loss = 0.6706117391586304, train/logprobs = tensor([[-1.3426, -1.7386],
        [-1.4885, -1.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043344803154468536
Epoch 0, Step 2393: train/loss = 0.6931581497192383, train/raw-loss = 0.6764299869537354, train/logprobs = tensor([[-1.2073, -1.6610],
        [-1.4098, -1.2117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033456284552812576
Epoch 0, Step 2394: train/loss = 0.6944583654403687, train/raw-loss = 0.6918880343437195, train/logprobs = tensor([[-1.3857, -1.5718],
        [-1.1059, -1.1029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005140769295394421
Epoch 0, Step 2395: train/loss = 0.6911186575889587, train/raw-loss = 0.6724405884742737, train/logprobs = tensor([[-1.2201, -1.2990],
        [-1.4217, -1.2330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037356071174144745
Epoch 0, Step 2396: train/loss = 0.7105291485786438, train/raw-loss = 0.6571909785270691, train/logprobs = tensor([[-1.0566, -2.1705],
        [-1.4661, -1.1881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1066763773560524
Epoch 0, Step 2397: train/loss = 0.7061262130737305, train/raw-loss = 0.7035631537437439, train/logprobs = tensor([[-1.4493, -1.6033],
        [-1.4591, -1.3846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005126189440488815
Epoch 0, Step 2398: train/loss = 0.6928533315658569, train/raw-loss = 0.6747221946716309, train/logprobs = tensor([[-0.9821, -1.4503],
        [-1.2830, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03626236692070961
Epoch 0, Step 2399: train/loss = 0.6943920254707336, train/raw-loss = 0.6894375085830688, train/logprobs = tensor([[-1.5610, -1.7588],
        [-1.2575, -1.1947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00990904588252306
Epoch 0, Step 2400: train/loss = 0.6963334083557129, train/raw-loss = 0.6859173774719238, train/logprobs = tensor([[-1.2232, -1.6537],
        [-1.1858, -1.0861]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020832082256674767
Epoch 0, Step 2401: train/loss = 0.6985927820205688, train/raw-loss = 0.6658653020858765, train/logprobs = tensor([[-1.1090, -1.9315],
        [-1.5177, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06545490771532059
Epoch 0, Step 2402: train/loss = 0.6842073798179626, train/raw-loss = 0.6162552833557129, train/logprobs = tensor([[-0.9419, -1.6901],
        [-1.8072, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1359042227268219
Epoch 0, Step 2403: train/loss = 0.6980117559432983, train/raw-loss = 0.6898560523986816, train/logprobs = tensor([[-1.2976, -1.1674],
        [-1.2796, -1.3757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016311364248394966
Epoch 0, Step 2404: train/loss = 0.6872758865356445, train/raw-loss = 0.651181161403656, train/logprobs = tensor([[-0.9476, -1.2686],
        [-1.4383, -1.0017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0721893385052681
Epoch 0, Step 2405: train/loss = 0.6965690851211548, train/raw-loss = 0.6865658760070801, train/logprobs = tensor([[-1.1234, -1.2251],
        [-1.4906, -1.0860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020006418228149414
Epoch 0, Step 2406: train/loss = 0.6884177923202515, train/raw-loss = 0.6742498278617859, train/logprobs = tensor([[-1.2121, -1.6298],
        [-1.4886, -1.2620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028335770592093468
Epoch 0, Step 2407: train/loss = 0.6978389024734497, train/raw-loss = 0.6943366527557373, train/logprobs = tensor([[-1.1844, -1.4054],
        [-1.3464, -1.2646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007004440296441317
Epoch 0, Step 2408: train/loss = 0.6885449886322021, train/raw-loss = 0.6711435914039612, train/logprobs = tensor([[-1.2949, -1.4941],
        [-1.7937, -1.1257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03480278328061104
Epoch 0, Step 2409: train/loss = 0.701718270778656, train/raw-loss = 0.6740610599517822, train/logprobs = tensor([[-1.0128, -1.6008],
        [-1.4430, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055314358323812485
Epoch 0, Step 2410: train/loss = 0.7030664682388306, train/raw-loss = 0.6993100643157959, train/logprobs = tensor([[-1.2138, -1.1605],
        [-1.9108, -1.5233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007512782234698534
Epoch 0, Step 2411: train/loss = 0.6912818551063538, train/raw-loss = 0.6731261610984802, train/logprobs = tensor([[-0.9922, -1.4429],
        [-1.5830, -1.4426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03631123900413513
Epoch 0, Step 2412: train/loss = 0.689125120639801, train/raw-loss = 0.6789387464523315, train/logprobs = tensor([[-1.1234, -1.3749],
        [-1.3228, -1.1968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020372755825519562
Epoch 0, Step 2413: train/loss = 0.6979049444198608, train/raw-loss = 0.686010479927063, train/logprobs = tensor([[-1.7381, -2.0234],
        [-1.1727, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02378876507282257
Epoch 0, Step 2414: train/loss = 0.6837579011917114, train/raw-loss = 0.64902663230896, train/logprobs = tensor([[-1.1319, -1.4703],
        [-1.6767, -1.1019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0694625973701477
Epoch 0, Step 2415: train/loss = 0.6950551867485046, train/raw-loss = 0.6853699088096619, train/logprobs = tensor([[-1.1213, -1.5558],
        [-1.3901, -1.1606]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019370581954717636
Epoch 0, Step 2416: train/loss = 0.6972945928573608, train/raw-loss = 0.6928317546844482, train/logprobs = tensor([[-1.0202, -1.1011],
        [-1.1988, -1.0112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00892559066414833
Epoch 0, Step 2417: train/loss = 0.6953941583633423, train/raw-loss = 0.6940315961837769, train/logprobs = tensor([[-1.2833, -1.3188],
        [-1.1474, -1.0260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027252202853560448
Epoch 0, Step 2418: train/loss = 0.6908921003341675, train/raw-loss = 0.6854427456855774, train/logprobs = tensor([[-1.0496, -1.3328],
        [-1.3757, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010898628272116184
Epoch 0, Step 2419: train/loss = 0.6786015629768372, train/raw-loss = 0.6201902627944946, train/logprobs = tensor([[-1.2931, -1.8882],
        [-1.6381, -0.8574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11682260036468506
Epoch 0, Step 2420: train/loss = 0.6969476938247681, train/raw-loss = 0.6964454650878906, train/logprobs = tensor([[-1.3793, -1.5779],
        [-1.2586, -1.2698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001004340359941125
Epoch 0, Step 2421: train/loss = 0.6943637728691101, train/raw-loss = 0.6918366551399231, train/logprobs = tensor([[-1.2157, -1.2199],
        [-1.1851, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005054267589002848
Epoch 0, Step 2422: train/loss = 0.6971668004989624, train/raw-loss = 0.6817663908004761, train/logprobs = tensor([[-1.0576, -1.3720],
        [-1.3243, -1.1694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03080078400671482
Epoch 0, Step 2423: train/loss = 0.6932363510131836, train/raw-loss = 0.6510553359985352, train/logprobs = tensor([[-1.1006, -1.7928],
        [-1.4443, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08436205983161926
Epoch 0, Step 2424: train/loss = 0.6904818415641785, train/raw-loss = 0.6712989807128906, train/logprobs = tensor([[-1.1153, -1.4036],
        [-1.4691, -1.0737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03836558759212494
Epoch 0, Step 2425: train/loss = 0.6968160271644592, train/raw-loss = 0.6637609004974365, train/logprobs = tensor([[-1.3668, -1.8475],
        [-1.7411, -1.1986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06611026078462601
Epoch 0, Step 2426: train/loss = 0.6952978372573853, train/raw-loss = 0.6896649599075317, train/logprobs = tensor([[-1.4498, -1.7976],
        [-1.2137, -1.1135]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011265713721513748
Epoch 0, Step 2427: train/loss = 0.696869969367981, train/raw-loss = 0.6901044845581055, train/logprobs = tensor([[-1.1506, -1.1815],
        [-1.1705, -0.8835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013531049713492393
Epoch 0, Step 2428: train/loss = 0.7005611658096313, train/raw-loss = 0.6812835335731506, train/logprobs = tensor([[-0.9479, -1.4364],
        [-1.3960, -1.1839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0385553278028965
Epoch 0, Step 2429: train/loss = 0.6852165460586548, train/raw-loss = 0.6785818338394165, train/logprobs = tensor([[-1.3409, -1.5611],
        [-1.4870, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013269394636154175
Epoch 0, Step 2430: train/loss = 0.7087545990943909, train/raw-loss = 0.7023960947990417, train/logprobs = tensor([[-1.3723, -1.7463],
        [-1.3690, -1.2148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012716913595795631
Epoch 0, Step 2431: train/loss = 0.7025787234306335, train/raw-loss = 0.6780591607093811, train/logprobs = tensor([[-1.2792, -1.8505],
        [-1.6642, -1.4575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04903903976082802
Epoch 0, Step 2432: train/loss = 0.6925582885742188, train/raw-loss = 0.6774937510490417, train/logprobs = tensor([[-1.1217, -1.6355],
        [-1.4696, -1.1663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030129078775644302
Epoch 0, Step 2433: train/loss = 0.6945125460624695, train/raw-loss = 0.6846896409988403, train/logprobs = tensor([[-1.1186, -1.2765],
        [-1.3705, -0.9994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01964580826461315
Epoch 0, Step 2434: train/loss = 0.6861751675605774, train/raw-loss = 0.6590624451637268, train/logprobs = tensor([[-1.1406, -1.6080],
        [-1.5328, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05422548949718475
Epoch 0, Step 2435: train/loss = 0.6964321732521057, train/raw-loss = 0.6825312376022339, train/logprobs = tensor([[-1.7119, -1.6152],
        [-1.3039, -1.3346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02780172973871231
Epoch 0, Step 2436: train/loss = 0.6876479387283325, train/raw-loss = 0.6656588315963745, train/logprobs = tensor([[-1.1690, -1.6650],
        [-1.3763, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04397817328572273
Epoch 0, Step 2437: train/loss = 0.6921485662460327, train/raw-loss = 0.6714816689491272, train/logprobs = tensor([[-1.1366, -1.6542],
        [-1.2247, -0.9873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041333939880132675
Epoch 0, Step 2438: train/loss = 0.6926438808441162, train/raw-loss = 0.6471325159072876, train/logprobs = tensor([[-1.2826, -1.7197],
        [-1.6108, -1.0205]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09102261811494827
Epoch 0, Step 2439: train/loss = 0.6831982135772705, train/raw-loss = 0.6656532883644104, train/logprobs = tensor([[-1.1208, -1.6239],
        [-1.7260, -1.3172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0350898802280426
Epoch 0, Step 2440: train/loss = 0.701543390750885, train/raw-loss = 0.6874533891677856, train/logprobs = tensor([[-1.1475, -1.6791],
        [-1.4107, -1.3733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028180141001939774
Epoch 0, Step 2441: train/loss = 0.6926661133766174, train/raw-loss = 0.6886122226715088, train/logprobs = tensor([[-1.0108, -1.1497],
        [-1.1068, -0.9316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008107910864055157
Epoch 0, Step 2442: train/loss = 0.7068238854408264, train/raw-loss = 0.6955643892288208, train/logprobs = tensor([[-1.2014, -1.2143],
        [-1.4195, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022518975660204887
Epoch 0, Step 2443: train/loss = 0.6962783932685852, train/raw-loss = 0.6878451108932495, train/logprobs = tensor([[-0.8730, -1.2049],
        [-1.2748, -1.1703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016866445541381836
Epoch 0, Step 2444: train/loss = 0.700525164604187, train/raw-loss = 0.6762925386428833, train/logprobs = tensor([[-1.0372, -1.3002],
        [-1.5976, -1.4354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0484653040766716
Epoch 0, Step 2445: train/loss = 0.6876823902130127, train/raw-loss = 0.6504723429679871, train/logprobs = tensor([[-1.1911, -1.6754],
        [-1.5976, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07442010194063187
Epoch 0, Step 2446: train/loss = 0.6826053857803345, train/raw-loss = 0.6267711520195007, train/logprobs = tensor([[-0.9368, -2.0592],
        [-1.6063, -1.0523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11166854202747345
Epoch 0, Step 2447: train/loss = 0.6914230585098267, train/raw-loss = 0.6755391955375671, train/logprobs = tensor([[-1.0462, -1.3024],
        [-1.1550, -0.8461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031767718493938446
Epoch 0, Step 2448: train/loss = 0.6923045516014099, train/raw-loss = 0.689337432384491, train/logprobs = tensor([[-1.1173, -1.3132],
        [-1.1536, -1.0474]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005934255663305521
Epoch 0, Step 2449: train/loss = 0.692402720451355, train/raw-loss = 0.6833279132843018, train/logprobs = tensor([[-1.3012, -1.4010],
        [-1.5246, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018149694427847862
Epoch 0, Step 2450: train/loss = 0.770153284072876, train/raw-loss = 0.7655289173126221, train/logprobs = tensor([[-1.3263, -1.1702],
        [-1.4849, -0.9683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009248681366443634
Epoch 0, Step 2451: train/loss = 0.6916135549545288, train/raw-loss = 0.6642678380012512, train/logprobs = tensor([[-1.1572, -1.5681],
        [-1.4958, -1.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05469142645597458
Epoch 0, Step 2452: train/loss = 0.7046534419059753, train/raw-loss = 0.6919040679931641, train/logprobs = tensor([[-1.2326, -1.6377],
        [-1.5064, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02549874782562256
Epoch 0, Step 2453: train/loss = 0.6918328404426575, train/raw-loss = 0.6638475656509399, train/logprobs = tensor([[-1.0804, -1.3185],
        [-1.3713, -0.7728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05597051605582237
Epoch 0, Step 2454: train/loss = 0.7015641927719116, train/raw-loss = 0.6962356567382812, train/logprobs = tensor([[-1.0108, -1.4409],
        [-1.3557, -1.3642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010657106526196003
Epoch 0, Step 2455: train/loss = 0.6819592714309692, train/raw-loss = 0.657158613204956, train/logprobs = tensor([[-1.0168, -1.3721],
        [-1.3549, -0.8955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04960114508867264
Epoch 0, Step 2456: train/loss = 0.7024000287055969, train/raw-loss = 0.6901286244392395, train/logprobs = tensor([[-1.2445, -1.2932],
        [-1.4289, -1.0448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024542812258005142
Epoch 0, Step 2457: train/loss = 0.698207437992096, train/raw-loss = 0.6588073372840881, train/logprobs = tensor([[-1.1062, -1.8575],
        [-1.6790, -1.3311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07880023121833801
Epoch 0, Step 2458: train/loss = 0.6917490363121033, train/raw-loss = 0.6798646450042725, train/logprobs = tensor([[-1.0409, -1.3229],
        [-1.1138, -0.8536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0237688347697258
Epoch 0, Step 2459: train/loss = 0.6925937533378601, train/raw-loss = 0.6614851951599121, train/logprobs = tensor([[-1.3057, -1.6763],
        [-1.6558, -1.3860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06221707537770271
Epoch 0, Step 2460: train/loss = 0.6946312785148621, train/raw-loss = 0.6839085817337036, train/logprobs = tensor([[-1.1763, -1.2547],
        [-1.4690, -1.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021445414051413536
Epoch 0, Step 2461: train/loss = 0.6913865208625793, train/raw-loss = 0.6784144639968872, train/logprobs = tensor([[-1.1360, -1.5510],
        [-1.3007, -0.9837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025944039225578308
Epoch 0, Step 2462: train/loss = 0.6999846696853638, train/raw-loss = 0.6789249181747437, train/logprobs = tensor([[-1.0021, -1.1156],
        [-1.4298, -0.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04211945831775665
Epoch 0, Step 2463: train/loss = 0.6913235187530518, train/raw-loss = 0.6865352392196655, train/logprobs = tensor([[-1.5963, -1.6611],
        [-1.2445, -0.9477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009576458483934402
Epoch 0, Step 2464: train/loss = 0.6989144682884216, train/raw-loss = 0.6974796056747437, train/logprobs = tensor([[-1.2916, -1.1951],
        [-1.2687, -1.0288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002869709860533476
Epoch 0, Step 2465: train/loss = 0.6957433223724365, train/raw-loss = 0.6736066937446594, train/logprobs = tensor([[-1.0682, -1.3789],
        [-1.2989, -0.9132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044273242354393005
Epoch 0, Step 2466: train/loss = 0.6931862235069275, train/raw-loss = 0.6830015182495117, train/logprobs = tensor([[-1.0721, -1.3250],
        [-1.3116, -1.0657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020369362086057663
Epoch 0, Step 2467: train/loss = 0.7122445106506348, train/raw-loss = 0.7069149017333984, train/logprobs = tensor([[-1.3987, -1.1950],
        [-1.4664, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010659053921699524
Epoch 0, Step 2468: train/loss = 0.6952311992645264, train/raw-loss = 0.6947023868560791, train/logprobs = tensor([[-1.1187, -1.2015],
        [-1.2254, -1.1686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010575810447335243
Epoch 0, Step 2469: train/loss = 0.7006991505622864, train/raw-loss = 0.6824285387992859, train/logprobs = tensor([[-1.1279, -1.5876],
        [-1.3742, -0.9881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03654124587774277
Epoch 0, Step 2470: train/loss = 0.6922426223754883, train/raw-loss = 0.6889177560806274, train/logprobs = tensor([[-1.2067, -1.3072],
        [-1.4976, -1.2941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006649716291576624
Epoch 0, Step 2471: train/loss = 0.6770505905151367, train/raw-loss = 0.650820791721344, train/logprobs = tensor([[-1.1234, -1.4469],
        [-1.6841, -1.4492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052459560334682465
Epoch 0, Step 2472: train/loss = 0.691769540309906, train/raw-loss = 0.680821418762207, train/logprobs = tensor([[-1.0420, -1.2746],
        [-1.2818, -1.0668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021896306425333023
Epoch 0, Step 2473: train/loss = 0.7011148929595947, train/raw-loss = 0.698606550693512, train/logprobs = tensor([[-1.1556, -1.0807],
        [-1.5008, -1.4878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005016535520553589
Epoch 0, Step 2474: train/loss = 0.6994575262069702, train/raw-loss = 0.6966322660446167, train/logprobs = tensor([[-1.2779, -1.3346],
        [-1.6958, -1.5991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005650480277836323
Epoch 0, Step 2475: train/loss = 0.6982873678207397, train/raw-loss = 0.6702253818511963, train/logprobs = tensor([[-1.0626, -1.5697],
        [-1.5182, -1.1023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05612405389547348
Epoch 0, Step 2476: train/loss = 0.6941245794296265, train/raw-loss = 0.6795516014099121, train/logprobs = tensor([[-1.0629, -1.4696],
        [-1.5701, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029145997017621994
Epoch 0, Step 2477: train/loss = 0.6751119494438171, train/raw-loss = 0.6488428711891174, train/logprobs = tensor([[-1.0640, -1.4349],
        [-1.6944, -0.9854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05253826826810837
Epoch 0, Step 2478: train/loss = 0.6923645734786987, train/raw-loss = 0.671368420124054, train/logprobs = tensor([[-1.2530, -1.5354],
        [-1.6628, -1.4311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04199223592877388
Epoch 0, Step 2479: train/loss = 0.6875458359718323, train/raw-loss = 0.6493239402770996, train/logprobs = tensor([[-1.0659, -1.7260],
        [-1.3764, -0.9986]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07644373178482056
Epoch 0, Step 2480: train/loss = 0.6918802261352539, train/raw-loss = 0.674017071723938, train/logprobs = tensor([[-1.2423, -1.5824],
        [-1.5446, -1.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03572634235024452
Epoch 0, Step 2481: train/loss = 0.7001410722732544, train/raw-loss = 0.6694670915603638, train/logprobs = tensor([[-1.0633, -1.3697],
        [-1.8992, -1.1338]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06134801357984543
Epoch 0, Step 2482: train/loss = 0.6984426975250244, train/raw-loss = 0.6708356142044067, train/logprobs = tensor([[-1.0883, -1.1729],
        [-1.6422, -0.8892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055214088410139084
Epoch 0, Step 2483: train/loss = 0.6914964318275452, train/raw-loss = 0.6557095050811768, train/logprobs = tensor([[-1.0705, -1.4516],
        [-1.6130, -1.0285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07157386094331741
Epoch 0, Step 2484: train/loss = 0.6953604817390442, train/raw-loss = 0.6915744543075562, train/logprobs = tensor([[-1.1886, -1.1916],
        [-1.4836, -1.1958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007571895606815815
Epoch 0, Step 2485: train/loss = 0.6914761066436768, train/raw-loss = 0.6771547794342041, train/logprobs = tensor([[-1.2823, -1.3903],
        [-1.5076, -1.2678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028642673045396805
Epoch 0, Step 2486: train/loss = 0.7073951959609985, train/raw-loss = 0.6881071329116821, train/logprobs = tensor([[-1.2045, -1.2377],
        [-1.7587, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03857634961605072
Epoch 0, Step 2487: train/loss = 0.6887010335922241, train/raw-loss = 0.6512086391448975, train/logprobs = tensor([[-0.9934, -1.5399],
        [-1.2730, -0.9365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07498473674058914
Epoch 0, Step 2488: train/loss = 0.6935821175575256, train/raw-loss = 0.6186299324035645, train/logprobs = tensor([[-1.2536, -1.8261],
        [-1.8744, -0.9701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14990440011024475
Epoch 0, Step 2489: train/loss = 0.6866967678070068, train/raw-loss = 0.6604263186454773, train/logprobs = tensor([[-0.9024, -1.5261],
        [-1.6686, -1.3734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05254095047712326
Epoch 0, Step 2490: train/loss = 0.6937822699546814, train/raw-loss = 0.6791970133781433, train/logprobs = tensor([[-1.1488, -1.4761],
        [-1.3753, -1.1707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029170485213398933
Epoch 0, Step 2491: train/loss = 0.6960650086402893, train/raw-loss = 0.6795989274978638, train/logprobs = tensor([[-1.1427, -1.4026],
        [-1.3822, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032932307571172714
Epoch 0, Step 2492: train/loss = 0.6763268709182739, train/raw-loss = 0.6448215842247009, train/logprobs = tensor([[-1.0317, -1.6286],
        [-1.6660, -1.2838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06301066279411316
Epoch 0, Step 2493: train/loss = 0.6881992220878601, train/raw-loss = 0.6294265985488892, train/logprobs = tensor([[-1.1552, -1.8909],
        [-1.6990, -1.1926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11754517257213593
Epoch 0, Step 2494: train/loss = 0.6878724098205566, train/raw-loss = 0.6667709350585938, train/logprobs = tensor([[-1.1860, -1.7324],
        [-1.4057, -1.1450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042202942073345184
Epoch 0, Step 2495: train/loss = 0.694054126739502, train/raw-loss = 0.6830865144729614, train/logprobs = tensor([[-1.0170, -1.2355],
        [-1.3234, -1.0527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02193526364862919
Epoch 0, Step 2496: train/loss = 0.6910394430160522, train/raw-loss = 0.6669482588768005, train/logprobs = tensor([[-1.1439, -1.3379],
        [-1.5741, -1.0837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048182398080825806
Epoch 0, Step 2497: train/loss = 0.6979376077651978, train/raw-loss = 0.6685393452644348, train/logprobs = tensor([[-0.9858, -1.2063],
        [-1.7244, -0.9804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058796461671590805
Epoch 0, Step 2498: train/loss = 0.6944772601127625, train/raw-loss = 0.6815670728683472, train/logprobs = tensor([[-1.2139, -1.3420],
        [-1.2261, -0.8690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025820434093475342
Epoch 0, Step 2499: train/loss = 0.7148263454437256, train/raw-loss = 0.7080491185188293, train/logprobs = tensor([[-1.1968, -1.1566],
        [-1.6221, -1.2374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013554466888308525
eval/loss: 0.6952247619628906
Epoch 0, Step 2500: train/loss = 0.6974581480026245, train/raw-loss = 0.6555981636047363, train/logprobs = tensor([[-1.1566, -1.7652],
        [-1.3490, -0.9416]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08371992409229279
Epoch 0, Step 2501: train/loss = 0.703129768371582, train/raw-loss = 0.6687711477279663, train/logprobs = tensor([[-0.9088, -1.1307],
        [-1.7076, -0.9791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06871730834245682
Epoch 0, Step 2502: train/loss = 0.6937977075576782, train/raw-loss = 0.6713805794715881, train/logprobs = tensor([[-1.0356, -1.4185],
        [-1.4291, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044834207743406296
Epoch 0, Step 2503: train/loss = 0.6806119084358215, train/raw-loss = 0.6575382947921753, train/logprobs = tensor([[-1.2025, -1.4760],
        [-1.5048, -1.1308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04614715650677681
Epoch 0, Step 2504: train/loss = 0.6921391487121582, train/raw-loss = 0.6793889999389648, train/logprobs = tensor([[-0.9639, -1.1709],
        [-1.1100, -0.9278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02550048567354679
Epoch 0, Step 2505: train/loss = 0.7033166885375977, train/raw-loss = 0.7004214525222778, train/logprobs = tensor([[-1.3190, -1.3478],
        [-1.6832, -1.3448]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005790332797914743
Epoch 0, Step 2506: train/loss = 0.7022480368614197, train/raw-loss = 0.6820234060287476, train/logprobs = tensor([[-0.9540, -1.1921],
        [-1.2433, -0.7747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04044923186302185
Epoch 0, Step 2507: train/loss = 0.6958868503570557, train/raw-loss = 0.6665846109390259, train/logprobs = tensor([[-1.2276, -1.4318],
        [-1.6741, -1.0796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05860453099012375
Epoch 0, Step 2508: train/loss = 0.6972001791000366, train/raw-loss = 0.6779767274856567, train/logprobs = tensor([[-1.0578, -1.2738],
        [-1.1670, -0.8332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03844689577817917
Epoch 0, Step 2509: train/loss = 0.6986684799194336, train/raw-loss = 0.6750305891036987, train/logprobs = tensor([[-1.2963, -1.5268],
        [-1.6534, -1.1102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04727568477392197
Epoch 0, Step 2510: train/loss = 0.69430011510849, train/raw-loss = 0.6930592656135559, train/logprobs = tensor([[-1.4532, -1.4685],
        [-1.2630, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002481833565980196
Epoch 0, Step 2511: train/loss = 0.6949412822723389, train/raw-loss = 0.6926432847976685, train/logprobs = tensor([[-1.1991, -1.3612],
        [-1.0847, -1.0101]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004596100654453039
Epoch 0, Step 2512: train/loss = 0.6942014694213867, train/raw-loss = 0.6924777030944824, train/logprobs = tensor([[-1.1490, -1.1472],
        [-1.2080, -1.0310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034474427811801434
Epoch 0, Step 2513: train/loss = 0.6912040114402771, train/raw-loss = 0.6653046011924744, train/logprobs = tensor([[-0.8719, -1.1302],
        [-1.4750, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05179882049560547
Epoch 0, Step 2514: train/loss = 0.6916147470474243, train/raw-loss = 0.687640368938446, train/logprobs = tensor([[-1.4429, -1.5644],
        [-1.4319, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007948639802634716
Epoch 0, Step 2515: train/loss = 0.6885274648666382, train/raw-loss = 0.6656509637832642, train/logprobs = tensor([[-1.0170, -1.2634],
        [-1.3646, -0.9358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04575316980481148
Epoch 0, Step 2516: train/loss = 0.6878107190132141, train/raw-loss = 0.6367967128753662, train/logprobs = tensor([[-0.9828, -1.6074],
        [-1.5346, -1.1281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10202813148498535
Epoch 0, Step 2517: train/loss = 0.7024599313735962, train/raw-loss = 0.69358891248703, train/logprobs = tensor([[-1.3208, -1.5446],
        [-1.5768, -1.2043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017742052674293518
Epoch 0, Step 2518: train/loss = 0.6867156028747559, train/raw-loss = 0.6603203415870667, train/logprobs = tensor([[-0.9768, -1.2941],
        [-1.4437, -1.0241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052790552377700806
Epoch 0, Step 2519: train/loss = 0.6974459886550903, train/raw-loss = 0.6886003017425537, train/logprobs = tensor([[-0.9244, -1.0569],
        [-1.3818, -1.1020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017691295593976974
Epoch 0, Step 2520: train/loss = 0.6943361759185791, train/raw-loss = 0.6942769289016724, train/logprobs = tensor([[-1.2999, -1.3371],
        [-1.1068, -1.1001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011850340524688363
Epoch 0, Step 2521: train/loss = 0.7217147946357727, train/raw-loss = 0.7122073769569397, train/logprobs = tensor([[-1.0236, -1.4991],
        [-1.1277, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019014868885278702
Epoch 0, Step 2522: train/loss = 0.6861295700073242, train/raw-loss = 0.6594933867454529, train/logprobs = tensor([[-0.9620, -1.4524],
        [-1.5185, -1.0540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053272515535354614
Epoch 0, Step 2523: train/loss = 0.6865322589874268, train/raw-loss = 0.6749922037124634, train/logprobs = tensor([[-1.2374, -1.4280],
        [-1.1136, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023080138489603996
Epoch 0, Step 2524: train/loss = 0.6885631084442139, train/raw-loss = 0.6601012349128723, train/logprobs = tensor([[-1.0174, -1.4597],
        [-1.6316, -1.0749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05692373588681221
Epoch 0, Step 2525: train/loss = 0.6917307376861572, train/raw-loss = 0.6803849339485168, train/logprobs = tensor([[-1.0572, -1.3440],
        [-1.4210, -1.1203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02269170805811882
Epoch 0, Step 2526: train/loss = 0.6985747814178467, train/raw-loss = 0.672924280166626, train/logprobs = tensor([[-1.2798, -1.4341],
        [-1.5066, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0513010248541832
Epoch 0, Step 2527: train/loss = 0.6952403783798218, train/raw-loss = 0.6723381280899048, train/logprobs = tensor([[-1.3236, -1.7985],
        [-1.7468, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045804619789123535
Epoch 0, Step 2528: train/loss = 0.6913919448852539, train/raw-loss = 0.6710599064826965, train/logprobs = tensor([[-1.1315, -1.4389],
        [-1.5957, -1.0497]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040664054453372955
Epoch 0, Step 2529: train/loss = 0.6854028701782227, train/raw-loss = 0.6505132913589478, train/logprobs = tensor([[-1.2062, -1.3815],
        [-1.2854, -1.1664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06977903842926025
Epoch 0, Step 2530: train/loss = 0.686127781867981, train/raw-loss = 0.6796622276306152, train/logprobs = tensor([[-1.1652, -1.3686],
        [-1.5921, -1.5244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01293110940605402
Epoch 0, Step 2531: train/loss = 0.6996355652809143, train/raw-loss = 0.6928791403770447, train/logprobs = tensor([[-1.3029, -1.5680],
        [-1.2086, -1.1086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013513014651834965
Epoch 0, Step 2532: train/loss = 0.6923714280128479, train/raw-loss = 0.6688452959060669, train/logprobs = tensor([[-1.4667, -2.0841],
        [-1.2567, -1.0698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04705217480659485
Epoch 0, Step 2533: train/loss = 0.7256495356559753, train/raw-loss = 0.7150832414627075, train/logprobs = tensor([[-1.3943, -1.0861],
        [-1.4292, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02113262750208378
Epoch 0, Step 2534: train/loss = 0.6979387998580933, train/raw-loss = 0.6852701902389526, train/logprobs = tensor([[-1.1534, -1.2121],
        [-1.5940, -1.1335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025337236002087593
Epoch 0, Step 2535: train/loss = 0.6973910927772522, train/raw-loss = 0.692952036857605, train/logprobs = tensor([[-1.1079, -1.1991],
        [-1.3633, -1.1311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008878091350197792
Epoch 0, Step 2536: train/loss = 0.7097041010856628, train/raw-loss = 0.7086716294288635, train/logprobs = tensor([[-1.3246, -1.1178],
        [-1.2029, -0.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002064851112663746
Epoch 0, Step 2537: train/loss = 0.6954551935195923, train/raw-loss = 0.6850832104682922, train/logprobs = tensor([[-1.3431, -1.4351],
        [-1.4640, -1.1096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020744049921631813
Epoch 0, Step 2538: train/loss = 0.6874752640724182, train/raw-loss = 0.6687126159667969, train/logprobs = tensor([[-1.0883, -1.5745],
        [-1.6219, -1.2409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03752521052956581
Epoch 0, Step 2539: train/loss = 0.690802276134491, train/raw-loss = 0.6780545711517334, train/logprobs = tensor([[-1.0498, -1.1938],
        [-1.3326, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025495488196611404
Epoch 0, Step 2540: train/loss = 0.6973667740821838, train/raw-loss = 0.6957929730415344, train/logprobs = tensor([[-1.1210, -1.1100],
        [-0.9733, -0.8743]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003147539682686329
Epoch 0, Step 2541: train/loss = 0.698589563369751, train/raw-loss = 0.6763210892677307, train/logprobs = tensor([[-1.2727, -1.4181],
        [-1.4237, -0.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04453694075345993
Epoch 0, Step 2542: train/loss = 0.6901440620422363, train/raw-loss = 0.6725749373435974, train/logprobs = tensor([[-1.0482, -1.4159],
        [-1.4168, -1.0598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03513817861676216
Epoch 0, Step 2543: train/loss = 0.6973649263381958, train/raw-loss = 0.693615198135376, train/logprobs = tensor([[-1.1829, -1.5029],
        [-1.2270, -1.1694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007499372586607933
Epoch 0, Step 2544: train/loss = 0.692815363407135, train/raw-loss = 0.6894046068191528, train/logprobs = tensor([[-1.2236, -1.3142],
        [-1.5428, -1.3020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006821585353463888
Epoch 0, Step 2545: train/loss = 0.6839753985404968, train/raw-loss = 0.6714544892311096, train/logprobs = tensor([[-1.1574, -1.5034],
        [-1.4353, -1.0977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02504177950322628
Epoch 0, Step 2546: train/loss = 0.6999666690826416, train/raw-loss = 0.6978726387023926, train/logprobs = tensor([[-1.1566, -1.3684],
        [-1.0694, -1.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004188092891126871
Epoch 0, Step 2547: train/loss = 0.7065064311027527, train/raw-loss = 0.6985392570495605, train/logprobs = tensor([[-1.1993, -1.3028],
        [-1.5464, -1.3714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015934333205223083
Epoch 0, Step 2548: train/loss = 0.6698673367500305, train/raw-loss = 0.6061567664146423, train/logprobs = tensor([[-1.0481, -2.0340],
        [-1.8684, -1.1368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12742115557193756
Epoch 0, Step 2549: train/loss = 0.7024269700050354, train/raw-loss = 0.6919925212860107, train/logprobs = tensor([[-1.2606, -1.2938],
        [-1.5393, -1.1166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020868942141532898
Epoch 0, Step 2550: train/loss = 0.7013754844665527, train/raw-loss = 0.696702778339386, train/logprobs = tensor([[-1.3661, -1.4026],
        [-1.4005, -1.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00934546161442995
Epoch 0, Step 2551: train/loss = 0.7028335928916931, train/raw-loss = 0.6931476593017578, train/logprobs = tensor([[-1.0108, -0.9657],
        [-1.2920, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01937190443277359
Epoch 0, Step 2552: train/loss = 0.6955958008766174, train/raw-loss = 0.6874414086341858, train/logprobs = tensor([[-1.1111, -1.4061],
        [-1.3686, -1.1093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01630878821015358
Epoch 0, Step 2553: train/loss = 0.6922428607940674, train/raw-loss = 0.6566318869590759, train/logprobs = tensor([[-1.1291, -1.4554],
        [-1.2598, -0.7498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07122211158275604
Epoch 0, Step 2554: train/loss = 0.7165339589118958, train/raw-loss = 0.7030202150344849, train/logprobs = tensor([[-1.0832, -0.9867],
        [-1.5776, -0.8850]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027027642354369164
Epoch 0, Step 2555: train/loss = 0.7007510662078857, train/raw-loss = 0.6698413491249084, train/logprobs = tensor([[-1.0340, -1.4899],
        [-1.5426, -0.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06181942671537399
Epoch 0, Step 2556: train/loss = 0.6804336905479431, train/raw-loss = 0.639787495136261, train/logprobs = tensor([[-1.1121, -1.9248],
        [-1.2873, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08129221200942993
Epoch 0, Step 2557: train/loss = 0.6881113648414612, train/raw-loss = 0.6619306206703186, train/logprobs = tensor([[-1.0262, -1.5206],
        [-1.4009, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05236155912280083
Epoch 0, Step 2558: train/loss = 0.695547878742218, train/raw-loss = 0.6934710741043091, train/logprobs = tensor([[-1.1997, -1.2653],
        [-1.2380, -1.1326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0041536916978657246
Epoch 0, Step 2559: train/loss = 0.6902670860290527, train/raw-loss = 0.670751690864563, train/logprobs = tensor([[-1.1345, -1.4686],
        [-1.3350, -1.0153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039030659943819046
Epoch 0, Step 2560: train/loss = 0.6878367066383362, train/raw-loss = 0.6635675430297852, train/logprobs = tensor([[-1.1272, -1.4979],
        [-1.4698, -0.9942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0485382154583931
Epoch 0, Step 2561: train/loss = 0.6929275393486023, train/raw-loss = 0.6809337139129639, train/logprobs = tensor([[-1.1241, -1.3403],
        [-1.2878, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02398746646940708
Epoch 0, Step 2562: train/loss = 0.6808401346206665, train/raw-loss = 0.6367403268814087, train/logprobs = tensor([[-1.2585, -1.5930],
        [-1.8013, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08819956332445145
Epoch 0, Step 2563: train/loss = 0.7033170461654663, train/raw-loss = 0.6779641509056091, train/logprobs = tensor([[-1.0819, -1.4484],
        [-1.7266, -1.2196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05070574954152107
Epoch 0, Step 2564: train/loss = 0.6946366429328918, train/raw-loss = 0.6843718886375427, train/logprobs = tensor([[-1.2715, -1.3870],
        [-1.2246, -0.9713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020529549568891525
Epoch 0, Step 2565: train/loss = 0.7061356902122498, train/raw-loss = 0.6683201789855957, train/logprobs = tensor([[-1.2064, -1.5370],
        [-1.8788, -1.2232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07563108205795288
Epoch 0, Step 2566: train/loss = 0.6902215480804443, train/raw-loss = 0.6523900032043457, train/logprobs = tensor([[-1.1119, -1.4201],
        [-1.5194, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07566316425800323
Epoch 0, Step 2567: train/loss = 0.6956830024719238, train/raw-loss = 0.6931706666946411, train/logprobs = tensor([[-1.2045, -1.0389],
        [-1.6653, -1.5931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005024757236242294
Epoch 0, Step 2568: train/loss = 0.7012134194374084, train/raw-loss = 0.6805460453033447, train/logprobs = tensor([[-1.2649, -1.4967],
        [-1.3139, -0.8691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04133467376232147
Epoch 0, Step 2569: train/loss = 0.696293294429779, train/raw-loss = 0.6622247695922852, train/logprobs = tensor([[-1.2345, -1.4927],
        [-1.5871, -0.9046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06813699007034302
Epoch 0, Step 2570: train/loss = 0.6932310461997986, train/raw-loss = 0.6754416823387146, train/logprobs = tensor([[-1.1615, -1.3382],
        [-1.4805, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03557877242565155
Epoch 0, Step 2571: train/loss = 0.6946731209754944, train/raw-loss = 0.6938481330871582, train/logprobs = tensor([[-1.3276, -1.5203],
        [-1.3459, -1.3721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016501294448971748
Epoch 0, Step 2572: train/loss = 0.7020425796508789, train/raw-loss = 0.6868469715118408, train/logprobs = tensor([[-1.1396, -1.6259],
        [-1.2212, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030391307547688484
Epoch 0, Step 2573: train/loss = 0.6846457719802856, train/raw-loss = 0.6403580904006958, train/logprobs = tensor([[-1.1058, -1.6129],
        [-1.6316, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08857521414756775
Epoch 0, Step 2574: train/loss = 0.7013029456138611, train/raw-loss = 0.6660172343254089, train/logprobs = tensor([[-1.2284, -1.5812],
        [-1.7128, -1.0429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07057128846645355
Epoch 0, Step 2575: train/loss = 0.6832767128944397, train/raw-loss = 0.6754693388938904, train/logprobs = tensor([[-1.2380, -1.5223],
        [-1.5388, -1.3573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015614775940775871
Epoch 0, Step 2576: train/loss = 0.722320556640625, train/raw-loss = 0.7191566228866577, train/logprobs = tensor([[-1.1740, -0.9504],
        [-1.4111, -0.8519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00632796436548233
Epoch 0, Step 2577: train/loss = 0.676599383354187, train/raw-loss = 0.6237542629241943, train/logprobs = tensor([[-1.2497, -1.8623],
        [-1.6803, -1.0409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10569016635417938
Epoch 0, Step 2578: train/loss = 0.7152006030082703, train/raw-loss = 0.7095932960510254, train/logprobs = tensor([[-1.2087, -1.0649],
        [-1.4417, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01121457014232874
Epoch 0, Step 2579: train/loss = 0.6989298462867737, train/raw-loss = 0.6858734488487244, train/logprobs = tensor([[-1.2266, -1.2236],
        [-1.6033, -1.3066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026112718507647514
Epoch 0, Step 2580: train/loss = 0.6913831233978271, train/raw-loss = 0.6721917390823364, train/logprobs = tensor([[-1.1986, -1.4033],
        [-1.5217, -0.9969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038382600992918015
Epoch 0, Step 2581: train/loss = 0.6765666604042053, train/raw-loss = 0.621751606464386, train/logprobs = tensor([[-1.0747, -1.6773],
        [-1.6430, -0.7514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10963010787963867
Epoch 0, Step 2582: train/loss = 0.6961380839347839, train/raw-loss = 0.6915374994277954, train/logprobs = tensor([[-1.1408, -1.3668],
        [-1.2065, -1.2275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009201185777783394
Epoch 0, Step 2583: train/loss = 0.6922181248664856, train/raw-loss = 0.6853070855140686, train/logprobs = tensor([[-1.1161, -1.1916],
        [-1.4312, -1.1831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013822143897414207
Epoch 0, Step 2584: train/loss = 0.7664475440979004, train/raw-loss = 0.6974091529846191, train/logprobs = tensor([[-1.2298, -2.5113],
        [-1.5218, -1.3838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1380767524242401
Epoch 0, Step 2585: train/loss = 0.6935383081436157, train/raw-loss = 0.6694939136505127, train/logprobs = tensor([[-1.0568, -1.3914],
        [-1.3727, -0.9593]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04808873310685158
Epoch 0, Step 2586: train/loss = 0.6976136565208435, train/raw-loss = 0.6596848964691162, train/logprobs = tensor([[-1.0703, -1.5030],
        [-1.6363, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07585744559764862
Epoch 0, Step 2587: train/loss = 0.6907776594161987, train/raw-loss = 0.6708757877349854, train/logprobs = tensor([[-1.2264, -1.3447],
        [-1.9006, -1.4249]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03980359062552452
Epoch 0, Step 2588: train/loss = 0.6950947046279907, train/raw-loss = 0.6635391712188721, train/logprobs = tensor([[-1.4405, -1.6820],
        [-1.8657, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06311118602752686
Epoch 0, Step 2589: train/loss = 0.7067124843597412, train/raw-loss = 0.6827945709228516, train/logprobs = tensor([[-0.8880, -1.0363],
        [-1.8130, -1.1478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047835834324359894
Epoch 0, Step 2590: train/loss = 0.6944369673728943, train/raw-loss = 0.6938664317131042, train/logprobs = tensor([[-1.2482, -1.2648],
        [-1.2559, -1.2066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011410824954509735
Epoch 0, Step 2591: train/loss = 0.6895900368690491, train/raw-loss = 0.6867073774337769, train/logprobs = tensor([[-1.2662, -1.3410],
        [-1.4277, -1.3177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005765360314399004
Epoch 0, Step 2592: train/loss = 0.6997389197349548, train/raw-loss = 0.6924736499786377, train/logprobs = tensor([[-1.0371, -0.9815],
        [-1.4184, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014530636370182037
Epoch 0, Step 2593: train/loss = 0.7729228138923645, train/raw-loss = 0.7558145523071289, train/logprobs = tensor([[-1.1803, -1.9043],
        [-1.3016, -1.3425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03421631455421448
Epoch 0, Step 2594: train/loss = 0.6965186595916748, train/raw-loss = 0.6821534633636475, train/logprobs = tensor([[-1.1166, -1.3726],
        [-1.4335, -1.1246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028730452060699463
Epoch 0, Step 2595: train/loss = 0.6993815898895264, train/raw-loss = 0.6952877640724182, train/logprobs = tensor([[-1.2208, -1.4893],
        [-1.4566, -1.3297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008187772706151009
Epoch 0, Step 2596: train/loss = 0.6743906736373901, train/raw-loss = 0.6384212970733643, train/logprobs = tensor([[-0.9671, -1.8056],
        [-1.6504, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07193863391876221
Epoch 0, Step 2597: train/loss = 0.6987108588218689, train/raw-loss = 0.6940426826477051, train/logprobs = tensor([[-1.1996, -1.2240],
        [-1.5243, -1.4938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00933627225458622
Epoch 0, Step 2598: train/loss = 0.6942358016967773, train/raw-loss = 0.6915754079818726, train/logprobs = tensor([[-1.1573, -1.2428],
        [-1.1834, -1.0160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005320732481777668
Epoch 0, Step 2599: train/loss = 0.6878732442855835, train/raw-loss = 0.6623069047927856, train/logprobs = tensor([[-1.0726, -1.5361],
        [-1.5548, -1.2132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051132865250110626
Epoch 0, Step 2600: train/loss = 0.6942910552024841, train/raw-loss = 0.6510128378868103, train/logprobs = tensor([[-1.0355, -1.4086],
        [-1.7093, -0.9415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08655638247728348
Epoch 0, Step 2601: train/loss = 0.692584753036499, train/raw-loss = 0.6792404651641846, train/logprobs = tensor([[-1.0319, -1.2230],
        [-1.6279, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02668866515159607
Epoch 0, Step 2602: train/loss = 0.6800004243850708, train/raw-loss = 0.5875600576400757, train/logprobs = tensor([[-1.0081, -2.0148],
        [-1.8182, -0.8322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1848808079957962
Epoch 0, Step 2603: train/loss = 0.6973403692245483, train/raw-loss = 0.6631735563278198, train/logprobs = tensor([[-1.3983, -1.9247],
        [-1.7848, -1.2570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06833365559577942
Epoch 0, Step 2604: train/loss = 0.6960175037384033, train/raw-loss = 0.6651374101638794, train/logprobs = tensor([[-1.2483, -1.4324],
        [-1.7390, -1.1607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06176012381911278
Epoch 0, Step 2605: train/loss = 0.6976757645606995, train/raw-loss = 0.6832330226898193, train/logprobs = tensor([[-1.0641, -1.1678],
        [-1.1931, -0.8234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0288853719830513
Epoch 0, Step 2606: train/loss = 0.7124055027961731, train/raw-loss = 0.6752262115478516, train/logprobs = tensor([[-1.2557, -1.4567],
        [-1.9054, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07435838878154755
Epoch 0, Step 2607: train/loss = 0.6953879594802856, train/raw-loss = 0.6921625733375549, train/logprobs = tensor([[-1.1477, -1.3236],
        [-1.2598, -1.0984]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006450693588703871
Epoch 0, Step 2608: train/loss = 0.7422786951065063, train/raw-loss = 0.7147741913795471, train/logprobs = tensor([[-1.5954, -1.6944],
        [-1.9590, -1.0649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055009059607982635
Epoch 0, Step 2609: train/loss = 0.678086519241333, train/raw-loss = 0.6530928611755371, train/logprobs = tensor([[-0.9968, -1.5150],
        [-1.3489, -0.9235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04998744651675224
Epoch 0, Step 2610: train/loss = 0.6980336904525757, train/raw-loss = 0.6877423524856567, train/logprobs = tensor([[-1.0974, -1.3560],
        [-1.3885, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02058277279138565
Epoch 0, Step 2611: train/loss = 0.6907753944396973, train/raw-loss = 0.6711031794548035, train/logprobs = tensor([[-1.1601, -1.5489],
        [-1.5894, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03934447094798088
Epoch 0, Step 2612: train/loss = 0.7003120183944702, train/raw-loss = 0.6885334253311157, train/logprobs = tensor([[-1.1746, -1.5886],
        [-1.2406, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023557165637612343
Epoch 0, Step 2613: train/loss = 0.6932059526443481, train/raw-loss = 0.6608128547668457, train/logprobs = tensor([[-1.0269, -1.2352],
        [-1.7849, -1.0978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06478618830442429
Epoch 0, Step 2614: train/loss = 0.7027693390846252, train/raw-loss = 0.6962089538574219, train/logprobs = tensor([[-1.0629, -0.9515],
        [-1.2628, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013120683841407299
Epoch 0, Step 2615: train/loss = 0.6980493664741516, train/raw-loss = 0.6805893182754517, train/logprobs = tensor([[-1.1698, -1.9310],
        [-1.4900, -1.3675]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03492002189159393
Epoch 0, Step 2616: train/loss = 0.696243166923523, train/raw-loss = 0.6800816655158997, train/logprobs = tensor([[-1.2770, -1.4345],
        [-1.8735, -1.1551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03232305124402046
Epoch 0, Step 2617: train/loss = 0.6885167360305786, train/raw-loss = 0.6311244368553162, train/logprobs = tensor([[-0.9974, -1.6557],
        [-1.5108, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1147846132516861
Epoch 0, Step 2618: train/loss = 0.6957509517669678, train/raw-loss = 0.6851608753204346, train/logprobs = tensor([[-1.2310, -1.4227],
        [-1.2801, -1.3038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021180111914873123
Epoch 0, Step 2619: train/loss = 0.6879949569702148, train/raw-loss = 0.6407463550567627, train/logprobs = tensor([[-1.2361, -1.9144],
        [-1.5909, -0.9475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09449731558561325
Epoch 0, Step 2620: train/loss = 0.6953839063644409, train/raw-loss = 0.6401880979537964, train/logprobs = tensor([[-0.8891, -1.3171],
        [-1.9242, -1.0580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11039162427186966
Epoch 0, Step 2621: train/loss = 0.6906446218490601, train/raw-loss = 0.6796162724494934, train/logprobs = tensor([[-1.2678, -1.4176],
        [-1.6711, -1.2348]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02205662801861763
Epoch 0, Step 2622: train/loss = 0.6951738595962524, train/raw-loss = 0.6813063621520996, train/logprobs = tensor([[-1.0401, -1.4504],
        [-1.1127, -0.9050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02773495391011238
Epoch 0, Step 2623: train/loss = 0.7139615416526794, train/raw-loss = 0.7002252340316772, train/logprobs = tensor([[-1.1159, -1.5716],
        [-1.3620, -1.2905]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027472496032714844
Epoch 0, Step 2624: train/loss = 0.7722658514976501, train/raw-loss = 0.7261285781860352, train/logprobs = tensor([[-1.2975, -1.2935],
        [-1.9940, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0922744944691658
Epoch 0, Step 2625: train/loss = 0.686981201171875, train/raw-loss = 0.607720136642456, train/logprobs = tensor([[-0.9568, -1.7496],
        [-1.3667, -0.7659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1585221141576767
Epoch 0, Step 2626: train/loss = 0.6930227875709534, train/raw-loss = 0.6493959426879883, train/logprobs = tensor([[-1.1206, -1.6029],
        [-1.7465, -1.0711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08725366741418839
Epoch 0, Step 2627: train/loss = 0.6957004070281982, train/raw-loss = 0.6792676448822021, train/logprobs = tensor([[-1.0842, -1.3010],
        [-1.3224, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03286557272076607
Epoch 0, Step 2628: train/loss = 0.6946054100990295, train/raw-loss = 0.6621500849723816, train/logprobs = tensor([[-1.0903, -1.3534],
        [-1.6588, -1.0913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0649106353521347
Epoch 0, Step 2629: train/loss = 0.6677167415618896, train/raw-loss = 0.6397923231124878, train/logprobs = tensor([[-1.3208, -1.6879],
        [-1.7520, -1.2969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05584883689880371
Epoch 0, Step 2630: train/loss = 0.6961718797683716, train/raw-loss = 0.6806708574295044, train/logprobs = tensor([[-1.4535, -1.6131],
        [-1.4324, -1.1487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031002070754766464
Epoch 0, Step 2631: train/loss = 0.6943265199661255, train/raw-loss = 0.6828480362892151, train/logprobs = tensor([[-1.2746, -1.1975],
        [-1.5647, -1.4035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02295699715614319
Epoch 0, Step 2632: train/loss = 0.7081624865531921, train/raw-loss = 0.6998253464698792, train/logprobs = tensor([[-1.1507, -1.2838],
        [-1.4396, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01667426899075508
Epoch 0, Step 2633: train/loss = 0.6849523782730103, train/raw-loss = 0.6646124720573425, train/logprobs = tensor([[-1.2266, -1.6453],
        [-1.4489, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04067979007959366
Epoch 0, Step 2634: train/loss = 0.6984509229660034, train/raw-loss = 0.6524330377578735, train/logprobs = tensor([[-0.9935, -1.7011],
        [-1.6810, -1.1340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09203574806451797
Epoch 0, Step 2635: train/loss = 0.6994960308074951, train/raw-loss = 0.6630123853683472, train/logprobs = tensor([[-1.1264, -1.2787],
        [-1.9536, -1.2663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07296723872423172
Epoch 0, Step 2636: train/loss = 0.699499785900116, train/raw-loss = 0.6907093524932861, train/logprobs = tensor([[-1.2458, -1.5635],
        [-1.1177, -1.0570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01758088916540146
Epoch 0, Step 2637: train/loss = 0.6742263436317444, train/raw-loss = 0.6697638630867004, train/logprobs = tensor([[-1.2992, -1.4172],
        [-1.4608, -1.0383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008924913592636585
Epoch 0, Step 2638: train/loss = 0.6806547045707703, train/raw-loss = 0.6479310393333435, train/logprobs = tensor([[-1.0453, -1.6319],
        [-1.4519, -0.9236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0654473751783371
Epoch 0, Step 2639: train/loss = 0.7124675512313843, train/raw-loss = 0.6948378086090088, train/logprobs = tensor([[-1.0870, -0.9256],
        [-1.4023, -1.4387]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03525937721133232
Epoch 0, Step 2640: train/loss = 0.6928054094314575, train/raw-loss = 0.6836446523666382, train/logprobs = tensor([[-1.3166, -1.4532],
        [-1.0771, -0.7831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01832164078950882
Epoch 0, Step 2641: train/loss = 0.6933124661445618, train/raw-loss = 0.677394449710846, train/logprobs = tensor([[-1.0453, -1.3076],
        [-1.6979, -1.1394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03183604031801224
Epoch 0, Step 2642: train/loss = 0.6905893087387085, train/raw-loss = 0.6463189125061035, train/logprobs = tensor([[-1.0901, -1.7106],
        [-1.6983, -1.2647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0885409414768219
Epoch 0, Step 2643: train/loss = 0.6987720727920532, train/raw-loss = 0.6911154985427856, train/logprobs = tensor([[-0.9663, -1.0617],
        [-1.3638, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01531311310827732
Epoch 0, Step 2644: train/loss = 0.6842517852783203, train/raw-loss = 0.6540554165840149, train/logprobs = tensor([[-1.1461, -1.4906],
        [-1.8100, -1.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06039270758628845
Epoch 0, Step 2645: train/loss = 0.6920181512832642, train/raw-loss = 0.6720523834228516, train/logprobs = tensor([[-1.2631, -1.4805],
        [-1.3262, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03993147611618042
Epoch 0, Step 2646: train/loss = 0.6883061528205872, train/raw-loss = 0.6807974576950073, train/logprobs = tensor([[-1.0692, -1.3014],
        [-1.3754, -1.0994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01501738466322422
Epoch 0, Step 2647: train/loss = 0.6974030137062073, train/raw-loss = 0.6885186433792114, train/logprobs = tensor([[-0.9580, -1.0611],
        [-1.4434, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01776876114308834
Epoch 0, Step 2648: train/loss = 0.688498854637146, train/raw-loss = 0.6772462129592896, train/logprobs = tensor([[-1.1094, -1.4982],
        [-1.5624, -1.3778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02250540442764759
Epoch 0, Step 2649: train/loss = 0.7370513081550598, train/raw-loss = 0.7299833297729492, train/logprobs = tensor([[-1.4495, -1.4602],
        [-1.4604, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014135835692286491
Epoch 0, Step 2650: train/loss = 0.6760162115097046, train/raw-loss = 0.6301300525665283, train/logprobs = tensor([[-1.1111, -1.5230],
        [-1.6606, -1.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09177237749099731
Epoch 0, Step 2651: train/loss = 0.7043649554252625, train/raw-loss = 0.6862273812294006, train/logprobs = tensor([[-1.1360, -1.6922],
        [-1.6192, -1.7314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03627520054578781
Epoch 0, Step 2652: train/loss = 0.6921517848968506, train/raw-loss = 0.6879000663757324, train/logprobs = tensor([[-1.0919, -1.2967],
        [-1.5913, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008503470569849014
Epoch 0, Step 2653: train/loss = 0.694512665271759, train/raw-loss = 0.6870020627975464, train/logprobs = tensor([[-1.0621, -1.0658],
        [-1.3783, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015021167695522308
Epoch 0, Step 2654: train/loss = 0.6886931657791138, train/raw-loss = 0.6606625914573669, train/logprobs = tensor([[-1.3427, -1.9240],
        [-1.6387, -1.1345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056061040610075
Epoch 0, Step 2655: train/loss = 0.699638843536377, train/raw-loss = 0.695950984954834, train/logprobs = tensor([[-1.3655, -1.3096],
        [-1.4879, -1.3105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007375691086053848
Epoch 0, Step 2656: train/loss = 0.6955258846282959, train/raw-loss = 0.6560042500495911, train/logprobs = tensor([[-1.0991, -1.5008],
        [-1.8577, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07904339581727982
Epoch 0, Step 2657: train/loss = 0.6874158382415771, train/raw-loss = 0.6629818677902222, train/logprobs = tensor([[-1.1678, -1.3990],
        [-1.7684, -1.5132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048867929726839066
Epoch 0, Step 2658: train/loss = 0.703284502029419, train/raw-loss = 0.6775757074356079, train/logprobs = tensor([[-1.3045, -1.3698],
        [-1.7963, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0514175184071064
Epoch 0, Step 2659: train/loss = 0.6957274675369263, train/raw-loss = 0.6947548389434814, train/logprobs = tensor([[-1.2023, -1.2630],
        [-1.3958, -1.4435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019452308770269156
Epoch 0, Step 2660: train/loss = 0.6913890838623047, train/raw-loss = 0.6765228509902954, train/logprobs = tensor([[-1.0519, -1.2917],
        [-1.4982, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029732435941696167
Epoch 0, Step 2661: train/loss = 0.6920831203460693, train/raw-loss = 0.6599223613739014, train/logprobs = tensor([[-1.1338, -1.4861],
        [-1.4566, -1.0376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06432139873504639
Epoch 0, Step 2662: train/loss = 0.7014121413230896, train/raw-loss = 0.6674395799636841, train/logprobs = tensor([[-0.8651, -1.1258],
        [-1.5737, -0.9703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06794510781764984
Epoch 0, Step 2663: train/loss = 0.6988247632980347, train/raw-loss = 0.6834149360656738, train/logprobs = tensor([[-1.0312, -1.3673],
        [-1.5685, -1.4506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030819706618785858
Epoch 0, Step 2664: train/loss = 0.6950333118438721, train/raw-loss = 0.6816803216934204, train/logprobs = tensor([[-1.4920, -1.6121],
        [-1.3722, -0.9892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02670597843825817
Epoch 0, Step 2665: train/loss = 0.6910903453826904, train/raw-loss = 0.6606225967407227, train/logprobs = tensor([[-1.0781, -1.5988],
        [-1.3604, -0.9583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06093553826212883
Epoch 0, Step 2666: train/loss = 0.6910709738731384, train/raw-loss = 0.6707425117492676, train/logprobs = tensor([[-1.1102, -1.4019],
        [-1.3930, -1.0545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04065678268671036
Epoch 0, Step 2667: train/loss = 0.6997984051704407, train/raw-loss = 0.6902107000350952, train/logprobs = tensor([[-1.1646, -1.2507],
        [-1.7909, -1.7382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019175341352820396
Epoch 0, Step 2668: train/loss = 0.7158222198486328, train/raw-loss = 0.6884900331497192, train/logprobs = tensor([[-1.3855, -1.9905],
        [-1.3197, -1.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05466441065073013
Epoch 0, Step 2669: train/loss = 0.6889622807502747, train/raw-loss = 0.6501666903495789, train/logprobs = tensor([[-1.1982, -1.5477],
        [-1.4072, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07759125530719757
Epoch 0, Step 2670: train/loss = 0.6971043348312378, train/raw-loss = 0.6966267824172974, train/logprobs = tensor([[-1.0177, -1.0689],
        [-1.1319, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009551408002153039
Epoch 0, Step 2671: train/loss = 0.6986019611358643, train/raw-loss = 0.6846956014633179, train/logprobs = tensor([[-0.9588, -1.1734],
        [-1.0997, -1.2572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027812909334897995
Epoch 0, Step 2672: train/loss = 0.6927902102470398, train/raw-loss = 0.6775628924369812, train/logprobs = tensor([[-1.1400, -1.3721],
        [-1.2775, -1.2119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030454495921730995
Epoch 0, Step 2673: train/loss = 0.6922459602355957, train/raw-loss = 0.6817276477813721, train/logprobs = tensor([[-1.1809, -1.5175],
        [-1.2608, -1.1360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021036744117736816
Epoch 0, Step 2674: train/loss = 0.6928367614746094, train/raw-loss = 0.6825255155563354, train/logprobs = tensor([[-1.0730, -1.2493],
        [-1.4322, -1.0756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020622355863451958
Epoch 0, Step 2675: train/loss = 0.6851126551628113, train/raw-loss = 0.6750375032424927, train/logprobs = tensor([[-1.2698, -1.6686],
        [-1.3753, -1.0886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020150333642959595
Epoch 0, Step 2676: train/loss = 0.6910032629966736, train/raw-loss = 0.6532137393951416, train/logprobs = tensor([[-1.0411, -1.5824],
        [-1.6214, -1.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.075578972697258
Epoch 0, Step 2677: train/loss = 0.6865893602371216, train/raw-loss = 0.6599833965301514, train/logprobs = tensor([[-0.9585, -1.3162],
        [-1.5963, -1.3573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0532119944691658
Epoch 0, Step 2678: train/loss = 0.6894343495368958, train/raw-loss = 0.6795005798339844, train/logprobs = tensor([[-1.3941, -1.4878],
        [-1.1826, -0.8525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019867492839694023
Epoch 0, Step 2679: train/loss = 0.6824305653572083, train/raw-loss = 0.6651017665863037, train/logprobs = tensor([[-1.1029, -1.4502],
        [-1.4406, -1.0258]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034657590091228485
Epoch 0, Step 2680: train/loss = 0.6974456310272217, train/raw-loss = 0.6819261312484741, train/logprobs = tensor([[-0.9571, -1.3077],
        [-1.2431, -1.0489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031039033085107803
Epoch 0, Step 2681: train/loss = 0.6984946727752686, train/raw-loss = 0.6750962734222412, train/logprobs = tensor([[-0.9879, -1.2309],
        [-1.4840, -1.0430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04679686576128006
Epoch 0, Step 2682: train/loss = 0.6863036751747131, train/raw-loss = 0.6424874067306519, train/logprobs = tensor([[-1.0076, -1.5175],
        [-1.7085, -1.1639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08763253688812256
Epoch 0, Step 2683: train/loss = 0.6992318630218506, train/raw-loss = 0.6730741858482361, train/logprobs = tensor([[-1.0802, -1.6083],
        [-1.3476, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.052315354347229004
Epoch 0, Step 2684: train/loss = 0.7020611763000488, train/raw-loss = 0.6804822683334351, train/logprobs = tensor([[-1.2706, -1.7360],
        [-1.5368, -1.3641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043157950043678284
Epoch 0, Step 2685: train/loss = 0.7111794948577881, train/raw-loss = 0.695361852645874, train/logprobs = tensor([[-1.2580, -1.4646],
        [-1.5342, -1.1363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031635310500860214
Epoch 0, Step 2686: train/loss = 0.6958497762680054, train/raw-loss = 0.6861973404884338, train/logprobs = tensor([[-1.4713, -1.5024],
        [-1.5357, -1.2953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01930483989417553
Epoch 0, Step 2687: train/loss = 0.7057672142982483, train/raw-loss = 0.683939516544342, train/logprobs = tensor([[-1.1105, -1.5577],
        [-1.5146, -1.6004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04365543648600578
Epoch 0, Step 2688: train/loss = 0.6889016032218933, train/raw-loss = 0.6589457988739014, train/logprobs = tensor([[-1.3049, -1.6518],
        [-1.7576, -1.4270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059911563992500305
Epoch 0, Step 2689: train/loss = 0.6964820623397827, train/raw-loss = 0.6711244583129883, train/logprobs = tensor([[-1.1585, -1.4280],
        [-1.4038, -0.9840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050715282559394836
Epoch 0, Step 2690: train/loss = 0.6947429180145264, train/raw-loss = 0.6639688014984131, train/logprobs = tensor([[-0.9301, -1.1277],
        [-1.3638, -1.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061548229306936264
Epoch 0, Step 2691: train/loss = 0.7038406133651733, train/raw-loss = 0.6735122203826904, train/logprobs = tensor([[-1.1110, -1.5785],
        [-1.3904, -0.9918]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060656771063804626
Epoch 0, Step 2692: train/loss = 0.7049514055252075, train/raw-loss = 0.7012603878974915, train/logprobs = tensor([[-1.5695, -1.6828],
        [-1.0205, -1.0588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007381947711110115
Epoch 0, Step 2693: train/loss = 0.7192341089248657, train/raw-loss = 0.7009201049804688, train/logprobs = tensor([[-1.0903, -1.5479],
        [-1.3726, -1.3895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03662805259227753
Epoch 0, Step 2694: train/loss = 0.7606710195541382, train/raw-loss = 0.731062650680542, train/logprobs = tensor([[-1.1920, -2.1513],
        [-1.6691, -1.6060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.059216633439064026
Epoch 0, Step 2695: train/loss = 0.7109849452972412, train/raw-loss = 0.6703194379806519, train/logprobs = tensor([[-1.1059, -1.3045],
        [-1.6081, -0.8517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08133099973201752
Epoch 0, Step 2696: train/loss = 0.6966610550880432, train/raw-loss = 0.6713280081748962, train/logprobs = tensor([[-1.3160, -1.6639],
        [-1.6393, -1.1974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05066615715622902
Epoch 0, Step 2697: train/loss = 0.6923202276229858, train/raw-loss = 0.6749260425567627, train/logprobs = tensor([[-1.2553, -1.1886],
        [-1.5935, -1.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03478838503360748
Epoch 0, Step 2698: train/loss = 0.6976791620254517, train/raw-loss = 0.6842398643493652, train/logprobs = tensor([[-1.4473, -1.4019],
        [-1.5476, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02687864378094673
Epoch 0, Step 2699: train/loss = 0.6911395788192749, train/raw-loss = 0.6899046897888184, train/logprobs = tensor([[-1.0383, -1.0507],
        [-1.5766, -1.3870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002469840692356229
Epoch 0, Step 2700: train/loss = 0.6735485792160034, train/raw-loss = 0.6396769285202026, train/logprobs = tensor([[-1.0759, -1.5081],
        [-1.6832, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06774329394102097
Epoch 0, Step 2701: train/loss = 0.6927461624145508, train/raw-loss = 0.6819069981575012, train/logprobs = tensor([[-1.3207, -1.5216],
        [-1.3328, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0216783806681633
Epoch 0, Step 2702: train/loss = 0.6967010498046875, train/raw-loss = 0.6817623376846313, train/logprobs = tensor([[-1.0492, -1.4117],
        [-1.5513, -1.5785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02987743355333805
Epoch 0, Step 2703: train/loss = 0.6977556347846985, train/raw-loss = 0.6877212524414062, train/logprobs = tensor([[-1.2568, -1.3658],
        [-1.4519, -1.1595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020068760961294174
Epoch 0, Step 2704: train/loss = 0.6990542411804199, train/raw-loss = 0.6549768447875977, train/logprobs = tensor([[-1.1841, -1.6035],
        [-1.5244, -0.9410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08815481513738632
Epoch 0, Step 2705: train/loss = 0.697115421295166, train/raw-loss = 0.6815846562385559, train/logprobs = tensor([[-1.2401, -1.2387],
        [-1.5909, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031061548739671707
Epoch 0, Step 2706: train/loss = 0.6972567439079285, train/raw-loss = 0.6878577470779419, train/logprobs = tensor([[-0.8724, -0.8142],
        [-1.6304, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018797867000102997
Epoch 0, Step 2707: train/loss = 0.6932657957077026, train/raw-loss = 0.6656354665756226, train/logprobs = tensor([[-1.1466, -1.6318],
        [-1.5083, -1.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055260565131902695
Epoch 0, Step 2708: train/loss = 0.6983028054237366, train/raw-loss = 0.6807198524475098, train/logprobs = tensor([[-1.0933, -1.5444],
        [-1.2856, -1.0362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035165853798389435
Epoch 0, Step 2709: train/loss = 0.696042537689209, train/raw-loss = 0.6812427043914795, train/logprobs = tensor([[-1.2347, -1.4755],
        [-1.4012, -1.0680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029599864035844803
Epoch 0, Step 2710: train/loss = 0.695326566696167, train/raw-loss = 0.6744318604469299, train/logprobs = tensor([[-1.0866, -1.3312],
        [-1.3816, -0.9070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04178944230079651
Epoch 0, Step 2711: train/loss = 0.698973536491394, train/raw-loss = 0.6720184087753296, train/logprobs = tensor([[-0.9644, -1.2837],
        [-1.6044, -1.1665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053910255432128906
Epoch 0, Step 2712: train/loss = 0.6938179731369019, train/raw-loss = 0.6774272918701172, train/logprobs = tensor([[-1.1427, -1.2987],
        [-1.5856, -1.2502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03278135508298874
Epoch 0, Step 2713: train/loss = 0.6951615214347839, train/raw-loss = 0.6790484189987183, train/logprobs = tensor([[-1.2888, -1.3595],
        [-1.4889, -1.2744]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03222630172967911
Epoch 0, Step 2714: train/loss = 0.6901878118515015, train/raw-loss = 0.6652359962463379, train/logprobs = tensor([[-1.1815, -1.4949],
        [-1.4005, -1.0583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049903638660907745
Epoch 0, Step 2715: train/loss = 0.6894493699073792, train/raw-loss = 0.6634659171104431, train/logprobs = tensor([[-1.2114, -1.5976],
        [-1.7852, -1.2623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05196690931916237
Epoch 0, Step 2716: train/loss = 0.6845226287841797, train/raw-loss = 0.6643902063369751, train/logprobs = tensor([[-1.1505, -1.4537],
        [-1.3446, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0402647890150547
Epoch 0, Step 2717: train/loss = 0.6817046999931335, train/raw-loss = 0.6293635368347168, train/logprobs = tensor([[-1.1012, -1.8173],
        [-1.6458, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1046823263168335
Epoch 0, Step 2718: train/loss = 0.6930363178253174, train/raw-loss = 0.68646639585495, train/logprobs = tensor([[-1.2481, -1.3404],
        [-1.4949, -1.1914]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013139850459992886
Epoch 0, Step 2719: train/loss = 0.6880320310592651, train/raw-loss = 0.6721192598342896, train/logprobs = tensor([[-1.1170, -1.5312],
        [-1.3465, -1.2310]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03182562440633774
Epoch 0, Step 2720: train/loss = 0.6963087320327759, train/raw-loss = 0.6922910213470459, train/logprobs = tensor([[-1.1628, -1.1431],
        [-1.3852, -1.1149]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008035395294427872
Epoch 0, Step 2721: train/loss = 0.7025591135025024, train/raw-loss = 0.7021867036819458, train/logprobs = tensor([[-1.3408, -1.1242],
        [-1.4366, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000744943565223366
Epoch 0, Step 2722: train/loss = 0.687639594078064, train/raw-loss = 0.6596438884735107, train/logprobs = tensor([[-1.1925, -1.6908],
        [-1.2892, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05599146708846092
Epoch 0, Step 2723: train/loss = 0.721199631690979, train/raw-loss = 0.6900222897529602, train/logprobs = tensor([[-1.4144, -1.4393],
        [-1.9768, -1.0431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06235475465655327
Epoch 0, Step 2724: train/loss = 0.6962711215019226, train/raw-loss = 0.6872940063476562, train/logprobs = tensor([[-0.9904, -1.3525],
        [-1.2442, -1.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01795412041246891
Epoch 0, Step 2725: train/loss = 0.6876939535140991, train/raw-loss = 0.6747572422027588, train/logprobs = tensor([[-1.3248, -1.5807],
        [-1.4035, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025873543694615364
Epoch 0, Step 2726: train/loss = 0.7018056511878967, train/raw-loss = 0.6910189390182495, train/logprobs = tensor([[-1.2029, -1.6979],
        [-1.3932, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021573448553681374
Epoch 0, Step 2727: train/loss = 0.6636776924133301, train/raw-loss = 0.6477264165878296, train/logprobs = tensor([[-1.3825, -1.7827],
        [-1.8273, -1.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031902559101581573
Epoch 0, Step 2728: train/loss = 0.6762785911560059, train/raw-loss = 0.623572051525116, train/logprobs = tensor([[-1.2201, -1.6141],
        [-1.8638, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10541297495365143
Epoch 0, Step 2729: train/loss = 0.7773405313491821, train/raw-loss = 0.7476215958595276, train/logprobs = tensor([[-1.4476, -1.2034],
        [-1.7809, -0.8961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05943780392408371
Epoch 0, Step 2730: train/loss = 0.6936116814613342, train/raw-loss = 0.6862033009529114, train/logprobs = tensor([[-1.2368, -1.4338],
        [-1.3923, -1.1789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014816846698522568
Epoch 0, Step 2731: train/loss = 0.7063508033752441, train/raw-loss = 0.6863914728164673, train/logprobs = tensor([[-1.4014, -1.4909],
        [-1.5175, -0.7784]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0399186909198761
Epoch 0, Step 2732: train/loss = 0.6882790923118591, train/raw-loss = 0.6661320328712463, train/logprobs = tensor([[-1.1118, -1.4761],
        [-1.6370, -1.1610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044293999671936035
Epoch 0, Step 2733: train/loss = 0.6958765983581543, train/raw-loss = 0.6752386689186096, train/logprobs = tensor([[-1.3083, -1.5183],
        [-1.7106, -1.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041275862604379654
Epoch 0, Step 2734: train/loss = 0.689534604549408, train/raw-loss = 0.6676042079925537, train/logprobs = tensor([[-1.0470, -1.4410],
        [-1.5894, -1.2752]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043860845267772675
Epoch 0, Step 2735: train/loss = 0.692234218120575, train/raw-loss = 0.6773625612258911, train/logprobs = tensor([[-1.0238, -1.1632],
        [-1.3111, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029743386432528496
Epoch 0, Step 2736: train/loss = 0.6966861486434937, train/raw-loss = 0.6624091863632202, train/logprobs = tensor([[-1.1864, -1.3121],
        [-1.7888, -0.9240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06855399161577225
Epoch 0, Step 2737: train/loss = 0.6753754615783691, train/raw-loss = 0.6540577411651611, train/logprobs = tensor([[-1.2182, -1.6432],
        [-1.6075, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042635478079319
Epoch 0, Step 2738: train/loss = 0.6910851001739502, train/raw-loss = 0.6478109359741211, train/logprobs = tensor([[-1.1820, -1.5437],
        [-1.6819, -0.9023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08654825389385223
Epoch 0, Step 2739: train/loss = 0.6919475793838501, train/raw-loss = 0.6643586158752441, train/logprobs = tensor([[-1.1567, -1.5371],
        [-1.4561, -1.1767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055178072303533554
Epoch 0, Step 2740: train/loss = 0.6978994607925415, train/raw-loss = 0.6953837871551514, train/logprobs = tensor([[-1.2931, -1.2726],
        [-1.1932, -0.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005031273700296879
Epoch 0, Step 2741: train/loss = 0.687743067741394, train/raw-loss = 0.651113748550415, train/logprobs = tensor([[-1.0651, -1.6232],
        [-1.4587, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07325848191976547
Epoch 0, Step 2742: train/loss = 0.6875909566879272, train/raw-loss = 0.6582270860671997, train/logprobs = tensor([[-1.1834, -1.5844],
        [-1.5259, -1.0498]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05872763693332672
Epoch 0, Step 2743: train/loss = 0.6832517385482788, train/raw-loss = 0.6376984119415283, train/logprobs = tensor([[-1.1280, -1.6726],
        [-1.9232, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09110669046640396
Epoch 0, Step 2744: train/loss = 0.6833482980728149, train/raw-loss = 0.6633191108703613, train/logprobs = tensor([[-0.9286, -1.2922],
        [-1.4894, -1.0887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040058284997940063
Epoch 0, Step 2745: train/loss = 0.6957245469093323, train/raw-loss = 0.6568213105201721, train/logprobs = tensor([[-0.9064, -1.5042],
        [-1.5251, -1.2499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07780639827251434
Epoch 0, Step 2746: train/loss = 0.6929874420166016, train/raw-loss = 0.6813715100288391, train/logprobs = tensor([[-0.9763, -1.2989],
        [-1.4750, -1.2148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02323186583817005
Epoch 0, Step 2747: train/loss = 0.6600672006607056, train/raw-loss = 0.6248542070388794, train/logprobs = tensor([[-1.0812, -1.7731],
        [-1.6335, -1.1038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07042600959539413
Epoch 0, Step 2748: train/loss = 0.6544960737228394, train/raw-loss = 0.6241677403450012, train/logprobs = tensor([[-1.1561, -2.0422],
        [-1.5645, -1.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060656651854515076
Epoch 0, Step 2749: train/loss = 0.6872464418411255, train/raw-loss = 0.6743514537811279, train/logprobs = tensor([[-1.2571, -1.5157],
        [-1.6023, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025790007784962654
Epoch 0, Step 2750: train/loss = 0.7050918340682983, train/raw-loss = 0.6926778554916382, train/logprobs = tensor([[-1.2258, -1.6044],
        [-1.6242, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02482794038951397
Epoch 0, Step 2751: train/loss = 0.6889064311981201, train/raw-loss = 0.6591848134994507, train/logprobs = tensor([[-1.2113, -2.0046],
        [-1.5498, -1.0626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05944319814443588
Epoch 0, Step 2752: train/loss = 0.685383677482605, train/raw-loss = 0.656665563583374, train/logprobs = tensor([[-1.1292, -1.5294],
        [-1.3138, -0.8372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05743633955717087
Epoch 0, Step 2753: train/loss = 0.695877194404602, train/raw-loss = 0.6877570152282715, train/logprobs = tensor([[-0.8949, -1.2510],
        [-1.2670, -1.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01624026708304882
Epoch 0, Step 2754: train/loss = 0.6768146753311157, train/raw-loss = 0.6375504732131958, train/logprobs = tensor([[-0.9941, -1.5394],
        [-1.7743, -1.3508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07852834463119507
Epoch 0, Step 2755: train/loss = 0.6920425891876221, train/raw-loss = 0.6789946556091309, train/logprobs = tensor([[-1.1327, -1.4181],
        [-1.4531, -1.1697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026095855981111526
Epoch 0, Step 2756: train/loss = 0.6933698654174805, train/raw-loss = 0.6933348774909973, train/logprobs = tensor([[-1.0478, -1.0398],
        [-1.5692, -1.5680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.991546251811087e-05
Epoch 0, Step 2757: train/loss = 0.6933625936508179, train/raw-loss = 0.6835089921951294, train/logprobs = tensor([[-1.0820, -1.3536],
        [-1.4174, -1.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019707191735506058
Epoch 0, Step 2758: train/loss = 0.6968211531639099, train/raw-loss = 0.6835581064224243, train/logprobs = tensor([[-1.4022, -1.5128],
        [-1.4480, -1.1691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02652600221335888
Epoch 0, Step 2759: train/loss = 0.6912854909896851, train/raw-loss = 0.6856512427330017, train/logprobs = tensor([[-1.0293, -1.1573],
        [-1.1528, -0.9913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011268439702689648
Epoch 0, Step 2760: train/loss = 0.7073059678077698, train/raw-loss = 0.679466962814331, train/logprobs = tensor([[-1.0963, -1.2044],
        [-1.7543, -1.1378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0556781105697155
Epoch 0, Step 2761: train/loss = 0.6846457123756409, train/raw-loss = 0.613102376461029, train/logprobs = tensor([[-1.1116, -1.8487],
        [-1.6078, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14308671653270721
Epoch 0, Step 2762: train/loss = 0.6970498561859131, train/raw-loss = 0.6729223728179932, train/logprobs = tensor([[-1.0390, -1.4867],
        [-1.5376, -1.1288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04825503006577492
Epoch 0, Step 2763: train/loss = 0.6933179497718811, train/raw-loss = 0.6688394546508789, train/logprobs = tensor([[-1.2459, -1.5865],
        [-1.5524, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048957034945487976
Epoch 0, Step 2764: train/loss = 0.6920915842056274, train/raw-loss = 0.6623853445053101, train/logprobs = tensor([[-1.3604, -1.6022],
        [-1.6763, -0.9952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05941271036863327
Epoch 0, Step 2765: train/loss = 0.691654622554779, train/raw-loss = 0.6873186230659485, train/logprobs = tensor([[-0.9767, -1.1129],
        [-1.1316, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008672034367918968
Epoch 0, Step 2766: train/loss = 0.6790443658828735, train/raw-loss = 0.6274452209472656, train/logprobs = tensor([[-1.1660, -1.5525],
        [-1.8128, -1.1038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10319831222295761
Epoch 0, Step 2767: train/loss = 0.6552243828773499, train/raw-loss = 0.618938684463501, train/logprobs = tensor([[-1.0408, -1.5685],
        [-1.8125, -1.2450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07257138192653656
Epoch 0, Step 2768: train/loss = 0.6924992203712463, train/raw-loss = 0.6579374670982361, train/logprobs = tensor([[-1.1754, -1.7255],
        [-1.3558, -0.9788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06912356615066528
Epoch 0, Step 2769: train/loss = 0.707952618598938, train/raw-loss = 0.6865373849868774, train/logprobs = tensor([[-1.4267, -1.6107],
        [-1.4554, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04283041134476662
Epoch 0, Step 2770: train/loss = 0.7023731470108032, train/raw-loss = 0.6791565418243408, train/logprobs = tensor([[-1.2078, -1.6395],
        [-1.4822, -1.2297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04643312841653824
Epoch 0, Step 2771: train/loss = 0.6954025030136108, train/raw-loss = 0.6749953627586365, train/logprobs = tensor([[-1.2566, -1.4450],
        [-1.4916, -1.0715]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04081416875123978
Epoch 0, Step 2772: train/loss = 0.6980597376823425, train/raw-loss = 0.6703250408172607, train/logprobs = tensor([[-1.1086, -1.3226],
        [-1.6320, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055469319224357605
Epoch 0, Step 2773: train/loss = 0.7002381086349487, train/raw-loss = 0.6808822154998779, train/logprobs = tensor([[-1.0954, -1.4932],
        [-1.3433, -1.1859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03871180862188339
Epoch 0, Step 2774: train/loss = 0.6945761442184448, train/raw-loss = 0.686948835849762, train/logprobs = tensor([[-1.6959, -1.8328],
        [-1.4283, -1.2980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01525467075407505
Epoch 0, Step 2775: train/loss = 0.691664457321167, train/raw-loss = 0.6695327162742615, train/logprobs = tensor([[-1.0358, -1.2118],
        [-1.2854, -0.8586]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04426340386271477
Epoch 0, Step 2776: train/loss = 0.6437241435050964, train/raw-loss = 0.6161069273948669, train/logprobs = tensor([[-0.9621, -1.5996],
        [-2.1837, -1.3314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.055234380066394806
Epoch 0, Step 2777: train/loss = 0.6933568716049194, train/raw-loss = 0.6752014756202698, train/logprobs = tensor([[-1.1533, -1.3151],
        [-1.3892, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03631085157394409
Epoch 0, Step 2778: train/loss = 0.6915707588195801, train/raw-loss = 0.6672831177711487, train/logprobs = tensor([[-1.0271, -1.2571],
        [-1.2987, -0.9707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04857533797621727
Epoch 0, Step 2779: train/loss = 0.6624422073364258, train/raw-loss = 0.61151123046875, train/logprobs = tensor([[-0.9352, -1.7266],
        [-1.7611, -1.3100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10186206549406052
Epoch 0, Step 2780: train/loss = 0.6984915733337402, train/raw-loss = 0.6819168925285339, train/logprobs = tensor([[-1.0922, -1.3253],
        [-1.5398, -1.0330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033149540424346924
Epoch 0, Step 2781: train/loss = 0.6909607648849487, train/raw-loss = 0.6642321348190308, train/logprobs = tensor([[-1.0079, -1.4503],
        [-1.7965, -1.2770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05345720797777176
Epoch 0, Step 2782: train/loss = 0.6872014403343201, train/raw-loss = 0.6461683511734009, train/logprobs = tensor([[-1.0669, -1.4001],
        [-1.6825, -1.0432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08206604421138763
Epoch 0, Step 2783: train/loss = 0.7246381044387817, train/raw-loss = 0.6817543506622314, train/logprobs = tensor([[-1.0847, -2.2458],
        [-1.5184, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08576744794845581
Epoch 0, Step 2784: train/loss = 0.6884925365447998, train/raw-loss = 0.6699156761169434, train/logprobs = tensor([[-1.0715, -1.3236],
        [-1.5840, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03715360909700394
Epoch 0, Step 2785: train/loss = 0.6906885504722595, train/raw-loss = 0.654052734375, train/logprobs = tensor([[-1.1226, -1.5204],
        [-1.7020, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07327168434858322
Epoch 0, Step 2786: train/loss = 0.7139062881469727, train/raw-loss = 0.706658124923706, train/logprobs = tensor([[-1.0785, -1.3827],
        [-1.0053, -0.8775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01449628360569477
Epoch 0, Step 2787: train/loss = 0.7137699127197266, train/raw-loss = 0.6809651851654053, train/logprobs = tensor([[-1.3791, -1.6035],
        [-1.5464, -0.8988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06560958176851273
Epoch 0, Step 2788: train/loss = 0.7059366106987, train/raw-loss = 0.701244056224823, train/logprobs = tensor([[-1.2906, -1.2690],
        [-1.8940, -1.7181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009385200217366219
Epoch 0, Step 2789: train/loss = 0.6955487132072449, train/raw-loss = 0.6912181377410889, train/logprobs = tensor([[-1.1723, -1.2236],
        [-1.3663, -1.0932]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008661064319312572
Epoch 0, Step 2790: train/loss = 0.6993130445480347, train/raw-loss = 0.6965376734733582, train/logprobs = tensor([[-1.2091, -1.3199],
        [-1.3605, -1.2405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00555084552615881
Epoch 0, Step 2791: train/loss = 0.6910836100578308, train/raw-loss = 0.6738303899765015, train/logprobs = tensor([[-1.3879, -1.7342],
        [-1.3139, -0.9745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034506380558013916
Epoch 0, Step 2792: train/loss = 0.6975038051605225, train/raw-loss = 0.6936150789260864, train/logprobs = tensor([[-0.9868, -0.9818],
        [-1.6570, -1.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00777735561132431
Epoch 0, Step 2793: train/loss = 0.702166736125946, train/raw-loss = 0.6783709526062012, train/logprobs = tensor([[-1.3702, -1.4253],
        [-1.6578, -1.0928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04759154096245766
Epoch 0, Step 2794: train/loss = 0.6979910135269165, train/raw-loss = 0.6876053810119629, train/logprobs = tensor([[-1.0202, -1.1223],
        [-1.6753, -1.2939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020771412178874016
Epoch 0, Step 2795: train/loss = 0.6855978965759277, train/raw-loss = 0.6440580487251282, train/logprobs = tensor([[-1.2477, -1.7392],
        [-1.9719, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08307967334985733
Epoch 0, Step 2796: train/loss = 0.6804071664810181, train/raw-loss = 0.6113384962081909, train/logprobs = tensor([[-0.9325, -1.6449],
        [-1.8302, -1.2123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13813719153404236
Epoch 0, Step 2797: train/loss = 0.6980006694793701, train/raw-loss = 0.695304274559021, train/logprobs = tensor([[-1.2506, -1.3322],
        [-1.6028, -1.4197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005392781924456358
Epoch 0, Step 2798: train/loss = 0.7562055587768555, train/raw-loss = 0.7194418907165527, train/logprobs = tensor([[-1.1671, -2.1656],
        [-1.6946, -1.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07352732867002487
Epoch 0, Step 2799: train/loss = 0.6788522005081177, train/raw-loss = 0.6530615091323853, train/logprobs = tensor([[-1.3366, -1.8191],
        [-1.5278, -1.1754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051581427454948425
Epoch 0, Step 2800: train/loss = 0.6795070767402649, train/raw-loss = 0.6686306595802307, train/logprobs = tensor([[-1.0333, -1.2525],
        [-1.5141, -1.1832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021752789616584778
Epoch 0, Step 2801: train/loss = 0.6978983879089355, train/raw-loss = 0.6949973106384277, train/logprobs = tensor([[-1.4041, -1.6296],
        [-1.0540, -1.0086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005802278406918049
Epoch 0, Step 2802: train/loss = 0.6424273252487183, train/raw-loss = 0.6270272731781006, train/logprobs = tensor([[-1.2769, -1.8916],
        [-1.6641, -1.1785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030800143256783485
Epoch 0, Step 2803: train/loss = 0.7035431265830994, train/raw-loss = 0.6811335682868958, train/logprobs = tensor([[-1.0307, -1.5287],
        [-1.5336, -1.3834]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04481919854879379
Epoch 0, Step 2804: train/loss = 0.6906442046165466, train/raw-loss = 0.6699386835098267, train/logprobs = tensor([[-1.0613, -1.3528],
        [-1.9510, -1.5147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04141108691692352
Epoch 0, Step 2805: train/loss = 0.6837159991264343, train/raw-loss = 0.6307163834571838, train/logprobs = tensor([[-1.0186, -1.9681],
        [-1.6646, -1.1169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10599924623966217
Epoch 0, Step 2806: train/loss = 0.7009320855140686, train/raw-loss = 0.672930121421814, train/logprobs = tensor([[-1.0765, -1.6531],
        [-1.5272, -1.1546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056003984063863754
Epoch 0, Step 2807: train/loss = 0.690812885761261, train/raw-loss = 0.6860173940658569, train/logprobs = tensor([[-1.1528, -1.3788],
        [-1.3458, -1.1718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009590985253453255
Epoch 0, Step 2808: train/loss = 0.6865108013153076, train/raw-loss = 0.651709794998169, train/logprobs = tensor([[-1.3824, -1.7630],
        [-1.8929, -1.3837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06960206478834152
Epoch 0, Step 2809: train/loss = 0.6866909265518188, train/raw-loss = 0.6409163475036621, train/logprobs = tensor([[-1.1842, -1.6857],
        [-1.3821, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0915491133928299
Epoch 0, Step 2810: train/loss = 0.6945509910583496, train/raw-loss = 0.6915403604507446, train/logprobs = tensor([[-0.9601, -1.0007],
        [-1.3625, -1.5505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006021265871822834
Epoch 0, Step 2811: train/loss = 0.6928720474243164, train/raw-loss = 0.6618244647979736, train/logprobs = tensor([[-1.0924, -1.6427],
        [-1.5568, -1.2979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06209508329629898
Epoch 0, Step 2812: train/loss = 0.6917537450790405, train/raw-loss = 0.6759148836135864, train/logprobs = tensor([[-1.0359, -1.2955],
        [-1.7717, -1.5089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03167782723903656
Epoch 0, Step 2813: train/loss = 0.6986105442047119, train/raw-loss = 0.665764570236206, train/logprobs = tensor([[-1.0126, -1.2597],
        [-1.8352, -0.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06569184362888336
Epoch 0, Step 2814: train/loss = 0.6947834491729736, train/raw-loss = 0.6822022199630737, train/logprobs = tensor([[-1.1370, -1.4060],
        [-1.4842, -1.3210]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025162501260638237
Epoch 0, Step 2815: train/loss = 0.6898731589317322, train/raw-loss = 0.671477735042572, train/logprobs = tensor([[-1.1372, -1.3720],
        [-1.7858, -1.3499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0367908775806427
Epoch 0, Step 2816: train/loss = 0.6892187595367432, train/raw-loss = 0.6471349000930786, train/logprobs = tensor([[-1.1488, -1.5469],
        [-1.8243, -1.0183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0841677114367485
Epoch 0, Step 2817: train/loss = 0.6930563449859619, train/raw-loss = 0.6622737646102905, train/logprobs = tensor([[-1.1951, -1.4447],
        [-1.5170, -0.7545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06156511977314949
Epoch 0, Step 2818: train/loss = 0.6794631481170654, train/raw-loss = 0.6400324106216431, train/logprobs = tensor([[-1.2190, -1.7881],
        [-1.7347, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07886151969432831
Epoch 0, Step 2819: train/loss = 0.6986100077629089, train/raw-loss = 0.6889374256134033, train/logprobs = tensor([[-1.2797, -1.2568],
        [-1.4689, -1.0099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019345201551914215
Epoch 0, Step 2820: train/loss = 0.6466320753097534, train/raw-loss = 0.6193889379501343, train/logprobs = tensor([[-1.2817, -1.8098],
        [-1.8031, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05448627844452858
Epoch 0, Step 2821: train/loss = 0.6796556711196899, train/raw-loss = 0.6243078112602234, train/logprobs = tensor([[-1.1294, -1.7622],
        [-1.7215, -0.8889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11069570481777191
Epoch 0, Step 2822: train/loss = 0.6935484409332275, train/raw-loss = 0.6636630296707153, train/logprobs = tensor([[-1.0359, -1.4176],
        [-1.6441, -1.2481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05977083370089531
Epoch 0, Step 2823: train/loss = 0.695752739906311, train/raw-loss = 0.6868559122085571, train/logprobs = tensor([[-1.0803, -1.1714],
        [-1.4728, -1.2576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017793593928217888
Epoch 0, Step 2824: train/loss = 0.6953096985816956, train/raw-loss = 0.679915189743042, train/logprobs = tensor([[-1.4258, -1.6326],
        [-1.5740, -1.2617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030789045616984367
Epoch 0, Step 2825: train/loss = 0.6878130435943604, train/raw-loss = 0.6540786623954773, train/logprobs = tensor([[-1.0971, -1.5311],
        [-1.7680, -1.2959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06746885180473328
Epoch 0, Step 2826: train/loss = 0.6791720390319824, train/raw-loss = 0.641665518283844, train/logprobs = tensor([[-1.2414, -1.7642],
        [-1.4424, -0.8071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07501297444105148
Epoch 0, Step 2827: train/loss = 0.699016809463501, train/raw-loss = 0.6738569736480713, train/logprobs = tensor([[-1.0621, -1.4463],
        [-1.5547, -1.2212]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05031969025731087
Epoch 0, Step 2828: train/loss = 0.6994767189025879, train/raw-loss = 0.6613028049468994, train/logprobs = tensor([[-0.8951, -1.3887],
        [-1.7759, -1.2176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07634785771369934
Epoch 0, Step 2829: train/loss = 0.6914939880371094, train/raw-loss = 0.6736224293708801, train/logprobs = tensor([[-1.2035, -1.4736],
        [-1.1904, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03574317321181297
Epoch 0, Step 2830: train/loss = 0.6894080638885498, train/raw-loss = 0.6435703635215759, train/logprobs = tensor([[-1.0778, -1.6153],
        [-1.4969, -0.8064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09167537838220596
Epoch 0, Step 2831: train/loss = 0.7046837210655212, train/raw-loss = 0.6794052720069885, train/logprobs = tensor([[-1.1395, -1.4036],
        [-1.8305, -1.1520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05055706202983856
Epoch 0, Step 2832: train/loss = 0.6938038468360901, train/raw-loss = 0.6937979459762573, train/logprobs = tensor([[-1.3125, -1.3039],
        [-1.4697, -1.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1909767636097968e-05
Epoch 0, Step 2833: train/loss = 0.6979517936706543, train/raw-loss = 0.6907141208648682, train/logprobs = tensor([[-1.2736, -1.3644],
        [-1.2097, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014475341886281967
Epoch 0, Step 2834: train/loss = 0.7024560570716858, train/raw-loss = 0.6761744022369385, train/logprobs = tensor([[-1.0758, -1.3178],
        [-1.5652, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05256336182355881
Epoch 0, Step 2835: train/loss = 0.6937172412872314, train/raw-loss = 0.6485447883605957, train/logprobs = tensor([[-1.1034, -1.5254],
        [-1.9000, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09034498780965805
Epoch 0, Step 2836: train/loss = 0.6854797601699829, train/raw-loss = 0.625598669052124, train/logprobs = tensor([[-1.0898, -1.7057],
        [-1.9217, -1.2633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11976228654384613
Epoch 0, Step 2837: train/loss = 0.7070799469947815, train/raw-loss = 0.6920112371444702, train/logprobs = tensor([[-1.1419, -1.4609],
        [-1.2576, -1.1997]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030137423425912857
Epoch 0, Step 2838: train/loss = 0.7199780344963074, train/raw-loss = 0.6312314867973328, train/logprobs = tensor([[-1.1409, -1.7138],
        [-2.1753, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1774931699037552
Epoch 0, Step 2839: train/loss = 0.6921491622924805, train/raw-loss = 0.6589562296867371, train/logprobs = tensor([[-1.2335, -1.5571],
        [-1.7885, -1.1801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06638593971729279
Epoch 0, Step 2840: train/loss = 0.6924874782562256, train/raw-loss = 0.6652078032493591, train/logprobs = tensor([[-1.0743, -1.3836],
        [-1.5835, -1.1432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05455933138728142
Epoch 0, Step 2841: train/loss = 0.6890780329704285, train/raw-loss = 0.673898458480835, train/logprobs = tensor([[-1.2783, -1.5200],
        [-1.6241, -1.0811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03035905212163925
Epoch 0, Step 2842: train/loss = 0.695177435874939, train/raw-loss = 0.6795827150344849, train/logprobs = tensor([[-1.1835, -1.3661],
        [-1.5714, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03118954598903656
Epoch 0, Step 2843: train/loss = 0.7039065361022949, train/raw-loss = 0.6925830841064453, train/logprobs = tensor([[-1.1899, -1.6540],
        [-1.4769, -1.4759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022647056728601456
Epoch 0, Step 2844: train/loss = 0.7055630087852478, train/raw-loss = 0.699786901473999, train/logprobs = tensor([[-1.3789, -1.8294],
        [-1.2969, -1.3553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011552184820175171
Epoch 0, Step 2845: train/loss = 0.6886839866638184, train/raw-loss = 0.6542797684669495, train/logprobs = tensor([[-1.0542, -1.5915],
        [-1.5935, -1.0108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06880856305360794
Epoch 0, Step 2846: train/loss = 0.6886913776397705, train/raw-loss = 0.6606045961380005, train/logprobs = tensor([[-1.0714, -1.4108],
        [-1.5058, -0.8958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056173551827669144
Epoch 0, Step 2847: train/loss = 0.6929442882537842, train/raw-loss = 0.6761427521705627, train/logprobs = tensor([[-1.1035, -1.6244],
        [-1.7261, -1.4872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03360305726528168
Epoch 0, Step 2848: train/loss = 0.6963182687759399, train/raw-loss = 0.6907286643981934, train/logprobs = tensor([[-1.2337, -1.3557],
        [-1.4730, -1.4095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01117925439029932
Epoch 0, Step 2849: train/loss = 0.6982781887054443, train/raw-loss = 0.6892585754394531, train/logprobs = tensor([[-1.2124, -1.4283],
        [-1.5172, -1.1650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0180391613394022
Epoch 0, Step 2850: train/loss = 0.7118891477584839, train/raw-loss = 0.6679454445838928, train/logprobs = tensor([[-1.6580, -1.7625],
        [-1.7346, -0.8994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08788735419511795
Epoch 0, Step 2851: train/loss = 0.7100483775138855, train/raw-loss = 0.6750885248184204, train/logprobs = tensor([[-1.2934, -1.7531],
        [-1.4346, -1.0651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0699196457862854
Epoch 0, Step 2852: train/loss = 0.6905585527420044, train/raw-loss = 0.6672645807266235, train/logprobs = tensor([[-1.1650, -1.4056],
        [-2.1627, -1.7236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04658793285489082
Epoch 0, Step 2853: train/loss = 0.6999460458755493, train/raw-loss = 0.6873028874397278, train/logprobs = tensor([[-1.2240, -1.2180],
        [-1.6966, -1.3949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02528630942106247
Epoch 0, Step 2854: train/loss = 0.6836053133010864, train/raw-loss = 0.6141373515129089, train/logprobs = tensor([[-1.0272, -2.0469],
        [-1.7754, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1389358937740326
Epoch 0, Step 2855: train/loss = 0.6920740008354187, train/raw-loss = 0.6449730396270752, train/logprobs = tensor([[-1.2055, -1.6787],
        [-2.0059, -1.2884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09420199692249298
Epoch 0, Step 2856: train/loss = 0.6969221830368042, train/raw-loss = 0.678658127784729, train/logprobs = tensor([[-0.9289, -1.0241],
        [-1.4447, -1.0105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03652818873524666
Epoch 0, Step 2857: train/loss = 0.6755290031433105, train/raw-loss = 0.6213881969451904, train/logprobs = tensor([[-0.9976, -1.8774],
        [-1.7487, -1.2084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10828171670436859
Epoch 0, Step 2858: train/loss = 0.702460765838623, train/raw-loss = 0.6959094405174255, train/logprobs = tensor([[-1.3111, -1.3889],
        [-1.5206, -1.1562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013102601282298565
Epoch 0, Step 2859: train/loss = 0.7031205892562866, train/raw-loss = 0.6505838632583618, train/logprobs = tensor([[-1.2649, -1.4255],
        [-1.5813, -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10507349669933319
Epoch 0, Step 2860: train/loss = 0.6868370771408081, train/raw-loss = 0.6616412401199341, train/logprobs = tensor([[-1.1880, -1.7229],
        [-1.7397, -1.2760]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05039163678884506
Epoch 0, Step 2861: train/loss = 0.688178300857544, train/raw-loss = 0.6586624979972839, train/logprobs = tensor([[-1.0310, -1.6546],
        [-2.0699, -1.4738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05903158336877823
Epoch 0, Step 2862: train/loss = 0.700241208076477, train/raw-loss = 0.6882035732269287, train/logprobs = tensor([[-1.2277, -1.2999],
        [-1.4683, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02407531999051571
Epoch 0, Step 2863: train/loss = 0.6727792024612427, train/raw-loss = 0.5954416990280151, train/logprobs = tensor([[-1.0534, -1.8924],
        [-1.9788, -1.0319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15467506647109985
Epoch 0, Step 2864: train/loss = 0.6884409189224243, train/raw-loss = 0.663713812828064, train/logprobs = tensor([[-1.2868, -1.6135],
        [-1.4547, -1.1700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04945414513349533
Epoch 0, Step 2865: train/loss = 0.6780039072036743, train/raw-loss = 0.6355080604553223, train/logprobs = tensor([[-1.2954, -2.1614],
        [-1.7464, -1.3828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08499154448509216
Epoch 0, Step 2866: train/loss = 0.697745680809021, train/raw-loss = 0.6878246665000916, train/logprobs = tensor([[-1.2788, -1.5048],
        [-1.4932, -1.2143]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019842125475406647
Epoch 0, Step 2867: train/loss = 0.6998472213745117, train/raw-loss = 0.6954870223999023, train/logprobs = tensor([[-1.2580, -1.4254],
        [-1.2888, -1.2239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008720542304217815
Epoch 0, Step 2868: train/loss = 0.6821075677871704, train/raw-loss = 0.6319515705108643, train/logprobs = tensor([[-1.0812, -1.7753],
        [-1.7834, -1.3340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10031208395957947
Epoch 0, Step 2869: train/loss = 0.6869252920150757, train/raw-loss = 0.6669317483901978, train/logprobs = tensor([[-1.1638, -1.4323],
        [-1.6713, -1.4299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03998717665672302
Epoch 0, Step 2870: train/loss = 0.6965616941452026, train/raw-loss = 0.6840728521347046, train/logprobs = tensor([[-1.0376, -1.1171],
        [-1.6336, -1.1563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024977579712867737
Epoch 0, Step 2871: train/loss = 0.6988385915756226, train/raw-loss = 0.6779228448867798, train/logprobs = tensor([[-0.9646, -1.4103],
        [-1.3743, -0.9613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04183165356516838
Epoch 0, Step 2872: train/loss = 0.6950922012329102, train/raw-loss = 0.6851467490196228, train/logprobs = tensor([[-1.1672, -1.1827],
        [-1.4093, -1.3232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019890811294317245
Epoch 0, Step 2873: train/loss = 0.6847631931304932, train/raw-loss = 0.6634311079978943, train/logprobs = tensor([[-0.9683, -1.5194],
        [-1.8529, -1.4564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042664241045713425
Epoch 0, Step 2874: train/loss = 0.6958186626434326, train/raw-loss = 0.6422421932220459, train/logprobs = tensor([[-1.1178, -1.6581],
        [-2.0621, -1.3316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10715284943580627
Epoch 0, Step 2875: train/loss = 0.6820660829544067, train/raw-loss = 0.6729038953781128, train/logprobs = tensor([[-0.9417, -1.0763],
        [-1.9277, -1.5754]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0183243565261364
Epoch 0, Step 2876: train/loss = 0.691918134689331, train/raw-loss = 0.6804014444351196, train/logprobs = tensor([[-1.1837, -1.4820],
        [-1.5477, -1.2821]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023033451288938522
Epoch 0, Step 2877: train/loss = 0.7053442001342773, train/raw-loss = 0.6575859189033508, train/logprobs = tensor([[-0.9748, -1.9196],
        [-1.5509, -1.2886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0955166220664978
Epoch 0, Step 2878: train/loss = 0.6830712556838989, train/raw-loss = 0.6470219492912292, train/logprobs = tensor([[-1.3093, -1.8148],
        [-1.8899, -1.6018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07209853082895279
Epoch 0, Step 2879: train/loss = 0.6942253708839417, train/raw-loss = 0.6725525856018066, train/logprobs = tensor([[-1.3852, -1.6650],
        [-0.8864, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04334555193781853
Epoch 0, Step 2880: train/loss = 0.680418074131012, train/raw-loss = 0.6279650330543518, train/logprobs = tensor([[-1.0810, -1.7147],
        [-1.5713, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1049061119556427
Epoch 0, Step 2881: train/loss = 0.6924434304237366, train/raw-loss = 0.6657699346542358, train/logprobs = tensor([[-0.8815, -1.3551],
        [-1.4903, -1.2463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053347088396549225
Epoch 0, Step 2882: train/loss = 0.6830853223800659, train/raw-loss = 0.627471387386322, train/logprobs = tensor([[-1.2811, -1.9053],
        [-1.6420, -1.1778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11122791469097137
Epoch 0, Step 2883: train/loss = 0.6918495297431946, train/raw-loss = 0.6840845346450806, train/logprobs = tensor([[-1.3459, -1.5157],
        [-1.4800, -1.2748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015530006028711796
Epoch 0, Step 2884: train/loss = 0.7040998935699463, train/raw-loss = 0.6588561534881592, train/logprobs = tensor([[-1.1276, -1.3982],
        [-1.7266, -0.8669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09048743546009064
Epoch 0, Step 2885: train/loss = 0.6629967093467712, train/raw-loss = 0.6555030941963196, train/logprobs = tensor([[-1.1343, -1.2224],
        [-2.0576, -1.3983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014987286180257797
Epoch 0, Step 2886: train/loss = 0.68657386302948, train/raw-loss = 0.6528493165969849, train/logprobs = tensor([[-1.3657, -1.7759],
        [-1.4343, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06744908541440964
Epoch 0, Step 2887: train/loss = 0.6974955797195435, train/raw-loss = 0.6787726879119873, train/logprobs = tensor([[-1.4402, -1.3722],
        [-1.3527, -0.9049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037445809692144394
Epoch 0, Step 2888: train/loss = 0.6920329332351685, train/raw-loss = 0.6881442070007324, train/logprobs = tensor([[-1.4004, -1.5225],
        [-1.0856, -0.9718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007777398452162743
Epoch 0, Step 2889: train/loss = 0.6940892934799194, train/raw-loss = 0.6653864979743958, train/logprobs = tensor([[-1.1289, -1.3205],
        [-1.7736, -1.4296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05740547180175781
Epoch 0, Step 2890: train/loss = 0.6851381063461304, train/raw-loss = 0.6384419202804565, train/logprobs = tensor([[-1.0662, -1.8835],
        [-1.5596, -1.0139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09339235723018646
Epoch 0, Step 2891: train/loss = 0.702257513999939, train/raw-loss = 0.6917586326599121, train/logprobs = tensor([[-1.3694, -1.6010],
        [-1.3150, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020997630432248116
Epoch 0, Step 2892: train/loss = 0.6804111003875732, train/raw-loss = 0.6072331666946411, train/logprobs = tensor([[-1.0282, -1.7662],
        [-1.6921, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14635588228702545
Epoch 0, Step 2893: train/loss = 0.7131129503250122, train/raw-loss = 0.6767616868019104, train/logprobs = tensor([[-1.3176, -1.4536],
        [-1.6724, -0.9649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07270251214504242
Epoch 0, Step 2894: train/loss = 0.6972185373306274, train/raw-loss = 0.685546338558197, train/logprobs = tensor([[-1.2362, -1.2995],
        [-1.3442, -1.1815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023344475775957108
Epoch 0, Step 2895: train/loss = 0.6848938465118408, train/raw-loss = 0.6544383764266968, train/logprobs = tensor([[-1.1083, -1.4399],
        [-1.4405, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06091097742319107
Epoch 0, Step 2896: train/loss = 0.6932389736175537, train/raw-loss = 0.6854135990142822, train/logprobs = tensor([[-1.3447, -1.6103],
        [-1.4117, -1.2286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01565064676105976
Epoch 0, Step 2897: train/loss = 0.6798458099365234, train/raw-loss = 0.6287627816200256, train/logprobs = tensor([[-0.9218, -1.4595],
        [-1.9517, -1.0305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10216612368822098
Epoch 0, Step 2898: train/loss = 0.7059987783432007, train/raw-loss = 0.6735782623291016, train/logprobs = tensor([[-1.4210, -1.4996],
        [-1.8018, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06484093517065048
Epoch 0, Step 2899: train/loss = 0.6931061744689941, train/raw-loss = 0.6549760699272156, train/logprobs = tensor([[-1.0572, -1.4939],
        [-1.8377, -1.2716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07626022398471832
Epoch 0, Step 2900: train/loss = 0.6872915625572205, train/raw-loss = 0.6709343194961548, train/logprobs = tensor([[-1.1915, -1.4800],
        [-1.7235, -1.5566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03271456062793732
Epoch 0, Step 2901: train/loss = 0.691567063331604, train/raw-loss = 0.666230320930481, train/logprobs = tensor([[-1.1146, -1.5178],
        [-1.5253, -1.3396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05067351460456848
Epoch 0, Step 2902: train/loss = 0.6925254464149475, train/raw-loss = 0.6691738367080688, train/logprobs = tensor([[-1.2656, -1.5186],
        [-1.9205, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04670330882072449
Epoch 0, Step 2903: train/loss = 0.691862940788269, train/raw-loss = 0.6586806774139404, train/logprobs = tensor([[-1.4048, -1.6942],
        [-1.8756, -1.2750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06636462360620499
Epoch 0, Step 2904: train/loss = 0.6980348825454712, train/raw-loss = 0.6671938896179199, train/logprobs = tensor([[-1.0859, -1.3358],
        [-1.6663, -1.0880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061681926250457764
Epoch 0, Step 2905: train/loss = 0.6891584396362305, train/raw-loss = 0.6766341924667358, train/logprobs = tensor([[-1.2790, -1.6494],
        [-1.7143, -1.5173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02504849061369896
Epoch 0, Step 2906: train/loss = 0.6888145208358765, train/raw-loss = 0.661384642124176, train/logprobs = tensor([[-1.1376, -1.5453],
        [-1.8351, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054859720170497894
Epoch 0, Step 2907: train/loss = 0.6938844323158264, train/raw-loss = 0.6936430931091309, train/logprobs = tensor([[-1.3809, -1.3349],
        [-1.2473, -1.1679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004827207885682583
Epoch 0, Step 2908: train/loss = 0.6964418888092041, train/raw-loss = 0.6579494476318359, train/logprobs = tensor([[-1.2154, -1.6878],
        [-1.7357, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07698486000299454
Epoch 0, Step 2909: train/loss = 0.6864364147186279, train/raw-loss = 0.6500622034072876, train/logprobs = tensor([[-1.1291, -1.4634],
        [-1.6703, -1.0953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0727483406662941
Epoch 0, Step 2910: train/loss = 0.6985083222389221, train/raw-loss = 0.6910319328308105, train/logprobs = tensor([[-1.3496, -1.6771],
        [-1.2303, -1.1877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014952865429222584
Epoch 0, Step 2911: train/loss = 0.6947423219680786, train/raw-loss = 0.661828875541687, train/logprobs = tensor([[-1.2871, -1.5826],
        [-1.6299, -1.4396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.065826915204525
Epoch 0, Step 2912: train/loss = 0.674979031085968, train/raw-loss = 0.6330039501190186, train/logprobs = tensor([[-1.4197, -1.9460],
        [-1.6237, -0.9732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08395012468099594
Epoch 0, Step 2913: train/loss = 0.6775231957435608, train/raw-loss = 0.6113982200622559, train/logprobs = tensor([[-1.2437, -1.9892],
        [-1.6443, -1.0040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1322498470544815
Epoch 0, Step 2914: train/loss = 0.7066624164581299, train/raw-loss = 0.6973556280136108, train/logprobs = tensor([[-1.3792, -1.6167],
        [-1.6933, -1.5556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018613610416650772
Epoch 0, Step 2915: train/loss = 0.6924629211425781, train/raw-loss = 0.681365430355072, train/logprobs = tensor([[-1.4932, -1.6026],
        [-1.4264, -1.3362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02219502255320549
Epoch 0, Step 2916: train/loss = 0.7056803107261658, train/raw-loss = 0.6661280393600464, train/logprobs = tensor([[-1.4445, -1.9065],
        [-1.7684, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0791044682264328
Epoch 0, Step 2917: train/loss = 0.6940171122550964, train/raw-loss = 0.6796064376831055, train/logprobs = tensor([[-1.2755, -1.4575],
        [-1.4669, -1.3080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02882133424282074
Epoch 0, Step 2918: train/loss = 0.7091317772865295, train/raw-loss = 0.680844247341156, train/logprobs = tensor([[-1.5321, -1.6730],
        [-1.9172, -1.2414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.056575000286102295
Epoch 0, Step 2919: train/loss = 0.70250403881073, train/raw-loss = 0.6691856980323792, train/logprobs = tensor([[-1.0133, -1.6723],
        [-1.4487, -1.1244]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06663664430379868
Epoch 0, Step 2920: train/loss = 0.6950571537017822, train/raw-loss = 0.6888811588287354, train/logprobs = tensor([[-1.3514, -1.3858],
        [-1.7374, -1.3712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012352129444479942
Epoch 0, Step 2921: train/loss = 0.6922027468681335, train/raw-loss = 0.6722875237464905, train/logprobs = tensor([[-1.1254, -1.2212],
        [-1.5826, -1.4724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03983050584793091
Epoch 0, Step 2922: train/loss = 0.6936875581741333, train/raw-loss = 0.6631383895874023, train/logprobs = tensor([[-1.1329, -1.6627],
        [-1.4692, -1.1985]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061098188161849976
Epoch 0, Step 2923: train/loss = 0.6941695213317871, train/raw-loss = 0.661250114440918, train/logprobs = tensor([[-1.1249, -1.6171],
        [-1.8072, -1.4423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06583886593580246
Epoch 0, Step 2924: train/loss = 0.6972856521606445, train/raw-loss = 0.6873525977134705, train/logprobs = tensor([[-1.3147, -1.6587],
        [-1.5814, -1.4837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019866058602929115
Epoch 0, Step 2925: train/loss = 0.7005299925804138, train/raw-loss = 0.6756677627563477, train/logprobs = tensor([[-1.0702, -1.3206],
        [-1.8565, -1.1122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04972425103187561
Epoch 0, Step 2926: train/loss = 0.6910792589187622, train/raw-loss = 0.6855900287628174, train/logprobs = tensor([[-1.3786, -1.5893],
        [-1.2033, -1.0151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010978433303534985
Epoch 0, Step 2927: train/loss = 0.6904549598693848, train/raw-loss = 0.6852185130119324, train/logprobs = tensor([[-1.2143, -1.4220],
        [-1.5201, -1.2504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010472997091710567
Epoch 0, Step 2928: train/loss = 0.7176240682601929, train/raw-loss = 0.7162206172943115, train/logprobs = tensor([[-1.1827, -1.5500],
        [-1.3254, -1.5191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028069172985851765
Epoch 0, Step 2929: train/loss = 0.7038088440895081, train/raw-loss = 0.6859170198440552, train/logprobs = tensor([[-1.2891, -1.2133],
        [-1.8341, -1.4972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035783566534519196
Epoch 0, Step 2930: train/loss = 0.6911458969116211, train/raw-loss = 0.6487261056900024, train/logprobs = tensor([[-1.1610, -1.7403],
        [-1.6411, -1.0492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08483952283859253
Epoch 0, Step 2931: train/loss = 0.6881595253944397, train/raw-loss = 0.6397407054901123, train/logprobs = tensor([[-1.1504, -1.7724],
        [-1.7141, -1.3470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0968375876545906
Epoch 0, Step 2932: train/loss = 0.6886333227157593, train/raw-loss = 0.6513258814811707, train/logprobs = tensor([[-0.9645, -1.4159],
        [-1.5156, -0.9748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07461491227149963
Epoch 0, Step 2933: train/loss = 0.7822456359863281, train/raw-loss = 0.7688881158828735, train/logprobs = tensor([[-1.5814, -1.4346],
        [-2.1662, -1.6211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026715103536844254
Epoch 0, Step 2934: train/loss = 0.6995645761489868, train/raw-loss = 0.6946707963943481, train/logprobs = tensor([[-1.4213, -1.8030],
        [-1.4059, -1.4451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009787432849407196
Epoch 0, Step 2935: train/loss = 0.7305154800415039, train/raw-loss = 0.7172781229019165, train/logprobs = tensor([[-1.6459, -1.4874],
        [-1.9352, -1.1762]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02647479809820652
Epoch 0, Step 2936: train/loss = 0.6785343885421753, train/raw-loss = 0.6261526346206665, train/logprobs = tensor([[-0.9707, -1.6193],
        [-2.1324, -1.4112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10476361960172653
Epoch 0, Step 2937: train/loss = 0.694646954536438, train/raw-loss = 0.6906026601791382, train/logprobs = tensor([[-1.1120, -1.1356],
        [-1.5332, -1.3571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008088629692792892
Epoch 0, Step 2938: train/loss = 0.6959076523780823, train/raw-loss = 0.6425262689590454, train/logprobs = tensor([[-1.1920, -1.7835],
        [-1.7902, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10676270723342896
Epoch 0, Step 2939: train/loss = 0.6911537647247314, train/raw-loss = 0.6727411150932312, train/logprobs = tensor([[-1.0150, -1.2697],
        [-1.4467, -1.1957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036825310438871384
Epoch 0, Step 2940: train/loss = 0.6936686038970947, train/raw-loss = 0.665113091468811, train/logprobs = tensor([[-1.2481, -1.8850],
        [-1.8937, -1.6737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05711105465888977
Epoch 0, Step 2941: train/loss = 0.702913224697113, train/raw-loss = 0.6711603403091431, train/logprobs = tensor([[-1.3000, -1.6234],
        [-1.6966, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0635058805346489
Epoch 0, Step 2942: train/loss = 0.6992542147636414, train/raw-loss = 0.6900521516799927, train/logprobs = tensor([[-0.9915, -1.0005],
        [-1.2397, -1.0817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01840415969491005
Epoch 0, Step 2943: train/loss = 0.6980744004249573, train/raw-loss = 0.6898545026779175, train/logprobs = tensor([[-1.2466, -1.6749],
        [-1.1967, -1.0695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016439734026789665
Epoch 0, Step 2944: train/loss = 0.6891567707061768, train/raw-loss = 0.5973067879676819, train/logprobs = tensor([[-1.0346, -2.0264],
        [-1.9565, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18369996547698975
Epoch 0, Step 2945: train/loss = 0.7075252532958984, train/raw-loss = 0.6866654753684998, train/logprobs = tensor([[-1.4020, -1.3725],
        [-1.6380, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04171963781118393
Epoch 0, Step 2946: train/loss = 0.7259011268615723, train/raw-loss = 0.6788415312767029, train/logprobs = tensor([[-1.1930, -1.3682],
        [-2.0970, -1.2002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09411933273077011
Epoch 0, Step 2947: train/loss = 0.695621132850647, train/raw-loss = 0.6536078453063965, train/logprobs = tensor([[-1.3014, -1.8444],
        [-1.5269, -1.0608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08402658253908157
Epoch 0, Step 2948: train/loss = 0.6812112331390381, train/raw-loss = 0.6351633071899414, train/logprobs = tensor([[-1.2082, -1.7567],
        [-1.7099, -0.9779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09209582209587097
Epoch 0, Step 2949: train/loss = 0.6949328780174255, train/raw-loss = 0.6786201596260071, train/logprobs = tensor([[-1.1250, -1.2674],
        [-1.8722, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032625459134578705
Epoch 0, Step 2950: train/loss = 0.6754806041717529, train/raw-loss = 0.601040780544281, train/logprobs = tensor([[-1.4080, -2.1666],
        [-2.0099, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1488795131444931
Epoch 0, Step 2951: train/loss = 0.7038840055465698, train/raw-loss = 0.6972971558570862, train/logprobs = tensor([[-1.4779, -1.5320],
        [-1.7633, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.013173621147871017
Epoch 0, Step 2952: train/loss = 0.6979886293411255, train/raw-loss = 0.6856085062026978, train/logprobs = tensor([[-1.2705, -1.3301],
        [-1.4272, -0.9113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024760324507951736
Epoch 0, Step 2953: train/loss = 0.6957353949546814, train/raw-loss = 0.6821975111961365, train/logprobs = tensor([[-1.1978, -1.3247],
        [-1.3632, -0.9793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02707573212683201
Epoch 0, Step 2954: train/loss = 0.694315493106842, train/raw-loss = 0.6817009449005127, train/logprobs = tensor([[-1.3296, -1.4945],
        [-1.5431, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02522912621498108
Epoch 0, Step 2955: train/loss = 0.6984150409698486, train/raw-loss = 0.690867006778717, train/logprobs = tensor([[-1.1953, -1.4937],
        [-1.8337, -1.8788]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015096010640263557
Epoch 0, Step 2956: train/loss = 0.6994950771331787, train/raw-loss = 0.6757644414901733, train/logprobs = tensor([[-1.1112, -1.3327],
        [-1.7758, -1.3804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047461364418268204
Epoch 0, Step 2957: train/loss = 0.6966656446456909, train/raw-loss = 0.6925775408744812, train/logprobs = tensor([[-1.4472, -1.6072],
        [-1.3807, -1.3130]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008176297880709171
Epoch 0, Step 2958: train/loss = 0.6983713507652283, train/raw-loss = 0.6938180327415466, train/logprobs = tensor([[-1.0705, -1.1200],
        [-1.4031, -1.1929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009106646291911602
Epoch 0, Step 2959: train/loss = 0.6928666234016418, train/raw-loss = 0.6689273118972778, train/logprobs = tensor([[-1.1341, -1.5247],
        [-1.5421, -1.0936]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04787861183285713
Epoch 0, Step 2960: train/loss = 0.6927379965782166, train/raw-loss = 0.6684809923171997, train/logprobs = tensor([[-1.1788, -1.6344],
        [-1.4361, -1.1506]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04851413890719414
Epoch 0, Step 2961: train/loss = 0.6919041275978088, train/raw-loss = 0.6508207321166992, train/logprobs = tensor([[-1.1761, -1.5894],
        [-1.3895, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08216686546802521
Epoch 0, Step 2962: train/loss = 0.7007118463516235, train/raw-loss = 0.6935420036315918, train/logprobs = tensor([[-0.9744, -1.0894],
        [-1.4330, -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014339747838675976
Epoch 0, Step 2963: train/loss = 0.6914427876472473, train/raw-loss = 0.6585928201675415, train/logprobs = tensor([[-1.2407, -1.5958],
        [-1.8103, -1.0361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06569995731115341
Epoch 0, Step 2964: train/loss = 0.6649486422538757, train/raw-loss = 0.6031832695007324, train/logprobs = tensor([[-1.0965, -1.8218],
        [-1.6514, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1235308051109314
Epoch 0, Step 2965: train/loss = 0.6943513751029968, train/raw-loss = 0.6914395093917847, train/logprobs = tensor([[-1.2318, -1.2100],
        [-1.7395, -1.6083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005823836661875248
Epoch 0, Step 2966: train/loss = 0.7289091348648071, train/raw-loss = 0.6984148025512695, train/logprobs = tensor([[-1.1722, -1.7488],
        [-1.6439, -1.4073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060988664627075195
Epoch 0, Step 2967: train/loss = 0.693609893321991, train/raw-loss = 0.691517174243927, train/logprobs = tensor([[-1.0121, -1.0113],
        [-1.4982, -1.4661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004185435362160206
Epoch 0, Step 2968: train/loss = 0.699945330619812, train/raw-loss = 0.6823554039001465, train/logprobs = tensor([[-1.0714, -1.2856],
        [-1.8436, -1.5158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03517991676926613
Epoch 0, Step 2969: train/loss = 0.7051679491996765, train/raw-loss = 0.6742821931838989, train/logprobs = tensor([[-1.0988, -1.4848],
        [-1.8247, -1.2791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061771493405103683
Epoch 0, Step 2970: train/loss = 0.6910467147827148, train/raw-loss = 0.6428030729293823, train/logprobs = tensor([[-1.1521, -1.6976],
        [-1.9851, -1.1689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09648716449737549
Epoch 0, Step 2971: train/loss = 0.696765661239624, train/raw-loss = 0.6920154094696045, train/logprobs = tensor([[-1.5067, -1.5165],
        [-1.4583, -1.1587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009500600397586823
Epoch 0, Step 2972: train/loss = 0.7118794322013855, train/raw-loss = 0.6949194669723511, train/logprobs = tensor([[-1.3295, -1.8899],
        [-1.5091, -1.6126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03392006829380989
Epoch 0, Step 2973: train/loss = 0.6920338869094849, train/raw-loss = 0.6395778656005859, train/logprobs = tensor([[-1.0899, -1.4767],
        [-1.8874, -1.3746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10491201281547546
Epoch 0, Step 2974: train/loss = 0.6939658522605896, train/raw-loss = 0.685626208782196, train/logprobs = tensor([[-1.3019, -1.4692],
        [-1.2542, -1.0076]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.016679298132658005
Epoch 0, Step 2975: train/loss = 0.68401700258255, train/raw-loss = 0.6176945567131042, train/logprobs = tensor([[-1.0082, -1.9567],
        [-1.5803, -0.9616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1326448917388916
Epoch 0, Step 2976: train/loss = 0.6930198669433594, train/raw-loss = 0.6445091962814331, train/logprobs = tensor([[-1.0006, -1.4597],
        [-1.8130, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09702138602733612
Epoch 0, Step 2977: train/loss = 0.6920454502105713, train/raw-loss = 0.6632283926010132, train/logprobs = tensor([[-1.1730, -1.5361],
        [-2.0624, -1.8476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.057634010910987854
Epoch 0, Step 2978: train/loss = 0.6741645336151123, train/raw-loss = 0.6330709457397461, train/logprobs = tensor([[-1.1673, -1.6678],
        [-1.9872, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08218702673912048
Epoch 0, Step 2979: train/loss = 0.6951602697372437, train/raw-loss = 0.6746233701705933, train/logprobs = tensor([[-1.2782, -1.5369],
        [-1.7142, -1.2660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04107363149523735
Epoch 0, Step 2980: train/loss = 0.6774041056632996, train/raw-loss = 0.6146855354309082, train/logprobs = tensor([[-1.2466, -1.9478],
        [-1.8256, -1.0550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12543725967407227
Epoch 0, Step 2981: train/loss = 0.6875636577606201, train/raw-loss = 0.660614013671875, train/logprobs = tensor([[-1.1362, -1.5205],
        [-1.9207, -1.3678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05389930307865143
Epoch 0, Step 2982: train/loss = 0.6919887065887451, train/raw-loss = 0.6356239318847656, train/logprobs = tensor([[-1.0712, -1.6229],
        [-1.8604, -0.9670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11272959411144257
Epoch 0, Step 2983: train/loss = 0.6958064436912537, train/raw-loss = 0.6734486818313599, train/logprobs = tensor([[-1.4765, -1.8103],
        [-1.3240, -1.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04471560940146446
Epoch 0, Step 2984: train/loss = 0.6813139915466309, train/raw-loss = 0.6276471614837646, train/logprobs = tensor([[-1.1295, -1.6027],
        [-1.8507, -1.0046]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10733366012573242
Epoch 0, Step 2985: train/loss = 0.7053948640823364, train/raw-loss = 0.6785199046134949, train/logprobs = tensor([[-1.1863, -1.5817],
        [-1.6130, -1.4882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053749971091747284
Epoch 0, Step 2986: train/loss = 0.672778844833374, train/raw-loss = 0.6072755455970764, train/logprobs = tensor([[-0.9910, -2.0177],
        [-1.9134, -1.2803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13100656867027283
Epoch 0, Step 2987: train/loss = 0.6941899061203003, train/raw-loss = 0.6579048037528992, train/logprobs = tensor([[-1.1787, -1.5091],
        [-1.4880, -0.7888]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07257027179002762
Epoch 0, Step 2988: train/loss = 0.6905969977378845, train/raw-loss = 0.6646589636802673, train/logprobs = tensor([[-1.0835, -1.5312],
        [-1.7263, -1.1781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051876168698072433
Epoch 0, Step 2989: train/loss = 0.6898889541625977, train/raw-loss = 0.649071216583252, train/logprobs = tensor([[-1.0537, -1.7654],
        [-1.7084, -1.2962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0816355049610138
Epoch 0, Step 2990: train/loss = 0.6943996548652649, train/raw-loss = 0.6647413372993469, train/logprobs = tensor([[-1.1525, -1.5564],
        [-1.4811, -1.1073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05931678041815758
Epoch 0, Step 2991: train/loss = 0.6940188407897949, train/raw-loss = 0.6592128276824951, train/logprobs = tensor([[-1.2278, -1.6247],
        [-1.8491, -1.3971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06961196660995483
Epoch 0, Step 2992: train/loss = 0.7065725326538086, train/raw-loss = 0.6726397275924683, train/logprobs = tensor([[-1.2316, -1.8929],
        [-1.4859, -1.2029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06786545366048813
Epoch 0, Step 2993: train/loss = 0.6970526576042175, train/raw-loss = 0.6663060188293457, train/logprobs = tensor([[-1.1244, -1.5496],
        [-1.8375, -1.5385]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06149326637387276
Epoch 0, Step 2994: train/loss = 0.6974542140960693, train/raw-loss = 0.6911640167236328, train/logprobs = tensor([[-0.8177, -0.9915],
        [-1.5020, -1.3430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012580420821905136
Epoch 0, Step 2995: train/loss = 0.6896229386329651, train/raw-loss = 0.6600791215896606, train/logprobs = tensor([[-1.1713, -1.5690],
        [-1.6475, -1.4378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05908779427409172
Epoch 0, Step 2996: train/loss = 0.6950627565383911, train/raw-loss = 0.6835082173347473, train/logprobs = tensor([[-1.4065, -1.6712],
        [-1.4329, -1.2393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023109126836061478
Epoch 0, Step 2997: train/loss = 0.6655502915382385, train/raw-loss = 0.5454863905906677, train/logprobs = tensor([[-1.0937, -2.2285],
        [-2.3650, -1.1359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.240127831697464
Epoch 0, Step 2998: train/loss = 0.6997473239898682, train/raw-loss = 0.6343595385551453, train/logprobs = tensor([[-1.0812, -1.8648],
        [-2.1704, -1.6774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13077571988105774
Epoch 0, Step 2999: train/loss = 0.7224544882774353, train/raw-loss = 0.7054829597473145, train/logprobs = tensor([[-1.5539, -1.3479],
        [-1.6755, -1.1117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033942949026823044
eval/loss: 0.6938697099685669
Epoch 0, Step 3000: train/loss = 0.6907938718795776, train/raw-loss = 0.6491482257843018, train/logprobs = tensor([[-1.1071, -1.5903],
        [-1.5346, -1.1751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08329121023416519
Epoch 0, Step 3001: train/loss = 0.6914944052696228, train/raw-loss = 0.6618037223815918, train/logprobs = tensor([[-1.0066, -1.3377],
        [-1.2837, -0.8890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05938136950135231
Epoch 0, Step 3002: train/loss = 0.6873077750205994, train/raw-loss = 0.609833836555481, train/logprobs = tensor([[-1.1385, -1.9070],
        [-2.1047, -1.3141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15494796633720398
Epoch 0, Step 3003: train/loss = 0.6905691623687744, train/raw-loss = 0.6650553941726685, train/logprobs = tensor([[-1.0533, -1.3086],
        [-1.4589, -1.0425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051027487963438034
Epoch 0, Step 3004: train/loss = 0.6705461740493774, train/raw-loss = 0.5930004119873047, train/logprobs = tensor([[-1.0815, -1.9288],
        [-2.1675, -1.1172]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15509141981601715
Epoch 0, Step 3005: train/loss = 0.6913938522338867, train/raw-loss = 0.6482817530632019, train/logprobs = tensor([[-1.1265, -1.5353],
        [-1.6531, -0.8491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0862242728471756
Epoch 0, Step 3006: train/loss = 0.701110303401947, train/raw-loss = 0.6627772450447083, train/logprobs = tensor([[-1.2646, -1.6907],
        [-1.7446, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07666616141796112
Epoch 0, Step 3007: train/loss = 0.7029906511306763, train/raw-loss = 0.6977893710136414, train/logprobs = tensor([[-1.2217, -1.1091],
        [-1.7000, -1.2977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010402409359812737
Epoch 0, Step 3008: train/loss = 0.6898663640022278, train/raw-loss = 0.6687232255935669, train/logprobs = tensor([[-1.1843, -1.6385],
        [-1.9004, -1.6295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04228631407022476
Epoch 0, Step 3009: train/loss = 0.7021586894989014, train/raw-loss = 0.6626983880996704, train/logprobs = tensor([[-1.4599, -1.6239],
        [-1.8165, -1.0281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07892069220542908
Epoch 0, Step 3010: train/loss = 0.6809700727462769, train/raw-loss = 0.6387108564376831, train/logprobs = tensor([[-1.3065, -1.9251],
        [-1.5129, -1.1580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08451834321022034
Epoch 0, Step 3011: train/loss = 0.7034849524497986, train/raw-loss = 0.6443154215812683, train/logprobs = tensor([[-1.0647, -1.5407],
        [-2.1731, -1.2382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11833911389112473
Epoch 0, Step 3012: train/loss = 0.7017887234687805, train/raw-loss = 0.6686340570449829, train/logprobs = tensor([[-1.2711, -1.6610],
        [-1.7568, -1.4171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0663093775510788
Epoch 0, Step 3013: train/loss = 0.6958153247833252, train/raw-loss = 0.6894903182983398, train/logprobs = tensor([[-1.4421, -1.4570],
        [-1.2950, -1.0974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012650000862777233
Epoch 0, Step 3014: train/loss = 0.7130484580993652, train/raw-loss = 0.6970741748809814, train/logprobs = tensor([[-0.9209, -1.6184],
        [-1.5858, -1.5730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031948596239089966
Epoch 0, Step 3015: train/loss = 0.7092331647872925, train/raw-loss = 0.6714662313461304, train/logprobs = tensor([[-1.1107, -1.3530],
        [-1.8444, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07553373277187347
Epoch 0, Step 3016: train/loss = 0.6928451657295227, train/raw-loss = 0.6569937467575073, train/logprobs = tensor([[-1.3626, -1.8281],
        [-1.8262, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07170292735099792
Epoch 0, Step 3017: train/loss = 0.6923749446868896, train/raw-loss = 0.6564491987228394, train/logprobs = tensor([[-1.1580, -1.5884],
        [-1.6186, -1.0808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07185155153274536
Epoch 0, Step 3018: train/loss = 0.6906420588493347, train/raw-loss = 0.6657979488372803, train/logprobs = tensor([[-1.4643, -1.8022],
        [-1.4117, -1.0187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049688130617141724
Epoch 0, Step 3019: train/loss = 0.6880283951759338, train/raw-loss = 0.621549129486084, train/logprobs = tensor([[-1.0935, -1.5637],
        [-1.9962, -0.8856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13295847177505493
Epoch 0, Step 3020: train/loss = 0.7131169438362122, train/raw-loss = 0.7119983434677124, train/logprobs = tensor([[-1.5045, -1.4028],
        [-0.9820, -0.7825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002237163484096527
Epoch 0, Step 3021: train/loss = 0.6861072778701782, train/raw-loss = 0.6011590957641602, train/logprobs = tensor([[-1.1557, -2.1005],
        [-2.0783, -1.2819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16989636421203613
Epoch 0, Step 3022: train/loss = 0.6829926371574402, train/raw-loss = 0.6050668954849243, train/logprobs = tensor([[-1.0333, -1.8546],
        [-1.8244, -0.8626]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15585140883922577
Epoch 0, Step 3023: train/loss = 0.6997665762901306, train/raw-loss = 0.6981558799743652, train/logprobs = tensor([[-1.3806, -1.2857],
        [-1.3314, -1.2326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00322146899998188
Epoch 0, Step 3024: train/loss = 0.6908890604972839, train/raw-loss = 0.6643189787864685, train/logprobs = tensor([[-1.2115, -1.5798],
        [-1.6556, -1.2551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05314024165272713
Epoch 0, Step 3025: train/loss = 0.681168258190155, train/raw-loss = 0.589425802230835, train/logprobs = tensor([[-1.1744, -2.2190],
        [-1.8274, -1.1545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18348479270935059
Epoch 0, Step 3026: train/loss = 0.6924382448196411, train/raw-loss = 0.6604057550430298, train/logprobs = tensor([[-1.2269, -1.5491],
        [-1.5538, -0.9315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06406500190496445
Epoch 0, Step 3027: train/loss = 0.6897301077842712, train/raw-loss = 0.645311176776886, train/logprobs = tensor([[-1.0142, -1.5183],
        [-1.5711, -1.1602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08883780241012573
Epoch 0, Step 3028: train/loss = 0.6870909929275513, train/raw-loss = 0.6160678863525391, train/logprobs = tensor([[-1.1390, -1.7256],
        [-1.7511, -0.9020]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14204616844654083
Epoch 0, Step 3029: train/loss = 0.6934495568275452, train/raw-loss = 0.6293972134590149, train/logprobs = tensor([[-1.0539, -1.5270],
        [-1.8895, -0.8185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12810465693473816
Epoch 0, Step 3030: train/loss = 0.6897268891334534, train/raw-loss = 0.637286365032196, train/logprobs = tensor([[-1.0214, -1.7785],
        [-1.7283, -1.2422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10488102585077286
Epoch 0, Step 3031: train/loss = 0.6940532922744751, train/raw-loss = 0.6846131086349487, train/logprobs = tensor([[-1.9670, -2.0809],
        [-2.2430, -1.9334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018880322575569153
Epoch 0, Step 3032: train/loss = 0.6870688199996948, train/raw-loss = 0.6446148753166199, train/logprobs = tensor([[-1.1574, -2.1633],
        [-1.5081, -1.1352]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0849079117178917
Epoch 0, Step 3033: train/loss = 0.6970190405845642, train/raw-loss = 0.6461841464042664, train/logprobs = tensor([[-1.2620, -1.5854],
        [-1.8291, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10166970640420914
Epoch 0, Step 3034: train/loss = 0.695478618144989, train/raw-loss = 0.6907451152801514, train/logprobs = tensor([[-1.0818, -1.3046],
        [-0.9453, -0.8648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009466886520385742
Epoch 0, Step 3035: train/loss = 0.6951179504394531, train/raw-loss = 0.6755832433700562, train/logprobs = tensor([[-1.0793, -1.6309],
        [-1.4054, -1.1775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039069291204214096
Epoch 0, Step 3036: train/loss = 0.7010663151741028, train/raw-loss = 0.6801956295967102, train/logprobs = tensor([[-1.0955, -1.5811],
        [-1.1646, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041741445660591125
Epoch 0, Step 3037: train/loss = 0.6965329051017761, train/raw-loss = 0.6941959857940674, train/logprobs = tensor([[-1.3269, -1.2859],
        [-1.6972, -1.6827]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00467380927875638
Epoch 0, Step 3038: train/loss = 0.6956520080566406, train/raw-loss = 0.6428970694541931, train/logprobs = tensor([[-1.0368, -1.6892],
        [-1.5735, -1.0085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10550972819328308
Epoch 0, Step 3039: train/loss = 0.7036265730857849, train/raw-loss = 0.6947776079177856, train/logprobs = tensor([[-1.1381, -1.3307],
        [-1.6713, -1.4055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017698045819997787
Epoch 0, Step 3040: train/loss = 0.6830560564994812, train/raw-loss = 0.6395903825759888, train/logprobs = tensor([[-1.1278, -1.7940],
        [-1.6290, -1.2077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08693140745162964
Epoch 0, Step 3041: train/loss = 0.6892997622489929, train/raw-loss = 0.6734175682067871, train/logprobs = tensor([[-1.2885, -1.6536],
        [-1.4518, -1.2312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03176438808441162
Epoch 0, Step 3042: train/loss = 0.6697638034820557, train/raw-loss = 0.6215755939483643, train/logprobs = tensor([[-1.3254, -1.7830],
        [-1.9428, -1.2958]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09637635946273804
Epoch 0, Step 3043: train/loss = 0.6890621185302734, train/raw-loss = 0.6482518911361694, train/logprobs = tensor([[-1.3523, -1.8943],
        [-1.5415, -1.1285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08162057399749756
Epoch 0, Step 3044: train/loss = 0.6920303106307983, train/raw-loss = 0.6710492968559265, train/logprobs = tensor([[-1.1966, -1.4831],
        [-1.5976, -1.2981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04196201264858246
Epoch 0, Step 3045: train/loss = 0.7070710062980652, train/raw-loss = 0.6900752782821655, train/logprobs = tensor([[-1.2336, -1.6983],
        [-1.4102, -1.3786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03399151936173439
Epoch 0, Step 3046: train/loss = 0.6894447207450867, train/raw-loss = 0.6465120315551758, train/logprobs = tensor([[-1.0812, -1.4567],
        [-1.5874, -1.1189]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08586541563272476
Epoch 0, Step 3047: train/loss = 0.6934248208999634, train/raw-loss = 0.6482592821121216, train/logprobs = tensor([[-1.0345, -1.5969],
        [-1.8302, -1.3917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09033113718032837
Epoch 0, Step 3048: train/loss = 0.759411096572876, train/raw-loss = 0.7327420711517334, train/logprobs = tensor([[-1.1308, -1.8228],
        [-1.4444, -1.4446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053337980061769485
Epoch 0, Step 3049: train/loss = 0.6914947628974915, train/raw-loss = 0.6850345134735107, train/logprobs = tensor([[-1.8020, -1.9478],
        [-1.5530, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012920328415930271
Epoch 0, Step 3050: train/loss = 0.6910920143127441, train/raw-loss = 0.6681497693061829, train/logprobs = tensor([[-1.3003, -1.5547],
        [-1.5153, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04588443413376808
Epoch 0, Step 3051: train/loss = 0.6839550733566284, train/raw-loss = 0.631192684173584, train/logprobs = tensor([[-1.2840, -1.7816],
        [-1.7256, -1.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1055247113108635
Epoch 0, Step 3052: train/loss = 0.7064249515533447, train/raw-loss = 0.7022947669029236, train/logprobs = tensor([[-1.3578, -1.3633],
        [-1.4861, -1.5236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00826032180339098
Epoch 0, Step 3053: train/loss = 0.7135796546936035, train/raw-loss = 0.6528407335281372, train/logprobs = tensor([[-1.1715, -1.6615],
        [-2.0922, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12147802114486694
Epoch 0, Step 3054: train/loss = 0.6956611275672913, train/raw-loss = 0.690448522567749, train/logprobs = tensor([[-1.1950, -1.3284],
        [-1.5807, -1.2399]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010425375774502754
Epoch 0, Step 3055: train/loss = 0.6910884976387024, train/raw-loss = 0.6668782234191895, train/logprobs = tensor([[-1.0628, -1.4089],
        [-1.2136, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04842057824134827
Epoch 0, Step 3056: train/loss = 0.6938830614089966, train/raw-loss = 0.6336329579353333, train/logprobs = tensor([[-1.2797, -1.6851],
        [-1.6313, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12050017714500427
Epoch 0, Step 3057: train/loss = 0.6924240589141846, train/raw-loss = 0.6419031620025635, train/logprobs = tensor([[-1.1343, -1.6532],
        [-1.5177, -0.7573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10104189813137054
Epoch 0, Step 3058: train/loss = 0.6869980096817017, train/raw-loss = 0.6471584439277649, train/logprobs = tensor([[-1.3276, -1.9468],
        [-1.7807, -1.2631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07967926561832428
Epoch 0, Step 3059: train/loss = 0.6913808584213257, train/raw-loss = 0.6838530898094177, train/logprobs = tensor([[-1.2417, -1.4907],
        [-1.5953, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015055583789944649
Epoch 0, Step 3060: train/loss = 0.6944102048873901, train/raw-loss = 0.6921194195747375, train/logprobs = tensor([[-1.5441, -1.5375],
        [-1.5987, -1.5025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0045815082266926765
Epoch 0, Step 3061: train/loss = 0.6885145902633667, train/raw-loss = 0.6503283381462097, train/logprobs = tensor([[-1.2592, -1.7442],
        [-1.7683, -1.4002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07637237012386322
Epoch 0, Step 3062: train/loss = 0.6975638270378113, train/raw-loss = 0.6873631477355957, train/logprobs = tensor([[-1.3296, -1.3334],
        [-1.5356, -1.2055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02040144056081772
Epoch 0, Step 3063: train/loss = 0.702650785446167, train/raw-loss = 0.6918709874153137, train/logprobs = tensor([[-1.2142, -1.0978],
        [-1.1612, -0.8280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021559638902544975
Epoch 0, Step 3064: train/loss = 0.6983512043952942, train/raw-loss = 0.6958563327789307, train/logprobs = tensor([[-1.2809, -1.3610],
        [-1.4970, -1.4384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004989772569388151
Epoch 0, Step 3065: train/loss = 0.6760264039039612, train/raw-loss = 0.5756582617759705, train/logprobs = tensor([[-0.9517, -1.6700],
        [-2.0853, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20073626935482025
Epoch 0, Step 3066: train/loss = 0.6810885667800903, train/raw-loss = 0.5984158515930176, train/logprobs = tensor([[-1.3898, -1.9412],
        [-2.0940, -0.7032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16534554958343506
Epoch 0, Step 3067: train/loss = 0.7284637689590454, train/raw-loss = 0.706464409828186, train/logprobs = tensor([[-1.1800, -1.7460],
        [-1.2560, -1.0890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043998610228300095
Epoch 0, Step 3068: train/loss = 0.6944515705108643, train/raw-loss = 0.6928188800811768, train/logprobs = tensor([[-1.2649, -1.2451],
        [-1.7568, -1.5867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0032654476817697287
Epoch 0, Step 3069: train/loss = 0.7013329863548279, train/raw-loss = 0.6478271484375, train/logprobs = tensor([[-0.8853, -1.2315],
        [-1.9560, -1.1581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10701161623001099
Epoch 0, Step 3070: train/loss = 0.7184239029884338, train/raw-loss = 0.684420108795166, train/logprobs = tensor([[-1.3175, -1.4853],
        [-1.9598, -1.0427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06800753623247147
Epoch 0, Step 3071: train/loss = 0.7111024856567383, train/raw-loss = 0.6906746029853821, train/logprobs = tensor([[-0.9610, -1.5983],
        [-2.0323, -2.0039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040855880826711655
Epoch 0, Step 3072: train/loss = 0.6969349384307861, train/raw-loss = 0.6890318989753723, train/logprobs = tensor([[-1.1702, -1.3074],
        [-1.5632, -1.1917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015806131064891815
Epoch 0, Step 3073: train/loss = 0.7240375280380249, train/raw-loss = 0.716549813747406, train/logprobs = tensor([[-1.4820, -1.4035],
        [-1.5688, -1.1975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014975475147366524
Epoch 0, Step 3074: train/loss = 0.6879221200942993, train/raw-loss = 0.6525626182556152, train/logprobs = tensor([[-1.2932, -1.7183],
        [-1.4784, -0.8336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07071900367736816
Epoch 0, Step 3075: train/loss = 0.7122283577919006, train/raw-loss = 0.6609335541725159, train/logprobs = tensor([[-1.2364, -1.9354],
        [-2.0919, -1.4330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10258956253528595
Epoch 0, Step 3076: train/loss = 0.692380964756012, train/raw-loss = 0.6022440195083618, train/logprobs = tensor([[-1.0560, -1.6074],
        [-1.6603, -0.7751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1802738606929779
Epoch 0, Step 3077: train/loss = 0.689180314540863, train/raw-loss = 0.6726112365722656, train/logprobs = tensor([[-1.1383, -1.5058],
        [-1.2364, -1.0010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03313816338777542
Epoch 0, Step 3078: train/loss = 0.6755619645118713, train/raw-loss = 0.6214845180511475, train/logprobs = tensor([[-1.1296, -1.8660],
        [-1.8321, -1.3054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10815485566854477
Epoch 0, Step 3079: train/loss = 0.6925363540649414, train/raw-loss = 0.6668041944503784, train/logprobs = tensor([[-1.0650, -1.2945],
        [-1.5918, -1.3097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05146433413028717
Epoch 0, Step 3080: train/loss = 0.6922163963317871, train/raw-loss = 0.6886617541313171, train/logprobs = tensor([[-1.4715, -1.6144],
        [-1.3779, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007109290920197964
Epoch 0, Step 3081: train/loss = 0.6930864453315735, train/raw-loss = 0.6629814505577087, train/logprobs = tensor([[-1.2549, -1.4982],
        [-1.7102, -1.2659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0602099746465683
Epoch 0, Step 3082: train/loss = 0.6992055773735046, train/raw-loss = 0.6482890844345093, train/logprobs = tensor([[-1.7950, -2.4504],
        [-1.7571, -1.0960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10183302313089371
Epoch 0, Step 3083: train/loss = 0.6886287331581116, train/raw-loss = 0.6621838808059692, train/logprobs = tensor([[-1.1431, -1.6809],
        [-1.6221, -1.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05288982391357422
Epoch 0, Step 3084: train/loss = 0.6910914778709412, train/raw-loss = 0.6545966863632202, train/logprobs = tensor([[-1.1581, -1.5883],
        [-2.0064, -1.3791]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0729893371462822
Epoch 0, Step 3085: train/loss = 0.6912741661071777, train/raw-loss = 0.6801437139511108, train/logprobs = tensor([[-1.1964, -1.4839],
        [-1.2977, -1.0544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02226080372929573
Epoch 0, Step 3086: train/loss = 0.684759795665741, train/raw-loss = 0.6264285445213318, train/logprobs = tensor([[-1.1280, -1.7083],
        [-2.0571, -1.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11666261404752731
Epoch 0, Step 3087: train/loss = 0.6890653967857361, train/raw-loss = 0.6652557849884033, train/logprobs = tensor([[-1.2937, -1.4272],
        [-1.6879, -1.4970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047619227319955826
Epoch 0, Step 3088: train/loss = 0.7100363373756409, train/raw-loss = 0.6977310180664062, train/logprobs = tensor([[-1.0887, -1.3878],
        [-2.0111, -1.6926]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024610746651887894
Epoch 0, Step 3089: train/loss = 0.6896141767501831, train/raw-loss = 0.6705285906791687, train/logprobs = tensor([[-1.0185, -1.1630],
        [-1.3665, -1.1011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03817122429609299
Epoch 0, Step 3090: train/loss = 0.6886229515075684, train/raw-loss = 0.6513752937316895, train/logprobs = tensor([[-1.2987, -1.7176],
        [-1.9350, -1.2519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07449530065059662
Epoch 0, Step 3091: train/loss = 0.7001780271530151, train/raw-loss = 0.637252688407898, train/logprobs = tensor([[-1.1962, -1.7712],
        [-1.7280, -1.0976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12585079669952393
Epoch 0, Step 3092: train/loss = 0.7134945392608643, train/raw-loss = 0.655962347984314, train/logprobs = tensor([[-1.0480, -1.2591],
        [-1.8180, -0.9906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11506445705890656
Epoch 0, Step 3093: train/loss = 0.6892942190170288, train/raw-loss = 0.6245774626731873, train/logprobs = tensor([[-1.0070, -1.8003],
        [-1.8138, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1294335275888443
Epoch 0, Step 3094: train/loss = 0.6948729753494263, train/raw-loss = 0.6909281015396118, train/logprobs = tensor([[-1.4272, -1.6231],
        [-1.6653, -1.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00788978859782219
Epoch 0, Step 3095: train/loss = 0.6795961856842041, train/raw-loss = 0.6440303325653076, train/logprobs = tensor([[-1.0912, -1.5178],
        [-1.6772, -0.9688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07113169878721237
Epoch 0, Step 3096: train/loss = 0.6929956674575806, train/raw-loss = 0.6412091255187988, train/logprobs = tensor([[-1.1120, -1.8716],
        [-1.8132, -1.2273]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10357304662466049
Epoch 0, Step 3097: train/loss = 0.6938667297363281, train/raw-loss = 0.6932395696640015, train/logprobs = tensor([[-1.0503, -1.0593],
        [-1.4168, -1.4527]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012542889453470707
Epoch 0, Step 3098: train/loss = 0.687548041343689, train/raw-loss = 0.6449671983718872, train/logprobs = tensor([[-0.9512, -1.4748],
        [-1.6706, -1.5030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08516158163547516
Epoch 0, Step 3099: train/loss = 0.6924912929534912, train/raw-loss = 0.6274693608283997, train/logprobs = tensor([[-1.2033, -1.7535],
        [-1.9229, -0.9817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13004383444786072
Epoch 0, Step 3100: train/loss = 0.6903975009918213, train/raw-loss = 0.6332314610481262, train/logprobs = tensor([[-1.1541, -1.8104],
        [-1.8494, -1.2224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11433221399784088
Epoch 0, Step 3101: train/loss = 0.6923746466636658, train/raw-loss = 0.668828010559082, train/logprobs = tensor([[-1.0624, -1.3460],
        [-1.9936, -1.2837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04709331691265106
Epoch 0, Step 3102: train/loss = 0.7026222348213196, train/raw-loss = 0.6687660217285156, train/logprobs = tensor([[-1.2816, -1.4067],
        [-1.8417, -1.2878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06771229952573776
Epoch 0, Step 3103: train/loss = 0.7113710045814514, train/raw-loss = 0.6957474946975708, train/logprobs = tensor([[-1.1376, -1.7438],
        [-1.3451, -1.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03124704584479332
Epoch 0, Step 3104: train/loss = 0.6947411298751831, train/raw-loss = 0.6680104732513428, train/logprobs = tensor([[-1.1235, -1.2337],
        [-1.7484, -1.2389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05346129462122917
Epoch 0, Step 3105: train/loss = 0.7017821073532104, train/raw-loss = 0.6482280492782593, train/logprobs = tensor([[-1.1838, -1.8289],
        [-1.7695, -1.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1071082204580307
Epoch 0, Step 3106: train/loss = 0.6943848133087158, train/raw-loss = 0.6250442266464233, train/logprobs = tensor([[-0.9959, -1.5273],
        [-2.0369, -1.0864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1386810839176178
Epoch 0, Step 3107: train/loss = 0.6912804841995239, train/raw-loss = 0.66106778383255, train/logprobs = tensor([[-1.2763, -1.5415],
        [-1.8148, -1.1649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06042541563510895
Epoch 0, Step 3108: train/loss = 0.6725246906280518, train/raw-loss = 0.5971633195877075, train/logprobs = tensor([[-1.0446, -1.8851],
        [-2.0896, -1.5088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15072286128997803
Epoch 0, Step 3109: train/loss = 0.6985141038894653, train/raw-loss = 0.6627898216247559, train/logprobs = tensor([[-1.2953, -1.5394],
        [-2.0900, -1.5843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0714484304189682
Epoch 0, Step 3110: train/loss = 0.6891959309577942, train/raw-loss = 0.6532831192016602, train/logprobs = tensor([[-1.2947, -1.4650],
        [-2.1426, -1.3405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0718255341053009
Epoch 0, Step 3111: train/loss = 0.6948986649513245, train/raw-loss = 0.6030892729759216, train/logprobs = tensor([[-1.3567, -1.8204],
        [-2.0437, -1.2650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1836187094449997
Epoch 0, Step 3112: train/loss = 0.6919463276863098, train/raw-loss = 0.6813291311264038, train/logprobs = tensor([[-1.2321, -1.5413],
        [-1.5013, -1.3226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021234434098005295
Epoch 0, Step 3113: train/loss = 0.69612717628479, train/raw-loss = 0.695561408996582, train/logprobs = tensor([[-1.0565, -1.1420],
        [-0.9981, -0.9733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011314328294247389
Epoch 0, Step 3114: train/loss = 0.6918715238571167, train/raw-loss = 0.673652172088623, train/logprobs = tensor([[-1.3949, -1.7727],
        [-1.6531, -1.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03643875569105148
Epoch 0, Step 3115: train/loss = 0.6908406019210815, train/raw-loss = 0.6105835437774658, train/logprobs = tensor([[-1.1449, -1.9538],
        [-2.1405, -1.2311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1605139523744583
Epoch 0, Step 3116: train/loss = 0.6975117921829224, train/raw-loss = 0.6457740664482117, train/logprobs = tensor([[-1.2549, -1.6293],
        [-1.3449, -0.8220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10347538441419601
Epoch 0, Step 3117: train/loss = 0.6937601566314697, train/raw-loss = 0.673286497592926, train/logprobs = tensor([[-1.2244, -1.3743],
        [-1.4451, -1.1129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04094746336340904
Epoch 0, Step 3118: train/loss = 0.692383885383606, train/raw-loss = 0.6523710489273071, train/logprobs = tensor([[-1.2488, -1.5086],
        [-1.4918, -1.1804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08002560585737228
Epoch 0, Step 3119: train/loss = 0.6902527809143066, train/raw-loss = 0.6505864858627319, train/logprobs = tensor([[-1.4838, -1.8803],
        [-1.7852, -1.1733]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07933254539966583
Epoch 0, Step 3120: train/loss = 0.70393306016922, train/raw-loss = 0.6385296583175659, train/logprobs = tensor([[-1.0447, -1.7903],
        [-1.8329, -1.6069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13080669939517975
Epoch 0, Step 3121: train/loss = 0.6797525882720947, train/raw-loss = 0.6498355865478516, train/logprobs = tensor([[-1.0328, -1.2697],
        [-1.7897, -1.3288]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05983402952551842
Epoch 0, Step 3122: train/loss = 0.6940732002258301, train/raw-loss = 0.6886440515518188, train/logprobs = tensor([[-1.1826, -1.2347],
        [-1.5771, -1.4877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010858166962862015
Epoch 0, Step 3123: train/loss = 0.6916487216949463, train/raw-loss = 0.6669908761978149, train/logprobs = tensor([[-1.1152, -1.4854],
        [-1.6651, -1.1928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04931570589542389
Epoch 0, Step 3124: train/loss = 0.7036594748497009, train/raw-loss = 0.6308947205543518, train/logprobs = tensor([[-1.0866, -1.6966],
        [-1.7293, -0.8283]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14552952349185944
Epoch 0, Step 3125: train/loss = 0.6973376870155334, train/raw-loss = 0.6621618270874023, train/logprobs = tensor([[-1.1710, -1.6408],
        [-1.2208, -1.1226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07035175710916519
Epoch 0, Step 3126: train/loss = 0.6988771557807922, train/raw-loss = 0.673778235912323, train/logprobs = tensor([[-1.6288, -1.9139],
        [-1.5503, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050197891891002655
Epoch 0, Step 3127: train/loss = 0.7275915741920471, train/raw-loss = 0.7016233205795288, train/logprobs = tensor([[-1.2791, -1.3054],
        [-1.6432, -1.4209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05193633586168289
Epoch 0, Step 3128: train/loss = 0.6995143890380859, train/raw-loss = 0.668806254863739, train/logprobs = tensor([[-1.4852, -2.0244],
        [-1.4923, -1.4809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061416395008563995
Epoch 0, Step 3129: train/loss = 0.6875301599502563, train/raw-loss = 0.6690091490745544, train/logprobs = tensor([[-1.2862, -1.4841],
        [-1.6712, -1.3854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03704208880662918
Epoch 0, Step 3130: train/loss = 0.7065619230270386, train/raw-loss = 0.6776089072227478, train/logprobs = tensor([[-1.1584, -1.4188],
        [-1.9407, -1.3440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05790598690509796
Epoch 0, Step 3131: train/loss = 0.7426488399505615, train/raw-loss = 0.6513895392417908, train/logprobs = tensor([[-1.2175, -1.5159],
        [-2.4054, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1825185865163803
Epoch 0, Step 3132: train/loss = 0.7000197172164917, train/raw-loss = 0.6864009499549866, train/logprobs = tensor([[-1.3103, -1.3456],
        [-1.5795, -1.1660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027237482368946075
Epoch 0, Step 3133: train/loss = 0.690255343914032, train/raw-loss = 0.6703248620033264, train/logprobs = tensor([[-0.9343, -1.1000],
        [-1.6681, -1.5200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03986099734902382
Epoch 0, Step 3134: train/loss = 0.6987365484237671, train/raw-loss = 0.673384428024292, train/logprobs = tensor([[-1.3454, -1.5017],
        [-1.7257, -1.4843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05070424824953079
Epoch 0, Step 3135: train/loss = 0.685748815536499, train/raw-loss = 0.5835030674934387, train/logprobs = tensor([[-1.0695, -1.7728],
        [-2.2847, -1.1162]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20449164509773254
Epoch 0, Step 3136: train/loss = 0.6303032040596008, train/raw-loss = 0.5774605870246887, train/logprobs = tensor([[-1.1095, -1.8015],
        [-2.8362, -1.4792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1056852638721466
Epoch 0, Step 3137: train/loss = 0.679772138595581, train/raw-loss = 0.6455278396606445, train/logprobs = tensor([[-0.9898, -1.2308],
        [-1.8768, -0.9186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06848859041929245
Epoch 0, Step 3138: train/loss = 0.7075820565223694, train/raw-loss = 0.6327539682388306, train/logprobs = tensor([[-1.1554, -1.5623],
        [-1.9953, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14965614676475525
Epoch 0, Step 3139: train/loss = 0.7070001363754272, train/raw-loss = 0.7050070762634277, train/logprobs = tensor([[-1.4565, -1.3828],
        [-1.6657, -1.3949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003986193332821131
Epoch 0, Step 3140: train/loss = 0.6921976804733276, train/raw-loss = 0.6452658176422119, train/logprobs = tensor([[-1.1635, -1.4647],
        [-1.9134, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09386363625526428
Epoch 0, Step 3141: train/loss = 0.7188425064086914, train/raw-loss = 0.6891524195671082, train/logprobs = tensor([[-0.9812, -1.0340],
        [-1.8376, -1.2289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05938008427619934
Epoch 0, Step 3142: train/loss = 0.6865736246109009, train/raw-loss = 0.6722068786621094, train/logprobs = tensor([[-1.1790, -1.4823],
        [-1.3701, -1.3530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028733406215906143
Epoch 0, Step 3143: train/loss = 0.688541054725647, train/raw-loss = 0.6503560543060303, train/logprobs = tensor([[-1.2920, -1.6266],
        [-1.8030, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07636991143226624
Epoch 0, Step 3144: train/loss = 0.7140355110168457, train/raw-loss = 0.7029680013656616, train/logprobs = tensor([[-1.4688, -1.4290],
        [-1.5732, -1.1950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02213502861559391
Epoch 0, Step 3145: train/loss = 0.6912445425987244, train/raw-loss = 0.6757164001464844, train/logprobs = tensor([[-1.0553, -1.2653],
        [-1.2783, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031056255102157593
Epoch 0, Step 3146: train/loss = 0.6617734432220459, train/raw-loss = 0.6007298231124878, train/logprobs = tensor([[-0.8924, -1.5675],
        [-2.1785, -1.1589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12208731472492218
Epoch 0, Step 3147: train/loss = 0.674401044845581, train/raw-loss = 0.6330857276916504, train/logprobs = tensor([[-1.2979, -1.6000],
        [-1.9298, -1.1939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08263064920902252
Epoch 0, Step 3148: train/loss = 0.7095723152160645, train/raw-loss = 0.6876919865608215, train/logprobs = tensor([[-1.2761, -1.1027],
        [-1.6908, -1.1661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043760716915130615
Epoch 0, Step 3149: train/loss = 0.694754958152771, train/raw-loss = 0.5764650702476501, train/logprobs = tensor([[-1.0514, -2.0411],
        [-2.2423, -1.0398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2365797758102417
Epoch 0, Step 3150: train/loss = 0.6987067461013794, train/raw-loss = 0.6943079233169556, train/logprobs = tensor([[-1.3330, -1.5234],
        [-1.2689, -1.0567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008797544054687023
Epoch 0, Step 3151: train/loss = 0.6883779764175415, train/raw-loss = 0.6359578967094421, train/logprobs = tensor([[-1.6506, -1.9879],
        [-1.8765, -0.9460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10484017431735992
Epoch 0, Step 3152: train/loss = 0.7106941938400269, train/raw-loss = 0.6792600154876709, train/logprobs = tensor([[-1.4579, -1.6261],
        [-1.6694, -1.6253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0628684014081955
Epoch 0, Step 3153: train/loss = 0.6753985285758972, train/raw-loss = 0.5591197609901428, train/logprobs = tensor([[-1.1619, -2.2243],
        [-2.2328, -1.0377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23255746066570282
Epoch 0, Step 3154: train/loss = 0.6940365433692932, train/raw-loss = 0.65899658203125, train/logprobs = tensor([[-1.2055, -1.5743],
        [-1.7924, -1.4184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07007990777492523
Epoch 0, Step 3155: train/loss = 0.7064415216445923, train/raw-loss = 0.6881474256515503, train/logprobs = tensor([[-1.2329, -1.5458],
        [-1.4125, -0.9659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036588218063116074
Epoch 0, Step 3156: train/loss = 0.7024053931236267, train/raw-loss = 0.6967056393623352, train/logprobs = tensor([[-1.2389, -1.5597],
        [-1.6418, -1.6846]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01139945536851883
Epoch 0, Step 3157: train/loss = 0.6924540996551514, train/raw-loss = 0.66204833984375, train/logprobs = tensor([[-1.1172, -1.3586],
        [-2.0478, -1.3897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06081152707338333
Epoch 0, Step 3158: train/loss = 0.7019897103309631, train/raw-loss = 0.6798108816146851, train/logprobs = tensor([[-1.2888, -1.3924],
        [-1.8965, -1.3047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04435756802558899
Epoch 0, Step 3159: train/loss = 0.6971869468688965, train/raw-loss = 0.648415207862854, train/logprobs = tensor([[-0.9210, -1.5133],
        [-1.6548, -1.1050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09754355996847153
Epoch 0, Step 3160: train/loss = 0.6791244745254517, train/raw-loss = 0.6188568472862244, train/logprobs = tensor([[-1.0223, -1.5373],
        [-2.1102, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12053518742322922
Epoch 0, Step 3161: train/loss = 0.6873665452003479, train/raw-loss = 0.6355993151664734, train/logprobs = tensor([[-1.3040, -1.4823],
        [-1.7824, -1.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10353438556194305
Epoch 0, Step 3162: train/loss = 0.686536431312561, train/raw-loss = 0.6637871265411377, train/logprobs = tensor([[-1.1616, -1.4293],
        [-1.6281, -1.0360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04549870640039444
Epoch 0, Step 3163: train/loss = 0.6976414918899536, train/raw-loss = 0.629240870475769, train/logprobs = tensor([[-1.1341, -1.8097],
        [-2.1693, -1.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13680122792720795
Epoch 0, Step 3164: train/loss = 0.6612305641174316, train/raw-loss = 0.5585677623748779, train/logprobs = tensor([[-1.1748, -2.2932],
        [-2.1502, -1.0767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2053256332874298
Epoch 0, Step 3165: train/loss = 0.6861153244972229, train/raw-loss = 0.6272876262664795, train/logprobs = tensor([[-1.0816, -1.6090],
        [-1.7886, -1.1039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1176554411649704
Epoch 0, Step 3166: train/loss = 0.6891627907752991, train/raw-loss = 0.6466919779777527, train/logprobs = tensor([[-0.9349, -1.2496],
        [-1.2614, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08494160324335098
Epoch 0, Step 3167: train/loss = 0.6958072185516357, train/raw-loss = 0.6909216642379761, train/logprobs = tensor([[-1.1826, -1.2457],
        [-1.5740, -1.7067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009771023876965046
Epoch 0, Step 3168: train/loss = 0.691831648349762, train/raw-loss = 0.6611396670341492, train/logprobs = tensor([[-1.2228, -1.4666],
        [-2.0183, -1.7948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.061383962631225586
Epoch 0, Step 3169: train/loss = 0.7022919654846191, train/raw-loss = 0.6632037162780762, train/logprobs = tensor([[-1.0402, -1.2434],
        [-1.8367, -1.2951]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07817648351192474
Epoch 0, Step 3170: train/loss = 0.6945630311965942, train/raw-loss = 0.6541167497634888, train/logprobs = tensor([[-1.1506, -1.5953],
        [-1.8796, -1.0553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08089257776737213
Epoch 0, Step 3171: train/loss = 0.6988748908042908, train/raw-loss = 0.5926792621612549, train/logprobs = tensor([[-1.4513, -1.8831],
        [-2.1780, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21239127218723297
Epoch 0, Step 3172: train/loss = 0.7232624292373657, train/raw-loss = 0.7159271240234375, train/logprobs = tensor([[-1.1651, -1.5360],
        [-1.7694, -1.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.014670677483081818
Epoch 0, Step 3173: train/loss = 0.6977163553237915, train/raw-loss = 0.6445865631103516, train/logprobs = tensor([[-1.0511, -1.5617],
        [-1.3521, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10625956207513809
Epoch 0, Step 3174: train/loss = 0.698110044002533, train/raw-loss = 0.6707292795181274, train/logprobs = tensor([[-1.1843, -1.4825],
        [-1.7340, -1.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05476156249642372
Epoch 0, Step 3175: train/loss = 0.6892061233520508, train/raw-loss = 0.6530040502548218, train/logprobs = tensor([[-1.2125, -1.6017],
        [-1.7243, -1.2377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0724041759967804
Epoch 0, Step 3176: train/loss = 0.6904882192611694, train/raw-loss = 0.6300710439682007, train/logprobs = tensor([[-0.9550, -1.7768],
        [-1.3552, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1208343654870987
Epoch 0, Step 3177: train/loss = 0.6990519165992737, train/raw-loss = 0.6251547336578369, train/logprobs = tensor([[-1.0424, -1.4877],
        [-2.2922, -1.2679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1477942019701004
Epoch 0, Step 3178: train/loss = 0.7001652717590332, train/raw-loss = 0.612011730670929, train/logprobs = tensor([[-0.9247, -1.5854],
        [-2.1755, -1.7970]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17630717158317566
Epoch 0, Step 3179: train/loss = 0.6975628137588501, train/raw-loss = 0.6918898224830627, train/logprobs = tensor([[-1.6237, -1.5019],
        [-1.1088, -0.9402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011346058920025826
Epoch 0, Step 3180: train/loss = 0.6954531073570251, train/raw-loss = 0.6877375841140747, train/logprobs = tensor([[-1.2217, -1.3544],
        [-1.6236, -1.3000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.015431026928126812
Epoch 0, Step 3181: train/loss = 0.6842859983444214, train/raw-loss = 0.6342593431472778, train/logprobs = tensor([[-1.0384, -1.4039],
        [-1.5460, -1.0596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1000533252954483
Epoch 0, Step 3182: train/loss = 0.6952905654907227, train/raw-loss = 0.693488359451294, train/logprobs = tensor([[-0.9939, -0.9786],
        [-1.3310, -1.3934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003604375058785081
Epoch 0, Step 3183: train/loss = 0.6944023370742798, train/raw-loss = 0.6892580986022949, train/logprobs = tensor([[-1.1618, -1.2915],
        [-1.6508, -1.2812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010288489051163197
Epoch 0, Step 3184: train/loss = 0.739302396774292, train/raw-loss = 0.6807852983474731, train/logprobs = tensor([[-1.4106, -1.6619],
        [-2.1551, -1.0727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11703408509492874
Epoch 0, Step 3185: train/loss = 0.7171118855476379, train/raw-loss = 0.607092559337616, train/logprobs = tensor([[-1.1736, -1.5848],
        [-2.3243, -0.8053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22003868222236633
Epoch 0, Step 3186: train/loss = 0.6626468896865845, train/raw-loss = 0.5770015120506287, train/logprobs = tensor([[-1.4820, -2.3716],
        [-1.7004, -1.0036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17129084467887878
Epoch 0, Step 3187: train/loss = 0.7099667191505432, train/raw-loss = 0.6774160861968994, train/logprobs = tensor([[-1.3316, -1.6005],
        [-1.6928, -1.0307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06510117650032043
Epoch 0, Step 3188: train/loss = 0.6853241324424744, train/raw-loss = 0.6580587029457092, train/logprobs = tensor([[-1.3941, -1.5606],
        [-1.3480, -0.7345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05453089252114296
Epoch 0, Step 3189: train/loss = 0.7022910714149475, train/raw-loss = 0.6432019472122192, train/logprobs = tensor([[-1.3611, -1.6446],
        [-2.2734, -1.4704]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11817820370197296
Epoch 0, Step 3190: train/loss = 0.6920189261436462, train/raw-loss = 0.6768370866775513, train/logprobs = tensor([[-1.2008, -1.4317],
        [-2.1384, -1.8903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030363593250513077
Epoch 0, Step 3191: train/loss = 0.7031501531600952, train/raw-loss = 0.6301130652427673, train/logprobs = tensor([[-1.0627, -1.6941],
        [-2.1512, -1.1277]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1460742950439453
Epoch 0, Step 3192: train/loss = 0.6860141754150391, train/raw-loss = 0.6400320529937744, train/logprobs = tensor([[-1.5909, -1.9366],
        [-1.6062, -0.9627]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09196421504020691
Epoch 0, Step 3193: train/loss = 0.696535050868988, train/raw-loss = 0.6640548706054688, train/logprobs = tensor([[-1.5659, -1.7610],
        [-1.6508, -1.1794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06496048718690872
Epoch 0, Step 3194: train/loss = 0.6945728063583374, train/raw-loss = 0.6429218649864197, train/logprobs = tensor([[-1.5058, -2.0639],
        [-1.6236, -1.1025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10330183804035187
Epoch 0, Step 3195: train/loss = 0.7077287435531616, train/raw-loss = 0.7070550918579102, train/logprobs = tensor([[-1.3430, -1.2533],
        [-1.4910, -1.3293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013473358703777194
Epoch 0, Step 3196: train/loss = 0.6974177360534668, train/raw-loss = 0.6816892623901367, train/logprobs = tensor([[-1.0034, -1.1357],
        [-1.7867, -1.5363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03145705163478851
Epoch 0, Step 3197: train/loss = 0.6451501846313477, train/raw-loss = 0.5746712684631348, train/logprobs = tensor([[-1.0867, -1.8760],
        [-2.1397, -0.9900]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14095792174339294
Epoch 0, Step 3198: train/loss = 0.693169116973877, train/raw-loss = 0.6908583641052246, train/logprobs = tensor([[-0.9654, -1.0313],
        [-1.4719, -1.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004621448460966349
Epoch 0, Step 3199: train/loss = 0.6766121983528137, train/raw-loss = 0.5049077272415161, train/logprobs = tensor([[-1.1445, -2.5566],
        [-2.3837, -1.0350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.34340888261795044
Epoch 0, Step 3200: train/loss = 0.6936659812927246, train/raw-loss = 0.6685863733291626, train/logprobs = tensor([[-1.2764, -1.5327],
        [-1.5687, -1.3306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050159282982349396
Epoch 0, Step 3201: train/loss = 0.680932343006134, train/raw-loss = 0.5935765504837036, train/logprobs = tensor([[-0.8652, -1.7140],
        [-2.2409, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1747114658355713
Epoch 0, Step 3202: train/loss = 0.6892650723457336, train/raw-loss = 0.6319160461425781, train/logprobs = tensor([[-1.0780, -1.5354],
        [-2.0400, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11469801515340805
Epoch 0, Step 3203: train/loss = 0.6869933605194092, train/raw-loss = 0.611382782459259, train/logprobs = tensor([[-1.0495, -1.6990],
        [-2.0906, -1.4996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1512211263179779
Epoch 0, Step 3204: train/loss = 0.7048628330230713, train/raw-loss = 0.6101268529891968, train/logprobs = tensor([[-1.4390, -2.0600],
        [-2.3672, -1.2263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18947196006774902
Epoch 0, Step 3205: train/loss = 0.7008588314056396, train/raw-loss = 0.6711859703063965, train/logprobs = tensor([[-1.2195, -1.4211],
        [-1.6169, -1.2139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0593457892537117
Epoch 0, Step 3206: train/loss = 0.6936384439468384, train/raw-loss = 0.6746976375579834, train/logprobs = tensor([[-1.1065, -1.4432],
        [-1.2056, -0.9381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03788146376609802
Epoch 0, Step 3207: train/loss = 0.687240719795227, train/raw-loss = 0.6181260347366333, train/logprobs = tensor([[-1.3489, -2.1204],
        [-1.7778, -0.8388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13822944462299347
Epoch 0, Step 3208: train/loss = 0.6868454813957214, train/raw-loss = 0.6592435240745544, train/logprobs = tensor([[-1.7369, -1.9385],
        [-1.5692, -1.4232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05520385131239891
Epoch 0, Step 3209: train/loss = 0.6940739154815674, train/raw-loss = 0.680191159248352, train/logprobs = tensor([[-1.3427, -1.3495],
        [-2.1181, -1.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02776530012488365
Epoch 0, Step 3210: train/loss = 0.6939915418624878, train/raw-loss = 0.6817920804023743, train/logprobs = tensor([[-1.2291, -1.3791],
        [-1.4590, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02439897134900093
Epoch 0, Step 3211: train/loss = 0.7012398838996887, train/raw-loss = 0.6857504844665527, train/logprobs = tensor([[-1.3120, -1.2900],
        [-1.8191, -1.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03097880259156227
Epoch 0, Step 3212: train/loss = 0.6966961622238159, train/raw-loss = 0.6850051879882812, train/logprobs = tensor([[-1.2435, -1.2844],
        [-1.5730, -1.2436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023381877690553665
Epoch 0, Step 3213: train/loss = 0.6932653784751892, train/raw-loss = 0.6601846814155579, train/logprobs = tensor([[-1.1687, -1.4432],
        [-2.0606, -1.5851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06616126745939255
Epoch 0, Step 3214: train/loss = 0.7012478113174438, train/raw-loss = 0.687232494354248, train/logprobs = tensor([[-1.2525, -1.7114],
        [-1.3692, -1.2737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028030578047037125
Epoch 0, Step 3215: train/loss = 0.695458710193634, train/raw-loss = 0.6228169202804565, train/logprobs = tensor([[-1.2847, -1.8882],
        [-1.7137, -0.8699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14528346061706543
Epoch 0, Step 3216: train/loss = 0.6975484490394592, train/raw-loss = 0.6931444406509399, train/logprobs = tensor([[-1.0758, -1.2270],
        [-2.0152, -1.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00880811270326376
Epoch 0, Step 3217: train/loss = 0.7019188404083252, train/raw-loss = 0.6949682235717773, train/logprobs = tensor([[-0.9784, -1.3449],
        [-1.6091, -1.7019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01390131190419197
Epoch 0, Step 3218: train/loss = 0.6969699263572693, train/raw-loss = 0.6591961979866028, train/logprobs = tensor([[-1.1815, -1.5905],
        [-1.9680, -1.2789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07554738968610764
Epoch 0, Step 3219: train/loss = 0.7350238561630249, train/raw-loss = 0.7189972400665283, train/logprobs = tensor([[-1.3634, -1.4319],
        [-1.7856, -1.3113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032053202390670776
Epoch 0, Step 3220: train/loss = 0.6976227760314941, train/raw-loss = 0.6641809940338135, train/logprobs = tensor([[-1.1515, -1.4014],
        [-1.8296, -1.3447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06688353419303894
Epoch 0, Step 3221: train/loss = 0.6719274520874023, train/raw-loss = 0.5937040448188782, train/logprobs = tensor([[-1.1805, -2.0636],
        [-2.1705, -1.2127]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15644681453704834
Epoch 0, Step 3222: train/loss = 0.6784772872924805, train/raw-loss = 0.6127725839614868, train/logprobs = tensor([[-1.1554, -1.6725],
        [-2.0325, -1.4892]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13140936195850372
Epoch 0, Step 3223: train/loss = 0.6913185715675354, train/raw-loss = 0.6855237483978271, train/logprobs = tensor([[-1.2435, -1.4492],
        [-1.1839, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.011589787900447845
Epoch 0, Step 3224: train/loss = 0.6856497526168823, train/raw-loss = 0.6169220209121704, train/logprobs = tensor([[-1.1209, -1.7892],
        [-2.1220, -1.9106]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13745549321174622
Epoch 0, Step 3225: train/loss = 0.6763783693313599, train/raw-loss = 0.6067523956298828, train/logprobs = tensor([[-1.1236, -1.8444],
        [-1.8910, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13925179839134216
Epoch 0, Step 3226: train/loss = 0.6870716214179993, train/raw-loss = 0.6356008052825928, train/logprobs = tensor([[-1.3030, -1.8800],
        [-1.9241, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10294174402952194
Epoch 0, Step 3227: train/loss = 0.6784583926200867, train/raw-loss = 0.6007717251777649, train/logprobs = tensor([[-1.2706, -2.2942],
        [-1.6874, -1.0367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15537331998348236
Epoch 0, Step 3228: train/loss = 0.7098829746246338, train/raw-loss = 0.6415480375289917, train/logprobs = tensor([[-1.1738, -1.5034],
        [-2.2171, -0.9035]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1366698145866394
Epoch 0, Step 3229: train/loss = 0.6982298493385315, train/raw-loss = 0.6679643988609314, train/logprobs = tensor([[-1.2226, -1.6654],
        [-1.4896, -1.0167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060530904680490494
Epoch 0, Step 3230: train/loss = 0.6744146347045898, train/raw-loss = 0.5981164574623108, train/logprobs = tensor([[-0.9834, -1.6332],
        [-1.7228, -1.1223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1525963842868805
Epoch 0, Step 3231: train/loss = 0.6733909845352173, train/raw-loss = 0.575980544090271, train/logprobs = tensor([[-0.9904, -1.8409],
        [-1.8974, -0.8163]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19482088088989258
Epoch 0, Step 3232: train/loss = 0.6923119425773621, train/raw-loss = 0.6600000262260437, train/logprobs = tensor([[-1.0906, -1.3919],
        [-1.7426, -1.3321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0646238625049591
Epoch 0, Step 3233: train/loss = 0.6876364946365356, train/raw-loss = 0.6316931843757629, train/logprobs = tensor([[-1.0169, -1.6211],
        [-1.5001, -1.0306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11188656091690063
Epoch 0, Step 3234: train/loss = 0.6908038258552551, train/raw-loss = 0.6566425561904907, train/logprobs = tensor([[-1.2169, -1.7335],
        [-1.3625, -0.9292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0683225691318512
Epoch 0, Step 3235: train/loss = 0.7159279584884644, train/raw-loss = 0.646927535533905, train/logprobs = tensor([[-1.2661, -1.4336],
        [-1.8373, -1.3517]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13800083100795746
Epoch 0, Step 3236: train/loss = 0.6917585730552673, train/raw-loss = 0.6314630508422852, train/logprobs = tensor([[-1.1966, -1.7385],
        [-1.5899, -0.9547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12059102952480316
Epoch 0, Step 3237: train/loss = 0.7110898494720459, train/raw-loss = 0.6690173149108887, train/logprobs = tensor([[-1.2230, -1.3259],
        [-2.2972, -1.6545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08414516597986221
Epoch 0, Step 3238: train/loss = 0.6919532418251038, train/raw-loss = 0.6476677060127258, train/logprobs = tensor([[-1.3505, -1.5513],
        [-1.5308, -1.4318]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08857106417417526
Epoch 0, Step 3239: train/loss = 0.6715306639671326, train/raw-loss = 0.5896767973899841, train/logprobs = tensor([[-0.9301, -1.5653],
        [-2.2795, -1.1182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16370786726474762
Epoch 0, Step 3240: train/loss = 0.6761280298233032, train/raw-loss = 0.6074125170707703, train/logprobs = tensor([[-1.2432, -1.7676],
        [-2.0986, -1.2290]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1374310404062271
Epoch 0, Step 3241: train/loss = 0.6872982978820801, train/raw-loss = 0.6071243286132812, train/logprobs = tensor([[-1.0895, -1.7515],
        [-2.1639, -1.1662]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1603478342294693
Epoch 0, Step 3242: train/loss = 0.6906415224075317, train/raw-loss = 0.6196902990341187, train/logprobs = tensor([[-1.3321, -1.8719],
        [-1.8555, -1.0255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14190247654914856
Epoch 0, Step 3243: train/loss = 0.6948487758636475, train/raw-loss = 0.647834062576294, train/logprobs = tensor([[-1.7615, -2.0103],
        [-1.8377, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09402944147586823
Epoch 0, Step 3244: train/loss = 0.7012524604797363, train/raw-loss = 0.6886199116706848, train/logprobs = tensor([[-1.0451, -1.0917],
        [-1.7062, -1.3459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025264985859394073
Epoch 0, Step 3245: train/loss = 0.6865938901901245, train/raw-loss = 0.6123596429824829, train/logprobs = tensor([[-1.2801, -1.7544],
        [-2.5125, -1.7438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.148468479514122
Epoch 0, Step 3246: train/loss = 0.6975404620170593, train/raw-loss = 0.6913047432899475, train/logprobs = tensor([[-1.3966, -1.4620],
        [-1.2335, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012471421621739864
Epoch 0, Step 3247: train/loss = 0.6900383234024048, train/raw-loss = 0.638124942779541, train/logprobs = tensor([[-1.1533, -1.6410],
        [-1.5940, -1.0094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10382667183876038
Epoch 0, Step 3248: train/loss = 0.7096906900405884, train/raw-loss = 0.7057991027832031, train/logprobs = tensor([[-1.3975, -1.6075],
        [-1.3119, -1.3520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00778299430385232
Epoch 0, Step 3249: train/loss = 0.6931087970733643, train/raw-loss = 0.6092756390571594, train/logprobs = tensor([[-1.1293, -1.6434],
        [-2.3038, -1.5377]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16766630113124847
Epoch 0, Step 3250: train/loss = 0.6950358152389526, train/raw-loss = 0.6919569969177246, train/logprobs = tensor([[-1.2921, -1.3904],
        [-1.4732, -1.3033]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006157741881906986
Epoch 0, Step 3251: train/loss = 0.6973676681518555, train/raw-loss = 0.6745840907096863, train/logprobs = tensor([[-1.1641, -1.4212],
        [-1.4970, -0.9019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04556730017066002
Epoch 0, Step 3252: train/loss = 0.6847174167633057, train/raw-loss = 0.6755362749099731, train/logprobs = tensor([[-1.4702, -1.7564],
        [-1.5570, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01836226135492325
Epoch 0, Step 3253: train/loss = 0.7202193737030029, train/raw-loss = 0.7080385684967041, train/logprobs = tensor([[-1.1744, -1.5491],
        [-1.2642, -1.1444]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024361636489629745
Epoch 0, Step 3254: train/loss = 0.6890349388122559, train/raw-loss = 0.5888558626174927, train/logprobs = tensor([[-1.2692, -2.0839],
        [-2.0859, -1.0532]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20035818219184875
Epoch 0, Step 3255: train/loss = 0.6884447932243347, train/raw-loss = 0.6854441165924072, train/logprobs = tensor([[-1.3675, -1.5419],
        [-1.5493, -1.3184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0060012806206941605
Epoch 0, Step 3256: train/loss = 0.6903116703033447, train/raw-loss = 0.6602166295051575, train/logprobs = tensor([[-1.3086, -1.3947],
        [-1.5762, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06019018217921257
Epoch 0, Step 3257: train/loss = 0.660988986492157, train/raw-loss = 0.5055580139160156, train/logprobs = tensor([[-1.0352, -2.1834],
        [-2.7796, -1.1561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31086185574531555
Epoch 0, Step 3258: train/loss = 0.6813477277755737, train/raw-loss = 0.6091259717941284, train/logprobs = tensor([[-0.9235, -1.6873],
        [-1.9023, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14444348216056824
Epoch 0, Step 3259: train/loss = 0.6965917944908142, train/raw-loss = 0.6729883551597595, train/logprobs = tensor([[-1.3636, -1.6323],
        [-1.0762, -0.7275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04720689728856087
Epoch 0, Step 3260: train/loss = 0.6927975416183472, train/raw-loss = 0.6508365869522095, train/logprobs = tensor([[-1.5630, -2.1891],
        [-1.5484, -1.2756]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08392190933227539
Epoch 0, Step 3261: train/loss = 0.6792112588882446, train/raw-loss = 0.5949540734291077, train/logprobs = tensor([[-1.0182, -1.8784],
        [-1.8764, -1.1510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16851447522640228
Epoch 0, Step 3262: train/loss = 0.695427417755127, train/raw-loss = 0.6836887001991272, train/logprobs = tensor([[-1.3303, -1.3998],
        [-1.6546, -1.2451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023477530106902122
Epoch 0, Step 3263: train/loss = 0.6551175713539124, train/raw-loss = 0.523810863494873, train/logprobs = tensor([[-0.9589, -2.2788],
        [-2.1002, -1.0896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2626133859157562
Epoch 0, Step 3264: train/loss = 0.6968235969543457, train/raw-loss = 0.6038073897361755, train/logprobs = tensor([[-1.3562, -1.7005],
        [-2.4362, -1.6696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18603242933750153
Epoch 0, Step 3265: train/loss = 0.6853350400924683, train/raw-loss = 0.639211893081665, train/logprobs = tensor([[-1.4380, -1.9265],
        [-1.7035, -1.2358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09224633127450943
Epoch 0, Step 3266: train/loss = 0.6893796920776367, train/raw-loss = 0.6516696810722351, train/logprobs = tensor([[-1.0956, -1.6524],
        [-2.0163, -1.8078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07542004436254501
Epoch 0, Step 3267: train/loss = 0.7179779410362244, train/raw-loss = 0.6677140593528748, train/logprobs = tensor([[-1.6935, -1.8069],
        [-1.9976, -1.3615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10052791237831116
Epoch 0, Step 3268: train/loss = 0.6746361255645752, train/raw-loss = 0.5504677295684814, train/logprobs = tensor([[-1.0620, -2.0466],
        [-2.1895, -1.0625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24833685159683228
Epoch 0, Step 3269: train/loss = 0.6767429113388062, train/raw-loss = 0.5782305002212524, train/logprobs = tensor([[-1.1063, -2.0274],
        [-2.0447, -0.9800]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19702471792697906
Epoch 0, Step 3270: train/loss = 0.6933697462081909, train/raw-loss = 0.6927140951156616, train/logprobs = tensor([[-1.3182, -1.3459],
        [-1.3705, -1.2911]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013113270979374647
Epoch 0, Step 3271: train/loss = 0.7105278968811035, train/raw-loss = 0.6597695350646973, train/logprobs = tensor([[-1.1077, -1.4140],
        [-2.0665, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1015167310833931
Epoch 0, Step 3272: train/loss = 0.6833933591842651, train/raw-loss = 0.6326743960380554, train/logprobs = tensor([[-1.3665, -1.6882],
        [-1.9865, -1.4853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10143795609474182
Epoch 0, Step 3273: train/loss = 0.6484696865081787, train/raw-loss = 0.5904320478439331, train/logprobs = tensor([[-1.0471, -1.9944],
        [-1.6519, -1.0809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11607538163661957
Epoch 0, Step 3274: train/loss = 0.6993808150291443, train/raw-loss = 0.6579814553260803, train/logprobs = tensor([[-1.2109, -1.6786],
        [-1.8898, -1.2940]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08279869705438614
Epoch 0, Step 3275: train/loss = 0.7017379403114319, train/raw-loss = 0.6372702121734619, train/logprobs = tensor([[-1.1531, -1.4752],
        [-2.3548, -1.5187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1289355307817459
Epoch 0, Step 3276: train/loss = 0.6858582496643066, train/raw-loss = 0.5944353342056274, train/logprobs = tensor([[-0.9847, -1.8980],
        [-1.9605, -0.9864]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18284574151039124
Epoch 0, Step 3277: train/loss = 0.6824547052383423, train/raw-loss = 0.5747413039207458, train/logprobs = tensor([[-1.0545, -1.9285],
        [-2.0995, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21542683243751526
Epoch 0, Step 3278: train/loss = 0.6991434097290039, train/raw-loss = 0.6419545412063599, train/logprobs = tensor([[-1.1303, -1.8119],
        [-1.9320, -1.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11437778174877167
Epoch 0, Step 3279: train/loss = 0.6915342807769775, train/raw-loss = 0.6610665321350098, train/logprobs = tensor([[-1.4705, -1.7406],
        [-1.3896, -0.9374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.060935474932193756
Epoch 0, Step 3280: train/loss = 0.701551079750061, train/raw-loss = 0.7004237174987793, train/logprobs = tensor([[-1.5429, -1.4004],
        [-1.5084, -1.4753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022546141408383846
Epoch 0, Step 3281: train/loss = 0.6971794962882996, train/raw-loss = 0.6560134887695312, train/logprobs = tensor([[-1.1190, -1.5476],
        [-1.5670, -0.9361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08233192563056946
Epoch 0, Step 3282: train/loss = 0.6729648113250732, train/raw-loss = 0.5842785835266113, train/logprobs = tensor([[-1.0809, -2.1943],
        [-2.0057, -1.1042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1773722767829895
Epoch 0, Step 3283: train/loss = 0.6952489018440247, train/raw-loss = 0.6613671183586121, train/logprobs = tensor([[-1.3291, -1.6112],
        [-1.5629, -1.0664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06776358932256699
Epoch 0, Step 3284: train/loss = 0.6851495504379272, train/raw-loss = 0.5912449955940247, train/logprobs = tensor([[-1.3912, -2.2436],
        [-2.0801, -1.0635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1878090798854828
Epoch 0, Step 3285: train/loss = 0.6930217146873474, train/raw-loss = 0.6683002710342407, train/logprobs = tensor([[-1.3887, -1.7904],
        [-1.2939, -1.1188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.049442894756793976
Epoch 0, Step 3286: train/loss = 0.6971052289009094, train/raw-loss = 0.6783818006515503, train/logprobs = tensor([[-1.2526, -1.5223],
        [-1.2915, -0.9328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037446893751621246
Epoch 0, Step 3287: train/loss = 0.6762795448303223, train/raw-loss = 0.5867960453033447, train/logprobs = tensor([[-1.2432, -1.9013],
        [-2.1238, -1.3091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17896711826324463
Epoch 0, Step 3288: train/loss = 0.703152060508728, train/raw-loss = 0.6222867965698242, train/logprobs = tensor([[-1.4153, -1.9776],
        [-1.7862, -1.0270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1617305725812912
Epoch 0, Step 3289: train/loss = 0.6744081377983093, train/raw-loss = 0.6198665499687195, train/logprobs = tensor([[-1.3659, -2.1815],
        [-2.0251, -1.1000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1090831384062767
Epoch 0, Step 3290: train/loss = 0.6722323894500732, train/raw-loss = 0.5596433877944946, train/logprobs = tensor([[-0.8890, -1.7893],
        [-2.2753, -0.9550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22517797350883484
Epoch 0, Step 3291: train/loss = 0.6957047581672668, train/raw-loss = 0.6927189826965332, train/logprobs = tensor([[-1.1877, -1.2820],
        [-1.5991, -1.4432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005971628241240978
Epoch 0, Step 3292: train/loss = 0.694267988204956, train/raw-loss = 0.6580535173416138, train/logprobs = tensor([[-1.1990, -1.4851],
        [-1.5417, -1.1374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07242894917726517
Epoch 0, Step 3293: train/loss = 0.693175196647644, train/raw-loss = 0.5938129425048828, train/logprobs = tensor([[-1.0790, -1.7895],
        [-2.0960, -0.9085]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1987244337797165
Epoch 0, Step 3294: train/loss = 0.6905022263526917, train/raw-loss = 0.6660728454589844, train/logprobs = tensor([[-1.2754, -1.4418],
        [-1.7728, -1.3803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04885881394147873
Epoch 0, Step 3295: train/loss = 0.6930859088897705, train/raw-loss = 0.6417896747589111, train/logprobs = tensor([[-1.2566, -1.7275],
        [-1.9202, -1.5490]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1025923639535904
Epoch 0, Step 3296: train/loss = 0.6780036687850952, train/raw-loss = 0.6454264521598816, train/logprobs = tensor([[-1.3159, -1.7727],
        [-1.5664, -1.1615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06515437364578247
Epoch 0, Step 3297: train/loss = 0.7174515128135681, train/raw-loss = 0.6550356149673462, train/logprobs = tensor([[-1.1750, -1.5590],
        [-2.3582, -1.2599]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12483172863721848
Epoch 0, Step 3298: train/loss = 0.6929726600646973, train/raw-loss = 0.6612478494644165, train/logprobs = tensor([[-1.1888, -1.4690],
        [-1.7069, -1.5057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0634496733546257
Epoch 0, Step 3299: train/loss = 0.699342668056488, train/raw-loss = 0.6577438116073608, train/logprobs = tensor([[-1.0719, -1.1758],
        [-1.9633, -1.6405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08319763839244843
Epoch 0, Step 3300: train/loss = 0.6936690807342529, train/raw-loss = 0.6915004253387451, train/logprobs = tensor([[-1.3723, -1.4548],
        [-1.4089, -1.4509]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004337365739047527
Epoch 0, Step 3301: train/loss = 0.7110249996185303, train/raw-loss = 0.6818063259124756, train/logprobs = tensor([[-1.4151, -1.5245],
        [-2.0787, -1.3884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05843731388449669
Epoch 0, Step 3302: train/loss = 0.6831570863723755, train/raw-loss = 0.6231187582015991, train/logprobs = tensor([[-1.5939, -2.0989],
        [-1.4311, -1.0397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12007670104503632
Epoch 0, Step 3303: train/loss = 0.6835646033287048, train/raw-loss = 0.6487956047058105, train/logprobs = tensor([[-1.4758, -1.7285],
        [-1.9033, -1.2064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06953813135623932
Epoch 0, Step 3304: train/loss = 0.6806614995002747, train/raw-loss = 0.6169050931930542, train/logprobs = tensor([[-1.0076, -1.5299],
        [-1.8853, -1.1154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1275128275156021
Epoch 0, Step 3305: train/loss = 0.6796903610229492, train/raw-loss = 0.5805826187133789, train/logprobs = tensor([[-0.9822, -1.9318],
        [-1.8456, -1.1209]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.198215514421463
Epoch 0, Step 3306: train/loss = 0.6962229013442993, train/raw-loss = 0.6949125528335571, train/logprobs = tensor([[-1.5661, -1.4799],
        [-0.9868, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002620544284582138
Epoch 0, Step 3307: train/loss = 0.6679056286811829, train/raw-loss = 0.5960171222686768, train/logprobs = tensor([[-1.0689, -1.8144],
        [-2.0508, -1.2867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14377707242965698
Epoch 0, Step 3308: train/loss = 0.7087889909744263, train/raw-loss = 0.6464235186576843, train/logprobs = tensor([[-1.3497, -1.9638],
        [-1.5602, -0.9187]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12473097443580627
Epoch 0, Step 3309: train/loss = 0.6973984837532043, train/raw-loss = 0.695207953453064, train/logprobs = tensor([[-1.3997, -1.3638],
        [-1.7586, -1.5696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004381075501441956
Epoch 0, Step 3310: train/loss = 0.6907485723495483, train/raw-loss = 0.6376193761825562, train/logprobs = tensor([[-1.1625, -1.8188],
        [-1.8572, -1.2098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10625846683979034
Epoch 0, Step 3311: train/loss = 0.7526347637176514, train/raw-loss = 0.6436351537704468, train/logprobs = tensor([[-1.3350, -1.6392],
        [-2.7459, -1.2067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21799921989440918
Epoch 0, Step 3312: train/loss = 0.6825859546661377, train/raw-loss = 0.6605290174484253, train/logprobs = tensor([[-1.8129, -2.0848],
        [-1.1856, -0.9090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04411394149065018
Epoch 0, Step 3313: train/loss = 0.6971869468688965, train/raw-loss = 0.6721241474151611, train/logprobs = tensor([[-1.3178, -1.5203],
        [-1.7214, -1.4968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05012551695108414
Epoch 0, Step 3314: train/loss = 0.6931105852127075, train/raw-loss = 0.6787918210029602, train/logprobs = tensor([[-1.8548, -2.0187],
        [-1.2357, -0.8639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028637459501624107
Epoch 0, Step 3315: train/loss = 0.6911500692367554, train/raw-loss = 0.5860700011253357, train/logprobs = tensor([[-1.5772, -2.4329],
        [-1.9891, -1.0537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21015995740890503
Epoch 0, Step 3316: train/loss = 0.6806290745735168, train/raw-loss = 0.6596249341964722, train/logprobs = tensor([[-1.3548, -1.5482],
        [-1.7167, -1.2326]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042008306831121445
Epoch 0, Step 3317: train/loss = 0.6753857731819153, train/raw-loss = 0.579767107963562, train/logprobs = tensor([[-1.3658, -2.2199],
        [-1.7769, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1912374049425125
Epoch 0, Step 3318: train/loss = 0.6897929906845093, train/raw-loss = 0.6208533048629761, train/logprobs = tensor([[-1.2464, -1.8854],
        [-1.7429, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13787946105003357
Epoch 0, Step 3319: train/loss = 0.7021370530128479, train/raw-loss = 0.6645679473876953, train/logprobs = tensor([[-1.1027, -1.2099],
        [-2.0428, -2.0118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07513829320669174
Epoch 0, Step 3320: train/loss = 0.6872500777244568, train/raw-loss = 0.5613325238227844, train/logprobs = tensor([[-0.8675, -1.8582],
        [-2.5818, -1.1837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2518351674079895
Epoch 0, Step 3321: train/loss = 0.6878122091293335, train/raw-loss = 0.6049658060073853, train/logprobs = tensor([[-1.0078, -2.0239],
        [-2.0060, -1.4597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16569268703460693
Epoch 0, Step 3322: train/loss = 0.7098890542984009, train/raw-loss = 0.6640580892562866, train/logprobs = tensor([[-1.2211, -2.1329],
        [-1.7015, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09166185557842255
Epoch 0, Step 3323: train/loss = 0.7058963775634766, train/raw-loss = 0.6703587770462036, train/logprobs = tensor([[-0.9985, -1.7977],
        [-1.5679, -1.4404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07107512652873993
Epoch 0, Step 3324: train/loss = 0.6972029805183411, train/raw-loss = 0.6288951635360718, train/logprobs = tensor([[-1.2794, -1.8789],
        [-2.3371, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13661561906337738
Epoch 0, Step 3325: train/loss = 0.6945495009422302, train/raw-loss = 0.6788425445556641, train/logprobs = tensor([[-1.3168, -1.4420],
        [-1.8822, -1.6369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03141384944319725
Epoch 0, Step 3326: train/loss = 0.6867941617965698, train/raw-loss = 0.617072343826294, train/logprobs = tensor([[-1.2386, -1.8385],
        [-1.7772, -1.1493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13944369554519653
Epoch 0, Step 3327: train/loss = 0.6782817244529724, train/raw-loss = 0.6236059665679932, train/logprobs = tensor([[-1.5811, -1.9620],
        [-1.7804, -1.0734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10935148596763611
Epoch 0, Step 3328: train/loss = 0.6659237146377563, train/raw-loss = 0.5694714784622192, train/logprobs = tensor([[-1.2717, -2.1654],
        [-2.1759, -1.2854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19290447235107422
Epoch 0, Step 3329: train/loss = 0.6796573400497437, train/raw-loss = 0.6079227328300476, train/logprobs = tensor([[-1.4437, -2.0710],
        [-1.6290, -0.9504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1434692144393921
Epoch 0, Step 3330: train/loss = 0.7029834389686584, train/raw-loss = 0.5758397579193115, train/logprobs = tensor([[-1.1219, -2.2691],
        [-2.1810, -1.1356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2542872726917267
Epoch 0, Step 3331: train/loss = 0.6841016411781311, train/raw-loss = 0.6421963572502136, train/logprobs = tensor([[-1.1619, -1.5744],
        [-1.4580, -1.1024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08381050825119019
Epoch 0, Step 3332: train/loss = 0.6921738982200623, train/raw-loss = 0.59964919090271, train/logprobs = tensor([[-1.1149, -1.9431],
        [-2.3594, -1.5501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18504953384399414
Epoch 0, Step 3333: train/loss = 0.6915366649627686, train/raw-loss = 0.604919970035553, train/logprobs = tensor([[-1.1745, -1.7971],
        [-1.9236, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17323344945907593
Epoch 0, Step 3334: train/loss = 0.6845114827156067, train/raw-loss = 0.6549908518791199, train/logprobs = tensor([[-1.2528, -1.7744],
        [-1.9907, -1.5373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0590413473546505
Epoch 0, Step 3335: train/loss = 0.6899735927581787, train/raw-loss = 0.6269779205322266, train/logprobs = tensor([[-1.3343, -2.0332],
        [-1.4622, -0.7858]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1259913146495819
Epoch 0, Step 3336: train/loss = 0.6987662315368652, train/raw-loss = 0.6448944807052612, train/logprobs = tensor([[-1.2023, -1.9739],
        [-1.4481, -0.8303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10774361342191696
Epoch 0, Step 3337: train/loss = 0.6751147508621216, train/raw-loss = 0.5647991299629211, train/logprobs = tensor([[-1.6000, -2.3113],
        [-2.0843, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22063136100769043
Epoch 0, Step 3338: train/loss = 0.6691648364067078, train/raw-loss = 0.5454602837562561, train/logprobs = tensor([[-0.9819, -2.0146],
        [-2.0729, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24740904569625854
Epoch 0, Step 3339: train/loss = 0.6944922804832458, train/raw-loss = 0.6298523545265198, train/logprobs = tensor([[-1.4556, -1.7976],
        [-2.2370, -1.3840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12927985191345215
Epoch 0, Step 3340: train/loss = 0.7047032713890076, train/raw-loss = 0.6672228574752808, train/logprobs = tensor([[-1.4319, -1.6734],
        [-1.8255, -1.3550]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07496077567338943
Epoch 0, Step 3341: train/loss = 0.685437798500061, train/raw-loss = 0.6106656789779663, train/logprobs = tensor([[-1.4190, -2.1649],
        [-1.8048, -1.0300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14954422414302826
Epoch 0, Step 3342: train/loss = 0.7097623944282532, train/raw-loss = 0.672759473323822, train/logprobs = tensor([[-1.3847, -1.4651],
        [-2.1032, -1.5236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0740058422088623
Epoch 0, Step 3343: train/loss = 0.6969953775405884, train/raw-loss = 0.6330333948135376, train/logprobs = tensor([[-1.2296, -1.7227],
        [-1.9166, -1.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.127923846244812
Epoch 0, Step 3344: train/loss = 0.6817640066146851, train/raw-loss = 0.6330684423446655, train/logprobs = tensor([[-1.3816, -1.9753],
        [-1.8909, -1.3063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09739106893539429
Epoch 0, Step 3345: train/loss = 0.7005928754806519, train/raw-loss = 0.697630763053894, train/logprobs = tensor([[-1.4366, -1.5783],
        [-1.3447, -1.2890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005924331024289131
Epoch 0, Step 3346: train/loss = 0.69326251745224, train/raw-loss = 0.6831502318382263, train/logprobs = tensor([[-1.7070, -2.0190],
        [-1.3335, -1.1198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020224539563059807
Epoch 0, Step 3347: train/loss = 0.7023399472236633, train/raw-loss = 0.6552939414978027, train/logprobs = tensor([[-0.9512, -1.4845],
        [-1.5090, -0.9140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09409195929765701
Epoch 0, Step 3348: train/loss = 0.6984992623329163, train/raw-loss = 0.636990487575531, train/logprobs = tensor([[-1.5392, -1.9886],
        [-1.6248, -1.1071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1230175718665123
Epoch 0, Step 3349: train/loss = 0.6928178071975708, train/raw-loss = 0.6348522901535034, train/logprobs = tensor([[-1.1918, -1.8111],
        [-2.0748, -1.3031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11593106389045715
Epoch 0, Step 3350: train/loss = 0.7052744626998901, train/raw-loss = 0.5788065195083618, train/logprobs = tensor([[-1.3202, -1.9668],
        [-2.3326, -0.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2529360055923462
Epoch 0, Step 3351: train/loss = 0.7013254165649414, train/raw-loss = 0.649574875831604, train/logprobs = tensor([[-1.0676, -1.5134],
        [-1.6533, -1.2254]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10350107401609421
Epoch 0, Step 3352: train/loss = 0.6924031972885132, train/raw-loss = 0.6398347616195679, train/logprobs = tensor([[-1.1593, -1.5039],
        [-2.1000, -1.6446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1051369309425354
Epoch 0, Step 3353: train/loss = 0.6980644464492798, train/raw-loss = 0.6198002696037292, train/logprobs = tensor([[-1.3693, -2.1482],
        [-1.9293, -1.1922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15652838349342346
Epoch 0, Step 3354: train/loss = 0.6631066799163818, train/raw-loss = 0.5060319900512695, train/logprobs = tensor([[-1.1620, -2.5898],
        [-2.1881, -0.9680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.31414949893951416
Epoch 0, Step 3355: train/loss = 0.6977052688598633, train/raw-loss = 0.6871119141578674, train/logprobs = tensor([[-1.2779, -1.3736],
        [-1.9268, -1.6766]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021186549216508865
Epoch 0, Step 3356: train/loss = 0.6877963542938232, train/raw-loss = 0.657454252243042, train/logprobs = tensor([[-1.5454, -2.0479],
        [-1.4877, -1.0746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06068424880504608
Epoch 0, Step 3357: train/loss = 0.6746459007263184, train/raw-loss = 0.5706202983856201, train/logprobs = tensor([[-1.1074, -1.8500],
        [-1.9728, -1.0561]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2080513834953308
Epoch 0, Step 3358: train/loss = 0.7034968137741089, train/raw-loss = 0.6322469711303711, train/logprobs = tensor([[-1.6112, -2.3973],
        [-1.6715, -1.3480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14249959588050842
Epoch 0, Step 3359: train/loss = 0.6886008977890015, train/raw-loss = 0.5795658826828003, train/logprobs = tensor([[-1.2826, -2.5367],
        [-1.9453, -1.2341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2180701494216919
Epoch 0, Step 3360: train/loss = 0.7135809659957886, train/raw-loss = 0.5627918243408203, train/logprobs = tensor([[-0.9643, -2.5971],
        [-2.1767, -1.4721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3015782833099365
Epoch 0, Step 3361: train/loss = 0.6868988275527954, train/raw-loss = 0.6051039099693298, train/logprobs = tensor([[-1.2265, -1.8873],
        [-1.9235, -1.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16358985006809235
Epoch 0, Step 3362: train/loss = 0.6941946744918823, train/raw-loss = 0.659943699836731, train/logprobs = tensor([[-1.7394, -1.9291],
        [-1.8539, -1.1462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06850206851959229
Epoch 0, Step 3363: train/loss = 0.7031298875808716, train/raw-loss = 0.6440858244895935, train/logprobs = tensor([[-1.2046, -1.7257],
        [-1.9203, -1.0981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11808815598487854
Epoch 0, Step 3364: train/loss = 0.6947755813598633, train/raw-loss = 0.6896952390670776, train/logprobs = tensor([[-1.3658, -1.2293],
        [-1.9079, -1.8783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010160695761442184
Epoch 0, Step 3365: train/loss = 0.6959043145179749, train/raw-loss = 0.6398065090179443, train/logprobs = tensor([[-1.4948, -2.0841],
        [-1.7267, -1.1673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11219542473554611
Epoch 0, Step 3366: train/loss = 0.6666688323020935, train/raw-loss = 0.6046854257583618, train/logprobs = tensor([[-1.1834, -1.9545],
        [-2.0849, -1.2541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12396678328514099
Epoch 0, Step 3367: train/loss = 0.6606863737106323, train/raw-loss = 0.5835403800010681, train/logprobs = tensor([[-1.3224, -2.5973],
        [-1.9071, -1.2955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1542920470237732
Epoch 0, Step 3368: train/loss = 0.6913443803787231, train/raw-loss = 0.6062371730804443, train/logprobs = tensor([[-1.3455, -1.9070],
        [-1.8625, -1.0256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17021451890468597
Epoch 0, Step 3369: train/loss = 0.6803102493286133, train/raw-loss = 0.6013399362564087, train/logprobs = tensor([[-1.6875, -2.5393],
        [-1.8421, -1.1266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1579405665397644
Epoch 0, Step 3370: train/loss = 0.693568229675293, train/raw-loss = 0.6786303520202637, train/logprobs = tensor([[-1.6049, -2.0152],
        [-1.5323, -1.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029875582084059715
Epoch 0, Step 3371: train/loss = 0.6879916191101074, train/raw-loss = 0.6566776037216187, train/logprobs = tensor([[-1.0514, -1.4910],
        [-1.8795, -1.4120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0626281276345253
Epoch 0, Step 3372: train/loss = 0.6837564706802368, train/raw-loss = 0.5454674363136292, train/logprobs = tensor([[-1.2803, -2.4642],
        [-1.7669, -0.9155]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2765780985355377
Epoch 0, Step 3373: train/loss = 0.6940299272537231, train/raw-loss = 0.6746674180030823, train/logprobs = tensor([[-1.0715, -1.3826],
        [-1.1634, -0.9335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03872499242424965
Epoch 0, Step 3374: train/loss = 0.6990775465965271, train/raw-loss = 0.6573067307472229, train/logprobs = tensor([[-1.7860, -2.0049],
        [-1.5574, -1.0021]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08354164659976959
Epoch 0, Step 3375: train/loss = 0.6689149141311646, train/raw-loss = 0.6366594433784485, train/logprobs = tensor([[-1.0815, -1.6077],
        [-2.2907, -1.7857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06451097130775452
Epoch 0, Step 3376: train/loss = 0.6967685222625732, train/raw-loss = 0.6751009821891785, train/logprobs = tensor([[-1.2273, -1.6600],
        [-1.6227, -1.4161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0433349683880806
Epoch 0, Step 3377: train/loss = 0.6894650459289551, train/raw-loss = 0.5489331483840942, train/logprobs = tensor([[-0.9404, -1.9859],
        [-2.1903, -1.0938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28106385469436646
Epoch 0, Step 3378: train/loss = 0.7247461080551147, train/raw-loss = 0.6071503162384033, train/logprobs = tensor([[-1.2275, -2.9326],
        [-2.0748, -1.6427]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23519164323806763
Epoch 0, Step 3379: train/loss = 0.6903215646743774, train/raw-loss = 0.5982245206832886, train/logprobs = tensor([[-1.4403, -2.3279],
        [-1.9102, -1.1293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18419398367404938
Epoch 0, Step 3380: train/loss = 0.7451456189155579, train/raw-loss = 0.7021850943565369, train/logprobs = tensor([[-1.5684, -2.6009],
        [-1.3729, -1.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08592105656862259
Epoch 0, Step 3381: train/loss = 0.7069109678268433, train/raw-loss = 0.6553632020950317, train/logprobs = tensor([[-1.3317, -2.1228],
        [-1.5708, -1.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10309562087059021
Epoch 0, Step 3382: train/loss = 0.6988427042961121, train/raw-loss = 0.6821150779724121, train/logprobs = tensor([[-1.4039, -1.7626],
        [-1.3427, -1.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03345534950494766
Epoch 0, Step 3383: train/loss = 0.6983015537261963, train/raw-loss = 0.6106220483779907, train/logprobs = tensor([[-1.1039, -1.7233],
        [-2.2520, -1.2344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17535896599292755
Epoch 0, Step 3384: train/loss = 0.6943320035934448, train/raw-loss = 0.6358409523963928, train/logprobs = tensor([[-1.4018, -2.1931],
        [-1.6790, -1.3313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11698216944932938
Epoch 0, Step 3385: train/loss = 0.7029430270195007, train/raw-loss = 0.6441957950592041, train/logprobs = tensor([[-1.3113, -1.6512],
        [-1.7685, -0.7755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11749438941478729
Epoch 0, Step 3386: train/loss = 0.6927191019058228, train/raw-loss = 0.6208311319351196, train/logprobs = tensor([[-1.0637, -1.8963],
        [-1.7387, -1.2852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14377596974372864
Epoch 0, Step 3387: train/loss = 0.6724016666412354, train/raw-loss = 0.6126114130020142, train/logprobs = tensor([[-1.1187, -2.1030],
        [-1.7305, -0.9652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11958055198192596
Epoch 0, Step 3388: train/loss = 0.6818462014198303, train/raw-loss = 0.5569152235984802, train/logprobs = tensor([[-1.3992, -2.3664],
        [-2.0158, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2498619556427002
Epoch 0, Step 3389: train/loss = 0.6936130523681641, train/raw-loss = 0.6410458087921143, train/logprobs = tensor([[-1.3094, -1.8072],
        [-1.7254, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10513442754745483
Epoch 0, Step 3390: train/loss = 0.6847156286239624, train/raw-loss = 0.5712593793869019, train/logprobs = tensor([[-1.1568, -2.1449],
        [-2.2793, -1.1670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2269124537706375
Epoch 0, Step 3391: train/loss = 0.6973344087600708, train/raw-loss = 0.6741961240768433, train/logprobs = tensor([[-1.7683, -2.1974],
        [-1.0145, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.046276628971099854
Epoch 0, Step 3392: train/loss = 0.6819156408309937, train/raw-loss = 0.613676905632019, train/logprobs = tensor([[-1.2135, -1.9612],
        [-1.5406, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1364775002002716
Epoch 0, Step 3393: train/loss = 0.6799318790435791, train/raw-loss = 0.5982586145401001, train/logprobs = tensor([[-1.2068, -2.0604],
        [-2.0467, -1.2267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16334649920463562
Epoch 0, Step 3394: train/loss = 0.6892021298408508, train/raw-loss = 0.6241514682769775, train/logprobs = tensor([[-1.2280, -2.0691],
        [-1.6408, -1.1530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13010132312774658
Epoch 0, Step 3395: train/loss = 0.7024567127227783, train/raw-loss = 0.6314711570739746, train/logprobs = tensor([[-1.1007, -1.7770],
        [-1.8620, -1.1297]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1419711858034134
Epoch 0, Step 3396: train/loss = 0.688158392906189, train/raw-loss = 0.6190448999404907, train/logprobs = tensor([[-1.3537, -1.7218],
        [-2.1322, -1.1248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13822685182094574
Epoch 0, Step 3397: train/loss = 0.691381573677063, train/raw-loss = 0.6655005216598511, train/logprobs = tensor([[-1.3482, -1.7564],
        [-1.6483, -1.4450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05176204815506935
Epoch 0, Step 3398: train/loss = 0.7010034918785095, train/raw-loss = 0.6409831047058105, train/logprobs = tensor([[-1.4871, -2.3580],
        [-1.2945, -0.9295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12004075944423676
Epoch 0, Step 3399: train/loss = 0.6820453405380249, train/raw-loss = 0.5915325880050659, train/logprobs = tensor([[-1.1796, -2.1479],
        [-2.0371, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18102562427520752
Epoch 0, Step 3400: train/loss = 0.6967000961303711, train/raw-loss = 0.6060565710067749, train/logprobs = tensor([[-1.3223, -2.3821],
        [-1.7473, -1.1567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18128713965415955
Epoch 0, Step 3401: train/loss = 0.6693844795227051, train/raw-loss = 0.5517615079879761, train/logprobs = tensor([[-1.1793, -2.4975],
        [-1.9614, -0.9384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23524586856365204
Epoch 0, Step 3402: train/loss = 0.7165049314498901, train/raw-loss = 0.6729452013969421, train/logprobs = tensor([[-0.9992, -1.8752],
        [-1.5619, -1.4449]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08711957186460495
Epoch 0, Step 3403: train/loss = 0.6858007311820984, train/raw-loss = 0.6023012399673462, train/logprobs = tensor([[-1.3247, -1.9718],
        [-2.1146, -1.4456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16699892282485962
Epoch 0, Step 3404: train/loss = 0.6954222917556763, train/raw-loss = 0.6090310215950012, train/logprobs = tensor([[-1.3494, -2.3414],
        [-1.8431, -1.1383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1727825403213501
Epoch 0, Step 3405: train/loss = 0.6897109746932983, train/raw-loss = 0.6540855765342712, train/logprobs = tensor([[-1.7078, -2.1277],
        [-1.3599, -1.0054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07125076651573181
Epoch 0, Step 3406: train/loss = 0.6912133097648621, train/raw-loss = 0.6108235716819763, train/logprobs = tensor([[-1.3336, -2.3650],
        [-1.5446, -0.9691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16077947616577148
Epoch 0, Step 3407: train/loss = 0.6965109705924988, train/raw-loss = 0.6511058211326599, train/logprobs = tensor([[-1.3334, -2.0105],
        [-1.5091, -1.1388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0908103957772255
Epoch 0, Step 3408: train/loss = 0.6715525388717651, train/raw-loss = 0.6060694456100464, train/logprobs = tensor([[-1.1378, -1.7264],
        [-2.1602, -1.0207]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13096609711647034
Epoch 0, Step 3409: train/loss = 0.699701189994812, train/raw-loss = 0.6517101526260376, train/logprobs = tensor([[-1.7380, -1.7375],
        [-1.5124, -1.2906]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09598195552825928
Epoch 0, Step 3410: train/loss = 0.6859528422355652, train/raw-loss = 0.5982056856155396, train/logprobs = tensor([[-1.1056, -1.9328],
        [-1.9904, -1.3233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1754942685365677
Epoch 0, Step 3411: train/loss = 0.6841086745262146, train/raw-loss = 0.5787047743797302, train/logprobs = tensor([[-1.2837, -2.0974],
        [-1.7996, -1.2681]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21080778539180756
Epoch 0, Step 3412: train/loss = 0.6950985193252563, train/raw-loss = 0.4823566973209381, train/logprobs = tensor([[-1.1260, -2.5276],
        [-2.9627, -1.1879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4254835844039917
Epoch 0, Step 3413: train/loss = 0.686478853225708, train/raw-loss = 0.6394681930541992, train/logprobs = tensor([[-1.2316, -1.7679],
        [-1.9502, -1.3371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09402122348546982
Epoch 0, Step 3414: train/loss = 0.6880464553833008, train/raw-loss = 0.6325556635856628, train/logprobs = tensor([[-1.1076, -1.8091],
        [-1.7706, -1.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11098159849643707
Epoch 0, Step 3415: train/loss = 0.7077378034591675, train/raw-loss = 0.6161794662475586, train/logprobs = tensor([[-0.9525, -1.5567],
        [-2.3571, -1.3726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.183116614818573
Epoch 0, Step 3416: train/loss = 0.6812412738800049, train/raw-loss = 0.5602445602416992, train/logprobs = tensor([[-1.0293, -2.0029],
        [-2.3527, -1.3423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2419935017824173
Epoch 0, Step 3417: train/loss = 0.6950793266296387, train/raw-loss = 0.665895938873291, train/logprobs = tensor([[-1.0901, -1.4736],
        [-1.4780, -1.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.058366838842630386
Epoch 0, Step 3418: train/loss = 0.6977024078369141, train/raw-loss = 0.675774335861206, train/logprobs = tensor([[-1.4095, -1.6483],
        [-1.4997, -1.0329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04385628178715706
Epoch 0, Step 3419: train/loss = 0.6904948353767395, train/raw-loss = 0.6356625556945801, train/logprobs = tensor([[-1.3828, -1.9790],
        [-1.4996, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1096646785736084
Epoch 0, Step 3420: train/loss = 0.6891223192214966, train/raw-loss = 0.6439923644065857, train/logprobs = tensor([[-1.3991, -1.7635],
        [-1.5615, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09025996923446655
Epoch 0, Step 3421: train/loss = 0.6730650067329407, train/raw-loss = 0.5804616212844849, train/logprobs = tensor([[-1.4053, -1.8484],
        [-2.3895, -0.8687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.185206800699234
Epoch 0, Step 3422: train/loss = 0.6784908175468445, train/raw-loss = 0.6121587753295898, train/logprobs = tensor([[-1.3706, -2.0469],
        [-1.8429, -1.2693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13266406953334808
Epoch 0, Step 3423: train/loss = 0.692857027053833, train/raw-loss = 0.6079188585281372, train/logprobs = tensor([[-1.2263, -2.1004],
        [-1.9413, -1.1604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16987648606300354
Epoch 0, Step 3424: train/loss = 0.6804386377334595, train/raw-loss = 0.5597630739212036, train/logprobs = tensor([[-1.2664, -2.0346],
        [-2.1774, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24135126173496246
Epoch 0, Step 3425: train/loss = 0.6924263834953308, train/raw-loss = 0.6737889051437378, train/logprobs = tensor([[-1.7610, -2.1110],
        [-1.5236, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03727498650550842
Epoch 0, Step 3426: train/loss = 0.68845534324646, train/raw-loss = 0.6669196486473083, train/logprobs = tensor([[-1.4644, -1.6058],
        [-1.7384, -1.6999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04307141155004501
Epoch 0, Step 3427: train/loss = 0.711138904094696, train/raw-loss = 0.6496939063072205, train/logprobs = tensor([[-1.3499, -2.1937],
        [-1.5191, -1.3469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12289003282785416
Epoch 0, Step 3428: train/loss = 0.6908305883407593, train/raw-loss = 0.6461297869682312, train/logprobs = tensor([[-1.1379, -1.6289],
        [-1.6468, -0.9931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08940151333808899
Epoch 0, Step 3429: train/loss = 0.688800573348999, train/raw-loss = 0.6252657771110535, train/logprobs = tensor([[-1.3057, -1.9130],
        [-2.2185, -1.8713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1270696222782135
Epoch 0, Step 3430: train/loss = 0.6968640685081482, train/raw-loss = 0.6097449064254761, train/logprobs = tensor([[-1.0677, -1.7897],
        [-1.8051, -1.1710]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1742384433746338
Epoch 0, Step 3431: train/loss = 0.6966003179550171, train/raw-loss = 0.6045953631401062, train/logprobs = tensor([[-1.1557, -2.1272],
        [-1.6287, -1.0169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1840098798274994
Epoch 0, Step 3432: train/loss = 0.6837517619132996, train/raw-loss = 0.5812273621559143, train/logprobs = tensor([[-1.6707, -2.5247],
        [-1.7199, -0.9098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20504888892173767
Epoch 0, Step 3433: train/loss = 0.6959112286567688, train/raw-loss = 0.6396304965019226, train/logprobs = tensor([[-1.0312, -1.5717],
        [-2.0624, -1.2547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11256140470504761
Epoch 0, Step 3434: train/loss = 0.6946924924850464, train/raw-loss = 0.6767496466636658, train/logprobs = tensor([[-1.2444, -1.4494],
        [-1.7242, -1.1440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03588556498289108
Epoch 0, Step 3435: train/loss = 0.6893026828765869, train/raw-loss = 0.5837916135787964, train/logprobs = tensor([[-1.2975, -2.0801],
        [-1.9802, -1.1406]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.21102219820022583
Epoch 0, Step 3436: train/loss = 0.6827232837677002, train/raw-loss = 0.6055675745010376, train/logprobs = tensor([[-0.9352, -1.9019],
        [-2.4092, -1.6419]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15431156754493713
Epoch 0, Step 3437: train/loss = 0.6843991875648499, train/raw-loss = 0.5889732837677002, train/logprobs = tensor([[-1.1383, -1.9559],
        [-2.2228, -1.5360]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19085168838500977
Epoch 0, Step 3438: train/loss = 0.7050348520278931, train/raw-loss = 0.587928831577301, train/logprobs = tensor([[-1.0452, -1.6925],
        [-2.4588, -1.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.23421207070350647
Epoch 0, Step 3439: train/loss = 0.6923242807388306, train/raw-loss = 0.6120432019233704, train/logprobs = tensor([[-1.1731, -1.9161],
        [-1.7865, -1.0433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16056205332279205
Epoch 0, Step 3440: train/loss = 0.6895326375961304, train/raw-loss = 0.6440452337265015, train/logprobs = tensor([[-1.1145, -1.6485],
        [-1.5427, -1.0713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09097488224506378
Epoch 0, Step 3441: train/loss = 0.6968945860862732, train/raw-loss = 0.6751296520233154, train/logprobs = tensor([[-1.1923, -1.6336],
        [-1.6688, -1.5584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04352981224656105
Epoch 0, Step 3442: train/loss = 0.6893684267997742, train/raw-loss = 0.6023284792900085, train/logprobs = tensor([[-1.2827, -2.3735],
        [-1.8432, -1.3330]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17407989501953125
Epoch 0, Step 3443: train/loss = 0.7017480134963989, train/raw-loss = 0.6904544830322266, train/logprobs = tensor([[-1.1515, -1.3817],
        [-1.5596, -1.4336]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02258720062673092
Epoch 0, Step 3444: train/loss = 0.6991291046142578, train/raw-loss = 0.667951226234436, train/logprobs = tensor([[-1.3297, -1.6595],
        [-1.3602, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.062355633825063705
Epoch 0, Step 3445: train/loss = 0.714005708694458, train/raw-loss = 0.6215863227844238, train/logprobs = tensor([[-1.4141, -2.2566],
        [-2.0318, -1.8117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18483856320381165
Epoch 0, Step 3446: train/loss = 0.7268517017364502, train/raw-loss = 0.642491340637207, train/logprobs = tensor([[-1.3670, -1.8268],
        [-2.2912, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16872060298919678
Epoch 0, Step 3447: train/loss = 0.6895511746406555, train/raw-loss = 0.5864824056625366, train/logprobs = tensor([[-1.5259, -2.3118],
        [-1.7753, -0.9204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20613762736320496
Epoch 0, Step 3448: train/loss = 0.691419243812561, train/raw-loss = 0.6255378723144531, train/logprobs = tensor([[-0.9653, -1.4952],
        [-2.3073, -2.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13176271319389343
Epoch 0, Step 3449: train/loss = 0.6965042352676392, train/raw-loss = 0.6205282211303711, train/logprobs = tensor([[-1.1918, -2.0268],
        [-1.7646, -1.1944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1519521176815033
Epoch 0, Step 3450: train/loss = 0.6740491390228271, train/raw-loss = 0.5686874389648438, train/logprobs = tensor([[-1.5657, -2.6241],
        [-1.7016, -0.7922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.210723415017128
Epoch 0, Step 3451: train/loss = 0.70330810546875, train/raw-loss = 0.6832608580589294, train/logprobs = tensor([[-0.9568, -1.2138],
        [-1.0716, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04009455069899559
Epoch 0, Step 3452: train/loss = 0.7033873796463013, train/raw-loss = 0.6224080324172974, train/logprobs = tensor([[-1.1171, -2.2159],
        [-1.7884, -1.0935]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16195857524871826
Epoch 0, Step 3453: train/loss = 0.6982665061950684, train/raw-loss = 0.6954025030136108, train/logprobs = tensor([[-1.7806, -1.7475],
        [-1.7695, -1.5467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005727804731577635
Epoch 0, Step 3454: train/loss = 0.6977970600128174, train/raw-loss = 0.6540144681930542, train/logprobs = tensor([[-1.2149, -1.6187],
        [-1.5557, -1.1426]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08756519109010696
Epoch 0, Step 3455: train/loss = 0.6998376250267029, train/raw-loss = 0.6365152597427368, train/logprobs = tensor([[-1.4843, -1.9023],
        [-1.9293, -1.2795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1266447752714157
Epoch 0, Step 3456: train/loss = 0.7001078128814697, train/raw-loss = 0.6732871532440186, train/logprobs = tensor([[-2.1780, -2.7427],
        [-1.3677, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.053641319274902344
Epoch 0, Step 3457: train/loss = 0.704308807849884, train/raw-loss = 0.6483229994773865, train/logprobs = tensor([[-1.5512, -2.3094],
        [-1.7696, -1.6857]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11197153478860855
Epoch 0, Step 3458: train/loss = 0.7069681882858276, train/raw-loss = 0.6528317332267761, train/logprobs = tensor([[-1.0863, -1.9471],
        [-1.3856, -1.1795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10827295482158661
Epoch 0, Step 3459: train/loss = 0.6940569281578064, train/raw-loss = 0.494253009557724, train/logprobs = tensor([[-1.1437, -2.9423],
        [-1.9537, -0.9635]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3996078670024872
Epoch 0, Step 3460: train/loss = 0.6919080018997192, train/raw-loss = 0.6430128216743469, train/logprobs = tensor([[-1.1550, -1.4144],
        [-2.0027, -2.0522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09779030829668045
Epoch 0, Step 3461: train/loss = 0.6796461939811707, train/raw-loss = 0.521428108215332, train/logprobs = tensor([[-1.1914, -2.5194],
        [-2.0046, -0.9274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3164362609386444
Epoch 0, Step 3462: train/loss = 0.6773616671562195, train/raw-loss = 0.549831211566925, train/logprobs = tensor([[-1.2228, -2.0020],
        [-2.4813, -1.1331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.25506091117858887
Epoch 0, Step 3463: train/loss = 0.6863995790481567, train/raw-loss = 0.6530874967575073, train/logprobs = tensor([[-1.3858, -1.8110],
        [-2.2583, -1.8202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06662412732839584
Epoch 0, Step 3464: train/loss = 0.6975988149642944, train/raw-loss = 0.6924242377281189, train/logprobs = tensor([[-1.3172, -1.3861],
        [-1.8357, -1.8423]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010349100455641747
Epoch 0, Step 3465: train/loss = 0.6806873083114624, train/raw-loss = 0.6046246886253357, train/logprobs = tensor([[-1.1902, -2.0062],
        [-2.1231, -1.2584]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1521252989768982
Epoch 0, Step 3466: train/loss = 0.6965539455413818, train/raw-loss = 0.6654030084609985, train/logprobs = tensor([[-1.6871, -2.0159],
        [-1.6753, -1.2307]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06230207160115242
Epoch 0, Step 3467: train/loss = 0.6983420252799988, train/raw-loss = 0.6633670330047607, train/logprobs = tensor([[-1.3402, -1.6231],
        [-1.4461, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0699499249458313
Epoch 0, Step 3468: train/loss = 0.6671179533004761, train/raw-loss = 0.5079225301742554, train/logprobs = tensor([[-0.8964, -2.6735],
        [-2.2119, -1.0686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3183908760547638
Epoch 0, Step 3469: train/loss = 0.6799018383026123, train/raw-loss = 0.5671237111091614, train/logprobs = tensor([[-0.9594, -1.9194],
        [-2.6710, -1.8462]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22555632889270782
Epoch 0, Step 3470: train/loss = 0.6911043524742126, train/raw-loss = 0.6263988614082336, train/logprobs = tensor([[-1.5656, -1.9531],
        [-1.6838, -1.4332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12941093742847443
Epoch 0, Step 3471: train/loss = 0.6875733137130737, train/raw-loss = 0.5949469804763794, train/logprobs = tensor([[-1.5901, -2.0196],
        [-2.1698, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1852526068687439
Epoch 0, Step 3472: train/loss = 0.6919721961021423, train/raw-loss = 0.5806522369384766, train/logprobs = tensor([[-1.0556, -2.2159],
        [-1.9438, -1.2656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22263987362384796
Epoch 0, Step 3473: train/loss = 0.6819815635681152, train/raw-loss = 0.5347632765769958, train/logprobs = tensor([[-1.1212, -2.3028],
        [-2.2852, -1.2242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.29443657398223877
Epoch 0, Step 3474: train/loss = 0.6962885856628418, train/raw-loss = 0.6930906176567078, train/logprobs = tensor([[-1.3592, -1.3202],
        [-1.4478, -1.2164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00639595789834857
Epoch 0, Step 3475: train/loss = 0.6907421350479126, train/raw-loss = 0.6532949209213257, train/logprobs = tensor([[-1.7291, -2.2008],
        [-1.6061, -1.2289]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07489446550607681
Epoch 0, Step 3476: train/loss = 0.6800248622894287, train/raw-loss = 0.6227123737335205, train/logprobs = tensor([[-1.2743, -2.2742],
        [-1.5622, -1.2071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11462486535310745
Epoch 0, Step 3477: train/loss = 0.7017041444778442, train/raw-loss = 0.6474406123161316, train/logprobs = tensor([[-1.3105, -1.9961],
        [-1.7527, -1.3793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10852712392807007
Epoch 0, Step 3478: train/loss = 0.6650452613830566, train/raw-loss = 0.4974380433559418, train/logprobs = tensor([[-1.0853, -2.3789],
        [-2.3535, -1.1769]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3352143168449402
Epoch 0, Step 3479: train/loss = 0.6842817068099976, train/raw-loss = 0.45920634269714355, train/logprobs = tensor([[-1.1386, -2.6470],
        [-2.4768, -0.8072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.45015063881874084
Epoch 0, Step 3480: train/loss = 0.6976374387741089, train/raw-loss = 0.6541135311126709, train/logprobs = tensor([[-1.0756, -1.7389],
        [-1.9313, -1.7241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08704783022403717
Epoch 0, Step 3481: train/loss = 0.6700265407562256, train/raw-loss = 0.5592353343963623, train/logprobs = tensor([[-1.0272, -2.0693],
        [-1.9148, -0.8344]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22158244252204895
Epoch 0, Step 3482: train/loss = 0.6930126547813416, train/raw-loss = 0.6674227714538574, train/logprobs = tensor([[-1.5174, -2.1029],
        [-1.8355, -1.5037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.051179759204387665
Epoch 0, Step 3483: train/loss = 0.6811845302581787, train/raw-loss = 0.5772789716720581, train/logprobs = tensor([[-1.3571, -2.1064],
        [-2.0173, -0.8651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20781131088733673
Epoch 0, Step 3484: train/loss = 0.681646466255188, train/raw-loss = 0.6253358125686646, train/logprobs = tensor([[-1.5905, -2.2852],
        [-1.5973, -1.0014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11262127757072449
Epoch 0, Step 3485: train/loss = 0.6910429000854492, train/raw-loss = 0.5925508737564087, train/logprobs = tensor([[-1.2008, -2.1300],
        [-2.4119, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19698412716388702
Epoch 0, Step 3486: train/loss = 0.6655615568161011, train/raw-loss = 0.5036856532096863, train/logprobs = tensor([[-1.2656, -2.7935],
        [-2.0194, -0.8337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3237518072128296
Epoch 0, Step 3487: train/loss = 0.6872798204421997, train/raw-loss = 0.5964545011520386, train/logprobs = tensor([[-1.2187, -2.0054],
        [-1.8186, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1816505491733551
Epoch 0, Step 3488: train/loss = 0.6895238757133484, train/raw-loss = 0.6138864755630493, train/logprobs = tensor([[-1.1425, -1.6874],
        [-2.0198, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15127480030059814
Epoch 0, Step 3489: train/loss = 0.6985193490982056, train/raw-loss = 0.6293979287147522, train/logprobs = tensor([[-1.4874, -1.7708],
        [-1.7897, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13824285566806793
Epoch 0, Step 3490: train/loss = 0.6959484815597534, train/raw-loss = 0.6895473003387451, train/logprobs = tensor([[-1.4909, -1.6314],
        [-1.3496, -1.3541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012802314013242722
Epoch 0, Step 3491: train/loss = 0.6810956001281738, train/raw-loss = 0.5383602380752563, train/logprobs = tensor([[-1.4423, -2.5942],
        [-2.0151, -0.9080]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2854706048965454
Epoch 0, Step 3492: train/loss = 0.685401976108551, train/raw-loss = 0.526161253452301, train/logprobs = tensor([[-1.1186, -2.6386],
        [-1.7302, -0.8118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3184814155101776
Epoch 0, Step 3493: train/loss = 0.6990652680397034, train/raw-loss = 0.5856578350067139, train/logprobs = tensor([[-1.2678, -1.4246],
        [-1.7261, -1.6182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22681479156017303
Epoch 0, Step 3494: train/loss = 0.7026301622390747, train/raw-loss = 0.6230970621109009, train/logprobs = tensor([[-1.1554, -1.8949],
        [-1.5524, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1590661108493805
Epoch 0, Step 3495: train/loss = 0.6921557784080505, train/raw-loss = 0.6080042123794556, train/logprobs = tensor([[-1.2102, -2.1103],
        [-1.8614, -1.3328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16830310225486755
Epoch 0, Step 3496: train/loss = 0.6930298805236816, train/raw-loss = 0.5813618898391724, train/logprobs = tensor([[-1.0736, -2.0825],
        [-2.2782, -1.5922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.22333601117134094
Epoch 0, Step 3497: train/loss = 0.6348335146903992, train/raw-loss = 0.609119713306427, train/logprobs = tensor([[-1.3885, -2.1942],
        [-1.7650, -1.0942]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05142749100923538
Epoch 0, Step 3498: train/loss = 0.6935291290283203, train/raw-loss = 0.5357851982116699, train/logprobs = tensor([[-0.9781, -2.1530],
        [-2.2751, -1.5837]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3154878318309784
Epoch 0, Step 3499: train/loss = 0.6768074035644531, train/raw-loss = 0.5934872627258301, train/logprobs = tensor([[-1.0913, -2.0143],
        [-2.0433, -1.4045]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16664013266563416
eval/loss: 0.6906157732009888
Epoch 0, Step 3500: train/loss = 0.665213406085968, train/raw-loss = 0.5920380353927612, train/logprobs = tensor([[-1.5008, -2.3242],
        [-1.5237, -0.8979]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.14635063707828522
Epoch 0, Step 3501: train/loss = 0.6770520806312561, train/raw-loss = 0.5876074433326721, train/logprobs = tensor([[-1.5275, -2.5052],
        [-1.9929, -1.2479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17888928949832916
Epoch 0, Step 3502: train/loss = 0.7303068041801453, train/raw-loss = 0.7018297910690308, train/logprobs = tensor([[-1.8205, -1.7547],
        [-1.7458, -1.1458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05695395916700363
Epoch 0, Step 3503: train/loss = 0.6891950368881226, train/raw-loss = 0.6238253116607666, train/logprobs = tensor([[-1.2915, -1.9618],
        [-2.0587, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13073940575122833
Epoch 0, Step 3504: train/loss = 0.700775146484375, train/raw-loss = 0.686129093170166, train/logprobs = tensor([[-1.8612, -2.1422],
        [-1.6575, -1.3093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02929200977087021
Epoch 0, Step 3505: train/loss = 0.6946114301681519, train/raw-loss = 0.6694841384887695, train/logprobs = tensor([[-1.1576, -1.5468],
        [-2.0023, -1.8188]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05025462433695793
Epoch 0, Step 3506: train/loss = 0.6831640005111694, train/raw-loss = 0.6205536127090454, train/logprobs = tensor([[-0.9898, -1.7322],
        [-2.4760, -2.0023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1252208650112152
Epoch 0, Step 3507: train/loss = 0.6671055555343628, train/raw-loss = 0.5441092252731323, train/logprobs = tensor([[-1.2890, -2.3225],
        [-1.8255, -0.9580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24599267542362213
Epoch 0, Step 3508: train/loss = 0.655555784702301, train/raw-loss = 0.554153323173523, train/logprobs = tensor([[-1.1581, -2.0109],
        [-2.1738, -1.0179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.20280495285987854
Epoch 0, Step 3509: train/loss = 0.7003259062767029, train/raw-loss = 0.6762251853942871, train/logprobs = tensor([[-1.4396, -1.4711],
        [-1.3959, -0.9032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048201560974121094
Epoch 0, Step 3510: train/loss = 0.686416506767273, train/raw-loss = 0.59684818983078, train/logprobs = tensor([[-1.1745, -2.0078],
        [-2.1094, -1.3604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17913666367530823
Epoch 0, Step 3511: train/loss = 0.7053621411323547, train/raw-loss = 0.6456993818283081, train/logprobs = tensor([[-1.7096, -2.3277],
        [-1.7400, -1.1575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.11932559311389923
Epoch 0, Step 3512: train/loss = 0.6745158433914185, train/raw-loss = 0.5522027611732483, train/logprobs = tensor([[-1.2240, -2.6425],
        [-1.8830, -1.0134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24462616443634033
Epoch 0, Step 3513: train/loss = 0.6931291818618774, train/raw-loss = 0.67893385887146, train/logprobs = tensor([[-1.3502, -1.7120],
        [-1.6964, -1.5226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02839081361889839
Epoch 0, Step 3514: train/loss = 0.6990563869476318, train/raw-loss = 0.6216558218002319, train/logprobs = tensor([[-0.9636, -1.7241],
        [-2.0952, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15480118989944458
Epoch 0, Step 3515: train/loss = 0.7015799880027771, train/raw-loss = 0.6693289279937744, train/logprobs = tensor([[-1.5901, -1.8777],
        [-1.4375, -0.9112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06450207531452179
Epoch 0, Step 3516: train/loss = 0.6492769718170166, train/raw-loss = 0.5963367819786072, train/logprobs = tensor([[-0.8039, -1.4792],
        [-2.0589, -1.4510]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10588041692972183
Epoch 0, Step 3517: train/loss = 0.6910186409950256, train/raw-loss = 0.6306150555610657, train/logprobs = tensor([[-1.8864, -2.3788],
        [-1.4016, -0.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.12080712616443634
Epoch 0, Step 3518: train/loss = 0.6712585687637329, train/raw-loss = 0.6081467270851135, train/logprobs = tensor([[-1.7347, -2.2273],
        [-1.6317, -1.0043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.126223623752594
Epoch 0, Step 3519: train/loss = 0.6921147108078003, train/raw-loss = 0.6886001825332642, train/logprobs = tensor([[-1.3419, -1.4877],
        [-1.3831, -1.2749]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00702899694442749
Epoch 0, Step 3520: train/loss = 0.7054212689399719, train/raw-loss = 0.6783713102340698, train/logprobs = tensor([[-1.1637, -1.9063],
        [-1.5540, -1.4523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.054099973291158676
Epoch 0, Step 3521: train/loss = 0.6666611433029175, train/raw-loss = 0.5533605813980103, train/logprobs = tensor([[-1.3060, -2.8006],
        [-1.9559, -1.0934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2266009896993637
Epoch 0, Step 3522: train/loss = 0.6769294738769531, train/raw-loss = 0.5086853504180908, train/logprobs = tensor([[-1.2033, -2.4966],
        [-2.0252, -1.2856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3364882469177246
Epoch 0, Step 3523: train/loss = 0.6870020031929016, train/raw-loss = 0.6065451502799988, train/logprobs = tensor([[-1.2533, -2.2785],
        [-2.0648, -1.3699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16091378033161163
Epoch 0, Step 3524: train/loss = 0.6939442157745361, train/raw-loss = 0.6058845520019531, train/logprobs = tensor([[-1.3261, -2.1334],
        [-1.5927, -1.0184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17611932754516602
Epoch 0, Step 3525: train/loss = 0.6959816813468933, train/raw-loss = 0.6944196224212646, train/logprobs = tensor([[-1.8633, -2.0086],
        [-1.0764, -0.9653]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031241723336279392
Epoch 0, Step 3526: train/loss = 0.6934592127799988, train/raw-loss = 0.5443978309631348, train/logprobs = tensor([[-1.2151, -2.4853],
        [-2.0403, -1.1259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.298122763633728
Epoch 0, Step 3527: train/loss = 0.6969287395477295, train/raw-loss = 0.6922305226325989, train/logprobs = tensor([[-1.3719, -1.6122],
        [-1.3962, -1.4960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009396541863679886
Epoch 0, Step 3528: train/loss = 0.6874469518661499, train/raw-loss = 0.6010194420814514, train/logprobs = tensor([[-1.0192, -1.8565],
        [-2.1203, -1.4161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17285504937171936
Epoch 0, Step 3529: train/loss = 0.6985887289047241, train/raw-loss = 0.6848515868186951, train/logprobs = tensor([[-1.4458, -1.9564],
        [-1.0995, -1.0050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027474291622638702
Epoch 0, Step 3530: train/loss = 0.6925393342971802, train/raw-loss = 0.65465247631073, train/logprobs = tensor([[-1.3612, -2.0078],
        [-1.4761, -1.0335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07577385008335114
Epoch 0, Step 3531: train/loss = 0.6950476169586182, train/raw-loss = 0.6708125472068787, train/logprobs = tensor([[-1.2516, -1.5584],
        [-1.1796, -0.9901]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04847021400928497
Epoch 0, Step 3532: train/loss = 0.7070533037185669, train/raw-loss = 0.5505535006523132, train/logprobs = tensor([[-1.3261, -2.3441],
        [-2.4609, -0.9993]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3129996061325073
Epoch 0, Step 3533: train/loss = 0.6848001480102539, train/raw-loss = 0.5513269901275635, train/logprobs = tensor([[-1.0492, -2.2485],
        [-2.0194, -1.0226]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26694634556770325
Epoch 0, Step 3534: train/loss = 0.6919975280761719, train/raw-loss = 0.6603859663009644, train/logprobs = tensor([[-1.4377, -1.9001],
        [-1.9923, -1.6531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06322310864925385
Epoch 0, Step 3535: train/loss = 0.6799998879432678, train/raw-loss = 0.5747677683830261, train/logprobs = tensor([[-1.0354, -1.8112],
        [-2.3499, -1.2898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2104642391204834
Epoch 0, Step 3536: train/loss = 0.7142786383628845, train/raw-loss = 0.6297369003295898, train/logprobs = tensor([[-1.6829, -2.6190],
        [-1.4916, -1.1805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1690833866596222
Epoch 0, Step 3537: train/loss = 0.7002648711204529, train/raw-loss = 0.656303346157074, train/logprobs = tensor([[-1.6475, -2.1089],
        [-1.8487, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08792299777269363
Epoch 0, Step 3538: train/loss = 0.707729697227478, train/raw-loss = 0.5845279693603516, train/logprobs = tensor([[-1.3749, -2.7182],
        [-1.9336, -1.3421]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24640345573425293
Epoch 0, Step 3539: train/loss = 0.6950685977935791, train/raw-loss = 0.6088034510612488, train/logprobs = tensor([[-1.4570, -2.3526],
        [-2.0021, -1.3623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17253032326698303
Epoch 0, Step 3540: train/loss = 0.6908819675445557, train/raw-loss = 0.512067973613739, train/logprobs = tensor([[-1.3038, -2.8508],
        [-2.1581, -0.9705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.3576279580593109
Epoch 0, Step 3541: train/loss = 0.7169507145881653, train/raw-loss = 0.6483235359191895, train/logprobs = tensor([[-1.7165, -2.7352],
        [-1.4384, -1.0885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.13725429773330688
Epoch 0, Step 3542: train/loss = 0.6940503120422363, train/raw-loss = 0.5624456405639648, train/logprobs = tensor([[-1.1866, -2.4037],
        [-1.8769, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.26320934295654297
Epoch 0, Step 3543: train/loss = 0.6893402338027954, train/raw-loss = 0.5923235416412354, train/logprobs = tensor([[-1.0324, -2.0927],
        [-2.0542, -1.3389]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19403336942195892
Epoch 0, Step 3544: train/loss = 0.67698734998703, train/raw-loss = 0.5887200236320496, train/logprobs = tensor([[-1.3623, -2.2009],
        [-1.9010, -0.9524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.17653465270996094
Epoch 0, Step 3545: train/loss = 0.7162829637527466, train/raw-loss = 0.6054990291595459, train/logprobs = tensor([[-1.1247, -2.0062],
        [-2.4360, -1.2380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2215677797794342
Epoch 0, Step 3546: train/loss = 0.6914782524108887, train/raw-loss = 0.5985764265060425, train/logprobs = tensor([[-1.7742, -2.4619],
        [-1.9991, -1.0186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18580374121665955
Epoch 0, Step 3547: train/loss = 0.6820884346961975, train/raw-loss = 0.634894847869873, train/logprobs = tensor([[-1.3501, -2.1902],
        [-1.6917, -1.2596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09438728541135788
Epoch 0, Step 3548: train/loss = 0.6716184020042419, train/raw-loss = 0.5634174346923828, train/logprobs = tensor([[-1.0875, -2.2785],
        [-1.9801, -1.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.2164018750190735
Epoch 0, Step 3549: train/loss = 0.6831740736961365, train/raw-loss = 0.47316038608551025, train/logprobs = tensor([[-0.8846, -2.9047],
        [-2.0066, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.4200274348258972
Epoch 0, Step 3550: train/loss = 0.6809669733047485, train/raw-loss = 0.5886372327804565, train/logprobs = tensor([[-1.2021, -2.3668],
        [-2.0132, -1.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18465951085090637
Epoch 0, Step 3551: train/loss = 0.6886759996414185, train/raw-loss = 0.6143179535865784, train/logprobs = tensor([[-1.6295, -2.3267],
        [-1.6013, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1487160474061966
Epoch 0, Step 3552: train/loss = 0.6898186206817627, train/raw-loss = 0.5691789388656616, train/logprobs = tensor([[-1.2052, -2.0974],
        [-1.9424, -0.9073]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.24127954244613647
Epoch 0, Step 3553: train/loss = 0.6869488954544067, train/raw-loss = 0.6103454232215881, train/logprobs = tensor([[-1.0233, -1.8583],
        [-2.2181, -1.5641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.15320703387260437
Epoch 0, Step 3554: train/loss = 0.6828452348709106, train/raw-loss = 0.584077000617981, train/logprobs = tensor([[-1.6612, -2.3230],
        [-1.8336, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.19753651320934296
Epoch 0, Step 3555: train/loss = 0.6559852957725525, train/raw-loss = 0.5146699547767639, train/logprobs = tensor([[-0.8491, -2.3815],
        [-2.1776, -1.0328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.28263065218925476
Epoch 0, Step 3556: train/loss = 0.6892142295837402, train/raw-loss = 0.5962274670600891, train/logprobs = tensor([[-1.8511, -2.6508],
        [-1.5302, -1.1005]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.1859733909368515
Epoch 0, Step 3557: train/loss = 0.685699462890625, train/raw-loss = 0.6362681984901428, train/logprobs = tensor([[-1.0979, -1.6306],
        [-2.0364, -1.5197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.09886254370212555
Epoch 0, Step 3558: train/loss = 0.6993910074234009, train/raw-loss = 0.6068033576011658, train/logprobs = tensor([[-1.3055, -2.3499],
        [-1.8519, -1.1150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18517526984214783
Epoch 0, Step 3559: train/loss = 0.6875750422477722, train/raw-loss = 0.595325767993927, train/logprobs = tensor([[-1.3538, -2.3790],
        [-2.0653, -1.2851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.18449857831001282
Epoch 0, Step 3560: train/loss = 0.680573582649231, train/raw-loss = 0.6401870250701904, train/logprobs = tensor([[-1.9424, -2.4738],
        [-1.7703, -1.4380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.08077316731214523
Epoch 0, Step 3561: train/loss = 0.6964429616928101, train/raw-loss = 0.6713110208511353, train/logprobs = tensor([[-1.9122, -1.9975],
        [-1.6352, -1.4123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.050263870507478714
Epoch 0, Step 3562: train/loss = 0.6867557764053345, train/raw-loss = 0.6037725806236267, train/logprobs = tensor([[-1.1708, -1.8298],
        [-2.2912, -1.4965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.16596633195877075
Epoch 0, Step 3563: train/loss = 0.6917275190353394, train/raw-loss = 0.6383601427078247, train/logprobs = tensor([[-1.0841, -1.5818],
        [-2.0134, -1.4077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.10673464834690094
