[2024-02-27 18:26:29,174][root][INFO] - beta: 7.5
[2024-02-27 18:26:29,174][root][INFO] - loss with_labels
[2024-02-27 18:26:29,175][root][INFO] - max_iter: 0
[2024-02-27 18:26:29,175][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-7.5
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
n helpful: 5000
n harmless: 5000
tokenized 9500 training examples...
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-7.5 after each epoch.
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-7.5 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-7.5 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-7.5 after each epoch.
Epoch 0, Step 0: train/loss = 0.6982459425926208, train/raw-loss = 0.6982459425926208, train/logprobs = tensor([[-0.8431, -2.6125],
        [-0.8326, -2.6216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.6927576065063477, train/raw-loss = 0.6927576065063477, train/logprobs = tensor([[-1.2483, -1.6199],
        [-1.2440, -1.6139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7061817049980164, train/raw-loss = 0.6891124844551086, train/logprobs = tensor([[-1.0788, -2.0911],
        [-1.1097, -2.1055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022758927661925554
Epoch 0, Step 3: train/loss = 0.9116026759147644, train/raw-loss = 0.6834738254547119, train/logprobs = tensor([[-0.5969, -1.4569],
        [-0.6010, -1.4220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03041718155145645
Epoch 0, Step 4: train/loss = 1.1574907302856445, train/raw-loss = 0.6715068221092224, train/logprobs = tensor([[-0.9716, -2.2355],
        [-1.0030, -2.1790]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06479786336421967
Epoch 0, Step 5: train/loss = 1.069038987159729, train/raw-loss = 0.6878856420516968, train/logprobs = tensor([[-1.3103, -1.8410],
        [-1.3103, -1.8198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05082046240568161
Epoch 0, Step 6: train/loss = 0.9596542119979858, train/raw-loss = 0.6820317506790161, train/logprobs = tensor([[-1.0053, -1.6098],
        [-1.0068, -1.5665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03701632842421532
Epoch 0, Step 7: train/loss = 1.048195242881775, train/raw-loss = 0.681455135345459, train/logprobs = tensor([[-1.0953, -1.5821],
        [-1.1386, -1.5779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048898667097091675
Epoch 0, Step 8: train/loss = 1.1588023900985718, train/raw-loss = 0.6789276003837585, train/logprobs = tensor([[-0.7938, -1.7401],
        [-0.7777, -1.6657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06398330628871918
Epoch 0, Step 9: train/loss = 1.2522530555725098, train/raw-loss = 0.667920708656311, train/logprobs = tensor([[-1.1166, -1.7777],
        [-1.1048, -1.6634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.07791098207235336
Epoch 0, Step 10: train/loss = 1.1228435039520264, train/raw-loss = 0.6421363949775696, train/logprobs = tensor([[-1.3076, -2.5250],
        [-1.4166, -2.4222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.06409428268671036
Epoch 0, Step 11: train/loss = 1.1025677919387817, train/raw-loss = 0.6644952297210693, train/logprobs = tensor([[-0.7364, -1.5759],
        [-0.7183, -1.4400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0584096759557724
Epoch 0, Step 12: train/loss = 1.0003142356872559, train/raw-loss = 0.6618167161941528, train/logprobs = tensor([[-0.7257, -1.8067],
        [-0.7948, -1.7470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04513299837708473
Epoch 0, Step 13: train/loss = 1.0098453760147095, train/raw-loss = 0.6572670936584473, train/logprobs = tensor([[-0.7195, -1.7058],
        [-0.7476, -1.5855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.047010429203510284
Epoch 0, Step 14: train/loss = 0.9460098743438721, train/raw-loss = 0.6615088582038879, train/logprobs = tensor([[-1.1348, -1.8455],
        [-1.1054, -1.6870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03793347254395485
Epoch 0, Step 15: train/loss = 0.957577109336853, train/raw-loss = 0.6680164337158203, train/logprobs = tensor([[-1.1649, -1.6484],
        [-1.1435, -1.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038608092814683914
Epoch 0, Step 16: train/loss = 0.9439905285835266, train/raw-loss = 0.6066042184829712, train/logprobs = tensor([[-1.0411, -2.3148],
        [-1.0079, -1.9167]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0449848435819149
Epoch 0, Step 17: train/loss = 0.9495958089828491, train/raw-loss = 0.666944146156311, train/logprobs = tensor([[-1.1233, -1.6316],
        [-1.1101, -1.5118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03768688812851906
Epoch 0, Step 18: train/loss = 0.9316971302032471, train/raw-loss = 0.6475947499275208, train/logprobs = tensor([[-1.1171, -1.7653],
        [-1.0782, -1.5394]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037880320101976395
Epoch 0, Step 19: train/loss = 0.9598430395126343, train/raw-loss = 0.6526970863342285, train/logprobs = tensor([[-0.7842, -1.4640],
        [-0.7571, -1.2696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04095279052853584
Epoch 0, Step 20: train/loss = 0.88860023021698, train/raw-loss = 0.6382386684417725, train/logprobs = tensor([[-0.7244, -1.7498],
        [-0.7253, -1.5139]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033381540328264236
Epoch 0, Step 21: train/loss = 0.934994637966156, train/raw-loss = 0.6584610939025879, train/logprobs = tensor([[-1.0103, -1.3886],
        [-0.9778, -1.2141]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03687114641070366
Epoch 0, Step 22: train/loss = 0.8662222623825073, train/raw-loss = 0.6446518898010254, train/logprobs = tensor([[-1.1709, -1.2785],
        [-1.0994, -0.9995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029542718082666397
Epoch 0, Step 23: train/loss = 0.8580795526504517, train/raw-loss = 0.5924537181854248, train/logprobs = tensor([[-1.2512, -2.3647],
        [-1.1562, -1.8315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03541678562760353
Epoch 0, Step 24: train/loss = 0.8129056096076965, train/raw-loss = 0.5810611248016357, train/logprobs = tensor([[-1.1033, -2.7866],
        [-0.9279, -2.0975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03091258928179741
Epoch 0, Step 25: train/loss = 0.7600574493408203, train/raw-loss = 0.5809539556503296, train/logprobs = tensor([[-0.8949, -2.5966],
        [-0.7136, -1.8495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02388046495616436
Epoch 0, Step 26: train/loss = 0.855397641658783, train/raw-loss = 0.5291553139686584, train/logprobs = tensor([[-0.6741, -3.0705],
        [-0.6181, -2.2542]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04349897801876068
Epoch 0, Step 27: train/loss = 0.7346118688583374, train/raw-loss = 0.5020380020141602, train/logprobs = tensor([[-1.2224, -3.9462],
        [-0.8629, -1.7713]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031009843572974205
Epoch 0, Step 28: train/loss = 0.7580903768539429, train/raw-loss = 0.49149394035339355, train/logprobs = tensor([[-1.0056, -2.4299],
        [-0.7585, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0355461910367012
Epoch 0, Step 29: train/loss = 0.7449771165847778, train/raw-loss = 0.47544071078300476, train/logprobs = tensor([[-0.6858, -2.6402],
        [-0.5419, -1.3853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03593818470835686
Epoch 0, Step 30: train/loss = 0.8472010493278503, train/raw-loss = 0.6401378512382507, train/logprobs = tensor([[-1.0988, -1.5556],
        [-0.6749, -0.9064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027608424425125122
Epoch 0, Step 31: train/loss = 0.7388419508934021, train/raw-loss = 0.4499807357788086, train/logprobs = tensor([[-1.2191, -3.4445],
        [-1.0837, -1.6691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03851483017206192
Epoch 0, Step 32: train/loss = 0.7492285370826721, train/raw-loss = 0.4369601011276245, train/logprobs = tensor([[-1.1459, -3.2542],
        [-0.9846, -1.8329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04163579270243645
Epoch 0, Step 33: train/loss = 0.7517199516296387, train/raw-loss = 0.44586431980133057, train/logprobs = tensor([[-1.0915, -2.9098],
        [-0.8288, -1.4414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04078076034784317
Epoch 0, Step 34: train/loss = 0.7870264053344727, train/raw-loss = 0.5105148553848267, train/logprobs = tensor([[-1.2411, -2.3079],
        [-0.9868, -1.1699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036868203431367874
Epoch 0, Step 35: train/loss = 0.7059081196784973, train/raw-loss = 0.4000900685787201, train/logprobs = tensor([[-1.2234, -3.2703],
        [-0.9545, -1.4246]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04077574610710144
Epoch 0, Step 36: train/loss = 0.8042028546333313, train/raw-loss = 0.510262668132782, train/logprobs = tensor([[-1.6288, -2.9649],
        [-1.2769, -1.1666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039192020893096924
Epoch 0, Step 37: train/loss = 0.7323344349861145, train/raw-loss = 0.4766954183578491, train/logprobs = tensor([[-0.7689, -2.9758],
        [-0.5359, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03408520296216011
Epoch 0, Step 38: train/loss = 0.7070872783660889, train/raw-loss = 0.46675780415534973, train/logprobs = tensor([[-0.9463, -2.5552],
        [-0.7906, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0320439375936985
Epoch 0, Step 39: train/loss = 0.7437521815299988, train/raw-loss = 0.4852725565433502, train/logprobs = tensor([[-0.9030, -2.5221],
        [-0.6177, -1.0676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034463949501514435
Epoch 0, Step 40: train/loss = 0.8408530950546265, train/raw-loss = 0.5728473663330078, train/logprobs = tensor([[-0.9891, -1.7128],
        [-0.7028, -0.8904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03573409467935562
Epoch 0, Step 41: train/loss = 0.7453510761260986, train/raw-loss = 0.40906643867492676, train/logprobs = tensor([[-1.2547, -3.6934],
        [-0.7772, -1.1397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04483795911073685
Epoch 0, Step 42: train/loss = 0.6377086043357849, train/raw-loss = 0.4121694266796112, train/logprobs = tensor([[-0.8718, -3.9873],
        [-0.6325, -1.1145]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030071889981627464
Epoch 0, Step 43: train/loss = 0.7694689035415649, train/raw-loss = 0.480462908744812, train/logprobs = tensor([[-1.6338, -3.9068],
        [-0.8935, -1.6674]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03853413090109825
Epoch 0, Step 44: train/loss = 0.7333927154541016, train/raw-loss = 0.5018951892852783, train/logprobs = tensor([[-1.3766, -2.3074],
        [-0.8642, -0.8439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030866337940096855
Epoch 0, Step 45: train/loss = 0.7424711585044861, train/raw-loss = 0.4979372024536133, train/logprobs = tensor([[-1.5128, -3.6216],
        [-0.8688, -1.3730]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032604530453681946
Epoch 0, Step 46: train/loss = 0.5804980397224426, train/raw-loss = 0.3648189306259155, train/logprobs = tensor([[-1.6523, -5.6343],
        [-1.1827, -2.1481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028757216408848763
Epoch 0, Step 47: train/loss = 0.7375372648239136, train/raw-loss = 0.43278253078460693, train/logprobs = tensor([[-0.9110, -2.9989],
        [-0.6659, -1.1964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04063395783305168
Epoch 0, Step 48: train/loss = 0.9044714570045471, train/raw-loss = 0.6832712888717651, train/logprobs = tensor([[-1.9860, -2.0794],
        [-1.4056, -1.4546]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02949335426092148
Epoch 0, Step 49: train/loss = 0.6365081071853638, train/raw-loss = 0.4050735831260681, train/logprobs = tensor([[-1.0559, -3.8212],
        [-0.8108, -1.6611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030857937410473824
Epoch 0, Step 50: train/loss = 0.7005740404129028, train/raw-loss = 0.5098069906234741, train/logprobs = tensor([[-1.4819, -2.6107],
        [-1.0272, -0.9896]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025435613468289375
Epoch 0, Step 51: train/loss = 0.6814342737197876, train/raw-loss = 0.44845959544181824, train/logprobs = tensor([[-1.7497, -3.8456],
        [-0.9201, -1.4402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031063294038176537
Epoch 0, Step 52: train/loss = 0.8889868259429932, train/raw-loss = 0.6694505214691162, train/logprobs = tensor([[-0.9649, -0.9976],
        [-0.7241, -0.6571]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02927149459719658
Epoch 0, Step 53: train/loss = 0.7333910465240479, train/raw-loss = 0.5421478152275085, train/logprobs = tensor([[-0.9294, -2.2370],
        [-0.5441, -0.7881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025499096140265465
Epoch 0, Step 54: train/loss = 0.713198721408844, train/raw-loss = 0.4385194778442383, train/logprobs = tensor([[-1.4695, -2.9537],
        [-1.1826, -1.2835]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036623891443014145
Epoch 0, Step 55: train/loss = 0.8151401281356812, train/raw-loss = 0.5402486324310303, train/logprobs = tensor([[-1.8068, -2.2593],
        [-1.2978, -0.9915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03665219247341156
Epoch 0, Step 56: train/loss = 0.6740708351135254, train/raw-loss = 0.43036437034606934, train/logprobs = tensor([[-1.3599, -3.0431],
        [-0.9221, -1.1131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0324941910803318
Epoch 0, Step 57: train/loss = 0.6790436506271362, train/raw-loss = 0.46461987495422363, train/logprobs = tensor([[-1.0685, -3.2006],
        [-0.7010, -0.8723]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028589840978384018
Epoch 0, Step 58: train/loss = 0.6363215446472168, train/raw-loss = 0.3957521915435791, train/logprobs = tensor([[-0.9677, -3.7176],
        [-0.6465, -1.1620]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0320759192109108
Epoch 0, Step 59: train/loss = 0.7266685962677002, train/raw-loss = 0.5245928764343262, train/logprobs = tensor([[-1.3796, -2.5056],
        [-0.8262, -1.1144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026943422853946686
Epoch 0, Step 60: train/loss = 0.6330902576446533, train/raw-loss = 0.41347602009773254, train/logprobs = tensor([[-1.9852, -3.8473],
        [-1.0245, -1.1518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029281890019774437
Epoch 0, Step 61: train/loss = 0.6563147306442261, train/raw-loss = 0.3681364357471466, train/logprobs = tensor([[-0.6702, -4.1219],
        [-0.4562, -0.8976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038423776626586914
Epoch 0, Step 62: train/loss = 0.7061401605606079, train/raw-loss = 0.48384755849838257, train/logprobs = tensor([[-1.7663, -3.2820],
        [-1.1400, -1.3240]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02963900938630104
Epoch 0, Step 63: train/loss = 0.6839428544044495, train/raw-loss = 0.4460582137107849, train/logprobs = tensor([[-1.3915, -2.8139],
        [-0.9834, -1.0030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03171795606613159
Epoch 0, Step 64: train/loss = 0.6800616383552551, train/raw-loss = 0.4249967336654663, train/logprobs = tensor([[-1.2519, -3.2048],
        [-0.8505, -1.3759]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034008655697107315
Epoch 0, Step 65: train/loss = 0.6155860424041748, train/raw-loss = 0.3808577060699463, train/logprobs = tensor([[-1.5753, -4.6031],
        [-0.8221, -1.0965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03129711002111435
Epoch 0, Step 66: train/loss = 0.713998556137085, train/raw-loss = 0.44475531578063965, train/logprobs = tensor([[-1.8148, -5.1328],
        [-1.0219, -1.4530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03589910268783569
Epoch 0, Step 67: train/loss = 0.5343551635742188, train/raw-loss = 0.2766065001487732, train/logprobs = tensor([[-0.9976, -5.0335],
        [-0.6429, -1.2402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034366484731435776
Epoch 0, Step 68: train/loss = 0.5810360312461853, train/raw-loss = 0.34002432227134705, train/logprobs = tensor([[-1.2972, -5.9005],
        [-0.8059, -2.1824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03213489428162575
Epoch 0, Step 69: train/loss = 0.7235943078994751, train/raw-loss = 0.514434814453125, train/logprobs = tensor([[-1.7392, -2.9907],
        [-1.3930, -1.5974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02788793295621872
Epoch 0, Step 70: train/loss = 0.5473266839981079, train/raw-loss = 0.2816779613494873, train/logprobs = tensor([[-0.8633, -4.7708],
        [-0.5902, -1.4587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03541983291506767
Epoch 0, Step 71: train/loss = 0.6359192132949829, train/raw-loss = 0.3903197646141052, train/logprobs = tensor([[-1.6893, -4.4147],
        [-0.9914, -1.4487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03274659812450409
Epoch 0, Step 72: train/loss = 0.5518537759780884, train/raw-loss = 0.3072894811630249, train/logprobs = tensor([[-0.6198, -5.1293],
        [-0.4370, -1.3461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03260857239365578
Epoch 0, Step 73: train/loss = 0.6773301959037781, train/raw-loss = 0.48755180835723877, train/logprobs = tensor([[-1.2739, -2.8640],
        [-0.7583, -0.9375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025303779169917107
Epoch 0, Step 74: train/loss = 0.639194667339325, train/raw-loss = 0.4380008578300476, train/logprobs = tensor([[-2.0090, -3.7657],
        [-1.5348, -1.8957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026825841516256332
Epoch 0, Step 75: train/loss = 0.6203533411026001, train/raw-loss = 0.37990033626556396, train/logprobs = tensor([[-0.8501, -4.2643],
        [-0.7228, -1.5031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032060399651527405
Epoch 0, Step 76: train/loss = 0.7398495674133301, train/raw-loss = 0.5543988347053528, train/logprobs = tensor([[-1.6371, -4.2489],
        [-1.0376, -1.0972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024726755917072296
Epoch 0, Step 77: train/loss = 0.6687500476837158, train/raw-loss = 0.4679282307624817, train/logprobs = tensor([[-2.1260, -3.9864],
        [-1.1177, -1.0556]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026776239275932312
Epoch 0, Step 78: train/loss = 0.5807801485061646, train/raw-loss = 0.3752634525299072, train/logprobs = tensor([[-1.6943, -5.0796],
        [-0.9349, -1.3907]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027402225881814957
Epoch 0, Step 79: train/loss = 0.7153346538543701, train/raw-loss = 0.5164312720298767, train/logprobs = tensor([[-0.9295, -3.1495],
        [-0.5658, -1.0468]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02652045711874962
Epoch 0, Step 80: train/loss = 0.5719314217567444, train/raw-loss = 0.3639982342720032, train/logprobs = tensor([[-1.9819, -5.4347],
        [-1.0231, -1.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02772442437708378
Epoch 0, Step 81: train/loss = 0.5972119569778442, train/raw-loss = 0.37275266647338867, train/logprobs = tensor([[-1.3551, -6.5107],
        [-0.8914, -1.4124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02992790937423706
Epoch 0, Step 82: train/loss = 0.8654496669769287, train/raw-loss = 0.6927463412284851, train/logprobs = tensor([[-2.5996, -3.1682],
        [-1.1672, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023027120158076286
Epoch 0, Step 83: train/loss = 0.5416731238365173, train/raw-loss = 0.3116527497768402, train/logprobs = tensor([[-0.9992, -4.3487],
        [-0.6404, -1.3220]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030669385567307472
Epoch 0, Step 84: train/loss = 0.5820839405059814, train/raw-loss = 0.3838422894477844, train/logprobs = tensor([[-0.7181, -4.3923],
        [-0.5322, -1.8090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02643221989274025
Epoch 0, Step 85: train/loss = 0.6308668851852417, train/raw-loss = 0.39514219760894775, train/logprobs = tensor([[-1.6940, -6.5695],
        [-0.8971, -1.7102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0314299575984478
Epoch 0, Step 86: train/loss = 0.6131985187530518, train/raw-loss = 0.337113618850708, train/logprobs = tensor([[-1.0955, -4.3766],
        [-0.6269, -1.5409]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03681132197380066
Epoch 0, Step 87: train/loss = 0.6751827597618103, train/raw-loss = 0.38416606187820435, train/logprobs = tensor([[-1.8899, -3.9234],
        [-1.4491, -1.1937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03880222886800766
Epoch 0, Step 88: train/loss = 0.49319902062416077, train/raw-loss = 0.27213525772094727, train/logprobs = tensor([[-1.5795, -6.1702],
        [-0.9919, -1.8284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029475171118974686
Epoch 0, Step 89: train/loss = 0.5518108606338501, train/raw-loss = 0.3237658143043518, train/logprobs = tensor([[-1.6232, -5.2534],
        [-1.1354, -1.6566]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030406009405851364
Epoch 0, Step 90: train/loss = 0.6191525459289551, train/raw-loss = 0.35818469524383545, train/logprobs = tensor([[-1.4240, -4.6375],
        [-0.9092, -1.5485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034795716404914856
Epoch 0, Step 91: train/loss = 0.8742749691009521, train/raw-loss = 0.6016989946365356, train/logprobs = tensor([[-2.4168, -2.6134],
        [-1.4016, -1.1245]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036343470215797424
Epoch 0, Step 92: train/loss = 0.684330940246582, train/raw-loss = 0.41695907711982727, train/logprobs = tensor([[-1.2210, -3.9227],
        [-0.9922, -1.5845]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035649582743644714
Epoch 0, Step 93: train/loss = 0.6738271713256836, train/raw-loss = 0.3864744305610657, train/logprobs = tensor([[-1.4725, -3.2975],
        [-1.1876, -1.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03831370174884796
Epoch 0, Step 94: train/loss = 0.5635825395584106, train/raw-loss = 0.29617631435394287, train/logprobs = tensor([[-1.6135, -7.0786],
        [-1.3245, -2.4937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035654161125421524
Epoch 0, Step 95: train/loss = 0.6902844905853271, train/raw-loss = 0.4980712831020355, train/logprobs = tensor([[-2.0528, -4.0710],
        [-1.5262, -1.9131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025628428906202316
Epoch 0, Step 96: train/loss = 0.6009552478790283, train/raw-loss = 0.3858555555343628, train/logprobs = tensor([[-1.2588, -4.0371],
        [-0.8851, -1.4429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028679953888058662
Epoch 0, Step 97: train/loss = 0.6698681116104126, train/raw-loss = 0.4894629716873169, train/logprobs = tensor([[-2.1553, -5.8410],
        [-1.7976, -2.4364]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024054016917943954
Epoch 0, Step 98: train/loss = 0.6045413613319397, train/raw-loss = 0.4076308012008667, train/logprobs = tensor([[-1.9346, -4.3377],
        [-1.1426, -1.3473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026254737749695778
Epoch 0, Step 99: train/loss = 0.5817108750343323, train/raw-loss = 0.41309821605682373, train/logprobs = tensor([[-1.3165, -4.6447],
        [-0.8437, -1.5241]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022481689229607582
Epoch 0, Step 100: train/loss = 0.6426831483840942, train/raw-loss = 0.41881874203681946, train/logprobs = tensor([[-1.5161, -3.1884],
        [-1.0086, -1.0656]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02984858676791191
Epoch 0, Step 101: train/loss = 0.7036886215209961, train/raw-loss = 0.5006374716758728, train/logprobs = tensor([[-2.0706, -4.0917],
        [-0.9888, -2.0282]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027073485776782036
Epoch 0, Step 102: train/loss = 0.5597524046897888, train/raw-loss = 0.37381869554519653, train/logprobs = tensor([[-1.0930, -4.0177],
        [-0.7233, -1.5341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024791169911623
Epoch 0, Step 103: train/loss = 0.51301509141922, train/raw-loss = 0.34868332743644714, train/logprobs = tensor([[-1.2084, -4.8795],
        [-0.8979, -1.3955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021910902112722397
Epoch 0, Step 104: train/loss = 0.5546468496322632, train/raw-loss = 0.41491109132766724, train/logprobs = tensor([[-1.3873, -3.8591],
        [-0.7685, -1.2114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.018631434068083763
Epoch 0, Step 105: train/loss = 0.570146918296814, train/raw-loss = 0.41123420000076294, train/logprobs = tensor([[-1.7341, -4.8204],
        [-0.9728, -1.5461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02118835598230362
Epoch 0, Step 106: train/loss = 0.5222818851470947, train/raw-loss = 0.3771933913230896, train/logprobs = tensor([[-1.2041, -5.6390],
        [-0.6634, -1.3234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019345128908753395
Epoch 0, Step 107: train/loss = 0.6273810267448425, train/raw-loss = 0.42062100768089294, train/logprobs = tensor([[-2.1637, -4.1661],
        [-1.2706, -1.4430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02756800875067711
Epoch 0, Step 108: train/loss = 0.8040423393249512, train/raw-loss = 0.6439543962478638, train/logprobs = tensor([[-1.0385, -1.3525],
        [-0.6685, -0.7446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021345051005482674
Epoch 0, Step 109: train/loss = 0.4817078113555908, train/raw-loss = 0.2897432744503021, train/logprobs = tensor([[-1.3772, -6.0300],
        [-0.7924, -1.1810]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025595271959900856
Epoch 0, Step 110: train/loss = 0.5725437998771667, train/raw-loss = 0.392605721950531, train/logprobs = tensor([[-1.7517, -5.3771],
        [-0.8042, -1.5411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023991743102669716
Epoch 0, Step 111: train/loss = 0.6961452960968018, train/raw-loss = 0.503532886505127, train/logprobs = tensor([[-1.5266, -3.3554],
        [-0.9755, -1.7996]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02568165585398674
Epoch 0, Step 112: train/loss = 0.7744361162185669, train/raw-loss = 0.5911698341369629, train/logprobs = tensor([[-2.0811, -2.4365],
        [-1.4456, -1.2563]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02443550154566765
Epoch 0, Step 113: train/loss = 0.7264801859855652, train/raw-loss = 0.5159202218055725, train/logprobs = tensor([[-1.5070, -2.5081],
        [-1.0704, -1.1629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028074659407138824
Epoch 0, Step 114: train/loss = 0.5797576904296875, train/raw-loss = 0.38400399684906006, train/logprobs = tensor([[-1.4585, -3.4085],
        [-0.9183, -0.7969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02610049396753311
Epoch 0, Step 115: train/loss = 0.5406802296638489, train/raw-loss = 0.3468870222568512, train/logprobs = tensor([[-1.6777, -5.2736],
        [-0.7462, -1.3147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025839094072580338
Epoch 0, Step 116: train/loss = 0.6688363552093506, train/raw-loss = 0.4525723457336426, train/logprobs = tensor([[-1.1325, -4.8762],
        [-0.5545, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028835207223892212
Epoch 0, Step 117: train/loss = 0.5154611468315125, train/raw-loss = 0.3492223024368286, train/logprobs = tensor([[-1.3375, -3.8007],
        [-0.9007, -1.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02216518111526966
Epoch 0, Step 118: train/loss = 0.5375734567642212, train/raw-loss = 0.3277914524078369, train/logprobs = tensor([[-1.4058, -5.8157],
        [-0.9933, -1.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0279709305614233
Epoch 0, Step 119: train/loss = 0.6164273023605347, train/raw-loss = 0.41565120220184326, train/logprobs = tensor([[-2.3621, -4.0790],
        [-1.3635, -1.5596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02677014283835888
Epoch 0, Step 120: train/loss = 0.5623623132705688, train/raw-loss = 0.35808196663856506, train/logprobs = tensor([[-1.9800, -7.7264],
        [-1.1028, -1.7024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02723737806081772
Epoch 0, Step 121: train/loss = 0.6308401823043823, train/raw-loss = 0.4637061655521393, train/logprobs = tensor([[-1.5028, -4.0886],
        [-0.7053, -0.9091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022284522652626038
Epoch 0, Step 122: train/loss = 0.5336461067199707, train/raw-loss = 0.3046559691429138, train/logprobs = tensor([[-1.2472, -8.6083],
        [-0.8802, -2.3575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030532026663422585
Epoch 0, Step 123: train/loss = 0.633286714553833, train/raw-loss = 0.4158460795879364, train/logprobs = tensor([[-1.8642, -3.9815],
        [-1.2346, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02899208664894104
Epoch 0, Step 124: train/loss = 0.5695491433143616, train/raw-loss = 0.3447781205177307, train/logprobs = tensor([[-1.0245, -4.2292],
        [-0.5762, -1.1598]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0299694687128067
Epoch 0, Step 125: train/loss = 0.5029798150062561, train/raw-loss = 0.28182655572891235, train/logprobs = tensor([[-1.7244, -7.0769],
        [-0.9540, -2.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02948709949851036
Epoch 0, Step 126: train/loss = 0.6642258167266846, train/raw-loss = 0.44674625992774963, train/logprobs = tensor([[-1.5716, -7.4801],
        [-1.2392, -2.6305]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028997275978326797
Epoch 0, Step 127: train/loss = 0.5841473340988159, train/raw-loss = 0.34209299087524414, train/logprobs = tensor([[-1.9905, -5.2744],
        [-0.9791, -1.3742]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03227391093969345
Epoch 0, Step 128: train/loss = 0.7254031896591187, train/raw-loss = 0.49500754475593567, train/logprobs = tensor([[-1.3781, -3.0084],
        [-0.8999, -1.4019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030719418078660965
Epoch 0, Step 129: train/loss = 0.647177517414093, train/raw-loss = 0.4293665885925293, train/logprobs = tensor([[-1.9769, -5.0723],
        [-1.0763, -1.5404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029041459783911705
Epoch 0, Step 130: train/loss = 0.6481214761734009, train/raw-loss = 0.38544997572898865, train/logprobs = tensor([[-2.5150, -8.3062],
        [-0.9803, -2.2966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03502286225557327
Epoch 0, Step 131: train/loss = 0.9737670421600342, train/raw-loss = 0.7896726727485657, train/logprobs = tensor([[-4.0127, -3.5029],
        [-1.5172, -1.2721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024545913562178612
Epoch 0, Step 132: train/loss = 0.6924725770950317, train/raw-loss = 0.4323123097419739, train/logprobs = tensor([[-1.1136, -3.3833],
        [-1.0059, -1.6458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034688036888837814
Epoch 0, Step 133: train/loss = 0.48282477259635925, train/raw-loss = 0.283826619386673, train/logprobs = tensor([[-2.4066, -6.9573],
        [-1.4714, -1.3831]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026533087715506554
Epoch 0, Step 134: train/loss = 0.5577820539474487, train/raw-loss = 0.35458165407180786, train/logprobs = tensor([[-1.6372, -6.9485],
        [-1.0134, -1.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02709338627755642
Epoch 0, Step 135: train/loss = 0.7536149621009827, train/raw-loss = 0.48958680033683777, train/logprobs = tensor([[-3.2385, -4.1975],
        [-1.6095, -1.3852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03520376235246658
Epoch 0, Step 136: train/loss = 0.5555470585823059, train/raw-loss = 0.3105649948120117, train/logprobs = tensor([[-2.4895, -7.2221],
        [-1.5397, -1.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03266427665948868
Epoch 0, Step 137: train/loss = 0.6924537420272827, train/raw-loss = 0.4511473774909973, train/logprobs = tensor([[-2.5919, -4.8276],
        [-1.6712, -1.1746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032174188643693924
Epoch 0, Step 138: train/loss = 0.6649898290634155, train/raw-loss = 0.4506080746650696, train/logprobs = tensor([[-2.2745, -4.4498],
        [-0.9882, -1.4541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028584228828549385
Epoch 0, Step 139: train/loss = 0.6332706809043884, train/raw-loss = 0.369958758354187, train/logprobs = tensor([[-1.8565, -4.7518],
        [-1.1814, -2.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03510825335979462
Epoch 0, Step 140: train/loss = 0.6836138963699341, train/raw-loss = 0.4519297480583191, train/logprobs = tensor([[-2.2601, -5.9999],
        [-1.0151, -1.9001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03089122474193573
Epoch 0, Step 141: train/loss = 0.6399914026260376, train/raw-loss = 0.4124314785003662, train/logprobs = tensor([[-1.7107, -5.0858],
        [-0.8602, -1.7842]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030341316014528275
Epoch 0, Step 142: train/loss = 0.5653688311576843, train/raw-loss = 0.3154343366622925, train/logprobs = tensor([[-2.4549, -6.7687],
        [-1.3781, -1.4582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033324599266052246
Epoch 0, Step 143: train/loss = 0.6908762454986572, train/raw-loss = 0.4010601341724396, train/logprobs = tensor([[-2.2675, -4.9473],
        [-1.5969, -1.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03864215314388275
Epoch 0, Step 144: train/loss = 0.5945670008659363, train/raw-loss = 0.4042711853981018, train/logprobs = tensor([[-1.9607, -4.8213],
        [-0.9284, -1.5312]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02537277713418007
Epoch 0, Step 145: train/loss = 0.956652820110321, train/raw-loss = 0.6448280811309814, train/logprobs = tensor([[-2.0174, -2.6489],
        [-1.2783, -1.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04157662019133568
Epoch 0, Step 146: train/loss = 0.568810224533081, train/raw-loss = 0.38161367177963257, train/logprobs = tensor([[-1.5550, -4.5773],
        [-0.8043, -1.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024959538131952286
Epoch 0, Step 147: train/loss = 0.6906018257141113, train/raw-loss = 0.4643741250038147, train/logprobs = tensor([[-2.5652, -5.5484],
        [-1.3002, -1.9366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030163690447807312
Epoch 0, Step 148: train/loss = 0.6630322337150574, train/raw-loss = 0.46861085295677185, train/logprobs = tensor([[-1.8699, -3.7505],
        [-1.1405, -1.3363]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025922849774360657
Epoch 0, Step 149: train/loss = 0.7760969996452332, train/raw-loss = 0.5143590569496155, train/logprobs = tensor([[-1.7291, -3.6084],
        [-0.9103, -1.5117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03489840030670166
Epoch 0, Step 150: train/loss = 0.6409673690795898, train/raw-loss = 0.4903606176376343, train/logprobs = tensor([[-1.9141, -3.7292],
        [-1.0613, -1.5898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020080897957086563
Epoch 0, Step 151: train/loss = 0.6609336137771606, train/raw-loss = 0.44096803665161133, train/logprobs = tensor([[-1.6342, -5.4101],
        [-0.9595, -1.3650]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029328742995858192
Epoch 0, Step 152: train/loss = 0.6135095357894897, train/raw-loss = 0.39989662170410156, train/logprobs = tensor([[-1.5643, -5.6641],
        [-0.8613, -1.4717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02848172001540661
Epoch 0, Step 153: train/loss = 0.7314245700836182, train/raw-loss = 0.5153112411499023, train/logprobs = tensor([[-2.9902, -5.8809],
        [-1.1095, -1.5018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02881511114537716
Epoch 0, Step 154: train/loss = 0.5728298425674438, train/raw-loss = 0.35767585039138794, train/logprobs = tensor([[-2.7320, -6.5960],
        [-1.4968, -1.7671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02868720516562462
Epoch 0, Step 155: train/loss = 0.5856717824935913, train/raw-loss = 0.4026355743408203, train/logprobs = tensor([[-1.3257, -3.8910],
        [-0.8295, -1.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024404827505350113
Epoch 0, Step 156: train/loss = 0.5160212516784668, train/raw-loss = 0.2817579209804535, train/logprobs = tensor([[-1.7736, -7.3068],
        [-1.1113, -2.0395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031235113739967346
Epoch 0, Step 157: train/loss = 0.6498585939407349, train/raw-loss = 0.4638572335243225, train/logprobs = tensor([[-1.6722, -3.5046],
        [-0.9390, -1.0400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02480018511414528
Epoch 0, Step 158: train/loss = 0.691606342792511, train/raw-loss = 0.49420130252838135, train/logprobs = tensor([[-1.5188, -2.5982],
        [-0.7963, -0.6438]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026320666074752808
Epoch 0, Step 159: train/loss = 0.6435315012931824, train/raw-loss = 0.43331092596054077, train/logprobs = tensor([[-1.5709, -3.6885],
        [-1.1257, -1.1349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028029413893818855
Epoch 0, Step 160: train/loss = 0.7771844267845154, train/raw-loss = 0.5246477127075195, train/logprobs = tensor([[-1.5431, -4.0809],
        [-0.8900, -1.1847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03367156162858009
Epoch 0, Step 161: train/loss = 0.6374278664588928, train/raw-loss = 0.39159107208251953, train/logprobs = tensor([[-1.3902, -4.6009],
        [-1.0547, -1.8114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032778240740299225
Epoch 0, Step 162: train/loss = 0.46443408727645874, train/raw-loss = 0.275259792804718, train/logprobs = tensor([[-1.3189, -7.8192],
        [-0.7240, -2.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02522323839366436
Epoch 0, Step 163: train/loss = 0.5357410907745361, train/raw-loss = 0.3448600172996521, train/logprobs = tensor([[-2.1890, -4.9201],
        [-1.2372, -1.5276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025450818240642548
Epoch 0, Step 164: train/loss = 0.673244297504425, train/raw-loss = 0.4297914206981659, train/logprobs = tensor([[-2.1340, -3.2528],
        [-1.7274, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03246038034558296
Epoch 0, Step 165: train/loss = 0.5634044408798218, train/raw-loss = 0.3638257682323456, train/logprobs = tensor([[-1.9996, -5.4398],
        [-1.1370, -1.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026610491797327995
Epoch 0, Step 166: train/loss = 0.4939866065979004, train/raw-loss = 0.30759745836257935, train/logprobs = tensor([[-1.8071, -6.5719],
        [-0.9433, -2.2206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024851888418197632
Epoch 0, Step 167: train/loss = 0.5910232067108154, train/raw-loss = 0.3548455834388733, train/logprobs = tensor([[-1.8655, -3.9869],
        [-1.3530, -1.0643]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031490348279476166
Epoch 0, Step 168: train/loss = 0.5725245475769043, train/raw-loss = 0.3776927590370178, train/logprobs = tensor([[-1.2558, -4.0533],
        [-1.1906, -1.3367]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025977566838264465
Epoch 0, Step 169: train/loss = 0.6630174517631531, train/raw-loss = 0.4529203474521637, train/logprobs = tensor([[-1.6343, -4.3164],
        [-0.9380, -1.5630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028012944385409355
Epoch 0, Step 170: train/loss = 0.5554035902023315, train/raw-loss = 0.36551591753959656, train/logprobs = tensor([[-1.1989, -5.7339],
        [-0.6017, -1.6003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02531835064291954
Epoch 0, Step 171: train/loss = 0.551753580570221, train/raw-loss = 0.33628979325294495, train/logprobs = tensor([[-2.1321, -4.4988],
        [-1.4038, -1.3544]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028728501871228218
Epoch 0, Step 172: train/loss = 0.5373172760009766, train/raw-loss = 0.2957909405231476, train/logprobs = tensor([[-1.7970, -5.4850],
        [-1.1166, -1.4708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032203514128923416
Epoch 0, Step 173: train/loss = 0.4995609521865845, train/raw-loss = 0.2853226065635681, train/logprobs = tensor([[-1.6917, -7.7153],
        [-1.4870, -2.2429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02856511063873768
Epoch 0, Step 174: train/loss = 0.4969881772994995, train/raw-loss = 0.29351863265037537, train/logprobs = tensor([[ -2.6824, -12.1768],
        [ -1.4117,  -2.3074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0271292757242918
Epoch 0, Step 175: train/loss = 0.6858797073364258, train/raw-loss = 0.46205902099609375, train/logprobs = tensor([[-2.5897, -3.9450],
        [-1.4683, -1.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029842745512723923
Epoch 0, Step 176: train/loss = 0.5273735523223877, train/raw-loss = 0.3284527063369751, train/logprobs = tensor([[-1.7636, -5.3011],
        [-0.8892, -1.4943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02652277611196041
Epoch 0, Step 177: train/loss = 0.5255663394927979, train/raw-loss = 0.3574106991291046, train/logprobs = tensor([[-1.3918, -3.8894],
        [-1.1749, -1.4169]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022420750930905342
Epoch 0, Step 178: train/loss = 0.6353697180747986, train/raw-loss = 0.4287708103656769, train/logprobs = tensor([[-1.5472, -5.1095],
        [-0.7822, -1.7304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02754652500152588
Epoch 0, Step 179: train/loss = 0.47161245346069336, train/raw-loss = 0.29813113808631897, train/logprobs = tensor([[-2.0926, -7.0621],
        [-1.4584, -1.6660]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02313084341585636
Epoch 0, Step 180: train/loss = 0.6684775948524475, train/raw-loss = 0.4488108456134796, train/logprobs = tensor([[-2.0778, -4.2165],
        [-1.3194, -1.3009]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029288901016116142
Epoch 0, Step 181: train/loss = 0.5871120095252991, train/raw-loss = 0.39141130447387695, train/logprobs = tensor([[-1.2905, -4.4229],
        [-1.1481, -1.5023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02609342709183693
Epoch 0, Step 182: train/loss = 0.671534538269043, train/raw-loss = 0.5062589645385742, train/logprobs = tensor([[-2.0815, -4.9430],
        [-1.0638, -1.2787]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022036738693714142
Epoch 0, Step 183: train/loss = 0.6011221408843994, train/raw-loss = 0.3508059084415436, train/logprobs = tensor([[-1.5790, -7.9685],
        [-1.1456, -1.4804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03337549790740013
Epoch 0, Step 184: train/loss = 0.5918928384780884, train/raw-loss = 0.36704152822494507, train/logprobs = tensor([[-1.3684, -6.1602],
        [-1.0638, -1.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029980169609189034
Epoch 0, Step 185: train/loss = 0.5804684162139893, train/raw-loss = 0.37734103202819824, train/logprobs = tensor([[-1.7113, -8.4738],
        [-0.9387, -1.3577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02708364836871624
Epoch 0, Step 186: train/loss = 0.5124297142028809, train/raw-loss = 0.34283098578453064, train/logprobs = tensor([[-1.4219, -6.0346],
        [-0.8262, -1.3697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022613167762756348
Epoch 0, Step 187: train/loss = 0.7402348518371582, train/raw-loss = 0.5033409595489502, train/logprobs = tensor([[-1.6510, -3.0482],
        [-0.9950, -1.3989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031585853546857834
Epoch 0, Step 188: train/loss = 0.6236859560012817, train/raw-loss = 0.4124521017074585, train/logprobs = tensor([[-2.6686, -4.9947],
        [-1.2968, -1.5722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028164517134428024
Epoch 0, Step 189: train/loss = 0.8597842454910278, train/raw-loss = 0.6113632917404175, train/logprobs = tensor([[-1.7826, -2.8650],
        [-1.0640, -1.6521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033122800290584564
Epoch 0, Step 190: train/loss = 0.5366042256355286, train/raw-loss = 0.33559566736221313, train/logprobs = tensor([[-2.4899, -5.0998],
        [-1.9247, -1.2796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02680114284157753
Epoch 0, Step 191: train/loss = 0.6172433495521545, train/raw-loss = 0.35519111156463623, train/logprobs = tensor([[-2.0280, -6.2883],
        [-1.3695, -1.3134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03494029492139816
Epoch 0, Step 192: train/loss = 0.5286152958869934, train/raw-loss = 0.33762383460998535, train/logprobs = tensor([[-1.9278, -4.7696],
        [-1.3043, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025465531274676323
Epoch 0, Step 193: train/loss = 0.6274100542068481, train/raw-loss = 0.47856980562210083, train/logprobs = tensor([[-1.4596, -3.4961],
        [-0.6661, -1.0144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01984536275267601
Epoch 0, Step 194: train/loss = 0.5940102338790894, train/raw-loss = 0.40497663617134094, train/logprobs = tensor([[-1.5114, -2.7408],
        [-1.3638, -0.9083]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025204475969076157
Epoch 0, Step 195: train/loss = 0.5968199968338013, train/raw-loss = 0.42548486590385437, train/logprobs = tensor([[-0.9779, -3.2791],
        [-0.6185, -1.1976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02284468337893486
Epoch 0, Step 196: train/loss = 0.5377976894378662, train/raw-loss = 0.3452552556991577, train/logprobs = tensor([[-2.4334, -5.6085],
        [-1.4014, -1.8380]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025672322139143944
Epoch 0, Step 197: train/loss = 0.5983802080154419, train/raw-loss = 0.38949358463287354, train/logprobs = tensor([[-1.8007, -5.4461],
        [-1.2119, -1.0526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027851544320583344
Epoch 0, Step 198: train/loss = 0.6610652804374695, train/raw-loss = 0.4041314125061035, train/logprobs = tensor([[-1.3093, -2.9925],
        [-1.1423, -0.9262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03425785154104233
Epoch 0, Step 199: train/loss = 0.6558874249458313, train/raw-loss = 0.4945111572742462, train/logprobs = tensor([[-1.4682, -3.4725],
        [-1.0431, -0.9150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021516837179660797
Epoch 0, Step 200: train/loss = 0.48053014278411865, train/raw-loss = 0.26362621784210205, train/logprobs = tensor([[-2.0484, -7.9936],
        [-1.3169, -1.6015]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028920523822307587
Epoch 0, Step 201: train/loss = 0.4316282570362091, train/raw-loss = 0.2577194273471832, train/logprobs = tensor([[-1.1817, -6.2577],
        [-0.6140, -1.3266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023187844082713127
Epoch 0, Step 202: train/loss = 0.572979211807251, train/raw-loss = 0.36912864446640015, train/logprobs = tensor([[-1.0075, -5.7073],
        [-0.6480, -1.4602]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02718007005751133
Epoch 0, Step 203: train/loss = 0.5677534937858582, train/raw-loss = 0.3601365089416504, train/logprobs = tensor([[-1.7996, -3.7246],
        [-1.3243, -0.9855]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027682267129421234
Epoch 0, Step 204: train/loss = 0.5040008425712585, train/raw-loss = 0.33862537145614624, train/logprobs = tensor([[-2.0461, -4.7371],
        [-1.4729, -1.1816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02205006033182144
Epoch 0, Step 205: train/loss = 0.6993718147277832, train/raw-loss = 0.3610869348049164, train/logprobs = tensor([[-1.2124, -5.8702],
        [-0.7380, -1.2105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.045104656368494034
Epoch 0, Step 206: train/loss = 0.6373992562294006, train/raw-loss = 0.49272584915161133, train/logprobs = tensor([[-1.5295, -4.7316],
        [-0.9108, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.019289791584014893
Epoch 0, Step 207: train/loss = 0.5858525037765503, train/raw-loss = 0.4161863327026367, train/logprobs = tensor([[-1.8665, -6.0847],
        [-0.9072, -1.7061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022622158750891685
Epoch 0, Step 208: train/loss = 0.5006422996520996, train/raw-loss = 0.25921112298965454, train/logprobs = tensor([[-1.4836, -6.1227],
        [-1.8014, -2.1116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03219082951545715
Epoch 0, Step 209: train/loss = 0.4927372932434082, train/raw-loss = 0.32623040676116943, train/logprobs = tensor([[-1.4509, -7.5253],
        [-1.1829, -1.8271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022200919687747955
Epoch 0, Step 210: train/loss = 0.5327223539352417, train/raw-loss = 0.3397023677825928, train/logprobs = tensor([[-2.0783, -4.9129],
        [-2.2574, -1.4608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025735989212989807
Epoch 0, Step 211: train/loss = 0.4745808243751526, train/raw-loss = 0.24885112047195435, train/logprobs = tensor([[-1.8135, -6.6522],
        [-1.3688, -1.6959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030097294598817825
Epoch 0, Step 212: train/loss = 0.610493540763855, train/raw-loss = 0.45474404096603394, train/logprobs = tensor([[-1.8309, -3.4763],
        [-0.7843, -1.0225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02076660469174385
Epoch 0, Step 213: train/loss = 0.4479916989803314, train/raw-loss = 0.2239840030670166, train/logprobs = tensor([[-1.9131, -6.1177],
        [-1.7976, -1.4594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02986769750714302
Epoch 0, Step 214: train/loss = 0.6355749368667603, train/raw-loss = 0.47006839513778687, train/logprobs = tensor([[-1.6814, -3.8438],
        [-1.0601, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022067533805966377
Epoch 0, Step 215: train/loss = 0.6163623929023743, train/raw-loss = 0.41401007771492004, train/logprobs = tensor([[-1.5533, -3.6296],
        [-1.1093, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02698030322790146
Epoch 0, Step 216: train/loss = 0.7269644141197205, train/raw-loss = 0.5733374953269958, train/logprobs = tensor([[-2.1732, -2.6240],
        [-1.5147, -1.4440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020483586937189102
Epoch 0, Step 217: train/loss = 0.5757573246955872, train/raw-loss = 0.3885740041732788, train/logprobs = tensor([[-1.4145, -4.1436],
        [-1.1744, -1.4316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024957776069641113
Epoch 0, Step 218: train/loss = 0.5121123194694519, train/raw-loss = 0.2795946002006531, train/logprobs = tensor([[-1.2321, -8.1505],
        [-1.1695, -1.6384]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031002357602119446
Epoch 0, Step 219: train/loss = 0.7875924110412598, train/raw-loss = 0.5335986614227295, train/logprobs = tensor([[-0.9292, -2.7089],
        [-0.9102, -0.8306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03386583924293518
Epoch 0, Step 220: train/loss = 0.5232678055763245, train/raw-loss = 0.19794663786888123, train/logprobs = tensor([[-1.7993, -9.1951],
        [-1.9463, -2.5737]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04337615892291069
Epoch 0, Step 221: train/loss = 0.7396732568740845, train/raw-loss = 0.5014905333518982, train/logprobs = tensor([[-2.5321, -2.5531],
        [-2.1291, -0.5947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03175769001245499
Epoch 0, Step 222: train/loss = 0.6760753393173218, train/raw-loss = 0.4370638430118561, train/logprobs = tensor([[-1.7519, -5.3168],
        [-1.0163, -1.1702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03186819702386856
Epoch 0, Step 223: train/loss = 0.5560817718505859, train/raw-loss = 0.23909643292427063, train/logprobs = tensor([[-1.7194, -6.6994],
        [-1.6415, -1.5495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04226471483707428
Epoch 0, Step 224: train/loss = 0.5221725106239319, train/raw-loss = 0.25280722975730896, train/logprobs = tensor([[-2.3150, -7.2110],
        [-1.8756, -2.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035915374755859375
Epoch 0, Step 225: train/loss = 0.5659583806991577, train/raw-loss = 0.31669965386390686, train/logprobs = tensor([[-1.0789, -4.8434],
        [-0.7790, -1.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033234503120183945
Epoch 0, Step 226: train/loss = 0.47231191396713257, train/raw-loss = 0.23483482003211975, train/logprobs = tensor([[-1.6138, -7.4458],
        [-1.3125, -2.0476]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03166361153125763
Epoch 0, Step 227: train/loss = 0.6450404524803162, train/raw-loss = 0.4325648546218872, train/logprobs = tensor([[-1.4649, -3.6099],
        [-0.8643, -1.3797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02833007648587227
Epoch 0, Step 228: train/loss = 0.6340045928955078, train/raw-loss = 0.4001563787460327, train/logprobs = tensor([[-1.8379, -6.0030],
        [-1.1772, -2.1624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0311797596514225
Epoch 0, Step 229: train/loss = 0.5767675042152405, train/raw-loss = 0.36769527196884155, train/logprobs = tensor([[-1.6302, -5.2297],
        [-1.3976, -1.5464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027876291424036026
Epoch 0, Step 230: train/loss = 0.4955819249153137, train/raw-loss = 0.30249786376953125, train/logprobs = tensor([[-1.6522, -7.4217],
        [-1.2866, -2.2690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025744548067450523
Epoch 0, Step 231: train/loss = 0.7012121677398682, train/raw-loss = 0.398632287979126, train/logprobs = tensor([[-1.7658, -3.1342],
        [-1.7735, -1.3472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.040343984961509705
Epoch 0, Step 232: train/loss = 0.5991846919059753, train/raw-loss = 0.3632977604866028, train/logprobs = tensor([[-1.4224, -4.5552],
        [-1.2801, -1.8577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03145159035921097
Epoch 0, Step 233: train/loss = 0.6213457584381104, train/raw-loss = 0.3839535117149353, train/logprobs = tensor([[-2.9677, -6.8437],
        [-2.0421, -1.6948]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0316522940993309
Epoch 0, Step 234: train/loss = 0.4666791558265686, train/raw-loss = 0.2542916238307953, train/logprobs = tensor([[-1.6332, -6.9703],
        [-1.9133, -1.8140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028318336233496666
Epoch 0, Step 235: train/loss = 0.5948265790939331, train/raw-loss = 0.4114210605621338, train/logprobs = tensor([[-2.1286, -4.5194],
        [-1.2875, -1.6388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02445407025516033
Epoch 0, Step 236: train/loss = 0.6485282778739929, train/raw-loss = 0.37796807289123535, train/logprobs = tensor([[-1.1032, -6.2894],
        [-0.7346, -1.1298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036074694246053696
Epoch 0, Step 237: train/loss = 0.6497904658317566, train/raw-loss = 0.4058094024658203, train/logprobs = tensor([[-1.2762, -3.1888],
        [-1.1770, -0.7677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032530806958675385
Epoch 0, Step 238: train/loss = 0.6536610722541809, train/raw-loss = 0.4037114977836609, train/logprobs = tensor([[-1.0692, -4.4863],
        [-0.7450, -1.4547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03332659974694252
Epoch 0, Step 239: train/loss = 0.7796105146408081, train/raw-loss = 0.5815240144729614, train/logprobs = tensor([[-2.7278, -2.9491],
        [-2.3128, -1.8397]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026411544531583786
Epoch 0, Step 240: train/loss = 0.6457353830337524, train/raw-loss = 0.39824923872947693, train/logprobs = tensor([[-1.9041, -4.4580],
        [-1.5821, -1.3395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03299814090132713
Epoch 0, Step 241: train/loss = 0.4783937335014343, train/raw-loss = 0.2657133936882019, train/logprobs = tensor([[-1.6146, -5.5261],
        [-1.5503, -1.7746]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028357379138469696
Epoch 0, Step 242: train/loss = 0.6059969067573547, train/raw-loss = 0.3420243561267853, train/logprobs = tensor([[-1.8728, -4.5775],
        [-2.4209, -1.8400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03519633412361145
Epoch 0, Step 243: train/loss = 0.45650631189346313, train/raw-loss = 0.2869589626789093, train/logprobs = tensor([[-2.0452, -5.5955],
        [-2.9107, -1.4633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022606316953897476
Epoch 0, Step 244: train/loss = 0.5245451927185059, train/raw-loss = 0.2807721197605133, train/logprobs = tensor([[-1.5526, -5.2347],
        [-1.0774, -1.3408]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032503075897693634
Epoch 0, Step 245: train/loss = 0.6015469431877136, train/raw-loss = 0.40595942735671997, train/logprobs = tensor([[-1.8585, -3.7496],
        [-1.7721, -1.6328]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02607833594083786
Epoch 0, Step 246: train/loss = 0.786881148815155, train/raw-loss = 0.49640321731567383, train/logprobs = tensor([[-1.8568, -3.5006],
        [-1.3488, -1.7114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03873039036989212
Epoch 0, Step 247: train/loss = 0.5184433460235596, train/raw-loss = 0.3120945692062378, train/logprobs = tensor([[-1.5239, -6.8298],
        [-0.9203, -1.4860]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027513179928064346
Epoch 0, Step 248: train/loss = 0.5636069774627686, train/raw-loss = 0.33714160323143005, train/logprobs = tensor([[-1.5182, -7.0999],
        [-1.1715, -1.9980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03019537776708603
Epoch 0, Step 249: train/loss = 0.5294952392578125, train/raw-loss = 0.30527186393737793, train/logprobs = tensor([[-2.1257, -3.5944],
        [-2.4757, -1.3578]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0298964511603117
Epoch 0, Step 250: train/loss = 0.4367744028568268, train/raw-loss = 0.24247212707996368, train/logprobs = tensor([[-0.9303, -8.0367],
        [-0.7045, -2.0502]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025906972587108612
Epoch 0, Step 251: train/loss = 0.663736879825592, train/raw-loss = 0.3937780261039734, train/logprobs = tensor([[-1.3582, -6.4083],
        [-1.0428, -2.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035994503647089005
Epoch 0, Step 252: train/loss = 0.7572050094604492, train/raw-loss = 0.543133556842804, train/logprobs = tensor([[-1.8748, -2.6441],
        [-1.0654, -0.9371]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028542861342430115
Epoch 0, Step 253: train/loss = 0.9910215735435486, train/raw-loss = 0.5806363224983215, train/logprobs = tensor([[-2.2806, -3.4022],
        [-1.5811, -1.7765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05471803620457649
Epoch 0, Step 254: train/loss = 0.6578192710876465, train/raw-loss = 0.39333078265190125, train/logprobs = tensor([[-1.6210, -3.7770],
        [-1.2425, -1.0198]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03526512533426285
Epoch 0, Step 255: train/loss = 0.5825057029724121, train/raw-loss = 0.26410600543022156, train/logprobs = tensor([[-1.0620, -5.4829],
        [-1.3679, -1.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04245329648256302
Epoch 0, Step 256: train/loss = 0.47620856761932373, train/raw-loss = 0.268815815448761, train/logprobs = tensor([[-1.4594, -6.3770],
        [-0.9013, -1.5818]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02765236422419548
Epoch 0, Step 257: train/loss = 0.5413973331451416, train/raw-loss = 0.3583872318267822, train/logprobs = tensor([[-2.4723, -6.2226],
        [-1.4567, -2.1261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02440134435892105
Epoch 0, Step 258: train/loss = 0.43489351868629456, train/raw-loss = 0.21172469854354858, train/logprobs = tensor([[-2.8650, -7.1427],
        [-2.9408, -1.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029755843803286552
Epoch 0, Step 259: train/loss = 0.7221882343292236, train/raw-loss = 0.5100104212760925, train/logprobs = tensor([[-2.2375, -2.8261],
        [-2.1125, -1.5433]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02829037979245186
Epoch 0, Step 260: train/loss = 0.5858878493309021, train/raw-loss = 0.38339805603027344, train/logprobs = tensor([[-2.0378, -4.9349],
        [-1.4880, -1.9431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02699863910675049
Epoch 0, Step 261: train/loss = 0.49140650033950806, train/raw-loss = 0.3150615692138672, train/logprobs = tensor([[-1.9844, -8.2718],
        [-0.8940, -1.8692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02351265773177147
Epoch 0, Step 262: train/loss = 0.6101422309875488, train/raw-loss = 0.4564424753189087, train/logprobs = tensor([[-3.8929, -6.3111],
        [-1.5668, -1.3507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02049330063164234
Epoch 0, Step 263: train/loss = 0.6777194738388062, train/raw-loss = 0.5005598664283752, train/logprobs = tensor([[-3.2377, -7.9656],
        [-2.2402, -2.8063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02362128160893917
Epoch 0, Step 264: train/loss = 0.4244306683540344, train/raw-loss = 0.27293455600738525, train/logprobs = tensor([[-2.1336, -8.1506],
        [-1.1178, -1.6500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020199477672576904
Epoch 0, Step 265: train/loss = 0.6070706248283386, train/raw-loss = 0.38915109634399414, train/logprobs = tensor([[-1.9538, -4.1762],
        [-2.0267, -2.1120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029055943712592125
Epoch 0, Step 266: train/loss = 0.6038543581962585, train/raw-loss = 0.4274023771286011, train/logprobs = tensor([[-2.5797, -3.3976],
        [-1.8224, -1.0234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023526934906840324
Epoch 0, Step 267: train/loss = 0.6047331094741821, train/raw-loss = 0.406319260597229, train/logprobs = tensor([[-2.1528, -5.3568],
        [-1.5818, -1.4844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02645518258213997
Epoch 0, Step 268: train/loss = 0.6421564817428589, train/raw-loss = 0.4161345660686493, train/logprobs = tensor([[-1.6163, -4.8766],
        [-1.9479, -1.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03013624995946884
Epoch 0, Step 269: train/loss = 0.6746436953544617, train/raw-loss = 0.49465975165367126, train/logprobs = tensor([[-1.3948, -4.5621],
        [-1.1984, -2.3460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02399785816669464
Epoch 0, Step 270: train/loss = 0.7260538339614868, train/raw-loss = 0.3965603709220886, train/logprobs = tensor([[-1.2320, -4.2658],
        [-0.8596, -1.7412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.043932463973760605
Epoch 0, Step 271: train/loss = 0.48846131563186646, train/raw-loss = 0.26969364285469055, train/logprobs = tensor([[-1.1109, -6.2883],
        [-0.7533, -1.7161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029169026762247086
Epoch 0, Step 272: train/loss = 0.6452078223228455, train/raw-loss = 0.40958359837532043, train/logprobs = tensor([[-1.5178, -3.9029],
        [-1.0788, -1.6750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03141656517982483
Epoch 0, Step 273: train/loss = 0.5800672173500061, train/raw-loss = 0.25961679220199585, train/logprobs = tensor([[-0.9318, -7.1640],
        [-0.5191, -1.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042726725339889526
Epoch 0, Step 274: train/loss = 0.6087771654129028, train/raw-loss = 0.38947901129722595, train/logprobs = tensor([[-2.0989, -6.2519],
        [-1.6715, -1.5237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029239758849143982
Epoch 0, Step 275: train/loss = 0.5490257143974304, train/raw-loss = 0.32684463262557983, train/logprobs = tensor([[-1.7935, -6.6450],
        [-1.6091, -2.4266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029624145478010178
Epoch 0, Step 276: train/loss = 0.4363948702812195, train/raw-loss = 0.2115890234708786, train/logprobs = tensor([[-0.9364, -9.3226],
        [-0.9577, -2.5642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029974114149808884
Epoch 0, Step 277: train/loss = 0.4897330105304718, train/raw-loss = 0.2575387954711914, train/logprobs = tensor([[-2.3181, -6.6312],
        [-2.7345, -2.1619]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030959228053689003
Epoch 0, Step 278: train/loss = 0.4148375988006592, train/raw-loss = 0.18852369487285614, train/logprobs = tensor([[ -2.0944, -10.5457],
        [ -2.6864,  -2.8541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030175184831023216
Epoch 0, Step 279: train/loss = 0.6702562570571899, train/raw-loss = 0.4945630729198456, train/logprobs = tensor([[-3.1172, -5.6988],
        [-1.4660, -1.9439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023425763472914696
Epoch 0, Step 280: train/loss = 0.5141780376434326, train/raw-loss = 0.21094465255737305, train/logprobs = tensor([[-1.5545, -5.7437],
        [-1.6898, -1.6314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04043111950159073
Epoch 0, Step 281: train/loss = 0.6119114756584167, train/raw-loss = 0.4220418632030487, train/logprobs = tensor([[-2.7986, -4.4183],
        [-2.5016, -1.7000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025315947830677032
Epoch 0, Step 282: train/loss = 0.6352733373641968, train/raw-loss = 0.46438708901405334, train/logprobs = tensor([[-1.2379, -4.8049],
        [-0.6704, -1.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022784831002354622
Epoch 0, Step 283: train/loss = 0.42210155725479126, train/raw-loss = 0.1942622810602188, train/logprobs = tensor([[-0.9941, -6.9052],
        [-1.3139, -2.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030378570780158043
Epoch 0, Step 284: train/loss = 0.6156136989593506, train/raw-loss = 0.371413916349411, train/logprobs = tensor([[-1.0779, -3.2225],
        [-1.3840, -1.2536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032559964805841446
Epoch 0, Step 285: train/loss = 0.4731197953224182, train/raw-loss = 0.23899075388908386, train/logprobs = tensor([[-1.5418, -6.0213],
        [-1.6136, -2.4728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03121720626950264
Epoch 0, Step 286: train/loss = 0.5937169790267944, train/raw-loss = 0.35234469175338745, train/logprobs = tensor([[-1.0113, -3.2775],
        [-1.5412, -1.5257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0321829691529274
Epoch 0, Step 287: train/loss = 0.6320316791534424, train/raw-loss = 0.33855974674224854, train/logprobs = tensor([[-1.5350, -2.4112],
        [-2.6047, -1.1372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039129588752985
Epoch 0, Step 288: train/loss = 0.37832510471343994, train/raw-loss = 0.12901140749454498, train/logprobs = tensor([[-1.9836, -9.2446],
        [-3.6376, -3.6805]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03324183076620102
Epoch 0, Step 289: train/loss = 0.6697469353675842, train/raw-loss = 0.49320119619369507, train/logprobs = tensor([[-1.6378, -3.1007],
        [-2.0675, -1.8436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023539436981081963
Epoch 0, Step 290: train/loss = 0.6672350764274597, train/raw-loss = 0.4824935793876648, train/logprobs = tensor([[-2.3936, -5.0782],
        [-0.9940, -1.5050]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024632198736071587
Epoch 0, Step 291: train/loss = 0.5992892980575562, train/raw-loss = 0.39976805448532104, train/logprobs = tensor([[-1.5321, -3.9303],
        [-1.0976, -0.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026602834463119507
Epoch 0, Step 292: train/loss = 0.47581201791763306, train/raw-loss = 0.2864222228527069, train/logprobs = tensor([[-1.7248, -6.5504],
        [-1.1475, -1.3868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025251969695091248
Epoch 0, Step 293: train/loss = 0.4711655080318451, train/raw-loss = 0.20350174605846405, train/logprobs = tensor([[-1.1173, -6.3585],
        [-1.4715, -1.8804]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035688504576683044
Epoch 0, Step 294: train/loss = 0.6576298475265503, train/raw-loss = 0.45368897914886475, train/logprobs = tensor([[-1.5585, -4.7184],
        [-1.2404, -2.2688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027192113921046257
Epoch 0, Step 295: train/loss = 0.572645902633667, train/raw-loss = 0.34368884563446045, train/logprobs = tensor([[-2.1440, -3.6174],
        [-3.3830, -2.2781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03052760660648346
Epoch 0, Step 296: train/loss = 0.3368816673755646, train/raw-loss = 0.15173044800758362, train/logprobs = tensor([[ -1.5254, -10.0225],
        [ -2.4651,  -2.1178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02468683011829853
Epoch 0, Step 297: train/loss = 0.6982369422912598, train/raw-loss = 0.4668746292591095, train/logprobs = tensor([[-2.2837, -5.8496],
        [-1.6355, -2.1583]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0308483075350523
Epoch 0, Step 298: train/loss = 0.5276848673820496, train/raw-loss = 0.27789852023124695, train/logprobs = tensor([[-1.4444, -9.4316],
        [-1.8794, -1.3469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0333048477768898
Epoch 0, Step 299: train/loss = 0.5993645191192627, train/raw-loss = 0.351652592420578, train/logprobs = tensor([[-2.0630, -3.7933],
        [-2.3988, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0330282598733902
Epoch 0, Step 300: train/loss = 0.8193375468254089, train/raw-loss = 0.5884965658187866, train/logprobs = tensor([[-1.7599, -2.3059],
        [-1.3946, -1.4836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030778793618083
Epoch 0, Step 301: train/loss = 0.7162913680076599, train/raw-loss = 0.5341664552688599, train/logprobs = tensor([[-1.6697, -3.8823],
        [-0.8041, -1.0417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02428331784904003
Epoch 0, Step 302: train/loss = 0.545867919921875, train/raw-loss = 0.3093932867050171, train/logprobs = tensor([[-1.8847, -6.9613],
        [-1.8128, -1.4493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031529951840639114
Epoch 0, Step 303: train/loss = 0.6513286828994751, train/raw-loss = 0.4772837162017822, train/logprobs = tensor([[-1.4094, -3.9949],
        [-0.7324, -1.5816]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02320600301027298
Epoch 0, Step 304: train/loss = 0.771251380443573, train/raw-loss = 0.37238913774490356, train/logprobs = tensor([[-2.0182, -6.4499],
        [-1.5029, -1.9751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05318162962794304
Epoch 0, Step 305: train/loss = 0.6678788661956787, train/raw-loss = 0.4278273284435272, train/logprobs = tensor([[-1.8216, -3.6817],
        [-1.9346, -1.0478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032006874680519104
Epoch 0, Step 306: train/loss = 0.6176123023033142, train/raw-loss = 0.3725290298461914, train/logprobs = tensor([[-1.1957, -5.8251],
        [-0.9388, -1.6477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03267776966094971
Epoch 0, Step 307: train/loss = 0.47302374243736267, train/raw-loss = 0.2883705496788025, train/logprobs = tensor([[-1.5653, -6.5439],
        [-0.9932, -1.9386]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02462042309343815
Epoch 0, Step 308: train/loss = 0.4209320843219757, train/raw-loss = 0.1990586519241333, train/logprobs = tensor([[-1.5160, -5.4449],
        [-2.3998, -1.4924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029583122581243515
Epoch 0, Step 309: train/loss = 0.5836709141731262, train/raw-loss = 0.29488232731819153, train/logprobs = tensor([[-1.4616, -4.3624],
        [-1.5466, -1.0819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03850514814257622
Epoch 0, Step 310: train/loss = 0.6901469230651855, train/raw-loss = 0.3677121698856354, train/logprobs = tensor([[-1.3579, -8.8394],
        [-1.0149, -2.2672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04299130663275719
Epoch 0, Step 311: train/loss = 0.5903137922286987, train/raw-loss = 0.3537285029888153, train/logprobs = tensor([[-1.1726, -6.3288],
        [-1.3212, -1.3150]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03154471144080162
Epoch 0, Step 312: train/loss = 0.6756229400634766, train/raw-loss = 0.4358729422092438, train/logprobs = tensor([[-1.7393, -4.7256],
        [-1.4100, -1.6114]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031966663897037506
Epoch 0, Step 313: train/loss = 0.4486125111579895, train/raw-loss = 0.23490917682647705, train/logprobs = tensor([[-1.3104, -9.3861],
        [-0.9715, -2.1771]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02849377691745758
Epoch 0, Step 314: train/loss = 0.4735989272594452, train/raw-loss = 0.1929328590631485, train/logprobs = tensor([[-1.2141, -9.4068],
        [-1.5044, -2.3739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037422142922878265
Epoch 0, Step 315: train/loss = 0.5078272223472595, train/raw-loss = 0.3284665644168854, train/logprobs = tensor([[-1.1629, -6.5254],
        [-0.8114, -2.0678]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02391475811600685
Epoch 0, Step 316: train/loss = 0.4946073591709137, train/raw-loss = 0.3256264328956604, train/logprobs = tensor([[-1.9889, -7.9165],
        [-1.3670, -1.4950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02253078669309616
Epoch 0, Step 317: train/loss = 0.5451754927635193, train/raw-loss = 0.3590477705001831, train/logprobs = tensor([[-1.7579, -4.6130],
        [-2.2322, -2.0807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024817030876874924
Epoch 0, Step 318: train/loss = 0.6716738343238831, train/raw-loss = 0.45079517364501953, train/logprobs = tensor([[-1.7780, -5.3334],
        [-2.0628, -2.4895]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02945048175752163
Epoch 0, Step 319: train/loss = 0.5780014991760254, train/raw-loss = 0.38492754101753235, train/logprobs = tensor([[-1.6156, -4.6516],
        [-1.4038, -2.1215]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02574319951236248
Epoch 0, Step 320: train/loss = 0.5068525671958923, train/raw-loss = 0.35625985264778137, train/logprobs = tensor([[-1.1895, -5.1410],
        [-0.5974, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020079029724001884
Epoch 0, Step 321: train/loss = 0.5140875577926636, train/raw-loss = 0.352631539106369, train/logprobs = tensor([[-1.6730, -6.2258],
        [-1.5154, -2.5078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02152746170759201
Epoch 0, Step 322: train/loss = 0.47926539182662964, train/raw-loss = 0.3005591034889221, train/logprobs = tensor([[-1.8686, -6.5082],
        [-1.3172, -2.0615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023827506229281425
Epoch 0, Step 323: train/loss = 0.6223492622375488, train/raw-loss = 0.4701476991176605, train/logprobs = tensor([[-2.2850, -2.5674],
        [-1.8661, -0.7388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020293541252613068
Epoch 0, Step 324: train/loss = 0.49395814538002014, train/raw-loss = 0.35526520013809204, train/logprobs = tensor([[-1.9752, -6.0388],
        [-1.5506, -2.2692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01849238947033882
Epoch 0, Step 325: train/loss = 0.5984864234924316, train/raw-loss = 0.4304158687591553, train/logprobs = tensor([[-4.3406, -5.7714],
        [-3.0732, -1.5618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022409407421946526
Epoch 0, Step 326: train/loss = 0.37056922912597656, train/raw-loss = 0.12319008260965347, train/logprobs = tensor([[-2.4301, -6.4868],
        [-3.6335, -1.8533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03298388794064522
Epoch 0, Step 327: train/loss = 0.6135556101799011, train/raw-loss = 0.4158085584640503, train/logprobs = tensor([[-2.3965, -6.0280],
        [-1.5921, -1.6461]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026366274803876877
Epoch 0, Step 328: train/loss = 0.5628712177276611, train/raw-loss = 0.37467360496520996, train/logprobs = tensor([[-2.6752, -5.8196],
        [-1.5370, -1.2439]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025093015283346176
Epoch 0, Step 329: train/loss = 0.4475627839565277, train/raw-loss = 0.2085564285516739, train/logprobs = tensor([[-2.0024, -6.7822],
        [-2.0567, -1.8872]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031867511570453644
Epoch 0, Step 330: train/loss = 0.4173709452152252, train/raw-loss = 0.235480397939682, train/logprobs = tensor([[-2.4538, -5.8632],
        [-2.8127, -2.4812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024252071976661682
Epoch 0, Step 331: train/loss = 0.45309391617774963, train/raw-loss = 0.24265798926353455, train/logprobs = tensor([[-3.1501, -6.4379],
        [-3.2050, -1.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028058120980858803
Epoch 0, Step 332: train/loss = 0.5881425738334656, train/raw-loss = 0.3693820536136627, train/logprobs = tensor([[-2.3639, -4.0815],
        [-2.1837, -1.1204]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02916806936264038
Epoch 0, Step 333: train/loss = 0.5118096470832825, train/raw-loss = 0.31637337803840637, train/logprobs = tensor([[-3.5116, -9.5794],
        [-1.4320, -2.5334]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026058167219161987
Epoch 0, Step 334: train/loss = 0.5884995460510254, train/raw-loss = 0.3994719386100769, train/logprobs = tensor([[-1.8735, -4.5007],
        [-1.6643, -2.2568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025203686207532883
Epoch 0, Step 335: train/loss = 0.5369699597358704, train/raw-loss = 0.29524174332618713, train/logprobs = tensor([[-1.7692, -5.5322],
        [-1.8359, -1.7232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0322304293513298
Epoch 0, Step 336: train/loss = 0.5590317249298096, train/raw-loss = 0.3383519649505615, train/logprobs = tensor([[-1.6085, -4.8689],
        [-2.1497, -1.3663]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029423968866467476
Epoch 0, Step 337: train/loss = 0.46167048811912537, train/raw-loss = 0.20488429069519043, train/logprobs = tensor([[-1.5686, -7.0063],
        [-1.9605, -2.3764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03423815965652466
Epoch 0, Step 338: train/loss = 0.4638199806213379, train/raw-loss = 0.299851655960083, train/logprobs = tensor([[-2.3381, -6.2107],
        [-3.0493, -2.5673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021862441673874855
Epoch 0, Step 339: train/loss = 0.4663909673690796, train/raw-loss = 0.2865768373012543, train/logprobs = tensor([[-2.0308, -5.2278],
        [-2.8547, -1.4366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02397521585226059
Epoch 0, Step 340: train/loss = 0.3303169012069702, train/raw-loss = 0.1331080049276352, train/logprobs = tensor([[-2.4037, -6.9528],
        [-3.6941, -2.3089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026294514536857605
Epoch 0, Step 341: train/loss = 0.5539230108261108, train/raw-loss = 0.346436083316803, train/logprobs = tensor([[-2.3555, -6.6983],
        [-2.4115, -1.7351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027664929628372192
Epoch 0, Step 342: train/loss = 0.6123782992362976, train/raw-loss = 0.4190799295902252, train/logprobs = tensor([[-2.1341, -5.6751],
        [-2.8558, -1.5751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02577311545610428
Epoch 0, Step 343: train/loss = 0.5584466457366943, train/raw-loss = 0.3502756357192993, train/logprobs = tensor([[-1.1981, -4.9519],
        [-0.8024, -1.6530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027756135910749435
Epoch 0, Step 344: train/loss = 0.6094586253166199, train/raw-loss = 0.41656720638275146, train/logprobs = tensor([[-2.4784, -4.2774],
        [-2.8949, -2.3666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02571886032819748
Epoch 0, Step 345: train/loss = 0.5793039798736572, train/raw-loss = 0.37895655632019043, train/logprobs = tensor([[-2.4225, -4.1914],
        [-1.9963, -1.3088]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026712995022535324
Epoch 0, Step 346: train/loss = 0.43263185024261475, train/raw-loss = 0.22098985314369202, train/logprobs = tensor([[-1.8024, -7.9249],
        [-2.6145, -2.6302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028218934312462807
Epoch 0, Step 347: train/loss = 0.5892635583877563, train/raw-loss = 0.39793410897254944, train/logprobs = tensor([[-2.2377, -4.3174],
        [-1.7513, -1.9867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02551058866083622
Epoch 0, Step 348: train/loss = 0.6465744972229004, train/raw-loss = 0.4318125545978546, train/logprobs = tensor([[-1.8598, -4.6916],
        [-0.9142, -1.2866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0286349318921566
Epoch 0, Step 349: train/loss = 0.5853185653686523, train/raw-loss = 0.41186046600341797, train/logprobs = tensor([[-1.4642, -4.5578],
        [-1.2184, -1.4262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02312774769961834
Epoch 0, Step 350: train/loss = 0.47152799367904663, train/raw-loss = 0.23198756575584412, train/logprobs = tensor([[-1.0424, -7.5505],
        [-0.8802, -2.5010]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03193872421979904
Epoch 0, Step 351: train/loss = 0.5304874181747437, train/raw-loss = 0.29560136795043945, train/logprobs = tensor([[-1.4931, -5.3792],
        [-1.9481, -2.2511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031318146735429764
Epoch 0, Step 352: train/loss = 0.47527357935905457, train/raw-loss = 0.2297348976135254, train/logprobs = tensor([[-1.6919, -7.3661],
        [-1.6892, -2.1315]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03273848444223404
Epoch 0, Step 353: train/loss = 0.5053784251213074, train/raw-loss = 0.2759520411491394, train/logprobs = tensor([[-1.8839, -5.7996],
        [-1.9225, -1.2092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030590184032917023
Epoch 0, Step 354: train/loss = 0.4256440997123718, train/raw-loss = 0.21197403967380524, train/logprobs = tensor([[-1.3698, -9.9763],
        [-1.2737, -2.4470]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02848934382200241
Epoch 0, Step 355: train/loss = 0.8382754325866699, train/raw-loss = 0.5279213786125183, train/logprobs = tensor([[-1.8336, -5.4905],
        [-1.1412, -1.7373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04138054698705673
Epoch 0, Step 356: train/loss = 0.6501511335372925, train/raw-loss = 0.45045530796051025, train/logprobs = tensor([[-1.6778, -2.8062],
        [-1.8998, -1.4558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026626110076904297
Epoch 0, Step 357: train/loss = 0.4768194556236267, train/raw-loss = 0.26790857315063477, train/logprobs = tensor([[-0.9889, -8.8012],
        [-0.9237, -2.1910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027854781597852707
Epoch 0, Step 358: train/loss = 0.5339171886444092, train/raw-loss = 0.31196218729019165, train/logprobs = tensor([[-2.1831, -7.2996],
        [-1.8254, -1.6976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029594004154205322
Epoch 0, Step 359: train/loss = 0.4856017529964447, train/raw-loss = 0.21249163150787354, train/logprobs = tensor([[-1.4439, -8.8920],
        [-1.5685, -2.4445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036414675414562225
Epoch 0, Step 360: train/loss = 0.6116836071014404, train/raw-loss = 0.35098421573638916, train/logprobs = tensor([[-1.2063, -8.4269],
        [-0.7505, -2.8113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034759923815727234
Epoch 0, Step 361: train/loss = 0.6669302582740784, train/raw-loss = 0.25416141748428345, train/logprobs = tensor([[-1.3557, -9.4340],
        [-0.9310, -2.2095]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05503584444522858
Epoch 0, Step 362: train/loss = 0.6034746170043945, train/raw-loss = 0.40137118101119995, train/logprobs = tensor([[-2.2260, -4.0684],
        [-2.2478, -1.6863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02694712206721306
Epoch 0, Step 363: train/loss = 0.4636753797531128, train/raw-loss = 0.2519039511680603, train/logprobs = tensor([[-1.6748, -4.6833],
        [-2.4459, -2.2274]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028236189857125282
Epoch 0, Step 364: train/loss = 0.5673332214355469, train/raw-loss = 0.2933301031589508, train/logprobs = tensor([[-1.5192, -5.6142],
        [-2.2532, -1.5223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03653375431895256
Epoch 0, Step 365: train/loss = 0.44226863980293274, train/raw-loss = 0.2777728736400604, train/logprobs = tensor([[-2.4360, -5.9977],
        [-2.2367, -1.1676]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02193276584148407
Epoch 0, Step 366: train/loss = 0.5748926401138306, train/raw-loss = 0.3667376935482025, train/logprobs = tensor([[-1.4982, -4.5305],
        [-2.0869, -1.7350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027753999456763268
Epoch 0, Step 367: train/loss = 0.43436944484710693, train/raw-loss = 0.26424819231033325, train/logprobs = tensor([[-1.2988, -4.9276],
        [-1.2277, -1.4022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022682834416627884
Epoch 0, Step 368: train/loss = 0.36028286814689636, train/raw-loss = 0.15804512798786163, train/logprobs = tensor([[-1.8340, -6.5178],
        [-3.0395, -2.1972]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026965033262968063
Epoch 0, Step 369: train/loss = 0.5342836380004883, train/raw-loss = 0.28093579411506653, train/logprobs = tensor([[-1.5577, -5.7038],
        [-1.9522, -1.5213]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03377971053123474
Epoch 0, Step 370: train/loss = 0.5064090490341187, train/raw-loss = 0.2919466495513916, train/logprobs = tensor([[-1.7530, -8.1946],
        [-1.1420, -2.3404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02859499305486679
Epoch 0, Step 371: train/loss = 0.7138029932975769, train/raw-loss = 0.4768005311489105, train/logprobs = tensor([[-0.9469, -2.9370],
        [-0.5647, -0.8446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03160031884908676
Epoch 0, Step 372: train/loss = 0.6064193248748779, train/raw-loss = 0.4265044927597046, train/logprobs = tensor([[-1.7468, -4.5145],
        [-2.2877, -2.2971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023988649249076843
Epoch 0, Step 373: train/loss = 0.5223535299301147, train/raw-loss = 0.26300057768821716, train/logprobs = tensor([[-1.3659, -7.6086],
        [-1.8729, -2.4513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03458039090037346
Epoch 0, Step 374: train/loss = 0.7248737812042236, train/raw-loss = 0.3981253504753113, train/logprobs = tensor([[-1.3199, -3.1082],
        [-1.1925, -1.0692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04356646537780762
Epoch 0, Step 375: train/loss = 0.5813369750976562, train/raw-loss = 0.356531023979187, train/logprobs = tensor([[-1.3405, -3.3247],
        [-2.2999, -1.3640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02997412532567978
Epoch 0, Step 376: train/loss = 0.6999012231826782, train/raw-loss = 0.5236889719963074, train/logprobs = tensor([[-2.2713, -4.5543],
        [-1.2819, -1.3025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023494958877563477
Epoch 0, Step 377: train/loss = 0.7618932127952576, train/raw-loss = 0.5801079869270325, train/logprobs = tensor([[-0.7565, -1.7519],
        [-0.7877, -0.8727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02423803135752678
Epoch 0, Step 378: train/loss = 0.49732643365859985, train/raw-loss = 0.2062169909477234, train/logprobs = tensor([[-3.2839, -4.5844],
        [-4.1796, -1.7105]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038814593106508255
Epoch 0, Step 379: train/loss = 0.5874224901199341, train/raw-loss = 0.3901422619819641, train/logprobs = tensor([[-2.9493, -6.9674],
        [-2.2809, -2.3595]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026304025202989578
Epoch 0, Step 380: train/loss = 0.5070858001708984, train/raw-loss = 0.32136738300323486, train/logprobs = tensor([[-1.5103, -5.8193],
        [-2.2842, -1.7038]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024762457236647606
Epoch 0, Step 381: train/loss = 0.4740350842475891, train/raw-loss = 0.2640630602836609, train/logprobs = tensor([[-1.5771, -7.3875],
        [-1.8266, -1.4989]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027996273711323738
Epoch 0, Step 382: train/loss = 0.4781448543071747, train/raw-loss = 0.2745858132839203, train/logprobs = tensor([[-1.8719, -6.0341],
        [-2.2218, -1.5368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027141204103827477
Epoch 0, Step 383: train/loss = 0.636390209197998, train/raw-loss = 0.44960856437683105, train/logprobs = tensor([[-3.0128, -4.0796],
        [-3.4717, -3.0355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02490421198308468
Epoch 0, Step 384: train/loss = 0.5351496338844299, train/raw-loss = 0.3494141697883606, train/logprobs = tensor([[-1.1872, -5.1956],
        [-1.2426, -2.0359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02476472593843937
Epoch 0, Step 385: train/loss = 0.5975852012634277, train/raw-loss = 0.37725651264190674, train/logprobs = tensor([[-2.5655, -3.9043],
        [-3.1733, -1.6898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029377158731222153
Epoch 0, Step 386: train/loss = 0.6750941872596741, train/raw-loss = 0.4517611265182495, train/logprobs = tensor([[-2.4595, -5.4085],
        [-2.7375, -2.7884]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029777739197015762
Epoch 0, Step 387: train/loss = 0.6445658206939697, train/raw-loss = 0.4260338544845581, train/logprobs = tensor([[-1.8150, -4.6486],
        [-1.5605, -1.9657]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02913760021328926
Epoch 0, Step 388: train/loss = 0.912609338760376, train/raw-loss = 0.5507820844650269, train/logprobs = tensor([[-1.4578, -2.3799],
        [-0.7647, -0.6618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04824363812804222
Epoch 0, Step 389: train/loss = 0.7894836664199829, train/raw-loss = 0.47635337710380554, train/logprobs = tensor([[-1.1696, -3.5930],
        [-0.8515, -1.1612]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0417507067322731
Epoch 0, Step 390: train/loss = 0.5214248895645142, train/raw-loss = 0.2983497977256775, train/logprobs = tensor([[-2.1798, -7.2699],
        [-2.2482, -2.4886]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029743345454335213
Epoch 0, Step 391: train/loss = 0.6827592849731445, train/raw-loss = 0.49900299310684204, train/logprobs = tensor([[-5.0705, -7.2398],
        [-1.4133, -1.7177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02450084500014782
Epoch 0, Step 392: train/loss = 0.6664643883705139, train/raw-loss = 0.4014194905757904, train/logprobs = tensor([[-1.6861, -6.8261],
        [-1.9386, -2.1779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035339318215847015
Epoch 0, Step 393: train/loss = 0.5152947306632996, train/raw-loss = 0.2713407278060913, train/logprobs = tensor([[-2.2404, -5.4006],
        [-2.4106, -2.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03252720460295677
Epoch 0, Step 394: train/loss = 0.5958724617958069, train/raw-loss = 0.31178608536720276, train/logprobs = tensor([[-2.0775, -7.3365],
        [-1.4745, -2.0511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03787818178534508
Epoch 0, Step 395: train/loss = 0.6262525916099548, train/raw-loss = 0.33478355407714844, train/logprobs = tensor([[-1.6939, -5.2118],
        [-1.7043, -1.5990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03886253759264946
Epoch 0, Step 396: train/loss = 0.6396971344947815, train/raw-loss = 0.3178156018257141, train/logprobs = tensor([[ -1.5950, -10.8956],
        [ -1.4153,  -2.2109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042917534708976746
Epoch 0, Step 397: train/loss = 0.7349070310592651, train/raw-loss = 0.527350902557373, train/logprobs = tensor([[-2.7601, -3.4636],
        [-2.0178, -1.2588]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027674153447151184
Epoch 0, Step 398: train/loss = 0.4780687987804413, train/raw-loss = 0.2740967273712158, train/logprobs = tensor([[-2.0846, -5.1660],
        [-2.4371, -2.0641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02719627507030964
Epoch 0, Step 399: train/loss = 0.5107536315917969, train/raw-loss = 0.2975768446922302, train/logprobs = tensor([[-1.9631, -4.9665],
        [-2.1745, -1.4365]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02842356264591217
Epoch 0, Step 400: train/loss = 0.4327279329299927, train/raw-loss = 0.21697184443473816, train/logprobs = tensor([[-2.3404, -5.0266],
        [-3.1302, -1.3682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028767479583621025
Epoch 0, Step 401: train/loss = 0.5060437321662903, train/raw-loss = 0.20962166786193848, train/logprobs = tensor([[-1.9101, -8.7880],
        [-2.0975, -1.4351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039522942155599594
Epoch 0, Step 402: train/loss = 0.5395099520683289, train/raw-loss = 0.3221372961997986, train/logprobs = tensor([[-1.5962, -6.4921],
        [-1.5516, -1.5270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028983019292354584
Epoch 0, Step 403: train/loss = 0.3850563168525696, train/raw-loss = 0.17371366918087006, train/logprobs = tensor([[-2.0680, -4.9798],
        [-3.3246, -1.5049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028179021552205086
Epoch 0, Step 404: train/loss = 0.4170741140842438, train/raw-loss = 0.20845931768417358, train/logprobs = tensor([[-1.8799, -5.7103],
        [-2.5293, -2.2613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027815308421850204
Epoch 0, Step 405: train/loss = 0.7176440358161926, train/raw-loss = 0.38498979806900024, train/logprobs = tensor([[-1.0793, -3.6124],
        [-1.5930, -1.6118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.044353898614645004
Epoch 0, Step 406: train/loss = 0.5094047784805298, train/raw-loss = 0.3353744149208069, train/logprobs = tensor([[-2.0891, -5.3627],
        [-2.1766, -1.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023204058408737183
Epoch 0, Step 407: train/loss = 0.3659282922744751, train/raw-loss = 0.20932184159755707, train/logprobs = tensor([[-2.1476, -5.9405],
        [-3.4391, -1.9442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.020880859345197678
Epoch 0, Step 408: train/loss = 0.5328865647315979, train/raw-loss = 0.3005588948726654, train/logprobs = tensor([[-2.0959, -3.8240],
        [-2.8148, -1.2718]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030977020040154457
Epoch 0, Step 409: train/loss = 0.6231932640075684, train/raw-loss = 0.37870514392852783, train/logprobs = tensor([[-1.1365, -5.2519],
        [-1.1093, -1.6452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03259841352701187
Epoch 0, Step 410: train/loss = 0.5297982692718506, train/raw-loss = 0.3327672481536865, train/logprobs = tensor([[-1.9729, -5.8295],
        [-1.2474, -1.3463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026270803064107895
Epoch 0, Step 411: train/loss = 0.7328206300735474, train/raw-loss = 0.6049240231513977, train/logprobs = tensor([[-2.8168, -2.7977],
        [-1.4039, -0.9487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.017052888870239258
Epoch 0, Step 412: train/loss = 0.4692944586277008, train/raw-loss = 0.2777412533760071, train/logprobs = tensor([[-1.4640, -4.6921],
        [-2.7593, -1.5634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02554043009877205
Epoch 0, Step 413: train/loss = 0.5322787761688232, train/raw-loss = 0.28703102469444275, train/logprobs = tensor([[-2.1287, -3.1586],
        [-3.4160, -1.1123]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032699696719646454
Epoch 0, Step 414: train/loss = 0.6070334911346436, train/raw-loss = 0.4070167541503906, train/logprobs = tensor([[-1.5719, -4.2421],
        [-1.0174, -1.0292]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02666890062391758
Epoch 0, Step 415: train/loss = 0.45216232538223267, train/raw-loss = 0.25768840312957764, train/logprobs = tensor([[-1.3978, -9.9091],
        [-0.6432, -1.9242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025929857045412064
Epoch 0, Step 416: train/loss = 0.4968838691711426, train/raw-loss = 0.28698495030403137, train/logprobs = tensor([[-1.5398, -6.7382],
        [-0.9380, -1.5239]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027986524626612663
Epoch 0, Step 417: train/loss = 0.46795976161956787, train/raw-loss = 0.20158475637435913, train/logprobs = tensor([[ -1.8053, -10.0007],
        [ -1.8957,  -2.7629]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03551666438579559
Epoch 0, Step 418: train/loss = 0.6642497181892395, train/raw-loss = 0.47962772846221924, train/logprobs = tensor([[-2.6904, -4.4464],
        [-1.7643, -1.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024616263806819916
Epoch 0, Step 419: train/loss = 0.48031085729599, train/raw-loss = 0.25100746750831604, train/logprobs = tensor([[-3.2937, -6.3874],
        [-4.7328, -2.3491]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030573789030313492
Epoch 0, Step 420: train/loss = 0.5509872436523438, train/raw-loss = 0.3226134777069092, train/logprobs = tensor([[-1.6503, -4.8695],
        [-2.4373, -2.9622]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03044983558356762
Epoch 0, Step 421: train/loss = 0.6674058437347412, train/raw-loss = 0.49809205532073975, train/logprobs = tensor([[-1.1418, -5.5602],
        [-0.8426, -1.7780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022575171664357185
Epoch 0, Step 422: train/loss = 0.3940524458885193, train/raw-loss = 0.13358071446418762, train/logprobs = tensor([[-1.2820, -4.4107],
        [-3.4413, -1.4306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03472956269979477
Epoch 0, Step 423: train/loss = 0.43267586827278137, train/raw-loss = 0.21092535555362701, train/logprobs = tensor([[-2.1187, -4.2375],
        [-4.0287, -1.7526]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02956673502922058
Epoch 0, Step 424: train/loss = 0.45413073897361755, train/raw-loss = 0.26645591855049133, train/logprobs = tensor([[-1.2869, -8.6694],
        [-1.1466, -1.5513]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025023313239216805
Epoch 0, Step 425: train/loss = 0.3895083963871002, train/raw-loss = 0.16937366127967834, train/logprobs = tensor([[-1.7384, -8.7063],
        [-2.2426, -2.2059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02935129776597023
Epoch 0, Step 426: train/loss = 0.541851282119751, train/raw-loss = 0.3520655930042267, train/logprobs = tensor([[-2.1479, -3.6690],
        [-2.9628, -2.3284]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025304749608039856
Epoch 0, Step 427: train/loss = 0.7836816310882568, train/raw-loss = 0.5489281415939331, train/logprobs = tensor([[-1.3369, -1.9957],
        [-1.3481, -1.2280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03130047395825386
Epoch 0, Step 428: train/loss = 0.5035008788108826, train/raw-loss = 0.22175633907318115, train/logprobs = tensor([[-2.2723, -5.4561],
        [-2.4230, -1.2673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037565942853689194
Epoch 0, Step 429: train/loss = 0.6769241094589233, train/raw-loss = 0.4719775915145874, train/logprobs = tensor([[-1.5151, -2.2304],
        [-2.2031, -0.9134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027326207607984543
Epoch 0, Step 430: train/loss = 0.5170271396636963, train/raw-loss = 0.21849629282951355, train/logprobs = tensor([[-2.4179, -7.3336],
        [-2.3623, -2.3684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039804115891456604
Epoch 0, Step 431: train/loss = 0.6229427456855774, train/raw-loss = 0.3461304306983948, train/logprobs = tensor([[-2.9493, -6.3451],
        [-2.3954, -2.4026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036908309906721115
Epoch 0, Step 432: train/loss = 0.543172299861908, train/raw-loss = 0.35889172554016113, train/logprobs = tensor([[-1.3964, -3.6436],
        [-2.0435, -1.3137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024570751935243607
Epoch 0, Step 433: train/loss = 0.38224875926971436, train/raw-loss = 0.14029106497764587, train/logprobs = tensor([[-1.8221, -5.9283],
        [-3.2176, -2.4382]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03226102888584137
Epoch 0, Step 434: train/loss = 0.6116532683372498, train/raw-loss = 0.36699390411376953, train/logprobs = tensor([[-1.7180, -6.8763],
        [-2.2926, -2.4840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03262124955654144
Epoch 0, Step 435: train/loss = 0.5039088726043701, train/raw-loss = 0.2727324366569519, train/logprobs = tensor([[-2.1100, -3.5807],
        [-2.9855, -1.7960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03082352504134178
Epoch 0, Step 436: train/loss = 0.4752007722854614, train/raw-loss = 0.28172236680984497, train/logprobs = tensor([[-1.6924, -4.5581],
        [-3.0036, -1.1373]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025797124952077866
Epoch 0, Step 437: train/loss = 0.4120737910270691, train/raw-loss = 0.23034954071044922, train/logprobs = tensor([[-1.5125, -6.0306],
        [-1.8352, -1.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024229897186160088
Epoch 0, Step 438: train/loss = 0.6396287083625793, train/raw-loss = 0.4561208486557007, train/logprobs = tensor([[-2.0086, -4.7567],
        [-1.9707, -1.6335]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024467708542943
Epoch 0, Step 439: train/loss = 0.45355701446533203, train/raw-loss = 0.2038440704345703, train/logprobs = tensor([[-1.5372, -5.5658],
        [-2.0952, -1.4801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033295053988695145
Epoch 0, Step 440: train/loss = 0.6388028860092163, train/raw-loss = 0.40904301404953003, train/logprobs = tensor([[-2.9532, -4.2748],
        [-2.5969, -1.9646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030634652823209763
Epoch 0, Step 441: train/loss = 0.4751330614089966, train/raw-loss = 0.20210865139961243, train/logprobs = tensor([[ -1.6383, -10.0684],
        [ -1.6591,  -2.3267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03640324994921684
Epoch 0, Step 442: train/loss = 0.4726603031158447, train/raw-loss = 0.18957263231277466, train/logprobs = tensor([[-2.5446, -4.0937],
        [-3.9972, -1.3798]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037745025008916855
Epoch 0, Step 443: train/loss = 0.3721219301223755, train/raw-loss = 0.19425074756145477, train/logprobs = tensor([[-1.7363, -7.7030],
        [-3.1402, -1.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023716162890195847
Epoch 0, Step 444: train/loss = 0.5059970021247864, train/raw-loss = 0.3302112817764282, train/logprobs = tensor([[-1.2060, -4.8371],
        [-1.6614, -1.4410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023438094183802605
Epoch 0, Step 445: train/loss = 0.4625132083892822, train/raw-loss = 0.23644417524337769, train/logprobs = tensor([[-2.1716, -4.7861],
        [-3.4357, -1.3122]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030142540112137794
Epoch 0, Step 446: train/loss = 0.5020323991775513, train/raw-loss = 0.2889504134654999, train/logprobs = tensor([[-2.3769, -8.1683],
        [-1.3562, -1.9422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02841092273592949
Epoch 0, Step 447: train/loss = 0.5871843695640564, train/raw-loss = 0.37674856185913086, train/logprobs = tensor([[-1.4965, -8.1491],
        [-1.5217, -2.6522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02805810607969761
Epoch 0, Step 448: train/loss = 0.5007709264755249, train/raw-loss = 0.335158109664917, train/logprobs = tensor([[-2.4593, -7.0171],
        [-2.3387, -1.7540]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022081706672906876
Epoch 0, Step 449: train/loss = 0.6210090517997742, train/raw-loss = 0.4357243478298187, train/logprobs = tensor([[-2.1582, -3.3500],
        [-2.1975, -0.9887]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02470462955534458
Epoch 0, Step 450: train/loss = 0.6015950441360474, train/raw-loss = 0.32895541191101074, train/logprobs = tensor([[-0.8522, -5.6305],
        [-0.8370, -1.2833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03635195642709732
Epoch 0, Step 451: train/loss = 0.6175841093063354, train/raw-loss = 0.45227229595184326, train/logprobs = tensor([[-2.2518, -4.0160],
        [-2.5037, -2.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022041570395231247
Epoch 0, Step 452: train/loss = 0.4257779121398926, train/raw-loss = 0.24505175650119781, train/logprobs = tensor([[-1.9684, -5.7546],
        [-2.3081, -1.4319]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02409682236611843
Epoch 0, Step 453: train/loss = 0.4290259778499603, train/raw-loss = 0.2439282238483429, train/logprobs = tensor([[-1.0899, -4.3997],
        [-2.4986, -1.2089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024679698050022125
Epoch 0, Step 454: train/loss = 0.4159019887447357, train/raw-loss = 0.229365274310112, train/logprobs = tensor([[-1.9889, -4.2464],
        [-3.3993, -1.2044]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02487156353890896
Epoch 0, Step 455: train/loss = 0.4766654670238495, train/raw-loss = 0.25673651695251465, train/logprobs = tensor([[-1.1795, -6.2730],
        [-1.0046, -1.3237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029323861002922058
Epoch 0, Step 456: train/loss = 0.6301039457321167, train/raw-loss = 0.36105161905288696, train/logprobs = tensor([[-1.4879, -5.5184],
        [-1.4520, -1.3401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.035873644053936005
Epoch 0, Step 457: train/loss = 0.56062912940979, train/raw-loss = 0.38069796562194824, train/logprobs = tensor([[-1.1015, -4.3665],
        [-0.7980, -1.3755]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023990821093320847
Epoch 0, Step 458: train/loss = 0.5915598273277283, train/raw-loss = 0.3026624917984009, train/logprobs = tensor([[-2.5376, -4.5410],
        [-2.6508, -1.5196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03851964324712753
Epoch 0, Step 459: train/loss = 0.5455067157745361, train/raw-loss = 0.32442963123321533, train/logprobs = tensor([[-1.2466, -4.6462],
        [-1.1771, -1.3092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029476940631866455
Epoch 0, Step 460: train/loss = 0.6375970840454102, train/raw-loss = 0.40478450059890747, train/logprobs = tensor([[-0.9888, -3.8021],
        [-1.5894, -1.2792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03104168176651001
Epoch 0, Step 461: train/loss = 0.5846412181854248, train/raw-loss = 0.3698984384536743, train/logprobs = tensor([[-2.9657, -4.3311],
        [-2.6722, -0.9728]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02863236889243126
Epoch 0, Step 462: train/loss = 0.4462158679962158, train/raw-loss = 0.21461735665798187, train/logprobs = tensor([[-1.2068, -8.0679],
        [-1.3727, -1.6952]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030879799276590347
Epoch 0, Step 463: train/loss = 0.6079133749008179, train/raw-loss = 0.38455721735954285, train/logprobs = tensor([[-1.4746, -5.8488],
        [-1.1895, -1.2545]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02978082001209259
Epoch 0, Step 464: train/loss = 0.5253303050994873, train/raw-loss = 0.3056737780570984, train/logprobs = tensor([[-1.5398, -8.7223],
        [-1.8934, -2.8356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.029287535697221756
Epoch 0, Step 465: train/loss = 0.7291354537010193, train/raw-loss = 0.4472517669200897, train/logprobs = tensor([[-1.6133, -2.8878],
        [-1.8377, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.037584494799375534
Epoch 0, Step 466: train/loss = 0.48761165142059326, train/raw-loss = 0.12228673696517944, train/logprobs = tensor([[-1.9157, -6.3784],
        [-3.6446, -1.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.048709988594055176
Epoch 0, Step 467: train/loss = 0.739579439163208, train/raw-loss = 0.3809951841831207, train/logprobs = tensor([[-2.4730, -3.8199],
        [-3.5466, -2.3477]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04781123250722885
Epoch 0, Step 468: train/loss = 0.5570319890975952, train/raw-loss = 0.2838525176048279, train/logprobs = tensor([[-2.1113, -4.5373],
        [-3.9594, -2.4690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036423925310373306
Epoch 0, Step 469: train/loss = 0.5821333527565002, train/raw-loss = 0.38083499670028687, train/logprobs = tensor([[-1.4002, -3.3857],
        [-1.5306, -1.2227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02683977782726288
Epoch 0, Step 470: train/loss = 0.48690664768218994, train/raw-loss = 0.21524019539356232, train/logprobs = tensor([[-1.2949, -6.5411],
        [-1.7410, -1.9447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036222193390131
Epoch 0, Step 471: train/loss = 0.6980347633361816, train/raw-loss = 0.4495556056499481, train/logprobs = tensor([[-1.8817, -7.6106],
        [-2.6684, -3.5575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03313055634498596
Epoch 0, Step 472: train/loss = 0.33634382486343384, train/raw-loss = 0.10904327034950256, train/logprobs = tensor([[ -2.4001, -13.2513],
        [ -4.1057,  -3.3358]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03030673786997795
Epoch 0, Step 473: train/loss = 0.5317236185073853, train/raw-loss = 0.3530254364013672, train/logprobs = tensor([[-2.7968, -4.5475],
        [-3.3227, -2.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023826422169804573
Epoch 0, Step 474: train/loss = 0.4362565875053406, train/raw-loss = 0.22665266692638397, train/logprobs = tensor([[-1.0978, -6.8362],
        [-0.9659, -1.6990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027947193011641502
Epoch 0, Step 475: train/loss = 0.4881163239479065, train/raw-loss = 0.25547149777412415, train/logprobs = tensor([[-1.7734, -7.4329],
        [-1.6013, -2.4977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031019311398267746
Epoch 0, Step 476: train/loss = 0.6195117831230164, train/raw-loss = 0.41554999351501465, train/logprobs = tensor([[-1.8936, -3.0417],
        [-1.8419, -1.0856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02719489485025406
Epoch 0, Step 477: train/loss = 0.5979421734809875, train/raw-loss = 0.29326140880584717, train/logprobs = tensor([[-2.9414, -5.1469],
        [-3.5684, -1.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04062409698963165
Epoch 0, Step 478: train/loss = 0.5977341532707214, train/raw-loss = 0.28400304913520813, train/logprobs = tensor([[-2.5499, -4.5261],
        [-3.4572, -1.5228]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04183081164956093
Epoch 0, Step 479: train/loss = 0.5166140794754028, train/raw-loss = 0.322900652885437, train/logprobs = tensor([[-2.8948, -8.7183],
        [-2.5389, -2.0634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02582845836877823
Epoch 0, Step 480: train/loss = 0.5407178997993469, train/raw-loss = 0.3114018440246582, train/logprobs = tensor([[-1.7067, -5.4558],
        [-1.8590, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030575476586818695
Epoch 0, Step 481: train/loss = 0.5337128639221191, train/raw-loss = 0.31660887598991394, train/logprobs = tensor([[-2.1376, -4.7697],
        [-2.5658, -1.4308]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028947193175554276
Epoch 0, Step 482: train/loss = 0.4915306568145752, train/raw-loss = 0.27500155568122864, train/logprobs = tensor([[-1.3840, -6.4083],
        [-2.0509, -1.8062]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02887054532766342
Epoch 0, Step 483: train/loss = 0.570612907409668, train/raw-loss = 0.34157973527908325, train/logprobs = tensor([[-1.7942, -6.1832],
        [-2.3199, -1.7233]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03053775429725647
Epoch 0, Step 484: train/loss = 0.5148030519485474, train/raw-loss = 0.1926007866859436, train/logprobs = tensor([[-1.5020, -8.3045],
        [-1.9449, -2.2456]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04296030104160309
Epoch 0, Step 485: train/loss = 0.5444859862327576, train/raw-loss = 0.33816689252853394, train/logprobs = tensor([[-2.0467, -4.3842],
        [-2.8022, -1.1235]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027509214356541634
Epoch 0, Step 486: train/loss = 0.7724063396453857, train/raw-loss = 0.554680347442627, train/logprobs = tensor([[-1.2541, -2.4621],
        [-0.6417, -1.1221]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02903013303875923
Epoch 0, Step 487: train/loss = 0.472653329372406, train/raw-loss = 0.26638075709342957, train/logprobs = tensor([[-1.9679, -9.0960],
        [-1.4406, -2.7332]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027503011748194695
Epoch 0, Step 488: train/loss = 0.5456329584121704, train/raw-loss = 0.3672753572463989, train/logprobs = tensor([[-3.1656, -4.9116],
        [-2.5971, -1.4856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023781009018421173
Epoch 0, Step 489: train/loss = 0.626844048500061, train/raw-loss = 0.3963332772254944, train/logprobs = tensor([[-2.7449, -5.1919],
        [-1.9910, -1.6374]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030734766274690628
Epoch 0, Step 490: train/loss = 0.8436968326568604, train/raw-loss = 0.5401054620742798, train/logprobs = tensor([[-0.9480, -2.5144],
        [-0.6446, -1.2432]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04047885537147522
Epoch 0, Step 491: train/loss = 0.6166143417358398, train/raw-loss = 0.37390846014022827, train/logprobs = tensor([[-1.6940, -5.9784],
        [-1.5121, -1.9404]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032360777258872986
Epoch 0, Step 492: train/loss = 0.5259329080581665, train/raw-loss = 0.3503285050392151, train/logprobs = tensor([[-0.9117, -8.5952],
        [-0.5460, -1.4463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.023413915187120438
Epoch 0, Step 493: train/loss = 0.44928014278411865, train/raw-loss = 0.25459814071655273, train/logprobs = tensor([[-1.8794, -5.9637],
        [-1.7590, -1.5568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02595759928226471
Epoch 0, Step 494: train/loss = 0.5848328471183777, train/raw-loss = 0.37088701128959656, train/logprobs = tensor([[-2.4617, -3.4231],
        [-3.5070, -0.9081]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02852611243724823
Epoch 0, Step 495: train/loss = 0.4272117018699646, train/raw-loss = 0.21399733424186707, train/logprobs = tensor([[-2.4600, -5.4739],
        [-3.4060, -1.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02842857874929905
Epoch 0, Step 496: train/loss = 0.7783064246177673, train/raw-loss = 0.368805468082428, train/logprobs = tensor([[-1.8415, -7.6819],
        [-2.1312, -2.3843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05460011959075928
Epoch 0, Step 497: train/loss = 0.45270970463752747, train/raw-loss = 0.2494986653327942, train/logprobs = tensor([[-1.6598, -8.8451],
        [-1.6027, -2.3013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027094805613160133
Epoch 0, Step 498: train/loss = 0.49256080389022827, train/raw-loss = 0.30772149562835693, train/logprobs = tensor([[-2.3770, -7.3036],
        [-3.0576, -1.9362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02464524656534195
Epoch 0, Step 499: train/loss = 0.40623030066490173, train/raw-loss = 0.20067211985588074, train/logprobs = tensor([[-1.7660, -7.1190],
        [-2.4882, -1.9054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027407757937908173
eval/loss: 0.5475242733955383
Epoch 0, Step 500: train/loss = 0.37659454345703125, train/raw-loss = 0.21606683731079102, train/logprobs = tensor([[-1.6222, -9.0678],
        [-2.2040, -2.0721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021403692662715912
Epoch 0, Step 501: train/loss = 0.5227072834968567, train/raw-loss = 0.289911150932312, train/logprobs = tensor([[-1.6756, -5.0594],
        [-3.1849, -1.4628]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031039481982588768
Epoch 0, Step 502: train/loss = 0.5434103608131409, train/raw-loss = 0.30988553166389465, train/logprobs = tensor([[-1.4796, -7.8391],
        [-0.8701, -1.7819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03113664872944355
Epoch 0, Step 503: train/loss = 0.4175534248352051, train/raw-loss = 0.21640625596046448, train/logprobs = tensor([[-1.8313, -6.9640],
        [-2.6853, -2.3004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0268196202814579
Epoch 0, Step 504: train/loss = 0.7776514291763306, train/raw-loss = 0.5915730595588684, train/logprobs = tensor([[-2.1647, -2.8790],
        [-1.2969, -1.5407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02481045201420784
Epoch 0, Step 505: train/loss = 0.4151768088340759, train/raw-loss = 0.23119975626468658, train/logprobs = tensor([[-1.4486, -6.9102],
        [-2.5950, -1.8666]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02453027106821537
Epoch 0, Step 506: train/loss = 0.5687038898468018, train/raw-loss = 0.3571191430091858, train/logprobs = tensor([[-2.2707, -7.0414],
        [-1.9520, -2.6280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02821129932999611
Epoch 0, Step 507: train/loss = 0.4313696324825287, train/raw-loss = 0.21662920713424683, train/logprobs = tensor([[-1.5201, -6.1586],
        [-1.9387, -1.8671]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028632057830691338
Epoch 0, Step 508: train/loss = 0.6632078886032104, train/raw-loss = 0.43091443181037903, train/logprobs = tensor([[-1.2031, -6.3701],
        [-0.8791, -1.5615]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030972454696893692
Epoch 0, Step 509: train/loss = 0.6290748119354248, train/raw-loss = 0.43036746978759766, train/logprobs = tensor([[-2.8125, -6.2614],
        [-2.5129, -3.3442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026494309306144714
Epoch 0, Step 510: train/loss = 0.5118061304092407, train/raw-loss = 0.32817700505256653, train/logprobs = tensor([[-0.9701, -6.2850],
        [-0.9760, -1.7166]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02448388561606407
Epoch 0, Step 511: train/loss = 0.6050587296485901, train/raw-loss = 0.3125540018081665, train/logprobs = tensor([[-2.4695, -9.8585],
        [-1.6954, -1.9454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039000630378723145
Epoch 0, Step 512: train/loss = 0.752274215221405, train/raw-loss = 0.3525976836681366, train/logprobs = tensor([[-1.0537, -8.9361],
        [-0.6563, -1.7182]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.05329020693898201
Epoch 0, Step 513: train/loss = 0.4323180317878723, train/raw-loss = 0.1973215788602829, train/logprobs = tensor([[-2.0487, -6.4120],
        [-2.3836, -1.7440]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03133285790681839
Epoch 0, Step 514: train/loss = 0.603644609451294, train/raw-loss = 0.3664681911468506, train/logprobs = tensor([[-2.2070, -3.1285],
        [-3.0303, -1.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03162351995706558
Epoch 0, Step 515: train/loss = 0.5930670499801636, train/raw-loss = 0.2996722459793091, train/logprobs = tensor([[-1.2365, -7.7525],
        [-1.1164, -1.9376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039119310677051544
Epoch 0, Step 516: train/loss = 0.5722370147705078, train/raw-loss = 0.2775994837284088, train/logprobs = tensor([[-3.9014, -5.8938],
        [-3.3727, -2.0655]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03928500413894653
Epoch 0, Step 517: train/loss = 0.6461489200592041, train/raw-loss = 0.31341391801834106, train/logprobs = tensor([[-1.0901, -4.4281],
        [-1.9373, -1.5329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04436466097831726
Epoch 0, Step 518: train/loss = 0.4347268342971802, train/raw-loss = 0.1930677592754364, train/logprobs = tensor([[-1.8358, -5.6380],
        [-3.1306, -2.2194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03222121298313141
Epoch 0, Step 519: train/loss = 0.6322296857833862, train/raw-loss = 0.4330834448337555, train/logprobs = tensor([[-1.0064, -4.3414],
        [-0.6683, -1.5482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02655283361673355
Epoch 0, Step 520: train/loss = 0.4939718246459961, train/raw-loss = 0.27908724546432495, train/logprobs = tensor([[-1.6508, -6.2545],
        [-1.9443, -2.1075]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02865128219127655
Epoch 0, Step 521: train/loss = 0.40854308009147644, train/raw-loss = 0.19453728199005127, train/logprobs = tensor([[-1.8004, -8.9798],
        [-1.9518, -2.1820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02853410691022873
Epoch 0, Step 522: train/loss = 0.4105481505393982, train/raw-loss = 0.15202531218528748, train/logprobs = tensor([[-2.3421, -7.0866],
        [-3.1898, -2.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.034469712525606155
Epoch 0, Step 523: train/loss = 0.6281952261924744, train/raw-loss = 0.4267910420894623, train/logprobs = tensor([[-0.9254, -5.5132],
        [-0.9062, -1.3634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02685389295220375
Epoch 0, Step 524: train/loss = 0.6069701910018921, train/raw-loss = 0.31588220596313477, train/logprobs = tensor([[-1.4698, -3.4129],
        [-2.4644, -1.2346]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.038811735808849335
Epoch 0, Step 525: train/loss = 0.5577899217605591, train/raw-loss = 0.36132651567459106, train/logprobs = tensor([[-2.3142, -6.0937],
        [-2.6276, -3.0780]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026195118203759193
Epoch 0, Step 526: train/loss = 0.4336957633495331, train/raw-loss = 0.20569120347499847, train/logprobs = tensor([[-1.6971, -5.4927],
        [-3.8700, -2.0530]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030400607734918594
Epoch 0, Step 527: train/loss = 0.3697924017906189, train/raw-loss = 0.15344169735908508, train/logprobs = tensor([[ -1.5343, -10.5787],
        [ -2.3782,  -2.2772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02884676307439804
Epoch 0, Step 528: train/loss = 0.7477641105651855, train/raw-loss = 0.5439849495887756, train/logprobs = tensor([[-1.1088, -1.4911],
        [-2.0520, -0.9738]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02717055380344391
Epoch 0, Step 529: train/loss = 0.44541943073272705, train/raw-loss = 0.19746345281600952, train/logprobs = tensor([[-0.9527, -8.5200],
        [-1.5827, -2.7603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033060796558856964
Epoch 0, Step 530: train/loss = 0.6430790424346924, train/raw-loss = 0.33739328384399414, train/logprobs = tensor([[-1.8362, -7.2784],
        [-1.3833, -1.7158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04075810685753822
Epoch 0, Step 531: train/loss = 0.7528446912765503, train/raw-loss = 0.5096716284751892, train/logprobs = tensor([[-2.0160, -4.5605],
        [-1.1921, -1.9048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03242307901382446
Epoch 0, Step 532: train/loss = 0.41181111335754395, train/raw-loss = 0.1831377148628235, train/logprobs = tensor([[-1.3688, -6.5559],
        [-2.1930, -1.9157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030489785596728325
Epoch 0, Step 533: train/loss = 0.5692951083183289, train/raw-loss = 0.31665611267089844, train/logprobs = tensor([[-0.7218, -5.5364],
        [-0.7038, -1.4616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.033685196191072464
Epoch 0, Step 534: train/loss = 0.6231680512428284, train/raw-loss = 0.396965354681015, train/logprobs = tensor([[-1.8730, -3.7207],
        [-1.8521, -1.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030160360038280487
Epoch 0, Step 535: train/loss = 0.519450306892395, train/raw-loss = 0.2836504280567169, train/logprobs = tensor([[-0.8155, -3.1695],
        [-1.8513, -1.3381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03143997862935066
Epoch 0, Step 536: train/loss = 0.34021568298339844, train/raw-loss = 0.13182993233203888, train/logprobs = tensor([[-1.3272, -6.2481],
        [-3.3727, -1.7894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027784764766693115
Epoch 0, Step 537: train/loss = 0.7344830632209778, train/raw-loss = 0.5357086062431335, train/logprobs = tensor([[-1.9029, -3.2025],
        [-1.2334, -1.1843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026503264904022217
Epoch 0, Step 538: train/loss = 0.6028929948806763, train/raw-loss = 0.3945330083370209, train/logprobs = tensor([[-1.6141, -4.2129],
        [-2.4127, -1.4640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027781333774328232
Epoch 0, Step 539: train/loss = 0.4507790207862854, train/raw-loss = 0.2490578293800354, train/logprobs = tensor([[-1.2178, -6.2550],
        [-1.9650, -3.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02689615823328495
Epoch 0, Step 540: train/loss = 0.606898307800293, train/raw-loss = 0.4428997039794922, train/logprobs = tensor([[-1.5574, -3.9287],
        [-2.0547, -2.0082]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021866479888558388
Epoch 0, Step 541: train/loss = 0.4164528250694275, train/raw-loss = 0.20985829830169678, train/logprobs = tensor([[-1.8315, -5.1046],
        [-2.8831, -1.7709]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.027545934543013573
Epoch 0, Step 542: train/loss = 0.6189451813697815, train/raw-loss = 0.4283270239830017, train/logprobs = tensor([[-1.5268, -4.8691],
        [-2.6475, -2.4052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.025415755808353424
Epoch 0, Step 543: train/loss = 0.5335237979888916, train/raw-loss = 0.2234153151512146, train/logprobs = tensor([[-1.3919, -6.4192],
        [-1.4590, -1.4880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.041347797960042953
Epoch 0, Step 544: train/loss = 0.7157505750656128, train/raw-loss = 0.4809032082557678, train/logprobs = tensor([[-1.2823, -4.1958],
        [-0.7934, -1.0748]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.031312983483076096
Epoch 0, Step 545: train/loss = 0.9052984714508057, train/raw-loss = 0.6198839545249939, train/logprobs = tensor([[-0.8865, -2.3176],
        [-0.9694, -1.6270]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03805527091026306
Epoch 0, Step 546: train/loss = 0.40871718525886536, train/raw-loss = 0.22681529819965363, train/logprobs = tensor([[-2.3006, -3.9131],
        [-3.3120, -1.4874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024253584444522858
Epoch 0, Step 547: train/loss = 0.532256543636322, train/raw-loss = 0.3026140630245209, train/logprobs = tensor([[-0.9320, -5.5789],
        [-0.6458, -1.3412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030619001016020775
Epoch 0, Step 548: train/loss = 0.47456762194633484, train/raw-loss = 0.28939002752304077, train/logprobs = tensor([[-1.3897, -3.6070],
        [-2.0905, -1.1672]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02469034492969513
Epoch 0, Step 549: train/loss = 0.5952065587043762, train/raw-loss = 0.2835503816604614, train/logprobs = tensor([[-1.5917, -3.4243],
        [-3.1033, -1.1185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.04155415669083595
Epoch 0, Step 550: train/loss = 0.689588725566864, train/raw-loss = 0.4225640594959259, train/logprobs = tensor([[-1.8621, -3.9172],
        [-1.4992, -1.1553]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03560327738523483
Epoch 0, Step 551: train/loss = 0.5672144889831543, train/raw-loss = 0.41335558891296387, train/logprobs = tensor([[-1.1781, -6.0881],
        [-0.6175, -0.9309]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02051451988518238
Epoch 0, Step 552: train/loss = 0.3895305395126343, train/raw-loss = 0.20418228209018707, train/logprobs = tensor([[-1.5527, -7.8380],
        [-1.8657, -1.5714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.024713099002838135
Epoch 0, Step 553: train/loss = 0.6117227673530579, train/raw-loss = 0.29165300726890564, train/logprobs = tensor([[-2.0658, -5.6402],
        [-2.7427, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.042675964534282684
Epoch 0, Step 554: train/loss = 0.7051780223846436, train/raw-loss = 0.42990607023239136, train/logprobs = tensor([[-1.7280, -4.0094],
        [-1.5679, -1.3826]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.036702923476696014
Epoch 0, Step 555: train/loss = 0.5922590494155884, train/raw-loss = 0.3468228578567505, train/logprobs = tensor([[-2.4100, -6.9251],
        [-1.7515, -2.2668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03272482752799988
Epoch 0, Step 556: train/loss = 0.419706255197525, train/raw-loss = 0.1255822777748108, train/logprobs = tensor([[-2.1270, -7.6684],
        [-3.5312, -1.6467]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.039216529577970505
Epoch 0, Step 557: train/loss = 0.6043128371238708, train/raw-loss = 0.314630389213562, train/logprobs = tensor([[-1.1784, -5.1541],
        [-1.2421, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03862432762980461
Epoch 0, Step 558: train/loss = 0.7186392545700073, train/raw-loss = 0.45590272545814514, train/logprobs = tensor([[-2.0518, -2.7747],
        [-2.0298, -1.2814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03503153845667839
Epoch 0, Step 559: train/loss = 0.5440234541893005, train/raw-loss = 0.26892125606536865, train/logprobs = tensor([[-1.2631, -5.9105],
        [-1.6043, -1.6354]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.03668029606342316
Epoch 0, Step 560: train/loss = 0.6618945598602295, train/raw-loss = 0.45197397470474243, train/logprobs = tensor([[-1.6224, -4.4654],
        [-1.0578, -1.5707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02798941358923912
Epoch 0, Step 561: train/loss = 0.408611536026001, train/raw-loss = 0.24504253268241882, train/logprobs = tensor([[-3.1139, -6.1051],
        [-3.4271, -1.6797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.021809199824929237
Epoch 0, Step 562: train/loss = 0.8245892524719238, train/raw-loss = 0.5821707844734192, train/logprobs = tensor([[-1.4254, -3.2639],
        [-1.3429, -1.9736]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.032322462648153305
Epoch 0, Step 563: train/loss = 0.4920509457588196, train/raw-loss = 0.2925910949707031, train/logprobs = tensor([[-2.8532, -6.4830],
        [-2.8725, -1.6499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.026594650000333786
Epoch 0, Step 564: train/loss = 0.5787403583526611, train/raw-loss = 0.35655924677848816, train/logprobs = tensor([[-2.2029, -3.1497],
        [-2.8192, -0.8789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02962414175271988
Epoch 0, Step 565: train/loss = 0.612339973449707, train/raw-loss = 0.38269343972206116, train/logprobs = tensor([[-1.5477, -5.3884],
        [-1.1719, -1.3110]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.030619535595178604
Epoch 0, Step 566: train/loss = 0.4043281078338623, train/raw-loss = 0.23773831129074097, train/logprobs = tensor([[-1.9183, -8.3999],
        [-1.5774, -1.6882]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022211972624063492
Epoch 0, Step 567: train/loss = 0.5686790347099304, train/raw-loss = 0.38122355937957764, train/logprobs = tensor([[-1.7811, -9.7145],
        [-0.7098, -2.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02499406225979328
Epoch 0, Step 568: train/loss = 0.3895008862018585, train/raw-loss = 0.18264806270599365, train/logprobs = tensor([[-2.4597, -9.8811],
        [-2.7027, -1.7392]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02758037857711315
Epoch 0, Step 569: train/loss = 0.3872888386249542, train/raw-loss = 0.17620223760604858, train/logprobs = tensor([[-2.2210, -7.4302],
        [-2.7901, -2.2707]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.028144877403974533
Epoch 0, Step 570: train/loss = 0.5387001633644104, train/raw-loss = 0.3518637418746948, train/logprobs = tensor([[-1.8906, -4.9493],
        [-2.0201, -1.5684]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02491152659058571
