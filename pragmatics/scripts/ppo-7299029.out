[2024-02-20 14:32:26,677][root][INFO] - beta: 0.3
[2024-02-20 14:32:26,677][root][INFO] - max_iter: 1
[2024-02-20 14:32:26,677][root][INFO] - writing checkpoints to: /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-max-iter-1
clearing gpu cache for all ranks
Model with 7241.732096M params prepared
tokenizing 10000 training examples...
Loaded model on rank 2
Loaded reference model on rank 2
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-max-iter-1 after each epoch.
Loaded model on rank 1
Loaded reference model on rank 1
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-max-iter-1 after each epoch.
train dataset has 9500 examples.
eval dataset has 500 examples.
Loaded model on rank 0
Loaded reference model on rank 0
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-max-iter-1 after each epoch.
Loaded model on rank 3
Loaded reference model on rank 3
Writing checkpoints to /scr/jphilipp/scai/trained_models/Mistral-7B-v0.1/checkpoints/ppo-beta-0.3-max-iter-1 after each epoch.
Epoch 0, Step 0: train/loss = 0.713974118232727, train/raw-loss = 0.713974118232727, train/logprobs = tensor([[-0.7455, -1.0226],
        [-0.7364, -0.9573]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 1: train/loss = 0.752000093460083, train/raw-loss = 0.752000093460083, train/logprobs = tensor([[-0.8334, -1.3747],
        [-0.8682, -1.2134]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 2: train/loss = 0.7133010625839233, train/raw-loss = 0.7133010625839233, train/logprobs = tensor([[-0.7484, -0.8076],
        [-0.7838, -0.7331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 3: train/loss = 0.727549135684967, train/raw-loss = 0.727549135684967, train/logprobs = tensor([[-0.8421, -1.3549],
        [-0.8680, -1.1995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 4: train/loss = 0.7360972762107849, train/raw-loss = 0.7360972762107849, train/logprobs = tensor([[-1.0698, -1.4510],
        [-1.0413, -1.2337]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 5: train/loss = 0.7204396724700928, train/raw-loss = 0.7204396724700928, train/logprobs = tensor([[-0.7672, -1.0824],
        [-0.7821, -0.9518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 6: train/loss = 0.7513324618339539, train/raw-loss = 0.7513324618339539, train/logprobs = tensor([[-0.7953, -1.0975],
        [-0.8507, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 7: train/loss = 0.8787336349487305, train/raw-loss = 0.8787336349487305, train/logprobs = tensor([[-1.0779, -1.1902],
        [-1.1492, -1.0495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 8: train/loss = 0.7739502787590027, train/raw-loss = 0.7739502787590027, train/logprobs = tensor([[-1.1014, -1.1445],
        [-1.1211, -0.9983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 9: train/loss = 0.730786919593811, train/raw-loss = 0.730786919593811, train/logprobs = tensor([[-1.1188, -1.2011],
        [-1.0964, -1.0568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 10: train/loss = 0.7592430710792542, train/raw-loss = 0.7592430710792542, train/logprobs = tensor([[-1.2226, -1.6038],
        [-1.1765, -1.5098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 11: train/loss = 0.7039228677749634, train/raw-loss = 0.7039228677749634, train/logprobs = tensor([[-0.7342, -1.0580],
        [-0.9309, -1.0313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 12: train/loss = 0.7423867583274841, train/raw-loss = 0.7423867583274841, train/logprobs = tensor([[-0.9704, -1.2385],
        [-0.9914, -1.1299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 13: train/loss = 0.8157531023025513, train/raw-loss = 0.8157531023025513, train/logprobs = tensor([[-1.0279, -1.1002],
        [-1.0404, -1.0388]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 14: train/loss = 0.7232985496520996, train/raw-loss = 0.7232985496520996, train/logprobs = tensor([[-0.9607, -1.3427],
        [-0.9610, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 15: train/loss = 0.6962568163871765, train/raw-loss = 0.6962568163871765, train/logprobs = tensor([[-0.8196, -0.9555],
        [-0.8241, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 16: train/loss = 0.7051495313644409, train/raw-loss = 0.7051495313644409, train/logprobs = tensor([[-0.8221, -0.9929],
        [-0.8046, -0.8659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 17: train/loss = 0.7589203715324402, train/raw-loss = 0.7589203715324402, train/logprobs = tensor([[-0.8956, -1.5347],
        [-0.8674, -1.3455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 18: train/loss = 0.7092028856277466, train/raw-loss = 0.7092028856277466, train/logprobs = tensor([[-0.8134, -0.7455],
        [-0.8448, -0.7086]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 19: train/loss = 0.7066609263420105, train/raw-loss = 0.7066609263420105, train/logprobs = tensor([[-0.9296, -1.0342],
        [-0.9464, -1.0067]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 20: train/loss = 0.7093161940574646, train/raw-loss = 0.7093161940574646, train/logprobs = tensor([[-1.3012, -1.2005],
        [-1.1840, -1.0793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 21: train/loss = 0.7097811698913574, train/raw-loss = 0.7097811698913574, train/logprobs = tensor([[-1.3539, -1.5973],
        [-1.3506, -1.4699]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 22: train/loss = 0.70055091381073, train/raw-loss = 0.70055091381073, train/logprobs = tensor([[-0.7490, -1.1321],
        [-0.8108, -0.9796]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 23: train/loss = 0.6964994668960571, train/raw-loss = 0.6964994668960571, train/logprobs = tensor([[-0.9989, -1.1937],
        [-1.0223, -1.0366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 24: train/loss = 0.7022837400436401, train/raw-loss = 0.7022837400436401, train/logprobs = tensor([[-0.7175, -0.9525],
        [-0.6778, -0.8624]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 25: train/loss = 0.7019379138946533, train/raw-loss = 0.7019379138946533, train/logprobs = tensor([[-0.8638, -1.1275],
        [-0.8749, -1.0133]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 26: train/loss = 0.7353549003601074, train/raw-loss = 0.7353549003601074, train/logprobs = tensor([[-0.6463, -1.1039],
        [-0.6486, -1.0000]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 27: train/loss = 0.7172316312789917, train/raw-loss = 0.7172316312789917, train/logprobs = tensor([[-1.1485, -1.2242],
        [-1.0707, -1.0772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 28: train/loss = 0.7442547082901001, train/raw-loss = 0.7442547082901001, train/logprobs = tensor([[-0.9744, -1.1718],
        [-1.0203, -1.1447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 29: train/loss = 0.7080467939376831, train/raw-loss = 0.7080467939376831, train/logprobs = tensor([[-1.1477, -1.0259],
        [-1.1191, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 30: train/loss = 0.7012585401535034, train/raw-loss = 0.7012585401535034, train/logprobs = tensor([[-1.1280, -1.2579],
        [-1.1611, -1.1982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 31: train/loss = 0.6932642459869385, train/raw-loss = 0.6932642459869385, train/logprobs = tensor([[-1.2200, -1.2428],
        [-1.2477, -1.1750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 32: train/loss = 0.6988556385040283, train/raw-loss = 0.6988556385040283, train/logprobs = tensor([[-1.1544, -1.2933],
        [-1.2153, -1.1706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 33: train/loss = 0.7183356285095215, train/raw-loss = 0.7183356285095215, train/logprobs = tensor([[-1.0192, -0.8052],
        [-1.0312, -0.8077]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 34: train/loss = 0.7210201621055603, train/raw-loss = 0.7210201621055603, train/logprobs = tensor([[-0.5816, -0.8397],
        [-0.5714, -0.7817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 35: train/loss = 0.7234370708465576, train/raw-loss = 0.7234370708465576, train/logprobs = tensor([[-0.9061, -0.6373],
        [-0.9531, -0.6495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 36: train/loss = 0.6991916298866272, train/raw-loss = 0.6991916298866272, train/logprobs = tensor([[-0.9190, -0.9279],
        [-0.9578, -0.8694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 37: train/loss = 0.8110309839248657, train/raw-loss = 0.8110309839248657, train/logprobs = tensor([[-0.9128, -1.6764],
        [-0.8827, -1.5108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 38: train/loss = 0.7210230827331543, train/raw-loss = 0.7210230827331543, train/logprobs = tensor([[-0.9563, -1.2494],
        [-0.9473, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 39: train/loss = 0.7364233136177063, train/raw-loss = 0.7364233136177063, train/logprobs = tensor([[-1.1877, -1.0266],
        [-1.1895, -0.9654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 40: train/loss = 0.7228058576583862, train/raw-loss = 0.7228058576583862, train/logprobs = tensor([[-1.0432, -1.0242],
        [-1.1040, -0.9697]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 41: train/loss = 0.7266352772712708, train/raw-loss = 0.7266352772712708, train/logprobs = tensor([[-0.6492, -1.1424],
        [-0.6564, -1.0691]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 42: train/loss = 0.7219683527946472, train/raw-loss = 0.7219683527946472, train/logprobs = tensor([[-1.0915, -1.6032],
        [-1.1550, -1.4828]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 43: train/loss = 0.7683465480804443, train/raw-loss = 0.7683465480804443, train/logprobs = tensor([[-0.9045, -1.5780],
        [-0.9263, -1.4838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 44: train/loss = 0.7669194340705872, train/raw-loss = 0.7669194340705872, train/logprobs = tensor([[-0.7626, -1.1490],
        [-0.7788, -1.0682]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 45: train/loss = 0.7112199068069458, train/raw-loss = 0.7112199068069458, train/logprobs = tensor([[-0.6316, -0.9687],
        [-0.6322, -0.8991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 46: train/loss = 0.7303957939147949, train/raw-loss = 0.7303957939147949, train/logprobs = tensor([[-0.9770, -1.3808],
        [-1.0208, -1.2988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 47: train/loss = 0.7417773008346558, train/raw-loss = 0.7417773008346558, train/logprobs = tensor([[-1.3705, -1.1575],
        [-1.3663, -1.1028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 48: train/loss = 0.714172899723053, train/raw-loss = 0.714172899723053, train/logprobs = tensor([[-0.8059, -0.9450],
        [-0.8191, -0.8366]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 49: train/loss = 0.8120728731155396, train/raw-loss = 0.8120728731155396, train/logprobs = tensor([[-0.8137, -1.6513],
        [-0.8865, -1.5815]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 50: train/loss = 0.7227821946144104, train/raw-loss = 0.7227821946144104, train/logprobs = tensor([[-0.9871, -1.3782],
        [-0.9947, -1.3580]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 51: train/loss = 0.7082295417785645, train/raw-loss = 0.7082295417785645, train/logprobs = tensor([[-0.8649, -1.2225],
        [-0.8688, -1.1157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 52: train/loss = 0.7377454042434692, train/raw-loss = 0.7377454042434692, train/logprobs = tensor([[-1.0971, -0.7423],
        [-1.1489, -0.7203]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 53: train/loss = 0.7064391374588013, train/raw-loss = 0.7064391374588013, train/logprobs = tensor([[-1.3404, -1.3085],
        [-1.3279, -1.1786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 54: train/loss = 0.697195291519165, train/raw-loss = 0.697195291519165, train/logprobs = tensor([[-0.9319, -0.9996],
        [-1.0078, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 55: train/loss = 0.7213572263717651, train/raw-loss = 0.7213572263717651, train/logprobs = tensor([[-1.0288, -1.1987],
        [-0.9993, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 56: train/loss = 0.7000918984413147, train/raw-loss = 0.7000918984413147, train/logprobs = tensor([[-0.8808, -0.7692],
        [-0.8665, -0.7178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 57: train/loss = 0.7425727248191833, train/raw-loss = 0.7425727248191833, train/logprobs = tensor([[-0.8949, -1.2674],
        [-0.9367, -1.1799]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 58: train/loss = 0.7090755701065063, train/raw-loss = 0.7090755701065063, train/logprobs = tensor([[-0.6935, -0.9580],
        [-0.7386, -0.8974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 59: train/loss = 0.7432910799980164, train/raw-loss = 0.7432910799980164, train/logprobs = tensor([[-1.2190, -1.1246],
        [-1.2778, -1.0591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 60: train/loss = 0.7427197694778442, train/raw-loss = 0.7427197694778442, train/logprobs = tensor([[-1.0228, -1.0941],
        [-1.1349, -1.0066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 61: train/loss = 0.7869271636009216, train/raw-loss = 0.7869271636009216, train/logprobs = tensor([[-0.7442, -1.3274],
        [-0.7931, -1.2817]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 62: train/loss = 0.7196345329284668, train/raw-loss = 0.7196345329284668, train/logprobs = tensor([[-1.0222, -1.2890],
        [-1.0348, -1.1688]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 63: train/loss = 0.7207246422767639, train/raw-loss = 0.7207246422767639, train/logprobs = tensor([[-1.1953, -1.2005],
        [-1.1689, -1.1052]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0
Epoch 0, Step 64: train/loss = 0.7049100995063782, train/raw-loss = 0.7049092054367065, train/logprobs = tensor([[-0.8885, -1.0939],
        [-0.8977, -0.9809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.9370348784141243e-06
Epoch 0, Step 65: train/loss = 0.7392329573631287, train/raw-loss = 0.7392323017120361, train/logprobs = tensor([[-0.8020, -1.0562],
        [-0.8292, -1.0093]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.396001946181059e-06
Epoch 0, Step 66: train/loss = 0.7462414503097534, train/raw-loss = 0.7462382912635803, train/logprobs = tensor([[-1.2354, -0.7571],
        [-1.3378, -0.6785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0626343282638118e-05
Epoch 0, Step 67: train/loss = 0.6990240812301636, train/raw-loss = 0.6990237236022949, train/logprobs = tensor([[-0.9310, -0.8397],
        [-0.8898, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0505573300179094e-06
Epoch 0, Step 68: train/loss = 0.8099243640899658, train/raw-loss = 0.8099202513694763, train/logprobs = tensor([[-0.7644, -1.3528],
        [-0.7211, -1.1811]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3719122762267943e-05
Epoch 0, Step 69: train/loss = 0.7167185544967651, train/raw-loss = 0.7167035937309265, train/logprobs = tensor([[-1.2602, -1.5008],
        [-1.2345, -1.2538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.004899139748886e-05
Epoch 0, Step 70: train/loss = 0.7707594633102417, train/raw-loss = 0.7707569003105164, train/logprobs = tensor([[-1.2194, -0.9239],
        [-1.3326, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.531864295946434e-06
Epoch 0, Step 71: train/loss = 0.6943498849868774, train/raw-loss = 0.6943473815917969, train/logprobs = tensor([[-1.1919, -1.3115],
        [-1.1991, -1.2469]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.15957537270151e-06
Epoch 0, Step 72: train/loss = 0.6991447806358337, train/raw-loss = 0.699142336845398, train/logprobs = tensor([[-0.8063, -1.0326],
        [-0.7657, -0.9761]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.185102160496172e-06
Epoch 0, Step 73: train/loss = 0.803013801574707, train/raw-loss = 0.8030128479003906, train/logprobs = tensor([[-0.7461, -1.5441],
        [-0.7393, -1.4648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.231991286156699e-06
Epoch 0, Step 74: train/loss = 0.7407569289207458, train/raw-loss = 0.7407509088516235, train/logprobs = tensor([[-0.7271, -1.2262],
        [-0.7566, -1.1488]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0220140868332237e-05
Epoch 0, Step 75: train/loss = 0.7788282632827759, train/raw-loss = 0.7788270711898804, train/logprobs = tensor([[-0.7307, -1.1778],
        [-0.7504, -1.1176]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6648125387728214e-06
Epoch 0, Step 76: train/loss = 0.7507869601249695, train/raw-loss = 0.7507853507995605, train/logprobs = tensor([[-0.6916, -1.3928],
        [-0.6932, -1.0853]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.384374162531458e-06
Epoch 0, Step 77: train/loss = 0.7174981832504272, train/raw-loss = 0.7174949049949646, train/logprobs = tensor([[-1.0162, -1.3148],
        [-0.9987, -1.1727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0852134437300265e-05
Epoch 0, Step 78: train/loss = 0.6950264573097229, train/raw-loss = 0.6950250864028931, train/logprobs = tensor([[-0.7712, -0.8249],
        [-0.7300, -0.7485]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.372051989776082e-06
Epoch 0, Step 79: train/loss = 0.6947548389434814, train/raw-loss = 0.6947546601295471, train/logprobs = tensor([[-0.8019, -0.8601],
        [-0.8157, -0.7750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.436683517880738e-07
Epoch 0, Step 80: train/loss = 0.7352864742279053, train/raw-loss = 0.7352796792984009, train/logprobs = tensor([[-0.9642, -1.3040],
        [-0.9283, -1.2369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.2627715225098655e-05
Epoch 0, Step 81: train/loss = 0.7208038568496704, train/raw-loss = 0.720798134803772, train/logprobs = tensor([[-1.0896, -1.5029],
        [-1.1253, -1.4350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.908809645101428e-05
Epoch 0, Step 82: train/loss = 0.7099791169166565, train/raw-loss = 0.7099781036376953, train/logprobs = tensor([[-0.8767, -0.9823],
        [-0.8961, -0.8665]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.3455435186624527e-06
Epoch 0, Step 83: train/loss = 0.9490991830825806, train/raw-loss = 0.9490898847579956, train/logprobs = tensor([[-0.9144, -1.7288],
        [-0.9022, -1.5242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1099203624762595e-05
Epoch 0, Step 84: train/loss = 0.7110969424247742, train/raw-loss = 0.7110966444015503, train/logprobs = tensor([[-1.2172, -1.1564],
        [-1.2617, -1.0978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0426356311654672e-06
Epoch 0, Step 85: train/loss = 0.6977097988128662, train/raw-loss = 0.6977087259292603, train/logprobs = tensor([[-1.0026, -1.1036],
        [-1.0820, -1.0316]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.6774763430003077e-06
Epoch 0, Step 86: train/loss = 0.7347055673599243, train/raw-loss = 0.7347038984298706, train/logprobs = tensor([[-0.6877, -1.1756],
        [-0.6774, -1.1066]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.4199626902118325e-06
Epoch 0, Step 87: train/loss = 0.7025367021560669, train/raw-loss = 0.7025347948074341, train/logprobs = tensor([[-0.6962, -0.8524],
        [-0.6851, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.335030775517225e-06
Epoch 0, Step 88: train/loss = 0.7064637541770935, train/raw-loss = 0.70646071434021, train/logprobs = tensor([[-0.6467, -0.8909],
        [-0.6169, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0324953109375201e-05
Epoch 0, Step 89: train/loss = 0.708743691444397, train/raw-loss = 0.7087435722351074, train/logprobs = tensor([[-0.7867, -0.5888],
        [-0.7930, -0.5607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.3831187213072553e-07
Epoch 0, Step 90: train/loss = 0.7006210088729858, train/raw-loss = 0.7006122469902039, train/logprobs = tensor([[-1.0395, -1.1992],
        [-1.0478, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.916638186434284e-05
Epoch 0, Step 91: train/loss = 0.7277442812919617, train/raw-loss = 0.7277399897575378, train/logprobs = tensor([[-0.7945, -1.2616],
        [-0.7787, -1.1705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4566689060302451e-05
Epoch 0, Step 92: train/loss = 0.7366926670074463, train/raw-loss = 0.7366890907287598, train/logprobs = tensor([[-0.8995, -1.4687],
        [-0.8996, -1.3443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1690114661178086e-05
Epoch 0, Step 93: train/loss = 0.6955164074897766, train/raw-loss = 0.6955157518386841, train/logprobs = tensor([[-0.8612, -0.9882],
        [-0.7850, -0.8148]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.142676294170087e-06
Epoch 0, Step 94: train/loss = 0.7347521781921387, train/raw-loss = 0.7347389459609985, train/logprobs = tensor([[-1.2951, -1.5843],
        [-1.3217, -1.4557]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.423686186783016e-05
Epoch 0, Step 95: train/loss = 0.6925964951515198, train/raw-loss = 0.6925891041755676, train/logprobs = tensor([[-0.8851, -1.0643],
        [-0.9299, -0.9436]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.4696506443433464e-05
Epoch 0, Step 96: train/loss = 0.7192591428756714, train/raw-loss = 0.7192153930664062, train/logprobs = tensor([[-0.9049, -1.3473],
        [-0.9672, -1.1874]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014580093557015061
Epoch 0, Step 97: train/loss = 0.7299172878265381, train/raw-loss = 0.7299003601074219, train/logprobs = tensor([[-0.8195, -1.3357],
        [-0.9365, -1.3257]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.681527545675635e-05
Epoch 0, Step 98: train/loss = 0.7099161744117737, train/raw-loss = 0.709891140460968, train/logprobs = tensor([[-0.7282, -0.7769],
        [-0.8119, -0.7505]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.33258091006428e-05
Epoch 0, Step 99: train/loss = 0.6944030523300171, train/raw-loss = 0.6943703889846802, train/logprobs = tensor([[-0.9940, -1.0152],
        [-0.9777, -0.9253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010882833157666028
Epoch 0, Step 100: train/loss = 0.7138805389404297, train/raw-loss = 0.7138744592666626, train/logprobs = tensor([[-0.8060, -1.0920],
        [-0.8045, -1.0452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0244362531229854e-05
Epoch 0, Step 101: train/loss = 0.7314263582229614, train/raw-loss = 0.7314231395721436, train/logprobs = tensor([[-0.9143, -1.1134],
        [-0.9643, -1.0623]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0983188985846937e-05
Epoch 0, Step 102: train/loss = 0.7173095941543579, train/raw-loss = 0.7172422409057617, train/logprobs = tensor([[-0.7772, -1.1425],
        [-0.8143, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022429850650951266
Epoch 0, Step 103: train/loss = 0.772000789642334, train/raw-loss = 0.771980881690979, train/logprobs = tensor([[-0.8997, -1.4658],
        [-0.9602, -1.4751]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.637466140091419e-05
Epoch 0, Step 104: train/loss = 0.7111765146255493, train/raw-loss = 0.7111440300941467, train/logprobs = tensor([[-0.7491, -1.1086],
        [-0.7420, -0.9801]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010813389963004738
Epoch 0, Step 105: train/loss = 0.7093638181686401, train/raw-loss = 0.7093633413314819, train/logprobs = tensor([[-1.0744, -1.1950],
        [-1.0986, -1.1271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4189263310981914e-06
Epoch 0, Step 106: train/loss = 0.7457292079925537, train/raw-loss = 0.7457170486450195, train/logprobs = tensor([[-0.5940, -1.1549],
        [-0.6897, -1.0644]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.053639713674784e-05
Epoch 0, Step 107: train/loss = 0.698188841342926, train/raw-loss = 0.6981624364852905, train/logprobs = tensor([[-0.9696, -0.9827],
        [-1.0343, -0.9492]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.792587323114276e-05
Epoch 0, Step 108: train/loss = 0.7189731001853943, train/raw-loss = 0.7189649343490601, train/logprobs = tensor([[-1.4107, -1.6988],
        [-1.2302, -1.5263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.720890915952623e-05
Epoch 0, Step 109: train/loss = 0.7490366697311401, train/raw-loss = 0.7489432096481323, train/logprobs = tensor([[-1.0668, -1.8224],
        [-1.0388, -1.6058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003115807776339352
Epoch 0, Step 110: train/loss = 0.7276235222816467, train/raw-loss = 0.727598249912262, train/logprobs = tensor([[-1.2098, -1.2279],
        [-1.3433, -1.1770]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.429140143562108e-05
Epoch 0, Step 111: train/loss = 0.7023269534111023, train/raw-loss = 0.7023100256919861, train/logprobs = tensor([[-0.7766, -0.7540],
        [-0.8127, -0.7478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.650106322718784e-05
Epoch 0, Step 112: train/loss = 0.6950955390930176, train/raw-loss = 0.6950924396514893, train/logprobs = tensor([[-0.6639, -0.7154],
        [-0.6800, -0.6890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.0265153832733631e-05
Epoch 0, Step 113: train/loss = 0.7408720850944519, train/raw-loss = 0.7408447265625, train/logprobs = tensor([[-0.9283, -1.3089],
        [-0.9034, -1.2053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.123131167143583e-05
Epoch 0, Step 114: train/loss = 0.6945953369140625, train/raw-loss = 0.6945458054542542, train/logprobs = tensor([[-0.9183, -1.0704],
        [-1.0083, -0.9974]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016501659411005676
Epoch 0, Step 115: train/loss = 0.7214049100875854, train/raw-loss = 0.7212498188018799, train/logprobs = tensor([[-0.9840, -1.2332],
        [-1.0471, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005169011419638991
Epoch 0, Step 116: train/loss = 0.7060222625732422, train/raw-loss = 0.7060147523880005, train/logprobs = tensor([[-0.7790, -1.0575],
        [-0.7922, -1.0120]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5106146495090798e-05
Epoch 0, Step 117: train/loss = 0.6997466087341309, train/raw-loss = 0.6996211409568787, train/logprobs = tensor([[-0.7803, -1.0914],
        [-0.8241, -0.8919]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004185033030807972
Epoch 0, Step 118: train/loss = 0.7393226623535156, train/raw-loss = 0.7393063902854919, train/logprobs = tensor([[-1.0045, -0.6711],
        [-1.0264, -0.6271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.424993287306279e-05
Epoch 0, Step 119: train/loss = 0.7114825248718262, train/raw-loss = 0.7114782333374023, train/logprobs = tensor([[-0.6228, -0.7888],
        [-0.6159, -0.8019]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4269811799749732e-05
Epoch 0, Step 120: train/loss = 0.7427380084991455, train/raw-loss = 0.7425228357315063, train/logprobs = tensor([[-0.8914, -1.5856],
        [-0.9395, -1.4071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00071727205067873
Epoch 0, Step 121: train/loss = 0.7312281131744385, train/raw-loss = 0.7310588359832764, train/logprobs = tensor([[-0.8712, -1.2630],
        [-0.9127, -1.0954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005640438757836819
Epoch 0, Step 122: train/loss = 0.7130514979362488, train/raw-loss = 0.7130453586578369, train/logprobs = tensor([[-0.6626, -1.0037],
        [-0.7420, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.079085970763117e-05
Epoch 0, Step 123: train/loss = 0.7140597701072693, train/raw-loss = 0.7140483856201172, train/logprobs = tensor([[-0.9896, -0.9444],
        [-0.9791, -0.8472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.7867852370254695e-05
Epoch 0, Step 124: train/loss = 0.6930277943611145, train/raw-loss = 0.6930033564567566, train/logprobs = tensor([[-0.8237, -0.8882],
        [-0.8530, -0.8298]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.136169344652444e-05
Epoch 0, Step 125: train/loss = 0.741822361946106, train/raw-loss = 0.7417904138565063, train/logprobs = tensor([[-0.9236, -1.5053],
        [-1.0515, -1.4129]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010643264977261424
Epoch 0, Step 126: train/loss = 0.7387424111366272, train/raw-loss = 0.7386436462402344, train/logprobs = tensor([[-0.8723, -1.5077],
        [-0.9086, -1.3879]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003292789915576577
Epoch 0, Step 127: train/loss = 0.7007189989089966, train/raw-loss = 0.7006646990776062, train/logprobs = tensor([[-1.0514, -0.9230],
        [-1.1471, -0.8703]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018089315562974662
Epoch 0, Step 128: train/loss = 0.7000933885574341, train/raw-loss = 0.6995435953140259, train/logprobs = tensor([[-0.9034, -0.9954],
        [-1.0091, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018329927697777748
Epoch 0, Step 129: train/loss = 0.7157590389251709, train/raw-loss = 0.7144947052001953, train/logprobs = tensor([[-0.7004, -1.1686],
        [-0.7302, -0.9343]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004214370157569647
Epoch 0, Step 130: train/loss = 0.708639919757843, train/raw-loss = 0.7086334228515625, train/logprobs = tensor([[-0.6758, -0.6429],
        [-0.6885, -0.6024]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1597712475340813e-05
Epoch 0, Step 131: train/loss = 0.7190606594085693, train/raw-loss = 0.717548131942749, train/logprobs = tensor([[-1.0478, -1.3045],
        [-1.1071, -1.0049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005041621159762144
Epoch 0, Step 132: train/loss = 0.7423862814903259, train/raw-loss = 0.7413628101348877, train/logprobs = tensor([[-1.1110, -1.3867],
        [-1.1376, -1.1132]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003411439945921302
Epoch 0, Step 133: train/loss = 0.7311616539955139, train/raw-loss = 0.730087161064148, train/logprobs = tensor([[-0.8543, -1.4717],
        [-0.9141, -1.2030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035814931616187096
Epoch 0, Step 134: train/loss = 0.700096845626831, train/raw-loss = 0.7000067234039307, train/logprobs = tensor([[-0.8832, -0.7723],
        [-0.8556, -0.7003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003004105528816581
Epoch 0, Step 135: train/loss = 0.6970067024230957, train/raw-loss = 0.6969836354255676, train/logprobs = tensor([[-0.7243, -0.8178],
        [-0.7375, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.700560672674328e-05
Epoch 0, Step 136: train/loss = 0.7119860053062439, train/raw-loss = 0.711946964263916, train/logprobs = tensor([[-0.8928, -0.8360],
        [-0.9238, -0.8223]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013027657405473292
Epoch 0, Step 137: train/loss = 0.7051684856414795, train/raw-loss = 0.7049447298049927, train/logprobs = tensor([[-0.8192, -1.0633],
        [-0.8837, -0.8971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007458408363163471
Epoch 0, Step 138: train/loss = 0.7206549644470215, train/raw-loss = 0.7195957899093628, train/logprobs = tensor([[-0.6522, -1.1558],
        [-0.7110, -0.9450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003530831541866064
Epoch 0, Step 139: train/loss = 0.7652813792228699, train/raw-loss = 0.7647854089736938, train/logprobs = tensor([[-0.6504, -1.2196],
        [-0.7178, -1.1314]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016532333102077246
Epoch 0, Step 140: train/loss = 0.7294571399688721, train/raw-loss = 0.7293112277984619, train/logprobs = tensor([[-1.1057, -0.9786],
        [-1.1813, -0.8739]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004862930509261787
Epoch 0, Step 141: train/loss = 0.6980162262916565, train/raw-loss = 0.6978791952133179, train/logprobs = tensor([[-0.8165, -0.9283],
        [-0.7809, -0.7400]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004566351417452097
Epoch 0, Step 142: train/loss = 0.696563184261322, train/raw-loss = 0.6964951753616333, train/logprobs = tensor([[-0.8005, -0.7728],
        [-0.8826, -0.7775]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022640207316726446
Epoch 0, Step 143: train/loss = 0.697927713394165, train/raw-loss = 0.6978912949562073, train/logprobs = tensor([[-0.8322, -0.8878],
        [-0.7847, -0.8501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001213195500895381
Epoch 0, Step 144: train/loss = 0.875146746635437, train/raw-loss = 0.8746515512466431, train/logprobs = tensor([[-0.7623, -1.8112],
        [-0.8257, -1.5306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001650812104344368
Epoch 0, Step 145: train/loss = 0.7199701070785522, train/raw-loss = 0.7180238962173462, train/logprobs = tensor([[-1.0163, -1.7980],
        [-1.1245, -1.3690]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006487329490482807
Epoch 0, Step 146: train/loss = 0.7079207301139832, train/raw-loss = 0.7075376510620117, train/logprobs = tensor([[-1.0539, -1.1927],
        [-1.1502, -1.1460]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012768483720719814
Epoch 0, Step 147: train/loss = 0.7107200026512146, train/raw-loss = 0.7102409601211548, train/logprobs = tensor([[-0.7440, -0.9615],
        [-0.7594, -0.8378]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001597008085809648
Epoch 0, Step 148: train/loss = 0.6992360353469849, train/raw-loss = 0.6984459161758423, train/logprobs = tensor([[-0.7012, -0.7451],
        [-0.8133, -0.6006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026338379830121994
Epoch 0, Step 149: train/loss = 0.698592483997345, train/raw-loss = 0.6985018253326416, train/logprobs = tensor([[-0.5907, -0.7787],
        [-0.6177, -0.6786]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003023942990694195
Epoch 0, Step 150: train/loss = 0.7187981605529785, train/raw-loss = 0.7186068892478943, train/logprobs = tensor([[-1.0968, -0.9363],
        [-1.1197, -0.8029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000637661200016737
Epoch 0, Step 151: train/loss = 0.7039186954498291, train/raw-loss = 0.7034850120544434, train/logprobs = tensor([[-0.7258, -0.8923],
        [-0.7525, -0.7381]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014455134514719248
Epoch 0, Step 152: train/loss = 0.7182552218437195, train/raw-loss = 0.7167195677757263, train/logprobs = tensor([[-1.0436, -1.0418],
        [-1.1783, -0.8576]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005118880420923233
Epoch 0, Step 153: train/loss = 0.7057309150695801, train/raw-loss = 0.7055249214172363, train/logprobs = tensor([[-0.7412, -1.0161],
        [-0.9205, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006867855554446578
Epoch 0, Step 154: train/loss = 0.8776602149009705, train/raw-loss = 0.8775429725646973, train/logprobs = tensor([[-0.6967, -1.7202],
        [-0.6843, -1.4825]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003907807404175401
Epoch 0, Step 155: train/loss = 0.7437019348144531, train/raw-loss = 0.7432849407196045, train/logprobs = tensor([[-0.7366, -1.4899],
        [-0.7699, -1.3171]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013900941703468561
Epoch 0, Step 156: train/loss = 0.6932011842727661, train/raw-loss = 0.6914523839950562, train/logprobs = tensor([[-0.9497, -1.1243],
        [-1.0021, -0.7928]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005829164758324623
Epoch 0, Step 157: train/loss = 0.7426779270172119, train/raw-loss = 0.7422211170196533, train/logprobs = tensor([[-0.8539, -1.3857],
        [-0.8670, -1.0302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001522688427940011
Epoch 0, Step 158: train/loss = 0.7009890079498291, train/raw-loss = 0.7006312608718872, train/logprobs = tensor([[-0.6267, -0.8725],
        [-0.6808, -0.7524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011922556441277266
Epoch 0, Step 159: train/loss = 0.6994042992591858, train/raw-loss = 0.699127197265625, train/logprobs = tensor([[-0.9350, -1.0517],
        [-0.9745, -0.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009237310150638223
Epoch 0, Step 160: train/loss = 0.7084343433380127, train/raw-loss = 0.7083505392074585, train/logprobs = tensor([[-0.7950, -1.0235],
        [-0.8482, -1.0058]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027917808620259166
Epoch 0, Step 161: train/loss = 0.7045698165893555, train/raw-loss = 0.7043145895004272, train/logprobs = tensor([[-0.6430, -0.8974],
        [-0.7156, -0.7813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008507161401212215
Epoch 0, Step 162: train/loss = 0.7087367177009583, train/raw-loss = 0.7084445953369141, train/logprobs = tensor([[-0.7106, -0.8857],
        [-0.8034, -0.8359]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009733980987221003
Epoch 0, Step 163: train/loss = 0.7547560930252075, train/raw-loss = 0.7544932961463928, train/logprobs = tensor([[-0.9428, -1.2467],
        [-0.9983, -1.1030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008762459619902074
Epoch 0, Step 164: train/loss = 0.7119173407554626, train/raw-loss = 0.7118357419967651, train/logprobs = tensor([[-0.5725, -0.9224],
        [-0.5972, -0.8702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002718576288316399
Epoch 0, Step 165: train/loss = 0.7058636546134949, train/raw-loss = 0.7057845592498779, train/logprobs = tensor([[-0.8860, -0.9947],
        [-1.0480, -0.9782]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026355311274528503
Epoch 0, Step 166: train/loss = 0.704436719417572, train/raw-loss = 0.7044036388397217, train/logprobs = tensor([[-0.8256, -1.0359],
        [-0.9280, -1.0648]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011057968367822468
Epoch 0, Step 167: train/loss = 0.7043260931968689, train/raw-loss = 0.7038619518280029, train/logprobs = tensor([[-0.7764, -1.1123],
        [-1.0241, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001547068590298295
Epoch 0, Step 168: train/loss = 0.7164150476455688, train/raw-loss = 0.7159082889556885, train/logprobs = tensor([[-0.6317, -1.1572],
        [-0.6944, -1.0512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016893759602680802
Epoch 0, Step 169: train/loss = 0.7116252183914185, train/raw-loss = 0.7086339592933655, train/logprobs = tensor([[-0.5801, -1.1539],
        [-0.7248, -0.8802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009970694780349731
Epoch 0, Step 170: train/loss = 0.7388017177581787, train/raw-loss = 0.7382761836051941, train/logprobs = tensor([[-0.7587, -1.3434],
        [-0.8316, -1.1933]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017515928484499454
Epoch 0, Step 171: train/loss = 0.701251745223999, train/raw-loss = 0.7008231282234192, train/logprobs = tensor([[-0.6596, -0.8027],
        [-0.7533, -0.7234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001428938820026815
Epoch 0, Step 172: train/loss = 0.7079788446426392, train/raw-loss = 0.7077020406723022, train/logprobs = tensor([[-0.8606, -1.0278],
        [-0.9672, -1.0351]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009224789682775736
Epoch 0, Step 173: train/loss = 0.7128841280937195, train/raw-loss = 0.7128487229347229, train/logprobs = tensor([[-1.0286, -1.4338],
        [-1.0958, -1.3789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011809106217697263
Epoch 0, Step 174: train/loss = 0.7085478901863098, train/raw-loss = 0.7065750360488892, train/logprobs = tensor([[-0.6768, -1.2638],
        [-0.8111, -0.8927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006576319690793753
Epoch 0, Step 175: train/loss = 0.7919462323188782, train/raw-loss = 0.7915834188461304, train/logprobs = tensor([[-0.8912, -1.4771],
        [-0.9262, -1.4054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012093806872144341
Epoch 0, Step 176: train/loss = 0.7052537798881531, train/raw-loss = 0.7047149538993835, train/logprobs = tensor([[-1.0275, -1.2552],
        [-1.0272, -1.1596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017961271805688739
Epoch 0, Step 177: train/loss = 0.7109590768814087, train/raw-loss = 0.7108570337295532, train/logprobs = tensor([[-0.9793, -0.9456],
        [-0.9570, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034010340459644794
Epoch 0, Step 178: train/loss = 0.7445085644721985, train/raw-loss = 0.7425583600997925, train/logprobs = tensor([[-0.7080, -1.4939],
        [-0.8761, -1.2482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006500891875475645
Epoch 0, Step 179: train/loss = 0.6974292397499084, train/raw-loss = 0.6973069906234741, train/logprobs = tensor([[-1.0092, -0.9171],
        [-0.9989, -0.7912]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004072812735103071
Epoch 0, Step 180: train/loss = 0.7019448280334473, train/raw-loss = 0.7017691135406494, train/logprobs = tensor([[-0.7139, -1.0412],
        [-0.7761, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005858188378624618
Epoch 0, Step 181: train/loss = 0.8071916103363037, train/raw-loss = 0.8049135208129883, train/logprobs = tensor([[-1.1835, -1.5382],
        [-1.1062, -1.2424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007593730464577675
Epoch 0, Step 182: train/loss = 0.6982299089431763, train/raw-loss = 0.6980395317077637, train/logprobs = tensor([[-0.8169, -0.9988],
        [-0.9058, -0.9495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006347199669107795
Epoch 0, Step 183: train/loss = 0.7525795698165894, train/raw-loss = 0.7513511180877686, train/logprobs = tensor([[-0.8462, -1.5045],
        [-0.9592, -1.2185]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0040947794914245605
Epoch 0, Step 184: train/loss = 0.6938427090644836, train/raw-loss = 0.6938027739524841, train/logprobs = tensor([[-0.8629, -0.8062],
        [-0.8264, -0.7724]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013329449575394392
Epoch 0, Step 185: train/loss = 0.6992859840393066, train/raw-loss = 0.699262261390686, train/logprobs = tensor([[-0.6536, -0.7754],
        [-0.7670, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.8885059338063e-05
Epoch 0, Step 186: train/loss = 0.7694326043128967, train/raw-loss = 0.7685359716415405, train/logprobs = tensor([[-1.1435, -1.4795],
        [-1.2133, -1.2778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029889876022934914
Epoch 0, Step 187: train/loss = 0.7042016386985779, train/raw-loss = 0.7028759717941284, train/logprobs = tensor([[-1.0515, -1.0265],
        [-1.1399, -0.7781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004418801516294479
Epoch 0, Step 188: train/loss = 0.7700626850128174, train/raw-loss = 0.769375205039978, train/logprobs = tensor([[-1.0635, -1.4835],
        [-1.1819, -1.2562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00229180627502501
Epoch 0, Step 189: train/loss = 0.7388426065444946, train/raw-loss = 0.7383614778518677, train/logprobs = tensor([[-0.6983, -1.2838],
        [-0.8481, -1.3057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001603935263119638
Epoch 0, Step 190: train/loss = 0.7036819458007812, train/raw-loss = 0.7029933929443359, train/logprobs = tensor([[-0.8121, -1.0362],
        [-0.9115, -1.0090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022953064180910587
Epoch 0, Step 191: train/loss = 0.7510058879852295, train/raw-loss = 0.7509312629699707, train/logprobs = tensor([[-0.9874, -1.2160],
        [-1.1284, -1.2967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002488958416506648
Epoch 0, Step 192: train/loss = 0.6990969181060791, train/raw-loss = 0.699043869972229, train/logprobs = tensor([[-0.7918, -0.9254],
        [-0.8222, -0.9395]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017688621301203966
Epoch 0, Step 193: train/loss = 0.6950923204421997, train/raw-loss = 0.6947623491287231, train/logprobs = tensor([[-0.9897, -1.2120],
        [-1.2501, -1.2049]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010997552890330553
Epoch 0, Step 194: train/loss = 0.7409760355949402, train/raw-loss = 0.7381615042686462, train/logprobs = tensor([[-0.9094, -1.6326],
        [-0.9576, -1.2747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.009381991811096668
Epoch 0, Step 195: train/loss = 0.6960831880569458, train/raw-loss = 0.6960223913192749, train/logprobs = tensor([[-0.6800, -0.8362],
        [-0.7355, -0.8157]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020262209000065923
Epoch 0, Step 196: train/loss = 0.8608712553977966, train/raw-loss = 0.8522491455078125, train/logprobs = tensor([[-0.8208, -2.5287],
        [-0.9606, -1.7271]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.02874056249856949
Epoch 0, Step 197: train/loss = 0.7241545915603638, train/raw-loss = 0.7240587472915649, train/logprobs = tensor([[-0.6206, -1.0266],
        [-0.7501, -0.9651]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003193587181158364
Epoch 0, Step 198: train/loss = 0.7157979607582092, train/raw-loss = 0.7151008248329163, train/logprobs = tensor([[-1.0079, -0.9691],
        [-1.0988, -0.8190]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002323848893865943
Epoch 0, Step 199: train/loss = 0.7397450804710388, train/raw-loss = 0.7365976572036743, train/logprobs = tensor([[-0.9412, -1.1315],
        [-1.0878, -0.8938]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010491527616977692
Epoch 0, Step 200: train/loss = 0.7917834520339966, train/raw-loss = 0.7880738377571106, train/logprobs = tensor([[-0.7896, -1.5622],
        [-1.0228, -1.3090]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012365478090941906
Epoch 0, Step 201: train/loss = 0.7081994414329529, train/raw-loss = 0.7072975635528564, train/logprobs = tensor([[-0.6429, -1.0481],
        [-0.7393, -0.8964]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030063518788665533
Epoch 0, Step 202: train/loss = 0.7005504965782166, train/raw-loss = 0.6995464563369751, train/logprobs = tensor([[-0.7350, -0.9679],
        [-0.9463, -0.9251]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0033468790352344513
Epoch 0, Step 203: train/loss = 0.7143492698669434, train/raw-loss = 0.713716983795166, train/logprobs = tensor([[-1.0203, -1.0043],
        [-1.1068, -0.8960]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021073943935334682
Epoch 0, Step 204: train/loss = 0.6989017724990845, train/raw-loss = 0.698604941368103, train/logprobs = tensor([[-0.7765, -0.7867],
        [-0.9344, -0.7486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009892795933410525
Epoch 0, Step 205: train/loss = 0.6935439705848694, train/raw-loss = 0.6934518218040466, train/logprobs = tensor([[-0.9426, -0.9981],
        [-1.1127, -0.9910]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030711974250152707
Epoch 0, Step 206: train/loss = 0.7009331583976746, train/raw-loss = 0.7008950710296631, train/logprobs = tensor([[-0.7833, -0.9177],
        [-0.8167, -0.9004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012699401122517884
Epoch 0, Step 207: train/loss = 0.7010375261306763, train/raw-loss = 0.7010250687599182, train/logprobs = tensor([[-0.9511, -1.0146],
        [-0.9798, -0.9965]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.155655551585369e-05
Epoch 0, Step 208: train/loss = 0.6958013772964478, train/raw-loss = 0.6957327723503113, train/logprobs = tensor([[-0.7423, -0.6690],
        [-0.8234, -0.6880]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022860273020341992
Epoch 0, Step 209: train/loss = 0.7232155203819275, train/raw-loss = 0.7215622067451477, train/logprobs = tensor([[-0.9732, -1.5926],
        [-1.0982, -1.3262]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0055109653621912
Epoch 0, Step 210: train/loss = 0.7112257480621338, train/raw-loss = 0.7105870246887207, train/logprobs = tensor([[-0.9176, -0.8692],
        [-1.2479, -0.8645]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021292581222951412
Epoch 0, Step 211: train/loss = 0.716334879398346, train/raw-loss = 0.715763509273529, train/logprobs = tensor([[-0.6845, -1.0492],
        [-0.8543, -0.8451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019043253269046545
Epoch 0, Step 212: train/loss = 0.6975765228271484, train/raw-loss = 0.6968838572502136, train/logprobs = tensor([[-0.8749, -0.8366],
        [-1.0315, -0.8158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002308861119672656
Epoch 0, Step 213: train/loss = 0.7051311731338501, train/raw-loss = 0.704422652721405, train/logprobs = tensor([[-1.0095, -1.1830],
        [-1.2701, -1.0922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00236168853007257
Epoch 0, Step 214: train/loss = 0.7134597897529602, train/raw-loss = 0.7121920585632324, train/logprobs = tensor([[-0.6880, -1.0028],
        [-0.8337, -0.8528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042258743196725845
Epoch 0, Step 215: train/loss = 0.7359153032302856, train/raw-loss = 0.7351964116096497, train/logprobs = tensor([[-1.2845, -1.0543],
        [-1.4421, -0.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023962268605828285
Epoch 0, Step 216: train/loss = 0.7111608982086182, train/raw-loss = 0.710573136806488, train/logprobs = tensor([[-1.0283, -1.3301],
        [-1.1082, -1.1638]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001959091518074274
Epoch 0, Step 217: train/loss = 0.6983587741851807, train/raw-loss = 0.697280764579773, train/logprobs = tensor([[-0.7123, -0.9470],
        [-0.7903, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0035933812614530325
Epoch 0, Step 218: train/loss = 0.716776967048645, train/raw-loss = 0.7156354188919067, train/logprobs = tensor([[-0.6959, -1.2172],
        [-0.8591, -1.0781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038052902091294527
Epoch 0, Step 219: train/loss = 0.7148193120956421, train/raw-loss = 0.7135368585586548, train/logprobs = tensor([[-0.9628, -1.4649],
        [-1.0071, -1.2091]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00427456246688962
Epoch 0, Step 220: train/loss = 0.6961935758590698, train/raw-loss = 0.6961793303489685, train/logprobs = tensor([[-0.7524, -0.8339],
        [-0.7569, -0.8508]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.7259010898415e-05
Epoch 0, Step 221: train/loss = 0.7187157869338989, train/raw-loss = 0.7181699275970459, train/logprobs = tensor([[-1.0872, -1.2207],
        [-1.2621, -1.1719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001819441094994545
Epoch 0, Step 222: train/loss = 0.7029403448104858, train/raw-loss = 0.702365517616272, train/logprobs = tensor([[-0.6657, -0.8397],
        [-0.8269, -0.8487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019159324001520872
Epoch 0, Step 223: train/loss = 0.7039934992790222, train/raw-loss = 0.7039574384689331, train/logprobs = tensor([[-0.7449, -0.9872],
        [-0.8768, -1.0321]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012006700853817165
Epoch 0, Step 224: train/loss = 0.7019617557525635, train/raw-loss = 0.7008175253868103, train/logprobs = tensor([[-0.8756, -1.1932],
        [-1.0567, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003813999705016613
Epoch 0, Step 225: train/loss = 0.7054942846298218, train/raw-loss = 0.7049369812011719, train/logprobs = tensor([[-0.6979, -0.6728],
        [-0.8995, -0.6929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018576837610453367
Epoch 0, Step 226: train/loss = 0.7249433994293213, train/raw-loss = 0.7240986227989197, train/logprobs = tensor([[-0.9198, -0.9404],
        [-1.0800, -1.0175]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028158514760434628
Epoch 0, Step 227: train/loss = 0.6994763016700745, train/raw-loss = 0.699270486831665, train/logprobs = tensor([[-0.8677, -0.9718],
        [-1.1376, -1.0102]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006859056884422898
Epoch 0, Step 228: train/loss = 0.7115073800086975, train/raw-loss = 0.7110718488693237, train/logprobs = tensor([[-1.1575, -0.9754],
        [-1.4245, -1.0206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001451808144338429
Epoch 0, Step 229: train/loss = 0.756522536277771, train/raw-loss = 0.7561254501342773, train/logprobs = tensor([[-0.7632, -1.2474],
        [-0.8637, -1.1990]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013237608363851905
Epoch 0, Step 230: train/loss = 0.7057041525840759, train/raw-loss = 0.7055317163467407, train/logprobs = tensor([[-0.8810, -0.7741],
        [-1.0788, -0.8342]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005748789408244193
Epoch 0, Step 231: train/loss = 0.7092885375022888, train/raw-loss = 0.7092223167419434, train/logprobs = tensor([[-0.6213, -0.9010],
        [-0.7493, -0.9917]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022038031602278352
Epoch 0, Step 232: train/loss = 0.7082842588424683, train/raw-loss = 0.7078349590301514, train/logprobs = tensor([[-0.6709, -0.6548],
        [-0.8739, -0.7414]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014976634411141276
Epoch 0, Step 233: train/loss = 0.7471736073493958, train/raw-loss = 0.7469558119773865, train/logprobs = tensor([[-0.7017, -1.1071],
        [-0.8318, -1.1216]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000726005993783474
Epoch 0, Step 234: train/loss = 0.7887049317359924, train/raw-loss = 0.7885335683822632, train/logprobs = tensor([[-0.8524, -0.9267],
        [-0.9204, -0.9117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005713008577004075
Epoch 0, Step 235: train/loss = 0.7242531180381775, train/raw-loss = 0.7233449220657349, train/logprobs = tensor([[-0.7791, -1.0783],
        [-0.9521, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030273073352873325
Epoch 0, Step 236: train/loss = 0.6928865313529968, train/raw-loss = 0.692752480506897, train/logprobs = tensor([[-0.7710, -0.8384],
        [-0.8778, -0.8646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004468006081879139
Epoch 0, Step 237: train/loss = 0.6965880393981934, train/raw-loss = 0.6961235404014587, train/logprobs = tensor([[-0.9903, -1.0498],
        [-1.2561, -1.1758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015483535826206207
Epoch 0, Step 238: train/loss = 0.7156760096549988, train/raw-loss = 0.7156339287757874, train/logprobs = tensor([[-0.9261, -0.8943],
        [-1.0862, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014003581600263715
Epoch 0, Step 239: train/loss = 0.6961270570755005, train/raw-loss = 0.6957247257232666, train/logprobs = tensor([[-0.6313, -0.8397],
        [-0.7601, -0.8679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013411176623776555
Epoch 0, Step 240: train/loss = 0.7306228280067444, train/raw-loss = 0.7289903163909912, train/logprobs = tensor([[-1.2071, -0.9447],
        [-1.5007, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005441868212074041
Epoch 0, Step 241: train/loss = 0.6948890089988708, train/raw-loss = 0.6948432326316833, train/logprobs = tensor([[-0.9221, -0.9427],
        [-0.9693, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001526637061033398
Epoch 0, Step 242: train/loss = 0.6965814232826233, train/raw-loss = 0.6962541341781616, train/logprobs = tensor([[-0.7341, -0.8692],
        [-0.8950, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001090934849344194
Epoch 0, Step 243: train/loss = 0.6949756145477295, train/raw-loss = 0.6937146186828613, train/logprobs = tensor([[-0.8614, -0.8058],
        [-1.0062, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042032403871417046
Epoch 0, Step 244: train/loss = 0.7091522216796875, train/raw-loss = 0.7091245055198669, train/logprobs = tensor([[-1.0329, -0.8194],
        [-1.1460, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.226046677213162e-05
Epoch 0, Step 245: train/loss = 0.7023680806159973, train/raw-loss = 0.7021753787994385, train/logprobs = tensor([[-0.9741, -1.2495],
        [-1.2278, -1.3504]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006424132734537125
Epoch 0, Step 246: train/loss = 0.6945902109146118, train/raw-loss = 0.694521963596344, train/logprobs = tensor([[-0.8565, -0.9320],
        [-1.0262, -1.0372]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002274218713864684
Epoch 0, Step 247: train/loss = 0.7178624868392944, train/raw-loss = 0.7167489528656006, train/logprobs = tensor([[-0.9490, -1.0481],
        [-1.1539, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003711713943630457
Epoch 0, Step 248: train/loss = 0.7574470043182373, train/raw-loss = 0.7559994459152222, train/logprobs = tensor([[-0.9964, -1.5097],
        [-1.0507, -1.3347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004825409501791
Epoch 0, Step 249: train/loss = 0.710509181022644, train/raw-loss = 0.7102522850036621, train/logprobs = tensor([[-0.7824, -0.6535],
        [-1.0171, -0.7966]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008565395255573094
Epoch 0, Step 250: train/loss = 0.6946093440055847, train/raw-loss = 0.6942561864852905, train/logprobs = tensor([[-0.8300, -0.8320],
        [-0.9872, -0.9661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011771416757255793
Epoch 0, Step 251: train/loss = 0.7419553399085999, train/raw-loss = 0.7407938241958618, train/logprobs = tensor([[-0.8427, -1.3367],
        [-0.9702, -1.1218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003871576627716422
Epoch 0, Step 252: train/loss = 0.7011146545410156, train/raw-loss = 0.7009987235069275, train/logprobs = tensor([[-0.6922, -0.8528],
        [-0.8533, -0.8521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003863386227749288
Epoch 0, Step 253: train/loss = 0.6958513855934143, train/raw-loss = 0.6958147883415222, train/logprobs = tensor([[-0.6343, -0.7355],
        [-0.7261, -0.7698]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012187787797302008
Epoch 0, Step 254: train/loss = 0.7049036026000977, train/raw-loss = 0.7043070793151855, train/logprobs = tensor([[-0.8538, -1.1443],
        [-0.9721, -1.0642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019883480854332447
Epoch 0, Step 255: train/loss = 0.7115831971168518, train/raw-loss = 0.7110870480537415, train/logprobs = tensor([[-0.9927, -0.7189],
        [-0.9987, -0.7692]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016539196949452162
Epoch 0, Step 256: train/loss = 0.7155951261520386, train/raw-loss = 0.7154810428619385, train/logprobs = tensor([[-1.2622, -1.0450],
        [-1.4488, -1.0961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038029756979085505
Epoch 0, Step 257: train/loss = 0.735029935836792, train/raw-loss = 0.7348682284355164, train/logprobs = tensor([[-0.9837, -1.4476],
        [-1.1817, -1.5178]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005388720310293138
Epoch 0, Step 258: train/loss = 0.7423306703567505, train/raw-loss = 0.7417152523994446, train/logprobs = tensor([[-1.0683, -0.6683],
        [-1.3398, -0.6915]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002051311545073986
Epoch 0, Step 259: train/loss = 0.7096081972122192, train/raw-loss = 0.7089125514030457, train/logprobs = tensor([[-1.2166, -1.0074],
        [-1.3096, -1.0909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002318729180842638
Epoch 0, Step 260: train/loss = 0.7001031041145325, train/raw-loss = 0.7000921368598938, train/logprobs = tensor([[-0.9870, -0.8558],
        [-1.0666, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.636844121501781e-05
Epoch 0, Step 261: train/loss = 0.7135639190673828, train/raw-loss = 0.7134522199630737, train/logprobs = tensor([[-0.7101, -1.0976],
        [-0.8253, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037240912206470966
Epoch 0, Step 262: train/loss = 0.8120927810668945, train/raw-loss = 0.8114409446716309, train/logprobs = tensor([[-1.2643, -0.5699],
        [-1.5240, -0.5809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021728347055613995
Epoch 0, Step 263: train/loss = 0.7464877963066101, train/raw-loss = 0.7463533878326416, train/logprobs = tensor([[-0.9967, -0.6527],
        [-1.1900, -0.7261]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004479063209146261
Epoch 0, Step 264: train/loss = 0.7241056561470032, train/raw-loss = 0.7231491804122925, train/logprobs = tensor([[-0.8168, -0.6006],
        [-0.8893, -0.7285]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003188116243109107
Epoch 0, Step 265: train/loss = 0.74427330493927, train/raw-loss = 0.7436295747756958, train/logprobs = tensor([[-0.7819, -1.3596],
        [-0.9227, -1.3446]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021458258852362633
Epoch 0, Step 266: train/loss = 0.6958742141723633, train/raw-loss = 0.695742130279541, train/logprobs = tensor([[-0.9562, -0.8966],
        [-1.1463, -1.0003]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044040754437446594
Epoch 0, Step 267: train/loss = 0.726638674736023, train/raw-loss = 0.7254822850227356, train/logprobs = tensor([[-1.1426, -1.0349],
        [-1.3105, -1.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00385458255186677
Epoch 0, Step 268: train/loss = 0.7572489976882935, train/raw-loss = 0.7565759420394897, train/logprobs = tensor([[-1.0526, -1.0506],
        [-1.2337, -1.1793]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022432960104197264
Epoch 0, Step 269: train/loss = 0.6951940655708313, train/raw-loss = 0.69490647315979, train/logprobs = tensor([[-0.8915, -0.9314],
        [-1.0690, -0.9265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009587466483935714
Epoch 0, Step 270: train/loss = 0.7133001089096069, train/raw-loss = 0.7127265930175781, train/logprobs = tensor([[-0.8765, -0.7173],
        [-1.0103, -0.7548]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019114625174552202
Epoch 0, Step 271: train/loss = 0.7087588906288147, train/raw-loss = 0.7082204818725586, train/logprobs = tensor([[-0.9015, -1.1159],
        [-1.1897, -1.2597]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017946851439774036
Epoch 0, Step 272: train/loss = 0.7263919711112976, train/raw-loss = 0.724625825881958, train/logprobs = tensor([[-0.9803, -1.3135],
        [-1.1198, -1.3899]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00588714424520731
Epoch 0, Step 273: train/loss = 0.7230120897293091, train/raw-loss = 0.722550630569458, train/logprobs = tensor([[-0.8659, -1.0890],
        [-1.2858, -1.1124]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015384673606604338
Epoch 0, Step 274: train/loss = 0.697208046913147, train/raw-loss = 0.6971313953399658, train/logprobs = tensor([[-1.0781, -1.0962],
        [-1.2288, -1.1138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025561643997207284
Epoch 0, Step 275: train/loss = 0.7092862129211426, train/raw-loss = 0.7087318897247314, train/logprobs = tensor([[-1.2112, -0.9461],
        [-1.3689, -1.0442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001847915700636804
Epoch 0, Step 276: train/loss = 0.7001569271087646, train/raw-loss = 0.7001132369041443, train/logprobs = tensor([[-0.6445, -0.7980],
        [-0.7534, -0.8894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001457093021599576
Epoch 0, Step 277: train/loss = 0.6958847045898438, train/raw-loss = 0.6951937675476074, train/logprobs = tensor([[-0.7862, -0.7557],
        [-0.8518, -0.8390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023029150906950235
Epoch 0, Step 278: train/loss = 0.7119302749633789, train/raw-loss = 0.7106025218963623, train/logprobs = tensor([[-0.6109, -0.9235],
        [-0.7005, -1.0303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004425637423992157
Epoch 0, Step 279: train/loss = 0.7036408185958862, train/raw-loss = 0.7033150792121887, train/logprobs = tensor([[-0.9238, -0.8879],
        [-1.0324, -0.9107]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001085747266188264
Epoch 0, Step 280: train/loss = 0.7016046643257141, train/raw-loss = 0.7015129327774048, train/logprobs = tensor([[-0.9055, -0.8810],
        [-1.1060, -1.0500]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030606077052652836
Epoch 0, Step 281: train/loss = 0.7574787735939026, train/raw-loss = 0.7569230794906616, train/logprobs = tensor([[-1.0488, -0.6366],
        [-1.2729, -0.7849]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018523051403462887
Epoch 0, Step 282: train/loss = 0.7005611062049866, train/raw-loss = 0.6999048590660095, train/logprobs = tensor([[-0.8391, -1.0044],
        [-0.9892, -1.0950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00218758056871593
Epoch 0, Step 283: train/loss = 0.7066195607185364, train/raw-loss = 0.7065433263778687, train/logprobs = tensor([[-1.0842, -0.9043],
        [-1.2163, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025408962392248213
Epoch 0, Step 284: train/loss = 0.6911395788192749, train/raw-loss = 0.6880767345428467, train/logprobs = tensor([[-0.8180, -0.9305],
        [-1.0649, -0.8518]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010209562256932259
Epoch 0, Step 285: train/loss = 0.7354915142059326, train/raw-loss = 0.7354670763015747, train/logprobs = tensor([[-0.9246, -0.8488],
        [-1.0420, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.173484820872545e-05
Epoch 0, Step 286: train/loss = 0.696453332901001, train/raw-loss = 0.6963185667991638, train/logprobs = tensor([[-0.4877, -0.5684],
        [-0.5831, -0.6164]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004492317675612867
Epoch 0, Step 287: train/loss = 0.7019761800765991, train/raw-loss = 0.7019212245941162, train/logprobs = tensor([[-0.7354, -0.7369],
        [-0.8193, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018306799756828696
Epoch 0, Step 288: train/loss = 0.7013132572174072, train/raw-loss = 0.7010043263435364, train/logprobs = tensor([[-0.9306, -0.8132],
        [-1.0377, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010299088899046183
Epoch 0, Step 289: train/loss = 0.7379342317581177, train/raw-loss = 0.7378547787666321, train/logprobs = tensor([[-1.1586, -0.8379],
        [-1.4312, -0.9252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026460865046828985
Epoch 0, Step 290: train/loss = 0.7412958145141602, train/raw-loss = 0.7375982999801636, train/logprobs = tensor([[-1.0139, -1.1048],
        [-1.1178, -1.1889]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.012325037270784378
Epoch 0, Step 291: train/loss = 0.7195667028427124, train/raw-loss = 0.7195348143577576, train/logprobs = tensor([[-1.2128, -0.8906],
        [-1.3147, -0.9459]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010617612861096859
Epoch 0, Step 292: train/loss = 0.7559480667114258, train/raw-loss = 0.7544495463371277, train/logprobs = tensor([[-1.3590, -0.8099],
        [-1.5124, -0.9767]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049950191751122475
Epoch 0, Step 293: train/loss = 0.7244107127189636, train/raw-loss = 0.7237500548362732, train/logprobs = tensor([[-1.2796, -1.2565],
        [-1.3473, -1.3096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022022926714271307
Epoch 0, Step 294: train/loss = 0.7885135412216187, train/raw-loss = 0.7881371378898621, train/logprobs = tensor([[-1.0086, -0.5255],
        [-1.0860, -0.6217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012548144441097975
Epoch 0, Step 295: train/loss = 0.7169197797775269, train/raw-loss = 0.7164705395698547, train/logprobs = tensor([[-1.1831, -1.1560],
        [-1.3517, -1.2774]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014973804354667664
Epoch 0, Step 296: train/loss = 0.7392532825469971, train/raw-loss = 0.7391515374183655, train/logprobs = tensor([[-0.9967, -0.7540],
        [-1.1697, -0.8572]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033905956661328673
Epoch 0, Step 297: train/loss = 0.7207293510437012, train/raw-loss = 0.720603346824646, train/logprobs = tensor([[-0.7645, -1.1804],
        [-0.9018, -1.2023]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004197311936877668
Epoch 0, Step 298: train/loss = 0.7539714574813843, train/raw-loss = 0.7535873651504517, train/logprobs = tensor([[-1.1104, -0.8696],
        [-1.3229, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012802177807316184
Epoch 0, Step 299: train/loss = 0.73884117603302, train/raw-loss = 0.7384580373764038, train/logprobs = tensor([[-1.3484, -0.8074],
        [-1.5551, -0.9317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012771824840456247
Epoch 0, Step 300: train/loss = 0.7229849100112915, train/raw-loss = 0.7222787141799927, train/logprobs = tensor([[-1.0416, -0.8039],
        [-1.2545, -0.9976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002353842370212078
Epoch 0, Step 301: train/loss = 0.7370005249977112, train/raw-loss = 0.7369503974914551, train/logprobs = tensor([[-0.7155, -0.7562],
        [-0.8093, -0.7812]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001672151847742498
Epoch 0, Step 302: train/loss = 0.6955347061157227, train/raw-loss = 0.695483386516571, train/logprobs = tensor([[-0.8337, -0.7600],
        [-1.0065, -0.9109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001711764489300549
Epoch 0, Step 303: train/loss = 0.7185104489326477, train/raw-loss = 0.7182106375694275, train/logprobs = tensor([[-1.3916, -1.4243],
        [-1.6063, -1.4839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009994963183999062
Epoch 0, Step 304: train/loss = 0.7103612422943115, train/raw-loss = 0.7100833654403687, train/logprobs = tensor([[-0.9725, -0.9505],
        [-1.0717, -1.0618]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009263177635148168
Epoch 0, Step 305: train/loss = 0.7064632177352905, train/raw-loss = 0.706430971622467, train/logprobs = tensor([[-0.7146, -0.9461],
        [-0.9678, -1.0025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010762212332338095
Epoch 0, Step 306: train/loss = 0.6948917508125305, train/raw-loss = 0.6947561502456665, train/logprobs = tensor([[-1.0008, -1.1009],
        [-1.0841, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004518813220784068
Epoch 0, Step 307: train/loss = 0.7339509129524231, train/raw-loss = 0.7338963747024536, train/logprobs = tensor([[-1.3331, -1.0392],
        [-1.5028, -1.1113]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001817154698073864
Epoch 0, Step 308: train/loss = 0.7014037370681763, train/raw-loss = 0.701311469078064, train/logprobs = tensor([[-0.7283, -0.6245],
        [-0.8431, -0.6716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003076065331697464
Epoch 0, Step 309: train/loss = 0.7332125306129456, train/raw-loss = 0.7330895662307739, train/logprobs = tensor([[-1.2507, -0.8377],
        [-1.5049, -0.8686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004099647339899093
Epoch 0, Step 310: train/loss = 0.6936712861061096, train/raw-loss = 0.6931918263435364, train/logprobs = tensor([[-1.1075, -1.1416],
        [-1.3183, -1.1856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001598092378117144
Epoch 0, Step 311: train/loss = 0.7272845506668091, train/raw-loss = 0.7272638082504272, train/logprobs = tensor([[-0.7570, -1.0376],
        [-0.8945, -1.1004]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.902057793922722e-05
Epoch 0, Step 312: train/loss = 0.7141132354736328, train/raw-loss = 0.7135528922080994, train/logprobs = tensor([[-1.2082, -0.9539],
        [-1.4076, -0.9631]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018677895423024893
Epoch 0, Step 313: train/loss = 0.7332720160484314, train/raw-loss = 0.7332627177238464, train/logprobs = tensor([[-0.9938, -0.7113],
        [-1.1612, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.088272933382541e-05
Epoch 0, Step 314: train/loss = 0.7413853406906128, train/raw-loss = 0.7410269975662231, train/logprobs = tensor([[-0.9560, -0.7877],
        [-1.1400, -0.8543]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001194703159853816
Epoch 0, Step 315: train/loss = 0.7207321524620056, train/raw-loss = 0.7139020562171936, train/logprobs = tensor([[-0.9975, -1.2647],
        [-1.1984, -1.3170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.022767063230276108
Epoch 0, Step 316: train/loss = 0.7049688100814819, train/raw-loss = 0.7038586139678955, train/logprobs = tensor([[-0.9371, -0.9779],
        [-1.0062, -1.0607]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037006684578955173
Epoch 0, Step 317: train/loss = 0.7112314105033875, train/raw-loss = 0.7105798721313477, train/logprobs = tensor([[-1.1854, -1.2414],
        [-1.3994, -1.3112]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021716170012950897
Epoch 0, Step 318: train/loss = 0.7443078756332397, train/raw-loss = 0.7438521385192871, train/logprobs = tensor([[-1.3250, -0.8182],
        [-1.4290, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015189966652542353
Epoch 0, Step 319: train/loss = 0.698794960975647, train/raw-loss = 0.6975283622741699, train/logprobs = tensor([[-1.0995, -1.2064],
        [-1.3008, -1.1897]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004221990238875151
Epoch 0, Step 320: train/loss = 0.7286238670349121, train/raw-loss = 0.7265021800994873, train/logprobs = tensor([[-1.3265, -1.0932],
        [-1.5771, -1.1511]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007072172127664089
Epoch 0, Step 321: train/loss = 0.7283937931060791, train/raw-loss = 0.7279366254806519, train/logprobs = tensor([[-1.0230, -0.7829],
        [-1.3272, -0.8537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001523903920315206
Epoch 0, Step 322: train/loss = 0.7098907232284546, train/raw-loss = 0.7094086408615112, train/logprobs = tensor([[-0.6947, -0.5041],
        [-0.9009, -0.5792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016071689315140247
Epoch 0, Step 323: train/loss = 0.7215061187744141, train/raw-loss = 0.7210373878479004, train/logprobs = tensor([[-1.1019, -0.7639],
        [-1.2804, -0.8424]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015625725500285625
Epoch 0, Step 324: train/loss = 0.7290970087051392, train/raw-loss = 0.7290931344032288, train/logprobs = tensor([[-1.1486, -0.6863],
        [-1.1582, -0.6957]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.2934644473716617e-05
Epoch 0, Step 325: train/loss = 0.7267075181007385, train/raw-loss = 0.72666335105896, train/logprobs = tensor([[-0.9670, -0.6433],
        [-1.0700, -0.6922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014710953109897673
Epoch 0, Step 326: train/loss = 0.7234112024307251, train/raw-loss = 0.7226150035858154, train/logprobs = tensor([[-0.6554, -0.9642],
        [-0.8051, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026538721285760403
Epoch 0, Step 327: train/loss = 0.72191321849823, train/raw-loss = 0.7217255234718323, train/logprobs = tensor([[-0.6752, -0.9913],
        [-0.8278, -1.1253]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006256165215745568
Epoch 0, Step 328: train/loss = 0.7548052072525024, train/raw-loss = 0.7539265155792236, train/logprobs = tensor([[-1.3384, -0.8960],
        [-1.4123, -1.0293]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029290278907865286
Epoch 0, Step 329: train/loss = 0.7712708711624146, train/raw-loss = 0.7707349061965942, train/logprobs = tensor([[-0.8883, -1.0916],
        [-1.0522, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017867209389805794
Epoch 0, Step 330: train/loss = 0.7071777582168579, train/raw-loss = 0.7067611813545227, train/logprobs = tensor([[-0.9690, -0.8818],
        [-1.0940, -0.9094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001388578093610704
Epoch 0, Step 331: train/loss = 0.698567271232605, train/raw-loss = 0.6983426809310913, train/logprobs = tensor([[-1.0135, -1.0468],
        [-1.1806, -0.9822]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007486251997761428
Epoch 0, Step 332: train/loss = 0.6995729207992554, train/raw-loss = 0.699541449546814, train/logprobs = tensor([[-0.9435, -0.8825],
        [-1.0878, -0.8898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001047810073941946
Epoch 0, Step 333: train/loss = 0.6957534551620483, train/raw-loss = 0.6957292556762695, train/logprobs = tensor([[-1.1537, -1.0449],
        [-1.2336, -1.1098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.020194945856929e-05
Epoch 0, Step 334: train/loss = 0.7313708066940308, train/raw-loss = 0.7307333946228027, train/logprobs = tensor([[-1.0710, -1.0539],
        [-1.2828, -1.1541]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002124789170920849
Epoch 0, Step 335: train/loss = 0.7289407253265381, train/raw-loss = 0.7288907170295715, train/logprobs = tensor([[-1.0434, -0.8201],
        [-1.1155, -0.8375]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00016655924264341593
Epoch 0, Step 336: train/loss = 0.7043020725250244, train/raw-loss = 0.7037943601608276, train/logprobs = tensor([[-1.0719, -1.2844],
        [-1.1258, -1.2809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016922205686569214
Epoch 0, Step 337: train/loss = 0.6960871815681458, train/raw-loss = 0.6959922313690186, train/logprobs = tensor([[-0.8146, -0.7874],
        [-0.9537, -0.9291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031661358661949635
Epoch 0, Step 338: train/loss = 0.7182860970497131, train/raw-loss = 0.7182186245918274, train/logprobs = tensor([[-0.9978, -0.7338],
        [-1.0304, -0.7711]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022485668887384236
Epoch 0, Step 339: train/loss = 0.6972206830978394, train/raw-loss = 0.6971129179000854, train/logprobs = tensor([[-0.7009, -0.8083],
        [-0.8659, -0.9179]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003595456073526293
Epoch 0, Step 340: train/loss = 0.6969913244247437, train/raw-loss = 0.6965268850326538, train/logprobs = tensor([[-1.1969, -1.1787],
        [-1.4177, -1.2994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015482093440368772
Epoch 0, Step 341: train/loss = 0.6947633028030396, train/raw-loss = 0.6947534084320068, train/logprobs = tensor([[-0.8781, -0.8315],
        [-0.9530, -0.8417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.320608811918646e-05
Epoch 0, Step 342: train/loss = 0.7059855461120605, train/raw-loss = 0.7055953741073608, train/logprobs = tensor([[-1.0178, -0.8321],
        [-1.2659, -1.0208]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013004608917981386
Epoch 0, Step 343: train/loss = 0.7245320081710815, train/raw-loss = 0.724465012550354, train/logprobs = tensor([[-0.9306, -1.2335],
        [-1.0290, -1.3030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022352259838953614
Epoch 0, Step 344: train/loss = 0.7038823366165161, train/raw-loss = 0.7038054466247559, train/logprobs = tensor([[-1.1352, -0.9407],
        [-1.2493, -0.9832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000256312545388937
Epoch 0, Step 345: train/loss = 0.7124735713005066, train/raw-loss = 0.7121440172195435, train/logprobs = tensor([[-0.9755, -0.7942],
        [-1.1700, -0.8876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010984818218275905
Epoch 0, Step 346: train/loss = 0.7082141041755676, train/raw-loss = 0.7058809995651245, train/logprobs = tensor([[-1.2481, -1.2102],
        [-1.4406, -1.3646]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0077771455980837345
Epoch 0, Step 347: train/loss = 0.7129195928573608, train/raw-loss = 0.7110991477966309, train/logprobs = tensor([[-1.0837, -1.1225],
        [-1.1885, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006068142596632242
Epoch 0, Step 348: train/loss = 0.7474949359893799, train/raw-loss = 0.7464093565940857, train/logprobs = tensor([[-1.2203, -1.0656],
        [-1.4160, -1.0720]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036186419893056154
Epoch 0, Step 349: train/loss = 0.7088345289230347, train/raw-loss = 0.7088245153427124, train/logprobs = tensor([[-0.9529, -1.1360],
        [-0.9748, -1.1600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.34095602738671e-05
Epoch 0, Step 350: train/loss = 0.7237198352813721, train/raw-loss = 0.7235196828842163, train/logprobs = tensor([[-1.1658, -0.8775],
        [-1.3032, -0.9955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006673975731246173
Epoch 0, Step 351: train/loss = 0.731775164604187, train/raw-loss = 0.7314596176147461, train/logprobs = tensor([[-1.2149, -0.8351],
        [-1.3291, -0.8405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010518607450649142
Epoch 0, Step 352: train/loss = 0.7054651975631714, train/raw-loss = 0.7045469284057617, train/logprobs = tensor([[-0.9046, -1.1614],
        [-0.9935, -1.2473]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030607199296355247
Epoch 0, Step 353: train/loss = 0.6974805593490601, train/raw-loss = 0.6973789930343628, train/logprobs = tensor([[-1.3258, -1.1995],
        [-1.3836, -1.2276]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003383678267709911
Epoch 0, Step 354: train/loss = 0.6946166753768921, train/raw-loss = 0.6946132779121399, train/logprobs = tensor([[-0.9007, -0.8400],
        [-0.9693, -0.8945]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.1299096513539553e-05
Epoch 0, Step 355: train/loss = 0.7074950933456421, train/raw-loss = 0.7073830366134644, train/logprobs = tensor([[-0.7801, -0.7051],
        [-0.8586, -0.7878]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037349871126934886
Epoch 0, Step 356: train/loss = 0.6990377902984619, train/raw-loss = 0.6989008188247681, train/logprobs = tensor([[-0.9066, -0.9417],
        [-1.1058, -1.1089]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045663805212825537
Epoch 0, Step 357: train/loss = 0.7261115312576294, train/raw-loss = 0.7255628108978271, train/logprobs = tensor([[-1.0930, -0.9447],
        [-1.3271, -0.9693]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018291017040610313
Epoch 0, Step 358: train/loss = 0.7008652687072754, train/raw-loss = 0.7007761597633362, train/logprobs = tensor([[-1.0467, -0.9172],
        [-1.1703, -0.9523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002970615460071713
Epoch 0, Step 359: train/loss = 0.7610346674919128, train/raw-loss = 0.7605931758880615, train/logprobs = tensor([[-1.0516, -1.1895],
        [-1.2176, -1.3475]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001471534138545394
Epoch 0, Step 360: train/loss = 0.7255866527557373, train/raw-loss = 0.7252975702285767, train/logprobs = tensor([[-0.9578, -0.6854],
        [-1.1122, -0.7947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000963788537774235
Epoch 0, Step 361: train/loss = 0.738969087600708, train/raw-loss = 0.738195538520813, train/logprobs = tensor([[-0.7376, -1.1798],
        [-0.8070, -1.2236]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025782978627830744
Epoch 0, Step 362: train/loss = 0.7030667662620544, train/raw-loss = 0.7027774453163147, train/logprobs = tensor([[-0.7252, -0.5715],
        [-0.8771, -0.6146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009644619422033429
Epoch 0, Step 363: train/loss = 0.6971437931060791, train/raw-loss = 0.6968480944633484, train/logprobs = tensor([[-1.0254, -1.1399],
        [-1.1728, -1.2594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009858876001089811
Epoch 0, Step 364: train/loss = 0.718238890171051, train/raw-loss = 0.717782735824585, train/logprobs = tensor([[-1.0763, -0.8517],
        [-1.1230, -0.9071]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015203715302050114
Epoch 0, Step 365: train/loss = 0.7196833491325378, train/raw-loss = 0.7193474173545837, train/logprobs = tensor([[-1.0521, -0.8681],
        [-1.4362, -1.0194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011198156280443072
Epoch 0, Step 366: train/loss = 0.7300687432289124, train/raw-loss = 0.7297284603118896, train/logprobs = tensor([[-1.0488, -1.1074],
        [-1.1176, -1.1902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011343888472765684
Epoch 0, Step 367: train/loss = 0.7422279119491577, train/raw-loss = 0.7420549392700195, train/logprobs = tensor([[-1.0120, -1.0340],
        [-1.1933, -1.0776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005764706875197589
Epoch 0, Step 368: train/loss = 0.7078049182891846, train/raw-loss = 0.7074962854385376, train/logprobs = tensor([[-1.1015, -0.9521],
        [-1.3551, -1.0789]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010287808254361153
Epoch 0, Step 369: train/loss = 0.7109241485595703, train/raw-loss = 0.7108057141304016, train/logprobs = tensor([[-0.8527, -0.6782],
        [-0.9546, -0.7437]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003948835073970258
Epoch 0, Step 370: train/loss = 0.7153882384300232, train/raw-loss = 0.7153369784355164, train/logprobs = tensor([[-1.0342, -0.8810],
        [-1.1763, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017099102842621505
Epoch 0, Step 371: train/loss = 0.7234418392181396, train/raw-loss = 0.7229659557342529, train/logprobs = tensor([[-1.1209, -0.7696],
        [-1.3086, -0.8947]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001586375292390585
Epoch 0, Step 372: train/loss = 0.6987312436103821, train/raw-loss = 0.6983389258384705, train/logprobs = tensor([[-1.0191, -1.0124],
        [-1.1435, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013077093753963709
Epoch 0, Step 373: train/loss = 0.6991643309593201, train/raw-loss = 0.6990684270858765, train/logprobs = tensor([[-0.7885, -0.7152],
        [-0.8700, -0.7856]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003194587188772857
Epoch 0, Step 374: train/loss = 0.7055469155311584, train/raw-loss = 0.7049908638000488, train/logprobs = tensor([[-1.1378, -1.1760],
        [-1.2982, -1.2734]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018537516007199883
Epoch 0, Step 375: train/loss = 0.7046177983283997, train/raw-loss = 0.7045887112617493, train/logprobs = tensor([[-0.9760, -0.7880],
        [-1.1238, -0.8792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.682681411504745e-05
Epoch 0, Step 376: train/loss = 0.7169374227523804, train/raw-loss = 0.7168920040130615, train/logprobs = tensor([[-1.2809, -0.9366],
        [-1.2715, -0.9256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015147111844271421
Epoch 0, Step 377: train/loss = 0.6941112279891968, train/raw-loss = 0.6940898895263672, train/logprobs = tensor([[-0.9551, -0.8988],
        [-1.1440, -1.0484]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.113063475117087e-05
Epoch 0, Step 378: train/loss = 0.7244347929954529, train/raw-loss = 0.7240610122680664, train/logprobs = tensor([[-1.1068, -1.0206],
        [-1.1790, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012460711877793074
Epoch 0, Step 379: train/loss = 0.7303838729858398, train/raw-loss = 0.7302575707435608, train/logprobs = tensor([[-0.9164, -0.6256],
        [-1.0040, -0.6528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000420927070081234
Epoch 0, Step 380: train/loss = 0.7166173458099365, train/raw-loss = 0.7164702415466309, train/logprobs = tensor([[-0.9720, -0.9290],
        [-1.0638, -1.0396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004901968641206622
Epoch 0, Step 381: train/loss = 0.6963484883308411, train/raw-loss = 0.6962130069732666, train/logprobs = tensor([[-1.0933, -1.1738],
        [-1.1366, -1.2018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004516500048339367
Epoch 0, Step 382: train/loss = 0.6990795135498047, train/raw-loss = 0.6990121603012085, train/logprobs = tensor([[-0.8411, -0.7112],
        [-0.9459, -0.7991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000224653456825763
Epoch 0, Step 383: train/loss = 0.7013466358184814, train/raw-loss = 0.7010359168052673, train/logprobs = tensor([[-1.1153, -1.0389],
        [-1.2966, -1.0840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010356031125411391
Epoch 0, Step 384: train/loss = 0.756182849407196, train/raw-loss = 0.7559747695922852, train/logprobs = tensor([[-0.7186, -0.8938],
        [-0.7789, -1.0008]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006935540586709976
Epoch 0, Step 385: train/loss = 0.7197304964065552, train/raw-loss = 0.7184292078018188, train/logprobs = tensor([[-1.1060, -0.9092],
        [-1.2538, -1.0252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00433757109567523
Epoch 0, Step 386: train/loss = 0.7022593021392822, train/raw-loss = 0.7021061778068542, train/logprobs = tensor([[-0.9397, -0.7692],
        [-1.0163, -0.7347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005102296709083021
Epoch 0, Step 387: train/loss = 0.7315911650657654, train/raw-loss = 0.7312295436859131, train/logprobs = tensor([[-1.0439, -1.0189],
        [-1.1776, -1.0592]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012055512052029371
Epoch 0, Step 388: train/loss = 0.7001244425773621, train/raw-loss = 0.6988670825958252, train/logprobs = tensor([[-1.0059, -1.2087],
        [-1.1293, -1.1983]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004191131331026554
Epoch 0, Step 389: train/loss = 0.8498778343200684, train/raw-loss = 0.8495782613754272, train/logprobs = tensor([[-1.3099, -0.5097],
        [-1.5357, -0.5658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009988851379603148
Epoch 0, Step 390: train/loss = 0.7301315665245056, train/raw-loss = 0.7300312519073486, train/logprobs = tensor([[-1.4229, -1.2960],
        [-1.6012, -1.3059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003342479467391968
Epoch 0, Step 391: train/loss = 0.6989833116531372, train/raw-loss = 0.6988024115562439, train/logprobs = tensor([[-0.8650, -0.7158],
        [-1.0425, -0.8922]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006029908545315266
Epoch 0, Step 392: train/loss = 0.7024122476577759, train/raw-loss = 0.701566219329834, train/logprobs = tensor([[-0.6815, -0.7676],
        [-0.7632, -0.8115]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002819990273565054
Epoch 0, Step 393: train/loss = 0.7045974731445312, train/raw-loss = 0.704529881477356, train/logprobs = tensor([[-0.8301, -0.6331],
        [-0.9691, -0.6852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022533340961672366
Epoch 0, Step 394: train/loss = 0.7246781587600708, train/raw-loss = 0.7246716022491455, train/logprobs = tensor([[-1.1378, -0.9551],
        [-1.1910, -0.9685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1980951714795083e-05
Epoch 0, Step 395: train/loss = 0.7258221507072449, train/raw-loss = 0.7245493531227112, train/logprobs = tensor([[-1.3623, -0.8744],
        [-1.5371, -1.0927]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004242465831339359
Epoch 0, Step 396: train/loss = 0.7433561086654663, train/raw-loss = 0.7424834966659546, train/logprobs = tensor([[-1.1612, -1.0165],
        [-1.2991, -1.1472]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00290863704867661
Epoch 0, Step 397: train/loss = 0.7131294012069702, train/raw-loss = 0.7120761275291443, train/logprobs = tensor([[-0.8630, -1.0438],
        [-0.9871, -1.0534]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003510945476591587
Epoch 0, Step 398: train/loss = 0.716435968875885, train/raw-loss = 0.7163900136947632, train/logprobs = tensor([[-0.7701, -0.8020],
        [-0.8110, -0.8507]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015328568406403065
Epoch 0, Step 399: train/loss = 0.7432829141616821, train/raw-loss = 0.7430857419967651, train/logprobs = tensor([[-1.4333, -1.2264],
        [-1.6066, -1.2577]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006572965066879988
Epoch 0, Step 400: train/loss = 0.7233099937438965, train/raw-loss = 0.7232115864753723, train/logprobs = tensor([[-1.0808, -0.9287],
        [-1.2555, -1.0610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032810692209750414
Epoch 0, Step 401: train/loss = 0.703184962272644, train/raw-loss = 0.7030231952667236, train/logprobs = tensor([[-1.2434, -1.1536],
        [-1.3440, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005393128958530724
Epoch 0, Step 402: train/loss = 0.7283577919006348, train/raw-loss = 0.7282785177230835, train/logprobs = tensor([[-1.0848, -0.7074],
        [-1.3445, -0.8452]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026435236213728786
Epoch 0, Step 403: train/loss = 0.6956612467765808, train/raw-loss = 0.6950666904449463, train/logprobs = tensor([[-0.7510, -0.9054],
        [-0.8807, -0.9721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019819019362330437
Epoch 0, Step 404: train/loss = 0.747046709060669, train/raw-loss = 0.7454319000244141, train/logprobs = tensor([[-1.4675, -0.8917],
        [-1.6147, -0.9781]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00538268405944109
Epoch 0, Step 405: train/loss = 0.7063920497894287, train/raw-loss = 0.7061168551445007, train/logprobs = tensor([[-0.8470, -1.0717],
        [-0.9524, -1.1379]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000917462632060051
Epoch 0, Step 406: train/loss = 0.7312921285629272, train/raw-loss = 0.731117844581604, train/logprobs = tensor([[-1.2357, -1.3698],
        [-1.2434, -1.3153]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000581029278691858
Epoch 0, Step 407: train/loss = 0.70947265625, train/raw-loss = 0.7091552019119263, train/logprobs = tensor([[-0.7616, -0.9963],
        [-0.8717, -1.0891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010583013063296676
Epoch 0, Step 408: train/loss = 0.7319302558898926, train/raw-loss = 0.7319155931472778, train/logprobs = tensor([[-0.9767, -0.8833],
        [-1.1420, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.9056572606787086e-05
Epoch 0, Step 409: train/loss = 0.7191009521484375, train/raw-loss = 0.7190031409263611, train/logprobs = tensor([[-1.1499, -0.9773],
        [-1.3265, -1.0109]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003261393867433071
Epoch 0, Step 410: train/loss = 0.723329484462738, train/raw-loss = 0.7226374745368958, train/logprobs = tensor([[-1.1317, -0.9847],
        [-1.2639, -0.9702]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00230654189363122
Epoch 0, Step 411: train/loss = 0.7012381553649902, train/raw-loss = 0.7010131478309631, train/logprobs = tensor([[-0.8823, -0.8291],
        [-1.1201, -0.9281]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007499082712456584
Epoch 0, Step 412: train/loss = 0.7182093262672424, train/raw-loss = 0.7179940938949585, train/logprobs = tensor([[-0.6755, -0.8907],
        [-0.7534, -0.9844]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007173513295128942
Epoch 0, Step 413: train/loss = 0.7572577595710754, train/raw-loss = 0.756952166557312, train/logprobs = tensor([[-1.1381, -0.6915],
        [-1.1929, -0.7429]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001018464332446456
Epoch 0, Step 414: train/loss = 0.7134422659873962, train/raw-loss = 0.7116321921348572, train/logprobs = tensor([[-0.7232, -0.6849],
        [-0.7980, -0.8183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006033538840711117
Epoch 0, Step 415: train/loss = 0.7285570502281189, train/raw-loss = 0.7281731367111206, train/logprobs = tensor([[-0.9043, -1.3769],
        [-1.1193, -1.5732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001279735006392002
Epoch 0, Step 416: train/loss = 0.7301462292671204, train/raw-loss = 0.7300843596458435, train/logprobs = tensor([[-0.9578, -0.7074],
        [-1.1530, -0.8057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020598279661498964
Epoch 0, Step 417: train/loss = 0.7064536809921265, train/raw-loss = 0.7046424150466919, train/logprobs = tensor([[-1.2361, -1.0972],
        [-1.3857, -1.2184]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006037904880940914
Epoch 0, Step 418: train/loss = 0.7313610911369324, train/raw-loss = 0.7306941747665405, train/logprobs = tensor([[-0.7816, -0.7016],
        [-0.8557, -0.7683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002223266288638115
Epoch 0, Step 419: train/loss = 0.6940011978149414, train/raw-loss = 0.6939970254898071, train/logprobs = tensor([[-0.8034, -0.8338],
        [-0.9587, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.3796583516523242e-05
Epoch 0, Step 420: train/loss = 0.7231805324554443, train/raw-loss = 0.7222892045974731, train/logprobs = tensor([[-1.4366, -1.0816],
        [-1.5966, -1.2383]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002971203764900565
Epoch 0, Step 421: train/loss = 0.7023837566375732, train/raw-loss = 0.7020082473754883, train/logprobs = tensor([[-1.2786, -1.1994],
        [-1.6951, -1.3048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012518273433670402
Epoch 0, Step 422: train/loss = 0.7698991298675537, train/raw-loss = 0.7686469554901123, train/logprobs = tensor([[-1.4057, -0.7309],
        [-1.6620, -0.8885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004174003377556801
Epoch 0, Step 423: train/loss = 0.7190350294113159, train/raw-loss = 0.718970537185669, train/logprobs = tensor([[-1.2197, -0.9650],
        [-1.4779, -1.1537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021520949667319655
Epoch 0, Step 424: train/loss = 0.7315900325775146, train/raw-loss = 0.7315632700920105, train/logprobs = tensor([[-0.9652, -0.5979],
        [-1.0963, -0.6772]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.910952601581812e-05
Epoch 0, Step 425: train/loss = 0.7702021598815918, train/raw-loss = 0.7696586847305298, train/logprobs = tensor([[-1.0413, -0.4889],
        [-1.3338, -0.5764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018116900464519858
Epoch 0, Step 426: train/loss = 0.6982396245002747, train/raw-loss = 0.6975524425506592, train/logprobs = tensor([[-0.8753, -0.8665],
        [-1.0160, -1.0524]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022904742509126663
Epoch 0, Step 427: train/loss = 0.7355281114578247, train/raw-loss = 0.7351155281066895, train/logprobs = tensor([[-1.1663, -0.6962],
        [-1.2692, -0.7968]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013753916136920452
Epoch 0, Step 428: train/loss = 0.7167220711708069, train/raw-loss = 0.7163615226745605, train/logprobs = tensor([[-0.8030, -0.6974],
        [-0.8013, -0.7562]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012017625849694014
Epoch 0, Step 429: train/loss = 0.6937746405601501, train/raw-loss = 0.6935449242591858, train/logprobs = tensor([[-0.7484, -0.8272],
        [-0.9585, -0.9313]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007657506503164768
Epoch 0, Step 430: train/loss = 0.7678844928741455, train/raw-loss = 0.7675809860229492, train/logprobs = tensor([[-1.2959, -0.8241],
        [-1.4122, -0.8454]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010117312194779515
Epoch 0, Step 431: train/loss = 0.698797881603241, train/raw-loss = 0.6985095143318176, train/logprobs = tensor([[-0.7914, -0.7129],
        [-1.1645, -0.7763]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009611544664949179
Epoch 0, Step 432: train/loss = 0.7266884446144104, train/raw-loss = 0.7249152064323425, train/logprobs = tensor([[-1.3245, -0.9996],
        [-1.8381, -1.1802]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005910935811698437
Epoch 0, Step 433: train/loss = 0.7194130420684814, train/raw-loss = 0.7190887331962585, train/logprobs = tensor([[-1.2070, -0.9105],
        [-1.3547, -0.9345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010810464154928923
Epoch 0, Step 434: train/loss = 0.7089278697967529, train/raw-loss = 0.7085757255554199, train/logprobs = tensor([[-0.8728, -0.8756],
        [-1.0568, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011737996246665716
Epoch 0, Step 435: train/loss = 0.7125437259674072, train/raw-loss = 0.7117575407028198, train/logprobs = tensor([[-0.7865, -0.9442],
        [-0.9635, -1.0773]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00262055778875947
Epoch 0, Step 436: train/loss = 0.7021329402923584, train/raw-loss = 0.7018895149230957, train/logprobs = tensor([[-1.1068, -1.0456],
        [-1.2761, -1.2295]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008112887153401971
Epoch 0, Step 437: train/loss = 0.7045820355415344, train/raw-loss = 0.7042945623397827, train/logprobs = tensor([[-0.7569, -0.6391],
        [-0.8140, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009581798803992569
Epoch 0, Step 438: train/loss = 0.7180373668670654, train/raw-loss = 0.7177945375442505, train/logprobs = tensor([[-0.8464, -0.9963],
        [-0.9182, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000809504883363843
Epoch 0, Step 439: train/loss = 0.7062519788742065, train/raw-loss = 0.7056487798690796, train/logprobs = tensor([[-1.0957, -0.9391],
        [-1.2944, -0.9600]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020108104217797518
Epoch 0, Step 440: train/loss = 0.7073837518692017, train/raw-loss = 0.7068971991539001, train/logprobs = tensor([[-0.7368, -0.9792],
        [-0.9714, -0.9551]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016217802185565233
Epoch 0, Step 441: train/loss = 0.7684597969055176, train/raw-loss = 0.7683886289596558, train/logprobs = tensor([[-1.1660, -0.6662],
        [-1.4110, -0.7582]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023733050329610705
Epoch 0, Step 442: train/loss = 0.7097817659378052, train/raw-loss = 0.7084728479385376, train/logprobs = tensor([[-1.0675, -1.3389],
        [-1.1804, -1.3776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004363036714494228
Epoch 0, Step 443: train/loss = 0.7032288312911987, train/raw-loss = 0.7028754353523254, train/logprobs = tensor([[-0.9930, -1.0205],
        [-1.1283, -0.9679]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011781848734244704
Epoch 0, Step 444: train/loss = 0.7112696170806885, train/raw-loss = 0.7111958265304565, train/logprobs = tensor([[-1.0469, -0.8875],
        [-1.2166, -0.9992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002457982627674937
Epoch 0, Step 445: train/loss = 0.7360393404960632, train/raw-loss = 0.7357776165008545, train/logprobs = tensor([[-0.8166, -0.6257],
        [-0.8664, -0.6854]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008722054190002382
Epoch 0, Step 446: train/loss = 0.7214635610580444, train/raw-loss = 0.7212957143783569, train/logprobs = tensor([[-0.9945, -0.7555],
        [-1.1251, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005595138063654304
Epoch 0, Step 447: train/loss = 0.7210237383842468, train/raw-loss = 0.7208722233772278, train/logprobs = tensor([[-1.0690, -1.1046],
        [-1.5457, -1.1700]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000505134230479598
Epoch 0, Step 448: train/loss = 0.7057803869247437, train/raw-loss = 0.7051711082458496, train/logprobs = tensor([[-1.1431, -0.9099],
        [-1.1832, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020308373495936394
Epoch 0, Step 449: train/loss = 0.694525957107544, train/raw-loss = 0.6944636106491089, train/logprobs = tensor([[-1.0263, -1.1601],
        [-1.1396, -1.2054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002079053083434701
Epoch 0, Step 450: train/loss = 0.7353857755661011, train/raw-loss = 0.7352362871170044, train/logprobs = tensor([[-1.1982, -1.0660],
        [-1.5140, -1.2921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004983178223483264
Epoch 0, Step 451: train/loss = 0.755562424659729, train/raw-loss = 0.7550613880157471, train/logprobs = tensor([[-1.1688, -0.7730],
        [-1.3442, -0.7943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016700525302439928
Epoch 0, Step 452: train/loss = 0.7095917463302612, train/raw-loss = 0.7094705104827881, train/logprobs = tensor([[-0.9552, -0.8784],
        [-1.1500, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004041363426949829
Epoch 0, Step 453: train/loss = 0.7151005864143372, train/raw-loss = 0.7150622010231018, train/logprobs = tensor([[-0.8839, -0.7196],
        [-1.0057, -0.7847]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012797361705452204
Epoch 0, Step 454: train/loss = 0.7186356782913208, train/raw-loss = 0.7182385325431824, train/logprobs = tensor([[-1.1799, -0.8585],
        [-1.3097, -0.9863]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013239290565252304
Epoch 0, Step 455: train/loss = 0.7000481486320496, train/raw-loss = 0.6995700597763062, train/logprobs = tensor([[-0.8191, -0.9179],
        [-0.9030, -0.8717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015936907147988677
Epoch 0, Step 456: train/loss = 0.7027996182441711, train/raw-loss = 0.7026328444480896, train/logprobs = tensor([[-1.0565, -0.8464],
        [-1.1996, -1.0078]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005559177370741963
Epoch 0, Step 457: train/loss = 0.693432629108429, train/raw-loss = 0.6928841471672058, train/logprobs = tensor([[-0.8004, -0.8501],
        [-0.9886, -0.8652]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001828256994485855
Epoch 0, Step 458: train/loss = 0.6936896443367004, train/raw-loss = 0.6936065554618835, train/logprobs = tensor([[-0.7302, -0.7380],
        [-0.8339, -0.8061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027689707349054515
Epoch 0, Step 459: train/loss = 0.7220709323883057, train/raw-loss = 0.7211877703666687, train/logprobs = tensor([[-1.0936, -0.8003],
        [-1.2026, -0.9722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00294414977543056
Epoch 0, Step 460: train/loss = 0.7031651735305786, train/raw-loss = 0.7028677463531494, train/logprobs = tensor([[-0.8609, -0.8039],
        [-0.9390, -0.8978]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009917134884744883
Epoch 0, Step 461: train/loss = 0.7292772531509399, train/raw-loss = 0.729206383228302, train/logprobs = tensor([[-1.0613, -0.7793],
        [-1.2389, -0.8949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002361555234529078
Epoch 0, Step 462: train/loss = 0.7040668725967407, train/raw-loss = 0.7039641737937927, train/logprobs = tensor([[-0.8617, -0.6928],
        [-1.2163, -0.7495]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003421709989197552
Epoch 0, Step 463: train/loss = 0.7060719728469849, train/raw-loss = 0.7056986093521118, train/logprobs = tensor([[-0.8082, -0.8027],
        [-0.9469, -0.8902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012441623257473111
Epoch 0, Step 464: train/loss = 0.7128941416740417, train/raw-loss = 0.7126981616020203, train/logprobs = tensor([[-0.9879, -0.7962],
        [-1.1214, -0.8022]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006530999089591205
Epoch 0, Step 465: train/loss = 0.7063380479812622, train/raw-loss = 0.7057675123214722, train/logprobs = tensor([[-1.0721, -0.8861],
        [-1.4232, -1.0324]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019017759477719665
Epoch 0, Step 466: train/loss = 0.7246628403663635, train/raw-loss = 0.7246567010879517, train/logprobs = tensor([[-1.1059, -0.8467],
        [-1.2989, -0.9617]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.0443054381757975e-05
Epoch 0, Step 467: train/loss = 0.7215670347213745, train/raw-loss = 0.7204497456550598, train/logprobs = tensor([[-0.9936, -0.9118],
        [-1.1323, -0.9493]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003724166890606284
Epoch 0, Step 468: train/loss = 0.7174139618873596, train/raw-loss = 0.7173586487770081, train/logprobs = tensor([[-1.0783, -0.8527],
        [-1.5716, -1.0092]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018437020480632782
Epoch 0, Step 469: train/loss = 0.7190078496932983, train/raw-loss = 0.7187424898147583, train/logprobs = tensor([[-0.9425, -0.7677],
        [-1.0523, -0.8585]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008845669217407703
Epoch 0, Step 470: train/loss = 0.7105814814567566, train/raw-loss = 0.7104190587997437, train/logprobs = tensor([[-1.0618, -0.8309],
        [-1.2087, -0.8820]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005414911429397762
Epoch 0, Step 471: train/loss = 0.7200093269348145, train/raw-loss = 0.7194048166275024, train/logprobs = tensor([[-0.8337, -0.6715],
        [-1.0882, -0.7108]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020148034673184156
Epoch 0, Step 472: train/loss = 0.7112160921096802, train/raw-loss = 0.7112147212028503, train/logprobs = tensor([[-0.9416, -0.8252],
        [-1.1427, -0.9267]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.513454769039527e-06
Epoch 0, Step 473: train/loss = 0.7199954390525818, train/raw-loss = 0.7197439670562744, train/logprobs = tensor([[-0.9286, -1.1345],
        [-1.1247, -1.1680]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008382846135646105
Epoch 0, Step 474: train/loss = 0.7395023107528687, train/raw-loss = 0.7391897439956665, train/logprobs = tensor([[-0.8760, -0.6354],
        [-0.9135, -0.6487]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010418794117867947
Epoch 0, Step 475: train/loss = 0.7252519130706787, train/raw-loss = 0.7252315878868103, train/logprobs = tensor([[-1.1372, -0.7872],
        [-1.3109, -0.8753]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.779306568205357e-05
Epoch 0, Step 476: train/loss = 0.7143532037734985, train/raw-loss = 0.7131408452987671, train/logprobs = tensor([[-0.9356, -0.6945],
        [-1.0398, -0.7999]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004041336476802826
Epoch 0, Step 477: train/loss = 0.7041568756103516, train/raw-loss = 0.702824592590332, train/logprobs = tensor([[-0.6139, -0.7868],
        [-0.7441, -0.9043]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004441170021891594
Epoch 0, Step 478: train/loss = 0.7108467221260071, train/raw-loss = 0.7106282711029053, train/logprobs = tensor([[-0.9336, -0.8085],
        [-1.0939, -0.7669]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000728069746401161
Epoch 0, Step 479: train/loss = 0.7670479416847229, train/raw-loss = 0.7667343616485596, train/logprobs = tensor([[-1.3005, -0.6761],
        [-1.3798, -0.6937]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010451761772856116
Epoch 0, Step 480: train/loss = 0.7138135433197021, train/raw-loss = 0.7137830257415771, train/logprobs = tensor([[-1.0200, -0.7194],
        [-1.2156, -0.8036]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010166139691136777
Epoch 0, Step 481: train/loss = 0.7048706412315369, train/raw-loss = 0.704704761505127, train/logprobs = tensor([[-0.9076, -1.2627],
        [-1.0842, -1.3420]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005528627661988139
Epoch 0, Step 482: train/loss = 0.7019609212875366, train/raw-loss = 0.7017965316772461, train/logprobs = tensor([[-1.0650, -1.0760],
        [-1.2543, -1.2131]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005476013175211847
Epoch 0, Step 483: train/loss = 0.7140070199966431, train/raw-loss = 0.7134232521057129, train/logprobs = tensor([[-0.9817, -0.6537],
        [-1.2025, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001945891068316996
Epoch 0, Step 484: train/loss = 0.717421293258667, train/raw-loss = 0.717328667640686, train/logprobs = tensor([[-1.1958, -1.1245],
        [-1.3495, -1.1840]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030871984199620783
Epoch 0, Step 485: train/loss = 0.7111077904701233, train/raw-loss = 0.7109430432319641, train/logprobs = tensor([[-0.9408, -0.8367],
        [-1.0078, -0.8589]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005491964984685183
Epoch 0, Step 486: train/loss = 0.7137138843536377, train/raw-loss = 0.7135626077651978, train/logprobs = tensor([[-0.9736, -0.7100],
        [-1.1440, -0.6967]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005040087271481752
Epoch 0, Step 487: train/loss = 0.713897168636322, train/raw-loss = 0.7134171724319458, train/logprobs = tensor([[-0.8783, -0.8033],
        [-0.9906, -0.8481]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016001374460756779
Epoch 0, Step 488: train/loss = 0.7170228958129883, train/raw-loss = 0.7169970273971558, train/logprobs = tensor([[-1.1299, -1.0828],
        [-1.2539, -1.1329]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.623822941444814e-05
Epoch 0, Step 489: train/loss = 0.7377045750617981, train/raw-loss = 0.7375026345252991, train/logprobs = tensor([[-1.2401, -1.0310],
        [-1.4642, -0.9232]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006730788154527545
Epoch 0, Step 490: train/loss = 0.6940751671791077, train/raw-loss = 0.6939486861228943, train/logprobs = tensor([[-0.6603, -0.6580],
        [-0.7590, -0.6706]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042148688226006925
Epoch 0, Step 491: train/loss = 0.7179831862449646, train/raw-loss = 0.7177643775939941, train/logprobs = tensor([[-0.7895, -0.8099],
        [-0.9557, -0.8924]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007292923983186483
Epoch 0, Step 492: train/loss = 0.7058917284011841, train/raw-loss = 0.7056176066398621, train/logprobs = tensor([[-0.7205, -0.6147],
        [-0.7543, -0.6640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009137318120338023
Epoch 0, Step 493: train/loss = 0.705052375793457, train/raw-loss = 0.7030140161514282, train/logprobs = tensor([[-0.9549, -1.0435],
        [-1.0765, -1.2006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006794454995542765
Epoch 0, Step 494: train/loss = 0.7089224457740784, train/raw-loss = 0.7081671953201294, train/logprobs = tensor([[-1.0036, -0.9099],
        [-1.1329, -0.9300]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002517472021281719
Epoch 0, Step 495: train/loss = 0.7462382316589355, train/raw-loss = 0.7460650205612183, train/logprobs = tensor([[-1.0882, -0.6526],
        [-1.2062, -0.7053]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005773338489234447
Epoch 0, Step 496: train/loss = 0.7032729387283325, train/raw-loss = 0.7029861211776733, train/logprobs = tensor([[-0.8182, -0.7983],
        [-0.9883, -0.8992]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009560309117659926
Epoch 0, Step 497: train/loss = 0.6948912143707275, train/raw-loss = 0.693881630897522, train/logprobs = tensor([[-0.8296, -0.8439],
        [-0.9246, -0.8934]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003365214914083481
Epoch 0, Step 498: train/loss = 0.6983305811882019, train/raw-loss = 0.6980644464492798, train/logprobs = tensor([[-1.1283, -1.0740],
        [-1.3954, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008871813188306987
Epoch 0, Step 499: train/loss = 0.7264335751533508, train/raw-loss = 0.7260857820510864, train/logprobs = tensor([[-0.7805, -0.9871],
        [-0.8382, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001159214647486806
eval/loss: 0.7077750563621521
Epoch 0, Step 500: train/loss = 0.7252010107040405, train/raw-loss = 0.7250329256057739, train/logprobs = tensor([[-1.1096, -0.9403],
        [-1.2777, -0.9988]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005600302829407156
Epoch 0, Step 501: train/loss = 0.7075679302215576, train/raw-loss = 0.7061998248100281, train/logprobs = tensor([[-0.9610, -0.8745],
        [-1.1112, -0.9741]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004560490138828754
Epoch 0, Step 502: train/loss = 0.7089177966117859, train/raw-loss = 0.7084034085273743, train/logprobs = tensor([[-0.8389, -0.7872],
        [-0.9605, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017147515900433064
Epoch 0, Step 503: train/loss = 0.7194564938545227, train/raw-loss = 0.7192137241363525, train/logprobs = tensor([[-0.9565, -1.0157],
        [-1.0510, -1.0519]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008093701908364892
Epoch 0, Step 504: train/loss = 0.7136012315750122, train/raw-loss = 0.7132852673530579, train/logprobs = tensor([[-0.8908, -0.7976],
        [-1.0271, -0.8654]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010532066226005554
Epoch 0, Step 505: train/loss = 0.6943018436431885, train/raw-loss = 0.6939841508865356, train/logprobs = tensor([[-1.0381, -1.1653],
        [-1.2476, -1.2147]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001059102825820446
Epoch 0, Step 506: train/loss = 0.7136044502258301, train/raw-loss = 0.7124068737030029, train/logprobs = tensor([[-1.1561, -1.0017],
        [-1.4078, -1.0745]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003992018289864063
Epoch 0, Step 507: train/loss = 0.6979467272758484, train/raw-loss = 0.6979308724403381, train/logprobs = tensor([[-1.0715, -0.9824],
        [-1.1239, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.279300967231393e-05
Epoch 0, Step 508: train/loss = 0.7046502828598022, train/raw-loss = 0.7043636441230774, train/logprobs = tensor([[-1.2297, -1.0566],
        [-1.4586, -1.1177]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000955620314925909
Epoch 0, Step 509: train/loss = 0.6988479495048523, train/raw-loss = 0.698058009147644, train/logprobs = tensor([[-0.8667, -0.8759],
        [-1.0514, -0.8393]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002633362077176571
Epoch 0, Step 510: train/loss = 0.7048740386962891, train/raw-loss = 0.7048301696777344, train/logprobs = tensor([[-0.8056, -0.7576],
        [-0.8766, -0.8362]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00014629197539761662
Epoch 0, Step 511: train/loss = 0.7112596035003662, train/raw-loss = 0.7111769914627075, train/logprobs = tensor([[-0.5441, -0.8947],
        [-0.6265, -0.8401]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027554092230275273
Epoch 0, Step 512: train/loss = 0.6967697739601135, train/raw-loss = 0.6959798336029053, train/logprobs = tensor([[-0.9954, -1.0310],
        [-1.1160, -1.1568]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026331522967666388
Epoch 0, Step 513: train/loss = 0.7115943431854248, train/raw-loss = 0.7112303376197815, train/logprobs = tensor([[-0.9403, -0.6864],
        [-1.0812, -0.7361]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012134319404140115
Epoch 0, Step 514: train/loss = 0.7087703943252563, train/raw-loss = 0.7086068987846375, train/logprobs = tensor([[-0.9688, -0.9933],
        [-1.1020, -0.9601]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005448076408356428
Epoch 0, Step 515: train/loss = 0.6956931352615356, train/raw-loss = 0.6946810483932495, train/logprobs = tensor([[-0.7107, -0.7175],
        [-0.8223, -0.9719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00337363057769835
Epoch 0, Step 516: train/loss = 0.7056116461753845, train/raw-loss = 0.7055908441543579, train/logprobs = tensor([[-0.9969, -0.8038],
        [-1.1507, -0.8726]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.948683585505933e-05
Epoch 0, Step 517: train/loss = 0.6994636654853821, train/raw-loss = 0.6992111802101135, train/logprobs = tensor([[-0.9006, -1.0715],
        [-1.0418, -0.9658]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008417684002779424
Epoch 0, Step 518: train/loss = 0.6964130997657776, train/raw-loss = 0.6959322094917297, train/logprobs = tensor([[-0.9764, -0.9271],
        [-1.2567, -0.9694]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016030757687985897
Epoch 0, Step 519: train/loss = 0.7024657130241394, train/raw-loss = 0.7022608518600464, train/logprobs = tensor([[-0.7896, -0.8525],
        [-0.8800, -0.9011]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006827794713899493
Epoch 0, Step 520: train/loss = 0.6947730183601379, train/raw-loss = 0.6942141056060791, train/logprobs = tensor([[-0.8684, -1.0314],
        [-1.0783, -0.9538]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018631907878443599
Epoch 0, Step 521: train/loss = 0.6822093725204468, train/raw-loss = 0.6810795068740845, train/logprobs = tensor([[-0.7399, -0.9968],
        [-0.9976, -0.8832]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0037662219256162643
Epoch 0, Step 522: train/loss = 0.7007251381874084, train/raw-loss = 0.7004177570343018, train/logprobs = tensor([[-1.0817, -1.1621],
        [-1.2592, -1.2708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00102440663613379
Epoch 0, Step 523: train/loss = 0.7013105154037476, train/raw-loss = 0.7012253999710083, train/logprobs = tensor([[-0.7215, -0.7654],
        [-0.8015, -0.8146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002839192748069763
Epoch 0, Step 524: train/loss = 0.7754121422767639, train/raw-loss = 0.7741549611091614, train/logprobs = tensor([[-1.4149, -0.7379],
        [-1.5566, -0.8396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004190671723335981
Epoch 0, Step 525: train/loss = 0.6940335631370544, train/raw-loss = 0.693863034248352, train/logprobs = tensor([[-0.8091, -0.7873],
        [-0.9801, -0.8567]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005685504875145853
Epoch 0, Step 526: train/loss = 0.7035414576530457, train/raw-loss = 0.7035332918167114, train/logprobs = tensor([[-0.9469, -0.8061],
        [-1.0715, -0.8921]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.723588841035962e-05
Epoch 0, Step 527: train/loss = 0.7144529819488525, train/raw-loss = 0.7143859267234802, train/logprobs = tensor([[-1.1271, -0.8687],
        [-1.1950, -0.9299]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022370793158188462
Epoch 0, Step 528: train/loss = 0.7086231112480164, train/raw-loss = 0.7031540274620056, train/logprobs = tensor([[-1.0643, -1.0504],
        [-1.2692, -1.1007]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.01823025941848755
Epoch 0, Step 529: train/loss = 0.7069985866546631, train/raw-loss = 0.7066006064414978, train/logprobs = tensor([[-0.8068, -0.8609],
        [-0.9930, -0.8909]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013265254674479365
Epoch 0, Step 530: train/loss = 0.7019769549369812, train/raw-loss = 0.7019051313400269, train/logprobs = tensor([[-0.8838, -1.1092],
        [-0.9790, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023943776614032686
Epoch 0, Step 531: train/loss = 0.6962289810180664, train/raw-loss = 0.6961790919303894, train/logprobs = tensor([[-0.5915, -0.6845],
        [-0.6691, -0.7151]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001663756265770644
Epoch 0, Step 532: train/loss = 0.7032085657119751, train/raw-loss = 0.7025808691978455, train/logprobs = tensor([[-1.0454, -0.8668],
        [-1.5595, -0.9794]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020920061506330967
Epoch 0, Step 533: train/loss = 0.7164458632469177, train/raw-loss = 0.7162545323371887, train/logprobs = tensor([[-1.0817, -0.7901],
        [-1.2719, -0.8664]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006375673692673445
Epoch 0, Step 534: train/loss = 0.7084126472473145, train/raw-loss = 0.706995964050293, train/logprobs = tensor([[-0.8785, -1.0929],
        [-0.9997, -1.1555]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004722150973975658
Epoch 0, Step 535: train/loss = 0.695980966091156, train/raw-loss = 0.6954931020736694, train/logprobs = tensor([[-0.8062, -0.8562],
        [-0.9212, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016257948009297252
Epoch 0, Step 536: train/loss = 0.721009373664856, train/raw-loss = 0.7206252813339233, train/logprobs = tensor([[-1.1292, -0.7534],
        [-1.3322, -0.8347]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012804495636373758
Epoch 0, Step 537: train/loss = 0.712116003036499, train/raw-loss = 0.711702823638916, train/logprobs = tensor([[-0.8660, -0.8869],
        [-0.9852, -0.9975]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001377086853608489
Epoch 0, Step 538: train/loss = 0.7149925231933594, train/raw-loss = 0.7148420214653015, train/logprobs = tensor([[-0.9381, -0.8805],
        [-1.1140, -0.9478]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005016698851250112
Epoch 0, Step 539: train/loss = 0.6996853947639465, train/raw-loss = 0.6983004212379456, train/logprobs = tensor([[-0.9360, -0.9464],
        [-1.0373, -0.9806]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004616483114659786
Epoch 0, Step 540: train/loss = 0.7131800651550293, train/raw-loss = 0.7130450010299683, train/logprobs = tensor([[-0.9439, -0.8588],
        [-1.0914, -0.9060]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045020817196927965
Epoch 0, Step 541: train/loss = 0.7313960790634155, train/raw-loss = 0.7300909161567688, train/logprobs = tensor([[-0.7435, -0.9803],
        [-0.8972, -1.0064]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004350647330284119
Epoch 0, Step 542: train/loss = 0.7143064141273499, train/raw-loss = 0.7142437100410461, train/logprobs = tensor([[-0.9051, -0.6340],
        [-1.0215, -0.6803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020904913253616542
Epoch 0, Step 543: train/loss = 0.704521656036377, train/raw-loss = 0.7043029069900513, train/logprobs = tensor([[-1.1418, -0.8784],
        [-1.2979, -0.9838]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007291771471500397
Epoch 0, Step 544: train/loss = 0.6938865184783936, train/raw-loss = 0.6934076547622681, train/logprobs = tensor([[-0.9385, -1.0065],
        [-1.0143, -1.0422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001596271526068449
Epoch 0, Step 545: train/loss = 0.6948196887969971, train/raw-loss = 0.6945841312408447, train/logprobs = tensor([[-0.9131, -1.0010],
        [-1.0766, -1.0830]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007849559187889099
Epoch 0, Step 546: train/loss = 0.7235919833183289, train/raw-loss = 0.7229577898979187, train/logprobs = tensor([[-0.7545, -1.1426],
        [-0.8643, -1.0340]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021141215693205595
Epoch 0, Step 547: train/loss = 0.7103815674781799, train/raw-loss = 0.7103024125099182, train/logprobs = tensor([[-1.0531, -1.0879],
        [-1.3143, -1.1376]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002636770950630307
Epoch 0, Step 548: train/loss = 0.6982825398445129, train/raw-loss = 0.6964724063873291, train/logprobs = tensor([[-0.9484, -0.8701],
        [-1.1490, -0.9604]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006033786106854677
Epoch 0, Step 549: train/loss = 0.6955451965332031, train/raw-loss = 0.6951966285705566, train/logprobs = tensor([[-0.8538, -0.8300],
        [-0.9364, -0.8032]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011617690324783325
Epoch 0, Step 550: train/loss = 0.6805266737937927, train/raw-loss = 0.679173469543457, train/logprobs = tensor([[-0.8201, -1.0787],
        [-1.4192, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004510768223553896
Epoch 0, Step 551: train/loss = 0.7875911593437195, train/raw-loss = 0.7869139909744263, train/logprobs = tensor([[-0.9579, -1.6409],
        [-1.0567, -1.5144]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022571308072656393
Epoch 0, Step 552: train/loss = 0.7046874761581421, train/raw-loss = 0.7037579417228699, train/logprobs = tensor([[-0.8074, -0.9899],
        [-0.9650, -0.9489]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003098453162238002
Epoch 0, Step 553: train/loss = 0.6962788105010986, train/raw-loss = 0.6961998343467712, train/logprobs = tensor([[-0.9161, -0.8982],
        [-1.0480, -1.0146]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026332837296649814
Epoch 0, Step 554: train/loss = 0.698409914970398, train/raw-loss = 0.6973644495010376, train/logprobs = tensor([[-0.9782, -0.9666],
        [-1.2589, -0.9943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003484977874904871
Epoch 0, Step 555: train/loss = 0.7250168919563293, train/raw-loss = 0.7249401807785034, train/logprobs = tensor([[-0.8317, -1.4412],
        [-0.9415, -1.3040]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00025573966559022665
Epoch 0, Step 556: train/loss = 0.7010166049003601, train/raw-loss = 0.7007278203964233, train/logprobs = tensor([[-0.8108, -0.8528],
        [-0.9521, -0.8813]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009626592509448528
Epoch 0, Step 557: train/loss = 0.704092264175415, train/raw-loss = 0.7010568380355835, train/logprobs = tensor([[-0.8488, -0.8168],
        [-0.9475, -0.8431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.010118207894265652
Epoch 0, Step 558: train/loss = 0.6964032053947449, train/raw-loss = 0.6957175731658936, train/logprobs = tensor([[-1.1044, -1.1459],
        [-1.3269, -1.0521]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00228517921641469
Epoch 0, Step 559: train/loss = 0.7129450440406799, train/raw-loss = 0.7123976945877075, train/logprobs = tensor([[-0.8277, -0.7477],
        [-1.0154, -0.7987]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001824727514758706
Epoch 0, Step 560: train/loss = 0.6944230198860168, train/raw-loss = 0.6943223476409912, train/logprobs = tensor([[-1.0725, -1.0803],
        [-1.2104, -1.1280]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033582071773707867
Epoch 0, Step 561: train/loss = 0.7064732313156128, train/raw-loss = 0.7059373259544373, train/logprobs = tensor([[-1.0897, -0.8578],
        [-1.2433, -0.9417]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017861586529761553
Epoch 0, Step 562: train/loss = 0.7119737267494202, train/raw-loss = 0.7118861675262451, train/logprobs = tensor([[-1.1327, -1.0934],
        [-1.2547, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029190920758992434
Epoch 0, Step 563: train/loss = 0.6973824501037598, train/raw-loss = 0.6964909434318542, train/logprobs = tensor([[-0.9738, -0.9694],
        [-1.0944, -0.9725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002971746027469635
Epoch 0, Step 564: train/loss = 0.6983784437179565, train/raw-loss = 0.6983239650726318, train/logprobs = tensor([[-1.0042, -0.9448],
        [-1.0729, -0.9558]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018167225061915815
Epoch 0, Step 565: train/loss = 0.6957932710647583, train/raw-loss = 0.6951749920845032, train/logprobs = tensor([[-0.7165, -0.6537],
        [-0.8173, -0.6776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0020609661005437374
Epoch 0, Step 566: train/loss = 0.6986417770385742, train/raw-loss = 0.6976998448371887, train/logprobs = tensor([[-0.8855, -0.9725],
        [-1.0765, -0.9471]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031399887520819902
Epoch 0, Step 567: train/loss = 0.709099292755127, train/raw-loss = 0.7084407210350037, train/logprobs = tensor([[-1.0825, -0.8377],
        [-1.2535, -0.9641]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021954094991087914
Epoch 0, Step 568: train/loss = 0.7048524022102356, train/raw-loss = 0.704048752784729, train/logprobs = tensor([[-1.0857, -0.9497],
        [-1.2579, -1.0869]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002678758930414915
Epoch 0, Step 569: train/loss = 0.6995154023170471, train/raw-loss = 0.6993323564529419, train/logprobs = tensor([[-0.8433, -0.8348],
        [-0.9647, -0.9441]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006102032493799925
Epoch 0, Step 570: train/loss = 0.7028141021728516, train/raw-loss = 0.7026969790458679, train/logprobs = tensor([[-0.8766, -0.9967],
        [-0.8920, -1.0117]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039045512676239014
Epoch 0, Step 571: train/loss = 0.694951593875885, train/raw-loss = 0.6948084831237793, train/logprobs = tensor([[-0.9262, -1.0028],
        [-0.9928, -1.0322]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047721166629344225
Epoch 0, Step 572: train/loss = 0.7830444574356079, train/raw-loss = 0.7828740477561951, train/logprobs = tensor([[-0.9593, -0.9549],
        [-1.0960, -0.9949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000568170624319464
Epoch 0, Step 573: train/loss = 0.7079622149467468, train/raw-loss = 0.7078756093978882, train/logprobs = tensor([[-0.6768, -0.9894],
        [-0.7510, -1.0001]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028872155235148966
Epoch 0, Step 574: train/loss = 0.7125750780105591, train/raw-loss = 0.7124252319335938, train/logprobs = tensor([[-0.9688, -0.9555],
        [-1.1080, -1.0098]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004996818024665117
Epoch 0, Step 575: train/loss = 0.6979507207870483, train/raw-loss = 0.697579562664032, train/logprobs = tensor([[-0.8257, -0.8656],
        [-0.8634, -0.9260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012372764758765697
Epoch 0, Step 576: train/loss = 0.7104271650314331, train/raw-loss = 0.7095556259155273, train/logprobs = tensor([[-0.9560, -1.1300],
        [-1.0292, -1.3224]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002905377186834812
Epoch 0, Step 577: train/loss = 0.7091306447982788, train/raw-loss = 0.7087969183921814, train/logprobs = tensor([[-0.8935, -0.7190],
        [-1.0792, -0.7451]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011123587610200047
Epoch 0, Step 578: train/loss = 0.7039719820022583, train/raw-loss = 0.7013702988624573, train/logprobs = tensor([[-0.7715, -0.8406],
        [-0.9627, -0.9302]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008672185242176056
Epoch 0, Step 579: train/loss = 0.6964195370674133, train/raw-loss = 0.696308434009552, train/logprobs = tensor([[-0.7825, -0.7618],
        [-0.9193, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00037051018443889916
Epoch 0, Step 580: train/loss = 0.6956630349159241, train/raw-loss = 0.6955546140670776, train/logprobs = tensor([[-0.6933, -0.7685],
        [-0.8127, -0.7735]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00036139172152616084
Epoch 0, Step 581: train/loss = 0.6986147165298462, train/raw-loss = 0.6979779005050659, train/logprobs = tensor([[-0.8835, -1.0781],
        [-1.1015, -1.1981]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00212267367169261
Epoch 0, Step 582: train/loss = 0.739189624786377, train/raw-loss = 0.7389760613441467, train/logprobs = tensor([[-1.0159, -0.7280],
        [-1.0995, -0.7390]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007119040237739682
Epoch 0, Step 583: train/loss = 0.7048830986022949, train/raw-loss = 0.7048369646072388, train/logprobs = tensor([[-0.9250, -0.7840],
        [-1.1111, -0.8705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015366228763014078
Epoch 0, Step 584: train/loss = 0.7008843421936035, train/raw-loss = 0.7000897526741028, train/logprobs = tensor([[-0.8538, -0.9108],
        [-0.9673, -0.9747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0026484564878046513
Epoch 0, Step 585: train/loss = 0.7050108313560486, train/raw-loss = 0.7049083709716797, train/logprobs = tensor([[-0.8693, -0.6997],
        [-0.9205, -0.7317]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003413027443457395
Epoch 0, Step 586: train/loss = 0.7040747404098511, train/raw-loss = 0.7027754783630371, train/logprobs = tensor([[-0.8716, -1.1981],
        [-1.0717, -1.1229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004330862313508987
Epoch 0, Step 587: train/loss = 0.7085050344467163, train/raw-loss = 0.7080111503601074, train/logprobs = tensor([[-0.8297, -0.5829],
        [-1.0051, -0.6193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001646246761083603
Epoch 0, Step 588: train/loss = 0.6959816217422485, train/raw-loss = 0.6954895257949829, train/logprobs = tensor([[-0.8004, -0.9223],
        [-0.9359, -1.0564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016401003813371062
Epoch 0, Step 589: train/loss = 0.6964566707611084, train/raw-loss = 0.6963285803794861, train/logprobs = tensor([[-0.8539, -0.9128],
        [-0.9441, -0.9391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042694108560681343
Epoch 0, Step 590: train/loss = 0.695592999458313, train/raw-loss = 0.692733883857727, train/logprobs = tensor([[-0.8653, -0.9356],
        [-0.9849, -0.9482]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00953032448887825
Epoch 0, Step 591: train/loss = 0.7029502391815186, train/raw-loss = 0.7028198838233948, train/logprobs = tensor([[-0.9053, -0.9846],
        [-1.0957, -1.0757]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00043439026921987534
Epoch 0, Step 592: train/loss = 0.6988937854766846, train/raw-loss = 0.6986674666404724, train/logprobs = tensor([[-0.9109, -0.7793],
        [-0.9793, -0.7501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007541662198491395
Epoch 0, Step 593: train/loss = 0.6983368396759033, train/raw-loss = 0.6981894373893738, train/logprobs = tensor([[-0.9368, -0.9962],
        [-1.1208, -1.0286]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004913897719234228
Epoch 0, Step 594: train/loss = 0.6862785220146179, train/raw-loss = 0.6862516403198242, train/logprobs = tensor([[-0.8400, -1.1464],
        [-0.8989, -0.8279]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.984450687421486e-05
Epoch 0, Step 595: train/loss = 0.7072035670280457, train/raw-loss = 0.7067742347717285, train/logprobs = tensor([[-0.9660, -1.0132],
        [-1.1063, -1.0670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014312762068584561
Epoch 0, Step 596: train/loss = 0.6887692809104919, train/raw-loss = 0.6868407726287842, train/logprobs = tensor([[-1.0484, -1.2084],
        [-1.2971, -1.1017]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0064284540712833405
Epoch 0, Step 597: train/loss = 0.7027778029441833, train/raw-loss = 0.7026762962341309, train/logprobs = tensor([[-1.2322, -1.1975],
        [-1.4323, -1.2587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033844151766970754
Epoch 0, Step 598: train/loss = 0.6958550214767456, train/raw-loss = 0.6956796646118164, train/logprobs = tensor([[-0.9431, -1.0020],
        [-1.0517, -1.0173]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005843350663781166
Epoch 0, Step 599: train/loss = 0.6999062299728394, train/raw-loss = 0.698625385761261, train/logprobs = tensor([[-0.8139, -1.0743],
        [-0.9376, -0.9953]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0042695458978414536
Epoch 0, Step 600: train/loss = 0.76069176197052, train/raw-loss = 0.7606217861175537, train/logprobs = tensor([[-1.0171, -0.9124],
        [-1.1555, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002332932490389794
Epoch 0, Step 601: train/loss = 0.7117937803268433, train/raw-loss = 0.7116599678993225, train/logprobs = tensor([[-1.0347, -0.7986],
        [-1.3282, -0.8865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044607813470065594
Epoch 0, Step 602: train/loss = 0.6987478137016296, train/raw-loss = 0.6986251473426819, train/logprobs = tensor([[-0.6875, -0.5302],
        [-0.7885, -0.5747]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040897284634411335
Epoch 0, Step 603: train/loss = 0.6963586807250977, train/raw-loss = 0.6961183547973633, train/logprobs = tensor([[-0.9167, -1.1730],
        [-1.0988, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008012186735868454
Epoch 0, Step 604: train/loss = 0.7463655471801758, train/raw-loss = 0.7461997866630554, train/logprobs = tensor([[-1.4860, -1.4462],
        [-1.7862, -1.5616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000552720099221915
Epoch 0, Step 605: train/loss = 0.6960632801055908, train/raw-loss = 0.6960546970367432, train/logprobs = tensor([[-0.8738, -0.8496],
        [-0.9133, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.8473063139244914e-05
Epoch 0, Step 606: train/loss = 0.7372796535491943, train/raw-loss = 0.7372403144836426, train/logprobs = tensor([[-0.7219, -1.0159],
        [-0.8158, -1.0063]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013086479157209396
Epoch 0, Step 607: train/loss = 0.6965053677558899, train/raw-loss = 0.6965000629425049, train/logprobs = tensor([[-0.9128, -0.8497],
        [-0.9639, -0.8422]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7648926586844027e-05
Epoch 0, Step 608: train/loss = 0.6993725895881653, train/raw-loss = 0.6989295482635498, train/logprobs = tensor([[-1.0723, -1.0716],
        [-1.1769, -1.0859]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014770617708563805
Epoch 0, Step 609: train/loss = 0.7796298861503601, train/raw-loss = 0.7790864706039429, train/logprobs = tensor([[-1.0446, -1.5563],
        [-1.2718, -1.5721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018111596582457423
Epoch 0, Step 610: train/loss = 0.7063016295433044, train/raw-loss = 0.7060809135437012, train/logprobs = tensor([[-1.0179, -0.9264],
        [-1.1173, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007355835987254977
Epoch 0, Step 611: train/loss = 0.7135273814201355, train/raw-loss = 0.7121363878250122, train/logprobs = tensor([[-1.0992, -0.9834],
        [-1.2871, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004636683501303196
Epoch 0, Step 612: train/loss = 0.6936517953872681, train/raw-loss = 0.6934190988540649, train/logprobs = tensor([[-0.8738, -0.8064],
        [-0.9147, -0.8843]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007755504921078682
Epoch 0, Step 613: train/loss = 0.8007846474647522, train/raw-loss = 0.8005858063697815, train/logprobs = tensor([[-0.8496, -1.2622],
        [-0.9155, -1.2118]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006628091214224696
Epoch 0, Step 614: train/loss = 0.6942516565322876, train/raw-loss = 0.6941957473754883, train/logprobs = tensor([[-0.8498, -0.9498],
        [-0.9105, -0.9463]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018637700122781098
Epoch 0, Step 615: train/loss = 0.7275882959365845, train/raw-loss = 0.7275521159172058, train/logprobs = tensor([[-0.7508, -1.0475],
        [-0.9295, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012079188309144229
Epoch 0, Step 616: train/loss = 0.7177013158798218, train/raw-loss = 0.7173887491226196, train/logprobs = tensor([[-1.0925, -0.9942],
        [-1.2642, -1.0061]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010419221362099051
Epoch 0, Step 617: train/loss = 0.7039703726768494, train/raw-loss = 0.7037361264228821, train/logprobs = tensor([[-1.1261, -0.9835],
        [-1.2307, -1.0824]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007806866196915507
Epoch 0, Step 618: train/loss = 0.7078354954719543, train/raw-loss = 0.707435667514801, train/logprobs = tensor([[-0.8723, -0.6435],
        [-1.0001, -0.6570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013327754568308592
Epoch 0, Step 619: train/loss = 0.702315628528595, train/raw-loss = 0.7022401094436646, train/logprobs = tensor([[-0.8958, -0.7541],
        [-0.9398, -0.8154]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002515699598006904
Epoch 0, Step 620: train/loss = 0.7694563269615173, train/raw-loss = 0.7689098119735718, train/logprobs = tensor([[-0.9740, -1.4141],
        [-1.0391, -1.3291]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018215933814644814
Epoch 0, Step 621: train/loss = 0.7212207913398743, train/raw-loss = 0.7209540605545044, train/logprobs = tensor([[-1.1768, -0.9186],
        [-1.2959, -1.0457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008892277837730944
Epoch 0, Step 622: train/loss = 0.7126230001449585, train/raw-loss = 0.7121375203132629, train/logprobs = tensor([[-0.9617, -0.8975],
        [-1.0239, -0.8943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016183089464902878
Epoch 0, Step 623: train/loss = 0.6927783489227295, train/raw-loss = 0.6926929354667664, train/logprobs = tensor([[-0.8881, -0.8806],
        [-1.0178, -0.8839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028469302924349904
Epoch 0, Step 624: train/loss = 0.7005288600921631, train/raw-loss = 0.7000229358673096, train/logprobs = tensor([[-0.8987, -0.9441],
        [-0.9579, -0.9217]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001686318777501583
Epoch 0, Step 625: train/loss = 0.7227005958557129, train/raw-loss = 0.7220101952552795, train/logprobs = tensor([[-0.9168, -1.2499],
        [-0.9838, -1.3160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002301185391843319
Epoch 0, Step 626: train/loss = 0.7073529958724976, train/raw-loss = 0.7063329219818115, train/logprobs = tensor([[-0.9703, -1.1934],
        [-1.1711, -1.1647]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034003963228315115
Epoch 0, Step 627: train/loss = 0.6934301257133484, train/raw-loss = 0.693425178527832, train/logprobs = tensor([[-0.7526, -0.7766],
        [-0.8518, -0.8750]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.6503850929439068e-05
Epoch 0, Step 628: train/loss = 0.7018021941184998, train/raw-loss = 0.700456440448761, train/logprobs = tensor([[-0.9523, -1.0436],
        [-1.1169, -1.0613]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004485899116843939
Epoch 0, Step 629: train/loss = 0.7056514620780945, train/raw-loss = 0.7052116394042969, train/logprobs = tensor([[-0.6307, -0.8736],
        [-0.7023, -0.8995]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001465904526412487
Epoch 0, Step 630: train/loss = 0.7934447526931763, train/raw-loss = 0.7933892607688904, train/logprobs = tensor([[-0.8264, -1.2518],
        [-0.8749, -1.2237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018519774312153459
Epoch 0, Step 631: train/loss = 0.7270511984825134, train/raw-loss = 0.7269552946090698, train/logprobs = tensor([[-0.7236, -1.0567],
        [-0.7368, -1.0931]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000319531187415123
Epoch 0, Step 632: train/loss = 0.7150525450706482, train/raw-loss = 0.71480393409729, train/logprobs = tensor([[-1.0385, -0.8249],
        [-1.1954, -0.8575]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008289163815788925
Epoch 0, Step 633: train/loss = 0.7052055597305298, train/raw-loss = 0.7050824761390686, train/logprobs = tensor([[-0.9169, -1.1551],
        [-0.9922, -1.1097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004102393868379295
Epoch 0, Step 634: train/loss = 0.6955264210700989, train/raw-loss = 0.695511519908905, train/logprobs = tensor([[-0.8893, -0.9975],
        [-0.9193, -1.0097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.975771298632026e-05
Epoch 0, Step 635: train/loss = 0.7326578497886658, train/raw-loss = 0.7325917482376099, train/logprobs = tensor([[-1.1055, -1.3914],
        [-1.1754, -1.3457]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00022028913372196257
Epoch 0, Step 636: train/loss = 0.7133479118347168, train/raw-loss = 0.7129004597663879, train/logprobs = tensor([[-0.9158, -1.2156],
        [-1.0035, -1.2126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014915831852704287
Epoch 0, Step 637: train/loss = 0.7053700089454651, train/raw-loss = 0.705255925655365, train/logprobs = tensor([[-0.8717, -0.8480],
        [-0.9192, -0.9026]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00038024812238290906
Epoch 0, Step 638: train/loss = 0.6982576847076416, train/raw-loss = 0.6981354355812073, train/logprobs = tensor([[-0.8696, -0.8957],
        [-1.0422, -1.0103]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004077085468452424
Epoch 0, Step 639: train/loss = 0.718866765499115, train/raw-loss = 0.7187544107437134, train/logprobs = tensor([[-1.1287, -1.2058],
        [-1.3089, -1.2074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003744155983440578
Epoch 0, Step 640: train/loss = 0.7056440114974976, train/raw-loss = 0.705417275428772, train/logprobs = tensor([[-0.9547, -1.1058],
        [-1.0893, -1.1640]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007557012140750885
Epoch 0, Step 641: train/loss = 0.7039734125137329, train/raw-loss = 0.7034499645233154, train/logprobs = tensor([[-0.7943, -0.7451],
        [-0.9397, -0.7306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017447280697524548
Epoch 0, Step 642: train/loss = 0.6975159049034119, train/raw-loss = 0.6973810195922852, train/logprobs = tensor([[-1.0911, -0.9873],
        [-1.1696, -0.9904]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004496381152421236
Epoch 0, Step 643: train/loss = 0.694140613079071, train/raw-loss = 0.6939659714698792, train/logprobs = tensor([[-0.7687, -0.8866],
        [-0.8928, -0.9100]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005822563543915749
Epoch 0, Step 644: train/loss = 0.7423831224441528, train/raw-loss = 0.7422612905502319, train/logprobs = tensor([[-1.0127, -1.0998],
        [-1.0489, -0.9871]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004059812054038048
Epoch 0, Step 645: train/loss = 0.6960087418556213, train/raw-loss = 0.6956406235694885, train/logprobs = tensor([[-0.9067, -1.0016],
        [-1.0288, -0.9893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012269383296370506
Epoch 0, Step 646: train/loss = 0.6997199058532715, train/raw-loss = 0.6993323564529419, train/logprobs = tensor([[-0.7264, -0.8769],
        [-0.9170, -0.9765]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001291961409151554
Epoch 0, Step 647: train/loss = 0.7162114977836609, train/raw-loss = 0.7160847783088684, train/logprobs = tensor([[-0.9701, -1.3181],
        [-1.2359, -1.4596]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004223767318762839
Epoch 0, Step 648: train/loss = 0.701917827129364, train/raw-loss = 0.7015881538391113, train/logprobs = tensor([[-1.0128, -1.1053],
        [-1.0501, -1.0525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010989055735990405
Epoch 0, Step 649: train/loss = 0.6984351277351379, train/raw-loss = 0.6981831789016724, train/logprobs = tensor([[-0.8043, -0.9523],
        [-0.8527, -0.9331]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008399420185014606
Epoch 0, Step 650: train/loss = 0.6959769129753113, train/raw-loss = 0.695960283279419, train/logprobs = tensor([[-0.9257, -1.0424],
        [-1.0988, -1.1407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.522747233044356e-05
Epoch 0, Step 651: train/loss = 0.723137378692627, train/raw-loss = 0.7220475673675537, train/logprobs = tensor([[-1.0647, -1.2136],
        [-1.1899, -1.3227]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003632596228271723
Epoch 0, Step 652: train/loss = 0.6992005109786987, train/raw-loss = 0.6989086866378784, train/logprobs = tensor([[-0.8318, -0.9209],
        [-0.9328, -0.9591]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009728851728141308
Epoch 0, Step 653: train/loss = 0.7016368508338928, train/raw-loss = 0.701408863067627, train/logprobs = tensor([[-1.0017, -0.8005],
        [-1.0693, -0.8006]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007601753459312022
Epoch 0, Step 654: train/loss = 0.7025846242904663, train/raw-loss = 0.7023756504058838, train/logprobs = tensor([[-0.9249, -1.0912],
        [-1.1278, -1.0785]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006964744534343481
Epoch 0, Step 655: train/loss = 0.6945430636405945, train/raw-loss = 0.6945137977600098, train/logprobs = tensor([[-0.8277, -0.8377],
        [-0.8837, -0.8480]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.753216727403924e-05
Epoch 0, Step 656: train/loss = 0.701805591583252, train/raw-loss = 0.7015126347541809, train/logprobs = tensor([[-1.0719, -0.8793],
        [-1.1127, -0.8721]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009764904389157891
Epoch 0, Step 657: train/loss = 0.6960703134536743, train/raw-loss = 0.6956253051757812, train/logprobs = tensor([[-0.7980, -0.9044],
        [-0.8988, -0.9196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014832655433565378
Epoch 0, Step 658: train/loss = 0.700171947479248, train/raw-loss = 0.6998879909515381, train/logprobs = tensor([[-0.8600, -0.9861],
        [-0.9976, -0.9929]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009468027856200933
Epoch 0, Step 659: train/loss = 0.7430122494697571, train/raw-loss = 0.7428145408630371, train/logprobs = tensor([[-0.8324, -1.3616],
        [-0.9937, -1.3758]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000659123994410038
Epoch 0, Step 660: train/loss = 0.7022486329078674, train/raw-loss = 0.7016904354095459, train/logprobs = tensor([[-0.9388, -0.9009],
        [-1.1412, -0.9018]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018606429221108556
Epoch 0, Step 661: train/loss = 0.6951711177825928, train/raw-loss = 0.6949553489685059, train/logprobs = tensor([[-0.8729, -0.8505],
        [-1.0357, -0.9074]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007190564647316933
Epoch 0, Step 662: train/loss = 0.695096492767334, train/raw-loss = 0.6949771642684937, train/logprobs = tensor([[-1.0327, -1.0678],
        [-1.1111, -1.0520]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00039781793020665646
Epoch 0, Step 663: train/loss = 0.6946848034858704, train/raw-loss = 0.6937603950500488, train/logprobs = tensor([[-0.8117, -0.8992],
        [-1.0708, -0.8873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0030811575707048178
Epoch 0, Step 664: train/loss = 0.7060278654098511, train/raw-loss = 0.7045021057128906, train/logprobs = tensor([[-0.9407, -0.9409],
        [-1.0325, -0.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005085826851427555
Epoch 0, Step 665: train/loss = 0.6976377964019775, train/raw-loss = 0.6972689628601074, train/logprobs = tensor([[-0.9120, -0.9124],
        [-1.0275, -0.9263]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012294938787817955
Epoch 0, Step 666: train/loss = 0.7005019187927246, train/raw-loss = 0.7003999948501587, train/logprobs = tensor([[-0.6789, -0.8687],
        [-0.7562, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033972616074606776
Epoch 0, Step 667: train/loss = 0.7113386392593384, train/raw-loss = 0.7103148102760315, train/logprobs = tensor([[-0.8277, -0.8135],
        [-0.8591, -0.8944]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034127100370824337
Epoch 0, Step 668: train/loss = 0.6962997317314148, train/raw-loss = 0.6960865259170532, train/logprobs = tensor([[-0.8499, -0.8625],
        [-0.9615, -0.8673]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007106162374839187
Epoch 0, Step 669: train/loss = 0.7033922076225281, train/raw-loss = 0.7029818296432495, train/logprobs = tensor([[-0.9627, -1.2714],
        [-1.1405, -1.2574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013679706025868654
Epoch 0, Step 670: train/loss = 0.7101789712905884, train/raw-loss = 0.7098696231842041, train/logprobs = tensor([[-0.8701, -1.0700],
        [-0.9610, -1.1445]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010307935299351811
Epoch 0, Step 671: train/loss = 0.7039766907691956, train/raw-loss = 0.7025365829467773, train/logprobs = tensor([[-0.7403, -0.9943],
        [-0.8020, -1.0943]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004800420254468918
Epoch 0, Step 672: train/loss = 0.7042899131774902, train/raw-loss = 0.7039761543273926, train/logprobs = tensor([[-1.0699, -0.8363],
        [-1.1296, -0.8632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010458460310474038
Epoch 0, Step 673: train/loss = 0.7154302597045898, train/raw-loss = 0.7153468728065491, train/logprobs = tensor([[-0.9732, -1.0716],
        [-1.1273, -1.1836]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002778393682092428
Epoch 0, Step 674: train/loss = 0.6985076069831848, train/raw-loss = 0.6980183124542236, train/logprobs = tensor([[-1.1017, -1.2406],
        [-1.1258, -1.2303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016311954241245985
Epoch 0, Step 675: train/loss = 0.711660623550415, train/raw-loss = 0.7112932205200195, train/logprobs = tensor([[-1.0728, -1.2979],
        [-1.1161, -1.3969]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012248193379491568
Epoch 0, Step 676: train/loss = 0.6908330917358398, train/raw-loss = 0.6905717849731445, train/logprobs = tensor([[-0.8656, -0.8455],
        [-1.4797, -0.8547]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008709784015081823
Epoch 0, Step 677: train/loss = 0.7014256119728088, train/raw-loss = 0.7011469602584839, train/logprobs = tensor([[-0.9339, -1.0491],
        [-1.0279, -1.0725]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009287273278459907
Epoch 0, Step 678: train/loss = 0.7081626057624817, train/raw-loss = 0.7076818943023682, train/logprobs = tensor([[-0.9729, -1.2536],
        [-1.1722, -1.3686]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016023109201341867
Epoch 0, Step 679: train/loss = 0.7037172317504883, train/raw-loss = 0.7035130262374878, train/logprobs = tensor([[-0.9239, -0.8490],
        [-1.0845, -0.9200]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006808090256527066
Epoch 0, Step 680: train/loss = 0.7019761800765991, train/raw-loss = 0.7018786072731018, train/logprobs = tensor([[-0.8819, -1.1582],
        [-0.9396, -1.1683]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00032542095868848264
Epoch 0, Step 681: train/loss = 0.6860016584396362, train/raw-loss = 0.6857625246047974, train/logprobs = tensor([[-0.7580, -0.9102],
        [-1.2179, -0.9266]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000797325512394309
Epoch 0, Step 682: train/loss = 0.7259222269058228, train/raw-loss = 0.7256492376327515, train/logprobs = tensor([[-0.9523, -1.3131],
        [-1.0645, -1.2639]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009100104798562825
Epoch 0, Step 683: train/loss = 0.7171421647071838, train/raw-loss = 0.7168650031089783, train/logprobs = tensor([[-0.8948, -0.8424],
        [-0.9956, -0.8455]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009240075596608222
Epoch 0, Step 684: train/loss = 0.7236171364784241, train/raw-loss = 0.7230754494667053, train/logprobs = tensor([[-0.9552, -1.3529],
        [-1.0536, -1.2959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001805631909519434
Epoch 0, Step 685: train/loss = 0.7049534320831299, train/raw-loss = 0.7048406600952148, train/logprobs = tensor([[-0.8251, -0.7776],
        [-0.9239, -0.8037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003760971885640174
Epoch 0, Step 686: train/loss = 0.6964123249053955, train/raw-loss = 0.696113109588623, train/logprobs = tensor([[-1.0147, -1.1751],
        [-1.1241, -1.1961]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000997492577880621
Epoch 0, Step 687: train/loss = 0.6916131973266602, train/raw-loss = 0.6891984939575195, train/logprobs = tensor([[-1.1027, -1.2059],
        [-1.2665, -1.0705]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008049066178500652
Epoch 0, Step 688: train/loss = 0.7537888884544373, train/raw-loss = 0.7536096572875977, train/logprobs = tensor([[-0.8204, -1.4745],
        [-0.8907, -1.4779]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005974293453618884
Epoch 0, Step 689: train/loss = 0.7007209062576294, train/raw-loss = 0.7006893754005432, train/logprobs = tensor([[-0.7284, -0.8433],
        [-0.8122, -0.8649]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010487818508408964
Epoch 0, Step 690: train/loss = 0.706811249256134, train/raw-loss = 0.7064501047134399, train/logprobs = tensor([[-1.0961, -1.2015],
        [-1.1200, -1.1903]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001203741761855781
Epoch 0, Step 691: train/loss = 0.6950260996818542, train/raw-loss = 0.6950085163116455, train/logprobs = tensor([[-0.8639, -0.8893],
        [-0.8730, -0.8833]], device='cuda:0', grad_fn=<DivBackward0>), KL = 5.866395076736808e-05
Epoch 0, Step 692: train/loss = 0.7037712931632996, train/raw-loss = 0.703072190284729, train/logprobs = tensor([[-0.8548, -1.0430],
        [-1.0171, -1.0876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023303574416786432
Epoch 0, Step 693: train/loss = 0.694983720779419, train/raw-loss = 0.6949389576911926, train/logprobs = tensor([[-0.9182, -0.9280],
        [-0.9616, -0.9320]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001491494185756892
Epoch 0, Step 694: train/loss = 0.7049744129180908, train/raw-loss = 0.7046844959259033, train/logprobs = tensor([[-0.9046, -1.0697],
        [-0.9751, -1.1255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009663832606747746
Epoch 0, Step 695: train/loss = 0.6934202909469604, train/raw-loss = 0.6933817863464355, train/logprobs = tensor([[-0.9659, -1.0092],
        [-1.0019, -1.0341]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001281517616007477
Epoch 0, Step 696: train/loss = 0.7063711881637573, train/raw-loss = 0.7056729793548584, train/logprobs = tensor([[-0.9379, -1.1613],
        [-0.9935, -1.1570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023274673148989677
Epoch 0, Step 697: train/loss = 0.6992886066436768, train/raw-loss = 0.698654055595398, train/logprobs = tensor([[-1.0797, -0.9948],
        [-1.2404, -0.9536]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021151136606931686
Epoch 0, Step 698: train/loss = 0.7178484201431274, train/raw-loss = 0.7173982262611389, train/logprobs = tensor([[-1.0824, -1.3694],
        [-1.1088, -1.2976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015005649765953422
Epoch 0, Step 699: train/loss = 0.7418060302734375, train/raw-loss = 0.7412209510803223, train/logprobs = tensor([[-1.0532, -0.9135],
        [-1.2506, -0.9991]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019503040239214897
Epoch 0, Step 700: train/loss = 0.6936565637588501, train/raw-loss = 0.6935650110244751, train/logprobs = tensor([[-0.8441, -0.9347],
        [-0.9824, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003049952501896769
Epoch 0, Step 701: train/loss = 0.7008177042007446, train/raw-loss = 0.7000744342803955, train/logprobs = tensor([[-0.9024, -1.1187],
        [-1.0788, -1.1054]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0024773820769041777
Epoch 0, Step 702: train/loss = 0.7793741226196289, train/raw-loss = 0.7790325880050659, train/logprobs = tensor([[-0.8064, -0.9921],
        [-0.8305, -0.9982]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011384632671251893
Epoch 0, Step 703: train/loss = 0.7036294937133789, train/raw-loss = 0.7031343579292297, train/logprobs = tensor([[-0.9513, -1.0082],
        [-1.1510, -0.9876]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016506204847246408
Epoch 0, Step 704: train/loss = 0.7096614837646484, train/raw-loss = 0.7084932327270508, train/logprobs = tensor([[-0.9611, -1.5343],
        [-1.2980, -1.4218]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003894204506650567
Epoch 0, Step 705: train/loss = 0.7034308910369873, train/raw-loss = 0.7034122943878174, train/logprobs = tensor([[-0.9379, -1.0033],
        [-0.9937, -0.9877]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.20588252786547e-05
Epoch 0, Step 706: train/loss = 0.7006849646568298, train/raw-loss = 0.700535774230957, train/logprobs = tensor([[-0.9772, -0.9230],
        [-1.0103, -0.9689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000497245229780674
Epoch 0, Step 707: train/loss = 0.7234998345375061, train/raw-loss = 0.7231208086013794, train/logprobs = tensor([[-0.9660, -1.3160],
        [-1.0630, -1.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012633269652724266
Epoch 0, Step 708: train/loss = 0.6975353360176086, train/raw-loss = 0.6968435645103455, train/logprobs = tensor([[-0.9879, -1.1888],
        [-1.0652, -1.0708]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023059200029820204
Epoch 0, Step 709: train/loss = 0.7422581911087036, train/raw-loss = 0.742111325263977, train/logprobs = tensor([[-1.1958, -1.0093],
        [-1.3040, -1.0055]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004892447032034397
Epoch 0, Step 710: train/loss = 0.7124356031417847, train/raw-loss = 0.712222695350647, train/logprobs = tensor([[-1.0303, -1.0652],
        [-1.0720, -1.0528]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007099051726981997
Epoch 0, Step 711: train/loss = 0.7125698328018188, train/raw-loss = 0.7120286226272583, train/logprobs = tensor([[-0.8958, -1.0960],
        [-0.8961, -1.0962]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018039967399090528
Epoch 0, Step 712: train/loss = 0.7001146078109741, train/raw-loss = 0.6999937891960144, train/logprobs = tensor([[-0.9271, -0.8570],
        [-1.1178, -0.8391]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040260981768369675
Epoch 0, Step 713: train/loss = 0.7070180177688599, train/raw-loss = 0.7069427371025085, train/logprobs = tensor([[-0.9486, -1.1496],
        [-0.9680, -1.1047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002510154154151678
Epoch 0, Step 714: train/loss = 0.707776665687561, train/raw-loss = 0.7076922655105591, train/logprobs = tensor([[-1.0111, -1.0571],
        [-1.1355, -1.0633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002815002226270735
Epoch 0, Step 715: train/loss = 0.6949878931045532, train/raw-loss = 0.6948272585868835, train/logprobs = tensor([[-0.8839, -0.8566],
        [-1.0278, -0.8689]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005354297463782132
Epoch 0, Step 716: train/loss = 0.7056968212127686, train/raw-loss = 0.7050719261169434, train/logprobs = tensor([[-0.9088, -1.0857],
        [-0.9519, -1.0717]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002083185827359557
Epoch 0, Step 717: train/loss = 0.7076138257980347, train/raw-loss = 0.707319974899292, train/logprobs = tensor([[-1.1071, -1.0179],
        [-1.2152, -1.0096]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009795408695936203
Epoch 0, Step 718: train/loss = 0.698596179485321, train/raw-loss = 0.6984734535217285, train/logprobs = tensor([[-0.9379, -1.0938],
        [-0.9836, -1.0722]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040904758498072624
Epoch 0, Step 719: train/loss = 0.7918356657028198, train/raw-loss = 0.7915446758270264, train/logprobs = tensor([[-0.8122, -1.2824],
        [-0.8192, -1.2902]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009701710077933967
Epoch 0, Step 720: train/loss = 0.724916398525238, train/raw-loss = 0.7247811555862427, train/logprobs = tensor([[-0.7704, -1.0633],
        [-0.8832, -1.0594]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004508838464971632
Epoch 0, Step 721: train/loss = 0.7353174686431885, train/raw-loss = 0.7350567579269409, train/logprobs = tensor([[-0.6105, -0.9308],
        [-0.7160, -0.9565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008690379909239709
Epoch 0, Step 722: train/loss = 0.7097725868225098, train/raw-loss = 0.7097263932228088, train/logprobs = tensor([[-0.8142, -0.8756],
        [-0.8646, -0.8608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000153900939039886
Epoch 0, Step 723: train/loss = 0.7076815962791443, train/raw-loss = 0.7075631618499756, train/logprobs = tensor([[-0.8480, -0.9457],
        [-0.9887, -1.0222]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003946704382542521
Epoch 0, Step 724: train/loss = 0.6982825398445129, train/raw-loss = 0.6981199383735657, train/logprobs = tensor([[-1.0060, -1.1431],
        [-1.0109, -1.1242]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005420848028734326
Epoch 0, Step 725: train/loss = 0.7088568210601807, train/raw-loss = 0.7087938785552979, train/logprobs = tensor([[-0.9935, -0.9375],
        [-1.0585, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002097573596984148
Epoch 0, Step 726: train/loss = 0.7114484310150146, train/raw-loss = 0.7101345062255859, train/logprobs = tensor([[-0.9468, -1.0730],
        [-0.9796, -1.1243]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004379458725452423
Epoch 0, Step 727: train/loss = 0.7161657214164734, train/raw-loss = 0.7159839868545532, train/logprobs = tensor([[-0.9567, -1.2250],
        [-1.1455, -1.1695]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006057728896848857
Epoch 0, Step 728: train/loss = 0.6997328400611877, train/raw-loss = 0.6997050046920776, train/logprobs = tensor([[-0.9208, -1.1015],
        [-1.0372, -1.1716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.27689834497869e-05
Epoch 0, Step 729: train/loss = 0.6957638263702393, train/raw-loss = 0.6946663856506348, train/logprobs = tensor([[-0.8795, -1.1196],
        [-0.9678, -1.0632]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0036582103930413723
Epoch 0, Step 730: train/loss = 0.7080631256103516, train/raw-loss = 0.7078185677528381, train/logprobs = tensor([[-1.1296, -1.4152],
        [-1.1438, -1.3059]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008152746595442295
Epoch 0, Step 731: train/loss = 0.6964548826217651, train/raw-loss = 0.6962772607803345, train/logprobs = tensor([[-0.8486, -0.9115],
        [-1.0542, -0.8851]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005917787202633917
Epoch 0, Step 732: train/loss = 0.7052849531173706, train/raw-loss = 0.7040845155715942, train/logprobs = tensor([[-0.9207, -1.0708],
        [-0.9385, -1.1499]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004001258406788111
Epoch 0, Step 733: train/loss = 0.6961563229560852, train/raw-loss = 0.6961559057235718, train/logprobs = tensor([[-0.7608, -0.8032],
        [-0.7810, -0.8160]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.4597171684727073e-06
Epoch 0, Step 734: train/loss = 0.697435736656189, train/raw-loss = 0.6968283653259277, train/logprobs = tensor([[-0.8443, -1.0982],
        [-0.9428, -0.9764]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002024664543569088
Epoch 0, Step 735: train/loss = 0.6948481798171997, train/raw-loss = 0.6945925951004028, train/logprobs = tensor([[-1.0104, -1.0904],
        [-1.1051, -1.1014]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000851726857945323
Epoch 0, Step 736: train/loss = 0.6961172819137573, train/raw-loss = 0.6960545778274536, train/logprobs = tensor([[-0.9092, -0.8278],
        [-0.9574, -0.8668]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00020890095038339496
Epoch 0, Step 737: train/loss = 0.6979920864105225, train/raw-loss = 0.6973320841789246, train/logprobs = tensor([[-0.9047, -0.9367],
        [-0.9149, -0.9516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021998900920152664
Epoch 0, Step 738: train/loss = 0.7043417692184448, train/raw-loss = 0.7038052082061768, train/logprobs = tensor([[-1.0374, -1.1857],
        [-1.1819, -1.3450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017885115230455995
Epoch 0, Step 739: train/loss = 0.7055918574333191, train/raw-loss = 0.7055386304855347, train/logprobs = tensor([[-0.7932, -1.0139],
        [-0.8466, -0.9579]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017755822045728564
Epoch 0, Step 740: train/loss = 0.6953968405723572, train/raw-loss = 0.6953568458557129, train/logprobs = tensor([[-0.8836, -0.9875],
        [-0.9257, -0.9533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001330771774519235
Epoch 0, Step 741: train/loss = 0.6962801218032837, train/raw-loss = 0.6956498622894287, train/logprobs = tensor([[-0.9347, -1.0442],
        [-0.9509, -0.9950]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021009102929383516
Epoch 0, Step 742: train/loss = 0.6971668004989624, train/raw-loss = 0.6965714693069458, train/logprobs = tensor([[-0.9285, -1.0751],
        [-1.0237, -0.9512]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001984360860660672
Epoch 0, Step 743: train/loss = 0.710951030254364, train/raw-loss = 0.7108133435249329, train/logprobs = tensor([[-0.9500, -1.1174],
        [-1.1714, -1.1278]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004589870513882488
Epoch 0, Step 744: train/loss = 0.697905421257019, train/raw-loss = 0.6977763175964355, train/logprobs = tensor([[-0.9955, -1.0770],
        [-1.0586, -1.1268]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004303951282054186
Epoch 0, Step 745: train/loss = 0.6995775103569031, train/raw-loss = 0.6987840533256531, train/logprobs = tensor([[-0.8729, -0.8423],
        [-0.9504, -0.8294]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002644966822117567
Epoch 0, Step 746: train/loss = 0.7041488885879517, train/raw-loss = 0.7041099071502686, train/logprobs = tensor([[-0.9653, -0.9042],
        [-1.0017, -0.8630]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012993236305192113
Epoch 0, Step 747: train/loss = 0.7146716117858887, train/raw-loss = 0.714168906211853, train/logprobs = tensor([[-0.9021, -1.1892],
        [-1.0406, -1.1140]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001675889128819108
Epoch 0, Step 748: train/loss = 0.6972211599349976, train/raw-loss = 0.6969101428985596, train/logprobs = tensor([[-1.0963, -1.2072],
        [-1.1415, -1.1792]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010368607472628355
Epoch 0, Step 749: train/loss = 0.7127623558044434, train/raw-loss = 0.7112915515899658, train/logprobs = tensor([[-0.7518, -1.0236],
        [-0.8026, -1.1170]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0049027614295482635
Epoch 0, Step 750: train/loss = 0.6946879029273987, train/raw-loss = 0.6946536302566528, train/logprobs = tensor([[-0.7394, -0.8356],
        [-0.7730, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011447547876741737
Epoch 0, Step 751: train/loss = 0.7015218734741211, train/raw-loss = 0.701205849647522, train/logprobs = tensor([[-0.9226, -0.9005],
        [-1.0125, -0.9025]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010535703040659428
Epoch 0, Step 752: train/loss = 0.7142016887664795, train/raw-loss = 0.7140862941741943, train/logprobs = tensor([[-0.9423, -1.2361],
        [-0.9490, -1.1514]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003846538602374494
Epoch 0, Step 753: train/loss = 0.7083573937416077, train/raw-loss = 0.7075348496437073, train/logprobs = tensor([[-0.9257, -1.1895],
        [-0.9987, -1.3111]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0027420453261584044
Epoch 0, Step 754: train/loss = 0.6984750032424927, train/raw-loss = 0.6984661817550659, train/logprobs = tensor([[-0.5624, -0.7039],
        [-0.5879, -0.6885]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.954052615677938e-05
Epoch 0, Step 755: train/loss = 0.696304202079773, train/raw-loss = 0.6960880756378174, train/logprobs = tensor([[-1.0602, -1.0461],
        [-1.1585, -1.1350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007203686982393265
Epoch 0, Step 756: train/loss = 0.7232478857040405, train/raw-loss = 0.7226819396018982, train/logprobs = tensor([[-1.0735, -0.8223],
        [-1.1523, -0.7533]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018865487072616816
Epoch 0, Step 757: train/loss = 0.6974983811378479, train/raw-loss = 0.6972646117210388, train/logprobs = tensor([[-0.7630, -0.8831],
        [-0.8633, -0.8954]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007792601827532053
Epoch 0, Step 758: train/loss = 0.700549840927124, train/raw-loss = 0.6993805170059204, train/logprobs = tensor([[-0.8939, -0.8612],
        [-1.0030, -0.8353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0038976718205958605
Epoch 0, Step 759: train/loss = 0.7015571594238281, train/raw-loss = 0.7013335227966309, train/logprobs = tensor([[-0.9135, -1.0250],
        [-0.9861, -0.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007456864695996046
Epoch 0, Step 760: train/loss = 0.6949650049209595, train/raw-loss = 0.6948814392089844, train/logprobs = tensor([[-0.8971, -0.9957],
        [-0.9066, -0.9819]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027832482010126114
Epoch 0, Step 761: train/loss = 0.6959964632987976, train/raw-loss = 0.6959378123283386, train/logprobs = tensor([[-0.8994, -0.9833],
        [-0.9453, -1.0197]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019524968229234219
Epoch 0, Step 762: train/loss = 0.7275136709213257, train/raw-loss = 0.7250845432281494, train/logprobs = tensor([[-0.8656, -1.2518],
        [-0.9604, -1.0325]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.008096979930996895
Epoch 0, Step 763: train/loss = 0.6983563899993896, train/raw-loss = 0.6978529691696167, train/logprobs = tensor([[-0.8228, -0.9167],
        [-0.8633, -0.9037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016781482845544815
Epoch 0, Step 764: train/loss = 0.708603024482727, train/raw-loss = 0.7082475423812866, train/logprobs = tensor([[-0.7622, -1.0789],
        [-0.9053, -1.0894]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011848751455545425
Epoch 0, Step 765: train/loss = 0.6959466338157654, train/raw-loss = 0.695944607257843, train/logprobs = tensor([[-1.0051, -1.1235],
        [-1.0321, -1.1306]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.745504833816085e-06
Epoch 0, Step 766: train/loss = 0.7131998538970947, train/raw-loss = 0.7121536731719971, train/logprobs = tensor([[-0.9671, -1.2407],
        [-1.0910, -1.1883]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0034873310942202806
Epoch 0, Step 767: train/loss = 0.7218084335327148, train/raw-loss = 0.7213181257247925, train/logprobs = tensor([[-0.9514, -0.9402],
        [-1.1591, -1.0028]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016345324693247676
Epoch 0, Step 768: train/loss = 0.7074577212333679, train/raw-loss = 0.7071391344070435, train/logprobs = tensor([[-0.9818, -0.9392],
        [-1.1270, -0.9370]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010619239183142781
Epoch 0, Step 769: train/loss = 0.696486234664917, train/raw-loss = 0.6959259510040283, train/logprobs = tensor([[-0.9734, -1.0556],
        [-0.9330, -1.0248]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018674512393772602
Epoch 0, Step 770: train/loss = 0.6951632499694824, train/raw-loss = 0.695141077041626, train/logprobs = tensor([[-0.8441, -0.9573],
        [-0.8743, -0.9608]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.39945680834353e-05
Epoch 0, Step 771: train/loss = 0.7126370668411255, train/raw-loss = 0.7124219536781311, train/logprobs = tensor([[-1.0666, -0.8069],
        [-1.3439, -0.7949]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007169068558141589
Epoch 0, Step 772: train/loss = 0.710700273513794, train/raw-loss = 0.7105782628059387, train/logprobs = tensor([[-0.9844, -0.8126],
        [-1.0231, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004067631089128554
Epoch 0, Step 773: train/loss = 0.6939610838890076, train/raw-loss = 0.693785548210144, train/logprobs = tensor([[-1.0961, -1.1596],
        [-1.1445, -1.1128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005853385664522648
Epoch 0, Step 774: train/loss = 0.6952198147773743, train/raw-loss = 0.6949001550674438, train/logprobs = tensor([[-0.8440, -0.8073],
        [-0.9453, -0.8196]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001065828837454319
Epoch 0, Step 775: train/loss = 0.7108442187309265, train/raw-loss = 0.7106924653053284, train/logprobs = tensor([[-0.9442, -1.0676],
        [-0.9998, -1.1667]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000505819742102176
Epoch 0, Step 776: train/loss = 0.6967207193374634, train/raw-loss = 0.6966895461082458, train/logprobs = tensor([[-0.9221, -1.1015],
        [-0.9674, -1.0873]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001040269125951454
Epoch 0, Step 777: train/loss = 0.6995363235473633, train/raw-loss = 0.6992242336273193, train/logprobs = tensor([[-1.0595, -1.1192],
        [-1.1432, -1.0920]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010401709005236626
Epoch 0, Step 778: train/loss = 0.6977823972702026, train/raw-loss = 0.6977768540382385, train/logprobs = tensor([[-0.9845, -0.8956],
        [-1.0114, -0.9029]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.8751350580714643e-05
Epoch 0, Step 779: train/loss = 0.697952926158905, train/raw-loss = 0.6966710090637207, train/logprobs = tensor([[-0.6884, -0.8157],
        [-0.7915, -0.9079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004273183178156614
Epoch 0, Step 780: train/loss = 0.7288456559181213, train/raw-loss = 0.7280498743057251, train/logprobs = tensor([[-1.1361, -0.9848],
        [-1.3226, -1.0013]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002652611117810011
Epoch 0, Step 781: train/loss = 0.7018270492553711, train/raw-loss = 0.7015986442565918, train/logprobs = tensor([[-0.9764, -0.8488],
        [-1.0158, -0.8522]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007615170325152576
Epoch 0, Step 782: train/loss = 0.6934365630149841, train/raw-loss = 0.6934104561805725, train/logprobs = tensor([[-0.8061, -0.8725],
        [-0.8626, -0.8701]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.717106538824737e-05
Epoch 0, Step 783: train/loss = 0.6948635578155518, train/raw-loss = 0.694344162940979, train/logprobs = tensor([[-0.9997, -1.1711],
        [-1.1168, -1.1079]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001731370808556676
Epoch 0, Step 784: train/loss = 0.6945753693580627, train/raw-loss = 0.6938512921333313, train/logprobs = tensor([[-0.9147, -1.0481],
        [-1.0207, -0.9959]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002413562498986721
Epoch 0, Step 785: train/loss = 0.7001727223396301, train/raw-loss = 0.6999421119689941, train/logprobs = tensor([[-0.8216, -0.7612],
        [-0.8636, -0.7405]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007686438038945198
Epoch 0, Step 786: train/loss = 0.6992253661155701, train/raw-loss = 0.6992119550704956, train/logprobs = tensor([[-0.8789, -0.8237],
        [-0.9667, -0.7976]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.464449011720717e-05
Epoch 0, Step 787: train/loss = 0.702794075012207, train/raw-loss = 0.7027382254600525, train/logprobs = tensor([[-0.8655, -0.7177],
        [-0.8948, -0.7402]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018621189519762993
Epoch 0, Step 788: train/loss = 0.6966754794120789, train/raw-loss = 0.6966465711593628, train/logprobs = tensor([[-0.7169, -0.8695],
        [-0.7445, -0.8809]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.609948028810322e-05
Epoch 0, Step 789: train/loss = 0.7180262207984924, train/raw-loss = 0.7172759771347046, train/logprobs = tensor([[-0.8454, -1.1739],
        [-1.0806, -1.1411]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002500892151147127
Epoch 0, Step 790: train/loss = 0.6981948614120483, train/raw-loss = 0.6962984204292297, train/logprobs = tensor([[-0.9013, -0.9761],
        [-1.0092, -1.0956]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006321804132312536
Epoch 0, Step 791: train/loss = 0.6990659832954407, train/raw-loss = 0.6988620758056641, train/logprobs = tensor([[-0.8171, -1.0286],
        [-0.8537, -0.9870]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006797551177442074
Epoch 0, Step 792: train/loss = 0.6948365569114685, train/raw-loss = 0.6947143077850342, train/logprobs = tensor([[-0.7819, -0.8605],
        [-0.7617, -0.8415]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040745583828538656
Epoch 0, Step 793: train/loss = 0.6944167017936707, train/raw-loss = 0.6932840347290039, train/logprobs = tensor([[-0.8983, -0.8936],
        [-0.9721, -0.9356]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.003775656223297119
Epoch 0, Step 794: train/loss = 0.7019197940826416, train/raw-loss = 0.7014753818511963, train/logprobs = tensor([[-0.8486, -0.7073],
        [-0.9360, -0.6525]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014812846202403307
Epoch 0, Step 795: train/loss = 0.698906660079956, train/raw-loss = 0.6988538503646851, train/logprobs = tensor([[-1.0424, -0.9920],
        [-1.1135, -1.0047]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00017601641593500972
Epoch 0, Step 796: train/loss = 0.715094804763794, train/raw-loss = 0.7145704030990601, train/logprobs = tensor([[-0.9029, -0.8507],
        [-0.9283, -0.7634]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0017478958470746875
Epoch 0, Step 797: train/loss = 0.6988335847854614, train/raw-loss = 0.6987497806549072, train/logprobs = tensor([[-0.8900, -1.0209],
        [-0.9978, -0.9865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002793915627989918
Epoch 0, Step 798: train/loss = 0.7027699947357178, train/raw-loss = 0.7025938034057617, train/logprobs = tensor([[-0.9362, -0.8378],
        [-0.9606, -0.8311]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005875807255506516
Epoch 0, Step 799: train/loss = 0.7056884169578552, train/raw-loss = 0.705649197101593, train/logprobs = tensor([[-1.0119, -1.1009],
        [-1.0891, -1.1137]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013090473657939583
Epoch 0, Step 800: train/loss = 0.7014836072921753, train/raw-loss = 0.7013965845108032, train/logprobs = tensor([[-0.9027, -1.0870],
        [-0.9530, -1.0072]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029015413019806147
Epoch 0, Step 801: train/loss = 0.6946161389350891, train/raw-loss = 0.6945755481719971, train/logprobs = tensor([[-0.8039, -0.7825],
        [-0.8226, -0.7048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00013529451098293066
Epoch 0, Step 802: train/loss = 0.7246493101119995, train/raw-loss = 0.724641740322113, train/logprobs = tensor([[-0.6753, -0.8100],
        [-0.6970, -0.8097]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.5267276214435697e-05
Epoch 0, Step 803: train/loss = 0.6946402788162231, train/raw-loss = 0.6944928765296936, train/logprobs = tensor([[-0.8014, -0.8102],
        [-0.8286, -0.7614]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004912624717690051
Epoch 0, Step 804: train/loss = 0.6969285607337952, train/raw-loss = 0.6965621709823608, train/logprobs = tensor([[-0.8290, -0.7646],
        [-0.8762, -0.7569]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012214171001687646
Epoch 0, Step 805: train/loss = 0.6973807215690613, train/raw-loss = 0.6972793340682983, train/logprobs = tensor([[-0.8565, -0.8356],
        [-0.8752, -0.7893]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00033798726508393884
Epoch 0, Step 806: train/loss = 0.6927908062934875, train/raw-loss = 0.6923779845237732, train/logprobs = tensor([[-1.0846, -1.0864],
        [-1.2315, -1.0069]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013761123409494758
Epoch 0, Step 807: train/loss = 0.6937300562858582, train/raw-loss = 0.6937021017074585, train/logprobs = tensor([[-0.8632, -0.8625],
        [-1.0016, -0.9152]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.314613998867571e-05
Epoch 0, Step 808: train/loss = 0.693982720375061, train/raw-loss = 0.6935195922851562, train/logprobs = tensor([[-0.7952, -0.8873],
        [-0.8455, -0.8777]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001543761813081801
Epoch 0, Step 809: train/loss = 0.7030118107795715, train/raw-loss = 0.7029321193695068, train/logprobs = tensor([[-0.9758, -1.1375],
        [-1.0566, -1.1303]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00026568735484033823
Epoch 0, Step 810: train/loss = 0.7138375043869019, train/raw-loss = 0.7133846282958984, train/logprobs = tensor([[-0.8993, -1.0563],
        [-0.9756, -1.0138]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0015096832066774368
Epoch 0, Step 811: train/loss = 0.7101117968559265, train/raw-loss = 0.7083892822265625, train/logprobs = tensor([[-1.0568, -0.9742],
        [-1.1155, -1.0202]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005741708446294069
Epoch 0, Step 812: train/loss = 0.6890402436256409, train/raw-loss = 0.6888656616210938, train/logprobs = tensor([[-1.0017, -1.0584],
        [-1.1492, -0.9065]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000581928645260632
Epoch 0, Step 813: train/loss = 0.6933615803718567, train/raw-loss = 0.6933282613754272, train/logprobs = tensor([[-0.8559, -0.9294],
        [-0.9361, -0.9057]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011112436186522245
Epoch 0, Step 814: train/loss = 0.7124999761581421, train/raw-loss = 0.7124137878417969, train/logprobs = tensor([[-0.8778, -1.1060],
        [-0.9229, -1.0867]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028714066138491035
Epoch 0, Step 815: train/loss = 0.7125034928321838, train/raw-loss = 0.712068498134613, train/logprobs = tensor([[-0.8261, -1.2525],
        [-0.8776, -1.1808]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014501784462481737
Epoch 0, Step 816: train/loss = 0.6924291849136353, train/raw-loss = 0.6920520067214966, train/logprobs = tensor([[-0.9374, -1.0390],
        [-1.0293, -0.9783]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001257085707038641
Epoch 0, Step 817: train/loss = 0.6981055736541748, train/raw-loss = 0.6979718208312988, train/logprobs = tensor([[-0.8762, -1.0820],
        [-0.9617, -1.0531]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00044580106623470783
Epoch 0, Step 818: train/loss = 0.7176517248153687, train/raw-loss = 0.7173927426338196, train/logprobs = tensor([[-0.8902, -1.2197],
        [-0.8936, -1.2094]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000863215362187475
Epoch 0, Step 819: train/loss = 0.7102594971656799, train/raw-loss = 0.709711492061615, train/logprobs = tensor([[-0.9782, -0.8512],
        [-1.0935, -0.8564]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001826853840611875
Epoch 0, Step 820: train/loss = 0.698857307434082, train/raw-loss = 0.6984976530075073, train/logprobs = tensor([[-0.8146, -0.5845],
        [-0.8108, -0.6296]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011985944584012032
Epoch 0, Step 821: train/loss = 0.7019615173339844, train/raw-loss = 0.7017961144447327, train/logprobs = tensor([[-0.8674, -1.0666],
        [-0.9137, -0.9350]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000551339820958674
Epoch 0, Step 822: train/loss = 0.700839638710022, train/raw-loss = 0.700767457485199, train/logprobs = tensor([[-1.0661, -1.0171],
        [-1.1068, -0.9570]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024091589148156345
Epoch 0, Step 823: train/loss = 0.6936962604522705, train/raw-loss = 0.6932929754257202, train/logprobs = tensor([[-0.7422, -0.7123],
        [-0.7135, -0.7565]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013443445786833763
Epoch 0, Step 824: train/loss = 0.7061518430709839, train/raw-loss = 0.7058597803115845, train/logprobs = tensor([[-0.8159, -1.0281],
        [-0.8392, -1.1070]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009734093910083175
Epoch 0, Step 825: train/loss = 0.7279889583587646, train/raw-loss = 0.7272937297821045, train/logprobs = tensor([[-1.2163, -0.9169],
        [-1.3296, -0.9183]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023174702655524015
Epoch 0, Step 826: train/loss = 0.7196660041809082, train/raw-loss = 0.719183623790741, train/logprobs = tensor([[-0.9211, -1.4008],
        [-0.9965, -1.3464]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016077151522040367
Epoch 0, Step 827: train/loss = 0.6986938118934631, train/raw-loss = 0.6986368298530579, train/logprobs = tensor([[-0.7746, -0.9472],
        [-0.8011, -0.9368]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018981279572471976
Epoch 0, Step 828: train/loss = 0.7014508843421936, train/raw-loss = 0.700945258140564, train/logprobs = tensor([[-0.8057, -0.9814],
        [-0.9263, -1.0501]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016857115551829338
Epoch 0, Step 829: train/loss = 0.7459916472434998, train/raw-loss = 0.7458711862564087, train/logprobs = tensor([[-1.0018, -1.3223],
        [-1.0388, -1.2186]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00040142389480024576
Epoch 0, Step 830: train/loss = 0.7208762764930725, train/raw-loss = 0.7201110124588013, train/logprobs = tensor([[-0.8592, -1.3228],
        [-1.0298, -1.2396]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0025507155805826187
Epoch 0, Step 831: train/loss = 0.7125428915023804, train/raw-loss = 0.7119354605674744, train/logprobs = tensor([[-0.8998, -0.8831],
        [-0.9784, -0.8128]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00202482333406806
Epoch 0, Step 832: train/loss = 0.6943509578704834, train/raw-loss = 0.6939527988433838, train/logprobs = tensor([[-0.9098, -0.9302],
        [-1.1072, -0.9714]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013272329233586788
Epoch 0, Step 833: train/loss = 0.695857048034668, train/raw-loss = 0.6958302855491638, train/logprobs = tensor([[-0.9237, -1.0548],
        [-1.0103, -0.9727]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.914295904105529e-05
Epoch 0, Step 834: train/loss = 0.6956027746200562, train/raw-loss = 0.6954753398895264, train/logprobs = tensor([[-0.9555, -0.9542],
        [-0.9922, -0.8696]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042466120794415474
Epoch 0, Step 835: train/loss = 0.7007413506507874, train/raw-loss = 0.6998674273490906, train/logprobs = tensor([[-1.0145, -1.0355],
        [-1.1041, -1.0797]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029129062313586473
Epoch 0, Step 836: train/loss = 0.6933680176734924, train/raw-loss = 0.6931238174438477, train/logprobs = tensor([[-0.9374, -1.0209],
        [-1.0357, -1.0181]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008141340222209692
Epoch 0, Step 837: train/loss = 0.7012398838996887, train/raw-loss = 0.6995612382888794, train/logprobs = tensor([[-0.8278, -1.0589],
        [-0.8975, -0.9890]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.005595325026661158
Epoch 0, Step 838: train/loss = 0.7050985097885132, train/raw-loss = 0.7032544016838074, train/logprobs = tensor([[-1.0084, -1.2751],
        [-1.0462, -1.0687]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.006147020496428013
Epoch 0, Step 839: train/loss = 0.6967534422874451, train/raw-loss = 0.69651859998703, train/logprobs = tensor([[-0.9171, -1.0576],
        [-1.0639, -1.1142]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007827794179320335
Epoch 0, Step 840: train/loss = 0.7720056772232056, train/raw-loss = 0.7719324827194214, train/logprobs = tensor([[-0.8243, -1.4399],
        [-0.8562, -1.4034]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00024391617625951767
Epoch 0, Step 841: train/loss = 0.7133775949478149, train/raw-loss = 0.7131304144859314, train/logprobs = tensor([[-0.8201, -1.1279],
        [-0.8994, -1.0659]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008237599395215511
Epoch 0, Step 842: train/loss = 0.6986324787139893, train/raw-loss = 0.6985682249069214, train/logprobs = tensor([[-0.9502, -0.8557],
        [-0.9391, -0.8119]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00021426132298074663
Epoch 0, Step 843: train/loss = 0.7040971517562866, train/raw-loss = 0.703255295753479, train/logprobs = tensor([[-1.1450, -1.1325],
        [-1.2514, -1.1677]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0028062607161700726
Epoch 0, Step 844: train/loss = 0.693659782409668, train/raw-loss = 0.6936545372009277, train/logprobs = tensor([[-0.7834, -0.8507],
        [-0.8057, -0.8442]], device='cuda:0', grad_fn=<DivBackward0>), KL = 1.7170987121062353e-05
Epoch 0, Step 845: train/loss = 0.6952779293060303, train/raw-loss = 0.6948761940002441, train/logprobs = tensor([[-0.9863, -1.0225],
        [-1.0172, -0.9642]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013391090324148536
Epoch 0, Step 846: train/loss = 0.7112500071525574, train/raw-loss = 0.7109599113464355, train/logprobs = tensor([[-0.8432, -1.1373],
        [-0.8589, -1.0603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009668684215284884
Epoch 0, Step 847: train/loss = 0.69521564245224, train/raw-loss = 0.6952062249183655, train/logprobs = tensor([[-0.8867, -0.8297],
        [-0.9326, -0.8425]], device='cuda:0', grad_fn=<DivBackward0>), KL = 3.1279108952730894e-05
Epoch 0, Step 848: train/loss = 0.7219863533973694, train/raw-loss = 0.721971869468689, train/logprobs = tensor([[-1.0090, -0.8632],
        [-1.0675, -0.8776]], device='cuda:0', grad_fn=<DivBackward0>), KL = 4.81926035718061e-05
Epoch 0, Step 849: train/loss = 0.708749532699585, train/raw-loss = 0.7081730961799622, train/logprobs = tensor([[-0.9168, -1.0907],
        [-1.0020, -1.0410]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019213929772377014
Epoch 0, Step 850: train/loss = 0.692338228225708, train/raw-loss = 0.6921953558921814, train/logprobs = tensor([[-0.7276, -0.7657],
        [-0.8550, -0.7231]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00047638220712542534
Epoch 0, Step 851: train/loss = 0.705047070980072, train/raw-loss = 0.7048401832580566, train/logprobs = tensor([[-0.9502, -0.9533],
        [-1.0307, -0.9193]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006899029831402004
Epoch 0, Step 852: train/loss = 0.6928912401199341, train/raw-loss = 0.6926445960998535, train/logprobs = tensor([[-1.1987, -1.2614],
        [-1.1120, -1.0450]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008221025345847011
Epoch 0, Step 853: train/loss = 0.70868980884552, train/raw-loss = 0.7081996202468872, train/logprobs = tensor([[-0.7445, -1.0566],
        [-0.8070, -0.8939]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016339251305907965
Epoch 0, Step 854: train/loss = 0.7018387317657471, train/raw-loss = 0.7017501592636108, train/logprobs = tensor([[-1.0483, -0.8951],
        [-1.0825, -0.8369]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00029512617038562894
Epoch 0, Step 855: train/loss = 0.7075719833374023, train/raw-loss = 0.7075399160385132, train/logprobs = tensor([[-1.1065, -0.8687],
        [-1.0887, -0.8039]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001069379213731736
Epoch 0, Step 856: train/loss = 0.7049641609191895, train/raw-loss = 0.7046471834182739, train/logprobs = tensor([[-0.9234, -1.0751],
        [-1.0039, -0.9636]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010563614778220654
Epoch 0, Step 857: train/loss = 0.6970958113670349, train/raw-loss = 0.6970775723457336, train/logprobs = tensor([[-0.7929, -0.8917],
        [-0.8107, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.073682743590325e-05
Epoch 0, Step 858: train/loss = 0.6993156671524048, train/raw-loss = 0.6989225745201111, train/logprobs = tensor([[-0.9037, -1.0178],
        [-0.9818, -1.0042]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013103079982101917
Epoch 0, Step 859: train/loss = 0.6984508633613586, train/raw-loss = 0.6984142065048218, train/logprobs = tensor([[-0.8297, -0.8527],
        [-0.8672, -0.8407]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001222092832904309
Epoch 0, Step 860: train/loss = 0.7055174112319946, train/raw-loss = 0.7053355574607849, train/logprobs = tensor([[-0.8053, -1.2315],
        [-0.8524, -0.9610]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006061665480956435
Epoch 0, Step 861: train/loss = 0.7175120115280151, train/raw-loss = 0.7172073721885681, train/logprobs = tensor([[-0.9491, -0.9562],
        [-0.9630, -0.9621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010154751362279058
Epoch 0, Step 862: train/loss = 0.6923998594284058, train/raw-loss = 0.6923590898513794, train/logprobs = tensor([[-0.9731, -1.0881],
        [-1.1252, -1.0479]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001358222507406026
Epoch 0, Step 863: train/loss = 0.6972306370735168, train/raw-loss = 0.6966718435287476, train/logprobs = tensor([[-1.0915, -1.0586],
        [-1.2184, -0.9611]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0018625403754413128
Epoch 0, Step 864: train/loss = 0.735700249671936, train/raw-loss = 0.7352572083473206, train/logprobs = tensor([[-1.0022, -1.3797],
        [-1.0163, -1.2881]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014766238164156675
Epoch 0, Step 865: train/loss = 0.6986241340637207, train/raw-loss = 0.6984583735466003, train/logprobs = tensor([[-0.8888, -0.9851],
        [-1.0085, -0.9398]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005526668974198401
Epoch 0, Step 866: train/loss = 0.6987902522087097, train/raw-loss = 0.6986939311027527, train/logprobs = tensor([[-0.8303, -0.8914],
        [-0.8943, -0.9211]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003209045680705458
Epoch 0, Step 867: train/loss = 0.718977689743042, train/raw-loss = 0.7183444499969482, train/logprobs = tensor([[-0.7976, -1.4089],
        [-0.8644, -1.2048]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021107846405357122
Epoch 0, Step 868: train/loss = 0.7154791951179504, train/raw-loss = 0.7154532670974731, train/logprobs = tensor([[-1.1112, -1.0253],
        [-1.1541, -0.9868]], device='cuda:0', grad_fn=<DivBackward0>), KL = 8.639616862637922e-05
Epoch 0, Step 869: train/loss = 0.699545681476593, train/raw-loss = 0.6992610096931458, train/logprobs = tensor([[-0.8632, -0.9492],
        [-0.8902, -0.8685]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009489376679994166
Epoch 0, Step 870: train/loss = 0.6967284679412842, train/raw-loss = 0.6967098712921143, train/logprobs = tensor([[-0.8064, -0.8033],
        [-0.8229, -0.7925]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.186296377563849e-05
Epoch 0, Step 871: train/loss = 0.7460664510726929, train/raw-loss = 0.7456556558609009, train/logprobs = tensor([[-0.9882, -1.2806],
        [-1.0628, -1.1852]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013692472130060196
Epoch 0, Step 872: train/loss = 0.6939507722854614, train/raw-loss = 0.6939207315444946, train/logprobs = tensor([[-0.9382, -1.0452],
        [-0.9326, -0.9807]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00010033161379396915
Epoch 0, Step 873: train/loss = 0.7126189470291138, train/raw-loss = 0.7123998403549194, train/logprobs = tensor([[-1.0150, -0.9815],
        [-1.1048, -0.9795]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007305122562684119
Epoch 0, Step 874: train/loss = 0.6959770917892456, train/raw-loss = 0.6952667832374573, train/logprobs = tensor([[-1.0313, -1.1451],
        [-1.0898, -1.1125]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023677428252995014
Epoch 0, Step 875: train/loss = 0.7132503390312195, train/raw-loss = 0.7130770087242126, train/logprobs = tensor([[-0.9278, -1.2061],
        [-0.9321, -1.1523]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005777705810032785
Epoch 0, Step 876: train/loss = 0.6978832483291626, train/raw-loss = 0.6978623867034912, train/logprobs = tensor([[-0.9584, -1.0348],
        [-1.0307, -0.9030]], device='cuda:0', grad_fn=<DivBackward0>), KL = 6.964616477489471e-05
Epoch 0, Step 877: train/loss = 0.7228153347969055, train/raw-loss = 0.7227739691734314, train/logprobs = tensor([[-0.7348, -0.9700],
        [-0.7957, -0.9355]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001381001784466207
Epoch 0, Step 878: train/loss = 0.719123363494873, train/raw-loss = 0.7189534306526184, train/logprobs = tensor([[-0.9601, -1.3219],
        [-1.0119, -1.1661]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005663438932970166
Epoch 0, Step 879: train/loss = 0.7095644474029541, train/raw-loss = 0.7093515396118164, train/logprobs = tensor([[-0.7811, -1.1026],
        [-0.8100, -1.1275]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007095994660630822
Epoch 0, Step 880: train/loss = 0.6982136964797974, train/raw-loss = 0.6981393098831177, train/logprobs = tensor([[-1.0475, -0.9708],
        [-1.1678, -0.9458]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002479146933183074
Epoch 0, Step 881: train/loss = 0.6975833177566528, train/raw-loss = 0.6974331736564636, train/logprobs = tensor([[-0.9634, -0.9717],
        [-0.9818, -0.9633]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005003397818654776
Epoch 0, Step 882: train/loss = 0.7071586847305298, train/raw-loss = 0.7067734003067017, train/logprobs = tensor([[-0.8831, -1.1680],
        [-0.8755, -1.1865]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012842738069593906
Epoch 0, Step 883: train/loss = 0.7022740840911865, train/raw-loss = 0.702030599117279, train/logprobs = tensor([[-0.8125, -1.0039],
        [-0.8602, -1.0116]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008117677643895149
Epoch 0, Step 884: train/loss = 0.6970874071121216, train/raw-loss = 0.6969003081321716, train/logprobs = tensor([[-0.8960, -1.0796],
        [-0.8949, -0.9941]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006236552726477385
Epoch 0, Step 885: train/loss = 0.7010619640350342, train/raw-loss = 0.7010025978088379, train/logprobs = tensor([[-0.8782, -1.0507],
        [-0.9596, -1.0637]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00019807189528364688
Epoch 0, Step 886: train/loss = 0.7157196402549744, train/raw-loss = 0.7155357599258423, train/logprobs = tensor([[-0.6523, -1.0430],
        [-0.6914, -0.9084]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006129519315436482
Epoch 0, Step 887: train/loss = 0.7881650924682617, train/raw-loss = 0.7874761819839478, train/logprobs = tensor([[-1.0500, -1.5444],
        [-1.1131, -1.4670]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0022961420472711325
Epoch 0, Step 888: train/loss = 0.6929571032524109, train/raw-loss = 0.6922482252120972, train/logprobs = tensor([[-0.8254, -1.0620],
        [-0.8946, -0.8778]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023627912160009146
Epoch 0, Step 889: train/loss = 0.7076334953308105, train/raw-loss = 0.7074171304702759, train/logprobs = tensor([[-0.8283, -0.7628],
        [-0.9304, -0.7587]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007212720811367035
Epoch 0, Step 890: train/loss = 0.6953812837600708, train/raw-loss = 0.6952561140060425, train/logprobs = tensor([[-1.0917, -1.1124],
        [-1.1787, -0.9443]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00041716574924066663
Epoch 0, Step 891: train/loss = 0.7125521898269653, train/raw-loss = 0.7124495506286621, train/logprobs = tensor([[-0.9520, -0.9205],
        [-1.0075, -0.8891]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003421169240027666
Epoch 0, Step 892: train/loss = 0.7248443365097046, train/raw-loss = 0.7239503860473633, train/logprobs = tensor([[-1.2949, -1.1644],
        [-1.6991, -1.1729]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002979857847094536
Epoch 0, Step 893: train/loss = 0.6944209337234497, train/raw-loss = 0.6943279504776001, train/logprobs = tensor([[-0.8030, -0.8659],
        [-0.8526, -0.8516]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003101146430708468
Epoch 0, Step 894: train/loss = 0.6952706575393677, train/raw-loss = 0.695159375667572, train/logprobs = tensor([[-0.7423, -0.8190],
        [-0.7878, -0.8265]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003712029429152608
Epoch 0, Step 895: train/loss = 0.7031413316726685, train/raw-loss = 0.7024897336959839, train/logprobs = tensor([[-1.0590, -1.1709],
        [-1.1471, -1.2260]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021718768402934074
Epoch 0, Step 896: train/loss = 0.7013493180274963, train/raw-loss = 0.7013258934020996, train/logprobs = tensor([[-0.9752, -0.8845],
        [-1.0458, -0.7839]], device='cuda:0', grad_fn=<DivBackward0>), KL = 7.788772927597165e-05
Epoch 0, Step 897: train/loss = 0.7152823209762573, train/raw-loss = 0.7151559591293335, train/logprobs = tensor([[-1.0099, -0.7221],
        [-1.0891, -0.6994]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00042127794586122036
Epoch 0, Step 898: train/loss = 0.7006014585494995, train/raw-loss = 0.7004391551017761, train/logprobs = tensor([[-0.8887, -0.9263],
        [-1.1369, -0.9866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005410420708358288
Epoch 0, Step 899: train/loss = 0.7002177238464355, train/raw-loss = 0.6999725699424744, train/logprobs = tensor([[-0.9341, -0.8229],
        [-1.1095, -0.8161]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008170561050064862
Epoch 0, Step 900: train/loss = 0.6954633593559265, train/raw-loss = 0.6951785087585449, train/logprobs = tensor([[-0.7569, -0.8609],
        [-0.8162, -0.7971]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009493499528616667
Epoch 0, Step 901: train/loss = 0.698724091053009, train/raw-loss = 0.6986331939697266, train/logprobs = tensor([[-0.9679, -0.9433],
        [-1.0692, -0.9716]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030313554452732205
Epoch 0, Step 902: train/loss = 0.7181492447853088, train/raw-loss = 0.7175511121749878, train/logprobs = tensor([[-0.8902, -1.3571],
        [-0.9564, -1.1192]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019936643075197935
Epoch 0, Step 903: train/loss = 0.7036772966384888, train/raw-loss = 0.7014003396034241, train/logprobs = tensor([[-1.0412, -1.1129],
        [-1.0410, -1.1814]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.007589865475893021
Epoch 0, Step 904: train/loss = 0.6957608461380005, train/raw-loss = 0.6956902146339417, train/logprobs = tensor([[-0.9928, -1.0962],
        [-1.1229, -1.0259]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00023553697974421084
Epoch 0, Step 905: train/loss = 0.6980224251747131, train/raw-loss = 0.6979174017906189, train/logprobs = tensor([[-0.8814, -0.7870],
        [-0.8845, -0.8304]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034994189627468586
Epoch 0, Step 906: train/loss = 0.6949722766876221, train/raw-loss = 0.6948854923248291, train/logprobs = tensor([[-0.9009, -0.9965],
        [-1.0290, -0.9435]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00028941809432581067
Epoch 0, Step 907: train/loss = 0.693290114402771, train/raw-loss = 0.6929956674575806, train/logprobs = tensor([[-0.7808, -0.8891],
        [-0.8344, -0.8447]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009815117809921503
Epoch 0, Step 908: train/loss = 0.699924111366272, train/raw-loss = 0.6990310549736023, train/logprobs = tensor([[-0.8186, -0.9776],
        [-0.8343, -0.9412]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0029769688844680786
Epoch 0, Step 909: train/loss = 0.7057003378868103, train/raw-loss = 0.7056654095649719, train/logprobs = tensor([[-1.0064, -1.1928],
        [-1.1119, -1.1732]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00011632696259766817
Epoch 0, Step 910: train/loss = 0.7001099586486816, train/raw-loss = 0.7000409960746765, train/logprobs = tensor([[-0.9826, -1.1144],
        [-0.9600, -1.0333]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002298314357176423
Epoch 0, Step 911: train/loss = 0.6932058334350586, train/raw-loss = 0.6931993961334229, train/logprobs = tensor([[-0.9421, -0.9294],
        [-0.9395, -0.8875]], device='cuda:0', grad_fn=<DivBackward0>), KL = 2.1411149646155536e-05
Epoch 0, Step 912: train/loss = 0.6959806084632874, train/raw-loss = 0.6959056854248047, train/logprobs = tensor([[-1.0302, -1.0978],
        [-1.0780, -1.0621]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002497811510693282
Epoch 0, Step 913: train/loss = 0.6985408663749695, train/raw-loss = 0.6976454257965088, train/logprobs = tensor([[-1.0868, -0.9893],
        [-1.2208, -0.9191]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002984839491546154
Epoch 0, Step 914: train/loss = 0.6946235299110413, train/raw-loss = 0.6945847868919373, train/logprobs = tensor([[-0.8689, -0.9022],
        [-0.8968, -0.9247]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00012916872219648212
Epoch 0, Step 915: train/loss = 0.6945268511772156, train/raw-loss = 0.6940817832946777, train/logprobs = tensor([[-0.8156, -1.0256],
        [-0.8996, -0.9158]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014836109476163983
Epoch 0, Step 916: train/loss = 0.6945735216140747, train/raw-loss = 0.6942605376243591, train/logprobs = tensor([[-0.9286, -0.9468],
        [-0.9437, -0.8581]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0010433702263981104
Epoch 0, Step 917: train/loss = 0.6957781910896301, train/raw-loss = 0.6943384408950806, train/logprobs = tensor([[-0.8378, -0.9424],
        [-1.0187, -0.9206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.004798993933945894
Epoch 0, Step 918: train/loss = 0.7018611431121826, train/raw-loss = 0.701221227645874, train/logprobs = tensor([[-0.8304, -0.9324],
        [-0.9442, -0.8998]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0021332704927772284
Epoch 0, Step 919: train/loss = 0.7373902201652527, train/raw-loss = 0.7372994422912598, train/logprobs = tensor([[-0.8854, -0.7203],
        [-1.1586, -0.6537]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00030247250106185675
Epoch 0, Step 920: train/loss = 0.7559914588928223, train/raw-loss = 0.7555527687072754, train/logprobs = tensor([[-1.0554, -1.5108],
        [-1.0438, -1.3099]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014620124129578471
Epoch 0, Step 921: train/loss = 0.718611478805542, train/raw-loss = 0.7183772325515747, train/logprobs = tensor([[-0.9286, -0.9534],
        [-0.9358, -0.8866]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0007807757938280702
Epoch 0, Step 922: train/loss = 0.71073979139328, train/raw-loss = 0.7105558514595032, train/logprobs = tensor([[-0.9797, -1.2090],
        [-1.0375, -1.1431]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000613157928455621
Epoch 0, Step 923: train/loss = 0.7355259656906128, train/raw-loss = 0.7345678806304932, train/logprobs = tensor([[-0.9134, -1.4239],
        [-0.9968, -1.2229]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0031936941668391228
Epoch 0, Step 924: train/loss = 0.7040538787841797, train/raw-loss = 0.7036482095718384, train/logprobs = tensor([[-1.0280, -0.8547],
        [-1.0034, -0.8252]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0013520955108106136
Epoch 0, Step 925: train/loss = 0.6956974267959595, train/raw-loss = 0.6955538392066956, train/logprobs = tensor([[-1.0202, -0.9438],
        [-0.9299, -0.8625]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0004786589415743947
Epoch 0, Step 926: train/loss = 0.7009211778640747, train/raw-loss = 0.7007625699043274, train/logprobs = tensor([[-0.9253, -1.0808],
        [-1.0044, -1.0345]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005287950043566525
Epoch 0, Step 927: train/loss = 0.7029707431793213, train/raw-loss = 0.702483057975769, train/logprobs = tensor([[-1.0674, -0.9752],
        [-1.1536, -0.9803]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016256736125797033
Epoch 0, Step 928: train/loss = 0.6990832686424255, train/raw-loss = 0.6983745694160461, train/logprobs = tensor([[-0.8753, -0.9700],
        [-0.9753, -0.9430]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0023622428998351097
Epoch 0, Step 929: train/loss = 0.7009085416793823, train/raw-loss = 0.7008259296417236, train/logprobs = tensor([[-0.9881, -1.1743],
        [-0.9481, -1.0214]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00027529947692528367
Epoch 0, Step 930: train/loss = 0.7259482145309448, train/raw-loss = 0.7256556749343872, train/logprobs = tensor([[-0.8673, -1.2414],
        [-0.8738, -1.0963]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000975028146058321
Epoch 0, Step 931: train/loss = 0.7012059092521667, train/raw-loss = 0.7011104822158813, train/logprobs = tensor([[-0.6997, -0.9734],
        [-0.7823, -0.9225]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031802727608010173
Epoch 0, Step 932: train/loss = 0.7090693116188049, train/raw-loss = 0.708976149559021, train/logprobs = tensor([[-0.9032, -1.2465],
        [-0.9179, -1.1353]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031055824365466833
Epoch 0, Step 933: train/loss = 0.7012605667114258, train/raw-loss = 0.7009190320968628, train/logprobs = tensor([[-0.9352, -1.1155],
        [-0.9539, -0.9977]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.001138471532613039
Epoch 0, Step 934: train/loss = 0.7004737854003906, train/raw-loss = 0.7003688216209412, train/logprobs = tensor([[-0.7319, -0.8206],
        [-0.7975, -0.7616]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00034980266354978085
Epoch 0, Step 935: train/loss = 0.7082914710044861, train/raw-loss = 0.7081562280654907, train/logprobs = tensor([[-0.9267, -0.8163],
        [-0.9844, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00045098550617694855
Epoch 0, Step 936: train/loss = 0.7101673483848572, train/raw-loss = 0.7097285985946655, train/logprobs = tensor([[-1.1987, -1.0081],
        [-1.3047, -0.9272]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0014623040333390236
Epoch 0, Step 937: train/loss = 0.7167041301727295, train/raw-loss = 0.716675341129303, train/logprobs = tensor([[-0.8852, -1.1154],
        [-0.9218, -1.1002]], device='cuda:0', grad_fn=<DivBackward0>), KL = 9.592118294676766e-05
Epoch 0, Step 938: train/loss = 0.7076866626739502, train/raw-loss = 0.7075973749160767, train/logprobs = tensor([[-0.9451, -0.7857],
        [-0.9556, -0.6955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000297612976282835
Epoch 0, Step 939: train/loss = 0.6995193958282471, train/raw-loss = 0.6994259357452393, train/logprobs = tensor([[-0.8984, -1.0022],
        [-0.9668, -1.0027]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00031134573509916663
Epoch 0, Step 940: train/loss = 0.7099353671073914, train/raw-loss = 0.709252119064331, train/logprobs = tensor([[-1.0300, -1.2526],
        [-1.1911, -1.1574]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.002277462976053357
Epoch 0, Step 941: train/loss = 0.6945772171020508, train/raw-loss = 0.6945216655731201, train/logprobs = tensor([[-1.0517, -1.1159],
        [-1.0746, -1.0037]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00018539070151746273
Epoch 0, Step 942: train/loss = 0.6935973763465881, train/raw-loss = 0.6934946775436401, train/logprobs = tensor([[-0.6860, -0.7485],
        [-0.6986, -0.7237]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003423705929890275
Epoch 0, Step 943: train/loss = 0.7127285599708557, train/raw-loss = 0.7123621702194214, train/logprobs = tensor([[-1.0273, -0.9343],
        [-1.1304, -0.7719]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0012214966118335724
Epoch 0, Step 944: train/loss = 0.7043873071670532, train/raw-loss = 0.7043259143829346, train/logprobs = tensor([[-1.1208, -1.4490],
        [-1.1711, -1.3255]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002047999296337366
Epoch 0, Step 945: train/loss = 0.6978046298027039, train/raw-loss = 0.6976381540298462, train/logprobs = tensor([[-0.8510, -1.0055],
        [-0.9135, -0.9234]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005546524189412594
Epoch 0, Step 946: train/loss = 0.7172971367835999, train/raw-loss = 0.7171387076377869, train/logprobs = tensor([[-0.9106, -1.0667],
        [-0.9360, -1.0031]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005282777710817754
Epoch 0, Step 947: train/loss = 0.6940504312515259, train/raw-loss = 0.6938666105270386, train/logprobs = tensor([[-0.8741, -0.8371],
        [-0.9492, -0.8603]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0006126202642917633
Epoch 0, Step 948: train/loss = 0.6943085789680481, train/raw-loss = 0.6942598223686218, train/logprobs = tensor([[-0.9134, -0.8952],
        [-0.9156, -0.8357]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000162669166456908
Epoch 0, Step 949: train/loss = 0.704356849193573, train/raw-loss = 0.7042742371559143, train/logprobs = tensor([[-0.8505, -0.7536],
        [-0.9255, -0.6980]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0002752268046606332
Epoch 0, Step 950: train/loss = 0.693411111831665, train/raw-loss = 0.6933634281158447, train/logprobs = tensor([[-0.7764, -0.7946],
        [-0.9340, -0.8913]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.00015888398047536612
Epoch 0, Step 951: train/loss = 0.7166801691055298, train/raw-loss = 0.7164168357849121, train/logprobs = tensor([[-1.1542, -1.3923],
        [-1.0645, -1.2168]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0008777193143032491
Epoch 0, Step 952: train/loss = 0.7259204387664795, train/raw-loss = 0.7257583141326904, train/logprobs = tensor([[-0.8407, -1.1568],
        [-0.8527, -1.0712]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005404464318417013
Epoch 0, Step 953: train/loss = 0.7312500476837158, train/raw-loss = 0.7311924695968628, train/logprobs = tensor([[-0.9157, -1.1858],
        [-0.9392, -1.1206]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0001919955393532291
Epoch 0, Step 954: train/loss = 0.6937378644943237, train/raw-loss = 0.6931538581848145, train/logprobs = tensor([[-0.8665, -0.9736],
        [-0.9472, -0.9486]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0019466654630377889
Epoch 0, Step 955: train/loss = 0.695769190788269, train/raw-loss = 0.6952758431434631, train/logprobs = tensor([[-0.9133, -0.8752],
        [-1.0774, -0.8256]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0016446978552266955
Epoch 0, Step 956: train/loss = 0.6979711651802063, train/raw-loss = 0.6976311206817627, train/logprobs = tensor([[-0.6966, -0.9049],
        [-0.8538, -0.8126]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0011337138712406158
Epoch 0, Step 957: train/loss = 0.694720983505249, train/raw-loss = 0.6946200728416443, train/logprobs = tensor([[-0.8818, -1.0270],
        [-0.9418, -0.9194]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0003361768904142082
Epoch 0, Step 958: train/loss = 0.7077188491821289, train/raw-loss = 0.7075577974319458, train/logprobs = tensor([[-0.8681, -1.0599],
        [-0.9017, -0.9898]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.000536928593646735
Epoch 0, Step 959: train/loss = 0.7052299380302429, train/raw-loss = 0.7050766944885254, train/logprobs = tensor([[-0.9035, -0.8606],
        [-1.0086, -0.7955]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0005106579628773034
Epoch 0, Step 960: train/loss = 0.7188535928726196, train/raw-loss = 0.7185696959495544, train/logprobs = tensor([[-0.8628, -1.1617],
        [-0.9054, -1.0349]], device='cuda:0', grad_fn=<DivBackward0>), KL = 0.0009464924223721027
